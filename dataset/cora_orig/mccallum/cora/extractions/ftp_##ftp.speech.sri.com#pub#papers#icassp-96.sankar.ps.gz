URL: ftp://ftp.speech.sri.com/pub/papers/icassp-96.sankar.ps.gz
Refering-URL: http://www.speech.sri.com/people/sankar/publications.html
Root-URL: 
Title: AN EXPERIMENTAL STUDY OF ACOUSTIC ADAPTATION ALGORITHMS  
Author: Ananth Sankar Leonardo Neumeyer Mitchel Weintraub 
Address: Menlo Park, CA  
Affiliation: Speech Technology And Research Laboratory SRI International  
Abstract: Recently there has been much interest in the area of adaptation for improved speech recognition in the presence of mismatches between the training and testing conditions. In this paper we focus on transformation-based maximum-likelihood (ML) adaptation. Some of the important adaptation parameters include whether the adaptation is sbibperformed in the feature-space or model-space, and whether the adaptation is supervised or unsupervised. An additional parameter is the adaptation data. For example adaptation may be performed using an independent dataset or the test data itself. The latter is referred to as transcription-mode adaptation. In this paper, we experimentally study the effect of these various parameters, and report on our findings. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Sankar and C.-H. Lee, </author> <title> "A Maximum-Likelihood Approach to Stochastic Matching for Robust Speech Recognition," </title> <journal> IEEE TSAP, </journal> <note> 1995, to appear. </note>
Reference-contexts: 1. INTRODUCTION Recently, there has been much interest in the area of transformation-based ML adaptation to reduce the recognition degradation caused by acoustic mismatches between the training and testing conditions <ref> [1, 2, 3] </ref>. It is assumed that the speech hidden Markov models (HMMs) estimated in the training condition and an adaptation data set collected in the testing condition are available. <p> The problem is to transform either the features or the models to reduce the mismatch between the two, and consequently reduce the degradation in performance caused by the mismatch. Depending on whether the features or models are being transformed, the methods are classified as feature-space or model-space algorithms <ref> [1, 4] </ref>. The form of the transformation is hypothesized, and its parameters are estimated by maximizing the likelihood of the adaptation data using the expectation-maximization (EM) algorithm [5]. In this paper, we study the effect of different ML-based adaptation parameters. <p> Note that the inverse transformation must exist. We have experimented with simple affine transformations of each feature component in the feature-space: x i = ay i + b: (4) In this case, closed-form reestimation expressions for the transformation parameters can be obtained <ref> [1, 2] </ref>. Note that the above transformation can be implemented equivalently in the model-space by appropriately transforming the means and variances of the HMMs. <p> We also note that the model-space approach is more versatile than the feature space approach. For example, we may separately transform the variances and means of the models <ref> [1, 4] </ref>. In addition, we can also explore complex nonlinear transformations such as the neural-network transformation approach described in [6]. 2.2. Supervised and Unsupervised Adaptation Equations 1 and 2 give the estimation method for the feature-space and model-space, respectively.
Reference: [2] <author> V. Digalakis, D. Rtischev, and L. Neumeyer, </author> <title> "Speaker adaptation using constrained reestimation of gaussian mixtures," </title> <journal> IEEE TSAP, </journal> <volume> vol. 3, no. 5, </volume> <pages> pp. 357-366, </pages> <year> 1995. </year>
Reference-contexts: 1. INTRODUCTION Recently, there has been much interest in the area of transformation-based ML adaptation to reduce the recognition degradation caused by acoustic mismatches between the training and testing conditions <ref> [1, 2, 3] </ref>. It is assumed that the speech hidden Markov models (HMMs) estimated in the training condition and an adaptation data set collected in the testing condition are available. <p> The EM algorithm is particularly useful when closed-form reestimation formulae for the transformation parameters can be obtained in each iteration. In our work on transformation-based ML estimation, separate transformations are applied to separate gaussian clusters <ref> [2] </ref>. More complex functions can be implemented using a greater number of transformations, each tied to a separate gaussian cluster. However, as the number of transforms is increased, a larger amount of adaptation data is needed to estimate their parameters. <p> Note that the inverse transformation must exist. We have experimented with simple affine transformations of each feature component in the feature-space: x i = ay i + b: (4) In this case, closed-form reestimation expressions for the transformation parameters can be obtained <ref> [1, 2] </ref>. Note that the above transformation can be implemented equivalently in the model-space by appropriately transforming the means and variances of the HMMs. <p> We observed no improvement over the SI performance (20:9% word error-rate). This demonstrates the lack of power in the component-wise transformation to improve performance for native speakers. We have previously reported significant improvement using this approach for non-native speakers <ref> [2] </ref> and noisy speech recognition [8]. In the model-space approach, we used the full-matrix affine transformation of Equation 5. Two different approaches were used to estimate the matrix. In the first approach, the matrix transformed the entire gaussian mean vector corresponding to the cepstrum, delta cepstrum, and delta-delta cepstrum. <p> Furthermore, model-space techniques can be used to explore a variety of possible adaptation algorithms, and are hence more flexible than feature-space techniques. We note that in previously reported results, the feature-space approach has given us a significant improvement for non-native test speakers <ref> [2] </ref> and for noisy speech [8]. We found that unsupervised methods performed almost as well as supervised approaches at operating error-rates of about 20%. This shows that we can use unsupervised techniques at these error-rates to obviate the need for speaker enrollment which is required in supervised adaptation.
Reference: [3] <author> C. J. Legetter and P. C. Woodland, </author> <title> "Flexible Speaker Adaptation using Maximum Likelihood Linear Regression," </title> <booktitle> in Proceedings of the Spoken Language Systems Technology Workshop, </booktitle> <pages> pp. 110-115, </pages> <year> 1995. </year>
Reference-contexts: 1. INTRODUCTION Recently, there has been much interest in the area of transformation-based ML adaptation to reduce the recognition degradation caused by acoustic mismatches between the training and testing conditions <ref> [1, 2, 3] </ref>. It is assumed that the speech hidden Markov models (HMMs) estimated in the training condition and an adaptation data set collected in the testing condition are available. <p> However, if we assume that only the HMM means are transformed by the affine transformation of Equation 5, and the variances remain unchanged, then closed-form rees-timation expressions can be derived for the parameters A and b <ref> [3] </ref>. This method can be rationalized as a model-space transformation where there is no underlying feature-space assumption. We have found that this approach performs better than the component-wise feature-space approach since it makes use of the dependencies between the different feature components.
Reference: [4] <author> L. Neumeyer, A. Sankar, and V. Digalakis, </author> <title> "A Comparative Study of Speaker Adaptation Techniques," </title> <booktitle> in Proceedings of EUROSPEECH, </booktitle> <year> 1995. </year>
Reference-contexts: The problem is to transform either the features or the models to reduce the mismatch between the two, and consequently reduce the degradation in performance caused by the mismatch. Depending on whether the features or models are being transformed, the methods are classified as feature-space or model-space algorithms <ref> [1, 4] </ref>. The form of the transformation is hypothesized, and its parameters are estimated by maximizing the likelihood of the adaptation data using the expectation-maximization (EM) algorithm [5]. In this paper, we study the effect of different ML-based adaptation parameters. <p> We also note that the model-space approach is more versatile than the feature space approach. For example, we may separately transform the variances and means of the models <ref> [1, 4] </ref>. In addition, we can also explore complex nonlinear transformations such as the neural-network transformation approach described in [6]. 2.2. Supervised and Unsupervised Adaptation Equations 1 and 2 give the estimation method for the feature-space and model-space, respectively. <p> Two different approaches were used to estimate the matrix. In the first approach, the matrix transformed the entire gaussian mean vector corresponding to the cepstrum, delta cepstrum, and delta-delta cepstrum. In the second approach, a separate transform was used for the cepstrum, delta-cepstrum, and delta-delta-cepstrum <ref> [4] </ref>. Thus the first approach uses a full matrix whereas the second approach uses a block-diagonal matrix. This leads to fewer parameters, and hence to more robust estimation with a limited amount of adaptation data. We have previously reported on the performance of these methods in [4]. <p> cepstrum, delta-cepstrum, and delta-delta-cepstrum <ref> [4] </ref>. Thus the first approach uses a full matrix whereas the second approach uses a block-diagonal matrix. This leads to fewer parameters, and hence to more robust estimation with a limited amount of adaptation data. We have previously reported on the performance of these methods in [4]. In this paper we tabulate the results according to the number of transformations used for each approach in Table 1. Recall from Section 2.1 that a separate transformation is used for each gaussian cluster. <p> In addition to the two methods described above, we have also used this paradigm to separately transform the variance and the means of the gaussians in the HMMs <ref> [4] </ref>, and to derive a neural-network-based non-linear transformation approach [6]. 3.2. Supervised vs. Unsupervised Methods The model-space block-diagonal approach used in Section 3.1 was tested in both supervised and unsupervised modes. For unsupervised adaptation, we used the CI phone loop described in Equation 9.
Reference: [5] <author> A. Dempster, N. Laird, and D. Rubin, </author> <title> "Maximum Likelihood from Incomplete Data via the EM Algorithm," </title> <journal> J. Roy. Stat. Soc., </journal> <volume> vol. 39, no. 1, </volume> <pages> pp. 1-38, </pages> <year> 1977. </year>
Reference-contexts: Depending on whether the features or models are being transformed, the methods are classified as feature-space or model-space algorithms [1, 4]. The form of the transformation is hypothesized, and its parameters are estimated by maximizing the likelihood of the adaptation data using the expectation-maximization (EM) algorithm <ref> [5] </ref>. In this paper, we study the effect of different ML-based adaptation parameters. These parameters include whether adaptation is performed in the feature-space or model-space, whether the method is supervised or unsupervised, and whether the adaptation is done on an independent adaptation set or on the test set (transcription-mode adaptation). <p> Thus, in the feature-space we need to find -0 such that -0 = argmax - and in the model-space we need to find 0 such that 0 = argmax To appear in Proc. ICASSP-96 1 c fl IEEE 1996 The ML problem is solved by the EM algorithm <ref> [5] </ref> which iteratively finds the new estimates of the transformation parameters, given the current estimates. The EM algorithm is particularly useful when closed-form reestimation formulae for the transformation parameters can be obtained in each iteration.
Reference: [6] <author> V. Abrash, A. Sankar, H. Franco, and M. Cohen, </author> <title> "Acoustic Adaptation using Non-Linear Transformations of HMM Parameters," </title> <booktitle> in Proceedings ICASSP, </booktitle> <year> 1996. </year>
Reference-contexts: We also note that the model-space approach is more versatile than the feature space approach. For example, we may separately transform the variances and means of the models [1, 4]. In addition, we can also explore complex nonlinear transformations such as the neural-network transformation approach described in <ref> [6] </ref>. 2.2. Supervised and Unsupervised Adaptation Equations 1 and 2 give the estimation method for the feature-space and model-space, respectively. In what follows, we restrict ourselves to the model-space case, since the equations are similar for the feature-space. <p> In addition to the two methods described above, we have also used this paradigm to separately transform the variance and the means of the gaussians in the HMMs [4], and to derive a neural-network-based non-linear transformation approach <ref> [6] </ref>. 3.2. Supervised vs. Unsupervised Methods The model-space block-diagonal approach used in Section 3.1 was tested in both supervised and unsupervised modes. For unsupervised adaptation, we used the CI phone loop described in Equation 9. The error-rates for supervised and unsupervised adaptation are given in Table 2.
Reference: [7] <author> R. Schwartz and Y.-L. Chow, </author> <title> "A Comparison of Several Approximate Algorithms for Finding Multiple (N-Best) Sentence Hypotheses," </title> <booktitle> in Proceedings ICASSP, </booktitle> <pages> pp. 701-704, </pages> <year> 1991. </year>
Reference-contexts: However, we may use an algorithm based on the recognized word-string W Y , that is, 0 = argmax This is the usual approach to unsupervised adaptation. Alternately, we may use Equation 6, but consider only the top N word-strings in an N -best framework <ref> [7] </ref> to reduce the number of computations. Note that in the unsupervised methods described above, it is necessary to first recognize the adaptation data to get the best word-string or the N -best word-strings. For a large recognition grammar, this is a significant overhead.
Reference: [8] <author> L. Neumeyer and M. Weintraub, </author> <title> "Robust Speech Recognition in Noise using Mapping and Adaptation Techniques," </title> <booktitle> in Proceedings ICASSP, </booktitle> <pages> pp. 141-144, </pages> <year> 1995. </year> <month> 4 </month>
Reference-contexts: We observed no improvement over the SI performance (20:9% word error-rate). This demonstrates the lack of power in the component-wise transformation to improve performance for native speakers. We have previously reported significant improvement using this approach for non-native speakers [2] and noisy speech recognition <ref> [8] </ref>. In the model-space approach, we used the full-matrix affine transformation of Equation 5. Two different approaches were used to estimate the matrix. In the first approach, the matrix transformed the entire gaussian mean vector corresponding to the cepstrum, delta cepstrum, and delta-delta cepstrum. <p> Furthermore, model-space techniques can be used to explore a variety of possible adaptation algorithms, and are hence more flexible than feature-space techniques. We note that in previously reported results, the feature-space approach has given us a significant improvement for non-native test speakers [2] and for noisy speech <ref> [8] </ref>. We found that unsupervised methods performed almost as well as supervised approaches at operating error-rates of about 20%. This shows that we can use unsupervised techniques at these error-rates to obviate the need for speaker enrollment which is required in supervised adaptation.
References-found: 8

