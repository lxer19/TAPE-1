URL: ftp://ftpipr.ira.uka.de/pub/papers/1994/irs94pw.ps.gz
Refering-URL: ftp://ftpipr.ira.uka.de/.public_html/papersna.html
Root-URL: 
Title: Photogrammetric Calibration Methods for an Active Stereo Vision System  
Author: Peter Weckesser Gunter Hetzel Prof. Dr. U. Rembold, Prof. Dr. R. Dillmann 
Address: Karlsruhe, Germany  
Affiliation: Institute for Real-time Computer Systems Robotics (IPR)  University of Karlsruhe Department for Computer Science  
Abstract: In this paper the active stereo vision system KASTOR 1 of the IPR 2 and its calibration technique are described. KASTOR is designed to serve as a flexible sensing device mounted on a mobile robot platform. It is used for collision avoidance, navigation based on natural landmark- and object-recognition. KASTOR has eight motorized optical and mechanical degrees of freedom. The article describes the design of KASTOR as well as the real-time vision system it is connected to. Then a new camera calibration technique is presented. The dlt-matrices (direct linear transformation) are computed directly by the observation of a reference object in a scene. A solution to the problem that the accuracy in the detection of reference points in the images is very low is presented. With the presented method reference points can be located with subpixel accuracy. As KASTOR alters any of its degrees of freedom, the calibration has to be updated. However, it is not possible to track a reference object when the head is mounted on a mobile robot. The new solution is to compute all possible dlt-matrices in advance and to store them in the memory. During autonomous operation the right matrices are selected according to the head-configuration. Experimental results prove that the accuracy of the new calibration technique is absolutely sufficient to use KASTOR as sensor for the navigation of a mobile robot. 
Abstract-found: 1
Intro-found: 1
Reference: [Aya91] <author> N. Ayache. </author> <title> Stereo Vision and Multisensor Perceptions. </title> <publisher> MIT-Press, </publisher> <year> 1991. </year>
Reference: [Bey91] <author> H. Beyer. </author> <title> An introduction to photogrammetric camera calibration. </title> <type> Technical report, </type> <institution> Institute of Geodesy and Photogrammetry, ETH, Zuerich, Schweiz, </institution> <year> 1991. </year>
Reference-contexts: The accuracy of corner detection determines the quality of calibration. 3.2 Detection of Reference Points In order to improve this poor accuracy in the detection of reference points for the calibration photogrammetric methods are applied <ref> [Bey91] </ref>. An automatic calibration technique that detects the reference points in the images with subpixel accuracy was developed [Het94]. In order to reach the accuracy of 0:1 pixels in the point detection a new reference object is used.
Reference: [CCZ92] <author> J. Calvary, J. Crowley, and B. Zopis. </author> <title> Perceptual grouping for scene interpretation in an active vision system. </title> <institution> Lifia (IMAG), </institution> <year> 1992. </year>
Reference: [CS93] <author> J. Crowley and C. Schmid. </author> <title> Maintaining stereo calibration by tracking image points. </title> <address> In CVPR New York, </address> <year> 1993. </year>
Reference: [DKW93] <editor> R. Dillmann, J. Kreuziger, and F. Wallner. </editor> <booktitle> The control architecture of the mobile system priamos. In Proc. of the 1st IFAC International Workshop on Intelligent Autonomous Vehicles. </booktitle> <address> Southampton, </address> <year> 1993. </year>
Reference-contexts: The need of reliable sensors for this purpose has led to the development of a multiple sensor system for the mobile robot PRIAMOS 3 . The development of the new sensor system was necessary in order to operate PRIAMOS safely and accurately in laboratory or industrial environments. PRIAMOS <ref> [DKW93] </ref> is equipped with four Mecanum wheels, which enable three degrees of freedom. This means that PRIAMOS is able to move forth and back, left and right and turn on the point. All these degrees of freedom can be combined.
Reference: [DM94] <author> J. Dold and H.-G. </author> <title> Mass. An application of epipolar line intersection in a hybrid close range photogram-metric system. </title> <editor> In Prof. J.F. Fryer, editor, </editor> <booktitle> Close Range Techniques and Machine Vision, </booktitle> <pages> pages 65-70. </pages> <publisher> ISPRS Commision V, </publisher> <year> 1994. </year>
Reference-contexts: With KASTOR being able to perform a real-time edge detection an edge-based matching algorithm is applied. The high quality of calibration enables a highly precise computation of corresponding endpoints of edges with the use of the epipolar constraint <ref> [DM94] </ref>. Results with this new calibration technique have shown that it is possible to maintain calibration during operation and to use stereo vision as a reliable sensor for observation of known objects as well as detection of unknown obstacles.
Reference: [Foe90] <editor> R. Foehr. Photogrammetrische Erfassung raumlicher Informationen aus Videobildern, </editor> <booktitle> volume 7 of Fortschritte der Robotik. </booktitle> <editor> W. Ameling and M. Weck, </editor> <year> 1990. </year>
Reference-contexts: With the dlt-matrix a homogeneous formulation ( equation 1 and 2) of the perspective transformation is possible. The 12 parameters of the dlt-matrix m i;j contain all 11 camera parameters <ref> [Foe90] </ref>. <p> So it is only necessary to calibrate for one setup of vergence. All other setups can later be used in the reconstruction process. Experimental results also show that it is not neccessary to use a more complex non linear camera model <ref> [Foe90] </ref> because the accuracy of calibration is about 2 times better than the mechanical precision of the lenses. As a reliable reconstruction of the 3D-scene can be reached with the described calibration method fu-ture work will focus on object recognition and classification in the 3D-scene.
Reference: [Het94] <author> G. Hetzel. </author> <title> Kalibrierung eines Stereo-Kamerasystems. </title> <type> Master's thesis, </type> <institution> Institute for Real-Time Control Systems and Robotics, University of Karlsruhe, </institution> <year> 1994. </year>
Reference-contexts: An automatic calibration technique that detects the reference points in the images with subpixel accuracy was developed <ref> [Het94] </ref>. In order to reach the accuracy of 0:1 pixels in the point detection a new reference object is used. Figure 3 shows a CAD-Model and figure 4 shows a foto of this new reference object. It is a black box with 16 circles in different distances to the backside. <p> This is possible due to the mechanical accuracy of the camera head and the high precision stepper motors. 3.4 Automatic calibration for different camera setups The whole calibration procedure can be fully automized <ref> [Het94] </ref>.
Reference: [Lae92] <author> T. Laengle. </author> <title> 3-D Maschinen-Sehen. </title> <type> Master's thesis, </type> <institution> Institute for Real-Time Control Systems and Robotics, University of Karlsruhe, </institution> <year> 1992. </year>
Reference-contexts: The camera is characterized by its image plane (ccd-chip) and the position of the optical center C. Fig. 2.: camera model Altogether there are 12 camera parameters in this camera model <ref> [Lae92] </ref>. external camera parameters : * position of the optical center C (x 0 ; y 0 ; z 0 ) * orientation of ccd chip (; ; ff) internal camera parameters : * center of image plane H (u z ; v z ) * focal length c and pixelsize
Reference: [Mel93] <author> T. Melen. </author> <title> Extracting physical camera parameters from the 3x3 direct linear transformation matrix. </title> <editor> In Prof. H. Grun, Prof. A. Kahmen, editor, </editor> <booktitle> Second Conference on Optical 3-D Measurement Techniques, </booktitle> <pages> pages 355-365. </pages> <address> ETH-Zurich, </address> <year> 1993. </year>
Reference-contexts: In addition to this it is possible to standardize the vergence parameter (orientation of camera) [WWD93]. As it is possible to extract all 11 camera parameters out of the dlt-matrices <ref> [Mel93] </ref> the position of the rotation axis for vergence can precisely be determined. With the use of this it will be possible to extract the vergence parameter. So it is only necessary to calibrate for one setup of vergence. All other setups can later be used in the reconstruction process.
Reference: [Reh91] <author> N. Rehfeld. Auswertung von Stereobildfolgen mit Kantenmerkmalen. VDI-Verlag, Dusseldorf, </author> <year> 1991. </year>
Reference: [Sch92] <author> C. Schmid. </author> <title> Auto-calibration of cameras by direct observation of objects. </title> <type> Master's thesis, </type> <institution> University of Karlsruhe, Institute for Real-Time Control Systems and Robotics, University of Grenoble, LIFIA, </institution> <year> 1992. </year>
Reference-contexts: d v ) * angle between the image coordinate axis Instead of extracting the camera parameters directly from the camera geometry it is possible with the knowledge of at least 6 corresponding scene (S) and image (I) points to compute the dlt-matrices (M ) for the left and right cameras <ref> [Sch92] </ref>. With the dlt-matrix a homogeneous formulation ( equation 1 and 2) of the perspective transformation is possible. The 12 parameters of the dlt-matrix m i;j contain all 11 camera parameters [Foe90]. <p> In <ref> [Sch92] </ref> a cube is used as reference object. The corners of the cube can be located with a corner operator or by the intersection of the edges of the cube. Experimental results have shown that the accuracy that can be reached by this method is not very high (2 pixels).
Reference: [Sug86] <author> Sugihara. </author> <title> Machine Interpretation of Line Drawings. </title> <publisher> MIT-Press, </publisher> <year> 1986. </year>
Reference: [Wec93] <author> P. Weckesser. </author> <title> Entwicklung und Aufbau des aktiven Echtzeit-Stereo-Sichtsystems KASTOR zur Navigation eines mobilen Robotersystems. </title> <type> Master's thesis, </type> <institution> University of Karlsruhe, Institute for Real-Time Control Systems and Robotics, </institution> <year> 1993. </year>
Reference-contexts: This data-rate is sufficient as the whole sensor information is processed on the robot. Only parametric information about the environment and commands to the robot are transmitted via radio. 2 The active vision system KASTOR KASTOR <ref> [Wec93] </ref> consists of two cameras, mounted on a platform with motor-controlled tilt and turn. Zoom and focus as well as the vergence of each camera unit are equipped with motors. The cameras are connected to a real-time vision system, which has been modified for stereo image-processing purposes.
Reference: [Wil93] <author> R. Wilson. </author> <title> Modeling and calibration of automized zoom lenses. </title> <type> PhD thesis, </type> <address> CMU, Pittsburgh, USA, </address> <year> 1993. </year>
Reference-contexts: 50 0.154 0.796 0.307 70 0.173 0.909 0.362 90 0.123 0.786 0.175 110 0.175 0.937 0.265 As a result one can say that it is possible to change the optical parameters and come back to a pre-calibrated position due to the high precision of the mechanical construction of the system <ref> [Wil93] </ref>. Because of tolerances in the lenses best results are received if the positions are always adjusted from the same side.
Reference: [WW94] <author> P. Weckesser and F. Wallner. </author> <title> Calibrating the active vision system KASTOR for real-time robot navigation. </title> <editor> In Prof. J.F. Fryer, editor, </editor> <booktitle> Close Range Techniques and Machine Vision, </booktitle> <pages> pages 430-436. </pages> <publisher> ISPRS Commision V, </publisher> <year> 1994. </year>
Reference: [WWD93] <author> P. Weckesser, F. Wallner, and R. Dillmann. </author> <title> Calibrating the active vision system kastor with standardized perspective matrices. </title> <editor> In Prof. H. Grun, Prof. A. Kahmen, editor, </editor> <booktitle> Second Conference on Optical 3-D Measurement Techniques, </booktitle> <pages> pages 430-436. </pages> <address> ETH-Zurich, </address> <year> 1993. </year> <title> This article was processed using the T E X macro package with IRS94 style </title>
Reference-contexts: First experiments have shown that only a about 20 different combinations of zoom and focus are really necessary for an autonomous operating robot. In addition to this it is possible to standardize the vergence parameter (orientation of camera) <ref> [WWD93] </ref>. As it is possible to extract all 11 camera parameters out of the dlt-matrices [Mel93] the position of the rotation axis for vergence can precisely be determined. With the use of this it will be possible to extract the vergence parameter.
References-found: 17

