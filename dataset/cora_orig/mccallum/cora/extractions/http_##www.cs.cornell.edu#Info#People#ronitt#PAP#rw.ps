URL: http://www.cs.cornell.edu/Info/People/ronitt/PAP/rw.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/ronitt/papers.html
Root-URL: 
Email: Ronitt Rubinfeld  
Title: Learning Distributions from Random Walks  
Author: Funda Ergun S Ravi Kumar 
Address: Ithaca, NY 14853.  
Affiliation: Department of Computer Science Cornell University  
Abstract: We introduce a new model of distributions generated by random walks on graphs. This model suggests a variety of learning problems, using the definitions and models of distribution learning defined in [6]. Our framework is general enough to model previously studied distribution learning problems, as well as to suggest new applications. We describe special cases of the general problem, and investigate their relative difficulty. We present algorithms to solve the learning problem under various conditions.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Cover and J. Thomas. </author> <title> Elements of Information Theory. </title> <publisher> John Wiley, </publisher> <year> 1991. </year>
Reference-contexts: KL-divergence, however, captures the distance in an information-theoretic sense <ref> [1] </ref>. In order to formally define what it means to learn a distribution, we need the following definitions of a generator and an evaluator for a distribution from [6]. <p> It can be shown <ref> [1] </ref> that for any two distributions D; D 0 , 2 ln 2 p KL (DkD 0 ) L 1 (D; D 0 ): We plug the bound obtained in Theorem 8 on KL (D T kD H 0 ) into the equation to get the bound. 2 Proof (of Corollary
Reference: [2] <author> M. Farach and S. Kannan. </author> <title> Efficient algorithms for inverting evolution. </title> <booktitle> In Proceedings of the 28th ACM Symposium on Theory of Computing, </booktitle> <pages> pages 230-236, </pages> <year> 1996. </year>
Reference-contexts: Our framework is general enough to model various noise processes, the Hamming ball distribution learning problem studied by [6], and the evolutionary tree model studied by Farach and Kannan <ref> [2] </ref>. Other possible applications to problems in context-sensitive spelling correction and unsupervised learning are suggested. <p> The Hamming ball and the hypercube distributions are natural graphs on which to study such noise processes. Cavender-Farris Distributions. The second model that fits into our framework is the model of Cavender-Farris Trees used to study evolution <ref> [2] </ref>. In this model there is a rooted (directed) tree with probabilities associated with each edge. The nodes have labels from f0; 1g. The label of the root is determined according to some probability p r . The nodes are labeled as follows. <p> This model is a special case of our model where the probabilities on the edges of the graph are not known to the learner. We show this by a reduction from the problem of learning the tree T in the model of <ref> [2] </ref> to a learning problem in our model. Given T , let G be a leveled graph whose nodes have labels that are of the form (i; x), where i denotes the level containing the node and x is an n-bit binary vector.
Reference: [3] <author> A. Golding and D. Roth. </author> <title> Applying winnow to context-sensitive spelling correction. </title> <booktitle> In Machine Learning: Proceedings of the 13th International Conference, </booktitle> <pages> pages 182-190, </pages> <year> 1996. </year>
Reference-contexts: The answer to the learning problem on G from this hypothesis class then can be used to determine the probabilities on T . Context-Sensitive Spelling Correction. Another setting in which that our model may be useful is one similar to that studied by Golding and Roth <ref> [3] </ref> for use in context-sensitive spelling correction. They study the problem of finding and correcting spelling mistakes which are not found by dictionary based approaches, because the misspelled word is also an English word. <p> Given the observed vectors of a single member of the confusion set, the learner learns the distribution on the vectors. Then, the spell checker may use the distribution information in order to choose the most likely member of the confusion set analogously to <ref> [3] </ref>. Classification and Unsupervised Learning. Finally, consider a classification system in which a small number of classes recursively branch off into smaller classes. For instance, the class of credit card holders have yuppies and women as subclasses.
Reference: [4] <author> G. H. Golub and C. F. </author> <title> Van Loan Matrix Computations. </title> <publisher> The Johns Hopkins University Press, </publisher> <year> 1991. </year>
Reference-contexts: Let x denote the vector representation of the actual distribution K on the centers. Since ^ b is only an approx imation to the vector b, we consider the stability of the system in order to show that ^x is a good approximation to x. We use theorems from <ref> [4] </ref> to show the following error bound. Theorem 12 k^x xk=kxk (P ) k ^ b bk=kbk. Here, (A) = kA l k k (A l ) 1 k is called the condition number of A. kAk denotes any norm of matrix A.
Reference: [5] <author> D. Haussler. </author> <title> Decision theoretic generalizations of the PAC model for neural net and other learning applications. </title> <booktitle> In Information and Computation, </booktitle> <volume> 100 </volume> <pages> 78-150, </pages> <year> 1992. </year>
Reference-contexts: Setting q = 1=N , E D H 0 (x) lg N 2 d l k lg m Using this bound and the uniform convergence result of Haussler <ref> [5] </ref>, one can conclude that for large enough X (whose size we will determine later) E x2D T [lg D H 0 (x)] is within * of E x2X [lg D H 0 (x)] with probability at least (1 ffi). <p> Combining with the previous bound, we have KL (D T kD H 0 ) + *. We now compute the minimum sample set size required to guarantee uniform convergence. To use the result in <ref> [5] </ref> one needs to bound D H 0 (x) both from above and below. Note that 1=N 2 D H 0 (x) 1, and thus 2 lg N lg (1=D H 0 (x)) 0. Using the uniform convergence result of [5], a sample size of m O k 2 lg 6 <p> To use the result in <ref> [5] </ref> one needs to bound D H 0 (x) both from above and below. Note that 1=N 2 D H 0 (x) 1, and thus 2 lg N lg (1=D H 0 (x)) 0. Using the uniform convergence result of [5], a sample size of m O k 2 lg 6 N lg 2 n 2 suffices. 2 We now present a bound on the distance between D H and D T .
Reference: [6] <author> M. Kearns, Y. Mansour, D. Ron, R. Rubinfeld, R. Schapire, and L. Sellie. </author> <title> On the learnability of discrete distributions. </title> <booktitle> In Proceedings of the 26th ACM Symposium on Theory of Computing, </booktitle> <pages> pages 273-282, </pages> <year> 1994. </year>
Reference-contexts: 1 INTRODUCTION In this paper, we introduce a new model of distributions generated by random walks on graphs. This model suggests a variety of learning problems, using the definitions and models of distribution learning defined by Kearns et. al. <ref> [6] </ref>. Our framework is general enough to model various noise processes, the Hamming ball distribution learning problem studied by [6], and the evolutionary tree model studied by Farach and Kannan [2]. Other possible applications to problems in context-sensitive spelling correction and unsupervised learning are suggested. <p> This model suggests a variety of learning problems, using the definitions and models of distribution learning defined by Kearns et. al. <ref> [6] </ref>. Our framework is general enough to model various noise processes, the Hamming ball distribution learning problem studied by [6], and the evolutionary tree model studied by Farach and Kannan [2]. Other possible applications to problems in context-sensitive spelling correction and unsupervised learning are suggested. <p> On this model it is natural to define a variety of learning problems depending on which parameters are known and which are unknown to the learner. In the model of distribution-learning defined in <ref> [6] </ref>, the learner has access to a set of samples generated according to the specific distribution that it is trying to learn. <p> Another learning problem involves efficiently constructing a mechanism which given a string, evaluates the probability that it is output by the distribution to within a good approximation, i.e., learning an evaluator. Our methods allow one to learn both an evaluator and generator as defined in <ref> [6] </ref>. We describe in precise terms several interesting special cases of this general problem. The first is the problem of learning the distribution when only the centers are unknown to the learner, called the hidden centers problem. <p> Next, we focus on finding learning algorithms for the hidden centers problem on large classes of graphs. We begin with an algorithm that nontrivially approximates distributions from bounded degree graphs with certain properties, that was inspired by an algorithm from <ref> [6] </ref>. Our running time is polynomial in k d l where k is the number of centers, d is the degree bound of the graph and l is the length of the walks, but depends only logarithmically on the number of nodes in the graph. <p> We also suggest other settings in which our framework may be of interest. Hamming Ball Distributions. In <ref> [6] </ref>, the problem of learning Hamming ball distributions is studied. This model is natural for concepts in which there are "canonical" examples of the concept, and in which the probability of an output decreases as the number of attributes in common with the canonical examples decreases. <p> The learning problem of <ref> [6] </ref> is exactly the distribution learning problem from random walks of length 1 on G, where the transition probabilities are known but the centers are unknown. <p> KL-divergence, however, captures the distance in an information-theoretic sense [1]. In order to formally define what it means to learn a distribution, we need the following definitions of a generator and an evaluator for a distribution from <ref> [6] </ref>. <p> One can treat an evaluator E as a distribution where the probabilities are defined according to the output of E. We define what it means to learn a distribution in time t (*; ffi; n). Our definition is based on the ones in <ref> [6] </ref>: Definition 3 Let D n be a class of distributions. <p> Then, P t (u; v) = (v) + O ( t 2 (v)=(u)). Since 2 is bounded by a constant less than one for expanders, by this fact, fi l = max v;u P l (u; v) is bounded away from one. In <ref> [6] </ref>, the learning problem is solved by finding a good set of centers and defining K 0 as the uniform distribution over this set. <p> They show that the distribution generated by picking the starting points according to K 0 is close to the distribution generated by picking them according to K. The algorithm presented here is inspired by the one in <ref> [6] </ref>. Algorithm. Let X be the set of samples and m = jXj. To produce an approximation to D T = rw (P; L; K), we first form a list of nodes that are likely candidates for centers as follows. <p> The next step is to cover the set X of sample points using these smaller subsets and to return the candidate centers associated with the subsets used in the set-cover as our set of centers. We perform the set-cover using a greedy approximation algorithm as in <ref> [6] </ref>. This algorithm returns at most k lg m subsets (and corresponding centers). Then our hypothesis distribution is D H = rw (P; L; K 0 ), where K 0 is the uniform distribution on the centers.
References-found: 6

