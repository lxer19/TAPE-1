URL: ftp://ftp.cs.rochester.edu/pub/papers/ai/96.Ringger-Allen.ICSLP96.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/ringger/research/icslp-96.html
Root-URL: 
Email: fringger, jamesg@cs.rochester.edu  
Title: A FERTILITY CHANNEL MODEL FOR POST-CORRECTION OF CONTINUOUS SPEECH RECOGNITION  
Author: Eric K. Ringger James F. Allen 
Web: http://www.cs.rochester.edu/research/trains/  
Address: Rochester; Rochester, New York 14627-0226  
Affiliation: Department of Computer Science; University of  
Abstract: We have implemented a post-processor called SPEECHPP to correct word-level errors committed by an arbitrary speech recognizer. Applying a noisy-channelmodel, SPEECHPP uses a Viterbi beam-search that employs language and channel models. Previous work demonstrated that a simple word-for-word channel model was sufficient to yield substantial increases in word accuracy. This paper demonstrates that some improvements in word accuracy result from augmenting the channel model with an account of word fertility in the channel. This work further demonstrates that a modern continuous speech recognizer can be used in black-box fashion for robustly recognizing speech for which the recognizer was not originally trained. This work also demonstrates that in the case where the recognizer can be tuned to the new task, environment, or speaker, the post-processor can also contribute to performance improvements. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. F. Allen, B. W. Miller, E. K. Ringger, and T. Sikorski. </author> <title> A robust system for natural spoken dialogue. </title> <booktitle> In Proceedings of the 1996 Annual Meeting of the Association for Computational Linguistics (ACL'96). ACL, </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: This work has been done as part of the TRAINS-95 and TRAINS-96 conversational planning systems, which are aimed at successfully understanding spontaneous spoken utterances in human-computer dialogue <ref> [1] </ref>. Thus, higher word recognition rates contribute to better end-to-end performance in the dialogue system. We use the Sphinx-II [4] speech recognizer in our systems, but results similar to those presented here could have been obtained with any modern SR.
Reference: [2] <author> L. R. Bahl, F. Jelinek, and R. Mercer. </author> <title> A Maximum Likelihood Approach to Continuous Speech Recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), </journal> <volume> 5(2) </volume> <pages> 179-190, </pages> <month> March </month> <year> 1983. </year>
Reference-contexts: THE MODELS AND ALGORITHM SPEECHPP yields fewer errors by effectively refining and tuning the vocabulary and language model used by the SR. To achieve this, we applied a noisy channel model and adapted techniques from statistical machine translation (such as [3]) and statistical speech recognition (c.f. <ref> [2] </ref>) in order to model the errors that Sphinx-II makes in our domain.
Reference: [3] <author> P. F. Brown, J. Cocke, S. A. Della Pietra, V. J. Della Pietra, F. Jelinek, J. D. Lafferty, R. L. Mercer, and P. S. Roossin. </author> <title> A Statistical Approach to Machine Translation. </title> <journal> Computational Linguistics, </journal> <volume> 16(2) </volume> <pages> 79-85, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Existing rescoring tactics cannot do so (c.f. [7]). 2. THE MODELS AND ALGORITHM SPEECHPP yields fewer errors by effectively refining and tuning the vocabulary and language model used by the SR. To achieve this, we applied a noisy channel model and adapted techniques from statistical machine translation (such as <ref> [3] </ref>) and statistical speech recognition (c.f. [2]) in order to model the errors that Sphinx-II makes in our domain.
Reference: [4] <author> X. D. Huang, F. Alleva, H. W. Hon, M. Y. Hwang, K. F. Lee, and R. Rosenfeld. </author> <title> The Sphinx-II Speech Recognition System: An Overview. </title> <booktitle> Computer, Speech and Language, </booktitle> <year> 1993. </year>
Reference-contexts: This work has been done as part of the TRAINS-95 and TRAINS-96 conversational planning systems, which are aimed at successfully understanding spontaneous spoken utterances in human-computer dialogue [1]. Thus, higher word recognition rates contribute to better end-to-end performance in the dialogue system. We use the Sphinx-II <ref> [4] </ref> speech recognizer in our systems, but results similar to those presented here could have been obtained with any modern SR. Here are a few examples of the kinds of errors that occur when recognizing spontaneous utterances in the TRAINS-95 domain using Sphinx-II and its models trained from ATIS data.
Reference: [5] <author> S. M. Katz. </author> <title> Estimation of probabilities from sparse data for the language model component of a speech recognizer. </title> <booktitle> In IEEE Transactions on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 400-401. </pages> <publisher> IEEE, </publisher> <month> March </month> <year> 1987. </year>
Reference-contexts: For efficiency and due to sparse data, it is necessary to estimate these distributions with relatively simple models by making independence assumptions. For P [w], we train a word-bigram "back-off" language model <ref> [5] </ref> from hand-transcribed dialogues previously collected with the TRAINS-95 system.
Reference: [6] <author> K.-F. Lee. </author> <title> Automatic Speech Recognition: the Development of the SPHINX System. </title> <publisher> Kluwer Academic, </publisher> <address> Boston, </address> <year> 1989. </year>
Reference-contexts: This provides further motivation for the placement of the SR module into our conception of a noisy channel. One poorly modeled phenomenon is assimilation of phonetic features. Most SR engines model phonemes in a context-dependent fashion (e.g., see <ref> [6] </ref>), and some attempt to model cross-word co-articulation effects (c.f. [6] also). However, as speaking speeds vary, the SR's models may not be well suited to the affected speech signal. Such errors can be corrected by the post-processing techniques discussed here, if enough training data from fast speakers is available. <p> This provides further motivation for the placement of the SR module into our conception of a noisy channel. One poorly modeled phenomenon is assimilation of phonetic features. Most SR engines model phonemes in a context-dependent fashion (e.g., see <ref> [6] </ref>), and some attempt to model cross-word co-articulation effects (c.f. [6] also). However, as speaking speeds vary, the SR's models may not be well suited to the affected speech signal. Such errors can be corrected by the post-processing techniques discussed here, if enough training data from fast speakers is available.
Reference: [7] <author> M. Rayner, D. Carter, V. Digalakis, and P. Price. </author> <title> Combining Knowledge Sources to Reorder N -best Speech Hypothesis Lists. </title> <booktitle> In Proceedings ARPA Human Language Technology Workshop, </booktitle> <pages> pages 212-217. ARPA, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: Finally, the primary advantage to the post-processing approach over existing approaches for overcoming SR errors lies in its ability to introduce options that are not available in the SR module's output. Existing rescoring tactics cannot do so (c.f. <ref> [7] </ref>). 2. THE MODELS AND ALGORITHM SPEECHPP yields fewer errors by effectively refining and tuning the vocabulary and language model used by the SR.
Reference: [8] <author> E. K. Ringger and J. F. Allen. </author> <title> Error Correction via a PostProcessor for Continuous Speech Recognition. </title> <booktitle> In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing. IEEE, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Its models are constructed with no preconceptions of the channel's nature beyond simple observations of the channel's effects on some training data. We adopt statistical techniques (some of them from statistical machine translation) for modeling that channel in order to correct some of the errors introduced there. Previous work <ref> [8] </ref> demonstrated that a simple word-for-word channel model was sufficient to yield substantial increases in word accuracy. This paper demonstrates that some improvements in word accuracy result from augmenting the channel model with an account of word fertility in the channel.
Reference: [9] <author> S. J. Young and P. C. Woodland. </author> <title> HTK: Hidden Markov Model Toolkit. </title> <institution> Entropic Research Lab., </institution> <address> Washington, D.C., </address> <year> 1993. </year>
Reference-contexts: In those experiments, the acoustic model and the class-based language model were trained on ATIS data. Similarly, a recognizer built using HTK <ref> [9] </ref> on human-human speech (Trains Dialogue Corpus) performed poorly on computer-human speech. SPEECHPP can help in precisely these scenarios. With regard to the small margins of improvement from our fertility models, we observe that the amounts of training data we have used are still largely insufficient.
References-found: 9

