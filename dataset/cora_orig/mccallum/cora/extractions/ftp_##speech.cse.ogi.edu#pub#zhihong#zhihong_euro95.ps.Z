URL: ftp://speech.cse.ogi.edu/pub/zhihong/zhihong_euro95.ps.Z
Refering-URL: http://cslu.cse.ogi.edu/people/hu/index.html
Root-URL: http://www.cse.ogi.edu
Email: zhihong,barnard,cole)@cse.ogi.edu  
Title: Transition-based Feature Extraction within Frame-based Recognition  
Author: Zhihong Hu, Etienne Barnard, Ronald Cole 
Affiliation: Oregon Graduate Institute of Science and Technology  
Note: Center for Spoken Language Understanding,  
Abstract: Current frame-based speech recognition systems sample speech at a fixed set of locations relative to each frame. Modeling the temporal dynamic behavior of speech is thereby complicated. This work shows that by explicitly using transitional information when extracting features, one can better model the acoustic phonetic structure, resulting in higher word level recognition performance. In this proposed approach, features representing local transitional information are used (a constant number of features are selected at each time frame, but the features are sampled near areas of greatest spectrum change within a relatively long window.) By explicitly modeling transitions in this way, we can also model local contextual information. Using this technique, the word level error rate decreased up to 30% on the databases we tested. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Rabiner and B.H. Juang. </author> <title> Fundamentals of Speech Recognition. </title> <address> Englewood Cliffs NJ: </address> <publisher> PTR Prentice Hall (Signal Processing Series), </publisher> <year> 1993. </year> <note> General Intro : ISBN 0-13-015157-2. </note>
Reference-contexts: 1. Introduction Current speech recognition systems can be categorized either as frame-based or segment-based <ref> [1] </ref>. Frame-based systems are currently more popular since they do not require explicit detection of segment boundaries in a vocabulary-independent fashion, and thus give better classification performance.
Reference: [2] <author> S. Furui. </author> <title> On the role of spectral transition for speech perception. </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 80(4) </volume> <pages> 1016-1025, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: One way to overcome some of these limitations is to construct a frame-based system which focuses on transitional information. Evidence suggesting that the transitional part of speech carries important information for speech perception exists <ref> [2] </ref>. Various approaches to incorporate this information have been suggested. For example, Ghitza and Sondhi's [3] HMM-based system recognizes speech based only upon classification of diphone transitions. Fanty and Cole [4] modeled dynamics by sampling features more densely at segment boundaries, therefore improved alphabet recognition performance.
Reference: [3] <author> O. Ghitza and M.M. Sondhi. </author> <title> Hidden markov models with templates as non-stationary states: an application to speech recognition. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 2 </volume> <pages> 101-119, </pages> <year> 1993. </year>
Reference-contexts: One way to overcome some of these limitations is to construct a frame-based system which focuses on transitional information. Evidence suggesting that the transitional part of speech carries important information for speech perception exists [2]. Various approaches to incorporate this information have been suggested. For example, Ghitza and Sondhi's <ref> [3] </ref> HMM-based system recognizes speech based only upon classification of diphone transitions. Fanty and Cole [4] modeled dynamics by sampling features more densely at segment boundaries, therefore improved alphabet recognition performance. Gold-enthal's segment based system [5] also attempts to model transitions by incorporating cross phone fea ture trajectories.
Reference: [4] <author> M. Fanty, R. Cole, and K. Roginski. </author> <title> English alphabet recognition with telephone speech. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippman, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kauf-mann, </publisher> <year> 1992. </year>
Reference-contexts: Evidence suggesting that the transitional part of speech carries important information for speech perception exists [2]. Various approaches to incorporate this information have been suggested. For example, Ghitza and Sondhi's [3] HMM-based system recognizes speech based only upon classification of diphone transitions. Fanty and Cole <ref> [4] </ref> modeled dynamics by sampling features more densely at segment boundaries, therefore improved alphabet recognition performance. Gold-enthal's segment based system [5] also attempts to model transitions by incorporating cross phone fea ture trajectories.
Reference: [5] <author> W.D. Goldenthal. </author> <title> Statistical Trajectory Models for Phonetic Recognition. </title> <type> PhD thesis, </type> <institution> M.I.T., </institution> <month> Auguest </month> <year> 1994. </year>
Reference-contexts: Various approaches to incorporate this information have been suggested. For example, Ghitza and Sondhi's [3] HMM-based system recognizes speech based only upon classification of diphone transitions. Fanty and Cole [4] modeled dynamics by sampling features more densely at segment boundaries, therefore improved alphabet recognition performance. Gold-enthal's segment based system <ref> [5] </ref> also attempts to model transitions by incorporating cross phone fea ture trajectories. Bahl's [6] HMM system uses discriminant projections to extract the most informative features among the adjoining features from several frames in order to capture the temporal information.
Reference: [6] <author> L.R. Bahl, P.V. de Souza, P.S. Gopalakrisnan, D Nahamoo, and M.A. Picheny. </author> <title> Robust methods for using context-dependent features and models in a continuous speech recognizer. </title> <booktitle> In IEEE Int. Conf. on ASSP, </booktitle> <pages> pages 533-536, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Fanty and Cole [4] modeled dynamics by sampling features more densely at segment boundaries, therefore improved alphabet recognition performance. Gold-enthal's segment based system [5] also attempts to model transitions by incorporating cross phone fea ture trajectories. Bahl's <ref> [6] </ref> HMM system uses discriminant projections to extract the most informative features among the adjoining features from several frames in order to capture the temporal information. These methods are computationally intensive, and are not easy to extend to implement in real time.
Reference: [7] <author> H. Hermansky. </author> <title> Perceptual linear predictive (PLP) analysis of speech. </title> <journal> J.Acoustic. Soc. Am., </journal> <volume> 4 </volume> <pages> 1738-1752, </pages> <year> 1987. </year>
Reference-contexts: Feature Extraction The general system structure is shown in Figure 1. Features are extracted for each frame of incoming speech. Typically these features are cepstrum based after some spectral warping (in our systems, 7th or der PLP coefficients are used <ref> [7] </ref>.) These features then serve as input to either a discriminative classifier (e.g. neural network) or an estimator of likelihoods (such as continuous hidden Markov models).
Reference: [8] <author> N. Morgan, H. Bourlard, S. Greenberg, H. Her-mansky, and S. Wu. </author> <title> Stochastic perceptual models of speech. </title> <booktitle> In IEEE Int. Conf. on ASSP, </booktitle> <pages> pages 397-400, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Experimental results on two different corpora indicate that using transition-based features can help to improve the recognition performance significantly, and therefore presents a promising new technique for extending speaker independent continuous speech recognition. The results we obtained conform to previous work done on stochastic perceptual models of speech <ref> [8] </ref>. 4 The feature vector dimension in experiment B1 is 56; the feature vector dimension in experiment B2, T1 and T2 is 104.
References-found: 8

