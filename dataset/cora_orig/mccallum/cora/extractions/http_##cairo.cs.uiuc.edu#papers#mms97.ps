URL: http://cairo.cs.uiuc.edu/papers/mms97.ps
Refering-URL: http://cairo.cs.uiuc.edu/papers.html
Root-URL: http://www.cs.uiuc.edu
Email: daman@ncsa.uiuc.edu  klara@cs.uiuc.edu  
Title: Link Management Framework for Hyper-media Documents  
Author: Dragos-Anton Manolescu Klara Nahrstedt 
Address: 405 N. Mathews Ave., Urbana, IL 61801  1304 W. Springfield Ave.,Urbana, IL 61801  
Affiliation: National Center for Supercomputing Applications  Department of Computer Science  
Abstract: This paper presents a framework for link management within hyper-media documents. The framework includes: (1) an object-oriented document architecture with a consistent interface for different media types; (2) a transition model between multimedia objects founded on content-based static links for atemporal media, and content/time-based dynamic links for temporal media; and (3) intrinsic support for content-based access which requires a reduced amount of indexing. A prototype system has been implemented to verify the feasibility of the paradigm. The results confirm that the framework is viable and back up the formalism. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. S. Subrahmanian at al., </author> <title> The Advanced Video Information System: data structures and query processing, </title> <journal> ACM-Springer Multimedia Systems Journal, </journal> <year> 1996. </year>
Reference-contexts: The user controls the presentation by clicking on different parts of an image. This determines the next image. The system handles just atem-poral information, and the only possible type of transi tion is given in Figure 2. Virtual Gallery. * The Advanced Video Information System (AVIS) <ref> [1] </ref> organizes video data to facilitate efficient querying. A video is first broken down into short sequences and several kinds of entities (objects, activities, and events) are associated with them. The system defines a 9-tuple database [3] which supports different types of queries. <p> Static links are a specialization of dynamic links, where the space is atemporal and the transition depends just on contents. Formally, they are modeled by s l : O ! O. We represent dynamic and static links with association maps <ref> [1] </ref>. An association map specifies which objects correspond to which strands when they take part in links. To formally define the association map, we make the following assumptions: 1. <p> The advantage of using association maps to model links is twofold: * Association maps correspond to line segments on the x-axis of the Cartesian plane. From a database perspective, they can be efficiently stored by any method for storing collinear line segments <ref> [1] </ref>. * For any given object, the association map determines all the referencing strands. This allows discarding of non-referenced objects with reference-based garbage collection mechanisms. A document containing just static links is organized in a tree-like hierarchy. Each node has a coordinate on the contents axis.
Reference: [2] <author> Roy H. Campbell et al., </author> <title> Real Time Video and Audio in the World Wide Web, </title> <booktitle> Fourth International World Wide Web Conference, </booktitle> <year> 1995. </year>
Reference-contexts: These could be colors, textures, shapes, camera and object motions. Queries are then composed graphically and their features are extracted as well. A matching engine finds the videos or images with similar features from the database. This is illustrated in Figure 4. * Vosaic <ref> [2] </ref> is a World-Wide Web browsing system extended to support continuous video media. Although not a CBIR system, it introduces the notion of video hyper-links which allow a user to click on an image in a video stream and pull up another video stream. <p> Consequently, in order to implement and test dynamic links, we use just temporal objects. We restrict the verification to video information. Besides supporting dynamic links, this choice also allows testing video to video transitions, which just a few other systems support <ref> [2] </ref>. Restricting to one media type does not decrease the generality. Rather, it simplifies the implementation. The details associated with manipulating other types of media (e.g., audio, text, etc.) are left aside. 5.2.
Reference: [3] <author> Ramez Elmasri, Shamkant Navathe, </author> <title> Fundamentals of Database Systems, </title> <publisher> Addison-Wesley 1994. </publisher>
Reference-contexts: Virtual Gallery. * The Advanced Video Information System (AVIS) [1] organizes video data to facilitate efficient querying. A video is first broken down into short sequences and several kinds of entities (objects, activities, and events) are associated with them. The system defines a 9-tuple database <ref> [3] </ref> which supports different types of queries. Possible transitions are from the atemporal domain (queries) to the temporal domain (video sequences) * The Query by Image Content (QBIC) [4] is another content-based image retrieval system (CBIR) [6] which takes a different approach. <p> Static links require just the objects. Dynamic links require the time coordinate as well. Unlink Removes a previously established link. Table 3. High-level composition operations. as a relational database <ref> [3] </ref>. Therefore, support for content-based access operations is intrinsic. The entity types correspond to each object's media data and the meta-data associated with it.
Reference: [4] <editor> Myron Flickner et al., </editor> <title> Query by Image and Video Content: </title> <booktitle> the QBIC System, IEEE Computer, </booktitle> <month> Septem-ber </month> <year> 1995. </year>
Reference-contexts: The system defines a 9-tuple database [3] which supports different types of queries. Possible transitions are from the atemporal domain (queries) to the temporal domain (video sequences) * The Query by Image Content (QBIC) <ref> [4] </ref> is another content-based image retrieval system (CBIR) [6] which takes a different approach. During an initial phase, called population, images and videos are pro-cessed to extract features describing their contents. These could be colors, textures, shapes, camera and object motions.
Reference: [5] <author> Erich Gamma, Richard Helm, Ralph Johnson, John Vlissides, </author> <title> Design PatternsElements of Reusable Object-Oriented Software, </title> <publisher> Addison-Wesley 1995. </publisher>
Reference-contexts: We use an object-oriented architecture which offers a high-level abstraction and is easy to integrate within existing multimedia document standards, like MHEG [9, 13]. The superclass of all document objects, multimedia object, is an abstract class. This is illustrated in Figure 1, where we use the notation from <ref> [5] </ref> and the abstract classes appear in italics. The two subclasses correspond to different requirements. The temporal subclass includes all objects which are intra-domain time dependent (e.g., audio, video, etc.). The atemporal subclass includes objects which do not have intra-domain time dependencies (e.g., text, static images, graphics, etc.). <p> Design patterns An essential framework attribute is a high degree of flexibility, such that the framework is usable for a wide range of applications. Design patterns help to achieve this objective, emphasizing the reuse of successful designs and architectures <ref> [5] </ref>. Our document architecture is an instance of the Composite pattern: each element of the hierarchy could be either a simple object or a composite object. Composite ensures an uniform document interface and enables for any combination of media types.
Reference: [6] <author> Venkat Gudivada, Vijay Raghava, </author> <title> Content-Based Image Retrieval Systems, </title> <booktitle> IEEE Computer, </booktitle> <month> Septem-ber </month> <year> 1995. </year>
Reference-contexts: The system defines a 9-tuple database [3] which supports different types of queries. Possible transitions are from the atemporal domain (queries) to the temporal domain (video sequences) * The Query by Image Content (QBIC) [4] is another content-based image retrieval system (CBIR) <ref> [6] </ref> which takes a different approach. During an initial phase, called population, images and videos are pro-cessed to extract features describing their contents. These could be colors, textures, shapes, camera and object motions. Queries are then composed graphically and their features are extracted as well. <p> Content-based Operations. Queries can be classified according to different criteria. We include examples for several query types. Type of information involved in a query. Depending on their type, some queries require an additional processing step for all objects in a hierarchy, similar to the indexing stages described in <ref> [6] </ref>. Queries on object information take into account just (two rings and a document). the media data. Unlike other systems [6], they do not require additional meta-data information and therefore work on any document structure. <p> Depending on their type, some queries require an additional processing step for all objects in a hierarchy, similar to the indexing stages described in <ref> [6] </ref>. Queries on object information take into account just (two rings and a document). the media data. Unlike other systems [6], they do not require additional meta-data information and therefore work on any document structure. QU E R Y 1 Return all objects that contain a given strand Queries on meta-data require objects to contain valid information (no NULL values 2 ) in the meta-data fields that are selected.
Reference: [7] <author> Dan Heller, Paula M. Ferguson, </author> <title> Motif Programming Manual, </title> <publisher> O'Reilly & Associates Inc., </publisher> <year> 1994. </year>
Reference-contexts: This flexibility is important in the context of large document databases, where recreating the entire database is an expensive operation. 5.3. Implementation For our prototype system, we have chosen an object-oriented architecture and design. A high-level toolkit like Motif <ref> [7] </ref> is the best candidate for the user interface, which focuses on ease of programming and event-driven processing. Likewise, media data processing requires fast and reliable code. C++ and the Standard Template Library [10] are an excellent choice for these requirements. The strands are motion-JPEG compressed video sequences. <p> Processing of the media data associated with digital video has to take place in a timely manner, according to the soft deadlines typical to multimedia systems [13]. The scheduling solution used in our prototype relies on the X timer callbacks <ref> [7, 14] </ref>. Although not optimal, this approach has the advantage of being portable and has been adopted by other multimedia applications [8]. However, our implementation is generic and could be easily modified to take into account real-time services, in case they are provided by the system. 5.4.
Reference: [8] <author> Christopher J. Lindblad, </author> <title> A Programming System for the Dynamic Manipulation of Temporally Sensitive Data, </title> <address> MIT/LCS/TR637, </address> <year> 1994. </year>
Reference-contexts: The scheduling solution used in our prototype relies on the X timer callbacks [7, 14]. Although not optimal, this approach has the advantage of being portable and has been adopted by other multimedia applications <ref> [8] </ref>. However, our implementation is generic and could be easily modified to take into account real-time services, in case they are provided by the system. 5.4. Results To verify the framework, we performed a series of experiments with the system described in 5.1 and 5.3.
Reference: [9] <author> Thomas Meyer-Boudnik, Wolfgang Effelsberg, MHEG: </author> <title> An Interchange Format for Interactive Multimedia Presentations, </title> <institution> Computer Science Technical Report, University on Mannheim, </institution> <year> 1994. </year>
Reference-contexts: We focus on two aspects: links 1 between related multimedia objects; and content-based access. We use an object-oriented architecture which offers a high-level abstraction and is easy to integrate within existing multimedia document standards, like MHEG <ref> [9, 13] </ref>. The superclass of all document objects, multimedia object, is an abstract class. This is illustrated in Figure 1, where we use the notation from [5] and the abstract classes appear in italics. The two subclasses correspond to different requirements.
Reference: [10] <author> David Musser, Atul Saini, </author> <title> STL Tutorial and Reference Guide, </title> <publisher> Addison-Wesley 1996. </publisher>
Reference-contexts: A high-level toolkit like Motif [7] is the best candidate for the user interface, which focuses on ease of programming and event-driven processing. Likewise, media data processing requires fast and reliable code. C++ and the Standard Template Library <ref> [10] </ref> are an excellent choice for these requirements. The strands are motion-JPEG compressed video sequences. The absence of temporal prediction allows for frame-level granularity. 3 For our implementation, we use 3 The framework does not depend on strand granularity.
Reference: [11] <author> P. Venkat Rangan, Harrick M. Vin, </author> <title> Designing File Systems for Digital Video and Audio, </title> <booktitle> Proc. of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <year> 1991. </year>
Reference-contexts: File systems designed to support continuous media (digital video and audio) by providing facilities for creating, editing and retrieving multimedia objects <ref> [11] </ref> use an identical structure and therefore no intermediate conversion layer is required. 4. Operations We classify hyper-media document management operations into two categories: low-level operations which are available at the application level, and high-level operations available to application users. 4.1.
Reference: [12] <author> Franc Solina et al., </author> <title> Slovenian Virtual Gallery, </title> <address> http://razor.fri.uni-lj.si:8080/gal. </address>
Reference-contexts: In each case, the behavior is illustrated in a transition diagram which represents different entities as filled circles and the transitions between them as arrows. * The Slovenian Virtual Gallery <ref> [12] </ref> offers a virtual 1 The abstractions we use are independent of the media. A link relates several objects which could have different media types. For this reason, there is no need to use the term hyper-link.
Reference: [13] <author> Ralf Steinmetz, Klara Nahrstedt, </author> <title> Multimedia: Computing, Communications & Applications, </title> <publisher> Prentice Hall 1995. </publisher>
Reference-contexts: We focus on two aspects: links 1 between related multimedia objects; and content-based access. We use an object-oriented architecture which offers a high-level abstraction and is easy to integrate within existing multimedia document standards, like MHEG <ref> [9, 13] </ref>. The superclass of all document objects, multimedia object, is an abstract class. This is illustrated in Figure 1, where we use the notation from [5] and the abstract classes appear in italics. The two subclasses correspond to different requirements. <p> Processing of the media data associated with digital video has to take place in a timely manner, according to the soft deadlines typical to multimedia systems <ref> [13] </ref>. The scheduling solution used in our prototype relies on the X timer callbacks [7, 14]. Although not optimal, this approach has the advantage of being portable and has been adopted by other multimedia applications [8].
Reference: [14] <author> Douglas A. Young, </author> <title> The X Window System Programming and Applications with Xt, </title> <publisher> Prentice Hall 1990. </publisher>
Reference-contexts: Processing of the media data associated with digital video has to take place in a timely manner, according to the soft deadlines typical to multimedia systems [13]. The scheduling solution used in our prototype relies on the X timer callbacks <ref> [7, 14] </ref>. Although not optimal, this approach has the advantage of being portable and has been adopted by other multimedia applications [8]. However, our implementation is generic and could be easily modified to take into account real-time services, in case they are provided by the system. 5.4.
References-found: 14

