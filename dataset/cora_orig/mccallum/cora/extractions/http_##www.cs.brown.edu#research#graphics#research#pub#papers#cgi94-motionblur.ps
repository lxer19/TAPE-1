URL: http://www.cs.brown.edu/research/graphics/research/pub/papers/cgi94-motionblur.ps
Refering-URL: http://www.cs.brown.edu/research/graphics/research/pub/
Root-URL: http://www.cs.brown.edu
Phone: 02912  
Title: Interactive Real-Time Motion Blur Motion blurring fast-moving objects is highly desirable for virtual environments and
Author: Matthias M. Wloka and Robert C. Zeleznik 
Keyword: motion blur, real-time, approximation, transparency, interaction, virtual reality  
Address: Providence, RI  
Affiliation: Computer Science Department Brown University  
Abstract: We introduce a new motion blur algorithm that works in 3D on a per-object basis. The algorithm operates in real-time even for complex objects consisting of several thousand polygons. While it only approximates true motion blur, the generated results are smooth and visually consistent. We achieve this performance break-through by taking advantage of hardware-assisted rendering of semi-transparent polygons, a feature commonly available in today's workstations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Michael Langford. </author> <title> The Master Guide to Photography. Knopf: Distributed by Random House, </title> <address> New York, </address> <year> 1982. </year>
Reference-contexts: Motion blur is common in photography and motion pictures. For example, still photographers deliberately use motion blur as a technique to express dynamic motion <ref> [1] </ref>.
Reference: [2] <author> RKO-Radio Pictures. King Kong Director: Ernest B. Schoedsack, </author> <title> Special Effects: </title> <address> Willes O'Brian, </address> <year> 1933. </year>
Reference-contexts: In contrast, viewers perceive the apparent motion of crisp, unblurred objects as jerky and stilted an effect observable in early stop-motion special effects <ref> [2] </ref>. This strobing effect is more pronounced the lower the frame rate. Unfortunately, correctly simulating motion blur in 3D computer graphics is hard [3]. However, viewers find even crude approximations of motion blur convincing, an acceptance exploited by creators of animated cartoons and computer generated special effects [4].
Reference: [3] <author> Robert L. Cook, Thomas Porter, and Loren Carpenter. </author> <booktitle> Distributed Ray Tracing Computer Graphics (SIGGRAPH '84 Proceedings), </booktitle> <volume> 18(3) </volume> <pages> 137-145, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: In contrast, viewers perceive the apparent motion of crisp, unblurred objects as jerky and stilted an effect observable in early stop-motion special effects [2]. This strobing effect is more pronounced the lower the frame rate. Unfortunately, correctly simulating motion blur in 3D computer graphics is hard <ref> [3] </ref>. However, viewers find even crude approximations of motion blur convincing, an acceptance exploited by creators of animated cartoons and computer generated special effects [4]. Besides looking more natural, motion blur also establishes visual coherence between temporally disparate renderings of the same object. <p> Third and last, the static image is merged with the convolved image, properly taking depth relations into account. Thereafter, research identifies motion blur as a temporal aliasing problem. Its solution for ray-tracing renderers is to supersample in the time domain with additional rays <ref> [3] </ref> [8] [9] [10]. All these solutions, since they depend on ray-tracing, are inherently too slow for interactive applications. Other work also supersamples objects in time independent of ray-tracing. Rendering an object multiple times at different points in time approximates motion blur [11] [12].
Reference: [4] <author> F. Thomas and O. Johnston. </author> <title> Disney Animation: The Illusion of Life. </title> <publisher> Abbeville Press, </publisher> <address> New York, NY, </address> <year> 1981. </year>
Reference-contexts: This strobing effect is more pronounced the lower the frame rate. Unfortunately, correctly simulating motion blur in 3D computer graphics is hard [3]. However, viewers find even crude approximations of motion blur convincing, an acceptance exploited by creators of animated cartoons and computer generated special effects <ref> [4] </ref>. Besides looking more natural, motion blur also establishes visual coherence between temporally disparate renderings of the same object. Until recently, 2D and 3D user interfaces disregarded such visual coherency, while commonly employing fast-moving (popping or iconifying) objects. <p> In this time-span, a viewer is unable to distinguish correct from approximated motion blur <ref> [4] </ref>. We take advantage of this inability and approximate motion blur with a simple and fast algorithm that operates in object space. The algorithm assumes only the existence of hardware-assisted rendering of transparent polygons.
Reference: [5] <author> George G. Robertson, Jock D. Mackinlay, and Stuart K. Card. </author> <title> Cone Trees: </title> <booktitle> Animated 3D Visualizations of Hierarchical Information In Proceedings of ACM CHI'91 Conference on Human Factors in Computing Systems, </booktitle> <pages> pages 189-194, </pages> <year> 1991. </year>
Reference-contexts: Until recently, 2D and 3D user interfaces disregarded such visual coherency, while commonly employing fast-moving (popping or iconifying) objects. The resulting interface is initially confusing, because without coherency clues the user cannot easily synthesize what happens. Work in 3D user interfaces <ref> [5] </ref> argues to animate the user interface, thereby shifting the user's cognitive load to the human perceptual system. Animation is adequate for relatively slow-moving objects. More recent work in 2D [6] demonstrates the usefulness of adding motion blur to the animated user interface.
Reference: [6] <author> Bay-Wei Chang and David Ungar. </author> <title> Animation: </title> <booktitle> From Cartoons To The User Interface UIST Proceedings, </booktitle> <pages> pages 45-55, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: Work in 3D user interfaces [5] argues to animate the user interface, thereby shifting the user's cognitive load to the human perceptual system. Animation is adequate for relatively slow-moving objects. More recent work in 2D <ref> [6] </ref> demonstrates the usefulness of adding motion blur to the animated user interface. Another potential benefit of motion blur is in the interaction with moving objects in virtual environments. The faster an object moves, the harder it is to select via the common point and click metaphors.
Reference: [7] <author> M. Potmesil and I. </author> <title> Chakravarty. </title> <booktitle> Modelling Motion Blur In Computer-Generated Images Computer Graphics (SIGGRAPH '83 Proceedings), </booktitle> <volume> 17(3) </volume> <pages> 389-399, </pages> <month> July </month> <year> 1983. </year>
Reference-contexts: In addition, the technique is too slow for use in interactive applications when applied to moderately complex objects. Much of the previous work on motion blur in computer graphics concentrates on how to generate motion blur for ray-tracing renderers. One of the earliest references <ref> [7] </ref> computes motion blur in a three step process. First, a ray-tracer determines visibility, as well as which pixels are moving points. Second, the algorithm convolves moving points with their image path functions to generate an appropriate blur.
Reference: [8] <author> Mark E. Lee, Richard A. Redner, and Samuel P. Uselton. </author> <title> Statistically Optimized Sampling For Distributed Ray Tracing Computer Graphics (SIGGRAPH '85 Proceedings), </title> <booktitle> 19(3) </booktitle> <pages> 61-67, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: Third and last, the static image is merged with the convolved image, properly taking depth relations into account. Thereafter, research identifies motion blur as a temporal aliasing problem. Its solution for ray-tracing renderers is to supersample in the time domain with additional rays [3] <ref> [8] </ref> [9] [10]. All these solutions, since they depend on ray-tracing, are inherently too slow for interactive applications. Other work also supersamples objects in time independent of ray-tracing. Rendering an object multiple times at different points in time approximates motion blur [11] [12].
Reference: [9] <author> Mark A. Z. Dippe and Erling Henry Wold. </author> <title> Antialiasing Through Stochastic Sampling Computer Graphics (SIGGRAPH '85 Proceedings), </title> <booktitle> 19(3) </booktitle> <pages> 69-78, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: Third and last, the static image is merged with the convolved image, properly taking depth relations into account. Thereafter, research identifies motion blur as a temporal aliasing problem. Its solution for ray-tracing renderers is to supersample in the time domain with additional rays [3] [8] <ref> [9] </ref> [10]. All these solutions, since they depend on ray-tracing, are inherently too slow for interactive applications. Other work also supersamples objects in time independent of ray-tracing. Rendering an object multiple times at different points in time approximates motion blur [11] [12]. <p> The leading, trailing, and joining polygons constructed in Section 3.3 constitute the motion volume. To make the motion volume look like motion blur, we need to associate transparency values with the various polygons. The transparency values we assign reflect the temporal filter <ref> [9] </ref> selected to model the motion blur. A variety of choices of filters are available, for example, Gaussian, triangular, ramp, or box filters. In all the examples shown in this paper, we use a ramp filter, because it gives visually pleasing results.
Reference: [10] <author> Robert L. </author> <title> Cook. </title> <journal> Stochastic Sampling In Computer Graphics ACM Transactions on Graphics, </journal> <volume> 5(1) </volume> <pages> 51-72, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: Third and last, the static image is merged with the convolved image, properly taking depth relations into account. Thereafter, research identifies motion blur as a temporal aliasing problem. Its solution for ray-tracing renderers is to supersample in the time domain with additional rays [3] [8] [9] <ref> [10] </ref>. All these solutions, since they depend on ray-tracing, are inherently too slow for interactive applications. Other work also supersamples objects in time independent of ray-tracing. Rendering an object multiple times at different points in time approximates motion blur [11] [12].
Reference: [11] <author> J. Korein and N. Badler. </author> <booktitle> Temporal Anti-Aliasing In Computer Generated Animation Computer Graphics (SIGGRAPH '83 Proceedings), </booktitle> <volume> 17(3) </volume> <pages> 377-388, </pages> <month> July </month> <year> 1983. </year>
Reference-contexts: All these solutions, since they depend on ray-tracing, are inherently too slow for interactive applications. Other work also supersamples objects in time independent of ray-tracing. Rendering an object multiple times at different points in time approximates motion blur <ref> [11] </ref> [12]. However, if the number of temporal sampling points is finite and constant, the approximation is poor (see Figure 4). Furthermore, special purpose hardware [12] is necessary to merge these multiple images efficiently. Even then, the cost of rendering an object multiple times is prohibitive. <p> We want to generate motion blur by supersampling the object's movement between subsequent frames. Repeated integration only incorporates information from the n previous frames and does not include information from the time period in-between subsequent frames. The various approaches described in <ref> [11] </ref> [14] [15] [16] [17] all operate on the 2D projection of the motion onto the film plane. Therefore, these algorithms cannot easily be adapted to take advantage of the graphics accelerators common in today's workstations.
Reference: [12] <author> Paul Haeberli and Kurt Akeley. </author> <title> The Accumulation Buffer: </title> <booktitle> Hardware Support For High-Quality Rendering Computer Graphics (SIGGRAPH '90 Proceedings), </booktitle> <volume> 24(4) </volume> <pages> 309-318, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: All these solutions, since they depend on ray-tracing, are inherently too slow for interactive applications. Other work also supersamples objects in time independent of ray-tracing. Rendering an object multiple times at different points in time approximates motion blur [11] <ref> [12] </ref>. However, if the number of temporal sampling points is finite and constant, the approximation is poor (see Figure 4). Furthermore, special purpose hardware [12] is necessary to merge these multiple images efficiently. Even then, the cost of rendering an object multiple times is prohibitive. <p> Other work also supersamples objects in time independent of ray-tracing. Rendering an object multiple times at different points in time approximates motion blur [11] <ref> [12] </ref>. However, if the number of temporal sampling points is finite and constant, the approximation is poor (see Figure 4). Furthermore, special purpose hardware [12] is necessary to merge these multiple images efficiently. Even then, the cost of rendering an object multiple times is prohibitive. <p> Haeberli and Akeley suggest increasing performance by applying repeated integration [13] to the rendering process <ref> [12] </ref>. In repeated integration, the renderer creates an initial frame by repeatedly rendering an object as described above. The resulting frame represents the object at time samples t 1 ; : : : ; t n . Thereafter, the renderer does not discard the frame, but instead modifies it repeatedly.
Reference: [13] <author> P. S. Heckbert. </author> <title> Filtering By Repeated Integration Computer Graphics (SIGGRAPH '86 Proceedings), </title> <booktitle> 20(4) </booktitle> <pages> 315-321, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: Haeberli and Akeley suggest increasing performance by applying repeated integration <ref> [13] </ref> to the rendering process [12]. In repeated integration, the renderer creates an initial frame by repeatedly rendering an object as described above. The resulting frame represents the object at time samples t 1 ; : : : ; t n .
Reference: [14] <author> Edwin Catmull. </author> <title> An Analytic Visible Surface Algorithm For Independant Pixel Processing Computer Graphics (SIGGRAPH '84 Proceedings), </title> <booktitle> 18(3) </booktitle> <pages> 109-115, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: We want to generate motion blur by supersampling the object's movement between subsequent frames. Repeated integration only incorporates information from the n previous frames and does not include information from the time period in-between subsequent frames. The various approaches described in [11] <ref> [14] </ref> [15] [16] [17] all operate on the 2D projection of the motion onto the film plane. Therefore, these algorithms cannot easily be adapted to take advantage of the graphics accelerators common in today's workstations.
Reference: [15] <author> C. W. Grant. </author> <title> Integrated Analytic Spatial And Temporal Anti-Aliasing For Polyhedra In 4-Space Computer Graphics (SIGGRAPH '85 Proceedings), </title> <booktitle> 19(3) </booktitle> <pages> 79-84, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: We want to generate motion blur by supersampling the object's movement between subsequent frames. Repeated integration only incorporates information from the n previous frames and does not include information from the time period in-between subsequent frames. The various approaches described in [11] [14] <ref> [15] </ref> [16] [17] all operate on the 2D projection of the motion onto the film plane. Therefore, these algorithms cannot easily be adapted to take advantage of the graphics accelerators common in today's workstations.
Reference: [16] <author> N. L. Max and D. M. Lerner. </author> <booktitle> A Two-And-A-Half-D Motion-Blur Algorithm Computer Graphics (SIGGRAPH '85 Proceedings), </booktitle> <volume> 19(3) </volume> <pages> 85-93, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: We want to generate motion blur by supersampling the object's movement between subsequent frames. Repeated integration only incorporates information from the n previous frames and does not include information from the time period in-between subsequent frames. The various approaches described in [11] [14] [15] <ref> [16] </ref> [17] all operate on the 2D projection of the motion onto the film plane. Therefore, these algorithms cannot easily be adapted to take advantage of the graphics accelerators common in today's workstations. The resulting performance penalty in rendering polygons therefore disqualifies these algorithms for use in virtual reality applications.
Reference: [17] <editor> Nelson Max. </editor> <booktitle> Polygon-Based Post-Process Motion Blur The Visual Computer, </booktitle> <volume> 6(6) </volume> <pages> 308-314, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: We want to generate motion blur by supersampling the object's movement between subsequent frames. Repeated integration only incorporates information from the n previous frames and does not include information from the time period in-between subsequent frames. The various approaches described in [11] [14] [15] [16] <ref> [17] </ref> all operate on the 2D projection of the motion onto the film plane. Therefore, these algorithms cannot easily be adapted to take advantage of the graphics accelerators common in today's workstations. The resulting performance penalty in rendering polygons therefore disqualifies these algorithms for use in virtual reality applications.
Reference: [18] <author> W. T. Reeves. </author> <title> Particle Systems ATechnique For Modeling A Class Of Fuzzy Objects ACM Transactions on Graphics, </title> <booktitle> 2 </booktitle> <pages> 91-108, </pages> <month> April </month> <year> 1983. </year>
Reference-contexts: Therefore, these algorithms cannot easily be adapted to take advantage of the graphics accelerators common in today's workstations. The resulting performance penalty in rendering polygons therefore disqualifies these algorithms for use in virtual reality applications. In other work, Reeves introduces a motion blur algorithm for his particle systems in <ref> [18] </ref>. Unfortunately, the algorithm only applies to particles volumeless points that are the size of a pixel. Finally, Chen has devised an algorithm to morph 2D images that correlate on a pixel basis [19] and has extended it to synthesize motion blur.
Reference: [19] <author> Shenchang Eric Chen and Lance Williams. </author> <title> View Interpolation For Image Synthesis In James T. </title> <editor> Kajiya, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH '93 Proceedings), </booktitle> <volume> volume 27, </volume> <pages> pages 279-288, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: In other work, Reeves introduces a motion blur algorithm for his particle systems in [18]. Unfortunately, the algorithm only applies to particles volumeless points that are the size of a pixel. Finally, Chen has devised an algorithm to morph 2D images that correlate on a pixel basis <ref> [19] </ref> and has extended it to synthesize motion blur. While the morphing part of his algorithm almost operates in real-time, automatically correlating the source images does not. Thus, it is unsuitable for general, interactive, or dynamic scenes.
Reference: [20] <author> Hewlett Packard. </author> <title> Starbase Reference: HP 9000 Computers, </title> <booktitle> first edition, </booktitle> <month> January </month> <year> 1991. </year> <title> HP Part No. </title> <type> 98592-90067. </type>
Reference-contexts: We can then let the hardware integrate these semi-transparent surfaces via alpha-blending during the z-buffering process. However, this algorithm is still too costly for two reasons. First, the algorithm generates too many sweep polygons, and second, current hardware requires semi-transparent polygons to be depth-sorted to guarantee proper alpha-blending <ref> [20] </ref>. Since the algorithm produces many overlapping polygons and sorting them is too expensive, the resulting image is likely to have alpha-blending errors. surface, shown here. <p> When an object moves quickly and therefore, when motion blur is needed most, the generated temporal aliasing becomes unacceptably crude, or conversely, the solution becomes non-real time. Finally, the third flaw is hardware related. Current z-buffers require transparent polygons to be rendered in order <ref> [20] </ref>, yet our algorithm does not sort the generated transparent polygons. However, possible resulting alpha-blending errors are not noticeable, because our algorithm generates few overlapping, transparent polygons. 5.2 Advantages The many benefits of our algorithm outweigh the above disadvantages.
References-found: 20

