URL: http://www.cis.ohio-state.edu/volviz/Papers/1997/eg97_wvlts.ps.gz
Refering-URL: http://www.cis.ohio-state.edu/volviz/papers_date.html
Root-URL: 
Title: Steering Image Generation with Wavelet Based Perceptual Metric  
Author: Ajeetkumar Gaddipatti , Raghu Machiraju , Roni Yagel , Cleveland, U. S. A. 
Note: Foundation,  
Affiliation: Department of Biomedical Engineering 1 Computer and Information Science 5 The Ohio State University Department of Computer Science 3 NSF Engineering Research Center 4 Mississippi State University Department of Biomedical Engineering 2 The Cleveland Clinic  
Abstract: It is often the case that images generated by image synthesis algorithms ar e judged by visual examination. The user resorts to an iterative refinement process of inspection and rendering until a satisfactory image is obtained. In this paper we propose quantitative met-rics to compare images that arise from an image synthesis algorithm. The intent is to be able to guide the refinement process inherent in image synthesis. The MeanSquare-Error (MSE) has been traditionally employed to guide this pr ocess. However, it is not a viable metric for image synthesis control. We propose the use of a wavelet based perceptual metric which incorporates the frequency response of the Human Visual System. A useful aspect of the wavelet based metric is its ability to selectively measure the changes to structures of different sizes and scales in specific locations. Also, by resorting to the use of wavelets of various degrees of regularity, one can seek different levels of smoothness in an image. It is rare that such level of control can be obtained from a metric other than a wavelet based metric. We show the usefulness of our metric by examining its effectiveness in providing insights for common operations of an image synthesis algorithm (e.g., blurring). W e also provide some examples of its use in rendering algorithms frequently used in graphics.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Chiu K., Herf M., Shirley P., Swamy S., Zimmerman K., </author> <title> Spatially Nonuniform Scaling Functions for High Contrast Images, </title> <booktitle> Proceedings of Graphics Interface93, </booktitle> <month> May </month> <year> 1993, </year> <pages> pp. 245-254. </pages>
Reference-contexts: The metrics employ the Fourier transform which does not preserve local spatial characteristics. Finally, the metrics were designed and used more for purposes of visual similitude rather than as guiding tools in a refinement process. In <ref> [1] </ref> methodologies have been proposed to include perceptual considerations into the rendering process. Although laudable, these methodologies are cumbersome to incorporate and are restricted to specific rendering algorithms. Much effort has been expended in incorporating the characteristics of the HVS into all aspects of image coding and restoration [8][19][20].
Reference: 2. <author> Cosman P. C., Gray R. M., Olshen R. A., </author> <title> Evaluating Quality of compressed medical images: SNR, subjective rating and diagnostic accuracy, </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 82(6) </volume> <pages> 919-932, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: We are cognizant of the fact that our objective measures have to be validated by an evaluation procedure that employs human subjects. However , objective measures can perform well in many situations if designed with care. For instance, it was reported in <ref> [2] </ref> that the quantitative measure of signal-to-noise ratio (SNR) actually outperformed more expensive subjective tests. There has been little ef fort in developing viable image metrics in image synthesis. <p> As a result, they design Figure-Of-Merits (FOMs) which can be used to benchmark algorithms. Also, Cosman et al. performed a study of quality measures which are applied to compressed medical images <ref> [2] </ref>. Similarly, considerable work has been done to develop viable metrics for searching in image databases. These metrics operate on color, texture, orientation, shape and contrast of images. Essentially , one searches for similitude in image content in an extracted feature space.The Haar wavelet transform was employed in [7].
Reference: 3. <author> Daubechies, I., </author> <title> Ten Lectures on Wavelets, </title> <booktitle> CBMS-NSF Regional Conference Series in Applied Mathematics, </booktitle> <publisher> SIAM, </publisher> <address> Philadelphia, PA, </address> <year> 1992. </year>
Reference-contexts: Finally, in this section we describe some previous efforts from various application domains. Of the many multiscale transforms used in image analysis, we are particularly interested in the Gabor [14], the Cortical [18] and the wavelet transforms <ref> [3] </ref>. The f irst two transformations are more amenable to use as tools for image analysis rather than coding or compression of images. It has also been shown that the receptive field of the visual cortex can be modeled as a 2D Gabor Transform [14]. <p> The process is similar to that of HVS wherein image is locally decomposed into spatial frequency and orientation components. Finally, by choosing wavelets with different degrees of regularity one can choose the level of smoothness one is seeking in the intensity function. W e employ Daubechies wavelets <ref> [3] </ref> in the work described here. These wavelets are indexed by a parameter N - a function is implemented as a 2N tap bandpass filter.
Reference: 4. <author> Donoho, D. L., Johnstone, I. M., </author> <title> Ideal Spatial Adaptation via Wavelet Shrinkage, </title> <journal> Biometrika 81 </journal> <pages> 422-455. </pages>
Reference-contexts: This mask can be used to further threshold the coef ficients. Denoising is also implemented in two stages of the algorithm. The coefficients are first thresholded by using a Gaussian noise model as reported in <ref> [4] </ref>. Later, while generating the combining mask, denoising is again achieved as the noise in smoother levels is eliminated.
Reference: 5. <author> Furuie S., Herman G. T., Narayan T. K., Kinahan P. E., Karp J. S., Lewitt R. M., Matej S., </author> <title> A methodology for testing statistically significant differences between fully 3D PET reconstruction algorithms, </title> <journal> Phys. Med. Biology, </journal> <volume> 39 </volume> <pages> 341-354, </pages> <year> 1994. </year>
Reference-contexts: In medical imaging, however , much effort has been expended in defining metrics. Furuie et al. designed a set of phantom images which test the reconstruction accuracy of algorithms on 3D PET (Positron Emission T omography) images <ref> [5] </ref>. As a result, they design Figure-Of-Merits (FOMs) which can be used to benchmark algorithms. Also, Cosman et al. performed a study of quality measures which are applied to compressed medical images [2]. Similarly, considerable work has been done to develop viable metrics for searching in image databases.
Reference: 6. <author> Higgins G. C., </author> <title> Image Quality Criteria, </title> <journal> Journal of Applied Photographic Engineering, 1977, </journal> <volume> 3(2) </volume> <pages> 53-60. </pages>
Reference-contexts: Our goals are similar in essence to those of Higgins who states that the image quality of tone reproduction systems depends on how well the microscopic details are reproduced <ref> [6] </ref>. We propose a perceptual metric that meets these three goals. Each of the two images to be compared is subject to a process to yield saliency values which are then actually compared in a MSE fashion. <p> A 2D version can be easily obtained by replacing f i with radial frequency, , where m and u are the horizontal and vertical frequencies. been described for photographic and tone reproduction systems <ref> [6] </ref> and used to describe the resulting image quality. We, however, shall restrict ourselves to the one constructed by Mannos and Sakrison [10]. One can conceivably multiply the CSF with the frequency spectrum of an image and then determine a saliency [15].
Reference: 7. <author> Jacobs, C. E., Finkelstein, A., Salesin, D. H., </author> <title> Fast Multiresolution Image Querying, </title> <booktitle> Computer Graphics (Proceedings of Siggraph95), </booktitle> <pages> pp. 277-286. </pages>
Reference-contexts: Similarly, considerable work has been done to develop viable metrics for searching in image databases. These metrics operate on color, texture, orientation, shape and contrast of images. Essentially , one searches for similitude in image content in an extracted feature space.The Haar wavelet transform was employed in <ref> [7] </ref>. However the resulting metric is not robust. Finally , in multispectral image fusion, images obtained from different spectral bands are combined [21]. The combination is guided by the presence of structures or information. Wavelet based methods are being reported which estimate the features or structures in an image region-by-region.

Reference: 9. <author> Levoy M., </author> <title> Display of Surfaces from Volume Data, </title> <journal> IEEE Computer Graphics and Applications, </journal> <month> May </month> <year> 1988, </year> <pages> 8(5) 29-37. </pages>
Reference-contexts: To explain the need for viable metrics let us consider the following examples derived from dif ferent image synthesis algorithms. For instance, in volumetric rendering blurring and aliasing can occur during the process of reconstruction along the ray (raycasting algorithms <ref> [9] </ref>) or along a slice (slicing algorithms [23]). Thus, if a certain filter of a certain size is used in function reconstruction, we would like to gauge the effect of this filter at different locations in the final image and on structures of different sizes.
Reference: 10. <author> Mannos, J. L., Sakrison, D. J., </author> <title> The Effects of a Visual Fidelity Criterion on the Encoding of Images, </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 20(3) </volume> <pages> 525-536, </pages> <month> July </month> <year> 1974. </year>
Reference-contexts: Black indicates low value and white the highest. (a) 0 p p/2 p/4 p/8 Gaddipati et al. / Steering Image Generation with Wavelet Metric for higher frequencies. There exists reported work which attempts to measure the CSF of the human visual system. For instance, Mannos and Sakrison <ref> [10] </ref>, after conducting a series of psychophysical experiments on human subjects, found that the CSF can be modeled by the function in Equation 2. (2) Here f s is spatial frequency in cycles per degree. <p> We, however, shall restrict ourselves to the one constructed by Mannos and Sakrison <ref> [10] </ref>. One can conceivably multiply the CSF with the frequency spectrum of an image and then determine a saliency [15]. However, this disallows the ability to delineate regions of interest and the use of simple schemes to detect structures. Hence, multiscale transforms offer significant advantages when combined with a CSF. <p> f ( ) 0.0499 0.2964f s +[ ] 0.114f s ( ) exp= cycles degree - f i cycles pixel - f n pixels degree - arc 1 d h v + + - = 2 2 Gaddipati et al. / Steering Image Generation with Wavelet Metric the one in <ref> [10] </ref>) performed adequately for the given scenes, they still did not capture local variations in intensity well. The metrics employ the Fourier transform which does not preserve local spatial characteristics. <p> Although laudable, these methodologies are cumbersome to incorporate and are restricted to specific rendering algorithms. Much effort has been expended in incorporating the characteristics of the HVS into all aspects of image coding and restoration [8][19][20]. For instance, the HVS weighing method of Mannos and Sakrison <ref> [10] </ref> has been applied to coders including those based on the wavelet transform. However, as it was pointed out in [15], one cannot directly use the metrics of coding in image synthesis. In medical imaging, however , much effort has been expended in defining metrics. <p> The images are combined if the images are close, otherwise the image with the lar ger estimate dominates. Wilson et al. also employ the HVS weighing method of Mannos and Sakrison <ref> [10] </ref> to guide the combining process. A windowed Fourier transform of the wavelet sub-bands is performed to obtain a finer frequency analysis of the wavelet spectrum. These frequencies are weighed by the contrast sensitivity function. We proposed a metric for image synthesis [11] similar in essence.
Reference: 11. <author> Machiraju, R., Gaddipati, A., Yagel, R., </author> <title> Steering Image Generation With Wavelet Based Perceptual Metric, presented at IEEE Visualization 96 as a hot topic paper. </title> <type> (Technical Research Report, </type> <institution> Department of Computer and Information Science, The Ohio State University, OSU-CISRC-6/96-TR) </institution>
Reference-contexts: A windowed Fourier transform of the wavelet sub-bands is performed to obtain a finer frequency analysis of the wavelet spectrum. These frequencies are weighed by the contrast sensitivity function. We proposed a metric for image synthesis <ref> [11] </ref> similar in essence. However, for reasons of computational efficiency we propose another metric which is easier to compute. We describe our methods in Section 4. 4. Wavelet Based Image Comparison Metric In this section we describe our metric.
Reference: 12. <author> Machiraju, R., Gaddipati A., Yagel, </author> <title> R, Detection and Enhancement of Scale Coherent Structures Using Wavelet Transform Products, </title> <booktitle> Technical Conference on Wavelet Applications in Signal and Image Processing V, SPIE Annual Meeting,San Diego, </booktitle> <address> CA, </address> <month> 27 July - August 1, </month> <note> 1997 (to appear). </note>
Reference-contexts: We describe our methods in Section 4. 4. Wavelet Based Image Comparison Metric In this section we describe our metric. The perceptual metric we propose here builds on the subband coherent structure detection algorithm described in <ref> [12] </ref>. The detection of coherent structure follows the wavelet transform. Later, by employing weights based on the CSF we modulate the wavelet coef ficients. Finally, the images are compared in the mean square sense. 4.1 Coherent Structure Detection Our sub-band combining algorithm described in [12] is similar to the one presented <p> coherent structure detection algorithm described in <ref> [12] </ref>. The detection of coherent structure follows the wavelet transform. Later, by employing weights based on the CSF we modulate the wavelet coef ficients. Finally, the images are compared in the mean square sense. 4.1 Coherent Structure Detection Our sub-band combining algorithm described in [12] is similar to the one presented in Xu et al. [23]. Both attempt to detect correlated structures across the scales by employing the product of the wavelet transform across scales. However, in [23] the emphasis is on denoising and being able to detect edges, while in [12] the algorithm identifies <p> algorithm described in <ref> [12] </ref> is similar to the one presented in Xu et al. [23]. Both attempt to detect correlated structures across the scales by employing the product of the wavelet transform across scales. However, in [23] the emphasis is on denoising and being able to detect edges, while in [12] the algorithm identifies structures of arbitrary singularity and assigns pixel-wise saliency values in regions populated by singular structures. The saliency is obtained from a mask derived from the process of multiplication. zero otherwise.
Reference: 13. <author> Mallat, S., </author> <title> A Theory for Multiresoultion Signal Decomposition: The Wavelet Representation, </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11(7) </volume> <pages> 674-693, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: We use the CSF model in Equation 2, substituting radial frequency f r for f i . The wavelet transform is obtained from the continuous application of two quadrature mirror filters <ref> [13] </ref>; H, a low-pass filter and G, a half band-pass filter. Thus, by applying G to a discrete input with bandwidth (0, p), a signal with bandwidth (0, p/2) is acquired.
Reference: 14. <author> Navarro P., Cristobal, G, </author> <title> Image Analysis using Gabor Transform, Advances in Electronics and Electron Physics, </title> <editor> (P.W. Hawkes ed.), </editor> <publisher> Academic Press, </publisher> <address> San Diego, </address> <booktitle> CA, </booktitle> <volume> Vol </volume> 8:(309-404). 
Reference-contexts: Then, we justify our choice of the wavelet transform for developing perceptual metric. Finally, in this section we describe some previous efforts from various application domains. Of the many multiscale transforms used in image analysis, we are particularly interested in the Gabor <ref> [14] </ref>, the Cortical [18] and the wavelet transforms [3]. The f irst two transformations are more amenable to use as tools for image analysis rather than coding or compression of images. <p> The f irst two transformations are more amenable to use as tools for image analysis rather than coding or compression of images. It has also been shown that the receptive field of the visual cortex can be modeled as a 2D Gabor Transform <ref> [14] </ref>. For 2D images, the Gabor transform also describes the orientation of the structures. However, the transform is redundant and is expensive to compute since it cannot be realized as a pyramid. There do exist bi-orthogonal approximations to the Gabor Transformation.
Reference: 15. <author> Rushmeier H., Ward G., Piatko C., Sanders P., Rust B., </author> <title> Comapring Real and Synthetic Images: Some Ideas About Metrics, </title> <booktitle> Sixth Eurographics Workshop on Rendering, </booktitle> <address> Dublin, Ireland, </address> <year> 1995, </year> <pages> pp. 82-91. </pages>
Reference-contexts: The metric ideally should identify benef icial or adverse effects of various rendering operations on the final image and facilitate the choice of parameters. We propose a wavelet based perceptual metric in this paper. Objective perceptual metrics have been proposed elsewhere also <ref> [15] </ref>. The proposed metric differs from previous methods in that it has the ability to measure variations in images at specific locations, orientations and scales. Also, it has the ability to discern intensity functions of varying degree of smoothness in the image. <p> We, however, shall restrict ourselves to the one constructed by Mannos and Sakrison [10]. One can conceivably multiply the CSF with the frequency spectrum of an image and then determine a saliency <ref> [15] </ref>. However, this disallows the ability to delineate regions of interest and the use of simple schemes to detect structures. Hence, multiscale transforms offer significant advantages when combined with a CSF. As an alternative, a windowed Fourier T ransform can be conducted to maintain locality [1 1] [21]. <p> There has been little ef fort in developing viable image metrics in image synthesis. Among the f irst known efforts, Rushmeier et al. employ metrics from image coding literature to compare images that arise from radi-osity algorithms <ref> [15] </ref>. Three metrics were described which differ from each other in the CSFs used. Five evaluation criteria were proposed to determine the suitability of the metrics. Sample scenes were constructed and the behavior of the metrics was examined for these scenes. <p> For instance, the HVS weighing method of Mannos and Sakrison [10] has been applied to coders including those based on the wavelet transform. However, as it was pointed out in <ref> [15] </ref>, one cannot directly use the metrics of coding in image synthesis. In medical imaging, however , much effort has been expended in defining metrics. Furuie et al. designed a set of phantom images which test the reconstruction accuracy of algorithms on 3D PET (Positron Emission T omography) images [5]. <p> The behavior should rather be dictated by the changes wrought upon the image. Rush-meier et al. used few ratio based criteria in addition to the ones listed above <ref> [15] </ref>. We did not consider ratios in our metric as it is already normalized. Before we describe our experimental methodology , we illustrate the short comings of the MSE metric. 5.1 Why Is MSE Not A Viable Metric? We illustrate this through the example shown in Figure 3. <p> This can be attributed to the fact that the MRI image is noisy and populated with small features and hence the pixel-wise dif ferences show up prominently. Our implementation of Rushmeier metric <ref> [15] </ref> followed MSE closely for this example. In the following examples also, Rushmeier metric fared worser when compared to our metric. Due to space constraints, we do not discuss this any further in this paper.
Reference: 16. <author> Simoncelli E. P., Freeman W. T., Adelson E. H., Heeger D. J., </author> <title> Shiftable Multi-Scale Transforms [or Whats Wrong with Orthonormal Wavelets], </title> <journal> IEEE Trans. Information Theory, Special Issue on Wavelets, </journal> <month> March </month> <year> 1992., </year> <pages> 38(2) 587-607. </pages>
Reference-contexts: It is only in the inverse transform that the aliasing effects are mitigated. Redundant transforms like the steerable transforms found in <ref> [16] </ref> perform a decomposition into frequency bands which are further split into orientation bands. In redundant transforms, basis functions overlap each other at dif ferent scales, thus reducing the aliasing artifact. However , we do not explore the use of this transform in this paper. <p> Thus for each band a weight can be computed which is then applied to the wavelet transform. The CSF based model is linear and cannot explain all aspects of human vision, especially the ability to detect low contrast images. In [17] the transform of <ref> [16] </ref> is used to construct a nonlinear model of human vision which can address the issue of contrast masking. W e however, limit ourselves to the linear perceptual model. W e provide the details of this process in Section 4. <p> The perceptual weights were computed with the assumption that the wavelet transforms are ideal. Thus, it might be useful to recompute the weights. Also, redundant wavelet schemes like those of <ref> [16] </ref> cure some of the ills of the orthogonal wavelet transform, especially aliasing. It will be useful to learn about use of such a transform in developing a metric. Finally, the metric should be tested on more image synthesis algorithms to understand its performance completely. FIGURE 4.

Reference: 18. <author> Watson A. B., </author> <title> The Cortex Transform: Rapid Computation of Simulated Neural Images, </title> <journal> CVGIP, </journal> <volume> 39 </volume> <pages> 311-327, </pages> <year> 1987. </year>
Reference-contexts: Then, we justify our choice of the wavelet transform for developing perceptual metric. Finally, in this section we describe some previous efforts from various application domains. Of the many multiscale transforms used in image analysis, we are particularly interested in the Gabor [14], the Cortical <ref> [18] </ref> and the wavelet transforms [3]. The f irst two transformations are more amenable to use as tools for image analysis rather than coding or compression of images. It has also been shown that the receptive field of the visual cortex can be modeled as a 2D Gabor Transform [14]. <p> For 2D images, the Gabor transform also describes the orientation of the structures. However, the transform is redundant and is expensive to compute since it cannot be realized as a pyramid. There do exist bi-orthogonal approximations to the Gabor Transformation. Notable among these is the cortical transformation of Watson <ref> [18] </ref> which has often served as a computational model of the HVS. The cortical transformation was devised as a result of a study of the human cortex and the visual system.
Reference: 19. <author> Watson A. B., Gloria Y. Y., Joshua A. S., Villasenor J., </author> <title> Visual thresholds for wavelet quantization error, Human Vision and Electronic Imaging, </title> <editor> Editors, Rogowitz B., Allebach J., </editor> <booktitle> Proceedings of the SPIE 2657, </booktitle> <pages> 382-392. </pages>
Reference: 20. <author> Watson A. B., Gale A. P., Joshua A. S., Ahumada A. J., </author> <title> Visibility of DCT quantization noise: Effects of display resolution, </title> <booktitle> Proceedings of Society for Information Display, </booktitle> <address> San Jose, CA, </address> <publisher> Society for Information Display, </publisher> <pages> pp. 697-700 </pages>
Reference: 21. <author> Wilson, T. A., Rogers, S. K., Myers, L. R., </author> <title> Perceptual Based Hyperspectral Image Fusion using Multiresoultion Analysis, Optical Engineering, </title> <month> November </month> <year> 1995. </year>
Reference-contexts: However, this disallows the ability to delineate regions of interest and the use of simple schemes to detect structures. Hence, multiscale transforms offer significant advantages when combined with a CSF. As an alternative, a windowed Fourier T ransform can be conducted to maintain locality [1 1] <ref> [21] </ref>. This methodology is however computationally expensive. We propose use of an alternate methodology which determines the weight of the CSF curve in each subband. A frequency decomposition induced by a dyadic wavelet transform is imposed on the CSF (Figure 1a). <p> Essentially , one searches for similitude in image content in an extracted feature space.The Haar wavelet transform was employed in [7]. However the resulting metric is not robust. Finally , in multispectral image fusion, images obtained from different spectral bands are combined <ref> [21] </ref>. The combination is guided by the presence of structures or information. Wavelet based methods are being reported which estimate the features or structures in an image region-by-region. The maximum estimator, the energy, or a HVS weighted measure is used to determine the closeness of two images.
Reference: 22. <author> Witkin A., </author> <title> Scale Space Filtering, </title> <booktitle> Proceedings of International Joint Conference on Artificial Intelligence, </booktitle> <address> Karlsruhe, </address> <year> 1983. </year>
Reference-contexts: Although the motivation for the multi-resolution nature was more for the sake of efficiency, it was noted by many that the HVS does function in a multi-scale fashion. Witkin <ref> [22] </ref>, for instance, noted that the eye discerns only those features that persist through all scales. Gaddipati et al. / Steering Image Generation with Wavelet Metric The discrete orthogonal wavelet transform does not serve as a computational model for the HVS.
Reference: 23. <author> Xu Y., Weaver J. B., Healy D. M., Lu J., </author> <title> Wavelet Transform Domain Filters: A Spatially Selective Noise Filtration Technique, </title> <journal> IEEE Transactions On Image Processing, </journal> <volume> Vol. 3, No. 6, </volume> <month> November </month> <year> 1994, </year> <pages> pp. 747-758. </pages>
Reference-contexts: To explain the need for viable metrics let us consider the following examples derived from dif ferent image synthesis algorithms. For instance, in volumetric rendering blurring and aliasing can occur during the process of reconstruction along the ray (raycasting algorithms [9]) or along a slice (slicing algorithms <ref> [23] </ref>). Thus, if a certain filter of a certain size is used in function reconstruction, we would like to gauge the effect of this filter at different locations in the final image and on structures of different sizes. <p> Later, by employing weights based on the CSF we modulate the wavelet coef ficients. Finally, the images are compared in the mean square sense. 4.1 Coherent Structure Detection Our sub-band combining algorithm described in [12] is similar to the one presented in Xu et al. <ref> [23] </ref>. Both attempt to detect correlated structures across the scales by employing the product of the wavelet transform across scales. However, in [23] the emphasis is on denoising and being able to detect edges, while in [12] the algorithm identifies structures of arbitrary singularity and assigns pixel-wise saliency values in regions <p> are compared in the mean square sense. 4.1 Coherent Structure Detection Our sub-band combining algorithm described in [12] is similar to the one presented in Xu et al. <ref> [23] </ref>. Both attempt to detect correlated structures across the scales by employing the product of the wavelet transform across scales. However, in [23] the emphasis is on denoising and being able to detect edges, while in [12] the algorithm identifies structures of arbitrary singularity and assigns pixel-wise saliency values in regions populated by singular structures. The saliency is obtained from a mask derived from the process of multiplication. zero otherwise.
Reference: 24. <author> Yagel R., Reed D. M., Law A., Shih P., Shareef N., </author> <title> Hardware Assisted Volume Rendering of Unstructured Grids by Incremental Slicing, </title> <booktitle> Proceedings 1996 Symposium on Volume Visualization, </booktitle> <address> San Francisco, CA, </address> <month> September </month> <year> 1996, </year> <pages> pp. 55-62. </pages>
Reference-contexts: As expected, the values for the MSE and perceptual metric were more for the jittered image sequence. 5.4 Artifacts in Volume Rendering We tested our metric on images obtained from a slice-based volume rendering algorithm for unstructured grids generated from tetrahedral cells <ref> [24] </ref>. The algorithm slices the unstructured grid parallel to the screen and then composites the resulting triangles from each slice. The algorithm employs an edge-table scheme to exploit the coherency in such grids. The quality of the image depends on the number of slices. The images suffer primarily from aliasing.
References-found: 22

