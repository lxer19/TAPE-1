URL: http://www.eecs.umich.edu/UMichMP/Publications/Proposals/proposal-claude.ps
Refering-URL: http://www.eecs.umich.edu/UMichMP/proposals.html
Root-URL: http://www.cs.umich.edu
Abstract: High performance I/O interface design is becoming a very important research area within VLSI. Increases in microprocessor clock frequencies have dramatically outpaced increases in I/O bandwidth, resulting in a bottleneck between processors and memory. This proposal discusses the issues relevant to high speed interface design. Studies are described that will allow for the design of a high speed, low power processor-memory interface. The interface is intended to be used in a complementary gallium arsenide (CGaAs), multichip module implementation of the PowerPC architecture. The goal of the work is to design an interface that maximizes bandwidth and noise immunity, minimizes power and meets the needs of future microprocessors. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Sharon E. Perl and Richard L. </author> <title> Sites, Studies of Windows NT Performance using Dynamic Execution Traces, </title> <booktitle> in Proceedings of the USENIX 2ndSymposium on Operating Systems Design and Implementation, </booktitle> <year> 1996. </year>
Reference: [2] <author> Burger et al., </author> <title> Quantifying Memory Bandwidth Limitations of Current and Future Microprocessors, </title> <booktitle> Proc of 23rd International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1996. </year>
Reference: [3] <author> William J. Dally and John Poulton, </author> <title> Digital Systems Engineering, </title> <publisher> Cambridge University Press, </publisher> <year> 1997. </year>
Reference-contexts: Current I/O interfaces do not provide enough bandwidth, and the result is a significant bottleneck between processors and memory [1],[2]. While processor speeds have increased at a rate of 40% per year, off-chip signaling rates have scaled more slowly, at a rate of approximately 14% per year <ref> [3] </ref>. Also, the number of available pins are increasing at a rate of approximately 12% per year [3], rapidly outpaced by the amount of on-chip functionality. The bandwidth gap is growing at 33% per year [3]. Recent trends in both computer architecture and applications are exacerbating the problem. <p> While processor speeds have increased at a rate of 40% per year, off-chip signaling rates have scaled more slowly, at a rate of approximately 14% per year <ref> [3] </ref>. Also, the number of available pins are increasing at a rate of approximately 12% per year [3], rapidly outpaced by the amount of on-chip functionality. The bandwidth gap is growing at 33% per year [3]. Recent trends in both computer architecture and applications are exacerbating the problem. While processor speeds have increased dramatically, DRAM speeds have increased at only 7% per year [4]. <p> off-chip signaling rates have scaled more slowly, at a rate of approximately 14% per year <ref> [3] </ref>. Also, the number of available pins are increasing at a rate of approximately 12% per year [3], rapidly outpaced by the amount of on-chip functionality. The bandwidth gap is growing at 33% per year [3]. Recent trends in both computer architecture and applications are exacerbating the problem. While processor speeds have increased dramatically, DRAM speeds have increased at only 7% per year [4]. This has led to architectural techniques designed to reduce or tolerate latency. However, many of these techniques require high peak bandwidth. <p> Conventional digital interface circuits have tended to overpower noise rather than reject it. This has led to the generation of more noise and higher power dissipation. Internal power supply voltages are decreasing by approximately 15% a year <ref> [3] </ref>. Currently, ICs operating with 2V supplies are not uncommon [9],[10]. This has resulted in low power cores. However, chips still require a 3.3V supply voltage for I/O. The interface voltage will eventually scale to 2V, seriously compromising I/O noise High Speed Processor-Memory Interfaces Ph.D. Thesis Proposal Claude R. <p> The following sections describe the required studies. UP DOWN V CTL I DOWN Fig. 24. Simple Charge Pump + - VCDL V REF Dirty V DD Dirty V DD Fig. 25. (a) Supply Filtering (b) Regulation <ref> [3] </ref> VCDL (a) 17 7.1 DATA RECOVERY The data recovery strategy determines the die area requirements, reliability and power dissipation of a transceiver circuit. Several strategies were discussed in Section 3.1.
Reference: [4] <author> Stanley et al., </author> <title> A Michroarchitectural Performance Evaluation of a 3.2 GB/s Microprocessor Bus, </title> <booktitle> in Proceedings of Micro-26, </booktitle> <year> 1993, </year> <month> pp31-40. </month>
Reference-contexts: The bandwidth gap is growing at 33% per year [3]. Recent trends in both computer architecture and applications are exacerbating the problem. While processor speeds have increased dramatically, DRAM speeds have increased at only 7% per year <ref> [4] </ref>. This has led to architectural techniques designed to reduce or tolerate latency. However, many of these techniques require high peak bandwidth. For example, hardware prefetching [5], stream buffers [6], and software directed prefetch-ing [7] trade increased bandwidth for reduced latency.
Reference: [5] <author> A. Smith, </author> <title> Sequential program prefetching in memory hierarchies, </title> <journal> IEEE Computer, </journal> <volume> vol. 11, no. 12, pp.721, </volume> <month> December </month> <year> 1978. </year>
Reference-contexts: While processor speeds have increased dramatically, DRAM speeds have increased at only 7% per year [4]. This has led to architectural techniques designed to reduce or tolerate latency. However, many of these techniques require high peak bandwidth. For example, hardware prefetching <ref> [5] </ref>, stream buffers [6], and software directed prefetch-ing [7] trade increased bandwidth for reduced latency. Multi-issue implementations and multiprocessors also require very high bandwidth to increase overall throughput. Popular applications are becoming more and more graphics intensive.
Reference: [6] <author> N. Jouppi, </author> <title> Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers, </title> <booktitle> in Proceeding of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pp. 364-373, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: While processor speeds have increased dramatically, DRAM speeds have increased at only 7% per year [4]. This has led to architectural techniques designed to reduce or tolerate latency. However, many of these techniques require high peak bandwidth. For example, hardware prefetching [5], stream buffers <ref> [6] </ref>, and software directed prefetch-ing [7] trade increased bandwidth for reduced latency. Multi-issue implementations and multiprocessors also require very high bandwidth to increase overall throughput. Popular applications are becoming more and more graphics intensive. These applications tend to have very little locality, leading to even higher bandwidth requirements.
Reference: [7] <author> D. Callahan et al., </author> <title> Software Prefetching, </title> <booktitle> in Proceedings of the 4th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pp. 40-52. </pages> <publisher> ACM, </publisher> <year> 1991. </year>
Reference-contexts: While processor speeds have increased dramatically, DRAM speeds have increased at only 7% per year [4]. This has led to architectural techniques designed to reduce or tolerate latency. However, many of these techniques require high peak bandwidth. For example, hardware prefetching [5], stream buffers [6], and software directed prefetch-ing <ref> [7] </ref> trade increased bandwidth for reduced latency. Multi-issue implementations and multiprocessors also require very high bandwidth to increase overall throughput. Popular applications are becoming more and more graphics intensive. These applications tend to have very little locality, leading to even higher bandwidth requirements.
Reference: [8] <author> A. Dehon and T. Knight, </author> <title> Automatic Impedance Control, </title> <booktitle> in ISSCC Digest of Technical Papers, </booktitle> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: Multi-issue implementations and multiprocessors also require very high bandwidth to increase overall throughput. Popular applications are becoming more and more graphics intensive. These applications tend to have very little locality, leading to even higher bandwidth requirements. The digital signalling problem is illustrated in Fig. 1 <ref> [8] </ref>. Two chips must exchange data over a multichip module (MCM) or printed-circuit board (PCB) at a high rate through a finite number of signal channels. The transfer rate is limited by noise in the electrical environment. <p> C B1 Drivers Logic Receiver Logic C B2 L ext R ext R chip L chip L bond L ext L bond R ext R chip L chip L chip R chip R chip L chip Fig. 1. Two chips exchange data over signal pins connected by transmission lines <ref> [8] </ref> 3 2.1 SYSTEM ARCHITECTURE The PUMA system architecture is illustrated in Fig. 2. The limited integration levels of CGaAs force a partitioning of the processor onto several VLSI chips and a small clock generator chip. <p> Controlled Slew Rate Driver 10 age swings are typically rail-to-rail for the system illustrated. The termination can be an on- or off-chip resistor, however, it is desirable to use MOS transistors. Processing variations can be overcome by using the automatic impedance control technique <ref> [8] </ref>. This technique replaces the termination resistor with several parallel MOS transistors. Startup circuits measure the impedance level and calibrate the termination resistance using registers and lookup tables.

Reference: [29] <author> M. Dolle, </author> <title> Dynamic Line-Termination Circuit for Multire-ceiver Nets, </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> Vol. 28, No. 12, </volume> <pages> pp. 1370-1373, </pages> <month> December </month> <year> 1993. </year> <editor> [30]Kim et al., </editor> <title> A 960-Mb/s/pin Interface for Skew-Tolerant Bus Using Low Jitter PLL, </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> Vol. 32, No. 5, </volume> <pages> pp. 691-700, </pages> <month> May </month> <year> 1997. </year> <note> [31]J. </note> <author> Maneatis and M. Horowitz, </author> <title> Precise Delay Generation Using Coupled Oscillators, </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> Vol. 28, No. 12, </volume> <month> December </month> <year> 1993. </year>
Reference-contexts: The second dynamic termination circuit <ref> [29] </ref> uses MOS devices in a latch configuration to terminate the line during transitions. The circuit is shown in Fig. 15. Transistors M1 and M2 act as termination resistors, again implying large devices. The inverter provides feedback to these transistors to control the termination.

References-found: 9

