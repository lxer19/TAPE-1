URL: http://www.icsi.berkeley.edu/ftp/global/pub/techreports/1994/tr-94-023.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/ftp/global/pub/techreports/1994/
Root-URL: http://www.icsi.berkeley.edu
Email: E-mail: oded@wisdom.weizmann.ac.il.  E-mail: rafail@cs.Berkeley.EDU.  E-mail: erez@cs.technion.ac.il.  
Title: Computational Complexity and Knowledge Complexity  
Author: Oded Goldreich Rafail Ostrovsky Erez Petrank 
Note: Supported by grant no. 92-00226 from the United States Israel Binational Science Foundation, Jerusalem, Israel.  Supported by an NSF Postdoctoral Fellowship and ICSI.  
Address: Rehovot, Israel.  Berkeley, CA 94720.  32000, Israel.  
Affiliation: Department of Applied Mathematics and Computer Science, Weizmann Institute of Science,  Computer Science Division, University of California at Berkeley, and International Computer Science Institute,  Computer Science Department, Technion Israel Institute of Technology, Haifa  
Date: June 1994  
Pubnum: TR-94-023  
Abstract: We study the computational complexity of languages which have interactive proofs of logarithmic knowledge complexity. We show that all such languages can be recognized in BPP NP . Prior to this work, for languages with greater-than-zero knowledge complexity (and specifically, even for knowledge complexity 1) only trivial computational complexity bounds (i.e., only recognizability in PSPACE = IP) were known. In the course of our proof, we relate statistical knowledge-complexity with perfect knowledge-complexity; specifically, we show that, for the honest verifier, these hierarchies coincide, up to a logarithmic additive term (i.e., SKC(k()) PKC(k() + log())). fl An extended abstract of this paper is to appear in The Twenty-sixth ACM Symposium on Theory of Computing (STOC 94) to be held in Montreal, Quebec, Canada, May 23-25, 1994. 
Abstract-found: 1
Intro-found: 1
Reference: [AH-87] <author> W. Aiello and J. H -astad. </author> <title> Perfect Zero-Knowledge can be Recognized in Two Rounds. </title> <booktitle> Proceedings of the 28th Annual IEEE Symposium on the Foundations of Computer Science, IEEE (1987). </booktitle>
Reference-contexts: Previous works have provided information only concerning the zero level of these hierarchies. Fortnow has pioneered the attempts to investigate the computational complexity of (perfect/statistical) zero-knowledge [F-89], and was followed by Aiello and Hastad <ref> [AH-87] </ref>. Their results can be summarized by the following theorem that bounds the computational complexity of languages having zero-knowledge proofs. Theorem [F-89, AH-87]: SKC (0) AM co-AM Hence, languages having statistical zero-knowledge must lie in the second level of the polynomial-time hierarchy. <p> Fortnow has pioneered the attempts to investigate the computational complexity of (perfect/statistical) zero-knowledge [F-89], and was followed by Aiello and Hastad [AH-87]. Their results can be summarized by the following theorem that bounds the computational complexity of languages having zero-knowledge proofs. Theorem <ref> [F-89, AH-87] </ref>: SKC (0) AM co-AM Hence, languages having statistical zero-knowledge must lie in the second level of the polynomial-time hierarchy. Needless to say that PKC (k ()) SKC (k ()), for any function k and in particular for k 0. <p> Their procedure, in turn, is a culmination of two sequences of works discussed bellow. The first sequence originates in Fortnow's definition of a simulator-based prover [F-89]. Fortnow [F-89], and consequently Aiello and Hastad <ref> [AH-87] </ref>, used the simulator-based prover in order to infer, by way of contradiction, bounds on the sizes of specific sets. <p> These problems were related by Jerrum et. al. [JVV-86]. Procedures for approximating the size of sets were invented by Sipser [Si-83] and Stockmeyer [St-83], and further improved in <ref> [GS-89, AH-87] </ref>, all using the "hashing paradigm". The same hashing technique, is the basis of the "universal extrapolation" procedures of [ILu-90, ILe-90]. <p> In particular, there is a flaw in the AM-protocol presented in [F-89] for the complement language (see Appendix). However, the paper of Aiello and Hastad provides all the necessary machinery for proving Fortnow's result as well <ref> [AH-87, H-94] </ref>. <p> However, the paper of Aiello and Hastad provides all the necessary machinery for proving Fortnow's result as well [AH-87, H-94]. Needless to say that the basic approach presented by Fortnow (i.e., looking at the "simulator-based prover") is valid and has inspired all subsequent works (e.g., <ref> [AH-87, BMO-90, Ost-91, BP-92, OW-93] </ref>) as well as the current one. 2 Preliminaries Let us state some of the definitions and conventions we use in the paper.
Reference: [BMO-90] <author> M. Bellare, S. Micali and R. Ostrovsky. </author> <title> The (True) Complexity of Statistical Zero-Knowledge. </title> <booktitle> Proceedings of the 22nd Annual ACM Symposium on the Theory of Computing, ACM (1990). </booktitle>
Reference-contexts: Fortnow [F-89], and consequently Aiello and Hastad [AH-87], used the simulator-based prover in order to infer, by way of contradiction, bounds on the sizes of specific sets. A more explicit usage of the simulator-based prover was introduced by Bellare, Micali and Ostrovsky <ref> [BMO-90] </ref>; specifically, they have suggested to use a PSPACE-implementation of the simulator-based prover, instead of using the original prover (of unbounded complexity) witnessing the existence of a zero-knowledge interactive proof system. (Thus, they obtained a bound on the complexity of provers required for zero-knowledge proof systems.) Ostrovsky [Ost-91] suggested to use <p> However, the paper of Aiello and Hastad provides all the necessary machinery for proving Fortnow's result as well [AH-87, H-94]. Needless to say that the basic approach presented by Fortnow (i.e., looking at the "simulator-based prover") is valid and has inspired all subsequent works (e.g., <ref> [AH-87, BMO-90, Ost-91, BP-92, OW-93] </ref>) as well as the current one. 2 Preliminaries Let us state some of the definitions and conventions we use in the paper. <p> Combining this result with the transformation (Theorem 2) of the subsequent section, we get the Main Theorem. Theorem 1 PKC (O (log n)) BPP N P 7 Our proof follows the procedure suggested in [BP-92], which in turn follows the approach of <ref> [F-89, BMO-90, Ost-91] </ref> while introducing a new uniform generation procedure which builds on ideas of [Si-83, St-83, GS-89, JVV-86] (see introduction).
Reference: [BP-92] <author> M. Bellare and E. Petrank. </author> <title> Making Zero-Knowledge Provers Efficient. </title> <booktitle> Proceedings of the 24rd Annual ACM Symposium on the Theory of Computing, ACM (1992) </booktitle>
Reference-contexts: The only attempt to bound the computational complexity of languages having interactive proofs of low knowledge-complexity was done by Bellare and Pe-trank. Yet, their work refers only to languages having interactive proofs that are both of few rounds and of low knowledge complexity <ref> [BP-92] </ref>. Specifically, they showed that if a language L has a r (n)-round interactive-proof of knowledge-complexity O ( log n r (n) ) then the language can be recognized in BPP N P . Our proof of the Main Theorem consists of two parts. <p> Our proof of the Main Theorem consists of two parts. In the first part, we show that the procedure described by Bellare and Petrank <ref> [BP-92] </ref> suffices for recognizing languages having interactive proofs of logarithmic perfect knowledge complexity. To this end, we use a more careful analysis than the one used in [BP-92]. <p> In the first part, we show that the procedure described by Bellare and Petrank <ref> [BP-92] </ref> suffices for recognizing languages having interactive proofs of logarithmic perfect knowledge complexity. To this end, we use a more careful analysis than the one used in [BP-92]. In the second part of our proof we transform interactive proofs of statistical knowledge complexity k (n) into interactive proofs of perfect knowledge complexity k (n) + log n. <p> PKC (k () + log ()) This result may be considered an indication that these two hierarchies may collide. 1 Alas, if one had been willing to assume that all languages in PSPACE have interactive proofs of logarithmically many rounds, an assumption that we consider unreasonable, then the result in <ref> [BP-92] </ref> would have yielded a proof that PSPACE is not contained in SKC (1), provided (again) that PH 6= PSPACE . 2 Techniques Used As stated above, the first part of our proof consists of presenting a more careful analysis of an existing procedure, namely the procedure suggested by Bellare and <p> yielded a proof that PSPACE is not contained in SKC (1), provided (again) that PH 6= PSPACE . 2 Techniques Used As stated above, the first part of our proof consists of presenting a more careful analysis of an existing procedure, namely the procedure suggested by Bellare and Petrank in <ref> [BP-92] </ref>. Their procedure, in turn, is a culmination of two sequences of works discussed bellow. The first sequence originates in Fortnow's definition of a simulator-based prover [F-89]. <p> Bellare and Petrank distilled the decision procedure from the context of one-way functions, showing that the simulator-based prover can be implemented using a perfect universal extrapolator (also known as a "uniform generation" procedure) <ref> [BP-92] </ref>. The error in the implementation is directly related to the deviation of the uniform generation procedure. The second sequence of works deals with the two related problems of approximating the size of sets and uniformly generating elements in them. These problems were related by Jerrum et. al. [JVV-86]. <p> Bellare and Petrank combined the hashing-based approximation methods with the ideas of [JVV-86] to obtain a BPP N P -procedure for uniform generation with exponentially vanishing error probability <ref> [BP-92] </ref>. <p> However, the paper of Aiello and Hastad provides all the necessary machinery for proving Fortnow's result as well [AH-87, H-94]. Needless to say that the basic approach presented by Fortnow (i.e., looking at the "simulator-based prover") is valid and has inspired all subsequent works (e.g., <ref> [AH-87, BMO-90, Ost-91, BP-92, OW-93] </ref>) as well as the current one. 2 Preliminaries Let us state some of the definitions and conventions we use in the paper. <p> case this means that for every c Prob (M (x; !) = c j ! 2 S x ) = Prob ((P; V )(x) = c) where M (x; !) denotes the output of the simulator M on input x and coin tosses sequence !. 3 The analysis of the <ref> [BP-92] </ref> procedure is easier when using the fraction version, whereas the transformation from statistical to perfect is easier when using the oracle version. 6 It is shown in [GP-91] that these two measures are almost equal. <p> Combining this result with the transformation (Theorem 2) of the subsequent section, we get the Main Theorem. Theorem 1 PKC (O (log n)) BPP N P 7 Our proof follows the procedure suggested in <ref> [BP-92] </ref>, which in turn follows the approach of [F-89, BMO-90, Ost-91] while introducing a new uniform generation procedure which builds on ideas of [Si-83, St-83, GS-89, JVV-86] (see introduction). <p> We are going to show that the probability that the interaction (P fl ; V ) is accepting is negligible if x 62 L and greater than a polynomial fraction if x 2 L. Our proof differs from <ref> [BP-92] </ref> in the analysis of the case x 2 L (and thus we get a stronger result although we use the same procedure). This separation between the cases x 62 L and x 2 L can be amplified by sequential repetitions of the protocol (P fl ; V ). <p> So it remains to observe that we can sample the (P fl ; V ) interactions in probabilistic polynomial-time having access to an NP oracle. This observation originates from <ref> [BP-92] </ref> and is justified as follows. Clearly, V 's part of the interaction can be produced in polynomial-time. Also, by the uniform generation procedure of [BP-92] we can implement P fl by a probabilistic polynomial time machine that has access to an NP oracle. <p> This observation originates from <ref> [BP-92] </ref> and is justified as follows. Clearly, V 's part of the interaction can be produced in polynomial-time. Also, by the uniform generation procedure of [BP-92] we can implement P fl by a probabilistic polynomial time machine that has access to an NP oracle. Actually, the implementation may fail with negligible probability, but this does not matter. Thus, it remains only to prove the following lemma. Lemma 3.1 1. <p> If x 2 L then the probability that (P fl ; V ) outputs an accepting conversation is at least 1 2 2 k . 2. If x 62 L then the probability that (P fl ; V ) outputs an accepting conversation is negligible. Remark: In <ref> [BP-92] </ref>, a weaker lemma is proven. Specifically, they show that the probability that (P fl ; V ) output an accepting conversation (on x 2 L) is related to 2 kt , where t is the number of rounds in the protocol.
Reference: [B+ 88] <author> M. Ben-Or, S. Goldwasser, O. Goldreich, J. H -astad, J. Kil-ian, S. Micali and P. Rogaway. </author> <title> Everything Provable is Provable in Zero-Knowledge. </title> <booktitle> Advances in Cryptology | Proceedings of CRYPTO 88, Lecture Notes in Computer Science 403, </booktitle> <publisher> Springer-Verlag (1989). </publisher> <editor> S. Gold-wasser, </editor> <publisher> ed. </publisher>
Reference-contexts: Actually, there are three hierarchies extending the three standard definitions of zero-knowledge; namely perfect, statistical and computational. Let us denote the corresponding hierarchies by PKC (), SKC (), and CKC (). Assuming the existence of one-way functions, the third hierarchy collapses, namely CKC (0) = CKC (poly) = IP <ref> [GMW-86, IY-87, B+ 88] </ref>. Put differently, the zero level of computational knowledge-complexity extends to the maximum possible. Anyhow, in the rest of this paper we will be only interested in the other two hierarchies. Previous works have provided information only concerning the zero level of these hierarchies.
Reference: [BHZ-87] <author> R. Boppana, J. H -astad and S. Zachos. </author> <title> Does coN P Have Short Interactive Proofs". </title> <journal> Information Processing Letters, </journal> <volume> Vol 25 (1987), No. 2, </volume> <pages> pp 127-132. </pages>
Reference-contexts: The first is to try to provide evidence that NP-complete languages cannot be proven within low (say logarithmic or even constant) knowledge complexity. A possible avenue for proving this conjecture is to show that languages having logarithmic knowledge complexity are in co-AM, rather than in BPP N P (see <ref> [BHZ-87] </ref>). The second suggestion is to try to provide indications that there are languages in PSPACE which do not have interactive proofs of linear (rather than logarithmic) knowledge complexity. The reader can easily envision more moderate and more ambitious challenges in this direction.
Reference: [F-89] <author> L. Fortnow. </author> <title> The Complexity of Perfect Zero-Knowledge. Advances in Computing Research (ed. </title> <editor> S. </editor> <volume> Micali) Vol. </volume> <month> 18 </month> <year> (1989). </year>
Reference-contexts: Anyhow, in the rest of this paper we will be only interested in the other two hierarchies. Previous works have provided information only concerning the zero level of these hierarchies. Fortnow has pioneered the attempts to investigate the computational complexity of (perfect/statistical) zero-knowledge <ref> [F-89] </ref>, and was followed by Aiello and Hastad [AH-87]. Their results can be summarized by the following theorem that bounds the computational complexity of languages having zero-knowledge proofs. Theorem [F-89, AH-87]: SKC (0) AM co-AM Hence, languages having statistical zero-knowledge must lie in the second level of the polynomial-time hierarchy. <p> Fortnow has pioneered the attempts to investigate the computational complexity of (perfect/statistical) zero-knowledge [F-89], and was followed by Aiello and Hastad [AH-87]. Their results can be summarized by the following theorem that bounds the computational complexity of languages having zero-knowledge proofs. Theorem <ref> [F-89, AH-87] </ref>: SKC (0) AM co-AM Hence, languages having statistical zero-knowledge must lie in the second level of the polynomial-time hierarchy. Needless to say that PKC (k ()) SKC (k ()), for any function k and in particular for k 0. <p> Their procedure, in turn, is a culmination of two sequences of works discussed bellow. The first sequence originates in Fortnow's definition of a simulator-based prover <ref> [F-89] </ref>. Fortnow [F-89], and consequently Aiello and Hastad [AH-87], used the simulator-based prover in order to infer, by way of contradiction, bounds on the sizes of specific sets. <p> Their procedure, in turn, is a culmination of two sequences of works discussed bellow. The first sequence originates in Fortnow's definition of a simulator-based prover <ref> [F-89] </ref>. Fortnow [F-89], and consequently Aiello and Hastad [AH-87], used the simulator-based prover in order to infer, by way of contradiction, bounds on the sizes of specific sets. <p> Furthermore, by an interactive proof we mean one in which the error probability is negligible (i.e., smaller than any polynomial fraction). A few words of justification appear in Section 2. A remark concerning Fortnow's paper <ref> [F-89] </ref>. In course of this research, we found out that the proof that SKC (0) co-AM as it appears in [F-89] is not correct. In particular, there is a flaw in the AM-protocol presented in [F-89] for the complement language (see Appendix). <p> A few words of justification appear in Section 2. A remark concerning Fortnow's paper <ref> [F-89] </ref>. In course of this research, we found out that the proof that SKC (0) co-AM as it appears in [F-89] is not correct. In particular, there is a flaw in the AM-protocol presented in [F-89] for the complement language (see Appendix). However, the paper of Aiello and Hastad provides all the necessary machinery for proving Fortnow's result as well [AH-87, H-94]. <p> A few words of justification appear in Section 2. A remark concerning Fortnow's paper <ref> [F-89] </ref>. In course of this research, we found out that the proof that SKC (0) co-AM as it appears in [F-89] is not correct. In particular, there is a flaw in the AM-protocol presented in [F-89] for the complement language (see Appendix). However, the paper of Aiello and Hastad provides all the necessary machinery for proving Fortnow's result as well [AH-87, H-94]. <p> ()) = languages having interactive proofs of perfect knowledge complexity k (). * SKC (k ()) = languages having interactive proofs of statistical knowledge complex ity k (). 2.3 The simulation based prover An important ingredient in our proof is the notion of a simulation based prover, introduced by Fortnow <ref> [F-89] </ref>. Consider a simulator M that outputs conversations of an interaction between a prover P and a verifier V . We define a new prover P fl , called the simulation based prover, which selects its messages according to the conditional probabilities induced by the simulation. <p> Combining this result with the transformation (Theorem 2) of the subsequent section, we get the Main Theorem. Theorem 1 PKC (O (log n)) BPP N P 7 Our proof follows the procedure suggested in [BP-92], which in turn follows the approach of <ref> [F-89, BMO-90, Ost-91] </ref> while introducing a new uniform generation procedure which builds on ideas of [Si-83, St-83, GS-89, JVV-86] (see introduction).
Reference: [GMS-87] <author> O. Goldreich, Y. Mansour and M. Sipser. </author> <title> Interactive Proof Systems: Provers that never Fail and Random Selection. </title> <booktitle> Proceedings of the 28th Annual IEEE Symposium on the Foundations of Computer Science, IEEE (1987). </booktitle>
Reference-contexts: Then, given a two-sided interactive proof of some statistical knowledge complexity you could have transformed it to a one-sided error proof of the same knowledge complexity (cf., <ref> [GMS-87] </ref>). Applying the transformation for the one-sided case would have yielded an even better result. 5 Next, we present the definitions of perfect (resp., statistical) knowledge-complexity which we use in the sequel.
Reference: [GMW-86] <author> O. Goldreich, S. Micali, and A. Wigderson, </author> <title> "Proofs that Yield Nothing But their Validity and a Methodology of Cryptographic Protocol Design", </title> <booktitle> Proc. 27th FOCS 86, See also Jour. of ACM. </booktitle> <volume> Vol 38, No 1, </volume> <month> July </month> <year> 1991, </year> <pages> pp. 691-729. </pages>
Reference-contexts: Actually, there are three hierarchies extending the three standard definitions of zero-knowledge; namely perfect, statistical and computational. Let us denote the corresponding hierarchies by PKC (), SKC (), and CKC (). Assuming the existence of one-way functions, the third hierarchy collapses, namely CKC (0) = CKC (poly) = IP <ref> [GMW-86, IY-87, B+ 88] </ref>. Put differently, the zero level of computational knowledge-complexity extends to the maximum possible. Anyhow, in the rest of this paper we will be only interested in the other two hierarchies. Previous works have provided information only concerning the zero level of these hierarchies. <p> The reason being that these (logarithmically many) bits can be guessed with non-negligible probability, which in turn means that any attack due to the "leaked bits" can be simulated with non-negligible probability without them. But why use low knowledge-complexity protocols when one can use zero-knowledge ones (see, <ref> [GMW-86, GMW-87] </ref>)? The reason is that the non-zero-knowledge protocols may be more efficient and/or may require weaker computational assumptions (see, for example, [OVY-91]). Remarks A remark concerning two definitions. Throughout the paper, SKC (k ()) and PKC (k ()) denote the classes of knowledge-complexity with respect to the honest verifier.
Reference: [GMW-87] <author> O. Goldreich, S. Micali, and A. Wigderson, </author> <title> "How to Play any Mental Game or a Completeness Theorems for Protocols of Honest Majority", </title> <type> STOC87. </type>
Reference-contexts: The reason being that these (logarithmically many) bits can be guessed with non-negligible probability, which in turn means that any attack due to the "leaked bits" can be simulated with non-negligible probability without them. But why use low knowledge-complexity protocols when one can use zero-knowledge ones (see, <ref> [GMW-86, GMW-87] </ref>)? The reason is that the non-zero-knowledge protocols may be more efficient and/or may require weaker computational assumptions (see, for example, [OVY-91]). Remarks A remark concerning two definitions. Throughout the paper, SKC (k ()) and PKC (k ()) denote the classes of knowledge-complexity with respect to the honest verifier.
Reference: [GP-91] <author> O. Goldreich and E. Petrank. </author> <title> Quantifying Knowledge Complexity. </title> <booktitle> Proceedings of the 32nd Annual IEEE Symposium on the Foundations of Computer Science, IEEE (1991). </booktitle> <pages> 21 </pages>
Reference-contexts: 1 Introduction The notion of knowledge-complexity was introduced in the seminal paper of Gold-wasser Micali and Rackoff [GMR-85, GMR-89]. Knowledge-complexity (KC) is intended to measure the computational advantage gained by interaction. Satisfactory formulations of knowledge-complexity, for the case that it is not zero, have recently appeared in <ref> [GP-91] </ref>. A natural suggestion, made by Goldwasser, Micali and Rackoff, is to classify languages according to the knowledge-complexity of their interactive-proofs [GMR-89]. We feel that it is worthwhile to give this suggestion a fair try. <p> On the other hand, if we allow polynomial amount of knowledge to be revealed, then every language in IP can be proven. Theorem [LFKN-90, Sh-90]: PKC (poly ()) = IP = PSPACE As indicated in <ref> [GP-91] </ref>, the first equality is a property of an adequate definition (of knowledge complexity) rather than a result. In this paper we study the class of languages that have interactive-proofs with logarithmic knowledge-complexity. <p> Actually, there are two alternative formulations of knowledge-complexity, called the oracle version and the fraction version. These formulations coincide at the zero level and differ by at most an additive constant otherwise <ref> [GP-91] </ref>. For further intuition and motivation see [GP-91]. It will be convenient to use both definitions in this paper 3 . By the oracle formulation, the knowledge-complexity of a protocol (P; V ) is the number of oracle (bit) queries that are needed to simulate the protocol efficiently. <p> Actually, there are two alternative formulations of knowledge-complexity, called the oracle version and the fraction version. These formulations coincide at the zero level and differ by at most an additive constant otherwise <ref> [GP-91] </ref>. For further intuition and motivation see [GP-91]. It will be convenient to use both definitions in this paper 3 . By the oracle formulation, the knowledge-complexity of a protocol (P; V ) is the number of oracle (bit) queries that are needed to simulate the protocol efficiently. <p> (x; !) denotes the output of the simulator M on input x and coin tosses sequence !. 3 The analysis of the [BP-92] procedure is easier when using the fraction version, whereas the transformation from statistical to perfect is easier when using the oracle version. 6 It is shown in <ref> [GP-91] </ref> that these two measures are almost equal. Theorem [GP-91]: The fraction measure and the oracle measure are equal up to an additive constant. <p> on input x and coin tosses sequence !. 3 The analysis of the [BP-92] procedure is easier when using the fraction version, whereas the transformation from statistical to perfect is easier when using the oracle version. 6 It is shown in <ref> [GP-91] </ref> that these two measures are almost equal. Theorem [GP-91]: The fraction measure and the oracle measure are equal up to an additive constant. Since none of our results is sensitive to a difference of an additive constant in the measure, we ignore this difference in the subsequent definition as well as in the statement of our results. <p> Without loss of generality, we may assume that all messages are of length 1. The message-length convention is merely a matter of encoding. Recall that Definition 2.1 only guarantees that the simulator produces output with probability 1 2 . Yet, employing Proposition 3.8 in <ref> [GP-91] </ref>, we get that there exists an oracle machine M , that after asking k (n) + 2 log log n queries, always produces an output so that the output is statistically close to the interaction of (P; V ).
Reference: [GMR-85] <author> S. Goldwasser, S. Micali, and C. Rackoff. </author> <title> The Knowledge Com--plexity of Interactive Proofs. </title> <booktitle> Proceedings of the 17th Annual ACM Symposium on the Theory of Computing, ACM (1985). </booktitle>
Reference-contexts: 1 Introduction The notion of knowledge-complexity was introduced in the seminal paper of Gold-wasser Micali and Rackoff <ref> [GMR-85, GMR-89] </ref>. Knowledge-complexity (KC) is intended to measure the computational advantage gained by interaction. Satisfactory formulations of knowledge-complexity, for the case that it is not zero, have recently appeared in [GP-91].
Reference: [GMR-89] <author> S. Goldwasser, S. Micali, and C. Rackoff. </author> <title> The Knowledge Complexity of Interactive Proofs. </title> <journal> SIAM J. Comput. </journal> <volume> 18 (1), </volume> <month> 186-208 (February </month> <year> 1989). </year>
Reference-contexts: 1 Introduction The notion of knowledge-complexity was introduced in the seminal paper of Gold-wasser Micali and Rackoff <ref> [GMR-85, GMR-89] </ref>. Knowledge-complexity (KC) is intended to measure the computational advantage gained by interaction. Satisfactory formulations of knowledge-complexity, for the case that it is not zero, have recently appeared in [GP-91]. <p> Knowledge-complexity (KC) is intended to measure the computational advantage gained by interaction. Satisfactory formulations of knowledge-complexity, for the case that it is not zero, have recently appeared in [GP-91]. A natural suggestion, made by Goldwasser, Micali and Rackoff, is to classify languages according to the knowledge-complexity of their interactive-proofs <ref> [GMR-89] </ref>. We feel that it is worthwhile to give this suggestion a fair try. The lowest level of the knowledge-complexity hierarchy is the class of languages having interactive proofs of knowledge-complexity zero, better known as zero-knowledge. <p> Throughout this paper we use n to denote the length of x. 2.1 Interactive proofs Let us recall the concept of interactive proofs, presented by <ref> [GMR-89] </ref>. For formal definitions and motivating discussions the reader is referred to [GMR-89]. <p> Throughout this paper we use n to denote the length of x. 2.1 Interactive proofs Let us recall the concept of interactive proofs, presented by <ref> [GMR-89] </ref>. For formal definitions and motivating discussions the reader is referred to [GMR-89].
Reference: [GS-89] <author> S. Goldwasser, and M. Sipser, </author> <title> Private Coins vs. Public Coins in Interactive Proof Systems, </title> <booktitle> Advances in Computing Research (ed. S. Mi-cali), 1989, </booktitle> <volume> Vol. 5, </volume> <pages> pp. 73-90. </pages>
Reference-contexts: These problems were related by Jerrum et. al. [JVV-86]. Procedures for approximating the size of sets were invented by Sipser [Si-83] and Stockmeyer [St-83], and further improved in <ref> [GS-89, AH-87] </ref>, all using the "hashing paradigm". The same hashing technique, is the basis of the "universal extrapolation" procedures of [ILu-90, ILe-90]. <p> Theorem 1 PKC (O (log n)) BPP N P 7 Our proof follows the procedure suggested in [BP-92], which in turn follows the approach of [F-89, BMO-90, Ost-91] while introducing a new uniform generation procedure which builds on ideas of <ref> [Si-83, St-83, GS-89, JVV-86] </ref> (see introduction). Suppose that (P; V ) is an interactive proof of perfect knowledge complexity k () = O (log n) for the languages L, and let M be the simulator guaranteed by the fraction formulation (i.e., Definition 2.2).
Reference: [H-94] <author> J. H -astad. </author> <title> Perfect Zero-Knowledge in AM " co-AM. Unpublished 2-page manuscript explaining the underlying ideas behind [AH-87]. </title> <year> 1994. </year>
Reference-contexts: In particular, there is a flaw in the AM-protocol presented in [F-89] for the complement language (see Appendix). However, the paper of Aiello and Hastad provides all the necessary machinery for proving Fortnow's result as well <ref> [AH-87, H-94] </ref>.
Reference: [ILu-90] <author> R. Impagliazzo and M. Luby, </author> <title> One-Way Functions are Essential for Complexity Based Cryptography, </title> <booktitle> 30th FOCS, </booktitle> <pages> pp. 230-235, </pages> <year> 1990. </year>
Reference-contexts: Furthermore, assuming that one-way functions do not exist, he used "universal extrapolation" procedures of <ref> [ILu-90, ILe-90] </ref> to approximate the behavior of the simulator-based prover. (Thus, assuming that one-way function do not exists, he presented an efficient procedure that decides languages in SKC (0) and inferred that one-way functions are essential to the non-triviality of statistical zero-knowledge). <p> These problems were related by Jerrum et. al. [JVV-86]. Procedures for approximating the size of sets were invented by Sipser [Si-83] and Stockmeyer [St-83], and further improved in [GS-89, AH-87], all using the "hashing paradigm". The same hashing technique, is the basis of the "universal extrapolation" procedures of <ref> [ILu-90, ILe-90] </ref>. However, the output of these procedures deviates from the objective (i.e., uniform distribution on the target set) by a non-negligible amount (i.e., 1=poly (T ) when running for time T ).
Reference: [ILe-90] <author> R. Impagliazzo and L.A. Levin, </author> <title> No Better Ways to Generate Hard NP Instances than Picking Uniformly at Random, </title> <booktitle> 31st FOCS, </booktitle> <pages> pp. 812-821, </pages> <year> 1990. </year>
Reference-contexts: Furthermore, assuming that one-way functions do not exist, he used "universal extrapolation" procedures of <ref> [ILu-90, ILe-90] </ref> to approximate the behavior of the simulator-based prover. (Thus, assuming that one-way function do not exists, he presented an efficient procedure that decides languages in SKC (0) and inferred that one-way functions are essential to the non-triviality of statistical zero-knowledge). <p> These problems were related by Jerrum et. al. [JVV-86]. Procedures for approximating the size of sets were invented by Sipser [Si-83] and Stockmeyer [St-83], and further improved in [GS-89, AH-87], all using the "hashing paradigm". The same hashing technique, is the basis of the "universal extrapolation" procedures of <ref> [ILu-90, ILe-90] </ref>. However, the output of these procedures deviates from the objective (i.e., uniform distribution on the target set) by a non-negligible amount (i.e., 1=poly (T ) when running for time T ).
Reference: [IY-87] <author> R. Impagliazzo and M. Yung. </author> <title> Direct Minimum-Knowledge computations. </title> <booktitle> Advances in Cryptology | Proceedings of CRYPTO 87, Lecture Notes in Computer Science 293, </booktitle> <publisher> Springer-Verlag (1987). </publisher>
Reference-contexts: Actually, there are three hierarchies extending the three standard definitions of zero-knowledge; namely perfect, statistical and computational. Let us denote the corresponding hierarchies by PKC (), SKC (), and CKC (). Assuming the existence of one-way functions, the third hierarchy collapses, namely CKC (0) = CKC (poly) = IP <ref> [GMW-86, IY-87, B+ 88] </ref>. Put differently, the zero level of computational knowledge-complexity extends to the maximum possible. Anyhow, in the rest of this paper we will be only interested in the other two hierarchies. Previous works have provided information only concerning the zero level of these hierarchies.
Reference: [JVV-86] <author> M. Jerrum, L. Valiant and V. Vazirani. </author> <title> Random Generation of Combinatorial Structures from a Uniform Distribution. </title> <booktitle> Theoretical Computer Science 43, </booktitle> <month> 169-188 </month> <year> (1986). </year>
Reference-contexts: The error in the implementation is directly related to the deviation of the uniform generation procedure. The second sequence of works deals with the two related problems of approximating the size of sets and uniformly generating elements in them. These problems were related by Jerrum et. al. <ref> [JVV-86] </ref>. Procedures for approximating the size of sets were invented by Sipser [Si-83] and Stockmeyer [St-83], and further improved in [GS-89, AH-87], all using the "hashing paradigm". The same hashing technique, is the basis of the "universal extrapolation" procedures of [ILu-90, ILe-90]. <p> On the other hand, Jerrum et. al. have also pointed out that (perfect) uni form generation can be done by a BPP P 2 -procedure <ref> [JVV-86] </ref>. Bellare and Petrank combined the hashing-based approximation methods with the ideas of [JVV-86] to obtain a BPP N P -procedure for uniform generation with exponentially vanishing error probability [BP-92]. <p> On the other hand, Jerrum et. al. have also pointed out that (perfect) uni form generation can be done by a BPP P 2 -procedure <ref> [JVV-86] </ref>. Bellare and Petrank combined the hashing-based approximation methods with the ideas of [JVV-86] to obtain a BPP N P -procedure for uniform generation with exponentially vanishing error probability [BP-92]. <p> Theorem 1 PKC (O (log n)) BPP N P 7 Our proof follows the procedure suggested in [BP-92], which in turn follows the approach of [F-89, BMO-90, Ost-91] while introducing a new uniform generation procedure which builds on ideas of <ref> [Si-83, St-83, GS-89, JVV-86] </ref> (see introduction). Suppose that (P; V ) is an interactive proof of perfect knowledge complexity k () = O (log n) for the languages L, and let M be the simulator guaranteed by the fraction formulation (i.e., Definition 2.2).
Reference: [LFKN-90] <author> C. Lund, L. Fortnow, H. Karloff and N. Nisan. </author> <title> Algebraic Methods for Interactive Proof Systems. </title> <booktitle> Proceedings of the 31st Annual IEEE Symposium on the Foundations of Computer Science, IEEE (1990). </booktitle>
Reference-contexts: Needless to say that PKC (k ()) SKC (k ()), for any function k and in particular for k 0. On the other hand, if we allow polynomial amount of knowledge to be revealed, then every language in IP can be proven. Theorem <ref> [LFKN-90, Sh-90] </ref>: PKC (poly ()) = IP = PSPACE As indicated in [GP-91], the first equality is a property of an adequate definition (of knowledge complexity) rather than a result. In this paper we study the class of languages that have interactive-proofs with logarithmic knowledge-complexity.
Reference: [Ost-91] <author> R. Ostrovsky. </author> <title> One-Way Functions, Hard on Average Problems, and Statistical Zero-Knowledge Proofs. </title> <booktitle> Proceedings of Structures In Complexity Theory 6th Annual Conference IEEE (1991). </booktitle>
Reference-contexts: Micali and Ostrovsky [BMO-90]; specifically, they have suggested to use a PSPACE-implementation of the simulator-based prover, instead of using the original prover (of unbounded complexity) witnessing the existence of a zero-knowledge interactive proof system. (Thus, they obtained a bound on the complexity of provers required for zero-knowledge proof systems.) Ostrovsky <ref> [Ost-91] </ref> suggested to use an implementation of the interaction between the verifier and the simulation-based prover as a procedure for deciding the language. <p> However, the paper of Aiello and Hastad provides all the necessary machinery for proving Fortnow's result as well [AH-87, H-94]. Needless to say that the basic approach presented by Fortnow (i.e., looking at the "simulator-based prover") is valid and has inspired all subsequent works (e.g., <ref> [AH-87, BMO-90, Ost-91, BP-92, OW-93] </ref>) as well as the current one. 2 Preliminaries Let us state some of the definitions and conventions we use in the paper. <p> Combining this result with the transformation (Theorem 2) of the subsequent section, we get the Main Theorem. Theorem 1 PKC (O (log n)) BPP N P 7 Our proof follows the procedure suggested in [BP-92], which in turn follows the approach of <ref> [F-89, BMO-90, Ost-91] </ref> while introducing a new uniform generation procedure which builds on ideas of [Si-83, St-83, GS-89, JVV-86] (see introduction).
Reference: [OW-93] <author> R. Ostrovsky and A. Wigderson. </author> <title> One-Way Functions are Essential For Non-Trivial Zero-Knowledge, </title> <booktitle> Proc. 2nd Israeli Symp. on Theory of Computing and Systems, </booktitle> <year> 1993. </year>
Reference-contexts: However, the paper of Aiello and Hastad provides all the necessary machinery for proving Fortnow's result as well [AH-87, H-94]. Needless to say that the basic approach presented by Fortnow (i.e., looking at the "simulator-based prover") is valid and has inspired all subsequent works (e.g., <ref> [AH-87, BMO-90, Ost-91, BP-92, OW-93] </ref>) as well as the current one. 2 Preliminaries Let us state some of the definitions and conventions we use in the paper.
Reference: [OVY-91] <author> R. Ostrovsky, R. Venkatesan and M. Yung. </author> <title> Fair Games Against an All-Powerful Adversary. </title> <booktitle> AMS DIMACS Series in Discrete Mathematics and Theoretical Computer Science. </booktitle> <volume> Vol 13. </volume> <publisher> (Jin-Yi Cai ed.) </publisher> <pages> pp. 155-169. </pages>
Reference-contexts: But why use low knowledge-complexity protocols when one can use zero-knowledge ones (see, [GMW-86, GMW-87])? The reason is that the non-zero-knowledge protocols may be more efficient and/or may require weaker computational assumptions (see, for example, <ref> [OVY-91] </ref>). Remarks A remark concerning two definitions. Throughout the paper, SKC (k ()) and PKC (k ()) denote the classes of knowledge-complexity with respect to the honest verifier. Note that the Main Theorem is only strengthen by this, whereas the transformation (mentioned above) is indeed weaker.
Reference: [Sh-90] <author> A. Shamir. IP=PSPACE. </author> <booktitle> Proc. 22nd ACM Symp. on Theory of Com--puting, </booktitle> <pages> pages 11-15, </pages> <year> 1990. </year>
Reference-contexts: Needless to say that PKC (k ()) SKC (k ()), for any function k and in particular for k 0. On the other hand, if we allow polynomial amount of knowledge to be revealed, then every language in IP can be proven. Theorem <ref> [LFKN-90, Sh-90] </ref>: PKC (poly ()) = IP = PSPACE As indicated in [GP-91], the first equality is a property of an adequate definition (of knowledge complexity) rather than a result. In this paper we study the class of languages that have interactive-proofs with logarithmic knowledge-complexity.
Reference: [Si-83] <author> M. Sipser. </author> <title> A Complexity Theoretic Approach to Randomness. </title> <booktitle> Proceedings of the 15th Annual ACM Symposium on the Theory of Computing, ACM (1983). </booktitle>
Reference-contexts: The second sequence of works deals with the two related problems of approximating the size of sets and uniformly generating elements in them. These problems were related by Jerrum et. al. [JVV-86]. Procedures for approximating the size of sets were invented by Sipser <ref> [Si-83] </ref> and Stockmeyer [St-83], and further improved in [GS-89, AH-87], all using the "hashing paradigm". The same hashing technique, is the basis of the "universal extrapolation" procedures of [ILu-90, ILe-90]. <p> Theorem 1 PKC (O (log n)) BPP N P 7 Our proof follows the procedure suggested in [BP-92], which in turn follows the approach of [F-89, BMO-90, Ost-91] while introducing a new uniform generation procedure which builds on ideas of <ref> [Si-83, St-83, GS-89, JVV-86] </ref> (see introduction). Suppose that (P; V ) is an interactive proof of perfect knowledge complexity k () = O (log n) for the languages L, and let M be the simulator guaranteed by the fraction formulation (i.e., Definition 2.2).
Reference: [St-83] <author> L. Stockmeyer. </author> <title> The Complexity of Approximate Counting. </title> <booktitle> Proceedings of the 15th Annual ACM Symposium on the Theory of Computing, ACM (1983). </booktitle> <pages> 23 </pages>
Reference-contexts: The second sequence of works deals with the two related problems of approximating the size of sets and uniformly generating elements in them. These problems were related by Jerrum et. al. [JVV-86]. Procedures for approximating the size of sets were invented by Sipser [Si-83] and Stockmeyer <ref> [St-83] </ref>, and further improved in [GS-89, AH-87], all using the "hashing paradigm". The same hashing technique, is the basis of the "universal extrapolation" procedures of [ILu-90, ILe-90]. <p> Theorem 1 PKC (O (log n)) BPP N P 7 Our proof follows the procedure suggested in [BP-92], which in turn follows the approach of [F-89, BMO-90, Ost-91] while introducing a new uniform generation procedure which builds on ideas of <ref> [Si-83, St-83, GS-89, JVV-86] </ref> (see introduction). Suppose that (P; V ) is an interactive proof of perfect knowledge complexity k () = O (log n) for the languages L, and let M be the simulator guaranteed by the fraction formulation (i.e., Definition 2.2).
References-found: 25

