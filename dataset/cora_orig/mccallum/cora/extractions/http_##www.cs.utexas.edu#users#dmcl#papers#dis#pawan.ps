URL: http://www.cs.utexas.edu/users/dmcl/papers/dis/pawan.ps
Refering-URL: http://www.cs.utexas.edu/users/dmcl/papers.html
Root-URL: http://www.cs.utexas.edu
Title: by  
Author: Pawan Goyal 
Date: 1997  
Note: Copyright  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> S. Baruah, G. Koren, B. Mishra, A. Raghunathan, L. Rosier, and D. Shasha. </author> <title> On-line Scheduling in the Presence of Overload. </title> <booktitle> In Proceeding of Foundations of Computer Science, </booktitle> <pages> pages 100110, </pages> <year> 1991. </year>
Reference-contexts: There are two main limitations of the Virtual Clock scheduling algorithm: Unfairness: Consider the previous example. Since the server capacity is 6pkts=s, the first 6 packets of flow 1 will be serviced by time 1. Now, consider the time interval <ref> [1; 2] </ref>. Since the priority of first 6 packets of flow 2 is at most the priority of the 7 th packet of flow 1, only flow 2 will be serviced in [1; 2]. Consequently, flow 1 will be unfairly penalized in the interval [1; 2] for using idle server resources <p> Now, consider the time interval <ref> [1; 2] </ref>. Since the priority of first 6 packets of flow 2 is at most the priority of the 7 th packet of flow 1, only flow 2 will be serviced in [1; 2]. Consequently, flow 1 will be unfairly penalized in the interval [1; 2] for using idle server resources in the interval [0; 1]. To address this limitation, fair algorithms have been designed [4, 12, 42, 22, 52]. <p> Now, consider the time interval <ref> [1; 2] </ref>. Since the priority of first 6 packets of flow 2 is at most the priority of the 7 th packet of flow 1, only flow 2 will be serviced in [1; 2]. Consequently, flow 1 will be unfairly penalized in the interval [1; 2] for using idle server resources in the interval [0; 1]. To address this limitation, fair algorithms have been designed [4, 12, 42, 22, 52]. Fair algorithms ensure that in any time interval in which two flows are backlogged, they receive service in proportion to their reserved rates. <p> Consequently, flow 1 will be unfairly penalized in the interval [1; 2] for using idle server resources in the interval <ref> [0; 1] </ref>. To address this limitation, fair algorithms have been designed [4, 12, 42, 22, 52]. Fair algorithms ensure that in any time interval in which two flows are backlogged, they receive service in proportion to their reserved rates. <p> Fair algorithms ensure that in any time interval in which two flows are backlogged, they receive service in proportion to their reserved rates. Hence, in the example scenario a fair algorithm will serve equal number of packets of flows 1 and 2 in the interval <ref> [1; 2] </ref>. Several fair scheduling algorithms such as Weighted Fair Queuing (WFQ) [12] (also known as Packet-by-packet Generalized Processor Sharing [42]), Self Clocked Fair Queuing (SCFQ) [22], and Frame-based Fair Queuing (FFQ) [52] have been designed in the literature. <p> We conduct 6 experiments and generate 100; 000 lists in each experiment. The ranges for all the factors other than delay are kept same in all the experiments. The ranges that we choose are: [b min ; b max ] = <ref> [1; 20] </ref>, [l min ; l max ] = [512; 8196] bits, [r min ; r max ] = [32; 2056] Kb/s, and [k min ; k max ] = [3; 15]. <p> This is desirable as hard real-time service may use a scheduling algorithm that performs well when there is no overbooking; soft real-time services may prefer to use a scheduling algorithm that provides QoS guarantees and/or minimizes deadline violations in presence of overbooking <ref> [1] </ref>; and best effort services may use a fair scheduler for throughput-intensive flow-controlled data applications. Thus, hierarchical link bandwidth allocation is a desirable mechanism for managing heterogeneity in services and protocols and a packet scheduling algorithm should enable it. * It should support link-sharing service. <p> Example 4.3 Let a server serve packets at a constant rate of K + 1pkt=s in <ref> [0; 1] </ref> and then at the constant rate of 2pkt=s. Thus, C is 2 pkt/s. Let the server serve K + 2 flows and let each flow be assigned a weight of 1pkt=s. <p> Thus, F (p 1 2 + 1. Since the first packet of flows 1::K + 1 are eligible at time 0 and WF 2 Q+ schedules packets in the increasing order of finish tags, first packet of flows 1::K + 1 will be served in the time interval <ref> [0; 1] </ref>. For ease of exposition of the later part of the schedule, let q = d K+1 2 e. Then, since S (p q K+1 ) = q 1 and v (1) &gt; q 1, packets p 2 K+1 ; ::p K+1 are eligible for scheduling at time 1. <p> Furthermore, since F (p q K+2 ), in the interval [1; 1 + q1 q 1 packets of flow K + 1 will be scheduled. Thus in the interval <ref> [1; 1 + q1 2 ] </ref> even though flows K + 1 and K + 2 are backlogged, whereas q 1 packets of flow K + 1 are served, no packet of flow K + 2 is served.
Reference: [2] <author> S. K. Baruah, J. E. Gehrke, and C. G. Plaxton. </author> <title> Fair On-Line Scheduling of a Dynamic Set of Tasks on a SingleResource. </title> <type> Technical Report TR-96-03, </type> <institution> Department of Computer Sciences, The University of Texas at Austin, </institution> <month> February </month> <year> 1996. </year>
Reference-contexts: There are two main limitations of the Virtual Clock scheduling algorithm: Unfairness: Consider the previous example. Since the server capacity is 6pkts=s, the first 6 packets of flow 1 will be serviced by time 1. Now, consider the time interval <ref> [1; 2] </ref>. Since the priority of first 6 packets of flow 2 is at most the priority of the 7 th packet of flow 1, only flow 2 will be serviced in [1; 2]. Consequently, flow 1 will be unfairly penalized in the interval [1; 2] for using idle server resources <p> Now, consider the time interval <ref> [1; 2] </ref>. Since the priority of first 6 packets of flow 2 is at most the priority of the 7 th packet of flow 1, only flow 2 will be serviced in [1; 2]. Consequently, flow 1 will be unfairly penalized in the interval [1; 2] for using idle server resources in the interval [0; 1]. To address this limitation, fair algorithms have been designed [4, 12, 42, 22, 52]. <p> Now, consider the time interval <ref> [1; 2] </ref>. Since the priority of first 6 packets of flow 2 is at most the priority of the 7 th packet of flow 1, only flow 2 will be serviced in [1; 2]. Consequently, flow 1 will be unfairly penalized in the interval [1; 2] for using idle server resources in the interval [0; 1]. To address this limitation, fair algorithms have been designed [4, 12, 42, 22, 52]. Fair algorithms ensure that in any time interval in which two flows are backlogged, they receive service in proportion to their reserved rates. <p> Fair algorithms ensure that in any time interval in which two flows are backlogged, they receive service in proportion to their reserved rates. Hence, in the example scenario a fair algorithm will serve equal number of packets of flows 1 and 2 in the interval <ref> [1; 2] </ref>. Several fair scheduling algorithms such as Weighted Fair Queuing (WFQ) [12] (also known as Packet-by-packet Generalized Processor Sharing [42]), Self Clocked Fair Queuing (SCFQ) [22], and Frame-based Fair Queuing (FFQ) [52] have been designed in the literature. <p> Hence, in the worst-case, O (Q) computation may have to be performed in a single packet transmission time. This worst-case complexity can be reduced to O (logQ) by implementing the rate controllers and the GSQ and ASQ scheduling algorithms using a single augmented binary search tree <ref> [2, 7, 39] </ref>. We illustrate this implementation using an augmented red-black tree which is a balanced binary search tree [7]. To implement FA using a red-black tree, we assume that the GSQ scheduling algorithm assigns a priority value to each packet and schedules packets in increasing order of priority.
Reference: [3] <author> J.C.R. Bennett and H. Zhang. </author> <title> Hierarchical Packet Fair Queuing Algorithms. </title> <booktitle> In Proceedings of SIGCOMM'96, </booktitle> <pages> pages 143156, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: The ranges that we choose are: [b min ; b max ] = [1; 20], [l min ; l max ] = [512; 8196] bits, [r min ; r max ] = [32; 2056] Kb/s, and [k min ; k max ] = <ref> [3; 15] </ref>. The six different ranges that we choose for delay are: [25; 200] ms, [100; 200] ms, [100; 300] ms, [100; 400] ms, [100; 500] ms, and [100; 600] ms. Figures 3.12 (a) and 3.12 (b) plot the metrics U r and U g for these experiments, respectively. <p> WF 2 Q+ has been recently, independent of our work, proposed to reduce the implementation complexity of WF 2 Q while retaining several of its properties (a similar, but not identical, algorithm termed Starting Potential based Fair Queuing was proposed in [51]) <ref> [3] </ref>. It defines start tag of packet p j f to be the finish tag of packet p j1 j j1 f ), if flow f is backlogged on arrival of p j f ; otherwise, S (p j f ) = maxfv (A (p j j1 f )g. <p> WF 2 Q+ , like WF 2 Q , schedules eligible packets in increasing order of finish tags. Though worst-case fairness of WF 2 Q+ has been derived, its fairness measure has not been derived in 3 <ref> [3] </ref>. To ensure that properties of WF 2 Q+ hold over variable rate servers, it has been proposed in [3] that reference time, instead of real time, should be used in virtual time computation. <p> Though worst-case fairness of WF 2 Q+ has been derived, its fairness measure has not been derived in 3 <ref> [3] </ref>. To ensure that properties of WF 2 Q+ hold over variable rate servers, it has been proposed in [3] that reference time, instead of real time, should be used in virtual time computation. <p> Given no a priori information regarding variation in server capacity, it appears that determining W (0; t) will require counting the number of bits that have been transmitted by the server in the interval [0; t]; this computation can be expensive (the simple implementation presented in <ref> [3] </ref> is inconsistent with its definition). Furthermore, WF 2 Q+ has been studied under the assumption that P n2Q n C where C is the minimum capacity of a server. <p> P n2Q i C may be ensured either by dynamically changing the weight assignments of flows or by performing admission control. An algorithm for dynamically changing the weights or an evaluation of its effects on the fairness properties have not been presented in <ref> [3] </ref>. On the other hand, it may not be possible to perform admission control for some flow types (for example, best-effort flows). Furthermore, it may not be feasible to employ admission control when minimum server capacity is zero. <p> ; t 2 ) r f (t 2 t 1 ) r f n2Q l max C f 1 Be ff P n r f ffi (C) r f l max ! The throughput guarantee established in Theorem 5.2 is the same as Bit Worst-case Fairness Index property defined in <ref> [3] </ref>. It can be shown that for constant rate servers, when similar admission control procedure is used, the throughput guarantee of WFQ and SCFQ is similar to that of SFQ. 5.4 Deadline Guarantee SFQ algorithm, as defined so far, only allocates constant rate to the packets of a flow. <p> delay, it may be desirable to employ: * Scheduling algorithms that allocate only rate and have delay guarantee similar to Weighted Fair Queuing (WFQ): Several fair algorithms that have delay guarantee similar to WFQ are known (for example, WFQ [12, 42], FFQ [52], WF 2 Q [4], WF 2 Q+ <ref> [3] </ref>, Leap Forward Virtual Clock [53], etc.). As demonstrated in Chapter 4, most of these algorithms are either unfair over variable rate servers or require the number of bits transmitted to be counted to achieve fairness over variable rate servers. <p> Furthermore, this analysis is tighter than the analysis presented in <ref> [3] </ref>. To observe this, consider a tree with three classes; two leaf classes and a root class. Let the rate of leaf classes 1 and 2 be r 1 and r 2 , respectively, and let each of them contain 2 flows with equal weights. <p> Let both the leaf classes be scheduled by SFQ and the length of all packets be l. Then, it can be shown that the best bound on delay of packet p j f for flow f in leaf class 1 using the analysis in <ref> [3] </ref> is: EAT (p f ; 2 l + C 2l (7.5) In contrast using our analysis, we get: EAT (p f ; 2 2l ) + r 1 Clearly, (7.6) is smaller than (7.5).
Reference: [4] <author> J.C.R. Bennett and H. Zhang. </author> <title> W F 2 Q: Worst-case Fair Weighted Fair Queuing. </title> <booktitle> In Proceedings of INFOCOM'96, </booktitle> <pages> pages 120127, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: Consequently, flow 1 will be unfairly penalized in the interval [1; 2] for using idle server resources in the interval [0; 1]. To address this limitation, fair algorithms have been designed <ref> [4, 12, 42, 22, 52] </ref>. Fair algorithms ensure that in any time interval in which two flows are backlogged, they receive service in proportion to their reserved rates. <p> For example, since Frame-based Fair Queuing [52] and Worst-case Fair Weighted Fair Queuing <ref> [4] </ref> also guarantee that, regardless of behaviour of other flows in the network, the bound on departure time of a packet is the same as in WFQ, they also belong to GR. <p> It can be shown that fair algorithms such as WFQ and SCFQ provide such a guarantee (the fi j+1;i for WFQ can be derived using a modification of the analysis presented in <ref> [4] </ref>). Now consider the previous example with a fair scheduling algorithm. <p> It only guarantees that the worst-case delay of a packet that may be incurred when all the flows are continuously backlogged is the same as in WFQ. 104 Worst-case-fair Fair Queuing (WF 2 Q ), proposed in <ref> [4] </ref>, was designed to improve WFQ's emulation of hypothetical bit-by-bit round robbin server. <p> It has been shown that WF 2 Q emulates the hypothetical server well and has a H (f; m) value of ( l max f l max m ) <ref> [4] </ref>. However, since it utilizes v (t) as defined in (4.1), it is computationally inefficient and unfair over variable rate servers. <p> Hence, in Theorem 5.7, p k f = p f and the corollary follows. 130 The property of SFQ established in Theorem 5.6 is similar to the worst-case fairness property of an algorithm that was proposed in <ref> [4] </ref>. <p> pre-specified bounds on packet delay, it may be desirable to employ: * Scheduling algorithms that allocate only rate and have delay guarantee similar to Weighted Fair Queuing (WFQ): Several fair algorithms that have delay guarantee similar to WFQ are known (for example, WFQ [12, 42], FFQ [52], WF 2 Q <ref> [4] </ref>, WF 2 Q+ [3], Leap Forward Virtual Clock [53], etc.). As demonstrated in Chapter 4, most of these algorithms are either unfair over variable rate servers or require the number of bits transmitted to be counted to achieve fairness over variable rate servers. <p> f at time t (including the length of the packet arriving at time t), C is the capacity of the server, and c f is a constant, referred to as the Normalized worst-case fairness index for flow f , independent of the queues of the other flows at the server <ref> [4] </ref>. Define Normalized worst-case fairness index for the algorithm, denoted by c, as c = max n2Q fc n g where Q is the set of flows served by a server. Then, an algorithm that has smaller c value is considered to be a better emulation of the GPS server.
Reference: [5] <author> R. Brown. </author> <title> Calendar Queues: A Fast O(1) Priority Queue Implementation for the Simulation Event Set Problem. </title> <journal> Communications of the ACM, </journal> <volume> 31(10):12201227, </volume> <month> October </month> <year> 1988. </year>
Reference-contexts: Since * is non-zero, the rate controllers for all the flows can be implemented by a single calendar queue with the clock tick value of 147 * <ref> [5] </ref>. The per packet complexity of calendar queue, and hence rate controller, is O (1).
Reference: [6] <author> D.D. Clark, S. Shenker, and L. Zhang. </author> <title> Supporting Real-Time Applications in an Integrated Services Packet Network. </title> <booktitle> In Proceedings of ACM SIGCOMM, </booktitle> <pages> pages 1426, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Isolation of flows enables a network to provide stronger guarantees and is highly desirable, especially in large heterogeneous networks where sources may be malicious <ref> [6, 12, 36, 45] </ref>. Thus, GR class has desirable properties. In the following subsections, we show that many of the work conserving as well as non-work conserving scheduling algorithms that either allocate only rate or separate rate and delay allocation belong to GR.
Reference: [7] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge MA, </address> <year> 1990. </year>
Reference-contexts: Hence, if there are Q flows at the server, all the priority queue operations can be performed in time O (logQ) <ref> [7] </ref>. Thus, per packet complexity of SFQ is O (logQ). 1 Observe that server virtual time changes only when a packet finishes service. <p> Hence, in the worst-case, O (Q) computation may have to be performed in a single packet transmission time. This worst-case complexity can be reduced to O (logQ) by implementing the rate controllers and the GSQ and ASQ scheduling algorithms using a single augmented binary search tree <ref> [2, 7, 39] </ref>. We illustrate this implementation using an augmented red-black tree which is a balanced binary search tree [7]. To implement FA using a red-black tree, we assume that the GSQ scheduling algorithm assigns a priority value to each packet and schedules packets in increasing order of priority. <p> This worst-case complexity can be reduced to O (logQ) by implementing the rate controllers and the GSQ and ASQ scheduling algorithms using a single augmented binary search tree [2, 7, 39]. We illustrate this implementation using an augmented red-black tree which is a balanced binary search tree <ref> [7] </ref>. To implement FA using a red-black tree, we assume that the GSQ scheduling algorithm assigns a priority value to each packet and schedules packets in increasing order of priority. <p> Let all backlogged flows be inserted in a red-black tree with eligibility time as the search key. Operations such as deletion/insertion of a node and finding the node (flow) with the minimum eligibility time value can be performed in time O (logQ) <ref> [7] </ref>. In FA at time t, the packet that has the smallest gsq priority value among the set of packets that have eligibility time at most t is scheduled. If such a packet does not exist, then the packet with the minimum asq priority is scheduled. <p> To determine the complexity of the algorithm, observe that the while loop in the algorithm is executed at most N times, where N is the depth of the tree. Since N = O (logQ) for a red-black tree <ref> [7] </ref>, we conclude that the complexity of the algorithm is O (logQ). The additional fields in the red-black tree may increase the complexity of the insertion and deletion operations. <p> The additional fields in the red-black tree may increase the complexity of the insertion and deletion operations. However, since these fields for a node can be computed using only the fields of the node and its immediate children, from Theorem 15.1 of <ref> [7] </ref> we know that the complexity of the insertion/deletion operations continues to remain O (logQ). <p> The priority queue is maintained as a binary heap using start tag of the packets as the key. We assume the number of backlogged flows at a server is bounded and implement the binary heap using an array <ref> [7] </ref>. The fields of a class that are maintained for its role as a flow are weight and finish tag. These fields have the same semantics as in the case of a flow. Additionally, a class has a list of its children nodes and a reference to its parent node.
Reference: [8] <author> R.L. Cruz. </author> <title> Service Burstiness and Dynamic Burstiness Measures: A Framework. Journal of High Speed Networks, </title> <address> 2:105127, </address> <year> 1992. </year> <month> 202 </month>
Reference-contexts: To derive the delay guarantee of a network of servers, we will first relate the guaranteed rate clock value of a packet at two adjacent servers. A similar approach of analyzing two adjacent servers to analyze end-to-end behaviour of a network of servers has been used in <ref> [8, 42] </ref>. <p> A RCSD scheduling algorithm employs a rate controller (also referred to as a shaper) for each flow (see Figure 6.1). A packet 1 The class of Fair Airport scheduling algorithms derives its name from the class of Airport scheduling algorithms presented in <ref> [8] </ref>. 142 on arrival joins the rate controller for its flow. The rate controller delays packets to ensure that the output traffic from the flow conforms to specified constraints. Once a packet passes through the rate controller, it joins a queue that we refer to as Guaranteed Service Queue (GSQ) [8]. <p> <ref> [8] </ref>. 142 on arrival joins the rate controller for its flow. The rate controller delays packets to ensure that the output traffic from the flow conforms to specified constraints. Once a packet passes through the rate controller, it joins a queue that we refer to as Guaranteed Service Queue (GSQ) [8]. Packets are serviced from GSQ using a work conserving GSQ scheduling algorithm. Observe that the rate controller limits the service received by a flow from the GSQ in any time interval. <p> Hence, the challenge is to make the algorithm work conserving while ensuring that it remains fair. RCSD can be made work conserving by introducing an Auxiliary Service Queue (ASQ) (this approach was first introduced in <ref> [8] </ref> and later employed in [19]). In such a case, packets on arrival not only join a rate controller, but also ASQ. When there are no packets in the GSQ, packets are scheduled from the ASQ. We assume that the packets of a flow are scheduled from ASQ in sequence.
Reference: [9] <author> R.L. Cruz. </author> <title> A Calculus for Network Delay, Part I : Network Elements in Isolation. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 37:114131, </volume> <month> Jan </month> <year> 1991. </year>
Reference-contexts: The work conserving algorithms can further be classified as either being fair or unfair. Table 1.1 summarizes this classification. To provide QoS guarantees to sources, several source traffic specifications also have been proposed. Examples include leaky bucket <ref> [9, 42] </ref>, Flow Specification [55], average and peak rate specification [14], Deterministic Bounding Interval Dependent model [35], and Exponentially Bounded Burstiness [56]. The QoS guarantees of a single server for different source traffic specifications and scheduling algorithms have been analyzed in the literature [9, 42]. <p> Examples include leaky bucket <ref> [9, 42] </ref>, Flow Specification [55], average and peak rate specification [14], Deterministic Bounding Interval Dependent model [35], and Exponentially Bounded Burstiness [56]. The QoS guarantees of a single server for different source traffic specifications and scheduling algorithms have been analyzed in the literature [9, 42]. The QoS guarantees provided by a single server have been extended to a network of servers [9, 10, 36, 42, 57]. A survey of single server and multiple server analysis techniques can be found in [58]. <p> The QoS guarantees of a single server for different source traffic specifications and scheduling algorithms have been analyzed in the literature [9, 42]. The QoS guarantees provided by a single server have been extended to a network of servers <ref> [9, 10, 36, 42, 57] </ref>. A survey of single server and multiple server analysis techniques can be found in [58]. There are two main limitations of the existing work on packet scheduling algorithms: * The scheduling algorithms have been analyzed only for a restricted set of source traffic characterizations. <p> Furthermore, most of them have been analyzed assuming that all the flows conform to their declared specifications. Finally, the analyses of a network of servers assumes that the same scheduling algorithm is employed at each of the servers <ref> [9, 10, 36, 42, 57] </ref>. In an integrated services network, sources have widely different characteristics and may not conform to their advertised specifications. Furthermore, since the 10 network may be part of several autonomous administrative domains, different scheduling algorithms may be employed at different servers.
Reference: [10] <author> R.L. Cruz. </author> <title> A Calculus for Network Delay, Part II : Network Analysis. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 37:132141, </volume> <month> Jan </month> <year> 1991. </year>
Reference-contexts: The QoS guarantees of a single server for different source traffic specifications and scheduling algorithms have been analyzed in the literature [9, 42]. The QoS guarantees provided by a single server have been extended to a network of servers <ref> [9, 10, 36, 42, 57] </ref>. A survey of single server and multiple server analysis techniques can be found in [58]. There are two main limitations of the existing work on packet scheduling algorithms: * The scheduling algorithms have been analyzed only for a restricted set of source traffic characterizations. <p> Furthermore, most of them have been analyzed assuming that all the flows conform to their declared specifications. Finally, the analyses of a network of servers assumes that the same scheduling algorithm is employed at each of the servers <ref> [9, 10, 36, 42, 57] </ref>. In an integrated services network, sources have widely different characteristics and may not conform to their advertised specifications. Furthermore, since the 10 network may be part of several autonomous administrative domains, different scheduling algorithms may be employed at different servers.
Reference: [11] <author> J. Davin and A. Heybey. </author> <title> A Simulation Study of Fair Queueing and Policy Enforcement. </title> <journal> Computer Communication Review, </journal> <volume> 20(5):2329, </volume> <month> October </month> <year> 1990. </year>
Reference-contexts: Self Clocked Fair Queuing The Self Clocked Fair Queuing scheme, originally proposed in <ref> [11] </ref> and later analyzed in [22], was designed to facilitate the implementation of a fair queuing scheme in broadband networks. We define a generalized SCFQ algorithm which can allocate variable rate to packets of a flow analogous to SCFQ as follows: 1. <p> Though FQS has advantages for processor scheduling, it is not known to have any advantage over WFQ for scheduling packets in a network. Moreover, since it utilizes v (t) as defined in (4.1), it has disadvantages similar to that of WFQ. Self Clocked Fair Queuing (SCFQ), originally proposed in <ref> [11] </ref> and later analyzed in [22], was designed to reduce the computational complexity of fair scheduling algorithms like WFQ. SCFQ also schedules packets in the increasing order of finish tags.
Reference: [12] <author> A. Demers, S. Keshav, and S. Shenker. </author> <title> Analysis and Simulation of a Fair Queueing Algorithm. </title> <booktitle> In Proceedings of ACM SIGCOMM, </booktitle> <pages> pages 112, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: Consequently, flow 1 will be unfairly penalized in the interval [1; 2] for using idle server resources in the interval [0; 1]. To address this limitation, fair algorithms have been designed <ref> [4, 12, 42, 22, 52] </ref>. Fair algorithms ensure that in any time interval in which two flows are backlogged, they receive service in proportion to their reserved rates. <p> Hence, in the example scenario a fair algorithm will serve equal number of packets of flows 1 and 2 in the interval [1; 2]. Several fair scheduling algorithms such as Weighted Fair Queuing (WFQ) <ref> [12] </ref> (also known as Packet-by-packet Generalized Processor Sharing [42]), Self Clocked Fair Queuing (SCFQ) [22], and Frame-based Fair Queuing (FFQ) [52] have been designed in the literature. <p> Further discussion of the tradeoffs between work conserving and non-work conserving algorithms can be found in [34]. * Best-effort QoS: In this case, one of the principal objectives of a packet scheduling algorithm is to allocate link bandwidth fairly <ref> [12] </ref>. The fair algorithms designed to provide guaranteed service can achieve this objective. <p> reserved 9 Rate Allocation Delay Allocation Work Virtual Clock Delay EDD Conserving WFQ SCFQ Non-work Hierarchical Round Robin Jitter EDD Conserving Stop-and-go Queuing RCSP Table 1.1: Classification of scheduling algorithms in best-effort service, fair scheduling algorithms allocate server bandwidth in proportion to weights, rather than reserved rates, of the flows <ref> [12] </ref>. Thus, most of the scheduling algorithms that have been proposed can be classified as either being work conserving or non-work conserving and either allocating only rate or separating rate and delay allocation. The work conserving algorithms can further be classified as either being fair or unfair. <p> Isolation of flows enables a network to provide stronger guarantees and is highly desirable, especially in large heterogeneous networks where sources may be malicious <ref> [6, 12, 36, 45] </ref>. Thus, GR class has desirable properties. In the following subsections, we show that many of the work conserving as well as non-work conserving scheduling algorithms that either allocate only rate or separate rate and delay allocation belong to GR. <p> To show that a scheduling algorithm belongs to GR, we would be required to prove a bound on the departure time of a packet. As observed in <ref> [12, 27] </ref>, it is typically easier to bound the departure time of a packet in preemptive scheduling algorithms. <p> Generalized Virtual Clock does not have such a requirement, and hence reduces the implementation complexity. Weighted Fair Queuing Weighted Fair Queuing (WFQ) scheduling algorithm is a practical realization of Generalized Processor Sharing (GPS) service discipline <ref> [12] </ref> (WFQ is also known 28 as Packet-by-packet Generalized Processor Sharing (PGPS) [42]). We first show that GPS be- longs to GR and then show that a generalized virtual time implementation of WFQ belongs to GR. <p> Hence, fair scheduling algorithms are desirable for video applications. * Data applications: To support low-throughput, interactive data applications (e.g., telnet), scheduling algorithms must provide low average delay. On the other hand, to support throughput-intensive flow-controlled applications in heterogeneous, large-scale, decentralized networks, scheduling algorithms must allocate bandwidth fairly <ref> [12, 33, 45] </ref>. Fair allocation of bandwidth at each server enables a network to achieve max-min fair allocation of network bandwidth in heterogeneous environments [12, 44]. <p> On the other hand, to support throughput-intensive flow-controlled applications in heterogeneous, large-scale, decentralized networks, scheduling algorithms must allocate bandwidth fairly [12, 33, 45]. Fair allocation of bandwidth at each server enables a network to achieve max-min fair allocation of network bandwidth in heterogeneous environments <ref> [12, 44] </ref>. Due to the coexistence of VBR video sources and data sources in integrated services networks, the bandwidth available to data applications may vary significantly over time. Consequently, the effective capacity of a server for data applications may vary over time. <p> In the next section, we examine these algorithms to determine if they meet the requirements for a suitable scheduling algorithm. 4.4 Evaluation of Existing Algorithms The earliest known fair scheduling algorithm is Weighted Fair Queuing (WFQ) <ref> [12] </ref> (also re ferred to as Packet-by-Packet Generalized Processor Sharing (PGPS) [42]). <p> of a scheduling algorithm is to provide pre-specified bounds on packet delay, it may be desirable to employ: * Scheduling algorithms that allocate only rate and have delay guarantee similar to Weighted Fair Queuing (WFQ): Several fair algorithms that have delay guarantee similar to WFQ are known (for example, WFQ <ref> [12, 42] </ref>, FFQ [52], WF 2 Q [4], WF 2 Q+ [3], Leap Forward Virtual Clock [53], etc.).
Reference: [13] <author> D. Ferrari. </author> <title> Client Requirements for Real-Time Communication Services. </title> <journal> IEEE Communications Magazine, </journal> <pages> pages 6572, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Consider sources requiring guaranteed QoS and best-effort service. Guaranteed QoS: In this case, sources require a network to guarantee QoS parameters such as minimum bandwidth and upper bound on packet delay, delay jitter, and loss. The bounds on delay and loss may be deterministic or probabilistic <ref> [13] </ref>. To meet the QoS requirements of such sources, a network employs an open-loop control technique. In this technique, a source specifies its QoS requirements and traffic characteristics such as average rate, peak rate, and burst size to the network [13]. <p> bounds on delay and loss may be deterministic or probabilistic <ref> [13] </ref>. To meet the QoS requirements of such sources, a network employs an open-loop control technique. In this technique, a source specifies its QoS requirements and traffic characteristics such as average rate, peak rate, and burst size to the network [13]. The network, in turn, employs an admission control algorithm to determine if the source can be admitted. <p> This inverse relationship between delay and rate reservation may lead to inefficient utilization of resources [61]. Thus, scheduling algorithms that achieve separation of rate and delay allocation have been designed. An example of such an algorithm is Delay EDD <ref> [13] </ref>. The algorithms that we have considered so far service a packet whenever a packet is backlogged at the server, i.e., they are are work conserving. Non-work conserving algorithms that keep a server idle even when packets are backlogged at the server also have been proposed in the literature. <p> Packets are served in the increasing order of deadline. It was shown in <ref> [13, 64] </ref> that if certain schedulability conditions are met and the mini mum inter-arrival time of packets is at least l f f , then a packet would depart by D i (p j f ). <p> Consequently, the guarantees offered by a network employing scheduling algorithms in 57 GR are independent of the behaviour of other flows, i.e., the network provides isolation between sources. Hence, unlike conventional network architectures where source traffic is policed to ensure that it conforms to the advertised characteristics <ref> [13] </ref>, policing of traffic is not required in GR networks. * A source should be able to request buffer reservation in the network: If a source does not specify the characteristics of the traffic to the network, then a network may not know the buffer space that should be reserved for <p> Algorithms such as Delay EDD belong to this class <ref> [13] </ref>. Thus, they decouple delay from the reserved rate for a flow and consequently can provide low delay to low throughput flows without increasing rate reservation. Hence, they may lead to higher achievable utilization of a network.
Reference: [14] <author> D. Ferrari and D. C. Verma. </author> <title> A Scheme for Real-Time Channel Establishment in Wide-Area Networks. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 8(3):368379, </volume> <month> April </month> <year> 1990. </year>
Reference-contexts: It is also applicable in networks with connectionless network layer such as Internet enhanced with resource reservation protocols such as RSVP [63]. To meet the QoS requirements of applications in an integrated services network, several packet scheduling algorithms have been designed <ref> [14, 21, 22, 30, 36, 42, 59, 61, 62, 64] </ref>. Since a detailed survey of these algorithms has been presented in [58], we review the algorithms only briefly. The design of a packet scheduling algorithm depends on the desired QoS. <p> The work conserving algorithms can further be classified as either being fair or unfair. Table 1.1 summarizes this classification. To provide QoS guarantees to sources, several source traffic specifications also have been proposed. Examples include leaky bucket [9, 42], Flow Specification [55], average and peak rate specification <ref> [14] </ref>, Deterministic Bounding Interval Dependent model [35], and Exponentially Bounded Burstiness [56]. The QoS guarantees of a single server for different source traffic specifications and scheduling algorithms have been analyzed in the literature [9, 42].
Reference: [15] <author> S. Floyd and V. Jacobson. </author> <title> Link-sharing and Resource Management Models for Packet Networks. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 3(4):365386, </volume> <month> August </month> <year> 1995. </year>
Reference-contexts: The ranges that we choose are: [b min ; b max ] = [1; 20], [l min ; l max ] = [512; 8196] bits, [r min ; r max ] = [32; 2056] Kb/s, and [k min ; k max ] = <ref> [3; 15] </ref>. The six different ranges that we choose for delay are: [25; 200] ms, [100; 200] ms, [100; 300] ms, [100; 400] ms, [100; 500] ms, and [100; 600] ms. Figures 3.12 (a) and 3.12 (b) plot the metrics U r and U g for these experiments, respectively. <p> Since these services as well as the protocols may be incompatible with each other, a mechanism that provides isolation between different services and protocols and enables their coexistence is required. Hierarchical link bandwidth allocation is one possible mechanism for managing heterogeneity in integrated services networks <ref> [15, 49] </ref>. In hierarchical link bandwidth alloca 97 tion, link bandwidth is allocated to a set of classes. The classes, in turn, recursively allocate the bandwidth among their subclasses. A class ensures that each of its sub-classes receives a minimum requested bandwidth. <p> An integrated services network will support a link-sharing service in which the bandwidth of a link is allocated among several organizations and the bandwidth of an organization is recursively allocated among its suborganizations <ref> [15, 47] </ref>. The bandwidth of an organization is allocated among the suborganizations in proportion to the weights of the suborganizations. The weights may be governed by the price paid by the various suborganizations or other policies [15]. <p> The bandwidth of an organization is allocated among the suborganizations in proportion to the weights of the suborganizations. The weights may be governed by the price paid by the various suborganizations or other policies <ref> [15] </ref>. Such a link-sharing service has been considered to be the most important service enhancement that is required in current Internet [47]. Link-sharing can be naturally supported by hierarchical link bandwidth allocation mechanism. <p> Thus, WFQ is unsuitable for achieving fairness over variable rate servers. As we will show in Chapter 7, to be useful for hierarchical link bandwidth allocation <ref> [15, 49] </ref>, a scheduling algorithm must provide fairness over variable rate servers. Consequently, WFQ is unsuitable for meeting two key requirements (i.e., fairness over variable rate servers and support for hierarchical link bandwidth allocation) of a fair scheduling algorithm for integrated services network.
Reference: [16] <author> D. Le Gall. </author> <title> MPEG: A Video Compression Standard for Multimedia Apllications. </title> <journal> Communications of the ACM, </journal> <volume> 34(4):4658, </volume> <month> April </month> <year> 1991. </year>
Reference-contexts: to audio sources, many of which have constant bit rate requirements, as well as Variable Bit Rate (VBR) video sources which have multiple time-scale variations in the bit rate (Figure 2.1 shows short-term as well as the long-term variations in the bit rate variation of a MPEG compressed video sequence <ref> [16] </ref>). Furthermore, since sources may not conform to the advertised specification, the QoS guarantees provided to a source should be independent of the behaviour of the other flows. A network of servers also should provide QoS guarantees similar to a single server.
Reference: [17] <author> L. Georgadis, R. Guerin, and A. Parekh. </author> <title> Optimal Multiplexing on a Single Link: Delay and Buffer Requirements. </title> <booktitle> In Proceeding of INFOCOM'94, </booktitle> <year> 1994. </year>
Reference-contexts: Hence, ^ L P S (p j ) t 0 + k2S C 24 Theorem 2.1 is superficially similar to Theorem 1 of [42] and its generalization in <ref> [17] </ref> which demonstrate that if a scheduling algorithm satisfies some assumptions, then the departure time of a packet in a non-preemptive scheduling algorithm is at most ^ l max C more than its departure time in a preemptive scheduling algorithm. <p> Some of the algorithms that we will be considering (for example, Virtual Clock) do not satisfy the assumptions required in those theorems. Furthermore, Theorem 2.1 proves a weaker result, which suffices for our purpose, then the results in <ref> [17, 42] </ref>. Specifically, whereas the results in [17, 42] bound the difference in departure time of a packet in a preemptive and non-preemptive scheduling algorithm, Theorem 2.1 relates the departure time of a packet in a non-preemptive algorithm to the bound on the departure time of the packet in a preemptive <p> Some of the algorithms that we will be considering (for example, Virtual Clock) do not satisfy the assumptions required in those theorems. Furthermore, Theorem 2.1 proves a weaker result, which suffices for our purpose, then the results in <ref> [17, 42] </ref>. Specifically, whereas the results in [17, 42] bound the difference in departure time of a packet in a preemptive and non-preemptive scheduling algorithm, Theorem 2.1 relates the departure time of a packet in a non-preemptive algorithm to the bound on the departure time of the packet in a preemptive scheduling algorithm.
Reference: [18] <author> L. Georgiadis, R. Guerin, V. Peris, and R. Rajan. </author> <title> Efficient Support of Delay and Rate Guarantees in an Internet. </title> <booktitle> In Proceedings of ACM SIGCOMM'96, </booktitle> <pages> pages 106116, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: Hence, if Q flows are served by a server, then the schedulability condition is P i=Q * RCSD: We use the schedulability condition presented in <ref> [18] </ref>, which is a generalization of Theorem 1 of [19] for networks that have variable packet sizes, to determine the schedula bility region. <p> Finally, a network that supports deterministic service as well as a service that provides guaranteed throughput, but not delay, may be able to employ additional buffer to increase its overall utilization <ref> [18] </ref>. 3.2 Relative Merits of Algorithm in GR The GR class contains algorithms with different properties. It includes algorithms : (1) that are work conserving or non-work conserving; (2) that are fair or unfair; and (3) that allocate only rate or achieve separation of rate and delay allocation.
Reference: [19] <author> L. Georgiadis, R. Guerin, V. Peris, and K.N. Sivarajan. </author> <title> Efficient Network QoS Provisioning Based on per Node Traffic Shaping. </title> <booktitle> In Proceedings of INFOCOM'96, </booktitle> <pages> pages 102110, </pages> <month> March </month> <year> 1996. </year> <month> 203 </month>
Reference-contexts: Several 37 non-work conserving scheduling algorithms have been proposed to address this limitation <ref> [19, 60] </ref>. Though non-work conserving algorithms reduce the buffer requirement in the network, they increase the average delay for all the flows. Even though this may be desirable for some flows, it may not be desirable for other flows. <p> The conclusions of this chapter are presented in Section 3.3. 3.1 Evaluation of the GR Class Most of the scheduling algorithms that have been proposed in the literature can be shown to belong to either the GR class or the class of Rate Controlled Service Disciplines (RCSD) presented in <ref> [19] </ref>. Since the RCSD class is known to be optimal when flows are served by a single server, we evaluate the completeness of the GR class by comparing its achievable utilization with the RCSD class [19]. <p> either the GR class or the class of Rate Controlled Service Disciplines (RCSD) presented in <ref> [19] </ref>. Since the RCSD class is known to be optimal when flows are served by a single server, we evaluate the completeness of the GR class by comparing its achievable utilization with the RCSD class [19]. In the next section we present the definition of the GR and RCSD classes and illustrate the differences between them. <p> EAT 1 (p f ; r f ) A (p f ) + n=1 f (3.1) where A (p j f ) is the time at which packet p j f is generated at the source. * RCSD class: The RCSD class is defined based on the concept of shapers <ref> [19] </ref>. A shaper is a network element that ensures that its output traffic satisfies some burstiness constraints. <p> RCSD class contains work conserving as well as non-work conserving algorithms (see <ref> [19, 60] </ref> for some examples). <p> RCSD class contains work conserving as well as non-work conserving algorithms (see [19, 60] for some examples). It has been shown in 2 For ease of exposition, we have assumed that the length of the packets of a flow does not vary. 63 <ref> [19] </ref> that if each server on the path of a flow employs a scheduling algorithm in RCSD, then the network guarantees that the maximum end-to-end delay of any packet, denoted by d f , is given as: d f = D S n=K X d n where D S f is <p> Intuitively, S f is a shaper composed by sequentially connecting shapers S 1 f ; ::; S K f (see <ref> [19] </ref> for a precise definition of composition of shapers). To determine the relationship between the GR and RCSD classes, observe that variable rate allocation algorithms such as generalized Virtual Clock, SCFQ, and WFQ belong to the GR class. <p> Since EDF has the largest schedulability region, let the RCSD scheduling algorithms employ EDF scheduler and a ( f ; r f ) leaky bucket shaper for flow f <ref> [19] </ref>. Consider two flows f and m that conform to leaky bucket with parameters (10pkt; 1pkt=s) and (1pkt; 1pkt=s), respectively. Let both flows f and m require delay of 5:5s and be served by a single server with capacity 2pkts=s. Then, from the results in [19], it can be shown that <p> bucket shaper for flow f <ref> [19] </ref>. Consider two flows f and m that conform to leaky bucket with parameters (10pkt; 1pkt=s) and (1pkt; 1pkt=s), respectively. Let both flows f and m require delay of 5:5s and be served by a single server with capacity 2pkts=s. Then, from the results in [19], it can be shown that a RCSD server satisfies the deadline requirements of both the flows. <p> Hence, if Q flows are served by a server, then the schedulability condition is P i=Q * RCSD: We use the schedulability condition presented in [18], which is a generalization of Theorem 1 of <ref> [19] </ref> for networks that have variable packet sizes, to determine the schedula bility region. <p> If all the flows have the same packet length l, then we use Theorem 1 of <ref> [19] </ref> and ensure that the following set of inequalities hold: minf (k + 1)l; Qlg + i=k X ( i l) ^ d k C i=1 ! i=k1 X r i ^ d i 1 k Q (3.6) To experimentally evaluate the difference in achievable utilization between RCSD and GR networks, <p> We address this limitation in this chapter by designing a class of Fair Airport (FA) algorithms. An algorithm in FA class combines SFQ with a non-work conserving algorithm in Rate Controlled Service Discipline (RCSD) class <ref> [19, 60] </ref>. We derive fairness and deadline guarantees for FA servers and demonstrate that by appropriately choosing an algorithm from RCSD class, algorithms that either allocate only rate or achieve separation of rate and delay allocation and are fair over Fluctuation Constrained variable rate servers can be designed. <p> Finally, Section 6.7 summarizes the results of this chapter. 6.1 Design of Fair Airport Scheduling Algorithms To gain an intuitive understand the design of Fair Airport 1 scheduling algorithms, consider the class of Rate Controlled Service Disciplines (RCSD) <ref> [19, 60] </ref>. A RCSD scheduling algorithm employs a rate controller (also referred to as a shaper) for each flow (see Figure 6.1). <p> Hence, the challenge is to make the algorithm work conserving while ensuring that it remains fair. RCSD can be made work conserving by introducing an Auxiliary Service Queue (ASQ) (this approach was first introduced in [8] and later employed in <ref> [19] </ref>). In such a case, packets on arrival not only join a rate controller, but also ASQ. When there are no packets in the GSQ, packets are scheduled from the ASQ. We assume that the packets of a flow are scheduled from ASQ in sequence. <p> However, whereas the former can support only predetermined set of delay vectors, the latter can support any [59]. * The concept of Fair Airport algorithm is general. The rate controller can be generalized as in <ref> [19] </ref> to enforce different traffic constraints. It can be shown that the generalized FA class continues to remain fair. * The FA algorithms can be generalized to achieve prioritized fair allocation of residual bandwidth which may be desirable to support high throughput flows in max-min fair networks [38].
Reference: [20] <author> J. Golestani. </author> <type> Personal Communication. </type> <month> March </month> <year> 1997. </year>
Reference-contexts: We conduct 6 experiments and generate 100; 000 lists in each experiment. The ranges for all the factors other than delay are kept same in all the experiments. The ranges that we choose are: [b min ; b max ] = <ref> [1; 20] </ref>, [l min ; l max ] = [512; 8196] bits, [r min ; r max ] = [32; 2056] Kb/s, and [k min ; k max ] = [3; 15]. <p> A proof that there is an inherent tradeoff between fairness guarantee and the computational complexity of an algorithm is desirable. It is our conjecture that the problem of achieving fairness is closely related to that of sorting and, hence, has a tight lower bound of O (logQ) <ref> [20] </ref>. * Optimal scheduling algorithm for providing heterogeneous services: The hierarchical scheduling algorithms that we have developed for providing heterogeneous services do not exploit the semantics of the services. Though this approach has the advantage that 200 different services can be designed independently, it may lead to sub-optimal performance.
Reference: [21] <author> S.J. Golestani. </author> <title> A Framing Strategy for Congestion Management. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <pages> pages 10641077, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: It is also applicable in networks with connectionless network layer such as Internet enhanced with resource reservation protocols such as RSVP [63]. To meet the QoS requirements of applications in an integrated services network, several packet scheduling algorithms have been designed <ref> [14, 21, 22, 30, 36, 42, 59, 61, 62, 64] </ref>. Since a detailed survey of these algorithms has been presented in [58], we review the algorithms only briefly. The design of a packet scheduling algorithm depends on the desired QoS. <p> Some non-work conserving scheduling algorithms serve a packet from a flow only at predetermined time instants. Examples of such algorithms include Hierarchical Round Robin and Stop-and-go Queuing <ref> [21, 61] </ref>. Other non-work conserving algorithms service a packet only after it becomes eligible [60]. Several eligibility notions have been defined [60].
Reference: [22] <author> S.J. Golestani. </author> <title> A Self-Clocked Fair Queueing Scheme for High Speed Applications. </title> <booktitle> In Proceedings of INFOCOM'94, </booktitle> <pages> pages 636646, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: It is also applicable in networks with connectionless network layer such as Internet enhanced with resource reservation protocols such as RSVP [63]. To meet the QoS requirements of applications in an integrated services network, several packet scheduling algorithms have been designed <ref> [14, 21, 22, 30, 36, 42, 59, 61, 62, 64] </ref>. Since a detailed survey of these algorithms has been presented in [58], we review the algorithms only briefly. The design of a packet scheduling algorithm depends on the desired QoS. <p> Consequently, flow 1 will be unfairly penalized in the interval [1; 2] for using idle server resources in the interval [0; 1]. To address this limitation, fair algorithms have been designed <ref> [4, 12, 42, 22, 52] </ref>. Fair algorithms ensure that in any time interval in which two flows are backlogged, they receive service in proportion to their reserved rates. <p> Hence, in the example scenario a fair algorithm will serve equal number of packets of flows 1 and 2 in the interval [1; 2]. Several fair scheduling algorithms such as Weighted Fair Queuing (WFQ) [12] (also known as Packet-by-packet Generalized Processor Sharing [42]), Self Clocked Fair Queuing (SCFQ) <ref> [22] </ref>, and Frame-based Fair Queuing (FFQ) [52] have been designed in the literature. These algorithms essentially emulate a hypothetical bit-by-bit round robin server in which the number of bits of a backlogged flow served in a round is proportional to the rate of the flow. <p> Hence, Virtual Clock, WFQ, and SCFQ also belong the GR class. These algorithms have different delay and fairness properties as well as implementation complexity, and hence demonstrate that the GR class is broad (an exposition of these algorithms along these dimensions can be found in <ref> [22, 42] </ref>). We will analyze the algorithms assuming that rate allocation may vary with every packet. However, a particular network architecture may choose to allocate variable rate for every message [36], in response to change in reservation [28, 25], or employ some other policy. <p> Self Clocked Fair Queuing The Self Clocked Fair Queuing scheme, originally proposed in [11] and later analyzed in <ref> [22] </ref>, was designed to facilitate the implementation of a fair queuing scheme in broadband networks. We define a generalized SCFQ algorithm which can allocate variable rate to packets of a flow analogous to SCFQ as follows: 1. <p> The objective of fair packet 100 scheduling algorithms is to ensure that j W f (t 1 ;t 2 ) m j is as close to 0 as possible 1 . However, it has been shown in <ref> [22] </ref> that if a packet scheduling algorithm guarantees that j f W m (t 1 ;t 2 ) j H (f; m) for all intervals [t 1 ; t 2 ] then H (f; m) 1 2 l max f l max m , where H (f; m) is a function <p> This simulation may require processing of O (Q) events in a single packet transmission time, where Q is the number of flows served, and thus is considered computationally expensive <ref> [22] </ref>. Furthermore, to retain fairness when server rate varies over time, the definition of virtual time will have to be modified. <p> Moreover, since it utilizes v (t) as defined in (4.1), it has disadvantages similar to that of WFQ. Self Clocked Fair Queuing (SCFQ), originally proposed in [11] and later analyzed in <ref> [22] </ref>, was designed to reduce the computational complexity of fair scheduling algorithms like WFQ. SCFQ also schedules packets in the increasing order of finish tags. However, it achieves efficiency over WFQ by approximating v (t) with the finish tag of the packet in service at time t. <p> It has been shown that the value of H (f; m) for SCFQ is ( l max f l max m ), which is only a factor of two away from the lower bound <ref> [22] </ref>. The main limitation of SCFQ is that it increases the maximum delay incurred by the packets significantly. <p> Guarantee The unfairness measure H (f; m) of SFQ was demonstrated in Theorem 5.1 to be l max r f l max r m Since the lower bound on unfairness measure achievable by any algorithm was shown to be 1 l max r f l max r m ) in <ref> [22] </ref>, it seems that the fairness guarantee of SFQ is factor of two higher than the best possible guarantee. We derive a tighter lower bound on unfairness measure and demonstrate that fairness guarantee of SFQ is better than what the current lower bound indicates. <p> example does not demonstrate the impossibility of designing a scheduling algorithm that has the fairness guarantee of SFQ but the deadline guarantee of WFQ; it only demonstrates a tradeoff between fairness and isolation. 8.3 Fairness Definitions We have chosen the definition of fairness, termed relative fairness, that was introduced in <ref> [22] </ref> and consider an algorithm fair if the difference in service normalized by weight received by two flows when they are backlogged is bounded, i.e., j W f (t 1 ;t 2 ) r m j is bounded.
Reference: [23] <author> P. Goyal, S. S. Lam, and H. M. Vin. </author> <title> Determining End-to-End Delay Bounds In Heterogeneous Networks. </title> <journal> ACM/Springer-Verlag Multimedia Systems Journal, </journal> <volume> 5(3):157163, </volume> <month> May </month> <year> 1997. </year> <booktitle> Also appeared in the Proceedings of the Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <pages> Pages 287-298, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: If the reserved rate for flow f is r f , they assign a priority to the packets of flow f such that the departure time of a flow f packet is at most a constant more than the departure time in a server of rate r f <ref> [23, 24] </ref>. One possible priority assignment for the packets of a flow is their departure time in a server of rate r f . This priority assignment results in the Virtual Clock scheduling algorithm [62].
Reference: [24] <author> P. Goyal and H. M. Vin. </author> <title> Generalized Guaranteed Rate Scheduling Algorithms: A Framework. </title> <note> In IEEE/ACM Transactions on Networking (to appear). Also available as technical report TR95-30, </note> <institution> Department of Computer Sciences, The University of Texas at Austin. </institution>
Reference-contexts: If the reserved rate for flow f is r f , they assign a priority to the packets of flow f such that the departure time of a flow f packet is at most a constant more than the departure time in a server of rate r f <ref> [23, 24] </ref>. One possible priority assignment for the packets of a flow is their departure time in a server of rate r f . This priority assignment results in the Virtual Clock scheduling algorithm [62]. <p> It may be served through ASQ or GSQ. Let us consider the two cases: * Packet p j f is serviced through GSQ: Since GSQ ensures (6.3): EAT GSQ (p f ; r f ) + +fi f (6.9) It has been shown in <ref> [24] </ref> that: EAT GSQ (p f ; r f ) = EAT RC (p f ; r f ) (6.10) when the rate controller satisfies (6.2).
Reference: [25] <author> P. Goyal and H. M. Vin. </author> <title> Network Algorithms and Protocol for Multimedia Servers. </title> <booktitle> In Proceedings of INFOCOM'96, </booktitle> <pages> pages 13711379, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: We will analyze the algorithms assuming that rate allocation may vary with every packet. However, a particular network architecture may choose to allocate variable rate for every message [36], in response to change in reservation <ref> [28, 25] </ref>, or employ some other policy. Virtual Clock We define generalized Virtual Clock (VC) scheduling algorithm analogous to the Virtual Clock algorithm [62]. The generalized VC algorithm is defined as follows: 1. <p> The six different ranges that we choose for delay are: <ref> [25; 200] </ref> ms, [100; 200] ms, [100; 300] ms, [100; 400] ms, [100; 500] ms, and [100; 600] ms. Figures 3.12 (a) and 3.12 (b) plot the metrics U r and U g for these experiments, respectively. <p> Hence, a scheduling algorithm should be able to provide low delay to low throughput applications. * Video applications: Variable bit rate (VBR) video sources, which are expected to impose significant requirements on network resources, have unpredictable as well as highly variable bit rate requirement at multiple time-scales <ref> [25, 26, 28] </ref>. Whereas the variation at time-scale of tens of milliseconds occurs due to use of interframe compression algorithms such as MPEG, variations at the time-scale of seconds or longer occur due to the inherent variation in scene complexity. <p> An integrated services network will provide several services as well as employ multiple protocol families that support different traffic types and/or congestion control mechanisms. For example, as demonstrated in <ref> [25, 26] </ref> since stored video is less delay sensitive than interactive video, the network protocols employed for stored and interactive video may be different.
Reference: [26] <author> P. Goyal, H. M. Vin, C. Shen, and P.J. Shenoy. </author> <title> A Reliable, Adaptive Protocol for Video Transport. </title> <booktitle> In Proceedings of INFOCOM'96, </booktitle> <pages> pages 10801090, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: Hence, a scheduling algorithm should be able to provide low delay to low throughput applications. * Video applications: Variable bit rate (VBR) video sources, which are expected to impose significant requirements on network resources, have unpredictable as well as highly variable bit rate requirement at multiple time-scales <ref> [25, 26, 28] </ref>. Whereas the variation at time-scale of tens of milliseconds occurs due to use of interframe compression algorithms such as MPEG, variations at the time-scale of seconds or longer occur due to the inherent variation in scene complexity. <p> An integrated services network will provide several services as well as employ multiple protocol families that support different traffic types and/or congestion control mechanisms. For example, as demonstrated in <ref> [25, 26] </ref> since stored video is less delay sensitive than interactive video, the network protocols employed for stored and interactive video may be different.
Reference: [27] <author> A. Greenberg and N. </author> <title> Madras. How Fair is Fair Queuing. </title> <journal> The Journal of ACM, </journal> <volume> 39(3):568 598, </volume> <month> July </month> <year> 1992. </year>
Reference-contexts: To show that a scheduling algorithm belongs to GR, we would be required to prove a bound on the departure time of a packet. As observed in <ref> [12, 27] </ref>, it is typically easier to bound the departure time of a packet in preemptive scheduling algorithms. <p> Hence, even though packet scheduling algorithms are inherently non-preemptive in nature, to show that a scheduling algorithm belongs to GR, we employ a proof methodology, similar to the methodology in <ref> [27, 42] </ref>, in which we first prove a bound on the departure time of a packet in preemptive scheduling algorithm, and then use a relationship between the departure times of a packet in equivalent preemptive and non-preemptive scheduling algorithm. <p> Clearly, this is significantly higher than the lower bound on H (f; m). Since in the hypothetical server j W f (t 1 ;t 2 ) m j= 0, this also demonstrates that WFQ does not emulate it well. 103 Fair Queuing based on Start-time (FQS), proposed in <ref> [27] </ref>, computes start tag and finish tag of a packet exactly as in WFQ. However, instead of scheduling packets in the increasing order of finish tags, it schedules packets in the increasing order of start tags.
Reference: [28] <author> M. Grossglauser, S. Keshav, and D. Tse. RCBR: </author> <title> A Simple and Efficient Service for Multiple Time-Scale Traffic. </title> <booktitle> In Proceedings of ACM SIGCOMM'95, </booktitle> <pages> pages 219230, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: We will analyze the algorithms assuming that rate allocation may vary with every packet. However, a particular network architecture may choose to allocate variable rate for every message [36], in response to change in reservation <ref> [28, 25] </ref>, or employ some other policy. Virtual Clock We define generalized Virtual Clock (VC) scheduling algorithm analogous to the Virtual Clock algorithm [62]. The generalized VC algorithm is defined as follows: 1. <p> Hence, a scheduling algorithm should be able to provide low delay to low throughput applications. * Video applications: Variable bit rate (VBR) video sources, which are expected to impose significant requirements on network resources, have unpredictable as well as highly variable bit rate requirement at multiple time-scales <ref> [25, 26, 28] </ref>. Whereas the variation at time-scale of tens of milliseconds occurs due to use of interframe compression algorithms such as MPEG, variations at the time-scale of seconds or longer occur due to the inherent variation in scene complexity.
Reference: [29] <author> J. D. Guyton and M. F. Schwartz. </author> <title> Locating Nearby Copies of Replicated Internet Servers. </title> <booktitle> In Proceedings of ACM SIGCOMM'95, </booktitle> <pages> pages 288298, </pages> <month> August </month> <year> 1995. </year> <month> 204 </month>
Reference-contexts: We let the number of servers on the path be either 1; 3; 5; 10; or 15. Note that since the average number of hops in Internet is 17, the number of servers we choose is conservative <ref> [29] </ref>. We conduct three experiments: * EXP1: S l and S h are chosen to be the low and high throughput sets.
Reference: [30] <author> C.R. Kalmanek, H. Kanakia, and S. Keshav. </author> <title> Rate Controlled Servers for Very High-Speed Networks. </title> <booktitle> In Proceedings of IEEE GLOBECOM'90, </booktitle> <address> San Diego, CA, pages 300.3.1 300.3.9, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: It is also applicable in networks with connectionless network layer such as Internet enhanced with resource reservation protocols such as RSVP [63]. To meet the QoS requirements of applications in an integrated services network, several packet scheduling algorithms have been designed <ref> [14, 21, 22, 30, 36, 42, 59, 61, 62, 64] </ref>. Since a detailed survey of these algorithms has been presented in [58], we review the algorithms only briefly. The design of a packet scheduling algorithm depends on the desired QoS.
Reference: [31] <author> D. D. Kandlur, K. G. Shin, and D. Ferrari. </author> <title> Real-Time Communication in Multihop Networks. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5(10):10441056, </volume> <month> Octo-ber </month> <year> 1994. </year>
Reference-contexts: However, in a networking environment even if the minimum inter-arrival time is at least l f f at the network entry point, it may become smaller than l f f at a server which is downstream on the path of a flow. This problem was addressed in <ref> [31, 64] </ref> by requiring the clocks of the servers to be synchronized. We demonstrate that this is an unnecessary restriction by proving that regardless of the inter-arrival time of packets, preemptive Delay EDD guarantees that packet p j f will be transmitted by D i (p j f ).
Reference: [32] <author> S. Keshav. </author> <title> Congestion Control for Computer Networks. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, University of California at Berkeley, </institution> <year> 1991. </year>
Reference-contexts: A fundamental problem at the network layer is to meet the QoS requirements of packet sources, i.e., avoid congestion <ref> [32] </ref>. To control packet delay and loss, and thus avoid congestion, a network has to manage two resources: link bandwidth and buffers at each packet-switch. In a packet-switched network, resources are not physically partitioned among various sources. Hence, contention for access to link and buffers may occur. <p> Packet sources estimate the network state such as available buffers and link bandwidth. On detection of congestion, either implicitly or through explicit notification from the network, they control their behaviour, using either a window or rate based flow control algorithm, to avoid congestion <ref> [32] </ref>. This control technique achieves efficient utilization of network resources. 4 A network may also employ a combination of open and closed loop control techniques for sources that desire a minimum guaranteed QoS for a subset of the packets and best-effort service for the remaining packets. <p> Furthermore, it ensures that a source receives service as per its reservation. In case of closed-loop control, scheduling algorithms enable: (1) fair allocation of network resources; (2) network state estimation; and (3) coexistence of different feedback control algorithms <ref> [32, 45] </ref>. Thus, packet and buffer scheduling algorithms enable a network to not only deliver different QoS to different sources, but also meet the QoS requirements of individual sources. Hence, packet and buffer scheduling algorithms are central to the realization of integrated services networks. <p> The ranges for all the factors other than delay are kept same in all the experiments. The ranges that we choose are: [b min ; b max ] = [1; 20], [l min ; l max ] = [512; 8196] bits, [r min ; r max ] = <ref> [32; 2056] </ref> Kb/s, and [k min ; k max ] = [3; 15]. The six different ranges that we choose for delay are: [25; 200] ms, [100; 200] ms, [100; 300] ms, [100; 400] ms, [100; 500] ms, and [100; 600] ms. <p> There are two criteria that we may use for evaluation: * Ability to achieve the objectives: There are two objectives of a fair scheduling algorithm: (1) it should allocate a server resources for flow-controlled data sources such that overall network resource allocation is max-min fair <ref> [32] </ref>; and (2) it should provide QoS guarantees to video sources even when persistent congestion occurs.
Reference: [33] <author> S. Keshav. </author> <title> A Control-Theoretic Approach to Flow Control. </title> <booktitle> In Proceedings of ACM SIGCOMM'91, </booktitle> <pages> pages 315, </pages> <year> 1991. </year>
Reference-contexts: Since all these algorithms provide end-to-end QoS guarantees in heterogeneous environments, a natural question that arises is whether some subclasses of GR have advantages over the other. We explore this issue in this section. The relative advantages of work conserving and non-work conserving scheduling algorithms are well known <ref> [34, 33] </ref>. Work conserving algorithms provide low average delay to flows but at the expense of increased buffer requirement in the network. Furthermore, they may be able to better multiplex packets from flows requiring best-effort service. <p> To increase its throughput by taking advantage of statistical multiplexing of various sources, it estimates the bottleneck rate, which is at least the reserved rate, and sends at the estimated bottleneck rate <ref> [33] </ref>. Due to the fluctuations in the bottleneck rate as well as the inherent delay 87 values of k. and errors in the estimation process, such a source may send at a rate higher than the bottleneck rate. <p> Hence, fair scheduling algorithms are desirable for video applications. * Data applications: To support low-throughput, interactive data applications (e.g., telnet), scheduling algorithms must provide low average delay. On the other hand, to support throughput-intensive flow-controlled applications in heterogeneous, large-scale, decentralized networks, scheduling algorithms must allocate bandwidth fairly <ref> [12, 33, 45] </ref>. Fair allocation of bandwidth at each server enables a network to achieve max-min fair allocation of network bandwidth in heterogeneous environments [12, 44].
Reference: [34] <author> S. Keshav. </author> <title> An Engineering Approach to Computer Networking. </title> <publisher> Addison Wesley, </publisher> <year> 1997. </year>
Reference-contexts: On the other hand, work conserving algorithms yield better average delay performance at the expense of increased buffer requirement in the network. Further discussion of the tradeoffs between work conserving and non-work conserving algorithms can be found in <ref> [34] </ref>. * Best-effort QoS: In this case, one of the principal objectives of a packet scheduling algorithm is to allocate link bandwidth fairly [12]. The fair algorithms designed to provide guaranteed service can achieve this objective. <p> Since all these algorithms provide end-to-end QoS guarantees in heterogeneous environments, a natural question that arises is whether some subclasses of GR have advantages over the other. We explore this issue in this section. The relative advantages of work conserving and non-work conserving scheduling algorithms are well known <ref> [34, 33] </ref>. Work conserving algorithms provide low average delay to flows but at the expense of increased buffer requirement in the network. Furthermore, they may be able to better multiplex packets from flows requiring best-effort service.
Reference: [35] <author> E. Knightly and H. Zhang. </author> <title> Traffic Characterization and Switch Utilization Using a Deterministic Bounding Interval Dependent Traffic Model. </title> <booktitle> In Proceedings of INFOCOM'95, </booktitle> <address> Boston, MA, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: Table 1.1 summarizes this classification. To provide QoS guarantees to sources, several source traffic specifications also have been proposed. Examples include leaky bucket [9, 42], Flow Specification [55], average and peak rate specification [14], Deterministic Bounding Interval Dependent model <ref> [35] </ref>, and Exponentially Bounded Burstiness [56]. The QoS guarantees of a single server for different source traffic specifications and scheduling algorithms have been analyzed in the literature [9, 42]. The QoS guarantees provided by a single server have been extended to a network of servers [9, 10, 36, 42, 57].
Reference: [36] <author> S.S. Lam and G.G. Xie. </author> <title> Burst Scheduling: Architecture and Algorithm for Switching Packet Video. </title> <booktitle> In Proceedings of INFOCOM'95, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: It is also applicable in networks with connectionless network layer such as Internet enhanced with resource reservation protocols such as RSVP [63]. To meet the QoS requirements of applications in an integrated services network, several packet scheduling algorithms have been designed <ref> [14, 21, 22, 30, 36, 42, 59, 61, 62, 64] </ref>. Since a detailed survey of these algorithms has been presented in [58], we review the algorithms only briefly. The design of a packet scheduling algorithm depends on the desired QoS. <p> The QoS guarantees of a single server for different source traffic specifications and scheduling algorithms have been analyzed in the literature [9, 42]. The QoS guarantees provided by a single server have been extended to a network of servers <ref> [9, 10, 36, 42, 57] </ref>. A survey of single server and multiple server analysis techniques can be found in [58]. There are two main limitations of the existing work on packet scheduling algorithms: * The scheduling algorithms have been analyzed only for a restricted set of source traffic characterizations. <p> Furthermore, most of them have been analyzed assuming that all the flows conform to their declared specifications. Finally, the analyses of a network of servers assumes that the same scheduling algorithm is employed at each of the servers <ref> [9, 10, 36, 42, 57] </ref>. In an integrated services network, sources have widely different characteristics and may not conform to their advertised specifications. Furthermore, since the 10 network may be part of several autonomous administrative domains, different scheduling algorithms may be employed at different servers. <p> Isolation of flows enables a network to provide stronger guarantees and is highly desirable, especially in large heterogeneous networks where sources may be malicious <ref> [6, 12, 36, 45] </ref>. Thus, GR class has desirable properties. In the following subsections, we show that many of the work conserving as well as non-work conserving scheduling algorithms that either allocate only rate or separate rate and delay allocation belong to GR. <p> We will analyze the algorithms assuming that rate allocation may vary with every packet. However, a particular network architecture may choose to allocate variable rate for every message <ref> [36] </ref>, in response to change in reservation [28, 25], or employ some other policy. Virtual Clock We define generalized Virtual Clock (VC) scheduling algorithm analogous to the Virtual Clock algorithm [62]. The generalized VC algorithm is defined as follows: 1. <p> Observe that generalized Virtual Clock is work conserving and permits variable rate to be allocated to the packets of a flow as long as the capacity of a server is not exceeded. This is in contrast to the non-work conserving Burst Scheduling algorithm presented in <ref> [36] </ref> in which Virtual Clock scheduling algorithm has been employed to allocate variable rate by defining the notion of an active flow. A flow has a constant rate allocated to it as long as it is active.
Reference: [37] <author> K. Lee. </author> <title> Performance Bounds in Communication Networks With Variable-Rate Links. </title> <booktitle> In Proceedings of ACM SIGCOMM'95, </booktitle> <pages> pages 126136, </pages> <year> 1995. </year>
Reference-contexts: Hence, we analyze for servers with bounded fluctuation in service rate. Two server models, termed Fluctuation Constrained (FC) server and Exponentially Bounded Fluctuation (EBF) server, that have bounded fluctuation in service rate and are suitable for modeling many variable rate servers have been introduced in <ref> [37] </ref> 2 . A FC server has two parameters; average rate C (bits/s) and burstiness ffi (C) (s). <p> Since a (C; 0) FC server is a constant rate server, the following analysis is also valid for constant rate servers. 2 The definitions of FC and EBF servers as presented here are different from that in <ref> [37] </ref>. Specifically, whereas [37] characterizes the servers by the work done in a busy period, we characterize the servers by the time taken to serve packets of length w in a busy period. 112 5.2 Fairness Guarantee To derive fairness guarantee of SFQ, we need to prove a bound on j <p> Since a (C; 0) FC server is a constant rate server, the following analysis is also valid for constant rate servers. 2 The definitions of FC and EBF servers as presented here are different from that in <ref> [37] </ref>. Specifically, whereas [37] characterizes the servers by the work done in a busy period, we characterize the servers by the time taken to serve packets of length w in a busy period. 112 5.2 Fairness Guarantee To derive fairness guarantee of SFQ, we need to prove a bound on j W f (t <p> Hence, Theorem 5.4 can be used to determine the delay guarantee of the lower priority flows. Similarly, if the aggregate arrival process of the high priority flows can be modeled as poisson process, then the residual bandwidth can be modeled as EBF server <ref> [37] </ref> and Theorem 5.5 can be used to determine the delay guarantee. Theorem 5.4 demonstrates that maximum delay of a packet in SFQ is smaller than in SCFQ. <p> j ; b r j ) max fi m;K Since b r j b r j;n1 , from Theorem 5.8 we get: P (D n (p j ) &gt; fl) B n1 e fl n1 Hence D n is an Exponentially bounded random variable with parameters B n1 and n1 <ref> [37] </ref>. Similarly from Theorem 5.5, we know: P D K+1 (p j ) &gt; fl B K e fl K Hence, D K+1 (p j ) is an Exponentially Bounded variable with parameters B K and K .
Reference: [38] <author> Q. Ma, P. Steenkiste, and H. Zhang. </author> <title> Routing High-bandwidth Traffic in Max-min Fair Networks. </title> <booktitle> In Proceedings of SIGCOMM'96, </booktitle> <pages> pages 206217, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: It can be shown that the generalized FA class continues to remain fair. * The FA algorithms can be generalized to achieve prioritized fair allocation of residual bandwidth which may be desirable to support high throughput flows in max-min fair networks <ref> [38] </ref>. To achieve this objective, let the set of flows served by a server be partitioned into various priority classes.
Reference: [39] <author> E. M. McCreight. </author> <title> Priority Search Trees. </title> <journal> SIAM Journal on Computing, </journal> <volume> 14:257276, </volume> <year> 1985. </year>
Reference-contexts: Hence, in the worst-case, O (Q) computation may have to be performed in a single packet transmission time. This worst-case complexity can be reduced to O (logQ) by implementing the rate controllers and the GSQ and ASQ scheduling algorithms using a single augmented binary search tree <ref> [2, 7, 39] </ref>. We illustrate this implementation using an augmented red-black tree which is a balanced binary search tree [7]. To implement FA using a red-black tree, we assume that the GSQ scheduling algorithm assigns a priority value to each packet and schedules packets in increasing order of priority.
Reference: [40] <author> A.K. Mok, P. Amarsinghe, M. Chen, S. Sutanthavibul, and K. Tanstisirivat. </author> <title> Synthesis of a Real-Time Message Processing System with Data-driven Timing Constraints. </title> <booktitle> In IEEE 7th Real-Time Systems Symposium, </booktitle> <pages> pages 133143, </pages> <year> 1987. </year> <month> 205 </month>
Reference-contexts: Also, ^ l max is the maximum length of a packet fragment and C is the capacity of the server. Proof: The structure of the proof is similar to the proof of Theorem 1 of <ref> [40] </ref> and Theorem 1 of [42]. Observe that since PS and its equivalent PPS are work conserving, their busy periods are the same. Hence, it is sufficient to show that (2.5) holds for all the packets served in a busy period.
Reference: [41] <author> A. K. Parekh and R. G. Gallager. </author> <title> A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks: The Multiple Node Case. </title> <journal> IEEE/ACM Transactions On Networking, </journal> <volume> 2(2):137150, </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: We illustrate the end-to-end delay bound computation for flows conforming to leaky bucket. We demonstrate that our method for determining these bounds leads to tighter results (e.g., it improves upon the delay bound presented in <ref> [41] </ref> for flows conforming to leaky bucket in WFQ networks). Finally, based on the properties of GR class, we present architectural principles for designing networks that provide guaranteed deterministic QoS. <p> We illustrate the subtleties in (2.45) by comparing it with the seminal analysis presented in <ref> [41] </ref> for Rate Proportional Processor Sharing (RPPS) rate assignment of WFQ networks. The delay bound in [41] for a flow that conforms to leaky bucket with parameters (; r) and has minimum rate b r r assigned to the packets ( b r r) is: d j b r i=K1 X <p> We illustrate the subtleties in (2.45) by comparing it with the seminal analysis presented in <ref> [41] </ref> for Rate Proportional Processor Sharing (RPPS) rate assignment of WFQ networks. The delay bound in [41] for a flow that conforms to leaky bucket with parameters (; r) and has minimum rate b r r assigned to the packets ( b r r) is: d j b r i=K1 X l max + n=1 where l max is the maximum length of a packet of the
Reference: [42] <author> A.K. Parekh. </author> <title> A Generalized Processor Sharing Approach to Flow Control in Integrated Services Networks. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, MIT, </institution> <year> 1992. </year>
Reference-contexts: It is also applicable in networks with connectionless network layer such as Internet enhanced with resource reservation protocols such as RSVP [63]. To meet the QoS requirements of applications in an integrated services network, several packet scheduling algorithms have been designed <ref> [14, 21, 22, 30, 36, 42, 59, 61, 62, 64] </ref>. Since a detailed survey of these algorithms has been presented in [58], we review the algorithms only briefly. The design of a packet scheduling algorithm depends on the desired QoS. <p> However, this approach is not feasible when flows may have different packet length and a flow may have variable length packets <ref> [42, 50] </ref>. This limitation has been addressed by Deficit Round Robin scheduling algorithm presented in [50]. The principal advantage of these round based scheduling algorithms is that they are simple to implement. However, they can guarantee only a very large upper bound on packet delay. <p> Consequently, flow 1 will be unfairly penalized in the interval [1; 2] for using idle server resources in the interval [0; 1]. To address this limitation, fair algorithms have been designed <ref> [4, 12, 42, 22, 52] </ref>. Fair algorithms ensure that in any time interval in which two flows are backlogged, they receive service in proportion to their reserved rates. <p> Hence, in the example scenario a fair algorithm will serve equal number of packets of flows 1 and 2 in the interval [1; 2]. Several fair scheduling algorithms such as Weighted Fair Queuing (WFQ) [12] (also known as Packet-by-packet Generalized Processor Sharing <ref> [42] </ref>), Self Clocked Fair Queuing (SCFQ) [22], and Frame-based Fair Queuing (FFQ) [52] have been designed in the literature. <p> The work conserving algorithms can further be classified as either being fair or unfair. Table 1.1 summarizes this classification. To provide QoS guarantees to sources, several source traffic specifications also have been proposed. Examples include leaky bucket <ref> [9, 42] </ref>, Flow Specification [55], average and peak rate specification [14], Deterministic Bounding Interval Dependent model [35], and Exponentially Bounded Burstiness [56]. The QoS guarantees of a single server for different source traffic specifications and scheduling algorithms have been analyzed in the literature [9, 42]. <p> Examples include leaky bucket <ref> [9, 42] </ref>, Flow Specification [55], average and peak rate specification [14], Deterministic Bounding Interval Dependent model [35], and Exponentially Bounded Burstiness [56]. The QoS guarantees of a single server for different source traffic specifications and scheduling algorithms have been analyzed in the literature [9, 42]. The QoS guarantees provided by a single server have been extended to a network of servers [9, 10, 36, 42, 57]. A survey of single server and multiple server analysis techniques can be found in [58]. <p> The QoS guarantees of a single server for different source traffic specifications and scheduling algorithms have been analyzed in the literature [9, 42]. The QoS guarantees provided by a single server have been extended to a network of servers <ref> [9, 10, 36, 42, 57] </ref>. A survey of single server and multiple server analysis techniques can be found in [58]. There are two main limitations of the existing work on packet scheduling algorithms: * The scheduling algorithms have been analyzed only for a restricted set of source traffic characterizations. <p> Furthermore, most of them have been analyzed assuming that all the flows conform to their declared specifications. Finally, the analyses of a network of servers assumes that the same scheduling algorithm is employed at each of the servers <ref> [9, 10, 36, 42, 57] </ref>. In an integrated services network, sources have widely different characteristics and may not conform to their advertised specifications. Furthermore, since the 10 network may be part of several autonomous administrative domains, different scheduling algorithms may be employed at different servers. <p> Hence, even though packet scheduling algorithms are inherently non-preemptive in nature, to show that a scheduling algorithm belongs to GR, we employ a proof methodology, similar to the methodology in <ref> [27, 42] </ref>, in which we first prove a bound on the departure time of a packet in preemptive scheduling algorithm, and then use a relationship between the departure times of a packet in equivalent preemptive and non-preemptive scheduling algorithm. <p> Also, ^ l max is the maximum length of a packet fragment and C is the capacity of the server. Proof: The structure of the proof is similar to the proof of Theorem 1 of [40] and Theorem 1 of <ref> [42] </ref>. Observe that since PS and its equivalent PPS are work conserving, their busy periods are the same. Hence, it is sufficient to show that (2.5) holds for all the packets served in a busy period. <p> Hence, ^ L P S (p j ) t 0 + k2S C 24 Theorem 2.1 is superficially similar to Theorem 1 of <ref> [42] </ref> and its generalization in [17] which demonstrate that if a scheduling algorithm satisfies some assumptions, then the departure time of a packet in a non-preemptive scheduling algorithm is at most ^ l max C more than its departure time in a preemptive scheduling algorithm. <p> Some of the algorithms that we will be considering (for example, Virtual Clock) do not satisfy the assumptions required in those theorems. Furthermore, Theorem 2.1 proves a weaker result, which suffices for our purpose, then the results in <ref> [17, 42] </ref>. Specifically, whereas the results in [17, 42] bound the difference in departure time of a packet in a preemptive and non-preemptive scheduling algorithm, Theorem 2.1 relates the departure time of a packet in a non-preemptive algorithm to the bound on the departure time of the packet in a preemptive <p> Some of the algorithms that we will be considering (for example, Virtual Clock) do not satisfy the assumptions required in those theorems. Furthermore, Theorem 2.1 proves a weaker result, which suffices for our purpose, then the results in <ref> [17, 42] </ref>. Specifically, whereas the results in [17, 42] bound the difference in departure time of a packet in a preemptive and non-preemptive scheduling algorithm, Theorem 2.1 relates the departure time of a packet in a non-preemptive algorithm to the bound on the departure time of the packet in a preemptive scheduling algorithm. <p> Hence, Virtual Clock, WFQ, and SCFQ also belong the GR class. These algorithms have different delay and fairness properties as well as implementation complexity, and hence demonstrate that the GR class is broad (an exposition of these algorithms along these dimensions can be found in <ref> [22, 42] </ref>). We will analyze the algorithms assuming that rate allocation may vary with every packet. However, a particular network architecture may choose to allocate variable rate for every message [36], in response to change in reservation [28, 25], or employ some other policy. <p> Generalized Virtual Clock does not have such a requirement, and hence reduces the implementation complexity. Weighted Fair Queuing Weighted Fair Queuing (WFQ) scheduling algorithm is a practical realization of Generalized Processor Sharing (GPS) service discipline [12] (WFQ is also known 28 as Packet-by-packet Generalized Processor Sharing (PGPS) <ref> [42] </ref>). We first show that GPS be- longs to GR and then show that a generalized virtual time implementation of WFQ belongs to GR. GPS is a fluid flow service discipline in which flows receive service in infinitesimally divisible units. <p> From (2.9) and (2.4), it can be shown that L i j j j;i Hence, GPS belongs to GR. We now define a virtual time implementation of packet-by-packet GPS which is a generalization of the implementation in <ref> [42] </ref>. Let v i (t) be the virtual time associated with server i at time t. Let v i (0) = 0 and v i (t) not change when no packet is backlogged. <p> Since v i (t) is monotonically increasing, packets leave a GPS server in the increasing order of finish tag. Hence, a scheduling algorithm that schedules packets in increasing order of the finish tags will simulate GPS. However, as WFQ is non-preemptive, from (2.10) and Theorem 1 of <ref> [42] </ref>, we get L i j j j;i l i C i Hence, WFQ scheduling algorithm belongs to GR for flow f with fi i = l i C i . <p> Similarly, Theorem 1 of <ref> [42] </ref> can be generalized in a manner analogous to Theorem 1 to show that partially-preemptive WFQ also belongs to GR with fi i = ^ l i max . 2.2.4.2 Effect of Rate Control It has been observed that if a network employs a work-conserving scheduling algorithm, then the burstiness of <p> To derive the delay guarantee of a network of servers, we will first relate the guaranteed rate clock value of a packet at two adjacent servers. A similar approach of analyzing two adjacent servers to analyze end-to-end behaviour of a network of servers has been used in <ref> [8, 42] </ref>. <p> We now illustrate the delay bound computation for flows conforming to leaky bucket which is a deterministic specification. Leaky bucket is used to specify the traffic characteristics of sources that transmit at an average rate but may deviate from it for short durations <ref> [42] </ref>. <p> over-booking may yield persistent congestion, a network should provide some QoS guarantees even in the presence of congestion. 95 Unfair scheduling algorithms, such as Virtual Clock [62], Delay EDD [61], etc., penalize flow for use of idle bandwidth and do not provide bandwidth allocation guarantee in the presence of congestion <ref> [42] </ref>. Fair scheduling algorithms, on the other hand, guarantee that, regardless of prior usage or congestion, bandwidth would be allocated fairly [42]. Hence, fair scheduling algorithms are desirable for video applications. * Data applications: To support low-throughput, interactive data applications (e.g., telnet), scheduling algorithms must provide low average delay. <p> algorithms, such as Virtual Clock [62], Delay EDD [61], etc., penalize flow for use of idle bandwidth and do not provide bandwidth allocation guarantee in the presence of congestion <ref> [42] </ref>. Fair scheduling algorithms, on the other hand, guarantee that, regardless of prior usage or congestion, bandwidth would be allocated fairly [42]. Hence, fair scheduling algorithms are desirable for video applications. * Data applications: To support low-throughput, interactive data applications (e.g., telnet), scheduling algorithms must provide low average delay. <p> In the next section, we examine these algorithms to determine if they meet the requirements for a suitable scheduling algorithm. 4.4 Evaluation of Existing Algorithms The earliest known fair scheduling algorithm is Weighted Fair Queuing (WFQ) [12] (also re ferred to as Packet-by-Packet Generalized Processor Sharing (PGPS) <ref> [42] </ref>). WFQ was designed to emulate a hypothetical bit-by-bit weighted round robin server in which the number of bits of a flow served in a round is proportional to the weight of the flow (such a server is also known as GPS server). <p> of a scheduling algorithm is to provide pre-specified bounds on packet delay, it may be desirable to employ: * Scheduling algorithms that allocate only rate and have delay guarantee similar to Weighted Fair Queuing (WFQ): Several fair algorithms that have delay guarantee similar to WFQ are known (for example, WFQ <ref> [12, 42] </ref>, FFQ [52], WF 2 Q [4], WF 2 Q+ [3], Leap Forward Virtual Clock [53], etc.).
Reference: [43] <author> S. A. Rago. </author> <title> Unix System V Network Programming. </title> <publisher> Addison-Wesley, </publisher> <year> 1993. </year>
Reference-contexts: We first describe our implementation in Section 7.5.1 and then present experimental results from the implementation in Section 7.5.2. 7.5.1 Implementation To understand our implementation, first briefly consider a networking subsystem implemented using the streams architecture <ref> [43] </ref>. In streams architecture, a packet is processed by a sequence of modules (see Figure 7.2). The terminating module is called a driver. Hence, the module for a network interface card is a driver. The interaction between modules occurs through queues.
Reference: [44] <author> S. Shenker. </author> <title> A Theoretical Analysis of Feedback Flow Control. </title> <booktitle> In Proceedings of ACM SIGCOMM'90, </booktitle> <pages> pages 156165, </pages> <year> 1990. </year>
Reference-contexts: On the other hand, to support throughput-intensive flow-controlled applications in heterogeneous, large-scale, decentralized networks, scheduling algorithms must allocate bandwidth fairly [12, 33, 45]. Fair allocation of bandwidth at each server enables a network to achieve max-min fair allocation of network bandwidth in heterogeneous environments <ref> [12, 44] </ref>. Due to the coexistence of VBR video sources and data sources in integrated services networks, the bandwidth available to data applications may vary significantly over time. Consequently, the effective capacity of a server for data applications may vary over time.
Reference: [45] <author> S. Shenker. </author> <title> Making Greed Work in Networks: A Game-Theoretic Analysis of Switch Service Disciplines. </title> <booktitle> In Proceedings of ACM SIGCOMM'94, </booktitle> <pages> pages 4757, </pages> <year> 1994. </year>
Reference-contexts: Furthermore, it ensures that a source receives service as per its reservation. In case of closed-loop control, scheduling algorithms enable: (1) fair allocation of network resources; (2) network state estimation; and (3) coexistence of different feedback control algorithms <ref> [32, 45] </ref>. Thus, packet and buffer scheduling algorithms enable a network to not only deliver different QoS to different sources, but also meet the QoS requirements of individual sources. Hence, packet and buffer scheduling algorithms are central to the realization of integrated services networks. <p> Isolation of flows enables a network to provide stronger guarantees and is highly desirable, especially in large heterogeneous networks where sources may be malicious <ref> [6, 12, 36, 45] </ref>. Thus, GR class has desirable properties. In the following subsections, we show that many of the work conserving as well as non-work conserving scheduling algorithms that either allocate only rate or separate rate and delay allocation belong to GR. <p> Hence, fair scheduling algorithms are desirable for video applications. * Data applications: To support low-throughput, interactive data applications (e.g., telnet), scheduling algorithms must provide low average delay. On the other hand, to support throughput-intensive flow-controlled applications in heterogeneous, large-scale, decentralized networks, scheduling algorithms must allocate bandwidth fairly <ref> [12, 33, 45] </ref>. Fair allocation of bandwidth at each server enables a network to achieve max-min fair allocation of network bandwidth in heterogeneous environments [12, 44].
Reference: [46] <author> S. Shenker. </author> <title> Contribution to the Int-serv mailing list. </title> <month> July </month> <year> 1995. </year>
Reference-contexts: Furthermore, a network may be able to achieve better statistical multiplexing of best effort packets and thereby achieve higher overall throughput <ref> [46] </ref>. Finally, a network that supports deterministic service as well as a service that provides guaranteed throughput, but not delay, may be able to employ additional buffer to increase its overall utilization [18]. 3.2 Relative Merits of Algorithm in GR The GR class contains algorithms with different properties. <p> In such a case, since the overall system is work conserving, a network may be able to achieve better statistical multiplexing of best effort packets and thereby achieve higher overall throughput <ref> [46] </ref>. Now, consider the incentives for a source and a network for the two transmission methods. Since work conserving behaviour is desirable from a networks perspective, a network has incentives to accept bursts.
Reference: [47] <author> S. Shenker. </author> <title> Fundamental Design Issues for the Future Internet. </title> <journal> IEEE Journal of Selected Areas in Communications, </journal> <volume> 13:11761188, </volume> <month> September </month> <year> 1995. </year>
Reference-contexts: From small networks connecting few computers, the largest computer network, the Internet, has evolved into a network connecting more than a million computers <ref> [47] </ref>. Conventionally, these networks have provided a best-effort service. In best-effort service, a network does not guarantee whether and when a packet will be delivered. <p> Since the network layer of OSI architecture defines the services exported by a network against which the applications are programmed, the most significant and long lasting changes are required at the network layer <ref> [47] </ref>. A fundamental problem at the network layer is to meet the QoS requirements of packet sources, i.e., avoid congestion [32]. To control packet delay and loss, and thus avoid congestion, a network has to manage two resources: link bandwidth and buffers at each packet-switch. <p> To allocate link bandwidth hierarchically, we employ SFQ and FA and develop Hierarchical SFQ and FA scheduling algorithms. Hierarchical SFQ and FA enable a network to provide a link-sharing service and manage heterogeneity in services and protocols <ref> [47] </ref>. These algorithms allow different scheduling algorithms to be employed for the leaf classes of a hierarchy. We develop a technique for analyzing the performance guarantees of Hierarchical SFQ and FA. <p> An integrated services network will support a link-sharing service in which the bandwidth of a link is allocated among several organizations and the bandwidth of an organization is recursively allocated among its suborganizations <ref> [15, 47] </ref>. The bandwidth of an organization is allocated among the suborganizations in proportion to the weights of the suborganizations. The weights may be governed by the price paid by the various suborganizations or other policies [15]. <p> The weights may be governed by the price paid by the various suborganizations or other policies [15]. Such a link-sharing service has been considered to be the most important service enhancement that is required in current Internet <ref> [47] </ref>. Link-sharing can be naturally supported by hierarchical link bandwidth allocation mechanism. Thus, hierarchical link bandwidth allocation is desirable for supporting link sharing service and a packet scheduling algorithm should enable it. * It should be computationally efficient.
Reference: [48] <author> S. Shenker and C. Partridge. </author> <title> Specification of Guaranteed Quality of Service. </title> <note> Available via anonymous ftp from ftp://ftp.ietf.cnri.reston.va.us/internet-drafts/draft-ietf-intserv-guaranteed-svc-03.txt, </note> <month> November </month> <year> 1995. </year>
Reference-contexts: Buffer required due to the increase in burstiness of a flow at downstream servers: This component at a server is dependent on the rate reservation at upstream servers and can be determined without traffic specification (an example method for deter mining this component is presented in <ref> [48] </ref>).
Reference: [49] <author> S. Shenker, L. Zhang, and D. Clark. </author> <title> A Scheduling Service Model and a Scheduling Architecture for an Integrated Services Packet Networks. </title> <note> Available via anonymous ftp from ftp://ftp.parc.xerox.com/pub/archfin.ps, </note> <year> 1995. </year>
Reference-contexts: Since these services as well as the protocols may be incompatible with each other, a mechanism that provides isolation between different services and protocols and enables their coexistence is required. Hierarchical link bandwidth allocation is one possible mechanism for managing heterogeneity in integrated services networks <ref> [15, 49] </ref>. In hierarchical link bandwidth alloca 97 tion, link bandwidth is allocated to a set of classes. The classes, in turn, recursively allocate the bandwidth among their subclasses. A class ensures that each of its sub-classes receives a minimum requested bandwidth. <p> Thus, WFQ is unsuitable for achieving fairness over variable rate servers. As we will show in Chapter 7, to be useful for hierarchical link bandwidth allocation <ref> [15, 49] </ref>, a scheduling algorithm must provide fairness over variable rate servers. Consequently, WFQ is unsuitable for meeting two key requirements (i.e., fairness over variable rate servers and support for hierarchical link bandwidth allocation) of a fair scheduling algorithm for integrated services network. <p> m )+ Fluctuation Constrained Required (fi max m ) + 2* Table 8.1: Fairness property of SFQ and FA flows and allocates the residual bandwidth fairly among best-effort flow controlled flows or hierarchically allocates it among best-effort flows belonging to various administrative domains (this is the scheduling architecture articulated in <ref> [49] </ref>).
Reference: [50] <author> M. Shreedhar and G. Varghese. </author> <title> Efficient Fair Queuing Using Deficit Round Robin. </title> <booktitle> In Proceedings of ACM SIGCOMM'95, </booktitle> <pages> pages 231242, </pages> <year> 1995. </year>
Reference-contexts: However, this approach is not feasible when flows may have different packet length and a flow may have variable length packets <ref> [42, 50] </ref>. This limitation has been addressed by Deficit Round Robin scheduling algorithm presented in [50]. The principal advantage of these round based scheduling algorithms is that they are simple to implement. However, they can guarantee only a very large upper bound on packet delay. <p> However, this approach is not feasible when flows may have different packet length and a flow may have variable length packets [42, 50]. This limitation has been addressed by Deficit Round Robin scheduling algorithm presented in <ref> [50] </ref>. The principal advantage of these round based scheduling algorithms is that they are simple to implement. However, they can guarantee only a very large upper bound on packet delay. <p> Similarly, since Deficit Round Robin (DRR <ref> [50] </ref>) also isolates flows and guarantees a minimum throughput, it can be shown that it also belongs to GR (although fi for DRR will be very high). Hence, the class of GR algorithms is broad. <p> Hence, per packet computational complexity is O (logQ) where Q is 106 the number of flows served by the server. To reduce this per packet computational complexity, Deficit Round Robin (DRR) was proposed in <ref> [50] </ref>. It is a derivative of weighted round robin algorithm designed to accommodate variable length packets of a flow. Though the per packet computational complexity of DRR is O (1) per packet and it is fair over variable rate servers, it has the following two limitations: 1.
Reference: [51] <author> D. Stiliadis. </author> <title> Traffic Scheduling in Packet-Switched Networks: Analysis, Design and Implementation. </title> <type> PhD thesis, </type> <institution> Department of Computer Science and Engineering, University of California at Santa Cruz, </institution> <year> 1996. </year> <month> 206 </month>
Reference-contexts: WF 2 Q+ has been recently, independent of our work, proposed to reduce the implementation complexity of WF 2 Q while retaining several of its properties (a similar, but not identical, algorithm termed Starting Potential based Fair Queuing was proposed in <ref> [51] </ref>) [3]. It defines start tag of packet p j f to be the finish tag of packet p j1 j j1 f ), if flow f is backlogged on arrival of p j f ; otherwise, S (p j f ) = maxfv (A (p j j1 f )g.
Reference: [52] <author> D. Stiliadis and A. Varma. </author> <title> Design and Analysis of Frame-based Fair Queueing: A New Traffic Scheduling Algorithm for Packet Switched Networks. </title> <booktitle> In Proceedings of SIGMET-RICS'96, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Consequently, flow 1 will be unfairly penalized in the interval [1; 2] for using idle server resources in the interval [0; 1]. To address this limitation, fair algorithms have been designed <ref> [4, 12, 42, 22, 52] </ref>. Fair algorithms ensure that in any time interval in which two flows are backlogged, they receive service in proportion to their reserved rates. <p> Several fair scheduling algorithms such as Weighted Fair Queuing (WFQ) [12] (also known as Packet-by-packet Generalized Processor Sharing [42]), Self Clocked Fair Queuing (SCFQ) [22], and Frame-based Fair Queuing (FFQ) <ref> [52] </ref> have been designed in the literature. These algorithms essentially emulate a hypothetical bit-by-bit round robin server in which the number of bits of a backlogged flow served in a round is proportional to the rate of the flow. <p> For example, since Frame-based Fair Queuing <ref> [52] </ref> and Worst-case Fair Weighted Fair Queuing [4] also guarantee that, regardless of behaviour of other flows in the network, the bound on departure time of a packet is the same as in WFQ, they also belong to GR. <p> Consequently, WFQ is unsuitable for meeting two key requirements (i.e., fairness over variable rate servers and support for hierarchical link bandwidth allocation) of a fair scheduling algorithm for integrated services network. Finally, WFQ does not have good fairness properties over constant rate servers. It has been shown in <ref> [52] </ref> that if all flows are continuously backlogged, then H (f; m) for WFQ is given as: max U m + f l max m l max + f ) where l max is the maximum packet length served by the server and U f = min (j Q j 1) <p> This may be unacceptably large in many cases. However, SCFQ is fair over variable rate servers. Frame-based Fair Queuing (FFQ), proposed in <ref> [52] </ref>, was designed to retain the efficiency of SCFQ in computing the start and finish tags but ensure that the worst-case delay that can be guaranteed to a packet is the same as in WFQ 2 . <p> which flows f and m are backlogged during the entire interval, the difference in the service received by two flows at a SFQ server is given as: j f W m (t 1 ; t 2 ) j f + m 115 Using Theorem 5.1 and the analysis presented in <ref> [52] </ref> we conclude that SFQ has unfair- ness measure that is at least as good as that of all the known scheduling algorithms. There are two important aspects of Theorem 5.1: * To establish it, we did not make any assumptions about the service rate of the server. <p> algorithm is to provide pre-specified bounds on packet delay, it may be desirable to employ: * Scheduling algorithms that allocate only rate and have delay guarantee similar to Weighted Fair Queuing (WFQ): Several fair algorithms that have delay guarantee similar to WFQ are known (for example, WFQ [12, 42], FFQ <ref> [52] </ref>, WF 2 Q [4], WF 2 Q+ [3], Leap Forward Virtual Clock [53], etc.). As demonstrated in Chapter 4, most of these algorithms are either unfair over variable rate servers or require the number of bits transmitted to be counted to achieve fairness over variable rate servers.
Reference: [53] <author> S. Suri, G. Varghese, and G. Chandramenon. </author> <title> Leap Forward Virtual Clock: A New Fair Queuing Scheme with Guaranteed Delays and Throughput fairness. </title> <booktitle> In Proceedings of INFOCOM'97, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: The key contributions of the GR framework are: (1) it decouples service guarantee provided by a network from source traffic characterization, and (2) it is the first framework that tightly analyzes heterogeneous networks. This framework is now being employed by other researchers to analyze new scheduling algorithms <ref> [53] </ref>. To gain a further understanding of the GR class, we evaluate the completeness and relative merits of algorithms in GR. * Completeness of GR: Though GR does not contain all the algorithms, we experimentally demonstrate that it does not lead to loss in achievable utilization of a network. <p> Furthermore, it may not be feasible to employ admission control when minimum server capacity is zero. Hence, a scheduling algorithm that does not require P n2Q i C is desirable. Recently, Leap Forward Virtual Clock has been proposed in <ref> [53] </ref>. This algorithm also assumes constant rate servers, and hence may not be fair over variable rate servers. However, it has lower implementation complexity than most of the fair algorithms proposed in the literature. <p> to employ: * Scheduling algorithms that allocate only rate and have delay guarantee similar to Weighted Fair Queuing (WFQ): Several fair algorithms that have delay guarantee similar to WFQ are known (for example, WFQ [12, 42], FFQ [52], WF 2 Q [4], WF 2 Q+ [3], Leap Forward Virtual Clock <ref> [53] </ref>, etc.). As demonstrated in Chapter 4, most of these algorithms are either unfair over variable rate servers or require the number of bits transmitted to be counted to achieve fairness over variable rate servers. <p> The key contributions of the GR framework are: (1) it decouples service guarantee provided by a network from source traffic characterization, and (2) it is the first framework that tightly analyzes heterogeneous networks. This framework is now being employed by other researchers to analyze new scheduling algorithms <ref> [53] </ref>. To gain a further understanding of the GR class, we evaluated the completeness and relative merits of algorithms in GR. * Completeness of GR: Though GR does not contain all the algorithms, we experimentally demonstrated that it does not lead to loss in achievable utilization of a network.
Reference: [54] <author> J. Wroclawski. </author> <title> Specification of Controlled-load Network Element Service. </title> <note> Available via anonymous ftp from ftp://ftp.ietf.cnri.reston.va.us/internet-drafts/draft-ietf-intserv-ctrl-load-svc-09.txt,, </note> <month> June </month> <year> 1996. </year>
Reference-contexts: Similarly, whereas a network will not overbook resources while providing deterministic services, it may overbook resources when providing services with weaker guarantees such as controlled load service defined in <ref> [54] </ref>. Since these services as well as the protocols may be incompatible with each other, a mechanism that provides isolation between different services and protocols and enables their coexistence is required. Hierarchical link bandwidth allocation is one possible mechanism for managing heterogeneity in integrated services networks [15, 49].
Reference: [55] <author> G.G. Xie and S.S. Lam. </author> <title> Delay Guarantee of Virtual Clock Server. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 3(6):683689, </volume> <month> December </month> <year> 1995. </year>
Reference-contexts: Similarly, the priority of j th packet of flow 2 (j 10) is 1 + j. It has been shown that Virtual Clock guarantees that departure time of a packet is at most a constant more than the departure time in a server of rate r f <ref> [55] </ref>. There are two main limitations of the Virtual Clock scheduling algorithm: Unfairness: Consider the previous example. Since the server capacity is 6pkts=s, the first 6 packets of flow 1 will be serviced by time 1. Now, consider the time interval [1; 2]. <p> The work conserving algorithms can further be classified as either being fair or unfair. Table 1.1 summarizes this classification. To provide QoS guarantees to sources, several source traffic specifications also have been proposed. Examples include leaky bucket [9, 42], Flow Specification <ref> [55] </ref>, average and peak rate specification [14], Deterministic Bounding Interval Dependent model [35], and Exponentially Bounded Burstiness [56]. The QoS guarantees of a single server for different source traffic specifications and scheduling algorithms have been analyzed in the literature [9, 42]. <p> We present an overview of the results and organization of this chapter in the next section. 2.1 Overview of Results The class of GR scheduling algorithms guarantees a deadline (referred to as delay guarantee) to a packet based on its expected arrival time (the delay guarantee term was introduced in <ref> [55] </ref>). The delay guarantee of these algorithms is independent of a traffic specification and the behaviour of other flows at the server. This enables a single server employing a scheduling algorithm in GR to isolate flows as well as provide service guarantees to flows conforming to any specification. <p> Thus, the scheduling algorithms in GR guarantee a bound on departure time of a packet based on the expected arrival time of the packet. Such a guarantee is referred to as delay guarantee <ref> [55] </ref>. The definition of guaranteed rate clock assumes that a fixed rate is allocated to packets of a flow. However, to efficiently support variable bit rate flows such as video, a packet scheduling algorithm may allocate variable rates to the packets of a flow.
Reference: [56] <author> O. Yaron and M. Sidi. </author> <title> Performance and Stability of Communication Networks via Robust Exponential Bounds. </title> <journal> In IEEE/ACM Transactions on Networking, </journal> <volume> volume 1, </volume> <pages> pages 372 385, </pages> <year> 1993. </year>
Reference-contexts: Table 1.1 summarizes this classification. To provide QoS guarantees to sources, several source traffic specifications also have been proposed. Examples include leaky bucket [9, 42], Flow Specification [55], average and peak rate specification [14], Deterministic Bounding Interval Dependent model [35], and Exponentially Bounded Burstiness <ref> [56] </ref>. The QoS guarantees of a single server for different source traffic specifications and scheduling algorithms have been analyzed in the literature [9, 42]. The QoS guarantees provided by a single server have been extended to a network of servers [9, 10, 36, 42, 57]. <p> Similarly from Theorem 5.5, we know: P D K+1 (p j ) &gt; fl B K e fl K Hence, D K+1 (p j ) is an Exponentially Bounded variable with parameters B K and K . From <ref> [56] </ref> we know that sum of Exponentially Bounded variables D 1 ; :::; D K with parameters B 1 ; :::; B K and 1 ; :::; K is also an Exponentially Bounded variable with parameters P n=K and 1 P n . <p> From <ref> [56] </ref> we know that sum of Exponentially Bounded variables D 1 and D 2 with parameters B 1 ; B 2 and 1 ; 2 is also an Exponentially Bounded variable, regard less of any statistical dependence between D 1 and D 2 , with parameters B 1 + B 2
Reference: [57] <author> O. Yaron and M. Sidi. </author> <title> Generalized Processor Sharing Networks with Exponentially Bounded Burstiness Arrivals. </title> <booktitle> In Proceedings of INFOCOM'94, </booktitle> <year> 1994. </year>
Reference-contexts: The QoS guarantees of a single server for different source traffic specifications and scheduling algorithms have been analyzed in the literature [9, 42]. The QoS guarantees provided by a single server have been extended to a network of servers <ref> [9, 10, 36, 42, 57] </ref>. A survey of single server and multiple server analysis techniques can be found in [58]. There are two main limitations of the existing work on packet scheduling algorithms: * The scheduling algorithms have been analyzed only for a restricted set of source traffic characterizations. <p> Furthermore, most of them have been analyzed assuming that all the flows conform to their declared specifications. Finally, the analyses of a network of servers assumes that the same scheduling algorithm is employed at each of the servers <ref> [9, 10, 36, 42, 57] </ref>. In an integrated services network, sources have widely different characteristics and may not conform to their advertised specifications. Furthermore, since the 10 network may be part of several autonomous administrative domains, different scheduling algorithms may be employed at different servers.
Reference: [58] <author> H. Zhang. </author> <title> Service Disciplines For Guaranteed Performance Service in Packet-Switching Networks. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 83(10), </volume> <month> October </month> <year> 1995. </year>
Reference-contexts: To meet the QoS requirements of applications in an integrated services network, several packet scheduling algorithms have been designed [14, 21, 22, 30, 36, 42, 59, 61, 62, 64]. Since a detailed survey of these algorithms has been presented in <ref> [58] </ref>, we review the algorithms only briefly. The design of a packet scheduling algorithm depends on the desired QoS. <p> The QoS guarantees provided by a single server have been extended to a network of servers [9, 10, 36, 42, 57]. A survey of single server and multiple server analysis techniques can be found in <ref> [58] </ref>. There are two main limitations of the existing work on packet scheduling algorithms: * The scheduling algorithms have been analyzed only for a restricted set of source traffic characterizations. Furthermore, most of them have been analyzed assuming that all the flows conform to their declared specifications.
Reference: [59] <author> H. Zhang and D. Ferrari. </author> <title> Rate Controlled Static Priority Queueing. </title> <booktitle> In Proceedings of INFOCOM'93, </booktitle> <volume> volume 2, </volume> <pages> pages 227236, </pages> <year> 1993. </year>
Reference-contexts: It is also applicable in networks with connectionless network layer such as Internet enhanced with resource reservation protocols such as RSVP [63]. To meet the QoS requirements of applications in an integrated services network, several packet scheduling algorithms have been designed <ref> [14, 21, 22, 30, 36, 42, 59, 61, 62, 64] </ref>. Since a detailed survey of these algorithms has been presented in [58], we review the algorithms only briefly. The design of a packet scheduling algorithm depends on the desired QoS. <p> For example, a static priority GSQ scheduler is more efficient than a Delay EDD scheduler. However, whereas the former can support only predetermined set of delay vectors, the latter can support any <ref> [59] </ref>. * The concept of Fair Airport algorithm is general. The rate controller can be generalized as in [19] to enforce different traffic constraints.
Reference: [60] <author> H. Zhang and D. Ferrari. </author> <title> Rate-controlled Service Disciplines. Journal of High Speed Networks, </title> <address> 3(4):389412, </address> <year> 1994. </year>
Reference-contexts: Some non-work conserving scheduling algorithms serve a packet from a flow only at predetermined time instants. Examples of such algorithms include Hierarchical Round Robin and Stop-and-go Queuing [21, 61]. Other non-work conserving algorithms service a packet only after it becomes eligible <ref> [60] </ref>. Several eligibility notions have been defined [60]. One of the simplest notions is to consider a packet eligible at the time at which it would have arrived if the flow was transmitting exactly at the reserved rate. <p> Some non-work conserving scheduling algorithms serve a packet from a flow only at predetermined time instants. Examples of such algorithms include Hierarchical Round Robin and Stop-and-go Queuing [21, 61]. Other non-work conserving algorithms service a packet only after it becomes eligible <ref> [60] </ref>. Several eligibility notions have been defined [60]. One of the simplest notions is to consider a packet eligible at the time at which it would have arrived if the flow was transmitting exactly at the reserved rate. To illustrate, consider a flow that has reserved rate 1pkt=s and sends 5 packets at time 0. <p> Then, the first packet will be eligible at time 0, second at time 1s, third at time 2s, and so on. This is the concept of eligibility employed by Rate Controlled Static Priority Queuing (RCSP) <ref> [60] </ref>. The non-work conserving algorithms may either allocate only rate or achieve separation of rate and delay allocation. Examples of algorithms that allocate only rate include Hierarchical Round Robin and Stop-and-go Queuing. Examples of algorithms that achieve separation of rate and delay allocation include RCSP and Jitter EDD [61]. <p> used, then one can similarly show that fi i is given as fi i = ( r i d i 2.2.3 Non-Work Conserving Algorithms A general framework for reasoning about the end-to-end performance guarantee of a class of non-work conserving algorithms termed Rate Controlled Service Disciplines has been presented in <ref> [60] </ref>. In this section, we show that some of the rate controlled service disciplines also belong to the GR class. Rate controlled service disciplines consist of a rate controller and a scheduler (see Figure 2.3). <p> Several 37 non-work conserving scheduling algorithms have been proposed to address this limitation <ref> [19, 60] </ref>. Though non-work conserving algorithms reduce the buffer requirement in the network, they increase the average delay for all the flows. Even though this may be desirable for some flows, it may not be desirable for other flows. <p> RCSD class contains work conserving as well as non-work conserving algorithms (see <ref> [19, 60] </ref> for some examples). <p> We address this limitation in this chapter by designing a class of Fair Airport (FA) algorithms. An algorithm in FA class combines SFQ with a non-work conserving algorithm in Rate Controlled Service Discipline (RCSD) class <ref> [19, 60] </ref>. We derive fairness and deadline guarantees for FA servers and demonstrate that by appropriately choosing an algorithm from RCSD class, algorithms that either allocate only rate or achieve separation of rate and delay allocation and are fair over Fluctuation Constrained variable rate servers can be designed. <p> Finally, Section 6.7 summarizes the results of this chapter. 6.1 Design of Fair Airport Scheduling Algorithms To gain an intuitive understand the design of Fair Airport 1 scheduling algorithms, consider the class of Rate Controlled Service Disciplines (RCSD) <ref> [19, 60] </ref>. A RCSD scheduling algorithm employs a rate controller (also referred to as a shaper) for each flow (see Figure 6.1).
Reference: [61] <author> H. Zhang and S. Keshav. </author> <title> Comparison of Rate-Based Service Disciplines. </title> <booktitle> In Proceedings of ACM SIGCOMM, </booktitle> <pages> pages 113121, </pages> <month> August </month> <year> 1991. </year> <month> 207 </month>
Reference-contexts: It is also applicable in networks with connectionless network layer such as Internet enhanced with resource reservation protocols such as RSVP [63]. To meet the QoS requirements of applications in an integrated services network, several packet scheduling algorithms have been designed <ref> [14, 21, 22, 30, 36, 42, 59, 61, 62, 64] </ref>. Since a detailed survey of these algorithms has been presented in [58], we review the algorithms only briefly. The design of a packet scheduling algorithm depends on the desired QoS. <p> If the flow desires delay of 0:5s, its rate reservation would have to be increased to 2pkt=s. This inverse relationship between delay and rate reservation may lead to inefficient utilization of resources <ref> [61] </ref>. Thus, scheduling algorithms that achieve separation of rate and delay allocation have been designed. An example of such an algorithm is Delay EDD [13]. The algorithms that we have considered so far service a packet whenever a packet is backlogged at the server, i.e., they are are work conserving. <p> Some non-work conserving scheduling algorithms serve a packet from a flow only at predetermined time instants. Examples of such algorithms include Hierarchical Round Robin and Stop-and-go Queuing <ref> [21, 61] </ref>. Other non-work conserving algorithms service a packet only after it becomes eligible [60]. Several eligibility notions have been defined [60]. <p> The non-work conserving algorithms may either allocate only rate or achieve separation of rate and delay allocation. Examples of algorithms that allocate only rate include Hierarchical Round Robin and Stop-and-go Queuing. Examples of algorithms that achieve separation of rate and delay allocation include RCSP and Jitter EDD <ref> [61] </ref>. The concept of fairness is not applicable for non-work conserving algorithms. The principal advantage of the non-work conserving algorithms is that they maintain the smoothness of a flow and thus reduce the buffer requirement for a flow in the network. <p> Let expected arrival time of a packet be the time at which it begins service in a server of rate r i f . Then, expected arrival time of p j f , denoted by EAT i (p j f ), is defined as <ref> [61] </ref>: EAT i (p f ; r i f ) = maxfA i (p j j1 f ) + j1 r i g (2.1) where EAT i (p 0 f ; r i l 0 r i = 0. <p> Since such over-booking may yield persistent congestion, a network should provide some QoS guarantees even in the presence of congestion. 95 Unfair scheduling algorithms, such as Virtual Clock [62], Delay EDD <ref> [61] </ref>, etc., penalize flow for use of idle bandwidth and do not provide bandwidth allocation guarantee in the presence of congestion [42]. Fair scheduling algorithms, on the other hand, guarantee that, regardless of prior usage or congestion, bandwidth would be allocated fairly [42].
Reference: [62] <author> L. Zhang. VirtualClock: </author> <title> A New Traffic Control Algorithm for Packet Switching Net--works. </title> <booktitle> In Proceedings of ACM SIGCOMM'90, pages 1929, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: The sequence of packets transmitted by a source to a sink is referred to as a flow <ref> [62] </ref>. We use the term flow synonymously with a connection. A flow is serviced by a fixed sequence of packet-switches (packet-switch is used synonymously with a router). For simplicity of analysis, packet-switches are assumed to be output buffered. <p> It is also applicable in networks with connectionless network layer such as Internet enhanced with resource reservation protocols such as RSVP [63]. To meet the QoS requirements of applications in an integrated services network, several packet scheduling algorithms have been designed <ref> [14, 21, 22, 30, 36, 42, 59, 61, 62, 64] </ref>. Since a detailed survey of these algorithms has been presented in [58], we review the algorithms only briefly. The design of a packet scheduling algorithm depends on the desired QoS. <p> One possible priority assignment for the packets of a flow is their departure time in a server of rate r f . This priority assignment results in the Virtual Clock scheduling algorithm <ref> [62] </ref>. To illustrate the priority assignment in Virtual Clock, consider a server of capacity 6pkts=s that is serving flows 1 and 2 with reserved rate 1pkt=s. Let flows flows 1 and 2 send 10 packets at time 0 and 1, respectively. <p> j f , denoted as GRC i (p j j;i f ), is given as follows: GRC i (p f ; r f ) = maxfA i (p j j1 j1;i l f j;i j 1 (2.4) 1 The definition of guaranteed rate clock is the same as virtual clock <ref> [62] </ref>. We have coined a new term for the virtual clock concept to differentiate between the general concept of virtual clock and as it relates to the Virtual Clock scheduling algorithm. 20 where GRC i (p 0 f ; r f ) = 0 2 . <p> However, a particular network architecture may choose to allocate variable rate for every message [36], in response to change in reservation [28, 25], or employ some other policy. Virtual Clock We define generalized Virtual Clock (VC) scheduling algorithm analogous to the Virtual Clock algorithm <ref> [62] </ref>. The generalized VC algorithm is defined as follows: 1. <p> Since such over-booking may yield persistent congestion, a network should provide some QoS guarantees even in the presence of congestion. 95 Unfair scheduling algorithms, such as Virtual Clock <ref> [62] </ref>, Delay EDD [61], etc., penalize flow for use of idle bandwidth and do not provide bandwidth allocation guarantee in the presence of congestion [42]. Fair scheduling algorithms, on the other hand, guarantee that, regardless of prior usage or congestion, bandwidth would be allocated fairly [42].
Reference: [63] <author> L. Zhang, S.E. Deering, D. Estrin, S. Shenker, and D. Zappala. RSVP: </author> <title> A New Resource ReSerVation Protocol. </title> <journal> IEEE Network, </journal> <volume> 7(5):818, </volume> <month> September </month> <year> 1993. </year>
Reference-contexts: We assume that per-flow state is available at each packet switch. This assumption holds for networks with connection oriented network layer such as Asynchronous Transfer Mode (ATM). It is also applicable in networks with connectionless network layer such as Internet enhanced with resource reservation protocols such as RSVP <ref> [63] </ref>. To meet the QoS requirements of applications in an integrated services network, several packet scheduling algorithms have been designed [14, 21, 22, 30, 36, 42, 59, 61, 62, 64]. Since a detailed survey of these algorithms has been presented in [58], we review the algorithms only briefly. <p> the second component, at each server. * A source should be able to request a network to employ rate controllers: As Theorem 2.5 illustrates, in GR networks the worst case delay of packet does not change when one or 5 In reservation setup protocols like RSVP, sinks initiate the reservation <ref> [63] </ref>. However, for the purpose of this discussion, this distinction does not make any difference. 58 more servers on the path of a flow employ a rate controller.
Reference: [64] <author> Q. Zheng and K. Shin. </author> <title> On the Ability of Establishing Real-Time Channels in Point-to-Point Packet-switching Networks. </title> <journal> IEEE Transactions on Communications, </journal> <volume> 42(3):1096 1105, </volume> <month> March </month> <year> 1994. </year> <month> 208 </month>
Reference-contexts: It is also applicable in networks with connectionless network layer such as Internet enhanced with resource reservation protocols such as RSVP [63]. To meet the QoS requirements of applications in an integrated services network, several packet scheduling algorithms have been designed <ref> [14, 21, 22, 30, 36, 42, 59, 61, 62, 64] </ref>. Since a detailed survey of these algorithms has been presented in [58], we review the algorithms only briefly. The design of a packet scheduling algorithm depends on the desired QoS. <p> Packets are served in the increasing order of deadline. It was shown in <ref> [13, 64] </ref> that if certain schedulability conditions are met and the mini mum inter-arrival time of packets is at least l f f , then a packet would depart by D i (p j f ). <p> However, in a networking environment even if the minimum inter-arrival time is at least l f f at the network entry point, it may become smaller than l f f at a server which is downstream on the path of a flow. This problem was addressed in <ref> [31, 64] </ref> by requiring the clocks of the servers to be synchronized. We demonstrate that this is an unnecessary restriction by proving that regardless of the inter-arrival time of packets, preemptive Delay EDD guarantees that packet p j f will be transmitted by D i (p j f ). <p> Due to high computational complexity, it may not be feasible to employ (2.16) as schedulability test. Hence, conditions stronger than (2.16) which have lower computational complexity have been developed in <ref> [64] </ref>. Clearly, the theorem holds under the stronger conditions developed in [64] as well. <p> Due to high computational complexity, it may not be feasible to employ (2.16) as schedulability test. Hence, conditions stronger than (2.16) which have lower computational complexity have been developed in <ref> [64] </ref>. Clearly, the theorem holds under the stronger conditions developed in [64] as well. Since Delay EDD guarantees that packet p j f will be transmitted by D i (p j f ) regardless of the arrival pattern of the packets, the following corollary is immediate from Theorem 2.1 and Theorem 2.4. <p> Hence, they may lead to higher achievable utilization of a network. On the other hand, the time-complexity of admission control for these algorithms is O (N ) where N is the number of flows at a server <ref> [64] </ref>. The experiments presented in Sections 3.1.3.1 and 3.1.3.2 demonstrate that rate-and-delay allocation algorithms in fact lead to higher utilization of a network. Hence, they are desirable. <p> Due to high computational complexity, it may not be feasible to employ (6.19) as the schedulability test. Hence, conditions stronger than (6.19) that have lower computational complexity have been developed in <ref> [64] </ref>. The delay guarantee holds under the stronger conditions as well.
References-found: 64

