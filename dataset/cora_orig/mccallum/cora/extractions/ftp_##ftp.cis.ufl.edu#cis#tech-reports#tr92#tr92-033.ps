URL: ftp://ftp.cis.ufl.edu/cis/tech-reports/tr92/tr92-033.ps
Refering-URL: http://www.cis.ufl.edu/tech-reports/tech-reports/tr92-abstracts.html
Root-URL: http://www.cis.ufl.edu
Title: Lazy Updates for Distributed Search Structures  
Author: Theodore Johnson and Padmashree Krishna 
Date: December 1, 1992  
Affiliation: Dept. of CIS University of Florida  
Abstract: Very large database systems require distributed storage, which means that they need distributed search structures for fast and efficient access to the data. In this paper, we present an approach to maintaining distributed data structures that uses lazy updates, which take advantage of the semantics of the search structure operations to allow for scalable and low-overhead replication. Lazy updates can be used to design distributed search structures that support very high levels of concurrency. The alternatives to lazy update algorithms (vigorous updates) use synchronization to ensure consistency. Hence, lazy update algorithms are a distributed analogue of shared-memory lock-free search structure algorithms. Since lazy updates avoid the use of synchronization, they are much easier to implement than vigorous update algorithms. We demonstrate the application of lazy updates to the dB-tree, which is a distributed B + tree that replicates its interior nodes for highly parallel access. We develop a correctness theory for lazy updates so that our algorithms can be applied to other distributed search structures. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F.B. Bastani, S.S. Iyengar, and I-Ling Yen. </author> <title> Concurrent maintenance of data structures in a distributed environment. </title> <journal> The Computer Journal, </journal> <volume> 21(2) </volume> <pages> 165-174, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction A common problem with distributed search structures is that they are often single-rooted. If the root node is not replicated, it becomes a bottleneck and overwhelms the node that stores it (as noted in <ref> [1] </ref>). A search structure node can be replicated by one of several well-known algorithms [2]. However, these algorithms synchronize operations, which reduces concurrency, and create a significant communications overhead. Techniques exist to reduce the cost of maintaining replicated data and for increasing concurrency. <p> Wang and Weihl [21] use a special form of cache coherence to implement a parallel B-tree, so that it can be implemented on a shared-nothing architecture with the appropriate underlying software. The dB-tree [9, 10] implements the B-link tree algorithm as a distributed protocol (as in <ref> [1] </ref>). An operation on the index (search, insert, or delete) is performed as a sequence of actions on the nodes in the search structure, which are distributed among different processors. Each processor that maintains part of the search structure has two components: a queue manager and a node manager.
Reference: [2] <author> P.A. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: 1 Introduction A common problem with distributed search structures is that they are often single-rooted. If the root node is not replicated, it becomes a bottleneck and overwhelms the node that stores it (as noted in [1]). A search structure node can be replicated by one of several well-known algorithms <ref> [2] </ref>. However, these algorithms synchronize operations, which reduces concurrency, and create a significant communications overhead. Techniques exist to reduce the cost of maintaining replicated data and for increasing concurrency. Ladin, Liskov, and Shira propose lazy replication for maintaining replicated servers [15]. <p> The replication strategy for a dB-tree helps to reduce the cost of maintaining a distributed search structure, but the replication strategy alone is not enough. If every node update required the execution of an available-copies algorithm <ref> [2] </ref>, the overhead of maintaining replicated copies would be prohibitive. Instead, we take advantage of the semantics of the actions on the search structure nodes and use lazy updates to maintain the replicated copies inexpensively. We note that many of the actions on a dB-tree node commute. <p> We can ensure the coherence of the coherence of the copies by serializing the actions on the nodes (perhaps via an available-copies algorithm <ref> [2] </ref>). However, we want to be lazy about the maintenance. In this section, we describe a model of distributed search structure computation and establish correctness criteria for lazy updates. A node of the logical search structure might be stored at several different processors.
Reference: [3] <author> A. Colbrook, E.A. Brewer, C.N. Dellarocas, and W.E. Weihl. </author> <title> An algorithm for concurrent search trees. </title> <booktitle> In Proceedings of the 20th International Conference on Parallel Processing, </booktitle> <pages> pages III138-III141, </pages> <year> 1991. </year>
Reference-contexts: A search operation examines one node at a time to find its key, and an insert operation searches for the node that contains its key, performs the insert, then restructures the tree from the bottom up. Some work has been done to develop a distributed B-tree. Colbrook et al. <ref> [3] </ref> developed a pipelined algorithm. Wang and Weihl [21] use a special form of cache coherence to implement a parallel B-tree, so that it can be implemented on a shared-nothing architecture with the appropriate underlying software.
Reference: [4] <author> D. Comer. </author> <title> The ubiquitious B-tree. </title> <journal> ACM Comp. Surveys, </journal> <volume> 11 </volume> <pages> 121-137, </pages> <year> 1979. </year>
Reference-contexts: In a B + -tree, the keys are stored in the leaves and the non-leaf nodes serve as the index. A B-link tree is a B + -tree in which every node contains a pointer to its right sibling <ref> [4] </ref>. Previous work on parallel-access search structures (see [8] for a survey). has concentrated on concurrent or shared-memory implementations. Particularly notable are the B-link tree algorithms [17, 18, 16], which we use as a base for our work.
Reference: [5] <author> C.S. Ellis. </author> <title> Distributed data structures: A case study. </title> <journal> IEEE Transactions on Computing, </journal> <volume> C-34(12):1178-1185, </volume> <year> 1985. </year>
Reference-contexts: The methods that we present can be applied to other distributed search structures, such as hash tables <ref> [5] </ref>. 1.1 The dB-tree We initiated our study of distributed search structures by examining the design of a highly concurrent distributed B-tree. A B-tree is a multi-ary tree in which every path from the root to the leaf is the same length. <p> We provide a correctness theory for lazy updates, so lazy update techniques can be used to implement lazy updates on other distributed and replicated search structures <ref> [5] </ref>. Lazy updates, like lazy replication, permit the efficient maintenance of the 19 replicated index nodes. Since little synchronization is required, lazy updates permit concurrent search and modification of a node, and even concurrent modification of a node.
Reference: [6] <author> M. Herlihy. </author> <title> A methodology for implementing highly concurrent data structures. </title> <booktitle> In Proceeding of the Second ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 197-206. </pages> <publisher> ACM, </publisher> <year> 1989. </year>
Reference-contexts: Lazy replication uses the dependencies that exist in the operations to determine if a server's data is sufficiently up-to-date to execute a new request. Several authors have explored the construction of non-blocking and wait-free concurrent data structures in a shared-memory environment <ref> [6, 20] </ref>. These algorithms enhance concurrency because a slow operation never blocks a fast operation. Lazy update algorithms are similar to lazy replication algorithms because both use the semantics of an operation to reduce the cost of maintaining replicated copies.
Reference: [7] <author> M. Herlihy and J. Wing. </author> <title> Linearizability: A correctness condition for concurrent objects. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(3) </volume> <pages> 463-492, </pages> <year> 1990. </year>
Reference-contexts: However, lazy updates are preferable. 3.1 Histories In order to capture the conditions under which actions on a copy commute, we model the value of a copy by its history (as in <ref> [7] </ref>). Formally, the total history of copy c 2 copies t (n) consists of the pair (I c ; A 0 c ), where I c is the initial value of c and A 0 c is a totally-ordered set of actions of c.
Reference: [8] <author> T. Johnson. </author> <title> The Performance of Concurrent Data Structure Algorithms. </title> <type> PhD thesis, </type> <institution> NYU Dept. of Computer Science, </institution> <year> 1990. </year>
Reference-contexts: In a B + -tree, the keys are stored in the leaves and the non-leaf nodes serve as the index. A B-link tree is a B + -tree in which every node contains a pointer to its right sibling [4]. Previous work on parallel-access search structures (see <ref> [8] </ref> for a survey). has concentrated on concurrent or shared-memory implementations. Particularly notable are the B-link tree algorithms [17, 18, 16], which we use as a base for our work. Concurrent B-link tree algorithms [17, 18] have been found to provide the highest concurrency of all concurrent B-tree algorithms [12].
Reference: [9] <author> T. Johnson and A. Colbrook. </author> <title> A distributed data-balanced dictionary based on the B-link tree. </title> <booktitle> In Proc. Int'l Parallel Processing Symp., </booktitle> <pages> pages 319-325, </pages> <year> 1992. </year>
Reference-contexts: Despite the benefits of the lazy update approach, implementors might be reluctant to use it without correctness guarantees. In this paper, we first present a framework for showing the correctness of lazy update algorithms. We next discuss lazy update algorithms for implementing a distributed B-tree, the dB-tree <ref> [9] </ref>. <p> Colbrook et al. [3] developed a pipelined algorithm. Wang and Weihl [21] use a special form of cache coherence to implement a parallel B-tree, so that it can be implemented on a shared-nothing architecture with the appropriate underlying software. The dB-tree <ref> [9, 10] </ref> implements the B-link tree algorithm as a distributed protocol (as in [1]). An operation on the index (search, insert, or delete) is performed as a sequence of actions on the nodes in the search structure, which are distributed among different processors. <p> Finally, distributed search structures that use lazy updates are easier to implement than more restrictive algorithms because lazy updates avoid the use of synchronization. Our plans for future work include developing lazy updates algorithms that for node merging and node deletion (for a dE-tree <ref> [9] </ref>). We will apply lazy updates to other distributed data structures, such as hash tables, tries, and parallel file structures. Finally, we will investigate fault-tolerant lazy updates.
Reference: [10] <author> T. Johnson and A. Colbrook. </author> <title> A distributed data-balanced dictionary based on the B-link tree. </title> <type> Technical Report TR-530, </type> <institution> MIT LCS, </institution> <year> 1992. </year> <note> Also available via anonymous ftp at cis.ufl.edu:cis/tech-reports. 20 </note>
Reference-contexts: Colbrook et al. [3] developed a pipelined algorithm. Wang and Weihl [21] use a special form of cache coherence to implement a parallel B-tree, so that it can be implemented on a shared-nothing architecture with the appropriate underlying software. The dB-tree <ref> [9, 10] </ref> implements the B-link tree algorithm as a distributed protocol (as in [1]). An operation on the index (search, insert, or delete) is performed as a sequence of actions on the nodes in the search structure, which are distributed among different processors.
Reference: [11] <author> T. Johnson and D. Shasha. </author> <title> Utilization of B-trees with inserts, </title> <booktitle> deletes and modifies. In ACM SIGACT/SIGMOD/SIGART Symposium on Principles of Database Systems, </booktitle> <pages> pages 235-246, </pages> <year> 1989. </year>
Reference-contexts: We present three algorithms, the last of which can implement a dB-tree that never merges nodes and performs data balancing on leaf nodes (we have previously found that never merging nodes results in little loss in space utilization <ref> [11] </ref>, and data balancing on the leaf level is low-overhead and effective [14]). <p> The algorithms in this paper can be used to implement a dB-tree that never merges empty nodes and performs data-balancing on the leaves (we have previously found that the free-at-empty policy provides good space utilization <ref> [11] </ref> and that leaf-level data balancing is effective and low-overhead [14]). We provide a correctness theory for lazy updates, so lazy update techniques can be used to implement lazy updates on other distributed and replicated search structures [5].
Reference: [12] <author> T. Johnson and D. Shasha. </author> <title> A framework for the performance analysis of concurrent B-tree algorithms. </title> <booktitle> In ACM Symp. on Principles of Database Systems, </booktitle> <pages> pages 273-287, </pages> <year> 1990. </year>
Reference-contexts: Particularly notable are the B-link tree algorithms [17, 18, 16], which we use as a base for our work. Concurrent B-link tree algorithms [17, 18] have been found to provide the highest concurrency of all concurrent B-tree algorithms <ref> [12] </ref>. In addition, operations on a B-link tree access one node at a time. A B-link tree's high performance and node independence makes it the most attractive starting point for constructing a distributed search structure.
Reference: [13] <author> E. Jul, H. Levy, N. Hutcjison, and A. Black. </author> <title> Fine-grained mobility in the Emerald system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 109-133, </pages> <year> 1988. </year>
Reference-contexts: When a node migrates, the host processor can broadcast its new location to every other processor that manages the node (as is done in Emerald <ref> [13] </ref>). However, this algorithm requires large amounts of wasted effort, and doesn't solve the garbage collection problems. 14 The algorithms that we propose inform the node's immediate neighbors of the new address.
Reference: [14] <author> P. Krishna and T. Johnson. </author> <title> Implementing distributed search structures. </title> <note> Technical Report UF CIS TR92-032, Availiable at anonymous ftp site cis.ufl.edu, </note> <institution> University of Florida, Dept. of CIS, </institution> <year> 1992. </year>
Reference-contexts: We present three algorithms, the last of which can implement a dB-tree that never merges nodes and performs data balancing on leaf nodes (we have previously found that never merging nodes results in little loss in space utilization [11], and data balancing on the leaf level is low-overhead and effective <ref> [14] </ref>). The methods that we present can be applied to other distributed search structures, such as hash tables [5]. 1.1 The dB-tree We initiated our study of distributed search structures by examining the design of a highly concurrent distributed B-tree. <p> As with the fixed-copies scenario, we propose an eager and a lazy algorithm to satisfy the protocol. We have implemented the lazy protocol, and found it effectively supports data balancing <ref> [14] </ref>. The eager algorithm ensures that a forwarding address exists until the processor is guaranteed that no message will arrive for it. Unfortunately, obtaining such a guarantee is complex and requires much message passing and synchronization. We omit the details of the eager algorithm to save space. <p> The algorithms in this paper can be used to implement a dB-tree that never merges empty nodes and performs data-balancing on the leaves (we have previously found that the free-at-empty policy provides good space utilization [11] and that leaf-level data balancing is effective and low-overhead <ref> [14] </ref>). We provide a correctness theory for lazy updates, so lazy update techniques can be used to implement lazy updates on other distributed and replicated search structures [5]. Lazy updates, like lazy replication, permit the efficient maintenance of the 19 replicated index nodes.
Reference: [15] <author> R. Ladin, B. Liskov, and L. Shira. </author> <title> Lazy replication: Exploiting the semantics of distibuted services. </title> <booktitle> In ACM Principles of Distributed Computing, </booktitle> <pages> pages 43-57, </pages> <year> 1990. </year>
Reference-contexts: However, these algorithms synchronize operations, which reduces concurrency, and create a significant communications overhead. Techniques exist to reduce the cost of maintaining replicated data and for increasing concurrency. Ladin, Liskov, and Shira propose lazy replication for maintaining replicated servers <ref> [15] </ref>. Lazy replication uses the dependencies that exist in the operations to determine if a server's data is sufficiently up-to-date to execute a new request. Several authors have explored the construction of non-blocking and wait-free concurrent data structures in a shared-memory environment [6, 20]. <p> Instead, the lazy update can be piggybacked onto messages used for other purposes, greatly reducing the cost of replication management (this is similar to the lazy replication techniques <ref> [15] </ref>). Second, index node searches and updates commute, so that one copy of a node may be read while another copy is being updated. Further, two updates to the copies of a node may proceed at the same time.
Reference: [16] <author> V. Lanin and D. Shasha. </author> <title> A symmetric concurrent B-tree algorithm. </title> <booktitle> In 1986 Fall Joint Computer Conference, </booktitle> <pages> pages 380-389, </pages> <year> 1986. </year>
Reference-contexts: A B-link tree is a B + -tree in which every node contains a pointer to its right sibling [4]. Previous work on parallel-access search structures (see [8] for a survey). has concentrated on concurrent or shared-memory implementations. Particularly notable are the B-link tree algorithms <ref> [17, 18, 16] </ref>, which we use as a base for our work. Concurrent B-link tree algorithms [17, 18] have been found to provide the highest concurrency of all concurrent B-tree algorithms [12]. In addition, operations on a B-link tree access one node at a time.
Reference: [17] <author> P.L. Lehman and S.B. Yao. </author> <title> Efficient locking for concurrent operations on B-trees. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 6(4) </volume> <pages> 650-670, </pages> <year> 1981. </year>
Reference-contexts: A B-link tree is a B + -tree in which every node contains a pointer to its right sibling [4]. Previous work on parallel-access search structures (see [8] for a survey). has concentrated on concurrent or shared-memory implementations. Particularly notable are the B-link tree algorithms <ref> [17, 18, 16] </ref>, which we use as a base for our work. Concurrent B-link tree algorithms [17, 18] have been found to provide the highest concurrency of all concurrent B-tree algorithms [12]. In addition, operations on a B-link tree access one node at a time. <p> Previous work on parallel-access search structures (see [8] for a survey). has concentrated on concurrent or shared-memory implementations. Particularly notable are the B-link tree algorithms [17, 18, 16], which we use as a base for our work. Concurrent B-link tree algorithms <ref> [17, 18] </ref> have been found to provide the highest concurrency of all concurrent B-tree algorithms [12]. In addition, operations on a B-link tree access one node at a time. A B-link tree's high performance and node independence makes it the most attractive starting point for constructing a distributed search structure.
Reference: [18] <author> Y. Sagiv. </author> <title> Concurrent operations on B fl -trees with overtaking. </title> <booktitle> In 4th ACM Symp. Principles of Database Systems, </booktitle> <pages> pages 28-37. </pages> <publisher> ACM, </publisher> <year> 1985. </year>
Reference-contexts: A B-link tree is a B + -tree in which every node contains a pointer to its right sibling [4]. Previous work on parallel-access search structures (see [8] for a survey). has concentrated on concurrent or shared-memory implementations. Particularly notable are the B-link tree algorithms <ref> [17, 18, 16] </ref>, which we use as a base for our work. Concurrent B-link tree algorithms [17, 18] have been found to provide the highest concurrency of all concurrent B-tree algorithms [12]. In addition, operations on a B-link tree access one node at a time. <p> Previous work on parallel-access search structures (see [8] for a survey). has concentrated on concurrent or shared-memory implementations. Particularly notable are the B-link tree algorithms [17, 18, 16], which we use as a base for our work. Concurrent B-link tree algorithms <ref> [17, 18] </ref> have been found to provide the highest concurrency of all concurrent B-tree algorithms [12]. In addition, operations on a B-link tree access one node at a time. A B-link tree's high performance and node independence makes it the most attractive starting point for constructing a distributed search structure. <p> Any two insert actions on a copy commute. As in Sagiv's algorithm <ref> [18] </ref>, we need to take care to perform out-of-order inserts properly. 2. Half-split operations do not commute. Since a half-split action modifies the right-sibling pointer, the final value of a copy depends on the order in which the half-splits are processed. 3.
Reference: [19] <author> D. Shasha and N. Goodman. </author> <title> Concurrent search structure algorithms. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 13(1) </volume> <pages> 53-90, </pages> <year> 1988. </year>
Reference-contexts: As a result, the dB-tree not only supports concurrent read actions on different copies of its nodes, it supports concurrent reads and updates, and also concurrent updates. 2 Correctness of Distributed Search Structures Shasha and Goodman <ref> [19] </ref> provide a framework for proving the correctness of non-replicated concurrent data structures. We make extensive use of their framework in order to discuss operation correctness.
Reference: [20] <author> J. Turek. </author> <title> Resilient Computation in the Presence of Slowdowns. </title> <type> PhD thesis, </type> <institution> NYU Dept. of Computer Science, </institution> <year> 1991. </year>
Reference-contexts: Lazy replication uses the dependencies that exist in the operations to determine if a server's data is sufficiently up-to-date to execute a new request. Several authors have explored the construction of non-blocking and wait-free concurrent data structures in a shared-memory environment <ref> [6, 20] </ref>. These algorithms enhance concurrency because a slow operation never blocks a fast operation. Lazy update algorithms are similar to lazy replication algorithms because both use the semantics of an operation to reduce the cost of maintaining replicated copies.
Reference: [21] <author> W.E. Weihl and P. Wang. </author> <title> Multi-version memory: Software cache management for concurrent B-trees. </title> <booktitle> In Proc. 2nd IEEE Symp. Parallel and Distributed Processing, </booktitle> <pages> pages 650-655, </pages> <year> 1990. </year> <month> 21 </month>
Reference-contexts: Some work has been done to develop a distributed B-tree. Colbrook et al. [3] developed a pipelined algorithm. Wang and Weihl <ref> [21] </ref> use a special form of cache coherence to implement a parallel B-tree, so that it can be implemented on a shared-nothing architecture with the appropriate underlying software. The dB-tree [9, 10] implements the B-link tree algorithm as a distributed protocol (as in [1]).
References-found: 21

