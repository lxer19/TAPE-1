URL: http://www.cs.washington.edu/homes/segal/st-bernard.ps.gz
Refering-URL: http://www.cs.washington.edu/homes/segal/resume.html
Root-URL: 
Email: segal@cs.washington.edu  
Title: St. Bernard: The File Retrieving Softbot  
Author: Richard Segal 
Date: June 30, 1993  
Address: Seattle, WA 98195  
Affiliation: Department of Computer Science and Engineering, FR-35 University of Washington  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [ Brooks, 1991 ] <author> Rodney A. Brooks. </author> <title> Intelligence without reason. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <year> 1991. </year>
Reference-contexts: Softbots or software robots are intelligent agents that interact with a software environment [ Etzioni and Segal, 1992 ] . They have several advantages as compared with robots. They do not require the expensive hardware nor do they suffer from the frequent malfunctions typical of robots <ref> [ Tan, 1991, Brooks, 1991 ] </ref> . They also have an easier time interacting with their environment. For instance consider a softbot that interacts with the UNIX operating system. A softbot of this type sends commands to the UNIX shell and senses to determine the results.
Reference: [ Etzioni and Segal, 1992 ] <author> Oren Etzioni and Richard Segal. </author> <title> Softbots as testbeds for machine learning. </title> <booktitle> In Working Notes of the AAAI Spring Symposium on Knowledge Assimilation, </booktitle> <year> 1992. </year>
Reference-contexts: One way to solve this problem is to let the program collect its own training data. This has traditionally been done using robots [ Tan, 1991 ] , but another possibility is to use soft bots. Softbots or software robots are intelligent agents that interact with a software environment <ref> [ Etzioni and Segal, 1992 ] </ref> . They have several advantages as compared with robots. They do not require the expensive hardware nor do they suffer from the frequent malfunctions typical of robots [ Tan, 1991, Brooks, 1991 ] . They also have an easier time interacting with their environment.
Reference: [ Etzioni, 1991 ] <author> Oren Etzioni. </author> <title> Embedding decision-analytic control in a learning architecture. </title> <journal> Artificial Intelligence, </journal> <volume> 49(1-3):129-160, </volume> <year> 1991. </year>
Reference-contexts: Unfortunately, the data in training set repositories are usually constructed to address specific research issues. This makes them of little use when addressing research topics outside their intended domains. Consider for example the theoretical work on satisficing search <ref> [ Simon and Kadane, 1975, Sproull, 1977, Etzioni, 1991 ] </ref> . Satisficing search minimizes expected search cost by trading off the cost of searching a node with the probability that searching a node will succeed.
Reference: [ Mitchell et al., 1990 ] <author> Tom M. Mitchell, John Allen, Prasad Chalasani, John Cheng, Oren Etzioni, Marc Ringuette, and Jeffrey C. Schlimmer. Theo: </author> <title> A framework for self-improving systems. </title> <editor> In K. VanLehn, editor, </editor> <booktitle> Architectures for Intelligence. </booktitle> <publisher> Erlbaum, </publisher> <year> 1990. </year>
Reference-contexts: The architecture provides mechanisms for modeling the UNIX file system, executing plans, and sensing the environment. Currently missing from the architecture is a planning system. For the moment, St. Bernard is using pre-generated plans to achieve its goals. The architecture is based on the Theo frame system <ref> [ Mitchell et al., 1990 ] </ref> . Theo provides many important capabilities. Theo's frames provide a good way to represent complex domains such as the UNIX operating system. Theo's meta-level uniform control structure allows us to define our own inference methods.
Reference: [ Murphy and Aha, 1991 ] <author> Patrick M. Murphy and David W. Aha. </author> <title> UCI Repository of Machine Learning Databases. [Machine-readable data repository]. </title> <institution> University of California, Department of Information and Computer Science, </institution> <address> Irvine, CA, </address> <year> 1991. </year>
Reference-contexts: This is often not done. One reason is the poor availability of the training data often required by Machine Learning algorithms. Recent efforts to establish archives for training data are a step in the right direction <ref> [ Murphy and Aha, 1991 ] </ref> . Unfortunately, the data in training set repositories are usually constructed to address specific research issues. This makes them of little use when addressing research topics outside their intended domains.
Reference: [ Salmon, 1984 ] <author> Wesley C. Salmon. </author> <title> Scientific Explanation and the Causal Structure of the World. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1984. </year>
Reference-contexts: The problem is without knowing what f is a priori it is impossible to calculate its probability. One solution to this problem is to partition the files into a set of classes (c i ; c 2 ; c 3 ; :::; c n ) <ref> [ Salmon, 1984 ] </ref> . Then for f 2 c, we use P (djc) as an approximation of P (djf ). Intuitively the classes group files together that are typically found in the same directory. For instance a file class might be defined for all executable programs.
Reference: [ Simon and Kadane, 1975 ] <author> Herbert A. Simon and Joseph B. Kadane. </author> <title> Optimal problem-solving search: All-or-none solutions. </title> <journal> Artificial Intelligence, </journal> <volume> 6 </volume> <pages> 235-247, </pages> <year> 1975. </year>
Reference-contexts: Unfortunately, the data in training set repositories are usually constructed to address specific research issues. This makes them of little use when addressing research topics outside their intended domains. Consider for example the theoretical work on satisficing search <ref> [ Simon and Kadane, 1975, Sproull, 1977, Etzioni, 1991 ] </ref> . Satisficing search minimizes expected search cost by trading off the cost of searching a node with the probability that searching a node will succeed.
Reference: [ Sproull, 1977 ] <author> R. F. Sproull. </author> <title> Strategy construction using a synthesis of heuristic and decision-theoretic methods. </title> <type> Technical Report CSL-77-2, </type> <institution> Xerox PARC, </institution> <address> Palo Alto, CA, </address> <year> 1977. </year>
Reference-contexts: Unfortunately, the data in training set repositories are usually constructed to address specific research issues. This makes them of little use when addressing research topics outside their intended domains. Consider for example the theoretical work on satisficing search <ref> [ Simon and Kadane, 1975, Sproull, 1977, Etzioni, 1991 ] </ref> . Satisficing search minimizes expected search cost by trading off the cost of searching a node with the probability that searching a node will succeed.
Reference: [ Tan, 1991 ] <author> Ming Tan. </author> <title> Cost Sensitive Robot Learning. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1991. </year> <note> Available as technical report CMU-CS-91-134. 10 </note>
Reference-contexts: Their estimation requires the use of training data. Without good sources of training data, it is difficult to empirically validate this research. One way to solve this problem is to let the program collect its own training data. This has traditionally been done using robots <ref> [ Tan, 1991 ] </ref> , but another possibility is to use soft bots. Softbots or software robots are intelligent agents that interact with a software environment [ Etzioni and Segal, 1992 ] . They have several advantages as compared with robots. <p> Softbots or software robots are intelligent agents that interact with a software environment [ Etzioni and Segal, 1992 ] . They have several advantages as compared with robots. They do not require the expensive hardware nor do they suffer from the frequent malfunctions typical of robots <ref> [ Tan, 1991, Brooks, 1991 ] </ref> . They also have an easier time interacting with their environment. For instance consider a softbot that interacts with the UNIX operating system. A softbot of this type sends commands to the UNIX shell and senses to determine the results.
References-found: 9

