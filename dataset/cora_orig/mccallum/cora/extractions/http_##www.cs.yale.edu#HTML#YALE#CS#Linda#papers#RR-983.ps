URL: http://www.cs.yale.edu/HTML/YALE/CS/Linda/papers/RR-983.ps
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/Linda/process-trellis.html
Root-URL: http://www.cs.yale.edu
Title: Piranha Scheduling: Strategies and Their Implementation  
Author: David Gelernter, Marc R. Jourdenais, and David Kaminsky 
Note: This work was supported by AASERT Grant F49620-92-J-0240 and NASA Training Grant NGT-50719.  
Date: September 1, 1993  
Address: New Haven, CT 06520  
Affiliation: Department of Computer Science Yale University  
Abstract: Piranha is a execution model for Linda 1 developed at Yale by Kaminsky and others[4] to reclaim idle cycles from networked workstations for use in executing parallel programs. Piranha has proven to be an effective system for harnessing large amounts of computing power. Most Piranha research to this point has concentrated on efficiently executing a single application at a time. In this paper we evaluate strategies for scheduling multiple Piranha applications. We examine methods for predicting idle periods and the effectiveness of scheduling strategies which make use of these predictions. We present a prototype scheduler for the Piranha system implemented using the process trellis software architecture for networks of workstations.[6] 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Nicholas Carriero, Eric Freeman, and David Gelernter. </author> <title> Adaptive parllelism on multiprocessors: Preliminary experience with Piranha on the CM-5. </title> <type> Technical Report YALEU/DCS/RR-969, </type> <institution> Yale University Department of Computer Science, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Higher level NPS systems could run at a relatively slower rate, occasionally becoming active to determine if any large-scale adjustments are desirable. We can also anticipate having future NPS implementations run on more exotic machines, such as the CM-5, for which Freeman has already developed a prototype Piranha system <ref> [1] </ref>, thus linking widely different types of machines into the same processor pool. Figure 9 shows the possible trellis structure of such a system.
Reference: [2] <author> Michael Factor, David Gelernter, and Dean F. Sittig. </author> <title> Multiple trellises and the intelligent cardiovascular monitor. </title> <type> Technical Report YALEU/DCS/TR-847, </type> <institution> Yale University Department of Computer Science, </institution> <month> February </month> <year> 1991. </year>
Reference: [3] <author> Michael E. </author> <title> Factor. The Process Trellis Software Architecture for Parallel, Real-Time Monitors. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: The trellis architecture was extended by Jourdenais [6] to run effectively on networks of workstations and to incorporate new communication primitives which allowed the construction of sensor-actuator trellises. A short introduction to the process trellis software architecture follows. See <ref> [3] </ref> for a more detailed presentation. 8.1 General Description The trellis system organizes a collection of heterogeneous decision processes into a data analysis hierarchy. A process trellis program is described by a directed information flow graph.
Reference: [4] <author> David Gelernter and David Kaminsky. </author> <title> Supercomputing out of recycled garbage: Preliminary experience with piranha. </title> <type> Technical Report YALEU/DCS/RR-883, </type> <institution> Yale University Department of Computer Science, </institution> <month> December </month> <year> 1991. </year>
Reference: [5] <author> B. A. Huberman, </author> <title> editor. The Ecology of Computation. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1988. </year>
Reference: [6] <author> Marc Jourdenais. </author> <title> Extending the process trellis software architecture to distributed environments. </title> <institution> Yale CS690/691 Research Project Report, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: Although the first uses of the system were for constructing monitoring applications, the trellis architecture is appropriate in general for the development of modular, flexible, predictable, and efficient parallel programs that fit a hierarchical decision-making model. The trellis architecture was extended by Jourdenais <ref> [6] </ref> to run effectively on networks of workstations and to incorporate new communication primitives which allowed the construction of sensor-actuator trellises. A short introduction to the process trellis software architecture follows. <p> The programmer using the trellis architecture need not concern himself or herself with the details of explicit parallelism or synchronization while programming an application. These issues are handled implicitly by the trellis system. 8.2 The Network Trellis System The Network Trellis System described in <ref> [6] </ref> extends the original trellis system in two significant ways. First, this system allows the construction of trellis programs for execution on networks of workstations and provides mechanisms for prediction of performance on that platform.
Reference: [7] <author> David Kaminsky. </author> <type> Personal communication, </type> <month> July </month> <year> 1993. </year>
Reference-contexts: An evaluator node exists which keeps track of estimated turnaround time and system usage by each scheduler, as well as statistics on each physical node's availability. The monitor processes send scheduling decisions to the Piranha system via a system-wide open tuple space <ref> [7] </ref> which allows loose coupling of the Piranha and NPS systems. There are two major reasons why we chose open tuple space for communication. First, the Piranha system already uses open tuple space for internal communication.
Reference: [8] <author> Abraham Silbershatz and James L. Peterson. </author> <title> Operating System Concepts. </title> <publisher> Addison-Wesley, </publisher> <address> alternate edition, </address> <year> 1988. </year>
Reference: [9] <author> Carl A. Waldspurger et al. Spawn: </author> <title> A distributed computational economy. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 18(2), </volume> <month> February </month> <year> 1992. </year>
Reference-contexts: A few of the more prominent systems are enumerated in <ref> [9] </ref>. The Worms project used programs composed of multiple segments, each executing on a different machine.
References-found: 9

