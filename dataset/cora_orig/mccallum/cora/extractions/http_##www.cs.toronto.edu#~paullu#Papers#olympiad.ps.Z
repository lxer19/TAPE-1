URL: http://www.cs.toronto.edu/~paullu/Papers/olympiad.ps.Z
Refering-URL: http://www.cs.toronto.edu/~paullu/publications.html
Root-URL: http://www.cs.toronto.edu
Title: REVIVING THE GAME OF CHECKERS  
Author: Jonathan Schaeffer Joseph Culberson Norman Treloar Brent Knight Paul Lu Duane Szafron 
Address: Edmonton, Alberta Canada T6G 2H1  
Affiliation: Department of Computing Science University of Alberta  
Abstract: Chinook is the strongest 8 8 checkers program around today. Its strength is largely a result of brute-force methods. The program is capable of searching to depths that make it a feared tactician. As with chess, knowledge is the Achilles' heel of the program. However, unlike the chess example, endgame databases go a long way to overcoming this limitation. The program has precomputed databases that classify all positions with 6 or less pieces on the board as won, lost or drawn (with 7 pieces under construction). The program came second to the human World Champion in the U.S. National Open, winning the right to play a World Championship match against him. Chinook is the first computer program in history to earn the right to play for a human World Championship. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> A.L. Samuel, </author> <title> Some Studies in Machine Learning Using the Game of Checkers, </title> <journal> IBM Journal of Research and Development 3, </journal> <volume> 3 (1959), </volume> <pages> 210-229. </pages> <note> See also (1963), Computers and Thought, E.A. </note> <editor> Feigenbaum and J. Feldman (eds.), </editor> <publisher> McGraw-Hill, </publisher> <pages> pp. </pages> <month> 71-105.. </month>
Reference-contexts: 1. Introduction The game of checkers was reputedly "solved" over 25 years ago. Samuel's famous checkers program <ref> [1, 2] </ref> was credited with defeating a master and, largely as a result of this one game, efforts stopped on developing a program to play world-class checkers. <p> Several studies have been done that quantify the value of the knowledge (for example, [9]). In checkers, the issue of knowledge has been less well studied. Samuel gave a description of the knowledge used in his program <ref> [1, 2] </ref>. As well, Oldbury has made an attempt to define and express mathematically the knowledge of checkers [10]. Unfortunately, these two efforts are only a beginning and it is difficult to know what knowledge is important and just how important it is.
Reference: 2. <author> A.L. Samuel, </author> <title> Some Studies in Machine Learning Using the Game of Checkers II - Recent Progress, </title> <journal> IBM Journal of Research and Development 11, </journal> <volume> 6 (1967), </volume> <pages> 601-617. </pages>
Reference-contexts: 1. Introduction The game of checkers was reputedly "solved" over 25 years ago. Samuel's famous checkers program <ref> [1, 2] </ref> was credited with defeating a master and, largely as a result of this one game, efforts stopped on developing a program to play world-class checkers. <p> Several studies have been done that quantify the value of the knowledge (for example, [9]). In checkers, the issue of knowledge has been less well studied. Samuel gave a description of the knowledge used in his program <ref> [1, 2] </ref>. As well, Oldbury has made an attempt to define and express mathematically the knowledge of checkers [10]. Unfortunately, these two efforts are only a beginning and it is difficult to know what knowledge is important and just how important it is.
Reference: 3. <author> T. Truscott, </author> <title> The Duke Checkers Program, </title> <institution> Duke University report, </institution> <year> 1978. </year>
Reference-contexts: Unfortunately, this single moment of human oversight in one game was not representative of the relative strengths of the best humans and the best checkers programs. With only a few exceptions (the Duke program being notable <ref> [3] </ref>), little effort has been devoted to computer checkers since Samuel's pioneering effort. Why the sudden interest in checkers? There are several reasons, including: (1) Checkers has a smaller search space than chess, approximately 5 10 20 positions versus O (10 44 ) for chess.
Reference: 4. <editor> D.N.L. Levy and D.F. Beal, eds., </editor> <booktitle> Heuristic Programming in Artificial Intelligence, </booktitle> <publisher> Ellis Horwood Limited, </publisher> <address> London, </address> <year> 1989. </year>
Reference-contexts: As discussed later, this is an enormous undertaking. Chinook is the strongest checkers program around today, and is regarded as being of strong master or grandmaster strength. The program won the checkers event at the 1st Computer Olympiad <ref> [4] </ref> and has scored excellent results against some of the strongest players in the world. In August 1990, the program won the Mississippi State Championship. It followed that up by coming second to the World Champion in the U.S. <p> Oldbury didn't believe Chinook's brashness and played an additional 20 moves before conceding the draw. In August 1989, Chinook won the checkers tournament at the 1st Computer Olympiad, going undefeated <ref> [4] </ref>. In the Mississippi State Championship, August 1990, Chi-nook came an undefeated first. In the U.S. National Open that followed, Chinook won 4 and drew 4 of its 8 matches, finishing a clear second to the World Champion, Dr. Marion Tinsley.
Reference: 5. <author> D.J. </author> <title> Slate and L.R. Atkin, Chess 4.5The Northwestern University Chess Program, in Chess Skill in Man and Machine, </title> <editor> P. Frey (ed.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1977, </year> <month> - 14 </month> - 
Reference-contexts: The Lessons of Computer Chess Chinook is a typical alpha-beta (ab) search program, with iterative deepening (2 ply at a time), transposition tables <ref> [5] </ref> and the history heuristic [6]. Many of the search ideas of computer chess carry over naturally to checkers. However, there are some differences: (1) Transposition tables are not quite as effective as in chess. In checkers, a man cannot move backwards (only kings can), reducing the likelihood of transpositions.
Reference: 6. <author> J. Schaeffer, </author> <title> The History Heuristic and Alpha-Beta Search Enhancements in Practice, </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence 11, </journal> <volume> 11 (1989), </volume> <pages> 1203-1212. </pages>
Reference-contexts: The Lessons of Computer Chess Chinook is a typical alpha-beta (ab) search program, with iterative deepening (2 ply at a time), transposition tables [5] and the history heuristic <ref> [6] </ref>. Many of the search ideas of computer chess carry over naturally to checkers. However, there are some differences: (1) Transposition tables are not quite as effective as in chess. In checkers, a man cannot move backwards (only kings can), reducing the likelihood of transpositions.
Reference: 7. <author> T.S. Anantharaman, M.S. Campbell and F-h. Hsu, </author> <title> Singular Extensions: Adding Selectivity to Brute-Force Searching, </title> <booktitle> AAAI Spring Symposium Proceedings, </booktitle> <year> 1988, </year> <note> P 8-13. Also published in the Journal of the International Computer Chess Association 11, 4 (1988), 135-143 and in Artificial Intelligence 43, </note> <month> 1 </month> <year> (1990), </year> <pages> 99-110. </pages>
Reference-contexts: No application-dependent knowledge is used. The history heuristic appears to be more effective than in chess programs. (3) Experiments were done with the singular extensions algorithm <ref> [7] </ref>. Unfortunately, the results were not encouraging. Checkers is not as tactical as chess, and the proportion of forcing moves appears to be less than in chess.
Reference: 8. <author> J.J. Gillogly, </author> <title> Performance Analysis of the Technology Chess Program, </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Science, Carnegie Mellon University, </institution> <year> 1978. </year>
Reference-contexts: In the middlegame, on average an extra 2 ply of search costs a factor of 4 in computation time. In contrast, for chess, a single ply often costs 4- to 8-fold <ref> [8] </ref>. 3. Knowledge For the game of chess, many of the important pieces of knowledge required to play the game well are documented. Several studies have been done that quantify the value of the knowledge (for example, [9]). In checkers, the issue of knowledge has been less well studied.
Reference: 9. <author> J. Schaeffer and T.A. Marsland, </author> <title> The Utility of Expert Knowledge, </title> <booktitle> International Joint Conference on Artificial Intelligence, </booktitle> <year> 1985, </year> <pages> 585-587. </pages>
Reference-contexts: In contrast, for chess, a single ply often costs 4- to 8-fold [8]. 3. Knowledge For the game of chess, many of the important pieces of knowledge required to play the game well are documented. Several studies have been done that quantify the value of the knowledge (for example, <ref> [9] </ref>). In checkers, the issue of knowledge has been less well studied. Samuel gave a description of the knowledge used in his program [1, 2]. As well, Oldbury has made an attempt to define and express mathematically the knowledge of checkers [10].
Reference: 10. <author> D. Oldbury, </author> <title> The Complete Encyclopedia of Checkers, Draughts & Checker Players' Guild, </title> <address> Torquay, England, </address> <year> 1978. </year> <note> In 6 volumes. </note>
Reference-contexts: In checkers, the issue of knowledge has been less well studied. Samuel gave a description of the knowledge used in his program [1, 2]. As well, Oldbury has made an attempt to define and express mathematically the knowledge of checkers <ref> [10] </ref>. Unfortunately, these two efforts are only a beginning and it is difficult to know what knowledge is important and just how important it is. Checkers, like chess, is usually considered to have 3 game stages: the opening, middlegame and endgame.
Reference: 11. <author> F-h. Hsu, M.S. Campbell, T. Anantharaman and A. Nowatzyk, </author> <title> Deep Thought, in Computers, Chess and Cognition, T.A. </title> <editor> Marsland and J. Schaeffer (ed.), </editor> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1990, </year> <pages> 55-78. </pages> <note> In press. </note>
Reference-contexts: The initial attempt at tuning involved modifying the program developed by Andreas Nowatzyk for the Deep Thought chess program <ref> [11] </ref>. It computes the weights using linear regression and least-squares-fit. Some of the other proposed methods include using linear discriminants [12], or minimizing a cost function that measures the inaccuracies of the current set of weights [13].
Reference: 12. <author> T. Anantharaman, </author> <title> A Statistical Study of Selective Min-Max Search, </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Science, Carnegie Mellon University, </institution> <year> 1990. </year>
Reference-contexts: The initial attempt at tuning involved modifying the program developed by Andreas Nowatzyk for the Deep Thought chess program [11]. It computes the weights using linear regression and least-squares-fit. Some of the other proposed methods include using linear discriminants <ref> [12] </ref>, or minimizing a cost function that measures the inaccuracies of the current set of weights [13]. Each of these techniques has its strengths and weaknesses, and it is not known which method suits our needs best. The current implementation of automated tuning has not been wholly successful.
Reference: 13. <author> T.A. Marsland, </author> <title> Evaluation-Function Factors, </title> <journal> Journal of the International Computer Chess Association 8, </journal> <volume> 2 (1985), </volume> <pages> 47-57. </pages>
Reference-contexts: It computes the weights using linear regression and least-squares-fit. Some of the other proposed methods include using linear discriminants [12], or minimizing a cost function that measures the inaccuracies of the current set of weights <ref> [13] </ref>. Each of these techniques has its strengths and weaknesses, and it is not known which method suits our needs best. The current implementation of automated tuning has not been wholly successful.
Reference: 14. <author> K. Thompson, </author> <title> Retrograde Analysis of Certain Endgames, </title> <journal> Journal of the International Computer Chess Association 9, </journal> <volume> 3 (1986), </volume> <pages> 131-139. </pages>
Reference-contexts: For now, this remains an open research problem. 4. Databases This section provides a brief overview of the methods used to compute the 6-piece databases. Thompson provides an excellent discussion of how to construct chess databases <ref> [14] </ref>. N-piece endgame database construction involves enumerating all positions with n pieces or less on the board and computing whether each is a win, loss or draw. The basic idea is quite simple; what makes the problem difficult is the sheer size of the problem as n increases.
Reference: 15. <author> J. Schaeffer, </author> <title> Experiments in Search and Knowledge, </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Science, University of Waterloo, </institution> <year> 1986. </year>
Reference-contexts: Thus, it is possible to search considerably deeper in checkers than in chess. Of course, this also means humans search deeper too! As a point of comparison, the chess program Phoenix <ref> [15] </ref> searches to 7 ply in the middlegame and 8+ ply in the endgame on a 20 MIPS machine on a typical 3 minute move. Chinook, on comparable hardware, completes 15-ply at the beginning of the game and as pieces come off, the search depth typically rises to 19 ply.
References-found: 15

