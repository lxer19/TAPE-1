URL: http://www.cs.virginia.edu/~humphrey/papers/TPDS_humphrey_V2.ps
Refering-URL: http://www.cs.virginia.edu/~humphrey/
Root-URL: http://www.cs.virginia.edu
Title: Predictable Threads for Dynamic, Hard Real-Time Environments  
Author: Marty Humphrey and John A. Stankovic 
Keyword: Real-Time Operating Systems, Threads, Multiprocessing  
Date: June 25, 1998  
Abstract: Next-generation hard real-time systems will require new, flexible functionality and guaranteed, predictable performance. This paper describes the UMass Spring threads package, designed specifically for multiprocessing in dynamic, hard real-time environments. This package is unique because of its support for new thread semantics for real-time processing. Predictable creation and execution of threads is achieved because of an underlying predictable kernel, the UMass Spring kernel. Design decisions and lessons learned while implementing the threads package are presented. Measurements affirm the predictability of this implementation on a representative multiprocessor platform. The adoption of the threads package in the UMass Spring kernel results in additional performance improvements, which include reduced context switching overhead and reduced average-case memory access durations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> John A. Stankovic and Krithi Ramamritham, </author> <title> Editorial: What is predictability for real-time systems?, </title> <journal> The Journal of Real-Time Systems, </journal> <volume> vol. 2, </volume> <pages> pp. 247254, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction For many applications, real-time threads executed by a fixed-priority policy offers the necessary predictability and flexibility. However, in contrast to the small, static environment for which this threads model is particularly well-suited, next-generation hard real-time systems will be large, complex, distributed, and adaptive <ref> [1] </ref>. The conventional approach for designing small, embedded systems is to, in effect, perform all schedula-bility analysis off-line and thus preallocate resources to activities with fixed attributes such as priority and execution rate.
Reference: [2] <author> John A. Stankovic and Krithi Ramamritham, </author> <title> The Spring kernel: A new paradigm for real-time systems, </title> <journal> IEEE Software, </journal> <volume> vol. 8, no. 3, </volume> <pages> pp. 6272, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: In this situation, the threads package enables both the spawning and spawned thread to be executed under hard real-time constraints. The most important property of UMass Spring threads is its run-time predictability. This predictability is ensured through the support and scheduling model of the UMass Spring kernel <ref> [2] </ref>. The UMass Spring kernel uses a dynamic, planning-based approach to resource usage, thus avoiding the blocking on resources that occurs in systems that are priority-based. This paper describes the design of the UMass Spring threads package and its implementation and measurement on a representative platform. <p> This paper describes the design of the UMass Spring threads package and its implementation and measurement on a representative platform. The real-time threads package builds upon previous work in the design and implementation of the UMass Spring kernel <ref> [2] </ref>. This paper extends the presentation of the high-level design and initial implementation contained in [3]. This completed implementation is, to our knowledge, the first threads package with such rich semantics that is suitable for hard real-time environments. <p> SpringNet is a physically distributed system consisting of a network of multi processors each running the UMass Spring kernel. The thread package does not directly address the distributed capabilities of UMass Spring, so SpringNet will not be discussed any further. Interested readers should consult <ref> [4, 2] </ref>. such as scheduling and interacting with outside entities. The remaining processors are Application Processors (APs), which execute application code according to timing and functional constraints. Physical memory resident on each processor board is capable of being referenced directly by any processor in the node. <p> When a new scheduling request arrives, to achieve concurrent execution of the scheduler and the multiple dispatchers, a set of tasks is reserved for each dispatcher, where the scheduler is not free to reschedule the tasks reserved for the dispatchers <ref> [2] </ref>. The mechanism for determining which tasks cannot be rescheduled involves a cutoff line. Once the scheduler has determined an upper bound of its cost for scheduling, the sched-uler adds this cost to the current time to determine the cutoff line.
Reference: [3] <author> Marty A. Humphrey, Gary Wallace, and John A. Stankovic, </author> <title> Kernel-level threads for dynamic, hard real-time environments, </title> <booktitle> in Proceedings of the 1995 IEEE Real-Time Systems Symposium, </booktitle> <address> Pisa, Italy, </address> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: The real-time threads package builds upon previous work in the design and implementation of the UMass Spring kernel [2]. This paper extends the presentation of the high-level design and initial implementation contained in <ref> [3] </ref>. This completed implementation is, to our knowledge, the first threads package with such rich semantics that is suitable for hard real-time environments.
Reference: [4] <author> John A. Stankovic, Douglas Niehaus, and Krithi Ramamritham, SpringNet: </author> <title> An architecture for high performance distributed real-time computing, </title> <booktitle> in Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <month> Apr. </month> <year> 1993. </year>
Reference-contexts: SpringNet is a physically distributed system consisting of a network of multi processors each running the UMass Spring kernel. The thread package does not directly address the distributed capabilities of UMass Spring, so SpringNet will not be discussed any further. Interested readers should consult <ref> [4, 2] </ref>. such as scheduling and interacting with outside entities. The remaining processors are Application Processors (APs), which execute application code according to timing and functional constraints. Physical memory resident on each processor board is capable of being referenced directly by any processor in the node.
Reference: [5] <author> Douglas Niehaus, </author> <title> Program Representation and Execution in Real-Time Multiprocessor Systems, </title> <type> Ph.D. thesis, </type> <institution> University of Massachusetts, </institution> <address> Amherst MA, </address> <year> 1994. </year> <month> 33 </month>
Reference-contexts: Before discussing the operating system, this section presents an overview of how the user encodes applications and instructs the UMass Spring operating system of the applications' timing requirements. To encode applications, the application developer uses Spring-C <ref> [5] </ref>, which is a version of ANSI C that has been modified for use in a real-time environment. The modifications enable the compile-time timing analysis of code segments by removing the ability of the user to perform operations for which the duration cannot be predicted, such as unbounded loops. <p> The modifications enable the compile-time timing analysis of code segments by removing the ability of the user to perform operations for which the duration cannot be predicted, such as unbounded loops. The Spring-C compiler <ref> [5] </ref> both produces object code and breaks the computation at potential blocking points into a series of precedence-related tasks. <p> Virtual memory is not supported in the UMass Spring kernel, because of its inherent unpredictability <ref> [5] </ref>. Execution is limited to the processors on which the process was physically loaded. The ability of the user to specify groups of activities, with a single end-to-end deadline, was provided by the process group SDL construct 2 . <p> There are two explanations for the difference between the compiler-computed WCET and the measured maximum duration. First, the technique used to compute the worst-case execution time for these experiments does not take into account pipelining effects during program execution, because a detailed model of the pipeline was unavailable <ref> [5] </ref>. Second, the compiler computes a worst-case behavior, while the measurements for this table did not stress the worst-case. Wide variances in execution time are inherent in a thread package for dynamic systems, as the design must take into account rarely-occuring events.
Reference: [6] <author> Marty A. Humphrey and John A. Stankovic, </author> <title> Multi-level scheduling for flexible manufacturing, </title> <type> Tech. Rep. 95-86, </type> <institution> Computer Science Dept., University of Mas-sachusetts, </institution> <address> Amherst, MA, </address> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: An example of the translation of a process to its corresponding task group is shown in flexible manufacturing workcell <ref> [6] </ref>. The left side of the figure shows the shell of the code, and the right side shows the task group that results from the compilation of the code. In this process, the resource corresponding to the linear table is called linear table.
Reference: [7] <author> Douglas Niehaus, John A. Stankovic, and Krithi Ramamritham, </author> <title> A real-time system description language, </title> <booktitle> in Proceedings of the 1995 IEEE Real-Time Technology and Applications Symposium, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: The arrows in the right side of Figure 2 indicate precedence constraints between tasks. While the functionality of an application program is expressed in Spring-C, the System Description Language (SDL) <ref> [7] </ref> is used to express timing and resource requirements 1 In scientific computation compilers are often utilized to identify parallelism and the expense of special purpose compilers is justified. Similarly, for hard real-time systems sophisticated compilers are utilized to enable predictability and the analysis of predictability.
Reference: [8] <author> Krithi Ramamritham, John A. Stankovic, and Perng-Fei Shiah, </author> <title> Efficient scheduling algorithms for real-time multiprocessor systems, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> vol. 1, no. 2, </volume> <pages> pp. 184195, </pages> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: The details of the Spring scheduler algorithms can be found in <ref> [8, 9, 10] </ref>. An example of a schedule produced by the Spring scheduler for three APs is shown in Figure 3. The schedule shown is for time 0 through time 15 milliseconds. Each task is labeled with its name and resource requirements. There are two resources, R1 and R2. <p> The basic idea is that at each of n scheduling choices, a heuristic function is applied to the top k choices in the list of unscheduled tasks sorted by increasing deadline; the highest-valued task is placed into the schedule. If k is constant, the scheduling algorithm is O (n) <ref> [8] </ref>. For a particular system, the system is designed with a maximum value of n. The implementation of the Spring threads package utilized this result in two steps: 1.
Reference: [9] <author> Krithi Ramamritham, John A. Stankovic, and Wei Zhao, </author> <title> Distributed scheduling of tasks with deadlines and resource requirements, </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 38, no. 8, </volume> <month> Aug. </month> <year> 1989. </year>
Reference-contexts: The details of the Spring scheduler algorithms can be found in <ref> [8, 9, 10] </ref>. An example of a schedule produced by the Spring scheduler for three APs is shown in Figure 3. The schedule shown is for time 0 through time 15 milliseconds. Each task is labeled with its name and resource requirements. There are two resources, R1 and R2.
Reference: [10] <author> Wei Zhao and Krithi Ramamritham, </author> <title> Simple and integrated heuristic algorithms for scheduling tasks with time and resource constraints, </title> <journal> Journal of Systems and Software, </journal> <volume> vol. 7, no. 3, </volume> <pages> pp. </pages> <address> 195205, </address> <month> Sept. </month> <year> 1987. </year>
Reference-contexts: The details of the Spring scheduler algorithms can be found in <ref> [8, 9, 10] </ref>. An example of a schedule produced by the Spring scheduler for three APs is shown in Figure 3. The schedule shown is for time 0 through time 15 milliseconds. Each task is labeled with its name and resource requirements. There are two resources, R1 and R2.
Reference: [11] <author> Jane W.S. Liu, Wei-Kuan Shih, Kewi-Jay Lin, Riccardo Bettati, and Jen-Yao Chung, </author> <title> Imprecise computations, </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 82, no. 1, </volume> <pages> pp. 8394, </pages> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: The UMass threads package provides flexible mechanisms for structuring arbitrary hard real-time computation by allowing the programmer to mix the use of Independent guarantees with Dependent guarantees. If the programmer uses only Independent guarantees, the style of hard real-time computation is similar to the model of imprecise computation <ref> [11] </ref> in which there is a mandatory and optional part of computation. The imprecise computation model has been proposed to handle transient overload and to enhance fault-tolerance properties of real-time applications.
Reference: [12] <author> David Hull, Wu-Chun Feng, and Jane W.S. Liu, </author> <title> Operating system support for imprecise computation, in Flexible Computation in Intelligent Systems: Results, Issues, and Opportunities, </title> <address> Cambridge, MA, </address> <month> Nov. </month> <year> 1996. </year>
Reference-contexts: The imprecise computation model has been proposed to handle transient overload and to enhance fault-tolerance properties of real-time applications. Although there has been significant results toward general scheduling theories for many models of imprecise computation, there has been only limited research into platforms for implementing imprecise computation <ref> [12] </ref>. The UMass Spring threads complements the development of general theories of imprecise computation by providing the necessary constructs to implement a hard real-time application according to the imprecise computation paradigm.
Reference: [13] <author> Eric C. Cooper and Richard P. Draves, </author> <title> C threads, </title> <type> Tech. Rep. </type> <institution> CMU- CS-88-154, School of Computer Science, Carnegie Mellon University, Pittsburg, </institution> <address> PA, </address> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: This is addressed in Section 3.3.6, Section 4.4, and Section 5.2. 3.3 Constructs The convention adopted for the syntax of the constructs in the UMass Spring thread package is based on <ref> [13] </ref> and [14].
Reference: [14] <author> Karsten Schwan, Hongyi Zhou, and Ahmed Gheith, </author> <title> Multiprocessor real-time threads, </title> <journal> Operating Systems Review, </journal> <volume> vol. 26, no. 1, </volume> <pages> pp. 5465, </pages> <month> Jan. </month> <year> 1992. </year>
Reference-contexts: This is addressed in Section 3.3.6, Section 4.4, and Section 5.2. 3.3 Constructs The convention adopted for the syntax of the constructs in the UMass Spring thread package is based on [13] and <ref> [14] </ref>. <p> If an application could arbitrarily decide to change from one thread to another, resources would be requested and released in an unpredictable manner. 6.4 CHAOS-arc Real-Time Threads The real-time threads package of <ref> [14] </ref> are used as the basis for the CHAOS-arc operating system [28]. The approach taken is that the schedulability of a thread should be guaranteed before it is actually run. This guarantee can be made at either program compilation time or at the time of thread creation. <p> The second principle difference is the semantics of a threaded application as a function of kernel support. In the approach of UMass Spring threads, a thread is scheduled based on its WCET but is guaranteed access to required resources before the thread executes. The approach described in <ref> [14] </ref> also schedules a task based on its WCET, but does not directly schedule access to required resources. The ramifications of this is that an executing thread can be denied access to a resource if that resource is held by a second thread.
Reference: [15] <author> John A. Stankovic, </author> <title> Misconceptions about real-time computing, </title> <journal> IEEE Computer, </journal> <volume> vol. 21, no. 10, </volume> <pages> pp. 93108, </pages> <year> 1988. </year>
Reference-contexts: Further, the real scientific issues revolve around predictability and not raw speed. The main concepts investigated here are not affected by using the 68020 CPUs. See <ref> [15] </ref> for a discussion of why real-time computing is not fast computing. 20 clocks that exist on the particular MVME136A board.
Reference: [16] <author> Chia Shen, Krithi Ramamritham, and John A. Stankovic, </author> <title> Resource reclaiming in multiprocessor real-time systems, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> vol. 4, no. 4, </volume> <pages> pp. 382398, </pages> <month> Apr. </month> <year> 1993. </year>
Reference-contexts: An additional goal is to improve the average-case performance of the kernel, irrespective of worst-case performance estimates. When activities take less than their worst-case durations, resources can be reclaimed and reused <ref> [16] </ref>. The first improvement is the average duration of a context switch. In the UMass Spring kernel, the contents of the Translation Lookaside Buffer (TLB) are explicitly managed in order to avoid misses during memory references.
Reference: [17] <author> Thomas H. Corman, Charles E. Leiserman, and Ronald L. Rivest, </author> <title> Introduction to Algorithms, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA., </address> <year> 1990. </year>
Reference-contexts: Otherwise, choose the TCB that is available closest to, but not earlier than, the release time of the thread. This is analogous to first sorting by AP, and then doing a stable sort <ref> [17] </ref> by available time. The first in the list is then chosen. Earliest Choose a TCB on the AP on which the process address space resides, if it is available at the time it is needed.
Reference: [18] <author> Marty Humphrey, </author> <title> Real-Time Operating Systems: Predictable Threads and Support for Multi-Level Scheduling, </title> <type> Ph.D. thesis, </type> <institution> University of Massachusetts, </institution> <address> Amherst MA, </address> <year> 1996. </year>
Reference-contexts: It has the advantage of reducing memory access costs without reducing schedulability. With more local executions, the average case durations of tasks will decrease, which will lead to more opportunity to perform resource reclaiming. Additional details are found in <ref> [18] </ref>. 6 Related Work Four approaches for real-time threads are discussed and contrasted with UMass Spring threads: the real-time threads of the POSIX standard, Solaris real-time threads, Real-Time Mach threads, and the threads of CHAOS-arc.
Reference: [19] <author> Technical Committee on Operating Systems and Application Environments of the IEEE, </author> <title> Portable Operating System Interface (POSIX)Part 1: System Application Program 34 Interface (API), 1996, ANSI/IEEE Std 1003.1, 1995 Edition, including Real Time Exten--sions (IEEE Std 1003.1b-1993 and Realtime Technical Corrigenda: </title> <journal> IEEE Std 1003.1i-1995) and Threads Extensions (IEEE Std 1003.1c-1995). </journal>
Reference-contexts: For completeness, the main properties of several non-real-time thread packages are also briefly discussed and contrasted to real-time thread packages. 6.1 POSIX Threads The POSIX standard <ref> [19] </ref> includes amendment P1003.1c for threads (Pthreads), which by default are used for non-real-time processing. Because the PThreads document specifies only the API, any compliant implementation of PThreads is not constrained in any way beyond providing the appropriate interfaces. Issues related to implementation are not part of the standard. <p> Thread cancellation is well-defined with specified cancellation points and optional cancellation cleanup handlers. PThreads also provide for thread-specific data, to allow threads to have thread-specific global variables. The POSIX realtime amendment, P1003.1b, also contained in <ref> [19] </ref>, extends the base POSIX standard in order to achieve bounded response time. The two primary scheduling policies defined in POSIX for real-time computing are SCHED FIFO (first-in, first-out), and SCHED OTHER, which can be used to support implementation-defined policies.
Reference: [20] <author> David R. Butenhof, </author> <title> Programming with POSIX threads, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1997. </year>
Reference-contexts: For example, the standard does not require that the threads be supported in kernel-space, nor does it require that the threads be supported in user-space. The basic PThreads thread model is priority driven and preemptive, with signal handling, mutual exclusion, and synchronized waiting <ref> [20] </ref>. PThreads provides semaphores, locks and condition variables as the primary means for synchronization. In general, the scheduling policy used in non-real-time is round robin, which is denoted SCHED RR.
Reference: [21] <author> Frank Mueller, Viresh Rustagi, and Theodore P. Baker, </author> <title> Mithos a real-time micro-kernel threads operating system, </title> <booktitle> in Proceedings of the 1995 IEEE Real-Time Systems Symposium, </booktitle> <address> Pisa, Italy, </address> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: Examples of these additions include barriers and spinlocks for fine-grained parallelism, and read/write locks. An earlier version of the POSIX Pthreads standard was used as the basis for MiThOS, which is a small kernel for multi-threaded embedded applications <ref> [21] </ref>. MiThOS implements priority scheduling and round-robin priority scheduling, but in addition supports deadline scheduling for a thread. That is, the scheduling attributes of a Pthread are extended to allow the specification of an absolute start time, an absolute deadline, and a relative period.
Reference: [22] <author> SunSoft, </author> <title> Pthreads and solaris threads: A comparison of two user-level thread apis, Sun Microsystems White Paper, </title> <month> May </month> <year> 1994, </year> <title> Early Access Edition (May 1994); pthreads based on POSIX 1003.4a/D8. </title>
Reference-contexts: Many of the functions in the Solaris threads package have a counterpart in the POSIX threads package, but there are some notable differences <ref> [22] </ref>. Features in POSIX threads that are not contained in Solaris threads include attribute objects that can be used to establish characteristics for each thread, cancellation semantics, and scheduling policies.
Reference: [23] <author> John R. Graham, </author> <title> Solaris 2.x: internals and architecture, </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: The most significant feature of Solaris threads not contained in POSIX is the ability to set concurrency through the use of Lightweight Processes (LWPs) <ref> [23] </ref>. Each LWP is viewed as a virtual CPU, available for executing user code or system calls. Each LWP in the system is separately scheduled and dispatched by the kernel.
Reference: [24] <author> Sandeep Khanna, Michael Sebree, and John Zolnowsky, </author> <title> Realtime scheduling in SunOS 5.0, </title> <booktitle> in Proceedings of the 1992 Winter USENIX Conference, </booktitle> <month> Jan. </month> <year> 1992. </year>
Reference-contexts: In addition, a programmer may choose to bind a thread to a LWP for performance reasons. Without this binding, multiple threads can be multiplexed onto a single LWP. Realtime scheduling is based on the scheduling classes <ref> [24] </ref> (this is similar to realtime scheduling in Windows NT [25]). The classes in order of priority are: Interrupt threads, realtime threads, system threads, and timesharing (TS) threads. Scheduling within a class is priority-based and preemptive.
Reference: [25] <author> Krithi Ramamritham, Chia Shen, Oscar Gonzalez, Subhabrata Sen, and Shreedhar Shirgurkar, </author> <title> Using Windows NT for real-time applications: Experimental observations and recommendations, </title> <booktitle> in Proceedings of the Fourth IEEE Real-Time Technology and Applications Symposium, </booktitle> <address> Denver, CO, </address> <month> June </month> <year> 1998. </year>
Reference-contexts: In addition, a programmer may choose to bind a thread to a LWP for performance reasons. Without this binding, multiple threads can be multiplexed onto a single LWP. Realtime scheduling is based on the scheduling classes [24] (this is similar to realtime scheduling in Windows NT <ref> [25] </ref>). The classes in order of priority are: Interrupt threads, realtime threads, system threads, and timesharing (TS) threads. Scheduling within a class is priority-based and preemptive.
Reference: [26] <author> C. L. Liu and J. W. Layland, </author> <title> Scheduling algorithms for multiprogramming in a hard real-time environment, </title> <journal> Journal of the ACM, </journal> <volume> vol. 20, no. 1, </volume> <pages> pp. 4661, </pages> <year> 1973. </year>
Reference-contexts: Preemption of a thread within a critical region is on a lock-by-lock basis: no preemption, preemptible, or restartable. The priority ceiling protocol can be used to control priority inversion. Threads are kernel-level objects. The kernel maintains separate dispatch queues for real-time threads and non-real-time threads. Earliest Deadline First (EDF) <ref> [26] </ref> is used as the queuing policy for both RT-mutex and RT-condition primitives. The kernel provides no run-time schedulability supportan application program cannot attempt to create a thread under the condition that the operating system provide immediate feedback concerning its schedulability.
Reference: [27] <author> Shuichi Oikawa and Hideyuki Tokuda, </author> <title> User-level real-time threads, </title> <booktitle> in Proceedings of the 11th IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <address> Seattle, WA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: The Spring OS provides direct support for predictability by handling 30 blocking issues via planning-based admission control. This paradigm difference affects various implementation concerns and permits a system-supported predictability. The kernel-level threads of Real-Time Mach have been extended to support user-level threads <ref> [27] </ref>. User-level threads offer two benefits over kernel-level threads: the ability to switch contexts without making a system call and the ability to support a variety of scheduling models. A main goal of user-level real-time threads in Real-Time Mach is the quick, dynamic management of thread attributes.
Reference: [28] <author> Ahmed Gheith and Karsten Schwan, Chaos-arc: </author> <title> Kernel support for multi-weight objects, invocations, and atomicity in real-time applications, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 11, no. 1, </volume> <pages> pp. 3372, </pages> <month> Apr. </month> <year> 1993. </year>
Reference-contexts: If an application could arbitrarily decide to change from one thread to another, resources would be requested and released in an unpredictable manner. 6.4 CHAOS-arc Real-Time Threads The real-time threads package of [14] are used as the basis for the CHAOS-arc operating system <ref> [28] </ref>. The approach taken is that the schedulability of a thread should be guaranteed before it is actually run. This guarantee can be made at either program compilation time or at the time of thread creation.
Reference: [29] <author> Brian D. Marsh, Michael L. Scott, Thomas J. LeBlanc, and Evangelos P. Markatos, </author> <title> First-class user-level threads, </title> <booktitle> in Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: Initially, threads were supported in the kernel of general purpose operating systems, e.g., the Mach threads. Such threads proved to be inefficient and later work demonstrated that user level threads perform best <ref> [29, 30] </ref>. However, many of the assumptions and requirements that make non-real-time thread packages suitable to run at the user level are not true for real-time threads.
Reference: [30] <author> Thomas E. Anderson, Brian N. Bershad, Edward D. Lazowska, and Henry M. Levy, </author> <title> Scheduler activations: Effective kernel support for the user-level management of parallelism, </title> <booktitle> in Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <month> Oct. </month> <year> 1991. </year> <month> 35 </month>
Reference-contexts: Initially, threads were supported in the kernel of general purpose operating systems, e.g., the Mach threads. Such threads proved to be inefficient and later work demonstrated that user level threads perform best <ref> [29, 30] </ref>. However, many of the assumptions and requirements that make non-real-time thread packages suitable to run at the user level are not true for real-time threads.
References-found: 30

