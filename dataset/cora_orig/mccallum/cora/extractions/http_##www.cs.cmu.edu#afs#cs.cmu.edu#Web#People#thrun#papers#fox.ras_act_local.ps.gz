URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/thrun/papers/fox.ras_act_local.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/thrun/papers/full.html
Root-URL: http://www.cs.cmu.edu
Title: Active Markov Localization for Mobile Robots  
Author: Dieter Fox, Wolfram Burgard Sebastian Thrun 
Keyword: Key words: Robot Position Estimation, Autonomous Service Robots  
Address: D-53117 Bonn, Germany  Pittsburgh, PA 15213  
Affiliation: Dept. of Computer Science III, University of Bonn,  Dept. of Computer Science, Carnegie Mellon University  
Abstract: Localization is the problem of determining the position of a mobile robot from sensor data. Most existing localization approaches are passive, i.e., they do not exploit the opportunity to control the robot's effectors during localization. This paper proposes an active localization approach. The approach is based on Markov localization and provides rational criteria for (1) setting the robot's motion direction (exploration), and (2) determining the pointing direction of the sensors so as to most efficiently localize the robot. Furthermore, it is able to deal with noisy sensors and approximative world models. The appropriateness of our approach is demonstrated empirically using a mobile robot in a structured office environment. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D.H. Ballard and C.M. Brown. </author> <title> Computer Vision. </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: For example, choosing the right action during exploration can reduce exponential complexity to low-degree polynomial complexity, as for example shown in Koenig's and Thrun's work on exploration in heuristic search and learning control [14,21]. Similarly, active vision (see e.g., <ref> [1] </ref>) has also led to results superior to passive approaches to computer vision. In the context of mobile robot localization, actively controlling a robot is particularly beneficial when the environment possesses relatively few features that enable a robot to unambiguously determine its location.
Reference: [2] <author> M. Beetz, W. Burgard, D. Fox, </author> <title> and A.B. Cremers. Integrating active localization into high-level robot control systems. </title> <journal> Robotics and Autonomous Systems, </journal> <note> Special Issue for SIRS'97, to appear. </note>
Reference-contexts: This observation is the basis for a selective computation scheme, which enhances the computational speed of the algorithm. Our implementation only considers 4 locations l for which Bel (L = l) is above a threshold 1 (see <ref> [2] </ref> for more details).
Reference: [3] <author> J. Borenstein, B. Everett, and L. Feng. </author> <title> Navigating Mobile Robots: Systems and Techniques. </title> <editor> A. K. Peters, </editor> <publisher> Ltd., </publisher> <address> Wellesley, MA, </address> <year> 1996. </year>
Reference-contexts: 1 Introduction To navigate reliably in indoor environments, a mobile robot must know where it is. Over the last few years, there has been a tremendous scientific interest in algorithms for estimating a robot's location from sensor data. A recent book on this issue <ref> [3] </ref> illustrates the importance of the localization problem and provides a unique description of the state-of-the-art. The majority of existing approaches to localization are passive. Passive localization exclusively addresses the estimation of the location based on an incoming stream of sensor data. <p> Our implementation assumes that initially, the robot is given a metric map of its environment, but it does not know where it is. Notice that this is a difficult localization problem; most existing approaches (see, e.g., <ref> [3] </ref>) concentrate on situations where the initial robot location is known and are not capable of localizing a robot from scratch. Our approach has been empirically tested using a mobile robot equipped with a circular array of 24 ultrasound sensors. <p> The key experimental result is that the efficiency of localization is improved drastically by actively controlling the robot's motion direction and by actively controlling its sensors. 2 Related Work While most research has concentrated on passive localization (see e.g., <ref> [3] </ref>), active localization has received considerably little attention in the mobile robotics community. This is primarily because the majority of literature concerned with robot control (e.g., the planning community) assumes that the position of the robot is known, whereas research on localization has mainly focused on the estimation problem itself.
Reference: [4] <author> W. Burgard, A.B. Cremers, D. Fox, D. Hahnel, G. Lakemeyer, D. Schulz, W. Steiner, and S. Thrun. </author> <title> The interactive museum tour-guide robot. </title> <booktitle> In Proc.of the Fifteenth National 13 Conference on Artificial Intelligence, </booktitle> <address> Madison, Wi, </address> <year> 1998. </year>
Reference: [5] <author> W. Burgard, D. Fox, and D. Hennig. </author> <title> Fast grid-based position tracking for mobile robots. </title> <booktitle> In Proc. of the 21th German Conference on Artificial Intelligence, </booktitle> <address> Germany. </address> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: Sensor model of ultrasound sensors and laser-range finders. Please note that the higher accuracy of laser-range finders versus ultrasound sensors is represented by a smaller standard deviation of the Gaussian distribution. With this sensor model, computing p (sjl) amounts to a fast series of two table look-ups (see <ref> [5] </ref> for more details). (2) Selective Computation. Most of the time the probability mass is centered on a small number of location. With the exception of the initial global localization phase, the vast majority of probabilities Bel (L = l) are usually close to 0 and can safely be ignored.
Reference: [6] <author> W. Burgard, D. Fox, D. Hennig, and T. Schmidt. </author> <title> Estimating the absolute position of a mobile robot using position probability grids. </title> <booktitle> In Proc. of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <year> 1996. </year>
Reference: [7] <author> D. Fox, W. Burgard, and S. Thrun. </author> <title> The dynamic window approach to collision avoidance. </title> <journal> IEEE Robotics & Automation Magazine, </journal> <volume> 4(1), </volume> <month> March </month> <year> 1997. </year>
Reference-contexts: In our implementation a global planning module uses dynamic programming as described in section 4.2 to generate a cost minimal path to the target location (see [20]). Intermediate target points on this path are presented to our reactive collision avoidance technique described in <ref> [7] </ref>. The collision avoidance then generates motion commands to safely guide the robot to these targets. An overview of the architecture of the navigation system is given in [22,4].
Reference: [8] <author> D. Fox, W. Burgard, S. Thrun, </author> <title> and A.B. Cremers. A hybrid collision avoidance method for mobile robots. </title> <booktitle> In Proc. of the IEEE International Conference on Robotics and Automation, </booktitle> <address> Belgium, </address> <year> 1998. </year> <note> to appear. </note>
Reference: [9] <author> D. Fox, W. Burgard, S. Thrun, </author> <title> and A.B. Cremers. Position estimation for mobile robots in dynamic environments. </title> <booktitle> In Proc.of the Fifteenth National Conference on Artificial Intelligence, </booktitle> <address> Madison,WI, </address> <year> 1998. </year>
Reference: [10] <editor> J. Hertzberg and F. Kirchner. </editor> <booktitle> Landmark-based autonomous navigation in sewerage pipes. In Proc. of the First Euromicro Workshop on Advanced Mobile Robots. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1996. </year>
Reference: [11] <author> L.P. Kaelbling, A.R. Cassandra, and J.A. Kurien. </author> <title> Acting under uncertainty: Discrete bayesian models for mobile-robot navigation. </title> <booktitle> In Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems, </booktitle> <year> 1996. </year>
Reference-contexts: In recent years, navigation under uncertainty has been addressed by a few researchers [17,19], who developed the Markov navigation paradigm. However, both their approaches do not aim at actively localizing the robot. Localization occurs as a side effect when operating the robot under uncertainty. Moreover, as argued by Kaelbling <ref> [11] </ref>, there exist conditions under which the approach reported in [19] can exhibit cyclic behavior due to uncertainty in localization. On the forefront of localization driven naviga 2 tion, [15] used a rehearsal procedure to check whether a location has been visited while learning a map. <p> In [12], acting in the environment is modeled as a partially observable Markov decision process (POMDP). This approach derives an optimal strategy for moving to a target location given that the position of the robot is not known perfectly. In <ref> [11] </ref> this method is extended by actions allowing the robot to improve its position estimation. This is done by minimizing the expected entropy after the immediate next robot control action. While this approach is computa-tionally tractable, its greediness might prevent it from finding efficient solutions in realistic environments.
Reference: [12] <author> L.P. Kaelbling, </author> <title> M.L. Littman, and A.R. Cassandra. Planning and acting in partially observable stochastic domains. </title> <type> Technical report, </type> <institution> Brown University, </institution> <year> 1995. </year>
Reference-contexts: In [13] the problem of active localization is treated theoretically in finding critical directions within the environment under the assumption of perfect sensors. In <ref> [12] </ref>, acting in the environment is modeled as a partially observable Markov decision process (POMDP). This approach derives an optimal strategy for moving to a target location given that the position of the robot is not known perfectly.
Reference: [13] <author> J. Kleinberg. </author> <title> The localization problem for mobile robots. </title> <booktitle> In Proc. of the 35th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1994. </year>
Reference-contexts: On the forefront of localization driven naviga 2 tion, [15] used a rehearsal procedure to check whether a location has been visited while learning a map. In <ref> [13] </ref> the problem of active localization is treated theoretically in finding critical directions within the environment under the assumption of perfect sensors. In [12], acting in the environment is modeled as a partially observable Markov decision process (POMDP).
Reference: [14] <author> S. Koenig. </author> <title> The complexity of real-time search. </title> <type> Technical Report CMU-CS-92-145, </type> <institution> Carnegie Mellon University, </institution> <month> April </month> <year> 1992. </year>
Reference: [15] <author> B. Kuipers and Y.T. Byun. </author> <title> A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <month> 8 </month> <year> 1981. </year>
Reference-contexts: Localization occurs as a side effect when operating the robot under uncertainty. Moreover, as argued by Kaelbling [11], there exist conditions under which the approach reported in [19] can exhibit cyclic behavior due to uncertainty in localization. On the forefront of localization driven naviga 2 tion, <ref> [15] </ref> used a rehearsal procedure to check whether a location has been visited while learning a map. In [13] the problem of active localization is treated theoretically in finding critical directions within the environment under the assumption of perfect sensors.
Reference: [16] <author> M.L. Littman, T.L. Dean, </author> <title> and L.P. Kaelbling. On the complexity of solving markov decision problems. </title> <booktitle> In Proc. of the Eleventh International Conference on Uncertainty in Artificial Intelligence, </booktitle> <year> 1995. </year>
Reference-contexts: The result is the expected occupancy of a point a relative to the robot. Cost and cost-optimal paths: Based on p occ (a), the expected path length and the cost-optimal policy can be obtained through value iteration, a popular version of dynamic programming (see e.g., <ref> [16] </ref> for details). Value iteration assigns to each location a a value v (a) that represents its distance to the robot. Initially, v (a) is set to 0 for the location a = (0; 0) (which is the robot's location), and 1 for all other locations a.
Reference: [17] <author> I. Nourbakhsh, R. Powers, and S. Birchfield. </author> <title> DERVISH an office-navigating robot. </title> <journal> AI Magazine, </journal> <volume> 16(2), </volume> <month> Summer </month> <year> 1995. </year>
Reference: [18] <author> Stuart J. Russell and Peter Norvig. </author> <title> Artificial Intelligence: A Modern Approach, </title> <booktitle> chapter 17. Number 0-13-103805-2 in Series in Artificial Intelligence. </booktitle> <publisher> Prentice Hall, </publisher> <year> 1995. </year>
Reference-contexts: give better-than-random results when applied to localization, their primary goal is not to localize a robot, and there are situations in which they will fail to do so. 3 Markov Localization 3.1 General Equations This section briefly outlines the basic Markov localization algorithm upon which our approach is based (see <ref> [18] </ref> for a detailed introduction). The key idea of Markov localization is to compute a probability distribution over all possible locations in the environment. Bel (L t = l) denotes the robot's belief of being at position l at time t.
Reference: [19] <author> R. Simmons and S. Koenig. </author> <title> Probabilistic robot navigation in partially observable environments. </title> <booktitle> In Proc. of the International Joint Conference on Artificial Intelligence, </booktitle> <year> 1995. </year>
Reference-contexts: However, both their approaches do not aim at actively localizing the robot. Localization occurs as a side effect when operating the robot under uncertainty. Moreover, as argued by Kaelbling [11], there exist conditions under which the approach reported in <ref> [19] </ref> can exhibit cyclic behavior due to uncertainty in localization. On the forefront of localization driven naviga 2 tion, [15] used a rehearsal procedure to check whether a location has been visited while learning a map.
Reference: [20] <author> S. Thrun. </author> <title> Learning metric-topological maps for indoor mobile robot navigation. </title> <journal> Journal of Artificial Intelligence. </journal> <note> to appear. </note>
Reference-contexts: For example, if disambiguating the robot's position requires the robot to move to a remote location, greedy single-step entropy minimization can fail to make the robot move there. In our own work <ref> [20] </ref>, we have developed robot exploration techniques for efficiently mapping unknown environments. <p> To overcome these problems the robot must be controlled by a reactive collision avoidance technique. In our implementation a global planning module uses dynamic programming as described in section 4.2 to generate a cost minimal path to the target location (see <ref> [20] </ref>). Intermediate target points on this path are presented to our reactive collision avoidance technique described in [7]. The collision avoidance then generates motion commands to safely guide the robot to these targets. An overview of the architecture of the navigation system is given in [22,4].
Reference: [21] <author> S. Thrun. </author> <title> The role of exploration in learning control. </title> <editor> In D. A. White and D. A. Sofge, editors, </editor> <title> Handbook of intelligent control: neural, fuzzy and adaptive approaches. </title> <publisher> Van Nostrand Reinhold, </publisher> <address> Florence, Kentucky 41022, </address> <year> 1992. </year>
Reference: [22] <author> S. Thrun, A. Bucken, W. Burgard, D. Fox, T. Frohlinghaus, D. Hennig, T. Hofmann, M. Krell, and T. Schimdt. </author> <title> Map learning and high-speed navigation in RHINO. </title> <publisher> MIT/AAAI Press, </publisher> <address> Cambridge, MA, </address> <year> 1998. </year> <month> 14 </month>
References-found: 22

