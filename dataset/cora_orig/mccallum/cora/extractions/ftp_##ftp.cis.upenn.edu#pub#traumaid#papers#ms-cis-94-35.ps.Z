URL: ftp://ftp.cis.upenn.edu/pub/traumaid/papers/ms-cis-94-35.ps.Z
Refering-URL: http://www.cis.upenn.edu/~traumaid/pub.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: agertner@linc.cis.upenn.edu  
Title: Critiquing: Effective Decision Support in Time-Critical Domains  
Author: Abigail S. Gertner 
Degree: Dissertation Proposal  
Address: Philadelphia, PA 19104  
Affiliation: Department of Computer and Information Science University of Pennsylvania  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> James F. Allen and C. Raymond Perrault. </author> <title> Analyzing intention in utterances. </title> <journal> Artificial Intelligence, </journal> <volume> 15 </volume> <pages> 143-178, </pages> <year> 1980. </year>
Reference-contexts: the scribe nurse, who can then convey it to the physician. 4.3 Recognizing the Physician's Plan From the early days of plan recognition research, it has been recognized that understanding a user's goals or intentions is important if systems are to be able to respond intelligently to the user's needs <ref> [1, 42] </ref>. This idea has been exploited in such applications as dialogue and text understanding [1, 5, 6, 15, 22], intelligent computer-assisted instruction (ICAI) [23, 24], and intelligent interface design [14]. <p> This idea has been exploited in such applications as dialogue and text understanding <ref> [1, 5, 6, 15, 22] </ref>, intelligent computer-assisted instruction (ICAI) [23, 24], and intelligent interface design [14]. <p> These systems work on the assumption that if an agent is understood to have a plan that could be part of some higher level domain plan, then the agent is actually pursuing that higher level plan. In language understanding systems <ref> [1, 5, 42] </ref>, the observed actions are utterances, which are assumed to fit into an overall plan on the part of the speaker. The recognition of domain plans is recursively generated from the recognition of utterance-level intentions or speech acts using heuristic rules to determine the most coherent relationship possible.
Reference: [2] <author> J.G. Anderson, S.J. Jay, H.M. Schweer, and M.M. Anderson. </author> <title> Why doctors don't use computers: some empirical findings. </title> <journal> Journal of the Royal Society of Medicine, </journal> <volume> 79 </volume> <pages> 142-144, </pages> <month> March </month> <year> 1986. </year>
Reference-contexts: While recognizing their potential for improving the quality of patient care and for controlling costs, physicians have tended to reject new technologies which they see as intrusive, time-consuming, or a challenge to their judgment or autonomy as clinical decision-makers <ref> [2] </ref>. The approach a system uses for human-computer interaction, therefore, plays an essential role in its ultimate effectiveness.
Reference: [3] <author> J.A. Bateman and C.L. Paris. </author> <title> Phrasing a text in terms the user can understand. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, Michigan, </address> <year> 1989. </year>
Reference-contexts: Since a critique is an evaluation of the user's reasoning, it is important to present it in a manner which will not be insulting or argumentative. An understanding of the impact of particular speech acts, words, and phrases is important for this purpose <ref> [3] </ref>. Deep generation involves selecting the content and organization of text. Both of these elements differ between explanation and critiquing. In terms of the content of the text, unlike explanations, critiques need to present alternative solutions to a single problem.
Reference: [4] <author> Karen E. Bradshaw, Reed M. Gardner, and T. Allan Pryor. </author> <title> Development of a computerized laboratory alerting system. </title> <journal> Computers and Biomedical Research, </journal> <volume> 22 </volume> <pages> 575-587, </pages> <year> 1989. </year>
Reference-contexts: This issue will be explored further in the discussion of critique generation in Chapter 4. 3.8 Reminders and Alerts Another approach to on-line decision support that is related to critiquing is represented by reminder or alerting systems <ref> [4, 26] </ref>. These systems are designed to monitor the data stored in computerized hospital information systems and produce alerts or reminders when a situation arises that should potentially be attended to. <p> An alert or reminder will be provided regardless of whether the physician has already indicated an intention to address that issue. Therefore, these systems are bound to produce a number of unnecces-sary comments, which may be the reason that physicians using the HELP system <ref> [4] </ref> indicated that the best method of communicating alerts would be to relay them to a nurse, who could then evaluate them and pass them on to the physican, thus adding a level of indirection between the system and the primary care-giver. 21 Chapter 4 TraumaTIQ: a Real-Time Critiquing Interface for
Reference: [5] <author> Sandra Carberry. </author> <title> Modeling the user's plans and goals. </title> <journal> Computational Linguistics, </journal> <volume> 14(3) </volume> <pages> 23-37, </pages> <year> 1988. </year>
Reference-contexts: This idea has been exploited in such applications as dialogue and text understanding <ref> [1, 5, 6, 15, 22] </ref>, intelligent computer-assisted instruction (ICAI) [23, 24], and intelligent interface design [14]. <p> These systems work on the assumption that if an agent is understood to have a plan that could be part of some higher level domain plan, then the agent is actually pursuing that higher level plan. In language understanding systems <ref> [1, 5, 42] </ref>, the observed actions are utterances, which are assumed to fit into an overall plan on the part of the speaker. The recognition of domain plans is recursively generated from the recognition of utterance-level intentions or speech acts using heuristic rules to determine the most coherent relationship possible.
Reference: [6] <author> Eugene Charniak and Robert P. Goldman. </author> <title> A bayesian model of plan recognition. </title> <journal> Artificial Intelligence, </journal> <volume> 64 </volume> <pages> 53-79, </pages> <year> 1993. </year>
Reference-contexts: This idea has been exploited in such applications as dialogue and text understanding <ref> [1, 5, 6, 15, 22] </ref>, intelligent computer-assisted instruction (ICAI) [23, 24], and intelligent interface design [14].
Reference: [7] <author> Brant Cheikes. </author> <title> Planning Responses From High-Level Goals: Adopting the Respondent's Perspective in Cooperative Response Generation. </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, </institution> <address> Philadelphia, PA, </address> <year> 1992. </year>
Reference-contexts: implicit query: "Is this (partial) plan acceptable in the current situation?" Like other models of cooperative response generation (CRG), I will be concerned with issues of plan inference, plan evaluation, user modelling, and response planning. (For a discussion of the range of work on CRG, see the literature review in <ref> [7] </ref>.) However, unlike other work in this area, which has focused on the interaction between an "expert" system and a "novice" 5 user, I am modelling the interaction between two experts or near-experts who share a common top-level goal managing the patient as effectively as possible.
Reference: [8] <author> J. R. Clarke. </author> <title> Clinical surgical decision making. In I.M. Rutkow, editor, </title> <journal> Socioeconomics of Surgery, </journal> <volume> chapter 19, </volume> <pages> pages 315-331. </pages> <address> Mosby, St. Louis, </address> <year> 1989. </year>
Reference-contexts: These biases have been demonstrated not just in untrained subjects reasoning about an unfamiliar domain, but also in the reasoning of experts, such as surgeons, who are trained in their area of expertise and may also have some background in statistics and formal reasoning <ref> [8, 43] </ref>. In Chapter 3 I will describe an approach to critiquing that makes explicit use of knowledge about these types of judgment biases [43]. <p> the general population: a patient who has symptoms consistent with a diagnosis of appendicitis, but whose symptoms are identical to the textbook description of some extremely rare disease is still more likely to have appendicitis purely on the basis of the much higher rate of appendicitis in the general population <ref> [8] </ref>. Failure to pursue appropriate therapy may therefore be the result of an incorrect diagnosis resulting from a representativeness bias. 8 2.3 Critiquing in Different Domains As we will see in Chapter 3, the critiquing approach has been used in a wide variety of applications in many different domains.
Reference: [9] <author> J. R. Clarke, R. Rymon, B. L. Webber, C. Hayward, T. Santora, D. Wagner, C. Friedman, A. Ruffin, C. Blank, L. Nieman, and A. B. Eastman. </author> <title> Computer-generated protocols: A tool for quality control during the initial definitive management of trauma patients. </title> <booktitle> Submitted to the Annual Meeting of the American Assoc. for the Surgery of Trauma, </booktitle> <month> September </month> <year> 1993. </year>
Reference-contexts: Unfortunately, however, the care given by even experienced trauma surgeons is often sub-optimal, although these problems do not always have an effect on the patient outcome. Support for this claim comes from the analysis of data from a study evaluating the performance of TraumAID 2.0 (see <ref> [9, 41] </ref>). This analysis suggests that the actual performance of physicians on real cases is not always acceptable to experts in the field of trauma surgery. <p> In order to develop criteria for assigning particular errors to one of the three categories above, I intend to make use of the data from a retrospective evaluation of TraumAID's performance as a management planner <ref> [9, 41] </ref>. These data consist of a step-by-step evaluation of the management plans produced by two versions of the TraumAID system (TraumAID 1.0 and TraumAID 2.0), as well as the actual care provided, for 97 real trauma cases. Three trauma surgeons evaluated all three versions of each case. <p> A comparison of the critiques produced by the system with critiques produced by actual trauma surgeons. It has been shown <ref> [9, 48] </ref> that there is often little agreement between physicians on what constitutes an error that should be commented on.
Reference: [10] <author> Richard E. Fikes and Nils J. Nilsson. </author> <title> STRIPS: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2 </volume> <pages> 189-208, </pages> <year> 1971. </year>
Reference-contexts: The early work in this area drew from the more established work on classical planning, using a representational framework modeled after the approach presented in STRIPS <ref> [10] </ref>. In the STRIPS formalism, a plan is a sequence of operators leading from a starting state to a goal state.
Reference: [11] <author> G. Fischer, A. C. Lemke, T. Mastaglio, and A. I. Morch. </author> <title> The role of critiquing in cooperative problem solving. </title> <journal> ACM Transactions on Information Systems, </journal> <year> 1991. </year>
Reference-contexts: Several researchers have pointed out that one of the advantages of critiquing is that it does not require a complete specification of the domain in order to be able to critique proposed solutions <ref> [11] </ref>. This does not mean, however, that such a specification is not useful, but rather that if it is not available, a critiquing system can still be implemented since it is possible to critique a proposal without having an alternative plan worked out. <p> In some domains, such as the domain of kitchen design considered by the critiquing system JANUS <ref> [11] </ref>, 1 Plan inference in this system is simple because the goals he considers for ventilator management are independent, and each action can only be used to satisfy one goal. <p> These stories serve as a critique, pointing out potential problems with the design the user has suggested. Another approach to design critiquing appears in LISP-CRITIC <ref> [11] </ref>. <p> One shortcoming of this system is that it is not able to evaluate the effect of its suggested transformations on the correctness of the code. JANUS <ref> [11] </ref> is a design environment for the construction of kitchen designs. The critiquing component of JANUS has knowledge about building codes, safety standards, and functional preferences. When a rule is violated, the system displays a message explaining the nature of the problem. <p> As was discussed earlier in this paper, plan evaluation can be done using a differential or an analytical approach <ref> [11, 12] </ref>. 30 The former method compares the user's plan to a "correct" plan generated by the system, while the latter evaluates plans with respect to a predefined specification of constraints on the solution without actually generating its own solution. <p> On the other hand, an analytical system for kitchen design might include a rule that the stove should be no less than five feet from the sink (see the JANUS system <ref> [11] </ref>). If this rule is violated in a proposed design, the system can cite it as a reason for not accepting the design. The model of plan evaluation that I am developing for TraumaTIQ makes use of the best features of both differential and analytical approaches.
Reference: [12] <author> Gerhard Fischer, Andreas C. Lemke, and Thomas Mastaglio. Critics: </author> <title> An emerging approach to knowledge-based human computer interaction. </title> <booktitle> In Conference on Human Factors in Computing Systems, </booktitle> <year> 1990. </year>
Reference-contexts: The evaluation indicates that the critiquing system can produce useful comments from the data in medical records. 3.4 Critiquing Designs Another area in which the critiquing paradigm has been applied with some success is that of design critiquing <ref> [12, 19, 39] </ref>. This is a rather different application of critiquing than I am concerned with for this project. Critics have been implemented to assist with the design of buildings, individual room layouts, computer programs, etc. <p> As was discussed earlier in this paper, plan evaluation can be done using a differential or an analytical approach <ref> [11, 12] </ref>. 30 The former method compares the user's plan to a "correct" plan generated by the system, while the latter evaluates plans with respect to a predefined specification of constraints on the solution without actually generating its own solution.
Reference: [13] <author> Gerhard Fischer, Kumiyo Nakakoji, and Jonathan Ostwald. Critics: </author> <title> Facilitating knowledge delivery and knowledge construction in integrated design environments. </title> <booktitle> In AAAI-93 Workshop on Expert Critiquing Systems, </booktitle> <year> 1993. </year>
Reference-contexts: JANUS [11] is a design environment for the construction of kitchen designs. The critiquing component of JANUS has knowledge about building codes, safety standards, and functional preferences. When a rule is violated, the system displays a message explaining the nature of the problem. An extension of this system, KID <ref> [13] </ref> allows the user to specify their high-level goals and priorities for a particular design, thus introducing greater flexibility into the system.
Reference: [14] <author> Bradley A. Goodman and Diane J. Litman. </author> <title> On the interaction between plan recognition and intelligent interfaces. User Modeling and User-Adapted Interaction, </title> <address> 2(1-2):55-82, </address> <year> 1992. </year>
Reference-contexts: This idea has been exploited in such applications as dialogue and text understanding [1, 5, 6, 15, 22], intelligent computer-assisted instruction (ICAI) [23, 24], and intelligent interface design <ref> [14] </ref>. At the same time, formal models have been developed in order to study the semantics of plan recognition in a rigorous way [18]. 26 Plan recognition problems vary according to a number of properties (see [18]). <p> realistic approach in this case is to use information about the situation in which the plan is being developed in order to infer the most likely plan that the physician would have developed that explains all the observations. 4.3.2 TraumaTIQ: Using expectations to infer a plan As Goodman and Litman <ref> [14] </ref> point out, formal models of plan recognition, while interesting in their own right, tell us little about how to implement a practical plan recognition system. Practical system design often involves making assumptions about the user and the domain in order to control computation and resolve ambiguities.
Reference: [15] <author> Barbara J. Grosz and Candace L. Sidner. </author> <title> Attentions, intentions and the structure of discourse. </title> <journal> Computational Linguistics, </journal> <volume> 12 </volume> <pages> 175-204, </pages> <year> 1986. </year>
Reference-contexts: This idea has been exploited in such applications as dialogue and text understanding <ref> [1, 5, 6, 15, 22] </ref>, intelligent computer-assisted instruction (ICAI) [23, 24], and intelligent interface design [14].
Reference: [16] <author> Karen E. Huff and Victor R. Lesser. </author> <title> Integrating plausible reasoning in an incremental plan recognizer. </title> <type> Technical Report 93-72, </type> <institution> University of Massachusetts, Amherst, </institution> <year> 1993. </year>
Reference-contexts: Huff and Lesser have pointed out the advantages of using contextual knowledge and basic domain principles to guide the search for an explanatory plan <ref> [16] </ref>.
Reference: [17] <author> Daniel Kahneman, Paul Slovic, and Amos Tversky, </author> <title> editors. Judgement under uncertainty: Heuristics and biases. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1982. </year>
Reference-contexts: The occurrence of errors in management plans suggests that the physicians responsible for the delivery of care sometimes have incorrect or missing knowledge, which can be counteracted with a simple reminder, or they experience lapses in judgment, such as those described in the literature on heuristic biases in decision-making <ref> [17] </ref>. From the point of view of critiquing, it may be advantageous to be able to detect when such biases might be influencing a physician's decision-making. <p> The process by which people make judgments and come to conclusions with incomplete knowledge and in uncertain situations has been the subject of numerous experimental studies, such as those presented in <ref> [17] </ref>. For example, Kahneman and Tversky have demonstrated that people making judgments based on uncertain information make use of heuristic rules to guide them toward conclusions.
Reference: [18] <author> Henry Kautz. </author> <title> A circumscriptive theory of plan recognition. </title> <editor> In Jerry Morgan Philip R. Cohen and Martha E. Pollack, editors, </editor> <title> Intentions in Communication. </title> <publisher> Bradford Books, </publisher> <year> 1990. </year>
Reference-contexts: At the same time, formal models have been developed in order to study the semantics of plan recognition in a rigorous way <ref> [18] </ref>. 26 Plan recognition problems vary according to a number of properties (see [18]). <p> At the same time, formal models have been developed in order to study the semantics of plan recognition in a rigorous way <ref> [18] </ref>. 26 Plan recognition problems vary according to a number of properties (see [18]). <p> A Formal Model of Keyhole Recognition In his work on plan recognition, Kautz <ref> [18] </ref> focuses exclusively on keyhole recognition of correct plans where the system has complete knowledge of the domain. He represents knowledge of plans as an abstraction hierarchy, connected by is-a links and is-step links.
Reference: [19] <author> J.L. Kolodner, </author> <title> E.A. Domeshek, and C.M. Zimring. Case-based design critiquing. </title> <booktitle> In AAAI-93 Workshop on Expert Critiquing Systems, </booktitle> <pages> pages 109-114, </pages> <year> 1993. </year>
Reference-contexts: The evaluation indicates that the critiquing system can produce useful comments from the data in medical records. 3.4 Critiquing Designs Another area in which the critiquing paradigm has been applied with some success is that of design critiquing <ref> [12, 19, 39] </ref>. This is a rather different application of critiquing than I am concerned with for this project. Critics have been implemented to assist with the design of buildings, individual room layouts, computer programs, etc. <p> In addition, since there is less of a sense of there being a "right answer" in design critiquing than in plan critiquing, the system does not have to generate its own solution in order to produce a critique. The Archie system <ref> [19] </ref> for assisting design in the domain of architecture uses a case-based approach to critiquing. The user interested in evaluating a potential building design inputs a description of the conceptual design of the building, and the system searches its database for relevant stories taken from evaluations of existing buildings.
Reference: [20] <author> Lynne Lambert and Sandra Carberry. </author> <title> A tripartite, plan-based model of dialogue. </title> <booktitle> In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, </booktitle> <year> 1991. </year>
Reference-contexts: More recent work in this area has focused on the need for more flexible representations of plans to account for such phenomena as reasoning about plans that have not yet been adopted, constructing alternative plans to achieve the same goal, and recognizing incorrect plans <ref> [20, 22, 34] </ref>. In particular, Pollack [34, 35] has argued that a plan should be thought of not in terms of a static recipe-for-action, but rather in terms of the complex mental attitudes that people have toward the actions that make up their plans.
Reference: [21] <author> C. P. Langlotz and E. H. Shortliffe. </author> <title> Adapting a consultation system to critique user plans. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 19 </volume> <pages> 479-496, </pages> <year> 1983. </year>
Reference-contexts: Here, a global evaluation of the plan is important. The second dimension is the depth of domain knowledge required to produce an effective critique. The most straightforward domains for critiquing are those in which there are established approaches to management, such as the oncology protocols used in ONCOCIN <ref> [21] </ref>. Here, the critiquing system needs only to recognize where the user's solution deviates from the established procedure. At the other extreme are problems that require reasoning from basic principles. Miller also identifies an intermediate level of domain knowledge that he refers to as the level of treatment goals. <p> Also, the focus of these systems on getting a correct diagnosis before proceeding to treatment is not shared by TraumAID. It is less important to TraumAID that the physician gets the correct diagnosis than that he does the right thing. 3.2 ONCOCIN: User-guided critiquing The ONCOCIN system <ref> [21] </ref> is an example of an expert consulting system that was adapted to critique user solutions rather than present its own recommendations.
Reference: [22] <author> Diane Litman and James Allen. </author> <title> Discourse processing and commonsense plans. </title> <editor> In Jerry Morgan Philip Cohen and James Allen, editors, </editor> <title> Intentions in Communication. </title> <publisher> MIT Press, </publisher> <year> 1989. </year> <month> 50 </month>
Reference-contexts: This idea has been exploited in such applications as dialogue and text understanding <ref> [1, 5, 6, 15, 22] </ref>, intelligent computer-assisted instruction (ICAI) [23, 24], and intelligent interface design [14]. <p> More recent work in this area has focused on the need for more flexible representations of plans to account for such phenomena as reasoning about plans that have not yet been adopted, constructing alternative plans to achieve the same goal, and recognizing incorrect plans <ref> [20, 22, 34] </ref>. In particular, Pollack [34, 35] has argued that a plan should be thought of not in terms of a static recipe-for-action, but rather in terms of the complex mental attitudes that people have toward the actions that make up their plans.
Reference: [23] <author> Robert London. </author> <title> Student modeling to support multiple instructional ap-proaches. User Modeling and User-Adapted Interaction, </title> <address> 2(1-2):117-154, </address> <year> 1992. </year>
Reference-contexts: This idea has been exploited in such applications as dialogue and text understanding [1, 5, 6, 15, 22], intelligent computer-assisted instruction (ICAI) <ref> [23, 24] </ref>, and intelligent interface design [14]. At the same time, formal models have been developed in order to study the semantics of plan recognition in a rigorous way [18]. 26 Plan recognition problems vary according to a number of properties (see [18]).
Reference: [24] <author> Robert London and William J. Clancey. </author> <title> Plan recognition strategies in student modelling: prediction and description. </title> <booktitle> In Proceedings of the American Association for Artificial Intelligence, </booktitle> <pages> pages 335-338, </pages> <address> Pittsburgh, </address> <year> 1982. </year>
Reference-contexts: This idea has been exploited in such applications as dialogue and text understanding [1, 5, 6, 15, 22], intelligent computer-assisted instruction (ICAI) <ref> [23, 24] </ref>, and intelligent interface design [14]. At the same time, formal models have been developed in order to study the semantics of plan recognition in a rigorous way [18]. 26 Plan recognition problems vary according to a number of properties (see [18]).
Reference: [25] <author> W.C. Mann and S.A. Thomson. </author> <title> Rhetorical structure theory: Description and construction of text structures. </title> <editor> In Gerard Kempen, editor, </editor> <booktitle> Natural Language Generation, </booktitle> <pages> pages 83-96. </pages> <publisher> Martinus Nijhoff, </publisher> <year> 1987. </year>
Reference-contexts: To produce a coherent critique, it is desirable to link related statements together in the final output, either by juxtaposition or by marking certain relationships such as elaborations or motivations with cue words. Rankin uses Rhetorical Structure Theory (RST) <ref> [25] </ref> to organize the comments in his critiques into longer sequences. RST is a model of text structure that uses predefined schemas to represent relationships such as elaboration, motivation, and causation, that can exist between different portions of text.
Reference: [26] <author> Clement J. McDonald, Siu L. Hui, David M. Smith, William M. Tierney, Stuart J. Cohen, Morris Weinberger, and George P. McCabe. </author> <title> Reminders to physicians from an introspective computer medical record. </title> <journal> Annals of Internal Medicine, </journal> <volume> 100 </volume> <pages> 130-138, </pages> <year> 1984. </year>
Reference-contexts: This issue will be explored further in the discussion of critique generation in Chapter 4. 3.8 Reminders and Alerts Another approach to on-line decision support that is related to critiquing is represented by reminder or alerting systems <ref> [4, 26] </ref>. These systems are designed to monitor the data stored in computerized hospital information systems and produce alerts or reminders when a situation arises that should potentially be attended to.
Reference: [27] <author> P. L. Miller. </author> <title> A Critiquing Approach to Expert Computer Advice: </title> <address> ATTENDING. London: </address> <publisher> Pittman Press, </publisher> <year> 1984. </year>
Reference-contexts: In this chapter, I present a brief review of some of the literature relevant to critiquing and discuss their contributions and weaknesses. 3.1 The ATTENDING family of critics The original ATTENDING system <ref> [27] </ref>, which was the first to be called a critiquing system, was designed to critique the management of anesthesia for patients undergoing surgery.
Reference: [28] <author> P. L. Miller. </author> <title> Expert Critiquing Systems: Practice-Based Medical Consultation by Computer. </title> <address> New York: </address> <publisher> Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: The approach a system uses for human-computer interaction, therefore, plays an essential role in its ultimate effectiveness. In general, there are several advantages of using a critiquing approach for decision-support rather than the more standard expert system approach <ref> [28] </ref>: * Acceptability: The difference in perceived roles of human and computer can affect the psychological acceptability of the system to its users: A critiquing system can be seen as assisting the user in developing his plan rather than presenting a contrary solution. <p> In general, then, one would like to be able to describe how the characteristics of a system's domain influences its requirements for critiquing. This issue was explored by Perry Miller in a series of prototype critiquing systems <ref> [28] </ref>. Miller was interested in identifying domain characteristics that would lend themselves to the critiquing approach. He also looked at how different aspects of critiquing might be more or less important in different domains. This experience led him to identify two dimensions along which domains vary. <p> A complete description of the ATTENDING family of critiquing systems is presented in Miller's book <ref> [28] </ref>. HT-ATTENDING is a critic for the pharmacologic management of essential hypertension. This domain has the properties that there are a huge number of drugs that can be used to treat a patient with hypertension, and that clinical knowledge in the field is in rapid flux.
Reference: [29] <author> V.O. Mittal and C.L. Paris. </author> <title> Text generation: Explanation vs. criticism in expert systems. </title> <booktitle> In AAAI-93 Workshop on Expert Critiquing Systems, </booktitle> <year> 1993. </year>
Reference-contexts: More recently, more sophisticated approaches have been proposed, integrating work from the natural language generation community with work on explainable expert systems [32], and allowing for interactive explanation, where the user can request additional clarification or justification in response to the system's explanations [30]. In <ref> [29] </ref>, Mittal and Paris discuss the differences between text generation for explanation and for critiquing, both in terms of surface (tactical) generation and deep (strategic) generation. In critiquing, the interpersonal aspect of the interaction is much more important than it is in explanation.
Reference: [30] <author> J. D. Moore and W.R. Swartout. </author> <title> A reactive approach to explanation. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, Michigan, </address> <year> 1989. </year>
Reference-contexts: More recently, more sophisticated approaches have been proposed, integrating work from the natural language generation community with work on explainable expert systems [32], and allowing for interactive explanation, where the user can request additional clarification or justification in response to the system's explanations <ref> [30] </ref>. In [29], Mittal and Paris discuss the differences between text generation for explanation and for critiquing, both in terms of surface (tactical) generation and deep (strategic) generation. In critiquing, the interpersonal aspect of the interaction is much more important than it is in explanation.
Reference: [31] <author> R. Neches, W. R. Swartout, and J. Moore. </author> <title> Explainable and maintainable expert systems. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 382-389, </pages> <address> Los Angeles, </address> <year> 1985. </year>
Reference-contexts: The KID system is user-extensible, allowing its users to add to the rule-base if the specific situation they 1 This is similar to the Program Enhancement Advisor described in <ref> [31] </ref> except that the latter is more concerned with the knowledge representations necessary to explain the system's reasoning. 16 are concerned with is not covered. 3.5 The deep generation of critique text As I have mentioned previously, one of the major motivations for developing critiquing systems over more traditional consulting systems <p> In developing explainable expert systems, researchers have been concerned primarily with such issues as the level of knowledge representation necessary to provide good explanations, and how to organize explanation into a coherent text <ref> [31] </ref>. More recently, more sophisticated approaches have been proposed, integrating work from the natural language generation community with work on explainable expert systems [32], and allowing for interactive explanation, where the user can request additional clarification or justification in response to the system's explanations [30].
Reference: [32] <author> Cecile Paris. </author> <title> Generation and explanation: Building an explanation facility for the explainable expert systems framework. </title> <editor> In C. Paris, W. Swartout, and W. Mann, editors, </editor> <booktitle> Natural Language Generation in Artificial Intelligence and Computational Linguistics, </booktitle> <pages> pages 49-81. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year>
Reference-contexts: More recently, more sophisticated approaches have been proposed, integrating work from the natural language generation community with work on explainable expert systems <ref> [32] </ref>, and allowing for interactive explanation, where the user can request additional clarification or justification in response to the system's explanations [30]. In [29], Mittal and Paris discuss the differences between text generation for explanation and for critiquing, both in terms of surface (tactical) generation and deep (strategic) generation.
Reference: [33] <author> Cecile L. Paris, William R. Swartout, and William C. Mann, </author> <title> editors. </title> <booktitle> Natural Language Generation in Artificial Intelligence and Computational Linguistics. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference-contexts: This stage of the critiquing process is not yet fully implemented in the TraumaTIQ system, but I will outline here how it will be done. In keeping with the approach seen in the language generation literature <ref> [33] </ref>, the generation process in TraumaTIQ will be separated into two stages: strategic (deep) generation, which involves determining the content and structure of the output, and tactical (surface) generation, in which the actual words and phrases are chosen and put together to produce written or spoken natural language.
Reference: [34] <author> Martha E. Pollack. </author> <title> Inferring domain plans in question-answering. </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, </institution> <year> 1986. </year> <month> 51 </month>
Reference-contexts: More recent work in this area has focused on the need for more flexible representations of plans to account for such phenomena as reasoning about plans that have not yet been adopted, constructing alternative plans to achieve the same goal, and recognizing incorrect plans <ref> [20, 22, 34] </ref>. In particular, Pollack [34, 35] has argued that a plan should be thought of not in terms of a static recipe-for-action, but rather in terms of the complex mental attitudes that people have toward the actions that make up their plans. <p> In particular, Pollack <ref> [34, 35] </ref> has argued that a plan should be thought of not in terms of a static recipe-for-action, but rather in terms of the complex mental attitudes that people have toward the actions that make up their plans.
Reference: [35] <author> Martha E. Pollack. </author> <title> Plans as complex mental attitudes. </title> <editor> In Cohen, Morgan and Pollack, eds. </editor> <title> Intentions in Communication, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA., </address> <year> 1990. </year>
Reference-contexts: In particular, Pollack <ref> [34, 35] </ref> has argued that a plan should be thought of not in terms of a static recipe-for-action, but rather in terms of the complex mental attitudes that people have toward the actions that make up their plans.
Reference: [36] <author> Scott Prevost and Mark Steedman. </author> <title> Generating contextually appropriate intonation. </title> <booktitle> Proceedings of the Sixth Conference of the European Chapter of the Association for Computational Linguistics, </booktitle> <year> 1993. </year>
Reference-contexts: In the future, synthesized speech with contextually appropriate intonations may be used to convey the critique to the physician, thus obviating the need for him to look up to read output on the monitor <ref> [36] </ref>. <p> I will include here a brief discussion of an approach that could be used in the future to generate comments in both written text and natural-sounding synthesized speech. In <ref> [36] </ref>, Prevost and Steedman describe their "functional head-driven, top-down approach" to tactical generation using a Combinatory Categorial Grammar (CCG) formalism. In their paper they discuss how this approach can be used to generate situationally appropriate prosodic stress contours in spoken language output.
Reference: [37] <author> Scott Prevost and Mark Steedman. </author> <title> Using context to specify intonation in speech synthesis. </title> <booktitle> In Proc. EuroSpeech '93, </booktitle> <address> Berlin, Germany, </address> <year> 1993. </year>
Reference-contexts: For the purposes of this project, I will be concerned primarily with the issues associated with strategic generation determining exactly what to say, how to represent concepts for the purposes of language generation, and how to organize the output. The problem of tactical generation will be addressed elsewhere (see <ref> [37] </ref> for an approach to tactical generation applied to the trauma domain.) 4.5.1 Strategic Generation Determining critique content The contents of the critique in this system are driven by the output of the plan evaluation routines, which are responsible for identifying information that should be reported to the physician.
Reference: [38] <author> I. Rankin. </author> <title> The deep generation of text in expert critiquing systems. </title> <type> Licentitate Thesis no.184, </type> <institution> Linkoping University, </institution> <year> 1989. </year>
Reference-contexts: Therefore, it is important that the output of these systems be easy to understand. To this end, Rankin <ref> [38] </ref> has investigated methods for the deep generation of text in critiquing systems. Deep generation, as opposed to surface generation, is concerned with establishing the content and ordering of the comments that will make up the critique. <p> Depending on the level of significance of the particular error, the comment will be assigned an illocutionary force of either INFORM or WARN. 5 The illocu 5 I do not adopt the strategy taken by Rankin <ref> [38] </ref> of commenting on every action proposed by the physician. While this strategy has the advantage of convincing the physician that the system 36 tionary force of a comment could ultimately influence the phrasing and, in the case of spoken critiques, the intonation of the output.
Reference: [39] <author> D. Rochowiak, J. Rogers, and S. Messimer. </author> <title> Composite design and manufacturing critiquing system. </title> <booktitle> In AAAI-93 Workshop on Expert Critiquing Systems, </booktitle> <year> 1993. </year>
Reference-contexts: The evaluation indicates that the critiquing system can produce useful comments from the data in medical records. 3.4 Critiquing Designs Another area in which the critiquing paradigm has been applied with some success is that of design critiquing <ref> [12, 19, 39] </ref>. This is a rather different application of critiquing than I am concerned with for this project. Critics have been implemented to assist with the design of buildings, individual room layouts, computer programs, etc.
Reference: [40] <author> R. Rymon, B. Webber, and J. Clarke. </author> <title> Progressive horizon planning: Planning exploratory-corrective behavior. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 23(6), </volume> <month> November </month> <year> 1993. </year> <note> Special Issue on Planning, Scheduling and Control. </note>
Reference-contexts: I will introduce them in turn and discuss how they address the problems mentioned above. The chapter begins with a brief discussion of the architecture and knowledge representation in TraumAID. For a more complete discussion of the TraumAID system, see <ref> [40, 41, 49] </ref>. 4.1 An Overview of TraumAID 2.0 At the core of the TraumAID system is the integration of a rule-based reasoner that reasons from evidence to conclusions and management goals, with a planner that determines how best to satisfy the set of currently active goals (see Figure 4.2).
Reference: [41] <author> Ron Rymon. </author> <title> Diagnostic Reasoning and Planning in Exploratory-Corrective Domains (Appears as Technical Report MS-CIS-93-84). </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, </institution> <year> 1993. </year>
Reference-contexts: reasoner, that derives conclusions and goals to pursue from the available evidence about the patient, and a planner, that constructs a (partially ordered) plan for how best to address the 1 Currently, the system's knowledge base is restricted to penetrating injuries to the chest and abdomen. 1 currently relevant goals <ref> [41, 49] </ref>. A more detailed discussion of the system appears in Chapter 4. <p> Unfortunately, however, the care given by even experienced trauma surgeons is often sub-optimal, although these problems do not always have an effect on the patient outcome. Support for this claim comes from the analysis of data from a study evaluating the performance of TraumAID 2.0 (see <ref> [9, 41] </ref>). This analysis suggests that the actual performance of physicians on real cases is not always acceptable to experts in the field of trauma surgery. <p> I will introduce them in turn and discuss how they address the problems mentioned above. The chapter begins with a brief discussion of the architecture and knowledge representation in TraumAID. For a more complete discussion of the TraumAID system, see <ref> [40, 41, 49] </ref>. 4.1 An Overview of TraumAID 2.0 At the core of the TraumAID system is the integration of a rule-based reasoner that reasons from evidence to conclusions and management goals, with a planner that determines how best to satisfy the set of currently active goals (see Figure 4.2). <p> After the new set of goals is complete, the planner is invoked to determine how best to satisfy this particular combination of goals. TraumAID's reasoner controls information acquisition using a conservative, staged strategy for diagnosis and treatment <ref> [41] </ref>: expensive, definitive tests are not included in a plan until they are justified by less costly tests or observations, and definitive treatment is not recommended without the results of sufficient evidence from diagnostic tests. 1 These strategies are reflected in the knowledge base by the occurrence of related management goals, <p> In order to develop criteria for assigning particular errors to one of the three categories above, I intend to make use of the data from a retrospective evaluation of TraumAID's performance as a management planner <ref> [9, 41] </ref>. These data consist of a step-by-step evaluation of the management plans produced by two versions of the TraumAID system (TraumAID 1.0 and TraumAID 2.0), as well as the actual care provided, for 97 real trauma cases. Three trauma surgeons evaluated all three versions of each case.
Reference: [42] <author> Candace Sidner. </author> <title> Plan parsing for intended response recognition in discourse. </title> <journal> Computational Intelligence, </journal> <volume> 1, </volume> <year> 1985. </year>
Reference-contexts: the scribe nurse, who can then convey it to the physician. 4.3 Recognizing the Physician's Plan From the early days of plan recognition research, it has been recognized that understanding a user's goals or intentions is important if systems are to be able to respond intelligently to the user's needs <ref> [1, 42] </ref>. This idea has been exploited in such applications as dialogue and text understanding [1, 5, 6, 15, 22], intelligent computer-assisted instruction (ICAI) [23, 24], and intelligent interface design [14]. <p> These systems work on the assumption that if an agent is understood to have a plan that could be part of some higher level domain plan, then the agent is actually pursuing that higher level plan. In language understanding systems <ref> [1, 5, 42] </ref>, the observed actions are utterances, which are assumed to fit into an overall plan on the part of the speaker. The recognition of domain plans is recursively generated from the recognition of utterance-level intentions or speech acts using heuristic rules to determine the most coherent relationship possible.
Reference: [43] <author> Barry G. Silverman. </author> <title> Expert critics: operationalizing the judgement/ decisionmaking literature as a theory of "bugs" and repair strategies. </title> <journal> Knowledge Acquisition, </journal> <volume> 3 </volume> <pages> 175-214, </pages> <year> 1991. </year>
Reference-contexts: These biases have been demonstrated not just in untrained subjects reasoning about an unfamiliar domain, but also in the reasoning of experts, such as surgeons, who are trained in their area of expertise and may also have some background in statistics and formal reasoning <ref> [8, 43] </ref>. In Chapter 3 I will describe an approach to critiquing that makes explicit use of knowledge about these types of judgment biases [43]. <p> In Chapter 3 I will describe an approach to critiquing that makes explicit use of knowledge about these types of judgment biases <ref> [43] </ref>. While this is not the approach I take in my work, I do believe that an understanding of typical judgment biases can be incorporated into the procedures the system uses for inferring and evaluating a physician's plans. <p> which can easily be recalled or assessed Fundamental attribution error Associating success with personal inherent ability and failure with poor luck Knowledge Missing knowledge Trying to solve problems, make decisions or form plans in multi-discipline domains 3.6 Critiquing Based on Cognitive Biases In his research on developing automated critics, Silverman <ref> [43] </ref> has developed what he calls a generative theory of "bugs" to produce a rule base of errors resulting from cognitive biases in information acquisition, information processing, intended output, and attention to feedback (see Figure 3.1). He also recognizes incorrect or missing knowledge as another potential source of error. <p> Once the typical sources of error have been identified, appropriate critiquing strategies can be developed to inform the user about his errors. In the application presented in <ref> [43] </ref>, forecasting potential threats for Army equipment during missions, the user's input is restricted to simple answers to queries from the system.
Reference: [44] <author> Barry G. Silverman. </author> <title> Survey of expert critiquing systems: Practical and theoretical frontiers. </title> <journal> Communications of the ACM, </journal> <volume> 35(4) </volume> <pages> 106-127, </pages> <year> 1992. </year>
Reference-contexts: work that remains to be done as part of this project. 4 Chapter 2 Issues for Critiquing System Design Over the past decade, the term critiquing has been applied to a wide range of applications including therapy planning, knowledge base acquisition, computer aided design, software engineering, and desktop publishing (see <ref> [44] </ref>). What these systems have in common is that they take a problem description and a proposed "solution" or "design" as input from the user and produce some kind of commentary aimed at improving the correctness, efficiency, clarity, and/or workability of the solution.
Reference: [45] <author> Barry G. Silverman. </author> <title> Expert bias research: Issues confronting knowlege engineers. </title> <booktitle> In AAAI-93 Workshop on Expert Critiquing Systems, </booktitle> <year> 1993. </year>
Reference-contexts: The system does not have any deep knowledge of the domain, or of the user's knowledge or reasoning processes. No reasoning about plans is involved in this critic. Ongoing work by Silverman and his colleagues covers three related lines of investigation <ref> [45] </ref>: 1. Expanding the rule-base for the identification of biases to include a greater number of lower-level rules. 2. Identifying the occurrence of biases in the behavior of professionals in specific domains. 3.
Reference: [46] <author> R. L. Teach and E. H. Shortliffe. </author> <title> An analysis of physician attitudes regarding computer-based clinical consultation systems. </title> <journal> Computers and Biomedical Research, </journal> <volume> 14 </volume> <pages> 542-558, </pages> <year> 1981. </year>
Reference-contexts: More in-depth studies of how to identify and critique a single bias, such as confirmation bias. 3.7 The Role of Explanation in Critiquing In their analysis of the attitudes of physicians toward computer-based consultation systems, Teach and Shortliffe <ref> [46] </ref> found that while doctors do not demand that a consultation system always be correct, it must be able to explain its decisions.
Reference: [47] <author> Amos Tversky and Daniel Kahneman. </author> <title> Judgement under uncertainty: heuristics and biases. </title> <editor> In Daniel Kahneman, Paul Slovic, and Amos Tversky, editors, </editor> <title> 52 Judgement under uncertainty: heuristics and biases, </title> <booktitle> chapter 1, </booktitle> <pages> pages 3-20. </pages> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1982. </year>
Reference-contexts: These heuristics are derived from everyday experience and, as such, are often useful in 7 simplifying complicated situations in order to decide what to do. In certain circum-stances, however, they can also lead to systematic, predictable biases <ref> [47] </ref>. These biases have been demonstrated not just in untrained subjects reasoning about an unfamiliar domain, but also in the reasoning of experts, such as surgeons, who are trained in their area of expertise and may also have some background in statistics and formal reasoning [8, 43].
Reference: [48] <author> J. van der Lei. </author> <title> Critiquing Based on Computer-Stored Medical Records. </title> <type> PhD thesis, </type> <institution> Erasmus University, </institution> <year> 1991. </year>
Reference-contexts: consulting session in which ONCOCIN was designed to be used, but it would not be feasible for a system that is intended to function during the management of a patient in need of urgent medical attention. 3.3 Critiquing from Automated Medical Records The HyperCritic system developed by Van der Lei <ref> [48] </ref> looks at patient data stored in automated medical records of patients with hypertension and critiques the therapy reported in those medical records. HyperCritic identifies significant events in the medical records and then uses a set of domain-independent critiquing tasks to assign critiquing statements to those events. <p> A comparison of the critiques produced by the system with critiques produced by actual trauma surgeons. It has been shown <ref> [9, 48] </ref> that there is often little agreement between physicians on what constitutes an error that should be commented on.
Reference: [49] <author> B. L. Webber, R. Rymon, and J. R. Clarke. </author> <title> Flexible support for trauma management through goal-directed reasoning and planning. </title> <journal> Artificial Intelligence in Medicine, </journal> <volume> 4, </volume> <year> 1992. </year> <month> 53 </month>
Reference-contexts: reasoner, that derives conclusions and goals to pursue from the available evidence about the patient, and a planner, that constructs a (partially ordered) plan for how best to address the 1 Currently, the system's knowledge base is restricted to penetrating injuries to the chest and abdomen. 1 currently relevant goals <ref> [41, 49] </ref>. A more detailed discussion of the system appears in Chapter 4. <p> I will introduce them in turn and discuss how they address the problems mentioned above. The chapter begins with a brief discussion of the architecture and knowledge representation in TraumAID. For a more complete discussion of the TraumAID system, see <ref> [40, 41, 49] </ref>. 4.1 An Overview of TraumAID 2.0 At the core of the TraumAID system is the integration of a rule-based reasoner that reasons from evidence to conclusions and management goals, with a planner that determines how best to satisfy the set of currently active goals (see Figure 4.2).
References-found: 49

