URL: http://www.cs.berkeley.edu/~alanm/CP/touch.infocom.94.ps
Refering-URL: http://www.cs.berkeley.edu/~alanm/CP/bib.html
Root-URL: 
Title: 2a.4.1  
Note: 1: Introduction  
Abstract: 1,2 Communication latency can be reduced by increasing bandwidth via a sender-based anticipation technique called Parallel Communication. Here we apply this method to anonymous FTP. Our analysis of log files indicates that latency can be reduced to 2 round-trip times, as small as 0.6 round-trip time/file, for a 7x increase in bandwidth. This technique applies to up to 95% of the FTP traffic. This method is expected to be especially useful in reducing latency in automated FTP access, such as in the World-WideWeb. Current gigabit networking research addresses limitations of communication and computation imposed by factors other than the finite speed of light [10]. Communication limits computation via latency, and computation limits communication, especially regarding coding and compression [13]. There is a need for an information theoretic theory of networks [10]. Just as computation is analyzed at various levels of abstraction, from the Boolean/gate logic levels, through the abstract machine to algorithms, communication must go beyond the bit-level coding and communication theory, to an algo-rithmic abstraction. To this end, we are addressing the finite limits of communication latency. Whereas the speed of light remains a fundamental limit, propagation latency alone is 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Banerjee, S., Li, V.O., Wang, C., </author> <title> Distributed Database Sys tems in High-Speed Wide-Area Networks, </title> <journal> IEEE Journal on Selected Areas in Communications, V. </journal> <volume> 11, </volume> <editor> N. </editor> <volume> 4, </volume> <month> May </month> <year> 1993, </year> <pages> pp. 617-630. </pages>
Reference-contexts: High-bandwidth fiber was used from the pump to the receivers, and a low-bandwidth return path was used for update requests. The Send-on-Demand (SOD) architecture uses the Datacycle integrated with many-to-many communication to provide distributed database performance with Datacy-cle anticipation <ref> [1] </ref>. SOD periodically pumps information out to the participant pumps, in the manner of periodic state update via timers of the Delta-t protocol [14]. Their goal, as in Mirage [11], is rollback-free anticipation.
Reference: [2] <author> Braden, R., </author> <title> Extending TCP for Transactions -- Concepts, </title> <address> RFC-1379, USC/ISI, </address> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: The file reply latency can vary, depending on the method used. We propose using Transaction-TCP <ref> [2] </ref>, which should be open for the entire ftp session anyway. The cd is a transaction, and the files follow on the heels of the cd. As a result, the cd and entire directory send occur in 1 rtt.
Reference: [3] <author> Cheriton, D.R., VMTP: </author> <title> A Transport Protocol for the Next Generation of Communication Systems, </title> <journal> Computer Com-munication Review, </journal> <month> Aug. </month> <year> 1986, </year> <pages> p. 406-415. </pages>
Reference-contexts: The figure illustrates that communication speed increases are expected to keep pace with microprocessors, but not memory, although the growth rates are too close to definitely call 1 FIGURE 1. Comparative rates 1.2: Existing Approaches Existing methods to accommodate bandwidth increases include high performance protocols (XTP [4], VMTP <ref> [3] </ref>, Delta-t [14]), and methods to increase the window size of sliding-window mechanisms [7][8][9]. High performance protocols primarily address implementation issues. If protocols cannot be implemented effectively at high speeds, neither can user applications. However, if context switching is expensive for protocols, it is for user applications, too.
Reference: [4] <author> Chesson, G., et. al., </author> <title> XTP Protocol Definition, Protocol Engines, </title> <publisher> Inc., </publisher> <month> Dec. </month> <year> 1988. </year>
Reference-contexts: The figure illustrates that communication speed increases are expected to keep pace with microprocessors, but not memory, although the growth rates are too close to definitely call 1 FIGURE 1. Comparative rates 1.2: Existing Approaches Existing methods to accommodate bandwidth increases include high performance protocols (XTP <ref> [4] </ref>, VMTP [3], Delta-t [14]), and methods to increase the window size of sliding-window mechanisms [7][8][9]. High performance protocols primarily address implementation issues. If protocols cannot be implemented effectively at high speeds, neither can user applications. However, if context switching is expensive for protocols, it is for user applications, too.
Reference: [5] <author> Hennesy, H.L., and Patterson, D.A., </author> <title> Computer Architec ture: A Quantitative Approach, </title> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: On a per-year basis, workstation sizes increase at a rate of 1.26x [12]. DRAMs increase at a well-established rate of 1.59x, equivalent to 4x in 3 years. Disk capacity increases at 1.26x, equivalent to 2x in 3 years <ref> [5] </ref>. Microprocessors power increases at 1.38x (2x in 2 years, sustained since 1979), and recently at up to 2x per year. <p> Touch and David J. Farber USC / Information Sciences Institute (touch@isi.edu) Univ. of Pennsylvania (farber@cis.upenn.edu) Reprinted from IEEE Infocom 94, Toronto Can., pp.175-181, June 175 2a.4.2 (mP) and their peak rate (mP*); the latter includes architectural phases that cannot be expected to continue <ref> [5] </ref>. The Internet backbone rates are shown as a shaded area, where the recent sustained increases are shown darker. The figure illustrates that communication speed increases are expected to keep pace with microprocessors, but not memory, although the growth rates are too close to definitely call 1 FIGURE 1. <p> Methods include caching and prefetching have been used in all these arenas to address access latency, usually directed at an I/O latency bottleneck <ref> [5] </ref>. Source anticipation has been used in file systems, so that when a file is accessed, its entire contents are transmitted. It has also been used in database systems, and, as with file systems and lower layer instances, solutions are directed at I/O (bandwidth) bottlenecks.
Reference: [6] <author> Herman, G., Gopal, G., Lee, K., and Weinrib, A., </author> <title> The data cycle architecture for very high throughput database sys-tems, </title> <booktitle> in Proc. ACM SIGMOD Conf., </booktitle> <year> 1987, </year> <pages> pp. 97-103. </pages>
Reference-contexts: Other research in databases has recently considered using I/O bottleneck solutions to address propagation latency as well. The I/O bottleneck was addressed by the Datacycle architecture at Bellcore <ref> [6] </ref>. In this system, the database was repeatedly pumped at receivers, where high-speed filters extracted the appropriate reply. High-bandwidth fiber was used from the pump to the receivers, and a low-bandwidth return path was used for update requests.
Reference: [7] <author> Jacobson, V., and Braden, R., </author> <title> TCP Extensions for Long Delay Paths, </title> <institution> RFC-1072, LBL and USC/Information Sci-ences Institute, </institution> <month> Oct. </month> <year> 1988. </year>
Reference: [8] <author> Jacobson, V., Braden, R., and Zhang, L., </author> <title> TCP Extensions for High-Speed Paths, </title> <institution> RFC-1185, LBL and USC/Informa-tion Sciences Institute, </institution> <month> Oct. </month> <year> 1990. </year>
Reference: [9] <author> Jacobson, V., Braden, R., and Borman, D., </author> <title> TCP Extensions for High Performance, </title> <institution> RFC-1323, LBL, USC/Information Sciences Institute, and Cray Research, </institution> <month> May </month> <year> 1992. </year>
Reference: [10] <institution> NSF Report 92-109, </institution> <note> Research Priorities in Networking and Communications, </note> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: 1: Introduction Current gigabit networking research addresses limitations of communication and computation imposed by factors other than the finite speed of light <ref> [10] </ref>. Communication limits computation via latency, and computation limits communication, especially regarding coding and compression [13]. There is a need for an information theoretic theory of networks [10]. <p> 1: Introduction Current gigabit networking research addresses limitations of communication and computation imposed by factors other than the finite speed of light <ref> [10] </ref>. Communication limits computation via latency, and computation limits communication, especially regarding coding and compression [13]. There is a need for an information theoretic theory of networks [10]. Just as computation is analyzed at various levels of abstraction, from the Boolean/gate logic levels, through the abstract machine to algorithms, communication must go beyond the bit-level coding and communication theory, to an algo-rithmic abstraction. To this end, we are addressing the finite limits of communication latency. <p> This assumes that bandwidth is a plentiful resource and latency is not. We are interested in considering bandwidth as a means, rather than an end. We want to investigate the real fundamental limit of communication - that of propagation latency, which is not currently being addressed <ref> [10] </ref>. 1.1: Is this a problem? From its inception in 1969 through 1988, available communication bandwidth remained constant in the Internet backbone as other computer resources grew. Bandwidth is resuming its own technology curve [13]. <p> We can also use statistical optimizations to enhance interactive access to visualization data. Current research programs emphasize the intelligent automatic sequencing and spatial organization of visual or auditory information, to match the...goals of the user. <ref> [10] </ref> One particular goal of these optimizations is the user perception of low latency, regardless of propagation latency. 2: An illustrative experiment - file transfer latency reduction The following is an illustrative experiment in latency reduction, applied to an interactive ftp session.
Reference: [11] <author> Touch, Joseph D., </author> <title> Mirage: A Model for Latency in Commu nication, </title> <type> Ph.D. dissertation, </type> <institution> Dept. of Computer and Information Science, Univ. of Pennsylvania, </institution> <year> 1992. </year> <note> Also available as Dept. of CIS Tech. Report MS-CIS-92-42 / DSL-11. </note>
Reference-contexts: The Send-on-Demand (SOD) architecture uses the Datacycle integrated with many-to-many communication to provide distributed database performance with Datacy-cle anticipation [1]. SOD periodically pumps information out to the participant pumps, in the manner of periodic state update via timers of the Delta-t protocol [14]. Their goal, as in Mirage <ref> [11] </ref>, is rollback-free anticipation. Mirage performs breadth-first search (BFS) Time-Warp-like anticipation, where the BFS alternates cover the space of possible states, thus avoiding rollback. 2. Technology required includes parallel implementations, high-perfor-mance hardware or software implementations, and better integration of protocol processing with other workstation processing. <p> The experiment determines the extent of gain and cost in using Parallel Communication methods to reduce propagation latency. Parallel Communication is a method of sender-based anticipation using coarse remote state, and is based on Mirage, an abstract model of latency in communication protocols <ref> [11] </ref> [13]. The gain is the reduction in per-trans-action propagation latency; the cost is the increased bandwidth required. In the case of ftp, coarse state is the current working directory (cwd) of the user. When a user types cd, she indicates a change in that state. <p> In the case of ftp, coarse state is the current working directory (cwd) of the user. When a user types cd, she indicates a change in that state. The server anticipates the requests that follow that state change by sending every possible next request <ref> [11] </ref>. In ftp, this reduces to sending the entire contents of the cwd after each cd. We chose ftp because it exhibits a limited communication parallelism, and because we could experiment using available log information. It isnt optimal because the par-allelism isnt multilevel, as in hypermedia. <p> The work of the server is increased to provide latency reduction without increasing the work of the receiver (other latency reduction methods, such as prefetching and cach-ing, increase receiver workload to reduce latency). 3: Why is this interesting? This experiment is based on the Mirage model of latency in communication <ref> [11] </ref>. In Mirage, latency induces imprecision of state, which is resolved via feedback. Latency is accommodated via source anticipation. Mirage is the name of the model; Parallel Communication is the name of the protocol derived from the model [13].
Reference: [12] <author> Touch, J.D., </author> <title> Physics Analogs in Communication Models, </title> <booktitle> Proc. </booktitle> <volume> PhysComp '92, </volume> <month> Oct. </month> <year> 1992, </year> <month> p.248-252. </month>
Reference-contexts: Bandwidth is resuming its own technology curve [13]. We notice that its rate of increase is challenging that of other computational resources, such as CPU rate, workstation memory, disk capacity, etc. On a per-year basis, workstation sizes increase at a rate of 1.26x <ref> [12] </ref>. DRAMs increase at a well-established rate of 1.59x, equivalent to 4x in 3 years. Disk capacity increases at 1.26x, equivalent to 2x in 3 years [5]. Microprocessors power increases at 1.38x (2x in 2 years, sustained since 1979), and recently at up to 2x per year. <p> This is to say that they are interesting and important, but not specifically communication issues. We have shown a sort of protocol relativity, that a protocol does not know the speed at which it operates, only the number of bits in transit between communicating entities <ref> [12] </ref>. As a result, protocols are sensitive to the bandwidth-delay product, not the raw bandwidth rate. A gigabit LAN is equivalent to a kilobit WAN, in that respect. There are significant implementation issues that accompany raw rate increases, but existing protocols suffice 2 . 1. <p> Latency is accommodated via source anticipation. Mirage is the name of the model; Parallel Communication is the name of the protocol derived from the model [13]. The model is based on analogies between protocols and latent interaction and quantum physics <ref> [12] </ref>. In source anticipation, the state of the receiver is partitioned into subsets, and messages are pre-sent labelled for each subspace. The result is a breadth-first search of the remote space, in contrast to the depth-first search of Time-Warp-like protocols.
Reference: [13] <author> Touch, J.D., </author> <title> Parallel Communication, </title> <booktitle> Proc. IEEE Info com, </booktitle> <month> Mar. </month> <year> 1993, </year> <pages> p. 505-512. </pages>
Reference-contexts: 1: Introduction Current gigabit networking research addresses limitations of communication and computation imposed by factors other than the finite speed of light [10]. Communication limits computation via latency, and computation limits communication, especially regarding coding and compression <ref> [13] </ref>. There is a need for an information theoretic theory of networks [10]. Just as computation is analyzed at various levels of abstraction, from the Boolean/gate logic levels, through the abstract machine to algorithms, communication must go beyond the bit-level coding and communication theory, to an algo-rithmic abstraction. <p> There are often ways to reduce the user-perceived communication latency to below that of speed-of-light propagation <ref> [13] </ref>. Network rate increases do not address the problem of propagation latency given effectively infinite bandwidth 3 What will this available bandwidth be used for? What will be changed as a result? We propose using excess bandwidth to reduce propagation latency. <p> Bandwidth is resuming its own technology curve <ref> [13] </ref>. We notice that its rate of increase is challenging that of other computational resources, such as CPU rate, workstation memory, disk capacity, etc. On a per-year basis, workstation sizes increase at a rate of 1.26x [12]. <p> The experiment determines the extent of gain and cost in using Parallel Communication methods to reduce propagation latency. Parallel Communication is a method of sender-based anticipation using coarse remote state, and is based on Mirage, an abstract model of latency in communication protocols [11] <ref> [13] </ref>. The gain is the reduction in per-trans-action propagation latency; the cost is the increased bandwidth required. In the case of ftp, coarse state is the current working directory (cwd) of the user. When a user types cd, she indicates a change in that state. <p> In Mirage, latency induces imprecision of state, which is resolved via feedback. Latency is accommodated via source anticipation. Mirage is the name of the model; Parallel Communication is the name of the protocol derived from the model <ref> [13] </ref>. The model is based on analogies between protocols and latent interaction and quantum physics [12]. In source anticipation, the state of the receiver is partitioned into subsets, and messages are pre-sent labelled for each subspace.
Reference: [14] <author> Watson, R.W., </author> <title> The Delta-t Transport Protocol: Features and Experience, Protocols for High Speed Networks, </title> <publisher> Elsevier, </publisher> <year> 1989, </year> <pages> p. 3-17. </pages>
Reference-contexts: Comparative rates 1.2: Existing Approaches Existing methods to accommodate bandwidth increases include high performance protocols (XTP [4], VMTP [3], Delta-t <ref> [14] </ref>), and methods to increase the window size of sliding-window mechanisms [7][8][9]. High performance protocols primarily address implementation issues. If protocols cannot be implemented effectively at high speeds, neither can user applications. However, if context switching is expensive for protocols, it is for user applications, too. <p> The Send-on-Demand (SOD) architecture uses the Datacycle integrated with many-to-many communication to provide distributed database performance with Datacy-cle anticipation [1]. SOD periodically pumps information out to the participant pumps, in the manner of periodic state update via timers of the Delta-t protocol <ref> [14] </ref>. Their goal, as in Mirage [11], is rollback-free anticipation. Mirage performs breadth-first search (BFS) Time-Warp-like anticipation, where the BFS alternates cover the space of possible states, thus avoiding rollback. 2.
Reference: [15] <author> Berners-Lee, T.J., Cailliau, R., Groff, J-F, Pollermann, B., </author> <title> World-Wide Web: The Information Universe, Electronic Networking: Research, Applications and Policy, </title> <publisher> Meckler Publishing, </publisher> <address> Connecticut, </address> <month> Spring </month> <year> 1992, </year> <month> p.52-58. </month>
Reference-contexts: It isnt optimal because the par-allelism isnt multilevel, as in hypermedia. The following results were obtained from file transfer logs of anonymous access at ISI (ftp.isi.edu) and NCSA (ftp.ncsa.uiuc.edu). Ideally, wed perfer to measure the utilization of a distributed hypermedia system, e.g., the World-Wide Web <ref> [15] </ref>, but here well start with some locally-available information, and see where it leads. Currently, in ftp, users usually cd to a directory, and retrieve files from that directory. <p> Wed prefer to measure the speedup of a system that shows a truly interactive nature, with large chunks of information, and a rich structure. One candidate of particular interest is the World-Wide Web <ref> [15] </ref>. WWW uses some of the same mechanisms as ftp, but uses embedded textual cookies to indicate hypermedia links to other files, rather than the ftp directory structure.
References-found: 15

