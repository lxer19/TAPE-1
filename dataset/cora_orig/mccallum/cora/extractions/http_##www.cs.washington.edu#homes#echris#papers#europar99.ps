URL: http://www.cs.washington.edu/homes/echris/papers/europar99.ps
Refering-URL: http://www.cs.washington.edu/homes/echris/pubs.html
Root-URL: http://www.cs.washington.edu
Email: fbrad,echris,snyderg@cs.washington.edu  
Phone: (206) 616-1848 (206) 543-2969 (FAX)  
Title: Array Language Support for Wavefront and Pipelined Computations  Topic 11: Parallel Programming Models, Methods and Languages  
Author: Bradford L. Chamberlain, E Christopher Lewis, and Lawrence Snyder 
Address: Seattle, WA 98195-2350 USA  
Affiliation: Department of Computer Science and Engineering University of Washington  
Abstract: Array languages such as Fortran 90, High Performance Fortran and ZPL are convenient vehicles for expressing data parallel computations. Unfortunately, array language semantics prohibit the natural expression of wavefront and pipelined computations, characterized by a sequential propagation of computed values along one or more dimensions of the data space. As a result, programmers scalarize wavefront computations (i.e., use loop nests and scalar indexing), sacrificing the benefits of the array language. We propose an extension to array languages that provides support for wavefront computation without scalarization. Like the role of array operations, our extension is particularly valuable in that it identifies parallelism to both the programmer and compiler. This paper describes and evaluates our extension and gives a model used to weigh the tradeoff between parallelism and communication costs. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Jeanne C. Adams, Walter S. Brainerd, Jeanne T. Martin, Brian T. Smith, and Jerrold L. Wa-gener. </author> <title> Fortran 90 Handbook. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction Array languages such as Fortran 90 <ref> [1] </ref>, High Performance Fortran (HPF) [8] and ZPL [17] have achieved success in expressing and exploiting data parallelism. They are distinguished from scalar languages by their support of operations on arrays as primitive entities, frequently obviating the need for explicit looping and scalar indexing.
Reference: 2. <author> Bradford L. Chamberlain, Sung-Eun Choi, E Christopher Lewis, Calvin Lin, Lawrence Sny-der, and W. Derrick Weathersby. </author> <title> ZPL's WYSIWYG performance model. </title> <booktitle> In Third IEEE International Workshop on High-Level Parallel Programming Models and Supportive Environments, </booktitle> <pages> pages 5061, </pages> <month> March </month> <year> 1998. </year>
Reference-contexts: Furthermore, we assume that all arrays in a scan block are aligned and block distributed in each dimension, so communication is only required for the shift operator. This last assumption is the basis of ZPL's WYSIWYG performance model <ref> [2] </ref>. There are obvious extensions for cyclic and block-cyclic distributions. Each processor blocks, waiting to receive all the data it needs to compute its portion of the scan block.
Reference: 3. <author> Bradford L. Chamberlain, Sung-Eun Choi, E Christopher Lewis, Lawrence Snyder, W. Derrick Weathersby, and Calvin Lin. </author> <title> The case for high-level parallel programming in ZPL. </title> <journal> IEEE Computational Science and Engineering, </journal> <volume> 5(3):7685, </volume> <month> JulySeptember </month> <year> 1998. </year>
Reference-contexts: Previous studies demonstrate that the ZPL compiler is competitive with hand-coded C with MPI <ref> [3] </ref> and that it generally outperforms HPF [14]. The compiler is publicly available for most modern parallel and sequential platforms [18]. The language is in active use by scientists in fields such as astronomy, civil engineering, biological statistics, mathematics, oceanography, and theoretical physics.
Reference: 4. <author> Bradford L. Chamberlain, E Christopher Lewis, Calvin Lin, and Lawrence Snyder. </author> <title> Regions: An abstraction for expressing array computation. </title> <type> Technical Report UW-CSE-98-10-02, </type> <institution> University of Washington, Department of Computer Science and Engineering, </institution> <month> October </month> <year> 1998. </year>
Reference-contexts: As an array language, it also offers array data types and operators. ZPL is distinguished from other array languages by its use of regions <ref> [4] </ref>. A region represents an index set and may precede a statement, specifying the extent of the array references within its dynamic scope. The region is said to cover statements of the same rank within this scope.
Reference: 5. <author> W. Crowley, C. P. Hendrickson, and T. I. Luby. </author> <title> The SIMPLE code. </title> <type> Technical Report UCID-17715, </type> <institution> Lawrence Livermore Laboratory, </institution> <year> 1978. </year>
Reference-contexts: The language extensions in this paper explicitly expose the parallelism in the source language so that programmers can be assured that their codes contain exploitable parallelism. We conduct experiments on the Cray T3E and the SGI PowerChallenge using the Tomcatv and SIMPLE <ref> [5] </ref> benchmarks. For each experiment, we consider the program as a whole, and we consider two components of it that contain a single wavefront computation.
Reference: 6. <author> Richard Friedman, John Levesque, and Gene Wagenbreth. </author> <title> Fortran Parallelization Handbook. </title> <booktitle> Applied Parallel Research, </booktitle> <month> April </month> <year> 1995. </year>
Reference-contexts: Without a performance model, programmers are left to guess how the compiler will optimize their code. They must often write to idioms to enable optimizations in a particular compiler, severely increasing programming effort and degrading performance. The proliferation of parallelizing restructuring tools <ref> [6, 7, 11] </ref> attest to the former and Ngo has demonstrated the latter [15]. ? This research was supported in part by DARPA Grant E30602-97-1-0152, NSF Grant CCR 9710284 and the Intel Corporation.
Reference: 7. <author> Mary W. Hall, Timothy J. Harvery, Ken Kennedy, Nethaniel McIntosh, Kathryn S. McKinley, Jeffrey D. Oldham, Michael Paleczny, and Gerald Roth. </author> <title> Experiences using the parascope editor: An interactive parallel programming tool. </title> <booktitle> In Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 3343, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Without a performance model, programmers are left to guess how the compiler will optimize their code. They must often write to idioms to enable optimizations in a particular compiler, severely increasing programming effort and degrading performance. The proliferation of parallelizing restructuring tools <ref> [6, 7, 11] </ref> attest to the former and Ngo has demonstrated the latter [15]. ? This research was supported in part by DARPA Grant E30602-97-1-0152, NSF Grant CCR 9710284 and the Intel Corporation.
Reference: 8. <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Langauge Specification, </title> <note> Version 2.0. </note> <month> January </month> <year> 1997. </year>
Reference-contexts: 1 Introduction Array languages such as Fortran 90 [1], High Performance Fortran (HPF) <ref> [8] </ref> and ZPL [17] have achieved success in expressing and exploiting data parallelism. They are distinguished from scalar languages by their support of operations on arrays as primitive entities, frequently obviating the need for explicit looping and scalar indexing.
Reference: 9. <author> Seema Hiranandani, Ken Kennedy, and Chau-Wen Tseng. </author> <title> Compiler optimizations for Fortran D on MIMD distributed-memory machines. </title> <booktitle> In Supercomputing '91, </booktitle> <pages> pages 96100, </pages> <address> Albuquerque, NM, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: Rogers and Pingali observed that though message vectorization (message combining) reduces the overhead of message passing, it may inhibit parallelism in wavefront computations [16]. Hiranandani et al. generalize Rogers' and Pingali's work in the compilation of Fortran D <ref> [9] </ref>. They describe the analysis requires to recognize the opportunity for pipelining and give a formula for deciding the optimal block size [10]. This paper, on the other hand, presents array language features that permit both the programmer and compiler to trivially identify opportunities for pipelined parallel execution. <p> Processors 3 and 4 must wait for processors 1 and 2 to compute its n 2 4 elements each before they may proceed. Furthermore, processors 1 and 2 may need to wait for the others to complete. Alternatively, the wavefront computation may be pipelined in order to exploit parallelism <ref> [9, 15, 16] </ref>. Specifically, a processor may compute over a block of its portion of the data space, transmit some of the data needed by subsequent processors, then continue to execute its next block. <p> Though it is possible that a compiler could optimize scalar or scalarized code resulting in the same performance <ref> [9, 10] </ref>, it is far more difficult for programmers to reason about their scalar codes' parallel performance. The language extensions in this paper explicitly expose the parallelism in the source language so that programmers can be assured that their codes contain exploitable parallelism.
Reference: 10. <author> Seema Hiranandani, Ken Kennedy, and Chau-Wen Tseng. </author> <title> Evaluation of compiler optimizations for Fortran D on MIMD distributed-memory machines. </title> <booktitle> In International Conference on Supercomputing, </booktitle> <pages> pages 114, </pages> <address> Washington, DC, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Hiranandani et al. generalize Rogers' and Pingali's work in the compilation of Fortran D [9]. They describe the analysis requires to recognize the opportunity for pipelining and give a formula for deciding the optimal block size <ref> [10] </ref>. This paper, on the other hand, presents array language features that permit both the programmer and compiler to trivially identify opportunities for pipelined parallel execution. In addition, we give and validate a more accurate model for finding the optimal block size than that of Hiranandani et al. <p> They can then immediately begin computing blocks of their portions of the scan block. Smaller blocks increase parallelism at the expense of sending more messages. Hi-ranandani et al. have developed a model for weighing this tradeoff and finding the optimal block size <ref> [10] </ref>. They model messages as having a particular cost, a, independent of the message size. We have developed a more accurate model that considers both the message startup, a, and per-element, b, communication costs. <p> As p grows, the optimal b decreases, because there are more processor to keep busy. As n grows, the optimal b becomes less sensitive to the relative values of a, b, and p. Hiranandani et al. derived a similar equation except that they ignore b <ref> [10] </ref>; as a result it gives no insight into the relative importance and roles of a, b, n, and p. Our equation reduces to theirs when we let b = 0 (i.e., b = a). <p> Though it is possible that a compiler could optimize scalar or scalarized code resulting in the same performance <ref> [9, 10] </ref>, it is far more difficult for programmers to reason about their scalar codes' parallel performance. The language extensions in this paper explicitly expose the parallelism in the source language so that programmers can be assured that their codes contain exploitable parallelism.
Reference: 11. <author> Seema Hiranandani, Ken Kennedy, Chau-Wen Tseng, and Scott Warren. </author> <title> The D Editor: A new interactive parallel programming tool. </title> <booktitle> In Supercomputing '94, </booktitle> <pages> pages 73342, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Without a performance model, programmers are left to guess how the compiler will optimize their code. They must often write to idioms to enable optimizations in a particular compiler, severely increasing programming effort and degrading performance. The proliferation of parallelizing restructuring tools <ref> [6, 7, 11] </ref> attest to the former and Ngo has demonstrated the latter [15]. ? This research was supported in part by DARPA Grant E30602-97-1-0152, NSF Grant CCR 9710284 and the Intel Corporation.
Reference: 12. <author> F. Thomas Leighton. </author> <title> Introduction to Parallel Algorithms and Architectures, chapter 1.2. </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, California, </address> <year> 1992. </year>
Reference-contexts: computation. (b) A demonstration of the value of modeling the per-word cost (b) of communication. can still extract parallelism with pipelining and more aggressive fusion can improve locality and enable other transformations such as array contraction [13]. (ii) When scan block computations are associative, more efficient parallel prefix implementations exist <ref> [12] </ref>; the compiler could recognize this and use the more efficient implementations. (iii) Similarly, scan blocks can be used to copy values across an array; the compiler could recognize this and use broadcasts instead instead of the more general scheme. 5 Performance Evaluation In this section we demonstrate the potential performance
Reference: 13. <author> E Christopher Lewis, Calvin Lin, and Lawrence Snyder. </author> <title> The implementation and evaluation of fusion and contraction in array languages. </title> <booktitle> In ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 5059, </pages> <month> June </month> <year> 1998. </year>
Reference-contexts: The use of regions improves code clarity and compactness. Note that though the scalar variable r is promoted to an array in the array codes, we have previously demonstrated compiler techniques by which this overhead may be eliminated via array contraction <ref> [13] </ref>. 2.2 Wavefront Computation in ZPL Array language semantics dictate that the right-hand side of an array statement is evaluated before the result is assigned to the left-hand side. As a result, the compiler will not generate a loop that carries a lexically backward true data dependence. <p> In previous work we have defined unconstrained distance vectors to represent these array-level data dependences, and we have developed an algorithm to decide loop structure given a set of unconstrained distance vectors <ref> [13] </ref>. The prime operator transforms what an array language would otherwise interpret as an anti-dependence into a true dependence. In order to represent this, the unconstrained distance vectors associated with primed array references are simply negated. <p> per-element communication cost. (a) Modeled versus experimental speedup due to pipelining of Tomcatv wavefront computation. (b) A demonstration of the value of modeling the per-word cost (b) of communication. can still extract parallelism with pipelining and more aggressive fusion can improve locality and enable other transformations such as array contraction <ref> [13] </ref>. (ii) When scan block computations are associative, more efficient parallel prefix implementations exist [12]; the compiler could recognize this and use the more efficient implementations. (iii) Similarly, scan blocks can be used to copy values across an array; the compiler could recognize this and use broadcasts instead instead of the <p> The scan block version of this code in Figure 2 (b), however, does not specify an iteration order at the source level, so the compiler has complete freedom to find a loop structure that exploits locality <ref> [13] </ref>. With this in mind, we experimentally compare the performance of partially scalar-ized and scan block exploiting implementations of identical computations. Figure 6 graphs the speedup of the former over the latter.
Reference: 14. <author> C. Lin, L. Snyder, R. Anderson, B. Chamberlain, S. Choi, G. Forman, E. Lewis, and W. D. Weathersby. </author> <title> ZPL vs. HPF: A comparison of performance and programming style. </title> <type> Technical Report 951105, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <year> 1994. </year>
Reference-contexts: Previous studies demonstrate that the ZPL compiler is competitive with hand-coded C with MPI [3] and that it generally outperforms HPF <ref> [14] </ref>. The compiler is publicly available for most modern parallel and sequential platforms [18]. The language is in active use by scientists in fields such as astronomy, civil engineering, biological statistics, mathematics, oceanography, and theoretical physics.
Reference: 15. <author> Ton A. Ngo. </author> <title> The Role of Performance Models in Parallel Programming and Languages. </title> <type> PhD thesis, </type> <institution> University of Washington, Department of Computer Science and Engineering, </institution> <year> 1997. </year>
Reference-contexts: They must often write to idioms to enable optimizations in a particular compiler, severely increasing programming effort and degrading performance. The proliferation of parallelizing restructuring tools [6, 7, 11] attest to the former and Ngo has demonstrated the latter <ref> [15] </ref>. ? This research was supported in part by DARPA Grant E30602-97-1-0152, NSF Grant CCR 9710284 and the Intel Corporation. <p> Processors 3 and 4 must wait for processors 1 and 2 to compute its n 2 4 elements each before they may proceed. Furthermore, processors 1 and 2 may need to wait for the others to complete. Alternatively, the wavefront computation may be pipelined in order to exploit parallelism <ref> [9, 15, 16] </ref>. Specifically, a processor may compute over a block of its portion of the data space, transmit some of the data needed by subsequent processors, then continue to execute its next block.
Reference: 16. <author> Anne Rogers and Keshav Pingali. </author> <title> Process decomposition through locality of reference. </title> <booktitle> In ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 6980, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Researchers have explored the extraction of pipelined parallelism from wavefront computations represented by serial loops. Rogers and Pingali observed that though message vectorization (message combining) reduces the overhead of message passing, it may inhibit parallelism in wavefront computations <ref> [16] </ref>. Hiranandani et al. generalize Rogers' and Pingali's work in the compilation of Fortran D [9]. They describe the analysis requires to recognize the opportunity for pipelining and give a formula for deciding the optimal block size [10]. <p> Processors 3 and 4 must wait for processors 1 and 2 to compute its n 2 4 elements each before they may proceed. Furthermore, processors 1 and 2 may need to wait for the others to complete. Alternatively, the wavefront computation may be pipelined in order to exploit parallelism <ref> [9, 15, 16] </ref>. Specifically, a processor may compute over a block of its portion of the data space, transmit some of the data needed by subsequent processors, then continue to execute its next block.
Reference: 17. <author> Lawrence Snyder. </author> <title> The ZPL Programmer's Guide. </title> <publisher> MIT Press (in pressavailable at ftp://ftp.cs.washington.edu/pub/orca/docs/zpl guide.ps), </publisher> <year> 1999. </year>
Reference-contexts: 1 Introduction Array languages such as Fortran 90 [1], High Performance Fortran (HPF) [8] and ZPL <ref> [17] </ref> have achieved success in expressing and exploiting data parallelism. They are distinguished from scalar languages by their support of operations on arrays as primitive entities, frequently obviating the need for explicit looping and scalar indexing. <p> The extension is of use in any code that requires loop carried true dependences, such as solvers and dynamic programming codes. Though our extension can be applied to any array language, we describe it in terms of the ZPL parallel array language <ref> [17] </ref>. Researchers have explored the extraction of pipelined parallelism from wavefront computations represented by serial loops. Rogers and Pingali observed that though message vectorization (message combining) reduces the overhead of message passing, it may inhibit parallelism in wavefront computations [16]. <p> Performance data is presented in Section 5, and conclusions and future work are given in the final section. 2 Array Language Support for Wavefront Computation This section describes array language support for wavefront computations in the context of the ZPL parallel array language <ref> [17] </ref>. Previous studies demonstrate that the ZPL compiler is competitive with hand-coded C with MPI [3] and that it generally outperforms HPF [14]. The compiler is publicly available for most modern parallel and sequential platforms [18].
Reference: 18. <institution> ZPL Project. ZPL project homepage. </institution> <note> http:/www.cs.washington.edu/research/zpl. </note>
Reference-contexts: Previous studies demonstrate that the ZPL compiler is competitive with hand-coded C with MPI [3] and that it generally outperforms HPF [14]. The compiler is publicly available for most modern parallel and sequential platforms <ref> [18] </ref>. The language is in active use by scientists in fields such as astronomy, civil engineering, biological statistics, mathematics, oceanography, and theoretical physics. Section 2.1 gives a very brief summary of the ZPL language, only describing the features of the language immediately relevant to this paper.
References-found: 18

