URL: http://www.cs.nyu.edu/cs/projects/proteus/sekine/papers/wvlc94.ps
Refering-URL: http://www.cs.nyu.edu/cs/projects/proteus/sekine/index.html
Root-URL: http://www.cs.nyu.edu
Title: Automatic Sublanguage Identification for a New Text  
Author: Satoshi SEKINE 
Address: New York University 715 Broadway, Room.709 New York, NY 10003, USA  
Affiliation: Computer Science Department  
Abstract: A number of theoretical studies have been devoted to the notion of sublanguage, which mainly concerns linguistic phenomena restricted by the domain or context. Furthermore, there are some successful NLP systems which have explicitly or implicitly addressed the sublanguage restrictions (e.g. TAUM-METEO, ATR). This suggests the following two objectives for future NLP research: 1) automatic linguistic knowledge acquisition for sublanguage, and 2) automatic definition of sublanguage and identification of it for a new text. The two issues become realistic owing to the appearance of large corpora. Despite of the recent bloom of the research on the first objective, there are few on the second objective. If this objective is achieved, NLP systems will be able to optimize to the sublanguage before processing the text, and this will be a significant help in automatic processing. A preliminary experiment aiming at the second objective is addressed in this paper. It is conducted on about 3 MB of Wall Street Journal corpus. We made up article clusters (sublanguages) based on word appearance, and the closest article cluster among the set of clusters is chosen for each test article. The comparison between the new articles and the clusters shows the success of the sublanguage identification and also the promising ability of the method. Also the result of an experiment using the first two sentences in the articles indicates the feasibility of applying this method to speech recognition or other systems which can't access the whole article prior to the processing. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> R.Kittredge, J.Lehrberger ed.: </editor> <booktitle> "Sublanguage: Study of language in restricted semantic domain" (1982) </booktitle>
Reference-contexts: In particular, sublanguage studies indicated that several kinds of restrictions or deviations are characteristic for each sublanguage <ref> [1] </ref> [2] [3] [4]. Furthermore, there are some successful natural language processing systems which have explicitly or implicitly utilized sublanguage restrictions. For example, TAUM-METEO [5] is a machine translation system in which the translation is aimed only at sentences in the weather forecast domain, and it works remarkably well .
Reference: [2] <editor> R.Grishman, R.Kittredge ed.: </editor> <booktitle> "Analyzing language in restricted domains" (1986) </booktitle>
Reference-contexts: In particular, sublanguage studies indicated that several kinds of restrictions or deviations are characteristic for each sublanguage [1] <ref> [2] </ref> [3] [4]. Furthermore, there are some successful natural language processing systems which have explicitly or implicitly utilized sublanguage restrictions. For example, TAUM-METEO [5] is a machine translation system in which the translation is aimed only at sentences in the weather forecast domain, and it works remarkably well .
Reference: [3] <author> D.Biber: </author> <title> "Using Register-Diversified Corpora for General Language Studies" Computational Linguistics Vol.19, </title> <booktitle> Number 2 (1993) </booktitle>
Reference-contexts: In particular, sublanguage studies indicated that several kinds of restrictions or deviations are characteristic for each sublanguage [1] [2] <ref> [3] </ref> [4]. Furthermore, there are some successful natural language processing systems which have explicitly or implicitly utilized sublanguage restrictions. For example, TAUM-METEO [5] is a machine translation system in which the translation is aimed only at sentences in the weather forecast domain, and it works remarkably well .
Reference: [4] <author> W.Gale, K.Church, D Yarowsky: </author> <title> "One Sense Per Discourse" 4th DARPA Speech and Natural Language Workshop (1992) </title>
Reference-contexts: In particular, sublanguage studies indicated that several kinds of restrictions or deviations are characteristic for each sublanguage [1] [2] [3] <ref> [4] </ref>. Furthermore, there are some successful natural language processing systems which have explicitly or implicitly utilized sublanguage restrictions. For example, TAUM-METEO [5] is a machine translation system in which the translation is aimed only at sentences in the weather forecast domain, and it works remarkably well .
Reference: [5] <editor> P.Isabelle: </editor> <booktitle> "Machine Translation at the TAUM group" The ISSCO Tutorial on Machine Translation (1984) </booktitle>
Reference-contexts: In particular, sublanguage studies indicated that several kinds of restrictions or deviations are characteristic for each sublanguage [1] [2] [3] [4]. Furthermore, there are some successful natural language processing systems which have explicitly or implicitly utilized sublanguage restrictions. For example, TAUM-METEO <ref> [5] </ref> is a machine translation system in which the translation is aimed only at sentences in the weather forecast domain, and it works remarkably well . Also, recently ATR [6] built a translation system for the conference registration task, and it works well, too.
Reference: [6] <editor> T.Morimoto et al.: </editor> <booktitle> "ATR's speech translation system: ASURA" 42.2, Eurospeech (1993) </booktitle>
Reference-contexts: Furthermore, there are some successful natural language processing systems which have explicitly or implicitly utilized sublanguage restrictions. For example, TAUM-METEO [5] is a machine translation system in which the translation is aimed only at sentences in the weather forecast domain, and it works remarkably well . Also, recently ATR <ref> [6] </ref> built a translation system for the conference registration task, and it works well, too. This suggests the following two objectives in order to make a breakthrough on current NLP research. 1. Automatic linguistic knowledge acquisition for sublanguages. 2.
Reference: [7] <author> R.Grishman: </author> <title> "Discovery Procedures for Sublanguage Selectional Patterns: Initial Experiments" Comp. </title> <note> Linguistics Vol.12 No.3 (1986) </note>
Reference-contexts: Automatic linguistic knowledge acquisition for sublanguages. 2. Automatic definition of sublanguages and identification of the sublanguage of a new text. These two goals become realistic owing to the appearance of large corpora. Using large corpora, preliminary experiments to meet the first objective have been conducted <ref> [7] </ref> [8]. Although these are still small experiments, in terms of the accuracy and the coverage for practical applications, their objectives address the first goal above, and could make a breakthrough for future N.L.P. systems by reducing the costly and errorsome linguistic knowledge encoding task by human linguists.
Reference: [8] <author> S.Sekine, S.Ananiadou, J.J.Carroll, J.Tsujii: </author> <title> "Linguistic Knowledge Generator" COLING-92 (1992) </title>
Reference-contexts: Automatic linguistic knowledge acquisition for sublanguages. 2. Automatic definition of sublanguages and identification of the sublanguage of a new text. These two goals become realistic owing to the appearance of large corpora. Using large corpora, preliminary experiments to meet the first objective have been conducted [7] <ref> [8] </ref>. Although these are still small experiments, in terms of the accuracy and the coverage for practical applications, their objectives address the first goal above, and could make a breakthrough for future N.L.P. systems by reducing the costly and errorsome linguistic knowledge encoding task by human linguists.
Reference: [9] <author> P.Willett: </author> <title> "Resent trends in hierarchic document clustering: a critical review" Information Processing and Management Vol.24, </title> <address> No.5 pp.577-597 (1988) </address>
Reference-contexts: Therefore we need an objective and linguistic measurement of sublanguage to define it. In our experiment, automatic article clustering based on word appearance is used to generate a set of sublanguages. The method we used is based on a document clustering metric <ref> [9] </ref> [10]. Although word appearance is one of the main features of sublanguage, other kinds of phenomena, including syntactic and semantic features, have been reported as sublanguage features.
Reference: [10] <author> K.Sparck-Jones: </author> <title> "Index Term Weighting" Information Storage and Retrieval, </title> <address> Vol.9, </address> <month> p619-633 </month> <year> (1973) </year>
Reference-contexts: Therefore we need an objective and linguistic measurement of sublanguage to define it. In our experiment, automatic article clustering based on word appearance is used to generate a set of sublanguages. The method we used is based on a document clustering metric [9] <ref> [10] </ref>. Although word appearance is one of the main features of sublanguage, other kinds of phenomena, including syntactic and semantic features, have been reported as sublanguage features. <p> The formula for the similarity measure is based on the combination of inverse document frequencies of words and normalization by the number of the words in a text <ref> [10] </ref>.
References-found: 10

