URL: http://www.cs.bris.ac.uk/~dattani/95_2.ps
Refering-URL: http://www.cs.bris.ac.uk/~dattani/research.html
Root-URL: 
Title: Knowledge Based Systems  
Author: Susan Craw and D. Sleeman THE ROBERT GORDON 
Affiliation: School of Computer and Mathematical Sciences FACULTY OF SCIENCE AND TECHNOLOGY  UNIVERSITY  
Date: January 1995  
Note: Knowledge-based Refinement of  
Abstract: Technical Report No. 95/2 
Abstract-found: 1
Intro-found: 1
Reference: <author> Allard, F., & Lackinger, F. </author> <year> (1993). </year> <title> Evaluation of toolset 1. Deliverable:D2-109-WP1.4-ESA, ESPRIT III Project 6125. </title>
Reference: <author> Baffes, P. T., & Mooney, R. J. </author> <year> (1993). </year> <title> Symbolic revision of theories with M-of-N rules. </title>
Reference-contexts: Theory revision systems have evolved in a Machine Learning background where Horn Clauses are a common representation. Therefore a main aim of researchers in theory revision has been extend the techniques from propositional theories (e.g. EITHER), through M-of-N theories (e.g. NEITHER <ref> (Baffes & Mooney, 1993) </ref>) 4 , to restricted first order theories systems (e.g. AUDREY-II, FORTE, WHY, MOBAL, CLINT). In contrast many expert systems are propositional, or at least use representational schema which do not need the full power of First Order Predicate Calculus.
Reference: <editor> In Bajcsy, R. (Ed.), </editor> <booktitle> Proceedings of the Thirteenth IJCAI Conference, </booktitle> <pages> pp. </pages> <address> 1135-1140 Chambery, FRANCE. </address> <note> 31 Carbonell, </note> <author> J. G. </author> <year> (1991). </year> <title> Scaling up knowledge-based systems via machine learning. Invited Talk, </title> <booktitle> Fifth European Working Session on Learning (EWSL-91). </booktitle>
Reference: <author> Craw, S. </author> <year> (1991). </year> <title> Automating the Refinement of Knowledge Based Systems. </title> <type> Ph.D. thesis, </type> <institution> University of Aberdeen. </institution>
Reference-contexts: The fact that small tweakings of the KB to fix single faults do not greatly affect the overall accuracy (although they completely fix the input fault) 22 will be addressed in the next section. A theoretical analysis <ref> (Craw, 1991) </ref> shows that the number of refinements is exponential with respect to the lengths of deductions, because the refinements are generated by searching the proof trees of the KB. <p> Table 10 shows this analysis for the 60 test runs from Section 7.1 (Batches 1-4) and the 5 "corrupted" test runs from Section 7.3. An alternative analysis, categorising the actual operations applied to form the recommended KBs, appears in <ref> (Craw, 1991) </ref>. We note that although we analysed 65 test runs, 72 refined KBs were inspected, since some test runs finally recommended more than one refined KB. <p> We note that not only did our testing produce a range of refinement types, but also, the two types of testing, Batches 1-4 and Corrupted, favoured differing refinements. This supports KRUST's "generate, discard and rank" behaviour as a suitable mechanism to provide flexibility in refinement <ref> (Craw & Sleeman, 1991) </ref>. 8 Related Work In this section we compare the approach of KRUST with other refinement systems. There are two terms for systems which alter knowledge to improve its performance: knowledge refinement and theory revision systems.
Reference: <author> Craw, S., & Sleeman, D. </author> <year> (1990). </year> <title> Automating the refinement of knowledge-based systems. </title>
Reference-contexts: This task-solution pair is used as a training case for the refinement process. Although KRUST applies the general process described above, it is unusual in several respects. * It implements many KB refinements that may overcome a fault <ref> (Craw & Sleeman, 1990) </ref> and is able to postpone its decision about which ones are most appropriate until it has confirming evidence of their suitability. * In addition to a static analysis of the declarative knowledge, it also takes account of the conflict resolution strategy when generating possible refinements; this is
Reference: <editor> In Aiello, L. C. (Ed.), </editor> <booktitle> Proceedings of the ECAI90 Conference, </booktitle> <pages> pp. </pages> <address> 167-172 Stockholm, SWEDEN. </address> <publisher> Pitman. </publisher>
Reference: <author> Craw, S., & Sleeman, D. </author> <year> (1991). </year> <title> The flexibility of speculative refinement. </title> <editor> In Birnbaum, L., & Collins, G. (Eds.), </editor> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 28-32 Evanston, IL. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The fact that small tweakings of the KB to fix single faults do not greatly affect the overall accuracy (although they completely fix the input fault) 22 will be addressed in the next section. A theoretical analysis <ref> (Craw, 1991) </ref> shows that the number of refinements is exponential with respect to the lengths of deductions, because the refinements are generated by searching the proof trees of the KB. <p> Table 10 shows this analysis for the 60 test runs from Section 7.1 (Batches 1-4) and the 5 "corrupted" test runs from Section 7.3. An alternative analysis, categorising the actual operations applied to form the recommended KBs, appears in <ref> (Craw, 1991) </ref>. We note that although we analysed 65 test runs, 72 refined KBs were inspected, since some test runs finally recommended more than one refined KB. <p> We note that not only did our testing produce a range of refinement types, but also, the two types of testing, Batches 1-4 and Corrupted, favoured differing refinements. This supports KRUST's "generate, discard and rank" behaviour as a suitable mechanism to provide flexibility in refinement <ref> (Craw & Sleeman, 1991) </ref>. 8 Related Work In this section we compare the approach of KRUST with other refinement systems. There are two terms for systems which alter knowledge to improve its performance: knowledge refinement and theory revision systems.
Reference: <author> Craw, S., & Sleeman, D. </author> <year> (1994). </year> <title> Refinement in response to validation. Expert Systems with Applications, </title> <type> 8 (2). </type> <note> Also appears in J. </note> <editor> Carde~nosa and P. Meseguer, editors, </editor> <booktitle> Proceedings of the EUROVAV93 Workshop, </booktitle> <pages> pages 85-99, </pages> <address> Palma, SPAIN, </address> <year> 1993. </year>
Reference-contexts: Validation and refinement tools integrate well together because a similar exploration of the KB is undertaken by both processes and a validation tool can often provide evidence for the need to refine the KB <ref> (Craw & Sleeman, 1994) </ref>. In addition Validation and Verification research is often concerned with developing metrics and testing tools which could be used by KRUST for evaluating the refined KBs. 9 Future Work In this paper we have described KRUST's refinement of a propositional KBSs. <p> We also wish to thank the anonymous reviewers whose useful comments encouraged us to focus our attention on the distinction between theory revision and knowledge refinement systems; a theme which we have previously explored <ref> (Craw, Sleeman, Boswell, & Carbonara, 1994) </ref>.
Reference: <author> Craw, S., Sleeman, D., Boswell, R., & Carbonara, L. </author> <year> (1994). </year> <title> Is knowledge refinement different from theory revision?. </title> <editor> In Wrobel, S. (Ed.), </editor> <booktitle> Proceedings MLNet Familiarization Workshop on Theory Revision and Restructuring in Machine Learning (at ECML-94, Catania, ITALY), No. 842 in Arbeitspapiere der GMD, </booktitle> <pages> pp. 32-34 GMD, </pages> <address> Pf. 1316, 53754 Sankt Augustin, Germany. </address>
Reference-contexts: Validation and refinement tools integrate well together because a similar exploration of the KB is undertaken by both processes and a validation tool can often provide evidence for the need to refine the KB <ref> (Craw & Sleeman, 1994) </ref>. In addition Validation and Verification research is often concerned with developing metrics and testing tools which could be used by KRUST for evaluating the refined KBs. 9 Future Work In this paper we have described KRUST's refinement of a propositional KBSs. <p> We also wish to thank the anonymous reviewers whose useful comments encouraged us to focus our attention on the distinction between theory revision and knowledge refinement systems; a theme which we have previously explored <ref> (Craw, Sleeman, Boswell, & Carbonara, 1994) </ref>.
Reference: <author> Davis, R. </author> <year> (1984). </year> <title> Interactive transfer of expertise. </title> <editor> In Buchanan, B., & Shortliffe, E. H. (Eds.), </editor> <booktitle> Rule-Based Expert Systems, </booktitle> <pages> pp. 171-205. </pages> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: Therefore techniques developed within this community have focused on updating the knowledge in a fairly mature system. In particular the knowledge representation and problem-solving method is fixed and much of the knowledge is acceptable. Therefore many systems have been designed round particular KBSs and shells. Examples include: TEIRESIAS <ref> (Davis, 1984) </ref>, SEEK (Ginsberg, 1988; Politakis, 1985), ODYSSEUS (Wilkins, 1990; Wilkins & Tan, 1989). * Theory revision uses automated learning to revise Horn clause theories where any satisfied rule may fire, and so there is no additional control.
Reference: <author> De Raedt, L. </author> <year> (1992). </year> <title> Interactive Theory Revision. </title> <publisher> Academic Press, London. </publisher>
Reference-contexts: Examples include: WHY (Saitta, Botta, & Neri, 1993), MOBAL (Morik, Wrobel, Kietz, & Emde, 1993) and CLINT <ref> (De Raedt, 1992) </ref>. In general there are many possible changes to a KB that achieve the desired effect.
Reference: <author> Ginsberg, A. </author> <year> (1988). </year> <title> Automatic Refinement of Expert System Knowledge Bases. </title> <booktitle> Research Notes in Artificial Intelligence. </booktitle> <publisher> Pitman, London. </publisher>
Reference: <author> Holland, J. H. </author> <year> (1986). </year> <title> Escaping brittleness: The possibilities of general-purpose learning algorithms applied to parallel rule-based systems. </title> <editor> In Michalski, R. S., Carbonell, J. G., & Mitchell, T. M. (Eds.), </editor> <booktitle> Machine Learning Volume II, </booktitle> <pages> pp. 593-623. </pages> <publisher> Morgan Kauffman, </publisher> <address> Los Altos, CA. </address>
Reference-contexts: Therefore, it is worthwhile using a fairly intensive empirical evaluation for the selection process. KRUST uses a compromise method between a simple accuracy metric and a complex bucket-brigade blame assignment method <ref> (Holland, 1986) </ref>. Two numerical slots, SPEC and GEN, are attached to each rule and they indicate the level of evidence that the rule is too general or too specific. KRUST generates the evidence for these slots by running the KB on a set of sample cases.
Reference: <author> Mahoney, J. J., & Mooney, R. J. </author> <year> (1994). </year> <title> Combining connectionist and symbolic learning to refine certainty-factor rule-bases. </title> <booktitle> Connection Science (Special issue on Architectures for Integrating Neural and Symbolic Processing), </booktitle> <pages> 5. </pages>
Reference-contexts: These ideas are similar to the network back-propagation approach of RAPTURE <ref> (Mahoney & Mooney, 1994) </ref> on MYCIN-like KBs. Finally, we consider the standard OPS-5 strategies: specificity and recency.
Reference: <author> Marcus, S. (Ed.). </author> <year> (1988). </year> <title> Automating Knowledge Acquisition for Expert Systems. </title> <publisher> Kluwer, </publisher> <address> Boston. </address>
Reference-contexts: 1 Introduction The widespread use of Knowledge Based Systems (KBS) has led to increasing interest in the design of automated tools to ease the Knowledge Acquisition Bottleneck, by relieving the knowledge engineer and the domain expert of some of the repetitive tasks. Tools such as MOLE and SALT <ref> (Marcus, 1988) </ref> have concentrated on the acquisition of domain knowledge, being guided by the requirements of the KBS's specified problem solving strategy. <p> SEEK applies a statistical analysis and ODYSSEUS suspects faulty domain knowledge when problem-solving meta-knowledge fails to match the current situation. ODYSSEUS' approach extends the task-driven method found in the MOLE and SALT knowledge acquisition tools <ref> (Marcus, 1988) </ref>. Smith et al.'s refinement of the Dipmeter Adviser requires access to a large source of meta-knowledge justifying the causal links between items of domain knowledge (Smith et al., 1985). Multi-strategy systems exploit a range of knowledge sources, including the expert, in the process of repairing knowledge.
Reference: <author> Morik, K., Wrobel, S., Kietz, J.-U., & Emde, W. </author> <year> (1993). </year> <title> Knowledge Acquisition and Machine Learning. </title> <publisher> Academic Press, London. </publisher>
Reference-contexts: Examples include EITHER (Ourston & Mooney, 1990), FORTE (Richards & Mooney, 1991) and AUDREY-II (Wogulis & Pazzani, 1993). 28 * Multi-strategy revision systems apply several learning techniques to a range of knowl-edge sources. Examples include: WHY (Saitta, Botta, & Neri, 1993), MOBAL <ref> (Morik, Wrobel, Kietz, & Emde, 1993) </ref> and CLINT (De Raedt, 1992). In general there are many possible changes to a KB that achieve the desired effect.
Reference: <author> Ourston, D., & Mooney, R. </author> <year> (1990). </year> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. </pages> <address> 815-820 Cambridge, MA. </address> <note> 32 Ourston, </note> <author> D., & Mooney, R. </author> <year> (1994). </year> <title> Theory refinement combining analytical and empirical methods. </title> <journal> Artificial Intelligence, </journal> <volume> 66, </volume> <pages> 273-309. </pages>
Reference-contexts: Examples include: TEIRESIAS (Davis, 1984), SEEK (Ginsberg, 1988; Politakis, 1985), ODYSSEUS (Wilkins, 1990; Wilkins & Tan, 1989). * Theory revision uses automated learning to revise Horn clause theories where any satisfied rule may fire, and so there is no additional control. Examples include EITHER <ref> (Ourston & Mooney, 1990) </ref>, FORTE (Richards & Mooney, 1991) and AUDREY-II (Wogulis & Pazzani, 1993). 28 * Multi-strategy revision systems apply several learning techniques to a range of knowl-edge sources. Examples include: WHY (Saitta, Botta, & Neri, 1993), MOBAL (Morik, Wrobel, Kietz, & Emde, 1993) and CLINT (De Raedt, 1992).
Reference: <author> Pazzani, M. J., & Brunk, C. A. </author> <year> (1991). </year> <title> Detecting and correcting errors in rule-based expert systems: An integration of empirical and explanation-based learning. </title> <journal> Knowledge Acquisition, </journal> <volume> 3, </volume> <pages> 157-173. </pages>
Reference-contexts: However, we are currently adapting KRUST to refine KBs with a restricted first order representation, as used by the student loan domain <ref> (Pazzani & Brunk, 1991) </ref>. The representation that KRUST refined in this paper closely matches that required but the refinement process must be adapted to cope with variables and their bindings.
Reference: <author> Politakis, P. G. </author> <year> (1985). </year> <title> Empirical Analysis for Expert Systems. </title> <booktitle> Research Notes in Artificial Intelligence. </booktitle> <publisher> Pitman, London. </publisher>
Reference: <author> Richards, B. L., & Mooney, R. J. </author> <year> (1991). </year> <title> First-order theory revision. </title> <editor> In Birnbaum, L., & Collins, G. (Eds.), </editor> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 447-451 Evanston, IL. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Examples include: TEIRESIAS (Davis, 1984), SEEK (Ginsberg, 1988; Politakis, 1985), ODYSSEUS (Wilkins, 1990; Wilkins & Tan, 1989). * Theory revision uses automated learning to revise Horn clause theories where any satisfied rule may fire, and so there is no additional control. Examples include EITHER (Ourston & Mooney, 1990), FORTE <ref> (Richards & Mooney, 1991) </ref> and AUDREY-II (Wogulis & Pazzani, 1993). 28 * Multi-strategy revision systems apply several learning techniques to a range of knowl-edge sources. Examples include: WHY (Saitta, Botta, & Neri, 1993), MOBAL (Morik, Wrobel, Kietz, & Emde, 1993) and CLINT (De Raedt, 1992).
Reference: <author> Saitta, L., Botta, M., & Neri, F. </author> <year> (1993). </year> <title> Multistrategy learning and theory revision. </title> <journal> Machine Learning, </journal> <volume> 11 (2/3), </volume> <pages> 153-172. </pages>
Reference-contexts: Examples include EITHER (Ourston & Mooney, 1990), FORTE (Richards & Mooney, 1991) and AUDREY-II (Wogulis & Pazzani, 1993). 28 * Multi-strategy revision systems apply several learning techniques to a range of knowl-edge sources. Examples include: WHY <ref> (Saitta, Botta, & Neri, 1993) </ref>, MOBAL (Morik, Wrobel, Kietz, & Emde, 1993) and CLINT (De Raedt, 1992). In general there are many possible changes to a KB that achieve the desired effect.
Reference: <author> Smith, R. G., Winston, H. A., Mitchell, T. M., & Buchanan, B. G. </author> <year> (1985). </year> <title> Representation and use of explicit justifications for knowledge base refinement. </title> <booktitle> In Proceedings of the Ninth IJCAI Conference, </booktitle> <pages> pp. </pages> <address> 367-374 Los Angeles, CA. </address> <month> ViVa Partners </month> <year> (1992). </year> <title> Verification, improvement & validation of knowledge based systems. Technical annexe, ESPRIT III Project 6125. </title>
Reference-contexts: KRUST applies a more knowledge-based, rather than data based, approach to implement more gradual changes to individual conditions, in contrast to the more coarse specialisation and generalisation operators that add or delete complete rules or conditions. The justification knowledge described by Smith et al. <ref> (Smith, Winston, Mitchell, & Buchanan, 1985) </ref> is considerably more difficult to acquire than the meta-knowledge used by KRUST which are domain hierarchies; our hierarchies are frequently collected during the general knowledge acquisition phase. <p> ODYSSEUS' approach extends the task-driven method found in the MOLE and SALT knowledge acquisition tools (Marcus, 1988). Smith et al.'s refinement of the Dipmeter Adviser requires access to a large source of meta-knowledge justifying the causal links between items of domain knowledge <ref> (Smith et al., 1985) </ref>. Multi-strategy systems exploit a range of knowledge sources, including the expert, in the process of repairing knowledge.
Reference: <author> Waterman, D. A. </author> <year> (1970). </year> <title> Generalization learning techniques for automating the learning of heuristics. </title> <journal> Artificial Intelligence, </journal> <volume> 1, </volume> <pages> 29-120. </pages>
Reference-contexts: In general there are many possible changes to a KB that achieve the desired effect. A variety of techniques have been used by knowledge refinement systems to make this choice: TEIRESIAS asks the user to agree a suitable change, Waterman's POKER playing learning program <ref> (Waterman, 1970) </ref> applies the first successful refinement, SEEK chooses the refinement that repairs the most faults in a set of training examples.
Reference: <author> Wilkins, D. C. </author> <year> (1990). </year> <title> Knowledge base refinement as improving an incorrect and incomplete domain theory. </title> <editor> In Kodratoff, Y., & Michalski, R. S. (Eds.), </editor> <booktitle> Machine Learning Volume III, </booktitle> <pages> pp. 493-513. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Wilkins, D. C., & Tan, K.-W. </author> <year> (1989). </year> <title> Knowledge base refinement as improving an incorrect, inconsistent and incomplete domain theory. </title> <editor> In Spatz, B. (Ed.), </editor> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <pages> pp. </pages> <address> 332-337 Ithaca, NY. </address> <publisher> Morgan Kauffman. </publisher>
Reference: <author> Wogulis, J., & Pazzani, M. </author> <year> (1993). </year> <title> A methodology for evaluating theory revision systems: Results with AUDREY II. </title> <editor> In Bajcsy, R. (Ed.), </editor> <booktitle> Proceedings of the Thirteenth IJCAI Conference, </booktitle> <pages> pp. </pages> <address> 1128-1134 Chambery, FRANCE. </address> <month> 33 </month>
Reference-contexts: KRUST selects those children that are not satisfied and creates one replacement rule for each suitable specialisation; equivalent to adding a disjunctive condition. These notions of gradual change extend the ideas of Wogulis & Pazzani <ref> (Wogulis & Paz-zani, 1993) </ref> from syntactic closeness to semantic proximity. Wogulis & Pazzani suggest that a syntactic distance metric between KBs is complementary to accuracy as a measure for comparing the quality of revised theories with respect to the original. <p> Examples include EITHER (Ourston & Mooney, 1990), FORTE (Richards & Mooney, 1991) and AUDREY-II <ref> (Wogulis & Pazzani, 1993) </ref>. 28 * Multi-strategy revision systems apply several learning techniques to a range of knowl-edge sources. Examples include: WHY (Saitta, Botta, & Neri, 1993), MOBAL (Morik, Wrobel, Kietz, & Emde, 1993) and CLINT (De Raedt, 1992).
References-found: 26

