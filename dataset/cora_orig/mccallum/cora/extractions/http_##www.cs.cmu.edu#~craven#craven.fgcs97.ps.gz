URL: http://www.cs.cmu.edu/~craven/craven.fgcs97.ps.gz
Refering-URL: http://www.cs.cmu.edu/~craven/rule-extraction.html
Root-URL: 
Email: mark.craven@cs.cmu.edu  shavlik@cs.wisc.edu  
Title: Submitted to the Future Generation Computer Systems special issue on Data Mining. Using Neural Networks
Author: Mark W. Craven Jude W. Shavlik 
Keyword: machine learning, neural networks, rule extraction, comprehensible models, decision trees, perceptrons  
Address: Pittsburgh, PA 15213-3891  Madison, WI 53706-1685  
Affiliation: School of Computer Science Carnegie Mellon University  Computer Sciences Department University of Wisconsin-Madison  
Abstract: Neural networks have been successfully applied in a wide range of supervised and unsupervised learning applications. Neural-network methods are not commonly used for data-mining tasks, however, because they often produce incomprehensible models and require long training times. In this article, we describe neural-network learning algorithms that are able to produce comprehensible models, and that do not require excessive training times. Specifically, we discuss two classes of approaches for data mining with neural networks. The first type of approach, often called rule extraction, involves extracting symbolic models from trained neural networks. The second approach is to directly learn simple, easy-to-understand networks. We argue that, given the current state of the art, neural-network methods deserve a place in the tool boxes of data-mining specialists. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Andrews, R., Diederich, J., & Tickle, A. B. </author> <year> (1995). </year> <title> A survey and critique of techniques for extracting rules from trained artificial neural networks. </title> <journal> Knowledge-Based Systems, </journal> <volume> 8(6). </volume>
Reference: <author> Bishop, C. M. </author> <year> (1996). </year> <title> Neural Networks for Pattern Recognition. </title> <publisher> Oxford University Press, Oxford, </publisher> <address> England. </address>
Reference-contexts: Neural-network learning methods, on the other hand, represent their learned solutions using real-valued parameters in a network of simple processing units. We do not provide an introduction to neural-network models in this article, but instead refer the interested reader to one of the good textbooks in the field <ref> (e.g., Bishop, 1996) </ref>. A detailed survey of real-world neural-network applications can be found elsewhere (Widrow et al., 1994). The rest of this article is organized as follows. In the next section, we consider the applicability of neural-network methods to the task of data mining.
Reference: <author> Breiman, L., Friedman, J., Olshen, R., & Stone, C. </author> <year> (1984). </year> <title> Classification and Regression Trees. </title> <publisher> Wadsworth and Brooks, </publisher> <address> Monterey, CA. </address>
Reference-contexts: Instead, Trepan's extraction process involves progressively refining a model of the entire network. The model, in this case, is a decision tree which is grown in a best-first manner. The Trepan algorithm, as shown in Table 1, is similar to conventional decision-tree algorithms, such as CART <ref> (Breiman et al., 1984) </ref> and C4.5 (Quinlan, 1993), which learn directly from a training set. These algorithms build decision trees by recursively partitioning the input space.
Reference: <author> Craven, M. & Shavlik, J. </author> <year> (1993). </year> <title> Learning symbolic rules using artificial neural networks. </title> <booktitle> In Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> (pp. 73-80), </pages> <address> Amherst, MA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Since they correspond the symbolic rules, the weights in these networks are initially well clustered, and empirical results indicate that the weights remain fairly clustered after training. The applicability of this approach was later extended to ordinary neural networks by using a special cost function for network training <ref> (Craven & Shavlik, 1993) </ref>. 3.3 A Learning-Based Rule-Extraction Method In contrast to the previously discussed methods, we have developed a rule-extraction algorithm called Trepan (Craven & Shavlik, 1996; Craven, 1996), that views the problem of extracting a comprehensible hypothesis from a trained network as an inductive learning task.
Reference: <author> Craven, M. W. </author> <year> (1996). </year> <title> Extracting Comprehensible Models from Trained Neural Networks. </title> <type> PhD thesis, </type> <institution> Computer Sciences Department, University of Wisconsin, Madison, WI. </institution> <note> Available as CS Technical Report 1326. Available by WWW as ftp://ftp.cs.wisc.edu/machine-learning/shavlik-group/craven.thesis.ps.Z. </note>
Reference-contexts: The results in this table indicate that, in general, the trees produced by the two algorithms are roughly comparable in terms of size. The results presented in this table are described in greater detail elsewhere <ref> (Craven, 1996) </ref>. 3.4 Finite State Automata Extraction Methods One specialized case of rule extraction is the extraction of finite state automata (FSA) from recurrent neural networks. A recurrent network is one that has links from a set of its hidden or output units to a set of its input units. <p> In this section we focus on one particular algorithm that is appealing for data-mining applications because it incrementally constructs its learned networks. This algorithm, called BBP <ref> (Jackson & Craven, 1996) </ref>, is unlike traditional neural-network methods in that it does not involve training with a gradient-based optimization method. The hypotheses it learns, however, are perceptrons, and thus we consider it to be a neural-network method. The BBP algorithm is shown in Table 3. <p> Additional details concerning these experiments can be found elsewhere <ref> (Craven, 1996) </ref>. 4.2 An Unsupervised Method As stated in the Introduction, unsupervised learning involves the use of inductive methods to discover regularities that are present in a data set.
Reference: <author> Craven, M. W. & Shavlik, J. W. </author> <year> (1996). </year> <title> Extracting tree-structured representations of trained networks. </title> <editor> In Touretzky, D., Mozer, M., & Hasselmo, M., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 8). </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: The results in this table indicate that, in general, the trees produced by the two algorithms are roughly comparable in terms of size. The results presented in this table are described in greater detail elsewhere <ref> (Craven, 1996) </ref>. 3.4 Finite State Automata Extraction Methods One specialized case of rule extraction is the extraction of finite state automata (FSA) from recurrent neural networks. A recurrent network is one that has links from a set of its hidden or output units to a set of its input units. <p> In this section we focus on one particular algorithm that is appealing for data-mining applications because it incrementally constructs its learned networks. This algorithm, called BBP <ref> (Jackson & Craven, 1996) </ref>, is unlike traditional neural-network methods in that it does not involve training with a gradient-based optimization method. The hypotheses it learns, however, are perceptrons, and thus we consider it to be a neural-network method. The BBP algorithm is shown in Table 3. <p> Additional details concerning these experiments can be found elsewhere <ref> (Craven, 1996) </ref>. 4.2 An Unsupervised Method As stated in the Introduction, unsupervised learning involves the use of inductive methods to discover regularities that are present in a data set.
Reference: <author> Freund, Y. & Schapire, R. E. </author> <year> (1996). </year> <title> Experiments with a new boosting algorithm. </title> <booktitle> In Proceedings of the Thirteenth International Conference on Machine Learning, </booktitle> <pages> (pp. 148-156), </pages> <address> Bari, Italy. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The other limitation of the method is that it assumes that the inputs are Boolean functions. As discussed above, however, domains with real-valued features can be handled by discretizing the features. The BBP method is based on an algorithm called AdaBoost <ref> (Freund & Schapire, 1996) </ref> which is a hypothesis-boosting algorithm.
Reference: <author> Fu, L. </author> <year> (1991). </year> <title> Rule learning by searching on adapted nets. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> (pp. 590-595), </pages> <address> Anaheim, CA. </address> <publisher> AAAI/MIT Press. </publisher>
Reference: <author> Gallant, S. I. </author> <year> (1993). </year> <title> Neural Network Learning and Expert Systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Giles, C. L., Miller, C. B., Chen, D., Chen, H. H., Sun, G. Z., & Lee, Y. C. </author> <year> (1992). </year> <title> Learning and extracting finite state automata with second-order recurrent neural networks. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 393-405. </pages>
Reference-contexts: Several research groups have developed algorithms for extracting finite state automata from trained recurrent networks. The key issue in such algorithms, is deciding how to partition the s-dimensional real-valued space into a set of discrete states. The method of Giles et al. <ref> (Giles et al., 1992) </ref>, which is representative of this class of algorithms, proceeds as follows. First, the algorithm partitions each state unit's activation range into q intervals of equal width, thus dividing the s-dimensional space into q s partitions.
Reference: <author> Jackson, J. C. & Craven, M. W. </author> <year> (1996). </year> <title> Learning sparse perceptrons. </title> <editor> In Touretzky, D., Mozer, M., & Hasselmo, M., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 8). </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: In this section we focus on one particular algorithm that is appealing for data-mining applications because it incrementally constructs its learned networks. This algorithm, called BBP <ref> (Jackson & Craven, 1996) </ref>, is unlike traditional neural-network methods in that it does not involve training with a gradient-based optimization method. The hypotheses it learns, however, are perceptrons, and thus we consider it to be a neural-network method. The BBP algorithm is shown in Table 3.
Reference: <author> Kohonen, T. </author> <year> (1995). </year> <title> Self-Organizing Maps. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, Germany. </address>
Reference-contexts: The first component is a neural network called a self-organizing map (SOM) <ref> (Kohonen, 1995) </ref> which is trained by an unsupervised learning process. An SOM learns a mapping from its input space to its output space that preserves the topological ordering of points in the input space.
Reference: <author> Lawrence, S., Giles, C. L., & Tsoi, A. C. </author> <year> (1997). </year> <title> Symbolic conversion, grammatical inference and rule extraction for foreign exchange rate prediction. </title> <editor> In Abu-Mostafa, Y., Weigend, A. S., & Refenes, P. N., editors, </editor> <title> Neural Networks in the Capital Markets. </title> <publisher> World Scientific, Singapore. </publisher>
Reference: <author> Quinlan, J. </author> <year> (1993). </year> <title> C4.5: Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: The model, in this case, is a decision tree which is grown in a best-first manner. The Trepan algorithm, as shown in Table 1, is similar to conventional decision-tree algorithms, such as CART (Breiman et al., 1984) and C4.5 <ref> (Quinlan, 1993) </ref>, which learn directly from a training set. These algorithms build decision trees by recursively partitioning the input space. Each internal node in such a tree represents a splitting criterion that partitions some part of the input space, and each leaf represents a predicted class. <p> Table 2 shows test-set accuracy and tree complexity results for five such problem domains. The table shows the predictive accuracy of feed-forward neural networks, decision trees extracted from the networks using Trepan, and decision trees learned directly from the data using the C4.5 algorithm <ref> (Quinlan, 1993) </ref>. It can be seen that, for every data set, neural networks provide better predictive accuracy than the decision trees learned by C4.5. This result indicates that these are domains for which neural networks have a more suitable inductive bias than C4.5.
Reference: <author> Rumelhart, D. E. & Zipser, D. </author> <year> (1985). </year> <title> Feature discovery by competitive learning. </title> <journal> Cognitive Science, </journal> <volume> 9 </volume> <pages> 75-112. </pages> <note> 21 Saito, </note> <author> K. & Nakano, R. </author> <year> (1988). </year> <title> Medical diagnostic expert system based on PDP model. </title> <booktitle> In Proceedings of the IEEE International Conference on Neural Networks, </booktitle> <pages> (pp. 255-262), </pages> <address> San Diego, CA. </address> <publisher> IEEE Press. </publisher>
Reference-contexts: Although there is a wide variety of neural-network algorithms for unsupervised learning, we discuss only one of them here: competitive learning <ref> (Rumelhart & Zipser, 1985) </ref>. Competitive learning is arguably the unsupervised neural-network algorithm that is most appropriate for data mining, and it is illustrative of the utility of single-layer neural-network methods.
Reference: <author> Sethi, I. K. & Yoo, J. H. </author> <year> (1994). </year> <title> Symbolic approximation of feedforward neural networks. </title> <editor> In Gelsema, E. S. & Kanal, L. N., editors, </editor> <booktitle> Pattern Recognition in Practice (volume 4). </booktitle> <publisher> North-Holland, </publisher> <address> New York, NY. </address>
Reference: <author> Shavlik, J., Mooney, R., & Towell, G. </author> <year> (1991). </year> <title> Symbolic and neural net learning algorithms: An empirical comparison. </title> <journal> Machine Learning, </journal> <volume> 6 </volume> <pages> 111-143. </pages>
Reference-contexts: Several empirical studies have pointed out that there are some problem domains in which neural networks provide superior predictive accuracy to commonly used symbolic learning algorithms <ref> (e.g., Shavlik et al., 1991) </ref>. Although neural networks have an appropriate inductive bias for a wide range of problems, they are not commonly used for data mining tasks.
Reference: <author> Thrun, S. </author> <year> (1995). </year> <title> Extracting rules from artificial neural networks with distributed representations. </title> <editor> In Tesauro, G., Touretzky, D., & Leen, T., editors, </editor> <booktitle> Advances in Neural Information Processing Systems (volume 7). </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Towell, G. & Shavlik, J. </author> <year> (1993). </year> <title> Extracting refined rules from knowledge-based neural networks. </title> <journal> Machine Learning, </journal> <volume> 13(1) </volume> <pages> 71-101. </pages>
Reference-contexts: This clustering reduces the search problem from one defined by n weights to one defined by (c t n) clusters. This approach, which assumes that the weights are fairly well clustered after training, was initially developed for knowledge-based neural networks <ref> (Towell & Shavlik, 1993) </ref>, in which the initial weights of the network are specified by a set of symbolic inference rules. Since they correspond the symbolic rules, the weights in these networks are initially well clustered, and empirical results indicate that the weights remain fairly clustered after training.
Reference: <author> Widrow, B., Rumelhart, D. E., & Lehr, M. A. </author> <year> (1994). </year> <title> Neural networks: Applications in industry, business, </title> <journal> and science. Communications of the ACM, </journal> <volume> 37(3) </volume> <pages> 93-105. 22 </pages>
Reference-contexts: We do not provide an introduction to neural-network models in this article, but instead refer the interested reader to one of the good textbooks in the field (e.g., Bishop, 1996). A detailed survey of real-world neural-network applications can be found elsewhere <ref> (Widrow et al., 1994) </ref>. The rest of this article is organized as follows. In the next section, we consider the applicability of neural-network methods to the task of data mining.
References-found: 20

