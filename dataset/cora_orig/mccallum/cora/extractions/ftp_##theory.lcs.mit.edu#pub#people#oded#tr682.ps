URL: ftp://theory.lcs.mit.edu/pub/people/oded/tr682.ps
Refering-URL: http://theory.lcs.mit.edu/~oded/cryptography.html
Root-URL: 
Email: canetti@theory.lcs.mit.edu.  ffeige,oded,naorg@wisdom.weizmann.ac.il.  
Title: Adaptively Secure Multi-party Computation  
Author: Ran Canetti Uri Feige Oded Goldreich Moni Naor yz 
Address: Rehovot, Israel.  
Affiliation: Department of Computer Science and Applied Math,Weizmann Institute of Science,  
Note: TOC/CIS groups, LCS, MIT.  Incumbent of the Morris and Rose Goldman Career Development Chair. Research supported by grants from the Israel Science Foundation administered by the Israeli Academy of Sciences and by the US-Israel Binational Science Foundation.  
Date: February 1996  
Pubnum: TR-682 (LCS/MIT),  
Abstract: It turns out that the power of an adaptive adversary is greatly affected by the amount of information gathered upon the corruption of a party. This amount of information models the extent to which uncorrupted parties are trusted to carry out instructions that cannot be externally verified, such as erasing records of past configurations. It has been shown that if the parties are trusted to erase such records, then adaptively secure computation can be carried out using known primitives. However, this total trust in parties may be unrealistic in many scenarios. An important question, open since 1986, is whether adaptively secure multi-party computation can be carried out in the "insecure channel" setting, even if no party is thoroughly trusted. Our main result is an affirmative resolution of this question for the case where even uncorrupted parties may deviate from the protocol by keeping record of all past configurations. We first propose a novel property of encryption protocols and show that if an encryption protocol enjoying this property is used, instead of a standard encryption scheme, then known constructions become adaptively secure. Next we construct, based on the standard RSA assumption, an encryption protocol that enjoys this property. We also consider parties that, even when uncorrupted, may internally deviate from their protocols in arbitrary ways, as long as no external test can detect faulty behavior. We show that in this case no non-trivial protocol can be proven adaptively secure using black-box simulation. This holds even if the communication channels are totally secure. 
Abstract-found: 1
Intro-found: 1
Reference: [B] <author> E. Bach, </author> <title> "How to generate factored random numbers", </title> <journal> SIAM J. on Comput., </journal> <volume> Vol. 17, No. 2, </volume> <year> 1988, </year> <pages> pp. 179-193. </pages>
Reference-contexts: The common domain, given security parameter n, is f0; 1g n . A permutation over f0; 1g n is chosen as follows. First choose a number N uniformly from [2 n1 : : : 2 n ], together with its factorization (via Bach's algorithm <ref> [B] </ref>).
Reference: [Be1] <author> D. Beaver, </author> <title> "Foundations of Secure Interactive Computing", </title> <booktitle> CRYPTO, </booktitle> <year> 1991. </year>
Reference-contexts: In order to present the extra difficulty in constructing adaptively secure protocols, we roughly sketch the standard definition of secure multi-party computation. (Full definitions appear in Section 3.) Our presentation follows <ref> [MR, Be1, GwL, C] </ref>, while incorporating the notion of semi-honest parties in the definition. The definition follows the same outline in the secure channels setting and in the computational settings. Background: How is security defined. First an ideal model for secure multi-party computation is formulated.
Reference: [Be2] <author> D. Beaver, </author> <title> "Adaptive Zero Knowledge and Computational Equivocation", </title> <booktitle> 28th STOC, </booktitle> <year> 1996. </year>
Reference-contexts: Related work. Independently of our work, Beaver has investigated the problem of converting, in the computational setting, protocols which are adaptively secure against eavesdropping adversaries into protocols adaptively secure against Byzantine adversaries <ref> [Be2] </ref>. No protocols adaptively secure against eavesdropping adversaries were known prior to our work, nor are such protocols suggested in [Be2]. We believe that the problem of adaptive security retains its difficulty even if only eavesdropping adversaries are considered. <p> Independently of our work, Beaver has investigated the problem of converting, in the computational setting, protocols which are adaptively secure against eavesdropping adversaries into protocols adaptively secure against Byzantine adversaries <ref> [Be2] </ref>. No protocols adaptively secure against eavesdropping adversaries were known prior to our work, nor are such protocols suggested in [Be2]. We believe that the problem of adaptive security retains its difficulty even if only eavesdropping adversaries are considered.
Reference: [BH] <author> D. Beaver and S. Haber, </author> <title> "Cryptographic Protocols Provably secure Against Dynamic Adversaries", </title> <booktitle> Eurocrypt, </booktitle> <year> 1992. </year>
Reference-contexts: If uncorrupted parties are trusted to carry out even unverifiable instructions such as erasing local data then adaptively secure computation can be carried out using known primitives <ref> [F, BH] </ref>. However, this trust may be unrealistic in many scenarios. We thus consider parties that, even when uncorrupted, internally deviate slightly from their protocols. We call such parties semi-honest. <p> This task is impossible if a standard encryption scheme (i.e., an encryption scheme where no ciphertext can be a legal encryption of both `1' and `0') is used. We remark that Feldman, and independently Beaver and Haber, have suggested to solve this problem as follows <ref> [F, BH] </ref>. Instruct each party to erase (say, at the end of each round) all the information involved with encrypting and decrypting of messages. If the parties indeed erase this data, then the adversary will no longer see, upon corrupting a party, how past messages were encrypted and decrypted. <p> Consequently, such "erasing" protocols can be shown adaptively secure in the computational setting. However, this approach is clearly not valid in the presence of semi-honest parties. In particular, it is not known whether the <ref> [F, BH] </ref> protocols (or any other previous protocols) are secure in the presence of non-erasing parties. Sketch of our solution. We solve this problem by constructing an encryption scheme that serves as an alternative to standard encryption schemes, and enjoys an additional property roughly described as follows.
Reference: [BGW] <author> M. Ben-Or, S. Goldwasser and A. Wigderson, </author> " <title> Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation", </title> <booktitle> 20th STOC, </booktitle> <pages> pp. 1-10, </pages> <year> 1988. </year>
Reference-contexts: All parties, as well as the adversary, are restricted to probabilistic polynomial time). Ben-Or, Goldwasser and Wigderson, and independently Chaum, Crepeau and Damgard, have shown how to securely compute any function in the secure channels setting <ref> [BGW, CCD] </ref>. (In the secure channels setting the adversary cannot eavesdrop on the communication between uncorrupted parties, and is allowed unlimited computational power.) These constructions can be shown secure in the presence of non-adaptive adversaries. <p> protocols that are secure even if the uncorrupted parties are semi-honest rather than honest. 1 We discuss the problems encountered in the secure channels setting, and state the amount of internal deviation from the protocol under which adaptively secure protocols are known to exist. (In particular, under these conditions the <ref> [BGW, CCD] </ref> protocols can be proven adaptively secure.) Finally we concentrate on the computational setting, and on semi-honest parties that follow their protocols with the exception that no internal data is ever erased. <p> The state-of-the-art with respect to adaptive computation in the secure channels setting can be briefly summarized as follows. Adaptively secure protocols for computing any function exist in the presence of non-erasing parties (e.g., <ref> [BGW, CCD] </ref>). However, in contrast with popular belief, not every non-adaptively secure protocol is also adaptively secure in the presence of non-erasing parties. Furthermore, current techniques are insufficient for proving adaptive security of any protocol for computing a non-trivial function in the presence of honest-looking parties. <p> It turns out that this can be done for the <ref> [BGW] </ref> protocols for computing any function in the presence of non-erasing parties. Thus, the [BGW] protocols are adaptively secure in the presence of non-erasing parties. <p> It turns out that this can be done for the <ref> [BGW] </ref> protocols for computing any function in the presence of non-erasing parties. Thus, the [BGW] protocols are adaptively secure in the presence of non-erasing parties. Recall, however, that not every protocol which is secure against non-adaptive adversaries is also secure against adaptive adversaries (see example in the third paragraph of the Introduction). In face of honest-looking parties. <p> If this honest-looking variant of fi is shown secure via an efficient black-box simulation as described above, then the constructed simulator can be used to find claws between f 0 and f 1 . Similar honest-looking variants can be constructed for the <ref> [BGW, CCD] </ref> protocols. Consequently, if claw-free pairs of permutations exist then adaptive security of the [BGW, CCD] protocols, in the presence of honest-looking parties, cannot be proven via black-box simulation. <p> Similar honest-looking variants can be constructed for the <ref> [BGW, CCD] </ref> protocols. Consequently, if claw-free pairs of permutations exist then adaptive security of the [BGW, CCD] protocols, in the presence of honest-looking parties, cannot be proven via black-box simulation. <p> We remark that the only purpose of the technical restrictions imposed on the operation of the simulator is to facilitate proving composition theorems (such as Theorem 4.2). We stress that the security of known protocols (e.g., <ref> [BGW] </ref>) can be shown via simulators that obey these restrictions. 3.3 Adaptive security in the computational setting We now turn to define adaptively secure multi-party computation in the computational setting. <p> In Subsection 4.2 we present our construction of non-committing encryption. We use the following result as our starting point: Theorem 4.1 The <ref> [BGW, CCD] </ref> protocols for computing any function of n inputs are (d n 3 e 1)-securely computable in a simulatable way, in the secure channels setting, in the presence of non-erasing parties and adaptive adversaries. 10 4.1 Adaptive security given non-committing encryption The following theorem formalizes the discussion in Section 2.3. <p> Then ~ t-securely computes f , in a simulatable way in the computational setting, in the presence of non-erasing parties and adaptive adversaries. 10 A security proof of the <ref> [BGW] </ref> construction can be extracted from [C, Chap. 3], which deals with the more involved asynchronous model. 14 Proof (sketch): Let 0 be a non-erasing protocol for and let S be a simulator for 0 in the secure channels setting.
Reference: [BM] <author> M. Blum, and S. Micali, </author> <title> "How to generate Cryptographically strong sequences of pseudo-random bits", </title> <journal> SIAM J. on Computing, </journal> <volume> Vol. 13, </volume> <year> 1984, </year> <pages> pp. 850-864. </pages>
Reference-contexts: Such an initial set-up is not desirable in practice and does not resolve the theoretically important problem of dealing with a setting in which no secret information is shared a-priori. Our scheme uses a collection of trapdoor permutations together with a corresponding hard-core predicate <ref> [BM, Y, GrL] </ref>. Actually, we need a collection of trapdoor permutation with the additional property that they are many permutations over the same domain.
Reference: [BCC] <author> G. Brassard, D. Chaum and C. Crepeau, </author> <title> "Minimum Disclosure Proofs of Knowledge", </title> <journal> JCSS, </journal> <volume> Vol. 37, No. 2, </volume> <year> 1988, </year> <pages> pp. 156-189. </pages>
Reference-contexts: Thus, all that ~ S needs to do is encrypt the messages it has obtained from S. 3 This "non-committing property" is reminiscent of the "Chameleon blobs" of <ref> [BCC] </ref>.
Reference: [C] <author> R. Canetti, </author> <title> "Studies in Secure Multi-Party Computation and Applications", </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Science and Applied Math, Weizmann Institute of Science, Rehovot, Israel, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: In order to present the extra difficulty in constructing adaptively secure protocols, we roughly sketch the standard definition of secure multi-party computation. (Full definitions appear in Section 3.) Our presentation follows <ref> [MR, Be1, GwL, C] </ref>, while incorporating the notion of semi-honest parties in the definition. The definition follows the same outline in the secure channels setting and in the computational settings. Background: How is security defined. First an ideal model for secure multi-party computation is formulated. <p> Then ~ t-securely computes f , in a simulatable way in the computational setting, in the presence of non-erasing parties and adaptive adversaries. 10 A security proof of the [BGW] construction can be extracted from <ref> [C, Chap. 3] </ref>, which deals with the more involved asynchronous model. 14 Proof (sketch): Let 0 be a non-erasing protocol for and let S be a simulator for 0 in the secure channels setting.
Reference: [CDNO] <author> R. Canetti, C. Dwork, M. Naor and R. Ostrovsky, "Deniable Encryptions", </author> <type> manuscript. </type>
Reference-contexts: We believe that the problem of adaptive security retains its difficulty even if only eavesdropping adversaries are considered. Following our work, and motivated by the "Incoercible Voting" Problem, Canetti et. al. <ref> [CDNO] </ref> introduced a stronger type of non-committing encryption protocol as well as an implementation of it based on any trapdoor permutation. Organization. The rest of this paper is organized as follows. In Section 2 we discuss the problem of adaptive security and our solution to it in more detail.
Reference: [CCD] <author> D. Chaum, C. Crepeau and I Damgard, </author> <title> "Multi-party unconditionally secure protocols", </title> <booktitle> 20th STOC, </booktitle> <pages> pp. 11-19, </pages> <year> 1988. </year>
Reference-contexts: All parties, as well as the adversary, are restricted to probabilistic polynomial time). Ben-Or, Goldwasser and Wigderson, and independently Chaum, Crepeau and Damgard, have shown how to securely compute any function in the secure channels setting <ref> [BGW, CCD] </ref>. (In the secure channels setting the adversary cannot eavesdrop on the communication between uncorrupted parties, and is allowed unlimited computational power.) These constructions can be shown secure in the presence of non-adaptive adversaries. <p> protocols that are secure even if the uncorrupted parties are semi-honest rather than honest. 1 We discuss the problems encountered in the secure channels setting, and state the amount of internal deviation from the protocol under which adaptively secure protocols are known to exist. (In particular, under these conditions the <ref> [BGW, CCD] </ref> protocols can be proven adaptively secure.) Finally we concentrate on the computational setting, and on semi-honest parties that follow their protocols with the exception that no internal data is ever erased. <p> The state-of-the-art with respect to adaptive computation in the secure channels setting can be briefly summarized as follows. Adaptively secure protocols for computing any function exist in the presence of non-erasing parties (e.g., <ref> [BGW, CCD] </ref>). However, in contrast with popular belief, not every non-adaptively secure protocol is also adaptively secure in the presence of non-erasing parties. Furthermore, current techniques are insufficient for proving adaptive security of any protocol for computing a non-trivial function in the presence of honest-looking parties. <p> If this honest-looking variant of fi is shown secure via an efficient black-box simulation as described above, then the constructed simulator can be used to find claws between f 0 and f 1 . Similar honest-looking variants can be constructed for the <ref> [BGW, CCD] </ref> protocols. Consequently, if claw-free pairs of permutations exist then adaptive security of the [BGW, CCD] protocols, in the presence of honest-looking parties, cannot be proven via black-box simulation. <p> Similar honest-looking variants can be constructed for the <ref> [BGW, CCD] </ref> protocols. Consequently, if claw-free pairs of permutations exist then adaptive security of the [BGW, CCD] protocols, in the presence of honest-looking parties, cannot be proven via black-box simulation. <p> In Subsection 4.2 we present our construction of non-committing encryption. We use the following result as our starting point: Theorem 4.1 The <ref> [BGW, CCD] </ref> protocols for computing any function of n inputs are (d n 3 e 1)-securely computable in a simulatable way, in the secure channels setting, in the presence of non-erasing parties and adaptive adversaries. 10 4.1 Adaptive security given non-committing encryption The following theorem formalizes the discussion in Section 2.3.
Reference: [DP] <author> A. De-Santis and G. Persiano, </author> <title> "Zero-Knowledge proofs of knowledge without interaction", </title> <booktitle> 33rd FOCS, </booktitle> <pages> pp. 427-436, </pages> <year> 1992. </year>
Reference-contexts: Both f a ; f b are now sent to the sender, who proceeds as in Section 4.2.1. In a simulated execution the simulator will choose both f a and f b together with their trapdoors. 14 14 A similar idea was used in <ref> [DP] </ref>. 26 An implementation based on DH. Consider the following construction. Although it fails to satisfy Definition 4.3, it will be `just as good' for our needs.
Reference: [EGL] <author> S. Even, O. Goldreich and A. Lempel, </author> <title> "A randomized protocol for signing contracts", </title> <journal> CACM, </journal> <volume> vol. 28, No. 6, </volume> <year> 1985, </year> <pages> pp. 637-647. </pages>
Reference-contexts: We use Oblivious Transfer <ref> [R, EGL] </ref> in our constructions. Oblivious Transfer (OT) is a protocol executed by a sender S with inputs s 1 and s 2 , and by a receiver R with input t 2 f1; 2g. <p> In particular S should not know whether R learns s 1 or s 2 . We are only concerned with the case where R is uncorrupted and non-erasing. We use the implementation of OT described in [GMW] (which in turn originates in <ref> [EGL] </ref>). This implementation has an additional property, discussed below, that is useful in our construction. For self containment we sketch, in Figure 5, the [GMW] protocol for OT of one bit. It can be easily verified that the receiver outputs the correct value of t in Step 4.
Reference: [F] <author> P. Feldman, </author> <type> personal communication via Cynthia Dwork, </type> <year> 1988. </year>
Reference-contexts: If uncorrupted parties are trusted to carry out even unverifiable instructions such as erasing local data then adaptively secure computation can be carried out using known primitives <ref> [F, BH] </ref>. However, this trust may be unrealistic in many scenarios. We thus consider parties that, even when uncorrupted, internally deviate slightly from their protocols. We call such parties semi-honest. <p> This task is impossible if a standard encryption scheme (i.e., an encryption scheme where no ciphertext can be a legal encryption of both `1' and `0') is used. We remark that Feldman, and independently Beaver and Haber, have suggested to solve this problem as follows <ref> [F, BH] </ref>. Instruct each party to erase (say, at the end of each round) all the information involved with encrypting and decrypting of messages. If the parties indeed erase this data, then the adversary will no longer see, upon corrupting a party, how past messages were encrypted and decrypted. <p> Consequently, such "erasing" protocols can be shown adaptively secure in the computational setting. However, this approach is clearly not valid in the presence of semi-honest parties. In particular, it is not known whether the <ref> [F, BH] </ref> protocols (or any other previous protocols) are secure in the presence of non-erasing parties. Sketch of our solution. We solve this problem by constructing an encryption scheme that serves as an alternative to standard encryption schemes, and enjoys an additional property roughly described as follows.
Reference: [GILVZ] <author> O. Goldreich, R. Impagliazzo, L. Levin, R. Venkatesan and D. Zuckerman, </author> <title> "Security Preserving Amplification of Hardness", </title> <booktitle> 31st FOCS, </booktitle> <year> 1990, </year> <pages> pp. 318-326. </pages>
Reference-contexts: This yields a collection of "common-domain" per mutations, fg fi : f0; 1g jfij 1-1 7! f0; 1g jfij g, which are weakly one-way. Employing amplification techniques (e.g., <ref> [Y, GILVZ] </ref>) we obtain a proper common-domain system. In the sequel we refer to common-domain trapdoor systems in a less formal way. <p> With non-negligible probability N is a product of two large primes. Thus, this construction yields a collection of common-domain permutations which are weakly one-way. Employing an amplification procedure (e.g., <ref> [Y, GILVZ] </ref>) we obtain a proper common-domain system. This common-domain trapdoor system can be used as described in Section 4.2. However, here the key-generation stage can be simplified considerably. Observe that it is possible to choose a permutation from the above distribution without knowing its trapdoor.
Reference: [GrL] <author> O. Goldreich and L. Levin, </author> <title> "A Hard-Core Predicate to any One-Way Function", </title> <booktitle> 21st STOC, </booktitle> <year> 1989, </year> <pages> pp. 25-32. </pages>
Reference-contexts: Such an initial set-up is not desirable in practice and does not resolve the theoretically important problem of dealing with a setting in which no secret information is shared a-priori. Our scheme uses a collection of trapdoor permutations together with a corresponding hard-core predicate <ref> [BM, Y, GrL] </ref>. Actually, we need a collection of trapdoor permutation with the additional property that they are many permutations over the same domain.
Reference: [GMW] <author> O. Goldreich, S. Micali and A. Wigderson, </author> <title> "How to Play any Mental Game", </title> <booktitle> 19th STOC, </booktitle> <pages> pp. 218-229, </pages> <year> 1987. </year>
Reference-contexts: Consequently, this protocol is secure in the presence of non-adaptive adversaries. Protocols for securely computing any function, in several computation models, have been known for a while: Goldreich, Micali and Wigderson have shown how to securely compute any function in the computational setting <ref> [GMW] </ref>. (In the computational setting all the communication between the parties is seen by the adversary. All parties, as well as the adversary, are restricted to probabilistic polynomial time). <p> Is adaptively secure computation possible in this scenario? This question has remained open since the result of <ref> [GMW] </ref> (even for the case in which the adversary only gathers information from corrupted parties and does not make them deviate any further from the protocol). We answer this question in the affirmative. The problems encountered, and our solution, are presented via the following transformation. <p> The sender S should learn nothing from participating in the protocol. In particular S should not know whether R learns s 1 or s 2 . We are only concerned with the case where R is uncorrupted and non-erasing. We use the implementation of OT described in <ref> [GMW] </ref> (which in turn originates in [EGL]). This implementation has an additional property, discussed below, that is useful in our construction. For self containment we sketch, in Figure 5, the [GMW] protocol for OT of one bit. <p> We use the implementation of OT described in <ref> [GMW] </ref> (which in turn originates in [EGL]). This implementation has an additional property, discussed below, that is useful in our construction. For self containment we sketch, in Figure 5, the [GMW] protocol for OT of one bit. It can be easily verified that the receiver outputs the correct value of t in Step 4. <p> The simulator S proceeds as follows. First an invocation of the key generation protocol " G is simulated, in such a way that S knows both trapdoors f 1 a and f 1 b . (This can be done using the additional property of the <ref> [GMW] </ref> Oblivious Transfer protocol, as described above.) For each party P that A corrupts during this stage, S hands A the internal data held by P in the simulated interaction. <p> If A corrupts P r , then S corrupts P r in the ideal model, learns , and hands A the value f 1 r () for P s 's internal data. The validity of the simulation follows from Lemma 4.7 and from the properties of the <ref> [GMW] </ref> Oblivious Transfer protocol. 2 4.3 Alternative implementations of non-committing encryption We describe two alternative implementations of our non-committing encryption scheme, based on the RSA and DH assumptions, respectively.
Reference: [GwL] <author> S. Goldwasser and L. Levin, </author> <title> "Fair Computation of General Functions in Presence of Immoral Majority", </title> <booktitle> CRYPTO, </booktitle> <year> 1990. </year>
Reference-contexts: In order to present the extra difficulty in constructing adaptively secure protocols, we roughly sketch the standard definition of secure multi-party computation. (Full definitions appear in Section 3.) Our presentation follows <ref> [MR, Be1, GwL, C] </ref>, while incorporating the notion of semi-honest parties in the definition. The definition follows the same outline in the secure channels setting and in the computational settings. Background: How is security defined. First an ideal model for secure multi-party computation is formulated.
Reference: [MR] <author> S. Micali and P. Rogaway, </author> <title> "Secure Computation", </title> <booktitle> CRYPTO, </booktitle> <year> 1991. </year>
Reference-contexts: In order to present the extra difficulty in constructing adaptively secure protocols, we roughly sketch the standard definition of secure multi-party computation. (Full definitions appear in Section 3.) Our presentation follows <ref> [MR, Be1, GwL, C] </ref>, while incorporating the notion of semi-honest parties in the definition. The definition follows the same outline in the secure channels setting and in the computational settings. Background: How is security defined. First an ideal model for secure multi-party computation is formulated.
Reference: [R] <author> M. Rabin, </author> <title> "How to exchange secrets by oblivious transfer", </title> <type> Tech. </type> <institution> Memo TR-81, Aiken Computation Laboratory, Harvard U., </institution> <year> 1981. </year>
Reference-contexts: We use Oblivious Transfer <ref> [R, EGL] </ref> in our constructions. Oblivious Transfer (OT) is a protocol executed by a sender S with inputs s 1 and s 2 , and by a receiver R with input t 2 f1; 2g.
Reference: [RB] <author> T. Rabin and M. Ben-Or, </author> <title> "Verifiable Secret Sharing and Multi-party Protocols with Honest Majority", </title> <booktitle> 21st STOC, </booktitle> <year> 1989, </year> <pages> pp. 73-85. </pages>
Reference-contexts: Thus, we get Theorem 2.1 If common-domain trapdoor systems exist, then there exist secure protocols for computing any (recursive) function in the computational setting, in the presence of non-erasing parties and adaptive adversaries that corrupt less than a third of the parties. We remark that, using standard constructions (e.g., <ref> [RB] </ref>), our protocols can be modified to withstand adversaries that corrupt less than half of the parties. Dealing with honest-looking parties.
Reference: [RSA] <author> R. Rivest, A. Shamir, and L. Adleman, </author> <title> "A Method for Obtaining Digital Signatures and Public Key Cryptosystems", </title> <journal> CACM, </journal> <volume> Vol. 21, </volume> <month> Feb. </month> <year> 1978, </year> <pages> pp. 120-126. </pages>
Reference: [Y] <author> A. Yao, </author> <title> "Theory and applications of trapdoor functions", </title> <booktitle> 23rd FOCS, </booktitle> <year> 1982, </year> <pages> pp. 80-91. 29 </pages>
Reference-contexts: Such an initial set-up is not desirable in practice and does not resolve the theoretically important problem of dealing with a setting in which no secret information is shared a-priori. Our scheme uses a collection of trapdoor permutations together with a corresponding hard-core predicate <ref> [BM, Y, GrL] </ref>. Actually, we need a collection of trapdoor permutation with the additional property that they are many permutations over the same domain. <p> This yields a collection of "common-domain" per mutations, fg fi : f0; 1g jfij 1-1 7! f0; 1g jfij g, which are weakly one-way. Employing amplification techniques (e.g., <ref> [Y, GILVZ] </ref>) we obtain a proper common-domain system. In the sequel we refer to common-domain trapdoor systems in a less formal way. <p> With non-negligible probability N is a product of two large primes. Thus, this construction yields a collection of common-domain permutations which are weakly one-way. Employing an amplification procedure (e.g., <ref> [Y, GILVZ] </ref>) we obtain a proper common-domain system. This common-domain trapdoor system can be used as described in Section 4.2. However, here the key-generation stage can be simplified considerably. Observe that it is possible to choose a permutation from the above distribution without knowing its trapdoor.
References-found: 22

