URL: http://wwwipd.ira.uka.de/~prechelt/Biblio/tcheck_tse98.ps.gz
Refering-URL: 
Root-URL: 
Title: A Controlled Experiment to Assess the Benefits of Procedure Argument Type Checking  
Author: Lutz Prechelt Walter F. Tichy 
Keyword: type checking, defects, quality, productivity, controlled experiment.  
Address: D-76128 Karlsruhe, Germany  
Affiliation: Fakultat fur Informatik Universitat Karlsruhe  
Note: To appear in IEEE Trans. on Software Engineering 1998 (Ref.no. S96134)  
Email: (prechelt@ira.uka.de)  (tichy@ira.uka.de)  
Phone: Phone: +49/721/608-4068, Fax: -7343  
Date: March 23, 1998  
Abstract: Type checking is considered an important mechanism for detecting programming errors, especially interface errors. This report describes an experiment to assess the defect-detection capabilities of static, inter-module type checking. The experiment uses Ansi C and Kernighan&Ritchie (K&R) C. The relevant difference is that the Ansi C compiler checks module interfaces (i.e., the parameter lists of calls to external functions), whereas K&R C does not. The experiment employs a counterbalanced design in which each of the 40 subjects, most of them CS Ph.D. students, writes two non-trivial programs that interface with a complex library (Motif). Each subject writes one program in Ansi C and one in K&R C. The input to each compiler run is saved and manually analyzed for defects. Results indicate that delivered Ansi C programs contain significantly fewer interface defects than delivered K&R C programs. Furthermore, after subjects have gained some familiarity with the interface they are using, Ansi C programmers remove defects faster and are more productive (measured in both delivery time and functionality implemented). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Victor R. Basili and B.T. Perricone. </author> <title> Software er rors and complexity: An empirical investigation. </title> <journal> Communications of the ACM, </journal> <volume> 27(1) </volume> <pages> 42-52, </pages> <month> Jan-uary </month> <year> 1984. </year>
Reference-contexts: The results are not necessarily relevant for advanced programmers. Furthermore, type errors do not play an important role in these studies. Defect classification has also been performed in larger scale software development settings, e.g. <ref> [1, 10] </ref>. Type checking was not an explicit concern in these studies, but in some cases related information can be derived. For instance, Basili and Perricone [1] report that 39 percent of all defects in a 90.000 line FORTRAN project were interface defects. <p> Defect classification has also been performed in larger scale software development settings, e.g. [1, 10]. Type checking was not an explicit concern in these studies, but in some cases related information can be derived. For instance, Basili and Perricone <ref> [1] </ref> report that 39 percent of all defects in a 90.000 line FORTRAN project were interface defects. We conjecture that some fraction of these could have been found by type checking. <p> fallbacks, NULL); /*---------- 2. create and configure widgets --------------------------*/ manager = XmCreateRowColumnManagerOCP ("manager", toplevel, XmVERTICAL, 2, False); /*FU 1*/ square = XmCreateRowColumnManagerOCP ("square", manager, XmHORIZONTAL, 2, True); /*FU 2*/ buttons = XmCreateRowColumnManagerOCP ("buttons", manager, XmHORIZONTAL, 1, False); /*FU 3*/ mw [0] = XmCreateTextFieldWidgetW ("aw", square, 100, "a"); /*FU 4*/ mw <ref> [1] </ref> = XmCreateTextFieldWidgetW ("bw", square, 100, "b"); /*FU 5*/ mw [2] = XmCreateTextFieldWidgetW ("cw", square, 100, "c"); /*FU 6*/ mw [3] = XmCreateTextFieldWidgetW ("dw", square, 100, "d"); /*FU 7*/ invert = XmCreatePushButtonL ("invert", buttons, /*FU 8*/ XmStringCreateLocalized ("Invert matrix")); quit = XmCreatePushButtonL ("quit", buttons, /*FU 9*/ XmStringCreateLocalized ("Quit")); /*---------- 3. register <p> det; /* determinant */ String s; if ((int)client_data == 99) exit (0); /*FU 12*/ else if ((int)client_data == 1) int i; XtGetStringValue (mw [i], XmCvalue, &s); /*FU 13*/ mat [i] = atof (s); /*FU 14*/ -det = mat [0]*mat [3] - mat <ref> [1] </ref>*mat [2]; new [0] = mat [3]/det; new [1] = -mat [1]/det; for (i = 0; i &lt;= 3; i++) XtSetStringValue (mw [i], XmCvalue, ftoa (new [i],8,2)); /*FU 15*/ else matrixErrorMessage ("Matrix cannot be inverted",mat,8,2);/*FU 16*/ -B Solution for Problem B See the description in Appendix A above. #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include "stdmotif.h" void handle_menu (Widget widget, XtPointer
Reference: [2] <author> B. Beizer. </author> <title> Software Testing Techniques. </title> <publisher> Van Nos trand Reinhold, </publisher> <year> 1990. </year>
Reference-contexts: For instance, Basili and Perricone [1] report that 39 percent of all defects in a 90.000 line FORTRAN project were interface defects. We conjecture that some fraction of these could have been found by type checking. The defect-detection capabilities of testing methods <ref> [2, 8, 22] </ref> have received some attention; the corresponding psychological problems were also investigated [20]. There is also a considerable literature about debugging, e.g. [7, 13, 16, 17], and its psychology, e.g. [17, 19]. However, the defects found by testing or debugging are those that already passed the type checks. <p> = XmCreateRowColumnManagerOCP ("manager", toplevel, XmVERTICAL, 2, False); /*FU 1*/ square = XmCreateRowColumnManagerOCP ("square", manager, XmHORIZONTAL, 2, True); /*FU 2*/ buttons = XmCreateRowColumnManagerOCP ("buttons", manager, XmHORIZONTAL, 1, False); /*FU 3*/ mw [0] = XmCreateTextFieldWidgetW ("aw", square, 100, "a"); /*FU 4*/ mw [1] = XmCreateTextFieldWidgetW ("bw", square, 100, "b"); /*FU 5*/ mw <ref> [2] </ref> = XmCreateTextFieldWidgetW ("cw", square, 100, "c"); /*FU 6*/ mw [3] = XmCreateTextFieldWidgetW ("dw", square, 100, "d"); /*FU 7*/ invert = XmCreatePushButtonL ("invert", buttons, /*FU 8*/ XmStringCreateLocalized ("Invert matrix")); quit = XmCreatePushButtonL ("quit", buttons, /*FU 9*/ XmStringCreateLocalized ("Quit")); /*---------- 3. register callback functions ---------------------------*/ XtAddCallbackF (invert, XmCactivateCallback, button_pushed, (XtPointer)1); /*FU 10*/ <p> /* old and new matrix coefficients */ det; /* determinant */ String s; if ((int)client_data == 99) exit (0); /*FU 12*/ else if ((int)client_data == 1) int i; XtGetStringValue (mw [i], XmCvalue, &s); /*FU 13*/ mat [i] = atof (s); /*FU 14*/ -det = mat [0]*mat [3] - mat [1]*mat <ref> [2] </ref>; new [0] = mat [3]/det; new [1] = -mat [1]/det; for (i = 0; i &lt;= 3; i++) XtSetStringValue (mw [i], XmCvalue, ftoa (new [i],8,2)); /*FU 15*/ else matrixErrorMessage ("Matrix cannot be inverted",mat,8,2);/*FU 16*/ -B Solution for Problem B See the description in Appendix A above. #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt;
Reference: [3] <author> Kim Bruce. </author> <title> Typing in object-oriented languages: Achieving expressibility and safety. </title> <journal> ACM Computing Surveys?, </journal> .(.):., <note> 1998? to appear, see http://www.cs.williams.edu/~kim/. </note>
Reference-contexts: In fact, modern programming languages have evolved elaborate type systems and checking rules. In some languages, such as C, the type-checking rules were even strengthened in later versions. Furthermore, type theory is an active area of research <ref> [3] </ref>. However, it seems that the benefits of type checking are largely taken for granted or are based on personal anecdotes. For instance, Wirth states [21] that the type-checking facilities of Oberon had been most helpful in evolving the Oberon system. <p> = XmCreateRowColumnManagerOCP ("square", manager, XmHORIZONTAL, 2, True); /*FU 2*/ buttons = XmCreateRowColumnManagerOCP ("buttons", manager, XmHORIZONTAL, 1, False); /*FU 3*/ mw [0] = XmCreateTextFieldWidgetW ("aw", square, 100, "a"); /*FU 4*/ mw [1] = XmCreateTextFieldWidgetW ("bw", square, 100, "b"); /*FU 5*/ mw [2] = XmCreateTextFieldWidgetW ("cw", square, 100, "c"); /*FU 6*/ mw <ref> [3] </ref> = XmCreateTextFieldWidgetW ("dw", square, 100, "d"); /*FU 7*/ invert = XmCreatePushButtonL ("invert", buttons, /*FU 8*/ XmStringCreateLocalized ("Invert matrix")); quit = XmCreatePushButtonL ("quit", buttons, /*FU 9*/ XmStringCreateLocalized ("Quit")); /*---------- 3. register callback functions ---------------------------*/ XtAddCallbackF (invert, XmCactivateCallback, button_pushed, (XtPointer)1); /*FU 10*/ XtAddCallbackF (quit, XmCactivateCallback, button_pushed, (XtPointer)99); /*FU 11*/ /*---------- 4. realize <p> mat [4], new [4], /* old and new matrix coefficients */ det; /* determinant */ String s; if ((int)client_data == 99) exit (0); /*FU 12*/ else if ((int)client_data == 1) int i; XtGetStringValue (mw [i], XmCvalue, &s); /*FU 13*/ mat [i] = atof (s); /*FU 14*/ -det = mat [0]*mat <ref> [3] </ref> - mat [1]*mat [2]; new [0] = mat [3]/det; new [1] = -mat [1]/det; for (i = 0; i &lt;= 3; i++) XtSetStringValue (mw [i], XmCvalue, ftoa (new [i],8,2)); /*FU 15*/ else matrixErrorMessage ("Matrix cannot be inverted",mat,8,2);/*FU 16*/ -B Solution for Problem B See the description in Appendix A above.
Reference: [4] <author> Larry B. Christensen. </author> <title> Experimental Methodology. </title> <publisher> Allyn and Bacon, </publisher> <address> Needham Heights, MA, 6th edition, </address> <year> 1994. </year>
Reference-contexts: After this mortality, the A/B groups had 8+8 subjects and the B/A groups had 11+7 subjects. We consider this to be still sufficiently balanced <ref> [4] </ref>. <p> The numbers in the FU comments count the functional units as defined in Section 1. #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include "stdmotif.h" void button_pushed (Widget widget, XtPointer client_data, XtPointer call_data); Widget mw <ref> [4] </ref>; /* text fields for matrix coefficients: 0,1,2,3 for a,b,c,d */ /************************* MAIN PROGRAM **************************/ int main (argc, argv) int argc; char *argv []; Widget toplevel, /* main window */ manager, /* manager for square and buttons */ square, /* manager for 4 TextFields */ buttons, /* manager for 2 PushButtons <p> control to X event loop ------*/ /* (already complete, should not be changed) */ XtRealizeWidget (toplevel); XtAppMainLoop (app); return (0); 11 -/************************* Functions *************************/ void button_pushed (Widget widget, XtPointer client_data, XtPointer call_data) /* this is the callback function to be called when clicking on the PushButtons occurs */ double mat <ref> [4] </ref>, new [4], /* old and new matrix coefficients */ det; /* determinant */ String s; if ((int)client_data == 99) exit (0); /*FU 12*/ else if ((int)client_data == 1) int i; XtGetStringValue (mw [i], XmCvalue, &s); /*FU 13*/ mat [i] = atof (s); /*FU 14*/ -det = mat [0]*mat [3] - <p> X event loop ------*/ /* (already complete, should not be changed) */ XtRealizeWidget (toplevel); XtAppMainLoop (app); return (0); 11 -/************************* Functions *************************/ void button_pushed (Widget widget, XtPointer client_data, XtPointer call_data) /* this is the callback function to be called when clicking on the PushButtons occurs */ double mat <ref> [4] </ref>, new [4], /* old and new matrix coefficients */ det; /* determinant */ String s; if ((int)client_data == 99) exit (0); /*FU 12*/ else if ((int)client_data == 1) int i; XtGetStringValue (mw [i], XmCvalue, &s); /*FU 13*/ mat [i] = atof (s); /*FU 14*/ -det = mat [0]*mat [3] - mat [1]*mat
Reference: [5] <author> Curtis R. Cook, Jean C. Scholtz, and James C. Spohrer, </author> <title> editors. Empirical Studies of Programmers: </title> <booktitle> Fifth Workshop, </booktitle> <address> Palo Alto, CA, December 1993. </address> <publisher> Ablex Publishing Corp. </publisher>
Reference: [6] <author> Alireza Ebrahimi. </author> <title> Novice programmer errors: Language constructs and plan composition. </title> <journal> Intl. J. of Human-Computer Studies, </journal> <volume> 41 </volume> <pages> 457-480, </pages> <year> 1994. </year>
Reference-contexts: Hence the experiment does not tell us how useful type checking is. There is some research on error and defect classification, which has some bearing on our experiment. Several publications describe and analyze the typical defects in programs written by novices, e.g. <ref> [6, 18] </ref>. The results are not necessarily relevant for advanced programmers. Furthermore, type errors do not play an important role in these studies. Defect classification has also been performed in larger scale software development settings, e.g. [1, 10]. <p> Several studies have compared the productivity effects of different programming languages, but they either used programmers with little experience and very small programming tasks, e.g. <ref> [6] </ref>, or somewhat larger tasks and experienced programmers, but lacked proper experimental control, e.g. [11]. In addition, all such studies have the inherent problem that they confound too many factors to draw conclusions regarding type checking, even if some of the languages provide type checking and others do not.
Reference: [7] <author> Marc Eisenstadt. </author> <title> Tales of debugging from the front lines. </title> <booktitle> In [5], </booktitle> <pages> pages 86-112, </pages> <year> 1993. </year>
Reference-contexts: We conjecture that some fraction of these could have been found by type checking. The defect-detection capabilities of testing methods [2, 8, 22] have received some attention; the corresponding psychological problems were also investigated [20]. There is also a considerable literature about debugging, e.g. <ref> [7, 13, 16, 17] </ref>, and its psychology, e.g. [17, 19]. However, the defects found by testing or debugging are those that already passed the type checks.
Reference: [8] <author> Phyllis G. Frankl and Stewart N. Weiss. </author> <title> An exper imental comparison of the effectiveness of branch testing and data flow testing. </title> <journal> IEEE Trans. on Software Engineering, </journal> <year> 1993. </year>
Reference-contexts: For instance, Basili and Perricone [1] report that 39 percent of all defects in a 90.000 line FORTRAN project were interface defects. We conjecture that some fraction of these could have been found by type checking. The defect-detection capabilities of testing methods <ref> [2, 8, 22] </ref> have received some attention; the corresponding psychological problems were also investigated [20]. There is also a considerable literature about debugging, e.g. [7, 13, 16, 17], and its psychology, e.g. [17, 19]. However, the defects found by testing or debugging are those that already passed the type checks.
Reference: [9] <author> J.D. Gannon. </author> <title> An experimental evaluation of data type conventions. </title> <journal> Communications of the ACM, </journal> <year> 1977. </year>
Reference-contexts: Many programmers can recall instances when type checking did or could have helped them. However, we could find only a single report on a controlled, repeatable experiment testing the benefits of typing <ref> [9] </ref>. The cost-benefit ratio of type checking is far from clear, 1 because type checking is not free: It requires effort on behalf of the programmer in providing type information. Furthermore, there are good arguments why relying on compiler type checking may be counterproductive when doing inspections [12, pp. 263-268]. <p> It is obvious that this type of study has many flaws. But to our knowledge it was never repeated in a more controlled setting. A different approach was taken by the second experiment, performed by Gannon <ref> [9] </ref>. This experiment compares frequencies of errors in programs written in a statically typed and a "type-less" language. Each subject writes the same program twice, once in each language, but a different order of languages is used for each half of the experiment group.
Reference: [10] <author> Robert B. Grady. </author> <title> Practical results from measuring software quality. </title> <journal> Communications of the ACM, </journal> <volume> 36(11) </volume> <pages> 62-68, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: The results are not necessarily relevant for advanced programmers. Furthermore, type errors do not play an important role in these studies. Defect classification has also been performed in larger scale software development settings, e.g. <ref> [1, 10] </ref>. Type checking was not an explicit concern in these studies, but in some cases related information can be derived. For instance, Basili and Perricone [1] report that 39 percent of all defects in a 90.000 line FORTRAN project were interface defects.
Reference: [11] <author> Paul Hudak and Mark P. Jones. </author> <title> Haskell vs. Ada vs. C++ vs. awk vs. . . . an experiment in software prototyping productivity. </title> <type> Technical report, </type> <institution> Yale University, Dept. of CS, </institution> <address> New Haven, CT, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: Several studies have compared the productivity effects of different programming languages, but they either used programmers with little experience and very small programming tasks, e.g. [6], or somewhat larger tasks and experienced programmers, but lacked proper experimental control, e.g. <ref> [11] </ref>. In addition, all such studies have the inherent problem that they confound too many factors to draw conclusions regarding type checking, even if some of the languages provide type checking and others do not.
Reference: [12] <author> Watts Humphrey. </author> <title> A Discipline for Software Engi neering. SEI Series in Software Engineering. </title> <publisher> Ad-dison Wesley, </publisher> <address> Reading, MA, </address> <year> 1995. </year>
Reference-contexts: The cost-benefit ratio of type checking is far from clear, 1 because type checking is not free: It requires effort on behalf of the programmer in providing type information. Furthermore, there are good arguments why relying on compiler type checking may be counterproductive when doing inspections <ref> [12, pp. 263-268] </ref>. We conclude that the actual costs and benefits of type checking are largely unknown. <p> In particular, it would be interesting to compare productivity and error rates under compile-time type checking, run-time type checking, and type inference. Other important questions concern the influence of a disciplined programming process such as the Personal Software Process <ref> [12] </ref>. Finally, an analysis of the errors occurring in practice might help devise more effective defect-detection mechanisms.
Reference: [13] <author> Murthi Nanja and Curtis R. Cook. </author> <title> An analysis of the on-line debugging process. </title> <booktitle> In [14], </booktitle> <pages> pages 172-184, </pages> <year> 1987. </year>
Reference-contexts: We conjecture that some fraction of these could have been found by type checking. The defect-detection capabilities of testing methods [2, 8, 22] have received some attention; the corresponding psychological problems were also investigated [20]. There is also a considerable literature about debugging, e.g. <ref> [7, 13, 16, 17] </ref>, and its psychology, e.g. [17, 19]. However, the defects found by testing or debugging are those that already passed the type checks.
Reference: [14] <author> Gary M. Olson, Sylvia Sheppard, and Elliot Soloway, </author> <title> editors. Empirical Studies of Programmers: </title> <booktitle> Second Workshop, </booktitle> <address> Washington, D.C., De-cember 1987. </address> <publisher> Ablex Publishing Corp. </publisher>
Reference: [15] <author> Lutz Prechelt and Walter F. Tichy. </author> <title> A controlled experiment measuring the impact of procedure argument type checking on programmer productivity. </title> <type> Technical Report CMU/SEI-96-TR-014, </type> <institution> Software Engineering Institute, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: The following subsections describe the tasks, the subjects, the experiment setup, and the observed variables and discuss internal and external validity of the experiment. Detailed information can be found in a technical report <ref> [15] </ref>. 3.1 Tasks Problem A (2 fi 2 matrix inversion): Open a window with four text fields arranged in a 2 fi 2 pattern plus an "Invert" and a "Quit" button. See Figure 1. "Quit" exits the program and closes the window.
Reference: [16] <author> B.A. Sheil. </author> <title> The psychological study of program ming. </title> <journal> ACM Computing Surveys, </journal> <year> 1981. </year>
Reference-contexts: We conjecture that some fraction of these could have been found by type checking. The defect-detection capabilities of testing methods [2, 8, 22] have received some attention; the corresponding psychological problems were also investigated [20]. There is also a considerable literature about debugging, e.g. <ref> [7, 13, 16, 17] </ref>, and its psychology, e.g. [17, 19]. However, the defects found by testing or debugging are those that already passed the type checks. <p> Another issue is worth discussing here: The learning effect (performance change from first task to second task) is larger than the treatment effect (performance change from K&R C to Ansi C). This would be a problem if the learning reduced the treatment effect <ref> [16, pages 106 and 113] </ref>. However, as we will see below, in our case the treatment effect is actually increased by learning, making our experiment results conservative ones. We are explicitly considering programmers who are not highly familiar with the interface used.
Reference: [17] <author> Elliot Soloway and Sitharama Iyengar, </author> <title> editors. Empirical Studies of Programmers. </title> <publisher> Ablex Publishing Corp., </publisher> <address> Norwood, NJ, </address> <month> June </month> <year> 1986. </year> <booktitle> (The papers of the First Workshop on Empirical Studies of Programmers, </booktitle> <address> Washington D.C.). </address>
Reference-contexts: We conjecture that some fraction of these could have been found by type checking. The defect-detection capabilities of testing methods [2, 8, 22] have received some attention; the corresponding psychological problems were also investigated [20]. There is also a considerable literature about debugging, e.g. <ref> [7, 13, 16, 17] </ref>, and its psychology, e.g. [17, 19]. However, the defects found by testing or debugging are those that already passed the type checks. <p> The defect-detection capabilities of testing methods [2, 8, 22] have received some attention; the corresponding psychological problems were also investigated [20]. There is also a considerable literature about debugging, e.g. [7, 13, 16, 17], and its psychology, e.g. <ref> [17, 19] </ref>. However, the defects found by testing or debugging are those that already passed the type checks. So the results from these studies would be applicable here only if they focused on defects detectable by type checking | which they do not.
Reference: [18] <author> James G. Spohrer and Elliot Soloway. </author> <title> Analyzing the high frequency bugs in novice programs. </title> <booktitle> In [17], </booktitle> <pages> pages 230-251, </pages> <year> 1986. </year>
Reference-contexts: Hence the experiment does not tell us how useful type checking is. There is some research on error and defect classification, which has some bearing on our experiment. Several publications describe and analyze the typical defects in programs written by novices, e.g. <ref> [6, 18] </ref>. The results are not necessarily relevant for advanced programmers. Furthermore, type errors do not play an important role in these studies. Defect classification has also been performed in larger scale software development settings, e.g. [1, 10].
Reference: [19] <author> Webb Stacy and Jean MacMillian. </author> <title> Cognitive bias in software engineering. </title> <journal> Communications of the ACM, </journal> <volume> 38(6) </volume> <pages> 57-63, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: The defect-detection capabilities of testing methods [2, 8, 22] have received some attention; the corresponding psychological problems were also investigated [20]. There is also a considerable literature about debugging, e.g. [7, 13, 16, 17], and its psychology, e.g. <ref> [17, 19] </ref>. However, the defects found by testing or debugging are those that already passed the type checks. So the results from these studies would be applicable here only if they focused on defects detectable by type checking | which they do not.
Reference: [20] <author> Barbee Teasley, Laura Marie Leventhal, and Di ane S. Rohlman. </author> <title> Positive test bias in software testing by professionals: what's right and what's wrong. In Empirical Studies of Programmers: </title> <booktitle> Fifth Workshop, </booktitle> <pages> pages 206-221, </pages> <address> Palo Alto, CA, December 1993. </address> <publisher> Ablex Publishing Corp. </publisher>
Reference-contexts: We conjecture that some fraction of these could have been found by type checking. The defect-detection capabilities of testing methods [2, 8, 22] have received some attention; the corresponding psychological problems were also investigated <ref> [20] </ref>. There is also a considerable literature about debugging, e.g. [7, 13, 16, 17], and its psychology, e.g. [17, 19]. However, the defects found by testing or debugging are those that already passed the type checks.
Reference: [21] <author> Nikolaus Wirth. </author> <title> Gedanken zur Software Explosion. </title> <journal> Informatik Spektrum, </journal> <volume> 17(1) </volume> <pages> 5-20, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: In some languages, such as C, the type-checking rules were even strengthened in later versions. Furthermore, type theory is an active area of research [3]. However, it seems that the benefits of type checking are largely taken for granted or are based on personal anecdotes. For instance, Wirth states <ref> [21] </ref> that the type-checking facilities of Oberon had been most helpful in evolving the Oberon system. Many programmers can recall instances when type checking did or could have helped them. However, we could find only a single report on a controlled, repeatable experiment testing the benefits of typing [9].

References-found: 21

