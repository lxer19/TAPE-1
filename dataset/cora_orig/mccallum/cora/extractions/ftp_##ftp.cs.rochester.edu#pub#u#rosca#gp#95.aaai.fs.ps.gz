URL: ftp://ftp.cs.rochester.edu/pub/u/rosca/gp/95.aaai.fs.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/rosca/research.html
Root-URL: 
Email: rosca@cs.rochester.edu  
Title: Towards Automatic Discovery of Building Blocks in Genetic Programming  
Author: Justinian P. Rosca 
Address: Rochester NY 14627  
Affiliation: Computer Science Department University of Rochester  
Abstract: This paper presents an algorithm for the discovery of building blocks in genetic programming (GP) called adaptive representation through learning (ARL). The central idea of ARL is the adaptation of the problem representation, by extending the set of terminals and functions with a set of evolvable subroutines. The set of subroutines extracts common knowledge emerging during the evolutionary process and acquires the necessary structure for solving the problem. ARL supports subroutine creation and deletion. Subroutine creation or discovery is performed automatically based on the differential parent-offspring fitness and block activation. Subroutine deletion relies on a utility measure similar to schema fitness over a window of past generations. The technique described is tested on the problem of controlling an agent in a dynamic and non-deterministic environment. The automatic discovery of subroutines can help scale up the GP technique to complex problems. 
Abstract-found: 1
Intro-found: 1
Reference: [Altenberg, 1994] <author> Lee Altenberg, </author> <title> "The Evolution of Evolvability in Genetic Programming," </title> <editor> In Kim Kin-near, editor, </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Evaluation should be based on additional domain knowledge whenever such knowledge is available. However, domain-independent methods are more desirable for this goal. Unfortunately, simply considering the frequency of a block in an individual [Tackett, 1993], in the population [Rosca and Ballard, 1994c], the block's constructional fitness or schema fitness <ref> [Altenberg, 1994] </ref> is not sufficient. Constructional fitness takes into account the proliferation rate of the block within the population. However, such a measure has inherent drawbacks. First, constructional fitness is biased due to the extremely small population sizes considered [O'Reilly and Oppacher, 1994]. <p> Third, a block of code may rarely have a stationary distribution in its effects on the fitness of programs, a necessary condition to make constructional fitness useful <ref> [Altenberg, 1994] </ref>. Schema fitness, also called conditional expected fitness of a block [Tackett, 1995] is the average fitness of all the members of the population which contain the block. Tackett performs an off-line analysis of conditional fitness.
Reference: [Angeline, 1994a] <author> Peter J. Angeline, </author> <title> Evolutionary Algorithms and Emergent Intelligence, </title> <type> PhD thesis, </type> <institution> Computer Science Department, Ohio State University, </institution> <year> 1994. </year>
Reference-contexts: Each branch of a program is designated as having a distinct type. In this case the crossover operator can only swap subtrees from analogous branches. The second approach to modularization is called module acquisition ([Angeline, 1994b], <ref> [Angeline, 1994a] </ref>). A module is a function with a unique name defined by selecting and chopping off branches of a subtree selected randomly from an individual.
Reference: [Angeline, 1994b] <author> Peter J. Angeline, </author> <title> "Genetic Programming and Emergent Intelligence," </title> <editor> In Kim Kinn-ear, editor, </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: Modularization addresses the problems of inefficiency and scaling in GP. Modulariza-tion approaches consider the effect of encapsulating and eventually generalizing blocks of code. Three main approaches to modularization, discussed in the GP literature, are automatically defined functions (ADFs) [Koza, 1992], module acquisition (MA) <ref> [Angeline, 1994b] </ref> and adaptive representation (AR) [Rosca and Ballard, 1994a]. A first approach to modularization was the idea of encapsulation or function definition, introduced in [Koza, 1992].
Reference: [Goldberg, 1989] <author> David E. Goldberg, </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning, </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: 1 Introduction Holland hypothesized that genetic algorithms (GAs) achieve their search capabilities by means of "block" processing (see [Holland, 1975], <ref> [Goldberg, 1989] </ref>). Blocks are relevant pieces of a solution that can be assembled together, through crossover, in order to generate problem solutions. <p> Last but not least, it is more difficult to combine building blocks whose bit positions are interleaved, based on fixed crossover operators and the mutate operator. Solving these problems would enable solving bounded deceptive problems <ref> [Goldberg, 1989] </ref>, and, in general, the linkage problem defined above. To solve such problems, an mGA encodes objects as variable length strings with position independent genes. Each gene is tagged with an index representing its original position.
Reference: [Goldberg et al., 1993] <author> David E. Goldberg, Kalyanmoy Deb, and Bradley Korb, </author> <title> "Rapid, Accurate Optimization of Difficult Problems Using Fast Messy Genetic Algorithms," </title> <booktitle> In Proceedings of the Fifth International Conference on Genetic Algorithms. </booktitle> <publisher> Morgan Kaufmann Publishers, Inc, </publisher> <year> 1993. </year>
Reference: [Goldberg et al., 1989] <author> David E. Goldberg, Bradley Korb, and Kalyanmoy Deb, </author> <title> "Messy Genetic Algorithms: Motivation, Analysis, and First Results," </title> <journal> Complex Systems, </journal> <volume> 3 </volume> <pages> 493-530, </pages> <year> 1989. </year>
Reference-contexts: This topic is even more challenging for genetic programming (GP,) which involves semantic evaluation of the structures evolved. A more detailed perspective of GA block processing is offered by the Messy Genetic Algorithm (mGA) approach <ref> [Goldberg et al., 1989] </ref>, [Goldberg et al., 1990]. The mGA attempts to solve the linkage problem, a problem of representations in which features are not tightly coded together. The messy genetic algorithm explicitly attempts to discover useful blocks of code, being guided by the string structure of individuals.
Reference: [Goldberg et al., 1990] <author> David E. Goldberg, Bradley Korb, and Kalyanmoy Deb, </author> <title> "Messy Genetic Algorithms Revisited: Studies in Mixed Size and Scale," </title> <journal> Complex Systems, </journal> <volume> 4 </volume> <pages> 415-444, </pages> <year> 1990. </year>
Reference-contexts: This topic is even more challenging for genetic programming (GP,) which involves semantic evaluation of the structures evolved. A more detailed perspective of GA block processing is offered by the Messy Genetic Algorithm (mGA) approach [Goldberg et al., 1989], <ref> [Goldberg et al., 1990] </ref>. The mGA attempts to solve the linkage problem, a problem of representations in which features are not tightly coded together. The messy genetic algorithm explicitly attempts to discover useful blocks of code, being guided by the string structure of individuals.
Reference: [Holland, 1975] <author> John H. Holland, </author> <title> Adaptation in Natural and Artificial Systems, An Introductory Analysis with Applications to Biology, </title> <booktitle> Control and Artificial Intelligence, </booktitle> <institution> The University of Michigan, </institution> <address> 1st edition, </address> <year> 1975. </year>
Reference-contexts: 1 Introduction Holland hypothesized that genetic algorithms (GAs) achieve their search capabilities by means of "block" processing (see <ref> [Holland, 1975] </ref>, [Goldberg, 1989]). Blocks are relevant pieces of a solution that can be assembled together, through crossover, in order to generate problem solutions.
Reference: [Jones, 1995] <author> Terry Jones, </author> <title> "Crossover, Macromuta-tion and Population-Based Search," </title> <booktitle> Proceedings of the Sixth International Conference on Genetic Algorithms (ICGA95), </booktitle> <pages> pages 73-80, </pages> <year> 1995. </year>
Reference-contexts: However, recent GA experimental work disputes the usefulness of crossover as a means of communication of building blocks between the individuals of a population <ref> [Jones, 1995] </ref>. The class of problems and problem representations for which block processing is useful remains an open research topic. This topic is even more challenging for genetic programming (GP,) which involves semantic evaluation of the structures evolved.
Reference: [Koza, 1992] <author> John R. Koza, </author> <title> Genetic Programming: On the Programming of Computers by Means of Natural Selection, </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: The main goal was understanding if GP problems have building block structure and when GP is superior to other search techniques. Next, we overview this analysis. A GP schema was defined to be a collection of tree fragments <ref> [Koza, 1992] </ref>. This intuitive definition was generalized to a collection of trees possibly having subtrees removed [O'Reilly and Oppacher, 1994]. An individual instantiates a schema in case it "covers" (matches) all the fragments. Overlappings between fragments are not allowed. <p> In contrast, modularization approaches take a functional perspective. Modularization addresses the problems of inefficiency and scaling in GP. Modulariza-tion approaches consider the effect of encapsulating and eventually generalizing blocks of code. Three main approaches to modularization, discussed in the GP literature, are automatically defined functions (ADFs) <ref> [Koza, 1992] </ref>, module acquisition (MA) [Angeline, 1994b] and adaptive representation (AR) [Rosca and Ballard, 1994a]. A first approach to modularization was the idea of encapsulation or function definition, introduced in [Koza, 1992]. <p> Three main approaches to modularization, discussed in the GP literature, are automatically defined functions (ADFs) <ref> [Koza, 1992] </ref>, module acquisition (MA) [Angeline, 1994b] and adaptive representation (AR) [Rosca and Ballard, 1994a]. A first approach to modularization was the idea of encapsulation or function definition, introduced in [Koza, 1992]. The encapsulation operation, originally called "define building block" was viewed as a genetic operation that identifies a potential useful subtree and gives it a name so that it can be referenced and used later. Encapsulation is a particular form of function definition, with no arguments. <p> Encapsulation is a particular form of function definition, with no arguments. In general, a function or subroutine is a piece of code that performs common calculations parameterized by one or more arguments. <ref> [Koza, 1992] </ref> also introduced the idea of automatic function definition. In this approach each individual program has a dual structure. The structure is defined based on a fixed number of components or branches to be evolved: several function branches, also called automatically defined functions, and a main program branch. <p> The code of deleted subroutines is substituted in all places where the subroutine is invoked. 6 Experimental Results 6.1 Test Case We have tested the ARL algorithm on the problem of controlling an agent in a dynamic environment, similar to the Pac-Man problem described in <ref> [Koza, 1992] </ref>). The problem is to evolve a controller to drive the agent (Pac-Man) in a dynamic and non-deterministic world in order to acquire the maximum reward. A partial solution to the problem is a program involving decisions of what actions to take in every resulting world state. <p> Pac-Man is complex discrete-time, discrete-space problem. Koza describes a GP implementation to the Pac-Man problem, that involves a high enough problem representation so as to focus on a single game aspect, that of task prioritization <ref> [Koza, 1992] </ref>. Call this representation A. <p> The GP system uses point typing in the random generation of programs and in crossover operations under this new representation B (see Table 1). The goal was to evolve programs that express explicit conditions under which certain actions are prescribed, as opposed to the non-causal representation in <ref> [Koza, 1992] </ref> which creates programs that encode state information and rely on side-effects. The typed representation takes into account the signature of each primitive, i.e. the return type of each function as well as the types of its arguments. <p> We also compared ARL with standard GP using the problem representation from <ref> [Koza, 1992] </ref>. In all experiments the population size was 500 and the algorithm was run for 100 generations. The size of the set of subroutines was 10. Other GP parameters were chosen as in [Koza, 1994b].
Reference: [Koza, 1994a] <author> John R. Koza, </author> <title> "Architecture-Altering Operations for Evolving the Architecture of a MultiPart Program in Genetic Programming," </title> <institution> Computer Science Department STAN-CS-TR-94-1528, Stan-ford University, </institution> <year> 1994. </year>
Reference-contexts: The duplication operations are causal [Rosca and Ballard, 1995] and should have exploitative role, by increasing the potential for specialization or generalization of the behavior of programs, similarly to the creation and addition of ADF operations described in <ref> [Koza, 1994a] </ref>. The mutation operator will have an exploitative role and enable the evolution of the set of functions. It would determine the creation of new population individuals that would invoke the newly created functions. A more thorough comparison among solutions obtained using the GP, ADF and ARL algorithms is undergoing.
Reference: [Koza, 1994b] <editor> John R. Koza, </editor> <booktitle> Genetic Programming II, </booktitle> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: We also compared ARL with standard GP using the problem representation from [Koza, 1992]. In all experiments the population size was 500 and the algorithm was run for 100 generations. The size of the set of subroutines was 10. Other GP parameters were chosen as in <ref> [Koza, 1994b] </ref>. Table 2 shows a sample of results for the best solutions obtained using standard GP, ARL and by hand coding. The best-of-generation program evolved by ARL for run number 3 is extremely modular, relying on 6 useful subroutines. Only one of the subroutines is reused a second time.
Reference: [Montana, 1994] <author> David J. Montana, </author> <title> "Strongly Typed Genetic Programming," </title> <type> Technical Report 7866, </type> <institution> BBN, </institution> <year> 1994. </year>
Reference-contexts: Generalization replaces some random subset of terminals in the block with variables. Variables become formal arguments of the subroutine created. This operation makes sense in the case when the closure condition is satisfied by the sets of terminals and functions. In typed GP <ref> [Montana, 1994] </ref>, each terminal selected for generalization will have a certain type. The type is inherited by the variable introduced in the corresponding place. Thus, the type information of all the variables introduced and the type of the block root node will define the signature of the new subroutine.
Reference: [Nordin et al., 1995] <author> Peter Nordin, Frank Francone, and Wolfgang Banzhaf, </author> <title> "Explicitly defined introns and destructive crossover in genetic programming," </title> <type> Technical Report NRL2, </type> <institution> Univ. of Rochester, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: This condition is imposed in order to eliminate from consideration blocks containing introns (for a discussion of introns in GP see <ref> [Nordin et al., 1995] </ref>) and hitch-hiking phenomena [Tackett, 1995]. 5 Adapting Representation through Learning 5.1 ARL Strategy The central idea of the ARL algorithm is the dynamic adaptation in the problem representation.
Reference: [O'Reilly and Oppacher, 1994] <author> Una-May O'Reilly and Franz Oppacher, </author> <title> "The troubling aspects of a building block hypothesis for genetic programming," </title> <booktitle> In Proceedings of the Third Workshop on Foundations of Genetic Algorithms. </booktitle> <publisher> Morgan Kaufmann Publishers, Inc, </publisher> <year> 1994. </year>
Reference-contexts: The messy genetic algorithm explicitly attempts to discover useful blocks of code, being guided by the string structure of individuals. In contrast, we argue that GP should rely entirely on the function of blocks of code. A lesson is learned by contrasting the GP analogy to schemata theorem from <ref> [O'Reilly and Oppacher, 1994] </ref> and modularization approaches in GP. Modularization approaches disregard the structure of manipulated subtrees. Among them, the adaptive representation (AR) GP extension [Rosca and Ballard, 1994a] points out the importance of considering fit blocks of code. <p> It is natural to question whether structure information could provide hints in the analysis of building blocks in genetic programming. A GP analogy along the lines of GA schemata theory and GA building block hypothesis has been attempted in <ref> [O'Reilly and Oppacher, 1994] </ref>. The main goal was understanding if GP problems have building block structure and when GP is superior to other search techniques. Next, we overview this analysis. A GP schema was defined to be a collection of tree fragments [Koza, 1992]. <p> Next, we overview this analysis. A GP schema was defined to be a collection of tree fragments [Koza, 1992]. This intuitive definition was generalized to a collection of trees possibly having subtrees removed <ref> [O'Reilly and Oppacher, 1994] </ref>. An individual instantiates a schema in case it "covers" (matches) all the fragments. Overlappings between fragments are not allowed. The probability of tree disruption by crossover was estimated based on this latter definition. A couple of problems specific to GP had to be overcome. <p> Second, the notion of schema order or specificity changes. Specificity is a relative measure, as the size of GP individuals is variable. A characterization of schema processing was difficult in the structural approach offered by the GP schema definition. <ref> [O'Reilly and Oppacher, 1994] </ref> conclude that schema processing, as defined, does not offer an appropriate perspective for analyzing GP. A structural approach is also at the basis of "constructional problems" [Tackett, 1995], i.e. problems in which the evolved trees are not semantically evaluated. <p> By ignoring the semantic evaluation step, the analysis of constructional problems is not generalizable to GP in general. 3.2 Functional Approach A GP structural theory analogous to GA schemata theory, as attempted in <ref> [O'Reilly and Oppacher, 1994] </ref> side-stepped the functional role of the GP representation. In contrast, modularization approaches take a functional perspective. Modularization addresses the problems of inefficiency and scaling in GP. Modulariza-tion approaches consider the effect of encapsulating and eventually generalizing blocks of code. <p> Constructional fitness takes into account the proliferation rate of the block within the population. However, such a measure has inherent drawbacks. First, constructional fitness is biased due to the extremely small population sizes considered <ref> [O'Reilly and Oppacher, 1994] </ref>. Second, it is computationally expensive to keep track of all possible blocks of code and block frequency can be misleading [Rosca and Ballard, 1994a].
Reference: [Rosca, 1995] <editor> Justinian P. Rosca, </editor> <booktitle> "Entropy-Driven Adaptive Representation," In Proceedings of the Workshop: Genetic Programming: From Theory to Real World Application, the Twelfth International Conference on Machine Learning, </booktitle> <pages> pages 23-32. </pages> <institution> Univ. of Rochester, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: It's simplified code is: (if (= (sense-direct-mon-1) (sense-direct-pill)) (act-r-mon-1) (act-a-pill)) Figures 4 and 5 compare the evolutionary process for GP (solution 1) and ARL (solution 3). ARL maintains a high diversity (measured as entropy, see <ref> [Rosca, 1995] </ref>) due to the discovery and use of new subroutines and is able to discover better solutions much faster. GP solutions have poor generalization capability but this may not be surprising taking into account that the environment is non-deterministic.
Reference: [Rosca and Ballard, 1994a] <author> Justinian P. Rosca and Dana H. Ballard, </author> <title> "Genetic Programming with Adaptive Representations," </title> <type> Technical Report 489, </type> <institution> University of Rochester, Computer Science Department, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: A lesson is learned by contrasting the GP analogy to schemata theorem from [O'Reilly and Oppacher, 1994] and modularization approaches in GP. Modularization approaches disregard the structure of manipulated subtrees. Among them, the adaptive representation (AR) GP extension <ref> [Rosca and Ballard, 1994a] </ref> points out the importance of considering fit blocks of code. <p> Modularization addresses the problems of inefficiency and scaling in GP. Modulariza-tion approaches consider the effect of encapsulating and eventually generalizing blocks of code. Three main approaches to modularization, discussed in the GP literature, are automatically defined functions (ADFs) [Koza, 1992], module acquisition (MA) [Angeline, 1994b] and adaptive representation (AR) <ref> [Rosca and Ballard, 1994a] </ref>. A first approach to modularization was the idea of encapsulation or function definition, introduced in [Koza, 1992]. <p> Two effects are achieved. First the expressiveness of the base language is increased. Second modules become frozen portions of genetic material, which are not subject to genetic operations unless they are subsequently decompressed. The third approach is called Adaptive Representation (AR) <ref> [Rosca and Ballard, 1994a] </ref>. The basic idea is to automatically extract common knowledge in the form of subroutines that extend the problem representation. AR explicitly attempts to discover new good functions or subroutines, based on heuristic criteria in the form of domain knowledge. <p> Extend the representation with the new subroutines. The generation intervals with no function set changes represent evolutionary epochs. At the beginning of each new epoch, part of the population is extinguished and replaced with random individuals built using the extended function set <ref> [Rosca and Ballard, 1994a] </ref>. The extinction step was introduced in order to make use of the newly discovered subroutines. Evaluation should be based on additional domain knowledge whenever such knowledge is available. However, domain-independent methods are more desirable for this goal. <p> However, such a measure has inherent drawbacks. First, constructional fitness is biased due to the extremely small population sizes considered [O'Reilly and Oppacher, 1994]. Second, it is computationally expensive to keep track of all possible blocks of code and block frequency can be misleading <ref> [Rosca and Ballard, 1994a] </ref>. Third, a block of code may rarely have a stationary distribution in its effects on the fitness of programs, a necessary condition to make constructional fitness useful [Altenberg, 1994]. <p> Only new blocks created through crossover are examined. All new blocks can be discovered in O (M ) time, where M is the population size, by marking the program-tree paths actually affected by GP crossover and by examining only those paths while searching for new blocks <ref> [Rosca and Ballard, 1994a] </ref>. Nodes with the highest activation value are considered as candidates. In addition, we require that all nodes of the subtree be activated at least once or a minimum percentage of the total number of activations of the root node.
Reference: [Rosca and Ballard, 1994b] <author> Justinian P. Rosca and Dana H. Ballard, </author> <title> "Hierarchical Self-Organization in Genetic Programming," </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> pages 251-258. </pages> <publisher> Morgan Kaufmann Publishers, Inc, </publisher> <year> 1994. </year>
Reference: [Rosca and Ballard, 1995] <author> Justinian P. Rosca and Dana H. Ballard, </author> <title> "Causality in Genetic Programming," </title> <booktitle> Proceedings of the Sixth International Conference on Genetic Algorithms (ICGA95), </booktitle> <year> 1995. </year>
Reference-contexts: ADF samples the space of subroutines by modifying automatically defined functions at randomly chosen crossover points. This may not be a good strategy due to the the non-causality problem of ADF <ref> [Rosca and Ballard, 1995] </ref>. The causality perspective analyzes how natural or smooth perturbations of solutions can be generated through crossover and are advantageous. <p> ADF counteracts the non-causality effect at some waste in computational effort by employing a bottom-up stabilization of subroutines. Also, the implicit biases of GP search (regarding expected height of crossover points, position of subtrees involved in crossover, effective code and structure exploitation in GP) alleviate the problem <ref> [Rosca and Ballard, 1995] </ref>. Early in the process changes are focused towards the evolution of more primitive functions. Later in the process the changes are focused towards the evolution of program control structures, i.e. at higher levels in the hierarchy. <p> They also compete for existence in the function set. The population of subroutines evolves slowlier than the population of programs. We plan to experiment with duplication and mutation operations on the population of subroutines. The duplication operations are causal <ref> [Rosca and Ballard, 1995] </ref> and should have exploitative role, by increasing the potential for specialization or generalization of the behavior of programs, similarly to the creation and addition of ADF operations described in [Koza, 1994a].
Reference: [Rosca and Ballard, 1994c] <author> Justinian P. Rosca and Dana H. Ballard, </author> <title> "Learning by Adapting Representations in Genetic Programming," </title> <booktitle> In Proceedings of the IEEE World Congress on Computational Intelligence, </booktitle> <pages> pages 407-412. </pages> <publisher> IEEE Press, </publisher> <address> Orlando, </address> <year> 1994. </year>
Reference-contexts: Evaluation should be based on additional domain knowledge whenever such knowledge is available. However, domain-independent methods are more desirable for this goal. Unfortunately, simply considering the frequency of a block in an individual [Tackett, 1993], in the population <ref> [Rosca and Ballard, 1994c] </ref>, the block's constructional fitness or schema fitness [Altenberg, 1994] is not sufficient. Constructional fitness takes into account the proliferation rate of the block within the population. However, such a measure has inherent drawbacks.
Reference: [Tackett, 1993] <author> Walter Alden Tackett, </author> <title> "Genetic Programming for Feature Discovery and Image Discrimination," </title> <booktitle> In Proceedings of the Fifth International Conference on Genetic Algorithms. </booktitle> <publisher> Morgan Kauf-mann Publishers, Inc, </publisher> <year> 1993. </year>
Reference-contexts: The extinction step was introduced in order to make use of the newly discovered subroutines. Evaluation should be based on additional domain knowledge whenever such knowledge is available. However, domain-independent methods are more desirable for this goal. Unfortunately, simply considering the frequency of a block in an individual <ref> [Tackett, 1993] </ref>, in the population [Rosca and Ballard, 1994c], the block's constructional fitness or schema fitness [Altenberg, 1994] is not sufficient. Constructional fitness takes into account the proliferation rate of the block within the population. However, such a measure has inherent drawbacks.
Reference: [Tackett, 1995] <author> Walter Alden Tackett, </author> <title> "Mining the Genetic Program," </title> <journal> IEEE Expert Magazine, </journal> <month> June </month> <year> 1995. </year>
Reference-contexts: A characterization of schema processing was difficult in the structural approach offered by the GP schema definition. [O'Reilly and Oppacher, 1994] conclude that schema processing, as defined, does not offer an appropriate perspective for analyzing GP. A structural approach is also at the basis of "constructional problems" <ref> [Tackett, 1995] </ref>, i.e. problems in which the evolved trees are not semantically evaluated. Instead, tree fitness is based on the decomposi tion into target expressions, similar to the generalized GP schema, to which are assigned fitness values. <p> Third, a block of code may rarely have a stationary distribution in its effects on the fitness of programs, a necessary condition to make constructional fitness useful [Altenberg, 1994]. Schema fitness, also called conditional expected fitness of a block <ref> [Tackett, 1995] </ref> is the average fitness of all the members of the population which contain the block. Tackett performs an off-line analysis of conditional fitness. <p> Salient blocks are active blocks of code that prove to be useful. The method requires that each node have an associated counter recording its number of executions but does not necessitate additional effort in an interpreted GP system. In contrast to <ref> [Tackett, 1995] </ref>, salient blocks have to be detected efficiently, on-line. Consequently, candidate blocks are only searched for among the blocks of small height (between 3 and 5 in the current implementation) present in the population. This is done by using a record of the dynamics of the population. <p> This condition is imposed in order to eliminate from consideration blocks containing introns (for a discussion of introns in GP see [Nordin et al., 1995]) and hitch-hiking phenomena <ref> [Tackett, 1995] </ref>. 5 Adapting Representation through Learning 5.1 ARL Strategy The central idea of the ARL algorithm is the dynamic adaptation in the problem representation.
References-found: 22

