URL: ftp://ftp.cis.upenn.edu/pub/msingh/uai93.ps.Z
Refering-URL: http://www.cis.upenn.edu/~msingh/frames/papers_list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: &lt; msingh@usceast.cs.scarolina.edu &gt;  &lt; mgv@usceast.cs.scarolina.edu &gt;  
Title: An Algorithm for the Construction of Bayesian Network Structures from Data  
Author: Moninder Singh Marco Valtorta 
Address: SC 29208  SC 29208  
Affiliation: Computer Science Department University of South Carolina Columbia,  Computer Science Department University of South Carolina Columbia,  
Note: Proceedings of the 9th Conference on Uncertainty in Artificial Intelligence 259-265, 1993: Morgan Kaufmann.  
Abstract: Previous algorithms for the construction of Bayesian belief network structures from data have been either highly dependent on conditional independence (CI) tests, or have required an ordering on the nodes to be supplied by the user. We present an algorithm that integrates these two approaches - CI tests are used to generate an ordering on the nodes from the database which is then used to recover the underlying Bayesian network structure using a non CI based method. Results of preliminary evaluation of the algorithm on two networks (ALARM and LED) are presented. We also discuss some algo rithm performance issues and open problems.
Abstract-found: 1
Intro-found: 1
Reference: [Beinlich et. al., 89] <author> Beinlich, I.A., Suermondt, H.J., Chavez, R.M. and Cooper, </author> <title> G.F. "The ALARM monitoring system: A Case Study with Two Probabilistic Inference Techniques for Belief Networks", </title> <booktitle> Proceedings of the Second European Conference on Artificial Intelligence in Medicine, </booktitle> <pages> 247-256, </pages> <address> 1989, London, England. </address> <note> (as referenced in [Cooper & Herskovits, 92]). </note>
Reference-contexts: Output old i 8i; 1 i n Output Old P rob 4 PRELIMINARY RESULTS We used an implementation of the algorithm on a DEC Station 5000 to reconstruct the ALARM network (Figure 1) <ref> [Beinlich et. al., 89] </ref> by using 10,000 cases of a database generated by Herskovits ( [Herskovits, 91], [Cooper & Herskovits, 92] ).
Reference: [Cooper & Herskovits, 92] <author> Cooper, G.F. and Her-skovits, E. </author> <title> "A Bayesian Method for the Induction of Probabilistic Networks from Data", </title> <journal> Machine Learning, </journal> <volume> 9, </volume> <pages> 309-347, </pages> <address> 1992, </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: However, there are two major drawbacks of such CI test based algorithms. Firstly, the CI test requires determining independence relations of order n 2, in the worst case. "Such tests may be unreliable, unless the volume of data is enormous" <ref> [Cooper & Herskovits, 92, page 332] </ref>. Also, as Verma and Pearl [Verma & Pearl, 92, pages 326-327] have noted, "in general, the set of all independence statements which hold for a given domain will grow exponentially as the number of variables grow". <p> vertices increases. [Spirtes & Glymour, 91, page 62] have presented "an asymptotically correct algorithm whose complexity for fixed graph connectivity increases polynomially in the number of vertices, and may in practice recover sparse graphs with several hundred variables"; but for dense graphs with limited data, the algorithm might be unreliable <ref> [Cooper & Herskovits, 92] </ref>. On the other hand, [Cooper & Herskovits, 92] have given a Bayesian non-CI test based method, which they call the BLN (Bayesian learning of belief networks) method. <p> have presented "an asymptotically correct algorithm whose complexity for fixed graph connectivity increases polynomially in the number of vertices, and may in practice recover sparse graphs with several hundred variables"; but for dense graphs with limited data, the algorithm might be unreliable <ref> [Cooper & Herskovits, 92] </ref>. On the other hand, [Cooper & Herskovits, 92] have given a Bayesian non-CI test based method, which they call the BLN (Bayesian learning of belief networks) method. <p> Cases occur independently, given a belief network model, (iii) All variables are instantiated to some value in every case, and finally (iv) Before observing the database, we are indifferent regarding the numerical probabilities to place on the belief network structure, Cooper and Herskovits have shown the following result: Theorem 1. <ref> [Cooper & Herskovits, 92] </ref>. Let Z be a set of n discrete variables, where variable x i in Z has r i possible value assignments: (v i1 ; : : : ; v ir i ). <p> However, since the number of possible structures grow exponentially as a function of the number of variables, it is computation-ally infeasible to find the most probable belief network structure, given the data, by exhaustively enumerating all possible belief network structures. Herskovits and Cooper ( <ref> [Cooper & Herskovits, 92] </ref>, [Herskovits, 91] ) proposed a greedy algorithm, called the K2 algorithm, to maximize P (B S ; D) by finding the parent set of each variable that maximizes the function g (i; i ). <p> Output old i 8i; 1 i n Output Old P rob 4 PRELIMINARY RESULTS We used an implementation of the algorithm on a DEC Station 5000 to reconstruct the ALARM network (Figure 1) [Beinlich et. al., 89] by using 10,000 cases of a database generated by Herskovits ( [Herskovits, 91], <ref> [Cooper & Herskovits, 92] </ref> ). We used the 2 test for the CI tests with a fixed ff level of 0.1, and a bound of 15 on the maximum degree of the undirected graph generated in step 2. <p> Due to the bound, it did not generate a network for CI relations of order 0. Out of 46 edges, it recovered 45 edges (Figure 2). The only missing edge was the edge 12 ! 32 (an edge which is not strongly supported by the data <ref> [Cooper & Herskovits, 92] </ref>). Two of the edges recovered were incorrectly oriented. However, the algorithm also recovered 14 extra edges. This is probably due to the incorrectly oriented edges, and to some extent, due to the greedy nature of K2. <p> The remaining extra edge was between nodes 15 and 34 which is recovered, once again, due to the greedy nature of K2. The total time taken was under 13 minutes. <ref> [Cooper & Herskovits, 92] </ref> reported that K2, when given a total ordering consistent with the partial order of the nodes as specified by ALARM, recovered the complete network with the exception of one missing edge (between nodes 12 and 32) and one extra arc (from node 15 to 34). [Spirtes, 93] <p> Each of steps 3 through 9 have only polynomial complexity in the number of variables, by arguments that are either simple or described in [Verma & Pearl, 92], <ref> [Cooper & Herskovits, 92] </ref>. In step 2, the number of independence tests carried out is exponential in the size of the order of the independence relations to be tested, which is bounded by the maximum of jA G abj.
Reference: [Fung & Crawford, 90] <author> Fung, R.M. and Crawford, </author> <title> S.L. "Constructor: A System for the Induction of Probabilistic Models", </title> <booktitle> Proceedings of AAAI, </booktitle> <pages> 762-769, </pages> <address> 1990, Boston, MA: </address> <publisher> MIT Press </publisher>
Reference-contexts: However, the metric used by K2 ranked the earlier network structure (Figure 2) to be more probable. The time taken was reduced to under 7 minutes. We also used the algorithm to reconstruct the faulty LED network (Figure 4) using a database of 199 cases ( <ref> [Fung & Crawford, 90] </ref> ). With an ff value of 0.1, CB reconstructed the network (Figure 5) with 3 edges incorrectly oriented and one extra edge in less than 1 second using CI tests up to order 1. <p> Secondly, we have used a fixed ff level for the 2 test. This will almost certainly introduce dependencies that are purely the result of chance. It is possible to use the technique of Cross Validation for tuning this parameter. <ref> [Fung & Crawford, 90] </ref> discusses the tuning of the alpha level in performing belief-network learning. Thirdly, the CB algorithm uses a greedy search mechanism (K2) to search for the set of parents of each node.
Reference: [Geiger and Heckerman, 91] <author> Geiger, Dan and Heck-erman, David. </author> <booktitle> "Advances in Probabilistic Reasoning." Uncertainty in Artificial Intelligence: Proceedings of the Seventh Conference, </booktitle> <address> San Mateo, CA: </address> <publisher> Mor-gan Kaufmann, </publisher> <pages> 118-126, </pages> <year> 1991. </year>
Reference: [Glymour, et al., 1987] <author> Glymour, C., Scheines, R., Spirtes, P., and Kelly, K. </author> <title> "Discovering Causal Structure". </title> <address> San Diego, CA: </address> <publisher> Academic Press, </publisher> <year> 1987. </year>
Reference: [Herskovits, 91] <author> Herskovits, E., H. </author> <title> "Computer-based probabilistic-network construction", </title> <type> Doctoral dissertation, </type> <institution> Medical Information Sciences, Stanford University, Stanford, </institution> <address> CA </address>
Reference-contexts: However, since the number of possible structures grow exponentially as a function of the number of variables, it is computation-ally infeasible to find the most probable belief network structure, given the data, by exhaustively enumerating all possible belief network structures. Herskovits and Cooper ( [Cooper & Herskovits, 92], <ref> [Herskovits, 91] </ref> ) proposed a greedy algorithm, called the K2 algorithm, to maximize P (B S ; D) by finding the parent set of each variable that maximizes the function g (i; i ). <p> In a domain where very little expertise is available, or the number of vertices is fairly large, finding such an ordering may not be feasible. As such, we would like to avoid such a requirement. The remainder of this section elaborates on this point. 1 Herskovits <ref> [Herskovits, 91] </ref> suggested the use of the metric (on which K2 is based) with a CI test based method to do away with the requirement for an order of nodes. <p> Output old i 8i; 1 i n Output Old P rob 4 PRELIMINARY RESULTS We used an implementation of the algorithm on a DEC Station 5000 to reconstruct the ALARM network (Figure 1) [Beinlich et. al., 89] by using 10,000 cases of a database generated by Herskovits ( <ref> [Herskovits, 91] </ref>, [Cooper & Herskovits, 92] ). We used the 2 test for the CI tests with a fixed ff level of 0.1, and a bound of 15 on the maximum degree of the undirected graph generated in step 2.
Reference: [Lauritzen and Wermuth, 89a] <author> Lauritzen, S.L. and N. Wermuth. </author> <title> "Graphical Models for Associations Between Variables, Some of Which Are Qualitative and Some Quantitative", </title> <journal> Annals of Statistics, </journal> <volume> 17, </volume> <pages> 31-57, </pages> <year> 1989. </year>
Reference: [Lauritzen and Wermuth, 89b] <author> Lauritzen, S.L. and N. Wermuth. </author> <title> "Graphical Models for Associations Between Variables, Some of Which Are Qualitative and Some Quantitative: Correction Note", </title> <journal> Annals of Statistics, </journal> <volume> 17, </volume> <year> 1916, 1989. </year>
Reference: [Lauritzen, Thiesson, & Spiegelhalter, 93] <author> Lauritzen S.L., B. Thiesson, and D. Spiegelhalter. </author> <title> "Diagnostic Systems Created by Model Selection Methods-A Case Study", </title> <booktitle> Preliminary Papers of the Fourth International Workshop on Artificial Intelligence and Statistics, </booktitle> <address> Ft. Lauderdale, FL, </address> <month> January 3-6, </month> <pages> 93-105, </pages> <year> 1993. </year>
Reference: [Mechling & Valtorta, 93] <author> Mechling, R. and Valtorta, M., "PaCCIN: </author> <title> A Parallel Constructor of Markov Networks", </title> <booktitle> Preliminary Papers of the Fourth International Workshop on Artificial Intelligence and Statistics, </booktitle> <address> Ft. Lauderdale, FL, </address> <month> January 3-6, </month> <pages> 405-410, </pages> <year> 1993. </year>
Reference-contexts: We are currently testing the CB algorithm on a number of databases that we have procured from the University of California (Irvine), Repository of Machine Learning databases. We also intend to test the algorithm on a large 147 variable medical database (cf. <ref> [Mechling & Valtorta, 93] </ref>), and see whether the recovered network is found plausible by medical experts. Secondly, we have used a fixed ff level for the 2 test. This will almost certainly introduce dependencies that are purely the result of chance.
Reference: [Pearl, 88] <author> Pearl, Judea. </author> <title> "Probabilistic Reasoning in Intelligent Systems", 1988, </title> <publisher> Morgan Kaufman, </publisher> <address> San Ma-teo. </address>
Reference-contexts: We ignore Markov nets <ref> [Pearl, 88, chapter 3] </ref>, chain graphs [Lauritzen and Wermuth, 1989a; 1989b], and other graphical representations (e.g., [Shachter, 1991; Geiger and Heckerman, 1991]). 4 The name reflects the initials of the two phases of the algorithm.
Reference: [Pearl & Verma, 91] <author> Pearl, Judea and Verma, Thomas. </author> <title> "A Theory of Inferred Causation", </title> <editor> In Allen, J.A., Fikes, R., and Sandwell, E., editors, </editor> <booktitle> Principles of Knowledge Representation and Reasoning: Proceedings of the Second International Conference, </booktitle> <pages> 441-452, </pages> <address> 1991, </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo. </address>
Reference-contexts: Some of these methods are based on linearity and normality assumptions ([Gly-mour et. al., 87], [Pearl & Wermuth, 93]); others are more general but require extensive testing of independence relations ([Fung & Crawford, 90], [Verma & Pearl, 92], [Spirtes & Glymour, 91], <ref> [Pearl & Verma, 91] </ref>, [Spirtes, Glymour & Scheines, 90]); others yet take a Bayesian approach ([Herskovits, 91], [Cooper & Her-skovits, 92], [Lauritzen, Thiesson & Spiegelhalter, 93]). In this paper, we do not consider methods of the first kind, namely, those that make linearity and normality assumptions.
Reference: [Pearl & Wermuth, 93] <author> Pearl, Judea and Nanny Wer-muth. </author> <title> "When Can Association Graphs Admit a Causal Interpretation? (First Report)" Preliminary Papers of the Fourth International Workshop on Artificial Intelligence and Statistics, </title> <address> Ft. Lauderdale, FL, </address> <month> January 3-6, </month> <pages> 141-150, </pages> <year> 1993. </year>
Reference-contexts: 1 INTRODUCTION In very general terms, different methods of learning probabilistic network structures from data can be classified into three groups. Some of these methods are based on linearity and normality assumptions ([Gly-mour et. al., 87], <ref> [Pearl & Wermuth, 93] </ref>); others are more general but require extensive testing of independence relations ([Fung & Crawford, 90], [Verma & Pearl, 92], [Spirtes & Glymour, 91], [Pearl & Verma, 91], [Spirtes, Glymour & Scheines, 90]); others yet take a Bayesian approach ([Herskovits, 91], [Cooper & Her-skovits, 92], [Lauritzen, Thiesson &
Reference: [Shachter, 91] <author> Shachter, Ross D. </author> <title> "A Graph-Based Inference Method for Conditional Independence", </title> <booktitle> Uncertainty in Artificial Intelligence: Proceedings of the Seventh Conference, </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kauf-mann, </publisher> <pages> 353-360, </pages> <year> 1991. </year>
Reference: [Spirtes, 93] <institution> Personal communication. </institution>
Reference-contexts: minutes. [Cooper & Herskovits, 92] reported that K2, when given a total ordering consistent with the partial order of the nodes as specified by ALARM, recovered the complete network with the exception of one missing edge (between nodes 12 and 32) and one extra arc (from node 15 to 34). <ref> [Spirtes, 93] </ref> reported similar results with the PC algorithm. They applied the PC algorithm [Spirtes & Glymour, 91] to the ALARM database split into two parts of 10000 cases each. The algorithm did not make any linearity assumption.
Reference: [Spirtes, Glymour & Scheines, 90] <author> Spirtes, P., Gly-mour, C., and Scheines, R. </author> <title> "Causality from probability", </title> <editor> In Tiles, J., McKee, G. and Dean, G., editors, </editor> <booktitle> Evolving knowledge in the natural and behavioral sciences, </booktitle> <pages> 181-199, </pages> <year> 1990, </year> <month> London:Pitman. </month>
Reference-contexts: Some of these methods are based on linearity and normality assumptions ([Gly-mour et. al., 87], [Pearl & Wermuth, 93]); others are more general but require extensive testing of independence relations ([Fung & Crawford, 90], [Verma & Pearl, 92], [Spirtes & Glymour, 91], [Pearl & Verma, 91], <ref> [Spirtes, Glymour & Scheines, 90] </ref>); others yet take a Bayesian approach ([Herskovits, 91], [Cooper & Her-skovits, 92], [Lauritzen, Thiesson & Spiegelhalter, 93]). In this paper, we do not consider methods of the first kind, namely, those that make linearity and normality assumptions.
Reference: [Spirtes & Glymour, 91] <author> Spirtes, Peter and Glymour, Clark. </author> <title> "An Algorithm for Fast Recovery of Sparse Causal Graphs", </title> <journal> Social Science Computing Review, </journal> <volume> 9:1, </volume> <pages> 62-72, </pages> <year> 1991. </year>
Reference-contexts: Some of these methods are based on linearity and normality assumptions ([Gly-mour et. al., 87], [Pearl & Wermuth, 93]); others are more general but require extensive testing of independence relations ([Fung & Crawford, 90], [Verma & Pearl, 92], <ref> [Spirtes & Glymour, 91] </ref>, [Pearl & Verma, 91], [Spirtes, Glymour & Scheines, 90]); others yet take a Bayesian approach ([Herskovits, 91], [Cooper & Her-skovits, 92], [Lauritzen, Thiesson & Spiegelhalter, 93]). In this paper, we do not consider methods of the first kind, namely, those that make linearity and normality assumptions. <p> As such, CI test based approaches become rapidly computationally infeasible as the number of vertices increases. <ref> [Spirtes & Glymour, 91, page 62] </ref> have presented "an asymptotically correct algorithm whose complexity for fixed graph connectivity increases polynomially in the number of vertices, and may in practice recover sparse graphs with several hundred variables"; but for dense graphs with limited data, the algorithm might be unreliable [Cooper & Herskovits, <p> The two phases are executed iteratively first for 0th order CI relations, then for 1st order CI relations, and so on until the termination criteria is met. Steps 1 to 4 of the algorithm are based on the algorithms given by ([Verma & Pearl, 92] and <ref> [Spirtes & Glymour, 91] </ref>). We have allowed edges to be oriented in both directions because at any given stage, since CI tests of all orders have not been performed, all CI relations have not been discovered and there will be a number of extra edges. <p> Let i be the set of parents of node i; 1 i n. 1. Start with the complete graph G 1 on the set of vertices Z. ord 0. 0. 2. <ref> [Spirtes & Glymour, 91] </ref> Modify G 1 as follows : For each pair of vertices a; b that are adjacent in G 1 , if A G 1 ab has a cardinality greater than or equal to ord, and I (a; S ab ; b) 5 where S ab A G <p> For each pair of non adjacent variables a; b in G, if there is a node c that is not in S ab and is adjacent to both a and b, then orient the edges from a ! c and b ! c ([Verma & Pearl, 92], <ref> [Spirtes & Glymour, 91] </ref>) unless such an orientation leads to the introduction of a directed cycle in the graph. If an edge has already been oriented in the reverse direction, make that edge bidirected. 4. <p> They applied the PC algorithm <ref> [Spirtes & Glymour, 91] </ref> to the ALARM database split into two parts of 10000 cases each. The algorithm did not make any linearity assumption. <p> The number of times that steps 2 through 9 of the CB algorithm are executed is bound by the sum of the largest two degrees in the undirected graph constructed at the end of step 2, by an argument almost identical to that of <ref> [Spirtes & Glymour, 91, page 68] </ref>. Each of steps 3 through 9 have only polynomial complexity in the number of variables, by arguments that are either simple or described in [Verma & Pearl, 92], [Cooper & Herskovits, 92].
Reference: [Verma & Pearl, 92] <author> Verma, Thomas and Pearl, Judea. </author> <title> "An Algorithm for Deciding if a Set of Observed Independencies Has a Causal Explanation", </title> <booktitle> Proceedings 8th Conference on Uncertainty in AI, </booktitle> <pages> 323-330, </pages> <year> 1992. </year>
Reference-contexts: Some of these methods are based on linearity and normality assumptions ([Gly-mour et. al., 87], [Pearl & Wermuth, 93]); others are more general but require extensive testing of independence relations ([Fung & Crawford, 90], <ref> [Verma & Pearl, 92] </ref>, [Spirtes & Glymour, 91], [Pearl & Verma, 91], [Spirtes, Glymour & Scheines, 90]); others yet take a Bayesian approach ([Herskovits, 91], [Cooper & Her-skovits, 92], [Lauritzen, Thiesson & Spiegelhalter, 93]). <p> Firstly, the CI test requires determining independence relations of order n 2, in the worst case. "Such tests may be unreliable, unless the volume of data is enormous" [Cooper & Herskovits, 92, page 332]. Also, as Verma and Pearl <ref> [Verma & Pearl, 92, pages 326-327] </ref> have noted, "in general, the set of all independence statements which hold for a given domain will grow exponentially as the number of variables grow". <p> If an edge has already been oriented in the reverse direction, make that edge bidirected. 4. Try to assign directions to the yet undirected edges in G by applying the following four rules <ref> [Verma & Pearl, 92] </ref>, if this can be done without introducing directed cycles in the graph: Rule 1: If a ! b and b c and a and c are not adjacent, then direct b ! c. <p> Each of steps 3 through 9 have only polynomial complexity in the number of variables, by arguments that are either simple or described in <ref> [Verma & Pearl, 92] </ref>, [Cooper & Herskovits, 92]. In step 2, the number of independence tests carried out is exponential in the size of the order of the independence relations to be tested, which is bounded by the maximum of jA G abj.
References-found: 18

