URL: http://www.cs.uni-bonn.de/II/staff/strelen/97freibe.ps.gz
Refering-URL: http://www.cs.uni-bonn.de/II/staff/strelen/SelectedPapers.htm
Root-URL: http://cs.uni-bonn.de
Title: Approximate Analysis of Queueing Networks with Markovian Arrival Processes and Phase Type Service Times  
Author: Johann Christoph Strelen Rheinische Friedrich-Wilhelms-Universitat Bonn 
Abstract: Open queueing networks with Markovian arrival processes and phase type service times are considered. A technique is proposed for the specification of the models. Using such a specification, a Markov chain can be generated automatically. Furthermore, this description can be used immediately for simulation. An approximate disaggregation-aggregation technique for finite state Markov chains is applied. Thus large models with many states can be solved, so large that the state probabilities could neither be stored nor calculated in any computer. Accurate approximations are obtained with different degrees of accuracy, depending on the investigated computational effort. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. O. Allen. </author> <title> Probability, Statistics and Queueing Theory. </title> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: Here we did not use the third degree of freedom: The third moment can also be taken into account <ref> [1, page 151] </ref>. Now we consider bursty arrivals using a hyperexponential distribution. <p> Each aggregate Z c;j defines a macro probability or aggregate probability PfZ 2 Z c;j g: r c (j) = z2Z c;j We collect the aggregate probabilities of a partition Z c into tuples r c and, in turn, these into R 4 By (2), the aggregation function A : <ref> [0; 1] </ref> n ! [0; 1] jN 1 j fi : : : fi [0; 1] jN C j ; p 7! R; is defined. It calculates the macro probabilities for given state probabilities. <p> defines a macro probability or aggregate probability PfZ 2 Z c;j g: r c (j) = z2Z c;j We collect the aggregate probabilities of a partition Z c into tuples r c and, in turn, these into R 4 By (2), the aggregation function A : <ref> [0; 1] </ref> n ! [0; 1] jN 1 j fi : : : fi [0; 1] jN C j ; p 7! R; is defined. It calculates the macro probabilities for given state probabilities. <p> c;j g: r c (j) = z2Z c;j We collect the aggregate probabilities of a partition Z c into tuples r c and, in turn, these into R 4 By (2), the aggregation function A : <ref> [0; 1] </ref> n ! [0; 1] jN 1 j fi : : : fi [0; 1] jN C j ; p 7! R; is defined. It calculates the macro probabilities for given state probabilities. The states of the system components are described by the random variables Z k : Z T ! S k ; z 7! z k . <p> In fact, the MED is completely determined by all MED parameters ae c;j ; ae for short. By (7) and (2), the disaggregation function is defined: D : <ref> [0; 1] </ref> jN 1 j fi : : : fi [0; 1] jN C j ! [0; 1] n ; R 7! : It calculates the MED over the state space for given aggregate probabilities. <p> In fact, the MED is completely determined by all MED parameters ae c;j ; ae for short. By (7) and (2), the disaggregation function is defined: D : <ref> [0; 1] </ref> jN 1 j fi : : : fi [0; 1] jN C j ! [0; 1] n ; R 7! : It calculates the MED over the state space for given aggregate probabilities. <p> In fact, the MED is completely determined by all MED parameters ae c;j ; ae for short. By (7) and (2), the disaggregation function is defined: D : <ref> [0; 1] </ref> jN 1 j fi : : : fi [0; 1] jN C j ! [0; 1] n ; R 7! : It calculates the MED over the state space for given aggregate probabilities. Instead of calculating the steady state probabilities q of a Markov chain we determine an approximation p = D (R) where R = T (R) holds. <p> Instead of calculating the steady state probabilities q of a Markov chain we determine an approximation p = D (R) where R = T (R) holds. Here the function T is defined as follows: T : <ref> [0; 1] </ref> jN 1 j fi : : : fi [0; 1] jN C j ! R 7! A D (R)P : This approximation p and its marginal probabilities R are referred to as steady state disaggregation-aggregation product-form (DA) solution. <p> Instead of calculating the steady state probabilities q of a Markov chain we determine an approximation p = D (R) where R = T (R) holds. Here the function T is defined as follows: T : <ref> [0; 1] </ref> jN 1 j fi : : : fi [0; 1] jN C j ! R 7! A D (R)P : This approximation p and its marginal probabilities R are referred to as steady state disaggregation-aggregation product-form (DA) solution. In fact, only the marginal probabilities R and the MED parameters ae and G must be calculated.
Reference: [2] <author> W. J. Stewart (ed.). </author> <title> Numerical Solution of Markov Chains. </title> <publisher> Marcel Dekker, </publisher> <address> New York, Basel, Hong Kong, </address> <year> 1991. </year>
Reference-contexts: The measures are calculated from the state probabilities of the Markov chain. Unfortunately, the number of states grows quickly as the complexity of the model increases. This is why much research was done about the solution of large Markov chains <ref> [2, 13, 3] </ref>. But the state space is subject to a combinatorial explosion law. Therefore exact methods will never suffice for all models, approximation techniques are needed. We propose the disaggregation-aggregation (DA) iteration [15].
Reference: [3] <author> W. J. Stewart (ed.). </author> <title> Computation with Markov Chains. </title> <publisher> Kluwer, </publisher> <year> 1995. </year>
Reference-contexts: The measures are calculated from the state probabilities of the Markov chain. Unfortunately, the number of states grows quickly as the complexity of the model increases. This is why much research was done about the solution of large Markov chains <ref> [2, 13, 3] </ref>. But the state space is subject to a combinatorial explosion law. Therefore exact methods will never suffice for all models, approximation techniques are needed. We propose the disaggregation-aggregation (DA) iteration [15].
Reference: [4] <author> E.Gelenbe and R.R.Muntz. </author> <title> Probabilistic models of computer systems. </title> <journal> Acta Infor-matica, </journal> <pages> pages 35-60, </pages> <year> 1976. </year>
Reference-contexts: But this example shows two interesting aspects: It is not surprising that the error diminishes if the number of arrival processes grows. In conformity with the theorem of Palm-Khinchine, see for example <ref> [4] </ref>, the overall arrival stream converges to a Poisson process, and for such an arrival process the DA method is here exact. Because of the symmetry of the model, the corresponding aggregate probabilities of all partitions are equal.
Reference: [5] <author> E. Gelenbe and I. Mitrani. </author> <title> Analysis and Synthesis of Computer Systems. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: Typically the first and second moments of the distributions are taken into account, and it is assumed that the arrivals to each node are renewal processes. Kuhn [10] proposed a decomposition method with these assumptions. Gelenbe and Mitrani <ref> [5] </ref> applied diffusion approximation for the analysis of the G/G/1 nodes. Whitt uses approximations of Marshall [11] and of Kramer and Langenbach-Belz [9] which are not always accurate [14]. Haverkort [6, 7] replaces these approximations and applies matrix-geometric and Markovian techniques instead, and he considers finite buffers.
Reference: [6] <author> B.R. Haverkort. </author> <title> Approximate analysis of networks of PH/PH/1/K queues: Theory & tool support. </title> <editor> In H. Beilner and F. Bause, editors, </editor> <booktitle> Quantitative Evaluation of Computing and Communication Systems, </booktitle> <pages> pages 239-253. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1995. </year>
Reference-contexts: Kuhn [10] proposed a decomposition method with these assumptions. Gelenbe and Mitrani [5] applied diffusion approximation for the analysis of the G/G/1 nodes. Whitt uses approximations of Marshall [11] and of Kramer and Langenbach-Belz [9] which are not always accurate [14]. Haverkort <ref> [6, 7] </ref> replaces these approximations and applies matrix-geometric and Markovian techniques instead, and he considers finite buffers. In this paper we consider steady state solutions.
Reference: [7] <author> B.R. Haverkort. </author> <title> Approximate analysis of networks of PH/PH/1/K queues: Test results. </title> <note> Accepted for publication in Annals of Operations Research, </note> <year> 1997. </year>
Reference-contexts: Kuhn [10] proposed a decomposition method with these assumptions. Gelenbe and Mitrani [5] applied diffusion approximation for the analysis of the G/G/1 nodes. Whitt uses approximations of Marshall [11] and of Kramer and Langenbach-Belz [9] which are not always accurate [14]. Haverkort <ref> [6, 7] </ref> replaces these approximations and applies matrix-geometric and Markovian techniques instead, and he considers finite buffers. In this paper we consider steady state solutions. <p> Also other authors who developed fixed point techniques observed that proofs of existence of a solution, of the uniqueness, and of convergence are difficult to state, as well as bounds for the accuracy, for example Haverkort <ref> [7] </ref>. But in [15] the existence of DA solutions is proven, and it is proven that there is always an aggregation with only a small number of aggregates for which an approximating product form (7) exists which is as accurate as desired.
Reference: [8] <author> A. M. Kagan, J. V. Linnik, and C. R. Rao. </author> <title> Characterization Problems in Mathematical Statistics. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: First, the distribution satisfies the macro probabilities, R = A (); and secondly, maximizes the entropy. According to the product-form theorem, see <ref> [8, theorem 13.2.1, page 409] </ref>, this maximum entropy distribution (MED) is uniquely determined and has a product form, (z) = ae 1;z 1 : : : ae C;z C =G; (7) where the ae c;z c &gt; 0 are some real numbers, and G is a normalizing constant.
Reference: [9] <author> W. Kramer and M. Langenbach-Belz. </author> <title> Approximate formulae for the delay in the queueing system GI/G/1. </title> <booktitle> In Proceedings ITC-8, </booktitle> <pages> pages 235 1-8, </pages> <address> Melbourne, </address> <year> 1976. </year>
Reference-contexts: Kuhn [10] proposed a decomposition method with these assumptions. Gelenbe and Mitrani [5] applied diffusion approximation for the analysis of the G/G/1 nodes. Whitt uses approximations of Marshall [11] and of Kramer and Langenbach-Belz <ref> [9] </ref> which are not always accurate [14]. Haverkort [6, 7] replaces these approximations and applies matrix-geometric and Markovian techniques instead, and he considers finite buffers. In this paper we consider steady state solutions.
Reference: [10] <author> P.J. Kuhn. </author> <title> Approximate analysis of general queueing networks by decomposition. </title> <journal> IEEE Trans. Comm., </journal> <pages> pages 113-126, </pages> <year> 1979. </year>
Reference-contexts: Typically the first and second moments of the distributions are taken into account, and it is assumed that the arrivals to each node are renewal processes. Kuhn <ref> [10] </ref> proposed a decomposition method with these assumptions. Gelenbe and Mitrani [5] applied diffusion approximation for the analysis of the G/G/1 nodes. Whitt uses approximations of Marshall [11] and of Kramer and Langenbach-Belz [9] which are not always accurate [14].
Reference: [11] <author> K.T. Marshall. </author> <title> Some inequalities in queueing. </title> <journal> Operations Research, </journal> <volume> 16(3), </volume> <year> 1968. </year>
Reference-contexts: Kuhn [10] proposed a decomposition method with these assumptions. Gelenbe and Mitrani [5] applied diffusion approximation for the analysis of the G/G/1 nodes. Whitt uses approximations of Marshall <ref> [11] </ref> and of Kramer and Langenbach-Belz [9] which are not always accurate [14]. Haverkort [6, 7] replaces these approximations and applies matrix-geometric and Markovian techniques instead, and he considers finite buffers. In this paper we consider steady state solutions.
Reference: [12] <author> M. F. Neuts. </author> <title> Structured Stochastic Matrices of M/G/1-Type and their Applications. </title> <publisher> Marcel Dekker, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Queueing networks with repetitive service blocking are discussed more thoroughly in [16]. Here we use transition classes and the DA technique for approximate solutions of queueing networks with phase type (PH) service time distributions and Markovian arrival processes (MAP) according to Neuts <ref> [12] </ref>. The latter comprises phase type interarrival time distributions, single or multiple arrival processes at a node, and single or batch arrivals. Some research was done about approximate solutions for open queueing networks with general interarrival time distributions and service time distributions, and with infinite buffers. <p> According to <ref> [12, page 231] </ref> a probability distribution F () on [0; 1) is of phase type if it is the distribution of the time until absorption in a finite-state Markov chain with a single absorbing state, that is, there exists a probability vector (fi; fi ) and a generator matrix " o
Reference: [13] <author> W. J. Stewart. </author> <title> Introduction to the numerical solution of Markov chains. </title> <publisher> Priceton University Press, </publisher> <year> 1994. </year>
Reference-contexts: The measures are calculated from the state probabilities of the Markov chain. Unfortunately, the number of states grows quickly as the complexity of the model increases. This is why much research was done about the solution of large Markov chains <ref> [2, 13, 3] </ref>. But the state space is subject to a combinatorial explosion law. Therefore exact methods will never suffice for all models, approximation techniques are needed. We propose the disaggregation-aggregation (DA) iteration [15].
Reference: [14] <author> J. Ch. Strelen. </author> <title> Piecewise approximation of densities applying the principle of maximum entropy: Waiting times in G/G/1-systems. </title> <editor> In R. Puigjaner and D. Poitier, editors, </editor> <booktitle> Modelling Techniques and Tools for Computer Performance Evaluation, </booktitle> <pages> pages 421-438. </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Kuhn [10] proposed a decomposition method with these assumptions. Gelenbe and Mitrani [5] applied diffusion approximation for the analysis of the G/G/1 nodes. Whitt uses approximations of Marshall [11] and of Kramer and Langenbach-Belz [9] which are not always accurate <ref> [14] </ref>. Haverkort [6, 7] replaces these approximations and applies matrix-geometric and Markovian techniques instead, and he considers finite buffers. In this paper we consider steady state solutions.
Reference: [15] <author> J. Ch. Strelen. </author> <title> Approximate product form solutions for Markov chains. </title> <booktitle> Performance Evaluation, </booktitle> <pages> pages 87-110, </pages> <year> 1997. </year>
Reference-contexts: This is why much research was done about the solution of large Markov chains [2, 13, 3]. But the state space is subject to a combinatorial explosion law. Therefore exact methods will never suffice for all models, approximation techniques are needed. We propose the disaggregation-aggregation (DA) iteration <ref> [15] </ref>. This is a general approximate technique for finite state Markov chains with discrete time which is based on aggregation. The calculated state probabilities are in product form; we call them disaggregation-aggregation product-form (DA) solutions. Here, neither the complete state space, nor all Correspondence to: J. Ch. <p> We call aggregations with many aggregates fine. It is interesting to note that the steady state probabilities of separable queueing networks are equal to DA solutions calculated according to suitably chosen aggregates. Here our DA method is exact. In <ref> [15] </ref> we propose also a description technique which we call transition classes. It is defined in the terms system components, component states, state transitions, transition probabilities. This technique helps to structure the design of the Markov models. In this paper, the paradigm of transition classes is developed further. <p> j fl a , and the component k of the destination state function is u ;k (z) = z k 0 + a if z k 0 + a k 0 ; k 0 otherwise: 4 Disaggregation-Aggregation Iteration In this section we survey the DA method, details are given in <ref> [15] </ref>. Our proposed solution technique needs disaggregation: Given positive macro probabilities R, a distribution over Z T is defined as follows where is a n-vector with the probabilities (z); z 2 Z T . First, the distribution satisfies the macro probabilities, R = A (); and secondly, maximizes the entropy. <p> Also other authors who developed fixed point techniques observed that proofs of existence of a solution, of the uniqueness, and of convergence are difficult to state, as well as bounds for the accuracy, for example Haverkort [7]. But in <ref> [15] </ref> the existence of DA solutions is proven, and it is proven that there is always an aggregation with only a small number of aggregates for which an approximating product form (7) exists which is as accurate as desired. <p> Moreover, the accuracy could be substantially ameliorated in all examples if more and suitably chosen aggregates are considered. These matters are discussed in <ref> [15] </ref>. 5 Numerical Examples Here we consider the steady state probabilities of the component states. Other performance measures are calculated from them. Therefore their accuracy is of particular interest.
Reference: [16] <author> J. Ch. Strelen, B. Bark, J. Becker, and V. Jonas. </author> <title> Analysis of queueing networks with blocking using a new aggregation technique. </title> <note> Accepted for publication in Annals of Operations Research, </note> <year> 1997. </year>
Reference-contexts: This technique helps to structure the design of the Markov models. In this paper, the paradigm of transition classes is developed further. Some restrictions are introduced which render possible to perform DA iteration automatically for a class of coarse and fine aggregations. Previously, for example in <ref> [16] </ref>, the development of the algorithms for DA iteration was a tedious task which had to be repeated for each aggregation. We use solutions of Markov chains to verify the accuracy of DA approximations. <p> In [17] transition classes and the DA technique are applied to queueing networks with different service disciplines like priorities and polling, Coxian service and interarrival time distributions, blocking, or fork and join. Queueing networks with repetitive service blocking are discussed more thoroughly in <ref> [16] </ref>. Here we use transition classes and the DA technique for approximate solutions of queueing networks with phase type (PH) service time distributions and Markovian arrival processes (MAP) according to Neuts [12].
Reference: [17] <author> J.Ch. Strelen. </author> <title> Approximate disaggregation-aggregation solutions for general queueing networks. </title> <editor> In A.R. Kaylan and A. Lehmann, editors, </editor> <booktitle> Proc. of the ESM 97 Conference, </booktitle> <pages> pages 773-778. </pages> <institution> Society for Computer Simulation, </institution> <year> 1997. </year>
Reference-contexts: We use solutions of Markov chains to verify the accuracy of DA approximations. The state spaces of these Markov chains and the transition probabilities are generated automatically from the transition classes. Moreover, simulation results are obtained using a simple general algorithm which acts directly upon the transition classes. In <ref> [17] </ref> transition classes and the DA technique are applied to queueing networks with different service disciplines like priorities and polling, Coxian service and interarrival time distributions, blocking, or fork and join. Queueing networks with repetitive service blocking are discussed more thoroughly in [16].
References-found: 17

