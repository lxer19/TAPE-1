URL: http://www.cs.indiana.edu/l/www/ftp/hanson/iucs-tr479.ps.gz
Refering-URL: http://www.cs.indiana.edu/l/www/ftp/hanson/
Root-URL: http://www.cs.indiana.edu
Title: Navigation with 2D Controllers  
Author: Andrew J. Hanson Eric Wernert 
Keyword: CR Categories: I.3.6 [Computer Graphics]: Methodology and Techniques|Interaction Techniques. I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism. I.3.8 [Computer Graphics]: Applications. Keywords: Navigation; Constrained Navigation; Viewing Control; Camera Control  
Address: Bloomington, IN 47405 USA  
Affiliation: Computer Science Department Indiana University  
Note: Constrained 3D  
Abstract: Hanson and Wernert | IUCS Technical Report 479 | March 1997 Abstract Navigation through 3D spaces is required in many interactive graphics and virtual reality applications. We consider the subclass of situations in which a 2D device such as a mouse controls smooth movements among viewpoints for a "through the screen" display of a 3D world. Frequently, there is a poor match between the goal of such a navigation activity, the control device, and the skills of the average user. We propose a unified mathematical framework for incorporating context-dependent constraints into the generalized viewpoint generation problem. These designer-supplied constraint modes provide a middle ground between the triviality of a single camera animation path and the confusing excess freedom of common unconstrained control paradigms. We demonstrate the approach with a varied spectrum of examples including terrain models, interior architectural spaces, and complex molecules. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Barr, B. Currin, S. Gabriel, and J. Hughes. </author> <title> Smooth interpolation of orientations with angular velocity constraints using quaternions. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 313-320, </pages> <year> 1992. </year> <note> Proceedings of SIGGRAPH '92. </note>
Reference-contexts: and refined in subsequent work such as that of Schlag [18], Nielson [14], and Kim, et al. [12]; 2D rectangular extensions of these methods are straightforward. (Note: One might use more complex interpolation methods such as a 2D minimal-surface version of the quaternion minimal path solutions of Barr, et al. <ref> [1] </ref>, but these would likely be too time consuming for most real-time applications.) Other variables such as the focal length and controller response field can be interpolated similarly in tandem. 4 Hanson and Wernert | IUCS Technical Report 479 | March 1997 3.3 Methods for Determining the Camera Model Field We
Reference: [2] <author> M. Billinghurst and J. Savage. </author> <title> Adding intelligence to the interface. </title> <booktitle> In Proceedings of VRAIS '96, </booktitle> <pages> pages 168-175, </pages> <year> 1996. </year>
Reference-contexts: The use of constraints in view selection specifically for virtual reality has been used, for example, by Robinett and Holloway [17] to go beyond the usual "flying" modality, and by Billinghurst and Savage <ref> [2] </ref> in an expert system context. <p> vertex values and the geodesic interpolation methods of Hanson and Ma [9]; these range from methods based on metric relations between the navigation surface and the nearby scene or terrain, to methods that could be based on arbitrary rules in the manner of Karp and Feiner, or Billinghurst and Savage <ref> [10, 11, 2] </ref>. While we focus here on 2D mouse-based interfaces, the framework clearly extends to immersive virtual reality environments, where the virtual space of the control device can select points and orientations in a 3D volume, instead of simple 2D mouse coordinates. <p> Context-based rules. A variety of approaches have been proposed in the literature to use context-based knowledge, expert system domain rules, and artificial intelligence planning methods to determine transitions among camera positions in animation or even complete animation paths (see, e.g., <ref> [10, 11, 2] </ref>).
Reference: [3] <author> James F. </author> <title> Blinn. A generalization of algebraic surfaces. </title> <journal> ACM Trans. on Graphics, </journal> <volume> 1 </volume> <pages> 235-256, </pages> <year> 1982. </year>
Reference-contexts: These can in turn be used in many ways to modulate the user's attention. See section 2 for a detailed example. Modifications based on designer-supplied interest field. Another flexible method is related to the level-set method for implicit surfaces (see, e.g., Blinn <ref> [3] </ref>).
Reference: [4] <author> F.P. Brooks. </author> <title> Walkthrough | a dynamic graphics system for simulating virtual buildings. </title> <booktitle> In Computer Graphics, </booktitle> <pages> pages 9-21, </pages> <year> 1987. </year> <booktitle> Proceedings of 1986 Workshop on Interactive 3D Graphics. </booktitle>
Reference-contexts: Examples of such viewing control methods run the gamut from orientation control paradigms (Brooks <ref> [4] </ref>, Nielson and Olson [15], Chen et al. [5], Hanson [8], and Shoemake [21, 22]) to methods that intelligently focus on particular scene points such as Mackinlay et al. [13], constraint-based camera placement systems such as Phillips et al. [16], and general control systems such as those discussed by Ware and
Reference: [5] <author> Michael Chen, S. Joy Mountford, and Abigail Sellen. </author> <title> A study in interactive 3-d rotation using 2-d control devices. </title> <journal> In Computer Graphics, </journal> <volume> volume 22, </volume> <pages> pages 121-130, </pages> <year> 1988. </year> <note> Proceedings of SIGGRAPH 1988. </note>
Reference-contexts: Examples of such viewing control methods run the gamut from orientation control paradigms (Brooks [4], Nielson and Olson [15], Chen et al. <ref> [5] </ref>, Hanson [8], and Shoemake [21, 22]) to methods that intelligently focus on particular scene points such as Mackinlay et al. [13], constraint-based camera placement systems such as Phillips et al. [16], and general control systems such as those discussed by Ware and Osborne [27] and Drucker et al. [6]. <p> Viewer state procedures and rules. The user state in a navigation problem contains a number of variables that can be tracked and computed, particularly those involving velocity and heading history (see, e.g., some of the techniques reviewed in Chen et al. <ref> [5] </ref>). Arcade games often exploit such information, particularly to add challenge to a control strategy by preventing direct manipulation of the object to be controlled. In physical simulations, momentum, friction, and air resistance play a crucial role in making driving and flight simulators realistic.
Reference: [6] <author> Steven M. Drucker, Tinsley A. Galyean, and David Zeltzer. Cinema: </author> <title> A system for procedural camera movements. </title> <booktitle> In Computer Graphics, </booktitle> <pages> pages 67-70, </pages> <year> 1992. </year> <booktitle> Proceedings of 1992 Symposium on Interactive 3D Graphics. </booktitle>
Reference-contexts: al. [5], Hanson [8], and Shoemake [21, 22]) to methods that intelligently focus on particular scene points such as Mackinlay et al. [13], constraint-based camera placement systems such as Phillips et al. [16], and general control systems such as those discussed by Ware and Osborne [27] and Drucker et al. <ref> [6] </ref>. The use of constraints in view selection specifically for virtual reality has been used, for example, by Robinett and Holloway [17] to go beyond the usual "flying" modality, and by Billinghurst and Savage [2] in an expert system context.
Reference: [7] <author> T. Eguchi, P.B. Gilkey, and A.J. Hanson. Gravitation, </author> <title> gauge theories and differential geometry. </title> <journal> Physics Reports, </journal> <volume> 66(6) </volume> <pages> 213-393, </pages> <month> December </month> <year> 1980. </year>
Reference-contexts: Therefore, we retain all the scene-viewing parameters in a single data structure, and treat its space as a type of fiber bundle (see <ref> [7, 23] </ref>) for which we choose a projection and a section. All that means for us is that, whichever guide field variables we choose to map the controller to, we need a consistent projection operator to make that the "base space" in the sense of fiber bundle theory.
Reference: [8] <author> A. J. Hanson. </author> <title> The rolling ball. </title> <editor> In David Kirk, editor, </editor> <booktitle> Graphics Gems III, </booktitle> <pages> pages 51-60. </pages> <publisher> Academic Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: Examples of such viewing control methods run the gamut from orientation control paradigms (Brooks [4], Nielson and Olson [15], Chen et al. [5], Hanson <ref> [8] </ref>, and Shoemake [21, 22]) to methods that intelligently focus on particular scene points such as Mackinlay et al. [13], constraint-based camera placement systems such as Phillips et al. [16], and general control systems such as those discussed by Ware and Osborne [27] and Drucker et al. [6].
Reference: [9] <author> A. J. Hanson and H. Ma. </author> <title> Space walking. </title> <booktitle> In Proceedings of Visualization '95, </booktitle> <pages> pages 126-133. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1995. </year>
Reference-contexts: A related example of such a system was introduced for the exploration of complex mathematical manifolds in Han-son and Ma <ref> [9] </ref>. <p> Below, we propose several additional families of dynamic procedures for determining the current camera parameters in addition to fixed key vertex values and the geodesic interpolation methods of Hanson and Ma <ref> [9] </ref>; these range from methods based on metric relations between the navigation surface and the nearby scene or terrain, to methods that could be based on arbitrary rules in the manner of Karp and Feiner, or Billinghurst and Savage [10, 11, 2]. <p> These can be joined as in Figure 2b to form a patchwork of polygons that can be navigated in the manner of Hanson and Ma <ref> [9] </ref>. More complex surfaces (e.g, multiple coverings, multi-branched soap-bubbles) may be used in a similar fashion for particular applications. <p> Note that a separate interest field can in principle be supplied for each parameter, allowing, e.g., the camera focal length, to be varied independently in complex ways throughout the navigation. Space-walk frames and constrained "up" fields. The basic manifold traversal method of Hanson and Ma <ref> [9] </ref> can be used with 2D constraint manifolds of arbitrary complexity, and is extensible to 3D as well. Effective use of the method requires data stored in a winged-edge format rather than the simpler 2D parametric rectangular grid format that we have implicitly assumed for most of the discussion.
Reference: [10] <author> P. Karp and S. Feiner. </author> <title> Issues in the automated generation of animated presentations. </title> <booktitle> In Graphics Interface 1990, </booktitle> <pages> pages 39-48, </pages> <year> 1990. </year>
Reference-contexts: Computer animation, for example, requires the choice of a time sequence of camera models that can be considered as a one-parameter constraint; applicable techniques range from direct orientation interpolation (e.g., [19, 12]) to rule-based systems <ref> [10, 11] </ref>. The more complex task of interactive navigation has been considered in a wide variety of contexts, ranging from the viewing of simple 3D scenes on a desktop monitor to the control of fully immer-sive virtual reality environments. <p> vertex values and the geodesic interpolation methods of Hanson and Ma [9]; these range from methods based on metric relations between the navigation surface and the nearby scene or terrain, to methods that could be based on arbitrary rules in the manner of Karp and Feiner, or Billinghurst and Savage <ref> [10, 11, 2] </ref>. While we focus here on 2D mouse-based interfaces, the framework clearly extends to immersive virtual reality environments, where the virtual space of the control device can select points and orientations in a 3D volume, instead of simple 2D mouse coordinates. <p> Context-based rules. A variety of approaches have been proposed in the literature to use context-based knowledge, expert system domain rules, and artificial intelligence planning methods to determine transitions among camera positions in animation or even complete animation paths (see, e.g., <ref> [10, 11, 2] </ref>).
Reference: [11] <author> P. Karp and S. Feiner. </author> <title> Automated presentation planning of animation using task decomposition with heuristic reasoning. </title> <booktitle> In Graphics Interface 1993, </booktitle> <pages> pages 118-127, </pages> <year> 1993. </year>
Reference-contexts: Computer animation, for example, requires the choice of a time sequence of camera models that can be considered as a one-parameter constraint; applicable techniques range from direct orientation interpolation (e.g., [19, 12]) to rule-based systems <ref> [10, 11] </ref>. The more complex task of interactive navigation has been considered in a wide variety of contexts, ranging from the viewing of simple 3D scenes on a desktop monitor to the control of fully immer-sive virtual reality environments. <p> vertex values and the geodesic interpolation methods of Hanson and Ma [9]; these range from methods based on metric relations between the navigation surface and the nearby scene or terrain, to methods that could be based on arbitrary rules in the manner of Karp and Feiner, or Billinghurst and Savage <ref> [10, 11, 2] </ref>. While we focus here on 2D mouse-based interfaces, the framework clearly extends to immersive virtual reality environments, where the virtual space of the control device can select points and orientations in a 3D volume, instead of simple 2D mouse coordinates. <p> Context-based rules. A variety of approaches have been proposed in the literature to use context-based knowledge, expert system domain rules, and artificial intelligence planning methods to determine transitions among camera positions in animation or even complete animation paths (see, e.g., <ref> [10, 11, 2] </ref>).
Reference: [12] <author> Myoung-Jun Kim, Myung-Soo Kim, and Sung Yong Shin. </author> <title> A general construction scheme for unit quaternion curves with simple high order derivatives. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series, </booktitle> <pages> pages 369-376, </pages> <year> 1995. </year> <note> Proceedings of SIGGRAPH '95. </note>
Reference-contexts: Computer animation, for example, requires the choice of a time sequence of camera models that can be considered as a one-parameter constraint; applicable techniques range from direct orientation interpolation (e.g., <ref> [19, 12] </ref>) to rule-based systems [10, 11]. The more complex task of interactive navigation has been considered in a wide variety of contexts, ranging from the viewing of simple 3D scenes on a desktop monitor to the control of fully immer-sive virtual reality environments. <p> Quaternions must be used to achieve smooth orientation interpolations as noted by Shoemake [19, 20], and refined in subsequent work such as that of Schlag [18], Nielson [14], and Kim, et al. <ref> [12] </ref>; 2D rectangular extensions of these methods are straightforward. (Note: One might use more complex interpolation methods such as a 2D minimal-surface version of the quaternion minimal path solutions of Barr, et al. [1], but these would likely be too time consuming for most real-time applications.) Other variables such as the
Reference: [13] <author> J.D. Mackinlay, S. Card, and G. Robertson. </author> <title> Rapid controlled movement through a virtual 3d workspace. </title> <journal> In Computer Graphics, </journal> <volume> volume 24, </volume> <pages> pages 171-176, </pages> <year> 1990. </year> <note> Proceedings of SIGGRAPH 1990. </note>
Reference-contexts: Examples of such viewing control methods run the gamut from orientation control paradigms (Brooks [4], Nielson and Olson [15], Chen et al. [5], Hanson [8], and Shoemake [21, 22]) to methods that intelligently focus on particular scene points such as Mackinlay et al. <ref> [13] </ref>, constraint-based camera placement systems such as Phillips et al. [16], and general control systems such as those discussed by Ware and Osborne [27] and Drucker et al. [6]. <p> As the viewer approaches the critical vista point itself, changes in the focal length, camera orientation, and control response can be imposed by the designer to exactly emulate features such as Mackinlay et al.'s <ref> [13] </ref> controlled approach, or even "dynamic field glasses" that focus in on distant scene features as though one had donned zoomable binoculars to pan across the scene of interest, similar to one scenario of Robinett and Holloway [17]. An example is given in Figure 9. Multiple Coverings. <p> Here, we just define a scalar field over the guide manifold and use it to magnify or reduce the bare controller displacement at each local point. Effects such as those to those of Mackinlay <ref> [13] </ref>, could be achieved without the use of scale factors simply by refining the mesh near the critical points of the guide manifold. However, it is quite tricky to make the changes occur smoothly in such a mesh, and the continuous scale change field overcomes this.
Reference: [14] <author> G. M. Nielson. </author> <title> Smooth interpolation of orientations. </title> <editor> In N.M. Thalman and D. Thalman, editors, </editor> <booktitle> Computer Animation '93, </booktitle> <pages> pages 75-93, </pages> <address> Tokyo, June 1993. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Quaternions must be used to achieve smooth orientation interpolations as noted by Shoemake [19, 20], and refined in subsequent work such as that of Schlag [18], Nielson <ref> [14] </ref>, and Kim, et al. [12]; 2D rectangular extensions of these methods are straightforward. (Note: One might use more complex interpolation methods such as a 2D minimal-surface version of the quaternion minimal path solutions of Barr, et al. [1], but these would likely be too time consuming for most real-time applications.)
Reference: [15] <author> G.M. Nielson and Dan R. Olson. </author> <title> Direct manipulation techniques for 3d objects using 2d locator devices. </title> <booktitle> In Computer Graphics, </booktitle> <pages> pages 175-182, </pages> <year> 1987. </year> <booktitle> Proceedings of 1986 Workshop on Interactive 3D Graphics. </booktitle>
Reference-contexts: Examples of such viewing control methods run the gamut from orientation control paradigms (Brooks [4], Nielson and Olson <ref> [15] </ref>, Chen et al. [5], Hanson [8], and Shoemake [21, 22]) to methods that intelligently focus on particular scene points such as Mackinlay et al. [13], constraint-based camera placement systems such as Phillips et al. [16], and general control systems such as those discussed by Ware and Osborne [27] and Drucker
Reference: [16] <author> Cary B. Phillips, Norman I. Badler, and John Granieri. </author> <title> Automatic viewing control for 3d direct manipulation. </title> <booktitle> In Computer Graphics, </booktitle> <pages> pages 71-74, </pages> <year> 1992. </year> <booktitle> Proceedings of 1992 Symposium on Interactive 3D Graphics. </booktitle>
Reference-contexts: viewing control methods run the gamut from orientation control paradigms (Brooks [4], Nielson and Olson [15], Chen et al. [5], Hanson [8], and Shoemake [21, 22]) to methods that intelligently focus on particular scene points such as Mackinlay et al. [13], constraint-based camera placement systems such as Phillips et al. <ref> [16] </ref>, and general control systems such as those discussed by Ware and Osborne [27] and Drucker et al. [6].
Reference: [17] <author> Warren Robinett and Richard Holloway. </author> <title> Implementation of flying, scaling, </title> <booktitle> and grabbing in virtual worlds. In Computer Graphics, </booktitle> <pages> pages 189-192, </pages> <year> 1992. </year> <booktitle> Proceedings of 1992 Symposium on Interactive 3D Graphics. </booktitle>
Reference-contexts: The use of constraints in view selection specifically for virtual reality has been used, for example, by Robinett and Holloway <ref> [17] </ref> to go beyond the usual "flying" modality, and by Billinghurst and Savage [2] in an expert system context. <p> imposed by the designer to exactly emulate features such as Mackinlay et al.'s [13] controlled approach, or even "dynamic field glasses" that focus in on distant scene features as though one had donned zoomable binoculars to pan across the scene of interest, similar to one scenario of Robinett and Holloway <ref> [17] </ref>. An example is given in Figure 9. Multiple Coverings.
Reference: [18] <author> John Schlag. </author> <title> Using geometric constructions to interpolate orientation with quaternions. </title> <editor> In James Arvo, editor, </editor> <booktitle> Graphics Gems II, </booktitle> <pages> pages 377-380. </pages> <publisher> Academic Press, </publisher> <year> 1991. </year>
Reference-contexts: Quaternions must be used to achieve smooth orientation interpolations as noted by Shoemake [19, 20], and refined in subsequent work such as that of Schlag <ref> [18] </ref>, Nielson [14], and Kim, et al. [12]; 2D rectangular extensions of these methods are straightforward. (Note: One might use more complex interpolation methods such as a 2D minimal-surface version of the quaternion minimal path solutions of Barr, et al. [1], but these would likely be too time consuming for most <p> We implemented our own Catmull-Rom interpolator based on the Schlag algorithm <ref> [18] </ref>. Wandering Camera Path with Wandering View. In a traditional computer animation, the camera itself may follow many different constraints such as looking at a single point on the ground throughout the motion, tracking a moving object in the scene, or staring in a fixed direction.
Reference: [19] <author> K. Shoemake. </author> <title> Animating rotation with quaternion curves. </title> <journal> In Computer Graphics, </journal> <volume> volume 19, </volume> <pages> pages 245-254, </pages> <year> 1985. </year> <note> Proceedings of SIGGRAPH 1985. </note>
Reference-contexts: Computer animation, for example, requires the choice of a time sequence of camera models that can be considered as a one-parameter constraint; applicable techniques range from direct orientation interpolation (e.g., <ref> [19, 12] </ref>) to rule-based systems [10, 11]. The more complex task of interactive navigation has been considered in a wide variety of contexts, ranging from the viewing of simple 3D scenes on a desktop monitor to the control of fully immer-sive virtual reality environments. <p> Quaternions must be used to achieve smooth orientation interpolations as noted by Shoemake <ref> [19, 20] </ref>, and refined in subsequent work such as that of Schlag [18], Nielson [14], and Kim, et al. [12]; 2D rectangular extensions of these methods are straightforward. (Note: One might use more complex interpolation methods such as a 2D minimal-surface version of the quaternion minimal path solutions of Barr, et
Reference: [20] <author> K. Shoemake. </author> <title> Animation with quaternions. </title> <booktitle> Siggraph Course Lecture Notes, </booktitle> <year> 1987. </year>
Reference-contexts: Quaternions must be used to achieve smooth orientation interpolations as noted by Shoemake <ref> [19, 20] </ref>, and refined in subsequent work such as that of Schlag [18], Nielson [14], and Kim, et al. [12]; 2D rectangular extensions of these methods are straightforward. (Note: One might use more complex interpolation methods such as a 2D minimal-surface version of the quaternion minimal path solutions of Barr, et
Reference: [21] <author> Ken Shoemake. </author> <title> Arcball rotation control. </title> <editor> In Paul Heck-bert, editor, </editor> <booktitle> Graphics Gems IV, </booktitle> <pages> pages 175-192. </pages> <publisher> Academic Press, </publisher> <year> 1994. </year>
Reference-contexts: Examples of such viewing control methods run the gamut from orientation control paradigms (Brooks [4], Nielson and Olson [15], Chen et al. [5], Hanson [8], and Shoemake <ref> [21, 22] </ref>) to methods that intelligently focus on particular scene points such as Mackinlay et al. [13], constraint-based camera placement systems such as Phillips et al. [16], and general control systems such as those discussed by Ware and Osborne [27] and Drucker et al. [6].
Reference: [22] <author> Ken Shoemake. </author> <title> Fiber bundle twist reduction. </title> <editor> In Paul Heckbert, editor, </editor> <booktitle> Graphics Gems IV, </booktitle> <pages> pages 230-236. </pages> <publisher> Academic Press, </publisher> <year> 1994. </year>
Reference-contexts: Examples of such viewing control methods run the gamut from orientation control paradigms (Brooks [4], Nielson and Olson [15], Chen et al. [5], Hanson [8], and Shoemake <ref> [21, 22] </ref>) to methods that intelligently focus on particular scene points such as Mackinlay et al. [13], constraint-based camera placement systems such as Phillips et al. [16], and general control systems such as those discussed by Ware and Osborne [27] and Drucker et al. [6].
Reference: [23] <author> N. Steenrod. </author> <title> The Topology of Fibre Bundles. </title> <publisher> Princeton University Press, </publisher> <address> 1951. </address> <publisher> Princeton Mathematical Series 14. </publisher>
Reference-contexts: Therefore, we retain all the scene-viewing parameters in a single data structure, and treat its space as a type of fiber bundle (see <ref> [7, 23] </ref>) for which we choose a projection and a section. All that means for us is that, whichever guide field variables we choose to map the controller to, we need a consistent projection operator to make that the "base space" in the sense of fiber bundle theory.
Reference: [24] <author> P. W. Thorndyke and S. E. Goldin. </author> <title> Spatial learning and reasoning skill. In H.L. Pick and L.P. Acredolo, editors, Spatial Orientation: Theory, </title> <booktitle> Research, and Application, </booktitle> <pages> pages 195-217. </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: at each point of a "virtual sidewalk." Substantive human factors studies of the comparative effectiveness of particular scenarios are beyond the intended scope of this paper; nevertheless, an evaluation of alternative constrained exploration modes is currently being pursued for room-like worlds, using criteria inspired by those of Thorndyke et al. <ref> [26, 25, 24] </ref>. Other future plans include the development of context-dependent, state-dependent, history-sensitive expert systems to recompute the camera model at each step the viewer takes on the journey.
Reference: [25] <author> P. W. Thorndyke and B. Hayes-Roth. </author> <title> Differences in spatial knowledge acquired from maps and navigation. </title> <journal> Cognitive Psychology, </journal> <volume> 14 </volume> <pages> 560-589, </pages> <year> 1982. </year>
Reference-contexts: at each point of a "virtual sidewalk." Substantive human factors studies of the comparative effectiveness of particular scenarios are beyond the intended scope of this paper; nevertheless, an evaluation of alternative constrained exploration modes is currently being pursued for room-like worlds, using criteria inspired by those of Thorndyke et al. <ref> [26, 25, 24] </ref>. Other future plans include the development of context-dependent, state-dependent, history-sensitive expert systems to recompute the camera model at each step the viewer takes on the journey.
Reference: [26] <author> P. W. Thorndyke and C. Stasz. </author> <title> Individual differences in procedures for knowledge acquisition from maps. </title> <journal> Cognitive Psychology, </journal> <volume> 12 </volume> <pages> 137-175, </pages> <year> 1980. </year>
Reference-contexts: at each point of a "virtual sidewalk." Substantive human factors studies of the comparative effectiveness of particular scenarios are beyond the intended scope of this paper; nevertheless, an evaluation of alternative constrained exploration modes is currently being pursued for room-like worlds, using criteria inspired by those of Thorndyke et al. <ref> [26, 25, 24] </ref>. Other future plans include the development of context-dependent, state-dependent, history-sensitive expert systems to recompute the camera model at each step the viewer takes on the journey.

References-found: 26

