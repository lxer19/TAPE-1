URL: ftp://ftp.cc.gatech.edu/pub/people/arkin/web-papers/asilomar.ps.Z
Refering-URL: http://www.cs.gatech.edu/aimosaic/robot-lab/mrl-online-publications.html
Root-URL: 
Title: The Multiple Dimensions of Action-Oriented Robotic Perception: Fission, Fusion, and Fashion  
Author: Ronald C. Arkin 
Address: Atlanta, GA 30332  
Affiliation: College of Computing Georgia Institute of Technology  
Abstract: Action-oriented perception provides an alternative to traditional high-level image understanding for the roboticist. By channeling sensory perception directly to motor behaviors (sensor fission) without mediating global representations rapid response is ensured. Forcing sensor fusion to be conducted within the context of motor needs reduces computational demand and enhances parallelism. Utilizing the correct visual algorithm to support motor action at the correct time (temporal coordination or sensor fashion) provides robust performance over wide ranges of activity. In this paper we describe the philosophy of action-oriented perception for the roboti-cist and discuss the different dimensions in which it may be effectively used. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anderson, T.L. and Donath, M., </author> <title> "Animal Behavior as a Paradigm for Developing Robot Autonomy", </title> <booktitle> Robotics and Autonomous Systems, 6 (1990), </booktitle> <pages> pp. 145-168. </pages>
Reference: [2] <author> Arbib, </author> <title> M.,The Metaphorical Brain, </title> <publisher> Wiley, </publisher> <year> 1972. </year>
Reference-contexts: Depending on their internal conditions, motivational state (plans), and sensory limitations we can develop algorithms that provide useful and focussed information for these actors. 2.2 Action-oriented Perception Action-oriented perception is not a new concept. It has roots in both cybernetics <ref> [2] </ref> and cognitive psychology [17]. The underlying principle is that perception is predicated upon the needs of action: only the information that is germane for a particular task needs to be extracted from the environment. The world is viewed in different ways based upon the agent's intentions.
Reference: [3] <author> Arkin, </author> <title> R.C., "The Impact of Cybernetics on the Design of a Mobile Robot System: A Case Study", </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> Vol. 20, No. 6, </volume> <month> Nov/Dec </month> <year> 1990, </year> <pages> pp. 1245-1257. </pages>
Reference-contexts: The world is viewed in different ways based upon the agent's intentions. In short, perception is conducted on a need to know basis. (A more detailed discussion of action-oriented perception appears in <ref> [3] </ref>). The ramifications of this philosophy should be readily apparent for the designer of a robotic system. In general, there is no point to constructing full scale scene interpretation and three dimensional world reconstruction.
Reference: [4] <author> Arkin, </author> <title> R.C., "Motor Schema-Based Mobile Robot Navigation", </title> <journal> International Journal of Robotics Research, </journal> <volume> Vol. 8, No. 4, </volume> <month> August </month> <year> 1989. </year>
Reference-contexts: In our work, we have used motor and perceptual schemas as a means for encapsulating and representing motor actions and perceptual strategies. This approach has been strongly motivated by neuroscientific, cognitive, and etho-logical studies and is discussed in detail in <ref> [4] </ref>. For the purposes of this paper, we must recognize that motor schemas provide the specifications for a perceptual process: i.e., what must be discerned from environmental sensing and perhaps constraining where it may be located, often bootstrapped by expectations from either a priori models or previous sensing.
Reference: [5] <author> Arkin, </author> <title> R.C., "Integrating Behavioral, Perceptual, and World Knowledge in Reactive Navigation", </title> <booktitle> Robotics and Autonomous Systems, 6 (1990), </booktitle> <pages> pp. 105-122. </pages>
Reference-contexts: The particular configuration of motor and perceptual schemas is configured prior to actual execution by a higher level planner <ref> [5] </ref>. 3. Dimensions of Action-oriented Perception The ways in which perceptual strategies can be arrayed relative to the motor behaviors constitutes the dimensions of action-oriented perception (Figure 1).
Reference: [6] <author> Arkin, R.C., Murphy, R.R., Pearson, M. and Vaughn, D., </author> <title> "Mobile Robot Docking Operations in a Manufacturing Environment: Progress in Visual Perceptual Strategies", </title> <booktitle> Proc. IEEE International Workshop on Intelligent Robots and Systems '89, </booktitle> <address> Tsukuba, Japan, </address> <year> 1989, </year> <pages> pp. 147-154. </pages>
Reference-contexts: A Hough transform model-based recogni tion strategy. 3. Adaptive tracking of a passive landmark using fast region segmentation. 4. Final positioning using texture-based vision or ultrasound. A description of several of these algorithms appears in <ref> [6] </ref>. The primary issues in temporal coordination are when to use each of these algorithms and how to determine the best time to switch over from one perceptual strategy to the next.
Reference: [7] <author> Ballard, D., </author> <title> "Animate Vision"", </title> <journal> Artificial In--telligence, </journal> <volume> Vol. 48, </volume> <month> Feb. </month> <year> 1991, </year> <pages> pp. </pages> <month> 57-86.. </month>
Reference-contexts: Nonetheless, even active perception in principle is a subset of action-oriented perception, as its ultimate goals serve also to provide support for acting within the world. Although important, we will not describe the work in active perception here (the reader is referred to [8] see also animate vision <ref> [7] </ref>). In either case, action and perception are inseparable.
Reference: [8] <editor> Bajcsy, R., </editor> <title> "Active Perception", </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> Vol. 76, No. 8, </volume> <month> August </month> <year> 1988, </year> <month> pp.966-1005. </month>
Reference-contexts: Nonetheless, even active perception in principle is a subset of action-oriented perception, as its ultimate goals serve also to provide support for acting within the world. Although important, we will not describe the work in active perception here (the reader is referred to <ref> [8] </ref> see also animate vision [7]). In either case, action and perception are inseparable.
Reference: [9] <author> Brooks, R.A., </author> <title> "A Robust Layered Control System for a Mobile Robot", </title> <journal> IEEE Jour. of Robotics and Auto., </journal> <volume> Vol. RA-2, No. 1, </volume> <pages> 1986 pp. 14-23. </pages>
Reference: [10] <author> Brooks, R.A., </author> <title> "Elephants Don't Play Chess", </title> <booktitle> Robotics and Autonomous Systems, 6 (1990), </booktitle> <pages> pp. 3-15. </pages>
Reference: [11] <author> Brooks, R.A., </author> <title> "Intelligence without Representation", </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 47, No. </volume> <pages> 1-3, </pages> <month> Jan. </month> <year> 1991, </year> <pages> pp. 139-159. </pages>
Reference-contexts: Instead of creating an omniscient universal representation that can support any conceivable robotic requirement, the task is greatly simplified by eliminating any common intervening representations. We actually soften the seemingly strict avoidance of representational constructs over some other approaches (e.g., <ref> [11] </ref>). We do not advocate the use of global representations (e.g., those that provide information without regard for motor needs), but do encourage the formation of local percepts defined within the context of a motor behavior.
Reference: [12] <author> Colgan, P., </author> <title> Comparative Social Recognition, </title> <editor> J. </editor> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: Looming and prey detectors [13] for guiding visual response in the frog are good examples. In recognition behavior, we find that some agents are capable of discerning things others simply cannot (e.g., intra-species recognition among birds <ref> [12] </ref>). Perceptual cues that are necessary for the survival and routine functioning of an organism are extracted cheaply and efficiently from the environment while irrelevant information is not processed at all (i.e., it's not even discarded pick-up never occurs).
Reference: [13] <author> Ewert, J-P., Neuroethology: </author> <title> an introduction to the neurophysiological fundamentals of behavior, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1980. </year>
Reference-contexts: The ethological literature is replete with examples of sensed information providing cues for evoking behavior (e.g., [19,20]). Indeed, evolution has provided biological agents with highly tuned apparatae to efficiently "pick-up" the information necessary to carry out useful actions. Looming and prey detectors <ref> [13] </ref> for guiding visual response in the frog are good examples. In recognition behavior, we find that some agents are capable of discerning things others simply cannot (e.g., intra-species recognition among birds [12]).
Reference: [14] <author> Murphy, </author> <title> R.R., "A Control Scheme for Sensor Fusion for Navigation of Autonomous Mobile Robots", </title> <booktitle> Proceedings of SPIE Sensor Fusion III, </booktitle> <address> Cambridge, MA, </address> <month> Nov. </month> <year> 1990. </year>
Reference-contexts: These perceptual schema/subschema arrays are configured prior to execution, based on the needs of the motor action, during the investigatory phase of the fusion process. The performa-tory phase of sensor fusion is analogous to the execution aspects of reactive control and proceeds without hierarchical supervision. A unique control scheme <ref> [14] </ref> has been developed to provide error recovery capabilities in light of potential sensor failures or uncertain readings.
Reference: [15] <author> Murphy, </author> <title> R.R., "An Application of Dempster-Shafer Theory to a Novel Control Scheme for Sensor Fusion", to be presented at SPIE Stochastic Methods in Signal Processing, </title> <booktitle> Image Processing, and Computer Vision, </booktitle> <address> San Diego, CA, </address> <month> July 21-26, </month> <year> 1991. </year>
Reference-contexts: These perceptual schemas are supported by perceptual subschemas which feed their parent the direct sensor information from each source. The parent perceptual schema combines this information using uncertainty management techniques <ref> [15] </ref> to produce a percept and a measure of its belief to be used within the motor schema itself. These perceptual schema/subschema arrays are configured prior to execution, based on the needs of the motor action, during the investigatory phase of the fusion process.
Reference: [16] <author> Murphy, </author> <title> R.R., "Towards a Foundation for Sensor Fusion: Grammar and Control", </title> <booktitle> working notes, AAAI Fall Workshop on Aspects of Sensory Intelligence, </booktitle> <year> 1991. </year>
Reference-contexts: A unique control scheme [14] has been developed to provide error recovery capabilities in light of potential sensor failures or uncertain readings. The approach and results of this work are described in more detail in a companion paper submitted to this conference <ref> [16] </ref>. 3.3 Temporal Coordination of Perceptual Algorithms Sen sor Fashion It is entirely possible, and in many instances highly desirable, to have more than one perceptual algorithm associated with a single motor behavior at different stages during its activation.
Reference: [17] <author> Neisser, U., </author> <title> Cognition and Reality: Principles and Implications of Cognitive Psychology, </title> <publisher> Freeman, </publisher> <year> 1976. </year>
Reference-contexts: Depending on their internal conditions, motivational state (plans), and sensory limitations we can develop algorithms that provide useful and focussed information for these actors. 2.2 Action-oriented Perception Action-oriented perception is not a new concept. It has roots in both cybernetics [2] and cognitive psychology <ref> [17] </ref>. The underlying principle is that perception is predicated upon the needs of action: only the information that is germane for a particular task needs to be extracted from the environment. The world is viewed in different ways based upon the agent's intentions.
Reference: [18] <author> Payton, D., </author> <title> "An Architecture for Reflexive Autonomous Vehicle Control", </title> <booktitle> IEEE Conf. on Robotics and Auto., </booktitle> <pages> pp. 1838-1845, </pages> <year> 1986. </year>
Reference: [19] <author> Smith, W.J., </author> <title> The Behavior of Communicating: An Ethological Approach, </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1977. </year>
Reference: [20] <author> Tinbergen, N., </author> <title> Social Behavior in Animals, </title> <publisher> Methuen, </publisher> <address> London, </address> <year> 1953. </year>
References-found: 20

