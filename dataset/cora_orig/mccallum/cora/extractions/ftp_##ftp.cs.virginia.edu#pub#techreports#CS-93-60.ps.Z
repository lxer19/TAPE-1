URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-93-60.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: The Advantages of MachineDependent Global Optimization  
Author: MANUEL E. BENITEZ and JACK W. DAVIDSON S. A. 
Note: U.  
Address: Charlottesville, VA 22903  
Affiliation: Department of Computer Science University of Virginia  
Abstract: Using an intermediate language is a well-known, effective technique for constructing interpreters and compilers. The use of an intermediate language forces a structure on the organization of the compiler. The front end translates the source code to semantically equivalent intermediate language. The back end processes the intermediate language and produces target machine code. The choice of an intermediate language for use in an optimizing compiler is a key design decision. The intermediate language affects the source languages that can be handled, the types of and effectiveness of the code improvements done, and the ease of target machine code generation. This paper describes experience with a retargetable, optimizing compilation system that is centered around the use of two intermediate representations: one relatively high level, the other a low level corresponding to target machine instructions. The high-level intermediate language (HIL) models a stack-based, hypothetical RISC machine. The low-level intermediate language (LIL) models target machines at the instructionset architecture level. All code improvements are applied to the LIL representation of a program. This is motivated by the observation that most all optimizations are machine dependent, and the few that are truly machine independent interact with the machinedependent ones. This paper describes several machine-independent code improvements and shows that they are actually machine dependent. To illustrate how code improvements can be applied to a LIL, an algorithm for induction variable elimination is presented. While the algorithm operates on a LIL, the algorithm is itself largely machine independent. It is demonstrated that this algorithm yields better code than traditional implementations that are applied machine-independently to a high-level representation. 
Abstract-found: 1
Intro-found: 1
Reference: [Aho86] <author> Aho, A. V., Sethi, R., and Ullman, J. D., </author> <booktitle> Compilers Principles, Techniques and Tools , Addison-Wesley, </booktitle> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: Thus, from any reference the code improver can find either the previous reference or the next reference. Previous reference involving merging flow can be found through functions [Cytr91]. Additionally, associated with each reference is a canonical value. This is similar to a value number <ref> [Aho86] </ref> and is used to perform commonsubexpression elimination as well as code motion. Notice that reference to r [6] and r [5] all have the same canonical value. <p> Simple induction variables are used to compute induced sequences of the form , where i is the basic induction variable. In the example in Figure 6a, the sequences being computed are and , where and are the starting addresses of the arrays. Using well-known algorithms <ref> [Aho86] </ref>, the induction variable i can be eliminated and be replaced by the computation of the induced sequence of the addresses. The SPARC code produced by a code improver operating on a HIL is shown in Figure 6b. Notice that the sequences of addresses are being computed using two registers.
Reference: [Chow83] <author> Chow, F. C., </author> <title> A Portable Machine-Independent Global OptimizerDesign and Measurements , Ph.D. </title> <type> Dissertation, </type> <institution> Stanford University, </institution> <year> 1983. </year>
Reference-contexts: One popular approach is to generate code for an abstract machine. Well-known abstract machines include P-code (used in a several Pascal compilers) [Nels79], U-code (used in the compilers developed by MIPS, Inc. for the R2000/R3000 family of microprocessors) <ref> [Chow83] </ref>, and EM (used in the Amsterdam compiler kit) [Tane82]. In the quest for efficiency, the abstract machine often models the operations and addressing modes found on the target architectures. For a retargetable compiler, with many intended targets, this can yield a large and complex abstract machine.
Reference: [Cytr91] <author> Cytron, R., Ferrante, J., Rosen, B. K., Wegman, M. N., and Zadeck, F. K., </author> <title> Efficiently Computing Static Single Assignment Form and the Control Dependence Graph, </title> <journal> ACM Transactions on Programming Languages and Systems , 13(4), </journal> <month> October </month> <year> 1991, </year> <pages> pp. 451490. </pages>
Reference-contexts: For each reference to a register or a memory location, a defuse chain is maintained. Thus, from any reference the code improver can find either the previous reference or the next reference. Previous reference involving merging flow can be found through functions <ref> [Cytr91] </ref>. Additionally, associated with each reference is a canonical value. This is similar to a value number [Aho86] and is used to perform commonsubexpression elimination as well as code motion. Notice that reference to r [6] and r [5] all have the same canonical value.
Reference: [Davi84a] <author> Davidson, J. W. and Fraser, C. W., </author> <title> Register Allocation and Exhaustive Peephole Optimization, </title> <journal> SoftwarePractice and Experience , 14(9), </journal> <month> September </month> <year> 1984, </year> <pages> pp. 857866. </pages>
Reference-contexts: The LIL representation used is based on RTLs. RTLs have been used successfully to automate machinespecific portions of a compiler such as instruction selection [Davi84b], common subexpression elimination <ref> [Davi84a] </ref>, and evaluation order determination [Davi84a]. These transformations are all local ones and do not require information beyond that contained in a basic block. <p> The LIL representation used is based on RTLs. RTLs have been used successfully to automate machinespecific portions of a compiler such as instruction selection [Davi84b], common subexpression elimination <ref> [Davi84a] </ref>, and evaluation order determination [Davi84a]. These transformations are all local ones and do not require information beyond that contained in a basic block.
Reference: [Davi84b] <author> Davidson, J. W. and Fraser, C. W., </author> <title> Code Selection Through Peephole Optimization, </title> <booktitle> Transactions on Programming Languages and Systems , 6 (4), </booktitle> <month> October </month> <year> 1984, </year> <pages> pp. 732. </pages>
Reference-contexts: For a retargetable compiler, with many intended targets, this can yield a large and complex abstract machine. Such abstract machines have been termed union machines as they attempt to include the union of the set of operators supported on the target architectures <ref> [Davi84b] </ref>. P-code, for example, has 219 operations and includes specialized operators for incrementing and decrementing variables, zeroing a memory location, etc. There is an equally compelling argument for designing a small, simple abstract machine. <p> The LIL representation used is based on RTLs. RTLs have been used successfully to automate machinespecific portions of a compiler such as instruction selection <ref> [Davi84b] </ref>, common subexpression elimination [Davi84a], and evaluation order determination [Davi84a]. These transformations are all local ones and do not require information beyond that contained in a basic block.
Reference: [Davi86] <author> Davidson, J. W., </author> <title> A Retargetable Instruction Reorganizer, </title> <booktitle> Proceedings of the '86 Symposium on Compiler Construction , Palo Alto, </booktitle> <address> CA, </address> <month> June </month> <year> 1986, </year> <pages> pp. 234 241. </pages>
Reference: [Davi87] <author> Davidson, J. W. and Gresh, J. V., Cint: </author> <title> A RISC Interpreter for the C Programming Language, </title> <booktitle> Proceedings of the ACM SIGPLAN '87 Symposium on Interpreters and Interpretive Techniques , St. </booktitle> <address> Paul, MN, </address> <month> June </month> <year> 1987, </year> <pages> pp. 189 198. </pages>
Reference-contexts: Second, it was important to be able to specify the semantics of operation of CVM. This is done operationally through an interpreter. Implementing an interpreter for a stack-based machine is quite simple, easy to understand, and reasonably efficient <ref> [Davi87] </ref>. 3.2 The Low-Level Intermediate Language The LIL representation of a program is what will be manipulated by all code improvement algorithms.
Reference: [Davi91a] <author> Benitez, M. E., and Davidson, J. W., </author> <title> Code Generation for Streaming: an Access/Execute Mechanism, </title> <booktitle> Proceedings of the Fourth International Symposium on Architectural Support for Programming Languages and Operating Systems , Santa Clara, </booktitle> <address> CA, </address> <month> April </month> <year> 1991, </year> <pages> pp. 132141. </pages>
Reference-contexts: For one program, iir , machine-independent IVE showed a large benefit. Inspection of this code revealed that this was because IVE produced an opportunity for recurrence detection and optimization <ref> [Davi91a] </ref> to take effect, and a large percent of the benefit was from this improvement. These results confirm that it is difficult to apply code improving transformations to a HIL because the cost/benefit analysis is so dependent on the target machine.
Reference: [Davi91b] <author> Davidson, J. W. and Whalley, D. B., </author> <title> A Design Environment for Addressing Architecture and Compiler Interactions, </title> <journal> Microprocessors and Microsystems, </journal> <volume> 15(9), </volume> <month> November </month> <year> 1991, </year> <pages> pp. 459472. </pages>
Reference-contexts: The improvement due to machinedependent IVE is similar to that reported elsewhere in the literature averaging two or three percent [Powe84]. The one anomaly in Column B is the serious loss of performance for espresso . Using a measurement tool called ease <ref> [Davi91b] </ref>, the execution behavior of the three versions of this program was examined. First, it was observed that several of the routines that were called frequently had loops with very low iteration counts (50% of the loops in these routines had iteration counts of less than two).
Reference: [McFa91] <author> McFarling, S., </author> <title> Procedure Merging with Instruction Caches, </title> <booktitle> Proceeding of the ACM SIGPLAN '91 Symposium on Programming Language Design and Implementation , Toronto, </booktitle> <address> Ontario, </address> <month> June </month> <year> 1991, </year> <pages> pp. 7179. </pages>
Reference-contexts: Inline code expansion is machine dependent because the decision to inline depends on the characteristics of the target machine. One important consideration is the size of the instruction cache <ref> [McFa91] </ref>. Inlining a function into a loop and possibly causing the loop to no longer fit in the cache can result in a serious drop in performance. To illustrate how DCE interacts with inlining, consider the daxpy function from the well-known linpack benchmark. The code is shown Figure 4.
Reference: [Nels79] <author> Nelson, P. A., </author> <title> A Comparison of PASCAL Intermediate Languages, </title> <booktitle> Proceedings of the SIGPLAN Symposium on Compiler Construction , Denver, </booktitle> <publisher> CO, </publisher> <month> August </month> <year> 1979, </year> <pages> pp. </pages> <year> 208213. </year>
Reference-contexts: One popular approach is to generate code for an abstract machine. Well-known abstract machines include P-code (used in a several Pascal compilers) <ref> [Nels79] </ref>, U-code (used in the compilers developed by MIPS, Inc. for the R2000/R3000 family of microprocessors) [Chow83], and EM (used in the Amsterdam compiler kit) [Tane82]. In the quest for efficiency, the abstract machine often models the operations and addressing modes found on the target architectures.
Reference: [Newe79] <author> Newey, M. C., Poole, P. C., and Waite, W. M., </author> <title> Abstract Machine Modelling to Produce Portable SoftwareA Review and Evaluation, </title> <booktitle> SoftwarePractice and Experience , 2 , 1972, </booktitle> <pages> pp. 107136. - 17 </pages> - 
Reference-contexts: There is an equally compelling argument for designing a small, simple abstract machine. Small, simple instruction sets are faster and less error prone to implement than a large complex instruction set. Abstract machine designers have long recognized this dilemma. In 1972, Newey, Poole, and Waite <ref> [Newe79] </ref> observed that Most problems will suggest a number of specialized operations which could possibly be implemented quite efficiently on certain hardware. The designer must balance the convenience and utility of these operations against the increased difficulty of implementing an abstract machine with a rich and varied instruction set. <p> The intersection machine, on the other hand, need only be changed if the new operation cannot be synthesized from the existing operations. Third, if the compiler is to be self-bootstrapping (a lost art), a small intermediate language can significantly reduce the effort to bootstrap <ref> [Rich71, Newe79] </ref>. For additional justification for preferring a small, simple abstract machine over a large, complex one see Davi84b.
Reference: [Powe84] <author> Powell, M. L., </author> <title> A Portable Optimizing Compiler for Modula-2, </title> <booktitle> Proceedings of the SIGPLAN '84 Symposium on Compiler Construction , Montreal, </booktitle> <address> Canada, </address> <month> June </month> <year> 1984, </year> <pages> pp. 310318. </pages>
Reference-contexts: Column B of Table II shows the speedup when machinedependent IVE was performed compared to when no IVE was performed. The improvement due to machinedependent IVE is similar to that reported elsewhere in the literature averaging two or three percent <ref> [Powe84] </ref>. The one anomaly in Column B is the serious loss of performance for espresso . Using a measurement tool called ease [Davi91b], the execution behavior of the three versions of this program was examined.
Reference: [Rich71] <author> Richards, M., </author> <title> The Portability of the BCPL Compiler, </title> <booktitle> SoftwarePractice and Experience , 1 (2), </booktitle> <month> April </month> <year> 1971, </year> <pages> pp. 135146. </pages>
Reference-contexts: The intersection machine, on the other hand, need only be changed if the new operation cannot be synthesized from the existing operations. Third, if the compiler is to be self-bootstrapping (a lost art), a small intermediate language can significantly reduce the effort to bootstrap <ref> [Rich71, Newe79] </ref>. For additional justification for preferring a small, simple abstract machine over a large, complex one see Davi84b.
Reference: [Spec89] <institution> Systems Performance Evaluation Cooperative, c/o Waterside Associates, </institution> <address> Fremont, CA, </address> <year> 1989. </year>
Reference-contexts: A set of experiments were performed using the benchmark programs described Table I. This set of programs includes the four C programs that are the C component of the SPEC89 suite <ref> [Spec89] </ref> as well as some common Unix utilities and user code. Together the programs comprise approximately 130,000 lines of source code. The first experiment determined the overall effectiveness of IVE. The programs in Table I were compiled with and without IVE enabled.
Reference: [Tane82] <author> Tanenbaum, A. S., Staveren, H. V., and Stevenson, J. W., </author> <title> Using Peephole Optimization on Intermediate Code, </title> <booktitle> Transactions on Programming Languages and Systems , 4 (1), </booktitle> <month> January </month> <year> 1982, </year> <pages> pp. 2136. </pages>
Reference-contexts: One popular approach is to generate code for an abstract machine. Well-known abstract machines include P-code (used in a several Pascal compilers) [Nels79], U-code (used in the compilers developed by MIPS, Inc. for the R2000/R3000 family of microprocessors) [Chow83], and EM (used in the Amsterdam compiler kit) <ref> [Tane82] </ref>. In the quest for efficiency, the abstract machine often models the operations and addressing modes found on the target architectures. For a retargetable compiler, with many intended targets, this can yield a large and complex abstract machine.
Reference: [Tane83] <author> Tanenbaum, A. S., Staveren, H. V., Keizer, E. G., and Stevenson, J. W., </author> <title> A Practical Tool Kit for Making Portable Compilers, </title> <booktitle> Communications of the ACM , 26 (9), </booktitle> <month> September </month> <year> 1983, </year> <pages> pp. 654660. </pages>
References-found: 17

