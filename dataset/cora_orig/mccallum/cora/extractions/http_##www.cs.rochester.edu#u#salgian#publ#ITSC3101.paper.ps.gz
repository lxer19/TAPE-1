URL: http://www.cs.rochester.edu/u/salgian/publ/ITSC3101.paper.ps.gz
Refering-URL: http://www.cs.rochester.edu/stats/oldmonths/1998.05/docs-name.html
Root-URL: 
Title: DEVELOPING AUTONOMOUS NAVIGATION ALGORITHMS USING PHOTOREALISTIC SIMULATION  
Author: Garbis Salgian and Dana Ballard 
Keyword: Simulation software, Autonomous navigation  
Address: Rochester, NY 14627, USA  
Affiliation: Computer Science Department, University of Rochester  
Note: In IEEE Conference on Intelligent Transportation Systems Boston, MA, Nov 9-12, 1997, pp 882-887  
Abstract: One of the principal problems in developing an automated driver is deciding how to handle the plethora of different decisions that have to be made in tactical situations. Insight on these problems can be obtained by the concurrent development of a driving simulator that allows both human and automated driving. A unique feature of the driving simulator that we have built is the ability to track eye movements within a freely moving VR helmet. This allows the assessment of exigencies in complex situations that can be used to guide the development of automated routines. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. D. Dickmanns, </author> <title> Performance improvements for autonomous road vehicles, </title> <booktitle> in Proceedings of the 4th International Conference on Intelligent Autonomous Systems, (Karlsruhe, Ger-many), </booktitle> <pages> pp. 214, </pages> <month> March 27-30 </month> <year> 1995. </year>
Reference-contexts: INTRODUCTION Automated driving holds the promise of improving traffic safety, alleviating highway congestion and saving fuel. Currently there are increased research efforts in a number of countries directed towards developing such capabilities owing to recent advances that have made the computing necessary to support automated driving practical <ref> [1] </ref>. We are studying the problem of autonomous navigation in complex (urban) environments, with an emphasis on perception. We have built a driving simulator which generates photo-realistic images to be used as a testbed for the driving program.
Reference: [2] <author> M. F. Land and D. N. Lee, </author> <title> Where we look when we steer, </title> <journal> Nature, </journal> <volume> vol. 369, </volume> <pages> pp. 742744, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: EYE TRACKING EXPERIMENTS One way to estimate the degree of realism of the simulator is to run experiments that have been performed in the real world and compare the results. Experiments recording eye movements of human drivers <ref> [2] </ref> show that for the task of road following, humans rely particularly on the tangent point on the inside of each curve, fixating it 1-2 seconds before issuing the steering command and constantly returning the gaze to it during the maneuver.
Reference: [3] <author> M. F. Land and S. Furneaux, </author> <title> The knowledge base of the oculomotor system. </title> <institution> Sussex Centre for Neuroscience, School of Biological Sciences, University of Sussex, </institution> <address> Brighton BN1 9QG, UK, </address> <year> 1996. </year>
Reference-contexts: For the left turn on a divided highway the equivalent of the road boundary is the center line, and the tangent point is situated on that line. Other experiments performed by the same researchers <ref> [3] </ref> show that humans are able to switch among several tasks (e.g. to fixate other relevant places in the visual field), which is essential for driving in complex environments such as city streets. A good example presented in their paper is that of a time relative to the first frame.
Reference: [4] <author> D. H. Ballard, M. M. Hayhoe, P. K. Pook, and R. P. N. Rao, </author> <title> Deictic codes for the embodiment of cognition, </title> <type> tech. rep., </type> <institution> University of Rochester, </institution> <year> 1996. </year>
Reference-contexts: In the case of road signs, the relevant information needs to be extracted and the signs should be tracked across frames. Finally in the case of independently moving objects, the agent's priority is to avoid collision. Adopting a deictic standpoint (like in <ref> [4] </ref>) we can consider all these features as discrete events in the world, competing for the agent's attention. A situation then becomes a collection of such events, each having attached a program, a list of actions that should be executed when the event occurs.
Reference: [5] <author> J. A. Michon, </author> <title> A critical view of driver behavior models: what do we know, what should we do ?, in Human Behavior and Traffic Safety, </title> <publisher> Plenum, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Part of the future work would be to estimate the relative efficiency of different such scenarios. The driving task has been characterized as a hierarchy of three levels <ref> [5] </ref>: * Strategic (high level): the global goals are de fined and a route is planned; * Tactical (mid level): driving maneuvers, trying to achieve short-term goals (passing a slower car, negotiating a turn, etc.); * Operational (low level): maneuvers are decomposed into a sequence of control opera tions (tracking a
Reference: [6] <author> D. A. Reece, </author> <title> Selective perception for robot driving, </title> <type> Tech. Rep. </type> <institution> CMU-CS-92-139, Carnegie Mellon University, </institution> <year> 1992. </year>
Reference: [7] <author> R. Sukthankar, D. Pomerleau, and C. Thorpe, Shiva: </author> <title> Simulated highways for intelligent vehicle algorithms, </title> <booktitle> in Proceedings of the Intelligent Vehicles '95 Symposium, </booktitle> <pages> pp. 332337, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: This is equivalent to assuming perfect perception. Table 1: Necessary cues for various behaviors The most relevant related work is represented by two simulators developed at CMU: PHAROS ([6], where perceptual routines were introduced) and SHIVA <ref> [7] </ref>. Both PHAROS and SHIVA were designed for driving systems that focussed on the tactical level. Therefore, the images they generate are used only for animation purposes and the perceptions are simulated.
Reference: [8] <author> G. Salgian and D. Ballard, </author> <title> Visual routines for autonomous driving, </title> <note> To appear in ICCV-98, Bombay, India. </note>
Reference-contexts: A set of image feature (steerable filter responses at different image resolutions) is used to match the potential traffic sign (detected by the color filter) against a stored response. The results of detailed experiments are described in <ref> [8] </ref>. Important insights on the automated system can be obtained by comparing its performance with a human driver. This has been done for stop sign detection.
References-found: 8

