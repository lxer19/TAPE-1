URL: http://seclab.cs.ucdavis.edu/papers/wetmore.thesis.ps
Refering-URL: http://seclab.cs.ucdavis.edu/awb/AuditWorkBench.html
Root-URL: http://www.cs.ucdavis.edu
Title: Paradigms for the Reduction of Audit Trails  
Author: by Bradford Rice Wetmore DAVIS 
Degree: THESIS Submitted in partial satisfaction of the requirements for the degree of MASTER OF SCIENCE in Computer Science in the GRADUATE DIVISION of the  Approved: Committee in Charge  
Affiliation: UNIVERSITY OF CALIFORNIA  
Date: 1989  1993  
Note: B.A. (Humboldt State University)  
Abstract-found: 0
Intro-found: 1
Reference: [Agra90] <author> Hiralal Agrawal and Joseph R. Horgan, </author> <title> "Dynamic Program Slicing," </title> <booktitle> Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: However, some trojan horse attacks do manage to escape auditing, thus frustrating our efforts. 5.7 The Downfall of Slicing One of the original goals of this thesis was to determine the utility of incorporating a debugging technique called slicing <ref> [Weis81, Agra90] </ref> into the analysis of audit trails. A goal of slicing is to use dataflow analysis and graph theory to determine all statements in a program or program segment which might affect the value of a variable.
Reference: [Ande80] <author> James P. Anderson, </author> <title> "Computer Security Threat Monitoring and Surveillance," </title> <type> Technical Report, </type> <address> James P. Anderson Co., Fort Washington, PA, </address> <month> April </month> <year> 1980. </year>
Reference-contexts: the existence of an effective auditing mechanism and a significant risk of getting caught, intruders will continue to operate in relative freedom. 2.3 Auditing for Intrusions 11 The first published work on intrusion detection tried to establish different classes of threats, and how they might be detected using audit data <ref> [Ande80] </ref>. Table 1 summarizes this work: Penetrator Not Authorized to Use Data/Program Resource Penetrator Authorized to Use Data/Program Resource Penetrator Not Authorized Use of Computer Case A: External Penetration none Penetrator Authorized Use of Computer Case B: Internal Penetration Case C: Misfeasance Table 1 Defining Intrusions. <p> Accepting that wiretaps and events outside the computer's realm are not generally auditable, trial and error attacks can be detected by an 12 abnormal amount of unauthorized activity, in the form of repeated failed login attempts. Internal penetration is generally more frequent than external penetration, according to <ref> [Ande80] </ref>. The three types of users in this class are the masquerader, the legitimate user, the clandestine user. The masquerader is a user who impersonates another user. The problem with detecting a masquerader is that there are no particular features which can provide conclusive evidence of masquerading.
Reference: [Bart92] <author> Tony Bartoletti, "SPI," </author> <note> available from irbus.llnl.gov, </note> <institution> Lawrence Livermore National Laboratory, </institution> <year> 1992. </year>
Reference-contexts: Another suggestion is to look for changes in the Operating System files, perhaps with a static analysis tool such as COPS [Farm91] or Lawrence Livermore's Security Profile Inspector <ref> [Bart92] </ref>. Such users have been known to modify system files and programs such as "login" to allow use of a system without detection. 2.4 Audit Trail Formats Audit trails have been implemented in a variety of ways.
Reference: [Bish89] <author> Matt Bishop, </author> <title> "A Model of Security Monitoring," </title> <booktitle> Proceedings of the Fifth Annual Computer Security Applications Conference, </booktitle> <address> Tucson, AZ, </address> <month> December </month> <year> 1989. </year>
Reference-contexts: Auditing is currently used as a tool for several purposes as listed in <ref> [Bish89] </ref>: to restore file systems and databases to known states after crashes, for security purposes, such as documenting intrusions, assessing damage or information disclosed, for electronic funds transfer systems used in banking, and for other types of data processing. In this research we focus primarily on auditing for security purposes. <p> events are required: 1) determine which types of audit data to collect, 2) collect that information, 3) reduce the information to a manageable size by eliminating useless information, 4) analyze the reduced data, 7 5) notify the proper authorities of the results, and 6) take appropriate actions (see Figure 1). <ref> [Bish89] </ref> makes the distinction between logging and auditing. Logging is the process of creating the records, while auditing is the actual review. In the above list of events, logging consists of steps 1 and 2, while the remaining steps make up the auditing stage.
Reference: [Bony81] <author> D. Bonyun, </author> <title> "The Role of a Well Defined Auditing Process in the Enforcement of Privacy Policy and Data Security," </title> <booktitle> Proceedings of the 1982 Symposium on Security and Privacy, </booktitle> <month> April </month> <year> 1981. </year>
Reference-contexts: They scan for "interesting" events, patterns of events, and behavior out of the ordinary, and then they summarize the findings. We also should make the distinction between "passive" and "active" auditing <ref> [Bony81] </ref>. Passive auditing assumes that the logs will be available for inspection, but does not assume that any such analysis will take place unless there is reason.
Reference: [Choi93] <author> Wilson Choi, </author> <type> Master's Thesis, </type> <institution> Department of Computer Science, University of California, Davis, </institution> <address> CA 95616, </address> <year> 1993. </year>
Reference-contexts: For example, there is a project under way at UC Davis to add auditing to Remote Procedure Calls (RPC) and the Network File System (NFS) to the Sun BSM <ref> [Choi93] </ref>. This will significantly enhance intermachine auditing, as RPCs are not audited. 4.3.6 Experimenting With Hard-to-Duplicate Conditions Using the Workbench, we hope to be able to synthesize audit trails. A normal trail with specific attacks embedded inside can be used for testing and debugging audit analysis algorithms.
Reference: [Colu92] <institution> Columbia University Guidelines for Computer Usage, </institution> <note> received from ftp.eff.org: /pub/academic/policies/columbia.edu, October 4, </note> <year> 1992. </year>
Reference-contexts: From Columbia University, we have: "Each user is responsible for insuring that his/her use of the computing facility does not interfere with other users or with proper function of the system" <ref> [Colu92] </ref>. Or from Rice University, we have: "It is expected that all users of University computing resources will use the facilities at their disposal in a manner that is ethical, legal, and responsible. Exercise etiquette and common sense when using the academic computing resources" [Rice92].
Reference: [Deba92] <author> Herve' Debar, Monique Becker, and Didier Siboni, </author> <title> "A Neural Network Component for an Intrusion Detection System," </title> <booktitle> Proceedings of the IEEE Symposium on Security and Privacy, </booktitle> <address> Oakland, CA, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: (incoming audited record is immediately examined), session (marked by login and logout), intermediate (done at the end of a particular type of action, such as a program run), and high level (to prevent attacks from occuring over multiple logins). 3.3 Machine Learning The application of machine learning and neural networks <ref> [Deba92, Doak92, Goan92, Vacc89] </ref> is a relatively new approach to the intrusion detection problem. Machine learning attempts to monitor and learn the normal activities of users. By knowing past events, inductive learning algorithms try to predict later events.
Reference: [Denn86] <author> Dorothy E. Denning, </author> <title> "An Intrusion Detection Model," </title> <booktitle> Proceedings of the IEEE Symposium on Security and Privacy, </booktitle> <month> April </month> <year> 1986. </year>
Reference-contexts: Most auditing systems follow the model of subjects, objects, and actions, as highlighted in <ref> [Denn86] </ref>. Subjects are generally the users of a system (but could be the systems themselves), those entities which initiate actions upon one or more objects. Objects are entities such as files, processes, or devices, and are managed by the system. <p> It is the responsibility of the SSO to examine the raw audit records to determine if indeed the events are indicative of an attack. These systems rely on the premise that there will be statistically significant differences between user behaviors. This idea was first proposed by Denning <ref> [Denn86] </ref>, but has yet to be verified experimentally. (IDES [Javi91] was the best attempt at such a system.) In general computing environments, for this type of anomaly detection it is particularly difficult to define the "normal" user, and what makes a user "suspicious." For this reason, "anomaly detection" seems to be <p> algorithms were also recently modified from strict session boundaries to handle a real-time monitoring capability, and were incorporated into the UC Davis Distributed Intrusion Detection System (DIDS) [Snap91a]. 3.1.2 IDES IDES grew out of work performed earlier by Sytek International [Syte85], and primarily from a model proposed by Dorothy Denning <ref> [Denn86] </ref>. The main goal of IDES is to provide a series of tools which could detect many forms of intrusions. IDES does have an expert system component, but its main contribution is the use of complex statistical 31 computations. <p> An object is any underlying system abstraction we wish to model: for example, users, processes, or files. (This differs from <ref> [Denn86] </ref>, where a separation is made between subjects and objects. For our model, adding subjects into the object class simplifies the analysis.) 55 Most of the analysis programs described in Section 3 model users as the only objects.
Reference: [Denn87] <author> Dorothy E. Denning, David Edwards, R. Jagannathan, Teresa Lunt, and Peter G. Neumann, </author> <title> "A Prototype IDES A Real-Time Intrusion Detection Expert 96 System," </title> <type> Technical Report, </type> <institution> SRI International, </institution> <month> August </month> <year> 1987. </year>
Reference-contexts: These tools do not assist in browsing raw audit trails; they only help to determine which data to examine, which also is far from a definitive solution. The three main approaches are statistical, rule-based expert systems, and machine learning. 3.1 Statistical Methods Automated statistical systems such as SRI's IDES <ref> [Denn87, Javi91] </ref> and Haystack Laboratory's Haystack [Smah88] focus primarily on defining characteristics of a normal user or group, which generally involves a period of training; then they employ statistical measures to determine if a current user's characteristics match his previously observed behavior.
Reference: [Doak92] <author> Justin Edgar Doak, </author> <title> "Intrusion Detection: the Application of Feature Selection, a Comparison of Algorithms, and the Application of a Wide Area Network Analyzer," </title> <type> Master's Thesis, </type> <institution> Department of Computer Science, University of California, </institution> <address> Davis CA 95616, </address> <year> 1992. </year>
Reference-contexts: (incoming audited record is immediately examined), session (marked by login and logout), intermediate (done at the end of a particular type of action, such as a program run), and high level (to prevent attacks from occuring over multiple logins). 3.3 Machine Learning The application of machine learning and neural networks <ref> [Deba92, Doak92, Goan92, Vacc89] </ref> is a relatively new approach to the intrusion detection problem. Machine learning attempts to monitor and learn the normal activities of users. By knowing past events, inductive learning algorithms try to predict later events.
Reference: [Dowe90] <author> Cheri Dowell and Paul Ramstedt, </author> <title> "The ComputerWatch Data Reduction Tool," </title> <booktitle> Proceedings of the 13th National Computer Security Conference, </booktitle> <address> Washington, DC, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: Fortunately, standard compression utilities can offset this bulk. [Sibe88] predicts up to a 8 to 1 compression ratio for highly repetitious data. The tradeoff is classic: ease-of-use versus resource space. The non-self- contained audit records employed by AT&T follows the opposite path <ref> [Dowe90] </ref>. By recording only the minimal amount of state change information, a smaller audit trail results. In the example above, a file access record might only contain the time, effective user name, an abbreviated filename, and return codes. <p> This makes it suitable for real-time intrusion detection. W&S 1.0 and 2.0 were designed for a single host, but W&S 3.0 is designed for a distributed environment, in which several systems are monitored by a single host [McAu90]. 3.2.4 ComputerWatch Audit Trail Analysis Tool AT&T's ComputerWatch tool <ref> [Dowe90] </ref> was designed to summarize audit trails for the AT&T System V/MLS Operating System. (MLS stands for Multi Level Security, which adds Mandatory Access Control to UNIX. This is similar to Sun's CMW.) Again, a priori rules are applied to the audit data, which give the usual security summaries. <p> However, getting and working with the raw audit data is exactly what is required when documenting damage, information flow, or change to a system. The only tool I know of for helping browse audit trails is ComputerWatch for AT&T's MLS <ref> [Dowe90] </ref>. It performs its analysis by formulating the raw data into eight human-readable database files. The exact contents of the files 39 were not apparent in [Dowe90], but they are grouped as follows: exec.tab Process execution information fork.tab Process fork/exit information alias.tab files accesses and link information ipc.tab interprocess communication information <p> The only tool I know of for helping browse audit trails is ComputerWatch for AT&T's MLS <ref> [Dowe90] </ref>. It performs its analysis by formulating the raw data into eight human-readable database files. The exact contents of the files 39 were not apparent in [Dowe90], but they are grouped as follows: exec.tab Process execution information fork.tab Process fork/exit information alias.tab files accesses and link information ipc.tab interprocess communication information syscall.tab system call failure information uli.tab user level information (logins, suid's) io.tab all read/write success/failure information other.tab everything else (mounts, kills, etc.) ComputerWatch approaches modelling as <p> One possible solution would be to include an "object record" the first time an object is seen, along with a cross-reference value which could be used in future references as in the AT&T style of auditing <ref> [Dowe90] </ref>. This "object record" would include all pertinent information relating to this object, its name, its type, and perhaps an ASCII description of the object. Unfortunately, this would require a penalty in performance in the audit daemon, as the daemon must now maintain this information. <p> While auditing cannot solve the problem of detecting all intrusions, it has the potential to help the SSO. But until reasonable methods are available for viewing these audit trails, the potential remains untapped. In this thesis, I have proposed an alternate method to the DBMS method proposed in <ref> [Dowe90] </ref>. Apparently these are the only two models in existence. This method develops system abstractions into objects, and then attempts to develop interconnective links. A UNIX-specific prototype system was developed, and showed great potential. It allowed a SSO to easily monitor the results of several controlled attacks.
Reference: [Farm91] <author> Dan Farmer, "COPS ver 1.04," </author> <note> source available from cert.sei.org, </note> <year> 1991 </year>
Reference-contexts: Another suggestion is to look for changes in the Operating System files, perhaps with a static analysis tool such as COPS <ref> [Farm91] </ref> or Lawrence Livermore's Security Profile Inspector [Bart92]. Such users have been known to modify system files and programs such as "login" to allow use of a system without detection. 2.4 Audit Trail Formats Audit trails have been implemented in a variety of ways. <p> For example, a user modifying the password file to create a new user will only generate file change records. Until the new user logs in, we won't know what change was made. Some of the modification problems would be better handled by static analysis tools such checksumming in COPS <ref> [Farm91] </ref> and SPI. 14) Are there indications of a virus or trojan horse? If the actions caused by the trojan horse or virus are auditable, it is very likely that the SSO would be able to detect attempted changes to system files using the methods 80 described.
Reference: [Garv91] <author> Thomas D. Garvey and Teresa Lunt, </author> <title> "Model-based Intrusion Detection," </title> <booktitle> Proceedings of the 14th National Computer Security Conference, </booktitle> <address> Washington DC, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: In the latest report, the covariance matrix was dropped, mainly because of the huge expense in computation [Wetm92c]. In fact, [Wetm92c] found that the statistical methods in IDES were very similar to Haystack's. 3.2 Rule Based Expert Systems Automated expert systems such as portions of IDES <ref> [Lunt89, Garv91] </ref>, DIDS [Snap91a], Wisdom & Sense (W&S) [Vacc89], and signature analysis [Snap91b] pursue a different approach. Instead of detecting anomalies, these systems attempt "misuse detection" by using a priori rules that are indicative to a human expert of an intrusion.
Reference: [Glig85] <author> Virgil D. Gligor, </author> <title> "Guideline for Trusted Facility Management and Audit," </title> <type> Technical Report, </type> <institution> University of Maryland, </institution> <year> 1985. </year>
Reference-contexts: of Auditing According to [NCSC88], the purposes of the audit mechanism are fivefold, viz. they must: 1) allow the review of patterns of accesses to objects, provide on demand the access histories of specific processes and individuals, and allow the use of the various protection mechanisms supported by the system <ref> [Glig85] </ref>, 2) allow discovery of both user's and outsider's repeated attempts to bypass the protection mechanisms, 3) allow discovery of use of privileges that may occur when a user assumes a functionality with privileges greater than his own, 4) act as a deterrent against perpetrators' habitual attempts to bypass the system <p> may occur when a user assumes a functionality with privileges greater than his own, 4) act as a deterrent against perpetrators' habitual attempts to bypass the system protection mechanisms, and 9 5) supply an additional form of user assurance that attempts to bypass the protection mechanisms are recorded and discovered <ref> [Glig85] </ref>. Unfortunately, a large gap has developed between the original design goals and the resulting implementations. The first goal has been the most underdeveloped. The auditing systems do allow for logging the activities; however, better tools for analyzing the data need to be developed.
Reference: [Goan92] <author> Terrance Lee Goan Jr., </author> <title> "Towards a Dynamic System for Accountability and Intrusion Detection in a Network Environment," </title> <type> Master's Thesis, </type> <institution> Department of Computer Science, University of California, Davis, </institution> <address> CA 95616, </address> <year> 1992. </year>
Reference-contexts: (incoming audited record is immediately examined), session (marked by login and logout), intermediate (done at the end of a particular type of action, such as a program run), and high level (to prevent attacks from occuring over multiple logins). 3.3 Machine Learning The application of machine learning and neural networks <ref> [Deba92, Doak92, Goan92, Vacc89] </ref> is a relatively new approach to the intrusion detection problem. Machine learning attempts to monitor and learn the normal activities of users. By knowing past events, inductive learning algorithms try to predict later events.
Reference: [Hebe91] <institution> Louis Todd Heberlein,"Towards Detecting Intrusions in a Networked Environment," </institution> <type> Master's Thesis, </type> <institution> Department of Computer Science, University of California, Davis, </institution> <address> CA 95616, </address> <year> 1991. </year>
Reference-contexts: There are other systems which provide for some analysis without relying on the system logs. Heberlein's NSM <ref> [Hebe91] </ref> and Clyde-Digital System's Audit [Lunt88] both allow a SSO to collect and analyze data passing through a network or terminal, respectively. They provide a set of warning levels for each session, and tell the SSO why the session was considered suspicious.
Reference: [Javi91] <author> Harold S. Javitz and Al Valdez, </author> <title> "The SRI IDES Statistical Anomaly Detector," </title> <booktitle> Proceedings of the IEEE Symposium on Security and Privacy, </booktitle> <address> Oakland, CA, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: These tools do not assist in browsing raw audit trails; they only help to determine which data to examine, which also is far from a definitive solution. The three main approaches are statistical, rule-based expert systems, and machine learning. 3.1 Statistical Methods Automated statistical systems such as SRI's IDES <ref> [Denn87, Javi91] </ref> and Haystack Laboratory's Haystack [Smah88] focus primarily on defining characteristics of a normal user or group, which generally involves a period of training; then they employ statistical measures to determine if a current user's characteristics match his previously observed behavior. <p> These systems rely on the premise that there will be statistically significant differences between user behaviors. This idea was first proposed by Denning [Denn86], but has yet to be verified experimentally. (IDES <ref> [Javi91] </ref> was the best attempt at such a system.) In general computing environments, for this type of anomaly detection it is particularly difficult to define the "normal" user, and what makes a user "suspicious." For this reason, "anomaly detection" seems to be falling out of favor from some members of the
Reference: [Lunt86] <author> T.F. Lunt, J. van Horne, and L. Halme, </author> <title> "Analysis of Computer System Audit Trails," </title> <institution> Sytek Technical Reports TR-85007, Mountain View, </institution> <address> CA, </address> <month> May </month> <year> 1986. </year>
Reference: [Lunt88] <author> Teresa Lunt, </author> <title> "Automated Audit Trail Analysis and Intrusion Detection: A Survey," </title> <booktitle> Proceedings of the 11th National Computer Security Conference, </booktitle> <month> October </month> <year> 1988. </year> <month> 97 </month>
Reference-contexts: It uses a forward chaining engine and an explanation facility, much like the signature analysis method above. The rules are written in LISP, and can run at 150 inferences per second. At the time the survey paper <ref> [Lunt88] </ref> was written, approximately 40 rules had been encoded. <p> There are other systems which provide for some analysis without relying on the system logs. Heberlein's NSM [Hebe91] and Clyde-Digital System's Audit <ref> [Lunt88] </ref> both allow a SSO to collect and analyze data passing through a network or terminal, respectively. They provide a set of warning levels for each session, and tell the SSO why the session was considered suspicious.
Reference: [Lunt89] <author> Teresa Lunt, R. Jagannathan, Rosanna Lee, Alan Whitehurst, and Sherry Listgarten, </author> <title> "Knowledge-Based Intrusion Detection", </title> <booktitle> Proceedings of the AI Systems in Government Conference, </booktitle> <address> Washington DC, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: In the latest report, the covariance matrix was dropped, mainly because of the huge expense in computation [Wetm92c]. In fact, [Wetm92c] found that the statistical methods in IDES were very similar to Haystack's. 3.2 Rule Based Expert Systems Automated expert systems such as portions of IDES <ref> [Lunt89, Garv91] </ref>, DIDS [Snap91a], Wisdom & Sense (W&S) [Vacc89], and signature analysis [Snap91b] pursue a different approach. Instead of detecting anomalies, these systems attempt "misuse detection" by using a priori rules that are indicative to a human expert of an intrusion.
Reference: [McAu90] <author> Noelle McAuliffe, Dawn Wolcott, Lorrayne Schaefer, Nancy Kelem, Brian Hubbard, and Theresa Haley, </author> <title> "Is Your Computer Being Misused? A Survey of Current Intrusion Detection Technology," </title> <booktitle> Proceedings of the Sixth Annual Computer Security Applications Conference, </booktitle> <address> Tucson, AZ, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: This makes it suitable for real-time intrusion detection. W&S 1.0 and 2.0 were designed for a single host, but W&S 3.0 is designed for a distributed environment, in which several systems are monitored by a single host <ref> [McAu90] </ref>. 3.2.4 ComputerWatch Audit Trail Analysis Tool AT&T's ComputerWatch tool [Dowe90] was designed to summarize audit trails for the AT&T System V/MLS Operating System. (MLS stands for Multi Level Security, which adds Mandatory Access Control to UNIX.
Reference: [NCSC85] <institution> National Computer Security Center, "Department of Defense Trusted Computer System Evaluation Criteria", DoD 5200.28-STD, </institution> <month> December </month> <year> 1985. </year>
Reference-contexts: We can modify Webster's definition of audit to be "a formal examination of records to analyze and document action within a computer system." In the 1980's, the United States Department of Defense published a series of computer security guidelines known as the "Rainbow" series. In particular, <ref> [NCSC85] </ref> (or the "Orange Book"), and [NCSC88] (or the "Tan Book") describe a set of guidelines to which computer systems must adhere to in order to be rated at a certain level of security. In sections relating to accountability, the specifications are clear. <p> The product of such record-keeping is called an "audit trail," and is "a set of records that collectively provide documentary evidence of processing used to aid in tracing from original transactions forward to related records and reports, and/or backwards from records and reports to their component source transactions" <ref> [NCSC85, NCSC88] </ref>. Most auditing systems follow the model of subjects, objects, and actions, as highlighted in [Denn86]. Subjects are generally the users of a system (but could be the systems themselves), those entities which initiate actions upon one or more objects.
Reference: [NCSC88] <institution> National Computer Security Center, </institution> <note> "A Guide to Understanding Audit in Trusted Systems," NCSC-TG-001", Version 2, </note> <month> June </month> <year> 1988. </year>
Reference-contexts: In particular, [NCSC85] (or the "Orange Book"), and <ref> [NCSC88] </ref> (or the "Tan Book") describe a set of guidelines to which computer systems must adhere to in order to be rated at a certain level of security. In sections relating to accountability, the specifications are clear. <p> The product of such record-keeping is called an "audit trail," and is "a set of records that collectively provide documentary evidence of processing used to aid in tracing from original transactions forward to related records and reports, and/or backwards from records and reports to their component source transactions" <ref> [NCSC85, NCSC88] </ref>. Most auditing systems follow the model of subjects, objects, and actions, as highlighted in [Denn86]. Subjects are generally the users of a system (but could be the systems themselves), those entities which initiate actions upon one or more objects. <p> If such events exist, the audit program or the SSO can take immediate action. Options include modifying the level of auditing on a user or file, removing a user from the system, in extreme cases shutting down the system, etc. 2.2 Purposes of Auditing According to <ref> [NCSC88] </ref>, the purposes of the audit mechanism are fivefold, viz. they must: 1) allow the review of patterns of accesses to objects, provide on demand the access histories of specific processes and individuals, and allow the use of the various protection mechanisms supported by the system [Glig85], 2) allow discovery of
Reference: [Neum88] <author> P.G. </author> <title> Neumann, </title> <booktitle> "The Computer-Related Risk of the Year: Computer Abuse", 3rd Annual Conference on Computer Assurance (COMPASS '88), </booktitle> <institution> National Bureau of Standards, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: Hackers will not heed the deterrent of an auditing system, given the combined lack of audit inspections and applicable legislation. This is the so-called social gap between social policies and actual human behavior <ref> [Neum88] </ref>. Prosecution is expensive, and usually undertaken only in extreme circumstances. In addition, previous laws were not conceived to cover the types of computing currently in use.
Reference: [Picc87] <author> Jeffrey Piccioto, </author> <title> "The Design of an Effective Auditing Subsystem," </title> <booktitle> Proceedings of the IEEE Symposium on Security and Privacy, </booktitle> <month> April </month> <year> 1987. </year>
Reference-contexts: As the data being processed became more sensitive and expensive, the need for security became critical. Unfortunately, many early systems tried to apply techniques from the accounting analysis domain into security. Experience shows that many of these techniques are not easily adaptable <ref> [Picc87] </ref>. Computer security issues have become extremely important in many organizations. Virtually every day we witness news stories of an invaded government machine, a person who was harassed because of certain information maintained in a computer, or in which some company's accounting data was destroyed by a malicious program. <p> If auditing is enabled, an audit record is created. Control is then transferred to the kernel, which then completes the system call. When control returns, syscall () notes the return values if any; then it updates and writes the audit record before exiting <ref> [Picc87] </ref>. 16 There are two major models for auditing, viz. application level and kernel level, and each has different properties. <p> This extra data only obfuscates the user's intentions <ref> [Picc87] </ref>. An application level auditor need only report that an editor was used to modify a specific file, and perhaps the actual data that was modified. However, this requires that the application program be trusted to properly report actions, which opens up the possibility of many vulnerabilities not being reported. <p> The SSO can set this state by a series of software switches, generally based on the type of auditing required. 18 <ref> [Picc87] </ref> has estimated that a Compartmented Mode Workstation (CMW) can generate up to 135 megabytes/user/day. Obviously, unless significant system resources are available, logging must be performed selectively.
Reference: [Rice92] <institution> Rice University Guidelines for Computer Usage, </institution> <note> received from ftp.eff.org: /pub/academic/policies/rice.edu, October 4, </note> <year> 1992. </year>
Reference-contexts: Or from Rice University, we have: "It is expected that all users of University computing resources will use the facilities at their disposal in a manner that is ethical, legal, and responsible. Exercise etiquette and common sense when using the academic computing resources" <ref> [Rice92] </ref>. As a result, it becomes a challenge to determine if actions violate policy. If we could develop and specify a policy language, we could take a big step to determine what kind of audit data is required for effective auditing.
Reference: [Sebr88] <author> Michael M. Sebring, Eric Shellhouse, Mary E. Hanna, and R. Alan Whitehurst, </author> <title> "Expert Systems in Intrusion Detection: A Case Study," </title> <booktitle> Proceedings of the 11th National Computer Security Conference, </booktitle> <address> Washington DC, </address> <month> October </month> <year> 1988. </year>
Reference-contexts: It then becomes a simple matter to traverse the states as the audit actions are observed. Intuitively, the mechanism holds promise, but currently only simple signatures have been implemented. 3.2.2 MIDAS MIDAS also attempts to encode a priori rules that define an intrusion <ref> [Sebr88] </ref>. This system is under 34 development at the National Computer Security Center (NCSC), A creates executable B runs executable B modifies .rhosts file Executable removed no change to .rhosts A runs as B and is designed to monitor a Multics system.
Reference: [Sibe88] <author> W. Olin Sibert, </author> <title> "Auditing in a Distributed System: SunOS MLS Audit Trails," </title> <booktitle> Proceedings of the 11th National Computer Security Conference, </booktitle> <month> October </month> <year> 1988. </year>
Reference-contexts: However, this method generates a large amount of data, namely because the information contained in repeated references to this file will be repeated in each audit record. Fortunately, standard compression utilities can offset this bulk. <ref> [Sibe88] </ref> predicts up to a 8 to 1 compression ratio for highly repetitious data. The tradeoff is classic: ease-of-use versus resource space. The non-self- contained audit records employed by AT&T follows the opposite path [Dowe90]. By recording only the minimal amount of state change information, a smaller audit trail results. <p> Therefore, a similar format was also used in each of the respective formats. <ref> [Sibe88] </ref> lists the design goals that were met using the token format, namely the expendability by third party vendors of the audit trail event and token types as well as the minimal changes to any existing or future audit analysis software. <p> Because the 23 audit tokens are self-contained, an analysis program can work regardless of the auditing style of the system generating the messages <ref> [Sibe88] </ref>. 2.8 Problems with Audit Analysis In addition to the problems discussed earlier, the major obstacle in developing effective analysis tools is the copious amounts of data that logging mechanisms generate.
Reference: [Smah88] <author> Stephen E. Smaha, "Haystack: </author> <title> An Intrusion Detection System," </title> <booktitle> Proceedings of the IEEE Fourth Aerospace Computer Security Applications Conference, </booktitle> <address> Orlando, FL, </address> <month> December </month> <year> 1988. </year>
Reference-contexts: The three main approaches are statistical, rule-based expert systems, and machine learning. 3.1 Statistical Methods Automated statistical systems such as SRI's IDES [Denn87, Javi91] and Haystack Laboratory's Haystack <ref> [Smah88] </ref> focus primarily on defining characteristics of a normal user or group, which generally involves a period of training; then they employ statistical measures to determine if a current user's characteristics match his previously observed behavior. <p> This predetermination is usually done in an ad-hoc manner. However, only anomaly detection can catch masqueradors, unless the perpetrator takes actions which are easily caught. 3.1.1 Haystack Haystack <ref> [Smah88] </ref> is a monitoring system originally designed to collect audit trails from a single Unisys (Sperry) 1100/60 mainframe, and perform the analysis on a personal computer. The data is first transformed into a Canonical Audit Trail, which is an attempt to define a system independent audit trail.
Reference: [Snap91a] <author> Steven R. Snapp, James Brentano, Gihan Dias, Terrance Goan, Louis Todd Heberlein, Che-lin Ho, 98 Karl Levitt, Biswanath Mukherjee, Stephen Smaha, Tim Grance, Daniel Teal, and Douglas Mansur, </author> <title> "DIDS (Distributed Intrusion Detection System) - Motivation, Architecture, and An Early Prototype", </title> <booktitle> Proceedings of the 14th National Computer Security Conference, </booktitle> <address> Washington DC, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: This requires a good audit browser or a lot of patience, two things missing in current analysis systems! 15 Since UC Davis uses the Sun BSM package for its Distributed Intrusion Detection System <ref> [Snap91a] </ref>, most of the discussion that follows will be Sun-based. 2.5 Methods of Data Collection My experience is in software based auditing systems only, but it would not be too difficult to develop hardware based packages as well. <p> Haystack's algorithms were also recently modified from strict session boundaries to handle a real-time monitoring capability, and were incorporated into the UC Davis Distributed Intrusion Detection System (DIDS) <ref> [Snap91a] </ref>. 3.1.2 IDES IDES grew out of work performed earlier by Sytek International [Syte85], and primarily from a model proposed by Dorothy Denning [Denn86]. The main goal of IDES is to provide a series of tools which could detect many forms of intrusions. <p> In the latest report, the covariance matrix was dropped, mainly because of the huge expense in computation [Wetm92c]. In fact, [Wetm92c] found that the statistical methods in IDES were very similar to Haystack's. 3.2 Rule Based Expert Systems Automated expert systems such as portions of IDES [Lunt89, Garv91], DIDS <ref> [Snap91a] </ref>, Wisdom & Sense (W&S) [Vacc89], and signature analysis [Snap91b] pursue a different approach. Instead of detecting anomalies, these systems attempt "misuse detection" by using a priori rules that are indicative to a human expert of an intrusion. <p> The unified View should be constructed such that an IDS algorithm using the View cannot distinguish between the two audit generators. This horizontal layer test in Figure 7 ensures that the layers' concept works with heterogeneous auditing systems. As an example, UCD's DIDS <ref> [Snap91a] </ref> is primarily concerned with users, host machines, and their interconnections over a network. Details about the file system, user processes, or activities which are strictly local to the hosts are generally irrelevant to DIDS's analysis algorithms.
Reference: [Snap91b] <author> Steven Ray Snapp, </author> <title> "Signature Analysis and Communication Issues in a Distributed Intrusion Detection System," </title> <type> Master's Thesis, </type> <institution> Department of Computer Science, University of California, </institution> <address> Davis CA 95616, </address> <year> 1991. </year>
Reference-contexts: In fact, [Wetm92c] found that the statistical methods in IDES were very similar to Haystack's. 3.2 Rule Based Expert Systems Automated expert systems such as portions of IDES [Lunt89, Garv91], DIDS [Snap91a], Wisdom & Sense (W&S) [Vacc89], and signature analysis <ref> [Snap91b] </ref> pursue a different approach. Instead of detecting anomalies, these systems attempt "misuse detection" by using a priori rules that are indicative to a human expert of an intrusion. These systems rely on the premise that intruders have distinct methods of operation, and use unique signatures to penetrate systems. <p> In addition, most systems are hand-crafted, meaning that an expert's knowledge must be extracted, codified, and documented. This process can take a great deal of energy. 3.2.1 Signature Analysis <ref> [Snap91b] </ref> explored the idea of applying a concept called signature analysis to intrusion detection. Snapp 33 proposed a method for utilizing finite state automata to determine whether a specific attack is under way.
Reference: [SUN91] <author> Sun Microsystems, Inc., "Installing, </author> <title> Administering, and Using the Basic Security Module", </title> <month> December </month> <year> 1991. </year>
Reference-contexts: Two major styles are in use, delineated by the type of information contained in each record. The self-contained style, used in the Sun Microsystems' Basic Security Module (BSM) <ref> [SUN91] </ref> requires that each record list all the "interesting" properties of all subjects and objects involved.
Reference: [Syte85] <author> Sytek, Inc. </author> <title> "Analysis of Computer System Audit Trails," </title> <type> Technical Reports 85009, 85012, 85018, 86005, </type> <institution> and 86007, Mountain View, </institution> <address> CA, </address> <pages> 1985-1986. </pages>
Reference-contexts: Haystack's algorithms were also recently modified from strict session boundaries to handle a real-time monitoring capability, and were incorporated into the UC Davis Distributed Intrusion Detection System (DIDS) [Snap91a]. 3.1.2 IDES IDES grew out of work performed earlier by Sytek International <ref> [Syte85] </ref>, and primarily from a model proposed by Dorothy Denning [Denn86]. The main goal of IDES is to provide a series of tools which could detect many forms of intrusions. IDES does have an expert system component, but its main contribution is the use of complex statistical 31 computations.
Reference: [Vacc89] <author> H.S. Vaccaro and G.E. Liepins, </author> <title> "Detection of Anomalous Computer Session Activity," </title> <booktitle> Proceedings of the IEEE Symposium on Security and Privacy, </booktitle> <month> May </month> <year> 1989. </year>
Reference-contexts: In fact, [Wetm92c] found that the statistical methods in IDES were very similar to Haystack's. 3.2 Rule Based Expert Systems Automated expert systems such as portions of IDES [Lunt89, Garv91], DIDS [Snap91a], Wisdom & Sense (W&S) <ref> [Vacc89] </ref>, and signature analysis [Snap91b] pursue a different approach. Instead of detecting anomalies, these systems attempt "misuse detection" by using a priori rules that are indicative to a human expert of an intrusion. <p> attacks: attempted break-ins (by authentication failures, unusual originating hosts, etc.), masqueraders (unusual times, locations, commands, etc.), penetrators (sensitive commands, unauthorized commands, sensitive objects, etc.), misuse (overuse of resources), and trojan horses and viruses which modify system files and programs by unusual execution of predictable commands. 3.2.3 Wisdom & Sense W&S <ref> [Vacc89] </ref> is a system under development at Los Alamos National Laboratory. It tries to combine statistical methods, machine learning, and rule-based expert systems. Given a set of training data, W&S tries to create rules regarding the observed behavior. <p> (incoming audited record is immediately examined), session (marked by login and logout), intermediate (done at the end of a particular type of action, such as a program run), and high level (to prevent attacks from occuring over multiple logins). 3.3 Machine Learning The application of machine learning and neural networks <ref> [Deba92, Doak92, Goan92, Vacc89] </ref> is a relatively new approach to the intrusion detection problem. Machine learning attempts to monitor and learn the normal activities of users. By knowing past events, inductive learning algorithms try to predict later events.
Reference: [Webs86] <institution> Webster's Ninth New Collegiate Dictionary, Merriam-Webster Inc., </institution> <address> Springfield, Mass. </address> <year> 1986. </year>
Reference-contexts: This work led to 4 a more general idea for a browser, which is presented as a proposal. After these initial experiences, the construction of an audit browser would be very straightforward, and could make the SSO's job of browsing audit trails much easier. 5 2 Background <ref> [Webs86] </ref> defines an audit as a formal examination of an organization's or individual's accounts or financial situation.
Reference: [Weis81] <author> Mark Weiser, </author> <title> "Program Slicing," </title> <journal> CH1627-9/81/0000/0439, IEEE, </journal> <year> 1981. </year>
Reference-contexts: However, some trojan horse attacks do manage to escape auditing, thus frustrating our efforts. 5.7 The Downfall of Slicing One of the original goals of this thesis was to determine the utility of incorporating a debugging technique called slicing <ref> [Weis81, Agra90] </ref> into the analysis of audit trails. A goal of slicing is to use dataflow analysis and graph theory to determine all statements in a program or program segment which might affect the value of a variable.
Reference: [Wetm92a] <author> Brad R. Wetmore, </author> <title> conversations with Gregory Elkinbard of Sun Microsystems during UC Davis' workshop on "Future Directions in Computer Misuse and Anomaly Detection," </title> <address> Davis, CA, </address> <month> April 2, </month> <year> 1992. </year>
Reference-contexts: Logging mechanisms generate single records as events occur, with no attempt made to link related records. System vendors such as Sun Microsystems have stated their job is only to provide the mechanisms for producing audit trails <ref> [Wetm92a] </ref>. (However, new initiatives taken by Sun may reverse this trend. Increasingly, management has begun to see the advantages to providing additional tools to help in the system administrator's role.) But for now, further analysis remains the responsibility of the customer.
Reference: [Wetm92b] <author> Brad R. Wetmore, </author> <title> conversations with Teresa Lunt of SRI International during UC Davis' workshop on "Future Directions in Computer Misuse and Anomaly Detection," </title> <address> Davis, CA, </address> <month> April 2, </month> <year> 1992. </year>
Reference-contexts: And, from individual conversations with Teresa Lunt, the project leader for IDES, IDES has not had a successful record of intrusion detection due to the high number of false conclusions reached <ref> [Wetm92b] </ref>. Both development efforts have the same problem with defining 29 exactly what makes a user "suspicious." The ability to accurately discriminate between normal and suspicious behavior highly depends on how widely the user's behavior varies.
Reference: [Wetm92c] <author> Brad R. Wetmore, </author> <title> conversations with L. </title> <institution> Todd Heberlein of UC Davis, Davis, </institution> <address> CA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: The original IDES prototype used several types of measures, and unlike Haystack, employed a covariance matrix to account for the interconnectedness of the variables used. IDES has changed much during its development. In the latest report, the covariance matrix was dropped, mainly because of the huge expense in computation <ref> [Wetm92c] </ref>. In fact, [Wetm92c] found that the statistical methods in IDES were very similar to Haystack's. 3.2 Rule Based Expert Systems Automated expert systems such as portions of IDES [Lunt89, Garv91], DIDS [Snap91a], Wisdom & Sense (W&S) [Vacc89], and signature analysis [Snap91b] pursue a different approach. <p> IDES has changed much during its development. In the latest report, the covariance matrix was dropped, mainly because of the huge expense in computation <ref> [Wetm92c] </ref>. In fact, [Wetm92c] found that the statistical methods in IDES were very similar to Haystack's. 3.2 Rule Based Expert Systems Automated expert systems such as portions of IDES [Lunt89, Garv91], DIDS [Snap91a], Wisdom & Sense (W&S) [Vacc89], and signature analysis [Snap91b] pursue a different approach.

References-found: 40

