URL: http://www.cs.ualberta.ca/~greiner/PAPERS/accurate.ps
Refering-URL: http://www.cs.ualberta.ca/~greiner/PAPERS/
Root-URL: 
Email: greiner@learning.siemens.com  dale@cs.toronto.edu  
Title: Learning an Optimally Accurate Representational System  
Author: Russell Greiner Dale Schuurmans 
Date: August 1992.  
Note: (ed: Gerhard Lakemeyer Bernhard Nebel), Vienna,  
Address: 755 College Road East Princeton, NJ 08540-6632  Toronto, Ontario M5S 1A4  
Affiliation: Siemens Corporate Research  Department of Computer Science University of Toronto  
Abstract: The multiple extension problem arises because a default theory can use different subsets of its defaults to propose different, mutually incompatible, answers to some queries. This paper presents an algorithm that uses a set of observations to learn a credulous version of this default theory that is (essentially) "optimally accurate". In more detail, we can associate a given default theory with a set of related credulous theories R = fR i g, where each R i uses its own total ordering of the defaults to determine which single answer to return for each query. Our goal is to select the credulous theory that has the highest "expected accuracy", where each R i 's expected accuracy is the probability that the answer it produces to a query will correspond correctly to the world. Unfortunately, a theory's expected accuracy depends on the distribution of queries, which is usually not known. Moreover, the task of identifying the optimal R opt 2 R, even given that distribution information, is intractable. This paper presents a method, OptAcc, that sidesteps these problems by using a set of samples to estimate the unknown distribution, and by hill-climbing to a local optimum. In particular, given any parameters *; ffi &gt; 0, OptAcc produces an R oa 2 R whose expected accuracy is, with probability at least 1 ffi, within * of a local optimum. Appeared in ECAI Workshop on Theoretical Foundations of Knowledge Representation and Reasoning, 
Abstract-found: 1
Intro-found: 1
Reference: [Bol85] <author> B. Bollobas. </author> <title> Random Graphs. </title> <publisher> Academic Press, </publisher> <year> 1985. </year>
Reference-contexts: C [ j+1 ] &gt; C [ j ]. As each query q i is selected inde-pendently according to some fixed distribution, Chernoff bounds <ref> [Che52, Bol85] </ref> show that the observed sample average, 1 k i=1 c ( ff ; q i ), converges exponentially fast to the population mean, C [ ff ].
Reference: [Bre89] <author> G. Brewka. </author> <title> Preferred subtheories: An extended logical framework for default reasoning. </title> <booktitle> In IJCAI-89, </booktitle> <year> 1989. </year>
Reference-contexts: To be useful, our representational system must return but a single answer. We therefore focus on a credulous form of such theories, formed by embellishing each default theory with an ordering on the defaults <ref> [vA90, Bre89] </ref>, with the understanding that only the most preferred defaults (s) will be used to reach a unique answer to each query; see Section 2. 1 The obvious question then arises: what is the best ordering of the defaults? We provide the obvious pragmatic answer: use the ordering that is <p> a score of +1, 0, or 1, respectively: c (R i ; q) = +1 if R i (q) = O 0 [ q ] 1 otherwise While many parts of this analysis apply in general, this paper will focus on a particular type of stratified Theorist-style representational system [PGA86] <ref> [Bre89, vA90] </ref>: Here, each R i can be expressed as a set of factual information, a set of allowed hypotheses (each a simple type of default) and a specific ordering of the hypotheses.
Reference: [CG91] <author> W. Cohen and R. Greiner. </author> <title> Probabilistic hill climbing. </title> <booktitle> In CLNL-91, </booktitle> <year> 1991. </year>
Reference-contexts: However, if this process is decidable (e.g., if we are dealing with propositional theories), then OptAcc will terminate with probability 1, as the space of strategies is finite; see <ref> [CG91] </ref>. Finally, each iteration in the OptAcc algorithm is polytime if the F [ fh i g j= ? q k computation is polytime; e.g., if we are dealing with propositional Horn theories or propositional 2-CNF, etc. Note3.
Reference: [Che52] <author> H. Chernoff. </author> <title> A measure of asymptotic efficiency for tests of a hypothesis based on the sums of observations. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 23 </volume> <pages> 493-507, </pages> <year> 1952. </year>
Reference-contexts: C [ j+1 ] &gt; C [ j ]. As each query q i is selected inde-pendently according to some fixed distribution, Chernoff bounds <ref> [Che52, Bol85] </ref> show that the observed sample average, 1 k i=1 c ( ff ; q i ), converges exponentially fast to the population mean, C [ ff ].
Reference: [Coh90] <author> W. Cohen. </author> <title> Learning from textbook knowledge: A case study. </title> <booktitle> In AAAI-90, </booktitle> <year> 1990. </year>
Reference-contexts: Note5. This paper considers only one type of transformation to convert one representational system into another | viz., by rearranging the set of hypotheses. There are many other approaches, e.g., by eliminating some inappropriate sets of hypotheses <ref> [Coh90, Won91] </ref>, or by modifying the antecedents of individual rules (cf., [OM90]), etc. Each of these approaches can be viewed as using a set of transformations to navigate around a space of interrelated representational systems.
Reference: [DB88] <author> T. Dean and M. Boddy. </author> <title> An analysis of time-dependent planning. </title> <booktitle> In AAAI-88, </booktitle> <year> 1988. </year>
Reference-contexts: Note3. If we set * = 0, the OptAcc (R 0 ; 0; ffi) process will not terminate. Its behavior is still quite useful: it will, with high probability, produce a series of better and better strategies. Indeed, we can view this system as an anytime algorithm <ref> [DB88] </ref> as, at any time, it will return a workable result (here, the ordering produced at the j th iteration, j ), with the property that the longer we wait, the better the result. Note4.
Reference: [GE91] <author> R. Greiner and C. Elkan. </author> <title> Measuring and improving the effectiveness of representations. </title> <booktitle> In IJCAI-91, </booktitle> <year> 1991. </year>
Reference-contexts: This would allow the user to prefer, for example, a performance system that returns IDK in complex situations, rather than spend a long time returning the correct answer; or even allow it to be wrong in some instances <ref> [GE91] </ref>. The OptAcc-variant may have to consider other transformations, besides the simple "reordering the hypotheses" one discussed above.
Reference: [GJ92] <author> R. Greiner and I. Jurisica. </author> <title> A statistical approach to solving the EBL utility problem. </title> <booktitle> In AAAI-92, </booktitle> <address> San Jose, </address> <year> 1992. </year>
Reference-contexts: There can, in some situations, be more efficient ways of estimating these values, for example, by using some Horn approximation to F [ fh i g; see [Gre92] and <ref> [GJ92] </ref>. We can also simplify the computation if the h j hypotheses are not independent; e.g., if each corresponds to a set of sub-hypotheses. Note5. This paper considers only one type of transformation to convert one representational system into another | viz., by rearranging the set of hypotheses.
Reference: [GO91] <author> R. Greiner and P. Orponen. </author> <title> Probably approximately optimal derivation strategies. </title> <address> KR-91, </address> <year> 1991. </year>
Reference-contexts: In some simple cases, we may be able to identify (an approximation to) the globally optimal element with high probability (a la the pao algorithm discussed in <ref> [OG90, GO91] </ref>). In most cases, however, this identification task is intractable.
Reference: [Gre92] <author> R. Greiner. </author> <title> Learning near optimal horn approximations. </title> <booktitle> In Knowledge Assimilation Symposium, </booktitle> <year> 1992. </year>
Reference-contexts: There can, in some situations, be more efficient ways of estimating these values, for example, by using some Horn approximation to F [ fh i g; see <ref> [Gre92] </ref> and [GJ92]. We can also simplify the computation if the h j hypotheses are not independent; e.g., if each corresponds to a set of sub-hypotheses. Note5. This paper considers only one type of transformation to convert one representational system into another | viz., by rearranging the set of hypotheses.
Reference: [Gro91] <editor> B. Grosof. Generalizing prioritization. In KR-91, </editor> <year> 1991. </year>
Reference-contexts: Note1. Our descriptions have assumed that every ordering of hypotheses is meaningful. In some contexts, there may already be a meaningful partial ordering of the hypotheses, perhaps based on specificity or some other criteria <ref> [Gro91] </ref>. Here, we can still use Op-tAcc to complete the partial ordering, by determining the relative priorities of the initially incomparable elements.
Reference: [GS92] <author> R. Greiner and D. Schuurmans. </author> <title> Producing more accurate representational systems. </title> <type> TR, </type> <institution> Siemens Corporate Research, </institution> <year> 1992. </year>
Reference-contexts: If there are several compatible binding lists, then R will select and return one of them; see extended paper <ref> [GS92] </ref>. is the hypothesis set, and and A = hh 1 ; h 2 i is the hypothesis ordering. 5 To explain how R A would process a query, imagine we want to know the color of Zelda | i.e., we want to find a binding for ?c such that = <p> This section first states the fundamental theorem that specifies Op-tAcc's functionality. It then discusses OptAcc's code and presents some elaborations and extensions to the algorithm. 7 All proofs appear in the expanded version <ref> [GS92] </ref>. Algorithm OptAcc ( hF; H; 0 i; *; ffi ) * ` 0 k 1 L1: Let S fg Neigh f t i;j ( ` ) g i;j L2: Get query/answer hq k ; a k i from oracle O. <p> The extended paper <ref> [GS92] </ref> discusses how to compute the values of P for each t ij` 2 T . Note1. Our descriptions have assumed that every ordering of hypotheses is meaningful.
Reference: [Hau88] <author> D. Haussler. </author> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <journal> Artificial Intelligence, </journal> <year> 1988. </year>
Reference-contexts: This is called the "multiple extension problem" in the knowledge representation community, and the "bias problem" in machine learning. In each, it has produced a great deal of attention and debate; cf., [Rei87] <ref> [Mit80, RG87, Hau88] </ref>. To be useful, our representational system must return but a single answer.
Reference: [Mit80] <author> T. Mitchell. </author> <title> The need for bias in learning generalizations. </title> <type> TR CBM-TR-117, </type> <year> 1980. </year>
Reference-contexts: This is called the "multiple extension problem" in the knowledge representation community, and the "bias problem" in machine learning. In each, it has produced a great deal of attention and debate; cf., [Rei87] <ref> [Mit80, RG87, Hau88] </ref>. To be useful, our representational system must return but a single answer.
Reference: [OG90] <author> P. Orponen and R. Greiner. </author> <title> On the sample complexity of finding good search strategies. </title> <booktitle> In COLT-90, </booktitle> <year> 1990. </year>
Reference-contexts: In some simple cases, we may be able to identify (an approximation to) the globally optimal element with high probability (a la the pao algorithm discussed in <ref> [OG90, GO91] </ref>). In most cases, however, this identification task is intractable.
Reference: [OM90] <author> D. Ourston and R. Mooney. </author> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <type> TR, </type> <institution> Dept of Computer Science, University of Texas, </institution> <year> 1990. </year>
Reference-contexts: Note5. This paper considers only one type of transformation to convert one representational system into another | viz., by rearranging the set of hypotheses. There are many other approaches, e.g., by eliminating some inappropriate sets of hypotheses [Coh90, Won91], or by modifying the antecedents of individual rules (cf., <ref> [OM90] </ref>), etc. Each of these approaches can be viewed as using a set of transformations to navigate around a space of interrelated representational systems. We can then consider the same objective described above: to identify which element has the highest expected accuracy.
Reference: [PGA86] <author> D. Poole, R. Goebel, and R. Aleliunas. </author> <title> Theorist: A logical reasoning system for default and diagnosis. </title> <type> TR CS-86-06, </type> <year> 1986. </year>
Reference-contexts: query a score of +1, 0, or 1, respectively: c (R i ; q) = +1 if R i (q) = O 0 [ q ] 1 otherwise While many parts of this analysis apply in general, this paper will focus on a particular type of stratified Theorist-style representational system <ref> [PGA86] </ref> [Bre89, vA90]: Here, each R i can be expressed as a set of factual information, a set of allowed hypotheses (each a simple type of default) and a specific ordering of the hypotheses.
Reference: [Rei87] <author> R. Reiter. </author> <title> Nonmonotonic reasoning. </title> <booktitle> In Annual Review of Computing Sciences, </booktitle> <volume> volume 2, </volume> <year> 1987. </year>
Reference-contexts: Unfortunately, there can often be more than one such hypothesis, and these hypotheses (and hence the conclusions they respectively entail) may not be compatible; consider for example the Nixon diamond <ref> [Rei87, p155] </ref>. This is called the "multiple extension problem" in the knowledge representation community, and the "bias problem" in machine learning. In each, it has produced a great deal of attention and debate; cf., [Rei87] [Mit80, RG87, Hau88]. To be useful, our representational system must return but a single answer. <p> This is called the "multiple extension problem" in the knowledge representation community, and the "bias problem" in machine learning. In each, it has produced a great deal of attention and debate; cf., <ref> [Rei87] </ref> [Mit80, RG87, Hau88]. To be useful, our representational system must return but a single answer.
Reference: [RG87] <author> S. Russell and Benjamin N. Grosof. </author> <title> A declarative approach to bias in concept learning. </title> <booktitle> In AAAI-87, </booktitle> <year> 1987. </year>
Reference-contexts: This is called the "multiple extension problem" in the knowledge representation community, and the "bias problem" in machine learning. In each, it has produced a great deal of attention and debate; cf., [Rei87] <ref> [Mit80, RG87, Hau88] </ref>. To be useful, our representational system must return but a single answer.
Reference: [Sha89] <author> L. Shastri. </author> <title> Default reasoning in semantic networks: A formalization of recognition and inheritance. </title> <journal> Artificial Intelligence, </journal> <volume> 39 </volume> <pages> 283-355, </pages> <year> 1989. </year>
Reference-contexts: Here, a representational system that accepts the N AE (Z 15 ) hypothesis will produce the answer IDK to the query S (Z 15 ; y). Note7. The motivation underlying this work is similar to the research of <ref> [Sha89] </ref> and others, who also use probabilistic information to order the various default rules.
Reference: [SK75] <author> H. Simon and J. Kadane. </author> <title> Optimal problem-solving search: All-or-none solutions. </title> <journal> Artificial Intelligence, </journal> <volume> 6 </volume> <pages> 235-247, </pages> <year> 1975. </year>
Reference: [Smi89] <author> D. Smith. </author> <title> Controlling backward inference. </title> <journal> Artificial Intelligence, </journal> <volume> 39(2) </volume> <pages> 145-208, </pages> <month> June </month> <year> 1989. </year>
Reference: [vA90] <author> P. van Arragon. </author> <title> Nested default reasoning with priority levels. </title> <booktitle> In CSCSI-90, </booktitle> <year> 1990. </year>
Reference-contexts: To be useful, our representational system must return but a single answer. We therefore focus on a credulous form of such theories, formed by embellishing each default theory with an ordering on the defaults <ref> [vA90, Bre89] </ref>, with the understanding that only the most preferred defaults (s) will be used to reach a unique answer to each query; see Section 2. 1 The obvious question then arises: what is the best ordering of the defaults? We provide the obvious pragmatic answer: use the ordering that is <p> a score of +1, 0, or 1, respectively: c (R i ; q) = +1 if R i (q) = O 0 [ q ] 1 otherwise While many parts of this analysis apply in general, this paper will focus on a particular type of stratified Theorist-style representational system [PGA86] <ref> [Bre89, vA90] </ref>: Here, each R i can be expressed as a set of factual information, a set of allowed hypotheses (each a simple type of default) and a specific ordering of the hypotheses.
Reference: [Vor91] <author> D. Vormittag. </author> <title> Evaluating answers to questions, </title> <month> May </month> <year> 1991. </year> <type> Bachelors Thesis, </type> <institution> University of Toronto. </institution>
Reference-contexts: As another situation, we may be able to rank responses in terms of their precision: e.g., knowing that the cost of watch 7 is $10;000 is more precise than knowing only that watch 7 is expensive <ref> [Vor91] </ref>.) We have also assumed that all queries are equally important; i.e., a wrong answer to any query "costs" us the same 1, whether we are asking for the location of a salt-shaker, or of the tiger currently stalking us.
Reference: [Won91] <author> J. Wong. </author> <title> Improving the accuracy of a representational system, </title> <month> May </month> <year> 1991. </year> <type> Bachelors Thesis, </type> <institution> University of Toronto. </institution>
Reference-contexts: Note5. This paper considers only one type of transformation to convert one representational system into another | viz., by rearranging the set of hypotheses. There are many other approaches, e.g., by eliminating some inappropriate sets of hypotheses <ref> [Coh90, Won91] </ref>, or by modifying the antecedents of individual rules (cf., [OM90]), etc. Each of these approaches can be viewed as using a set of transformations to navigate around a space of interrelated representational systems.
References-found: 25

