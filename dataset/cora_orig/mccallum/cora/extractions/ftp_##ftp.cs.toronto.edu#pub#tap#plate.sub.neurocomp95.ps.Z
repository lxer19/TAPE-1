URL: ftp://ftp.cs.toronto.edu/pub/tap/plate.sub.neurocomp95.ps.Z
Refering-URL: http://www.cs.utoronto.ca/~tap/
Root-URL: 
Email: tap@epi.terryfox.ubc.ca  
Title: Networks which learn to store variable-length sequences in a fixed set of unit activations  
Author: Tony A. Plate 
Date: 22 March 1995  
Address: 2216 Main Mall Vancouver BC Canada V6T 1Z4  
Affiliation: Dept of Chemical Engineering University of British Columbia  
Abstract: A method for storing sequences of varying lengths in a fixed-width vector is described. The method is implemented, in an adaptive form, in a recurrent network which learns to generate sequences. The performance of this network is compared with that of a more conventional recurrent network on the same task.
Abstract-found: 1
Intro-found: 1
Reference: <author> Davis, P. J. </author> <year> 1979. </year> <title> Circulant matrices. </title> <publisher> John Wiley & Sons, </publisher> <address> New York. </address>
Reference: <author> Elman, J. </author> <year> 1991. </year> <title> Distributed representations, simple recurrent networks and grammatical structure. </title> <journal> Machine Learning, </journal> 7(2/3):195-226. 
Reference: <author> Hinton, G. E. </author> <year> 1986. </year> <title> Learning distributed representations of concepts. </title> <booktitle> In Proc. Eighth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 1-12. </pages> <address> Hillsdale, NJ: </address> <publisher> Erlbaum. </publisher>
Reference: <author> Hopfield, J. J. </author> <year> 1982. </year> <title> Neural networks and physical systems with emergent collective computational abilities. </title> <booktitle> Proceedings of the National Academy of Sciences U.S.A., </booktitle> <volume> 79 </volume> <pages> 2554-2558. </pages>
Reference: <author> Maskara, A. and Noetzel, A. </author> <year> 1992. </year> <title> Forcing simple recurrent neural networks to encode context. </title> <booktitle> In Proceedings of the 1992 Long Island Conference on Artificial Intelligence and Computer Graphics. </booktitle>
Reference: <author> Plate, T. A. </author> <year> 1994. </year> <title> Distributed Representations and Nested Compositional Structure. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Toronto. </institution>
Reference: <author> Plate, T. A. </author> <year> 1995. </year> <title> Holographic reduced representations. </title> <journal> IEEE Transactions on Neural Networks. </journal> <note> To appear. </note>
Reference: <author> Rumelhart, D. E., Hinton, G. E., and J., W. R. </author> <year> 1986. </year> <title> Learning internal representations by error propagation. </title> <booktitle> In Parallel distributed processing: Explorations in the microstructure of cognition, </booktitle> <volume> volume 1, </volume> <pages> pages 318-362. </pages> <publisher> The MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Sejnowski, T. J. and Rosenberg, C. R. </author> <year> 1986. </year> <title> NETtalk: A parallel network that learns to read aloud. </title> <type> Technical report 86-01, </type> <institution> Department of Electrical Engineering and Computer Science, Johns Hopkins University, Baltimore, MD. </institution>
Reference: <author> Servan-Schreiber, D., Cleeremans, A., and McClelland, J. L. </author> <year> 1991. </year> <title> Graded state machines: The representation of temporal contingencies in simple recurrent networks. </title> <journal> Machine Learning, </journal> 7(2/3):161-194. 
Reference: <author> Simard, P. and LeCun, Y. </author> <year> 1992a. </year> <title> Reverse tdnn: an architecture for trajectory generation. </title> <editor> In Moody, J. M., Hanson, S. J., and Lippman, R. P., editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4 (NIPS*91), </booktitle> <address> Denver, </address> <publisher> CO. Morgan Kaufman. </publisher>
Reference: <author> Simard, P. and LeCun, Y. </author> <year> 1992b. </year> <title> Reverse TDNN: an architecture for trajectory generation. </title> <editor> In Moody, J. M., Hanson, S. J., and Lippman, R. P., editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4 (NIPS*91), </booktitle> <address> Denver, </address> <publisher> CO. Morgan Kaufmann. </publisher> <month> 22 March </month> <year> 1995 </year> <month> 19 </month>
References-found: 12

