URL: ftp://ftp.cs.rochester.edu/pub/u/jag/iccv95.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/jag/publications.html
Root-URL: 
Email: jag@cs.rochester.edu  
Title: Saliency Maps and Attention Selection in Scale and Spatial Coordinates: An Information Theoretic Approach  
Author: Martin Jagersand 
Web: http://www.cs.rochester.edu/u/jag/  
Address: Rochester, Rochester, NY 14627  
Affiliation: Department of Computer Science, University of  
Note: In Proc of 5th International Conference on Computer Vision, 1995, p. 195-202  
Abstract: Information measures with respect to spatial locations and scales of objects in an image are important to image processing and interpretation. It allows us to focus attention on relevant data, saving effort and reducing false positives. In particular, the information content of a man-made scene is typically confined to a small set of scales. We devise a scale space based measure of image information. Kullback contrasts between successive resolution lengths gives the differential information gain. Experiments show that this measure gives a clear indication of characteristic lengths in a variety of real world images and is superior to power spectrum based measurements. Decomposing the expected information gain into spatial coordinates gives us a saliency map for use by an attention selector. Last we combine the scale and spatial decompositions into a single information measure, giving both the spatial extent and scale range of interest. The information measure has an efficient implementation, and thus can be used routinely in early vision processing. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Karl Erik Eriksson, </author> <title> Kristian Lindgren "Structural Information in Self Organizing Systems" Physica scripta v 35 p388-397, </title> <year> 1987 </year>
Reference-contexts: So far there have been few attempts to use information theoretic concepts related to the interpretation of images. This is in contrast to physics, where in the eighties the combination of computer simulations and information theoretic analysis of complex systems got much attention <ref> [1] </ref>. We believe in the application of information theory to AI, and particularly to vision. In this report a scale decomposition of an information measure in images is presented. Its usefulness as a step in early vision is discussed, and the theory is supported by an efficient implementation.
Reference: [2] <institution> Tony Lindeberg Discrete Scale-Space Theory and the Scale-Space Primal Sketch, </institution> <type> PhD thesis KTH 1991. </type>
Reference-contexts: We present experimental results from a wide range of images. The importance of scale-space processing was acknowledged in the eighties in vision beginning with Witkin's early paper [4], and much of the work in this decade is nicely brought together by Lindeberg <ref> [2] </ref>. <p> Traditionally the problem of choosing the relevant scale has been tackled by considering all possible scales. This has been done in for instance matching [10, 11], edge detection and segmentation <ref> [2] </ref>. This can require considerable extra time in an already complex algorithm, and we propose that in many cases is not necessary.
Reference: [3] <institution> Jonas G-arding Tony Lindeberg "Direct computation of shape cues using scale-adapted spatial derivative operators" To appear in Int. J. of Computer vision </institution>
Reference: [4] <author> A. </author> <title> Witkin "Scale-Space Filtering" Proc. </title> <booktitle> 8th Int. Joint Conf. on AI p. </booktitle> <pages> 1019-1022 </pages>
Reference-contexts: Its usefulness as a step in early vision is discussed, and the theory is supported by an efficient implementation. We present experimental results from a wide range of images. The importance of scale-space processing was acknowledged in the eighties in vision beginning with Witkin's early paper <ref> [4] </ref>, and much of the work in this decade is nicely brought together by Lindeberg [2].
Reference: [5] <author> B. B. </author> <title> Mandelbrot The Fractal Gerometry of Nature Freeman 1983 </title>
Reference-contexts: Furniture in the room would typically be in the one to two meter range, and other objects, say the typical household items in a kitchen or items occupying an office desktop, are mostly in the one decimeter scale range. 1 This is not true of most natural scenes <ref> [5] </ref>.
Reference: [6] <author> Alex P. Pentland, </author> <title> "Fractal-Based Description of Natural Scenes" In From Pixels to Predicates: Recent Advances in Computational and Robotic Vision, </title> <editor> Ed Pentland, </editor> <publisher> Ablex 1986 </publisher>
Reference: [7] <author> Hugh R. Wilson, Dennis Levi, Lamberto Maf-fei, Jyrki Rovamo, </author> <title> Russell DeValois "The Perception of Form: Retina to Striate Cortex" In Visual Perception: The Neurophysiological Foundations, </title> <editor> Ed's Spillman, Werner, </editor> <publisher> Academic Press 1990 </publisher>
Reference-contexts: Among other possible measures we try a line-oriented one, "lininess", in Section 6. This measure is obtained by convolving the image with Gabor patches used as line finders of different scales and orientations, similar to those of directionally sensitive simple cells in human visual cortex <ref> [7] </ref>. This helps "draw attention" to objects, rather than texture when for instance we have a high contrast random noise like texture in an image. 2 What we consider to be the underlying event for our distribution is really not that important.
Reference: [8] <editor> Y. Bar Schalom, T. </editor> <publisher> Fortman Tracking and Data Association Academic Press 1988 </publisher>
Reference-contexts: An example of this is the validation gate of <ref> [8, 9] </ref>. It uses a time varying (scale) window, but still needs an initial estimate of the relevant scale.
Reference: [9] <author> Andrew Blake, Rupert Curwen, </author> <title> Andrew Zis-serman "A Framework for Spartio-Temporal Control in the Tracking of Visual Contours" Real Time Computer Vision Ed's C. </title> <publisher> Brown, </publisher> <address> D. Terzopoulus, </address> <publisher> Cambridge University Press 1994 </publisher>
Reference-contexts: An example of this is the validation gate of <ref> [8, 9] </ref>. It uses a time varying (scale) window, but still needs an initial estimate of the relevant scale.
Reference: [10] <author> Dana H. Ballard and Lambert E. </author> <title> Wixson "Object Recognition Using Steerable Filters at Multiple Scales" Proceedings of the IEEE Workshop on Qualitative Vision, </title> <year> 1993 </year>
Reference-contexts: Traditionally the problem of choosing the relevant scale has been tackled by considering all possible scales. This has been done in for instance matching <ref> [10, 11] </ref>, edge detection and segmentation [2]. This can require considerable extra time in an already complex algorithm, and we propose that in many cases is not necessary.
Reference: [11] <author> Dana H. Ballard and Rajesh P.N. </author> <booktitle> Rao "Seeing Behind Occlusions" Proc of ECCV, </booktitle> <address> Stock-holm, Sweden, </address> <month> May </month> <year> 1994, </year>
Reference-contexts: Traditionally the problem of choosing the relevant scale has been tackled by considering all possible scales. This has been done in for instance matching <ref> [10, 11] </ref>, edge detection and segmentation [2]. This can require considerable extra time in an already complex algorithm, and we propose that in many cases is not necessary.
Reference: [12] <author> Raymond D. Rimey, Christopher M. </author> <title> Brown "Control of Selective Perception Using Bayes Nets and Decision Theory" Int. </title> <editor> J. </editor> <booktitle> of Computer Vision v 12:2/3 p173-207, </booktitle> <year> 1994 </year>
Reference-contexts: Attention selection can be data-driven bottom-up, model-driven top-down or both [14, 16]. Attention selection allows us to focus attention on relevant data, not only saving effort, but also reducing the chance of false positive responses <ref> [12] </ref>. Much of the work in attention selection has been based on perceptual grouping and structural saliency [15]. More recently, appealing linear filter based approaches have proven successful [13], which looks promising in that it allows simpler, low level explanation of the human pre-attentive process.
Reference: [13] <institution> Ivan Marsic "Data-Driven Shifts of Attention in Wavelet Scale Space" IEEE trans. </institution> <note> PAMI submitted </note>
Reference-contexts: Much of the work in attention selection has been based on perceptual grouping and structural saliency [15]. More recently, appealing linear filter based approaches have proven successful <ref> [13] </ref>, which looks promising in that it allows simpler, low level explanation of the human pre-attentive process. These data-driven attention mechanisms work in two steps: 1. Pre-attentive processing Compute some measure of saliency or conspicuousness globally over the whole image. 2.
Reference: [14] <institution> Tanveer Fathima Syeda-Mahmood Attentional Selection in Object Recognition, </institution> <type> PhD thesis, TR 1420, </type> <institution> AI LAB, MIT 1993 </institution>
Reference-contexts: Attention selection can be data-driven bottom-up, model-driven top-down or both <ref> [14, 16] </ref>. Attention selection allows us to focus attention on relevant data, not only saving effort, but also reducing the chance of false positive responses [12]. Much of the work in attention selection has been based on perceptual grouping and structural saliency [15].
Reference: [15] <author> Amnon Sha'ashua Shimon Ullman "Structual Saliency: </author> <title> The Detection of Globally Salient Structures Using a Locally Connected Network" Proc of ICCV 1988 p321-327 </title>
Reference-contexts: Attention selection allows us to focus attention on relevant data, not only saving effort, but also reducing the chance of false positive responses [12]. Much of the work in attention selection has been based on perceptual grouping and structural saliency <ref> [15] </ref>. More recently, appealing linear filter based approaches have proven successful [13], which looks promising in that it allows simpler, low level explanation of the human pre-attentive process. These data-driven attention mechanisms work in two steps: 1.
Reference: [16] <author> R. Milanese H. Wechsler S. Gill J.M. Bost T. </author> <title> Pun "Integration of Bottom-Up and Top-Down Cues for Visual Attention Using NonLinear Relaxation" PRoc of CVPR 1994 p 781-785 </title>
Reference-contexts: Attention selection can be data-driven bottom-up, model-driven top-down or both <ref> [14, 16] </ref>. Attention selection allows us to focus attention on relevant data, not only saving effort, but also reducing the chance of false positive responses [12]. Much of the work in attention selection has been based on perceptual grouping and structural saliency [15].
Reference: [17] <author> M. Jagersand R. </author> <title> Nelson Adaptive Differential Visual Feedback for Uncalibrated Hand-Eye Coordination and Motor Control TR 579 Dept of CS, </title> <institution> University of Rochester 1994 </institution>
Reference-contexts: We plan to explore the use of our information measures and attention selection method, in various practical applications. In visual space robotics visual features need to be found, and attended to during manipulation tasks <ref> [17] </ref>. Similarly model free, filter based methods used for visual search initially have to be pointed to interesting regions. So far a human operator has had to point out the relevant features on objects to manipulate, or objects which should be found.
Reference: [18] <author> M. </author> <title> Jagersand "A Scale Decomposed Information Measure in Images" Proc. </title> <booktitle> ARPA Image Understanding Workshop 1994 </booktitle>
Reference-contexts: We approximate the convolutions by several moving averages. Our 2D moving average separates into two 1D, and can be efficiently computed on a parallel processor. Details of our implementation can be found in <ref> [18] </ref>.
References-found: 18

