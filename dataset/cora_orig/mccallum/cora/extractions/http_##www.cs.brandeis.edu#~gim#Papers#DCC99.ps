URL: http://www.cs.brandeis.edu/~gim/Papers/DCC99.ps
Refering-URL: http://www.cs.brandeis.edu/~gim/papers.html
Root-URL: http://www.cs.brandeis.edu
Title: Adaptive Linear Prediction Lossless Image Coding  
Author: Giovanni Motta James A. Storer and Bruno Carpentieri 
Abstract: The practical lossless digital image compressors that achieve the best results in terms of compression ratio are also simple and fast algorithms with low complexity both in terms of memory usage and running time. Surprisingly, the compression ratio achieved by these systems cannot be substantially improved even by using image-by-image optimization techniques or more sophisticate and complex algorithms [6]. A year ago, B. Meyer and P. Tischer were able, with their TMW [2], to improve some current best results (they do not report results for all test images) by using global optimization techniques and multiple blended linear predictors. Our investigation is directed to determine the effectiveness of an algorithm that uses multiple adaptive linear predictors, locally optimized on a pixel-by-pixel basis. The results we obtained on a test set of nine standard images are encouraging, where we improve over CALIC on some images. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M.J. Weinberger, G. Seroussi and G. Sapiro, "LOCO-I: </author> <title> A Low Complexity, Context-Based, Lossless Image Compression Algorithm", </title> <booktitle> Proceedings IEEE Data Compression Conference (DCC), </booktitle> <address> Snowbird, Utah, </address> <month> Mar-Apr </month> <year> 1996. </year>
Reference-contexts: Most algorithms existing in literature use a simple pixel predictor and compensate the weak prediction with sophisticate heuristics to model the error as a function of the context in which it occurs (see for example LOCO-I <ref> [1] </ref>). Our algorithm, instead, embeds the contextual encoding inside the error prediction step. The classification of the samples in clusters of pixels that have a similar context is performed by using a Generalized Lloyd Algorithm [9] (or LBG). <p> It has symbols in the range [D+1, ..., max (abs (Max), abs (Min))]; ACM_S Used to encode the error sign. It has two symbols <ref> [0, 1] </ref> that represent positive and negative errors. <p> The number of predictors is 2 and R p =10. Prediction error is encoded as described in the "Entropy Coding" section. - 8 - baloon barb barb2 board boats girl gold hotel zelda Average SUNSET CB9 <ref> [1] </ref> 2.89 4.64 4.71 3.72 3.99 3.90 4.60 4.48 3.79 4.08 LOCO-I [1] 2.90 4.65 4.66 3.64 3.92 3.90 4.47 4.35 3.87 4.04 UCM [6] 2.81 4.44 4.57 3.57 3.85 3.81 4.45 4.28 3.80 3.95 2 Pred., Rp=10, EC with Re 2.84 4.16 4.48 3.59 3.89 3.80 4.42 4.41 3.64 3.91 <p> The number of predictors is 2 and R p =10. Prediction error is encoded as described in the "Entropy Coding" section. - 8 - baloon barb barb2 board boats girl gold hotel zelda Average SUNSET CB9 <ref> [1] </ref> 2.89 4.64 4.71 3.72 3.99 3.90 4.60 4.48 3.79 4.08 LOCO-I [1] 2.90 4.65 4.66 3.64 3.92 3.90 4.47 4.35 3.87 4.04 UCM [6] 2.81 4.44 4.57 3.57 3.85 3.81 4.45 4.28 3.80 3.95 2 Pred., Rp=10, EC with Re 2.84 4.16 4.48 3.59 3.89 3.80 4.42 4.41 3.64 3.91 CALIC [6] 2.78 4.31 4.46 3.51 3.78 3.72 4.35 4.18 3.69 3.86
Reference: [2] <author> B. Meyer and P. Tischer, </author> <title> "Extending TMW for Near Lossless Compression of Greyscale Images", </title> <booktitle> Proceedings IEEE Data Compression Conference (DCC), </booktitle> <address> Snowbird, Utah, </address> <month> Mar-Apr </month> <year> 1998. </year>
Reference-contexts: On the other hand, most of them use heuristics and, even if the compression ratio achieved cannot be in practice easily improved, it is not completely clear they are able to capture the real entropy of the image or not. In <ref> [2] </ref> and [5] B. Meyer and P. Tischer proposed TMW, a lossless image coding algorithm that, by using linear predictors, achieves on some test images compression performance higher than CALIC [3], that is the best (in terms of compression ratio) algorithm known so far.
Reference: [3] <author> X. Wu and N. Memon, </author> <title> "Context-based, Adaptive, Lossless Image Codec", </title> <journal> IEEE Trans. on Communications, Vol.45, </journal> <volume> No.4, </volume> <month> Apr </month> <year> 1997. </year>
Reference-contexts: In [2] and [5] B. Meyer and P. Tischer proposed TMW, a lossless image coding algorithm that, by using linear predictors, achieves on some test images compression performance higher than CALIC <ref> [3] </ref>, that is the best (in terms of compression ratio) algorithm known so far. TMW improves the current best results by using global optimization and blended linear predictors; a TMW compressed file consists of two parts: a header that contains the parameters of the model and the encoded data itself.
Reference: [4] <author> X. Wu, W. Choi and N. Memon, </author> <title> "Lossless Interframe Image Compression via Context Modeling", </title> <booktitle> Proceedings IEEE Data Compression Conference (DCC), </booktitle> <address> Snowbird, Utah, </address> <month> Mar-Apr </month> <year> 1998. </year>
Reference: [5] <author> B. Meyer and P. Tischer, </author> <title> "TMW - a New Method for Lossless Image Compression", </title> <booktitle> International Picture Coding Symposium PCS97 conference proceedings, </booktitle> <month> Sep </month> <year> 1997. </year>
Reference-contexts: On the other hand, most of them use heuristics and, even if the compression ratio achieved cannot be in practice easily improved, it is not completely clear they are able to capture the real entropy of the image or not. In [2] and <ref> [5] </ref> B. Meyer and P. Tischer proposed TMW, a lossless image coding algorithm that, by using linear predictors, achieves on some test images compression performance higher than CALIC [3], that is the best (in terms of compression ratio) algorithm known so far.
Reference: [6] <author> X. Wu, </author> <title> "An Algorithmic Study on Lossless Image Compression", </title> <booktitle> Proceedings IEEE Data Compression Conference (DCC), </booktitle> <address> Snowbird, Utah, </address> <month> Mar-Apr </month> <year> 1996. </year>
Reference-contexts: Even if TMW has a computational complexity several orders of magnitude greater than CALIC, the results are in any case surprising because: Linear predictors are known to be not effective in capturing fast transitions in image luminosity (edges) <ref> [6] </ref>; Global optimization seemed unable to improve substantially the performance of lossless image compressors [6]; CALIC was thought to achieve a data rate extremely close to the real entropy of the image. <p> TMW has a computational complexity several orders of magnitude greater than CALIC, the results are in any case surprising because: Linear predictors are known to be not effective in capturing fast transitions in image luminosity (edges) <ref> [6] </ref>; Global optimization seemed unable to improve substantially the performance of lossless image compressors [6]; CALIC was thought to achieve a data rate extremely close to the real entropy of the image. In this paper, we discuss a series of experiments we made with an algorithm that uses multiple adaptive linear predictors that are locally optimized on a pixel-by-pixel basis. <p> In our implementation, we used as a default the classic "planar predictor" <ref> [6] </ref>: P w w w w w w def = = = - = = = =- , , , , , -0 1 2 3 4 5 0 1 1 0 0 1 The algorithm uses at each step the refined predictor from the previous iterations, so initialization is not <p> Prediction error is encoded as described in the "Entropy Coding" section. - 8 - baloon barb barb2 board boats girl gold hotel zelda Average SUNSET CB9 [1] 2.89 4.64 4.71 3.72 3.99 3.90 4.60 4.48 3.79 4.08 LOCO-I [1] 2.90 4.65 4.66 3.64 3.92 3.90 4.47 4.35 3.87 4.04 UCM <ref> [6] </ref> 2.81 4.44 4.57 3.57 3.85 3.81 4.45 4.28 3.80 3.95 2 Pred., Rp=10, EC with Re 2.84 4.16 4.48 3.59 3.89 3.80 4.42 4.41 3.64 3.91 CALIC [6] 2.78 4.31 4.46 3.51 3.78 3.72 4.35 4.18 3.69 3.86 TWM [2],[13] 2.65 4.08 4.38 3.61 4.28 3.80 Table 4: Compression rate <p> 4.64 4.71 3.72 3.99 3.90 4.60 4.48 3.79 4.08 LOCO-I [1] 2.90 4.65 4.66 3.64 3.92 3.90 4.47 4.35 3.87 4.04 UCM <ref> [6] </ref> 2.81 4.44 4.57 3.57 3.85 3.81 4.45 4.28 3.80 3.95 2 Pred., Rp=10, EC with Re 2.84 4.16 4.48 3.59 3.89 3.80 4.42 4.41 3.64 3.91 CALIC [6] 2.78 4.31 4.46 3.51 3.78 3.72 4.35 4.18 3.69 3.86 TWM [2],[13] 2.65 4.08 4.38 3.61 4.28 3.80 Table 4: Compression rate in bit per pixel achieved on the test set by some popular lossless image encoding algorithms.
Reference: [7] <author> D. Speck, </author> <title> "Fast Robust Adaptation of Predictor Weights from Min/Max Neighboring Pixels for minimal Conditional Entropy", </title> <booktitle> Proc. Twenty-Ninth Asilomar Conference Signal, Systems and Computers, pgg. </booktitle> <pages> 234-242, </pages> <address> Oct 30 - Nov 2, Pacific Groove, CA. </address>
Reference: [8] <author> I.H. Witten, R. Neal and J.G. Cleary, </author> <title> "Arithmetic Coding for Data Compression", </title> <journal> Communications of the ACM, Vol.30, </journal> <volume> No.6, </volume> <month> Jun </month> <year> 1987, </year> <month> pp.520-540. </month>
Reference-contexts: In our case, adaptive linear prediction generates a skewed Laplacian distribution, centered on zero and with very long tails. We decided to use an Arithmetic Encoder <ref> [8] </ref> for the error entropy coding. Arithmetic encoding divides the coding step into the determination of a probabilistic model for the - 5 - source and in the entropy coding that uses that model. <p> While typical values for Ds are in the range <ref> [8, ...,20] </ref>, Min and Max assume, in general, values in the range [-120, ..., 120]. The Arithmetic Coder implementation that we used [11] has the limitation that the initial probabilities must be always greater than zero.
Reference: [9] <author> Y. Linde, A. Buzo and R.M. Gray, </author> <title> "An Algorithm for Vector Quantization Design", </title> <journal> IEEE Trans. Communications, </journal> <month> Jan </month> <year> 1980, </year> <editor> v. COM-28, </editor> <booktitle> pgg. </booktitle> <pages> 84-95. </pages>
Reference-contexts: Our algorithm, instead, embeds the contextual encoding inside the error prediction step. The classification of the samples in clusters of pixels that have a similar context is performed by using a Generalized Lloyd Algorithm <ref> [9] </ref> (or LBG). This classification method, although not optimal in our framework, is good enough to improve the performance of the basic adaptive predictor. However, we are confident that a better classification would improve the performance of our algorithm.
Reference: [10] <author> P.G. Howard, </author> <title> "The Design and Analysis of Efficient Lossless Data Compression Systems", </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science, Brown University, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: Reinitializing the predictors, instead of using the previous refined weights, while resulting in a much slower convergence, doesn't seems to change the compression ratio. Entropy Coding As is common in literature <ref> [10] </ref>, we assume that for most images, prediction errors can be closely approximated by a Laplace distribution. In our case, adaptive linear prediction generates a skewed Laplacian distribution, centered on zero and with very long tails. We decided to use an Arithmetic Encoder [8] for the error entropy coding.
Reference: [11] <author> F. Wheeler, </author> <title> Adaptive Arithmetic Coding, Source Code from: </title> <address> "http://ipl.rpi.edu/wheeler/ac/". </address>
Reference-contexts: While typical values for Ds are in the range [8, ...,20], Min and Max assume, in general, values in the range [-120, ..., 120]. The Arithmetic Coder implementation that we used <ref> [11] </ref> has the limitation that the initial probabilities must be always greater than zero. As a consequence, when only a small number of samples is available to model the distribution, encoder efficiency can be compromised by the use of a coding range that is substantially greater than necessary.
Reference: [12] <author> X. Wu, </author> <title> Test Images, from: </title> <publisher> "ftp://ftp.csd.uwo.ca/pub/from_wu/images/". </publisher>
Reference-contexts: set composed of nine greylevel images 720 * 576 pixels, digitized with a resolution of 8 bit (256 grey levels) per pixel. - 6 - The same test set is widely used for comparisons in most of the lossless data compression literature and can be downloaded from an ftp site <ref> [12] </ref>. Main results are expressed in terms of bit per pixels or by giving the size of the compressed file.
Reference: [13] <author> B. Meyer, </author> <title> TMW Code and new results, from: </title> <address> "http://www.cs.monash.edu.au/~bmeyer/tmw". </address>
References-found: 13

