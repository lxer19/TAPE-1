URL: http://www.cs.umn.edu/Users/dept/users/padma/optimization/decomp93.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/padma/optimization/
Root-URL: http://www.cs.umn.edu
Title: A TreeDecomposition Approach to Parallel Query Optimization  
Author: Thomas M. Fellow Jaideep Srivastava Bhaskar Himatsingka Jianzhong Li 
Address: Building 200 Union Street S.E. Minneapolis, Minnesota 55455  
Affiliation: Computer Science Department University of Minnesota 4-192 Electrical Engineering/Computer Science  
Note: Niccum1, HPC Graduate  
Abstract: In this paper we present an approach for transforming a relational join tree into a detailed execution plan with resource allocation information, for execution on a parallel machine. Our approach starts by transforming a query tree, such as might be generated by a sequential optimizer, into an operator tree which is then partitioned into a forest of linear chains of pipelined operators. We present an algorithm for scheduling these chains in conformance to their precedence ordering on a parallel machine. The aim of the scheduling is to achieve some objective like minimum response time or maximum speedup, etc. We provide a set of experiments to demonstrate the quality of the allocation plans generated by the method. A major benefit of the method is that it uses inter-operator, intra-operator and pipelining methods of parallelizing relational query operators simultaneously. Our experiments show that the heuristic scheduling method creates schedules that are close to optimal while being very easy to compute. We also propose a new way to calculate speedup that takes into account the amount of work that is done. 
Abstract-found: 1
Intro-found: 1
Reference: [CHEN92a] <author> M.S. Chen, M.L. Lo, P.S. Yu and H.C. Young, </author> <title> "Using Segmented Right-Deep Trees for the Execution of Pipelined Hash Joins", </title> <booktitle> in Proceedings of the 18th VLDB Conference, </booktitle> <address> Vancouver, Canada, </address> <year> 1992. </year>
Reference-contexts: Equijoin or Nonequijoin - Nonequijoins require an algorithm that examines each possibility, such as nested-loops. Absolute and Relative Input Relation Sizes - sizes of input relations that are intermediate results from other joins in the query can be estimated using various formulae <ref> [CHEN92a, SRIV93] </ref>. 9 Prediction of Available Memory - a rough idea of the amount of available memory can give us the ability to reject some algorithms, such as nested-loops, which require large amounts of memory to be competitive. <p> Work Model We calculate the amount of work needed to compute an operator, given the amount of memory available for execution. Our timing parameters have been taken from <ref> [CHEN92a] </ref> with a few more added to facilitate the calculation of work done.
Reference: [CHEN92b] <author> M.S. Chen, P.S. Yu and K. Wu, </author> <title> "Scheduling and Processor Allocation for Parallel Execution of Multi-Join Queries", </title> <booktitle> in Proceedings of Data Engineering 92, </booktitle> <year> 1992. </year>
Reference-contexts: However, some architectural characteristics may constrain the problem, e.g. in a distributed memory architecture processor/memory assignment are equivalent since each goes with the other. Disk allocation, primarily for 2 intermediate results, will usually be guided by the data declustering approach being used. Processor assignment has been considered in <ref> [LU91, HONG92, GANG92, SRIV93, TUREK92, CHEN92b, HUA93] </ref>, while memory assignment has been considered in [SRIV93 and ZIAN93]. Since memory continues to be a critical resource for the performance of database operations even in the parallel environment [SCHN90], a careful modeling of contention on it is important. <p> The goals are (i) to obey the precedence constraints (i.e. some operations may not be started until operations lower in the join tree have completed), (ii) allocate processors to avoid idling as much as possible (called system fragmentation <ref> [CHEN92b] </ref>), and (iii) allocate memory to maximize its effectiveness. These goals increase the difficulty of scheduling [CHEN92b]. The first step is to transform the join tree into a more basic form, called an operator tree. Here joins are replaced by their constituent operations. <p> to obey the precedence constraints (i.e. some operations may not be started until operations lower in the join tree have completed), (ii) allocate processors to avoid idling as much as possible (called system fragmentation <ref> [CHEN92b] </ref>), and (iii) allocate memory to maximize its effectiveness. These goals increase the difficulty of scheduling [CHEN92b]. The first step is to transform the join tree into a more basic form, called an operator tree. Here joins are replaced by their constituent operations. For example, a sort-merge join is replaced by a sort on the left-input, a sort on the right-input, and a merge.
Reference: [CHOU85] <author> H-T. Chou, D. J. DeWitt, R. H. Katz and A. C. Klug, </author> <title> "Design and Implementation of the Wisconsin Storage System," </title> <journal> Software-Practice and Experience, </journal> <volume> Vol. 15, No. 10, </volume> <month> October </month> <year> 1985. </year> <month> 25 </month>
Reference-contexts: Each task is placed, in order, on shelves. Remaining tasks are assigned to the existing shelves using several rules. Experimental evaluation shows that the method compares favorably with the plan found by exhaustive search. Studies in buffer management in the sequential <ref> [CHOU85] </ref> and parallel [SCHN90] environments have shown that query execution performance is highly sensitive to the amount of memory available. A nested-loops join algorithm, for instance, goes from quadratic to linear in I/O complexity if there is enough memory to hold the smaller relation.
Reference: [DeWI90] <author> D. J. DeWitt and J. Gray, </author> <title> "Parallel Database Systems: The Future of Database Processing or a Passing Fad?," </title> <booktitle> in ACM SIGMOD Record, </booktitle> <volume> Vol. 19, No. 4, </volume> <month> December </month> <year> 1990. </year>
Reference-contexts: To quote DeWitt and Gray, "While the necessary optimizer technology exists, accurate cost models have not been developed, let alone validated. More work is needed in this area" <ref> [DeWI90] </ref>. [LU91] proposed a cost model in which response time of a query plan is considered. Not having pipelining between successive levels of the plan tree simplifies its calculation considerably.
Reference: [GANG92] <author> S. Ganguly, W. Hasan and R. Krishnamurthy, </author> <title> "Query Optimization for Parallel Execution", </title> <booktitle> in Proceedings of the 1992 ACM SIGMOD International Conference on Management of Data, </booktitle> <address> San Diego, CA June 1992. </address>
Reference-contexts: The effect on the response time due to pipelined execution between operators is modeled. <ref> [GANG92] </ref> has proposed a similar approach at the operator-tree level. This proposal is the most comprehensive one to date as it provides details of the cost formulae for operators and rules for their combination. The effect of resource contention is modeled as a multiplicative factor that stretches response time. <p> However, some architectural characteristics may constrain the problem, e.g. in a distributed memory architecture processor/memory assignment are equivalent since each goes with the other. Disk allocation, primarily for 2 intermediate results, will usually be guided by the data declustering approach being used. Processor assignment has been considered in <ref> [LU91, HONG92, GANG92, SRIV93, TUREK92, CHEN92b, HUA93] </ref>, while memory assignment has been considered in [SRIV93 and ZIAN93]. Since memory continues to be a critical resource for the performance of database operations even in the parallel environment [SCHN90], a careful modeling of contention on it is important. <p> Since memory continues to be a critical resource for the performance of database operations even in the parallel environment [SCHN90], a careful modeling of contention on it is important. A first step towards memory allocation has been reported in <ref> [GANG92] </ref>, while its use as a critical resource to guide the search heuristic is shown in [SRIV93]. <p> Resource Allocation In this section we describe a cost model for trees, where the cost descriptor of a node is expressed as a function of the cost of its children and its own parameters. Such a cost model lends itself naturally to a bottom-up evaluation. Both <ref> [GANG92] </ref> and [SRIV93] describe cost models that are of this type. The work of a query is the sum of the effort spent by all processors working on it. The response time is the (parallel) time to evaluate a particular query. <p> The work of a query is the sum of the effort spent by all processors working on it. The response time is the (parallel) time to evaluate a particular query. The cost model used is an enhancement of those used in <ref> [GANG92] </ref> and [SRIV93] and is described in further detail below. 4.1. Work Model We calculate the amount of work needed to compute an operator, given the amount of memory available for execution.
Reference: [HONG92] <author> W. Hong, </author> <title> "Exploiting Inter-Operation Parallelism in XPRS", </title> <booktitle> in Proceedings of the 1992 ACM SIGMOD International Conference on Management of Data , San Diego, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: However, some architectural characteristics may constrain the problem, e.g. in a distributed memory architecture processor/memory assignment are equivalent since each goes with the other. Disk allocation, primarily for 2 intermediate results, will usually be guided by the data declustering approach being used. Processor assignment has been considered in <ref> [LU91, HONG92, GANG92, SRIV93, TUREK92, CHEN92b, HUA93] </ref>, while memory assignment has been considered in [SRIV93 and ZIAN93]. Since memory continues to be a critical resource for the performance of database operations even in the parallel environment [SCHN90], a careful modeling of contention on it is important.
Reference: [IOAN90] <author> Y. E. Ioannidis, and Y. Kang, </author> <title> "Randomized Algorithms for Optimizing Large Join Queries," </title> <booktitle> in Proc. of Intl. Conf. on the Mgmt. of Data , Atlantic City, </booktitle> <address> NJ, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: The success in building good query optimizers for relational databases [SELI79, YOUS76, JARK84] has been an important reason for their popularity. Since it is an NP-Hard problem, the optimal solution can be found only for small problems. This has led to substantial research in improved heuristics over the years <ref> [ONO90, SWAM88, IOAN90] </ref>. The focus in relational query optimization so far has been on finding plans which involve the least amount of work, since on a uniprocessor the time taken is proportional to the work done.
Reference: [HUA93] <author> K. A. Hua, Y. Lo, and H. C. Young, </author> <title> "Including the Load Balancing Issue in The Optimization of Multi-way Join Queries for Shared-Nothing Database Computers", </title> <booktitle> in Proceedings of the 2nd International Conference on Parallel and Distributed Information Systems, </booktitle> <address> San Diego, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: However, some architectural characteristics may constrain the problem, e.g. in a distributed memory architecture processor/memory assignment are equivalent since each goes with the other. Disk allocation, primarily for 2 intermediate results, will usually be guided by the data declustering approach being used. Processor assignment has been considered in <ref> [LU91, HONG92, GANG92, SRIV93, TUREK92, CHEN92b, HUA93] </ref>, while memory assignment has been considered in [SRIV93 and ZIAN93]. Since memory continues to be a critical resource for the performance of database operations even in the parallel environment [SCHN90], a careful modeling of contention on it is important.
Reference: [JARK84] <author> M. Jarke, and J. Koch, </author> <title> "Query Optimization in database Systems," </title> <journal> in ACM Computing Surveys , Vol. </journal> <volume> 16, No. 2, </volume> <pages> pp. 111-152, </pages> <month> June </month> <year> 1982. </year>
Reference-contexts: IRI-9110584. 3 On leave from Heilongjiang University, P. R. China. having a different cost. Selecting the best (least cost) plan for executing a given query is the problem of query optimization. The success in building good query optimizers for relational databases <ref> [SELI79, YOUS76, JARK84] </ref> has been an important reason for their popularity. Since it is an NP-Hard problem, the optimal solution can be found only for small problems. This has led to substantial research in improved heuristics over the years [ONO90, SWAM88, IOAN90].
Reference: [KNUTH68] <author> D. Knuth, </author> <title> Fundamental Algorithms, </title> <booktitle> volume 1 of The Art of Computer Programming. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1968. </year>
Reference-contexts: Scheduling the Components The units of scheduling are the N tree components constructed in the previous phase. The schedule must follow the precedence indicated in the original tree, so the first step in developing the high level schedule is to perform a topological sort <ref> [KNUTH68] </ref> on the components to form a precedence graph. Since each component ends with a materialized edge (connecting it to another component), our rule is that the children of a component must be finished prior to the component starting.
Reference: [LI92] <author> J. Li, J. Srivastava and D. Rotem, CMD: </author> <title> A Multidimensional Declustering Method for Parallel Database Systems, </title> <booktitle> Proceedings of the 18th VLDB Conference, </booktitle> <year> 1992. </year>
Reference-contexts: Next it makes resource allocation, i.e. processor and memory, decisions. Decisions about which disks to use are not made as they will be guided by how relations are already stored, i.e. declustered <ref> [LI92] </ref>. The aim of this phase is to minimize the overall objective function, e.g. work, response time, etc. In this paper we consider response time (i.e. parallel execution time) as the optimization objective. Since standard sequential query optimization technology is used in Phase I, this paper discusses only Phase II.
Reference: [LIPT90] <author> R. J. Lipton, J. F. Naughton, D. A. Schneider, </author> <title> "Practical Selectivity Estimation through Adaptive Sampling," </title> <booktitle> in Proc. of Intl. Conf. on Mgmt. of Data, </booktitle> <address> Atlantic City, NJ, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: While a substantial amount of research was done to develop accurate cost models for the sequential environment [SELI79, MACK86], and continues to be done <ref> [LIPT90] </ref>, no good cost models exist for the parallel environment. To quote DeWitt and Gray, "While the necessary optimizer technology exists, accurate cost models have not been developed, let alone validated.
Reference: [LU91] <author> H. Lu, M.-C. Shan and K.-L. Tan, </author> <title> "Optimization of Multi-Way Join Queries for Parallel Execution", </title> <booktitle> in Proceedings of the 17th VLDB Conference, </booktitle> <address> Barcelona, Spain, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: To quote DeWitt and Gray, "While the necessary optimizer technology exists, accurate cost models have not been developed, let alone validated. More work is needed in this area" [DeWI90]. <ref> [LU91] </ref> proposed a cost model in which response time of a query plan is considered. Not having pipelining between successive levels of the plan tree simplifies its calculation considerably. <p> However, some architectural characteristics may constrain the problem, e.g. in a distributed memory architecture processor/memory assignment are equivalent since each goes with the other. Disk allocation, primarily for 2 intermediate results, will usually be guided by the data declustering approach being used. Processor assignment has been considered in <ref> [LU91, HONG92, GANG92, SRIV93, TUREK92, CHEN92b, HUA93] </ref>, while memory assignment has been considered in [SRIV93 and ZIAN93]. Since memory continues to be a critical resource for the performance of database operations even in the parallel environment [SCHN90], a careful modeling of contention on it is important.
Reference: [MACK86] <author> L. F. Mackert, and G. M. Lohman, </author> <title> R* Optimizer Validation and Performance Evaluation for Local Queries," </title> <booktitle> in Proc. of ACM SIGMOD Intl. Conf. on the Mgmt. of Data, </booktitle> <address> Washington D.C., </address> <month> May </month> <year> 1986. </year> <month> 26 </month>
Reference-contexts: While a substantial amount of research was done to develop accurate cost models for the sequential environment <ref> [SELI79, MACK86] </ref>, and continues to be done [LIPT90], no good cost models exist for the parallel environment. To quote DeWitt and Gray, "While the necessary optimizer technology exists, accurate cost models have not been developed, let alone validated.
Reference: [ONO90] <author> K. Ono, and G. M. Lohman, </author> <title> "Measuring the Complexity of Join Enumeration in Query Optimization," </title> <booktitle> in Proc. of the 16th Very Large Database Conference, </booktitle> <address> Brisbane, Australia, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: The success in building good query optimizers for relational databases [SELI79, YOUS76, JARK84] has been an important reason for their popularity. Since it is an NP-Hard problem, the optimal solution can be found only for small problems. This has led to substantial research in improved heuristics over the years <ref> [ONO90, SWAM88, IOAN90] </ref>. The focus in relational query optimization so far has been on finding plans which involve the least amount of work, since on a uniprocessor the time taken is proportional to the work done.
Reference: [SCHN89] <author> D. A. Schneider and D. J. DeWitt, </author> <title> A Performance Evaluation of Four Parallel Join Algorithms in a Shared-Nothing Multiprocessor Environment, </title> <booktitle> Proceedings of the ACM SIGMOD Conference, </booktitle> <year> 1989. </year>
Reference-contexts: Otherwise, the algorithm defaults to writing the portion of the Rinp that will not fit into memory onto disk, using a partitioning split table <ref> [SCHN89] </ref> as in the hybrid-hash algorithm. The portion in memory is joined first, and then another buffer full is read from disk and used to probe the hash table.
Reference: [SCHN90] <author> D. A. Schneider and D. J. DeWitt, </author> <title> "Tradeoffs in Processing Complex Join Queries via Hashing in Multiprocessor Database Machines," </title> <booktitle> in Proc. of the 16th Very Large Database Conference, </booktitle> <month> August </month> <year> 1990, </year> <institution> Brisbane, Australia. </institution>
Reference-contexts: Processor assignment has been considered in [LU91, HONG92, GANG92, SRIV93, TUREK92, CHEN92b, HUA93], while memory assignment has been considered in [SRIV93 and ZIAN93]. Since memory continues to be a critical resource for the performance of database operations even in the parallel environment <ref> [SCHN90] </ref>, a careful modeling of contention on it is important. A first step towards memory allocation has been reported in [GANG92], while its use as a critical resource to guide the search heuristic is shown in [SRIV93]. <p> Each task is placed, in order, on shelves. Remaining tasks are assigned to the existing shelves using several rules. Experimental evaluation shows that the method compares favorably with the plan found by exhaustive search. Studies in buffer management in the sequential [CHOU85] and parallel <ref> [SCHN90] </ref> environments have shown that query execution performance is highly sensitive to the amount of memory available. A nested-loops join algorithm, for instance, goes from quadratic to linear in I/O complexity if there is enough memory to hold the smaller relation. <p> Join Join sequential optimizer) R1 R2 R4 R6 hash join sort merge hash join R5 Join hash join scan scan scanscan scan scan scan scan scan scan operator tree Much literature exists for deciding the best algorithm for a given set of join conditions in both sequential [SELI79] and parallel <ref> [SCHN90] </ref> environments. It is not within the scope of this paper to develop any new methods for this selection.
Reference: [SELI79] <author> P. P. Selinger, et al, </author> <title> "Access Path Selection in a Relational Database Management System," </title> <booktitle> in Proceedings of ACM SIGMOD Intl. Conf. on Mgmt. of Data, </booktitle> <year> 1979. </year>
Reference-contexts: IRI-9110584. 3 On leave from Heilongjiang University, P. R. China. having a different cost. Selecting the best (least cost) plan for executing a given query is the problem of query optimization. The success in building good query optimizers for relational databases <ref> [SELI79, YOUS76, JARK84] </ref> has been an important reason for their popularity. Since it is an NP-Hard problem, the optimal solution can be found only for small problems. This has led to substantial research in improved heuristics over the years [ONO90, SWAM88, IOAN90]. <p> While a substantial amount of research was done to develop accurate cost models for the sequential environment <ref> [SELI79, MACK86] </ref>, and continues to be done [LIPT90], no good cost models exist for the parallel environment. To quote DeWitt and Gray, "While the necessary optimizer technology exists, accurate cost models have not been developed, let alone validated. <p> The second step is to decide which intermediate results are materialized and which are pipelined. Characteristics of operators, e.g. "sorts must be completed before merge," as well as heuristics, e.g. "keep 1 It is possible to use a sequential optimizer which generates linear join trees only <ref> [SELI79] </ref>. In this case, however, while intra-operator parallelism can be used, inter-operator parallelism cannot. This will become clearer in section 2. 3 pipelines short since the processors at the end may starve," are used. The third step is to use a heuristic processor allocation method based on k-shelf scheduling [TUREK92]. <p> Join Join R5 Join Join sequential optimizer) R1 R2 R4 R6 hash join sort merge hash join R5 Join hash join scan scan scanscan scan scan scan scan scan scan operator tree Much literature exists for deciding the best algorithm for a given set of join conditions in both sequential <ref> [SELI79] </ref> and parallel [SCHN90] environments. It is not within the scope of this paper to develop any new methods for this selection.
Reference: [SRIV93] <author> J. Srivastava and G. Elsesser, </author> <title> "Optimizing Multi-Join Queries in Parallel Relational Databases", </title> <booktitle> in Proceedings of the 2nd International Conference on Parallel and Distributed Information Systems, </booktitle> <address> San Diego, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: However, some architectural characteristics may constrain the problem, e.g. in a distributed memory architecture processor/memory assignment are equivalent since each goes with the other. Disk allocation, primarily for 2 intermediate results, will usually be guided by the data declustering approach being used. Processor assignment has been considered in <ref> [LU91, HONG92, GANG92, SRIV93, TUREK92, CHEN92b, HUA93] </ref>, while memory assignment has been considered in [SRIV93 and ZIAN93]. Since memory continues to be a critical resource for the performance of database operations even in the parallel environment [SCHN90], a careful modeling of contention on it is important. <p> A first step towards memory allocation has been reported in [GANG92], while its use as a critical resource to guide the search heuristic is shown in <ref> [SRIV93] </ref>. This paper presents a 2-phase optimization approach, with the following phases: Phase I (work minimization): In this phase the relational calculus/algebra query is translated into a procedural plan (query tree) and transformations are applied to obtain the plan with the (heuristically) minimal work (i.e. sequential execution time). <p> Equijoin or Nonequijoin - Nonequijoins require an algorithm that examines each possibility, such as nested-loops. Absolute and Relative Input Relation Sizes - sizes of input relations that are intermediate results from other joins in the query can be estimated using various formulae <ref> [CHEN92a, SRIV93] </ref>. 9 Prediction of Available Memory - a rough idea of the amount of available memory can give us the ability to reject some algorithms, such as nested-loops, which require large amounts of memory to be competitive. <p> Resource Allocation In this section we describe a cost model for trees, where the cost descriptor of a node is expressed as a function of the cost of its children and its own parameters. Such a cost model lends itself naturally to a bottom-up evaluation. Both [GANG92] and <ref> [SRIV93] </ref> describe cost models that are of this type. The work of a query is the sum of the effort spent by all processors working on it. The response time is the (parallel) time to evaluate a particular query. <p> The work of a query is the sum of the effort spent by all processors working on it. The response time is the (parallel) time to evaluate a particular query. The cost model used is an enhancement of those used in [GANG92] and <ref> [SRIV93] </ref> and is described in further detail below. 4.1. Work Model We calculate the amount of work needed to compute an operator, given the amount of memory available for execution. Our timing parameters have been taken from [CHEN92a] with a few more added to facilitate the calculation of work done. <p> 255382 349551 5 heuristic 83 194 305 416 5 exhaustive 4547567 10880122 17190631 23513280 Table 3 - Number of alternatives tested by method, relations, and processors Search Space A heuristic is generally used because the search space for an optimal parallel query plan is too large to be searched exhaustively <ref> [SRIV93] </ref>. In order to measure how much we have reduced the space to be searched we compared the number of tree alternatives examined by the heuristic treedecomposition method vs. the number of alternatives examined by the exhaustive search method.
Reference: [SWAM88] <author> A. Swami, and A. Gupta, </author> <title> "Optimization of Large Join Queries," </title> <booktitle> in Proc. of ACM SIGMOD Intl . Conf. on Mgmt. of Data, </booktitle> <address> Chicago, IL, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: The success in building good query optimizers for relational databases [SELI79, YOUS76, JARK84] has been an important reason for their popularity. Since it is an NP-Hard problem, the optimal solution can be found only for small problems. This has led to substantial research in improved heuristics over the years <ref> [ONO90, SWAM88, IOAN90] </ref>. The focus in relational query optimization so far has been on finding plans which involve the least amount of work, since on a uniprocessor the time taken is proportional to the work done.
Reference: [TUREK92] <author> J. Turek, J. L. Wolf, K. R. Pattipati, and P. S. Yu, </author> <title> "Scheduling Parallelizable Tasks: Putting it All on the Shelf", </title> <booktitle> in ACM Sigmetrics, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: However, some architectural characteristics may constrain the problem, e.g. in a distributed memory architecture processor/memory assignment are equivalent since each goes with the other. Disk allocation, primarily for 2 intermediate results, will usually be guided by the data declustering approach being used. Processor assignment has been considered in <ref> [LU91, HONG92, GANG92, SRIV93, TUREK92, CHEN92b, HUA93] </ref>, while memory assignment has been considered in [SRIV93 and ZIAN93]. Since memory continues to be a critical resource for the performance of database operations even in the parallel environment [SCHN90], a careful modeling of contention on it is important. <p> In this case, however, while intra-operator parallelism can be used, inter-operator parallelism cannot. This will become clearer in section 2. 3 pipelines short since the processors at the end may starve," are used. The third step is to use a heuristic processor allocation method based on k-shelf scheduling <ref> [TUREK92] </ref>. The original heuristic for scheduling a set of independent tasks has been generalized to handle a set of dependent ones. The approach is based on finding the critical path through the precedence graph of the operator tree. Each task is placed, in order, on shelves. <p> We consider each component a schedulable task, and label these tasks t i N i , 0 . Figure 10 shows the precedence graph for the components in the example graph. In order to schedule the components we use the idea of a shelf strategy <ref> [TUREK92] </ref>, which is a way of performing orthogonal rectangle packing. We treat the tasks as malleable rectangles where the height of each rectangle is a nondecreasing function of the rectangle's width. <p> We treat the tasks as malleable rectangles where the height of each rectangle is a nondecreasing function of the rectangle's width. The width represents the number of processors assigned to the task and the height represents the time that the task will take (given the number of processors). <ref> [TUREK92] </ref> gives a general solution for the case when the tasks are all independent, and where the number of tasks is larger than the number of processors. We have generalized this approach to model the notion of precedence. In [TUREK92] the k-shelf scheduling algorithm must compute the optimal number of shelves <p> time that the task will take (given the number of processors). <ref> [TUREK92] </ref> gives a general solution for the case when the tasks are all independent, and where the number of tasks is larger than the number of processors. We have generalized this approach to model the notion of precedence. In [TUREK92] the k-shelf scheduling algorithm must compute the optimal number of shelves as well as pack each shelf in an optimal manner. They show that when P&gt;N, a single shelf is optimal for independent tasks. <p> Within each shelf use the greedy processor assignment algorithm given by <ref> [TUREK92] </ref>. We next examine each step of the scheduling algorithm in detail by means of our continuing example: Step 1: Compute initial work estimates For each task we use the appropriate work estimation functions from section 4.1 to get an estimate of the work to be done by the task. <p> Clearly, we want all the tasks to finish at nearly the same time to reduce processor idling. The optimal greedy algorithm from <ref> [TUREK92] </ref> is used to assign the processors such that this is accomplished. The algorithm works by first assigning one processor to each task. The following (greedy) step is repeated once for each remaining processor: Find j j S, 1 for which T t estimate j d i is maximal.
Reference: [WILS91] <author> A.N. Wilschut and P.M.G. Apers, </author> <title> "Dataflow Query Execution in a Parallel Main-Memory Environment", </title> <booktitle> in Proceedings of the 1st International Conference on Parallel and Distributed Information Systems, </booktitle> <address> Miami, </address> <month> December, </month> <year> 1991. </year>
Reference-contexts: More work is needed in this area" [DeWI90]. [LU91] proposed a cost model in which response time of a query plan is considered. Not having pipelining between successive levels of the plan tree simplifies its calculation considerably. Query execution is modeled in a data flow manner in <ref> [WILS91] </ref> and a flow-rate based expression for the average response time is derived. [SRIV93]'s model uses a bottom-up approach in which the response time of a tree rooted at an operator is estimated as the sum of the time taken by the operator and the maximum of the response times of
Reference: [YOUS76] <author> K. Youssefi, and E. Wong, </author> <title> "Decomposition: A Strategy for Processing Relational Queries," </title> <journal> in ACM Transactions on Database Systems, </journal> <volume> Vol. 1, No. 3, </volume> <month> September </month> <year> 1976. </year>
Reference-contexts: IRI-9110584. 3 On leave from Heilongjiang University, P. R. China. having a different cost. Selecting the best (least cost) plan for executing a given query is the problem of query optimization. The success in building good query optimizers for relational databases <ref> [SELI79, YOUS76, JARK84] </ref> has been an important reason for their popularity. Since it is an NP-Hard problem, the optimal solution can be found only for small problems. This has led to substantial research in improved heuristics over the years [ONO90, SWAM88, IOAN90].
Reference: [ZIAN93] <author> M. Ziane, M. Zait, and P. Borla-Salamet, </author> <title> "Parallel Query Processing in DBS3", </title> <booktitle> in Proceedings of the 2nd International Conference on Parallel and Distributed Information Systems, </booktitle> <address> San Diego, </address> <month> January </month> <year> 1993. </year> <month> 27 </month>
References-found: 24

