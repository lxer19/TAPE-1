URL: http://www.cirl.uoregon.edu/pemberto/papers/dis.ps
Refering-URL: http://www.csi.uottawa.ca/~istvan/bookmarks/bookmarks.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Incremental Search Methods for Real-Time Decision Making  
Author: Joseph Carl Pemberton 
Degree: A dissertation submitted in partial satisfaction of the requirements for the degree Doctor of Philosophy in Computer Science by  
Date: 1995  
Affiliation: University of California Los Angeles  
Abstract-found: 0
Intro-found: 1
Reference: [ACH90] <author> T. Anantharaman, M.S. Campbell, and F.H. Hsu. </author> <title> "Singular extensions: Adding selectivity to brute-force searching." </title> <journal> Artificial Intelligence, </journal> <volume> 43(1) </volume> <pages> 99-109, </pages> <year> 1990. </year>
Reference-contexts: This would particularly important in light of the many less than entirely successful attempts to improve upon minimax with alpha-beta pruning (e.g., <ref> [ACH90, Bau93, Ber79, KC94, Nau83, Nil69, McA88, Riv87, RW89] </ref>). CHAPTER 12 Contributions and Conclusions There are four main research contributions reported in this dissertation. The first contribution is our formulation of the real-time incremental decision-making problem.
Reference: [Bau93] <author> Eric B. Baum. </author> <title> "How a Bayesian approaches games like chess." </title> <booktitle> In Proceedings of the AAAI Fall Symposium on Games: Planning and Learning, </booktitle> <pages> pp. 48-50, </pages> <address> Raleigh, NC, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: This would particularly important in light of the many less than entirely successful attempts to improve upon minimax with alpha-beta pruning (e.g., <ref> [ACH90, Bau93, Ber79, KC94, Nau83, Nil69, McA88, Riv87, RW89] </ref>). CHAPTER 12 Contributions and Conclusions There are four main research contributions reported in this dissertation. The first contribution is our formulation of the real-time incremental decision-making problem.
Reference: [BBS93] <author> Andrew G. Barto, Steven J. Bradtke, and Satinder P. Singh. </author> <title> "Learning to Act Using Real-Time Dynamic Programming." </title> <type> Technical Report UM-CS-1993-002, </type> <institution> University of Massachusetts, Amherst, </institution> <year> 1993. </year> <note> [URL: ftp://ftp.cs.umass.edu/pub/techrept/techreport/1993/UM-CS-1993-002.ps.] </note>
Reference-contexts: Their work is complementary to ours, in the sense that they have focussed on more effective exploration, and we have focussed on better decision making. Sutton, Barto and others <ref> [Sut91, Sut90b, Sut90a, BBS93] </ref>, have proposed a dynamic programming approach to incrementally generating plans in situations where the same or similar problems recur. This is a very interesting approach that can be easily extended to stochastic problem domains [BBS93]. <p> Sutton, Barto and others [Sut91, Sut90b, Sut90a, BBS93], have proposed a dynamic programming approach to incrementally generating plans in situations where the same or similar problems recur. This is a very interesting approach that can be easily extended to stochastic problem domains <ref> [BBS93] </ref>. Their work focusses on learning to solve a problem over many instances. Our work has focussed on solving a problem once, although our work on learning the problem-space distribution in Chapter 8 can be viewed as related to their work on learning. <p> One additional extension of the random-tree model would be to allow for stochastic events rather than just deterministic execution of the schedule as specified (i.e., a Markov Decision Problem <ref> [Dea91a, BBS93] </ref>). One example is if the time required to process a job was not a fixed constant, but rather was described by a continuous probability distribution over a range of processing times.
Reference: [BCG76] <author> J. L. Bruno, E. G. Coffman, Jr., R. L. Graham, W. H. Kohler, R. Sethi, K. Steiglitz, and J. D. Ullman. </author> <title> "Computer and Job-Shop Scheduling Theory." </title> <publisher> John Wiley and Sons, </publisher> <year> 1976. </year>
Reference-contexts: Papadimitriou and Steiglitz [PS82] further discuss this problem in their book on combinatorial optimization. We found their treatment of the InS heuristic function easier to follow than the original treatment. Other good general references on scheduling problems include [CMM67], which contains detailed examples of different schedule cost functions, and <ref> [BCG76] </ref>, which is a collection of papers that investigate the use of computers in scheduling domains. Garey and Johnson [GS79] have compiled a number of complexity results on scheduling problems.
Reference: [BD94] <author> Mark Boddy and Thomas L. Dean. </author> <title> "Deliberation scheduling for problem solving in time-constrained environments." </title> <journal> Artificial Intelligence, </journal> <volume> 67 </volume> <pages> 245-285, </pages> <year> 1994. </year>
Reference-contexts: trees so that the average-case search complexity of finding a minimum-cost root-to-leaf path is exponential in the search depth. 10.2.2 Resource-Bounded Decision Making Dean and Boddy first coined the phrase anytime algorithms to refer to one type of time-dependent decision making in [DB88], and later developed this idea further in <ref> [Bod91, BD94] </ref>. The idea behind anytime algorithms is that they can be interrupted at any time during the computation and return a result whose quality is a non-decreasing function of the computation time.
Reference: [Ber79] <author> H. J. Berliner. </author> <title> "The B fl tree search algorithm: A best-first proof procedure." </title> <journal> Artificial Intelligence, </journal> <volume> 12 </volume> <pages> 23-40, </pages> <year> 1979. </year>
Reference-contexts: This would particularly important in light of the many less than entirely successful attempts to improve upon minimax with alpha-beta pruning (e.g., <ref> [ACH90, Bau93, Ber79, KC94, Nau83, Nil69, McA88, Riv87, RW89] </ref>). CHAPTER 12 Contributions and Conclusions There are four main research contributions reported in this dissertation. The first contribution is our formulation of the real-time incremental decision-making problem.
Reference: [Bod91] <author> Mark Boddy. </author> <title> Solving Time-Dependent Problems: A Decision-Theoretic Approach to Planning in Dynamic Environments. </title> <type> PhD thesis, </type> <institution> Brown University, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: In addition, the time spent trying to find the optimal decision needs to be factored into the cost of the final decision. 1.3 Example: Robot Traveling Salesperson Problem Another good example of real-time decision making is a real-time version of the well known traveling salesperson problem (TSP) <ref> [Bod91] </ref>. The traveling salesperson problem is defined as follows. Given a set of cities, what is the shortest tour that visits each city once and returns to the initial city. This is a difficult problem that typically requires computation that is exponential in the number of cities to solve optimally. <p> trees so that the average-case search complexity of finding a minimum-cost root-to-leaf path is exponential in the search depth. 10.2.2 Resource-Bounded Decision Making Dean and Boddy first coined the phrase anytime algorithms to refer to one type of time-dependent decision making in [DB88], and later developed this idea further in <ref> [Bod91, BD94] </ref>. The idea behind anytime algorithms is that they can be interrupted at any time during the computation and return a result whose quality is a non-decreasing function of the computation time. <p> He has looked at many different aspects of the resource-bounded decision problem. In particular, he used decision theory to develop a normative approach to metareasoning. Metareason-ing, also known as deliberation scheduling in <ref> [Bod91, DKK93b, DKK93a] </ref>, and metal-level reasoning in [RW91], describes the process of deciding what computations to perform in support of a reasoning process. <p> In addition to flowshop scheduling, we are interested in applying our incremental search to other real-time planning and scheduling problems. We have considered applying our incremental search methods to a real-time formulation of the traveling salesperson problem (e.g., the robot courier problem in <ref> [Bod91] </ref>). We have also investigated the possibility of applying our methods to more general scheduling problems such as airline gate scheduling [Gre94], diverting airplanes 148 when an airport is closed [Cra94], and allocating medical resources during trauma care [Hor93].
Reference: [CGA89] <author> P. P. Chakrabarti, S. Ghose, A. Acharya, and S. C. de Sarkar. </author> <title> "Heuristic Search in Restricted Memory." </title> <journal> Artificial Intelligence, </journal> <volume> 41 </volume> <pages> 197-221, </pages> <year> 1989. </year>
Reference-contexts: At this point a decision 144 is made. This allows us to prune the irrelevant nodes from the OPEN list, freeing up space to explore for the next decision. Thus decisions are made when the time runs out or the memory becomes full. Other approaches have been considered in <ref> [CGA89, Rus92, SB89, MGP92, Kor93] </ref>, for the general search problem. Through the design of our random-tree model, and our choice of the flowshop-scheduling problem, we have focussed on problems where every leaf node is a solution, and the objective is simply to find a low-cost solution.
Reference: [CMM67] <author> Richard W. Conway, William L. Maxwell, and Louis W. Miller. </author> <title> Theory of Scheduling. </title> <publisher> Addison-Wesley, </publisher> <year> 1967. </year>
Reference-contexts: This is a reasonable assumption because, for any schedule with a cost based on any regular measure of performance (e.g., makespan or sum-finishing-time), there exists a schedule with the same or lower cost for which the order of jobs on each machine is the same <ref> [CMM67] </ref>. The optimal schedule with respect to the makespan and sum-finishing-time cost functions are indicated by the arrows in Figure 9.2. <p> Papadimitriou and Steiglitz [PS82] further discuss this problem in their book on combinatorial optimization. We found their treatment of the InS heuristic function easier to follow than the original treatment. Other good general references on scheduling problems include <ref> [CMM67] </ref>, which contains detailed examples of different schedule cost functions, and [BCG76], which is a collection of papers that investigate the use of computers in scheduling domains. Garey and Johnson [GS79] have compiled a number of complexity results on scheduling problems.
Reference: [Cra94] <author> James Crawford. </author> <type> "Personal Communication.", </type> <month> September </month> <year> 1994. </year>
Reference-contexts: In order to address the issue of sibling-node cost correlation, it has been suggested <ref> [Cra94] </ref> that the random-tree model can be updated to allow the range of edge costs to change with the depth of the tree. If the edge-cost range increases with the depth of a node, then the correlation between sibling node costs will be reduced. <p> We have also investigated the possibility of applying our methods to more general scheduling problems such as airline gate scheduling [Gre94], diverting airplanes 148 when an airport is closed <ref> [Cra94] </ref>, and allocating medical resources during trauma care [Hor93]. Our plan is to investigate these and other applications as the next step of our research. Another area that deserves more attention is the connection between our k-best algorithms and McAllester's work on conspiracy theory [McA88].
Reference: [DB88] <author> Thomas Dean and Mark Boddy. </author> <title> "An Analysis of Time-Dependent Planning." </title> <booktitle> In Proceedings, 7 th National Conference on Artificial Intelligence (AAAI-88), </booktitle> <address> St. Paul, MN, </address> <pages> pp. 49-54, </pages> <address> Palo Alto, CA, </address> <year> 1988. </year> <month> 191 </month>
Reference-contexts: The interesting part of this problem is that the robot can think while it is moving, thus the time spent traveling to the next city can be used to further calculate which of the remaining cities is the best next choice. An anytime approach to this problem <ref> [DB88] </ref> assumes that there is some initial computation time after which the tour is executed without change. Anytime algorithms are designed to produce a complete solution when the computation time runs out. <p> a range of edge costs for our random trees so that the average-case search complexity of finding a minimum-cost root-to-leaf path is exponential in the search depth. 10.2.2 Resource-Bounded Decision Making Dean and Boddy first coined the phrase anytime algorithms to refer to one type of time-dependent decision making in <ref> [DB88] </ref>, and later developed this idea further in [Bod91, BD94]. The idea behind anytime algorithms is that they can be interrupted at any time during the computation and return a result whose quality is a non-decreasing function of the computation time.
Reference: [Dea86] <author> Thomas L. Dean. </author> <title> "Intractability and Time-Dependent Planning." </title> <editor> In Michael P. Georgeff and Amy L. Lansky, editors, </editor> <booktitle> Proceedings of the 1986 Workshop on Reasoning About Actions and Plans, </booktitle> <pages> pp. 245-266. </pages> <publisher> Morgan Kaufmann, </publisher> <month> June </month> <year> 1986. </year>
Reference: [Dea91a] <author> Thomas Dean. </author> <title> "Decision-Theoretic Control of Inference for Time-Critical Applications." </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 6 </volume> <pages> 417-441, </pages> <year> 1991. </year>
Reference-contexts: One additional extension of the random-tree model would be to allow for stochastic events rather than just deterministic execution of the schedule as specified (i.e., a Markov Decision Problem <ref> [Dea91a, BBS93] </ref>). One example is if the time required to process a job was not a fixed constant, but rather was described by a continuous probability distribution over a range of processing times.
Reference: [Dea91b] <author> Thomas Dean. </author> <title> "Planning Under Uncertainty and Time Pressure." </title> <booktitle> In Proceedings of the 1990 Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pp. 390-395, </pages> <year> 1991. </year>
Reference: [Dea94] <author> Thomas Dean. </author> <title> "Decision-Theoretic Planning and Markov Decision Processes." </title> <type> Unpublished manuscript, </type> <year> 1994. </year>
Reference-contexts: One common thread in this work is a desire to understand the problem of how to operate under conditions where computational resources are limited. Three surveys of real-time problem solving techniques can be found in <ref> [DW91, SP94, Dea94] </ref>. Hansson and Mayer [HM90] have also proposed a decision-theoretic approach to search control. Their basic idea is to treat search as a decision problem.
Reference: [DKK93a] <author> Thomas Dean, Leslie Kaelbling, Jak Kirman, and Ann Nicholson. </author> <title> "Deliberation Scheduling for Time-Critical Sequential Decision Making." </title> <editor> In David Heckerman and Abe Mamdani, editors, </editor> <booktitle> Proceedings of the Ninth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pp. 309-316, </pages> <address> Washington, D. C., </address> <month> July </month> <year> 1993. </year>
Reference-contexts: He has looked at many different aspects of the resource-bounded decision problem. In particular, he used decision theory to develop a normative approach to metareasoning. Metareason-ing, also known as deliberation scheduling in <ref> [Bod91, DKK93b, DKK93a] </ref>, and metal-level reasoning in [RW91], describes the process of deciding what computations to perform in support of a reasoning process.
Reference: [DKK93b] <author> Thomas Dean, Leslie Pack Kaelbling, Jak Kirman, and Ann Nichol-son. </author> <title> "Planning Under Time Constraints in Stochastic Domains." </title> <type> Technical Report CS-93-55, </type> <institution> Brown University Computer Science Department, </institution> <year> 1993. </year> <note> [URL: http://www.cs.brown.edu/publications/techreports/reports/CS-93-55.] </note>
Reference-contexts: He has looked at many different aspects of the resource-bounded decision problem. In particular, he used decision theory to develop a normative approach to metareasoning. Metareason-ing, also known as deliberation scheduling in <ref> [Bod91, DKK93b, DKK93a] </ref>, and metal-level reasoning in [RW91], describes the process of deciding what computations to perform in support of a reasoning process.
Reference: [DS90] <author> Thomas Dean and Greg Siegle. </author> <title> "An Approach to Reasoning About Continuous Change for Applications in Planning." </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence (AAAI90), </booktitle> <pages> pp. 132-137. </pages> <booktitle> American Association for Artificial Intelligence, </booktitle> <year> 1990. </year>
Reference: [DSB93] <author> Mark Drummond, Keith Swanson, John Bresina, and Rich Levin-son. </author> <title> "Reaction-First Search." </title> <booktitle> In Proceedings of the 13 th International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <year> 1993. </year>
Reference: [DW91] <author> Thomas L. Dean and Michael P. Wellman. </author> <title> Planning and Control. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1991. </year> <month> 192 </month>
Reference-contexts: One common thread in this work is a desire to understand the problem of how to operate under conditions where computational resources are limited. Three surveys of real-time problem solving techniques can be found in <ref> [DW91, SP94, Dea94] </ref>. Hansson and Mayer [HM90] have also proposed a decision-theoretic approach to search control. Their basic idea is to treat search as a decision problem.
Reference: [Elk90] <author> Charles Elkan. </author> <title> "Incremental, Approximate Planning." </title> <booktitle> In Pro--ceedings of the Eighth National Conference on Artificial Intelligence (AAAI90), </booktitle> <pages> pp. 145-150. </pages> <booktitle> American Association for Artificial Intelligence, </booktitle> <year> 1990. </year>
Reference: [Etz89] <author> Oren Etzioni. </author> <title> "Tractable Decision-Analytic Control." </title> <booktitle> In Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pp. 114-125, </pages> <month> May </month> <year> 1989. </year>
Reference: [FGG73] <author> S. H. Fuller, J. G. Gaschnig, and J. J. Gillogly. </author> <title> "An analysis of the alpha-beta pruning algorithm." </title> <type> Technical report, </type> <institution> Department of Computer Science, Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, </address> <year> 1973. </year>
Reference-contexts: In addition, these models have been used to better understand the general search process. Fuller et al. <ref> [FGG73] </ref> first used a random tree model to evaluate alpha-beta pruning in two player games. Karp and Pearl [KP83] considered the problem of finding an optimal path from the root to a leaf node in a uniform binary tree of known depth.
Reference: [Gin90] <author> Matthew L. Ginsberg. </author> <title> "Computational Considerations in Reasoning about Action." </title> <editor> In Katia Sycara, editor, </editor> <booktitle> Proceedings of the 1990 Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pp. 37-47, </pages> <year> 1990. </year>
Reference: [GJS76] <author> M. R. Garey, D. S. Johnson, and R. Sethi. </author> <title> "The complexity of flow-shop and jobshop scheduling." </title> <journal> Math. Oper. Res., </journal> <volume> 1 </volume> <pages> 117-129, </pages> <year> 1976. </year>
Reference-contexts: It has also been observed that the minimum sum-finishing-time decision 122 problem (namely does there exist a flowshop schedule with a sum-finishing-time of at most T ?) is NP-complete for flowshop problems with two or more machines <ref> [GJS76, GS79] </ref>. The sum-finishing-time optimization problem (namely what is the minimum sum-finishing-time schedule?) is at least as hard as the sum-finishing-time decision problem. <p> In particular, they cite the results of a different Johnson [Joh54] who first showed that two-machine flowshop scheduling can be solved in polynomial time when the objective is to minimize the time that the last job finishes (i.e., minimizing the makespan). Garey, Johnson, and Sethi <ref> [GJS76] </ref> later showed that the sum-finishing-time problem (i.e., is there a schedule with sum-finishing-time less than a certain value) is NP-complete for the two-machine flowshop scheduling problem. 10.2.4 Related Search Methods McAllester has also proposed a different search control method called conspiracy search [McA88].
Reference: [Goo94] <author> Richard Goodwin. </author> <title> "Reasoning About When to Start Acting." </title> <editor> In K. Hammond, editor, </editor> <booktitle> Proceedings of the Second International Conference on Artificial Intelligence Planning Systems (AIPS-94), </booktitle> <pages> pp. 86-91, </pages> <year> 1994. </year>
Reference-contexts: The obvious relaxation of this assumption is to allow for a general computation-cost function and then require the decision maker to determine when it should to stop and make decisions over the course of generating a solution. The work of Goodwin <ref> [Goo94] </ref> is one example of what has been done on this problem, although there is still ample room for research on this topic. In Chapter 9, we assumed that a good strategy for solving the real-time two-machine flowshop-scheduling problem is to keep the first machine busy.
Reference: [Gre94] <author> Lloyd Greenwald. </author> <type> "Personal Communication.", </type> <month> July </month> <year> 1994. </year>
Reference-contexts: We have considered applying our incremental search methods to a real-time formulation of the traveling salesperson problem (e.g., the robot courier problem in [Bod91]). We have also investigated the possibility of applying our methods to more general scheduling problems such as airline gate scheduling <ref> [Gre94] </ref>, diverting airplanes 148 when an airport is closed [Cra94], and allocating medical resources during trauma care [Hor93]. Our plan is to investigate these and other applications as the next step of our research.
Reference: [GS79] <author> Michael R. Garey and David S.Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <year> 1979. </year>
Reference-contexts: It has also been observed that the minimum sum-finishing-time decision 122 problem (namely does there exist a flowshop schedule with a sum-finishing-time of at most T ?) is NP-complete for flowshop problems with two or more machines <ref> [GJS76, GS79] </ref>. The sum-finishing-time optimization problem (namely what is the minimum sum-finishing-time schedule?) is at least as hard as the sum-finishing-time decision problem. <p> Other good general references on scheduling problems include [CMM67], which contains detailed examples of different schedule cost functions, and [BCG76], which is a collection of papers that investigate the use of computers in scheduling domains. Garey and Johnson <ref> [GS79] </ref> have compiled a number of complexity results on scheduling problems.
Reference: [HA90] <author> James Hendler and Ashok Agrawala. </author> <title> "Mission Critical Planning: AI on the MARUTI Real-time Operating System." </title> <editor> In Katia Sycara, editor, </editor> <booktitle> Proceedings of the 1990 Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pp. 231-239, </pages> <year> 1990. </year>
Reference: [Har90] <author> Leo Hartman. </author> <title> "Decision Theory and the Cost of Planning." </title> <type> Technical Report TR-CS-355, </type> <institution> University of Rochester, </institution> <year> 1990. </year>
Reference: [HF90] <author> Steve Hanks and R. James Firby. </author> <title> "Issues and Architectures for Planning and Execution." </title> <editor> In Katia Sycara, editor, </editor> <booktitle> Proceedings of the 1990 Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pp. 231-239, </pages> <year> 1990. </year> <month> 193 </month>
Reference: [HHR90] <author> Adele E. Howe, David M. Hart, and Paul R.Cohen. </author> <title> "Addressing Real--Time Constraints in the Design of Autonomous Agents." </title> <journal> The Journal of Real-Time Systems, </journal> <volume> 1 </volume> <pages> 81-97, </pages> <year> 1990. </year>
Reference: [HM90] <author> Othar Hansson and Andrew Mayer. </author> <title> "Decision-Theoretic Control of Search in BPS." </title> <booktitle> In Working Notes of the 1989 AAAI Spring Symposium on AI and Limited Rationality, </booktitle> <pages> pp. 59-63, </pages> <year> 1990. </year>
Reference-contexts: For our experiments, we made part of the metareasoning decision in advance (i.e., the stopping criteria) when we chose to investigate problems that have strict decision deadlines measured in terms of node generations. A large number of people have investigated similar problems (e.g., <ref> [HM90] </ref> and others in the 1989 AAAI Spring Symposium on AI and Limited Rationality). One common thread in this work is a desire to understand the problem of how to operate under conditions where computational resources are limited. <p> One common thread in this work is a desire to understand the problem of how to operate under conditions where computational resources are limited. Three surveys of real-time problem solving techniques can be found in [DW91, SP94, Dea94]. Hansson and Mayer <ref> [HM90] </ref> have also proposed a decision-theoretic approach to search control. Their basic idea is to treat search as a decision problem. They 140 use heuristic values in the search tree to update a Bayesian network [Pea88] that is used to maintain the set of beliefs about the current search problem.
Reference: [HMR90] <author> Othar Hansson, Andrew Mayer, and Stuart Russell. </author> <title> "Decision-Theoretic Planning in BPS." </title> <booktitle> In Working Notes of the AAAI Spring Symposium on Planning in Uncertain, Unpredictable or Changing Environments, </booktitle> <pages> pp. 44-48. </pages> <booktitle> American Association for Artificial Intelligence, </booktitle> <year> 1990. </year>
Reference: [Hor87] <author> Eric J. Horvitz. </author> <title> "Reasoning about Beliefs and Actions under Computational Resource Constraints." </title> <booktitle> In Proceedings, 3 rd Workshop on Uncertainty in AI, </booktitle> <address> Seattle, WA, </address> <pages> pp. 301-324, </pages> <month> July </month> <year> 1987. </year>
Reference: [Hor90] <author> Eric J. Horvitz. </author> <title> Computation and Action Under Bounded Resources. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: Alternatively, we could define the exploration problem based on some different stopping criterion, but this particular definition was chosen to simplify the analysis. This formulation of the problem also ignores the cost of the metareasoning <ref> [Hor90] </ref>, namely the cost of figuring out which nodes to explore. <p> We later relax this assumption, limiting the the number of node expansions per decision instead of the exploration depth. In terms of a general cost function for the computation, the allowed computations are free, and any additional computations have infinite cost. Thus, this is a strict-deadline problem formulation <ref> [Hor90] </ref>. In our flowshop-scheduling example, there is no cost for the exploration performed during the time that the 37 current job is being processed on the first machine. <p> Anytime algorithms try to find the best complete solution under a time constraint, whereas our real-time incremental search algorithms try to find the best next decision under a time constraint. Eric Horvitz <ref> [Hor90] </ref> has also investigated the problem of reasoning under resource constraints, which he called flexible computation. He has looked at many different aspects of the resource-bounded decision problem. In particular, he used decision theory to develop a normative approach to metareasoning.
Reference: [Hor93] <author> Eric J. Horvitz. </author> <type> "Personal Communication.", </type> <month> August </month> <year> 1993. </year>
Reference-contexts: We have also investigated the possibility of applying our methods to more general scheduling problems such as airline gate scheduling [Gre94], diverting airplanes 148 when an airport is closed [Cra94], and allocating medical resources during trauma care <ref> [Hor93] </ref>. Our plan is to investigate these and other applications as the next step of our research. Another area that deserves more attention is the connection between our k-best algorithms and McAllester's work on conspiracy theory [McA88].
Reference: [Iba76] <author> T. Ibaraki. </author> <title> "Computational efficiency of approximate branch-and-bound algorithms." </title> <journal> Mathematics of Operations Research, </journal> <volume> 1 </volume> <pages> 287-298, </pages> <year> 1976. </year>
Reference-contexts: The idea is that we are likely to find a lower-cost leaf node under a lower-cost child node. There are several different ways to adapt DFBnB for the real-time constraint. The first, and perhaps most obvious way is called truncated branch-and-bound (tBnB) <ref> [Iba76] </ref>. The idea is to perform DFBnB until the available time expires (or the available node generations are used up), and then return the best leaf node found so far. <p> At the very least, we could process some of the jobs while we are figuring out the optimal schedule, and then execute the remaining jobs according to the optimal schedule when it becomes available. One such algorithm is called truncated branch-and-bound (tBnB) <ref> [Iba76] </ref>. TBnB is a branch-and-bound algorithm for finding suboptimal solutions to combinatorial optimization problems, such as flowshop scheduling. It is most useful when there is only a limited amount of computation available to produce a complete solution.
Reference: [IS65] <author> Edward Ignall and Linus Schrage. </author> <title> "Application of the Branch and Bound Technique to Some Flow-Shop Scheduling Problems." </title> <journal> Operations Research, </journal> <volume> 13 </volume> <pages> 400-412, </pages> <year> 1965. </year>
Reference-contexts: Recall that there were four jobs to schedule on two machines. It turns out that it is only necessary to consider permutation schedules in order to find an optimal solution to a two-machine flowshop scheduling problem <ref> [IS65] </ref>. A permutation schedule is a schedule in which the order of job processing is the same on both machines. <p> The third is our incremental search approach. All of the search algorithms presented make use of a simple but accurate heuristic function for estimating the sum-finishing-time cost of completing a partial schedule that was first suggested by Ignall and Schrage <ref> [IS65] </ref>. Their basic idea is to calculate two simple estimates of the complete-schedule cost, one by ignoring the one-job-at-a-time constraint for jobs on the first machine and the other by ignoring the one-job-at-a-time constraint for jobs on the second machine. <p> real-time search as a method for making decisions in real time, by interleaving the scheduling process with the execution of the schedule. 141 10.2.3.2 General Scheduling References In our experiments presented in Chapter 9, we used a flowshop scheduling heuristic function (InS) that was first presented by Ignall and Schrage <ref> [IS65] </ref>. Their objective was to find a way to better prune a branch-and-bound search in order to solve large scheduling problems optimally. Papadimitriou and Steiglitz [PS82] further discuss this problem in their book on combinatorial optimization. <p> completion cost before returning */ return (expMinPathCost + (double)z1/(double)(maxCost-1)); - APPENDIX E Estimating the Cost of a Flowshop Schedule The first half of this appendix contains a detailed description of the Ignall and Schrage's lower-bound heuristic evaluation function for the two-machine flowshop scheduling problem when using the sum-finishing-time cost function <ref> [IS65] </ref>. The second half contains the code we used to implement the InS heuristic evaulation function. E.1 Estimating the Complete Schedule Cost Ignall and Schrage [IS65] have proposed a simple but accurate heuristic function (InS heuristic) for estimating the cost of completing a partial schedule when using the sum-finishing-time cost function. <p> contains a detailed description of the Ignall and Schrage's lower-bound heuristic evaluation function for the two-machine flowshop scheduling problem when using the sum-finishing-time cost function <ref> [IS65] </ref>. The second half contains the code we used to implement the InS heuristic evaulation function. E.1 Estimating the Complete Schedule Cost Ignall and Schrage [IS65] have proposed a simple but accurate heuristic function (InS heuristic) for estimating the cost of completing a partial schedule when using the sum-finishing-time cost function.
Reference: [Joh54] <author> S. M. Johnson. </author> <title> "Optimal Two- and Three-Stage Production Schedules with Setup Times Included." </title> <journal> Nav. Res. Log. Quart., </journal> <volume> 1(1), </volume> <month> March </month> <year> 1954. </year> <title> also in Industrial Scheduling, </title> <editor> J. F. Muth and G. L. Thompson, eds., </editor> <publisher> Prentice-Hall, </publisher> <year> 1963, </year> <note> Chapter 2. </note>
Reference-contexts: It has been observed that for the case of a two-machine flowshop, the makespan decision problem (namely does there exist a flowshop schedule with a makespan of at most T ?) can be solved in time that is polynomial in the number of jobs <ref> [Joh54] </ref>. It has also been observed that the minimum sum-finishing-time decision 122 problem (namely does there exist a flowshop schedule with a sum-finishing-time of at most T ?) is NP-complete for flowshop problems with two or more machines [GJS76, GS79]. <p> Garey and Johnson [GS79] have compiled a number of complexity results on scheduling problems. In particular, they cite the results of a different Johnson <ref> [Joh54] </ref> who first showed that two-machine flowshop scheduling can be solved in polynomial time when the objective is to minimize the time that the last job finishes (i.e., minimizing the makespan).
Reference: [Joh90] <author> David S. Johnson. </author> <title> "Local Optimization and the Traveling Salesman Problem." </title> <editor> In M. S. Paterson, editor, </editor> <booktitle> Proceedings of the Seventeenth International Colloquium on Automata, Languages and Programming, </booktitle> <pages> pp. 446-461. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: This is essentially an incremental version of local search (e.g., <ref> [Joh90] </ref>). Whether failure recovery is possible or not, the general problem of making real-time decisions when all paths don't lead to a solution is still open.
Reference: [KC94] <author> R. E. Korf and D. M. Chickering. </author> <title> "Best-First Minimax: Othello Results." </title> <booktitle> In Proceedings of the 12 th National Conference on Artificial Intelligence (AAAI-94), </booktitle> <pages> pp. 1365-1370, </pages> <address> Seattle, WA, </address> <month> August </month> <year> 1994. </year> <month> 194 </month>
Reference-contexts: This would particularly important in light of the many less than entirely successful attempts to improve upon minimax with alpha-beta pruning (e.g., <ref> [ACH90, Bau93, Ber79, KC94, Nau83, Nil69, McA88, Riv87, RW89] </ref>). CHAPTER 12 Contributions and Conclusions There are four main research contributions reported in this dissertation. The first contribution is our formulation of the real-time incremental decision-making problem.
Reference: [KNP90] <author> Sarit Kraus, Madhura Nirkhe, and Donald Perlis. </author> <title> "Deadline-Coupled Real-Time Planning." </title> <editor> In Katia Sycara, editor, </editor> <booktitle> Proceedings of the 1990 Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pp. 100-108, </pages> <year> 1990. </year>
Reference: [Koe92] <author> Sven Koenig. </author> <title> "The Complexity of Real-time Search." </title> <type> Technical Report CMU-CS-92-145, </type> <institution> Carnegie Mellon University, </institution> <year> 1992. </year>
Reference: [Kor85] <author> Richard E. Korf. </author> <title> "Depth-first iterative-deepening: an optimal admissible tree search." </title> <journal> Artificial Intelligence, </journal> <volume> 27 </volume> <pages> 97-109, </pages> <year> 1985. </year>
Reference-contexts: There are two potential problems with this approach, however, both of which stem from the fact that we want to be able to generate the same random tree or subtree more than once. The first problem is that a linear-space search algorithm (e.g., iterative-deepening <ref> [Kor85] </ref> or recursive best-first search [Kor93]) usually regenerates part of the random tree, and expects a node and its subtree to look the same when it is revisited. <p> The OPEN list is the set of nodes that have been generated but not expanded by a best-first exploration. The main problem with this approach is the exponential memory requirement. To avoid the memory problem, Korf suggested a variation of IDA* <ref> [Kor85] </ref> called threshold-limited-IDA*. The idea is to run a single iteration of IDA* with a threshold that is a constant amount greater than the heuristic estimate of the current node.
Reference: [Kor90] <author> Richard E. Korf. </author> <title> "Real-time heuristic search." </title> <journal> Artificial Intelligence, </journal> <volume> 42(2-3):189-211, </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: One answer is to use MINIMIN <ref> [Kor90] </ref>, which is an existing real-time decision algorithm. <p> The third contribution is a set of analytical and experimental results that demonstrate the unexpectedly high level of performance of MINIMIN on randomly generated decision problems. MINIMIN is an incremental search algorithm for real-time decision making previously described in <ref> [Kor90] </ref>. This high level of performance limits the amount of improvement that any new algorithm could obtain. Our fourth contribution is a new decision method called k-best. k-best is both an approximation of the optimal decision method, and an extension of MINIMIN. <p> We present the optimal decision-making algorithm for the last incremental decision, which moves to a child of the root node with the lowest expected minimum path cost (E (M P C)). We also present MINIMIN <ref> [Kor90] </ref>, which is the best-known existing algorithm for this problem. A MIN-IMIN decision is to move to a child of the root on a minimum-cost path in the explored part of the problem space. <p> We first summarize Mutchler's work on allocating limited search resources [Mut86], specifically including a discussion of his random-tree model for evaluating search methods. Next we discuss Korf's presentation of the MINIMIN decision algorithm <ref> [Kor90] </ref>. The discussion of MIN-IMIN is important because it serves as both a benchmark and starting point for 11 our new incremental search algorithms. Finally, we summarize Russell and We--fald's work on DTA*, which provides a general decision-theoretic framework for real-time search. <p> depth, the margin for improvement will increase with the number of unexplored levels in the problem-space tree. 5.1 Making a Last Incremental Decision In this section, we present MINIMIN and E (M P C), which are two methods for making incremental decisions. 54 5.1.1 The MINIMIN Decision Method MINIMIN algorithm <ref> [Kor90] </ref> is the single-agent analog of the minimax algorithm for two-player games, such as chess. <p> To our knowledge, Korf <ref> [Kor90] </ref> was the first to apply these ideas to single-agent heuristic search problems. Real-time A* (RTA*) is the first example of a single-agent incremental search algorithm, and has served as a strong motivation for our approach. The MINIMIN algorithm also serves as a benchmark algorithm for our experiments.
Reference: [Kor93] <author> Richard E. Korf. </author> <title> "Linear-space best-first search." </title> <journal> Artificial Intelligence, </journal> <volume> 62(1) </volume> <pages> 41-78, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: There are two potential problems with this approach, however, both of which stem from the fact that we want to be able to generate the same random tree or subtree more than once. The first problem is that a linear-space search algorithm (e.g., iterative-deepening [Kor85] or recursive best-first search <ref> [Kor93] </ref>) usually regenerates part of the random tree, and expects a node and its subtree to look the same when it is revisited. <p> Increasing the size of the OPEN list will increase the overhead, but reduce the number of decisions made because the OPEN list is full. Alternatively, we could have chosen to implement a linear-space best-first search algorithm (e.g., <ref> [Kor93] </ref>). We decided against this because of the overhead cost resulting from regenerating nodes. <p> At this point a decision 144 is made. This allows us to prune the irrelevant nodes from the OPEN list, freeing up space to explore for the next decision. Thus decisions are made when the time runs out or the memory becomes full. Other approaches have been considered in <ref> [CGA89, Rus92, SB89, MGP92, Kor93] </ref>, for the general search problem. Through the design of our random-tree model, and our choice of the flowshop-scheduling problem, we have focussed on problems where every leaf node is a solution, and the objective is simply to find a low-cost solution.
Reference: [KP83] <author> R.M. Karp and J. Pearl. </author> <title> "Searching for an optimal path in a tree with random costs." </title> <journal> Artificial Intelligence, </journal> <volume> 21 </volume> <pages> 99-117, </pages> <year> 1983. </year>
Reference-contexts: Even with pruning, in the worst case we may still have to generate all of the leaf nodes in order to make an optimal incremental search decision. The problem of finding a minimum-cost path in a random tree has been previously examined by <ref> [KP83, McD90b, MP91, ZK95, KPZ94] </ref>. Their results include the observation that there is no known closed form for the distribution of minimum-cost paths in a general random tree. <p> The problem of determining the expected minimum path cost in an unexplored 46 random tree has been previously studied <ref> [KP83, McD90b, MP91] </ref>. Unfortunately, there is no known closed form solution for the distribution or expected minimum path cost as a function of the tree depth (d) and branching factor (b). <p> In addition, these models have been used to better understand the general search process. Fuller et al. [FGG73] first used a random tree model to evaluate alpha-beta pruning in two player games. Karp and Pearl <ref> [KP83] </ref> considered the problem of finding an optimal path from the root to a leaf node in a uniform binary tree of known depth. Their random trees had edge costs of 1 or 0 with probability p and (1 p).
Reference: [KPZ94] <author> Richard E. Korf, Joseph C. Pemberton, and Weixiong Zhang. </author> <title> "Incremental Random Search Trees." </title> <editor> In James M. Crawford and Bart Selman, editors, </editor> <booktitle> Working Notes of the AAAI-94 Workshop on Experimental Evaluation of Reasoning and Search Methods. American Association for Artificial Intelligence, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: For example, every time a node is expanded, we could first call a random number generator to determine the branching factor b, and then call the random number generator again b times, once for each edge cost. This 17 on-demand method <ref> [KPZ94] </ref> works fine if the tree will only be searched once and the same node is never revisited by the search process. <p> Even with pruning, in the worst case we may still have to generate all of the leaf nodes in order to make an optimal incremental search decision. The problem of finding a minimum-cost path in a random tree has been previously examined by <ref> [KP83, McD90b, MP91, ZK95, KPZ94] </ref>. Their results include the observation that there is no known closed form for the distribution of minimum-cost paths in a general random tree. <p> The first section is from <ref> [KPZ94] </ref>. The second section contains annotated code that implements the random tree generator. A.1 The Method In order to reproducibly generate a random tree without storing it, we first make the following observation.
Reference: [KR88] <author> Brian W. Kernighan and Dennis M. Ritchie. </author> <title> The C Programming Language. </title> <publisher> Prentice Hall, </publisher> <address> second edition, </address> <year> 1988. </year>
Reference-contexts: To address the problem of efficiently generating the random number associated with a given breadth-first index, we developed a method for efficiently finding the k th random seed that would occur after k calls to the rand () function in the standard C library distribution <ref> [KR88] </ref>. The approach is based on analyzing what operations the rand () function performs and then solving for an equation that describes the k th random seed as a function of the initial random seed and k. <p> As might be expected, this approach is very inefficient. In order to efficiently generate the random number associated with a given breadth-first index, we examined the details of the rand () function in the standard C library distribution <ref> [KR88] </ref>. Recall that the breadth-first index of a node is determined by the order in which nodes would be generated by a breadth-first search.
Reference: [KS76] <author> W. H. Kohler and K. Steiglitz. </author> <title> Computer and Job-Shop Scheduling Theory, </title> <booktitle> chapter 6: Enumerative and Iterative Computational Approaches, </booktitle> <pages> pp. 229-288. </pages> <publisher> John Wiley and Sons, </publisher> <year> 1976. </year>
Reference: [LPD88] <author> Victor R. Lesser, Jasmina Pavlin, and Edmund Durfee. </author> <title> "Approximate Processing in Real-Time Problem Solving." </title> <journal> AI Magazine, </journal> <pages> pp. 49-61, </pages> <year> 1988. </year>
Reference: [Man79] <author> Edwin Mansfield. Micro-Economics: </author> <title> Theory and Applications. W.W. </title> <publisher> Norton and Company, </publisher> <address> third edition, </address> <year> 1979. </year>
Reference: [McA88] <author> David Allen McAllester. </author> <title> "Conspiracy Numbers for Min-Max Search." </title> <journal> Artificial Intelligence, </journal> <volume> 35 </volume> <pages> 287-310, </pages> <year> 1988. </year> <month> 195 </month>
Reference-contexts: Garey, Johnson, and Sethi [GJS76] later showed that the sum-finishing-time problem (i.e., is there a schedule with sum-finishing-time less than a certain value) is NP-complete for the two-machine flowshop scheduling problem. 10.2.4 Related Search Methods McAllester has also proposed a different search control method called conspiracy search <ref> [McA88] </ref>. His basic idea is to focus the search resources in locations where they are most likely to have an effect on the current decision. He introduced the idea of a conspiracy number, which is the number of frontier nodes whose value would have to change the current decision. <p> Our plan is to investigate these and other applications as the next step of our research. Another area that deserves more attention is the connection between our k-best algorithms and McAllester's work on conspiracy theory <ref> [McA88] </ref>. His basic idea is to focus the search resources in locations where they are most likely to have an effect on the current decision. He introduced the idea of a conspiracy number, which is the number of frontier nodes whose value would have to change the current decision. <p> This would particularly important in light of the many less than entirely successful attempts to improve upon minimax with alpha-beta pruning (e.g., <ref> [ACH90, Bau93, Ber79, KC94, Nau83, Nil69, McA88, Riv87, RW89] </ref>). CHAPTER 12 Contributions and Conclusions There are four main research contributions reported in this dissertation. The first contribution is our formulation of the real-time incremental decision-making problem.
Reference: [McD90a] <author> Drew McDermott. </author> <title> "Planning Reactive Behavior: A Progress Report." </title> <editor> In Katia Sycara, editor, </editor> <booktitle> Proceedings of the 1990 Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pp. 231-239, </pages> <year> 1990. </year>
Reference: [McD90b] <author> C. J. H. McDiarmid. </author> <title> "Probabilistic analysis of tree search." </title> <editor> In G. R. Gummett and D. J. A. Welsh, editors, </editor> <booktitle> Disorder in Physical Systems, </booktitle> <pages> pp. 249-260. </pages> <publisher> Oxford Science Publishing, </publisher> <year> 1990. </year>
Reference-contexts: Even with pruning, in the worst case we may still have to generate all of the leaf nodes in order to make an optimal incremental search decision. The problem of finding a minimum-cost path in a random tree has been previously examined by <ref> [KP83, McD90b, MP91, ZK95, KPZ94] </ref>. Their results include the observation that there is no known closed form for the distribution of minimum-cost paths in a general random tree. <p> The problem of determining the expected minimum path cost in an unexplored 46 random tree has been previously studied <ref> [KP83, McD90b, MP91] </ref>. Unfortunately, there is no known closed form solution for the distribution or expected minimum path cost as a function of the tree depth (d) and branching factor (b). <p> Their random trees had edge costs of 1 or 0 with probability p and (1 p). Their analytical results concerned the expected complexity of algorithms for finding an optimal or near optimal solution as a function of p. Others <ref> [McD90b, ZK95, ZP94a] </ref> have extended the single-agent search model to real-valued edge costs and have further analyzed both the model and new algorithms based on this analysis. Our development of real-time search on random trees and our choice of edge-cost ranges has benefited from this prior work on random trees.
Reference: [MG90] <author> A. Mahanti and S. Ghosh. </author> <title> "Best First Search with Controlled Time and Storage." </title> <type> Technical Report UMIACS-TR-90-108, </type> <institution> Institute for Advanced Computer Studies, University of Maryland, </institution> <year> 1990. </year>
Reference: [MGP92] <author> A. Mahanti, S. Ghosh, and A. K. Pal. </author> <title> "A High-Performance Limited-Memory Admissible and Real Time Search Algorithm for Networks." </title> <type> Technical Report UM-CS-TR-2858, </type> <institution> University of Maryland, </institution> <year> 1992. </year>
Reference-contexts: At this point a decision 144 is made. This allows us to prune the irrelevant nodes from the OPEN list, freeing up space to explore for the next decision. Thus decisions are made when the time runs out or the memory becomes full. Other approaches have been considered in <ref> [CGA89, Rus92, SB89, MGP92, Kor93] </ref>, for the general search problem. Through the design of our random-tree model, and our choice of the flowshop-scheduling problem, we have focussed on problems where every leaf node is a solution, and the objective is simply to find a low-cost solution.
Reference: [MP91] <author> C. J. H. McDiarmid and G. M. A. Provan. </author> <title> "An expected-cost analysis of backtracking and non-backtracking algorithms." </title> <booktitle> In Proceedings, 12 th International Joint Conference on Artificial Intelligence, (IJCAI-91), </booktitle> <pages> pp. 172-177, </pages> <address> Sydney, Australia, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: Even with pruning, in the worst case we may still have to generate all of the leaf nodes in order to make an optimal incremental search decision. The problem of finding a minimum-cost path in a random tree has been previously examined by <ref> [KP83, McD90b, MP91, ZK95, KPZ94] </ref>. Their results include the observation that there is no known closed form for the distribution of minimum-cost paths in a general random tree. <p> The problem of determining the expected minimum path cost in an unexplored 46 random tree has been previously studied <ref> [KP83, McD90b, MP91] </ref>. Unfortunately, there is no known closed form solution for the distribution or expected minimum path cost as a function of the tree depth (d) and branching factor (b).
Reference: [MS90] <author> Nicola Muscettola and Stephen F. Smith. </author> <title> "Integrating Planning and Scheduling to Solve Space Mission Scheduling Problems." </title> <editor> In Katia Sycara, editor, </editor> <booktitle> Proceedings of the 1990 Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pp. 220-230, </pages> <year> 1990. </year>
Reference: [Mut86] <author> David Mutchler. </author> <title> "Optimal Allocation of Very Limited Search Resources." </title> <booktitle> In Proceedings, 5 th National Conference on Artificial Intelligence (AAAI-86), </booktitle> <address> Philadelphia, PA, </address> <pages> pp. 467-471, </pages> <address> Palo Alto, CA, </address> <year> 1986. </year>
Reference-contexts: The decision-making problem is the task of choosing an action or committing to a move based on the available information. This corresponds to choosing a child of the root node to become the next root node. A specific case of the exploration problem has been previously examined by Mutchler <ref> [Mut86] </ref>. An example of Mutchler's exploration problem is shown in more edge (b, c, or d) before it must choose a complete path from the root to a leaf node at the bottom of the tree. <p> The first half of this chapter contains a discussion of three papers that have most directly impacted our research. We first summarize Mutchler's work on allocating limited search resources <ref> [Mut86] </ref>, specifically including a discussion of his random-tree model for evaluating search methods. Next we discuss Korf's presentation of the MINIMIN decision algorithm [Kor90]. The discussion of MIN-IMIN is important because it serves as both a benchmark and starting point for 11 our new incremental search algorithms. <p> One additional result is that, under certain conditions, any algorithm for finding a solution path with cost that is within a constant of optimal must take time that is exponential in the search depth on average. 21 David Mutchler <ref> [Mut86] </ref> has looked at a similar problem, where his task was to decide which nodes to expand (where expanding a node consists of learning the edge costs to its children) in order to minimize the cost of a traversed path. <p> cost of the metareasoning, and use the issue of overall efficiency to argue against any algorithm that requires more than a small amount of computation for metareasoning. 3.2 Background on Exploration Our definition of the exploration problem can be viewed as an extension of the problem investigated by Mutchler in <ref> [Mut86] </ref>. <p> This is similar to the way that Mutchler evaluated frontier nodes in <ref> [Mut86] </ref>. 3.4 The Stopping Problem Although we have assumed strict decision deadlines in order to avoid the stopping problem, in this section we define the stopping problem and discuss the issues related to solving it. The stopping problem can be defined as follows. <p> Lastly we present a brief summary of Russell and Wefald's approach to real-time decision making. 10.1.1 Searching Random Trees with Limited Resources Much of our work on using random trees to analyze real-time decision making was motivated by David Mutchler's work on how to optimally allocate scarce search resources <ref> [Mut86] </ref>. In his work, he used a random-tree to model the complete solution problem under real-time constraints.
Reference: [Mut92] <author> David Mutchler. </author> <title> "Heuristic search with limited resources, Part I." </title> <type> Unpublished manuscript, </type> <month> November </month> <year> 1992. </year>
Reference: [Nau83] <author> D. S. Nau. </author> <title> "Pathology on Game Trees Revisited, and an Alternative to Minimaxing." </title> <journal> Artificial Intelligence, </journal> <volume> 21(1, </volume> 2):221-244, March 1983. 
Reference-contexts: This would particularly important in light of the many less than entirely successful attempts to improve upon minimax with alpha-beta pruning (e.g., <ref> [ACH90, Bau93, Ber79, KC94, Nau83, Nil69, McA88, Riv87, RW89] </ref>). CHAPTER 12 Contributions and Conclusions There are four main research contributions reported in this dissertation. The first contribution is our formulation of the real-time incremental decision-making problem.
Reference: [Nil69] <author> N. J. Nilsson. </author> <title> "Searching problem-solving and game-playing trees for minimal cost solutions." </title> <editor> In A. J. H. Morrell, editor, </editor> <booktitle> Information Processing 68, Proceedings of the IFIP Congress 1968, </booktitle> <pages> pp. 1556-1562, </pages> <address> Amsterdam, 1969. </address> <publisher> North-Holland. </publisher> <pages> 196 </pages>
Reference-contexts: This would particularly important in light of the many less than entirely successful attempts to improve upon minimax with alpha-beta pruning (e.g., <ref> [ACH90, Bau93, Ber79, KC94, Nau83, Nil69, McA88, Riv87, RW89] </ref>). CHAPTER 12 Contributions and Conclusions There are four main research contributions reported in this dissertation. The first contribution is our formulation of the real-time incremental decision-making problem.
Reference: [Pea83] <author> Judea Pearl. </author> <title> "Knowledge versus Search: A Quantitative Analysis Using A fl ." Artificial Intelligence, </title> <booktitle> 20 </booktitle> <pages> 1-13, </pages> <year> 1983. </year>
Reference: [Pea84] <author> Judea Pearl. </author> <title> Heuristics. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1984. </year>
Reference-contexts: In this interpretation, the edge costs correspond to the costs of applying the operators. Alternatively, we can view the random tree as a heuristic search tree. If the heuristic function is admissible (never overestimates the actual cost to a leaf node <ref> [Pea84] </ref>) and consistent (the estimated complete solution cost of a parent node is 16 never greater than the estimated complete solution cost of a child node [Pea84]), then the edge costs are equal to the difference between adjacent node costs in the random-tree model. <p> If the heuristic function is admissible (never overestimates the actual cost to a leaf node <ref> [Pea84] </ref>) and consistent (the estimated complete solution cost of a parent node is 16 never greater than the estimated complete solution cost of a child node [Pea84]), then the edge costs are equal to the difference between adjacent node costs in the random-tree model. From the perspective of heuristic search, edge costs can be viewed as the improvement in heuristic estimate that results when a node is expanded. <p> In fact, for the random-tree model that we have adopted, the node-cost search heuristic is the only admissible heuristic. A heuristic function h is admissible if h (n) h fl (n) for all n, where h fl is the actual value being estimated <ref> [Pea84] </ref>. In other words, an admissible heuristic function never overestimates the value being estimated.
Reference: [Pea88] <author> Judea Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: For example, a common assumption is that the value of a computation can be evaluated in isolation from other computations (a myopic assumption <ref> [Pea88] </ref>). This is clearly suboptimal, because one the reasons for expanding a node is that it makes other node expansions possible. Nonetheless, this assumption is reasonable, when the main value of a node expansion is being able to see and evaluate its children. <p> Hansson and Mayer [HM90] have also proposed a decision-theoretic approach to search control. Their basic idea is to treat search as a decision problem. They 140 use heuristic values in the search tree to update a Bayesian network <ref> [Pea88] </ref> that is used to maintain the set of beliefs about the current search problem. Their BPS search algorithm uses the Bayesian network to calculate the expected effect of an exploration, and then choose the exploration with the best expected influence on the current decision.
Reference: [Per90] <author> E. L. Perry. </author> <title> "Solution of Time Constrained Scheduling Problems with Parallel Tabu Search." </title> <editor> In Katia Sycara, editor, </editor> <booktitle> Proceedings of the 1990 Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pp. 231-239, </pages> <year> 1990. </year>
Reference: [PK93] <author> Joseph C. Pemberton and Richard E. Korf. </author> <title> "An Incremental Search Approach to Real-Time Planning and Scheduling." In Foundations of Automatic Planning: </title> <booktitle> The Classical Approach and Beyond, </booktitle> <pages> pp. 107-111. </pages> <note> AAAI Press Technical Report #SS-93-03, </note> <year> 1993. </year>
Reference: [PK94a] <author> Joseph C. Pemberton and Richard E. Korf. </author> <title> "Incremental Search Algorithms for Real-Time Decision Making." </title> <booktitle> In Proceedings, Second International Conference on Artificial Intelligence Planning Systems (AIPS-94), </booktitle> <pages> pp. 140-145, </pages> <year> 1994. </year>
Reference: [PK94b] <author> Joseph C. Pemberton and Richard E. Korf. </author> <title> "An Incremental Search Approach to Real-Time Decision Making." </title> <booktitle> In Proceedings, AAAI Spring Symposium on Planning, </booktitle> <address> Stanford, CA, </address> <year> 1994. </year>
Reference: [PS82] <author> Christos H. Papadimitriou and Kenneth Steiglitz. </author> <title> Combinatorial Optimization: Algorithms and Complexity. </title> <publisher> Prentice Hall, </publisher> <year> 1982. </year>
Reference-contexts: A sample flowshop schedule is shown in Figure 9.1c. 119 jobs and their processing times, and (c) a sample schedule. 120 The cost of a flowshop schedule depends on the cost function employed. For the two-machine flowshop scheduling problem, there are two commonly used cost functions: makespan and sum-finish-time <ref> [PS82] </ref>. The makespan, which is perhaps the most obvious cost function, is simply the time when the last job finishes being processed by the last machine. For the example, the makespan of the sample schedule in Figure 9.1 is 32 time units. <p> Their objective was to find a way to better prune a branch-and-bound search in order to solve large scheduling problems optimally. Papadimitriou and Steiglitz <ref> [PS82] </ref> further discuss this problem in their book on combinatorial optimization. We found their treatment of the InS heuristic function easier to follow than the original treatment. <p> This is because we can calculate the two lower bound estimates by simply sorting the jobs based on their processing time on the machine that still has the one-job-at-a-time constraint. Our presentation of Ignall and Schrage's heuristic follows Papadimitriou and Steiglitz's treatment in <ref> [PS82] </ref>. Again we consider the scheduling problem in Figure 9.1, except that now we assume that these are the last four jobs to be scheduled. The other jobs (not shown) have already been scheduled.
Reference: [Riv87] <author> R. L. Rivest. </author> <title> "Game tree searching by min/max approximation." </title> <journal> Artificial Intelligence, </journal> <volume> 34(1) </volume> <pages> 77-96, </pages> <year> 1987. </year>
Reference-contexts: This would particularly important in light of the many less than entirely successful attempts to improve upon minimax with alpha-beta pruning (e.g., <ref> [ACH90, Bau93, Ber79, KC94, Nau83, Nil69, McA88, Riv87, RW89] </ref>). CHAPTER 12 Contributions and Conclusions There are four main research contributions reported in this dissertation. The first contribution is our formulation of the real-time incremental decision-making problem.
Reference: [Rus92] <author> Stuart Russell. </author> <title> "Efficient memory-bounded search methods." </title> <booktitle> In Proceedings, European Conference on Artificial Intelligence (ECAI-92), </booktitle> <year> 1992. </year>
Reference-contexts: At this point a decision 144 is made. This allows us to prune the irrelevant nodes from the OPEN list, freeing up space to explore for the next decision. Thus decisions are made when the time runs out or the memory becomes full. Other approaches have been considered in <ref> [CGA89, Rus92, SB89, MGP92, Kor93] </ref>, for the general search problem. Through the design of our random-tree model, and our choice of the flowshop-scheduling problem, we have focussed on problems where every leaf node is a solution, and the objective is simply to find a low-cost solution.
Reference: [RW89] <author> S. Russell and E. Wefald. </author> <title> "On optimal game-tree search using rational meta-reasoning." </title> <booktitle> In Proceedings of the 11 th International Joint Conference on Artificial Intelligence (IJCAI-89), </booktitle> <pages> pp. 334-340, </pages> <address> Detroit, MI, </address> <year> 1989. </year>
Reference-contexts: This would particularly important in light of the many less than entirely successful attempts to improve upon minimax with alpha-beta pruning (e.g., <ref> [ACH90, Bau93, Ber79, KC94, Nau83, Nil69, McA88, Riv87, RW89] </ref>). CHAPTER 12 Contributions and Conclusions There are four main research contributions reported in this dissertation. The first contribution is our formulation of the real-time incremental decision-making problem.
Reference: [RW91] <author> Stuart Russell and Eric Wefald. </author> <title> Do the Right Thing. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year> <month> 197 </month>
Reference-contexts: Note that these results assume that there are not sufficient node generations to reach the bottom of the tree. The general conclusion from Mutchler's work is that the exploration problem is difficult. Others have also argued that the general exploration problem is difficult (e.g., <ref> [RW91] </ref>), and that it is necessary to make simplifying assumptions in order to address the problem. For example, a common assumption is that the value of a computation can be evaluated in isolation from other computations (a myopic assumption [Pea88]). <p> The marginal utility in this case is the added benefit to the decision maker of the information made available by one additional node expansion, and the marginal cost is the time needed to expand a node. This is essentially what Russell and Wefald suggested in <ref> [RW91] </ref>. There are two potential problems with this approach. One is that the time needed to calculate the marginal utility may be more than the time needed to perform the computation itself. The second is that the information needed to calculate or estimate the marginal utility may not be available. <p> In this case, the value of a node expansion can be approximated by the expected effect that it would have on the decision if it were the last computation performed before making a decision <ref> [RW91] </ref>. One problem with this approach is that it can easily underestimate the value of a node exploration by not considering the additive effect of several node explorations together. <p> This single-heuristic cost function approach has also been suggested by Russell and Wefald <ref> [RW91] </ref> for use in real-time search algorithms (e.g., DTA*). The motivation for using a single heuristic for exploration and decision making comes from a combination of their meta-greedy assumption and their single-step assumption. <p> The results for the traditional best-first search algorithms are not surprising since node-cost and estimated-cost BFS were not expected to perform well. What is interesting is that a previous decision-theoretic analysis of the exploration problem <ref> [RW91] </ref> suggested that, for a given decision heuristic evaluation function and the single-step assumption (i.e., that the value of a node expansion can be determined by assuming that it is the last computation before a move decision), the best node to explore should be determined by the same heuristic function. 103 <p> In general, Korf's work on real-time search algorithms has provided us with a good starting point, and with a better than expected benchmark (MINIMIN). 10.1.3 Decision-Theoretic Search (DTA*) Russell and Wefald <ref> [RW91] </ref> present a general decision-theoretic framework for making real-time search decisions. In particular, they present a real-time search algorithm called DTA* that is based on decision-theoretic principles. DTA* consists of three parts. <p> MINIMIN is only guaranteed to be optimal under certain conditions, such as when a single lookahead search is followed by a choice of a complete solution path, as in the problem considered by Mutchler. For example, consider the tree in Figure 10.1. Here our notation follows <ref> [RW91] </ref>. At this point in the search, the child node labeled ff has the lowest f-value of children of the root. <p> He has looked at many different aspects of the resource-bounded decision problem. In particular, he used decision theory to develop a normative approach to metareasoning. Metareason-ing, also known as deliberation scheduling in [Bod91, DKK93b, DKK93a], and metal-level reasoning in <ref> [RW91] </ref>, describes the process of deciding what computations to perform in support of a reasoning process. A general decision-theoretic approach to metareasoning is useful for analyzing problems and algorithms, but, as Horvitz notes, the improvement in resource allocation may not make up for the computation time spent performing the metareasoning.
Reference: [SB89] <author> A.K. Sen and A. Bagchi. </author> <title> "Fast recursive formulations for best-first search that allow controlled use of memory." </title> <booktitle> In Proceedings, 11 th International Joint Conference on Artificial Intelligence, (IJCAI-89), </booktitle> <address> Detroit, MI, </address> <pages> pp. 297-302, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: At this point a decision 144 is made. This allows us to prune the irrelevant nodes from the OPEN list, freeing up space to explore for the next decision. Thus decisions are made when the time runs out or the memory becomes full. Other approaches have been considered in <ref> [CGA89, Rus92, SB89, MGP92, Kor93] </ref>, for the general search problem. Through the design of our random-tree model, and our choice of the flowshop-scheduling problem, we have focussed on problems where every leaf node is a solution, and the objective is simply to find a low-cost solution.
Reference: [Sha50] <author> C. E. Shannon. </author> <title> "Programming a computer for playing chess." </title> <journal> Philosophical Magazine, </journal> <volume> 41(7) </volume> <pages> 256-275, </pages> <year> 1950. </year>
Reference-contexts: This extension makes the results more generally applicable, although the analysis is more difficult. 10.1.2 Real-Time Search The idea of exploring to a limited search depth and then committing to moves in constant bounded time has existed in two-player game research since the initial work of Shannon <ref> [Sha50] </ref>. To our knowledge, Korf [Kor90] was the first to apply these ideas to single-agent heuristic search problems. Real-time A* (RTA*) is the first example of a single-agent incremental search algorithm, and has served as a strong motivation for our approach.
Reference: [Smi93] <author> David E. Smith. </author> <type> "Personal Communication.", </type> <month> August </month> <year> 1993. </year>
Reference-contexts: Through the design of our random-tree model, and our choice of the flowshop-scheduling problem, we have focussed on problems where every leaf node is a solution, and the objective is simply to find a low-cost solution. Such problem spaces are sometimes referred to as solution rich <ref> [Smi93] </ref>. Many planning and scheduling problems do not have this characteristic, in which case much of the computation for these problems is spent finding a feasible solution, if one exists.
Reference: [SOM90] <author> Stephen F. Smith, Peng Si Ow, Nicola Muscettola, Jean-Yves Potvin, and Dirk C. Matthys. "OPIS: </author> <title> An Integrated Framework for Generating and Revising Factory Schedules." </title> <editor> In Katia Sycara, editor, </editor> <booktitle> Proceedings of the 1990 Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pp. 231-239, </pages> <year> 1990. </year>
Reference: [SP94] <author> Jay K. Strosnider and C. J. Paul. </author> <title> "A Structured View of Real-Time Problem Solving." </title> <journal> AI Magazine, </journal> <volume> 15(2) </volume> <pages> 45-66, </pages> <year> 1994. </year>
Reference-contexts: One common thread in this work is a desire to understand the problem of how to operate under conditions where computational resources are limited. Three surveys of real-time problem solving techniques can be found in <ref> [DW91, SP94, Dea94] </ref>. Hansson and Mayer [HM90] have also proposed a decision-theoretic approach to search control. Their basic idea is to treat search as a decision problem.
Reference: [SRS90] <author> Katia Sycara, Steve Roth, Norman Sadeh, and Mark Fox. </author> <title> "Managing Resource Allocation in Multi-Agent Time-Constrained Domains." </title> <editor> In Katia Sycara, editor, </editor> <booktitle> Proceedings of the 1990 Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pp. 240-250, </pages> <year> 1990. </year>
Reference: [Sut90a] <author> Richard S. Sutton. </author> <title> "First Results with DYNA, an Integrated Architecture for Learning, Planning and Reacting." </title> <booktitle> In Working Note of the 1990 AAAI Spring Symposium on Planning in Uncertain, Unpredictable or Changing Environments, </booktitle> <pages> pp. 136-140, </pages> <year> 1990. </year>
Reference-contexts: Their work is complementary to ours, in the sense that they have focussed on more effective exploration, and we have focussed on better decision making. Sutton, Barto and others <ref> [Sut91, Sut90b, Sut90a, BBS93] </ref>, have proposed a dynamic programming approach to incrementally generating plans in situations where the same or similar problems recur. This is a very interesting approach that can be easily extended to stochastic problem domains [BBS93].
Reference: [Sut90b] <author> Richard S. Sutton. </author> <title> "Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming." </title> <booktitle> In Proceedings of the Seventh International Workshop on Machine Learning (ML90), </booktitle> <pages> pp. 216-224, </pages> <year> 1990. </year>
Reference-contexts: Their work is complementary to ours, in the sense that they have focussed on more effective exploration, and we have focussed on better decision making. Sutton, Barto and others <ref> [Sut91, Sut90b, Sut90a, BBS93] </ref>, have proposed a dynamic programming approach to incrementally generating plans in situations where the same or similar problems recur. This is a very interesting approach that can be easily extended to stochastic problem domains [BBS93].
Reference: [Sut91] <author> Richard S. Sutton. </author> <title> "Planning by Incremental Dynamic Programming." </title> <editor> In Lawrence A. Birnbaum and Gregg C. Collins, editors, </editor> <booktitle> Proceedings of the Eighth International Workshop on Machine Learning (ML91), </booktitle> <pages> pp. 353-357. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Their work is complementary to ours, in the sense that they have focussed on more effective exploration, and we have focussed on better decision making. Sutton, Barto and others <ref> [Sut91, Sut90b, Sut90a, BBS93] </ref>, have proposed a dynamic programming approach to incrementally generating plans in situations where the same or similar problems recur. This is a very interesting approach that can be easily extended to stochastic problem domains [BBS93].
Reference: [TJ92] <author> Prasad Tadepalli and Varad Joshi. </author> <title> "Real-time Scheduling Using Min-imin Search." </title> <booktitle> In Working Notes of the 1992 AAAI Spring Symposium on Planning, </booktitle> <pages> pp. 77-81. </pages> <booktitle> American Association for Artificial Intelligence, </booktitle> <year> 1992. </year> <month> 198 </month>
Reference-contexts: We then briefly comment on the scheduling literature that we used in our research. 10.2.3.1 Real-Time Scheduling Tadepalli and Joshi <ref> [TJ92] </ref> have also proposed using real-time incremental search methods for scheduling problems. In their paper, they first present a state-space formulation of job shop scheduling and then apply MINIMIN with bounded search-depth exploration as a method for finding suboptimal solutions quickly.
Reference: [ZDG90] <editor> Monte Zweben, Michael Deale, and Robert Gargan. "Anytime Rescheduling." In Katia Sycara, editor, </editor> <booktitle> Proceedings of the 1990 Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pp. 231-239, </pages> <year> 1990. </year>
Reference: [ZK95] <author> Weixiong Zhang and Richard E. Korf. </author> <title> "Performance of linear-space search algorithms." </title> <note> to appear in Artificial Intelligence, </note> <year> 1995. </year>
Reference-contexts: Even with pruning, in the worst case we may still have to generate all of the leaf nodes in order to make an optimal incremental search decision. The problem of finding a minimum-cost path in a random tree has been previously examined by <ref> [KP83, McD90b, MP91, ZK95, KPZ94] </ref>. Their results include the observation that there is no known closed form for the distribution of minimum-cost paths in a general random tree. <p> Their random trees had edge costs of 1 or 0 with probability p and (1 p). Their analytical results concerned the expected complexity of algorithms for finding an optimal or near optimal solution as a function of p. Others <ref> [McD90b, ZK95, ZP94a] </ref> have extended the single-agent search model to real-valued edge costs and have further analyzed both the model and new algorithms based on this analysis. Our development of real-time search on random trees and our choice of edge-cost ranges has benefited from this prior work on random trees.
Reference: [ZP94a] <author> Weixiong Zhang and Joseph C. Pemberton. "Epsilon-transformation: </author> <title> Exploiting phase transitions to solve combinatorial optimization problems initial results." </title> <booktitle> In Proceedings of the 12 th National Conference on Artificial Intelligence (AAAI-94). American Association for Artificial Intelligence, </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: Their random trees had edge costs of 1 or 0 with probability p and (1 p). Their analytical results concerned the expected complexity of algorithms for finding an optimal or near optimal solution as a function of p. Others <ref> [McD90b, ZK95, ZP94a] </ref> have extended the single-agent search model to real-valued edge costs and have further analyzed both the model and new algorithms based on this analysis. Our development of real-time search on random trees and our choice of edge-cost ranges has benefited from this prior work on random trees.
Reference: [ZP94b] <author> Weixiong Zhang and Joseph C. Pemberton. "Epsilon-transformation: </author> <title> Exploiting phase transitions to solve combinatorial optimization problems." </title> <type> Technical Report UCLA-CSD-940003, </type> <institution> Computer Science Department, University of California, </institution> <address> Los Angeles, </address> <month> January </month> <year> 1994. </year> <note> to appear in Artificial Intelligence. 199 </note>
References-found: 90

