URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR96640.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: An Approach to Parallelizing Isotonic Regression  
Author: Anthony J. Kearsley Richard A. Tapia Michael W. Trosset 
Note: This author was supported in part by NSF Cooperative Agreement No. CCR9120008 and DOE DEFG05-86ER25017.  
Affiliation: Department of Mathematics, University of Massachusetts at Dartmouth. Department of Computational Applied Mathematics and Center for Research in Parallel Computation, Rice University.  
Date: January 19, 1996  
Abstract: Isotonic regression is the problem of fitting data to order constraints. We demonstrate that the isotonic regression of a finite set of numbers Y can be obtained by decomposing Y into subsets, performing parallel isotonic regressions on each subset, then performing a trivial isotonic regression on the resulting combined set. Numerical experiments confirm the efficacy of this approach. z Department of Computational & Applied Mathematics (adjunct), Rice University; Department of Psychology (adjunct), University of Arizona; and Consultant, P. O. Box 40993, Tucson, AZ 85717-0993. This author was supported in part by NSF Cooperative Agreement No. CCR9120008, as a visiting member of the Center for Research in Parallel Computation, Rice University, August 1993 and 1994. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. E. Barlow, J. M. Bartholomew, J. M. Bremner, and H. D. Brunk. </author> <title> Statistical Inference Under Order Restrictions. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: Many important problems in statistics and other disciplines can be posed as isotonic regression problems. Comprehensive surveys of this subject were made by Barlow, Bartholomew, Bremner, and Brunk <ref> [1] </ref> and by Robertson, Wright, and Dykstra [5] in their respective monographs. The fundamental concern of the present report is revealed by considering a simple example.
Reference: [2] <author> M. J. Best and N. Chakravarti. </author> <title> Active set algorithms for isotonic regression; a unifying framework. </title> <journal> Mathematical Programming, </journal> <volume> 47 </volume> <pages> 425-439, </pages> <year> 1990. </year>
Reference-contexts: The efficiency of various isotonic regression algorithms has been discussed by Best and Chakravarti <ref> [2] </ref>. A very fast formulation of the Pool Adjacent Violators algorithm was provided by Grotzinger and Witzgall [3]. In light of the preceding arguments, we are virtually assured that a parallel approach to isotonic regression will speed up computation when n is sufficiently large.
Reference: [3] <author> S. J. Grotzinger and C. Witzgall. </author> <title> Projections onto order simplexes. </title> <journal> Applied Mathematics and Optimization, </journal> <volume> 12 </volume> <pages> 247-270, </pages> <year> 1984. </year>
Reference-contexts: The efficiency of various isotonic regression algorithms has been discussed by Best and Chakravarti [2]. A very fast formulation of the Pool Adjacent Violators algorithm was provided by Grotzinger and Witzgall <ref> [3] </ref>. In light of the preceding arguments, we are virtually assured that a parallel approach to isotonic regression will speed up computation when n is sufficiently large. This phenomenon is demonstrated in Section 4. <p> For each regression, the data set was decomposed into A subsets of (approximately) equal size. Each subset was simultaneously sent to a separate processor, where its isotonic regression was computed using Grotzinger's and Witzgall's <ref> [3] </ref> formulation of the Pool Adjacent Violators algorithm. As soon as the isotonic regressions of two consecutive subsets were computed, the combined result was sent to one of the available processors, which then computed the combined iso-tonic regression by means of the device described in Section 3.
Reference: [4] <author> A. J. Kearsley. </author> <title> A steady state model of Couette flow with viscous heating. </title> <journal> International Journal of Engineering Science, </journal> <volume> 32 </volume> <pages> 179-186, </pages> <year> 1994. </year>
Reference-contexts: In this case, one might want to replace the vector of observed viscosities with the nearest vector that is nonincreasing when ordered by temperature. This can be posed as an isotonic regression problem with unit weights. As have Kearsley <ref> [4] </ref> and others, we assumed that viscosity () is exponentially dependent on temperature (T ): = 0 exp (ffT ): For our experiments, we set 0 = 1 and ff = 10 4 .
Reference: [5] <author> T. Robertson, F. T. Wright, and R. L. Dykstra. </author> <title> Order Restricted Statistical Inference. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1988. </year> <month> 7 </month>
Reference-contexts: Many important problems in statistics and other disciplines can be posed as isotonic regression problems. Comprehensive surveys of this subject were made by Barlow, Bartholomew, Bremner, and Brunk [1] and by Robertson, Wright, and Dykstra <ref> [5] </ref> in their respective monographs. The fundamental concern of the present report is revealed by considering a simple example. Suppose that f1; 3; 2; 4; 5; 7; 6; 8g is the given set of real numbers, and that the weights are all identically one.
References-found: 5

