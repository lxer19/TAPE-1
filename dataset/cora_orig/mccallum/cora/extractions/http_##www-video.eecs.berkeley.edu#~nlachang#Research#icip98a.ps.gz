URL: http://www-video.eecs.berkeley.edu/~nlachang/Research/icip98a.ps.gz
Refering-URL: http://www-video.eecs.berkeley.edu/~nlachang/Research/pubs.html
Root-URL: 
Email: Email: fnlachang,avzg@eecs.Berkeley.EDU  
Title: MULTIVALUED REPRESENTATION FOR IMAGE RECONSTRUCTION AND NEW VIEW SYNTHESIS  
Author: Nelson L. Chang and Avideh Zakhor 
Address: Berkeley, CA 94720 USA  
Date: 4-8 October 1998  
Affiliation: Chicago, Illinois  Video and Image Processing Lab EECS Dept, University of California,  
Note: Submitted to ICIP98  
Abstract: To address both image reconstruction and new view synthesis, we propose an approach which combines the features of view interpolation techniques and layered representations. Our representation consists of a dense array of intensity and depth points, possibly multivalued, with respect to a reference frame. Given an image sequence, an adaptive multiframe algorithm estimates the depth of all points seen in at least two frames. The approach proceeds to identify occluded and uncovered regions, discard redundant data, and finally integrate the intensity and depth information into a single representation. Results on real scenes are presented to demonstrate its effectiveness. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. L. Chang and A. Zakhor, </author> <title> "Arbitrary view generation for three-dimensional scenes from uncalibrated video cameras," </title> <booktitle> in Proceedings of ICASSP, </booktitle> <pages> pp. 2455-2458, </pages> <address> De-troit, MI, </address> <month> 8-12 May </month> <year> 1995. </year>
Reference-contexts: LR overcomes problems of occlusion in scene. and redundancy by integrating information over the entire image set. While it can display the scene with different objects removed, LR has not been shown to facilitate new view synthesis. In contrast, view interpolation (VI) techniques such as <ref> [4, 7, 1, 6, 3] </ref> offer a solution to the latter part of the problem. In this case, a subset of frames from the input data is selected to be reference views. The representation consists of these views and either the associated depth or correspondence maps.
Reference: [2] <author> N. L. Chang and A. Zakhor, </author> <title> "Multivalued representations for image reconstruction and new view synthesis." Qualifying Examination Proposal, </title> <institution> University of Califor-nia at Berkeley, </institution> <month> January </month> <year> 1997. </year> <note> Also Technical Report, Video and Image Processing Lab, </note> <month> Feb. </month> <year> 1997. </year>
Reference-contexts: As seen in Figure 1, the representation consists of scene points organized into different levels of intensity and depth based on occlusion properties <ref> [2] </ref>. The levels indicate the number of surfaces occluding the given point with respect to the reference view|points in level 0 are completely visible, those in level 1 are occluded by one surface in level 0, and so forth.
Reference: [3] <author> N. L. Chang and A. Zakhor, </author> <title> "View generation for three-dimensional scenes from video sequences," </title> <journal> IEEE Trans. on Image Proc., </journal> <volume> vol. 6, no. 4, </volume> <pages> pp. 584-598, </pages> <month> Apr. </month> <year> 1997. </year>
Reference-contexts: LR overcomes problems of occlusion in scene. and redundancy by integrating information over the entire image set. While it can display the scene with different objects removed, LR has not been shown to facilitate new view synthesis. In contrast, view interpolation (VI) techniques such as <ref> [4, 7, 1, 6, 3] </ref> offer a solution to the latter part of the problem. In this case, a subset of frames from the input data is selected to be reference views. The representation consists of these views and either the associated depth or correspondence maps. <p> Estimate motion between PRF and each neighbor. Sparse point correspondences are first established by the approach of Zhang, Deriche, et al. [11]. Since only relative motion may be estimated, one horizontal parameter is fixed to 1. The remaining motion parameters are estimated using least squares <ref> [3] </ref>. 2. Calculate dense depth for PRF using the multiframe algorithm in Section 3. 3. Compute depth for new information in other frames. Once found, the PRF depth may be warped to each of its neighbors' coordinate system. <p> Once the multivalued representation has been obtained, it is relatively straightforward to reconstruct the original images or synthesize new views of the scene. The procedure consists of regarding the representation as a deformable mesh of quadrilateral patches and applying the appropriate transformation to the vertices <ref> [3] </ref>. 3. MULTIFRAME DEPTH ESTIMATION In order to estimate depth with respect to a particular frame as in Steps 2 and 3 in Section 2, a variant of Okutomi and Kanade's multiple-baseline algorithm is used [8]. <p> In addition, adaptive neighborhood sizes for N are employed to improve estimation in low-textured regions. The neighborhood is automatically adjusted according to the local variance of neighboring intensities <ref> [3] </ref>. Next, instead of normalizing the largest baseline to be 1, one of the shorter baselines is considered to have unity baseline. This feature permits wider baselines to be included without drastically increasing computational time.
Reference: [4] <author> S. E. Chen and L. Williams, </author> <title> "View interpolation for image synthesis," </title> <booktitle> in Proceedings of SIGGRAPH, </booktitle> <pages> pp. 279-288, </pages> <address> New York, NY, 1-6 Aug. </address> <year> 1993. </year>
Reference-contexts: LR overcomes problems of occlusion in scene. and redundancy by integrating information over the entire image set. While it can display the scene with different objects removed, LR has not been shown to facilitate new view synthesis. In contrast, view interpolation (VI) techniques such as <ref> [4, 7, 1, 6, 3] </ref> offer a solution to the latter part of the problem. In this case, a subset of frames from the input data is selected to be reference views. The representation consists of these views and either the associated depth or correspondence maps.
Reference: [5] <author> T. Darrell and A. Pentland, </author> <title> "Robust estimation of a multi-layered motion representation," </title> <booktitle> in IEEE Workshop on Visual Motion, </booktitle> <pages> pp. 173-178, </pages> <address> Princeton, NJ, 7-9 Oct. </address> <year> 1991. </year>
Reference-contexts: Traditional video coding schemes like MPEG and wavelet-based techniques fail at new view synthesis since they simply attempt to decorrelate the data. More recently, layered representation (LR) schemes such as <ref> [5, 10, 9] </ref> have been introduced. In this case, the image data is segmented into regions exhibiting similar 2-D affine motions and then grouped into layers defined with respect to a single reference frame.
Reference: [6] <author> T. Kanade, P. J. Narayanan, and P. W. Rander, </author> <title> "Vir-tualized reality: Concepts and early results," </title> <booktitle> in IEEE Workshop on Representation of Visual Scenes, </booktitle> <pages> pp. 69-76, </pages> <address> Cambridge, MA, </address> <month> June 24 </month> <year> 1995. </year>
Reference-contexts: LR overcomes problems of occlusion in scene. and redundancy by integrating information over the entire image set. While it can display the scene with different objects removed, LR has not been shown to facilitate new view synthesis. In contrast, view interpolation (VI) techniques such as <ref> [4, 7, 1, 6, 3] </ref> offer a solution to the latter part of the problem. In this case, a subset of frames from the input data is selected to be reference views. The representation consists of these views and either the associated depth or correspondence maps.
Reference: [7] <author> S. Laveau and O. Faugeras, </author> <title> "3-D scene representation as a collection of images and fundamental matrices," </title> <type> Tech. Rep. 2205, </type> <institution> INRIA, </institution> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: LR overcomes problems of occlusion in scene. and redundancy by integrating information over the entire image set. While it can display the scene with different objects removed, LR has not been shown to facilitate new view synthesis. In contrast, view interpolation (VI) techniques such as <ref> [4, 7, 1, 6, 3] </ref> offer a solution to the latter part of the problem. In this case, a subset of frames from the input data is selected to be reference views. The representation consists of these views and either the associated depth or correspondence maps.
Reference: [8] <author> M. Okutomi and T. Kanade, </author> <title> "A multiple-baseline stereo," </title> <journal> IEEE Trans. on Patt. Anal. Mach. Intell., </journal> <volume> vol. 15, no. 4, </volume> <pages> pp. 353-363, </pages> <month> Apr. </month> <year> 1993. </year>
Reference-contexts: MULTIFRAME DEPTH ESTIMATION In order to estimate depth with respect to a particular frame as in Steps 2 and 3 in Section 2, a variant of Okutomi and Kanade's multiple-baseline algorithm is used <ref> [8] </ref>. The approach consists of finding the inverse depths that minimize the sum of component intensity errors. More precisely, suppose there are M images denoted by I i (; ) and let k 2 1; 2; : : : M be the reference frame.
Reference: [9] <author> H. S. Sawhney and S. Ayer, </author> <title> "Compact representations of videos through dominant and multiple motion estimation," </title> <journal> IEEE Trans. on Patt. Anal. Mach. Intell., </journal> <volume> vol. 18, no. 8, </volume> <pages> pp. 814-830, </pages> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: Traditional video coding schemes like MPEG and wavelet-based techniques fail at new view synthesis since they simply attempt to decorrelate the data. More recently, layered representation (LR) schemes such as <ref> [5, 10, 9] </ref> have been introduced. In this case, the image data is segmented into regions exhibiting similar 2-D affine motions and then grouped into layers defined with respect to a single reference frame.
Reference: [10] <author> J. Y. A. Wang and E. H. Adelson, </author> <title> "Representing moving images with layers," </title> <journal> IEEE Trans. on Image Proc., </journal> <volume> vol. 3, no. 5, </volume> <pages> pp. 625-638, </pages> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: Traditional video coding schemes like MPEG and wavelet-based techniques fail at new view synthesis since they simply attempt to decorrelate the data. More recently, layered representation (LR) schemes such as <ref> [5, 10, 9] </ref> have been introduced. In this case, the image data is segmented into regions exhibiting similar 2-D affine motions and then grouped into layers defined with respect to a single reference frame.
Reference: [11] <author> Z. Zhang, R. Deriche, et al., </author> <title> "A robust technique for matching two uncalibrated images through the recovery of the unknown epipolar geometry," </title> <journal> Artificial Intelligence, </journal> <volume> vol. 78, no. </volume> <pages> 1-2, pp. 87-119, </pages> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: The following steps are performed: 1. Estimate motion between PRF and each neighbor. Sparse point correspondences are first established by the approach of Zhang, Deriche, et al. <ref> [11] </ref>. Since only relative motion may be estimated, one horizontal parameter is fixed to 1. The remaining motion parameters are estimated using least squares [3]. 2. Calculate dense depth for PRF using the multiframe algorithm in Section 3. 3. Compute depth for new information in other frames.
References-found: 11

