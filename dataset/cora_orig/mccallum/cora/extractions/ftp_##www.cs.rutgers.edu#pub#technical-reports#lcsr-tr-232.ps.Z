URL: ftp://www.cs.rutgers.edu/pub/technical-reports/lcsr-tr-232.ps.Z
Refering-URL: http://www.cs.rutgers.edu/pub/technical-reports/
Root-URL: 
Title: Integrating Qualitative and Quantitative Shape Recovery  
Author: Sven J. Dickinson P. O. Dimitri Metaxas 
Address: Box 1179 Piscataway, NJ 08855-1179  Philadelphia, PA 19104-6389  
Affiliation: Rutgers University Center for Cognitive Science (RuCCS) and Department of Computer Science Rutgers University  Department of Computer and Information Science University of Pennsylvania  
Abstract: Recent work in qualitative shape recovery and object recognition has focused on solving the "what is it" problem, while avoiding the "where is it" problem. In contrast, typical CAD-based recognition systems have focused on the "where is it" problem, while assuming they know what the object is. Although each approach addresses an important aspect of the 3-D object recognition problem, each falls short in addressing the complete problem of recognizing and localizing 3-D objects from a large database. In this paper, we first synthesize a new approach to shape recovery for 3-D object recognition that decouples recognition from localization by combining basic elements from these two approaches. Specifically, we use qualitative shape recovery and recognition techniques to provide strong fitting constraints on physics-based deformable model recovery techniques. Secondly, we extend our previously developed technique of fitting deformable models to occluding image contours to the case of image data captured under general orthographic, perspective, and stereo projections. On one hand, integrating qualitative knowledge of the object being fitted to the data, along with knowledge of occlusion supports a much more robust and accurate quantitative fitting. On the other hand, recovering object pose and quantitative surface shape not only provides a richer description for indexing, but supports interaction with the world when object manipulation is required. This paper presents the approach in detail and applies it to real imagery. to appear: International Journal of Computer Vision, Vol. 13, No. 3, 1994, pp 1-20.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Barr. </author> <title> Superquadrics and angle-preserving transformations. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 1 </volume> <pages> 11-23, </pages> <year> 1981. </year>
Reference-contexts: Thus, we have: p = s: (4) The ensuing formulation can be carried out for any reference shape given as a parameterized function of u. Based on the shapes we want to recover, we first consider the case of superquadric ellipsoids <ref> [1] </ref>, which are given by the following formula: e = a B a 1 C u * 2 * 1 S v a 3 S u 1 A ; (5) where =2 u =2 and v &lt; , and where S w * = sgn (sin w)j sin wj * and
Reference: [2] <author> R. Bergevin and M. Levine. </author> <title> Generic object recognition: Building coarse 3D descriptions from line drawings. </title> <booktitle> In Proceedings, IEEE Workshop on Interpretation of 3D Scenes, </booktitle> <pages> pages 68-74, </pages> <address> Austin, TX, </address> <year> 1989. </year>
Reference-contexts: 1 Introduction Since the introduction of a class of qualitatively-defined volumetric primitives, called geons [3], interest has been growing in building 3-D object recognition systems based on qualitative shape <ref> [2, 4, 10, 9, 11, 14, 25] </ref>. One of the primary motivations in these systems is that, as stated by Biederman [3], the task of recognizing (or identifying) an object should be separated from the task of locating it.
Reference: [3] <author> I. Biederman. </author> <title> Human image understanding: Recent research and a theory. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 32 </volume> <pages> 29-73, </pages> <year> 1985. </year>
Reference-contexts: 1 Introduction Since the introduction of a class of qualitatively-defined volumetric primitives, called geons <ref> [3] </ref>, interest has been growing in building 3-D object recognition systems based on qualitative shape [2, 4, 10, 9, 11, 14, 25]. One of the primary motivations in these systems is that, as stated by Biederman [3], the task of recognizing (or identifying) an object should be separated from the task <p> 1 Introduction Since the introduction of a class of qualitatively-defined volumetric primitives, called geons <ref> [3] </ref>, interest has been growing in building 3-D object recognition systems based on qualitative shape [2, 4, 10, 9, 11, 14, 25]. One of the primary motivations in these systems is that, as stated by Biederman [3], the task of recognizing (or identifying) an object should be separated from the task of locating it. Furthermore, the exact shape of the object need not be recovered to facilitate recognition; a coarse-level description of shape is sufficient to distinguish between different classes of objects. <p> Whichever set of volumetric modeling primitives is chosen, they will be mapped to a set of viewer-centered aspects. To demonstrate our approach to object recognition, we have selected an object representation similar to that used by Biederman <ref> [3] </ref>, in which the Cartesian product of contrastive shape properties gives rise to a set of volumetric primitives called geons. For our investigation, we have chosen three properties including cross-section shape, axis shape, and cross-section size variation (Dickinson et al. [8]).
Reference: [4] <author> I. Biederman, J. Hummel, P. Gerhardstein, and E. Cooper. </author> <title> From images edges to geons to viewpoint invariant object models: A neural net implementation. </title> <booktitle> In Proceedings, SPIE Applications of Artificial Intelligence X: Machine Vision and Robotics, </booktitle> <pages> pages 570-578, </pages> <address> Orlando, FL, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction Since the introduction of a class of qualitatively-defined volumetric primitives, called geons [3], interest has been growing in building 3-D object recognition systems based on qualitative shape <ref> [2, 4, 10, 9, 11, 14, 25] </ref>. One of the primary motivations in these systems is that, as stated by Biederman [3], the task of recognizing (or identifying) an object should be separated from the task of locating it.
Reference: [5] <author> R. Brooks. </author> <title> Model-based 3-D interpretations of 2-D images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 5(2) </volume> <pages> 140-150, </pages> <year> 1983. </year>
Reference-contexts: Many 3-D object recognition systems have successfully employed 3-D volumetric primitives to construct objects. Commonly used classes of volumetric primitives include polyhedra (e.g., Lowe [17]), generalized cylinders (e.g., Brooks <ref> [5] </ref>), and su-perquadrics (e.g., Pentland [22]). Whichever set of volumetric modeling primitives is chosen, they will be mapped to a set of viewer-centered aspects.
Reference: [6] <author> D. Clemens. </author> <title> Region-based feature interpretation for recognizing 3-D models in 2-D images. </title> <type> Technical Report AI-TR 1307, </type> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1991. </year>
Reference-contexts: The above systems, therefore, address only the task of recognizing the object. This is in contrast to classical 3-D object recognition systems, in which exact viewpoint is required to verify typically weak object hypotheses, while the object models capture the exact geometry of the object <ref> [6, 13, 17, 32] </ref>. Determining the pose of the object is a critical component of these approaches. Each of the above recognition schools addresses an important requirement of recognition systems: coarse object identification and object localization. However, there has been little effort to combine them into a single paradigm.
Reference: [7] <author> S. Dickinson, G. Olofsson, and H. Christensen. </author> <title> Qualitative prediction in active recognition. </title> <booktitle> In Proceedings, 8th Scandinavian Conference on Image Analysis (SCIA), </booktitle> <address> Tromst, Norway, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: This attention mechanism has been used to drive an active recognition system which moves the cameras to obtain either a more likely or unambiguous view of an object's part <ref> [7] </ref>. 4.1.3 Primitive Recovery In the expected object recognition approach described above, primitive recovery consists of mapping the recovered aspect directly to the target primitive prediction. Primitive recovery for the unexpected object recognition case is more complex.
Reference: [8] <author> S. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> A representation for qualitative 3-D object recognition integrating object-centered and viewer-centered models. </title> <editor> In K. Leibovic, editor, </editor> <title> Vision: A Convergence of Disciplines. </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: In recent work, we presented an approach to the representation, recovery, and recognition of qualitative 3-D objects from a single 2-D image <ref> [8, 10, 9] </ref>. In that approach, an object is modeled using a set of object-centered 3-D volumetric modeling primitives; the primitives, in turn, are mapped to a set of viewer-centered aspects. <p> In addition, we generalize our deformable model fitting technique to accommodate orthographic, perspective, and stereo projections. 3 Object Modeling 3.1 Qualitative Shape Modeling In this section, we briefly review the qualitative shape modeling technique described in <ref> [8, 10, 9] </ref>. 3.1.1 Object-Centered Models Given a database of object models representing the domain of a recognition task, we seek a set of three-dimensional volumetric primitives that, when assembled together, can be used to construct the object models. <p> For our investigation, we have chosen three properties including cross-section shape, axis shape, and cross-section size variation (Dickinson et al. <ref> [8] </ref>). The values of these properties give rise to a set of ten primitives (a subset of Biederman's geons), modeled using Pentland's SuperSketch 3-D modeling tool [22], and illustrated in Figure 1 (a). <p> Figure 1 (b) illustrates a portion of the aspect hierarchy. The ambiguous mappings between the levels of the aspect hierarchy are captured in a set of conditional probabilities (Dickinson et al. <ref> [8, 10] </ref>), mapping boundary groups to faces, faces to aspects, and aspects to primitives.
Reference: [9] <author> S. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> From volumes to views: An approach to 3-D object recognition. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 55(2) </volume> <pages> 130-154, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction Since the introduction of a class of qualitatively-defined volumetric primitives, called geons [3], interest has been growing in building 3-D object recognition systems based on qualitative shape <ref> [2, 4, 10, 9, 11, 14, 25] </ref>. One of the primary motivations in these systems is that, as stated by Biederman [3], the task of recognizing (or identifying) an object should be separated from the task of locating it. <p> In recent work, we presented an approach to the representation, recovery, and recognition of qualitative 3-D objects from a single 2-D image <ref> [8, 10, 9] </ref>. In that approach, an object is modeled using a set of object-centered 3-D volumetric modeling primitives; the primitives, in turn, are mapped to a set of viewer-centered aspects. <p> In addition, we generalize our deformable model fitting technique to accommodate orthographic, perspective, and stereo projections. 3 Object Modeling 3.1 Qualitative Shape Modeling In this section, we briefly review the qualitative shape modeling technique described in <ref> [8, 10, 9] </ref>. 3.1.1 Object-Centered Models Given a database of object models representing the domain of a recognition task, we seek a set of three-dimensional volumetric primitives that, when assembled together, can be used to construct the object models.
Reference: [10] <author> S. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> 3-D shape recovery using distributed aspect matching. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(2) </volume> <pages> 174-198, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction Since the introduction of a class of qualitatively-defined volumetric primitives, called geons [3], interest has been growing in building 3-D object recognition systems based on qualitative shape <ref> [2, 4, 10, 9, 11, 14, 25] </ref>. One of the primary motivations in these systems is that, as stated by Biederman [3], the task of recognizing (or identifying) an object should be separated from the task of locating it. <p> In recent work, we presented an approach to the representation, recovery, and recognition of qualitative 3-D objects from a single 2-D image <ref> [8, 10, 9] </ref>. In that approach, an object is modeled using a set of object-centered 3-D volumetric modeling primitives; the primitives, in turn, are mapped to a set of viewer-centered aspects. <p> In addition, we generalize our deformable model fitting technique to accommodate orthographic, perspective, and stereo projections. 3 Object Modeling 3.1 Qualitative Shape Modeling In this section, we briefly review the qualitative shape modeling technique described in <ref> [8, 10, 9] </ref>. 3.1.1 Object-Centered Models Given a database of object models representing the domain of a recognition task, we seek a set of three-dimensional volumetric primitives that, when assembled together, can be used to construct the object models. <p> Figure 1 (b) illustrates a portion of the aspect hierarchy. The ambiguous mappings between the levels of the aspect hierarchy are captured in a set of conditional probabilities (Dickinson et al. <ref> [8, 10] </ref>), mapping boundary groups to faces, faces to aspects, and aspects to primitives. <p> recovery consists of the following three steps, resulting in a graph representation of the image in which nodes represent recovered 3-D primitives, and arcs represent hypothesized connections between the primitives; details of the complete recovery process, including algorithms to handle various segmentation errors, can be found in Dickinson et al. <ref> [10] </ref>. In the following subsections, we briefly review the approach to recovering qualitative shape. 4.1.1 Face Recovery The first step to recovering a set of faces is a region segmentation of the input image. <p> There is no known polynomial time algorithm to solve this problem (see <ref> [10] </ref> for a discussion on the problem's computational complexity); however, the conditional probability matrices embedded in the aspect hierarchy provide a powerful constraint that can make the problem tractable. <p> the recovery process which attends first to 3 The probability of an aspect hypothesis is the product of the face to aspect mapping and the probability of the face hypothesis from which it was inferred. 4 For a detailed discussion of aspect instantiation and how occluded aspects are instantiated, see <ref> [10] </ref>. 12 high-quality faces. <p> The mnemonics, PN, PL, and PP, refer to primitive number (simply an enumeration of the primitives in the covering), primitive label (see Figure 1 (a)), and primitive probability, respectively. The mnemonics AN, AL, AP, and AS refer to the aspect number (an enumeration), aspect label (see <ref> [10] </ref>), aspect probability, and aspect score (how well aspect was verified), respectively. The mnemonics FN, FL, FP, and PS refer to face number (in image window), face label (see [10]), face probability, and corresponding primitive attachment surface (see [10]), respectively, for each component face of the aspect. <p> The mnemonics AN, AL, AP, and AS refer to the aspect number (an enumeration), aspect label (see <ref> [10] </ref>), aspect probability, and aspect score (how well aspect was verified), respectively. The mnemonics FN, FL, FP, and PS refer to face number (in image window), face label (see [10]), face probability, and corresponding primitive attachment surface (see [10]), respectively, for each component face of the aspect. To illustrate the fitting stage, consider the contours belonging to the lamp shade (truncated cone). <p> and AS refer to the aspect number (an enumeration), aspect label (see <ref> [10] </ref>), aspect probability, and aspect score (how well aspect was verified), respectively. The mnemonics FN, FL, FP, and PS refer to face number (in image window), face label (see [10]), face probability, and corresponding primitive attachment surface (see [10]), respectively, for each component face of the aspect. To illustrate the fitting stage, consider the contours belonging to the lamp shade (truncated cone).
Reference: [11] <author> R. Fairwood. </author> <title> Recognition of generic components using logic-program relations of image contours. </title> <journal> Image and Vision Computing, </journal> <volume> 9(2) </volume> <pages> 113-122, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction Since the introduction of a class of qualitatively-defined volumetric primitives, called geons [3], interest has been growing in building 3-D object recognition systems based on qualitative shape <ref> [2, 4, 10, 9, 11, 14, 25] </ref>. One of the primary motivations in these systems is that, as stated by Biederman [3], the task of recognizing (or identifying) an object should be separated from the task of locating it.
Reference: [12] <author> A. Gupta. </author> <title> Surface and volumetric segmentation of 3D objects using parametric shape models. </title> <type> Technical Report MS-CIS-91-45, </type> <institution> GRASP LAB 128, University of Pennsylvania, </institution> <address> Philadelphia, PA, </address> <year> 1991. </year>
Reference-contexts: Most of those approaches are applied to range data only <ref> [28, 12] </ref>, while Pentland [23] describes a two-stage algorithm to fit superquadrics to image data.
Reference: [13] <author> D. Huttenlocher. </author> <title> Three-dimensional recognition of solid objects from a two-dimensional image. </title> <type> Technical Report 1045, </type> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: The above systems, therefore, address only the task of recognizing the object. This is in contrast to classical 3-D object recognition systems, in which exact viewpoint is required to verify typically weak object hypotheses, while the object models capture the exact geometry of the object <ref> [6, 13, 17, 32] </ref>. Determining the pose of the object is a critical component of these approaches. Each of the above recognition schools addresses an important requirement of recognition systems: coarse object identification and object localization. However, there has been little effort to combine them into a single paradigm.
Reference: [14] <author> A. Jacot-Descombes and T. Pun. </author> <title> A probabilistic approach to 3-D inference of geons from a 2-D view. </title> <booktitle> In Proceedings, SPIE Applications of Artificial Intelligence X: Machine Vision and Robotics, </booktitle> <pages> pages 579-588, </pages> <address> Orlando, FL, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction Since the introduction of a class of qualitatively-defined volumetric primitives, called geons [3], interest has been growing in building 3-D object recognition systems based on qualitative shape <ref> [2, 4, 10, 9, 11, 14, 25] </ref>. One of the primary motivations in these systems is that, as stated by Biederman [3], the task of recognizing (or identifying) an object should be separated from the task of locating it.
Reference: [15] <author> J. Koenderink and A. van Doorn. </author> <title> The internal representation of solid shape with respect to vision. </title> <journal> Biological Cybernetics, </journal> <volume> 32 </volume> <pages> 211-216, </pages> <year> 1979. </year>
Reference-contexts: Traditional aspect graph representations of 3-D objects model an entire object with a set of aspects, each defining a topologically distinct view of an object in terms of its visible surfaces <ref> [15] </ref>. Our approach differs in that we use aspects to represent a (typically small) set of volumetric primitives from which each object in our database is 4 (a) (b) constructed, rather than representing an entire object directly.
Reference: [16] <author> J. Lee, R. Haralick, and L Shapiro. </author> <title> Morphologic edge detection. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-3(2):142-155, </volume> <year> 1987. </year>
Reference-contexts: We begin by applying Saint-Marc, Chen, and Medioni's edge-preserving adaptive smoothing filter to the image [26], followed by a morphological gradient operator <ref> [16] </ref>. A hysteresis thresholding operation is then applied to produce a binary image from which a set of connected components is extracted. Edge regions are then burned away, resulting in a region topology graph in which nodes represent regions and arcs specify region adjacencies.
Reference: [17] <author> D. Lowe. </author> <title> Perceptual Organization and Visual Recognition. </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1985. </year>
Reference-contexts: The above systems, therefore, address only the task of recognizing the object. This is in contrast to classical 3-D object recognition systems, in which exact viewpoint is required to verify typically weak object hypotheses, while the object models capture the exact geometry of the object <ref> [6, 13, 17, 32] </ref>. Determining the pose of the object is a critical component of these approaches. Each of the above recognition schools addresses an important requirement of recognition systems: coarse object identification and object localization. However, there has been little effort to combine them into a single paradigm. <p> Many 3-D object recognition systems have successfully employed 3-D volumetric primitives to construct objects. Commonly used classes of volumetric primitives include polyhedra (e.g., Lowe <ref> [17] </ref>), generalized cylinders (e.g., Brooks [5]), and su-perquadrics (e.g., Pentland [22]). Whichever set of volumetric modeling primitives is chosen, they will be mapped to a set of viewer-centered aspects.
Reference: [18] <author> D. Metaxas. </author> <title> Physics-based modeling of nonrigid objects for vision and graphics. </title> <type> Ph.D. thesis, </type> <institution> Dept. of Computer Science, Univ. of Toronto, </institution> <year> 1992. </year>
Reference-contexts: In this paper, we unify these two schools into a single approach which first recovers qualitative shape from an image, and then uses that shape to constrain a quantitative recovery of the object's shape and pose. Physics-based modeling <ref> [24, 31, 29, 19, 18, 20] </ref> provides a very powerful mechanism for quantitatively modeling an object's shape for recognition. <p> In previous work, we developed a physics-based framework for recovering shape and nonrigid motion from both 2-D and 3-D data using a new class of deformable part models <ref> [29, 19, 18] </ref>. These models incorporate global deformation parameters which represent the salient shape features of natural parts, and local deformation parameters which capture shape details. Thus, unlike previous physics-based techniques [31], the shape of an object can both be abstracted or represented in detail.
Reference: [19] <author> D. Metaxas and D. Terzopoulos. </author> <title> Constrained deformable superquadrics and nonrigid motion tracking. </title> <booktitle> In Proceedings, IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 337-343, </pages> <year> 1991. </year>
Reference-contexts: In this paper, we unify these two schools into a single approach which first recovers qualitative shape from an image, and then uses that shape to constrain a quantitative recovery of the object's shape and pose. Physics-based modeling <ref> [24, 31, 29, 19, 18, 20] </ref> provides a very powerful mechanism for quantitatively modeling an object's shape for recognition. <p> In previous work, we developed a physics-based framework for recovering shape and nonrigid motion from both 2-D and 3-D data using a new class of deformable part models <ref> [29, 19, 18] </ref>. These models incorporate global deformation parameters which represent the salient shape features of natural parts, and local deformation parameters which capture shape details. Thus, unlike previous physics-based techniques [31], the shape of an object can both be abstracted or represented in detail. <p> These conditional probabilities result from a statistical analysis of a set of images approximating the set of all views of all the primitives. 3.2 Quantitative Shape Modeling In this section we first briefly review the general formulation of deformable models; further detail can be found in <ref> [29, 19] </ref>. We then extend the formulation to the case of orthographic, perspective, and stereo projections. 5 3.2.1 Geometry Geometrically, the models developed in this paper are closed surfaces in space whose intrinsic (material) coordinates are u = (u; v), defined on a domain .
Reference: [20] <author> D. Metaxas and D. Terzopoulos. </author> <title> Shape and nonrigid motion estimation through physics-based synthesis. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(6) </volume> <pages> 580-591, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: In this paper, we unify these two schools into a single approach which first recovers qualitative shape from an image, and then uses that shape to constrain a quantitative recovery of the object's shape and pose. Physics-based modeling <ref> [24, 31, 29, 19, 18, 20] </ref> provides a very powerful mechanism for quantitatively modeling an object's shape for recognition.
Reference: [21] <author> N. Nilsson. </author> <booktitle> Principles of Artificial Intelligence, chapter 2. </booktitle> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Los Altos, CA, </address> <year> 1980. </year>
Reference-contexts: In other words, we wish to choose one aspect hypothesis from the list at each node, such that the instantiated aspects completely cover the face topology graph. For our search through the possible aspect labelings of the face topology graph, we employ Algorithm A (Nilsson <ref> [21] </ref>) with a heuristic designed to meet three objectives. First, we favor selections of aspects instantiated from higher probability aspect hypotheses. Second, we favor selections whose aspects have fewer occluded faces, since we are more confident of their labels.
Reference: [22] <author> A. Pentland. </author> <title> Perceptual organization and the representation of natural form. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 293-331, </pages> <year> 1986. </year>
Reference-contexts: Many 3-D object recognition systems have successfully employed 3-D volumetric primitives to construct objects. Commonly used classes of volumetric primitives include polyhedra (e.g., Lowe [17]), generalized cylinders (e.g., Brooks [5]), and su-perquadrics (e.g., Pentland <ref> [22] </ref>). Whichever set of volumetric modeling primitives is chosen, they will be mapped to a set of viewer-centered aspects. <p> For our investigation, we have chosen three properties including cross-section shape, axis shape, and cross-section size variation (Dickinson et al. [8]). The values of these properties give rise to a set of ten primitives (a subset of Biederman's geons), modeled using Pentland's SuperSketch 3-D modeling tool <ref> [22] </ref>, and illustrated in Figure 1 (a).
Reference: [23] <author> A. Pentland. </author> <title> Automatic extraction of deformable part models. </title> <journal> International Journal of Computer Vision, </journal> <volume> 4 </volume> <pages> 107-126, </pages> <year> 1990. </year>
Reference-contexts: Most of those approaches are applied to range data only [28, 12], while Pentland <ref> [23] </ref> describes a two-stage algorithm to fit superquadrics to image data.
Reference: [24] <author> A. Pentland and S. Sclaroff. </author> <title> Closed-form solutions for physically based shape modeling and recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(7) </volume> <pages> 715-729, </pages> <year> 1991. </year>
Reference-contexts: In this paper, we unify these two schools into a single approach which first recovers qualitative shape from an image, and then uses that shape to constrain a quantitative recovery of the object's shape and pose. Physics-based modeling <ref> [24, 31, 29, 19, 18, 20] </ref> provides a very powerful mechanism for quantitatively modeling an object's shape for recognition. <p> Pentland's approach is only applicable to the case of occluding boundary data under simple orthographic projection, as is true of earlier work of Terzopoulos et al. [31], Terzopoulos and Metaxas [29], and Pentland and Sclaroff <ref> [24] </ref>, which address only the problem of model fitting. The fundamental difference between our approach and the above approaches is that we use a qualitative segmentation of the image to provide sufficient constraints to our deformable model fitting procedure. <p> unit normal at any model point, i is the unit vector from the focal point to a point on the model, and t is a small threshold. 4.2.3 Model Initialization One of the major limitations of previous deformable model fitting approaches is their dependence on model initialization and prior segmentation <ref> [31, 29, 24] </ref>. Using the qualitative shape recovery process as a front end, we first segment the image into parts, and for each part, we identify the relevant non-occluded contour data belonging to the part.
Reference: [25] <author> N. Raja and A. Jain. </author> <title> Recognizing geons from superquadrics fitted to range data. </title> <journal> Image and Vision Computing, </journal> <volume> 10(3) </volume> <pages> 179-190, </pages> <year> 1992. </year> <month> 32 </month>
Reference-contexts: 1 Introduction Since the introduction of a class of qualitatively-defined volumetric primitives, called geons [3], interest has been growing in building 3-D object recognition systems based on qualitative shape <ref> [2, 4, 10, 9, 11, 14, 25] </ref>. One of the primary motivations in these systems is that, as stated by Biederman [3], the task of recognizing (or identifying) an object should be separated from the task of locating it.
Reference: [26] <author> P. Saint-Marc, J.-S. Chen, and G. Medioni. </author> <title> Adaptive smoothing: A general tool for early vision. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(6) </volume> <pages> 514-529, </pages> <year> 1991. </year>
Reference-contexts: In the following subsections, we briefly review the approach to recovering qualitative shape. 4.1.1 Face Recovery The first step to recovering a set of faces is a region segmentation of the input image. We begin by applying Saint-Marc, Chen, and Medioni's edge-preserving adaptive smoothing filter to the image <ref> [26] </ref>, followed by a morphological gradient operator [16]. A hysteresis thresholding operation is then applied to produce a binary image from which a set of connected components is extracted. <p> From a region topology graph, each region is characterized according to the qualitative shapes of its bounding contours. First, the bounding contour of each region is partitioned at curvature extrema using Saint-Marc, Chen, and Medioni's adaptive smoothing curve partitioning technique <ref> [26] </ref>. Next, each bounding contour is classified as straight, convex, or concave, by comparing the contour to a fitted line. Finally, each pair of bounding contours is checked for cotermination, parallelism, or symmetry.
Reference: [27] <author> A. Shabana. </author> <title> Dynamics of Multibody Systems. </title> <publisher> Wiley, </publisher> <year> 1989. </year>
Reference-contexts: + v 2 2 (v 1 v 3 sv 2 ) 2 (v 2 v 3 + sv 1 ) 1 2 (v 2 2 ) 7 To obtain q from (27), we use the generalized torque at time t given by f &gt; = f &gt; Bdu, with B <ref> [27, 29] </ref>: where R represents the rotation matrix at time t, where ~p (u) is the dual 3 fi 3 matrix of the position vector p (u) = (p 1 ; p 2 ; p 3 ) &gt; (see (4)) defined as: ~p (u) = 6 0 p 3 p 2
Reference: [28] <author> F. Solina and R. </author> <title> Bajcsy. Recovery of parametric models from range images: The case for superquadrics with global deformations. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12(2) </volume> <pages> 131-146, </pages> <year> 1990. </year>
Reference-contexts: Most of those approaches are applied to range data only <ref> [28, 12] </ref>, while Pentland [23] describes a two-stage algorithm to fit superquadrics to image data.
Reference: [29] <author> D. Terzopoulos and D. Metaxas. </author> <title> Dynamic 3D models with local and global deformations: Deformable superquadrics. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(7) </volume> <pages> 703-714, </pages> <year> 1991. </year>
Reference-contexts: In this paper, we unify these two schools into a single approach which first recovers qualitative shape from an image, and then uses that shape to constrain a quantitative recovery of the object's shape and pose. Physics-based modeling <ref> [24, 31, 29, 19, 18, 20] </ref> provides a very powerful mechanism for quantitatively modeling an object's shape for recognition. <p> In previous work, we developed a physics-based framework for recovering shape and nonrigid motion from both 2-D and 3-D data using a new class of deformable part models <ref> [29, 19, 18] </ref>. These models incorporate global deformation parameters which represent the salient shape features of natural parts, and local deformation parameters which capture shape details. Thus, unlike previous physics-based techniques [31], the shape of an object can both be abstracted or represented in detail. <p> Furthermore, this correspondence allows us to extend our previously developed technique for deformable model fitting, which is limited to orthographic projection of occluding boundaries <ref> [29] </ref>, to the case of more general objects with internal surface discontinuities under general orthographic, perspective, and stereo projections. The paper is organized as follows. First we describe both the qualitative and quantitative object modeling paradigms. Next, we describe both the qualitative and quantitative shape recovery processes. <p> In the second stage, he fits superquadrics to the segmented data using a least squares algorithm. Pentland's approach is only applicable to the case of occluding boundary data under simple orthographic projection, as is true of earlier work of Terzopoulos et al. [31], Terzopoulos and Metaxas <ref> [29] </ref>, and Pentland and Sclaroff [24], which address only the problem of model fitting. The fundamental difference between our approach and the above approaches is that we use a qualitative segmentation of the image to provide sufficient constraints to our deformable model fitting procedure. <p> These conditional probabilities result from a statistical analysis of a set of images approximating the set of all views of all the primitives. 3.2 Quantitative Shape Modeling In this section we first briefly review the general formulation of deformable models; further detail can be found in <ref> [29, 19] </ref>. We then extend the formulation to the case of orthographic, perspective, and stereo projections. 5 3.2.1 Geometry Geometrically, the models developed in this paper are closed surfaces in space whose intrinsic (material) coordinates are u = (u; v), defined on a domain . <p> Thus, p (u; t) denotes the canonical positions of points on the model relative to the model frame. In <ref> [29] </ref>, we further express p as the sum of a reference shape s (u; t) (global deformation) and a displacement function d (u; t) (local deformation): p = s + d: (3) However, since computing 3-D local deformations from 2-D contour data is underconstrained, we will consider only global deformations, s, <p> This allows us, through the apparatus of Lagrangian dynamics, to arrive at a set of equations of motion governing the behavior of our model under the action of externally applied forces. 8 The Lagrange equations of motion take the form <ref> [29] </ref>: M q + D _ q + Kq = g q + f q ; (12) where M, D, and K are the mass, damping, and stiffness matrices, respectively, where g q are inertial (centrifugal and Coriolis) forces arising from the dynamic coupling between the local and global degrees of <p> We can simplify the equations while preserving useful dynamics by setting the mass density (u) to zero to obtain <ref> [29] </ref>: D _ q + Kq = f q : (26) These equations yield a model which has no inertia and comes to rest as soon as all the applied forces vanish or equilibrate. Equation (26) is discretized in material coordinates u using nodal finite element basis functions. <p> + v 2 2 (v 1 v 3 sv 2 ) 2 (v 2 v 3 + sv 1 ) 1 2 (v 2 2 ) 7 To obtain q from (27), we use the generalized torque at time t given by f &gt; = f &gt; Bdu, with B <ref> [27, 29] </ref>: where R represents the rotation matrix at time t, where ~p (u) is the dual 3 fi 3 matrix of the position vector p (u) = (p 1 ; p 2 ; p 3 ) &gt; (see (4)) defined as: ~p (u) = 6 0 p 3 p 2 <p> We convert the external forces to generalized forces f q which act on the generalized coordinates of the model <ref> [29] </ref>. We apply forces to the models based on differences between the model's projection in the image and the image data. Each of these 14 forces corresponds to the appropriate generalized coordinate that has to be adapted so that the model fits the data. <p> unit normal at any model point, i is the unit vector from the focal point to a point on the model, and t is a small threshold. 4.2.3 Model Initialization One of the major limitations of previous deformable model fitting approaches is their dependence on model initialization and prior segmentation <ref> [31, 29, 24] </ref>. Using the qualitative shape recovery process as a front end, we first segment the image into parts, and for each part, we identify the relevant non-occluded contour data belonging to the part.
Reference: [30] <author> D. Terzopoulos and A. Witkin. </author> <title> Physically based models with rigid and deformable components. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 8(6) </volume> <pages> 41-51, </pages> <year> 1988. </year>
Reference-contexts: A full implementation and simulation of the general equations would be appropriate for physically-based animation where realistic motion is important <ref> [30] </ref>. However, in computer vision and geometric design applications involving the fitting of models to data, models governed by simplified equations of motion suffice, as the experiments in Section 5 will demonstrate.
Reference: [31] <author> D. Terzopoulos, A. Witkin, and M. Kass. </author> <title> Constraints on deformable models: Recovering 3d shape and nonrigid motion. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 91-123, </pages> <year> 1988. </year>
Reference-contexts: In this paper, we unify these two schools into a single approach which first recovers qualitative shape from an image, and then uses that shape to constrain a quantitative recovery of the object's shape and pose. Physics-based modeling <ref> [24, 31, 29, 19, 18, 20] </ref> provides a very powerful mechanism for quantitatively modeling an object's shape for recognition. <p> These models incorporate global deformation parameters which represent the salient shape features of natural parts, and local deformation parameters which capture shape details. Thus, unlike previous physics-based techniques <ref> [31] </ref>, the shape of an object can both be abstracted or represented in detail. The framework also develops physics-based constraints to recover complex articulated models from deformable parts, and provides force-based techniques for fitting such models to sparse, noise-corrupted 2D and 3D visual data. <p> In the second stage, he fits superquadrics to the segmented data using a least squares algorithm. Pentland's approach is only applicable to the case of occluding boundary data under simple orthographic projection, as is true of earlier work of Terzopoulos et al. <ref> [31] </ref>, Terzopoulos and Metaxas [29], and Pentland and Sclaroff [24], which address only the problem of model fitting. The fundamental difference between our approach and the above approaches is that we use a qualitative segmentation of the image to provide sufficient constraints to our deformable model fitting procedure. <p> unit normal at any model point, i is the unit vector from the focal point to a point on the model, and t is a small threshold. 4.2.3 Model Initialization One of the major limitations of previous deformable model fitting approaches is their dependence on model initialization and prior segmentation <ref> [31, 29, 24] </ref>. Using the qualitative shape recovery process as a front end, we first segment the image into parts, and for each part, we identify the relevant non-occluded contour data belonging to the part.
Reference: [32] <author> D. Thompson and J. Mundy. </author> <title> Model-directed object recognition on the connection machine. </title> <booktitle> In Proceedings, DARPA Image Understanding Workshop, </booktitle> <pages> pages 93-106, </pages> <address> Los Angeles, CA, </address> <year> 1987. </year> <month> 33 </month>
Reference-contexts: The above systems, therefore, address only the task of recognizing the object. This is in contrast to classical 3-D object recognition systems, in which exact viewpoint is required to verify typically weak object hypotheses, while the object models capture the exact geometry of the object <ref> [6, 13, 17, 32] </ref>. Determining the pose of the object is a critical component of these approaches. Each of the above recognition schools addresses an important requirement of recognition systems: coarse object identification and object localization. However, there has been little effort to combine them into a single paradigm.
References-found: 32

