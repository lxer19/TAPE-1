URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-90-23.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.cs.virginia.edu
Date: ABSTRACT  
Pubnum: 1  
Abstract: Access/execute architectures have several advantages over more traditional architectures. Because address generation and memory access are decoupled from operand use, memory latencies are tolerated better, there is more potential for concurrent operation, and it permits the use of specialized hardware to facilitate fast address generation. This paper describes the code generation and optimization algorithms that are used in an optimizing compiler for an architecture that contains explicit hardware support for the access/execute model of computation. Of particular interest is the novel approach that the compiler uses to detect recurrence relations in programs and to generate code for them. Because these relations are often used in problem domains that require significant computational resources, detecting and handling them can result in significant reductions in execution time. While the techniques discussed were originally targeted for one specific architecture, many of the techniques are applicable to commonly available microprocessors. The paper describes the algorithms as well as our experience with using them on a number of machines. 
Abstract-found: 1
Intro-found: 1
Reference: [ATT88] <institution> WE DSP32 Digital Signal Processor Information Manual, AT&T Documentation Management Organization, </institution> <year> 1988. </year>
Reference-contexts: For example, scaled addressing modes, commonly used for array operations, are coded as a single instruction using shift and add as op1 and op2. Auto-increment and auto-decrement addressing modes are also easily synthesized. A few machines include special instructions for performing a multiply and add <ref> [ATT88, OEHL90] </ref>. They are particularly useful in codes that perform transformations such as the fast fourier transformation and graphics transformations. This is easily and naturally handled by the two-operation, three-operand instructions. The Vector Execution Unit The architecture also supports vector operations.
Reference: [BENI88] <author> M. E. Benitez and J. W. Davidson, </author> <title> A Portable Global Optimizer and Linker, </title> <booktitle> Proceedings of the SIGPLAN Notices 88 Symposium on Programming Language Design and Implementation, </booktitle> <address> Atlanta, GA, </address> <month> June </month> <year> 1988, </year> <pages> 329-338. </pages>
Reference-contexts: It is the compilers responsibility to detect codes that have recurrences and to generate streaming code. CODE GENERATION An optimizing C compiler that supports streaming has been constructed for WM. The compiler is based on an portable optimizer that operates at the machine-level <ref> [BENI88] </ref>. Using the diagrammatic notation of Wulf [WULF75], Figure 3 shows the overall structure of the C compiler. Vertical columns within a box represent logical phases which operate serially. Columns that are divided horizontally into rows indicate that the subphases of the column may be executed in arbitrary order.
Reference: [AHO86] <author> A. V. Aho, R. Sethi and J. D. Ullman, </author> <booktitle> Compilers Principles, Techniques, and Tools, </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: In this case, the reference will be added to each partition as it potentially touches each. See Compilers, Principles, Techniques and Tools <ref> [AHO86] </ref> for a complete description of induction variable detection. - 5 - Step 2. For each memory reference in the loop, determine the induction variable, the direction of the loop (i.e., whether the induction variable is increasing or decreasing), the cee value, and the dee value.
Reference: [AUSL82] <author> M. Auslander and M. Hopkins, </author> <title> An Overview of the PL.8 Compiler, </title> <booktitle> Proceedings of the SIGPLAN Notices 82 Symposium on Compiler Construction, </booktitle> <address> Boston, MA, </address> <month> June </month> <year> 1982, </year> <pages> 22-31. </pages>
Reference-contexts: The second strategy is that all optimizations are performed on object code (RTLs). The guiding principle is that more complete and thorough optimization is possible by operating on object code. The above two strategies are similar to the approach taken in the PL.8 compiler for the IBM 801 <ref> [AUSL82, RADI82] </ref>. The third strategy is that the optimizer uses the same representation for all phases of optimization. This allows optimization phases to be reinvoked at any time.
Reference: [GOOD85] <author> J. R. Goodman, J. Hsieh, K. Kiou, A. R. Pleszkun, P. B. Schechter and H. C. Young, </author> <title> PIPE: A VLSI Decoupled Architecture, </title> <booktitle> Proceedings of the 12th International Symposium on Computer Architecture, </booktitle> <address> Boston, MA, </address> <month> June </month> <year> 1985, </year> <pages> 20-27. </pages>
Reference-contexts: A term that has been coined to denote this type of processor is decoupled to emphasize the separation of the units and their independent, yet cooperative operation <ref> [GOOD85, SMITH84] </ref>. Conceptually, the instruction stream can be viewed as being divided into two or more separate streams for the individual units. The IBM RISC System/6000 [OEHL90], Intels i860 [INTE89], the Astronautics ZS-1 [SMIT87], PIPE [GOOD85], and WM [WULF88] are all architectures in this class. <p> Conceptually, the instruction stream can be viewed as being divided into two or more separate streams for the individual units. The IBM RISC System/6000 [OEHL90], Intels i860 [INTE89], the Astronautics ZS-1 [SMIT87], PIPE <ref> [GOOD85] </ref>, and WM [WULF88] are all architectures in this class. The major advantage of such machines is the ability to exploit instruction-level parallelism by executing instructions for the individual units simultaneously. <p> Streams are structured data stored in memory with a known, fixed displacement between successive elements. Streaming can be viewed as a special case of the access/ execute model of computation <ref> [GOOD85, SMIT84] </ref>. In this model, address generation is separated from consumption of the data. This allows two processors to be used concurrently and in concert to execute a task. One processor performs address generation and fetches the data, while the second processor performs all data processing calculations. <p> The separation of address generation from consumption (access/execute), combined with the use of queues to buffer data to and from memory is described by Smith [SMITH84]. It has been used in the PIPE processor <ref> [GOOD85] </ref>, and the ZS-1 [SMIT87]. The advantage is that, in concert with the compiler, it allows the processor to mask memory latency by issuing loads in advance of the data consumption. The result is a machine that is less sensitive to memory latency and cache misses.
Reference: [HENN90] <author> J. L. Hennessy and D. A. Patterson, </author> <title> Computer Architecture A Quantitative Approach, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year> <title> [INTE89] i860 64-Bit Microprocessor Hardware Reference Manual, </title> <publisher> Intel Corporation, </publisher> <address> Santa Clara, CA, </address> <year> 1989. </year>
Reference-contexts: These relations occur frequently in solutions to problems that require significant computational resources to solve. Recurrences occur in algorithms involving solutions of partial differential equations, signal processing, imaging transformations, and graphical transformations. Furthermore, codes that contain recurrences are difficult and often impossible to vectorize <ref> [HENN90] </ref>. Consequently, the detection of recurrence relations in programs coded in a high-level programming language and the accompanying generation of efficient machine language instruction sequences can yield significant execution performance improvements.
Reference: [KNUT73] <author> D. E. Knuth, </author> <title> Fundamental Algorithms, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1973. </year>
Reference-contexts: For example, on the Sun-3/280 using the C component of the SPEC benchmark suite, the compiler achieves a SPECratio of 4.3 (see SPEC Tables in Appendix I). The native C compiler, using the highest optimization level available, obtains a SPEC rating of 4.0. Recurrence Detection and Optimization Algorithm Knuth <ref> [KNUT73] </ref> defines a recurrence relation as: A rule which defines each element of a sequence in terms of the preceding elements.
Reference: [OEHL90] <author> R. R. Oehler and R. D. Groves, </author> <title> IBM RISC System/ 6000 Processor Architecture, </title> <journal> IBM Journal of Research and Development 34,1 (January 1990), </journal> <pages> 23-36. </pages>
Reference-contexts: Conceptually, the instruction stream can be viewed as being divided into two or more separate streams for the individual units. The IBM RISC System/6000 <ref> [OEHL90] </ref>, Intels i860 [INTE89], the Astronautics ZS-1 [SMIT87], PIPE [GOOD85], and WM [WULF88] are all architectures in this class. The major advantage of such machines is the ability to exploit instruction-level parallelism by executing instructions for the individual units simultaneously. <p> Each execution unit operates at its peak speed. In this respect WM is similar to the IBM RS/6000 <ref> [OEHL90] </ref>. Control instructions, that is those that affect the program counter, and other instructions that require synchronization of the execution units (such as converting a floating-point value to an integer value) are executed by the IFU. <p> For example, scaled addressing modes, commonly used for array operations, are coded as a single instruction using shift and add as op1 and op2. Auto-increment and auto-decrement addressing modes are also easily synthesized. A few machines include special instructions for performing a multiply and add <ref> [ATT88, OEHL90] </ref>. They are particularly useful in codes that perform transformations such as the fast fourier transformation and graphics transformations. This is easily and naturally handled by the two-operation, three-operand instructions. The Vector Execution Unit The architecture also supports vector operations.
Reference: [RADI82] <author> G. Radin, </author> <title> The 801 Minicomputer, </title> <booktitle> Proceedings of the Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Palo Alto, CA, </address> <month> March </month> <year> 1982, </year> <pages> 39-47. </pages>
Reference-contexts: The second strategy is that all optimizations are performed on object code (RTLs). The guiding principle is that more complete and thorough optimization is possible by operating on object code. The above two strategies are similar to the approach taken in the PL.8 compiler for the IBM 801 <ref> [AUSL82, RADI82] </ref>. The third strategy is that the optimizer uses the same representation for all phases of optimization. This allows optimization phases to be reinvoked at any time.
Reference: [SMIT84] <author> J. E. Smith, </author> <title> Decoupled Access/Execute Architectures, </title> <journal> ACM Transactions on Computer Systems 2,4 (November 1984), </journal> <pages> 289-308. </pages>
Reference-contexts: Streams are structured data stored in memory with a known, fixed displacement between successive elements. Streaming can be viewed as a special case of the access/ execute model of computation <ref> [GOOD85, SMIT84] </ref>. In this model, address generation is separated from consumption of the data. This allows two processors to be used concurrently and in concert to execute a task. One processor performs address generation and fetches the data, while the second processor performs all data processing calculations.
Reference: [SMIT87] <author> J. E. Smith, G. E. Dermer, B. D. Vanderwarn, S. D. Klinger, C. M. Roszewski, D. L. Fowler, K. R. Scidmore and J. P. Laudon, </author> <title> The ZS-1 Central Processor, </title> <booktitle> Proceedings of the Second International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Palo Alto, CA, </address> <month> October </month> <year> 1987, </year> <note> 199- 204. </note>
Reference-contexts: Conceptually, the instruction stream can be viewed as being divided into two or more separate streams for the individual units. The IBM RISC System/6000 [OEHL90], Intels i860 [INTE89], the Astronautics ZS-1 <ref> [SMIT87] </ref>, PIPE [GOOD85], and WM [WULF88] are all architectures in this class. The major advantage of such machines is the ability to exploit instruction-level parallelism by executing instructions for the individual units simultaneously. <p> The separation of address generation from consumption (access/execute), combined with the use of queues to buffer data to and from memory is described by Smith [SMITH84]. It has been used in the PIPE processor [GOOD85], and the ZS-1 <ref> [SMIT87] </ref>. The advantage is that, in concert with the compiler, it allows the processor to mask memory latency by issuing loads in advance of the data consumption. The result is a machine that is less sensitive to memory latency and cache misses.
Reference: [WULF75] <author> W. Wulf, R. K. Johnsson, C. B. Weinstock, S. O. Hobbs and C. M. Geschke, </author> <title> The Design of an Optimizing Compiler, </title> <publisher> American Elsevier, </publisher> <address> New York, NY, </address> <year> 1975. </year>
Reference-contexts: CODE GENERATION An optimizing C compiler that supports streaming has been constructed for WM. The compiler is based on an portable optimizer that operates at the machine-level [BENI88]. Using the diagrammatic notation of Wulf <ref> [WULF75] </ref>, Figure 3 shows the overall structure of the C compiler. Vertical columns within a box represent logical phases which operate serially. Columns that are divided horizontally into rows indicate that the subphases of the column may be executed in arbitrary order. The optimizer operates on register transfer lists (RTLs).
Reference: [WULF88] <author> W. A. Wulf, </author> <booktitle> The WM Computer Architecture, Computer Architecture News 16,1 (March 1988), </booktitle> <pages> 70-84. </pages>
Reference-contexts: Conceptually, the instruction stream can be viewed as being divided into two or more separate streams for the individual units. The IBM RISC System/6000 [OEHL90], Intels i860 [INTE89], the Astronautics ZS-1 [SMIT87], PIPE [GOOD85], and WM <ref> [WULF88] </ref> are all architectures in this class. The major advantage of such machines is the ability to exploit instruction-level parallelism by executing instructions for the individual units simultaneously.
Reference: [WULF90a] <author> W. A. Wulf, </author> <title> The WM Computer Architectures: Principles of Operation, </title> <institution> TR90-02, University of Virginia, </institution> <month> January </month> <year> 1990. </year>
Reference-contexts: Many details of the architecture, such as the various data types supported, instruction format, operating system support, and I/O, are not discussed. The interested reader can find these details in The WM Computer Architectures: Principles of Operation <ref> [WULF90a] </ref>. The Functional Units The machine has four main functional units: an instruction fetch unit (IFU), an integer execution unit (IEU), a floating-point execution unit (FEU), and a vector execution unit (VEU). All four units operate concurrently. There is also a fifth unit that is dedicated to handling streaming instructions.
Reference: [WULF90b] <author> W. A. Wulf and C. Hitchcock, </author> <title> The WM Family of Computer Architectures, </title> <institution> TR90-05, University of Virginia, </institution> <month> March </month> <year> 1990. </year> <month> - 10 </month> - 
Reference-contexts: However, regardless of the mechanisms used to fetch and issue instructions, the ability of the compiler to generate code that effectively exploits the multiple execution units is critical. This paper discusses the algorithms used in an optimizing compiler for exploiting an execution unit specifically designed to handle streams <ref> [WULF90b] </ref>. Streams are structured data stored in memory with a known, fixed displacement between successive elements. Streaming can be viewed as a special case of the access/ execute model of computation [GOOD85, SMIT84]. In this model, address generation is separated from consumption of the data.
References-found: 15

