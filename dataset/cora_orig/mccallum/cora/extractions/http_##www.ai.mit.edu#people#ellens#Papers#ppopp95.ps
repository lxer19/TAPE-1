URL: http://www.ai.mit.edu/people/ellens/Papers/ppopp95.ps
Refering-URL: http://www.ai.mit.edu/people/ellens/cv.html
Root-URL: 
Email: ellens@ai.mit.edu, billd@ai.mit.edu  
Title: Evaluating the Locality Benefits of Active Messages  
Author: Ellen Spertus and William J. Dally 
Address: Cambridge, Massachusetts 02139  
Affiliation: Laboratory for Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology  
Abstract: A major challenge in fine-grained computing is achieving locality without excessive scheduling overhead. We built two J-Machine implementations of a fine-grained programming model, the Berkeley Threaded Abstract Machine. One implementation takes an Active Messages approach, maintaining a scheduling hierarchy in software in order to improve data cache performance. Another approach relies on the J-Machine's message queues and fast task switch, lowering the control costs at the expense of data locality. Our analysis measures the costs and benefits of each approach, for a variety of programs and cache configurations. The Active Messages implementation is strongest when miss penalties are high and for the finest-grained programs. The hardware-buffered implementation is strongest in direct-mapped caches, where it achieves substantially better instruction cache performance. 
Abstract-found: 1
Intro-found: 1
Reference: [AHN88] <author> Arvind, S. K. Heller, and R. S. Nikhil. </author> <title> Programming generality and parallel computers. </title> <booktitle> In Proceedings of the 4 th International Symposium on Biological and Artificial Intelligence Systems, </booktitle> <pages> pages 255-286, </pages> <address> Trento, Italy, </address> <month> September </month> <year> 1988. </year> <note> ESCOM (Leider). </note>
Reference-contexts: 50, which multiplies two matrices of floating-point numbers and sums the elements of the product; quicksort (QS) 100, which sorts an array of random integers; discrete time warp (DTW) 10, a speech-processing application that performs operations on matrices of floating-point numbers; paraffins 13, which enumerates the distinct isomers of paraffins <ref> [AHN88] </ref>; wavefront 40, which computes successive matrices in which each element depends on a function of north and west values of the previous and current matrix; and selection sort (SS) 100, which sorts an array of integers that are originally in reverse order.
Reference: [CGSvE93] <author> D. E. Culler, S. C. Goldstein, K. E. Schauser, and T. von Eicken. </author> <title> TAM A Compiler Controlled Threaded Abstract Machine. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 18 </volume> <pages> 347-370, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Ideally, both approaches should be explored in combination. We compare two implementations of the same programming system, varying the scheduling hierarchy: (1) The Active Messages implementation, based directly on Culler's Threaded Abstract Machine (TAM) <ref> [CSS + 91, CGSvE93] </ref> and von Eicken's Active Messages fl Current address: Microsoft Research, 1 Microsoft Way, Redmond, WA 98052.
Reference: [CSS + 91] <author> D. Culler, A. Sah, K. Schauser, T. von Eicken, and J. Wawrzynek. </author> <title> Fine-grain Parallelism with Minimal Hardware Support: A Compiler-Controlled Threaded Abstract Machine. </title> <booktitle> In Proc. of 4th Int. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa-Clara, CA, </address> <month> April </month> <year> 1991. </year> <note> Also available as Technical Report UCB/CSD 91/591, </note> <institution> CS Div., University of California at Berkeley. </institution>
Reference-contexts: Ideally, both approaches should be explored in combination. We compare two implementations of the same programming system, varying the scheduling hierarchy: (1) The Active Messages implementation, based directly on Culler's Threaded Abstract Machine (TAM) <ref> [CSS + 91, CGSvE93] </ref> and von Eicken's Active Messages fl Current address: Microsoft Research, 1 Microsoft Way, Redmond, WA 98052. <p> Specifically, tasks using the same context are scheduled to run together, before switching to a different context. Coordi nating tasks from a single context creates larger-grained computation, leading to less frequent context-switching and, ideally, better memory usage (for both caches and registers) <ref> [vECGS92, CSS + 91] </ref>. 1.1.2 The MIT J-Machine The MIT J-Machine, a massively-parallel computer built using Message-Driven Processors (MDPs), was designed to support fine-grained parallel processing. Its mechanisms include two complete priority levels, each with its own register set and large (4 Kbyte) message queue. <p> We evaluate this claim, finding that under some circumstances, a message-driven approach provides a substantial improvement. 1.1.3 TAM The Berkeley Threaded Abstract Machine (TAM) <ref> [CSS + 91] </ref> is a fine-grained parallel execution model that is used as a back-end for the implicitly-parallel functional language Id [Nik91]. An Id codeblock is compiled into a set of inlets and threads, each made up of a sequence of instructions. <p> We now take into account the differences in cache performance, showing the net effect of the trade-offs in instruction counts and locality. 3.2 Measures of Granularity A useful metric of granularity is threads per quantum <ref> [CSS + 91] </ref>, which indicates how many threads from a frame are executed before a switch to another frame. This can involve emptying the LCV multiple times if subsequent messages are destined for the same frame.
Reference: [D + 87] <author> William J. Dally et al. </author> <title> Architecture of a message-driven processor. </title> <booktitle> In Proceedings of the 14th International Symposium on Computer Architecture, </booktitle> <pages> pages 189-205. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1987. </year>
Reference-contexts: Its mechanisms include two complete priority levels, each with its own register set and large (4 Kbyte) message queue. When a message arrives to the high-priority queue, low-priority computation is preempted. Message reception does not interrupt execution of a same-priority task; dispatch occurs when the task suspends <ref> [D + 87, DFK + 92] </ref>. The hardware message buffering has a negligible effect on system cost. y The J-Machine provides a superset of the base hardware required by Active Messages. Specifically, because of the large message queues with automatic buffering, messages need not be serviced immediately.
Reference: [DFK + 92] <author> William J. Dally, J. A. Stuart Fiske, John S. Keen, Richard A. Lethin, Michael D. Noakes, Peter R. Nuth, Roy E. Davison, and Gregory A. Fyler. </author> <title> The Message-Driven Processor: A multicomputer processing node with efficient mechanisms. </title> <journal> IEEE Micro, </journal> <volume> 12(2) </volume> <pages> 23-39, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Two different approaches to lowering the costs of frequent context switches are bringing the programming model closer to the architecture (as is done by Active Messages [vECGS92]) and bringing the architecture closer to the programming model's needs (as is done by the MIT J-Machine <ref> [DFK + 92] </ref>). Ideally, both approaches should be explored in combination. <p> Its mechanisms include two complete priority levels, each with its own register set and large (4 Kbyte) message queue. When a message arrives to the high-priority queue, low-priority computation is preempted. Message reception does not interrupt execution of a same-priority task; dispatch occurs when the task suspends <ref> [D + 87, DFK + 92] </ref>. The hardware message buffering has a negligible effect on system cost. y The J-Machine provides a superset of the base hardware required by Active Messages. Specifically, because of the large message queues with automatic buffering, messages need not be serviced immediately.
Reference: [MB91] <author> Jeffrey C. Mogul and Anita Borg. </author> <title> The effect of context switches on cache performance. </title> <booktitle> In Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa Clara, California, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: These latencies are due to both communication and synchronization among parallel computations. Counteracting the benefits of multithread-ing is the cost of context switching, which includes both direct overhead and the indirect cost of impaired cache performance <ref> [MB91] </ref>. Two different approaches to lowering the costs of frequent context switches are bringing the programming model closer to the architecture (as is done by Active Messages [vECGS92]) and bringing the architecture closer to the programming model's needs (as is done by the MIT J-Machine [DFK + 92]).
Reference: [ML95] <author> David Metz and Ben Lee. </author> <title> Analyzing the benefits of a separate processor to handle messages for fine-grain multithreading. </title> <type> Technical Report TRECE95.03, </type> <institution> Department of Electrical and Computer Engineering, Ore-gon State University, </institution> <year> 1995. </year> <booktitle> Submitted to the Seventh IEEE Symposium on Parallel and Distributed Processing. </booktitle>
Reference-contexts: Other Active Messages implementations avoid this problem by polling for messages at permissible points, rather than taking interrupts [SGS + 93] or through new atomic operations <ref> [ML95] </ref>. In Section 2.4, we discuss the effects of different policies toward message reception. 2.2 Message-Driven Implementation The Message-Driven (MD) implementation uses the message queues as task queues instead of servicing messages immediately.
Reference: [Nik91] <author> R. S. Nikhil. </author> <title> Id (version 90.1) reference manual. </title> <type> CSG Memo 284-2, </type> <institution> MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge, MA 02139, USA, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: We evaluate this claim, finding that under some circumstances, a message-driven approach provides a substantial improvement. 1.1.3 TAM The Berkeley Threaded Abstract Machine (TAM) [CSS + 91] is a fine-grained parallel execution model that is used as a back-end for the implicitly-parallel functional language Id <ref> [Nik91] </ref>. An Id codeblock is compiled into a set of inlets and threads, each made up of a sequence of instructions. Inlets are short message handlers that receive arguments from outside the codeblock, and threads are sequences of code corresponding to the body of the codeblock.
Reference: [Nik93] <author> Rishiyur S. Nikhil. </author> <title> A multithreaded implementation of Id using P-RISC graphs. </title> <booktitle> In Proceedings of the Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Port-land, OR, </address> <year> 1993. </year>
Reference-contexts: Nikhil made similar observations independently, criticizing TAM for its atomicity problems, frame memory traffic, and scheduling overhead, which he found to be of greater significance than the improvement in locality <ref> [Nik93] </ref>. An additional benefit of the MD implementation is that, because inlets pass control directly to threads instead of placing them into a continuation vector, a bigger region of code is open to conventional optimization.
Reference: [Sch91] <author> Klaus Erik Schauser. </author> <title> Compiling dataflow into threads. </title> <type> Master's thesis, </type> <institution> Computer Science Division, University of California at Berkeley, </institution> <year> 1991. </year>
Reference-contexts: At the end of the quantum, the exit thread would store them into frame memory. Entry and exit threads have not been implemented in the TAM compiler, however, and are not included in our analysis. Details on compiling Id programs to run on TAM are available elsewhere <ref> [Sch91, TCS92] </ref>. 2 Two TAM Implementations for the J-Machine To explore the benefits of Active Messages on a computer with the J-Machine's ability to buffer messages, we implemented two TAM back-ends. TAM is designed to be implemented on top of Active Messages.
Reference: [SGS + 93] <author> Ellen Spertus, Seth Copen Goldstein, Klaus Erik Schauser, Thorsten von Eicken, David E. Culler, and William J. Dally. </author> <title> Evaluation of mechanisms for fine-grained parallel programs in the J-Machine and the CM-5. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 302-313, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: TAM is designed to be implemented on top of Active Messages. A separate study examines how TAM's performance is affected by other J-Machine mechanisms, such as tagged memory, automatic dispatch on messages, and tight processor-network coupling <ref> [SGS + 93] </ref>. <p> In order to ensure atomic access of data structures accessible from both threads and inlets, interrupts are disabled during control operations in thread bodies. Other Active Messages implementations avoid this problem by polling for messages at permissible points, rather than taking interrupts <ref> [SGS + 93] </ref> or through new atomic operations [ML95]. In Section 2.4, we discuss the effects of different policies toward message reception. 2.2 Message-Driven Implementation The Message-Driven (MD) implementation uses the message queues as task queues instead of servicing messages immediately. <p> More generally, we have shown that the J-Machine's buffered message queues, an inexpensive mechanism, can provide a real benefit over the Active Messages approach. The benefit of hardware dispatch has been shown elsewhere <ref> [SGS + 93] </ref>. The net lesson is that hardware mechanisms for fine-grained parallelism can significantly improve performance. Our results depend heavily on cache miss penalties and cache sizes. In the future, we can expect both the miss penalty and size of caches to grow.
Reference: [Spe92] <author> Ellen Spertus. </author> <title> Execution of Dataflow Programs on General-Purpose Hardware. </title> <type> Master's thesis, </type> <institution> Department of EECS, Mas-sachusetts Institute of Technology, </institution> <type> 545 Tech. </type> <institution> Square, </institution> <address> Cambridge, MA, </address> <month> August </month> <year> 1992. </year> <note> To be expanded and released as Technical Report 1380. </note>
Reference-contexts: The last item in the LCV is the address of the system code to swap in a new frame. An atomicity problem arises due to allowing inlets to interrupt threads <ref> [Spe92] </ref>. Specifically, consider the case where the TAM fork t instruction is interrupted by an inlet that includes the instruction post t. If the thread and the inlet belong to the same codeblock activation, the synchronization counter for thread t may be improperly decremented.
Reference: [TCS92] <author> K. R. Traub, D. E. Culler, and K. E. Schauser. </author> <title> Global analysis for partitioning non-strict programs into sequential threads. </title> <journal> ACM LISP Pointers, </journal> <volume> 5(1) </volume> <pages> 324-334, </pages> <year> 1992. </year> <booktitle> Proceedings of the 1992 ACM Conference on LISP and Functional Programming. </booktitle>
Reference-contexts: At the end of the quantum, the exit thread would store them into frame memory. Entry and exit threads have not been implemented in the TAM compiler, however, and are not included in our analysis. Details on compiling Id programs to run on TAM are available elsewhere <ref> [Sch91, TCS92] </ref>. 2 Two TAM Implementations for the J-Machine To explore the benefits of Active Messages on a computer with the J-Machine's ability to buffer messages, we implemented two TAM back-ends. TAM is designed to be implemented on top of Active Messages.
Reference: [Thi92] <institution> Thinking Machines Corporation, Cam-bridge, Massachusetts. </institution> <note> The Connection Machine CM-5 Technical Summary, </note> <month> January </month> <year> 1992. </year>
Reference-contexts: If the network interface is attached to a lower level of the memory hierarchy, as with the CM-5 <ref> [Thi92] </ref>, even more scarce memory bandwidth is consumed reading incoming message data out of the memory-mapped registers.
Reference: [vECGS92] <author> Thorsten von Eicken, David E. Culler, Seth Copen Goldstein, and Klaus Erik Schauser. </author> <title> Active Messages: a Mechanism for Integrated Communication and Computation. </title> <booktitle> In Proc. of the 19th Int'l Symposium on Computer Architecture, </booktitle> <address> Gold Coast, Aus-tralia, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Two different approaches to lowering the costs of frequent context switches are bringing the programming model closer to the architecture (as is done by Active Messages <ref> [vECGS92] </ref>) and bringing the architecture closer to the programming model's needs (as is done by the MIT J-Machine [DFK + 92]). Ideally, both approaches should be explored in combination. <p> To appear in the Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, July 1995. <ref> [vECGS92] </ref>, manages tasks explicitly with the goal of improving data locality. (2) The message-driven implementation flattens TAM's scheduling hierarchy by exploiting the J-Machine's message queue, requiring fewer overhead instructions. We measure the costs and benefits of the two systems, quantitatively evaluating the claim [vECGS92] that using the J-Machine's message queue as <p> and Practice of Parallel Programming, July 1995. <ref> [vECGS92] </ref>, manages tasks explicitly with the goal of improving data locality. (2) The message-driven implementation flattens TAM's scheduling hierarchy by exploiting the J-Machine's message queue, requiring fewer overhead instructions. We measure the costs and benefits of the two systems, quantitatively evaluating the claim [vECGS92] that using the J-Machine's message queue as a task queue hurts cache performance too much to be useful. <p> This is accomplished by requiring message handlers to be short, restricting them to (1) storing message words (and any control information) into user-allocated memory or (2) replying immediately to a simple request that does not require storage <ref> [vECGS92] </ref>. The key difference between programming models based on Active Messages and message-driven processing is where the computation is performed. In purely message-driven systems, the computation is performed in the message handlers, i.e., directly in response to incoming messages. <p> Specifically, tasks using the same context are scheduled to run together, before switching to a different context. Coordi nating tasks from a single context creates larger-grained computation, leading to less frequent context-switching and, ideally, better memory usage (for both caches and registers) <ref> [vECGS92, CSS + 91] </ref>. 1.1.2 The MIT J-Machine The MIT J-Machine, a massively-parallel computer built using Message-Driven Processors (MDPs), was designed to support fine-grained parallel processing. Its mechanisms include two complete priority levels, each with its own register set and large (4 Kbyte) message queue. <p> Specifically, because of the large message queues with automatic buffering, messages need not be serviced immediately. The designers of Active Messages considered this feature counterproductive, claiming that the relatively short run lengths of a message-driven approach significantly impair data locality by preventing efficient use of registers and cache memory <ref> [vECGS92, p. 261] </ref>. We evaluate this claim, finding that under some circumstances, a message-driven approach provides a substantial improvement. 1.1.3 TAM The Berkeley Threaded Abstract Machine (TAM) [CSS + 91] is a fine-grained parallel execution model that is used as a back-end for the implicitly-parallel functional language Id [Nik91].
Reference: [WHJ + 95] <author> Deborah A. Wallach, Wilson C. Hsieh, Kirk L. Johnson, M. Frans Kaashoek, and William E. Weihl. </author> <title> Optimistic active messages: A mechanism for scheduling communication with computation. </title> <booktitle> In Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: Another variation is to combine the two approaches, using the message-driven approach for short threads and the Active Messages approach for long threads, as is done with Optimistic Active Messages <ref> [WHJ + 95] </ref>. In this study, however, our goal is to understand the differences in behavior of the two pure systems. 3 Analysis In this section, we compare the code produced by the two implementations, including relative numbers of data and instruction accesses and cache performance.
References-found: 16

