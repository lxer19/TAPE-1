URL: http://polaris.cs.uiuc.edu/reports/1427.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Email: lchoi@csrd.uiuc.edu yew@cs.umn.edu  
Phone: (217)333-0969 (612)625-7387  
Title: Interprocedural Array Data-Flow Analysis for Cache Coherence  
Author: Lynn Choi Pen-Chung Yew 
Note: This work is supported in part by the National Science Foundation under Grant No. MIP 89-20891, MIP 93-07910.  
Date: April 24, 1995  
Address: Urbana, IL 61801-1351 Minneapolis, MN 55455-0519  
Affiliation: Center for Supercomputing R D Department of Computer Science University of Illinois University of Minnesota  
Abstract: The presence of procedures and procedure calls introduces side effects, which complicate the analysis of stale reference detection in compiler-directed cache coherence schemes [4, 3, 9]. Previous compiler algorithms use the invalidation of an entire cache at procedure boundary [5, 8] or inlining [8] to avoid reference marking interprocedurally. However, frequent cache invalidations will result in poor performance since locality can not be exploited across the procedure boundary. Also, the inlining is often prohibitive due to both its code expansion and increase in its compilation time and memory requirements. In this paper, we introduce an improved intraprocedural and interprocedural algorithms for detecting references to stale data. The intraprocedural algorithm can mark potential stale references without relying on any cache invalidation or inlining at procedure boundaries, thus avoiding unnecessary cache misses for subroutine local data. The interprocedural algorithm performs bottom-up and top-down analysis on procedure call graph to further exploit locality across procedure boundaries. We also propose a condition for a stale access, which identifies the memory reference sequence leading to a potential stale access at compile time. The condition considers RAW (read-after-write) and WAW (write-after-write) dependencies caused by multi-word cache lines. We have implemented the intraprocedural algorithm and currently we are implementing the full interprocedural compiler algorithm on the Polaris parallelizing compiler [14]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Ballance, A. Maccabe, and K. Ottenstein. </author> <title> The Program Dependence Web: a Representation Supporting Control Data- and Demand-Driven Interpretation of Imperative 17 Languages. </title> <booktitle> Proceedings of the SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 257-271, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: To perform effective array flow analysis, symbolic manipulation of expressions is necessary since the computation of array regions often involves the equality and comparison tests between symbolic expressions. For this purpose, we use the gated single assignment (GSA) form <ref> [1] </ref>. By transforming a source program into its GSA form, we can treat arrays with different reference regions as different symbolic variables. In addition, the GSA is used for demand-driven symbolic analysis which can determine the relationship between symbolic expressions across the confluence points of a program [15]. <p> S20, S21, S22 and S23) or the epoch from S6 to S13 (The epoch consists of nodes S6, S7, S8, S9, S10, S11, S8, S16, S17, S18, S6, S7, S12, and S13 if S9 does not contain any parallel loop.). 2.2 Overall algorithm to a gated single assignment (GSA) form <ref> [1] </ref>, which is used to refine symbolic analysis involving array references. Then, we construct the epoch flow graph, which contains the epoch boundary information as well as the control flows of the program.
Reference: [2] <author> D. Callahan and K. Kennedy. </author> <title> Analysis of Interprocedural Side Effects in a Parallel Programming Environment. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 517-550, </pages> <year> 1988. </year>
Reference-contexts: The notion of subarray we use is an extension to the regular section used in <ref> [2, 11] </ref>. A subarray consists of a subscripted variable and one or more ranges for some of the indices in the subscript expression. A range includes expressions for the lower bound, upper bound and stride. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which can limit compiler-directed coherence schemes <ref> [2, 4, 3, 9, 12, 13] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 8] or selective inlining [8] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [3] <author> Hoichi Cheong. </author> <title> Life Span Strategy A Compiler-Based Approach to Cache Coherence. </title> <booktitle> Proceedings of the 1992 International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Procedure calls introduce complications in most global compiler analysis and optimizations due to its side effects and potential aliasing caused by parameter passing. Stale access detection [5, 9] is a compile time analysis to identify potential references to stale data for compiler-directed coherence schemes <ref> [4, 3, 9] </ref>. By identifying these potential stale references at compile time, cache coherence can be maintained by forcing those references to get up-to-date data directly from the main memory, instead of from the cache. <p> The compiler marking algorithm developed here are also general enough to be applicable to other compiler-directed coherence schemes <ref> [3, 4] </ref>. The interprocedural algorithm performs both bottom-up and top-down analysis on a procedure call graph to exploit cache locality across procedure boundaries. The first bottom-up side effect analysis eliminates the side effects caused by procedure calls by summarizing the access information at each call site. <p> A and B are assumed to be in the same cache line 1.3 Coherence mechanism and hardware support In our cache coherence scheme, each epoch is assigned a unique epoch number which is similar to the version number in previous schemes <ref> [3, 6, 7, 13] </ref>. The epoch number is stored in an n-bit register in each processor, called epoch counter (R counter ), and is incremented at the end of 4 every epoch by each processor individually. <p> In a scalar analysis, even a write to a single element of an array is interpreted as a write to the entire array. This conservative scalar analysis often creates unnecessary cache misses either through invalidations or by redundant accesses to main 6 memory <ref> [3, 4, 9] </ref>. These unnecessary memory accesses can be avoided by a more precise analysis. In our analysis, we identify the region of an array that are referenced by each array reference and treat it as a distinct variable. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which can limit compiler-directed coherence schemes <ref> [2, 4, 3, 9, 12, 13] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 8] or selective inlining [8] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [4] <author> Hoichi Cheong and Alex Veidenbaum. </author> <title> A Cache Coherence Scheme with Fast Selective Invalidation. </title> <booktitle> Proceedings of The 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> page 299, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Procedure calls introduce complications in most global compiler analysis and optimizations due to its side effects and potential aliasing caused by parameter passing. Stale access detection [5, 9] is a compile time analysis to identify potential references to stale data for compiler-directed coherence schemes <ref> [4, 3, 9] </ref>. By identifying these potential stale references at compile time, cache coherence can be maintained by forcing those references to get up-to-date data directly from the main memory, instead of from the cache. <p> The compiler marking algorithm developed here are also general enough to be applicable to other compiler-directed coherence schemes <ref> [3, 4] </ref>. The interprocedural algorithm performs both bottom-up and top-down analysis on a procedure call graph to exploit cache locality across procedure boundaries. The first bottom-up side effect analysis eliminates the side effects caused by procedure calls by summarizing the access information at each call site. <p> In a scalar analysis, even a write to a single element of an array is interpreted as a write to the entire array. This conservative scalar analysis often creates unnecessary cache misses either through invalidations or by redundant accesses to main 6 memory <ref> [3, 4, 9] </ref>. These unnecessary memory accesses can be avoided by a more precise analysis. In our analysis, we identify the region of an array that are referenced by each array reference and treat it as a distinct variable. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which can limit compiler-directed coherence schemes <ref> [2, 4, 3, 9, 12, 13] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 8] or selective inlining [8] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [5] <author> Hoichi Cheong and Alexander V. Veidenbaum. </author> <title> Stale Data Detection and Coherence Enforcement Using Flow Analysis. </title> <booktitle> Proceedings of the 1988 International Conference on Parallel Processing, I, </booktitle> <address> Architecture:138-145, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Procedure calls introduce complications in most global compiler analysis and optimizations due to its side effects and potential aliasing caused by parameter passing. Stale access detection <ref> [5, 9] </ref> is a compile time analysis to identify potential references to stale data for compiler-directed coherence schemes [4, 3, 9]. <p> By identifying these potential stale references at compile time, cache coherence can be maintained by forcing those references to get up-to-date data directly from the main memory, instead of from the cache. In stale reference detection, procedure boundaries force all previous algorithms <ref> [5, 8] </ref> to use conservative approaches such as cache invalidation or inlining to avoid reference marking across procedure calls. However, both approaches have their own problems. <p> The staleness of the data is determined at runtime by using this Time-Read instruction because it will check whether the cache data is created after the most recent write by checking the condition (1). Array data-flow analysis Previous compiler algorithms <ref> [5, 9] </ref> treat an entire array as a single variable, which leads to conservative estimation of potential stale references. Consider the program example in Figure 5 (b) in which the iteration space of the second DO loop (epoch 2) is from n+1 to 2n instead of 1 to n. <p> In addition, this also causes another problem at the beginning of procedure since any global COMMON variables and formal parameters could have been previously modified before entering the procedure. To avoid the complications caused by procedure calls, previous algorithms <ref> [5, 8] </ref> use cache invalidation both at the beginning of a procedure and after each call site. Since the algorithms assume a clean cache at procedure boundaries, their analysis can guarantee the correctness of reference marking. <p> For a target reference which does not have a reaching definition inside a procedure, we issue a Time-Read with the minimum offset, implying the data item referenced can be potentially modified before entering the procedure. This is an improvement over previous algorithms <ref> [5, 8] </ref> which use cache invalidation at the procedure beginning since only global and formal variables are affected by the unknown context information. We propagate definitions through the flow graph and increment their offsets when they cross the scheduling edges. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which can limit compiler-directed coherence schemes [2, 4, 3, 9, 12, 13] to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation <ref> [5, 8] </ref> or selective inlining [8] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [6] <author> Hoichi Cheong and Alexander V. Veidenbaum. </author> <title> A Version Control Approach To Cache Coherence. </title> <booktitle> Proceedings of 1989 ACM/SIGARCH International Conference on Supercomputing, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: A and B are assumed to be in the same cache line 1.3 Coherence mechanism and hardware support In our cache coherence scheme, each epoch is assigned a unique epoch number which is similar to the version number in previous schemes <ref> [3, 6, 7, 13] </ref>. The epoch number is stored in an n-bit register in each processor, called epoch counter (R counter ), and is incremented at the end of 4 every epoch by each processor individually.
Reference: [7] <author> T. Chiueh. </author> <title> A Generational Approach to Software-Controlled Multiprocessor Cache Coherence. </title> <booktitle> Proceedings 1993 International Conference on Parallel Processing, </booktitle> <year> 1993. </year>
Reference-contexts: A and B are assumed to be in the same cache line 1.3 Coherence mechanism and hardware support In our cache coherence scheme, each epoch is assigned a unique epoch number which is similar to the version number in previous schemes <ref> [3, 6, 7, 13] </ref>. The epoch number is stored in an n-bit register in each processor, called epoch counter (R counter ), and is incremented at the end of 4 every epoch by each processor individually.
Reference: [8] <author> Lynn Choi and Pen-Chung Yew. </author> <title> Eliminating Stale Data References through Array Data-Flow Analysis. </title> <note> submitted for publication, </note> <month> April </month> <year> 1995. </year>
Reference-contexts: By identifying these potential stale references at compile time, cache coherence can be maintained by forcing those references to get up-to-date data directly from the main memory, instead of from the cache. In stale reference detection, procedure boundaries force all previous algorithms <ref> [5, 8] </ref> to use conservative approaches such as cache invalidation or inlining to avoid reference marking across procedure calls. However, both approaches have their own problems. <p> In addition, this also causes another problem at the beginning of procedure since any global COMMON variables and formal parameters could have been previously modified before entering the procedure. To avoid the complications caused by procedure calls, previous algorithms <ref> [5, 8] </ref> use cache invalidation both at the beginning of a procedure and after each call site. Since the algorithms assume a clean cache at procedure boundaries, their analysis can guarantee the correctness of reference marking. <p> However, note that such invalidations cause unnecessary cache misses for global COMMON variables and parameters as well as for subroutine local variables. Frequent invalidations at procedure boundaries will degrade cache performance significantly because it limits the scope of locality within procedural boundaries. From our execution-driven simulations on Perfect benchmarks <ref> [8] </ref>, the performance degradation could be significant especially if a program contains many small procedures. 2 Intraprocedural Algorithm 2.1 Basics We consider the problem of identifying potential stale references in a data-flow framework. <p> In such a case, both array references should be marked as having upwardly-exposed uses. For those partially upwardly-exposed references, we keep only the region of the array that is actually upwardly-exposed and use the subarray information for later analysis. We use the algorithm proposed in <ref> [8] </ref> to mark the target references. 2.3 Stale reference detection The intraprocedural algorithm for stale reference detection is an improved version of the previous algorithm we developed in [8]. We refine the algorithm both to accommodate multi-word cache blocks as well as to eliminate cache invalidation at procedure boundaries. <p> We use the algorithm proposed in <ref> [8] </ref> to mark the target references. 2.3 Stale reference detection The intraprocedural algorithm for stale reference detection is an improved version of the previous algorithm we developed in [8]. We refine the algorithm both to accommodate multi-word cache blocks as well as to eliminate cache invalidation at procedure boundaries. Each definition of a variable v, denoted as d v offset , is associated with an offset. <p> For a target reference which does not have a reaching definition inside a procedure, we issue a Time-Read with the minimum offset, implying the data item referenced can be potentially modified before entering the procedure. This is an improvement over previous algorithms <ref> [5, 8] </ref> which use cache invalidation at the procedure beginning since only global and formal variables are affected by the unknown context information. We propagate definitions through the flow graph and increment their offsets when they cross the scheduling edges. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which can limit compiler-directed coherence schemes [2, 4, 3, 9, 12, 13] to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation <ref> [5, 8] </ref> or selective inlining [8] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which can limit compiler-directed coherence schemes [2, 4, 3, 9, 12, 13] to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 8] or selective inlining <ref> [8] </ref> to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path. Inlining allows the most precise analysis but often prohibitive due to its potential code size expansion as well as the compile time increase.
Reference: [9] <author> Lynn Choi and Pen-Chung Yew. </author> <title> A Compiler-Directed Cache Coherence Scheme with Improved Intertask Locality. </title> <booktitle> Proceedings of the Supercomputing'94, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Procedure calls introduce complications in most global compiler analysis and optimizations due to its side effects and potential aliasing caused by parameter passing. Stale access detection <ref> [5, 9] </ref> is a compile time analysis to identify potential references to stale data for compiler-directed coherence schemes [4, 3, 9]. <p> 1 Introduction Procedure calls introduce complications in most global compiler analysis and optimizations due to its side effects and potential aliasing caused by parameter passing. Stale access detection [5, 9] is a compile time analysis to identify potential references to stale data for compiler-directed coherence schemes <ref> [4, 3, 9] </ref>. By identifying these potential stale references at compile time, cache coherence can be maintained by forcing those references to get up-to-date data directly from the main memory, instead of from the cache. <p> Then in section 1.3, we briefly introduce a compiler-directed coherence scheme <ref> [9] </ref> as the target machine environment for our reference marking algorithm. In section 2, we first describe our program representation methods: epoch flow graph [9], array descriptors, and GSA. <p> Then in section 1.3, we briefly introduce a compiler-directed coherence scheme <ref> [9] </ref> as the target machine environment for our reference marking algorithm. In section 2, we first describe our program representation methods: epoch flow graph [9], array descriptors, and GSA. Then, we present an intraprocedural reference marking algorithm which can detect stale data references without cache invalidation nor inlining in the presence of procedure calls. <p> The staleness of the data is determined at runtime by using this Time-Read instruction because it will check whether the cache data is created after the most recent write by checking the condition (1). Array data-flow analysis Previous compiler algorithms <ref> [5, 9] </ref> treat an entire array as a single variable, which leads to conservative estimation of potential stale references. Consider the program example in Figure 5 (b) in which the iteration space of the second DO loop (epoch 2) is from n+1 to 2n instead of 1 to n. <p> In a scalar analysis, even a write to a single element of an array is interpreted as a write to the entire array. This conservative scalar analysis often creates unnecessary cache misses either through invalidations or by redundant accesses to main 6 memory <ref> [3, 4, 9] </ref>. These unnecessary memory accesses can be avoided by a more precise analysis. In our analysis, we identify the region of an array that are referenced by each array reference and treat it as a distinct variable. <p> Figure 6 shows the example program and its GSA form which will be used throughout the discussion in this section. Because the epoch boundary information is essential in identifying potential stale references, we include parallel constructs in our control flow graph, called the epoch flow graph <ref> [9] </ref>. 8 Epoch flow graph Let the directed graph G = (V, E) represent a control flow graph where V is a set of statements, and E is a set of directed edges, representing the control flow between nodes in V. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which can limit compiler-directed coherence schemes <ref> [2, 4, 3, 9, 12, 13] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 8] or selective inlining [8] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [10] <author> Mary W. Hall. </author> <title> Managing Interprocedural Optimization. </title> <type> Technical report, </type> <institution> Rice University, Dept. of Computer Science, </institution> <month> April </month> <year> 1991. </year> <type> Ph.D. Thesis. </type>
Reference-contexts: However, it is not always practical to perform inlining due to its code expansion and compilation time increase. In addition, the inlining needs to deal with other implementation issues such as type mismatch and array reshaping between actual parameters and formal parameters <ref> [10] </ref>. Since inlining is the most effective for small procedures, we selectively inline a procedure only if its size (determined in terms of references) is less than a threshold value. In general, we use the following interprocedural algorithm.
Reference: [11] <author> Paul Havlak. </author> <title> Interprocedural Symbolic Analysis. </title> <type> Technical report, </type> <institution> Rice University, Dept. of Computer Science, </institution> <month> May </month> <year> 1994. </year> <type> Ph.D. Thesis. </type>
Reference-contexts: The notion of subarray we use is an extension to the regular section used in <ref> [2, 11] </ref>. A subarray consists of a subscripted variable and one or more ranges for some of the indices in the subscript expression. A range includes expressions for the lower bound, upper bound and stride.
Reference: [12] <author> A. Louri and H. Sung. </author> <title> A Compiler Directed Cache Coherence Scheme with Fast and Parallel Explicit Invalidation. </title> <booktitle> Proceedings of the 1992 International Conference on Parallel Processing, I, </booktitle> <address> Architecture:I-2-I-9, </address> <month> August </month> <year> 1992. </year> <month> 18 </month>
Reference-contexts: Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which can limit compiler-directed coherence schemes <ref> [2, 4, 3, 9, 12, 13] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 8] or selective inlining [8] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [13] <author> S. L. Min and J.-L. Baer. </author> <title> A Timestamp-based Cache Coherence Scheme. </title> <booktitle> 1989 International Conference on Parallel Processing, </booktitle> <address> I:23-32, </address> <year> 1989. </year>
Reference-contexts: A and B are assumed to be in the same cache line 1.3 Coherence mechanism and hardware support In our cache coherence scheme, each epoch is assigned a unique epoch number which is similar to the version number in previous schemes <ref> [3, 6, 7, 13] </ref>. The epoch number is stored in an n-bit register in each processor, called epoch counter (R counter ), and is incremented at the end of 4 every epoch by each processor individually. <p> Procedure calls can introduce side effects at a call site and hidden context at the beginning of a procedure, which can limit compiler-directed coherence schemes <ref> [2, 4, 3, 9, 12, 13] </ref> to exploit locality only within procedure boundaries. Previous algorithms use cache invalidation [5, 8] or selective inlining [8] to solve the problem. However, invalidation at procedure boundaries incur significant performance penalty especially if a program contains many small procedures in its critical path.
Reference: [14] <author> D. A. Padua, R. Eigenmann, J. Hoeflinger, P. Peterson, P. Tu, S. Weatherford, and K. Faign. </author> <title> Polaris: A New-Generation Parallelizing Compiler for MPPs. In CSRD Rept. No. </title> <type> 1306. </type> <institution> Univ. of Illinois at Urbana-Champaign., </institution> <month> June, </month> <year> 1993. </year>
Reference-contexts: This two-pass analysis avoids redundant computation by performing incremental update of reference marking with a minimal number of computation per procedure. We have implemented the intraprocedural algorithm and currently implementing the full interprocedural analysis on the Polaris parallelizing compiler <ref> [14] </ref>. In the following sections 1.1 and 1.2, we first describe our parallel program execution model and introduce a stale reference condition which identifies the sequence of memory reference events leading to a stale data access at compile time for both single and multi-word cache lines. <p> In addition, the top-down pass updates the reference marking result of the side effect analysis incrementally, minimizing the compilation time. We are currently implementing these algorithms on the Polaris parallelizing compiler <ref> [14] </ref>.
Reference: [15] <author> P. Tu and D. Padua. </author> <title> Gated SSA Based Demand-Driven Symbolic Analysis. </title> <type> CSRD Technical Report No. 1336, </type> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: By transforming a source program into its GSA form, we can treat arrays with different reference regions as different symbolic variables. In addition, the GSA is used for demand-driven symbolic analysis which can determine the relationship between symbolic expressions across the confluence points of a program <ref> [15] </ref>. We also propose a new condition for a stale access which determines the memory reference sequences leading to stale accesses at compile time. <p> Similarly, by representing the subarray fields in the GSA form, we can perform subarray operations involving symbolic loop bounds. In addition, GSA allows a backward demand-driven symbolic analysis to compute values and conditions across the confluence points <ref> [15] </ref>. Figure 6 shows the example program and its GSA form which will be used throughout the discussion in this section.
Reference: [16] <author> A. V. Veidenbaum. </author> <title> A Compiler-Assisted Cache Coherence Solution for Multiprocessors. </title> <booktitle> Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <pages> pages 1029-1035, </pages> <month> August </month> <year> 1986. </year> <title> 19 example. A bold arc denotes a scheduling edge while a normal arc denotes a flow edge. Head nodes are represented as bold nodes. Call sites are denoted as shaded nodes. The bold-dotted paths show two instances of the epoch where statement S17 can belong at runtime. The epoch flow graph also shows the set of definitions GEN(S), TARGET(S), and STALE(S) computed for each statement according to the intraprocedural algorithm. </title> <type> 20 21 22 23 24 </type>
Reference-contexts: We also propose a new condition for a stale access which determines the memory reference sequences leading to stale accesses at compile time. The new condition is a refinement to previously proposed condition <ref> [16] </ref>, which fails to cover all potential stale references in the presence of multi-word cache lines due to the line aliasing problem. <p> Barrier synchronizations are used at the end of parallel 2 epochs. 1.2 Memory reference patterns for stale references Let's first define the ordering of events which leads to stale references. As shown in Figure 2, the following sequence of events creates a stale access <ref> [16] </ref>: (1) a read/write to a memory location x by the processor i in the epoch a; (2) a write to x by another processor j (6= i) in the epoch b; (3) a read of x by the processor i in the epoch c.
References-found: 16

