URL: ftp://ftp.cs.kun.nl/pub/CSI/SoftwEng.FunctLang/papers/kesm95-skeletons.ps.gz
Refering-URL: http://www.cs.kun.nl/~clean/Clean.Papers.html
Root-URL: 
Title: Constructing Skeletons in Clean The Bare Bones  
Author: Marco Kesseler 
Address: Toernooiveld 1, 6525 ED Nijmegen, The Netherlands  
Affiliation: Faculty of Mathematics and Computer Science, University of Nijmegen,  
Abstract: Skeletons are wellsuited to structure parallel pro gram-ming. They allow the easy use of some well-known parallel programming paradigms to construct portable, efficient programs. Much research has been focused on the use of skeletons in functional pro gramming languages, because they can be expressed elegantly as higher order functions. On the other hand, little attention has been paid to an elementary weakness of skeletons: how to im plement them. In this paper we will show that functional languages with some low level constructs for parallelism can be used to efficiently implement a range of high level skeletons. We will construct skeletons for data parallelism, for parallel I/O, and for stream processing. Our experiments demonstrate that no performance penalty needs to be paid, compared to more restrictive solutions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Guy E. Blelloch, Siddhartha Chatterjee, Jonathan C. Hardwick, Jay Sipelstein, </author> <title> and Marco Zagha Implementation of a Portable Nested Data-Parallel Language In Principles of Programming Languages, </title> <booktitle> pages 102--111, </booktitle> <month> May 93. </month>
Reference-contexts: Many have advocated the use of skeletons in parallel programming environments and in particular, research has focused on functional languages <ref> [1, 3, 4, 8, 9, 14, 17] </ref>. This is mainly because skeletons can be expressed elegantly as higher order functions. <p> Considering this, it is not surprising that most experiments with some form of skeletons have been produced with a small set of data parallel languages on a limited set of machines that support these languages well <ref> [1, 6] </ref>. So far, we have gained only little experience with skeletons in more common functional languages on more general purpose machines [3, 4, 14]. This indicates that an intermediate level of abstraction is desirable.
Reference: [2] <author> A.P.W. Bhm, J. Sargeant, </author> <title> Code Optimisation for Tagged Token Dataflow Machines, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol 38, Nmb 1, </volume> <month> January </month> <year> 1989. </year>
Reference-contexts: We will construct skeletons that provide efficient data parallel constructs, skeletons to perform parallel I/O, and finally, skeletons that describe stream processing. 3. Skeletons for Data Parallelism Unlike Sisal <ref> [2, 6] </ref>, Concurrent Clean is not a strict lan - guage dedicated to data parallelism. One of its major shortcomings has been the lack of suitable constructs for this kind of parallel processing. <p> Usually, this requirement will be met by the ar ray-constructing argument functions of the skeletons. We have not (yet) made use of uniqueness properties within the definition of the skeletons themselves. With relation to imperative languages and languages like Sisal <ref> [2] </ref>, it is important to know that the tested version of Clean does not optimise loops on arrays, nor does it generate code for array selection. Instead it uses small functions like Put and Get to insert or extract elements.
Reference: [3] <author> Tore A. Bratvold, </author> <title> Parallelising a Functional Program Using a List-Homomorphism Skeleton. The First International Symposium on Parallel S y m b o l i c C o m p u t a t i o n , P A S C O 9 4 , Hagenberg/Linz, </title> <booktitle> Austria, </booktitle> <pages> pages 44-53, </pages> <publisher> World Scientific, </publisher> <year> 1994. </year>
Reference-contexts: Many have advocated the use of skeletons in parallel programming environments and in particular, research has focused on functional languages <ref> [1, 3, 4, 8, 9, 14, 17] </ref>. This is mainly because skeletons can be expressed elegantly as higher order functions. <p> So far, we have gained only little experience with skeletons in more common functional languages on more general purpose machines <ref> [3, 4, 14] </ref>. This indicates that an intermediate level of abstraction is desirable.
Reference: [4] <author> Tore A. Bratvold, </author> <title> A Skeleton-Based Parallelising Compiler for ML. </title> <booktitle> In Proceedings of the fifth International Workshop on the Implementation of Functional Languages, Nijmegen, the Netherlands, </booktitle> <pages> pages 23-33, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Many have advocated the use of skeletons in parallel programming environments and in particular, research has focused on functional languages <ref> [1, 3, 4, 8, 9, 14, 17] </ref>. This is mainly because skeletons can be expressed elegantly as higher order functions. <p> So far, we have gained only little experience with skeletons in more common functional languages on more general purpose machines <ref> [3, 4, 14] </ref>. This indicates that an intermediate level of abstraction is desirable. <p> Some experiments on a general purpose machine with distributed memory 1 will make clear that no performance penalty needs to be paid, compared to parallel functional (Concurrent Clean) programs without skeletons [5, 16], and compared to other functional languages that provide skeletons in more restrictive ways <ref> [4, 14] </ref>. With respect to imperative languages like C our results suffer from suboptimal sequential compilation techniques. It is not the use of the skeletons that causes problems. If we manually optimise the code (only a little) Concurrent Clean programs become competitive with C. <p> Recursive versions in C on the other hand, perform worse than Clean, even after some tuning. Compared to SkelML <ref> [4] </ref>, which is strict, the raytracer in Clean is a factor 3.5 faster, although the speedups are comparable (SkelML uses OCCAM as an intermediate language, whereas the Clean system generates transputer assembly directly).
Reference: [5] <author> Torsten Blk, Achim Held, Werner Kluge, Stefan Pantke, Carsten Rathsack, Sven-Bodo Scholz, Raimund Schrder, </author> <title> Preliminary Experience with a p-RED + Implementation on an nCUBE/2 System, </title> <booktitle> In Proceedings of the fifth International Workshop on the Implementation of Functional Languages, Nijmegen, the Netherlands, </booktitle> <pages> pages 101-113, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Power of expression is important, but actual speed is crucial in a parallel system. Some experiments on a general purpose machine with distributed memory 1 will make clear that no performance penalty needs to be paid, compared to parallel functional (Concurrent Clean) programs without skeletons <ref> [5, 16] </ref>, and compared to other functional languages that provide skeletons in more restrictive ways [4, 14]. With respect to imperative languages like C our results suffer from suboptimal sequential compilation techniques. It is not the use of the skeletons that causes problems. <p> The figures presented above are about as good as the ones we have obtained earlier in Concurrent Clean without using data parallel constructs [12], and they compare favourably to the ones presented for pRED + <ref> [5] </ref> and the Data Parallel Functional Language (DPFL) presented in [14]. Both give similar speedups, but have worse abso lute performance (No absolute performance figures have been presented for pRED + , but this is an interpreter).
Reference: [6] <institution> David Cann Retire Fortran? A debate rekindled Communications of the ACM , 1992. </institution>
Reference-contexts: Considering this, it is not surprising that most experiments with some form of skeletons have been produced with a small set of data parallel languages on a limited set of machines that support these languages well <ref> [1, 6] </ref>. So far, we have gained only little experience with skeletons in more common functional languages on more general purpose machines [3, 4, 14]. This indicates that an intermediate level of abstraction is desirable. <p> We will construct skeletons that provide efficient data parallel constructs, skeletons to perform parallel I/O, and finally, skeletons that describe stream processing. 3. Skeletons for Data Parallelism Unlike Sisal <ref> [2, 6] </ref>, Concurrent Clean is not a strict lan - guage dedicated to data parallelism. One of its major shortcomings has been the lack of suitable constructs for this kind of parallel processing.
Reference: [7] <author> Murray Cole, </author> <title> Algorithmic Skeletons: Structured Management of Parallel Computation. </title> <booktitle> Research Monographs in Parallel and Distributed Computing. </booktitle> <address> Pitman/MIT, </address> <year> 1989. </year>
Reference-contexts: However, at this moment no method is known that will automatically derive efficient parallel programs in all cir - cumstances. This means that compilers currently need some form of guidance from the programmer. The concept of skeletons <ref> [7] </ref> forms an interesting idea for structuring this guidance. Skeletons can be seen as predefined templates that are used to control parallel exe - cution of programs.
Reference: [8] <author> Marco Danelutto and Susanna Pelagatti. </author> <title> Parallel Implementation of FP using a Template-based ap - proach. </title> <booktitle> In Proceedings of the Fifth International Workshop on the Implementation of Functional Languages, Nijmegen, the Netherlands, </booktitle> <pages> pages 7-21, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Many have advocated the use of skeletons in parallel programming environments and in particular, research has focused on functional languages <ref> [1, 3, 4, 8, 9, 14, 17] </ref>. This is mainly because skeletons can be expressed elegantly as higher order functions.
Reference: [9] <author> J. Darlington, A.J. Field, P.G. Harrison, P.H.J. Kelly, D.W.N. Sharp, Q. Wu, </author> <title> and R.L. While Parallel Programming Using Skeleton Functions In Parallel Architectures & Languages Europe, </title> <booktitle> PARLE 93, </booktitle> <publisher> pages 146-160 LNCS 694 Springer-Verlag, </publisher> <year> 1993 </year>
Reference-contexts: Many have advocated the use of skeletons in parallel programming environments and in particular, research has focused on functional languages <ref> [1, 3, 4, 8, 9, 14, 17] </ref>. This is mainly because skeletons can be expressed elegantly as higher order functions. <p> In this paper, some examples will illustrate how Concurrent Clean - a lazy, higher order functional lan - guage with a few low level constructs for parallelism [15, 17, 19] - can be used to implement a range of high level skeletons. In contrast to Darlington <ref> [9] </ref>, not only the meaning of each skeleton will be established by its func - tional language definition, but also its behaviour. Thus, we will use a lazy functional programming language with general mechanisms for unstructured parallelism only, to capture structured parallelism.
Reference: [10] <author> W.M. Gentleman, </author> <title> Some Complexity Results for Matrix Computations on Parallel Processors, </title> <journal> Journal of the ACM, </journal> <volume> vol. 25, </volume> <pages> pages 112-115, </pages> <year> 1978. </year>
Reference-contexts: First we will choose the structure of the distributed matrix and define some - rather general data parallel operations on it. Next, we will use these to construct a data parallel matrix multiplication program that is based on Gentlemans algorithm <ref> [10] </ref>. And finally, we will present the execution times of this program, which will make clear that building data parallel skeletons in Clean does not result in a performance penalty. 3.2.
Reference: [11] <author> Jonathan M.D. </author> <title> Hill The AIM is laziness in a data - parallel language In K. Hammond, </title> <editor> and J. T. O'Donnell, editors, </editor> <title> G l a s g o w F u n c t i o n a l Programming workshop, </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: This definition is completely lazy. It is not parallel, which may seem odd. Our aim however, is to provide the kind of data parallel laziness that is proposed by Hill <ref> [11] </ref>. The parallel construct we have defined above is nothing more than a description of what should happen where when it is needed. It is still a bit too eager, because the Ap function embodies a -P- annotation that starts up a new process.
Reference: [12] <author> Marco Kesseler, </author> <title> Reducing Graph Copying Costs - Time to Wrap it Up. </title> <booktitle> The First International Symposium on Parallel Symbolic Computation, PASCO 94, Hagenberg/Linz, Austria, </booktitle> <pages> pages 244-253, </pages> <publisher> World Scientific, </publisher> <year> 1994. </year>
Reference-contexts: Compared to lists, strict arrays can be considerably more efficient when they are to be transmitted to other processors. For instance, using arrays instead of lists can dramatically speed up parallel matrix multiplication, even if one uses a very straightforward algorithm without any data parallel constructs <ref> [12] </ref>. Below, we will demonstrate how an efficient imple - mentation of data parallel matrices can be obtained from the standard matrices in Clean. First we will choose the structure of the distributed matrix and define some - rather general data parallel operations on it. <p> This as sumption is strongly supported by the results we have obtained for the sequential program. The figures presented above are about as good as the ones we have obtained earlier in Concurrent Clean without using data parallel constructs <ref> [12] </ref>, and they compare favourably to the ones presented for pRED + [5] and the Data Parallel Functional Language (DPFL) presented in [14]. Both give similar speedups, but have worse abso lute performance (No absolute performance figures have been presented for pRED + , but this is an interpreter). <p> Examples are well-known programs like queens and the sieve of Erathostenes. Using basic Clean constructs, we have ob - tained good speedups for both in a rather straightforward way, although the sieve required a special buffering func - tion between distinct filter functions <ref> [12] </ref>. These examples are very simple however, and inserting special functions, such as buffers, may be hard sometimes. In these cases, skeletons are invaluable. The parallel mergesort program below is a divide-and-conquer style program that uses streams.
Reference: [13] <author> Marco Kesseler, </author> <title> Uniqueness and Lazy Graph Copying Copyright for the Unique, </title> <booktitle> In proceed - ings of the 6th International Workshop on the Implementation of Functional Languages, </booktitle> <institution> University of East Anglia, Norwich, UK, </institution> <year> 1994. </year>
Reference-contexts: The effect is that only normal forms can travel implicitly between processors, closures are always evaluated before copying and act as copy-stoppers. This Lazy Normal Form Copying <ref> [13] </ref> provides the concept of distributed processes, all re ducing lazily to normal form, although in reality each actual process only reduces to RNF.
Reference: [14] <author> H. Kuchen, R. Plasmeijer, and H. </author> <booktitle> Stoltze Distributed Implementation of a Data Parallel Functional Language In Parallel Architectures & Languages Europe, </booktitle> <pages> PARLE 94 , pages 464-477, </pages> <publisher> LNCS 817, Springer Verlag, </publisher> <year> 1994. </year>
Reference-contexts: Many have advocated the use of skeletons in parallel programming environments and in particular, research has focused on functional languages <ref> [1, 3, 4, 8, 9, 14, 17] </ref>. This is mainly because skeletons can be expressed elegantly as higher order functions. <p> So far, we have gained only little experience with skeletons in more common functional languages on more general purpose machines <ref> [3, 4, 14] </ref>. This indicates that an intermediate level of abstraction is desirable. <p> Some experiments on a general purpose machine with distributed memory 1 will make clear that no performance penalty needs to be paid, compared to parallel functional (Concurrent Clean) programs without skeletons [5, 16], and compared to other functional languages that provide skeletons in more restrictive ways <ref> [4, 14] </ref>. With respect to imperative languages like C our results suffer from suboptimal sequential compilation techniques. It is not the use of the skeletons that causes problems. If we manually optimise the code (only a little) Concurrent Clean programs become competitive with C. <p> The figures presented above are about as good as the ones we have obtained earlier in Concurrent Clean without using data parallel constructs [12], and they compare favourably to the ones presented for pRED + [5] and the Data Parallel Functional Language (DPFL) presented in <ref> [14] </ref>. Both give similar speedups, but have worse abso lute performance (No absolute performance figures have been presented for pRED + , but this is an interpreter). <p> These skeletons may then be parametrised with functions that perform local transformations on the database. Acknowledgements I would like to thank Herbert Kuchen for providing the latest information on DPFL <ref> [14] </ref>.
Reference: [15] <author> Ncker E.G.J.M.H., Smetsers J.E.W., Eekelen M.C.J.D. van, Plasmeijer M.J., </author> <year> (1991). </year> <title> Concurrent Clean, </title> <booktitle> Proceedings of the conference on Parallel Architectures and Languages Europe (PARLE'91). Springer Lecture Notes in Computer Science 505, </booktitle> <volume> Vol. II, </volume> <pages> page 202-219. </pages>
Reference-contexts: This indicates that an intermediate level of abstraction is desirable. In this paper, some examples will illustrate how Concurrent Clean - a lazy, higher order functional lan - guage with a few low level constructs for parallelism <ref> [15, 17, 19] </ref> - can be used to implement a range of high level skeletons. In contrast to Darlington [9], not only the meaning of each skeleton will be established by its func - tional language definition, but also its behaviour.
Reference: [16] <author> Eric Ncker, </author> <title> Efficient Parallel Functional Programming Some Case Studies. </title> <booktitle> In Proceedings of the fifth International Workshop on the Implementation of Functional Languages, Nijmegen, the Netherlands, </booktitle> <pages> pages 51-67, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Power of expression is important, but actual speed is crucial in a parallel system. Some experiments on a general purpose machine with distributed memory 1 will make clear that no performance penalty needs to be paid, compared to parallel functional (Concurrent Clean) programs without skeletons <ref> [5, 16] </ref>, and compared to other functional languages that provide skeletons in more restrictive ways [4, 14]. With respect to imperative languages like C our results suffer from suboptimal sequential compilation techniques. It is not the use of the skeletons that causes problems. <p> The tree of unsorted lists is generated at a single processor. Two versions have been tested. One that uses the standard integer comparison, and one that employs a complex comparison. Compared to earlier ex - periments with special stream functions in Clean <ref> [16] </ref>, the use of buffers gives better performance, while improving memory usage. # processors 1 8 16 32 Standard 20000 15.6 sec 4.6 sec 3.5 sec 3.9 sec Standard 40000 59.8 sec 11.2 sec 8.0 sec 9.1 sec Complex 20000 79.2 sec 19.4 sec 12.2 sec 10.9 sec Complex 40000 196.0
Reference: [17] <author> Plasmeijer M.J., Eekelen M.C.J.D. </author> <title> van (1993). Functional Programming and Parallel Graph Rewriting. </title> <publisher> Addison Wesley, </publisher> <year> 1993. </year>
Reference-contexts: Many have advocated the use of skeletons in parallel programming environments and in particular, research has focused on functional languages <ref> [1, 3, 4, 8, 9, 14, 17] </ref>. This is mainly because skeletons can be expressed elegantly as higher order functions. <p> This indicates that an intermediate level of abstraction is desirable. In this paper, some examples will illustrate how Concurrent Clean - a lazy, higher order functional lan - guage with a few low level constructs for parallelism <ref> [15, 17, 19] </ref> - can be used to implement a range of high level skeletons. In contrast to Darlington [9], not only the meaning of each skeleton will be established by its func - tional language definition, but also its behaviour.
Reference: [18] <author> David B. </author> <title> Skillicorn The Bird-Meertens Formalism as a Parallel Model In NATO ARW Software for Parallel Computation, </title> <year> 1992. </year>
Reference-contexts: Similar concepts form the basis of the idea to use the Bird-Meertens Formalism as a parallel programming model <ref> [18] </ref>. On the other hand, little attention has been paid to the elementary weaknesses of skeletons: first of all, a set of skeletons has to be implemented on every platform and secondly, a given set may not be very suited to solve some problems efficiently or elegantly.
Reference: [19] <author> Smetsers J.E.W., Ncker E.G.J.M.H., Van Groningen J.C., Plasmeijer M.J. </author> <year> (1991). </year> <title> Generating Efficient Code for Lazy Functional Languages. </title> <booktitle> Proceedings of the Fifth International Conference on Functional Programming Languages and Computer Architecture (FPCA91), U.S.A., Springer Lecture Notes on Computer Science. </booktitle>
Reference-contexts: This indicates that an intermediate level of abstraction is desirable. In this paper, some examples will illustrate how Concurrent Clean - a lazy, higher order functional lan - guage with a few low level constructs for parallelism <ref> [15, 17, 19] </ref> - can be used to implement a range of high level skeletons. In contrast to Darlington [9], not only the meaning of each skeleton will be established by its func - tional language definition, but also its behaviour.
Reference: [20] <author> S. Smetsers, E. Barendsen, M. van Eekelen, R. </author> <title> Plasmeijer (1993). Guaranteeing Safe Destructive Updates through a Type System with Uniqueness Information for Graphs. </title> <booktitle> In Graph Transformations in Computer Science. </booktitle> <address> Dagstuhl Castle, Germany, </address> <publisher> Springer LNCS 776, </publisher> <pages> pages 358-379. </pages>
Reference-contexts: have used a different structure, like for instance a quad-tree, or a doubly linked circular list, or several, while using some natural transformation functions to get from one form to the other. 3 In Clean, destructive updates are allowed if derived uniqueness properties indicate that an object is not shared <ref> [20] </ref>. :: PMat :== [[R Matrix]] Map and Fold-like operations are crucial in data parallel programming languages. We will give Clean definitions of each kind below. These functions are polymorphic and operate on double lists of general remote objects. <p> Though messages may pass each other in Clean as well, we do not need such a construct, because the correct order of opera - tions is automatically maintained by data dependencies. In addition, we do not rely on uniqueness properties <ref> [20] </ref> as heavily as DPFL. Instead of requiring each instance of an entire array to be unique, we only need this property temporarily during sequential construction of some remote sub-array. Usually, this requirement will be met by the ar ray-constructing argument functions of the skeletons.
References-found: 20

