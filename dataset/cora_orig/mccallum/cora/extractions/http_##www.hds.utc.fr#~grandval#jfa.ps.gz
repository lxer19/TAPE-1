URL: http://www.hds.utc.fr/~grandval/jfa.ps.gz
Refering-URL: http://www.hds.utc.fr/~grandval/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: boukari@utc.fr grandval@utc.fr  
Title: Penalisation multiple adaptative un nouvel algorithme de regression, la penalisation multiple adapta-tive. Cet algorithme represente
Author: Halim Boukari Yves Grandvalet R esum e. Nous proposons 
Keyword: Mots cl es regression flexible, penalisation, selection de variables, selection de modele, reechantillonnage.  
Address: BP 20.529 60205 COMPIEGNE CEDEX  
Affiliation: Heudiasyc, UMR CNRS 6599, UTC  
Abstract: Chaque parametre du modele est penalise individuellement. Le reglage de ces penalisations se fait automatiquement a partir de la definition d'un hyperparametre de regularisation globale. Cet hyperparametre, qui controle la complexite du regresseur, peut ^etre estime par des techniques de reechantillonnage. Nous montrons experimentalement les performances et la stabilite de la penalisation multiple adaptative dans le cadre de la regression lineaire. Nous avons choisi des problemes pour lesquels le probleme du controle de la complexite est particulierement crucial, comme dans le cadre plus general de l'estimation fonctionnelle. Les comparaisons avec les moindres carres regularises et la selection de variables nous permettent de deduire les conditions d'application de chaque algorithme de penalisation. Lors des simulations, nous testons egalement plusieurs techniques de reechantillonnage. Ces techniques sont utilisees pour selectionner la complexite optimale des estimateurs de la fonction de regression. Nous comparons les pertes occasionnees par chacune d'entre elles lors de la selection de modeles sous-optimaux. Nous regardons egalement si elles permettent de determiner l'estimateur de la fonction de regression minimisant l'erreur en generalisation parmi les differentes methodes de penalisation en competition. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Breiman, L. </author> <title> Bagging predictors. </title> <institution> Rapport interne, Statistics Department, University of Cali-fornia at Berkeley, </institution> <year> 1994. </year>
Reference-contexts: L'estimateur ainsi obtenu serait de variance trop forte. Nous utilisons le cas lineaire pour comparer facilement les differentes methodes et deduire les conditions d'applications de chacune d'elles. Nous avons ainsi repris le Benchmark propose par Breiman <ref> [1] </ref>. Les donnees sont generees a partir d'un modele lineaire perturbe par un bruit additif : y = m=1 avec " ~ N (0; 1). Les entrees sont de dimensions 30 suivent une loi gaussienne de moyenne nulle et de covariance , telle que i;j = jijj . <p> Dans tous les autres cas, le risque associe a la selection de variables est considerablement plus important que pour les autres. Ceci illustre l'instabilite de la selection de variables. Ce defaut peut ^etre corrige en stabilisant la methode par des techniques de combinaison d'estimateurs de type bagging <ref> [1] </ref>. Le risque en prediction de la penalisation adaptative est toujours du m^eme ordre que celui des moindres carres regularises. Nous sommes donc assures de sa stabilite.
Reference: [2] <author> Breiman, L. </author> <title> Heuristics of instability and stabilization in model selection. </title> <journal> The Annals of Statistics, </journal> <volume> 24(6), </volume> <pages> pp. 2350-2383, </pages> <year> 1996. </year>
Reference-contexts: En particulier, il peut montrer des variabilites importantes dans le choix des parametres selectionnes, ce qui peut rendre les interpretations douteuses. C'est ce qui a motive le developpe-ment d'autres methodes de penalisation de parametres, comme : la "garotte" et la "non negative garotte" de Breiman <ref> [2] </ref> ou le "lasso" de Tibshirani [13]. Nous proposons une nouvelle alternative a ces deux methodes, pour eviter d'avoir a choisir entre stabilite et interpretabilite. Nous montrerons experimentalement dans la section 4.2.2 que la methode proposee est stable, et nous illustrerons ses proprietes de selection de variables. <p> La methode proposee consiste a utiliser plusieurs hyperparametres j ; (j = 1; 2 ; d), ou chaque hyperparametre penalise un parametre w j . Cela revient a trouver les parametres w et j 1 Selon Breiman <ref> [2] </ref>, une methode de penalisation est instable si pour deux echantillons peu differents, l'algorithme d'estimation de f donne des resultats tres variables. qui minimisent le co^ut penalise : C 0 d X j w 2 Le co^ut (7) est minimise sur les variables w j et j . <p> Neanmoins, l'augmentation de l'erreur en prediction causee par l'estimation de fl est plus co^uteuse pour la selection de variables. Cette constatation confirme les resultats experimentaux de Breiman <ref> [2] </ref> sur l'instabilite de la selection de variables. Un algorithme d'estimation de w tres sensible a de petites modifications de l'echantillon est dit instable. Pour un algorithme instable, EP est une fonction irreguliere du parametre de controle de la complexite. Il est donc plus difficile d'y reperer le minimum.
Reference: [3] <author> Dempster, A.P. ,Laird, N.M. et Rubin, </author> <title> D.B. Maximum likelihood from incomplete data with the EM algorithm. </title> <journal> Journal of the Royal Statistical Society, B, </journal> <volume> 39(1), </volume> <pages> pp. 1-38, </pages> <year> 1977. </year>
Reference-contexts: La contrainte impose a la variance moyenne des differents parametres d'^etre constante, inversement proportionnelle a . Pour trouver les parametre j et w, il suffit d'utiliser la methode de Lagrange. L'algorithme propose est du type point fixe EM <ref> [3] </ref>. A chaque etape, on estime w avec les parametres des lois a priori j fixe. Les j sont a leur tour estimes a w fixe. Nous donnons dans ce qui suit les differentes etapes de l'algorithme dans le cadre de la regression lineaire : 1.
Reference: [4] <author> Efron, B. et Tibshirani, </author> <title> R.J. An Introduction to the Bootstrap. </title> <journal> Monographs on Statistics and Applied Probability, </journal> <volume> volume 57, </volume> <publisher> Chapman & Hall, </publisher> <year> 1993. </year>
Reference-contexts: de l'erreur en prediction sont : 1. les criteres analytique comme AIC (Akaike Information Criterion), C p de Mallows, BIC (Bayesian Information Criterion) de Schwartz, le selecteur de Shibata, MDL (Minimimum Description Length) de Rissanen (cf. [8]) 2. les techniques de reechantillonnage comme le bootstrap ou la validation croisee (cf. <ref> [4] </ref>). 3.1 Le reechantillonnage Nous utilisons ici les techniques de reechantillonnage, qui ont l'avantage de ne faire d'hypotheses ni sur la fonction de regression, ni sur la forme de bruit. Les criteres analytiques ne sont applicables qu'aux cas ou le modele de la fonction de regression est connu. <p> Pour chaque ensemble s b ` , on calcule l'estimateur b f b qui minimise le co^ut empirique sur s b ` . Il existe plusieurs estimateurs du bootstrap pour estimer l'erreur en prediction : le bootstrap "simple", le bootstrap "sophistique", et le bootstrap .632 <ref> [4] </ref>. Ces deux derniers sont bases sur l'estimation de l'optimisme (biais du co^ut empirique comme estimateur de l'erreur en prediction). Le bootstrap "sophistique" utilise le principe du plug-in. Le bootstrap .632 n'utilise que les couples (x i ; y i ) absents des echantillons du bootstrap.
Reference: [5] <author> Grandvalet, Y. et Canu, S. </author> <title> Adaptive noise injection for input relevance determination. </title> <booktitle> In ICANN'97, Lectures Notes in Computer Science, </booktitle> <pages> pp. 463-468, </pages> <publisher> Springer-Verlag, </publisher> <month> octobre </month> <year> 1997. </year>
Reference-contexts: En utilisant l'heuristique injection de bruit pour le controle de la complexite des perceptrons multi-couches, Grandvalet et Canu <ref> [5] </ref> ont propose un algorithme de penalisation multiple. Cet algorithme a l'avantage de ne necessiter le reglage ad hoc que d'un seul parametre de penalisation. La valeur optimale de ce dernier est estimee en utilisant les techniques de reechantillonnage. Il n'y a donc finalement aucun parametre a regler manuellement. <p> Cet algorithme a l'avantage de ne necessiter le reglage ad hoc que d'un seul parametre de penalisation. La valeur optimale de ce dernier est estimee en utilisant les techniques de reechantillonnage. Il n'y a donc finalement aucun parametre a regler manuellement. L'algorithme propose dans <ref> [5] </ref> est stochastique, et son etude theorique dans le cadre des perceptrons multi-couches est complexe. L'utilisation des reseaux de neurones rend les simulations a grande echelle relativement co^uteuses en temps de calcul. Nous presentons dans ce papier un nouvel algorithme de penalisation adaptative. <p> L'utilisation des reseaux de neurones rend les simulations a grande echelle relativement co^uteuses en temps de calcul. Nous presentons dans ce papier un nouvel algorithme de penalisation adaptative. Il s'agit de la version deterministe de l'algorithme d'injection de bruit pour la determination de variables pertinentes <ref> [5] </ref>. Nous utilisons la regression lineaire pour le tester a grande echelle. Dans la premiere partie de ce papier, nous presentons le principe de la methode, ainsi que le detail de l'algorithme propose. <p> La minimisation du co^ut (7) par rapport a j donne a pour solution j = 0. On a alors C 0 emp = C emp : il n'y a plus d'a priori sur le modele, et donc pas de controle de la complexite. L'idee proposee dans <ref> [5] </ref> evite cette solution triviale. Elle consiste a introduire une contrainte sur les hyperparametres : j=d X 1 = L'origine de cette contrainte est liee a l'interpretation bayesienne du co^ut penalise (7).
Reference: [6] <author> Hinton, G.E. </author> <title> Learning translation invariant recognition in massively parallel networks. </title> <booktitle> In PARLE Conference on Parallel Architectures and Languages Europe, </booktitle> <editor> edite par de Bakker, J.W. Nijman, A.J. </editor> <booktitle> et Treleaven, </booktitle> <pages> pp. 1-13, </pages> <publisher> Springer, </publisher> <year> 1987. </year>
Reference-contexts: Soit w 2 IR d , le vecteur forme des parametres du modele. Les deux approches de penalisation les plus utilisees sont : 1. les moindres carres regularises ("ridge regression" [7] ou "weight decay" <ref> [6] </ref> dans la littera-ture neuronale). La complexite du modele est ici controlee par la norme euclidienne des parametres. Le critere minimise est : C 0 i=d X w 2 2. la selection de parametres, qui penalise le nombre de parametres non nuls.
Reference: [7] <author> Hoerl, A.E. et Kennard, R.W. </author> <title> Ridge regression: Biased estimation for nonorthogonal problems. </title> <journal> Technometrics, </journal> <volume> 12(3), </volume> <pages> pp. 55-67, </pages> <year> 1970. </year>
Reference-contexts: Cette erreur en prediction n'est pas calculable, mais peut ^etre estimee analytiquement ou en utilisant les techniques de reechantillonnage. Soit w 2 IR d , le vecteur forme des parametres du modele. Les deux approches de penalisation les plus utilisees sont : 1. les moindres carres regularises ("ridge regression" <ref> [7] </ref> ou "weight decay" [6] dans la littera-ture neuronale). La complexite du modele est ici controlee par la norme euclidienne des parametres. Le critere minimise est : C 0 i=d X w 2 2. la selection de parametres, qui penalise le nombre de parametres non nuls.
Reference: [8] <author> Kotz, K. et Johnson, </author> <title> N.L. Encyclopedia of Statistical Sciences. </title> <publisher> John Wiley & sons, </publisher> <pages> 1985-1989. </pages>
Reference-contexts: Elle doit donc ^etre estimee. Les deux types de techniques d'estimation de l'erreur en prediction sont : 1. les criteres analytique comme AIC (Akaike Information Criterion), C p de Mallows, BIC (Bayesian Information Criterion) de Schwartz, le selecteur de Shibata, MDL (Minimimum Description Length) de Rissanen (cf. <ref> [8] </ref>) 2. les techniques de reechantillonnage comme le bootstrap ou la validation croisee (cf. [4]). 3.1 Le reechantillonnage Nous utilisons ici les techniques de reechantillonnage, qui ont l'avantage de ne faire d'hypotheses ni sur la fonction de regression, ni sur la forme de bruit.
Reference: [9] <author> Le Cun, Y., Denker, J.S. et Solla, S.A. </author> <title> Optimal brain damage. </title> <booktitle> In Advances in Neural Information Processing Systems, edite par Touretzky, D.S., </booktitle> <pages> pp. 598-605, </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Le critere minimise est : C 0 i=d X w 2 2. la selection de parametres, qui penalise le nombre de parametres non nuls. Cette technique est a la base des techniques d'elagage des reseaux de neurones comme "Optimal Brain Dam age" <ref> [9] </ref>. Le co^ut est : emp (f ) = C emp (f ) + i=1 avec : I (w j ) = 1 si w j 6= 0 (6) L'algorithme des moindres carres regularises est stable 1 , mais il ne permet pas d'annuler les parametres.
Reference: [10] <author> Neal, R. M. </author> <title> Bayesian Learning for Neural Networks. </title> <booktitle> Lecture Notes in Statistics, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: Recemment, divers auteurs se sont inspires des moindres carres regularises pour developper des algorithmes penalisant differemment chaque parametre du modele : "Automatic Relevance Determination" de MacKay et Neal <ref> [10] </ref>, ou la regularisation locale de Orr [11]. En utilisant l'heuristique injection de bruit pour le controle de la complexite des perceptrons multi-couches, Grandvalet et Canu [5] ont propose un algorithme de penalisation multiple.
Reference: [11] <author> Orr, M.J.L. </author> <title> Local smoothing of Radial Basis Function Networks. </title> <booktitle> In International Symposium on Artificial Neural Networks, </booktitle> <address> Hsinchu, Taiwan, </address> <year> 1995. </year>
Reference-contexts: Recemment, divers auteurs se sont inspires des moindres carres regularises pour developper des algorithmes penalisant differemment chaque parametre du modele : "Automatic Relevance Determination" de MacKay et Neal [10], ou la regularisation locale de Orr <ref> [11] </ref>. En utilisant l'heuristique injection de bruit pour le controle de la complexite des perceptrons multi-couches, Grandvalet et Canu [5] ont propose un algorithme de penalisation multiple. Cet algorithme a l'avantage de ne necessiter le reglage ad hoc que d'un seul parametre de penalisation.
Reference: [12] <author> Tibshirani, </author> <title> R.J. A comparison of some error estimates for neural networks models. </title> <journal> Neural Computation, </journal> <volume> 8(1), </volume> <pages> pp. 152-163, </pages> <year> 1996. </year>
Reference-contexts: Les criteres analytiques ne sont applicables qu'aux cas ou le modele de la fonction de regression est connu. Le probleme de regression est dans ce cas assimilable a un probleme d'estimation de parametres. Une etude de Tibshirani <ref> [12] </ref> montre la superiorite des techniques de reechantillonnage pour fournir des estimateurs precis de l'erreur en prediction pour les reseaux de neurones. Ces techniques sont basees sur le principe de divisions multiples de l'echantillon en un ensemble d'apprentissage et un ensemble de validation. Chacune des divisions, reclame un nouvel apprentissage.
Reference: [13] <author> Tibshirani, </author> <title> R.J. Regression shrinkage and selection via the lasso. </title> <institution> Rapport interne, Department of Statistics and Divison of Biostatistics Stanford University, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: C'est ce qui a motive le developpe-ment d'autres methodes de penalisation de parametres, comme : la "garotte" et la "non negative garotte" de Breiman [2] ou le "lasso" de Tibshirani <ref> [13] </ref>. Nous proposons une nouvelle alternative a ces deux methodes, pour eviter d'avoir a choisir entre stabilite et interpretabilite. Nous montrerons experimentalement dans la section 4.2.2 que la methode proposee est stable, et nous illustrerons ses proprietes de selection de variables.
References-found: 13

