URL: http://www.csc.ncsu.edu/faculty/mpsingh/papers/mas/cogsci-91.ps
Refering-URL: http://www.csc.ncsu.edu/faculty/mpsingh/papers/mas/
Root-URL: http://www.csc.ncsu.edu
Title: Intentions, Commitments and Rationality  
Author: Munindar P. Singh 
Address: Austin, TX 78712 USA  
Affiliation: Center for Cognitive Science and Dept of Computer Sciences University of Texas  
Date: 1991  
Note: In Proceedings of the Annual Conference of the Cognitive Science Society (CogSci),  
Abstract: Intentions are an important concept in Cognitive Science and Artificial Intelligence (AI). Perhaps the salient property of (future-directed) intentions is that the agents who have them are committed to them. If intentions are to be seriously used in Cognitive Science and AI, a rigorous theory of commitment must be developed that relates it to the rationality of limited agents. Unfortunately, the available theory (i.e., the one of Cohen & Levesque) defines commitment in such a manner that the only way in which it can be justified reduces it to vacuity. I present an alternative model in which commitment can be defined so as to have more of the intuitive properties we expect, and be closely connected to agent rationality. This definition is intuitively obvious, does not reduce to vacuity, and has useful consequences, e.g., that a rational agent ought not to be more committed to his means than to his ends. 
Abstract-found: 1
Intro-found: 1
Reference: [ Brand, 1984 ] <author> Myles Brand. </author> <title> Intending and Acting. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1984. </year>
Reference-contexts: The modern philosophical view is that intentions cannot be reduced to desires and beliefs (e.g., see <ref> [ Brand, 1984, pp. 121-125 ] </ref> , [ Bratman, 1987, pp. 18-23 ] and [ Harman, 1986, pp. 78-79 ] ). Intentions are most often seen as being mutually consistent, compatible with beliefs, and direct or immediate causes of action (e.g., [ Brand, 1984, p. 46 ] ). <p> Intentions are most often seen as being mutually consistent, compatible with beliefs, and direct or immediate causes of action (e.g., <ref> [ Brand, 1984, p. 46 ] </ref> ). This is a useful property for the purposes of this paper, since it helps relate intentions to rationality via actions. Intentions come in at least two shades: present-directed ones and future-directed ones. It is the latter that will interest us here.
Reference: [ Bratman, 1987 ] <author> Michael E. Bratman. </author> <title> Intention, Plans, and Practical Reason. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: The modern philosophical view is that intentions cannot be reduced to desires and beliefs (e.g., see [ Brand, 1984, pp. 121-125 ] , <ref> [ Bratman, 1987, pp. 18-23 ] </ref> and [ Harman, 1986, pp. 78-79 ] ). Intentions are most often seen as being mutually consistent, compatible with beliefs, and direct or immediate causes of action (e.g., [ Brand, 1984, p. 46 ] ). <p> It is the latter that will interest us here. Perhaps the salient property of future-directed intentions is that they involve commitment on the part of agents. This view has been gaining ground in the philosophical and AI literatures recently (e.g., see <ref> [ Bratman, 1987, ch. 2 ] </ref> , [ Harman, 1986, p. 94 ] and [ Cohen and Levesque, 1990, p. 217 ] ).
Reference: [ Cohen and Levesque, 1990 ] <author> Philip R. Cohen and Hector J. Levesque. </author> <title> Intention is choice with commitment. </title> <journal> Artificial Intelligence, </journal> <volume> 42 </volume> <pages> 213-261, </pages> <year> 1990. </year>
Reference-contexts: Perhaps the salient property of future-directed intentions is that they involve commitment on the part of agents. This view has been gaining ground in the philosophical and AI literatures recently (e.g., see [ Bratman, 1987, ch. 2 ] , [ Harman, 1986, p. 94 ] and <ref> [ Cohen and Levesque, 1990, p. 217 ] </ref> ).
Reference: [ Emerson, 1990 ] <author> E. A. Emerson. </author> <title> Temporal and modal logic. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume B. </booktitle> <publisher> North-Holland Publishing Company, </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1990. </year>
Reference-contexts: Note that agents can have beliefs, and even intentions, that involve objective probability and utility statements. 5 The Formal Language The formal language of this paper, L, is CTL* (a propositional branching time logic <ref> [ Emerson, 1990 ] </ref> ) augmented with quantification over basic actions; functions: Prob, Utility, Cost; and predicates: Believes, Commits, Intends, Acts-for and Performs; and the arithmetic required. Let x be an agent; p, q propositions; a an action; and v a probability. <p> The satisfaction conditions for the temporal operators too are adapted from those in <ref> [ Emerson, 1990 ] </ref> . Formally, we have the following definitions: 1. M j= w;t iff hw; ti 2 [[ ]] 3. M j= w;t :p iff M 6j= w;t p 5. M j= w;t Ap iff (8S : S 2 S w;t ! M j= S;t p) 6. <p> A stronger formulation would require that an agent did not hold an intention infinitely without acting for it, but there is no space to include such "fairness" conditions here <ref> [ Emerson, 1990 ] </ref> . 1. A [Intends (x; p)! FDeliberates (x) _ F (9a : Acts-for (x; a; p))] Another constraint that we need is the following which essentially "uses up" a part of the commitment to an intention.
Reference: [ Harman, 1986 ] <author> Gilbert Harman. </author> <title> Change in View. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: The modern philosophical view is that intentions cannot be reduced to desires and beliefs (e.g., see [ Brand, 1984, pp. 121-125 ] , [ Bratman, 1987, pp. 18-23 ] and <ref> [ Harman, 1986, pp. 78-79 ] </ref> ). Intentions are most often seen as being mutually consistent, compatible with beliefs, and direct or immediate causes of action (e.g., [ Brand, 1984, p. 46 ] ). <p> It is the latter that will interest us here. Perhaps the salient property of future-directed intentions is that they involve commitment on the part of agents. This view has been gaining ground in the philosophical and AI literatures recently (e.g., see [ Bratman, 1987, ch. 2 ] , <ref> [ Harman, 1986, p. 94 ] </ref> and [ Cohen and Levesque, 1990, p. 217 ] ).
Reference: [ McDermott, 1982 ] <author> Drew McDermott. </author> <title> A temporal logic for reasoning about processes and plans. </title> <journal> Cognitive Science, </journal> <volume> 6(2) </volume> <pages> 101-155, </pages> <year> 1982. </year>
Reference: [ Singh and Asher, 1990 ] <author> Munindar P. Singh and Nicholas M. Asher. </author> <title> Towards a formal theory of intentions. </title> <booktitle> In European Workshop on Logics in Artificial Intelligence, </booktitle> <month> September </month> <year> 1990. </year>
Reference-contexts: This model is quite abstract, is derived from models for branching time temporal logic, has previously been developed, and has been applied to the formalization of intentions and know-how <ref> [ Singh, 1990, Singh, 1991, Singh and Asher, 1990 ] </ref> . 3 The Model, Intuitively For concepts such as intention, commitment and expected utility to even be formalized, we need a formal model that includes not just time and action, but also possibility, probability and choice.
Reference: [ Singh, 1990 ] <author> Munindar P. Singh. </author> <title> Group intentions. </title> <booktitle> In 10th Workshop on Distributed Artificial Intelligence, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: This model is quite abstract, is derived from models for branching time temporal logic, has previously been developed, and has been applied to the formalization of intentions and know-how <ref> [ Singh, 1990, Singh, 1991, Singh and Asher, 1990 ] </ref> . 3 The Model, Intuitively For concepts such as intention, commitment and expected utility to even be formalized, we need a formal model that includes not just time and action, but also possibility, probability and choice.
Reference: [ Singh, 1991 ] <author> Munindar P. Singh. </author> <title> A logic of situated know-how. </title> <booktitle> In National Conference on Artificial Intelligence (AAAI), </booktitle> <month> July </month> <year> 1991. </year>
Reference-contexts: This model is quite abstract, is derived from models for branching time temporal logic, has previously been developed, and has been applied to the formalization of intentions and know-how <ref> [ Singh, 1990, Singh, 1991, Singh and Asher, 1990 ] </ref> . 3 The Model, Intuitively For concepts such as intention, commitment and expected utility to even be formalized, we need a formal model that includes not just time and action, but also possibility, probability and choice. <p> Scenarios as described in x5 can be defined easily from &lt; <ref> [ Singh, 1991 ] </ref> ; S w;t is the class of all scenarios at world w and time t: (w 6= w 0 _ t 6= t 0 )) S w;t " S w 0 ;t 0 = ;. hS; t; t 0 i is a subscenario of S from t
References-found: 9

