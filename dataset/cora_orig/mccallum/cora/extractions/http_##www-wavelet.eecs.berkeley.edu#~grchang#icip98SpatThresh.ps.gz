URL: http://www-wavelet.eecs.berkeley.edu/~grchang/icip98SpatThresh.ps.gz
Refering-URL: http://www-wavelet.eecs.berkeley.edu/~grchang/publications.html
Root-URL: 
Email: grchang@eecs.berkeley.edu, binyu@stat.berkeley.edu, vetterli@de.epfl.ch  
Phone: 2  3  
Title: SPATIALLY ADAPTIVE WAVELET THRESHOLDING WITH CONTEXT MODELING FOR IMAGE DENOISING  
Author: S. Grace Chang Bin Yu Martin Vetterli ; 
Address: Berkeley, CA 94720, USA  Berkeley, CA 94720, USA  CH-1015 Lausanne, Switzerland  
Affiliation: 1 Department of Electrical Engineering and Computer Sciences University of California,  Department of Statistics University of California,  Departement d'Electricite Ecole Polytechnique Federale de Lausanne,  
Abstract: The method of wavelet thresholding for removing noise, or denoising, has been researched extensively due to its effectiveness and simplicity. Much of the work has been concentrated on finding the best uniform threshold or best basis. However, not much has been done to make this method adaptive to spatially changing statistics which is typical of a large class of images. This work proposes a spatially adaptive wavelet thresholding method based on context modeling, a common technique used in image compression to adapt the coder to the non-stationarity of images. We model each coefficient as a random variable with the Generalized Gaussian prior with unknown parameters. Context modeling is used to estimate the parameters for each coefficient, which are then used to adapt the thresholding strategy. Experimental results show that spatially adaptive wavelet thresholding yields significantly superior image quality and lower MSE than optimal uniform thresholding. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S.G. Chang, B. Yu, and M. Vetterli, </author> <title> "Image Denoising via Lossy Compression and Wavelet Thresholding," </title> <booktitle> Proc. IEEE Int. Conf. Image Processing, Vol.1, </booktitle> <pages> pp. 604-607, </pages> <month> Oct. </month> <year> 1997. </year>
Reference-contexts: Thus, context-modeling allows us to model each coefficient as a Generalized Gaussian random variable with varying parameters. Now, given that we can estimate the parameters for each coefficient, the next step is to use them to calculate the threshold. In <ref> [1] </ref>, we found that when the signal coefficients are modeled as Generalized To appear in Proc. IEEE Int. Conf. Image Processing, 1998 1 White pixels indicate large magnitude coefficients, and black signifies small magnitude. <p> In <ref> [1] </ref>, we found that T fl can be well approximated by ~ T = 2 = x , where x is the standard deviation of X.
Reference: [2] <author> R.R. Coifman and D.L. Donoho, "Translationinvariant de-noising," </author> <title> Wavelets and Statistics, </title> <editor> A. Antoniadis and G. Oppenheim eds., </editor> <publisher> Springer-Verlag Lecture Notes, </publisher> <year> 1995. </year>
Reference-contexts: Very little has been done on developing thresholds that are adaptive to different spatial characteristics. Other works investigate the choice of wavelet coefficient expansion for the thresholding framework. One particularly interesting result is that thresholding in a shift-invariant expansion (dubbed translation-invariant (TI) denoising by Coifman and Donoho <ref> [2] </ref>) eliminates some of the unpleasant artifacts introduced by modifying the coefficients of the orthogonal wavelet expansion. <p> Thresholding in Overcomplete Expansion Thresholding in the orthogonal wavelet domain produces significantly noticeable artifacts such as Gibbs-like ringing and blips. To ameliorate this unpleasant phenomenon, Coifman and Donoho <ref> [2] </ref> proposed the translation-invariant (TI) denoising. Let Shift k;` [] denote the operation of circularly shifting the input by k indices in the vertical direction and ` indices in the horizontal, and let Unshift k;` [] be a similar operation but in the opposite direction.
Reference: [3] <author> D.L. Donoho and I.M. Johnstone, </author> <title> "Ideal spatial adap-tation via wavelet shrinkage," </title> <journal> Biometrika, </journal> <volume> vol 81, </volume> <pages> pp. 425-455, </pages> <year> 1994. </year>
Reference-contexts: 1. INTRODUCTION In this paper we address the classical problem of removing additive noise from a corrupted image, or denoising. In recent years there has been a plethora of work on using wavelet thresholding <ref> [3] </ref> for denoising, in both the signal processing and statistics community, due to its effectiveness and simplicity. <p> If this is not the case, we estimate it by using the robust median estimator in the highest subband of the wavelet transform, ^ = Median (jY [i; j]j)=:6745 ; Y [i; j] 2 subband HH 1 , also used in <ref> [3] </ref>. 2.3. Thresholding in Overcomplete Expansion Thresholding in the orthogonal wavelet domain produces significantly noticeable artifacts such as Gibbs-like ringing and blips. To ameliorate this unpleasant phenomenon, Coifman and Donoho [2] proposed the translation-invariant (TI) denoising.
Reference: [4] <author> S. LoPresto, K. Ramchandran, and M. Orchard, </author> <title> "Image coding based on mixture modeling of wavelet coef-ficients and a fast estimation-quantization framework," </title> <booktitle> Proc. Data Compression Conference, </booktitle> <address> Snowbird, Utah, </address> <month> March </month> <year> 1997. </year>
Reference-contexts: One may ask why the local variance is not estimated from, say, a local window, but rather from an indirect way of grouping the coefficients first via its context. Estimating from a local neighborhood is simple, and, as demonstrated by the good performance of the image coder in <ref> [4] </ref>, it yields an estimate good enough for adapting the coder. However, our experience with noisy images show that such an estimate yields considerably more unreliable variance estimates and also blotchy denoised image.
Reference: [5] <author> S. Mallat, </author> <title> "A theory for multiresolution signal de-composition: The wavelet representation," </title> <journal> IEEE Pat. Anal. Mach. Intell., vol.11, no.7, </journal> <volume> pp.674-693, </volume> <month> July </month> <year> 1989. </year>
Reference-contexts: To accomplish wavelet thresholding for denoising, the observations fy [i; j]g are first transformed into the wavelet domain. The necessary notations for the wavelet transform will be introduced here, and the readers are referred to references such as <ref> [5, 6] </ref> for more details. The 2D discrete orthogonal wavelet transform (DWT) can be implemented as a critically sampled octave-band filter bank, where separable filtering is used.
Reference: [6] <author> M. Vetterli and J. Kovacevic, </author> <title> Wavelets and Subband Coding, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1995. </year>
Reference-contexts: To accomplish wavelet thresholding for denoising, the observations fy [i; j]g are first transformed into the wavelet domain. The necessary notations for the wavelet transform will be introduced here, and the readers are referred to references such as <ref> [5, 6] </ref> for more details. The 2D discrete orthogonal wavelet transform (DWT) can be implemented as a critically sampled octave-band filter bank, where separable filtering is used. <p> Thus we proceed to extend our spatial adaptive algorithm to this redundant expansion. The adaptive algorithm in the orthogonal basis described above can easily be extended to the overcomplete basis. Now consider the same orthogonal filters but used in a filter bank without downsampler (see <ref> [6] </ref> for more detail on non-subsampled filter banks). The filters are renormalized Table 1. Comparing the MSE of the spatially adaptive algorithm with optimal subband uniform threshold in the DWT and overcomplete expansion for various test images and .
Reference: [7] <author> P.H. Westerink, J. Biemond, and D.E. Boekee, </author> <title> "An optimal bit allocation algorithm for sub-band coding", </title> <booktitle> Proc. Int. Conf. on Acous., Speech and Signal Process., </booktitle> <address> Dallas, Texas, </address> <pages> pp. 1378-1381, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: It has long been accepted in the subband coding community that for a large class of images, the coefficients in each subband form a distribution well described by the Gen- eralized Gaussian prior <ref> [7] </ref>. The classification-based compression method in [8] found that these coefficients can be further clustered into several subgroups, each described by this distribution but of different parameters. The clustering of the coefficients is based on context-modeling, a popular method used in compression for differentiating pixels of varied characteristics. <p> It has been observed that for a large class of images, the coefficients from each subband (except LL) form a symmetric distribution that is sharply peaked at zero, well described by the Generalized Gaussian distribu <p>- tion <ref> [7] </ref>, GG ff;fi (x) = C (ff; fi) e (ffjxj) fi , where C (ff; fi) = fffi 2 ( 1 R 1 0 e u u t1 du is the gamma function.
Reference: [8] <author> Y. Yoo, A. Ortega, and B. Yu, </author> <title> "Image Subband Coding using Progressive Classification and Adaptive Quantization" preprint, 1997. = 25. From left to right, top to bottom: original, noisy observation, adaptive threshold-ing in DWT basis (AdaptDWT), uniform threshold-ing in DWT basis (OrcUnifDWT), spatial thresh-olding in overcomplete expansion (AdaptNS), and uniform thresholding in overcomplete expan-sion (OrcUnifNS). </title> <note> This figure can also be found at http://www-wavelet.eecs.berkeley.edu/~grchang/ icip98SpatialDenoise.pgm . 5 </note>
Reference-contexts: It has long been accepted in the subband coding community that for a large class of images, the coefficients in each subband form a distribution well described by the Gen- eralized Gaussian prior [7]. The classification-based compression method in <ref> [8] </ref> found that these coefficients can be further clustered into several subgroups, each described by this distribution but of different parameters. The clustering of the coefficients is based on context-modeling, a popular method used in compression for differentiating pixels of varied characteristics. <p> To do this, we adopt the context modeling idea used frequently in image compression for adapting the coder to changing image characteristics. That is, the statistical model for a given coefficient is conditioned on a function of its neighbors. In the wavelet-based compression scheme in <ref> [8] </ref>, context modeling was used to further categorize coefficients into several classes of varied activity levels within each subband, that is, classes of Generalized Gaussian distribution with different parameters ff; fi. The distribution parameters are estimated from the coefficients for each class, which are then used to adapt the coder. <p> The distribution parameters are estimated from the coefficients for each class, which are then used to adapt the coder. Since the description of each class and the distribution parameters needs to be sent as overhead, only four classes were used in <ref> [8] </ref>. For the denoising problem, there is no need to conserve bits, thus it is not necessary to explicitly classify the pixels, and parameters can be estimated for each coefficient (rather than for each class), resulting in virtually an infinite mixture of distributions. <p> Note that this is a moving window rather than the fixed classes in <ref> [8] </ref>, and thus allows a continuous range of estimate values. Let B i 0 j 0 denote the set of points fY [i; j]g whose context falls in the moving window.
References-found: 8

