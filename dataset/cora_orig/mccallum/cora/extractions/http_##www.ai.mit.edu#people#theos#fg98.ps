URL: http://www.ai.mit.edu/people/theos/fg98.ps
Refering-URL: http://www.ai.mit.edu/people/theos/theos.html
Root-URL: 
Email: theos@ai.mit.edu  poggio@ai.mit.edu  
Title: Robust Image-Based View Synthesis using the Trilinear Tensor  
Author: Theodoros Evgeniou Tomaso Poggio 
Address: Cambridge, MA 02139, USA  Cambridge, MA 02139, USA  
Affiliation: Center for Biological and and Computational Learning MIT  Center for Biological and Computational Learning MIT  
Abstract: We present a new method for image-based reprojection. The method uses the trilinear tensor relating three views of a scene to predict a new virtual image from two real example ones. We report that using the trilinear tensor for a simple method such as the one we developed leads to a robust reprojection system. Using the core of our method we perform tests about the relation between errors in internal and external parameters of the camera and reprojection error. Finally we develop a new camera calibration method. The system can be used for fast reprojection as well as for analysis by synthesis. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Avidan and A. Shashua. </author> <title> Novel view synthesis in tensor space. </title> <type> CIS Technical Report 9602, </type> <institution> Technion University, Israel, </institution> <month> January </month> <year> 1996. </year>
Reference-contexts: Those methods, however, don't take advantage of known algebraic constraints that bind views of the same scene from different positions, therefore they fail to generate physically correct virtual views of the scene. On the other hand, a number of algebraic methods have been developed by various groups ([13], [14], <ref> [1] </ref>, [2]). These methods are based on known algebraic constraints that two or more images of the same object must satisfy. The re-projection method for rigid motion that we develop in this paper belongs in this last category and is similar in spirit to that in [1] and [2]. <p> various groups ([13], [14], <ref> [1] </ref>, [2]). These methods are based on known algebraic constraints that two or more images of the same object must satisfy. The re-projection method for rigid motion that we develop in this paper belongs in this last category and is similar in spirit to that in [1] and [2]. In general the contributions of this paper are: 1. The development of a new simple reprojection method based on the trilinear tensor that binds three images of the same scene, which can also be simply used for analysis by synthesis. 2. <p> Alternatively, another possibility that avoids the typically expensive analysis by synthesis approach would be to first estimate the trilinear tensor between the new image and the two example ones (robust methods for tensor estimation are presented, for example, in <ref> [1] </ref>) and then estimate the pose parameters from this tensor (see again [1] for the relation between tensors and pose parameters). <p> another possibility that avoids the typically expensive analysis by synthesis approach would be to first estimate the trilinear tensor between the new image and the two example ones (robust methods for tensor estimation are presented, for example, in <ref> [1] </ref>) and then estimate the pose parameters from this tensor (see again [1] for the relation between tensors and pose parameters). Although we have not conducted any experiments for analysis of images we believe that given the robustness of the synthesis system its use for analysis can be easy and robust. 7.
Reference: [2] <author> S. Avidan,T. Evgeniou, A. Shashua and T. </author> <booktitle> Poggio Image-Based View Synthesis by Combining Trilinear Tensors and Learning Techniques In VRST '97, </booktitle> <pages> pages 103-110, </pages> <address> Lausanne, Switzetland, </address> <month> September </month> <year> 1997 </year>
Reference-contexts: On the other hand, a number of algebraic methods have been developed by various groups ([13], [14], [1], <ref> [2] </ref>). These methods are based on known algebraic constraints that two or more images of the same object must satisfy. The re-projection method for rigid motion that we develop in this paper belongs in this last category and is similar in spirit to that in [1] and [2]. <p> ([13], [14], [1], <ref> [2] </ref>). These methods are based on known algebraic constraints that two or more images of the same object must satisfy. The re-projection method for rigid motion that we develop in this paper belongs in this last category and is similar in spirit to that in [1] and [2]. In general the contributions of this paper are: 1. The development of a new simple reprojection method based on the trilinear tensor that binds three images of the same scene, which can also be simply used for analysis by synthesis. 2.
Reference: [3] <author> J.R. Bergen and R. Hingorani. </author> <title> Hierarchical motion-based frame rate conversion. </title> <type> Technical report, </type> <institution> David Sarnoff Research Center, Princeton, </institution> <address> New Jersey, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: There are many ways to obtain such a dense, pixel-wise correspondence between the example images. We utilized optical flow algorithms borrowed from the computer vision literature. Specifically, we used the optical flow algorithms developed by Bergen and Hingorani <ref> [3] </ref>. For details the reader can refer to that source. Finally we handle occlusions like in [20]. We estimate the position of the epipole using again the camera matrices directly.
Reference: [4] <author> D. Beymer, A. Shashua, and T. Poggio. </author> <title> Example based image analysis and synthesis. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1431, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1993. </year>
Reference: [5] <author> Shenchang Eric Chen. </author> <title> Quicktime vr an image-based approach to virtual environment navigation. </title> <booktitle> In SIG-GRAPH '95 Proceedings, </booktitle> <pages> pages 29-37, </pages> <address> Los Angeles, CA, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: Moreover, the computation required for rendering using these systems is independent of the complexity of the scene and can be done efficiently for real-time use <ref> [5] </ref>. Various image-based scene reprojection methods have been proposed in the past. Past work can be generally divided in two major groups. On the one hand we have methods that are based on interpolation techniques ([4], [15], [5], [20], [17]). <p> the complexity of the scene and can be done efficiently for real-time use <ref> [5] </ref>. Various image-based scene reprojection methods have been proposed in the past. Past work can be generally divided in two major groups. On the one hand we have methods that are based on interpolation techniques ([4], [15], [5], [20], [17]). Those methods, however, don't take advantage of known algebraic constraints that bind views of the same scene from different positions, therefore they fail to generate physically correct virtual views of the scene.
Reference: [6] <author> Shenchang Eric Chen and Lance Williams. </author> <title> View interpolation for image synthesis. </title> <booktitle> In SIGGRAPH '93 Proceedings, </booktitle> <pages> pages 279-288, </pages> <address> Anaheim, CA, </address> <month> August </month> <year> 1993. </year>
Reference: [7] <author> T. Ezzat. </author> <title> Example-Based Analysis and Synthesis for Images of Human Faces. </title> <type> Master Thesis, </type> <institution> Mas-sachusetts Institute of Technology, </institution> <month> February </month> <year> 1996. </year>
Reference-contexts: One straight forward possibility for pose estimation given a new image would be to iteratively find the pose parameters that best synthesize the new image from the example ones (analysis by synthesis see for example <ref> [7] </ref>).
Reference: [8] <author> O. Faugeras. </author> <title> Three-dimensional computer vision: a geometric viewpoint. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: The development of a new camera calibration method. 2. Mathematical Background The camera model we use is that of a pinhole camera <ref> [8] </ref>. Object points are represented with capital letters, such as O, and image points as bold lower case letters, such as o. <p> For more information on the derivation of this matrix the reader can refer to <ref> [8] </ref>. The product P = M K is called the camera matrix. Estimating the internal parameters of the camera is called calibration of the camera. Various methods for camera calibration have been developed ([9], [19]). We propose a new one below. 3.
Reference: [9] <author> O. Faugeras, Q.-T. Luong and S.J. Maynank. </author> <title> Camera self-calibration: theory and experiments. </title> <booktitle> Proceedings European Conference on Computer Vision, </booktitle> <pages> pages 321-334, </pages> <address> Santa-Margerita, Italy, </address> <year> 1992. </year>
Reference: [10] <author> O. Faugeras and B. Mourrain. </author> <title> On the geometry and algebra of the point and line correspondences between N images. </title> <booktitle> Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 951-956, </pages> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: If we know the parameters of these relations (trilinear tensor) and the projections of the point on the two real images, we are able to find the projection of the point on any third virtual image. Different ways of getting the trilinear relations relations are described in <ref> [10] </ref>, [18] and [12]. For computational purposes we use the trilinear relations as derived in [10]. For convenience we show here two of those equations. <p> Different ways of getting the trilinear relations relations are described in <ref> [10] </ref>, [18] and [12]. For computational purposes we use the trilinear relations as derived in [10]. For convenience we show here two of those equations. Let the rows of P i be P1, P2, P3, the rows of P j be P4, P5, P6, and the rows of the new matrix P new = P 0 K be P7, P8, P9. <p> Specifically, we used the optical flow algorithms developed by Bergen and Hingorani [3]. For details the reader can refer to that source. Finally we handle occlusions like in [20]. We estimate the position of the epipole using again the camera matrices directly. By <ref> [10] </ref>, the location of the epipole in example one should be (in terms of the camera matrices as described in the previous section): epipole 1new = ([P 1P 7P 8P 9]; [P 2P 7P 8P 9]; [P 3P 7P 8P 9]) (6) where the notation is the same as in the
Reference: [11] <author> O. Faugeras and L. Robert. </author> <title> What can two images tell us about a third one? Proceedings of the Euro-pean Conference on Computer Vision, </title> <address> pages 485-492, Stockholm, Sweden, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Generally speaking, changes in these two sets of parameters have the following effects: 1. Small change of the internal parameters do not have significant visual effects. It is known that changes to internal parameters produce only projective transformations of the image <ref> [11] </ref>. We claim that if the changes are small these transformations are not important in terms of the quality of the reprojected image. This is better shown in Fig. 1 (due to space limimations we show all figures at the end of the paper). 2.
Reference: [12] <author> R. </author> <title> Hartley. Lines and points in three views a unified approach. </title> <booktitle> Proc. Image Understanding Workshop, </booktitle> <address> Monterey, California, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Different ways of getting the trilinear relations relations are described in [10], [18] and <ref> [12] </ref>. For computational purposes we use the trilinear relations as derived in [10]. For convenience we show here two of those equations.
Reference: [13] <author> S. Laveau and O. Faugeras. </author> <title> 3-d scene representation as a collection of images and fundamental matrices. </title> <type> Technical Report Technical Report No. 2205, </type> <institution> INRIA, </institution> <year> 1994. </year>
Reference: [14] <author> Leonard McMillan and Gary Bishop. </author> <title> Plenoptic modeling: An image-based rendering system. </title> <booktitle> In SIGGRAPH '95 Proceedings, </booktitle> <address> Los Angeles, CA, </address> <year> 1995. </year>
Reference-contexts: Those methods, however, don't take advantage of known algebraic constraints that bind views of the same scene from different positions, therefore they fail to generate physically correct virtual views of the scene. On the other hand, a number of algebraic methods have been developed by various groups ([13], <ref> [14] </ref>, [1], [2]). These methods are based on known algebraic constraints that two or more images of the same object must satisfy. The re-projection method for rigid motion that we develop in this paper belongs in this last category and is similar in spirit to that in [1] and [2].
Reference: [15] <author> Tomaso Poggio and Roberto Brunelli. </author> <title> A novel approach to graphics. </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1354, </pages> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology, </institution> <year> 1992. </year>
Reference-contexts: Various image-based scene reprojection methods have been proposed in the past. Past work can be generally divided in two major groups. On the one hand we have methods that are based on interpolation techniques ([4], <ref> [15] </ref>, [5], [20], [17]). Those methods, however, don't take advantage of known algebraic constraints that bind views of the same scene from different positions, therefore they fail to generate physically correct virtual views of the scene.
Reference: [16] <author> W.H. Press, B.P. Flannery, S.A. Teukolski and W.T. Vetterling. </author> <title> Numerical recipes in C. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, Massachusetts, pp.309-317, </address> <year> 1988. </year>
Reference-contexts: We do this for all pixels in the middle third of I 0 and we sum the distances. The minimization is done using Powells' multivariable minimization method <ref> [16] </ref>. The initial guess is typically that the focal length is about the length of the diagonal of the image plane, and the center of projection is at the center of the image. Starting from such an estimate we typically reach a solution after 16 iterations.
Reference: [17] <author> Steven M. Seitz and Charles R. Dyers. </author> <title> Physically-valid view synthesis by image interpolation. </title> <booktitle> IEEE Workshop on Representation of Visual Scenes, </booktitle> <address> Boston, USA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Various image-based scene reprojection methods have been proposed in the past. Past work can be generally divided in two major groups. On the one hand we have methods that are based on interpolation techniques ([4], [15], [5], [20], <ref> [17] </ref>). Those methods, however, don't take advantage of known algebraic constraints that bind views of the same scene from different positions, therefore they fail to generate physically correct virtual views of the scene.
Reference: [18] <author> A. Shashua. </author> <title> Algebraic functions for recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17(8) </volume> <pages> 779-789, </pages> <year> 1995. </year>
Reference-contexts: Having a pair of real images I i , I j , we can get the new image coordinates of a point appearing in both real views using the trilinear constraints described in <ref> [18] </ref>. If we know the parameters of these relations (trilinear tensor) and the projections of the point on the two real images, we are able to find the projection of the point on any third virtual image. Different ways of getting the trilinear relations relations are described in [10], [18] and <p> in <ref> [18] </ref>. If we know the parameters of these relations (trilinear tensor) and the projections of the point on the two real images, we are able to find the projection of the point on any third virtual image. Different ways of getting the trilinear relations relations are described in [10], [18] and [12]. For computational purposes we use the trilinear relations as derived in [10]. For convenience we show here two of those equations.
Reference: [19] <author> G. Stein. </author> <title> Accurate Internal Camera Calibration using Rotation, with Analysis of Sources of Error. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: For more information on the derivation of this matrix the reader can refer to [8]. The product P = M K is called the camera matrix. Estimating the internal parameters of the camera is called calibration of the camera. Various methods for camera calibration have been developed ([9], <ref> [19] </ref>). We propose a new one below. 3. Reprojection using the Trilinear Tensor We are interested in generating new views of an object given a set of real images.

References-found: 19

