URL: http://www.math.macalester.edu/~fox/archive/iccbr-95.ps
Refering-URL: http://www.math.macalester.edu/~fox/archive/papers.html
Root-URL: 
Title: Learning to Refine Indexing by Introspective Reasoning  
Author: Susan Fox and David B. Leake 
Address: Bloomington, IN 47405, USA  
Affiliation: Computer Science Department Indiana University  
Abstract: A significant problem for case-based reasoning (CBR) systems is determining the features to use in judging case similarity for retrieval. We describe research that addresses the feature selection problem by using introspective reasoning to learn new features for indexing. Our method augments the CBR system with an introspective reasoning component which monitors system performance to detect poor retrievals, identifies features which would lead retrieval of more adaptable cases, and refines the indexing criteria to include the needed features to avoid future failures. We explore the benefit of introspective reasoning by performing empirical tests on the implemented system. These tests examine the effect of introspective index refinement, and the effects of problem order on case and index learning, and show that introspective learning of new index features improves performance across the different problem orders.
Abstract-found: 1
Intro-found: 1
Reference: 1. <editor> D. Aha, editor. </editor> <booktitle> Proceedings of the AAAI-94 Workshop on Case-Based Reasoning, </booktitle> <address> Seattle, WA, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: to the features used in indexing cases, and re-indexing the cases in memory to include the new feature. 3 Empirical Evaluation There has been growing interest in evaluation of case-based reasoning systems to identify to what extent they succeed and what components of their processing are responsible for their success <ref> [1] </ref>. However, little work has been done to quantify the benefits of introspective reasoning for improving reasoning methods, and the relationship between case presentation order and learning is largely unaddressed. We performed experiments to evaluate the effect of introspective learning of new index features on the overall performance of ROBBIE.
Reference: 2. <author> R. Alterman. </author> <title> An adaptive planner. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> pages 65-69, </pages> <address> Philadelphia, PA, </address> <month> August </month> <year> 1986. </year> <note> AAAI. </note>
Reference-contexts: The system has two main parts: a planner which develops plans through case-based reasoning <ref> [2, 14, 15] </ref> and applies them through execution in a simulated world, and an introspective model-based reasoner which detects, explains, and repairs reasoning failures caused by poor indexing criteria. The performance task of ROBBIE is to navigate around a simulated set of city streets as a pedestrian.
Reference: 3. <author> J. Arcos and E. </author> <title> Plaza. A reflective architecture for integrated memory-based learning and reasoning. </title> <editor> In S. Wess, K.D. Altoff, and M. Richter, editors, </editor> <booktitle> Topics in Case-Based Reasoning. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Kaiserslautern, Germany, </address> <year> 1993. </year>
Reference-contexts: IULIAN [17] also performs introspective learning, but instead of using an explicit introspective model, it stores plans for repairing its reasoning which are recalled when failures occur. Arcos and Plaza <ref> [3] </ref> create a unified architecture for describing case-based and meta-level problem solving tasks by describing each process by decomposition into tasks and sub-tasks.
Reference: 4. <author> W.M. Bain. </author> <title> Case-based Reasoning: A Computer Model of Subjective Assessment. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <year> 1986. </year> <note> Computer Science Department Technical Report 470. </note>
Reference-contexts: It is acknowledged that problem order can strongly affect learning in general, and learning of CBR systems in particular (e.g. <ref> [4, 18] </ref>). A sequence of goals which gradually increases in complexity and distance from the original cases in memory, and which covers the range of possible situations, should maximize the effectiveness of the case-based reasoner's learning.
Reference: 5. <author> S. Bhatta and A. Goel. </author> <title> Model-based learning of structural indices to design cases. </title> <booktitle> In Proceedings of the IJCAI-93 Workshop on Reuse of Design, </booktitle> <address> Chambery, France, </address> <month> September </month> <year> 1993. </year> <pages> IJCAI. </pages>
Reference-contexts: Arcos and Plaza [3] create a unified architecture for describing case-based and meta-level problem solving tasks by describing each process by decomposition into tasks and sub-tasks. IDEAL <ref> [5] </ref> investigates index learning, but uses a model of its domain, not the reasoning task, as well as cases from its domain, in order to learn new indices.
Reference: 6. <author> L. Birnbaum, G. Collins, M. Brand, M. Freed, B. Krulwich, and L. Pryor. </author> <title> A model-based approach to the construction of adaptive case-based planning systems. </title> <editor> In R. Bareiss, editor, </editor> <booktitle> Proceedings of the Case-Based Reasoning Workshop, </booktitle> <pages> pages 215-224, </pages> <address> San Mateo, </address> <year> 1991. </year> <title> DARPA, </title> <publisher> Morgan Kaufmann, Inc. </publisher>
Reference-contexts: A discrepancy indicates a reasoning failure; the failure is corrected by explaining why it occurred and revising the reasoning process to avoid future failures. Using introspective learning to improve the case-based reasoning process itself was first suggested by Birnbaum et al. <ref> [6] </ref>. Introspective improvement of reasoning processes is a relatively new approach, and there have been few evaluations of its effect on the performance of a system using it. <p> ROBBIE's high-level task is to improve its reasoning process (in particular, its feature selection process) when it detects failures in its reasoning. As the planner reasons about its task, the introspective component monitors its reasoning process by comparing it to a declarative model describing the planner's ideal reasoning processes <ref> [6, 9, 12] </ref>. Reasoning failures occur when the model's expectations about the reasoning process are not fulfilled by the actual reasoning. Expectations are encoded as assertions; facts that would be ideally true of particular points in the case-based reasoning process. <p> Characterizing sequences like this one further and determining their frequency is an important task for the future. 5 Related Work Other work has combined CBR with learning about the reasoning process itself. A proposal by Birnbaum et al. <ref> [6] </ref> inspired ROBBIE's framework, but that proposal was not implemented and did not use a hierarchical model. Meta-AQUA [7] performs failure-driven introspective learning, but contains no explicit model of correct behavior. Instead, it uses a set of template descriptions for reasoning failures which provide diagnosis and repair information.
Reference: 7. <author> M. Cox and A. Ram. </author> <title> Managing learning goals in strategy-selection problems. </title> <booktitle> In Proceedings of the Second European Workshop on Case-Based Reasoning, </booktitle> <pages> pages 85-93, </pages> <address> Chantilly, France, </address> <year> 1994. </year>
Reference-contexts: A proposal by Birnbaum et al. [6] inspired ROBBIE's framework, but that proposal was not implemented and did not use a hierarchical model. Meta-AQUA <ref> [7] </ref> performs failure-driven introspective learning, but contains no explicit model of correct behavior. Instead, it uses a set of template descriptions for reasoning failures which provide diagnosis and repair information.
Reference: 8. <author> R. J. Firby. </author> <title> Adaptive Execution in Complex Dynamic Worlds. </title> <type> PhD thesis, </type> <institution> Yale University, Computer Science Department, </institution> <year> 1989. </year> <type> Technical Report 672. </type>
Reference-contexts: ROBBIE is given a goal location and must create a plan for getting from its current location to the goal. Plan creation involves retrieving and adapting an old case. Because adaptation is not always guaranteed to be correct, ROBBIE executes the newly created plan using reactive planning <ref> [8] </ref> to fill in missing details and recover from failures. Execution evaluates the quality of the CBR-created plan, and permits ROBBIE to arrive at a solution despite flaws in the plan.
Reference: 9. <author> S. Fox and D. Leake. </author> <title> Using introspective reasoning to guide index refinement in case-based reasoning. </title> <booktitle> In Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 324-329, </pages> <address> Atlanta, GA, 1994. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: ROBBIE's high-level task is to improve its reasoning process (in particular, its feature selection process) when it detects failures in its reasoning. As the planner reasons about its task, the introspective component monitors its reasoning process by comparing it to a declarative model describing the planner's ideal reasoning processes <ref> [6, 9, 12] </ref>. Reasoning failures occur when the model's expectations about the reasoning process are not fulfilled by the actual reasoning. Expectations are encoded as assertions; facts that would be ideally true of particular points in the case-based reasoning process. <p> Failure detection for the introspective reasoner involves noticing discrepancies between assertions and actual behavior. At each point in the reasoning process, the introspective reasoner compares the actual reasoning to the ideal. When they fail to match, a reasoning failure has occurred (See <ref> [9] </ref> for a more extensive discussion of ROBBIE's failure detection). Detecting failures due to faulty indexing criteria requires monitoring the entire reasoning process: the failure may not be discovered until after the inappropriately retrieved case has been adapted and executed. <p> In addition, introspective reasoning for self-improvement is a general approach that could be extended to other portions of the CBR process: altering adaptation, evaluation, and case storage (See <ref> [9] </ref> for a more general discussion). Little empirical evaluation has been done to measure the effects of introspective reasoning on the behavior of systems which use it.
Reference: 10. <author> S. Fox and D. Leake. </author> <title> An introspective reasoning method for index refinement. </title> <booktitle> In Proceedings of 14th international Joint Conference on Artificial Intelligence. IJCAI, </booktitle> <year> 1995. </year>
Reference-contexts: By putting runs of a sequence together on one set of axes, we see trends in the retrieval performance. For a more detailed discussion of these results see <ref> [10] </ref>. cases the decrease with re-indexing was much more dramatic. The size and consistency of the drop were greater for sequences with high success rates, and for sequences with large differences between success rates with and without re-indexing. The anomalous sequence led to poor performance under any measure.
Reference: 11. <author> S. Fox and D. Leake. </author> <title> Modeling case-based planning for repairing reasoning failures. </title> <booktitle> In Proceedings of the 1995 AAAI Spring Symposium on Representing Mental States and Mechanisms, </booktitle> <address> Stanford, CA, </address> <month> March </month> <year> 1995. </year> <note> AAAI. (ftp.cs.indiana.edu:/pub/leake/p-95-02.ps.Z). </note>
Reference-contexts: The assertions are clustered together by the part of the reasoning process to which they refer, and by how abstract or specific they are. Each assertion also contains links to other causally related assertions inside or outside its cluster. Fox and Leake <ref> [11] </ref> contains a detailed description of the model and its representation. Failure detection for the introspective reasoner involves noticing discrepancies between assertions and actual behavior. At each point in the reasoning process, the introspective reasoner compares the actual reasoning to the ideal.
Reference: 12. <author> M. Freed and G. Collins. </author> <title> Adapting routines to improve task coordination. </title> <booktitle> In Proceedings of the 1994 Conference on AI Planning Systems, </booktitle> <pages> pages 255-259, </pages> <year> 1994. </year>
Reference-contexts: ROBBIE's high-level task is to improve its reasoning process (in particular, its feature selection process) when it detects failures in its reasoning. As the planner reasons about its task, the introspective component monitors its reasoning process by comparing it to a declarative model describing the planner's ideal reasoning processes <ref> [6, 9, 12] </ref>. Reasoning failures occur when the model's expectations about the reasoning process are not fulfilled by the actual reasoning. Expectations are encoded as assertions; facts that would be ideally true of particular points in the case-based reasoning process.
Reference: 13. <author> A. Goel, K. Ali, and Andres Gomez de Silva Garza. </author> <title> Computational tradeoffs in experience-based reasoning. </title> <booktitle> In Proceedings of the AAAI-94 workshop on Case-Based Reasoning, </booktitle> <pages> pages 55-61, </pages> <address> Seattle, WA, </address> <year> 1994. </year>
Reference-contexts: Our testbed computer system, ROBBIE 2 , is a case-based route planner. Its CBR component learns by adding successful plans to its memory, as in other case-based route planners such as ROUTER <ref> [13] </ref>. However, our research focus is not the route planning task itself. Instead, the focus is on how introspective reasoning can be used by the CBR system to refine its indexing criteria. ROBBIE combines a case-based planner with an introspective component.
Reference: 14. <author> C. Hammond. </author> <title> Case-Based Planning: Viewing Planning as a Memory Task. </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1989. </year>
Reference-contexts: The system has two main parts: a planner which develops plans through case-based reasoning <ref> [2, 14, 15] </ref> and applies them through execution in a simulated world, and an introspective model-based reasoner which detects, explains, and repairs reasoning failures caused by poor indexing criteria. The performance task of ROBBIE is to navigate around a simulated set of city streets as a pedestrian.
Reference: 15. <author> J. Kolodner. </author> <title> Case-Based Reasoning. </title> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction Selecting the best set of features to use in indexing a case-based reasoning (CBR) system's memory may be difficult; determining which features are most appropriate may require experience <ref> [15] </ref>. An appealing alternative is to permit the system itself to learn what features are relevant in response to its experiences. <p> The system has two main parts: a planner which develops plans through case-based reasoning <ref> [2, 14, 15] </ref> and applies them through execution in a simulated world, and an introspective model-based reasoner which detects, explains, and repairs reasoning failures caused by poor indexing criteria. The performance task of ROBBIE is to navigate around a simulated set of city streets as a pedestrian.
Reference: 16. <author> D. Leake. </author> <title> Constructive similarity assessment: Using stored cases to define new situations. </title> <booktitle> In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 313-318, </pages> <address> Bloomington, IN, 1992. </address> <publisher> Cognitive Science Society. </publisher>
Reference-contexts: Because the quality of a retrieval scheme depends on retrieving cases that are easy to adapt, it is desirable to achieve more direct connections between similarity criteria and case adaptation ability in CBR systems (e.g., <ref> [16, 19] </ref>); our research is one way to make indexing criteria better reflect adaptability. In addition, introspective reasoning for self-improvement is a general approach that could be extended to other portions of the CBR process: altering adaptation, evaluation, and case storage (See [9] for a more general discussion).
Reference: 17. <author> R. Oehlmann, P. Edwards, and D. Sleeman. </author> <title> Changing the viewpoint: Re-indexing by introspective questioning. </title> <booktitle> In Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 675-680. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1994. </year>
Reference-contexts: Instead, it uses a set of template descriptions for reasoning failures which provide diagnosis and repair information. Autognostic [20] applies an existing framework for device modeling (SBF) to introspective modeling of the route planner ROUTER; their approach focuses on explanation of failures without strongly addressing failure detection. IULIAN <ref> [17] </ref> also performs introspective learning, but instead of using an explicit introspective model, it stores plans for repairing its reasoning which are recalled when failures occur.
Reference: 18. <author> M. </author> <title> Redmond. Learning by Observing and Understanding Expert Problem Solving. </title> <type> PhD thesis, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <year> 1992. </year> <note> Technical report GIT-CC-92/43. </note>
Reference-contexts: It is acknowledged that problem order can strongly affect learning in general, and learning of CBR systems in particular (e.g. <ref> [4, 18] </ref>). A sequence of goals which gradually increases in complexity and distance from the original cases in memory, and which covers the range of possible situations, should maximize the effectiveness of the case-based reasoner's learning.
Reference: 19. <author> B. Smyth and M. Keane. </author> <title> Retrieving adaptable cases: The role of adaptation knowledge in case retrieval. </title> <editor> In S. Wess, K. Althoff, and M Richter, editors, </editor> <booktitle> Topics in Case-Based Reasoning, </booktitle> <pages> pages 209-220, </pages> <address> Berlin, 1994. </address> <publisher> Springer Verlag. </publisher>
Reference-contexts: Because the quality of a retrieval scheme depends on retrieving cases that are easy to adapt, it is desirable to achieve more direct connections between similarity criteria and case adaptation ability in CBR systems (e.g., <ref> [16, 19] </ref>); our research is one way to make indexing criteria better reflect adaptability. In addition, introspective reasoning for self-improvement is a general approach that could be extended to other portions of the CBR process: altering adaptation, evaluation, and case storage (See [9] for a more general discussion).
Reference: 20. <author> E. Stroulia and A. Goel. </author> <title> Task structures: What to learn? In M. </title> <editor> desJardins and A. Ram, editors, </editor> <booktitle> Proceedings of the 1994 AAAI Spring Symposium on Goal-driven Learning, </booktitle> <pages> pages 112-121. </pages> <publisher> AAAI Press, </publisher> <year> 1994. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: Meta-AQUA [7] performs failure-driven introspective learning, but contains no explicit model of correct behavior. Instead, it uses a set of template descriptions for reasoning failures which provide diagnosis and repair information. Autognostic <ref> [20] </ref> applies an existing framework for device modeling (SBF) to introspective modeling of the route planner ROUTER; their approach focuses on explanation of failures without strongly addressing failure detection.
References-found: 20

