URL: ftp://speech.cse.ogi.edu/pub/docs/icslp96/vanvuuren-speaker-recog.ps.gz
Refering-URL: http://www.cse.ogi.edu/CSLU/publications/publications.html
Root-URL: http://www.cse.ogi.edu
Title: Comparison of text-independent speaker recognition methods on telephone speech with acoustic mismatch  
Author: Sarel van Vuuren 
Address: 20000 N.W. Walker Road Beaverton, Oregon 97006 USA  
Affiliation: Oregon Graduate Institute of Science Technology Center for Spoken Language Understanding  
Abstract: We compare speaker recognition performance of Vector Quantization (VQ), Gaussian Mixture Modeling (GMM) and the Arithmetic Harmonic Sphericity measure (AHS) in adverse telephone speech conditions. The aim is to address the question: how do multimodal VQ and GMM typically compare to the simpler unimodal AHS for matched and mismatched training and testing environments. We study identification (closed set) and verification errors on a new multi-environment database. We consider LPC and PLP features as well as their RASTA derivatives. We conclude that RASTA processing can remove redundancies from the features. We affirm that even when we use channel and noise compensation schemes speaker recognition errors remain high when there is acoustic mismatch. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> F. Bimbot and L. Mathan. </author> <title> Text-free speaker recognition using an arithmetic-harmonic sphericity measure. </title> <booktitle> In Eurospeech, </booktitle> <pages> pages 169-172, </pages> <address> Berlin, </address> <year> 1993. </year>
Reference-contexts: We apply LPC and PLP analysis and channel and noise compensation by RASTA [4], Cepstral Mean Subtraction (CMS) [3] and normalization [6]. We use Vector Quantization (VQ) [7], Gaussian Mixture Modeling (GMM) [10] and the Arithmetic Harmonic Sphericity measure (AHS) <ref> [1] </ref>. <p> Assuming that local covariance information is preserved in adverse conditions and can be accurately estimated, we expect GMM to outperform VQ on average. Arithmetic Harmonic Sphericity measure. AHS <ref> [1] </ref> is a function of the eigenvalues of a test covariance matrix S relative to a reference covariance matrix S r for speaker r and is defined by the measure d r = log fi r ) 2 log D; which is non-negative and zero iff all the eigenvalues are equal.
Reference: 2. <author> J.-L. Le Floch, C. Montacie', and M.-J. Caraty. </author> <title> Speaker recognition experiments on the NTIMIT database. </title> <booktitle> In Eurospeech, </booktitle> <pages> pages 379-382, </pages> <month> Sept </month> <year> 1995. </year>
Reference-contexts: While results for mixture modeling are available on TIMIT, NTIMIT, Switchboard, YOHO and King databases [10] and results for unimodal statistical methods are available on Switchboard [11] and TIMIT and NTIMIT <ref> [2] </ref> these databases generally allow only limited cross-environment experiments (although some experiments with Switchboard 1 1 In Switchboard for example it has to be assumed that telephone numbers identify unique handsets. and King are possible [9]). <p> This database consists of isolated words spoken by 36 speakers 3 from each of 4 different telephone handset and channel environments. Each speaker produced 6 repetitions of a fixed 13 word vocabulary in each environment. To relate results on this multi-environment database to results reported in the literature <ref> [2] </ref> we report 4 35:7% (PLP) and 29:1% (LPC) identification error when using GMM over the 168 speakers in the test portion of the NTIMIT database, where for each speaker, we tested individually on two of the sx sentences and trained on the eight other sentences. <p> RASTA is seen to affect GMM little, but results in a substantial improvement for AHS. (This is to be contrasted to the finding that GMMs easily outperform AHS on NTIMIT <ref> [2] </ref>.) An explanation for this effect may be that the bandpass filtering of RASTA reduces spurious modalities in the data. For verification we note that the ROC curves have large tails.
Reference: 3. <author> S. Furui. </author> <title> Cepstral analysis technique for automatic speaker verification. </title> <journal> IEEE Trans. Acoust., Speech, Signal Processing, </journal> <volume> ASSP-29:254-272, </volume> <month> April </month> <year> 1981. </year>
Reference-contexts: In this paper we study recognition performance for speech collected over different telephone handsets and channels. We apply LPC and PLP analysis and channel and noise compensation by RASTA [4], Cepstral Mean Subtraction (CMS) <ref> [3] </ref> and normalization [6]. We use Vector Quantization (VQ) [7], Gaussian Mixture Modeling (GMM) [10] and the Arithmetic Harmonic Sphericity measure (AHS) [1].
Reference: 4. <author> H. Hermansky. </author> <title> Perceptual linear predictive (PLP) analysis of speech. </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 87(4) </volume> <pages> 1738-1752, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Reynolds [10] observed that acoustic mismatch due to different training and testing environments can severely degrade recognition performance. In this paper we study recognition performance for speech collected over different telephone handsets and channels. We apply LPC and PLP analysis and channel and noise compensation by RASTA <ref> [4] </ref>, Cepstral Mean Subtraction (CMS) [3] and normalization [6]. We use Vector Quantization (VQ) [7], Gaussian Mixture Modeling (GMM) [10] and the Arithmetic Harmonic Sphericity measure (AHS) [1]. <p> In the rest of this paper, we study the effect of different training and test environments on identification and verification performance. 2. DESCRIPTION 2.1. Features PLP and LPC analysis. We compare the discriminabil-ity and robustness to noise of Perceptual Linear Prediction (PLP) <ref> [4] </ref> and Linear Prediction (LPC). For PLP the spectral scale is the non-linear Bark scale and the spectral features are smoothed within frequency bands. In contrast for LPC the spectral scale is linear and no smoothing is done.
Reference: 5. <author> H. Hermansky. </author> <title> Rasta processing of speech. </title> <journal> IEEE Trans. Speech and Audio Processing, </journal> <volume> 2(4), </volume> <month> Oct </month> <year> 1994. </year>
Reference-contexts: We compensate for convolutional noise (as may be due to the additive effect of a channel in the log-spectral domain), by subtracting the long-term average from the ceptral coefficients (CMS) on a per utterance basis and/or by bandpass filtering in the log-spectral domain (RASTA filtering <ref> [5] </ref>). CMS performs a lowpass filtering operation of the speech in contrast to the bandpass filtering (between 1Hz and 16Hz modulation frequency [5]) performed by RASTA. <p> the log-spectral domain), by subtracting the long-term average from the ceptral coefficients (CMS) on a per utterance basis and/or by bandpass filtering in the log-spectral domain (RASTA filtering <ref> [5] </ref>). CMS performs a lowpass filtering operation of the speech in contrast to the bandpass filtering (between 1Hz and 16Hz modulation frequency [5]) performed by RASTA. In [6] it is shown that the norm of the cepstral coefficient vector is particularly sensitive to additive noise, while its direction is less affected.
Reference: 6. <author> D. Mansour and Biing Hwang Juang. </author> <title> A family of distortion measures based upon projection operation for robust speech recognition. </title> <booktitle> In ICASSP, </booktitle> <pages> pages 36-39, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: In this paper we study recognition performance for speech collected over different telephone handsets and channels. We apply LPC and PLP analysis and channel and noise compensation by RASTA [4], Cepstral Mean Subtraction (CMS) [3] and normalization <ref> [6] </ref>. We use Vector Quantization (VQ) [7], Gaussian Mixture Modeling (GMM) [10] and the Arithmetic Harmonic Sphericity measure (AHS) [1]. <p> CMS performs a lowpass filtering operation of the speech in contrast to the bandpass filtering (between 1Hz and 16Hz modulation frequency [5]) performed by RASTA. In <ref> [6] </ref> it is shown that the norm of the cepstral coefficient vector is particularly sensitive to additive noise, while its direction is less affected. However, we found no benefit from normalizing the cepstral feature vectors to unit magnitude above and beyond the results reported here. 2.2.
Reference: 7. <author> T. Matsui and S. Furui. </author> <title> Comparison of text-independent speaker recognition methods using VQ-distortion and discrete/continuous HMMs. </title> <booktitle> In ICASSP, </booktitle> <pages> pages 157-160, </pages> <year> 1992. </year>
Reference-contexts: In this paper we study recognition performance for speech collected over different telephone handsets and channels. We apply LPC and PLP analysis and channel and noise compensation by RASTA [4], Cepstral Mean Subtraction (CMS) [3] and normalization [6]. We use Vector Quantization (VQ) <ref> [7] </ref>, Gaussian Mixture Modeling (GMM) [10] and the Arithmetic Harmonic Sphericity measure (AHS) [1]. <p> Conversely unimodal models are expected to be less sensitive to small perturbations in the speech that might arise in noisy conditions. Of the modeling methods GMM has the greatest degree of modeling freedom. Vector Quantization. We use VQ <ref> [7] </ref> as the baseline for results reported here. It differs from GMM in that it does not use local covariance information and classification takes place in a winner-takes-all fashion.
Reference: 8. <author> D. Ormoneit and V. Tresp. </author> <title> Improved gaussian mixture density estimates using Bayesian penalty terms and network averaging. In Advances in Neural Information Processing Systems, volume 8, page not yet available. </title> <publisher> The MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: Here r denotes the parameter vector (ff r i ; r i ) n estimate the parameter vector with the EM algorithm and regularize with a Bayesian prior <ref> [8] </ref>. Since AHS covers the case of a full single covariance matrix effectively, we choose to use a 32 mixture GMM with diagonal covariance matri ces [10].
Reference: 9. <author> D.A. Reynolds. </author> <title> Experimental evaluation of features for robust speaker identification. </title> <journal> IEEE Trans. Speech and Audio Processing, </journal> <volume> 2(4) </volume> <pages> 639-643, </pages> <month> Oct </month> <year> 1994. </year>
Reference-contexts: and results for unimodal statistical methods are available on Switchboard [11] and TIMIT and NTIMIT [2] these databases generally allow only limited cross-environment experiments (although some experiments with Switchboard 1 1 In Switchboard for example it has to be assumed that telephone numbers identify unique handsets. and King are possible <ref> [9] </ref>). In contrast, the database used in this paper 2 allows us to explicitly investigate the effect of well characterized environments. This database consists of isolated words spoken by 36 speakers 3 from each of 4 different telephone handset and channel environments.
Reference: 10. <author> D.A. Reynolds. </author> <title> Speaker identification and verification using Gaussian mixture speaker models. </title> <journal> Speech Communication, </journal> <volume> 17 </volume> <pages> 91-108, </pages> <year> 1995. </year>
Reference-contexts: 1. INTRODUCTION In a realistic telephone application, speech collected during enrollment of the speaker and available for initial training typically come from a single environment, while at test time the environment is generally unknown. Reynolds <ref> [10] </ref> observed that acoustic mismatch due to different training and testing environments can severely degrade recognition performance. In this paper we study recognition performance for speech collected over different telephone handsets and channels. <p> In this paper we study recognition performance for speech collected over different telephone handsets and channels. We apply LPC and PLP analysis and channel and noise compensation by RASTA [4], Cepstral Mean Subtraction (CMS) [3] and normalization [6]. We use Vector Quantization (VQ) [7], Gaussian Mixture Modeling (GMM) <ref> [10] </ref> and the Arithmetic Harmonic Sphericity measure (AHS) [1]. While results for mixture modeling are available on TIMIT, NTIMIT, Switchboard, YOHO and King databases [10] and results for unimodal statistical methods are available on Switchboard [11] and TIMIT and NTIMIT [2] these databases generally allow only limited cross-environment experiments (although some <p> We use Vector Quantization (VQ) [7], Gaussian Mixture Modeling (GMM) <ref> [10] </ref> and the Arithmetic Harmonic Sphericity measure (AHS) [1]. While results for mixture modeling are available on TIMIT, NTIMIT, Switchboard, YOHO and King databases [10] and results for unimodal statistical methods are available on Switchboard [11] and TIMIT and NTIMIT [2] these databases generally allow only limited cross-environment experiments (although some experiments with Switchboard 1 1 In Switchboard for example it has to be assumed that telephone numbers identify unique handsets. and King are possible <p> We train the VQ models with the LBG algorithm, choose to model the feature vectors for each speaker by 32 clusters and use the Euclidean norm. Gaussian Mixture Modeling. GMM <ref> [10] </ref> uses a mixture of Gaussian densities to model the distribution of the feature vectors x of each speaker. <p> Since AHS covers the case of a full single covariance matrix effectively, we choose to use a 32 mixture GMM with diagonal covariance matri ces <ref> [10] </ref>. Given a reference model r for speaker r and assuming independent feature vectors X = fx 1 ; : : : ; x T g the average log-likelihood for the utterance is formulated as L (Xj r ) = 1=T t=1 log p (x t j r ).
Reference: 11. <author> M. Schmidt, H. Gish, and A. Mielke. </author> <title> Covariance estimation methods for channel robust text-independent speaker identification. </title> <booktitle> In ICASSP, </booktitle> <pages> pages 333-336, </pages> <year> 1995. </year>
Reference-contexts: We use Vector Quantization (VQ) [7], Gaussian Mixture Modeling (GMM) [10] and the Arithmetic Harmonic Sphericity measure (AHS) [1]. While results for mixture modeling are available on TIMIT, NTIMIT, Switchboard, YOHO and King databases [10] and results for unimodal statistical methods are available on Switchboard <ref> [11] </ref> and TIMIT and NTIMIT [2] these databases generally allow only limited cross-environment experiments (although some experiments with Switchboard 1 1 In Switchboard for example it has to be assumed that telephone numbers identify unique handsets. and King are possible [9]).
References-found: 11

