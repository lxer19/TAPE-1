URL: http://www.cs.rice.edu:80/~gaurav/my_papers/bmvc.ps
Refering-URL: http://www.cs.rice.edu:80/~gaurav/gaurav_research.html
Root-URL: 
Address: Hauz Khas, New Delhi 110016, India  
Affiliation: COMPUTER SCIENCE AND ENGINEERING  Department of Computer Science and Engineering INDIAN INSTITUTE OF TECHNOLOGY, DELHI  
Pubnum: TECHNICAL REPORT  
Abstract: Communication Efficient Parallel Mixed-Radix FFTs Gaurav Banga and Gautam M. Shroff Technical Report 94/1 February 1994 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Bellman. </author> <title> "Introduction to Matrix Analysis", </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: Element (j; k) of a matrix A will be denoted by jAj (j; k) with the convention that the rows and columns of a N fi N matrix are indexed from 0 to N 1. 2. Following Bellman <ref> [1] </ref>, define a Kronecker matrix product by A fi B = (a ij B): In the present notation, let A and B be square matrices of order p and q respectively. Then jA fi Bj (tq + u; rq + s) = jAj (t; r):jBj (u; s) (3) 3.
Reference: [2] <author> Clive Temperton. </author> <title> "Self-Sorting Mixed-Radix Fast Fourier Transforms", </title> <journal> Journal of Computational Physics 52, </journal> <pages> 1-23, </pages> <year> 1983. </year>
Reference-contexts: Straightforward generalizations of these algorithms for the case when the number of processors is not a power of two have high inter-stage communication overhead and/or poor load-balance properties [12]. We present here a generalized parallel FFT algorithm based on the Temperton FFT <ref> [2] </ref> which puts no restrictions on the number of processors or on the size of the input vector. Our algorithm has provably low communication overhead which is independent of the number of processors. This together with good load balance properties fl gbanga@henna.iitd.ernet.in y gmshroff@cse.iitd.ernet.in render the algorithm highly scalable. <p> The idea behind the FFT algorithm is to factorize W N so that the process of multiplication by W N is broken up into O (N log N ) multiplications by smaller matrices (each of small constant size). Temperton <ref> [2] </ref> has presented several variants of the FFT algorithm expressing them as different factorized multiplications of the form W N z. 2.1 Some Notation In the argument that follows, we use some notation from [2] which needs some explanation. 1. <p> Temperton <ref> [2] </ref> has presented several variants of the FFT algorithm expressing them as different factorized multiplications of the form W N z. 2.1 Some Notation In the argument that follows, we use some notation from [2] which needs some explanation. 1. Element (j; k) of a matrix A will be denoted by jAj (j; k) with the convention that the rows and columns of a N fi N matrix are indexed from 0 to N 1. 2. <p> Next, define a permutation matrix P p q of order pq by jP p ( 0 otherwise (4) 4. Finally, define a diagonal matrix D p q of order pq by jD p ( 0 otherwise (5) where ! = exp (2i=pq). 2.2 Temperton's Algorithm Temperton <ref> [2] </ref> has shown that if N = n 1 n 2 : : : n k1 n k then W N = P k T k P k1 T k1 : : : P 2 T 2 P 1 T 1 (6) where T i = (W n i fi I <p> In the algorithm presented below, we use a variant of the Temperton factorization of W N which allows us to treat this inter-stage communication as a structured redistribution. In his paper <ref> [2] </ref>, Temperton has shown that if N = n 1 n 2 : : : n k1 n k then W N = T k T k1 : : : T 2 T 1 P 1 P 2 : : : P k1 P k (7) where T i = (I
Reference: [3] <author> J. W. Cooley and J. W. Tuckey. </author> <title> "An Algorithm for the machine calculation of complex Fourier series", </title> <journal> Math. Comp. </journal> <volume> 19, </volume> <pages> 297-301, </pages> <year> 1965 </year>
Reference: [4] <author> G. D. Bergland. </author> <title> "A Parallel implementation of the Fast Fourier Transform algorithm", </title> <journal> IEEE Transactions on Computers C-21, </journal> <volume> 4(April), </volume> <pages> 366-370, </pages> <year> 1972 </year>
Reference: [5] <author> S. D. Conte and C. de Boor. </author> <title> "Elementary Numerical Analysis: An Algorithmic Approach", 3rd Edition, </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1980 </year>
Reference: [6] <author> C. de Boor. </author> <title> "FFT as nested multiplication, with a twist", </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 1, </volume> <pages> 173-178, </pages> <year> 1980 </year>
Reference: [7] <author> S. Winograd. </author> <title> "On computing the discrete Fourier Transform", </title> <journal> Math. Comp., </journal> <volume> 32, </volume> <pages> 175-199, </pages> <year> 1978 </year>
Reference: [8] <author> R. C. </author> <title> Singleton. "On computing the Fast Fourier Transform", </title> <journal> J. ACM, </journal> <volume> 10, </volume> <pages> 647-654, </pages> <year> 1967 </year>
Reference: [9] <author> R. C. </author> <title> Singleton. "An algorithm for computing the mixed-radix Fast Fourier Transform", </title> <journal> IEEE Transactions on Audio Electroacoust, </journal> <pages> 93-103, </pages> <year> 1969 </year>
Reference: [10] <author> W. M. Gentleman and G. Sande. </author> <title> "Fast Fourier Transforms-For fun and profit ", Procs. </title> <booktitle> AFIPS Joint Computer Conference 29, </booktitle> <pages> 563-578, </pages> <year> 1966 </year>
Reference: [11] <author> C. R. Jesshope. </author> <title> "Implementation of fast radix-2 transforms on array processors", </title> <journal> IEEE Transactions on Computers C-29, </journal> <volume> 1(Jan), </volume> <pages> 20-27, </pages> <year> 1980 </year>
Reference: [12] <author> G. C. Fox, M. A. Johnson, G. A. Lyzenga, S. W. Otto, J. K. Salmon, D. W. Walker. </author> <title> "Solving Problems on Concurrent Processors", </title> <publisher> Prentice Hall, </publisher> <address> New Jersey, 187-200,431-433,1988 </address>
Reference-contexts: All these involve computationally intensive tasks requiring the use of supercomputing hardware - which today means distributed memory parallel machines. FFT algorithms for the distributed memory parallel computing paradigm with number of processors equal to a power of two are well known in the literature <ref> [12] </ref>, [13], [15]. Straightforward generalizations of these algorithms for the case when the number of processors is not a power of two have high inter-stage communication overhead and/or poor load-balance properties [12]. <p> parallel computing paradigm with number of processors equal to a power of two are well known in the literature <ref> [12] </ref>, [13], [15]. Straightforward generalizations of these algorithms for the case when the number of processors is not a power of two have high inter-stage communication overhead and/or poor load-balance properties [12]. We present here a generalized parallel FFT algorithm based on the Temperton FFT [2] which puts no restrictions on the number of processors or on the size of the input vector. Our algorithm has provably low communication overhead which is independent of the number of processors. <p> comm = P and on a fully interconnected machine with hardware routing t comm = 1.) We also assume that ff fi so that what matters is the number of communication calls and not their sizes. 2.4 The Hypercube FFT The mixed-radix FFT algorithm for a hypercube (Fox et al. <ref> [12] </ref>, Aloisio et al. [13]) can be viewed as a variant of the Temperton factorization of W N . This algorithm regards the inter-stage redistribution of the vector z as a complete shu*ing. The cost of this inter-stage redistribution is (in general) O (N=P ) communication steps [12]. <p> (Fox et al. <ref> [12] </ref>, Aloisio et al. [13]) can be viewed as a variant of the Temperton factorization of W N . This algorithm regards the inter-stage redistribution of the vector z as a complete shu*ing. The cost of this inter-stage redistribution is (in general) O (N=P ) communication steps [12]. <p> The classical hypercube Global Combine algorithm <ref> [12] </ref> and the more recent Hybrid Combine algorithm [18] work only for number of processors equal to a power of two. The communication complexity of these algorithms is O (log P ).
Reference: [13] <author> G. Aloisio, G. C. Fox, J. S. Kim, N Veneziani. </author> <title> "A concurrent implementation of the prime factor algorithm on the hypercube", unpublished Caltech report, C 3 P -468, </title> <year> 1987 </year>
Reference-contexts: All these involve computationally intensive tasks requiring the use of supercomputing hardware - which today means distributed memory parallel machines. FFT algorithms for the distributed memory parallel computing paradigm with number of processors equal to a power of two are well known in the literature [12], <ref> [13] </ref>, [15]. Straightforward generalizations of these algorithms for the case when the number of processors is not a power of two have high inter-stage communication overhead and/or poor load-balance properties [12]. <p> on a fully interconnected machine with hardware routing t comm = 1.) We also assume that ff fi so that what matters is the number of communication calls and not their sizes. 2.4 The Hypercube FFT The mixed-radix FFT algorithm for a hypercube (Fox et al. [12], Aloisio et al. <ref> [13] </ref>) can be viewed as a variant of the Temperton factorization of W N . This algorithm regards the inter-stage redistribution of the vector z as a complete shu*ing. The cost of this inter-stage redistribution is (in general) O (N=P ) communication steps [12].
Reference: [14] <author> M. C. Pease III. </author> <title> "An Adaption of the Fast Fourier Transform for Parallel Processing", </title> <journal> Journal of the ACM, </journal> <volume> 15, 2(April), </volume> <year> 1968 </year>
Reference: [15] <author> Michael J. Quinn. </author> <title> "Designing Efficient Algorithms for Parallel Computers", </title> <publisher> McGraw-Hill, Singapore, </publisher> <pages> 97-102, </pages> <year> 1987 </year>
Reference-contexts: All these involve computationally intensive tasks requiring the use of supercomputing hardware - which today means distributed memory parallel machines. FFT algorithms for the distributed memory parallel computing paradigm with number of processors equal to a power of two are well known in the literature [12], [13], <ref> [15] </ref>. Straightforward generalizations of these algorithms for the case when the number of processors is not a power of two have high inter-stage communication overhead and/or poor load-balance properties [12].
Reference: [16] <author> A. Gupta and V. Kumar. </author> <title> "On the Scalability of FFT on Parallel Computers", </title> <type> Technical Report TR 90-20, </type> <institution> Dept. of Computer Science, University of Minnesota, Minneapolis, </institution> <year> 1990 </year>
Reference: [17] <author> Eric F. Van de Velde and Jens Lorenz. </author> <title> "Adaptive Data Distribution for Concurrent Continuation", </title> <type> Technical Report CRPC-89-4-revised, </type> <institution> Center For Research On Parallel Computing, Caltech, </institution> <year> 1989 </year>
Reference-contexts: 12 ! x 4 ; z 2 ! ! 21 ! 22 x 2 ! z 6 = ! 11 ! 12 ! x 6 3.2 Distributions A central idea in the paradigm of distributed memory parallel computing is the distribution of a data structure over the ensemble of processors <ref> [17] </ref>. In our algorithm, we will distribute a 1-D array (the input vector) over the processors. Thus the global array A [] is physically present as a number of local arrays A p loc [] (0 p P 1). <p> A Proc (i) loc [Local [i]] = A [i]. 3. Global p (i) This specifies the global index of A p loc [i], i.e. A p loc [i] = A [Global p (i)]. Linear Distribution A simple distribution is the Linear distribution <ref> [17] </ref>. Linear (N; P ) is defined by 1.
Reference: [18] <author> Robert A. van de Geijn. </author> <title> "On Global Combine Operations", </title> <note> LAPACK Working Note 29, </note> <institution> Dept. of Computer Science, University of Tennessee, Knoxville, </institution> <year> 1991 </year>
Reference-contexts: The classical hypercube Global Combine algorithm [12] and the more recent Hybrid Combine algorithm <ref> [18] </ref> work only for number of processors equal to a power of two. The communication complexity of these algorithms is O (log P ).
Reference: [19] <author> Charles L. Seitz, Jakov Seizovic, Wen-King Su. </author> <title> "The C Programmer's Abbreviated Guide to Multicomputer Programming", </title> <institution> Caltech Computer Science Department Technical Report, Caltech-CS-TR-88-1, </institution> <year> 1988 </year> <month> p </month>
Reference-contexts: So the generalized Global Combine has the same complexity as the power of two algorithm. 5 Implementation To test our theoretical results, we implemented Algorithm 5 on a network of SUN workstations running the "Cosmic Environment" <ref> [19] </ref> together with an inhouse developed higher level communication library. A network of powerful workstations is the ideal test-bed for our algorithm since here the communication cost is very high as compared to the computation cost. In addition a network satisfies our assumption of ff fi very closely.
References-found: 19

