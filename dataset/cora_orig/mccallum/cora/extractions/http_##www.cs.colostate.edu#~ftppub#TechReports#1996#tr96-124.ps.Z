URL: http://www.cs.colostate.edu/~ftppub/TechReports/1996/tr96-124.ps.Z
Refering-URL: http://www.cs.colostate.edu/~ftppub/
Root-URL: 
Email: fstevensm,anderson,rossg@cs.colostate.edu  
Phone: Phone: (970) 491-5792 Fax: (970) 491-2466  
Title: Using Large Neural Networks as an Efficient Indexing Method for ATR Template Matching  
Author: Mark R. Stevens Charles W. Anderson J. Ross Beveridge 
Note: This work was sponsored by the Defense Advanced Research Projects Agency (DARPA) Image Understanding Program under grants DAAH04 93-G-422 and DAAH04-95-1-0447, monitored by the U. S. Army Research Office. This work, or any substantial part thereof, has not been submitted to or has not appeared in any other scientific conference  
Web: WWW: http://www.cs.colostate.edu  
Date: October 28, 1996  
Address: Fort Collins, CO 80523  Fort Collins, CO 80523-1873  
Affiliation: Computer Science  Department of Computer Science Colorado State University  Computer Science Department Colorado State University  
Pubnum: Technical Report  Technical Report CS-96-124  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. Ross Beveridge, Allen Hanson, and Durga Panda. </author> <title> Integrated color ccd, flir & ladar based object modeling and recognition. </title> <type> Technical report, </type> <institution> Colorado State University and Alliant Techsystems and University of Massachusetts, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: Computation time for template application is usually O (n) where n is the number of templates. Two methods are typically used for reducing this processing time: parallel hardware is added to increase computation speed [4, 7], and focus-of-attention mechanisms are used to predict the vehicle location <ref> [1] </ref>. Neither method reduces the number of templates to apply. A different approach is to index, or select, a subset of the available templates to apply to each window. Here we describe how neural networks can be used to predict the utility of applying each template to a window. <p> The number of nonzero bits in the resulting matrix are counted and divided by the number of nonzero elements in the template co-occurrence matrix. The result is a number in the range <ref> [0; 1] </ref> representing the quality of that template's match to the data in that window. The twenty-five templates which best match any sub-window across the entire range image are recorded. Templates whose degree of match less than 0:6 are discarded to reduce the number of false positives. <p> The RMS error on the test data after 12 epochs was 0:056 for the M113 network, 0:063 for the M35 network, and 0:055 for the M60 network (recall that the network outputs are constrained to the range <ref> [0; 1] </ref>). 3 RESULTS ON ACTUAL LADAR DATA As described in the previous section, the networks were trained only on synthetic imagery. After training, the networks were tested on 15 real LADAR images 2 from the Fort Carson data set [2]. Figure 4 shows four of the fifteen images tested.
Reference: [2] <author> J. Ross Beveridge, Durga P. Panda, and Theodore Yachik. </author> <title> November 1993 Fort Carson RSTA Data Collection Final Report. </title> <type> Technical Report CSS-94-118, </type> <institution> Colorado State University, </institution> <address> Fort Collins, CO, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: After training, the networks were tested on 15 real LADAR images 2 from the Fort Carson data set <ref> [2] </ref>. Figure 4 shows four of the fifteen images tested. Shown in each figure are the original range image and the pixels at the center of windows for which the all-templates and the neural-network indexing methods predicted degrees of match greater than 0.6.
Reference: [3] <author> James E. Bevington. </author> <title> Laser Radar ATR Algorithms: Phase III Final Report. </title> <type> Technical report, </type> <institution> Alliant Techsys-tems, Inc., </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: The windows are small, rectangular subsets of pixels just large enough to contain each vehicle. After all templates are applied to an image, the vehicle type and orientation corresponding to the best matched templates are returned as the most likely to be present in the image <ref> [3] </ref>. In order to detect a wide range of vehicle types and orientations, a large number of templates must be applied. Computation time for template application is usually O (n) where n is the number of templates.
Reference: [4] <author> Zhixi Fang, Xiabo Li, and Lionel M. Ni. </author> <title> Parallel algorithms for image template matching on hypercube SIMD computers. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-9(6):835-841, </volume> <month> November </month> <year> 1987. </year>
Reference-contexts: Computation time for template application is usually O (n) where n is the number of templates. Two methods are typically used for reducing this processing time: parallel hardware is added to increase computation speed <ref> [4, 7] </ref>, and focus-of-attention mechanisms are used to predict the vehicle location [1]. Neither method reduces the number of templates to apply. A different approach is to index, or select, a subset of the available templates to apply to each window.
Reference: [5] <author> S. Ghosal and R. Mehrotra. </author> <title> Range surface characterization and segmentation using neural networks. </title> <journal> Pattern Recognition, </journal> <volume> 28(5) </volume> <pages> 711-727, </pages> <month> may </month> <year> 1995. </year>
Reference-contexts: However, in this article we use the nonlinear mapping capability of neural networks to reduce the computation associated with an essentially linear procedure-template matching for automatic target recognition (ATR). Template matching for vehicle identification in ATR requires the application of numerous templates to rectangular windows of an image <ref> [12, 8, 5, 6] </ref>. Each template corresponds to a particular type of vehicle at a particular orientation. The windows are small, rectangular subsets of pixels just large enough to contain each vehicle.
Reference: [6] <author> Alana Katz and Philip Thrift. </author> <title> Hybrid neural network classifiers for automatic target detection. </title> <journal> Expert Systems, </journal> <volume> 10(4):243, </volume> <month> nov </month> <year> 1993. </year>
Reference-contexts: However, in this article we use the nonlinear mapping capability of neural networks to reduce the computation associated with an essentially linear procedure-template matching for automatic target recognition (ATR). Template matching for vehicle identification in ATR requires the application of numerous templates to rectangular windows of an image <ref> [12, 8, 5, 6] </ref>. Each template corresponds to a particular type of vehicle at a particular orientation. The windows are small, rectangular subsets of pixels just large enough to contain each vehicle.
Reference: [7] <author> V. K. Prasanna Kumar and Venkatesh Krishnan. </author> <title> Efficient parallel algorithms for image template matching on hypercube SIMD machines. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-11(6):665-669, </volume> <month> June </month> <year> 1989. </year>
Reference-contexts: Computation time for template application is usually O (n) where n is the number of templates. Two methods are typically used for reducing this processing time: parallel hardware is added to increase computation speed <ref> [4, 7] </ref>, and focus-of-attention mechanisms are used to predict the vehicle location [1]. Neither method reduces the number of templates to apply. A different approach is to index, or select, a subset of the available templates to apply to each window.
Reference: [8] <author> L.I. Perlovsky, J.A. Chernick, and W.H. Schoendorf. </author> <title> Multisensor atr and identification of friend or foe using mlans. Neural Networks, </title> <address> 8(7-8):1185-1200, </address> <year> 1995. </year>
Reference-contexts: However, in this article we use the nonlinear mapping capability of neural networks to reduce the computation associated with an essentially linear procedure-template matching for automatic target recognition (ATR). Template matching for vehicle identification in ATR requires the application of numerous templates to rectangular windows of an image <ref> [12, 8, 5, 6] </ref>. Each template corresponds to a particular type of vehicle at a particular orientation. The windows are small, rectangular subsets of pixels just large enough to contain each vehicle.
Reference: [9] <editor> D. E. Rumelhart and J. L. McClelland. </editor> <booktitle> Parallel Distributed Processing, Volume 1: Foundations, </booktitle> <volume> volume 1. </volume> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1986. </year>
Reference-contexts: Each network must have an output for each possible template. For each vehicle type there are 1; 800 templates, so each network has 1; 800 outputs. The networks were trained with standard error back-propagation with momentum <ref> [9] </ref>. The training data was generated from 250 synthetic LADAR images with the various vehicles placed in the scene at a depth of 85m and at different orientations. Figure 3 shows two such images.
Reference: [10] <author> Mark R. Stevens, J. Ross Beveridge, and Michael E. Goss. </author> <title> Reduction of BRL/CAD Models and Their Use in Automatic Target Recognition Algorithms. </title> <booktitle> In Proceedings: BRL-CAD Symposium. </booktitle> <institution> Army Research Labs, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: The models used were reduced from highly-detailed BRLCAD models [11] to a level-of-detail more closely related to the granularity of a LAser raDAR (LADAR) sensor <ref> [10] </ref>. The reduction phase preserves salient features 2 which are typically present in actual, coarse, range data that is obtained by a LADAR sensor as it scans a scene and produces an image of depth values. Models of three vehicles, designated M113, M35, and M60 1 , were used.
Reference: [11] <author> U. S. </author> <note> Army Ballistic Research Laboratory. BRL-CAD User's Manual, release 4.0 edition, </note> <month> December </month> <year> 1991. </year>
Reference-contexts: Figure 1 provides an overview of the entire system detailed below. 2.1 GENERATION AND USE OF TEMPLATES Template generation begins with the generation of synthetic images from three-dimensional models. The models used were reduced from highly-detailed BRLCAD models <ref> [11] </ref> to a level-of-detail more closely related to the granularity of a LAser raDAR (LADAR) sensor [10].
Reference: [12] <author> Allen M. Waxman, Micheal C. Seibert, Alan Gove, David A. Fay, Ann Marie Bernardon, Carol Lazott, William R. Steele, and Robert K. Cunningham. </author> <title> Neural processing of targets in visible, multispectral ir and sar imagery. Neural Networks, </title> <address> 8(7/8):1029, </address> <month> may </month> <year> 1995. </year> <month> 6 </month>
Reference-contexts: However, in this article we use the nonlinear mapping capability of neural networks to reduce the computation associated with an essentially linear procedure-template matching for automatic target recognition (ATR). Template matching for vehicle identification in ATR requires the application of numerous templates to rectangular windows of an image <ref> [12, 8, 5, 6] </ref>. Each template corresponds to a particular type of vehicle at a particular orientation. The windows are small, rectangular subsets of pixels just large enough to contain each vehicle.
References-found: 12

