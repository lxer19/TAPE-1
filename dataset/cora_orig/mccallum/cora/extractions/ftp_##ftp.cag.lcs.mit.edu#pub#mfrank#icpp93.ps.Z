URL: ftp://ftp.cag.lcs.mit.edu/pub/mfrank/icpp93.ps.Z
Refering-URL: http://www.cag.lcs.mit.edu/~mfrank/pubs.html
Root-URL: 
Abstract-found: 0
Intro-found: 1
Reference: [Ande91] <author> Anderson, R. J. and L. Snyder, </author> <title> A Comparison of Shared and Nonshared Memory Models of Parallel Computation, </title> <journal> Proc. of the IEEE, </journal> <volume> Vol. 79, No. </volume> <month> 4 , April </month> <year> 1991, </year> <pages> pp. 480-487. </pages>
Reference-contexts: Background: Dynamic Shared Memory Previous studies have observed that the dynamic shared memory programming model must include the notion of non-uniform memory access times, since programs developed using uniform memory access semantics have notoriously poor performance <ref> [Ande91, Cher91a, Hill90, Lin90, Mart89] </ref>. What is required is an approximate model of the coherence operations that provides a framework for assessing trade-offs between logically partitioning the data among the processes and balancing the computational load among the processes.
Reference: [Cart91] <author> Carter, J. B., J. K. Bennett and W. Zwaenepoel, </author> <title> Implementation and Performance of Munin, </title> <booktitle> Proc. 13th ACM Symp. on Operating System Principles, </booktitle> <address> Pacific Grove, CA , pp. 152-164, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: Write-update operations, which update rather than invalidate all copies of a block whenever a particular pro cessor writes the block, are available in some systems [Leno92] and have recently been advocated as a tech nique for overlapping communication and computation in SM systems <ref> [Cart91, Rost93] </ref>. Our SM/MP primitives have some features in common with write-update primi tives.
Reference: [Cher91a] <author> Cheriton, D. R., H. A. Goosen and P. Machanick, </author> <title> Restructuring a Parallel Simulation to Improve Cache Behavior in a Shared Memory Multiprocessor: A First Experience, </title> <booktitle> Int'l. Symp. on Shared Memory Multiprocessing, </booktitle> <pages> Tokyo , pp. 109-118, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Background: Dynamic Shared Memory Previous studies have observed that the dynamic shared memory programming model must include the notion of non-uniform memory access times, since programs developed using uniform memory access semantics have notoriously poor performance <ref> [Ande91, Cher91a, Hill90, Lin90, Mart89] </ref>. What is required is an approximate model of the coherence operations that provides a framework for assessing trade-offs between logically partitioning the data among the processes and balancing the computational load among the processes.
Reference: [Cher91b] <author> Cheriton, D. R., H. A. Goosen and P. D. Boyle, </author> <title> Paradigm: A Highly Scalable Shared-Memory Multicomputer Architecture, </title> <journal> Computer, </journal> <volume> Vol. 24, No. </volume> <month> 2 , February </month> <year> 1991, </year> <pages> pp. 33-46. </pages>
Reference-contexts: These opera tions allow a prefetch to be issued early and to remain pending in the memory system until a new value is released by another processor. Recent examples include QOLB [Jame90], Notify <ref> [Cher91b] </ref>, and cooperative pre fetch [Hill92]. The advantages of the SM/MP primitives include: 1) simpler hardware support, 2) more general and efficient support for multiple consumers, 3) lower overhead and a simpler programming model in many cases (such as those illustrated in section 3.2).
Reference: [Fuen92] <author> Fuentes, Y. O. and S. Kim, </author> <title> Parallel Computational Microhydrodynamics: Communication Scheduling Strategies, </title> <journal> AIChE Journal, </journal> <volume> Vol. 38, No. </volume> <month> 7 , July </month> <year> 1992, </year> <pages> pp. 1059-1078. </pages>
Reference-contexts: x, A; Spawn P threads; task k: Apply-MP-read x; repeat until x converges for each i in thread k's partition of x x i := f (A, x); compute subset-of-P to receive x i MP-send (x i , subset-of-P); hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh a process sends updated values to each other process (e.g. <ref> [Fuen92] </ref>). Due to the chaotic nature of the algorithm, processes are allowed to use stale values if they have not received the update. Note that MP-prefetch operations can be used instead of the MP-send operations to implement a similar communication schedule.
Reference: [Good89] <author> Goodman, J. R., M. K. Vernon and P. J. Woest, </author> <title> A Set of Efficient Synchronization Primitives for a Large-Scale Shared-Memory Multiprocessor, </title> <booktitle> Proc. 3rd Int'l. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> Boston , pp. 64-75, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Comparison with Previous Approaches Prefetching techniques have been the principal approach advocated in the literature for reducing read latencies (i.e., for overlapping communication and com putation) in large-scale SM systems. Synchronized pre fetching techniques have been proposed <ref> [Good89] </ref> for Table 1: State Transitions for MP Requests in the SM/MP Coherence Protocol iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii Cache Block Next Request State State Action iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii Shared or forward MP-put request Processor Exclusive Unchanged to remote processor iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii MP-send Possibly Stale forward MP-send or Invalid Unchanged request to directory iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii Shared or forward
Reference: [Hill90] <author> Hill, M. D. and J. R. Larus, </author> <title> Cache Considerations for Multiprocessor Programmers, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 33, No. </volume> <month> 8 , August </month> <year> 1990, </year> <pages> pp. 97-102. </pages>
Reference-contexts: Background: Dynamic Shared Memory Previous studies have observed that the dynamic shared memory programming model must include the notion of non-uniform memory access times, since programs developed using uniform memory access semantics have notoriously poor performance <ref> [Ande91, Cher91a, Hill90, Lin90, Mart89] </ref>. What is required is an approximate model of the coherence operations that provides a framework for assessing trade-offs between logically partitioning the data among the processes and balancing the computational load among the processes.
Reference: [Hill92] <author> Hill, M. D., J. R. Larus, S. K. Reinhardt and D. A. Wood, </author> <title> Cooperative Shared Memory: Software and Hardware for Scalable Multiprocessors, </title> <booktitle> 5th Int'l. Conf. on Architectural Support for Programming Languages and Systems, </booktitle> <pages> Boston , pp. 262-273, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: These opera tions allow a prefetch to be issued early and to remain pending in the memory system until a new value is released by another processor. Recent examples include QOLB [Jame90], Notify [Cher91b], and cooperative pre fetch <ref> [Hill92] </ref>. The advantages of the SM/MP primitives include: 1) simpler hardware support, 2) more general and efficient support for multiple consumers, 3) lower overhead and a simpler programming model in many cases (such as those illustrated in section 3.2).
Reference: [Jame90] <author> James, D. V., A. T. Laundrie, S. Gjessing and G. S. Sohi, </author> <title> Distributed-Directory Scheme: Scalable Coherent Interface, </title> <journal> IEEE Computer, </journal> <volume> Vol. 23, No. </volume> <month> 6 , June </month> <year> 1990, </year> <pages> pp. 74-77. </pages>
Reference-contexts: These opera tions allow a prefetch to be issued early and to remain pending in the memory system until a new value is released by another processor. Recent examples include QOLB <ref> [Jame90] </ref>, Notify [Cher91b], and cooperative pre fetch [Hill92]. The advantages of the SM/MP primitives include: 1) simpler hardware support, 2) more general and efficient support for multiple consumers, 3) lower overhead and a simpler programming model in many cases (such as those illustrated in section 3.2).
Reference: [Kran93] <author> Kranz, D., K. Johnson, A. Agarwal, J. Kubiatowicz and B. Lim, </author> <title> Integrating Message-Passing and Shared-Memory: </title> <note> Early Experience, to appear Symp. on Principles and Practice of Parallel Programming (PPoPP), </note> <month> May </month> <year> 1993. </year>
Reference-contexts: They also propose that the software use the local-only operations for private variables, to avoid false-sharing conflicts in some cases where private and shared data are assigned to the same cache block. Kranz et. al. have recently proposed integrating message-passing primitives into dynamic shared memory systems <ref> [Kran93] </ref>. Their principle motivations were to bundle data into large messages, and to combine synchronization with data transfer. Key differences in the SM/MP approach include: 1) the MP primitives are embedded in the shared memory hardware, and 2) SM/MP messages do not interrupt the destination processor.
Reference: [Lee91] <author> Lee, J. and U. Ramachandran, </author> <title> Architectural Primitives for a Scalable Shared Memory Multiprocessor, </title> <booktitle> 3rd ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pp. 103-114, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Lee and Ramachandran <ref> [Lee91] </ref> have proposed a selec-tive WRITE-GLOBAL primitive, as well as primitives that read and write only the local cache, to support implementing a weak-consistency coherence model in software.
Reference: [Leno92] <author> Lenoski, D., J. Laudon, K. Gharachorloo, W. Weber, A. Gupta, J. Hennessy, M. Horowitz and M. S. Lam, </author> <title> The Stanford Dash Multiprocessor, </title> <journal> Computer, </journal> <volume> Vol. 25, No. </volume> <month> 3 , March </month> <year> 1992, </year> <pages> pp. 63-79. </pages>
Reference-contexts: Whether synchronized prefetching or synchronized MP prefetching would be desirable in an SM/MP system is an open question. Write-update operations, which update rather than invalidate all copies of a block whenever a particular pro cessor writes the block, are available in some systems <ref> [Leno92] </ref> and have recently been advocated as a tech nique for overlapping communication and computation in SM systems [Cart91, Rost93]. Our SM/MP primitives have some features in common with write-update primi tives.
Reference: [Lin90] <author> Lin, C. and L. Snyder, </author> <title> A Comparison of Programming Models for Shared Memory Multiprocessors, </title> <booktitle> Int'l. Conf. on Parallel Processing, Vol. II , August 1990, </booktitle> <pages> pp. 163-170. </pages>
Reference-contexts: Background: Dynamic Shared Memory Previous studies have observed that the dynamic shared memory programming model must include the notion of non-uniform memory access times, since programs developed using uniform memory access semantics have notoriously poor performance <ref> [Ande91, Cher91a, Hill90, Lin90, Mart89] </ref>. What is required is an approximate model of the coherence operations that provides a framework for assessing trade-offs between logically partitioning the data among the processes and balancing the computational load among the processes.
Reference: [Mart89] <author> Martonosi, M. and A. Gupta, </author> <title> Tradeoffs in Message-Passing and Shared-Memory Implementations of a Standard Cell Router, </title> <booktitle> Proc. Int'l. Conf. on Parallel Processing, Vol. III , August 1989, </booktitle> <pages> pp. 88-96. </pages>
Reference-contexts: Background: Dynamic Shared Memory Previous studies have observed that the dynamic shared memory programming model must include the notion of non-uniform memory access times, since programs developed using uniform memory access semantics have notoriously poor performance <ref> [Ande91, Cher91a, Hill90, Lin90, Mart89] </ref>. What is required is an approximate model of the coherence operations that provides a framework for assessing trade-offs between logically partitioning the data among the processes and balancing the computational load among the processes.
Reference: [Rost93] <author> Rosti, E., E. Smirni, T. D. Wagner, A. W. Apon and L. W. Dowdy, </author> <title> The KSR1: Experimentation and Modeling of Poststore, </title> <booktitle> to appear Proc. of the 1993 ACM Sigmetrics Conference, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: Write-update operations, which update rather than invalidate all copies of a block whenever a particular pro cessor writes the block, are available in some systems [Leno92] and have recently been advocated as a tech nique for overlapping communication and computation in SM systems <ref> [Cart91, Rost93] </ref>. Our SM/MP primitives have some features in common with write-update primi tives.
Reference: [Schn89] <author> Schneider, D. A. and D. J. DeWitt, </author> <title> A Performance Evaluation of Four Parallel Join Algorithms in a Shared-Nothing Multiprocessor Environment, </title> <booktitle> Proc. 1989 SIGMOD Conf., </booktitle> <address> Portland, Oregon , June 1989. </address>
Reference-contexts: In this example, the MP primitives are highly efficient, whereas standard prefetching or update-write operations would have significantly higher overhead. The second example is one in which two processes communicate via a circular buffer, as is often done in pipelined and other course-grain dataflow algorithms (e.g., <ref> [Schn89] </ref>). In contrast to the previous example, the possibly-stale copies are known to be up-to-date at the time of the MP-read operations.
References-found: 16

