URL: ftp://speech.cse.ogi.edu/pub/docs/imposter94.ps.Z
Refering-URL: http://www.cse.ogi.edu/CSLU/publications/publications.html
Root-URL: http://www.cse.ogi.edu
Title: DETECTING AN IMPOSTER IN TELEPHONE SPEECH  
Author: Johan Schalkwyk, Etienne Barnard, Ronald A. Coleyand Jeffrey R. Sachsz zDaniel H. Wagner 
Keyword: Imposter Detection, Speaker Verification  
Affiliation: Oregon Graduate Institute  Associates, Sunnyvale, California  
Note: yCenter for Spoken Language Understanding,  
Abstract: This paper presents initial results on imposter detection in telephone speech. The imposter detector problem is defined in terms of a real-world security problem. Perceptual studies are then presented. These studies present a good estimate on the difficulty of the task at hand; it is found that humans classify approximately 85.6% of our benchmark utterances correctly. To design an automatic imposter detector, features which elicit speaker differences are studied. A baseline system based only on 20'th order Linear Predictive Coefficients (LPC) classifies 75.0% of the test set correctly. By extracting features only in vowel and semi-vowel regions, i.e. where the all-pole model of the linear predictor is most accurate, the classification performance is increased to 80.0%. Further features such as average energy and median pitch result in a correct classification rate of 83.7%, comparable to the perceptual benchmarks. Results are also presented for Mandarin, Japanese and Spanish. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E.Barnard and R.A.Cole. </author> <title> A neural-net training program based on conjugate-gradient descent optimization. </title> <type> Technical Report CSE 89-014, </type> <institution> Oregon Graduate Institute, </institution> <year> 1989. </year>
Reference-contexts: Features are extracted for each portion of speech separately, and then used as input to a discriminative classifier (in this case, we experimented with a simple distance-based classifier and a neural network). All neural-network classifiers used are fully connected feed-forward networks trained using backpropagation with conjugate- gradient optimization <ref> [1] </ref>. The number of hidden nodes used was determined experimentally. The crux of the classification problem, as in most classification problems, lies in the measurement of features.
Reference: [2] <author> P.Schmid M.Fanty and R.A.Cole. </author> <title> City name recognition over the telephone. </title> <booktitle> In International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 549-552, </pages> <address> Min-neapolis, MI, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: This approach is conceptually similar to methods that have been used in speaker identification with much success [3, 4], in that the acoustic vectors of sounds with similar hypothesized identities are used for classification. The system described in this section makes use of a neural-network phonetic front-end <ref> [2] </ref> in order to select the segments for which the feature representation will be calculated. The classifier used for all our experiments agrees with hand labeled segments 48% of the time using a set of 39 phonemes.
Reference: [3] <author> A.Tsopanoglou N.Fakotakis and G.Kokkinakis. </author> <title> A text-independent speaker recognition system based on vowel spotting. </title> <booktitle> In Proceedings Internation Conference on Spoken Language Processing 92, </booktitle> <year> 1991. </year>
Reference-contexts: This approach is conceptually similar to methods that have been used in speaker identification with much success <ref> [3, 4] </ref>, in that the acoustic vectors of sounds with similar hypothesized identities are used for classification. The system described in this section makes use of a neural-network phonetic front-end [2] in order to select the segments for which the feature representation will be calculated.
Reference: [4] <author> T.Matsui and S.Furui. </author> <title> Speaker recognition using concatenated phoneme models. </title> <booktitle> In Proceedings Internation Conference on Spoken Language Processing 92, </booktitle> <pages> pages 603-606, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: This approach is conceptually similar to methods that have been used in speaker identification with much success <ref> [3, 4] </ref>, in that the acoustic vectors of sounds with similar hypothesized identities are used for classification. The system described in this section makes use of a neural-network phonetic front-end [2] in order to select the segments for which the feature representation will be calculated.
Reference: [5] <author> T.Matsui and S.Furui. </author> <title> Concatenated phoneme models for text-variable speaker recognition. </title> <booktitle> In International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 391-394, </pages> <address> Minneapolis, MI, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: Thus, one would have a set of inputs which contain the average features of the vowel `ah' in each segment; another set of inputs for the average features of `ih', etc. This is closely related to the most successful speaker identification algorithms <ref> [5] </ref> currently used. We have conducted a set of experiments by only extracting features for the four phonemes that are most commonly recognized by the neural-network phonetic front-end. These are [ah] as in `but', [ih] as in `bit', [aw] as in `pout' and [iy] as in `beet'.
Reference: [6] <author> R.A.Cole Y.K.Muthusamy and B.T.Oshika. </author> <title> The ogi-multi language telephone speech corpus. </title> <booktitle> In Proceedings International Conference on Spoken Language Processing 92, </booktitle> <pages> pages 895-898, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: The imposter detection algorithms were developed and evaluated using only male English speakers in the OGI Multi-language Telephone Speech Corpus, described in <ref> [6] </ref>. 3. PERCEPTUAL STUDIES In order to get a good estimate on the difficulty of the classification problem at hand, a set of perceptual experiments were conducted. For this experiment we used all the male speakers in the Mandarin database of the OGI Multi-Language Telephone Speech Corpus [6]. (Including speakers of <p> Corpus, described in <ref> [6] </ref>. 3. PERCEPTUAL STUDIES In order to get a good estimate on the difficulty of the classification problem at hand, a set of perceptual experiments were conducted. For this experiment we used all the male speakers in the Mandarin database of the OGI Multi-Language Telephone Speech Corpus [6]. (Including speakers of different genders would make the problem trivial in many cases, as would including utterances in a language which is familiar to the experimental subjects.) Our experimental design attempts to force subjects to focus on segments. acoustical cues only in order to make a decision.
References-found: 6

