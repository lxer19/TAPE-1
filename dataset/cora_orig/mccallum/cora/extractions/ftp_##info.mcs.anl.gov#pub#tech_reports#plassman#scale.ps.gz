URL: ftp://info.mcs.anl.gov/pub/tech_reports/plassman/scale.ps.gz
Refering-URL: http://www.mcs.anl.gov/sumaa3d/Papers/papers.html
Root-URL: http://www.mcs.anl.gov
Title: THE SCALABILITY OF MESH IMPROVEMENT ALGORITHMS  
Author: LORI F. FREITAG MARK T. JONES AND PAUL E. PLASSMANN 
Keyword: Key words. Adaptive mesh refinement, distributed memory computers, edge flipping, mesh improvement, mesh smoothing, parallel algorithms, unstructured mesh computation.  
Note: AMS(MOS) subject classifications. Primary 65N50, 65Y05, 68Q20, 68Q22.  
Abstract: In this paper we develop a common framework to explore the scalability of three improvement strategies for unstructured meshes: adaptive refinement, vertex smoothing, and edge flipping. We give a general parallel algorithm for these strategies based on defining, for each algorithm, an elemental operation and a task graph. By choosing the correct task graph, we can ensure the correct parallel execution of the algorithms independent of implementation. Finally, we present experimental results obtained on an IBM SP system and use these results to investigate, in practice, the scaling and relative costs of these algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Amenta, M. Bern, and D. Eppstein, </author> <title> Optimal point placement for mesh smoothing, </title> <booktitle> in 8th ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <address> New Orleans, </address> <note> to appear. </note>
Reference-contexts: Optimization-based smoothing techniques guarantee valid meshes, allow for a variety of mesh quality measures, and, if carefully implemented, can be computationally affordable <ref> [1] </ref> [4] [8] [10] [26]. In [8] and [10], a local smoothing algorithm is given based on optimization techniques for nondifferentiable functions. This algorithm moves vertices in a manner guaranteed to maintain or improve mesh quality.
Reference: [2] <author> I. Babu ska and A. K. Aziz, </author> <title> On the angle condition in the finite element method, </title> <journal> SIAM Journal of Numerical Analysis, </journal> <volume> 13 (1976), </volume> <pages> pp. 214-226. </pages>
Reference-contexts: For example, in the two-dimensional case it is known that the accuracy of the finite-element approximation degrades as the maximum interior angle of an element approaches <ref> [2] </ref>; further, the condition number of the resulting matrices grow as O ( 1 min ), where min is the minimum interior angle of the mesh [11]. The same basic principles apply in three dimensions; however, more complex measures of element quality are required as discussed in [19].
Reference: [3] <author> R. E. Bank, A. H. Sherman, and A. Weiser, </author> <title> Refinement algorithms and data structures for regular local mesh refinement, in Scientific Computing, </title> <editor> R. Stepleman et al., ed., </editor> <publisher> IMACS/North-Holland Publishing Company, </publisher> <address> Ams-terdam, </address> <year> 1983, </year> <pages> pp. 3-17. </pages>
Reference-contexts: Element Division. The two viable techniques for dividing a triangle, regular refinement and bisection, are shown in Figure 2. Several algorithms for two-dimensional simplicial mesh refinement have been proposed that use one or both of these techniques <ref> [3] </ref> [23] [24]. All of these methods have the property that the interior angles of all the resulting triangles are bounded away from 0 and . <p> THE SCALABILITY OF MESH IMPROVEMENT ALGORITHMS 19 If this were a problem, one could modify the bisection algorithm by introducing a temporary green edge <ref> [3] </ref> to make the mesh conforming, as shown in the figure on the right in Figure 22. This green edge would be removed prior to the next level of refinement and the nonconforming element marked for refinement.
Reference: [4] <author> R. E. Bank and R. K. Smith, </author> <title> Mesh smoothing using a posteriori error estimates, </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 34 (1997), </volume> <pages> pp. 979-997. </pages>
Reference-contexts: Optimization-based smoothing techniques guarantee valid meshes, allow for a variety of mesh quality measures, and, if carefully implemented, can be computationally affordable [1] <ref> [4] </ref> [8] [10] [26]. In [8] and [10], a local smoothing algorithm is given based on optimization techniques for nondifferentiable functions. This algorithm moves vertices in a manner guaranteed to maintain or improve mesh quality.
Reference: [5] <author> E. B ansch, </author> <title> Local mesh refinement in 2 and 3 dimensions, </title> <booktitle> Impact of Computing in Science and Engineering, 3 (1991), </booktitle> <pages> pp. 181-191. </pages>
Reference-contexts: An algorithm for three dimensional simplicial mesh refinement, based on the selective bisection of tetrahedra, has been proven to result in meshes for which the quality of the resulting tetrahedra is bounded independent of the number of levels of refinement <ref> [5] </ref> [20]. Generally, it is not sufficient to divide only those triangles that have been selected for refinement; such an approach typically results in a mesh that is not conforming.
Reference: [6] <author> N. Dyn, D. Levin, and S. Rippa, </author> <title> Data dependent triangulations for piecewise linear interpolation, </title> <journal> IMA J. Numer. Anal., </journal> <volume> 10 (1990), </volume> <pages> pp. 137-154. </pages>
Reference-contexts: The longest edge refinement algorithm is used to create the conforming mesh. At each step of this algorithm, all nonconforming triangles are bisected across their longest edge. other metrics exist; for example, some use error estimates of an existing PDE solution on the mesh to evaluate potential flips <ref> [6] </ref>. However, all are local in these sense that the criteria can be evaluated by using information local to the elements involved in the flip. Fig. 5.
Reference: [7] <author> D. A. </author> <title> Field, Laplacian smoothing and Delaunay triangulations, Communications and Applied Numerical Methods, </title> <booktitle> 4 (1988), </booktitle> <pages> pp. 709-712. </pages>
Reference-contexts: The local optimization problem must be inexpensive to compute, as it is typically solved one or more times for every vertex in the mesh. In elements and vertices for which information is required are shaded. The simplest and least expensive local mesh-smoothing technique is Laplacian smoothing <ref> [7] </ref> [21]. In this technique, the position of a vertex v is adjusted to be the average of the positions of its neighbors.
Reference: [8] <author> L. A. Freitag, M. T. Jones, and P. E. Plassmann, </author> <title> An efficient parallel algorithm for mesh smoothing, </title> <booktitle> in Proceedings of the Fourth International Meshing Roundtable, </booktitle> <institution> Sandia National Laboratories, </institution> <year> 1995, </year> <pages> pp. </pages> <month> 47-58. </month> <title> [9] , A parallel algorithm for mesh smoothing, </title> <type> Preprint ANL/MCS-P668-0697, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <year> 1997. </year>
Reference-contexts: Optimization-based smoothing techniques guarantee valid meshes, allow for a variety of mesh quality measures, and, if carefully implemented, can be computationally affordable [1] [4] <ref> [8] </ref> [10] [26]. In [8] and [10], a local smoothing algorithm is given based on optimization techniques for nondifferentiable functions. This algorithm moves vertices in a manner guaranteed to maintain or improve mesh quality. <p> Optimization-based smoothing techniques guarantee valid meshes, allow for a variety of mesh quality measures, and, if carefully implemented, can be computationally affordable [1] [4] <ref> [8] </ref> [10] [26]. In [8] and [10], a local smoothing algorithm is given based on optimization techniques for nondifferentiable functions. This algorithm moves vertices in a manner guaranteed to maintain or improve mesh quality.
Reference: [10] <author> L. A. Freitag and C. F. Ollivier-Gooch, </author> <title> Tetrahedral mesh improvement using face swapping and smoothing, International Journal for Numerical Methods in Engineering, (to appear). THE SCALABILITY OF MESH IMPROVEMENT ALGORITHMS 27 </title>
Reference-contexts: Optimization-based smoothing techniques guarantee valid meshes, allow for a variety of mesh quality measures, and, if carefully implemented, can be computationally affordable [1] [4] [8] <ref> [10] </ref> [26]. In [8] and [10], a local smoothing algorithm is given based on optimization techniques for nondifferentiable functions. This algorithm moves vertices in a manner guaranteed to maintain or improve mesh quality. <p> Optimization-based smoothing techniques guarantee valid meshes, allow for a variety of mesh quality measures, and, if carefully implemented, can be computationally affordable [1] [4] [8] <ref> [10] </ref> [26]. In [8] and [10], a local smoothing algorithm is given based on optimization techniques for nondifferentiable functions. This algorithm moves vertices in a manner guaranteed to maintain or improve mesh quality. <p> Fortunately, empirical results indicate that a small, constant number of sweeps through all the elements suffice to produce a mesh whose 20 LORI F. FREITAG, MARK T. JONES, AND PAUL E. PLASSMANN quality is not improved significantly by additional smoothing passes <ref> [10] </ref>. 4. Experimental Results. In this section we present experimental results that demonstrate the parallel performance of the mesh improvement algorithms. These results are based on the adaptive solution of two finite-element applications for a sequence of problem sizes. <p> The smoothing technique used for these results is a combined Laplacian/optimization-based smoothing technique using the minimum sine of element angle as the quality measure <ref> [10] </ref>. The results presented in the remainder of this section are run on 32 processors of the SP.
Reference: [11] <author> I. Fried, </author> <title> Condition of finite element matrices generated from nonuniform meshes, </title> <journal> AIAA Journal, </journal> <volume> 10 (1972), </volume> <pages> pp. 219-221. </pages>
Reference-contexts: in the two-dimensional case it is known that the accuracy of the finite-element approximation degrades as the maximum interior angle of an element approaches [2]; further, the condition number of the resulting matrices grow as O ( 1 min ), where min is the minimum interior angle of the mesh <ref> [11] </ref>. The same basic principles apply in three dimensions; however, more complex measures of element quality are required as discussed in [19].
Reference: [12] <author> P. Green and R. Sibson, </author> <title> Computing Dirichelet tesselations in the plane, </title> <journal> The Computer Journal, </journal> <volume> 21 (1977), </volume> <pages> pp. 168-173. </pages>
Reference-contexts: The most commonly used criterion is maximizing the minimum interior angle (maxmin angle). That is, the edge is flipped if the minimum angle in the resulting two triangles is larger than the minimum angle in the original two triangles <ref> [12] </ref>.
Reference: [13] <author> B. Joe, </author> <title> Construction of three-dimensional improved-quality triangulations using local transformations, </title> <journal> SIAM Journal on Scientific Computing, </journal> <volume> 16 (1995), </volume> <pages> pp. 1292-1307. </pages>
Reference-contexts: Edge Flipping. Edge flipping can be used to improve mesh quality in several contexts. The fundamental operation, in two dimensions, is to flip an edge shared by two triangles and, in three dimensions, to flip one or more tetrahedral faces <ref> [13] </ref> [18]. We illustrate such a flip for a triangle pair in Figure 5. An edge is flipped to improve a mesh quality metric; it is a local optimization technique that attempts to improve overall mesh quality. The most commonly used criterion is maximizing the minimum interior angle (maxmin angle).
Reference: [14] <author> M. T. Jones and P. E. Plassmann, </author> <title> A parallel graph coloring heuristic, </title> <journal> SIAM Journal on Scientific Computing, </journal> <volume> 14 (1993), </volume> <pages> pp. </pages> <month> 654-669. </month> <title> [15] , BlockSolve95 users manual: Scalable library software for the parallel solution of sparse linear systems, </title> <type> ANL Report ANL-95/48, </type> <institution> Argonne National Laboratory, Argonne, Ill., </institution> <month> Dec. </month> <year> 1995. </year> <title> [16] , Parallel algorithms for adaptive mesh refinement, </title> <journal> SIAM Journal on Scientific Computing, </journal> <volume> 18 (1997), </volume> <pages> pp. </pages> <month> 686-708. </month> <title> [17] , A parallel mesh improvement algorithm, </title> <type> Preprint ANL/MCS-P675-0797, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <year> 1997. </year>
Reference-contexts: This model underestimates the cost of interprocessor communication, and operations such as global reductions, which involve expensive synchronizations between the processors, are unrealistically cheap. Fortunately, the algorithms considered here run in an asynchronous style that requires only individual processor-to-processor communication and at most a small number of global reductions <ref> [14] </ref>. Thus, the performance of these algorithms is predicted fairly well by the PRAM model. For the PRAM analysis, we assume that the number of processors is equal to the number of tasks jSj. Let the maximum time required to execute any of the elemental operations be t max . <p> We can use the fact that these task graphs have bounded degree to obtain bounds for the scaling of j G as given in Equation 3.1. In <ref> [14] </ref> it is shown that a vertex coloring of a bounded degree graph G, with n = jV j, can be found by a randomized algorithm in expected time EO (log (n)= log log (n)) under the PRAM computational model using O (n) processors. <p> The greedy algorithm presented in <ref> [14] </ref> shows that every vertex can be colored in EO (log (n)= log log (n)) time by coloring the independent set chosen by the Monte Carlo rule, deleting these vertices from the set of vertices remaining to be colored, and reapplying this process until all the vertices are colored. In [14] <p> <ref> [14] </ref> shows that every vertex can be colored in EO (log (n)= log log (n)) time by coloring the independent set chosen by the Monte Carlo rule, deleting these vertices from the set of vertices remaining to be colored, and reapplying this process until all the vertices are colored. In [14] it is shown that a distributed-memory implementation of this algorithm is efficient in practice. In a distributed-memory implementation the vertices can be divided into local and global sets.
Reference: [18] <author> C. L. Lawson, </author> <title> Software for C 1 surface interpolation, in Mathematical Software III, </title> <editor> J. R. Rice, ed., </editor> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1977, </year> <pages> pp. 161-194. </pages>
Reference-contexts: Edge Flipping. Edge flipping can be used to improve mesh quality in several contexts. The fundamental operation, in two dimensions, is to flip an edge shared by two triangles and, in three dimensions, to flip one or more tetrahedral faces [13] <ref> [18] </ref>. We illustrate such a flip for a triangle pair in Figure 5. An edge is flipped to improve a mesh quality metric; it is a local optimization technique that attempts to improve overall mesh quality. The most commonly used criterion is maximizing the minimum interior angle (maxmin angle). <p> This scheme results in a Delaunay triangulation, a triangulation with maximum minimum angle with respect to all other possible triangulations that contain only those vertices <ref> [18] </ref>. 1 Many 1 While similar criteria can improve the quality of the mesh in three dimensions, there is no guarantee that the resulting mesh will be optimal with respect to all other possible meshes containing only those vertices. THE SCALABILITY OF MESH IMPROVEMENT ALGORITHMS 5 Fig. 4.
Reference: [19] <author> A. Liu and B. Joe, </author> <title> Relationship between tetrahedron shape measures, </title> <journal> BIT, </journal> <volume> 34 (1994), </volume> <pages> pp. </pages> <month> 268-287. </month> <title> [20] , Quality local refinement of tetrahedral meshes based on bisection, </title> <journal> SIAM Journal on Scientific Computing, </journal> <volume> 16 (1995), </volume> <pages> pp. 1269-1291. </pages>
Reference-contexts: The same basic principles apply in three dimensions; however, more complex measures of element quality are required as discussed in <ref> [19] </ref>. Adaptive refinement of a mesh, using element division, seeks to improve the solution quality by increasing the number of elements and vertices in areas of the domain where the discretization error is large.
Reference: [21] <author> S. H. Lo, </author> <title> A new mesh generation scheme for arbitrary planar domains, International Journal for Numerical Methods in Engineering, </title> <booktitle> 21 (1985), </booktitle> <pages> pp. 1403-1426. </pages>
Reference-contexts: The local optimization problem must be inexpensive to compute, as it is typically solved one or more times for every vertex in the mesh. In elements and vertices for which information is required are shaded. The simplest and least expensive local mesh-smoothing technique is Laplacian smoothing [7] <ref> [21] </ref>. In this technique, the position of a vertex v is adjusted to be the average of the positions of its neighbors.
Reference: [22] <author> M. Luby, </author> <title> A simple parallel algorithm for the maximal independent set problem, </title> <journal> SIAM Journal on Computing, </journal> <volume> 4 (1986), </volume> <pages> pp. 1036-1053. </pages>
Reference-contexts: This coloring uses at most (G) + 1 colors. The randomized algorithm is motivated by a Monte Carlo rule for finding independent sets introduced by Luby <ref> [22] </ref>. The rule works by assigning to each vertex, v, in the graph an independent random number ae (v) and making the observation that the set, I = fv 2 V j ae (v) &gt; ae (u); 8u 2 adj (v)g, is an independent set in G.
Reference: [23] <author> W. F. Mitchell, </author> <title> A comparison of adaptive refinement techniques for elliptic problems, </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 15 (1989), </volume> <pages> pp. 326-347. </pages>
Reference-contexts: Element Division. The two viable techniques for dividing a triangle, regular refinement and bisection, are shown in Figure 2. Several algorithms for two-dimensional simplicial mesh refinement have been proposed that use one or both of these techniques [3] <ref> [23] </ref> [24]. All of these methods have the property that the interior angles of all the resulting triangles are bounded away from 0 and .
Reference: [24] <author> M.-C. Rivara, </author> <title> Mesh refinement processes based on the generalized bisection of simplices, </title> <journal> SIAM Journal of Numerical Analysis, </journal> <volume> 21 (1984), </volume> <pages> pp. 604-613. </pages>
Reference-contexts: Element Division. The two viable techniques for dividing a triangle, regular refinement and bisection, are shown in Figure 2. Several algorithms for two-dimensional simplicial mesh refinement have been proposed that use one or both of these techniques [3] [23] <ref> [24] </ref>. All of these methods have the property that the interior angles of all the resulting triangles are bounded away from 0 and . <p> The Elemental Operation for Refinement. Consider the refinement algorithm given in Figure 3 where we use bisection for element subdivision. We refer to this refinement approach as Rivara's bisection algorithm <ref> [24] </ref>. Thus, the tasks S are the bisection of some subset of elements, T 0 T , marked for refinement. Unfortunately, we cannot arbitrarily refine elements in parallel and maintain coherency of the distributed data structure. For example, in adjacent elements are refined simultaneously.
Reference: [25] <author> I. G. Rosenberg and F. Stenger, </author> <title> A lower bound on the angles of triangles constructed by bisecting the longest side, </title> <journal> Mathematics of Computation, </journal> <volume> 29 (1975), </volume> <pages> pp. 390-395. </pages>
Reference-contexts: We assume that this minimum angle is a property of the domain geometry and independent of the mesh size. Rivara's bisection algorithm generates a refined mesh whose minimum angle is no smaller than min =2 <ref> [25] </ref>. Thus, the maximum number of vertices any vertex can be adjacent to in G V is bounded by 4= min . G T The version of Rivara's algorithm we use guarantees that any edge in the triangulation can have at most one nonconforming vertex. <p> The initial angle in the coarse mesh is 8.650 o . The bisection-based refinement technique tends to have a slightly detrimental effect on the minimum angle, but is well within the theoretical bound <ref> [25] </ref>. Both the flipping and smoothing techniques improve the minimum angle in the mesh every iteration. Smoothing is somewhat more effective than flipping and improves the minimum angle in the mesh to roughly 30 o every iteration. 5. Concluding Remarks.
Reference: [26] <author> M. Shephard and M. Georges, </author> <title> Automatic three-dimensional mesh generation by the finite octree technique, International Journal for Numerical Methods in Engineering, </title> <booktitle> 32 (1991), </booktitle> <pages> pp. 709-749. </pages>
Reference-contexts: Optimization-based smoothing techniques guarantee valid meshes, allow for a variety of mesh quality measures, and, if carefully implemented, can be computationally affordable [1] [4] [8] [10] <ref> [26] </ref>. In [8] and [10], a local smoothing algorithm is given based on optimization techniques for nondifferentiable functions. This algorithm moves vertices in a manner guaranteed to maintain or improve mesh quality.
References-found: 21

