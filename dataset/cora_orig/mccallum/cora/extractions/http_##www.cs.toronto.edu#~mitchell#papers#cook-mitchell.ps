URL: http://www.cs.toronto.edu/~mitchell/papers/cook-mitchell.ps
Refering-URL: http://www.cs.toronto.edu/~mitchell/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Finding Hard Instances of the Satisfiability Problem: A Survey  
Author: Stephen A. Cook and David G. Mitchell 
Note: DIMACS Series in Discrete Mathematics and Theoretical Computer Science V olume 35, 1997.  
Abstract: Finding sets of hard instances of propositional satisfiability is of interest for understanding the complexity of SAT, and for experimentally evaluating SAT algorithms. In discussing this we consider the performance of the most popular SAT algorithms on random problems, the theory of average case complexity, the threshold phenomenon, known lower bounds for certain classes of algorithms, and the problem of generating hard instances with solutions. 
Abstract-found: 1
Intro-found: 1
Reference: [APT79] <author> Bengt Aspvall, Michael F. Plass, and Robert Endre Tarjan. </author> <title> A linear-time algorithm for testing the truth of certain quantified boolean formulas. </title> <journal> Information Processing Letters, </journal> <volume> 8(3) </volume> <pages> 121-123, </pages> <month> March </month> <year> 1979. </year>
Reference-contexts: The restriction of SAT to instances where all clauses have length k is denoted k-SAT. Of special interest are 2-SAT and 3-SAT: 3 is the smallest value of k for which k-SAT is NP-complete [Coo71], while 2-SAT is solvable in linear time <ref> [EIS76, APT79] </ref>. Horn-SAT is the restriction to instances where each clause has at most one unnegated variable.
Reference: [Asp80] <author> Bengt Aspvall. </author> <title> Recognizing disguised NR(1) instances of the satisfiability problem. </title> <journal> Journal of Algorithms, </journal> <volume> 1 </volume> <pages> 97-103, </pages> <year> 1980. </year>
Reference-contexts: Horn-SAT is solvable in linear time [DG84], as are a number of generalizations such as Re-nameable Horn-SAT, the class of formulas that can be converted to Horn merely by renaming (reversing the sign) of some variables <ref> [Lew78, Asp80] </ref>, and Generalized Horn-SAT, an extension of Horn-SAT based on a nesting property [CH91, CCH + 90] (see also [CC92, SAFS95]).
Reference: [BS96] <author> Roberto J. Bayardo, Jr. and Robert Schrag. </author> <title> Using CSP look-back techniques to solve exceptionally hard SAT instances. </title> <booktitle> In Proc. of the Second Int'l Conf. on Principles and Practice of Constraint Programming, (Lecture Notes in Computer Science 1118), </booktitle> <pages> 46-60, </pages> <publisher> Springer, </publisher> <year> 1996. </year>
Reference-contexts: These appear in both random clause and fixed clause formula families in the "easy" region, where most instances are trivial to show satisfiable. However, such instances seem to be amenable to attack by one or more existing enhancements to backtracking <ref> [SK96, CA96, BS96] </ref>. Thus it appears that the hard formulas in the transition region for random k-SAT are the most useful random formulas of the kind we have so far discussed for evaluating the performance of algorithms. <p> Thus it appears that the hard formulas in the transition region for random k-SAT are the most useful random formulas of the kind we have so far discussed for evaluating the performance of algorithms. Recently Bayardo and Schrag <ref> [BS96] </ref> have FINDING HARD INSTANCES OF THE SATISFIABILITY PROBLEM 9 described "literal-regular 3-SAT" instances, which are like random 3-SAT instances, except the number of occurrences of each literal in an instance is forced to be the same.
Reference: [BA80] <author> Mordechai Ben-Ari. </author> <title> A simplified proof that regular resolution is exponential. </title> <journal> Information Processing Letters, </journal> <volume> 10(2) </volume> <pages> 96-98, </pages> <year> 1980. </year>
Reference-contexts: The computation of either DP60 or DPLL on an unsatisfiable input instance gives rise to a regular resolution proof for that instance whose number of lines is bounded by the number of steps in the computation. Hence the exponential lower bound on regular resolution proofs <ref> [Tse70, Gal77, BA80] </ref> gives rise to worst-case exponential lower bounds on the time required for both DP60 and DPLL, and the exponential lower bounds for general resolution [Hak85, Urq87] show that no smarter use of resolution will help.
Reference: [BCGL92] <author> S. Ben-David, B. Chor, O. Goldreich, and M. Luby. </author> <title> On the theory of average case complexity. </title> <journal> JCSS, </journal> <volume> 44, </volume> <pages> 193-219, </pages> <year> 1992. </year>
Reference-contexts: The theory of average-case completeness tells us that such distributions exist, but there is evidence that none of them is "natural". This theory was initiated by Levin [Lev86] and extensively developed by others (see <ref> [BCGL92] </ref> and [Gur91]). Traditionally it requires specification of a global distribution to all instances of a problem D.
Reference: [BAH + 94] <author> A. Beringer, G. Aschemann, H.H. Hoos, M. Metzger and A. Wei. </author> <title> GSAT versus Simulated Annealing. </title> <booktitle> In Proc. ECAI-94, </booktitle> <pages> pages 130-134, </pages> <year> 1994. </year>
Reference-contexts: Viewed schematically, these procedures bear considerable resemblance to simulated annealing (SA) [JAMS91], and suitably tuned versions of SA do in fact perform comparably with the algorithms just described <ref> [Sp93, BAH + 94, SKC94] </ref>. The basic SA algorithm for SAT begins with an initial random truth assignment, and repeats the following step; Pick a random variable, and compute ffi, the change in the number of un-satisfied clauses when the variable is flipped.
Reference: [BFU93] <author> A. Broder, A. Frieze, and E. Upfal. </author> <title> On the satisfiability and maximum satisfiability of random 3-CNF formulas. </title> <booktitle> In Proc. Fourth Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1993. </year>
Reference-contexts: This lower bound was given by Frieze and Suen [FS92] who, extending previous work by Chao and Franco [CF90], and Broder, Frieze and Upfal <ref> [BFU93] </ref>, gave an algorithm GUCB which, with probability tending to 1, finds a satisfying truth assignment (in polynomial time) for instances of random 3-SAT whenever c &lt; 3:003.
Reference: [CA96] <author> J.M. Crawford and L.D. Auton. </author> <title> Experimental results on the cross-over point in random 3-SAT. </title> <journal> Artificial Intelligence, </journal> <volume> 81 </volume> <pages> 31-57, </pages> <year> 1996. </year>
Reference-contexts: A wide range of heuristics can be found in the literature. In particular, Dubois and 4 STEPHEN A. COOK AND DAVID G. MITCHELL colleagues [DABC93], Crawford and Auton <ref> [CA96] </ref>, and Freeman [Fre94], have employed careful evaluation of heuristics in developing extremely fast implementations. Variants of DPLL work quite well in practice, and are probably the most widely known and used SAT testing methods. <p> These appear in both random clause and fixed clause formula families in the "easy" region, where most instances are trivial to show satisfiable. However, such instances seem to be amenable to attack by one or more existing enhancements to backtracking <ref> [SK96, CA96, BS96] </ref>. Thus it appears that the hard formulas in the transition region for random k-SAT are the most useful random formulas of the kind we have so far discussed for evaluating the performance of algorithms. <p> The known lower bounds result from analyzing specific algorithms, as explained above. Attempts have also been made to construct a quantitative model of the transition region based on empirical data. This also appears quite challenging (see <ref> [SK96, CA96] </ref>). 3.2. WalkSAT performance near the threshold. Random instances appear to be hardest when generated near the threshold ratio. DPLL and its variations are hopelessly slow on many instances of random 3-SAT at this ratio when n is much larger than 400. <p> Crawford and Auton studied the empirical scaling behavior of their implementation of a very refined version of DPLL, and found that the average solution cost grew roughly as 2 n=19:5 near the transition region, and something like 2 n=68 at higher ratios <ref> [CA96] </ref>. A slightly stronger proof system than resolution is the cutting plane system. Some work has been done using cutting planes in a SAT tester, for example [Hoo88].
Reference: [CCH + 90] <author> Vijaya Chandru, Collette R. Coullard, Peter L. Hammer, Miguel Monta~nez, and Xi-aorong Sun. </author> <title> On renamable horn and generalized horn functions. </title> <journal> Annals of Mathematics and Artificial Intelligence, </journal> <pages> pages 33-47, </pages> <year> 1990. </year>
Reference-contexts: Horn-SAT is solvable in linear time [DG84], as are a number of generalizations such as Re-nameable Horn-SAT, the class of formulas that can be converted to Horn merely by renaming (reversing the sign) of some variables [Lew78, Asp80], and Generalized Horn-SAT, an extension of Horn-SAT based on a nesting property <ref> [CH91, CCH + 90] </ref> (see also [CC92, SAFS95]). In what follows, we will use n for the number of variables in a formula, m for the number of clauses and k for the clause "length" (e.g., number of literals).
Reference: [CH91] <author> Vijaya Chandru and John Hooker. </author> <title> Extended Horn sets in propositional logic. </title> <journal> Journal of the ACM, </journal> <volume> 38(1): </volume> <pages> 205-221, </pages> <year> 1991. </year>
Reference-contexts: Horn-SAT is solvable in linear time [DG84], as are a number of generalizations such as Re-nameable Horn-SAT, the class of formulas that can be converted to Horn merely by renaming (reversing the sign) of some variables [Lew78, Asp80], and Generalized Horn-SAT, an extension of Horn-SAT based on a nesting property <ref> [CH91, CCH + 90] </ref> (see also [CC92, SAFS95]). In what follows, we will use n for the number of variables in a formula, m for the number of clauses and k for the clause "length" (e.g., number of literals).
Reference: [CF90] <author> M. Chao and J. Franco. </author> <title> Probabilistic analysis of a generalization of the unit-clause literal selection heuristics for the k satisfiability problem. </title> <journal> Information Sciences, </journal> <volume> 51 </volume> <pages> 289-314, </pages> <year> 1990. </year>
Reference-contexts: In the case of k = 3, the current bounds on the location of this threshold, if it exists, are 3:003 &lt; c fl &lt; 4:598. This lower bound was given by Frieze and Suen [FS92] who, extending previous work by Chao and Franco <ref> [CF90] </ref>, and Broder, Frieze and Upfal [BFU93], gave an algorithm GUCB which, with probability tending to 1, finds a satisfying truth assignment (in polynomial time) for instances of random 3-SAT whenever c &lt; 3:003.
Reference: [CR92] <author> V. Chvatal and B. Reed. </author> <title> Mick gets some (the odds are on his side). </title> <booktitle> In Proc. of the 33rd IEEE Symposium on the Foundations of Computer Science, </booktitle> <address> Pittsburgh, </address> <year> 1992. </year>
Reference-contexts: For the case of random 2-SAT, the conjecture has been shown true, and c fl = 1 <ref> [Goe92, CR92] </ref>. In the case of k = 3, the current bounds on the location of this threshold, if it exists, are 3:003 &lt; c fl &lt; 4:598.
Reference: [CS88] <author> Vasek Chvatal and Endre Szemeredi. </author> <title> Many hard examples for resolution. </title> <journal> Journal of the ACM, </journal> <volume> 35(4) </volume> <pages> 759-768, </pages> <year> 1988. </year>
Reference-contexts: From our point of view, the strongest lower bound for proof systems is due to Chvatal and Szemeredi <ref> [CS88] </ref>, since their bound yields an exponential lower bound on the average-case performance of DP60 and DPLL.
Reference: [CC92] <author> Michele Conforti and Gerard Cornuejols. </author> <title> A class of logic problems solvable by linear programming. </title> <booktitle> In Proc. of the 33rd IEEE Symposium on the Foundations of Computer Science, </booktitle> <address> Pittsburgh, </address> <year> 1992. </year>
Reference-contexts: [DG84], as are a number of generalizations such as Re-nameable Horn-SAT, the class of formulas that can be converted to Horn merely by renaming (reversing the sign) of some variables [Lew78, Asp80], and Generalized Horn-SAT, an extension of Horn-SAT based on a nesting property [CH91, CCH + 90] (see also <ref> [CC92, SAFS95] </ref>). In what follows, we will use n for the number of variables in a formula, m for the number of clauses and k for the clause "length" (e.g., number of literals).
Reference: [Coo71] <author> Stephen Cook. </author> <title> The complexity of theorem proving procedures. </title> <booktitle> In Proc. 3rd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 151-158, </pages> <address> New York, </address> <year> 1971. </year> <institution> Association for Computing Machinery. </institution>
Reference-contexts: The restriction of SAT to instances where all clauses have length k is denoted k-SAT. Of special interest are 2-SAT and 3-SAT: 3 is the smallest value of k for which k-SAT is NP-complete <ref> [Coo71] </ref>, while 2-SAT is solvable in linear time [EIS76, APT79]. Horn-SAT is the restriction to instances where each clause has at most one unnegated variable.
Reference: [Coo75] <author> Stephen Cook. </author> <title> Feasibly constructive proofs and the propositional calculus. </title> <booktitle> In Proc. 7th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> 83-97, </pages> <year> 1975. </year>
Reference-contexts: Exponential lower bounds have not been shown for some more powerful proof systems, such as Frege systems and extended Frege systems. A lower bound for extended Frege systems would yield a similar lower bound for any complete SAT tester whose correctness can be proved using feasibly constructive methods <ref> [Coo75, Kra95] </ref>. 6. Hard Satisfiable Instances As we mentioned, the known unconditional lower bounds apply only to hard unsatisfiable instances, and furthermore existing model finders perform remarkably well on satisfiable instances even near the difficult threshold ratio on random 3-SAT (see section 3.2).
Reference: [DLL62] <author> M. Davis, G. Logemann, and D. Loveland. </author> <title> A machine program for theorem-proving. </title> <journal> Communications of the ACM, </journal> <volume> 5 </volume> <pages> 394-397, </pages> <year> 1962. </year>
Reference-contexts: Indeed, DP60 seems ill-suited for use on satisfiable formulas, since many resolvents may be generated even when a satisfying assignment can be found easily by other methods. Davis, Logemann and Loveland <ref> [DLL62] </ref> found that in implementation DP60 generated an unmanageable number of resolvent clauses, and replaced the "elimination rule" with a "splitting rule". In this version, selecting a variable leads to two smaller sub-problems one for each truth value instead of a single, possibly large, sub-problem. <p> In the original version the rule used is; pick a variable occurring in the first clause of minimal length. The most popular rules currently are variants on ideas suggested in <ref> [DLL62, Gol79] </ref>, and described by Pretolani [Pre93] as Moms variable selection strategy: branch on a variable (or literal) with Maximum number of occurrences in minimum size clauses. A wide range of heuristics can be found in the literature. In particular, Dubois and 4 STEPHEN A. COOK AND DAVID G.
Reference: [DP60] <author> M. Davis and H. Putnam. </author> <title> A computing procedure for quantification theory. </title> <journal> Journal of the ACM, </journal> <volume> 7 </volume> <pages> 201-215, </pages> <year> 1960. </year>
Reference-contexts: Complete Methods. Since resolution is refutation complete, a simple method for testing satisfiability is to generate all possible resolvents, and then check FINDING HARD INSTANCES OF THE SATISFIABILITY PROBLEM 3 if the empty clause has been generated. Davis and Putnam <ref> [DP60] </ref> introduced a method (hereafter called DP60), in which variables are eliminated one-by-one from the formula by, at each step, generating all possible resolvents based on a chosen variable and then deleting all clauses mentioning that variable.
Reference: [DR94] <author> R. Dechter and I. Rish. </author> <title> Directional Resolution: The Davis-Putnam Procedure, Revisited. </title> <booktitle> In Proc. KR-94, </booktitle> <pages> 134-145, </pages> <year> 1994. </year>
Reference-contexts: However, the two methods perform quite differently on some problems, and are incomparable with respect to complexity analysis <ref> [Gol79, DR94] </ref>. The variable selection rule (*) may be as simple as choosing the first remaining variable in , or it may be quite sophisticated. In the original version the rule used is; pick a variable occurring in the first clause of minimal length.
Reference: [DG84] <author> W.F. Dowling and J.H. Gallier. </author> <title> Linear-time algorithms for testing the satisfiability of propositional Horn formulas. </title> <journal> Journal of Logic Programming, </journal> <volume> 1(3) </volume> <pages> 267-284, </pages> <year> 1984. </year>
Reference-contexts: Horn-SAT is the restriction to instances where each clause has at most one unnegated variable. Horn-SAT is solvable in linear time <ref> [DG84] </ref>, as are a number of generalizations such as Re-nameable Horn-SAT, the class of formulas that can be converted to Horn merely by renaming (reversing the sign) of some variables [Lew78, Asp80], and Generalized Horn-SAT, an extension of Horn-SAT based on a nesting property [CH91, CCH + 90] (see also [CC92,
Reference: [DABC93] <author> O. Dubois, P. Andre, Y. Boufkhad and J. Carlier. </author> <title> SAT versus UNSAT. In Cliques, Coloring, and Satisfiability: Second DIMACS Implementation Challenge, </title> <editor> David S. Johnson and Michael A. Trick (eds.), </editor> <booktitle> Dimacs Series in Discrete Mathematics and Computer Science (26), </booktitle> <publisher> American Mathematical Society, </publisher> <year> 1993. </year>
Reference-contexts: A wide range of heuristics can be found in the literature. In particular, Dubois and 4 STEPHEN A. COOK AND DAVID G. MITCHELL colleagues <ref> [DABC93] </ref>, Crawford and Auton [CA96], and Freeman [Fre94], have employed careful evaluation of heuristics in developing extremely fast implementations. Variants of DPLL work quite well in practice, and are probably the most widely known and used SAT testing methods.
Reference: [DB96] <author> O. Dubois, Y. Boufkhad. </author> <title> A General Upper Bound for the Satisfiability Threshold of Random r-SAT Formulae. </title> <type> Preprint, </type> <year> 1996. </year> <note> See also: </note> <institution> Les lois de tout our rein, in Pour la Science, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: The upper bound is due to Kirousis, Kranakas and Krizanc [KKK96], which improves previous bounds of 4.64 by Dubois and Boufkhad <ref> [DB96] </ref>, 4.78 by Kamath et al [KMPS94], and 5.19 reported by several authors. <p> This may help explain the success of local search methods on satisfiable instances.) The improved upper bounds given in <ref> [DB96, KKK96] </ref> are based on the observation that if an instance is satisfiable, then some assignment t maximally satisfies , meaning t satisfies , but flipping the value of t on any single variable from false to true falsifies .
Reference: [EIS76] <author> S. Even, A. Itai, and A Shamir. </author> <title> On the complexity of timetable and multi-commodity flow problems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 5(4), </volume> <year> 1976. </year> <title> FINDING HARD INSTANCES OF THE SATISFIABILITY PROBLEM 15 </title>
Reference-contexts: The restriction of SAT to instances where all clauses have length k is denoted k-SAT. Of special interest are 2-SAT and 3-SAT: 3 is the smallest value of k for which k-SAT is NP-complete [Coo71], while 2-SAT is solvable in linear time <ref> [EIS76, APT79] </ref>. Horn-SAT is the restriction to instances where each clause has at most one unnegated variable.
Reference: [FP83] <author> J. Franco and M. Paull. </author> <title> Probabilistic analysis of the Davis Putnam procedure for solving the satisfiability problem. </title> <journal> Discrete Applied Math, </journal> <volume> 5 </volume> <pages> 77-87, </pages> <year> 1983. </year>
Reference-contexts: It follows from Goldberg's work that, for any constant value of p, DPLL solves these formulas in time O (mn 2 ) on average. This first positive result was put in perspective by Franco and Paull <ref> [FP83] </ref>, who showed that it was a consequence of a favorable choice of distribution, rather than favorable properties of DPLL: A constant number of guesses of random truth assignments will find one that satisfies an instance from this family with probability tending to 1 as n grows. (More recently it has <p> Experimental study confirms this, as we discuss below. Franco also found that the fixed-clause length formulas took exponential time on average for DPLL when finding all solutions, and suggested this might be a more interesting distribution for study <ref> [FP83] </ref>. Fixed-clause-length formulas are generated by selecting clauses uniformly at random from the set of all possible (nontrivial) clauses of a given length. We call such sets random k-SAT. The empirical performance of a version of DPLL on random 3-SAT was investigated in [MSL92] (see Figure 1).
Reference: [FW97] <author> J. Franco and R.P. Swamanithan. </author> <title> Average Case Results for Satisfiability Algorithms Under the Random Clause Model. </title> <note> To appear in: Annals of Mathematics and Artificial Intelligence. </note>
Reference-contexts: The formulas not yet known to be solvable efficiently on average occur, roughly, when the expected clause length is a little less than ln (m). See the study by Franco and Swaminathan <ref> [FW97] </ref> for details. See also [Pur90, Fra86] for earlier work. It is worth noting that the algorithms involved are quite simple, and easily implemented. For most practical purposes, then, this family of formula distribution must be regarded as easy on average, and not a likely source of hard instances.
Reference: [Fra86] <author> John Franco. </author> <title> On the probabilistic performance of algorithms for the satisfiability problem. </title> <journal> Information Processing Letters, </journal> <volume> 23 </volume> <pages> 103-106, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: The formulas not yet known to be solvable efficiently on average occur, roughly, when the expected clause length is a little less than ln (m). See the study by Franco and Swaminathan [FW97] for details. See also <ref> [Pur90, Fra86] </ref> for earlier work. It is worth noting that the algorithms involved are quite simple, and easily implemented. For most practical purposes, then, this family of formula distribution must be regarded as easy on average, and not a likely source of hard instances.
Reference: [Fre94] <author> J.W. Freeman. </author> <title> Improvements to propositional satisfiability search algorithms., </title> <type> Doctoral Dissertation, </type> <institution> University of Pennsylvania, </institution> <address> Philadelphia, PA, </address> <year> 1994. </year>
Reference-contexts: A wide range of heuristics can be found in the literature. In particular, Dubois and 4 STEPHEN A. COOK AND DAVID G. MITCHELL colleagues [DABC93], Crawford and Auton [CA96], and Freeman <ref> [Fre94] </ref>, have employed careful evaluation of heuristics in developing extremely fast implementations. Variants of DPLL work quite well in practice, and are probably the most widely known and used SAT testing methods.
Reference: [FS92] <author> A. Frieze and S. Suen. </author> <title> Analysis of three simple heuristics on a random instance of k-SAT. </title> <type> Preprint, </type> <year> 1992. </year> <note> To appear in Journal of Algorithms. </note>
Reference-contexts: In the case of k = 3, the current bounds on the location of this threshold, if it exists, are 3:003 &lt; c fl &lt; 4:598. This lower bound was given by Frieze and Suen <ref> [FS92] </ref> who, extending previous work by Chao and Franco [CF90], and Broder, Frieze and Upfal [BFU93], gave an algorithm GUCB which, with probability tending to 1, finds a satisfying truth assignment (in polynomial time) for instances of random 3-SAT whenever c &lt; 3:003.
Reference: [Fu95] <author> Xudong Fu. </author> <title> The complexity of the resolution proofs for the random set of clauses. </title> <type> Preprint, </type> <year> 1995. </year>
Reference-contexts: Notice however that if c is not a constant and exceeds n 2 then sub-linear length proofs almost surely exist <ref> [Fu95, MS95] </ref>. The experimental finding that random 3-SAT with large c is easy is not in conflict with the exponential lower bound for large (constant) ratios, but only shows that at a given n these are much easier than formulas in the transition region.
Reference: [Gal77] <author> Zvi Galil. </author> <title> On the complexity of regular resolution and the Davis-Putnam procedure. </title> <journal> Theoretical Computer Science, </journal> <volume> 4 </volume> <pages> 23-46, </pages> <year> 1977. </year>
Reference-contexts: The computation of either DP60 or DPLL on an unsatisfiable input instance gives rise to a regular resolution proof for that instance whose number of lines is bounded by the number of steps in the computation. Hence the exponential lower bound on regular resolution proofs <ref> [Tse70, Gal77, BA80] </ref> gives rise to worst-case exponential lower bounds on the time required for both DP60 and DPLL, and the exponential lower bounds for general resolution [Hak85, Urq87] show that no smarter use of resolution will help.
Reference: [Goe92] <author> A. Goerdt. </author> <title> A threshold for unsatisfiability. </title> <booktitle> In Proc. of the 17th International Symposium on Mathematical Foundations of Computer Science, </booktitle> <address> Prague, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: For the case of random 2-SAT, the conjecture has been shown true, and c fl = 1 <ref> [Goe92, CR92] </ref>. In the case of k = 3, the current bounds on the location of this threshold, if it exists, are 3:003 &lt; c fl &lt; 4:598.
Reference: [Gol79] <author> A. Goldberg. </author> <title> On the complexity of the satisfiability problem. </title> <institution> Courant Computer Science Report No. </institution> <address> 16., 1979. New York University. </address>
Reference-contexts: However, the two methods perform quite differently on some problems, and are incomparable with respect to complexity analysis <ref> [Gol79, DR94] </ref>. The variable selection rule (*) may be as simple as choosing the first remaining variable in , or it may be quite sophisticated. In the original version the rule used is; pick a variable occurring in the first clause of minimal length. <p> In the original version the rule used is; pick a variable occurring in the first clause of minimal length. The most popular rules currently are variants on ideas suggested in <ref> [DLL62, Gol79] </ref>, and described by Pretolani [Pre93] as Moms variable selection strategy: branch on a variable (or literal) with Maximum number of occurrences in minimum size clauses. A wide range of heuristics can be found in the literature. In particular, Dubois and 4 STEPHEN A. COOK AND DAVID G. <p> We may call the backtrack tree of DPLL on an unsatisfiable formula a "DPLL proof". Corresponding to every DPLL proof is a tree resolution refutation of size no larger than the DPLL proof tree <ref> [Gol79, Chapter 3] </ref> (sometimes there are also much smaller tree refutations). <p> Formula distributions may be used in analyzing algorithms, in empirically evaluating algorithms, or as a subject in problem complexity. The first average case analysis of SAT of which we are aware was carried out by Goldberg <ref> [Gol79] </ref> on random clause length formulas. Formulas from the random clause length (or "fixed density") model are constructed in the following way: For each of the m clauses, include each of the 2n literals with probability p (where p and m may be functions of n).
Reference: [GU89] <author> Giorgio Gallo and Giampaolo Urbani. </author> <title> Algorithms for testing the satisfiability of propositional formulae. </title> <journal> Journal of Logic Programming, </journal> <volume> 7 </volume> <pages> 45-61, </pages> <year> 1989. </year>
Reference-contexts: Many other complete methods have been devised, including for example Iwama's method for enumerating sets of non-solutions [Iwa89], Larrabee's method of trying to extend solutions to the 2-CNF subset of a general formula [Lar92], and Gallo and Urbani's use of Horn relaxations <ref> [GU89] </ref>. While some of these perform well on some classes of problems, they have not been as widely studied or tested as DPLL. 2.2. Incomplete Methods. <p> Selman's algorithm GSAT was inspired by a very closely related technique developed by Minton and his colleagues for Constraint Satisfaction Problems [MJPL90]. An intriguing contribution was the report by Sosic and Gu <ref> [Gu89, SG90] </ref> that this approach yielded very fast solutions to n-queens problems, which had previously been popular as a benchmark (known explicit solutions not-with-standing). In local search, a cost function is defined over truth assignments such that global minima correspond to satisfying assignments.
Reference: [Gu89] <author> Jun Gu. </author> <title> Parallel algorithms and architectures for very fast search. </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Science, University of Utah, </institution> <year> 1989. </year>
Reference-contexts: Many other complete methods have been devised, including for example Iwama's method for enumerating sets of non-solutions [Iwa89], Larrabee's method of trying to extend solutions to the 2-CNF subset of a general formula [Lar92], and Gallo and Urbani's use of Horn relaxations <ref> [GU89] </ref>. While some of these perform well on some classes of problems, they have not been as widely studied or tested as DPLL. 2.2. Incomplete Methods. <p> Selman's algorithm GSAT was inspired by a very closely related technique developed by Minton and his colleagues for Constraint Satisfaction Problems [MJPL90]. An intriguing contribution was the report by Sosic and Gu <ref> [Gu89, SG90] </ref> that this approach yielded very fast solutions to n-queens problems, which had previously been popular as a benchmark (known explicit solutions not-with-standing). In local search, a cost function is defined over truth assignments such that global minima correspond to satisfying assignments.
Reference: [Gu92] <author> Jun Gu. </author> <title> Efficient local search for very large-scale satisfiability problems. </title> <journal> SIGART Bulletin, </journal> <volume> 3(1) </volume> <pages> 8-12, </pages> <year> 1992. </year>
Reference-contexts: Typically these methods employ some notion of randomized local search. That this was a promising approach for SAT is a relatively recent discovery, made independently by Selman et al [SLM92] and Gu <ref> [Gu92] </ref>. Selman's algorithm GSAT was inspired by a very closely related technique developed by Minton and his colleagues for Constraint Satisfaction Problems [MJPL90].
Reference: [Gu93] <author> Jun Gu. </author> <title> Local search for satisfiability problem. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 23(4) </volume> <pages> 1108-1129, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Gu, in the development of his SAT1 family of local search based algorithms, also employed a variety of techniques for escaping local minima, including backtracking and random flips as well as restarts <ref> [Gu93] </ref>. Determining a general restart criterion would appear to be a tricky problem (see for example [GW95, HK93]). However it seems that for some related algorithms, which we discuss next, re-starting is not necessary.
Reference: [Gur91] <author> Yuri Gurevich. </author> <title> Average case completeness. </title> <journal> JCSS 42,3, </journal> <pages> 346-398, </pages> <year> 1991. </year>
Reference-contexts: The theory of average-case completeness tells us that such distributions exist, but there is evidence that none of them is "natural". This theory was initiated by Levin [Lev86] and extensively developed by others (see [BCGL92] and <ref> [Gur91] </ref>). Traditionally it requires specification of a global distribution to all instances of a problem D. <p> This includes all the random formulas we have discussed here, and probably all those to be found in the literature. Extending results of Gurevich <ref> [Gur91] </ref> they showed that provided DEXP6=NEXP (a slightly stronger assumption than P6=NP, but nonetheless expected to be true) k-SAT is not DistNP-complete under deterministic reductions for any of these distributions. <p> However this induced distribution will not be natural in any sense. Polytime and average polytime reductions are deterministic reductions. A notion of randomizing reduction has been defined, and examples given which are complete for DistNP with respect to these reductions but (assuming DEXP6=NEXP) not with respect to deterministic reductions <ref> [VL88, Gur91] </ref>. Makowsky and Sharell ([MS95], p90) suspect that their incompleteness result is due to the restric tion to deterministic reductions. Thus a major open problem is to find a natural distribution for which SAT is DistNP-complete under randomizing reductions. 5.
Reference: [GW94] <author> I.P. Gent and T. Walsh. </author> <title> The hardest random SAT problems. </title> <booktitle> In Proceedings, KI-94, </booktitle> <year> 1994. </year>
Reference-contexts: In some cases, formulas with thousands of variables and tens of thousands of clauses can be consistently solved with no more than two or three backtracks each. Gent and Walsh <ref> [GW94] </ref> investigated rare instances to the left of the "hard region" which appear extremely hard because of excessive run times for DPLL. These appear in both random clause and fixed clause formula families in the "easy" region, where most instances are trivial to show satisfiable.
Reference: [GW95] <author> I.P. Gent and T. Walsh. </author> <title> Unsatisfied variables in local search. </title> <booktitle> In Proceedings, AISB-95, </booktitle> <pages> pages 73-85, </pages> <year> 1995. </year> <title> (Appears as a the book entitled Hybrid Problems, Hybrid Solutions, </title> <editor> J. Hallam (Ed.), </editor> <publisher> IOS Press, </publisher> <year> 1995.) </year>
Reference-contexts: Gu, in the development of his SAT1 family of local search based algorithms, also employed a variety of techniques for escaping local minima, including backtracking and random flips as well as restarts [Gu93]. Determining a general restart criterion would appear to be a tricky problem (see for example <ref> [GW95, HK93] </ref>). However it seems that for some related algorithms, which we discuss next, re-starting is not necessary.
Reference: [Hak85] <author> A. Haken. </author> <title> The intractability of resolution. </title> <journal> Theoretical Computer Science, </journal> <volume> 39 </volume> <pages> 297-308, </pages> <year> 1985. </year>
Reference-contexts: Hence the exponential lower bound on regular resolution proofs [Tse70, Gal77, BA80] gives rise to worst-case exponential lower bounds on the time required for both DP60 and DPLL, and the exponential lower bounds for general resolution <ref> [Hak85, Urq87] </ref> show that no smarter use of resolution will help. From our point of view, the strongest lower bound for proof systems is due to Chvatal and Szemeredi [CS88], since their bound yields an exponential lower bound on the average-case performance of DP60 and DPLL.
Reference: [HK93] <author> Steven Hampson and Dennis Kibler. </author> <title> Plateaus and plateau search in boolean satisfi-ability problems: When to give up searching and start again. </title> <booktitle> Workshop Notes: 2nd DIMACS Challenge, </booktitle> <year> 1993. </year>
Reference-contexts: Gu, in the development of his SAT1 family of local search based algorithms, also employed a variety of techniques for escaping local minima, including backtracking and random flips as well as restarts [Gu93]. Determining a general restart criterion would appear to be a tricky problem (see for example <ref> [GW95, HK93] </ref>). However it seems that for some related algorithms, which we discuss next, re-starting is not necessary.
Reference: [Hoo88] <author> J.N. Hooker. </author> <title> Resolution vs. cutting plane solution of inference problems: some computational experience, </title> <journal> Operations Research Letters, </journal> <volume> 7(1) </volume> <pages> 1-7, </pages> <year> 1988. </year>
Reference-contexts: Other incomplete algorithms include use of standard mathematical programming and numerical optimization methods. Experiments have been reported, for example, using branch-and-bound, cutting planes, and interior point methods <ref> [Hoo88, HF90, JW90, KKRR90] </ref>. Although many experimenters have done SAT testing with mathematical programming methods, most published reports have used problems which are quite easy for a good implementation of DPLL [ML96], so the effectiveness of these approaches is not well established in the literature. 3. <p> A slightly stronger proof system than resolution is the cutting plane system. Some work has been done using cutting planes in a SAT tester, for example <ref> [Hoo88] </ref>. Recently, exponential worst-case lower bounds have also been given for cutting plane proofs [Pud96], but so far nothing comparable to the average-case resolution lower bound of Chvatal and Szemeredi has been shown.
Reference: [HF90] <author> J.N. Hooker and C. Fedjki. </author> <title> Branch-and-cut solution of inference problems in propositional logic. </title> <journal> Annals of Mathematics and Artificial Intelligence, </journal> <volume> 1 </volume> <pages> 123-139, </pages> <year> 1990. </year>
Reference-contexts: Other incomplete algorithms include use of standard mathematical programming and numerical optimization methods. Experiments have been reported, for example, using branch-and-bound, cutting planes, and interior point methods <ref> [Hoo88, HF90, JW90, KKRR90] </ref>. Although many experimenters have done SAT testing with mathematical programming methods, most published reports have used problems which are quite easy for a good implementation of DPLL [ML96], so the effectiveness of these approaches is not well established in the literature. 3. <p> When p is made a function of n so that expected clause length remains constant as n is increased, these formulas exhibit the same easy-hard-easy pattern, and the same satisfiable-to-unsatisfiable transition, as the random 3-SAT formulas (as was also observed in <ref> [HF90] </ref>). However, the peak in difficulty at the transition region is much less dramatic with these formulas, and they are very much easier to test than similar sized fixed-clause length formulas.
Reference: [HTL92] <author> T.H. Hu, C.Y. Tang, and R.C.T. Lee. </author> <title> An average case analysis of a resolution principle algorithm in mechanical theorem proving. </title> <journal> Annals of Mathematics and Artificial Intelligence, </journal> <volume> 6 </volume> <pages> 235-252, </pages> <year> 1992. </year>
Reference-contexts: rather than favorable properties of DPLL: A constant number of guesses of random truth assignments will find one that satisfies an instance from this family with probability tending to 1 as n grows. (More recently it has been shown that DP60 has linear time average performance on these same formulas <ref> [HTL92] </ref>.) Numerous further analyses of these formula distributions have been published, employing a variety of algorithms which take advantage of different properties which hold in different areas of the parameter space.
Reference: [ILL89] <author> R. Impagliazzo, L. Levin, and M. Luby. </author> <title> Pseudo-random number generation from one-way functions. </title> <booktitle> Proc. 21st STOC, </booktitle> <year> 1989, </year> <pages> pp 12-24. </pages>
Reference-contexts: More precisely, Russell Impagliazzo has pointed out that generating hard solved instances of 3-SAT is equivalent to computing a one-way function, which in turn is equivalent to generating pseudo-random numbers and private key cryptography <ref> [ILL89, Luby96] </ref>. (It may be easier to generate hard satisfiable instances than hard solved instances, but we have no insight on this.) FINDING HARD INSTANCES OF THE SATISFIABILITY PROBLEM 13 The problem of generating hard solved instances can be explained as follows: Find a polytime function h which takes a string
Reference: [Iwa89] <author> Kazuo Iwama. </author> <title> CNF satisfiability test by counting and polynomial average time. </title> <journal> SIAM Journal on Computing, </journal> <volume> 18(2) </volume> <pages> 385-391, </pages> <year> 1989. </year>
Reference-contexts: Corresponding to every DPLL proof is a tree resolution refutation of size no larger than the DPLL proof tree [Gol79, Chapter 3] (sometimes there are also much smaller tree refutations). Many other complete methods have been devised, including for example Iwama's method for enumerating sets of non-solutions <ref> [Iwa89] </ref>, Larrabee's method of trying to extend solutions to the 2-CNF subset of a general formula [Lar92], and Gallo and Urbani's use of Horn relaxations [GU89]. While some of these perform well on some classes of problems, they have not been as widely studied or tested as DPLL. 2.2.
Reference: [JAMS91] <author> D.S. Johnson, C.R. Aragon, L.A. McGeoch, and C. Schevon. </author> <title> Optimization by simulated annealing: an experimental evaluation; part ii, graph coloring and number partitioning. </title> <journal> Operations Research, </journal> <volume> 39(3) </volume> <pages> 378-406, </pages> <year> 1991. </year>
Reference-contexts: In both algorithms, the case of flipping a literal non-greedily serves to prevent getting stuck in local optima, so that restarting becomes less important. Viewed schematically, these procedures bear considerable resemblance to simulated annealing (SA) <ref> [JAMS91] </ref>, and suitably tuned versions of SA do in fact perform comparably with the algorithms just described [Sp93, BAH + 94, SKC94].
Reference: [JW90] <author> Robert E. Jeroslow and Jinchang Wang. </author> <title> Solving propositional satisfiability problems. </title> <journal> Annals of Mathematics and Artificial Intelligence, </journal> <volume> 1 </volume> <pages> 167-187, </pages> <year> 1990. </year>
Reference-contexts: Other incomplete algorithms include use of standard mathematical programming and numerical optimization methods. Experiments have been reported, for example, using branch-and-bound, cutting planes, and interior point methods <ref> [Hoo88, HF90, JW90, KKRR90] </ref>. Although many experimenters have done SAT testing with mathematical programming methods, most published reports have used problems which are quite easy for a good implementation of DPLL [ML96], so the effectiveness of these approaches is not well established in the literature. 3.
Reference: [KKRR90] <author> A.P. Kamath, N.K. Karmarkar, K.G. Ramakrishnan, and M.G.C. Resende. </author> <title> Computational experience with an interior point algorithm on the satisfiability problem. </title> <journal> Annals of Operations Research, </journal> <volume> 25 </volume> <pages> 43-58, </pages> <year> 1990. </year> <editor> 16 STEPHEN A. COOK AND DAVID G. </editor> <publisher> MITCHELL </publisher>
Reference-contexts: Other incomplete algorithms include use of standard mathematical programming and numerical optimization methods. Experiments have been reported, for example, using branch-and-bound, cutting planes, and interior point methods <ref> [Hoo88, HF90, JW90, KKRR90] </ref>. Although many experimenters have done SAT testing with mathematical programming methods, most published reports have used problems which are quite easy for a good implementation of DPLL [ML96], so the effectiveness of these approaches is not well established in the literature. 3.
Reference: [KMPS94] <author> Anil Kamath, Rajeev Motwani, Krishna Palem, and Paul Spirakis. </author> <title> Tail bounds for occupancy and the satisfiability threshold conjecture. </title> <booktitle> In Proc. </booktitle> <address> FOCS-94, </address> <year> 1994. </year>
Reference-contexts: The upper bound is due to Kirousis, Kranakas and Krizanc [KKK96], which improves previous bounds of 4.64 by Dubois and Boufkhad [DB96], 4.78 by Kamath et al <ref> [KMPS94] </ref>, and 5.19 reported by several authors. The easy 5.19 bound comes from observing that a fixed assignment t satisfies a random 3-literal clause with probability 7 8 and hence t satisfies a random instance of 3-SAT with probability ( 7 8 ) cn .
Reference: [KKK96] <author> L.M. Kirousis, E. Kranakis, and D. Krizanc. </author> <title> Approximating the unsatisfiability threshold of random formulas. </title> <type> Preprint, </type> <year> 1996. </year>
Reference-contexts: Suitable variants of DPLL succeed in finding solutions whenever GUCB does, and in the same time, and therefore will almost always find solutions to these instances in polynomial time (although polynomial average time does not necessarily follow). The upper bound is due to Kirousis, Kranakas and Krizanc <ref> [KKK96] </ref>, which improves previous bounds of 4.64 by Dubois and Boufkhad [DB96], 4.78 by Kamath et al [KMPS94], and 5.19 reported by several authors. <p> This may help explain the success of local search methods on satisfiable instances.) The improved upper bounds given in <ref> [DB96, KKK96] </ref> are based on the observation that if an instance is satisfiable, then some assignment t maximally satisfies , meaning t satisfies , but flipping the value of t on any single variable from false to true falsifies .
Reference: [KP92] <author> Elias Koutsoupias and Christos H. Papadimitriou. </author> <title> On the greedy algorithm for satis-fiability. </title> <journal> Information Processing Letters, </journal> <volume> 30 </volume> <pages> 53-55, </pages> <year> 1992. </year>
Reference-contexts: As mentioned above, all iterative repair methods work in polynomial expected time for satisfiable instances of 2-SAT and (via a simple rewriting trick), Re-nameable-Horn-SAT. These problems, however, have linear time deterministic algorithms. Koutsoupias and Papadimitriou <ref> [KP92] </ref> proved for a version of randomized 3-SAT that any local search algorithm will almost always find solutions to satisfiable instances with at least (n 2 ) clauses, however random formulas with more than a linear number of clauses are almost always unsatisfiable.
Reference: [Kra95] <author> Jan Kraj icek. </author> <title> Bounded Arithmetic, Propositional logic, and Complexity Theory, </title> <address> Cam-bridge, </address> <year> 1995. </year>
Reference-contexts: Exponential lower bounds have not been shown for some more powerful proof systems, such as Frege systems and extended Frege systems. A lower bound for extended Frege systems would yield a similar lower bound for any complete SAT tester whose correctness can be proved using feasibly constructive methods <ref> [Coo75, Kra95] </ref>. 6. Hard Satisfiable Instances As we mentioned, the known unconditional lower bounds apply only to hard unsatisfiable instances, and furthermore existing model finders perform remarkably well on satisfiable instances even near the difficult threshold ratio on random 3-SAT (see section 3.2).
Reference: [Lar92] <author> T. Larrabee. </author> <title> Test pattern generation using Boolean satisfiability. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <pages> pages 6-22, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: Many other complete methods have been devised, including for example Iwama's method for enumerating sets of non-solutions [Iwa89], Larrabee's method of trying to extend solutions to the 2-CNF subset of a general formula <ref> [Lar92] </ref>, and Gallo and Urbani's use of Horn relaxations [GU89]. While some of these perform well on some classes of problems, they have not been as widely studied or tested as DPLL. 2.2. Incomplete Methods.
Reference: [LT92] <author> T. Larrabee and Y. Tsuji. </author> <title> Evidence for a satisfiability threshold for random 3CNF formulas. </title> <type> Technical Report UCSC-CRL-92-42, CRL, </type> <institution> University of California, Santa Cruz, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: It is intriguing that the peak in difficulty occurs near the ratio where about half of the formulas are satisfiable especially since this is the same region that appears hardest to analyze. The same pattern of hardness was found in <ref> [LT92] </ref>, using a substantially different algorithm, and we have conjectured that this general pattern will hold, qualitatively, for all reasonable complete methods. The same pattern is also found for larger values of k, but with the transition at higher ratios, and the peak difficulty for DPLL much greater [ML96].
Reference: [Lev86] <author> Leonid A. Levin. </author> <title> Average case complete problems. </title> <journal> SIAM J. Comput., </journal> <volume> 15(1) </volume> <pages> 285-286, </pages> <month> February </month> <year> 1986. </year>
Reference-contexts: Thus we want a distribution on 3-SAT instances for each length l which makes the problem complete in some average-case sense. The theory of average-case completeness tells us that such distributions exist, but there is evidence that none of them is "natural". This theory was initiated by Levin <ref> [Lev86] </ref> and extensively developed by others (see [BCGL92] and [Gur91]). Traditionally it requires specification of a global distribution to all instances of a problem D.
Reference: [Lew78] <author> Harry R. Lewis. </author> <title> Renaming a set of clauses as a horn set. </title> <journal> Journal of the ACM, </journal> <volume> 25(1) </volume> <pages> 134-135, </pages> <month> January </month> <year> 1978. </year>
Reference-contexts: Horn-SAT is solvable in linear time [DG84], as are a number of generalizations such as Re-nameable Horn-SAT, the class of formulas that can be converted to Horn merely by renaming (reversing the sign) of some variables <ref> [Lew78, Asp80] </ref>, and Generalized Horn-SAT, an extension of Horn-SAT based on a nesting property [CH91, CCH + 90] (see also [CC92, SAFS95]).
Reference: [Luby96] <author> Michael Luby. </author> <title> Pseudorandomness and Cryptographic Applications. </title> <publisher> Princeton University Press, </publisher> <year> 1996. </year>
Reference-contexts: More precisely, Russell Impagliazzo has pointed out that generating hard solved instances of 3-SAT is equivalent to computing a one-way function, which in turn is equivalent to generating pseudo-random numbers and private key cryptography <ref> [ILL89, Luby96] </ref>. (It may be easier to generate hard satisfiable instances than hard solved instances, but we have no insight on this.) FINDING HARD INSTANCES OF THE SATISFIABILITY PROBLEM 13 The problem of generating hard solved instances can be explained as follows: Find a polytime function h which takes a string
Reference: [MJPL90] <author> S. Minton, M.D. Johnston, A.B. Philips, and P. Laird. </author> <title> Solving large-scale constraint satisfaction and scheduling problems using a heuristic repair method. </title> <booktitle> In Proceedings AAAI-90, </booktitle> <pages> pages 17-24, </pages> <year> 1990. </year>
Reference-contexts: That this was a promising approach for SAT is a relatively recent discovery, made independently by Selman et al [SLM92] and Gu [Gu92]. Selman's algorithm GSAT was inspired by a very closely related technique developed by Minton and his colleagues for Constraint Satisfaction Problems <ref> [MJPL90] </ref>. An intriguing contribution was the report by Sosic and Gu [Gu89, SG90] that this approach yielded very fast solutions to n-queens problems, which had previously been popular as a benchmark (known explicit solutions not-with-standing).
Reference: [MS95] <author> Jahann A. Makowsky and Abraham Sharell. </author> <title> On average case complexity of SAT for symmetric distribution. </title> <journal> J. Logic Computat., </journal> <volume> 5(1) </volume> <pages> 71-92, </pages> <year> 1995. </year>
Reference-contexts: Here we adapt the theory to follow the tradition in average-case analysis of algorithms, where one need only specify a family of local distributions, i.e. for each l a distribution l on instances of length l (see <ref> [MS95] </ref>). If D is a decision problem, then D l denotes the restriction of D to inputs of length l. A randomized decision problem is a sequence hD l ; l i, where D is a decision problem and l is a probability distribution on instances of D l . <p> A few other such natural examples have been found ([Gur91]), but very few compared to the vast number of NP-complete problems known. SAT is not among the examples, as we now explain. Makowsky and Sharell <ref> [MS95] </ref> define the class of negation-symmetric distributions on SAT or k-SAT to be all those with the following property: If an instance I 0 results from an instance I by replacing a particular literal with its negation throughout, then I and I 0 have equal probability. <p> Notice however that if c is not a constant and exceeds n 2 then sub-linear length proofs almost surely exist <ref> [Fu95, MS95] </ref>. The experimental finding that random 3-SAT with large c is easy is not in conflict with the exponential lower bound for large (constant) ratios, but only shows that at a given n these are much easier than formulas in the transition region.
Reference: [ML96] <author> David G. Mitchell and Hector J. Levesque. </author> <title> Some pitfalls for experimenters with random SAT. </title> <journal> Artificial Intelligence, </journal> <volume> 81 </volume> <pages> 111-125, </pages> <year> 1996. </year>
Reference-contexts: Experiments have been reported, for example, using branch-and-bound, cutting planes, and interior point methods [Hoo88, HF90, JW90, KKRR90]. Although many experimenters have done SAT testing with mathematical programming methods, most published reports have used problems which are quite easy for a good implementation of DPLL <ref> [ML96] </ref>, so the effectiveness of these approaches is not well established in the literature. 3. Average-Case Performance The theory of NP-completeness is based on worst-case complexity. <p> The same pattern is also found for larger values of k, but with the transition at higher ratios, and the peak difficulty for DPLL much greater <ref> [ML96] </ref>. Random clause length formulas have also been studied empirically, (and until recently were the most popular in reported experiments). It is readily apparent that most of these formulas are easy, because they often contain empty clauses, unit clauses and trivial clauses. <p> It is readily apparent that most of these formulas are easy, because they often contain empty clauses, unit clauses and trivial clauses. Thus, experimenters shifted to a model where these 8 STEPHEN A. COOK AND DAVID G. MITCHELL being satisfiable. three clause types are excluded. In <ref> [MSL92, ML96] </ref>, the performance of DPLL on these modified formulas was investigated.
Reference: [MSL92] <author> D.G. Mitchell, B. Selman, and H.J. Levesque. </author> <title> Hard and easy distributions of SAT problems. </title> <booktitle> In Proc. AAAI-92, </booktitle> <address> San Jose, CA, </address> <year> 1992. </year>
Reference-contexts: Fixed-clause-length formulas are generated by selecting clauses uniformly at random from the set of all possible (nontrivial) clauses of a given length. We call such sets random k-SAT. The empirical performance of a version of DPLL on random 3-SAT was investigated in <ref> [MSL92] </ref> (see Figure 1). When c is small, say less than 3, most instances are are very quickly solved. When c is large, say more than 6, instances are harder than those at small ratios, but only moderately. In the region between these ratios average difficulty is dramatically greater. <p> It is readily apparent that most of these formulas are easy, because they often contain empty clauses, unit clauses and trivial clauses. Thus, experimenters shifted to a model where these 8 STEPHEN A. COOK AND DAVID G. MITCHELL being satisfiable. three clause types are excluded. In <ref> [MSL92, ML96] </ref>, the performance of DPLL on these modified formulas was investigated.
Reference: [Pap91] <author> Christos H. Papadimitriou. </author> <title> On selecting a satisfying truth assignment. </title> <booktitle> In Proc. FOCS-91, </booktitle> <pages> pages 163-169, </pages> <year> 1991. </year>
Reference-contexts: In the case of satisfiable instances of 2-SAT, Random Walk (indeed any reasonable iterative repair algorithm) may be analyzed as a gambler's ruin, and shown to solve such instances in O (n 2 ) time on average <ref> [Pap91] </ref>. Although Random Walk will always eventually solve any satisfiable CNF formula, it is not hard to demonstrate 3-CNF examples with exponential expected time [Pap94], and in experimentation the method fails badly on random 3-SAT.
Reference: [Pap94] <author> Christos H. Papadimitriou. </author> <title> Computational Complexity. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: Although Random Walk will always eventually solve any satisfiable CNF formula, it is not hard to demonstrate 3-CNF examples with exponential expected time <ref> [Pap94] </ref>, and in experimentation the method fails badly on random 3-SAT. Selman, Kautz and Cohen [SKC94], found that a probabilistically greedy version of Random Walk performed better than GSAT on most types of problems tested. On each iteration this algorithm, called WalkSAT, selects an unsatisfied clause at 6 STEPHEN A.
Reference: [Pre93] <author> D. Pretolani. </author> <title> Solving satisfiability problems: An algorithm implementation challenge? (extended abstract). </title> <booktitle> Workshop notes, 2nd DIMACS Challenge, </booktitle> <year> 1993. </year>
Reference-contexts: In the original version the rule used is; pick a variable occurring in the first clause of minimal length. The most popular rules currently are variants on ideas suggested in [DLL62, Gol79], and described by Pretolani <ref> [Pre93] </ref> as Moms variable selection strategy: branch on a variable (or literal) with Maximum number of occurrences in minimum size clauses. A wide range of heuristics can be found in the literature. In particular, Dubois and 4 STEPHEN A. COOK AND DAVID G.
Reference: [Pud96] <author> Pavel Pudlak. </author> <title> Lower bounds for resolution and cutting planes proofs and monotone computations. </title> <journal> J. </journal> <note> Symbolic Logic (to appear). </note>
Reference-contexts: A slightly stronger proof system than resolution is the cutting plane system. Some work has been done using cutting planes in a SAT tester, for example [Hoo88]. Recently, exponential worst-case lower bounds have also been given for cutting plane proofs <ref> [Pud96] </ref>, but so far nothing comparable to the average-case resolution lower bound of Chvatal and Szemeredi has been shown. Exponential lower bounds have not been shown for some more powerful proof systems, such as Frege systems and extended Frege systems.
Reference: [Pur90] <author> P. Purdom. </author> <title> A survey of average time analyses of satisfiability algorithms. </title> <journal> Journal of Information Processing, </journal> <volume> 13(4), </volume> <year> 1990. </year>
Reference-contexts: The formulas not yet known to be solvable efficiently on average occur, roughly, when the expected clause length is a little less than ln (m). See the study by Franco and Swaminathan [FW97] for details. See also <ref> [Pur90, Fra86] </ref> for earlier work. It is worth noting that the algorithms involved are quite simple, and easily implemented. For most practical purposes, then, this family of formula distribution must be regarded as easy on average, and not a likely source of hard instances.
Reference: [Sch96] <author> Ingo Schiermeyer. </author> <title> Pure Literal Look Ahead: An O(1; 497 n ) 3-Satisfiability Algorithm (Extended Abstract). In: Workshop on the Satisfiability Problem, </title> <type> Technical Report, </type> <institution> Siena, </institution> <month> April 29-May3, </month> <year> 1996, </year> <editor> J. Franco, G. Gallo, H. Kleine-Buning, E. Speckenmeyer, C. Spera (Eds.), </editor> <publisher> University of Koln, </publisher> <year> 1996. </year>
Reference-contexts: The worst case time for this procedure on 3-SAT is O (2 0:762n ), and a very small modification improves it to O (2 0:694n ) [VanG96]. The current best bound on the time to decide membership in 3-SAT is O (2 0:582n ) <ref> [Sch96] </ref>, using a set of complex refinements to DPLL which seem unlikely to be useful in practice. Complex methods to reduce the size of the search tree often do not lead to corresponding reductions in actual execution time, because of the additional work needed at each node.
Reference: [SAFS95] <author> John Schlipf, Fred Annextein, John Franco and R.P. Swaminathan. </author> <title> On finding solutions for extended Horn formulas. </title> <journal> Information Processing Letters, </journal> <volume> 54 </volume> <pages> 133-137, </pages> <year> 1995. </year>
Reference-contexts: [DG84], as are a number of generalizations such as Re-nameable Horn-SAT, the class of formulas that can be converted to Horn merely by renaming (reversing the sign) of some variables [Lew78, Asp80], and Generalized Horn-SAT, an extension of Horn-SAT based on a nesting property [CH91, CCH + 90] (see also <ref> [CC92, SAFS95] </ref>). In what follows, we will use n for the number of variables in a formula, m for the number of clauses and k for the clause "length" (e.g., number of literals).
Reference: [SK93] <author> Bart Selman and Henry Kautz. </author> <title> An empirical study of greedy local search for satisfia-bility testing. </title> <booktitle> In Proc. AAAI-93, </booktitle> <pages> pages 46-51, </pages> <year> 1993. </year>
Reference-contexts: If restricted to improving steps, GSAT performs very poorly, and in practice steps which make no change to the score dominate the search, except during an short initial descent phase <ref> [SK93] </ref>. One's intuition might be that such an algorithm will always get stuck in local minima, and the surprise of it's success is that this happens much less often than one might expect.
Reference: [SKC94] <author> Bart Selman, Henry Kautz, and Bram Cohen. </author> <title> Noise strategies for improving local search. </title> <booktitle> In Proceedings, AAAI-94, </booktitle> <pages> pages 337-343, </pages> <year> 1994. </year>
Reference-contexts: Although Random Walk will always eventually solve any satisfiable CNF formula, it is not hard to demonstrate 3-CNF examples with exponential expected time [Pap94], and in experimentation the method fails badly on random 3-SAT. Selman, Kautz and Cohen <ref> [SKC94] </ref>, found that a probabilistically greedy version of Random Walk performed better than GSAT on most types of problems tested. On each iteration this algorithm, called WalkSAT, selects an unsatisfied clause at 6 STEPHEN A. COOK AND DAVID G. <p> Viewed schematically, these procedures bear considerable resemblance to simulated annealing (SA) [JAMS91], and suitably tuned versions of SA do in fact perform comparably with the algorithms just described <ref> [Sp93, BAH + 94, SKC94] </ref>. The basic SA algorithm for SAT begins with an initial random truth assignment, and repeats the following step; Pick a random variable, and compute ffi, the change in the number of un-satisfied clauses when the variable is flipped. <p> WalkSAT performance near the threshold. Random instances appear to be hardest when generated near the threshold ratio. DPLL and its variations are hopelessly slow on many instances of random 3-SAT at this ratio when n is much larger than 400. However, Selman et al <ref> [SKC94] </ref> found that WalkSAT solves most of the satisfiable cases for much larger n. With n = 2000 variables, the best current estimate of the ratio at which 50% of formulas will be satisfiable is about c = m=n = 4:24, or m = 8480 clauses.
Reference: [SK96] <author> Bart Selman and Scott Kirkpatrick. </author> <title> Critical behavior in the computational cost of satisfiability testing. </title> <journal> Artificial Intelligence, </journal> <volume> 81 </volume> <pages> 273-295, </pages> <year> 1996. </year>
Reference-contexts: These appear in both random clause and fixed clause formula families in the "easy" region, where most instances are trivial to show satisfiable. However, such instances seem to be amenable to attack by one or more existing enhancements to backtracking <ref> [SK96, CA96, BS96] </ref>. Thus it appears that the hard formulas in the transition region for random k-SAT are the most useful random formulas of the kind we have so far discussed for evaluating the performance of algorithms. <p> The known lower bounds result from analyzing specific algorithms, as explained above. Attempts have also been made to construct a quantitative model of the transition region based on empirical data. This also appears quite challenging (see <ref> [SK96, CA96] </ref>). 3.2. WalkSAT performance near the threshold. Random instances appear to be hardest when generated near the threshold ratio. DPLL and its variations are hopelessly slow on many instances of random 3-SAT at this ratio when n is much larger than 400.
Reference: [SLM92] <author> Bart Selman, Hector Levesque, and David Mitchell. </author> <title> A new method for solving hard satisfiability problems. </title> <booktitle> In Proceedings, AAAI-92, </booktitle> <address> San Jose, CA, </address> <year> 1992. </year>
Reference-contexts: Typically these methods employ some notion of randomized local search. That this was a promising approach for SAT is a relatively recent discovery, made independently by Selman et al <ref> [SLM92] </ref> and Gu [Gu92]. Selman's algorithm GSAT was inspired by a very closely related technique developed by Minton and his colleagues for Constraint Satisfaction Problems [MJPL90]. <p> The most widely studied of these algorithms is Selman's GSAT <ref> [SLM92] </ref>. At each step of this algorithm the truth assignment of one variable is "flipped". The variable selected is the one which leads to the best neighboring truth assignment. FINDING HARD INSTANCES OF THE SATISFIABILITY PROBLEM 5 Ties are broken randomly.
Reference: [SD89] <author> J.C. Simon and O. Dubois. </author> <title> Number of solutions of satisfiability instances applications to knowledge bases. </title> <journal> Inter. J. of Pattern Recognition and A.I., </journal> <volume> 3(1) </volume> <pages> 53-65, </pages> <year> 1989. </year>
Reference-contexts: In the region between these ratios average difficulty is dramatically greater. Also between these ratios, the probability of satisfiability shifts smoothly from near 1 to near 0 (as independently reported earlier in <ref> [SD89] </ref>). It is intriguing that the peak in difficulty occurs near the ratio where about half of the formulas are satisfiable especially since this is the same region that appears hardest to analyze.
Reference: [SG90] <author> R. Sosic and J. Gu. </author> <title> A Polynomial Time Algorithm for the N-Queens Problem. </title> <journal> SIGART Bulletin, </journal> <volume> 1(3), </volume> <year> 1990. </year>
Reference-contexts: Selman's algorithm GSAT was inspired by a very closely related technique developed by Minton and his colleagues for Constraint Satisfaction Problems [MJPL90]. An intriguing contribution was the report by Sosic and Gu <ref> [Gu89, SG90] </ref> that this approach yielded very fast solutions to n-queens problems, which had previously been popular as a benchmark (known explicit solutions not-with-standing). In local search, a cost function is defined over truth assignments such that global minima correspond to satisfying assignments.
Reference: [Sp93] <author> William M. Spears. </author> <title> Simulated annealing for hard satisfiability problems. In, Workshop Notes from the 1993 DIMACS Challenge. FINDING HARD INSTANCES OF THE SATISFIABILITY PROBLEM 17 </title>
Reference-contexts: Viewed schematically, these procedures bear considerable resemblance to simulated annealing (SA) [JAMS91], and suitably tuned versions of SA do in fact perform comparably with the algorithms just described <ref> [Sp93, BAH + 94, SKC94] </ref>. The basic SA algorithm for SAT begins with an initial random truth assignment, and repeats the following step; Pick a random variable, and compute ffi, the change in the number of un-satisfied clauses when the variable is flipped.
Reference: [Tse70] <author> G.S. Tseitin. </author> <title> On the complexity of derivation in propositional calculus. </title> <editor> In; Slisenko (Ed.), </editor> <booktitle> Studies in Constructive Mathematics and Mathematical Logic Part II, A.O., </booktitle> <pages> pages 115-125. </pages> <publisher> Consultants Bureau, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: The computation of either DP60 or DPLL on an unsatisfiable input instance gives rise to a regular resolution proof for that instance whose number of lines is bounded by the number of steps in the computation. Hence the exponential lower bound on regular resolution proofs <ref> [Tse70, Gal77, BA80] </ref> gives rise to worst-case exponential lower bounds on the time required for both DP60 and DPLL, and the exponential lower bounds for general resolution [Hak85, Urq87] show that no smarter use of resolution will help.
Reference: [Urq87] <author> Alasdair Urquhart. </author> <title> Hard examples for resolution. </title> <journal> Journal of the ACM, </journal> <volume> 34(1) </volume> <pages> 209-219, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: Hence the exponential lower bound on regular resolution proofs [Tse70, Gal77, BA80] gives rise to worst-case exponential lower bounds on the time required for both DP60 and DPLL, and the exponential lower bounds for general resolution <ref> [Hak85, Urq87] </ref> show that no smarter use of resolution will help. From our point of view, the strongest lower bound for proof systems is due to Chvatal and Szemeredi [CS88], since their bound yields an exponential lower bound on the average-case performance of DP60 and DPLL.
Reference: [VanG96] <author> Allen Van Gelder. </author> <type> Personal Communication. </type>
Reference-contexts: DPLL also appears to be close to the best we currently know how to do in terms of worst-case performance. The worst case time for this procedure on 3-SAT is O (2 0:762n ), and a very small modification improves it to O (2 0:694n ) <ref> [VanG96] </ref>. The current best bound on the time to decide membership in 3-SAT is O (2 0:582n ) [Sch96], using a set of complex refinements to DPLL which seem unlikely to be useful in practice.
Reference: [VL88] <author> Ramarathnam Venkatesan and Leonid A. Levin. </author> <title> Random instances of a graph coloring problem are hard. </title> <booktitle> Proc. 20th STOC, </booktitle> <pages> 217-222, </pages> <year> 1988. </year>
Reference-contexts: However this induced distribution will not be natural in any sense. Polytime and average polytime reductions are deterministic reductions. A notion of randomizing reduction has been defined, and examples given which are complete for DistNP with respect to these reductions but (assuming DEXP6=NEXP) not with respect to deterministic reductions <ref> [VL88, Gur91] </ref>. Makowsky and Sharell ([MS95], p90) suspect that their incompleteness result is due to the restric tion to deterministic reductions. Thus a major open problem is to find a natural distribution for which SAT is DistNP-complete under randomizing reductions. 5.
Reference: [WB93] <author> J. Wang and J. Belanger. </author> <title> On average P vs. average NP. In Complexity Theory - Current research (K. </title> <editor> Ambos-Spies, S. Homer, U. Schoning, eds.), </editor> <publisher> Cambridge University Press, </publisher> <year> 1993, </year> <month> pp.47-67. </month>
Reference-contexts: The notion AvNP of average NP has been defined, and Wang and Belanger <ref> [WB93] </ref> proved that any problem complete for DistNP is also complete for the larger class AvNP, provided that more general "polytime on average" reductions are allowed, as opposed to the strict polytime reductions defined above.
Reference: [Weg] <author> Ingo Wegener. </author> <title> The Complexity of Boolean Functions, </title> <publisher> Wiley and Teubner, </publisher> <year> 1987. </year> <institution> Department of Computer Science, University of Toronto, Toronto, Ontario, M5S 3G4 CANADA E-mail address: sacook@cs.toronto.edu Department of Computer Science, University of Toronto, Toronto, Ontario, M5S 3G4 CANADA E-mail address: mitchell@cs.toronto.edu </institution>
Reference-contexts: Challenge: Report the largest n for which your SAT solver can (consistently) find P and Q within one hour. Part of the challenge is to find a suitable multiplier circuit: not too complex, and probably not too deep (see for example <ref> [Weg] </ref>, section 3.2). The state of the art for number-theoretic factoring methods seems to be around n ' 200 bits (about 60 decimal digits for each prime). We believe that the current state for the SAT encoding approach is very much less than this. 14 STEPHEN A.
References-found: 82

