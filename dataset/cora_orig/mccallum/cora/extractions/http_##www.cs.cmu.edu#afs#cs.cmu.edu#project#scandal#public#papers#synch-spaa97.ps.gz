URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/scandal/public/papers/synch-spaa97.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/scandal/public/papers/synch-spaa97.html
Root-URL: 
Email: guyb@cs.cmu.edu  gibbons@research.bell-labs.com  matias@research.bell-labs.com  girija@cs.cmu.edu  
Title: Space-Efficient Scheduling of Parallelism with Synchronization Variables  
Author: Guy E. Blelloch Phillip B. Gibbons Yossi Matias Girija J. Narlikar 
Affiliation: Carnegie Mellon  Bell Laboratories  Bell Laboratories  Carnegie Mellon  
Abstract: Recent work on scheduling algorithms has resulted in provable bounds on the space taken by parallel computations in relation to the space taken by sequential computations. The results for online versions of these algorithms, however, have been limited to computations in which threads can only synchronize with ancestor or sibling threads. Such computations do not include languages with futures or user-specified synchronization constraints. Here we extend the results to languages with synchronization variables. Such languages include languages with futures, such as Multilisp and Cool, as well as other languages such as id. The main result is an online scheduling algorithm which, given a computation with w work (total operations), synchronizations, d depth (critical path) and s 1 sequential space, will run in O(w=p + log(pd)=p + d log(pd)) time and s 1 + O(pd log(pd)) space, on a p-processor crcw pram with a fetch-and-add primitive. This includes all time and space costs for both the computation and the scheduler. The scheduler is non-preemptive in the sense that it will only move a thread if the thread suspends on a synchronization, forks a new thread, or exceeds a threshold when allocating space. For the special case where the computation is a planar graph with left-to-right synchronization edges, the scheduling algorithm can be implemented in O(w=p+d log p) time and s 1 + O(pd log p) space. These are the first nontrivial space bounds described for such languages. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Arvind, R. S. Nikhil, and K. K. Pingali. I-structures: </author> <title> Data structures for parallel computing. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 11(4) </volume> <pages> 598-632, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Many parallel languages allow for dynamic fine-grained parallelism and leave the task of mapping the parallelism onto processors to the implementation. Such languages include both data-parallel languages such as hpf [24] and nesl [3], and control-parallel languages such as Multilisp [23], id <ref> [1] </ref>, sisal [18] and Proteus [28]. Since there is often significantly more parallelism expressed in these languages than there are processors, the implementation must not only decide onto which processors to schedule computations, but in what order to schedule them. <p> All this work, however, has been limited to computations in which threads can only synchronize with their sibling or ancestor threads. Although this is a reasonably general class, it does not include languages based on futures [23, 27, 12, 14, 13], languages based on lenient or speculative evaluation <ref> [1, 32] </ref>, or languages with general user-specified synchronization constraints [33]. In this paper we show how to extend the results to support synchronization based on write-once synchronization variables. <p> Such synchronization variables can be used to implement futures in such languages as Multilisp [23], Mul-T [27], Cool [14] and olden [13]; I-structures in ID <ref> [1] </ref>; events in PCF [38]; streams in sisal [18]; and are likely to be helpful in implementing the user-specified synchronization constraints in Jade [33]. <p> We assume there is an end instruction to end execution of a thread. In this model a future can be implemented by allocating a synchronization variable, forking a thread to evaluate the future value, and having the forked thread write its result to the synchronization variable. I-structures in id <ref> [1] </ref> can similarly be implemented with an array of pointers to synchronization variables and a fork for evaluating each value. Streams in sisal [18] can be implemented by associating a synchronization variable with each element (or block of elements) of the stream.
Reference: [2] <author> J. Aspnes, M.P. Herlihy, and N. Shavit. </author> <title> Counting networks. </title> <journal> Journal of the ACM, </journal> <volume> 41(5) </volume> <pages> 1020-1048, </pages> <year> 1994. </year>
Reference-contexts: idle, between putting their thread in Q in , and taking their new threads from Q out . (Details will be given in the full paper.) We finally remark that the various queues used in the scheduling algorithm can be implemented using asynchronous low-contention data structures such as counting networks <ref> [2] </ref> and diffracting trees [37].
Reference: [3] <author> G. E. Blelloch, S. Chatterjee, J. C. Hardwick, J. Sipel-stein, and M. Zagha. </author> <title> Implementation of a portable nested data-parallel language. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 21(1) </volume> <pages> 4-14, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Many parallel languages allow for dynamic fine-grained parallelism and leave the task of mapping the parallelism onto processors to the implementation. Such languages include both data-parallel languages such as hpf [24] and nesl <ref> [3] </ref>, and control-parallel languages such as Multilisp [23], id [1], sisal [18] and Proteus [28]. Since there is often significantly more parallelism expressed in these languages than there are processors, the implementation must not only decide onto which processors to schedule computations, but in what order to schedule them.
Reference: [4] <author> G. E. Blelloch, P. B. Gibbons, and Y. Matias. </author> <title> Provably efficient scheduling for languages with fine-grained parallelism. </title> <booktitle> In Proc. Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 1-12, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: These results were used to bound the time and space used by the Cilk programming language [7]. Blelloch, Gibbons and Matias <ref> [4] </ref> showed that for nested computations, the time bounds can be maintained while bounding the space by s 1 + O (pd), which for sufficient parallelism is just an additive factor over the sequential space. This was used to bound the space of the nesl programming language [5]. <p> Planar dags are a more general class of dags than the computation dags considered in <ref> [8, 9, 4] </ref>. Previously, no space bounds were known for computations with synchronization variables, even in the case where the dags are planar. <p> Planar dags are a more general class of dags than the computation dags considered in [8, 9, 4]. Previously, no space bounds were known for computations with synchronization variables, even in the case where the dags are planar. As with previous work <ref> [4, 29] </ref>, the idea behind the implementation is to schedule the threads in an order that is as close as possible to the sequential order (while still obtaining good load balance across the processors). <p> Let S 1 be any 1-schedule for a task graph with n tasks, and let v 1 ; v 2 ; : : : ; v n be the tasks in the order they appear in S 1 . As defined in <ref> [4] </ref>, we say a prioritized p-schedule is based on S 1 if the relative priorities of tasks are based on their serial execution order: 8i; j 2 f1; : : : ; ng; i &lt; j ) priority (v i ) &gt; priority (v j ). <p> Handling arbitrarily big allocations. Actions that allocate more that a constant K units of memory are handled in the following manner, similar to the technique suggested in <ref> [4] </ref> and [29]. The key idea is to delay the big allocations, so that if tasks with higher priorities become ready, they will be executed instead. <p> Instead, each newly-reactivated suspended node will be inserted into R fl (in step 2) in the place where the node activating it was, since it is a child of its activating node. We show below that for planar computation graphs, priority order is maintained. In <ref> [4] </ref>, we showed that a similar stack-based scheduling algorithm, where we restrict step 1 to schedule only the highest-priority nodes, can be used to maintain priority order for any series-parallel computation graph.
Reference: [5] <author> G. E. Blelloch and J. Greiner. </author> <title> A provable time and space efficient implementation of NESL. </title> <booktitle> In Proc. International Conference on Functional Programming, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: This was used to bound the space of the nesl programming language <ref> [5] </ref>. Narlikar and Blelloch [30] showed that this same bound can be achieved in a non-preemptive manner (threads are only moved from a processor when synchronizing, forking or allocating memory) and gave experimental results showing the effectiveness of the technique.
Reference: [6] <author> G. E. Blelloch and M. Reid-Miller. </author> <title> Pipelining with futures. </title> <booktitle> Proc. Symposium on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: First we note that although the implementation uses fetch-and-add, the only places where it is used are for the processors to access the work queues (in which case we can get away with a small constant number of variables), and to handle the queues of suspended jobs. Other work <ref> [6] </ref> has shown that for certain types of code the number of reads to any synchronization variable can be limited to one, making the fetch-and-add unnecessary for handling the queues of suspended jobs.
Reference: [7] <author> R. D. Blumofe, C. F. Joerg, B. C. Kuszmaul, C. E. Leiseron, K. H. Randall, and Zhou Yuli. CILK: </author> <title> an efficient multithreaded runtime system. </title> <booktitle> In Proc. Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <pages> pages 207-216, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: These results were used to bound the time and space used by the Cilk programming language <ref> [7] </ref>. Blelloch, Gibbons and Matias [4] showed that for nested computations, the time bounds can be maintained while bounding the space by s 1 + O (pd), which for sufficient parallelism is just an additive factor over the sequential space.
Reference: [8] <author> R. D. Blumofe and C. E. Leiserson. </author> <title> Space-efficient scheduling of multithreaded computations. </title> <booktitle> In Proc. Symposium on Theory of Computing, </booktitle> <pages> pages 362-371, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Burton [11] first showed that for a certain class of computations the space required by a parallel implementation on p processors can be bound by p s 1 (s 1 space per processor). Blumofe and Leiserson <ref> [8, 9] </ref> then showed that this space bound can be maintained while also achieving good time bounds. <p> Planar dags are a more general class of dags than the computation dags considered in <ref> [8, 9, 4] </ref>. Previously, no space bounds were known for computations with synchronization variables, even in the case where the dags are planar. <p> Threads are shown as a vertical sequence of actions (nodes); each right-to-left edge represents a fork of a new thread, while each left-to-right edge represents a synchronization between two threads. 2 Programming model As with the work of Blumofe and Leiserson <ref> [8] </ref>, we model a computation as a set of threads, each comprised of a sequence of instructions. Threads can fork new threads and can synchronize through the use of write-once synchronization variables (henceforth just called synchronization variables). All threads share a single address space. <p> A task v is ready when all its parent tasks have been completed and the latencies on all edges into v have been satisfied, but v is yet to be scheduled. We say that a p-schedule is greedy <ref> [8] </ref> if 8i 2 1; : : : ; T ; jV i j &lt; p implies all ready tasks are scheduled on that step. Figure 3 shows an example task graph and a greedy p-schedule for it. The proof of the following theorem can be found in [29].
Reference: [9] <author> R. D. Blumofe and C. E. Leiserson. </author> <title> Scheduling mul-tithreaded computations by work stealing. </title> <booktitle> In Proc. 35th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 356-368, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Burton [11] first showed that for a certain class of computations the space required by a parallel implementation on p processors can be bound by p s 1 (s 1 space per processor). Blumofe and Leiserson <ref> [8, 9] </ref> then showed that this space bound can be maintained while also achieving good time bounds. <p> Planar dags are a more general class of dags than the computation dags considered in <ref> [8, 9, 4] </ref>. Previously, no space bounds were known for computations with synchronization variables, even in the case where the dags are planar.
Reference: [10] <author> F. W. Burton and M. R. Sleep. </author> <title> Executing functional programs on a virtual tree of processors. </title> <booktitle> In Proc. Conf. on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 187-194, </pages> <month> October </month> <year> 1981. </year>
Reference-contexts: A poor schedule can require exponentially more space than a good schedule [11]. Early solutions to the space problem considered various heuristics to reduce the number of active threads <ref> [10, 23, 34, 16, 26] </ref>. More recent work has considered provable bounds on space usage. The idea is to relate the space required by the parallel execution to the space s 1 required by the sequential execution.
Reference: [11] <author> F. Warren Burton. </author> <title> Storage management in virtual tree machines. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 37(3) </volume> <pages> 321-328, </pages> <year> 1988. </year>
Reference-contexts: This concern has been motivated in part by the high memory usage of many implementations of languages with dynamic parallelism, and by the fact that parallel computations are often memory limited. A poor schedule can require exponentially more space than a good schedule <ref> [11] </ref>. Early solutions to the space problem considered various heuristics to reduce the number of active threads [10, 23, 34, 16, 26]. More recent work has considered provable bounds on space usage. <p> More recent work has considered provable bounds on space usage. The idea is to relate the space required by the parallel execution to the space s 1 required by the sequential execution. Burton <ref> [11] </ref> first showed that for a certain class of computations the space required by a parallel implementation on p processors can be bound by p s 1 (s 1 space per processor).
Reference: [12] <author> D. Callahan and B. Smith. </author> <title> A future-based parallel language for a general-purpose highly-parallel computer. </title> <editor> In David Padua, David Gelernter, and Alexan-dru Nicolau, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, Research Monographs in Parallel and Distributed Computing, </booktitle> <pages> pages 95-113. </pages> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: All this work, however, has been limited to computations in which threads can only synchronize with their sibling or ancestor threads. Although this is a reasonably general class, it does not include languages based on futures <ref> [23, 27, 12, 14, 13] </ref>, languages based on lenient or speculative evaluation [1, 32], or languages with general user-specified synchronization constraints [33]. In this paper we show how to extend the results to support synchronization based on write-once synchronization variables.
Reference: [13] <author> M. C. Carlisle, A. Rogers, J. H. Reppy, and L. J. Hen-dren. </author> <title> Early experiences with OLDEN (parallel programming). </title> <booktitle> In Proc. International Workshop on Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 1-20. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1993. </year>
Reference-contexts: All this work, however, has been limited to computations in which threads can only synchronize with their sibling or ancestor threads. Although this is a reasonably general class, it does not include languages based on futures <ref> [23, 27, 12, 14, 13] </ref>, languages based on lenient or speculative evaluation [1, 32], or languages with general user-specified synchronization constraints [33]. In this paper we show how to extend the results to support synchronization based on write-once synchronization variables. <p> Pointers to such synchronization variables can be passed around among threads and synchronization can take place between two threads that have pointers to the variable. Such synchronization variables can be used to implement futures in such languages as Multilisp [23], Mul-T [27], Cool [14] and olden <ref> [13] </ref>; I-structures in ID [1]; events in PCF [38]; streams in sisal [18]; and are likely to be helpful in implementing the user-specified synchronization constraints in Jade [33].
Reference: [14] <author> R. Chandra, A. Gupta, and J. Hennessy. </author> <title> COOL: A Language for Parallel Programming. </title> <editor> In David Padua, David Gelernter, and Alexandru Nicolau, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, Research Monographs in Parallel and Distributed Computing, </booktitle> <pages> pages 126-148. </pages> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: All this work, however, has been limited to computations in which threads can only synchronize with their sibling or ancestor threads. Although this is a reasonably general class, it does not include languages based on futures <ref> [23, 27, 12, 14, 13] </ref>, languages based on lenient or speculative evaluation [1, 32], or languages with general user-specified synchronization constraints [33]. In this paper we show how to extend the results to support synchronization based on write-once synchronization variables. <p> Pointers to such synchronization variables can be passed around among threads and synchronization can take place between two threads that have pointers to the variable. Such synchronization variables can be used to implement futures in such languages as Multilisp [23], Mul-T [27], Cool <ref> [14] </ref> and olden [13]; I-structures in ID [1]; events in PCF [38]; streams in sisal [18]; and are likely to be helpful in implementing the user-specified synchronization constraints in Jade [33].
Reference: [15] <author> C. D. Clack and S. L. Peyton Jones. </author> <title> Strictness analysis a practical approach. </title> <booktitle> In Proc. Functional Program-minng Languages and Computer Architecture. </booktitle> <publisher> Springer-Verlag LNCS 201, </publisher> <month> Sept. </month> <year> 1985. </year>
Reference-contexts: However, since synchronizations are expensive in any implementation, there has been considerable work in reducing the number of synchronizations using compile-time analysis <ref> [19, 15, 35, 36, 25] </ref>. We plan to explore the use of such methods to improve the running time of our implementation.
Reference: [16] <author> D. E. Culler and Arvind. </author> <title> Resource requirements of dataflow programs. </title> <booktitle> In Proc. Intl. Symposium on Computer Architecture, </booktitle> <pages> pages 141-150, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: A poor schedule can require exponentially more space than a good schedule [11]. Early solutions to the space problem considered various heuristics to reduce the number of active threads <ref> [10, 23, 34, 16, 26] </ref>. More recent work has considered provable bounds on space usage. The idea is to relate the space required by the parallel execution to the space s 1 required by the sequential execution.
Reference: [17] <author> E.G. Coffman, Jr., </author> <title> editor. Computer and job-shop scheduling theory. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: If tasks are assigned priorities, and at every step, the tasks scheduled are the ready tasks with the highest priorities, we call the resulting schedule a prioritized schedule . This definition is similar to the class of list schedules described in <ref> [17] </ref>. Let S 1 be any 1-schedule for a task graph with n tasks, and let v 1 ; v 2 ; : : : ; v n be the tasks in the order they appear in S 1 .
Reference: [18] <author> J. T. Feo, D. C. Cann, and R. R. Oldehoeft. </author> <title> A Report on the Sisal Language Project. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 10(4) </volume> <pages> 349-366, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Many parallel languages allow for dynamic fine-grained parallelism and leave the task of mapping the parallelism onto processors to the implementation. Such languages include both data-parallel languages such as hpf [24] and nesl [3], and control-parallel languages such as Multilisp [23], id [1], sisal <ref> [18] </ref> and Proteus [28]. Since there is often significantly more parallelism expressed in these languages than there are processors, the implementation must not only decide onto which processors to schedule computations, but in what order to schedule them. <p> Such synchronization variables can be used to implement futures in such languages as Multilisp [23], Mul-T [27], Cool [14] and olden [13]; I-structures in ID [1]; events in PCF [38]; streams in sisal <ref> [18] </ref>; and are likely to be helpful in implementing the user-specified synchronization constraints in Jade [33]. We model computations that use synchronization variables as directed acyclic graphs (dags) in which each node is a unit time action and each edge represents either a control or data dependence between actions. <p> I-structures in id [1] can similarly be implemented with an array of pointers to synchronization variables and a fork for evaluating each value. Streams in sisal <ref> [18] </ref> can be implemented by associating a synchronization variable with each element (or block of elements) of the stream. We associate a directed acyclic graph (dag) called a computation graph with every computation in the model.
Reference: [19] <author> C. Flanagan and M. Felleisen. </author> <title> The semantics of future and its use in program optimizations. </title> <booktitle> In Proc. Symposium on Principles of Programming Languages, </booktitle> <pages> pages 209-220, </pages> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: However, since synchronizations are expensive in any implementation, there has been considerable work in reducing the number of synchronizations using compile-time analysis <ref> [19, 15, 35, 36, 25] </ref>. We plan to explore the use of such methods to improve the running time of our implementation.
Reference: [20] <author> Allan Gottlieb, B. D. Lubachevsky, and Larry Rudolph. </author> <title> Basic techniques for the efficient coordination of very large numbers of cooperating sequential processors. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 5(2), </volume> <month> April </month> <year> 1983. </year>
Reference-contexts: a parallel program with synchronization variables such that the computation has w work, synchronizations, d depth and s 1 sequential space, executes the computation in s 1 +O (pd log (pd)) space and O (w=p+ log (pd)=p+ d log (pd)) time on a p-processor crcw pram with a fetch-and-add primitive <ref> [20] </ref>. This includes all time and space costs for both the computation and the scheduler. This algorithm is work-efficient for computations in which there are (log (pd)) units of work per synchronization (on average).
Reference: [21] <author> R. L. Graham. </author> <title> Bounds for certain multiprocessing anomalies. </title> <journal> The Bell System Technical Journal, </journal> <volume> 45(9) </volume> <pages> 1563-1581, </pages> <year> 1966. </year>
Reference-contexts: There has been a large body of work on how to schedule computations so as to minimize running time. This work dates back at least to the results by Graham <ref> [21] </ref>. More recently, in addition to time, there has been significant concern about space. This concern has been motivated in part by the high memory usage of many implementations of languages with dynamic parallelism, and by the fact that parallel computations are often memory limited.
Reference: [22] <author> J. Greiner and G. E. Blelloch. </author> <title> A provably time-efficient parallel implementation of full speculation. </title> <booktitle> In Proceedings of the 23rd ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 309-321, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: To maintain the priorities we introduce a black-white priority-queue data structure, in which each element (thread) is colored either black (ready) or white (suspended), and describe an efficient implementation of the data structure based on 2-3 trees. In addition, we use previous ideas <ref> [22] </ref> for efficiently maintaining the queues of suspended threads which need to be associated with each synchronization variable. As with [29], our sched-uler is asynchronous (its execution overlaps asynchronously with the computation) and non-preemptive (threads execute uninterrupted until they suspend, fork, allocate memory or terminate). <p> The other operation the scheduler needs to perform is to handle the queues of threads waiting on synchronization variables. We use an array for each queue, which we will call a synchronization queue <ref> [22] </ref>. Aiming for an efficient implementation of the scheduler, we set q max to be p and the maximum task space M to be log (pd). <p> This is based on Lemma 5.1 and previous bounds that state that n threads can be reawak-ened from a set of synchronization queues <ref> [22] </ref> in O (n=p) time on a crcw pram with fetch-and-add. Since at most threads will be awakened during a computation, the sum of the above time over m scheduling iterations is bound by O ((=p + m) log jLj). Again based on previous results [22] the cost of suspending threads <p> a set of synchronization queues <ref> [22] </ref> in O (n=p) time on a crcw pram with fetch-and-add. Since at most threads will be awakened during a computation, the sum of the above time over m scheduling iterations is bound by O ((=p + m) log jLj). Again based on previous results [22] the cost of suspending threads (placing them in the synchronization queues) can be amortized against the cost of reawakening them.
Reference: [23] <author> R. H. Halstead, Jr. </author> <title> Multilisp: A language for concurrent symbolic computation. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 7(4) </volume> <pages> 501-538, </pages> <year> 1985. </year>
Reference-contexts: 1 Introduction Many parallel languages allow for dynamic fine-grained parallelism and leave the task of mapping the parallelism onto processors to the implementation. Such languages include both data-parallel languages such as hpf [24] and nesl [3], and control-parallel languages such as Multilisp <ref> [23] </ref>, id [1], sisal [18] and Proteus [28]. Since there is often significantly more parallelism expressed in these languages than there are processors, the implementation must not only decide onto which processors to schedule computations, but in what order to schedule them. <p> A poor schedule can require exponentially more space than a good schedule [11]. Early solutions to the space problem considered various heuristics to reduce the number of active threads <ref> [10, 23, 34, 16, 26] </ref>. More recent work has considered provable bounds on space usage. The idea is to relate the space required by the parallel execution to the space s 1 required by the sequential execution. <p> All this work, however, has been limited to computations in which threads can only synchronize with their sibling or ancestor threads. Although this is a reasonably general class, it does not include languages based on futures <ref> [23, 27, 12, 14, 13] </ref>, languages based on lenient or speculative evaluation [1, 32], or languages with general user-specified synchronization constraints [33]. In this paper we show how to extend the results to support synchronization based on write-once synchronization variables. <p> Pointers to such synchronization variables can be passed around among threads and synchronization can take place between two threads that have pointers to the variable. Such synchronization variables can be used to implement futures in such languages as Multilisp <ref> [23] </ref>, Mul-T [27], Cool [14] and olden [13]; I-structures in ID [1]; events in PCF [38]; streams in sisal [18]; and are likely to be helpful in implementing the user-specified synchronization constraints in Jade [33].
Reference: [24] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification, </title> <month> May </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Many parallel languages allow for dynamic fine-grained parallelism and leave the task of mapping the parallelism onto processors to the implementation. Such languages include both data-parallel languages such as hpf <ref> [24] </ref> and nesl [3], and control-parallel languages such as Multilisp [23], id [1], sisal [18] and Proteus [28].
Reference: [25] <author> J. E. Hoch, D. M. Davenport, V. G. Grafe, and K. M. Steele. </author> <title> Compile-time partitioning of a non-strict language into sequential threads. </title> <booktitle> In Proc. Symposium on Parallel and Distributed Computing, </booktitle> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: However, since synchronizations are expensive in any implementation, there has been considerable work in reducing the number of synchronizations using compile-time analysis <ref> [19, 15, 35, 36, 25] </ref>. We plan to explore the use of such methods to improve the running time of our implementation.
Reference: [26] <author> S. Jagannathan and J. Philbin. </author> <title> A foundation for an efficient multi-threaded Scheme system. </title> <booktitle> In Proc. 1992 ACM Conf. on Lisp and Functional Programming, </booktitle> <pages> pages 345-357, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: A poor schedule can require exponentially more space than a good schedule [11]. Early solutions to the space problem considered various heuristics to reduce the number of active threads <ref> [10, 23, 34, 16, 26] </ref>. More recent work has considered provable bounds on space usage. The idea is to relate the space required by the parallel execution to the space s 1 required by the sequential execution.
Reference: [27] <author> D. A. Krantz, R. H. Halstead, Jr., and E. Mohr. </author> <month> Mul-T: </month>
Reference-contexts: All this work, however, has been limited to computations in which threads can only synchronize with their sibling or ancestor threads. Although this is a reasonably general class, it does not include languages based on futures <ref> [23, 27, 12, 14, 13] </ref>, languages based on lenient or speculative evaluation [1, 32], or languages with general user-specified synchronization constraints [33]. In this paper we show how to extend the results to support synchronization based on write-once synchronization variables. <p> Pointers to such synchronization variables can be passed around among threads and synchronization can take place between two threads that have pointers to the variable. Such synchronization variables can be used to implement futures in such languages as Multilisp [23], Mul-T <ref> [27] </ref>, Cool [14] and olden [13]; I-structures in ID [1]; events in PCF [38]; streams in sisal [18]; and are likely to be helpful in implementing the user-specified synchronization constraints in Jade [33].
References-found: 27

