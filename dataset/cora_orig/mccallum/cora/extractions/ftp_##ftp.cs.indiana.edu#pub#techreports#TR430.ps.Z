URL: ftp://ftp.cs.indiana.edu/pub/techreports/TR430.ps.Z
Refering-URL: http://www.cs.indiana.edu/trindex.html
Root-URL: 
Email: nsundare@cs.indiana.edu gannon@cs.indiana.edu  
Title: Coir: A Thread-Model for Supporting Task- and Data- Parallelism in Object-Oriented Parallel Languages  
Author: Neelakantan Sundaresan Dennis Gannon 
Address: 215 Lindley Hall  Bloomington, IN 47405  
Affiliation: Computer Science Department  Indiana University  
Abstract: We propose a thread model of parallelism that addresses both data and task parallelism. Computation and communication can be overlapped by suspending a thread of computation which is waiting for an event and running an eligible thread of computation in its place. Threads naturally subsume task-parallelism. Threads are encapsulated into thread objects may be grouped into rope objects [22, 20], that span the parallel machine domain, for collective computation and communication. Thus data-parallelism can be supported. Since rope objects are parallel objects, they can be customized, interestingly, in a serial or a parallel manner. Spatial transparency of objects is achieved by global pointer templates. We present results from a prototype system running on the SGI Challenge and the Intel Paragon. keywords: task-parallelism, data-parallelism, thread, rope, object-oriented paradigm 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Peter Beckman, Dennis Gannon, and Neelakantan Sundaresan. </author> <title> pC++ Meets Multi-Threaded Computation. </title> <editor> In Jack Dongarra and Bernard Tourancheau, editors, </editor> <booktitle> Proceedings of the second workshop on Environments and Tools for Parallel Scientific Computing, </booktitle> <address> Philadelphia, </address> <month> May </month> <year> 1994. </year> <note> SIAM. </note>
Reference-contexts: Our approach is library-based and addresses both data and task parallel issues. The library provides a target model and runtime system for parallel extensions to C++ like pC++[15]. The relevance of this model to pC++ is discussed in <ref> [1] </ref>. The library itself is extensible, with Inheritance 2 and polymorphism, for an advanced user to be able to write programs in C++ using the model. It is built in a hierarchical manner, for easily portability and interface with other similar systems. The paper is organized as follows. <p> In the future, we will study the advantages of this model over a pure data-parallel model by studying irregular and adaptive algorithms with regular components. We are using this model and this library to build parallel language extensions in pC++-2.0 <ref> [1] </ref> and an interface for global active objects.
Reference: [2] <author> Brian Bershad, Edward Lazowska, and Henry Levy. </author> <title> Presto: A system for object-oriented parallel programming. </title> <journal> Software-Practice and Experience, </journal> <volume> 18(8) </volume> <pages> 713-732, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Those with C++ interface for sequential and shared memory machines include Awesime [10] and Presto <ref> [2] </ref>.
Reference: [3] <author> Mani Chandy and Carl Kesselman. </author> <title> Compositional CC++: A Declarative Concurrent Object-Oriented Programming Notation. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference: [4] <author> Eric C. Cooper and Richard P. Draves. </author> <title> C Threads. </title> <type> Technical Report CMU-CS-88-154, </type> <institution> Carnegie Mellon University, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: There are a variety of other thread libraries those from the vendors include DCE threads, SGI sprocs and SUN light weight processes; and others from the university communities include NewThreads [6](which has a communication model) and Cthreads <ref> [4] </ref> and its extensions [17]. Those with C++ interface for sequential and shared memory machines include Awesime [10] and Presto [2].
Reference: [5] <author> Edward Felten and Dylan McNamee. </author> <title> Improving the Performance of Message-Passing Applications by Multithreading. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference(SHPCC-92), 1992. </booktitle> <address> Williamsburg VA. </address>
Reference-contexts: Thus the total cost is kfi ( R which is fi ( P This formula is very approximate as we do not take into account cost of context switches and thread management. This is offset by the effect of overlapping communication with computation <ref> [5, 7, 11] </ref>. For fixed P and N , the cost is fi ((log K) 2 ); for fixed N and k, the cost is fi ((log P ) 2 =P ); and for fixed k and P , it is fi (N log N ).
Reference: [6] <author> Edward Felten and Dylan McNamee. </author> <title> NewThreads2.0 User's Guide, August 1992. </title> <address> Williamsburg VA. </address>
Reference: [7] <author> Ian Foster, Carl Kesselman, Robert Olson, and Steve Tuecke. </author> <title> Nexus: An Interoperability Layer for Parallel and Distributed Systems. </title> <type> Technical report, </type> <institution> California Institute of Technology, Computer Science Department, Pasadena, </institution> <address> CA., </address> <month> August </month> <year> 1994. </year>
Reference-contexts: Thus the total cost is kfi ( R which is fi ( P This formula is very approximate as we do not take into account cost of context switches and thread management. This is offset by the effect of overlapping communication with computation <ref> [5, 7, 11] </ref>. For fixed P and N , the cost is fi ((log K) 2 ); for fixed N and k, the cost is fi ((log P ) 2 =P ); and for fixed k and P , it is fi (N log N ).
Reference: [8] <author> Dennis Gannon. </author> <title> Private Communication. </title>
Reference-contexts: The member-function interface is the same as that for Thread class except that, for threads which are remote it sends a message to the processor on which the thread resides and the necessary function is locally executed and a result is returned <ref> [8] </ref>. Message-Passing View Message passing can take place between two threads in the same processor context or different processor contexts in the same subdomain or different subdomains.
Reference: [9] <author> Andrew Grimshaw. </author> <title> Easy-to-use Object-Oriented Parallel Processing with Mentat. </title> <booktitle> IEEE Computer, </booktitle> <month> May </month> <year> 1993. </year> <month> 17 </month>
Reference: [10] <author> Dirk Grunwald. </author> <title> A Users Guide to AWESIME: An Object-Oriented Parallel Programming and Simu--lation System. </title> <type> Technical Report CU-CS-552-91, </type> <institution> University of Colorado, Boulder, Colorado, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: Those with C++ interface for sequential and shared memory machines include Awesime <ref> [10] </ref> and Presto [2].
Reference: [11] <author> Matthew Haines, David Cronk, and Piyush Mehrotra. </author> <title> On the design of Chant: A Talking Threads Package. </title> <booktitle> In Proceedings of Supercomputing 94, </booktitle> <address> Washington D.C., </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Thus the total cost is kfi ( R which is fi ( P This formula is very approximate as we do not take into account cost of context switches and thread management. This is offset by the effect of overlapping communication with computation <ref> [5, 7, 11] </ref>. For fixed P and N , the cost is fi ((log K) 2 ); for fixed N and k, the cost is fi ((log P ) 2 =P ); and for fixed k and P , it is fi (N log N ).
Reference: [12] <author> IEEE. </author> <title> Thread Extensions for Portable Operating Systems (Draft 6), </title> <month> February </month> <year> 1992. </year> <month> P1003.4a/6. </month>
Reference: [13] <author> Laxmikant Kale and Sanjeev Krishnan. CHARM++: </author> <title> A Portable Concurrent Object-Oriented System Based on C++. </title> <type> Technical report, </type> <institution> University of Illinois, Urbana-Champaign, </institution> <month> March </month> <year> 1993. </year>
Reference: [14] <author> Allen Malony, Bernd Mohr, Peter Beckman, and Dennis Gannon. </author> <title> Program Analysis and Tuning Tools for a Parallel Object Oriented Language: An Experiment with the TAU System. </title> <note> To appear. </note>
Reference-contexts: fl = 2) this thr.merge (i); g instantiate it with any other class derived from the Thread class 3 template &lt;class ThreadClass&gt; class RopeTemplate f g; The simplest instantiation of this template is the rope class which is RopeTemplate&lt;Thread&gt; 5 An Example: Bitonic Sort We describe a bitonic merge-sort program <ref> [14] </ref> written in our model (refer figure 4). The program was adapted from a parallel version bitonic sort for coarse-grain object parallelism, written in pC++[14]. The data, of size N , is divided among the threads of a rope of size R.
Reference: [15] <author> Allen Malony, Bernd Mohr, Peter Beckman, Dennis Gannon, Shelby Yang, Fran~cois Bodin, and S Ke-savan. </author> <title> Implementing a Parallel C++ Runtime System for Scalable Parallel Systems. </title> <booktitle> Proceedings, Supercomputing '93, </booktitle> <pages> pages 588-597, </pages> <month> November </month> <year> 1993. </year> <journal> ACM Sigarch and IEEE Computer Society Technical Committees on Supercomputing Applications and Computer Architecture. </journal>
Reference: [16] <author> Frank Mueller. </author> <title> Pthreads Library Interface. </title> <type> Technical report, </type> <institution> Florida State University, </institution> <month> July </month> <year> 1993. </year>
Reference: [17] <author> Bodhisattwa Mukherjee, Greg Eisenhauer, and Kaushik Ghosh. </author> <title> A Machine Independent Interface for LightWeight Threads. </title> <type> Technical Report GIT-CC-93/53, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: There are a variety of other thread libraries those from the vendors include DCE threads, SGI sprocs and SUN light weight processes; and others from the university communities include NewThreads [6](which has a communication model) and Cthreads [4] and its extensions <ref> [17] </ref>. Those with C++ interface for sequential and shared memory machines include Awesime [10] and Presto [2].
Reference: [18] <author> Stephen Murer, Jerome Feldman, and Chu-Cheow Lim. </author> <title> pSather monitors: Design, Tutorial, Rationale and Implementation. </title> <type> Technical Report TR-93-028, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> CA., </address> <month> June </month> <year> 1993. </year>
Reference: [19] <author> Neelakantan Sundaresan. </author> <title> A thread model for supporting task and data parallelism in object-oriented parallel languages. Presentation at the Parallel Object-Oriented Machines and Applications Workshop, </title> <address> POOMA 94, </address> <year> 1994. </year> <month> 18 </month>
Reference-contexts: These objects can be customized to specific application target by using object-oriented features like Inheritance, polymor-phism, dynamic dispatch and parameterized data types. This model was introduced for shared memory machines in [22] and later generalized in <ref> [21, 19] </ref>. A detailed discussion on rope objects and their implementation can be found in [20]. Our approach is library-based and addresses both data and task parallel issues. The library provides a target model and runtime system for parallel extensions to C++ like pC++[15].
Reference: [20] <author> Neelakantan Sundaresan and Dennis Gannon. </author> <title> Implementation of Ropes: An Aggregate Thread Class Library for Parallelism. </title> <institution> Indiana University, Computer Science Department, </institution> <type> Technical Report. </type> <note> In preparation, </note> <year> 1995. </year>
Reference-contexts: This model was introduced for shared memory machines in [22] and later generalized in [21, 19]. A detailed discussion on rope objects and their implementation can be found in <ref> [20] </ref>. Our approach is library-based and addresses both data and task parallel issues. The library provides a target model and runtime system for parallel extensions to C++ like pC++[15]. The relevance of this model to pC++ is discussed in [1]. <p> A domain object denotes the space over which threads are distributed and computation is done. Operations on a domain object lets the user define or compose subsets. These operations are useful in defining rope contexts and implementing nested parallelism <ref> [20] </ref>. 3 Threads A thread 1 is a unit of control for parallel execution. A thread may be created whenever the program sees a separate control of execution independent of the current thread. <p> Choosing the context-model minimizes unnecessary message passing at the same time avoids the disadvantages of unnecessary synchronization unlike in the SPMD model. The context model also provides a good way to define, represent and compile constructs for nested-parallelism <ref> [20] </ref>. 4.1 Customizing Rope Objects Rope objects can be customized to application-specific data-parallel active objects using the Inheritance facility in C++. <p> The effect of thread distribution on communication is studied in <ref> [20] </ref>. 12 5.1 Performance We studied the performance of our library on the bitonic sort program. We concentrated on issues like independence of rope sizes to processors, interference of threads on the same processor within ropes and across ropes.
Reference: [21] <author> Neelakantan Sundaresan and Linda Lee. </author> <title> A Thread-based Object-Oriented Expansible Library Model for Parallelism:Abstract. </title> <booktitle> Poster presentation at the Scalable High-Performance Computing Conference, </booktitle> <address> Knoxville, Tennessee, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: These objects can be customized to specific application target by using object-oriented features like Inheritance, polymor-phism, dynamic dispatch and parameterized data types. This model was introduced for shared memory machines in [22] and later generalized in <ref> [21, 19] </ref>. A detailed discussion on rope objects and their implementation can be found in [20]. Our approach is library-based and addresses both data and task parallel issues. The library provides a target model and runtime system for parallel extensions to C++ like pC++[15].
Reference: [22] <author> Neelakantan Sundaresan and Linda Lee. </author> <title> An Object-Oriented Thread Model for Parallel Numerical Applications. </title> <booktitle> In Proceedings of the second annual Object-Oriented Numerics Conference, </booktitle> <month> April </month> <year> 1994. </year> <institution> Sunriver, Oregon. </institution> <month> 19 </month>
Reference-contexts: Thread objects provide abstractions for control parallelism and rope objects provide abstractions for data parallelism. These objects can be customized to specific application target by using object-oriented features like Inheritance, polymor-phism, dynamic dispatch and parameterized data types. This model was introduced for shared memory machines in <ref> [22] </ref> and later generalized in [21, 19]. A detailed discussion on rope objects and their implementation can be found in [20]. Our approach is library-based and addresses both data and task parallel issues. The library provides a target model and runtime system for parallel extensions to C++ like pC++[15].
References-found: 22

