URL: http://vis-www.cs.umass.edu/vislib/Papers/rochwerger/cvpr94.ps.gz
Refering-URL: http://vis-www.cs.umass.edu/vislib/Papers/rochwerger/files.html
Root-URL: 
Title: Executing Reactive Behavior for Autonomous Navigation (Extended Abstract)  
Author: Benny Rochwerger Claude L. Fennema Bruce Draper Allen R. Hanson Edward M. Riseman 
Address: Amherst, MA 01003  
Affiliation: Computer Vision Laboratory Dept. of Computer Science University of Massachusetts  
Abstract: Complex problems, such as driving, can be solved more easily by decomposing them into smaller sub-problems, solving each sub-problem, and then integrating the solutions. In the case of an autonomous vehicle, the integrated system should be able to "react" in real time to a changing environment and to "reason" about ways to achieve its goals. This paper describes the approach taken on the UMass Mobile Perception Laboratory (MPL) to integrate independent processes (each solving a particular aspect of the navigation problem) into a fully capable autonomous vehicle. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Beveridge. </author> <title> Local search algorithms for geometric object recognition: Optimal correspondence and pose. </title> <type> Ph.D. </type> <institution> Thesis CMPSCI TR93-71, University of Massachusetts at Amherst, </institution> <year> 1993. </year>
Reference-contexts: 2 E + s:t: ^ ffi (b; s b ) = f etch goal where ^ ffi is the transition function applied to a sequence of events. 4 An example The following perception-action processes have been successfully tested on the MPL: * Vehicle pose determination based on landmark model matching <ref> [1, 5] </ref>. * Neural-network road following (ALVINN) [7]. * Servo-based steering [4]. * Obstacle detection via stereo. * Reflexive obstacle avoidance. * A distance monitor. * Turning via dead reckoning. Theses processes were combined in a script to achieve the following: 1.
Reference: [2] <author> J. Brolio et al. </author> <title> The ISR: an intermediate-level database for computer vision. </title> <journal> Computer, </journal> <volume> 22(12) </volume> <pages> 22-30, </pages> <year> 1989. </year>
Reference-contexts: Since the latter is unpredictable, so is the former. To pro 1 In its current incarnation, the blackboard is built on top of the ISR3 a symbolic real-time database for vision <ref> [2] </ref>. state machine (FSM) representation. Listed below the state name are the perception-action processes that should be run and killed (marked with a ~ ) in that state.
Reference: [3] <author> R. A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-2(1), </volume> <month> March </month> <year> 1986. </year>
Reference-contexts: A combination of behaviors is also called a behavior, thus, a complex behavior can be achieved by combining simpler behaviors. In Brooks' subsumption architecture <ref> [3] </ref>, the task of robot control is decomposed into levels of competence; each level, in combination with lower levels, defines a behavior.
Reference: [4] <author> C. L. Fennema. </author> <title> Interweaving reason, action and perception. </title> <type> Ph.D. Thesis COINS TR91-56, </type> <institution> University of Massachusetts, </institution> <year> 1991. </year>
Reference-contexts: f etch goal where ^ ffi is the transition function applied to a sequence of events. 4 An example The following perception-action processes have been successfully tested on the MPL: * Vehicle pose determination based on landmark model matching [1, 5]. * Neural-network road following (ALVINN) [7]. * Servo-based steering <ref> [4] </ref>. * Obstacle detection via stereo. * Reflexive obstacle avoidance. * A distance monitor. * Turning via dead reckoning. Theses processes were combined in a script to achieve the following: 1. Drive on the road, while avoiding obstacles, for x meters. distance, then check position.
Reference: [5] <author> R. Kumar. </author> <title> Model dependent inference of 3D information from a sequence of 2D images. </title> <type> Ph.D. Thesis COINS TR92-04, </type> <institution> University of Massachusetts at Amherst, </institution> <year> 1992. </year>
Reference-contexts: 2 E + s:t: ^ ffi (b; s b ) = f etch goal where ^ ffi is the transition function applied to a sequence of events. 4 An example The following perception-action processes have been successfully tested on the MPL: * Vehicle pose determination based on landmark model matching <ref> [1, 5] </ref>. * Neural-network road following (ALVINN) [7]. * Servo-based steering [4]. * Obstacle detection via stereo. * Reflexive obstacle avoidance. * A distance monitor. * Turning via dead reckoning. Theses processes were combined in a script to achieve the following: 1.
Reference: [6] <author> D. W. Payton, K. Rosenblatt, and D. M. Keirsey. </author> <title> Plan guided reaction. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <pages> pages 1370-1382, </pages> <year> 1990. </year>
Reference-contexts: In Brooks' subsumption architecture [3], the task of robot control is decomposed into levels of competence; each level, in combination with lower levels, defines a behavior. Pay-ton, Rosenblatt and Keirsey <ref> [6] </ref> in their Distributed Architecture for Mobile Navigation system (DAMN), refer to behaviors as very low level decision-making processes which are guided by high level plans and combined through arbitration. <p> These definitions, although consistent, can be confusing the same term is used for individual processes and for the composition of these processes. To make the distinction clear, we have chosen to think of a behavior as a mode of operation <ref> [6] </ref>, in which several perception-action processes [9] are executed concurrently. Each process converts sensory data into some kind of action (either physical or cognitive), and at any time may generate an event a signal to let the system know that "something" significant has occurred.
Reference: [7] <author> D. A. Pomerleau. </author> <title> Neural network based autonomous navigation. </title> <editor> In Charles Thorpe, editor, </editor> <booktitle> Vision and Navigation: </booktitle> <address> The CMU Navlab. </address> <publisher> Kluwer Academic Publishers, </publisher> <year> 1990. </year>
Reference-contexts: s b ) = f etch goal where ^ ffi is the transition function applied to a sequence of events. 4 An example The following perception-action processes have been successfully tested on the MPL: * Vehicle pose determination based on landmark model matching [1, 5]. * Neural-network road following (ALVINN) <ref> [7] </ref>. * Servo-based steering [4]. * Obstacle detection via stereo. * Reflexive obstacle avoidance. * A distance monitor. * Turning via dead reckoning. Theses processes were combined in a script to achieve the following: 1. Drive on the road, while avoiding obstacles, for x meters. distance, then check position.
Reference: [8] <author> P. J. Ramadge and W. M. Wonham. </author> <title> The control of discrete event systems. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 77(1) </volume> <pages> 81-98, </pages> <month> January </month> <year> 1989. 1994. </year>
Reference-contexts: Pay-ton, Rosenblatt and Keirsey [6] in their Distributed Architecture for Mobile Navigation system (DAMN), refer to behaviors as very low level decision-making processes which are guided by high level plans and combined through arbitration. In their DEDS work, Ramadge and Wonham <ref> [8] </ref>, events are considered the alphabet, , of a formal language; a behavior is a sequence of events, or a string over fl . Note that in this terminology every prefix of a string is also a behavior, i.e., the sequential combination of behaviors is a behavior.
Reference: [9] <author> B. Rochwerger et al. </author> <title> Executing reactive behavior for autonomous navigation. </title> <type> Technical Report CMPSCI TR94-05, </type> <institution> University of Massachusetts at Amherst, </institution> <year> 1994. </year>
Reference-contexts: These definitions, although consistent, can be confusing the same term is used for individual processes and for the composition of these processes. To make the distinction clear, we have chosen to think of a behavior as a mode of operation [6], in which several perception-action processes <ref> [9] </ref> are executed concurrently. Each process converts sensory data into some kind of action (either physical or cognitive), and at any time may generate an event a signal to let the system know that "something" significant has occurred. <p> For example, consider the FSM in Figure 2. This system will drive on the road while obeying traffic lights, until a given distance is travelled. Based on the notion of behaviors represented as states of a finite state machines, we have implemented a Behavior Description Language (BDL) <ref> [9] </ref>. Behaviors are described as two sets of perception-action processes, and a transition table. The run set specifies the minimum set of processes that form the behavior; the kill set specifies those processes that should not be running for the correct execution of the behavior.
References-found: 9

