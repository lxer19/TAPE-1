URL: http://www.ius.cs.cmu.edu/afs/cs/usr/brajovic/ftp/icra96.ps.Z
Refering-URL: http://www.ius.cs.cmu.edu/afs/cs/usr/brajovic/www/lab/vlsi.html
Root-URL: 
Title: A Sorting Image Sensor: An Example of Massively Parallel IntensitytoTime Processing for LowLatency Computational Sensors  
Author: Vladimir Brajovic and Takeo Kanade 
Date: April 1996  
Address: Minneapolis, Minnesota  Pittsburgh, PA 15213  
Affiliation: Robotics and Automation  The Robotics Institute Carnegie Mellon University  
Note: Proceedings of the 1996 IEEE International Conference on  0-7803-2988-4/96 $4.00 1996 IEEE 1638 Anton Philips Prize for the Best Student Paper  
Abstract: The need for low-latency vision systems is growing: high speed visual servoing and visionbased human computer interface. In this paper we present a new intensitytotime processing paradigm suitable for lowlatency massively parallel global computation over finegrained data such as images. As an example of a lowlatency global computation, we have developed a VLSI sorting computational sensor a sensor which sorts all pixels of an input image by their intensities, as the image is being sensed. The first sorting sensor prototype is a 21 by 26 array of cells. It detects an image focused thereon and computes the image of indices as well as the images cumulative histogram, before the intensity data are readout. The image of indices never saturates and has uniform histogram. Under users control, the chip can perform other operations including simple segmentation and labeling. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ballard, D.H. and C.M. Brown, </author> <title> Computer Vision, </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: This time waveform is closely related to a cumulative histogram of the input image. The time derivative of this signal is related to a histogram of the input image <ref> [1] </ref>. This is one global property of the input image that is reported by the chip with very low latency. 4 VLSI Realization and Evaluation A 21 x 26 cell sorting sensor has been built in 2m CMOS technology. <p> Histogram Equalization. When the voltage of the cumulative histogram (computed by the chip itself) is supplied to the local processors, the generated image is a histogram equalized version of the input image <ref> [1] </ref>. This is the basic mode of operation for the sorting chip and has been illustrated in the previous section. Linear Imaging. <p> Image Segmentation. Thresholding is a rudimentary technique to segment an image into regions. The cumulative histogram can be used to determine this threshold. Pixels from a single region often have pixels of similar intensity that appear as clusters in the image histogram <ref> [1] </ref>. The values which ought to be stored in the cells can be generated to correspond to the label of each such region. The global processor can perform this labeling by updating the supplied value when the transition between the clusters in the (cumulative) histogram is detected.
Reference: [2] <author> Brajovic, V. and T. Kanade, </author> <title> Computational Sensors for Global Operations, </title> <booktitle> IUS Proceedings, </booktitle> <pages> pp. 621-630, </pages> <year> 1994. </year>
Reference-contexts: However, implementing global operations in hardware is not trivial. The main difficulty comes from the necessity to bring together, or aggregate, all or most of the data in the input data set <ref> [2] </ref>. This global exchange of data among a large number of processors/sites quickly saturates communication connections and adversely affects computing efficiency in parallel systems parallel digital computers and computational sensors alike.
Reference: [3] <author> Burgi, P.Y. and T. Pun, </author> <title> Asynchrony in Image Analysis: using the luminancetoresponselatency relationship to improve segmentation, </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> Vol. 11, No. 6, </volume> <month> June </month> <year> 1994, </year> <pages> pp. 17201726 </pages>
Reference-contexts: A single global processor supervises and services the array of cells. Since local processors trigger at times determined by the magnitude of their input operands, the global processor serves only a few local processors at a time. The intensitytotime relationship has been used to improve image segmentation <ref> [3] </ref> a local operation, and for image processing in a SIMD architecture [4]. In contrast, our architecture allows global operations and shares some features of traditional MIMD parallel processing.
Reference: [4] <author> Forchheimer R. and A. Astrom, </author> <title> NearSensor Image Processing: A New Paradigm, </title> <journal> IEEE Trans. on Image Proc., </journal> <volume> Vol. 3, No. 6, </volume> <pages> pp. 736746, </pages> <month> Novem-ber </month> <year> 1994. </year>
Reference-contexts: Since local processors trigger at times determined by the magnitude of their input operands, the global processor serves only a few local processors at a time. The intensitytotime relationship has been used to improve image segmentation [3] a local operation, and for image processing in a SIMD architecture <ref> [4] </ref>. In contrast, our architecture allows global operations and shares some features of traditional MIMD parallel processing.
Reference: [5] <author> Kanade, T. and R. </author> <title> Bajcsy, Computational Sensors: </title>
Reference-contexts: These two examples point to two main sources of latency in vision systems: data transfer bottleneck and the computational load bottleneck. It is clear that an alternative is needed. The computational sensor paradigm <ref> [5] </ref> has potential to greatly reduce latency. By integrating sensing and processing on a VLSI chip both transfer and computational bottlenecks can be alleviated. Onchip routing provides high throughput transfer, while an on-chip processor could implement massively parallel computational models. <p> Onchip routing provides high throughput transfer, while an on-chip processor could implement massively parallel computational models. A great majority of computational sensory solutions so far implement local operations on a single light sensitive VLSI chip (for examples see <ref> [5] </ref> [6] [8]). Local operations use operands within a small spatial/temporal neighborhood of data and thus land themselves to the graceful implementation in VLSI. Typical examples include smoothing and edge detection.
References-found: 5

