URL: http://logic.stanford.edu/papers/on-site.ps
Refering-URL: http://logic.stanford.edu/papers/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: ofer@cs.stanford.edu  
Title: On-Site Learning  
Author: Ofer Matan 
Date: April 3, 1995  
Address: CA 94305  
Affiliation: Department of Computer Science Stanford University,  
Abstract: A model for on-site learning is presented. The system learns by querying "hard" patterns while classifying "easy" ones. This model is related to query-based filtering methods, but takes into account that in addition to labelling, filtering through the data has a cost. A few simple policies are introduced and analyzed for a simple problem (1D high low game). In addition the Query-by-Committee algorithm (Seung et. al) is suggested as a good approximator of the model space for real-world domains. Results using this algorithm on a synthesized problem and a real-world OCR task using both a backpropagation network and a nearest neighbor classifier show that an on-site learner can perform as well as a classifier trained off-site, while achieving significant cost reduction. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Dana Angluin. </author> <title> Queries and concept learning. </title> <booktitle> ML, </booktitle> <volume> 2 </volume> <pages> 319-342, </pages> <year> 1988. </year>
Reference-contexts: There has been both theoretical <ref> [1] </ref> and experimental study of this paradigm [2]. The method chooses informative patterns and requests labels from a teacher. The limitation of this method is that it considers only optimally learning the concept without regard to the distribution of the data in the execution stage. <p> In the following section we show the solution for a simple one-dimensional problem. 4.1 An example: the high low game As an example we study the one dimensional high-low game. The concept is a point h on the interval <ref> [0; 1] </ref>. Points less than h are labeled negatively and those greater than or equal to h, are labeled positively. The version space, V [x min ] is between the largest negative example and the smallest positive example seen so far. <p> The version space, V [x min ] is between the largest negative example and the smallest positive example seen so far. P c is 1 outside the version space and less than one inside. We assume that the example distribution is uniform over <ref> [0; 1] </ref>.
Reference: [2] <author> Eric Baum. </author> <title> Neural net algorithms that learn in polynomial time from examples and queries. </title> <journal> IEEE Trans. Neural Networks, </journal> <volume> 2 </volume> <pages> 5-19, </pages> <year> 1991. </year>
Reference-contexts: The information captured by a corpus as a function of its size flattens out quickly. For particular problems, one can show that the expected information gain of a pattern's label diminishes exponentially [13]. Work in query-based methods <ref> [3, 2, 13] </ref> has dealt with the issue of minimizing labeling cost, but it ignores the cost of waiting for the informative patterns. <p> There has been both theoretical [1] and experimental study of this paradigm <ref> [2] </ref>. The method chooses informative patterns and requests labels from a teacher. The limitation of this method is that it considers only optimally learning the concept without regard to the distribution of the data in the execution stage.
Reference: [3] <author> D. Cohen, L. Atlas, and R. Ladner. </author> <title> Training connectionist networks with queries and selective sampling. </title> <editor> In Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 2. </volume> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year>
Reference-contexts: The information captured by a corpus as a function of its size flattens out quickly. For particular problems, one can show that the expected information gain of a pattern's label diminishes exponentially [13]. Work in query-based methods <ref> [3, 2, 13] </ref> has dealt with the issue of minimizing labeling cost, but it ignores the cost of waiting for the informative patterns. <p> Each time an additional 20 new patterns had been queried, the committee was retrained on the complete set of queried patterns. This is similar to the method described in <ref> [3] </ref>, yet differs in that we use the current networks as the new initial points. In this work we did not concern ourselves with the computational requirements of the methods.
Reference: [4] <author> Belur V. Dasarathy, </author> <title> editor. Nearest neighbor (NN) norms : NN pattern classification techniques. </title> <publisher> IEEE Computer Society Press, </publisher> <year> 1991. </year>
Reference-contexts: The results for the nearest neighbor classifier seem quite surprising. Only 30% of the data was used for comparable performance results. QBC may be 11 a useful method for editing in nearest neighbor methods <ref> [4] </ref>. 6 Discussion & Future Work We have presented the on-site model and studied the design of a policy for querying during the performance stage. Query-By-Committee was tested as a possible method for approximating the model space in an on-site system and demonstrated encouraging results.
Reference: [5] <author> Y. Freund, H.S. Seung, E Shamir, and N. Tishby. </author> <title> Information, prediction, and query by committee. </title> <editor> In Hanson, Cowan, and Giles, editors, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 5. </volume> <publisher> Morgan Kaufman, </publisher> <year> 1993. </year>
Reference-contexts: It has been proposed for better generalization [6, 11] and has been shown to converge to the Bayes estimate in perceptron learning [10]. Our use of ensembles of learners is a modification of the Query-By-Committee (QBC) algorithm, proposed by Seung et al. <ref> [13, 5] </ref> for ap proximating the version space in a query filtering problem. The algorithm 5 areas are labeled +, white areas are labeled . Samples for training and testing were drawn uniformly from the domain. maintains a 2k-committee of concepts drawn at random from the version space.
Reference: [6] <author> L. K. Hansen and P. Salamon. </author> <title> Neural network ensembles. </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> 12(10) </volume> <pages> 993-10001, </pages> <year> 1990. </year>
Reference-contexts: The key problem is maintaining the model space. We propose using an ensemble of learners to maintain an estimate of the model space. The use of ensembles is not a new idea. It has been proposed for better generalization <ref> [6, 11] </ref> and has been shown to converge to the Bayes estimate in perceptron learning [10]. Our use of ensembles of learners is a modification of the Query-By-Committee (QBC) algorithm, proposed by Seung et al. [13, 5] for ap proximating the version space in a query filtering problem. <p> The second policy rejects patterns on which the two members disagree. The rejected patterns are considered as queries. Results of off-site training of a single network are not presented but they were found to be similar yet slightly worse than cases 1,2. <ref> [6, 9] </ref> The QBC network classified the patterns that the committee agreed upon and queried when there was disagreement. Each time an additional 20 new patterns had been queried, the committee was retrained on the complete set of queried patterns.
Reference: [7] <author> Y. Le Cun, O. Matan, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, L. D. Jackel, and H. S. Baird. </author> <title> Handwritten zip code recognition with multilayer networks. </title> <booktitle> In Proceedings of the 10th International conference on Pattern Recognition. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1990. </year>
Reference-contexts: We conjecture that the severity of this problem may decrease if the committee size increases or we use K-nearest neighbors. 5.3 An OCR problem We have experimented with QBC on a handwritten digit database described in <ref> [7] </ref>. We compared the performance of a two-member committee and a single learner trained on the same data. The results are summarized in Table 1. We did not study the utility of the different methods since the data set is not large enough to exhibit long term effects.
Reference: [8] <author> N. Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: A new linear threshold algorithm. </title> <booktitle> ML, </booktitle> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: The on-site model may be seen as a combination of models studied in previous work. On one hand, query filtering focuses on minimizing the number of queries needed to reach a given error rate. On the other hand, the goal of on-line learning <ref> [8] </ref> is to minimize the errors made over time. On-site learning tries to minimize a combination of queries and errors with respect to a cost model. We have studied the model under the assumption that the target concept is static.
Reference: [9] <author> O. Matan, R. K. Kiang, C. E. Stenard, B. Boser, J. S. Denker, D. Hen-derson, R. E. Howard, W. Hubbard, L. D. Jackel, and Y. Le Cun. </author> <title> Handwritten character recognition using neural network architectures. </title> <booktitle> In Proceedings of the 4th United States Postal Service Advanced Technology Conference, volume 2, </booktitle> <address> Washington D.C., </address> <year> 1990. </year>
Reference-contexts: The second policy rejects patterns on which the two members disagree. The rejected patterns are considered as queries. Results of off-site training of a single network are not presented but they were found to be similar yet slightly worse than cases 1,2. <ref> [6, 9] </ref> The QBC network classified the patterns that the committee agreed upon and queried when there was disagreement. Each time an additional 20 new patterns had been queried, the committee was retrained on the complete set of queried patterns.
Reference: [10] <author> M. Opper and D. Haussler. </author> <title> Generalization performance of bayes optimal classification algorithm for learning a perceptron. </title> <journal> Physical Review Letters, </journal> <volume> 66(20) </volume> <pages> 2677-2680, </pages> <year> 1991. </year> <month> 13 </month>
Reference-contexts: We propose using an ensemble of learners to maintain an estimate of the model space. The use of ensembles is not a new idea. It has been proposed for better generalization [6, 11] and has been shown to converge to the Bayes estimate in perceptron learning <ref> [10] </ref>. Our use of ensembles of learners is a modification of the Query-By-Committee (QBC) algorithm, proposed by Seung et al. [13, 5] for ap proximating the version space in a query filtering problem. The algorithm 5 areas are labeled +, white areas are labeled .
Reference: [11] <author> M. P. Perrone and L. N. Cooper. </author> <title> When networks disagree: Ensemble methods for hybrid neural networks. </title> <editor> In R. J. Mammone, editor, </editor> <booktitle> Neural Networks for speech and Image Processing. </booktitle> <address> Chapman-Hall, </address> <year> 1993. </year>
Reference-contexts: The key problem is maintaining the model space. We propose using an ensemble of learners to maintain an estimate of the model space. The use of ensembles is not a new idea. It has been proposed for better generalization <ref> [6, 11] </ref> and has been shown to converge to the Bayes estimate in perceptron learning [10]. Our use of ensembles of learners is a modification of the Query-By-Committee (QBC) algorithm, proposed by Seung et al. [13, 5] for ap proximating the version space in a query filtering problem.
Reference: [12] <author> Elaine Rich and Kevin Knight. </author> <booktitle> Artificial Intelligence. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1991. </year>
Reference-contexts: This limitation of QBC may occur for any learning algorithm that is not truly sampling the model space, but is conducting a beam search <ref> [12] </ref> in the space. Nearest neighbor classifiers seem more prone to encounter this problem due to the local nature of their representation.
Reference: [13] <author> H. S. Seung, M. Opper, and H. Sompolinsky. </author> <title> Query by committee. </title> <booktitle> In Proceedings of the annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 287-294, </pages> <year> 1992. </year>
Reference-contexts: The motivation for studying this model is that collecting and labelling data is costly. The information captured by a corpus as a function of its size flattens out quickly. For particular problems, one can show that the expected information gain of a pattern's label diminishes exponentially <ref> [13] </ref>. Work in query-based methods [3, 2, 13] has dealt with the issue of minimizing labeling cost, but it ignores the cost of waiting for the informative patterns. <p> The information captured by a corpus as a function of its size flattens out quickly. For particular problems, one can show that the expected information gain of a pattern's label diminishes exponentially [13]. Work in query-based methods <ref> [3, 2, 13] </ref> has dealt with the issue of minimizing labeling cost, but it ignores the cost of waiting for the informative patterns. <p> What is needed is a measure of the uncertainty in the hypothesis space. Theoretically, this is supplied by the version or model space. Practically, one needs to approximate these spaces. A method that has given some promising results is the Query-by-Committee algorithm <ref> [13] </ref>. In Section 5 we present preliminary results using this algorithm on a synthesized problem and a real-world OCR task using both a back-propagation network and a nearest neighbor classifier. <p> It has been proposed for better generalization [6, 11] and has been shown to converge to the Bayes estimate in perceptron learning [10]. Our use of ensembles of learners is a modification of the Query-By-Committee (QBC) algorithm, proposed by Seung et al. <ref> [13, 5] </ref> for ap proximating the version space in a query filtering problem. The algorithm 5 areas are labeled +, white areas are labeled . Samples for training and testing were drawn uniformly from the domain. maintains a 2k-committee of concepts drawn at random from the version space. <p> This leads to an exponential decay of the generalization error as a function of queries. The following experiments were conducted to explore the potential of QBC as an applicable algorithm. QBC was studied in <ref> [13] </ref> under two unrealistic conditions: 1. The target concept is realizable by the learners and uncorrupted by noise, i.e., there exists a version space. 2. The committee members are chosen at random from the version space at each step (Gibbs sampling).
Reference: [14] <author> Vladimir Vapnik, Esther Levin, and Yann Le Cun. </author> <title> Measuring the vc-dimension of a learning machine. </title> <journal> Neural Computation, </journal> <volume> 6 </volume> <pages> 851-876, </pages> <year> 1994. </year> <month> 14 </month>
Reference-contexts: Comm100 and Comm1000 exhibit fixed error and query rates. Qbc100's rates of errors and queries decrease till they reach a constant. That is, at a certain point in time, additional queries do not decrease the error rate. This is due to a lack of capacity <ref> [14] </ref> of the committee learners for fitting the target concept. Adding more training points, however informative, does not help. 5.2.2 Nearest neighbor classifiers QBC can easily be used with any incremental supervised learning algorithm that generates different concepts due to varying initial conditions.
References-found: 14

