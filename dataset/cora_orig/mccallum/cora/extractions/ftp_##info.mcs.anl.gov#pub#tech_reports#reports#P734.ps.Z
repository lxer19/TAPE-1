URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P734.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts98.htm
Root-URL: http://www.mcs.anl.gov
Email: E-mail: tufo@mcs.anl.gov, fischer@mcs.anl.gov  
Title: Fast Parallel Direct Solvers for Coarse Grid Problems  
Author: H. M. Tufo P. F. Fischer 
Keyword: plexity over competing methods while retaining minimal message startup cost.  
Address: Argonne, IL 60439, USA.  
Affiliation: Mathematics and Computer Science Division, Argonne National Laboratory,  
Abstract: We develop a fast direct solver for parallel solution of "coarse grid" problems, Ax = b, such as arise when domain decomposition or multigrid methods are applied to elliptic partial differential equations in d space dimensions. The approach is based on a (quasi-) sparse factorization of the inverse of A. If A is n fi n and the number of processors is P , our approach requires O(n fl log 2 P ) time for communication and O(n 1+fl =P ) time for computation, where fl j d1 d . Results from a 512-node Intel Paragon show that our algorithm compares favorably with more commonly used approaches that require O(n log 2 P ) time for communication and O(n 1+fl ) or O(n 2 =P ) time for computation. Moreover, for leading-edge multicomputer systems with thousands of processors and n = P (i.e., communication-dominated solves), we expect our algorithm to be markedly superior because it achieves substantially reduced message volume and arithmetic com 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. Alvarado, A. Pothen, and R. Schreiber, </author> <title> "Highly parallel sparse triangular solution", </title> <institution> Univ. Waterloo Research Rep. CS-92-51, Waterloo, </institution> <address> Ontario, </address> <year> 1992. </year> <month> 22 </month>
Reference-contexts: With the advent of computers containing thousands of processors, this restriction is problematic. Ideally, one would like a matrix-vector product-based approach involving sparse matrices. A step in this direction is the method of Alvarado et al. <ref> [1] </ref> who develop fast parallel triangular solvers by recasting the inverse of a sparse triangular matrix, L, as a product of l sparse factors, ~ L 1 i , each of which can be computed in place.
Reference: [2] <author> X.-C. Cai, </author> <title> "The use of pointwise interpolation in domain decomposition with non--nested meshes," </title> <note> SIAM J. Sci. Comput., 14 (1995) pp. 250-256. </note>
Reference-contexts: Gropp et al. [9, 11, 14] also discuss the importance and challenge of developing an efficient parallel coarse grid solver for domain decomposition methods. Cai <ref> [2] </ref> has developed a domain decomposition scheme requiring a very low dimensional coarse grid space where much of the information transfer is through the action of the restriction/prolongation operators.
Reference: [3] <author> T. Chan and J. P. Shao, </author> <title> "Parallel complexity of domain decomposition methods and optimal coarse grid size", </title> <booktitle> Parallel Computing, 21 (1995) pp. </booktitle> <pages> 1033-1049. </pages>
Reference-contexts: We target our algorithm for the "fine-grained" regime (i.e., n=P 1) and large numbers of processors, P . Such fine-grained solvers are required for the solution of the coarse grid systems encountered when using multigrid or domain decomposition methods to solve larger linear systems (e.g., <ref> [3, 4] </ref>). This work focuses on the coarse grid solution times rather than factor times, as we expect to amortize the factorization costs over several iterations and/or time-steps of the larger governing systems. <p> The problem of the coarse grid solve has been studied widely in the domain decomposition community. Widlund [16] established that order-independent convergence rates in domain decomposition methods cannot be obtained without the solution of a coarse grid problem. In <ref> [3] </ref>, Chan and Shao present a study of the optimal coarse grid size for parallel applications that illustrates the importance of a fast coarse grid solver. Gropp et al. [9, 11, 14] also discuss the importance and challenge of developing an efficient parallel coarse grid solver for domain decomposition methods.
Reference: [4] <author> M. Dryja and O. Widlund, </author> <title> "Towards a unified theory of domain decomposition algorithms for elliptic problems", in Proceedings of the Third International Symposium on Domain Decomposition Methods for Partial Differential Equations, </title> <editor> R. Glowinski, J. Periaux, and O. Widlund, eds., </editor> <publisher> SIAM, </publisher> <address> Philadelphia, p. 3, </address> <year> 1990. </year>
Reference-contexts: We target our algorithm for the "fine-grained" regime (i.e., n=P 1) and large numbers of processors, P . Such fine-grained solvers are required for the solution of the coarse grid systems encountered when using multigrid or domain decomposition methods to solve larger linear systems (e.g., <ref> [3, 4] </ref>). This work focuses on the coarse grid solution times rather than factor times, as we expect to amortize the factorization costs over several iterations and/or time-steps of the larger governing systems.
Reference: [5] <author> C. Farhat and P. S. Chen, </author> <title> "Tailoring domain decomposition methods for efficient parallel coarse grid solution and for systems with many right hand sides," </title> <journal> Contemporary Math., </journal> <volume> 180 (1994) p. </volume> <pages> 401-406 </pages> . 
Reference-contexts: This estimate neglects both the work, which, with a lower bound of ( n log 2 n P ) [8], probably is negligible, and the amount of data communicated, which probably is not negligible. Another approach of interest is that of Farhat and Chen <ref> [5] </ref>, who solve the coarse grid problem by projecting onto sets of previously generated Krylov vectors that constitute an approximation space. <p> In time transient problems, the successive right-hand sides often share enough information such that very few CG iterations are required to solve the problem subsequent to the initial projection (6). In the examples reported in <ref> [5] </ref>, Farhat and Chen observe that superconvergence sets in for k &gt; 0:25n, at which point only one or two conjugate gradient iterations are required subsequent to the initial projection. <p> Moreover, this approach requires a minimum number of message cycles and thus achieves the lower bound latency time of 2fft a log 2 P . 4 Sparse Basis Projection Method The goal of the method of Farhat and Chen <ref> [5] </ref> is to choose a basis set X k such that x is a good approximation to x. We observe that if k = n, then R (X k ) = lR n and, from (6), x j x.
Reference: [6] <author> P. F. Fischer, </author> <title> "Parallel domain decomposition for incompressible fluid dynamics", </title> <booktitle> Contemporary Mathematics, 157 (1994) pp. </booktitle> <pages> 313-322. </pages>
Reference-contexts: For large numbers of processors and relatively small systems (e.g., P &gt; 128, n &lt; 5000), computing the full inverse of A can be far more effective than solving the system redundantly (e.g., <ref> [6, 10] </ref>). By distributing the rows of A 1 in the same manner as x and b , the solution can be computed as a parallel matrix-vector product, A 1 b , once b has been gathered onto each processor.
Reference: [7] <author> P. F. Fischer, </author> <title> "Parallel multi-level solvers for spectral element methods", </title> <booktitle> in Proceedings of Intl. Conf. on Spectral and High-Order Methods '95, </booktitle> <address> Houston, Houston J. </address> <publisher> Math., </publisher> <editor> R. Scott, ed., </editor> <booktitle> (1996) pp. </booktitle> <pages> 595-604. </pages>
Reference-contexts: We observe that if k = n, then R (X k ) = lR n and, from (6), x j x. This implies that X n X T n is the inverse of A. In <ref> [7] </ref>, we introduced a method in which the projection approach is modified to incorporate a matrix of n basis vectors, X j X n , which is as sparse as possible and which yields significantly reduced computational and communication complexities.
Reference: [8] <author> J. A. George, </author> <title> "Nested dissection of a regular finite element mesh", </title> <note> SIAM J. Numer. Anal., 15 (1978) pp. 1053-1069. </note>
Reference-contexts: If A is the discrete Laplacian for a problem on a two-dimensional grid, the number of factors is typically l 6 log 2 n log 2 P (see, e.g., <ref> [8] </ref>). Since solution of (??) requires both a forward and backward sweep, we estimate a lower bound on the solution time of 2ff (log 2 P ) 2 t a . This estimate neglects both the work, which, with a lower bound of ( n log 2 n P ) [8], <p> <ref> [8] </ref>). Since solution of (??) requires both a forward and backward sweep, we estimate a lower bound on the solution time of 2ff (log 2 P ) 2 t a . This estimate neglects both the work, which, with a lower bound of ( n log 2 n P ) [8], probably is negligible, and the amount of data communicated, which probably is not negligible. Another approach of interest is that of Farhat and Chen [5], who solve the coarse grid problem by projecting onto sets of previously generated Krylov vectors that constitute an approximation space. <p> As k increases beyond k 1 , X k will begin to fill in. The goal is to find an ordering, V , which yields minimal or near minimal fill for the factor X. Following <ref> [8] </ref>, an efficient procedure for selecting the permutation matrix, V , can be developed by defining separators that recursively divide the domain (or graph) associated with A into nearly equal subdomains. For a p p n grid the first such separator is shown in Fig. 1b.
Reference: [9] <author> W. D. Gropp, </author> <title> "Parallel computing and domain decomposition", in Fifth Conference on Domain Decomposition Methods for Partial Differential Equations, </title> <editor> T. F. Chan, D. E. Keyes, G. A. Meurant, J. S. Scroggs, and R. G. Voigt, eds., </editor> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1992. </year>
Reference-contexts: In [3], Chan and Shao present a study of the optimal coarse grid size for parallel applications that illustrates the importance of a fast coarse grid solver. Gropp et al. <ref> [9, 11, 14] </ref> also discuss the importance and challenge of developing an efficient parallel coarse grid solver for domain decomposition methods. <p> We remark that the daxpy-based approach in which the communication is performed after the computation can be implemented with identical complexity if one chooses to store C in a column-contiguous format. 5 3 Survey of Coarse Grid Solvers It is well known (e.g., <ref> [9] </ref>) that parallel solution of the coarse grid problem is hampered by the inherent sequentiality of the forward and backward substitution phases of standard triangular (LU or LL T ) solves.
Reference: [10] <author> W. D. Gropp and D. E. Keyes, </author> <title> "Domain decomposition with local mesh refinement", </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <note> 15 4 (July 1992) pp. 967-993. </note>
Reference-contexts: For large numbers of processors and relatively small systems (e.g., P &gt; 128, n &lt; 5000), computing the full inverse of A can be far more effective than solving the system redundantly (e.g., <ref> [6, 10] </ref>). By distributing the rows of A 1 in the same manner as x and b , the solution can be computed as a parallel matrix-vector product, A 1 b , once b has been gathered onto each processor.
Reference: [11] <author> D. E. Keyes, Y. Saad, and D. G. Truhlar, </author> <title> Domain-Based Parallelism and Problem Decomposition Methods in Computational Science and Engineering, </title> <publisher> SIAM, </publisher> <year> 1995. </year>
Reference-contexts: In [3], Chan and Shao present a study of the optimal coarse grid size for parallel applications that illustrates the importance of a fast coarse grid solver. Gropp et al. <ref> [9, 11, 14] </ref> also discuss the importance and challenge of developing an efficient parallel coarse grid solver for domain decomposition methods.
Reference: [12] <author> J. L. Gustafson, G. R. Montry, and R. E. Benner, </author> <title> "Development of parallel methods for a 1024-processor hypercube", </title> <journal> SIAM J. on Sci. and Stat. Comput., </journal> <note> 9 4 (1988) p. 609. </note>
Reference-contexts: Since leading-edge multicomputer systems are currently scaling to thousands of processors, there is a clear need for an efficient treatment of the parallel coarse grid problem. In particular, if the work per processor remains constant while the number of processors increases (the standard model for scaled speedup <ref> [12] </ref>), the coarse grid problem will ultimately dominate the complexity unless the solve time can be substantially reduced.
Reference: [13] <author> A. Pothen, H. D. Simon, and K. P. Liou, </author> <title> "Partitioning sparse matrices with eigenvectors of graphs", </title> <note> SIAM J. Matrix Anal. Appl., 11 3 (1990) pp. 430-452. </note>
Reference-contexts: For more complex two- or three-dimensional meshes, separator sets can be found with standard graph-splitting techniques (e.g., recursive coordinate bisection) or via one of the many variants of recursive spectral bisection (e.g., <ref> [13] </ref>). In general, one can expect somewhat smaller complexity constants than for the examples considered here, as p generally the worst-case separator bound for planar graphs.
Reference: [14] <author> B. Smith, P. Bjorstad, and W. Gropp, </author> <title> Domain Decomposition, </title> <publisher> Cambridge University Press, </publisher> <year> 1996. </year>
Reference-contexts: In [3], Chan and Shao present a study of the optimal coarse grid size for parallel applications that illustrates the importance of a fast coarse grid solver. Gropp et al. <ref> [9, 11, 14] </ref> also discuss the importance and challenge of developing an efficient parallel coarse grid solver for domain decomposition methods.
Reference: [15] <author> R. van de Geijn, </author> <title> "On global combine operations," </title> <journal> J. Parallel & Distributed Comput., </journal> <note> 22 (1994) pp. 324-328. </note>
Reference-contexts: For example, for concatenation, recursive doubling can be used until ^m ff=fi and fan-in/fan-out then used on processor subsets to span the remaining levels of the tree (s). For vector summation there is a well-known hybrid scheme due to van de Geijn et al. <ref> [15] </ref> that is effective when m AE ff=fi.
Reference: [16] <author> O. B. Widlund, </author> <title> "Iterative substructuring methods: Algorithms and theory for elliptic problems in the plane", in Proceedings of the First International Symposium on Domain Decomposition Methods for Partial Differential Equations, </title> <editor> R. Glowinski, G. H. Golub, G. A. Meurant, and J. Periaux, eds., </editor> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1988. </year> <month> 24 </month>
Reference-contexts: The problem of the coarse grid solve has been studied widely in the domain decomposition community. Widlund <ref> [16] </ref> established that order-independent convergence rates in domain decomposition methods cannot be obtained without the solution of a coarse grid problem. In [3], Chan and Shao present a study of the optimal coarse grid size for parallel applications that illustrates the importance of a fast coarse grid solver.
References-found: 16

