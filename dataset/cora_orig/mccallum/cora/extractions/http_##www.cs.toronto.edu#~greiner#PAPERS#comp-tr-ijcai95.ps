URL: http://www.cs.toronto.edu/~greiner/PAPERS/comp-tr-ijcai95.ps
Refering-URL: http://www.cs.toronto.edu/~greiner/PAPERS/
Root-URL: 
Email: greiner@scr.siemens.com  
Title: The Complexity of Theory Revision  
Author: Russell Greiner 
Date: August 1995.  
Note: To appear in the Proceedings of the Fourteenth International Conference on Artificial Intelligence (IJCAI-95), Montreal,  
Address: Princeton, NJ 08540-6632  
Affiliation: Siemens Corporate Research  
Abstract: A knowledge-based system uses its database (a.k.a. its "theory") to produce answers to the queries it receives. Unfortunately, these answers may be incorrect if the underlying theory is faulty. Standard "theory revision" systems use a given set of "labeled queries" (each a query paired with its correct answer) to transform the given theory, by adding and/or deleting either rules and/or antecedents, into a related theory that is as accurate as possible. After formally defining the theory revision task and bounding its sample complexity, this paper addresses the task's computational complexity. It first proves that, unless P = N P , no polynomial time algorithm can identify the optimal theory, even given the exact distribution of queries, except in the most trivial of situations. It also shows that, except in such trivial situations, no polynomial-time algorithm can produce a theory whose inaccuracy is even close (i.e., within a particular polynomial factor) to optimal. These results justify the standard practice of hill-climbing to a locally-optimal theory, based on a given set of labeled sam ples.
Abstract-found: 1
Intro-found: 1
Reference: [ AGM85 ] <author> Carlos E. Alchourron, Peter Gardenfors, and David Makinson. </author> <title> On the logic of theory change: Partial meet contraction and revision functions. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 50 </volume> <pages> 510-30, </pages> <year> 1985. </year>
Reference-contexts: Finally, note that, in some cases, our task can require extracting the best consistent sub-theory from a given inconsistent theory. From this perspective, our work is related to "Knowledge Representation" form of theory revision, a la Gardenfors <ref> [ Gar88; AGM85 ] </ref> , Katsuno and Mendelzon [ KM91 ] and many others.
Reference: [ BCH90 ] <author> E. Boros, Y. Crama, and P.L. Hammer. </author> <title> Polynomial-time inference of all valid implications for horn and related formulae. </title> <journal> Annals of Mathematics and Artificial Intelligence, </journal> <volume> 1 </volume> <pages> 21-32, </pages> <year> 1990. </year>
Reference-contexts: Our results show that the task of finding the optimal theory is intractable even given a poly-time oracle for these arbitrary derivations. Of course, as we are considering only Horn theories, these computations are guaranteed to be poly-time in the propositional case <ref> [ BCH90 ] </ref> . c (t AR ) = jj for each add-rule (resp., delete-rule) transformation that adds (resp., deletes) the rule , which has 1 conclusion and jj 1 antecedent literals.
Reference: [ BI88 ] <author> G. Benedek and A. Itai. </author> <title> Nonuniform learnability. </title> <booktitle> In Proceedings ICALP-88, </booktitle> <pages> pages 82-92, </pages> <year> 1988. </year>
Reference-contexts: But even here, the sample complexity remains polynomial in the size of the revised theory, which effectively means again that sample-efficient learning remains possible; cf., "nonuniform" pac-learning <ref> [ BI88 ] </ref> 2.3 Dealing with Predicate Calculus To handle predicate calculus expressions, we have to consider answers of the form fYes [ fX i =v i g ]g, where the expression within each Yes [] is a binding list of the free variables, corresponding to a single answer to the
Reference: [ BM93 ] <author> Paul T. Baffes and Raymond J. Mooney. </author> <title> Symbolic revision of theories with M-of-N rules. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: Our analysis, and results, can easily be applied to many other types of modifications | e.g., specializing or generalizing antecedents [ OM94 ] , using "n-of-m rules" <ref> [ BM93 ] </ref> , or merging rules and removing chains paths of rules that produced incorrect results [ Coh90; Coh92 ] . 3 While these projects provide empirical evidence of the effectiveness of their specific algorithms, and deal with classification (i.e., determining whether a given element is a member of some
Reference: [ Cla78 ] <author> K. Clark. </author> <title> Negation as failure. </title> <editor> In H. Gallaire and J. Minker, editors, </editor> <booktitle> Logic and Data Bases, </booktitle> <pages> pages 293-322. </pages> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: [] ); MaxPerf [MaxTR []]( B; x ) 2 The companion paper [ Gre95a ] considers other related cases, including the above special cases in the context where our underlying theories can use the not () operator to return Yes if the specified goal cannot be proven; i.e., using Negation-as-Failure <ref> [ Cla78 ] </ref> . It also considers the effect of re-ordering the rules and the antecedents, in the context where such shu*ings can affect the answers returned.
Reference: [ Coh90 ] <author> William W. Cohen. </author> <title> Learning from textbook knowledge: A case study. </title> <booktitle> In Proceeding of AAAI-90, </booktitle> <year> 1990. </year>
Reference-contexts: Most theory revision algorithms use a set of transformations to hill-climb through successive theories, until reaching a theory whose accuracy is (locally) optimal, based on a set of correctly-answered queries; cf., <ref> [ Pol85; MB88; Coh90; OM94; WP93; CS90; LDRG94 ] </ref> . <p> Our analysis, and results, can easily be applied to many other types of modifications | e.g., specializing or generalizing antecedents [ OM94 ] , using "n-of-m rules" [ BM93 ] , or merging rules and removing chains paths of rules that produced incorrect results <ref> [ Coh90; Coh92 ] </ref> . 3 While these projects provide empirical evidence of the effectiveness of their specific algorithms, and deal with classification (i.e., determining whether a given element is a member of some target class) rather than general derivation, our work formally addresses the complexities inherent in finding the best
Reference: [ Coh92 ] <author> William W. Cohen. </author> <title> Abductive explanation-based learning: A solution to the multiple inconsistent explanation problems. </title> <journal> Machine Learning, </journal> <volume> 8(2) </volume> <pages> 167-219, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Our analysis, and results, can easily be applied to many other types of modifications | e.g., specializing or generalizing antecedents [ OM94 ] , using "n-of-m rules" [ BM93 ] , or merging rules and removing chains paths of rules that produced incorrect results <ref> [ Coh90; Coh92 ] </ref> . 3 While these projects provide empirical evidence of the effectiveness of their specific algorithms, and deal with classification (i.e., determining whether a given element is a member of some target class) rather than general derivation, our work formally addresses the complexities inherent in finding the best
Reference: [ CP91 ] <author> P. Crescenzi and A. Panconesi. </author> <title> Completeness in approximation classes. </title> <journal> Information and Computation, </journal> <volume> 93(2) </volume> <pages> 241-62, </pages> <year> 1991. </year>
Reference-contexts: Or if this bound was some constant c (x) = c 2 &lt;, then we could efficiently obtain a solution within a factor of c of optimal, which may be good enough for some applications. 9 However, not all problems can be so approximated. Following <ref> [ CP91; Kan92 ] </ref> , we define Definition 2 A minimization problem MinP is Not-PolyApprox if there is a fl 2 &lt; + such that 8B 2 Poly ( MinP ); 9x 2 MinP; MinPerf [MinP]( B; x ) jxj fl : Lund and Yannakakis [ LY93 ] prove that the
Reference: [ CS90 ] <author> Susan Craw and Derek Sleeman. </author> <title> Automating the refinement of knowledge-based systems. In L.C. </title> <editor> Aiello, editor, </editor> <booktitle> Proceedings of ECAI 90. </booktitle> <publisher> Pitman, </publisher> <year> 1990. </year>
Reference-contexts: Most theory revision algorithms use a set of transformations to hill-climb through successive theories, until reaching a theory whose accuracy is (locally) optimal, based on a set of correctly-answered queries; cf., <ref> [ Pol85; MB88; Coh90; OM94; WP93; CS90; LDRG94 ] </ref> .
Reference: [ DP91 ] <author> Jon Doyle and Ramesh Patil. </author> <title> Two theses of knowledge representation: Language restrictions, taxonomic classification, and the utility of representation services. </title> <journal> Artificial Intelligence, </journal> <volume> 48(3), </volume> <year> 1991. </year>
Reference-contexts: Borrowing from <ref> [ Lev84; DP91 ] </ref> , we also view a theory T as a function that maps each query to its proposed answer; hence, T: Q 7! A, where Q is a (possibly infinite) set of Horn queries, and A = f No; Yes g is the set of possible 2 The
Reference: [ FP93 ] <author> Michael Frazier and Leonard Pitt. </author> <title> Learning from entailment: An application to propositional horn sentences. </title> <booktitle> In Proceedings of IML-93, </booktitle> <pages> pages 120-27. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: this entailment condition holds iff T j= :f 1 (p) _ : : : _ :f n (p) _ disease i (p); i.e., iff the Horn query "disease i (p) :- f 1 (p), : : : , f n (p)" follows from the initial theory. (See also "entailment queries" <ref> [ FP93 ] </ref> .) We assume there is a single correct answer to each question, and represent it using the real-world oracle O : Q 7! A. Here, perhaps, O ( h ) = No, meaning that "h" should not hold.
Reference: [ Gar88 ] <author> Peter Gardenfors. </author> <title> Knowledge in Flux: Modeling the Dynamics of the Epistemic States. </title> <publisher> Bradford Book, MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: Finally, note that, in some cases, our task can require extracting the best consistent sub-theory from a given inconsistent theory. From this perspective, our work is related to "Knowledge Representation" form of theory revision, a la Gardenfors <ref> [ Gar88; AGM85 ] </ref> , Katsuno and Mendelzon [ KM91 ] and many others.
Reference: [ GJ79 ] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: We also discuss the 1 Throughout, we will assume that P 6=N P <ref> [ GJ79 ] </ref> , which implies that any NP-hard problem is intractable. This also implies certain approximation claims, presented below. efficiency of other restricted variants of theory revision, providing sharp boundaries that describe exactly when this task is, versus is not, tractable. <p> decision problems correspond immediately to optimization problems; for example, the MinGraphColor decision problem (given a graph G = hN; Ei and a positive integer K, can each node be labeled by one of K colors in such a way that no edge connects two nodes of the same color; see <ref> [ GJ79, p191 (Chromatic Number) ] </ref> ) corresponds to the obvious minimization problem: Find the minimal coloring of the given graph G. <p> For example, there is a polynomial-time algorithm that computes a solution whose cost is within a factor of 1:5 for any TravelingSalesman-with-Triangle Equality problem; see <ref> [ GJ79, Theorem 6.5 ] </ref> . returns No too often), then we may want to consider "generalizing" it by applying only the "add rule" and "delete antecedent" transformations; here, we consider +R;A [T], +R [T] and A [T], which are the set of theories obtained by applying an arbitrary number of
Reference: [ Gre95a ] <author> Russell Greiner. </author> <title> The challenge of revising impure theories. </title> <booktitle> In Proceedings of the Twelfth International Machine Learning Conference, </booktitle> <year> 1995. </year>
Reference-contexts: T: Q 7! A, where Q is a (possibly infinite) set of Horn queries, and A = f No; Yes g is the set of possible 2 The technical report [ Gre95b ] provides a more extensive literature survey, as well as proofs of the theorems. 3 The companion paper <ref> [ Gre95a ] </ref> considers yet other ways of modifying a theory, viz., by rearranging its component rules or antecedents. answers. 4 Hence, given T 1 = h :- f, g. f :- c, d. q. c. d. e. ffi a b f g ffi ffi ffi ffi ffi ffi @ @ <p> optimal value, MaxPerf [MaxTR [ y ]]( B; x ) = A ( opt (x) ) Theorem 7 For 2 f R;+A ; R ; +A ; +R;A ; +R ; A g, 9B 2 Poly ( MaxTR [] ); MaxPerf [MaxTR []]( B; x ) 2 The companion paper <ref> [ Gre95a ] </ref> considers other related cases, including the above special cases in the context where our underlying theories can use the not () operator to return Yes if the specified goal cannot be proven; i.e., using Negation-as-Failure [ Cla78 ] .
Reference: [ Gre95b ] <author> Russell Greiner. </author> <title> The complexity of theory revision. </title> <type> Technical Report SCR-95-TR-539, </type> <institution> Siemens Corporate Research, </institution> <year> 1995. </year> <note> ftp://scr.siemens.com/pub/learning/Papers/ greiner/comp-tr.ps. </note>
Reference-contexts: ] , we also view a theory T as a function that maps each query to its proposed answer; hence, T: Q 7! A, where Q is a (possibly infinite) set of Horn queries, and A = f No; Yes g is the set of possible 2 The technical report <ref> [ Gre95b ] </ref> provides a more extensive literature survey, as well as proofs of the theorems. 3 The companion paper [ Gre95a ] considers yet other ways of modifying a theory, viz., by rearranging its component rules or antecedents. answers. 4 Hence, given T 1 = h :- f, g. f <p> It also considers the effect of re-ordering the rules and the antecedents, in the context where such shu*ings can affect the answers returned. In most of these cases, we show that the corresponding maximization problem is not approximatable within a particular polynomial. (The extended <ref> [ Gre95b ] </ref> explains the asymmetry be-tween TR P rop;Perf [ R ] versus TR P rop;Perf [ +R ], and discusses how these results relate to both inductive logic programming, and to default theories.) 4 Conclusion A knowledge-based system can produce incorrect answers to queries if its underlying theory is
Reference: [ Kan92 ] <author> Viggo Kann. </author> <title> On the Approximability of NP-Complete Optimization Problems. </title> <type> PhD thesis, </type> <institution> Royal Institute of Technology, Stockholm, </institution> <year> 1992. </year>
Reference-contexts: Or if this bound was some constant c (x) = c 2 &lt;, then we could efficiently obtain a solution within a factor of c of optimal, which may be good enough for some applications. 9 However, not all problems can be so approximated. Following <ref> [ CP91; Kan92 ] </ref> , we define Definition 2 A minimization problem MinP is Not-PolyApprox if there is a fl 2 &lt; + such that 8B 2 Poly ( MinP ); 9x 2 MinP; MinPerf [MinP]( B; x ) jxj fl : Lund and Yannakakis [ LY93 ] prove that the
Reference: [ KM91 ] <author> Hirofumi Katsuno and Alberto Mendelzon. </author> <title> On the difference between updating a knowledge base and revising it. </title> <booktitle> In Proceedings of KR-91, </booktitle> <pages> pages 387-94, </pages> <address> Boston, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Finally, note that, in some cases, our task can require extracting the best consistent sub-theory from a given inconsistent theory. From this perspective, our work is related to "Knowledge Representation" form of theory revision, a la Gardenfors [ Gar88; AGM85 ] , Katsuno and Mendelzon <ref> [ KM91 ] </ref> and many others.
Reference: [ LDRG94 ] <author> Pat Langley, George Drastal, R. Bharat Rao, and Russell Greiner. </author> <title> Theory revision in fault hierarchies. </title> <booktitle> In Proceedings of The Fifth International Workshop on Principles of Diagnosis (DX-94), </booktitle> <address> New Paltz, NY, </address> <year> 1994. </year>
Reference-contexts: Most theory revision algorithms use a set of transformations to hill-climb through successive theories, until reaching a theory whose accuracy is (locally) optimal, based on a set of correctly-answered queries; cf., <ref> [ Pol85; MB88; Coh90; OM94; WP93; CS90; LDRG94 ] </ref> . <p> There are several implemented theory revision systems. Most use essentially the same set of transformations we describe | e.g., Audrey [ WP93 ] , Fonte [ MB88 ] , Either [ OM94 ] and <ref> [ LDRG94 ] </ref> all consider adding or deleting antecedents or rules.
Reference: [ Lev84 ] <author> Hector J. Levesque. </author> <title> Foundations of a functional approach to knowledge representation. </title> <journal> Artificial Intelligence, </journal> <volume> 23 </volume> <pages> 155-212, </pages> <year> 1984. </year>
Reference-contexts: 1 Introduction There are many fielded knowledge-based systems, ranging from expert systems and logic programs to production systems and database management systems <ref> [ Lev84 ] </ref> . <p> Borrowing from <ref> [ Lev84; DP91 ] </ref> , we also view a theory T as a function that maps each query to its proposed answer; hence, T: Q 7! A, where Q is a (possibly infinite) set of Horn queries, and A = f No; Yes g is the set of possible 2 The
Reference: [ LY93 ] <author> Carsten Lund and Mihalis Yannakakis. </author> <title> On the hardness of approximating minimization problems. </title> <booktitle> In Proceeding of Twenty-fifth Annual ACM Symposium on Theory of Computation (STOC-93), </booktitle> <pages> pages 286-93, </pages> <year> 1993. </year>
Reference-contexts: Following [ CP91; Kan92 ] , we define Definition 2 A minimization problem MinP is Not-PolyApprox if there is a fl 2 &lt; + such that 8B 2 Poly ( MinP ); 9x 2 MinP; MinPerf [MinP]( B; x ) jxj fl : Lund and Yannakakis <ref> [ LY93 ] </ref> prove that the "Min-GraphColor minimization problem" is NotPolyAp-prox. We can use that result to prove: Theorem 4 Unless P = N P , each of MinTR P rop;Disj [ 1 ], MinTR (P redCal);(Horn) [ 1 ] and MinTR P rop;Atom [ K ] is NotPolyApprox.
Reference: [ MB88 ] <author> S. Muggleton and W. Buntine. </author> <title> Machine invention of first order predicates by inverting resolution. </title> <booktitle> In Proceedings of IML-88, </booktitle> <pages> pages 339-51. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: Most theory revision algorithms use a set of transformations to hill-climb through successive theories, until reaching a theory whose accuracy is (locally) optimal, based on a set of correctly-answered queries; cf., <ref> [ Pol85; MB88; Coh90; OM94; WP93; CS90; LDRG94 ] </ref> . <p> There are several implemented theory revision systems. Most use essentially the same set of transformations we describe | e.g., Audrey [ WP93 ] , Fonte <ref> [ MB88 ] </ref> , Either [ OM94 ] and [ LDRG94 ] all consider adding or deleting antecedents or rules.
Reference: [ OM94 ] <author> Dirk Ourston and Raymond J. Mooney. </author> <title> Theory refinement combining analytical and empirical methods. </title> <journal> Artificial Intelligence, </journal> <volume> 66(2) </volume> <pages> 273-310, </pages> <year> 1994. </year>
Reference-contexts: Most theory revision algorithms use a set of transformations to hill-climb through successive theories, until reaching a theory whose accuracy is (locally) optimal, based on a set of correctly-answered queries; cf., <ref> [ Pol85; MB88; Coh90; OM94; WP93; CS90; LDRG94 ] </ref> . <p> There are several implemented theory revision systems. Most use essentially the same set of transformations we describe | e.g., Audrey [ WP93 ] , Fonte [ MB88 ] , Either <ref> [ OM94 ] </ref> and [ LDRG94 ] all consider adding or deleting antecedents or rules. Our analysis, and results, can easily be applied to many other types of modifications | e.g., specializing or generalizing antecedents [ OM94 ] , using "n-of-m rules" [ BM93 ] , or merging rules and removing <p> we describe | e.g., Audrey [ WP93 ] , Fonte [ MB88 ] , Either <ref> [ OM94 ] </ref> and [ LDRG94 ] all consider adding or deleting antecedents or rules. Our analysis, and results, can easily be applied to many other types of modifications | e.g., specializing or generalizing antecedents [ OM94 ] , using "n-of-m rules" [ BM93 ] , or merging rules and removing chains paths of rules that produced incorrect results [ Coh90; Coh92 ] . 3 While these projects provide empirical evidence of the effectiveness of their specific algorithms, and deal with classification (i.e., determining whether a
Reference: [ Pol85 ] <author> P.G. Politakis. </author> <title> Empirical Analysis for Expert Systems. </title> <booktitle> Pitman Research Notes in Artificial Intelligence, </booktitle> <year> 1985. </year>
Reference-contexts: Most theory revision algorithms use a set of transformations to hill-climb through successive theories, until reaching a theory whose accuracy is (locally) optimal, based on a set of correctly-answered queries; cf., <ref> [ Pol85; MB88; Coh90; OM94; WP93; CS90; LDRG94 ] </ref> .
Reference: [ Vap82 ] <author> V.N. Vapnik. </author> <title> Estimation of Dependences Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: Complexity We can use following standard Computational Learning Theory theorem to bound the number of samples required to obtain the information needed to identify a good T fl 2 T with high probability; showing in particular how this depends on the space of theories T being considered: Theorem 1 (from <ref> [ Vap82, Theorem 6.2 ] </ref> ) Given a class of theories T and *; ffi &gt; 0, let T fl 2 T be the theory with the largest empirical accuracy after M upper (T ; *; ffi) = l * 2 ln jT j m samples (each a labeled query), drawn
Reference: [ WP93 ] <author> James Wogulis and Michael J. Pazzani. </author> <title> A methodology for evaluating theory revision systems: Results with Audrey II. </title> <booktitle> In Proceedings of IJCAI-93, </booktitle> <pages> pages 1128-1134, </pages> <year> 1993. </year>
Reference-contexts: Most theory revision algorithms use a set of transformations to hill-climb through successive theories, until reaching a theory whose accuracy is (locally) optimal, based on a set of correctly-answered queries; cf., <ref> [ Pol85; MB88; Coh90; OM94; WP93; CS90; LDRG94 ] </ref> . <p> There are several implemented theory revision systems. Most use essentially the same set of transformations we describe | e.g., Audrey <ref> [ WP93 ] </ref> , Fonte [ MB88 ] , Either [ OM94 ] and [ LDRG94 ] all consider adding or deleting antecedents or rules.
References-found: 25

