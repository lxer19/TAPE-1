URL: http://www.cs.washington.edu/research/projects/lis/oetools/www/papers/burns-phd.ps
Refering-URL: http://www.cs.washington.edu/homes/burns/professional/pubs.html
Root-URL: http://www.cs.washington.edu
Title: Performance Analysis and Optimization of Asynchronous Circuits  
Author: Steven Morgan Burns 
Degree: Thesis by  In Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy  
Date: 1991 (Defended December 5, 1990)  
Address: Pasadena, California USA  
Affiliation: California Institute of Technology  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1974. </year>
Reference: [2] <author> Richard E. Bellman, Kenneth L. Cooke, and Jo Ann Lockett. </author> <title> Algorithms, Graphs, and Computers. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1970. </year>
Reference: [3] <author> Steven M. Burns. </author> <title> Automated compilation of concurrent programs into self-timed circuits. M.S. </title> <type> thesis, </type> <institution> California Institute of Technology, </institution> <year> 1988. </year> <month> CS-TR-88-2. </month>
Reference-contexts: However, only a few of the best alternatives need be considered at the next synthesis level, thus significantly reducing the vast search space of the synthesis problem. Instead of exploiting performance information to prune the search space, existing solutions to the synthesis problem <ref> [3, 4] </ref> seek to use the same sub-circuit template to implement each language construct. We do not use the term optimization to refer to this searching activity, but instead reserve that term for the final adjustment of low-level parameters, in particular, the sizing of transistors.
Reference: [4] <author> Steven M. Burns and Alain J. Martin. </author> <title> Syntax-directed translation of concurrent programs into self-timed circuits. </title> <editor> In J. Allen and F. Leighton, editors, </editor> <booktitle> Advanced Research in VLSI, Proceedings of the Fifth MIT Conference, </booktitle> <pages> pages 35-50. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: However, only a few of the best alternatives need be considered at the next synthesis level, thus significantly reducing the vast search space of the synthesis problem. Instead of exploiting performance information to prune the search space, existing solutions to the synthesis problem <ref> [3, 4] </ref> seek to use the same sub-circuit template to implement each language construct. We do not use the term optimization to refer to this searching activity, but instead reserve that term for the final adjustment of low-level parameters, in particular, the sizing of transistors. <p> The decomposition can be written as S 0 ; S; S 1 B (S 0 ; C; C; S 1 k fl [D; S; D]) channel (C; D) : The symbol B should be read as "compiles into" [5]. (In previous work <ref> [4, 5] </ref>, process decomposition has been performed by replacing S with a single communication and surrounding S in the new process by a single probed communication. The techniques are identical if C is active and D is passive.
Reference: [5] <author> Steven M. Burns and Alain J. Martin. </author> <title> Synthesis of self-timed circuits by program transformation. In G.J. Milne, editor, The Fusion of Hardward Design and Verification. </title> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: The decomposition can be written as S 0 ; S; S 1 B (S 0 ; C; C; S 1 k fl [D; S; D]) channel (C; D) : The symbol B should be read as "compiles into" <ref> [5] </ref>. (In previous work [4, 5], process decomposition has been performed by replacing S with a single communication and surrounding S in the new process by a single probed communication. The techniques are identical if C is active and D is passive. <p> The decomposition can be written as S 0 ; S; S 1 B (S 0 ; C; C; S 1 k fl [D; S; D]) channel (C; D) : The symbol B should be read as "compiles into" [5]. (In previous work <ref> [4, 5] </ref>, process decomposition has been performed by replacing S with a single communication and surrounding S in the new process by a single probed communication. The techniques are identical if C is active and D is passive.
Reference: [6] <author> R. A. Cuningham-Green. </author> <title> Describing industrial processes with interference and approximating their steady-state behaviour. </title> <journal> Operational Research Quarterly, </journal> <volume> 13(1) </volume> <pages> 95-100, </pages> <year> 1962. </year>
Reference: [7] <author> David L. Dill. </author> <title> Trace Theory for Automatic Hierarchical Verification of Speed-Independent Circuits. </title> <type> Ph.D. thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1988. </year> <month> CMU-CS-88-119. </month>
Reference-contexts: Such a circuit functions correctly regardless of delays within its elements, except for some necessary assumptions about the relative delays along a few local wires. This view of delays, except for a trivial difference in the way wires with delays are named, is equivalent to the speed-independent delay model <ref> [28, 7] </ref>, originally introduced by David Muller in the 1950s. There are many advantages of asynchronous circuits over synchronous circuits. These advantages include design modularity, interchangeability of subcomponents, tolerance to variation in power-supply voltages, tolerance to variation in temperatures, lower power consumption, and higher performance.
Reference: [8] <author> Jo C. Ebergen. </author> <title> Translating Programs into Delay-Insensitive Circuits. </title> <type> Ph.D. thesis, </type> <institution> Technische Universiteit Eindhoven, </institution> <year> 1987. </year> <month> 152 </month>
Reference-contexts: These advantages include design modularity, interchangeability of subcomponents, tolerance to variation in power-supply voltages, tolerance to variation in temperatures, lower power consumption, and higher performance. The reader is referred to the literature for a more complete list of these advantages (especially <ref> [36, 8, 38, 25] </ref>). Here we will concentrate on the possible higher performance of an implementation of a computation as 2 an asynchronous circuit rather than as a synchronous circuit. It is not al-ways the case that an asynchronous circuit will outperform its synchronous counterpart.
Reference: [9] <author> W.C. </author> <title> Elmore. The transient response of damped linear networks with partic-ular regard to wideband amplifiers. </title> <journal> Journal of Applied Physics, </journal> <volume> 19(1) </volume> <pages> 55-63, </pages> <month> January </month> <year> 1948. </year>
Reference: [10] <author> Shimon Even. </author> <title> Graph Algorithms. </title> <publisher> Computer Science Press, </publisher> <address> Rockville, MD, </address> <year> 1979. </year>
Reference: [11] <author> J.P. Fishburn and A.E. Dunlop. TILOS: </author> <title> A posynomial programming approach to transistor sizing. </title> <booktitle> In IEEE ICCAD, </booktitle> <pages> pages 326-328, </pages> <month> November </month> <year> 1985. </year>
Reference-contexts: This dependence is normally small and is ignored in the optimization problem. Timing models similar to the tau model are used in other transistor optimization tools (designed for synchronous circuits), such as TILOS <ref> [11] </ref>, COP [21], and EPOXY [29]. Example 7.1 As an example, we will construct the optimization equations for the C-element circuit.
Reference: [12] <author> L.R. Ford, Jr. and D.R. Fulkerson. </author> <title> Flows in Networks. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1962. </year>
Reference: [13] <author> Joel Franklin. </author> <title> Methods of Mathematical Economics. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1980. </year>
Reference-contexts: The techniques of linear programming <ref> [13, 30] </ref> can be used to find such a minimum-period linear timing function (MPLTF). <p> The dual has no feasible solution, but the primal has feasible solutions x with c T x = 1. 4. Neither the primal nor the dual has a feasible solution. Proof: See <ref> [13] </ref>. The constraints of a linear timing function (2:9) are simple linear inequalities in the offsets x v and cycle period p. <p> As a consequence, x can be unrestricted in the primal equation (5:3). 5.2 Minimum-Period/Minimum-Latency Lin ear Timing Functions Our goal now is to find simultaneous optimal solutions for the objective functions min p and min `. Optimization problems of this type are called multi-objective linear programming problems <ref> [13] </ref>. A simultaneous optimal solution exists if there exists a feasible x; p; ` that is optimal for every objective function c 0 p + c 1 ` with non-negative c 0 and c 1 . <p> 1 . 0.5 1 1.5 2 2.5 3 4 8 12 with respect to w 2 . 0.5 1 1.5 2 2.5 3 4 8 12 with respect to w 3 . 0.5 1 1.5 2 2.5 3 4 8 12 with respect to w 4 . 141 log w's <ref> [13] </ref>. Because both the sum and the maximum of two convex functions are convex functions, the resulting expression for p is a convex function of the log w's; and, thus, each minimum of p is global.
Reference: [14] <author> M. Greenstreet, T. Williams, and J. Staunstrup. </author> <title> Self-timed iteration. </title> <booktitle> In VLSI 1987, </booktitle> <pages> pages 1-20, </pages> <year> 1987. </year> <note> Draft. </note>
Reference-contexts: Mod has a smaller cycle period than lap if ffi c &lt; min (ffi o ; ffi r ), which is typically the case. 6.3.2 Greenstreet, Williams, and Staunstrup Greenstreet, Williams, and Staunstrup <ref> [14] </ref> use the implementation of a pipeline stage as shown in Figure 6.39 for their work with self-timed iterations. A number n of these pipeline stages (at least three and with at least one process initialized differently) are connected together to form a ring. <p> The three cycles 125 ffi C" ; ffi C# lo ri Greenstreet, Williams, and Staunstrup <ref> [14] </ref>. 126 li " lo " ri " ro # co " ci " +` ffi C# ` pipeline stage. 127 ffi C" ; ffi C# lo ri li ro ffi C" ; ffi C# lo ri true true go ring. in the graph produce the constraints ` = ffi C" <p> What is important is the cycle period of three stages connected together to form a ring (Figure 6.41). The surprising result is that with this implementation, all six of the datapath delays occur in series. Even with the (non-speed-independent) optimization performed in <ref> [14, 39] </ref>, all datapath delays occur in series.
Reference: [15] <author> John L. Hennessy and David A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufman Publishers, Inc., </publisher> <year> 1990. </year>
Reference-contexts: This modification had the effect of adding another pipeline stage to the processor and slightly complicating the mechanism needed to ensure the absence of data hazards <ref> [15] </ref>. The modification split in two the data path activities modeled by the single delay named za.
Reference: [16] <author> C.A.R. Hoare. </author> <title> Communicating Sequential Processes. </title> <journal> Communications of the ACM, </journal> <volume> 21(8) </volume> <pages> 666-677, </pages> <year> 1978. </year>
Reference-contexts: The highest-level representations are in the form of Communication Sequential Processes (CSP) programs based on Hoare's original programming notation <ref> [16] </ref>. These representations are transformed into handshaking expansions, a refined form of CSP programs where all communication actions are replaced by explicit manipulations of boolean variables. Handshaking expansions are further transformed into sets of production rules where all explicit sequencing has been removed.
Reference: [17] <author> Eugene L. Lawler. </author> <title> Combinatorial Optimization: Networks and Matroids. </title> <publisher> Holt, Rinehart and Winston, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: This advantage is described in detail in Chapter 5. Algorithm 2.2 provides a solution to a more general problem, the minimum ratio cycle problem. Lawler <ref> [17] </ref> describes this problem and a provides a solution based on testing whether or not a given cycle period is feasible, and then bisecting an interval containing an infeasible and a feasible cycle period.
Reference: [18] <author> Tony Lee. </author> <title> Communication behavior of linear arrays of processes. M.S. </title> <type> thesis, </type> <institution> California Institute of Technology, </institution> <year> 1989. </year> <month> CS-TR-89-13. </month>
Reference-contexts: Instead, a linear timing function exists for a regular system if the generated repetitive systems with an arbitrary number of processes have a property known as constant response time <ref> [18, 35] </ref>. <p> However, such interleavings must retain the constant response time (CRT) property of the array of processes, and must also not violate any of the assumptions| about when data variables change|that were made during synthesis of the data part. 6.1.1 CRT Constraint From the work of Lee <ref> [18] </ref>, a simple necessary condition for such an interleaving to be CRT is (ro "OE [li]) ^ (ro #OE [:li]) _ (lo "OE [ri]) ^ (lo #OE [:ri]) : (6.1) li ro li lori ro lo ri lori ro lo ri lori ro pa-iso pa-latch L LR R P PO O
Reference: [19] <author> Tzu-Mu Lin. </author> <title> A Hierarchical Timing Simulation Model For Digital Integrated Circuits and Systems. </title> <type> Ph.D. thesis, </type> <institution> California Institute of Technology, </institution> <year> 1984. </year> <month> 5133:TR:84. </month>
Reference: [20] <author> Jan Magott. </author> <title> Performance evaluation of concurrent systems using Petri nets. </title> <journal> Information Processing Letters, </journal> <volume> 18 </volume> <pages> 7-13, </pages> <year> 1984. </year>
Reference-contexts: Timed Petri nets could also be used as the underlying formalism. Similar results to Theorem 2.8 and Theorem 2.10 were shown by Ramamoorthy and Ho [32] for decision-free timed Petri nets. The connection between this problem and linear programming was established by Magott <ref> [20] </ref>. Neither work utilized a result similar to Lemma 2.6. Magott briefly mentions that the resulting linear programming problem can be solved by a general-purpose polynomial-time algorithm.
Reference: [21] <author> David P. Marple and Abbas El Gamal. </author> <title> Optimal selection of transistor sizes in digital VLSI circuits. </title> <editor> In Paul Losleben, editor, </editor> <booktitle> Advanced Research in VLSI, Proceedings of the 1987 Stanford Conference, </booktitle> <pages> pages 151-172. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year> <month> 153 </month>
Reference-contexts: This dependence is normally small and is ignored in the optimization problem. Timing models similar to the tau model are used in other transistor optimization tools (designed for synchronous circuits), such as TILOS [11], COP <ref> [21] </ref>, and EPOXY [29]. Example 7.1 As an example, we will construct the optimization equations for the C-element circuit.
Reference: [22] <author> A.J. Martin. </author> <title> The limitation to delay-insensitivity in asynchronous circuits. </title> <editor> In William J. Dally, editor, </editor> <booktitle> Advanced Research in VLSI: Proceedings of the Sixth MIT Conference, </booktitle> <pages> pages 263-278, </pages> <address> Cambridge, MA, 1990. </address> <publisher> MIT Press. </publisher>
Reference-contexts: The circuit designer can concentrate on the design at a high level, where most radical improvements in performance can be achieved. The synthesis method produces circuits that contain no races or hazards; in fact, the circuits have a property known as quasi-delay-insensitivity <ref> [22] </ref>. Such a circuit functions correctly regardless of delays within its elements, except for some necessary assumptions about the relative delays along a few local wires. <p> Handshaking expansions are further transformed into sets of production rules where all explicit sequencing has been removed. There is a direct transformation from production rule sets into quasi-delay-insensitive circuits, circuits that function correctly regardless of delays in all gates and most wires <ref> [22] </ref>. 3.1.1 Communicating Sequential Processes The language constructs of our variant of CSP are shown in Table 3.1. Both synchronization and distributed assignment are performed by communication actions. <p> A circuit is delay-insensitive (DI) if it functions correctly regardless of delays in both its operators and its wires. The class of computations that can be performed without making any assumptions about wire delays is very limited <ref> [22] </ref>. 46 A circuit is speed-independent (SI) if it functions correctly regardless of delays in its operators. The wires in a SI circuit are assumed to be instantaneous or isochronic.
Reference: [23] <author> A.J. Martin, S.M. Burns, T.K. Lee, D. Borkovic, and P.J. Hazewindus. </author> <title> The design of an asynchronous microprocessor. </title> <editor> In C.L. Seitz, editor, </editor> <booktitle> Advanced Research in VLSI: Proceedings of the Decennial Caltech Conference on VLSI, </booktitle> <pages> pages 351-373, </pages> <address> Cambridge, MA, 1989. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Instead of a global signal controlling the rhythmic pulsing of the computation, the mechanism that performs a single step of the computation determines when it has completed, and then triggers the next step of the computation to be performed. Figure 1.1 contains measured data from the Asynchronous Microprocessor <ref> [23] </ref>, an example of such an asynchronous digital circuit. Techniques to design these asynchronous circuits have existed for nearly as long as there have been techniques for their clock-based counterparts. However, for various reasons, the vast majority of the existing digital circuits are synchronous. <p> ii ; (4.1) hbi "; ii 7! hco "; ii (4.2) depending on whether ff ao# + ff ai" &gt; ff bo# + ff bi" : Inherently disjunctive processes have not been encountered in any of the circuits fabricated by Martin's group at Caltech, including the Caltech Asyn chronous Microprocessor <ref> [23] </ref>. If they are needed, we suggest two techniques for modeling such processes. 76 First, in the previous example, we can simply choose one of the two rules (4:1) and (4:2) as the constraining rule for co ". <p> The active/passive scheme does have the advantage that it can be efficiently implemented without using a latched output-unit in the datapath. 6.2 Microprocessor The Asynchronous Microprocessor described in <ref> [23] </ref> was designed using the analysis techniques of Chapter 2 and provides a good example of how to apply performance analysis to a synthesized design. A complete CSP description of the microprocessor is given on Pages 356-7 of [23]. <p> latched output-unit in the datapath. 6.2 Microprocessor The Asynchronous Microprocessor described in <ref> [23] </ref> was designed using the analysis techniques of Chapter 2 and provides a good example of how to apply performance analysis to a synthesized design. A complete CSP description of the microprocessor is given on Pages 356-7 of [23].
Reference: [24] <author> Alain J. Martin. </author> <title> An axiomatic definition of synchronization primitives. </title> <journal> Acta Informatica, </journal> <volume> 16 </volume> <pages> 219-235, </pages> <year> 1981. </year>
Reference-contexts: If no guards are true, then continue with the next command. Perform one of the commands with a true guard. Repeat the previous steps. fl [S] Abbreviation for fl [true ! S]. Table 3.1: Basic constructs of CSP used to describe processes. communication port, performs a zero-slack <ref> [24] </ref> synchronization with a communication action on port Y in a second process. The control flow of the first process cannot pass the statement X without the control flow of the second process reaching (and being assured of passing) the statement Y . Distributed assignment is performed during the synchronization.
Reference: [25] <author> Alain J. Martin. </author> <title> Programming in VLSI: From communicating processes to delay-insensitive circuits. In C.A.R. Hoare, editor, </title> <booktitle> UT Year of Programming Institute on Concurrent Programming. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1990. </year>
Reference-contexts: These advantages include design modularity, interchangeability of subcomponents, tolerance to variation in power-supply voltages, tolerance to variation in temperatures, lower power consumption, and higher performance. The reader is referred to the literature for a more complete list of these advantages (especially <ref> [36, 8, 38, 25] </ref>). Here we will concentrate on the possible higher performance of an implementation of a computation as 2 an asynchronous circuit rather than as a synchronous circuit. It is not al-ways the case that an asynchronous circuit will outperform its synchronous counterpart. <p> Algorithm 2.2 has a provable running time of O (ev 2 ), but typically performs in O (e) time on real circuits. 42 Chapter 3 The Synthesis Method In this chapter, we briefly review the synthesis method developed by Martin <ref> [25] </ref> for systematically transforming concurrent programs into self-timed circuits. 3.1 Notation and Intermediate Forms The synthesis method is based on semantics-preserving transformations between intermediate representations of a concurrent program. The highest-level representations are in the form of Communication Sequential Processes (CSP) programs based on Hoare's original programming notation [16].
Reference: [26] <author> Nimrod Megiddo. </author> <title> Combinatorial optimization with rational objective functions. </title> <journal> Mathematics of Operations Research, </journal> <volume> 4(4) </volume> <pages> 414-424, </pages> <year> 1979. </year>
Reference-contexts: The number of bisections required is related to the logarithm of the size of the problem specification, including the number of bits need to describe the ff and * values. Megiddo <ref> [26] </ref> provides another solution. His solution depends only on the size of the graph and has a running time of O (e 2 v 2 log v). However, both algorithms seem to require their worst-case bound, even when the graphs correspond to repetitive ER systems generated from real circuits.
Reference: [27] <author> Teresa H.-Y. Meng, Robert W. Brodersen, and David G. Messerschmitt. </author> <title> Automatic synthesis of asynchronous circuits from high-level specifications. </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits, </journal> <volume> 8(11) </volume> <pages> 1185-1205, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: The modification split in two the data path activities modeled by the single delay named za. Only two named datapath delays occur in series in the modified version and the delay values in the datapath are smaller. 6.3 Other Asynchronous Pipeline Circuits 6.3.1 Meng Teresa Meng <ref> [27] </ref> uses the circuit shown in Figure 6.36 to implement a pipelined FIFO buffer. The control circuit enforces more sequencing than is necessary resulting in an inefficient implementation.
Reference: [28] <author> David E. Muller and W.S. Bartky. </author> <title> A theory of asynchronous circuits. </title> <booktitle> In The Annals of the Computation Laboratory of Harvard University. Volume XXIX: Proceedings of an International Symposium on the Theory of Switching, Part I., </booktitle> <pages> pages 204-243, </pages> <year> 1959. </year>
Reference-contexts: Such a circuit functions correctly regardless of delays within its elements, except for some necessary assumptions about the relative delays along a few local wires. This view of delays, except for a trivial difference in the way wires with delays are named, is equivalent to the speed-independent delay model <ref> [28, 7] </ref>, originally introduced by David Muller in the 1950s. There are many advantages of asynchronous circuits over synchronous circuits. These advantages include design modularity, interchangeability of subcomponents, tolerance to variation in power-supply voltages, tolerance to variation in temperatures, lower power consumption, and higher performance.
Reference: [29] <author> Fred W. Obermeier. </author> <title> An Open Architecture for Improving VLSI Circuit Performance. </title> <type> Ph.D. thesis, </type> <institution> UC Berkeley, </institution> <year> 1989. </year>
Reference-contexts: This dependence is normally small and is ignored in the optimization problem. Timing models similar to the tau model are used in other transistor optimization tools (designed for synchronous circuits), such as TILOS [11], COP [21], and EPOXY <ref> [29] </ref>. Example 7.1 As an example, we will construct the optimization equations for the C-element circuit.
Reference: [30] <author> Christos H. Papadimitriou and Kenneth Steiglitz. </author> <title> Combinatorial Optimization: Algorithms and Complexity. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1982. </year>
Reference-contexts: The techniques of linear programming <ref> [13, 30] </ref> can be used to find such a minimum-period linear timing function (MPLTF). <p> See Section 6.2 for an example of these transformations. 2.5.2 Primal-Dual Method In this section, we develop an algorithm which solves the primal program (2:27) and the dual program (2:26), simultaneously. This iterative algorithm is constructed by applying the primal-dual method <ref> [30] </ref>, a general technique for constructing special-case algorithms for solving linear programs. <p> If the equilibrium conditions y T " = 1 _ p = 0 (2.41) are satisfied, then x; p and y are optimal solutions, and p = y T ff. Proof: (This result and its converse follow from the equilibrium theorem <ref> [30] </ref>, a direct consequence of the duality theorem. Here, we prove the result directly.) By (2:42), y T (A 0 x + "p ff) = 0 : Thus, y T "p = y T ff. By (2:41), y T "p = p.
Reference: [31] <author> P. Penfield and J. Rubinstein. </author> <title> Signal delay in RC tree networks. </title> <editor> In Charles L. Seitz, editor, </editor> <booktitle> Proceedings of the Second Caltech Conference on VLSI, </booktitle> <pages> pages 269-283. </pages> <institution> Caltech Computer Science Department, </institution> <month> January </month> <year> 1981. </year>
Reference: [32] <author> C.V. Ramamoorthy and Gary S. Ho. </author> <title> Performance evaluation of asynchronous concurrent systems using Petri nets. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 6(5) </volume> <pages> 440-449, </pages> <month> September </month> <year> 1980. </year> <month> 154 </month>
Reference-contexts: We describe mechanical techniques to perform this transformation for a certain class of computations. The techniques we use to analyze the performance of an event-rule system are similar to techniques advocated by other researchers for other timing analysis problems. One such alternative methodology uses timed Petri nets <ref> [32] </ref> as the underlying description of the system. While both approaches are based on linear programming, they are developed differently. Our development, we believe, is more elegant, and is easily extended to include linear arrays of identical processes. <p> The second technique is less intuitive, but provides a solution in low-order polynomial time. Timed Petri nets could also be used as the underlying formalism. Similar results to Theorem 2.8 and Theorem 2.10 were shown by Ramamoorthy and Ho <ref> [32] </ref> for decision-free timed Petri nets. The connection between this problem and linear programming was established by Magott [20]. Neither work utilized a result similar to Lemma 2.6. Magott briefly mentions that the resulting linear programming problem can be solved by a general-purpose polynomial-time algorithm.
Reference: [33] <author> Edward M. Reingold, Jurg Nievergelt, and Narsingh Deo. </author> <title> Combinatorial Algorithms: Theory and Practice. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1977. </year>
Reference: [34] <author> Raymond Reiter. </author> <title> Scheduling parallel computations. </title> <journal> Journal of the ACM, </journal> <volume> 15(4) </volume> <pages> 590-599, </pages> <month> October </month> <year> 1968. </year>
Reference: [35] <author> Martin Rem. </author> <title> Trace theory and systolic computations. </title> <institution> Computer Science 5239:TR:87, California Institute of Technology, </institution> <year> 1987. </year>
Reference-contexts: Instead, a linear timing function exists for a regular system if the generated repetitive systems with an arbitrary number of processes have a property known as constant response time <ref> [18, 35] </ref>.
Reference: [36] <author> Charles L. Seitz. </author> <title> System timing. </title> <editor> In Carver Mead and Lynn Conway, editors, </editor> <title> Introduction to VLSI Systems, chapter 7. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1980. </year>
Reference-contexts: These advantages include design modularity, interchangeability of subcomponents, tolerance to variation in power-supply voltages, tolerance to variation in temperatures, lower power consumption, and higher performance. The reader is referred to the literature for a more complete list of these advantages (especially <ref> [36, 8, 38, 25] </ref>). Here we will concentrate on the possible higher performance of an implementation of a computation as 2 an asynchronous circuit rather than as a synchronous circuit. It is not al-ways the case that an asynchronous circuit will outperform its synchronous counterpart.
Reference: [37] <author> N.Z. Shor. </author> <title> Minimization Methods for Non-Differentiable Functions. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1985. </year> <note> Translated from Russian. </note>
Reference-contexts: The nonsmooth nature of the function makes the optimization problem difficult and traditional techniques such as gradient following must be modified to provide solutions to this problem. The subgra-dient techniques described by Shor <ref> [37] </ref> provide adequate methods for finding optimal solutions. 7.3.1 The Subgradient The subgradient of a convex function f of the vector x at the point x 0 can be defined as any vector g f (x 0 ) such that for all x f (x) f (x 0 ) g f <p> The step-sizes must be decreased with subsequent iterations; however, they must not be decreased too quickly, for in such a case all x (k) will be a bounded distance away from the starting point x (0) . Theorem 2:2 in <ref> [37] </ref> (p. 25) states that given any sequence h (k) such that h (k) &gt; 0; lim h (k) = 0; k=1 145 then the iteration x (k+1) = x (k) h (k+1) g f (x (k) ) (7.4) converges to the minimum solution. <p> This straight algorithm with space dilation is still too slow. We actually use Algorithm 7.2, which is described in <ref> [37] </ref> (pp. 135-139). While this algorithm does not have the provable convergence properties of the previous algorithm, in practice, it converges to the optimal solution in fewer steps. We have implemented Algorithm 7.2.
Reference: [38] <author> Ivan E. Sutherland. </author> <title> A theory of logical effort (revised version). </title> <type> Technical Report SSA 4679, Sutherland, </type> <institution> Sproull and Associates, Inc., </institution> <month> September </month> <year> 1986. </year>
Reference-contexts: These advantages include design modularity, interchangeability of subcomponents, tolerance to variation in power-supply voltages, tolerance to variation in temperatures, lower power consumption, and higher performance. The reader is referred to the literature for a more complete list of these advantages (especially <ref> [36, 8, 38, 25] </ref>). Here we will concentrate on the possible higher performance of an implementation of a computation as 2 an asynchronous circuit rather than as a synchronous circuit. It is not al-ways the case that an asynchronous circuit will outperform its synchronous counterpart.
Reference: [39] <author> Ted Williams, Mark Horowitz, R.L. Alverson, and T.S. Yang. </author> <title> A self-timed chip for division. </title> <editor> In Paul Losleben, editor, </editor> <booktitle> Advanced Research in VLSI, Proceedings of the 1987 Stanford Conference, </booktitle> <pages> pages 75-95. </pages> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1987. </year> <month> 155 </month>
Reference-contexts: What is important is the cycle period of three stages connected together to form a ring (Figure 6.41). The surprising result is that with this implementation, all six of the datapath delays occur in series. Even with the (non-speed-independent) optimization performed in <ref> [14, 39] </ref>, all datapath delays occur in series.
References-found: 39

