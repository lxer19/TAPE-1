URL: http://www.csd.uu.se/~jakob/publications/exjobb.ps
Refering-URL: http://www.csd.uu.se/~jakob/publications.html
Root-URL: 
Title: Worst-Case Execution Time Analysis for Optimized Code  
Author: Jakob Engblom 
Date: October 18, 1997  
Abstract-found: 0
Intro-found: 1
Reference: [Alt96a] <author> Peter Altenbernd. </author> <title> On the False Path Problem in Hard Real-Time Programs. </title> <booktitle> In Proceedings 8th Euromicro Workshop on Real Time Systems, </booktitle> <year> 1996. </year>
Reference-contexts: In the example below, the time taken to perform a multiplication may be very different from the time taken to perform an addition. 5 The term false path is also used in some literature <ref> [Alt96a] </ref>. 8 CHAPTER 2. <p> A heuristic is needed since the general problem of identifying infeasible paths is assumed to be NP-complete, even for the simple programs generated in the CHaRY project <ref> [Alt96a] </ref>. The disadvantage of the approach is that loops and function calls are difficult to handle. In this thesis we have not done any work on representing or identifying infeasible paths.
Reference: [Alt96b] <author> Peter Altenbernd. </author> <title> Timing Analysis, Scheduling, and Allocation of Periodic Hard Real-Time Tasks. </title> <type> PhD thesis, </type> <institution> Universitat-GH Paderborn, Germany, </institution> <year> 1996. </year>
Reference-contexts: In some cases, it also of interest to the system designer to know the minimum execution time of a certain program, for example when outputs must be separated in time by a certain minimum time, or to perform scheduling analysis <ref> [Alt96b] </ref>. This is called the best case execution time, bcet. In the general case, we cannot determine the exact execution time of a program, but only an estimate. <p> I/O operations must have bounded execution times, which can be included in the analysis when I/O is performed. If the system cannot give such guarantees, it can hardly be considered a suitable real-time system. 11 See for example <ref> [Alt96b] </ref>. 2.7. PORTING A TIMING ANALYSIS TOOL 13 Still, there are many functions and algorithms in a timing analyzer which are not dependent upon the target machine. The architecture presented in Chapter 3 strives to isolate the issues related to the target system to a single component.
Reference: [Alt97] <author> Peter Altenbernd. CHaRy: </author> <title> The C-Lab Hard Real-Time System to Support Mechatronical Design. </title> <booktitle> In Proceedings IEEE International Symposium and Workshop on Systems Engineering of Computer Based Systems. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1997. </year>
Reference-contexts: The disadvantage is that the analysis is performed for a language which is not in common use. * Altenbernd has performed research into heuristically determining infeasible paths in simple C programs, as a part of the CHaRy software architecture at C-LAB in Paderborn <ref> [Alt97] </ref>, where his heuristic is used on non-looping programs automatically generated from a higher-level representation. A heuristic is needed since the general problem of identifying infeasible paths is assumed to be NP-complete, even for the simple programs generated in the CHaRY project [Alt96a]. <p> The program is executed using symbolic values for variables instead of concrete values, and the result is symbolic expressions for the values of variables in the program <ref> [CR81, Alt97] </ref>. Depending upon the accuracy, the approach can be quite time-consuming; it is hard to find a good trade-off between accuracy and performance. It should be noted that the difference between symbolic execution and abstract interpretation is quite unclear, and it seems useful to blend elements of both techniques. <p> They handle pipeline effects, set-associative and direct-mapped instruction caches, and direct-mapped data caches. The approach is all-encompassing, and they have produced a number of papers on the subject of wcet analysis in general and the handling of caches in particular. * The CHaRY software architecture <ref> [Alt97] </ref>, uses the advanced Motorola PowerPC 604 processor, and thus need to handle cache and pipeline issues in order to obtain good timing estimates. The code they analyze is rather limited, containing no function calls and no loops. <p> Nobody has actually used this approach, because its exponential complexity. Each if-branch encountered doubles the set of possible executions; an if within a loop produces 2 n paths (where n is the maximum number of iterations of the loop). * The CHaRy system <ref> [Alt97] </ref>, uses a k-longest path search. The k longest paths are enumerated, and then checked for executability in order to decreasing length.
Reference: [AMWH94] <author> Robert Arnold, Frank Muller, David Whalley, and Marion Harmon. </author> <title> Bounding worst-case instruction cache performance. </title> <booktitle> In IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 172-181, </pages> <month> December </month> <year> 1994. </year> <note> Available via WWW from http://www.informatik.hu-berlin.de/~mueller/publications.html </note>
Reference-contexts: This requires the programmer to maintain a mapping between source level and object code loops. Usually, only loop bounds can be provided. This approach is taken in <ref> [LBJ + 95, AMWH94] </ref>. As stated above in Section 3.1 (page 16), all approaches using annotations share the problem of the quality of the annotations. Annotations cannot not be trusted unless supported by some form of validation; humans do make mistakes. <p> They introduce the idea of a wcta, a worst-case timing abstraction, which is a concept related to our idea about the connection between the LLA and the calculator. * Some research groups centered around Florida State University and Florida A&M University <ref> [WMH + 97, HWH95, AMWH94] </ref> have built a powerful low level tool using a static cache simulator. They handle pipeline effects, set-associative and direct-mapped instruction caches, and direct-mapped data caches. <p> In our framework, this means using the compiler to perform both the HLA and the mapping. The idea is a step on the way to co-transformation, but it is rather ad hoc and not well documented <ref> [AMWH94, HWH95, WMH + 97, LBJ + 95] </ref>. * The timing tool can co-transform the timing information: every time the compiler changes the code, an equivalent operation is performed on the timing information.
Reference: [ASU86] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year> <note> Generally known as the "Dragon Book". </note>
Reference-contexts: These optimizations are very interesting from a debugger viewpoint since they affect when, where, and in which order values are computed and instructions executed. This is an important difference in the high to low level mapping required by a timing analyzer and that required by a debugger. CSE <ref> [Nul97, ASU86] </ref> Common Subexpression Elimination. A subexpression common to two calculations (or more) is broken out and evaluated only once. Constant Folding [Nul97] Expressions with values which can be computed at compile time are replaced with the (constant) result of the expressions. For example, a=4+5*6 ! a=34. Constant Propagation [Nul97, ASU86] <p> CSE <ref> [Nul97, ASU86] </ref> Common Subexpression Elimination. A subexpression common to two calculations (or more) is broken out and evaluated only once. Constant Folding [Nul97] Expressions with values which can be computed at compile time are replaced with the (constant) result of the expressions. For example, a=4+5*6 ! a=34. Constant Propagation [Nul97, ASU86] A constant value assigned to a variable is propagated through the flow graph and substituted at the use of the variable. Expression Simplification [Nul97] Expressions can be simplified to equivalent expressions (which are faster to execute), using mathematical equivalences. For example, i*0 ! 0, or a+5*(a+b) ! 6*a+5*b. <p> The ODL code can be found in Appendix B, as Transformation B.1 (page 78). Branch elimination A branch elimination optimization shortcuts a jump (conditional or not) to an unconditional jump, replacing it by a single jump to the destination of the unconditional jump <ref> [Nul97, ASU86] </ref>. <p> The code is given in Transformation 6.1. Note how two compound nodes are used to pick up the if-branches, and how only one of them remain in the out-pattern. Loop preheader creation A loop preheader is a basic block executed once before every loop execution <ref> [ASU86] </ref>. <p> Each will need its own transformation (s). Code generation for switch statements is a complex topic. In <ref> [ASU86, Section 8.5] </ref>, a number of tech niques are given: sequences of conditional branches, sequential search jump tables, hashed jump tables, and direct-indexed jump tables. Obviously, each such technique must have its own corresponding co transform. <p> One area where the results are useful is in memory reference analysis, where we want to figure out the addresses referred in order to model the data and instruction caches of our processor <ref> [ASU86, BGS90, HHG + 95] </ref>. * Abstract interpretation is a "a general theory for approximating the semantics of discrete dynamic systems".
Reference: [AT96] <author> Ali-Reza Adl-Tabatabai. </author> <title> Source-Level Debugging of Global Optimized Code. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> June </month> <year> 1996. </year> <note> Available via ftp from reports.adm.cs.cmu.edu/usr/anon/1996/CMU-CS-96-133.ps, and as technical report CMU-CS-96-133. </note>
Reference-contexts: The program simply cannot be run without being optimized. 7 * For debugging, the necessity of working with the optimized program has been pointed out in several works <ref> [AT96, Cop92, Coo92] </ref>. The main reasons cited are: Language definition ambiguities and misunderstanding may cause an optimized program to differ from the expected behavior of the source program. Optimizations may mask or reveal bugs compared to unoptimized program because of changed memory layouts, less redundant code, and other subtle effects. <p> The code location problem is determining which source statement corresponds to a certain object code instruction, and vice versa. This information is needed by the user interface of debuggers. In debugging research, the data value problem has attracted the most attention <ref> [AT96, p. 28] </ref>, and in [Coo92, p. 14] it is stated that most problems in debugging are data value problems or can be reduced to them. For the purpose of wcet analysis, the code location problem is the most relevant. <p> For the purpose of wcet analysis, the code location problem is the most relevant. This is a static problem, where correspondences need to be found between the source and object code versions of a program, regardless of the paths taken. The mappings required are summarized in <ref> [AT96] </ref>: one mapping from object-code instructions to source-level expressions or statements (to show where a program is stopped) , and one mapping from source-level statements to object code (in order to place breakpoints). * Zellweger completed a PhD thesis about the debugging of optimized code in 1984 [Zel84]. <p> loop nests, he uses a technique whereby the graph for a loop in unrolled a few times in order to make it possible to determine which variables are current (available with expected values) and which are not. * Adl-Tabatabai has written a thesis on the subject of debugging optimized code <ref> [AT96] </ref>, as well as a number of articles in cooperation with Thomas Gross [ATG96, ATG94, ATG92]. The work has resulted in the implementation of a prototype as a part of the cmcc optimizing C-compiler.
Reference: [ATG92] <author> Ali-Reza Adl-Tabatabai and Thomas Gross. </author> <title> Evicted variables and the interaction of global register allocation and symbolic debugging. </title> <type> Technical Report CMU/CS-92-202, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: unrolled a few times in order to make it possible to determine which variables are current (available with expected values) and which are not. * Adl-Tabatabai has written a thesis on the subject of debugging optimized code [AT96], as well as a number of articles in cooperation with Thomas Gross <ref> [ATG96, ATG94, ATG92] </ref>. The work has resulted in the implementation of a prototype as a part of the cmcc optimizing C-compiler. His approach to debugging requires two code mappings (as described above), one to obtain the source position corresponding to an exception, and one in order to place breakpoints.
Reference: [ATG94] <author> Ali-Reza Adl-Tabatabai and Thomas Gross. </author> <title> Symbolic debugging of globally optimized code: Data value problems and their solutions. </title> <type> Technical Report CMU/CS-94-105, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: unrolled a few times in order to make it possible to determine which variables are current (available with expected values) and which are not. * Adl-Tabatabai has written a thesis on the subject of debugging optimized code [AT96], as well as a number of articles in cooperation with Thomas Gross <ref> [ATG96, ATG94, ATG92] </ref>. The work has resulted in the implementation of a prototype as a part of the cmcc optimizing C-compiler. His approach to debugging requires two code mappings (as described above), one to obtain the source position corresponding to an exception, and one in order to place breakpoints.
Reference: [ATG96] <author> Ali-Reza Adl-Tabatabai and Thomas Gross. </author> <title> Source-level debugging of scalar optimized code. </title> <booktitle> In Proceedings of ACM SIGPLAN'96 Conf. on Prog. Language Design and Implementation, </booktitle> <pages> pages 33-43. </pages> <publisher> ACM, </publisher> <month> May </month> <year> 1996. </year>
Reference-contexts: unrolled a few times in order to make it possible to determine which variables are current (available with expected values) and which are not. * Adl-Tabatabai has written a thesis on the subject of debugging optimized code [AT96], as well as a number of articles in cooperation with Thomas Gross <ref> [ATG96, ATG94, ATG92] </ref>. The work has resulted in the implementation of a prototype as a part of the cmcc optimizing C-compiler. His approach to debugging requires two code mappings (as described above), one to obtain the source position corresponding to an exception, and one in order to place breakpoints.
Reference: [AWVW96] <author> Joe Armstrong, Mike Williams, Robert Virding, and Claes Wikstrom. </author> <title> Concurrent Programming in Erlang. </title> <publisher> Prentice-Hall, </publisher> <address> 2 edition, </address> <year> 1996. </year>
Reference-contexts: It outputs an interme diate file (not shown) which is read by the main program (cox). 1 See [GHL + 92]. 2 See <ref> [AWVW96] </ref>. 27 28 CHAPTER 5. PROTOTYPE IMPLEMENTATION * The progreader reads the .prog files containing program instances. .prog files are used both as input and output.
Reference: [BGS90] <author> David F. Bacon, Susan L. Graham, and Oliver J. Sharp. </author> <title> Compiler transformations for high-performance computing. </title> <type> Technical report, </type> <institution> University of California, Computer Science Division, Berkeley, </institution> <address> California 94730, </address> <year> 1990. </year>
Reference-contexts: In this chapter, we will examine some function level transformations found in the literature, transformations for both optimization and code generation. We have used two catalogs of transformations as our main source of transformations <ref> [Nul97, BGS90] </ref>, and we have not selected transformations based on how easy they are to handle in ODL. 35 36 CHAPTER 6. <p> These changes will affect the results of the LLA, but not the mapped information from the HLA. 6.2. IMPLEMENTING TRANSFORMATIONS IN ODL 37 Function Inlining [Nul97] Puts a copy of a function inside another function, removing the call over head. Loop Pushing <ref> [BGS90, Section 6.8.7] </ref> A loop is pushed from a calling function to a specialized version of the called function. Procedure Cloning [BGS90, Section 6.8.6] Specialized versions of a function are used instead of the original function. Different calls are replaced by calls to different versions. <p> IMPLEMENTING TRANSFORMATIONS IN ODL 37 Function Inlining [Nul97] Puts a copy of a function inside another function, removing the call over head. Loop Pushing [BGS90, Section 6.8.7] A loop is pushed from a calling function to a specialized version of the called function. Procedure Cloning <ref> [BGS90, Section 6.8.6] </ref> Specialized versions of a function are used instead of the original function. Different calls are replaced by calls to different versions. Tail Recursion Optimization [BGS90, Section 6.8.8] Recursion is replaced by iteration. <p> Procedure Cloning [BGS90, Section 6.8.6] Specialized versions of a function are used instead of the original function. Different calls are replaced by calls to different versions. Tail Recursion Optimization <ref> [BGS90, Section 6.8.8] </ref> Recursion is replaced by iteration. <p> One area where the results are useful is in memory reference analysis, where we want to figure out the addresses referred in order to model the data and instruction caches of our processor <ref> [ASU86, BGS90, HHG + 95] </ref>. * Abstract interpretation is a "a general theory for approximating the semantics of discrete dynamic systems". <p> The main problem he identifies is that some source program variables will be present in several versions at once. Typically, these problems are caused by techniques that overlap several executions of a loop (such as software pipelining and loop unrolling and scheduling <ref> [BGS90] </ref>). This problem is also present with modern superscalar architectures. His solutions are A user interface that helps explain the changes to the program.
Reference: [Bla94] <author> R. J. Blainey. </author> <title> Instruction scheduling in the TOBEY compiler. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 38(5) </volume> <pages> 577-593, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: A node N postdominates another node M if all paths from M to the end node passes through N. See <ref> [Bla94, p. 582] </ref> for a formal definition. 5.2. OPTIMIZATION DESCRIPTION LANGUAGE (ODL) 31 Transformation declarations The main body of the ODL program is the list of transformation declarations.
Reference: [Bor95] <author> Hans Borjesson. </author> <title> Incorporating worst-case execution time in a commercial c-compiler. </title> <type> Master's thesis, </type> <institution> Department of Computer Systems, Uppsala University, </institution> <month> December </month> <year> 1995. </year> <type> DoCS MSc Thesis 95/69. 90 BIBLIOGRAPHY 91 </type>
Reference-contexts: every path from a start marker must pass the corresponding stop marker, and every path to the stop marker must pass the corresponding start marker. 9 For more on specializing functions for certain input, see [CP + 91], or any text on partial evaluation. 10 This approach is taken in <ref> [Bor95] </ref>; see section Section 7.3.1 (page 58). 12 CHAPTER 2. BACKGROUND: REAL-TIME SYSTEMS AND WCET ESTIMATION Presentation of results The presentation of the results of the timing analysis should make it easy to draw conclusions and identify timing culprits in the code.
Reference: [BW97] <author> Alan Burns and Andy Wellings. </author> <title> Real-Time Systems and Programming Languages. </title> <publisher> Addison-Wesley, </publisher> <year> 1997. </year>
Reference-contexts: In this thesis, we consider real-time systems, with a focus on embedded real-time systems. 2.1 The correctness of real-time systems Real-time programs differ from "ordinary" programs in that they have to be correct both in terms of what is delivered and when it is delivered. In <ref> [BW97, p. 2] </ref> the following definition of the correctness of a real-time system is given: The correctness of a real-time system depends not only on the logical result of the computation but also on the time at which the results are produced.
Reference: [CBW94] <author> Roderick Chapman, Alan Burns, and Andy Wellings. </author> <title> Integrated program proof and worst-case timing analysis of SPARK Ada. </title> <booktitle> In ACM Sigplan Workshop on Language, Compiler and Tool Support for Real-Time Systems, </booktitle> <year> 1994. </year> <note> Available on www.cs.umd.edu/users/pugh/sigplan realtime workshop/lct-rts94/. </note>
Reference-contexts: The wcet varies according to the instance. The functions could capture most behaviors, but generating such functions is not a trivial task. We doubt the feasibility. 4. The wcet function for a function is generated from other user information. This approach is used in <ref> [CBW94, Cha94] </ref>, where the user may supply a number of modes for a function. A mode is a set of input values. Each mode is given its own set of execution constraints, and a symbolic expression for the execution time for a certain function in a certain mode is deduced. <p> During development, it is the correct approach: fail eagerly in order to catch errors, but not in shipping software. * The SPATS tool adds a set of annotations to spark Ada to allow execution time analysis <ref> [CBW94, Cha94] </ref>. The annotations are used to divide programs into appropriate pieces for analysis, and to give bounds on the input and output data from a function. The annotations are entered inside comments and are processed by stand-alone tools.
Reference: [CCG + 75] <author> Graham Chapman, John Cleese, Terry Gilliam, Eric Idle, Terry Jones, and Michael Palin. </author> <title> Monthy Python and the Holy Grail. Movie produced by Python (Monty) Pictures, </title> <year> 1975. </year>
Reference: [CD95] <author> Tai M. Chung and Hank G. Dietz. </author> <title> Language constructs and transformation for hard real-time systems. </title> <booktitle> In Proceedings of the Second ACM SIGPLAN Workshop on Languages, Compilers, and Tools for Real-Time Systems, </booktitle> <month> June </month> <year> 1995. </year> <note> Available on www.cs.umd.edu/projects/TimeWare/sigplan95/. </note>
Reference-contexts: This approach is used in the Modula/R compiler for the MARS project, where a timing tree is processed at the same time as the code [Vrc94b]. Chung and Dietz also describe an approach where timing information is explicitly manipulated by the compiler <ref> [CD95] </ref>. We believe that the co-transformer approach is the best solution. It makes intuitive sense to send the information about the program in the same direction through the compiler as the code itself.
Reference: [Cha94] <author> Roderick Chapman. </author> <title> Worst-case timing analysis via finding longest paths in SPARK Ada basic-path graphs. </title> <type> Technical Report YCS-94-246, </type> <institution> Department of Computer Science, York University, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: The wcet varies according to the instance. The functions could capture most behaviors, but generating such functions is not a trivial task. We doubt the feasibility. 4. The wcet function for a function is generated from other user information. This approach is used in <ref> [CBW94, Cha94] </ref>, where the user may supply a number of modes for a function. A mode is a set of input values. Each mode is given its own set of execution constraints, and a symbolic expression for the execution time for a certain function in a certain mode is deduced. <p> During development, it is the correct approach: fail eagerly in order to catch errors, but not in shipping software. * The SPATS tool adds a set of annotations to spark Ada to allow execution time analysis <ref> [CBW94, Cha94] </ref>. The annotations are used to divide programs into appropriate pieces for analysis, and to give bounds on the input and output data from a function. The annotations are entered inside comments and are processed by stand-alone tools. <p> A program written using no gotos is always well structured. 62 CHAPTER 7. PREVIOUS WORK * Chapman <ref> [Cha94] </ref> uses regular expressions to represent program paths and graph rewriting rules to perform calculations. <p> Debug information is used in the York Software Engineering timing tools [For92], in the spats tool <ref> [Cha94] </ref>, and by the cinderella tool [Cin97, LMW96]. 2 Using debug information in some sense amounts to avoiding the issue by transforming it into somebody else's problem: the compiler writer has to provide enough information, but nothing is said how she manages to do so.
Reference: [Cin97] <institution> WWW homepage for the cinderella system, </institution> <month> August </month> <year> 1997. </year> <note> Available via WWW at the address: http://www.ee.princeton.edu/~yauli/cinderella-3.0/. </note>
Reference-contexts: Information about loop bounds and infeasible paths can be entered. Infeasible paths are specified by declaring that two blocks of code lie on the same or different paths. * The cinderella tool <ref> [LM95, LMW96, Cin97] </ref> prompts the user to interactively provide the information required for timing analysis. The information which can be provided are loop bounds and infeasible paths. <p> The code they analyze is rather limited, containing no function calls and no loops. This simplifies the problem enough so that their Program Timing Analyzer can handle the effects of pipelining and set-associative instruction and data caches [Sta97]. * The cinderella tool from Princeton <ref> [LM95, LMW96, Cin97] </ref> implements an approach which is powerful enough to handle pipelines, set-associative instruction caches, data caches and unified caches (other approaches have assumed the data and instruction caches to be separated). They allow for set-associative data caches. <p> Debug information is used in the York Software Engineering timing tools [For92], in the spats tool [Cha94], and by the cinderella tool <ref> [Cin97, LMW96] </ref>. 2 Using debug information in some sense amounts to avoiding the issue by transforming it into somebody else's problem: the compiler writer has to provide enough information, but nothing is said how she manages to do so. <p> Times are displayed for individual source statements [PS93]. * The cinderella tool has a graphical user interface used to present information about the program to the user, and to prompt for information used in the analysis. Timing information is displayed per function <ref> [Cin97] </ref>. * Harmon et al has been working on user interfaces for timing tools. They realize that optimized code causes problems, but proposes no solution to the problem. The user can view information about the program on the level of functions, loops, paths, subpaths, and ranges of machine instructions.
Reference: [Coo92] <author> Lyle Edward Cool. </author> <title> Debugging VLIW code after instruction scheduling. </title> <type> Master's thesis, </type> <institution> Oregon Graduate Institute, Department of Computer Science, </institution> <month> July </month> <year> 1992. </year> <note> Available via ftp from ftp://cse.ogi.edu/pub/tech-reports/1992/92-TH-009.ps.gz. </note>
Reference-contexts: The program simply cannot be run without being optimized. 7 * For debugging, the necessity of working with the optimized program has been pointed out in several works <ref> [AT96, Cop92, Coo92] </ref>. The main reasons cited are: Language definition ambiguities and misunderstanding may cause an optimized program to differ from the expected behavior of the source program. Optimizations may mask or reveal bugs compared to unoptimized program because of changed memory layouts, less redundant code, and other subtle effects. <p> The code location problem is determining which source statement corresponds to a certain object code instruction, and vice versa. This information is needed by the user interface of debuggers. In debugging research, the data value problem has attracted the most attention [AT96, p. 28], and in <ref> [Coo92, p. 14] </ref> it is stated that most problems in debugging are data value problems or can be reduced to them. For the purpose of wcet analysis, the code location problem is the most relevant. <p> According to Cool <ref> [Coo92] </ref>, Zellweger attacks the problem of mapping source and object code to one another from the execution path perspective. She inserts hidden breakpoints into the code, and uses these to determine by which path execution has reached a certain point in the program. <p> The compiler needs to maintain the information: a concept similar to co-transformation. * Cool <ref> [Coo92] </ref> attacks the problem of debugging optimized VLIW 3 code. The main problem he identifies is that some source program variables will be present in several versions at once. <p> The user can view information about the program on the level of functions, loops, paths, subpaths, and ranges of machine instructions. Pipeline diagrams can be invoked to show detailed information about the execution of the program [KHR + 96]. * <ref> [Coo92] </ref> presents the idea that the user interface should try to explain the changes the program has undergone.
Reference: [Cop92] <author> Max Copperman. </author> <title> Debugging optimized code without being misled. </title> <type> Technical Report UCSC-CRL-92-01, </type> <institution> University of California, Santa Cruz, </institution> <month> May </month> <year> 1992. </year> <note> Available via ftp from ftp://ftp.cse.ucsc.edu/pub/tr/ucsc-crl-92-01.ps.Z. </note>
Reference-contexts: The program simply cannot be run without being optimized. 7 * For debugging, the necessity of working with the optimized program has been pointed out in several works <ref> [AT96, Cop92, Coo92] </ref>. The main reasons cited are: Language definition ambiguities and misunderstanding may cause an optimized program to differ from the expected behavior of the source program. Optimizations may mask or reveal bugs compared to unoptimized program because of changed memory layouts, less redundant code, and other subtle effects. <p> She also mentions the idea that the user may be presented with a modified source program that more closely corresponds to the program being executed. * Copperman <ref> [Cop92] </ref> approaches the problem of mapping optimized and unoptimized code by maintaining both an unoptimized and an optimized flow graph for the same program. His main focus is on data value problems, and correspondences between paths.
Reference: [Cou81] <author> P. Cousot. </author> <title> Semantic foundations of program analysis. </title> <editor> In Steven S. Muchnick and Neil D. Jones, editors, </editor> <title> Program Flow Analysis: </title> <journal> Theory and Applications, </journal> <volume> chapter 10, </volume> <pages> pages 303-342. </pages> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: It works by approximating the semantics of a program language, typically by replacing single values with sets of values <ref> [Cou96, Cou81] </ref>. * Symbolic execution is another approximation approach with a slightly more operational slant. The program is executed using symbolic values for variables instead of concrete values, and the result is symbolic expressions for the values of variables in the program [CR81, Alt97].
Reference: [Cou96] <author> Patrick Cousot. </author> <title> Abstract interpretation. </title> <journal> ACM Computing Surveys, </journal> <volume> 28(2) </volume> <pages> 324-328, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: It works by approximating the semantics of a program language, typically by replacing single values with sets of values <ref> [Cou96, Cou81] </ref>. * Symbolic execution is another approximation approach with a slightly more operational slant. The program is executed using symbolic values for variables instead of concrete values, and the result is symbolic expressions for the values of variables in the program [CR81, Alt97].
Reference: [CP + 91] <author> Alberto Coen-Porisini et al. </author> <title> Software specialization via symbolic execution. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(9) </volume> <pages> 884-899, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: and input operations do. 10 The placement of markers must be restricted to sensible combinations: every path from a start marker must pass the corresponding stop marker, and every path to the stop marker must pass the corresponding start marker. 9 For more on specializing functions for certain input, see <ref> [CP + 91] </ref>, or any text on partial evaluation. 10 This approach is taken in [Bor95]; see section Section 7.3.1 (page 58). 12 CHAPTER 2.
Reference: [CR81] <author> Lori A. Clarke and Debra J. Richardson. </author> <title> Symbolic evaluation methods for program analysis. </title> <editor> In Steven S. Muchnick and Neil D. Jones, editors, </editor> <title> Program Flow Analysis: </title> <journal> Theory and Applications, </journal> <volume> chapter 9, </volume> <pages> pages 264-300. </pages> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: The program is executed using symbolic values for variables instead of concrete values, and the result is symbolic expressions for the values of variables in the program <ref> [CR81, Alt97] </ref>. Depending upon the accuracy, the approach can be quite time-consuming; it is hard to find a good trade-off between accuracy and performance. It should be noted that the difference between symbolic execution and abstract interpretation is quite unclear, and it seems useful to blend elements of both techniques.
Reference: [Dot97] <institution> WWW homepage for the graphics visualizations at AT&T Research, </institution> <month> August </month> <year> 1997. </year> <note> Available via WWW at the address: http://www.research.att.com/sw/tools/graphviz/. </note>
Reference-contexts: Update the execution information about the program in such a way that the it is consistent with the state of the program code and possible program executions after a transformation. 3 The .dot format is the input to the graph drawing tool Dot <ref> [Dot97, KN] </ref>, and is used to visualize the function graphs for debugging and development purposes. 5.2. OPTIMIZATION DESCRIPTION LANGUAGE (ODL) 29 To meet goal 1, we need to restructure the flow graph of the program in the same way as the compiler, giving corresponding names to basic blocks.
Reference: [EG97a] <author> Andreas Ermedahl and Jan Gustafsson. </author> <title> Deriving annotations for tight calculation of execution time. </title> <institution> Department of Computer Systems, University of Uppsala and Department of Computer Engineering, Malardalen University, Sweden. </institution> <note> Submitted to EuroPar'97, Febru-ary 1997. </note>
Reference-contexts: In the wcet community, some work has been performed on automatically analyzing programs with an eye towards obtaining the information needed by timing analysis tools. * Ermedahl and Gustafsson <ref> [EG97a] </ref> analyze a small subset of C using techniques related to abstract interpretation and symbolic execution. The resulting data includes loop bounds for loops, even with quite complex dependences.
Reference: [EG97b] <author> Andreas Ermedahl and Jan Gustafsson. </author> <title> Realtidsindustrins syn pa verktyg for exekver-ingstidsanalys. </title> <type> Technical Report ASTEC Technical Report 97/06, </type> <institution> ASTEC Competence Center, Uppsala University, </institution> <month> July </month> <year> 1997. </year>
Reference-contexts: However, we feel that a short overview of the methods used today to determine execution times is in order to place our work into context. The state of the practice in industry today seems to be various forms of measurement and educated guesses. In <ref> [EG97b] </ref> they have investigated which methods are actually used in practice, and they give the following list of techniques: * Manually counting assembler instructions and calculating the time taken for instruction sequences, using the cycles per instruction tables provided by the processor manufacturers. <p> The other approaches are measurements, and thus lacks in the safety quality dimension. From this we conclude that the need for software development tools supporting execution time analysis is great. In <ref> [EG97b] </ref>, most respondents replied that a software tool to help them would be most useful. <p> It is also of interest to determine the characteristics of real-time programs: are they long or short, how complex are they, which language constructions are used, are there some language features which are never used, etc. An investigation of this is underway in Uppsala (preliminary results are given in <ref> [EG97b] </ref>). Ideally, this investigation should be carried out across disciplines (in cooperation between real-time, software engineering, business, and social researchers) and continuously, to obtain data about the development of programming habits and methods.
Reference: [For92] <author> Charles Forsyth. </author> <title> Implementation of the worst-case execution analyser. Technical Report Hard Real-Time Operating System Kernel Study Task 8, Volume E, </title> <institution> York Software Engineering Ltd, </institution> <month> July </month> <year> 1992. </year> <note> 92 BIBLIOGRAPHY </note>
Reference-contexts: The annotations are entered inside comments and are processed by stand-alone tools. Program correctness can be proven in parallel with the calculation of the program wcet, using the same tool. * Forsyth <ref> [For92] </ref> uses Ada PRAGMA statements to enter information about loop bounds, and has modified the York Ada compiler to emit the information from the PRAGMAS into the debug information in the object code. <p> Debug information is used in the York Software Engineering timing tools <ref> [For92] </ref>, in the spats tool [Cha94], and by the cinderella tool [Cin97, LMW96]. 2 Using debug information in some sense amounts to avoiding the issue by transforming it into somebody else's problem: the compiler writer has to provide enough information, but nothing is said how she manages to do so.
Reference: [For93] <author> Charles Forsyth. </author> <title> Using the worst-case execution analyser. Technical Report Hard Real-Time Operating System Kernel Study Task 8, Volume D, </title> <institution> York Software Engineering Ltd, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: The wcet for a function is a given constant. The user gives the system information about the wcet for each function, obtained in some unspecified way. This approach is taken in <ref> [For93] </ref>. The wcet is the same for all calls to a function. This has the potential to lead to overestimations and makes it hard to capture the behavior of complex functions. Manual calculations of execution times must also be treated with caution with regard to correctness. 2.
Reference: [GE97] <author> Jan Gustafsson and Andreas Ermedahl. </author> <title> Automatic derivation of path and loop annotations in object-oriented real-time programs. </title> <booktitle> In Joint Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <address> Geneva, Switzerland, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: The resulting data includes loop bounds for loops, even with quite complex dependences. The present subset is rather small, and they do not allow global data. * Gustafsson et al <ref> [GE97, GPMTB97, RTT97] </ref> have analyzed the object-oriented RealTimeTalk language, trying to obtain information useful for wcet analysis for object-oriented programs.
Reference: [Ger94] <author> Richard Gerber. </author> <title> Languages and tools for real-time systems: Problems, solutions and opportunities. </title> <type> Technical Report UMD CS-TR-3362, </type> <institution> UMIACS-TR-94-117, Department of Computer Science, University of Maryland, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: In <ref> [Ger94] </ref>, Richard Gerber points out the importance of traceability between the source code and the generated assembly code in order to support debugging of real-time programs. 2.6. USER INTERFACE ISSUES 11 their timing slots.
Reference: [GHL + 92] <author> R. W. Gray, V. P. Heuring, S. P. Levi, A. M. Sloane, and W. M. Waite. Eli: </author> <title> A complete, flexible compiler construction system. </title> <journal> Communications of the ACM, </journal> <pages> pages 121-131, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: The output from the parsers are intermediate files containing Erlang terms easily read by the Erlang system. * The tracereader reads the .trace files containing transformation traces. It outputs an interme diate file (not shown) which is read by the main program (cox). 1 See <ref> [GHL + 92] </ref>. 2 See [AWVW96]. 27 28 CHAPTER 5. PROTOTYPE IMPLEMENTATION * The progreader reads the .prog files containing program instances. .prog files are used both as input and output.
Reference: [GPMTB97] <author> Jan Gustafsson, Kjell Post, Jukka Maki-Turja, and Ellus Brorson. </author> <title> Benefits of type inference for an object-oriented real-time language. In Preprints for SNART 97, </title> <institution> Konferens om Realtidssystem, Lund, </institution> <month> 21-22 augusti </month> <year> 1997, </year> <month> August </month> <year> 1997. </year>
Reference-contexts: The resulting data includes loop bounds for loops, even with quite complex dependences. The present subset is rather small, and they do not allow global data. * Gustafsson et al <ref> [GE97, GPMTB97, RTT97] </ref> have analyzed the object-oriented RealTimeTalk language, trying to obtain information useful for wcet analysis for object-oriented programs.
Reference: [HBW94] <author> Marion G. Harmon, T. P. Baker, and David B. Whalley. </author> <title> A retargetable technique for predicting execution time of code segments. </title> <booktitle> Real-Time Systems, </booktitle> <pages> pages 159-182, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: See Figure 2.1. Knowing the the wcet of a program is useful in a number of contexts: * To perform task scheduling analysis. Most approaches to real-time scheduling assumes that the maximum execution times of the programs involved in the scheduling problem are known <ref> [HBW94] </ref>. * To check that a program meets timing constraints; an example is a feedback system where sensors deliver inputs at a regular pace, and the software has to produce output within a certain time of receiving input. * To find the most time-consuming parts of a program in order to <p> The approach is applicable to simple processors, which are often found in embedded real time systems, but gives enormous overestimations for processors employing caches or pipelines. * A more complex approach called microanalysis is described by Harmon, Baker and Whalley <ref> [HBW94] </ref>. This involves constructing a very detailed model of the processor, and essentially executing each straight segment of code on it.
Reference: [HHG + 95] <author> W. W. Hwu, R. E. Hank, D. M. Gallagher, S. A. Mahlke, D. M. Lavery, G. E. Haab, J. C. Gyllenhaal, and D. I. </author> <month> August. </month> <title> Compiler technology for future microprocessors. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 83(12) </volume> <pages> 1625-1995, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: One area where the results are useful is in memory reference analysis, where we want to figure out the addresses referred in order to model the data and instruction caches of our processor <ref> [ASU86, BGS90, HHG + 95] </ref>. * Abstract interpretation is a "a general theory for approximating the semantics of discrete dynamic systems". <p> In <ref> [HHG + 95] </ref>, they discuss the problem of maintaining information about arrays through the compilation process. They also refer to a different solution, where source level information is maintained instead of the result of the source analysis (used in the Multiflow and Cydra-5 compilers).
Reference: [HWH95] <author> C. A. Healy, D. B. Whalley, and M. G. Harmon. </author> <title> Integrating the timing analysis of pipelin-ing and instruction caching. </title> <booktitle> In Proceedings of the IEEE Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: The LLA provides raw data, but it is the the calculator which uses the information from the high level to perform the actual cache calculations. Taking caches into consideration, the pipeline behavior becomes dependent upon the cache behavior <ref> [HWH95] </ref>. Calculating execution times when caches are involved include iteration (it is usually some variant of fixed point iteration); the iteration may be localized to a separate component (a cache simulator), as done in [WMH + 97], or integrated into the general calculator [OS97]. <p> They introduce the idea of a wcta, a worst-case timing abstraction, which is a concept related to our idea about the connection between the LLA and the calculator. * Some research groups centered around Florida State University and Florida A&M University <ref> [WMH + 97, HWH95, AMWH94] </ref> have built a powerful low level tool using a static cache simulator. They handle pipeline effects, set-associative and direct-mapped instruction caches, and direct-mapped data caches. <p> In our framework, this means using the compiler to perform both the HLA and the mapping. The idea is a step on the way to co-transformation, but it is rather ad hoc and not well documented <ref> [AMWH94, HWH95, WMH + 97, LBJ + 95] </ref>. * The timing tool can co-transform the timing information: every time the compiler changes the code, an equivalent operation is performed on the timing information.
Reference: [IAR97] <institution> IAR Systems WWW homepage. </institution> <note> WWW-address: http://www.iar.se, August 1997. </note>
Reference-contexts: The debug information is then used by the timing tool. * Borjesson [Bor95]uses some special pragmas to add a wcet capability to the (commercial) IAR Systems C compiler <ref> [IAR97] </ref>. Information about loop bounds and infeasible paths can be entered. Infeasible paths are specified by declaring that two blocks of code lie on the same or different paths. * The cinderella tool [LM95, LMW96, Cin97] prompts the user to interactively provide the information required for timing analysis.
Reference: [KHR + 96] <author> L. Ko, C. Healy, E. Ratliff, R. Arnold, D. Whalley, and M.G. Harmon. </author> <title> Supporting the specification and analysis of timing constraints. </title> <booktitle> In Proceedings of the IEEE Real-Time Technology and Applications Symposium, </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: have timing information about individual source statements, in order to find the most time-consuming parts of the program and to identify culprits when programs do not fit 8 The user interface problems faced when constructing a wcet tool is very similar to those of symbolic debuggers (this is noted in <ref> [KHR + 96] </ref>). In [Ger94], Richard Gerber points out the importance of traceability between the source code and the generated assembly code in order to support debugging of real-time programs. 2.6. USER INTERFACE ISSUES 11 their timing slots. <p> Debugging optimized code requires a correspondence between optimized object code and source code, a problem similar to that faced in mapping information for wcet analysis (this is noted in <ref> [KHR + 96] </ref>). <p> The user can view information about the program on the level of functions, loops, paths, subpaths, and ranges of machine instructions. Pipeline diagrams can be invoked to show detailed information about the execution of the program <ref> [KHR + 96] </ref>. * [Coo92] presents the idea that the user interface should try to explain the changes the program has undergone.
Reference: [KN] <author> Eleftherios Koutsofios and Stephen C. </author> <title> North. Drawing Graphs with dot. </title> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, NJ. </address>
Reference-contexts: Update the execution information about the program in such a way that the it is consistent with the state of the program code and possible program executions after a transformation. 3 The .dot format is the input to the graph drawing tool Dot <ref> [Dot97, KN] </ref>, and is used to visualize the function graphs for debugging and development purposes. 5.2. OPTIMIZATION DESCRIPTION LANGUAGE (ODL) 29 To meet goal 1, we need to restructure the flow graph of the program in the same way as the compiler, giving corresponding names to basic blocks.
Reference: [Kou96] <author> Apostolos A. Kountouris. </author> <title> Safe and efficient elimination of infeasible execution paths in WCET estimation. </title> <booktitle> In Proceedings of RTCSA'96. </booktitle> <publisher> IEEE, IEEE Computer Society Press, </publisher> <year> 1996. </year>
Reference-contexts: The algorithms described are applied during the compilation of signal programs, and eliminate the need for annotations. The approach seems exact: all infeasible paths are found. The complexity is manageable thanks to the high level of abstraction in the language <ref> [Kou96] </ref>.
Reference: [LBJ + 95] <author> S.-S. Lim, Y. H. Bae, C. T. Jang, B.-D. Rhee, S. L. Min, C. Y. Park, H. Shin, K. Park, and C. S. Ki. </author> <title> An accurate worst-case timing analysis for risc processors. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(7) </volume> <pages> 593-604, </pages> <month> July </month> <year> 1995. </year> <note> Available using WWW from http://archi.snu.ac.kr/symin/ets.ps. </note>
Reference-contexts: This requires the programmer to maintain a mapping between source level and object code loops. Usually, only loop bounds can be provided. This approach is taken in <ref> [LBJ + 95, AMWH94] </ref>. As stated above in Section 3.1 (page 16), all approaches using annotations share the problem of the quality of the annotations. Annotations cannot not be trusted unless supported by some form of validation; humans do make mistakes. <p> The advantage is that very good estimates may be produced. A tool has been created which handles the Motorola 68010 and Intel 80386 processors. The approach only applies in limited ways to cached or pipelined processors. * Lim et al <ref> [LBJ + 95] </ref> describe an extension of the timing schema of Park and Shaw to handle caches and pipelines. They handle pipelines and direct-mapped instruction caches. Possible ways to handle set-associative instruction caches are described, but apparently not implemented. <p> In our framework, this means using the compiler to perform both the HLA and the mapping. The idea is a step on the way to co-transformation, but it is rather ad hoc and not well documented <ref> [AMWH94, HWH95, WMH + 97, LBJ + 95] </ref>. * The timing tool can co-transform the timing information: every time the compiler changes the code, an equivalent operation is performed on the timing information.
Reference: [LM95] <author> Yau-Tsun Steven Li and Sharad Malik. </author> <title> Performance analysis of embedded software using implicit path enumeration. </title> <booktitle> In Proceedings of the 32th Design Automation Conference, </booktitle> <pages> pages 456-461, </pages> <year> 1995. </year>
Reference-contexts: Information about loop bounds and infeasible paths can be entered. Infeasible paths are specified by declaring that two blocks of code lie on the same or different paths. * The cinderella tool <ref> [LM95, LMW96, Cin97] </ref> prompts the user to interactively provide the information required for timing analysis. The information which can be provided are loop bounds and infeasible paths. <p> The code they analyze is rather limited, containing no function calls and no loops. This simplifies the problem enough so that their Program Timing Analyzer can handle the effects of pipelining and set-associative instruction and data caches [Sta97]. * The cinderella tool from Princeton <ref> [LM95, LMW96, Cin97] </ref> implements an approach which is powerful enough to handle pipelines, set-associative instruction caches, data caches and unified caches (other approaches have assumed the data and instruction caches to be separated). They allow for set-associative data caches. <p> Furthermore, the complexity of the analysis is very high in the worst case (exponential), even though in practice most problems can be solved quickly because programs produce quite well-behaved constraint systems. The IPE approach has been used in a number of research projects <ref> [PS95, LM95] </ref>, and has been extended to handle cache and pipeline analysis [OS97, LMW96]. A good introduction is found in [PS95].
Reference: [LMW96] <author> Yau-Tsun Steven Li, Sharad Malik, and Andrew Wolfe. </author> <title> Cache modelling for real-time software: Beyond direct mapped instruction caches. </title> <booktitle> In Proceedings of the 17th IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 254-263. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1996. </year>
Reference-contexts: Information about loop bounds and infeasible paths can be entered. Infeasible paths are specified by declaring that two blocks of code lie on the same or different paths. * The cinderella tool <ref> [LM95, LMW96, Cin97] </ref> prompts the user to interactively provide the information required for timing analysis. The information which can be provided are loop bounds and infeasible paths. <p> The code they analyze is rather limited, containing no function calls and no loops. This simplifies the problem enough so that their Program Timing Analyzer can handle the effects of pipelining and set-associative instruction and data caches [Sta97]. * The cinderella tool from Princeton <ref> [LM95, LMW96, Cin97] </ref> implements an approach which is powerful enough to handle pipelines, set-associative instruction caches, data caches and unified caches (other approaches have assumed the data and instruction caches to be separated). They allow for set-associative data caches. <p> The IPE approach has been used in a number of research projects [PS95, LM95], and has been extended to handle cache and pipeline analysis <ref> [OS97, LMW96] </ref>. A good introduction is found in [PS95]. <p> Debug information is used in the York Software Engineering timing tools [For92], in the spats tool [Cha94], and by the cinderella tool <ref> [Cin97, LMW96] </ref>. 2 Using debug information in some sense amounts to avoiding the issue by transforming it into somebody else's problem: the compiler writer has to provide enough information, but nothing is said how she manages to do so.
Reference: [Mar94] <author> William Marsh. </author> <title> Formal semantics of SPARK: Static sematics. </title> <type> Technical report, </type> <institution> Praxis Critical Systems Ltd, </institution> <note> www.praxis-cs.co.uk, October 1994. BIBLIOGRAPHY 93 </note>
Reference-contexts: This information is used by the calculator to obtain a final execution time estimate, and 2 The SPARK Ada language was designed in York, and is described in <ref> [Mar94, O'N94] </ref>. 18 CHAPTER 3. A NEW WCET ANALYSIS FRAMEWORK contains information about low level effects such as execution times and memory usage.
Reference: [MG95] <author> Peter Mardwedel and Gert Goosens, </author> <title> editors. Code Generation for Embedded Processors, chapter 1. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1995. </year> <title> Chapter written by Araujo, </title> <type> Devadas, Keutzer, Liao, Malik, </type> <institution> Sudarsanam, Tijang, and Wang. </institution>
Reference-contexts: This technique is known as external pointer macros <ref> [MG95, Section 3.5] </ref>.
Reference: [Nul97] <institution> Nullstone Corporation WWW homepage. </institution> <note> Available via WWW at the address: http://www.nullstone.com/htmls/category.htm, July 1997. </note>
Reference-contexts: In this chapter, we will examine some function level transformations found in the literature, transformations for both optimization and code generation. We have used two catalogs of transformations as our main source of transformations <ref> [Nul97, BGS90] </ref>, and we have not selected transformations based on how easy they are to handle in ODL. 35 36 CHAPTER 6. <p> These optimizations are very interesting from a debugger viewpoint since they affect when, where, and in which order values are computed and instructions executed. This is an important difference in the high to low level mapping required by a timing analyzer and that required by a debugger. CSE <ref> [Nul97, ASU86] </ref> Common Subexpression Elimination. A subexpression common to two calculations (or more) is broken out and evaluated only once. Constant Folding [Nul97] Expressions with values which can be computed at compile time are replaced with the (constant) result of the expressions. For example, a=4+5*6 ! a=34. Constant Propagation [Nul97, ASU86] <p> This is an important difference in the high to low level mapping required by a timing analyzer and that required by a debugger. CSE [Nul97, ASU86] Common Subexpression Elimination. A subexpression common to two calculations (or more) is broken out and evaluated only once. Constant Folding <ref> [Nul97] </ref> Expressions with values which can be computed at compile time are replaced with the (constant) result of the expressions. For example, a=4+5*6 ! a=34. Constant Propagation [Nul97, ASU86] A constant value assigned to a variable is propagated through the flow graph and substituted at the use of the variable. <p> CSE <ref> [Nul97, ASU86] </ref> Common Subexpression Elimination. A subexpression common to two calculations (or more) is broken out and evaluated only once. Constant Folding [Nul97] Expressions with values which can be computed at compile time are replaced with the (constant) result of the expressions. For example, a=4+5*6 ! a=34. Constant Propagation [Nul97, ASU86] A constant value assigned to a variable is propagated through the flow graph and substituted at the use of the variable. Expression Simplification [Nul97] Expressions can be simplified to equivalent expressions (which are faster to execute), using mathematical equivalences. For example, i*0 ! 0, or a+5*(a+b) ! 6*a+5*b. <p> For example, a=4+5*6 ! a=34. Constant Propagation [Nul97, ASU86] A constant value assigned to a variable is propagated through the flow graph and substituted at the use of the variable. Expression Simplification <ref> [Nul97] </ref> Expressions can be simplified to equivalent expressions (which are faster to execute), using mathematical equivalences. For example, i*0 ! 0, or a+5*(a+b) ! 6*a+5*b. The integer div, mod, and mul optimizations described below can be considered special cases of expression simplification. Hoisting/Loop Invariant Code Motion [Nul97] Moving loop invariant code <p> Expression Simplification <ref> [Nul97] </ref> Expressions can be simplified to equivalent expressions (which are faster to execute), using mathematical equivalences. For example, i*0 ! 0, or a+5*(a+b) ! 6*a+5*b. The integer div, mod, and mul optimizations described below can be considered special cases of expression simplification. Hoisting/Loop Invariant Code Motion [Nul97] Moving loop invariant code out of loops, usually to before the loop. Induction Variable Elimination [Nul97] Some loops contain two or more induction variables (variables which are dependent upon the iteration count) that can be combined into one induction variable. Instruction Combination [Nul97] Combining several instructions into a single one <p> For example, i*0 ! 0, or a+5*(a+b) ! 6*a+5*b. The integer div, mod, and mul optimizations described below can be considered special cases of expression simplification. Hoisting/Loop Invariant Code Motion <ref> [Nul97] </ref> Moving loop invariant code out of loops, usually to before the loop. Induction Variable Elimination [Nul97] Some loops contain two or more induction variables (variables which are dependent upon the iteration count) that can be combined into one induction variable. Instruction Combination [Nul97] Combining several instructions into a single one with the same effect. For example, a++;a++ ! a+=2. Integer Divide, Mod, and Multiply [Nul97] Constant <p> Hoisting/Loop Invariant Code Motion <ref> [Nul97] </ref> Moving loop invariant code out of loops, usually to before the loop. Induction Variable Elimination [Nul97] Some loops contain two or more induction variables (variables which are dependent upon the iteration count) that can be combined into one induction variable. Instruction Combination [Nul97] Combining several instructions into a single one with the same effect. For example, a++;a++ ! a+=2. Integer Divide, Mod, and Multiply [Nul97] Constant integer divides, modulo operations, and multiplies can be replaced with a sequence of shifts, adds, subtracts, and logical and operations. <p> Elimination <ref> [Nul97] </ref> Some loops contain two or more induction variables (variables which are dependent upon the iteration count) that can be combined into one induction variable. Instruction Combination [Nul97] Combining several instructions into a single one with the same effect. For example, a++;a++ ! a+=2. Integer Divide, Mod, and Multiply [Nul97] Constant integer divides, modulo operations, and multiplies can be replaced with a sequence of shifts, adds, subtracts, and logical and operations. For example, x*4 ! x&lt;<2, or c%8 ! c&7. Sinking Moving code later into the instruction stream. Printf Optimization [Nul97] Replacing printf () calls with more specialized calls for <p> Integer Divide, Mod, and Multiply <ref> [Nul97] </ref> Constant integer divides, modulo operations, and multiplies can be replaced with a sequence of shifts, adds, subtracts, and logical and operations. For example, x*4 ! x&lt;<2, or c%8 ! c&7. Sinking Moving code later into the instruction stream. Printf Optimization [Nul97] Replacing printf () calls with more specialized calls for certain common cases. 6.1.2 Transformations across functions To handle transformations (usually optimizations) across functions we need to handle the movement of code and data between function instances in the program call graph, and to change the structure of the call graph. <p> These changes will affect the results of the LLA, but not the mapped information from the HLA. 6.2. IMPLEMENTING TRANSFORMATIONS IN ODL 37 Function Inlining <ref> [Nul97] </ref> Puts a copy of a function inside another function, removing the call over head. Loop Pushing [BGS90, Section 6.8.7] A loop is pushed from a calling function to a specialized version of the called function. <p> The ODL code for some transformations will be shown, but in most cases we refer to Appendix B. Block merging Block merging means merging a number of basic blocks (which are always executed in sequence) into one block. <ref> [Nul97] </ref> We handle the merge of two blocks (since larger groups of blocks can be merged in steps). Merging two blocks requires that the first block is the only predecessor to the second block, and the that the only successor to the first block is the second block. <p> The ODL code can be found in Appendix B, as Transformation B.1 (page 78). Branch elimination A branch elimination optimization shortcuts a jump (conditional or not) to an unconditional jump, replacing it by a single jump to the destination of the unconditional jump <ref> [Nul97, ASU86] </ref>. <p> The code for dead code elimination is given in Appendix B, as Transformation B.2 (page 79). If optimization If the outcome of the condition of an if-statements is known at compile time, the if can be eliminated and replaced by straight-line code <ref> [Nul97] </ref>. This is a more sophisticated variety of dead code elimination, eliminating not only the dead code but also the conditional leading up to it. Removing one alternative branch from an if-statement is quite simple.
Reference: [O'N94] <author> Ian O'Neill. </author> <title> Formal semantics of SPARK: Dynamic sematics. </title> <type> Technical report, </type> <institution> Praxis Critical Systems Ltd, </institution> <note> www.praxis-cs.co.uk, October 1994. </note>
Reference-contexts: This information is used by the calculator to obtain a final execution time estimate, and 2 The SPARK Ada language was designed in York, and is described in <ref> [Mar94, O'N94] </ref>. 18 CHAPTER 3. A NEW WCET ANALYSIS FRAMEWORK contains information about low level effects such as execution times and memory usage.
Reference: [OS97] <author> G. Ottosson and M. Sjodin. </author> <title> Worst-Case Execution Time Analysis for Modern Hardware Architectures. </title> <booktitle> In Proc. SIGPLAN 1997 Workshop on Languages, Compilers and Tools for Real-Time Systems, </booktitle> <month> June </month> <year> 1997. </year> <note> Also avaible as ASTEC Report 97/01 from the Deparment of Computer Systems, </note> <institution> Uppsala University. </institution>
Reference-contexts: Calculating execution times when caches are involved include iteration (it is usually some variant of fixed point iteration); the iteration may be localized to a separate component (a cache simulator), as done in [WMH + 97], or integrated into the general calculator <ref> [OS97] </ref>. There are several different methods of calculation used in the literature on wcet estimation. Each method has its own way of representing the program and performing the calculations. <p> The IPE approach has been used in a number of research projects [PS95, LM95], and has been extended to handle cache and pipeline analysis <ref> [OS97, LMW96] </ref>. A good introduction is found in [PS95].
Reference: [Par93] <author> Chang Yun Park. </author> <title> Predicting program execution times by analyzing static and dynamic program paths. </title> <booktitle> Real-Time Systems, </booktitle> <volume> 5(1) </volume> <pages> 31-62, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: The basic block variables are displayed on the source level. * Park and Shaw <ref> [Par93] </ref> have created a language called idl, Information Description Language, to allow the programmer to add information about infeasible paths and loop bounds to a program. <p> The tree is evaluated bottom-up, and each node contains information about the timing for a certain statement in the program. The approach requires that the executable program is well-structured 1 [Vrc94b, PS93]. * Park and Shaw <ref> [Par93] </ref> use timing schema to calculate the execution times of a program. A timing schema is a formula which describes how the execution time of a statement is composed from the execution times of its constituent statements.
Reference: [PK89] <author> Peter Puschner and Ch. Koza. </author> <title> Calculating the maximum execution time of real-time programs. </title> <journal> The Journal of Real-Time Systems, </journal> <volume> 1(1) </volume> <pages> 159-176, </pages> <year> 1989. </year>
Reference-contexts: There are a number of different flavors of annotations; the following list gives a brief overview of the approaches found in the literature: * The MARS project introduces a rich set of annotations <ref> [PK89, Vrc93, Vrc94a] </ref>, allowing for the specification of loop bounds and limits on executions of various parts of the loop body relative to the surrounding loop. The annotations are part of the language used (Modula/R), and are processed by the compiler.
Reference: [PS93] <author> Peter Puschner and Anton Schedl. </author> <title> A tool for the computation of worst case task execution times. </title> <booktitle> In Proc. of the 5:th EUROMICRO Workshop on Real-Time Systems, </booktitle> <year> 1993. </year>
Reference-contexts: This tree is used both for calculations and for presenting the result of the analysis to the user. The tree is evaluated bottom-up, and each node contains information about the timing for a certain statement in the program. The approach requires that the executable program is well-structured 1 <ref> [Vrc94b, PS93] </ref>. * Park and Shaw [Par93] use timing schema to calculate the execution times of a program. A timing schema is a formula which describes how the execution time of a statement is composed from the execution times of its constituent statements. <p> Times are displayed for individual source statements <ref> [PS93] </ref>. * The cinderella tool has a graphical user interface used to present information about the program to the user, and to prompt for information used in the analysis. Timing information is displayed per function [Cin97]. * Harmon et al has been working on user interfaces for timing tools.
Reference: [PS95] <author> Peter Puschner and Anton Schedl. </author> <title> Computing maximum task execution times with linear programming techniques. </title> <type> Technical report, </type> <institution> Technische Universitat, Institut fur Technische Informatik, Wien, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: Furthermore, the complexity of the analysis is very high in the worst case (exponential), even though in practice most problems can be solved quickly because programs produce quite well-behaved constraint systems. The IPE approach has been used in a number of research projects <ref> [PS95, LM95] </ref>, and has been extended to handle cache and pipeline analysis [OS97, LMW96]. A good introduction is found in [PS95]. <p> The IPE approach has been used in a number of research projects [PS95, LM95], and has been extended to handle cache and pipeline analysis [OS97, LMW96]. A good introduction is found in <ref> [PS95] </ref>. We consider IPE to be the best calculation device for our framework, since it makes it very easy to unify the information obtained from the HLA via the mapper with the LLA information: all information must be structured like the object code for the program.
Reference: [RTT97] <institution> RealTimeTalk Homepage at Malardalens Hogskola, Vaster-as, Sweden. </institution> <note> Available via WWW at the address: http://www.mdh.se/avdelningar/idt/forskning/cus/rtt_projekt/, August 1997. </note>
Reference-contexts: The resulting data includes loop bounds for loops, even with quite complex dependences. The present subset is rather small, and they do not allow global data. * Gustafsson et al <ref> [GE97, GPMTB97, RTT97] </ref> have analyzed the object-oriented RealTimeTalk language, trying to obtain information useful for wcet analysis for object-oriented programs.
Reference: [Sta97] <author> Friedhelm Stappert. </author> <title> Predicting pipelining and caching behaviour of hard real-time programs. </title> <booktitle> In EUROMICRO Workshop on Real-Time Systems, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: The code they analyze is rather limited, containing no function calls and no loops. This simplifies the problem enough so that their Program Timing Analyzer can handle the effects of pipelining and set-associative instruction and data caches <ref> [Sta97] </ref>. * The cinderella tool from Princeton [LM95, LMW96, Cin97] implements an approach which is powerful enough to handle pipelines, set-associative instruction caches, data caches and unified caches (other approaches have assumed the data and instruction caches to be separated). They allow for set-associative data caches.
Reference: [Vrc93] <author> Alexander Vrchoticky. </author> <title> Modula/R language definition. </title> <type> Technical Report TU Wien rr-02-92, version 2.0, </type> <institution> Dept. for Real-Time Systems, Technical University of Vienna, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: There are a number of different flavors of annotations; the following list gives a brief overview of the approaches found in the literature: * The MARS project introduces a rich set of annotations <ref> [PK89, Vrc93, Vrc94a] </ref>, allowing for the specification of loop bounds and limits on executions of various parts of the loop body relative to the surrounding loop. The annotations are part of the language used (Modula/R), and are processed by the compiler.
Reference: [Vrc94a] <author> Alexander Vrchoticky. </author> <title> The Basis for Static Execution Time Prediction. </title> <type> PhD thesis, </type> <institution> Institut fur Technische Informatik, Technische Universitat Wien, Treitlstrae 3/182.1, A-1040 Wien, Austria, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: There are a number of different flavors of annotations; the following list gives a brief overview of the approaches found in the literature: * The MARS project introduces a rich set of annotations <ref> [PK89, Vrc93, Vrc94a] </ref>, allowing for the specification of loop bounds and limits on executions of various parts of the loop body relative to the surrounding loop. The annotations are part of the language used (Modula/R), and are processed by the compiler.
Reference: [Vrc94b] <author> Alexander Vrchoticky. </author> <title> Compilation support for fine-grained execution analysis. </title> <booktitle> In ACM Sigplan Workshop on Language, Compiler and Tool Support for Real-Time Systems, </booktitle> <year> 1994. </year> <note> Available on www.cs.umd.edu/users/pugh/sigplan realtime workshop/lct-rts94/. </note>
Reference-contexts: This tree is used both for calculations and for presenting the result of the analysis to the user. The tree is evaluated bottom-up, and each node contains information about the timing for a certain statement in the program. The approach requires that the executable program is well-structured 1 <ref> [Vrc94b, PS93] </ref>. * Park and Shaw [Par93] use timing schema to calculate the execution times of a program. A timing schema is a formula which describes how the execution time of a statement is composed from the execution times of its constituent statements. <p> The introduction of such a system is expensive for the compiler writer. This approach is used in the Modula/R compiler for the MARS project, where a timing tree is processed at the same time as the code <ref> [Vrc94b] </ref>. Chung and Dietz also describe an approach where timing information is explicitly manipulated by the compiler [CD95]. We believe that the co-transformer approach is the best solution. It makes intuitive sense to send the information about the program in the same direction through the compiler as the code itself.
Reference: [Wis93] <author> Roland Wismuller. </author> <title> Source level debugging of optimized programs using data flow analysis. </title> <booktitle> In Proceedings of the ACM/ONR Workshop on Parallel and Distributed Debugging, </booktitle> <pages> pages 238-240. </pages> <publisher> ACM, </publisher> <month> May </month> <year> 1993. </year> <note> Available via WWW from http://wwwbode.informatik.tu-muenchen.de/~wismuell/publications.html </note>
Reference-contexts: USER INTERFACE ISSUES 65 He only uses one code map, from object code instructions to the corresponding source level expressions. To handle overlapped execution, the code map contains indications that several instances of a source expression may be in execution at one time. * Wismuller <ref> [Wis93, Wis94] </ref> attacks the data value problem in loops. He maintains a copy of both the source and object code flow graphs of a program, and maintains a relation called code between them.
Reference: [Wis94] <author> Roland Wismuller. </author> <title> Debugging of globally optimized programs using data flow analysis. </title> <booktitle> In Proceedings of the ACM/SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 278-289. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1994. </year> <note> Available via WWW from http://wwwbode.informatik.tu-muenchen.de/~wismuell/publications.html </note>
Reference-contexts: USER INTERFACE ISSUES 65 He only uses one code map, from object code instructions to the corresponding source level expressions. To handle overlapped execution, the code map contains indications that several instances of a source expression may be in execution at one time. * Wismuller <ref> [Wis93, Wis94] </ref> attacks the data value problem in loops. He maintains a copy of both the source and object code flow graphs of a program, and maintains a relation called code between them. <p> He maintains a copy of both the source and object code flow graphs of a program, and maintains a relation called code between them. The creation of the mapping code is never described in detail, but an example is given in <ref> [Wis94] </ref>. The mapping has two parts: nodes (instructions) to nodes, and edges to edges.
Reference: [WMH + 97] <author> R. White, F. Muller, C. Healy, D. Whalley, and M. Harmon. </author> <title> Timing analysis for data caches and set-associative caches. </title> <booktitle> In Proceedings of the IEEE Real-Time Technology and Applications Symposium, </booktitle> <pages> pages 192-202, </pages> <month> June </month> <year> 1997. </year> <note> 94 BIBLIOGRAPHY </note>
Reference-contexts: Taking caches into consideration, the pipeline behavior becomes dependent upon the cache behavior [HWH95]. Calculating execution times when caches are involved include iteration (it is usually some variant of fixed point iteration); the iteration may be localized to a separate component (a cache simulator), as done in <ref> [WMH + 97] </ref>, or integrated into the general calculator [OS97]. There are several different methods of calculation used in the literature on wcet estimation. Each method has its own way of representing the program and performing the calculations. <p> They introduce the idea of a wcta, a worst-case timing abstraction, which is a concept related to our idea about the connection between the LLA and the calculator. * Some research groups centered around Florida State University and Florida A&M University <ref> [WMH + 97, HWH95, AMWH94] </ref> have built a powerful low level tool using a static cache simulator. They handle pipeline effects, set-associative and direct-mapped instruction caches, and direct-mapped data caches. <p> In our framework, this means using the compiler to perform both the HLA and the mapping. The idea is a step on the way to co-transformation, but it is rather ad hoc and not well documented <ref> [AMWH94, HWH95, WMH + 97, LBJ + 95] </ref>. * The timing tool can co-transform the timing information: every time the compiler changes the code, an equivalent operation is performed on the timing information.
Reference: [Zel84] <author> P. T. Zellweger. </author> <title> Interactions between high-level debugging and optimised code. </title> <type> PhD thesis, </type> <institution> Computer Science Division, University of California, Berkeley, </institution> <year> 1984. </year> <note> Published as Xerox PARC Technical Report CSL-84-5. </note>
Reference-contexts: In the following, we give a brief overview of some work in the field of debugging optimized code. There are two distinct subproblems when debugging optimized code: the code location problem and the data value problem <ref> [Zel84] </ref>. The data value problem concerns the question where the value of a certain variable can be found at a certain point in the program execution, and whether this value is up-to-date. <p> are summarized in [AT96]: one mapping from object-code instructions to source-level expressions or statements (to show where a program is stopped) , and one mapping from source-level statements to object code (in order to place breakpoints). * Zellweger completed a PhD thesis about the debugging of optimized code in 1984 <ref> [Zel84] </ref>. According to Cool [Coo92], Zellweger attacks the problem of mapping source and object code to one another from the execution path perspective. She inserts hidden breakpoints into the code, and uses these to determine by which path execution has reached a certain point in the program.
References-found: 62

