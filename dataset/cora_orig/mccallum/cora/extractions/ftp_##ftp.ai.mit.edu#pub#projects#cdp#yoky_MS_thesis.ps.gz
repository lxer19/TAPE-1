URL: ftp://ftp.ai.mit.edu/pub/projects/cdp/yoky_MS_thesis.ps.gz
Refering-URL: http://www.ai.mit.edu/projects/cog/Text/publications.html
Root-URL: 
Title: Embodiment and Manipulation Learning Process for a Humanoid Hand  
Author: by Yoky Matsuoka Rodney A. Brooks 
Degree: Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Master of Science at the  Signature of Author  Certified by  Professor, Department of Electrical Engineering and Computer Science Thesis Supervisor Accepted by Frederic R. Morgenthaler Chairman, Departmental Committee on Graduate Students  
Note: c Massachusetts Institute of Technology  
Date: (1993)  May 1995  1995  May 12, 1995  
Address: Berkeley  
Affiliation: B.S., University of California,  MASSACHUSETTS INSTITUTE OF TECHNOLOGY  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Bower, T. G. R., </author> <title> "The Rational Infant: Learning in Infancy", </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <year> 1989. </year>
Reference: [2] <author> Brock, David L. Brock, and Salisbury, J. Kenneth, </author> <title> "Implementation of Behavioral Control on a Robot Hand/Arm System", </title> <year> 1991 </year>
Reference-contexts: is interfaced for higher operations such as learning and coordinating with other features such as eyes and ears. 2.2.2 Constraints Strength and Precision Many researchers have successfully created hands that are reasonably small and strong, interfaced with large forearms in order to carry many high-powered motors, precision encoders, and gears <ref> [2, 30, 31] </ref>. However, in creating a human scale model, it is crucial to minimize the weight and the size of the hand. As a trade off, increasing the strength and the precision becomes complex.
Reference: [3] <author> Brooks, Rodney A., and Stein, Lynn A., </author> <title> "Building Brains for Bodies", </title> <journal> A.I. </journal> <volume> Memo No. </volume> <pages> 1439, </pages> <address> Cambridge, MA. </address> <year> 1993. </year>
Reference-contexts: Cog At the MIT Artificial Intelligence Laboratory, a research group headed by professors Rodney A. Brooks and Lynn Andrea Stein is currently developing an integrated physical humanoid robot named Cog <ref> [3] </ref> shown in Figure 2-1. This system will include 2.1. MOTIVATION AND RELATED WORK 25 vision, sound input and output, and dextrous manipulation all controlled by a continuously operating parallel MIMD computer as the brain. The processors are 16Mhz Motorola 68332s in standard boards which plug 16 to a backplane.
Reference: [4] <author> Brooks, Rodney A., </author> <title> "L", IS Robotics, </title> <publisher> Inc., </publisher> <year> 1994. </year>
Reference-contexts: FEP and InterFEP are interfaced with a SCSI bus and InterFEP and the backplanes are interfaced through a serial port. The programming environment is based on the Macintosh and in particular runs in Macintosh Common Lisp. L, developed by Brooks <ref> [4] </ref> is a downwardly compatible subset of Common Lisp and it is run on each MIMD machine node.
Reference: [5] <author> Buekers, Martinus J., Magill, Richard A., and Sneyers, Katrien M., </author> <title> "Resolving a Conflict Between Sensory Feedback and Knowledge of Results, While Learning a Motor Skill", </title> <journal> Journal of Motor Behavior, 1994, </journal> <volume> Vol. 26, No. 1, </volume> <pages> pp. 27-35. </pages>
Reference: [6] <author> Chamberlin, Craig J., and Magill, Richard A., </author> <title> "A Note on Schema and Exemplar Approaches to Motor Skill Representation in Memory", </title> <journal> Journal of Motor Behavior, 1992, </journal> <volume> Vol. 24, No. 2, </volume> <month> pp.221-224. </month>
Reference: [7] <author> Cutkosky, Mark R., and Howe, Robert D., </author> <title> "Dextrous Robot Hands" </title>
Reference: [8] <author> Durbin, Richard, Miall, Christopher, and Mitchison, Graeme, </author> <title> "The Computing Neuron", </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1989. </year>
Reference-contexts: By applying those two trained networks, the optimal grasping action is searched by a reinforcement learning strategy (that is somewhat similar to Q-learning technique). 4.2.1 Hardness Recognition Network Theory of Competitive Learning Topologically, there is substantial evidence for the spatial self-organization of brain areas that contain sensory or motor maps <ref> [8] </ref>. For some stimuli, there is some form of competition between activities of neurons on the neural surface. The idea of competitive learning was originally proposed by Rosenblatt [29], and implemented by many [17] successfully.
Reference: [9] <author> Franklin, Gene F, Powell, J. David, and Emami-Naeini, Abbas, </author> <title> "Feedback Control of Dynamic Systems", </title> <publisher> Addison Wesley Publishing Company, </publisher> <year> 1991. </year> <note> 87 88 BIBLIOGRAPHY </note>
Reference-contexts: Equation 4.1, using Laplace Transform, the motor process can be written as Motor = K 1 : (4:2) For this system, a proportional plus integral plus derivative (PID) controller is chosen because of its ability to provide an acceptable degree of error reduction while simultaneously providing sufficient stability and damping <ref> [9] </ref>. For this system, the controller can be written as Controller = G (1 + 1 + T D s)E (4:3) 58 CHAPTER 4.
Reference: [10] <author> Goodwin, A. W., Darian-Smith, I., </author> <title> "Hand Function and the Neocortex", </title> <institution> University of Melbourne, Australia. </institution> <year> 1985. </year>
Reference: [11] <author> Greiner, Helen, </author> <title> "Passive and Active Grasping with a Prehensile Robot End-Effector", </title> <type> S.M. thesis, </type> <institution> MIT A.I. Lab, </institution> <address> Cambridge, MA. </address> <year> 1990. </year>
Reference: [12] <author> Heykin, Simon, </author> <title> "Neural Networks", </title> <publisher> Macmillan College Publishing Company, </publisher> <address> New York, NY. </address> <year> 1994. </year>
Reference: [13] <author> Hertz, John, Krogh, Anders, Palmer, Richard G., </author> <title> "Introduction to the theory of neural computation", </title> <publisher> Addison Wesley Publishing Company, </publisher> <year> 1991. </year>
Reference: [14] <editor> Jacobson S.C., et Al., </editor> <booktitle> "The Utah/MIT Dextrous Hand: Work in Progress", The first International Symposium of Robotics Research, </booktitle> <year> 1984. </year>
Reference-contexts: Their functions are mostly clamping, vacuum, and magnet which are activated by pneumatic, hydraulic, electric and mechanical force. The first dexterous mechanical hand that resembled a human hand was the Utah/MIT Dextrous Hand built about 10 years ago <ref> [14] </ref>. The hand itself was approximately anthropomorphic in size, including three tendon operated fingers and a thumb with multichannel touch sensing capability.
Reference: [15] <author> Kapogiannis, Eleni, </author> <title> "Design of a Large Scale MIMD Computer", </title> <type> M.Eng. thesis, </type> <institution> MIT A.I. Lab, </institution> <address> Cambridge, MA. </address> <year> 1994. </year>
Reference-contexts: The design is done in a way that the whole process can be expanded to 16 backplanes and each backplane consisting of 16 processing elements as shown in Figure 3-13 <ref> [15] </ref>. A commercially available Vesta SBC332 Board is used as the basic processing element, each dedicated to control a specific subsystem of the whole robot. Each board contains a Motorola MC68332 microcontroller and onboard RAM and EPROM up to 1 Mbyte each.
Reference: [16] <author> Kernodle, Michael W., and Carlton, Les G., </author> <title> "Information Feedback and the Learning of Multiple-Degree-of-Freedom Activities" Journal of Motor Behavior, </title> <booktitle> 1992, </booktitle> <volume> Vol. 24, No. 2, </volume> <month> pp.187-196. </month>
Reference: [17] <author> Kohonen, T., </author> <title> "Self-organized formation of topologically correct feature maps", </title> <booktitle> Biological Cybernetics 43, </booktitle> <address> pp.59-69, </address> <year> 1982. </year>
Reference-contexts: For some stimuli, there is some form of competition between activities of neurons on the neural surface. The idea of competitive learning was originally proposed by Rosenblatt [29], and implemented by many <ref> [17] </ref> successfully. Competitive learning contains lateral feedback, which depends on the lateral distance from the point of its application. From biological inspiration, lateral feedback is described by a Mexican hat function, shown in Figure 4-4.
Reference: [18] <author> Lambert, D., et al. </author> <title> "The brain: A user's manual", </title> <publisher> Berkley Publishing Group, </publisher> <year> 1982. </year>
Reference: [19] <author> Langreth, Robert, </author> <title> "The Bad Boy of Robotics", </title> <journal> Popular Science, </journal> <volume> pp.88 - 91, </volume> <month> June, </month> <year> 1995. </year>
Reference: [20] <author> Lin, Long-Ji, </author> <title> "Reinforcement Learning for Robots Using Neural Networks", </title> <type> Ph.D thesis, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA. </address> <year> 1992. </year> <note> BIBLIOGRAPHY 89 </note>
Reference: [21] <author> Lundstrom, G., Glemme, B., Rooks, B. W., </author> <title> "Industrial Robots-GRIPPER REVIEW", </title> <publisher> International Fluidics Services Ltd., </publisher> <year> 1979. </year>
Reference-contexts: This instinctive motivating information is triggered somewhere in the nervous system and allows explorative learning to initiate. 2.1.2 Mechanical Hand Since the eighteenth century the mechanics of hands has been studied and has been the model for various mechanical constructions, primarily for protheses and telema-nipulators, manipulators controlled remotely <ref> [21] </ref>. More recently, human hands have been analyzed for industrial mechanical grippers and many of them are used reliably in assembly settings. They are built specifically for the environment in which the grippers have to work, and they are so different for each application that a standard 2.1.
Reference: [22] <author> McCall, Robert B., </author> <title> "Exploratory Manipulation And Play In the Human Infant", Monographs: Society of research in child development, </title> <journal> Unversity of Chicago Press, </journal> <volume> No. 155, Vol. 39, </volume> <pages> No.2, </pages> <year> 1974. </year>
Reference-contexts: The advantages and disadvantages associated with building such a system are considered. 2.1 Motivation and Related Work 2.1.1 Infants Piaget was one of the first of the modern psychologists to recognize the infant's manipulative exploratory behavior with the environment as a vehicle of cognitive stimulation <ref> [22] </ref>. Infancy is not only a time when muscles and the nervous system mature, but also a time of active and continuous learning which allows a baby to establish effective transactions with the environment and move toward a greater degree of autonomy.
Reference: [23] <author> Miller, W. Thomas, Sutton, Richard S., and Werbos, Paul J., </author> <title> "Neural Networks for Control", </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA. </address> <year> 1990. </year>
Reference-contexts: It requires a nonlinear controller to respond in a nonlinear system that contains significant amount of sensory inputs and noise <ref> [23] </ref>. Investigating the human manipulation learning system and implementing it in a physical system has not been done due to its complexity and too many unknown parameters. Conventional adaptive control theory assumes too many parameters that are constantly changing in a real 2.2. EMBODIMENT OF HAND 31 environment [33, 37].
Reference: [24] <author> Napier, John Russell, </author> <title> "Hands", </title> <publisher> Pantheon Books, </publisher> <address> New York, </address> <year> 1980. </year>
Reference: [25] <author> Narendra, Kumpati S., and Mukhopadhyay, Snehasis, </author> <title> "Intelligent Control Using Neural Networks", </title> <booktitle> American Control Conference, </booktitle> <address> Boston, MA. </address> <year> 1991. </year>
Reference: [26] <author> Nolte, John, </author> <title> "The human brain", </title> <publisher> Mosby Year Book. </publisher>
Reference-contexts: Research in human cognition, formerly limited to the fields neuroscience, cognitive science, philosophy and psychology, has recently been extended to artificial intelligence where scientists attempt to recreate what is not known yet to our species. In adults, almost 1 million motor neurons control our muscles <ref> [26] </ref>, enabling an enormous range of complex activities. The primary motor cortex is known to be active when the body movements are detected. As shown in the somatotopic maps in cortex are responsible for representing the fingers and the hand.
Reference: [27] <author> Rabelo, Luis C., and Avula, Xavier J. R., </author> <title> "Nierarchical Neurocontroller Architecture for Robotic Manipulation", </title> <booktitle> IEEE International Conference on Robotics and Automation, </booktitle> <address> Sacramento, CA. </address> <year> 1991. </year>
Reference: [28] <author> Rader, N., Sstern, J.D., </author> <title> "Visually elicited reaching in neonatates", Chile Development, </title> <address> 53:1004 - 1007. </address> <year> 1982. </year>
Reference-contexts: Visual feedback is a crucial piece in manipulation learning as seen in the infants of a few days old extending their hands toward a visible object <ref> [28] </ref>. This instinctive motivating information is triggered somewhere in the nervous system and allows explorative learning to initiate. 2.1.2 Mechanical Hand Since the eighteenth century the mechanics of hands has been studied and has been the model for various mechanical constructions, primarily for protheses and telema-nipulators, manipulators controlled remotely [21].
Reference: [29] <author> Rosenblatt, F., </author> <title> "The Perceptron: A probabilistic model for information storage and organization in the brain", </title> <journal> Psychological Review 65, </journal> <volume> pp.386-408, </volume> <year> 1958. </year>
Reference-contexts: For some stimuli, there is some form of competition between activities of neurons on the neural surface. The idea of competitive learning was originally proposed by Rosenblatt <ref> [29] </ref>, and implemented by many [17] successfully. Competitive learning contains lateral feedback, which depends on the lateral distance from the point of its application. From biological inspiration, lateral feedback is described by a Mexican hat function, shown in Figure 4-4.
Reference: [30] <author> Salisbury, J. Kenneth, and Craig, John J., </author> <title> "Articulated Hands: Force Control and Kinematic Issues", </title> <journal> International Journal of Robotics Research, 1982, </journal> <volume> Vol. 1, No. </volume> <pages> 1. </pages>
Reference-contexts: is interfaced for higher operations such as learning and coordinating with other features such as eyes and ears. 2.2.2 Constraints Strength and Precision Many researchers have successfully created hands that are reasonably small and strong, interfaced with large forearms in order to carry many high-powered motors, precision encoders, and gears <ref> [2, 30, 31] </ref>. However, in creating a human scale model, it is crucial to minimize the weight and the size of the hand. As a trade off, increasing the strength and the precision becomes complex. <p> For the humanoid hand, a three finger with a thumb configuration is used to reinforce the stability for various shaped object manipulation <ref> [30] </ref>. For example, the last finger can be used as the base to hold a small object. Young infants do not use the thumb as an opposing finger, and use all fingers like a one degree of freedom compliant gripper.
Reference: [31] <author> Salisbury, J. K., </author> <title> "Kinematic and Force Analysis of Articulated Hands", </title> <type> Ph.D Thesis, </type> <institution> Stanford University Mechanical Engineering and Computer Science Dept., Stanford, </institution> <address> CA, </address> <year> 1982. </year> <note> 90 BIBLIOGRAPHY </note>
Reference-contexts: is interfaced for higher operations such as learning and coordinating with other features such as eyes and ears. 2.2.2 Constraints Strength and Precision Many researchers have successfully created hands that are reasonably small and strong, interfaced with large forearms in order to carry many high-powered motors, precision encoders, and gears <ref> [2, 30, 31] </ref>. However, in creating a human scale model, it is crucial to minimize the weight and the size of the hand. As a trade off, increasing the strength and the precision becomes complex.
Reference: [32] <author> Shirane, Reikichi, </author> <title> "Tsukuba kagakuhaku to Nihon no kagaku gijutsu", </title> <journal> Journal of the Robotics Society of Japan, </journal> <volume> vol. 4, no. 4, p.42. </volume> <year> 1985. </year>
Reference-contexts: Later there were explicit attempts to make robots anthropomorphical in appearance and capabilities. Wabot was exhibited at the Japanese Expo in 1985 and it played a piano, with its precise and fast finger works <ref> [32] </ref>. It had a human appearance and if examined briefly, it could visually fool people that it had a cognitive system. Though this robot design was inspired by the human hand motor system, it was not practical in any sense of the word.
Reference: [33] <author> Sutton, Richard S., Barto, Andrew G., and Williams, Ronald J., </author> <title> "Reinforcement Learning is Direct Adaptice Optimal Control", </title> <booktitle> American Control Conference, </booktitle> <address> Boston, MA. </address> <year> 1991. </year> <title> [34] von Hofsten, Claes, "Structuring of Early Reaching Movements: A Longitudinal Study", </title> <journal> Journal of Motor Behavior, </journal> <volume> Vol. 23, No. 4, pp.280-292, </volume> <year> 1991. </year>
Reference-contexts: Investigating the human manipulation learning system and implementing it in a physical system has not been done due to its complexity and too many unknown parameters. Conventional adaptive control theory assumes too many parameters that are constantly changing in a real 2.2. EMBODIMENT OF HAND 31 environment <ref> [33, 37] </ref>. For an embodied hand, even the simplest form of learning process requires more intelligent control network. Wiener [36] has proposed the idea of "Connectionism", which suggests that a muscle is controlled by affecting the gain of the "efferent-nerve muscle- kinesthetic-end-body afferent nerve - central-spinal-synapse - efferent-nerve" loop. <p> HIGH LEVEL NEURAL NETWORKS 75 4.2.3 Grasping Action Network Theory of Reinforcement Learning Reinforcement learning is based on a common sense idea that if an action is followed by a satisfactory state of affairs, then the tendency to produce that action is strengthened <ref> [33] </ref>. This idea was initially studied in psychology by Pavlov in learning work with animals. In neural networks, the studies are focused on actor-critic learning algorithm or Q-learning, both based on the temporal difference method [33, 35, 37]. <p> This idea was initially studied in psychology by Pavlov in learning work with animals. In neural networks, the studies are focused on actor-critic learning algorithm or Q-learning, both based on the temporal difference method <ref> [33, 35, 37] </ref>. An actor-critic system has two subsystems, one is an evaluation network which estimates the long term utility for each state and the other is a policy network which learn to choose the optimal action in each state.
Reference: [35] <author> Watkins, C.J.C.H., </author> <title> "Learning from Delayed Rewards", </title> <type> Ph.D thesis, </type> <institution> King's College, </institution> <address> Cambridge, </address> <year> 1989. </year>
Reference-contexts: This idea was initially studied in psychology by Pavlov in learning work with animals. In neural networks, the studies are focused on actor-critic learning algorithm or Q-learning, both based on the temporal difference method <ref> [33, 35, 37] </ref>. An actor-critic system has two subsystems, one is an evaluation network which estimates the long term utility for each state and the other is a policy network which learn to choose the optimal action in each state. <p> A gain sequence has a characteristic such that 0 &lt; fi n &lt; 1, P 1 P 1 n &lt; 1. Q-learning has been proven to converge at all time <ref> [35] </ref>. 76 CHAPTER 4.
Reference: [36] <author> Wiener, N., </author> <booktitle> "Cybernetics", </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1948. </year>
Reference-contexts: Conventional adaptive control theory assumes too many parameters that are constantly changing in a real 2.2. EMBODIMENT OF HAND 31 environment [33, 37]. For an embodied hand, even the simplest form of learning process requires more intelligent control network. Wiener <ref> [36] </ref> has proposed the idea of "Connectionism", which suggests that a muscle is controlled by affecting the gain of the "efferent-nerve muscle- kinesthetic-end-body afferent nerve - central-spinal-synapse - efferent-nerve" loop. Each system within the loop such as efferent nerve contains its own feedback loop system.
Reference: [37] <author> Williams, Ronald J., </author> <title> "One the Use of Backpropagation in Associative Reinforcement Learning", </title> <booktitle> IEEE International Conference on Neural Networks, </booktitle> <year> 1988. </year>
Reference-contexts: Investigating the human manipulation learning system and implementing it in a physical system has not been done due to its complexity and too many unknown parameters. Conventional adaptive control theory assumes too many parameters that are constantly changing in a real 2.2. EMBODIMENT OF HAND 31 environment <ref> [33, 37] </ref>. For an embodied hand, even the simplest form of learning process requires more intelligent control network. Wiener [36] has proposed the idea of "Connectionism", which suggests that a muscle is controlled by affecting the gain of the "efferent-nerve muscle- kinesthetic-end-body afferent nerve - central-spinal-synapse - efferent-nerve" loop. <p> This idea was initially studied in psychology by Pavlov in learning work with animals. In neural networks, the studies are focused on actor-critic learning algorithm or Q-learning, both based on the temporal difference method <ref> [33, 35, 37] </ref>. An actor-critic system has two subsystems, one is an evaluation network which estimates the long term utility for each state and the other is a policy network which learn to choose the optimal action in each state.
References-found: 36

