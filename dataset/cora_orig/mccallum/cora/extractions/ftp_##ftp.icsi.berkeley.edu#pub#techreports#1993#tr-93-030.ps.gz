URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1993/tr-93-030.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1993.html
Root-URL: http://www.icsi.berkeley.edu
Email: E-mail: bernasconi@iei.pi.cnr.it  E-mail: brunoc@icsi.berkeley.edu  codenotti@iei.pi.cnr.it  
Title: Sensitivity of Boolean Functions,  
Author: Bernasconi B. Codenotti 
Web: or  
Address: Pisa (Italy).  
Affiliation: Istituto di Elaborazione dell'Informazione, Consiglio Nazionale delle Ricerche, Pisa (Italy).  International Computer Science Institute, Berkeley CA, and Istituto di Elaborazione dell'In-formazione, Consiglio Nazionale delle Ricerche,  
Date: June 1993  
Note: A.  Supported by the Consorzio Pisa Ricerche.  
Pubnum: TR-93-030  
Abstract: Harmonic Analysis, and Abstract We exploit the notion of sensitivity of Boolean functions to find complexity results. We first analyze the distribution of the average sensitivity over the set of all the n-ary Boolean functions, and show some applications of this analysis. We then use harmonic analysis on the cube to study how the average sensitivity of a Boolean function propagates if the function corresponds, e.g., to an oracle available to compute another function. To do this, we analyze the sensitivity of the composition of Boolean functions. We find the relation existing between a complexity measure for symmetric functions introduced in [FKPS 85] and the average sensitivity. We use this relation to prove that symmetric functions in AC 0 have exponentially decreasing average sensitivity. This is, in the special case of symmetric functions, a substantial improvement over the characterization given in [LMN 89]. fl This work has been partly supported by the Italian National Research Council, under the "Pro-getto Finalizzato Sistemi Informatici e Calcolo Parallelo", subproject 2 "Processori dedicati".
Abstract-found: 1
Intro-found: 1
Reference: [ABCG 93] <author> S. Ar, M. Blum, B. Codenotti, P. </author> <title> Gemmell. Checking Approximate Computations over the Reals. </title> <booktitle> Proc. 25th STOC (1993), </booktitle> <address> pp.786-795. </address>
Reference-contexts: The influence of sensitivity on the efficiency of computational tasks has been studied in other areas, like, e.g., parallelism [CLR 93], dynamization [EGIN 92], and program checking <ref> [ABCG 93] </ref>. We believe that more general results are to come, expecially for what concerns the interplay between parallel complexity and sensitivity. 19
Reference: [BL 89] <author> M. Ben Or, N. Linial. </author> <title> Collective Coin Flipping. </title> <booktitle> In Advances in Computing Research Randomness and Computation, </booktitle> <volume> Vol. 5, </volume> <publisher> JAI Press (1989), pp.91-115. </publisher>
Reference-contexts: In addition, they relate the average sensitivity of functions to their Fourier coefficients. However this relation was already implicit from the work of [HMM 82]. Ben-Or and Linial <ref> [BL 89] </ref> study collective coin flipping, 1 where the collective coin is viewed as a Boolean function.
Reference: [Bop 89] <author> R. B. Boppana. </author> <title> Amplification of Probabilistic Boolean Formulas. </title> <booktitle> In Advances in Computing Research Randomness and Computation, </booktitle> <volume> Vol. 5, </volume> <publisher> JAI Press (1989), pp.27-46. </publisher>
Reference-contexts: We then apply this notion to evaluate the sensitivity of functions computable by read-once formulas. We also show the natural connection between the notion of on-line sensitivity and the technique of amplification of Boolean formulas see <ref> [Bop 89] </ref>, [DZ 92] for an introduction to this topic and for relevant results.
Reference: [BOH 90] <author> Y. Brandman, A. Orlitsky, J. Hennessy. </author> <title> A Spectral Lower Bound Technique for the Size of Decision Trees and Two-Level AND/OR Circuits. </title> <journal> IEEE Trans. on Computers Vol. </journal> <volume> 39 (2) (1990), </volume> <month> pp.282-287. </month>
Reference-contexts: Karpovsky [Kar 76] proposes to use the number of nonvanishing Fourier coefficients of a Boolean function f as a measure of its complexity. Hurst et al. [HMM 82] relate the circuit complexity of a Boolean function to its power spectrum coefficients. Brandman et al. <ref> [BOH 90] </ref> establish a relationship between the Fourier coefficients of a Boolean function f and (i) the average size of any decision tree for f ; (ii) the minimum number of ^ gates in a circuit computing f according to its disjuntive normal form. <p> D (OR) functions, and if the fan-in of the ^ (_) gates is of order n, then s (h) = O (c (n) n 2 n ), where c (n) is the number of ^ (_) gates, from which c (n) = ( 2 n n s (h)). (See also <ref> [BOH 90] </ref> for another bound on c (n).) Thus the notion of sensitivity explains why some functions can not be computed by circuits with polynomial size and small depth. Other applications will be shown in the full paper. We consider now the upper bound of Theorem 9. <p> Using a different terminology which refers to the notions of entropy and information content, the same lower bound was proved in <ref> [BOH 90] </ref>. We first give a Lemma that links sensitivity to adjacency [Sub 90] and then a Lemma that states a property of the MAJ ORIT Y function. Lemma 14 Let f and h be two Boolean functions over f0 ; 1g n .
Reference: [Bru 90] <author> J. Bruck. </author> <title> Harmonic Analysis of Polynomial Threshold Functions. </title> <note> SIAM Journal on Discrete Mathematics Vol. 3 (1990), pp.168-177. </note>
Reference-contexts: Linial et al. [LMN 89] take advantage of the relation between the average sensitivity of Boolean functions and their Fourier transform to prove several facts, e.g., that sets in AC 0 have low average sensitivity. Bruck <ref> [Bru 90] </ref> and Bruck and Smolensky [BS 92] use abstract harmonic analysis to derive necessary and sufficient conditions for a Boolean function to be a polynomial threshold. 1.2 Results of this paper We first analyze the distribution of the average sensitivity and show that almost all n-ary Boolean functions have average
Reference: [BS 92] <author> J. Bruck, R. Smolensky. </author> <title> Polynomial Threshold Functions, AC 0 Functions, and Spectral Norms. </title> <note> SIAM Journal on Computing Vol. 21(1) (1992), pp.33-42. </note>
Reference-contexts: Linial et al. [LMN 89] take advantage of the relation between the average sensitivity of Boolean functions and their Fourier transform to prove several facts, e.g., that sets in AC 0 have low average sensitivity. Bruck [Bru 90] and Bruck and Smolensky <ref> [BS 92] </ref> use abstract harmonic analysis to derive necessary and sufficient conditions for a Boolean function to be a polynomial threshold. 1.2 Results of this paper We first analyze the distribution of the average sensitivity and show that almost all n-ary Boolean functions have average sensitivity in the vicinity of n
Reference: [CK 91] <author> P. Clote, E. Kranakis. </author> <title> Boolean Functions, Invariance Groups, and Parallel Complexity. </title> <note> SIAM Journal on Computing Vol. 20(3) (1991), pp.553-590. </note>
Reference-contexts: Then we find some interesting relations between a measure of complexity for symmetric functions defined in [FKPS 85] and the average sensitivity. These relationships allow us to use a result of <ref> [CK 91] </ref> for proving that the average sensitivity of symmetric functions and, more in general, of functions with polynomial index in AC 0 decreases exponentially.
Reference: [CLR 93] <author> B. Codenotti, M. Leoncini, G. Resta. </author> <title> Oracle Computations in Parallel Numerical Linear Algebra. </title> <note> Theoretical Computer Science, to appear (1993). </note>
Reference-contexts: The influence of sensitivity on the efficiency of computational tasks has been studied in other areas, like, e.g., parallelism <ref> [CLR 93] </ref>, dynamization [EGIN 92], and program checking [ABCG 93]. We believe that more general results are to come, expecially for what concerns the interplay between parallel complexity and sensitivity. 19
Reference: [DZ 92] <author> M. Dubiner, U. Zwick. </author> <title> Amplification and Percolation. </title> <booktitle> Proc. 33rd FOCS (1992), </booktitle> <address> pp.258-267. </address>
Reference-contexts: We then apply this notion to evaluate the sensitivity of functions computable by read-once formulas. We also show the natural connection between the notion of on-line sensitivity and the technique of amplification of Boolean formulas see [Bop 89], <ref> [DZ 92] </ref> for an introduction to this topic and for relevant results.
Reference: [EGIN 92] <author> D. Eppstein, Z. Galil, G.F. Italiano, A. Nissenzweig. </author> <title> Sparsification A Technique for Speeding up Dynamic Graph Algorithms. </title> <booktitle> Proc. 33rd FOCS (1992), </booktitle> <address> pp.60-69. </address>
Reference-contexts: The influence of sensitivity on the efficiency of computational tasks has been studied in other areas, like, e.g., parallelism [CLR 93], dynamization <ref> [EGIN 92] </ref>, and program checking [ABCG 93]. We believe that more general results are to come, expecially for what concerns the interplay between parallel complexity and sensitivity. 19
Reference: [FKPS 85] <author> R. Fagin, M.M. Klawe, N.J. Pippenger, L. Stockmeyer. Bounded-Depth, </author> <title> Polynomial Size Circuits for Symmetric Functions. </title> <note> Theoretical Computer Science Vol. 36 (1985), pp.239-250. </note>
Reference-contexts: We find the relation existing between a complexity measure for symmetric functions introduced by <ref> [FKPS 85] </ref> and the average sensitivity (see Lemma 11 in Section 5). We use this relation to prove that the average sensitivity of symmetric functions in AC 0 decreases exponentially (see Theorem 12 in Section 5). <p> This fact is the basis for showing that low average sensitivity is a structural property of sets which generalizes sparsity in a natural way. Then we find some interesting relations between a measure of complexity for symmetric functions defined in <ref> [FKPS 85] </ref> and the average sensitivity. These relationships allow us to use a result of [CK 91] for proving that the average sensitivity of symmetric functions and, more in general, of functions with polynomial index in AC 0 decreases exponentially. <p> The proof for almost sparse or almost co-sparse sets is similar. From now on in this section f will be a symmetric Boolean function. We recall some definitions from <ref> [FKPS 85] </ref>. The minimum number of variables of f that have to be set to constant values so that f becomes a constant function is called measure of f and is denoted by (f ). <p> A subword of the spectrum is a string of the form w i w i+1 : : : w i+k . <ref> [FKPS 85] </ref> show that (f ) can be easily evaluated from the spectrum because (f ) = n + 1 , where is the length of the longest constant subword of w. 12 Lemma 11 Let f be a symmetric Boolean function defined on f0 ; 1g n with measure (f <p> Then s (f ) = O (2 n+polylog n ), and this is equivalent to saying that f is the characteristic function of an almost sparse or almost co-sparse language. Proof A consequence of Lemma 11, together with the characterization of <ref> [FKPS 85] </ref>, is that symmetric functions in AC 0 have exponentially decreasing average sensitivity.
Reference: [HMM 82] <author> S.L. Hurst, D.M. Miller, </author> <title> J.C. Muzio. Spectral Method of Boolean Function Complexity. </title> <journal> Electronics Letters Vol. </journal> <volume> 18 (33) (1982), </volume> <month> pp.572-574. </month>
Reference-contexts: It turns out that the Boolean difference allows to define both influence and sensitivity. Karpovsky [Kar 76] proposes to use the number of nonvanishing Fourier coefficients of a Boolean function f as a measure of its complexity. Hurst et al. <ref> [HMM 82] </ref> relate the circuit complexity of a Boolean function to its power spectrum coefficients. <p> Kahan et al. [KKL 88] find connections between influence and harmonic analysis and use theorems on influence to prove results on rapidly mixing Markov chains. In addition, they relate the average sensitivity of functions to their Fourier coefficients. However this relation was already implicit from the work of <ref> [HMM 82] </ref>. Ben-Or and Linial [BL 89] study collective coin flipping, 1 where the collective coin is viewed as a Boolean function. <p> In section 7 we provide a framework for future research. 3 2 Abstract harmonic analysis and sensitivity In this section we give some background on abstract harmonic analysis. Our main sources are [Leh 71] and [Loo 53]. Then we show, using a simple derivation based on <ref> [HMM 82] </ref>, the relation between Fourier coefficients and sensitivity. At the end of the section we take into account the special cases of symmetric and monotone functions. Let us consider the space F of all the two-valued functions on f0 ; 1g n . <p> Sometimes we will use the terminology sensitivity of a set as a shortcut for sen sitivity of the characteristic function of the elements of length n of a set. By using the approach of <ref> [HMM 82] </ref>, we now show the connection between average sensitiv ity and Fourier coefficients. We take advantage of two identities, i.e.
Reference: [KKL 88] <author> J. Kahn, G. Kalai, N. Linial. </author> <title> The Influence of Variables on Boolean Functions. </title> <booktitle> Proc. 29th FOCS (1988), pp.68-80. </booktitle> <pages> 20 </pages>
Reference-contexts: Kahan et al. <ref> [KKL 88] </ref> find connections between influence and harmonic analysis and use theorems on influence to prove results on rapidly mixing Markov chains. In addition, they relate the average sensitivity of functions to their Fourier coefficients. However this relation was already implicit from the work of [HMM 82]. <p> Symmetric Functions. Let w be a binary string of length n. f fl (w) = 2 n k=0 X (1) w T x ; s (f ) = 4n i=1 n 1 ! f fl 2 Monotone Functions. The n coefficients which are sufficient to determine the sensitivity <ref> [KKL 88] </ref> can be computed as f fl = 2 n ^ H n f , where ^ H n is an n fi 2 n matrix defined as ^ H 1 = 1 1 ; ^ H k = ^ H k1 ^ H k1 ! where v i =
Reference: [Kar 76] <author> M.G. Karpovsky. </author> <title> Finite Orthogonal Series in the Design of Digital Devices. </title> <publisher> John Wiley and Son, </publisher> <address> New York (1976). </address>
Reference-contexts: It turns out that the Boolean difference allows to define both influence and sensitivity. Karpovsky <ref> [Kar 76] </ref> proposes to use the number of nonvanishing Fourier coefficients of a Boolean function f as a measure of its complexity. Hurst et al. [HMM 82] relate the circuit complexity of a Boolean function to its power spectrum coefficients.
Reference: [Leh 71] <author> R. J. Lechner. </author> <title> Harmonic Analysis of Switching Functions. In Recent Development in Switching Theory, </title> <publisher> Academic Press (1971), pp.122-229. </publisher>
Reference-contexts: The nature of this transformation makes the Fourier coefficients informative about the regularities of the function, and thus about its computational complexity. This fact was well known since the early ages of switching function theory. In a review article of 1971 <ref> [Leh 71] </ref>, Robert Lechner says that "The representation of a switching functions as an n-dimensional abstract Fourier transform over the finite two-element field (...) has many valuable properties. <p> In section 7 we provide a framework for future research. 3 2 Abstract harmonic analysis and sensitivity In this section we give some background on abstract harmonic analysis. Our main sources are <ref> [Leh 71] </ref> and [Loo 53]. Then we show, using a simple derivation based on [HMM 82], the relation between Fourier coefficients and sensitivity. At the end of the section we take into account the special cases of symmetric and monotone functions. <p> Note that the matrix H n is the Hadamard symmetric transform matrix <ref> [Leh 71] </ref> and can be recursively defined as H 1 = 1 1 ! H n1 H n1 : We give now an interpretation to the Fourier coefficients. The coefficient f fl 0 is the probability that f takes the value 1. <p> In fact sAC 0 ACC. In addition, we can use Theorems 2.2 and 2.8 in <ref> [Leh 71] </ref>, to prove that, if g = f P ARIT Y , then g fl (w) = 1 2 ffi w;0 1 2 ffi wu;0 + f fl (w u), where u is the vector whose entries are all equal to 1, and ffi i;j is the Kronecker delta function. <p> From the fact that p m (w) = w T a (mod 2), where a T = [ 1 ; 1 ; : : : ; 1 ; 0 ; : : : ; 0 ], some algebra and the application of Theorem 2.8 in <ref> [Leh 71] </ref> yield g fl (w 1 ; : : : ; w n ) = f fl ( w 1 ; : : : ; w m ; w m+1 ; : : : ; w n ), for w 6= 0 and w 6= a, and g fl (0) <p> It remains to prove that the functions with exponentially low average sensitivity are the characteristic functions of a sparse or co-sparse set. From Parseval's identity <ref> [Leh 71] </ref> and from the definition of f fl 0 we obtain p = P i ) 2 and 0 .
Reference: [LMN 89] <author> N. Linial, Y. Mansour, N. Nisan. </author> <title> Constant Depth Circuits, Fourier Transform, and Learnability. </title> <booktitle> Proc. 30th FOCS (1989), </booktitle> <address> pp.574-579. </address>
Reference-contexts: Linial et al. <ref> [LMN 89] </ref> take advantage of the relation between the average sensitivity of Boolean functions and their Fourier transform to prove several facts, e.g., that sets in AC 0 have low average sensitivity. <p> We use this relation to prove that the average sensitivity of symmetric functions in AC 0 decreases exponentially (see Theorem 12 in Section 5). This is, in the special case of symmetric functions, a substantial improvement over the characterization given in <ref> [LMN 89] </ref>. We also prove that a family of Boolean functions has exponentially decreasing sensitivity if and only if the associated set is almost sparse or co-sparse. This allows us to conclude that sets in AC 0 whose characteristic function is symmetric are almost sparse or co-sparse. <p> Since Boolean functions in AC 0 have average sensitivity s (f ) log O (1) n <ref> [LMN 89] </ref>, we can use Theorem 5 to prove that 2 2 n n2 n 1 + 4 log O (1) n is an upper bound to the number of functions in AC 0 . 8 The proof of Lemma 3 suggests to define the complexity classes pAC 0 (parity AC
Reference: [Lit 40] <author> D. Littlewood. </author> <title> The Theory of Group Characters and the Matrix Representation of Groups. </title> <publisher> Oxford University Press, </publisher> <address> London (1940). </address>
Reference-contexts: The functions Q w (x) = (1) w 1 x 1 (1) w 2 x 2 : : : (1) w n x n = (1) w T x are known as group characters or Fourier transform kernel functions <ref> [Lit 40] </ref>. The set of functions fQ w jw 2 f0 ; 1g n g is an orthogonal basis for F .
Reference: [Loo 53] <author> L.M. Loomis. </author> <title> An Introduction to Abstract Harmonic Analysis. </title> <publisher> Van Nos-trand, </publisher> <address> Princeton, New Jersey (1953). </address>
Reference-contexts: In section 7 we provide a framework for future research. 3 2 Abstract harmonic analysis and sensitivity In this section we give some background on abstract harmonic analysis. Our main sources are [Leh 71] and <ref> [Loo 53] </ref>. Then we show, using a simple derivation based on [HMM 82], the relation between Fourier coefficients and sensitivity. At the end of the section we take into account the special cases of symmetric and monotone functions.
Reference: [SHB 68] <author> F. Sellers, M.Y. Hsiao, L.W. Bearnson. </author> <title> Error Detecting Logic for Digital Computers. </title> <publisher> McGraw Hill (1968). </publisher>
Reference-contexts: Since the sum of the influences of all the variables defines the average sensitivity, Fourier analysis can be used to determine how much a function is sensitive to its arguments. Chapter 2 in <ref> [SHB 68] </ref> is dedicated to the description of some mathematical background on error detection in digital machines.
Reference: [SV 81] <author> S. Skyum, L.G. Valiant. </author> <title> A Complexity Theory Based on Boolean Algebra. </title> <booktitle> Proc. 22nd FOCS (1981), </booktitle> <address> pp.244-253. </address>
Reference-contexts: The notion of projection reducibility was studied in <ref> [SV 81] </ref>. Lemma 16 Let f be a set and ff i ; i = 1; : : :g be the set of Boolean functions representing it. <p> Proof Follows from the fact that g pj f implies s (g) s max (f). <ref> [SV 81] </ref> proved that M AJ ORIT Y is not complete for the class NC 1 under reduction by projections. Lemma 16 allows us to find another proof of this fact. 15 Corollary 17 MAJ ORIT Y is not complete for the class NC 1 under reduction by projections.
Reference: [Sub 90] <author> A. Subramanian. </author> <title> The Computational Complexity of the Circuit Value and Network Stability Problems. </title> <type> PhD Thesis, Tech. Report No. </type> <institution> STAN-CS-90-1311, Stanford University (1990). </institution>
Reference-contexts: Using a different terminology which refers to the notions of entropy and information content, the same lower bound was proved in [BOH 90]. We first give a Lemma that links sensitivity to adjacency <ref> [Sub 90] </ref> and then a Lemma that states a property of the MAJ ORIT Y function. Lemma 14 Let f and h be two Boolean functions over f0 ; 1g n .
Reference: [WWY 92] <author> I. Wegener, N. Wurm, S.Z. Yi. </author> <title> Symmetric Functions in AC 0 can be Computed in Constant Depth with Very Small Size. In "Boolean Function Complexity", Edited by M.S. Paterson, </title> <publisher> Cambridge University Press (1992), pp.129-139. </publisher>
Reference-contexts: This confirms the intuition that almost all the 2 n sym metric functions of n variables are in N C 1 AC 0 . The result of Theorem 12, together 2 with the characterization of <ref> [WWY 92] </ref>, give a very clear picture of the very simple structure of symmetric functions in AC 0 . We show that sets with a given sensitivity can not be complete in N C 1 under certain special reductions. <p> Corollary 13 The number of symmetric functions of n variables which are com putable by polynomial size constant depth circuits is of order n polylogn . Proof The upper bound follows from Theorem 1 in <ref> [WWY 92] </ref> and standard counting arguments. The lower bound is obtained by counting the number of functions for which (f ) = O (polylog n). 6 Applications In this section we present some applications of the results of section 4 and we study some special cases.
References-found: 22

