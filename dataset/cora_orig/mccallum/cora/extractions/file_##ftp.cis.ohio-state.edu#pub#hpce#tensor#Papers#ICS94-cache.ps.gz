URL: file://ftp.cis.ohio-state.edu/pub/hpce/tensor/Papers/ICS94-cache.ps.gz
Refering-URL: http://www.cis.ohio-state.edu/~chh/Publication/tensor-papers.html
Root-URL: 
Phone: 2  
Title: An Algebraic Approach to Cache Memory Characterization for Block Recursive Algorithms  
Author: B. Kumar C.-H. Huang P. Sadayappan R. W. Johnson 
Address: Columbus, OH 43210  St. Cloud, MN 56301  
Affiliation: 1 The Ohio State University,  St. Cloud State University,  
Abstract: Multiprocessor systems usually have cache or local memory in the memory hierarchy. Obtaining good performance on these systems requires that a program utilizes the cache efficiently. In this paper, we address the issue of generating efficient cache based algorithms from tensor product formulas. Tensor product formulas have been used for expressing block recursive algorithms like Strassen's matrix multiplication and fast Fourier transforms. These formulas can be translated into efficient parallel programs for shared and distributed memory multiprocessors. We analyze the utilization of a set associative cache for programs generated from tensor product formulas. Simulation results are shown to be consistent with the analysis. Strategies are presented to algebraically transform a formula such that the resulting program has a better cache utilization. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Callahan, K. Kennedy, and A. Porterfield. </author> <booktitle> Software prefetch-ing. Fourth international conference on architectural support for programming languages and operating systems, </booktitle> <pages> pages 40-52, </pages> <month> Apr. </month> <year> 1991. </year>
Reference-contexts: A number of program transformations can be performed to improve data locality [8]. Certain transformations such as loop fusion may result in better temporal locality, and others such as blocking [5] may improve spatial locality. Other methods have been considered to improve cache performance, such as data prefetching <ref> [1] </ref>, partitioning the iteration set into groups that reuse data [2], and managing reference windows that reflect the elements to be kept in the fl This work was supported in part by ARPA, order number 7898, monitored by NIST under grant number 60NANB1D1151, and ARPA, order number 7899, monitored by NIST
Reference: [2] <author> J. Fang and M. Lu. </author> <title> An iteration partition approach for cache and local memory thrashing on parallel processing. </title> <booktitle> Languages and compilers for parallel computing, </booktitle> <pages> pages 313-327, </pages> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: Certain transformations such as loop fusion may result in better temporal locality, and others such as blocking [5] may improve spatial locality. Other methods have been considered to improve cache performance, such as data prefetching [1], partitioning the iteration set into groups that reuse data <ref> [2] </ref>, and managing reference windows that reflect the elements to be kept in the fl This work was supported in part by ARPA, order number 7898, monitored by NIST under grant number 60NANB1D1151, and ARPA, order number 7899, monitored by NIST under grant number 60NANB1D1150. cache [3].
Reference: [3] <author> D. Gannon, W. Jalby, and K. Gallivan. </author> <title> Strategies for cache and local memory management by global program transformations. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 587-616, </pages> <year> 1988. </year>
Reference-contexts: groups that reuse data [2], and managing reference windows that reflect the elements to be kept in the fl This work was supported in part by ARPA, order number 7898, monitored by NIST under grant number 60NANB1D1151, and ARPA, order number 7899, monitored by NIST under grant number 60NANB1D1150. cache <ref> [3] </ref>. All these methods attempt to find regular patterns of access of array elements and utilize them to guide the transformations. In this paper, we present a methodology to generate efficient cache based programs from tensor product formulas.
Reference: [4] <author> R.W. Johnson, C.-H. Huang, and J.R. Johnson. </author> <title> Multilinear Algebra and Parallel Programming. </title> <journal> Journal of Supercomputing, </journal> <volume> 5 </volume> <pages> 189-217, </pages> <year> 1991. </year>
Reference-contexts: In this paper, we present a methodology to generate efficient cache based programs from tensor product formulas. Tensor products, also known as Kronecker products, have been used for expressing block recursive algorithms such as Strassen's matrix multiplication <ref> [4, 6] </ref> and fast Fourier transforms [7]. Tensor product formulas can be used for the automatic synthesis of efficient parallel programs for multiprocessors. In this paper, we present an algebraic model for measuring the cache utilization of block recursive algorithms for a set associative cache. <p> For details, the reader is referred to <ref> [4] </ref>. Stockham's FFT on a 2 n element vector X can be rep resented as Y = i=1 (F 2 I 2 n1 )(L 2 i i where F 2 = 1 1 F 2 is a linear transformation and is referred to as an operator matrix.
Reference: [5] <author> K. Kennedy and K. S. McKinley. </author> <title> Optimizing for parallelism and data locality. </title> <booktitle> International conference on supercomputing, </booktitle> <pages> pages 323-334, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Hence, it is necessary to perform program transformations to make efficient utilization of the memory hierarchy. A number of program transformations can be performed to improve data locality [8]. Certain transformations such as loop fusion may result in better temporal locality, and others such as blocking <ref> [5] </ref> may improve spatial locality.
Reference: [6] <author> B. Kumar, C. H. Huang, J. Johnson, R. W. Johnson, and P. Sa-dayappan. </author> <title> A tensor product formulation of Strassen's matrix multiplication algorithm with memory reduction. </title> <booktitle> In Seventh International Parallel Processing Symposium, </booktitle> <pages> pages 582-588, </pages> <month> Apr. </month> <year> 1993. </year>
Reference-contexts: In this paper, we present a methodology to generate efficient cache based programs from tensor product formulas. Tensor products, also known as Kronecker products, have been used for expressing block recursive algorithms such as Strassen's matrix multiplication <ref> [4, 6] </ref> and fast Fourier transforms [7]. Tensor product formulas can be used for the automatic synthesis of efficient parallel programs for multiprocessors. In this paper, we present an algebraic model for measuring the cache utilization of block recursive algorithms for a set associative cache.
Reference: [7] <author> C.V. Loan. </author> <title> Computational Frameworks for the Fast Fourier Transform. </title> <publisher> SIAM, </publisher> <year> 1992. </year>
Reference-contexts: In this paper, we present a methodology to generate efficient cache based programs from tensor product formulas. Tensor products, also known as Kronecker products, have been used for expressing block recursive algorithms such as Strassen's matrix multiplication [4, 6] and fast Fourier transforms <ref> [7] </ref>. Tensor product formulas can be used for the automatic synthesis of efficient parallel programs for multiprocessors. In this paper, we present an algebraic model for measuring the cache utilization of block recursive algorithms for a set associative cache. The issue of data reuse for multi-pass algorithms is also addressed.
Reference: [8] <author> A. K. Porterfield. </author> <title> Software methods for improvement of cache performance on supercomputer applications. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> May </month> <year> 1989. </year>
Reference-contexts: Cache memory can be accessed very rapidly, but has limited storage capacity. Hence, it is necessary to perform program transformations to make efficient utilization of the memory hierarchy. A number of program transformations can be performed to improve data locality <ref> [8] </ref>. Certain transformations such as loop fusion may result in better temporal locality, and others such as blocking [5] may improve spatial locality.
References-found: 8

