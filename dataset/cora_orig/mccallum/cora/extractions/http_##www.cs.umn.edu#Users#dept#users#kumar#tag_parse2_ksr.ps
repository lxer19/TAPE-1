URL: http://www.cs.umn.edu/Users/dept/users/kumar/tag_parse2_ksr.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Email: nurkkala@cs.umn.edu kumar@cs.umn.edu  
Title: The Performance of a Highly Unstructured Parallel Algorithm on the KSR1  
Author: Tom Nurkkala Vipin Kumar 
Address: Minneapolis, MN 55455  
Affiliation: Department of Computer Science, University of Minnesota,  
Abstract: This paper examines the performance on the Kendall Square Research KSR1 multicomputer of a highly unstructured algorithm for natural language parsing. It describes a Tree Adjoining Grammar parsing algorithm that exhibits near linear speedup and very high efficiency for grammars of even moderate size. The work reported demonstrates the utility of shared-address-space parallel architectures for algorithms that require shared data structures. Finally, the paper presents practical guidelines for the efficient use of the KSR1. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aho and J. Ullman. </author> <title> The Theory of Parsing, Translation, and Compiling, Vol. 1: Parsing. </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: For an n-word input sentence, TAG parsers based on the CYK parsing model <ref> [1, 3] </ref> exhibit tightly-bounded asymptotic complexity of fi (n 6 ). Earley-style TAG parsers [2, 8] also have an upper-bound complexity of O (n 6 ). Given this computational complexity, the principle constraint on natural language research using TAG is the amount of time necessary to parse sentences.
Reference: [2] <author> J. Earley. </author> <title> An efficient context-free parsing algorithm. </title> <journal> Communications of the ACM, </journal> <volume> 13 </volume> <pages> 94-102, </pages> <year> 1970. </year>
Reference-contexts: For an n-word input sentence, TAG parsers based on the CYK parsing model [1, 3] exhibit tightly-bounded asymptotic complexity of fi (n 6 ). Earley-style TAG parsers <ref> [2, 8] </ref> also have an upper-bound complexity of O (n 6 ). Given this computational complexity, the principle constraint on natural language research using TAG is the amount of time necessary to parse sentences.
Reference: [3] <author> A. K. Joshi, L. S. Levy, and M. Takahashi. </author> <title> Tree adjunct grammars. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 10 </volume> <pages> 136-63, </pages> <year> 1975. </year>
Reference-contexts: This lower latency allows shared-address-space machines to exploit fine-grain parallelism more effectively than message-passing multicomputers. Natural language parsing using Tree Adjoining Grammar (TAG) is one such unstructured algorithm. TAG is a powerful grammatical formalism for large-scale natural language processing <ref> [3, 9] </ref>. <p> For an n-word input sentence, TAG parsers based on the CYK parsing model <ref> [1, 3] </ref> exhibit tightly-bounded asymptotic complexity of fi (n 6 ). Earley-style TAG parsers [2, 8] also have an upper-bound complexity of O (n 6 ). Given this computational complexity, the principle constraint on natural language research using TAG is the amount of time necessary to parse sentences.
Reference: [4] <institution> Kendall Square Research, </institution> <address> 170 Tracer Lane, Waltham, MA 021454-1379. </address> <note> KSR Parallel Programming, Febu-rary 1992. </note>
Reference-contexts: The algorithm also uses hashing to avoid processing duplicate states. 4 Parallel Formulation We have parallelized Algorithm 1 on the KSR1 using its pthread mechanism. A pthread is a lightweight process that is the fundamental unit of concurrency on the KSR1 <ref> [4] </ref>. Each pthread executes on a separate processor, which has its own local memory. Pthreads communicate by accessing other processors' memories using the KSR ALLCACHE mechanism. ALLCACHE provides a single global address space and treats the entire physical memory as cache. <p> Conceptually, the KSR1 is a shared-memory architecture. However, it is a non-uniform memory access (NUMA) machine|the ratio of local 2 to remote access times is about 1:300 <ref> [4] </ref>. This ratio implies that the KSR1 cannot be programmed as if it were a true shared memory machine. We found the following guidelines critical to implementing a high-efficiency KSR1 algorithm. Avoid frequent updates to shared data.
Reference: [5] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis. </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms. </title> <address> Ben-jamin/Cummings, </address> <year> 1994. </year>
Reference-contexts: Although it is highly unstructured, the algorithm exhibits good speedup and high efficiency, subject to the limitations of the KSR1's communication architecture. With the exception of problems with its standard libraries, the KSR1 is exceptionally easy to program when compared to message-passing architectures. Operations like one-to-all and all-to-all broadcasts <ref> [5] </ref> become simple memory references. Distributed hashing is straightforward to implement and performs well by merit of the ALLCACHE mechanism. Complex tasks, like dynamic load balancing, require only a few lines of code for locks and memory reads. Ease of use, however, does not come for free.
Reference: [6] <author> Vipin Kumar, Ananth Grama, and V. Nageshwara Rao. </author> <title> Scalable load balancing techniques for parallel computers. </title> <type> Technical Report 91-55, </type> <institution> Computer Science Department, University of Minnesota, </institution> <year> 1991. </year> <note> To appear in Journal of Distributed and Parallel Computing, </note> <year> 1994. </year>
Reference-contexts: When a pthread runs out of work, it randomly chooses a donor pthread, locks the donor's agenda, and steals a fixed fraction of the donor's work. The performance and scalability of this load balancing scheme is expected to be similar to that of Kumar et. al.'s random polling scheme <ref> [6] </ref>. Conceptually, the KSR1 is a shared-memory architecture. However, it is a non-uniform memory access (NUMA) machine|the ratio of local 2 to remote access times is about 1:300 [4]. This ratio implies that the KSR1 cannot be programmed as if it were a true shared memory machine.
Reference: [7] <author> Tom Nurkkala and Vipin Kumar. </author> <title> A parallel algorithm for natural language parsing using tree adjoining grammar. </title> <booktitle> In Proceedings of the International Parallel Processing Symposium, 1994 (to appear). </booktitle>
Reference-contexts: Thus, TAG parsing is a good candidate for paral-lelization. However, TAG parsers demonstrate highly unstructured behavior. They exhibit highly unbalanced computation, resulting in poor efficiency due to processor idling, load imbalance, and communication overhead. Our earlier work considered CYK-style TAG parsing on a message-passing architecture <ref> [7] </ref>. In this paper, we examine an Earley-style TAG parser on the shared-address-space KSR1.
Reference: [8] <author> Yves Schabes. </author> <title> Mathematical and Computational Aspects of Lexicalized Grammars. </title> <type> PhD thesis, </type> <institution> University of Pennsylvania, Department of Computer and Information Science, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: For an n-word input sentence, TAG parsers based on the CYK parsing model [1, 3] exhibit tightly-bounded asymptotic complexity of fi (n 6 ). Earley-style TAG parsers <ref> [2, 8] </ref> also have an upper-bound complexity of O (n 6 ). Given this computational complexity, the principle constraint on natural language research using TAG is the amount of time necessary to parse sentences. <p> If such a tree can be composed, the TAG accepts the input string; otherwise, it rejects it. 3 Serial Algorithm Our algorithm is an Earley-style TAG parser, based on the work of Schabes <ref> [8] </ref>. Such parsers use three basic types of operators: 1 1. Scanner|scans input tokens. 2. Predictor|makes top-down predictions that spe cific grammar rules will be used. 3. Completor|indicates bottom-up completions of grammar rules predicted by an earlier prediction operation.
Reference: [9] <author> K. Vijay-Shankar and A. K. Joshi. </author> <title> Some computational properties of tree adjoining grammars. </title> <booktitle> In Proceedings of the 11th Meeting of the Association of Computational Linguistics, </booktitle> <month> August </month> <year> 1986. </year>
Reference-contexts: This lower latency allows shared-address-space machines to exploit fine-grain parallelism more effectively than message-passing multicomputers. Natural language parsing using Tree Adjoining Grammar (TAG) is one such unstructured algorithm. TAG is a powerful grammatical formalism for large-scale natural language processing <ref> [3, 9] </ref>.
References-found: 9

