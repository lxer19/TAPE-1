URL: http://www.research.microsoft.com/~mhwang/csr-isr.ps
Refering-URL: http://www.research.microsoft.com/~mhwang/
Root-URL: http://www.research.microsoft.com
Email: Mhwang@microsoft.com  
Phone: Voice: 425-936-5375 fax: 425-936-7329  
Title: CAN CONTINUOUS SPEECH RECOGNIZERS HANDLE ISOLATED SPEECH?  
Author: Fil Alleva, Xuedong Huang, Mei-Yuh Hwang and Li Jiang Contact person: Mei-Yuh Hwang 
Address: One Microsoft Way Redmond, Washington 98052, USA  
Affiliation: Microsoft Research  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Alleva, F., Huang, X., Hwang, M., </author> <year> 1996. </year> <title> Improvements on the Pronunciation Prefix Tree Search Organization. </title> <booktitle> In: IEEE ICASSP, </booktitle> <address> Atlanta, GA, </address> <pages> pp. 133-136. </pages>
Reference-contexts: Viterbi maximum likelihood training is performed followed by maximum a posteriori smoothing [4] at each iteration. The North American Business News corpus [8] was used to derive a 60,000-word trigram language model. The recognition system is based on the pronunciation prefix-tree decoder <ref> [1] </ref>. A more complete description of the Whisper speech recognition system can be found in [5]. Two test and two training acoustic corpora were used in this study.
Reference: [2] <author> Breiman, L., Friedman, J.H., Olshen, R.A., </author> <year> 1984. </year> <title> Classification and Regression Trees, </title> <publisher> Wadsworth, Inc. </publisher>
Reference-contexts: These models are gender dependent and each model was 6 built using its own set of gender-independent classification and regression trees (CART) <ref> [2] </ref> for senone sharing [6]. As the first row of Table 1 shows, the word error rate of the CSR model on H1dev94 was 8.5%. However, its performance degraded significantly to 13.3% on ISR test data. Using the same search engine, the ISR model achieved an error rate of 4.9%.
Reference: [3] <author> Davis, S.B., Mermelstein, P., </author> <year> 1980. </year> <title> Comparison of Parametric Representations of Monosyllabic Word Recognition in Continuously Spoken Sentences. </title> <journal> IEEE Trans. On Acoustics, Speech, and Signal Processing. </journal> <volume> Vol. 28; No. 4, </volume> <month> pp357-366. </month>
Reference-contexts: This result means that system performance is now in line with user expectations; that is, the accuracy of the CSR system actually improves, rather than deteriorates, when the user slows down. 5 2. SYSTEM DESCRIPTION The system being discussed processes 16kHz PCM data using a MEL-scale cep-strum <ref> [3] </ref> along with its dynamics into a multidimensional feature vector. The acoustic model is a gender dependent HMM model with continuous-density output probabilities, consisting of 6000 senones [6]. A senone is a cluster of acoustically similar Markov states.
Reference: [4] <author> Gauvain, J.L., and Lee, C.H., </author> <year> 1994. </year> <title> Maximum A Posteriori Estimation for Mul-tivariate Gaussian Mixture Observations of Markov Chains. </title> <journal> IEEE Trans. On Speech and Audio Processing, Vol.2, </journal> <volume> No. 2, </volume> <pages> pp. 291-298. </pages>
Reference-contexts: A mixture of 20 Gaussian densities with diagonal co-variances is used for each senone. The phonetic modeling in the system consists of position and context dependent within-word and crossword triphones. Viterbi maximum likelihood training is performed followed by maximum a posteriori smoothing <ref> [4] </ref> at each iteration. The North American Business News corpus [8] was used to derive a 60,000-word trigram language model. The recognition system is based on the pronunciation prefix-tree decoder [1]. A more complete description of the Whisper speech recognition system can be found in [5].
Reference: [5] <author> Huang, X., Acero, A., Alleva, F., Hwang, M., Jiang, L., Mahajan, M., </author> <year> 1994. </year> <title> From Sphinx-II to Whisper - Making Speech Recognition Usable. In: Speech and Speaker Recognition-Advanced Topics, </title> <publisher> Kluwer Academic Publishers, pp.481-508. </publisher>
Reference-contexts: The North American Business News corpus [8] was used to derive a 60,000-word trigram language model. The recognition system is based on the pronunciation prefix-tree decoder [1]. A more complete description of the Whisper speech recognition system can be found in <ref> [5] </ref>. Two test and two training acoustic corpora were used in this study. The CSR training and test corpora correspond to the widely used ARPA SI-284 [7] training set and the 1994 H1 development test set [7] (denoted as H1dev94).
Reference: [6] <author> Hwang, M., Huang, X., Alleva, F., </author> <year> 1996. </year> <title> Predicting Unseen Triphones with Se-nones. </title> <journal> IEEE Trans. On Speech and Audio Processing. </journal> <volume> Vol. 4; No. 6, </volume> <pages> pp. 412-419. </pages>
Reference-contexts: SYSTEM DESCRIPTION The system being discussed processes 16kHz PCM data using a MEL-scale cep-strum [3] along with its dynamics into a multidimensional feature vector. The acoustic model is a gender dependent HMM model with continuous-density output probabilities, consisting of 6000 senones <ref> [6] </ref>. A senone is a cluster of acoustically similar Markov states. A mixture of 20 Gaussian densities with diagonal co-variances is used for each senone. The phonetic modeling in the system consists of position and context dependent within-word and crossword triphones. <p> These models are gender dependent and each model was 6 built using its own set of gender-independent classification and regression trees (CART) [2] for senone sharing <ref> [6] </ref>. As the first row of Table 1 shows, the word error rate of the CSR model on H1dev94 was 8.5%. However, its performance degraded significantly to 13.3% on ISR test data. Using the same search engine, the ISR model achieved an error rate of 4.9%.
Reference: [7] <institution> Linguistic Data Consortium, </institution> <year> 1994. </year> <title> CSR-II ARPA Continuos Speech Recognition Corpus, </title> <institution> University of Pennsylvania. </institution>
Reference-contexts: A more complete description of the Whisper speech recognition system can be found in [5]. Two test and two training acoustic corpora were used in this study. The CSR training and test corpora correspond to the widely used ARPA SI-284 <ref> [7] </ref> training set and the 1994 H1 development test set [7] (denoted as H1dev94). The ISR training and test corpora were collected locally and consist of 133 training speakers and 19 test speakers. <p> Two test and two training acoustic corpora were used in this study. The CSR training and test corpora correspond to the widely used ARPA SI-284 <ref> [7] </ref> training set and the 1994 H1 development test set [7] (denoted as H1dev94). The ISR training and test corpora were collected locally and consist of 133 training speakers and 19 test speakers. The content of the ISR training corpus was partially taken from the Wall Street Journal, and partially from some simple stories designed to obtain broad phonetic coverage.
Reference: [8] <institution> Linguistic Data Consortium, </institution> <year> 1994. </year> <title> CSR-III Text Language Model, </title> <institution> University of Pennsylvania. </institution>
Reference-contexts: The phonetic modeling in the system consists of position and context dependent within-word and crossword triphones. Viterbi maximum likelihood training is performed followed by maximum a posteriori smoothing [4] at each iteration. The North American Business News corpus <ref> [8] </ref> was used to derive a 60,000-word trigram language model. The recognition system is based on the pronunciation prefix-tree decoder [1]. A more complete description of the Whisper speech recognition system can be found in [5]. Two test and two training acoustic corpora were used in this study.
References-found: 8

