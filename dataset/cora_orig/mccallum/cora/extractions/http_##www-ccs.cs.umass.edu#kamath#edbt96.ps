URL: http://www-ccs.cs.umass.edu/kamath/edbt96.ps
Refering-URL: http://ccs-www.cs.umass.edu/db/wf.html
Root-URL: 
Email: kamath@cs.umass.edu alonso@inf.ethz.ch  rgunthor@heidelbg.ibm.com mohan@almaden.ibm.com  
Title: Providing High Availability in Very Large Workflow Management Systems 1  
Author: M. Kamath G. Alonso R. Gunthor C. Mohan 
Address: Amherst, MA 01003, USA CH-8092 Zurich, Switzerland  Vangerowstr. 18, 69115 Heidelberg 650 Harry Road, San Jose, CA 95120 Germany USA  
Affiliation: Dept. of Computer Science Institute for Information Systems University of Massachusetts Database Group, ETH Zentrum  IBM European Networking Center IBM Almaden Research Center  
Abstract: Workflow management systems (WFMS) support the modeling, coordinated execution and monitoring of business processes within an organization. In particular, very large workflow management systems are used in organizations with several thousand users, hundreds of thousands of process instances, and several thousand sites, all distributed over wide geographic areas. In these environments, failure of the WFMS or the underlying workflow database which stores the meta-information about the processes is not tolerable. This paper addresses the problem of providing high availability in workflow management systems by proposing a backup technique which ensures that execution of a process instance can be resumed at any point in time in the event of a failure. An essential characteristic of our backup scheme is that it allows the user to define different availability levels, reducing the cost of maintaining backups. The backup scheme is implemented using the workflow semantics, which we believe will (i) make it independent of the underlying workflow database, thus permitting the use of heterogeneous databases as primary and backup, (ii) reduce overheads, especially when compared to backup schemes provided by database systems.
Abstract-found: 1
Intro-found: 1
Reference: [BGHJ92] <author> A. Bhide, A. Goyal, H Hsiao, and A. Jhingran. </author> <title> An Efficient Scheme for Providing High Availability. </title> <booktitle> In Proc. of 1992 SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 236-245, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: By using application (workflow) level backup, the replication scheme becomes independent of the underlying platform, thus allowing the use of heterogeneous databases. * Need for flexibility in replicating process instance data: In traditional database backup techniques, the units of exchange tend to be pages or log records <ref> [GMP90, BGHJ92, MTO93] </ref> which makes it difficult to control which data is actually being replicated. If such techniques are used to replicate data between two workflow databases, log records of changes to all objects, including those that correspond to static information about processes will be replicated. <p> There is, of course, the risk of data loss when the backup takes over but in practice the 1-safe policy is preferred over the 2-safe due to its lower overhead. Algorithms for the maintenance of remote copies under the 1-safe and 2-safe policies are discussed in [GMP90] and <ref> [BGHJ92] </ref> respectively. In the case of workflow systems, we do not believe that the 1-safe option is viable always. In the case of traditional databases, since transactions are short and perform few changes, losing these changes may not be critical.
Reference: [BT90] <author> D. L. Burkes and R. K. Treiber. </author> <title> Design Approach for Real-Time Transaction Processing Remote Site Recovery. </title> <booktitle> In Proceedings of IEEE Com-pcon, </booktitle> <pages> pages 568-572, </pages> <year> 1990. </year>
Reference-contexts: These can be adapted to WFMS to speed up recovery. A disaster recovery scheme with options to choose the desired degree of data durability and service durability through different insurance levels and readiness levels on a per-transaction basis is discussed in <ref> [BT90] </ref>. However, the scheme is based on remote logging of data pages and cannot be used for process-instance replication since this can lead to higher overheads. Apart from less overheads, another important requirement for our backup technique is the fact that it should be database independent.
Reference: [CS92] <author> D. D. Chamberlain and F. B. Schmuck. </author> <title> Dynamic Data Distribution (D 3 )in a Shared-Nothing Multiprocessor Data Store. </title> <booktitle> In Proceedings of 18th VLDB Conference, </booktitle> <pages> pages 163-174, </pages> <address> Vancouver, British Columbia, </address> <year> 1992. </year>
Reference-contexts: However, this is not a suitable approach since there are enormous overheads due to duplication of processing and different order of executions at the primary and backup can cause inconsistencies within a business process. Coordinating the nodes of a distributed system that contain replicated data is discussed in <ref> [CS92] </ref> in the context of the D 3 model. The model provides schemes for choosing a coordinator and a new primary/backup in case of node failures. The model also has provision for load-balancing and for adding/removing nodes from the system without interruption of normal operation. <p> The actual decision of choosing which server will be the primary and which will be the backup is left to the user. This can also be done automatically using the techniques described in <ref> [CS92] </ref>. Another alternative to achieve this is to use load balancing algorithms, but this issue is beyond the scope of the paper. The architecture is summarized in We will assume there is an underlying communication layer that provides the appropriate interface and mechanisms for the clients and servers to communicate.
Reference: [FCK87] <author> J. C. Freytag, F. Cristian, and B. Kaehler. </author> <title> Masking System Crashes in Database Application Programs. </title> <booktitle> In Proceedings of 13th VLDB Conference, </booktitle> <pages> pages 407-416, </pages> <address> Brighton, England, </address> <year> 1987. </year>
Reference-contexts: To add flexibility to our design, we provide the user with the possibility of using both approaches: cold standby and hot standby. Inconsistencies that can arise due to transaction dependencies during crash recovery are discussed in <ref> [FCK87, MHL + 92] </ref>. However they are irrelevant in the workflow context since the execution states of different business processes are independent.
Reference: [Fry94] <author> C. Frye. </author> <title> Move to Workflow Provokes Business Process Scrutiny. </title> <journal> Software Magazine, </journal> <pages> pages 77-89, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: With these figures, continuous availability becomes a crucial aspect of any successful commercial WFMS. Though more than 70 work flow products exist in the market <ref> [Fry94] </ref>, this is an issue that has been ignored by workflow developers, and to our knowledge, has not yet been addressed by research in the area of workflow management. 1 This work was performed while M. Kamath, G. Alonso and R.
Reference: [GMP90] <author> H. Garcia-Molina and C. A. Polyzois. </author> <title> Two Epoch Algorithms for Disaster Recovery. </title> <booktitle> In Proc. of 16th VLDB Conference, </booktitle> <address> Brisbane, Australia, </address> <pages> pages 222-230, </pages> <year> 1990. </year>
Reference-contexts: By using application (workflow) level backup, the replication scheme becomes independent of the underlying platform, thus allowing the use of heterogeneous databases. * Need for flexibility in replicating process instance data: In traditional database backup techniques, the units of exchange tend to be pages or log records <ref> [GMP90, BGHJ92, MTO93] </ref> which makes it difficult to control which data is actually being replicated. If such techniques are used to replicate data between two workflow databases, log records of changes to all objects, including those that correspond to static information about processes will be replicated. <p> There is, of course, the risk of data loss when the backup takes over but in practice the 1-safe policy is preferred over the 2-safe due to its lower overhead. Algorithms for the maintenance of remote copies under the 1-safe and 2-safe policies are discussed in <ref> [GMP90] </ref> and [BGHJ92] respectively. In the case of workflow systems, we do not believe that the 1-safe option is viable always. In the case of traditional databases, since transactions are short and perform few changes, losing these changes may not be critical.
Reference: [GHS95] <author> Georgakopolous D. and Hornick M. and Sheth A. </author> <title> An Overview of Work-flow Management: From Process Modelling to Workflow Automation Infrastructure. </title> <journal> Distributed and Parallel Databases Journal, </journal> <volume> 3(2) </volume> <pages> 119-152, </pages> <year> 1995. </year>
Reference-contexts: In this paper our focus will be on WFMSs that use a centralized database (work-flow database) to store meta-information about the business processes. They conform to the reference model developed by the Workflow Management Coalition [WfMC94] and typically handle production workflows <ref> [GHS95] </ref>. In environments where several workflow databases coexist, each of them typically stores a different subset of processes instances. If one database fails, all process instances running off that database will stop their execution. This behavior is unacceptable for several critical business processes which cannot be delayed. <p> Though these concepts have been around for a number of years, the technology required to implement suitable systems has however been available only recently. Currently, there is a considerable amount of attention devoted to this area <ref> [GHS95, Hsu95, She94] </ref>. A workflow model is a description of a business process.
Reference: [Gol94] <author> R. Goldring. </author> <title> A Discussion of Relational Database Replication Technology. </title> <journal> InfoDB, </journal> <volume> 8(1), </volume> <year> 1994. </year>
Reference-contexts: However they are irrelevant in the workflow context since the execution states of different business processes are independent. Techniques to replicate data at a high level in the context of relational databases are discussed in <ref> [Gol94] </ref> where SQL calls are trapped at the primary and executed at the backup site. However, this is not a suitable approach since there are enormous overheads due to duplication of processing and different order of executions at the primary and backup can cause inconsistencies within a business process.
Reference: [GR93] <author> J. Gray and A. Reuter. </author> <title> Transaction Processing: Concepts and Techniques. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Note that since there are only two participants involved, the primary and the backup, some optimizations of 2PC can be implemented <ref> [SBCM95, GR93] </ref>. When using 2PC, this approach is known as 2-safe and it is similar in some aspects to the very-safe case of [GR93]. Contrary to the 2-safe policy, the 1-safe policy does not require the primary to wait for the secondary. <p> Note that since there are only two participants involved, the primary and the backup, some optimizations of 2PC can be implemented [SBCM95, GR93]. When using 2PC, this approach is known as 2-safe and it is similar in some aspects to the very-safe case of <ref> [GR93] </ref>. Contrary to the 2-safe policy, the 1-safe policy does not require the primary to wait for the secondary. It commits its transaction first and then propagates the log records to the secondary.
Reference: [Hsu95] <author> M. </author> <title> Hsu. </title> <journal> Special Issue on Workflow Systems. Bulletin of the Technical Committee on Data Engineering, IEEE, </journal> <volume> 18(1), </volume> <month> March </month> <year> 1995. </year>
Reference-contexts: Though these concepts have been around for a number of years, the technology required to implement suitable systems has however been available only recently. Currently, there is a considerable amount of attention devoted to this area <ref> [GHS95, Hsu95, She94] </ref>. A workflow model is a description of a business process.
Reference: [IBMa] <author> IBM. </author> <title> FlowMark for OS/2: Managing Your Workflow. Document No. </title> <address> SH19-8176-00, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Kamath, G. Alonso and R. Gunthor were visiting scientists at the IBM Almaden Research Center This paper reports ongoing research in the availability of WFMSs, as part of the research efforts of the Exotica project [MAGK95]. The research has been centered around FlowMark <ref> [IBMa, LR94] </ref>, a WFMS from IBM. However our results can be easily generalized to any WFMS. In this paper our focus will be on WFMSs that use a centralized database (work-flow database) to store meta-information about the business processes.
Reference: [LR94] <author> F. Leymann and D. </author> <title> Roller. Business Processes Management with Flow-Mark. </title> <booktitle> In Proc. 39th IEEE Computer Society Int'l Conference (Com-pCon), Digest of Papers, </booktitle> <pages> pages 230-233, </pages> <address> San Francisco, California, </address> <month> February 28 March 4 </month> <year> 1994. </year> <note> IEEE. </note>
Reference-contexts: Kamath, G. Alonso and R. Gunthor were visiting scientists at the IBM Almaden Research Center This paper reports ongoing research in the availability of WFMSs, as part of the research efforts of the Exotica project [MAGK95]. The research has been centered around FlowMark <ref> [IBMa, LR94] </ref>, a WFMS from IBM. However our results can be easily generalized to any WFMS. In this paper our focus will be on WFMSs that use a centralized database (work-flow database) to store meta-information about the business processes.
Reference: [Lyo90] <author> J. Lyon. </author> <title> Tandem's Remote Data Facility. </title> <booktitle> In Proc. of IEEE Compcon, </booktitle> <year> 1990. </year>
Reference-contexts: This will help us focus on the specifics of our workflow semantics-based backup technique in the rest of the sections. The basic ideas behind backup mechanisms are well known. Consider, for instance, Tandem's Remote Data Facility <ref> [Lyo90] </ref>. In this environment a server or group of servers, known as primary, use a single backup computer, known as secondary. Under normal operation, a client sends requests to the primary, and the log records generated at the primary are sent to the backup and applied to its state.
Reference: [MAGK95] <author> C. Mohan, G. Alonso, R. Gunthor, and M. Kamath. Exotica: </author> <title> A Research Perspective on Workflow Management Systems. </title> <booktitle> In [Hsu95]. </booktitle>
Reference-contexts: Kamath, G. Alonso and R. Gunthor were visiting scientists at the IBM Almaden Research Center This paper reports ongoing research in the availability of WFMSs, as part of the research efforts of the Exotica project <ref> [MAGK95] </ref>. The research has been centered around FlowMark [IBMa, LR94], a WFMS from IBM. However our results can be easily generalized to any WFMS. In this paper our focus will be on WFMSs that use a centralized database (work-flow database) to store meta-information about the business processes.
Reference: [MHL + 92] <author> C. Mohan, D. Haderle, B. Lindsay, H. Pirahesh, and P. Schwarz. </author> <title> ARIES: A transaction recovery method supporting fine-granularity locking and partial rollbacks using write-ahead logging. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 17(1), </volume> <year> 1992. </year>
Reference-contexts: To add flexibility to our design, we provide the user with the possibility of using both approaches: cold standby and hot standby. Inconsistencies that can arise due to transaction dependencies during crash recovery are discussed in <ref> [FCK87, MHL + 92] </ref>. However they are irrelevant in the workflow context since the execution states of different business processes are independent.
Reference: [MTO93] <author> C. Mohan, K. Treiber, and R. Obermarck. </author> <title> Algorithms for the Management of Remote Backup Data Bases for Disaster Recovery. </title> <booktitle> In Proc. of 9th International Conference on Data Engineering, </booktitle> <pages> pages 511-518, </pages> <year> 1993. </year>
Reference-contexts: By using application (workflow) level backup, the replication scheme becomes independent of the underlying platform, thus allowing the use of heterogeneous databases. * Need for flexibility in replicating process instance data: In traditional database backup techniques, the units of exchange tend to be pages or log records <ref> [GMP90, BGHJ92, MTO93] </ref> which makes it difficult to control which data is actually being replicated. If such techniques are used to replicate data between two workflow databases, log records of changes to all objects, including those that correspond to static information about processes will be replicated. <p> Techniques that exploit parallelism in processing the log records at the backup, and schemes that allow new transactions to begin in parallel along with the takeover process are discussed in <ref> [MTO93] </ref>. These can be adapted to WFMS to speed up recovery. A disaster recovery scheme with options to choose the desired degree of data durability and service durability through different insurance levels and readiness levels on a per-transaction basis is discussed in [BT90].
Reference: [SBCM95] <author> Samaras, G., Britton, K., Citron, A., Mohan, C. </author> <title> Two-Phase Commit Optimizations in a Commercial Distributed Environment. </title> <journal> In Distributed and Parallel Databases Journal, </journal> <volume> Vol. 3, No. 4, </volume> <month> October </month> <year> 1995. </year>
Reference-contexts: Note that since there are only two participants involved, the primary and the backup, some optimizations of 2PC can be implemented <ref> [SBCM95, GR93] </ref>. When using 2PC, this approach is known as 2-safe and it is similar in some aspects to the very-safe case of [GR93]. Contrary to the 2-safe policy, the 1-safe policy does not require the primary to wait for the secondary.
Reference: [She94] <author> A.P. Sheth. </author> <title> On Multi-system Applications and Transactional Workflows, 1994. Collection of papers from Bellcore. </title>
Reference-contexts: Though these concepts have been around for a number of years, the technology required to implement suitable systems has however been available only recently. Currently, there is a considerable amount of attention devoted to this area <ref> [GHS95, Hsu95, She94] </ref>. A workflow model is a description of a business process.
Reference: [WfMC94] <institution> The Workflow Reference Model. Workflow Management Coalition, </institution> <note> De-cember 1994. Accessible via: http://www.aiai.ed.ac.uk/WfMC/. </note>
Reference-contexts: However our results can be easily generalized to any WFMS. In this paper our focus will be on WFMSs that use a centralized database (work-flow database) to store meta-information about the business processes. They conform to the reference model developed by the Workflow Management Coalition <ref> [WfMC94] </ref> and typically handle production workflows [GHS95]. In environments where several workflow databases coexist, each of them typically stores a different subset of processes instances. If one database fails, all process instances running off that database will stop their execution. <p> A common term used to refer to the work performed in large organizations is a business process, defined by the Workflow Management Coalition as "a procedure where documents, information or tasks are passed between participants according to defined sets of rules to achieve, or contribute to, an overall business goal" <ref> [WfMC94] </ref>. A workflow is a particular representation of a business process. The role of a workflow management system, WFMS, is the scheduling and coordination of all the activities encompassing a business process. <p> Currently, there is a considerable amount of attention devoted to this area [GHS95, Hsu95, She94]. A workflow model is a description of a business process. For this purpose, the Workflow Management Coalition has proposed the following reference model <ref> [WfMC94] </ref>: A business process is represented by a schema that includes the process name, version number, start and termination conditions and additional data for security, audit and control. A process consists of several steps.
Reference: [WN94] <author> J. Wiener and J. Naughton. </author> <title> Bulk Loading into an OODB: A Performance Study. </title> <booktitle> In Proceedings of the 20th VLDB Conference, </booktitle> <pages> pages 120-131, </pages> <address> Santiago, Chile, </address> <year> 1994. </year>
Reference-contexts: Thus, a mechanism is needed to map entities between both databases. For instance, in object-oriented databases, objects reference each other by their OIDs. However, these OIDs are usually not visible to the user, hence a surrogate identifier must be used to refer to the object <ref> [WN94] </ref>. Moreover, even if the OIDs of objects were to be available, two databases will assign different OIDs to what is essentially the same object, one at the primary and one at the backup database. <p> Creating a new backup database, on the failure of the existing backup database is handled similarly. To further speed up the setting of a new primary/backup database, it may be possible to use database loaders <ref> [WN94] </ref>. However, their efficient use requires, for instance, to turn logging off, which would conflict with normal operations and many object-oriented databases do not provide such a feature. Hence, it is not yet clear if this is a feasible option.
References-found: 20

