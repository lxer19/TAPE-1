URL: http://www.isi.edu/~mhall/malaga.ps
Refering-URL: http://www.isi.edu/~mhall/mypapers.html
Root-URL: http://www.isi.edu
Title: Overview of an Interprocedural Automatic Parallelization System  
Author: Mary W. Hall Brian R. Murphy Saman P. Amarasinghe Shih-Wei Liao Monica S. Lam 
Abstract: We present an overview of our interprocedural analysis system, which applies the program analysis required for parallelization across procedure boundaries. We discuss the issues we addressed to efficiently obtain precise results in the interprocedural setting. We present the analysis required for parallelization, illustrated with an excerpt from a Fortran benchmark program. By integrating a comprehensive suite of interprocedural analyses, we have built a system that is much more effective at locating parallelism in scientific benchmarks than earlier interprocedural systems.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. W. Hall, J. Mellor-Crummey, A. Carle, and R. Rodriguez. FIAT: </author> <title> A framework for interprocedural analysis and transformation. </title> <booktitle> In Proceedings of the Sixth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year> <month> 10 </month>
Reference-contexts: The final section highlights results we have gathered with this system. 2 Interprocedural Framework Interprocedural parallelization depends upon the solution of a large number of interprocedural data-flow analysis problems. These problems share many commonalities. We have encapsulated these common features in a tool, Fiat <ref> [1] </ref>, which we have combined with the Stanford SUIF compiler to constitute our interprocedural parallelization system. Fiat is an interproce-dural framework, analogous to traditional data-flow analysis frameworks [5].
Reference: [2] <author> P. Havlak and K. Kennedy. </author> <title> An implementation of interprocedural bounded regular section analysis. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 350-360, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: We have implemented all the analyses described in this paper and have been evaluating the effectiveness of this system at locating coarse-grain parallelism in scientific Fortran codes from the Perfect, Spec and Nas benchmark suites. 9 Some studies of earlier interprocedural systems have shown reasonable success on linear algebra libraries <ref> [2, 4, 6, 7] </ref>, but the results on larger programs have been much less promising [4]. We have compared our results with the Fida system (Full Interprocedural Data-Flow Analysis), an inter-procedural system that performs precise flow-insensitive array analysis [3].
Reference: [3] <author> M. Hind, M. Burke, P. Carini, and S. Midkiff. </author> <title> An empirical study of precise interprocedural array analysis. </title> <journal> Scientific Programming, </journal> <volume> 3(3) </volume> <pages> 255-271, </pages> <year> 1994. </year>
Reference-contexts: We have compared our results with the Fida system (Full Interprocedural Data-Flow Analysis), an inter-procedural system that performs precise flow-insensitive array analysis <ref> [3] </ref>. The Fida system was the first to measure how interprocedural analysis on full applications (from the Perfect and Spec89 benchmark suites) affects the number of parallel loops that the system can recognize.
Reference: [4] <author> M. Hind, P. Carini, M. Burke, and S. Midkiff. </author> <title> Interprocedural array analysis: how much precision do we need? In Proceedings of the 3rd Workshop on Compilers for Parallel Computers, vol. </title> <type> 2, </type> <institution> University of Vienna, Austria, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: We have implemented all the analyses described in this paper and have been evaluating the effectiveness of this system at locating coarse-grain parallelism in scientific Fortran codes from the Perfect, Spec and Nas benchmark suites. 9 Some studies of earlier interprocedural systems have shown reasonable success on linear algebra libraries <ref> [2, 4, 6, 7] </ref>, but the results on larger programs have been much less promising [4]. We have compared our results with the Fida system (Full Interprocedural Data-Flow Analysis), an inter-procedural system that performs precise flow-insensitive array analysis [3]. <p> effectiveness of this system at locating coarse-grain parallelism in scientific Fortran codes from the Perfect, Spec and Nas benchmark suites. 9 Some studies of earlier interprocedural systems have shown reasonable success on linear algebra libraries [2, 4, 6, 7], but the results on larger programs have been much less promising <ref> [4] </ref>. We have compared our results with the Fida system (Full Interprocedural Data-Flow Analysis), an inter-procedural system that performs precise flow-insensitive array analysis [3].
Reference: [5] <author> J. Kam and J. Ullman. </author> <title> Global data flow analysis and iterative algorithms. </title> <journal> Journal of the ACM, </journal> <volume> 23(1) </volume> <pages> 159-171, </pages> <month> January </month> <year> 1976. </year>
Reference-contexts: These problems share many commonalities. We have encapsulated these common features in a tool, Fiat [1], which we have combined with the Stanford SUIF compiler to constitute our interprocedural parallelization system. Fiat is an interproce-dural framework, analogous to traditional data-flow analysis frameworks <ref> [5] </ref>. A framework is even more important for interprocedural optimization because of the complexity of collecting and managing information about all the procedures in a program.
Reference: [6] <author> Z. Li and P. Yew. </author> <title> Efficient interprocedural analysis for program restructuring for parallel programs. </title> <booktitle> In Proceedings of the ACM SIGPLAN Symposium on Parallel Programming: Experience with Applications, Languages, and Systems (PPEALS), </booktitle> <address> New Haven, CT, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: We have implemented all the analyses described in this paper and have been evaluating the effectiveness of this system at locating coarse-grain parallelism in scientific Fortran codes from the Perfect, Spec and Nas benchmark suites. 9 Some studies of earlier interprocedural systems have shown reasonable success on linear algebra libraries <ref> [2, 4, 6, 7] </ref>, but the results on larger programs have been much less promising [4]. We have compared our results with the Fida system (Full Interprocedural Data-Flow Analysis), an inter-procedural system that performs precise flow-insensitive array analysis [3].
Reference: [7] <author> R. Triolet, F. Irigoin, and P. Feautrier. </author> <title> Direct parallelization of call statements. </title> <booktitle> In Proceedings of the SIGPLAN '86 Symposium on Compiler Construction, SIGPLAN Notices 21(7), </booktitle> <pages> pages 176-185. </pages> <publisher> ACM, </publisher> <month> July </month> <year> 1986. </year>
Reference-contexts: We have implemented all the analyses described in this paper and have been evaluating the effectiveness of this system at locating coarse-grain parallelism in scientific Fortran codes from the Perfect, Spec and Nas benchmark suites. 9 Some studies of earlier interprocedural systems have shown reasonable success on linear algebra libraries <ref> [2, 4, 6, 7] </ref>, but the results on larger programs have been much less promising [4]. We have compared our results with the Fida system (Full Interprocedural Data-Flow Analysis), an inter-procedural system that performs precise flow-insensitive array analysis [3].
References-found: 7

