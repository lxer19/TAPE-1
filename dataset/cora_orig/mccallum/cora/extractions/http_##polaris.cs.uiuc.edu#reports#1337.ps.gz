URL: http://polaris.cs.uiuc.edu/reports/1337.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Email: fmoreira,cdpg@csrd.uiuc.edu  
Title: Autoscheduling in a Shared Memory Multiprocessor IEEE/USP International Workshop on High Performance Computing Compilers and
Author: Jose E. Moreira Constantine D. Polychronopoulos 
Date: 1337  
Note: Presented at the  March 28-30, 1994, Sao Paulo, SP, Brazil CSRD Report No.  
Address: 1308 W. Main St., Urbana, IL USA  
Affiliation: Center for Supercomputing Research and Development and Coordinated Science Laboratory University of Illinois at Urbana-Champaign  
Abstract: This paper describes the implementation of autoscheduling on shared memory multiprocessors. Autoscheduling is a model of computation that provides efficient support for multiprocessing and multiprogramming in a general purpose multiprocessor by exploiting parallelism at different levels of granularity. The vehicle for implementing autoscheduling is the hierarchical task graph (HTG), an intermediate program representation that encapsulates the information on control and data dependencesat all levels. In this paper we discuss the fundamentals of autoscheduling and describe how the HTG can be used by an autoscheduling compiler to generate object code that exploits the parallelism present in the program. We also discuss several implementations issues for autoscheduling in shared memory processors. Validation and performance measurements of the autoscheduled code are accomplished by means of an instruction-level multiprocessor simulator. Our results show that autoscheduling can effectively use the processors in a multiprocessor, and enables us to exploit additional parallelism in a program, resulting in better speedup figures.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: task queue execute task forever As each task is executed, its drive code tests the remaining tasks for readiness, and the new ready tasks are inserted in the queue. 4 The activation frames of a parallel program cannot be implemented with the simple stack structure normally used in sequential programs <ref> [1] </ref>, since several instances of subroutines and loop iterations can be active at the same time. <p> The compiler consists of a series of transformation passes that operate on an internal data structure representing the program. We divide the passes in five phases: Phase 0 Parsing of the program: construction of the abstract syntax tree <ref> [1] </ref>. Phase 1 Task identification: derivation of the hierarchical structure of the HTG. Phase 2 Computation of the control and data dependence graphs.
Reference: [2] <author> Thomas Anderson et al. </author> <title> Scheduler activations: Effective kernel support for the user-level management of parallelism. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 95-109, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Examples of such work can be found in <ref> [3, 10, 9, 14, 2] </ref>. 8 Conclusion We have shown that autoscheduling can be efficiently implemented in a shared memory multiprocessor based on commercial microprocessors.
Reference: [3] <author> Thomas Anderson, Edward Lazowska, and Henry Levy. </author> <title> The performance implications of thread management alternatives for shared-memory multiprocessors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(12), </volume> <month> December </month> <year> 1989. </year>
Reference-contexts: Examples of such work can be found in <ref> [3, 10, 9, 14, 2] </ref>. 8 Conclusion We have shown that autoscheduling can be efficiently implemented in a shared memory multiprocessor based on commercial microprocessors.
Reference: [4] <author> Carl J. Beckmann and Constantine D. Polychronopoulos. </author> <title> Microarchitecture support for dynamic scheduling of acyclic task graphs. </title> <booktitle> In Proceedings 25th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 140-148, </pages> <address> Portland, Oregon, December 1992. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference: [5] <author> William Blume and Rudolf Eigenmann. </author> <title> Performance analysis of parallelizing compilers on the Perfect Benchmarks programs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(6), </volume> <month> November </month> <year> 1992. </year>
Reference-contexts: Dynamic allocation of activation frames is necessary to support reentrant code, recursion and (most important in our case) concurrency. Variable privatization has been demonstrated to be an important feature for parallelization of programs <ref> [5] </ref>. To implement variable privatization with static allocation, it is necessary to expand the loop local variables by adding one dimension to their structure, and distributing them among the processors along that dimension. The major 10 disadvantage of doing this is that the maximum number of processors must be known.
Reference: [6] <author> Carl J. Beckmann. </author> <title> Hardware and Software for Functional and Fine Grain Parallelism. </title> <type> PhD thesis, </type> <institution> Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, </institution> <year> 1993. </year>
Reference-contexts: It is the information on control and data 2 dependences that allow the exploitation of functional (task level) parallelism, in addition to data (loop level) parallelism. The definitions, properties, and construction mechanism of the HTG presented here are from <ref> [21, 11, 16, 6] </ref>. The hierarchical task graph is a directed acyclic graph HT G = (HV; HE) with unique nodes START and STOP 2 HV . <p> The candidates are all the nodes that are data and control dependent on node k, plus all the nodes that are data dependent on nodes bypassed by branch l, minus those nodes bypassed by branch l <ref> [6] </ref>. Let T G be a given task graph (a certain level of an HTG) with n nodes. A bit-vector DONE [1::n] is used to represent the data dependences. DONE [i] is set to TRUE whenever the data dependences originating from node x i are satisfied. <p> To minimize accesses to shared memory, DONE and CONT are packed into one bit-vector SATISFIED [1::2n] which can be stored in a single word. SATISFIED [1::n] = DONE [1::n], and SATISFIED [n + 1::2n] = CONT [1::n]. The algorithms described in <ref> [6] </ref> can be used to minimize the number of bits necessary for each task graph in a program and to guarantee that any bit-vector will fit in one word. <p> The theoretical foundations for autoscheduling were developed in [12, 16]. The functions of the entry and exit blocks, and a method for granularity control, were defined in [21]. Efficient implementation schemes for the scheduling operations and algorithms for optimizing the HTG are presented in <ref> [6] </ref>. The motivation to exploit functional parallelism comes from measurements of the dynamic behavior of programs, such as those in [7, 19], in which large amounts of parallelism have been found beyond that available from totally parallel loops alone.
Reference: [7] <author> Ding-Kai Chen. </author> <title> MaxPar: An execution driven simulator for studying parallel systems. </title> <type> Master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <month> October </month> <year> 1989. </year>
Reference-contexts: Efficient implementation schemes for the scheduling operations and algorithms for optimizing the HTG are presented in [6]. The motivation to exploit functional parallelism comes from measurements of the dynamic behavior of programs, such as those in <ref> [7, 19] </ref>, in which large amounts of parallelism have been found beyond that available from totally parallel loops alone. Another effort to exploit functional parallelism is described in [23], where scheduling and allocation algorithms for the exploitation of functional parallelism on distributed memory machines are developed.
Reference: [8] <author> David E. Culler et al. </author> <title> Fine-grain Parallelism with Minimal Hardware Support: A Compiler-Controlled Threaded Abstract Machine. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-IV). </booktitle> <address> April 8-11, 1991. Santa Clara, CA, </address> <pages> pages 164-175, </pages> <year> 1991. </year>
Reference: [9] <author> Richard Draves et al. </author> <title> Using continuations to implement thread management and communication in operating systems. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 122-136, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Examples of such work can be found in <ref> [3, 10, 9, 14, 2] </ref>. 8 Conclusion We have shown that autoscheduling can be efficiently implemented in a shared memory multiprocessor based on commercial microprocessors.
Reference: [10] <author> Derek Eager and John Zahorjan. Chores: </author> <title> Enhanced run-time support for shared-memory parallel computing. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(1), </volume> <month> February </month> <year> 1993. </year> <month> 15 </month>
Reference-contexts: Examples of such work can be found in <ref> [3, 10, 9, 14, 2] </ref>. 8 Conclusion We have shown that autoscheduling can be efficiently implemented in a shared memory multiprocessor based on commercial microprocessors.
Reference: [11] <author> M. Girkar and C. D. Polychronopoulos. </author> <title> The HTG: An intermediate representation for programs based on control and data dependences. </title> <type> Technical Report 1046, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: It is the information on control and data 2 dependences that allow the exploitation of functional (task level) parallelism, in addition to data (loop level) parallelism. The definitions, properties, and construction mechanism of the HTG presented here are from <ref> [21, 11, 16, 6] </ref>. The hierarchical task graph is a directed acyclic graph HT G = (HV; HE) with unique nodes START and STOP 2 HV .
Reference: [12] <author> Milind Girkar and Constantine Polychronopoulos. </author> <title> Automatic detection and generation of unstructured parallelism in ordinary programs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(2), </volume> <month> April </month> <year> 1992. </year>
Reference-contexts: We present related work in Section 7, and our concluding remarks in Section 8. 2 The Autoscheduling Model of Computation The approach discussed here is based on the autoscheduling abstract architectural model of [21]. This model uses the hierarchical task graph <ref> [12] </ref> of a program (described below) as its execution vehicle. The efficiency in scheduling provided by the drive code and the ability to control the size of parallel tasks at run-time, allow an autoscheduled program to adjust to varying execution-time conditions, which is particularly important in multiprogramming environments. <p> The theoretical foundations for autoscheduling were developed in <ref> [12, 16] </ref>. The functions of the entry and exit blocks, and a method for granularity control, were defined in [21]. Efficient implementation schemes for the scheduling operations and algorithms for optimizing the HTG are presented in [6].
Reference: [13] <author> Evangelos Markatos. </author> <title> Scheduling for Locality in Shared-Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Rochester, </institution> <year> 1993. </year>
Reference: [14] <author> Brian Marsh et al. </author> <title> First-class user-level threads. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 110-121, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: Examples of such work can be found in <ref> [3, 10, 9, 14, 2] </ref>. 8 Conclusion We have shown that autoscheduling can be efficiently implemented in a shared memory multiprocessor based on commercial microprocessors.
Reference: [15] <author> Cathy McCann, Raj Vaswany, and John Zahorjan. </author> <title> A dynamic processor allocation policy for multiprogrammed shared-memory multiprocessors. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(2), </volume> <month> May </month> <year> 1993. </year>
Reference: [16] <author> Milind Girkar. </author> <title> Functional Parallelism: Theoretical Foundations and Implementation. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <year> 1992. </year>
Reference-contexts: It is the information on control and data 2 dependences that allow the exploitation of functional (task level) parallelism, in addition to data (loop level) parallelism. The definitions, properties, and construction mechanism of the HTG presented here are from <ref> [21, 11, 16, 6] </ref>. The hierarchical task graph is a directed acyclic graph HT G = (HV; HE) with unique nodes START and STOP 2 HV . <p> The theoretical foundations for autoscheduling were developed in <ref> [12, 16] </ref>. The functions of the entry and exit blocks, and a method for granularity control, were defined in [21]. Efficient implementation schemes for the scheduling operations and algorithms for optimizing the HTG are presented in [6].
Reference: [17] <author> Per Stenstrom. </author> <title> VLSI Support for Cactus Stack Oriented Memory Organization. </title> <booktitle> In Proceedings of the 21 st Annual Hawaii International Conference on System Sciences, </booktitle> <volume> vol I., </volume> <pages> pages 211-220, </pages> <year> 1988. </year>
Reference-contexts: Instead, a cactus-stack <ref> [17] </ref>, equivalent to a (dynamic) tree of activation frames, is used. 4 Implementation of Autoscheduling In this section we discuss the main issues regarding the implementation of autoscheduling in a general purpose shared memory multiprocessor.
Reference: [18] <author> Paul Petersen and David Padua. </author> <title> Machine independent evaluation of parallelizing compilers. </title> <type> Technical Report 1173, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <year> 1991. </year>
Reference: [19] <author> Paul Marx Petersen. </author> <title> Evaluation of Programs and Parallelizing Compilers Using Dynamic Analysis Techniques. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: Efficient implementation schemes for the scheduling operations and algorithms for optimizing the HTG are presented in [6]. The motivation to exploit functional parallelism comes from measurements of the dynamic behavior of programs, such as those in <ref> [7, 19] </ref>, in which large amounts of parallelism have been found beyond that available from totally parallel loops alone. Another effort to exploit functional parallelism is described in [23], where scheduling and allocation algorithms for the exploitation of functional parallelism on distributed memory machines are developed.
Reference: [20] <author> Constantine D. Polychronopoulos. </author> <title> On Program Restructuring, Scheduling, and Communications for Parallel Processor Systems. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> August </month> <year> 1986. </year>
Reference-contexts: part, long interruptions of execution. 11 4.7 Implementing DOALL Tasks Consider a DOALL task, normalized from doall I = START, FINISH, INC: LIMIT$ = floor ((FINISH-START)/INC) + 1 doall I$ = 1, LIMIT$, 1 I = (I$-1)*INC + START B end doall We use self-scheduling (SS) or guided self-scheduling (GSS) <ref> [20] </ref>) to distribute the iterations of this loop in P processors. The loop is implemented with three tasks: task S performs initialization of the iteration counter, and enqueues P instances of task L, and the corresponding activation frames, for execution. These instances of task L perform the loop iterations.
Reference: [21] <author> Constantine D. Polychronopoulos. Autoscheduling: </author> <title> Control flow and data flow come together. </title> <type> Technical Report 1058, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <year> 1990. </year>
Reference-contexts: We describe the compiler in Section 5, and in Section 6 we present some performance results. We present related work in Section 7, and our concluding remarks in Section 8. 2 The Autoscheduling Model of Computation The approach discussed here is based on the autoscheduling abstract architectural model of <ref> [21] </ref>. This model uses the hierarchical task graph [12] of a program (described below) as its execution vehicle. <p> It is the information on control and data 2 dependences that allow the exploitation of functional (task level) parallelism, in addition to data (loop level) parallelism. The definitions, properties, and construction mechanism of the HTG presented here are from <ref> [21, 11, 16, 6] </ref>. The hierarchical task graph is a directed acyclic graph HT G = (HV; HE) with unique nodes START and STOP 2 HV . <p> The theoretical foundations for autoscheduling were developed in [12, 16]. The functions of the entry and exit blocks, and a method for granularity control, were defined in <ref> [21] </ref>. Efficient implementation schemes for the scheduling operations and algorithms for optimizing the HTG are presented in [6].
Reference: [22] <author> Constantine D. Polychronopoulos et al. </author> <title> Parafrase-2: an environment for parallelizing, partitioning, synchronizing, and scheduling programs on multiprocessors. </title> <journal> International Journal of High Speed Computing, </journal> <volume> 1(1) </volume> <pages> 45-72, </pages> <year> 1989. </year>
Reference: [23] <author> Shankar Ramswamy and Prithviraj Banerjee. </author> <title> Processor allocation and scheduling of macro dataflow graphs on distributed memory multicomputers by the paradigm compiler. </title> <booktitle> In Proceedings of the 1993 International Conference on Parallel Processing, </booktitle> <pages> pages 134-138, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: The motivation to exploit functional parallelism comes from measurements of the dynamic behavior of programs, such as those in [7, 19], in which large amounts of parallelism have been found beyond that available from totally parallel loops alone. Another effort to exploit functional parallelism is described in <ref> [23] </ref>, where scheduling and allocation algorithms for the exploitation of functional parallelism on distributed memory machines are developed.
Reference: [24] <author> Vivek Sarkar. </author> <title> Automatic partitioning of a program dependence graph into parallel tasks. </title> <journal> IBM Journal of Research and Development, </journal> 35(5/6):779-804, September/October 1991. 
Reference-contexts: ..... ...... ...... ..... ...... ...... ..... ...... ...... ...... ..... ...... ...... ..... ...... ................. ................................ ................................ ................................. ................................ ................................ ................................ ................................ ................................ ................................ ................................. ................................ ................................ .. * * * * 7 Related Work The theory for construction and partitioning of a program dependence graph is presented in <ref> [25, 24] </ref>. The theoretical foundations for autoscheduling were developed in [12, 16]. The functions of the entry and exit blocks, and a method for granularity control, were defined in [21]. Efficient implementation schemes for the scheduling operations and algorithms for optimizing the HTG are presented in [6].
Reference: [25] <author> Vivek Sarkar and David Cann. </author> <title> POSC a partitioning and optimizing SISAL compiler. </title> <booktitle> In Proceedings of the International Conference on Supercomputing, </booktitle> <pages> pages 148-163, </pages> <year> 1990. </year>
Reference-contexts: ..... ...... ...... ..... ...... ...... ..... ...... ...... ...... ..... ...... ...... ..... ...... ................. ................................ ................................ ................................. ................................ ................................ ................................ ................................ ................................ ................................ ................................. ................................ ................................ .. * * * * 7 Related Work The theory for construction and partitioning of a program dependence graph is presented in <ref> [25, 24] </ref>. The theoretical foundations for autoscheduling were developed in [12, 16]. The functions of the entry and exit blocks, and a method for granularity control, were defined in [21]. Efficient implementation schemes for the scheduling operations and algorithms for optimizing the HTG are presented in [6].
Reference: [26] <author> Dale A. Schouten. </author> <title> Design and Implementation of Autoscheduled Threads. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> August </month> <year> 1994. </year> <note> In preparation. </note>
Reference-contexts: processors allocated to the program at the time we start executing the compound task: mode = 8 &gt; &gt; : 1 otherwise where Q n is the number of tasks in the queue, P is the number of processors currently allocated to the program, and ff is a given threshold <ref> [26] </ref>. In general, the best value for ff will be machine and application dependent. 4.6 Activation Frames All the data structures used during program execution are stored in dynamically allocated activation frames.
Reference: [27] <author> M. Weiss, Z. Fhang, C. R. Morgan, and P. </author> <title> Belmont. Dynamic scheduling and memory management for parallel programs. </title> <booktitle> In Proceedings of the 1988 International Conference on Parallel Processing, </booktitle> <volume> volume II, </volume> <pages> pages 161-165, </pages> <month> August </month> <year> 1988. </year> <month> 16 </month>
References-found: 27

