URL: ftp://ftp.ai.sri.com/pub/papers/fua-leclerc-ijcv93.ps.gz
Refering-URL: http://www.ai.sri.com/~leclerc/meshes/
Root-URL: 
Email: (fua@ai.sri.com leclerc@ai.sri.com)  
Title: Object-Centered Surface Reconstruction: Combining Multi-Image Stereo and Shading  
Author: P. Fua and Y. G. Leclerc 
Address: 333 Ravenswood Avenue, Menlo Park, CA 94025  
Affiliation: SRI International  
Abstract: Our goal is to reconstruct both the shape and reflectance properties of surfaces from multiple images. We argue that an object-centered representation is most appropriate for this purpose because it naturally accommodates multiple sources of data, multiple images (including motion sequences of a rigid object), and self-occlusions. We then present a specific object-centered reconstruction method and its implementation. The method begins with an initial estimate of surface shape provided, for example, by triangulating the result of conventional stereo. The surface shape and reflectance properties are then iteratively adjusted to minimize an objective function that combines information from multiple input images. The objective function is a weighted sum of stereo, shading, and smoothness components, where the weight varies over the surface. For example, the stereo component is weighted more strongly where the surface projects onto highly textured areas in the images, and less strongly otherwise. Thus, each component has its greatest influence where its accuracy is likely to be greatest. Experimental results on both synthetic and real images are presented. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Abbot, A. L. and Ahuja, N. </author> <year> (1990). </year> <title> Active surface reconstruction by integrating focus, vergence, stereo, and camera calibration. </title> <booktitle> In International Conference on Computer Vision, </booktitle> <pages> pages 489-492. </pages>
Reference-contexts: Others have combined sources of information, such as shading and texture (Choe and Kashyap 1991), focus, vergence, stereo, and camera calibration <ref> (Abbot and Ahuja 1990) </ref>. See (Aloimonos 1989) for further discussions on information fusion.
Reference: <author> Aloimonos, J. Y. </author> <year> (1989). </year> <title> Unification and integration of visual modules: an extension of the Marr paradigm. </title> <booktitle> In ARPA Image Understanding Workshop, </booktitle> <pages> pages 507-551. </pages>
Reference-contexts: Others have combined sources of information, such as shading and texture (Choe and Kashyap 1991), focus, vergence, stereo, and camera calibration (Abbot and Ahuja 1990). See <ref> (Aloimonos 1989) </ref> for further discussions on information fusion.
Reference: <author> Asada, M., Kimura, M., Taniguchi, Y., and Shirai, Y. </author> <year> (1992). </year> <title> Dynamic integration of height maps into a 3D world representation from range image sequences. </title> <journal> International Journal of Computer Vision, </journal> <volume> 9(1), </volume> <pages> 31-54. </pages>
Reference-contexts: These view-centered surface representations have been the basis for quite successful systems for recovering shape and surface properties. Some have used single sources of information, such as sequences of range 2 data or intensity images <ref> (Asada et al. 1992, Hung et al. 1991) </ref>, stereo (Diehl and Heipke 1992, Kaiser et al. 1992, Witkin et al. 1987, Wrobel 1991), and shading (Hartt and Carlotto 1989, Horn 1990, Terzopoulos 1988).
Reference: <author> Baltsavias, E. P. </author> <year> (1991). </year> <title> Multiphoto Geometrically Constrained Matching. </title> <type> Ph.D. thesis, </type> <institution> Institute for Geodesy and Photgrammetry, ETH Zurich. </institution>
Reference-contexts: The projection of an arbitrary point x = (x; y; z) in space into image g i is denoted m i (x). There are well-known methods for correcting both geometric and radiometric errors in images, as surveyed in <ref> (Baltsavias 1991) </ref>. Thus, we assume that all effects of lens distortion and the like have been taken care of in producing the input images, so that the projection of a surface into an image is well modeled by a perspective projection.
Reference: <author> Barnard, S. </author> <year> (1989). </year> <title> Stochastic stereo matching over scale. </title> <journal> International Journal of Computer Vision, </journal> <volume> 3(1), </volume> <pages> 17-32. </pages>
Reference: <author> Barrow, H. G. and Tenenbaum, J. M. </author> <year> (1978). </year> <title> Recovering intrinsic scene characteristics from images. </title> <booktitle> In Computer Vision Systems, </booktitle> <pages> pages 3-26, </pages> <publisher> Academic Press, </publisher> <address> New York, New York. </address>
Reference-contexts: Initially, much of the work concentrated on 2 1 2 -D image-centered reconstructions, such as Barrow and Tenenbaum's Intrinsic Images <ref> (Barrow and Tenenbaum 1978) </ref> and Marr's 2 1 2 -D Sketch (Marr 1982). These view-centered surface representations have been the basis for quite successful systems for recovering shape and surface properties.
Reference: <author> Blake, A., Zisserman, A., and Knowles, G. </author> <year> (1985). </year> <title> Surface descriptions from stereo and shading. </title> <journal> Image Vision Computation, </journal> <volume> 3(4), </volume> <pages> 183-191. </pages>
Reference-contexts: Consequently, the natural choice for the monocular information source is shading, while intensity is the natural choice for the image feature used in multi-image correspondence. Not only are these the natural choices given a Lambertian reflectance model, they are also complementary <ref> (Blake et al. 1985, Leclerc and Bobick 1991) </ref>: intensity correlation is most accurate wherever the input images are highly textured, whereas shading is most accurate where the input images are untextured.
Reference: <author> Choe, Y. and Kashyap, R. L. </author> <year> (1991). </year> <title> 3-d shape from a shaded and textural surface image. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13, </volume> <pages> 907-919. </pages>
Reference-contexts: Others have combined sources of information, such as shading and texture <ref> (Choe and Kashyap 1991) </ref>, focus, vergence, stereo, and camera calibration (Abbot and Ahuja 1990). See (Aloimonos 1989) for further discussions on information fusion.
Reference: <author> Cohen, I., Cohen, L. D., and Ayache, N. </author> <year> (1991). </year> <title> Introducing new deformable surfaces to segment 3D images. </title> <booktitle> In Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 738-739. </pages>
Reference: <author> Cryer, J. E., Tsai, P.-S., and Shah, M. </author> <year> (1992). </year> <title> Combining shape from shading and stereo using human vision model. </title> <type> Technical Report CS-TR-92-25, </type> <institution> U. Central Florida. </institution>
Reference: <author> Delingette, H., Hebert, M., and Ikeuchi, K. </author> <year> (1991). </year> <title> Shape representation and image segmentation using deformable surfaces. </title> <booktitle> In Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 467-472. </pages> <note> 33 Diehl, </note> <author> H. and Heipke, C. </author> <year> (1992). </year> <title> Surface reconstruction from data of digital line cameras by means of object based image matching. </title> <booktitle> In International Society for Photogrammetry and Remote Sensing, </booktitle> <pages> pages 287-294, </pages> <address> Washington D.C. </address>
Reference: <author> Faugeras, O. and Toscani, G. </author> <year> (1986). </year> <title> The calibration problem for stereo. </title> <booktitle> In Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 15-20, </pages> <address> Miami Beach, Florida. </address>
Reference-contexts: In this case, because the illumination in each image is different and there are very few bland areas, the shape-from-shading term actually degrades the result. 5.2.2 Face Images In Figure 8 we show two triplets of images of faces. They have been produced using the INRIA three-camera system <ref> (Faugeras and Toscani 1986) </ref> that provides us with the camera models we need to perform our computations. In this case it is essential to have more than two images to be able to reconstruct both sides of the face because of self-occlusions.
Reference: <author> Ferrie, F. P., Lagarde, J., and Whaite, P. </author> <year> (1992). </year> <title> Recovery of volumetric object descriptions from laser rangefinder images. </title> <booktitle> In European Conference on Computer Vision, </booktitle> <address> Genoa, Italy. </address>
Reference-contexts: See (Aloimonos 1989) for further discussions on information fusion. More recently, full 3-D representations have been used, such as 3-D surface meshes (Terzopoulos and Vasilescu 1991, Vemuri and Malladi 1991), parameterized surfaces (Stokely and Wu 1992, Lowe 1991), local surfaces <ref> (Ferrie et al. 1992, Fua and Sander 1992) </ref>, particle systems (Szeliski and Tonnesen 1992), and volumetric models (Pentland 1990, Terzopoulos and Metaxas 1991, Pentland and Sclaroff 1991).
Reference: <author> Fua, P. </author> <year> (1993). </year> <title> A parallel stereo algorithm that produces dense depth maps and preserves image features. Machine Vision and Applications, </title> <type> 6(1). </type> <note> Available as INRIA research report 1369. </note>
Reference-contexts: For the experiments described in this paper, we have derived this initial estimate using one of the various methods mentioned in Section 5. 8 The simplest one is to triangulate the smooth depth-map generated by the correlation-based stereo algorithm described in <ref> (Fua 1993) </ref>. 4.1 Images and Camera Models In this paper, we assume that images are monochrome, and that their camera models are known a priori. The set of gray-level images is denoted G = (g 1 ; g 2 ; : : : ; g n g ). <p> Standard correlation-based techniques can provide starting points that have the required properties. For example, the specific algorithm we use in this paper <ref> (Fua 1993) </ref> has been shown to find few false matches and to yield a precision in the order of one pixel in disparity in the areas where it finds relatively dense matches. 5 Behavior of the Ob jective Function and Results We first illustrate the behavior of the complete objective function <p> For each triplet, we have computed disparity maps corresponding to images 1 and 2 and to images 1 and 3 and combined them to produce the depth maps shown in the rightmost column of the figure using the algorithms described in <ref> (Fua 1993) </ref>. Triplet 1 Disparities Triplet 2 Disparities 26 (a) (b) (c) (d) by smoothing and triangulating the computed disparity map.
Reference: <author> Fua, P. and Leclerc, Y. G. </author> <year> (1990). </year> <title> Model driven edge detection. </title> <journal> Machine Vision and Applications, </journal> <volume> 3, </volume> <pages> 45-56. </pages>
Reference-contexts: Thus, the user can more easily specify the relative contributions of each component in an image-independent fashion. This normalization scheme was used with great success in <ref> (Fua and Leclerc 1990) </ref>, and is analogous to standard constrained optimization techniques in which the various constraints are scaled so that their eigenvalues have comparable magnitudes (Luenberger 1984).
Reference: <author> Fua, P. and Sander, P. </author> <year> (1992). </year> <title> Segmenting unstructured 3d points into surfaces. </title> <booktitle> In European Conference on Computer Vision, </booktitle> <address> Genoa, Italy. </address>
Reference-contexts: See (Aloimonos 1989) for further discussions on information fusion. More recently, full 3-D representations have been used, such as 3-D surface meshes (Terzopoulos and Vasilescu 1991, Vemuri and Malladi 1991), parameterized surfaces (Stokely and Wu 1992, Lowe 1991), local surfaces <ref> (Ferrie et al. 1992, Fua and Sander 1992) </ref>, particle systems (Szeliski and Tonnesen 1992), and volumetric models (Pentland 1990, Terzopoulos and Metaxas 1991, Pentland and Sclaroff 1991). <p> 2 -D representations, those employing 3-D representations have used a variety of single image cues for reconstruction, such as silhouettes and image features (Cohen et al. 1991, Delingette et al. 1991, Terzopoulos et al. 1987, Tomasi and Kanade 1992, Wang and Wang 1992), range data (Whaite and Ferrie 1991), stereo <ref> (Fua and Sander 1992) </ref>, and motion (Szeliski 1991). Liedtke et al. (1991) first uses silhouettes to derive an initial estimate of the surface, and then uses a multi-image stereo algorithm to improve on the result. <p> These facets tend to form hexagons and can be used to construct virtually arbitrary surfaces. Finally, standard triangulation algorithms can be used to generate such a surface from noisy real data <ref> (Fua and Sander 1992, Szeliski and Tonnesen 1992) </ref>. 3.2 Material Properties and Their Representation Objects in the world are composed of many types of material, and the material type can vary across the object's surface in many ways. <p> For each triplet, we have computed a correlation map. We have then used the technique described in <ref> (Fua and Sander 1992) </ref> to merge the resulting 3-D points and generate a Delaunay triangulation. Because the tops of some of the rocks are sharply slanted, the result is relatively rough and can be refined using our technique.
Reference: <author> Grimson, W. E. L. and Huttenlocher, D. P. </author> <year> (1992). </year> <title> Introduction to the special issue on interpretation of 3-d scenes. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(2), </volume> <pages> 97-98. </pages>
Reference: <author> Hannah, M. J. </author> <year> (1989). </year> <title> A system for digital stereo image matching. </title> <journal> Photogrammetric Engineering and Remote Sensing, </journal> <volume> 55(12), </volume> <pages> 1765-1770. </pages>
Reference: <author> Hartt, K. and Carlotto, M. </author> <year> (1989). </year> <title> A method for shape-from-shading using multiple images acquired under different viewing and lighting conditions. </title> <booktitle> In Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 53-60. </pages>
Reference-contexts: Some have used single sources of information, such as sequences of range 2 data or intensity images (Asada et al. 1992, Hung et al. 1991), stereo (Diehl and Heipke 1992, Kaiser et al. 1992, Witkin et al. 1987, Wrobel 1991), and shading <ref> (Hartt and Carlotto 1989, Horn 1990, Terzopoulos 1988) </ref>. Others have combined sources of information, such as shading and texture (Choe and Kashyap 1991), focus, vergence, stereo, and camera calibration (Abbot and Ahuja 1990). See (Aloimonos 1989) for further discussions on information fusion.
Reference: <author> Heipke, C. </author> <year> (1992). </year> <title> Integration of digital image matching and multi image shape from shading. </title> <booktitle> In International Society for Photogrammetry and Remote Sensing, </booktitle> <pages> pages 832-841, </pages> <address> Washington D.C. </address>
Reference: <author> Horn, B. K. P. </author> <year> (1990). </year> <title> Height and gradient from shading. </title> <journal> International Journal of Computer Vision, </journal> <volume> 5(1), </volume> <pages> 37-75. </pages>
Reference: <author> Hung, Y., Cooper, D. B., and Cernuschi-Frias, B. </author> <year> (1991). </year> <title> Asymptotic bayesian surface estimation using an image sequence. </title> <journal> International Journal of Computer Vision, </journal> <volume> 6(2), </volume> <pages> 105-132. </pages>
Reference: <author> Kaiser, B., Schmolla, M., and Wrobel, B. P. </author> <year> (1992). </year> <title> Application of image pyramid for surface reconstruction with fast vision. </title> <booktitle> In International Society for Photogrammetry and Remote Sensing, </booktitle> <pages> page 1, </pages> <address> Washington, D.C. </address>
Reference: <author> Kanade, T. and Okutomi, M. </author> <year> (1990). </year> <title> A stereo matching algorithm with an adaptative window: Theory and experiment. </title> <booktitle> In ARPA Image Understanding Workshop. </booktitle>
Reference-contexts: Consequently, the reconstruction can be significantly more accurate for slanted surfaces. Some correlation-based algorithms achieve similar results by using variable-shaped windows in the images. Control Data's work (Panton 1978), the Hierarchical Warp Stereo System (Quam 1984), Nishihara's real-time stereo matcher (1984), and the adaptative windows technique described in <ref> (Kanade and Okutomi 1990) </ref> are examples of such methods. However, they typically use only image-centered representations of the surface. As for the monocular information source, we have chosen to use shading. There are a 6 number of reasons for this.
Reference: <author> Kass, M., Witkin, A., and Terzopoulos, D. </author> <year> (1988). </year> <title> Snakes: Active contour models. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1(4), </volume> <pages> 321-331. </pages>
Reference-contexts: Note that this term is also equivalent to the squared directional curvature of the surface when the sides have approximately equal lengths <ref> (Kass et al. 1988) </ref>.
Reference: <author> Leclerc, Y. G. </author> <year> (1989a). </year> <title> Constructing simple stable descriptions for image partitioning. </title> <journal> International Journal of Computer Vision, </journal> <volume> 3(1), </volume> <pages> 73-102. </pages>
Reference: <author> Leclerc, Y. G. </author> <year> (1989b). </year> <title> The Local Structure of Image Intensity Discontinuities. </title> <type> Ph.D. thesis, </type> <institution> McGill University, </institution> <address> Montreal, Quebec, Canada. </address>
Reference: <author> Leclerc, Y. G. and Bobick, A. F. </author> <year> (1991). </year> <title> The direct computation of height from shading. </title> <booktitle> In Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Lahaina, Maui, Hawaii. </address>
Reference-contexts: We overcome this limitation by improving upon a method to deal with discontinu-ities in albedo alluded to in the summary of <ref> (Leclerc and Bobick 1991) </ref>. We compute the albedo at each facet using the normal to the facet, a light-source direction, and the average of the intensities projected onto the facet from all images. <p> In this paper, we assume that the ambient and direct illumination (i.e., a, b, and ! L ) are either given or estimated from the initial surface and images, as was done in <ref> (Leclerc and Bobick 1991) </ref>. The average intensity g k of a facet is computed by scanning over all the Facet-ID images for index k, and taking the average of the intensities at matching points in the corresponding images.
Reference: <author> Liedtke, C. E., Busch, H., and Koch, R. </author> <year> (1991). </year> <title> Shape adaptation for modelling of 3D objects in natural scenes. </title> <booktitle> In Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 704-705. </pages>
Reference: <author> Lowe, D. G. </author> <year> (1991). </year> <title> Fitting parameterized three-dimensional models to images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <pages> 13(441-450). </pages>
Reference: <author> Luenberger, D. G. </author> <year> (1984). </year> <title> Linear and Nonlinear Programming. </title> <publisher> Addison-Wesley, </publisher> <address> Menlo Park, California, </address> <note> second edition. </note>
Reference-contexts: This normalization scheme was used with great success in (Fua and Leclerc 1990), and is analogous to standard constrained optimization techniques in which the various constraints are scaled so that their eigenvalues have comparable magnitudes <ref> (Luenberger 1984) </ref>. As mentioned earlier, the c k weights are a function of the degree of texturing in the intensities projected within a facet f k .
Reference: <author> Marr, D. </author> <year> (1982). </year> <title> Vision. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> San Francisco, California. </address>
Reference-contexts: Initially, much of the work concentrated on 2 1 2 -D image-centered reconstructions, such as Barrow and Tenenbaum's Intrinsic Images (Barrow and Tenenbaum 1978) and Marr's 2 1 2 -D Sketch <ref> (Marr 1982) </ref>. These view-centered surface representations have been the basis for quite successful systems for recovering shape and surface properties.
Reference: <author> Nishihara, H. </author> <year> (1984). </year> <title> Practical real-time imaging stereo matcher. </title> <journal> Optical Engineering, </journal> <volume> 23(5). </volume>
Reference: <author> Okutomi, M. and Kanade, T. </author> <year> (1991). </year> <title> A multiple-baseline stereo. </title> <booktitle> In Computer Vision and Pattern Recognition 91, </booktitle> <pages> pages 63-69, </pages> <address> Maui, Hawaii. </address>
Reference: <author> Oren, M. and Nayar, S. </author> <year> (1993). </year> <title> Generalization of the lambertian model. </title> <booktitle> In ARPA Image Understanding Workshop, </booktitle> <pages> pages 1037-1048. </pages>
Reference: <author> Panton, D. J. </author> <year> (1978). </year> <title> A flexible approach to digital stereo mapping. </title> <journal> Photogramm. Eng. Remote Sensing, </journal> <volume> 44(12), </volume> <pages> 1499-1512. </pages>
Reference-contexts: Instead, we compare the intensities as projected onto the facets of the surface. Consequently, the reconstruction can be significantly more accurate for slanted surfaces. Some correlation-based algorithms achieve similar results by using variable-shaped windows in the images. Control Data's work <ref> (Panton 1978) </ref>, the Hierarchical Warp Stereo System (Quam 1984), Nishihara's real-time stereo matcher (1984), and the adaptative windows technique described in (Kanade and Okutomi 1990) are examples of such methods. However, they typically use only image-centered representations of the surface.
Reference: <author> Pentland, A. </author> <year> (1990). </year> <title> Automatic extraction of deformable part models. </title> <journal> International Journal of Computer Vision, </journal> <volume> 4(2), </volume> <pages> 107-126. </pages> <note> 35 Pentland, </note> <author> A. and Sclaroff, S. </author> <year> (1991). </year> <title> Closed-form solutions for physically based shape mod-eling and recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13, </volume> <pages> 715-729. </pages>
Reference-contexts: More recently, full 3-D representations have been used, such as 3-D surface meshes (Terzopoulos and Vasilescu 1991, Vemuri and Malladi 1991), parameterized surfaces (Stokely and Wu 1992, Lowe 1991), local surfaces (Ferrie et al. 1992, Fua and Sander 1992), particle systems (Szeliski and Tonnesen 1992), and volumetric models <ref> (Pentland 1990, Terzopoulos and Metaxas 1991, Pentland and Sclaroff 1991) </ref>.
Reference: <author> Poggio, T., Torre, V., and Koch, C. </author> <year> (1985). </year> <title> Computational vision and regularization theory. </title> <booktitle> Nature, </booktitle> <pages> 317. </pages>
Reference-contexts: Otherwise, there would be significant ambiguity in the correspondence of pixels across the images. Differences in radiometry, however, can be accommodated by first band-passing the images <ref> (Poggio et al. 1985, Barnard 1989) </ref>. In contrast to our approach, traditional correlation-based stereo methods use fixed-size windows in images to measure disparities, which will in general yield correct results only when the surface is parallel to the image plane.
Reference: <author> Press, W., Flannery, B., Teukolsky, S., and Vetterling, W. </author> <year> (1986). </year> <title> Numerical Recipes, </title> <booktitle> the Art of Scientific Computing. </booktitle> <address> Cambridge U. </address> <publisher> Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: We first fix 16 the x and y coordinates of vertices and adjust z alone. Once the surface has been optimized, we then allow all of the coordinates to vary simultaneously. The optimization procedure we use at every stage is a standard conjugate-gradient descent procedure called FRPRMN (from <ref> (Press et al. 1986) </ref>) in conjunction with a simple line-search algorithm.
Reference: <author> Quam, L. </author> <year> (1984). </year> <title> Hierarchical warp stereo. </title> <booktitle> In ARPA Image Understanding Workshop, </booktitle> <pages> pages 149-155. </pages>
Reference-contexts: Instead, we compare the intensities as projected onto the facets of the surface. Consequently, the reconstruction can be significantly more accurate for slanted surfaces. Some correlation-based algorithms achieve similar results by using variable-shaped windows in the images. Control Data's work (Panton 1978), the Hierarchical Warp Stereo System <ref> (Quam 1984) </ref>, Nishihara's real-time stereo matcher (1984), and the adaptative windows technique described in (Kanade and Okutomi 1990) are examples of such methods. However, they typically use only image-centered representations of the surface. As for the monocular information source, we have chosen to use shading.
Reference: <author> Stokely, E. M. and Wu, S. Y. </author> <year> (1992). </year> <title> Surface parameterization and curvature measurement of arbitrary 3-d objects: five practical methods. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(8), </volume> <pages> 833-839. </pages>
Reference-contexts: See (Aloimonos 1989) for further discussions on information fusion. More recently, full 3-D representations have been used, such as 3-D surface meshes (Terzopoulos and Vasilescu 1991, Vemuri and Malladi 1991), parameterized surfaces <ref> (Stokely and Wu 1992, Lowe 1991) </ref>, local surfaces (Ferrie et al. 1992, Fua and Sander 1992), particle systems (Szeliski and Tonnesen 1992), and volumetric models (Pentland 1990, Terzopoulos and Metaxas 1991, Pentland and Sclaroff 1991).
Reference: <author> Szeliski, R. </author> <year> (1991). </year> <title> Shape from rotation. </title> <booktitle> In Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 625-630. </pages>
Reference-contexts: representations have used a variety of single image cues for reconstruction, such as silhouettes and image features (Cohen et al. 1991, Delingette et al. 1991, Terzopoulos et al. 1987, Tomasi and Kanade 1992, Wang and Wang 1992), range data (Whaite and Ferrie 1991), stereo (Fua and Sander 1992), and motion <ref> (Szeliski 1991) </ref>. Liedtke et al. (1991) first uses silhouettes to derive an initial estimate of the surface, and then uses a multi-image stereo algorithm to improve on the result.
Reference: <author> Szeliski, R. and Tonnesen, D. </author> <year> (1992). </year> <title> Surface modeling with oriented particle systems. </title> <booktitle> In Computer Graphics (SIGGRAPH'92), </booktitle> <pages> pages 185-194. </pages>
Reference-contexts: More recently, full 3-D representations have been used, such as 3-D surface meshes (Terzopoulos and Vasilescu 1991, Vemuri and Malladi 1991), parameterized surfaces (Stokely and Wu 1992, Lowe 1991), local surfaces (Ferrie et al. 1992, Fua and Sander 1992), particle systems <ref> (Szeliski and Tonnesen 1992) </ref>, and volumetric models (Pentland 1990, Terzopoulos and Metaxas 1991, Pentland and Sclaroff 1991). <p> These facets tend to form hexagons and can be used to construct virtually arbitrary surfaces. Finally, standard triangulation algorithms can be used to generate such a surface from noisy real data <ref> (Fua and Sander 1992, Szeliski and Tonnesen 1992) </ref>. 3.2 Material Properties and Their Representation Objects in the world are composed of many types of material, and the material type can vary across the object's surface in many ways.
Reference: <author> Terzopoulos, D. </author> <year> (1986). </year> <title> Regularization of inverse visual problems involving discontinuities. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 8, </volume> <pages> 413-424. </pages>
Reference-contexts: Consequently, we use an optimization method that is inspired by the heuristic technique known as a continuation method <ref> (Terzopoulos 1986, Leclerc 1989a, Leclerc 1989b, Leclerc and Bobick 1991) </ref>.
Reference: <author> Terzopoulos, D. </author> <year> (1988). </year> <title> The computation of visible-surface representations. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> , <pages> 417-438. </pages>
Reference: <author> Terzopoulos, D. and Metaxas, D. </author> <year> (1991). </year> <title> Dynamic 3D models with local and global deformations: Deformable superquadrics. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <pages> 13(703-714). </pages>
Reference-contexts: Others have combined sources of information, such as shading and texture (Choe and Kashyap 1991), focus, vergence, stereo, and camera calibration (Abbot and Ahuja 1990). See (Aloimonos 1989) for further discussions on information fusion. More recently, full 3-D representations have been used, such as 3-D surface meshes <ref> (Terzopoulos and Vasilescu 1991, Vemuri and Malladi 1991) </ref>, parameterized surfaces (Stokely and Wu 1992, Lowe 1991), local surfaces (Ferrie et al. 1992, Fua and Sander 1992), particle systems (Szeliski and Tonnesen 1992), and volumetric models (Pentland 1990, Terzopoulos and Metaxas 1991, Pentland and Sclaroff 1991).
Reference: <author> Terzopoulos, D. and Vasilescu, M. </author> <year> (1991). </year> <title> Sampling and reconstruction with adaptive meshes. </title> <booktitle> In Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 70-75. </pages>
Reference-contexts: Others have combined sources of information, such as shading and texture (Choe and Kashyap 1991), focus, vergence, stereo, and camera calibration (Abbot and Ahuja 1990). See (Aloimonos 1989) for further discussions on information fusion. More recently, full 3-D representations have been used, such as 3-D surface meshes <ref> (Terzopoulos and Vasilescu 1991, Vemuri and Malladi 1991) </ref>, parameterized surfaces (Stokely and Wu 1992, Lowe 1991), local surfaces (Ferrie et al. 1992, Fua and Sander 1992), particle systems (Szeliski and Tonnesen 1992), and volumetric models (Pentland 1990, Terzopoulos and Metaxas 1991, Pentland and Sclaroff 1991).
Reference: <author> Terzopoulos, D., Witkin, A., and Kass, M. </author> <year> (1987). </year> <title> Symmetry-seeking models and 3D object reconstruction. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1, </volume> <pages> 211-221. </pages>
Reference: <author> Tomasi, C. and Kanade, T. </author> <year> (1992). </year> <title> The factorization method for the recovery of shape and motion from image streams. </title> <booktitle> In ARPA Image Understanding Workshop, </booktitle> <pages> pages 459-472. </pages>
Reference: <author> Vemuri, B. C. and Malladi, R. </author> <year> (1991). </year> <title> Deformable models: Canonical parameters for surface representation and multiple view integration. </title> <booktitle> In Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 724-725. </pages> <note> 36 Wang, </note> <author> Y. F. and Wang, J. F. </author> <year> (1992). </year> <title> Surface reconstruction using deformable models with interior and boundary constraints. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(5), </volume> <pages> 572-579. </pages>
Reference-contexts: Others have combined sources of information, such as shading and texture (Choe and Kashyap 1991), focus, vergence, stereo, and camera calibration (Abbot and Ahuja 1990). See (Aloimonos 1989) for further discussions on information fusion. More recently, full 3-D representations have been used, such as 3-D surface meshes <ref> (Terzopoulos and Vasilescu 1991, Vemuri and Malladi 1991) </ref>, parameterized surfaces (Stokely and Wu 1992, Lowe 1991), local surfaces (Ferrie et al. 1992, Fua and Sander 1992), particle systems (Szeliski and Tonnesen 1992), and volumetric models (Pentland 1990, Terzopoulos and Metaxas 1991, Pentland and Sclaroff 1991).
Reference: <author> Whaite, P. and Ferrie, F. P. </author> <year> (1991). </year> <title> From uncertainty to visual exploration. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <pages> 13(1038-1049). </pages>
Reference-contexts: the methods employing 2 1 2 -D representations, those employing 3-D representations have used a variety of single image cues for reconstruction, such as silhouettes and image features (Cohen et al. 1991, Delingette et al. 1991, Terzopoulos et al. 1987, Tomasi and Kanade 1992, Wang and Wang 1992), range data <ref> (Whaite and Ferrie 1991) </ref>, stereo (Fua and Sander 1992), and motion (Szeliski 1991). Liedtke et al. (1991) first uses silhouettes to derive an initial estimate of the surface, and then uses a multi-image stereo algorithm to improve on the result.
Reference: <author> Witkin, A. W., Terzopoulos, D., and Kass, M. </author> <year> (1987). </year> <title> Signal matching through scale space. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1, </volume> <pages> 133-144. </pages>
Reference: <author> Wrobel, B. P. </author> <year> (1991). </year> <title> The evolution of digital photgrammetry from analytical phogram-metry. </title> <journal> Photogrammetric Record, </journal> <volume> 13(77), </volume> <pages> 765-776. 37 </pages>
References-found: 53

