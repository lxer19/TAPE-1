URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1993/tr-93-072.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1993.html
Root-URL: http://www.icsi.berkeley.edu
Title: Software Protection and Simulation on Oblivious RAMs  
Author: Oded Goldreich Rafail Ostrovsky 
Address: Israel.  
Affiliation: Computer Sci. Dept., Technion, Haifa,  
Note: Partially supported by the Fund for Promotion of Research at the Technion; Current Addr:  
Pubnum: TR-93-072  
Email: e-mail: oded@cs.technion.AC.IL  
Date: November 1993  
Abstract: Software protection is one of the most important issues concerning computer practice. There exist many heuristics and ad-hoc methods for protection, but the problem as a whole has not received the theoretical treatment it deserves. In this paper we provide theoretical treatment of software protection 1 . We reduce the problem of software protection to the problem of efficient simulation on oblivious RAM. A machine is oblivious if the sequence in which it accesses memory locations is equivalent for any two inputs with the same running time. For example, an oblivious Turing Machine is one for which the movement of the heads on the tapes is identical for each computation. (Thus, it is independent of the actual input.) What is the slowdown in the running time of any machine, if it is required to be oblivious? In 1979 Pippenger and Fischer showed how a two-tape oblivious Turing Machine can simulate, on-line, a one-tape Turing Machine, with a logarithmic slowdown in the running time. We show an analogue result for the random-access machine (RAM) model of computation. In particular, we show how to do an on-line simulation of an arbitrary RAM input by a probabilistic oblivious RAM with a poly-logarithmic slowdown in the running time. On the other hand, we show that a logarithmic slowdown is a lower bound. y University of California at Berkeley Computer Science Division, and International Computer Science Institute at Berkeley. E-mail: rafail@melody.berkeley.edu. Supported by NSF postdoctoral fellowship and ICSI. Part of this work was done at MIT. 1 This paper unifies and extends abstracts of [G] and [Ost]. Applications of this work are described in 
Abstract-found: 1
Intro-found: 1
Reference: [AHU] <author> Aho, A.V., J.E. Hopcroft, and J.D. Ullman, </author> <title> "The Design and Analysis of Computer Algorithms" Addison-Wesley Publ. </title> <publisher> Co., </publisher> <year> 1974 </year>
Reference-contexts: Subsections 2.3 and 2.4 can be read independently of each other. 2.2 RAMs as interactive machines 2.2.1 The Basic Model Our concept of a RAM is the standard one (i.e., as presented in <ref> [AHU] </ref>). However, we decouple the RAM into two interactive machines, the CPU and the memory module, in order to explicitly discuss the interaction between the two.
Reference: [AKS] <author> Ajtai, M., J. Komlos, and E. </author> <title> Szemeredi "An O(n log n) Sorting Network" STOC 83. </title>
Reference-contexts: This is due to the simple structure of Batcher's network, which is uniform with respect to logarithmic space 6 . 6 The simplicity of Batcher sorting network is the main reason we prefer it (in practice) upon the asymptotically superior Ajtai-Komlos-Szemeredi sorting network <ref> [AKS] </ref>. 24 Next we specify how to access a virtual location i. Notice that after step (1), the virtual locations 1 through m + p m are sorted according to their tag (i.e. ()). Thus, we must access actual location which contains tag (i) when looking for virtual location i.
Reference: [ACGS] <author> Alexi, W., B Chor, O Goldreich, and C.P Schnorr, </author> <title> "RSA and Rabin Functions: Certain Parts Are As Hard As The Whole", </title> <note> SIAM Jour on Computing, Extended Abstract in Proc 25th FOCS, </note> <year> 1984. </year>
Reference: [Bat] <author> Batcher, K. </author> <booktitle> "Sorting Networks and their Applications" AFIPS Spring Joint Computer Conference 32, </booktitle> <year> 1968, </year> <pages> pp. 307-314. </pages>
Reference-contexts: Now we face the problem of obliviously sorting the t elements (by their tags). The crucial condition is that the RAM which executes the sorting can store only a fix number of values (say 2) at a time. The idea is to "implement" Batcher's Sorting Network <ref> [Bat] </ref>, which allows to sort t elements by t dlog 2 te 2 comparisons. Each comparison is "implemented" by accessing both corresponding words, reading their contents, and then writing these values back in the desired order.
Reference: [Be] <author> Best, R. </author> <title> "Microprocessor for Executing Encrypted Programs" US Patent 4,168396 Issued September 1979. </title>
Reference-contexts: Of course, the more hardware we must physically protect, the more expensive our solution is. Hence, we must also consider what is the minimal amount of the physically protected hardware we really need. 2 It has been suggested <ref> [Be, K] </ref> to protect software against duplication by selling a phys-ically shielded Central Processing Unit (CPU) together with an encrypted program (hereafter called the Software-Hardware-package or the SH-package). <p> We note that the technology to physically shield (at least to some degree) the CPU (which, in practice, is a single computer chip) does already exist indeed, every ATM bank machine has such a protected chip. Thus, the SH-package employs feasible software and hardware measures <ref> [Be, K] </ref>. Using encryption to keep the contents of the memory secret is certainly a step in the right direction. However, as we will shortly see, this does not provide the protection one may want.
Reference: [B] <author> M. Blum, </author> <title> "Designing programs to check their work" manuscript. </title>
Reference-contexts: We note that further work in this direction, dealing with a more powerful adversary was addressed in [SR]. Another application of our technique is for data-structure checking <ref> [B, BK, BEGKN] </ref>, where assuming that a data-structure has small reliable memory we can guarantee that it was not modified by an adversary. Acknowledgments We wish to thank many friends and colleagues for their contributions to this work and its presentation.
Reference: [BK] <author> M. Blum., and S. Kannan., </author> <title> "Program correctness checking... and the design of programs that check their work" STOC 89 </title>
Reference-contexts: We note that further work in this direction, dealing with a more powerful adversary was addressed in [SR]. Another application of our technique is for data-structure checking <ref> [B, BK, BEGKN] </ref>, where assuming that a data-structure has small reliable memory we can guarantee that it was not modified by an adversary. Acknowledgments We wish to thank many friends and colleagues for their contributions to this work and its presentation.
Reference: [BEGKN] <author> M. Blum, W. Evans, P. Gemmell, S. Kannan M. </author> <title> Naor "Checking the Correectness of Memories" FOCS 91. </title>
Reference-contexts: We note that further work in this direction, dealing with a more powerful adversary was addressed in [SR]. Another application of our technique is for data-structure checking <ref> [B, BK, BEGKN] </ref>, where assuming that a data-structure has small reliable memory we can guarantee that it was not modified by an adversary. Acknowledgments We wish to thank many friends and colleagues for their contributions to this work and its presentation.
Reference: [BM] <author> Blum, M., and S. Micali, </author> <title> "How to Generate Cryptographically Strong Sequences of Pseudorandom Bits", </title> <journal> SIAM J. on Comput., </journal> <volume> Vol. 13, </volume> <year> 1984, </year> <pages> pp. 850-864. 43 </pages>
Reference-contexts: We stress that there is no assumptions in the above theorems. In practice, we substitute access to a random oracle by a pseudo-random function, which assuming the existence of one-way functions, can be implemented using a short randomly chosen seed (cf. <ref> [BM, Y, ILL, H] </ref>, and [GGM]). <p> Detailed comments concerning such implementations will be given in the corresponding sections. Here, we merely recall that pseudorandom functions can be constructed using pseudorandom generators (cf. Goldreich et. al. [GGM]), and that the later can be constructed provided that one-way functions exist (cf. Blum and Micali <ref> [BM] </ref>, Yao [Y], Impagliazzo et. al. [ILL], and Hastad [H]).
Reference: [CW] <author> J.L. Carter J.L. and M. N. </author> <title> Wegman "Universal Classes of Hash Functions" Journal of Computer and System Sciences 18 (1979), </title> <journal> pp. </journal> <pages> 143-154. </pages>
Reference: [G] <author> Goldreich, O. </author> <title> "Towards a Theory of Software Protection and simulation by Oblivious RAMs" STOC 87 </title> . 
Reference: [GO] <author> Goldreich, O. and R. </author> <title> Ostrovsky "Comprehensive Software Protection System" U.S. Patent, Serial No. </title> <publisher> 07/395.882. </publisher>
Reference: [GGM] <author> Goldreich, O., S. Goldwasser, and S. Micali, </author> <title> "How To Construct Random Functions," </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> Vol. 33, No. 4 (Oc-tober 1986), </volume> <pages> 792-807. </pages>
Reference-contexts: There are two issues: The first issue is to hide from the adversary the values stored and retrieved from memory, and to prevent the adversary's attempts to change these values. This is done by an innovative use of traditional cryptographic techniques (e.g., probabilistic encryption [GM] and message authentication <ref> [GGM] </ref>). The second issue is to hide (from the adversary) the sequence of addresses accessed during the execution (hereafter referred as hiding the access pattern). Hiding the (original) memory access pattern is a completely new problem and traditional cryptographic techniques are not applicable to it. <p> We stress that there is no assumptions in the above theorems. In practice, we substitute access to a random oracle by a pseudo-random function, which assuming the existence of one-way functions, can be implemented using a short randomly chosen seed (cf. [BM, Y, ILL, H], and <ref> [GGM] </ref>). <p> Detailed comments concerning such implementations will be given in the corresponding sections. Here, we merely recall that pseudorandom functions can be constructed using pseudorandom generators (cf. Goldreich et. al. <ref> [GGM] </ref>), and that the later can be constructed provided that one-way functions exist (cf. Blum and Micali [BM], Yao [Y], Impagliazzo et. al. [ILL], and Hastad [H]). <p> The reader may be annoyed, at this point, of the fact that the transformation produces a random function f which may have an unbounded (or "huge") description. However, in practice, the function f will be pseudorandom <ref> [GGM] </ref>, and will have a succinct description as discussed in the introduction. We start by defining compilers as transformations of programs into (program,oracle) pairs, which when executed by an oracle-ram are functionally equivalent to executions of the original programs. <p> The above theorem holds in the information-theoretic sense on a probabilistic-RAM (which uses a random oracle.) As noted in the introduction, instead of random oracle we can use pseudo-random functions <ref> [GGM] </ref>, and state a practical analogue of the above theorem. That is, assuming the existence of a strong one-way function, the above algorithm can be implemented in practice using O (t (log 2 t) 3 k c ) steps. However, the security parameter k implies that 2 k is infeasible.
Reference: [GM] <author> Goldwasser S., and S. Micali, </author> <title> "Probabilistic Encryption" Jour. </title> <journal> of Computer and System Science, </journal> <volume> Vol. 28, No. 2, </volume> <year> 1984, </year> <pages> pp. 270-299. </pages>
Reference-contexts: There are two issues: The first issue is to hide from the adversary the values stored and retrieved from memory, and to prevent the adversary's attempts to change these values. This is done by an innovative use of traditional cryptographic techniques (e.g., probabilistic encryption <ref> [GM] </ref> and message authentication [GGM]). The second issue is to hide (from the adversary) the sequence of addresses accessed during the execution (hereafter referred as hiding the access pattern). Hiding the (original) memory access pattern is a completely new problem and traditional cryptographic techniques are not applicable to it.
Reference: [GMR] <author> S. Goldwasser, S. Micali and C. Rackoff, </author> <title> The Knowledge Complexity of Interactive Proof-Systems, </title> <booktitle> STOC 1985, ACM, </booktitle> <pages> pp. 291-304. </pages>
Reference-contexts: We begin with a definition of Interactive Turing-Machine (itm), where the formalization of Interactive Turing-Machines is due to Manuel Blum (private communication), and first appeared in the work of Goldwasser, Micali anr Rackoff <ref> [GMR] </ref>. We modify it with explicit bounds on the length of "messages" and on the size of work tape. <p> To this end, we define both the cpu and the memory as itms, 9 and associate the read-only communication tape of the cpu with the write-only commu-nication tape of the memory, and vice versa (cf. <ref> [GMR] </ref>). In addition, both cpu and memory will have the same message length, however they will have drastically different work tape size and finite control.
Reference: [H] <author> Hastad, J., </author> <title> "Pseudo-Random Generators under Uniform Assumptions", </title> <note> STOC 90 </note> . 
Reference-contexts: We stress that there is no assumptions in the above theorems. In practice, we substitute access to a random oracle by a pseudo-random function, which assuming the existence of one-way functions, can be implemented using a short randomly chosen seed (cf. <ref> [BM, Y, ILL, H] </ref>, and [GGM]). <p> Here, we merely recall that pseudorandom functions can be constructed using pseudorandom generators (cf. Goldreich et. al. [GGM]), and that the later can be constructed provided that one-way functions exist (cf. Blum and Micali [BM], Yao [Y], Impagliazzo et. al. [ILL], and Hastad <ref> [H] </ref>).
Reference: [ILL] <author> R. Impagliazzo, R., L. Levin, and M. </author> <title> Luby "Pseudo-Random Generation from One-Way Functions," </title> <note> STOC 89. </note>
Reference-contexts: We stress that there is no assumptions in the above theorems. In practice, we substitute access to a random oracle by a pseudo-random function, which assuming the existence of one-way functions, can be implemented using a short randomly chosen seed (cf. <ref> [BM, Y, ILL, H] </ref>, and [GGM]). <p> Here, we merely recall that pseudorandom functions can be constructed using pseudorandom generators (cf. Goldreich et. al. [GGM]), and that the later can be constructed provided that one-way functions exist (cf. Blum and Micali [BM], Yao [Y], Impagliazzo et. al. <ref> [ILL] </ref>, and Hastad [H]).
Reference: [K] <author> Kent, S.T., </author> <title> "Protecting Externally Supplied Software in Small Computers" Ph.D. </title> <type> Thesis, </type> <month> MIT/LCS/TR-255 </month> <year> 1980. </year>
Reference-contexts: Of course, the more hardware we must physically protect, the more expensive our solution is. Hence, we must also consider what is the minimal amount of the physically protected hardware we really need. 2 It has been suggested <ref> [Be, K] </ref> to protect software against duplication by selling a phys-ically shielded Central Processing Unit (CPU) together with an encrypted program (hereafter called the Software-Hardware-package or the SH-package). <p> We note that the technology to physically shield (at least to some degree) the CPU (which, in practice, is a single computer chip) does already exist indeed, every ATM bank machine has such a protected chip. Thus, the SH-package employs feasible software and hardware measures <ref> [Be, K] </ref>. Using encryption to keep the contents of the memory secret is certainly a step in the right direction. However, as we will shortly see, this does not provide the protection one may want.
Reference: [LR] <author> Luby, M., and C. Rackoff, </author> <title> "Pseudo-Random Permutation Generators and Cryp-tograpic Composition" Proc. </title> <booktitle> of 18'th SOTC, </booktitle> <year> 1986, </year> <pages> pp. 356-363. </pages>
Reference: [PF] <author> Pippengerr, N., and M.J. Fischer, </author> <title> "Relations Among Complexity Measures" JACM, </title> <booktitle> Vol 26, </booktitle> <volume> No. 2, </volume> <year> 1979, </year> <pages> pp. 361-381. </pages>
Reference-contexts: For every reasonable model of computation such a transformation does exist. The question is its cost: namely, the slowdown in the running time of the oblivious machine (when compared to the original machine). In 1979 Pippenger and Fischer <ref> [PF] </ref> showed how a one-tape Turing Machine can be simulated, on-line, by a two-tape oblivious Turing Machine, with a logarithmic slowdown in the running time. We study an analogue question for random-access machine (RAM) model of computation. <p> The solution of <ref> [PF] </ref> for making a single-tape Turing Machine oblivious heavily relies on the fact that the movement of the (single-tape Turing Machine) head is very "local" (i.e., immediately after accessing location i, a single-tape Turing-Machine is only able to access locations i 1; i; i + 1). <p> Moreover, we have established the analog of Pippenger and Fisher result <ref> [PF] </ref> for random-access machines, despite the fact that random-access machines can access its memory in an arbitrary manner, whereas the result of [PF] relies on the fact that single-tape Turing machine memory-access is severely limited. <p> Moreover, we have established the analog of Pippenger and Fisher result <ref> [PF] </ref> for random-access machines, despite the fact that random-access machines can access its memory in an arbitrary manner, whereas the result of [PF] relies on the fact that single-tape Turing machine memory-access is severely limited. On a practical side, we have presented a compiler which translates RAM-programs to equivalent programs which defeat attempts to learn anything about the program by executing it.
Reference: [Ost] <author> Ostrovsky, R. </author> <title> "Efficient Computation on Oblivious RAMs" STOC, </title> <year> 1990. </year>
Reference: [SR] <author> Simon M., and C. Rackoff, </author> <type> personal communication. </type>
Reference-contexts: We note that further work in this direction, dealing with a more powerful adversary was addressed in <ref> [SR] </ref>. Another application of our technique is for data-structure checking [B, BK, BEGKN], where assuming that a data-structure has small reliable memory we can guarantee that it was not modified by an adversary.
Reference: [Y] <author> Yao, </author> <title> A.C., "Theory and Applications of Trapdoor Functions", </title> <booktitle> 23rd FOCS, </booktitle> <year> 1982, </year> <pages> pp. 80-91. </pages>
Reference-contexts: We stress that there is no assumptions in the above theorems. In practice, we substitute access to a random oracle by a pseudo-random function, which assuming the existence of one-way functions, can be implemented using a short randomly chosen seed (cf. <ref> [BM, Y, ILL, H] </ref>, and [GGM]). <p> Detailed comments concerning such implementations will be given in the corresponding sections. Here, we merely recall that pseudorandom functions can be constructed using pseudorandom generators (cf. Goldreich et. al. [GGM]), and that the later can be constructed provided that one-way functions exist (cf. Blum and Micali [BM], Yao <ref> [Y] </ref>, Impagliazzo et. al. [ILL], and Hastad [H]).
References-found: 23

