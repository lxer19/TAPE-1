URL: http://www.cs.umn.edu/Users/dept/users/kumar/passing.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Title: Role of Message-Passing in Performance Oriented Parallel Programming  
Author: Vipin Kumar, George Karypis, and Ananth Grama 
Affiliation: University of Minnesota, Department of Computer Science University of Minnesota, Department of Computer Science Purdue University, Department of Computer Science  
Note: This work was supported by NSF CCR-9423082, by Army Research Office contract DA/DAAH04-95-1-0538, by Army High Performance Computing Research Center cooperative agreement number DAAH04-95-2-0003/contract number DAAH04-95-C-0008, by the IBM Partnership Award, and by the IBM SUR equipment grant.  
Abstract: The message-passing programming paradigm is often called the assembly language of parallel computers. The paradigm requires the user to partition the data among processors and specify interaction among processors explicitly. In contrast, the shared memory programming paradigm offers the user a global address space, making it unnecessary to specify data partitioning and communication. Indeed, many parallel programs written using the shared-memory paradigm are much shorter than their counterparts in the message-passing paradigm. Until recently, cache-coherent shared address space architectures were largely based on a global shared bus, making them inherently unscalable beyond a few dozen processors. More recently, scalable directory-based cache-coherent shared address space architectures are being offered by many vendors. This seems to make the message-passing programming style obsolete. In this article, we argue that the style of message-passing programming makes it much easier to develop efficient parallel programs even on cache-coherent shared address space architectures. The message-passing programming paradigm is often called the assembly language of parallel computers. The paradigm requires the user to partition the data among processors and specify interaction among processors explicitly. In contrast, the shared memory programming paradigm offers the user a global address space, making it unnecessary to specify data partitioning and communication. Indeed, many parallel programs written using the shared-memory paradigm are much shorter than their counterparts in the message-passing paradigm. Until recently, cache-coherent shared address space architectures were largely based on a global shared bus, making them inherently unscalable beyond a few dozen processors. More recently, scalable directory-based cache-coherent shared address space architectures are being offered by many vendors. Nearly all of the architectures are NUMA; i.e., they have physically distributed memory, but they offer a cache-coherent view of the entire memory to all the processors. Since access to local memory is faster than access to non-local 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. E. Cannon. </author> <title> A cellular computer to implement the Kalman Filter Algorithm. </title> <type> PhD thesis, </type> <institution> Montana State University, Bozman, MT, </institution> <year> 1969. </year>
Reference: [2] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis. </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms. </title> <publisher> Benjamin/Cummings Publishing Company, </publisher> <address> Redwood City, CA, </address> <year> 1994. </year>
Reference-contexts: Consider the situation in which it is necessary to compute a global sum of some M values computed by each processor. In a message passing paradigm this will be computed by the reduction operation, and will take O.M/ or O.M log p/ time, depending upon the size of M <ref> [2] </ref>. But in a shared memory paradigm, it will be natural to write the following at each processor 3 lock (global-var) Add the elements in the global-sum array. unlock (global-var) This will clearly take O.M p/ time, and will be much more inefficient compared to the message passing solution.
References-found: 2

