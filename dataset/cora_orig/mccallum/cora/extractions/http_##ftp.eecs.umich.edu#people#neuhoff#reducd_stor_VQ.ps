URL: http://ftp.eecs.umich.edu/people/neuhoff/reducd_stor_VQ.ps
Refering-URL: http://ftp.eecs.umich.edu/people/neuhoff/
Root-URL: http://www.eecs.umich.edu
Title: EDICS category: IP 1.1 Coding. Reduced Storage VQ via Secondary Quantization  
Author: Dennis Hui, Daniel F. Lyons and David L. Neuhoff 
Note: Presently with  This work was supported by NSF Grants NCR-9105647 and NCR 9415754. Portions were presented at the 1993 IEEE ICASSP, Minneapolis.  
Address: Ann Arbor, MI 48109  M/S N312, 7700 Arlington Blvd, Falls Church, VA  
Affiliation: Department of Electrical Engineering and Computer Science University of Michigan,  Raytheon E-Systems, Falls Church Division,  
Date: Jan. 30, 1997  22046.  
Abstract: This paper introduces methods for reducing the table storage required for encoding and decoding with unstructured vector quantization (UVQ) or treestructured vector quantization (TSVQ). Specifically, a lowstorage secondary quantizer is used to compress the codevectors (and testvectors) of the primary quantizer. The relative advantages of uniform and nonuniform secondary quantization are investigated. An LBG-like algorithm that optimizes the primary UVQ codebook for a given secondary codebook and another that jointly optimizes both primary and secondary codebooks are presented. In comparison to conventional methods, it is found that significant storage reduction is possible (typically a factor of 2 to 3) with little loss of signal-to-noise ratio (SNR). Moreover, when reducing dimension is considered as another method of reducing storage, it is found that the best strategy is a combination of both. The method of secondary quantization is also applied to TSVQ to reduce the table storage required for both encoding and decoding. It is shown that by exploiting the correlation among the testvectors in the tree, both encoder and decoder storage can be significantly reduced with little loss of SNR - by a factor of about 4 (or 2) relative to the conventional method of storing testvectors (or test hyperplanes). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. E. Shannon, </author> <title> "Coding theorems for a discrete source with a fidelity criterion," IRE Nat. </title> <booktitle> Conv. Rec., </booktitle> <pages> pp. 142-163, </pages> <year> 1959. </year>
Reference: [2] <author> Y. Linde, A. Buzo and R.M. Gray, </author> <title> "Algorithm for vector quantizer design," </title> <journal> IEEE Trans. Commun. </journal> <volume> vol. COM-28, </volume> <pages> pp. 84-95, </pages> <month> Jan. </month> <year> 1980. </year>
Reference-contexts: Consequently, similar to the conditions upon which the LBG algorithm is based <ref> [2] </ref>, two necessary conditions for ( C, P ) to minimize (10) can be stated.
Reference: [3] <author> A. Buzo, A.H. Gray, Jr., R.M. Gray, and J.D. Markel, </author> <title> "Speech coding based upon vector quantization," </title> <journal> IEEE Trans. ASSP, </journal> <volume> vol. ASSP-28, </volume> <pages> pp. 562-574, </pages> <month> Oct. </month> <year> 1980. </year>
Reference: [4] <author> P.A. Chou, T. Lookabaugh and R.M. Gray, </author> <title> "Optimal pruning with applications to tree-structured source coding and modeling," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-35, </volume> <month> Mar. </month> <year> 1989. </year>
Reference-contexts: 1 TSVQ may also be based on pruned or variable-depth trees <ref> [4] </ref>.
Reference: [5] <author> R.M. Gray and Y. Linde, </author> <title> "Vector quantizers and predictive quantizers for Gauss-Markov sources," </title> <journal> IEEE Trans. Commun., </journal> <volume> vol. COM-30, </volume> <pages> pp. 381-389, </pages> <month> Feb. </month> <year> 1982. </year>
Reference-contexts: The latter becomes the chosen codevector, and the kr bit path through the tree to it becomes its index. The codebook is the set of all terminal testvectors. There is an LBG type algorithm for designing the tree from a training sequence <ref> [5] </ref>. Although it is a greedy algorithm that does not necessarily produce an optimal TSVQ, it has been found to design TSVQ's whose distortion is reasonably close to that of optimal UVQ's in ordinary situations [5,6]. <p> Moreover, since the encoding tree is highly structured, one may foresee that the use of a secondary quantizer that exploits the correlations within the tree could be quite beneficial. This is explored in Subsection B. A. Basic Secondary Quantization of TSVQ In the conventional TSVQ design algorithm <ref> [5] </ref>, after designing the testvectors at levels 1 through i - 1, each pair of sibling testvectors at level i is designed by iteratively replacing each candidate testvectors with the centroid of the training vectors associated with their parent that are closer to it than to its sibling.
Reference: [6] <author> D. Neuhoff and D.H. Lee, </author> <title> "On the performance of tree structured vector quantizers," </title> <booktitle> in Proc. ICASSP, Toronto, </booktitle> <pages> pp. 2277-2280, </pages> <month> May </month> <year> 1991. </year>
Reference: [7] <institution> W.A. Finamore and W.A. </institution> <month> Pearlman, </month> <title> "Optimal encoding of discrete-time continuous-amplitude memoryless sources with finite output alphabets," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-26, </volume> <pages> pp. 144-155, </pages> <month> Mar. </month> <year> 1980. </year>
Reference: [8] <author> W. A. Pearlman and A. Chekima, </author> <title> "Source coding bounds using quantizer reproduction levels," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-30, </volume> <pages> pp. 559-567, </pages> <month> May </month> <year> 1984. </year>
Reference: [9] <author> W.A. Pearlman, </author> <title> "Sliding-block and random source coding with constrained size reproduction alphabets," </title> <journal> IEEE Trans. Commun., </journal> <volume> vol. COM-30, </volume> <pages> pp. 1859-1867, </pages> <month> Aug. </month> <year> 1982. </year>
Reference: [10] <author> R.P. Rao, W. A. Pearlman, </author> <title> and W.A. Finamore, "Alphabet-constrained optimal vector quantization," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-39, </volume> <pages> pp. 1167-1179, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: It also found procedures for designing certain types of codes, such as trellis and sliding-block codes, with finitely constrained reproduction alphabets [7,9]. In other work of Pearlman et al. <ref> [10] </ref>, entropy-constrained VQ's were designed under the constraint that their code-books are subsets of certain master VQ codebooks, which are, effectively, vector secondary code-books. None of this work, however, addressed reduction of storage issues for VQ or other coding techniques. <p> The flowchart in Figure 5 summarizes this algorithm, which we call the constrained LBG (CLBG) algorithm for designing UVQ/2Q. It is similar to the alphabet and entropy constrained VQ design algorithm in <ref> [10] </ref>, but without the constraint on entropy. One may think of it as integrating the secondary quantization into the ordinary LBG algorithm. Similar to the LBG algorithm, it can be run on a training sequence generated by the source.
Reference: [11] <author> K. Zeger, A. Bist and T. Linder, </author> <title> "Universal source coding with codebook transmission," </title> <journal> IEEE Trans. Commun., </journal> <volume> vol. COM-42, </volume> <pages> pp. 336-346, </pages> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: None of this work, however, addressed reduction of storage issues for VQ or other coding techniques. Second, there is work on adaptive and universal source coding where a VQ codebook must be designed and transmitted along with encoded data <ref> [11, 12, 13] </ref>. In these schemes, the code-book is constrained to be a subset of some fixed master codebook, which can again be considered to be a secondary codebook. <p> APPENDIX In this appendix, we derive upper bounds to the additional distortion incurred by secondary quantization as described by (3) and (5) in Section II-B. These are similar to bounds derived in [24] and <ref> [11] </ref>, respectively, but they are included here for completeness. <p> In addition, if one assumes that each primary codevector is equally likely to be anywhere inside a secondary cell relative to the secondary point, the bound can be further tightened by another factor of 1/3. This tightening is similar to the additive-quantization-noise argument of <ref> [11] </ref>. 29
Reference: [12] <author> P.A. Chou and M. Effros, </author> <title> "Rate and distortion redundancies for universal source coding with respect to a fidelity criterion," </title> <booktitle> in Proc. </booktitle> <address> ISIT, San Antonio, Texas, </address> <pages> pp. 53, </pages> <month> Jan. </month> <year> 1993. </year>
Reference-contexts: None of this work, however, addressed reduction of storage issues for VQ or other coding techniques. Second, there is work on adaptive and universal source coding where a VQ codebook must be designed and transmitted along with encoded data <ref> [11, 12, 13] </ref>. In these schemes, the code-book is constrained to be a subset of some fixed master codebook, which can again be considered to be a secondary codebook.
Reference: [13] <author> M. Effros, P.A. Chou and R.M. Gray, </author> <title> "One-pass adaptive universal vector quantization," </title> <booktitle> in Proc. ICASSP, </booktitle> <volume> vol. </volume> <pages> 5, </pages> <address> Adelaide, Australia, </address> <pages> pp. 625-628, </pages> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: None of this work, however, addressed reduction of storage issues for VQ or other coding techniques. Second, there is work on adaptive and universal source coding where a VQ codebook must be designed and transmitted along with encoded data <ref> [11, 12, 13] </ref>. In these schemes, the code-book is constrained to be a subset of some fixed master codebook, which can again be considered to be a secondary codebook.
Reference: [14] <author> J. Ziv, </author> <title> "Coding of Sources with unknown statistics - Part 2: Distortion relative to a fidelity criterion, </title> " <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-18, </volume> <pages> pp. 389-394, </pages> <month> May </month> <year> 1972. </year>
Reference: [15] <author> D.L. Neuhoff, R.M. Gray, and L.D. Davisson. </author> <title> "Fixed-rate universal block source coding with a fidelity criterion," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-21, </volume> <pages> pp. 511-523, </pages> <month> Sept. </month> <year> 1975. </year> <month> 30 </month>
Reference: [16] <author> W. Chan and A. Gersho, </author> <title> "Constrained-storage quantization of multiple vector sources by codebook sharing," </title> <journal> IEEE Trans. Commun., </journal> <volume> vol. COM-39, </volume> <pages> pp. 11-13, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: The earliest work exploiting finitely constrained reproduction alphabets for adaptive and universal source coding appears to be contained in [14,15]. Finally, we mention that the codebook sharing approach of Chan and Gersho <ref> [16] </ref> is an alternative strategy for reducing the storage required for TSVQ. In summary, this paper explores the benefits and relative merits of a variety of secondary quantization techniques.
Reference: [17] <author> A. Gersho, </author> <title> "Asymptotically optimal block quantization," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-25, </volume> <pages> pp. 373-380, </pages> <month> July </month> <year> 1979. </year>
Reference-contexts: 1 (x), and overload distortion is negligible, it is also shown in the Appendix that N s D 2Q p 1 (y) 2 dy (5) where l s ( x) [ N s diam (T i )] -1 when x T i is the point density of the secondary quantizer <ref> [17] </ref>, and the approximate inequality " ~ " means that the left-hand side of (5) is no larger than (1 + d ) times the right-hand side for arbitrary d &gt; 0 and sufficiently large N s . <p> Note that the right-hand side of (5) does not depend on the primary quantizer. Combining (4), (5) and Zador's approximation to D UVQ * <ref> [17, 18] </ref>, we have DD D UVQ N N s p 1 ( x) 2 dx = 2 p 1 (x) 2 dx (6a) where M k is the k dimensional Zador-Gersho constant, and p a p (x) a 1/a . <p> ) [ ] 2 N j =1 k l s (y j ) j =1 = l s (y) where p j (y) is the marginal probability density of the j th component of X and l s (x) [N s diam (T x )] -1 is the point density <ref> [17] </ref> of the secondary quantizer. It is worthwhile to note that if the secondary quantization points are approximately located at the middle of their corresponding cells, this bound can be tightened by a factor of 1/4.
Reference: [18] <author> P. Zador, </author> <title> "Asymptotic quantization error of continuous signals and quantization dimension," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-28, </volume> <pages> pp. 139-149, </pages> <month> Mar. </month> <year> 1982. </year>
Reference-contexts: Note that the right-hand side of (5) does not depend on the primary quantizer. Combining (4), (5) and Zador's approximation to D UVQ * <ref> [17, 18] </ref>, we have DD D UVQ N N s p 1 ( x) 2 dx = 2 p 1 (x) 2 dx (6a) where M k is the k dimensional Zador-Gersho constant, and p a p (x) a 1/a .
Reference: [19] <author> D. Hui and D.L. Neuhoff, </author> <title> "Asymptotic analysis of fixed-rate uniform scalar quantization," </title> <note> in preparation. </note>
Reference-contexts: the offset of the uniform quantizer need to be stored), and the storage reduction is approximately the factor B / r s . 6 For most commonly used densities, the support length of a uniform scalar quantizer that minimizes mean squared error is known to increase slowly with its rate <ref> [19] </ref>. For example, it increases as the square root of its rate for a Gaussian density. We expect the support length of good secondary quantizers to behave similarly. 10 various primary rates and dimensions for the IID Gaussian source.
Reference: [20] <author> S. Na and D.L. Neuhoff, </author> <title> "Bennett's integral for vector quantizers," </title> <journal> IEEE Trans. Inform. Theory, </journal> <volume> vol. IT-41, </volume> <pages> pp. 886-900, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: This is because the distribution of primary quantization points, weighted by their probabilities, is approximately the source distribution, and because the LM quantizer induces the best product quantizer for the k dimensional source density <ref> [20] </ref>. N/N for Nonintegrated design with Nonuniform secondary quantization. For comparison, the performance of UVQ/2Q with a uniform scalar quantizer (from Figure 1) is also plotted (labeled N/U). Though not shown, the results for the G-M source were similar in nature.
Reference: [21] <author> B.H. Juang and A.H. Gray, </author> <title> "Multiple stage vector quantization for speech coding," </title> <booktitle> Proc. ICASSP, </booktitle> <volume> vol. </volume> <pages> 1, </pages> <address> Paris, France, </address> <pages> pp. 597-600, </pages> <month> May </month> <year> 1982. </year>
Reference-contexts: In this case, the actual testvector would need to be reconstructed prior to its use, by summing the differential testvector and the reconstruction of its parent. Alternatively, we prefer the following encoding method, in the style of multistage quantization <ref> [21] </ref>. After a sibling is selected, the corresponding differential testvector is subtracted from the current source vector forming a new current source vector.
Reference: [22] <author> A. Gersho and R.M. Gray, </author> <title> Vector Quantization and Signal Compression, </title> <publisher> Kluwer, </publisher> <year> 1992. </year>
Reference-contexts: In general, any existing (primary) quantization schemes may be considered for secondary quantization. Indeed, one may think of the differential TSVQ/2Q schemes used to exploit the correlation among the additional testvector storage required for fast encoding as analogous to the well known differential quantization methods used in predictive coding <ref> [22] </ref>. Other popular coding schemes not mentioned in this paper may also be applied. For instance, in the case of UVQ/2Q, one may apply a unitary transform to the primary codevectors before secondary quantization to reduce the higher secondary rate required for sources with memory, as compared to memoryless sources.
Reference: [23] <author> P.A. Chou, T. Lookabaugh and R.M. Gray, </author> <title> "Entropy-constrained vector quantization," </title> <journal> IEEE Trans. ASSP, </journal> <volume> vol. ASSP-37, </volume> <pages> pp. 31-42, </pages> <month> Jan. </month> <year> 1989. </year>
Reference-contexts: Moreover, to further reduce the overall storage, one may apply entropy coding to the indices of primary codevector components, or alternatively, using Lagrangian formulation, integrate the entropy-constrained VQ design algorithm introduced in <ref> [23] </ref> into the secondary routine of the ILBG algorithm to design a fixed-rate primary quantizer with variable-rate secondary quantization. Although many interesting aspects of secondary quantization remain to be investigated, it is hoped that this paper provides useful guidelines and understanding for the designer.
Reference: [24] <author> N. Moayeri, D. L. Neuhoff and W.E. Stark, </author> <title> "Fine-coarse vector quantization," </title> <journal> IEEE Trans. Signal Proc., </journal> <volume> vol. SP-39, </volume> <month> July </month> <year> 1991. </year>
Reference-contexts: APPENDIX In this appendix, we derive upper bounds to the additional distortion incurred by secondary quantization as described by (3) and (5) in Section II-B. These are similar to bounds derived in <ref> [24] </ref> and [11], respectively, but they are included here for completeness.
Reference: [25] <author> W.R. Bennett, </author> <title> "Spectra of quantized signals," </title> <journal> Bell Syst. Tech. J., </journal> <volume> vol. 27, </volume> <pages> pp. 446-472, </pages> <month> July </month> <year> 1948. </year>
Reference-contexts: ( ) [ ] 2 N j =1 , For the case that k s = 1, N and N s are large, all secondary cells are intervals, the source vector has identical components with probability density p 1 (x), and overload distortion is negligible, we can use Bennett's integral <ref> [25] </ref> to approximate the above expression.
References-found: 25

