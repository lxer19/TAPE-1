URL: http://www.umiacs.umd.edu:80/users/betke/techreport834.ps
Refering-URL: http://www.umiacs.umd.edu:80/users/betke/index.html
Root-URL: 
Title: Multiple Vehicle Detection and Tracking in Hard Real Time  
Author: Margrit Betke, Esin Haritaoglu and Larry S. Davis. 
Note: The support of DARPA, the Office of Naval Research, the Army Strategic Defense Command, and Philips Laboratories under Contracts N00014-95-1-0521 and DASG-60-92-C-0055 is gratefully acknowledged.  
Address: College Park, MD 20742-3275  
Affiliation: Computer Vision Laboratory Center for Automation Research and Institute for Advanced Computer Studies University of Maryland  
Date: July 1996  
Pubnum: CAR-TR-834 UMIACS-TR-96-52 N00014-95-1-0521 DASG-60-92-C-0055  
Abstract: A vision system has been developed that recognizes and tracks multiple vehicles from sequences of gray-scale images taken from a moving car in hard real time. Recognition is accomplished by combining the analysis of single image frames with the analysis of the motion information provided by multiple consecutive image frames. In single image frames, cars are recognized by matching deformable gray-scale templates, by detecting image features, such as corners, and by evaluating how these features relate to each other. Cars are also recognized by differencing consecutive image frames and by tracking motion parameters that are typical for cars. The vision system utilizes the hard real-time operating system Maruti which guarantees that the timing constraints on the various vision processes are satisfied. The dynamic creation and termination of tracking processes optimizes the amount of computational resources spent and allows fast detection and tracking of multiple cars. Experimental results demonstrate robust, real-time recognition and tracking over thousands of image frames. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Reinhold Behringer. </author> <title> Detection of discontinuities of road curvature changes by GLR. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 78-83, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Related problems are autonomous convoy driving [31, 11], road detection and following <ref> [1, 2, 5-9, 12, 16, 19, 20, 23, 28] </ref>, lane transition [17], and image stabilization [25]. (Since some of these areas have been researched extensively, we only refer to some of the more recent approaches.) There has also been work on tracking vehicles using stationary cameras (e.g., [21, 14, 10]).
Reference: [2] <author> Reinhold Behringer and Stefan Hotzel. </author> <title> Simultaneous estimation of pitch angle and lane width from the video image of a marked road. </title> <booktitle> In Proceedings of the IEEE/RSJ/GI 19 International Conference on Intelligent Robots and Systems, </booktitle> <pages> pages 966-973, </pages> <address> Munich, Germany, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Related problems are autonomous convoy driving [31, 11], road detection and following <ref> [1, 2, 5-9, 12, 16, 19, 20, 23, 28] </ref>, lane transition [17], and image stabilization [25]. (Since some of these areas have been researched extensively, we only refer to some of the more recent approaches.) There has also been work on tracking vehicles using stationary cameras (e.g., [21, 14, 10]).
Reference: [3] <author> Margrit Betke and Nicholas C. Makris. </author> <title> Fast object recognition in noisy images using simulated annealing. </title> <booktitle> In Proceedings of the Fifth International Conference on Computer Vision, </booktitle> <pages> pages 523-530, </pages> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year> <note> Also published as MIT AI Memo 1510. </note>
Reference-contexts: The objective function combines evaluation of the history of tracking a potential car with correlation of the potential car with a deformable template of a car created on-line using the method described in Ref. <ref> [3] </ref>. Various approaches for recognizing and/or tracking cars from a moving camera have been suggested in the literature for example, detecting symmetry [33, 29, 4], approximating optical flow [32, 13, 15, 22], exploiting binocular or trinocular stereopsis [23, 4, 26, 18], matching templates [26], and training a neural net [27]. <p> example, the shift is up and right, decreasing from frame to frame.) If large brightness changes are detected in consecutive images, a gray-scale template T of a size corresponding to the hypothesized size of the passing car is created from a model image M using the method described in Ref. <ref> [3] </ref>. It is correlated with the image region R that is hypothesized to contain a passing car.
Reference: [4] <author> Stefan Bohrer, Thomas Zielke, and Volker Freiburg. </author> <title> An integrated obstacle detection framework for intelligent cruise control on motorways. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 276-281, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Various approaches for recognizing and/or tracking cars from a moving camera have been suggested in the literature for example, detecting symmetry <ref> [33, 29, 4] </ref>, approximating optical flow [32, 13, 15, 22], exploiting binocular or trinocular stereopsis [23, 4, 26, 18], matching templates [26], and training a neural net [27]. <p> Various approaches for recognizing and/or tracking cars from a moving camera have been suggested in the literature for example, detecting symmetry [33, 29, 4], approximating optical flow [32, 13, 15, 22], exploiting binocular or trinocular stereopsis <ref> [23, 4, 26, 18] </ref>, matching templates [26], and training a neural net [27]. <p> In addition, it does not need any initialization by a human operator, but recognizes the cars it tracks automatically. Our method also does not rely on having to estimate road parameters (as does Ref. [23]). Unlike other methods <ref> [4, 13, 22, 23, 26, 27, 29, 32] </ref>, our vision system processes the video data in real time without any specialized hardware. All we need is an ordinary video camera and a low-cost PC. Simplicity is the key to the real-time performance of our method.
Reference: [5] <author> Alberto Broggi. </author> <title> Parallel and local feature extraction: A real-time approach to road boundary detection. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 4(2) </volume> <pages> 217-223, </pages> <month> February </month> <year> 1995. </year>
Reference: [6] <author> Alberto Broggi. </author> <title> Robust real-time lane and road detection in critical shadow conditions. </title> <booktitle> In Proceedings of the International Symposium on Computer Vision, </booktitle> <pages> pages 353-359, </pages> <address> Coral Gables, FL, </address> <month> November </month> <year> 1995. </year>
Reference: [7] <author> Jill D. Crisman and Charles E. Thorpe. SCARF: </author> <title> A color vision system that tracks roads and intersections. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 9(1) </volume> <pages> 49-58, </pages> <month> February </month> <year> 1993. </year>
Reference: [8] <author> Ernst D. Dickmanns and Volker Graefe. </author> <title> Applications of dynamic monocular machine vision. </title> <journal> Machine Vision and Applications, </journal> <volume> 1(4) </volume> <pages> 241-261, </pages> <year> 1988. </year>
Reference: [9] <author> Ernst D. Dickmanns and Birger D. Mysliwetz. </author> <title> Recursive 3-D road and relative ego state recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14(2) </volume> <pages> 199-213, </pages> <month> February </month> <year> 1992. </year>
Reference: [10] <author> M. Fathy and M. Y. Siyal. </author> <title> A window-based edge detection technique for measuring road traffic parameters in real-time. </title> <booktitle> Real-Time Imaging, </booktitle> <volume> 1(4) </volume> <pages> 297-305, </pages> <year> 1995. </year> <month> 20 </month>
Reference-contexts: detection and following [1, 2, 5-9, 12, 16, 19, 20, 23, 28], lane transition [17], and image stabilization [25]. (Since some of these areas have been researched extensively, we only refer to some of the more recent approaches.) There has also been work on tracking vehicles using stationary cameras (e.g., <ref> [21, 14, 10] </ref>). A collection of articles on vision-based vehicle guidance can be found in Ref. [24]. Unlike some methods described in the literature, our vision system can track more than one car at a time.
Reference: [11] <author> U. Franke, F. Bottinger, Z. Zomoter, and D. Seeberger. </author> <title> Truck platooning in mixed traffic. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 1-6, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Related problems are autonomous convoy driving <ref> [31, 11] </ref>, road detection and following [1, 2, 5-9, 12, 16, 19, 20, 23, 28], lane transition [17], and image stabilization [25]. (Since some of these areas have been researched extensively, we only refer to some of the more recent approaches.) There has also been work on tracking vehicles using stationary
Reference: [12] <author> V. Gengenbach, H.-H. Nagel, F. Heimes, G. Struck, and H. Kollnig. </author> <title> Model-based recognition of intersection and lane structure. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 512-517, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Related problems are autonomous convoy driving [31, 11], road detection and following <ref> [1, 2, 5-9, 12, 16, 19, 20, 23, 28] </ref>, lane transition [17], and image stabilization [25]. (Since some of these areas have been researched extensively, we only refer to some of the more recent approaches.) There has also been work on tracking vehicles using stationary cameras (e.g., [21, 14, 10]).
Reference: [13] <author> Andrea Giachetti, Marco Cappello, and Vincent Torre. </author> <title> Dynamic segmentation of traffic scenes. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 258-263, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Various approaches for recognizing and/or tracking cars from a moving camera have been suggested in the literature for example, detecting symmetry [33, 29, 4], approximating optical flow <ref> [32, 13, 15, 22] </ref>, exploiting binocular or trinocular stereopsis [23, 4, 26, 18], matching templates [26], and training a neural net [27]. <p> In addition, it does not need any initialization by a human operator, but recognizes the cars it tracks automatically. Our method also does not rely on having to estimate road parameters (as does Ref. [23]). Unlike other methods <ref> [4, 13, 22, 23, 26, 27, 29, 32] </ref>, our vision system processes the video data in real time without any specialized hardware. All we need is an ordinary video camera and a low-cost PC. Simplicity is the key to the real-time performance of our method.
Reference: [14] <author> Sylvia Gil, Ruggero Milanese, and Thierry Pun. </author> <title> Combining multiple motion estimates for vehicle tracking. </title> <booktitle> In Lecture Notes in Computer Science. </booktitle> <volume> Vol. 1065: </volume> <booktitle> Proceedings of the 4th European Conference on Computer Vision, </booktitle> <volume> volume II, </volume> <pages> pages 307-320. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: detection and following [1, 2, 5-9, 12, 16, 19, 20, 23, 28], lane transition [17], and image stabilization [25]. (Since some of these areas have been researched extensively, we only refer to some of the more recent approaches.) There has also been work on tracking vehicles using stationary cameras (e.g., <ref> [21, 14, 10] </ref>). A collection of articles on vision-based vehicle guidance can be found in Ref. [24]. Unlike some methods described in the literature, our vision system can track more than one car at a time.
Reference: [15] <author> Walter J. Gillner. </author> <title> Motion based vehicle detection on motorways. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 483-487, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Various approaches for recognizing and/or tracking cars from a moving camera have been suggested in the literature for example, detecting symmetry [33, 29, 4], approximating optical flow <ref> [32, 13, 15, 22] </ref>, exploiting binocular or trinocular stereopsis [23, 4, 26, 18], matching templates [26], and training a neural net [27].
Reference: [16] <author> Tetsuji Haga, Koichi Sasakawa, and Shin'ichi Kuroda. </author> <title> The detection of line boundary markings using the modified spoke filter. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 293-298, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Related problems are autonomous convoy driving [31, 11], road detection and following <ref> [1, 2, 5-9, 12, 16, 19, 20, 23, 28] </ref>, lane transition [17], and image stabilization [25]. (Since some of these areas have been researched extensively, we only refer to some of the more recent approaches.) There has also been work on tracking vehicles using stationary cameras (e.g., [21, 14, 10]).
Reference: [17] <author> Todd Jochem, Dean Pomerleau, and Charles Thorpe. </author> <title> Vision guided lane-transition. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 30-35, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Related problems are autonomous convoy driving [31, 11], road detection and following [1, 2, 5-9, 12, 16, 19, 20, 23, 28], lane transition <ref> [17] </ref>, and image stabilization [25]. (Since some of these areas have been researched extensively, we only refer to some of the more recent approaches.) There has also been work on tracking vehicles using stationary cameras (e.g., [21, 14, 10]).
Reference: [18] <author> L. Kaminski, J. Allen, I. Masaki, and G. Lemus. </author> <title> A sub-pixel stereo vision system for cost-effective intelligent vehicle applications. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 7-12, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Various approaches for recognizing and/or tracking cars from a moving camera have been suggested in the literature for example, detecting symmetry [33, 29, 4], approximating optical flow [32, 13, 15, 22], exploiting binocular or trinocular stereopsis <ref> [23, 4, 26, 18] </ref>, matching templates [26], and training a neural net [27].
Reference: [19] <author> Karl Kluge and Greg Johnson. </author> <title> Statistical characterization of the visual characteristics of painted lane markings. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 488-493, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year> <month> 21 </month>
Reference-contexts: Related problems are autonomous convoy driving [31, 11], road detection and following <ref> [1, 2, 5-9, 12, 16, 19, 20, 23, 28] </ref>, lane transition [17], and image stabilization [25]. (Since some of these areas have been researched extensively, we only refer to some of the more recent approaches.) There has also been work on tracking vehicles using stationary cameras (e.g., [21, 14, 10]).
Reference: [20] <author> Karl Kluge and Sridhar Lakshmanan. </author> <title> A deformable-template approach to line detec tion. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 54-59, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Related problems are autonomous convoy driving [31, 11], road detection and following <ref> [1, 2, 5-9, 12, 16, 19, 20, 23, 28] </ref>, lane transition [17], and image stabilization [25]. (Since some of these areas have been researched extensively, we only refer to some of the more recent approaches.) There has also been work on tracking vehicles using stationary cameras (e.g., [21, 14, 10]).
Reference: [21] <author> Dieter Koller, Joseph Weber, and Jitendra Malik. </author> <title> Robust multiple car tracking with occlusion reasoning. </title> <booktitle> In Lecture Notes in Computer Science. </booktitle> <volume> Vol. 800: </volume> <booktitle> Proceedings of the 3rd European Conference on Computer Vision, </booktitle> <volume> volume I, </volume> <pages> pages 189-196. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: detection and following [1, 2, 5-9, 12, 16, 19, 20, 23, 28], lane transition [17], and image stabilization [25]. (Since some of these areas have been researched extensively, we only refer to some of the more recent approaches.) There has also been work on tracking vehicles using stationary cameras (e.g., <ref> [21, 14, 10] </ref>). A collection of articles on vision-based vehicle guidance can be found in Ref. [24]. Unlike some methods described in the literature, our vision system can track more than one car at a time.
Reference: [22] <author> W. Kruger, W. Enkelmann, and S. Rossle. </author> <title> Real-time estimation and tracking of optical flow vectors for obstacle detection. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 304-309, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Various approaches for recognizing and/or tracking cars from a moving camera have been suggested in the literature for example, detecting symmetry [33, 29, 4], approximating optical flow <ref> [32, 13, 15, 22] </ref>, exploiting binocular or trinocular stereopsis [23, 4, 26, 18], matching templates [26], and training a neural net [27]. <p> In addition, it does not need any initialization by a human operator, but recognizes the cars it tracks automatically. Our method also does not rely on having to estimate road parameters (as does Ref. [23]). Unlike other methods <ref> [4, 13, 22, 23, 26, 27, 29, 32] </ref>, our vision system processes the video data in real time without any specialized hardware. All we need is an ordinary video camera and a low-cost PC. Simplicity is the key to the real-time performance of our method.
Reference: [23] <author> Q.-T. Luong, J. Weber, D. Koller, and J. Malik. </author> <title> An integrated stereo-based approach to automatic vehicle guidance. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 52-57, </pages> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: Various approaches for recognizing and/or tracking cars from a moving camera have been suggested in the literature for example, detecting symmetry [33, 29, 4], approximating optical flow [32, 13, 15, 22], exploiting binocular or trinocular stereopsis <ref> [23, 4, 26, 18] </ref>, matching templates [26], and training a neural net [27]. <p> Related problems are autonomous convoy driving [31, 11], road detection and following <ref> [1, 2, 5-9, 12, 16, 19, 20, 23, 28] </ref>, lane transition [17], and image stabilization [25]. (Since some of these areas have been researched extensively, we only refer to some of the more recent approaches.) There has also been work on tracking vehicles using stationary cameras (e.g., [21, 14, 10]). <p> In addition, it does not need any initialization by a human operator, but recognizes the cars it tracks automatically. Our method also does not rely on having to estimate road parameters (as does Ref. <ref> [23] </ref>). Unlike other methods [4, 13, 22, 23, 26, 27, 29, 32], our vision system processes the video data in real time without any specialized hardware. All we need is an ordinary video camera and a low-cost PC. Simplicity is the key to the real-time performance of our method. <p> In addition, it does not need any initialization by a human operator, but recognizes the cars it tracks automatically. Our method also does not rely on having to estimate road parameters (as does Ref. [23]). Unlike other methods <ref> [4, 13, 22, 23, 26, 27, 29, 32] </ref>, our vision system processes the video data in real time without any specialized hardware. All we need is an ordinary video camera and a low-cost PC. Simplicity is the key to the real-time performance of our method.
Reference: [24] <author> Ichiro Masaki, </author> <title> editor. Vision-based Vehicle Guidance. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1992. </year>
Reference-contexts: A collection of articles on vision-based vehicle guidance can be found in Ref. <ref> [24] </ref>. Unlike some methods described in the literature, our vision system can track more than one car at a time. In addition, it does not need any initialization by a human operator, but recognizes the cars it tracks automatically.
Reference: [25] <author> Carlos Morimoto, Daniel DeMenthon, Larry S. Davis, Rama Chellappa, and Randal Nelson. </author> <title> Detection of independently moving objects in passive video. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 270-275, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Related problems are autonomous convoy driving [31, 11], road detection and following [1, 2, 5-9, 12, 16, 19, 20, 23, 28], lane transition [17], and image stabilization <ref> [25] </ref>. (Since some of these areas have been researched extensively, we only refer to some of the more recent approaches.) There has also been work on tracking vehicles using stationary cameras (e.g., [21, 14, 10]). A collection of articles on vision-based vehicle guidance can be found in Ref. [24].
Reference: [26] <author> Yoshiki Ninomiya, Sachiko Matsuda, Mitsuhiko Ohta, Yoshihisa Harata, and Toshihika Suzuki. </author> <title> A real-time vision for intelligent vehicles. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 101-106, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Various approaches for recognizing and/or tracking cars from a moving camera have been suggested in the literature for example, detecting symmetry [33, 29, 4], approximating optical flow [32, 13, 15, 22], exploiting binocular or trinocular stereopsis <ref> [23, 4, 26, 18] </ref>, matching templates [26], and training a neural net [27]. <p> Various approaches for recognizing and/or tracking cars from a moving camera have been suggested in the literature for example, detecting symmetry [33, 29, 4], approximating optical flow [32, 13, 15, 22], exploiting binocular or trinocular stereopsis [23, 4, 26, 18], matching templates <ref> [26] </ref>, and training a neural net [27]. <p> In addition, it does not need any initialization by a human operator, but recognizes the cars it tracks automatically. Our method also does not rely on having to estimate road parameters (as does Ref. [23]). Unlike other methods <ref> [4, 13, 22, 23, 26, 27, 29, 32] </ref>, our vision system processes the video data in real time without any specialized hardware. All we need is an ordinary video camera and a low-cost PC. Simplicity is the key to the real-time performance of our method.
Reference: [27] <author> Detlev Noll, Martin Werner, and Werner von Seelen. </author> <title> Real-time vehicle tracking and classification. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 101-106, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year>
Reference-contexts: Various approaches for recognizing and/or tracking cars from a moving camera have been suggested in the literature for example, detecting symmetry [33, 29, 4], approximating optical flow [32, 13, 15, 22], exploiting binocular or trinocular stereopsis [23, 4, 26, 18], matching templates [26], and training a neural net <ref> [27] </ref>. <p> In addition, it does not need any initialization by a human operator, but recognizes the cars it tracks automatically. Our method also does not rely on having to estimate road parameters (as does Ref. [23]). Unlike other methods <ref> [4, 13, 22, 23, 26, 27, 29, 32] </ref>, our vision system processes the video data in real time without any specialized hardware. All we need is an ordinary video camera and a low-cost PC. Simplicity is the key to the real-time performance of our method.
Reference: [28] <author> Dean Pomerleau. RALPH: </author> <title> Rapidly adapting lateral position handler. </title> <booktitle> In Proceedings of the Intelligent Vehicles Symposium, </booktitle> <pages> pages 506-511, </pages> <address> Detroit, MI, </address> <month> September </month> <year> 1995. </year> <month> 22 </month>
Reference-contexts: Related problems are autonomous convoy driving [31, 11], road detection and following <ref> [1, 2, 5-9, 12, 16, 19, 20, 23, 28] </ref>, lane transition [17], and image stabilization [25]. (Since some of these areas have been researched extensively, we only refer to some of the more recent approaches.) There has also been work on tracking vehicles using stationary cameras (e.g., [21, 14, 10]).
Reference: [29] <author> Uwe Regensburger and Volker Graefe. </author> <title> Visual recognition of obstacles on roads. </title> <booktitle> In Proceedings of the IEEE/RSJ/GI International Conference on Intelligent Robots and Systems, </booktitle> <pages> pages 982-987, </pages> <address> Munich, Germany, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Various approaches for recognizing and/or tracking cars from a moving camera have been suggested in the literature for example, detecting symmetry <ref> [33, 29, 4] </ref>, approximating optical flow [32, 13, 15, 22], exploiting binocular or trinocular stereopsis [23, 4, 26, 18], matching templates [26], and training a neural net [27]. <p> In addition, it does not need any initialization by a human operator, but recognizes the cars it tracks automatically. Our method also does not rely on having to estimate road parameters (as does Ref. [23]). Unlike other methods <ref> [4, 13, 22, 23, 26, 27, 29, 32] </ref>, our vision system processes the video data in real time without any specialized hardware. All we need is an ordinary video camera and a low-cost PC. Simplicity is the key to the real-time performance of our method.
Reference: [30] <author> Manas C. Saksena, James da Silva, and Ashok K. Agrawala. </author> <title> Design and implementation of Maruti-II. In Sang Son, editor, </title> <booktitle> Principles of Real-Time Systems. </booktitle> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1994. </year> <note> Also available as UMD CS-TR-3181, UMIACS TR-93-122. </note>
Reference-contexts: Most of the related research aims at "virtual real-time" performance, i.e., fast processing without timing guarantees. In contrast, we utilize the advantages of Maruti, a hard real-time operating system developed at the University of Maryland <ref> [30] </ref>. Maruti finds an efficient schedule for allocating resources to the various processes that search for, recognize, and track the cars. Maruti's scheduling guarantees that the required deadlines are met. It reserves the required resources for each task prior to execution. This paper is organized as follows. <p> The temporal correctness of the system is ensured if a feasible schedule can be constructed. The scheduler has explicit control over when a task is dispatched. Our vision system utilizes the hard real-time system Maruti <ref> [30] </ref>. Maruti is a "dynamic hard real-time system" that can handle on-line requests. It either schedules and executes them if the resources needed are available, or rejects them.
Reference: [31] <author> H. Schneiderman, M. Nashman, A. J. Wavering, and R. Lumia. </author> <title> Vision-based robotic convoy driving. </title> <journal> Machine Vision and Applications, </journal> <volume> 8(6) </volume> <pages> 359-364, </pages> <year> 1995. </year>
Reference-contexts: Related problems are autonomous convoy driving <ref> [31, 11] </ref>, road detection and following [1, 2, 5-9, 12, 16, 19, 20, 23, 28], lane transition [17], and image stabilization [25]. (Since some of these areas have been researched extensively, we only refer to some of the more recent approaches.) There has also been work on tracking vehicles using stationary
Reference: [32] <author> S. M. Smith. ASSET-2: </author> <title> Real-time motion segmentation and shape tracking. </title> <booktitle> In Proceed ings of the International Conference on Computer Vision, </booktitle> <pages> pages 237-244, </pages> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: Various approaches for recognizing and/or tracking cars from a moving camera have been suggested in the literature for example, detecting symmetry [33, 29, 4], approximating optical flow <ref> [32, 13, 15, 22] </ref>, exploiting binocular or trinocular stereopsis [23, 4, 26, 18], matching templates [26], and training a neural net [27]. <p> In addition, it does not need any initialization by a human operator, but recognizes the cars it tracks automatically. Our method also does not rely on having to estimate road parameters (as does Ref. [23]). Unlike other methods <ref> [4, 13, 22, 23, 26, 27, 29, 32] </ref>, our vision system processes the video data in real time without any specialized hardware. All we need is an ordinary video camera and a low-cost PC. Simplicity is the key to the real-time performance of our method.
Reference: [33] <author> Thomas Zielke, Michael Brauckmann, and Werner von Seelen. </author> <title> Intensity and edge-based symmetry detection with an application to car-following. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 58(2) </volume> <pages> 177-190, </pages> <month> September </month> <year> 1993. </year> <month> 23 </month>
Reference-contexts: Various approaches for recognizing and/or tracking cars from a moving camera have been suggested in the literature for example, detecting symmetry <ref> [33, 29, 4] </ref>, approximating optical flow [32, 13, 15, 22], exploiting binocular or trinocular stereopsis [23, 4, 26, 18], matching templates [26], and training a neural net [27].
References-found: 33

