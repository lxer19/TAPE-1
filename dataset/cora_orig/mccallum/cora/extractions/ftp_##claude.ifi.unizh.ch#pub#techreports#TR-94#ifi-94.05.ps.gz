URL: ftp://claude.ifi.unizh.ch/pub/techreports/TR-94/ifi-94.05.ps.gz
Refering-URL: http://www.cs.gatech.edu/people/home/jmankoff/collab-immers-env.html
Root-URL: 
Email: E-Mail: almassy vinkhuyz@ifi.unizh.ch  
Title: In  Evolution of adaptive behavior in dynamic environments  
Author: M. Jamashidi, C.C. Nguyen, R. Lumia, and J. Yuh Nikolaus Alm assy and Erik Vinkhuyzen 
Address: Winterthurerstrasse 190, 8057 Zurich, Switzerland  
Affiliation: AILab, Department of Computer Science, University Zurich-Irchel  
Note: (Eds.), Intelligent Automation and Soft Computing: Trends in Research, Development and Applications, Albuquerque, NM, pp. 419-424. TSI Press.  
Abstract: We use genetic algorithms to evolve behavioral properties of simulated autonomous vehicles. The traits of the robots that are being evolved include parameters and internal control mechanisms that drive the following-, approach- or avoidance behavior. A parallel steady state genetic algorithm is used to simulate natural evolution. We argue why we need evolutionary techniques to create adaptive behavior in dynamic environments.
Abstract-found: 1
Intro-found: 1
Reference: <author> Almassy, </author> <title> Nikolaus (1993). BUGWORLD: A distributed environment for the development of control-architectures in multi-agent worlds. </title> <type> technical report 93-32, </type> <institution> Department of Computer Science, University Zurich. </institution>
Reference-contexts: Such 1 simulations of autonomous robots are then criticized for the simplicity of the possible interac-tions. Despite these drawbacks simulations are vital to explore unknown aspects of the control architecture. In this work we use the BUGWORLD simulator <ref> (Almassy 1993) </ref> that makes the best possible trade-off between simple and fast simulations and a test bed that offers robot environment interactions that are rich enough such that they can be compared with real robots. <p> No other information about the simulated world is available to the agent. Separate processes define the world with its obstacles and targets and display it on the screen (See figure 1). The simulator <ref> (Almassy 1993) </ref> has been and is still successfully used in several projects (Almassy and Verschure 1992; Verschure 1992; Mondada and Verschure 1993).
Reference: <author> Almassy, Nikolaus and Paul Verschure (1992). </author> <title> Optimizing self-organizing control architectures with genetic algorithms: the interaction between natural selection and ontogenesis. </title> <booktitle> In Proceedings of the Second Conference on Parallel Problem Solving from Nature, </booktitle> <pages> pp. 451-460. </pages> <publisher> Elsevier. </publisher>
Reference-contexts: As a starting point we use basic mechanisms described in (Verschure and Pfeifer 1992) that are extended by genetically determined behavioral traits, that are implemented by various parameters and low-level rules. Previous work in this direction <ref> (Almassy and Verschure 1992) </ref> already showed the potential of evolutionary techniques in the development of robot controllers. Genetic programming (Koza 1992), a special form of evolutionary techniques was also used by (Brooks 1992) to achieve a more robust adaptive behavior of both simulated and real robots.
Reference: <author> Brooks, Rodney A. </author> <year> (1991). </year> <title> Intelligence without representation. </title> <journal> Artificial Intelligence, </journal> <volume> 47, </volume> <pages> 139-159. </pages>
Reference: <author> Brooks, Rodney A. </author> <year> (1992). </year> <title> Artificial life and real robots. </title> <booktitle> In Proceedings of the First European Conference on Artificial Life, </booktitle> <pages> pp. 3-10. </pages> <publisher> MIT Press. </publisher>
Reference-contexts: Previous work in this direction (Almassy and Verschure 1992) already showed the potential of evolutionary techniques in the development of robot controllers. Genetic programming (Koza 1992), a special form of evolutionary techniques was also used by <ref> (Brooks 1992) </ref> to achieve a more robust adaptive behavior of both simulated and real robots.
Reference: <editor> Davis, Lawrence (Ed.) </editor> <booktitle> (1991). Handbook of Genetic Algorithms, </booktitle> <address> New York. </address> <publisher> Van Nostrand Rein-hold. </publisher>
Reference: <author> Goldberg, David E. </author> <year> (1989). </year> <title> Genetic Algorithms in Search, Optimization, </title> <booktitle> and Machine Learning. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Therefore all PEs are always busy, and no time is waisted by waiting for a resynchronization necessary for a generational step. Such a genetic algorithm is called a steady state algorithm (Whitley 1989), to be distinguished from a canonical GA <ref> (Goldberg 1989) </ref>, that needs to know the mean fitness of the whole genotype pool (i.e. the current generation) to determine the selection function for the next generation.
Reference: <author> Harvey, Inman, Philip Husbands, and Dave Cliff (1992). </author> <title> Issues in evolutionary robotics. </title> <editor> In (Meyer, Roitblat, </editor> <booktitle> and Wilson 1992), </booktitle> <pages> pp. 364-373. </pages>
Reference: <author> Koza, John R. </author> <year> (1992). </year> <title> Genetic programming: on the programming of computers by means of natural selection. </title> <address> Cambridge, Mass.: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Previous work in this direction (Almassy and Verschure 1992) already showed the potential of evolutionary techniques in the development of robot controllers. Genetic programming <ref> (Koza 1992) </ref>, a special form of evolutionary techniques was also used by (Brooks 1992) to achieve a more robust adaptive behavior of both simulated and real robots.
Reference: <editor> Meyer, Jean-Arcady, Herbert L. Roitblat, and Stewart W. Wilson (Eds.) </editor> <booktitle> (1992). From Animals to Animats 2: Proceedings of the 2nd International Conference on Simulation of Adaptive Bahavior. </booktitle> <publisher> MIT Press. </publisher>
Reference: <author> Mondada, Francesco and Paul Verschure (1993). </author> <title> Modeling system-environment interaction: The complementary roles of simulation and real world artifacts. In Proceedings of the ECAL 93: Self organization & life: from simple rules to global complexity, pp. </title> <type> 808-817. </type> <institution> Universite Libre de Bruxelles. </institution>
Reference-contexts: The code of the robot's control architecture just has to be modified at the interface to the sensors and actuators. This technique of integrating simulations in the development of control architectures for real robots was successfully used by <ref> (Mondada and Verschure 1993) </ref>. 2 Evolution of behavioral properties As already outlined in Section 1 we believe that learning autonomous robots will exhibit a more robust behavior in dynamic environments than robots equipped with control architectures designed with traditional AI methods.
Reference: <author> Vaario, </author> <title> Jari and Setsuo Ohsuga (1992). An emergent construction of adaptive neural architectures. </title> <journal> Heuristics the journal of knowledge engineering. </journal>
Reference: <author> Verschure, </author> <month> Paul </month> <year> (1992). </year> <title> Modeling adaptive behavior: the dynamics of system environment interaction. </title> <type> Ph. D. thesis, </type> <institution> University of Zurich, Switzerland. </institution> <note> 7 Verschure, </note> <author> Paul, Ben Kr ose, and Rolf Pfeifer (1992). </author> <title> Distributed adaptive control, the self organi-zation of structured behavior. </title> <booktitle> In Robotics and Autonomous Systems. </booktitle> <publisher> Elsevier. </publisher>
Reference-contexts: Unlike others who used a genetic algorithm (GA) to evolve robot controllers (Vaario and Ohsuga 1992; Harvey, Husbands, and Cliff 1992), we do not start from scratch. As a starting point we use basic mechanisms described in <ref> (Verschure and Pfeifer 1992) </ref> that are extended by genetically determined behavioral traits, that are implemented by various parameters and low-level rules. Previous work in this direction (Almassy and Verschure 1992) already showed the potential of evolutionary techniques in the development of robot controllers. <p> As a starting point we use basic mechanisms described in (Verschure and Pfeifer 1992) that are extended by genetically determined behavioral traits, that are implemented by various parameters and low-level rules. Previous work in this direction <ref> (Almassy and Verschure 1992) </ref> already showed the potential of evolutionary techniques in the development of robot controllers. Genetic programming (Koza 1992), a special form of evolutionary techniques was also used by (Brooks 1992) to achieve a more robust adaptive behavior of both simulated and real robots. <p> These sensors are connected to a neural network very similar to the one used in <ref> (Verschure, Kr ose, and Pfeifer 1992) </ref>. We added a motion detector that detects other agents in the environment. This motion detector is a virtual sensor that predicts the range finder input based upon the previous two range finder inputs and the last step. <p> This decaying inhibitory connection between target seeking and obstacle avoidance, was also used by <ref> (Verschure 1992) </ref>, and implements some kind of frustration behavior. Additionally we have implemented a behavior that reacts to moving objects in the environment. In our simulated world, there are only static obstacles, so anything that moves must be another robot.
Reference: <author> Verschure, Paul and Rolf Pfeifer (1992). </author> <title> Categorization, representations, and the dynamics of system-environment interaction: A case study in autonomous agents. </title> <editor> In (Meyer, Roitblat, </editor> <booktitle> and Wilson 1992), </booktitle> <pages> pp. 210-217. </pages>
Reference-contexts: Unlike others who used a genetic algorithm (GA) to evolve robot controllers (Vaario and Ohsuga 1992; Harvey, Husbands, and Cliff 1992), we do not start from scratch. As a starting point we use basic mechanisms described in <ref> (Verschure and Pfeifer 1992) </ref> that are extended by genetically determined behavioral traits, that are implemented by various parameters and low-level rules. Previous work in this direction (Almassy and Verschure 1992) already showed the potential of evolutionary techniques in the development of robot controllers. <p> As a starting point we use basic mechanisms described in (Verschure and Pfeifer 1992) that are extended by genetically determined behavioral traits, that are implemented by various parameters and low-level rules. Previous work in this direction <ref> (Almassy and Verschure 1992) </ref> already showed the potential of evolutionary techniques in the development of robot controllers. Genetic programming (Koza 1992), a special form of evolutionary techniques was also used by (Brooks 1992) to achieve a more robust adaptive behavior of both simulated and real robots. <p> These sensors are connected to a neural network very similar to the one used in <ref> (Verschure, Kr ose, and Pfeifer 1992) </ref>. We added a motion detector that detects other agents in the environment. This motion detector is a virtual sensor that predicts the range finder input based upon the previous two range finder inputs and the last step. <p> This decaying inhibitory connection between target seeking and obstacle avoidance, was also used by <ref> (Verschure 1992) </ref>, and implements some kind of frustration behavior. Additionally we have implemented a behavior that reacts to moving objects in the environment. In our simulated world, there are only static obstacles, so anything that moves must be another robot.
Reference: <author> Whitley, </author> <title> Darrel (1989). The GENITOR algorithm and selection pressure: why rank-based allocation of reproductive trials is best. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pp. 116-121. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Therefore all PEs are always busy, and no time is waisted by waiting for a resynchronization necessary for a generational step. Such a genetic algorithm is called a steady state algorithm <ref> (Whitley 1989) </ref>, to be distinguished from a canonical GA (Goldberg 1989), that needs to know the mean fitness of the whole genotype pool (i.e. the current generation) to determine the selection function for the next generation. <p> Steady state GAs can be used to speed up a robust and focused evolutionary search <ref> (Whitley 1989) </ref>. Integration with a real environment To verify the control architectures, a robot interface will be built, that allows the execution of the same code of the control architectures on a real robot with hardware sensors and actuators.

References-found: 14

