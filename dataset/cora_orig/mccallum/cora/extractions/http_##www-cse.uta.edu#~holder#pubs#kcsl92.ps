URL: http://www-cse.uta.edu/~holder/pubs/kcsl92.ps
Refering-URL: http://www-cse.uta.edu/~holder/pubs.html
Root-URL: 
Title: Unifying Empirical and Explanation-Based Learning by Modeling the Utility of Learned Knowledge  
Author: Lawrence B. Holder 
Address: Box 19015, Arlington, TX 76019  
Affiliation: Department of Computer Science Engineering University of Texas at Arlington  
Abstract: The overfit problem in empirical learning and the utility problem in explanation-based learning describe a similar phenomenon: the degradation of performance due to an increase in the amount of learned knowledge. Plotting the performance of learned knowledge during the course of learning (the performance response) reveals a common trend for several learning methods. Modeling this trend allows a control system to constrain the amount of learned knowledge to achieve peak performance and avoid the general utility problem. Experiments evaluate a particular empirical model of the trend, and analysis of the learners derive several formal models. If, as evidence suggests, the general utility problem can be modeled using the same mechanisms for different learning paradigms, then the model serves to unify the paradigms into one framework capable of comparing and selecting different learning methods based on predicted achievable performance.
Abstract-found: 1
Intro-found: 1
Reference: <author> A. R. Barron. </author> <title> Predicted squared error: A criterion for automatic model selection. </title> <editor> In S. J. Farlow, editor, </editor> <booktitle> Self-Organizing Methods in Modeling, chapter 4, </booktitle> <pages> pages 87-103. </pages> <publisher> Marcel Dekker, </publisher> <year> 1984. </year>
Reference: <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <year> 1984. </year>
Reference: <author> P. Clark and T. Niblett. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 261-284, </pages> <year> 1989. </year>
Reference: <author> R. E. Fikes, P. E. Hart, and N. J. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 4(3) </volume> <pages> 189-208, </pages> <year> 1972. </year>
Reference: <author> L. B. Holder. </author> <title> The general utility problem in machine learning. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pages 402-410, </pages> <year> 1990. </year>
Reference: <author> L. B. Holder. </author> <title> Maintaining the Utility of Learned Knowledge Using Model-Based Adaptive Control. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Illinois, </institution> <month> October </month> <year> 1991. </year>
Reference: <author> L. B. Holder. </author> <title> Selection of learning methods using an adaptive model of knowledge utility. </title> <booktitle> In Proceedings of the First International Workshop on Multistrategy Learning, </booktitle> <pages> pages 247-254, </pages> <year> 1991. </year>
Reference: <author> R. C. Holte, L. E. Acker, and B. W. Porter. </author> <title> Concept learning and the problem of small disjuncts. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 813-818, </pages> <year> 1989. </year>
Reference: <author> E. D. Karnin. </author> <title> A simple procedure for pruning backpropagation trained neural networks. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 1(2) </volume> <pages> 239-242, </pages> <year> 1990. </year>
Reference: <author> R. S. Michalski. </author> <title> How to learn imprecise concepts: A method based on two-tiered representation and the AQ15 program. </title> <editor> In Y. Kodratoff and R. S. Michal-ski, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, Vol III. </booktitle> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1989. </year>
Reference: <author> S. Minton. </author> <title> Selectively generalizing plans for problem-solving. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 596-599, </pages> <year> 1985. </year>
Reference: <author> S. Minton. </author> <title> Learning Search Control Knowledge: An Explanation-Based Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference: <author> S. Minton. </author> <title> Issues in the design of operator composition systems. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pages 304-312, </pages> <year> 1990. </year>
Reference: <author> R. J. Mooney. </author> <title> The effect of rule use on the utility of explanation-based learning. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 725-730, </pages> <year> 1989. </year>
Reference: <author> M. C. Mozer and P. Smolensky. </author> <title> Using relevance to reduce network size automatically. </title> <journal> Connection Science, </journal> <volume> 1(1) </volume> <pages> 3-16, </pages> <year> 1989. </year>
Reference: <author> G. Pagallo and D. Haussler. </author> <title> Boolean feature discovery in empirical learning. </title> <journal> Machine Learning, </journal> <volume> 5(1) </volume> <pages> 71-100, </pages> <year> 1990. </year>
Reference: <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference: <author> J. R. Quinlan. </author> <title> Simplifying decision trees. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 27 </volume> <pages> 221-234, </pages> <year> 1987. </year>
Reference: <author> L. A. Rendell. </author> <title> A new basis for state-space learning systems and a successful implementation. </title> <journal> Artificial Intelligence, </journal> <volume> 20(4) </volume> <pages> 369-392, </pages> <year> 1983. </year>
Reference: <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <booktitle> In Parallel Distributed Processing, </booktitle> <volume> Volume 1, chapter 8, </volume> <pages> pages 318-362. </pages> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference: <author> M. Tambe and P. Rosenbloom. </author> <title> Eliminating expensive chunks by restricting expressiveness. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 731-737, </pages> <year> 1989. </year>
Reference: <author> J. Yoo and D. Fisher. </author> <title> Concept formation over problem-solving experience. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 630-636, </pages> <year> 1991. </year>
References-found: 22

