URL: http://www-cad.eecs.berkeley.edu:80/HomePages/aml/publications/ml91_def.ps.gz
Refering-URL: http://www-cad.eecs.berkeley.edu:80/HomePages/aml/publications/index.html
Root-URL: 
Title: Learning Concepts by Synthesizing Minimal Threshold Gate Networks  
Author: Arlindo L. Oliveira and Alberto Sangiovanni-Vincentelli 
Address: Berkeley CA 94720  
Affiliation: Dept. of EECS UC Berkeley  
Abstract: We propose a new methodology for the synthesis of two-level networks of threshold gates based on techniques related to the ones used in the logic synthesis of digital networks. The proposed approach starts with a large network that performs the desired mapping and reduces its size by applying transformations that preserve the func tionality for all examples in the training set.
Abstract-found: 1
Intro-found: 1
Reference: [Ash 89] <author> Ash, </author> <title> Timur "Dynamic Node Creation in Back Propagation Networks", </title> <booktitle> Connection Science 1:4, </booktitle> <pages> pp. 365-375, </pages> <year> 1989. </year>
Reference-contexts: Furthermore, these results were obtained after careful optimization of the parameters involved and he simply disregarded all cases where no convergence was obtained. Ash <ref> [Ash 89] </ref> reports superior convergence results with a constructive algorithm, but the larger examples reported are the 6-parity and 6-asymmetry, which are trivially simple for our algorithm. Furthermore, his algorithm failed to find solutions with the minimum number of units even for these smaller problems in some of the runs.
Reference: [Brayton et Al. 1984] <author> Brayton, R. K., G. D. Hachtel, C. T. McMullen & A. L. </author> <title> Sangiovanni-Vincentelli "Logic Minimization Algorithms for VLSI Synthesis", </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1984. </year>
Reference-contexts: The approach presented in this paper is different and introduces some new concepts like pyramids and M-covers. We will show that a substantial subset of the concepts developed for the synthesis of two-level logic networks <ref> [Brayton et Al. 1984] </ref> can be extended to the synthesis of threshold gate networks. 2 Basic concepts 2.1 Concepts, hypothesis and boolean functions We will use the usual setting for the problem of learning from examples in an attribute based description language. <p> We will generalize the concept of cube cover of a boolean function defined in <ref> [Brayton et Al. 1984] </ref> in two different directions. This generalization keeps the relation between a cover and a two-level implementation of f but allows for the use of general threshold gates in both the first and second levels. <p> zn dimensions that covers all the minterms in the f z ON set and none in the f z OF F . 2.5 Expanding and reducing pyramids The synthesis algorithm we propose in the next section is inspired in two-level synthesis algorithms for logic gate networks like, for example, ESPRESSO <ref> [Brayton et Al. 1984] </ref>. These algorithms work by perform ing successive expansion and reduction of cubes in the cover. Therefore, the ability to expand and reduce pyra mids proves necessary to the implementation of similar algorithms in the current setting.
Reference: [Brayton et Al. 1989] <author> Brayton, R. K., G. D. Hachtel & A. L. </author> <title> Sangiovanni-Vincentelli "Multilevel Logic Synthesis", </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 78:2, </volume> <pages> pp. 264-300, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: While two-level networks of threshold gates are enough to implement any concept, compact two-level representations may not exist for a large family of interesting concepts. The use of multi-level synthesis techniques <ref> [Brayton et Al. 1989] </ref> is the natural solution for this problem and a study on the applicability of these techniques to this problem is a promising area for future research. Acknowledgments This work was supported by the Air Force Office of Scientific Research (AFOSR/JSEP) under Contract No.
Reference: [Huyser & Horowitz, 1988] <author> Huyser, K. A & Horowitz, M. A. </author> <title> "Generalization in Digital Functions", </title> <booktitle> Abstract in Neural Networks 1:Suppl. </booktitle> <volume> 1, </volume> <pages> pp. 101, </pages> <year> 1988. </year>
Reference-contexts: Each hidden unit represents an intermediate concept, and its function is to be derived by some learning algorithm. In general, the smaller the network, the better the generalization performed, as long as it is large enough to learn the required mapping <ref> [Huyser & Horowitz, 1988] </ref>. Empirical evidence suggests that, in many cases, learning with the absolute minimum number of units is far more difficult than if some extra hidden units are allowed [Rumelhart & McClelland, Eds. 1986]. Logic synthesis techniques have been successfully used to generate compact implementations of logic networks.
Reference: [Kramer & Sangiovanni, 1989] <author> Alan Kramer & A. San-giovanni Vincentelli, </author> <title> "Efficient Parallel Learning Algorithms for Neural Networks", </title> <booktitle> Proceedings of 1988 IEEE Conference on Neural Information Processing Systems, </booktitle> <pages> pp. 40-48, </pages> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: Furthermore, his algorithm failed to find solutions with the minimum number of units even for these smaller problems in some of the runs. Our own experiments with a conjugate gradient method <ref> [Kramer & Sangiovanni, 1989] </ref> led us to conclude that, in general, it is difficult to load these concepts into networks when the minimum number of units is used in the hidden layer. For the larger problems the algorithm got consistently stuck in local minima.
Reference: [Muroga, 1971] <author> Muroga, </author> <title> Saburo "Threshold Logic and its Applications", </title> <publisher> Wiley-Interscience, </publisher> <year> 1971. </year>
Reference-contexts: Therefore, a strong motivation exists to apply some of the techniques used in traditional circuit design to the definition of architectures for general networks. While algorithms for the synthesis of threshold gate networks have been proposed before <ref> [Muroga, 1971] </ref> they are only applicable for functions of a very small number of variables and, in most cases, find solutions very far from the optimum. The approach presented in this paper is different and introduces some new concepts like pyramids and M-covers. <p> It is trivial to show that p p = ; and p [ p = f0; 1g n . This fact, together with a trivial generalization of the De Morgan laws leads to the following interesting result <ref> [Muroga, 1971] </ref>: Lemma 1: If a function f can be implemented by a network with H threshold gates and the inputs are available in both negated and non-negated form, then function f can also be implemented by a network of H threshold gates. 2.3 Covers and M-covers We are interested in
Reference: [Oliveira, 1991] <author> Oliveira, </author> <title> Arlindo "Logic Synthesis Using Threshold Gates", </title> <type> Internal Report, </type> <note> in preparation, </note> <institution> UC Berkeley, </institution> <year> 1991. </year>
Reference-contexts: In the outer loop of the algorithm, M is treated as a variable and increased when the search for a better solution fails. The procedure stops when a value of M is reached 2 A detailed description of the procedure can be found in <ref> [Oliveira, 1991] </ref>. for which no solution is found. This procedure may fail to find the best M -cover, even if the inner loop is guaranteed to find the global optimum for a given M . <p> For the larger problems the algorithm got consistently stuck in local minima. When larger networks were used for this method in order for the learning algorithm to succeed, the quality of the generalization obtained was consistently worst than the one obtained by applying our algorithm <ref> [Oliveira, 1991] </ref>.
Reference: [Rumelhart & McClelland, Eds. 1986] <editor> Rumelhart, D. E. & J. L. McClelland &, editors. </editor> <booktitle> "Parallel Distributed Processing: Explorations in the Microstructure of Cognition, </booktitle> <volume> Vol. 1, </volume> <publisher> MIT Press, </publisher> <address> Cambridge MA, </address> <year> 1986. </year>
Reference-contexts: Empirical evidence suggests that, in many cases, learning with the absolute minimum number of units is far more difficult than if some extra hidden units are allowed <ref> [Rumelhart & McClelland, Eds. 1986] </ref>. Logic synthesis techniques have been successfully used to generate compact implementations of logic networks. Unlike in most connectionist approaches, an architecture is derived from scratch to map the given input to the desired output, and is then modified to optimize one or more criteria. <p> The performance of our approach was evaluated by comparing the number of hidden units (H) in the networks synthesized by our algorithm with known bounds (H min ) on the size of two-level layered networks required to implement these concepts <ref> [Rumelhart & McClelland, Eds. 1986] </ref>. The maximum weight allowed for each network was the weight needed to achieve the known minimum realization. Table 1: Concepts description.
Reference: [Roychowdhury, 1989] <author> Roychowdhury, </author> <title> Jaijeet "Synthesis with M of N Gates", Internal Memo, </title> <institution> UC Berkeley, </institution> <year> 1989. </year>
Reference: [Tesauro & Janssens, 1988] <author> Tesauro, </author> <title> Gerald & Robert Janssens "Scaling relationships in back-propagation learning", </title> <journal> Complex Systems, </journal> <volume> 2 </volume> <pages> 39-44, </pages> <year> 1988. </year>
Reference-contexts: All results were obtained in a DECstation 3100. 4.1 Discussion Table 2 shows that we were able to obtain the minimum size realization for all but the two larger parity problems. The CPU times involved compare favorably with the ones described by Tesauro <ref> [Tesauro & Janssens, 1988] </ref> for the back-propagation method applied to the N-parity problems. He used 2N hidden units for an N-parity problem Table 2: Results.
References-found: 10

