URL: http://www-mash.cs.berkeley.edu/dist/mccanne/csd-96-928.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~mccanne/phd-work/
Root-URL: http://www.cs.berkeley.edu
Title: Scalable Compression and Transmission of Internet Multicast Video  
Author: Steven Ray McCanne 
Address: Berkeley, California 94720  
Affiliation: Computer Science Division (EECS) University of California  
Date: December 16, 1996  
Pubnum: Report No. UCB/CSD-96-928  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> E. H. Adelson, E. Simoncelli, and R. Hingorani. </author> <title> Orthogonal pyramid transforms for image coding. </title> <booktitle> In Proc. SPIE, </booktitle> <volume> volume 845, </volume> <pages> pages 50-58, </pages> <address> Cambridge, MA, </address> <month> October </month> <year> 1987. </year>
Reference-contexts: The filters used in many practical subband coding systems are neither orthonor-mal nor perfect-reconstruction. Stopband transitions, phase response characteristics, and ringing effects turn out to have a larger impact on the coding and perceptual performance of many practical algorithms. For example, the filters described in <ref> [1] </ref> perform well in practice but provide only nearly perfect reconstruction. However, the errors introduced by reconstruction imperfection are much smaller than those due to quantization and compression. <p> The YCbCr color space is related to the physical RGB space according to the following invertible transform: 2 4 C b 3 5 = 6 16 128 7 2 4 37:797 74:203 112:0 3 5 6 R B 7 where R, G, and B are each in <ref> [0; 1] </ref>. The chrominance components are sampled at half the rate of the luminance component along both the horizontal and vertical dimensions of the signal. <p> More specifically, call the input signal x = (x [0]; x <ref> [1] </ref>; : : : ; x [N 1]) of length N . We form a new signal ^x = (x [0]; x [0]; : : : ; x [N 1]; x [N 1]) of length N +2.
Reference: [2] <author> Andres Albanese, Johannes Bl omer, Jeff Edmonds, and Michael Luby. </author> <title> Priority encoding transmission. </title> <type> Technical Report TR-94-039, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> CA, </address> <month> Septem-ber </month> <year> 1994. </year>
Reference-contexts: Yavatkar and Manoj presented some simple techniques for packet transmission based on repetition codes (i.e., packet duplication) and parity packets [178]. Although these types of error-control codes are simple to implement, they have high overhead compared to more sophisticated codes and are not widely used. Priority Encoding Transmission (PET) <ref> [2] </ref> utilizes forward error-correction coding but considers only the so called unequal error protection (UEP) codes [116]. In this scheme, the source signal is partitioned according to the relative importance of different subsets of the bit stream. <p> Several researchers have additionally suggested using the I, P, B frame structure of MPEG to induce a temporal hierarchy <ref> [155, 2, 44] </ref>. 2.2.2 Pyramid Coding A landmark work in multiresolution image coding is Burt and Adelson's pyramid coding framework [19]. The basic structure is illustrated in Figure 2.5. The input image is first downsampled and low-pass 28 structure.
Reference: [3] <author> Elan Amir, Steven McCanne, and Martin Vetterli. </author> <title> A layered DCT coder for Internet video. </title> <booktitle> In Proceedings of the IEEE International Conference on Image Processing, </booktitle> <pages> pages 13-16, </pages> <address> Lausanne, Switzerland, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: Even though Progressive-JPEG is constrained to produce a layered representation, it often outperforms the non-layered baseline JPEG algorithm. Using the Independent JPEG Group's implementation, we found that Progressive-JPEG outperforms baseline JPEG by by 0.5 to 1dB of peak signal to noise ratio (PSNR) for the 512x512 Lena test image <ref> [3] </ref>. Progressive-JPEG is now widely deployed in the Internet because vendors of World Wide Web browsers embraced the technology soon after it was implemented and made freely available by the Independent JPEG group. <p> In the case of the Web, bottlenecks in network transmission far outweigh run-time performance bottlenecks and performance is of little concern. But for real-time video processing, the performance of the standard Progressive-JPEG algorithm degrades with the number of layers encoded. To reduce this effect, Amir et al. <ref> [3] </ref> designed a variant of Progressive-JPEG, called Layered-DCT (LDCT), specifically for Internet video coding. LDCT runs significantly faster than Progressive-JPEG with equivalent or better compression gain. <p> Instead of carrying out a separate pass for every bit-plane, the first several planes are grouped together and treated as a quantized coefficient. This reduces the run-time overhead since we process multiple layers in parallel as is done by the Layered-DCT implementation in <ref> [3] </ref>. We scan the subband coefficients in a quad-tree fashion as described above and entropy-code each non-zero coefficient that is identified in the scan.
Reference: [4] <author> Elan Amir, Steven McCanne, and Hui Zhang. </author> <title> An application-level video gateway. </title> <booktitle> In Proceedings of ACM Multimedia '95, </booktitle> <pages> pages 255-265, </pages> <address> San Francisco, CA, </address> <month> November </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: This video gateway architecture was first fully developed and fielded by Amir et al. <ref> [4] </ref> in a specific application called vgw, which provided design feedback for the RTP specification and contributed an efficient software-based method for transcoding high-rate Motion-JPEG video into low-rate H.261. For example, network heterogeneity underlying the UCB MBone seminar transmissions described in Chapter 1 has been handled with video gateways. <p> For example, the gateway could allocate the largest share of bandwidth to the most recently active user and small amounts of bandwidth to less recently active users <ref> [4] </ref>. Floor Control All of our MBone tools have the ability to mute or ignore a network media source, and the disposition of this mute control can be controlled by external agents via the Coordination Bus.
Reference: [5] <author> T. Bailly, Bernard Gold, and Stephanie Seneff. </author> <title> A technique for adaptive voice flow control in integrated packet networks. </title> <journal> IEEE Transactions on Communications, </journal> <volume> COM-28(4):325-333, </volume> <month> March </month> <year> 1980. </year>
Reference-contexts: One early work on packet audio proposed that short-term congestion be accommodated through the combination of layered compression at the source with prioritized packet dropping in the network <ref> [5] </ref>. Karlsson and Vetterli [100, 101] later described the integration of packet video into a general network architecture. They were the first to suggest the use of layered source-coding for video combined with prioritized packet-discard to carry out loss recovery.
Reference: [6] <author> D. Balenson. </author> <title> Privacy Enhancement for Internet Electronic Mail: Part III: Algorithms, Modes, and Identifiers. ARPANET Working Group Requests for Comment, </title> <institution> DDN Network Information Center, </institution> <month> February </month> <year> 1993. </year> <month> RFC-1423. </month>
Reference-contexts: The encryption key is specified to the session participants via some external, secure distribution mechanism. Vic supports multiple encryption schemes with a C++ class hierarchy. By default, we use the Data Encryption Standard (DES) in cipher block chaining mode <ref> [6] </ref>. While weaker forms of encryption could be used (e.g., those based on linear feedback shift registers), efficient implementations of the DES give good performance on current hardware (measurements are given in [91]). The computational requirements of compression/decompression far outweigh the cost of encryption/decryption.
Reference: [7] <author> Tony Ballardie, Paul Francis, and Jon Crowcroft. </author> <title> Core based trees (CBT) an architecture for scalable inter-domain multicast routing. </title> <booktitle> In Proceedings of SIGCOMM '93, </booktitle> <pages> pages 85-95, </pages> <address> San Francisco, CA, </address> <month> September </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: A number of multicast routing protocols compute spanning trees from an anchor point in the network (either the sending host or a rendezvous point or core) to all of the receivers, e.g., Protocol Independent Multicast (PIM) [40], Distance Vector Multicast Routing Protocol (DVMRP) [174], or Core Based Trees (CBT) <ref> [7] </ref>. Because the anchor point (i.e., source address) uniquely identifies the spanning tree, multi-cast routers can use it to compute the forwarding decision for a given packet. <p> One way to improve this scaling behavior is to use a centralized rather than source-based approach to mul-ticast routing as in CBT <ref> [7] </ref> and Sparse-mode PIM [40]. Although this approach improves the state requirement to scale linearly with the number of groups, it precludes the efficiency of shortest path routes in a source-based tree. <p> A.2.2 Block Transform PVH is a transform coding algorithm that exploits the Discrete Cosine Transform (DCT) over 8x8 blocks. The 8x8 DCT is defined as follows: f (x; y) = 1=4 u=0 v=0 for u; v; x; y 2 <ref> [0; 7] </ref> and where C (x) = 1= 2 for x = 0 f () represents the image block signal in the pixel domain while F () represents the block of DCT transform coefficients.
Reference: [8] <author> A. Banerjea, D. Ferrari, B. Mah, M. Moran, D. Verma, and H. Zhang. </author> <title> The Tenet real-time protocol suite: Design, implementation, and experiences. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 4(1) </volume> <pages> 1-10, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: A comprehensive survey of all of this work is beyond the scope of this chapter and we instead describe just a few of the approaches. A landmark work in real-time service guarantees is the Tenet Real-time Protocol Suite <ref> [53, 8] </ref>. The 19 Tenet project focused on providing provable performance guarantees from the network to the client. In the Tenet model, a client describes its traffic parameters and its service requirements to the network. <p> Since RTP is independent of the underlying network technology, it simultaneously supports multiple network protocols. Figure 3.2 illustrates how RTP fits into several protocol stacks. For IP and IP Mul-ticast, RTP is layered over UDP, while in the Tenet protocols, it runs over RMTP/RTIP <ref> [8] </ref>. Similarly, applications can run directly over an ATM Adaptation Layer. In all these cases, RTP is realized in the application itself. 46 RTP has allowed our tool vic to be successfully deployed over the Tenet Real-time Message Transport Protocol (RMTP) [8] and the ATM Adaptation Layer (AAL5) in addition to <p> while in the Tenet protocols, it runs over RMTP/RTIP <ref> [8] </ref>. Similarly, applications can run directly over an ATM Adaptation Layer. In all these cases, RTP is realized in the application itself. 46 RTP has allowed our tool vic to be successfully deployed over the Tenet Real-time Message Transport Protocol (RMTP) [8] and the ATM Adaptation Layer (AAL5) in addition to its commonly used configuration of UDP over IP Multicast. 3.5 Multiple Multicast Groups A network host typically differentiates multiple incoming data flows with a transport-level demul-tiplexing identifier usually called a port.
Reference: [9] <author> A. Banerjea, E. Knightly, F. Templin, and H. Zhang. </author> <title> Experiments with the Tenet real-time protocol suite on the Sequoia 2000 wide area network. </title> <booktitle> In Proceedings of ACM Multimedia '94, </booktitle> <address> San Francisco, CA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: Vic has been used in several class projects at U.C. Berkeley as well as in several external research projects. It was the test application in a study of the Tenet real-time protocols over the Sequoia 2000 network <ref> [9] </ref>. In November 1994, a live surgery performed at the U.C. San Francisco Medical School was transmitted to a medical conference in Europe using vic's Intra-H.261. During the surgical demonstration, the surgeon lectured to medical students at Middlesex and Whittington Hospitals in London and in Gothenburg, Sweden.
Reference: [10] <author> L. Berc, W. Fenner, R. Frederick, and S. McCanne. </author> <title> RTP Payload Format for JPEG-compressed Video. </title> <institution> Internet Engineering Task Force, Audio-Video Transport Working Group, </institution> <month> November </month> <year> 1995. </year> <title> Internet Draft (work in progress). </title>
Reference-contexts: Moreover, our experience implementing the RTP payload specification for H.261 led to an improved scheme based on macroblock-level fragmentation, which resulted in a revised protocol [166]. Finally, the RTP payload specification for JPEG <ref> [10] </ref> evolved from a vic implementation. The most recent major development in MBone applications is the Robust Audio Tool, rat, from University College London in 1995. Rat uses a novel forward error correction scheme where redundant information is coded at lower quality.
Reference: [11] <author> Arthur W. Berger, Samuel P. Morgan, and Amy R. Reibman. </author> <title> Statistical multiplexing of layered video streams over ATM networks with leaky-bucket traffic descriptors. </title> <journal> Submitted to IEEE Transactions on Networking, </journal> <year> 1993. </year> <month> 160 </month>
Reference-contexts: A large number of layered coding schemes have been proposed, including schemes based on progressive DCT [68, 142, 104], subband coding <ref> [39, 11, 158] </ref>, and pyramidal coding [139]. We reviewed some key areas in layered compression research and cited representative or landmark work in each area.
Reference: [12] <author> Tim Berners-Lee, Robert Cailliau, Ari Luotonen, Henrik Frystyk Nielson, and Arthur Secret. </author> <title> The World-Wide Web. </title> <journal> Communications of the ACM, </journal> <volume> 37(8) </volume> <pages> 76-82, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: But advances in digital video compression and high-speed networking along with improved workstation performance have together made digital video applications not only feasible but also economical. These trends combine with growing public interest in the Internet and the proliferation of the World Wide Web <ref> [12] </ref> to create a new breed of multimedia-rich application requirements and new demand for packet video applications. As a result, research related to packet video has proliferated.
Reference: [13] <author> Steven Langley Blake. </author> <title> Optimized Two-Layer DCT-Based Video Compression Algorithm for Packet-switched Network Transmission. </title> <type> PhD thesis, </type> <institution> North Carolina State University, </institution> <year> 1995. </year>
Reference-contexts: His scheme is targeted for a specific slotted network which provides real-time guarantees. Similarly, Blake proposed a two-layer coder that is backward compatible with the H.261 specification <ref> [13] </ref>. He explored the performance implications of rate-control applied jointly to both layers and its impact on an admission control algorithm. Forward error-correction (FEC) coding is often cited as a technique for coping with isolated packet loss.
Reference: [14] <author> Jean-Chrysostome Bolot. </author> <title> End-to-end packet delay and loss behavior in the Internet. </title> <booktitle> In Proceedings of SIGCOMM '93, </booktitle> <pages> pages 289-298, </pages> <address> San Francisco, CA, </address> <month> September </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: to use it, the software must work well over a large range of machine capabilities and therefore must have an efficient implementation. * Finally, because RLM drives the network into momentary periods of congestion and because the Internet environment is best-effort, loosely controlled, sometimes unpredictable, and involves bursty packet loss <ref> [14] </ref>, the algorithm must have high loss resilience. That is when packets are dropped, the decoder should not have to wait long before re-synchronizing and the resulting errors should not persist unrea sonably long or make the partially decoded video signal incomprehensible.
Reference: [15] <author> Jean-Chrysostome Bolot, Thierry Turletti, and Ian Wakeman. </author> <title> Scalable feedback control for multi-cast video distribution in the Internet. </title> <booktitle> In Proceedings of SIGCOMM '94, </booktitle> <address> University College London, London, U.K., </address> <month> September </month> <year> 1994. </year> <note> ACM. </note>
Reference-contexts: The most widely deployed reactive congestion control scheme is a feedback protocol developed by Bolot, Turletti and Wakeman <ref> [15] </ref>. Their protocol is implemented in the INRIA Videoconferenceing System (ivs), which like nv and vic, runs over RTP and IP Multicast. As in related schemes, they use feedback from the network to control the output rate of the video coder, in this case, an H.261 [171] software codec. <p> We now consider the performance of RLM's receiver-based adaptation relative to source-based control. To do so, we implemented a version of the ivs congestion control scheme in ns based both on the description in <ref> [15] </ref> and on a reference implementation. We separately simulated an IVS conversation 4 and an RLM conversation on the topology depicted in Figure 5.19. In both cases, we configured a source at S to become active at the beginning of the simulation simultaneously with a receiver labeled R 1 . <p> No damping is introduced into the control law, thus preventing the system from settling to a stable operating point. We note that this same ringing effect is apparent from actual measurements carried out in <ref> [15, Figure 5] </ref>. When the second receiver arrives at time 300, congestion occurs because of limited capacity along the S=R 2 path. R 2 eventually notifies the source, which in response throttles back its transmission rate on each round-trip time until the new receiver no longer reports congestion. <p> RLM on the other handles this condition gracefully 5 . As seen in the figure, the two receivers split 5 The IVS congestion control scheme was a pioneering work in rate-adaptive video and its authors readily recognized the shortcoming of source-based adaptation. In <ref> [15] </ref>, layered transmission was briefly cited as a potential solution for accommodating bandwidth heterogeneity but the authors proposed no specific solution and suggested that such a system would require explicit support from network routers. 91 their rate and adapt to the capacity of the individual links.
Reference: [16] <author> C. Mic Borman, Peter B. Danzig, Darren R. Hardy, Udi Manber, and Michael F. Schwartz. </author> <title> The harvest information discovery and access system. </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> 28 </volume> <pages> 119-125, </pages> <year> 1995. </year>
Reference-contexts: Likewise, both the PVH image and video formats have the potential to enhance the effectiveness and performance of Web proxies [60] and Web caches <ref> [16] </ref>. Rather than perform potentially heavy computation to transcode image formats on the fly, a bandwidth-adaptive proxy could selectively forward image or video layers to tailor the transfer to network path. <p> CCIR Recommendation 601-1 specifies an 8-bit coding for each component where Y ranges over 0 to 219 with an offset of 16 while Cb and Cr range over -112 to +112 with an offset of 128. Hence, encoded values of Y fall in the absolute range <ref> [16; 235] </ref> while Cb and Cr fall in [16; 240]. <p> Hence, encoded values of Y fall in the absolute range [16; 235] while Cb and Cr fall in <ref> [16; 240] </ref>.
Reference: [17] <author> R. Braden, L. Zhang, D. Estrin, S. Herzog, and S. Jamin. </author> <title> Resource reservation protocol (RSVP) - version 1 function specification, </title> <month> November </month> <year> 1996. </year> <title> Internet Draft (RFC pending). </title>
Reference-contexts: For example, on a network that supports different qualities of service, a QoS tool might use the focus message to give more video bandwidth to the current speaker, e.g., using dynamic RSVP filters <ref> [17] </ref>. Alternatively, a video gateway might monitor the audio channel to dynamically adapt the allocation of video bandwidth to each source in the session.
Reference: [18] <author> Tom Brown, Sharif Sazzad, Charles Schroeder, Pierce Cantrell, and Jerry Gibson. </author> <title> Packet video for heterogeneous networks using CU-SeeMe. </title> <booktitle> In Proceedings of the IEEE International Conference on Image Processing, </booktitle> <pages> pages 9-12, </pages> <address> Lausanne, Switzerland, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: Brown et al. have implemented a multi-resolution extension to the CU-SeeMe video conferencing system where IP Multicast receivers subscribe to either a 160x120 or a 320x240 stream by joining either one or two multicast groups <ref> [18] </ref>. Receivers drop down to the 160x120 resolution when they detect high packet loss rates. The RSVP architecture was designed to explicitly accommodate layered flows using resource reservations [179].
Reference: [19] <author> Peter J. Burt and Edward H. Adelson. </author> <title> The laplacian pyramid as a compact image code. </title> <journal> IEEE Transactions on Communications, </journal> <volume> COM-31(4):532-540, </volume> <month> April </month> <year> 1983. </year>
Reference-contexts: Several researchers have additionally suggested using the I, P, B frame structure of MPEG to induce a temporal hierarchy [155, 2, 44]. 2.2.2 Pyramid Coding A landmark work in multiresolution image coding is Burt and Adelson's pyramid coding framework <ref> [19] </ref>. The basic structure is illustrated in Figure 2.5. The input image is first downsampled and low-pass 28 structure. The input signal is low-pass filtered and downsampled to give a coarse scale representation, which is quantized by Q C and transmitted on a base-layer channel.
Reference: [20] <author> Ingo Busse, Bernd Deffner, and Henning Schulzrinne. </author> <title> Dynamic QoS control of multimedia applications based on RTP. </title> <booktitle> In Proceedings of the First International Workship on High Speed Networks and Open Distributed Platforms, </booktitle> <address> St. Petersburg, Russia, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Busse et al. <ref> [20] </ref> first implemented this approach (and worked out many unspecified details) by modifying vic [120] with a specific instance of an RTCP-based multicast feedback control algorithm.
Reference: [21] <author> A. Campbell and G. Coulson. </author> <title> A QoS adaptive transport system: Design, implementation and experience. </title> <booktitle> In Proceedings of ACM Multimedia '96, </booktitle> <address> Boston, MA, </address> <month> November </month> <year> 1996. </year> <note> ACM. </note>
Reference-contexts: Also, there is no mechanism for discovering bandwidth when it becomes available. Since the only action is to drop a layer, over time, each receiver eventually drops down to the minimal level of subscription. Campbell and Coulson proposed a receiver-oriented video delivery system that relies on layered compression <ref> [21] </ref>. Their QoS adaptor assumes a native ATM network that provides performance guarantees on a base-layer stream. Receivers issue reservation signaling messages to the network that reflect the level of congestion. In the presence of congestion, the receiver reduces the resource request in the reservation.
Reference: [22] <author> S. Casner, J. Lynn, P. Park, K. Schroder, and C. Topolcic. </author> <title> Experimental Internet Stream Protocol, </title> <type> version 2 (ST-II). </type> <institution> ARPANET Working Group Requests for Comment, DDN Network Information Center, SRI International, </institution> <address> Menlo Park, CA, </address> <month> October </month> <year> 1990. </year> <month> RFC-1190. </month>
Reference-contexts: The Discrete Scaling mechanism in the Heidelberg Transport System (HeiTS) [44] uses a receiver-oriented scheme for adapting to delivered bandwidth. Here, receivers open and close ST-II <ref> [22] </ref> multicast 24 connections to adapt to bandwidth. The authors do not discuss adaptation algorithms or report implementation results. As described in Chapter 1, Deering first suggested that the IP Multicast be used as a layered transmission system where layers are individually mapped onto multicast groups [43].
Reference: [23] <author> Steve Casner and Steve Deering. </author> <title> First IETF Internet audiocast. </title> <journal> ConneXions, </journal> <volume> 6(6) </volume> <pages> 10-17, </pages> <year> 1992. </year>
Reference-contexts: Thirty-two isolated multicast sites spread over four countries were configured into a large virtual multicast network, which in turn was used to audiocast the 23rd Internet Engineering Task Force (IETF) meeting. The virtual network backbone used to glue together the multicast-capable subnetworks was dubbed the Multicast Backbone, or MBone <ref> [23] </ref>. For the first time, IETF participants were able to attend working group meetings and participate in the conference from a distance. Even though there were a number of technical difficulties, the experiment proved enormously successful.
Reference: [24] <author> Navin Chaddha. </author> <title> Software only scalable video delivery system for multimedia applications over hetro-geneous networks. </title> <booktitle> In Proceedings of the IEEE International Conference on Image Processing, </booktitle> <address> Wash-ington, DC, </address> <month> October </month> <year> 1995. </year>
Reference-contexts: The network forwards only the number of layers that each physical link can support. much of the previous work leaves this problem as an implementation detail, a novel and practical scheme was proposed by Deering [43] and was further described and/or independently cited in <ref> [24, 44, 83, 122, 165] </ref>. In this approach, the layers that comprise the hierarchical signal are striped across distinct multicast groups thereby allowing receivers to adjust their reception rate by controlling the number of groups they receive. <p> When combined with RLM, our Progressive Video with Hybrid-transform codec, or PVH, provides a comprehensive solution for scalable multicast video transmission in heterogeneous networks. 1.4 Contributions A number of research activities have laid the groundwork for both layered video compression <ref> [100, 124, 24, 162, 173] </ref> and layered transmission systems [101, 155, 43, 132, 165, 78]. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem. <p> The Laplacian pyramid was a break-through innovation that led to a number of image and video coding schemes. One example is Chaddha et al.'s scheme <ref> [26, 24] </ref> based on a Laplacian pyramid and tree-structured vector quantization [67] of the refinement bands. Both the vector codebook construction algorithm and vector searches during the encoding process are computationally expensive, but the decoder algorithm can be carried out efficiently almost exclusively with table lookups.
Reference: [25] <author> Navin Chaddha and Anoop Gupta. </author> <title> A frame-work for live multicast of video streams over the Internet. </title> <booktitle> In Proceedings of the IEEE International Conference on Image Processing, </booktitle> <pages> pages 1-4, </pages> <address> Lausanne, Switzerland, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: The authors do not discuss adaptation algorithms or report implementation results. As described in Chapter 1, Deering first suggested that the IP Multicast be used as a layered transmission system where layers are individually mapped onto multicast groups [43]. Both Turletti and Bolot [165] and Chaddha and Gupta <ref> [25] </ref> describe this architecture but do not present an adaptation algorithm or implementation. Our approach was first described in [118] and [122], but a specific adaptation scheme was not published until [121].
Reference: [26] <author> Navin Chaddha, Gerard A. Wall, and Brian Schmidt. </author> <title> An end to end software only scalable video delivery system. </title> <booktitle> In Proceedings of the Fifth International Workshop on Network and OS Support for Digital Audio and Video, </booktitle> <address> Durham, NH, </address> <month> April </month> <year> 1995. </year> <journal> ACM. </journal> <volume> 161 </volume>
Reference-contexts: The Laplacian pyramid was a break-through innovation that led to a number of image and video coding schemes. One example is Chaddha et al.'s scheme <ref> [26, 24] </ref> based on a Laplacian pyramid and tree-structured vector quantization [67] of the refinement bands. Both the vector codebook construction algorithm and vector searches during the encoding process are computationally expensive, but the decoder algorithm can be carried out efficiently almost exclusively with table lookups.
Reference: [27] <author> Shun Yan Cheung, Mostafa H. Ammar, and Xue Li. </author> <title> On the use of destination set grouping to improve fairness in multicast video distribution. </title> <booktitle> In Proceedings IEEE Infocom '96, </booktitle> <pages> pages 553-560, </pages> <address> San Francisco, CA, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: The network informs the source of the new requirements, which in turn may cause the source to alter its transmission rates. If so, an adapt message is broadcast to the receivers to update their knowledge of available resources. Cheung et al. <ref> [27] </ref> extended the ivs congestion control scheme with destination set grouping (DSG). Under DSG, a source transmits its signal at multiple rates across a set of multicast groups. The receivers are partitioned across the groups and each group's rate is controlled via the ivs algorithm.
Reference: [28] <author> Hin Soon Chin, John W. Goodge, Roy Griffiths, and David J. Parish. </author> <title> Statistics of video signals for viewphone-type pictures. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 7(5) </volume> <pages> 826-832, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: The efficiency of peak rate allocation is greatly reduced by the inherent burstiness of video. Chin 16 packet video. The smoothing buffer is eliminated and replaced by the network. Congestion feedback from the network, rather than the smoothing-buffer occupancy, controls the codec output rate. et al. <ref> [28] </ref> characterized the burstiness of compressed video signals, and later, Garrett and Willenger [65] showed that typical video sources exhibit long-range dependence, where rate behavior is bursty even on large time scales.
Reference: [29] <author> C. A. Christopoulos, A. N. Skodras, and J. Cornelis. </author> <title> Comparative performance evaluation of algorithms for fast computation of the two-dimensional DCT. </title> <booktitle> In Proceedings of the IEFFF Benelux and ProRISC Workshop on Circuits, Systems and Signal Processing, </booktitle> <address> Papendal, Arnhen, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: Because the encoder uses only a small, simple subset of H.261, the implementation is straightforward (a few hundred lines of C++). We achieve good computational performance by folding quantization into the DCT computation and by using an efficient 80-multiply 8x8 DCT [135]. We experimented with several vector-radix DCTs <ref> [29] </ref> but found that the separable row-column approach, despite having asymptotically higher complexity, performed better in the 8x8 case because of reduced memory traffic. Furthermore, because Intra-H.261 never sends inter-coded blocks, the algorithm avoids computing a prediction error signal.
Reference: [30] <author> David Clark, Scott Shenker, and Lixia Zhang. </author> <title> Supporting realtime applications in an integrated services packet network: Architecture and mechanism. </title> <booktitle> In Proceedings of SIGCOMM '92, </booktitle> <pages> pages 14-26, </pages> <address> Baltimore, Maryland, </address> <month> August </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: In [99], Karlsson surveys the integration of digital video and ATM networks. In contrast to the focus on provable guarantees taken in Tenet and ATM, some researchers believe that softer guarantees can be used to simplify the network design but still provide good performance. In Predictive Service <ref> [30] </ref>, present and past performance is used to predict future performance and hence the network can base admission control decisions on measurements rather than a priori traffic signatures [96]. <p> In all of our simulations, the link bandwidths are 510 kb/s, the traffic sources are modeled as a six-layer CBR stream at rates 32 fi 2 m kb/s; m = 0 : : : 5, and the start-time of each receiver is randomly chosen uniformly on the interval <ref> [30; 120] </ref> seconds. The protocol constants from Table 5.1 have the following values: ff = 2, fi = 3=4, k 1 = 1, k 2 = 2, g 1 = 0:25, g 2 = 0:25, T min J = 60 sec.
Reference: [31] <author> David D. Clark and David L. Tennenhouse. </author> <title> Architectural considerations for a new generation of protocols. </title> <booktitle> In Proceedings of SIGCOMM '90, </booktitle> <address> Philadelphia, PA, </address> <month> September </month> <year> 1990. </year> <note> ACM. </note>
Reference-contexts: This chapter develops the idea that ALF and JSCC are parallel concepts. The notion that an application's semantics should be reflected in the design of its network protocol is embodied in Clark and Tennenhouse's ALF protocol architecture <ref> [31] </ref>. Heybey's thesis explores the integration of video coding algorithms into the ALF framework by adopting existing compression standards (e.g., JPEG, H.261, and MPEG) without modification [81].
Reference: [32] <author> D. Cohen. </author> <title> On packet speech communication. </title> <booktitle> In Proceedings of the Fifth International Conference on Computer Communications, </booktitle> <pages> pages 271-274, </pages> <address> Atlanta, Georgia, </address> <month> October </month> <year> 1980. </year> <note> IEEE. </note>
Reference-contexts: In support of one of its key research charters, the DARTNet community developed a number of real-time, interactive multimedia applications that exploited IP Multicast to study the problem of multiparty remote-conferencing over packet-switched networks. Building on their pioneering packet audio work from the seventies <ref> [32] </ref> and on earlier work at Bolt, Beranek, and Newman Inc., researchers at ISI crafted an audio conferencing application called the Voice Terminal, or vt. In February of 1991, the first packet audio conference was held over DARTNet using the Network Voice Protocol (NVP) [33] implemented within vt. <p> a number of remaining challenges with our approach, present plans for future work, provide references to our implementation and simulation framework, and conclude. 14 Chapter 2 Related Work In the early days of the Internet, experiments with digitized voice demonstrated that interactive, real-time signals could be carried over packet-switched networks <ref> [32, 33, 149] </ref>. While packet voice was relatively easy to deploy because voice-grade audio codecs generate fairly low-rate data streams, packet video was less practical because of much higher bandwidth requirements and, at the time, limitations in digital video technology.
Reference: [33] <author> Danny Cohen. </author> <title> Specifications for the Network Voice Protocol (NVP). ARPANET Working Group Requests for Comment, </title> <institution> DDN Network Information Center, Information Sciences Institute, </institution> <year> 1976. </year> <month> RFC-741. </month>
Reference-contexts: In February of 1991, the first packet audio conference was held over DARTNet using the Network Voice Protocol (NVP) <ref> [33] </ref> implemented within vt. By June, weekly research meetings among the DARTNet participants were held using NVP audio and the DARTNet multicast infrastructure. Because vt was a pioneering research prototype that focused principally on network research issues, little effort went into developing its user interface. <p> a number of remaining challenges with our approach, present plans for future work, provide references to our implementation and simulation framework, and conclude. 14 Chapter 2 Related Work In the early days of the Internet, experiments with digitized voice demonstrated that interactive, real-time signals could be carried over packet-switched networks <ref> [32, 33, 149] </ref>. While packet voice was relatively easy to deploy because voice-grade audio codecs generate fairly low-rate data streams, packet video was less practical because of much higher bandwidth requirements and, at the time, limitations in digital video technology.
Reference: [34] <author> Charles Compton and David Tennenhouse. </author> <title> Collaborative load shedding for media-based applications. </title> <booktitle> International Conference on Multimedia Computing and Systems, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: Consequently, in addition to packet loss in the network, messages can be lost in the end-system when the decoder cannot keep up with a high-rate incoming bit stream. In this case, the decoder should gracefully adapt by trading off reconstruction quality to shed work <ref> [34, 51] </ref>. However, such adaptation is difficult under the temporal prediction model because the decoder must fully decode all differential updates to maintain a consistent prediction state. In contrast, with conditional replenishment, compute-scalability is both feasible and simple. <p> In this case, packets are dropped by the operating system due to input buffer overflows and quality degrades dramatically. To address this problem, we can exploit RLM to gracefully adapt the application to the available CPU resources by shedding load <ref> [51, 34] </ref>. On the one hand, RLM provides a convenient mechanism for adapting not only to network loss but also to local computational resources because its reaction of dropping layers reduces the local processing burden. Hence, we can carry out both load adaptation and network congestion adaptation exclusively with RLM.
Reference: [35] <author> Thomas M. </author> <title> Cover. Broadcast channels. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-18(1):2-14, </volume> <month> January </month> <year> 1972. </year>
Reference-contexts: On the other hand, separation does not necessarily apply to other typical communication environments. Cover showed that, for a certain model of broadcast channel, performance can be improved by superimposing the delivery of low-rate and high-rate information <ref> [35] </ref>, e.g., by distributing video to heterogeneous receivers in a layered format. Hence, performance can be improved by modifying the source-coding algorithm (i.e., layered compression) to better match the channel-coding algorithm (i.e., layered transmission).
Reference: [36] <author> Earl Craighill, Martin Fong, Keith Skinner, Ruth Lang, and Kathryn Gruenefeldt. SCOOT: </author> <title> An object-oriented toolkit for multimedia collaboration. </title> <booktitle> In Proceedings of ACM Multimedia '94, </booktitle> <pages> pages 41-49. </pages> <publisher> ACM, </publisher> <month> October </month> <year> 1994. </year>
Reference-contexts: To simplify the programming model, toolkits usually assume that communication is application-independent and offer a generic, least-common-denominator network interface built using traditional transport protocols. The multimedia and computer-supported collaborative-work research communities have developed an array of toolkits and techniques for collaborative work. Examples include DAVE [125], SCOOT <ref> [36] </ref>, 38 GroupKit [143], the Continuous Media Toolkit (CMT) [144], and VuSystem [112]. We briefly describe CMT and VuSystem since their approaches are most similar to ours. CMT is an object-oriented multimedia toolkit that allows objects to be mixed and matched into arbitrary applications. <p> Likewise, Schulzrinne developed a coordination scheme that ties together the MBone tools using Pattern Matching Multicast, a framework like our Coordination Bus with pattern-matching filters [151]. Our Composable Tools approach to networked multimedia contrasts with the more common toolkit framework adopted by other multimedia systems <ref> [36, 125, 143, 145] </ref>. Toolkits provide basic building blocks in the form of a code library with an application programming interface (API) to that library providing high-level abstractions for manipulating multimedia data flows.
Reference: [37] <author> John M. Danskin, Geoffrey M. Davis, and Xiyong Song. </author> <title> Fast lossy Internet image transmission. </title> <booktitle> In Proceedings of ACM Multimedia '95, </booktitle> <pages> pages 321-332, </pages> <address> San Francisco, CA, </address> <month> November </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: We believe that the emergence of JSCC and ALF signals a shift in the core nature of network research the traditional, highly layered protocol architecture must be abandoned. Rather than design protocols composed of modular black boxes, we must synthesize new, application-specific protocols (e.g., FLIIT <ref> [37] </ref>, RLM, RTP [153], and SRM [59]) that account for the interaction between application and network. 52 In this chapter, we establish ALF and JSCC as a core design principle for our layered video architecture.
Reference: [38] <author> Peter B. Danzig. </author> <title> Optimally Selecting the Parameters of Adaptive Backoff Algorithms for Computer Networks and Multiprocessors. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: Multicast control is fundamentally more complex than its unicast counterpart because there are multiple sources of feedback. This multiplicity of feedback causes scaling problems. In a naively designed multicast protocol, certain events could cause synchronous actions where an entire multicast group responds with feedback simultaneously. First described by Danzig <ref> [38] </ref>, this feedback implosion can swamp the source and lead to unstable conditions. For example, a straightforward extension of unicast-based congestion control to multicast might have the source solicit feedback from all the receivers in the network. But as Figure 2.3 illustrates, this would cause feedback implosion.
Reference: [39] <author> John C. Darragh and Richard L. Baker. </author> <title> Fixed distortion subband coding of images for packet-switched networks. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 7(5) </volume> <pages> 789-800, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: One solution to the problem of variable quality at constant rate is to allocate enough bandwidth in the CBR channel to handle the peak rate of the transmission. Although peak rate allocation allows constant quality or fixed distortion <ref> [39] </ref> transmission, the network is underutilized because the CBR channel is not wholly exploited whenever the variable bit-rate (VBR) signal runs below peak rate. The efficiency of peak rate allocation is greatly reduced by the inherent burstiness of video. Chin 16 packet video. <p> A large number of layered coding schemes have been proposed, including schemes based on progressive DCT [68, 142, 104], subband coding <ref> [39, 11, 158] </ref>, and pyramidal coding [139]. We reviewed some key areas in layered compression research and cited representative or landmark work in each area.
Reference: [40] <author> Stephen Deering, Deborah Estrin, Dino Farinacci, Van Jacobson, Ching-Gung Liu, and Liming Wei. </author> <title> An architecture for wide-area multicast routing. </title> <booktitle> In Proceedings of SIGCOMM '94, </booktitle> <address> University College London, London, U.K., </address> <month> September </month> <year> 1994. </year> <note> ACM. </note>
Reference-contexts: A number of multicast routing protocols compute spanning trees from an anchor point in the network (either the sending host or a rendezvous point or core) to all of the receivers, e.g., Protocol Independent Multicast (PIM) <ref> [40] </ref>, Distance Vector Multicast Routing Protocol (DVMRP) [174], or Core Based Trees (CBT) [7]. Because the anchor point (i.e., source address) uniquely identifies the spanning tree, multi-cast routers can use it to compute the forwarding decision for a given packet. <p> Ns is an event-driven packet-level simulator controlled and configured via Tcl [131]. Shortest-path routes are computed for the input topology and mul-ticast packets are routed via reverse-path forwarding. A flooding algorithm similar to Dense-mode Protocol Independent Multicast (PIM) <ref> [40] </ref> handles forwarding and pruning of multicast flows. Layered video sources are modeled as a set of constant-bit rate (CBR) streams with fixed packet sizes. <p> One way to improve this scaling behavior is to use a centralized rather than source-based approach to mul-ticast routing as in CBT [7] and Sparse-mode PIM <ref> [40] </ref>. Although this approach improves the state requirement to scale linearly with the number of groups, it precludes the efficiency of shortest path routes in a source-based tree. Furthermore, the scale of future networks will likely require sub-linear growth and no current approach offers this degree of performance.
Reference: [41] <author> Stephen E. Deering. </author> <title> Multicast Routing in a Datagram Internetwork. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> December </month> <year> 1991. </year> <month> 162 </month>
Reference-contexts: By 1990, the infrastructure, composed of UNIX workstations serving as programmable routers and interconnected via T1 links, was in place. Early in the project, the research community deployed a fledgling new technology, IP Multicast <ref> [41] </ref>, over DARTNet providing the first opportunity to study and experiment with wide-area network-layer multicast on a non-trivial scale. The IP Multicast architecture extends the traditional best-effort, unicast delivery model of the Internet Protocol architecture for efficient multipoint packet transmission. <p> Deering proposed this approach in the IP Multicast service model, which extends the traditional IP unicast delivery semantics for efficient multipoint transmission <ref> [41] </ref>. In IP Multicast, packets are forwarded along a distribution tree, rooted at the source of the data and extending to each receiver in the multicast group. A key feature of IP Multicast is the level of indirection provided by its host group abstraction. <p> For example, an individual subnet cannot simultaneously be in an LBL-scope and a UCB-scope unless the LBL-scope is contained entirely within the UCB-scope, or vice versa. Deering proposed an administrative scoping scheme that provides overlapped regions by associating the scope region with a multicast address rather than a TTL <ref> [41, x3.2] </ref>, and Jacobson and Deering presented specific mechanisms for incrementally realizing this scheme [89]. Here administrative scopes are imposed by configuring administrative boundaries at the borders between organizations.
Reference: [42] <author> Stephen E. Deering and Robert M. Hinden. </author> <title> Internet Protocol, </title> <institution> Verion 6 (IPv6). Internet Engineering Task Force, IPNG Working Group, </institution> <month> December </month> <year> 1995. </year> <month> RFC-1883. </month>
Reference-contexts: To summarize, we believe that drop priorities should not be incorporated into best-effort networks as has been preliminarily proposed in Version 6 of the Internet Protocol <ref> [42, x 7] </ref>.
Reference: [43] <author> Steve Deering. </author> <title> Internet multicast routing: </title> <booktitle> State of the art and open research issues, </booktitle> <month> October </month> <year> 1993. </year> <institution> Multimedia Integrated Conferencing for Europe (MICE) Seminar at the Swedish Institute of Computer Science, Stockholm. </institution>
Reference-contexts: A uniform transmission rate fails to accommodate the bandwidth heterogeneity of this diverse set of receivers. 1.3 A Solution: Layered Compression and Transmission An often cited approach for coping with receiver heterogeneity in real-time multimedia transmissions is the use of layered media streams <ref> [43, 44, 83, 122, 154, 162, 165, 173] </ref>. In this model, rather than distribute a single level of quality using a single network channel, the source distributes multiple levels of 8 quality simultaneously across multiple network channels. <p> While 11 solve the heterogeneity problem. The network forwards only the number of layers that each physical link can support. much of the previous work leaves this problem as an implementation detail, a novel and practical scheme was proposed by Deering <ref> [43] </ref> and was further described and/or independently cited in [24, 44, 83, 122, 165]. In this approach, the layers that comprise the hierarchical signal are striped across distinct multicast groups thereby allowing receivers to adjust their reception rate by controlling the number of groups they receive. <p> When combined with RLM, our Progressive Video with Hybrid-transform codec, or PVH, provides a comprehensive solution for scalable multicast video transmission in heterogeneous networks. 1.4 Contributions A number of research activities have laid the groundwork for both layered video compression [100, 124, 24, 162, 173] and layered transmission systems <ref> [101, 155, 43, 132, 165, 78] </ref>. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem. <p> The authors do not discuss adaptation algorithms or report implementation results. As described in Chapter 1, Deering first suggested that the IP Multicast be used as a layered transmission system where layers are individually mapped onto multicast groups <ref> [43] </ref>. Both Turletti and Bolot [165] and Chaddha and Gupta [25] describe this architecture but do not present an adaptation algorithm or implementation. Our approach was first described in [118] and [122], but a specific adaptation scheme was not published until [121].
Reference: [44] <author> Luca Delgrossi, Christian Halstrick, Dietmar Hehmann, Ralf Guido Herrtwich, Oliver Krone, Jochen Sandvoss, and Carsten Vogt. </author> <title> Media scaling for audiovisual communication with the Heidelberg transport system. </title> <booktitle> In Proceedings of ACM Multimedia '93, </booktitle> <pages> pages 99-104. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1993. </year>
Reference-contexts: A uniform transmission rate fails to accommodate the bandwidth heterogeneity of this diverse set of receivers. 1.3 A Solution: Layered Compression and Transmission An often cited approach for coping with receiver heterogeneity in real-time multimedia transmissions is the use of layered media streams <ref> [43, 44, 83, 122, 154, 162, 165, 173] </ref>. In this model, rather than distribute a single level of quality using a single network channel, the source distributes multiple levels of 8 quality simultaneously across multiple network channels. <p> The network forwards only the number of layers that each physical link can support. much of the previous work leaves this problem as an implementation detail, a novel and practical scheme was proposed by Deering [43] and was further described and/or independently cited in <ref> [24, 44, 83, 122, 165] </ref>. In this approach, the layers that comprise the hierarchical signal are striped across distinct multicast groups thereby allowing receivers to adjust their reception rate by controlling the number of groups they receive. <p> For many applications, source rates cannot be known a priori. Finally, the framework assumes the existence of an end-to-end infrastructure for resource-controlled multicast connections, which is not (and may not ever be) universally deployed. The Discrete Scaling mechanism in the Heidelberg Transport System (HeiTS) <ref> [44] </ref> uses a receiver-oriented scheme for adapting to delivered bandwidth. Here, receivers open and close ST-II [22] multicast 24 connections to adapt to bandwidth. The authors do not discuss adaptation algorithms or report implementation results. <p> Unfortunately, since 25 the source continually transmits packets during the G 2 excursion, the path to R becomes severely congested for a sustained period of time. The DSG architecture represents a hybrid of the source-based and receiver-based congestion control methods. Delgrossi et al. describe a similar hybrid using HeiTS <ref> [44] </ref> where they suggest that their continuous (i.e., source-based) and discrete (i.e., receiver-based) scaling methods could in principle be combined in a single approach, but they did not develop or implement this idea. 2.1.9 Summary of Packet Video Work In the previous sections, we summarized related work in a number of <p> Several researchers have additionally suggested using the I, P, B frame structure of MPEG to induce a temporal hierarchy <ref> [155, 2, 44] </ref>. 2.2.2 Pyramid Coding A landmark work in multiresolution image coding is Burt and Adelson's pyramid coding framework [19]. The basic structure is illustrated in Figure 2.5. The input image is first downsampled and low-pass 28 structure.
Reference: [45] <author> A. Demers, S. Keshav, and S. Shenker. </author> <title> Analysis and simulation of a fair queueing algorithm. </title> <journal> Inter-networking: Research and Experience, </journal> <volume> 1 </volume> <pages> 3-26, </pages> <year> 1990. </year>
Reference-contexts: Similar circumstance surrounds the design of TCP. TCP congestion control works well in isolation but in aggregation can be unfair [55]. As an optimization, network mechanisms can be introduced to make TCP perform better: RED gateways or Fair Queuing (FQ) <ref> [45] </ref> routers minimize the interaction between connections to improve aggregate system performance.
Reference: [46] <author> Tim Dorcey. </author> <title> CU-SeeMe desktop videoconferencing software. </title> <journal> ConneXions, </journal> <volume> 9(3), </volume> <month> March </month> <year> 1995. </year>
Reference-contexts: Their application, called CU-SeeMe, uses a simple, low-quality grayscale video coding scheme combined with a unicast-based transmission scheme over the reflector network described earlier <ref> [46] </ref>. The compression scheme downsamples the input video to 160x120 4-bit grayscale image and on each new frame conditionally replenishes every 4x4 image block that changes sufficiently.
Reference: [47] <author> Tim Dorcey and Richard Cogger. </author> <month> CU-SeeMe. </month> <institution> Cornell University. </institution> <note> Software on-line 1 </note> . 
Reference-contexts: While this architecture supports heterogeneous transmission, it does not provide a mechanism for end-systems to adapt dynamically to the available capacity in the network. Instead, MMC relies on admission control to explicitly allocate available bandwidth to heterogeneous receivers. The CU-SeeMe system <ref> [47] </ref> from Cornell University distributes video over a manually configured multicast distribution mechanism. So called reflectors are manually placed throughout the network to effect a multicast distribution tree using native unicast transmission. Receivers generate loss reports that are sent back up the distribution tree via the reflectors.
Reference: [48] <author> Ernest A. Edmonds, Linda Candy, Rachel Jones, and Bassel Soufi. </author> <title> Support for collaborative design: Agents and emergece. </title> <journal> Communications of the ACM, </journal> <volume> 37(7) </volume> <pages> 41-47, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: The notion of an agent-based architecture is not a new idea. At least one approach to collaborative design from the Artificial Intelligence community resembles our Composable Tools framework <ref> [48] </ref>. Ed-monds et al. decompose their application functionality into a number of agents user agents, groups floor agents, conference agents, presentation agents, and so forth that interact over a software communication bus.
Reference: [49] <author> Alexandros Eleftheriadis, Sassan Pejhan, and Dimitris Anastassiou. </author> <title> Algorithms and performance evaluation of the Xphone multimedia communication system. </title> <booktitle> In Proceedings of ACM Multimedia '93, </booktitle> <pages> pages 311-320. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1993. </year>
Reference-contexts: A controller uses this information to adjust the output rate of an MPEG [108] coder, allowing the source to react to queue buildup before packet loss occurs. A very different approach is taken in the Xphone system <ref> [49] </ref>, which leverages off the congestion avoidance algorithms built into TCP/IP [137]. Xphone transmits JPEG [85] video over a TCP connection and measures the throughput of the transmission.
Reference: [50] <author> William H. R. Equitz and Thomas M. </author> <title> Cover. Successive refinement of information. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 37(2) </volume> <pages> 269-275, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: For example, the performance of a vector quantizer of size N approaches D I (R) as N increases [67]. A layered coder D L (R) generally performs worse than the vector quantizer because layering imposes an additional constraint <ref> [50] </ref>. On the other hand, the advantage of the layered representation is that both the encoder and decoder can travel along the distortion rate curve.
Reference: [51] <author> Kevin Fall, Joseph Pasquale, and Steven McCanne. </author> <title> Workstation video playback performance with competitive process load. </title> <booktitle> In Proceedings of the Fifth International Workshop on Network and OS Support for Digital Audio and Video, </booktitle> <pages> pages 179-182, </pages> <address> Durham, NH, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: Consequently, in addition to packet loss in the network, messages can be lost in the end-system when the decoder cannot keep up with a high-rate incoming bit stream. In this case, the decoder should gracefully adapt by trading off reconstruction quality to shed work <ref> [34, 51] </ref>. However, such adaptation is difficult under the temporal prediction model because the decoder must fully decode all differential updates to maintain a consistent prediction state. In contrast, with conditional replenishment, compute-scalability is both feasible and simple. <p> In this case, packets are dropped by the operating system due to input buffer overflows and quality degrades dramatically. To address this problem, we can exploit RLM to gracefully adapt the application to the available CPU resources by shedding load <ref> [51, 34] </ref>. On the one hand, RLM provides a convenient mechanism for adapting not only to network loss but also to local computational resources because its reaction of dropping layers reduces the local processing burden. Hence, we can carry out both load adaptation and network congestion adaptation exclusively with RLM.
Reference: [52] <author> W. Fenner. </author> <title> Internet Group Management Protocol, </title> <type> Version 2. </type> <institution> Internet Engineering Task Force, Inter-Domain Multicast Routing Working Group, </institution> <month> February </month> <year> 1996. </year> <title> Internet Draft (work in progress). </title>
Reference-contexts: In this group-oriented communication framework, senders need not know explicitly about receivers and receivers need not know about senders. Instead, a sender simply transmits packets to an IP group address and receivers tell the network (via the Internet Group Management Protocol or IGMP <ref> [52] </ref>) that they are interested in receiving packets sent to that group. Moreover, the process by which receivers join and leave multicast groups is timely and efficient (on the order of a few milliseconds).
Reference: [53] <author> Domenico Ferrari and Dinesh Verma. </author> <title> A scheme for real-time communication services in wide-area networks. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 8(3) </volume> <pages> 368-379, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: In winter 1993, we started work on the UCB/LBL video conferencing application, vic, which became a core research vehicle for the work contained herein. We originally conceived vic as an application to demonstrate the Tenet real-time networking protocols <ref> [53] </ref> and to simultaneously support the evolving Lightweight Sessions architecture [88] that implicitly underlies all of the tools discussed. Work on vic 4 has since driven the evolution of the Real-time Transport Protocol (RTP) [153]. <p> A comprehensive survey of all of this work is beyond the scope of this chapter and we instead describe just a few of the approaches. A landmark work in real-time service guarantees is the Tenet Real-time Protocol Suite <ref> [53, 8] </ref>. The 19 Tenet project focused on providing provable performance guarantees from the network to the client. In the Tenet model, a client describes its traffic parameters and its service requirements to the network.
Reference: [54] <author> Sally Floyd. </author> <title> Notes on CBQ and guaranteed service. </title> <note> Unpublished note available in ftp://ftp.ee.lbl.gov/papers/guaranteed.ps, </note> <month> July </month> <year> 1995. </year>
Reference-contexts: Hence, the size of the resource management state within the network scales with the number of traffic classes rather than the number of active flows. CBQ provides a flexible building block for implementing link sharing policies and has been shown to be capable of providing high-level service guarantees <ref> [54] </ref>. The ReSerVation Protocol (RSVP) working group within the Internet Engineering Task Force (IETF) is developing a protocol for establishing Internet-based integrated services reservations [179]. While RSVP defines the core setup protocol, the actual service models and infrastructure are being developed by the Integrated Services working group.
Reference: [55] <author> Sally Floyd and Van Jacobson. </author> <title> On traffic phase effects in packet-switched gateways. Internetworking: </title> <journal> Research and Experience, </journal> <volume> 3(3) </volume> <pages> 115-156, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Because packets are dropped deterministically from the end of the queue, end-system protocols can interact adversely with the network and suboptimal traffic patterns can emerge. For example, Floyd and Jacobson found that TCP connections can suffer pathological phase synchronization effects that bias the throughput of some connections over others <ref> [55] </ref>. They and others have proposed that the impact of these adverse effects can be reduced by replacing the drop-tail policy with random-drop, where the dropped packet is chosen at random from the queue [115]. <p> But, if machinery for fairness is added to the network, our protocol could work effectively in concert with it. Similar circumstance surrounds the design of TCP. TCP congestion control works well in isolation but in aggregation can be unfair <ref> [55] </ref>. As an optimization, network mechanisms can be introduced to make TCP perform better: RED gateways or Fair Queuing (FQ) [45] routers minimize the interaction between connections to improve aggregate system performance. <p> An exploration of the protocol's sensitivity to these parameters as well as the development of analytic models that shed light on parameter tuning are both areas of future work. 3 Drop-tail queues have been shown to contribute to protocol synchronization effects that can confound end-to-end performance <ref> [55] </ref>. In our simulations, drop-tail routers do not pose such problems because we optimistically inject randomness into the source model.
Reference: [56] <author> Sally Floyd and Van Jacobson. </author> <title> Random early detection gateways for congestion avoidance. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 1(4) </volume> <pages> 397-413, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: to all traffic (within the class) and enhanced services should optionally be provided through separate service interfaces, e.g., via RSVP. 3.6.3 Random Early Detection Although random-drop gives advantages over the drop-tail packet discard policy, we can improve performance further with a variant of random-drop called Random Early Detection or RED <ref> [56] </ref>. Under both drop-tail and random-drop, routers drop packets only after their queue is full. This widely deployed drop-tail discard policy is unfortunate because it delays the congestion warning signal from the receivers until well after congestion has occurred. <p> RED gateways, on the other hand, react to incipient congestion by discarding packets at the onset of congestion (i.e., when the average queue size exceeds a threshold) <ref> [56] </ref>. <p> We have not yet implemented nor simulated the performance of this proposed mechanism. An important component of a RED gateway is the algorithm that decides when a flow is non-responsive and therefore should be penalized by preferentially discarding its traffic <ref> [56] </ref>. This penalty box classification scheme could potentially subsume the RLM tentative-graft reaction. Alternatively, the two algorithms could share a common implementation but be individually tailored through configuration parameters. 8.2.2 PVH In this section, we outline a number of areas for future work related to PVH: * Codec Performance.
Reference: [57] <author> Sally Floyd and Van Jacobson. </author> <title> The synchronization of periodic routing messages. </title> <booktitle> In Proceedings of SIGCOMM '93, </booktitle> <pages> pages 33-44, </pages> <address> San Francisco, CA, </address> <month> September </month> <year> 1993. </year> <journal> ACM. </journal> <volume> 1 ftp://gated.cornell.edu/pub/video 163 </volume>
Reference-contexts: Each state transition is labeled with the reason for the transition, either packet loss or a timeout. Actions associated with a transition are indicated in parentheses. Join-timers (T J ) are randomized to avoid protocol synchronization effects <ref> [57] </ref>, while detection timers (T D ) are set to a weighted value of the detection-time estimator.
Reference: [58] <author> Sally Floyd and Van Jacobson. </author> <title> Link-sharing and resource management models for packet networks. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 3(4) </volume> <pages> 365-386, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: This approach has the advantage that hard connection state need not be maintained throughout the network, but has the disadvantage that no absolute guarantees are provided. Floyd and Jacobson proposed a mechanism rather than a service interface for network resource management called Class Based Queuing (CBQ) <ref> [58] </ref>. CBQ contrasts with traditional approaches to resource management that rely on fine-grained connection bookkeeping to provide guarantees. In CBQ, traffic is aggregated into classes and resource management state is maintained on a per-class basis. <p> Although RLM adaptation is not strictly necessary when the network provides resource guarantees, RLM might still be useful within this environment when resource management is coarse-grained. For example, Class Based Queuing (CBQ) <ref> [58] </ref> could be used to provide an adaptive-rate video traffic class with some specified bandwidth. Then within this CBQ class, independent video sessions would contend for the aggregate class bandwidth using RLM.
Reference: [59] <author> Sally Floyd, Van Jacobson, Steven McCanne, Ching-Gung Liu, and Lixia Zhang. </author> <title> A reliable multicast framework for light-weight sessions and application level framing. </title> <booktitle> In Proceedings of SIGCOMM '95, </booktitle> <pages> pages 342-356, </pages> <address> Boston, MA, </address> <month> September </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: The underlying protocol framework, later termed Scalable Reliable Multicast (SRM), was further refined, analyzed, and simulated by Floyd et al. <ref> [59] </ref>. In December 1992, Frederick released the Xerox PARC Network Video tool, nv, a video-only 1 Lacking creativity for program names, we chose the name vat because it was a small change from vt, reflecting the incremental evolution of the application. <p> Rather than design protocols composed of modular black boxes, we must synthesize new, application-specific protocols (e.g., FLIIT [37], RLM, RTP [153], and SRM <ref> [59] </ref>) that account for the interaction between application and network. 52 In this chapter, we establish ALF and JSCC as a core design principle for our layered video architecture. To this end, we present our earlier work on the non-layered Intra-H.261 format that forged our approach to ALF/JSCC-based design. <p> After several design iterations over transport protocols for several different audio/video compression formats, it became clear that a one size fits all protocol was inadequate <ref> [59, 120] </ref>. Instead, a framework based on ALF emerged where a thin base protocol defines the core mechanisms and profile extensions define application-specific semantics. <p> A media source simply transmits data packets to the multicast group address. Audio and video data is transported via RTP while wb data is disseminated using a preliminary prototype of the Scalable Reliable Multicast (SRM) framework <ref> [59] </ref>. In [74], Handley and Crowcroft outline this overall architecture and relate the components to present and planned Internet standards. Because of its ALF-like model, RTP is a natural match to our Composable Tools framework and serves as the foundation for the tools' network architecture. <p> The combination of CBQ and RLM can be used to isolate the interactions of end-to-end congestion control and thereby avoid unforeseen modes of controller instability. The RLM framework could be combined with the Scalable Reliable Multicast (SRM) protocol framework <ref> [59] </ref> in the LBNL whiteboard wb to optimize the latency of rate-controlled transmissions. Because SRM uses a token-bucket rate-controller, it has the same limitations that single-layer video has in heterogeneous environments.
Reference: [60] <author> Armando Fox, Steven D. Gribble, and Eric A. Brewer Elan Amir. </author> <title> Adapting to network and client variability via on-demand dynamic distillation. </title> <booktitle> In Proceedings of ASPLOS '96, </booktitle> <address> Cambridge, MA, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: Likewise, both the PVH image and video formats have the potential to enhance the effectiveness and performance of Web proxies <ref> [60] </ref> and Web caches [16]. Rather than perform potentially heavy computation to transcode image formats on the fly, a bandwidth-adaptive proxy could selectively forward image or video layers to tailor the transfer to network path.
Reference: [61] <author> Ron Frederick. </author> <title> Network Video (nv). </title> <institution> Xerox Palo Alto Research Center. </institution> <note> Software on-line 2 </note> . 
Reference-contexts: Within LWS and on top of the IP service interface we must define specific transport protocols and data formats to facilitate communication, and we must further determine a method for mapping these data formats onto multicast transmission channels. Through our work on the MBone tools and other similar efforts <ref> [164, 61, 149, 150] </ref>, the following communication model emerged. A session is comprised of a number of media and each media type is allocated to two transport channels one for data and one for control each using the same multicast group. <p> network to improve the end-to-end performance of packet video. 55 4.4 Integrated Design with ALF/JSCC: The Real-time Transport Protocol About the same time that Clark and Tennenhouse proposed ALF, we and others developed a number of tools to explore the problem of interactive audio and video transport across packet-switched networks <ref> [90, 149, 61, 117, 164, 150] </ref>. After several design iterations over transport protocols for several different audio/video compression formats, it became clear that a one size fits all protocol was inadequate [59, 120].
Reference: [62] <author> Ron Frederick. </author> <title> Experiences with real-time software video compression. </title> <booktitle> In Proceedings of the Sixth International Workshop on Packet Video, </booktitle> <address> Portland, OR, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: backward compatibility and for some time, conferences were held using a mixture of vt and vat. 3 IP source-routing was used originally as the mechanism for tunneling through non-multicast capable networks. 5 application that utilizes a custom coding scheme tailored specifically for the Internet and targeted for efficient software implementation <ref> [62] </ref>. Nv quickly became the de facto standard for MBone video. About the same time, Jacobson created the Session Directory tool, sd [86]. A user creates and advertises a conference or session with sd. <p> In this section, we survey related work on applications, systems, and architectures for video transmission over the Internet. 2.3.1 Xerox PARC Network Video One of the earliest widely-used applications for Internet video transmission is the Network Video tool nv from Xerox PARC <ref> [62] </ref>. An important prototype in the development of the early RTP draft standards, 36 nv is based on open-loop transmission of real-time video to an arbitrary number of receivers using IP Multi-cast. <p> A particularly novel aspect of nv is its custom coding scheme based on a Haar wavelet decomposition. The compression algorithm is tailored specifically for the Internet and targeted for efficient software implementation <ref> [62] </ref>. Moreover, the compression and packetization schemes were designed jointly and as a result, nv video streams exhibited much better end-to-end performance compared to other techniques that at the time were based on existing coding models. <p> The high-level compression model utilized by nv is decomposed as follows <ref> [62] </ref>: Here, 8x8 image blocks from the conditional replenishment stage are transformed using a Haar wavelet decomposition. A threshold is then applied to each coefficient and coefficients with magnitude below the threshold are set to zero. This process creates runs of zeros, which are run-length coded in the last stage. <p> We now describe the detailed algorithmic steps of conditional replenishment: block selection, block aging, and temporal layering. Our scheme is derived in part from the conditional replenishment algorithm used by the Xerox PARC Network Video tool, nv <ref> [62] </ref>. 6.2.1 Block Selection To decide whether or not to encode and transmit a block, the conditional replenishment algorithm computes a distance between the reference block and the current block. As is standard practice with common motion-compensation algorithms, we run conditional replenishment exclusively off the luminance component of the video.
Reference: [63] <author> Mark W. Garrett and Martin Vetterli. </author> <title> Congestion control strategies for packet video. </title> <booktitle> In Proceedings of the Fourth International Workshop on Packet Video, </booktitle> <pages> pages 1-6, </pages> <address> Kyoto, Japan, </address> <month> March </month> <year> 1991. </year>
Reference-contexts: Karlsson and Vetterli [100, 101] later described the integration of packet video into a general network architecture. They were the first to suggest the use of layered source-coding for video combined with prioritized packet-discard to carry out loss recovery. In <ref> [63, 64] </ref>, Garrett and Vetterli demonstrated the benefits of using network feedback to control the coding process. They were the first to describe their approach as a form of joint source and channel coding (JSCC), borrowing this terminology from traditional communication theory. <p> Joint source/channel coding states that one can often achieve better system performance by combining the design of compression and error-control coding rather than treating these sub-problems independently. Garrett and Vetterli <ref> [63, 64] </ref> first applied this terminology to packet networks by viewing the packet transport mechanism as the channel-coding algorithm. In his thesis, Garrett argues that real-time traffic is better served by jointly designing the compression algorithm with the transmission system [66].
Reference: [64] <author> Mark W. Garrett and Martin Vetterli. </author> <title> Joint source/channel coding of statistically multiplexed real-time services on packet networks. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 1(1) </volume> <pages> 71-80, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: Karlsson and Vetterli [100, 101] later described the integration of packet video into a general network architecture. They were the first to suggest the use of layered source-coding for video combined with prioritized packet-discard to carry out loss recovery. In <ref> [63, 64] </ref>, Garrett and Vetterli demonstrated the benefits of using network feedback to control the coding process. They were the first to describe their approach as a form of joint source and channel coding (JSCC), borrowing this terminology from traditional communication theory. <p> Joint source/channel coding states that one can often achieve better system performance by combining the design of compression and error-control coding rather than treating these sub-problems independently. Garrett and Vetterli <ref> [63, 64] </ref> first applied this terminology to packet networks by viewing the packet transport mechanism as the channel-coding algorithm. In his thesis, Garrett argues that real-time traffic is better served by jointly designing the compression algorithm with the transmission system [66].
Reference: [65] <author> Mark W. Garrett and Walter Willinger. </author> <title> Analysis, modeling and generation of self-similar VBR video traffic. </title> <booktitle> In Proceedings of SIGCOMM '94, </booktitle> <address> University College London, London, U.K., </address> <month> September </month> <year> 1994. </year> <note> ACM. </note>
Reference-contexts: Chin 16 packet video. The smoothing buffer is eliminated and replaced by the network. Congestion feedback from the network, rather than the smoothing-buffer occupancy, controls the codec output rate. et al. [28] characterized the burstiness of compressed video signals, and later, Garrett and Willenger <ref> [65] </ref> showed that typical video sources exhibit long-range dependence, where rate behavior is bursty even on large time scales. <p> Unfortunately, this simple model fails to capture the burstiness of real video streams <ref> [65] </ref>. Because convergence in RLM relies on matching the layered rates to available capacity, smooth sources are well-behaved and this traffic model is overly optimistic. On the other hand, a bursty source can be smoothed out by applying rate-control through adaptive quantization at the cost of variable quality. <p> But over time, the entropy of the underlying signal might vary dramatically (i.e., the signal becomes harder or easier to compress) causing the bit-rate of each output layer to change over time. Garrett and Willenger <ref> [65] </ref> have shown that typical video sources exhibit long range dependence, where rate behavior is bursty even on large time scales. However, our RLM simulations were carried out with video sources that assume a constant bit-rate output on each layer.
Reference: [66] <author> Mark William Garrett. </author> <title> Contributions Toward Real-Time Services on Packet Switched Networks. </title> <type> PhD thesis, </type> <institution> Columbia University, </institution> <year> 1993. </year>
Reference-contexts: Garrett and Vetterli [63, 64] first applied this terminology to packet networks by viewing the packet transport mechanism as the channel-coding algorithm. In his thesis, Garrett argues that real-time traffic is better served by jointly designing the compression algorithm with the transmission system <ref> [66] </ref>. We believe that the emergence of JSCC and ALF signals a shift in the core nature of network research the traditional, highly layered protocol architecture must be abandoned.
Reference: [67] <author> Allen Gersho and Robert M. Gray. </author> <title> Vector Quantization and Signal Compression. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year>
Reference-contexts: A real coder D R (R) can perform close to the ideal curve but never better. For example, the performance of a vector quantizer of size N approaches D I (R) as N increases <ref> [67] </ref>. A layered coder D L (R) generally performs worse than the vector quantizer because layering imposes an additional constraint [50]. On the other hand, the advantage of the layered representation is that both the encoder and decoder can travel along the distortion rate curve. <p> The Laplacian pyramid was a break-through innovation that led to a number of image and video coding schemes. One example is Chaddha et al.'s scheme [26, 24] based on a Laplacian pyramid and tree-structured vector quantization <ref> [67] </ref> of the refinement bands. Both the vector codebook construction algorithm and vector searches during the encoding process are computationally expensive, but the decoder algorithm can be carried out efficiently almost exclusively with table lookups.
Reference: [68] <author> M. Ghanbari. </author> <title> Two-layer coding of video signals for VBR networks. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 7(5) </volume> <pages> 771-781, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: While this approach optimizes the delivery of high-priority traffic in the face of congestion, the output rate of the coder is not in the feedback loop and therefore this approach by itself is not well-suited for best effort networks. A joint source/channel coding approach is similarly taken by Ghanbari <ref> [68] </ref>. He designed a two-layer architecture, where a base layer is transmitted with guaranteed performance while an enhancement layer is transmitted on a lossy channel. His scheme is targeted for a specific slotted network which provides real-time guarantees. <p> A large number of layered coding schemes have been proposed, including schemes based on progressive DCT <ref> [68, 142, 104] </ref>, subband coding [39, 11, 158], and pyramidal coding [139]. We reviewed some key areas in layered compression research and cited representative or landmark work in each area. <p> Since JPEG does not carry out conditional replenishment in the compression algorithm itself, we apply conditional replenishment at the receiver to prune unnecessary computation. A similar thresholding algorithm is described in <ref> [68] </ref>, though it is used for a different purpose (i.e., motion detection at the encoder). 7.5 Rendering Another performance-critical operation is converting video from the YUV pixel representation used by most compression schemes to a format suitable for the output device.
Reference: [69] <author> H. Gharavi. </author> <title> Subband coding of video signals. </title> <editor> In J. W. Woods, editor, </editor> <title> Subband Image Coding. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: Despite many attempts, the ability of temporal subband coding algorithms to exploit motion is consistently inferior to the traditional block-based motion-compensation techniques that MPEG and H.261 35 utilize. Consequently, some researchers have proposed coding systems based on motion compensation where the motion prediction error is coded through subband decomposition <ref> [69] </ref>. Unfortunately, all of these schemes entail high implementation complexity and fail to outperform traditional schemes based on motion vectors and the DCT. WWHVQ.
Reference: [70] <author> M. Gilge and R. Gusella. </author> <title> Motion video coding for packet-switching networksan integrated approach. </title> <booktitle> In Proceedings of the SPIE Conference on Visual Communications and Image Processing, </booktitle> <address> Boston, MA, </address> <month> November </month> <year> 1991. </year> <note> ACM. </note>
Reference-contexts: This reactive approach to congestion control for packet video has been proposed and analyzed by a number of researchers. We outline some of these approaches in the following section. 17 2.1.3 Congestion Control for Packet Video Gilge and Gusella <ref> [70] </ref> proposed an early congestion control scheme for video transmission over best effort packet-switched networks. Their end-to-end design uses explicit feedback from the receiver to throttle the video transmission rate at the source.
Reference: [71] <author> Amit Gupta, Wendy Heffner, Mark Moran, and Clemens Szyperski. </author> <title> Network support for realtime multi-party applications. </title> <booktitle> In Proceedings of the Fourth International Workshop on Network and OS Support for Digital Audio and Video, </booktitle> <address> Lancaster, U.K., </address> <month> November </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: The RSVP architecture was designed to explicitly accommodate layered flows using resource reservations [179]. Similarly, Heffner proposed the use of layered media streams in tandem with resource reservations [80] in the context of the Tenet Scheme 2 protocol suite <ref> [71] </ref>. Concurrent with our work, Hoffman and Speer built a system based on the layered multicast architecture [83]. They use multiple frame rates of JPEG video to generate a temporal hierarchy and employ two techniques for adaptation.
Reference: [72] <author> A. </author> <title> Haar. Zur Theorie der orthogonalen Funktionensysteme. </title> <journal> Math. Annal., </journal> <volume> 69 </volume> <pages> 331-371, </pages> <year> 1910. </year> <note> 2 ftp://ftp.parc.xerox.com/net-research 164 </note>
Reference-contexts: When iterated, the Haar filters perform signal expansion onto a square wave basis <ref> [72] </ref>. Because of this, quantization noise typically shows up as obvious blocking artifacts. Moreover, the Haar filter has poor energy compaction because of its gradual stopband transition.
Reference: [73] <author> Mark Handley. </author> <title> Session DiRectory. </title> <institution> University College London. </institution> <note> Software on-line 3 </note> . 
Reference-contexts: This work was refined by Handley and Jacobson into the Session Description Protocol (SDP) [75] and Handley developed a much improved SDP-based session directory tool call sdr <ref> [73] </ref> first released in late 1995. In winter 1993, we started work on the UCB/LBL video conferencing application, vic, which became a core research vehicle for the work contained herein. <p> In the current design, all of this functionality resides in a session advertisement tool like sdr <ref> [73] </ref>. As described in Chapter 3, sdr implements the Session Description Protocol to automatically advertise sessions and related mappings for individual media to multicast addresses. In addition, sdr consolidates these mappings, presents their corresponding high-level session name to the user, and allows the user to invoke the session.
Reference: [74] <author> Mark Handley and Jon Crowcroft. </author> <title> Internet multimedia conferencing architecture. </title> <journal> ConneXions, </journal> <volume> 10(6) </volume> <pages> 2-13, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: A media source simply transmits data packets to the multicast group address. Audio and video data is transported via RTP while wb data is disseminated using a preliminary prototype of the Scalable Reliable Multicast (SRM) framework [59]. In <ref> [74] </ref>, Handley and Crowcroft outline this overall architecture and relate the components to present and planned Internet standards. Because of its ALF-like model, RTP is a natural match to our Composable Tools framework and serves as the foundation for the tools' network architecture.
Reference: [75] <author> Mark Handley and Van Jacobson. SDP: </author> <title> Session description protocol, </title> <month> November </month> <year> 1995. </year> <title> Internet Draft (work in progress). </title>
Reference-contexts: In turn, each participant uses sd to automatically launch all the media tools pertaining to that session, freeing the user from burdensome configuration of multicast addresses, ports, and scopes. This work was refined by Handley and Jacobson into the Session Description Protocol (SDP) <ref> [75] </ref> and Handley developed a much improved SDP-based session directory tool call sdr [73] first released in late 1995. In winter 1993, we started work on the UCB/LBL video conferencing application, vic, which became a core research vehicle for the work contained herein. <p> Here each participant must merely learn the addresses that correspond to the session using a simple Announce/Listen protocol [148] running on a well-known multicast group. The Session Description Protocol (SDP) <ref> [75] </ref> is a proposed standard that defines the message formats and protocol for advertising the multicast address bindings. In LWS, group management is not explicit. <p> An image is defined by a collection of packets from potentially different layers. Each packet is prefixed by a standard RTP header as described in [153]. The RTP payload type is not pre-assigned and is instead dynamically assigned by an external mechanism (e.g., using the Session Description Protocol (SDP) <ref> [75] </ref>). All packets that belong to an identical image have the same RTP timestamp but are in no particular order. Moreover, the semantics of the RTP timestamp field are the same across each layer and are derived from the same time base.
Reference: [76] <author> Mark Handley and Ian Wakeman. CCCP: </author> <title> Conference control channel protocol, a scalable base for building conference control applications. </title> <booktitle> In Proceedings of SIGCOMM '95, </booktitle> <address> Boston, MA, </address> <month> September </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: Ed-monds et al. decompose their application functionality into a number of agents user agents, groups floor agents, conference agents, presentation agents, and so forth that interact over a software communication bus. In the context of the MBone tools, Handley and Wakeman independently developed the Conference Control Channel Protocol <ref> [76] </ref>, which shares design goals and has architectural similarities with our approach. Likewise, Schulzrinne developed a coordination scheme that ties together the MBone tools using Pattern Matching Multicast, a framework like our Coordination Bus with pattern-matching filters [151].
Reference: [77] <author> Mark J. Handley. </author> <title> Using the UCL H.261 codec controller, </title> <month> December </month> <year> 1993. </year> <note> On-line html document 4 </note> . 
Reference-contexts: Because it utilizes a standardized algorithm, ivs interoperates with a large installed base of H.320 video codecs as an H.320-compliant bit stream is easily generated from an H.261 packet stream by introducing H.221 framing in software <ref> [77] </ref>. Also in contrast to nv, ivs makes no assumptions about the availability of network resources and adapts to available capacity through the source-based congestion control algorithm described earlier in this chapter.
Reference: [78] <author> Paul Haskell and David Messerschmitt. </author> <title> Open network architecture for continuous-media services: The medley gateway. </title> <type> Technical report, </type> <institution> University of California, Berkeley, </institution> <address> CA, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: When combined with RLM, our Progressive Video with Hybrid-transform codec, or PVH, provides a comprehensive solution for scalable multicast video transmission in heterogeneous networks. 1.4 Contributions A number of research activities have laid the groundwork for both layered video compression [100, 124, 24, 162, 173] and layered transmission systems <ref> [101, 155, 43, 132, 165, 78] </ref>. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem.
Reference: [79] <author> Paul Heckbert. </author> <title> Color image quantization for frame buffer display. </title> <booktitle> In Proceedings of SIGGRAPH '82, </booktitle> <pages> page 297, </pages> <year> 1982. </year>
Reference-contexts: Vic computes this color map using a static optimization explicitly invoked by the user. When the user clicks a button, a histogram of colors computed across all active display windows is fed into Heckbert's median cut algorithm <ref> [79] </ref>. The resulting color map is then downloaded into the rendering module. Since median cut is a compute-intensive operation that can take several seconds, it runs asynchronously in a separate process. We have found that this approach is qualitatively well matched to LCD color displays found on laptop PCs.
Reference: [80] <author> Wendy Heffner. </author> <title> Scaling issues in the design and implementation of the Tenet RCAP2 signaling protocol. </title> <type> Technical Report TR-95-022, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> CA, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: Receivers drop down to the 160x120 resolution when they detect high packet loss rates. The RSVP architecture was designed to explicitly accommodate layered flows using resource reservations [179]. Similarly, Heffner proposed the use of layered media streams in tandem with resource reservations <ref> [80] </ref> in the context of the Tenet Scheme 2 protocol suite [71]. Concurrent with our work, Hoffman and Speer built a system based on the layered multicast architecture [83]. They use multiple frame rates of JPEG video to generate a temporal hierarchy and employ two techniques for adaptation.
Reference: [81] <author> Andrew T. Heybey. </author> <title> Video coding and the application level framing protocol architecture. </title> <type> Technical Report MITE/LCS/TR-542, </type> <institution> Massachusetts Institute of Technology, </institution> <address> Cambridge, MA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Heybey's thesis explores the integration of video coding algorithms into the ALF framework by adopting existing compression standards (e.g., JPEG, H.261, and MPEG) without modification <ref> [81] </ref>. In contrast, we elaborate ALF with the premise that we should not only optimize the network protocol for the application, but we should also optimize the application for the network. Heybey's approach treats the compression algorithm as an immutable black box.
Reference: [82] <author> Don Hoffman, Gerard Fernando, and Vivek Goyal. </author> <title> RTP Payload Format for MPEG1/MPEG2 Video. </title> <institution> Internet Engineering Task Force, Audio-Video Transport Working Group, </institution> <month> June </month> <year> 1995. </year> <title> Internet Draft (work in progress). </title>
Reference-contexts: The interpretation of fields may be further refined by the Payload Format Specification. For example, an audio payload might define the RTP timestamp as a audio sample counter while the MPEG/RTP specification <ref> [82] </ref> defines it as the Presentation Time Stamp from the MPEG system specification. By structuring the protocol architecture in this way, RTP facilitates the ALF/JSCC design approach.
Reference: [83] <author> Don Hoffman and Michael Speer. </author> <title> Hierarchical video distribution over Internet-style networks. </title> <booktitle> In Proceedings of the IEEE International Conference on Image Processing, </booktitle> <pages> pages 5-8, </pages> <address> Lausanne, Switzer-land, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: A uniform transmission rate fails to accommodate the bandwidth heterogeneity of this diverse set of receivers. 1.3 A Solution: Layered Compression and Transmission An often cited approach for coping with receiver heterogeneity in real-time multimedia transmissions is the use of layered media streams <ref> [43, 44, 83, 122, 154, 162, 165, 173] </ref>. In this model, rather than distribute a single level of quality using a single network channel, the source distributes multiple levels of 8 quality simultaneously across multiple network channels. <p> The network forwards only the number of layers that each physical link can support. much of the previous work leaves this problem as an implementation detail, a novel and practical scheme was proposed by Deering [43] and was further described and/or independently cited in <ref> [24, 44, 83, 122, 165] </ref>. In this approach, the layers that comprise the hierarchical signal are striped across distinct multicast groups thereby allowing receivers to adjust their reception rate by controlling the number of groups they receive. <p> Similarly, Heffner proposed the use of layered media streams in tandem with resource reservations [80] in the context of the Tenet Scheme 2 protocol suite [71]. Concurrent with our work, Hoffman and Speer built a system based on the layered multicast architecture <ref> [83] </ref>. They use multiple frame rates of JPEG video to generate a temporal hierarchy and employ two techniques for adaptation. Their first technique is a negotiation algorithm run by each receiver that obtains the highest available quality of service explicitly from the network (e.g., using RSVP). <p> In an integrated services network, a receiver could explicitly negotiate with the network to determine the appropriate number of layers <ref> [83] </ref> with or without consideration of a pricing structure. Although RLM adaptation is not strictly necessary when the network provides resource guarantees, RLM might still be useful within this environment when resource management is coarse-grained. <p> PVH can also be used in tandem with the Resource ReserVation Protocol (RSVP) [179], which supports the notion of layered reservations. In this approach, receivers negotiate explicitly with the network for bandwidth by adjusting their reservation to the maximum number of layers that the network can deliver <ref> [83] </ref>.
Reference: [84] <author> D. A. Huffman. </author> <title> A method for the construction of minimum-redundancy codes. </title> <journal> Proceedings of IRE, </journal> <volume> 40(9) </volume> <pages> 1098-1101, </pages> <year> 1952. </year>
Reference-contexts: These coefficients are then quantized with a uniform scalar quantizer. Finally, runs of zeros are run-length coded and the run-codes and quantization levels are combined into Huffman codes <ref> [84] </ref>. This is the basic algorithm used by JPEG. A color image is represented by three bit-planes (a luminance plane and two color planes) and broken up into a number of 8x8 blocks.
Reference: [85] <institution> ISO DIS 10918-1 Digital compression and coding of continuous-tone still images (JPEG). CCITT Recommendation T.81. </institution>
Reference-contexts: A very different approach is taken in the Xphone system [49], which leverages off the congestion avoidance algorithms built into TCP/IP [137]. Xphone transmits JPEG <ref> [85] </ref> video over a TCP connection and measures the throughput of the transmission. <p> DCT Image and video compression algorithms based on the Discrete Cosine Transform (DCT) have been enormously successful and are now used in a number of international image and video coding standards, 26 e.g., the Motion Picture Experts Group (MPEG) [108] video compression standard and the Joint Photographic Experts Group (JPEG) <ref> [85, 135] </ref> image compression standard. The DCT-based algorithms are instances of a generic transform coder, which is decomposed as follows: In this model, a transform, T , is applied to the input image to decorrelate the pixel values. <p> These three schemes all appear in the JPEG standard. While spectral separation and spatial scaling are rarely used, the successive quantization algorithm has been widely used because the Independent JPEG Group has publicly distributed a robust implementation. They utilized the point-transform technique in the JPEG standard <ref> [85, Annex G] </ref> to produce a layered JPEG codec, which is now referred to as Progressive-JPEG. Even though Progressive-JPEG is constrained to produce a layered representation, it often outperforms the non-layered baseline JPEG algorithm. <p> To retain an embedded bit stream, we encode the transform coefficients progressively by coding the DCT coefficients a bit-plane at a time. Our technique is similar to the point transform used in progressive-mode JPEG <ref> [85, Annex G] </ref> and the SNR-scalability profile in MPEG-2. We code the DCT coefficients in a number of passes. <p> Hence, we removed temporal coding overheads (like macroblock addressing codes) from each codec. Because we compare only grayscale PSNR performance, we additionally removed chrominance syntax overhead. In addition to the Internet video codecs, we compared our results against Shapiro's EZW algorithm [157] and progressive-mode JPEG <ref> [85, Annex G] </ref> to gauge the performance of our scheme against well-established subband- and DCT-based image codecs. For each algorithm, we obtained a distortion-rate characteristic for the 512x512 Lena gray scale test image as follows: * Intra-H.261. <p> For the DCT, we refine each coefficient by jointly coding the entire bit-plane of the next significant bit position of the AC coefficient magnitudes in a fashion analogous to progressive-mode JPEG <ref> [85, Annex G] </ref>. A refinement bit-plane is coded by first refining each previously transmitted coefficient magnitude by one bit and then identifying coefficient positions that become significant on this pass using a series of run-lengths over the zig-zag scan order.
Reference: [86] <author> Van Jacobson. </author> <title> Session Directory. </title> <institution> Lawrence Berkeley Laboratory. </institution> <note> Software on-line 5 </note> . 
Reference-contexts: Nv quickly became the de facto standard for MBone video. About the same time, Jacobson created the Session Directory tool, sd <ref> [86] </ref>. A user creates and advertises a conference or session with sd. In turn, each participant uses sd to automatically launch all the media tools pertaining to that session, freeing the user from burdensome configuration of multicast addresses, ports, and scopes.
Reference: [87] <author> Van Jacobson. </author> <title> Congestion avoidance and control. </title> <booktitle> In Proceedings of SIGCOMM '88, </booktitle> <address> Stanford, CA, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: Under this scheme, a receiver searches for the optimal level of subscription much as a TCP source searches for the bottleneck transmission rate with the slow-start congestion avoidance algorithm <ref> [87] </ref>. The receiver adds layers until congestion occurs and backs off to an operating point below this bottleneck rate. three layers of video to receivers R 1 , R 2 , and R 3 .
Reference: [88] <author> Van Jacobson. </author> <title> SIGCOMM '94 Tutorial: Multimedia conferencing on the Internet, </title> <month> August </month> <year> 1994. </year> <note> 3 ftp://cs.ucl.ac.uk/mice/sdr/ 4 http://www.cs.ucl.ac.uk/mice/codec manual/doc.html 5 ftp://ftp.ee.lbl.gov/conferencing/sd 165 </note>
Reference-contexts: Additionally, in joint work with Jacobson [90], we enhanced vt's algorithms for counteracting network packet jitter through receiver buffering and playback point estimation <ref> [88] </ref>. Our new application 4 became the LBL Visual Audio Tool, vat 1 , and the DARTNet community gradually began using our new tool upon its release in the fall of 1991 2 . <p> In winter 1993, we started work on the UCB/LBL video conferencing application, vic, which became a core research vehicle for the work contained herein. We originally conceived vic as an application to demonstrate the Tenet real-time networking protocols [53] and to simultaneously support the evolving Lightweight Sessions architecture <ref> [88] </ref> that implicitly underlies all of the tools discussed. Work on vic 4 has since driven the evolution of the Real-time Transport Protocol (RTP) [153]. As RTP evolved, we tracked and implemented protocol changes, and fed back implementation experience to the design process. <p> This playback point algorithm can be extended to carry out cross-media synchronization by aligning each individual media with the media that has the maximal playback point <ref> [88] </ref>. Since RTP is independent of the underlying network technology, it simultaneously supports multiple network protocols. Figure 3.2 illustrates how RTP fits into several protocol stacks. For IP and IP Mul-ticast, RTP is layered over UDP, while in the Tenet protocols, it runs over RMTP/RTIP [8]. <p> Synchronization Cross-media synchronization can also be carried out over the Coordination Bus. Each real-time application induces a buffering delay, called the playback point, to adapt to packet delay variations <ref> [88] </ref>. We can broaden the semantics of the playback point to effect synchronization across media. By broadcasting synchronize messages across the Coordination Bus, the different media can compute the maximum of all advertised playout delays. This maximum is then used in the delay-adaptation algorithm.
Reference: [89] <author> Van Jacobson and Steve Deering. </author> <title> Administratively scoped IP multicast. </title> <booktitle> In Proceedings of the 30th Internet Engineering Task Force, </booktitle> <address> Toronto, Canada, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: Deering proposed an administrative scoping scheme that provides overlapped regions by associating the scope region with a multicast address rather than a TTL [41, x3.2], and Jacobson and Deering presented specific mechanisms for incrementally realizing this scheme <ref> [89] </ref>. Here administrative scopes are imposed by configuring administrative boundaries at the borders between organizations. A special block of multicast addresses is reserved for administrative scope and since administratively scoped traffic does not flow across boundaries, scoped addresses need not be unique across organizational boundaries.
Reference: [90] <author> Van Jacobson and Steven McCanne. </author> <title> Visual Audio Tool. </title> <institution> Lawrence Berkeley Laboratory. </institution> <note> Software on-line 6 </note> . 
Reference-contexts: Consequently, vt's text-based interface was cumbersome and provided limited user control and feedback. To improve upon vt, we elaborated ISI's work with a graphical user interface that displays all of the participants in the audio conference and highlights the active speaker. Additionally, in joint work with Jacobson <ref> [90] </ref>, we enhanced vt's algorithms for counteracting network packet jitter through receiver buffering and playback point estimation [88]. <p> network to improve the end-to-end performance of packet video. 55 4.4 Integrated Design with ALF/JSCC: The Real-time Transport Protocol About the same time that Clark and Tennenhouse proposed ALF, we and others developed a number of tools to explore the problem of interactive audio and video transport across packet-switched networks <ref> [90, 149, 61, 117, 164, 150] </ref>. After several design iterations over transport protocols for several different audio/video compression formats, it became clear that a one size fits all protocol was inadequate [59, 120].
Reference: [91] <author> Van Jacobson, Steven McCanne, and Sally Floyd. </author> <title> A privacy architecture for lightweight sessions, </title> <month> September </month> <year> 1994. </year> <title> ARPA Network PI Meeting presentation 7 </title> . 
Reference-contexts: In LWS, group management is not explicit. Unlike many traditional conference management schemes, there is no protocol for controlling access to the group or for maintaining a consistent group view at each receiver. Privacy is achieved not through access control, but instead through end-to-end encryption <ref> [91] </ref>. Similarly, conference control mechanisms are effected through the receiver orchestration techniques discussed in Chapter 7. <p> By default, we use the Data Encryption Standard (DES) in cipher block chaining mode [6]. While weaker forms of encryption could be used (e.g., those based on linear feedback shift registers), efficient implementations of the DES give good performance on current hardware (measurements are given in <ref> [91] </ref>). The computational requirements of compression/decompression far outweigh the cost of encryption/decryption. One attractive feature of layered streams is that we can accommodate heterogeneity even with encryption because we can simply encrypt each layer of a hierarchical flow independently.
Reference: [92] <author> Jeffrey M. Jaffe. </author> <title> Bottleneck flow control. </title> <journal> IEEE Transactions on Communications, </journal> <volume> 29(7) </volume> <pages> 954-962, </pages> <month> July </month> <year> 1981. </year>
Reference-contexts: Unfortunately, we can say little about the stable operating point that our protocol by itself would obtain. In general it is not possible to achieve a fair allocation of bandwidth without some additional machinery in the network, even if all the end-nodes cooperate <ref> [92] </ref>. But, if machinery for fairness is added to the network, our protocol could work effectively in concert with it. Similar circumstance surrounds the design of TCP. TCP congestion control works well in isolation but in aggregation can be unfair [55]. <p> As described in x3.6.4, it is not generally possible to achieve a fair allocation of bandwidth without some additional machinery in the network, even if all the end-nodes cooperate <ref> [92] </ref>. Even if the bandwidth allocation were fair, the aggregate system performance, as measured by the sum of distortions at each receiver, would not be optimal.
Reference: [93] <author> Anil K. Jain. </author> <title> Fundamentals of Digital Image Processing. </title> <publisher> Prentice-Hall International, Inc., </publisher> <year> 1989. </year>
Reference-contexts: Since the Haar transform requires only additions and subtractions and the threshold step requires only two conditionals, the algorithm has very low computational complexity. Unfortunately, compression performance suffers because the Haar transform provides relatively poor energy compaction of the signal <ref> [93] </ref> and the entropy coder is based exclusively on fixed size run-length codes. The performance of the nv coder can be substantially improved with the following changes: (i) Replace the Haar transform with the Discrete Cosine Transform (DCT), which has good energy com paction for images [93]. (ii) Replace the coefficient <p> compaction of the signal <ref> [93] </ref> and the entropy coder is based exclusively on fixed size run-length codes. The performance of the nv coder can be substantially improved with the following changes: (i) Replace the Haar transform with the Discrete Cosine Transform (DCT), which has good energy com paction for images [93]. (ii) Replace the coefficient threshold stage with a uniform quantizer to reduce the entropy of quantized coefficients. (iii) Follow the run-length coder with a Huffman coder to further compress the symbol stream. The modified encoder structure then becomes: Intra-H.261. <p> A background fill process spontaneously promotes a small number of idle blocks to the background state (bg). The block is replenished in the shaded states. techniques <ref> [93] </ref>. However, larger blocks cause coarse grained image updates, which consequently results in redundant transmission, limiting the potential improvement of an arbitrarily large block. 6.2.2 Robust Refresh The threshold in the block selection algorithm provides hysteresis by suppressing block updates when there is little change.
Reference: [94] <author> Raj Jain. </author> <title> The Art of Computer Systems Performance Analysis. </title> <publisher> John Wiley and Sons, Inc., </publisher> <year> 1991. </year>
Reference-contexts: Hence, we instead rely on a technique that identifies clusters of packet loss, i.e., congestion periods, simply by monitoring the incoming packet process at an individual receiver. The performance evaluation literature contains many techniques for automatically identifying clusters in data sets <ref> [94] </ref>, but we adopt the following very simple heuristic based on perceptual factors and the time scales on which RLM operates. We define a loss event to be the time interval that starts at a packet arrival just before a dropped packet and ends when a subsequent packet arrives.
Reference: [95] <author> Sugih Jamin. </author> <title> A Measurement-based Admission Control Algorithm for Integrated Services Packet Networks. </title> <type> PhD thesis, </type> <institution> University of Southern California, </institution> <month> August </month> <year> 1996. </year>
Reference-contexts: Jamin proposed a somewhat similar mechanism called preemptible service <ref> [95, Ch. 11] </ref>. In this framework, layered transmission is combined with a measurement-based admission control system.
Reference: [96] <author> Sugih Jamin, Peter B. Danzig, Scott Shenker, and Lixia Zhang. </author> <title> A measurement-based admission control algorithm for integrated services packet networks. </title> <booktitle> In Proceedings of SIGCOMM '95, </booktitle> <address> Boston, MA, </address> <month> September </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: In Predictive Service [30], present and past performance is used to predict future performance and hence the network can base admission control decisions on measurements rather than a priori traffic signatures <ref> [96] </ref>. This approach has the advantage that hard connection state need not be maintained throughout the network, but has the disadvantage that no absolute guarantees are provided. Floyd and Jacobson proposed a mechanism rather than a service interface for network resource management called Class Based Queuing (CBQ) [58].
Reference: [97] <author> K. Jeffay, D. L. Stone, T. Talley, and F. D. Smith. </author> <title> Adaptive, best-effort delivery of digital audio and video across packet-switched networks. </title> <booktitle> In Proceedings of the Third International Workshop on Network and OS Support for Digital Audio and Video, </booktitle> <address> San Diego, CA, </address> <month> November </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: In effect, the application measures the bandwidth that TCP obtains from the network and uses the measurement to adjust its source-coding rate. The measurement is input into an empirical model of an operational rate-distortion curve to update the JPEG quantizer. Jeffay et. al. <ref> [97] </ref> view the audio/video transport process as a distributed pipeline. They designed an unreliable connection-oriented transport protocol on top of UDP/IP called the Multimedia Transport Protocol (MTP). MTP detects congestion by monitoring the local packet transmission queue.
Reference: [98] <author> Hemant Kanakia, Partho P. Mishra, and Amy Reibman. </author> <title> An adaptive congestion control scheme for real-time packet video transport. </title> <booktitle> In Proceedings of SIGCOMM '93, </booktitle> <pages> pages 20-31, </pages> <address> San Francisco, CA, </address> <month> September </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: As illustrated in Figure 2.2, they adapted the traditional CBR coding model to packet networks by viewing the network as the smoothing buffer. The buffer occupancy feedback is replaced by loss feedback from the network. Kanakia et al. <ref> [98] </ref> build on Gilge and Gusella's model with an architecture where the feedback signal is derived directly from the network. The bottleneck switch or router along the transmission path communicates its queuing delay back to the source.
Reference: [99] <author> Gunnar Karlsson. </author> <title> Asynchronous transfer of video. </title> <journal> IEEE Communications Magazine, </journal> <volume> 34(8), </volume> <month> August </month> <year> 1996. </year>
Reference-contexts: A cooperative, primarily industrial-based consortium called the ATM Forum has developed service definitions, traffic models, and protocols for providing quality of service guarantees in ATM networks. In <ref> [99] </ref>, Karlsson surveys the integration of digital video and ATM networks. In contrast to the focus on provable guarantees taken in Tenet and ATM, some researchers believe that softer guarantees can be used to simplify the network design but still provide good performance.
Reference: [100] <author> Gunnar Karlsson and Martin Vetterli. </author> <title> Three-deimensional subband coding of video. </title> <booktitle> In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 1100-1103, </pages> <address> New York, NY, </address> <month> April </month> <year> 1988. </year>
Reference-contexts: When combined with RLM, our Progressive Video with Hybrid-transform codec, or PVH, provides a comprehensive solution for scalable multicast video transmission in heterogeneous networks. 1.4 Contributions A number of research activities have laid the groundwork for both layered video compression <ref> [100, 124, 24, 162, 173] </ref> and layered transmission systems [101, 155, 43, 132, 165, 78]. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem. <p> One early work on packet audio proposed that short-term congestion be accommodated through the combination of layered compression at the source with prioritized packet dropping in the network [5]. Karlsson and Vetterli <ref> [100, 101] </ref> later described the integration of packet video into a general network architecture. They were the first to suggest the use of layered source-coding for video combined with prioritized packet-discard to carry out loss recovery.
Reference: [101] <author> Gunnar Karlsson and Martin Vetterli. </author> <title> Packet video and its integration into the network architecture. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 7(5) </volume> <pages> 739-751, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: When combined with RLM, our Progressive Video with Hybrid-transform codec, or PVH, provides a comprehensive solution for scalable multicast video transmission in heterogeneous networks. 1.4 Contributions A number of research activities have laid the groundwork for both layered video compression [100, 124, 24, 162, 173] and layered transmission systems <ref> [101, 155, 43, 132, 165, 78] </ref>. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem. <p> One early work on packet audio proposed that short-term congestion be accommodated through the combination of layered compression at the source with prioritized packet dropping in the network [5]. Karlsson and Vetterli <ref> [100, 101] </ref> later described the integration of packet video into a general network architecture. They were the first to suggest the use of layered source-coding for video combined with prioritized packet-discard to carry out loss recovery. <p> But this results in poor compression performance because the scheme does not exploit the tremendous frame-to-frame or temporal redundancies in typical video sequences. Spatio-temporal Wavelet Pyramid. Karlsson and Vetterli were the first to extend subband coding techniques to video by introducing spatio-temporal wavelet pyramid <ref> [101] </ref>. In this model, subband decomposition is carried out not only spatially across each frame but also temporally from frame to frame. The simplest example of a temporal subband filter is the Haar wavelet. In this case, two frames are coded at a time.
Reference: [102] <author> Leonid Kasperovich. </author> <title> Multiplication free scaled 8x8 DCT algorithm with 530 additions. </title> <booktitle> In Proc. SPIE, </booktitle> <volume> volume 2419, </volume> <pages> pages 105-110. </pages> <publisher> ACM, </publisher> <year> 1995. </year>
Reference-contexts: Here we can exploit numerical approximations to trade off reconstruction quality for run-time performance. For example, the inverse DCT could be replaced by an approximate algorithm that runs faster at the expense of decreased accuracy <ref> [102] </ref>. Likewise, the degree of quantization applied to the DCT coefficients can be dynamically manipulated to meet a computation budget [110]. * Self-correlated Updates. The update heuristic that transmits only blocks that change works well in practice because block updates are self-correlated.
Reference: [103] <author> Christopher A. Kent and Jeffrey Mogul. </author> <title> Fragmentation considered harmful. </title> <booktitle> In Proceedings of SIG-COMM '87. ACM, </booktitle> <month> August </month> <year> 1987. </year>
Reference-contexts: If the source uses packets that are too large, then the Internet Protocol network layer will fragment the datagrams into smaller packets and confound our one-to-one mapping of ADU onto packet. For unicast transmission, a source can use Path MTU Discovery <ref> [103, 126] </ref> to learn the maximum transmission unit allowed along a certain unicast path through the network. (Note that this is another example of joint source channel coding where we are using network properties to control the source-coder.) But for multicast transmission, we have no such path discovery mechanism and rely
Reference: [104] <author> F. Kishino, K. Manabe, Y.Hayahi, and H. Yasuda. </author> <title> Variable bit-rate coding of video signals for ATM networks. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 7(5) </volume> <pages> 801-806, </pages> <month> June </month> <year> 1989. </year> <note> 6 ftp://ftp.ee.lbl.gov/conferencing/vat 7 ftp://ftp.ee.lbl.gov/talks/lws-privacy.ps.Z 166 </note>
Reference-contexts: A large number of layered coding schemes have been proposed, including schemes based on progressive DCT <ref> [68, 142, 104] </ref>, subband coding [39, 11, 158], and pyramidal coding [139]. We reviewed some key areas in layered compression research and cited representative or landmark work in each area.
Reference: [105] <author> Isidor Kouvelas, Vicky Hardman, and Anna Watson. </author> <title> Lip synchronisation for use over the Internet: Analysis and implementation. </title> <booktitle> In Proceedings of GLOBECOM '96, </booktitle> <address> London, UK, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: Kouvelas et al. implemented a lip synchronization technique based on this architecture using a modified version of vic and their audio tool rat <ref> [105] </ref>. 123 of events signaled over the Coordination Bus causes (1) the audio device to be transferred to the active session, (2) the video to switch to the active speaker, and (3) the user-interface to highlight the corresponding participant.
Reference: [106] <author> Murat Kunt and Ottar Johnsen. </author> <title> Block coding of graphics: A tutorial review. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 68(7) </volume> <pages> 770-786, </pages> <month> July </month> <year> 1980. </year>
Reference-contexts: Otherwise, output 1. If this is the most significant bit of the magnitude of this position, output the sign. Divide bit-plane into four equally sized bit-planes, and recursively code these subplanes. This decomposition is similar to the Autoadaptive Block Coding algorithm of Kunt and Johsen <ref> [106] </ref> though they applied it to bi-level images without any transformation. The hcompress algorithm described in [176] similarly exploits this technique in combination with subband decomposition over the entire image. In practice, our algorithm diverges somewhat from this conceptual framework in order to optimize the syntax for better run-time performance.
Reference: [107] <author> Didier Le Gall. </author> <title> Sub-band coding of images with low computational complexity. </title> <booktitle> In Proceedings of the Picture Coding Symposium, </booktitle> <address> Stockholm, Sweden, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: Much research has been carried out that explores tradeoffs in filter design for subband analysis, but most of this work does not address the issue of implementation complexity. One exception is LeGall's work on a low-complexity video coding system <ref> [107] </ref> that uses the following biorthogonal filter pair: H 0 (z) = 1 + 3z + 3z z H 1 (z) = 1 + 3z 1 3z 2 + z 3 31 A four-level analysis is carried out by first applying filtering and downsampling horizontally, resulting in two subbands each half
Reference: [108] <author> Didier Le Gall. </author> <title> MPEG: A video compression standard for multimedia applications. </title> <journal> Communications of the ACM, </journal> <volume> 34(4) </volume> <pages> 47-58, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: The bottleneck switch or router along the transmission path communicates its queuing delay back to the source. A controller uses this information to adjust the output rate of an MPEG <ref> [108] </ref> coder, allowing the source to react to queue buildup before packet loss occurs. A very different approach is taken in the Xphone system [49], which leverages off the congestion avoidance algorithms built into TCP/IP [137]. <p> the algorithms and techniques presented in the following sections. 2.2.1 Layered DCT Image and video compression algorithms based on the Discrete Cosine Transform (DCT) have been enormously successful and are now used in a number of international image and video coding standards, 26 e.g., the Motion Picture Experts Group (MPEG) <ref> [108] </ref> video compression standard and the Joint Photographic Experts Group (JPEG) [85, 135] image compression standard. The DCT-based algorithms are instances of a generic transform coder, which is decomposed as follows: In this model, a transform, T , is applied to the input image to decorrelate the pixel values.
Reference: [109] <author> D. J. LeGall, H. Gaggioni, and C. T. Chen. </author> <title> Transmission of HDTV signals under 140 Mbits/s using a subband decomposition and Discrete Cosine Transform coding. </title> <editor> In L. Chiariglione, editor, </editor> <booktitle> Signal Processing of HDTV, </booktitle> <pages> pages 287-293. </pages> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1988. </year>
Reference-contexts: Hence, a coding scheme tailored for normal images will work well on the coarse-scale LL subband <ref> [109] </ref>. Rather than carry out additional subband decomposition using the Haar transform on the LL subband, we instead apply an 8x8 DCT as depicted in Figure 6.6. To retain an embedded bit stream, we encode the transform coefficients progressively by coding the DCT coefficients a bit-plane at a time. <p> By decomposing the compression process into a number of passes that successively refine the transform coefficients, we can easily format the bit stream into a layered representation. Although DCT-based coding of the LL coarse scale band has been previously proposed <ref> [109] </ref>, as far as we know, the combination of progressive DCT transmission and multiresolution subband decomposition has not been explored. Simultaneously with the progressive coding of DCT coefficients, we encode the LH and HL sub-band coefficients using a simple quad-tree decomposition of bit-planes.
Reference: [110] <author> Krisda Lengwehasatit and Antonio Ortega. </author> <title> Distortion/decoding time trade-offs in software DCT-based image coding. </title> <booktitle> In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Munich, Germany, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: For example, the inverse DCT could be replaced by an approximate algorithm that runs faster at the expense of decreased accuracy [102]. Likewise, the degree of quantization applied to the DCT coefficients can be dynamically manipulated to meet a computation budget <ref> [110] </ref>. * Self-correlated Updates. The update heuristic that transmits only blocks that change works well in practice because block updates are self-correlated.
Reference: [111] <author> A. S. Lewis and G. Knowles. </author> <title> Image compression using the 2-D wavelet transform. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 1(2) </volume> <pages> 244-250, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Lewis and Knowles dramatically improved subband coding techniques by exploiting these inter-subband correlations in their image compression algorithm <ref> [111] </ref>. They arrange subband coefficients in the now well-known quadtree structure. For each coefficient (except those in the LL and the leaf subbands), we identify the four children coefficients whose basis vectors are centered at the spatial location of their parent.
Reference: [112] <author> Christopher J. Lindblad, David J. Wetherall, and David L. Tennenhouse. </author> <title> The VuSystem: A programming system for visual processing of digital video. </title> <booktitle> In Proceedings of ACM Multimedia '94, </booktitle> <pages> pages 307-314. </pages> <publisher> ACM, </publisher> <month> October </month> <year> 1994. </year>
Reference-contexts: The multimedia and computer-supported collaborative-work research communities have developed an array of toolkits and techniques for collaborative work. Examples include DAVE [125], SCOOT [36], 38 GroupKit [143], the Continuous Media Toolkit (CMT) [144], and VuSystem <ref> [112] </ref>. We briefly describe CMT and VuSystem since their approaches are most similar to ours. CMT is an object-oriented multimedia toolkit that allows objects to be mixed and matched into arbitrary applications. CMT objects are implemented in C and composed using the Tool Command Language Tcl [131]. <p> Smith's Cyclic-UDP described earlier is implemented as a CMT object and more recently the CMT development team has added objects that interface with RTP and the MBone [144]. The VuSystem is a similar multimedia toolkit built on top of an object-oriented Tcl extension <ref> [112] </ref>. C++ classes implement multimedia objects that produce, consume, or filter real-time media streams and a Tcl shadow object mirrors each C++ object. Methods invoked on the Tcl shadow object are dispatched to the C++ object. Like CMT, objects can be created, composed, and configured from Tcl.
Reference: [113] <author> Mark Linton, Parl R. Calder, and John M. Vlissides. InterViews: </author> <title> A C++ graphical interface toolkit. </title> <type> Technical Report CSL-TR-88-358, </type> <institution> Stanford University, </institution> <address> Palo Alto, CA, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: The heterogeneity inherent in underlying internet 4 The software architecture currently in vic and vat was developed essentially in the context of vic and retrofitted into vat. We originally based vat on the Interviews structured graphics library <ref> [113] </ref>, which at the time, was one of the best solutions for user-interface construction. Ousterhout's later development of the Tool Command Language (Tcl) and its graphics toolkit Tk provided the ingredients for the much improved Tcl/C++ object architecture described in Chapter 7.
Reference: [114] <author> Michael R. Macedonia and Donald P. Brutzman. </author> <title> MBone provides audio and video across the Internet. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 30-36, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Rather than send a copy of each packet to each user individually as is required by the conventional unicast packet delivery model in the Internet each packet was efficiently multicast to all receivers simultaneously using a multicast-capable portion of the Internet known as the Multicast Backbone or MBone <ref> [114] </ref>. Though bandwidth-efficient, this style of multipoint transmission where a packet stream is transmitted to all receivers at a uniform rate is undesirable because receivers are usually connected to the Internet at heterogeneous rates.
Reference: [115] <author> Allison Mankin. </author> <title> Random drop congestion control. </title> <booktitle> In Proceedings of SIGCOMM '90, </booktitle> <address> Philadelphia, PA, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: They and others have proposed that the impact of these adverse effects can be reduced by replacing the drop-tail policy with random-drop, where the dropped packet is chosen at random from the queue <ref> [115] </ref>. Under both drop-tail and random-drop, packets are dropped at a congested router in an uncontrolled fashion.
Reference: [116] <author> Burt Masnick and Jack Wolf. </author> <title> On linear unequal error protection codes. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-3(4), </volume> <month> October </month> <year> 1967. </year>
Reference-contexts: Although these types of error-control codes are simple to implement, they have high overhead compared to more sophisticated codes and are not widely used. Priority Encoding Transmission (PET) [2] utilizes forward error-correction coding but considers only the so called unequal error protection (UEP) codes <ref> [116] </ref>. In this scheme, the source signal is partitioned according to the relative importance of different subsets of the bit stream. For example, the PET authors prioritize MPEG by separating the intra-coded (I), predicted (P), and bi-directionally predicted (B) frames into three classes of decreasing importance.
Reference: [117] <author> Steven McCanne. </author> <title> A distributed whiteboard for network conferencing, </title> <month> May </month> <year> 1992. </year> <title> U.C. Berkeley CS268 Computer Networks term project and paper. </title>
Reference-contexts: Rather than place tight constraints on message delivery order, we explicitly accounted for the whiteboard's application semantics in the design of its network protocol, relaxed the ordering guarantees, and adopted a model of eventual consistency. We worked out the initial wb software architecture and implementation for a class project <ref> [117] </ref>, refined the protocol over the summer of 1992, and Jacobson improved the user interface and added functionality the subsequent fall. The underlying protocol framework, later termed Scalable Reliable Multicast (SRM), was further refined, analyzed, and simulated by Floyd et al. [59]. <p> network to improve the end-to-end performance of packet video. 55 4.4 Integrated Design with ALF/JSCC: The Real-time Transport Protocol About the same time that Clark and Tennenhouse proposed ALF, we and others developed a number of tools to explore the problem of interactive audio and video transport across packet-switched networks <ref> [90, 149, 61, 117, 164, 150] </ref>. After several design iterations over transport protocols for several different audio/video compression formats, it became clear that a one size fits all protocol was inadequate [59, 120].
Reference: [118] <author> Steven McCanne. </author> <title> Joint source/channel coding for multicast packet video. Dissertation Proposal, </title> <type> Qualifying Exam, </type> <institution> Electrical Engineering and Computer Science Dept., U.C. Berkeley, Berkeley, </institution> <address> CA, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Both Turletti and Bolot [165] and Chaddha and Gupta [25] describe this architecture but do not present an adaptation algorithm or implementation. Our approach was first described in <ref> [118] </ref> and [122], but a specific adaptation scheme was not published until [121]. Brown et al. have implemented a multi-resolution extension to the CU-SeeMe video conferencing system where IP Multicast receivers subscribe to either a 160x120 or a 320x240 stream by joining either one or two multicast groups [18]. <p> this simulated backbone topology. receiver-set sizes though its variability increases. 88 RLM conversation starts and converges first, then the final bandwidth apportionment is approximately fair; otherwise, it is grossly unfair. the results of this random placement simulation with those obtained by computing the optimal allocation of layers as described in <ref> [118] </ref>. 5.4.5 Interaction with TCP Because of the non-stationary and non-linear nature of RLM and other congestion control algorithms like TCP slow-start, formal analysis of their interaction is a hard, open problem and we thus cannot analytically predict their interdependent behavior.
Reference: [119] <author> Steven McCanne and Sally Floyd. </author> <title> The LBNL Network Simulator. </title> <institution> Lawrence Berkeley Laboratory. </institution> <note> Software on-line 8 . 8 http://www-nrg.ee.lbl.gov/ns/ 167 </note>
Reference-contexts: In a real network, performance will be affected by cross-traffic and competing groups, both of which add noise to the measurement process and introduce interactions that could potentially result in oscillatory behavior. We implemented the RLM protocol described above in the UCB/LBNL network simulator ns <ref> [119] </ref>. Not only did this implementation serve as a framework for evaluating the protocol's performance, but the simulator provided feedback that was critical to the design process. Ns is an event-driven packet-level simulator controlled and configured via Tcl [131].
Reference: [120] <author> Steven McCanne and Van Jacobson. </author> <title> vic: a flexible framework for packet video. </title> <booktitle> In Proceedings of ACM Multimedia '95, </booktitle> <pages> pages 511-522, </pages> <address> San Francisco, CA, </address> <month> November </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: Busse et al. [20] first implemented this approach (and worked out many unspecified details) by modifying vic <ref> [120] </ref> with a specific instance of an RTCP-based multicast feedback control algorithm. <p> After several design iterations over transport protocols for several different audio/video compression formats, it became clear that a one size fits all protocol was inadequate <ref> [59, 120] </ref>. Instead, a framework based on ALF emerged where a thin base protocol defines the core mechanisms and profile extensions define application-specific semantics. <p> In all of our simulations, the link bandwidths are 510 kb/s, the traffic sources are modeled as a six-layer CBR stream at rates 32 fi 2 m kb/s; m = 0 : : : 5, and the start-time of each receiver is randomly chosen uniformly on the interval <ref> [30; 120] </ref> seconds. The protocol constants from Table 5.1 have the following values: ff = 2, fi = 3=4, k 1 = 1, k 2 = 2, g 1 = 0:25, g 2 = 0:25, T min J = 60 sec. <p> Given that no current algorithm satisfied all of our design constraints, we designed a new layered compression scheme based on our experiences adapting H.261 for Internet transmission <ref> [120] </ref>. To meet our goal of low-complexity, the algorithm is relatively simple and admits an efficient software implementation. Moreover, the software-based approach provides an easy route for incrementally improving the algorithm as technology improves and as we better understand how to achieve robust compression in the presence of packet loss. <p> compression attempts to reduce the bit rate by exploiting statistical correlations from frame to frame in an image sequence, while spatial compression attempts to eliminate redundancies by exploiting statistical correlations within a given frame. 94 Our algorithm employs a very simple model for temporal compression known as block-based conditional replenishment <ref> [120, 127] </ref>, and uses a hybrid DCT/subband transform coding scheme for spatial compression. <p> Although this codec outperforms several existing Internet video coding schemes, its compression performance is somewhat inferior to the commonly used Intra-H.261 format <ref> [120] </ref>. To carry out ongoing, large-scale experiments within the MBone user community, we rely on active use of the applications, protocols, and compression formats. <p> We implemented PVH and these optimizations in our video conferencing application vic and compared its performance with the widely used Intra-H.261 codec <ref> [120] </ref>. As a simple quantitative assessment, we measured the run-time performance of both codecs within vic on an SGI Indy (200MHz MIPS R4400) 112 using the built-in VINO video device.
Reference: [121] <author> Steven McCanne, Van Jacobson, and Martin Vetterli. </author> <title> Receiver-driven layered multicast. </title> <booktitle> In Proceedings of SIGCOMM '96, </booktitle> <pages> pages 117-130, </pages> <address> Stanford, CA, </address> <month> August </month> <year> 1996. </year> <note> ACM. </note>
Reference-contexts: In this thesis, we fill this void with a specific protocol and adaptation algorithm called Receiver-driven Layered Multicast or RLM <ref> [121] </ref>. Additionally, we have designed and implemented a layered source coder based on a hybrid wavelet/DCT transform. <p> Both Turletti and Bolot [165] and Chaddha and Gupta [25] describe this architecture but do not present an adaptation algorithm or implementation. Our approach was first described in [118] and [122], but a specific adaptation scheme was not published until <ref> [121] </ref>. Brown et al. have implemented a multi-resolution extension to the CU-SeeMe video conferencing system where IP Multicast receivers subscribe to either a 160x120 or a 320x240 stream by joining either one or two multicast groups [18].
Reference: [122] <author> Steven McCanne and Martin Vetterli. </author> <title> Joint source/channel coding for multicast packet video. </title> <booktitle> In Proceedings of the IEEE International Conference on Image Processing, </booktitle> <pages> pages 25-28, </pages> <address> Washington, DC, </address> <month> October </month> <year> 1995. </year>
Reference-contexts: A uniform transmission rate fails to accommodate the bandwidth heterogeneity of this diverse set of receivers. 1.3 A Solution: Layered Compression and Transmission An often cited approach for coping with receiver heterogeneity in real-time multimedia transmissions is the use of layered media streams <ref> [43, 44, 83, 122, 154, 162, 165, 173] </ref>. In this model, rather than distribute a single level of quality using a single network channel, the source distributes multiple levels of 8 quality simultaneously across multiple network channels. <p> The network forwards only the number of layers that each physical link can support. much of the previous work leaves this problem as an implementation detail, a novel and practical scheme was proposed by Deering [43] and was further described and/or independently cited in <ref> [24, 44, 83, 122, 165] </ref>. In this approach, the layers that comprise the hierarchical signal are striped across distinct multicast groups thereby allowing receivers to adjust their reception rate by controlling the number of groups they receive. <p> Both Turletti and Bolot [165] and Chaddha and Gupta [25] describe this architecture but do not present an adaptation algorithm or implementation. Our approach was first described in [118] and <ref> [122] </ref>, but a specific adaptation scheme was not published until [121]. Brown et al. have implemented a multi-resolution extension to the CU-SeeMe video conferencing system where IP Multicast receivers subscribe to either a 160x120 or a 320x240 stream by joining either one or two multicast groups [18]. <p> In this section, we describe the layered spatial compression algorithm that is applied to each block. The first version of our coder <ref> [122] </ref> utilized subband decomposition since this approach induces an inherently layered representation. In this coder, we carry out subband decomposition over the entire image and then use pixel-domain conditional replenishment to determine the subband coefficients to transmit.
Reference: [123] <author> Steven McCanne, Martin Vetterli, and Van Jacobson. </author> <title> Low-complexity video coding for receiver-driven layered multicast. </title> <journal> Accepted for publication in IEEE Journal on Selected Areas in Communications, </journal> <year> 1997. </year>
Reference-contexts: Second, small local changes can dramatically impact the global optimization, precluding an incremental optimization structured in a distributed, scalable fashion. For example, if one receiver drops a layer, then the entire distribution topology might need to be re-routed (see <ref> [123, Appendix] </ref> for a proof that optimality requires a global exchange of information). We believe that theoretic optimality should be sacrificed in favor of local and scalable computation.
Reference: [124] <author> K. Metin Uz, Martin Vetterli, and Didier LeGall. </author> <title> Interpolative multiresolution coding of advanced television with compatible subchannels. IEEE Transactions on CAS for Video Technology, </title> <booktitle> Special Issue on Signal Processing for Advanced Television, </booktitle> <volume> 1(1) </volume> <pages> 86-99, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: When combined with RLM, our Progressive Video with Hybrid-transform codec, or PVH, provides a comprehensive solution for scalable multicast video transmission in heterogeneous networks. 1.4 Contributions A number of research activities have laid the groundwork for both layered video compression <ref> [100, 124, 24, 162, 173] </ref> and layered transmission systems [101, 155, 43, 132, 165, 78]. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem.
Reference: [125] <author> Robert F. Mines, Jerrold A. Friesen, and Christine L. Yang. DAVE: </author> <title> A plug and play model for distributed multimedia application development. </title> <booktitle> In Proceedings of ACM Multimedia '94, </booktitle> <pages> pages 59-66. </pages> <publisher> ACM, </publisher> <month> October </month> <year> 1994. </year>
Reference-contexts: To simplify the programming model, toolkits usually assume that communication is application-independent and offer a generic, least-common-denominator network interface built using traditional transport protocols. The multimedia and computer-supported collaborative-work research communities have developed an array of toolkits and techniques for collaborative work. Examples include DAVE <ref> [125] </ref>, SCOOT [36], 38 GroupKit [143], the Continuous Media Toolkit (CMT) [144], and VuSystem [112]. We briefly describe CMT and VuSystem since their approaches are most similar to ours. CMT is an object-oriented multimedia toolkit that allows objects to be mixed and matched into arbitrary applications. <p> Likewise, Schulzrinne developed a coordination scheme that ties together the MBone tools using Pattern Matching Multicast, a framework like our Coordination Bus with pattern-matching filters [151]. Our Composable Tools approach to networked multimedia contrasts with the more common toolkit framework adopted by other multimedia systems <ref> [36, 125, 143, 145] </ref>. Toolkits provide basic building blocks in the form of a code library with an application programming interface (API) to that library providing high-level abstractions for manipulating multimedia data flows.
Reference: [126] <author> Jeffrey Mogul and Steve Deering. </author> <title> Path MTU Discovery. ARPANET Working Group Requests for Comment, DDN Network Information Center, </title> <booktitle> SRI International, </booktitle> <address> Menlo Park, CA, </address> <month> November </month> <year> 1990. </year> <month> RFC-1191. </month>
Reference-contexts: If the source uses packets that are too large, then the Internet Protocol network layer will fragment the datagrams into smaller packets and confound our one-to-one mapping of ADU onto packet. For unicast transmission, a source can use Path MTU Discovery <ref> [103, 126] </ref> to learn the maximum transmission unit allowed along a certain unicast path through the network. (Note that this is another example of joint source channel coding where we are using network properties to control the source-coder.) But for multicast transmission, we have no such path discovery mechanism and rely
Reference: [127] <author> F. W. Mounts. </author> <title> A video encoding system with conditional picture-element replenishment. </title> <journal> Bell Systems Technical Journal, </journal> <volume> 48(7) </volume> <pages> 2545-2554, </pages> <month> September </month> <year> 1969. </year>
Reference-contexts: compression attempts to reduce the bit rate by exploiting statistical correlations from frame to frame in an image sequence, while spatial compression attempts to eliminate redundancies by exploiting statistical correlations within a given frame. 94 Our algorithm employs a very simple model for temporal compression known as block-based conditional replenishment <ref> [120, 127] </ref>, and uses a hybrid DCT/subband transform coding scheme for spatial compression.
Reference: [128] <author> Arun Netravali and Barry Haskell. </author> <title> Digital Pictures. </title> <publisher> Plenum Press, </publisher> <address> New York, NY, </address> <year> 1988. </year>
Reference-contexts: As a result, packet loss causes persistent corruption of the decoded image sequence. Alternatively, the use of leaky prediction lessens the impact of errors but incurs increased complexity and slower recovery <ref> [128, Ch. 5] </ref>. * Decoupled Decoder State. In the temporal prediction model, there is a tight coupling between the prediction state at the encoder and that at the decoder.
Reference: [129] <author> Antonio Ortega, Kannan Ramchandran, and Martin Vetterli. </author> <title> Optimal trellis-based buffered compression and fast approximations. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 3(1) </volume> <pages> 16-40, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Since the subprocess distortions are additive (by linearity of the DCT and subband transforms), we could use a dynamic program to find a good approximation of the optimal solution <ref> [129] </ref>. Unfortunately, computing an on-line, adaptive optimization algorithm like this adds complexity that inhibits real-time performance. An alternative approach is to pre-select a fixed set of quantizers by hand and hope that they are never far from optimal.
Reference: [130] <author> John K. Ousterhout. </author> <title> An X11 toolkit based on the Tcl language. </title> <booktitle> In Proceedings of the 1991 Winter USENIX Technical Conference, </booktitle> <address> Dallas, TX, </address> <month> January </month> <year> 1991. </year> <booktitle> USENIX. </booktitle>
Reference-contexts: Similarly, we use modular, configurable 120 applications, each specialized to implement a particular media, which can be easily composed via a Coordination Bus to support the variety of conferencing styles necessary for effective human communication. This approach derives from the framework proposed by Ousterhout in <ref> [130] </ref>, where he claims that large systems are easily composed from small tools that are glued together with a simple communication primitive (e.g., the Tk send command). We have simply replaced his send primitive with a well-defined (and more restrictive) Coordination Bus protocol.
Reference: [131] <author> John K. Ousterhout. </author> <title> Tcl and the Tk Toolkit. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: We briefly describe CMT and VuSystem since their approaches are most similar to ours. CMT is an object-oriented multimedia toolkit that allows objects to be mixed and matched into arbitrary applications. CMT objects are implemented in C and composed using the Tool Command Language Tcl <ref> [131] </ref>. Smith's Cyclic-UDP described earlier is implemented as a CMT object and more recently the CMT development team has added objects that interface with RTP and the MBone [144]. The VuSystem is a similar multimedia toolkit built on top of an object-oriented Tcl extension [112]. <p> Not only did this implementation serve as a framework for evaluating the protocol's performance, but the simulator provided feedback that was critical to the design process. Ns is an event-driven packet-level simulator controlled and configured via Tcl <ref> [131] </ref>. Shortest-path routes are computed for the input topology and mul-ticast packets are routed via reverse-path forwarding. A flooding algorithm similar to Dense-mode Protocol Independent Multicast (PIM) [40] handles forwarding and pruning of multicast flows. <p> Since each tool deals directly with its media stream and sends only low-rate reports like user X is actively transmitting on the Coordination Bus, the agent necessary to implement a particular conferencing scenario can be written in a simple interpreted language like Tcl <ref> [131] </ref>. This allows the most volatile part of the conferencing problem, the piece that melds audio, video, and other media into a coordinated unit that meets particular human needs and expectations, to be simple and easy to evolve. <p> In this way, the compressed bit stream can be made more robust to packet loss. At the macroscopic level, the software architecture is built upon an event-driven model with highly optimized data paths glued together and controlled by a flexible Tcl/Tk <ref> [131] </ref> framework. A number of basic objects are implemented in C++ and are coordinated via Tcl/Tk. Portions of the C++ object hierarchy mirror a set of object-oriented Tcl commands. <p> The PVH codec and framing protocol are implemented as a modular C++ object in the Tcl/Tk-based <ref> [131] </ref> multimedia toolkit described in Chapter 7. Likewise, a common RLM implementation is shared across our network simulator ns as well vic. Even with RLM fully integrated into vic, the current framework is still experimental.
Reference: [132] <author> Joseph C. Pasquale, George C. Polyzos, Eric W. Anderson, and Vachspathi P. Kompella. </author> <title> Filter propagation in dissemenation trees: Trading off bandwidth and processing in continuous media networks. </title> <booktitle> In Proceedings of the Fourth International Workshop on Network and OS Support for Digital Audio and Video, </booktitle> <pages> pages 269-278, </pages> <address> Lancaster, U.K., </address> <month> November </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: When combined with RLM, our Progressive Video with Hybrid-transform codec, or PVH, provides a comprehensive solution for scalable multicast video transmission in heterogeneous networks. 1.4 Contributions A number of research activities have laid the groundwork for both layered video compression [100, 124, 24, 162, 173] and layered transmission systems <ref> [101, 155, 43, 132, 165, 78] </ref>. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem. <p> In this way, heterogeneity is locally accommodated by fine-tuning the transmission rate to exactly match the available capacity on each link in the network. In <ref> [132, 133] </ref>, Pasquale et al. cite the shortcomings of closed-loop congestion control for multi-cast networks. Their Multimedia Multicast Channel (MMC) is designed specifically for heterogeneity by imposing only a loose coupling between the receivers and sources. In their architecture, receivers connect to a multicast channel through a port. <p> In the presence of congestion, the receiver reduces the resource request in the reservation. ATM switch managers coalesce reservation messages and send them up the distribution tree toward the source in a fashion reminiscent of Pasquale's filter propagation <ref> [132] </ref>. The network informs the source of the new requirements, which in turn may cause the source to alter its transmission rates. If so, an adapt message is broadcast to the receivers to update their knowledge of available resources.
Reference: [133] <author> Joseph C. Pasquale, George C. Polyzos, Eric W. Anderson, and Vachspathi P. Kompella. </author> <title> The multimedia multicast channel. Internetworking: </title> <journal> Research and Experience, </journal> <volume> 5(4) </volume> <pages> 151-162, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: In this way, heterogeneity is locally accommodated by fine-tuning the transmission rate to exactly match the available capacity on each link in the network. In <ref> [132, 133] </ref>, Pasquale et al. cite the shortcomings of closed-loop congestion control for multi-cast networks. Their Multimedia Multicast Channel (MMC) is designed specifically for heterogeneity by imposing only a loose coupling between the receivers and sources. In their architecture, receivers connect to a multicast channel through a port.
Reference: [134] <author> Ketan Patel, Brian C. Smith, and Lawrence A. Rowe. </author> <title> Performance of a software MPEG video decoder. </title> <booktitle> In Proceedings of ACM Multimedia '93, </booktitle> <pages> pages 75-82. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1993. </year> <month> 168 </month>
Reference-contexts: However, the codewords whose lengths are greater than M collide with other codewords in the table. In this case, the table entry contains an ESCAPE code that instructs the decoder to use a slower but completely defined operation (e.g., a full-sized table lookup). The Berkeley MPEG decoder <ref> [134] </ref> uses a similar table-driven approach. Several operations are combined or are carried out in-place to reduce processor/memory traffic: * The subband analysis stage performs quantization on the fly so that the output coefficients are stored in 8-bit format. <p> Since this rendering operation is performed after the decompression on uncompressed video, it can be a bottleneck and must be carefully implemented. Our profiles of vic match the experiences reported by Patel et al. <ref> [134] </ref>, where image rendering sometimes accounts for 50% or more of the execution time. Video output is rendered either through an output port on an external video device or to an X window. <p> For color-mapped displays, vic supports several modes of dithering that trade off quality for computational efficiency. The default mode is a simple error-diffusion dither carried out in the YUV domain. Like the approach described in <ref> [134] </ref>, we use table lookups for computing the error terms, but we use an improved algorithm for distributing color cells in the YUV color space. <p> Finally, we optimized the true-color rendering case. Here, the problem is simply to convert pixels from the YUV color space to RGB. Typically, this involves a linear transformation requiring four scalar multiplications and six conditionals. Inspired by the approach in <ref> [134] </ref>, vic uses an algorithm that gives full 24-bit resolution using a single table lookup on each U-V chrominance pair and performs all the saturation checks in parallel.
Reference: [135] <author> William B. Pennebaker and Joan L. Mitchell. </author> <title> JPEG Still Image Data Compression Standard. </title> <publisher> Van Nostrand Reinhold, </publisher> <year> 1993. </year>
Reference-contexts: DCT Image and video compression algorithms based on the Discrete Cosine Transform (DCT) have been enormously successful and are now used in a number of international image and video coding standards, 26 e.g., the Motion Picture Experts Group (MPEG) [108] video compression standard and the Joint Photographic Experts Group (JPEG) <ref> [85, 135] </ref> image compression standard. The DCT-based algorithms are instances of a generic transform coder, which is decomposed as follows: In this model, a transform, T , is applied to the input image to decorrelate the pixel values. <p> Because the encoder uses only a small, simple subset of H.261, the implementation is straightforward (a few hundred lines of C++). We achieve good computational performance by folding quantization into the DCT computation and by using an efficient 80-multiply 8x8 DCT <ref> [135] </ref>. We experimented with several vector-radix DCTs [29] but found that the separable row-column approach, despite having asymptotically higher complexity, performed better in the 8x8 case because of reduced memory traffic. Furthermore, because Intra-H.261 never sends inter-coded blocks, the algorithm avoids computing a prediction error signal.
Reference: [136] <author> J. Postel. </author> <title> User Datagram Protocol. </title> <institution> Internet Engineering Task Force, USC/Information Sciences Institute, </institution> <month> August </month> <year> 1980. </year> <month> RFC-768. </month>
Reference-contexts: An RTP session is a component of an LWS session and represents a collection of two or more end-systems exchanging a single media type and related control information over two distinct underlying transport channels. For UDP <ref> [136] </ref> over IP Multicast, these two underlying transport channels are mapped onto two distinct UDP port numbers sharing a common multicast address. An active source transmits its signal by generating packets on the data channel that conform to the payload format specification for the underlying compression format.
Reference: [137] <author> J. B. Postel. </author> <title> Transmission Control Protocol. ARPANET Working Group Requests for Comment, DDN Network Information Center, </title> <booktitle> SRI International, </booktitle> <address> Menlo Park, CA, </address> <month> August </month> <year> 1989. </year> <month> RFC-793. </month>
Reference-contexts: We will later see that building a video transmission system out of existing modular components can lead to suboptimal performance. For example, a video delivery system based on analytic decomposition might result in H.261 [171] for compression and TCP <ref> [137] </ref> for transport. Although these two approaches perform well in their individual environments, their combination results in poor end-to-end performance. Instead, we synthesize an end-to-end design that accounts for component interdependencies to optimize system-level behavior. <p> A controller uses this information to adjust the output rate of an MPEG [108] coder, allowing the source to react to queue buildup before packet loss occurs. A very different approach is taken in the Xphone system [49], which leverages off the congestion avoidance algorithms built into TCP/IP <ref> [137] </ref>. Xphone transmits JPEG [85] video over a TCP connection and measures the throughput of the transmission.
Reference: [138] <author> Calton Pu, Henry Massalin, and John Ioannidis. </author> <title> The synthesis kernel. </title> <journal> Computing Systems, </journal> <volume> 1(1) </volume> <pages> 11-32, </pages> <year> 1998. </year>
Reference-contexts: Moreover, we can use this approach to effect dynamic code generation (DCG) <ref> [138] </ref> where the codec is synthesized on demand to incorporate run-time knowledge into the compile-time optimizations. For example, we can use DCG to optimize the fast path of a bottleneck operation like rendering.
Reference: [139] <author> Kannan Ramchandran, Antonio Ortega, K. Metin Uz, and Martin Vetterli. </author> <title> Multiresolution broadcast for digital HDTV using joint source/channel coding. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 11(1) </volume> <pages> 6-23, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: A large number of layered coding schemes have been proposed, including schemes based on progressive DCT [68, 142, 104], subband coding [39, 11, 158], and pyramidal coding <ref> [139] </ref>. We reviewed some key areas in layered compression research and cited representative or landmark work in each area.
Reference: [140] <author> Anup Rao, Rob Lanphier, et al. </author> <title> Real time streaming protocol (RTSP), </title> <month> October </month> <year> 1996. </year> <title> Internet Draft (work in progress). </title>
Reference-contexts: That is, the buffer can underflow because the actual bandwidth was less than the predicted bandwidth and an inadequate amount of data was buffered before initiating playback. Two vendors of Web-related software have recently joined forces and proposed the Real Time Streaming Protocol (RTSP) <ref> [140] </ref> as an open standard for controlling and configuring streaming media. 2.3.5 Digital Media Toolkits Several research systems for networked multimedia emphasize the software architecture over the communication protocol.
Reference: [141] <author> K. R. Rao and P. Yip. </author> <title> Discrete Cosine Transform: Algorithms, Advantages, Applications. </title> <publisher> Academic Press, Inc., </publisher> <year> 1990. </year>
Reference-contexts: A well known property of the DCT is that it approximates the optimal decorrelating transform, the Karhunen-Loeve transform, for continuous tone images with high spatial correlation <ref> [141] </ref>. As a result, standards like MPEG and JPEG have adopted the DCT as the transform component in the diagram above: Here, 8x8 image blocks are first decomposed using a DCT. These coefficients are then quantized with a uniform scalar quantizer.
Reference: [142] <author> Amy R. Reibman. </author> <title> DCT-based embedded coding for packet video. </title> <booktitle> Signal Processing: Image Communication 3, </booktitle> <pages> pages 231-237, </pages> <year> 1991. </year>
Reference-contexts: A large number of layered coding schemes have been proposed, including schemes based on progressive DCT <ref> [68, 142, 104] </ref>, subband coding [39, 11, 158], and pyramidal coding [139]. We reviewed some key areas in layered compression research and cited representative or landmark work in each area.
Reference: [143] <author> Mark Roseman and Saul Greenberg. GroupKit: </author> <title> A groupware toolkit for building real-time conferencing applications. </title> <booktitle> In Proceedings of the Conference on Computer-Supported Cooperative Work, </booktitle> <month> October </month> <year> 1992. </year>
Reference-contexts: The multimedia and computer-supported collaborative-work research communities have developed an array of toolkits and techniques for collaborative work. Examples include DAVE [125], SCOOT [36], 38 GroupKit <ref> [143] </ref>, the Continuous Media Toolkit (CMT) [144], and VuSystem [112]. We briefly describe CMT and VuSystem since their approaches are most similar to ours. CMT is an object-oriented multimedia toolkit that allows objects to be mixed and matched into arbitrary applications. <p> Likewise, Schulzrinne developed a coordination scheme that ties together the MBone tools using Pattern Matching Multicast, a framework like our Coordination Bus with pattern-matching filters [151]. Our Composable Tools approach to networked multimedia contrasts with the more common toolkit framework adopted by other multimedia systems <ref> [36, 125, 143, 145] </ref>. Toolkits provide basic building blocks in the form of a code library with an application programming interface (API) to that library providing high-level abstractions for manipulating multimedia data flows.
Reference: [144] <author> Lawrence Rowe et al. </author> <title> Continuous Media Toolkit (CMT). </title> <institution> University of California, Berkeley. </institution> <note> Software on-line 9 </note> . 
Reference-contexts: The multimedia and computer-supported collaborative-work research communities have developed an array of toolkits and techniques for collaborative work. Examples include DAVE [125], SCOOT [36], 38 GroupKit [143], the Continuous Media Toolkit (CMT) <ref> [144] </ref>, and VuSystem [112]. We briefly describe CMT and VuSystem since their approaches are most similar to ours. CMT is an object-oriented multimedia toolkit that allows objects to be mixed and matched into arbitrary applications. CMT objects are implemented in C and composed using the Tool Command Language Tcl [131]. <p> CMT objects are implemented in C and composed using the Tool Command Language Tcl [131]. Smith's Cyclic-UDP described earlier is implemented as a CMT object and more recently the CMT development team has added objects that interface with RTP and the MBone <ref> [144] </ref>. The VuSystem is a similar multimedia toolkit built on top of an object-oriented Tcl extension [112]. C++ classes implement multimedia objects that produce, consume, or filter real-time media streams and a Tcl shadow object mirrors each C++ object.
Reference: [145] <author> Lawrence A. Rowe, Ketan D. Patel, Brian C. Smith, and Kim Liu. </author> <title> MPEG video in software: Representation, transmission, and playback. In High Speed Network and Multimedia Computing, </title> <booktitle> Symp. </booktitle> <institution> on Elec. Imaging Sci. & Tech., </institution> <address> San Jose, CA, </address> <month> February </month> <year> 1994. </year>
Reference-contexts: Likewise, Schulzrinne developed a coordination scheme that ties together the MBone tools using Pattern Matching Multicast, a framework like our Coordination Bus with pattern-matching filters [151]. Our Composable Tools approach to networked multimedia contrasts with the more common toolkit framework adopted by other multimedia systems <ref> [36, 125, 143, 145] </ref>. Toolkits provide basic building blocks in the form of a code library with an application programming interface (API) to that library providing high-level abstractions for manipulating multimedia data flows.
Reference: [146] <author> Amir Said and William A. Pearlman. </author> <title> A new fast and efficient image codec based on set partitioning in hierarchical trees. </title> <journal> IEEE Transactions on Circuits and Systems for Video Technology, </journal> <note> 1996. Submitted for publication. </note>
Reference-contexts: Hence we can trivially form a layered code from an embedded code by breaking up the longer code at arbitrary boundaries. Moreover we can tune the rates of the different layers since we have the freedom to break the embedded code at an arbitrary point. Said and Pearlman <ref> [146] </ref> improve EZW by using a two-level zerotree data structure. They describe their algorithm in terms of set partitioning of the wavelet coefficients, which is an alternate interpretation of the EZW algorithm. In turn, they effectively extend the notion of zerotree with a symbol that we call a grandparent zerotree.
Reference: [147] <author> J. H. Saltzer, D. P. Reed, and D. D. Clark. </author> <title> End-to-end arguments in system design. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(4), </volume> <month> November </month> <year> 1984. </year>
Reference-contexts: Together, these points support the classic end-to-end argument <ref> [147] </ref>. Any functionality that can be implemented efficiently at higher layers, outside of the network, should not be built into the network.
Reference: [148] <author> Eve M. Schooler. </author> <title> A multicast user directory service for synchronous rendezvous. </title> <institution> Computer science department, California Institute of Technology, </institution> <month> September </month> <year> 1996. </year>
Reference-contexts: The session rendezvous problem i.e., the task of each participant locating all others in a distributed group is greatly simplified by the level of indirection provided by multicast groups. Here each participant must merely learn the addresses that correspond to the session using a simple Announce/Listen protocol <ref> [148] </ref> running on a well-known multicast group. The Session Description Protocol (SDP) [75] is a proposed standard that defines the message formats and protocol for advertising the multicast address bindings. In LWS, group management is not explicit.
Reference: [149] <author> Eve M. Schooler and Stephen L. Casner. </author> <title> A packet-switched multimedia conferencing system. </title> <journal> ACM Special Interest Group on Office Information Systems Bulletin, </journal> <volume> 10 </volume> <pages> 12-22, </pages> <month> January </month> <year> 1989. </year> <note> 9 http://www.bmrc.berkeley.edu/cmt/ 169 </note>
Reference-contexts: a number of remaining challenges with our approach, present plans for future work, provide references to our implementation and simulation framework, and conclude. 14 Chapter 2 Related Work In the early days of the Internet, experiments with digitized voice demonstrated that interactive, real-time signals could be carried over packet-switched networks <ref> [32, 33, 149] </ref>. While packet voice was relatively easy to deploy because voice-grade audio codecs generate fairly low-rate data streams, packet video was less practical because of much higher bandwidth requirements and, at the time, limitations in digital video technology. <p> Within LWS and on top of the IP service interface we must define specific transport protocols and data formats to facilitate communication, and we must further determine a method for mapping these data formats onto multicast transmission channels. Through our work on the MBone tools and other similar efforts <ref> [164, 61, 149, 150] </ref>, the following communication model emerged. A session is comprised of a number of media and each media type is allocated to two transport channels one for data and one for control each using the same multicast group. <p> network to improve the end-to-end performance of packet video. 55 4.4 Integrated Design with ALF/JSCC: The Real-time Transport Protocol About the same time that Clark and Tennenhouse proposed ALF, we and others developed a number of tools to explore the problem of interactive audio and video transport across packet-switched networks <ref> [90, 149, 61, 117, 164, 150] </ref>. After several design iterations over transport protocols for several different audio/video compression formats, it became clear that a one size fits all protocol was inadequate [59, 120].
Reference: [150] <author> Henning Schulzrinne. </author> <title> Voice communication across the Internet: A network voice terminal. </title> <type> Technical Report TR 92-50, </type> <institution> Dept. of Computer Science, University of Massachusetts, Amherst, Massachusetts, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: Within LWS and on top of the IP service interface we must define specific transport protocols and data formats to facilitate communication, and we must further determine a method for mapping these data formats onto multicast transmission channels. Through our work on the MBone tools and other similar efforts <ref> [164, 61, 149, 150] </ref>, the following communication model emerged. A session is comprised of a number of media and each media type is allocated to two transport channels one for data and one for control each using the same multicast group. <p> network to improve the end-to-end performance of packet video. 55 4.4 Integrated Design with ALF/JSCC: The Real-time Transport Protocol About the same time that Clark and Tennenhouse proposed ALF, we and others developed a number of tools to explore the problem of interactive audio and video transport across packet-switched networks <ref> [90, 149, 61, 117, 164, 150] </ref>. After several design iterations over transport protocols for several different audio/video compression formats, it became clear that a one size fits all protocol was inadequate [59, 120].
Reference: [151] <author> Henning Schulzrinne. </author> <title> Dynamic configuration of conferencing applications using pattern-matching multicast. </title> <booktitle> In Proceedings of the Fifth International Workshop on Network and OS Support for Digital Audio and Video, </booktitle> <address> Durham, NH, </address> <month> April </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: Likewise, Schulzrinne developed a coordination scheme that ties together the MBone tools using Pattern Matching Multicast, a framework like our Coordination Bus with pattern-matching filters <ref> [151] </ref>. Our Composable Tools approach to networked multimedia contrasts with the more common toolkit framework adopted by other multimedia systems [36, 125, 143, 145].
Reference: [152] <author> Henning Schulzrinne. </author> <title> RTP Profile for Audio and Video Conferences with Minimal Control. </title> <institution> Internet Engineering Task Force, Audio-Video Transport Working Group, </institution> <month> January </month> <year> 1996. </year> <month> RFC-1890. </month>
Reference-contexts: As described in the previous chapter, the Audio/Video Transport Working Group of the Internet Engineering Task Force (IETF) standardized this base protocol in the Real-time Transport Protocol or RTP [153] and developed a profile for Audio and Video conferences with minimal control <ref> [152] </ref> along with a number of payload format standards for specific applications like H.261, JPEG, and MPEG. A key goal in RTP is to provide a very thin transport layer without overly restricting the application designer.
Reference: [153] <author> Henning Schulzrinne, Steve Casner, Ron Frederick, and Van Jacobson. RTP: </author> <title> A Transport Protocol for Real-Time Applications. </title> <institution> Internet Engineering Task Force, Audio-Video Transport Working Group, </institution> <month> January </month> <year> 1996. </year> <month> RFC-1889. </month>
Reference-contexts: In the fall of 1992, Schulzrinne released an MBone audio tool similar to vat called nevot. This tool was the principal development vehicle for the earliest versions of the Real-time Transport Protocol (RTP) <ref> [153] </ref>. RTP and the vat audio protocol were eventually combined, culminating in a revamped version of the RTP specification in 1995. <p> We originally conceived vic as an application to demonstrate the Tenet real-time networking protocols [53] and to simultaneously support the evolving Lightweight Sessions architecture [88] that implicitly underlies all of the tools discussed. Work on vic 4 has since driven the evolution of the Real-time Transport Protocol (RTP) <ref> [153] </ref>. As RTP evolved, we tracked and implemented protocol changes, and fed back implementation experience to the design process. Moreover, our experience implementing the RTP payload specification for H.261 led to an improved scheme based on macroblock-level fragmentation, which resulted in a revised protocol [166]. <p> Vic was a critical substrate for the de velopment of Intra-H.261, PVH, and the our system architecture for multimedia conferencing. * RTP. Work on vic and RLM has facilitated the development and deployment of the Real-time Transport Protocol (RTP) <ref> [153] </ref>. Vic was the first implementation of Version 2 of RTP and was the test vehicle for many of the algorithms used in the protocol. * Coordination Bus. <p> While these two approaches increase the scalability of the protocol, they do not eliminate the implosion problem altogether. The IETF's Audio/Video Transport Working Group (AVT) has standardized the Real-time Transport Protocol <ref> [153] </ref>, or RTP, for real-time multimedia delivery over multicast (and unicast) networks. RTCP, the control protocol embedded in RTP, requires that receivers transmit reception reports back to the multicast group, which contain loss, throughput, and delay statistics as seen by the reporting host. <p> be dynamically computed so that the aggregate report bandwidth is some small percentage of the real-time media bandwidth. 21 The RTP specification suggests that the reception reports could be used in a feedback control loop where the source would adjust its transmission rate based on the state of the network <ref> [153, Section 6.3.4] </ref>. Busse et al. [20] first implemented this approach (and worked out many unspecified details) by modifying vic [120] with a specific instance of an RTCP-based multicast feedback control algorithm. <p> Traditional transport protocols are typically implemented within the operating system kernel and entail hard connection state, whereas the LWS model for transport is relatively thin and is implemented within the application. This approach is embodied in the Real-time Transport Protocol or RTP <ref> [153] </ref>, recently standardized by the Audio/Video Transport Working group of the Internet Engineering Task Force (IETF). RTP defines much of the protocol architecture necessary for video transmission over a multi-point packet network. <p> We believe that the emergence of JSCC and ALF signals a shift in the core nature of network research the traditional, highly layered protocol architecture must be abandoned. Rather than design protocols composed of modular black boxes, we must synthesize new, application-specific protocols (e.g., FLIIT [37], RLM, RTP <ref> [153] </ref>, and SRM [59]) that account for the interaction between application and network. 52 In this chapter, we establish ALF and JSCC as a core design principle for our layered video architecture. <p> As described in the previous chapter, the Audio/Video Transport Working Group of the Internet Engineering Task Force (IETF) standardized this base protocol in the Real-time Transport Protocol or RTP <ref> [153] </ref> and developed a profile for Audio and Video conferences with minimal control [152] along with a number of payload format standards for specific applications like H.261, JPEG, and MPEG. A key goal in RTP is to provide a very thin transport layer without overly restricting the application designer. <p> We can avoid these problems by scaling down the individual join-experiment rates in proportion to the overall group size. In other words, we can fix the aggregate join-experiment rate independent of session size much as RTCP scales back its control message rate in proportion to the group size <ref> [153] </ref>. However, reducing the experiment rate in this manner decreases the learning rate. For large groups, the algorithm will take too long to converge. Our solution is shared learning: Before a receiver conducts a join-experiment, it notifies the entire group by multicasting a message identifying the experimental layer. <p> To scale to large session sizes, T max J is dynamically adjusted in proportion to the number of receivers. The number of receivers is in turn dynamically estimated through the exchange of session-wide control messages (e.g., as in RTCP <ref> [153] </ref>). Thus the aggregate join-experiment rate is fixed, independent of the session size, and packet loss induced by join-experiments does not increase with session size. The join-timer undergoes relaxation in steady-state. <p> As we described in Chapter 4, ALF allows us to optimize the application explicitly for the network by reflecting an application's semantics in the design of its network protocol. Fortunately, a great deal of machinery for packet video transmission is already defined by the Real-time Transport Protocol or RTP <ref> [153] </ref> (see Chapter 3). Because RTP is based on ALF and meets many of our design goals, we leverage upon RTP in our design of a framing protocol for PVH. <p> Because of its ALF-like model, RTP is a natural match to our Composable Tools framework and serves as the foundation for the tools' network architecture. Complete details of the RTP specification are provided in <ref> [153] </ref> but we briefly review one feature of the protocol relevant to the Coordination Bus. Because media are distributed on independent RTP sessions (and because vic is implemented independently of other multimedia applications), the protocol must provide a mechanism for identifying relationships among media streams (e.g., for audio/video synchronization). <p> We can similarly exploit the embedded property of PVH to adjust the bit-rate allocated to each layer based on feedback from the receivers. By monitoring scalable, low-rate feedback from RLM receivers (e.g., as provided by RTCP <ref> [153] </ref>), a source can tailor its overall rate allocation to the particular network environment. <p> This document describes only a video coding algorithm and assumes that other components requisite to a complete multimedia communication system are defined elsewhere. The codec is based on an underlying packet-switched internetworks and utilizes the Real-time Transport Protocol (RTP) <ref> [153] </ref> and related standards from the Internet Engineering Task Force (IETF). In the RTP framework, a number of documents known as payload format specifications describe methods for adapting existing audio and video coding schemes for packet transmission using RTP. <p> An image is defined by a collection of packets from potentially different layers. Each packet is prefixed by a standard RTP header as described in <ref> [153] </ref>. The RTP payload type is not pre-assigned and is instead dynamically assigned by an external mechanism (e.g., using the Session Description Protocol (SDP) [75]). All packets that belong to an identical image have the same RTP timestamp but are in no particular order.
Reference: [154] <author> Nachum Shacham. </author> <title> Multicast routing of hierachical data. </title> <booktitle> In Proceedings of the International Conference on Computer Communications. IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: A uniform transmission rate fails to accommodate the bandwidth heterogeneity of this diverse set of receivers. 1.3 A Solution: Layered Compression and Transmission An often cited approach for coping with receiver heterogeneity in real-time multimedia transmissions is the use of layered media streams <ref> [43, 44, 83, 122, 154, 162, 165, 173] </ref>. In this model, rather than distribute a single level of quality using a single network channel, the source distributes multiple levels of 8 quality simultaneously across multiple network channels.
Reference: [155] <author> Nachum Shacham. </author> <title> Multipoint communication by hierarchically encoded data. </title> <booktitle> In Proceedings IEEE Infocom '92, </booktitle> <pages> pages 2107-2114, </pages> <year> 1992. </year>
Reference-contexts: When combined with RLM, our Progressive Video with Hybrid-transform codec, or PVH, provides a comprehensive solution for scalable multicast video transmission in heterogeneous networks. 1.4 Contributions A number of research activities have laid the groundwork for both layered video compression [100, 124, 24, 162, 173] and layered transmission systems <ref> [101, 155, 43, 132, 165, 78] </ref>. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem. <p> Using the layered compression and transmission model described in Chapter 1, receivers adapt to local capacity in the network by adjusting their level of subscription to the transmission. The earliest appearance in the literature of the layered compression/transmission model for mul-ticast was due to Shacham <ref> [155] </ref>. In his Heterogeneous Multicast (HMC), network and end-system heterogeneity is handled through a combination of layered source coding and layered packet forwarding. This early work focused on optimal route computations that maximize the aggregate delivered rate across all of the destinations for a given traffic mix. <p> Several researchers have additionally suggested using the I, P, B frame structure of MPEG to induce a temporal hierarchy <ref> [155, 2, 44] </ref>. 2.2.2 Pyramid Coding A landmark work in multiresolution image coding is Burt and Adelson's pyramid coding framework [19]. The basic structure is illustrated in Figure 2.5. The input image is first downsampled and low-pass 28 structure.
Reference: [156] <author> C. E. Shannon. </author> <title> A mathematical theory of communication. </title> <journal> Bell Systems Technical Journal, </journal> <volume> 27 </volume> <pages> 379-423, </pages> <year> 1948. </year>
Reference-contexts: This idea that the rate of an information source (like video) can be adjusted by degrading reconstruction quality was born in rate-distortion theory first developed by Shannon <ref> [156] </ref>. The rate-distortion framework forms the bedrock of traditional video codec design, where codec parameters (i.e., compression quality) are dynamically adjusted to match the transmission rate of a CBR communications channel. is controlled via quantization parameters.
Reference: [157] <author> Jerome M. Shapiro. </author> <title> Embedded image coding using zerotrees of wavelet coefficients. </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> 41(12) </volume> <pages> 3445-3462, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Consequently, a high-energy edge that appears only at fine scales would be missed. Second, although the coder is based on subband decomposition, it does not immediately admit a layered representation. Shapiro solved both of these problems in a scheme called Embedded Zerotrees of Wavelet coefficients (EZW) <ref> [157] </ref>. He improved upon Lewis and Knowles' scheme by creating a fully embedded code through successive refinement of quantization intervals. When the quantization intervals are refined by powers of two, the scheme is equivalent to bit-plane coding of the subband coefficient magnitudes. <p> We then group the coefficients across scales with like orientation into the well-known quad-tree structure, and then entropy-code them using a variant of Shapiro's scheme for Embedded Zerotrees of Wavelet coefficients (EZW) <ref> [157] </ref>. This coding structure is illustrated in Unfortunately, a tension arises between subband decomposition and conditional replenishment. <p> Hence, we removed temporal coding overheads (like macroblock addressing codes) from each codec. Because we compare only grayscale PSNR performance, we additionally removed chrominance syntax overhead. In addition to the Internet video codecs, we compared our results against Shapiro's EZW algorithm <ref> [157] </ref> and progressive-mode JPEG [85, Annex G] to gauge the performance of our scheme against well-established subband- and DCT-based image codecs. For each algorithm, we obtained a distortion-rate characteristic for the 512x512 Lena gray scale test image as follows: * Intra-H.261. <p> We obtained the curve using the JPEG codec's scans option to compute multiple operating points by controlling the number of refinement passes used by the encoder. * EZW. We used the performance results reported in <ref> [157] </ref>. 106 at low rates, comparable at medium rates, and somewhat inferior at high rates. 107 we must choose a single path through this rate-scaling space.
Reference: [158] <author> Robert J. Siracusa, Kuriacose Joseph, Joel Zdepski, and Dipankar Raychaudhuri. </author> <title> Flexible and robust packet transport for digital HDTV. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 11(1) </volume> <pages> 88-98, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: A large number of layered coding schemes have been proposed, including schemes based on progressive DCT [68, 142, 104], subband coding <ref> [39, 11, 158] </ref>, and pyramidal coding [139]. We reviewed some key areas in layered compression research and cited representative or landmark work in each area.
Reference: [159] <author> Brian Christopher Smith. </author> <title> Implementation Techniques for Continuous Media Systems and Applications. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: When packets are discarded due to queue overflow, the application layer is notified to reduce its data rate. This scheme works only for local area networks, where congestion results in increased media access latencies at the local adaptor. Smith's Cyclic-UDP <ref> [159] </ref> maintains a bandwidth estimator that drives a rate-based control algorithm. At regularly spaced intervals, the receiver transmits a feedback report to the sender summarizing loss, delay, and received throughput. The sender uses a number of heuristics to adjust its estimated bandwidth based on this report.
Reference: [160] <author> Michael F. Speer and Steven McCanne. </author> <title> RTP usage with Layered Multimedia Streams. </title> <institution> Internet Engineering Task Force, Audio-Video Transport Working Group, </institution> <month> March </month> <year> 1996. </year> <title> Internet Draft (work in progress). </title>
Reference-contexts: These proposed changes allow a participant to use one Source-ID consistently across the logically distinct RTP sessions comprising the RLM/PVH hierarchy. This proposal is currently under review by the IETF 3 <ref> [160] </ref>. 6.6.1 The PVH Framing Protocol The flexibility of RTP's ALF-based framework gives us the freedom to optimize the PVH framing protocol for robust interaction with the underlying network.
Reference: [161] <author> Lawrence C. Stewart, Andrew C. Payne, and Thomas M. Levergood. </author> <type> Are DSP chips obsolete? Technical Report CRL 92/10, </type> <institution> Digital Equipment Corporation Cambridge Research Lab, </institution> <address> Cambridge, MA, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: In this framework, a codec is specified as an interconnection of modules in a high level language and compiled into native code through translation and optimization. While earlier attempts to use high-level languages like C for signal processing algorithms have produced lukewarm results <ref> [161] </ref>, we believe that better performance can be realized with a highly constrained specification syntax targeted specifically for video codecs and certain specialized optimizations 2 .
Reference: [162] <author> David Taubman and Avideh Zakhor. </author> <title> Multi-rate 3-D subband coding of video. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 3(5) </volume> <pages> 572-588, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: A uniform transmission rate fails to accommodate the bandwidth heterogeneity of this diverse set of receivers. 1.3 A Solution: Layered Compression and Transmission An often cited approach for coping with receiver heterogeneity in real-time multimedia transmissions is the use of layered media streams <ref> [43, 44, 83, 122, 154, 162, 165, 173] </ref>. In this model, rather than distribute a single level of quality using a single network channel, the source distributes multiple levels of 8 quality simultaneously across multiple network channels. <p> When combined with RLM, our Progressive Video with Hybrid-transform codec, or PVH, provides a comprehensive solution for scalable multicast video transmission in heterogeneous networks. 1.4 Contributions A number of research activities have laid the groundwork for both layered video compression <ref> [100, 124, 24, 162, 173] </ref> and layered transmission systems [101, 155, 43, 132, 165, 78]. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem. <p> Clearly, this scheme can be generalized to an arbitrary number of frames by using longer and/or iterated temporal subband filters. 3D Subband Video Coding. Taubman and Zakhor <ref> [162] </ref> build on both the spatio-temporal pyramid structure and the intersubband coding techniques with a layered video compression algorithm that performs on par with the best non-layered schemes. <p> Instead of a standardized compression algorithm, we could potentially adopt an existing experimental layered compression algorithm in our system. Taubman and Zakhor's 3D Subband Coding system is a high performance scalable video compression algorithm that produces a very fine-grained layered representation <ref> [162] </ref>. Its computational complexity, however, is relatively high and acceptable run-time performance will require a few more generations of processor evolution. Vishwanath and Chou's Weighted Wavelet Hierarchical Vector Quantization algorithm [173] is low-complexity and has a layered output format.
Reference: [163] <author> David L. Tennenhouse and David J. Wetherall. </author> <title> Towards an active network architecture. </title> <journal> Computer Communication Review, </journal> <volume> 26(2) </volume> <pages> 5-18, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: A 1 Mb/s Motion-JPEG stream is transmitted over the campus network and two gateways are deployed. One gateway transcodes the high-rate stream to a 128 kb/s H.261 stream for the Internet, while the other produces an 80 kb/s stream for users over ISDN. Tennenhouse and Wetherall's Active Network Architecture <ref> [163] </ref> provides a vastly generalized approach for the deployment of rate-adaptive video gateways within the network. In their architecture, network nodes carry out arbitrary computation to implement not only network functions but also user-specified algorithms.
Reference: [164] <author> Thierry Turletti. </author> <title> INRIA Video Conferencing System (ivs). </title> <institution> Institut National de Recherche en Informa-tique et an Automatique. </institution> <note> Software on-line 10 . 10 http://www.inria.fr/rodeo/ivs.html 170 </note>
Reference-contexts: Within LWS and on top of the IP service interface we must define specific transport protocols and data formats to facilitate communication, and we must further determine a method for mapping these data formats onto multicast transmission channels. Through our work on the MBone tools and other similar efforts <ref> [164, 61, 149, 150] </ref>, the following communication model emerged. A session is comprised of a number of media and each media type is allocated to two transport channels one for data and one for control each using the same multicast group. <p> network to improve the end-to-end performance of packet video. 55 4.4 Integrated Design with ALF/JSCC: The Real-time Transport Protocol About the same time that Clark and Tennenhouse proposed ALF, we and others developed a number of tools to explore the problem of interactive audio and video transport across packet-switched networks <ref> [90, 149, 61, 117, 164, 150] </ref>. After several design iterations over transport protocols for several different audio/video compression formats, it became clear that a one size fits all protocol was inadequate [59, 120].
Reference: [165] <author> Thierry Turletti and Jean-Chrysostome Bolot. </author> <title> Issues with multicast video distribution in heterogeneous packet networks. </title> <booktitle> In Proceedings of the Sixth International Workshop on Packet Video, </booktitle> <address> Portland, OR, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: A uniform transmission rate fails to accommodate the bandwidth heterogeneity of this diverse set of receivers. 1.3 A Solution: Layered Compression and Transmission An often cited approach for coping with receiver heterogeneity in real-time multimedia transmissions is the use of layered media streams <ref> [43, 44, 83, 122, 154, 162, 165, 173] </ref>. In this model, rather than distribute a single level of quality using a single network channel, the source distributes multiple levels of 8 quality simultaneously across multiple network channels. <p> The network forwards only the number of layers that each physical link can support. much of the previous work leaves this problem as an implementation detail, a novel and practical scheme was proposed by Deering [43] and was further described and/or independently cited in <ref> [24, 44, 83, 122, 165] </ref>. In this approach, the layers that comprise the hierarchical signal are striped across distinct multicast groups thereby allowing receivers to adjust their reception rate by controlling the number of groups they receive. <p> When combined with RLM, our Progressive Video with Hybrid-transform codec, or PVH, provides a comprehensive solution for scalable multicast video transmission in heterogeneous networks. 1.4 Contributions A number of research activities have laid the groundwork for both layered video compression [100, 124, 24, 162, 173] and layered transmission systems <ref> [101, 155, 43, 132, 165, 78] </ref>. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem. <p> In this configuration, the server replicates each incoming packet to each of the outgoing connections causing quadratic growth of traffic. The RTP architecture explicitly allows application-level gateways to carry out format conversion and rate-adaptation between RTP sessions. Turletti and Bolot <ref> [165] </ref> describe an architecture based on this model where video gateways are placed throughout the network to transcode portions of the multicast distribution tree into a lower bit rate coding, using either the same coding format with different parameters or a different coding scheme altogether. <p> The authors do not discuss adaptation algorithms or report implementation results. As described in Chapter 1, Deering first suggested that the IP Multicast be used as a layered transmission system where layers are individually mapped onto multicast groups [43]. Both Turletti and Bolot <ref> [165] </ref> and Chaddha and Gupta [25] describe this architecture but do not present an adaptation algorithm or implementation. Our approach was first described in [118] and [122], but a specific adaptation scheme was not published until [121].
Reference: [166] <author> Thierry Turletti and Christian Huitema. </author> <title> RTP Payload Format for H.261 Video Streams. </title> <institution> Internet Engineering Task Force, Audio-Video Transport Working Group, </institution> <month> October </month> <year> 1996. RFC-2032. </year>
Reference-contexts: As RTP evolved, we tracked and implemented protocol changes, and fed back implementation experience to the design process. Moreover, our experience implementing the RTP payload specification for H.261 led to an improved scheme based on macroblock-level fragmentation, which resulted in a revised protocol <ref> [166] </ref>. Finally, the RTP payload specification for JPEG [10] evolved from a vic implementation. The most recent major development in MBone applications is the Robust Audio Tool, rat, from University College London in 1995. Rat uses a novel forward error correction scheme where redundant information is coded at lower quality. <p> In addition, our development of Intra-H.261 influenced the RTP Payload Format Specification for H.261 <ref> [166] </ref>, where the fragmentation algorithm was improved through the integration of ALF 6 . Intra-H.261 is currently the most commonly used compression format for MBone video and has been incorporated into several commercial products. * vic. <p> Our scheme called Intra-H.261 led to improvements in the RTP Payload Specification for H.261 <ref> [166] </ref>. 4.1 The Separation Principle Before we can precisely define joint source/channel coding, we must first describe Shannon's separation principle. <p> This approach was taken in early versions of Turletti and Huitema's RTP Payload Format Specification for H.261 <ref> [166] </ref>, but it had several shortcomings: (i) A GOB does not necessarily fit within a packet and often must be fragmented across multiple packets.
Reference: [167] <author> Thierry Turletti and Christian Huitema. </author> <title> Videoconferencing in the Internet. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 4(3) </volume> <pages> 340-351, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: it is now strained by the growth of the MBone user community and by the MBone's transition from experimental to production service. 2.3.2 INRIA Videoconferencing System Soon after nv was put to use for MBone video transmission, INRIA released their video application called the INRIA Video Conferencing System or ivs <ref> [167] </ref>. Unlike nv, ivs is an integrated audio/video conferencing system that relies exclusively on H.261 [171] for video compression. <p> Turletti and Huitema proposed such a loss-adaptive source-coding technique where the interval of intra-mode block updates (i.e., the amount of rate allocated to redundancy) is controlled by observations of the network <ref> [167] </ref>. <p> In the summer of 1995, the RTP/H.261 packet format was modified to include fields for the spatial prediction state required by macroblock-based fragmentation. These changes were based on our experiences with Intra-H.261 in combination with the pioneering work on the original adaptation of H.261 for Internet transmission in ivs <ref> [167] </ref>. The resulting payload format and fragmentation scheme is detailed in [167]. 4.6 Performance Results Because the Intra-H.261 and nv compression schemes use similar conditional replenishment algorithms, we can evaluate their relative compression performance by ignoring the temporal dimension and comparing only their 2D image compression performance. <p> These changes were based on our experiences with Intra-H.261 in combination with the pioneering work on the original adaptation of H.261 for Internet transmission in ivs <ref> [167] </ref>. The resulting payload format and fragmentation scheme is detailed in [167]. 4.6 Performance Results Because the Intra-H.261 and nv compression schemes use similar conditional replenishment algorithms, we can evaluate their relative compression performance by ignoring the temporal dimension and comparing only their 2D image compression performance.
Reference: [168] <author> Martin Vetterli. </author> <title> Multidimensional subband coding: Some theory and algorithms. </title> <booktitle> Signal Processing, </booktitle> <volume> 6(2) </volume> <pages> 97-112, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: Moreover, the filters can be efficiently computed in software (and hardware) using only shifts and adds. Vetterli first suggested that wavelet transforms be applied to image coding by applying separable subband filters sequentially across the horizontal and vertical directions <ref> [168] </ref>. An example of this widely used separable 2D subband/wavelet decomposition is shown in Figure 2.7. We first apply the subband analysis filter pairs horizontally, which results in the coarse scale and enhancement subsignals often called the L subband and the H subband.
Reference: [169] <author> Martin Vetterli and Jelena Kovacevic. </author> <title> Wavelets and Subband Coding. </title> <publisher> Prentice-Hall, </publisher> <year> 1995. </year>
Reference-contexts: a hierarchy that complements the resolution adaptability of the human visual system. 32 the four-stage decomposition from Figure 2.7 to the LL subband. 33 One of the simplest subband coding techniques is to process the subbands in some well defined scan order and code each coefficient of each subband independently <ref> [169] </ref>. A bit-allocation optimization determines how many bits of precision to allocate to each band (e.g., the coarse scale bands are typically most important and are allocated more bits per coefficient than the finest scale subbands). <p> Our solution for the coder described above was to use short analysis filters to increase the coherence between the subband and pixel representations. We used the following biorthogonal filters for the first-stage analysis <ref> [169] </ref>: H 0 (z) = 1 + 3z 1 + 3z 2 z 3 with the following synthesis 1 G 0 (z) = (1 + 3z 1 + 3z 2 + z 3 )=16 and Haar filters for the remaining three stages.
Reference: [170] <author> Martin Vetterli and Steven McCanne. </author> <title> On the sub-optimality of receiver-driven layered multicast. </title> <type> Technical report, </type> <institution> University of California, Berkeley, </institution> <address> CA, </address> <month> January </month> <year> 1997. </year>
Reference-contexts: Even if the bandwidth allocation were fair, the aggregate system performance, as measured by the sum of distortions at each receiver, would not be optimal. As shown in <ref> [170] </ref>, minimization of the total distortion in general requires an exchange of information among receivers. 1 If X k is a continuous random variable on (a; b), then lim inffX n g is a. 71 the graft point.
Reference: [171] <institution> Video codec for audiovisual services at p*64kb/s, </institution> <year> 1993. </year> <note> ITU-T Recommendation H.261. </note>
Reference-contexts: We will later see that building a video transmission system out of existing modular components can lead to suboptimal performance. For example, a video delivery system based on analytic decomposition might result in H.261 <ref> [171] </ref> for compression and TCP [137] for transport. Although these two approaches perform well in their individual environments, their combination results in poor end-to-end performance. Instead, we synthesize an end-to-end design that accounts for component interdependencies to optimize system-level behavior. <p> This success prompted continued work on remote collaboration tools like vat and many new pieces came together in 1992. INRIA released their video conferencing tool, ivs, an integrated audio/video conferencing system that relies exclusively on H.261 <ref> [171] </ref> for video compression. In the fall of 1992, Schulzrinne released an MBone audio tool similar to vat called nevot. This tool was the principal development vehicle for the earliest versions of the Real-time Transport Protocol (RTP) [153]. <p> Moreover, the run-time performance is comparable to that of existing single-layer Internet video codecs. * Intra-H.261. We designed a novel coding scheme for Internet video using a fully-compliant subset of the ITU H.261 video compression standard <ref> [171] </ref>. Our scheme, called Intra-H.261, gives significant gain in compression performance compared to the custom coding scheme in nv and substantial improvement in both run-time performance and packet-loss tolerance compared to the conventional H.261 algorithm in ivs. <p> Their protocol is implemented in the INRIA Videoconferenceing System (ivs), which like nv and vic, runs over RTP and IP Multicast. As in related schemes, they use feedback from the network to control the output rate of the video coder, in this case, an H.261 <ref> [171] </ref> software codec. Their protocol employs a novel probing mechanism to elicit feedback from the network that is based on a probabilistic solicitation of the receivers to determine the size of the multicast group and the worst case state of congestion. <p> Unlike nv, ivs is an integrated audio/video conferencing system that relies exclusively on H.261 <ref> [171] </ref> for video compression. Because it utilizes a standardized algorithm, ivs interoperates with a large installed base of H.320 video codecs as an H.320-compliant bit stream is easily generated from an H.261 packet stream by introducing H.221 framing in software [77].
Reference: [172] <institution> Video coding for low bitrate communication, </institution> <year> 1996. </year> <note> ITU-T Recommendation H.263. </note>
Reference-contexts: We therefore measured the utilization and found it to be 40%, which adjusts the 30 f/s measure to 75 f/s. Conditional-Replenishment. To quantify the advantages of conditional replenishment over temporal prediction, we compared the relative performances of Intra-H.261 and of the newer ITU H.263 <ref> [172] </ref> standard in a simulation of different packet loss rates in the network. H.263 is widely regarded as the state of the art in low bit-rate video coding. We coded the standard Miss America grayscale test sequence using both Intra-H.261 and the Telenor implementation 3 of H.263.
Reference: [173] <author> Mohan Vishwanath and Phil Chou. </author> <title> An efficient algorithm for hierarchical compression of video. </title> <booktitle> In Proceedings of the IEEE International Conference on Image Processing, </booktitle> <address> Austin, TX, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: A uniform transmission rate fails to accommodate the bandwidth heterogeneity of this diverse set of receivers. 1.3 A Solution: Layered Compression and Transmission An often cited approach for coping with receiver heterogeneity in real-time multimedia transmissions is the use of layered media streams <ref> [43, 44, 83, 122, 154, 162, 165, 173] </ref>. In this model, rather than distribute a single level of quality using a single network channel, the source distributes multiple levels of 8 quality simultaneously across multiple network channels. <p> When combined with RLM, our Progressive Video with Hybrid-transform codec, or PVH, provides a comprehensive solution for scalable multicast video transmission in heterogeneous networks. 1.4 Contributions A number of research activities have laid the groundwork for both layered video compression <ref> [100, 124, 24, 162, 173] </ref> and layered transmission systems [101, 155, 43, 132, 165, 78]. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem. <p> WWHVQ. One of the first works from the compression community to specifically target the problem of Internet multicast video delivery is Vishwanath and Chou's perceptually-Weighted Wavelets using Hierarchical Vector Quantization (WWHVQ) <ref> [173] </ref>. Their hybrid scheme combines hierarchical vector quantization with wavelet decomposition. The approach is especially attractive because it can be implemented efficiently in software using only table lookups. However, their scheme does not produce an embedded code and hence requires active manipulation to transcode the bit rate. <p> Its computational complexity, however, is relatively high and acceptable run-time performance will require a few more generations of processor evolution. Vishwanath and Chou's Weighted Wavelet Hierarchical Vector Quantization algorithm <ref> [173] </ref> is low-complexity and has a layered output format. Their algorithm is based entirely on table look-ups and runs fast on current generation hardware. However, they have not produced a publicly available implementation nor presented details on its overall performance in real environments.
Reference: [174] <author> D. Waitzman, C. Partridge, and S. Deering. </author> <title> Distance Vector Multicast Routing Protocol. ARPANET Working Group Requests for Comment, DDN Network Information Center, </title> <booktitle> SRI International, </booktitle> <address> Menlo Park, CA, </address> <month> November </month> <year> 1988. </year> <month> RFC-1075. </month>
Reference-contexts: A number of multicast routing protocols compute spanning trees from an anchor point in the network (either the sending host or a rendezvous point or core) to all of the receivers, e.g., Protocol Independent Multicast (PIM) [40], Distance Vector Multicast Routing Protocol (DVMRP) <ref> [174] </ref>, or Core Based Trees (CBT) [7]. Because the anchor point (i.e., source address) uniquely identifies the spanning tree, multi-cast routers can use it to compute the forwarding decision for a given packet.
Reference: [175] <author> David Wetherall and Christopher J. Lindblad. </author> <title> Extending Tcl for dynamic object-oriented programming. </title> <booktitle> In Proceedings of the Tcl/Tk Workshop, </booktitle> <address> Ontario, Canada, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: This style of explicit method combination contrasts with other object-oriented methodologies e.g., the Common Lisp Object System or the Object Tcl programming model <ref> [175] </ref> that automatically combine methods that are split across classes. To facilitate the introduction of new object types into MBTK, we created a special base class called Matcher that provides a template for object creation. <p> This has led to substantial complexity in our Tcl scripts; we have thus concluded that we must revisit our Tcl-level design. We plan to enhance MBTK with MIT's Object Tcl or OTcl <ref> [175] </ref>. On the one hand, our TclObject framework allows us to export C++ objects into a monolithic Tcl program, while on the other, OTcl provides an object-orienting programming methodology within Tcl itself.
Reference: [176] <author> Richard L. White. </author> <title> High-performance compression of astronomical images. </title> <editor> In James C. Tilton, editor, </editor> <booktitle> Proceedings of the NASA Space and Earth Science Data Compression Workshop, </booktitle> <address> Snowbird, Utah, </address> <month> March </month> <year> 1992. </year>
Reference-contexts: Divide bit-plane into four equally sized bit-planes, and recursively code these subplanes. This decomposition is similar to the Autoadaptive Block Coding algorithm of Kunt and Johsen [106] though they applied it to bi-level images without any transformation. The hcompress algorithm described in <ref> [176] </ref> similarly exploits this technique in combination with subband decomposition over the entire image. In practice, our algorithm diverges somewhat from this conceptual framework in order to optimize the syntax for better run-time performance.
Reference: [177] <author> J. W. Woods and S. D. O'Neil. </author> <title> Sub-band coding of images. </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> 34(5) </volume> <pages> 1278-1288, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: We then apply the vertical filters to each of the new subbands. This results in the four band decomposition consisting of a coarse scale LL band and the LH, HL, and HH enhancement subbands. Woods independently developed this coding model and designed the first compression schemes based on it <ref> [177] </ref>. A layered structure is explicit in this representation and one obvious approach for a layered coding algorithm is to code each subband independently.
Reference: [178] <author> Raj Yavatkar and Leelanivas Manoj. </author> <title> Optimistic strategies for large-scale dissemination of multimedia information. </title> <booktitle> In Proceedings of ACM Multimedia '93, </booktitle> <pages> pages 1-8. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1993. </year>
Reference-contexts: The coding theory literature contains a rich array of techniques for error-correcting block codes. Yavatkar and Manoj presented some simple techniques for packet transmission based on repetition codes (i.e., packet duplication) and parity packets <ref> [178] </ref>. Although these types of error-control codes are simple to implement, they have high overhead compared to more sophisticated codes and are not widely used. Priority Encoding Transmission (PET) [2] utilizes forward error-correction coding but considers only the so called unequal error protection (UEP) codes [116]. <p> But as Figure 2.3 illustrates, this would cause feedback implosion. When the source queries the group for feedback, the entire group sends back control messages that implode at the source. Yavatkar and Manoj <ref> [178] </ref> address the feedback implosion problem using rate-based flow-control driven by selective receiver feedback. In their Quasi-reliable Multicast Transport Protocol (QMTP), a source transmits at a constant rate over a fixed time-interval or epoch.
Reference: [179] <author> Lixia Zhang, Steve Deering, Deborah Estrin, Scott Shenker, and Daniel Zappala. RSVP: </author> <title> A new resource reservation protocol. </title> <journal> IEEE Network, </journal> <volume> 7 </volume> <pages> 8-18, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: CBQ provides a flexible building block for implementing link sharing policies and has been shown to be capable of providing high-level service guarantees [54]. The ReSerVation Protocol (RSVP) working group within the Internet Engineering Task Force (IETF) is developing a protocol for establishing Internet-based integrated services reservations <ref> [179] </ref>. While RSVP defines the core setup protocol, the actual service models and infrastructure are being developed by the Integrated Services working group. Finally, a number of researchers believe that integrated services networks can ultimately be implemented by simply overprovisioning the network. <p> Receivers drop down to the 160x120 resolution when they detect high packet loss rates. The RSVP architecture was designed to explicitly accommodate layered flows using resource reservations <ref> [179] </ref>. Similarly, Heffner proposed the use of layered media streams in tandem with resource reservations [80] in the context of the Tenet Scheme 2 protocol suite [71]. Concurrent with our work, Hoffman and Speer built a system based on the layered multicast architecture [83]. <p> For example, we might distribute the UCB MBone seminar by sending 32 kb/s to the world scope, 128 kb/s to the well-connected MBone, 256 kb/s across our campus network, and 1 Mb/s throughout the department network. PVH can also be used in tandem with the Resource ReserVation Protocol (RSVP) <ref> [179] </ref>, which supports the notion of layered reservations. In this approach, receivers negotiate explicitly with the network for bandwidth by adjusting their reservation to the maximum number of layers that the network can deliver [83].
References-found: 179

