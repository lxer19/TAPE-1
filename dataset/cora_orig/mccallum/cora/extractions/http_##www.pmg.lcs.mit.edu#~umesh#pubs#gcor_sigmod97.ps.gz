URL: http://www.pmg.lcs.mit.edu/~umesh/pubs/gcor_sigmod97.ps.gz
Refering-URL: http://www.pmg.lcs.mit.edu/~umesh/pubs/
Root-URL: 
Email: umesh@lcs.mit.edu  liskov@lcs.mit.edu  
Title: Partitioned Garbage Collection of a Large Object Store  
Author: Umesh Maheshwari Barbara Liskov 
Keyword: garbage collection, partitions, cyclic garbage, object database  
Affiliation: Lab for Computer Science at MIT  Lab for Computer Science at MIT  
Abstract: We present new techniques for efficient garbage collection in a large persistent object store. The store is divided into partitions that are collected independently using information about inter-partition references. This information is maintained on disk so that it can be recovered after a crash. We use new techniques to organize and update this information while avoiding disk accesses. We also present a new global marking scheme to collect cyclic garbage across partitions. Global marking is piggybacked on partitioned collection; the result is an efficient scheme that preserves the localized nature of partitioned collection, yet is able to collect all garbage. We have implemented the part of garbage collection responsible for maintaining information about inter-partition references. We present a performance study to evaluate this work; the results show that our techniques result in substantial savings in the usage of disk and memory. 
Abstract-found: 1
Intro-found: 1
Reference: [AFFS95] <author> L. Amsaleg, P. Ferreira, M. Franklin, and M. Shapiro. </author> <title> Evaluating garbage collection for large persistent stores. </title> <booktitle> In Addendum to Proc. 1995 OOPSLA Workshop on Object Database Behavior. </booktitle> <publisher> ACM Press, </publisher> <year> 1995. </year>
Reference-contexts: We have not yet implemented crash recovery and the actions needed on truncating the stable log. In our experiments, however, we accounted for the expected log overhead from these actions. 5.3 Workload Amsaleg et al. pointed out the lack of a standard benchmark for database garbage collectors <ref> [AFFS95] </ref>; such a benchmark remains absent today. Therefore, we designed a micro-benchmark specifically for evaluating the overhead of maintaining inter-partition reference information. The benchmark database consists of a homogenous collection of small objects, each of which has a single reference and some data fields.
Reference: [AGF95] <author> L. Amsaleg, O. Gruber, and M. Franklin. </author> <title> Efficient incremental garbage collection for workstation-server database systems. </title> <booktitle> In Proc. 21st VLDB. </booktitle> <publisher> ACM Press, </publisher> <year> 1995. </year>
Reference-contexts: Schemes that trace the entire heap [Bak78, KW93, ONG93] do not scale to very large heaps because the nonlocal nature of tracing causes random disk accesses. Therefore, large systems partition the heap into independently collectible areas <ref> [Bis77, YNY94, AGF95, MMH96, CKWZ96] </ref>. This is also the approach taken in many distributed systems [LQP92, LL92, ML94, FS96]. <p> While increasing the partition size reduces the number of inter-partition references, previous studies have shown that tracing very large partitions slows down the collector and the applications due to increased contention for the cache and disk <ref> [AGF95] </ref>. Second, if the information about inter-partition references is not persistent, recomputing it after a crash would take a very long time. Maintaining the information persistently requires care in keeping the disk utilization low, both for the garbage collector to perform well and, more importantly, to avoid degrading application performance. <p> We assume logical names are used to refer to objects. Such names are common in objects stores; for example, in Thor and EXODUS, each page provides logical names for its objects by mapping an object's index to the object's location in the page <ref> [AGF95, LAC + 96] </ref>. Our scheme could also be used in systems that store memory addresses in objects, but in that case it would need to store more information to allow compaction. 3 Partitioned Collection The garbage collector divides the heap into partitions for separate collection. <p> We also record information about outgoing references from a partition in an outlist. The outlist isn't necessary but it allows efficient removal of references from inlists. The scheme by Amsaleg et al. has no outlists <ref> [AGF95] </ref>; after collecting a partition P , untraced inter-partition references from P must be removed by scanning inlists of other partitions. <p> Tracing Scheme. Our approach can be used in combination with various concurrent collectors. For example, we could use a replicating collector [ONG93]. Such a scheme requires little synchronization with applications, but needs space for two partitions in primary memory. A mark-and-sweep collector can be used as well, as in <ref> [AGF95] </ref>. The sweep phase can compact one page at a time, either by locking the page from applications and sliding objects, or by making a new copy of the page and updating the page table to point to it. <p> They used remembered sets that recorded the objects containing inter-partition references, which had to be fetched and scanned before tracing a partition. Amsaleg et al. designed a partitioned collector for a transactional, client-server database <ref> [AGF95] </ref>. Their work focuses on supporting transactional mechanisms such as rollback. The collector uses the log to process inter-partition references in modified objects; the authors point out the need for efficient maintenance of stable inlists.
Reference: [Bak78] <author> H. G. Baker. </author> <title> List processing in real-time on a serial computer. </title> <journal> CACM, </journal> <volume> 21(4) </volume> <pages> 280-94, </pages> <year> 1978. </year>
Reference-contexts: In these systems, the heap resides on the disk because it is much larger than the primary memory and must be recoverable after a crash. Applications access the objects through a memory cache and log updates for crash recovery. Schemes that trace the entire heap <ref> [Bak78, KW93, ONG93] </ref> do not scale to very large heaps because the nonlocal nature of tracing causes random disk accesses. Therefore, large systems partition the heap into independently collectible areas [Bis77, YNY94, AGF95, MMH96, CKWZ96]. This is also the approach taken in many distributed systems [LQP92, LL92, ML94, FS96].
Reference: [Bak93] <author> H. G. Baker. </author> <title> `Infant mortality' and generational garbage collection. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 28(4), </volume> <year> 1993. </year>
Reference-contexts: ages of ob This research was supported in part by the Advanced Research Projects Agency of the Department of Defense, monitored by the Office of Naval Research under contract N00014-91-J-4136. jects to optimize the collection of younger, smaller partitions [Ung84]; however, the age-based heuristics are not useful in persistent stores <ref> [Bak93] </ref>. To trace a partition independently of the others, one must remember references to its objects from other partitions and use them as roots. This introduces two problems. One is performance: maintaining information about inter-partition references has a space and time overhead.
Reference: [Bis77] <author> P. B. Bishop. </author> <title> Computer systems with a very large address space and garbage collection. </title> <type> Technical Report MIT/LCS/TR-178, </type> <institution> MIT, </institution> <year> 1977. </year>
Reference-contexts: Schemes that trace the entire heap [Bak78, KW93, ONG93] do not scale to very large heaps because the nonlocal nature of tracing causes random disk accesses. Therefore, large systems partition the heap into independently collectible areas <ref> [Bis77, YNY94, AGF95, MMH96, CKWZ96] </ref>. This is also the approach taken in many distributed systems [LQP92, LL92, ML94, FS96]. <p> Therefore, we relate our work to systems with large heaps as well as large distributed systems. Bishop first proposed dividing a large address space into independently collectible partitions <ref> [Bis77] </ref>. He proposed collecting cyclic garbage by migrating objects to partitions that reference them. Migration is also used in some distributed systems because it is fault tolerant and decentralized [SGP90, ML95]. The cost of migration is copying objects and patching up the references to the moved objects.
Reference: [CKWZ96] <author> J. E. Cook, A. W. Klauser, A. L. Wolf, and B. G. Zorn. </author> <title> Semi-automatic, self-adaptive control of garbage collection rates in object databases. </title> <booktitle> In Proc. 1996 SIGMOD. </booktitle> <publisher> ACM Press, </publisher> <year> 1996. </year>
Reference-contexts: Schemes that trace the entire heap [Bak78, KW93, ONG93] do not scale to very large heaps because the nonlocal nature of tracing causes random disk accesses. Therefore, large systems partition the heap into independently collectible areas <ref> [Bis77, YNY94, AGF95, MMH96, CKWZ96] </ref>. This is also the approach taken in many distributed systems [LQP92, LL92, ML94, FS96].
Reference: [CWZ94] <author> J. E. Cook, A. L. Wolf, and B. G. Zorn. </author> <title> Partition selection policies in object databases garbage collection. </title> <booktitle> In Proc. 1994 SIGMOD. </booktitle> <publisher> ACM Press, </publisher> <year> 1994. </year>
Reference-contexts: addition if a new translist is created, we enter it in the appropriate inlist and outlist and write them to the log. 3.3 Collecting a Partition Any policy may be used to select partitions for collection. (Cook et al. showed that it is desirable to be flexible in selecting partitions <ref> [CWZ94] </ref>.) To trace a partition, we load its pages into the cache; this is possible since a partition is a small fraction of the cache. We also process the log completely to find all new references to the partition. Roots. We include the following in the root set: 1. <p> Therefore termination is guaranteed even if applications are continually creating and modifying objects. Termination does require that any unmarked partition be traced eventually, but the relative frequency of tracing various partitions can still be governed by an independent policy, as recommended by Cook el al. <ref> [CWZ94] </ref>. Although global marking is guaranteed to terminate, it is difficult to estimate a practical bound on the number of traces it would take in the presence of concurrent mutations. We can estimate the length of a marking phase by assuming that applications are quiescent, that is, not modifying objects.
Reference: [FS96] <author> P. Ferreira and M. Shapiro. Larchant: </author> <title> Persistence by reach-ability in distributed shared memory through garbage collection. </title> <booktitle> In Proc. 16th ICDCS, </booktitle> <year> 1996. </year>
Reference-contexts: Therefore, large systems partition the heap into independently collectible areas [Bis77, YNY94, AGF95, MMH96, CKWZ96]. This is also the approach taken in many distributed systems <ref> [LQP92, LL92, ML94, FS96] </ref>. <p> Although the scheme avoids unnecessary migration, it still requires patching up references to the moved objects. Ferriera and Shapiro designed a collector for a distributed shared memory system that caches replicas of data segments <ref> [FS96] </ref>. Each segment has an inlist and outlist, and segments cached at the same node can be grouped to form a unit of tracing. However, such a group may not contain all of a garbage cycle.
Reference: [Ghe95] <author> S. Ghemawat. </author> <title> The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1995. </year>
Reference-contexts: Objects are accessed within transactions that run at the clients; at commit, copies of modified objects are sent back to the servers. The server stores modified objects in a memory-resident log and installs them into disk pages in the background <ref> [Ghe95] </ref>. Log stability is intended to be accomplished through replication [LGG + 91], but in our experiments we simulate delays for log forces as if the log were stored on a logging disk, separate from the database disk.
Reference: [HM92] <author> R. L. Hudson and J. E. B. Moss. </author> <title> Incremental garbage collection for mature objects. </title> <booktitle> In Proc. IWMM, volume 637 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: In PMOS, by Moss et al., the outlist is computed whenever a page is fetched and also when a modified page is evicted, and the differences are applied to the inlists <ref> [HM92, MMH96] </ref>. We share information between inlists and outlists in translists: a translist from P to Q records the set of references contained in partition P to objects in another partition Q. <p> For a compound cycle such as a doubly-linked list to be collected, all component cycles must be cached for any to be collected. None of the above works addresses efficient maintenance of inter-partition references. The only previous work that addresses this issue is PMOS by Moss et al. <ref> [HM92, MMH96] </ref>. PMOS collects one page at a time; a page is the unit of both fetching and tracing. Each page has an inlist that identifies the source pages for each incoming reference.
Reference: [Hug85] <author> R. J. M. Hughes. </author> <title> A distributed garbage collection algorithm. </title> <booktitle> In Proc. 1985 FPCA, volume 201 of Lecture Notes in Computer Science, </booktitle> <pages> pages 256-272. </pages> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: As in previous schemes, global marking can take a long time to terminate, but that is acceptable assuming cyclic garbage spanning partitions is generated slowly. Previous proposals for using global marking with partitioned collection either delay the collection of acyclic garbage <ref> [Hug85] </ref>, or need to run separate traces for global marking and partitioned collection [JJ92], or are not guaranteed to terminate correctly in the presence of modifications [LQP92]. <p> Previous marking schemes either propagate global marks separately from regular partition traces [JJ92], or delay the collection of acyclic inter-partition garbage <ref> [Hug85] </ref>, or are not guaranteed to terminate correctly in the presence of concurrent mutations [LQP92]. 4.1 Data Structures Each partition has a markmap, which contains a mark bit per object. <p> Rule 3. Every time we unmark a partition, we mark at least one of its unmarked objects. In fact, we keep a mark bit per object expressly to guarantee termination by enforcing these rules. Otherwise, mark bits for just the inter-partition references would suffice, as in <ref> [Hug85, LQP92] </ref>. 4.3 Starting a Phase When a phase starts, only the persistent root is marked. The partition containing the persistent root is unmarked and the rest are marked. This satisfies Invariant 1. We perform these actions incrementally as follows.
Reference: [JJ92] <author> N.-C. Juul and E. </author> <month> Jul. </month> <title> Comprehensive and robust garbage collection in a distributed system. </title> <booktitle> In Proc. IWMM, volume 637 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Previous proposals for using global marking with partitioned collection either delay the collection of acyclic garbage [Hug85], or need to run separate traces for global marking and partitioned collection <ref> [JJ92] </ref>, or are not guaranteed to terminate correctly in the presence of modifications [LQP92]. We have implemented the part of garbage collection responsible for maintaining information about inter-partition references in the context of Thor, an object database [LAC + 96]. <p> The scheme has little time and space overhead and does not delay the collection of acyclic garbage; as in partitioned collection, we organize the collector information to use the disk efficiently. Previous marking schemes either propagate global marks separately from regular partition traces <ref> [JJ92] </ref>, or delay the collection of acyclic inter-partition garbage [Hug85], or are not guaranteed to terminate correctly in the presence of concurrent mutations [LQP92]. 4.1 Data Structures Each partition has a markmap, which contains a mark bit per object. <p> It is unclear whether such a scheme has any advantage over global marking when partitions are collected sequentially. Juul and Jul designed a distributed collector with both partitioned collection and global marking <ref> [JJ92] </ref>. The scheme relies on global marking to remove unnecessary inlist references, whether or not they form an inter-partition garbage cycle. Global marking is not piggybacked on partition traces and is conducted separately.
Reference: [KW93] <author> E. K. Kolodner and W. E. Weihl. </author> <title> Atomic incremental garbage collection and recovery for large stable heap. </title> <booktitle> In Proc. 1993 SIGMOD, </booktitle> <pages> pages 177-186, </pages> <year> 1993. </year>
Reference-contexts: In these systems, the heap resides on the disk because it is much larger than the primary memory and must be recoverable after a crash. Applications access the objects through a memory cache and log updates for crash recovery. Schemes that trace the entire heap <ref> [Bak78, KW93, ONG93] </ref> do not scale to very large heaps because the nonlocal nature of tracing causes random disk accesses. Therefore, large systems partition the heap into independently collectible areas [Bis77, YNY94, AGF95, MMH96, CKWZ96]. This is also the approach taken in many distributed systems [LQP92, LL92, ML94, FS96]. <p> Only inlist and outlist references need mark bits. However, the scheme does not elaborate on concurrent execution with the mutator, and we believe that it would fail to terminate correctly in the presence of concurrent mutations. Kolodner proposed recoverable collection of a large heap using unpartitioned but incremental copying <ref> [KW93] </ref>. Like other unpartitioned schemes, this collector must make random accesses in the old space. O'Toole et al. proposed concurrent copying of a persistent heap by letting applications access the old space while the collector copies it to new space [ONG93].
Reference: [LAC + 96] <author> B. Liskov, A. Adya, M. Castro, M. Day, S. Ghemawat, R. Gruber, U. Maheshwari, A. Myers, and L. Shrira. </author> <title> Safe and efficient sharing of persistent objects in Thor. </title> <booktitle> In Proc. 1996 SIGMOD, </booktitle> <pages> pages 318-329. </pages> <publisher> ACM Press, </publisher> <year> 1996. </year>
Reference-contexts: We have implemented the part of garbage collection responsible for maintaining information about inter-partition references in the context of Thor, an object database <ref> [LAC + 96] </ref>. We present a performance study to evaluate this work; the results show that our techniques result in substantial savings in the usage of disk and memory. The remainder of the paper is organized as follows. Section 2 describes the system model. <p> We assume logical names are used to refer to objects. Such names are common in objects stores; for example, in Thor and EXODUS, each page provides logical names for its objects by mapping an object's index to the object's location in the page <ref> [AGF95, LAC + 96] </ref>. Our scheme could also be used in systems that store memory addresses in objects, but in that case it would need to store more information to allow compaction. 3 Partitioned Collection The garbage collector divides the heap into partitions for separate collection. <p> The global phase counter is stably updated when a phase terminates. The phase counters of partitions are stably updated when they are first traced in a new phase. 5 Performance We are implementing partitioned garbage collection in Thor, an object database <ref> [LAC + 96] </ref>. This section describes some details of the implementation and then presents some experiments to evaluate our technique for maintaining information about inter-partition references.
Reference: [LGG + 91] <author> B. Liskov, S. Ghemawat, R. Gruber, P. Johnson, L. Shrira, and M. Williams. </author> <title> Replication in the Harp file system. </title> <booktitle> In Proc. SOSP, </booktitle> <pages> pages 226-238. </pages> <publisher> ACM Press, </publisher> <year> 1991. </year>
Reference-contexts: The server stores modified objects in a memory-resident log and installs them into disk pages in the background [Ghe95]. Log stability is intended to be accomplished through replication <ref> [LGG + 91] </ref>, but in our experiments we simulate delays for log forces as if the log were stored on a logging disk, separate from the database disk.
Reference: [LL92] <author> R. Ladin and B. Liskov. </author> <title> Garbage collection of a distributed heap. </title> <booktitle> In Proc. International Conference on Distributed Computing Systems. </booktitle> <publisher> IEEE Press, </publisher> <year> 1992. </year>
Reference-contexts: Therefore, large systems partition the heap into independently collectible areas [Bis77, YNY94, AGF95, MMH96, CKWZ96]. This is also the approach taken in many distributed systems <ref> [LQP92, LL92, ML94, FS96] </ref>.
Reference: [LMN96] <author> B. Liskov, U. Maheshwari, and T. Ng. </author> <title> Partitioned garbage collection of a large stable heap. </title> <booktitle> In Proc. IWOOOS, </booktitle> <year> 1996. </year>
Reference-contexts: Sharing translists between inlists and outlists provides significant advantages. Without translists, inlists and outlist would store redundant information, resulting in higher overheads and complexity. Our previous scheme did not use translists and as a result the system invariants were more complex than they are now <ref> [Ng96, LMN96] </ref>. Additionally, the new scheme provides compact storage. Inlists and out-lists use two words per translist, and translists use one word per hsource-partition, referencei pair.
Reference: [LQP92] <author> B. Lang, C. Queinniec, and J. Piquer. </author> <title> Garbage collecting the world. </title> <booktitle> In Proc. POPL '92, </booktitle> <pages> pages 39-50. </pages> <publisher> ACM Press, </publisher> <year> 1992. </year>
Reference-contexts: Therefore, large systems partition the heap into independently collectible areas [Bis77, YNY94, AGF95, MMH96, CKWZ96]. This is also the approach taken in many distributed systems <ref> [LQP92, LL92, ML94, FS96] </ref>. <p> Previous proposals for using global marking with partitioned collection either delay the collection of acyclic garbage [Hug85], or need to run separate traces for global marking and partitioned collection [JJ92], or are not guaranteed to terminate correctly in the presence of modifications <ref> [LQP92] </ref>. We have implemented the part of garbage collection responsible for maintaining information about inter-partition references in the context of Thor, an object database [LAC + 96]. <p> Previous marking schemes either propagate global marks separately from regular partition traces [JJ92], or delay the collection of acyclic inter-partition garbage [Hug85], or are not guaranteed to terminate correctly in the presence of concurrent mutations <ref> [LQP92] </ref>. 4.1 Data Structures Each partition has a markmap, which contains a mark bit per object. The markmap is implemented as a set of bitmaps, one per page in the partition; each bitmap contains a bit per potential object name in the page. <p> Rule 3. Every time we unmark a partition, we mark at least one of its unmarked objects. In fact, we keep a mark bit per object expressly to guarantee termination by enforcing these rules. Otherwise, mark bits for just the inter-partition references would suffice, as in <ref> [Hug85, LQP92] </ref>. 4.3 Starting a Phase When a phase starts, only the persistent root is marked. The partition containing the persistent root is unmarked and the rest are marked. This satisfies Invariant 1. We perform these actions incrementally as follows. <p> Global marking is not piggybacked on partition traces and is conducted separately. Lang et al. proposed marking within a selected group of partitions to collect inter-partition cyclic garbage contained in the group <ref> [LQP92] </ref>. Marking is piggybacked on partition traces as in our scheme and comprises a marked trace followed by an unmarked trace. Only inlist and outlist references need mark bits.
Reference: [ML94] <author> U. Maheshwari and B. Liskov. </author> <title> Fault-tolerant distributed garbage collection in a client-server object-oriented database. </title> <booktitle> In Proc. 3rd Parallel and Distributed Information Systems. </booktitle> <publisher> IEEE Press, </publisher> <year> 1994. </year>
Reference-contexts: Therefore, large systems partition the heap into independently collectible areas [Bis77, YNY94, AGF95, MMH96, CKWZ96]. This is also the approach taken in many distributed systems <ref> [LQP92, LL92, ML94, FS96] </ref>. <p> The task of garbage collection in Thor is distributed across servers and clients <ref> [ML94, ML95] </ref>, but this paper pertains to garbage collection within a single server. 5.2 Implementation Work related to garbage collection is performed by a collector thread, which is run at low priority to avoid delaying application requests. The collector scans modified and new objects in the log for inter-partition references.
Reference: [ML95] <author> U. Maheshwari and B. Liskov. </author> <title> Collecting cyclic distributed garbage by controlled migration. </title> <booktitle> In Proceedings of PODC'95 Principles of Distributed Computing, </booktitle> <pages> pages 57-63, </pages> <year> 1995. </year>
Reference-contexts: The task of garbage collection in Thor is distributed across servers and clients <ref> [ML94, ML95] </ref>, but this paper pertains to garbage collection within a single server. 5.2 Implementation Work related to garbage collection is performed by a collector thread, which is run at low priority to avoid delaying application requests. The collector scans modified and new objects in the log for inter-partition references. <p> Bishop first proposed dividing a large address space into independently collectible partitions [Bis77]. He proposed collecting cyclic garbage by migrating objects to partitions that reference them. Migration is also used in some distributed systems because it is fault tolerant and decentralized <ref> [SGP90, ML95] </ref>. The cost of migration is copying objects and patching up the references to the moved objects. Hughes's algorithm, also designed for distributed systems, propagates timestamps from inlists to outlists and collects objects timestamped below a certain global threshold. <p> The collector uses the log to process inter-partition references in modified objects; the authors point out the need for efficient maintenance of stable inlists. Maheshwari and Liskov proposed identifying objects that are highly likely to be cyclic garbage and migrating them <ref> [ML95] </ref>. An object is suspected to be cyclic garbage if it has a large distance: The distance of an object is the minimum number of inter-partition references on any path from a persistent root to that object.
Reference: [MMH96] <author> J. E. B. Moss, D. S. Munro, and R. L. Hudson. Pmos: </author> <title> A complete and coarse-grained incremental garbage collector for persistent object stores. </title> <booktitle> In Proc. 7th Workshop on Persistent Object Systems, </booktitle> <year> 1996. </year>
Reference-contexts: Schemes that trace the entire heap [Bak78, KW93, ONG93] do not scale to very large heaps because the nonlocal nature of tracing causes random disk accesses. Therefore, large systems partition the heap into independently collectible areas <ref> [Bis77, YNY94, AGF95, MMH96, CKWZ96] </ref>. This is also the approach taken in many distributed systems [LQP92, LL92, ML94, FS96]. <p> Disk accesses for updating this information are deferred and batched. 3. Reading objects from the disk and evicting them from the cache do not require processing this information. 4. The information is compact yet efficiently usable. One other scheme, PMOS <ref> [MMH96] </ref>, batches disk accesses for inter-partition information; however, PMOS processes information and scans objects whenever they are fetched or evicted, which would slow down applications. We also describe a new global marking scheme that collects cyclic garbage across partitions. <p> In PMOS, by Moss et al., the outlist is computed whenever a page is fetched and also when a modified page is evicted, and the differences are applied to the inlists <ref> [HM92, MMH96] </ref>. We share information between inlists and outlists in translists: a translist from P to Q records the set of references contained in partition P to objects in another partition Q. <p> For a compound cycle such as a doubly-linked list to be collected, all component cycles must be cached for any to be collected. None of the above works addresses efficient maintenance of inter-partition references. The only previous work that addresses this issue is PMOS by Moss et al. <ref> [HM92, MMH96] </ref>. PMOS collects one page at a time; a page is the unit of both fetching and tracing. Each page has an inlist that identifies the source pages for each incoming reference.
Reference: [Ng96] <author> T. Ng. </author> <title> Efficient garbage collection for large object-oriented databases. </title> <type> Technical Report MIT/LCS/TR-692, </type> <institution> MIT LCS, </institution> <year> 1996. </year>
Reference-contexts: Sharing translists between inlists and outlists provides significant advantages. Without translists, inlists and outlist would store redundant information, resulting in higher overheads and complexity. Our previous scheme did not use translists and as a result the system invariants were more complex than they are now <ref> [Ng96, LMN96] </ref>. Additionally, the new scheme provides compact storage. Inlists and out-lists use two words per translist, and translists use one word per hsource-partition, referencei pair.
Reference: [ONG93] <author> J. W. O'Toole, S. M. Nettles, and D. Gifford. </author> <title> Concurrent compacting garbage collection of a persistent heap. </title> <booktitle> In Proc. 14th SOSP, </booktitle> <pages> pages 161-174, </pages> <year> 1993. </year>
Reference-contexts: In these systems, the heap resides on the disk because it is much larger than the primary memory and must be recoverable after a crash. Applications access the objects through a memory cache and log updates for crash recovery. Schemes that trace the entire heap <ref> [Bak78, KW93, ONG93] </ref> do not scale to very large heaps because the nonlocal nature of tracing causes random disk accesses. Therefore, large systems partition the heap into independently collectible areas [Bis77, YNY94, AGF95, MMH96, CKWZ96]. This is also the approach taken in many distributed systems [LQP92, LL92, ML94, FS96]. <p> However, such mechanisms add substantial cost and complexity in a disk-based heap. Tracing Scheme. Our approach can be used in combination with various concurrent collectors. For example, we could use a replicating collector <ref> [ONG93] </ref>. Such a scheme requires little synchronization with applications, but needs space for two partitions in primary memory. A mark-and-sweep collector can be used as well, as in [AGF95]. <p> Like other unpartitioned schemes, this collector must make random accesses in the old space. O'Toole et al. proposed concurrent copying of a persistent heap by letting applications access the old space while the collector copies it to new space <ref> [ONG93] </ref>. The collector picks up the modifications made by applications by using an update log. The scheme was designed for an unpartitioned heap that fit in the primary memory.
Reference: [SGP90] <author> M. Shapiro, O. Gruber, and D. Plainfoss e. </author> <title> A garbage detection protocol for a realistic distributed object-support system. </title> <institution> Rapports de Recherche 1320, INRIA-Rocquencourt, </institution> <year> 1990. </year>
Reference-contexts: Bishop first proposed dividing a large address space into independently collectible partitions [Bis77]. He proposed collecting cyclic garbage by migrating objects to partitions that reference them. Migration is also used in some distributed systems because it is fault tolerant and decentralized <ref> [SGP90, ML95] </ref>. The cost of migration is copying objects and patching up the references to the moved objects. Hughes's algorithm, also designed for distributed systems, propagates timestamps from inlists to outlists and collects objects timestamped below a certain global threshold.
Reference: [Sob88] <author> P. Sobalvarro. </author> <title> A lifetime-based garbage collector for Lisp systems on general-purpose computers. </title> <type> Technical Report AITR-1417, </type> <institution> MIT, AI Lab, </institution> <year> 1988. </year>
Reference-contexts: Additionally, the new scheme provides compact storage. Inlists and out-lists use two words per translist, and translists use one word per hsource-partition, referencei pair. The remembered sets used in some generational collectors record the locationsat the level of a word, object, or page that may contain inter-partition references <ref> [Ung84, Sob88] </ref>. This scheme is not suitable for disk-based heaps because tracing a partition requires examining locations in other partitions. Further, storing locations at a fine granularity results in more information if multiple locations contain the same reference.
Reference: [Ung84] <author> D. M. Ungar. </author> <title> Generation scavenging: A non-disruptive high performance storage reclamation algorithm. </title> <journal> ACM SIG-PLAN Notices, </journal> <volume> 19(5) </volume> <pages> 157-167, </pages> <year> 1984. </year>
Reference-contexts: Generational collectors are a variant of partitioned collection that use the ages of ob This research was supported in part by the Advanced Research Projects Agency of the Department of Defense, monitored by the Office of Naval Research under contract N00014-91-J-4136. jects to optimize the collection of younger, smaller partitions <ref> [Ung84] </ref>; however, the age-based heuristics are not useful in persistent stores [Bak93]. To trace a partition independently of the others, one must remember references to its objects from other partitions and use them as roots. This introduces two problems. <p> Additionally, the new scheme provides compact storage. Inlists and out-lists use two words per translist, and translists use one word per hsource-partition, referencei pair. The remembered sets used in some generational collectors record the locationsat the level of a word, object, or page that may contain inter-partition references <ref> [Ung84, Sob88] </ref>. This scheme is not suitable for disk-based heaps because tracing a partition requires examining locations in other partitions. Further, storing locations at a fine granularity results in more information if multiple locations contain the same reference.
Reference: [YNY94] <author> V. Yong, J. Naughton, and J. Yu. </author> <title> Storage reclamation and reorganization in clinet-server persistent object stores. </title> <booktitle> In Proc. Data Engineering, </booktitle> <pages> pages 120-133. </pages> <publisher> IEEE Press, </publisher> <year> 1994. </year>
Reference-contexts: Schemes that trace the entire heap [Bak78, KW93, ONG93] do not scale to very large heaps because the nonlocal nature of tracing causes random disk accesses. Therefore, large systems partition the heap into independently collectible areas <ref> [Bis77, YNY94, AGF95, MMH96, CKWZ96] </ref>. This is also the approach taken in many distributed systems [LQP92, LL92, ML94, FS96]. <p> The scheme was designed for an unpartitioned heap that fit in the primary memory. Yong et al. compared incremental copying, reference counting, and partitioned collection in a client-server object store and found partitioned collection to perform the best <ref> [YNY94] </ref>. They used remembered sets that recorded the objects containing inter-partition references, which had to be fetched and scanned before tracing a partition. Amsaleg et al. designed a partitioned collector for a transactional, client-server database [AGF95]. Their work focuses on supporting transactional mechanisms such as rollback.
References-found: 27

