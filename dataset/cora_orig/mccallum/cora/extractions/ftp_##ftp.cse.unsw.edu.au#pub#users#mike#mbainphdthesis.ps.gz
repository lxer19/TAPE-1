URL: ftp://ftp.cse.unsw.edu.au/pub/users/mike/mbainphdthesis.ps.gz
Refering-URL: http://www.ai.univie.ac.at/~juffi/lig/lig-bib.html
Root-URL: 
Title: LEARNING LOGICAL EXCEPTIONS IN CHESS  
Author: Michael Bain 
Degree: a dissertation submitted to the  and the committee for  in partial fulfillment of the requirements for the degree of doctor of philosophy By  
Date: 1994  
Affiliation: department of statistics and modelling science  postgraduate studies of the University of Strathclyde, Glasgow,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. Altman, A. Cheng, and S. Galeota. AQ11: </author> <title> Experiments and Evaluation. </title> <type> C.S. 397, </type> <institution> 1979. University of Illinois at Urbana Champaign. </institution>
Reference: [2] <author> D. Angluin and C. H. Smith. </author> <title> A survey of inductive inference: theory and methods. </title> <journal> Computing Surveys, </journal> <volume> 15(3) </volume> <pages> 237-269, </pages> <year> 1983. </year>
Reference: [3] <author> M. Bain. </author> <title> Experiments in non-monotonic learning. </title> <editor> In L. Birnbaum and G. Collins, editors, </editor> <booktitle> Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 380-384, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: The induction of a 100% correct solution for KRK illegality presented in this chapter was dependent not solely on efficient generalisation using a first-order hypothesis language, but additionally on its combination with a method of minimal specialisation. To our knowledge the original publication of this result <ref> [3] </ref> was the first time a complete and correct solution to this standard problem had been recorded by an incremental learning system. This advance was possible due to efficient generalisation in a first-order hypothesis language, and minimal specialisation in a non-monotonic framework. <p> These are preceded in Section 7.2 by a review of the database of positions used in this work, and followed by a discussion of some relations to other work in Section 7.5. 7.2 Materials In previous work <ref> [123, 80, 85, 3] </ref> chess endgame databases have been used as sources of training and testing examples for machine learning experiments. The current work employs an exhaustive database which is a complete tabulation for the KRK endgame. The entries of this database contain optimal depth-to-win values for all positions. <p> The novelty of the present approach lies in the application of relational learning using RLGG as implemented in GOLEM coupled with specialisation techniques based on predicate invention. This follows from earlier results with a similar approach in the simpler KRK illegality domain <ref> [3] </ref>. 2 Not including background predicates. CHAPTER 7.
Reference: [4] <author> M. Bain. </author> <title> Learning optimal chess strategies. </title> <editor> In S. Muggleton, editor, </editor> <booktitle> ILP 92: Proc. Intl. Workshop on Inductive Logic Programming, volume ICOT TM-1182. </booktitle> <institution> Institute for New Generation Computer Technology, </institution> <address> Tokyo, Japan, </address> <year> 1992. </year>
Reference: [5] <author> M. Bain and S. H. Muggleton. </author> <title> Non-monotonic learning. </title> <editor> In J. E. Hayes, D. Michie, and E. Tyugu, editors, </editor> <booktitle> Machine Intelligence 12, </booktitle> <pages> pages 105-119. </pages> <publisher> Oxford University Press, Oxford, </publisher> <year> 1991. </year>
Reference: [6] <author> F. Bergadano and A. Giordana. </author> <title> A knowledge intensive approach to concept induction. </title> <booktitle> In ML-88: Proc. of the Fifth Intl. Conference on Machine Learning, </booktitle> <pages> pages 305-317, </pages> <address> San Mateo, CA, 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This system does not appear to avoid possible over-specialisation. Other systems that carry out intermediate operationalization steps include FOCL [97] and ML-SMART <ref> [6] </ref>. Minimal specialisation according to our definitions is not reported for the above theory revision systems. A proposal to use criteria other than minimal specialisation for theory revision has recently been made by Wrobel [142].
Reference: [7] <author> H. J. Berliner and M. Campbell. </author> <title> Using chunking to play chess pawn end-games. </title> <journal> Artificial Intelligence, </journal> <volume> 23 </volume> <pages> 97-120, </pages> <year> 1984. </year> <note> 183 BIBLIOGRAPHY 184 </note>
Reference: [8] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. </author> <title> Occam's Razor. </title> <type> Technical Report UCSC-CRL-86-2, </type> <institution> Computer Research Laboratory, University of California at Santa Cruz, </institution> <year> 1986. </year>
Reference: [9] <author> I. Bratko. </author> <title> Prolog Programming for Artificial Intelligence. </title> <publisher> Addison-Wesley, </publisher> <address> Wokingham, </address> <year> 1990. </year>
Reference-contexts: EXPERIMENTS IN NON-MONOTONIC LEARNING 114 of KRK illegality. NM-CIGOL is CIGOL plus the CWS algorithm presented in Chapter 5. To illustrate the operation of NM-CIGOL compared with CIGOL we give below two partial traces of their interactive usage. The instance and hypothesis language is a subset of "Edinburgh" Prolog <ref> [9] </ref>. Both systems were implemented in Prolog and in the following execution traces were invoked from within the Prolog interpreter. User input is shown in a bold font and system output in a typewriter font.
Reference: [10] <author> I. Bratko, I. Mozetic, and N. Lavrac. KARDIO: </author> <title> a study in deep and qualitative knowledge for expert systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1989. </year>
Reference-contexts: These initial results in chess endgame domains led to a variety of successful applications. The landmark KARDIO system used a deep model of the heart to synthesise shallow rules for ECG interpretation <ref> [10] </ref>. Among the rules which came out of this study were some previously undiscovered in over 200 years of cardiology. This route was also taken in an application to satellite fault diagnosis [98].
Reference: [11] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Belmont, </address> <year> 1984. </year>
Reference: [12] <author> A. Bundy, B. Silver, and D. Plummer. </author> <title> An analytical comparison of some rule-learning programs. </title> <journal> Artificial Intelligence, </journal> <volume> 27 </volume> <pages> 137-181, </pages> <year> 1985. </year>
Reference: [13] <author> W. Buntine. </author> <title> Generalised subsumption and its applications to induction and redundancy. </title> <journal> Artificial Intelligence, </journal> <volume> 36(2) </volume> <pages> 149-176, </pages> <year> 1988. </year>
Reference: [14] <author> W. L. Buntine. </author> <title> A Theory of Learning Classification Rules. </title> <type> PhD thesis, </type> <institution> University of Sydney, </institution> <year> 1992. </year>
Reference-contexts: The rand subset function therefore implements a form of theory-guided sampling 1 . This is related to Quinlan's technique of windowing as used in ID3 and its derivatives [106], and stratified sampling <ref> [14] </ref>. 6.2.2 Results The working hypothesis was that NM-CIGOL would improve on the initial theory. Recall that this initial theory was found to give the maximum performance in Experiment 1a of Chapter 4, recording 91.4% predictive accuracy.
Reference: [15] <author> J. G. Carbonell, R. S. Michalski, and T. M. Mitchell. </author> <title> An Overview of Machine Learning. </title> <editor> In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning, </booktitle> <volume> volume 1, </volume> <pages> pages 3-23. </pages> <publisher> Tioga, </publisher> <address> Palo Alto, CA., </address> <year> 1983. </year>
Reference: [16] <author> B. Cestnik, I. Kononenko, and I. Bratko. </author> <title> ASSISTANT 86: a knowledge-elicitation tool for sophisticated users. </title> <booktitle> In Progress in Machine Learning, </booktitle> <pages> pages 31-45, </pages> <address> Wilmslow, England, </address> <year> 1987. </year> <pages> Sigma. </pages>
Reference: [17] <author> G. Chaitin. </author> <title> Information, Randomness and Incompleteness Papers on Algorithmic Information Theory. </title> <publisher> World Scientific Press, </publisher> <address> Singapore, </address> <year> 1987. </year>
Reference-contexts: Although in this thesis the learning data may be assumed to be error-free, our method has elsewhere been augmented with a noise-detection mechanism based on a compression metric using the algorithmic complexity model of induction <ref> [129, 43, 17, 79] </ref>. The results so far from experimental testing of this approach are promising [79].
Reference: [18] <author> C-L. Chang and R. C-T. Lee. </author> <title> Symbolic Logic and Mechanical Theorem Proving. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1973. </year> <note> BIBLIOGRAPHY 185 </note>
Reference-contexts: As such, this marks out the limit of the learning techniques developed in the thesis. Appendix A Definitions A.1 Definitions from logic In this section we give definitions for logical expressions used in this thesis. These are based on those of <ref> [18, 56, 82] </ref>. A.1.1 Formulae in propositional calculus A proposition (propositional variable) is represented by a lower case letter followed by a string of lower case letters and digits. The negation symbol is: :. The binary connectives are: ^, _, !, $. A proposition is an atomic formula, or atom.
Reference: [19] <author> P. Clark and T. Niblett. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3(4) </volume> <pages> 261-283, </pages> <year> 1989. </year>
Reference: [20] <author> M. R. B. Clarke. </author> <title> A Quantitative Study of King and Pawn Against King. </title> <editor> In M. R. B. Clarke, editor, </editor> <booktitle> Advances in Computer Chess, </booktitle> <volume> volume 1, </volume> <pages> pages 108-118. </pages> <publisher> Edinburgh University Press, Edinburgh, </publisher> <year> 1977. </year>
Reference-contexts: That this is so is apparent from a past failed attempt made by unaided human experts to construct by analysis an optimal classifier theory. Clarke <ref> [20] </ref> established (by constructing a database) that, contrary to previously published statements in standard texts, KRK was won for white in a maximum of sixteen moves. 7.4 Induction of complete and correct classi fiers From the results of the previous section it is notable that although complete and in most cases
Reference: [21] <author> W.F. Clocksin and C.S. Mellish. </author> <title> Programming in Prolog. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1981. </year>
Reference: [22] <author> S. Craw and D. Sleeman. </author> <title> The flexibility of speculative refinement. </title> <editor> In L. Birnbaum and G. Collins, editors, ML-91: </editor> <booktitle> Proc. Eighth Intl. Workshop on Machine Learning, </booktitle> <pages> pages 28 - 32, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Also, although he has proposed using negation as failure (NF) and an equality theory to construct a most general specialisation of a set of clauses, this may not give a result which is finitely axiomatisable. Within a finite language, Ling and Valtorta [55] and Craw and Sleeman <ref> [22] </ref> have given results for the complexity of the refinements produced by their systems. However, in both cases the representation is restricted to propositional rules, although Ling and Valtorta have uncertainties attached to the rules.
Reference: [23] <author> R. Dechter and D. Michie. </author> <title> Induction of plans. </title> <type> TIRM 84-006, </type> <institution> The Turing Institute, Glasgow, </institution> <year> 1984. </year>
Reference: [24] <author> N. Dershowitz and Y. Lee. </author> <title> Deductive Debugging. </title> <type> UIUCDCS-F- 87-961, </type> <institution> University of Illinois at Urbana-Champaign, Urbana, IL, </institution> <year> 1987. </year>
Reference-contexts: This approach is shared by many Machine Learning systems, including those discussed in the remainder of this section. It is also a feature of work in automated program debugging which builds on Shapiro's system. Dershowitz and Lee <ref> [24] </ref> describe a debugging system for Pure Prolog which relies on the provision of executable specifications. The specifications, also in Pure Prolog, are assumed to be correct, and are executed to provide test cases which can serve to locate bugs.
Reference: [25] <author> C. Feng. </author> <title> Inducing temporal fault diagnostic rules from a qualitative model. </title> <editor> In S. H. Muggleton, editor, </editor> <booktitle> Inductive Logic Programming, </booktitle> <pages> pages 473-493. </pages> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1992. </year>
Reference-contexts: This route was also taken in an application to satellite fault diagnosis [98]. Most recently, an ILP approach in the same domain allowed the learning of significant temporal relations not expressed in the earlier solution <ref> [25] </ref>. The role of Machine Learning in previous work has focused on database compression. Even with decision tree induction this compression can be significant, as in the KARDIO work, which compressed 5 MBytes of ground descriptions to 30 KBytes of rules.
Reference: [26] <author> S. Gallant. </author> <title> Example-based knowledge engineering with conectionist expert systems. </title> <booktitle> In IEEE Midcon, </booktitle> <month> August 30 - September 1. </month> <institution> Dallas, Texas, </institution> <year> 1988. </year>
Reference: [27] <author> P. Gardenfors. </author> <title> Knowledge in Flux: Modeling the Dynamics of Epistemic States. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: A proposal to use criteria other than minimal specialisation for theory revision has recently been made by Wrobel [142]. This is a formalisation of the exception list method implemented in MODELER, discussed above in Section 5.1.3. The particular criteria he suggests are based on the set of Gardenfors postulates <ref> [27] </ref> for belief revision. Unfortunately this framework depends on a classical logic representation in which belief sets are closed theories. In this representation revisions may not be finitely axiomatis-able, which is similar to the problem illustrated by Example 5.12. <p> Theory Revision. Gardenfors <ref> [27] </ref> has proposed a general theory of updating beliefs. Defeasible reasoning. Pollock [102] has developed a theory of defeasible rea soning and implemented a prototype system. 8.3 Future directions We believe that several important open issues may be identified from the foregoing results.
Reference: [28] <author> M. R. Genesereth and N. J. Nilsson. </author> <booktitle> Logical foundations of artificial intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, </address> <year> 1987. </year> <note> BIBLIOGRAPHY 186 </note>
Reference-contexts: Semantics of Non-monotonic logic. Konolige [44] has proposed partial mod els as a semantics for non-monotonic logic; Przyminski [104] considers semantics of non-monotonic formalism in the framework of general logic programs; Nilsson and Genesereth <ref> [28] </ref> cover many of the essentials of non-monotonic logic in their textbook; Ginsberg [30] has collected many foundational but hard-to-find papers in non-monotonic reasoning (includ ing papers by McCarthy, Lifschitz et al.). Theory Revision. Gardenfors [27] has proposed a general theory of updating beliefs. Defeasible reasoning.
Reference: [29] <author> A. Ginsberg. </author> <title> Theory Revision via Prior Operationalization. </title> <booktitle> In AAAI-88: Proc. Seventh National Conf. on Artificial Intelligence, </booktitle> <pages> pages 590 - 595, </pages> <address> San Mateo, CA, 1988. </address> <publisher> Morgan Kaufmann for AAAI. </publisher>
Reference-contexts: The latter method is based on generating multiple rule refinements and heuristically filtering those considered suitable. Hamakawa [33], working with a propositional Horn-clause representation, points out the problem of over-specialisation and the need for incremental learning. Ginsberg <ref> [29] </ref> provides a frequent reference point for work on theory revision. Again, his system uses a set of heuristic refinement operators and a propositional representation. A number of theory revision systems which are related to our method include those using logic programs as a representation.
Reference: [30] <author> M. Ginsberg. </author> <title> Readings in nonmonotonic reasoning. </title> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1987. </year>
Reference-contexts: Semantics of Non-monotonic logic. Konolige [44] has proposed partial mod els as a semantics for non-monotonic logic; Przyminski [104] considers semantics of non-monotonic formalism in the framework of general logic programs; Nilsson and Genesereth [28] cover many of the essentials of non-monotonic logic in their textbook; Ginsberg <ref> [30] </ref> has collected many foundational but hard-to-find papers in non-monotonic reasoning (includ ing papers by McCarthy, Lifschitz et al.). Theory Revision. Gardenfors [27] has proposed a general theory of updating beliefs. Defeasible reasoning.
Reference: [31] <author> A. Guessoum and J. W. Lloyd. </author> <title> Updating Knowledge Bases. </title> <journal> New Generation Computing, </journal> <volume> 8(1) </volume> <pages> 71-89, </pages> <year> 1990. </year>
Reference-contexts: NON-MONOTONIC LEARNING 109 Wrobel suggests that exception lists may be replaced by invented predicates. However, this would result in a revised theory which no longer meets the base revision postulates. In Logic Programming the problem may be expressed in terms of updating logic databases. For instance, Guessoum and Lloyd <ref> [31, 32] </ref> have recently presented results for provably correct updates on normalised logic programs. This is an interesting technique which takes advantage of the soundness of SLDNF resolution to insert or delete an atom from a logic program. <p> The key to these techniques is usually reliant on the CHAPTER 8. CONCLUSION 164 knowledge representation. There are also relations to abduction and default logic. The work on updating knowledge bases by Guessoum and Lloyd <ref> [31, 32] </ref>, who consider view updates on logic databases, particularly the correctness of updates, is discussed in Chapter 5.
Reference: [32] <author> A. Guessoum and J. W. Lloyd. </author> <title> Updating Knowledge Bases II. </title> <journal> New Generation Computing, </journal> <volume> 10(1) </volume> <pages> 73-100, </pages> <year> 1991. </year>
Reference-contexts: NON-MONOTONIC LEARNING 109 Wrobel suggests that exception lists may be replaced by invented predicates. However, this would result in a revised theory which no longer meets the base revision postulates. In Logic Programming the problem may be expressed in terms of updating logic databases. For instance, Guessoum and Lloyd <ref> [31, 32] </ref> have recently presented results for provably correct updates on normalised logic programs. This is an interesting technique which takes advantage of the soundness of SLDNF resolution to insert or delete an atom from a logic program. <p> The key to these techniques is usually reliant on the CHAPTER 8. CONCLUSION 164 knowledge representation. There are also relations to abduction and default logic. The work on updating knowledge bases by Guessoum and Lloyd <ref> [31, 32] </ref>, who consider view updates on logic databases, particularly the correctness of updates, is discussed in Chapter 5.
Reference: [33] <author> R. Hamakawa. </author> <title> Revision Cost for Theory Refinement. </title> <editor> In L. Birnbaum and G. Collins, editors, ML-91: </editor> <booktitle> Proc. Eighth Intl. Workshop on Machine Learning, </booktitle> <pages> pages 514 - 518, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In their representation, which is similar to that of the expert system MYCIN [127], complexity results relate to the intractability of certain strength refinements where these uncertainties are updated. The latter method is based on generating multiple rule refinements and heuristically filtering those considered suitable. Hamakawa <ref> [33] </ref>, working with a propositional Horn-clause representation, points out the problem of over-specialisation and the need for incremental learning. Ginsberg [29] provides a frequent reference point for work on theory revision. Again, his system uses a set of heuristic refinement operators and a propositional representation.
Reference: [34] <author> D. Haussler. </author> <title> Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. </title> <journal> Artificial Intelligence, </journal> <volume> 36:177 - 221, </volume> <year> 1988. </year>
Reference: [35] <author> N. Helft. </author> <title> Inductive generalisation: a logical framework. </title> <editor> In I. Bratko and N. Lavrac, editors, </editor> <booktitle> Progress in Machine Learning (EWSL-87), </booktitle> <address> London, 1987. </address> <publisher> Pitman. </publisher>
Reference: [36] <author> I. S. Herschberg and J. van den Herik. </author> <title> A database on databases. </title> <journal> ICCA Journal, </journal> <volume> 8(3) </volume> <pages> 131-139, </pages> <year> 1986. </year>
Reference: [37] <author> C. A. R. Hoare. </author> <title> Programs are Predicates. </title> <booktitle> In FGCS-92: Proc. of the Final Conference on New Generation Computer Technology, </booktitle> <address> Tokyo, 1992. </address> <publisher> Ohmsha. </publisher>
Reference-contexts: Muggleton [77] has pointed out the correspondence between this incremental learning approach to program synthesis (in an CHAPTER 5. NON-MONOTONIC LEARNING 107 Inductive Logic Programming framework) and the deductive approach of formal methods as described by Hoare <ref> [37] </ref>. Under this reading, in both ILP and formal methods the fundamental relation is that the target program ought to imply its specification. The correspondence is a broad one, since in ILP, unlike formal methods, it is generally assumed that the specification may be incomplete.
Reference: [38] <author> E. B. Hunt and C. I. Hovland. </author> <title> Programming a model of concept formation. </title> <editor> In E. A. Feigenbaum and J. Feldman, editors, </editor> <booktitle> Computers and Thought, </booktitle> <pages> pages 310-328. </pages> <publisher> Krieger, </publisher> <address> Malabar, FLA., </address> <year> 1963. </year> <note> BIBLIOGRAPHY 187 </note>
Reference: [39] <author> K. </author> <title> Jantke. Monotonic and non-monotonic inductive inference. </title> <editor> In S. Arikawa et al., editor, </editor> <booktitle> Proceedings of the Workshop on Algorithmic Learning Theory, </booktitle> <pages> pages 269-281, </pages> <address> Tokyo, 1990. </address> <publisher> Ohmsha. </publisher>
Reference-contexts: There is also a relation to Vere's method of learning "counterfac-tuals" in classical logic [137]. This is discussed further on page 125. Within an incremental learning framework, the combination of CWS with methods of gen-eralisation leads to a process of non-monotonic inductive inference as discussed in <ref> [39] </ref>. However, we began in Section 5.1.3 by identifying deficiencies in certain specialisation systems which could lead those systems to over-specialise. In developing our system we were motivated to avoid over-specialisation. To the extent that we have developed a specialisation system, we relied on an assumption common to such systems.
Reference: [40] <author> A. C. Kakas, R. A. Kowalski, and F. Toni. </author> <title> Abductive logic programming. TM- 1186, </title> <publisher> ICOT, </publisher> <address> Tokyo, Japan, </address> <year> 1993. </year>
Reference-contexts: The work on updating knowledge bases by Guessoum and Lloyd [31, 32], who consider view updates on logic databases, particularly the correctness of updates, is discussed in Chapter 5. Kakas and Mancar-ella [41] discuss semantics; Kowalski and Sadri [48] consider an exceptions representation for logic programming; Kakas et al <ref> [40] </ref> review abductive logic programming, for example its relation to truth maintenance. Semantics of Non-monotonic logic.
Reference: [41] <author> A. C. Kakas and P. Mancarella. </author> <title> Generalized Stable Models: A Semantics for Abduction. </title> <booktitle> In ECAI 90: Proceedings of the Ninth European Conference on Artificial Intelligence, </booktitle> <pages> pages 385-391, </pages> <address> London, 1990. </address> <publisher> Pitman. </publisher>
Reference-contexts: CONCLUSION 164 knowledge representation. There are also relations to abduction and default logic. The work on updating knowledge bases by Guessoum and Lloyd [31, 32], who consider view updates on logic databases, particularly the correctness of updates, is discussed in Chapter 5. Kakas and Mancar-ella <ref> [41] </ref> discuss semantics; Kowalski and Sadri [48] consider an exceptions representation for logic programming; Kakas et al [40] review abductive logic programming, for example its relation to truth maintenance. Semantics of Non-monotonic logic.
Reference: [42] <author> S.T. Kedar-Cabelli and L.T. McCarty. </author> <title> Explanation-based generalization as resolution theorem proving. </title> <editor> In P. Langley, editor, </editor> <booktitle> Proceedings of the Fourth International Workshop on Machine Learning, </booktitle> <pages> pages 383-389, </pages> <address> Los Altos, 1987. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: QED APPENDIX B. PROOFS AND THE "DERIV" FUNCTION 175 B.2 "Deriv" as an Explanation-Based Gener alisation technique The "deriv" function of Appendix B turns out to be almost entirely isomorphic to the EBG algorithm "prolog ebg" described in <ref> [42] </ref>. The main differences between deriv and prolog ebg are as follows. Firstly, while deriv acts on general clauses, prolog ebg is restricted to Horn clauses. Secondly, prolog ebg depends on a user-defined "operationality criterion". No such criterion is necessary for deriv. <p> Secondly, prolog ebg depends on a user-defined "operationality criterion". No such criterion is necessary for deriv. Thirdly, although EBG is supposed to find a "generalisation of the training example that is a sufficient concept definition for the target concept and that satisfies the operationality criterion" <ref> [42] </ref>, we are not aware of any rigorous definition or proofs concerning these aims. <p> PROOFS AND THE "DERIV" FUNCTION 177 skolemises (Tms,N,O), skolemises (T,O,M), !. % gmem (Goal,Units) unifies Goal to a member of Units if possible. % Otherwise fails. gmem (X,X). gmem (X,(A,B)) :- gmem (X,A) ; gmem (X,B). This was run on the "suicide" example from <ref> [42] </ref>. The background knowledge was kill (A,B) :- hate (A,B), possess (A,C), weapon (C). hate (W,W) :- depressed (W). possess (U,V) :- buy (U,V). weapon (Z) :- gun (Z).
Reference: [43] <author> A.N. </author> <title> Kolmogorov. Three approaches to the quantitative definition of information. </title> <journal> Prob. Inf. Trans., </journal> <volume> 1 </volume> <pages> 1-7, </pages> <year> 1965. </year>
Reference-contexts: Although in this thesis the learning data may be assumed to be error-free, our method has elsewhere been augmented with a noise-detection mechanism based on a compression metric using the algorithmic complexity model of induction <ref> [129, 43, 17, 79] </ref>. The results so far from experimental testing of this approach are promising [79].
Reference: [44] <author> K. Konolige. </author> <title> Partial models and non-monotonic inference. </title> <editor> In J.E. Hayes, D. Michie, and J. Richard, editors, </editor> <booktitle> Machine Intelligence 11, </booktitle> <pages> pages 3-19. </pages> <publisher> Oxford University Press, Oxford, </publisher> <year> 1988. </year>
Reference-contexts: Kakas and Mancar-ella [41] discuss semantics; Kowalski and Sadri [48] consider an exceptions representation for logic programming; Kakas et al [40] review abductive logic programming, for example its relation to truth maintenance. Semantics of Non-monotonic logic. Konolige <ref> [44] </ref> has proposed partial mod els as a semantics for non-monotonic logic; Przyminski [104] considers semantics of non-monotonic formalism in the framework of general logic programs; Nilsson and Genesereth [28] cover many of the essentials of non-monotonic logic in their textbook; Ginsberg [30] has collected many foundational but hard-to-find papers in
Reference: [45] <author> I. Kononenko. </author> <title> ID3, Sequential Bayes, Naive Bayes and Bayesian Neural Networks. </title> <booktitle> In Proceedings of the Fourth European Working Session on Learning, </booktitle> <pages> pages 91-98. </pages> <publisher> Pitman, </publisher> <year> 1989. </year>
Reference: [46] <author> I. Kononenko. </author> <title> Interpretation of neural networks decisions. </title> <booktitle> In Proceedings of IASTED Internat. Conf. on Expert Systems and Applications. </booktitle> <address> Zurich, </address> <year> 1989. </year>
Reference: [47] <author> D. Kopec and T. Niblett. </author> <title> How hard is the play of the KRKN ending ? In M. </title> <editor> R. B. Clarke, editor, </editor> <booktitle> Advances in Computer Chess, </booktitle> <volume> volume 2, </volume> <pages> pages 57-82. </pages> <publisher> Edinburgh University Press, Edinburgh, </publisher> <year> 1980. </year> <note> BIBLIOGRAPHY 188 </note>
Reference: [48] <author> R. A. Kowlaski and F. Sadri. </author> <title> Logic programs with exceptions. </title> <editor> In D. H. D. Warren and P. Szeredi, editors, </editor> <booktitle> Logic Programming: Proceedings of the Seventh International Conference, </booktitle> <pages> pages 598-613, </pages> <address> Cambridge, MA, 1990. </address> <publisher> MIT Press. </publisher>
Reference-contexts: There are also relations to abduction and default logic. The work on updating knowledge bases by Guessoum and Lloyd [31, 32], who consider view updates on logic databases, particularly the correctness of updates, is discussed in Chapter 5. Kakas and Mancar-ella [41] discuss semantics; Kowalski and Sadri <ref> [48] </ref> consider an exceptions representation for logic programming; Kakas et al [40] review abductive logic programming, for example its relation to truth maintenance. Semantics of Non-monotonic logic.
Reference: [49] <author> J.-L. Lassez and K. Marriott. </author> <title> Explicit Representation of Terms Defined by Counter Examples. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 3 </volume> <pages> 301-317, </pages> <year> 1987. </year>
Reference-contexts: Vere [137] developed methods to deal with counterexamples during induction. These are termed "counterfactu-als" and they define a set of conditions which must be false if a gener-alisation is to be satisfied. Lassez and Marriott <ref> [49] </ref> have dealt with the problem of generalisation given a set of counter-examples using a technique of representing explicit exceptions. As discussed previously, work in Machine Learning such as that by Michalski [63] covers handling of counter-examples in a representation based on classical logic. Logic Programming.
Reference: [50] <author> N. Lavrac and S. Dzeroski. </author> <title> Learning of relational descriptions from noisy examples. </title> <editor> In S. H. Muggleton, editor, </editor> <booktitle> Inductive Logic Programming, </booktitle> <address> Wok-ingham, UK, 1991. </address> <publisher> Turing Institute Press with Addison Wesley. </publisher>
Reference-contexts: This is of practical importance, for instance, in the area of induction over databases, where typically the formalisms are relational. Consequently the KRK illegality induction task has become something of a benchmark in relational learning studies (for example <ref> [85, 109, 50] </ref>). 6.2 Experiment 1: NM-CIGOL This experiment followed from the work reported in Chapter 4 in which several algorithms, including CIGOL, were compared on the task of learning the concept CHAPTER 6.
Reference: [51] <author> C. Lee. </author> <title> A completeness theorem and a computer program for finding theorems derivable from given axioms. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1967. </year>
Reference-contexts: Appendix B Proofs and the "deriv" function B.1 Proof of Theorem 5.7 This appendix contains the lengthy proof of Theorem 5.7 from Section 5.2 in Chapter 5. A related result known as the "Subsumption theorem" was proved by Lee <ref> [51] </ref>. For the purposes of the proof we will make various definitions based on the theory of resolution theorem proving [115].
Reference: [52] <author> K. Lindsay, B. Buchanan, E. Feigenbaum, and J. Lederberg. </author> <title> DENDRAL: a case study of the first expert system for scientific hypothesis formation. </title> <journal> Artificial Intelligence, </journal> <volume> 61(2) </volume> <pages> 209-261, </pages> <year> 1993. </year>
Reference: [53] <author> X. C. Ling. </author> <title> Inductive Learning from Good Examples. </title> <booktitle> In IJCAI-87: Proc. Twelfth Intl. Joint Conf. on Artificial Intelligence, </booktitle> <pages> pages 751 - 756, </pages> <address> Los Altos, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: It appears, though, that his method may not give minimal specialisations which are finitely axiomatisable. His proposal is to augment a specialisation method based on Shapiro's refinement operator [125]. Other work by Ling <ref> [53] </ref> using a system called SIM relies on heuristic-guided abstraction operators, which are inversions of refinement operators. Ling's motive is an identification in the limit result for SIM, which he obtains.
Reference: [54] <author> X. C. Ling. </author> <title> Non-monotonic Specialization. Unpublished, </title> <booktitle> 1991. First International Workshop on Inductive Logic Programming, </booktitle> <address> Viana de Castelo, Portugal. </address>
Reference-contexts: NON-MONOTONIC LEARNING 106 date seem not to have been applied in machine learning. However, based on an earlier version of the work described in this chapter, Ling <ref> [54] </ref> has developed a related method relying on SLDNF resolution. It appears, though, that his method may not give minimal specialisations which are finitely axiomatisable. His proposal is to augment a specialisation method based on Shapiro's refinement operator [125].
Reference: [55] <author> X. C. Ling and M. Valtorta. </author> <title> Revision of Reduced Theories. </title> <editor> In L. Birnbaum and G. Collins, editors, ML-91: </editor> <booktitle> Proc. Eighth Intl. Workshop on Machine Learning, </booktitle> <pages> pages 519 - 523, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Also, although he has proposed using negation as failure (NF) and an equality theory to construct a most general specialisation of a set of clauses, this may not give a result which is finitely axiomatisable. Within a finite language, Ling and Valtorta <ref> [55] </ref> and Craw and Sleeman [22] have given results for the complexity of the refinements produced by their systems. However, in both cases the representation is restricted to propositional rules, although Ling and Valtorta have uncertainties attached to the rules.
Reference: [56] <author> J. W. Lloyd. </author> <title> Logic Programming. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1984. </year> <note> BIBLIOGRAPHY 189 </note>
Reference-contexts: In the following note that "theory" is used as a synonym for logic program, and P ` G will be taken to mean "P ^ G is refutable using SLDNF resolution" (see <ref> [56] </ref>). The initial theory in this experiment was the best-performing theory induced by CIGOL from 100 examples in Experiment 1a, Chapter 4. This theory was found to be 91.4% correct on the test set, as discussed in Section 4.3.1 of Chapter 4. <p> As such, this marks out the limit of the learning techniques developed in the thesis. Appendix A Definitions A.1 Definitions from logic In this section we give definitions for logical expressions used in this thesis. These are based on those of <ref> [18, 56, 82] </ref>. A.1.1 Formulae in propositional calculus A proposition (propositional variable) is represented by a lower case letter followed by a string of lower case letters and digits. The negation symbol is: :. The binary connectives are: ^, _, !, $. A proposition is an atomic formula, or atom.
Reference: [57] <author> J. W. Lloyd. </author> <title> Logic Programming, 2nd Edition. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1987. </year>
Reference: [58] <author> W. Marek and M. Truszczynski. </author> <title> Autoepistemic Logic. </title> <journal> Journal of the ACM, </journal> <volume> 38(3) </volume> <pages> 588-619, </pages> <year> 1991. </year>
Reference: [59] <author> J. McCarthy. </author> <title> Applications of circumscription to formalizing common sense knowledge. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 89-116, </pages> <year> 1986. </year>
Reference-contexts: As the name suggests, in the Closed-World Specialisation (CWS) algorithm, the Closed-World Assumption [111] is applied. The "exception" predicates constructed by the CWS algorithm under the Closed-World Assumption are related to McCarthy's use of "abnormality" predicates within the framework of circumscription <ref> [59] </ref>. There is also a relation to Vere's method of learning "counterfac-tuals" in classical logic [137]. This is discussed further on page 125. Within an incremental learning framework, the combination of CWS with methods of gen-eralisation leads to a process of non-monotonic inductive inference as discussed in [39]. <p> Although the case does not arise in the chosen experimental domain, obviously the exceptions to any clause may themselves have exceptions, and so forth. Some of McCarthy's and Vere's examples demonstrate such levels of exceptions <ref> [59, 137] </ref>. For example, to re-express in our non-monotonic formalism some of McCarthy's axioms on the ability of things in general and birds in particular to fly: thing (X) :- flightless (X). CHAPTER 6.
Reference: [60] <author> D. McDermott. </author> <title> A critique of pure reason (Article plus commentaries). </title> <journal> Computational Intelligence, </journal> <volume> 3(3) </volume> <pages> 151-237, </pages> <month> August </month> <year> 1987. </year>
Reference: [61] <author> R. Michalski and J. Larson. </author> <title> Selection of most representative training examples and incremental generation of VL1 hypotheses: the underlying methodology and the description of programs ESEL and AQ11. </title> <type> UIUCDCS-R 78-867, </type> <institution> Computer Science Department, Univ. of Illinois at Urbana-Champaign, </institution> <year> 1978. </year>
Reference: [62] <author> R. Michalski and J. Larson. </author> <title> Incremental generation of vl1 hypotheses: the underlying methodology and the description of program AQ11. </title> <type> ISG 83-5, </type> <institution> Computer Science Department, Univ. of Illinois at Urbana-Champaign, </institution> <year> 1980. </year>
Reference: [63] <author> R. S. Michalski. </author> <title> A theory and methodology of inductive learning. </title> <editor> In R. Michalski, J. Carbonnel, and T. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <pages> pages 83-134. </pages> <publisher> Tioga, </publisher> <address> Palo Alto, CA, </address> <year> 1983. </year>
Reference-contexts: Lassez and Marriott [49] have dealt with the problem of generalisation given a set of counter-examples using a technique of representing explicit exceptions. As discussed previously, work in Machine Learning such as that by Michalski <ref> [63] </ref> covers handling of counter-examples in a representation based on classical logic. Logic Programming. Apart from Shapiro's seminal work (discussed in Chapter 5) on the incremental synthesis by debugging of Prolog programs, some work has been done with similar motivations in Logic Programming.
Reference: [64] <author> R. S. Michalski and P. Negri. </author> <title> An experiment in inductive learning in chess end-games. </title> <editor> In E. W. Elcock and D. Michie, editors, </editor> <booktitle> Machine Intelligence, </booktitle> <volume> volume 8, </volume> <pages> pages 168-201. </pages> <publisher> Edinburgh University Press, Edinburgh, </publisher> <year> 1977. </year>
Reference: [65] <editor> D. Michie. King and Rook Against King: </editor> <title> Historical Background and a Problem on the Infinite Board. </title> <editor> In M. R. B. Clarke, editor, </editor> <booktitle> Advances BIBLIOGRAPHY 190 in Computer Chess, </booktitle> <volume> volume 1, </volume> <pages> pages 30-59. </pages> <publisher> Edinburgh University Press, Edinburgh, </publisher> <year> 1977. </year>
Reference-contexts: Note that this Prolog representation of positions is based on the standard algebraic notation used for representing human chess games [138]. Despite the simplicity of KRK <ref> [65] </ref>, the task of inducing classification rules to distinguish legal from illegal positions highlights the shortcomings of induction in non-relational formalisms, as evidenced by the results of Chapters 3 and 4.
Reference: [66] <editor> D. Michie. </editor> <booktitle> Computer Chess and the Humanisation of Technology. </booktitle> <editor> In D. Michie, editor, </editor> <booktitle> On Machine Intelligence (Second Edition), </booktitle> <pages> pages 77 - 86. </pages> <publisher> Ellis Horwood, </publisher> <address> Chichester, </address> <year> 1986. </year>
Reference: [67] <author> D. Michie. </author> <title> The superarticulacy phenomenon in the context of software manufacture. </title> <journal> Proceedings of the Royal Society of London, </journal> <volume> A 405 </volume> <pages> 185-212, </pages> <year> 1986. </year>
Reference: [68] <author> D. Michie. </author> <title> Towards a knowledge accelerator. </title> <editor> In D. F. Beal, editor, </editor> <booktitle> Advances in Computer Chess, </booktitle> <volume> volume 4, </volume> <pages> pages 1-8. </pages> <publisher> Pergamon Press, Oxford, </publisher> <year> 1986. </year>
Reference-contexts: More importantly, these rules together with their accompanying chessboard diagrams have been verified as meaningful by chess expert and Prolog specialist Ivan Bratko. Work on the inductive synthesis of knowledge employing the "easy inverse trick" <ref> [68] </ref> pushed the nascent technology of decision-tree induction to its limits in the late 70s and early 80s [106]. These initial results in chess endgame domains led to a variety of successful applications.
Reference: [69] <author> D. Michie. </author> <title> Current developments in expert systems. </title> <editor> In J. R. Quinlan, editor, </editor> <booktitle> Applications of expert systems, </booktitle> <pages> pages 137-156. </pages> <publisher> Turing Institute Press in association with Addison-Wesley, </publisher> <address> Wokingham, </address> <year> 1987. </year>
Reference: [70] <editor> D. Michie. </editor> <booktitle> Machine learning in the next five years. In Proceedings of the Third European Working Session on Learning, </booktitle> <pages> pages 107-122. </pages> <publisher> Pitman, </publisher> <year> 1988. </year>
Reference: [71] <author> D. Michie. </author> <title> Problems of computer-aided concept formation. </title> <editor> In J. R. Quin-lan, editor, </editor> <booktitle> Applications of expert systems (Vol. </booktitle> <volume> 2), </volume> <pages> pages 310-333. </pages> <publisher> Turing Institute Press in association with Addison-Wesley, </publisher> <address> Wokingham, </address> <year> 1989. </year>
Reference: [72] <author> D. Michie. </author> <title> Personal models of rationality. </title> <journal> Journal of Statistical Planning and Inference, </journal> <volume> 25 </volume> <pages> 381-399, </pages> <year> 1990. </year>
Reference: [73] <author> D. Michie and M. Bain. </author> <title> Machine acquisition of concepts from sample data. </title> <editor> In D. Kopec and R. Thompson, editors, </editor> <booktitle> Artificial intelligence and intelligent tutoring systems: knowledge-based systems for teaching and learning, </booktitle> <pages> pages 5-23. </pages> <publisher> Ellis Horwood, </publisher> <address> Chichester, </address> <year> 1992. </year> <note> BIBLIOGRAPHY 191 </note>
Reference: [74] <author> D. Michie and D. Kopec. </author> <title> Mismatch between machine representations and human concepts: dangers and remedies. FAST Series No. </title> <booktitle> 9, 1983. </booktitle> <address> Brussels: </address> <publisher> Commission of the European Communities. </publisher>
Reference: [75] <author> T.M. Mitchell. </author> <title> Generalisation as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18 </volume> <pages> 203-226, </pages> <year> 1982. </year>
Reference: [76] <author> R. Mooney and B. Richards. </author> <title> Automated Debugging of Logic Programs via Theory Revision. </title> <editor> In S. Muggleton, editor, </editor> <booktitle> Proceedings of the Second International Workshop on Inductive Logic Programming, </booktitle> <institution> Institute for New Generation Computer Technology, </institution> <address> Tokyo, Japan, 1992. </address> <publisher> ICOT TM-1182. </publisher>
Reference-contexts: A number of theory revision systems which are related to our method include those using logic programs as a representation. EITHER [92, 93, 94] was restricted to a propositional representation, but was a precursor of the first-order system FORTE <ref> [113, 76] </ref>. This system is designed to implement generalisation as well as specialisation. The specialisation operators used in FORTE consist CHAPTER 5. NON-MONOTONIC LEARNING 108 of deleting a clause from the theory or adding a literal to a clause.
Reference: [77] <author> S. Muggleton. </author> <title> Inverting Implication. </title> <booktitle> In ILP-92: Proc. of the Second Intl. Workshop on Inductive Logic Programming, </booktitle> <address> Tokyo, </address> <year> 1992. </year> <institution> ICOT TM 1182 Institute for New Generation Computer Technology. </institution>
Reference-contexts: Then the user may terminate the incremental learning process at any stage and have confidence as to the behaviour of the current program. In this context, the specification is an example set which should be covered by a complete and correct program. Muggleton <ref> [77] </ref> has pointed out the correspondence between this incremental learning approach to program synthesis (in an CHAPTER 5. NON-MONOTONIC LEARNING 107 Inductive Logic Programming framework) and the deductive approach of formal methods as described by Hoare [37].
Reference: [78] <author> S. Muggleton. </author> <title> Predicate invention and utility. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <note> (to appear), </note> <year> 1993. </year>
Reference-contexts: CHAPTER 7. LEARNING OPTIMAL KRK STRATEGIES 158 The predicate invention methods by which induced clauses are specialised by introducing literals into the clause body are a special case of predicate invention within Muggleton's <ref> [78] </ref> "refinement lattice" framework. 7.6 Summary We have presented results from learning optimal strategies in the KRK endgame. Optimality is achieved through the use of examples extracted from an exhaustive database for the endgame.
Reference: [79] <author> S. Muggleton, A. Srinivasan, and M. Bain. </author> <title> Compression, Significance and Accuracy. </title> <editor> In D. Sleeman and P. Edwards, editors, ML-92: </editor> <booktitle> Proc. of the Ninth Intl. Workshop on Machine Learning, </booktitle> <pages> pages 338-347, </pages> <address> San Mateo, CA, 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Although in this thesis the learning data may be assumed to be error-free, our method has elsewhere been augmented with a noise-detection mechanism based on a compression metric using the algorithmic complexity model of induction <ref> [129, 43, 17, 79] </ref>. The results so far from experimental testing of this approach are promising [79]. <p> The results so far from experimental testing of this approach are promising <ref> [79] </ref>. We have shown in this chapter the improvements over Shapiro's speciali-sation method gained by our approach, but we have not shown how our CWS algorithm may be properly integrated into an incremental learning framework such as that of PDS. <p> In this section the experimental tasks were restricted to positions with depth 0 or 1. Also, we did not apply any measure of relative conciseness 1 . A suitable candidate measure could be HP-compression as described in <ref> [79] </ref>. We adopted an Inductive Logic Programming approach, using a new algorithm called GCWS ("Generalising Closed-World Specialisation"). GCWS is a combined generalisation and specialisation system. It carries out incremental learning, and incorporates theory-guided sampling. An algorithm schema for GCWS is given in Figure 28. <p> LEARNING OPTIMAL KRK STRATEGIES 157 were more concise than the examples. Although some work has been done on this front <ref> [79] </ref> we do not present any results in this thesis. However, the Prolog programs 2 from Section 7.4.2 are more compact on an informal "lines of code" criterion (10 lines and 21 respectively) than their representation as ground examples (28056).
Reference: [80] <author> S. H. Muggleton. Duce, </author> <title> an oracle-based approach to constructive induction. </title> <booktitle> In IJCAI-87, </booktitle> <pages> pages 287-292, </pages> <address> Los Altos, CA, 1987. </address> <publisher> Kaufmann. </publisher>
Reference-contexts: These are preceded in Section 7.2 by a review of the database of positions used in this work, and followed by a discussion of some relations to other work in Section 7.5. 7.2 Materials In previous work <ref> [123, 80, 85, 3] </ref> chess endgame databases have been used as sources of training and testing examples for machine learning experiments. The current work employs an exhaustive database which is a complete tabulation for the KRK endgame. The entries of this database contain optimal depth-to-win values for all positions.
Reference: [81] <author> S. H. Muggleton. </author> <title> A strategy for constructing new predicates in first order logic. </title> <booktitle> In Proceedings of the Third European Working Session on Learning, </booktitle> <pages> pages 123-130. </pages> <publisher> Pitman, </publisher> <year> 1988. </year>
Reference: [82] <author> S. H. Muggleton. </author> <title> Inductive Logic Programming. </title> <journal> New Generation Computing, </journal> <volume> 8 </volume> <pages> 295-318, </pages> <year> 1991. </year> <note> BIBLIOGRAPHY 192 </note>
Reference-contexts: As such, this marks out the limit of the learning techniques developed in the thesis. Appendix A Definitions A.1 Definitions from logic In this section we give definitions for logical expressions used in this thesis. These are based on those of <ref> [18, 56, 82] </ref>. A.1.1 Formulae in propositional calculus A proposition (propositional variable) is represented by a lower case letter followed by a string of lower case letters and digits. The negation symbol is: :. The binary connectives are: ^, _, !, $. A proposition is an atomic formula, or atom.
Reference: [83] <author> S. H. Muggleton. </author> <title> Inverting the resolution principle. </title> <editor> In J. E. Hayes, D. Michie, and E. Tyugu, editors, </editor> <booktitle> Machine Intelligence 12, </booktitle> <pages> pages 93-103, </pages> <address> Oxford, 1991. </address> <publisher> Oxford University Press. </publisher>
Reference: [84] <author> S. H. Muggleton, </author> <year> 1993. </year> <type> Personal Communication. </type>
Reference-contexts: This points to a topic of great future importance concerned with the utilisation by machine learners of discovered concepts through common predicate libraries. While this thesis has not sought to enter this territory, ground has been cleared for relevant new work in progress elsewhere <ref> [84] </ref>. CHAPTER 8. CONCLUSION 166 8.4 Summary In this thesis we embarked on the task of learning KRK concepts. We began with some rules of the game and progressed to the induction of rules for winning the endgame.
Reference: [85] <author> S. H. Muggleton, M. E. Bain, J. Hayes-Michie, and D. Michie. </author> <title> An experimental comparison of human and machine learning formalisms. </title> <editor> In A. Segre, editor, </editor> <booktitle> Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <pages> pages 113-118, </pages> <address> Los Altos, CA, 1989. </address> <publisher> Kaufmann. </publisher>
Reference-contexts: This is of practical importance, for instance, in the area of induction over databases, where typically the formalisms are relational. Consequently the KRK illegality induction task has become something of a benchmark in relational learning studies (for example <ref> [85, 109, 50] </ref>). 6.2 Experiment 1: NM-CIGOL This experiment followed from the work reported in Chapter 4 in which several algorithms, including CIGOL, were compared on the task of learning the concept CHAPTER 6. <p> These are preceded in Section 7.2 by a review of the database of positions used in this work, and followed by a discussion of some relations to other work in Section 7.5. 7.2 Materials In previous work <ref> [123, 80, 85, 3] </ref> chess endgame databases have been used as sources of training and testing examples for machine learning experiments. The current work employs an exhaustive database which is a complete tabulation for the KRK endgame. The entries of this database contain optimal depth-to-win values for all positions.
Reference: [86] <author> S. H. Muggleton and W. Buntine. </author> <title> Machine invention of first-order predicates by inverting resolution. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> pages 339-352. </pages> <publisher> Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: In both experiments, the generalisation methods employed were those of learning in a Horn clause subset of first-order logic. To be precise, in the first experiment a version of Muggleton and Buntine's system CIGOL <ref> [86] </ref> was used, and in the second experiment this was replaced with Muggleton and Feng's GOLEM system [87]. Both generalisation methods were combined with the Closed-World Specialisation (CWS) technique described in Chapter 5 for "correcting" over-general logic programs. 111 CHAPTER 6. <p> PROOFS AND THE "DERIV" FUNCTION 171 Since the dot () operator represents binary resolution it is commutative, non-associative and non-distributive. These dotted derivation expressions are an extension of notation introduced in <ref> [86] </ref>. Clearly C is an element of R fl (T ) if and only if there exists a derivation expression whose clauses are all elements of T and whose resolvent is C. We say that a derivation expression RE is a refutation expression whenever resolvent (RE) = 2.
Reference: [87] <author> S. H. Muggleton and C. Feng. </author> <title> Efficient induction of logic programs. </title> <editor> In S. Arikawa et al., editor, </editor> <booktitle> Proceedings of the Workshop on Algorithmic Learning Theory, </booktitle> <pages> pages 368-381, </pages> <address> Tokyo, 1990. </address> <publisher> Ohmsha. </publisher>
Reference-contexts: To be precise, in the first experiment a version of Muggleton and Buntine's system CIGOL [86] was used, and in the second experiment this was replaced with Muggleton and Feng's GOLEM system <ref> [87] </ref>. Both generalisation methods were combined with the Closed-World Specialisation (CWS) technique described in Chapter 5 for "correcting" over-general logic programs. 111 CHAPTER 6. <p> if training = ; then P f = P i else P = Gen (training; background) P 0 = P i [ P hP 00 ; exceptionsi = Spec (P 0 , test, background) P f = GCWS (P 00 , exceptions, test, background) Output : P f GOLEM system <ref> [87] </ref>. GOLEM appears in the generalisation procedure schemas of Figure 29 as a function called with four arguments.
Reference: [88] <author> S. H. Muggleton, A. Srinivasan, and M. Bain. </author> <title> MDL codes for non-monotonic learning. </title> <type> Technical report, </type> <institution> Turing Institute, Glasgow, </institution> <year> 1991. </year>
Reference-contexts: This is particularly true of the specialisation method, where observed exceptions to rules may be due to bad data. Some work on this has CHAPTER 8. CONCLUSION 165 already been completed using techniques based on the theory of algorithmic (Kolmogorov) complexity, and this is reported in <ref> [88] </ref>. However, this version of non-monotonic learning is not incremental. An incremental approach requires testing theories against large data sets, which involves theorem-proving and is consequently expensive. Secondly, we have shown that restriction of the hypothesis language, e.g. by restricting vocabulary, is a major obstacle for successful learning.
Reference: [89] <author> A. Newell, J. Shaw, and H. Simon. </author> <title> Chess-Playing Programs and the Problem of Complexity. </title> <editor> In D. Levy, editor, </editor> <booktitle> Computer Games 1, </booktitle> <pages> pages 89 - 115. </pages> <publisher> Springer, </publisher> <address> New York, </address> <year> 1988. </year>
Reference: [90] <author> T. Niblett. </author> <title> A study of generalisation in logic programs. </title> <booktitle> In EWSL-88, </booktitle> <address> London, 1988. </address> <publisher> Pitman. </publisher>
Reference: [91] <author> P. O'Rorke. </author> <title> A comparative study of inductive learning systems AQ11P and ID3 using a chess end-game test problem. </title> <type> ISG 82-2, </type> <institution> Computer Science Department, Univ. of Illinois at Urbana-Champaign, </institution> <year> 1982. </year>
Reference: [92] <author> D. Ourston and R. Mooney. </author> <title> Changing the rules: a comprehensive approach to theory refinement. </title> <booktitle> In AAAI-90: Proc. of the Eighth National BIBLIOGRAPHY 193 Conference on Artificial Intelligence, </booktitle> <pages> pages 815-820, </pages> <address> Menlo Park, CA, 1990. </address> <publisher> AAAI Press/The MIT Press. </publisher>
Reference-contexts: Ginsberg [29] provides a frequent reference point for work on theory revision. Again, his system uses a set of heuristic refinement operators and a propositional representation. A number of theory revision systems which are related to our method include those using logic programs as a representation. EITHER <ref> [92, 93, 94] </ref> was restricted to a propositional representation, but was a precursor of the first-order system FORTE [113, 76]. This system is designed to implement generalisation as well as specialisation. The specialisation operators used in FORTE consist CHAPTER 5.
Reference: [93] <author> D. Ourston and R. Mooney. </author> <title> Constructive Induction in Theory Refinement. </title> <editor> In L. Birnbaum and G. Collins, editors, ML-91: </editor> <booktitle> Proc. of the Eighth Intl. Workshop on Machine Learning, </booktitle> <pages> pages 178-182, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Ginsberg [29] provides a frequent reference point for work on theory revision. Again, his system uses a set of heuristic refinement operators and a propositional representation. A number of theory revision systems which are related to our method include those using logic programs as a representation. EITHER <ref> [92, 93, 94] </ref> was restricted to a propositional representation, but was a precursor of the first-order system FORTE [113, 76]. This system is designed to implement generalisation as well as specialisation. The specialisation operators used in FORTE consist CHAPTER 5.
Reference: [94] <author> D. Ourston and R. Mooney. </author> <title> Improving Shared Rules in Multiple Category Domain Theories. </title> <editor> In L. Birnbaum and G. Collins, editors, ML-91: </editor> <booktitle> Proc. of the Eighth Intl. Workshop on Machine Learning, </booktitle> <pages> pages 534-538, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Ginsberg [29] provides a frequent reference point for work on theory revision. Again, his system uses a set of heuristic refinement operators and a propositional representation. A number of theory revision systems which are related to our method include those using logic programs as a representation. EITHER <ref> [92, 93, 94] </ref> was restricted to a propositional representation, but was a precursor of the first-order system FORTE [113, 76]. This system is designed to implement generalisation as well as specialisation. The specialisation operators used in FORTE consist CHAPTER 5.
Reference: [95] <author> G. Pagallo. </author> <title> Learning DNF by decision trees. </title> <booktitle> In IJCAI-89: Proceedings of the 11th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 639-644, </pages> <address> Los Altos, CA, 1989. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [96] <author> A. Paterson. </author> <title> An attempt to use cluster to synthesise humanly intelligible subproblems for the kpk chess endgame. </title> <type> Technical Report UIUCDCS-R-83-1156, </type> <institution> Univ. Illinois, Urbana, IL, </institution> <year> 1983. </year>
Reference: [97] <author> M. Pazzani, C. Brunk, and G. Silverstein. </author> <title> A knowledge-intensive approach to learning relational concepts. </title> <booktitle> In ML-91: Proc. of the Eighth Intl. Workshop on Machine Learning, </booktitle> <pages> pages 432-436, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This system does not appear to avoid possible over-specialisation. Other systems that carry out intermediate operationalization steps include FOCL <ref> [97] </ref> and ML-SMART [6]. Minimal specialisation according to our definitions is not reported for the above theory revision systems. A proposal to use criteria other than minimal specialisation for theory revision has recently been made by Wrobel [142].
Reference: [98] <author> D. Pearce. </author> <title> The induction of fault diagnosis systems from qualitative models. </title> <booktitle> In AAAI-88: Proceedings of the 7th National Conference on Artificial Intelligence, </booktitle> <pages> pages 353-357, </pages> <address> San Mateo, CA, 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Among the rules which came out of this study were some previously undiscovered in over 200 years of cardiology. This route was also taken in an application to satellite fault diagnosis <ref> [98] </ref>. Most recently, an ILP approach in the same domain allowed the learning of significant temporal relations not expressed in the earlier solution [25]. The role of Machine Learning in previous work has focused on database compression.
Reference: [99] <author> G. D. Plotkin. </author> <title> A note on inductive generalization. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence, </booktitle> <volume> volume 5, </volume> <pages> pages 153-163. </pages> <publisher> Edin-burgh University Press, Edinburgh, </publisher> <year> 1969. </year> <note> BIBLIOGRAPHY 194 </note>
Reference: [100] <author> G. D. Plotkin. </author> <title> Automatic Methods of Inductive Inference. </title> <type> PhD thesis, </type> <institution> Edinburgh University, </institution> <month> August </month> <year> 1971. </year>
Reference: [101] <author> G. D. Plotkin. </author> <title> A further note on inductive generalization. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence, </booktitle> <volume> volume 6, </volume> <pages> pages 101-124. </pages> <publisher> Edinburgh University Press, Edinburgh, </publisher> <year> 1971. </year>
Reference: [102] <author> J. L. Pollock. </author> <title> How to reason defeasibly. </title> <journal> Artificial Intelligence, </journal> <volume> 57 </volume> <pages> 1-42, </pages> <year> 1992. </year>
Reference-contexts: Theory Revision. Gardenfors [27] has proposed a general theory of updating beliefs. Defeasible reasoning. Pollock <ref> [102] </ref> has developed a theory of defeasible rea soning and implemented a prototype system. 8.3 Future directions We believe that several important open issues may be identified from the foregoing results.
Reference: [103] <author> R. J. Popplestone. </author> <title> An experiment in automatic induction. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence, </booktitle> <volume> volume 5, </volume> <pages> pages 203-215. </pages> <publisher> Edinburgh University Press, Edinburgh, </publisher> <year> 1969. </year>
Reference: [104] <author> T. Przymusinski. </author> <title> Three-valued nonmonotonic formalisms and semantics of logic programs. </title> <journal> Artificial Intelligence, </journal> <volume> 49 </volume> <pages> 309-343, </pages> <year> 1991. </year>
Reference-contexts: Semantics of Non-monotonic logic. Konolige [44] has proposed partial mod els as a semantics for non-monotonic logic; Przyminski <ref> [104] </ref> considers semantics of non-monotonic formalism in the framework of general logic programs; Nilsson and Genesereth [28] cover many of the essentials of non-monotonic logic in their textbook; Ginsberg [30] has collected many foundational but hard-to-find papers in non-monotonic reasoning (includ ing papers by McCarthy, Lifschitz et al.). Theory Revision.
Reference: [105] <author> J. R. Quinlan. </author> <title> Semi-autonomous acquisition of pattern-based knowledge. </title> <editor> In D. Michie, editor, </editor> <booktitle> Introductory readings in expert systems, </booktitle> <pages> pages 192-207. </pages> <publisher> Gordon and Breach, </publisher> <address> New York, </address> <year> 1982. </year>
Reference: [106] <author> J. R. Quinlan. </author> <title> Learning efficient classification procedures and their application to chess end games. </title> <editor> In R. Michalski, J. Carbonnel, and T. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <pages> pages 464-482. </pages> <publisher> Tioga, </publisher> <address> Palo Alto, CA, </address> <year> 1983. </year>
Reference-contexts: The rand subset function therefore implements a form of theory-guided sampling 1 . This is related to Quinlan's technique of windowing as used in ID3 and its derivatives <ref> [106] </ref>, and stratified sampling [14]. 6.2.2 Results The working hypothesis was that NM-CIGOL would improve on the initial theory. Recall that this initial theory was found to give the maximum performance in Experiment 1a of Chapter 4, recording 91.4% predictive accuracy. <p> CHAPTER 7. LEARNING OPTIMAL KRK STRATEGIES 130 Previous attempts to learn classification rules in chess endgame domains have typically used a much more powerful set of domain features to describe example positions than is the case in the current study. Quinlan <ref> [106] </ref> has reported that in an application of ID3 to learning a classification for the "lost n-ply" relation in the King and Rook against King and Knight (KRKN) endgame the main obstacle to producing a complete and correct set of classification rules was the lack of suitable attributes. <p> Work on the inductive synthesis of knowledge employing the "easy inverse trick" [68] pushed the nascent technology of decision-tree induction to its limits in the late 70s and early 80s <ref> [106] </ref>. These initial results in chess endgame domains led to a variety of successful applications. The landmark KARDIO system used a deep model of the heart to synthesise shallow rules for ECG interpretation [10].
Reference: [107] <author> J. R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference: [108] <author> J. R. Quinlan. </author> <title> Generating production rules from decision trees. </title> <booktitle> In Proceedings of the Tenth International Conference on Artificial Intelligence, </booktitle> <pages> pages 304-307, </pages> <address> Los Altos, CA:, 1987. </address> <publisher> Kaufmann. </publisher>
Reference: [109] <author> J. R. Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5(3) </volume> <pages> 239-266, </pages> <year> 1990. </year> <note> BIBLIOGRAPHY 195 </note>
Reference-contexts: This is of practical importance, for instance, in the area of induction over databases, where typically the formalisms are relational. Consequently the KRK illegality induction task has become something of a benchmark in relational learning studies (for example <ref> [85, 109, 50] </ref>). 6.2 Experiment 1: NM-CIGOL This experiment followed from the work reported in Chapter 4 in which several algorithms, including CIGOL, were compared on the task of learning the concept CHAPTER 6.
Reference: [110] <author> J. R. Quinlan, P. J. Compton, K.A. Horn, and L. Lazarus. </author> <title> Inductive knowledge acquisition: A case study. </title> <booktitle> In Proceedings of the Second Aus-tralian Conference on the Applications of Expert Systems, </booktitle> <pages> pages 183-204, </pages> <address> Sydney, </address> <year> 1986. </year> <institution> New South Wales Institute of Technology. </institution>
Reference: [111] <author> R. Reiter. </author> <title> On closed world data bases. </title> <editor> In H. Gallaire and J. Minker, editors, </editor> <title> Logic and databases. </title> <publisher> Plenum, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: We briefly discuss below some work on CHAPTER 5. NON-MONOTONIC LEARNING 105 specialisation, primarily in the context of Machine Learning. As the name suggests, in the Closed-World Specialisation (CWS) algorithm, the Closed-World Assumption <ref> [111] </ref> is applied. The "exception" predicates constructed by the CWS algorithm under the Closed-World Assumption are related to McCarthy's use of "abnormality" predicates within the framework of circumscription [59]. There is also a relation to Vere's method of learning "counterfac-tuals" in classical logic [137].
Reference: [112] <author> J. C. Reynolds. </author> <title> Transformational Systems and the Algebraic Structure of Atomic Formulas. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence, </booktitle> <volume> volume 5, </volume> <pages> pages 135-151. </pages> <publisher> Edinburgh University Press, Edinburgh, </publisher> <year> 1969. </year>
Reference: [113] <author> B. Richards and R. Mooney. </author> <title> First-Order Theory Revision. </title> <editor> In L. Birnbaum and G. Collins, editors, ML-91: </editor> <booktitle> Proc. of the Eighth Intl. Workshop on Machine Learning, </booktitle> <pages> pages 447-451, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A number of theory revision systems which are related to our method include those using logic programs as a representation. EITHER [92, 93, 94] was restricted to a propositional representation, but was a precursor of the first-order system FORTE <ref> [113, 76] </ref>. This system is designed to implement generalisation as well as specialisation. The specialisation operators used in FORTE consist CHAPTER 5. NON-MONOTONIC LEARNING 108 of deleting a clause from the theory or adding a literal to a clause.
Reference: [114] <author> J. A. Robinson. </author> <title> Automatic deduction with hyper-resolution. </title> <journal> International Jounal of Computer Mathematics, </journal> <volume> 1 </volume> <pages> 227-234, </pages> <year> 1965. </year>
Reference-contexts: Let C = (l 1 ^ l 2 ^ : : :) s where s is a skolemisation of the variables of C. Note that we can write 1 s as a deterministic "deskolemisation" rewrite due to the nature of skolemisation. Following a convention introduced in <ref> [114] </ref>, resolution-based refutations and derivations are drawn as binary trees. There is a one-one correspondence between derivation expressions and derivation trees. Figure 38 represents the transformation of a refutation tree into a derivation tree using "deriv". In this figure both the refutation tree and the derivation tree represent general cases.
Reference: [115] <author> J. A. Robinson. </author> <title> A machine-oriented logic based on the resolution principle. </title> <journal> JACM, </journal> <volume> 12(1) </volume> <pages> 23-41, </pages> <month> January </month> <year> 1965. </year>
Reference-contexts: A related result known as the "Subsumption theorem" was proved by Lee [51]. For the purposes of the proof we will make various definitions based on the theory of resolution theorem proving <ref> [115] </ref>.
Reference: [116] <author> C. Rouveirol and J-F Puget. </author> <title> A simple solution for inverting resolution. </title> <booktitle> In EWSL'89: Proceedings of the Fourth European Working Session on Learning, </booktitle> <address> Montpellier, </address> <year> 1989, </year> <pages> pages 201-210, </pages> <address> London, 1989. </address> <publisher> Pitman. </publisher>
Reference: [117] <author> A. J. Roycroft. </author> <title> The GBR code: a 4-digit code for precise specification of chess force. </title> <journal> Journal of the International Computer Chess Association, </journal> <volume> 7(1) </volume> <pages> 53-54, </pages> <year> 1984. </year>
Reference: [118] <author> A. J. Roycroft. </author> <title> Database "oracles": Necessary and desirable features. </title> <journal> ICCA Journal, </journal> <volume> 8(2) </volume> <pages> 100-104, </pages> <year> 1986. </year> <note> BIBLIOGRAPHY 196 </note>
Reference: [119] <author> C. Sammut and R. B. Banerji. </author> <title> Learning concepts by asking questions. </title> <editor> In R. Michalski, J. Carbonnel, and T. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach. </booktitle> <volume> Vol. 2, </volume> <pages> pages 167-192. </pages> <publisher> Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1986. </year>
Reference: [120] <author> J. C. Schlimmer and D. H. Fisher. </author> <title> A case study of incremental concept induction. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> pages 496-501, </pages> <address> Philadelphia, PA:, 1986. </address> <publisher> Kaufmann. </publisher>
Reference: [121] <author> C. Shannon. </author> <title> Programming a computer to play chess. </title> <journal> Philosophical Magazine, </journal> <volume> 8(3) </volume> <pages> 131-139, </pages> <year> 1950. </year>
Reference: [122] <author> A. Shapiro and T. Niblett. </author> <title> Automatic induction of classification rules for a chess end-game. </title> <editor> In M. R. B. Clarke, editor, </editor> <booktitle> Advances in Computer Chess, </booktitle> <volume> volume 3, </volume> <pages> pages 73-92. </pages> <publisher> Pergamon Press, Oxford, </publisher> <year> 1982. </year>
Reference: [123] <author> A. D. Shapiro. </author> <title> Structured Induction in Expert Systems. </title> <publisher> Turing Institute Press with Addison Wesley, </publisher> <address> Wokingham, UK, </address> <year> 1987. </year>
Reference-contexts: These are preceded in Section 7.2 by a review of the database of positions used in this work, and followed by a discussion of some relations to other work in Section 7.5. 7.2 Materials In previous work <ref> [123, 80, 85, 3] </ref> chess endgame databases have been used as sources of training and testing examples for machine learning experiments. The current work employs an exhaustive database which is a complete tabulation for the KRK endgame. The entries of this database contain optimal depth-to-win values for all positions.
Reference: [124] <author> A. D. Shapiro and D. Michie. </author> <title> A self-commenting facility for inductively synthesised endgame expertise. </title> <editor> In D.F. Beal, editor, </editor> <booktitle> Advances in Computer Chess, </booktitle> <volume> volume 4, </volume> <pages> pages 147-165. </pages> <address> Pergammon, Oxford, </address> <year> 1986. </year>
Reference-contexts: Typically, however, in the chess endgame applications to date the bottleneck for decision-tree induction has been selection of an adequate set of attributes. For example, in experiments on the KPa7KR domain <ref> [124] </ref> most of the effort was expended on hand-crafting the attributes which capture the necessary relational features of the won/not won predicate. The novelty of the present approach lies in the application of relational learning using RLGG as implemented in GOLEM coupled with specialisation techniques based on predicate invention.
Reference: [125] <author> E. Y. Shapiro. </author> <title> Inductive inference of theories from facts. </title> <type> Technical Report 192, </type> <institution> Dept. Comp. Sci., Yale University, </institution> <address> Connecticut, </address> <year> 1981. </year>
Reference-contexts: It appears, though, that his method may not give minimal specialisations which are finitely axiomatisable. His proposal is to augment a specialisation method based on Shapiro's refinement operator <ref> [125] </ref>. Other work by Ling [53] using a system called SIM relies on heuristic-guided abstraction operators, which are inversions of refinement operators. Ling's motive is an identification in the limit result for SIM, which he obtains.
Reference: [126] <author> E. Y. Shapiro. </author> <title> Algorithmic Program Debugging. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA., </address> <year> 1983. </year>
Reference-contexts: In developing our system we were motivated to avoid over-specialisation. To the extent that we have developed a specialisation system, we relied on an assumption common to such systems. This has been termed "the competent programmer assumption" by E. Shapiro <ref> [126] </ref> and others. On this view, at any stage in the incremental learning process the current program is probably largely correct. Testing of the program can confirm if this is justified.
Reference: [127] <author> E.H. Shortliffe and B. Buchanan. </author> <title> A model of inexact reasoning in medicine. </title> <journal> Mathematical Biosciences, </journal> <volume> 23 </volume> <pages> 351-379, </pages> <year> 1975. </year>
Reference-contexts: However, in both cases the representation is restricted to propositional rules, although Ling and Valtorta have uncertainties attached to the rules. In their representation, which is similar to that of the expert system MYCIN <ref> [127] </ref>, complexity results relate to the intractability of certain strength refinements where these uncertainties are updated. The latter method is based on generating multiple rule refinements and heuristically filtering those considered suitable.
Reference: [128] <author> H.A. Simon. </author> <title> Why should machines learn? In R. </title> <editor> Michalski, J. Carbon-nel, and T. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <pages> pages 25-37. </pages> <publisher> Tioga, </publisher> <address> Palo Alto, CA, </address> <year> 1983. </year> <note> BIBLIOGRAPHY 197 </note>
Reference: [129] <author> R.J. Solomonoff. </author> <title> A formal theory of inductive inference. </title> <journal> J. Comput. Sys., </journal> <volume> 7 </volume> <pages> 376-388, </pages> <year> 1964. </year>
Reference-contexts: Although in this thesis the learning data may be assumed to be error-free, our method has elsewhere been augmented with a noise-detection mechanism based on a compression metric using the algorithmic complexity model of induction <ref> [129, 43, 17, 79] </ref>. The results so far from experimental testing of this approach are promising [79].
Reference: [130] <author> S. T. Tan. </author> <title> Describing pawn structures. </title> <editor> In M. R. B. Clarke, editor, </editor> <booktitle> Advances in Computer Chess, </booktitle> <volume> volume 1, </volume> <pages> pages 74-88. </pages> <publisher> Edinburgh University Press, Edinburgh, </publisher> <year> 1977. </year>
Reference: [131] <author> S. Tangkitvanich and M. Shimura. </author> <title> Refining a Relational Theory with Multiple Faults in the Concept and Sub-concepts. </title> <booktitle> In ML-92: Proc. of the Ninth Intl. Conference on Machine Learning, </booktitle> <pages> pages 436-444, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: AU-DREY, a similar system at least in the respect of the specialisation methods used, is described by Wogulis [140]. A slightly different approach is taken in systems which operationalize or partially evaluate the theory before revision. For example, in the recent system of Tankitvanich et al. <ref> [131] </ref>, the faulty theory is operationalized using Explanation-Based Learning (EBL) techniques, faults are detected and then specialisation carried out using methods of first-order learning. This system does not appear to avoid possible over-specialisation. Other systems that carry out intermediate operationalization steps include FOCL [97] and ML-SMART [6].
Reference: [132] <author> K. Thompson. </author> <title> Retrograde Analysis of Certain Endgames. </title> <journal> ICCA Journal, </journal> <volume> 8(3) </volume> <pages> 131-139, </pages> <year> 1986. </year>
Reference: [133] <author> P.E. Utgoff. </author> <title> Adjusting bias in concept learning. </title> <booktitle> In IJCAI-83, </booktitle> <pages> pages 447-449, </pages> <address> Los Angeles, CA, 1983. </address> <publisher> Kaufmann. </publisher>
Reference: [134] <author> J. van den Herik and I. S. Herschberg. </author> <title> The construction of an omniscient endgame database. </title> <journal> ICCA Journal, </journal> <volume> 8(2) </volume> <pages> 66-87, </pages> <year> 1985. </year>
Reference: [135] <author> M. H. van Emden and R. A. Kowalski. </author> <title> The Semantics of Predicate Logic as a Programming Language. </title> <journal> JACM, </journal> <volume> 23(4) </volume> <pages> 733-742, </pages> <year> 1976. </year>
Reference: [136] <author> A. van Gelder, K.A. Ross, and J.S. Schlipf. </author> <title> The Well-Founded Semantics for General Logic Programs. </title> <journal> Journal of the ACM, </journal> <volume> 38(3) </volume> <pages> 620-650, </pages> <year> 1991. </year>
Reference: [137] <author> S. A. Vere. </author> <title> Multilevel Counterfactuals for Generalizations of Relational Concepts and Productions. </title> <journal> Artificial Intelligence, </journal> <volume> 14 </volume> <pages> 139-164, </pages> <year> 1980. </year>
Reference-contexts: The "exception" predicates constructed by the CWS algorithm under the Closed-World Assumption are related to McCarthy's use of "abnormality" predicates within the framework of circumscription [59]. There is also a relation to Vere's method of learning "counterfac-tuals" in classical logic <ref> [137] </ref>. This is discussed further on page 125. Within an incremental learning framework, the combination of CWS with methods of gen-eralisation leads to a process of non-monotonic inductive inference as discussed in [39]. <p> Although the case does not arise in the chosen experimental domain, obviously the exceptions to any clause may themselves have exceptions, and so forth. Some of McCarthy's and Vere's examples demonstrate such levels of exceptions <ref> [59, 137] </ref>. For example, to re-express in our non-monotonic formalism some of McCarthy's axioms on the ability of things in general and birds in particular to fly: thing (X) :- flightless (X). CHAPTER 6. <p> Instead we give in this section a short annotated list of references which have certain links to the issues addressed by our method of learning logical exceptions. Classical logic representations. Before referring to non-monotonic logic representations, some notable work on specialisation in Classical Logic representations should be mentioned. Vere <ref> [137] </ref> developed methods to deal with counterexamples during induction. These are termed "counterfactu-als" and they define a set of conditions which must be false if a gener-alisation is to be satisfied.
Reference: [138] <author> R. G. Wade. </author> <title> The Batsford Book of Chess. </title> <editor> B. T. Batsford, </editor> <address> London, UK, </address> <year> 1984. </year>
Reference-contexts: Each of the three pieces takes two arguments, for file and rank values, from respectively fa, : : :, hg and f1, : : :, 8g. Note that this Prolog representation of positions is based on the standard algebraic notation used for representing human chess games <ref> [138] </ref>. Despite the simplicity of KRK [65], the task of inducing classification rules to distinguish legal from illegal positions highlights the shortcomings of induction in non-relational formalisms, as evidenced by the results of Chapters 3 and 4.
Reference: [139] <author> R. Wirth. </author> <title> Completing logic programs by inverse resolution. </title> <booktitle> In EWSL-89, </booktitle> <pages> pages 239-250, </pages> <address> London, 1989. </address> <publisher> Pitman. BIBLIOGRAPHY 198 </publisher>
Reference: [140] <author> J. Wogulis. </author> <title> Revising Relational Domain Theories. </title> <editor> In L. Birnbaum and G. Collins, editors, ML-91: </editor> <booktitle> Proc. of the Eighth Intl. Workshop on Machine Learning, </booktitle> <pages> pages 462-466, </pages> <address> San Mateo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: NON-MONOTONIC LEARNING 108 of deleting a clause from the theory or adding a literal to a clause. Heuristics are used to guide a hill-climbing search strategy for the "optimal" revision. AU-DREY, a similar system at least in the respect of the specialisation methods used, is described by Wogulis <ref> [140] </ref>. A slightly different approach is taken in systems which operationalize or partially evaluate the theory before revision.
Reference: [141] <author> S. Wrobel. </author> <title> Automatic representation adjustment in an observational discovery system. </title> <booktitle> In EWSL-88, </booktitle> <pages> pages 253-262, </pages> <address> London, 1988. </address> <publisher> Pitman. </publisher>
Reference: [142] <author> S. Wrobel. </author> <title> On the proper definition of minimality in specialization and theory revision. </title> <booktitle> In ECML-93: Proc. of the European Conf. on Machine Learning, </booktitle> <year> 1993. </year>
Reference-contexts: Other systems that carry out intermediate operationalization steps include FOCL [97] and ML-SMART [6]. Minimal specialisation according to our definitions is not reported for the above theory revision systems. A proposal to use criteria other than minimal specialisation for theory revision has recently been made by Wrobel <ref> [142] </ref>. This is a formalisation of the exception list method implemented in MODELER, discussed above in Section 5.1.3. The particular criteria he suggests are based on the set of Gardenfors postulates [27] for belief revision.
References-found: 142

