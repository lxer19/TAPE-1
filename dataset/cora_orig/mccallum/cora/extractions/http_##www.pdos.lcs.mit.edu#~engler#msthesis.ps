URL: http://www.pdos.lcs.mit.edu/~engler/msthesis.ps
Refering-URL: http://www.pdos.lcs.mit.edu/~engler/
Root-URL: 
Title: The Design and Implementation of a Prototype Exokernel Operating System  
Author: by Dawson R. Engler c flDawson R. Engler, . M. Frans Kaashoek 
Degree: Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Master of Science in Computer Science and Engineering at the  Author  Certified by  Assistant Professor of Computer Science and Engineering Thesis Supervisor Accepted by Frederic R. Morgenthaler Chairman, Committee on Graduate Students  
Date: January 1995  January 1995  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. Accetta, R. Baron, W. Bolosky, D. Golub, R. Rashid, A. Tevanian, and M. Young. </author> <title> Mach: a new kernel foundation for UNIX development. </title> <booktitle> Proc. Summer 1986 USENIX Conference, </booktitle> <pages> pages 93-112, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: Lampson's description of the CAL-TSS [60, 63] and Brinch Hansen's microkernel paper [43] are two classic rationales. Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets [108]. Modern revisitations of microkernels have also argued for kernel extensibility <ref> [1, 80, 84, 95, 28] </ref>. Anderson and Kiczales et al. also recently argued for minimalism and customizable [3, 56].
Reference: [2] <author> W.B. Ackerman and W.W. Plummer. </author> <title> An implementaton of a multiprocessing computer system. </title> <booktitle> Proceedings of the First ACM Symposium on Operating Systems Principles, </booktitle> <month> October </month> <year> 1967. </year>
Reference-contexts: Therefore, its structure has a dramatic impact on the performance and the scope of applications that can be built on it. Since its inception, the field of operating systems has been attempting to identify an appropriate structure: from familiar monolithic [99, 103] to micro-kernel operating systems <ref> [2, 43] </ref> to more exotic language-based [81] and virtual machine [27, 40] operating systems. This search, spanning the last three decades, has been aggressive and vigorous but, unfortunately, has not been satisfactorily resolved [13, 22, 36, 43, 63, 72].
Reference: [3] <author> T.E. Anderson. </author> <title> The case for application-specific operating systems. </title> <booktitle> In Third Workshop on Workstation Operating Systems, </booktitle> <pages> pages 92-94, </pages> <year> 1992. </year>
Reference-contexts: The single insight that we wish to offer is that these policy decisions and implementation trade-offs are unnecessary. If the operating system tracks ownership, application-level libraries can implement the rest | more reliably, efficiently, and appropriately than any general-purpose operating system could hope to do <ref> [3] </ref>. <p> Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets [108]. Modern revisitations of microkernels have also argued for kernel extensibility [1, 80, 84, 95, 28]. Anderson and Kiczales et al. also recently argued for minimalism and customizable <ref> [3, 56] </ref>. The most important difference between our work and previous approaches is the explicit view that the operating system should not provide abstractions; as a result the interface in these systems is a much higher one (e.g., page-tables are implemented by the kernel).
Reference: [4] <author> T.E. Anderson, B.N. Bershad, E.D. Lazowska, and H.M. Levy. </author> <title> Scheduler activations: Effective kernel support for the user-level management of parallelism. </title> <booktitle> In Proc. Thirteenth Symposium on Operating System Principles, </booktitle> <pages> pages 95-109, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: For example, what operating systems support scheduler activations <ref> [4] </ref>, multiple protection domains within a single-address space [20], efficient IPC [67], or efficient and flexible virtual memory primitives [5, 45, 58]? The structure of traditional operating systems ensures that good ideas will, for the most part, remain research curiosities. <p> Applications that do not need a given feature pay unnecessary overhead <ref> [4, 72] </ref>. Additionally, simply using a given feature is costly, since the operating system must interpret a myriad of system call options [72]. <p> Scheduler activations. The inefficiency of the process abstraction has led to a proliferation of user-level lightweight processes or threads. Unfortunately, since user-level threads are invisible to the operating system, their use can result in both performance and correct 76 ness problems <ref> [4] </ref>. For example, consider the case where two threads are multiplexed on top of a heavy-weight process: if one thread causes a page-fault, the OS will block the entire process, rather than letting the other thread run.
Reference: [5] <author> A.W. Appel and K. Li. </author> <title> Virtual memory primitives for user programs. </title> <booktitle> In Proceedings of the Fourth International Conference on ASPLOS, </booktitle> <pages> pages 96-107, </pages> <address> Santa Clara, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Instead, it concentrates solely on multiplexing the raw hardware: from these hardware primitives, application-level libraries and servers can directly implement traditional operating system abstractions, specialized for appropriateness and speed. 1.1 The Problem The cost of inappropriate, inefficient operating system abstractions has had a large impact on applications <ref> [5, 13, 44, 45, 72, 91, 97] </ref>. This situation has persisted for the last three decades, and has survived numerous assaults (e.g., object-oriented operating systems and micro-kernels). Any concept that cannot be realized after such a long period of time should be reexamined. <p> For example, what operating systems support scheduler activations [4], multiple protection domains within a single-address space [20], efficient IPC [67], or efficient and flexible virtual memory primitives <ref> [5, 45, 58] </ref>? The structure of traditional operating systems ensures that good ideas will, for the most part, remain research curiosities. In an exokernel based system, these mechanisms can be implemented directly at application-level without special privileges, and without compromising system integrity. <p> For example, once the application has no access to the raw disk interface, database records must be emulated on top of files: further examples of conflicts between OS-provided abstractions and what applications require can be found in the literature <ref> [5, 13, 44, 45, 72, 91, 97] </ref>. The abstractions of modern operating systems hide useful information and capabilities. <p> DEC2100 Aegis 2.8 2.8 2.8 3.0 DEC3100 Ultrix4.2 n/a 200. n/a 242. DEC3100 Aegis 2.1 2.1 2.1 2.3 Emulation of sub-page protection [97]. Many applications would benefit from a page size smaller than that provided by current machines <ref> [5] </ref>. Efficient page-protection traps. These exceptions are used by applications such as distributed shared memory systems, persistent object stores and garbage collectors [97, 5]. Instruction emulation. The efficient emulation of privileged instructions is crucial for application-level OS emulation via direct execution. Unbounded data-structures. <p> DEC3100 Aegis 2.1 2.1 2.1 2.3 Emulation of sub-page protection [97]. Many applications would benefit from a page size smaller than that provided by current machines [5]. Efficient page-protection traps. These exceptions are used by applications such as distributed shared memory systems, persistent object stores and garbage collectors <ref> [97, 5] </ref>. Instruction emulation. The efficient emulation of privileged instructions is crucial for application-level OS emulation via direct execution. Unbounded data-structures. Efficient unaligned pointer traps can be used to implement conditional signals of various flavors. <p> Finally, Subsection 4.6.7 provides a number of micro-benchmark measurements of VM system and the cost of application-level virtual memory. Additional examples of inadequate operating system support for application-level virtual memory primitives can be found in <ref> [5] </ref>. <p> Fine-grained control over virtual memory attributes. Giving applications access to the full complement of hardware facilities allows precise control of page information (e.g., reference bits, page-size, caching attributes, etc.). Reference bits can be used to track writes to memory pages (useful for garbage-collectors <ref> [5] </ref>). Application-controlled caching can be used to reduce cache pollution by disabling caching for memory that exhibits poor locality. <p> An application level virtual memory library allows this operation to be done much more readily. Aliasing. Many operations such as garbage collection benefit from aliasing <ref> [5] </ref>. For example, aliasing allows a garbage collector to map the same physical page using different virtual memory attributes: the mapping in the mutator's space can be read-protected, while the mapping in the collector's space has normal protections. <p> trade-off that, if done in application space, allows virtual memory implementations to be tuned to a specific application domain, rather than forcing all applications to use a general-purpose implementation. 4.6.7 Virtual memory experiments We compare Aegis and ExOS to Ultrix on seven virtual memory experiments, based upon those listed in <ref> [5] </ref>: dirty: Measures the time to query whether a page is "dirty" or not. Since it does not require examination of the TLB, this measurement is used to test the base cost of looking up a virtual address in ExOS's page-table structure. <p> Involves updating the page-table and modifying the TLB and STLB entries. trap: Time to take a page-protection trap. appel1: Time to access a random protected page and in the fault-handler, protect some other page and unprotect the faulting page (this benchmark is "prot1+trap+unprot" in Appel et al. <ref> [5] </ref>). 86 Machine OS dirty (un)prot1 prot100 unprot100 trap appel1 appel2 DEC2100 Ultrix4.2 n/a 51.6 175. 175. 297. 438. 392. DEC2100 Aegis 17.5 32.5 213. 275. 13.9 74.4 45.9 DEC3100 Ultrix4.2 n/a 47.8 140. 140. 240. 370. 325. <p> DEC3100 Aegis 13.1 24.4 156. 206. 10.1 55. 34. appel2: Time to protect 100 pages, access each page in a random sequence and, in the fault-handler, unprotect the faulting page (this benchmark is "protN+trap+unprot" in Appel et al. <ref> [5] </ref>). The exokernel based virtual memory system resides entirely in application-space. The current page-table structure we use is a simple linear vector: entries are found using binary search. Obviously, these times could be greatly improved. dirty measures the time to parse the page-table for a random entry.
Reference: [6] <author> H. Assenmacher, T. Breitbach, P. Buhler, V. Hubsch, H. Peine, and R. </author> <title> Schwarz. </title> <booktitle> Meeting the application in user space. In Proceedings of the Sixth SIGOPS European Workshop, </booktitle> <pages> pages 82-87, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: For example, usage of the low-level kernel interface is typically restricted to highly privileged servers, which are expected to be cooperative during resource allocation and deallocation. 90 5.2.1 The pico kernel The pico kernel attempts to provide a minimal set of abstractions: virtual processors and protection domains <ref> [6] </ref>. As with the other minimal, abstraction-based kernels, the main difference between it and an exokernel is that it is abstraction-based: instead of concentrating solely on multiplexing and exporting the whole of hardware functionality, it attempts to provide a small set of abstractions.
Reference: [7] <author> O. Babaoglu and W. Joy. </author> <title> Converting a swap-based system to do paging in an architecture lacking page-referenced bits. </title> <booktitle> In Proceedings of the Eighth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 78-86, </pages> <address> Pacific Grove, CA, </address> <month> December </month> <year> 1981. </year>
Reference-contexts: Furthermore, any application can do this at any time: no special dedicated hardware is needed. Exposure of memory attributes. For example, reference counting and dirty bits can be simulated in software, once applications have access to TLB exceptions <ref> [7] </ref>. Monitoring translation hardware. TLB access patterns can be used to derive working sets, or to deduce which pages take frequent TLB misses; this enables techniques such as page-migration [19]. Knowledge about TLB misses is also useful because they approximate cache misses [19].
Reference: [8] <author> Mary L. Bailey, Burra Gopal, Michael A. Pagels, Larry L. Peterson, and Prasenjit Sarkar. PATHFINDER: </author> <title> A pattern-based packet classifier. </title> <booktitle> In Proceedings of the First Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 115-123, </pages> <year> 1994. </year>
Reference-contexts: Lack of statement ordering enables aggressive inter-filter optimizations, since functional equivalence is no longer obscured by structural artifacts. dpf is not the first declarative language for packet-filters. However, the other declarative packet filter language that we know of (described in Bailey et al. <ref> [8] </ref>) does not utilize the 44 power of declarative specifications: predicates are not re-arranged to increase commonalities and similar inter-filter "suffixes" are not utilized [77]. Once a destination process is found for a packet, the problem then becomes where to put the message.
Reference: [9] <author> K. Bala, M.F. Kaashoek, and W.E. Weihl. </author> <title> Software prefetching and caching for translation lookaside buffers. </title> <booktitle> In Proceedings of the First Symposium on OSDI, </booktitle> <pages> pages 243-253, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: For example, checking the access rights to a given physical page on a TLB miss can add significant overhead to virtual memory management but can be directly countered through the use of a software TLB to handle hardware TLB capacity misses <ref> [9, 49] </ref>. We believe that the global effect of the flexibility and efficiency of application-specific resource management will outweigh the micro-costs of its use. Again, the experiments in Chapter 4 provide provisional assurance that this assumption is correct. <p> There are two places where Aegis virtualizes a resource. The first is the TLB: because access checks would add a large overhead to each TLB miss, Aegis overlays the hardware TLB with a larger software TLB <ref> [9, 49] </ref> to absorb capacity misses. The second area is the network interface, which requires virtualization in order to multiplex; the specifics of this virtualization are discussed in Section 2.7. <p> The exokernel checks that the given capability corresponds to the access rights requested by the application. If so, the mapping is installed in the TLB and software TLB (STLB) <ref> [9, 49] </ref>; control is then returned to the application. Otherwise an error is returned. 4. The application performs cleanup and resumes execution. The obvious challenge in supporting application-level virtual memory is making it fast. <p> Otherwise an error is returned. 4. The application performs cleanup and resumes execution. The obvious challenge in supporting application-level virtual memory is making it fast. We accomplish this by overlaying the hardware TLB with a large software TLB (STLB) to absorb capacity misses <ref> [9, 49] </ref>. On a TLB miss, Aegis first checks to see whether the required mapping is in the STLB; if so, Aegis installs it and resumes execution. Otherwise, the miss is forwarded to the application. <p> We give some examples here. TLB prefetching. If TLB penalties increase, TLB prefetching will become important <ref> [9] </ref>. Exposing the TLB to applications allows them to do this optimization simply and directly. Appropriate page replacement policy. Since the exokernel allows applications to control paging, they can can implement an application-specific paging policy (e.g., LRU, MRU, by priorities, etc.).
Reference: [10] <author> Thomas Ball and James R. Larus. </author> <title> Optimally profiling and tracing programs. </title> <booktitle> In Proceedings of the 19th Annual Symposium on Principles of Programming Languages, </booktitle> <pages> pages 59-70, </pages> <address> Albequerque, New Mexico, </address> <month> January </month> <year> 1992. </year>
Reference-contexts: This technique is much more efficient than a deterministic method such as described by Larus <ref> [10] </ref>; furthermore, it does not require compiler support. 4.2.4 Experiments We verify that the use of prologue and epilogue code does not introduce noticeable overhead. This can be seen in Figure 4-2, which measured the time to perform a function call ten million calls.
Reference: [11] <author> R. Bedichek. </author> <title> Private Communication, </title> <month> December </month> <year> 1994. </year> <month> 99 </month>
Reference-contexts: In this manner, very little code must be mapped and exceptions are handled extremely quickly. Variants of the above method has been used by Bedichek <ref> [11] </ref> and Thekkath [96]. An alternative solution is to return control using the kernel. Given the exokernel's efficient system call dispatching, this method may not be unacceptable for real applications. 3.6.3 Time-sharing As discussed previously, Aegis calls application-supplied prologue and epilogue code on time-slice initiation and completion, respectively.
Reference: [12] <author> B. N. Bershad. </author> <title> High performance cross-address space communication. </title> <type> Technical Report 90-06-02 (PhD Thesis), </type> <institution> University of Washington, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: In a more mature implementation the kernel will simply context-switch the application "by hand." 3.2.4 Upcalls Aegis provides an upcall [25] mechanism as a substrate for implementing efficient IPC mechanisms (e.g., <ref> [12, 48, 67] </ref>). An upcall is a light-weight, cross-domain calling mechanism. <p> The lack of difference should be attributed to the fact that the time-quanta (15.625 milliseconds) is fairly large relative to the extra overhead induced by allowing applications themselves to context switch. 4.3 IPC Fast IPC is crucial for a efficient, decoupled system <ref> [12, 48, 67] </ref>. As described in Chapter 3, the Aegis upcall mechanism is an efficient substrate for implementing fast IPC mechanisms. We enumerate some IPC mechanisms that can be constructed on top of it. Trusted LRPC. IPC to a trusted domain can be optimized. <p> Because the machine state of current RISC machines is growing larger [76], this optimization is crucial for good performance. Efficient LRPC. As we show by experiment, the efficiency of the upcall mechanism can be used to implement a very efficient RPC with traditional semantics <ref> [12] </ref>. 4.3.1 IPC Experiments Measurements section IPC is measured in four ways: upcall: measures the "bare-bones" cost of the exokernel's upcall mechanism.
Reference: [13] <author> B.N. Bershad, C. Chambers, S. Eggers, C. Maeda, D. McNamee, P. Pardyak, S. Savage, and E. Sirer. </author> <title> SPIN an extensible microkernel for application-specific operating system services. </title> <type> TR 94-03-03, </type> <institution> Univ. of Washington, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: This search, spanning the last three decades, has been aggressive and vigorous but, unfortunately, has not been satisfactorily resolved <ref> [13, 22, 36, 43, 63, 72] </ref>. In this thesis we propose a new operating system structure that dramatically departs from previous work. An exokernel eliminates the notion that an operating system should provide abstractions on which applications are built. <p> Instead, it concentrates solely on multiplexing the raw hardware: from these hardware primitives, application-level libraries and servers can directly implement traditional operating system abstractions, specialized for appropriateness and speed. 1.1 The Problem The cost of inappropriate, inefficient operating system abstractions has had a large impact on applications <ref> [5, 13, 44, 45, 72, 91, 97] </ref>. This situation has persisted for the last three decades, and has survived numerous assaults (e.g., object-oriented operating systems and micro-kernels). Any concept that cannot be realized after such a long period of time should be reexamined. <p> For example, once the application has no access to the raw disk interface, database records must be emulated on top of files: further examples of conflicts between OS-provided abstractions and what applications require can be found in the literature <ref> [5, 13, 44, 45, 72, 91, 97] </ref>. The abstractions of modern operating systems hide useful information and capabilities. <p> Exception propagation is done in a direct manner by saving a few scratch registers in some agreed-upon location in application-space and then jumping to an application-specified PC-address [97]. All of these operations can be sped up by downloading application code into the kernel <ref> [13, 36] </ref>. This implementation techniques aside, the full functionality provided by the underlying hardware should be exposed. For instance reference bits, the ability to disable caching on a page-basis, the ability to use different page sizes, etc. should all be available for application-level control. <p> With the ability to download application code into the kernel, these operations would be unnecessary. Interestingly, the ability to download code into the kernel <ref> [13, 31, 36, 104] </ref> would simplify the interface: Aegis would not have to provide all "reasonable" machine instructions and their aggregates but, instead, would just make the underlying hardware securely visible to applications. <p> In addition, he does not report on an implementation of his ideas. Nevertheless, this paper can be considered a first step in the direction of an exokernel architecture. 5.5 SPIN The SPIN project investigates adaptable kernels that allow applications to make policy decisions efficiently <ref> [13] </ref>. The SPIN system encapsulates policies in spindles that can be dynamically loaded into the kernel. To ensure safety, spindles will be written in a pointer-safe language and will be translated by a trusted compiler. <p> Current attempts include Scout [44], Bridge [69], and Vino [87]. Some of the techniques used in these systems, such as type-safe languages <ref> [13, 36, 74, 81] </ref> and software fault-isolation [31, 104], are also applicable to exokernels.
Reference: [14] <author> B.N. Bershad, D. Lee, T.H. Romer, and J.B. Chen. </author> <title> Avoiding conflict misses dynamically in large direct-mapped caches. </title> <booktitle> In Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VI), </booktitle> <year> 1994. </year>
Reference-contexts: The simplest bootstrapping mechanism is to provide a small number of "guaranteed mappings" that can be used to map the page-table and exception handling code. Physical memory allocation should support requests for a given page number (enabling such techniques as "page-coloring" for improved caching <ref> [14] </ref>). Privileged instructions (e.g., flush, probe, and modify instructions) can be wrapped in systems calls, and those that write to privileged state (e.g., TLB write instructions) are associated with access checks. <p> Cache conscious data layout. Control over the physical page numbers allows cache-conscious layout of data on systems with physically mapped caches <ref> [14, 18, 45] </ref>. For example, "page-recoloring" can be used to reduce cache conflicts [17]. This method is further assisted by the ability of applications to approximate the working set using TLB snapshots [83]. Contiguous physical page sequences. Applications can use this exokernel-bestowed ability to request specific physical pages.
Reference: [15] <author> B.N. Bershad, D.D. Redell, and J.R. Ellis. </author> <title> Fast mutual exclusion for uniprocessors. </title> <booktitle> In Proc. of the Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 223-237, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Placing context-switching under application control (through the application-defined prologue and epilogue code) enables techniques such as moving the program counter out of critical sections at context-switch time <ref> [15] </ref>. <p> For example, it allows efficient uni-processor synchronization through critical-section aware context-switching code that can "pc-luser" the program counter out of critical sections at context-switching time <ref> [15] </ref>. Fine-grained PC-sampling.
Reference: [16] <author> Brian N. Bershad. </author> <title> Private Communication, </title> <month> December </month> <year> 1994. </year>
Reference-contexts: This can be seen in the current crop of inter-filter optimizers, which requires that filters be textually equal from their initial statement onward in order to be grouped in equivalence classes with other, similar packet filters (indeed, filters reversed in even a single instruction are not recognized as equivalent <ref> [16] </ref>). Such a constraint is severely limiting on an exokernel system that allows multiple applications to write and install their own packets. <p> This ability directly eliminates the copying costs associated with current filter implementations. (Concurrently with our work, the SPIN project is adding active message support to the packet filter language MPF <ref> [16] </ref>.) 2.8 Global Optimization One of the most common concerns about an exokernel structure is that it disallows effective global optimization. <p> To ensure safety, spindles will be written in a pointer-safe language and will be translated by a trusted compiler. An interesting result of their implementation is the pervasive role naming can play in protection: control of what applications can name (and hence manipulate) is, effectively, protection <ref> [16] </ref>. The SPIN project is attempting to solve a different from our work. Namely, they investigate the difficult problem of how large software systems be meaningfully and reliably parameterized by untrusted applications.
Reference: [17] <author> Brian N. Bershad, Dennis Lee, Theodore H. Romer, and J. Bradley Chen. </author> <title> Avoiding conflict misses dynamically in large direct mapped caches. </title> <booktitle> In Proceedings of the Sixth International Conference on ASPLOS, </booktitle> <pages> pages 158-170, </pages> <year> 1994. </year>
Reference-contexts: Cache conscious data layout. Control over the physical page numbers allows cache-conscious layout of data on systems with physically mapped caches [14, 18, 45]. For example, "page-recoloring" can be used to reduce cache conflicts <ref> [17] </ref>. This method is further assisted by the ability of applications to approximate the working set using TLB snapshots [83]. Contiguous physical page sequences. Applications can use this exokernel-bestowed ability to request specific physical pages. This functionality can be used to construct contiguous runs of physical pages.
Reference: [18] <author> Brian K. Bray, William L. Lynch, and M. J. Flynn. </author> <title> Page allocation to reduce access time of physical pages. </title> <type> Technical Report CSL-TR-90-454, </type> <institution> Stanford University, </institution> <year> 1990. </year>
Reference-contexts: Cache conscious data layout. Control over the physical page numbers allows cache-conscious layout of data on systems with physically mapped caches <ref> [14, 18, 45] </ref>. For example, "page-recoloring" can be used to reduce cache conflicts [17]. This method is further assisted by the ability of applications to approximate the working set using TLB snapshots [83]. Contiguous physical page sequences. Applications can use this exokernel-bestowed ability to request specific physical pages.
Reference: [19] <author> Rohit Chandra, Scott Devine, Ben Verghese, Anoop Gupta, and Mendel Rosenblum. </author> <title> Scheduling and page migration for multiprocessor compute servers. </title> <booktitle> In Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VI), </booktitle> <year> 1994. </year>
Reference-contexts: For example, reference counting and dirty bits can be simulated in software, once applications have access to TLB exceptions [7]. Monitoring translation hardware. TLB access patterns can be used to derive working sets, or to deduce which pages take frequent TLB misses; this enables techniques such as page-migration <ref> [19] </ref>. Knowledge about TLB misses is also useful because they approximate cache misses [19]. Application-level operating systems can use this heuristic to decide 82 which pages to mark as uncachable, potentially improving global system performance. <p> Monitoring translation hardware. TLB access patterns can be used to derive working sets, or to deduce which pages take frequent TLB misses; this enables techniques such as page-migration <ref> [19] </ref>. Knowledge about TLB misses is also useful because they approximate cache misses [19]. Application-level operating systems can use this heuristic to decide 82 which pages to mark as uncachable, potentially improving global system performance.
Reference: [20] <author> Jeffrey S. Chase, Henry M. Levy, Michel Baker-Harvey, and Edward D. Lazowska. </author> <title> How to use a 64-bit virtual address space. </title> <type> Technical Report TR 92-03-02, </type> <institution> University of Washington, </institution> <year> 1992. </year>
Reference-contexts: For example, what operating systems support scheduler activations [4], multiple protection domains within a single-address space <ref> [20] </ref>, efficient IPC [67], or efficient and flexible virtual memory primitives [5, 45, 58]? The structure of traditional operating systems ensures that good ideas will, for the most part, remain research curiosities. <p> The ability to decouple naming from protection is also important in a single address space operating system <ref> [20] </ref>. The exokernel allows applications to define their own page-tables and to directly manipulate context identifiers. <p> Single-address space subsystems. The exokernel exports all the primitives required to construct an address space with a separate protection domain, directly enabling the application-level construction of single-address space subsystems <ref> [20, 85] </ref>. 4.5 Exceptions Fast user-level traps enable a number of intriguing applications. The exokernel structure is uniquely suited to efficiently dispatch exceptions to user space. <p> This issue comes up in single-address space operating systems: without private naming, "private data" must be relocated to global addresses at load-time <ref> [20] </ref>. With private names, this naming can be done at compile time. Control over layout. The ability to partition up virtual memory in an application specific way allows dynamically typed languages to partition their object space (type-segmentation) at different virtual memory segments, in order to have types be self-identifying [42]. <p> The use of large pages directly reduces the size of page-tables needed to map an address space. Given that address space usage has been growing at a rate of a bit and a half per year <ref> [20] </ref>, this is an important optimization. An object-based virtual memory system may find variable page size useful both in the reduction in fragmentation it can bring and in the space savings that can be had for objects larger than the base page size.
Reference: [21] <author> D.L. Chaum and R.S. Fabry. </author> <title> Implementing capability-based protection using encryption. </title> <type> Technical Report UCB/ERL M78/46, </type> <institution> University of California at Berkeley, </institution> <month> July </month> <year> 1978. </year>
Reference-contexts: In contrast, capabilities are a ticket-based approach, where possession of a ticket is taken as prima facie evidence that the principal has the right to use the resource. There are numerous capability schemes. We only consider self-authenticating capabilities, which are large numbers that are unlikely to be guessed <ref> [21] </ref>. In other words, security is achieved through obscurity. Self-authenticating capabilities allow ease of sharing and requires only simple protection machinery. Sharing is easy, since capabilities can be passed as data between principals without kernel intervention.
Reference: [22] <author> D. Cheriton and K. Duda. </author> <title> A caching model of operating system kernel functionality. </title> <booktitle> In Proceedings of the Sixth SIGOPS European Workshop, </booktitle> <month> September </month> <year> 1994. </year>
Reference-contexts: This search, spanning the last three decades, has been aggressive and vigorous but, unfortunately, has not been satisfactorily resolved <ref> [13, 22, 36, 43, 63, 72] </ref>. In this thesis we propose a new operating system structure that dramatically departs from previous work. An exokernel eliminates the notion that an operating system should provide abstractions on which applications are built. <p> A partial solution is to allow applications to mark resource instances as non-deallocatable. For example, this is done by the Cache Kernel to pin virtual memory mappings <ref> [22] </ref>. The problem then becomes how these pinned resources can be deallocated. A possible solution is to associate with every application a "swap server" that acts as a guardian. <p> As devices are added, revocation will be done at two levels: the first is a request for the given object, the second level is a demand. The abort protocol follows the "hint" protocol described above. Resources are forcibly flushed to a backing store (similar to the Caching Kernel <ref> [22] </ref>), and the application is given an exception that its revocation time was exceeded. The location of the backing store will be included as an argument to the exception. Initially, random selection will be used to select which application to revoke a resource from. <p> In the future, we will likely use an ACL scheme modeled on Lampson's "bitstrings" [62] to protect most resources (a likely exception will be disk blocks). This approach has been recently used both in SPACE [79] and in the Cache Kernel <ref> [22] </ref>. 41 2.7 Device Multiplexing Devices are difficult to multiplex: their interfaces are complex and their state extremely volatile. For example, device buffer usage can fluctuate dramatically within short amounts of time. <p> To the best of our knowlege ExOS is one of the first general-purpose library operating system implemented in a multiprogramming environment. (The Cache Kernel is investigating this approach concurrently with our work <ref> [22] </ref>.) For this reason, the implementation techniques we describe should warrent the attention of the reader. <p> This section introduces the data structures and operations that can be performed on these objects. In general the design has emphasized simplicity. For example, static allocation is used throughout the implementation, in a manner similar to <ref> [22, 78] </ref>. Also, the Aegis implementation is completely unmapped (both code and data), eliminating the complication (and inefficiency) of virtual memory. 3.3.1 Capabilities Capabilities consist of the resource name and a random sequence of bits; they are untyped and may be passed freely as data. <p> An interesting result of the Raven work is that they have found that simply lowering the kernel interface increases efficiency, since applications do not have to explicitly communicate with the kernel for many operations. 5.3 The Cache Kernel The Cache Kernel <ref> [22] </ref> is a low-level kernel that adheres to some of our precepts for a model operating system. The difference between the Cache Kernel and Aegis is mainly one of high-level philosophy: the Cache Kernel focuses primarily on reliability, rather than securely exporting hardware resources to applications.
Reference: [23] <author> D. R. Cheriton. </author> <title> An experiment using registers for fast message-based interprocess communication. </title> <journal> Operating Systems Review, </journal> <volume> 18 </volume> <pages> 12-20, </pages> <month> [10] </month> <year> 1984. </year>
Reference-contexts: Among their advantages, these properties allow the vast register state of modern processors to be used as a temporary message buffer <ref> [23] </ref>. Currently, our synchronous upcall implementation costs 30 instructions. Because Aegis implements the bare minimum required for any IPC mechanism, applications can pay for just the functionality they require. This is a very important property, since it allows IPC to be optimized for application-specific conditions.
Reference: [24] <author> D. R. Cheriton, G. R. Whitehead, and E. W. Sznyter. </author> <title> Binary emulation of unix using the v kernel. </title> <booktitle> Proceedings of the Summer 1990 USENIX Conference, </booktitle> <pages> pages 73-85, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Furthermore, this decoupling is critical for backwards compatibility since it allows the operating system to be developed in a totally separate environment from applications: to use a new operating system implementation, applications do not have to be re-linked (e.g., binary compatibility can be achieved by radically different operating system implementations <ref> [24] </ref>). There are a number of ways that exokernel-based systems can realize these same benefits. 46 The first is that a library operating system can use system call forwarding to communicate with an application strictly through a system call interface.
Reference: [25] <author> D.D. Clark. </author> <title> On the structuring of systems using upcalls. </title> <booktitle> In Proceedings of the Tenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 171-180, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: The time the application has to save its state is bounded: if this limit is exceeded, Aegis destroys the application. In a more mature implementation the kernel will simply context-switch the application "by hand." 3.2.4 Upcalls Aegis provides an upcall <ref> [25] </ref> mechanism as a substrate for implementing efficient IPC mechanisms (e.g., [12, 48, 67]). An upcall is a light-weight, cross-domain calling mechanism.
Reference: [26] <author> Eric Cooper, Robert Harper, and Peter Lee. </author> <title> The Fox project: Advanced development of systems software. </title> <type> Technical Report CMU-CS-91-178, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA 15213, </address> <year> 1991. </year> <month> 100 </month>
Reference-contexts: Unfortunately, current OS implementations do not support this optimization, and therefore garbage-collection results in a "flurry" of I/O activity, because the OS VM system does not realize that while the page has indeed been modified, it contains garbage and so does not need to be stored to disk <ref> [26] </ref>. 84 Page-prefetching. A scientific application may follow well-defined access patterns, allowing it to predict which pages will be needed [45]. Accurate "in core" information. Accurate knowledge of which pages are resident in memory can be useful to many types of applications.
Reference: [27] <author> R. J. Creasy. </author> <title> The origin of the VM/370 time-sharing system. </title> <journal> IBM J. Research and Development, </journal> <volume> 25(5) </volume> <pages> 483-490, </pages> <month> September </month> <year> 1981. </year>
Reference-contexts: Since its inception, the field of operating systems has been attempting to identify an appropriate structure: from familiar monolithic [99, 103] to micro-kernel operating systems [2, 43] to more exotic language-based [81] and virtual machine <ref> [27, 40] </ref> operating systems. This search, spanning the last three decades, has been aggressive and vigorous but, unfortunately, has not been satisfactorily resolved [13, 22, 36, 43, 63, 72]. In this thesis we propose a new operating system structure that dramatically departs from previous work. <p> For instance, VM/370 provided each user with a virtual machine detailed to the level of devices and privileged instructions <ref> [27] </ref>, consumed significant resources in the process and, as discussed previously, did not allow much more actual distributed control than a traditional operating system. 33 However, there are particular cases where virtualization is either unavoidable or can dramatically improve performance. <p> We view the SPIN project complementary to our exokernel research, and we hope to directly use their results to optimize application-level operating systems. 5.6 VM/370 The interface provided by the VM/370 operating system <ref> [27] </ref> is very similar to what would be provided by our ideal OS: namely, the raw hardware. However, the important difference is that VM/370 provides this interface by virtualizing the entire base-machine.
Reference: [28] <author> H. Custer. </author> <title> Inside Windows/NT. </title> <publisher> Microsoft Press, </publisher> <address> Redmond, WA, </address> <year> 1993. </year>
Reference-contexts: If the exokernel ideas work in practice, these layers could aid the transition from traditional operating system structures to more flexible, efficient and simple exokernels. In the future, we hope to perform such a transformation on the codified HAL of Windows/NT <ref> [28] </ref> 5.9 Extensible Operating Systems Many early operating systems papers discussed the need for extendible, flexible kernels [50, 65, 81, 107, 108]. Lampson's description of the CAL-TSS [60, 63] and Brinch Hansen's microkernel paper [43] are two classic rationales. <p> Lampson's description of the CAL-TSS [60, 63] and Brinch Hansen's microkernel paper [43] are two classic rationales. Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets [108]. Modern revisitations of microkernels have also argued for kernel extensibility <ref> [1, 80, 84, 95, 28] </ref>. Anderson and Kiczales et al. also recently argued for minimalism and customizable [3, 56].
Reference: [29] <author> R.H. Halstead D.A. Kranz and E. Mohr. Mul-t: </author> <title> A high-performance parallel lisp. </title> <booktitle> In Proceedings of the SIGPLAN '89 Conference on Programming Language Design and Implementation, </booktitle> <year> 1989. </year>
Reference-contexts: Instruction emulation. The efficient emulation of privileged instructions is crucial for application-level OS emulation via direct execution. Unbounded data-structures. Efficient unaligned pointer traps can be used to implement conditional signals of various flavors. For example, futures <ref> [29] </ref> can be implemented efficiently using unaligned pointer traps: the pointer of an unresolved future to its value is made to be unaligned. References to an outstanding future will trap, and the accessing thread can then be suspended.
Reference: [30] <author> Wiebren de Jonge, M. Frans Kaashoek, and Wilson C. Hsieh. </author> <title> The logical disk: A new approach to improving file systems. </title> <booktitle> In Proceedings of the Thirteenth ACM Symposium on Operating Systems Principles, </booktitle> <year> 1993. </year>
Reference-contexts: The use of virtual naming allows some operating system optimizations that are otherwise difficult. For instance, disk compaction is very easy with the use of virtual names, since applications and higher-level filesystems do not need to be involved in the process <ref> [30] </ref>. However, the use of such a "logical disk" to map disk blocks can require over 4 megabytes of physical memory for disks of even moderate size [30]. <p> is very easy with the use of virtual names, since applications and higher-level filesystems do not need to be involved in the process <ref> [30] </ref>. However, the use of such a "logical disk" to map disk blocks can require over 4 megabytes of physical memory for disks of even moderate size [30]. Summary The cost of virtual naming is the associated loss of information and the computation required to map the virtual name to the corresponding physical name.
Reference: [31] <author> P. Deutsch and C.A. Grant. </author> <title> A flexible measurement tool for software systems. </title> <booktitle> Information Processing 71, </booktitle> <year> 1971. </year>
Reference-contexts: A more "low-tech" approach is to allow a window server process to download pieces of code into the kernel; these pieces can be called by applications to perform operations that they require. Protection can be ensured by bounding memory operations and jumps [104] and by limiting resource consumption <ref> [31] </ref> (e.g., CPU time and memory). The window server can use this capability to allow the applications themselves to write code fragments (say to implement a particular clipping algorithm) that it can check for safety and then download into the kernel. <p> With the ability to download application code into the kernel, these operations would be unnecessary. Interestingly, the ability to download code into the kernel <ref> [13, 31, 36, 104] </ref> would simplify the interface: Aegis would not have to provide all "reasonable" machine instructions and their aggregates but, instead, would just make the underlying hardware securely visible to applications. <p> Current attempts include Scout [44], Bridge [69], and Vino [87]. Some of the techniques used in these systems, such as type-safe languages [13, 36, 74, 81] and software fault-isolation <ref> [31, 104] </ref>, are also applicable to exokernels.
Reference: [32] <author> R. Draves. </author> <title> The case for run-time replaceable kernel modules. </title> <booktitle> In Fourth Workshop on Workstation Operating Systems, </booktitle> <pages> pages 160-165, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Draves has argued for selecting among several implementations of a specific kernel abstraction to allow customization <ref> [32] </ref>.
Reference: [33] <author> Richard Draves. </author> <title> Private Communication, </title> <month> December </month> <year> 1994. </year>
Reference-contexts: To avoid the worst-case behavior of a direct mapped STLB, we will likely move to a two-way set-associative structure as the implementation matures (as is used in Rialto <ref> [33] </ref> and PA-RISC operating systems [49]). Another alternative is the use of a "victim cache" [52] to absorb STLB conflicts. As noted in Huck [49], avoiding cache misses is crucial for efficient TLB replacement. This constraint can have a noticeable impact on TLB lookup.
Reference: [34] <author> Peter Druschel, Larry L. Peterson, and Bruce S. Davie. </author> <title> Experiences with a high-speed network adaptor: A software perspective. </title> <booktitle> In SIGCOMM`94, </booktitle> <pages> pages 2-13, </pages> <year> 1994. </year>
Reference-contexts: Sending is simpler; we consider it first. Multiplexing the send capabilities of the network device is simply a matter of multiplexing send buffers. With simple hardware support, this is fairly easy to achieve. For example, one solution (suggested by Druschel <ref> [34] </ref>) is to map a send buffer into the address space of each process. These buffers can be allocated/shared/revoked in a manner analogous to physical memory. Demultiplexing messages is a more difficult problem, since it requires associating a string of bits with protocol-specific meaning. <p> Contiguous physical page sequences. Applications can use this exokernel-bestowed ability to request specific physical pages. This functionality can be used to construct contiguous runs of physical pages. These blocks can be used to construct super-pages [94] and to improve the efficiency of DMA operations <ref> [34] </ref>. Cache multiplexing.
Reference: [35] <author> D. R. Engler, M. F. Kaashoek, and J. O'Toole. </author> <title> The exokernel approach to extensibility (abstract). </title> <booktitle> In Proceedings of the First Symposium on OSDI, </booktitle> <month> November </month> <year> 1994. </year>
Reference: [36] <author> D. R. Engler, M. F. Kaashoek, and J. O'Toole. </author> <title> The operating system kernel as a secure programmable machine. </title> <booktitle> In Proceedings of the Sixth SIGOPS European Workshop, </booktitle> <month> September </month> <year> 1994. </year>
Reference-contexts: This search, spanning the last three decades, has been aggressive and vigorous but, unfortunately, has not been satisfactorily resolved <ref> [13, 22, 36, 43, 63, 72] </ref>. In this thesis we propose a new operating system structure that dramatically departs from previous work. An exokernel eliminates the notion that an operating system should provide abstractions on which applications are built. <p> Exception propagation is done in a direct manner by saving a few scratch registers in some agreed-upon location in application-space and then jumping to an application-specified PC-address [97]. All of these operations can be sped up by downloading application code into the kernel <ref> [13, 36] </ref>. This implementation techniques aside, the full functionality provided by the underlying hardware should be exposed. For instance reference bits, the ability to disable caching on a page-basis, the ability to use different page sizes, etc. should all be available for application-level control. <p> With the ability to download application code into the kernel, these operations would be unnecessary. Interestingly, the ability to download code into the kernel <ref> [13, 31, 36, 104] </ref> would simplify the interface: Aegis would not have to provide all "reasonable" machine instructions and their aggregates but, instead, would just make the underlying hardware securely visible to applications. <p> Current attempts include Scout [44], Bridge [69], and Vino [87]. Some of the techniques used in these systems, such as type-safe languages <ref> [13, 36, 74, 81] </ref> and software fault-isolation [31, 104], are also applicable to exokernels.
Reference: [37] <author> D. R. Engler, M. F. Kaashoek, and J. O'Toole. </author> <title> The operating system kernel as a secure programmable machine. </title> <booktitle> In Operating systems review, </booktitle> <month> January </month> <year> 1995. </year>
Reference: [38] <author> Dawson R. Engler, Wilson C. Hsieh, and M. Frans Kaashoek. </author> <title> `C: A language for high-level, efficient, and machine-independent dynamic code generation. </title> <note> Submitted for publication. </note>
Reference-contexts: We expect to use dynamic code generation pervasively in the optimization of application-level operating systems; the main difference will be our reliance on portable, high-level methods for generating code on the fly (e.g., as described in <ref> [39, 38] </ref>). 5.8 HAL Many operating systems have a hardware abstraction layer. If the exokernel ideas work in practice, these layers could aid the transition from traditional operating system structures to more flexible, efficient and simple exokernels.
Reference: [39] <author> D.R. Engler and T.A. Proebsting. </author> <title> DCG: An efficient, retargetable dynamic code generation system. </title> <booktitle> Proceedings of ASPLOS-VI, </booktitle> <pages> pages 263-272, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Since each filter must be applied to each message, computation rises linearly with the number of packet-filters installed. Fortunately, there are very effective optimizations that can counter the cost of using packet-filters. We look at both intra-filter <ref> [39] </ref> and inter-filter [109] optimizations. The most effective intra-filter optimization is to dynamically generate the machine code corresponding to the filter. Our prototype implementation shows that compiled packet filters execute an order of magnitude more efficiently than when interpreted [39]. <p> We look at both intra-filter <ref> [39] </ref> and inter-filter [109] optimizations. The most effective intra-filter optimization is to dynamically generate the machine code corresponding to the filter. Our prototype implementation shows that compiled packet filters execute an order of magnitude more efficiently than when interpreted [39]. Thekkath suggests this optimization in [98], but does not implement it. Inter-filter optimizations revolve around the recognition of commonalities between filters: many filters look for similar packets (e.g., TCP, UDP, etc.) and therefore have large overlap [109]. <p> We expect to use dynamic code generation pervasively in the optimization of application-level operating systems; the main difference will be our reliance on portable, high-level methods for generating code on the fly (e.g., as described in <ref> [39, 38] </ref>). 5.8 HAL Many operating systems have a hardware abstraction layer. If the exokernel ideas work in practice, these layers could aid the transition from traditional operating system structures to more flexible, efficient and simple exokernels.
Reference: [40] <author> R. Goldberg. </author> <title> Architecture of virtual machines. </title> <booktitle> 1973 NCC AFIPS Conf. Proc., </booktitle> <volume> 42 </volume> <pages> 309-318, </pages> <year> 1973. </year>
Reference-contexts: Since its inception, the field of operating systems has been attempting to identify an appropriate structure: from familiar monolithic [99, 103] to micro-kernel operating systems [2, 43] to more exotic language-based [81] and virtual machine <ref> [27, 40] </ref> operating systems. This search, spanning the last three decades, has been aggressive and vigorous but, unfortunately, has not been satisfactorily resolved [13, 22, 36, 43, 63, 72]. In this thesis we propose a new operating system structure that dramatically departs from previous work.
Reference: [41] <author> Susan L. Graham, Peter B. Kessler, and M. K. McKusick. </author> <title> gprof: a call graph execution profiler. </title> <booktitle> In Proceedings of the ACM SIGPLAN '82 Symposium on Compiler Construction, </booktitle> <pages> pages 120-126, </pages> <address> Boston, MA, </address> <month> June </month> <year> 1982. </year>
Reference-contexts: Efficient timer interrupts allow fast (and thus more fine-grained) PC-sampling, a profiling technique based on the simple observation that, since the program counter will most frequently have values on the critical path, recording (or sampling) the program counter values at each timer-interrupt can closely approximate actual execution time <ref> [41] </ref>. This technique is much more efficient than a deterministic method such as described by Larus [10]; furthermore, it does not require compiler support. 4.2.4 Experiments We verify that the use of prologue and epilogue code does not introduce noticeable overhead.
Reference: [42] <author> David Gudeman. </author> <title> Representing type information in dynamically typed languages. </title> <type> Technical Report TR 93-27, </type> <institution> University of Arizona, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: With private names, this naming can be done at compile time. Control over layout. The ability to partition up virtual memory in an application specific way allows dynamically typed languages to partition their object space (type-segmentation) at different virtual memory segments, in order to have types be self-identifying <ref> [42] </ref>. An application level virtual memory library allows this operation to be done much more readily. Aliasing. Many operations such as garbage collection benefit from aliasing [5].
Reference: [43] <author> Per Brinch Hansen. </author> <title> The nucleus of a multiprogramming system. </title> <journal> Communications of the ACM, </journal> <volume> 13(4) </volume> <pages> 238-241, </pages> <month> April </month> <year> 1970. </year> <month> 101 </month>
Reference-contexts: Therefore, its structure has a dramatic impact on the performance and the scope of applications that can be built on it. Since its inception, the field of operating systems has been attempting to identify an appropriate structure: from familiar monolithic [99, 103] to micro-kernel operating systems <ref> [2, 43] </ref> to more exotic language-based [81] and virtual machine [27, 40] operating systems. This search, spanning the last three decades, has been aggressive and vigorous but, unfortunately, has not been satisfactorily resolved [13, 22, 36, 43, 63, 72]. <p> This search, spanning the last three decades, has been aggressive and vigorous but, unfortunately, has not been satisfactorily resolved <ref> [13, 22, 36, 43, 63, 72] </ref>. In this thesis we propose a new operating system structure that dramatically departs from previous work. An exokernel eliminates the notion that an operating system should provide abstractions on which applications are built. <p> Lampson's description of the CAL-TSS [60, 63] and Brinch Hansen's microkernel paper <ref> [43] </ref> are two classic rationales. Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets [108]. Modern revisitations of microkernels have also argued for kernel extensibility [1, 80, 84, 95, 28].
Reference: [44] <author> J.H. Hartman, A.B. Montz, David Mosberger, S.W. O'Malley, L.L. Peterson, and T.A. Proebsting. </author> <title> Scout: A communication-oriented operating system. </title> <type> Technical Report TR 94-20, </type> <institution> University of Arizona, </institution> <address> Tucson, AZ, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Instead, it concentrates solely on multiplexing the raw hardware: from these hardware primitives, application-level libraries and servers can directly implement traditional operating system abstractions, specialized for appropriateness and speed. 1.1 The Problem The cost of inappropriate, inefficient operating system abstractions has had a large impact on applications <ref> [5, 13, 44, 45, 72, 91, 97] </ref>. This situation has persisted for the last three decades, and has survived numerous assaults (e.g., object-oriented operating systems and micro-kernels). Any concept that cannot be realized after such a long period of time should be reexamined. <p> For example, once the application has no access to the raw disk interface, database records must be emulated on top of files: further examples of conflicts between OS-provided abstractions and what applications require can be found in the literature <ref> [5, 13, 44, 45, 72, 91, 97] </ref>. The abstractions of modern operating systems hide useful information and capabilities. <p> The most important difference between our work and previous approaches is the explicit view that the operating system should not provide abstractions; as a result the interface in these systems is a much higher one (e.g., page-tables are implemented by the kernel). Current attempts include Scout <ref> [44] </ref>, Bridge [69], and Vino [87]. Some of the techniques used in these systems, such as type-safe languages [13, 36, 74, 81] and software fault-isolation [31, 104], are also applicable to exokernels.
Reference: [45] <author> K. Harty and D.R. Cheriton. </author> <title> Application-controlled physical memory using external page-cache management. </title> <booktitle> In Proceedings of the Fifth International Conference on ASPLOS, </booktitle> <pages> pages 187-199, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Instead, it concentrates solely on multiplexing the raw hardware: from these hardware primitives, application-level libraries and servers can directly implement traditional operating system abstractions, specialized for appropriateness and speed. 1.1 The Problem The cost of inappropriate, inefficient operating system abstractions has had a large impact on applications <ref> [5, 13, 44, 45, 72, 91, 97] </ref>. This situation has persisted for the last three decades, and has survived numerous assaults (e.g., object-oriented operating systems and micro-kernels). Any concept that cannot be realized after such a long period of time should be reexamined. <p> For example, what operating systems support scheduler activations [4], multiple protection domains within a single-address space [20], efficient IPC [67], or efficient and flexible virtual memory primitives <ref> [5, 45, 58] </ref>? The structure of traditional operating systems ensures that good ideas will, for the most part, remain research curiosities. In an exokernel based system, these mechanisms can be implemented directly at application-level without special privileges, and without compromising system integrity. <p> For example, once the application has no access to the raw disk interface, database records must be emulated on top of files: further examples of conflicts between OS-provided abstractions and what applications require can be found in the literature <ref> [5, 13, 44, 45, 72, 91, 97] </ref>. The abstractions of modern operating systems hide useful information and capabilities. <p> Cache conscious data layout. Control over the physical page numbers allows cache-conscious layout of data on systems with physically mapped caches <ref> [14, 18, 45] </ref>. For example, "page-recoloring" can be used to reduce cache conflicts [17]. This method is further assisted by the ability of applications to approximate the working set using TLB snapshots [83]. Contiguous physical page sequences. Applications can use this exokernel-bestowed ability to request specific physical pages. <p> A scientific application may follow well-defined access patterns, allowing it to predict which pages will be needed <ref> [45] </ref>. Accurate "in core" information. Accurate knowledge of which pages are resident in memory can be useful to many types of applications. For example, a scientific program manipulating large matrices could work on those pieces that are "in core", while prefetching others. <p> Finally, this information is critical to real-time applications, which must meet deadlines and cannot be subject to the vagaries of current VM systems. Pinning pages. Predicating that certain pages are pinned in memory before proceeding can allow real-time applications to calculate and meet tighter deadlines <ref> [45] </ref>. Furthermore, control over which pages are paged-out can allow applications to exploit application-specific knowledge over what pages should reside in main memory. For instance, a database management system could ensure that critical pages, such as those containing directories, reside in physical memory [45]. 4.6.5 Page size Trade offs Increasing or <p> applications to calculate and meet tighter deadlines <ref> [45] </ref>. Furthermore, control over which pages are paged-out can allow applications to exploit application-specific knowledge over what pages should reside in main memory. For instance, a database management system could ensure that critical pages, such as those containing directories, reside in physical memory [45]. 4.6.5 Page size Trade offs Increasing or decreasing the page size that is being mapped affects the amount of memory needed to map a virtual address space, the base unit of protection available, the working-set size [75, 93], and the frequency of TLB faults [75, 93, 94].
Reference: [46] <author> G. J. Henry. </author> <title> The fair share scheduler. </title> <journal> AT&T Bell Laboratories Technical Journal, </journal> <month> October </month> <year> 1984. </year>
Reference-contexts: Revocation is done when resource usage exceeds a specified threshold. Which instance of the resource to revoke and who to revoke it from are highly system dependent. For example, on a system with proportional sharing [105], this determination will be made differently than on a "fair-share" system <ref> [46, 55] </ref>. As discussed later, Aegis will allow this to be parameterized on a system-wide basis. We discuss the default mechanism below. As devices are added, revocation will be done at two levels: the first is a request for the given object, the second level is a demand.
Reference: [47] <author> D. Hildebrand. </author> <title> An architectural overview of QNX. </title> <booktitle> In Proceedings of the Usenix Workshop on Micro-kernels and Other Kernel Architectures, </booktitle> <month> April </month> <year> 1992. </year>
Reference-contexts: to be constructed, so it is difficult to determine their relationship to exokernels in general and Aegis in particular. 5.10 Dynamically loaded device drivers The commercial world has long looked at extensibility in the form of dynamically loaded device drivers: the QNX operating system allows user-level handlers for device I/O <ref> [47] </ref>; Chorus servers are loaded into the kernel [84]; Mach 3.0 has migrated some of the AFS cache manager back into the kernel [75]; Lepreau et. al. has provided a tool to reintroduce servers into Mach 3.0 [66].
Reference: [48] <author> W.C. Hsieh, M.F. Kaashoek, and W.E. Weihl. </author> <title> The persistent relevance of IPC performance: New techniques for reducing the IPC penalty. </title> <booktitle> In Fourth Workshop on Workstation Operating Systems, </booktitle> <pages> pages 186-190, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: In a more mature implementation the kernel will simply context-switch the application "by hand." 3.2.4 Upcalls Aegis provides an upcall [25] mechanism as a substrate for implementing efficient IPC mechanisms (e.g., <ref> [12, 48, 67] </ref>). An upcall is a light-weight, cross-domain calling mechanism. <p> The lack of difference should be attributed to the fact that the time-quanta (15.625 milliseconds) is fairly large relative to the extra overhead induced by allowing applications themselves to context switch. 4.3 IPC Fast IPC is crucial for a efficient, decoupled system <ref> [12, 48, 67] </ref>. As described in Chapter 3, the Aegis upcall mechanism is an efficient substrate for implementing fast IPC mechanisms. We enumerate some IPC mechanisms that can be constructed on top of it. Trusted LRPC. IPC to a trusted domain can be optimized. <p> Trusted LRPC. IPC to a trusted domain can be optimized. For example, a client that trusts a server may, instead of a saving and then restoring its entire register state, allow the server to save and restore the registers it needs <ref> [48] </ref>. Because the machine state of current RISC machines is growing larger [76], this optimization is crucial for good performance. Efficient LRPC.
Reference: [49] <author> J. Huck and J. Hays. </author> <title> Architectural support for translation table management in large address space machines. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <year> 1992. </year>
Reference-contexts: For example, checking the access rights to a given physical page on a TLB miss can add significant overhead to virtual memory management but can be directly countered through the use of a software TLB to handle hardware TLB capacity misses <ref> [9, 49] </ref>. We believe that the global effect of the flexibility and efficiency of application-specific resource management will outweigh the micro-costs of its use. Again, the experiments in Chapter 4 provide provisional assurance that this assumption is correct. <p> Virtualization can be used to avoid such a situation. A specific place in an exokernel where virtualization may improve performance (possibly by a substantial amount) is in increasing the size of the hardware TLB through the use of a software TLB <ref> [49] </ref>: by virtualizing the TLB to a larger size, capacity misses can be reduced, and with them, the cost of inserting a mapping into the TLB (e.g., system calls and access right checks). We measure the overhead of application-level virtual memory in Section 4.6.7. <p> There are two places where Aegis virtualizes a resource. The first is the TLB: because access checks would add a large overhead to each TLB miss, Aegis overlays the hardware TLB with a larger software TLB <ref> [9, 49] </ref> to absorb capacity misses. The second area is the network interface, which requires virtualization in order to multiplex; the specifics of this virtualization are discussed in Section 2.7. <p> The exokernel checks that the given capability corresponds to the access rights requested by the application. If so, the mapping is installed in the TLB and software TLB (STLB) <ref> [9, 49] </ref>; control is then returned to the application. Otherwise an error is returned. 4. The application performs cleanup and resumes execution. The obvious challenge in supporting application-level virtual memory is making it fast. <p> Otherwise an error is returned. 4. The application performs cleanup and resumes execution. The obvious challenge in supporting application-level virtual memory is making it fast. We accomplish this by overlaying the hardware TLB with a large software TLB (STLB) to absorb capacity misses <ref> [9, 49] </ref>. On a TLB miss, Aegis first checks to see whether the required mapping is in the STLB; if so, Aegis installs it and resumes execution. Otherwise, the miss is forwarded to the application. <p> To avoid the worst-case behavior of a direct mapped STLB, we will likely move to a two-way set-associative structure as the implementation matures (as is used in Rialto [33] and PA-RISC operating systems <ref> [49] </ref>). Another alternative is the use of a "victim cache" [52] to absorb STLB conflicts. As noted in Huck [49], avoiding cache misses is crucial for efficient TLB replacement. This constraint can have a noticeable impact on TLB lookup. <p> the worst-case behavior of a direct mapped STLB, we will likely move to a two-way set-associative structure as the implementation matures (as is used in Rialto [33] and PA-RISC operating systems <ref> [49] </ref>). Another alternative is the use of a "victim cache" [52] to absorb STLB conflicts. As noted in Huck [49], avoiding cache misses is crucial for efficient TLB replacement. This constraint can have a noticeable impact on TLB lookup. For example, currently we expend one cycle aligning the tlbctx register to 8-bytes; this instruction could be eliminated by separating the STLB tag from the entry it maps. <p> The characteristics of this function (its sparsity, the range of inputs and outputs it has to produce and the number of points it may be expected to match) have a deep impact on the appropriateness of a given structure <ref> [49] </ref>. Below we examine some specific arenas where the 85 page-table structure may be stressed. Different address space sizes. With the advent of 64-bit machines, the consideration of what address space size is appropriate for a given application should become increasingly important.
Reference: [50] <author> D.H.R. </author> <title> Huxtable and M.T. Warwick. Dynamic supervisors | their design and construction. </title> <booktitle> Proceedings of the First ACM Symposium on Operating Systems Principles, </booktitle> <year> 1967. </year>
Reference-contexts: In the future, we hope to perform such a transformation on the codified HAL of Windows/NT [28] 5.9 Extensible Operating Systems Many early operating systems papers discussed the need for extendible, flexible kernels <ref> [50, 65, 81, 107, 108] </ref>. Lampson's description of the CAL-TSS [60, 63] and Brinch Hansen's microkernel paper [43] are two classic rationales. Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets [108].
Reference: [51] <author> SPARC International. </author> <title> The SPARC Architecture Manual Verson 8. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey 07632, </address> <year> 1992. </year>
Reference-contexts: Registers are allocated "whole cloth" to each process: on the current architecture allocating specific registers to a given process is more trouble then it is worth. However, on a different architecture this might not be such an obvious decision. For instance, on a SPARC processor <ref> [51] </ref> allocating individual register windows may be useful. TLB entries and cache blocks do not have explicit owners: they can be written and read by each individual process. Aegis allows applications to issue all privileged instructions and load/store operations to memory mapped I/O devices. <p> Generally, large-page sizes allow fewer TLB misses and (possibly) smaller page-tables, but at a cost of larger working-sets and a coarse grain of protection. These trade-offs are highly application dependent, and have thus far been poorly served by existing operating systems [94]. Many machines support multiple page-sizes <ref> [54, 51, 94] </ref>. There are a number of specific ways that page size fluctuations may be useful: Reduced page-table overhead. The use of large pages directly reduces the size of page-tables needed to map an address space.
Reference: [52] <author> Norman P. Jouppi. </author> <title> Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers. </title> <booktitle> In 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 364-373, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: To avoid the worst-case behavior of a direct mapped STLB, we will likely move to a two-way set-associative structure as the implementation matures (as is used in Rialto [33] and PA-RISC operating systems [49]). Another alternative is the use of a "victim cache" <ref> [52] </ref> to absorb STLB conflicts. As noted in Huck [49], avoiding cache misses is crucial for efficient TLB replacement. This constraint can have a noticeable impact on TLB lookup.
Reference: [53] <author> M.F. Kaashoek, R. van Renesse, H. van Staveren, </author> <title> and A.S. Tanenbaum. FLIP: an internetwork protocol for supporting distributed systems. </title> <journal> ACM Trans. Comp. Syst., </journal> <volume> 11(1) </volume> <pages> 73-106, </pages> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: This approach is used in <ref> [53] </ref>. Unfortunately, networking has tremendous backwards compatibility constraints. An exuberant alternative is to treat every process as a connection point and give it its own Ethernet address [61]. This allows simple vectoring and requires no protocol changes. Unfortunately there are reasons why this cannot, in general, be done with impunity.
Reference: [54] <author> Gerry Kane and Joe Heinrich. </author> <title> MIPS RISC Architecture. </title> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference-contexts: As such the architecture for which an exokernel is designed for has a profound impact on its structure and interface. We base our exokernel on the MIPS architecture <ref> [54] </ref>; Aegis runs on the DECsta-tion/MIPS family [54]. These machines have separate instruction and data caches, software handled TLB faults, 64 context identifiers and a math coprocessor that controls floating-point operations. <p> As such the architecture for which an exokernel is designed for has a profound impact on its structure and interface. We base our exokernel on the MIPS architecture <ref> [54] </ref>; Aegis runs on the DECsta-tion/MIPS family [54]. These machines have separate instruction and data caches, software handled TLB faults, 64 context identifiers and a math coprocessor that controls floating-point operations. The machine configurations that we use are uni-processor machines with physically indexed caches, 31 general-purpose and 32 floating-point application-level registers. <p> to match any application's virtual address, it is the only capability Aegis does not export to applications. (This restriction could be lifted if Aegis flushed the TLB when context-switching from processes that used these bits.) The following special registers will be referenced to in subsequent discussion (all information taken from <ref> [54] </ref>): status : the current process status word: supervisor and user mode bits and the status of interrupts and co-processors (enabled or disabled). tlbhi : contains the context identifier used to match the virtual address with a TLB entry when virtual addresses are presented for translation. tlblo : holds the low <p> Its registers hold many useful values (e.g., the process status word, etc.). Applications can read any of these registers using this primitive operation. The specific register to be read is specified by reg, which is a flag formed by capitalizing the register name as given in <ref> [54] </ref> and prepending AE_ (e.g., AE_CONTEXT, AE_ERROR, AE_STATUS, AE_BADVADDR, etc.). int tlbwr (unsigned hi, unsigned lo, auth c) Insert the given virtual to physical translation in a pseudo-random TLB entry. <p> Generally, large-page sizes allow fewer TLB misses and (possibly) smaller page-tables, but at a cost of larger working-sets and a coarse grain of protection. These trade-offs are highly application dependent, and have thus far been poorly served by existing operating systems [94]. Many machines support multiple page-sizes <ref> [54, 51, 94] </ref>. There are a number of specific ways that page size fluctuations may be useful: Reduced page-table overhead. The use of large pages directly reduces the size of page-tables needed to map an address space.
Reference: [55] <author> J. Kay and P. Lauder. </author> <title> A fair share scheduler. </title> <journal> Communications of the ACM, </journal> <month> January </month> <year> 1988. </year>
Reference-contexts: Revocation is done when resource usage exceeds a specified threshold. Which instance of the resource to revoke and who to revoke it from are highly system dependent. For example, on a system with proportional sharing [105], this determination will be made differently than on a "fair-share" system <ref> [46, 55] </ref>. As discussed later, Aegis will allow this to be parameterized on a system-wide basis. We discuss the default mechanism below. As devices are added, revocation will be done at two levels: the first is a request for the given object, the second level is a demand.
Reference: [56] <author> G. Kiczales, J. Lamping, C. Maeda, D. Keppel, and D. McNamee. </author> <title> The need for customizable operating systems. </title> <booktitle> In Fourth Workshop on Workstation Operating Systems, </booktitle> <pages> pages 165-170, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets [108]. Modern revisitations of microkernels have also argued for kernel extensibility [1, 80, 84, 95, 28]. Anderson and Kiczales et al. also recently argued for minimalism and customizable <ref> [3, 56] </ref>. The most important difference between our work and previous approaches is the explicit view that the operating system should not provide abstractions; as a result the interface in these systems is a much higher one (e.g., page-tables are implemented by the kernel).
Reference: [57] <author> David Kotz, Song Bac Toh, and Sriram Radhakrishnan. </author> <title> A detailed simulation model of the HP 97560 disk drive. </title> <type> Technical Report PCS-TR94-220, </type> <institution> Dartmouth, </institution> <year> 1994. </year>
Reference-contexts: We believe all of these factors will encourage disk managers to wisely manage their consumption of blocks in this very attractive territory. Finally, the growing sophistication of disks will make them relatively impervious to any form of disk management (or mis-management) <ref> [57] </ref>; as such, many of the mechanisms we discuss will become irrelevant for effective disk performance. 2.9 Some Practical Considerations As discussed in Section 2.2 centralization can have a simplifying effect on the system as a whole.
Reference: [58] <author> Keith Krueger, David Loftesness, Amin Vahdat, and Thomas Anderson. </author> <title> Tools for development of application-specific virtual memory management. </title> <booktitle> In Proceedings of OOPSLA, </booktitle> <pages> pages 48-64, </pages> <month> October </month> <year> 1993. </year> <month> 102 </month>
Reference-contexts: For example, what operating systems support scheduler activations [4], multiple protection domains within a single-address space [20], efficient IPC [67], or efficient and flexible virtual memory primitives <ref> [5, 45, 58] </ref>? The structure of traditional operating systems ensures that good ideas will, for the most part, remain research curiosities. In an exokernel based system, these mechanisms can be implemented directly at application-level without special privileges, and without compromising system integrity.
Reference: [59] <author> B. W. Lampson. </author> <title> Hints for computer system design. </title> <booktitle> In Proceedings of the Eighth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 33-48, </pages> <month> December </month> <year> 1983. </year>
Reference-contexts: Supporting this illusion aggressively precludes application management: since the application is not supposed to see VM/70 it is unable to communicate with it over such issues as explicit allocation, revocation, naming and sharing (sharing is particularly difficult across virtual machines <ref> [59] </ref>). 5.7 Synthesis Synthesis is an innovative operating system that investigated the effects of a tight coupling between operating system and compiler. In particular, Synthesis used dynamic code generation to generate extremely efficient code sequences for a fixed, high-level UNIX interface [72].
Reference: [60] <author> Butler W. Lampson. </author> <title> Scheduling and Protection in Interactive Multi-Processing Systems. </title> <type> PhD thesis, </type> <institution> Berkeley, </institution> <year> 1967. </year>
Reference-contexts: In the future, we hope to perform such a transformation on the codified HAL of Windows/NT [28] 5.9 Extensible Operating Systems Many early operating systems papers discussed the need for extendible, flexible kernels [50, 65, 81, 107, 108]. Lampson's description of the CAL-TSS <ref> [60, 63] </ref> and Brinch Hansen's microkernel paper [43] are two classic rationales. Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets [108]. Modern revisitations of microkernels have also argued for kernel extensibility [1, 80, 84, 95, 28].
Reference: [61] <author> Butler W. Lampson. </author> <title> Private Communication, </title> <month> November </month> <year> 1994. </year>
Reference-contexts: This approach is used in [53]. Unfortunately, networking has tremendous backwards compatibility constraints. An exuberant alternative is to treat every process as a connection point and give it its own Ethernet address <ref> [61] </ref>. This allows simple vectoring and requires no protocol changes. Unfortunately there are reasons why this cannot, in general, be done with impunity. The traditional compromise between flexibility and backwards compatibility has been to allow applications to demultiplex the messages themselves through packet filters [74].
Reference: [62] <author> B.W. Lampson. </author> <title> Dynamic protection structures. </title> <booktitle> AFIPS Conf. Proc. 1969 FJCC, </booktitle> <volume> 35 </volume> <pages> 27-28, </pages> <year> 1969. </year>
Reference-contexts: Finally, capabilities have a practical disadvantage in terms of bookkeeping and interfaces: tracking large numbers and passing them to system routines can be clumsy. In the future, we will likely use an ACL scheme modeled on Lampson's "bitstrings" <ref> [62] </ref> to protect most resources (a likely exception will be disk blocks). This approach has been recently used both in SPACE [79] and in the Cache Kernel [22]. 41 2.7 Device Multiplexing Devices are difficult to multiplex: their interfaces are complex and their state extremely volatile. <p> An upcall is a light-weight, cross-domain calling mechanism. Operationally, an upcall changes the value of the PC in the caller to an agreed-upon value in the callee (the "gate" <ref> [62] </ref>), donates the current time-slice, and installs the destination domain's context (context identifier, address space tag, and process status word). Two flavors of upcalls are provided: synchronous and asynchronous.
Reference: [63] <author> B.W. Lampson. </author> <title> On reliable and extendable operating systems. State of the Art Report, </title> <type> 1, </type> <year> 1971. </year>
Reference-contexts: This search, spanning the last three decades, has been aggressive and vigorous but, unfortunately, has not been satisfactorily resolved <ref> [13, 22, 36, 43, 63, 72] </ref>. In this thesis we propose a new operating system structure that dramatically departs from previous work. An exokernel eliminates the notion that an operating system should provide abstractions on which applications are built. <p> In the future, we hope to perform such a transformation on the codified HAL of Windows/NT [28] 5.9 Extensible Operating Systems Many early operating systems papers discussed the need for extendible, flexible kernels [50, 65, 81, 107, 108]. Lampson's description of the CAL-TSS <ref> [60, 63] </ref> and Brinch Hansen's microkernel paper [43] are two classic rationales. Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets [108]. Modern revisitations of microkernels have also argued for kernel extensibility [1, 80, 84, 95, 28].
Reference: [64] <author> B.W. Lampson. </author> <title> Protection. </title> <booktitle> In Proc. 5th Princeton Conf. on Inform. Sci. and Syst., </booktitle> <pages> pages 437-443, </pages> <month> March </month> <year> 1971. </year>
Reference-contexts: is simply the transfer of a PC from one protection domain to an agreed-upon value in another, with the donation of the current time-slice, installation of the called domain's exception context, and an indication of which process initiated the call (security reasons for this last constraint are given in Lampson <ref> [64] </ref>). This lightweight cross-domain calling mechanism implements the bare-minimum required by any IPC mechanism, allowing the application to pay for just the functionality that it requires.
Reference: [65] <author> B.W. Lampson and H.E. Sturgis. </author> <title> Reflections on an operating system design. </title> <journal> Communications of the ACM, </journal> <volume> 19(5) </volume> <pages> 251-265, </pages> <month> May </month> <year> 1976. </year>
Reference-contexts: In the future, we hope to perform such a transformation on the codified HAL of Windows/NT [28] 5.9 Extensible Operating Systems Many early operating systems papers discussed the need for extendible, flexible kernels <ref> [50, 65, 81, 107, 108] </ref>. Lampson's description of the CAL-TSS [60, 63] and Brinch Hansen's microkernel paper [43] are two classic rationales. Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets [108].
Reference: [66] <author> Jay Lepreau, Mike Hibler, Bryan Ford, and Jeff Law. </author> <title> In-kernel servers in Mach 3.0: implementation and performance. </title> <booktitle> Proc. of the Third Usenix Mach Symposium, </booktitle> <year> 1993. </year>
Reference-contexts: loaded device drivers: the QNX operating system allows user-level handlers for device I/O [47]; Chorus servers are loaded into the kernel [84]; Mach 3.0 has migrated some of the AFS cache manager back into the kernel [75]; Lepreau et. al. has provided a tool to reintroduce servers into Mach 3.0 <ref> [66] </ref>. Draves has argued for selecting among several implementations of a specific kernel abstraction to allow customization [32].
Reference: [67] <author> Jochen Liedtke. </author> <title> Improving IPC by kernel design. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 175-188, </pages> <year> 1993. </year>
Reference-contexts: For example, what operating systems support scheduler activations [4], multiple protection domains within a single-address space [20], efficient IPC <ref> [67] </ref>, or efficient and flexible virtual memory primitives [5, 45, 58]? The structure of traditional operating systems ensures that good ideas will, for the most part, remain research curiosities. In an exokernel based system, these mechanisms can be implemented directly at application-level without special privileges, and without compromising system integrity. <p> In a more mature implementation the kernel will simply context-switch the application "by hand." 3.2.4 Upcalls Aegis provides an upcall [25] mechanism as a substrate for implementing efficient IPC mechanisms (e.g., <ref> [12, 48, 67] </ref>). An upcall is a light-weight, cross-domain calling mechanism. <p> The lack of difference should be attributed to the fact that the time-quanta (15.625 milliseconds) is fairly large relative to the extra overhead induced by allowing applications themselves to context switch. 4.3 IPC Fast IPC is crucial for a efficient, decoupled system <ref> [12, 48, 67] </ref>. As described in Chapter 3, the Aegis upcall mechanism is an efficient substrate for implementing fast IPC mechanisms. We enumerate some IPC mechanisms that can be constructed on top of it. Trusted LRPC. IPC to a trusted domain can be optimized. <p> We do an approximate comparison of our upcall to L3's RPC mechanism | which is the fastest in the world <ref> [67] </ref> | by scaling L3's times to the MIPS of our DECstation. Aegis's upcall mechanism performs well: the untrusted upcall is approximately 30% faster than L3, and the trusted upcalls approximately 2 times faster.
Reference: [68] <author> Barbara Liskov, Mark Day, and Liuba Shrira. </author> <title> Distributed Object Management, </title> <booktitle> chapter Distributed Object Management in Thor, </booktitle> <pages> pages 79-91. </pages> <publisher> Morgan Kaufman, </publisher> <year> 1993. </year>
Reference-contexts: Database systems. To eliminate the cost of cross-domain calls, database programs such as POSTGRES [92, 104] allow clients to download code into their address space. Embedded protection domains would allow them to efficiently isolate client code. Client/server systems. Many client/server configurations (e.g., the Thor system <ref> [68] </ref>) would also benefit from the ability to ship client code to the server. Furthermore, the tighter coupling between client and server allows the cost of marshaling and copying (required if IPC is used for cross-domain calls) to be eliminated. Light-weight application fire-walls.
Reference: [69] <author> Steven Lucco. </author> <title> High-performance microkernel systems (abstract). </title> <booktitle> In Proc. of the first Symp. on OSDI, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: The most important difference between our work and previous approaches is the explicit view that the operating system should not provide abstractions; as a result the interface in these systems is a much higher one (e.g., page-tables are implemented by the kernel). Current attempts include Scout [44], Bridge <ref> [69] </ref>, and Vino [87]. Some of the techniques used in these systems, such as type-safe languages [13, 36, 74, 81] and software fault-isolation [31, 104], are also applicable to exokernels.
Reference: [70] <author> C. </author> <title> Maeda. </title> <type> Thesis proposal, </type> <month> January </month> <year> 1994. </year>
Reference-contexts: This calamity can be prevented by either merging the writes or by granting exclusive access to the disk block. Either method can be safely performed by a server, which can manage a cache of file-buffers, ensuring coherence, protection and fault-isolation <ref> [70] </ref>. The important property of this configuration is that applications do not have to trust each other to manage objects correctly. <p> There are many examples of servers as managers of bindings. For example, Maeda discusses a situation where a server manages a cache of file-buffers <ref> [70] </ref>.
Reference: [71] <author> C. Maeda and B. N. Bershad. </author> <title> Protocol service decomposition for high-performance networking. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 244-255, </pages> <year> 1993. </year>
Reference-contexts: A nice property of this model is that it maps directly onto the operating system's traditional role as a trusted manager <ref> [71] </ref>.
Reference: [72] <author> H. Massalin. </author> <title> Synthesis: an efficient implementation of fundamental operating system services. </title> <type> PhD thesis, </type> <institution> Columbia University, </institution> <year> 1992. </year>
Reference-contexts: This search, spanning the last three decades, has been aggressive and vigorous but, unfortunately, has not been satisfactorily resolved <ref> [13, 22, 36, 43, 63, 72] </ref>. In this thesis we propose a new operating system structure that dramatically departs from previous work. An exokernel eliminates the notion that an operating system should provide abstractions on which applications are built. <p> Instead, it concentrates solely on multiplexing the raw hardware: from these hardware primitives, application-level libraries and servers can directly implement traditional operating system abstractions, specialized for appropriateness and speed. 1.1 The Problem The cost of inappropriate, inefficient operating system abstractions has had a large impact on applications <ref> [5, 13, 44, 45, 72, 91, 97] </ref>. This situation has persisted for the last three decades, and has survived numerous assaults (e.g., object-oriented operating systems and micro-kernels). Any concept that cannot be realized after such a long period of time should be reexamined. <p> Applications that do not need a given feature pay unnecessary overhead <ref> [4, 72] </ref>. Additionally, simply using a given feature is costly, since the operating system must interpret a myriad of system call options [72]. <p> Applications that do not need a given feature pay unnecessary overhead [4, 72]. Additionally, simply using a given feature is costly, since the operating system must interpret a myriad of system call options <ref> [72] </ref>. Furthermore, the mere existence of OS abstractions consumes significant amounts of main memory, cache space, TLB space, and cycles, which could be used by applications to perform useful work. <p> For example, once the application has no access to the raw disk interface, database records must be emulated on top of files: further examples of conflicts between OS-provided abstractions and what applications require can be found in the literature <ref> [5, 13, 44, 45, 72, 91, 97] </ref>. The abstractions of modern operating systems hide useful information and capabilities. <p> This flexibility allows a number of simple optimizations: Fast process context switching. Context-switching costs can be reduced by not saving floating-point registers if they have not been used. This well-known technique can substantially reduce the cost of context switches <ref> [72] </ref>. Information about the use of floating-point can either be deduced statically (e.g., through application-specific knowledge) or dynamically. Dynamic detection can be done in a number of ways. <p> In particular, Synthesis used dynamic code generation to generate extremely efficient code sequences for a fixed, high-level UNIX interface <ref> [72] </ref>. While their performance improvements were impressive, the fixed interface they 92 provided precluded much application-level customization. Furthermore, an exokernel's low--level interface directly eliminates the need to partially evaluate complex operating system functions: all functions are simple and, therefore, quite efficient.
Reference: [73] <author> Dylan McNamee and Katherine Armstrong. </author> <title> Extending the mach external pager interface to accommodate user-level page replacement policies. </title> <booktitle> In Mach Workshop Conference Proceedings, </booktitle> <pages> pages 17-30, </pages> <address> Burlington, VT, </address> <month> October 4-5 </month> <year> 1990. </year> <booktitle> USENIX. </booktitle>
Reference-contexts: This section concentrates on the tradeoffs of visible and invisible revocation schemes. Revocation can either be visible or invisible to processes. Systems with external pagers <ref> [73] </ref> use a form of visible revocation for physical memory. Traditionally, operating systems have performed revocation invisibly. For example, with the exception of some external pagers, most operating systems deallocate (and allocate) physical memory without informing applications.
Reference: [74] <author> J.C. Mogul, R.F. Rashid, and M.J. Accetta. </author> <title> The packet filter: An efficient mechanism for user-level network code. </title> <booktitle> In Proceedings of 11th SOSP, </booktitle> <pages> pages 39-51, </pages> <address> Austin, TX, </address> <month> November </month> <year> 1987. </year>
Reference-contexts: This allows simple vectoring and requires no protocol changes. Unfortunately there are reasons why this cannot, in general, be done with impunity. The traditional compromise between flexibility and backwards compatibility has been to allow applications to demultiplex the messages themselves through packet filters <ref> [74] </ref>. Packet filters are predicates written in a small type-safe language. Logically, packet filters examine all incoming network packets; those messages that satisfy their predicate are delivered to the filter's associated application. <p> Current attempts include Scout [44], Bridge [69], and Vino [87]. Some of the techniques used in these systems, such as type-safe languages <ref> [13, 36, 74, 81] </ref> and software fault-isolation [31, 104], are also applicable to exokernels.
Reference: [75] <author> David Nagle, Richard Uhlig, Tim Stanley, Stuart Sechrest, Trevor Mudge, and Richard Brown. </author> <title> Design tradeoffs for software-managed TLBs. </title> <booktitle> 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 27-38, </pages> <year> 1993. </year> <month> 103 </month>
Reference-contexts: It is a mature monolithic system that performs quite well in comparison to other research operating systems. For example, it performs two to three times better than Mach 3.0 in a set of I/O benchmarks <ref> [75] </ref>. Also, its virtual memory performance (measured in Section 4.6) is approximately twice that of Mach 2.5 and three times that of Mach 3.0. A few of the Aegis benchmarks were extremely sensitive to instruction cache conflicts. In some cases the effects amounted to a factor of three performance penalty. <p> ensure that critical pages, such as those containing directories, reside in physical memory [45]. 4.6.5 Page size Trade offs Increasing or decreasing the page size that is being mapped affects the amount of memory needed to map a virtual address space, the base unit of protection available, the working-set size <ref> [75, 93] </ref>, and the frequency of TLB faults [75, 93, 94]. Generally, large-page sizes allow fewer TLB misses and (possibly) smaller page-tables, but at a cost of larger working-sets and a coarse grain of protection. <p> directories, reside in physical memory [45]. 4.6.5 Page size Trade offs Increasing or decreasing the page size that is being mapped affects the amount of memory needed to map a virtual address space, the base unit of protection available, the working-set size [75, 93], and the frequency of TLB faults <ref> [75, 93, 94] </ref>. Generally, large-page sizes allow fewer TLB misses and (possibly) smaller page-tables, but at a cost of larger working-sets and a coarse grain of protection. These trade-offs are highly application dependent, and have thus far been poorly served by existing operating systems [94]. <p> drivers The commercial world has long looked at extensibility in the form of dynamically loaded device drivers: the QNX operating system allows user-level handlers for device I/O [47]; Chorus servers are loaded into the kernel [84]; Mach 3.0 has migrated some of the AFS cache manager back into the kernel <ref> [75] </ref>; Lepreau et. al. has provided a tool to reintroduce servers into Mach 3.0 [66]. Draves has argued for selecting among several implementations of a specific kernel abstraction to allow customization [32].
Reference: [76] <author> J. K. Ousterhout. </author> <title> Why aren't operating systems getting faster as fast as hardware? In Proc. </title> <booktitle> Summer Usenix, </booktitle> <pages> pages 247-256, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: For instance, a client that trusts a server may allow the server to save and restore the registers it needs, instead of saving the entire register file on every IPC. Since the machine state of current RISC machines is growing larger <ref> [76] </ref>, this can be crucial for good performance. This is far from a complete enumeration of all system primitives (for example, we have so 18 far neglected disks and devices), but should give a feel for what level of functionality the OS is required to provide. <p> For example, a client that trusts a server may, instead of a saving and then restoring its entire register state, allow the server to save and restore the registers it needs [48]. Because the machine state of current RISC machines is growing larger <ref> [76] </ref>, this optimization is crucial for good performance. Efficient LRPC. <p> Furthermore, for the trusted measurements, application-level code must save 8 general-purpose callee-saved registers. pipe: measures the time needed to send a word-sized message from one process to another using pipes. It was measured by "ping-ponging" a counter between two processes. This experiment is based on Ousterhout's experiments <ref> [76] </ref>. The Ultrix pipe implementation uses the standard UNIX pipe implementation. The ExOS pipe implementation uses a shared-memory circular buffer. Writes to full buffers and reads from empty ones cause the current time slice to be yielded by the current process to the reader or writer of the buffer, respectively.
Reference: [77] <author> M. </author> <title> Pagels. </title> <type> Private Communication, </type> <month> October </month> <year> 1994. </year>
Reference-contexts: However, the other declarative packet filter language that we know of (described in Bailey et al. [8]) does not utilize the 44 power of declarative specifications: predicates are not re-arranged to increase commonalities and similar inter-filter "suffixes" are not utilized <ref> [77] </ref>. Once a destination process is found for a packet, the problem then becomes where to put the message. We will allow packet filters to determine destination by adding support for computation within the packet filter itself (this portion of the filter can be viewed as an active message [102]).
Reference: [78] <author> G.J. Popek et al. </author> <title> UCLA data secure UNIX. </title> <booktitle> In Proc. of the 1979 National Computer Conference, </booktitle> <pages> pages 355-364, </pages> <year> 1979. </year>
Reference-contexts: This section introduces the data structures and operations that can be performed on these objects. In general the design has emphasized simplicity. For example, static allocation is used throughout the implementation, in a manner similar to <ref> [22, 78] </ref>. Also, the Aegis implementation is completely unmapped (both code and data), eliminating the complication (and inefficiency) of virtual memory. 3.3.1 Capabilities Capabilities consist of the resource name and a random sequence of bits; they are untyped and may be passed freely as data. <p> The difference between the Cache Kernel and Aegis is mainly one of high-level philosophy: the Cache Kernel focuses primarily on reliability, rather than securely exporting hardware resources to applications. For example, the Cache Kernel attempts to eliminate all dynamic memory allocation (similarly to Popek and Klines' Data Secure Unix <ref> [78] </ref>). Unsurprisingly, this single constraint lowers the kernel interface as compared to traditional operating systems. However, the de-emphasis on application flexibility and extensibility is telling; the cache kernel is biased towards a server-based system structure (for example, it supports only 16 "application-level" kernels concurrently).
Reference: [79] <author> D. Probert, J.L. Bruno, and M. Karzaorman. </author> <title> SPACE: A new approach to operating system abstraction. </title> <booktitle> In IWOOS, </booktitle> <year> 1991. </year>
Reference-contexts: In the future, we will likely use an ACL scheme modeled on Lampson's "bitstrings" [62] to protect most resources (a likely exception will be disk blocks). This approach has been recently used both in SPACE <ref> [79] </ref> and in the Cache Kernel [22]. 41 2.7 Device Multiplexing Devices are difficult to multiplex: their interfaces are complex and their state extremely volatile. For example, device buffer usage can fluctuate dramatically within short amounts of time. <p> As in the Raven Kernel (discussed below) the pico-kernel designers have noticed that application-level services cause less communication between the application and its operating system. 5.2.2 SPACE SPACE is an interesting "submicro-kernel" that provides only low-level kernel abstractions defined by the trap and architecture interface <ref> [79] </ref>. Its close coupling to the architecture has many similarities to the philosophy we have espoused.
Reference: [80] <author> R.F. Rashid and G. Robertson. </author> <title> Accent: A communication oriented network operating system kernel. </title> <booktitle> Proceedings of the Eighth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 64-75, </pages> <month> December </month> <year> 1981. </year>
Reference-contexts: Lampson's description of the CAL-TSS [60, 63] and Brinch Hansen's microkernel paper [43] are two classic rationales. Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets [108]. Modern revisitations of microkernels have also argued for kernel extensibility <ref> [1, 80, 84, 95, 28] </ref>. Anderson and Kiczales et al. also recently argued for minimalism and customizable [3, 56].
Reference: [81] <author> D.D. Redell, Y.K. Dalal, T.R. Horsley, H.C. Lauer, W.C. Lynch, P.R. McJones, H.G. Murray, </author> <title> and S.C. Purcell. Pilot: An operating system for a personal computer. </title> <journal> Communications of the ACM, </journal> <volume> 23(2) </volume> <pages> 81-92, </pages> <month> February </month> <year> 1980. </year>
Reference-contexts: Since its inception, the field of operating systems has been attempting to identify an appropriate structure: from familiar monolithic [99, 103] to micro-kernel operating systems [2, 43] to more exotic language-based <ref> [81] </ref> and virtual machine [27, 40] operating systems. This search, spanning the last three decades, has been aggressive and vigorous but, unfortunately, has not been satisfactorily resolved [13, 22, 36, 43, 63, 72]. In this thesis we propose a new operating system structure that dramatically departs from previous work. <p> In the future, we hope to perform such a transformation on the codified HAL of Windows/NT [28] 5.9 Extensible Operating Systems Many early operating systems papers discussed the need for extendible, flexible kernels <ref> [50, 65, 81, 107, 108] </ref>. Lampson's description of the CAL-TSS [60, 63] and Brinch Hansen's microkernel paper [43] are two classic rationales. Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets [108]. <p> Current attempts include Scout [44], Bridge [69], and Vino [87]. Some of the techniques used in these systems, such as type-safe languages <ref> [13, 36, 74, 81] </ref> and software fault-isolation [31, 104], are also applicable to exokernels.
Reference: [82] <author> Duncan Stuart Ritchie. </author> <title> The Raven kernel: a microkernel for shared memory multiprocessors. </title> <type> Technical Report TR 93-36, </type> <institution> University of British Columbia, Vancouver, B.C., </institution> <address> Canada V6T 1Z2, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: Its close coupling to the architecture has many similarities to the philosophy we have espoused. However, it is difficult to evaluate the SPACE approach, since the authors provide neither an explicit methodology nor performance results. 5.2.3 The Raven Kernel The Raven kernel dislocates many traditional abstractions to user-space <ref> [82] </ref>: tasks, exception handling and virtual memory are all that is provided by the kernel. However, it does not share our belief that the operating system has no business abstracting the hardware. <p> Rather, it views the operating systems main task as providing a reliable and convenient work environment: the "raw physical hardware [is] an environment far to exacting for higher level users to deal with" <ref> [82] </ref>. This view manifests in a simple virtual memory and task interface that hides many of the features of the underlying hardware.
Reference: [83] <author> Theodore H. Romer, Dennis Lee, Brian N. Bershad, and J. Bradley Chen. </author> <title> Dynamic page mapping policies for cache conflict resolution on standard hardware. </title> <booktitle> In Proceedings of the First Symposium on OSDI, </booktitle> <pages> pages 255-266, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: For instance, in a system with direct mapped caches, the 39 name of the physical page (i.e., the page-number) determines where it maps in the cache. Two pages with names that fall in the same "page-color" equivalence class will contend for the same regions of the cache <ref> [83] </ref>. If applications can request specific physical pages, they can minimize their conflict between already owned pages and between the pages allocated elsewhere in the system. Traditionally, operating systems have not provided any support for direct request of resources by name (e.g., physical page "42"). <p> Control over the physical page numbers allows cache-conscious layout of data on systems with physically mapped caches [14, 18, 45]. For example, "page-recoloring" can be used to reduce cache conflicts [17]. This method is further assisted by the ability of applications to approximate the working set using TLB snapshots <ref> [83] </ref>. Contiguous physical page sequences. Applications can use this exokernel-bestowed ability to request specific physical pages. This functionality can be used to construct contiguous runs of physical pages. These blocks can be used to construct super-pages [94] and to improve the efficiency of DMA operations [34]. Cache multiplexing.
Reference: [84] <author> M. Rozier, V. Abrossimov, F. Armand, I. Boule, M. Gien, M. Guillemont, F. Her-rmann, C. Kaiser, S. Langlois, P. Leonard, and W. Neuhauser. </author> <title> Chorus distributed operating system. </title> <journal> Computing Systems, </journal> <volume> 1(4) </volume> <pages> 305-370, </pages> <year> 1988. </year>
Reference-contexts: Lampson's description of the CAL-TSS [60, 63] and Brinch Hansen's microkernel paper [43] are two classic rationales. Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets [108]. Modern revisitations of microkernels have also argued for kernel extensibility <ref> [1, 80, 84, 95, 28] </ref>. Anderson and Kiczales et al. also recently argued for minimalism and customizable [3, 56]. <p> determine their relationship to exokernels in general and Aegis in particular. 5.10 Dynamically loaded device drivers The commercial world has long looked at extensibility in the form of dynamically loaded device drivers: the QNX operating system allows user-level handlers for device I/O [47]; Chorus servers are loaded into the kernel <ref> [84] </ref>; Mach 3.0 has migrated some of the AFS cache manager back into the kernel [75]; Lepreau et. al. has provided a tool to reintroduce servers into Mach 3.0 [66]. Draves has argued for selecting among several implementations of a specific kernel abstraction to allow customization [32].
Reference: [85] <author> J. Saltzer. </author> <title> Naming and Binding of Objects, </title> <booktitle> chapter 3.A., </booktitle> <pages> pages 99-208. </pages> <booktitle> Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1978. </year>
Reference-contexts: We discuss the tradeoffs between virtual and physical names. For a more extensive and 37 general discussion of naming see Saltzer <ref> [85] </ref>. <p> Virtual naming A virtual naming scheme adds a level of indirection between a name used by an application and the real, physical name of the resource. A familiar example of this is virtual memory. This level of indirection (called a context <ref> [85] </ref>) can be per-process, per-system, or any range in between. The primary advantage of virtual naming springs from the transparent relocation it allows. For example, if an operating system controls the mappings of virtual to physical names, it does not have to explicitly communicate with applications on revocation. <p> Single-address space subsystems. The exokernel exports all the primitives required to construct an address space with a separate protection domain, directly enabling the application-level construction of single-address space subsystems <ref> [20, 85] </ref>. 4.5 Exceptions Fast user-level traps enable a number of intriguing applications. The exokernel structure is uniquely suited to efficiently dispatch exceptions to user space.
Reference: [86] <author> Jerome H. Saltzer and Michael D. Schroeder. </author> <title> The protection of information in computer systems. </title> <journal> Proc. of the IEEE, </journal> <volume> 63(9) </volume> <pages> 1278-1308, </pages> <month> September </month> <year> 1975. </year>
Reference-contexts: However, the issues we discuss here are hardly unique to exokernels: we discuss them because they are so central, not because of unique tradeoffs. Protection is a well-known area: our discussion is based mainly on the literature. We elide many details; for a general discussion, consult Saltzer <ref> [86] </ref>. 2.6.1 Tradeoffs At a high-level, there are two protection schemes we consider: access control lists and capabilities [86]. Both associate guards with resources: when principals attempt to use 40 a resource (or encode a binding involving it) these guards check access rights. <p> Protection is a well-known area: our discussion is based mainly on the literature. We elide many details; for a general discussion, consult Saltzer <ref> [86] </ref>. 2.6.1 Tradeoffs At a high-level, there are two protection schemes we consider: access control lists and capabilities [86]. Both associate guards with resources: when principals attempt to use 40 a resource (or encode a binding involving it) these guards check access rights. ACLs are simply lists of principals allowed to use a given resource. ACLs cannot be circumvented: the kernel has absolute control over access rights.
Reference: [87] <editor> Margo Seltzer et al. </editor> <title> An introduction to the architecture of the VINO kernel, </title> <month> November </month> <year> 1994. </year>
Reference-contexts: Current attempts include Scout [44], Bridge [69], and Vino <ref> [87] </ref>. Some of the techniques used in these systems, such as type-safe languages [13, 36, 74, 81] and software fault-isolation [31, 104], are also applicable to exokernels.
Reference: [88] <author> R.L. </author> <title> Sites. Alpha axp architecture. </title> <journal> Comm. of the ACM, </journal> <volume> 36(2), </volume> <month> February </month> <year> 1993. </year>
Reference-contexts: AE DEAD ENV: The called environment has been terminated. AE NO FREE: There are no unallocated instances of the resource. 3.5 Primitive Operations The exokernel supplies a number of primitive operations that should be viewed as pseudo-instructions (similar to the Alpha's use of PALcode <ref> [88] </ref>). Each operation is guaranteed to not alter the value of any application register: as such it can be used to read and write machine state without requiring the saving and restoring of appropriate registers, etc.
Reference: [89] <author> M.J. Spier, Thomas N. Hastings, and David N. Cutler. </author> <title> An experimental implementation of the kernel/domain architecture. </title> <booktitle> In Fourth Symposium on Operating Systems Principles, </booktitle> <month> October </month> <year> 1973. </year>
Reference-contexts: The industry is well aware of this fact, and every change | no matter how trivial | is typically cautiously debated and evaluated as to whether or not it really has to be incorporated; its implementation is typically undertaken with great reluctance <ref> [89] </ref>. The interesting fact about this observation is that it was made in 1973; since then, operating system complexity has increased. And for good reason: traditional operating system design forces kernel implementors to implement the virtual machine for radically different applications and requirements.
Reference: [90] <author> Richard Stallman. </author> <title> Using and porting GCC. </title>
Reference-contexts: To efficiently implement primitive operations requires either that the operation be coded in assembly or that the calling conventions be changed (i.e., so that caller-saved registers are not overwritten). Fortunately, the GNU C compiler <ref> [90] </ref> allows command line alterations of the register convention. This allows primitive operations (and other routines that must assume all registers are "live") to be coded in ANSI C and still have guarantees that they will not trample caller-saved registers.
Reference: [91] <author> M. Stonebraker. </author> <title> Operating system support for database management. </title> <journal> CACM, </journal> <volume> 24(7) </volume> <pages> 412-418, </pages> <month> July </month> <year> 1981. </year>
Reference-contexts: Instead, it concentrates solely on multiplexing the raw hardware: from these hardware primitives, application-level libraries and servers can directly implement traditional operating system abstractions, specialized for appropriateness and speed. 1.1 The Problem The cost of inappropriate, inefficient operating system abstractions has had a large impact on applications <ref> [5, 13, 44, 45, 72, 91, 97] </ref>. This situation has persisted for the last three decades, and has survived numerous assaults (e.g., object-oriented operating systems and micro-kernels). Any concept that cannot be realized after such a long period of time should be reexamined. <p> For example, once the application has no access to the raw disk interface, database records must be emulated on top of files: further examples of conflicts between OS-provided abstractions and what applications require can be found in the literature <ref> [5, 13, 44, 45, 72, 91, 97] </ref>. The abstractions of modern operating systems hide useful information and capabilities.
Reference: [92] <author> Michael Stonebraker. </author> <title> Readings in Database Systems, chapter Inclusion of new types in relational data base systems, </title> <address> pages 480-487. </address> <publisher> Morgan Kaufmann Publishers Inc., </publisher> <year> 1988. </year>
Reference-contexts: We look at a few examples of where embedded protection domains would be useful. Database systems. To eliminate the cost of cross-domain calls, database programs such as POSTGRES <ref> [92, 104] </ref> allow clients to download code into their address space. Embedded protection domains would allow them to efficiently isolate client code. Client/server systems. Many client/server configurations (e.g., the Thor system [68]) would also benefit from the ability to ship client code to the server.
Reference: [93] <author> M. Talluri, S. Kong, M.D. Hill, and D.A. Patterson. </author> <title> Tradeoffs in supporting two page sizes. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 415-424, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: ensure that critical pages, such as those containing directories, reside in physical memory [45]. 4.6.5 Page size Trade offs Increasing or decreasing the page size that is being mapped affects the amount of memory needed to map a virtual address space, the base unit of protection available, the working-set size <ref> [75, 93] </ref>, and the frequency of TLB faults [75, 93, 94]. Generally, large-page sizes allow fewer TLB misses and (possibly) smaller page-tables, but at a cost of larger working-sets and a coarse grain of protection. <p> directories, reside in physical memory [45]. 4.6.5 Page size Trade offs Increasing or decreasing the page size that is being mapped affects the amount of memory needed to map a virtual address space, the base unit of protection available, the working-set size [75, 93], and the frequency of TLB faults <ref> [75, 93, 94] </ref>. Generally, large-page sizes allow fewer TLB misses and (possibly) smaller page-tables, but at a cost of larger working-sets and a coarse grain of protection. These trade-offs are highly application dependent, and have thus far been poorly served by existing operating systems [94].
Reference: [94] <author> Madhusudhan Talluri and Mark D. Hill. </author> <title> Surpassing the TLB performance of super-pages with less operating system support. </title> <booktitle> In Proceedings of the Sixth International Conference on ASPLOS, </booktitle> <year> 1994. </year>
Reference-contexts: Contiguous physical page sequences. Applications can use this exokernel-bestowed ability to request specific physical pages. This functionality can be used to construct contiguous runs of physical pages. These blocks can be used to construct super-pages <ref> [94] </ref> and to improve the efficiency of DMA operations [34]. Cache multiplexing. <p> directories, reside in physical memory [45]. 4.6.5 Page size Trade offs Increasing or decreasing the page size that is being mapped affects the amount of memory needed to map a virtual address space, the base unit of protection available, the working-set size [75, 93], and the frequency of TLB faults <ref> [75, 93, 94] </ref>. Generally, large-page sizes allow fewer TLB misses and (possibly) smaller page-tables, but at a cost of larger working-sets and a coarse grain of protection. These trade-offs are highly application dependent, and have thus far been poorly served by existing operating systems [94]. <p> Generally, large-page sizes allow fewer TLB misses and (possibly) smaller page-tables, but at a cost of larger working-sets and a coarse grain of protection. These trade-offs are highly application dependent, and have thus far been poorly served by existing operating systems <ref> [94] </ref>. Many machines support multiple page-sizes [54, 51, 94]. There are a number of specific ways that page size fluctuations may be useful: Reduced page-table overhead. The use of large pages directly reduces the size of page-tables needed to map an address space. <p> Generally, large-page sizes allow fewer TLB misses and (possibly) smaller page-tables, but at a cost of larger working-sets and a coarse grain of protection. These trade-offs are highly application dependent, and have thus far been poorly served by existing operating systems [94]. Many machines support multiple page-sizes <ref> [54, 51, 94] </ref>. There are a number of specific ways that page size fluctuations may be useful: Reduced page-table overhead. The use of large pages directly reduces the size of page-tables needed to map an address space.
Reference: [95] <author> A.S. Tanenbaum, R. van Renesse, H. van Staveren, G. Sharp, S.J. Mullender, A. Jansen, and G. van Rossum. </author> <title> Experiences with the Amoeba distributed operating system. </title> <journal> Communications of the ACM, </journal> <volume> 33(12) </volume> <pages> 46-63, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Lampson's description of the CAL-TSS [60, 63] and Brinch Hansen's microkernel paper [43] are two classic rationales. Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets [108]. Modern revisitations of microkernels have also argued for kernel extensibility <ref> [1, 80, 84, 95, 28] </ref>. Anderson and Kiczales et al. also recently argued for minimalism and customizable [3, 56].
Reference: [96] <author> C. Thekkath. </author> <title> Private Communication, </title> <month> November </month> <year> 1994. </year>
Reference-contexts: In this manner, very little code must be mapped and exceptions are handled extremely quickly. Variants of the above method has been used by Bedichek [11] and Thekkath <ref> [96] </ref>. An alternative solution is to return control using the kernel. Given the exokernel's efficient system call dispatching, this method may not be unacceptable for real applications. 3.6.3 Time-sharing As discussed previously, Aegis calls application-supplied prologue and epilogue code on time-slice initiation and completion, respectively.
Reference: [97] <author> C. A. Thekkath and Henry M. Levy. </author> <title> Hardware and software support for efficient exception handling. </title> <booktitle> In Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VI), </booktitle> <year> 1994. </year>
Reference-contexts: Instead, it concentrates solely on multiplexing the raw hardware: from these hardware primitives, application-level libraries and servers can directly implement traditional operating system abstractions, specialized for appropriateness and speed. 1.1 The Problem The cost of inappropriate, inefficient operating system abstractions has had a large impact on applications <ref> [5, 13, 44, 45, 72, 91, 97] </ref>. This situation has persisted for the last three decades, and has survived numerous assaults (e.g., object-oriented operating systems and micro-kernels). Any concept that cannot be realized after such a long period of time should be reexamined. <p> For example, once the application has no access to the raw disk interface, database records must be emulated on top of files: further examples of conflicts between OS-provided abstractions and what applications require can be found in the literature <ref> [5, 13, 44, 45, 72, 91, 97] </ref>. The abstractions of modern operating systems hide useful information and capabilities. <p> Exception propagation is done in a direct manner by saving a few scratch registers in some agreed-upon location in application-space and then jumping to an application-specified PC-address <ref> [97] </ref>. All of these operations can be sped up by downloading application code into the kernel [13, 36]. This implementation techniques aside, the full functionality provided by the underlying hardware should be exposed. <p> Figure 3-1 shows the MIPS assembly required to do this (the data-structure fields it accesses are defined in Section 3.3). The low-level nature of Aegis allows an extremely efficient implementation: exception forwarding requires almost four times fewer instructions than the most highly-tuned implementation in the literature <ref> [97] </ref>. Part of the reason for this improvement is that Aegis does not used mapped data structures, and so does not have to carefully seperate out kernel TLB misses from the more general class of exceptions in its exception demultiplexing routine. <p> Its lack of management allows exceptions to be dispatched in 16 MIPS instructions, four times fewer instructions than the most efficient implementation in the literature (an implementation that improved the documented state-of-the-art by an order of magnitude <ref> [97] </ref>). We look at a list of applications and operations that benefit from efficient traps. Many of these examples are drawn from Thekkath [97]. 80 Machine OS unaligned overflow co-proc prot DEC2100 Ultrix4.2 n/a 272 n/a 294. DEC2100 Aegis 2.8 2.8 2.8 3.0 DEC3100 Ultrix4.2 n/a 200. n/a 242. <p> 16 MIPS instructions, four times fewer instructions than the most efficient implementation in the literature (an implementation that improved the documented state-of-the-art by an order of magnitude <ref> [97] </ref>). We look at a list of applications and operations that benefit from efficient traps. Many of these examples are drawn from Thekkath [97]. 80 Machine OS unaligned overflow co-proc prot DEC2100 Ultrix4.2 n/a 272 n/a 294. DEC2100 Aegis 2.8 2.8 2.8 3.0 DEC3100 Ultrix4.2 n/a 200. n/a 242. DEC3100 Aegis 2.1 2.1 2.1 2.3 Emulation of sub-page protection [97]. <p> Many of these examples are drawn from Thekkath <ref> [97] </ref>. 80 Machine OS unaligned overflow co-proc prot DEC2100 Ultrix4.2 n/a 272 n/a 294. DEC2100 Aegis 2.8 2.8 2.8 3.0 DEC3100 Ultrix4.2 n/a 200. n/a 242. DEC3100 Aegis 2.1 2.1 2.1 2.3 Emulation of sub-page protection [97]. Many applications would benefit from a page size smaller than that provided by current machines [5]. Efficient page-protection traps. These exceptions are used by applications such as distributed shared memory systems, persistent object stores and garbage collectors [97, 5]. Instruction emulation. <p> DEC3100 Aegis 2.1 2.1 2.1 2.3 Emulation of sub-page protection [97]. Many applications would benefit from a page size smaller than that provided by current machines [5]. Efficient page-protection traps. These exceptions are used by applications such as distributed shared memory systems, persistent object stores and garbage collectors <ref> [97, 5] </ref>. Instruction emulation. The efficient emulation of privileged instructions is crucial for application-level OS emulation via direct execution. Unbounded data-structures. Efficient unaligned pointer traps can be used to implement conditional signals of various flavors. <p> Unfortunately, applications currently have no control over either page size or the mapping structure, which removes them from having any useful mechanism to realize this (other than having one object per page, which can get expensive). Small pages can be implemented through either hardware or emulation <ref> [97] </ref>. An additional area where false sharing may have overhead is on conventional shared memory machines where TLB invalidates of other processors must be done on protection changes, etc. 4.6.6 Page-table Structures Page-tables are used to construct a discrete function from virtual to physical addresses.
Reference: [98] <author> C.A. Thekkath, T.D. Nguyen, E. Moy, and E. Lazowska. </author> <title> Implementing network protocols at user level. </title> <booktitle> In SIGCOMM '93, </booktitle> <pages> pages 64-73, </pages> <year> 1993. </year>
Reference-contexts: The most effective intra-filter optimization is to dynamically generate the machine code corresponding to the filter. Our prototype implementation shows that compiled packet filters execute an order of magnitude more efficiently than when interpreted [39]. Thekkath suggests this optimization in <ref> [98] </ref>, but does not implement it. Inter-filter optimizations revolve around the recognition of commonalities between filters: many filters look for similar packets (e.g., TCP, UDP, etc.) and therefore have large overlap [109].
Reference: [99] <author> K. Thompson. </author> <title> UNIX implementation. </title> <journal> Bell Systems Technical Journal, </journal> <volume> 57(6) </volume> <pages> 1931-1946, </pages> <month> July </month> <year> 1978. </year>
Reference-contexts: Therefore, its structure has a dramatic impact on the performance and the scope of applications that can be built on it. Since its inception, the field of operating systems has been attempting to identify an appropriate structure: from familiar monolithic <ref> [99, 103] </ref> to micro-kernel operating systems [2, 43] to more exotic language-based [81] and virtual machine [27, 40] operating systems. This search, spanning the last three decades, has been aggressive and vigorous but, unfortunately, has not been satisfactorily resolved [13, 22, 36, 43, 63, 72]. <p> Operating systems have traditionally provided a high-level virtual machine that is portable across architectures (indeed, many successful operating system interfaces have outlived the machines that birthed them <ref> [99] </ref>). Those kernels that do allow low-level allocation typically only allocate those resources to a server, which in turn manages them (e.g., window managers are typically granted exclusive access to a frame-buffer). 2.3.3 Export all hardware operations Flexible management requires access to the full capabilities of a system object.
Reference: [100] <author> K. Thompson, R. Pike, et al. Plan9 Manual Page, </author> <year> 1991. </year>
Reference-contexts: The cost of application-level virtual memory is measured in Section 4.6; we also detail a myriad of uses for flexible application-level virtual memory. 3.6.6 Process creation ExOS provides several fork variants (similar in spirit to the Plan9 rfork mechanisms <ref> [100] </ref>). Fork requires a few hundred lines of code, most deal with duplication of the page-table. Fork is interesting since it requires that the executing process create a clone of itself while running and do so without directly manipulating physical memory. <p> Expressive process creation. Application-level process creation allows a great deal of flexibility in implementation; furthermore, as we discussed previously, since the implementation of these abstractions does not require special privileges, good ideas can be incorporated in systems other than those that they originated on (e.g., Plan9's rfork <ref> [100] </ref>). Specialized fork implementations. Many micro-kernels omit effective optimizations that would complicate their virtual memory system. For example, QNX does not support copy-on-write, even though that could speed up process creation by an order of magnitude.
Reference: [101] <author> Richard Uhlig, David Nagle, Trevor Mudge, and Stuart Schrest. </author> <title> Trap-driven simulation with tapeworm II. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VI), </booktitle> <pages> pages 132-144, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Exposing the full set of hardware capabilities enables operations that are not possible on current operating systems: Fine-grain monitoring. The tight coupling between applications and the virtual memory system allows efficient address tracing <ref> [101] </ref>. Furthermore, any application can do this at any time: no special dedicated hardware is needed. Exposure of memory attributes. For example, reference counting and dirty bits can be simulated in software, once applications have access to TLB exceptions [7]. Monitoring translation hardware.
Reference: [102] <author> T. von Eicken, D.E. Culler, S.C. Goldstein, and K.E. Schauser. </author> <title> Active messages: a mechanism for integrated communication and computation. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <pages> pages 256-267, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Once a destination process is found for a packet, the problem then becomes where to put the message. We will allow packet filters to determine destination by adding support for computation within the packet filter itself (this portion of the filter can be viewed as an active message <ref> [102] </ref>).
Reference: [103] <author> V.A. Vyssotsky, F.J. Corbato', and R.M. Graham. </author> <title> Structure of the multics supervisor. </title> <booktitle> AFIPS FJCC 1965, </booktitle> <pages> pages 203-212, </pages> <year> 1965. </year>
Reference-contexts: Therefore, its structure has a dramatic impact on the performance and the scope of applications that can be built on it. Since its inception, the field of operating systems has been attempting to identify an appropriate structure: from familiar monolithic <ref> [99, 103] </ref> to micro-kernel operating systems [2, 43] to more exotic language-based [81] and virtual machine [27, 40] operating systems. This search, spanning the last three decades, has been aggressive and vigorous but, unfortunately, has not been satisfactorily resolved [13, 22, 36, 43, 63, 72].
Reference: [104] <author> R. Wahbe, S. Lucco, T. Anderson, and S. Graham. </author> <title> Efficient software-based fault isolation. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 203-216, </pages> <year> 1993. </year>
Reference-contexts: The abstractions of modern operating systems hide useful information and capabilities. For instance, even simple operations such as monitoring TLB misses or determining the physical page used to map a virtual one are not possible on any operating system, even though the effects of cache conflicts can be great <ref> [104] </ref>. Finally, the high-level nature of 16 operating systems is self-fulfilling: removing application-level access to hardware resources and operations forces any software that must use these resources to be implemented in the kernel. <p> A more "low-tech" approach is to allow a window server process to download pieces of code into the kernel; these pieces can be called by applications to perform operations that they require. Protection can be ensured by bounding memory operations and jumps <ref> [104] </ref> and by limiting resource consumption [31] (e.g., CPU time and memory). The window server can use this capability to allow the applications themselves to write code fragments (say to implement a particular clipping algorithm) that it can check for safety and then download into the kernel. <p> With the ability to download application code into the kernel, these operations would be unnecessary. Interestingly, the ability to download code into the kernel <ref> [13, 31, 36, 104] </ref> would simplify the interface: Aegis would not have to provide all "reasonable" machine instructions and their aggregates but, instead, would just make the underlying hardware securely visible to applications. <p> The most important factor for this difference is the efficiency of the upcall mechanism. 4.4 Protection Many applications would benefit from the ability to use protection domains as fire-walls for enhanced modularity or to safely execute untrusted code via quarantine (e.g., for fault-isolation <ref> [104] </ref>). The ability to decouple naming from protection is also important in a single address space operating system [20]. The exokernel allows applications to define their own page-tables and to directly manipulate context identifiers. <p> This enables both lightweight protection and the separation of protection and naming. 79 4.4.1 Embedded protection domains One method to allow untrusted code to be safely imported into an address space is to use sandboxing <ref> [104] </ref>. Sandboxing is a software fault-isolation technique that makes code safe by bounding memory operations and jumps. Unfortunately, the average cost of general protection (i.e., sandboxing loads, stores and jumps) is quite high. The SPEC92 benchmarks, running on DEC-MIPS and DEC-ALPHA machines, degrade in average performance by approximately 17-20% [104]. <p> sandboxing <ref> [104] </ref>. Sandboxing is a software fault-isolation technique that makes code safe by bounding memory operations and jumps. Unfortunately, the average cost of general protection (i.e., sandboxing loads, stores and jumps) is quite high. The SPEC92 benchmarks, running on DEC-MIPS and DEC-ALPHA machines, degrade in average performance by approximately 17-20% [104]. Additional costs of sandboxing include a pair of dedicated registers and, since sandboxing relies on the fact that the upper bits in a protection domain are all the same (i.e., there is only one segment), an increase in the difficulty of sharing across segments. <p> We look at a few examples of where embedded protection domains would be useful. Database systems. To eliminate the cost of cross-domain calls, database programs such as POSTGRES <ref> [92, 104] </ref> allow clients to download code into their address space. Embedded protection domains would allow them to efficiently isolate client code. Client/server systems. Many client/server configurations (e.g., the Thor system [68]) would also benefit from the ability to ship client code to the server. <p> A more efficient mechanism is to use intentional cache conflicts to ensure that the cache does not hold a piece of data (i.e., the "flush" becomes implicit). 83 Performance debugging. Increasingly, performance anomalies are claimed to be in-struction cache related <ref> [104] </ref>. The control the exokernel provides over page selection allows such propositions to be verified. 4.6.3 Address space structure Application control over the structure of its address space allows a number of interesting techniques. Better static fault-isolation techniques. <p> Current attempts include Scout [44], Bridge [69], and Vino [87]. Some of the techniques used in these systems, such as type-safe languages [13, 36, 74, 81] and software fault-isolation <ref> [31, 104] </ref>, are also applicable to exokernels.
Reference: [105] <author> Carl A. Waldspurger and William E. Weihl. </author> <title> Lottery scheduling: Flexible proportional-share resource management. </title> <booktitle> In Proceedings of the First Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 1-11, </pages> <year> 1994. </year>
Reference-contexts: Context-identifiers are reclaimed "invisibly" from applications. Revocation is done when resource usage exceeds a specified threshold. Which instance of the resource to revoke and who to revoke it from are highly system dependent. For example, on a system with proportional sharing <ref> [105] </ref>, this determination will be made differently than on a "fair-share" system [46, 55]. As discussed later, Aegis will allow this to be parameterized on a system-wide basis. We discuss the default mechanism below. <p> Randomized revocation has very good properties for equal sharing. Introducing a proportional-share structure on top of it is a matter of scaling this selection so that some entities are more likely to be selected than others <ref> [105] </ref>. We do not consider these issues in this thesis. 2.5 Resource Naming The representation of names determines both how heavyweight the OS management must be and the effectiveness of application-level resource management. An exokernel attempts to use physical names wherever possible. <p> capability fl/ struct env fle; /fl associated environment (null if no one) fl/ unsigned short next, /fl next slice fl/ prev, /fl previous slice fl/ ticks, /fl ticks consumed in interrupts fl/ int:1; /fl whether it can be preempted on interrupts fl/ g; enforce proportional sharing (perhaps through lottery scheduling <ref> [105] </ref>) on a collection of sub-processes by allocating a number of time-slices; as each time-slice is initiated the server first determines which of its sub-process should run and then enables it by performing a yield system call to the chosen process.
Reference: [106] <author> D.W. Wall. </author> <title> Systems for late code modification. CODE 91 Workshop on Code Generation, </title> <year> 1991. </year>
Reference-contexts: This use of embedded protection domains can speed applications up, eliminate the need to postprocess object code (which can be quite challenging <ref> [106] </ref>), and allow multiple segments to be accessed simultaneously. We look at a few examples of where embedded protection domains would be useful. Database systems. To eliminate the cost of cross-domain calls, database programs such as POSTGRES [92, 104] allow clients to download code into their address space.
Reference: [107] <author> B.A. Wichmann. </author> <title> A modular operating system. </title> <booktitle> Proc. IFIP Cong. </booktitle> <year> 1968, 1968. </year>
Reference-contexts: In the future, we hope to perform such a transformation on the codified HAL of Windows/NT [28] 5.9 Extensible Operating Systems Many early operating systems papers discussed the need for extendible, flexible kernels <ref> [50, 65, 81, 107, 108] </ref>. Lampson's description of the CAL-TSS [60, 63] and Brinch Hansen's microkernel paper [43] are two classic rationales. Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets [108].
Reference: [108] <author> W. Wulf, E. Cohen, W. Corwin, A. Jones, R. Levin, C. Pierson, and F. Pollack. HYDRA: </author> <title> The kernel of a multiprocessing operating system. </title> <journal> Communications of the ACM, </journal> <volume> 17(6) </volume> <pages> 337-345, </pages> <month> July </month> <year> 1974. </year> <month> 105 </month>
Reference-contexts: The premise behind this principle is that distributed resource management is the best way to built an efficient, flexible system. This premise (which is partly shared by other "extensible" operating systems <ref> [108] </ref>) departs from traditional operating systems. Since Chapter 1 has already presented arguments for why high-level operating system abstractions are deleterious, this section concentrates on the tradeoffs between distributed and centralized control. <p> In the future, we hope to perform such a transformation on the codified HAL of Windows/NT [28] 5.9 Extensible Operating Systems Many early operating systems papers discussed the need for extendible, flexible kernels <ref> [50, 65, 81, 107, 108] </ref>. Lampson's description of the CAL-TSS [60, 63] and Brinch Hansen's microkernel paper [43] are two classic rationales. Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets [108]. <p> Lampson's description of the CAL-TSS [60, 63] and Brinch Hansen's microkernel paper [43] are two classic rationales. Hydra was the most ambitious system to have the separation of kernel policy and mechanism as one of its central tenets <ref> [108] </ref>. Modern revisitations of microkernels have also argued for kernel extensibility [1, 80, 84, 95, 28]. Anderson and Kiczales et al. also recently argued for minimalism and customizable [3, 56].
Reference: [109] <author> Yahara, B. Bershad, C. Maeda, and E. Moss. </author> <title> Efficient packet demultiplexing for multiple endpoints and large messages. </title> <booktitle> In Winter USENIX 94, </booktitle> <year> 1994. </year>
Reference-contexts: Since each filter must be applied to each message, computation rises linearly with the number of packet-filters installed. Fortunately, there are very effective optimizations that can counter the cost of using packet-filters. We look at both intra-filter [39] and inter-filter <ref> [109] </ref> optimizations. The most effective intra-filter optimization is to dynamically generate the machine code corresponding to the filter. Our prototype implementation shows that compiled packet filters execute an order of magnitude more efficiently than when interpreted [39]. Thekkath suggests this optimization in [98], but does not implement it. <p> Thekkath suggests this optimization in [98], but does not implement it. Inter-filter optimizations revolve around the recognition of commonalities between filters: many filters look for similar packets (e.g., TCP, UDP, etc.) and therefore have large overlap <ref> [109] </ref>. These commonalities can be used to collapse similar predicates, allowing many filters to be pruned for each failed condition. Unfortunately, recognition of overlaps has been hampered by the low-level nature of current packet filter languages, which are typically pseudo-assembly languages.
Reference: [110] <author> C. Yarvin, R. Bukowski, and T. Anderson. Anonymous RPC: </author> <title> Low-latency protection in a 64-bit address space. </title> <booktitle> In Proceedings of the Summer 1993 USENIX Conference, </booktitle> <month> June </month> <year> 1993. </year> <month> 106 </month>
Reference-contexts: A very interesting possibility is to map critical data to arbitrary locations in the address space: in a large address space it is unlikely that a wild write could find such state. In a sense, the virtual address is a capability <ref> [110] </ref>. Finally, the flippant answer is, of course, that applications should be written in a type-safe language. In conclusion, there are any number of methods to protect critical state from buggy applications. At a practical level, we do not expect this problem to be a difficult one to solve. <p> Better static fault-isolation techniques. With control of their address space layout, applications place sensitive state in arbitrary locations. This control can be used for improved fault isolation, by reducing the chance that a write or read will access this state; in a sense, the virtual address is a capability <ref> [110] </ref>. This technique can be used to allow applications to safely import untrusted code (or to guard against their own buggy algorithms). Fine-grain control of naming.
References-found: 110

