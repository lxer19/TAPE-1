URL: http://www-unix.mcs.anl.gov/~wright/papers/P705.ps.gz
Refering-URL: http://www.mcs.anl.gov/~wright/papers/
Root-URL: http://www.mcs.anl.gov
Title: EFFECTS OF FINITE-PRECISION ARITHMETIC ON INTERIOR-POINT METHODS FOR NONLINEAR PROGRAMMING  
Author: STEPHEN J. WRIGHT 
Affiliation: MATHEMATICS AND COMPUTER SCIENCE DIVISION, ARGONNE NATIONAL LABORATORY  
Date: JANUARY, 1998,  
Note: PREPRINT ANL/MCS-P705-0198,  AMS(MOS) subject classifications. 90C33, 90C30, 49M45  
Abstract: We show that the effects of finite-precision arithmetic in forming and solving the linear system that arises at each iteration of primal-dual interior-point algorithms for nonlinear programming are benign. Even when we replace the standard assumption that the active constraint gradients are independent by the weaker Mangasarian-Fromovitz constraint qualification, rapid convergence usually is attainable, even when cancellation and roundoff errors occur during the calculations. This conclusion holds for all three of the standard formulations of the linear system that is solved at each iteration of a primal-dual method. In deriving our main results, we prove a key technical result about the size of the exact primal-dual step. This result can be used to modify existing analysis of primal-dual interior-point methods for convex programming, making it possible to extend the superlinear local convergence results to the nonconvex case. 1. Introduction. We investigate the effects of finite-precision arithmetic on the 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Bunch and L. Kaufman, </author> <title> Some stable methods for calculating inertia and solving symmetric linear systems, </title> <journal> Mathematics of Computation, </journal> <volume> 31 (1977), </volume> <pages> pp. 163-179. </pages>
Reference-contexts: The vector t frequently contains a centering term oee, where oe is a centering parameter in the range <ref> [0; 1] </ref>. It sometimes also contains higher-order information, such as the product fl aff S aff e, where fl aff and S aff are the diagonal matrices constructed from the components of the pure Newton step. <p> The best-known methods of this class are due to Bunch and Parlett [2] and Bunch and Kaufman <ref> [1] </ref>, while Duff et al. [4] and Fourer and Mehrotra [7] have described sparse variants. These algorithms differ in their selection criteria for the 1 fi 1 and 2 fi 2 pivot blocks. <p> When the pivots are of type (95a) and (95b), the standard argument of Bunch and Kaufman <ref> [1] </ref> can be applied to show that the norm of CR 1 C T is at most a modest multiple of kCk. <p> combining (82a) with (112) that c s i = s i + ffi u + O ( 2 ); for all i 2 B.(113) FINITE-PRECISION EFFECTS IN NONLINEAR PROGRAMMING 35 Therefore, if s i + ff c s i = 0 for some i 2 B and some ff 2 <ref> [0; 1] </ref>, we have by using (31a) again that s i + ff (s i + ffi u + O ( 2 )) = 0 ) (1 ff) = ffi u = + O (); for any i 2 B.(114) Meanwhile, for i 2 N , we have from (31b), (65), <p> )) = 0 ) (1 ff) = ffi u = + O (); for any i 2 B.(114) Meanwhile, for i 2 N , we have from (31b), (65), and (82a) that s i + ff c s i &gt; 0; for all i 2 N and all ff 2 <ref> [0; 1] </ref>,(115) so the components c s N do not place a limit on the step length bound ^ff max . <p> Therefore, if i + ff c i = 0 for some i 2 N and some ff 2 <ref> [0; 1] </ref>, we have by arguing as in (114) that 1 ff = ffi u + O ():(116) Finally, for i 2 B, we have from (31a) that i = fi (1), while from (65), (82a), and (82b), we have that i = O (); c i = O () + <p> from (65), (82a), and (82b), we have that i = O (); c i = O () + ffi u =; for all i 2 B.(117) Therefore, we have for all AE u that i + ff c i &gt; 0; for all i 2 B and all ff 2 <ref> [0; 1] </ref>.(118) By combining the observations (114), (115), (116), and (118), we conclude that there is a value ^ff max satisfying ^ff max 2 [0; 1]; 1 ^ff max = ffi u = + O () such that (; s) + ff ( c ; c s) &gt; 0; for all <p> 2 B.(117) Therefore, we have for all AE u that i + ff c i &gt; 0; for all i 2 B and all ff 2 <ref> [0; 1] </ref>.(118) By combining the observations (114), (115), (116), and (118), we conclude that there is a value ^ff max satisfying ^ff max 2 [0; 1]; 1 ^ff max = ffi u = + O () such that (; s) + ff ( c ; c s) &gt; 0; for all ff 2 [0; ^ff max ], proving the claim (84). <p> WRIGHT From (65) and (82a), we have c z = ffi u + O (), so for AE u and ff 2 <ref> [0; 1] </ref>, we have ff 2 k c zk 2 = O ( 2 ):(120) From the definition (15) of the SVD of rg B (z fl ), Theorem 3.3, and (82a), we have that rg B (z)( c B B ) = rg B (z fl )( c B B
Reference: [2] <author> J. R. Bunch and B. N. Parlett, </author> <title> Direct methods for solving symmetric indefinite systems of linear equations, </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 8 (1971), </volume> <pages> pp. 639-655. </pages>
Reference-contexts: The best-known methods of this class are due to Bunch and Parlett <ref> [2] </ref> and Bunch and Kaufman [1], while Duff et al. [4] and Fourer and Mehrotra [7] have described sparse variants. These algorithms differ in their selection criteria for the 1 fi 1 and 2 fi 2 pivot blocks.
Reference: [3] <author> G. Debreu, </author> <title> Definite and semidefinite quadratic forms, </title> <journal> Econometrica, </journal> <volume> 20 (1952), </volume> <pages> pp. 295-300. </pages>
Reference-contexts: We state first the following technical result. Since it is similar to one proved by Hager [11, Lemma 3] and Debreu <ref> [3, Theorem 3] </ref>, its proof is omitted. Lemma 5.2. Suppose that M and A are two matrices with the properties that M is symmetric and A T x = 0 ) x T M x ffkM kkxk 2 ; for some constant ff &gt; 0.
Reference: [4] <author> I. S. Duff, N. I. M. Gould, J. K. Reid, J. A. Scott, and K. Turner, </author> <title> The factorization of sparse symmetric indefinite matrices, </title> <journal> IMA Journal on Numerical Analysis, </journal> <volume> 11 (1991), </volume> <pages> pp. 181-204. </pages>
Reference-contexts: The best-known methods of this class are due to Bunch and Parlett [2] and Bunch and Kaufman [1], while Duff et al. <ref> [4] </ref> and Fourer and Mehrotra [7] have described sparse variants. These algorithms differ in their selection criteria for the 1 fi 1 and 2 fi 2 pivot blocks. <p> This method also satisfies Condition 1. We then examine the sparse diagonal pivoting approaches of Duff et al. <ref> [4] </ref> and Fourer and Mehrotra [7], which may not satisfy Condition 1, because of the possible presence of 2 fi 2 pivots in which one of the diagonals has size fi ( 1 ). <p> Sparse Diagonal Pivoting. For large instances of (1), the Bunch-Kaufman and Bunch-Parlett procedures are usually inefficient because they do not try to maintain sparsity in the lower triangular factor L. Sparse variants of these algorithms, such as those of Duff et al. <ref> [4] </ref> and Fourer and Mehrotra [7], use pivot selection strategies that combine stability considerations with Markowitz-like estimates of the amount of fill-in that a candidate pivot will cause in the remaining matrix. <p> As soon as a pivot is found that meets the stability criteria described below, it is accepted. Both algorithms prefer to use 1 fi 1 pivots where possible. For candidate 1fi1 pivots, Duff et al. <ref> [4, p. 190] </ref> use the following stability criterion: jR 1 jkCk 1 ae;(99) where the notation R and C is from (94) and ae 2 [2; 1) is some user-selected parameter that represents the tolerable growth factor at each stage of the factorization.
Reference: [5] <author> A. El-Bakry, R. A. Tapia, and Y. Zhang, </author> <title> On convergence rate of newton interior-point algorithms in the absence of strict complementarity, </title> <journal> Computational Optimization and Applications, </journal> <volume> 6 (1996), </volume> <pages> pp. 157-167. </pages>
Reference-contexts: If SC fails to hold, superlinear convergence of Newton-like algorithms does not occur, except for specially modified algorithms such as those that identify the active constraints explicitly (see Monteiro and Wright [15] and El-Bakry, Tapia, and Zhang <ref> [5] </ref>). The major conclusion of the paper is that the effects of roundoff errors on the rapid local convergence of the algorithm are fairly benign.
Reference: [6] <author> A. Forsgren, P. Gill, and J. Shinnerl, </author> <title> Stability of symmetric ill-conditioned systems arising in interior methods for constrained optimization, </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 17 (1996), </volume> <pages> pp. 187-211. </pages>
Reference-contexts: In addition, we go into more depth in checking that the computed iterates can continue to satisfy the approximate centrality conditions usually required in primal-dual algorithms, and in deriving expressions for the rate at which the computed iterates approach the solution set. Related work by Forsgren, Gill, and Shinnerl <ref> [6] </ref> deals with one formulation of the step equations for the nonlinear programming problem|the so-called augmented form treated here in Section 6|but makes assumptions on the pivot sequence that may not always hold in practice. M. H.
Reference: [7] <author> R. Fourer and S. Mehrotra, </author> <title> Solving symmetric indefinite systems in an interior-point method for linear programming, </title> <journal> Mathematical Programming, </journal> <volume> 62 (1993), </volume> <pages> pp. 15-39. </pages>
Reference-contexts: The best-known methods of this class are due to Bunch and Parlett [2] and Bunch and Kaufman [1], while Duff et al. [4] and Fourer and Mehrotra <ref> [7] </ref> have described sparse variants. These algorithms differ in their selection criteria for the 1 fi 1 and 2 fi 2 pivot blocks. <p> This method also satisfies Condition 1. We then examine the sparse diagonal pivoting approaches of Duff et al. [4] and Fourer and Mehrotra <ref> [7] </ref>, which may not satisfy Condition 1, because of the possible presence of 2 fi 2 pivots in which one of the diagonals has size fi ( 1 ). <p> Sparse Diagonal Pivoting. For large instances of (1), the Bunch-Kaufman and Bunch-Parlett procedures are usually inefficient because they do not try to maintain sparsity in the lower triangular factor L. Sparse variants of these algorithms, such as those of Duff et al. [4] and Fourer and Mehrotra <ref> [7] </ref>, use pivot selection strategies that combine stability considerations with Markowitz-like estimates of the amount of fill-in that a candidate pivot will cause in the remaining matrix. <p> For a 2 fi 2 pivot, the criterion is jR 1 j kC ;1 k 1 ae ;(100) where C ;1 and C ;2 are the two columns of C. The stability criteria of Fourer and Mehrotra <ref> [7] </ref> are similar. As they stand, the stability tests (99) and (100) do not necessarily restrict the choice of pivots to the three types (95).
Reference: [8] <author> J. Gauvin, </author> <title> A necessary and sufficient regularity condition to have bounded multipliers in nonconvex programming, </title> <journal> Mathematical Programming, </journal> <volume> 12 (1977), </volume> <pages> pp. 136-138. </pages>
Reference-contexts: The Mangasarian-Fromovitz constraint qualification (MFCQ) is satisfied at z fl ; that is, there is a vector y 2 IR n such that rg B (z fl ) T y &lt; 0:(9) The following fundamental result about MFCQ is due to Gauvin <ref> [8] </ref>. Lemma 2.1. Suppose that the first-order conditions are satisfied at z fl . Then S is bounded if and only if the MFCQ condition (9) is satisfied.
Reference: [9] <author> G. H. Golub and C. F. Van Loan, </author> <title> Matrix Computations, </title> <publisher> The Johns Hopkins University Press, </publisher> <address> Baltimore, </address> <note> second ed., </note> <year> 1989. </year>
Reference-contexts: this matrix is of size O ( 1 ), so we have cond (L zz (z; ) + rg (z)D 1 rg (z) T ) = O ( 1 ):(83) FINITE-PRECISION EFFECTS IN NONLINEAR PROGRAMMING 21 It is known from a result of Wilkinson (cited by Golub and Van Loan <ref> [9, p. 145] </ref>) that the Cholesky algorithm runs to completion if q n ffi u cond () 1, where q n is a modest quantity that depends polynomially on the dimension n of the matrix.
Reference: [10] <author> W. W. Hager, </author> <title> Convergence of Wright's stabilized SQP algorithm, </title> <type> Technical Report, </type> <institution> Department of Mathematics, University of Florida, </institution> <address> Gainesville, Fl., </address> <month> January </month> <year> 1997. </year> <title> [11] , Stability in the presence of degeneracy and error estimation, </title> <type> Technical Report, </type> <institution> Department of Mathematics, University of Florida, </institution> <address> Gainesville, Fl., </address> <month> January </month> <year> 1997. </year>
Reference-contexts: This allows the local convergence results of Ralph and Wright [25, 17, 16] to be extended to general nonconvex nonlinear problems. The analysis of this paper could also be applied to the recently proposed stabilized sequential quadratic programming (sSQP) algorithm (see Wright [24] and Hager <ref> [10] </ref>), in which small penalties on the change in the multiplier estimate from one iteration to the next ensure rapid convergence even when LICQ is relaxed to MFCQ. A finite-precision analysis of the sSQP method appears in [24, Section 3.2], but only for the augmented form of the step equations. <p> The principal reason for our focus on (44) is that the proof of the main result can be derived from fairly standard linear algebra arguments. We mention too that the form (44) is also relevant to the stabilized sequential quadratic programming (sSQP) method of Wright [24] and Hager <ref> [10] </ref>; that is, slight modifications to the FINITE-PRECISION EFFECTS IN NONLINEAR PROGRAMMING 11 results of this paper can be used to show that the condensed and augmented formulations of the step equations for this algorithm yield good steps even in the presence of roundoff and cancellation errors.
Reference: [12] <author> N. J. Higham, </author> <title> Accuracy and Stability of Numerical Algorithms, </title> <publisher> SIAM Publications, </publisher> <address> Philadel-phia, </address> <year> 1996. </year> <title> [13] , Stability of the diagonal pivoting method with partial pivoting, </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 18 (1997), </volume> <pages> pp. 52-65. </pages>
Reference-contexts: Gaussian Elimination. Another possibility for solving the system (42) is to ignore its symmetry and apply a Gaussian elimination algorithm, with row and/or column pivoting to preserve sparsity and prevent excessive element growth. Such a strategy satisfies Condition 1. In [19], the author uses a result of Higham <ref> [12] </ref> to show that the effects of the large diagonal elements are to some extent confined to the columns in which they appear.
Reference: [14] <author> O. L. Mangasarian and S. Fromovitz, </author> <title> The Fritz-John necessary optimality conditions in the presence of equality and inequality constraints, </title> <journal> Journal of Mathematical Analysis and Applications, </journal> <volume> 17 (1967), </volume> <pages> pp. 37-47. </pages>
Reference-contexts: WRIGHT we weaken an assumption that is often made in the analysis of algorithms for (1), namely, that the gradients of the active constraints are linearly independent at the solution. We replace this linear independence constraint qualification (LICQ) with the weaker Mangasarian-Fromovitz constraint qualification (MFCQ) <ref> [14] </ref>. MFCQ allows constraint gradients to become dependent at the solution, so that the set S of optimal Lagrange multipliers is no longer necessarily a singleton, though it remains bounded.
Reference: [15] <author> R. D. C. Monteiro and S. J. Wright, </author> <title> Local convergence of interior-point algorithms for degenerate monotone LCP, </title> <journal> Computational Optimization and Applications, </journal> <volume> 3 (1994), </volume> <pages> pp. 131-155. </pages>
Reference-contexts: If SC fails to hold, superlinear convergence of Newton-like algorithms does not occur, except for specially modified algorithms such as those that identify the active constraints explicitly (see Monteiro and Wright <ref> [15] </ref> and El-Bakry, Tapia, and Zhang [5]). The major conclusion of the paper is that the effects of roundoff errors on the rapid local convergence of the algorithm are fairly benign.
Reference: [16] <author> D. Ralph and S. J. Wright, </author> <title> Superlinear convergence of an interior-point method despite dependent constraints, </title> <type> Preprint ANL.MCS-P622-1196, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <month> November </month> <year> 1996. </year> <title> [17] , Superlinear convergence of an interior-point method for monotone variational inequalities, in Complementarity and Variational Problems: State of the Art, </title> <editor> M. C. Ferris and J. Pang, eds., </editor> <publisher> SIAM Publications, </publisher> <year> 1997, </year> <pages> pp. 345-385. </pages>
Reference-contexts: Strong theory is also available for these algorithms when applied to convex programming, in which OE () and g i (), i = 1; : : : ; m are all convex functions; see, for example, Wright and Ralph [25] and Ralph and Wright <ref> [17, 16] </ref>. The latter two papers drop the LICQ assumption FINITE-PRECISION EFFECTS IN NONLINEAR PROGRAMMING 3 in favor of the MFCQ, making the local theory stronger in one sense than the corresponding local theory for the sequential quadratic programming (SQP) algorithm. <p> A significant by-product of the current paper is to prove the key technical result about the length of the rapidly convergent step (Corollary 4.3) under MFCQ and SC, even when the problem (1) is not convex. This allows the local convergence results of Ralph and Wright <ref> [25, 17, 16] </ref> to be extended to general nonconvex nonlinear problems. <p> This is the key technical result used by Ralph and Wright <ref> [17, 16] </ref> to prove superlinear convergence of PDIP algorithms for convex programming problems. The result below, however, does not require a convexity assumption. Corollary 4.3. Suppose that Assumption 1 (a) holds. Then the (exact) solution (z; ; s) of the system (23) satisfies (z; ; s) = O ():(65) Proof.
Reference: [18] <author> M. H. Wright, </author> <title> Ill-conditioning and computational error in interior methods for nonlinear programming, </title> <type> Technical Report 97-4-04, </type> <institution> Bell Labs, Lucent Technologies, Computing Sciences Research Center, Bell Laboratories, </institution> <address> Murray Hill, NJ 07974, </address> <month> April </month> <year> 1997. </year> <note> To appear in SIAM Journal on Optimization. </note>
Reference-contexts: Related work by Forsgren, Gill, and Shinnerl [6] deals with one formulation of the step equations for the nonlinear programming problem|the so-called augmented form treated here in Section 6|but makes assumptions on the pivot sequence that may not always hold in practice. M. H. Wright <ref> [18] </ref> recently presented an analysis of another formulation of the step equations|the condensed form discussed in Section 5|under the assumption that LICQ holds. For linear programming, the PDIP approach has emerged as the most powerful of the interior-point approaches. <p> Earlier discussion of cancellation errors can be found in the papers [19, 23, 20] and <ref> [18] </ref>. 18 STEPHEN J. WRIGHT The second source of error is evaluation of the matrix D 1 and computation of the matrices and right-hand side of (70) from the computed quantities in (71). <p> H. Wright <ref> [18] </ref> for accuracy of the computed solution of the condensed system by relaxing the LICQ assumption to MFCQ. When LICQ holds, the matrix V is vacuous, so the absolute error in all components is of size at most ffi u . <p> When LICQ holds, the matrix V is vacuous, so the absolute error in all components is of size at most ffi u . The higher accuracy (82c) of the components c N (also noted in <ref> [18] </ref>) does not contribute significantly to the progress that can be made along the inexact direction ( c z; c ; c s), in the sense of Section 5.3. 5.2. The Cholesky Algorithm Runs to Completion.

Reference: [25] <author> S. J. Wright and D. Ralph, </author> <title> A superlinear infeasible-interior-point algorithm for monotone nonlinear complementarity problems, </title> <journal> Mathematics of Operations Research, </journal> <volume> 21 (1996), </volume> <pages> pp. 815-838. </pages>
Reference-contexts: Strong theory is also available for these algorithms when applied to convex programming, in which OE () and g i (), i = 1; : : : ; m are all convex functions; see, for example, Wright and Ralph <ref> [25] </ref> and Ralph and Wright [17, 16]. The latter two papers drop the LICQ assumption FINITE-PRECISION EFFECTS IN NONLINEAR PROGRAMMING 3 in favor of the MFCQ, making the local theory stronger in one sense than the corresponding local theory for the sequential quadratic programming (SQP) algorithm. <p> A significant by-product of the current paper is to prove the key technical result about the length of the rapidly convergent step (Corollary 4.3) under MFCQ and SC, even when the problem (1) is not convex. This allows the local convergence results of Ralph and Wright <ref> [25, 17, 16] </ref> to be extended to general nonconvex nonlinear problems.
References-found: 16

