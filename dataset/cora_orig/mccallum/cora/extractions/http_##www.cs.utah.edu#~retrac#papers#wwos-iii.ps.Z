URL: http://www.cs.utah.edu/~retrac/papers/wwos-iii.ps.Z
Refering-URL: http://www.cs.utah.edu/~retrac/papers.html
Root-URL: 
Title: Distributed Operating Systems Based on a Protected Global Virtual Address Space  
Author: John B. Carter David B. Johnson Alan L. Cox Willy Zwaenepoel 
Affiliation: Rice University, Department of Computer Science  
Abstract: With the advent of 64-bit processors, virtual address spaces will be large enough to make it feasible for a distributed operating system to support as the primary system abstraction the illusion of a uniform shared address space that spans a collection of workstations. Under such a system, interprocess communication can be performed by invoking functions that operate on a virtually shared memory rather than via explicit message passing. We propose that with the correct mechanisms to provide protection and fault tolerance, such a system could provide the benefits of conventional message-passing-based distributed operating systems (e.g., protection domains, hidden data abstractions, simple client-server interface, and failure isolation), with several additional benefits (e.g., efficient sharing of complex data structures between processes, transparent replication of server functions, and a uniform interface for all communications).
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Atkinson, A. Demers, C. Hauser, C. Jacobi, , P. Kessler, and M. Weiser. </author> <title> Experiences creating a portable Cedar. </title> <booktitle> In Proceedings of the SIGPLAN `89 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: Other research projects have explored the use of a single address space as a shared name space. In these systems, memory access serves as the primary mechanism for interprocess communication <ref> [1, 10, 12] </ref>. Most of these systems are intended to execute on a single machine. We believe an efficient implementation of a single address space across multiple machines is possible by combining a high-performance DSM system and a fast RPC mechanism to provide both data movement and function shipping. <p> The choice of invocation style (data shipping versus function shipping, trusted versus untrusted) is under software control, which gives programmers the flexibility to use either RPC or shared memory semantics. Our proposed system differs from existing single address space systems <ref> [1, 10, 12] </ref>. Psyche is perhaps the most similar to our proposed system. However, differences exist in the cross-domain communication mechanism. Psyche uses page faults to trigger cross-domain calls rather than explicit traps by stubs. We believe that the use of stubs can reduce the cost of cross-domain communication.
Reference: [2] <author> H.E. Bal and A.S. Tanenbaum. </author> <title> Distributed programming with shared data. </title> <booktitle> In Proceedings of the 1988 International Conference on Computer Languages, </booktitle> <pages> pages 82-91, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Many researchers have developed distributed shared memory (DSM) systems that enable a single shared-memory parallel program to execute on multiple machines <ref> [2, 3, 4, 9, 11] </ref>. The typical motivation behind DSM is to reduce the effort required to program distributed memory multicomputers. However, no existing DSM provides the protection necessary for multiple, potentially mistrusting programs to safely coexist within the same address space.
Reference: [3] <author> J.B. Carter, J.K. Bennett, and W. Zwaenepoel. </author> <title> Implementation and performance of Munin. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 152-164, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Many researchers have developed distributed shared memory (DSM) systems that enable a single shared-memory parallel program to execute on multiple machines <ref> [2, 3, 4, 9, 11] </ref>. The typical motivation behind DSM is to reduce the effort required to program distributed memory multicomputers. However, no existing DSM provides the protection necessary for multiple, potentially mistrusting programs to safely coexist within the same address space. <p> However, the provision of function shipping is necessary when the shared data cannot be moved or replicated. Second, relaxed memory consistency models, such as release consistency [6] and lazy consistency [8], can reduce significantly the communication that occurs between machines in a DSM. Munin <ref> [3] </ref> has demonstrated that a DSM program can achieve performance comparable to its message passing equivalent. Third, with the advent of 64-bit processors, the address space is large enough to name all potential objects in a distributed system.
Reference: [4] <author> J.S. Chase, F.G. Amador, E.D. Lazowska, H.M. Levy, and R.J. Littlefield. </author> <title> The Amber system: Parallel programming on a network of multiprocessors. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 147-158, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Many researchers have developed distributed shared memory (DSM) systems that enable a single shared-memory parallel program to execute on multiple machines <ref> [2, 3, 4, 9, 11] </ref>. The typical motivation behind DSM is to reduce the effort required to program distributed memory multicomputers. However, no existing DSM provides the protection necessary for multiple, potentially mistrusting programs to safely coexist within the same address space.
Reference: [5] <author> E.N. Elnozahy and W. Zwaenepoel. Manetho: </author> <title> Transparent rollback-recovery with low overhead, limited rollback, and fast output commit. </title> <journal> IEEE Transactions on Computers Special Issue On Fault-Tolerant Computing, </journal> <volume> 41(5), </volume> <month> May </month> <year> 1992. </year> <note> To appear. </note>
Reference-contexts: These messages may be caused either by RPCs or by the protocols used to maintain memory consistency of the global address space. By integrating the fault-tolerance support with the RPC and consistency protocol support, existing distributed system fault-tolerance approaches <ref> [7, 5] </ref> can be used with minor modification.
Reference: [6] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <address> Seattle, Washington, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: However, the provision of function shipping is necessary when the shared data cannot be moved or replicated. Second, relaxed memory consistency models, such as release consistency <ref> [6] </ref> and lazy consistency [8], can reduce significantly the communication that occurs between machines in a DSM. Munin [3] has demonstrated that a DSM program can achieve performance comparable to its message passing equivalent.
Reference: [7] <author> D.B. Johnson. </author> <title> Distributed System Fault Tolerance Using Message Logging and Checkpointing. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: These messages may be caused either by RPCs or by the protocols used to maintain memory consistency of the global address space. By integrating the fault-tolerance support with the RPC and consistency protocol support, existing distributed system fault-tolerance approaches <ref> [7, 5] </ref> can be used with minor modification.
Reference: [8] <author> P. Keleher, A. Cox, and W. Zwaenepoel. </author> <title> Lazy consistency for software distributed shared memory. </title> <booktitle> Submitted to the 18th Annual International Symposium on Computer Architecture, </booktitle> <month> November </month> <year> 1991. </year>
Reference-contexts: However, the provision of function shipping is necessary when the shared data cannot be moved or replicated. Second, relaxed memory consistency models, such as release consistency [6] and lazy consistency <ref> [8] </ref>, can reduce significantly the communication that occurs between machines in a DSM. Munin [3] has demonstrated that a DSM program can achieve performance comparable to its message passing equivalent.
Reference: [9] <author> K. Li and P. Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Many researchers have developed distributed shared memory (DSM) systems that enable a single shared-memory parallel program to execute on multiple machines <ref> [2, 3, 4, 9, 11] </ref>. The typical motivation behind DSM is to reduce the effort required to program distributed memory multicomputers. However, no existing DSM provides the protection necessary for multiple, potentially mistrusting programs to safely coexist within the same address space.
Reference: [10] <author> C. Pu, H. Massalin, and J. Ioannidis. </author> <title> The Synthesis kernel. </title> <journal> Computing Systems, </journal> <volume> 1(1) </volume> <pages> 11-32, </pages> <month> Winter </month> <year> 1988. </year>
Reference-contexts: Other research projects have explored the use of a single address space as a shared name space. In these systems, memory access serves as the primary mechanism for interprocess communication <ref> [1, 10, 12] </ref>. Most of these systems are intended to execute on a single machine. We believe an efficient implementation of a single address space across multiple machines is possible by combining a high-performance DSM system and a fast RPC mechanism to provide both data movement and function shipping. <p> The choice of invocation style (data shipping versus function shipping, trusted versus untrusted) is under software control, which gives programmers the flexibility to use either RPC or shared memory semantics. Our proposed system differs from existing single address space systems <ref> [1, 10, 12] </ref>. Psyche is perhaps the most similar to our proposed system. However, differences exist in the cross-domain communication mechanism. Psyche uses page faults to trigger cross-domain calls rather than explicit traps by stubs. We believe that the use of stubs can reduce the cost of cross-domain communication.
Reference: [11] <author> U. Ramachandran and M.Y.A. Khalidi. </author> <title> An implementation of distributed shared memory. </title> <booktitle> Distributed and Multiprocessor Systems Workshop, </booktitle> <pages> pages 21-38, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Many researchers have developed distributed shared memory (DSM) systems that enable a single shared-memory parallel program to execute on multiple machines <ref> [2, 3, 4, 9, 11] </ref>. The typical motivation behind DSM is to reduce the effort required to program distributed memory multicomputers. However, no existing DSM provides the protection necessary for multiple, potentially mistrusting programs to safely coexist within the same address space.
Reference: [12] <author> M.L. Scott, T.J. LeBlanc, and B.D. Marsh. </author> <title> Design rational for Psyche, a general-purpose multiprocessor operating system. </title> <booktitle> In 1988 International Conference on Parallel Processing, </booktitle> <pages> pages 252-262, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Other research projects have explored the use of a single address space as a shared name space. In these systems, memory access serves as the primary mechanism for interprocess communication <ref> [1, 10, 12] </ref>. Most of these systems are intended to execute on a single machine. We believe an efficient implementation of a single address space across multiple machines is possible by combining a high-performance DSM system and a fast RPC mechanism to provide both data movement and function shipping. <p> The choice of invocation style (data shipping versus function shipping, trusted versus untrusted) is under software control, which gives programmers the flexibility to use either RPC or shared memory semantics. Our proposed system differs from existing single address space systems <ref> [1, 10, 12] </ref>. Psyche is perhaps the most similar to our proposed system. However, differences exist in the cross-domain communication mechanism. Psyche uses page faults to trigger cross-domain calls rather than explicit traps by stubs. We believe that the use of stubs can reduce the cost of cross-domain communication.
References-found: 12

