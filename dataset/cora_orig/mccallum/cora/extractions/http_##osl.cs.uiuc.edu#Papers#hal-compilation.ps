URL: http://osl.cs.uiuc.edu/Papers/hal-compilation.ps
Refering-URL: http://osl.cs.uiuc.edu/Papers/Language.html
Root-URL: http://www.cs.uiuc.edu
Email: Email: fwooyoung j aghag@cs.uiuc.edu  
Title: Compilation of a Highly Parallel Actor-Based Language  
Author: WooYoung Kim and Gul Agha 
Keyword: Actor, concurrency, synchronization constraint, inheritance, optimization  
Note: This author is sponsored by a fellowship from Ministry of Education in Korea.  
Date: June 23, 1992  
Address: Urbana, IL 61801, USA  
Affiliation: Department of Computer Science University of Illinois at Urbana-Champaign  
Abstract: Hal incorporates a number of high-level language constructs such as the incremental specialization of synchronization constraints to maintain the consistency of actors at run-time, the inheritance of both code and synchronization constraints, and limited reflective capabilities to customize the system with respect to fault tolerance. This paper describes some issues in compiling Hal, and, in particular, three source level transformations used by the compiler for Hal. Two of the transformations translate RPC-style message sending into asynchronous message sending. The third transformation performs code motion to optimize the implementation of replacement behavior. This optimization results in the reduction of object code size as well as execution time. y The work described in this paper has been made possible by generous support provided by a Young Investigator Award from the Office of Naval Research (ONR contract number N00014-90-J-1899), by an Incentives for Excellence Award from the Digital Equipment Corporation, and by joint support from the Defense Advanced Research Projects Agency and the National Science Foundation (NSF CCR 90-07195). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Agha. </author> <title> Actors: A Model of Concurrent Computation in Distributed Systems. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: Others have concentrated on compiling specialized languages which are inherently concurrent, such as functional languages [18] and Data Flow [7]. Unfortunately, such languages are inadequate to model concurrency in a state-based, nondeterministic world <ref> [1] </ref>. A third language paradigm consists of languages which explicitly manipulate parallelism. Some examples are CSP [9] and Occam [25]. <p> The configuration of the system is fixed at compile time resulting in a static topology. Our work is related to the last two paradigms. We use the Actor model <ref> [1] </ref> which unifies the functional and the object-based view of computation, supports parallelism explicitly and provides for a dynamic topology of computational agents. <p> The compiler must combine these two kinds of specifications for efficient execution (Section 2.7). 3 Inherent Concurrency The Actor model supports internal concurrency as well as explicit parallelism <ref> [1] </ref>. The internal concurrency is inherently fine-grained. However, almost every conventional processor is too coarse grained to realize the fine-grained computation inherent in the internal concurrency in an efficient way. To achieve better performance, we must have a certain amount of run-time control over grain size. <p> Finally, issues related to memory management, extensions to the asynchronous message passing primitive and reflection capability are addressed in that order. 2.1 The Actor Model Actors are self contained, independent computational agents that communicate by asynchronous message passing <ref> [1] </ref>. An actor consists of its mail queue and behavior. It is identified by its unique mail address. The mail queue of an actor buffers incoming communications (i.e. messages). The 5 behavior of an actor specifies the action performed by an actor in response to a communication. <p> 17 3.2 Optimization on the Replacement Behavior 3.2.1 Transformation for Code Motion of Replacement Behavior The semantics of the Actor model dictates that each communication to an actor is processed on its own version of the actor's state, allowing pipelining in the execution of the method containing become / update <ref> [1] </ref>. This internal concurrency implies that each expression in a method can be executed concurrently and the effect of replacement behavior is visible only to subsequent communications. However, it can be very expensive to utilize all available internal concurrency on conventional multiprocessor architectures.
Reference: [2] <author> G. Agha, S. Frtlund, R. Panwar, and D. Sturman. </author> <title> A Linguistic Framework for Dynamic Composition of Fault-Tolerance Protocols. </title> <type> Technical Report UIUCDCS-R-92-1730, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: Note, however, that the changes go into effect only for the subsequent messages. In general, reflection may be used to customize the implementation of a system from within the language. Currently, Hal supports the minimal amount of reflection capability necessary to customize the system with respect to fault tolerance <ref> [2] </ref>. An actor can reify its dispatcher and mail queue (the conceptual entities responsible for sending and receiving the communication, respectively). (Mailq &lt;expr&gt;) (Dispatcher &lt;expr&gt;) The value of &lt;expr&gt; is the mail address of an actor. <p> These reflection capabilities have been used to carry out an experiments in implementing reusable software fault tolerance protocols <ref> [2] </ref>. Such capabilities can also be used to separate the code for resource management, such as that for optimal actor placement, from the code for an application. 3 Implementation Issues In this section, we discuss three transformation techniques used in the Hal compiler.
Reference: [3] <author> G. Agha, C. Houck, and R. Panwar. </author> <title> Distributed Execution of Actor Systems. </title> <booktitle> In Proceedings of Fourth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Santa Clara, </address> <year> 1991. </year>
Reference-contexts: In order to protect the system as well as an actor from possible internal inconsistency due to message order nondeterminism, we need to be able to specify synchronization constraints on actors. Earlier work has established how synchronization constraints can be used for software pipelining <ref> [3] </ref>. In particular, such pipelining transforms some algorithms, such as the Cholesky Decomposition of a symmetric positive definite matrix, from unscalable algorithms into scalable ones. We have adopted a philosophy of synchronization constraints proposed in [15]. All constraints are expressed as disabling restrictions. <p> One difference of Hal and ABCL is that ABCL does not support inheritance [35]. 5 Current Status and Future Research Direction Some practical examples show the performance advantage of using fine-grained inherent concurrency in the Actor model for distributed execution on multicomputers <ref> [3] </ref>. However, to design an actor-based language which is easy to use and machine independent, we need to add several linguistic extensions to the basic Actor model. <p> Currently, the run-time system for Hal does not support garbage collection. Distributed garbage collector [19, 32] should be incorporated in near future. Finally, the compiler should be able to provide the run-time system with information on load balancing and locality control using modular specifications given by the user <ref> [3] </ref>. 22 Acknowledgments We would like to thank other members of Open Systems Laboratory at the University of Illinois at Urbana-Illinois, in particular, Svend Frolund and Daniel Sturman for their constructive suggestions for designing Hal, and Raju Panwar and Chirstian Callsen for careful reading the draft of this paper.
Reference: [4] <author> A. Aho, R. Sethi, and J. Ullman. </author> <booktitle> Compilers: Principles, Techniques and Tools. </booktitle> <publisher> Addison Wesly, </publisher> <year> 1986. </year>
Reference: [5] <author> R. Allen and K. Kennedy. </author> <title> Automatic Translation of Fortran Program to Vector Form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9, </volume> <year> 1987. </year>
Reference-contexts: 1 Introduction A number of efforts have been made to build parallelizing or vectorizing compilers which attempt to extract parallelism from code written in traditional sequential programming languages such as FORTRAN <ref> [26, 5, 27] </ref>. Others have concentrated on compiling specialized languages which are inherently concurrent, such as functional languages [18] and Data Flow [7]. Unfortunately, such languages are inadequate to model concurrency in a state-based, nondeterministic world [1]. A third language paradigm consists of languages which explicitly manipulate parallelism.
Reference: [6] <author> P. America and F. van der Linden. </author> <title> A Parallel Object-Oriented Language with Inheritance and Subtyping. </title> <booktitle> In OOPSLA '90, </booktitle> <pages> pages 161-168, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: All messages with the method name are not accepted until all conditions evaluate to FALSE . Use of disabling restrictions instead of enabling conditions <ref> [30, 6] </ref> ensures that the synchronization constraints which hold for a superclass also hold for the subclasses which are derived from the superclass. Therefore, programmers can reason about the subclasses in terms of the superclass [15].
Reference: [7] <author> Arvind and D. Culler. </author> <booktitle> Annual Reviews in Computer Science, chapter Dataflow Architecture, </booktitle> <pages> pages 225-253. </pages> <publisher> Annual Reviews Inc., </publisher> <year> 1986. </year>
Reference-contexts: Others have concentrated on compiling specialized languages which are inherently concurrent, such as functional languages [18] and Data Flow <ref> [7] </ref>. Unfortunately, such languages are inadequate to model concurrency in a state-based, nondeterministic world [1]. A third language paradigm consists of languages which explicitly manipulate parallelism. Some examples are CSP [9] and Occam [25].
Reference: [8] <author> W. Athas and C. Seitz. </author> <title> Cantor User Report Version 2.0. </title> <type> Technical Report 5232:TR:86, </type> <institution> California Institute of Technology, Pasadena, </institution> <address> CA, </address> <month> January </month> <year> 1987. </year>
Reference-contexts: It is beneficial to reclaim the resources which belong to such actors as soon as they become garbage. suicide is the primitive which does exactly what we want. It is similar to that used in Cantor <ref> [8] </ref>. When an actor executes the suicide primitive, it frees all the resources which are allocated to it so that the resources can be reused. This primitive can be used by a programmer or the compiler. Readers can find an example for the latter case in Section 3.1.1. <p> Act: It compiles the Scripter language into code which can be executed on a simulator for the Actor model, called Apiary, written on Symbolics 3600 Lisp machines. The Act compiler changes most system generated message sending to lisp function calls [13]. Cantor: Programs written for the Cantor system <ref> [8] </ref> can run on either sequential machines or Intel iPSC series machines. All communication is done through asynchronous message passing. Acore: C. Hewitt's group at M.I.T. implemented the Acore compiler on the Apiary operating system [24]. It allows for synchronous message passing as well as asynchronous message passing.
Reference: [9] <author> S. Brookes, C. Hoare, and A. Roscoe. </author> <title> A Theory of Communicating Sequential Processes. </title> <journal> Communications of the ACM, </journal> <volume> 31 </volume> <pages> 560-599, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: Others have concentrated on compiling specialized languages which are inherently concurrent, such as functional languages [18] and Data Flow [7]. Unfortunately, such languages are inadequate to model concurrency in a state-based, nondeterministic world [1]. A third language paradigm consists of languages which explicitly manipulate parallelism. Some examples are CSP <ref> [9] </ref> and Occam [25]. However, CSP and Occam have an unavoidable limitation in the sense that a process in these systems cannot create a new communication channel at run-time or pass it to another process. The configuration of the system is fixed at compile time resulting in a static topology.
Reference: [10] <author> Roy H. Campbell, Vincent Russo, and Gary Johnston. </author> <title> Choices: The Design of a Multiprocessor Operating System. </title> <booktitle> In Proceedings of the USENIX C++ Workshop, </booktitle> <pages> pages 109-123, </pages> <address> Santa Fe, New Mexico, </address> <month> November </month> <year> 1987. </year> <note> IEEE. </note>
Reference-contexts: Over 90% of the time was spent to execute CHARM kernel code, showing that the start-up overhead of CHARM is very high. In order to further improve performance, we are implementing our compiler on a lower-level run-time system, namely, CHOICES <ref> [10] </ref>, an object-oriented distributed operating system, which is known to be more efficient. 4 Related work In this section, we briefly compare our work with several previous efforts to build actor-based parallel languages and their compilers.
Reference: [11] <author> N. Carriero and D. Gelernter. </author> <title> Linda in Context. </title> <journal> Communication of the ACM, </journal> <volume> 32(4) </volume> <pages> 444-458, </pages> <month> April </month> <year> 1989. </year> <month> 23 </month>
Reference-contexts: We use the Actor model [1] which unifies the functional and the object-based view of computation, supports parallelism explicitly and provides for a dynamic topology of computational agents. On the other hand, the Actor model differs from the model used in LINDA <ref> [11] </ref>, which separates coordination from computation rather than treats them in a single framework. We have developed a high-level programming language, called Hal. Our goals in designing Hal are as follows: Generality: We want our programming language to be truly general purpose.
Reference: [12] <author> A. Chien. </author> <title> Concurrent Aggregates: An Object-Oriented Language for Fine-Grained Message--Passing Machines. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <month> July </month> <year> 1990. </year>
Reference-contexts: We avoid the single address bottleneck problem associated with the uniqueness of an actor's address by allowing concurrent access to a large data structure and locking only the relevant portion of the data structure. Our approach follows work on Concurrent Aggregates <ref> [12] </ref>. In the following section, we discuss some linguistic features of Hal with their semantics. Section 3 discusses the transformations of RPC style message sending and the transformation for code motion to optimize the implementation of replacement behavior. Some research related to our compiler is described in Section 4.
Reference: [13] <author> P. de Jong. </author> <title> Compilation into Actors. </title> <journal> SIGPLAN Notices, </journal> <volume> 21(10) </volume> <pages> 68-77, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: Act: It compiles the Scripter language into code which can be executed on a simulator for the Actor model, called Apiary, written on Symbolics 3600 Lisp machines. The Act compiler changes most system generated message sending to lisp function calls <ref> [13] </ref>. Cantor: Programs written for the Cantor system [8] can run on either sequential machines or Intel iPSC series machines. All communication is done through asynchronous message passing. Acore: C. Hewitt's group at M.I.T. implemented the Acore compiler on the Apiary operating system [24].
Reference: [14] <author> N. Francez. </author> <title> Fairness. Texts and Monographs in Computer Science. </title> <publisher> Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: Furthermore, asynchronous communication localizes the enforcement of synchronization constraints at the recipient. This is especially important since a requirement of fairness requires the re-evaluation of synchronization constraints with each message and state 4 change <ref> [14, 15] </ref>. Distributed Objects If only one actor is responsible for processing all incoming communications to a large data structure, the actor will be a bottleneck. <p> Communication is asynchronous and point-to-point to an acquaintance. The sender may not be known, but the recipient must be an acquaintance of the sender. The delivery of a message is guaranteed after an arbitrary, but finite, delay (a fairness condition <ref> [14] </ref>). * it may create more actors. These actors have their own unique mail addresses which are initially known only to their creator and possibly themselves. The replacement behavior of an actor is specified through the become primitive.
Reference: [15] <author> S. Frtlund. </author> <title> Inheritance of Synchronization Constraints in Concurrent Object-Oriented Programming Languages. </title> <booktitle> In Proceedings of European Conference on Object-Oriented Programming, </booktitle> <year> 1992. </year> <note> (to appear). </note>
Reference-contexts: Furthermore, asynchronous communication localizes the enforcement of synchronization constraints at the recipient. This is especially important since a requirement of fairness requires the re-evaluation of synchronization constraints with each message and state 4 change <ref> [14, 15] </ref>. Distributed Objects If only one actor is responsible for processing all incoming communications to a large data structure, the actor will be a bottleneck. <p> Earlier work has established how synchronization constraints can be used for software pipelining [3]. In particular, such pipelining transforms some algorithms, such as the Cholesky Decomposition of a symmetric positive definite matrix, from unscalable algorithms into scalable ones. We have adopted a philosophy of synchronization constraints proposed in <ref> [15] </ref>. All constraints are expressed as disabling restrictions. A disabling restriction means whenever any condition associated with a method evaluates to TRUE , the underlying system closes the entry point of the method and disables the method. <p> Use of disabling restrictions instead of enabling conditions [30, 6] ensures that the synchronization constraints which hold for a superclass also hold for the subclasses which are derived from the superclass. Therefore, programmers can reason about the subclasses in terms of the superclass <ref> [15] </ref>. Disabling restrictions are specified using the following syntax: (disable &lt;msg-expr&gt; &lt;expr&gt;) (all-except &lt;msg-expr&gt; &lt;expr&gt;) where &lt;msg-expr&gt; specifies the method name on which the constraint is imposed. <p> Hal allows the inheritance of both code and synchronization constraints. As in Smalltalk [22], any method of the superclass of an actor may be redefined in the definition of the actor. Synchronization constraints, however, may only be strengthened, not weakened <ref> [15] </ref>. In this sense, inheritance can be viewed as a means of specialization. However, we are investigating whether it is beneficial to allow first-class constraints. synchronization constraints. The most basic actor class is Stack which has the methods to push and pop one element to and from the stack, respectively. <p> This behavior is provided through the pop2 method. Under our constraint specification scheme, the definition of both pop and push methods can be inherited from the Stack class into both of these subclasses. Also, the incremental specialization of synchronization constraints is allowed through inheritance <ref> [15] </ref>. 9 2.4 State Change Replacement behavior is computed by the become primitive in the Actor model. An actor can become an entirely different actor as a result of processing the become primitive. However, in many cases, replacement behavior involves only one or two acquaintance changes of an actor.
Reference: [16] <author> C. Houck. </author> <title> Run-Time System Support for Distributed Actor Programs. </title> <type> Master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: Note that communications may contain mail addresses of actors; thus the interconnection topology of an actor system is dynamic. Building on the basic actor execution model, we have designed a high-level programming language, named Hal <ref> [16] </ref>. Hal is a descendant of actor languages such as Acore [24], Rosette [30] and ABCL/R [33]. It provides abstractions which facilitate software development. We describe the constructs used for such abstractions below, emphasizing implementation issues. <p> It provides abstractions which facilitate software development. We describe the constructs used for such abstractions below, emphasizing implementation issues. A more detailed description of the language constructs and their motivation may be found in <ref> [16, 17] </ref>. Note, however, that Hal is an evolving language. New high-level constructs are continually being developed and tested in order to explore ways of simplifying the task of parallel programming while improving 6 efficiency in execution. 2.2 Specification of Synchronization Constraints Actor semantics does not require message order preservation. <p> )) (if ra (block (update a x)) (block (update b y))) (if rb (block (update c x)) (block (update c y))))) 3.2.2 Performance Comparison Table 1 shows the execution time of different number of update 's when we compiled an actor program with 6 acquaintance variables using the earlier version <ref> [16] </ref> and the current version of the Hal compiler. The current version uses the optimization which is mentioned in Section 3.2.1.
Reference: [17] <author> C. Houck and G. Agha. HAL: </author> <title> A High-level Actor Language and Its Distributed Implementation. </title> <booktitle> In 21st International Conference on Parallel Processing (ICPP '92), </booktitle> <month> August </month> <year> 1992. </year> <note> (to appear). </note>
Reference-contexts: It provides abstractions which facilitate software development. We describe the constructs used for such abstractions below, emphasizing implementation issues. A more detailed description of the language constructs and their motivation may be found in <ref> [16, 17] </ref>. Note, however, that Hal is an evolving language. New high-level constructs are continually being developed and tested in order to explore ways of simplifying the task of parallel programming while improving 6 efficiency in execution. 2.2 Specification of Synchronization Constraints Actor semantics does not require message order preservation.
Reference: [18] <author> P. Hudak. </author> <title> Conception, Evolution and Application of Functional Programming Languages. </title> <journal> ACM Computing Surveys, </journal> <volume> 21(3) </volume> <pages> 359-411, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: 1 Introduction A number of efforts have been made to build parallelizing or vectorizing compilers which attempt to extract parallelism from code written in traditional sequential programming languages such as FORTRAN [26, 5, 27]. Others have concentrated on compiling specialized languages which are inherently concurrent, such as functional languages <ref> [18] </ref> and Data Flow [7]. Unfortunately, such languages are inadequate to model concurrency in a state-based, nondeterministic world [1]. A third language paradigm consists of languages which explicitly manipulate parallelism. Some examples are CSP [9] and Occam [25].
Reference: [19] <author> D. Kafura, D. Washabaugh, and J. Nelson. </author> <title> Garbage Collection of Actors. </title> <booktitle> In OOPSLA '90, </booktitle> <pages> pages 126-134, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: Active research is being done to incorporate distributed data structures in our compiler. A fair amount of effort has been made to preserve the concurrency which is naturally expressed in Hal. Currently, the run-time system for Hal does not support garbage collection. Distributed garbage collector <ref> [19, 32] </ref> should be incorporated in near future.
Reference: [20] <author> L. Kale. </author> <title> The CHARM(3.0) Programming Language Manual. </title> <institution> University of Illinois, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: In all cases, optimized update yields less code size. Currently, Hal programs run on the top of the CHARM programming system which is a C based system <ref> [20] </ref>. CHARM has been implemented on both shared and distributed memory machines. The total execution time for this simple example was about 0.0527 20 sec. Over 90% of the time was spent to execute CHARM kernel code, showing that the start-up overhead of CHARM is very high. <p> Hal supports the specialization and factorization of both code and synchronization constraints using inheritance. Other features such as sequenced send, RPC style send, and update are added to make the language a general and easily programmable one. The Hal compiler generates a program written in CHARM <ref> [20] </ref> as its output. Optimization on the update primitive is implemented in Hal. We are implementing the transformation to extract a join continuation actor. Optimization on synchronization constraints is going to be added in near future. Active research is being done to incorporate distributed data structures in our compiler.
Reference: [21] <author> D. A. Kranz. </author> <title> ORBIT: An Optimizing Compiler for Scheme. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> February </month> <year> 1988. </year> <month> YALEU/DCS/RR-632. </month>
Reference-contexts: The send expression has no effect on the computation of the other parts of the method script except that it should be executed only after it gets all the replies from the bsend expressions. Simply making the continuation passing style (CPS) conversion <ref> [29, 21] </ref> is not satisfactory since it sequentializes the execution of the bsend expressions, causing a loss of concurrency. We create an independent join continuation actor through dependency analyses.
Reference: [22] <author> W. LaLonde and J. Pugh. </author> <title> Inside Smalltalk, volume 1. </title> <publisher> Prentice Hall, </publisher> <year> 1990. </year>
Reference-contexts: Class variables are not supported since they imply shared data between actors, thus restricting their autonomy and distribution. Hal allows the inheritance of both code and synchronization constraints. As in Smalltalk <ref> [22] </ref>, any method of the superclass of an actor may be redefined in the definition of the actor. Synchronization constraints, however, may only be strengthened, not weakened [15]. In this sense, inheritance can be viewed as a means of specialization.
Reference: [23] <author> P. Maes. </author> <title> computational reflection. </title> <type> Technical Report 87-2, </type> <institution> Vrije University. Artificial Intelligence Laboratory, </institution> <year> 1987. </year>
Reference-contexts: Readers can find an example for the latter case in Section 3.1.1. Once garbage collection has been fully optimized, use of suicide would be discouraged since suicide creates unsafe programs. 2.7 Reflection Reflection is a system's ability to reason about itself and manipulate a causally connected description of itself <ref> [28, 23] </ref>. Causal connection means that changes to the description have an immediate effect on the described object. Note, however, that the changes go into effect only for the subsequent messages. In general, reflection may be used to customize the implementation of a system from within the language.
Reference: [24] <author> C. Manning. ACORE: </author> <title> The Design of a Core Actor Language and its Compiler. </title> <type> Master's thesis, </type> <institution> MIT, Artificial Intelligence Laboratory, </institution> <month> August </month> <year> 1987. </year>
Reference-contexts: Note that communications may contain mail addresses of actors; thus the interconnection topology of an actor system is dynamic. Building on the basic actor execution model, we have designed a high-level programming language, named Hal [16]. Hal is a descendant of actor languages such as Acore <ref> [24] </ref>, Rosette [30] and ABCL/R [33]. It provides abstractions which facilitate software development. We describe the constructs used for such abstractions below, emphasizing implementation issues. A more detailed description of the language constructs and their motivation may be found in [16, 17]. Note, however, that Hal is an evolving language. <p> The former is the message order preserving send primitive, or sequenced send. The latter is the RPC style send primitive akin to Acore's ask primitive <ref> [24] </ref>. <p> acq1 acq2 v1 x v3) (suicide)) (block (update v2 x) (update f2 TRUE)))) (method (ep3 x) (if (and f1 f2) (block (send mB acq1 acq2 v1 v2 x) (suicide)) (block (update v3 x) (update f3 TRUE))))) The transformation given in this section is similar to the transformation done in Acore <ref> [24] </ref>. 15 (let* [[jc (new JC (new ActorB a b) x 0 0 0 FALSE FALSE FALSE)]] (send mC ActorC ... ep1 jc) (send mD ActorD ... ep2 jc) (send mE ActorE ... ep3 jc)) However, there are two major differences. <p> Cantor: Programs written for the Cantor system [8] can run on either sequential machines or Intel iPSC series machines. All communication is done through asynchronous message passing. Acore: C. Hewitt's group at M.I.T. implemented the Acore compiler on the Apiary operating system <ref> [24] </ref>. It allows for synchronous message passing as well as asynchronous message passing. Rosette: Developed at MCC in collaboration with one of the authors, Rosette [30] runs on a uni-processor virtual machine. It supports synchronous and asynchronous message passing.
Reference: [25] <author> D. May, R. Shepherd, and C. Keane. </author> <title> Communicating Process Architecture: Transputer and Occam. </title> <editor> In P. Treleaven and M. Vanneschi, editors, </editor> <booktitle> Future Parallel Architecture, </booktitle> <pages> pages 35-81. </pages> <publisher> Springer-Verlag, </publisher> <year> 1986. </year> <note> LNCS 272. </note>
Reference-contexts: Unfortunately, such languages are inadequate to model concurrency in a state-based, nondeterministic world [1]. A third language paradigm consists of languages which explicitly manipulate parallelism. Some examples are CSP [9] and Occam <ref> [25] </ref>. However, CSP and Occam have an unavoidable limitation in the sense that a process in these systems cannot create a new communication channel at run-time or pass it to another process. The configuration of the system is fixed at compile time resulting in a static topology.
Reference: [26] <author> D. Padua and M. Wolfe. </author> <title> Advance compiler optimizations for supercomputers. </title> <journal> Communication of the ACM, </journal> <volume> 29(12) </volume> <pages> 1184-1201, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: 1 Introduction A number of efforts have been made to build parallelizing or vectorizing compilers which attempt to extract parallelism from code written in traditional sequential programming languages such as FORTRAN <ref> [26, 5, 27] </ref>. Others have concentrated on compiling specialized languages which are inherently concurrent, such as functional languages [18] and Data Flow [7]. Unfortunately, such languages are inadequate to model concurrency in a state-based, nondeterministic world [1]. A third language paradigm consists of languages which explicitly manipulate parallelism.
Reference: [27] <author> C.D. Polychronopoulos, M.B. Girkar, M.R. Haghighat, C.L. Lee, B.P. Leung, and D.A. Schouten. </author> <title> The Structure of Parafrase-2: an Advanced Parallelizing Compiler for C and Fortran. </title> <editor> In D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 423-453. </pages> <publisher> The MIT press, </publisher> <year> 1990. </year>
Reference-contexts: 1 Introduction A number of efforts have been made to build parallelizing or vectorizing compilers which attempt to extract parallelism from code written in traditional sequential programming languages such as FORTRAN <ref> [26, 5, 27] </ref>. Others have concentrated on compiling specialized languages which are inherently concurrent, such as functional languages [18] and Data Flow [7]. Unfortunately, such languages are inadequate to model concurrency in a state-based, nondeterministic world [1]. A third language paradigm consists of languages which explicitly manipulate parallelism.
Reference: [28] <author> B. C. Smith. </author> <title> Reflection and semantics in a procedural language. </title> <type> Technical Report 272, </type> <institution> Massachusetts Institute of Technology. Laboratory of Computer Science, </institution> <year> 1982. </year>
Reference-contexts: Readers can find an example for the latter case in Section 3.1.1. Once garbage collection has been fully optimized, use of suicide would be discouraged since suicide creates unsafe programs. 2.7 Reflection Reflection is a system's ability to reason about itself and manipulate a causally connected description of itself <ref> [28, 23] </ref>. Causal connection means that changes to the description have an immediate effect on the described object. Note, however, that the changes go into effect only for the subsequent messages. In general, reflection may be used to customize the implementation of a system from within the language.
Reference: [29] <author> G.L. Jr. Steele. RABBIT: </author> <title> a compiler for SCHEME. AI Memo 474, </title> <publisher> MIT, </publisher> <month> May </month> <year> 1978. </year> <month> 24 </month>
Reference-contexts: The send expression has no effect on the computation of the other parts of the method script except that it should be executed only after it gets all the replies from the bsend expressions. Simply making the continuation passing style (CPS) conversion <ref> [29, 21] </ref> is not satisfactory since it sequentializes the execution of the bsend expressions, causing a loss of concurrency. We create an independent join continuation actor through dependency analyses.
Reference: [30] <author> C. Tomlinson, W. Kim, M. Schevel, V. Singh, B. Will, and G. Agha. Rosette: </author> <title> An Object Oriented Concurrent System Architecture. </title> <journal> SIGPLAN Notices, </journal> <volume> 24(4) </volume> <pages> 91-93, </pages> <year> 1989. </year>
Reference-contexts: Note that communications may contain mail addresses of actors; thus the interconnection topology of an actor system is dynamic. Building on the basic actor execution model, we have designed a high-level programming language, named Hal [16]. Hal is a descendant of actor languages such as Acore [24], Rosette <ref> [30] </ref> and ABCL/R [33]. It provides abstractions which facilitate software development. We describe the constructs used for such abstractions below, emphasizing implementation issues. A more detailed description of the language constructs and their motivation may be found in [16, 17]. Note, however, that Hal is an evolving language. <p> All messages with the method name are not accepted until all conditions evaluate to FALSE . Use of disabling restrictions instead of enabling conditions <ref> [30, 6] </ref> ensures that the synchronization constraints which hold for a superclass also hold for the subclasses which are derived from the superclass. Therefore, programmers can reason about the subclasses in terms of the superclass [15]. <p> All communication is done through asynchronous message passing. Acore: C. Hewitt's group at M.I.T. implemented the Acore compiler on the Apiary operating system [24]. It allows for synchronous message passing as well as asynchronous message passing. Rosette: Developed at MCC in collaboration with one of the authors, Rosette <ref> [30] </ref> runs on a uni-processor virtual machine. It supports synchronous and asynchronous message passing. Synchronization constraints are specified through enabled sets [31] which specify the methods that may be invoked by the next message.
Reference: [31] <author> C. Tomlinson and V. Singh. </author> <title> Inheritance and Synchronization with Enabled-Sets. </title> <booktitle> In OOPSLA, </booktitle> <year> 1989. </year>
Reference-contexts: It allows for synchronous message passing as well as asynchronous message passing. Rosette: Developed at MCC in collaboration with one of the authors, Rosette [30] runs on a uni-processor virtual machine. It supports synchronous and asynchronous message passing. Synchronization constraints are specified through enabled sets <ref> [31] </ref> which specify the methods that may be invoked by the next message. Enabled sets are mixed in with the code so that Rosette cannot support incremental specialization of synchronization constraints. 21 ABCL/R: ABCL (Actor Based Concurrent Language) provides for asynchronous, synchronous and future based message passing.
Reference: [32] <author> N. Venkatasubramian. </author> <title> Hierarchical Memory Management in Scalable Parallel Systems. </title> <type> Master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1991. </year>
Reference-contexts: Active research is being done to incorporate distributed data structures in our compiler. A fair amount of effort has been made to preserve the concurrency which is naturally expressed in Hal. Currently, the run-time system for Hal does not support garbage collection. Distributed garbage collector <ref> [19, 32] </ref> should be incorporated in near future.
Reference: [33] <author> T. Watanabe and A. Yonezawa. </author> <title> ABCL An Object-Oriented Concurrent System, </title> <booktitle> chapter Reflection in an Object-Oriented Concurrent Language, </booktitle> <pages> pages 45-70. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, Mass, </address> <year> 1990. </year>
Reference-contexts: Building on the basic actor execution model, we have designed a high-level programming language, named Hal [16]. Hal is a descendant of actor languages such as Acore [24], Rosette [30] and ABCL/R <ref> [33] </ref>. It provides abstractions which facilitate software development. We describe the constructs used for such abstractions below, emphasizing implementation issues. A more detailed description of the language constructs and their motivation may be found in [16, 17]. Note, however, that Hal is an evolving language.
Reference: [34] <author> P. Wegner. </author> <title> Dimensions of Object-Based Language Design. </title> <type> Technical Report CS-87-14, </type> <institution> Brown University, </institution> <month> July </month> <year> 1987. </year>
Reference-contexts: Specifically, our scheme uses dynamic dependency lists between an actors acquaintance and constraints. 2.3 Inheritance Hal has been designed to satisfy all of Wegner's qualifications to be classified as an object-oriented language <ref> [34] </ref> . Class variables are not supported since they imply shared data between actors, thus restricting their autonomy and distribution. Hal allows the inheritance of both code and synchronization constraints.
Reference: [35] <author> A. Yonezawa, </author> <title> editor. ABCL An Object-Oriented Concurrent System. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1990. </year> <month> 25 </month>
Reference-contexts: ABCL also allows the specification of synchronization constraints. One difference of Hal and ABCL is that ABCL does not support inheritance <ref> [35] </ref>. 5 Current Status and Future Research Direction Some practical examples show the performance advantage of using fine-grained inherent concurrency in the Actor model for distributed execution on multicomputers [3].
References-found: 35

