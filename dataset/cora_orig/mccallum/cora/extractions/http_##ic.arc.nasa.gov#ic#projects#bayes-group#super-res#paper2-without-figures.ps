URL: http://ic.arc.nasa.gov/ic/projects/bayes-group/super-res/paper2-without-figures.ps
Refering-URL: http://ic.arc.nasa.gov/ic/projects/super-res/
Root-URL: 
Email: Email: &lt;last-name&gt;@ptolemy.arc.nasa.gov  
Phone: Phone: (415) 604-4946  
Title: Super-Resolved Surface Reconstruction From Multiple Images  
Author: Peter Cheeseman RIACS Bob Kanefsky Richard Kraft John Stutz Robin Hanson 
Date: December 14, 1994  
Web: World-Wide Web: http://ic-www.arc.nasa.gov/ic/projects/bayes-group/group/super-res/  
Note: Related information available on the  
Address: Moffett Field, CA 94035, USA  
Affiliation: Recom Technologies  Recom Technologies  NASA  Recom Technologies Artificial Intelligence Research Branch NASA Ames Research Center, Mail Stop 269-2  Research Institute for Advanced Computer Science  
Pubnum: Technical Report FIA-94-12  
Abstract: This paper describes a Bayesian method for constructing a super-resolved surface model by combining information from a set of images of the given surface. We develop the theory and algorithms in detail for the 2-D reconstruction problem, appropriate for the case where all images are taken from roughly the same direction and under similar lighting conditions. We show the results of this 2-D reconstruction on Viking Martian data. These results show dramatic improvements in both spatial and gray-scale resolution. The Bayesian approach uses a neighbor correlation model as well as pixel data from the image set. Some extensions of this method are discussed, including 3-D surface reconstruction and the resolution of diffraction blurred images. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. Press, B. Flannery, S. Teukolsky, W. </author> <title> Vetterling,Numerical Recipes in C, </title> <publisher> Cambridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: Optimal registration parameters were determined by the Simplex algorithm <ref> [1] </ref>, which searches for a minimum of the squared error by systematically varying the registration parameters, and then calculating the squared error for each such registration. (However, we assume that the error is a smooth function of the registration parameters.
Reference: [2] <author> R. W. Gaskell. </author> <title> Digital Identification of Cartographic Control Points, </title> <journal> Photogrammetric Engineering and Remote Sensing, </journal> <volume> Vol. 54, No. 6, Part 1, </volume> <month> June </month> <year> 1988, </year> <pages> pp. 723-727. </pages>
Reference-contexts: There are more efficient search algorithms than the Simplex algorithm, but they are not generally as robust. Note that standard methods for accurate relative image registration required locating features common to both images and finding a global mapping for all features to their counterparts in the other image <ref> [2] </ref>. The method described here uses all the information in both images, and this is part of the reason for the very high (subpixel) accuracy achieved by the method described here.
Reference: [3] <author> M. Benesh, and T. Thorpe. </author> <title> Viking Orbiter 1975 visual imaging subsystem calibration report, </title> <type> JPL Document 611-125, </type> <institution> Jet Propulsion Laboratory, Pasadena, </institution> <address> Ca., </address> <year> 1976. </year> <month> 11 </month>
Reference-contexts: The affine transformation set is the parameter space in which the registration search is executed, and is sufficient for accurate registration provided that the principle nonlinear camera effects <ref> [3] </ref> are not severe. When these effects interfere, we have extended to a quadratic family of transformations. 4.2 PSF and Other Parameters The point spread function (PSF) describes how the light energy from a point on the external surface is distributed over the image plane. <p> In practice, the PSF can vary across the image plane, and with time. We have not attempted to model this variation, and work with an average PSF derived from the instrument's bench calibration <ref> [3] </ref>. Shading is the characteristic smooth variation in detector sensitivity across the image plane 7 in vidicon tubes, equivalent to the variation of individual cell sensitivities in array detectors. <p> x (r) = (L + U ) x (r1) + b which, if Dx = x (r) x (r1) can be rewritten Dx = D 1 (b A x (r1) ) (13) 5 These are permanent marks on the camera faceplate used for calibrating the optics in the Vidicon camera <ref> [3] </ref>. 8 This can be shown to be equivalent to the method of substitution, a useful fact for extensions of the model. To implement Eqn. (13), note that D = s 2 (1 + j ij ) + 2 p ip (14) is the denominator of Eqn. (13).
Reference: [4] <author> E. Eliason et. al. </author> <title> Adaptive box filters for removal of random noise from digital images, </title> <journal> Pho--togrammetric Engineering and Remote Sensing, </journal> <volume> 56, </volume> <pages> 453-456, </pages> <year> 1990. </year>
Reference-contexts: Defects in the optical system or on the image plane generate blemishes e.g., dust particles and scratches common to all images from that camera. A blemish map is used to identify suspect pixels. Rather than interpolating the missing values as is common practice <ref> [4] </ref>, we ignore these pixels, so that the corresponding mixels may be influenced only by the other frames. Also, since spacecraft that are many light-minutes away cannot be asked to retransmit corrupted data packets, they do not implement a reliable transport protocol, and some pixels have incorrect values.
Reference: [5] <author> M. Carr et. al. </author> <title> Archive of Digital Images from NASA's Viking Orbiter 1 and 2 Missions, Planetary Data System, </title> <institution> National Space Science Data Center, CD-ROM: USA NASA PDS VO 1003, Frames VO217S42-88. </institution>
Reference-contexts: routine is of order O (k)P , suggesting that finding an optimal compositing routine would be a good strategy for obtaining quick (if improvable) results. 4.6 Results Fig. 4.6 gives results for a U.S. postage stamp digitized at low resolution by a scanner, and for Viking Orbiter images of Mars <ref> [5] </ref>. The Viking reconstruction uses a series of 24 vidicon images of Mars; the data are from a high spacecraft altitude, with frames of very similar sun and camera angles.
Reference: [6] <author> B.K.P. Horn and M.J. </author> <title> Brooks.Shape from Shading, </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1989 </year>
Reference-contexts: This information loss makes pixel-by-pixel comparison very dubious. The super-resolved surface modeling described in this paper does allow the integration and comparison of information from many images through the accumulated super-resolution surface model. A related approach to the Bayesian 3-D surface reconstruction described above is called Shape from Shading <ref> [6] </ref>. This approach integrates observed surface intensity gradients from a single image to give a 3-D elevation model of the generating surface. It assumes a constant albedo, known illumination conditions, and surface continuity.
Reference: [7] <author> J. Thomas, W. Kober, and F. </author> <title> Leberl.Multiple Image SAR Shape-from-Shading, </title> <journal> Photogrammetric Engineering and Remote Sensing, </journal> <volume> Vol. 57, No. 1, </volume> <month> Jan. </month> <year> 1991, </year> <pages> pp. 51-59. </pages>
Reference-contexts: This approach integrates observed surface intensity gradients from a single image to give a 3-D elevation model of the generating surface. It assumes a constant albedo, known illumination conditions, and surface continuity. Shape from shading can be extended to multiple images <ref> [7] </ref>, and the result is greater detail in the elevation map because each grid point contains information from multiple images. However, the constant albedo assumption is a strong limitation on the ability to extract information from multiple images. A Bayesian approach very similar to ours is described in [8].
Reference: [8] <author> Y. P. Hung and D. B. </author> <title> Cooper.Maximum a posteriori probability 3D surface reconstruction using multiple intensity images directly, </title> <booktitle> SPIE Vol. 1260 Sensing and Reconstruction of Three-Dimensional Objects and Scenes (1990), </booktitle> <pages> pp. 36-48. </pages>
Reference-contexts: However, the constant albedo assumption is a strong limitation on the ability to extract information from multiple images. A Bayesian approach very similar to ours is described in <ref> [8] </ref>. This approach does surface reconstruction using images from different viewpoints, and a neighbor correlation prior with a Gaussian noise model. The surface is represented by planar patches joined to form a curved surface.
Reference: [9] <author> C. </author> <title> Elachi.Introduction to the Physics and Techniques of Remote Sensing, </title> <publisher> Wiley and Sons, </publisher> <address> New York, </address> <year> 1987 </year>
Reference-contexts: What we read off the camera is the radiant energy received by each pixel <ref> [9] </ref>. Note the split of parameters into two sets: observation parameters and mixels. We will explain the significance of this split below.
Reference: [10] <author> K. Mardia, J. Kent, and J. Bibby. </author> <title> Multivariate Analysis, </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1979. </year>
Reference-contexts: [m i j m; S ij ] fl p = M ax (N [m i j m; A ij ]) (10) where A ij = S ij + 2 p The matrix A ij in Eqn. (11) is calculated by standard methods in completing the square for multi variate distributions <ref> [10] </ref>. The peak of the distribution in Eqn. (10) are the m i that satisfy X A ij (m i m) = 2 p We can thus find the maximum posterior mixel grid m i given the auxiliary parameters by simply solving this linear equation.
Reference: [11] <author> S. Mann and R. </author> <title> Picard. Virtual Bellows: Constructing High Quality Stills from Video, </title> <booktitle> Proc. ICIP, </booktitle> <address> Austin, Texas, </address> <month> Nov. </month> <year> 1994. </year> <month> 12 </month>
Reference-contexts: In our approach we achieve super-resolution, and there is no aggregation of surface mixels into large scale patches. Although our goals and assumptions are significantly different we use the same basic Bayesian approach. A related area of study is in combining images from video <ref> [11] </ref>. Here, the registration of images passes from the discrete to the continuous, and thus the techniques of optical flow are used. Acknowledgements We gratefully acknowledge the fruitful contributions of Chris Wallace and Wray Buntine.
References-found: 11

