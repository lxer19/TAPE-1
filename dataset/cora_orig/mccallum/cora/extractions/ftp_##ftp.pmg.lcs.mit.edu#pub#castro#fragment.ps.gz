URL: ftp://ftp.pmg.lcs.mit.edu/pub/castro/fragment.ps.gz
Refering-URL: http://www.pmg.lcs.mit.edu/~castro/pubs.html
Root-URL: 
Title: Fragment Reconstruction: A New Cache Coherence Scheme for Split Caching Storage Systems (Looking at the
Author: Liuba Shrira, Barbara Liskov, Miguel Castro and Atul Adya 
Address: Cambridge, MA 02139  
Affiliation: Laboratory for Computer Science MIT  
Abstract: This paper describes a new scalable memory management architecture, split caching, for network-based transactional object storage systems. The architecture allows storage system clients and servers to take advantage of emerging high speed networks to avoid the increasing disk I/O bottleneck. In contrast to traditional storage systems, where server caches are used both to avoid disk reads and optimize disk updates, split caching decouples the two functions. Clients fetch pages from other clients' caches. Servers cache only new versions of recently modified objects, fetching an object's page from a client when they install a new version of the object on the database copy on disk. This reduces the number of disk reads both for satisfying client fetches, and for installing new object versions. Split caching uses a fine-grained concurrency control algorithm. This algorithm invalidates stale cached copies of an object when a transaction commits a new version of that object. Therefore, the pages in a client's cache may be fragmented, i.e. contain "holes" corresponding to invalid objects. When such a page is sent to the server or to another client, it is necessary to fill in the holes using the modifications cached at the server, an algorithm we call fragment reconstruction. This paper describes this algorithm and argues that it provides clients with a consistent view of database objects. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Adya, R. Gruber, B. Liskov, and U. Mahesh-wari. </author> <title> Efficient optimistic concurrency control using loosely synchronized clocks. </title> <booktitle> In International Conference on Management of Data. Association for Computing Machinery SIGMOD, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: Split caching relies on a cache coherence protocol called fragment reconstruction that ensures clients have a consistent view of database objects. The protocol works in the presence of concurrency control techniques that support fine-grained sharing (e.g., adaptive call-back locking [3] or the optimistic approach used in Thor <ref> [1] </ref>); such techniques are desirable because they avoid conflicts due to false sharing. In such systems, when a transaction commits new versions of some objects, this may cause pages in other client caches to become fragments, i.e. pages containing stale copies of the objects modified by those transactions. <p> The server responds with a copy of the requested object. Clients cache objects across transaction boundaries. Thor uses a new optimistic concurrency control and cache consistency protocol based on loosely synchronized clocks and invalidation messages <ref> [1] </ref>. When the application requests a transaction commit, the new values of the objects modified by the transaction are sent from the client cache to the server along with other concurrency control information. The server validates the transaction, using a two-phase commit protocol if a transaction accesses multiple servers. <p> In contrast, fragment reconstruction takes advantage of the update absorption provided by the modified object cache. The split caching architecture builds on our work in Thor [2], namely on the mcache architecture [16, 7], hybrid caching [15] and transactional invalidation based coherence <ref> [1] </ref>, and extends this work to support global caching in a workstation cluster and avoid installation reads from disk. 6 Conclusions This paper presents the split caching global memory management scheme, and the transactional fragment reconstruction coherence protocol integrated with Thor's mcache.
Reference: [2] <author> B.Liskov, A.Adya, M.Castro, M.Day, S.Ghemawat, R.Gruber, U.Maheshwari, A.Myers, and L.Shrira. </author> <title> Safe and efficient sharing of persistent objects in thor. </title> <year> 1996. </year>
Reference-contexts: Therefore, we instead invalidate those stale copies, and use fragment reconstruction to bring those pages up to date using the fragment and the information in the mcache. Our work has been done in the context of Thor <ref> [2] </ref>. Thor supports fine-grained sharing and uses an mcache architecture to optimize updates. However, Thor clients maintain an object cache, whereas split caching uses a page cache; and Thor servers have a page cache, unlike servers in the split caching architecture that only maintain the mcache. <p> We discuss related research in Section 5 and our conclusions in Section 6. 2 Thor Architecture We are carrying out our studies in the context of the Thor object-oriented database system <ref> [2] </ref>. Thor has a distributed client/server architecture. Persistent objects are stored on disk at the servers. Application code runs at clients. Applications interact with Thor within atomic transactions that read and write persistent objects. <p> The recoverable distributed shared memory coherence protocol propagates updates to cached pages at commit time. In contrast, fragment reconstruction takes advantage of the update absorption provided by the modified object cache. The split caching architecture builds on our work in Thor <ref> [2] </ref>, namely on the mcache architecture [16, 7], hybrid caching [15] and transactional invalidation based coherence [1], and extends this work to support global caching in a workstation cluster and avoid installation reads from disk. 6 Conclusions This paper presents the split caching global memory management scheme, and the transactional fragment
Reference: [3] <author> M. Carey, M. Franklin, and M. Zaharioudakis. </author> <title> Fine-Grained Sharing in a Page Server OODBMS. </title> <booktitle> In Proceedings of SIGMOD 1994, </booktitle> <year> 1994. </year>
Reference-contexts: Split caching relies on a cache coherence protocol called fragment reconstruction that ensures clients have a consistent view of database objects. The protocol works in the presence of concurrency control techniques that support fine-grained sharing (e.g., adaptive call-back locking <ref> [3] </ref> or the optimistic approach used in Thor [1]); such techniques are desirable because they avoid conflicts due to false sharing. <p> Simulation studies show that this scheme outperforms the best pessimistic scheme (adaptive callback locking <ref> [3] </ref>) on almost all workloads [9]. 2.2 Server Organization The servers have disk for storing persistent objects, a stable transaction log and some memory. The disk is organized as a collection of large pages that contain many objects, and that are the items read and written to disk. <p> In particular, fragment reconstruction could be used in a more traditional caching architecture where servers cache pages. It could also be used with different concurrency control mechanisms although the concurrency control mechanism affects how coherence works, e.g., a system that uses locking <ref> [3] </ref> might have to send a page with holes in response to a fetch (since some of its objects are locked right now). The paper argues that the fragment reconstruction protocol preserves the correctness of the con-currency control and recovery protocols in Thor.
Reference: [4] <author> Michael J. Carey, Michael J. Franklin, Miron Livny, and Eugene J. Shekita. </author> <title> Data caching tradeoffs in client-server dbms architectures. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 357-366, </pages> <year> 1991. </year>
Reference-contexts: Research indicates that bringing such pages up to date by propagating the new object versions is not efficient <ref> [4] </ref>. Therefore, we instead invalidate those stale copies, and use fragment reconstruction to bring those pages up to date using the fragment and the information in the mcache. Our work has been done in the context of Thor [2].
Reference: [5] <author> A. Delis and N. Roussopoulos. </author> <title> Performance and scalability of client-server database architecture. </title> <booktitle> In Proceedings of the 18th Conference on Very-Large Databases, </booktitle> <year> 1992. </year>
Reference-contexts: Unlike split caching, this work considers a page granularity architecture and does not deal with fine-grained sharing of objects. Another difference is that it uses locking instead of optimistic concurrency control. A scheme similar to Thor's mcache is described in <ref> [5] </ref>. In this scheme, the database server manages a cache of recent updates. Before a client accesses an object, it contacts a server to retrieve the updates needed to bring the cached copy of the object up to date.
Reference: [6] <author> M. Franklin, M. Carey, and M. Livny. </author> <title> Global memory management in client-server dbms architectures. </title> <booktitle> In Proceedings of 18th VLDB Conf., </booktitle> <year> 1992. </year>
Reference-contexts: In contrast, split caching exploits the mcache based server architecture to provide both transactional reliability guarantees and good performance. Several transactional storage systems have used remote memory to reduce disk accesses. Franklin et al. <ref> [6] </ref> studied the advantages of remote memory access and global caching in a page-based client/server database. Unlike split caching, this work considers a page granularity architecture and does not deal with fine-grained sharing of objects. Another difference is that it uses locking instead of optimistic concurrency control.
Reference: [7] <author> S. Ghemawat. </author> <title> The Modified Object Buffer: A Storage Management Technique for Object-Oriented Databases. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1995. </year>
Reference-contexts: Clients exploit network speed and large aggregate client memory by fetching pages from other clients' caches to avoid disk reads. Servers cache only new versions of recently modified objects, using a large recoverable cache called the mcache, to perform disk updates more efficiently <ref> [16, 7] </ref>. When objects are moved from the mcache to the database on disk, it is necessary to first perform an installation read to obtain the containing pages; these pages are read from client caches to avoid reading them from disk. <p> If the object is not in the cache, the server reads the object's page from disk, stores it in the cache, and replies to the client when the disk read completes. The mcache based server architecture improves the efficiency of disk updates for small objects <ref> [16, 7] </ref>. It stores modifications in a very compact form, since only the modified objects are stored. This allows the system to delay writing modifications to the database longer than if the pages containing the objects were stored. <p> If the server crashes, the mcache is reconstructed at recovery by scanning the log. Performance studies show that for most work-loads the mcache architecture outperforms other architectures <ref> [16, 7] </ref>, including conventional architectures in which the server stores modified pages, and the clients ship entire pages to the server at commit. 3 The New Caching Architecture The new caching architecture is based on Thor. <p> Work on the mcache has shown that for most workloads, performance improves as memory is shifted from the server cache to the mcache <ref> [7] </ref>. This result is consistent with the third observation: since the server page cache is not very effective, it makes sense to shift the memory to the mcache (where it can be used to delay in stalling changes in the database). 6. <p> The recoverable distributed shared memory coherence protocol propagates updates to cached pages at commit time. In contrast, fragment reconstruction takes advantage of the update absorption provided by the modified object cache. The split caching architecture builds on our work in Thor [2], namely on the mcache architecture <ref> [16, 7] </ref>, hybrid caching [15] and transactional invalidation based coherence [1], and extends this work to support global caching in a workstation cluster and avoid installation reads from disk. 6 Conclusions This paper presents the split caching global memory management scheme, and the transactional fragment reconstruction coherence protocol integrated with Thor's
Reference: [8] <author> J. Gray and A. Reuter. </author> <title> Transaction Processing: Concepts and Techniques. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: It combines highly scalable caching techniques developed in large-scale cache-coherent multiprocessors like DASH [10] and in distributed file systems like xFS [12], with high reliability techniques developed in traditional databases <ref> [8] </ref>. Traditionally, server caches are used both to avoid disk reads and optimize disk updates. This organization is not scalable because a server cache becomes less effective in avoiding disk reads when there are many clients.
Reference: [9] <author> R. Gruber. </author> <title> "Optimism vs. Locking: A Study of Concurrency Control for Client-Server Object-Oriented Databases". </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1996. </year>
Reference-contexts: Simulation studies show that this scheme outperforms the best pessimistic scheme (adaptive callback locking [3]) on almost all workloads <ref> [9] </ref>. 2.2 Server Organization The servers have disk for storing persistent objects, a stable transaction log and some memory. The disk is organized as a collection of large pages that contain many objects, and that are the items read and written to disk.
Reference: [10] <author> D. Lenoski, J. Laudon, K. Ghara-chorloo, A. Gupta, and J. Henessy. </author> <title> The directory based cache coherence protocol for the dash multiprocessor. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <year> 1990. </year>
Reference-contexts: Split caching addresses this problem by taking advantage of emerging high speed local area networks to o*oad work from servers to clients. It combines highly scalable caching techniques developed in large-scale cache-coherent multiprocessors like DASH <ref> [10] </ref> and in distributed file systems like xFS [12], with high reliability techniques developed in traditional databases [8]. Traditionally, server caches are used both to avoid disk reads and optimize disk updates.
Reference: [11] <author> L.Shrira. </author> <title> A Correctness Proof for Fragment Reconstruction. </title> <booktitle> In umpublished manuscript, </booktitle> <year> 1996. </year>
Reference-contexts: A detailed correctness proof is given in <ref> [11] </ref>. Our goal is to show that the new memory management system with split caching and fragment reconstruction 6 (NEW) implements a version of Thor with a zero size server cache and a client object cache replacement policy that mimics a page-based cache (OLD). <p> Therefore using the cached copy of the page to update the disk has the same effect as reading the page from disk. In <ref> [11] </ref>, we give a precise description of the execution of OLD and NEW, using an automaton based model.
Reference: [12] <author> M.D.Dahlin, R.Y. Wang, T.E.Anderson, and D.A. Patterson. </author> <title> Cooperative caching:using remote client memory to improve file system performance. </title> <booktitle> In Proceedings of Operating Systems Design and Implementation, </booktitle> <year> 1994. </year>
Reference-contexts: Split caching addresses this problem by taking advantage of emerging high speed local area networks to o*oad work from servers to clients. It combines highly scalable caching techniques developed in large-scale cache-coherent multiprocessors like DASH [10] and in distributed file systems like xFS <ref> [12] </ref>, with high reliability techniques developed in traditional databases [8]. Traditionally, server caches are used both to avoid disk reads and optimize disk updates. This organization is not scalable because a server cache becomes less effective in avoiding disk reads when there are many clients. <p> When a client fetches a page, it may have to evict another page. This evicted page may be sent to another client so that it can be refetched later if needed. Strategies have been developed to utilize the client caches effectively <ref> [12, 13] </ref>. In this paper, we focus on the orthogonal issue of supporting efficient fine-grained write sharing with 1 transactional reliability guarantees. Split caching relies on a cache coherence protocol called fragment reconstruction that ensures clients have a consistent view of database objects. <p> To put our work in perspective, we describe related research in storage systems that use global caching techniques to avoid disk accesses and improve scalability. Recent work in the xFS file system <ref> [12] </ref> explores a scalable serverless storage architecture with global caching. xFS does not provide fine-grained write sharing, whereas split-caching supports efficient sharing of fine-grained objects. Furthermore, xFS does not provide the reliability guarantees of a transactional storage system. <p> Split caching is attractive because it provides a scalable memory management architecture that supports larger databases than current transactional object storage systems based 7 on distributed virtual memory. Like caching in serverless file systems <ref> [12] </ref>, split caching increases scalability by exploiting remote memory access and efficient disk management. However, in contrast to the file system, split caching supports transactional reliability guarantees. The fragment reconstruction coherence protocol is attractive because it is simple and ought to perform well.
Reference: [13] <author> M.Feeley, J.Chase, V.Narasayya, and H.Levy. </author> <title> Integrating coherency and recoverability in distributed systems. </title> <booktitle> In Usenix Symposium on Operating System Design and Implementation, </booktitle> <year> 1994. </year>
Reference-contexts: When a client fetches a page, it may have to evict another page. This evicted page may be sent to another client so that it can be refetched later if needed. Strategies have been developed to utilize the client caches effectively <ref> [12, 13] </ref>. In this paper, we focus on the orthogonal issue of supporting efficient fine-grained write sharing with 1 transactional reliability guarantees. Split caching relies on a cache coherence protocol called fragment reconstruction that ensures clients have a consistent view of database objects. <p> Another difference is that this scheme is based on locking, whereas split caching uses optimistic concurrency control and invalidations. The issues that arise in our cache coherence work are similar to recent work in recoverable distributed shared memory <ref> [13] </ref>. One important difference is that in this shared memory system clients read the entire database into their caches at startup time. Therefore, for performance reasons, this system is limited to main memory databases.
Reference: [14] <author> D. Muntz and P. Honeyman. </author> <title> Multi-level caching in distributed file systems or your cache ain't nothin' but trash. </title> <booktitle> In Winter Usenix Technical Conference, </booktitle> <year> 1992. </year>
Reference-contexts: Earlier research has shown that when there is a large number of clients with caches, and when they are sharing a large database whose size is much larger than the server memory, the server 3 cache is relatively ineffective <ref> [14] </ref>; it is unlikely to satisfy client requests with pages fetched earlier for that client since they are already present in that client's cache.
Reference: [15] <author> James O'Toole and Liuba Shrira. </author> <title> Hybrid Caching for Scalable Object Systems (Think Globally, Act Locally. </title> <booktitle> In Proceedings of the 6th Workshop on Persistent Object Systems, </booktitle> <address> Tarascon, France, </address> <month> September </month> <year> 1994. </year> <note> ACM. </note>
Reference-contexts: In contrast, fragment reconstruction takes advantage of the update absorption provided by the modified object cache. The split caching architecture builds on our work in Thor [2], namely on the mcache architecture [16, 7], hybrid caching <ref> [15] </ref> and transactional invalidation based coherence [1], and extends this work to support global caching in a workstation cluster and avoid installation reads from disk. 6 Conclusions This paper presents the split caching global memory management scheme, and the transactional fragment reconstruction coherence protocol integrated with Thor's mcache.
Reference: [16] <author> James O'Toole and Liuba Shrira. </author> <title> Opportunistic Log: Efficient Installation Reads in a Reliable Object Server. </title> <booktitle> In Proceedings of OSDI, </booktitle> <year> 1994. </year> <month> 8 </month>
Reference-contexts: Clients exploit network speed and large aggregate client memory by fetching pages from other clients' caches to avoid disk reads. Servers cache only new versions of recently modified objects, using a large recoverable cache called the mcache, to perform disk updates more efficiently <ref> [16, 7] </ref>. When objects are moved from the mcache to the database on disk, it is necessary to first perform an installation read to obtain the containing pages; these pages are read from client caches to avoid reading them from disk. <p> If the object is not in the cache, the server reads the object's page from disk, stores it in the cache, and replies to the client when the disk read completes. The mcache based server architecture improves the efficiency of disk updates for small objects <ref> [16, 7] </ref>. It stores modifications in a very compact form, since only the modified objects are stored. This allows the system to delay writing modifications to the database longer than if the pages containing the objects were stored. <p> If the server crashes, the mcache is reconstructed at recovery by scanning the log. Performance studies show that for most work-loads the mcache architecture outperforms other architectures <ref> [16, 7] </ref>, including conventional architectures in which the server stores modified pages, and the clients ship entire pages to the server at commit. 3 The New Caching Architecture The new caching architecture is based on Thor. <p> The recoverable distributed shared memory coherence protocol propagates updates to cached pages at commit time. In contrast, fragment reconstruction takes advantage of the update absorption provided by the modified object cache. The split caching architecture builds on our work in Thor [2], namely on the mcache architecture <ref> [16, 7] </ref>, hybrid caching [15] and transactional invalidation based coherence [1], and extends this work to support global caching in a workstation cluster and avoid installation reads from disk. 6 Conclusions This paper presents the split caching global memory management scheme, and the transactional fragment reconstruction coherence protocol integrated with Thor's
References-found: 16

