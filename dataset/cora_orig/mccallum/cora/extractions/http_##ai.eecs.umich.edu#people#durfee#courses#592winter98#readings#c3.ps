URL: http://ai.eecs.umich.edu/people/durfee/courses/592winter98/readings/c3.ps
Refering-URL: http://ai.eecs.umich.edu/people/durfee/courses/592winter98/index.html
Root-URL: http://www.cs.umich.edu
Title: 3 Distributed Problem Solving and Planning  
Author: Edmund H. Durfee 
Note: Sometimes the problem the agents are solving is to construct a plan. And of  
Date: 3.1 Introduction  
Abstract: Distributed problem solving is the name applied to a subfield of distributed AI in which the emphasis is on getting agents to work together well to solve problems that require collective effort. Due to an inherent distribution of resources such as knowledge, capability, information, and expertise among the agents, an agent in a distributed problem-solving system is unable to accomplish its own tasks alone, or at least can accomplish its tasks better (more quickly, completely, precisely, or certainly) when working with others. Solving distributed problems well demands both group coherence (that is, agents need to want to work together) and competence (that is, agents need to know how to work together well). As the reader by now recognizes, group coherence is hard to realize among individually-motivated agents (see chapters 2 and 5, for example). In distributed problem solving, we typically assume a fair degree of coherence is already present: the agents have been designed to work together; or the payoffs to self-interested agents are only accrued through collective efforts; or social engineering has introduced disincentives for agent individualism; etc. Distributed problem solving thus concentrates on competence; as anyone who has played on a team, worked on a group project, or performed in an orchestra can tell you, simply having the desire to work together by no means ensures a competent collective outcome! Distributed problem solving presumes the existence of problems that need to be solved and expectations about what constitute solutions. For example, a problem to solve might be for a team of (computational) agents to design an artifact (say, a car). The solution they formulate must satisfy overall requirements (it should have four wheels, the engine should fit within the engine compartment and be powerful enough to move the car, etc.), and must exist in a particular form (a specification document for the assembly plant). The teamed agents formulate solutions by each tackling (one or more) subproblems and synthesizing these subproblem solutions into overall solutions. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> W. Briggs and D.J. Cook. </author> <title> Flexible social laws. </title> <booktitle> In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence (IJCAI-95), </booktitle> <month> August </month> <year> 1995. </year>
Reference-contexts: A challenge is to find restrictions that prevent undesirable states without handcuffing agents from achieving states that are acceptable and desirable. When overly constrictive, relaxations of social laws can be made <ref> [1] </ref>. Alternatively, in domains where conflict avoidance is not a key consideration, it is still possible that agents might mutually benefit if they each prefer to take actions that benefit society as a whole, even if not directly relevant to the agent's goal.
Reference: 2. <author> Susan E. Conry, Kazuhiro Kuwabara, Victor R. Lesser, and Robert A. Meyer. </author> <title> Multistage negotiation for distributed constraint satisfaction. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> SMC-21(6):1462-1477, </volume> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: For example, in the domain of communication networks, localized agents can tentatively allocate network connections to particular circuits and share these tentative allocations with neighbors <ref> [2] </ref>. When inconsistent allocations are noticed, some agents try other allocations, and the process continues until a consistent set of allocations have been found.
Reference: 3. <author> Daniel D. Corkill. </author> <title> A Framework for Organizational Self-Design in Distributed Problem Solving Networks. </title> <type> PhD thesis, </type> <institution> University of Massachusetts, </institution> <month> December </month> <year> 1982. </year>
Reference-contexts: Alternatively, organizational structuring can be viewed as a top-down design problem, where the space of alternative designs can be selectively explored and candidate designs can be evaluated prior to their implementation <ref> [3, 34, 40] </ref>. The use of computational techniques to study, and prescribe, organizational structures 3.4 Result Sharing 17 is covered in Chapter 7. 3.4.5 Communication Strategies Organization structures, or similar knowledge, can provide static guidelines about who is generally interested in what results. But this ignores timing issues. <p> But when the space of results formed is large and only few are really needed by others, then sending requests (or more generally, goals) to others makes more sense. This strategy has been explored in the DVM problem <ref> [3] </ref>, as well as in distributed theorem proving [15, 31].
Reference: 4. <author> Randall Davis and Reid Smith. </author> <title> Negotiation as a metaphor for distributed problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 20 </volume> <pages> 63-109, </pages> <year> 1983. </year>
Reference-contexts: say no more about these issues here, other than to stress the research opportunities in this area. 3.3.3 Task Sharing for DSNE Smith and Davis (and others since) have explored the use of the Contract Net protocol for a variety of problems, including the Distributed Sensor Net Establishment (DSNE) problem <ref> [4] </ref>. To give the reader a flavor of this approach, we briefly summarize the stages of this application. At the outset, it is assumed that a particular agent is given the task of monitoring a wide geographic area.
Reference: 5. <author> Keith Decker and Victor Lesser. </author> <title> A one-shot dynamic coordination algorithm for distributed sensor networks. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence (AAAI-93), </booktitle> <pages> pages 210-216, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: The design of organizational structures for multi- agent systems, however, is generally a complex search problem in its own right. The search can be conducted in a bottom-up distributed manner, where boundaries between the roles of agents can be determined as the problem instance is initialized <ref> [5] </ref> or as problem solving progresses [19, 35], where adjustments to the structure can be based on reacting to performance inefficiencies of the current structure.
Reference: 6. <author> Keith Decker and Victor Lesser. </author> <title> Designing a family of coordination mechanisms. </title> <booktitle> In Proceedings of the First International Conf. on Multi-Agent Systems (ICMAS-95), </booktitle> <pages> pages 73-80, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: The TAEMS work of Decker and Lesser has investigated this question much more concretely <ref> [6] </ref>. In their model, an agent's local problem solving can have non-local effects on the activity of other agents. Perhaps it is supplying a result that another agent must have to enable its problem-solving tasks.
Reference: 7. <author> Edmund H. Durfee, Victor R. Lesser, and Daniel D. Corkill. </author> <title> Cooperation Through Communication in a Distributed Problem Solving Network. </title> <editor> In M. Huhns, editor, </editor> <booktitle> Distributed Artificial Intelligence, Chapter 2, </booktitle> <publisher> Pitman 1987. </publisher>
Reference-contexts: Between the extremes of sending everything and sending only locally complete results are a variety of gradations <ref> [7] </ref>, including sending a small partial result early on (to potentially spur the recipient into pursuing useful related results earlier). For example, in the DVM problem, agents in neighboring regions need to agree when they map vehicles from one region to the other. <p> If any of these planners cannot perform its planning subtask with the partially- constructed plan, they can backtrack and try other choices (See Chapter 4 on DCSPs). Similar techniques have been used for planning in domains such as mission planning for unmanned vehicles <ref> [7] </ref> and for logistics planning [46]. The more asynchronous activity on the part of planning problem-solvers that is characteristic of most distributed problem-solving systems can also be achieved through the use of result sharing.
Reference: 8. <author> Edmund H. Durfee. </author> <title> Coordination of Distributed Problem Solvers, </title> <publisher> Kluwer Academic Press, </publisher> <address> Boston 1988. </address>
Reference-contexts: In either case, planning and coordination are interleaved with each other, and often with execution as well. Let us consider a particular example of an approach that assumes that planning and coordination decisions must be continually revisited and revised. The approach we focus on is called Partial Global Planning <ref> [8] </ref>. Task Decomposition Partial Global Planning starts with the premise that tasks are inherently decomposed or at least that they could be.
Reference: 9. <author> Edmund H. Durfee and Thomas A. Montgomery. </author> <title> Coordination as Distributed Search in a Hierarchical Behavior Space. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, Special Issue on Distributed Artificial Intelligence, </journal> <volume> SMC-21(6):1363-1378, </volume> <month> November </month> <year> 1991. </year>
Reference-contexts: The inner loop of the protocol conducts what can be thought of as a distributed constraint satisfaction search to resolve the conflicts. Because the plans at various abstraction levels dictate the behaviors of agents to a particular degree, this approach has been characterized as search through hierarchical behavior space <ref> [9] </ref>. The algorithm is presented in Figure 3.6. Provided that there are finite abstraction levels and that agents are restricted in the changes to their plans that they can make such that they cannot get into cyclic plan generation patterns, the above protocol is assured to terminate.
Reference: 10. <author> Edmund H. Durfee, Patrick G. Kenny, and Karl C. Kluge. </author> <title> Integrated Premission Planning and Execution for Unmanned Ground Vehicles. </title> <booktitle> In Proceedings of the First 42 Distributed Problem Solving and Planning International Conference on Autonomous Agents, </booktitle> <pages> pages 348-354, </pages> <month> February </month> <year> 1997. </year>
Reference: 11. <author> Eithan Ephrati and Jeffrey S. Rosenschein. </author> <title> Divide and conquer in multi-agent planning. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <pages> pages 375-380, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: Thus, each agent might construct the set of all feasible plans 3.5 Distributed Planning 25 for accomplishing its own goals. The distributed planning process then consists of a search through how subsets of agents' plans can fit together. Ephrati and Rosenschein <ref> [11] </ref> have developed a plan combination search approach for doing this kind of search, where the emphasis is on beginning with encompassing sets of possible plans and refining these to converge on a nearly optimal subset.
Reference: 12. <author> Eithan Ephrati, Martha E. Pollack, and Jeffrey S. Rosenschein. </author> <title> A tractable heuristic that maximizes global utility through local plan combination. </title> <booktitle> In Proceedings of the First International Conference on Multi-Agent Systems (ICMAS-95), </booktitle> <pages> pages 94-101, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: When there might not be feasible schedules to satisfy all agents, issues arise about how agents should decide which plans to combine to maximize their global performance <ref> [12] </ref>. More complex representations of reactive plans and techniques for coordinating them based on model-checking and Petri-net-based mechanisms have also been explored [20, 27, 37]. Iterative Plan Formation Plan merging is a powerful technique for increasing parallelism in the planning process as well as during execution.
Reference: 13. <author> Maier Fenster, Sarit Kraus, and Jeffrey S. Rosenschein. </author> <title> Coordination without communication: experimental validation of focal point techniques. </title> <booktitle> In Proceedings of the First International Conference on Multi-Agent Systems (ICMAS-95), </booktitle> <pages> pages 102-108, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: For example, if Distributed Delivery agents are going to hand off objects to each other, they might infer that some locations (such as a hub) are more likely to be mutually recognized as good choices. Such solutions to choice problems have been referred to as focal points <ref> [13] </ref>. 3.8 Conclusions Distributed planning has a variety of reasonably well-studied tools and techniques in its repertoire. One of the important challenges to the field is in characterizing these tools and undertanding where and when to apply each.
Reference: 14. <author> R.E. Fikes and N.J. Nilsson. </author> <title> STRIPS: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2(3-4):189-208, </volume> <year> 1971. </year>
Reference-contexts: They also need to know how to change the plan in ways that will be interpreted correctly by other agents and lead to desirable effects. To date, there are few standards for specifying plans for computer-based agents. Some conventions certainly exist (such as the "STRIPS operator" format <ref> [14] </ref>), but these are usually useful only within a narrow context. In most distributed planning systems, it is assumed that the agents use identical representations and are built to interpret them in the same ways.
Reference: 15. <author> Michael Fisher and Michael Wooldridge. </author> <title> Distributed problem-solving as concurrent theorem-proving. </title> <booktitle> In Proceedings of MAAMAW'97 , Lecture Notes in Artificial Intelligence, </booktitle> <publisher> Springer-Verlag. </publisher>
Reference-contexts: But when the space of results formed is large and only few are really needed by others, then sending requests (or more generally, goals) to others makes more sense. This strategy has been explored in the DVM problem [3], as well as in distributed theorem proving <ref> [15, 31] </ref>. For example, in DARES [31], when a theorem proving agent would fail to make progress, it would request to 18 Distributed Problem Solving and Planning import clauses from other such agents, where the set of desired literals would be heuristically chosen (Figure 3.5).
Reference: 16. <author> Michael Georgeff. </author> <title> Communication and Interaction in multi-agent planning. </title> <booktitle> In Proceedings of the Third National Conference on Artificial Intelligence (AAAI-83), </booktitle> <pages> pages 125-129, </pages> <month> July </month> <year> 1983. </year>
Reference-contexts: From the planning literature, many assumptions about the limited effects of actions and minimal interdependence between agents' goals can be used to reduce the search. We will look at one way of doing this, adapted from Georgeff <ref> [16] </ref> next. As is traditional, assume that the agents know the possible initial states of the world, and each agent builds a totally-ordered plan using any planning technology.
Reference: 17. <author> Claudia Goldman and Jeffrey S. Rosenschein. </author> <title> Emergent coordination through the use of cooperative state-changing rules. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <pages> pages 408-413, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: For example, the delivery agents might pass through a "hub" location. The bias toward doing such favors for other agents could be encoded into cooperative state-changing rules <ref> [17] </ref> that require agents to take such cooperative actions even to their individual detriment, as long as they are not detrimental beyond some threshold. 3.7.3 Interleaved Planning, Coordination, and Execution More generally, between approaches that assume agents have detailed plans to coordinate and approaches that assume general-purpose coordination policies can apply
Reference: 18. <author> Marcus J. Huber and Edmund H. Durfee. </author> <title> An initial assessment of plan-recognition-based coordination for multi-agent teams. </title> <booktitle> In Proceedings of the Second International Conference on Multi-Agent Systems (ICMAS-96), </booktitle> <pages> pages 126-133, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: The plan recognition literature focuses on how observed actions can lead to hypotheses about the plans being executed by others. While generally more uncertain than coordination using explicit communication, observation-based plan coordination can still achieve high-quality results and, under some circumstances can outperform communication-based distributed planning <ref> [18] </ref>. Another way of coordinating without explicit communication is to allow agents to make inferences about the choices others are likely to make based on assumptions about their rationality [36] or about how they view the world.
Reference: 19. <author> Toru Ishida, Les Gasser, and Makoto Yokoo. </author> <title> Organization self-design of distributed production systems, </title> <journal> IEEE Trans on Knowl. and Data Sys., DKE4(2):123-134. </journal>
Reference-contexts: The search can be conducted in a bottom-up distributed manner, where boundaries between the roles of agents can be determined as the problem instance is initialized [5] or as problem solving progresses <ref> [19, 35] </ref>, where adjustments to the structure can be based on reacting to performance inefficiencies of the current structure.
Reference: 20. <author> Froduald Kabanza. </author> <title> Synchronizing multiagent plans using temporal logic specifications. </title> <booktitle> In Proceedings of the First International Conference on Multi-Agent Systems (ICMAS-95), </booktitle> <pages> pages 217-224, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: When there might not be feasible schedules to satisfy all agents, issues arise about how agents should decide which plans to combine to maximize their global performance [12]. More complex representations of reactive plans and techniques for coordinating them based on model-checking and Petri-net-based mechanisms have also been explored <ref> [20, 27, 37] </ref>. Iterative Plan Formation Plan merging is a powerful technique for increasing parallelism in the planning process as well as during execution. <p> Other efforts have sought planning languages grounded in temporal logics and operational formalisms such as Petri Nets and Graphcet <ref> [20, 27, 37] </ref>.
Reference: 21. <author> Subbarao Kambhampati, Mark Cutkosky, Marty Tenenbaum, and Soo Hong Lee. </author> <title> Combining specialized reasoners and general purpose planners: A case study. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 199-205, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: For some types of problems, the interactions among the planning specialists might be through the exchange of a partially-specified plan. For example, this model has been used in the manufacturing domain, where a general-purpose planner has been coupled with specialist planners for geometric reasoning and fixturing <ref> [21] </ref>. In this application, the geometric specialist considers the shape of a part to be machined, and generates an abstract plan as an ordering over the geometric features to put into the part.
Reference: 22. <author> David Kinney, Magus Ljungberg, Anand Rao, Elizabeth Sonenberg, Gil Tidhar, and Eric Werner. </author> <title> Planned Team Activity, </title> <booktitle> Preproceedings of the Fourth European Workshop on Modeling Autonomous Agents in a MultiAgent World, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: Then, during execution, an agent can replan details without requiring coordination with others so long as its plan revision fits within the coordinated abstract plan. This approach has been taken in the team plan execution work of Kinney and colleagues, for example <ref> [22] </ref>. The perceptive reader will also recognize in this approach the flavor of organizational structuring and distributed planning in a hierarchical behavior space: so long as it remains within the scope of its roles and responsibilities, an agent can individually decide what is the best way of accomplishing its goals.
Reference: 23. <author> Craig A. Knoblock. </author> <title> Generating Abstraction Hierarchies: An Automated Approach to Reducing Search in Planning. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference-contexts: f (k)) + (n=k l2 f (k)) + : : : + (n=k f (k)) : Since k is a constant, and we can choose l = log k n, the equation can be reduced to O ([(k l 1)=(k 1)]f (k)) which can be simplified simply to O (n) <ref> [23, 23] </ref>. More importantly, if each level of the hierarchy has agents that solve their subproblems in parallel, then the time needed below the top of the hierarchy (assuming negligible distribution and communication time) is simply f (k) for each level, so (l 1)f (k).
Reference: 24. <author> Richard E. Korf. </author> <title> Planning as search: A qualitative approach. </title> <journal> Artificial Intelligence, </journal> <volume> 33(1) </volume> <pages> 65-88, </pages> <year> 1987. </year>
Reference: 25. <author> Susan E. Lander and Victor R. Lesser. </author> <title> Understanding the role of negotiation in distributed search among heterogeneous agents. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <pages> pages 438-444, </pages> <month> August </month> <year> 1993. </year> <note> 3.10 References 43 </note>
Reference-contexts: The blackboard architecture, for example, allows cooperating knowledge sources to exchange results and build off of them by communicating through a common, structured blackboard (Chapter 2). This strategy has been adopted in a variety of distributed problem-solving approaches, including those for design applications <ref> [25, 45] </ref>. In essence, using a shared repository can support search through alternative designs, where agents with different design criteria can revise and critique the alternatives. In many ways, this is a distributed constraint satisfaction problem (Chapter 4), but it differs from traditional formulations in a few respects. <p> For example, agents engaged in negotiated search <ref> [25] </ref> have at their disposal a variety of operators for progressing the distributed problem-solving effort: initiate-solution (propose a new starting point for a solution); extend-solution (revise an already existing partial solution); critique-solution (provide feedback on the viability of an already existing partial solution); and relax-solution-requirement (change local requirements for solution acceptability).
Reference: 26. <author> Amy L. Lansky. </author> <title> Localized Search for Controlling Automated Reasoning. </title> <booktitle> In Proceedings of the DARPA Workshop on Innovative Approaches to Planning, Scheduling, and Control, </booktitle> <pages> pages 115-125, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: When possible, bias the search to find a plan in which the steps have few ordering constraints among them. 2. Decompose the plan into subplans such that ordering relationships between steps tend to be concentrated within subplans and minimized across subplans. <ref> [26] </ref>. 3. Insert synchronization (typically, communication) actions into subplans. 4. Allocate subplans to agents using task-passing mechanisms. If failure, return to previous steps (decompose differently, or generate a different partial order plan, ...).
Reference: 27. <author> Jaeho Lee. </author> <title> An Explicit Semantics for Coordinated Multiagent Plan Execution. </title> <type> PhD dissertation. </type> <institution> University of Michigan, </institution> <year> 1997. </year>
Reference-contexts: When there might not be feasible schedules to satisfy all agents, issues arise about how agents should decide which plans to combine to maximize their global performance [12]. More complex representations of reactive plans and techniques for coordinating them based on model-checking and Petri-net-based mechanisms have also been explored <ref> [20, 27, 37] </ref>. Iterative Plan Formation Plan merging is a powerful technique for increasing parallelism in the planning process as well as during execution. <p> Other efforts have sought planning languages grounded in temporal logics and operational formalisms such as Petri Nets and Graphcet <ref> [20, 27, 37] </ref>.
Reference: 28. <author> Victor R. Lesser and Daniel D. Corkill. </author> <title> Functionally accurate, cooperative distributed systems. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> SMC-11(1):81-96, </volume> <year> 1981. </year>
Reference-contexts: This style of collective problem solving has been termed functionally-accurate (it gets the answer eventually, but with possibly many false starts) and cooperative (it requires iterative exchange) <ref> [28] </ref>. Functionally-accurate cooperation has been used extensively in distributed problem solving for tasks such as interpretation and design, where agents only discover the details of how their subproblem results interrelate through tentative formulation and iterative exchange.
Reference: 29. <author> Victor R. Lesser and Lee D. Erman. </author> <title> Distributed interpretation: A model and an experiment. </title> <journal> IEEE Transactions on Computers (Special Issue on Distributed Processing), C-29(12):1144-1163. </journal>
Reference-contexts: One solution to this is to require that messages be acknowledged, and that an agent sending a message will periodically repeat the message (sometimes called "murmuring") until it gets an acknowledgment <ref> [29] </ref>.
Reference: 30. <author> Jyi-Shane Liu and Katia P. Sycara. </author> <title> Multiagent coordination in tightly coupled task scheduling. </title> <booktitle> In Proceedings of the Second International Conference on Multi-Agent Systems (ICMAS-96), </booktitle> <pages> pages 181-188, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: When there are uncertainties about the time needs of tasks, or of the possibility of arrival of new tasks, the distributed scheduling problem requires mechanisms to maximize expected performance and to make forecasts about future activities <ref> [30] </ref>. When there might not be feasible schedules to satisfy all agents, issues arise about how agents should decide which plans to combine to maximize their global performance [12].
Reference: 31. <author> Douglas MacIntosh, Susan Conry, and Robert Meyer. </author> <title> Distributed automated reasoning: Issues in coordination, cooperation, and performance. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, SMC-21(6):1307-1316. </journal>
Reference-contexts: But when the space of results formed is large and only few are really needed by others, then sending requests (or more generally, goals) to others makes more sense. This strategy has been explored in the DVM problem [3], as well as in distributed theorem proving <ref> [15, 31] </ref>. For example, in DARES [31], when a theorem proving agent would fail to make progress, it would request to 18 Distributed Problem Solving and Planning import clauses from other such agents, where the set of desired literals would be heuristically chosen (Figure 3.5). <p> This strategy has been explored in the DVM problem [3], as well as in distributed theorem proving [15, 31]. For example, in DARES <ref> [31] </ref>, when a theorem proving agent would fail to make progress, it would request to 18 Distributed Problem Solving and Planning import clauses from other such agents, where the set of desired literals would be heuristically chosen (Figure 3.5).
Reference: 32. <author> Frank von Martial. </author> <title> Coordinating Plans of Autonomous Agents. </title> <booktitle> Lecture Notes in Artificial Intelligence, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: For example, partial global planning (see Subsection 3.7.3) emphasized a search for generating partial solutions near partial solution boundaries with other agents, so as to provide them with useful focusing information early on (see Subsection 3.4.5 on communication strategies). The work of von Martial <ref> [32] </ref> concentrated on strategies that agents can use to exploit "favor relations" among their goals, such as accomplishing a goal for another agent while pursuing its own goal. 30 Distributed Problem Solving and Planning 3.6 Distributed Plan Representations Distributed problem solving, encompassing distributed planning, generally relies heavily on agents being able
Reference: 33. <author> Thomas A. Montgomery and Edmund H. Durfee. </author> <title> Search Reduction in Hierarchical Distributed Problem Solving. Group Decision and Negotiation, 2 </title> <journal> 301-317 (Special issue on Distributed Artificial Intelligence), </journal> <year> 1993. </year>
Reference-contexts: Again, since k (and hence f (k)) is constant, and l = log k n, this reduces simply to O (log k n). This means that through decomposition and parallel problem solving, the exponential ToH problem can be reduced to logarithmic time complexity <ref> [33] </ref>. What the ToH problem illustrates is the potential for improved parallelism due to distributed problem solving in the ideally decomposable case. Unfortunately, few problems satisfy the assumptions in this analysis of ToH, including: 1.
Reference: 34. <author> H. Edward Pattison, Daniel D. Corkill, and Victor R. Lesser. </author> <title> Instantiating descriptions of organizational structures. </title> <editor> In M. Huhns, editor, </editor> <booktitle> Distributed Artificial Intelligence. </booktitle> <address> London, </address> <publisher> Pittman. </publisher>
Reference-contexts: Alternatively, organizational structuring can be viewed as a top-down design problem, where the space of alternative designs can be selectively explored and candidate designs can be evaluated prior to their implementation <ref> [3, 34, 40] </ref>. The use of computational techniques to study, and prescribe, organizational structures 3.4 Result Sharing 17 is covered in Chapter 7. 3.4.5 Communication Strategies Organization structures, or similar knowledge, can provide static guidelines about who is generally interested in what results. But this ignores timing issues.
Reference: 35. <author> M.V. Nagendra Prasad, Keith Decker, Alan Garvey, and Victor Lesser. </author> <title> Exploring organizational designs with TAEMS: A case study of distributed data processing. </title> <booktitle> In Proceedings of the Second International Conference on Multi-Agent Systems (ICMAS-96), </booktitle> <pages> pages 283-290, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: The search can be conducted in a bottom-up distributed manner, where boundaries between the roles of agents can be determined as the problem instance is initialized [5] or as problem solving progresses <ref> [19, 35] </ref>, where adjustments to the structure can be based on reacting to performance inefficiencies of the current structure.
Reference: 36. <author> Jeffrey S. Rosenschein and John S. Breese. </author> <title> Communication-free interactions among rational agents: A probabilistic approach. </title> <editor> In L. Gasser and M. Huhns, editors, </editor> <booktitle> Distributed Artificial Intelligence volume II , pages 99-118, </booktitle> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: Another way of coordinating without explicit communication is to allow agents to make inferences about the choices others are likely to make based on assumptions about their rationality <ref> [36] </ref> or about how they view the world. For example, if Distributed Delivery agents are going to hand off objects to each other, they might infer that some locations (such as a hub) are more likely to be mutually recognized as good choices.
Reference: 37. <author> Amal El Fallah Seghrouchni and Serge Haddad. </author> <title> A recursive model for distributed planning. </title> <booktitle> In Proceedings of the Second International Conference on Multi-Agent Systems (ICMAS-96), </booktitle> <pages> pages 307-314, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: When there might not be feasible schedules to satisfy all agents, issues arise about how agents should decide which plans to combine to maximize their global performance [12]. More complex representations of reactive plans and techniques for coordinating them based on model-checking and Petri-net-based mechanisms have also been explored <ref> [20, 27, 37] </ref>. Iterative Plan Formation Plan merging is a powerful technique for increasing parallelism in the planning process as well as during execution. <p> Other efforts have sought planning languages grounded in temporal logics and operational formalisms such as Petri Nets and Graphcet <ref> [20, 27, 37] </ref>.
Reference: 38. <author> Sandip Sen and Edmund H. Durfee. </author> <title> A contracting model for flexible distributed scheduling. </title> <journal> Annals of Operations Research, </journal> <volume> 65, </volume> <pages> pp. 195-222, </pages> <year> 1996. </year>
Reference-contexts: Clearly, there is a tradeoff between reducing information exchanged by iterative messaging versus reducing delay in having the needed information reach its destination by sending many messages at the same time. Sen, for example, has looked at this in the context of distributed meeting scheduling <ref> [38] </ref>. Our experience as human meeting schedulers tells us that finding a meeting time could involve a series of proposals of specific times until one is acceptable, or it could involve having the participants send all of their available times at the outset.
Reference: 39. <author> Yoav Shaham and Moshe Tennenholtz. </author> <title> On the synthesis of useful social laws for artificial agent societies. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence (AAAI-92), </booktitle> <pages> pages 276-281-380, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: This was the answer in organizational structuring in distributed problem solving, where an agent could choose to work on any part of the problem so long as it fit within its range of responsibilities. A variation on this theme is captured in the work on social laws <ref> [39] </ref>. A social law is a prohibition against particular choices of actions in particular contexts. For example, entering an intersection on a red light is prohibited, as might be not 3.7 Distributed Planning and Execution 33 entering the intersection on a green light.
Reference: 40. <author> Young-pa So and Edmund H. Durfee. </author> <title> Designing tree-structured organizations for computational agents. </title> <journal> Computational and Mathematical Organization Theory, </journal> <volume> 2(3) </volume> <pages> 219-246, </pages> <month> Fall </month> <year> 1996. </year>
Reference-contexts: Alternatively, organizational structuring can be viewed as a top-down design problem, where the space of alternative designs can be selectively explored and candidate designs can be evaluated prior to their implementation <ref> [3, 34, 40] </ref>. The use of computational techniques to study, and prescribe, organizational structures 3.4 Result Sharing 17 is covered in Chapter 7. 3.4.5 Communication Strategies Organization structures, or similar knowledge, can provide static guidelines about who is generally interested in what results. But this ignores timing issues.
Reference: 41. <author> John A. Stankovic, Krithi Ramamritham, and S.-C. Cheng. </author> <title> Evaluation of a flexible task scheduling algorithm for distributed hard real- time systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-34(12):1130-1143, </volume> <year> 1985. </year> <title> 44 Distributed Problem Solving and Planning </title>
Reference-contexts: the protocol can be used by potential contractors to announce availability, and managers can respond to the announcements by bidding their pending tasks! It is possible to have a system alternate between the task and availability announcement strategies depending on where the bottlenecks are in the system at various times <ref> [41] </ref>. Announcement Revision Part of the announcement message that a manager sends is the eligibility specification for potential contractors. When no (satisfactory) contractors respond to an announcement, it could be that the manager was being too exclusive in whom it would entertain bids from.
Reference: 42. <author> Toshiharu Sugawara. </author> <title> Reusing past plans in distributed planning. </title> <booktitle> In Proceedings of the First International Conference on Multi-Agent Systems (ICMAS-95), </booktitle> <pages> pages 360-367, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Obviously, if this happens frequently, a substantial expenditure of effort for planning and coordination can result. Sometimes, strategies such as repairing the previous plans, or accessing a library of reusable plans <ref> [42] </ref> can reduce the effort to make it managable. Significant overhead can of course be saved if a plan deviation can be addressed locally rather than having to require coordination. For example, rather than coordinating sequences of actions, the agents might coordinate their plans at an abstract level.
Reference: 43. <author> Katia Sycara, Steven Roth, Norman Sadeh, and Mark Fox. </author> <title> Distributed constrained heuristic search. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, SMC-21(6):1446-1461. </journal>
Reference-contexts: For example, distributed constrained heuristic search (DCHS) uses aggregate demand to inform a heuristic search for solving a distributed constraint satisfaction problem <ref> [43] </ref>. The idea is that more informed search decisions decrease wasted backtracking effort, and that constraint satisfaction heuristics such as variable and value ordering can be gainfully employed in a distributed environment. DCHS works as follows (Figure 3.4): 1.
Reference: 44. <author> Michael P. Wellman. </author> <title> A market-oriented programming environment and its application to distributed multicommodity flow problems. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1 </volume> <pages> 1-23, </pages> <year> 1993. </year>
Reference-contexts: One form that this strategy takes is so-called market-oriented programming <ref> [44] </ref> where associated 14 Distributed Problem Solving and Planning with resources are auctions that support the search for equilibria in which resources are allocated efficiently. Market mechanisms are covered in detail in Chapter 5.
Reference: 45. <author> Keith J. Werkman. </author> <title> Multiple agent cooperative design evaluation using negotiation. </title> <booktitle> In Proceedings of the Second International Conference on Artificial Intelligence in Design, </booktitle> <address> Pittsburgh PA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: The blackboard architecture, for example, allows cooperating knowledge sources to exchange results and build off of them by communicating through a common, structured blackboard (Chapter 2). This strategy has been adopted in a variety of distributed problem-solving approaches, including those for design applications <ref> [25, 45] </ref>. In essence, using a shared repository can support search through alternative designs, where agents with different design criteria can revise and critique the alternatives. In many ways, this is a distributed constraint satisfaction problem (Chapter 4), but it differs from traditional formulations in a few respects.
Reference: 46. <author> D.E. Wilkins and K.L. Myers. </author> <title> A common knowledge representation for plan generation and reactive execution. </title> <journal> Journal of Logic and Computation, </journal> <volume> 5(6) </volume> <pages> 731-761, </pages> <year> 1995. </year>
Reference-contexts: If any of these planners cannot perform its planning subtask with the partially- constructed plan, they can backtrack and try other choices (See Chapter 4 on DCSPs). Similar techniques have been used for planning in domains such as mission planning for unmanned vehicles [7] and for logistics planning <ref> [46] </ref>. The more asynchronous activity on the part of planning problem-solvers that is characteristic of most distributed problem-solving systems can also be achieved through the use of result sharing. <p> In most distributed planning systems, it is assumed that the agents use identical representations and are built to interpret them in the same ways. One effort for formulating a more general description of a plan has been undertaken by SRI, in the development of their Cypress system <ref> [46] </ref>. In a nutshell, Cypress combined existing systems for plan generation and for plan execution.
Reference: 47. <author> Chenqi Zhang. </author> <title> Cooperation under uncertainty in distributed expert systems. </title> <journal> Artificial Intelligence, </journal> <volume> 56 </volume> <pages> 21-69, </pages> <year> 1992. </year>
Reference-contexts: In general, most distributed problem-solving systems assume similar representations of partial solutions (and their certainty measures) which makes combining them straightforward, although some researchers have considered challenges in crossing between representations, such as combining different uncertainty measurements <ref> [47] </ref>. In functionally accurate cooperation, the iterative exchange of partial results is expected to lead, eventually, to some agent having enough information to keep moving the overall problem solving forward. Given enough information exchange, therefore, the overall problem will be solved.
References-found: 47

