URL: ftp://ftp.cs.brown.edu/pub/techreports/96/cs96-33.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-96-33.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [1] <institution> Proceedings of the Twenty-Sixth Annual ACM Symposium on Theory of Computing, </institution> <address> Montreal, Quebec, Canada, </address> <month> 23-25 May </month> <year> 1994. </year>
Reference: [2] <institution> Proceedings of the Twenty-Seventh Annual ACM Symposium on Theory of Computing, </institution> <address> Las Vegas, Nevada, 29 May-1 June 1995. </address>
Reference: [3] <institution> Proceedings of the Twenty-Eighth Annual ACM Symposium on Theory of Computing, </institution> <address> Philadelphia, Pennsylvania, </address> <month> 22-24 May </month> <year> 1996. </year>
Reference: [4] <author> F. Alizadeh. </author> <title> A sublinear-time randomized parallel algorithm for the maximum clique problem in perfect graphs. </title> <booktitle> In Proceedings of the Second Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 188-194, </pages> <address> San Francisco, California, </address> <month> 28-30 Jan. </month> <year> 1991. </year>
Reference-contexts: Since there are n iterations in MaxClique, a maximum clique in a perfect graph G with n nodes and m edges can be found in time ~ O (n 1:5 m 3 ) using interior-point methods. Based on the above observation, Alizadeh <ref> [4, 5] </ref> developed a parallel algorithm for finding a maximum clique in perfect graphs. 5.2.2 MAX STABLE SET One can easily see that finding a maximum clique in G is equivalent to finding a maximum stable set in G.
Reference: [5] <author> F. Alizadeh. </author> <title> Interior point methods in semidefinite programming with applications to combinatorial optimization. </title> <journal> SIAM Journal on Optimization, </journal> <volume> 5(1) </volume> <pages> 13-51, </pages> <year> 1995. </year>
Reference-contexts: Specifically they write the NP-complete MAXCUT problem as a nonlinear integer program and then relax it as a semidefinite program, which is a nonlinear program. After obtaining a near-optimal solution to this semidef-inite relaxation of MAXCUT in polynomial time <ref> [5] </ref>, their algorithm "rounds" the solution, which is a positive-semidefinite matrix, to an integral solution for the original nonlinear integer program. <p> The vector coloring problem can be written as a semidefinite program, whose near-optimal solution can be found in polynomial time <ref> [5] </ref>. The near-optimal vector coloring is then "rounded" to a regular coloring by vector projection in n-dimensional space. The number of colors required by the algorithm is ~ O (n 13=(k+1) ). <p> This subroutine, combined with the ellipsoid method, provided a polynomial-time algorithm for semidefinite programming. However, the complexity of this algorithm is quite high. Nesterov and Nemirovskii [112] showed how to use the interior-point methods to solve semidefinite programs. Alizadeh <ref> [5] </ref> showed how an interior-point algorithm for linear programming could be directly generalized to handle semidef-inite programming. Since the work of Alizadeh, there has been a great deal of research into such algorithms [83, 149, 131, 157, 75, 101, 53]. A simplex-type 4 method was also discovered by Pataki [119]. <p> Although a semidefinite program is a nonlinear program, surprisingly it preserves many nice properties of a linear program. For instance most methods for solving integer programs (e.g., simplex [48], ellipsoid [92], and interior-point [89, 156]) can be generalized to semidefinite programs <ref> [119, 68, 146, 5, 112, 113] </ref>. As a result, a semidefinite program can be approximately solved to within an additive error * in polynomial time unless the optimal solution itself is exponentially large [5]. <p> As a result, a semidefinite program can be approximately solved to within an additive error * in polynomial time unless the optimal solution itself is exponentially large <ref> [5] </ref>. <p> Since there are n iterations in MaxClique, a maximum clique in a perfect graph G with n nodes and m edges can be found in time ~ O (n 1:5 m 3 ) using interior-point methods. Based on the above observation, Alizadeh <ref> [4, 5] </ref> developed a parallel algorithm for finding a maximum clique in perfect graphs. 5.2.2 MAX STABLE SET One can easily see that finding a maximum clique in G is equivalent to finding a maximum stable set in G.
Reference: [6] <author> N. Alon and N. Kahale. </author> <title> Approximating the independence number via the -fucntion. </title> <type> Unpublished manuscript, </type> <month> Nov. </month> <year> 1994. </year>
Reference: [7] <author> K. Appel and W. Haken. </author> <title> Every planar map is four colorable. Part I: </title> <journal> Discharging. Illinois Journal of Mathematics, </journal> <volume> 21 </volume> <pages> 429-490, </pages> <year> 1977. </year>
Reference-contexts: The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie. The conjecture has been answered affirmatively <ref> [7, 9] </ref>. Moreover, a planar graph can actually be four-colored in quadratic time [8, 133]. However, COLORING is much harder than four-coloring a planar graph. Coloring a 3-colorable planar graph with three colors is NP-complete [60].
Reference: [8] <author> K. Appel and W. Haken. </author> <title> Every planar graph is four colorable. </title> <journal> Contemporary Mathematics, </journal> <volume> 98 </volume> <pages> 1-741, </pages> <year> 1989. </year>
Reference-contexts: The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie. The conjecture has been answered affirmatively [7, 9]. Moreover, a planar graph can actually be four-colored in quadratic time <ref> [8, 133] </ref>. However, COLORING is much harder than four-coloring a planar graph. Coloring a 3-colorable planar graph with three colors is NP-complete [60].
Reference: [9] <author> K. Appel, W. Haken, and J. Koch. </author> <title> Every planar map is four colorable. Part II: Reducibility. </title> <journal> Illinois Journal of Mathematics, </journal> <volume> 21 </volume> <pages> 491-567, </pages> <year> 1977. </year>
Reference-contexts: The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie. The conjecture has been answered affirmatively <ref> [7, 9] </ref>. Moreover, a planar graph can actually be four-colored in quadratic time [8, 133]. However, COLORING is much harder than four-coloring a planar graph. Coloring a 3-colorable planar graph with three colors is NP-complete [60].
Reference: [10] <author> S. Arora, D. Karger, and M. Karpinski. </author> <title> Polynomial time approximation schemes for dense instances of N P-hard problems. </title> <booktitle> In ACM [2], </booktitle> <pages> pages 284-293. </pages>
Reference-contexts: There are also some results on approximation algorithms for MAXCUT on special graphs. It is known that MAXCUT has a polynomial-time approximation scheme when the given graph is dense <ref> [49, 10] </ref>. 2.2.2 COLORING COLORING [84] has applications in register allocation, time tabling, scheduling, sequencing, and circuit testing [39, 38, 34, 44, 70, 35, 24, 154, 59]. The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie.
Reference: [11] <author> S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy. </author> <title> Proof veri-fication and hardness of approximation problems. </title> <booktitle> In 33rd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 14-23, </pages> <address> Pittsburgh, Pennsylvania, 24-27 Oct. 1992. </address> <publisher> IEEE. </publisher>
Reference-contexts: The other direction is to look for approximation algorithms. It is known that MAXCUT is MAX SNP-complete, even if the degree of the graph is bounded by a constant [116]. It follows from <ref> [11] </ref> that MAXCUT does not have a polynomial-time approximation scheme (PTAS) [85] unless P=NP. Namely there exists a positive constant * such that approximating MAXCUT to within a ratio of 1* is NP-complete. For example it is NP-complete to approximate MAXCUT to within the ratio of 65=66 [20].
Reference: [12] <author> E. Balas and J. Xue. </author> <title> Minimum weighted coloring of triangulated graphs, with application to maximum weight vertex packing and clique finding in arbitrary graphs. </title> <journal> SIAM Journal on Computing, </journal> <volume> 20(2) </volume> <pages> 209-221, </pages> <month> Apr. </month> <year> 1991. </year>
Reference-contexts: Moreover, a planar graph can actually be four-colored in quadratic time [8, 133]. However, COLORING is much harder than four-coloring a planar graph. Coloring a 3-colorable planar graph with three colors is NP-complete [60]. There are many positive results on solving COLORING on special graphs <ref> [61, 66, 67, 57, 145, 80, 12, 13] </ref>, among which a quite general result is that perfect graphs can be colored with the fewest possible number of colors in polynomial time [66, 67]. Approximating COLORING is difficult.
Reference: [13] <author> E. Balas and J. Xue. </author> <title> Addendum: Minimum weighted coloring of triangulated graphs, with application to maximum weight vertex packing and clique finding in arbitrary graphs. </title> <journal> SIAM Journal on Computing, </journal> <volume> 21(5):1000, </volume> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: Moreover, a planar graph can actually be four-colored in quadratic time [8, 133]. However, COLORING is much harder than four-coloring a planar graph. Coloring a 3-colorable planar graph with three colors is NP-complete [60]. There are many positive results on solving COLORING on special graphs <ref> [61, 66, 67, 57, 145, 80, 12, 13] </ref>, among which a quite general result is that perfect graphs can be colored with the fewest possible number of colors in polynomial time [66, 67]. Approximating COLORING is difficult.
Reference: [14] <author> F. Barahona. </author> <title> On the computational complexity of Ising spin glass models. </title> <journal> Journal of Physics A, </journal> <volume> 15 </volume> <pages> 3241-3253, </pages> <year> 1982. </year>
Reference-contexts: Start with both sides empty, so the initial value of the cut is zero. 2. For every node v in G do (a) Put v on the side which increases the current cut value more. cubic [123, 155], or quasi-planar <ref> [14] </ref>. Since this problem is so hard, researchers have been working along two different directions. The first direction is to look for algorithms for MAXCUT on special graphs. <p> Specifically, we ran our program on graphs which come from Spin Glasses <ref> [14, 142, 143, 132] </ref>. Junger offers five weighted sparse graphs at http://www.informatik.uni-koeln.de/ls_juenger/projects/spinglass/index.html These graphs have 9, 64, 100, 400, and 2500 nodes. The number of edges in each graph is two times the number of nodes. There are edges of positive and negative weights in these graphs.
Reference: [15] <author> F. Barahona. </author> <title> The Max Cut problem in graphs not contractible to K 5 . Operations Research Letters, </title> <booktitle> 2 </booktitle> <pages> 107-111, </pages> <year> 1983. </year>
Reference-contexts: The first direction is to look for algorithms for MAXCUT on special graphs. It is known that MAX-CUT is polynomial-time solvable on planar graphs [72, 114], weakly bipartite graphs [69], and graphs that are not contractible to K 5 <ref> [15] </ref>. The other direction is to look for approximation algorithms. It is known that MAXCUT is MAX SNP-complete, even if the degree of the graph is bounded by a constant [116]. It follows from [11] that MAXCUT does not have a polynomial-time approximation scheme (PTAS) [85] unless P=NP.
Reference: [16] <author> F. Barahona. </author> <title> On some applications of the Chinese Postman Problem. </title> <editor> In B. Korte, L. Lovasz, H. J. Promel, and A. Schrijver, editors, </editor> <title> Paths, Flows, </title> <booktitle> and VLSI-Layout, volume 9 of Algorithms and Combinatorics, </booktitle> <pages> pages 1-16. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: COLORING | Given a graph, we would like to color its nodes with the fewest number of distinct colors such that no adjacent nodes have the same color. Both problems are NP-complete [58]. 2.2.1 MAXCUT MAXCUT [125] has applications in VLSI layout design and statistical physics <ref> [16, 17, 40, 42, 120, 142, 143, 132] </ref>. It is among Karp's original NP-complete problems [90]. It remains NP-complete even if the given graph is unweighted [60], 14 Algorithm GreedyCut (G) Input: an undirected graph G with weights on edges Output: a cut of G 1.
Reference: [17] <author> F. Barahona, M. Grotschel, M. Junger, and G. Reinelt. </author> <title> An application of combinatorial optimization to statistical optimization and circuit layout design. </title> <journal> Operations Research, </journal> <volume> 36(3) </volume> <pages> 493-513, </pages> <year> 1988. </year>
Reference-contexts: COLORING | Given a graph, we would like to color its nodes with the fewest number of distinct colors such that no adjacent nodes have the same color. Both problems are NP-complete [58]. 2.2.1 MAXCUT MAXCUT [125] has applications in VLSI layout design and statistical physics <ref> [16, 17, 40, 42, 120, 142, 143, 132] </ref>. It is among Karp's original NP-complete problems [90]. It remains NP-complete even if the given graph is unweighted [60], 14 Algorithm GreedyCut (G) Input: an undirected graph G with weights on edges Output: a cut of G 1.
Reference: [18] <author> A. I. Barvinok. </author> <title> Problems of distance geometry and convex properties of quadratic maps. </title> <journal> Discrete and Computational Geometry, </journal> <volume> 13 </volume> <pages> 189-202, </pages> <year> 1995. </year>
Reference-contexts: set in a perfect graph, if the chromatic number of the given graph is a constant. 1.2.4 Compact algorithms Pataki shows that any extreme solution to a semidefinite program with ` constraints has rank at most p 2` [117, 118]. (The same result is implied by the work of Barvinok <ref> [18] </ref>.) The space required by any interior-point method is (n 2 ), because it has to maintain a full-rank n fi n matrix during the execution. Our basic algorithm for MAXCUT's semidefinite relaxation is potentially better because it does not have to maintain a full-rank matrix all the time.
Reference: [19] <author> M. S. Bazaraa, J. J. Jarvis, and H. D. Sherali. </author> <title> Linear Programming and Network Flows. </title> <publisher> John Wiley & Sons, </publisher> <address> second edition, </address> <year> 1990. </year>
Reference-contexts: Pataki [117] shows that if Q is nonempty, then Q contains a matrix of rank k, for some k such that k (k + 1) 2m. The low-rank matrix is called a basic solution, by analogy to the notion of a basic solution to a linear program <ref> [46, 138, 19] </ref>. His proof relies on the facial structure of the positive-semidefinite cone, which requires background from convex analysis [134, 36]. Based on the existence of basic solutions, Pataki [119] also shows how to obtain a basic solution from a feasible solution by performing a sequence of rank-reduction procedure.
Reference: [20] <author> M. Bellare, O. Goldreich, and M. Sudan. </author> <title> Free bits, PCPs and non-approximability|towards tight results. </title> <booktitle> In 36th Annual Symposium on Foundations of Computer Science [82], </booktitle> <pages> pages 422-431. 101 </pages>
Reference-contexts: Namely there exists a positive constant * such that approximating MAXCUT to within a ratio of 1* is NP-complete. For example it is NP-complete to approximate MAXCUT to within the ratio of 65=66 <ref> [20] </ref>. However, MAXCUT can be easily approximated to within a constant factor. The first approximation algorithm for MAXCUT, as shown in Figure 2.1, was given by Sahni and Gonzalez in 1976 [137].
Reference: [21] <author> M. Bellare and M. Sudan. </author> <title> Improved non-approximability results. </title> <booktitle> In ACM [1], </booktitle> <pages> pages 184-193. </pages>
Reference-contexts: There exists a positive constant * such that approximating COLORING to within a factor of n * is NP-complete [110]. Moreover, COLORING cannot be approximated in polynomial time to within a factor of n 1=10 (or n 1=13 ) unless NQP 6= co-RQP (or NP = co-RP) <ref> [21] </ref>. Researchers have been trying hard to improve the approximation ratio for COLORING [153, 29, 74].
Reference: [22] <author> C. Berge. Farbung von Graphen, deren samtliche bzw, ungerade Kreise starr sind (Zusammenfassung). </author> <booktitle> In Wissenschaftliche Zeitschrift, </booktitle> <pages> pages 114-115. </pages> <institution> Martin Luther Universitat Halle-Wittenberg, Mathematisch-Naturwissenschaftliche Reihe, </institution> <year> 1961. </year>
Reference-contexts: Lovasz [106] showed that !(G) #( G) (G); for any graph G, which is called the Sandwich Theorem by Lovasz [107]. A graph G is perfect if !(G 0 ) = (G 0 ); for any induced subgraph G 0 of G <ref> [22, 23] </ref>. Therefore both !(G) and (G) are polynomial-time computable, if G is a perfect graph. 5.2 Two Polynomial-time Algorithms for Perfect Graphs 5.2.1 MAXCLIQUE Let v be node of G.
Reference: [23] <author> C. Berge. </author> <title> Sur une conjecture relative au probleme des codes optimaux. In Communication. </title> <address> 13eme Assemblee Generale de 1'URSI, Tokyo, </address> <year> 1962. </year>
Reference-contexts: Lovasz [106] showed that !(G) #( G) (G); for any graph G, which is called the Sandwich Theorem by Lovasz [107]. A graph G is perfect if !(G 0 ) = (G 0 ); for any induced subgraph G 0 of G <ref> [22, 23] </ref>. Therefore both !(G) and (G) are polynomial-time computable, if G is a perfect graph. 5.2 Two Polynomial-time Algorithms for Perfect Graphs 5.2.1 MAXCLIQUE Let v be node of G.
Reference: [24] <author> C. Berge. </author> <title> Graphs and Hypergraphs. </title> <publisher> North-Holland, </publisher> <address> Amsterdam and London, </address> <year> 1973. </year>
Reference-contexts: There are also some results on approximation algorithms for MAXCUT on special graphs. It is known that MAXCUT has a polynomial-time approximation scheme when the given graph is dense [49, 10]. 2.2.2 COLORING COLORING [84] has applications in register allocation, time tabling, scheduling, sequencing, and circuit testing <ref> [39, 38, 34, 44, 70, 35, 24, 154, 59] </ref>. The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie. The conjecture has been answered affirmatively [7, 9].
Reference: [25] <author> D. Bertsimas and R. Vohra. </author> <title> Linear programming relaxations, approximation algorithms and randomization; A unified view of covering problems. </title> <type> Draft, </type> <year> 1994. </year>
Reference-contexts: Moreover, the randomized-rounding procedure can usually be derandomized to a deterministic algorithm [127]. It is surprising that the technique of fractional relaxation plus randomized rounding gives the best performance guarantees for many NP-hard problems <ref> [25] </ref>. Linear programming, however, is not always this powerful. Sometimes the performance of linear relaxation is limited. Therefore whether nonlinear relaxation can work better has been an open question. <p> We then round x fractional into an integral solution x integral . The vector x integral is a good approximate solution to the original integer linear program if the rounding procedure is successful. This technique has been used in approximation algorithms for many discrete optimization problems <ref> [76, 128, 127, 25] </ref>. Goemans and Williamson generalized the above linear-relaxation technique to obtain a nonlinear-relaxation one [63]: they write the MAXCUT problem as an integer semidefinite program, i.e., a semidefinite program with some integral constraints, max 4 s.t.
Reference: [26] <author> B. Bixby and G. Reinelt. </author> <title> TSPLIB | A library of travelling salesman and related problem instances. </title> <address> http://nhse.cs.rice.edu/softlib/catalog/tsplib.html, Dec. </address> <year> 1992. </year>
Reference-contexts: The result is shown in Table 7.4, and illustrated in Figure 7.6. 7.3.3 Sparse non-random graphs Since random graphs usually behave nicely, we also ran experiments on some non-random graphs. We took some graph instances from TSPLIB <ref> [129, 26] </ref>. They are all complete graphs, so we obtained a sparse graph from each of them by keeping the heaviest ten edges from each node. A typical graph of this kind is shown in Figure 7.7, where each dot corresponds to an edge.
Reference: [27] <author> A. Blum. </author> <title> An ~ O(n 0:4 )-approximation algorithm for 3-coloring (and improved approximation algorithm for k-coloring). </title> <booktitle> In Proceedings of the Twenty-First Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 535-542, </pages> <address> Seattle, Washington, </address> <month> 15-17 May </month> <year> 1989. </year>
Reference: [28] <author> A. Blum. </author> <title> Some tools for approximate 3-coloring (extended abstract). </title> <booktitle> In 31st Annual Symposium on Foundations of Computer Science, </booktitle> <volume> volume II, </volume> <pages> pages 554-562, </pages> <address> St. Louis, Missouri, 22-24 Oct. 1990. </address> <publisher> IEEE. </publisher>
Reference: [29] <author> A. Blum. </author> <title> New approximation algorithms for graph coloring. </title> <journal> Journal of the ACM, </journal> <volume> 41(3) </volume> <pages> 470-516, </pages> <month> May </month> <year> 1994. </year> <note> The preliminary versions are [27] and [28]. </note>
Reference-contexts: The near-optimal vector coloring is then "rounded" to a regular coloring by vector projection in n-dimensional space. The number of colors required by the algorithm is ~ O (n 13=(k+1) ). The number of colors required by the best previously known approximation algorithm is ~ O (n 11=(k4=3) ) <ref> [29] </ref>. The improvement is by a factor of ~ (n 2=k ). The approximation ratio for COLORING on a 3-colorable graph was later improved by Blum and Karger [30]. <p> Moreover, COLORING cannot be approximated in polynomial time to within a factor of n 1=10 (or n 1=13 ) unless NQP 6= co-RQP (or NP = co-RP) [21]. Researchers have been trying hard to improve the approximation ratio for COLORING <ref> [153, 29, 74] </ref>. The currently best approximation ratio for COLORING is O (n (log log n) 2 = log 3 n) due to Halldorsson [74]. 16 In the thesis we are interested in approximating COLORING for a k-colorable graph. The problem is also difficult. <p> The problem is also difficult. Given a 3-colorable graph, it is NP-complete to color the graph with four colors [93]. Karger, Motwani, and Sudan give the best currently known approximation algorithm for COLORING on a k-colorable graph [86]. Their result improves the best previously known ratio <ref> [29] </ref> by a factor of (n 2=k ). Their work is based on the technique of semidefinite relaxation invented by Goemans and Williamson for MAXCUT [63]. Blum and Karger combine the results in [29] and [86] and give the best known approximation algorithm for coloring a 3-colorable graph. 2.3 Semidefinite Relaxation <p> Their result improves the best previously known ratio <ref> [29] </ref> by a factor of (n 2=k ). Their work is based on the technique of semidefinite relaxation invented by Goemans and Williamson for MAXCUT [63]. Blum and Karger combine the results in [29] and [86] and give the best known approximation algorithm for coloring a 3-colorable graph. 2.3 Semidefinite Relaxation We explain the idea of semidefinite relaxation in this section. 2.3.1 Positive semidefinite matrices An n fi n matrix X is positive semidefinite if v T Xv 0 for every n-element vector v.
Reference: [30] <author> A. Blum and D. Karger. </author> <title> An ~ O(n 3=14 )-coloring for 3-colorable graphs. </title> <note> Submitted to Information Processing Letters, </note> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: The number of colors required by the best previously known approximation algorithm is ~ O (n 11=(k4=3) ) [29]. The improvement is by a factor of ~ (n 2=k ). The approximation ratio for COLORING on a 3-colorable graph was later improved by Blum and Karger <ref> [30] </ref>. Each of these improved algorithms is based on obtaining a near-optimal solution to a semidefinite program, which is referred as the semidefinite relaxation of the underlining optimization problem. Therefore how to approximately solve these semidefinite relaxations efficiently, in both time and space, is practically important.
Reference: [31] <author> I. Borosh and L. B. Treybig. </author> <title> Bounds on positive integral solutions of linear Diophantine equations. </title> <journal> Proceedings of the American Mathematical Society, </journal> <volume> 55 </volume> <pages> 299-304, </pages> <year> 1976. </year> <month> 102 </month>
Reference-contexts: Solving an integer linear program is known to be NP-complete <ref> [90, 31] </ref>, but linear program can be efficiently solved in polynomial time. Therefore the technique of fractional relaxation works as follows. The linear program without the integral constraints is called the linear relaxation of the original integer linear program.
Reference: [32] <author> S. Boyd, L. E. Ghaoui, E. Feron, and V. Balakrishnan. </author> <title> Linear matrix Inequalities in System and Control Theory. </title> <publisher> SIAM, </publisher> <year> 1994. </year>
Reference-contexts: be applied to reduce the time or space complexity of the only known polynomial-time algorithm for solving MAXCLIQUE and MAX STABLE SET on a perfect graph if its chromatic number is a constant. 8.2 Future Work We propose the following future work. * There are plenty of other semidefinite programs <ref> [106, 108, 63, 55, 51, 52, 150, 113, 32] </ref>. It would be nice if our algorithms could be generalized to work on some of them. * Our compact algorithms are still far from practical due to their time complexity.
Reference: [33] <author> S. Boyd and S. Wu. SDPSOL: </author> <title> A parser/solver for semidefinite programs with matrix structure. </title> <address> ftp://isl.stanford.edu/pub/boyd/semidef prog/sdpsol, </address> <year> 1996. </year>
Reference-contexts: is a constant, then the rank of the *-optimal solution output by CompactVectorColoring is asymptot ically lower than Pataki's rank bound O ( p m) on the basic solutions. 73 Part III Experiments and Conclusion 74 Chapter 7 Implementation Many researchers have implemented general interior-point methods for solving semidefinite programs <ref> [148, 33, 131, 130, 56] </ref>. In order to evaluate the practical performance of our algorithms, we have done some preliminary numerical experiments on our basic algorithm for MAXCUT. The programs are written in Matlab.
Reference: [34] <author> P. Briggs, K. D. Cooper, K. Kennedy, and L. Torczon. </author> <title> Coloring heuristics for register allocation. </title> <booktitle> In the SIGPLAN'89 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 257-274, </pages> <year> 1989. </year>
Reference-contexts: There are also some results on approximation algorithms for MAXCUT on special graphs. It is known that MAXCUT has a polynomial-time approximation scheme when the given graph is dense [49, 10]. 2.2.2 COLORING COLORING [84] has applications in register allocation, time tabling, scheduling, sequencing, and circuit testing <ref> [39, 38, 34, 44, 70, 35, 24, 154, 59] </ref>. The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie. The conjecture has been answered affirmatively [7, 9].
Reference: [35] <author> P. Briggs, K. D. Cooper, and L. Torczon. </author> <title> Improvements to graph coloring register allocation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 16(3) </volume> <pages> 428-455, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: There are also some results on approximation algorithms for MAXCUT on special graphs. It is known that MAXCUT has a polynomial-time approximation scheme when the given graph is dense [49, 10]. 2.2.2 COLORING COLORING [84] has applications in register allocation, time tabling, scheduling, sequencing, and circuit testing <ref> [39, 38, 34, 44, 70, 35, 24, 154, 59] </ref>. The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie. The conjecture has been answered affirmatively [7, 9].
Reference: [36] <author> A. Brtndsted. </author> <title> An Introduction to Convex Polytopes. </title> <publisher> Springer-Verlag, </publisher> <address> New York Heidelberg Berlin, </address> <year> 1983. </year>
Reference-contexts: The low-rank matrix is called a basic solution, by analogy to the notion of a basic solution to a linear program [46, 138, 19]. His proof relies on the facial structure of the positive-semidefinite cone, which requires background from convex analysis <ref> [134, 36] </ref>. Based on the existence of basic solutions, Pataki [119] also shows how to obtain a basic solution from a feasible solution by performing a sequence of rank-reduction procedure. In the subsection we explain Pataki's rank-reduction procedure. The key for the rank-reduction procedure is the following straightforward observation.
Reference: [37] <author> A. M. Bruaset. </author> <title> A Survey of Preconditioned Iterative Methods. </title> <publisher> Longman Scientific & Technical, </publisher> <year> 1995. </year>
Reference-contexts: This is due to the accumulation of the error in the computation. Researchers have developed various kinds of preconditioning techniques to bring down the condition number of the given linear system <ref> [71, 37, 91, 136] </ref>. As explained in x6.1, however, we can afford to perform the computation in O ( p n)-bit precision.
Reference: [38] <author> G. J. Chaitin. </author> <title> Register allocation and spilling via graph coloring. </title> <booktitle> In the SIGPLAN'82 Conference on Compiler Construction, </booktitle> <pages> pages 98-101, </pages> <year> 1982. </year>
Reference-contexts: There are also some results on approximation algorithms for MAXCUT on special graphs. It is known that MAXCUT has a polynomial-time approximation scheme when the given graph is dense [49, 10]. 2.2.2 COLORING COLORING [84] has applications in register allocation, time tabling, scheduling, sequencing, and circuit testing <ref> [39, 38, 34, 44, 70, 35, 24, 154, 59] </ref>. The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie. The conjecture has been answered affirmatively [7, 9].
Reference: [39] <author> G. J. Chaitin, M. A. Auslander, A. K. Chandra, J. Cocke, M. E. Hop-kins, and P. W. Markstein. </author> <title> Register allocation via coloring. </title> <journal> Computer Languages, </journal> <volume> 6 </volume> <pages> 47-57, </pages> <year> 1981. </year>
Reference-contexts: There are also some results on approximation algorithms for MAXCUT on special graphs. It is known that MAXCUT has a polynomial-time approximation scheme when the given graph is dense [49, 10]. 2.2.2 COLORING COLORING [84] has applications in register allocation, time tabling, scheduling, sequencing, and circuit testing <ref> [39, 38, 34, 44, 70, 35, 24, 154, 59] </ref>. The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie. The conjecture has been answered affirmatively [7, 9].
Reference: [40] <author> K. C. Chang and D. H. Du. </author> <title> Efficient algorithms for layer assignment problems. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> CAD-6(1):67-78, </volume> <year> 1987. </year>
Reference-contexts: COLORING | Given a graph, we would like to color its nodes with the fewest number of distinct colors such that no adjacent nodes have the same color. Both problems are NP-complete [58]. 2.2.1 MAXCUT MAXCUT [125] has applications in VLSI layout design and statistical physics <ref> [16, 17, 40, 42, 120, 142, 143, 132] </ref>. It is among Karp's original NP-complete problems [90]. It remains NP-complete even if the given graph is unweighted [60], 14 Algorithm GreedyCut (G) Input: an undirected graph G with weights on edges Output: a cut of G 1.
Reference: [41] <author> F. Chatelin. </author> <title> Eigenvalues of Matrices. </title> <publisher> John Wiley & Sons, </publisher> <year> 1993. </year>
Reference-contexts: We show that it is in fact an eigenvector problem to find a feasible matrix uu T such that huu T i y = (y). The eigenvector problem can be approximately solved by a well-known numerical algorithm called the power method (see, e.g., x5.3 of <ref> [41] </ref>), which is one of the oldest methods for computing the dominant eigenpair of a matrix. Let L 0 be a matrix defined as L 0 L ij y i y j Since L - 0, one can easily verify that L 0 - 0.
Reference: [42] <author> R. Chen, Y. Kajitani, and S. Chan. </author> <title> A graph-theoretic via minimization algorithm for two-layer printed circuit boards. </title> <journal> IEEE Transactions on Circuits and Systems, </journal> <volume> CAS-30(5):284-299, </volume> <year> 1983. </year>
Reference-contexts: COLORING | Given a graph, we would like to color its nodes with the fewest number of distinct colors such that no adjacent nodes have the same color. Both problems are NP-complete [58]. 2.2.1 MAXCUT MAXCUT [125] has applications in VLSI layout design and statistical physics <ref> [16, 17, 40, 42, 120, 142, 143, 132] </ref>. It is among Karp's original NP-complete problems [90]. It remains NP-complete even if the given graph is unweighted [60], 14 Algorithm GreedyCut (G) Input: an undirected graph G with weights on edges Output: a cut of G 1.
Reference: [43] <author> B. Chor and M. Sudan. </author> <title> A geometric approach to betweenness. </title> <booktitle> In Proceedings of the Third Annual European Symposium Algorithms, </booktitle> <pages> pages 227-237, </pages> <address> Corfu, Greece, 25-27 Sept. </address> <year> 1995. </year> <month> 103 </month>
Reference: [44] <author> F. C. Chow and J. L. Hennessy. </author> <title> The priority-based coloring approach to register allocation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(4) </volume> <pages> 501-536, </pages> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: There are also some results on approximation algorithms for MAXCUT on special graphs. It is known that MAXCUT has a polynomial-time approximation scheme when the given graph is dense [49, 10]. 2.2.2 COLORING COLORING [84] has applications in register allocation, time tabling, scheduling, sequencing, and circuit testing <ref> [39, 38, 34, 44, 70, 35, 24, 154, 59] </ref>. The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie. The conjecture has been answered affirmatively [7, 9].
Reference: [45] <author> V. Chvatal. </author> <title> Edmonds polytopes and a hierarchy of combinatorial problems. </title> <journal> Discrete Mathematics, </journal> <volume> 4 </volume> <pages> 305-337, </pages> <year> 1973. </year>
Reference-contexts: Gomory [64] proposes a way to obtain the integral convex hull by applying a sequence of linear cuts on the fractional convex hull. Chvatal <ref> [45] </ref> shows that the Gomory-cut procedure always terminates in a finite number of steps and obtains the integral convex hull. The number of steps, however, could be very large. Lovasz and Schrijver [108] show that nonlinear cuts do perform better in this aspect.
Reference: [46] <author> V. Chvatal. </author> <title> Linear Programming. </title> <publisher> Freeman, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: Pataki [117] shows that if Q is nonempty, then Q contains a matrix of rank k, for some k such that k (k + 1) 2m. The low-rank matrix is called a basic solution, by analogy to the notion of a basic solution to a linear program <ref> [46, 138, 19] </ref>. His proof relies on the facial structure of the positive-semidefinite cone, which requires background from convex analysis [134, 36]. Based on the existence of basic solutions, Pataki [119] also shows how to obtain a basic solution from a feasible solution by performing a sequence of rank-reduction procedure.
Reference: [47] <author> J. K. Cullum and R. A. Willoughby. </author> <title> Lanczos Algorithms for Large Symmetric Eigenvalue Computations, Vol. 1 Theory. </title> <publisher> Birkhauser, </publisher> <address> Boston, Basel, Stuttgart, </address> <year> 1985. </year>
Reference-contexts: In practice, however, Lanczos method is not as stable as the power method. Therefore Lanczos method involves expensive reorthogonalization during its execution. Some researchers <ref> [47] </ref> argued that reorthogonalization is not really necessary for Lanczos method.
Reference: [48] <author> G. B. Dantzig. </author> <title> Maximization of a linear function of variables subject to linear inequalities. </title> <editor> In T. C. Koopmans, editor, </editor> <title> Activity Analysis of Production and Allocation, </title> <journal> Cowles Commission Monograph No. </journal> <volume> 13, </volume> <pages> pages 339-347. </pages> <publisher> Wiley, </publisher> <address> New York, NY, </address> <year> 1951. </year>
Reference-contexts: Therefore a semidefinite program is a special case of a convex program. Although a semidefinite program is a nonlinear program, surprisingly it preserves many nice properties of a linear program. For instance most methods for solving integer programs (e.g., simplex <ref> [48] </ref>, ellipsoid [92], and interior-point [89, 156]) can be generalized to semidefinite programs [119, 68, 146, 5, 112, 113]. As a result, a semidefinite program can be approximately solved to within an additive error * in polynomial time unless the optimal solution itself is exponentially large [5].
Reference: [49] <author> W. F. de la Vega. </author> <title> MAXCUT has a randomized approximation scheme in dense graphs. </title> <type> unpublished manuscript, </type> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: There are also some results on approximation algorithms for MAXCUT on special graphs. It is known that MAXCUT has a polynomial-time approximation scheme when the given graph is dense <ref> [49, 10] </ref>. 2.2.2 COLORING COLORING [84] has applications in register allocation, time tabling, scheduling, sequencing, and circuit testing [39, 38, 34, 44, 70, 35, 24, 154, 59]. The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie.
Reference: [50] <author> D. den Hertog. </author> <title> Interior Point Approach to Linear, Quadratic and Convex Programming. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference-contexts: It basically works as follows: Suppose we are given a set of constraints, over which an objective function is supposed to be optimized. Instead of solving it using general-purpose algorithms such as ellipsoid methods [92, 68] or interior-point methods <ref> [89, 147, 50] </ref>, we could separate the constraints into two sets, say P easy and P hard , where we know how to efficiently optimize a linear objective function over P easy .
Reference: [51] <author> U. Feige and M. X. Goemans. </author> <title> Approximating the value of two prover proof systems, with applications to MAX 2SAT and MAX DICUT. </title> <booktitle> In Proceedings of the Third Israel Symposium on Theory of Computing and Systems, </booktitle> <pages> pages 182-189, </pages> <year> 1995. </year>
Reference-contexts: Later the performance ratios for MAX DICUT and MAX 2SAT are improved to 0.859 and 0.991 respectively by Feige and Goemans <ref> [51] </ref>. Using the same technique of semidef-inite relaxation, Frieze and Jerrum [55] improve the approximation algorithms for MAX BISECTION and MAX k-CUT for large k. <p> be applied to reduce the time or space complexity of the only known polynomial-time algorithm for solving MAXCLIQUE and MAX STABLE SET on a perfect graph if its chromatic number is a constant. 8.2 Future Work We propose the following future work. * There are plenty of other semidefinite programs <ref> [106, 108, 63, 55, 51, 52, 150, 113, 32] </ref>. It would be nice if our algorithms could be generalized to work on some of them. * Our compact algorithms are still far from practical due to their time complexity.
Reference: [52] <author> R. Fletcher. </author> <title> Semi-definite matrix constraints in optimization. </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 23(4) </volume> <pages> 493-513, </pages> <year> 1985. </year>
Reference-contexts: be applied to reduce the time or space complexity of the only known polynomial-time algorithm for solving MAXCLIQUE and MAX STABLE SET on a perfect graph if its chromatic number is a constant. 8.2 Future Work We propose the following future work. * There are plenty of other semidefinite programs <ref> [106, 108, 63, 55, 51, 52, 150, 113, 32] </ref>. It would be nice if our algorithms could be generalized to work on some of them. * Our compact algorithms are still far from practical due to their time complexity.
Reference: [53] <author> R. M. Freund. </author> <title> Complexity of an algorithm for finding an approximate solution of a semi-definite program with no regularity assumption. </title> <type> Technical Report OR-302-94, </type> <institution> Operations Research Center, M.I.T., </institution> <year> 1994. </year>
Reference-contexts: Nesterov and Nemirovskii [112] showed how to use the interior-point methods to solve semidefinite programs. Alizadeh [5] showed how an interior-point algorithm for linear programming could be directly generalized to handle semidef-inite programming. Since the work of Alizadeh, there has been a great deal of research into such algorithms <ref> [83, 149, 131, 157, 75, 101, 53] </ref>. A simplex-type 4 method was also discovered by Pataki [119]. Among these varieties, the per-formance of interior-point methods are the best in both theory and practice. Suppose there are ` constraints in a semidefinite program, whose variable is an n fi n matrix.
Reference: [54] <author> A. Frieze and M. Jerrum. </author> <title> Improved approximation algorithms for MAX k-CUT and MAX BISECTION. </title> <booktitle> In Proceedings of the Sixth IPCO Conference on Integer Programming and Combinatorial Optimization, </booktitle> <volume> LNCS 920, </volume> <pages> pages 1-13. </pages> <publisher> Springer, </publisher> <year> 1996. </year> <note> The journal version is [55]. 104 </note>
Reference: [55] <author> A. Frieze and M. Jerrum. </author> <title> Improved approximation algorithms for MAX k--CUT and MAX BISECTION. </title> <journal> Algorithmica, </journal> <note> (to appear). The preliminary version is [54]. </note>
Reference-contexts: Later the performance ratios for MAX DICUT and MAX 2SAT are improved to 0.859 and 0.991 respectively by Feige and Goemans [51]. Using the same technique of semidef-inite relaxation, Frieze and Jerrum <ref> [55] </ref> improve the approximation algorithms for MAX BISECTION and MAX k-CUT for large k. Inspired by the work on MAXCUT, Karger, Motwani, and Sudan [86] apply the same idea of semidefinite relaxation to the problem of coloring a k-colorable graph with the fewest possible number of colors. <p> be applied to reduce the time or space complexity of the only known polynomial-time algorithm for solving MAXCLIQUE and MAX STABLE SET on a perfect graph if its chromatic number is a constant. 8.2 Future Work We propose the following future work. * There are plenty of other semidefinite programs <ref> [106, 108, 63, 55, 51, 52, 150, 113, 32] </ref>. It would be nice if our algorithms could be generalized to work on some of them. * Our compact algorithms are still far from practical due to their time complexity.
Reference: [56] <author> K. Fujisawa and M. Kojima. </author> <title> SDPA (Semidefinite Programming Algorithm) users manual. </title> <type> Technical Report B-308, </type> <institution> Department Mathemat-ica and Computer Sciences, Tokyo Institute of Technology, </institution> <address> 2-12-1 Oh-Okayama, Meguro-ku, Tokyo 152, Japan, </address> <year> 1995. </year>
Reference-contexts: is a constant, then the rank of the *-optimal solution output by CompactVectorColoring is asymptot ically lower than Pataki's rank bound O ( p m) on the basic solutions. 73 Part III Experiments and Conclusion 74 Chapter 7 Implementation Many researchers have implemented general interior-point methods for solving semidefinite programs <ref> [148, 33, 131, 130, 56] </ref>. In order to evaluate the practical performance of our algorithms, we have done some preliminary numerical experiments on our basic algorithm for MAXCUT. The programs are written in Matlab.
Reference: [57] <author> H. N. Gabow and O. Kariv. </author> <title> Algorithms for edge coloring bipartite graphs and multigraphs. </title> <journal> SIAM Journal on Computing, </journal> <volume> 11(1) </volume> <pages> 117-129, </pages> <month> Feb. </month> <year> 1982. </year>
Reference-contexts: Moreover, a planar graph can actually be four-colored in quadratic time [8, 133]. However, COLORING is much harder than four-coloring a planar graph. Coloring a 3-colorable planar graph with three colors is NP-complete [60]. There are many positive results on solving COLORING on special graphs <ref> [61, 66, 67, 57, 145, 80, 12, 13] </ref>, among which a quite general result is that perfect graphs can be colored with the fewest possible number of colors in polynomial time [66, 67]. Approximating COLORING is difficult.
Reference: [58] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability|A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <year> 1979. </year>
Reference-contexts: Introduction Linear Programming has been a very useful tool for designing approximation algorithms. A combinatorial optimization problem can usually be written as an integer linear program, which is NP-complete to be solved <ref> [58] </ref>. A widely used technique is relaxing the underlining integer linear program to a linear program by allowing the solution to be fractional. The resulting linear program, called the fractional relaxation, is often polynomial-time solvable, e.g. if the original integer linear program has a polynomial number of constraints [92]. <p> COLORING | Given a graph, we would like to color its nodes with the fewest number of distinct colors such that no adjacent nodes have the same color. Both problems are NP-complete <ref> [58] </ref>. 2.2.1 MAXCUT MAXCUT [125] has applications in VLSI layout design and statistical physics [16, 17, 40, 42, 120, 142, 143, 132]. It is among Karp's original NP-complete problems [90].
Reference: [59] <author> M. R. Garey, D. S. Johnson, and H. C. </author> <title> So. An application of graph coloring to printed circuit testing (working paper). </title> <booktitle> In 16th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 178-183, </pages> <institution> The University of California, Berkeley, </institution> <month> 13-15 Oct. </month> <year> 1975. </year> <note> IEEE. </note>
Reference-contexts: There are also some results on approximation algorithms for MAXCUT on special graphs. It is known that MAXCUT has a polynomial-time approximation scheme when the given graph is dense [49, 10]. 2.2.2 COLORING COLORING [84] has applications in register allocation, time tabling, scheduling, sequencing, and circuit testing <ref> [39, 38, 34, 44, 70, 35, 24, 154, 59] </ref>. The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie. The conjecture has been answered affirmatively [7, 9].
Reference: [60] <author> M. R. Garey, D. S. Johnson, and L. Stockmeyer. </author> <title> Some simplified NP-complete graph problems. </title> <journal> Theoretical Computer Science, </journal> <volume> 1(3) </volume> <pages> 237-267, </pages> <month> Feb. </month> <year> 1976. </year>
Reference-contexts: Both problems are NP-complete [58]. 2.2.1 MAXCUT MAXCUT [125] has applications in VLSI layout design and statistical physics [16, 17, 40, 42, 120, 142, 143, 132]. It is among Karp's original NP-complete problems [90]. It remains NP-complete even if the given graph is unweighted <ref> [60] </ref>, 14 Algorithm GreedyCut (G) Input: an undirected graph G with weights on edges Output: a cut of G 1. Start with both sides empty, so the initial value of the cut is zero. 2. <p> Guthrie. The conjecture has been answered affirmatively [7, 9]. Moreover, a planar graph can actually be four-colored in quadratic time [8, 133]. However, COLORING is much harder than four-coloring a planar graph. Coloring a 3-colorable planar graph with three colors is NP-complete <ref> [60] </ref>. There are many positive results on solving COLORING on special graphs [61, 66, 67, 57, 145, 80, 12, 13], among which a quite general result is that perfect graphs can be colored with the fewest possible number of colors in polynomial time [66, 67]. Approximating COLORING is difficult.
Reference: [61] <author> F. Gavril. </author> <title> Algorithms for minimum coloring, maximum clique, minimum covering by cliques, and maximum independent set of a chordal graph. </title> <journal> SIAM Journal on Computing, </journal> <volume> 1(2) </volume> <pages> 180-187, </pages> <month> June </month> <year> 1972. </year>
Reference-contexts: Moreover, a planar graph can actually be four-colored in quadratic time [8, 133]. However, COLORING is much harder than four-coloring a planar graph. Coloring a 3-colorable planar graph with three colors is NP-complete [60]. There are many positive results on solving COLORING on special graphs <ref> [61, 66, 67, 57, 145, 80, 12, 13] </ref>, among which a quite general result is that perfect graphs can be colored with the fewest possible number of colors in polynomial time [66, 67]. Approximating COLORING is difficult.
Reference: [62] <author> M. X. Goemans and D. P. Williamson. </author> <title> .878-approximation algorithms for MAX CUT and MAX 2SAT. </title> <booktitle> In ACM [1], </booktitle> <pages> pages 422-431. </pages>
Reference-contexts: Their result suggests that nonlinear relaxation might perform better in designing approximation algorithms. Recently Goemans and Williamson give the first approximation algorithm which shows that nonlinear relaxation does perform better than linear relaxation <ref> [62] </ref>. Specifically they write the NP-complete MAXCUT problem as a nonlinear integer program and then relax it as a semidefinite program, which is a nonlinear program. <p> If the approximation precision * is a constant, then our algorithm performs better than the general interior-point methods, which take time ~ O (n 3:5 ) <ref> [62] </ref>. The improvement is particularly striking when the input graph is very sparse, e.g., m = O (n). We have performed some numerical experiments on sparse large graphs.
Reference: [63] <author> M. X. Goemans and D. P. Williamson. </author> <title> Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming. </title> <journal> Journal of the ACM, </journal> <volume> 42(6) </volume> <pages> 1115-1145, </pages> <month> Nov. </month> <year> 1995. </year> <note> The preliminary version is [62]. </note>
Reference-contexts: None of the results, however, makes progress on the constant term 1 2 in the approximation ratio. In the thesis we are interested in approximation algorithms for MAXCUT. 15 For a graph with no negative edge weights, Goemans and Williamson <ref> [63] </ref> give the currently best approximation algorithm for this problem in 1994. They use the technique of semidefinite relaxation to significantly improve the approximation ratio of MAXCUT to 0.878, which is provably tight [88]. <p> Their result improves the best previously known ratio [29] by a factor of (n 2=k ). Their work is based on the technique of semidefinite relaxation invented by Goemans and Williamson for MAXCUT <ref> [63] </ref>. <p> This technique has been used in approximation algorithms for many discrete optimization problems [76, 128, 127, 25]. Goemans and Williamson generalized the above linear-relaxation technique to obtain a nonlinear-relaxation one <ref> [63] </ref>: they write the MAXCUT problem as an integer semidefinite program, i.e., a semidefinite program with some integral constraints, max 4 s.t. <p> The semidefinite relaxation of MAXCUT is the following semidefinite program as shown in x2.3.4: max 1 s.t. X ii = 1 for every 1 i n X - 0: In order to handle the negative edge costs, however, Goemans and Williamson work on the following semidefinite program <ref> [63, Theorem 2.6] </ref>. max 1 4 C * (J X) c negative s.t. X ii = 1 for every 1 i n X - 0; where c negative is the sum of negative edge costs of G. <p> be applied to reduce the time or space complexity of the only known polynomial-time algorithm for solving MAXCLIQUE and MAX STABLE SET on a perfect graph if its chromatic number is a constant. 8.2 Future Work We propose the following future work. * There are plenty of other semidefinite programs <ref> [106, 108, 63, 55, 51, 52, 150, 113, 32] </ref>. It would be nice if our algorithms could be generalized to work on some of them. * Our compact algorithms are still far from practical due to their time complexity.
Reference: [64] <author> R. E. Gomory. </author> <title> An algorithm for integer solutions to linear programs. </title> <booktitle> Recent Advances in Mathematical Programming, </booktitle> <pages> pages 269-302, </pages> <year> 1963. </year>
Reference-contexts: The approach of the fractional relaxation described in the previous paragraph is closely related to how to obtain the integral convex hull from the 2 fractional convex hull of the underlining linear program. Gomory <ref> [64] </ref> proposes a way to obtain the integral convex hull by applying a sequence of linear cuts on the fractional convex hull. Chvatal [45] shows that the Gomory-cut procedure always terminates in a finite number of steps and obtains the integral convex hull.
Reference: [65] <author> M. D. Grigoriadis and L. G. Khachiyan. </author> <title> Fast approximation schemes for convex programs with many blocks and coupling constraints. </title> <type> Technical Report DCS-TR-273, </type> <institution> Rutgers University, </institution> <address> New Brunswick, NJ, </address> <year> 1991. </year> <month> 105 </month>
Reference-contexts: Plotkin, Shmoys, and Tardos then took a final step and generalized this multicommodity flow algorithm, obtaining not a single algorithm but a whole framework in which algorithms for a variety of problems could be formulated. Grigoriadis and Khachiyan <ref> [65] </ref> independently generalized the above results on multicommodity flow problem to other applications. This framework, like that of the ellipsoid algorithm [68] and the method given by Vaidya [147], casts algorithms in terms of a subroutine, an oracle. For the ellipsoid algorithm, the subroutine is called a separation oracle.
Reference: [66] <author> M. Grotschel, L. Lovasz, and A. Schrijver. </author> <title> The ellipsoid method and its consequences in combinatorial optimization. </title> <journal> Combinatorica, </journal> <volume> 1 </volume> <pages> 169-197, </pages> <year> 1981. </year>
Reference-contexts: A symmetric matrix X is positive-semidefinite if and only if every eigenvalue of X is nonnegative. The first polynomial-time algorithm proposed for solving semidefinite programs was based on the ellipsoid method. Grotschel, Lovasz, and Schrijver <ref> [66] </ref> gave a subroutine that, given a matrix X that is not positive semidefinite, finds a hyperplane separating X from the set of positive-semidefinite matrices. This subroutine, combined with the ellipsoid method, provided a polynomial-time algorithm for semidefinite programming. However, the complexity of this algorithm is quite high. <p> The required work space of both algorithms is still O (m). 1.2.3 Applications to some algorithms for perfect graphs The only known polynomial-time algorithms for some optimization problems, such as MAXCLIQUE, MAX STABLE SET, COLORING, and MIN CLIQUE COVER, on perfect graphs <ref> [66, 67] </ref>, are based on the observation that Lovasz's theta function [106] can be computed in polynomial time. It follows from the journal version of [86] that the optimum value of COLORING's semidefinite relaxation is closely related to Lovasz's theta function. <p> Moreover, a planar graph can actually be four-colored in quadratic time [8, 133]. However, COLORING is much harder than four-coloring a planar graph. Coloring a 3-colorable planar graph with three colors is NP-complete [60]. There are many positive results on solving COLORING on special graphs <ref> [61, 66, 67, 57, 145, 80, 12, 13] </ref>, among which a quite general result is that perfect graphs can be colored with the fewest possible number of colors in polynomial time [66, 67]. Approximating COLORING is difficult. <p> There are many positive results on solving COLORING on special graphs [61, 66, 67, 57, 145, 80, 12, 13], among which a quite general result is that perfect graphs can be colored with the fewest possible number of colors in polynomial time <ref> [66, 67] </ref>. Approximating COLORING is difficult. There exists a positive constant * such that approximating COLORING to within a factor of n * is NP-complete [110]. <p> The only known polynomial-time algorithms for some optimization problems on perfect graphs are based on the observation that Lovasz's theta function [106] can be computed in polynomial time <ref> [66] </ref>. It follows from a result in the journal version of [86] that the clique number of a perfect graph is strongly related to the optimal value of its semidefinite relaxation of COLORING. <p> Let G v be the induced subgraph of G obtained from G by removing v and all the edges that are incident on v. Based on the observation that !(G 0 ) = #(G 0 ) for any induced subgraph of a perfect graph G, Grotschel, Lovasz, and Schrijver <ref> [66] </ref> gave the only known polynomial-time algorithm for obtaining a maximum clique in a perfect graph. We show the algorithm in 56 Algorithm MaxClique (G) Input: a perfect graph G Output: a maximum clique of G 1. Let C = fg. 2. Compute ! = !(G). 3.
Reference: [67] <author> M. Grotschel, L. Lovasz, and A. Schrijver. </author> <title> Polynomial algorithms for perfect graphs. </title> <journal> Annal of Discrete Mathematics, </journal> <volume> 21 </volume> <pages> 325-357, </pages> <year> 1984. </year>
Reference-contexts: The required work space of both algorithms is still O (m). 1.2.3 Applications to some algorithms for perfect graphs The only known polynomial-time algorithms for some optimization problems, such as MAXCLIQUE, MAX STABLE SET, COLORING, and MIN CLIQUE COVER, on perfect graphs <ref> [66, 67] </ref>, are based on the observation that Lovasz's theta function [106] can be computed in polynomial time. It follows from the journal version of [86] that the optimum value of COLORING's semidefinite relaxation is closely related to Lovasz's theta function. <p> Moreover, a planar graph can actually be four-colored in quadratic time [8, 133]. However, COLORING is much harder than four-coloring a planar graph. Coloring a 3-colorable planar graph with three colors is NP-complete [60]. There are many positive results on solving COLORING on special graphs <ref> [61, 66, 67, 57, 145, 80, 12, 13] </ref>, among which a quite general result is that perfect graphs can be colored with the fewest possible number of colors in polynomial time [66, 67]. Approximating COLORING is difficult. <p> There are many positive results on solving COLORING on special graphs [61, 66, 67, 57, 145, 80, 12, 13], among which a quite general result is that perfect graphs can be colored with the fewest possible number of colors in polynomial time <ref> [66, 67] </ref>. Approximating COLORING is difficult. There exists a positive constant * such that approximating COLORING to within a factor of n * is NP-complete [110]. <p> Compute ! = !(G). 3. For every node v in G (a) Compute ! 0 = !(G v ). (b) If ! = ! 0 then Let G = G v , else Let C = C [ fvg. 4. Return C. When Grotschel, Lovasz, and Schrijver <ref> [67] </ref> presented the above algorithm and other only known polynomial-time algorithms for perfect graphs, the only choice for solving semidefinite programs was the ellipsoid method, whose time complexity is high.
Reference: [68] <author> M. Grotschel, L. Lovasz, and A. Schrijver. </author> <title> Geometric Algorithms and Combinatorial Optimization. </title> <publisher> Springer Verlag, </publisher> <year> 1988. </year>
Reference-contexts: La-grangean relaxation useful in exploiting the structure of mathematical programs [96, 105, 121, 87, 158]. It basically works as follows: Suppose we are given a set of constraints, over which an objective function is supposed to be optimized. Instead of solving it using general-purpose algorithms such as ellipsoid methods <ref> [92, 68] </ref> or interior-point methods [89, 147, 50], we could separate the constraints into two sets, say P easy and P hard , where we know how to efficiently optimize a linear objective function over P easy . <p> Although a semidefinite program is a nonlinear program, surprisingly it preserves many nice properties of a linear program. For instance most methods for solving integer programs (e.g., simplex [48], ellipsoid [92], and interior-point [89, 156]) can be generalized to semidefinite programs <ref> [119, 68, 146, 5, 112, 113] </ref>. As a result, a semidefinite program can be approximately solved to within an additive error * in polynomial time unless the optimal solution itself is exponentially large [5]. <p> Grigoriadis and Khachiyan [65] independently generalized the above results on multicommodity flow problem to other applications. This framework, like that of the ellipsoid algorithm <ref> [68] </ref> and the method given by Vaidya [147], casts algorithms in terms of a subroutine, an oracle. For the ellipsoid algorithm, the subroutine is called a separation oracle. For Plotkin, Shmoys, and Tardos, the subroutine must find an optimum (or near-optimum) solution to a simpler optimization problem. <p> Lovasz's theta function #(G), can be defined as follows. #(G) = minf max (A) : A is feasible for Gg: In fact there are five equivalent definitions for Lovasz's theta function. The above definition is the definition # 2 (G), as described in <ref> [68, Equation (9.3.9) in page 287] </ref> and [100, Definition (6.3) in page 9]. Lovasz [106] introduced this function to approximate the Shannon capacity [140, 135, 115] of a graph. Clearly the theta function of G can be written as a semidefinite program as follows. min s.t.
Reference: [69] <author> M. Grotschel and W. R. Pulleyblank. </author> <title> Weakly bipartite graphs and the max-cut problem. </title> <journal> Operations Research Letters, </journal> <volume> 1 </volume> <pages> 23-27, </pages> <year> 1981. </year>
Reference-contexts: Since this problem is so hard, researchers have been working along two different directions. The first direction is to look for algorithms for MAXCUT on special graphs. It is known that MAX-CUT is polynomial-time solvable on planar graphs [72, 114], weakly bipartite graphs <ref> [69] </ref>, and graphs that are not contractible to K 5 [15]. The other direction is to look for approximation algorithms. It is known that MAXCUT is MAX SNP-complete, even if the degree of the graph is bounded by a constant [116].
Reference: [70] <author> R. Gupta, M. L. Soffa, and D. Ombres. </author> <title> Efficient register allocation via coloring using clique separators. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 16(3) </volume> <pages> 370-386, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: There are also some results on approximation algorithms for MAXCUT on special graphs. It is known that MAXCUT has a polynomial-time approximation scheme when the given graph is dense [49, 10]. 2.2.2 COLORING COLORING [84] has applications in register allocation, time tabling, scheduling, sequencing, and circuit testing <ref> [39, 38, 34, 44, 70, 35, 24, 154, 59] </ref>. The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie. The conjecture has been answered affirmatively [7, 9].
Reference: [71] <author> W. Hackbusch. </author> <title> Iterative Solution of Large Sparse Systems of Equations. </title> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: This is due to the accumulation of the error in the computation. Researchers have developed various kinds of preconditioning techniques to bring down the condition number of the given linear system <ref> [71, 37, 91, 136] </ref>. As explained in x6.1, however, we can afford to perform the computation in O ( p n)-bit precision.
Reference: [72] <author> F. Hadlock. </author> <title> Finding a maximum cut of a planar graph in polynomial time. </title> <journal> SIAM Journal on Computing, </journal> <volume> 4(3) </volume> <pages> 221-225, </pages> <month> Sept. </month> <year> 1975. </year>
Reference-contexts: Since this problem is so hard, researchers have been working along two different directions. The first direction is to look for algorithms for MAXCUT on special graphs. It is known that MAX-CUT is polynomial-time solvable on planar graphs <ref> [72, 114] </ref>, weakly bipartite graphs [69], and graphs that are not contractible to K 5 [15]. The other direction is to look for approximation algorithms. It is known that MAXCUT is MAX SNP-complete, even if the degree of the graph is bounded by a constant [116].
Reference: [73] <author> D. J. Haglin and S. M. Venkatesan. </author> <title> Approximation and intractability results for the maximum cut problem and its variant. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 40 </volume> <pages> 110-113, </pages> <year> 1991. </year>
Reference-contexts: Researchers have slightly improved the approximation ratio for unweighted graph MAXCUT <ref> [151, 124, 73] </ref>. None of the results, however, makes progress on the constant term 1 2 in the approximation ratio.
Reference: [74] <author> M. M. Halldorsson. </author> <title> A still better performance guarantee for approximate graph coloring. </title> <journal> Information Processing Letters, </journal> <volume> 45 </volume> <pages> 19-23, </pages> <year> 1993. </year>
Reference-contexts: Moreover, COLORING cannot be approximated in polynomial time to within a factor of n 1=10 (or n 1=13 ) unless NQP 6= co-RQP (or NP = co-RP) [21]. Researchers have been trying hard to improve the approximation ratio for COLORING <ref> [153, 29, 74] </ref>. The currently best approximation ratio for COLORING is O (n (log log n) 2 = log 3 n) due to Halldorsson [74]. 16 In the thesis we are interested in approximating COLORING for a k-colorable graph. The problem is also difficult. <p> Researchers have been trying hard to improve the approximation ratio for COLORING [153, 29, 74]. The currently best approximation ratio for COLORING is O (n (log log n) 2 = log 3 n) due to Halldorsson <ref> [74] </ref>. 16 In the thesis we are interested in approximating COLORING for a k-colorable graph. The problem is also difficult. Given a 3-colorable graph, it is NP-complete to color the graph with four colors [93].
Reference: [75] <author> C. Helmberg, F. Rendl, R. J. Vanderbei, and H. Wolkowicz. </author> <title> An interior-point method for semidefinite programming. </title> <journal> SIAM Journal on Optimization, </journal> <volume> 6(2) </volume> <pages> 342-361, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Nesterov and Nemirovskii [112] showed how to use the interior-point methods to solve semidefinite programs. Alizadeh [5] showed how an interior-point algorithm for linear programming could be directly generalized to handle semidef-inite programming. Since the work of Alizadeh, there has been a great deal of research into such algorithms <ref> [83, 149, 131, 157, 75, 101, 53] </ref>. A simplex-type 4 method was also discovered by Pataki [119]. Among these varieties, the per-formance of interior-point methods are the best in both theory and practice. Suppose there are ` constraints in a semidefinite program, whose variable is an n fi n matrix.
Reference: [76] <author> D. S. Hochbaum. </author> <title> Approximation algorithms for the set covering and vertex cover problems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 11(3) </volume> <pages> 555-556, </pages> <month> Aug. </month> <year> 1982. </year>
Reference-contexts: We then round x fractional into an integral solution x integral . The vector x integral is a good approximate solution to the original integer linear program if the rounding procedure is successful. This technique has been used in approximation algorithms for many discrete optimization problems <ref> [76, 128, 127, 25] </ref>. Goemans and Williamson generalized the above linear-relaxation technique to obtain a nonlinear-relaxation one [63]: they write the MAXCUT problem as an integer semidefinite program, i.e., a semidefinite program with some integral constraints, max 4 s.t.
Reference: [77] <author> G. H. Holub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> The Johns Hopkins University Press, </publisher> <address> second edition, </address> <year> 1989. </year> <month> 106 </month>
Reference-contexts: We would like to point out that Lanczos method (see, e.g., x9 of <ref> [77] </ref>) is an alternative to the power method for the above eigenvector problem. It is observed that Lanczos method outperforms the power method in practice (see, e.g., x9.1.5 of [77]). <p> We would like to point out that Lanczos method (see, e.g., x9 of <ref> [77] </ref>) is an alternative to the power method for the above eigenvector problem. It is observed that Lanczos method outperforms the power method in practice (see, e.g., x9.1.5 of [77]). Based on exact arithmetic, Lanczos method requires only O (* 1=2 ln n) matrix-vector multiplications to obtain a vector x such that A * (xx T ) (1 + *) 1 [102]. <p> Then ^ ~ = maxf~ : S + ^ ~ ^ S - 0g: is well-defined. Moreover, the rank of S + ^ ~ ^ S is at most k 1. Proof Since S - 0, it follows from Theorem 8.7.1 of <ref> [77] </ref> that there exists a nonsingular k fik matrix R such that S = RDR T and ^ S = R ^ DR T , where D and ^ D are diagonal. Since R is nonsingular, we know the columns of R are linearly independent. <p> Since r 1 ; : : :; r k are linearly independent with probability one, we know ff 1 = = ff k = 0 with probability one. Now we orthonormalize w 1 ; : : : ; w ` using the Gram-Shmidt procedure (see, e.g., Chapter 5 of <ref> [77] </ref>), and get a set of orthonormal vectors u 1 ; : : : ; u k such that the linear space spanned by w 1 ; : : :; w ` is equal to the linear space spanned 66 by u 1 ; : : : ; u k . <p> It follows from x6.2.1 that the first step can be done in time O (n 2 ) and space (n 1:5 ). Step 2-(b) can be done in time O (k 3 ) and space O (k 2 ) using, for example, Algorithm 8.7.1 in <ref> [77] </ref>. The real challenge comes from Step 2-(a), which requires that we find a nonzero solution to the underconstrained homogeneous linear system Ax = 0 with O (n) variables and O (n) constraints.
Reference: [78] <author> S. Homer and M. Peinado. </author> <title> A highly parallel algorithm to approximate MaxCut on distributed memory architechtures. </title> <booktitle> In Proceedings of the 9th International Symposium on Parallel Processing (IPPS'95), </booktitle> <pages> pages 113-117. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> Apr. </month> <year> 1995. </year>
Reference: [79] <author> R. A. Horn and C. R. Johnson. </author> <title> Matrix Analysis. </title> <publisher> Cambridge University Press, </publisher> <year> 1985. </year>
Reference-contexts: It is well-known that every nfin symmetric rank-k matrix X can be written as X = V DV T for some k fi k diagonal matrix D and n fi k matrix V , where the columns of V are orthonormal (see, e.g., Theorem 2.5.4 of <ref> [79] </ref>). Let L be a linear subspace of n-dimensional space. We use L ? to denote the orthogonal space of L. Namely L ? is composed of all the vectors that are orthogonal to each vector in L. Let A be an n fi n matrix. <p> It follows from Lemma 11 that (y) = minfv v : L 0 * (vv T ) = 1g: Therefore 1=(y) = maxfL 0 * (ww T ) : w w = 1g: 37 By Rayleigh-Ritz's theorem (see, e.g., Theorem 4.2.2 of <ref> [79] </ref>) we know 1=(y) is the maximum eigenvalue of L 0 . A unit eigenvector w in the eigenspace of L 0 corresponding to 1=(y) is a vector that maximizes L 0 * (ww T ) over all unit vectors.
Reference: [80] <author> W.-L. Hsu. </author> <title> The coloring and maximum independent set problems on planar perfect graphs. </title> <journal> Journal of the ACM, </journal> <volume> 35(3) </volume> <pages> 535-563, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: Moreover, a planar graph can actually be four-colored in quadratic time [8, 133]. However, COLORING is much harder than four-coloring a planar graph. Coloring a 3-colorable planar graph with three colors is NP-complete [60]. There are many positive results on solving COLORING on special graphs <ref> [61, 66, 67, 57, 145, 80, 12, 13] </ref>, among which a quite general result is that perfect graphs can be colored with the fewest possible number of colors in polynomial time [66, 67]. Approximating COLORING is difficult.
Reference: [81] <editor> IEEE. </editor> <booktitle> 30th Annual Symposium on Foundations of Computer Science, </booktitle> <address> Research Triangle Park, North Carolina, 30 Oct.-1 Nov. </address> <year> 1989. </year>
Reference: [82] <editor> IEEE. </editor> <booktitle> 36th Annual Symposium on Foundations of Computer Science, </booktitle> <address> Milwaukee, Wisconsin, 23-25 Oct. </address> <year> 1995. </year>
Reference: [83] <author> F. Jarre. </author> <title> An interior-point method for minimizing the maximum eigenvalue of a linear combination of matrices. </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 31(5) </volume> <pages> 1360-1377, </pages> <year> 1993. </year>
Reference-contexts: Nesterov and Nemirovskii [112] showed how to use the interior-point methods to solve semidefinite programs. Alizadeh [5] showed how an interior-point algorithm for linear programming could be directly generalized to handle semidef-inite programming. Since the work of Alizadeh, there has been a great deal of research into such algorithms <ref> [83, 149, 131, 157, 75, 101, 53] </ref>. A simplex-type 4 method was also discovered by Pataki [119]. Among these varieties, the per-formance of interior-point methods are the best in both theory and practice. Suppose there are ` constraints in a semidefinite program, whose variable is an n fi n matrix.
Reference: [84] <author> T. R. Jensen and B. Toft. </author> <title> Graph Coloring Problems. Wiley-Interscience series in discrete mathematics and optimization. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: There are also some results on approximation algorithms for MAXCUT on special graphs. It is known that MAXCUT has a polynomial-time approximation scheme when the given graph is dense [49, 10]. 2.2.2 COLORING COLORING <ref> [84] </ref> has applications in register allocation, time tabling, scheduling, sequencing, and circuit testing [39, 38, 34, 44, 70, 35, 24, 154, 59]. The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie.
Reference: [85] <author> D. S. Johnson. </author> <title> Approximation algorithms for combinatorial problems. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 9(3) </volume> <pages> 256-278, </pages> <month> Dec. </month> <year> 1974. </year>
Reference-contexts: The other direction is to look for approximation algorithms. It is known that MAXCUT is MAX SNP-complete, even if the degree of the graph is bounded by a constant [116]. It follows from [11] that MAXCUT does not have a polynomial-time approximation scheme (PTAS) <ref> [85] </ref> unless P=NP. Namely there exists a positive constant * such that approximating MAXCUT to within a ratio of 1* is NP-complete. For example it is NP-complete to approximate MAXCUT to within the ratio of 65=66 [20]. However, MAXCUT can be easily approximated to within a constant factor.
Reference: [86] <author> D. Karger, R. Motwani, and M. Sudan. </author> <title> Approximate graph coloring by semidefinite programming. </title> <booktitle> In 35th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 2-13, </pages> <address> Santa Fe, New Mexico, 20-22 Nov. 1994. </address> <publisher> IEEE. </publisher>
Reference-contexts: Using the same technique of semidef-inite relaxation, Frieze and Jerrum [55] improve the approximation algorithms for MAX BISECTION and MAX k-CUT for large k. Inspired by the work on MAXCUT, Karger, Motwani, and Sudan <ref> [86] </ref> apply the same idea of semidefinite relaxation to the problem of coloring a k-colorable graph with the fewest possible number of colors. They generalize the notion of color to that of vector color. Consider a graph of n nodes. <p> It follows from the journal version of <ref> [86] </ref> that the optimum value of COLORING's semidefinite relaxation is closely related to Lovasz's theta function. <p> The problem is also difficult. Given a 3-colorable graph, it is NP-complete to color the graph with four colors [93]. Karger, Motwani, and Sudan give the best currently known approximation algorithm for COLORING on a k-colorable graph <ref> [86] </ref>. Their result improves the best previously known ratio [29] by a factor of (n 2=k ). Their work is based on the technique of semidefinite relaxation invented by Goemans and Williamson for MAXCUT [63]. Blum and Karger combine the results in [29] and [86] and give the best known approximation <p> for COLORING on a k-colorable graph <ref> [86] </ref>. Their result improves the best previously known ratio [29] by a factor of (n 2=k ). Their work is based on the technique of semidefinite relaxation invented by Goemans and Williamson for MAXCUT [63]. Blum and Karger combine the results in [29] and [86] and give the best known approximation algorithm for coloring a 3-colorable graph. 2.3 Semidefinite Relaxation We explain the idea of semidefinite relaxation in this section. 2.3.1 Positive semidefinite matrices An n fi n matrix X is positive semidefinite if v T Xv 0 for every n-element vector v. <p> = 4c negative + C * J: Therefore L * X = D * X C * X = 4c negative + C * J C * X = C * (J X) 4c negative : The semidefinite relaxation of COLORING is the following semidefinite pro gram as shown in <ref> [86] </ref>. min s.t. <p> Assume ( ~ X; ~ ) is * 3k -optimal. We show that ~ X satisfies (3.13). Let (X; ) be an optimal solution to the semidefinite relaxation of COLORING, i.e., the mathematical program (3.12). Since G is k-colorable, it follows 42 from the results in <ref> [86] </ref> that 1 k 1 : By the feasibility of (X; ) we know that Y * X k Let X fl be an optimal solution to MAXCUT's semidefinite relaxation (3.4) corresponding to the cost matrix Y . Clearly (Y ) = Y * X fl . <p> The i th node is assigned color s if z (s) is the vector in fz (1) ; : : : ; z (t) g that has the largest dot-product with h (i) . As described in <ref> [86] </ref>, each z (s) can be obtained by independently choosing each of its components from the standard normal distribution (without normalization). Therefore our basic algorithm can determine the j th component of each z (s) in the j th iteration. <p> The only known polynomial-time algorithms for some optimization problems on perfect graphs are based on the observation that Lovasz's theta function [106] can be computed in polynomial time [66]. It follows from a result in the journal version of <ref> [86] </ref> that the clique number of a perfect graph is strongly related to the optimal value of its semidefinite relaxation of COLORING. <p> It is shown in the journal version of <ref> [86] </ref> that (G) = 1=(1 !(G)). If the given perfect graph is k-colorable, then !(G) = (G) k by definition of perfect graphs. It follows that an O (1=k)-optimal approximation to (G) can be used to determine !(G), since !(G) is an integer.
Reference: [87] <author> D. Karger and S. Plotkin. </author> <title> Adding multiple cost constraints to combinatorial optimization problems, with applications to multicommodity flows. </title> <booktitle> In ACM [2], </booktitle> <pages> pages 18-25. </pages>
Reference-contexts: The basis of our algorithms is the framework of Plotkin, Shmoys, and Tar-dos [121], which is related to the technique of Lagrangean relaxation. La-grangean relaxation useful in exploiting the structure of mathematical programs <ref> [96, 105, 121, 87, 158] </ref>. It basically works as follows: Suppose we are given a set of constraints, over which an objective function is supposed to be optimized.
Reference: [88] <author> H. Karloff. </author> <title> How good is the Goemans-Williamson MAX CUT algorithm? In ACM [3], </title> <address> pages 427-434. </address>
Reference-contexts: They use the technique of semidefinite relaxation to significantly improve the approximation ratio of MAXCUT to 0.878, which is provably tight <ref> [88] </ref>. For a graph with negative edge weights, Goemans and Williamson's algorithm guarantees to find a cut whose value minus the negative edge weights is no less than 0.878 times the maximum cut value minus the negative edge weights.
Reference: [89] <author> N. Karmarkar. </author> <title> A new polynomial-time algorithm for linear programming. </title> <booktitle> In Proceedings of the Sixteenth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 302-311, </pages> <address> Washington, D.C., </address> <year> 1984. </year> <month> 107 </month>
Reference-contexts: It basically works as follows: Suppose we are given a set of constraints, over which an objective function is supposed to be optimized. Instead of solving it using general-purpose algorithms such as ellipsoid methods [92, 68] or interior-point methods <ref> [89, 147, 50] </ref>, we could separate the constraints into two sets, say P easy and P hard , where we know how to efficiently optimize a linear objective function over P easy . <p> Therefore a semidefinite program is a special case of a convex program. Although a semidefinite program is a nonlinear program, surprisingly it preserves many nice properties of a linear program. For instance most methods for solving integer programs (e.g., simplex [48], ellipsoid [92], and interior-point <ref> [89, 156] </ref>) can be generalized to semidefinite programs [119, 68, 146, 5, 112, 113]. As a result, a semidefinite program can be approximately solved to within an additive error * in polynomial time unless the optimal solution itself is exponentially large [5].
Reference: [90] <author> R. M. Karp. </author> <title> Reducibility among combinatorial problems. </title> <editor> In R. Miller and J. Thatcher, editors, </editor> <booktitle> Complexity of Computer Computations, </booktitle> <pages> pages 85-103. </pages> <publisher> Plenum Press, </publisher> <address> New York, NY, </address> <year> 1972. </year>
Reference-contexts: Both problems are NP-complete [58]. 2.2.1 MAXCUT MAXCUT [125] has applications in VLSI layout design and statistical physics [16, 17, 40, 42, 120, 142, 143, 132]. It is among Karp's original NP-complete problems <ref> [90] </ref>. It remains NP-complete even if the given graph is unweighted [60], 14 Algorithm GreedyCut (G) Input: an undirected graph G with weights on edges Output: a cut of G 1. Start with both sides empty, so the initial value of the cut is zero. 2. <p> Solving an integer linear program is known to be NP-complete <ref> [90, 31] </ref>, but linear program can be efficiently solved in polynomial time. Therefore the technique of fractional relaxation works as follows. The linear program without the integral constraints is called the linear relaxation of the original integer linear program.
Reference: [91] <author> C. T. Kelly. </author> <title> Iterative Methods for Linear and Nonlinear Equations. </title> <publisher> SIAM, </publisher> <year> 1995. </year>
Reference-contexts: This is due to the accumulation of the error in the computation. Researchers have developed various kinds of preconditioning techniques to bring down the condition number of the given linear system <ref> [71, 37, 91, 136] </ref>. As explained in x6.1, however, we can afford to perform the computation in O ( p n)-bit precision.
Reference: [92] <author> L. G. Khachiyan. </author> <title> A polynomial algorithm in linear programming. </title> <journal> Doklady Akademii Nuak SSSR, </journal> <volume> 244 </volume> <pages> 1093-1096, </pages> <year> 1979. </year>
Reference-contexts: A widely used technique is relaxing the underlining integer linear program to a linear program by allowing the solution to be fractional. The resulting linear program, called the fractional relaxation, is often polynomial-time solvable, e.g. if the original integer linear program has a polynomial number of constraints <ref> [92] </ref>. The optimal fractional solution can be regarded as some kind of approximate solution to the original integer linear program. Sometimes randomly rounding the fractional solution to an integer solution gives a good approximation to the original integer linear program with high probability [128]. <p> La-grangean relaxation useful in exploiting the structure of mathematical programs [96, 105, 121, 87, 158]. It basically works as follows: Suppose we are given a set of constraints, over which an objective function is supposed to be optimized. Instead of solving it using general-purpose algorithms such as ellipsoid methods <ref> [92, 68] </ref> or interior-point methods [89, 147, 50], we could separate the constraints into two sets, say P easy and P hard , where we know how to efficiently optimize a linear objective function over P easy . <p> Therefore a semidefinite program is a special case of a convex program. Although a semidefinite program is a nonlinear program, surprisingly it preserves many nice properties of a linear program. For instance most methods for solving integer programs (e.g., simplex [48], ellipsoid <ref> [92] </ref>, and interior-point [89, 156]) can be generalized to semidefinite programs [119, 68, 146, 5, 112, 113]. As a result, a semidefinite program can be approximately solved to within an additive error * in polynomial time unless the optimal solution itself is exponentially large [5].
Reference: [93] <author> S. Khanna, N. Linial, and S. Safra. </author> <title> On the hardness of approximating the chromatic number. </title> <booktitle> In the Second Israeli Symposium on Theory and Computing Systems, </booktitle> <pages> pages 250-260, </pages> <year> 1992. </year>
Reference-contexts: The problem is also difficult. Given a 3-colorable graph, it is NP-complete to color the graph with four colors <ref> [93] </ref>. Karger, Motwani, and Sudan give the best currently known approximation algorithm for COLORING on a k-colorable graph [86]. Their result improves the best previously known ratio [29] by a factor of (n 2=k ).
Reference: [94] <author> P. Klein and H.-I. Lu. </author> <title> Efficient approximation algorithms for semidefinite programs arising from MAXCUT and COLORING. </title> <booktitle> In ACM [3], </booktitle> <pages> pages 338-347. </pages>
Reference: [95] <author> P. Klein and H.-I. Lu. </author> <title> Space-efficient approximation algorithms for MAX-CUT and COLORING semidefinite programs. </title> <note> Submmitted to SODA'97, </note> <year> 1996. </year>
Reference: [96] <author> P. Klein, S. Plotkin, C. Stein, and E. Tardos. </author> <title> Faster approximation algorithms for the unit capacity concurrent flow problem with applications to routing and finding sparse cuts. </title> <journal> SIAM Journal on Computing, </journal> <volume> 23(3) </volume> <pages> 466-487, </pages> <month> June </month> <year> 1994. </year> <note> The preliminary version is [97]. </note>
Reference-contexts: The basis of our algorithms is the framework of Plotkin, Shmoys, and Tar-dos [121], which is related to the technique of Lagrangean relaxation. La-grangean relaxation useful in exploiting the structure of mathematical programs <ref> [96, 105, 121, 87, 158] </ref>. It basically works as follows: Suppose we are given a set of constraints, over which an objective function is supposed to be optimized. <p> Shahrokhi and Matula proved a polynomial but rather high bound on the running time of their algorithm. A much faster algorithm for this problem was developed by Klein, Plotkin, Stein, and Tardos <ref> [96] </ref>. One important ingredient in the improvement is a formulation of approximate optimality (relaxed complementary slackness conditions) that works well in this setting. This mul-ticommodity flow algorithm was generalized by Leighton, Makedon, Plotkin, Stein, Tardos, and Tragoudas [105].
Reference: [97] <author> P. Klein, C. Stein, and E. Tardos. </author> <title> Leighton-Rao might be practical: Faster approximation algorithms for concurrent flow with uniform capacities. </title> <booktitle> In Proceedings of the Twenty Second Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 310-321, </pages> <address> Baltimore, Maryland, </address> <month> 14-16 May </month> <year> 1990. </year>
Reference: [98] <author> J. Kleinberg and M. Goemans. </author> <title> The Lovasz theta function and a semidef-inite programming relaxation of vertex cover. </title> <note> SIAM Journal on Discrete Mathematics, to appear. </note>
Reference: [99] <author> D. E. Knuth. </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> volume 2. </volume> <publisher> Addison-Wesley, </publisher> <year> 1973. </year>
Reference-contexts: It is known that z can be obtained by independently choosing each component z i from the standard normal distribution and normalizing the resulting vector z (see, e.g., <ref> [99, p. 130] </ref>). For our purpose, however, there is no need to normalize the resulting vector z. Therefore we can determine z j in the j th iteration of our basic algorithm. <p> 1 : A uniformly distributed random vector x on the surface of the n-dimensional unit sphere can be obtained by randomly generating n values x 1 ; : : :; x n independently from the standard normal distribution, and then normalizing the 98 resulting vector (see, e.g., page 130 of <ref> [99] </ref>.) The standard normal distribution can be simulated using the uniform distribution between 0 and 1 (see, e.g., page 117 of [99].) Let x = x (k) , where k = d 1 * ln ( 2n c+1 * )e. <p> generating n values x 1 ; : : :; x n independently from the standard normal distribution, and then normalizing the 98 resulting vector (see, e.g., page 130 of <ref> [99] </ref>.) The standard normal distribution can be simulated using the uniform distribution between 0 and 1 (see, e.g., page 117 of [99].) Let x = x (k) , where k = d 1 * ln ( 2n c+1 * )e. It follows from Lemma 36 and Lemma 37 that the probability that A * (xx T ) (1 + *) 1 1 holds is at least 1 n c .
Reference: [100] <author> D. E. Knuth. </author> <title> The sandwich theorem. </title> <journal> The Electronic Journal of Combinatorics, </journal> <volume> 1(A1):1-48, </volume> <year> 1994. </year> <month> 108 </month>
Reference-contexts: The above definition is the definition # 2 (G), as described in [68, Equation (9.3.9) in page 287] and <ref> [100, Definition (6.3) in page 9] </ref>. Lovasz [106] introduced this function to approximate the Shannon capacity [140, 135, 115] of a graph. Clearly the theta function of G can be written as a semidefinite program as follows. min s.t.
Reference: [101] <author> M. Kojima, S. Shindoh, and S. Hara. </author> <title> Interior-point methods for the monotone linear complementarity problem in symmetric matrices. </title> <type> Technical Report B-282, </type> <institution> Department of Information Sciences, Tokyo Institute of Technology, </institution> <year> 1994. </year>
Reference-contexts: Nesterov and Nemirovskii [112] showed how to use the interior-point methods to solve semidefinite programs. Alizadeh [5] showed how an interior-point algorithm for linear programming could be directly generalized to handle semidef-inite programming. Since the work of Alizadeh, there has been a great deal of research into such algorithms <ref> [83, 149, 131, 157, 75, 101, 53] </ref>. A simplex-type 4 method was also discovered by Pataki [119]. Among these varieties, the per-formance of interior-point methods are the best in both theory and practice. Suppose there are ` constraints in a semidefinite program, whose variable is an n fi n matrix.
Reference: [102] <author> J. Kuczynski and H. Wozniakowski. </author> <title> Estimating the largest eigenvalue by the power and Lanczos algorithms with a random start. </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 13(4) </volume> <pages> 1094-1122, </pages> <month> Oct. </month> <year> 1992. </year>
Reference-contexts: The current solution X is guaranteed to be *-optimal after ~ O (* 2 n) iterations. It is known that the power method takes ~ O (* 1 ) matrix-vector multiplications to yield the required solution to each optimization subproblem <ref> [102] </ref>. Therefore it takes time ~ O (* 3 mn) for our basic algorithm to produce an *-optimal solution to the semidefinite relaxation of MAXCUT, where m is the number of edges. <p> We therefore do not include their proofs in the main content of the thesis. However, to make the thesis self-contained, we put their proofs in Appendix A. The power method is the core of our algorithms. Its analysis of can be found in <ref> [102] </ref>. For completeness of the thesis, we give an easier-to-read and shorter analysis in Appendix B. 12 Chapter 2 Background 2.1 Notation In this section we define some notation that will be used throughout the thesis. All vectors and matrices in the thesis are real. All vectors are column vectors. <p> Computing each of these products takes time proportional to the number of nonzero elements of A. In this case, the number is O (m). It is known that a good enough solution is obtained by taking k = O (* 1 log n) <ref> [102] </ref>. Thus we obtain a fast subroutine to optimize over P . Some additional work is needed. We need to ensure that the vectors obtained by the power method have reasonably small components. <p> and then compute x (k) = kA k x (0) k 2 using the recurrence x (i+1) = kAx (i) k 2 It is known that if k = (* 1 ln n) then A * (x (k) x T (k) ) (1 + *) 1 holds with high probability <ref> [102] </ref>. (For completeness of the thesis, we include an easier-to-read proof in Appendix B.) Since each iteration of the power method requires a matrix-vector multiplication, which takes time O (m), Lemma 14 follows. <p> It is observed that Lanczos method outperforms the power method in practice (see, e.g., x9.1.5 of [77]). Based on exact arithmetic, Lanczos method requires only O (* 1=2 ln n) matrix-vector multiplications to obtain a vector x such that A * (xx T ) (1 + *) 1 <ref> [102] </ref>. Therefore if we use Lanczos method to implement Direction, then the running time of VectorMaxCut would be reduced by a 38 factor of * 1=2 in exact arithmetic. In practice, however, Lanczos method is not as stable as the power method.
Reference: [103] <author> P. Lancaster and M. Tismenetsky. </author> <title> The Theory of Matrices. </title> <publisher> Academic Press, </publisher> <year> 1985. </year>
Reference-contexts: It follows directly from the definition that the sum of two positive semidefinite matrices is still positive semidefinite. If X is symmetric (which implies that all of its eigenvalues are real, see, e.g., x5.5 of [144]), then the following statements are equivalent (see, e.g., <ref> [103] </ref>): * X is positive semidefinite. * All eigenvalues of X are nonnegative. * X admits a Cholesky decomposition. Namely there exists a matrix H such that X = H T H. Recall that we use X - 0 to signify that X is symmetric and positive semidef-inite. <p> The following lemma is immediate from Gersgorin's theorem (e.g. see x10.6 of <ref> [103] </ref>). Lemma 3 Let L = L (G). Then L - 0. The semidefinite relaxation of MAXCUT is the following semidefinite program as shown in x2.3.4: max 1 s.t. <p> It follows from Gersgorin's theorem (see, e.g., x10.6 of <ref> [103] </ref>) that L + 2C - 0. Therefore Y L - 0. Note that I * Y = 2I * L 1 = 5: It follows from Lemma 7 that the optimal value is at least 0:2. <p> The procedure InitialC (G) obtains an initial solution (X; ) as follows: X ij = &gt; &gt; &gt; &lt; 1 if i = j n if ij is an edge of G 0 otherwise: Clearly X - 0 (see, e.g., Gersgorin's theorem in x10.6 of <ref> [103] </ref>). Thus the initial solution (X; 1 n ) is feasible. The procedure ImproveC (X; 0 ; *) uses a nonnegative matrix Y defined as a function of the current solution (X; ) such that (C1) is always satisfied.
Reference: [104] <author> M. Laurent, S. Poljak, and F. Rendl. </author> <title> Connections between semidefinite relaxations of the max-cut and stable set problems. </title> <type> Technical Report BS-R9502, </type> <institution> Department of Operations Research, Statistics, and System Theory, Centrum voor Wiskunde en Informatica, </institution> <year> 1995. </year>
Reference-contexts: Using the framework of Plotkin, Shmoys, and Tardos, we observe an interesting relation between the semidefinite relaxations of MAXCUT and COLORING: the semidefinite relaxation of MAXCUT can be regarded as an optimization subproblem for solving the semidefinite relaxation of COLORING. Besides our observation, Laurent, Poljak and Rendl <ref> [104] </ref> show that the semidefinite relaxation of MAX INDEPENDENCE SET can be reduced to the semidefinite relaxation of MAXCUT by introducing a new node adjacent to each node of the original graph.
Reference: [105] <author> T. Leighton, F. Makedon, S. Plotkin, C. Stein, E. Tardos, and S. Tragoudas. </author> <title> Fast approximation algorithms for multicommodity flow problems. </title> <booktitle> In Proceedings of the Twenty Third Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 101-111, </pages> <address> New Orleans, Louisiana, </address> <month> 6-8 May </month> <year> 1991. </year>
Reference-contexts: The basis of our algorithms is the framework of Plotkin, Shmoys, and Tar-dos [121], which is related to the technique of Lagrangean relaxation. La-grangean relaxation useful in exploiting the structure of mathematical programs <ref> [96, 105, 121, 87, 158] </ref>. It basically works as follows: Suppose we are given a set of constraints, over which an objective function is supposed to be optimized. <p> One important ingredient in the improvement is a formulation of approximate optimality (relaxed complementary slackness conditions) that works well in this setting. This mul-ticommodity flow algorithm was generalized by Leighton, Makedon, Plotkin, Stein, Tardos, and Tragoudas <ref> [105] </ref>. Plotkin, Shmoys, and Tardos then took a final step and generalized this multicommodity flow algorithm, obtaining not a single algorithm but a whole framework in which algorithms for a variety of problems could be formulated.
Reference: [106] <author> L. Lovasz. </author> <title> On the Shannon Capacity of a graph. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> IT-25:1-7, </volume> <year> 1979. </year>
Reference-contexts: space of both algorithms is still O (m). 1.2.3 Applications to some algorithms for perfect graphs The only known polynomial-time algorithms for some optimization problems, such as MAXCLIQUE, MAX STABLE SET, COLORING, and MIN CLIQUE COVER, on perfect graphs [66, 67], are based on the observation that Lovasz's theta function <ref> [106] </ref> can be computed in polynomial time. It follows from the journal version of [86] that the optimum value of COLORING's semidefinite relaxation is closely related to Lovasz's theta function. <p> The only known polynomial-time algorithms for some optimization problems on perfect graphs are based on the observation that Lovasz's theta function <ref> [106] </ref> can be computed in polynomial time [66]. It follows from a result in the journal version of [86] that the clique number of a perfect graph is strongly related to the optimal value of its semidefinite relaxation of COLORING. <p> The above definition is the definition # 2 (G), as described in [68, Equation (9.3.9) in page 287] and [100, Definition (6.3) in page 9]. Lovasz <ref> [106] </ref> introduced this function to approximate the Shannon capacity [140, 135, 115] of a graph. Clearly the theta function of G can be written as a semidefinite program as follows. min s.t. <p> Let G be the complement graph of G. Clearly #( G) is also a polynomial-time computable function. Let !(G) be the size of the maximum clique in G. Let (G) be the chromatic number of G. Lovasz <ref> [106] </ref> showed that !(G) #( G) (G); for any graph G, which is called the Sandwich Theorem by Lovasz [107]. A graph G is perfect if !(G 0 ) = (G 0 ); for any induced subgraph G 0 of G [22, 23]. <p> be applied to reduce the time or space complexity of the only known polynomial-time algorithm for solving MAXCLIQUE and MAX STABLE SET on a perfect graph if its chromatic number is a constant. 8.2 Future Work We propose the following future work. * There are plenty of other semidefinite programs <ref> [106, 108, 63, 55, 51, 52, 150, 113, 32] </ref>. It would be nice if our algorithms could be generalized to work on some of them. * Our compact algorithms are still far from practical due to their time complexity.
Reference: [107] <author> L. Lovasz. </author> <title> Stable sets and polynomials. </title> <note> Discrete Mathematics, to appear. </note>
Reference-contexts: Clearly #( G) is also a polynomial-time computable function. Let !(G) be the size of the maximum clique in G. Let (G) be the chromatic number of G. Lovasz [106] showed that !(G) #( G) (G); for any graph G, which is called the Sandwich Theorem by Lovasz <ref> [107] </ref>. A graph G is perfect if !(G 0 ) = (G 0 ); for any induced subgraph G 0 of G [22, 23].
Reference: [108] <author> L. Lovasz and A. Schrijver. </author> <title> Cones of Matrices and Setfunctions, </title> <journal> and 0-1 Optimization. SIAM Journal on Optimization, </journal> <volume> 1(2) </volume> <pages> 166-190, </pages> <year> 1991. </year>
Reference-contexts: Chvatal [45] shows that the Gomory-cut procedure always terminates in a finite number of steps and obtains the integral convex hull. The number of steps, however, could be very large. Lovasz and Schrijver <ref> [108] </ref> show that nonlinear cuts do perform better in this aspect. <p> be applied to reduce the time or space complexity of the only known polynomial-time algorithm for solving MAXCLIQUE and MAX STABLE SET on a perfect graph if its chromatic number is a constant. 8.2 Future Work We propose the following future work. * There are plenty of other semidefinite programs <ref> [106, 108, 63, 55, 51, 52, 150, 113, 32] </ref>. It would be nice if our algorithms could be generalized to work on some of them. * Our compact algorithms are still far from practical due to their time complexity.
Reference: [109] <author> C. Lund and M. Yannakakis. </author> <title> On the hardness of approximating minimization problems (extended abstract). </title> <booktitle> In Proceedings of the Twenty-Fifth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 286-293, </pages> <address> San Diego, California, </address> <month> 16-18 May </month> <year> 1993. </year>
Reference: [110] <author> C. Lund and M. Yannakakis. </author> <title> On the hardness of approximating minimization problems. </title> <journal> Journal of the ACM, </journal> <volume> 41(5) </volume> <pages> 960-981, </pages> <month> Sept. </month> <year> 1994. </year> <note> The preliminary version is [109]. 109 </note>
Reference-contexts: Approximating COLORING is difficult. There exists a positive constant * such that approximating COLORING to within a factor of n * is NP-complete <ref> [110] </ref>. Moreover, COLORING cannot be approximated in polynomial time to within a factor of n 1=10 (or n 1=13 ) unless NQP 6= co-RQP (or NP = co-RP) [21]. Researchers have been trying hard to improve the approximation ratio for COLORING [153, 29, 74].
Reference: [111] <author> S. Mahajan and H. Ramesh. </author> <title> Derandomizing semidefinite programming based approximation algorithms. </title> <booktitle> In 36th Annual Symposium on Foundations of Computer Science [82], </booktitle> <pages> pages 162-169. </pages>
Reference: [112] <author> Y. Nesterov and A. Nemirovskii. </author> <title> Self-Concordant Functions and Polynomial Time Methods in Covex Programming. </title> <institution> Central Economic and Mathematical Institute, USSR Academy of Science, Moscow, </institution> <year> 1989. </year>
Reference-contexts: This subroutine, combined with the ellipsoid method, provided a polynomial-time algorithm for semidefinite programming. However, the complexity of this algorithm is quite high. Nesterov and Nemirovskii <ref> [112] </ref> showed how to use the interior-point methods to solve semidefinite programs. Alizadeh [5] showed how an interior-point algorithm for linear programming could be directly generalized to handle semidef-inite programming. <p> Although a semidefinite program is a nonlinear program, surprisingly it preserves many nice properties of a linear program. For instance most methods for solving integer programs (e.g., simplex [48], ellipsoid [92], and interior-point [89, 156]) can be generalized to semidefinite programs <ref> [119, 68, 146, 5, 112, 113] </ref>. As a result, a semidefinite program can be approximately solved to within an additive error * in polynomial time unless the optimal solution itself is exponentially large [5].
Reference: [113] <author> Y. Nesterov and A. Nemirovskii. </author> <title> Interior Point Polynomial Methods in Convex Programming: Theory and Applications. </title> <institution> Society for Industrial and Applied Mathematics, </institution> <address> Philadelphia, </address> <year> 1994. </year>
Reference-contexts: Although a semidefinite program is a nonlinear program, surprisingly it preserves many nice properties of a linear program. For instance most methods for solving integer programs (e.g., simplex [48], ellipsoid [92], and interior-point [89, 156]) can be generalized to semidefinite programs <ref> [119, 68, 146, 5, 112, 113] </ref>. As a result, a semidefinite program can be approximately solved to within an additive error * in polynomial time unless the optimal solution itself is exponentially large [5]. <p> be applied to reduce the time or space complexity of the only known polynomial-time algorithm for solving MAXCLIQUE and MAX STABLE SET on a perfect graph if its chromatic number is a constant. 8.2 Future Work We propose the following future work. * There are plenty of other semidefinite programs <ref> [106, 108, 63, 55, 51, 52, 150, 113, 32] </ref>. It would be nice if our algorithms could be generalized to work on some of them. * Our compact algorithms are still far from practical due to their time complexity.
Reference: [114] <author> G. I. Orlova and Y. G. Dorfman. </author> <title> Finding the maximal cut in a graph. </title> <journal> Engineering Cybernetics, </journal> <volume> 10(3) </volume> <pages> 502-506, </pages> <year> 1972. </year>
Reference-contexts: Since this problem is so hard, researchers have been working along two different directions. The first direction is to look for algorithms for MAXCUT on special graphs. It is known that MAX-CUT is polynomial-time solvable on planar graphs <ref> [72, 114] </ref>, weakly bipartite graphs [69], and graphs that are not contractible to K 5 [15]. The other direction is to look for approximation algorithms. It is known that MAXCUT is MAX SNP-complete, even if the degree of the graph is bounded by a constant [116].
Reference: [115] <author> W. W. Padberg. </author> <title> On the facial structure of set packing polyhedra. </title> <journal> Mathematical Programming, </journal> <volume> 5 </volume> <pages> 199-215, </pages> <year> 1973. </year>
Reference-contexts: The above definition is the definition # 2 (G), as described in [68, Equation (9.3.9) in page 287] and [100, Definition (6.3) in page 9]. Lovasz [106] introduced this function to approximate the Shannon capacity <ref> [140, 135, 115] </ref> of a graph. Clearly the theta function of G can be written as a semidefinite program as follows. min s.t.
Reference: [116] <author> C. H. Papadimitriou and M. Yannakakis. </author> <title> Optimization, approximation, and complexity classes. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 43(3) </volume> <pages> 425-440, </pages> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: The other direction is to look for approximation algorithms. It is known that MAXCUT is MAX SNP-complete, even if the degree of the graph is bounded by a constant <ref> [116] </ref>. It follows from [11] that MAXCUT does not have a polynomial-time approximation scheme (PTAS) [85] unless P=NP. Namely there exists a positive constant * such that approximating MAXCUT to within a ratio of 1* is NP-complete.
Reference: [117] <author> G. Pataki. </author> <title> On the facial structure of cone-LP's and semi-definite programs. </title> <type> Technical Report MSRR-595, </type> <institution> Graduate School of Industrial Administration, Carnegie-Mellon University, </institution> <year> 1994. </year>
Reference-contexts: known polynomial-time algorithms for finding a maximum clique or a maximum stable set in a perfect graph, if the chromatic number of the given graph is a constant. 1.2.4 Compact algorithms Pataki shows that any extreme solution to a semidefinite program with ` constraints has rank at most p 2` <ref> [117, 118] </ref>. (The same result is implied by the work of Barvinok [18].) The space required by any interior-point method is (n 2 ), because it has to maintain a full-rank n fi n matrix during the execution. <p> Pataki <ref> [117] </ref> shows that if Q is nonempty, then Q contains a matrix of rank k, for some k such that k (k + 1) 2m. The low-rank matrix is called a basic solution, by analogy to the notion of a basic solution to a linear program [46, 138, 19].
Reference: [118] <author> G. Pataki. </author> <title> On cone-LP's and semi-definite programs: Facial structure, basic solutions and the simplex method. </title> <type> Draft, </type> <year> 1995. </year>
Reference-contexts: known polynomial-time algorithms for finding a maximum clique or a maximum stable set in a perfect graph, if the chromatic number of the given graph is a constant. 1.2.4 Compact algorithms Pataki shows that any extreme solution to a semidefinite program with ` constraints has rank at most p 2` <ref> [117, 118] </ref>. (The same result is implied by the work of Barvinok [18].) The space required by any interior-point method is (n 2 ), because it has to maintain a full-rank n fi n matrix during the execution. <p> Therefore our compact algorithm for MAXCUT's 10 semidefinite relaxation is basically the basic algorithm with a number of rank--reduction steps, which were proposed by Pataki <ref> [118] </ref>. Specifically, whenever the rank of the current solution is more than p 2 (n + 1), we replace the current solution by a rank p 2 (n + 1) solution that has the same quality.
Reference: [119] <author> G. Pataki. </author> <title> Cone-LP's and semidefinite programs: Geometry and a simplex-type method. </title> <booktitle> In Proceedings of the Fifth IPCO Conference on Integer Programming and Combinatorial Optimization, </booktitle> <pages> pages 162-174, </pages> <address> Vancouver, B.C., </address> <month> 3-5 June </month> <year> 1996. </year> <note> The preliminary version is [118]. </note>
Reference-contexts: Since the work of Alizadeh, there has been a great deal of research into such algorithms [83, 149, 131, 157, 75, 101, 53]. A simplex-type 4 method was also discovered by Pataki <ref> [119] </ref>. Among these varieties, the per-formance of interior-point methods are the best in both theory and practice. Suppose there are ` constraints in a semidefinite program, whose variable is an n fi n matrix. <p> Although a semidefinite program is a nonlinear program, surprisingly it preserves many nice properties of a linear program. For instance most methods for solving integer programs (e.g., simplex [48], ellipsoid [92], and interior-point [89, 156]) can be generalized to semidefinite programs <ref> [119, 68, 146, 5, 112, 113] </ref>. As a result, a semidefinite program can be approximately solved to within an additive error * in polynomial time unless the optimal solution itself is exponentially large [5]. <p> Therefore our compact algorithm is simply the basic algorithm augmented with a number of rank-reduction steps, which was first proposed by Pataki <ref> [119] </ref>. Specifically, whenever the rank of the current solution is one more than the bound given by Pataki, we replace the current solution matrix by a new matrix with the same quality, whose rank is one less than the current solution matrix. <p> His proof relies on the facial structure of the positive-semidefinite cone, which requires background from convex analysis [134, 36]. Based on the existence of basic solutions, Pataki <ref> [119] </ref> also shows how to obtain a basic solution from a feasible solution by performing a sequence of rank-reduction procedure. In the subsection we explain Pataki's rank-reduction procedure. The key for the rank-reduction procedure is the following straightforward observation.
Reference: [120] <author> R. Y. Pinter. </author> <title> Optimal layer assignment for interconnect. </title> <journal> Journal of VLSI and Computer Systems, </journal> <volume> 1 </volume> <pages> 123-137, </pages> <year> 1984. </year>
Reference-contexts: COLORING | Given a graph, we would like to color its nodes with the fewest number of distinct colors such that no adjacent nodes have the same color. Both problems are NP-complete [58]. 2.2.1 MAXCUT MAXCUT [125] has applications in VLSI layout design and statistical physics <ref> [16, 17, 40, 42, 120, 142, 143, 132] </ref>. It is among Karp's original NP-complete problems [90]. It remains NP-complete even if the given graph is unweighted [60], 14 Algorithm GreedyCut (G) Input: an undirected graph G with weights on edges Output: a cut of G 1.
Reference: [121] <author> S. A. Plotkin, D. B. Shmoys, and E. Tardos. </author> <title> Fast approximation algorithms for fractional packing and covering problems. </title> <booktitle> In 32nd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 495-504, </pages> <address> San Juan, Puerto Rico, 1-4 Oct. </address> <year> 1991. </year> <note> IEEE. The journal version is [122]. 110 </note>
Reference-contexts: Although our algorithms perform well only for obtaining rough approximations, as predicted by the analysis and shown in the experiments, they can handle instances that previous algorithms cannot even touch. The basis of our algorithms is the framework of Plotkin, Shmoys, and Tar-dos <ref> [121] </ref>, which is related to the technique of Lagrangean relaxation. La-grangean relaxation useful in exploiting the structure of mathematical programs [96, 105, 121, 87, 158]. It basically works as follows: Suppose we are given a set of constraints, over which an objective function is supposed to be optimized. <p> The basis of our algorithms is the framework of Plotkin, Shmoys, and Tar-dos [121], which is related to the technique of Lagrangean relaxation. La-grangean relaxation useful in exploiting the structure of mathematical programs <ref> [96, 105, 121, 87, 158] </ref>. It basically works as follows: Suppose we are given a set of constraints, over which an objective function is supposed to be optimized. <p> Based on the technique of Lagrangean relaxation, Plotkin, Shmoys, and Tardos <ref> [121] </ref> give a framework for designing efficient approximation algorithms for convex programs. All the previous applications of this framework are to linear programs. The results in the thesis are the first applications of the framework to nonlinear programs. <p> The time complexity of this step is O ( p using interior-point methods. In this chapter, we propose an alternative approach. We apply the method of Plotkin, Shmoys, and Tardos <ref> [121] </ref> to find approximate solutions to both semidefinite programs. As the core of these algorithms, we use the power method to solve an eigenvalue problem. The power method can exploit the sparsity of the matrix, which in turn reflects the sparsity of the graph.
Reference: [122] <author> S. A. Plotkin, D. B. Shmoys, and E. Tardos. </author> <title> Fast approximation al-gorithms for fractional packing and covering problems. </title> <note> Mathematics of Operations Research, to appear. The preliminary version is [121]. </note>
Reference-contexts: In the last chapter, we summarize our contribution, and propose some future work. Lemma 12, Lemma 13, Lemma 15, Lemma 22, Lemma 23, and Lemma 25 of the thesis are adapted from the paper by Plotkin, Shmoys, and Tardos <ref> [122] </ref>. We therefore do not include their proofs in the main content of the thesis. However, to make the thesis self-contained, we put their proofs in Appendix A. The power method is the core of our algorithms. Its analysis of can be found in [102]. <p> Let (X; ) be a feasible solution. Let ~ X be a feasible matrix such that h ~ Xi y (1 + *=13)(y): (3.10) We define the following relaxed optimality conditions, which are adapted from <ref> [122] </ref>. (P1) (1 *)y ~ 1 hXi y The following two lemmas are adapted from [122]. The first lemma shows that (P1) and (P2) together ensure the near optimality of (X; ). The second lemma shows that (P1) always holds if ff is sufficiently large. <p> Let ~ X be a feasible matrix such that h ~ Xi y (1 + *=13)(y): (3.10) We define the following relaxed optimality conditions, which are adapted from <ref> [122] </ref>. (P1) (1 *)y ~ 1 hXi y The following two lemmas are adapted from [122]. The first lemma shows that (P1) and (P2) together ensure the near optimality of (X; ). The second lemma shows that (P1) always holds if ff is sufficiently large. Lemma 12 Let y be a nonnegative vector. <p> Therefore the correctness of the algorithm relies on the termination of Improve. Clearly e ff fl y ~ 1 ne ff where fl is the optimal value and is the initial value. The following lemma, which is adapted from <ref> [122] </ref>, ensures that Improve (X; ; *) terminates in a finite number of iterations. Lemma 15 Suppose 0 &lt; * 1. Let (X; ) be a feasible solution. Let ff, , y be as defined in Improve (X; ; *). <p> Let (X; ) be a feasible solution. Let ~ X be a feasible matrix such that Y * ~ X (1 + *) 1 (Y ): (3.13) We define the following relaxed optimality conditions, which are adapted from <ref> [122] </ref>. (C1) (1 + *)Y * J Y * X The following two lemmas are adapted from [122]. The first lemma shows that (C1) and (C2) together ensure the near optimality of (X; ). The second lemma shows that (C1) is always satisfied if ff is sufficiently large. <p> Let ~ X be a feasible matrix such that Y * ~ X (1 + *) 1 (Y ): (3.13) We define the following relaxed optimality conditions, which are adapted from <ref> [122] </ref>. (C1) (1 + *)Y * J Y * X The following two lemmas are adapted from [122]. The first lemma shows that (C1) and (C2) together ensure the near optimality of (X; ). The second lemma shows that (C1) is always satisfied if ff is sufficiently large. Lemma 22 Let Y be a cost matrix for G. Let ~ X be a matrix satisfying (3.13). <p> Clearly e ff fl Y * J n 2 e ff 0 , where fl is the optimal value and 0 is the initial value. The fol lowing lemma, which is an easy adaption of Lemma 3.3 in <ref> [122] </ref>, ensures that ImproveC (X; 0 ; *) terminates in a finite number of iterations. 43 Lemma 25 Suppose 0 &lt; * 1. Let (X; ) be a feasible solution. Let ff, , Y be as defined in ImproveC (X; 0 ; *). <p> Appendix A The Proofs of Six Lemmas We include the proofs of six lemmas here. All these proofs are adapted from the corresponding proofs in the paper by Plotkin, Shmoys, and Tardos <ref> [122] </ref>. A.1 The Proof of Lemma 12 Lemma 12 Let y be a nonnegative vector. Let ~ X be a matrix such that h ~ Xi y (1 + *=13)(y). If * 1=13, then (P1) and (P2) imply that (X; ) is 4*-optimal.
Reference: [123] <author> S. Poljak. </author> <title> Integer linear programs and local search for max-cut. </title> <journal> SIAM Journal on Computing, </journal> <volume> 24(4) </volume> <pages> 822-839, </pages> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: Start with both sides empty, so the initial value of the cut is zero. 2. For every node v in G do (a) Put v on the side which increases the current cut value more. cubic <ref> [123, 155] </ref>, or quasi-planar [14]. Since this problem is so hard, researchers have been working along two different directions. The first direction is to look for algorithms for MAXCUT on special graphs.
Reference: [124] <author> S. Poljak and D. Turzk. </author> <title> A polynomial algorithm for constructing a large bipartite subgraph. </title> <journal> Canadian Journal of Mathematics, </journal> <volume> 34 </volume> <pages> 519-524, </pages> <year> 1982. </year>
Reference-contexts: Researchers have slightly improved the approximation ratio for unweighted graph MAXCUT <ref> [151, 124, 73] </ref>. None of the results, however, makes progress on the constant term 1 2 in the approximation ratio.
Reference: [125] <author> S. Poljak and Z. Tuza. </author> <title> Maximum cuts and largest bipartite subgraphs. </title> <editor> In W. Cook, L. Lovasz, and P. Seymour, editors, </editor> <booktitle> Combinatorial Optimization, volume 20 of DIMACS series in Discrete Mathematics and Theoretical Computer Science, </booktitle> <pages> pages 181-244. </pages> <publisher> Americal Mathematical Society, </publisher> <year> 1995. </year>
Reference-contexts: COLORING | Given a graph, we would like to color its nodes with the fewest number of distinct colors such that no adjacent nodes have the same color. Both problems are NP-complete [58]. 2.2.1 MAXCUT MAXCUT <ref> [125] </ref> has applications in VLSI layout design and statistical physics [16, 17, 40, 42, 120, 142, 143, 132]. It is among Karp's original NP-complete problems [90].
Reference: [126] <author> G. B. Price. </author> <title> Multivariable Analysis. </title> <publisher> Springer-Verlag, </publisher> <year> 1984. </year>
Reference-contexts: Clearly Pr ((x x 0 ) 2 a 2 ) = Pr (jx x 0 j a). We show Pr (jx x 0 j a) n c . Let ^ = arccos a. It is known by multivariable analysis (see, e.g. x60 of <ref> [126] </ref>) that Pr (jx yj a) = S ^ S ^ ); where S = Z =2 sin n2 d. Note that 2 sin , for any 2 . <p> Note that 2 sin , for any 2 . It follows that ^ 2 sin ( 2 = 2 cos ^ = n c1 : Therefore it suffices to show that S 1 n . It is known (see, e.g., (131) of x60 in <ref> [126] </ref>) that S = 2 + 1)n n=2 2 + 1) for any n 2.
Reference: [127] <author> P. Raghavan. </author> <title> Probabilistic construction of deterministic algorithms approximating packing integer programs. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 37(2) </volume> <pages> 130-143, </pages> <month> Oct. </month> <year> 1988. </year>
Reference-contexts: Sometimes randomly rounding the fractional solution to an integer solution gives a good approximation to the original integer linear program with high probability [128]. Moreover, the randomized-rounding procedure can usually be derandomized to a deterministic algorithm <ref> [127] </ref>. It is surprising that the technique of fractional relaxation plus randomized rounding gives the best performance guarantees for many NP-hard problems [25]. Linear programming, however, is not always this powerful. Sometimes the performance of linear relaxation is limited. <p> We then round x fractional into an integral solution x integral . The vector x integral is a good approximate solution to the original integer linear program if the rounding procedure is successful. This technique has been used in approximation algorithms for many discrete optimization problems <ref> [76, 128, 127, 25] </ref>. Goemans and Williamson generalized the above linear-relaxation technique to obtain a nonlinear-relaxation one [63]: they write the MAXCUT problem as an integer semidefinite program, i.e., a semidefinite program with some integral constraints, max 4 s.t.
Reference: [128] <author> P. Raghavan and C. Thompson. </author> <title> Randomized rounding: A technique for provably good algorithms and algorithmic proofs. </title> <journal> Combinatorica, </journal> <volume> 7 </volume> <pages> 365-374, </pages> <year> 1987. </year>
Reference-contexts: The optimal fractional solution can be regarded as some kind of approximate solution to the original integer linear program. Sometimes randomly rounding the fractional solution to an integer solution gives a good approximation to the original integer linear program with high probability <ref> [128] </ref>. Moreover, the randomized-rounding procedure can usually be derandomized to a deterministic algorithm [127]. It is surprising that the technique of fractional relaxation plus randomized rounding gives the best performance guarantees for many NP-hard problems [25]. Linear programming, however, is not always this powerful. <p> We then round x fractional into an integral solution x integral . The vector x integral is a good approximate solution to the original integer linear program if the rounding procedure is successful. This technique has been used in approximation algorithms for many discrete optimization problems <ref> [76, 128, 127, 25] </ref>. Goemans and Williamson generalized the above linear-relaxation technique to obtain a nonlinear-relaxation one [63]: they write the MAXCUT problem as an integer semidefinite program, i.e., a semidefinite program with some integral constraints, max 4 s.t.
Reference: [129] <author> G. Reinelt. </author> <title> TSPLIB | A traveling salesman problem library. </title> <journal> ORSA Journal on Computing, </journal> <volume> 3 </volume> <pages> 376-384, </pages> <year> 1991. </year>
Reference-contexts: The result is shown in Table 7.4, and illustrated in Figure 7.6. 7.3.3 Sparse non-random graphs Since random graphs usually behave nicely, we also ran experiments on some non-random graphs. We took some graph instances from TSPLIB <ref> [129, 26] </ref>. They are all complete graphs, so we obtained a sparse graph from each of them by keeping the heaviest ten edges from each node. A typical graph of this kind is shown in Figure 7.7, where each dot corresponds to an edge.
Reference: [130] <author> F. Rendl. </author> <title> A Matlab toolbox for semidefinite programming. The program can be found at ftp://orion.uwaterloo.ca/pub/henry/teaching/co769g/, </title> <year> 1994. </year>
Reference-contexts: is a constant, then the rank of the *-optimal solution output by CompactVectorColoring is asymptot ically lower than Pataki's rank bound O ( p m) on the basic solutions. 73 Part III Experiments and Conclusion 74 Chapter 7 Implementation Many researchers have implemented general interior-point methods for solving semidefinite programs <ref> [148, 33, 131, 130, 56] </ref>. In order to evaluate the practical performance of our algorithms, we have done some preliminary numerical experiments on our basic algorithm for MAXCUT. The programs are written in Matlab. <p> The programs are written in Matlab. We use SPARC station 10, which has 32 MB main memory and 105 MB swap space, to perform the experiments. For comparison, we use Rendl's code <ref> [130] </ref>, which is also written in Matlab. Rendl's code implements an interior-point algorithm for a very special kind of semidefinite programs.
Reference: [131] <author> F. Rendl, R. Vanderbei, and H. Wolkowicz. </author> <title> A primal-dual interior-point method for the max-min eigenvalue problem. </title> <type> Technical report, </type> <institution> University of Waterloo, Dept. of Combinatorics and Optimization, </institution> <year> 1993. </year>
Reference-contexts: Nesterov and Nemirovskii [112] showed how to use the interior-point methods to solve semidefinite programs. Alizadeh [5] showed how an interior-point algorithm for linear programming could be directly generalized to handle semidef-inite programming. Since the work of Alizadeh, there has been a great deal of research into such algorithms <ref> [83, 149, 131, 157, 75, 101, 53] </ref>. A simplex-type 4 method was also discovered by Pataki [119]. Among these varieties, the per-formance of interior-point methods are the best in both theory and practice. Suppose there are ` constraints in a semidefinite program, whose variable is an n fi n matrix. <p> is a constant, then the rank of the *-optimal solution output by CompactVectorColoring is asymptot ically lower than Pataki's rank bound O ( p m) on the basic solutions. 73 Part III Experiments and Conclusion 74 Chapter 7 Implementation Many researchers have implemented general interior-point methods for solving semidefinite programs <ref> [148, 33, 131, 130, 56] </ref>. In order to evaluate the practical performance of our algorithms, we have done some preliminary numerical experiments on our basic algorithm for MAXCUT. The programs are written in Matlab.
Reference: [132] <author> H. Rieger, L. Santen, U. Blasum, M. Junger, and M. Diehl. </author> <title> The critical exponents of the two-dimensional Ising spin glass revisited: Exact ground state calculations and Monte Carlo simulations. </title> <journal> Journal Physica A, </journal> <note> to appear. 111 </note>
Reference-contexts: COLORING | Given a graph, we would like to color its nodes with the fewest number of distinct colors such that no adjacent nodes have the same color. Both problems are NP-complete [58]. 2.2.1 MAXCUT MAXCUT [125] has applications in VLSI layout design and statistical physics <ref> [16, 17, 40, 42, 120, 142, 143, 132] </ref>. It is among Karp's original NP-complete problems [90]. It remains NP-complete even if the given graph is unweighted [60], 14 Algorithm GreedyCut (G) Input: an undirected graph G with weights on edges Output: a cut of G 1. <p> Specifically, we ran our program on graphs which come from Spin Glasses <ref> [14, 142, 143, 132] </ref>. Junger offers five weighted sparse graphs at http://www.informatik.uni-koeln.de/ls_juenger/projects/spinglass/index.html These graphs have 9, 64, 100, 400, and 2500 nodes. The number of edges in each graph is two times the number of nodes. There are edges of positive and negative weights in these graphs.
Reference: [133] <author> N. Robertson, D. P. Sanders, P. Seymour, and R. Thomas. </author> <title> Efficiently four-coloring planar graphs. </title> <booktitle> In ACM [3], </booktitle> <pages> pages 571-575. </pages>
Reference-contexts: The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie. The conjecture has been answered affirmatively [7, 9]. Moreover, a planar graph can actually be four-colored in quadratic time <ref> [8, 133] </ref>. However, COLORING is much harder than four-coloring a planar graph. Coloring a 3-colorable planar graph with three colors is NP-complete [60].
Reference: [134] <author> R. T. Rockafellar. </author> <title> Convex Analysis. </title> <publisher> Princeton University Press, </publisher> <address> Prince-ton, New Jersey, </address> <year> 1970. </year>
Reference-contexts: The low-rank matrix is called a basic solution, by analogy to the notion of a basic solution to a linear program [46, 138, 19]. His proof relies on the facial structure of the positive-semidefinite cone, which requires background from convex analysis <ref> [134, 36] </ref>. Based on the existence of basic solutions, Pataki [119] also shows how to obtain a basic solution from a feasible solution by performing a sequence of rank-reduction procedure. In the subsection we explain Pataki's rank-reduction procedure. The key for the rank-reduction procedure is the following straightforward observation.
Reference: [135] <author> M. Rosenfeld. </author> <title> On a problem of Shannon. </title> <journal> Proceedings of the American Mathematical Society, </journal> <volume> 18 </volume> <pages> 315-319, </pages> <year> 1967. </year>
Reference-contexts: The above definition is the definition # 2 (G), as described in [68, Equation (9.3.9) in page 287] and [100, Definition (6.3) in page 9]. Lovasz [106] introduced this function to approximate the Shannon capacity <ref> [140, 135, 115] </ref> of a graph. Clearly the theta function of G can be written as a semidefinite program as follows. min s.t.
Reference: [136] <author> Y. Saad. </author> <title> Iterative Methods for Sparse Linear Systems. </title> <publisher> PWS Publishing Company, </publisher> <year> 1996. </year>
Reference-contexts: This is due to the accumulation of the error in the computation. Researchers have developed various kinds of preconditioning techniques to bring down the condition number of the given linear system <ref> [71, 37, 91, 136] </ref>. As explained in x6.1, however, we can afford to perform the computation in O ( p n)-bit precision.
Reference: [137] <author> S. Sahni and T. Gonzalez. </author> <title> P-complete approximation problems. </title> <journal> Journal of the ACM, </journal> <volume> 23(3) </volume> <pages> 555-565, </pages> <month> July </month> <year> 1976. </year>
Reference-contexts: For example it is NP-complete to approximate MAXCUT to within the ratio of 65=66 [20]. However, MAXCUT can be easily approximated to within a constant factor. The first approximation algorithm for MAXCUT, as shown in Figure 2.1, was given by Sahni and Gonzalez in 1976 <ref> [137] </ref>. One can easily see that the resulting cut output by the above greedy algorithm has value at least one half of the total edge weight of G. Clearly the value of any cut is at most the sum of positive edge weights of G. <p> We also need to show how to obtain a good initial solution to the semidefinite program. For this, we use the previously known approximation algorithm for MAXCUT, due to Sahni and Gonzalez <ref> [137] </ref>, which is shown in Figure 2.1. Finally, we show that after only O (* 2 n log n) iterations of optimizing over P , we obtain an *- optimal solution X to the semidefinite program. The time required is thus O (* 3 nm log 2 n). <p> The algorithm VectorMaxCut (C; *) is given in Figure 3.1. The procedure Initial (C) obtains an initial solution (X; ) from a greedy solution to the MAXCUT problem. Using the greedy method by Sahni and Gonzalez <ref> [137] </ref>, which is shown in Figure 2.1, one can obtain a 2 3 -optimal solution to the MAXCUT problem in time linear in the number of edges. Moreover, such a greedy cut has value at least one half of the sum of edge costs.
Reference: [138] <author> A. Schrijver. </author> <title> Theory of Linear and Integer Programming. </title> <publisher> John Wiley & Sons, </publisher> <year> 1986. </year>
Reference-contexts: Pataki [117] shows that if Q is nonempty, then Q contains a matrix of rank k, for some k such that k (k + 1) 2m. The low-rank matrix is called a basic solution, by analogy to the notion of a basic solution to a linear program <ref> [46, 138, 19] </ref>. His proof relies on the facial structure of the positive-semidefinite cone, which requires background from convex analysis [134, 36]. Based on the existence of basic solutions, Pataki [119] also shows how to obtain a basic solution from a feasible solution by performing a sequence of rank-reduction procedure.
Reference: [139] <author> F. Shahrokhi and D. W. Matula. </author> <title> The maximum concurrent flow problem. </title> <journal> Journal of the ACM, </journal> <volume> 37(2) </volume> <pages> 318-334, </pages> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: These penalties are used to select a direction to move from the current candidate solution to obtain the next candidate solution, and the process is repeated. Some of the particulars of their approach originated in the work of Shahrokhi 22 and Matula <ref> [139] </ref> on approximate solution of a multicommodity flow problem. Shahrokhi and Matula proved a polynomial but rather high bound on the running time of their algorithm. A much faster algorithm for this problem was developed by Klein, Plotkin, Stein, and Tardos [96].
Reference: [140] <author> C. E. Shannon. </author> <title> The zero-error capacity of a noisy channel. </title> <journal> IRE Transaction on Information Theory, </journal> <volume> IT-2(3):8-19, </volume> <year> 1956. </year>
Reference-contexts: The above definition is the definition # 2 (G), as described in [68, Equation (9.3.9) in page 287] and [100, Definition (6.3) in page 9]. Lovasz [106] introduced this function to approximate the Shannon capacity <ref> [140, 135, 115] </ref> of a graph. Clearly the theta function of G can be written as a semidefinite program as follows. min s.t.
Reference: [141] <author> J. R. Shewchuk. </author> <title> An introduction to the Conjugate Gradient Method without the agonizing pain. </title> <type> Technical Report CMU-CS-94-125, </type> <institution> Shool of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA 15213, </address> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: Then a solution to the system can be found in time O (n 3 ) in exact arithmetic and space O (n) using iterative methods like the conjugate gradient method <ref> [141] </ref>. It can be shown that in our homogeneous system Ax = 0, the number of variables is O ( p n) more than the number of constraints.
Reference: [142] <author> C. D. Simone, M. Diehl, M. Junger, P. Mutzel, G. Reinelt, and G. Rinaldi. </author> <title> Exact ground states of Ising spin glasses: New experimental results with a branch and cut algorithm. </title> <journal> Journal of Statistical Physics, </journal> <volume> 80 </volume> <pages> 487-496, </pages> <year> 1995. </year>
Reference-contexts: COLORING | Given a graph, we would like to color its nodes with the fewest number of distinct colors such that no adjacent nodes have the same color. Both problems are NP-complete [58]. 2.2.1 MAXCUT MAXCUT [125] has applications in VLSI layout design and statistical physics <ref> [16, 17, 40, 42, 120, 142, 143, 132] </ref>. It is among Karp's original NP-complete problems [90]. It remains NP-complete even if the given graph is unweighted [60], 14 Algorithm GreedyCut (G) Input: an undirected graph G with weights on edges Output: a cut of G 1. <p> Specifically, we ran our program on graphs which come from Spin Glasses <ref> [14, 142, 143, 132] </ref>. Junger offers five weighted sparse graphs at http://www.informatik.uni-koeln.de/ls_juenger/projects/spinglass/index.html These graphs have 9, 64, 100, 400, and 2500 nodes. The number of edges in each graph is two times the number of nodes. There are edges of positive and negative weights in these graphs.
Reference: [143] <author> C. D. Simone, M. Diehl, M. Junger, P. Mutzel, G. Reinelt, and G. Rinaldi. </author> <title> Exact ground states of two-dimensional J Ising spin glasses. </title> <journal> Journal of Statistical Physics, </journal> <volume> 84(5/6), </volume> <year> 1996. </year>
Reference-contexts: COLORING | Given a graph, we would like to color its nodes with the fewest number of distinct colors such that no adjacent nodes have the same color. Both problems are NP-complete [58]. 2.2.1 MAXCUT MAXCUT [125] has applications in VLSI layout design and statistical physics <ref> [16, 17, 40, 42, 120, 142, 143, 132] </ref>. It is among Karp's original NP-complete problems [90]. It remains NP-complete even if the given graph is unweighted [60], 14 Algorithm GreedyCut (G) Input: an undirected graph G with weights on edges Output: a cut of G 1. <p> Specifically, we ran our program on graphs which come from Spin Glasses <ref> [14, 142, 143, 132] </ref>. Junger offers five weighted sparse graphs at http://www.informatik.uni-koeln.de/ls_juenger/projects/spinglass/index.html These graphs have 9, 64, 100, 400, and 2500 nodes. The number of edges in each graph is two times the number of nodes. There are edges of positive and negative weights in these graphs.
Reference: [144] <author> G. Strang. </author> <title> Linear Algebra and Its Applications. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <note> second edition, </note> <year> 1980. </year>
Reference-contexts: It follows directly from the definition that the sum of two positive semidefinite matrices is still positive semidefinite. If X is symmetric (which implies that all of its eigenvalues are real, see, e.g., x5.5 of <ref> [144] </ref>), then the following statements are equivalent (see, e.g., [103]): * X is positive semidefinite. * All eigenvalues of X are nonnegative. * X admits a Cholesky decomposition. Namely there exists a matrix H such that X = H T H.
Reference: [145] <author> A. Tucker and D. Wilson. </author> <title> An O(N 2 ) algorithm for coloring perfect planar graphs. </title> <journal> Journal of Algorithms, </journal> <volume> 5(1) </volume> <pages> 60-68, </pages> <month> Mar. </month> <year> 1984. </year> <month> 112 </month>
Reference-contexts: Moreover, a planar graph can actually be four-colored in quadratic time [8, 133]. However, COLORING is much harder than four-coloring a planar graph. Coloring a 3-colorable planar graph with three colors is NP-complete [60]. There are many positive results on solving COLORING on special graphs <ref> [61, 66, 67, 57, 145, 80, 12, 13] </ref>, among which a quite general result is that perfect graphs can be colored with the fewest possible number of colors in polynomial time [66, 67]. Approximating COLORING is difficult.
Reference: [146] <author> P. M. Vaidya. </author> <title> A new algorithm for minimizing convex functions over con-vex sets (extended abstract). </title> <booktitle> In 30th Annual Symposium on Foundations of Computer Science [81], </booktitle> <pages> pages 338-343. </pages>
Reference-contexts: Although a semidefinite program is a nonlinear program, surprisingly it preserves many nice properties of a linear program. For instance most methods for solving integer programs (e.g., simplex [48], ellipsoid [92], and interior-point [89, 156]) can be generalized to semidefinite programs <ref> [119, 68, 146, 5, 112, 113] </ref>. As a result, a semidefinite program can be approximately solved to within an additive error * in polynomial time unless the optimal solution itself is exponentially large [5].
Reference: [147] <author> P. M. Vaidya. </author> <title> Speeding-up linear programming using fast matrix multiplication (extended abstract). </title> <booktitle> In 30th Annual Symposium on Foundations of Computer Science [81], </booktitle> <pages> pages 332-337. </pages>
Reference-contexts: It basically works as follows: Suppose we are given a set of constraints, over which an objective function is supposed to be optimized. Instead of solving it using general-purpose algorithms such as ellipsoid methods [92, 68] or interior-point methods <ref> [89, 147, 50] </ref>, we could separate the constraints into two sets, say P easy and P hard , where we know how to efficiently optimize a linear objective function over P easy . <p> Grigoriadis and Khachiyan [65] independently generalized the above results on multicommodity flow problem to other applications. This framework, like that of the ellipsoid algorithm [68] and the method given by Vaidya <ref> [147] </ref>, casts algorithms in terms of a subroutine, an oracle. For the ellipsoid algorithm, the subroutine is called a separation oracle. For Plotkin, Shmoys, and Tardos, the subroutine must find an optimum (or near-optimum) solution to a simpler optimization problem.
Reference: [148] <author> L. Vandenberghe and S. Boyd. </author> <title> SP: Software for semidefinite programming. </title> <journal> ftp://isl.stanford.edu/pub/boyd/semidef prog/, </journal> <year> 1994. </year>
Reference-contexts: is a constant, then the rank of the *-optimal solution output by CompactVectorColoring is asymptot ically lower than Pataki's rank bound O ( p m) on the basic solutions. 73 Part III Experiments and Conclusion 74 Chapter 7 Implementation Many researchers have implemented general interior-point methods for solving semidefinite programs <ref> [148, 33, 131, 130, 56] </ref>. In order to evaluate the practical performance of our algorithms, we have done some preliminary numerical experiments on our basic algorithm for MAXCUT. The programs are written in Matlab.
Reference: [149] <author> L. Vandenberghe and S. Boyd. </author> <title> A primal-dual potential reduction method for problems involving matrix inequalities. </title> <journal> Mathematical Programming, Series B, </journal> <volume> 69 </volume> <pages> 205-236, </pages> <year> 1995. </year>
Reference-contexts: Nesterov and Nemirovskii [112] showed how to use the interior-point methods to solve semidefinite programs. Alizadeh [5] showed how an interior-point algorithm for linear programming could be directly generalized to handle semidef-inite programming. Since the work of Alizadeh, there has been a great deal of research into such algorithms <ref> [83, 149, 131, 157, 75, 101, 53] </ref>. A simplex-type 4 method was also discovered by Pataki [119]. Among these varieties, the per-formance of interior-point methods are the best in both theory and practice. Suppose there are ` constraints in a semidefinite program, whose variable is an n fi n matrix.
Reference: [150] <author> L. Vandenberghe and S. Boyd. </author> <title> Semidefinite programming. </title> <journal> SIAM Review, </journal> <volume> 38(1) </volume> <pages> 49-95, </pages> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: be applied to reduce the time or space complexity of the only known polynomial-time algorithm for solving MAXCLIQUE and MAX STABLE SET on a perfect graph if its chromatic number is a constant. 8.2 Future Work We propose the following future work. * There are plenty of other semidefinite programs <ref> [106, 108, 63, 55, 51, 52, 150, 113, 32] </ref>. It would be nice if our algorithms could be generalized to work on some of them. * Our compact algorithms are still far from practical due to their time complexity.
Reference: [151] <author> P. M. Vitanyi. </author> <title> How well can a graph be n-colored? Discrete Mathematics, </title> <booktitle> 34 </booktitle> <pages> 69-80, </pages> <year> 1981. </year>
Reference-contexts: Researchers have slightly improved the approximation ratio for unweighted graph MAXCUT <ref> [151, 124, 73] </ref>. None of the results, however, makes progress on the constant term 1 2 in the approximation ratio.
Reference: [152] <author> A. Wigderson. </author> <title> A new approximate graph coloring algorithm. </title> <booktitle> In Proceedings of the Fourteenth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 325-329, </pages> <address> San Francisco, California, </address> <month> 5-7 May </month> <year> 1982. </year>
Reference: [153] <author> A. Wigderson. </author> <title> Improving the performance guarantee for approximate graph coloring. </title> <journal> Journal of the ACM, </journal> <volume> 30(4) </volume> <pages> 729-735, </pages> <month> Oct. </month> <year> 1983. </year> <note> The preliminary version is [152]. </note>
Reference-contexts: Moreover, COLORING cannot be approximated in polynomial time to within a factor of n 1=10 (or n 1=13 ) unless NQP 6= co-RQP (or NP = co-RP) [21]. Researchers have been trying hard to improve the approximation ratio for COLORING <ref> [153, 29, 74] </ref>. The currently best approximation ratio for COLORING is O (n (log log n) 2 = log 3 n) due to Halldorsson [74]. 16 In the thesis we are interested in approximating COLORING for a k-colorable graph. The problem is also difficult.
Reference: [154] <author> D. C. Wood. </author> <title> A technique for coloring a graph applicable to large-scale optimization problems. </title> <journal> Computer Journal, </journal> <volume> 12:317, </volume> <year> 1969. </year>
Reference-contexts: There are also some results on approximation algorithms for MAXCUT on special graphs. It is known that MAXCUT has a polynomial-time approximation scheme when the given graph is dense [49, 10]. 2.2.2 COLORING COLORING [84] has applications in register allocation, time tabling, scheduling, sequencing, and circuit testing <ref> [39, 38, 34, 44, 70, 35, 24, 154, 59] </ref>. The most famous problem related to graph coloring is probably the four-colorability of planar graphs, which is due to F. Guthrie. The conjecture has been answered affirmatively [7, 9].
Reference: [155] <author> M. Yannakakis. </author> <title> Node- and edge-deletion NP-complete problems. </title> <booktitle> In Conference Record of the Tenth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 253-264, </pages> <address> San Diego, California, </address> <month> 1-3 May </month> <year> 1978. </year>
Reference-contexts: Start with both sides empty, so the initial value of the cut is zero. 2. For every node v in G do (a) Put v on the side which increases the current cut value more. cubic <ref> [123, 155] </ref>, or quasi-planar [14]. Since this problem is so hard, researchers have been working along two different directions. The first direction is to look for algorithms for MAXCUT on special graphs.
Reference: [156] <author> Y. Ye. </author> <title> An O(n 3 L) potential reduction algorithm for linear programming. </title> <journal> Mathematical Programming, </journal> <volume> 50 </volume> <pages> 239-258, </pages> <year> 1991. </year>
Reference-contexts: Therefore a semidefinite program is a special case of a convex program. Although a semidefinite program is a nonlinear program, surprisingly it preserves many nice properties of a linear program. For instance most methods for solving integer programs (e.g., simplex [48], ellipsoid [92], and interior-point <ref> [89, 156] </ref>) can be generalized to semidefinite programs [119, 68, 146, 5, 112, 113]. As a result, a semidefinite program can be approximately solved to within an additive error * in polynomial time unless the optimal solution itself is exponentially large [5].
Reference: [157] <author> A. Yoshise. </author> <title> An optimization method for convex programs|interior-point method and analytical center. </title> <journal> Systems, Control and Information, </journal> <volume> 38(3) </volume> <pages> 155-160, </pages> <month> Mar. </month> <year> 1994. </year> <month> 113 </month>
Reference-contexts: Nesterov and Nemirovskii [112] showed how to use the interior-point methods to solve semidefinite programs. Alizadeh [5] showed how an interior-point algorithm for linear programming could be directly generalized to handle semidef-inite programming. Since the work of Alizadeh, there has been a great deal of research into such algorithms <ref> [83, 149, 131, 157, 75, 101, 53] </ref>. A simplex-type 4 method was also discovered by Pataki [119]. Among these varieties, the per-formance of interior-point methods are the best in both theory and practice. Suppose there are ` constraints in a semidefinite program, whose variable is an n fi n matrix.
Reference: [158] <author> N. E. Young. </author> <title> Randomized rounding without solving the linear program. </title> <booktitle> In Proceedings of the Sixth Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 170-178, </pages> <address> San Fransico, California, </address> <month> 22-24 Jan. </month> <year> 1995. </year> <month> 114 </month>
Reference-contexts: The basis of our algorithms is the framework of Plotkin, Shmoys, and Tar-dos [121], which is related to the technique of Lagrangean relaxation. La-grangean relaxation useful in exploiting the structure of mathematical programs <ref> [96, 105, 121, 87, 158] </ref>. It basically works as follows: Suppose we are given a set of constraints, over which an objective function is supposed to be optimized.
References-found: 158

