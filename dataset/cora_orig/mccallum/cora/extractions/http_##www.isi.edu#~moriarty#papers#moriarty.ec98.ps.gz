URL: http://www.isi.edu/~moriarty/papers/moriarty.ec98.ps.gz
Refering-URL: http://www.isi.edu/~moriarty/mypapers.html
Root-URL: http://www.isi.edu
Email: moriarty@isi.edu  risto@cs.utexas.edu  
Title: Forming Neural Networks through Efficient and Adaptive Coevolution  
Author: David E. Moriarty Risto Miikkulainen 
Address: 4676 Admiralty Way Marina del Rey, CA 90292  Austin, TX 78712  
Affiliation: Information Sciences Institute University of Southern California  Department of Computer Sciences The University of Texas at Austin  
Note: Evolutionary Computation, 5(4), 1998. (In Press).  
Abstract: This article demonstrates the advantages of a cooperative, coevolutionary search in difficult control problems. The SANE system coevolves a population of neurons that cooperate to form a functioning neural network. In this process, neurons assume different but overlapping roles, resulting in a robust encoding of control behavior. SANE is shown to be more efficient, more adaptive, and maintain higher levels of diversity than the more common network-based population approaches. Further empirical studies illustrate the emergent neuron specializations and the different roles the neurons assume in the population. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Belew, R. K., McInerney, J., & Schraudolph, N. N. </author> <year> (1991). </year> <title> Evolving networks: Using genetic algorithm with connectionist learning. </title> <editor> In Farmer, J. D., Langton, C., Rasmussen, S., & Taylor, C. (Eds.), </editor> <booktitle> Artificial Life II Reading, </booktitle> <address> MA. </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Brooks, R. A. </author> <year> (1991). </year> <title> Intelligence without representation. </title> <journal> Artificial Intelligence, </journal> <volume> 47, </volume> <pages> 139-159. </pages>
Reference-contexts: An important facet of SANE's neurons is that they form complete input to output mappings, which makes every neuron a primitive solution in its own right. SANE can thus form subsumption-type architectures <ref> (Brooks, 1991) </ref>, where certain neurons provide very crude solutions and other neurons perform higher-level functions that fix problems in the crude solutions. Preliminary studies in simple classification tasks have uncovered some subsumptive behavior among SANE's neurons.
Reference: <author> Collins, R. J., & Jefferson, D. R. </author> <year> (1991). </year> <title> Selection in massively parallel genetic algorithms. </title> <booktitle> In Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pp. </pages> <address> 249-256 San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The SANE system will demonstrate that aggressive selection and recombination strategies can work well if tempered with effective diversity pressures. Several more intelligent methods have been developed to enforce population diversity, including fitness sharing (Goldberg & Richardson, 1987), crowding (De Jong, 1975), and local mating <ref> (Collins & Jefferson, 1991) </ref>. Each of these techniques relies on external genetic functions that prevent convergence of the genetic material. The diversity assurances, however, are normally achieved through very expensive operations.
Reference: <author> De Jong, K. A. </author> <year> (1975). </year> <title> An Analysis of the Behavior of a Class of Genetic Adaptive Systems. </title> <type> Ph.D. thesis, </type> <institution> The University of Michigan, </institution> <address> Ann Arbor, MI. </address>
Reference-contexts: The SANE system will demonstrate that aggressive selection and recombination strategies can work well if tempered with effective diversity pressures. Several more intelligent methods have been developed to enforce population diversity, including fitness sharing (Goldberg & Richardson, 1987), crowding <ref> (De Jong, 1975) </ref>, and local mating (Collins & Jefferson, 1991). Each of these techniques relies on external genetic functions that prevent convergence of the genetic material. The diversity assurances, however, are normally achieved through very expensive operations.
Reference: <author> Fahlman, S. E., & Lebiere, C. </author> <year> (1990). </year> <title> The cascade-correlation learning architecture. </title> <editor> In Touretzky, D. S. (Ed.), </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <pages> pp. 524-532. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: Unlike SANE, the LCS/NN is a pure "Michigan" approach where the entire population of neurons represents the final solution. In SANE, subpopulations represent the solution. The LCS/NN implementation uses a variant of the cascade correlation algorithm <ref> (Fahlman & Lebiere, 1990) </ref> to compute fitness levels for each neuron. Neuron fitness levels are increased if their activations correlate with correct output from the neural network.
Reference: <author> Goldberg, D. E. </author> <year> (1989). </year> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: Through this process, populations normally lose diversity and eventually converge around a single "type" of individual <ref> (Goldberg, 1989) </ref>. Such convergence is undesirable for two reasons: (1) populations often converge on suboptimal peaks and (2) converged populations cannot adapt well to changes in the task environment. <p> A neuron-level evolution explicitly promotes genetic building blocks in the population that may be useful in building other networks. A network-level evolution does so only implicitly, along with various other sub- and superstructures <ref> (Goldberg, 1989) </ref>.
Reference: <author> Goldberg, D. E., & Deb, K. </author> <year> (1991). </year> <title> A comparative analysis of selection schemes used in genetic algorithms. </title> <editor> In Rawlins, G. (Ed.), </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pp. 69-93. </pages> <publisher> Morgan-Kaufmann. </publisher>
Reference-contexts: Recent research has shown tournament selection to be the preferred method of genetic selection in terms of its growth ratios for discouraging premature convergence <ref> (Goldberg & Deb, 1991) </ref>. Comparisons of SANE to the standard tournament neuro-evolution approach demonstrate the performance of the symbiotic search relative to a more "state of the art" genetic search strategy. The fourth evolutionary approach, Neuron SANE, is a symbiotic neuron search without the higher-level blueprint evolution.
Reference: <author> Goldberg, D. E., & Richardson, J. </author> <year> (1987). </year> <title> Genetic algorithms with sharing for multimodal function optimization. </title> <booktitle> In Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pp. </pages> <address> 148-154 San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The SANE system will demonstrate that aggressive selection and recombination strategies can work well if tempered with effective diversity pressures. Several more intelligent methods have been developed to enforce population diversity, including fitness sharing <ref> (Goldberg & Richardson, 1987) </ref>, crowding (De Jong, 1975), and local mating (Collins & Jefferson, 1991). Each of these techniques relies on external genetic functions that prevent convergence of the genetic material. The diversity assurances, however, are normally achieved through very expensive operations.
Reference: <author> Grefenstette, J. J., Ramsey, C. L., & Schultz, A. C. </author> <year> (1990). </year> <title> Learning sequential decision rules using simulation models and competition. </title> <journal> Machine Learning, </journal> <volume> 5, </volume> <pages> 355-381. </pages> <publisher> 26 Holland, </publisher> <editor> J. H. </editor> <year> (1975). </year> <title> Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, </title> <booktitle> Control and Artificial Intelligence. </booktitle> <publisher> University of Michigan Press, </publisher> <address> Ann Arbor, MI. </address>
Reference: <author> Horn, J., Goldberg, D. E., & Deb, K. </author> <year> (1994). </year> <title> Implicit niching in a learning classifier system: Nature's way. </title> <journal> Evolutionary Computation, </journal> <volume> 2 (1), </volume> <pages> 37-66. </pages>
Reference: <author> Jolliffe, I. T. </author> <year> (1986). </year> <title> Principal Component Analysis. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY. </address>
Reference-contexts: The experiments described in this section illustrate this process and, in the context of the Khepera simulator, describe how and why certain neuron specializations emerge. 5.1 Principal Component Analysis In order to visualize SANE's populations, a method for displaying the neurons in 2-D is needed. Principal component analysis (PCA) <ref> (see e.g., Jolliffe, 1986) </ref> is a useful tool for visualizing the relative distances between high-dimensional vectors. PCA performs a coordinate transformation on a set of data points. The first dimension is chosen along the direction with the most variance in the data.
Reference: <author> Koza, J. R., & Rice, J. P. </author> <year> (1991). </year> <title> Genetic generalization of both the weights and architecture for a neural network. </title> <booktitle> In International Joint Conference on Neural Networks, </booktitle> <volume> Vol. 2, </volume> <pages> pp. </pages> <address> 397-404 New York, NY. </address> <publisher> IEEE. </publisher>
Reference: <author> Lee, K.-F., & Mahajan, S. </author> <year> (1990). </year> <title> The development of a world class Othello program. </title> <journal> Artificial Intelligence, </journal> <volume> 43, </volume> <pages> 21-36. </pages>
Reference-contexts: SANE was implemented to generate neural networks that serve as filters for minimax, allowing it to see only information that lead to good decisions. The SANE networks were implemented in the former world champion Othello program Bill <ref> (Lee & Mahajan, 1990) </ref> and significantly improved its performance. SANE's application to game playing demonstrates how it may be used to develop new advances in widely studied problems. Controlling Chaos (Weeks & Burgess, 1997). Weeks and Burgess applied SANE to the difficult task of controlling chaos in unstable systems.
Reference: <author> Michel, O. </author> <year> (1995). </year> <note> Khepera simulator version 1.0 user manual. http://wwwi3s.unice.fr/ om/khep-sim.html. </note>
Reference: <author> Mondada, F., Franzi, E., & Ienne, P. </author> <year> (1993). </year> <title> Mobile robot miniaturization: A tool for investigation in control algorithms. </title> <booktitle> In Proceedings of the Third International Symposium on Experimental Robotics, </booktitle> <pages> pp. </pages> <address> 501-513 Kyoto, Japan. </address>
Reference-contexts: The experiments show the advantages of SANE's symbiotic search strategy in terms of search efficiency, diversity, and adaptability. 9 Khepera and the configuration of its artificial world. 4.1 The Khepera Robot Simulator The domain chosen for evaluation of SANE was mobile robotics, or more specifically, controlling the Khepera mobile robot <ref> (Mondada, Franzi, & Ienne, 1993) </ref>. 3 Michel (1995) has developed a simulator of the Khepera robot, which contains useful X window utilities for visualizing neural network controllers. Network architectures and activations can be viewed during the simulation along with the activation of the robot's sensors and motors. <p> Khepera contains both infrared and light sensors positioned around its circumference. Despite its size, the robot is not easy to control. Khepera provides real world sensory information and requires a strong grounding to the motor outputs to effectively maneuver the robot <ref> (Mondada et al., 1993) </ref>. The I/O resources of the simulator were designed to accurately reflect those of the real robot. The eight infrared sensors detect the proximity of objects by light reflection and return values between 0 and 1023 depending on the color level.
Reference: <author> Moriarty, D. E. </author> <year> (1997). </year> <title> Symbiotic Evolution of Neural Networks in Sequential Decision Tasks. </title> <type> Ph.D. thesis, </type> <institution> Department of Computer Sciences, The University of Texas at Austin. </institution>
Reference-contexts: Figures 9 plots the two-dimensional functional representations of the neuron populations from a simulation in the Khepera task. Other simulations produced similar plots <ref> (Moriarty, 1997) </ref>. Snapshots of the populations were taken at generations 0, 10, 20, 40, and 80. Generation 0 shows a fairly uniform distribution reflective of the initially random populations. As the populations evolve, neurons begin to cluster together and form subpopulations or specializations. <p> Slows robot when an object is sensed in front and to right. 39 Veers the robot right to avoid objects to the left. Lesion studies conducted in other Khepera simulations produced similar results <ref> (Moriarty, 1997) </ref>. In almost all cases, separate specializations evolved to control the forward thrust, right turns, and left turns. At least one simulation evolved a neuron specialization that produced a 0,0 motor activation across all sensory inputs.
Reference: <author> Moriarty, D. E., & Miikkulainen, R. </author> <year> (1994). </year> <title> Evolving neural networks to focus minimax search. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <pages> pp. </pages> <address> 1371-1377 Seattle, WA. </address> <publisher> MIT Press. </publisher>
Reference-contexts: This section describes three such applications that demonstrate SANE's scope and its scale up potential. Each of these applications have used the same approach described in this paper. The only domain-specific engineering occurred in the input and output layer representations. Game Tree Search <ref> (Moriarty & Miikkulainen, 1994) </ref>. Minimax search is currently the standard method for game tree searching. Unfortunately, minimax relies on heuristic evaluation functions that are often inaccurate and misleading. They generate errors that propagate through the tree and can cause minimax to select poor moves.
Reference: <author> Moriarty, D. E., & Miikkulainen, R. </author> <year> (1996a). </year> <title> Efficient reinforcement learning through symbiotic evolution. </title> <journal> Machine Learning, </journal> <volume> 22, </volume> <pages> 11-32. </pages>
Reference-contexts: Diversity is maintained and the EA can utilize its recombination operators throughout evolution. This article demonstrates the advantages of cooperative, coevolutionary algorithms in difficult control problems using a new system called SANE (Symbiotic, Adaptive Neuro-Evolution). SANE was designed as an efficient method for building neural networks in dynamic environments <ref> (Moriarty & Miikkulainen, 1996a) </ref>. Unlike most neuro-evolutionary approaches, which operate on a population of neural networks, SANE evolves a population of neurons. Each neuron's task involves establishing connections with other neurons in the population to form a functioning neural network.
Reference: <author> Moriarty, D. E., & Miikkulainen, R. </author> <year> (1996b). </year> <title> Evolving obstacle avoidance behavior in a robot arm. </title> <booktitle> In From Animals to Animats: Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior (SAB-96), </booktitle> <pages> pp. </pages> <address> 468-475 Cape Cod, MA. </address>
Reference-contexts: The results show that SANE is quite effective at controlling chaotic behavior and should be applicable to many unstable systems including systems that are poorly understood. Robot Arm Control <ref> (Moriarty & Miikkulainen, 1996b) </ref>. Most neural network applications to robot arm control learn hand-eye coordination through supervised training methods such as backpropagation or conjugate gradient descent. Supervised learning, however, requires training examples that demonstrate correct mappings from input to output.
Reference: <author> Nolfi, S., & Parisi, D. </author> <year> (1992). </year> <title> Growing neural networks. </title> <booktitle> In Artificial Life III Reading, </booktitle> <address> MA. </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Ourston, D., & Mooney, R. J. </author> <year> (1994). </year> <title> Theory refinement combining analytical and emprical methods. </title> <journal> Artificial Intelligence, </journal> <volume> 66, </volume> <pages> 311-344. </pages>
Reference-contexts: Shared concepts, however, are advantageous because they can increase the classification accuracy for each category by applying general knowledge attained about one category to a related, but possibly more unfamiliar category <ref> (Ourston & Mooney, 1994) </ref>. Symbiotic evolution, however, is capable of forming shared intermediate concepts by simultaneously evolving rules which are used to classify multiple categories. From an initially random rule base, subpopulations of rules could be selected to form a domain theory. <p> Symbiotic evolution, however, is capable of forming shared intermediate concepts by simultaneously evolving rules which are used to classify multiple categories. From an initially random rule base, subpopulations of rules could be selected to form a domain theory. The domain theory could then be evaluated through theory refinement <ref> (Ourston & Mooney, 1994) </ref> which measures both the accuracy of the domain theory and the amount of refinement necessary. The evaluation score of the domain theory would be given to each participating rule and the process of selecting and evaluating random subpopulations would repeat.
Reference: <author> Paredis, J. </author> <year> (1995). </year> <title> Coevolutionary computation. </title> <journal> Artificial Life, </journal> <volume> 2, </volume> <pages> 355-375. </pages>
Reference: <author> Potter, M. A. </author> <year> (1997). </year> <title> The Design and Analysis of a Computational Model of Cooperative Coevolution. </title> <type> Ph.D. thesis, </type> <institution> George Mason University. </institution>
Reference: <author> Potter, M. A., & De Jong, K. A. </author> <year> (1995). </year> <title> Evolving neural networks with collaborative species. </title> <booktitle> In Proceedings of the 1995 Summer Computer Simulation Conference Ottawa, </booktitle> <address> Canada. </address>
Reference: <author> Potter, M. A., De Jong, K. A., & Grefenstette, J. </author> <year> (1995). </year> <title> A coevolutionary approach to learning sequential decision rules. </title> <editor> In Eshelman, L. (Ed.), </editor> <booktitle> Proceedings of the Sixth International Conference on Genetic Algorithms Pittsburgh, </booktitle> <address> PA. </address> <note> 27 Smith, </note> <author> R. E., & Cribbs, H. B. </author> <year> (1994). </year> <title> Is a learning classifier system a type of neural network?. </title> <journal> Evolutionary Computation, </journal> <volume> 2 (1). </volume>
Reference: <author> Smith, R. E., Forrest, S., & Perelson, A. S. </author> <year> (1993). </year> <title> Searching for diverse, cooperative populations with genetic algorithms. </title> <journal> Evolutionary Computation, </journal> <volume> 1 (2), </volume> <pages> 127-149. </pages>
Reference-contexts: Sharing requires O (n 2 ) similarity comparisons each generation, where n is the size of the population. In large populations with large chromosomes, comparison-based diversity methods such as sharing, crowding, and local mating are simply not practical <ref> (Smith et al., 1993) </ref>. A more recent technique for ensuring diversity has been termed implicit fitness sharing (Horn et al., 1994; Smith et al., 1993). No comparisons are made between individuals. Instead, diversity pressures are built into the task through cooperative behavior among the individuals in the population.
Reference: <author> Smith, R. E., & Gray, B. </author> <year> (1993). </year> <title> Co-adaptive genetic algorithms: An example in othello strategy. </title> <type> Tech. rep. </type> <institution> TCGA 94002, Department of Engineering Science and Mechanics, The University of Alabama. </institution>
Reference-contexts: Sharing requires O (n 2 ) similarity comparisons each generation, where n is the size of the population. In large populations with large chromosomes, comparison-based diversity methods such as sharing, crowding, and local mating are simply not practical <ref> (Smith et al., 1993) </ref>. A more recent technique for ensuring diversity has been termed implicit fitness sharing (Horn et al., 1994; Smith et al., 1993). No comparisons are made between individuals. Instead, diversity pressures are built into the task through cooperative behavior among the individuals in the population.
Reference: <author> Steetskamp, R. </author> <year> (1995). </year> <title> Explorations in symbiotic neuro-evolution search spaces. </title> <type> Masters Stage Report, </type> <institution> Department of Computer Science, University of Twente, The Netherlands. </institution>
Reference-contexts: Symbiosis emerges naturally in the current representation of neural networks as collections of hidden neurons, but preliminary experiments with other types of encodings, such as populations of individual network connections, have been unsuccessful <ref> (Steetskamp, 1995) </ref>. An important facet of SANE's neurons is that they form complete input to output mappings, which makes every neuron a primitive solution in its own right.
Reference: <author> Weeks, E. R., & Burgess, J. M. </author> <year> (1997). </year> <title> Evolving artificial neural networks to control chaos. </title> <journal> Phys. Rev. E, </journal> <volume> 56, </volume> <pages> 1531-1540. </pages>
Reference-contexts: The SANE networks were implemented in the former world champion Othello program Bill (Lee & Mahajan, 1990) and significantly improved its performance. SANE's application to game playing demonstrates how it may be used to develop new advances in widely studied problems. Controlling Chaos <ref> (Weeks & Burgess, 1997) </ref>. Weeks and Burgess applied SANE to the difficult task of controlling chaos in unstable systems. Chaos is dynamical behavior that is unpredictable over long periods of time, but obeys simple laws.
Reference: <author> Whitehead, B. A., & Choate, T. D. </author> <year> (1995). </year> <title> Cooperative competitive genetic evolution of radial basis function centers and widths for time series prediction. </title> <journal> IEEE Transactions on Neural Networks. </journal>
Reference: <author> Whitley, D., Dominic, S., Das, R., & Anderson, C. W. </author> <year> (1993). </year> <title> Genetic reinforcement learning for neurocontrol problems. </title> <journal> Machine Learning, </journal> <volume> 13, </volume> <pages> 259-284. 28 </pages>
References-found: 31

