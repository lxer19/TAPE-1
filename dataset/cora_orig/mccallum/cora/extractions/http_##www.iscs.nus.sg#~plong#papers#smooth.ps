URL: http://www.iscs.nus.sg/~plong/papers/smooth.ps
Refering-URL: 
Root-URL: 
Email: kimber@parc.xerox.com  plong@cs.duke.edu  
Title: On-line Learning of Smooth Functions of a Single Variable  
Author: Don Kimber Philip M. Long 
Date: April 12, 1994  
Address: Stanford, CA 94304  P.O. Box 90129 Durham, NC 27708  
Affiliation: Information Systems Laboratory Department of Electrical Engineering Stanford University  Computer Science Department Duke University  
Abstract: We study the on-line learning of classes of functions of a single real variable formed through bounds on various norms of functions' derivatives. We determine the best bounds obtainable on the worst-case sum of squared errors (also "absolute" errors) for several such classes. We prove upper bounds for these classes of smooth functions for other loss functions, and prove upper and lower bounds in terms of the number of trials.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Barron. </author> <title> Approximation and estimation bounds for artificial neural networks. </title> <booktitle> The 1991 Workshop on Computational Learning Theory, </booktitle> <year> 1991. </year>
Reference-contexts: 1 Introduction We consider the learning of real-valued functions of a single <ref> [0; 1] </ref>-valued variable in a model introduced by Mycielski [11], and independently by Littlestone and Warmuth [10]. A learning problem consists of a class F of such functions. <p> A learning problem consists of a class F of such functions. We assume that a function f 2 F is hidden from the learner, and that learning proceeds in trials, where in the tth trial, the learning algorithm receives x t 2 <ref> [0; 1] </ref> from the environment, is required to output a prediction ^y t of f (x t ), then finds out the value of f (x t ). <p> For each p 1, the p-performance of a learning algorithm A for F on a finite sequence = hx t i tm 2 <ref> [0; 1] </ref> and an f 2 F is 1 L p (A; f; ) = t=2 The p-performance of A on F is then defined to be L p (A; F) = sup L p (A; f; ): We will focus primarily on the choices p 2 f1; 2g. <p> Toward this end, for q 2 f1; 2; 1g, we will study the class F q of well-behaved functions whose first derivatives have q-norm at most 1. Recall that, for 1 q &lt; 1, the q-norm of a function f defined on <ref> [0; 1] </ref> is defined to be Z 1 jf (x)j q dx ; and that the infinity norm of f is the limit, as q approaches infinity, of its q-norm. <p> Many statisticians, and, more recently, computational learning theorists (see e.g., [4] <ref> [1] </ref> [5]) have studied the induction of classes of functions obtained through smoothness constraints. The spirit of their work differs from ours in several ways. First, their theorems usually concern functions of potentially many real variables, where ours, at present, apply only to functions of a single real variable. <p> In our analysis, it will be convenient to consider classes of functions defined on [0; a] for a &gt; 0, constrained by the values of the functions at 0 and a. For a; b 2 <ref> [0; 1] </ref>, define G a;b to be the class of well-behaved functions g defined on [0; a] for which g (0) = 0 and g (a) = b, with the further restriction that g 0 (x) 1 for all x on which g 0 is defined. <p> We showed in Section 2 that opt 2 (F 1 ) = 1. Suppose S = f (u i ; v i ) : 1 i mg is a finite subset of <ref> [0; 1] </ref> fi R such that u 1 &lt; u 2 &lt; &lt; u m : Define f S : [0; 1] ! R as follows: for all x; f ; (x) = 0, and f S (x) = &lt; v 1 if x u 1 (xu i )(v i+1 v <p> Suppose S = f (u i ; v i ) : 1 i mg is a finite subset of <ref> [0; 1] </ref> fi R such that u 1 &lt; u 2 &lt; &lt; u m : Define f S : [0; 1] ! R as follows: for all x; f ; (x) = 0, and f S (x) = &lt; v 1 if x u 1 (xu i )(v i+1 v i ) v m if x &gt; u m For f : [0; 1] ! R, define the action of <p> u m : Define f S : <ref> [0; 1] </ref> ! R as follows: for all x; f ; (x) = 0, and f S (x) = &lt; v 1 if x u 1 (xu i )(v i+1 v i ) v m if x &gt; u m For f : [0; 1] ! R, define the action of f, denoted by J [f], to be J [f ] = 0 Note that jjf 0 jj 2 1 exactly when J [f ] 1, and therefore that F 2 can also be thought of as the set of functions whose action is <p> Let (u 1 ; v 1 ); :::; (u m ; v m ) be a sample with 0 u 1 &lt; u 2 &lt; &lt; u m 1. Let S = f (u i ; v i ) : 1 i mg. Choose an example (x; y) 2 <ref> [0; 1] </ref> fi R. <p> Theorem 11 L 2 (LININT; F 2 ) 1: Proof: Choose a target function f 2 F 2 and a sequence x 1 ; x 2 ; ::: of elements of <ref> [0; 1] </ref>. Assume without loss of generality that the x t 's are distinct. By Lemma 10, we have that the action of the algorithm's hypothesis increases by at least (^y t f (x t )) 2 on each trial t &gt; 1. <p> The following lemma will be useful in both analyses. Lemma 14 Choose a sequence x 1 ; x 2 ; ::: of elements of <ref> [0; 1] </ref>. For each t &gt; 1, let d t = min jx t x i j: 1 X d t 1 + 1=(2 p 2): Proof: Choose a sequence x 1 ; x 2 ; ::: of elements of [0; 1]. <p> x 1 ; x 2 ; ::: of elements of <ref> [0; 1] </ref>. For each t &gt; 1, let d t = min jx t x i j: 1 X d t 1 + 1=(2 p 2): Proof: Choose a sequence x 1 ; x 2 ; ::: of elements of [0; 1]. Assume without loss of generality that the x i 's are distinct. <p> We begin with F 1 . We will make use of the following simple lemma, whose proof is omitted. It establishes the fact that functions in F 1 satisfy a Lipschitz condition. Lemma 15 If f 2 F 1 , then for all x; y 2 <ref> [0; 1] </ref>, we have jf (x) f (y)j jx yj: A bound on opt 1+* (F 1 ) follows immediately from the previous two lemmas. Recall that opt 2 (F 1 ) = 1, and therefore opt p (F 1 ) = 1 for all p 2. <p> Choose a sequence x 1 ; :::; x m of elements of <ref> [0; 1] </ref> and f 2 F 1 . Let ^y 2 ; :::; ^y m be the predictions of this "nearest neighbor" algorithm on trials 2 through m, and let p = 1 + *. <p> Theorem 17 If * &gt; 0, opt 1+* (F 2 ) 2 + 2 1+* 2 1 : Proof: Choose * &gt; 0 and let p = 1 + *. Choose a sequence x 1 ; :::; x m of elements of <ref> [0; 1] </ref> and f 2 F 1 . <p> We also show that the "linear interpolation" algorithm studied in Section 3 achieves the same bound on its cumulative (unsquared) error on any sequence of m trials consistent with a function in F 2 . For a class F of functions from <ref> [0; 1] </ref> to R, define opt 1 (F; m) = inf sup L 1 (A; f; ) where A ranges over learning algorithms. Both proofs make use of the following inequality, which follows immediately by the standard convexity argument.
Reference: [2] <author> N. Cesa-Bianchi, </author> <title> P.M. Long, and M.K. Warmuth. Worst-case quadratic loss bounds for prediction using linear functions and gradient descent. </title> <type> Technical Report ucsc-crl-93-36, </type> <institution> UC Santa Cruz, </institution> <year> 1993. </year> <note> A preliminary version of this report appeared in the 1993 Workshop on Computational Learning Theory. </note>
Reference-contexts: The difference in complexity of the algorithms is illustrated by the fact that the tth prediction of the linear interpolation algorithm trivially can be made in O (log t) time, whereas the best known bound on the time required for the algorithm of [3] is O (t) <ref> [2] </ref>. In recent work pursued subsequently to this research, Cesa-Bianchi, Long and Warmuth [2] generalized the results of Faber and Mycielski to show that a modification of the algorithm of [3] was optimal in the model of their paper, in which a smooth function only approximately maps x t 's to <p> the fact that the tth prediction of the linear interpolation algorithm trivially can be made in O (log t) time, whereas the best known bound on the time required for the algorithm of [3] is O (t) <ref> [2] </ref>. In recent work pursued subsequently to this research, Cesa-Bianchi, Long and Warmuth [2] generalized the results of Faber and Mycielski to show that a modification of the algorithm of [3] was optimal in the model of their paper, in which a smooth function only approximately maps x t 's to y t 's.
Reference: [3] <author> V. Faber and J. Mycielski. </author> <title> Applications of learning theorems. </title> <journal> Fundamenta Informaticae, </journal> <volume> 15(2) </volume> <pages> 145-167, </pages> <year> 1991. </year>
Reference-contexts: in their present form to facilitate presentation of lower bounds, as well as to cut down on unnecessary notation, as we feel that the essence of the problems is captured in the simple cases. 2 On the very first trial, it predicts arbitrarily, say with 0. 2 Faber and Mycielski <ref> [3] </ref> proved, using a different algorithm, that opt 2 (F 2 ) 1. <p> The difference in complexity of the algorithms is illustrated by the fact that the tth prediction of the linear interpolation algorithm trivially can be made in O (log t) time, whereas the best known bound on the time required for the algorithm of <ref> [3] </ref> is O (t) [2]. In recent work pursued subsequently to this research, Cesa-Bianchi, Long and Warmuth [2] generalized the results of Faber and Mycielski to show that a modification of the algorithm of [3] was optimal in the model of their paper, in which a smooth function only approximately maps <p> (log t) time, whereas the best known bound on the time required for the algorithm of <ref> [3] </ref> is O (t) [2]. In recent work pursued subsequently to this research, Cesa-Bianchi, Long and Warmuth [2] generalized the results of Faber and Mycielski to show that a modification of the algorithm of [3] was optimal in the model of their paper, in which a smooth function only approximately maps x t 's to y t 's. Many statisticians, and, more recently, computational learning theorists (see e.g., [4] [1] [5]) have studied the induction of classes of functions obtained through smoothness constraints. <p> action 0, and since, by Lemma 9, the action of LININT's hypothesis is always at most that of the target function, which in turn is at most 1, we may conclude that P We may apply this result to obtain an alternative proof of a result of Faber and Mycielski <ref> [3] </ref>, who analyzed another, more complicated, algorithm for their upper bounds. Theorem 12 ([3]) opt 2 (F 2 ) = 1: Proof: The previous theorem implies that opt 2 (F 2 ) 1.
Reference: [4] <author> W. Hardle. </author> <title> Smoothing Techniques. </title> <publisher> Springer Verlag, </publisher> <year> 1991. </year>
Reference-contexts: Many statisticians, and, more recently, computational learning theorists (see e.g., <ref> [4] </ref> [1] [5]) have studied the induction of classes of functions obtained through smoothness constraints. The spirit of their work differs from ours in several ways. First, their theorems usually concern functions of potentially many real variables, where ours, at present, apply only to functions of a single real variable.
Reference: [5] <author> D. Haussler. </author> <title> Generalizing the PAC model: sample size bounds from metric dimension-based uniform convergence results. </title> <booktitle> Proceedings of the 30th Annual Symposium on the Foundations of Computer Science, </booktitle> <year> 1989. </year>
Reference-contexts: Many statisticians, and, more recently, computational learning theorists (see e.g., [4] [1] <ref> [5] </ref>) have studied the induction of classes of functions obtained through smoothness constraints. The spirit of their work differs from ours in several ways. First, their theorems usually concern functions of potentially many real variables, where ours, at present, apply only to functions of a single real variable.
Reference: [6] <author> S. Kaczmarz. </author> <title> Angenaherte Auflosung von systemen linearer gleichungen. </title> <journal> Bull. Acad. Polon. Sci. Lett. A, </journal> <volume> 35 </volume> <pages> 355-357, </pages> <year> 1937. </year>
Reference-contexts: This result amounts to a special case of a beautiful theorem about learning linear functionals defined on Hilbert spaces using a generalization of the Widrow-Hoff algorithm <ref> [6, 12] </ref>, and their paper contains numerous other applications of their Hilbert space results. Nevertheless, we feel it is interesting that even the very simple linear interpolation algorithm is optimal for F 2 with respect to worst-case on-line sums of squared errors.
Reference: [7] <author> G. Leitmann. </author> <title> The Calculus of Variations and Optimal Control. </title> <publisher> Plenum Press, </publisher> <year> 1981. </year>
Reference-contexts: The following lemma concerning the function of minimum action subject to certain constraints is well known, and can be proved fairly easily, for instance, through application of an elementary result from the Calculus of Variations (see <ref> [7, Theorem 2.2] </ref> 3 ). Lemma 9 Choose m 2 N. Let (u 1 ; v 1 ); :::; (u m ; v m ) be a sample. Let S = f (u i ; v i ) : 1 i mg.
Reference: [8] <author> N. Littlestone. </author> <title> Mistake Bounds and Logarithmic Linear-threshold Learning Algorithms. </title> <type> PhD thesis, </type> <institution> UC Santa Cruz, </institution> <year> 1989. </year>
Reference-contexts: Extending the terminology of <ref> [8] </ref>, we define opt p (F) = inf L p (A; F ): 1 Note that we begin summing the algorithm's errors on the second trial. This is not unreasonable, since the algorithm's performance on the first trial is not indicative of learning ability anyway. <p> These assumptions have enabled researchers to prove bounds on the expected "loss" on a particular trial. In worst-case models such as that considered here, such "instantaneous" bounds are clearly impossible (see <ref> [8] </ref>).
Reference: [9] <author> N. Littlestone, </author> <title> P.M. Long, and M.K. Warmuth. On-line learning of linear functions. </title> <booktitle> Proceedings of the 23rd ACM Symposium on the Theory of Computation, </booktitle> <pages> pages 465-475, </pages> <year> 1991. </year>
Reference-contexts: The following lemmas may be easily verified, e.g., by using reductions between real-valued learning problems <ref> [9] </ref> to scale, translate and reflect appropriately. Lemma 1 For any a; c &gt; 0; opt 1 (G ca;0 ) = c opt 1 (G a;0 ). Lemma 2 Choose a; b; c; d 2 R.
Reference: [10] <author> N. Littlestone and M.K. Warmuth. </author> <title> The weighted majority algorithm. </title> <booktitle> Proceedings of the 30th Annual Symposium on the Foundations of Computer Science, </booktitle> <year> 1989. </year> <month> 11 </month>
Reference-contexts: 1 Introduction We consider the learning of real-valued functions of a single [0; 1]-valued variable in a model introduced by Mycielski [11], and independently by Littlestone and Warmuth <ref> [10] </ref>. A learning problem consists of a class F of such functions.
Reference: [11] <author> J. Mycielski. </author> <title> A learning algorithm for linear operators. </title> <journal> Proceedings of the American Mathematical Society, </journal> <volume> 103(2) </volume> <pages> 547-550, </pages> <year> 1988. </year>
Reference-contexts: 1 Introduction We consider the learning of real-valued functions of a single [0; 1]-valued variable in a model introduced by Mycielski <ref> [11] </ref>, and independently by Littlestone and Warmuth [10]. A learning problem consists of a class F of such functions.
Reference: [12] <author> B. Widrow and M.E. Hoff. </author> <title> Adaptive switching circuits. </title> <booktitle> 1960 IRE WESCON Conv. Record, </booktitle> <pages> pages 96-104, </pages> <year> 1960. </year>
Reference-contexts: This result amounts to a special case of a beautiful theorem about learning linear functionals defined on Hilbert spaces using a generalization of the Widrow-Hoff algorithm <ref> [6, 12] </ref>, and their paper contains numerous other applications of their Hilbert space results. Nevertheless, we feel it is interesting that even the very simple linear interpolation algorithm is optimal for F 2 with respect to worst-case on-line sums of squared errors.
References-found: 12

