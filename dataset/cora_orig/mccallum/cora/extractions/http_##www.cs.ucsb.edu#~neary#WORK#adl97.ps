URL: http://www.cs.ucsb.edu/~neary/WORK/adl97.ps
Refering-URL: http://www.cs.ucsb.edu/~neary/WORK/dir.html
Root-URL: http://www.cs.ucsb.edu
Title: Scalable Access within the Context of Digital Libraries  
Author: X. Cheng R. Dolin M. Neary S. Prabhakar K. V. Ravi Kanth D. Wu D. Agrawal A. El Abbadi M. Freeston A. Singh T. Smith J. Su 
Address: Library Project  Santa Barbara, CA 93106  
Affiliation: Alexandria Digital  Department of Computer Science University of California  
Abstract: This paper presents a summary of some of the work-in-progress within the Alexandria Digital Library Project. In particular, we present scalable methods of locating information at different levels within a distributed digital library environment. Starting at the high level, we show how queries can be routed to appropriate information sources. At a given source, efficient query processing is supported by using materialized views and multidimensional index structures. Finally, we propose solutions to the problem of storage and retrieval of large objects on secondary and tertiary storage. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Andresen, L. Carver, R. Dolin, C. Fischer, J. Frew, M. Goodchild, O. Ibarra, R. B. Kemp, R. Kothuri, M. Larsgaard, B. S. Manjunath, D. Nebert, J. Simpson, T. R. Smith, A. Wells, T. Yang, and Q. Zheng. </author> <title> The WWW Prototype of the Alexandria Digital Library. </title> <booktitle> In Proceedings of the International Symposium on Digital Libraries, </booktitle> <address> Tsukuba, Japan, </address> <year> 1995. </year> <note> Also appeared in IEEE Computer, </note> <month> 29(5): </month> <pages> 54-60, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: In this paper, we identify three primary scalability issues related to providing information access within the context of a digital library, and show how the Alexandria Digital Library (ADL) Project <ref> [1] </ref> ad fl This research was partially supported by NSF/NASA /DARPA under grant number IRI94-11330. dresses them. First, the data itself is distributed on a scale that was not possible earlier.
Reference: [2] <author> N. Beckmann, H. Kriegel, R. Schneider, and B. Seeger. </author> <title> The R* tree: An efficient and robust access method for points and rectangles. </title> <booktitle> Proc. of the ACM SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 322-331, </pages> <month> May 23-25 </month> <year> 1990. </year>
Reference-contexts: To illustrate this situation, consider the following example. Figure 5 shows a set of 2-dimensional data objects and an R fl tree <ref> [2] </ref> indexing these data objects. The dashed box in the figure represents an arbitrary range query. Note that no data objects are contained in the query box and hence the query result is empty. <p> This ensures that most queries can be processed in parallel. Using these ideas, we parallelized two index structures the R fl tree <ref> [2] </ref> and the LIB structure [21]. We chose the R fl tree because it is a versatile multidimensional index that caters to arbitrary data. We selected the LIB structure because it maintains multiple index components that can be searched in parallel. <p> With this development, we are carrying out a new comparative performance study, specifically against R fl trees <ref> [2] </ref> and Oracle's SDO. In addition, we are incorporating a new technique to improve the performance of conventional index structures for different types of queries on spatial data. <p> For a small number of images, a sequential browsing of images using their feature vectors may suffice. However, for large image databases such as in ADL, the problem of efficient browsing and retrieval of images has to be addressed. Multidimensional search structures like the R fl tree <ref> [2] </ref> do not scale with the dimensionality of data [9] and hence are not directly helpful. Our approach to solving this problem [25] is to first reduce the dimensionality of the image data and then use multidimensional index structures to support efficient retrieval.
Reference: [3] <author> C.M. Bowman, P.B. Danzig, D.R. Hardy, U. Manber, et al. </author> <title> The harvest information discovery and access system. </title> <booktitle> In Proceedings of the Second International World-Wide Web Conference, </booktitle> <pages> pages 763-771, </pages> <address> Chicago, Illinois, </address> <month> October </month> <year> 1994. </year> <note> http://harvest.cs.colorado.edu/. </note>
Reference-contexts: The mid-level servers in Pharos are responsible for keeping their metadata up-to-date. This approach minimizes network traffic and guarantees that the mid-level servers are ready to receive the metadata before it is sent. Harvest <ref> [3] </ref> provides a suitable transport mechanism for distributing and storing mid-level metadata in Pharos [7].
Reference: [4] <author> P. Brodatz. </author> <title> Textures: A Photographic Album for Artists & Designers. </title> <publisher> Dover, </publisher> <address> New York, New York, </address> <year> 1966. </year>
Reference-contexts: To compare whether truncated SVD components or DFT coefficients provide better retrieval performance, we simulate a series of queries on a collection of tex tures from the Brodatz album <ref> [4] </ref>. This collection has 1856 feature vectors, each representing an image. Every vector is processed at the time of insertion into the database with SVD or DFT.
Reference: [5] <author> K. R. Castleman. </author> <title> Digital Image Processing. </title> <publisher> Prentice-Hall, Inc., </publisher> <year> 1996. </year>
Reference-contexts: It is therefore important to provide the ability to browse items and view them at multiple levels of detail or resolution. For the purposes of ADL, which is designed to handle mostly image data, the technique of wavelet decomposition <ref> [5] </ref> has been proposed for generating mul-tiresolution images. Using this technique, an image is decomposed into a low resolution copy or icon and several coefficients. The icon is the lowest resolution copy available. Higher resolution copies can be progressively reconstructed from the icon and other coefficients.
Reference: [6] <author> X. Cheng and J. Su. </author> <title> Materialized views as a technique to improve database performance. </title> <type> Manuscript, </type> <year> 1996. </year>
Reference-contexts: We have developed a general approach based on these steps for relational databases <ref> [6] </ref>. Briefly, we first analyze frequent user queries and identify query patterns in them. We then select materialized views based on the frequencies and complexity of query patterns.
Reference: [7] <author> R. Dolin, D. Agrawal, L. Dillon, and A. El Abbadi. Pharos: </author> <title> A scalable distributed architecture for locating heterogeneous information sources. </title> <type> Technical Report TRCS96-05, </type> <institution> Computer Science Department, University of California, Santa Barbara, </institution> <year> 1996. </year> <note> http://www.cs.ucsb.edu /TRs/TRCS96-05.html. </note>
Reference-contexts: The mid-level servers in Pharos are responsible for keeping their metadata up-to-date. This approach minimizes network traffic and guarantees that the mid-level servers are ready to receive the metadata before it is sent. Harvest [3] provides a suitable transport mechanism for distributing and storing mid-level metadata in Pharos <ref> [7] </ref>. We have performed a set of simulation experiments of Pharos which indicate that a sufficient number of good sources could be located with the Pharos architecture so that the majority of relevant documents could be retrieved [7]. 3 Materialized Views and Database Performance In the previous section, we presented an <p> provides a suitable transport mechanism for distributing and storing mid-level metadata in Pharos <ref> [7] </ref>. We have performed a set of simulation experiments of Pharos which indicate that a sufficient number of good sources could be located with the Pharos architecture so that the majority of relevant documents could be retrieved [7]. 3 Materialized Views and Database Performance In the previous section, we presented an overall framework and specific techniques for locating infor mation sources. In this section, we focus on organizing and searching data collections efficiently within an individual site (source).
Reference: [8] <author> R. Dolin, D. Agrawal, and A. El Abbadi. </author> <title> Classifying network architectures for locating information sources. </title> <booktitle> In DASFAA, </booktitle> <address> Melbourne, Australia, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: Prior to digital networks, the number of potential information sources was relatively limited, mainly by locality; a user could discover what was available by browsing individual sources. On the Internet, information resides in numerous heterogeneous systems; each such distributed system may provide many information sources. 2.1 Network Models In <ref> [8] </ref>, we consider three general classes of network models that encompass the discovery and querying of information sources. The first class of models uses no intermediate servers; the only communication is directly between query generators and information sources. <p> These servers supply more detailed information about this filtered list of sources, thus further reducing the number of potentially relevant sources (say from ~10 3 to ~ 10 1 ). These sources are then queried directly. Pharos is presented in more detail below. The analysis of these models in <ref> [8] </ref> indicates that Pharos scales well by comparison. The BF Model requires that all intermediate servers pull over the actual documents of all sources, causing problems as the number of sources and documents per source increase.
Reference: [9] <author> C. Faloutsos, M. Ranganathan, and Y. Manolopoulos. </author> <title> Fast subsequence matching in time-series databases. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 419-429, </pages> <address> Minneapolis, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: First, we explore the impact of parallelism on query processing in multidimensional index structures. Next, we devise new indexing strategies to improve the performance of queries on low dimensional data. Finally, for high dimensional data we note that the query overheads increase with the dimensionality of the data <ref> [9] </ref>. Hence we examine several techniques to reduce the dimensionality of such data. 4.1 Parallelism in Indexing Parallelism can take advantage of the need for searching multiple portions in a multidimensional index for range and intersection queries. To illustrate this situation, consider the following example. <p> However, for large image databases such as in ADL, the problem of efficient browsing and retrieval of images has to be addressed. Multidimensional search structures like the R fl tree [2] do not scale with the dimensionality of data <ref> [9] </ref> and hence are not directly helpful. Our approach to solving this problem [25] is to first reduce the dimensionality of the image data and then use multidimensional index structures to support efficient retrieval. <p> To reduce the dimensionality of the feature vector data, we consider two different techniques based on the Discrete Fourier Transform (DFT) and the Singular Value Decomposition (SVD) in [25]. These techniques have been used to reduce the dimensionality of information in several other projects <ref> [9] </ref>. Both these methods have their relative merits and demerits. SVD is computationally expensive, requiring O (mn 2 ) time to process m n-dimensional feature vectors. By using Fast Fourier Transform techniques, the DFT can be calculated in O (mn log n) time. <p> In SVD processing, truncation is performed by picking the first few components (which SVD ensures to be the largest singular values). For the DFT, we can truncate by retaining the first few Fourier coefficients as shown in <ref> [9] </ref>. This approach works well when the data is very smooth and dominated by low-order coefficients, however as our experiments on texture image data indicates, better results can be obtained by taking the first few dominant Fourier coefficients [25].
Reference: [10] <author> M. W. Freeston. </author> <title> The bang file: a new kind of grid file. </title> <booktitle> Proc. of the ACM SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 260-269, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: We evaluated the performance of the parallelized structures on the Gazetteer and Catalog data of the Alexandria Digital Library. In our experiments, both structures registered a speed-up of 3 on 5 processors. Besides, our parallelizing techniques can also be applied to other index structures like BANG files <ref> [10] </ref> and BV-trees [11] to improve their query performance. 4.2 Indexing Low Dimensionality Data In this subsection, we examine different ways of structuring multidimensional data to support efficient location of data using different types of queries. <p> As part of this study, we are developing a new, generalized implementation of BANG indexing <ref> [10] </ref>. BANG indexing was originally developed as a first step in a research effort to overcome the problem of indexing rules in large-scale deductive database systems. Over the years, it evolved into an efficient multidimensional index [11] with broad applicability to different types of data. <p> In its current form, BANG indexing combines the indexing of points (n-tuples) and spatial objects (n-dimensional bounding boxes) through a dual recursive partitioning of an n-dimensional space. In the original implementation <ref> [10] </ref>, which was restricted to point indexing, this partitioning was represented by a balanced, multiply-branched index tree structure similar to a B-tree.
Reference: [11] <author> M. W. Freeston. </author> <title> A general solution of the n-dimensional b-tree problem. </title> <booktitle> Proc. of the ACM SIGMOD Intl. Conf. on Management of Data, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: In our experiments, both structures registered a speed-up of 3 on 5 processors. Besides, our parallelizing techniques can also be applied to other index structures like BANG files [10] and BV-trees <ref> [11] </ref> to improve their query performance. 4.2 Indexing Low Dimensionality Data In this subsection, we examine different ways of structuring multidimensional data to support efficient location of data using different types of queries. As part of this study, we are developing a new, generalized implementation of BANG indexing [10]. <p> BANG indexing was originally developed as a first step in a research effort to overcome the problem of indexing rules in large-scale deductive database systems. Over the years, it evolved into an efficient multidimensional index <ref> [11] </ref> with broad applicability to different types of data. In its current form, BANG indexing combines the indexing of points (n-tuples) and spatial objects (n-dimensional bounding boxes) through a dual recursive partitioning of an n-dimensional space. <p> However, such performance could not be guaranteed, and pathological cases could be devised which would give much worse and uncontrolled performance. The new version preserves all the principles of BANG indexing, but is implemented as a BV-tree <ref> [11] </ref>. The properties of this structure make it possible to guarantee logarithmic single-entry access and update, and a minimum 33% index and data node occupancy, for both point and spatial object indexing.
Reference: [12] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability A guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Co., </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Therefore, any efficient scheduling policy for a single medium may be used. For multiple drives, the problem of finding an optimal solution is shown to be NP-Complete by a simple reduction from the Minimum Weighted Completion Time <ref> [12] </ref>. In the absence of an efficient optimal solution, we have shown that the policy that achieves optimal solutions for the single drive case, OP T , is an effective heuristic for the multiple drive case also.
Reference: [13] <author> L. Gravano, K. Chang, H. Garca-Molina, and A. Paepcke. </author> <title> STARTS: Stanford Protocol Proposal for Internet Retrieval and Search. </title> <address> http://www-db.stanford.edu/~gravano /starts.html, </address> <year> 1996. </year>
Reference-contexts: Lycos, AltaVista, etc.). In this model an intermediary extracts metadata by gathering all documents available at all sources. Queries are sent to the intermediary, which returns a result set to the query generator; queries are not propagated to the sources. A more sophisticated approach is the STARTS Model <ref> [13] </ref>, built on a gGlOSS [14] framework. Here, each source extracts its own metadata; the intermediary then gathers this metadata rather than extracting its own. When an intermediary receives a query, it analyzes its pre-collected metadata and chooses a set of relevant sources.
Reference: [14] <author> L. Gravano and H. Garca-Molina. </author> <title> Generalizing GlOSS to vector-space databases and broker hierarchies. </title> <booktitle> In Proceedings of the 21st VLDB Conference, </booktitle> <address> Zurich, Switzerland, </address> <year> 1995. </year>
Reference-contexts: Queries are sent to the intermediary, which returns a result set to the query generator; queries are not propagated to the sources. A more sophisticated approach is the STARTS Model [13], built on a gGlOSS <ref> [14] </ref> framework. Here, each source extracts its own metadata; the intermediary then gathers this metadata rather than extracting its own. When an intermediary receives a query, it analyzes its pre-collected metadata and chooses a set of relevant sources.
Reference: [15] <author> I. Kamel and C. Faloutsos. </author> <title> Parallel R-trees. </title> <booktitle> Proc. of the ACM SIGMOD Intl. Conf. on Management of Data, </booktitle> <pages> pages 195-204, </pages> <year> 1992. </year>
Reference-contexts: Using the techniques proposed in [22], we partition the R fl tree into two components, each assigned to a separate processor. These techniques estimate the proximity (likelihood of being retrieved in the same query) of every pair of nodes and assign nodes with high proximity to different processors <ref> [15] </ref>. This ensures that most queries can be processed in parallel. Using these ideas, we parallelized two index structures the R fl tree [2] and the LIB structure [21]. We chose the R fl tree because it is a versatile multidimensional index that caters to arbitrary data.
Reference: [16] <author> Alon Y. Levy, Alberto O. Mendelzon, Yehoshua Sagiv, and Divesh Srivastava. </author> <title> Answering queries using views. </title> <booktitle> In Proceedings of the Fourteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, </booktitle> <pages> pages 95-104, </pages> <year> 1995. </year>
Reference-contexts: Note that when we generalize the problem to include D and V as a part of the input <ref> [16] </ref>, the new problem is exactly the minimum cover problem which is known to be NP-complete. In our case the query Q is the only input to deal with, which permits an efficient solution to our problem.
Reference: [17] <institution> Library of Congress, </institution> <address> Washington, D.C. LC Classification Outline, fifth edition, </address> <year> 1986. </year>
Reference-contexts: In order to describe the collection at a source, we quantify the number of documents with content relevant to each part of an information hierarchy. For example, the subject hierarchy is modeled after the Library of Congress's LC Classification system <ref> [17] </ref>, which has a fixed list of categories. Similarly, a simplistic geographical information hierarchy can be formed by tiling the Earth's surface into progressively smaller, hierarchical, longitude/latitude squares. An information taxonomy is defined as a static hierarchy within which documents can be classified, usually according to their content.
Reference: [18] <author> S. Prabhakar, D. Agrawal, A. El Abbadi, and A. Singh. </author> <title> Efficient I/O scheduling in tertiary libraries. </title> <type> Technical Report TRCS96-26, </type> <institution> Dept. of Computer Science, Univ. of Calilfornia, Santa Barbara, </institution> <year> 1996. </year>
Reference-contexts: Further details about tertiary storage technology and recent work on current issues in tertiary storage can be found in [19]. In contrast to other studies, we have explored the problem of scheduling requests for more than one medium <ref> [18] </ref>. Due to the great difference in speeds between the processors and tertiary storage, we expect that request traffic will be bursty. Consequently, we have studied the problem of scheduling bursty I/O requests.
Reference: [19] <author> S. Prabhakar, D. Agrawal, A. El Abbadi, and A. Singh. </author> <title> Tertiary storage: Current status and future trends. </title> <type> Technical Report TRCS96-21, </type> <institution> Dept. of Computer Science, Univ. of Calilfornia, Santa Barbara, </institution> <year> 1996. </year>
Reference-contexts: It can take up to a few minutes to seek to the desired location on a tape. Further details about tertiary storage technology and recent work on current issues in tertiary storage can be found in <ref> [19] </ref>. In contrast to other studies, we have explored the problem of scheduling requests for more than one medium [18]. Due to the great difference in speeds between the processors and tertiary storage, we expect that request traffic will be bursty.
Reference: [20] <author> S. Prabhakar, D. Agrawal, A. El Abbadi, A. Singh, and T. R. Smith. </author> <title> Browsing and placement of multiresolution images on secondary storage. </title> <type> Technical Report TRCS96-22, </type> <institution> Dept. of Computer Science, Univ. of California, Santa Barbara, </institution> <year> 1996. </year>
Reference-contexts: Higher resolution copies can be progressively reconstructed from the icon and other coefficients. The original image can be reconstructed from the icon and all the coefficients. In order to improve the I/O performance of browsing, we have investigated efficient placement techniques on magnetic disks <ref> [20] </ref>. The latency of disk access is reduced by fetching data in parallel from multiple disks. The study focuses on browsing access patterns when images are retrieved by similarity matching, where similarity is based on the content of the images. Two orthogonal declustering schemes have been evaluated.
Reference: [21] <author> K. V. Ravi Kanth, D. Agrawal, A. El Abbadi, and A. Singh. </author> <title> Indexing non-uniform spatial data. </title> <type> Manuscript, </type> <year> 1996. </year>
Reference-contexts: This ensures that most queries can be processed in parallel. Using these ideas, we parallelized two index structures the R fl tree [2] and the LIB structure <ref> [21] </ref>. We chose the R fl tree because it is a versatile multidimensional index that caters to arbitrary data. We selected the LIB structure because it maintains multiple index components that can be searched in parallel. <p> Indexing such dead space implies accessing irrelevant parts of the tree that may not contribute to the result of the query in any way. To reduce the effect of these two anomalies in current index structures, we proposed a promotion strategy in <ref> [21] </ref>. This is explained using the following example. Consider the non-uniform data of Figure 7. The data object A contains data object B and overlaps with data objects C; D and E as shown in Figure 7 (a). <p> This index organization solves both the problems of non-uniformity - (1) it reduces the overlaps in index entries, and (2) it reduces the dead space that is indexed (region k is excluded). Based on this simple idea, we devised different criteria for data object promotion <ref> [21] </ref>.
Reference: [22] <author> K. V. Ravi Kanth, D. Agrawal, A. El Abbadi, A. Singh, and T. R. Smith. </author> <title> Parallelizing multidimensional index structures. </title> <booktitle> IEEE Symposium on Parallel and Distributed Processing, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: Consequently, all the nodes of the tree are searched despite an empty query result. In this context, let us illustrate how parallelism can help. Using the techniques proposed in <ref> [22] </ref>, we partition the R fl tree into two components, each assigned to a separate processor. These techniques estimate the proximity (likelihood of being retrieved in the same query) of every pair of nodes and assign nodes with high proximity to different processors [15].
Reference: [23] <author> K. V. Ravi Kanth and A. Singh. </author> <title> Complexity of multidimensional range queries. </title> <type> Manuscript, </type> <year> 1996. </year>
Reference-contexts: Common queries on such data are "retrieve all data items contained or intersecting a user-specified query box" (range/intersection queries) and "retrieve data items that have specific attributes" (exact match query). Image objects are characterized by high-dimensional feature vectors and queries retrieve images similar to user-specified patterns (similarity queries). In <ref> [23] </ref>, we show that the time complexity of range queries on n d-dimensional objects (d &gt; 1) using simple tree structures is O (n 11=d ). In contrast, for 1-dimensional data, range queries can be answered in logarithmic time.
Reference: [24] <author> G. Salton. </author> <title> Automatic Text Processing. </title> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: In our experiments, we measured the quality of the two transformations by evaluating the recall and precision <ref> [24] </ref> for different types of queries on the reduced-dimension data. Suppose a user issues a similarity query and retrieves m images from the database. The number of relevant images stored in the database is n; of these only k are returned from the query.
Reference: [25] <author> D. Wu, D. Agrawal, , A. El Abbadi, A. Singh, and T. R. Smith. </author> <title> Efficient retrieval for browsing large image databases. </title> <booktitle> Proc. Conf. on Information and Knowledge Management, </booktitle> <pages> pages 11-18, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: Multidimensional search structures like the R fl tree [2] do not scale with the dimensionality of data [9] and hence are not directly helpful. Our approach to solving this problem <ref> [25] </ref> is to first reduce the dimensionality of the image data and then use multidimensional index structures to support efficient retrieval. To reduce the dimensionality of the feature vector data, we consider two different techniques based on the Discrete Fourier Transform (DFT) and the Singular Value Decomposition (SVD) in [25]. <p> problem <ref> [25] </ref> is to first reduce the dimensionality of the image data and then use multidimensional index structures to support efficient retrieval. To reduce the dimensionality of the feature vector data, we consider two different techniques based on the Discrete Fourier Transform (DFT) and the Singular Value Decomposition (SVD) in [25]. These techniques have been used to reduce the dimensionality of information in several other projects [9]. Both these methods have their relative merits and demerits. SVD is computationally expensive, requiring O (mn 2 ) time to process m n-dimensional feature vectors. <p> This approach works well when the data is very smooth and dominated by low-order coefficients, however as our experiments on texture image data indicates, better results can be obtained by taking the first few dominant Fourier coefficients <ref> [25] </ref>. In our experiments, we measured the quality of the two transformations by evaluating the recall and precision [24] for different types of queries on the reduced-dimension data. Suppose a user issues a similarity query and retrieves m images from the database. <p> Using the feature vector for I, the range query retrieves all other images lying in a neighborhood of radius R about I. Alternatively, a nearest-neighbor query retrieves the M images closest to the reference image I. As explained in <ref> [25] </ref>, range queries provide 100% recall, while in nearest-neighbor queries recall and precision are the same. In our experiments, we performed range and nearest-neighbor queries on each feature vector in the database, for varying values for radius R and number of nearest-neighbors M on the truncated feature space.
References-found: 25

