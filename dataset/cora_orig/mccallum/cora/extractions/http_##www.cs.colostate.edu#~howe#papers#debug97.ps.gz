URL: http://www.cs.colostate.edu/~howe/papers/debug97.ps.gz
Refering-URL: http://www.cs.colostate.edu/~howe/pubs.html
Root-URL: 
Email: email: fhowe,somlog@cs.colostate.edu  
Title: Modeling Intelligent System Execution as State Transition Diagrams to Support Debugging  
Author: Adele E. Howe Gabriel Somlo 
Web: URL: http://www.cs.colostate.edu/~fhowe,somlog  
Address: Fort Collins, CO 80523  
Affiliation: Computer Science Department Colorado State University  
Abstract: Currently, few tools are available for assisting developers with debugging intelligent systems. Because these systems rely heavily on context dependent knowledge and sometimes stochastic decision making, replicating problematic performance may be difficult. Consequently, we adopt a statistical approach to modeling behavior as the basis for identifying potential causes of failure. This paper describes an algorithm for constructing state transition models of system behavior from execution traces. The algorithm is the latest in a family of statistics based algorithms for modelling system execution called Dependency Detection. We present preliminary accuracy results for the algorithm on synthetically generated data and an example of its use in debugging a neural network controller for a race car simulator.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Marc Abrams, Alan Batongbacal, Randy Ribler, and Devendra Vazirani. CHI-TRA94: </author> <title> A tool to dynamically characterize ensembles of traces for input data modeling and output analysis. </title> <institution> Computer Science Dept. 94-21, Virginia Poly-technical Institute, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: The CHAID-based analysis is part of the Chitra family of systems (Chitra 92-96), which were developed to support the modeling and visualization of execution data from parallel and distributed systems <ref> [1] </ref>. The probability threshold is the primary mechanism for adjusting the ocmplex-ity of the model. Lower probabilities result in less complex models because fewer transitions are recognized as significant. One option for determining how to set the probability threshold is to model its effect.
Reference: [2] <author> Horacio T. Cadiz. </author> <title> The development of a CHAID-based model for CHITRA93. </title> <institution> Computer Science dept., Virginia Polytechnic Institute, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: We are currently exploring principled methods of setting these. One option is to use CHAID based analysis to determine dependency length. CHAID constructs an n-step transition matrix, which indicates what earlier point in the execution traces was most predictive of the occurrence of each type of events <ref> [2] </ref>. The CHAID-based analysis is part of the Chitra family of systems (Chitra 92-96), which were developed to support the modeling and visualization of execution data from parallel and distributed systems [1]. The probability threshold is the primary mechanism for adjusting the ocmplex-ity of the model.
Reference: [3] <author> S. Chien, H. Mortensen, C. Ying, and S. Hsiao. </author> <title> Integrated planning for automated image processing. </title> <booktitle> In Working Notes of the AAAI Spring Symposium on Integrated Planning Applications, </booktitle> <month> March </month> <year> 1995. </year>
Reference-contexts: Plan debugging has been a topic of some interest as a method for plan construction (e.g., [6, 15]), but planner and system debugging has received less attention. Chien at JPL has developed two methods for analyzing a planner's knowledge base: static and completion analysis <ref> [3, 4] </ref>; these methods identify certain classes of syntactic errors and gaps in knowledge that prevent complete plans from being generated. Some planning systems include a mechanism for incrementally fl This research was supported in part by by NSF Career Award IRI-9624058 and by DARPA-AFOSR contract F30602-93-C-0100 and F30602-95-0257.
Reference: [4] <author> Steve A. Chien. </author> <title> Static and completion analysis for planning knowledge base development and verificiation. </title> <booktitle> In Proceedings of the Third International Conference on Artificial Intelligence Planning Systems (AIPS96), </booktitle> <pages> pages 53-61, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Plan debugging has been a topic of some interest as a method for plan construction (e.g., [6, 15]), but planner and system debugging has received less attention. Chien at JPL has developed two methods for analyzing a planner's knowledge base: static and completion analysis <ref> [3, 4] </ref>; these methods identify certain classes of syntactic errors and gaps in knowledge that prevent complete plans from being generated. Some planning systems include a mechanism for incrementally fl This research was supported in part by by NSF Career Award IRI-9624058 and by DARPA-AFOSR contract F30602-93-C-0100 and F30602-95-0257.
Reference: [5] <author> David Christianson and Chung Kwok. </author> <title> PDB Reference Manual. </title> <institution> University of Washington, </institution> <address> 4.0 edition. </address>
Reference: [6] <author> Kristian J. Hammond. </author> <title> Explaining and repairing plans that fail. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 109-114, </pages> <address> Milan, Italy, </address> <year> 1987. </year>
Reference-contexts: Plan debugging has been a topic of some interest as a method for plan construction (e.g., <ref> [6, 15] </ref>), but planner and system debugging has received less attention. Chien at JPL has developed two methods for analyzing a planner's knowledge base: static and completion analysis [3, 4]; these methods identify certain classes of syntactic errors and gaps in knowledge that prevent complete plans from being generated.
Reference: [7] <author> Adele E. Howe. </author> <title> Improving the reliability of AI planning systems by analyzing their failure recovery. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 7(1) </volume> <pages> 14-25, </pages> <year> 1995. </year>
Reference-contexts: Both of these approaches emphasize the plan generation phase, assuming that execution should proceed as planned. Execution was the focus of Failure Recovery Analysis (FRA) <ref> [7, 11] </ref>. FRA is a methodology for debugging some canonical bug types in the Phoenix planner by statistically analyzing traces of failure recovery.
Reference: [8] <author> Adele E. Howe, </author> <title> editor. </title> <booktitle> Working Notes of the AAAI Spring Symposium on Integrated Planning Systems, </booktitle> <address> Palo Alto, CA, March 1995. </address> <publisher> AAAI. </publisher>
Reference-contexts: At a symposium on Integrated Planning Applications, developers agreed that the primary barriers to successful deployment were user acceptance (i.e., ensuring that the system does what the users need) and acquiring and debugging domain knowledge <ref> [8] </ref>. Plan debugging has been a topic of some interest as a method for plan construction (e.g., [6, 15]), but planner and system debugging has received less attention.
Reference: [9] <author> Adele E. Howe. </author> <title> Detecting imperfect patterns in event streams using local search. </title> <editor> In D. Fisher and H. Lenz, editors, </editor> <booktitle> Learning from Data: Artificial Intelligence and Statistics V. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: The resulting family of techniques, called Dependency Detection, discover unusually frequently reoccurring patterns of events in execution traces using contingency table analysis. These techniques divide into two types: "snapshots" and "overviews". The snapshot models, called "dependencies", collect frequently co-occurring linear sequences of events <ref> [10, 9] </ref>. The overview models relate a set of statistically significant patterns as a single model that includes interconnections between events. Our first overview modeling algorithm constructs complete, Semi-Markov models of the execution traces [12]. However, many systems are not Markov in their execution. <p> A dependency is added to the list if p falls below a pre-determined threshold. Due to the statistics, dependencies include both uncommonly frequently and uncommonly infrequently co-occurring sequences; we call the latter type negative dependencies. DD has been extended to find more complex patterns <ref> [10, 9] </ref>. One version collects dependencies up to some length pruning overlapping dependencies based on an analysis of which is the best descriptor. Another detects partial order sequences, which is robust to the introduction of intervening events.
Reference: [10] <author> Adele E. Howe and Paul R. Cohen. </author> <title> Detecting and explaining dependencies in execution traces. </title> <editor> In P. Cheeseman and R.W. Oldford, editors, </editor> <booktitle> Selecting Models from Data; Artificial Intelligence and Statistics IV, </booktitle> <pages> pages 71-78. </pages> <publisher> Springer-Verlag, </publisher> <address> NY,NY, </address> <year> 1994. </year>
Reference-contexts: The resulting family of techniques, called Dependency Detection, discover unusually frequently reoccurring patterns of events in execution traces using contingency table analysis. These techniques divide into two types: "snapshots" and "overviews". The snapshot models, called "dependencies", collect frequently co-occurring linear sequences of events <ref> [10, 9] </ref>. The overview models relate a set of statistically significant patterns as a single model that includes interconnections between events. Our first overview modeling algorithm constructs complete, Semi-Markov models of the execution traces [12]. However, many systems are not Markov in their execution. <p> A dependency is added to the list if p falls below a pre-determined threshold. Due to the statistics, dependencies include both uncommonly frequently and uncommonly infrequently co-occurring sequences; we call the latter type negative dependencies. DD has been extended to find more complex patterns <ref> [10, 9] </ref>. One version collects dependencies up to some length pruning overlapping dependencies based on an analysis of which is the best descriptor. Another detects partial order sequences, which is robust to the introduction of intervening events.
Reference: [11] <author> Adele E. Howe and Paul R. Cohen. </author> <title> Understanding planner behavior. </title> <journal> Artificial Intelligence, </journal> <volume> 76(1-2):125-166, </volume> <year> 1995. </year>
Reference-contexts: Both of these approaches emphasize the plan generation phase, assuming that execution should proceed as planned. Execution was the focus of Failure Recovery Analysis (FRA) <ref> [7, 11] </ref>. FRA is a methodology for debugging some canonical bug types in the Phoenix planner by statistically analyzing traces of failure recovery. <p> (C D B) (75 93 246 584) (B C B) (74 14 247 663) Table 2: Length 3 dependencies (sequence with contingency table) collected for synthetic five token model 3 What We Have Learned So Far Snapshot dependencies have been used to support debugging failure recovery in the Phoenix planner <ref> [11] </ref> and to identify search control problems in UCPOP [17].
Reference: [12] <author> Adele E. Howe and Larry D. Pyeatt. </author> <title> Constructing transition models of AI planner behavior. </title> <booktitle> In Proceedings of the 11th Knowledge-Based Software Engineering Conference, </booktitle> <month> September </month> <year> 1996. </year>
Reference-contexts: The snapshot models, called "dependencies", collect frequently co-occurring linear sequences of events [10, 9]. The overview models relate a set of statistically significant patterns as a single model that includes interconnections between events. Our first overview modeling algorithm constructs complete, Semi-Markov models of the execution traces <ref> [12] </ref>. However, many systems are not Markov in their execution. Additionally, these models include all sequences, including those due to noise, and grow rather large, making them difficult to understand and use for debugging.
Reference: [13] <author> Eleftherios Koutsofios and Stephen C. </author> <title> North. Drawing graphs with dot. </title> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, NJ, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: The basic algorithm, which appears in Figure 1, iteratively connects together the dependencies, merging states where possible. The resulting diagram often has states composed of sequences of events. We display the diagram using a publicly available graphing package, called Dot <ref> [13] </ref>. The rules for when to link, merge or create new states are based on the information available from dependency detection. This part is the most complex in the algorithm because it requires generating all sequences from the state and its existing predecessors and successors in the state transition diagram.
Reference: [14] <author> Larry D. Pyeatt, Adele E. Howe, and Charles W. Anderson. </author> <title> Learning coordinated behaviors for control of a simulated robot. </title> <type> Technical report, </type> <institution> Computer Science Dept, Colorado State University, </institution> <year> 1996. </year>
Reference-contexts: Hits 20,937 21,116 23,774 65,827 Hit-rate .838 .845 .952 .878 False Positives 27 2,517 604 3,148 Table 3: Accuracy of transition diagram generation on synthetic models Debugging Example from RARS Reinforcement Learning Controller We have been building a reinforcement learning controller for RARS (Robot Automobile Racing Simulator) <ref> [14] </ref>. The controller must regulate the acceleration and steering of a race car on simulated tracks, which requires that it negotiate the track, avoid crashing into the walls, pass cars and go in for pit stops. As we develop the system, we are incrementally adding behaviors.
Reference: [15] <author> Reid G. Simmons. </author> <title> A theory of debugging plans and interpretations. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 94-99, </pages> <address> Minneapolis, MN, </address> <year> 1988. </year>
Reference-contexts: Plan debugging has been a topic of some interest as a method for plan construction (e.g., <ref> [6, 15] </ref>), but planner and system debugging has received less attention. Chien at JPL has developed two methods for analyzing a planner's knowledge base: static and completion analysis [3, 4]; these methods identify certain classes of syntactic errors and gaps in knowledge that prevent complete plans from being generated.
Reference: [16] <author> Robert R. Sokal and F. James Rohlf. Biometry: </author> <booktitle> The Principles and Practice of Statistics in Biological Research. W.H. </booktitle> <publisher> Freeman and Co., </publisher> <address> New York, </address> <note> second edition, </note> <year> 1981. </year>
Reference-contexts: From these frequencies, we construct a two by two contingency table, as in Table 1. Based on this table, P a seems to be a good predictor of T t . A statistical test, the G-test, indicates whether the two events are likely to be dependent <ref> [16] </ref>; in this case, G = 5:174; p &lt; :023, which means that the two events are unlikely to be independent and conclude that T t depends on P a . A dependency is added to the list if p falls below a pre-determined threshold.
Reference: [17] <author> Raghavan Srinivasan and Adele E. Howe. </author> <title> Comparison of methods for improving search efficiency in a partial-order planner. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1620-1626, </pages> <address> Montreal, CA, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: B) (74 14 247 663) Table 2: Length 3 dependencies (sequence with contingency table) collected for synthetic five token model 3 What We Have Learned So Far Snapshot dependencies have been used to support debugging failure recovery in the Phoenix planner [11] and to identify search control problems in UCPOP <ref> [17] </ref>. However, the dependencies were rather limited in their temporal scope and complexity; in some cases, especially with Phoenix, the short sequences led us to make changes that caused other problems, changes that would have been different had we known of other interactions.
Reference: [18] <author> David E. Wilkins. SIPE-2: </author> <title> A system for interactive planning and execution. </title> <address> http://www.ai.sri.com/ sipe/, </address> <month> April </month> <year> 1995. </year>
References-found: 18

