URL: http://www.wi.leidenuniv.nl/~gusz/ismis.ps.gz
Refering-URL: http://www.wi.leidenuniv.nl/~gusz/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: gusz@wi.leidenuniv.nl  
Title: Evolutionary exploration of search spaces  
Author: A.E. Eiben 
Affiliation: Leiden University, Department of Computer Science  
Abstract: Exploration and exploitation are the two cornerstones of problem solving by search. Evolutionary Algorithms (EAs) are search algorithms that explore the search space by the genetic search operators, while exploitation is done by selection. During the history of EAs different operators have emerged, mimicing asexual and sexual reproduction in Nature. Here we give an overview of the variety of these operators, review results discussing the (dis)advantages of asexual and sexual mech anisms and touch on a new phenomenon: multi-parent reproduction.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> T. Back F. Hoffmeister and H.-P. Schwefel. </author> <title> A survey of evolution strategies. </title> <booktitle> In Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-9. </pages> <publisher> Morgan Kauf-mann, </publisher> <year> 1991. </year>
Reference-contexts: Intermediate recombination (where 2 <ref> [0; 1] </ref> is a uniform random variable) makes a child that is the weighted average of the two parents. Just like mutation, recombination is applied to the object variables (x i 's) as well as to the strategy parameters ( i 's). <p> new individual x 0 by x i x i or y i global discrete recombination x i + i (y i x i ) global intermediate recombination where x and y are two parent individuals selected at random from the whole population for each i anew and drawing i 2 <ref> [0; 1] </ref> also happens for every i independently, [3]. Thus, although for each component x i 0 only two mating partners are consulted, the resampling mechanism causes that the child may inherit genes from more parents. <p> Thus, although for each component x i 0 only two mating partners are consulted, the resampling mechanism causes that the child may inherit genes from more parents. This results in a higher mixing of the genetic information than the 2-parent versions, <ref> [1] </ref>. In GAs there are three general multi-parent crosover mechanisms. Scanning crossover and diagonal crossover were introduced in [7], where the performance of scanning was studied. In [9] diagonal crossover was investigated, compared to scanning and the classical 2-parent n-point crossover. An extensive overview of experiments is given in [8].
Reference: 2. <author> T. </author> <title> Back. The interaction of mutation rate, selection, and self-adaptation within a genetic algorithm. </title> <booktitle> In Parallel Problem Solving from Nature - 2, </booktitle> <pages> pages 85-94. </pages> <publisher> North-Holland, </publisher> <year> 1992. </year>
Reference-contexts: Let us note that in [12] exponentially decreasing mutation rates were succesfully applied in a GA. Cross-fertilization of ideas from ES and GAs has led to using individual mutation rates that undergo self-adaptation in a GA with binary representation, <ref> [2] </ref>. The basic idea is to extend each individual with extra bits that represent the individual's own mutation rate. <p> Classical GA investigations tried to obtain a robust parameter setting concerning mutation rate and crossover rate, in combination with the pool size [4, 17, 27]. The generally acknowledged good heuristic values for mutation rate and crossover rate are 1=chromosome:length, respectively 0.7-0.8. Recent stud-ies, for instance <ref> [2, 12, 19, 23] </ref> provide theoretical and experimental evidence that decreasing mutation rate along the evolution is optimal. This suggests that mutation is important at the beginning of the search but becomes 'risky' at the end.
Reference: 3. <author> T. Back and H.-P. Schwefel. </author> <title> An overview of evolutionary algorithms for parameter optimization. </title> <journal> Journal of Evolutionary Computation, </journal> <volume> 1 </volume> <pages> 1-23, </pages> <year> 1993. </year>
Reference-contexts: Evolutionary Algorithms (EAs) are stochastic generate-and-test search algorithms having a number of particular properties. The standard pseudo-code for an EA is given in Figure 1, after [18]. There are different types of EAs, the most common classification distinguishes Genetic Algorithms (GA), Evolution Strategies (ES) and Evolutionary Programming (EP), <ref> [3] </ref>. Genetic Programming (GP) has grown out of GAs and can be seen as a sub-class of them. Besides the different historical roots and philosophy there are also technical differences between the three main streams in evolutionary computation. <p> in 2 n genes for n object variables. (For this discussion we disregard the incorporation and adaptation of covariances.) In ES the mean step sizes are modified log-normally: i where t 0 N (0; 1) and t N i (0; 1) provide for global, repsectively individual control of step sizes, <ref> [3] </ref>. In Evolutionary Programming the so-called meta-EP scheme is introduced for adapting mean step sizes. It works by modifying 's normally: i where is a scaling constant, [13]. <p> In Evolution Strategies there are different sexual recombination mechanisms all creating one child from a number of parents. The usual form of recombination, <ref> [3] </ref>, produces one new individual x 0 from two parents x and y by x i x i or y i discrete recombination x i + (y i x i ) intermediate recombination Discrete recombination is pretty much like uniform crossover creating only one child. <p> This ought to make one cautious and not rejecting it a priori. 3 Sex or no sex: importance of crossover and mutation The traditional views of EA streams on genetic operators are summarized in Table 1, after <ref> [3] </ref>. Triggered by the provoking success of EP without recombina ES EP GA mutation main operator only operator background operator recombination important for none main operator self-adaptation Table 1. <p> i or y i global discrete recombination x i + i (y i x i ) global intermediate recombination where x and y are two parent individuals selected at random from the whole population for each i anew and drawing i 2 [0; 1] also happens for every i independently, <ref> [3] </ref>. Thus, although for each component x i 0 only two mating partners are consulted, the resampling mechanism causes that the child may inherit genes from more parents. This results in a higher mixing of the genetic information than the 2-parent versions, [1].
Reference: 4. <author> K.A. De Jong. </author> <title> An analysis of the behavior of a class of genetic adaptive systems. </title> <type> Doctoral dissertation, </type> <institution> University of Michigan, </institution> <year> 1975. </year>
Reference-contexts: Although neither GAs nor EP were originally developed as function optimizers, [5, 13], such investigations are usually performed on function optimization problems. Classical GA investigations tried to obtain a robust parameter setting concerning mutation rate and crossover rate, in combination with the pool size <ref> [4, 17, 27] </ref>. The generally acknowledged good heuristic values for mutation rate and crossover rate are 1=chromosome:length, respectively 0.7-0.8. Recent stud-ies, for instance [2, 12, 19, 23] provide theoretical and experimental evidence that decreasing mutation rate along the evolution is optimal.
Reference: 5. <author> K.A. De Jong. </author> <title> Are genetic algorithms function optimizers? In R. </title> <editor> Manner and B. Manderick, editors, </editor> <booktitle> Parallel Problem Solving from Nature - 2, </booktitle> <pages> pages 3-13. </pages> <publisher> North-Holland, </publisher> <year> 1992. </year>
Reference-contexts: Role of mutation and recombination in different EA paradigms tion, as well as by 'introspective' motives in GA and ES there is more and more research devoted to the usefulness of mutation and recombination. Although neither GAs nor EP were originally developed as function optimizers, <ref> [5, 13] </ref>, such investigations are usually performed on function optimization problems. Classical GA investigations tried to obtain a robust parameter setting concerning mutation rate and crossover rate, in combination with the pool size [4, 17, 27].
Reference: 6. <author> K.A. De Jong and W.M. Spears. </author> <title> A formal analysis of the role of multi-point crossover in genetic algorithms. </title> <journal> Annals of Mathematics and Artificial Intelligence, </journal> <volume> 5 </volume> <pages> 1-26, </pages> <year> 1992. </year>
Reference-contexts: Formally, a schema can be seen as a partial instantiation of the variables, i.e. a string based on a ternary alphabet 0; 1; #, where # means undefined or don't care. Investigations in, for instance <ref> [6, 10, 30, 31] </ref>, cumulated substantial knowledge on the disruptiveness of n-point and uniform crossover. <p> Investigations in, for instance [6, 10, 30, 31], cumulated substantial knowledge on the disruptiveness of n-point and uniform crossover. The most important observation from <ref> [6] </ref> concerns the relationship between the disruptiveness and the power to recombine schemata. '... if one operator is better than another for survival, [i.e. less disruptive] it is worse for recombination (and vice versa).
Reference: 7. <author> A.E. Eiben, P-E. Raue, and Zs. Ruttkay. </author> <title> Genetic algorithms with multi-parent recombination. In Parallel Problem Solving from Nature - 3, </title> <publisher> LNCS 866, </publisher> <pages> pages 78-87. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: This results in a higher mixing of the genetic information than the 2-parent versions, [1]. In GAs there are three general multi-parent crosover mechanisms. Scanning crossover and diagonal crossover were introduced in <ref> [7] </ref>, where the performance of scanning was studied. In [9] diagonal crossover was investigated, compared to scanning and the classical 2-parent n-point crossover. An extensive overview of experiments is given in [8]. <p> increase in the rate of progress in changing from the bisexual to the multisexual scheme, whereas appreciable acceleration was achieved by introducing the bisexual in place of the asexual scheme, which allowed no recombination.' Scanning crossover and diagonal crossover show increased performance when using more parents on several numerical functions <ref> [7, 9, 8] </ref>, and ongoing research proves the same on NK-landscapes.
Reference: 8. <author> A.E. Eiben and C.H.M. van Kemenade. </author> <title> Performance of multi-parent crossover operators on numerical function optimization problems. </title> <type> Technical Report TR-95-33, </type> <institution> Leiden University, </institution> <year> 1995. </year>
Reference-contexts: In GAs there are three general multi-parent crosover mechanisms. Scanning crossover and diagonal crossover were introduced in [7], where the performance of scanning was studied. In [9] diagonal crossover was investigated, compared to scanning and the classical 2-parent n-point crossover. An extensive overview of experiments is given in <ref> [8] </ref>. Scanning crossover generalizes uniform crossover, although creating only one child, by chosing one of the i-th genes of the n parents to be the i-th gene of the child. <p> increase in the rate of progress in changing from the bisexual to the multisexual scheme, whereas appreciable acceleration was achieved by introducing the bisexual in place of the asexual scheme, which allowed no recombination.' Scanning crossover and diagonal crossover show increased performance when using more parents on several numerical functions <ref> [7, 9, 8] </ref>, and ongoing research proves the same on NK-landscapes.
Reference: 9. <author> A.E. Eiben, C.H.M. van Kemenade, and J.N. Kok. </author> <booktitle> Orgy in the computer: Multi-parent reproduction in genetic algorithms. In Third European Conference on Artificial Life, LNAI 929, </booktitle> <pages> pages 934-945. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: This results in a higher mixing of the genetic information than the 2-parent versions, [1]. In GAs there are three general multi-parent crosover mechanisms. Scanning crossover and diagonal crossover were introduced in [7], where the performance of scanning was studied. In <ref> [9] </ref> diagonal crossover was investigated, compared to scanning and the classical 2-parent n-point crossover. An extensive overview of experiments is given in [8]. <p> increase in the rate of progress in changing from the bisexual to the multisexual scheme, whereas appreciable acceleration was achieved by introducing the bisexual in place of the asexual scheme, which allowed no recombination.' Scanning crossover and diagonal crossover show increased performance when using more parents on several numerical functions <ref> [7, 9, 8] </ref>, and ongoing research proves the same on NK-landscapes.
Reference: 10. <editor> L.J. Eshelman and R.A. Caruana andJ.D. Schaffer. </editor> <title> Biases in the crossover landscape. </title> <booktitle> In Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 10-19, </pages> <year> 1989. </year>
Reference-contexts: Formally, a schema can be seen as a partial instantiation of the variables, i.e. a string based on a ternary alphabet 0; 1; #, where # means undefined or don't care. Investigations in, for instance <ref> [6, 10, 30, 31] </ref>, cumulated substantial knowledge on the disruptiveness of n-point and uniform crossover. <p> In other words, the number of different chromosomes that can be created by applying an operator. Clearly, 'exploration in the form of new recombinations comes at the cost of disruption', <ref> [10] </ref>. Recent research has thus shown that disruption is not necessarily disadvantageous. Nevertheless, no general conclusions on the relationship between the disruptiveness of genetic operators and the quality of the GA they are applied in could be established so far. Most probably this relation is (to some extent) problem dependent.
Reference: 11. <editor> L.J. Eshelman and J.D. Schaffer. Crossover's niche. </editor> <booktitle> In Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 9-14, </pages> <year> 1993. </year>
Reference-contexts: Nevertheless, it is observed that a GA with highly disruptive crossover outperforms a GA with mutation alone on problems with a low level of interactions between genes. It is also remarked that the power of an operator is strongly related to the selection mechanism. In <ref> [11] </ref> 'crossover's niche' is sought, i.e. problems where pair-wise mating has competitive advantages. This niche turns out to be non-empty, in the meanwhile the authors suspect that sexual recombination in GAs might be less powerful than generally believed.
Reference: 12. <author> T. Fogarty. </author> <title> Varying the probability of mutation in the genetic algorithm. </title> <booktitle> In Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 104-109, </pages> <year> 1989. </year>
Reference-contexts: Let us note that in <ref> [12] </ref> exponentially decreasing mutation rates were succesfully applied in a GA. Cross-fertilization of ideas from ES and GAs has led to using individual mutation rates that undergo self-adaptation in a GA with binary representation, [2]. <p> Classical GA investigations tried to obtain a robust parameter setting concerning mutation rate and crossover rate, in combination with the pool size [4, 17, 27]. The generally acknowledged good heuristic values for mutation rate and crossover rate are 1=chromosome:length, respectively 0.7-0.8. Recent stud-ies, for instance <ref> [2, 12, 19, 23] </ref> provide theoretical and experimental evidence that decreasing mutation rate along the evolution is optimal. This suggests that mutation is important at the beginning of the search but becomes 'risky' at the end.
Reference: 13. <editor> D.B. Fogel. </editor> <booktitle> Evolutionary Computation. </booktitle> <publisher> IEEE Press, </publisher> <year> 1995. </year>
Reference-contexts: Accordingly, the search operators are defined for trees instead of strings. Real valued numerical optimization is the standard application area of Evolution Strategies [29]. Therefore, real-valued representation is the standard in ES. The original Evolutionary Programming scheme was applied to finite state machines, using appropriately defined operators, <ref> [13] </ref>. More recently, combinatorial and numerical optimization problems have been treated by EP, thus involving real-valued representation in the EP paradigm too. As far as their arity is concerned, the operators used commonly in EAs are either unary or binary. <p> In Evolutionary Programming the so-called meta-EP scheme is introduced for adapting mean step sizes. It works by modifying 's normally: i where is a scaling constant, <ref> [13] </ref>. <p> Mutation is the only search operator, and 'recombination in evolutionary programming is a nonissue beacause each solution is typically viewed as the analog of a species, and there is no sexual communication between species.', cf. <ref> [13] </ref> p. 103. Indeed, this view justifies the omittance of recombination, however, this view is only justified by the human operator's freedom in taking any arbitrary perspective. Nevertheless, the fact that apparently all higher species apply sexual recombination indicates that it does have a competitive advantage in natural evolution. <p> Role of mutation and recombination in different EA paradigms tion, as well as by 'introspective' motives in GA and ES there is more and more research devoted to the usefulness of mutation and recombination. Although neither GAs nor EP were originally developed as function optimizers, <ref> [5, 13] </ref>, such investigations are usually performed on function optimization problems. Classical GA investigations tried to obtain a robust parameter setting concerning mutation rate and crossover rate, in combination with the pool size [4, 17, 27].
Reference: 14. <editor> D.B. Fogel and J.W. Atmar. </editor> <title> Comparing genetic operators with gaussian mutations in simulated evolutionary processes using linear systems. </title> <journal> Biological Cybernetics, </journal> <volume> 63 </volume> <pages> 111-114, </pages> <year> 1990. </year>
Reference-contexts: Based on a comparison of EP and GA in <ref> [14] </ref> it is argued that crossover does not have any competitive advantage above mutation. Critiques on this investigation, for instance in [28], initiated more extensive comparisons of GAs and EP on function optimization problems.
Reference: 15. <editor> D.B. Fogel and L.C. Stayton. </editor> <title> On the effectiveness of crossover in simulated evo-lutionary optimization. </title> <journal> Biosystems, </journal> <volume> 32:3:171-182, </volume> <year> 1994. </year>
Reference-contexts: Based on a comparison of EP and GA in [14] it is argued that crossover does not have any competitive advantage above mutation. Critiques on this investigation, for instance in [28], initiated more extensive comparisons of GAs and EP on function optimization problems. The results in <ref> [15] </ref> show a clear advatage of EP and make the authors conclude that 'no consistent advantage accrues from representing real-valued parameters as binary strings and allowing crossover to do within-parameter search.' Summarizing, at the moment there is a lot of effort payed to establishing the (dis)advantages of sexual, respectively asexual reproduction
Reference: 16. <author> B.R. Fox and M.B. McMahon. </author> <title> Genetic operators for sequencing problems. </title> <booktitle> In Foundations of Genetic Algorithms - 1, </booktitle> <pages> pages 284-300, </pages> <year> 1991. </year>
Reference-contexts: In traditional GAs binary representation is used, that is candidate solutions (individuals or chromosomes) are bit-strings with a fixed length L. The study of sequencing problems, such as routing and scheduling, has yielded order-based representation, where each individual is a permutation, <ref> [16, 32] </ref>. Parameter optimization problems with variables over continous domains has led to real-valued, or floating point, representation. <p> Applying n-point and uniform crossover to permutations may create children containing multiple occurrences of genes, i.e. children of permutations will not necessarily be permutations. This fact has led to the design of special order-based crossovers that do preserve the property of 'being a permutation', <ref> [16, 32] </ref>. One example is the order crossover OX that resembles 2-point crossover. OX cuts the parents in three segments along two randomly chosen crossover points. Child 1 inherits the middle segment from parent 1 without modification.
Reference: 17. <author> D.E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Although neither GAs nor EP were originally developed as function optimizers, [5, 13], such investigations are usually performed on function optimization problems. Classical GA investigations tried to obtain a robust parameter setting concerning mutation rate and crossover rate, in combination with the pool size <ref> [4, 17, 27] </ref>. The generally acknowledged good heuristic values for mutation rate and crossover rate are 1=chromosome:length, respectively 0.7-0.8. Recent stud-ies, for instance [2, 12, 19, 23] provide theoretical and experimental evidence that decreasing mutation rate along the evolution is optimal.
Reference: 18. <author> J. Heitkotter and D. Beasley. </author> <title> The Hitch-Hiker's Guide to Evolutionary Computation. FAQ for comp.ai.genetic, </title> <year> 1996. </year>
Reference-contexts: Evolutionary Algorithms (EAs) are stochastic generate-and-test search algorithms having a number of particular properties. The standard pseudo-code for an EA is given in Figure 1, after <ref> [18] </ref>. There are different types of EAs, the most common classification distinguishes Genetic Algorithms (GA), Evolution Strategies (ES) and Evolutionary Programming (EP), [3]. Genetic Programming (GP) has grown out of GAs and can be seen as a sub-class of them.
Reference: 19. <author> Hesser and Manner. </author> <title> Towards an optimal mutation probability for genetic algorithms. In Parallel Problem Solving from Nature - 1, </title> <publisher> LNCS 496, </publisher> <pages> pages 23-32. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: Classical GA investigations tried to obtain a robust parameter setting concerning mutation rate and crossover rate, in combination with the pool size [4, 17, 27]. The generally acknowledged good heuristic values for mutation rate and crossover rate are 1=chromosome:length, respectively 0.7-0.8. Recent stud-ies, for instance <ref> [2, 12, 19, 23] </ref> provide theoretical and experimental evidence that decreasing mutation rate along the evolution is optimal. This suggests that mutation is important at the beginning of the search but becomes 'risky' at the end.
Reference: 20. <author> R. Hinterding. </author> <title> Gaussian mutation and self-adaptation for numeric genetic algorithms. </title> <booktitle> In Second IEEE conference on Evolutionary Computation, </booktitle> <pages> pages 384-389, </pages> <year> 1995. </year>
Reference-contexts: This resembles ES and EP, but differs from them in an important aspect. Namely, while in ES and EP step sizes are adapted by the evolutionary process itself, here the changes follow a previously determined schedule. An interesting GA using bit representation combined with Gaussian mutation is presented in <ref> [20, 21] </ref>. The individuals are binary coded and undergo crossover acting on bits as usual. However, mutation is applied on the decoded values of the object variables x i and not on their binary codes.
Reference: 21. <author> R. Hinterding, H. Gielewski, </author> <title> and T.C. Peachey. The nature of mutation in genetic algorithms. </title> <booktitle> In Sixth International Conference on Genetic Algorithms, </booktitle> <pages> pages 65-72, </pages> <year> 1995. </year>
Reference-contexts: This resembles ES and EP, but differs from them in an important aspect. Namely, while in ES and EP step sizes are adapted by the evolutionary process itself, here the changes follow a previously determined schedule. An interesting GA using bit representation combined with Gaussian mutation is presented in <ref> [20, 21] </ref>. The individuals are binary coded and undergo crossover acting on bits as usual. However, mutation is applied on the decoded values of the object variables x i and not on their binary codes.
Reference: 22. <author> W. Hordijk and B. Manderick. </author> <title> The usefulness of recombination. </title> <booktitle> In Third Eu-ropean Conference on Artificial Life, LNAI 929, </booktitle> <pages> pages 908-919. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: This niche turns out to be non-empty, in the meanwhile the authors suspect that sexual recombination in GAs might be less powerful than generally believed. The usefulness of recombination is investigated on NK landscapes that allow gradual tuning of the ruggedness of the landscape in <ref> [22] </ref>. The conclusion is that 'recombination is useless on uncorrelated landscapes, but useful when high peaks are near one another and hence carry mutual information about their joint locations in the fitness landscape'.
Reference: 23. <author> B.A. Julstrom. </author> <title> What have you done for me lately? adapting operator probabilities in a steady-state genetic algorithm. </title> <booktitle> In Sixth International Conference on Genetic Algorithms, </booktitle> <pages> pages 81-87, </pages> <year> 1995. </year>
Reference-contexts: Classical GA investigations tried to obtain a robust parameter setting concerning mutation rate and crossover rate, in combination with the pool size [4, 17, 27]. The generally acknowledged good heuristic values for mutation rate and crossover rate are 1=chromosome:length, respectively 0.7-0.8. Recent stud-ies, for instance <ref> [2, 12, 19, 23] </ref> provide theoretical and experimental evidence that decreasing mutation rate along the evolution is optimal. This suggests that mutation is important at the beginning of the search but becomes 'risky' at the end.
Reference: 24. <editor> J.R. Koza. </editor> <booktitle> Genetic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Pseudo-code of an Evolutionary Algorithm tree structures, <ref> [24] </ref>. Accordingly, the search operators are defined for trees instead of strings. Real valued numerical optimization is the standard application area of Evolution Strategies [29]. Therefore, real-valued representation is the standard in ES. The original Evolutionary Programming scheme was applied to finite state machines, using appropriately defined operators, [13]. <p> Mutation rate in GP is interpreted as the frequency of performing mutation, similarily to order-based GAs. It is remarkable that the general advice concerning mutation rate in GP is to set p m to zero, <ref> [24] </ref>. For the real-valued representation as used in ES, EP and lately in GAs the basic unit of inheritance, i.e. one gene, is a floating point number x i , rather than a bit. In ES and EP a separate mutation mechanism is used for each gene, i.e. object variable.
Reference: 25. <author> Z. Michalewicz. </author> <title> Genetic Algorithms + Data structures = Evolution programs. </title> <publisher> Springer-Verlag, </publisher> <address> second edition, </address> <year> 1994. </year>
Reference-contexts: + (t; U B i x i ) if a random digit is 0 x i (t; x i LB i ) if a random digit is 1 U B i and LB i being the upper, repectively lower bound of the domain and t the generation number (time counter), <ref> [25] </ref>. The function (t; y) returns a value from [0; y] getting closer to 0 as t increases. This mechanism yields a dynamically changing mutation step size. This resembles ES and EP, but differs from them in an important aspect. <p> Empirically, discrete recombination on object variables and intermediate recombination on strategy parameters gives best results. Similar operators are also introduced for GAs with real valued representation applied to convex search spaces <ref> [25] </ref>. These operators create two children of two parents. The so-called simple crossover choses a random crossover point k and crosses the parents after the k-th position applying a contraction coefficient a to guarantee that the offspring fall inside the convex search space.
Reference: 26. <author> H. Muhlenbein and H.-M. Voigt. </author> <title> Gene pool recombination in genetic algorithms. </title> <booktitle> In Proc. of the Metaheuristics Conference. </booktitle> <publisher> Kluwer Academic Publishers, </publisher> <year> 1995. </year>
Reference-contexts: Diagonal crossover generalizes n-point crossover by selecting (n 1) crossover points and composing n children by taking the resulting n chromosome segments from the parents 'along the diagonals'. Figure 2 illustrates this idea. The Gene Pool Recombination (GPR) in GAs was introduced in <ref> [26] </ref>. It was further studied and extended with a fuzzy mechanism in [33]. In GPR first Fig. 2. Diagonal crossover with three parents a set of parents has to be selected, these form the so-called gene pool. <p> GPR was reported to converge 25 % faster than two parent recombination (TPR) on the ONEMAX problem <ref> [26] </ref>, and the fuzzyfied version of GPR proved to outperform fuzzyfied TPR in speed as well as in realized heritability on the spherical function [33]. 5 Conclusions Evolutionary Algorithms perform search by means of creating genetic diversity by genetic operators and reducing this diversity by selection.
Reference: 27. <editor> J.D. Schaffer R.A. Caruana, L.J. Eshelman and R. </editor> <title> Das. A study of control parameters affecting the online performance of genetic algorithms. </title> <booktitle> In Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 51-60, </pages> <year> 1989. </year>
Reference-contexts: Although neither GAs nor EP were originally developed as function optimizers, [5, 13], such investigations are usually performed on function optimization problems. Classical GA investigations tried to obtain a robust parameter setting concerning mutation rate and crossover rate, in combination with the pool size <ref> [4, 17, 27] </ref>. The generally acknowledged good heuristic values for mutation rate and crossover rate are 1=chromosome:length, respectively 0.7-0.8. Recent stud-ies, for instance [2, 12, 19, 23] provide theoretical and experimental evidence that decreasing mutation rate along the evolution is optimal.
Reference: 28. <editor> J.D. Schaffer and L.J. Eshelman. </editor> <title> On crossover as an evolutionary viable strategy. </title> <booktitle> In Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 61-68, </pages> <year> 1991. </year>
Reference-contexts: Most probably this relation is (to some extent) problem dependent. Besides comparisons of crossover operators, the relative importance, i.e. search power, of sexual recombination and asexual, unary operators is investigated. The experiments reported in <ref> [28] </ref> show that mutation and selection are more powerful than previously believed. Nevertheless, it is observed that a GA with highly disruptive crossover outperforms a GA with mutation alone on problems with a low level of interactions between genes. <p> Based on a comparison of EP and GA in [14] it is argued that crossover does not have any competitive advantage above mutation. Critiques on this investigation, for instance in <ref> [28] </ref>, initiated more extensive comparisons of GAs and EP on function optimization problems.
Reference: 29. <author> H.-P. Schwefel. </author> <title> Evolution and Optimum Seeking. </title> <booktitle> Sixth-Generation Computer Technology Series. </booktitle> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: Pseudo-code of an Evolutionary Algorithm tree structures, [24]. Accordingly, the search operators are defined for trees instead of strings. Real valued numerical optimization is the standard application area of Evolution Strategies <ref> [29] </ref>. Therefore, real-valued representation is the standard in ES. The original Evolutionary Programming scheme was applied to finite state machines, using appropriately defined operators, [13]. More recently, combinatorial and numerical optimization problems have been treated by EP, thus involving real-valued representation in the EP paradigm too. <p> GPR allows for theoretical analysis of GA convergence for infinite populations with binomial fitness distribution. As for the performance of multi-parent recombination, at the moment there are not many accessible results within ES. In <ref> [29] </ref> p. 146 the following is stated: 'A crude test yielded only a slight further increase in the rate of progress in changing from the bisexual to the multisexual scheme, whereas appreciable acceleration was achieved by introducing the bisexual in place of the asexual scheme, which allowed no recombination.' Scanning crossover
Reference: 30. <author> W.M. Spears. </author> <booktitle> Crossover or mutation? In Foundations of Genetic Algorithms - 2, </booktitle> <pages> pages 221-238, </pages> <year> 1993. </year>
Reference-contexts: Formally, a schema can be seen as a partial instantiation of the variables, i.e. a string based on a ternary alphabet 0; 1; #, where # means undefined or don't care. Investigations in, for instance <ref> [6, 10, 30, 31] </ref>, cumulated substantial knowledge on the disruptiveness of n-point and uniform crossover. <p> The conclusion is that 'recombination is useless on uncorrelated landscapes, but useful when high peaks are near one another and hence carry mutual information about their joint locations in the fitness landscape'. The view presented in <ref> [30] </ref> relativizes the mutation-or-crossover battle by noting that both operators serve another purpose. 'Mutation serves to create random diversity in the population, while crossover serves as an accelerator that promotes emergent behavior from components.' Additionally, crossover is useful for maximizing the accumulated payoff, while it can be harm-ful if optimality is
Reference: 31. <author> G. Syswerda. </author> <title> Uniform crossover in genetic algorithms. </title> <booktitle> In Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-9, </pages> <year> 1989. </year>
Reference-contexts: Formally, a schema can be seen as a partial instantiation of the variables, i.e. a string based on a ternary alphabet 0; 1; #, where # means undefined or don't care. Investigations in, for instance <ref> [6, 10, 30, 31] </ref>, cumulated substantial knowledge on the disruptiveness of n-point and uniform crossover.
Reference: 32. <author> T. Starkweather, S. McDaniel K. Mathias D. Whitley and C. Whitley. </author> <title> A comparison of genetic sequenceing operators. </title> <booktitle> In Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 69-76, </pages> <year> 1991. </year>
Reference-contexts: In traditional GAs binary representation is used, that is candidate solutions (individuals or chromosomes) are bit-strings with a fixed length L. The study of sequencing problems, such as routing and scheduling, has yielded order-based representation, where each individual is a permutation, <ref> [16, 32] </ref>. Parameter optimization problems with variables over continous domains has led to real-valued, or floating point, representation. <p> Applying n-point and uniform crossover to permutations may create children containing multiple occurrences of genes, i.e. children of permutations will not necessarily be permutations. This fact has led to the design of special order-based crossovers that do preserve the property of 'being a permutation', <ref> [16, 32] </ref>. One example is the order crossover OX that resembles 2-point crossover. OX cuts the parents in three segments along two randomly chosen crossover points. Child 1 inherits the middle segment from parent 1 without modification.
Reference: 33. <author> H.-M. Voigt and H. Muhlenbein. </author> <title> Gene pool recombination and utilization of co-variances for the Breeder Genetic Algorithm. </title> <booktitle> In Second IEEE conference on Evolutionary Computation, </booktitle> <pages> pages 172-177, </pages> <year> 1995. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: Figure 2 illustrates this idea. The Gene Pool Recombination (GPR) in GAs was introduced in [26]. It was further studied and extended with a fuzzy mechanism in <ref> [33] </ref>. In GPR first Fig. 2. Diagonal crossover with three parents a set of parents has to be selected, these form the so-called gene pool. <p> GPR was reported to converge 25 % faster than two parent recombination (TPR) on the ONEMAX problem [26], and the fuzzyfied version of GPR proved to outperform fuzzyfied TPR in speed as well as in realized heritability on the spherical function <ref> [33] </ref>. 5 Conclusions Evolutionary Algorithms perform search by means of creating genetic diversity by genetic operators and reducing this diversity by selection. There exists a great variety of genetic operators, in this paper we gave an overview.
References-found: 33

