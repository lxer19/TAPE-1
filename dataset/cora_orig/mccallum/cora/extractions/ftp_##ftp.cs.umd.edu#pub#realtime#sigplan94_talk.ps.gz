URL: ftp://ftp.cs.umd.edu/pub/realtime/sigplan94_talk.ps.gz
Refering-URL: http://www.cs.umd.edu/projects/TimeWare/TimeWare-index-no-abs.html
Root-URL: 
Email: rich@cs.umd.edu  
Phone: (301) 405-2710  
Title: Languages and Tools for Real-time Systems: Problems, Solutions and Opportunities  
Author: Richard Gerber 
Note: Since so much work has been done in real-time systems and even more in programming languages my references are by necessity incomplete. Author supported by ONR project N00014-94-10228, NSF grant CCR-9209333, and an NSF Young Investigator Award CCR-9357850.  
Date: October 14, 1994  
Address: College Park, MD 20742  
Affiliation: Department of Computer Science University of Maryland  University of Maryland  
Pubnum: Technical Report CS-TR-3362, UMIACS-TR-94-117  
Abstract: This report summarizes two talks I gave at the ACM SIGPLAN Workshop on Language, Compiler, and Tool Support for Real-Time Systems, which took place on June 21, 1994, in in Orlando, Florida. The workshop was held in concert with ACM SIGPLAN Conference on Programming Languages Design and Implementation. The first talk ("Statements about Real-Time: Truth or Bull?") was given in the early morning. At the behest of the workshop's organizers, its primary function was to seed the ongoing discourse and provoke some debate. Besides asking controversial questions, and positing opinions, the talk also identified some several fertile research areas that might interest PLDI attendees. The second talk ("Languages and Transformations: Some Solutions") was more technical, and it reviewed our research on program optimizations for real-time domains. However, I tried as much as possible to revisit the research problems raised in the morning talk, and present some possible approaches to them. The following paragraphs contain the text from my viewgraphs, laced with some commentary. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Agrawal, Richard DeMillo, and Eugene H. Spafford. </author> <title> Debugging with dynamic slicing and backtracking. </title> <journal> Software Practice and Experience, </journal> <volume> 23(6) </volume> <pages> 589-616, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: The tool provides graphical, user-selectable transformations, so that the programmer remains informed of all slicing decisions. In this manner, the programmer maintains a reasonable degree of traceability to the original program. Much of the interface, as well as the slicing routines, was cannibalized from Agrawal and Spafford's Spyder toolset <ref> [1] </ref>.
Reference: [2] <author> T. Baker and A. Shaw. </author> <title> The cyclic executive model and ada. </title> <journal> The Journal of Real-Time Systems, </journal> <volume> 1(1) </volume> <pages> 7-25, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: This group argues for an easier design process, cheaper analysis tests, more adaptability, etc. The "time-line group" uses terms like "calendar-based dispatching," "cyclic executive dispatching," <ref> [35, 7, 2, 38, 36] </ref>, etc. Basically, these terms add up to the same approach amajor frame (or LCM, or hyper-period) is created, and all task instances falling within the frame are sorted to execute non-preemptively. This group argues for more dependability, predictability, less nondeter-minism, etc.
Reference: [3] <author> A. Burns, K.Tindell, and A.J.Wellings. </author> <title> Fixed priority scheduling with deadlines prior to completion. </title> <booktitle> In 6th Euromicro Workshop on Real-Time Systems, </booktitle> <month> pages ??-??, June </month> <year> 1994. </year>
Reference-contexts: However, the on 18 line scheduler was a bit more complicated than desired, in that it added a dynamic, time-based component to the dispatcher. But research moves quickly in this field! After investigating TCEL's "delayed deadline" model, Alan Burns at the University of York <ref> [3] </ref> developed a static-priority scheduling scheme to handle such applications. Unlike "pure" rate-monotonic schemes, here the actual priority assignment is dependent the respective execution times of each IO-handler and state-update component, as well as the task periods.
Reference: [4] <author> R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K. Zadeck. </author> <title> Efficiently computing static single assignment form and the control dependence graph. </title> <journal> ACM Transactions on Programming Languages and systems, </journal> <volume> 9 </volume> <pages> 319-345, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: And the situation gets significantly more complicated when the program possesses a branching structure, i.e., when the actual execution paths are determined at runtime. Thus we take a greedy approximation approach, which works in several phases. First the TCEL source is translated into a single-static-assignment (SSA) representation <ref> [4] </ref>, whose naming conventions help isolate the "worst-case" execution paths. Next the code is decomposed into several blocks, and equations are generated to constrain their start and finish-times. Finally a variant of code scheduling is used to relocate the unobservable code, and hopefully attain feasibility.
Reference: [5] <author> B. Dasarathy. </author> <title> Timing constraints of real-time systems: Constructs for expressing them, method for validating them. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 11(1) </volume> <pages> 80-86, </pages> <month> Jan-uary </month> <year> 1985. </year> <month> 26 </month>
Reference-contexts: Indeed, almost all formal models ease this process by making some distinction between an "event" and a corresponding "action." For example, in Real-Time Logic [18], events are instantaneous and require no resources while actions consume nonzero time. Similar distinctions exist in RTRL <ref> [5] </ref>, Timed IO Automata [25], ACSR [19], and in almost every formal approach to real-time.
Reference: [6] <author> J. A. Fisher. </author> <title> Trace scheduling: A technique for global microcode compaction. </title> <journal> IEEE Transac--tions on Computer, </journal> <volume> 30 </volume> <pages> 478-490, </pages> <month> July </month> <year> 1981. </year>
Reference-contexts: When faced with an infeasible task, using local transformations to achieve local feasibility is certainly better than taking no action at all. Our approach to this problem is to us a variant of of trace-scheduling <ref> [6] </ref>, with the objective of (1) finding the overloaded paths in the program; and then (2) relocating the unobservable code off of these paths.
Reference: [7] <author> G. Fohler and C. Koza. </author> <title> Heuristic Scheduling for Distributed Real-Time Systems. </title> <type> MARS 6/89, </type> <institution> Technische Universitat Wien, Vienna, Austria, </institution> <month> April </month> <year> 1989. </year>
Reference-contexts: This group argues for an easier design process, cheaper analysis tests, more adaptability, etc. The "time-line group" uses terms like "calendar-based dispatching," "cyclic executive dispatching," <ref> [35, 7, 2, 38, 36] </ref>, etc. Basically, these terms add up to the same approach amajor frame (or LCM, or hyper-period) is created, and all task instances falling within the frame are sorted to execute non-preemptively. This group argues for more dependability, predictability, less nondeter-minism, etc.
Reference: [8] <author> R. Gerber and S. Hong. </author> <title> Semantics-based compiler transformations for enhanced schedulability. </title> <booktitle> In Proceedings IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 232-242. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1993. </year>
Reference-contexts: Finally a variant of code scheduling is used to relocate the unobservable code, and hopefully attain feasibility. The actual details of the method are rather complex, and are not within the scope of this paper; readers should refer to our more technical papers referenced below. Transformations for Schedulability. In <ref> [8] </ref> we addressed a more ambitious goal that of transforming multiple tasks to achieve schedulability. The problem here is that "schedulability," by definition, depends on interactions between multiple tasks. <p> The actual transformation is carried out via program slicing. Briefly stated, a slice of a program P with respect to a program point p and variable v consists of P 's statements and control predicates that affect v at point p. (See <ref> [8] </ref> for details on our approach; refer to [33, 16, 27, 32] on program slicing in general.) Consider the program in Figure 4 (A), and its two residual slices in Figure 4 (B).
Reference: [9] <author> R. Gerber and S. Hong. </author> <title> Compiling real-time programs with timing constraint refinement and structural code motion. </title> <type> Technical Report UMD CS-TR-3323, </type> <institution> UMIACS-TR-94-90, Department of Computer Science, University of Maryland, </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: In performing these transformations, the observable events act as "semantic markers," denoting the places where code can be moved. While the method appears straightforward (and in this case simple), using it on larger programs is a nontrivial compiler problem. Indeed, in <ref> [9] </ref> we show that even in the case of a basic block, simply determining which instructions to move is NP-Hard. And the situation gets significantly more complicated when the program possesses a branching structure, i.e., when the actual execution paths are determined at runtime. <p> This is correct. Throughout the course of the project, we gradually learned that that the original approach while theoretically sound was untenable to implement. The revised approach (and algorithm) is described in a more recent report <ref> [9] </ref>. Lesson 3: Traceability is a Must. The results of multiple SSA-based transformations are, at best, cryptic. And as mentioned above, programmers of real-time systems will not accept any auto-transform tool.
Reference: [10] <author> R. Gerber, S. Hong, and M. Saksena. </author> <title> Guaranteeing end-to-end timing constraints by calibrating intermediate processes. </title> <booktitle> In Proceedings IEEE Real-Time Systems Symposium. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: In doing so, we may learn new ways of evaluating design alternatives before it's 21 too late. We have done some research on this problem, and our initial results are in a paper entitled "Guaranteeing End-to-End Timing Constraints by Calibrating Intermediate Processes" <ref> [10] </ref>. These results are encouraging, and they do yield a new way to approach the problem as well as some algorithms to help solve it in certain circumstances.
Reference: [11] <author> R. Gerber and I. Lee. </author> <title> A Hierarchical Approach for Automating the Verification of Real-Time Systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 18(9) </volume> <pages> 768-784, </pages> <year> 1992. </year>
Reference-contexts: To achieve balance at this point usually requires a costly and arduous process of instrumentation and system tuning. By the time we looked at this problem from a research perspective, two trends had emerged. First, a variety of experimental real-time programming languages had been posited (e.g., <ref> [17, 20, 23, 26, 34, 11] </ref>). While differing in several details, they had converged on a core set of real-time constructs and functionality. Second, there was a proliferation (indeed an explosion) of compiler optimization techniques, designed to take advantage of emerging computer architectures - e.g., RISC, SPMD, VLIW, superscaler, etc.
Reference: [12] <author> M. G. Harmon, T. P. Baker, and D. B. Whalley. </author> <title> A retargetable technique for predicting execution time. </title> <booktitle> In Proceedings IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 68-77. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1992. </year>
Reference-contexts: In fact, there has recently been very encouraging work in this area. For example, the tool described in [28] lets one perform analysis at the source-level; while it necessarily leads to a rough estimate, it's a nice start in the prediction process. In <ref> [12] </ref> a more accurate timing tool is described; it analyzes micro-instruction streams using an abstract architecture description. Getting more refined, the tool described in [37] analyzes instruction timings at the pipeline level, and [22] pushes (conservative) analysis to both the cache and pipeline levels.
Reference: [13] <author> John L. Hennessy and David Patterson. </author> <title> Computer Architecture, A Quantitative Approach. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: These features can dramatically increase average-case performance, which is exactly what we want in our desktop workstations. This principle is cogently explained in Hennessy and Patterson's text <ref> [13] </ref>, so there's little need for me to belabor it here. But the perspective changes when I'm looking for a real-time platform, especially one that'll host a mission-critical system. <p> But the perspective changes when I'm looking for a real-time platform, especially one that'll host a mission-critical system. Yes, I do want my general-purpose workstation to perform like a Lamborghini and maybe I'll settle for a Corvette to borrow the analogy made in <ref> [13] </ref>. But my idea of a good real-time CPU is more like a Mercedes Wagon high class, yet safe and reliable. 9 Indeed, the very features that enhance RISC performance (loads of registers, pipelines, intense compiler optimizations) can become liabilities in the world of real-time.
Reference: [14] <author> Dan Hildebrand. </author> <title> A microkernel posix os for real-time embedded systems. </title> <booktitle> In Proceedings of Embedded Systems Conference, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: But if we have to declare a winner here, it's the the real-time research community. There is now a panoply of industrial real-time kernels, all of which are well-supported, lightweight, and to a greater or lesser extent - POSIX-compliant. To name three, QNX <ref> [14] </ref>, VxWorks and Lynx-OS support very fast context-switch latencies, programmable timers, multiple-levels of priorities and full preemptivity. These kernels were built using the principles that university-types developed.
Reference: [15] <author> S. Hong and R. Gerber. </author> <title> Compiling real-time programs into schedulable code. </title> <booktitle> In Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation. </booktitle> <publisher> ACM Press, </publisher> <month> June </month> <year> 1993. </year> <journal> SIGPLAN Notices, </journal> <volume> 28(6) </volume> <pages> 166-176. </pages>
Reference-contexts: move, by transferring them to their "correct" places, and by analyzing the results. 3 Program Transformations: Problems, Solutions and Introspec tions For the past several years we have investigated the problem of optimizations for real-time programs. (In fact the first report on this work was given at last year's PLDI <ref> [15] </ref>.) I'll now briefly describe the work, how it evolved, and most importantly what we learned in the process. For those interested in more technical aspects of our work, please see our research papers (accessible by World-Wide-Web and FTP 2 ). 3.1 Balancing Time. <p> Performing such re-timing is especially important in a cached memory structure, where code scheduling will always change the instruction alignment. At the workshop, it was remarked that this approach (and its resulting algorithms) represents a departure from our original PLDI paper <ref> [15] </ref>. This is correct. Throughout the course of the project, we gradually learned that that the original approach while theoretically sound was untenable to implement. The revised approach (and algorithm) is described in a more recent report [9]. Lesson 3: Traceability is a Must.
Reference: [16] <author> S. Horwitz, T. Reps, and D. Binkley. </author> <title> Interprocedural slicing using dependence graph. </title> <journal> ACM Transactions on Programming Languages and systems, </journal> <volume> 12 </volume> <pages> 26-60, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Briefly stated, a slice of a program P with respect to a program point p and variable v consists of P 's statements and control predicates that affect v at point p. (See [8] for details on our approach; refer to <ref> [33, 16, 27, 32] </ref> on program slicing in general.) Consider the program in Figure 4 (A), and its two residual slices in Figure 4 (B). Since slice t IO contains all of t 's IO operations, the observable behavior of the transformed task will be semantically identical to the original.
Reference: [17] <author> Y. Ishikawa, H. Tokuda, and C. W. Mercer. </author> <title> Object-oriented real-time language design: Constructs for timing constraints. </title> <booktitle> In Proceedings of OOPSLA-90, </booktitle> <pages> pages 289-298, </pages> <month> October </month> <year> 1990. </year>
Reference-contexts: To achieve balance at this point usually requires a costly and arduous process of instrumentation and system tuning. By the time we looked at this problem from a research perspective, two trends had emerged. First, a variety of experimental real-time programming languages had been posited (e.g., <ref> [17, 20, 23, 26, 34, 11] </ref>). While differing in several details, they had converged on a core set of real-time constructs and functionality. Second, there was a proliferation (indeed an explosion) of compiler optimization techniques, designed to take advantage of emerging computer architectures - e.g., RISC, SPMD, VLIW, superscaler, etc.
Reference: [18] <author> F. Jahanian and Al Mok. </author> <title> Safety analysis of timing properties in real-time systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 12(9) </volume> <pages> 890-904, </pages> <month> September </month> <year> 1986. </year> <month> 27 </month>
Reference-contexts: When reasoning about a real-time concurrent system it is often useful to consider only "events of interest," and to abstract away local-state information. Indeed, almost all formal models ease this process by making some distinction between an "event" and a corresponding "action." For example, in Real-Time Logic <ref> [18] </ref>, events are instantaneous and require no resources while actions consume nonzero time. Similar distinctions exist in RTRL [5], Timed IO Automata [25], ACSR [19], and in almost every formal approach to real-time.
Reference: [19] <author> I. Lee, P. Bremond-Gregoire, and R. Gerber. </author> <title> A Process Algebraic Apprach to the Specification and Analysis of Resource-Bound Real-Time Systems. </title> <journal> IEEE Proceedings, </journal> <volume> 82(1), </volume> <month> January </month> <year> 1994. </year>
Reference-contexts: Indeed, almost all formal models ease this process by making some distinction between an "event" and a corresponding "action." For example, in Real-Time Logic [18], events are instantaneous and require no resources while actions consume nonzero time. Similar distinctions exist in RTRL [5], Timed IO Automata [25], ACSR <ref> [19] </ref>, and in almost every formal approach to real-time.
Reference: [20] <author> I. Lee and V. Gehlot. </author> <title> Language constructs for real-time programming. </title> <booktitle> In Proceedings IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 57-66. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1985. </year>
Reference-contexts: To achieve balance at this point usually requires a costly and arduous process of instrumentation and system tuning. By the time we looked at this problem from a research perspective, two trends had emerged. First, a variety of experimental real-time programming languages had been posited (e.g., <ref> [17, 20, 23, 26, 34, 11] </ref>). While differing in several details, they had converged on a core set of real-time constructs and functionality. Second, there was a proliferation (indeed an explosion) of compiler optimization techniques, designed to take advantage of emerging computer architectures - e.g., RISC, SPMD, VLIW, superscaler, etc.
Reference: [21] <author> J. P. Lehoczky, L. Sha, and Y. Ding. </author> <title> The rate monotonic scheduling algorithm: Exact characterization and average case behavior. </title> <booktitle> In Proceedings IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 166-171. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1989. </year>
Reference-contexts: You see, there have traditionally been two schools in this: those who advocated preemptive, priority-based scheduling, and those who advocated nonpreemptive, time-based scheduling. The "priority group" employs methods like "rate-monotonic scheduling" <ref> [24, 21] </ref> (which statically assigns the highest priority to the highest-rate process), the "priority-ceiling-protocol" [29] (which handles priority inversion due to blocked resources), "EDF-scheduling" [24] (which dynamically assigns the highest priority to the process with the earliest deadline), "general static-priority-scheduling" [31] (which accounts for offsets, blocking, and deadlines), and a variety
Reference: [22] <author> S. Lim, Y. Bae, C. Jang, B. Rhee, S. Min, C. Park, H. Shin, K. Park, and C. Kim. </author> <title> An accurate worst case timing analysis for risc processors. </title> <booktitle> In Proceedings IEEE Real-Time Systems Symposium. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: In [12] a more accurate timing tool is described; it analyzes micro-instruction streams using an abstract architecture description. Getting more refined, the tool described in [37] analyzes instruction timings at the pipeline level, and <ref> [22] </ref> pushes (conservative) analysis to both the cache and pipeline levels. And now, several papers in this workshop present even newer approaches, and we should expect 7 to see further progress along these lines. Yet I'll still maintain that static analysis will always produce conservative results.
Reference: [23] <author> K. J. Lin and S. Natarajan. </author> <title> Expressing and maintaining timing constraints in FLEX. </title> <booktitle> In Proceedings IEEE Real-Time Systems Symposium. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1988. </year>
Reference-contexts: To achieve balance at this point usually requires a costly and arduous process of instrumentation and system tuning. By the time we looked at this problem from a research perspective, two trends had emerged. First, a variety of experimental real-time programming languages had been posited (e.g., <ref> [17, 20, 23, 26, 34, 11] </ref>). While differing in several details, they had converged on a core set of real-time constructs and functionality. Second, there was a proliferation (indeed an explosion) of compiler optimization techniques, designed to take advantage of emerging computer architectures - e.g., RISC, SPMD, VLIW, superscaler, etc.
Reference: [24] <author> C. L. Liu and J. Layland. </author> <title> Scheduling algorithm for multiprogramming in a hard real-time environment. </title> <journal> Journal of the ACM, </journal> <volume> 20(1) </volume> <pages> 46-61, </pages> <month> January </month> <year> 1973. </year>
Reference-contexts: You see, there have traditionally been two schools in this: those who advocated preemptive, priority-based scheduling, and those who advocated nonpreemptive, time-based scheduling. The "priority group" employs methods like "rate-monotonic scheduling" <ref> [24, 21] </ref> (which statically assigns the highest priority to the highest-rate process), the "priority-ceiling-protocol" [29] (which handles priority inversion due to blocked resources), "EDF-scheduling" [24] (which dynamically assigns the highest priority to the process with the earliest deadline), "general static-priority-scheduling" [31] (which accounts for offsets, blocking, and deadlines), and a variety <p> The "priority group" employs methods like "rate-monotonic scheduling" [24, 21] (which statically assigns the highest priority to the highest-rate process), the "priority-ceiling-protocol" [29] (which handles priority inversion due to blocked resources), "EDF-scheduling" <ref> [24] </ref> (which dynamically assigns the highest priority to the process with the earliest deadline), "general static-priority-scheduling" [31] (which accounts for offsets, blocking, and deadlines), and a variety of other policies. This group argues for an easier design process, cheaper analysis tests, more adaptability, etc.
Reference: [25] <author> M. Merritt, F. Modungo, and M. Tuttle. </author> <title> Time-Constrained Automata. </title> <booktitle> In CONCUR '91, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: Indeed, almost all formal models ease this process by making some distinction between an "event" and a corresponding "action." For example, in Real-Time Logic [18], events are instantaneous and require no resources while actions consume nonzero time. Similar distinctions exist in RTRL [5], Timed IO Automata <ref> [25] </ref>, ACSR [19], and in almost every formal approach to real-time.
Reference: [26] <author> V. Nirkhe. </author> <title> Application of Partial Evaluation to Hard Real-Time Programming. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Maryland at College Park, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: To achieve balance at this point usually requires a costly and arduous process of instrumentation and system tuning. By the time we looked at this problem from a research perspective, two trends had emerged. First, a variety of experimental real-time programming languages had been posited (e.g., <ref> [17, 20, 23, 26, 34, 11] </ref>). While differing in several details, they had converged on a core set of real-time constructs and functionality. Second, there was a proliferation (indeed an explosion) of compiler optimization techniques, designed to take advantage of emerging computer architectures - e.g., RISC, SPMD, VLIW, superscaler, etc.
Reference: [27] <author> K. J. Ottenstein and L. M. Ottenstein. </author> <title> The program dependence graph in a software development environment. </title> <booktitle> In Proceedings of the ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software Development Environments, </booktitle> <pages> pages 177-184, </pages> <month> May </month> <year> 1984. </year>
Reference-contexts: Briefly stated, a slice of a program P with respect to a program point p and variable v consists of P 's statements and control predicates that affect v at point p. (See [8] for details on our approach; refer to <ref> [33, 16, 27, 32] </ref> on program slicing in general.) Consider the program in Figure 4 (A), and its two residual slices in Figure 4 (B). Since slice t IO contains all of t 's IO operations, the observable behavior of the transformed task will be semantically identical to the original.
Reference: [28] <author> C. Park and A. C. Shaw. </author> <title> Experimenting with a program timing tool based on source-level timing schema. </title> <booktitle> In Proceedings IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 72-81. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1990. </year>
Reference-contexts: In fact, there has recently been very encouraging work in this area. For example, the tool described in <ref> [28] </ref> lets one perform analysis at the source-level; while it necessarily leads to a rough estimate, it's a nice start in the prediction process. In [12] a more accurate timing tool is described; it analyzes micro-instruction streams using an abstract architecture description.
Reference: [29] <author> L. Sha, R. Rajkumar, and J. P. Lehoczky. </author> <title> Priority inheritance protocols: An approach to real-time synchronization. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 39 </volume> <pages> 1175-1185, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: You see, there have traditionally been two schools in this: those who advocated preemptive, priority-based scheduling, and those who advocated nonpreemptive, time-based scheduling. The "priority group" employs methods like "rate-monotonic scheduling" [24, 21] (which statically assigns the highest priority to the highest-rate process), the "priority-ceiling-protocol" <ref> [29] </ref> (which handles priority inversion due to blocked resources), "EDF-scheduling" [24] (which dynamically assigns the highest priority to the process with the earliest deadline), "general static-priority-scheduling" [31] (which accounts for offsets, blocking, and deadlines), and a variety of other policies.
Reference: [30] <author> Ada 9X Mapping/Revision Team. </author> <title> Ada 9X Reference Manual, Draft ANSI/ISO Standard, ANSI/ISO/IEC CD 8652. Intermetrics, </title> <publisher> Inc., </publisher> <year> 1993. </year>
Reference-contexts: One may argue whether it's good, bad, ugly, cumbersome, etc., but the fact remains that it is used in many realtime systems. In a large sense, the Ada 9X real-time annex <ref> [30] </ref> simply codified many components of the de facto standard. It supports shared, protected objects (i.e., typed, shared memory segments), asynchronous transfer of control, first-class interrupt handlers and exceptions.
Reference: [31] <author> K. W. Tindell, A. Burns, and A. J. Wellings. </author> <title> An extendible approach for analysing fixed priority hard real-time tasks. </title> <journal> The Journal of Real-Time Systems, </journal> <volume> 6(2) </volume> <pages> 133-152, </pages> <month> March </month> <year> 1994. </year> <month> 28 </month>
Reference-contexts: The "priority group" employs methods like "rate-monotonic scheduling" [24, 21] (which statically assigns the highest priority to the highest-rate process), the "priority-ceiling-protocol" [29] (which handles priority inversion due to blocked resources), "EDF-scheduling" [24] (which dynamically assigns the highest priority to the process with the earliest deadline), "general static-priority-scheduling" <ref> [31] </ref> (which accounts for offsets, blocking, and deadlines), and a variety of other policies. This group argues for an easier design process, cheaper analysis tests, more adaptability, etc. The "time-line group" uses terms like "calendar-based dispatching," "cyclic executive dispatching," [35, 7, 2, 38, 36], etc.
Reference: [32] <author> G. A. Venkatesh. </author> <title> The semantic approach to program slicing. </title> <booktitle> In Proceedings of the ACM SIGPLAN '91 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: Briefly stated, a slice of a program P with respect to a program point p and variable v consists of P 's statements and control predicates that affect v at point p. (See [8] for details on our approach; refer to <ref> [33, 16, 27, 32] </ref> on program slicing in general.) Consider the program in Figure 4 (A), and its two residual slices in Figure 4 (B). Since slice t IO contains all of t 's IO operations, the observable behavior of the transformed task will be semantically identical to the original.
Reference: [33] <author> M. Weiser. </author> <title> Program slicing. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 10 </volume> <pages> 352-357, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: Briefly stated, a slice of a program P with respect to a program point p and variable v consists of P 's statements and control predicates that affect v at point p. (See [8] for details on our approach; refer to <ref> [33, 16, 27, 32] </ref> on program slicing in general.) Consider the program in Figure 4 (A), and its two residual slices in Figure 4 (B). Since slice t IO contains all of t 's IO operations, the observable behavior of the transformed task will be semantically identical to the original.
Reference: [34] <author> V. Wolfe, S. Davidson, and I. Lee. RTC: </author> <title> Language support for real-time concurrency. </title> <booktitle> In Proceedings IEEE Real-Time Systems Symposium, </booktitle> <pages> pages 43-52. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1991. </year>
Reference-contexts: To achieve balance at this point usually requires a costly and arduous process of instrumentation and system tuning. By the time we looked at this problem from a research perspective, two trends had emerged. First, a variety of experimental real-time programming languages had been posited (e.g., <ref> [17, 20, 23, 26, 34, 11] </ref>). While differing in several details, they had converged on a core set of real-time constructs and functionality. Second, there was a proliferation (indeed an explosion) of compiler optimization techniques, designed to take advantage of emerging computer architectures - e.g., RISC, SPMD, VLIW, superscaler, etc.
Reference: [35] <author> J. Xu and D. Parnas. </author> <title> Scheduling processes with release times, deadlines, precedence and exclusion relations. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(3) </volume> <pages> 360-369, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: This group argues for an easier design process, cheaper analysis tests, more adaptability, etc. The "time-line group" uses terms like "calendar-based dispatching," "cyclic executive dispatching," <ref> [35, 7, 2, 38, 36] </ref>, etc. Basically, these terms add up to the same approach amajor frame (or LCM, or hyper-period) is created, and all task instances falling within the frame are sorted to execute non-preemptively. This group argues for more dependability, predictability, less nondeter-minism, etc.
Reference: [36] <author> X. Yuan, M. Saksena, and A. Agrawala. </author> <title> A Decomposition Approach to Real-Time Scheduling. </title> <booktitle> Real-Time Systems, </booktitle> <volume> 6(1), </volume> <year> 1994. </year>
Reference-contexts: This group argues for an easier design process, cheaper analysis tests, more adaptability, etc. The "time-line group" uses terms like "calendar-based dispatching," "cyclic executive dispatching," <ref> [35, 7, 2, 38, 36] </ref>, etc. Basically, these terms add up to the same approach amajor frame (or LCM, or hyper-period) is created, and all task instances falling within the frame are sorted to execute non-preemptively. This group argues for more dependability, predictability, less nondeter-minism, etc.
Reference: [37] <author> N. Zhang, A. Burns, and M. Nicholson. </author> <title> Pipelined processors and worst case execution times. </title> <journal> The Journal of Real-Time Systems, </journal> <volume> 5(4), </volume> <month> October </month> <year> 1993. </year>
Reference-contexts: In [12] a more accurate timing tool is described; it analyzes micro-instruction streams using an abstract architecture description. Getting more refined, the tool described in <ref> [37] </ref> analyzes instruction timings at the pipeline level, and [22] pushes (conservative) analysis to both the cache and pipeline levels. And now, several papers in this workshop present even newer approaches, and we should expect 7 to see further progress along these lines.
Reference: [38] <author> W. Zhao, K. Ramamritham, and J. A. Stankovic. </author> <title> Scheduling Tasks with Resource requirements in a Hard Real-Time System. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-13(5):564-577, </volume> <month> May </month> <year> 1987. </year> <month> 29 </month>
Reference-contexts: This group argues for an easier design process, cheaper analysis tests, more adaptability, etc. The "time-line group" uses terms like "calendar-based dispatching," "cyclic executive dispatching," <ref> [35, 7, 2, 38, 36] </ref>, etc. Basically, these terms add up to the same approach amajor frame (or LCM, or hyper-period) is created, and all task instances falling within the frame are sorted to execute non-preemptively. This group argues for more dependability, predictability, less nondeter-minism, etc.
References-found: 38

