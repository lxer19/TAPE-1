URL: http://www.cs.wisc.edu/~condon/papers/random.ps
Refering-URL: http://www.cs.wisc.edu/~condon/condon.html
Root-URL: 
Title: On Algorithms for Simple Stochastic Games  
Author: Anne Condon 
Address: 1210 West Dayton Street Madison, WI 53706  
Affiliation: Computer Sciences Department University of Wisconsin-Madison  
Abstract: We survey a number of algorithms for the simple stochastic game problem, which is to determine the winning probability of a type of stochastic process, where the transitions are partially controlled by two players. We show that four natural approaches to solving the problem are incorrect, and present two new algorithms for the problem. The first reduces the problem to that of finding a locally optimal solution to a (non-convex) quadratic program with linear constraints. The second extends a technique of Shapley called the successive approximation technique, by using linear programming to maximize the improvement at each approximation step. Finally, we analyze a randomized variant of the Hoffman-Karp strategy improvement algorithm. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Condon, A. </author> <title> The complexity of stochastic games, </title> <journal> Information and Computation, </journal> <volume> 96(2) </volume> <pages> 203-224, </pages> <month> Febru-ary </month> <year> 1992. </year>
Reference-contexts: A simple stochastic game is a restriction of the general stochastic game introduced by Shapley [10] in 1953. Although this problem is known to be in NP " co-NP (Condon <ref> [1] </ref>), no algorithm for the problem is known to run in polynomial time. We conjecture that the problem is in P and are interested in finding a polynomial time algorithm for the problem. <p> Condon <ref> [1] </ref> showed that the SSG problem is polynomial time many-one reducible to the SSG problem where instances are restricted to be stopping games. Hence, a polynomial time algorithm for stopping SSG's also yields a polynomial time algorithm for the unrestricted SSG problem. <p> Also, I Q is invertible, all entries of (I Q) 1 are non-negative and the entries along the diagonal are strictly positive. Uniqueness in the above lemma follows from the assumption that G is a stopping game. A proof can be found in <ref> [1] </ref>. 1.1.2 Optimal Values and Strategies We next summarize properties of the optimal values of a SSG. Shapley [10] (see also [1]) showed that for any node i, max min v ;t (i) = min max v ;t (i): We define the optimal value vector of G to be the vector <p> Uniqueness in the above lemma follows from the assumption that G is a stopping game. A proof can be found in <ref> [1] </ref>. 1.1.2 Optimal Values and Strategies We next summarize properties of the optimal values of a SSG. Shapley [10] (see also [1]) showed that for any node i, max min v ;t (i) = min max v ;t (i): We define the optimal value vector of G to be the vector of optimal values of the nodes of G. <p> Shapley showed that there is a pair of optimal strategies (opt) and t (opt) such that if v is the optimal value vector of the game, then for all i; 1 i n, v (i) = v (opt);t (opt) (i). The following lemma is proved in <ref> [1] </ref>. <p> The previous definition of a (pure) strategy is the special case where all weights are either 0 or 1. Second, we sometimes define a game to have more than two sink nodes. Each sink node has no outgoing edges and has an associated value in the range <ref> [0; 1] </ref>. If a sink node s has value v, then the probability that player 1 wins, given that sink node s is reached, is v. Note that the 0-sink and 1-sink have values 0 and 1, respectively.
Reference: [2] <author> Derman, C. </author> <title> Finite State Markov Decision processes, </title> <publisher> Academic Press, </publisher> <year> 1972. </year>
Reference-contexts: When a SSG game is restricted to just two types of nodes either max and average, or min and average the problem is polynomial time solvable by reduction to linear programming. The proof is due to Derman <ref> [2] </ref>.
Reference: [3] <author> Federgruen, A. </author> <title> Successive approximation methods in undiscounted stochastic games, </title> <journal> Operations Research 1 </journal> <pages> 794-810, </pages> <year> 1980. </year> <month> 17 </month>
Reference-contexts: In these variations, instead of switching all switchable max nodes in obtaining 0 , only one switchable max node is switched. Other relevant surveys of algorithms for stochastic games can be found in Vrieze [15] and Peters and Vrieze [8]. Also Van der Wal [13] and Federgruen <ref> [3] </ref> contain results on convergence rates for successive approximation schemes.
Reference: [4] <author> Filar, J. A. and T. Schultz, </author> <title> Non-linear programming and stationary strategies in stochastic games, </title> <booktitle> Mathematical Programming 35 </booktitle> <pages> 243-247, </pages> <year> 1987. </year>
Reference-contexts: Yet, in the optimal value vector, the value of this min node is 1. Another approach to solving general stochastic game problems is by reduction to mathematical programming problems, usually quadratic programming problems with non-convex objective functions, which are NP-complete. See Schultz [11] or Filar and Schultz <ref> [4] </ref> for a survey of such algorithms. When a SSG game is restricted to just two types of nodes either max and average, or min and average the problem is polynomial time solvable by reduction to linear programming. The proof is due to Derman [2].
Reference: [5] <author> Hoffman, A. and Karp, R. </author> <title> On nonterminating stochastic games, </title> <booktitle> Management Science 12 </booktitle> <pages> 359-370, </pages> <year> 1966. </year>
Reference-contexts: The second extends a technique of Shapley [10], called the successive approximation technique, by using linear programming to maximize the improvement at each approximation step. Finally, we analyze a randomized variant of the Hoffman-Karp strategy improvement algorithm <ref> [5] </ref> and show that the number of iterations required is at most 2 nf (n) + o (2 n ), for any function f (n) = o (n), where n is the number of nodes of the game. The rest of this paper is organized as follows. <p> A third method is known as the strategy improvement method, which was developed first for Markov decision processes, which are simple stochastic games with just max and average nodes, and no min nodes. This method was first proposed by Hoffman and Karp <ref> [5] </ref> for stochastic games.
Reference: [6] <author> Khachiyan, L. G. </author> <title> A polynomial time algorithm for linear programming. </title> <journal> Soviet Math Dokl., </journal> <volume> 20 </volume> <pages> 191-194, </pages> <year> 1979. </year>
Reference-contexts: Khachiyan <ref> [6] </ref> has shown that the linear programming problem is computable in time polynomial in the length of the input, which is 5 polynomial in n in this case. The proof for case (2), where G has just min and average vertices, is very similar.
Reference: [7] <author> Melekopoglou, M. and A. Condon. </author> <title> On the Complexity of the Policy Iteration Algorithm for Simple Stochastic Games, </title> <institution> University of Wisconsin-Madison Computer Sciences Department Technical Report Number 941, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: Each iteration can be executed in polynomial time, by using Derman's linear programming algorithm to find t 0 when 0 is fixed. It is not known if this algorithm requires an exponential number of iterations in the worst case. However, Melekopoglou and Condon <ref> [7] </ref> showed that many variations of the Hoffman-Karp algorithm require exponential time. In these variations, instead of switching all switchable max nodes in obtaining 0 , only one switchable max node is switched.
Reference: [8] <author> Peters, H. J. M and O. J. Vrieze. </author> <title> Surveys in game theory and related topics, </title> <type> CWI Tract 39, </type> <institution> Center for Mathematics and Computer Science, </institution> <address> Amsterdam, </address> <year> 1987. </year>
Reference-contexts: In these variations, instead of switching all switchable max nodes in obtaining 0 , only one switchable max node is switched. Other relevant surveys of algorithms for stochastic games can be found in Vrieze [15] and Peters and Vrieze <ref> [8] </ref>. Also Van der Wal [13] and Federgruen [3] contain results on convergence rates for successive approximation schemes.
Reference: [9] <author> Pollatschek, M. A. and B. Avi-Itzhak. </author> <title> Algorithms for stochastic games with geometrical interpretation, </title> <booktitle> Management Science 15 </booktitle> <pages> 399-415, </pages> <year> 1969. </year>
Reference-contexts: 1.0 (obtain t ) ff1; 3g; f2; 6gg ff3; 8g; f4; 1gg 0.4 0.55 0.4 0.4 0.3 0.55 Table 1: Values of nodes of SSG of Figure 3 in the first two iterations of the Modified Hoffman-Karp Algorithm 2.3 Pollatschek Avi-Itzhak Algorithm This algorithm was proposed by Pollatschek and Avi-Itzhak <ref> [9] </ref> for general stochastic games. It is similar to the Hoffman-Karp algorithm, except that instead of finding optimal strategies at each iteration, it simply modifies both strategies from the previous iteration by switching all switchable nodes. Pollatschek and Avi-Itzhak proved that the method is correct under very strong assumptions.
Reference: [10] <author> Shapley, S. </author> <title> Stochastic games, </title> <booktitle> Proceedings of the National Academy of Sciences, U.S.A, </booktitle> <volume> 39 </volume> <pages> 1095-1100, </pages> <year> 1953. </year>
Reference-contexts: The problem is to find the winning probability of a type of stochastic process where transitions are partially controlled by two players. A simple stochastic game is a restriction of the general stochastic game introduced by Shapley <ref> [10] </ref> in 1953. Although this problem is known to be in NP " co-NP (Condon [1]), no algorithm for the problem is known to run in polynomial time. We conjecture that the problem is in P and are interested in finding a polynomial time algorithm for the problem. <p> We also describe two new (correct) algorithms for the simple stochastic game problem. The first reduces the problem to that of finding a locally optimal solution to a (non-convex) quadratic program with linear constraints. The second extends a technique of Shapley <ref> [10] </ref>, called the successive approximation technique, by using linear programming to maximize the improvement at each approximation step. <p> Uniqueness in the above lemma follows from the assumption that G is a stopping game. A proof can be found in [1]. 1.1.2 Optimal Values and Strategies We next summarize properties of the optimal values of a SSG. Shapley <ref> [10] </ref> (see also [1]) showed that for any node i, max min v ;t (i) = min max v ;t (i): We define the optimal value vector of G to be the vector of optimal values of the nodes of G. <p> This can be generalized to switching sets of nodes. 1.3 Previous Work Shapley <ref> [10] </ref> introduced the stochastic game model in 1953. Since then, numerous variations of Shapley's model have been studied, and many algorithms have been proposed. <p> Naturally, algorithms for the more general models also solve the SSG problem. In this section, we summarize three techniques that have been developed in previous work on general stochastic games, and apply them to our simple model. The first is called successive approximation, introduced by Shapley <ref> [10] </ref>, where a solution to the problem is found from an initial feasible vector, by repeatedly updating the value of each node based on the values of its children.
Reference: [11] <author> Schultz, T. A. </author> <title> Mathematical Programming and Stochastic Games, </title> <publisher> Ph. </publisher> <address> D. </address> <institution> Dissertation, Johns Hop-kins University, Baltimore, Maryland, </institution> <year> 1987. </year>
Reference-contexts: Yet, in the optimal value vector, the value of this min node is 1. Another approach to solving general stochastic game problems is by reduction to mathematical programming problems, usually quadratic programming problems with non-convex objective functions, which are NP-complete. See Schultz <ref> [11] </ref> or Filar and Schultz [4] for a survey of such algorithms. When a SSG game is restricted to just two types of nodes either max and average, or min and average the problem is polynomial time solvable by reduction to linear programming. The proof is due to Derman [2].
Reference: [12] <author> Rao, S. S., Chandrasekaran, R. and Nair, K. P. K. </author> <title> Algorithms for discounted stochastic games, </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 11(6) </volume> <year> 627-637,1973. </year>
Reference-contexts: It is similar to the Hoffman-Karp algorithm, except that instead of finding optimal strategies at each iteration, it simply modifies both strategies from the previous iteration by switching all switchable nodes. Pollatschek and Avi-Itzhak proved that the method is correct under very strong assumptions. Rao, Chandrasekaran 8 and Nair <ref> [12] </ref> gave a proof that the algorithm is correct for a general class of stochastic games. Van Der Wal [14] pointed out that their proof is incorrect and gave a counterexample. His example is a general stochastic game, not a SSG.
Reference: [13] <author> Van Der Wal, J. </author> <title> Discounted Markov games: successive approximations and stopping times, </title> <journal> International Journal of Game Theory, </journal> <volume> 6 </volume> <pages> 11-22, </pages> <year> 1977. </year>
Reference-contexts: In these variations, instead of switching all switchable max nodes in obtaining 0 , only one switchable max node is switched. Other relevant surveys of algorithms for stochastic games can be found in Vrieze [15] and Peters and Vrieze [8]. Also Van der Wal <ref> [13] </ref> and Federgruen [3] contain results on convergence rates for successive approximation schemes.
Reference: [14] <author> Van Der Wal, J. </author> <title> Discounted Markov games: generalized policy iteration method, </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> 25(1) </volume> <year> 125-138,1978. </year>
Reference-contexts: Other relevant surveys of algorithms for stochastic games can be found in Vrieze [15] and Peters and Vrieze [8]. Also Van der Wal [13] and Federgruen [3] contain results on convergence rates for successive approximation schemes. Van der Wal <ref> [14] </ref> describes a variation of the strategy improvement algorithm of Hoffman and Karp in which an approximation to the optimal strategy is found at every step. 2 Incorrect Algorithms In this section, we present four algorithms for the SSG problem. <p> Pollatschek and Avi-Itzhak proved that the method is correct under very strong assumptions. Rao, Chandrasekaran 8 and Nair [12] gave a proof that the algorithm is correct for a general class of stochastic games. Van Der Wal <ref> [14] </ref> pointed out that their proof is incorrect and gave a counterexample. His example is a general stochastic game, not a SSG.
Reference: [15] <author> Vrieze, O.J., </author> <title> Stochastic games with finite state and action spaces, </title> <type> CWI Tract 33, </type> <institution> Center for Mathematics and Computer Science, </institution> <address> Amsterdam, </address> <year> 1987. </year> <month> 18 </month>
Reference-contexts: In these variations, instead of switching all switchable max nodes in obtaining 0 , only one switchable max node is switched. Other relevant surveys of algorithms for stochastic games can be found in Vrieze <ref> [15] </ref> and Peters and Vrieze [8]. Also Van der Wal [13] and Federgruen [3] contain results on convergence rates for successive approximation schemes.
References-found: 15

