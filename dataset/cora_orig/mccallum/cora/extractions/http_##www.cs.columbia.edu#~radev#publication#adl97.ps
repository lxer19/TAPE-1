URL: http://www.cs.columbia.edu/~radev/publication/adl97.ps
Refering-URL: http://www.cs.columbia.edu/~radev/publication/publications.html
Root-URL: http://www.cs.columbia.edu
Email: zkazig@cs.columbia.edu  fsfchang, jrsmithg@ctr.columbia.edu  
Title: Columbia Digital News System An Environment for Briefing and Search over Multimedia Information  
Author: Alfred Aho Shih-Fu Chang Kathleen McKeown Dragomir Radev John Smith and Kazi Zaman faho, kathy, radev, 
Address: New York, NY 10027  New York, NY 10027  
Affiliation: Department of Computer Science Columbia University  Department of Electrical Engineering and Center for Telecommunications Research Columbia University  
Abstract: In this paper we describe an ongoing research project called the Columbia Digital News System. The goal of this project is to develop a suite of effective interoperable tools with which people can find relevant information (text, images, video, and structured documents) from distributed sources and track it over a period of time. Our initial focus is on the development of a system with which researchers, journalists, and students can keep track of current news events in specific areas. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> CIA. </author> <title> The CIA world factbook. </title> <note> URL: http:// www.odci.gov/cia/publications/95fact, 1995. </note>
Reference-contexts: The summary information extracted from the documents can be stored in database templates. In addition, the user may search online for related databases (e.g., in the current news domain, the CIA World Fact Book <ref> [1] </ref> contains relevant information) from which additional information can be gleaned and merged with information from the set of articles for the summary. At the same time, representative images and videos illustrating new information or common content can be selected to be included in the summary. <p> These will provide notification when new information arrives and will extract information from remote sites for summarization. CDNS currently includes tools for access to the CIA Fact Book <ref> [1] </ref> and the George Mason database of terrorist organizations [36], both of which provide information relevant to terrorism and current affairs in general. 5.2 Conceptual Summarization Conceptual summarization requires determining which information from the set of possible extracted information to include in the summary, how to combine information from multiple sources,
Reference: [2] <author> Ralph Grishman, Catherine Macleod, and John Sterling. </author> <title> New York University: Description of the PROTEUS system as used for MUC-4. </title> <booktitle> In Proceedings of the Fourth Message Understanding Conference, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: Currently, summarization is done using templates representing information extracted from the news article using a system developed for the DARPA message understanding conference (MUC) <ref> [2] </ref>. Since the MUC systems only handle South American terrorist news, we also store some hand-constructed templates in the same format for testing purposes. Following receipt of the summary, the user then can search for additional images, here choosing to search for images similar to the map. <p> Currently we are using an information extraction system for the domain of terrorist news articles developed under the DARPA human language technology program, NYU's Proteus system <ref> [2] </ref>. Proteus filters irrelevant sentences from the input articles, and uses parsing and pattern matching techniques to identify event type, location, perpetrator, and victim, among others, building a template representation of the event as shown in Table 1. Coverage of Proteus is limited to South American terrorist activities.
Reference: [3] <author> Dragomir R. Radev and Kathleen R. McKeown. </author> <title> Building a generation knowledge source using internet-accessible newswire. </title> <booktitle> In Proceedings of the 5th Conference on Applied Natural Language Processing, </booktitle> <address> Washington, DC, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: In order to facilitate scaling the system, our work includes development of tools for building resources that can be used for searching, tracking, and summarization. We are developing tools to annotate and catalog images using image features and associated text, tools to extract lexical resources from on-line corpora <ref> [3] </ref>, tools to scan corpora to identify patterns in text not found by information extraction (e.g., role of a person), and are collecting domain ontologies and tools, such as the hierarchies of locations and companies developed for use in the DARPA (Defense Advanced Research Projects Agency) TIPSTER effort (e.g., [4]). 3
Reference: [4] <institution> New Mexico State University CRL. Products and prototypes. </institution> <note> URL: http:// www.nmsu.edu/offer.html, 1996. </note>
Reference-contexts: corpora [3], tools to scan corpora to identify patterns in text not found by information extraction (e.g., role of a person), and are collecting domain ontologies and tools, such as the hierarchies of locations and companies developed for use in the DARPA (Defense Advanced Research Projects Agency) TIPSTER effort (e.g., <ref> [4] </ref>). 3 Knowledge Management The Columbia Digital News System contains a number of tools to help collect, categorize, and classify information. In order to track events of interest, CDNS must be able to identify new information that is related to the user's interests.
Reference: [5] <author> Interpix. </author> <title> Image Surfer. </title> <type> Technical Report http://www.interpix.com/. </type>
Reference-contexts: While other groups have used image collections that were manually annotated with textual key words <ref> [5] </ref>, our work focuses on semi-automatic cataloging through incremental classification into and extension of the taxonomy. This classification can then be subsequently used as an additional constraint on search to improve accuracy. <p> We have developed a new working taxonomy for organizing image and video subject classes. Our WWW image/video cataloging system is unique in that it integrates both the visual features and text keys in visual material detection and classification. There are a few independently developed systems with similar goals <ref> [7, 5] </ref>, but they do not use multimedia features to construct a comprehensive taxonomy like ours. Our system uses both textual information and visual features to derive image/video type and subject classes.
Reference: [6] <author> J. R. Smith and S.-F. Chang. </author> <title> Searching for images and videos on the WorldWide Web. </title> <note> submitted to IEEE multimedia magazine, also cu-ctr technical report 459-96-25, 1996. Demo accessible from URL http://www.ctr.columbia.edu/webseek. </note>
Reference-contexts: In this section, we describe our current prototypes for image and video categorization. 3.1 Cataloging Images and Video Aiming at a truly functional image/video search engine for online information, we have developed a tool called WebSeek <ref> [6] </ref> that issues a series of software agents (called spiders) to traverse the Web, automatically detect visual information, and collect it for automated cataloging and indexing. Taxonomies of knowledge are very useful for organizing, searching, and navigating through large collections of information.
Reference: [7] <author> C. Frankel, M. Swain, and V. Athitsos. Web-Seer: </author> <title> An image search engine for the World Wide Web. </title> <type> Technical Report TR-96-14, </type> <institution> University of Chicago, </institution> <month> July </month> <year> 1996. </year>
Reference-contexts: We have developed a new working taxonomy for organizing image and video subject classes. Our WWW image/video cataloging system is unique in that it integrates both the visual features and text keys in visual material detection and classification. There are a few independently developed systems with similar goals <ref> [7, 5] </ref>, but they do not use multimedia features to construct a comprehensive taxonomy like ours. Our system uses both textual information and visual features to derive image/video type and subject classes.
Reference: [8] <author> D. Zhong, H. Zhang, and S.-F. Chang. </author> <title> Clustering methods for video browsing and annotation. </title> <booktitle> In IS&T/SPIE Symposium on Electronic Imaging: Science and Technology Storage& Retrieval for Image and Video Databases IV, </booktitle> <address> San Jose, CA, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: Visual features are used in automated type mapping, but not in subject mapping. We are investigating new techniques using sophisticated combination of visual features and text features. In <ref> [8] </ref>, we used feature clustering to generate a hierarchical view of a series of video scenes and to detect video scenes with specific semantic content (e.g., anchorperson scenes). Several clustering techniques, such as self-organization maps, isodata, and k-mean, have been applied over various visual features (color, texture, and motion). <p> features, new powerful functionalities are added to the system: * query based on features of visual information * classification of images and video into meaningful semantic classes * browsing and navigation by content through im- age and video archives [15] * automated grouping of visual scenes into visually homogeneous clusters <ref> [8] </ref> Much work in computer vision and pattern recognition has dealt with related problems, such as object segmentation and recognition. Some techniques are suited for generalization to tasks for visual query, such as texture analysis, shape comparison, and face recognition. However, CBVQ has new characteristics and requirements.
Reference: [9] <author> T. P. Minka and R. W. </author> <title> Picard. An image database browser that learns from user interaction. </title> <type> Technical Report 365, </type> <institution> MIT Media Laboratory and Modeling Group Technical Report, </institution> <year> 1996. </year>
Reference-contexts: Consistency relations over various features within each cluster will be measured to assess the association strength of visual features and the semantic classes. Best representative features for different subject classes will be identified through a learning process <ref> [9] </ref>. Mapping of feature clusters to semantic objects will be derived through training and learning. For example, detection of salient objects (people, animals, logos, skylines) and activities may be achieved by optimal selection of features and their dynamic clustering based on the training data and user interaction.
Reference: [10] <author> John S. Justeson and Slava M. Katz. </author> <title> Technical terminology: some linguistic properties and an algorithm for identification in text. </title> <booktitle> Natural Language Engineering, </booktitle> <volume> 1 </volume> <pages> 9-27, </pages> <year> 1995. </year>
Reference-contexts: We are evaluating the use of statistical natural language tools we have developed for identifying key phrases in a textual documents, including tools for extracting technical terms <ref> [10] </ref>, for extracting commonly occurring collocations [11, 12], and for identifying semantically related groups of words [13].
Reference: [11] <author> Frank Smadja and Kathleen R. McKeown. </author> <title> Using collocations for language generation. </title> <journal> Computational Intelligence, </journal> <volume> 7(4), </volume> <month> December </month> <year> 1991. </year>
Reference-contexts: We are evaluating the use of statistical natural language tools we have developed for identifying key phrases in a textual documents, including tools for extracting technical terms [10], for extracting commonly occurring collocations <ref> [11, 12] </ref>, and for identifying semantically related groups of words [13].
Reference: [12] <author> Frank Smadja. </author> <title> Retrieving collocations from text: </title> <journal> Xtract. Computational Linguistics, </journal> <volume> 19(1) </volume> <pages> 143-177, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: We are evaluating the use of statistical natural language tools we have developed for identifying key phrases in a textual documents, including tools for extracting technical terms [10], for extracting commonly occurring collocations <ref> [11, 12] </ref>, and for identifying semantically related groups of words [13].
Reference: [13] <author> Vasileios Hatzivassiloglou and Kathleen R. McK-eown. </author> <title> Towards the automatic identification of adjectival scales: Clustering adjectives according to meaning. </title> <booktitle> In Proceedings of the 31st Annual Meeting of the ACL, </booktitle> <pages> pages 172-182, </pages> <address> Columbus, Ohio, </address> <month> June </month> <year> 1993. </year> <institution> Association for Computational Linguistics. </institution>
Reference-contexts: We are evaluating the use of statistical natural language tools we have developed for identifying key phrases in a textual documents, including tools for extracting technical terms [10], for extracting commonly occurring collocations [11, 12], and for identifying semantically related groups of words <ref> [13] </ref>.
Reference: [14] <author> W. Niblack, R. Barber, W. Equitz, M. Flick-ner, E. Glasman, D. Petkovic, P. Yanker, and C. Faloutsos. </author> <title> The QBIC project: Querying images by content using color, texture, and shape. In Storage and Retrieval for Image and Video Databases, </title> <booktitle> volume SPIE Vol. </booktitle> <year> 1908, </year> <month> February </month> <year> 1993. </year>
Reference-contexts: briefings, users can examine the source documents and pursue an active process of in-depth information exploration. 4.1 Content-Based Visual Query and Search Content-based visual query (CBVQ) techniques provide for the automated assessment of salient visual features such as color, texture, shape, motion, spatial and temporal information contained within visual scenes <ref> [14] </ref>. <p> Data requirements are usually reduced by orders of magnitude (e.g., 10 times reduction in jpeg, 30 times reduction in mpeg). Required space and computation for decoding can be reduced as well. Various visual similarity measurements have been investigated, including quadratic correlation distance and intersection of color histograms <ref> [14, 16] </ref>, Ma-halanobis distance of transformed vectors of texture [17, 18], and distance of absolute spatial orientations [19, 20]. Spatial indexing methods have been used to avoid exhaustive search of the entire collection and computing distance of each feature of every image in the collection [21].
Reference: [15] <author> J. R. Smith and S.-F. Chang. VisualSEEk: </author> <title> a fully automated content-based image query system. </title> <booktitle> In Proc. ACM Intern. Conf. Multimedia, </booktitle> <address> Boston, MA, </address> <month> May </month> <year> 1996. </year> <note> ACM. Demo accessible from URL http://www.ctr.columbia.edu/VisualSEEk. </note>
Reference-contexts: computing the similarities between images and videos using these extracted visual features, new powerful functionalities are added to the system: * query based on features of visual information * classification of images and video into meaningful semantic classes * browsing and navigation by content through im- age and video archives <ref> [15] </ref> * automated grouping of visual scenes into visually homogeneous clusters [8] Much work in computer vision and pattern recognition has dealt with related problems, such as object segmentation and recognition. <p> The associated visual features and their spatial information are compared against the image regions and features in the archive to find the matched results. We have developed efficient algorithms and several CBVQ prototypes. Our early tool, VisualSEEk <ref> [15] </ref>, is a fully automated image query system which supports both localized content query and spatial query. It allows users to specify visual features using a WWW/JAVA graphic interface. Users may specify arbitrarily-shaped regions with different features (e.g., color and texture) and their spatial relationship.
Reference: [16] <author> M. J. Swain and D. H. Ballard. </author> <title> Color index-ing. </title> <journal> International Journal of Computer Vision, </journal> <month> 7:1 </month> <year> 1991. </year>
Reference-contexts: Data requirements are usually reduced by orders of magnitude (e.g., 10 times reduction in jpeg, 30 times reduction in mpeg). Required space and computation for decoding can be reduced as well. Various visual similarity measurements have been investigated, including quadratic correlation distance and intersection of color histograms <ref> [14, 16] </ref>, Ma-halanobis distance of transformed vectors of texture [17, 18], and distance of absolute spatial orientations [19, 20]. Spatial indexing methods have been used to avoid exhaustive search of the entire collection and computing distance of each feature of every image in the collection [21].
Reference: [17] <author> F. Liu and R. W. </author> <title> Picard. Periodicity, direc-tionality, and randomness: Wold features for image modeling and retrieval. </title> <type> Technical Report 320, </type> <institution> MIT Media Laboratory and Modeling Group Technical Report, </institution> <year> 1994. </year>
Reference-contexts: Required space and computation for decoding can be reduced as well. Various visual similarity measurements have been investigated, including quadratic correlation distance and intersection of color histograms [14, 16], Ma-halanobis distance of transformed vectors of texture <ref> [17, 18] </ref>, and distance of absolute spatial orientations [19, 20]. Spatial indexing methods have been used to avoid exhaustive search of the entire collection and computing distance of each feature of every image in the collection [21]. Initial work has been reported for joint CBVQ search and spatial query [22].
Reference: [18] <author> T. Chang and C.-C. Kuo. </author> <title> Texture analysis and classification with tree-structured wavelet transform. </title> <journal> IEEE Trans. Image Processing, </journal> <volume> 3(4), </volume> <month> Oc-tober </month> <year> 1993. </year>
Reference-contexts: Required space and computation for decoding can be reduced as well. Various visual similarity measurements have been investigated, including quadratic correlation distance and intersection of color histograms [14, 16], Ma-halanobis distance of transformed vectors of texture <ref> [17, 18] </ref>, and distance of absolute spatial orientations [19, 20]. Spatial indexing methods have been used to avoid exhaustive search of the entire collection and computing distance of each feature of every image in the collection [21]. Initial work has been reported for joint CBVQ search and spatial query [22].
Reference: [19] <author> H. Samet. </author> <title> The quadtree and related hierarchical data structures. </title> <journal> ACM Computing Surveys, </journal> <volume> 16(2):187 - 260, </volume> <year> 1984. </year>
Reference-contexts: Required space and computation for decoding can be reduced as well. Various visual similarity measurements have been investigated, including quadratic correlation distance and intersection of color histograms [14, 16], Ma-halanobis distance of transformed vectors of texture [17, 18], and distance of absolute spatial orientations <ref> [19, 20] </ref>. Spatial indexing methods have been used to avoid exhaustive search of the entire collection and computing distance of each feature of every image in the collection [21]. Initial work has been reported for joint CBVQ search and spatial query [22].
Reference: [20] <author> S.-K. Chang, Q. Y. Shi, and C. Y. Yan. </author> <title> Iconic indexing by 2-D strings. </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> 9(3):413 - 428, </volume> <month> May </month> <year> 1987. </year>
Reference-contexts: Required space and computation for decoding can be reduced as well. Various visual similarity measurements have been investigated, including quadratic correlation distance and intersection of color histograms [14, 16], Ma-halanobis distance of transformed vectors of texture [17, 18], and distance of absolute spatial orientations <ref> [19, 20] </ref>. Spatial indexing methods have been used to avoid exhaustive search of the entire collection and computing distance of each feature of every image in the collection [21]. Initial work has been reported for joint CBVQ search and spatial query [22].
Reference: [21] <author> C. Faloutsos and K.-I. Lin. </author> <title> FastMap: A fast algorithm for indexing, data mining and visualization of traditional and multimedia datasets. </title> <booktitle> In ACM Proc. Int. Conf. Manag. Data (SIGMOD), </booktitle> <pages> pages 163 - 174, </pages> <year> 1995. </year>
Reference-contexts: Spatial indexing methods have been used to avoid exhaustive search of the entire collection and computing distance of each feature of every image in the collection <ref> [21] </ref>. Initial work has been reported for joint CBVQ search and spatial query [22]. We have developed a powerful technique, binary feature map, in combining feature representation and indexing. Color and texture image regions are represented by a unified binary vector.
Reference: [22] <author> E. G. M. Petrakis and C. Faloutsos. </author> <title> Similarity searching in large image databases. </title> <type> Technical Report 3388, </type> <institution> Department of Computer Science, University of Maryland, </institution> <year> 1995. </year>
Reference-contexts: Spatial indexing methods have been used to avoid exhaustive search of the entire collection and computing distance of each feature of every image in the collection [21]. Initial work has been reported for joint CBVQ search and spatial query <ref> [22] </ref>. We have developed a powerful technique, binary feature map, in combining feature representation and indexing. Color and texture image regions are represented by a unified binary vector. Efficient indexing methods (similar to file inversion) and fast distance comparison can be derived with binary feature vector to greatly reduce computation.
Reference: [23] <author> S. Chawathe, S. Rajaraman, H. Garcia-Molina, and Widom J. </author> <title> Change detection in hierarchically structured information. </title> <booktitle> In Proceedings ACM SIGMOD Symposium. ACM, </booktitle> <year> 1996. </year>
Reference-contexts: We use a part-of-speech tagger to identify the content words in the documents under consideration. The statistical metrics we currently use are based on the number of content words common to the docu ments. For structural differences, we are building on the recent work done at Stanford <ref> [23] </ref> for measuring change detection in hierarchies of objects. The structural properties we employ are based on the grammatical structure of an HTML page as well as other kinds of metadata associated with a document.
Reference: [24] <author> Lisa F. Rau, R. Brandow, and K. Mitze. </author> <title> Domain-independent summarization of news. </title> <booktitle> In Summarizing Text for Intelligent Communication, </booktitle> <pages> pages 71-75, </pages> <address> Dagstuhl, Germany, </address> <year> 1994. </year>
Reference-contexts: This is in contrast to most previous work that summarizes sin gle articles <ref> [24, 25, 26, 27] </ref>. * Summaries must identify how perception of the event changes over time, distinguishing between accounts of the event and the event itself [28]. * Given access to live news, the summarizer must provide an update since the last generated summary, identifying new information and linking its presentation
Reference: [25] <author> Julian M. Kupiec, Jan Pedersen, and Francine Chen. </author> <title> A trainable document summarizer. </title> <editor> In Ed-ward A. Fox, Peter Ingwersen, and Raya Fidel, editors, </editor> <booktitle> Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 68-73, </pages> <address> Seattle, Washington, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: This is in contrast to most previous work that summarizes sin gle articles <ref> [24, 25, 26, 27] </ref>. * Summaries must identify how perception of the event changes over time, distinguishing between accounts of the event and the event itself [28]. * Given access to live news, the summarizer must provide an update since the last generated summary, identifying new information and linking its presentation
Reference: [26] <author> Chris D. Paice and Paul A. Jones. </author> <title> The identification of important concepts in highly structured technical papers. </title> <booktitle> In Proceedings of the 16th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 69-78, </pages> <year> 1993. </year>
Reference-contexts: This is in contrast to most previous work that summarizes sin gle articles <ref> [24, 25, 26, 27] </ref>. * Summaries must identify how perception of the event changes over time, distinguishing between accounts of the event and the event itself [28]. * Given access to live news, the summarizer must provide an update since the last generated summary, identifying new information and linking its presentation
Reference: [27] <author> Hans P. Luhn. </author> <title> The automatic creation of literature abstracts. </title> <journal> IBM Journal, </journal> <pages> pages 159-165, </pages> <year> 1958. </year>
Reference-contexts: This is in contrast to most previous work that summarizes sin gle articles <ref> [24, 25, 26, 27] </ref>. * Summaries must identify how perception of the event changes over time, distinguishing between accounts of the event and the event itself [28]. * Given access to live news, the summarizer must provide an update since the last generated summary, identifying new information and linking its presentation
Reference: [28] <author> Kathleen R. McKeown and Dragomir R. Radev. </author> <title> Generating summaries of multiple news articles. </title> <editor> In Edward A. Fox, Peter Ingwersen, and Raya Fidel, editors, </editor> <booktitle> Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 74-82, </pages> <address> Seattle, Washington, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: This is in contrast to most previous work that summarizes sin gle articles [24, 25, 26, 27]. * Summaries must identify how perception of the event changes over time, distinguishing between accounts of the event and the event itself <ref> [28] </ref>. * Given access to live news, the summarizer must provide an update since the last generated summary, identifying new information and linking its presentation to earlier summaries. Given the multimedia nature of the tracking environment, presentation of tracked information must include more than just textual summaries. <p> Our work builds on our prototype system, SUMMONS <ref> [28] </ref>, which generates summaries of a series of news articles using the set of templates produced by DARPA message understanding systems as input (SUMMONS architecture is shown in Figure 10).
Reference: [29] <author> Kathleen R. McKeown. </author> <title> Text Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text. </title> <booktitle> Studies in Natural Language Processing. </booktitle> <publisher> Cambridge University Press, </publisher> <address> Cambridge, England, </address> <year> 1985. </year>
Reference-contexts: Unlike previous work on summarization, CDNS does not ex-tract sentences from the input articles to serve as the summary. Instead, we use natural language processing techniques to extract structured information from the document and language generation techniques <ref> [29] </ref> to merge information extracted from different documents and form the language of the summary. Our research focus is on problems in the language generation stage.
Reference: [30] <author> Darrin Duford. CREP: </author> <title> a regular expression-matching textual corpus tool. </title> <type> Technical Report CUCS-005-93, </type> <institution> Columbia University, </institution> <year> 1993. </year>
Reference-contexts: Coverage of Proteus is limited to South American terrorist activities. In order to handle common events in current news (e.g., terrorism in the Mid East or the US), we are enhancing this approach using finite-state techniques <ref> [30] </ref> for extraction of the fields in the templates. We have also developed separate pattern matching techniques to extract specific types of information from input text, building domain knowledge sources for use in text generation.
Reference: [31] <author> Michael Elhadad. </author> <title> Using Argumentation to Control Lexical Choice: A Functional Unification Implementation. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Columbia University, </institution> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Descriptions of entities are collected over a period of time to ensure large lexical coverage. Our database contains automatically retrieved descriptions of 2,100 entities at this moment. Once the descriptions of entities have been extracted, they are converted automatically into Functional Descriptions (FD) <ref> [31] </ref> which are fed to the natural language generation component. FDs generated in this way can be reused in summaries and can be manipulated using linguistic techniques. <p> During this process, words are selected to realize the values of the fields. The resulting case frame is passed through syntactic generation, where a full syntactic tree of the sentence is created, grammatical constraints are enforced, and morphological agreement is carried out. We use the FUF/SURGE package <ref> [31, 37] </ref>, a robust grammar of English (SURGE) along with a unification interpreter (FUF) and some text manipulation tools written in Perl as the basis for both word choice and syntactic generation.
Reference: [32] <author> James Shaw. </author> <title> Conciseness through aggregation in text generation. </title> <booktitle> In Proceedings of the 33rd Annual Meeting of the ACL (Student Session), </booktitle> <pages> pages 329-331, </pages> <address> Cambridge, Massachusetts, </address> <month> June </month> <year> 1995. </year> <institution> Association for Computational Linguistics. </institution>
Reference-contexts: By searching through profiles from past news, a description suitable for the summary can be selected. Using language generation techniques such as aggregation (e.g., <ref> [32, 33, 34] </ref>), the exact phrasing of the description may be modified to produce more concise wordings for the summary. For example, two descriptions may merged into a shorter description conveying the same meaning (e.g., "presidents Clinton and Chirac" instead of "president Clin-ton and president Chirac").
Reference: [33] <author> Kathleen McKeown, Jacques Robin, and Karen Kukich. </author> <title> Generating concise natural language summaries. Information Processing and Management, </title> <journal> Special Issue on Summarization, </journal> <volume> 31(5) </volume> <pages> 703-733, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: By searching through profiles from past news, a description suitable for the summary can be selected. Using language generation techniques such as aggregation (e.g., <ref> [32, 33, 34] </ref>), the exact phrasing of the description may be modified to produce more concise wordings for the summary. For example, two descriptions may merged into a shorter description conveying the same meaning (e.g., "presidents Clinton and Chirac" instead of "president Clin-ton and president Chirac").
Reference: [34] <author> Jacques Robin and Kathleen McKeown. </author> <title> Empirically designing and evaluating a new revision-based model for summary generation. </title> <journal> Artificial Intelligence, </journal> <volume> 85, </volume> <month> August </month> <year> 1996. </year> <note> Special Issue on Empirical Methods. </note>
Reference-contexts: By searching through profiles from past news, a description suitable for the summary can be selected. Using language generation techniques such as aggregation (e.g., <ref> [32, 33, 34] </ref>), the exact phrasing of the description may be modified to produce more concise wordings for the summary. For example, two descriptions may merged into a shorter description conveying the same meaning (e.g., "presidents Clinton and Chirac" instead of "president Clin-ton and president Chirac").
Reference: [35] <author> Tim Finin, Rich Fritzson, Don McKay, and Robin McEntire. </author> <title> KQML | a language and protocol for knowledge and information exchange. </title> <type> Technical Report CS-94-02, </type> <institution> Computer Science Department, University of Maryland and Valley Forge Engineering Center, Unisys Corporation, Computer Science Department, University of Maryland, </institution> <address> UMBC, Baltimore, MD 21228, </address> <year> 1994. </year> <note> Accessible from ftp://gopher.cs.umbc.edu/- pub/ARPA/kqml/papers/kbks.ps. </note>
Reference-contexts: For example, two descriptions may merged into a shorter description conveying the same meaning (e.g., "presidents Clinton and Chirac" instead of "president Clin-ton and president Chirac"). In order to tap into nontextual sources, we are building facilitators using KQML as a communication language <ref> [35] </ref> that monitor on-line databases that are available through the World-Wide Web, providing an implementation independent view of the source. These will provide notification when new information arrives and will extract information from remote sites for summarization.
Reference: [36] <institution> The Terrorist Profile Weekly. The TPW terrorist group index. </institution> <address> URL: http://www.site.gmu.edu/~cdibona/- grpindex.html, </address> <year> 1996. </year>
Reference-contexts: These will provide notification when new information arrives and will extract information from remote sites for summarization. CDNS currently includes tools for access to the CIA Fact Book [1] and the George Mason database of terrorist organizations <ref> [36] </ref>, both of which provide information relevant to terrorism and current affairs in general. 5.2 Conceptual Summarization Conceptual summarization requires determining which information from the set of possible extracted information to include in the summary, how to combine information from multiple sources, and how to organize it coherently.
Reference: [37] <author> Jacques Robin. </author> <title> Revision-Based Generation of Natural Language Summaries Providing Historical Background. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Columbia University, </institution> <address> New York, </address> <year> 1994. </year>
Reference-contexts: During this process, words are selected to realize the values of the fields. The resulting case frame is passed through syntactic generation, where a full syntactic tree of the sentence is created, grammatical constraints are enforced, and morphological agreement is carried out. We use the FUF/SURGE package <ref> [31, 37] </ref>, a robust grammar of English (SURGE) along with a unification interpreter (FUF) and some text manipulation tools written in Perl as the basis for both word choice and syntactic generation.
References-found: 37

