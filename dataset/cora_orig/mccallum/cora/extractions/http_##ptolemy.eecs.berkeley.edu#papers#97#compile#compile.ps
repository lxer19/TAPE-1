URL: http://ptolemy.eecs.berkeley.edu/papers/97/compile/compile.ps
Refering-URL: http://ptolemy.eecs.berkeley.edu/papers/97/compile/
Root-URL: 
Title: Compile-Time Scheduling of Dynamic Constructs in Dataflow Program Graphs  
Author: Soonhoi Ha, Member, IEEE and Edward A. Lee, Fellow, IEEE 
Keyword: multiprocessor scheduling, dynamic constructs, profile, macro actor, dataflow program graphs.  
Date: 7, JULY 1997  
Note: 768 IEEE TRANSACTIONS ON COMPUTERS, VOL. 46, NO.  
Abstract: Scheduling dataflow graphs onto processors consists of assigning actors to processors, ordering their execution within the processors, and specifying their firing time. While all scheduling decisions can be made at runtime, the overhead is excessive for most real systems. To reduce this overhead, compile-time decisions can be made for assigning and/or ordering actors on processors. Compile-time decisions are based on known profiles available for each actor at compile time. The profile of an actor such as the execution time and the communication patterns. However, a dynamic construct within a macro actor, such as a conditional and a data-dependent iteration, makes the profile of the actor unpredictable at compile time. For those constructs, we propose to assume some profile at compile-time and define a cost to be minimized when deciding on the profile under the assumption that the runtime statistics are available at compile-time. Our decisions on the profiles of dynamic constructs are shown to be optimal under some bold assumptions, and expected to be near-optimal in most cases. The proposed scheduling technique has been implemented as one of the rapid prototyping facilities in Ptolemy. This paper presents the preliminary results on the performance with synthetic examples. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W.B.Ackerman, </author> <title> "Data Flow Languages", </title> <journal> Computer, </journal> <volume> Vol. 15, No. 2, </volume> <pages> pp. 15-25, </pages> <month> Feb. </month> <year> 1982. </year>
Reference: [2] <author> E.A.Lee and D.G.Messerschmitt, </author> <title> "Synchronous Data Flow", </title> <booktitle> IEEE Proceedings, </booktitle> <month> September, </month> <year> 1987. </year>
Reference: [3] <author> S.Ha and E.A.Lee, </author> <title> "Compile-Time Scheduling and Assignment of Dataflow Program Graphs with Data-Dependent Iteration", </title> <journal> IEEE Trans. Computers, </journal> <month> November, </month> <year> 1991. </year>
Reference-contexts: p (x + 1 + ik) 0 N t T t i=0 Since t is positive, from inequality (5), 1 X p (x + 1 + ik) T 1 X p (x + ik): (6) If k is equal to 1, the above inequality becomes same as inequality (5) in <ref> [3] </ref>, which shows that the previous work is a special case of this more general method. Up to now, we decided the optimal value for x and k for a given number N . How to choose optimal N is the next question we have to answer. <p> Moreover, our experiments show that the search space for N is often reduced significantly using some criteria. Our experiments show that the method is relatively insensitive to the approximated probability mass function for i <ref> [3] </ref>. Using some well-known distributions which have nice mathematical properties for the approximation, we can reduce the summation terms in (3) and (6) to closed forms. Let us consider a geometric probability mass function with parameter q as the approximated distribution of the number of iteration cycles. <p> Similar simplification is possible also with uniform distributions [17]. If k equals to 1, our results coincide with the previous result reported in <ref> [3] </ref>. V. Recursion Recursion is a construct which instantiates itself as a part of the computation if some termination condition is not satisfied. Most high level programming languages support this construct since it makes a program compact and easy to understand.
Reference: [4] <author> E.G.Coffman,Jr., </author> <title> Computer and Job Scheduling Theory, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1976. </year>
Reference: [5] <author> M.J.Gonzalez, </author> <title> "Deterministic Processor Scheduling", </title> <journal> Computing Surveys, </journal> <volume> 9(3), </volume> <month> September, </month> <year> 1977. </year>
Reference: [6] <author> G.C.Sih, </author> <title> "Multiprocessor Scheduling to Account for Interpro-cessor Communications", </title> <type> Ph.D. Thesis, </type> <institution> University of California, Berkeley, </institution> <month> April, </month> <year> 1991. </year>
Reference: [7] <author> S.J.Kim and J.C.Browne, </author> <title> "A General Approach to Mapping of Parallel Computations Upon Multiprocessor Architecture", </title> <booktitle> Int. Conf. on Distributed Computing Systems, </booktitle> <pages> pp. 1-8, </pages> <year> 1988. </year>
Reference: [8] <author> K.Konstantinides, R.T.Kaneshiro, and J.R.Tani, </author> <title> "Task Allocation and Scheduling Models for Multiprocessor Digital Signal Processing", </title> <journal> IEEE Trans. Acoustics, Speech, and Signal Processing, Vol.38, </journal> <volume> No.12, </volume> <pages> pp. 2151-2161, </pages> <month> December, </month> <year> 1990. </year> <journal> Computing Surveys, </journal> <volume> 9(3), </volume> <month> September, </month> <year> 1977. </year>
Reference: [9] <author> G.N.S.Prasanna, A.Agarwal, and B.R.Musicus, </author> <title> "Hierarchical Compilation of Macro Dataflow Graphs for Multiprocessors with Local Memory", </title> <journal> IEEE Trans. on Parallel and Distributed Systems, Vol.5, No.7, </journal> <volume> pp.720-736, </volume> <month> July, </month> <year> 1994. </year>
Reference: [10] <author> E.A.Lee, </author> <title> "Recurrences, Iteration, and Conditionals in Statically Scheduled Block Diagram Languages", VLSI Signal Processing III, </title> <publisher> IEEE Press, </publisher> <year> 1988. </year>
Reference-contexts: Instead, a numerical algorithm is developed. 1. Initially, take the maximum finish time of both branch schedules for each processor according to Lee's method <ref> [10] </ref>. 2. Define ff i = max [0; max j (t ij ^ t j ); 0)]. Initially, all ff i = 0. The variable ff i represents the excessive cost per processor over the expected cost when branch i is selected at run time. <p> Assign all processors to each dynamic con struct Method 2. Assign only one processor to each dynamic construct Method 3. Apply a fully dynamic scheduling ignoring all overhead Method 4. Apply a fully static scheduling Method 1 corresponds to the previous research on quasi-static scheduling technique made by Lee <ref> [10] </ref> and by Loef-fler et. al. [13] for data dependent iterations. Method 2 approximately models the situation when we implement each dynamic construct as a single big atomic actor. To simulate the third model, we list all possible outcomes, each of which can be represented as a data-independent macro actor.
Reference: [11] <author> D.F.Martin and G.Estrin, </author> <title> "Path Length Computation on Graph Models of Computations", </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-18, </volume> <pages> pp. 530-536, </pages> <month> June, </month> <year> 1969. </year>
Reference: [12] <author> M. Granski, I. Korn, and G.M.Silberman, </author> <title> "The Effect of Operation Scheduling on the Performance of a Data Flow Computer", </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-36(9), </volume> <month> September, </month> <year> 1987. </year>
Reference: [13] <author> C.Loe*er, A.Lightenberg, H.Bheda, and G. Moschytz, </author> <title> "Hierarchical Scheduling Systems for Parallel Architectures", </title> <booktitle> Proceedings of Euco, </booktitle> <address> Grenoble, </address> <month> September, </month> <year> 1988. </year>
Reference-contexts: Assign only one processor to each dynamic construct Method 3. Apply a fully dynamic scheduling ignoring all overhead Method 4. Apply a fully static scheduling Method 1 corresponds to the previous research on quasi-static scheduling technique made by Lee [10] and by Loef-fler et. al. <ref> [13] </ref> for data dependent iterations. Method 2 approximately models the situation when we implement each dynamic construct as a single big atomic actor. To simulate the third model, we list all possible outcomes, each of which can be represented as a data-independent macro actor.
Reference: [14] <author> P.A.Suhler, J.Biswas, K.M.Korner, and J.C.Browne, "TDFL: </author> <title> A Task-Level Dataflow Language", </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 9, </volume> <pages> pp. 103-115, </pages> <year> 1990. </year>
Reference: [15] <author> J. Buck, S. Ha, E. A. Lee, and D.G. Messerschmitt, "Ptolemy: </author> <title> A Framework for Simulating and Prototyping Heterogeneous Systems", </title> <journal> International Journal of Computer Simulation Vol. </journal> <volume> 4. </volume> <month> April, </month> <pages> pp. 155-182, </pages> <year> 1994. </year>
Reference-contexts: To obtain the optimal number of assigned processors, we compute the total expected cost for each number and choose the minimum. VII. An Example The proposed technique to schedule data-dependent actors has been implemented in Ptolemy, which is a heterogeneous simulation and prototyping environment being developed in U.C.Berkeley, U.S.A. <ref> [15] </ref>. One of the key objectives of Ptolemy is to allow many different computational models to coexist in the same system. A domain is a set of blocks that obey a common computational model. An example of mixed domain system is shown in figure 9.
Reference: [16] <author> P.Hoang and J.Rabaey, </author> <title> "Program Partitioning for a Reconfigurable Multiprocessor System", </title> <booktitle> IEEE Workshop on VLSI Signal Processing IV, </booktitle> <month> November, </month> <year> 1990. </year>

References-found: 16

