URL: http://www.cs.umn.edu/Users/dept/users/satish/HDFA/final.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/satish/HDFA/
Root-URL: http://www.cs.umn.edu
Title: Hierarchical Data Flow Analysis for OO Programs  
Author: Satish Subramanian Wei-Tek Tsai Shekhar H. Kirani 
Keyword: Data flow analysis, Object-oriented programming, Data flow testing, data flow anomalies.  
Date: August 2, 1994  
Address: Minneapolis, MN-55455  
Affiliation: Department of Computer Science University of Minnesota  
Abstract: The structural difference between the programs written in procedural languages and object oriented (OO) languages makes it imperative to modify the existing data flow analysis techniques to suit the OO paradigm. Here we propose a Hierarchical Data Flow Analysis (HDFA) for OO programs, which exploits the structural hierarchy found in OO programs. The structural hierarchy consists of reusable components, classes, objects and attributes. The HDFA shifts the focus from variables to states of objects as the fundamental unit of data flow analysis. The HDFA can be used to analyze data flow at various levels in the structural hierarchy. Definitions of data flow operators for classes, objects and attributes are defined and used in the HDFA. We also describe the use of this technique to perform data flow testing of OO programs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. E. Allen and J. Cocke. </author> <title> A program data flow analysis procedure. </title> <journal> Communications of the ACM, </journal> <volume> 19(3) </volume> <pages> 137-147, </pages> <year> 1976. </year> <month> 27 </month>
Reference-contexts: In OO 1 programs, the encapsulation of program and data, in the form of objects, has added an extra level of reusability. Data flow analysis is a technique of ascertaining and collecting information about the modification, preservation and use of variables in a computer program <ref> [7, 1] </ref>. In OO programs, objects being the main entities, the need arises to modify the existing data flow analysis techniques to analyze OO programs.
Reference: [2] <author> Colin Atkinson. </author> <title> Object-Oriented Reuse, Concurrency and Distributed -An Ada-Based Approach. </title> <publisher> Addison Wesley Publishing Company, </publisher> <year> 1991. </year>
Reference-contexts: 1 Introduction Object-Oriented (OO) programming paradigm is gaining popularity over traditional imperative programming paradigm because it unifies the principles of modularity, abstraction and information hiding in a simple and natural concept called objects <ref> [6, 10, 2] </ref>. In traditional imperative programming languages, the procedures, macros and library routines have been the primary reusable components. In OO 1 programs, the encapsulation of program and data, in the form of objects, has added an extra level of reusability.
Reference: [3] <author> Jeffrey M. Barth. </author> <title> A practical interprocedural data flow analysis algorithm. </title> <journal> Communications of the ACM, </journal> <volume> 21 </volume> <pages> 724-736, </pages> <year> 1978. </year>
Reference-contexts: So it is not possible to infer the data flow information for the attributes as both methods are mutually dependent on one other. The technique proposed by Barth <ref> [3] </ref> for interprocedural data flow analysis can be used for analyzing the data flow in recursive and cyclic procedure calls. 24 7 Comparison of DFA Techniques In this section we will compare and contrast the proposed HDFA with the existing DFA techniques and also discuss an example in C++ to compare
Reference: [4] <author> Boris Beizer. </author> <title> Software Testing Techniques. </title> <publisher> Van Nostrand Reinhold, </publisher> <address> 2nd edition, </address> <year> 1990. </year>
Reference-contexts: This is the most common form of anomaly. Also a kill of a variable without a preceding definition is also a anomaly. A detailed discussion of anomalies in the usage of variables is discussed in <ref> [4] </ref>. Using the HDFA one can detect anomalies in the usage of classes, objects and attributes. <p> These variables are not instance variables or class variables of the class to which the method belongs. If these local variables are not instances of any class then the conventional data flow anomalies are applicable to them and these can be detected using the conventional data flow testing techniques <ref> [4] </ref>. If these local variables are instances of some class then HDFA has to be used to detect the anomalies in their usage. <p> This is an anomaly because there is no usage of that variable in between the two definitions of the variable <ref> [4] </ref>. The anomalies that result in the usage of local variables can thus be detected using conventional techniques. * Anomalies in the usage of class variables : A state of a class is defined in terms of the states of the class variables and instances of that class.
Reference: [5] <author> Lloyd D. Fosdick and Leon J. Osterweil. </author> <title> Data flow analysis in software reliability. </title> <journal> ACM Computing Surveys, </journal> <volume> 8(3) </volume> <pages> 305-330, </pages> <year> 1976. </year>
Reference-contexts: Data flow testing is the name given to the family of test strategies based on selecting paths through the programs control flow to explore the sequences of events related to the status of data objects <ref> [5, 9] </ref>. When a sequence of unreasonable operations are performed on a data object then an anomaly is said to have occurred in the usage of that object. The HDFA can be used to detect anomalies that occur at various levels in the structural hierarchy.
Reference: [6] <author> Adele Goldberg and David Robson. </author> <title> Smalltalk-80: The Language and Its Implementation. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1983. </year>
Reference-contexts: 1 Introduction Object-Oriented (OO) programming paradigm is gaining popularity over traditional imperative programming paradigm because it unifies the principles of modularity, abstraction and information hiding in a simple and natural concept called objects <ref> [6, 10, 2] </ref>. In traditional imperative programming languages, the procedures, macros and library routines have been the primary reusable components. In OO 1 programs, the encapsulation of program and data, in the form of objects, has added an extra level of reusability. <p> We also discuss the use of this technique for data flow testing of OO programs. 2 OO Paradigm In OO programs, an object consists of attributes and methods <ref> [6] </ref>, that constitute the private memory of the object. The behaviour of the object depends on the class to which is belongs. A message is a request for an object to carry out one of its methods. And the receiver of the message determines how to carry out the method. <p> Three examples are discussed in detail here. Two example programs are written using C++ [10] and the third one is written using Smalltalk <ref> [6] </ref>. 14 5.1 C++ Examples Example 1. <p> And by using the interrelationship between the attribute flow and object flow, we determine that the object s1 is defined in the statement s1.push ('a') because one of its attributes was defined. 5.2 Smalltalk Example Another example from Smalltalk <ref> [6] </ref> is given below to illustrate the data flow of class variables. In the following example, a class Expenditure is defined, which is used to record the amount spend on various activities.
Reference: [7] <author> Matthew S. Hecht. </author> <title> Flow Analysis of Computer Programs. </title> <publisher> Elsevier North-Holland, Inc, </publisher> <year> 1977. </year>
Reference-contexts: In OO 1 programs, the encapsulation of program and data, in the form of objects, has added an extra level of reusability. Data flow analysis is a technique of ascertaining and collecting information about the modification, preservation and use of variables in a computer program <ref> [7, 1] </ref>. In OO programs, objects being the main entities, the need arises to modify the existing data flow analysis techniques to analyze OO programs. <p> Data flow analysis techniques consists of local (statement and intra-block) and global (intra-procedural and inter-procedural) data flow analysis techniques to analyze programs that follow the procedural languages paradigms <ref> [7] </ref>. But in OO programs the data is encapsulated inside objects, in the form of the attributes of the objects, and these can be manipulated only by methods of objects [Fig 1]. <p> data flow of classes (class flow), objects (object flow) and attributes (attribute flow) are defined and are used to analyze the data flow present in OO programs. 3 State and Data Flow Operators In conventional data flow analysis techniques, the state and data flow operators are defined for a variable <ref> [7] </ref>. In this section we discuss the definitions of the state and data flow operators for various levels in the hierarchy that are used in the HDFA. 4 3.1 State Each level in the hierarchy has a state associated with it. The state of an attribute is its value. <p> The state of a class is defined as a set which includes the states of all its class variables and all its instances. 3.2 Data Flow Operators In traditional data flow analysis the operators defined for a variable are Define, Kill/Undefine and Use <ref> [7] </ref>. In OO programs, an object is a collection of data items and thus the definitions of these operators must be modified for objects. 5 The three basic operators used in data flow analysis, namely define, use and kill, are all redefined for each level in the hierarchy.
Reference: [8] <author> Kernighan and Ritchie. </author> <title> The C Programming Language. </title> <publisher> Prentice Hall, </publisher> <address> 2nd edition, </address> <year> 1990. </year>
Reference-contexts: The Table 3 gives a comparison of the existing DFA techniques and the HDFA technique. 7.1 DFA of C++ Programs Since the C++ programming language was an extension of the C programming language <ref> [8] </ref>, the conventional data flow techniques can be applied to 25 Issue Current DFA tech. HDFA tech.
Reference: [9] <author> S. Rapps and E. J. Weyuker. </author> <title> Selecting software test data using data flow information. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 11 </volume> <pages> 367-375, </pages> <year> 1985. </year>
Reference-contexts: Data flow testing is the name given to the family of test strategies based on selecting paths through the programs control flow to explore the sequences of events related to the status of data objects <ref> [5, 9] </ref>. When a sequence of unreasonable operations are performed on a data object then an anomaly is said to have occurred in the usage of that object. The HDFA can be used to detect anomalies that occur at various levels in the structural hierarchy.

References-found: 9

