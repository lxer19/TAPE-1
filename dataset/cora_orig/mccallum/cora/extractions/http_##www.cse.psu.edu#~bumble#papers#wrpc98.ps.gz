URL: http://www.cse.psu.edu/~bumble/papers/wrpc98.ps.gz
Refering-URL: http://www.cse.psu.edu/~bumble/resume.html
Root-URL: http://www.cse.psu.edu
Title: Implementing Parallelism in Random Discrete Event-Driven Simulation  
Author: Marc Bumble and Lee Coraor 
Address: Park PA 16801  
Affiliation: The Pennsylvania State University, University  
Abstract: The inherently sequential nature of random discrete event-driven simulation has made parallel and distributed processing difficult. This paper presents a method of applying Reconfigurable Logic to gain some parallelism in event generation. Field Programmable Gate Arrays (FPGAs) are used to create a flexible and fast environment in which events may be generated according to various statistical models. The method presented accelerates both event generation and the elimination of some blocked events from the Event Queue. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Jerry Banks, John S. Carson II, and Barry L. Nelson. </author> <title> Discrete-Event System Simulation. </title> <booktitle> International Series in Industrial and Systems Engineering. </booktitle> <publisher> Prentice Hall, </publisher> <address> Upper Saddle River, New Jersey 07458, </address> <note> second edition, </note> <year> 1996. </year>
Reference: 2. <author> Marc Bumble and Lee Coraor. </author> <title> Introducing parallelism to event-driven simulation. </title> <booktitle> In Proceedings of the IASTED International Conference-Applied Simulation and Modelling, ASM '97, </booktitle> <address> Banff, Canada, July 27-August 1, </address> <year> 1997. </year> <booktitle> The International Association of Science and Technology for Development, </booktitle> <month> August </month> <year> 1997. </year>
Reference-contexts: Event Generation verse Event Execution Time VII 3 The Acceleration Mechanism The enhanced hardware implementation of the accelerator consists of two parts. The Event Generator mechanism is illustrated in figure 3A <ref> [2] </ref>. The Event Generator creates random events using a pipelined systolic array [6]. Statistical distributions implemented in hardware determine event start and finish times. This work assumes that uniform random numbers are generated in hardware [7].
Reference: 3. <author> Bradly K. Fawcett. </author> <title> Taking advantage of reconfigurable logic. </title> <booktitle> Seventh Annual IEEE International ASIC Conference and Exhibit, </booktitle> <pages> pages 227-230, </pages> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: Event generation is accomplished by a two-dimensional reconfigurable systolic array which allows the two time offsets to be created in parallel. Reconfigurable logic <ref> [3] </ref> boosts the execution speed of event generation by avoiding much of the communications overhead required by parallel processors. The systolic array depicted in figure 3A, pumps data from one processing block to the next at regular intervals, until the data circulates to the Event Queue.
Reference: 4. <author> Richard M. Fujimoto. </author> <title> Parallel discrete event simulation. </title> <journal> In Communications of the ACM, </journal> <volume> volume 33 no. 10, </volume> <pages> pages 30-53. </pages> <publisher> ACM, </publisher> <month> October </month> <year> 1990. </year>
Reference-contexts: The simulation model is then configured and downloaded by the host platform. The initial simulator configuration will remain for the duration of the simulation. 1.2 Sequential Random Discrete Event-Driven Simulations Event-driven simulations typically have three <ref> [4] </ref> basic common denominators. First, they contain a set of state variables which denote the state of the simulation model. The state variables contain information such as the number and availability of system resources. Secondly, a typical random discrete event-driven simulation contains an event list, depicted in figure 1A. <p> Software event-driven simulations often execute several loops. One loop may generate events which arrive based on a specific statistical frequency. The loop repeatedly creates the next simulation event based on an offset from the previous event's start time. A second simulation loop <ref> [4] </ref> generally removes the event with the smallest time-stamp from the event list.
Reference: 5. <author> Donald E. Knuth. </author> <booktitle> The art of computer programming. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1968. </year>
Reference-contexts: The random number generator is composed of the ACG Class from the LibG++ standard library template class. The ACG Class is a variant of a Linear Congruential Generator (Algorithm M) described in <ref> [5] </ref>. The numeric result is permuted with a Fibonacci Additive Congruential Generator (ACG) to get good independence between samples.
Reference: 6. <author> H. T. Kung. </author> <title> Why systolic architectures. </title> <journal> IEEE Computer, </journal> <volume> 15(1) </volume> <pages> 37-46, </pages> <month> January </month> <year> 1982. </year>
Reference-contexts: Event Generation verse Event Execution Time VII 3 The Acceleration Mechanism The enhanced hardware implementation of the accelerator consists of two parts. The Event Generator mechanism is illustrated in figure 3A [2]. The Event Generator creates random events using a pipelined systolic array <ref> [6] </ref>. Statistical distributions implemented in hardware determine event start and finish times. This work assumes that uniform random numbers are generated in hardware [7]. The resulting random values are then used to generate the event start and finish times. <p> Reconfigurable logic was configured to implement adders, multipliers, and a natural logarithm, ln (), functional unit. These functional units are processing elements within the systolic array. The array calculates event arrivals and durations based on the Poisson Distribution. [1][10] The systolic array <ref> [6] </ref> is implemented in reconfigurable logic, which consists of a large collection of flexibly connected elementary logic units. Reconfigurable logic allows the same hardware to implement various statistical distributions according to user preference.
Reference: 7. <author> Sean Monaghan. </author> <title> A gate-level reconfigurable monte carlo processor. </title> <journal> Journal of VLSI Signal Processing, </journal> <volume> 6(2) </volume> <pages> 139-153, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: The Event Generator mechanism is illustrated in figure 3A [2]. The Event Generator creates random events using a pipelined systolic array [6]. Statistical distributions implemented in hardware determine event start and finish times. This work assumes that uniform random numbers are generated in hardware <ref> [7] </ref>. The resulting random values are then used to generate the event start and finish times. The second part of the Acceleration Mechanism splits the Event List of figure 1A into two queues found in figure 1B, the Event Queue and the Event List.
Reference: 8. <author> David M. Nicol. </author> <title> Principles of conservative parallel simulation. </title> <editor> In J. M. Charnes, D. J. Morrice, D. T. Brunner, and J. J. Swain, editors, </editor> <booktitle> Proceedings of the 1996 Winter Simulation Conference, </booktitle> <pages> pages 128-135, </pages> <year> 1996. </year>
Reference-contexts: 1 Introduction Using reconfigurable logic, this study explores a method of accelerating random discrete event-driven simulation. Random discrete event-driven simulation is inherently serial in nature due to its causality <ref> [8] </ref> constraints. In 1987, Reed et al reported that the parallel implementation [of simulations] rarely completes more quickly than the sequential implementation [when distributed simulations are run with a central server network] [9]. However, the benefits of faster simulation execution make parallelism a very attractive pursuit.
Reference: 9. <author> Daniel A. Reed, Allen D. Molony, and Bradley D McCredie. </author> <title> Parallel discrete event simulation: A shared memory approach. </title> <booktitle> Proc of the 1987 ACM SIGMETRICS Conf on Meas and Model of Comput Syst, </booktitle> <volume> 15(1) </volume> <pages> 36-38, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: Random discrete event-driven simulation is inherently serial in nature due to its causality [8] constraints. In 1987, Reed et al reported that the parallel implementation [of simulations] rarely completes more quickly than the sequential implementation [when distributed simulations are run with a central server network] <ref> [9] </ref>. However, the benefits of faster simulation execution make parallelism a very attractive pursuit. Faster simulations could benefit traffic engineers in predicting and accommodating emergency changes in metropolitan traffic models. Analogous applications exist for simulating aerospace traffic and telephone networks.
Reference: 10. <author> Jean Walrand. </author> <title> Communication Networks: A First Course. </title> <publisher> Aksen Associates, Inc., </publisher> <year> 1991. </year>
Reference-contexts: The numeric result is permuted with a Fibonacci Additive Congruential Generator (ACG) to get good independence between samples. The results from the ACG class are then converted to the Poisson distribution by an application of formulas obtained from <ref> [10] </ref> or by the application of additional classes from the LibG++ standard library. A priority V queue, with a running time of O (n*Log (n)), is used to pop the earliest event from the queue. All events have the same priority.
References-found: 10

