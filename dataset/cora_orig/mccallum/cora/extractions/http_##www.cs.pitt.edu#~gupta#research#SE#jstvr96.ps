URL: http://www.cs.pitt.edu/~gupta/research/SE/jstvr96.ps
Refering-URL: http://www.cs.pitt.edu/~gupta/research/testing.html
Root-URL: 
Email: gupta@cs.pitt.edu harrold@cis.ohio-state.edu soffa@cs.pitt.edu  
Title: Program Slicing-Based Regression Testing Techniques  
Author: Rajiv Gupta Mary Jean Harrold Mary Lou Soffa 
Address: Pittsburgh Pittsburgh, PA 15260 Columbus, OH 43210-1277 Pittsburgh, PA 15260  
Affiliation: Dept. of Computer Science Dept. of Computer and Information Science Dept. of Computer Science University of Pittsburgh Ohio State University University of  
Abstract: After changes are made to a previously tested program, a goal of regression testing is to perform retesting based on the modifications while maintaining the same testing coverage as completely retesting the program. We present a novel approach to data ow based regression testing that uses slicing algorithms to explicitly detect definition-use associations that are affected by a program change. An important benefit of our slicing technique is, unlike previous techniques, neither data ow history nor recomputation of data ow for the entire program is required to detect affected definition-use associations. The program changes drive the recomputation of the required partial data ow through slicing. Another advantage is that our technique achieves the same testing coverage with respect to the affected definition-use associations as a complete retest of the program without maintaining a test suite. Thus, the overhead of maintaining and updating a test suite is eliminated. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> A. V. Aho, R. Sethi, and J. D. Ullman, </author> <booktitle> in Compilers, Principles, Techniques, and Tools, </booktitle> <publisher> A ddison-Wesley Publishing Company, </publisher> <address> Massachusetts, </address> <year> 1986. </year>
Reference-contexts: Data Flow Testing Several data ow testing techniques [6, 12, 13] have been developed to assist in detecting program errors. All of these techniques use the data ow information in a program to guide the selection of test data. Traditional data ow analysis techniques <ref> [1] </ref>, based on a control ow graph representation of a program, are used to compute def-use associations. In a control ow graph, each node corresponds to a statement and each edge represents the ow of control between statements.
Reference: 2. <author> S. Bates and S. Horwitz, </author> <title> ``Incremental program testing using program dependence graphs,'' </title> <booktitle> Conference Record of 20st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pp. 384-396, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Existing regression testing techniques identify these indirectly affected def-use associations by either running all tests from the test suite that previously executed through the changed code [9, 10, 19], or using slicing techniques that require prior computation of the data ow information for the program <ref> [2, 18] </ref>. This paper presents a new approach to selective regression testing using the concept of a program slice. <p> Additional details of our slicing algorithm and its use in test generation can be found in references [7, 8]. Another approach to regression testing based on slicing was developed by Bates and Horwitz <ref> [2] </ref>. This approach uses backward slicing algorithms on program dependence graphs to determine the affected parts of a program that require retesting. Following program changes the program dependence graph must be reconstructed before slicing algorithms can be applied for identifying the affected parts of the program.
Reference: 3. <author> L. A. Clarke, A. Podgurski, D. Richardson, and S. Zeil, </author> <title> ``A comparison of data ow path selection criteria,'' </title> <booktitle> Proceedings 8th International Conference on Software Engineering, </booktitle> <pages> pp. 244-251, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: Techniques for selective regression testing that use the data ow in a program to identify program components to retest after changes [9, 10, 14, 19] have been developed. In data ow testing <ref> [3, 6, 12, 13] </ref>, a variable assignment is tested (satisfied) by tests that execute subpaths from the assignment (i.e., definition) to points where the variable's value is used (i.e., use).
Reference: 4. <author> E. Duesterwald, R. Gupta, </author> <title> and M.L. Soffa, ``Interprocedural data ow analysis on demand,'' </title> <booktitle> Proceedings of the 22nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pp. 37-48, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: The first ForwardWalk on variable Y at statement 2 finds the use of Y in statement 4 to yield the def-use association (2,4,Y). Since definition J in statement 4 is affected by the change in Y, ForwardWalk adds (4,J) to OUT <ref> [4] </ref> and continues the traversal to find the def-use association (4,10,J). In the second ForwardWalk, the walk begins with statement 3 and the definitions that reach it, (1,X) and (2,Y). Thus, the initial Pairs consist of (3,X) and (3,Y). <p> The problem of performing partial data ow analysis is also addressed by a demand driven data ow framework described in Reference <ref> [4] </ref>. However, this framework does not apply to analyses that require consideration of control dependence information. Therefore, although the framework could be used to derive the BackwardWalk algorithm, it cannot be used in developing the ForwardWalk algorithm. - 25 - 5.
Reference: 5. <author> J. Ferrante, K. J. Ottenstein, and J. D. Warren, </author> <title> ``The program dependence graph and its use in optimization,'' </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> vol. 9, no. 3, </volume> <pages> pp. 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: This definition of control dependence, given by Ferrante, Ottenstein and Warren <ref> [5] </ref>, is essentially the same as the definition of direct strong control dependence given by Clarke and Podgurski [15]. In Figure 1, the execution of statement 2 depends on statement 1 evaluating to true, whereas the execution of statement 3 depends on statement 1 evaluating to false. <p> The example in Figure 2 demonstrates an application of BackwardWalk to locate the definitions of X that reach statement 7. The algorithm first initializes Worklist to statement 5, the only immediate predecessor of 7. After computing In <ref> [5] </ref> and Out [5], the immediate predecessors of statement 5, the algorithm examines statements 4 and 6. Since statements 4 and 6 define variable X, the traversal stops and BackwardWalk returns statements 4 and 6. <p> The example in Figure 2 demonstrates an application of BackwardWalk to locate the definitions of X that reach statement 7. The algorithm first initializes Worklist to statement 5, the only immediate predecessor of 7. After computing In <ref> [5] </ref> and Out [5], the immediate predecessors of statement 5, the algorithm examines statements 4 and 6. Since statements 4 and 6 define variable X, the traversal stops and BackwardWalk returns statements 4 and 6. <p> Thus, the control dependence information must be computed prior to using ForwardWalk. Control dependencies are efficiently computed for each node in a control ow graph using the post-dominator relation among the nodes <ref> [5] </ref>. For each control ow graph node n, Cd [n] stores the set of nodes on which n is control dependent. A set of nodes AffectedPreds stores the current list of affected predicates.
Reference: 6. <author> P. G. Frankl and E. J. Weyuker, </author> <title> ``An applicable family of data ow testing criteria,'' </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. SE-14, no. 10, </volume> <pages> pp. 1483-1498, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Techniques for selective regression testing that use the data ow in a program to identify program components to retest after changes [9, 10, 14, 19] have been developed. In data ow testing <ref> [3, 6, 12, 13] </ref>, a variable assignment is tested (satisfied) by tests that execute subpaths from the assignment (i.e., definition) to points where the variable's value is used (i.e., use). <p> Background This section overviews data ow testing, the basis of the regression testing technique. The technique also uses control dependence information to identify which affected def-use associations in a program to retest. Thus, this section also briey discusses control dependence. 2.1. Data Flow Testing Several data ow testing techniques <ref> [6, 12, 13] </ref> have been developed to assist in detecting program errors. All of these techniques use the data ow information in a program to guide the selection of test data. <p> Another criterion, all-uses, requires that each definition of a variable be tested on some subpath to each of its uses. Other criteria, such as all-defs, require that fewer def-use associations be tested. For a complete discussion of data ow testing, see references <ref> [6, 16] </ref>. 2.2. Control Dependence To identify def-use associations that may be affected by a program change, the slice-based approach uses control dependence information.
Reference: 7. <author> R. Gupta and M. L. Soffa, </author> <title> ``Employing static information in the generation of test cases ,'' Journal of Software Testing, Verification and Reliability, </title> <journal> vol. </journal> <volume> 3, no. 1, </volume> <pages> pp. 29-48, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: In either case, using the slice reduces the test generation effort since only the input variables on the slice are considered. Additional details of our slicing algorithm and its use in test generation can be found in references <ref> [7, 8] </ref>. Another approach to regression testing based on slicing was developed by Bates and Horwitz [2]. This approach uses backward slicing algorithms on program dependence graphs to determine the affected parts of a program that require retesting.
Reference: 8. <author> R. Gupta and M. L. Soffa, </author> <title> ``A framework for partial data ow analysis,'' </title> <booktitle> Proceedings of International Conference on Software Maintenance, </booktitle> <pages> pp. 4-13, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: In either case, using the slice reduces the test generation effort since only the input variables on the slice are considered. Additional details of our slicing algorithm and its use in test generation can be found in references <ref> [7, 8] </ref>. Another approach to regression testing based on slicing was developed by Bates and Horwitz [2]. This approach uses backward slicing algorithms on program dependence graphs to determine the affected parts of a program that require retesting.
Reference: 9. <author> M. J. Harrold and M. L. Soffa, </author> <title> ``An incremental approach to unit testing during maintenance,'' </title> <booktitle> Proceedings of the International Conference on Software Maintenance, </booktitle> <pages> pp. 362-367, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: This work focuses on the second problem in that it identifies program components to satisfy data ow testing criteria for the changed program. Techniques for selective regression testing that use the data ow in a program to identify program components to retest after changes <ref> [9, 10, 14, 19] </ref> have been developed. In data ow testing [3, 6, 12, 13], a variable assignment is tested (satisfied) by tests that execute subpaths from the assignment (i.e., definition) to points where the variable's value is used (i.e., use). <p> These techniques compute the changed data ow by either (1) incrementally updating the original data ow to agree with the modified code <ref> [9, 10, 19] </ref> or (2) exhaustively computing the data ow for both the original and modified programs and comparing the sets to determine the differences. Thus, these techniques either save data ow information between testing sessions or completely recompute it at the beginning of each session. <p> Existing regression testing techniques identify these indirectly affected def-use associations by either running all tests from the test suite that previously executed through the changed code <ref> [9, 10, 19] </ref>, or using slicing techniques that require prior computation of the data ow information for the program [2, 18]. This paper presents a new approach to selective regression testing using the concept of a program slice.
Reference: 10. <author> M. J. Harrold, </author> <title> ``An approach to incremental testing,'' </title> <institution> Technical Report 89-1 Department of Computer Science, </institution> <type> Ph.D. Thesis, </type> <institution> University of Pittsburgh, </institution> <month> January </month> <year> 1989. </year>
Reference-contexts: This work focuses on the second problem in that it identifies program components to satisfy data ow testing criteria for the changed program. Techniques for selective regression testing that use the data ow in a program to identify program components to retest after changes <ref> [9, 10, 14, 19] </ref> have been developed. In data ow testing [3, 6, 12, 13], a variable assignment is tested (satisfied) by tests that execute subpaths from the assignment (i.e., definition) to points where the variable's value is used (i.e., use). <p> These techniques compute the changed data ow by either (1) incrementally updating the original data ow to agree with the modified code <ref> [9, 10, 19] </ref> or (2) exhaustively computing the data ow for both the original and modified programs and comparing the sets to determine the differences. Thus, these techniques either save data ow information between testing sessions or completely recompute it at the beginning of each session. <p> Existing regression testing techniques identify these indirectly affected def-use associations by either running all tests from the test suite that previously executed through the changed code <ref> [9, 10, 19] </ref>, or using slicing techniques that require prior computation of the data ow information for the program [2, 18]. This paper presents a new approach to selective regression testing using the concept of a program slice.
Reference: 11. <author> S. Horwitz, T. Reps, and D. Binkley, </author> <title> ``Interprocedural slicing using dependence graphs,'' </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> vol. 12, no. 1, </volume> <pages> pp. 26-60, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: This paper presents a new approach to selective regression testing using the concept of a program slice. A backward program slice <ref> [11, 20] </ref> at a program point p for variable v consists of all statements in the program, including conditionals, that might affect the value of v at p, whereas a forward program slice [11] at a program point p for variable v consists of all statements in the program, including conditionals, <p> A backward program slice [11, 20] at a program point p for variable v consists of all statements in the program, including conditionals, that might affect the value of v at p, whereas a forward program slice <ref> [11] </ref> at a program point p for variable v consists of all statements in the program, including conditionals, that might be affected by the value of v at p. The technique uses two slicing algorithms to determine directly and indirectly affected def-use associations.
Reference: 12. <author> B. Korel and J. Laski, </author> <title> ``A tool for data ow oriented program testing,'' </title> <booktitle> ACM Softfair Proceedings, </booktitle> <pages> pp. 35-37, </pages> <month> December </month> <year> 1985. </year>
Reference-contexts: Techniques for selective regression testing that use the data ow in a program to identify program components to retest after changes [9, 10, 14, 19] have been developed. In data ow testing <ref> [3, 6, 12, 13] </ref>, a variable assignment is tested (satisfied) by tests that execute subpaths from the assignment (i.e., definition) to points where the variable's value is used (i.e., use). <p> Background This section overviews data ow testing, the basis of the regression testing technique. The technique also uses control dependence information to identify which affected def-use associations in a program to retest. Thus, this section also briey discusses control dependence. 2.1. Data Flow Testing Several data ow testing techniques <ref> [6, 12, 13] </ref> have been developed to assist in detecting program errors. All of these techniques use the data ow information in a program to guide the selection of test data.
Reference: 13. <author> S. C. Ntafos, </author> <title> ``An evaluation of required element testing strategies,'' </title> <booktitle> Proceedings of 7th International Conference on Software Engineering, </booktitle> <pages> pp. 250-256, </pages> <month> March </month> <year> 1984. </year> <month> - 26 </month> - 
Reference-contexts: Techniques for selective regression testing that use the data ow in a program to identify program components to retest after changes [9, 10, 14, 19] have been developed. In data ow testing <ref> [3, 6, 12, 13] </ref>, a variable assignment is tested (satisfied) by tests that execute subpaths from the assignment (i.e., definition) to points where the variable's value is used (i.e., use). <p> Background This section overviews data ow testing, the basis of the regression testing technique. The technique also uses control dependence information to identify which affected def-use associations in a program to retest. Thus, this section also briey discusses control dependence. 2.1. Data Flow Testing Several data ow testing techniques <ref> [6, 12, 13] </ref> have been developed to assist in detecting program errors. All of these techniques use the data ow information in a program to guide the selection of test data.
Reference: 14. <author> T. J. Ostrand and E. J. Weyuker, </author> <title> ``Using data ow analysis for regression testing,'' </title> <booktitle> Proceedings of Sixth Annual Pacific Northwest Software Quality Conference, </booktitle> <pages> pp. 58-71, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: This work focuses on the second problem in that it identifies program components to satisfy data ow testing criteria for the changed program. Techniques for selective regression testing that use the data ow in a program to identify program components to retest after changes <ref> [9, 10, 14, 19] </ref> have been developed. In data ow testing [3, 6, 12, 13], a variable assignment is tested (satisfied) by tests that execute subpaths from the assignment (i.e., definition) to points where the variable's value is used (i.e., use).
Reference: 15. <author> A. Podgurski and L. Clarke, </author> <title> ``A formal model of program dependences and its implications for software testing, debugging, and maintenance,'' </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 16, no. 9, </volume> <pages> pp. 965-979, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: This definition of control dependence, given by Ferrante, Ottenstein and Warren [5], is essentially the same as the definition of direct strong control dependence given by Clarke and Podgurski <ref> [15] </ref>. In Figure 1, the execution of statement 2 depends on statement 1 evaluating to true, whereas the execution of statement 3 depends on statement 1 evaluating to false. Thus, statements 2 and 3 are control dependent on statement 1.
Reference: 16. <author> S. Rapps and E. J. Weyuker, </author> <title> ``Selecting software test data using data ow information,'' </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. SE-11, no. 4, </volume> <pages> pp. 367-375, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: Another criterion, all-uses, requires that each definition of a variable be tested on some subpath to each of its uses. Other criteria, such as all-defs, require that fewer def-use associations be tested. For a complete discussion of data ow testing, see references <ref> [6, 16] </ref>. 2.2. Control Dependence To identify def-use associations that may be affected by a program change, the slice-based approach uses control dependence information.
Reference: 17. <author> G. Rothermel and M.J. Harrold, </author> <title> ``A safe, efficient algorithm for regression test selection,'' </title> <booktitle> Proceedings of the International Conference on Software maintenance , pp. </booktitle> <pages> 358-367, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: This construction of a program dependence graph requires the exhaustive recomputation of all def-use associations in the program or the incremental update of changed def-use associations based on previous def-use associations. A different approach to regression testing, also based on slicing, was developed by Rothermel and Harrold <ref> [17, 18] </ref>. This approach also uses a program dependence graph representation to identify the changed def-use pairs for regression testing. Unlike the above approaches to slicing, the approach presented in this paper only requires partial data ow analysis following program changes and does not depend on any def-use history.
Reference: 18. <author> G. Rothermel and M.J. Harrold, </author> <title> ``Selecting tests and identifying test coverage requirements for modified software,'' </title> <booktitle> Proceedings of the International Symposium on Software Testing and Analysis, </booktitle> <pages> pp. 169-184, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: Existing regression testing techniques identify these indirectly affected def-use associations by either running all tests from the test suite that previously executed through the changed code [9, 10, 19], or using slicing techniques that require prior computation of the data ow information for the program <ref> [2, 18] </ref>. This paper presents a new approach to selective regression testing using the concept of a program slice. <p> This construction of a program dependence graph requires the exhaustive recomputation of all def-use associations in the program or the incremental update of changed def-use associations based on previous def-use associations. A different approach to regression testing, also based on slicing, was developed by Rothermel and Harrold <ref> [17, 18] </ref>. This approach also uses a program dependence graph representation to identify the changed def-use pairs for regression testing. Unlike the above approaches to slicing, the approach presented in this paper only requires partial data ow analysis following program changes and does not depend on any def-use history.
Reference: 19. <author> A. M. Taha, S. M. Thebut, and S. S. Liu, </author> <title> ``An approach to software fault localization and revalidation based on incremental data ow analysis,'' </title> <booktitle> Proceedings of COMPSAC 89, </booktitle> <pages> pp. 527-534, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: This work focuses on the second problem in that it identifies program components to satisfy data ow testing criteria for the changed program. Techniques for selective regression testing that use the data ow in a program to identify program components to retest after changes <ref> [9, 10, 14, 19] </ref> have been developed. In data ow testing [3, 6, 12, 13], a variable assignment is tested (satisfied) by tests that execute subpaths from the assignment (i.e., definition) to points where the variable's value is used (i.e., use). <p> These techniques compute the changed data ow by either (1) incrementally updating the original data ow to agree with the modified code <ref> [9, 10, 19] </ref> or (2) exhaustively computing the data ow for both the original and modified programs and comparing the sets to determine the differences. Thus, these techniques either save data ow information between testing sessions or completely recompute it at the beginning of each session. <p> Existing regression testing techniques identify these indirectly affected def-use associations by either running all tests from the test suite that previously executed through the changed code <ref> [9, 10, 19] </ref>, or using slicing techniques that require prior computation of the data ow information for the program [2, 18]. This paper presents a new approach to selective regression testing using the concept of a program slice.
Reference: 20. <author> M. Weiser, </author> <title> ``Program slicing,'' </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. SE-10, no. 4, </volume> <pages> pp. 352-357, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: This paper presents a new approach to selective regression testing using the concept of a program slice. A backward program slice <ref> [11, 20] </ref> at a program point p for variable v consists of all statements in the program, including conditionals, that might affect the value of v at p, whereas a forward program slice [11] at a program point p for variable v consists of all statements in the program, including conditionals, <p> The slicing algorithms are efficient in that they detect the def-use associations without requiring either the data ow history or the complete recomputation of data ow for the entire program. These algorithms are based on the approach taken by Weiser <ref> [20] </ref> that uses the control ow graph representation of the program and only requires the computation of partial data ow information. Unlike previous regression testing techniques that require either a test suite or data ow information to select tests for regression testing, this technique explicitly identifies all affected defuse associations. <p> These algorithms are designed based on the approach taken by Weiser for computing slices <ref> [20] </ref>. This approach lets relevant program slices be computed without exhaustively computing the def-use information for the program. This discussion assumes that only scalars are being considered; the technique is easily extended to include arrays by adding a new condition for halting the search along paths. 3.3. <p> Rothermel and Harrold also consider interproce-dural regression testing while in this paper we focus on intraprocedural testing. However, since the slicing algorithms presented in this paper are based on Weiser 's technique <ref> [20] </ref> which handles interprocedural slicing, these algorithms can also be extended to allow interprocedural regression testing. The problem of performing partial data ow analysis is also addressed by a demand driven data ow framework described in Reference [4].
References-found: 20

