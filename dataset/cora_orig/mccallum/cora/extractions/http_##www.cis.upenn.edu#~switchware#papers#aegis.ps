URL: http://www.cis.upenn.edu/~switchware/papers/aegis.ps
Refering-URL: http://www.cis.upenn.edu/~switchware/home.html
Root-URL: 
Title: A Secure and Reliable Bootstrap Architecture  
Author: William A. Arbaugh David J. Farber Jonathan M. Smith 
Date: December 2, 1996  
Affiliation: University of Pennsylvania  
Abstract: In a computer system, the integrity of lower layers is treated as axiomatic by higher layers. Under the presumption that the hardware comprising the machine (the lowest layer) is valid, integrity of a layer can be guaranteed if and only if: (1) the integrity of the lower layers is checked, and (2) transitions to higher layers occur only after integrity checks on them are complete. The resulting integrity "chain" inductively guarantees system integrity. When these conditions are not met, as they typically are not in the bootstrapping (initialization) of a computer system, no integrity guarantees can be made. Yet, these guarantees are increasingly important to diverse applications such as Internet commerce, intrusion detection systems, and "active networks." In this paper, we describe the AEGIS architecture for initializing a computer system. It validates integrity at each layer transition in the bootstrap process. AEGIS also includes a recovery process for integrity check failures, and we show how this results in robust systems. We discuss our prototype implementation for the IBM personal computer (PC) architecture, and show that the cost of such system protection is surprisingly small. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Atkinson, R. J., McDonald, D. L., Phan, B. G., Metz, C. W., and Chin, K. C. </author> <booktitle> Implementation of ipv6 in 4.4 bsd. In Proceedings of the 1996 USENIX Technical Conference (Jan-uary 1996), USENIX, </booktitle> <pages> pp. 113-125. </pages>
Reference-contexts: A failure beyond the BIOS causes the system to boot into a recovery kernel contained on the ROM card. The recovery kernel contacts a "trusted" host through a secure protocol, e.g., IPv6 <ref> [1] </ref>, to recover a verified copy of the failed component. The failed component is then replaced and the system is restarted. The resultant AEGIS boot process is shown in figure 3.
Reference: [2] <author> Bishop, M., and Dilger, M. </author> <title> Checking for race conditions in file accesses. </title> <booktitle> Computing Systems 9, 2 (Spring 1996), </booktitle> <pages> 131-152. </pages>
Reference-contexts: We plan to address this once a full prototype is completed, and will report on the results. As a minimum, we expect to use flaw detection techniques such as those from Bishop <ref> [2] </ref>, Kannan [4], and others to assist in a technical vetting before the actual signing of the component.
Reference: [3] <author> Blaze, M., Feigenbaum, J., and Lacy, J. </author> <title> Decentralized Trust Management. </title> <booktitle> In IEEE Conference on Security and Privacy (May 1996), IEEE. </booktitle> <address> REFERENCES 7 </address>
Reference-contexts: The second assumption is the existence of a cryptographic certificate authority infrastructure in order to bind an identity with a public key. However, there is no restriction on its form, e.g., single trusted authority, hierarchical, web of trust [22] <ref> [3] </ref>. The final assumption is that some trusted source exists for recovery purposes.
Reference: [4] <author> Blum, M., and Kannan, S. </author> <title> Designing programs that check their work. </title> <journal> JACM 42, </journal> <volume> 1 (Jan-uary 1995), </volume> <pages> 269-291. </pages>
Reference-contexts: We plan to address this once a full prototype is completed, and will report on the results. As a minimum, we expect to use flaw detection techniques such as those from Bishop [2], Kannan <ref> [4] </ref>, and others to assist in a technical vetting before the actual signing of the component.
Reference: [5] <author> Clark, P. C. </author> <title> BITS: A Smartcard Protected Operating System. </title> <type> PhD thesis, </type> <institution> George Wash-ington University, </institution> <year> 1994. </year>
Reference-contexts: Yee states that boot ROM modifications may be required, but since a prototype secure boot process was never implemented more implementations questions are raised than answered by his discussion. Clark <ref> [5] </ref> presents a secure boot process for DOS that stores all of the operating system bootstrap code on a PCMCIA card. He does not address the verification of any firmware (system BIOS or expansion cards).
Reference: [6] <author> DOD. </author> <title> Trusted computer system evaluation criteria. </title> <type> Tech. Rep. </type> <institution> DOD 5200.28-STD, Department of Defense, </institution> <month> December </month> <year> 1985. </year>
Reference-contexts: Without such a secure bootstrap the operating system kernel cannot be trusted since it is invoked by an untrusted process. Designers of trusted systems often avoid this problem by including the boot components in the trusted computing base (TCB) <ref> [6] </ref>. That is, the bootstrap steps are explicitly trusted. We believe that this provides a false sense of security to the users of the operating system, and more important, is unnecessary. 1.1 AEGIS We have designed AEGIS, a secure bootstrap process.
Reference: [7] <author> Elischer, J. </author> <type> 386 boot. </type> <institution> /sys/i386/boot/biosboot/README.386, </institution> <month> July </month> <year> 1996. </year> <note> 2.1.5 FreeBSD. </note>
Reference-contexts: Once it finds a bootable disk, it loads the primary boot block into memory and passes control to it. The code contained in the boot block proceeds to load the operating system, or a secondary boot block depending on the operating system [10] <ref> [7] </ref>. Once the BIOS has performed all of its power on tests, it begins searching for expansion card ROMs which are identified in memory by a specific signature. Once a valid ROM signature is found by the BIOS, control is immediately passed to it.
Reference: [8] <author> Engler, D. R., Kaashoek, M. F., and Jr., J. W. O. </author> <title> The operating system kernel as a secure programmable machine. </title> <booktitle> In Proceedings of the Sixth SIGOPS European Workshop (Septem-ber 1994), </booktitle> <pages> pp. 62-67. </pages>
Reference-contexts: An essential presumption of the security arguments for these designs was that system layers underpinning the operating system, whether hardware, firmware, or both, are trusted. We find it surprising, given the great attention paid to operating system security [13] <ref> [8] </ref> that so little attention has been paid to the underpinnings required for secure operation, e.g., a secure bootstrapping phase for these operating systems. Without such a secure bootstrap the operating system kernel cannot be trusted since it is invoked by an untrusted process.
Reference: [9] <author> G. Davida, Y. D., and Matt, B. </author> <title> Defending systems against viruses through cryptographic authentication. </title> <booktitle> In 1989 IEEE Symposium on Security and Privacy (1989), IEEE, </booktitle> <pages> pp. 312-318. </pages>
Reference-contexts: In essence, the trusted software serves as the root of an authentication chain that extends to the operating system and potentially beyond to applica 3 AEGIS ARCHITECTURE 3 tion software [18] <ref> [9] </ref> [15]. A high level depiction of the bootstrap process is shown in figure 1. In the AEGIS boot process, either the operating system kernel is started, or a recovery process is entered in order to repair any integrity failure detected.
Reference: [10] <author> Grimes, R. </author> <title> At386 protected mode bootstrap loader. </title> <address> /sys/i386/boot/biosboot/README.MACH, </address> <month> October </month> <year> 1993. </year> <note> 2.1.5 FreeBSD. </note>
Reference-contexts: Once it finds a bootable disk, it loads the primary boot block into memory and passes control to it. The code contained in the boot block proceeds to load the operating system, or a secondary boot block depending on the operating system <ref> [10] </ref> [7]. Once the BIOS has performed all of its power on tests, it begins searching for expansion card ROMs which are identified in memory by a specific signature. Once a valid ROM signature is found by the BIOS, control is immediately passed to it.
Reference: [11] <author> H artig, H., Kowalski, O., and K uhnhauser, W. </author> <title> The Birlix security architecture. </title> <journal> Journal of Computer Security 2, </journal> <volume> 1 (1993), </volume> <pages> 5-21. </pages>
Reference-contexts: Lampson [12] describes a secure boot model as an example for his authentication calculus. In Lamp-son's model, the entire boot ROM is trusted, and he does not address the verification of expansion cards/ROMs. The Birlix <ref> [11] </ref> Security Architecture proposes a model designed by Michael Gross that is similar to Lampson's. The Birlix model also suffers from the same problems.
Reference: [12] <author> Lampson, B., Abadi, M., and Burrows, M. </author> <title> Authentication in distributed systems: </title> <journal> Theory and practice. ACM Transactions on Computer Systems v10 (November 1992), </journal> <pages> 265-310. </pages>
Reference-contexts: However, 7 CONCLUSIONS 6 the use of a PCMCIA card containing all of the system boot files creates several configuration management problems, e.g., a system upgrade requires the reprogramming of all the cards in circulation. Lampson <ref> [12] </ref> describes a secure boot model as an example for his authentication calculus. In Lamp-son's model, the entire boot ROM is trusted, and he does not address the verification of expansion cards/ROMs. The Birlix [11] Security Architecture proposes a model designed by Michael Gross that is similar to Lampson's.
Reference: [13] <author> M. Branstad, H. Tajalli, F. M., and Dalva, D. </author> <title> Access mediation in a message-passing kernel. </title> <booktitle> In IEEE Conference on Security and Privacy (1989), </booktitle> <pages> pp. 66-71. </pages>
Reference-contexts: An essential presumption of the security arguments for these designs was that system layers underpinning the operating system, whether hardware, firmware, or both, are trusted. We find it surprising, given the great attention paid to operating system security <ref> [13] </ref> [8] that so little attention has been paid to the underpinnings required for secure operation, e.g., a secure bootstrapping phase for these operating systems. Without such a secure bootstrap the operating system kernel cannot be trusted since it is invoked by an untrusted process.
Reference: [14] <author> Maughan, D., Schertler, M., Schneider, M., and Turner, J. </author> <title> Internet security association and key management protocol (isakmp). </title> <type> Internet-draft, </type> <institution> IPSEC Working Group, </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: The current recovery kernel prototype uses IPv6 as a means of recovering replacement files. We intend to switch to the Internet Engineering Task Force's (IETF) Internet Security Association and Key Management Protocol (ISAKMP) <ref> [14] </ref> to allow user choice of a secure protocol. Additionally, the method with which the recovery kernel contacts a host is currently via a fixed address. We hope to develop or use a protocol in which the recovery host's address can be determined when needed.
Reference: [15] <author> Microsoft. Authenticode techonology. </author> <title> Mi-crosoft's Developer Network Library, </title> <month> October </month> <year> 1996. </year>
Reference-contexts: In essence, the trusted software serves as the root of an authentication chain that extends to the operating system and potentially beyond to applica 3 AEGIS ARCHITECTURE 3 tion software [18] [9] <ref> [15] </ref>. A high level depiction of the bootstrap process is shown in figure 1. In the AEGIS boot process, either the operating system kernel is started, or a recovery process is entered in order to repair any integrity failure detected.
Reference: [16] <author> Microsoft. </author> <title> Overview of fat, hpfs, and ntfs file systems. Knowledge Base Article Q100108, </title> <address> Mi-crosoft, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: The user is now free to read and write anywhere on the local disk circumventing any security systems put in place by the "real" boot floppy or the on disk operating system. This problem is described by Mi-crosoft <ref> [16] </ref> as a method of circumventing the Windows NT file system (NTFS). The major shortcoming, however, in using a boot disk is that none of the firmware is verified prior to use.
Reference: [17] <author> Phoenix Technologies, L. </author> <title> System BIOS for IBM PCs, Compatiables, and EISA Computers, 2nd ed. </title> <publisher> Addison Wesley, </publisher> <year> 1991. </year>
Reference-contexts: We have divided this process into four levels of abstraction (see figure 2), which correspond to phases of the bootstrap operation. The first phase is the Power on Self Test or POST <ref> [17] </ref>. POST is invoked in one of four ways: 1. Applying power to the computer automatically invokes POST causing the processor to jump to the entry point indicated by the processor reset vector. 2.
Reference: [18] <author> Pozzo, M. M., and Gray, T. E. </author> <title> A model for the containment of computer viruses. </title> <booktitle> In 1989 IEEE Symposium on Security and Privacy (1989), IEEE, </booktitle> <pages> pp. 312-318. </pages>
Reference-contexts: In essence, the trusted software serves as the root of an authentication chain that extends to the operating system and potentially beyond to applica 3 AEGIS ARCHITECTURE 3 tion software <ref> [18] </ref> [9] [15]. A high level depiction of the bootstrap process is shown in figure 1. In the AEGIS boot process, either the operating system kernel is started, or a recovery process is entered in order to repair any integrity failure detected.
Reference: [19] <author> RSA Data Security, I. </author> <title> Bsafe 3.0 benchmarks. RSA Data Security Engineering Report, </title> <note> 1996. http://www.rsa.com/rsa/developers/bench.htm. </note>
Reference-contexts: In estimating the time of the verification function, V i , we use the BSAFE benchmarks <ref> [19] </ref> for an Intel 90Mhz Pentium computer, shown in table 1. The cost of verification includes time required for computing a MD5 message digest, and the time required to verify the digest against a stored signature. Any signatures embedded in the public key certificate are ignored at the moment.
Reference: [20] <author> Schroeder, M. </author> <title> Engineering a security kernel for multics. </title> <booktitle> In Fifth Symposium on Operating Systems Principles (November 1975), </booktitle> <pages> pp. 125-132. </pages>
Reference-contexts: Thus, any system is only as secure as the foundation upon which it is built. For example, a number of attempts were made in the 1960s and 1970s to produce secure computing systems, using a secure operating system environment as a basis <ref> [20] </ref>. An essential presumption of the security arguments for these designs was that system layers underpinning the operating system, whether hardware, firmware, or both, are trusted.
Reference: [21] <author> Tygar, J., and Yee, B. Dyad: </author> <title> A system for using physically secure coprocessors. </title> <type> Technical Report CMU-CS-91-140R, </type> <institution> Carnegie Mellon University, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: )) = 0:018second t (V 3 (L 4 )) = 0:114seconds: Summing these times gives T 4 = 0:1665seconds which is insignificant compared to the length of time currently needed to bootstrap an IBM PC. 5 Related work The first presentation of a secure boot process was done by Yee <ref> [21] </ref>. In Yee's model, a cryptographic coprocessor is the first to gain control of the system. Unfortunately, this is not possible without a complete architectural revision of most computer systems| even if the coprocessor is tightly coupled.
Reference: [22] <author> Verisign, I. </author> <title> Verisign certification practice statement. </title> <type> Tech. Rep. Version 1.1, </type> <institution> Verisign, Inc., Mountain View, </institution> <address> CA., </address> <month> August </month> <year> 1996. </year>
Reference-contexts: The second assumption is the existence of a cryptographic certificate authority infrastructure in order to bind an identity with a public key. However, there is no restriction on its form, e.g., single trusted authority, hierarchical, web of trust <ref> [22] </ref> [3]. The final assumption is that some trusted source exists for recovery purposes.
Reference: [23] <author> Yee, B. </author> <title> Using Secure Coprocessors. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1994. </year>
Reference-contexts: In Yee's model, a cryptographic coprocessor is the first to gain control of the system. Unfortunately, this is not possible without a complete architectural revision of most computer systems| even if the coprocessor is tightly coupled. Yee expands his discussion of a secure boot in his thesis <ref> [23] </ref>, but he continues to state that the secure coprocessor should control the boot process verifying each component prior to its use.
References-found: 23

