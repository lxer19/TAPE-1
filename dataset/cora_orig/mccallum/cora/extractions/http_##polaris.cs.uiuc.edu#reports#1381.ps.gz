URL: http://polaris.cs.uiuc.edu/reports/1381.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/polaris/rep2.html
Root-URL: http://www.cs.uiuc.edu
Email: blume@csrd.uiuc.edu eigenman@csrd.uiuc.edu  
Title: Symbolic Range Propagation  
Author: William Blume Rudolf Eigenmann 
Date: September 20, 1994  
Address: 1308 W. Main St., Urbana, Illinois 61801-2307  
Affiliation: Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign  
Abstract: Many analyses and transformations in a parallelizing compiler can benefit from the ability to compare arbitrary symbolic expressions. In this paper, we describe how one can compare expressions by using symbolic ranges of variables. A range is a lower and upper bound on a variable. We will also describe how these ranges can be efficiently computed from the program text. Symbolic range propagation has been implemented in Polaris, a parallelizing compiler being developed at the University of Illinois, and is used for symbolic dependence testing, detection of zero-trip loops, determining array sections possibly referenced by an access, and loop iteration-count estimation.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley. </publisher> <address> Reading, MA., </address> <year> 1986. </year>
Reference-contexts: Similarly, if f (x) is monotonically non-increasing, then f (min (a; b)) is transformed into max (f (a); f (b)). The rules for handling expressions with MAXs are similar. As an example, suppose we wish to replace x with [1 : min (10; y)] in d = <ref> [max (x 2 x; x); 1] </ref>. Since the previous example has shown that x 2 x is monotonically non-decreasing, its lower bound is 1 2 1 = 0. Similarly, since x is monotonically non-increasing, its lower bound is min (10; y), which can be rewritten to max (10; y). <p> For each of these phases, mappings of variables to their ranges, (i.e., range dictionaries), are associated with each statement and each control-flow edge of the program unit. In the widening phase, iterative data-flow analysis <ref> [1] </ref> is used to compute the ranges for each statement and control flow-edge of the program. The ranges for all variables for all program entry points is initially defined to be [1 : 1]. <p> They are more accurate in the computation and propagation of affine variable constraints. However, they cannot handle non-affine variable constraints, such as a &lt; b fl c. Another strength in our representation is that our technique can use a sparse data-flow form, such as definition-use chains <ref> [1] </ref> or Static Single Assignment [10], while theirs cannot. Performing range propagation on such a sparse form should greatly increase its efficiency. Tu and Padua [15] also present a symbolic expression comparison and constraint propagation technique, based on an extension of Static Single Assignment form [10].
Reference: [2] <author> Bill Blume, Rudolf Eigenmann, Keith Faigin, John Grout, Jay Hoeflinger, David Padua, Paul Petersen, Bill Pottenger, Lawrence Rauchwerger, Peng Tu, and Stephen Weatherford. </author> <title> Polaris: The Next Generation in Parallelizing Compilers. </title> <booktitle> Proceedings of the Seventh Annual Languages and Compilers for Parallelism Workshop, </booktitle> <address> Portland, Oregon, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: We have also shown that this technique can benefit several passes in a parallelizing compiler. We have implemented range propagation in Polaris, a parallelizing compiler being developed at the University of Illinois <ref> [2] </ref>. Range propagation is currently being used for symbolic data dependence testing by the Range Test [4], detection of zero-trip loops, computation of symbolic range of values that may possibly be referenced by an array access, and estimation of iteration counts of loops.
Reference: [3] <author> William Blume and Rudolf Eigenmann. </author> <title> An Overview of Symbolic Analysis Techniques Needed for the Effective Parallelization of the Perfect Benchmarks. </title> <booktitle> Proceedings of ICPP'94, </booktitle> <address> St. Charles, IL, </address> <year> 1994. </year>
Reference-contexts: 1 Introduction To effectively parallelize real programs, parallelizing compilers need powerful symbolic analysis techniques <ref> [11, 3] </ref>. One of most useful of these techniques is the ability to compare arbitrary symbolic expressions, using constraint information derived from the program [3]. Many transformations in a par-allelizing compiler can benefit from such an ability. <p> 1 Introduction To effectively parallelize real programs, parallelizing compilers need powerful symbolic analysis techniques [11, 3]. One of most useful of these techniques is the ability to compare arbitrary symbolic expressions, using constraint information derived from the program <ref> [3] </ref>. Many transformations in a par-allelizing compiler can benefit from such an ability. Examples are symbolic dependence testing, detection of zero-trip loops, dead-code elimination, determination of array sections referenced by an array access, and loop trip-count estimation.
Reference: [4] <author> William Blume and Rudolf Eigenmann. </author> <title> The Range Test: A Dependence Test for Symbolic, Nonlinear Expressions. </title> <note> To appear in Supercomputing '94, 1994. 14 </note>
Reference-contexts: We will examine two of these examples, symbolic dependence testing and detection of zero-trip loops, in detail. The ability to compare symbolic expressions is probably most useful for symbolic data dependence tests. In fact, two symbolic data dependence tests, the authors' Range Test <ref> [4] </ref> and the Symbolic Banerjee's Inequalities Test as suggested by Haghighat and Polychronopoulos [11], are built upon this ability. <p> We have also shown that this technique can benefit several passes in a parallelizing compiler. We have implemented range propagation in Polaris, a parallelizing compiler being developed at the University of Illinois [2]. Range propagation is currently being used for symbolic data dependence testing by the Range Test <ref> [4] </ref>, detection of zero-trip loops, computation of symbolic range of values that may possibly be referenced by an array access, and estimation of iteration counts of loops.
Reference: [5] <author> Franc~ois Bourdoncle. </author> <title> Abstract Debugging of Higher-Order Imperative Languages. </title> <booktitle> Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 46-55, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: The narrowing operator is used to regain some of the information lost by the widening operator. Our definitions of the narrowing and widening operators were influenced by the operators given by Bourdoncle <ref> [5] </ref>. The range propagation algorithm uses a special range, denoted as &gt;, which represents an undefined value. <p> Although he does propose simple techniques to handle symbolic ranges, our symbolic analysis techniques are superior. (He restricts the bounds of his symbolic ranges to the form &lt; variable &gt; + &lt; constant &gt;.) Bourdoncle <ref> [5] </ref> greatly improves the accuracy of the integer range propagation algorithm by Harrison, through the use of abstract interpretation [8]. Our use of the narrowing operator was influenced by his algorithm. Bourdoncle's algorithm is unable to generate symbolic ranges.
Reference: [6] <author> Thomas E. Cheatham Jr., Glenn H. Holloway, and Judy A. Townley. </author> <title> Symbolic Evaluation and the Analysis of Programs. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-5(4):402-417, </volume> <month> July </month> <year> 1979. </year>
Reference-contexts: These rules are displayed in Table 2. In addition to the range, MIN, or MAX specific simplifications given earlier, we apply conventional symbolic simplification techniques to the expression. These techniques include constant folding, distribution of products-of-sums, and the combination and cancellation of common symbolic terms <ref> [6, 11, 12, 14] </ref>. We also use advanced techniques to simplify expressions containing integer divisions, which were developed by Haghighat [12]. In addition to Haghighat's exact techniques, we use an approximate technique that handles divisions by multiplying them out from the difference range d from Figure 2.
Reference: [7] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Efficient algorithms for finding SCCs and back-edges, and performing topological sorts can be found in <ref> [7] </ref>. As an example, we will compute the replacement order for the RDG graph shown in Figure 4. The algorithm first computes the strongly connected components of the graph, then topologically sorts them into the order (SCC1, SCC2, SCC3, SCC4).
Reference: [8] <author> Partrick Cousot and Radhia Cousot. </author> <title> Abstract Interpretation: A unified Lattice Model for Static Analysis of Programs by Construction or Approximation of Fixpoints. </title> <booktitle> Proceedings of the 4th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 238-252, </pages> <month> January </month> <year> 1977. </year>
Reference-contexts: We have found these heuristics to be effective at preventing exponential expression growth in practice. 3 Propagating ranges The range propagation algorithm centers on the collection and propagation of ranges through a program unit. Abstract interpretation <ref> [8] </ref> is used to compute the ranges for variables at each point of a program unit. <p> simple techniques to handle symbolic ranges, our symbolic analysis techniques are superior. (He restricts the bounds of his symbolic ranges to the form &lt; variable &gt; + &lt; constant &gt;.) Bourdoncle [5] greatly improves the accuracy of the integer range propagation algorithm by Harrison, through the use of abstract interpretation <ref> [8] </ref>. Our use of the narrowing operator was influenced by his algorithm. Bourdoncle's algorithm is unable to generate symbolic ranges. The accuracy of the ranges generated by his (and Harrison's) technique can be improved with our monotonicity replacement method in Section 2.
Reference: [9] <author> Partrick Cousot and Nicolas Halbwachs. </author> <title> Automatic Discovery of Linear Restraints Among Variables of a Program. </title> <booktitle> Proceedings of the 5th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 84-97, </pages> <year> 1978. </year>
Reference-contexts: However, a more accurate result can be achieved for variable modifications caused by a special class of assignment statement called an invertible assignment <ref> [9] </ref>. <p> Our use of the narrowing operator was influenced by his algorithm. Bourdoncle's algorithm is unable to generate symbolic ranges. The accuracy of the ranges generated by his (and Harrison's) technique can be improved with our monotonicity replacement method in Section 2. Cousot and Halbwachs <ref> [9] </ref> presents a different method to compute and propagate constraints through a program. In their technique, sets of constraints between variables are represented as a convex polyhedron in the n-space of variable values.
Reference: [10] <author> Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Kenneth Zadeck. </author> <title> Efficiently Computing Static Single Assignment Form and the Control Dependence Graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: However, they cannot handle non-affine variable constraints, such as a &lt; b fl c. Another strength in our representation is that our technique can use a sparse data-flow form, such as definition-use chains [1] or Static Single Assignment <ref> [10] </ref>, while theirs cannot. Performing range propagation on such a sparse form should greatly increase its efficiency. Tu and Padua [15] also present a symbolic expression comparison and constraint propagation technique, based on an extension of Static Single Assignment form [10]. <p> form, such as definition-use chains [1] or Static Single Assignment <ref> [10] </ref>, while theirs cannot. Performing range propagation on such a sparse form should greatly increase its efficiency. Tu and Padua [15] also present a symbolic expression comparison and constraint propagation technique, based on an extension of Static Single Assignment form [10]. Their technique compares expressions 13 by repeatedly substituting variables with their constant symbolic values until the two expressions differ by only an integer constant. The values to substitute are determined by a demand-driven analysis of the program.
Reference: [11] <author> Mohammad Haghighat and Constantine Polychronopoulos. </author> <title> Symbolic Dependence Analysis for High-Performance Parallelizing Compilers. </title> <booktitle> Parallel and Distributed Computing: Advances in Languages and Compilers for Parallel Processing, </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <pages> pages 310-330, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction To effectively parallelize real programs, parallelizing compilers need powerful symbolic analysis techniques <ref> [11, 3] </ref>. One of most useful of these techniques is the ability to compare arbitrary symbolic expressions, using constraint information derived from the program [3]. Many transformations in a par-allelizing compiler can benefit from such an ability. <p> The ability to compare symbolic expressions is probably most useful for symbolic data dependence tests. In fact, two symbolic data dependence tests, the authors' Range Test [4] and the Symbolic Banerjee's Inequalities Test as suggested by Haghighat and Polychronopoulos <ref> [11] </ref>, are built upon this ability. The Range Test proves that two array accesses do not have a loop-carried dependence by proving that the range of possible values referenced by one access does not overlap with the range of possible values for the other access. <p> A cost analysis of this algorithm will then be performed. 2.1 Algorithm This algorithm assumes that the compiler can manipulate and simplify arbitrary symbolic expressions. Efficient symbolic analysis techniques for parallelizing compilers can be found in <ref> [11, 12, 14] </ref>. <p> These rules are displayed in Table 2. In addition to the range, MIN, or MAX specific simplifications given earlier, we apply conventional symbolic simplification techniques to the expression. These techniques include constant folding, distribution of products-of-sums, and the combination and cancellation of common symbolic terms <ref> [6, 11, 12, 14] </ref>. We also use advanced techniques to simplify expressions containing integer divisions, which were developed by Haghighat [12]. In addition to Haghighat's exact techniques, we use an approximate technique that handles divisions by multiplying them out from the difference range d from Figure 2.
Reference: [12] <author> Mohammad R. Haghighat and Constantine D. Polychronopoulos. </author> <title> Symbolic Program Analysis and Optimization for Parallelizing Compilers. </title> <booktitle> Presented at the 5th Annual Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> New Haven, CT, </address> <month> August 3-5, </month> <year> 1992. </year>
Reference-contexts: A cost analysis of this algorithm will then be performed. 2.1 Algorithm This algorithm assumes that the compiler can manipulate and simplify arbitrary symbolic expressions. Efficient symbolic analysis techniques for parallelizing compilers can be found in <ref> [11, 12, 14] </ref>. <p> These rules are displayed in Table 2. In addition to the range, MIN, or MAX specific simplifications given earlier, we apply conventional symbolic simplification techniques to the expression. These techniques include constant folding, distribution of products-of-sums, and the combination and cancellation of common symbolic terms <ref> [6, 11, 12, 14] </ref>. We also use advanced techniques to simplify expressions containing integer divisions, which were developed by Haghighat [12]. In addition to Haghighat's exact techniques, we use an approximate technique that handles divisions by multiplying them out from the difference range d from Figure 2. <p> These techniques include constant folding, distribution of products-of-sums, and the combination and cancellation of common symbolic terms [6, 11, 12, 14]. We also use advanced techniques to simplify expressions containing integer divisions, which were developed by Haghighat <ref> [12] </ref>. In addition to Haghighat's exact techniques, we use an approximate technique that handles divisions by multiplying them out from the difference range d from Figure 2.
Reference: [13] <author> William H. Harrison. </author> <title> Compiler Analysis of the Value Ranges for Variables. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-3(3):243-250, </volume> <month> May </month> <year> 1977. </year>
Reference-contexts: Since e s, we can simplify this down to O (erv 3 ). 4 Related work The idea for representing program constraints as ranges was first proposed by Harrison <ref> [13] </ref> for array bounds checking and program verification. In his paper, Harrison describes how one can compute the range of integer values that variables can take in a program unit, using data-flow analysis.
Reference: [14] <author> Paul Havlak. </author> <title> Interprocedural Symbolic Analysis. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: A cost analysis of this algorithm will then be performed. 2.1 Algorithm This algorithm assumes that the compiler can manipulate and simplify arbitrary symbolic expressions. Efficient symbolic analysis techniques for parallelizing compilers can be found in <ref> [11, 12, 14] </ref>. <p> These rules are displayed in Table 2. In addition to the range, MIN, or MAX specific simplifications given earlier, we apply conventional symbolic simplification techniques to the expression. These techniques include constant folding, distribution of products-of-sums, and the combination and cancellation of common symbolic terms <ref> [6, 11, 12, 14] </ref>. We also use advanced techniques to simplify expressions containing integer divisions, which were developed by Haghighat [12]. In addition to Haghighat's exact techniques, we use an approximate technique that handles divisions by multiplying them out from the difference range d from Figure 2.
Reference: [15] <author> Peng Tu and David Padua. </author> <title> Demand-Driven Symbolic Analysis. </title> <type> Technical Report 1336, </type> <institution> Univ. of Illinois at Urbana-Champaign, Cntr. for Supercomputing Res. & Dev., </institution> <month> Febraury </month> <year> 1994. </year> <month> 15 </month>
Reference-contexts: Another strength in our representation is that our technique can use a sparse data-flow form, such as definition-use chains [1] or Static Single Assignment [10], while theirs cannot. Performing range propagation on such a sparse form should greatly increase its efficiency. Tu and Padua <ref> [15] </ref> also present a symbolic expression comparison and constraint propagation technique, based on an extension of Static Single Assignment form [10]. Their technique compares expressions 13 by repeatedly substituting variables with their constant symbolic values until the two expressions differ by only an integer constant. <p> By using such a form, we should be able to improve its time complexity to O (erv 2 ), as well as eliminate the practical costs of handling side effects and duplicating ranges. We will also look into demand-driven analysis <ref> [15] </ref>, which should be greatly beneficial for range propagation since several of the compiler transformations which call it need only a few ranges.
References-found: 15

