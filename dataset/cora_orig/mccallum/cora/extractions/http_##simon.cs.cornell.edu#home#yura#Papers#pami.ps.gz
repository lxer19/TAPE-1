URL: http://simon.cs.cornell.edu/home/yura/Papers/pami.ps.gz
Refering-URL: http://simon.cs.cornell.edu/home/yura/Abstracts/pami98-abs.html
Root-URL: 
Title: A Variable Window Approach to Early Vision  on both synthetic and real imagery with ground truth  
Author: Yuri Boykov Olga Veksler Ramin Zabih 
Note: Performance  appears promising.  
Affiliation: Computer Science Department Cornell University  
Abstract: Early vision relies heavily on rectangular windows for tasks such as smoothing and computing correspondence. While rectangular windows are efficient, they yield poor results near object boundaries. We describe an efficient method for choosing an arbitrarily shaped connected window, in a manner which varies at each pixel. Our approach can be applied to many problems, including image restoration and visual correspondence. It runs in linear time, and takes a few seconds on traditional benchmark images. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Barnard. </author> <title> Stochastic stereo matching over scale. </title> <journal> International Journal of Computer Vision, </journal> <volume> 3(1) </volume> <pages> 17-32, </pages> <year> 1989. </year>
Reference-contexts: This assumption is quite common in motion or stereo (e.g., <ref> [1, 10] </ref>), but it is often violated in practice. For example, Cox et al. [6] point out that most of the images in the JISCT collection [3] violate the constant brightness assumption. There are several reasons why the constant brightness assumption is invalid.
Reference: [2] <author> Paul Besl, Jeffrey Birch, and Layne Watson. </author> <title> Robust window operators. </title> <booktitle> In 2nd International Conference on Computer Vision, </booktitle> <pages> pages 591-600, </pages> <year> 1988. </year>
Reference-contexts: Due to the discontinuity, the data comes from a bi-modal population. Conventional statistical methods perform poorly in this situation. In the last decade, a number of authors have addressed this problem using robust statistics <ref> [2, 14] </ref>. Techniques from robust statistics reduce the influence of gross errors (called outliers) in a data set. From the point of view of robust statistics, one set of points in a bi-modal distribution should be classified as outliers and thus disregarded.
Reference: [3] <author> R. Bolles, H. Baker, and M. Hannah. </author> <title> The JISCT stereo evaluation. </title> <booktitle> In DARPA Image Understanding Workshop, </booktitle> <pages> pages 263-274, </pages> <year> 1993. </year>
Reference-contexts: This assumption is quite common in motion or stereo (e.g., [1, 10]), but it is often violated in practice. For example, Cox et al. [6] point out that most of the images in the JISCT collection <ref> [3] </ref> violate the constant brightness assumption. There are several reasons why the constant brightness assumption is invalid. Stereo uses two cameras, and cameras have different internal parameters.
Reference: [4] <author> Yuri Boykov, Olga Veksler, and Ramin Zabih. </author> <title> Disparity component matching for computing visual correspondence. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 470-475, </pages> <year> 1997. </year>
Reference-contexts: In order to withstand noise, statistics must be collected over the pixels in a local window. The shape of this window is of great importance. If the window overlaps fl An early version of this work appeared in <ref> [4] </ref> 1 a discontinuity, and thus contains more than one object, it is difficult to obtain a correct solution. Most algorithms use rectangular windows of fixed size, largely for reasons of efficiency. Such windows poorly model the boundaries of real-world objects.
Reference: [5] <author> Ingemar Cox, Sunita Hingorani, Satish Rao, and Bruce Maggs. </author> <title> A maximum likelihood stereo algorithm. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 63(3) </volume> <pages> 542-567, </pages> <year> 1996. </year>
Reference-contexts: We also provide comparisons against a number of well-known methods, namely: 17 * Kanade and Okotumi's adaptive window scheme [12] * MLMHV <ref> [5] </ref> * Bandpass-filtered L 2 correlation [16] * Normalized correlation [9] We used published parameter settings where available, and otherwise empirically determined the parameters that gave the best results. In section 5.3 we discuss the sensitivity of our method to various parameter settings. <p> We obtained source code for Kanade's method from his web site, and ran it on a 50 MHz SuperSparc. We implemented normalized correlation and bandpass-filtered L 2 ourselves, and the implementations are reasonably optimized (for example they exploit dynamic programming). 29 Method Time MLMHV <ref> [5] </ref> 1.4 Kanade [12] ~ 3600 Normalized correlation 3 Bandpass-filtered L 2 [16] 4 Our method (x4.3.1) 140 Our method (x4.3.2) 4 truth. 6 Future work The work described in this paper has numerous natural extensions. Our current definition of plausibility can be extended in various ways.
Reference: [6] <author> Ingemar Cox, Sebastien Roy, and Sunita Hingorani. </author> <title> Dynamic histogram warping of image pairs for constant image brightness. </title> <booktitle> In IEEE International Conference on Image Processing, </booktitle> <year> 1995. </year> <note> Extended version available as an NEC technical report. </note>
Reference-contexts: This assumption is quite common in motion or stereo (e.g., [1, 10]), but it is often violated in practice. For example, Cox et al. <ref> [6] </ref> point out that most of the images in the JISCT collection [3] violate the constant brightness assumption. There are several reasons why the constant brightness assumption is invalid. Stereo uses two cameras, and cameras have different internal parameters.
Reference: [7] <author> Stuart Geman and Donald Geman. </author> <title> Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 721-741, </pages> <year> 1984. </year>
Reference-contexts: We will provide an empirical comparison of our results with Kanade and Okotumi's in section 5. Another class of solutions are based on global optimization. These methods simultaneously compute a piecewise smooth solution and estimate the discontinuities. The best known such method is Markov Random Fields <ref> [7] </ref>. Unfortunately, MRF's require global optimization of a non-convex objective function, in a space with extremely high dimension.
Reference: [8] <author> Michael Gennert. </author> <title> Brightness-based stereo matching. </title> <booktitle> In 2nd International Conference on Computer Vision, </booktitle> <pages> pages 139-143, </pages> <year> 1988. </year>
Reference-contexts: Bias can be removed by low-pass filtering the images [16], although this loses image detail. Other factors also cause corresponding points to have different intensities. For example, there are changes in illumination and viewing angle, which are extremely difficult to model for arbitrary scenes. Gennert <ref> [8] </ref> proposed a spatially varying gain, which can be justified when the changes in albedo are more important than the changes in reflectance. Shahriar and Yu [15] propose the most general model for this problem.
Reference: [9] <author> Marsha Jo Hanna. </author> <title> Computer Matching of Areas in Stereo Images. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1974. </year>
Reference-contexts: We also provide comparisons against a number of well-known methods, namely: 17 * Kanade and Okotumi's adaptive window scheme [12] * MLMHV [5] * Bandpass-filtered L 2 correlation [16] * Normalized correlation <ref> [9] </ref> We used published parameter settings where available, and otherwise empirically determined the parameters that gave the best results. In section 5.3 we discuss the sensitivity of our method to various parameter settings.
Reference: [10] <author> Berthold Horn and Brian Schunk. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: These problems are ill-posed, and thus cannot be solved without somehow constraining the desired output. Some approaches assume that the answer should be smooth everywhere <ref> [10, 17] </ref>, which causes difficulties near the edges of objects. In practice, most existing methods aggregate information over a fixed, rectangular window. Fixed window approaches yield good results when all the pixels in the window W p come from the same population as the pixel P . <p> This assumption is quite common in motion or stereo (e.g., <ref> [1, 10] </ref>), but it is often violated in practice. For example, Cox et al. [6] point out that most of the images in the JISCT collection [3] violate the constant brightness assumption. There are several reasons why the constant brightness assumption is invalid.
Reference: [11] <author> David Jones and Jitendra Malik. </author> <title> A computational framework for determining stereo correspondence from a set of linear spatial filters. </title> <booktitle> In 2nd European Conference on Computer Vision, </booktitle> <pages> pages 395-410, </pages> <year> 1992. </year>
Reference-contexts: Note that most pixels in W p have the dark intensity. and at corners. Several recent papers <ref> [11, 12, 13] </ref> attempt to overcome these limitations by allowing the size of the window to vary across the image. These methods are still restricted to rectangular windows, and impose significant computational overhead. <p> These methods are still restricted to rectangular windows, and impose significant computational overhead. Little [13] uses correlation with several different rectangular windows, and selects the window that best explains the data. Jones and Malik <ref> [11] </ref> take a similar approach, although image matching is performed via filter banks. Both of these methods also reduce the influence of pixels near the outskirts of the window. Kanade and Okotumi [12] model the distribution of disparity within a window.
Reference: [12] <author> Takeo Kanade and Masatoshi Okutomi. </author> <title> A stereo matching algorithm with an adaptive window: Theory and experiment. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 16(9) </volume> <pages> 920-932, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Note that most pixels in W p have the dark intensity. and at corners. Several recent papers <ref> [11, 12, 13] </ref> attempt to overcome these limitations by allowing the size of the window to vary across the image. These methods are still restricted to rectangular windows, and impose significant computational overhead. <p> Jones and Malik [11] take a similar approach, although image matching is performed via filter banks. Both of these methods also reduce the influence of pixels near the outskirts of the window. Kanade and Okotumi <ref> [12] </ref> model the distribution of disparity within a window. They perform a greedy search of the space of rectangular windows, in order to minimize the uncertainty of their estimate. We will provide an empirical comparison of our results with Kanade and Okotumi's in section 5. <p> We also provide comparisons against a number of well-known methods, namely: 17 * Kanade and Okotumi's adaptive window scheme <ref> [12] </ref> * MLMHV [5] * Bandpass-filtered L 2 correlation [16] * Normalized correlation [9] We used published parameter settings where available, and otherwise empirically determined the parameters that gave the best results. In section 5.3 we discuss the sensitivity of our method to various parameter settings. <p> We obtained source code for Kanade's method from his web site, and ran it on a 50 MHz SuperSparc. We implemented normalized correlation and bandpass-filtered L 2 ourselves, and the implementations are reasonably optimized (for example they exploit dynamic programming). 29 Method Time MLMHV [5] 1.4 Kanade <ref> [12] </ref> ~ 3600 Normalized correlation 3 Bandpass-filtered L 2 [16] 4 Our method (x4.3.1) 140 Our method (x4.3.2) 4 truth. 6 Future work The work described in this paper has numerous natural extensions. Our current definition of plausibility can be extended in various ways.
Reference: [13] <author> Jim Little. </author> <title> Accurate early detection of discontinuities. </title> <booktitle> In Vision Interface, </booktitle> <pages> pages 97-102, </pages> <year> 1992. </year>
Reference-contexts: Note that most pixels in W p have the dark intensity. and at corners. Several recent papers <ref> [11, 12, 13] </ref> attempt to overcome these limitations by allowing the size of the window to vary across the image. These methods are still restricted to rectangular windows, and impose significant computational overhead. <p> Several recent papers [11, 12, 13] attempt to overcome these limitations by allowing the size of the window to vary across the image. These methods are still restricted to rectangular windows, and impose significant computational overhead. Little <ref> [13] </ref> uses correlation with several different rectangular windows, and selects the window that best explains the data. Jones and Malik [11] take a similar approach, although image matching is performed via filter banks. Both of these methods also reduce the influence of pixels near the outskirts of the window.
Reference: [14] <author> Peter Meer, Doron Mintz, Azriel Rosenfeld, and Dong Yoon Kim. </author> <title> Robust regression methods for computer vision: A review. </title> <journal> International Journal of Computer Vision, </journal> <volume> 6(1) </volume> <pages> 59-70, </pages> <year> 1991. </year>
Reference-contexts: Due to the discontinuity, the data comes from a bi-modal population. Conventional statistical methods perform poorly in this situation. In the last decade, a number of authors have addressed this problem using robust statistics <ref> [2, 14] </ref>. Techniques from robust statistics reduce the influence of gross errors (called outliers) in a data set. From the point of view of robust statistics, one set of points in a bi-modal distribution should be classified as outliers and thus disregarded.
Reference: [15] <author> Shahriar Negahdaripour and Chih-Ho Yu. </author> <title> A generalized brightness change model for computing optical flow. </title> <booktitle> In 4th International Conference on Computer Vision, </booktitle> <pages> pages 2-11, </pages> <year> 1993. </year>
Reference-contexts: For example, there are changes in illumination and viewing angle, which are extremely difficult to model for arbitrary scenes. Gennert [8] proposed a spatially varying gain, which can be justified when the changes in albedo are more important than the changes in reflectance. Shahriar and Yu <ref> [15] </ref> propose the most general model for this problem. They allow gain and bias to vary smoothly over the image, and solved for gain, bias and disparity simultaneously. They explicitly assume that the gain, bias and disparity are constant in a square window of fixed size surrounding each pixel. <p> They explicitly assume that the gain, bias and disparity are constant in a square window of fixed size surrounding each pixel. Our method can be extended to handle changes in brightness in two ways. Both extensions permit gain and bias to vary over the image, as does <ref> [15] </ref>. However, we use variable windows instead of fixed ones. Our extensions differ in terms of the model for brightness change, and in terms of computational complexity.
Reference: [16] <author> Masatoshi Okutomi and Takeo Kanade. </author> <title> A multiple baseline stereo. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(4) </volume> <pages> 353-363, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: The difference between two cameras can be modeled as a linear transformation of intensities I = g I 0 + b, where we will call the multiplier g the gain and the offset b the bias. Bias can be removed by low-pass filtering the images <ref> [16] </ref>, although this loses image detail. Other factors also cause corresponding points to have different intensities. For example, there are changes in illumination and viewing angle, which are extremely difficult to model for arbitrary scenes. <p> We also provide comparisons against a number of well-known methods, namely: 17 * Kanade and Okotumi's adaptive window scheme [12] * MLMHV [5] * Bandpass-filtered L 2 correlation <ref> [16] </ref> * Normalized correlation [9] We used published parameter settings where available, and otherwise empirically determined the parameters that gave the best results. In section 5.3 we discuss the sensitivity of our method to various parameter settings. <p> We implemented normalized correlation and bandpass-filtered L 2 ourselves, and the implementations are reasonably optimized (for example they exploit dynamic programming). 29 Method Time MLMHV [5] 1.4 Kanade [12] ~ 3600 Normalized correlation 3 Bandpass-filtered L 2 <ref> [16] </ref> 4 Our method (x4.3.1) 140 Our method (x4.3.2) 4 truth. 6 Future work The work described in this paper has numerous natural extensions. Our current definition of plausibility can be extended in various ways.
Reference: [17] <author> Tomaso Poggio, Vincent Torre, and Christof Koch. </author> <title> Computational vision and regularization theory. </title> <journal> Nature, </journal> <volume> 317 </volume> <pages> 314-319, </pages> <year> 1985. </year>
Reference-contexts: These problems are ill-posed, and thus cannot be solved without somehow constraining the desired output. Some approaches assume that the answer should be smooth everywhere <ref> [10, 17] </ref>, which causes difficulties near the edges of objects. In practice, most existing methods aggregate information over a fixed, rectangular window. Fixed window approaches yield good results when all the pixels in the window W p come from the same population as the pixel P .
Reference: [18] <author> Peter Rousseeuw and Annick Leroy. </author> <title> Robust Regression and Outlier Detection. </title> <address> New York: </address> <publisher> Wiley, </publisher> <year> 1987. </year>
Reference-contexts: From the point of view of robust statistics, one set of points in a bi-modal distribution should be classified as outliers and thus disregarded. Robust methods are evaluated in terms of their breakdown point, which determines the percentage of outliers they can tolerate (see <ref> [18] </ref> for a formal definition). Optimal methods such as Least Median Squares [18] have a breakdown point of just under 50%, and this cannot be improved upon under general assumptions. 1 These methods thus fail when the correct solution is in the minority, as illustrated in figure 1. <p> Robust methods are evaluated in terms of their breakdown point, which determines the percentage of outliers they can tolerate (see <ref> [18] </ref> for a formal definition). Optimal methods such as Least Median Squares [18] have a breakdown point of just under 50%, and this cannot be improved upon under general assumptions. 1 These methods thus fail when the correct solution is in the minority, as illustrated in figure 1.
Reference: [19] <author> Charles Stewart. MINPRAN: </author> <title> A new robust estimator for computer vision. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17(10) </volume> <pages> 925-938, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: This situation is very common at the boundaries of objects 1 Stewart <ref> [19] </ref> gives one example of how to achieve a higher breakdown point by making assumptions about the distributions of outliers. 3 P light pixels' intensity. Note that most pixels in W p have the dark intensity. and at corners.
Reference: [20] <author> Richard Szeliski and Geoffrey Hinton. </author> <title> Solving random-dot stereograms using the heat equation. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 284-288, </pages> <year> 1985. </year>
Reference-contexts: Thus the running time of the first step is O (nm). The second step of our method is to consider each disparity in turn; in this respect, our solution resembles diffusion <ref> [20] </ref>. For the disparity d, we compute connected components among pixels plausible for d. This immediately gives us W p (d) for any pixel P for which the disparity d is plausible.
Reference: [21] <author> Robert Tarjan. </author> <title> Depth first search and linear graph algorithms. </title> <journal> SIAM Journal on Computing, </journal> <volume> 1(2) </volume> <pages> 146-160, </pages> <year> 1972. </year> <month> 34 </month>
Reference-contexts: For a fixed pixel P , the window W p (i) is precisely the connected component containing P . Connected components can be computed in O (n) time <ref> [21] </ref>, so the running time of the second step is O (nm). The third step is to assign an intensity to each pixel P . We select the i that maximizes the size of W p (i).
References-found: 21

