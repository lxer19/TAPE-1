URL: http://www.ri.cmu.edu/afs/cs/project/sensor-9/ftp/papers/graded.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs/project/sensor-9/ftp/papers/
Root-URL: 
Title: Gas Identification System using Graded Temperature Sensor and Neural Net Interpretation  
Author: Lanwai Wong, Toshikazu Takemori, and M. W. Siegel 
Date: May 1997  
Address: Pittsburgh, PA 15213  
Affiliation: Intelligent Sensors Laboratory The Robotics Institute Carnegie Mellon University  
Note: Copyright 1997 Carnegie Mellon University  
Pubnum: CMU-RI-TR-20-89  
Abstract-found: 0
Intro-found: 1
Reference: 1. <author> Murakami, Takabata and Seiyama, </author> <title> ``Selective Detection of CO by SnO 2 Gas Sensor Using Periodic Temperature Change'', </title> <booktitle> Proceedings of the 1987 Meeting, IEEE - Transducers'87, 4th International Conference on Solid-State Sensors and Actuators, </booktitle> <month> June </month> <year> 1987, </year> <pages> pp. 618-21, </pages> <address> Figaro #213 type CO Gas Sensor </address>
Reference: 2. <author> H. D. </author> <title> Block, ``The Perceptron: A Model for Brain Functioning'', </title> <journal> Reviews of Modern Physics, </journal> <volume> Vol. 34, No. 1, </volume> <month> January </month> <year> 1962, </year> <pages> pp. 123-35. </pages>
Reference: 3. <editor> David E. Rumelhard, James L. McClelland, et al, </editor> <booktitle> Parallel Distributed Processing, </booktitle> <publisher> The MIT Press, </publisher> <address> Cambridge MA, </address> <note> Vol. 1, </note> <year> 1988. </year>
Reference-contexts: Then a set of training data (in a demonstration of this sort a subset of the experimental data) is presented to the input units of the network. The weights and thresholds are adjusted by the back propagation <ref> [3] </ref> learning algorithm until the outputs converge on the known input classifications. The result of a classification is interpreted by a decision rule that relates the numerical outputs of the top layer to a set of symbolic descriptions of the systems activating the inputs, e.g., "methanol/ethanol mixture".
Reference: 4. <author> B. S. Hoffheins, R. J. Lauf, M. W. Siegel, </author> <title> ``Intelligent Thick Film Gas Sensor'', </title> <journal> Hybrid Circuits, </journal> <volume> Vol. 14, </volume> <month> September </month> <year> 1987, </year> <pages> pp. 8-12, </pages> <note> Invited by journal editor. </note>
Reference: 5. <author> M. W. Siegel, R. J. Lauf, and B. S. Hoffheins, </author> <title> ``Dual Gradient Thick-Film Metal Oxide Gas Sensors'', </title> <booktitle> Proceedings of the Tokyo meeting, </booktitle> <volume> Transducers '87, </volume> <month> June </month> <year> 1987, </year> <pages> pp. 599-604. </pages>
Reference: 6. <author> B. S. Hoffheins, R. J. Lauf, M. W. Siegel, </author> <title> ``Intelligent Thick Film Gas Sensor'', </title> <booktitle> Proceedings of the Atlanta Meeting, International Society for Hybrid Microelectronics, </booktitle> <month> October </month> <year> 1986. </year>
Reference: 7. <author> Frank Rosenblatt, </author> <title> Principles of Neurodynamics, </title> <publisher> Spartan Books, </publisher> <address> Washington DC, </address> <year> 1962. </year>
Reference-contexts: introduction are characteristic of the sensor. 7 Data Interpretation A three-layered neural network, the simplest non-trivial implementation <ref> [7, 8] </ref>, is investigated for data interpretation with our integrated thick film sensor. It has one input layer, one hidden layer, and one output layer. The topology of this neural network is illustrated in Figure 5.
Reference: 8. <author> Marvin Minsky and Seymour Pappert, </author> <title> Perceptrons, </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1969. </year> <note> i </note>
Reference-contexts: introduction are characteristic of the sensor. 7 Data Interpretation A three-layered neural network, the simplest non-trivial implementation <ref> [7, 8] </ref>, is investigated for data interpretation with our integrated thick film sensor. It has one input layer, one hidden layer, and one output layer. The topology of this neural network is illustrated in Figure 5.
References-found: 8

