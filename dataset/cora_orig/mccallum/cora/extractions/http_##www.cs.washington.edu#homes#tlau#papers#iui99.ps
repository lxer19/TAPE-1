URL: http://www.cs.washington.edu/homes/tlau/papers/iui99.ps
Refering-URL: http://www.cs.washington.edu/homes/tlau/
Root-URL: http://www.cs.washington.edu
Title: Programming by Demonstration: An Inductive Learning Formulation  
Author: Tessa A. Lau and Daniel S. Weld 
Keyword: Programming by Demonstration, machine learning, inductive logic programming, version spaces  
Note: ftlau,  
Address: Seattle, WA 98195-2350  
Affiliation: Department of Computer Science and Engineering University of Washington  
Email: weldg@cs.washington.edu  
Date: October 7, 1998  
Abstract: Although Programming by Demonstration (PBD) has the potential to improve the productivity of unsophisticated users, previous PBD systems have used brittle, heuristic, domain-specific approaches to execution-trace generalization. In this paper we define two application-independent methods for performing generalization that are based on well-understood machine learning technology. TGen vs uses version-space generalization, and TGen foil is based on the FOIL inductive logic programming algorithm. We analyze each method both theoretically and empirically, arguing that TGen vs has lower sample complexity, but TGen foil can learn a much more interesting class of programs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Bauer. </author> <title> Acquisition of Abstract Plan Descriptions for Plan Recognition. </title> <booktitle> In Proc. 15th Nat. Conf. AI, </booktitle> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: Plan recognition [21, 5] typically requires a large library of possible plans which are checked against user actions. This work may be viewed as inductive learning with a very strong bias (the plan library). Bauer <ref> [1] </ref> presents algorithms for constructing plan libraries from a corpus of logged user traces and optional action models. Weida and Litman [25] use terminological sub-sumption with temporal constraint networks to match execution sequences with library plans.
Reference: [2] <author> William W. Cohen. </author> <title> Grammatically biased learning: learning logic programs using an explicit antecedent description language. </title> <journal> Artificial Intelligence, </journal> <volume> 68 </volume> <pages> 303-366, </pages> <year> 1994. </year>
Reference-contexts: of scalability: prioritizing literals in order to direct the heuristic search down more promising paths; increasing the search bias by using FOCL [20] to give the learner background information about previous tasks or likely loop lengths; increasing bias by encoding command-argument agreement constraints as a grammar and learning with GRENDEL <ref> [2] </ref>; or asking the user to disambiguate between several equally likely (to the learner) alternatives. Other machine learning algorithms may prove better suited to PBD than either version spaces or inductive logic programming. Explanation-based generalization might use models of action preconditions and effects to learn from a single example.
Reference: [3] <author> Allen Cypher. Eager: </author> <title> Programming repetitive tasks by demonstration. </title> <editor> In Allen Cypher, editor, </editor> <title> Watch What I Do: </title> <booktitle> Programming by Demonstration, </booktitle> <pages> pages 205-217. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: In contrast, we define two robust, application-independent methods for performing generalization based on well-understood machine learning technology: * Version-space generalization (TGen vs ) * Inductive logic programming (TGen foil ) We theoretically and empirically analyze these two implemented systems, offering a rational reconstruction of aspects of the Eager <ref> [3] </ref> PBD system. TGen vs can learn with fewer examples, but TGen foil can learn a much more interesting class of programs, such as programs with variable-length loop iterations. For example, TGen foil quickly learns a program equivalent to the one shown above from the training examples shown. <p> Although prior PBD systems have made significant contributions to both of these components, our work is restricted to trace generalization so we focus on that aspect in this discussion. Cypher [4] describes many PBD systems. The Eager <ref> [3] </ref> system detects and automates repetitive actions in Hypercard applications. Each user action is compared against the action history using a pattern-matching scheme. Once the system detects a repetitive sequence, it highlights its prediction of the next action, and offers to automate the remainder of the sequence. <p> Example 2: Consider the following simple execution trace adapted from the Eager paper <ref> [3] </ref> in which a horizontal line separates the loop iterations. <p> In contrast, we implement PBD trace generalization as an inductive learning problem, raising the possibility of a robust, domain-independent method for applying PBD to any application. We have developed two prototypes, TGen vs and TGen foil , and tested them in an email context motivated by Eager <ref> [3] </ref>. Both systems learn quickly; TGen vs has generally lower sample complexity due to a strong conjunctive bias, but TGen foil learns variable length conditional loops which frustrate TGen vs . TGen foil learns nontrivial programs with as few as four iterations.
Reference: [4] <author> Allen Cypher, </author> <title> editor. Watch What I Do: Program--ming by Demonstration. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: While this type of customization allows a user the most control, it also requires programming experience and knowledge of the potentially complex scripting language and application interface. Programming by Demonstration (PBD) <ref> [4] </ref> aims to combine the simple interface of macros with the expressiveness of a scripting language. Like a macro recorder, PBD allows users to construct a program by simply performing actions in the user interface with which they are already familiar. <p> The interaction manager, on the other hand, explains the generalization to the user and obtains authorization for program execution. Although prior PBD systems have made significant contributions to both of these components, our work is restricted to trace generalization so we focus on that aspect in this discussion. Cypher <ref> [4] </ref> describes many PBD systems. The Eager [3] system detects and automates repetitive actions in Hypercard applications. Each user action is compared against the action history using a pattern-matching scheme.
Reference: [5] <author> H. Kautz. </author> <title> A Formal Theory Of Plan Recognition. </title> <type> PhD thesis, </type> <institution> University of Rochester, </institution> <year> 1987. </year>
Reference-contexts: Nevill-Manning and Witten [16, 17] describe a linear-time algorithm for detecting hierarchical structure in sequences by generalizing a grammar from repeated subsequences in a single example. Their algorithm is elegantly simple, but it is not obvious how to apply background knowledge to bias the generated grammars. Plan recognition <ref> [21, 5] </ref> typically requires a large library of possible plans which are checked against user actions. This work may be viewed as inductive learning with a very strong bias (the plan library).
Reference: [6] <author> David Kurlander. </author> <title> Chimera: Example-Based Graphical Editing. </title> <editor> In Allen Cypher, editor, </editor> <title> Watch What I Do: </title> <booktitle> Programming by Demonstration, </booktitle> <pages> pages 270-290. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: It uses a set of condition-action rules to determine when to infer constraints over widget placement and iterations over sequences. Cima [12] learns text editing commands by example; it relies on user hints, rather than multiple examples, to disambiguate possible programs. Chimera <ref> [6] </ref> generalizes constraints between graphical objects from multiple snapshots and provides a macro-by-example facility for creating macros in a graphical editing domain. Tinker [10] supports programming Lisp by demonstration, but performs no inference, instead relying on the user to disambiguate the examples.
Reference: [7] <author> N. Kushmerick, D. Weld, and R. Doorenbos. </author> <title> Wrapper Induction for Information Extraction. </title> <booktitle> In Proc. 15th Int. Joint Conf. AI, </booktitle> <year> 1997. </year>
Reference-contexts: Since machine learning algorithms are often sensitive to the available attributes, it is important to experiment with alternate ontologies and representations. A propositional learner might be able to handle actions as training examples if given a vocabulary of program templates (this approach has been successfully applied to wrapper induction <ref> [7] </ref>). Another open question is how our system should deal with noisy data. Both of our implementations would be confused if the user inserted an irrelevant action or switched the order of two actions in subsequent iterations | even if the ordering is unimportant.
Reference: [8] <author> Neal Lesh and Oren Etzioni. </author> <title> A sound and fast goal recognizer. </title> <booktitle> In Proc. 14th Int. Joint Conf. AI, </booktitle> <pages> pages 1704-1710, </pages> <year> 1995. </year>
Reference-contexts: Bauer [1] presents algorithms for constructing plan libraries from a corpus of logged user traces and optional action models. Weida and Litman [25] use terminological sub-sumption with temporal constraint networks to match execution sequences with library plans. Lesh and Et-zioni <ref> [8, 9] </ref> adapt the version space algorithm to perform goal recognition with an implicit plan-library representation which is constructed by reasoning about action preconditions and effects. Our work is similar to previous machine learning efforts at developing self-customizing software.
Reference: [9] <author> Neal Lesh and Oren Etzioni. </author> <title> Scaling up goal recognition. </title> <booktitle> In Proc. 5th Int. Conf. Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 178-189, </pages> <year> 1996. </year>
Reference-contexts: Bauer [1] presents algorithms for constructing plan libraries from a corpus of logged user traces and optional action models. Weida and Litman [25] use terminological sub-sumption with temporal constraint networks to match execution sequences with library plans. Lesh and Et-zioni <ref> [8, 9] </ref> adapt the version space algorithm to perform goal recognition with an implicit plan-library representation which is constructed by reasoning about action preconditions and effects. Our work is similar to previous machine learning efforts at developing self-customizing software.
Reference: [10] <author> Henry Lieberman. Tinker: </author> <title> A Programming by Demonstration System for Beginning Programmers. </title> <editor> In Allen Cypher, editor, </editor> <title> Watch What I Do: </title> <booktitle> Programming by Demonstration, </booktitle> <pages> pages 49-64. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: Cima [12] learns text editing commands by example; it relies on user hints, rather than multiple examples, to disambiguate possible programs. Chimera [6] generalizes constraints between graphical objects from multiple snapshots and provides a macro-by-example facility for creating macros in a graphical editing domain. Tinker <ref> [10] </ref> supports programming Lisp by demonstration, but performs no inference, instead relying on the user to disambiguate the examples. These PBD systems all rely on heuristic rules to describe when a generalization is appropriate.
Reference: [11] <editor> Pattie Maes and Robyn Kozierok. </editor> <booktitle> Learning interface agents. In Proceedings of AAAI-93, </booktitle> <pages> pages 459-465, </pages> <year> 1993. </year>
Reference-contexts: Schlim-mer and Hermens [24] describe a note-taking system that predicts what the user is going to write and fa cilitates completion; the system works by learning a finite state machine (FSM) modeling note syntax and decision tree classifiers for each FSM state. Maes and Kozierok <ref> [11] </ref> use nearest-neighbor learning (adjusted by user feedback) to predict the user's next action from the action most recently executed, but in contrast to our work there is no attempt to learn loops.
Reference: [12] <author> David Maulsby and Ian H. Witten. </author> <title> Cima: An Interactive Concept Learning System for End-User Applications. </title> <journal> Applied Artificial Intelligence, </journal> <volume> 11 </volume> <pages> 653-671, </pages> <year> 1997. </year>
Reference-contexts: Peridot [15] allows programmers to construct user interfaces by drawing them interactively. It uses a set of condition-action rules to determine when to infer constraints over widget placement and iterations over sequences. Cima <ref> [12] </ref> learns text editing commands by example; it relies on user hints, rather than multiple examples, to disambiguate possible programs. Chimera [6] generalizes constraints between graphical objects from multiple snapshots and provides a macro-by-example facility for creating macros in a graphical editing domain.
Reference: [13] <author> T. Mitchell. </author> <title> Generalization as search. </title> <journal> J. Artificial Intelligence, </journal> <volume> 18 </volume> <pages> 203-226, </pages> <year> 1982. </year>
Reference-contexts: In the remainder of this section, we elaborate on these encodings and discuss their relative advantages. Version Space Encoding Version space algorithms <ref> [13] </ref> use a general-to-specific ordering among possible hypotheses to maintain a compact representation (the set of maximally specific and the set of maximally general hypotheses) of the version space | the set of expressible hypotheses which are consistent with the training data to date. <p> TGen vs uses version spaces 1 to perform trace generalization by considering each loop iteration to be a positive example, encoded as a feature vector with a column for each command, argument, and (optionally) argument attributes. We adopt a simple conjunctive hypothesis language with "?" wildcards <ref> [13] </ref>; the semantics of this representation is simple | a hypothesis represents the set of examples (loop iterations) that match the pattern.
Reference: [14] <author> T. Mitchell. </author> <title> Machine Learning. </title> <publisher> McGraw Hill, </publisher> <year> 1997. </year>
Reference-contexts: Since we are only interested in the most specific hypotheses consistent with the training examples, we only need the Find-S half <ref> [14, p. 29] </ref> of the full algorithm. TGen vs uses version spaces 1 to perform trace generalization by considering each loop iteration to be a positive example, encoded as a feature vector with a column for each command, argument, and (optionally) argument attributes.
Reference: [15] <author> Brad A. Myers. Peridot: </author> <title> Creating User Interfaces by Demonstration. </title> <editor> In Allen Cypher, editor, </editor> <title> Watch What I Do: </title> <booktitle> Programming by Demonstration, </booktitle> <pages> pages 125-153. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: Each user action is compared against the action history using a pattern-matching scheme. Once the system detects a repetitive sequence, it highlights its prediction of the next action, and offers to automate the remainder of the sequence. Peridot <ref> [15] </ref> allows programmers to construct user interfaces by drawing them interactively. It uses a set of condition-action rules to determine when to infer constraints over widget placement and iterations over sequences.
Reference: [16] <author> C.G. Nevill-Manning and I.H. Witten. </author> <title> Detecting sequential structure. </title> <booktitle> In Proc. Workshop on Programming by Demonstration, </booktitle> <address> ML'95, Tahoe City, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: Witten et al [27] identify shortcomings in current machine learning approaches when applied to PBD, such as an inability to take advantage of domain knowledge or user hints. Paynter sketches out a general-purpose PBD framework using machine learning [18]. Nevill-Manning and Witten <ref> [16, 17] </ref> describe a linear-time algorithm for detecting hierarchical structure in sequences by generalizing a grammar from repeated subsequences in a single example. Their algorithm is elegantly simple, but it is not obvious how to apply background knowledge to bias the generated grammars.
Reference: [17] <author> C.G. Nevill-Manning and I.H. Witten. </author> <title> Identifying Hierarchical Structure in Sequences: A linear-time algorithm. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 7 </volume> <pages> 67-82, </pages> <year> 1997. </year>
Reference-contexts: Witten et al [27] identify shortcomings in current machine learning approaches when applied to PBD, such as an inability to take advantage of domain knowledge or user hints. Paynter sketches out a general-purpose PBD framework using machine learning [18]. Nevill-Manning and Witten <ref> [16, 17] </ref> describe a linear-time algorithm for detecting hierarchical structure in sequences by generalizing a grammar from repeated subsequences in a single example. Their algorithm is elegantly simple, but it is not obvious how to apply background knowledge to bias the generated grammars.
Reference: [18] <author> Gordon W. Paynter. </author> <title> Generalising Programming by Demonstration. </title> <booktitle> In Proceedings Sixth Aus-tralian Conference on Computer-Human Interaction, </booktitle> <pages> pages 344-345, </pages> <month> Nov </month> <year> 1996. </year>
Reference-contexts: Others have considered applying domain-independent algorithms to PBD. Witten et al [27] identify shortcomings in current machine learning approaches when applied to PBD, such as an inability to take advantage of domain knowledge or user hints. Paynter sketches out a general-purpose PBD framework using machine learning <ref> [18] </ref>. Nevill-Manning and Witten [16, 17] describe a linear-time algorithm for detecting hierarchical structure in sequences by generalizing a grammar from repeated subsequences in a single example. Their algorithm is elegantly simple, but it is not obvious how to apply background knowledge to bias the generated grammars.
Reference: [19] <author> M. Pazzani and D. Kibler. </author> <title> The utility of prior knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 54-97, </pages> <year> 1992. </year>
Reference-contexts: TGen foil was unable to learn the correct program for the Big Relation ontology in under 100 training examples and several hours. This is unsurprising since the branching factor of the search grows exponentially with the arity of the target predicate; see Pazzani and Ki-bler <ref> [19] </ref> for an analysis of FOIL's complexity. FUTURE WORK Our work raises a number of research questions. The primary concern for our TGen foil system is whether it will scale as the domain becomes more complex and as program complexity increases.
Reference: [20] <author> M. Pazzani and D. Kibler. </author> <title> The utility of knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9(1) </volume> <pages> 57-94, </pages> <year> 1997. </year>
Reference-contexts: We can see several ways to address the issue of scalability: prioritizing literals in order to direct the heuristic search down more promising paths; increasing the search bias by using FOCL <ref> [20] </ref> to give the learner background information about previous tasks or likely loop lengths; increasing bias by encoding command-argument agreement constraints as a grammar and learning with GRENDEL [2]; or asking the user to disambiguate between several equally likely (to the learner) alternatives.
Reference: [21] <author> M. Pollack. </author> <title> Inferring domain plans in question-answering. </title> <type> PhD thesis, </type> <institution> University of Pennslyvania, </institution> <year> 1986. </year>
Reference-contexts: Nevill-Manning and Witten [16, 17] describe a linear-time algorithm for detecting hierarchical structure in sequences by generalizing a grammar from repeated subsequences in a single example. Their algorithm is elegantly simple, but it is not obvious how to apply background knowledge to bias the generated grammars. Plan recognition <ref> [21, 5] </ref> typically requires a large library of possible plans which are checked against user actions. This work may be viewed as inductive learning with a very strong bias (the plan library).
Reference: [22] <author> J.R. Quinlan. </author> <title> Learning Logical Definitions from Relations. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 239-266, </pages> <year> 1997. </year>
Reference-contexts: To address this problem, we next consider a much more expressive hypothesis language: recursive Datalog programs. Inductive Logic Programming (FOIL) An ILP learner, such as FOIL <ref> [22] </ref>, is a first-order extension of a decision rule learner. It takes as input a set of relational training examples classified into those that are examples of a target concept (the positive examples) and those that are not.
Reference: [23] <author> R. Reiter. </author> <title> On closed world databases. </title> <editor> In H. Gal-laire and J. Minker, editors, </editor> <booktitle> Logic and Data Bases, </booktitle> <pages> pages 55-76. </pages> <publisher> Plenum Press, </publisher> <year> 1978. </year>
Reference-contexts: We encode a simple model of time so the learner can utilize the order in which actions are executed when generalizing. The feature vector encoding cannot ex press this information. 4. The closed world assumption (CWA) <ref> [23] </ref> provides negative training examples | if the second command is "Save message to file1," then the second command is not everything else. (It's impossible to exploit these negative examples without a notion of time, because the user might eventually execute any action.) We illustrate our TGen foil algorithm in terms
Reference: [24] <author> J. Schlimmer and L. Hermens. </author> <title> Software agents: Completing patterns and constructing user interfaces. </title> <journal> J. Artificial Intelligence Research, </journal> <pages> pages 61-89, </pages> <year> 1993. </year>
Reference-contexts: Lesh and Et-zioni [8, 9] adapt the version space algorithm to perform goal recognition with an implicit plan-library representation which is constructed by reasoning about action preconditions and effects. Our work is similar to previous machine learning efforts at developing self-customizing software. Schlim-mer and Hermens <ref> [24] </ref> describe a note-taking system that predicts what the user is going to write and fa cilitates completion; the system works by learning a finite state machine (FSM) modeling note syntax and decision tree classifiers for each FSM state.
Reference: [25] <author> R. Weida and D. Litman. </author> <title> Terminological Reasoning with Constraint Networks and an Application to Plan Recognition. </title> <booktitle> In Proc. 3rd Int. Conf. Principles of Knowledge Representation and Reasoning, </booktitle> <month> October </month> <year> 1992. </year>
Reference-contexts: This work may be viewed as inductive learning with a very strong bias (the plan library). Bauer [1] presents algorithms for constructing plan libraries from a corpus of logged user traces and optional action models. Weida and Litman <ref> [25] </ref> use terminological sub-sumption with temporal constraint networks to match execution sequences with library plans. Lesh and Et-zioni [8, 9] adapt the version space algorithm to perform goal recognition with an implicit plan-library representation which is constructed by reasoning about action preconditions and effects.
Reference: [26] <author> D. Weld. </author> <title> An introduction to least-commitment planning. </title> <journal> AI Magazine, </journal> <pages> pages 27-61, </pages> <month> Winter </month> <year> 1994. </year> <note> Available at ftp://ftp.cs.washington.- edu/pub/ai/. </note>
Reference-contexts: Another open question is how our system should deal with noisy data. Both of our implementations would be confused if the user inserted an irrelevant action or switched the order of two actions in subsequent iterations | even if the ordering is unimportant. Planning-style reasoning with precondition-effect models <ref> [26] </ref> might alleviate this type of noise. The segmentation problem can be viewed as a different type of noisy data.
Reference: [27] <author> I.H. Witten, C.G. Nevill-Manning, and D.L. Maulsby. </author> <title> Interacting with learning agents: implications for ml from hci. In Workshop on Machine Learning meets Human-Computer Interaction, </title> <booktitle> ML'96, </booktitle> <pages> pages 51-58, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: As we demonstrate in the remainder of this paper, our approach also yields low sample complexity | TGen vs and TGen foil are capable of generalizing from a small number of training examples. Others have considered applying domain-independent algorithms to PBD. Witten et al <ref> [27] </ref> identify shortcomings in current machine learning approaches when applied to PBD, such as an inability to take advantage of domain knowledge or user hints. Paynter sketches out a general-purpose PBD framework using machine learning [18].
References-found: 27

