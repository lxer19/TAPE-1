URL: http://www.cs.umn.edu/Users/dept/users/du/papers/cm2transposition.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/du/papers/
Root-URL: http://www.cs.umn.edu
Email: vetter@cs.umn.edu  du@cs.umn.edu  alan@msc.edu  
Phone: (612) 626-7509 (612) 625-0572  (612) 625-2560 (612) 625-0572  (612) 626-1737 (612) 624-6550  
Title: The CM-2 Data Transposition Problem  
Author: Ronald J. Vetter and David H.C. Du Alan E. Klietz 
Note: Electronic Mail Address Telephone Number FAX Number  IPPS '93 Technical Paper  
Address: 200 Union Street SE 1200 Washington Avenue South Minneapolis, MN 55455 Minneapolis, MN 55415  
Affiliation: Computer Science Department Minnesota Supercomputer Center University of Minnesota University of Minnesota  
Abstract: In a previous paper [6], we noted that the CM-2's natural data layout is not conducive to exchanging data with other machines. In order for CM-2 data to be understandable to a remote machine, a bitwise transpose must be performed on the data. Each bit in an n bit value must be transmitted to a different processor, requiring n send operations through the CM-2's global router network. The time required to transpose the data limits the effective throughput of the I/O channel to a small fraction of its peak theoretical bandwidth. For example, when sending data to a remote supercomputer using a 100 MB/s HIPPI channel, an effective throughput of only 4.9 MB/s can be achieved. In this paper, we describe the CM-2 transpose problem in detail and study ways to improve the performance of transposed data transmissions. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Committee on Computer Research and Applications, "The Federal High Performance Computing Program", Office of Science and Technology Policy, Federal Coordinating Council for Science, Engineering and Technology, </institution> <month> September 8, </month> <year> 1989. </year>
Reference-contexts: 1 Introduction The main driving force behind high performance computing and communication is the various large-scale scientific and engineering applications or "grand challenge problems" that need to be solved <ref> [1] </ref>. For example, a typical volume rendering application will require large amounts of memory (1 to 4 gigabytes), gigaflop computational rates, and very high input and output data rates 1 .
Reference: [2] <author> Johnsson, S.L. and Ho, C.-T., </author> <title> "Optimum Broadcasting and Personalized Communication in Hypercubes", </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 38, No. 9, </volume> <month> September </month> <year> 1989. </year>
Reference-contexts: A permutation algorithm is constructed by scheduling a sequence of these shu*e and exchange operations. For example, a simple 1-dimensional physical ordering is constructed by first performing an LST on the source operands, performing a Global Exchange, and then performing another LST at the destination. 4 Johnsson and Ho <ref> [2] </ref> call this a Scheduling Discipline. 5 The latter includes both "twiddle" (inter-processor) and "shu*e" (intra-processor) permutations, hence "twu*e". 15 For each I/O operation, the Twu*e Compiler generates the microcode sequence nec-essary to perform the transpose. Each geometry requires a different microcode sequence. The microcode is cached for re-use.
Reference: [3] <author> Schneider, M., </author> <title> "Tying the Knot Between Serial and Massively Parallel Computing: </title> <booktitle> Pittsburgh's Not-So-Odd Couple", Supercomputing Review, </booktitle> <pages> pp. 36-38, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: D (0,8177) : D (0,4111) D (0,4127) D (0,4143) ... D (0,8191) D (1,4097) D (1,4113) D (1,4129) ... D (1,8177) : D (1,4111) D (1,4127) D (1,4143) ... D (1,8191) : : 3 The bits are ordered according to what Thinking Machines Corp. calls the "twiddle shu*e" <ref> [3] </ref>. 9 This permutation must somehow be undone in order for the data to be understandable to a remote machine or peripheral device.
Reference: [4] <author> Thinking Machines Corporation, </author> <title> "Connection Machine Model CM-2 Technical Summary", </title> <note> Version 5.1, </note> <month> May </month> <year> 1989. </year>
Reference-contexts: When the CM-2 is operating in virtual processor mode, each instruction must 2 Note: The material in this section was extracted from <ref> [4] </ref> and [5]. 3 be executed many times in each physical processor, once for every virtual processor. <p> In effect, the router allows the local memories of the data processors to be treated as a single large shared memory. The throughput of the router depends on the message length and on the pattern of communication <ref> [4] </ref>. Each CM-2 processor chip contains one router node which serves the 16 data processors on the chip.
Reference: [5] <institution> Thinking Machines Corporation, </institution> <note> "The CMIS Reference Manual", Version 6.0, Oc-tober 12, </note> <year> 1990. </year>
Reference-contexts: When the CM-2 is operating in virtual processor mode, each instruction must 2 Note: The material in this section was extracted from [4] and <ref> [5] </ref>. 3 be executed many times in each physical processor, once for every virtual processor. The virtual processor mode allows users to write programs assuming a number of processors that is natural for the application, rather than forcing the code to conform to the number of physical processors available. <p> By using all the edges or wires concurrently, a large aggregate bandwidth can be achieved (6.9 gigabytes per second in the case of a CM-2 with 65,536 processors <ref> [5] </ref>). Cube swaps are useful for implementing permutation patterns such as the I/O transpose and similar patterns that do not exhibit fan-in or fan-out congestion. 6 2.5 Data Layout Any I/O transpose algorithm must take into account the layout of parallel data before it can convert it to serial form.
Reference: [6] <author> Vetter, R., Du, D. and Klietz, A., </author> <title> "Network Supercomputing: Experiments with a CRAY-2 to CM-2 HIPPI Connection", </title> <booktitle> Sixth International Parallel Processing Symposium (IPPS '92), </booktitle> <month> March 23-26, </month> <year> 1992. </year> <month> 21 </month>
Reference-contexts: HIPPI hardware and software were recently installed to provide high speed internet-working capabilities between a massively parallel Connection Machine model CM-2 and a CRAY-2 supercomputer located in the Minnesota Supercomputer Center <ref> [6] </ref>. Through our work with the HIPPI, we found that when transmitting data from the CM-2 to the CRAY-2, the CM-2 was able to sustain an effective throughput rate of only 4.9 MB/s, a small fraction of the HIPPI's peak theoretical bandwidth of 100 MB/s. <p> Since the transpose is component-wise invertible, we do not know the reason for this reduction in performance in the reverse direction. 16 4.3.2 HIPPI Performance In a previous paper <ref> [6] </ref>, we experimented with a CRAY-2 to CM-2 HIPPI connection. This experimentation found that the utilization of the HIPPI channel was limited by the I/O performance of the CMFS transpose library routine.
References-found: 6

