URL: ftp://garovix.ijs.si/pub/papers/bz/aime97.ps.gz
Refering-URL: http://www-ai.ijs.si/BlazZupan/papers.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: (E-mail: Blaz.Zupan@ijs.si, Saso.Dzeroski@ijs.si)  
Title: Acquiring and validating background knowledge for machine learning using function decomposition  
Author: Blaz Zupan and Saso Dzeroski 
Address: 1000 Ljubljana, Slovenia  
Affiliation: Department of Intelligent Systems, Jozef Stefan Institute  
Abstract: Domain or background knowledge is often needed in order to solve difficult problems of learning medical diagnostic rules. Earlier experiments have demonstrated the utility of background knowledge when learning rules for early diagnosis of rheumatic diseases. A particular form of background knowledge comprising typical co-occurrences of several groups of attributes was provided by a medical expert. This paper explores the possibility to automate the process of acquiring background knowledge of this kind. A method based on function decomposition is proposed that identifies typical co-occurrences for a given set of attributes. The method is evaluated by comparing the typical co-occurrences it identifies, as well as their contribution to the performance of machine learning algorithms, to the ones provided by a medical expert.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Ashenhurst, R.L. </author> <year> (1952). </year> <title> The decomposition of switching functions. </title> <type> Technical report, </type> <institution> Bell Laboratories BL-1(11): </institution> <month> 541-602. </month>
Reference-contexts: The typical co-occurrence acquisition method proposed in this paper uses several fundamental algorithms from function decomposition. The pioneers of this field are Ashenhurst <ref> [1] </ref> and Curtis [5]. They have used function decomposition for the discovery of Boolean functions. Its potential use within machine learning was first observed by Samuel [17] and Biermann [2]. A recent report of Perkowski et al. [15] provides a comprehensive survey of the literature on function decomposition.
Reference: 2. <author> Biermann, A.W., Fairfield, J., and Beres, T. </author> <year> (1982). </year> <title> Signature table systems and learning. </title> <journal> IEEE Trans. Syst. Man Cybern., </journal> <volume> 12(5): </volume> <pages> 635-648. </pages>
Reference-contexts: The pioneers of this field are Ashenhurst [1] and Curtis [5]. They have used function decomposition for the discovery of Boolean functions. Its potential use within machine learning was first observed by Samuel [17] and Biermann <ref> [2] </ref>. A recent report of Perkowski et al. [15] provides a comprehensive survey of the literature on function decomposition. In this paper we refer to the decomposition algorithms which use decision tables with multi-valued attributes and classes and were developed by Zupan and Bohanec [20].
Reference: 3. <author> Clark, P., and Boswell, R. </author> <year> (1991). </year> <title> Rule induction with CN2: Some recent improvements. </title> <booktitle> In Proc. Fifth European Working Session on Learning, </booktitle> <pages> pages 151-163. </pages> <publisher> Springer, </publisher> <address> Berlin. </address>
Reference-contexts: For a particular patient record (example) this attribute has as value the typical co-occurrence observed for the patient, if one was indeed observed, or has the value "irrelevant" otherwise. A rule induction system, such as CN2 <ref> [3] </ref>, or any attribute-value learning system can then be applied to the extended learning problem. To illustrate the concept, let us consider Grouping 2. <p> LINUS then introduces a new attribute for each grouping (as explained in the introduction). The 462 examples augmented with the six new attributes (thus having in total 22 attributes) are then fed to the rule induction system CN2 <ref> [3] </ref> and to a nearest neighbor classifier [19, 8, 4]. The goal of this was to evaluate the usefulness of the new attributes and in this way the usefulness of the typical co-occurrences proposed by HINT TCO .
Reference: 4. <author> Cover, T.M., and Hart, P.E. </author> <year> (1968). </year> <title> Nearest neighbor pattern classification. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 13: </volume> <pages> 21-27. </pages>
Reference-contexts: LINUS then introduces a new attribute for each grouping (as explained in the introduction). The 462 examples augmented with the six new attributes (thus having in total 22 attributes) are then fed to the rule induction system CN2 [3] and to a nearest neighbor classifier <ref> [19, 8, 4] </ref>. The goal of this was to evaluate the usefulness of the new attributes and in this way the usefulness of the typical co-occurrences proposed by HINT TCO .
Reference: 5. <author> Curtis, H.A. </author> <year> (1962). </year> <title> A New Approach to the Design of Switching Functions. </title> <publisher> Van Nostrand, </publisher> <address> Princeton, N.J. </address>
Reference-contexts: The typical co-occurrence acquisition method proposed in this paper uses several fundamental algorithms from function decomposition. The pioneers of this field are Ashenhurst [1] and Curtis <ref> [5] </ref>. They have used function decomposition for the discovery of Boolean functions. Its potential use within machine learning was first observed by Samuel [17] and Biermann [2]. A recent report of Perkowski et al. [15] provides a comprehensive survey of the literature on function decomposition.
Reference: 6. <author> Dzeroski, S., Cestnik, B., and Petrovski, I. </author> <year> (1993). </year> <title> Using the m-estimate in rule induction. </title> <journal> Journal of Computing and Information Technology, </journal> <volume> 1: </volume> <pages> 37-46. </pages>
Reference-contexts: As an overall evaluation of the typical co-occurrences suggested by HINT TCO , let us consider the performance and size of the rules induced by CN2 from the dataset generated by LINUS. The accuracy and information content <ref> [11, 6] </ref> (as measured on the training set) of the rules induced (using the significance test in CN2) are 56.5% and 31%, respectively. For comparison, those obtained with the expert-proposed co-occurrences are 52.4% and 30%, respectively.
Reference: 7. <author> Dzeroski, S., and Lavrac, N. </author> <year> (1996). </year> <title> Rule induction and instance-based learning applied in medical diagnosis. Technology and Health Care. </title>
Reference-contexts: Second, it substantially improves the quality of induced rules from a medical point of view as assessed by a medical expert [14]. Finally, it reduces the effects of noisy data on the process of rule induction and nearest neighbor classification <ref> [7] </ref>. The motivation for our work is based on the following line of reasoning: It is very desirable to have and use background knowledge in the form of typical co-occurrences in rule induction, as it can greatly improve performance. <p> The use of background knowledge in this domain has been investigated by Lavrac et al. in combination with a decision tree approach [13] and in combination with a rule induction approach [14] and by Dzeroski and Lavrac <ref> [7] </ref> in combination with nearest neighbor classification. The typical co-occurrence acquisition method proposed in this paper uses several fundamental algorithms from function decomposition. The pioneers of this field are Ashenhurst [1] and Curtis [5]. They have used function decomposition for the discovery of Boolean functions. <p> The mutual information [18] between an attribute and the class tells us how useful the attribute is for classification. The two measures have been used in earlier experiments to assess the utility of background knowledge in machine learning <ref> [14, 7] </ref>. 4 Discussion For groupings 1, 2, 5, and 6, the typical co-occurrences derived by HINT TCO correspond reasonably well to those proposed by the specialist for rheumatic diseases.
Reference: 8. <author> Fix, E., and Hodges, J.L. </author> <year> (1957). </year> <title> Discriminatory analysis. Nonparametric discrimination. Consistency properties. </title> <type> Technical Report 4, </type> <institution> US Air Force School of Aviation Medicine. Randolph Field, TX. </institution>
Reference-contexts: LINUS then introduces a new attribute for each grouping (as explained in the introduction). The 462 examples augmented with the six new attributes (thus having in total 22 attributes) are then fed to the rule induction system CN2 [3] and to a nearest neighbor classifier <ref> [19, 8, 4] </ref>. The goal of this was to evaluate the usefulness of the new attributes and in this way the usefulness of the typical co-occurrences proposed by HINT TCO .
Reference: 9. <author> Harmon, P., Maus, R., and Morrissey, W. </author> <year> (1988). </year> <title> Expert systems: Tools & Applications. </title> <publisher> John Wiley, </publisher> <address> New York. </address>
Reference-contexts: Typical co-occurrences are also a natural and useful human concept used by the medical expert. However, it is well-known that direct knowledge acquisition from experts is an arduous and error-prone process <ref> [9] </ref>. This paper therefore proposes a method for automated acquisition of background knowledge in the form of typical co-occurrences. The expert need only specify the groupings, while the associated co-occurrences are determined automatically. Before proceeding further, let us briefly mention related work.
Reference: 10. <author> Karalic, A., and Pirnat, V. </author> <year> (1990). </year> <booktitle> Machine learning in rheumatology. </booktitle> <volume> Sistemica 1(2): </volume> <pages> 113-123. </pages>
Reference-contexts: Before proceeding further, let us briefly mention related work. The domain of early diagnosis of rheumatic diseases has been first treated with a machine learning approach by Pirnat et al. [16]. Decision tree based approaches have been further applied to this domain by Karalic and Pirnat <ref> [10] </ref>. The use of background knowledge in this domain has been investigated by Lavrac et al. in combination with a decision tree approach [13] and in combination with a rule induction approach [14] and by Dzeroski and Lavrac [7] in combination with nearest neighbor classification.
Reference: 11. <author> Kononenko, I., and Bratko, I. </author> <year> (1991). </year> <title> Information-based evaluation criterion for classifier's performance. </title> <journal> Machine Learning, </journal> <volume> 6(1): </volume> <pages> 67-80. </pages>
Reference-contexts: As an overall evaluation of the typical co-occurrences suggested by HINT TCO , let us consider the performance and size of the rules induced by CN2 from the dataset generated by LINUS. The accuracy and information content <ref> [11, 6] </ref> (as measured on the training set) of the rules induced (using the significance test in CN2) are 56.5% and 31%, respectively. For comparison, those obtained with the expert-proposed co-occurrences are 52.4% and 30%, respectively.
Reference: 12. <author> Lavrac, N., and Dzeroski, S. </author> <year> (1994). </year> <title> Inductive Logic Programming: Techniques and Applications. </title> <publisher> Ellis Horwood, </publisher> <address> Chichester. </address>
Reference-contexts: In machine learning terminology, additional expert knowledge is usually referred to as background knowledge. While most machine learning approaches have only limited capabilities of taking into account such knowledge, inductive logic programming <ref> [12] </ref> systems can handle different types of background knowledge. A particular type of medical expert knowledge specifies which combinations of values (co-occurrences) of a set (grouping) of attributes have high importance for the diagnostic problem at hand. These combinations of values are called typical co-occurrences. <p> Typical co-occurrences are used in expert diagnosis. When asked for some additional knowledge about the difficult problem of early diagnosis of rheumatic diseases, a medical expert provided typical co-occurrences for several groupings of attributes. These were then used by the LINUS <ref> [12] </ref> system for inductive logic programming in the domain of early diagnosis of rheumatic diseases [14] from anamnestic data. In this domain, the task here is to diagnose into one of eight diagnostic classes, given sixteen anamnestic attributes. <p> The groupings with the new typical co-occurrences suggested by HINT TCO are then provided as background knowledge to LINUS <ref> [12] </ref> in addition to the 462 training examples (patient records). LINUS then introduces a new attribute for each grouping (as explained in the introduction).
Reference: 13. <author> Lavrac, N., Dzeroski, S., Pirnat, V., and Krizman, V. </author> <year> (1991). </year> <title> Learning rules for early diagnosis of rheumatic diseases. </title> <booktitle> In Proc. Third Scandinavian Conference on Artificial Intelligence, </booktitle> <pages> pages 138-149. </pages> <publisher> IOS Press, Amsterdam. </publisher>
Reference-contexts: Decision tree based approaches have been further applied to this domain by Karalic and Pirnat [10]. The use of background knowledge in this domain has been investigated by Lavrac et al. in combination with a decision tree approach <ref> [13] </ref> and in combination with a rule induction approach [14] and by Dzeroski and Lavrac [7] in combination with nearest neighbor classification. The typical co-occurrence acquisition method proposed in this paper uses several fundamental algorithms from function decomposition. The pioneers of this field are Ashenhurst [1] and Curtis [5]. <p> For example, from Table 4.1 we can see that the attribute "Duration of morning stiffness" has been discretized into two intervals: up to 1 hour and longer than 1 hour. 3.2 The background knowledge In an earlier study <ref> [13] </ref>, a specialist for rheumatic diseases has provided his knowledge about typical co-occurrences of six groupings of attributes.
Reference: 14. <author> Lavrac, N., Dzeroski, S., Pirnat, V., and Krizman, V. </author> <year> (1993). </year> <title> The utility of background knowledge in learning medical diagnostic rules. </title> <journal> Applied Artificial Intelligence, </journal> <volume> 7 </volume> <pages> 273-293. </pages>
Reference-contexts: When asked for some additional knowledge about the difficult problem of early diagnosis of rheumatic diseases, a medical expert provided typical co-occurrences for several groupings of attributes. These were then used by the LINUS [12] system for inductive logic programming in the domain of early diagnosis of rheumatic diseases <ref> [14] </ref> from anamnestic data. In this domain, the task here is to diagnose into one of eight diagnostic classes, given sixteen anamnestic attributes. The difficulty of the diagnostic problem itself and noise in the data make this a very hard problem for machine learning approaches. <p> An example rule that uses this grouping and the second co-occurrence is given in Table 1. This rule was induced by LINUS using CN2 <ref> [14] </ref>. Table 1. <p> First, rules induced in the presence of background knowledge performed better in terms of classification accuracy and information content <ref> [14] </ref>. Second, it substantially improves the quality of induced rules from a medical point of view as assessed by a medical expert [14]. Finally, it reduces the effects of noisy data on the process of rule induction and nearest neighbor classification [7]. <p> First, rules induced in the presence of background knowledge performed better in terms of classification accuracy and information content <ref> [14] </ref>. Second, it substantially improves the quality of induced rules from a medical point of view as assessed by a medical expert [14]. Finally, it reduces the effects of noisy data on the process of rule induction and nearest neighbor classification [7]. <p> Decision tree based approaches have been further applied to this domain by Karalic and Pirnat [10]. The use of background knowledge in this domain has been investigated by Lavrac et al. in combination with a decision tree approach [13] and in combination with a rule induction approach <ref> [14] </ref> and by Dzeroski and Lavrac [7] in combination with nearest neighbor classification. The typical co-occurrence acquisition method proposed in this paper uses several fundamental algorithms from function decomposition. The pioneers of this field are Ashenhurst [1] and Curtis [5]. <p> The mutual information [18] between an attribute and the class tells us how useful the attribute is for classification. The two measures have been used in earlier experiments to assess the utility of background knowledge in machine learning <ref> [14, 7] </ref>. 4 Discussion For groupings 1, 2, 5, and 6, the typical co-occurrences derived by HINT TCO correspond reasonably well to those proposed by the specialist for rheumatic diseases.
Reference: 15. <author> Perkowski, M.A., and Grygiel, S. </author> <year> (1995). </year> <title> A survey of literature on function decomposition. </title> <type> Techical report, </type> <institution> Dept. of Electrical Engineering, Portland State University. </institution>
Reference-contexts: The pioneers of this field are Ashenhurst [1] and Curtis [5]. They have used function decomposition for the discovery of Boolean functions. Its potential use within machine learning was first observed by Samuel [17] and Biermann [2]. A recent report of Perkowski et al. <ref> [15] </ref> provides a comprehensive survey of the literature on function decomposition. In this paper we refer to the decomposition algorithms which use decision tables with multi-valued attributes and classes and were developed by Zupan and Bohanec [20]. The remainder of the paper is organized as follows. <p> Since graph coloring is an NP-hard problem, the computation time of an exhaustive search algorithm is prohibitive even for small graphs with about 15 nodes. Instead, we use the simple Color Influence Method of polynomial complexity <ref> [15] </ref>. The Color Influence Method sorts the nodes to color by their decreasing connectivity and then assigns to each node a color that is different from the colors of its neighbors so that a minimal number of colors is used.
Reference: 16. <author> Pirnat, V., Kononenko, I., Janc, T., and Bratko, I. </author> <year> (1989). </year> <title> Medical analysis of automatically induced rules. </title> <booktitle> In Proc. 2nd European Conference on Artificial Intelligence in Medicine, </booktitle> <pages> pages 24-36. </pages> <publisher> Springer, </publisher> <address> Berlin. </address>
Reference-contexts: The expert need only specify the groupings, while the associated co-occurrences are determined automatically. Before proceeding further, let us briefly mention related work. The domain of early diagnosis of rheumatic diseases has been first treated with a machine learning approach by Pirnat et al. <ref> [16] </ref>. Decision tree based approaches have been further applied to this domain by Karalic and Pirnat [10]. <p> Both HINT and HINT TCO run on a variety of UNIX platforms, including HP/UX, SunOS and IRIS. 3 Extracting and validating background knowledge in early diagnosis of rheumatic diseases 3.1 The domain The data used originate from the University Medical Center in Ljubljana <ref> [16] </ref> and comprise records on 462 patients. The multitude of over 200 different diagnoses have been grouped into three, six, eight or twelve diagnostic classes.
Reference: 17. <author> Samuel, A. </author> <year> (1967). </year> <title> Some studies in machine learning using the game of checkers II: Recent progress. </title> <journal> IBM J. Res. Develop., </journal> <volume> 11 </volume> <pages> 601-617. </pages>
Reference-contexts: The typical co-occurrence acquisition method proposed in this paper uses several fundamental algorithms from function decomposition. The pioneers of this field are Ashenhurst [1] and Curtis [5]. They have used function decomposition for the discovery of Boolean functions. Its potential use within machine learning was first observed by Samuel <ref> [17] </ref> and Biermann [2]. A recent report of Perkowski et al. [15] provides a comprehensive survey of the literature on function decomposition. In this paper we refer to the decomposition algorithms which use decision tables with multi-valued attributes and classes and were developed by Zupan and Bohanec [20].
Reference: 18. <author> Shannon, C.E. </author> <year> (1948). </year> <title> A mathematical theory of communication. </title> <journal> Bell. Syst. Techn. J., </journal> <volume> 27: </volume> <pages> 379-423. </pages>
Reference-contexts: The mutual information between the grouping and the diagnostic class, calculated as a weight for nearest neighbor classification [19] is listed in the column marked f NN . The mutual information <ref> [18] </ref> between an attribute and the class tells us how useful the attribute is for classification.
Reference: 19. <author> Wettschereck, D. </author> <year> (1994). </year> <title> A study of distance-based machine learning algorithms. </title> <type> PhD Thesis, </type> <institution> Department of Computer Science, Oregon State University, Corvallis, </institution> <address> OR. </address>
Reference-contexts: LINUS then introduces a new attribute for each grouping (as explained in the introduction). The 462 examples augmented with the six new attributes (thus having in total 22 attributes) are then fed to the rule induction system CN2 [3] and to a nearest neighbor classifier <ref> [19, 8, 4] </ref>. The goal of this was to evaluate the usefulness of the new attributes and in this way the usefulness of the typical co-occurrences proposed by HINT TCO . <p> The mutual information between the grouping and the diagnostic class, calculated as a weight for nearest neighbor classification <ref> [19] </ref> is listed in the column marked f NN . The mutual information [18] between an attribute and the class tells us how useful the attribute is for classification.
Reference: 20. <author> Zupan, B., and Bohanec, M. </author> <year> (1996). </year> <title> Learning concept hierarchies from examples by function decomposition. </title> <type> Technical report, </type> <note> IJSDP-7455, </note> <author> J. Stefan Institute, </author> <title> Ljubljana. URL ftp://ftp-e8.ijs.si/pub/reports/IJSDP-7455.ps. This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: A recent report of Perkowski et al. [15] provides a comprehensive survey of the literature on function decomposition. In this paper we refer to the decomposition algorithms which use decision tables with multi-valued attributes and classes and were developed by Zupan and Bohanec <ref> [20] </ref>. The remainder of the paper is organized as follows. Section 2 describes the method for acquisition of typical co-occurrences. Section 3 describes the domain of early diagnosis of rheumatic diseases, and the background knowledge provided by the expert. <p> The al-gorithms for the construction of the partition matrix and incompatibility graph are described in detail in <ref> [20] </ref>. The typical co-occurrences derivation method then uses the incompatibility graph and discovers the typical co-occurrences through coloring. Since graph coloring is an NP-hard problem, the computation time of an exhaustive search algorithm is prohibitive even for small graphs with about 15 nodes. <p> The examples from E 0 are then removed from E and the process repeated until there are no more examples in E. 2.4 Implementation The typical co-occurrences extraction method was implemented as HINT TCO , an extension of the Hierarchy Induction Tool HINT <ref> [20] </ref> for learning concept hierar chies from examples by decision table decomposition.
References-found: 20

