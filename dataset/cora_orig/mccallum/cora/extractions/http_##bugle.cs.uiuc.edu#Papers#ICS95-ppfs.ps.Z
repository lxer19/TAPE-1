URL: http://bugle.cs.uiuc.edu/Papers/ICS95-ppfs.ps.Z
Refering-URL: http://bugle.cs.uiuc.edu/Papers/ICS95-ppfs.html
Root-URL: http://www.cs.uiuc.edu
Title: PPFS: A High Performance Portable Parallel File System  
Author: James V. Huber, Jr. Christopher L. Elford Daniel A. Reed Andrew A. Chien David S. Blumenthal 
Address: Urbana, Illinois 61801  
Affiliation: Department of Computer Science University of Illinois  
Abstract: Rapid increases in processor performance over the past decade have outstripped performance improvements in input/output devices, increasing the importance of input/output performance to overall system performance. Further, experience has shown that the performance of parallel input/output systems is particularly sensitive to data placement and data management policies, making good choices critical. To explore this vast design space, we have developed a user-level library, the Portable Parallel File System (PPFS), which supports rapid experimentation and exploration. The PPFS includes a rich application interface, allowing the application to advertise access patterns, control caching and prefetching, and even control data placement. PPFS is both extensible and portable, making possible a wide range of experiments on a broad variety of platforms and configurations. Our initial experiments, based on simple benchmarks and two application programs, show that tailoring policies to input/output access patterns yields significant performance benefits, often improving performance by nearly an order of magnitude. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Arendt, J. W. </author> <title> Parallel Genome Sequence Comparison Using an iPSC/2 with a Concurrent File System. </title> <type> Master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: The input/output behavior of the first of these, a parallel gene sequence matching code <ref> [1, 25] </ref>, is strongly data-dependent. The second, a low temperature plasma electron scattering code [27], has more regular spatial and temporal input/output patterns.
Reference: [2] <author> Aydt, R. A. SDDF: </author> <title> The Pablo Self-Describing Data Format. </title> <type> Tech. rep., </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: Because all performance data is written in the Pablo self-defining data format (SDDF) <ref> [2] </ref>, extensive, off-line analysis and behavioral comparisons are possible via the Pablo performance analysis environment. 5 PFS and PPFS Benchmarks To assess the performance of any parallel file system, one must have a baseline for performance comparison.
Reference: [3] <author> Cabrera, L.-F., and Long, D. D. E. </author> <title> Exploiting Multiple I/O Streams to Provide High Data-Rates. </title> <booktitle> In Proceedingsof the 1991 Summer Usenix Conference (1991), </booktitle> <pages> pp. 31-48. </pages>
Reference-contexts: These provide data striping and a small number of parallel file access modes. In many cases, these access modes provide insufficient control for the application to extract good performance from the input/output system. Distributed file systems, such as Zebra [10] and Swift <ref> [3] </ref>, stripe data over distributed input/output servers, but do not provide distribution or policy control to the application layer. Further, because the performance requirements in this environment are quite different (users are not as willing to tune for input/output performance), these systems provide little control to the application program.
Reference: [4] <author> Choudhary, A., Bordawekar, R., Harry, M., Krishnaiyer, R., Ponnusamy, R., Singh, T., and Thakur, R. </author> <title> PASSION: Parallel And Scalable Software for Input-Output. </title> <type> Tech. rep., </type> <institution> Department of Electrical and Computer Engineering, Syracuse University, </institution> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: PIOUS [18] is a portable input/output system designed for use with PVM. PIOUS enforces sequential consistency on file accesses; in contrast, PPFS allows data consistency to be controlled by the application, enabling higher performance as with the genome matching application. PASSION <ref> [4] </ref> supports out-of-core algorithms in a user-level library, but focuses on a high-level array oriented interface. IBM's Vesta parallel file system [5] allows applications to define logical partitions, data distributions, and some access information. However applications have little control over caching.
Reference: [5] <author> Corbett, P., and Feitelson, D. </author> <title> Design and Implementation of the Vesta Parallel File System. </title> <booktitle> In Scalable High-Performance Computing Conference (May 1994), </booktitle> <pages> pp. 63-70. </pages>
Reference-contexts: PASSION [4] supports out-of-core algorithms in a user-level library, but focuses on a high-level array oriented interface. IBM's Vesta parallel file system <ref> [5] </ref> allows applications to define logical partitions, data distributions, and some access information. However applications have little control over caching.
Reference: [6] <author> Elford, C. L., Kuszmaul, C., Huber, J., and Madhyastha, T. M. </author> <title> Design of a Portable Parallel File System. </title> <type> Tech. rep., </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: Dashed arrows in Figure 1 represent local library or system calls, and solid arrows (e.g., those between clients and servers) correspond to message passing interactions. A more detailed description of the file system can be found in <ref> [7, 6, 8] </ref>. Clients In an SPMD computation, a client consists of an instance of the user application code and the local caching, prefetching, and bookkeeping software that permits an application to use PPFS.
Reference: [7] <author> Elford, C. L., Kuszmaul, C., Huber, J., and Madhyastha, T. M. </author> <title> Portable Parallel File System Detailed Design. </title> <type> Tech. rep., </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: Dashed arrows in Figure 1 represent local library or system calls, and solid arrows (e.g., those between clients and servers) correspond to message passing interactions. A more detailed description of the file system can be found in <ref> [7, 6, 8] </ref>. Clients In an SPMD computation, a client consists of an instance of the user application code and the local caching, prefetching, and bookkeeping software that permits an application to use PPFS.
Reference: [8] <author> Elford, C. L., Kuszmaul, C., Huber, J., and Madhyastha, T. M. </author> <title> Scenarios for the Portable Parallel File System. </title> <type> Tech. rep., </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: Dashed arrows in Figure 1 represent local library or system calls, and solid arrows (e.g., those between clients and servers) correspond to message passing interactions. A more detailed description of the file system can be found in <ref> [7, 6, 8] </ref>. Clients In an SPMD computation, a client consists of an instance of the user application code and the local caching, prefetching, and bookkeeping software that permits an application to use PPFS.
Reference: [9] <author> French, J. C., Pratt, T. W., and Das, M. </author> <title> Performance Measurement of the Concurrent File System of the Intel iPSC/2 Hypercube. </title> <journal> Journal of Parallel and Distributed Computing 17, </journal> <note> 1-2 (January and February 1993), 115-121. </note>
Reference-contexts: This infrastructure is far more flexible than current vendor parallel systems; both Thinking Machines' SFS [17] and Intel's CFS/PFS <ref> [9, 12] </ref> support only a small number of access modes and an even smaller number of automatic file data distributions among the disks. <p> However applications have little control over caching. Related work also includes a number of commercial parallel file systems | the CM-5 Scalable Parallel File System [17, 16], the Intel Concurrent File System <ref> [9] </ref> for the iPSC/2 and iPSC/860, and the Intel Paragon's Parallel File System [12]. These provide data striping and a small number of parallel file access modes. In many cases, these access modes provide insufficient control for the application to extract good performance from the input/output system.
Reference: [10] <author> Hartman, J. H., and Ousterhout, J. K. </author> <title> Zebra: </title>
Reference-contexts: These provide data striping and a small number of parallel file access modes. In many cases, these access modes provide insufficient control for the application to extract good performance from the input/output system. Distributed file systems, such as Zebra <ref> [10] </ref> and Swift [3], stripe data over distributed input/output servers, but do not provide distribution or policy control to the application layer.
References-found: 10

