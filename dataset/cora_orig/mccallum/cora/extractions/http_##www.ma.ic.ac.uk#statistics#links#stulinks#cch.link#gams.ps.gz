URL: http://www.ma.ic.ac.uk/statistics/links/stulinks/cch.link/gams.ps.gz
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Parallel Markov chain Monte Carlo sampling.  
Author: C C Holmes and B K Mallick 
Keyword: Bayesian computation, Markov chain Monte Carlo, Genetic algorithms, Variable selection, Neural networks, Bayesian model choice.  
Date: February 1998  
Address: London SW7 2BZ  
Affiliation: Department of Mathematics, Imperial College 180 Queen's Gate  
Abstract: Markov chain Monte Carlo (MCMC) samplers have proved remarkably popular as tools for Bayesian computation. However, problems can arise in their application when the density of interest is high dimensional and strongly correlated. In these circumstances the sampler may be slow to traverse the state space and mixing is poor. In this article we offer a partial solution to this problem. The state space of the Markov chain is augmented to accommodate multiple chains in parallel. Updates to individual chains are based around a genetic style crossover operator acting on `parent' states drawn from the population of chains. This process makes efficient use of gradient information implicitly encoded within the distribution of states across the population. Empirical studies support the claim that the crossover operator acting on a parallel population of chains improves mixing. This is illustrated with an example of sampling a high dimensional posterior probability density from a complex predictive model. By adopting a latent variable approach the methodology is extended to deal with variable selection and model averaging in high dimensions. This is illustrated with an example of knot selection for a spline interpolant. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Antonisse, J. </author> <title> (1989) A New Interpretation of Schema Notation that Overturns the Binary Encoding. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <editor> Schaffer, J. D., ed. </editor> <publisher> Morgan Kauf-mann. </publisher>
Reference: <author> Besag, J., Green, P., Higdon, D., and Mengersen, K. </author> <title> (1996) Bayesian Computation and Stochastic Systems. </title> <journal> Stat. Sci., </journal> <volume> vol. 10, no. 1, </volume> <pages> pp. 3-66. </pages>
Reference: <author> Bishop, C. </author> <title> (1995) Neural Networks for Pattern Recognition. </title> <publisher> Oxford. </publisher>
Reference: <author> Cleveland, W. S., Devlin, S. J. and Grosse, E. H. </author> <title> (1988) Regression by local fitting: methods, properties and computational algorithms. </title> <journal> Journal of Econometrics, </journal> <volume> vol. 37, </volume> <pages> pp. 87-114. </pages>
Reference: <author> Davidor, Y. </author> <booktitle> (1991) Genetic algorithms and robotics. </booktitle> <publisher> World Scientific Publishing. </publisher>
Reference-contexts: It is irreducible, aperiodic and satisfies detailed balance. It has as its stationary distribution the distribution of interest. The GA has shown itself to be a very efficient optimization scheme for non-linear optimization in high dimensional multi-model correlated spaces <ref> (Davidor, 1991) </ref>. As such we might expect it to provide benefits as the basis for an efficient MCMC sampler in similar cases.
Reference: <author> Davis, L. </author> <title> (1991) Handbook of Genetic Algorithms. </title> <publisher> Van Nostrand Reinhold. </publisher>
Reference-contexts: The processing of a single state at a time rather than the whole population is referred to as steady state GA and is commonly adopted in GA applications <ref> (Davis, 1991) </ref>. Finally the proposed GA update is accepted with probability given by (3).
Reference: <author> Denison, D., Mallick, B. K., and Smith, A. F. M. </author> <title> (1998) Automatic Bayesian Curve Fitting. </title> <journal> J. Royal Stat. Soc. B, </journal> <volume> vol. 80, </volume> <pages> pp. 331-350. </pages>
Reference: <author> Duane, S., Kennedy, A. D., Pendleton, B. J., and Roweth, D. </author> <title> (1987) Hybrid Monte Carlo. </title> <journal> Physics Letters B, </journal> <volume> vol. 195, </volume> <pages> pp. 216-222. </pages>
Reference-contexts: Other methods include using gradient information to bias the update proposals. These methods are based on continuous time processes and include the Langevin diffusion algorithm and the Hybrid MCMC method <ref> (Duane et al, 1987) </ref>, see Chapter 5 of Neal (1993) for details and references. During simulation these continuous algorithms must be discretised and hence a Metropolis-Hastings rejection step is required to ensure recurrence. While this preserves stationarity the algorithm can often be rendered non-geometric (Roberts and Tweedie, 1995).
Reference: <author> Fan, J and Gijbels, I. </author> <year> (1996). </year> <title> Local Polynomial Modelling and Its Applications. </title> <publisher> Chapman & Hall. </publisher>
Reference: <author> Gelfand, A. and Smith, A. F. M. </author> <title> (1990) Sampling-based approaches to calculating marginal densities. </title> <journal> Journal of the American Statistical Association, </journal> <volume> vol. 85, </volume> <pages> pp. 398-409. </pages>
Reference: <author> George, E. I., and McCulloch, R. E. </author> <title> (1993) Variable Selection via Gibbs Sampling. </title> <journal> Journal of the American Statistical Association, </journal> <volume> vol. 88, </volume> <pages> pp 881-889. </pages>
Reference: <author> Geyer, C. J. and Thompson, E. A. </author> <title> (1995) Annealing Markov chain Monte Carlo with applications to ancestral inference. </title> <journal> Journal of the American Statistical Association. </journal> <volume> vol. 90, </volume> <pages> pp. 909-920. </pages> <note> 22 Gilks, </note> <author> W. R., and Roberts, G. O. </author> <title> (1996) Strategies for improving MCMC. </title>
Reference: <editor> In Markov chain Monte Carlo in Practice, Gilks, W. O., Richardson, S., and Spiegelhalter, D. J. eds. </editor> <publisher> Chapman and Hall. </publisher>
Reference: <author> Gilks, W. R., Roberts, G. O. and George, E. I. </author> <title> (1994) Adaptive direction sampling. </title> <journal> The Statistician, </journal> <volume> vol. 43, </volume> <pages> pp. 179-189. </pages>
Reference: <author> Green, P. J. </author> <title> (1995) Reversible Jump Markov chain Monte Carlo computation and Bayesian model determination. </title> <journal> Biometrika, </journal> <volume> vol. 82, </volume> <pages> pp. 711-732. </pages>
Reference: <author> Hastings, W. K. </author> <title> (1970) Monte Carlo sampling methods using Markov chains and their applications. </title> <journal> Biometrica, </journal> <volume> vol. 57, </volume> <pages> pp. 97-109. </pages>
Reference: <author> Holland, J. H. </author> <booktitle> (1975) Adaption in Natural and Artificial Systems. </booktitle> <address> Ann Arbor, </address> <publisher> Mich.: University of Michigan Press. </publisher>
Reference: <author> Holmes, C. C., and Mallick, B. K. </author> <title> (1997) Bayesian wavelet networks for Nonparametric regression. </title> <type> Technical report. </type> <institution> Imperial College. </institution>
Reference: <author> Holmes, C. C., and Mallick, B. K. </author> <title> (1998) Bayesian radial basis functions of variable dimension. Neural Computation. </title> <note> To appear. </note>
Reference: <author> Kuo, L. and Mallick, B. K. </author> <title> (1995) Bayesian variable selection. </title> <journal> Sankhya. </journal> <note> To appear. </note>
Reference: <author> Mackay, D. </author> <title> (1992) A practical Bayesian framework for backpropogation networks. </title> <journal> Neural Computation, </journal> <volume> vol. 4, </volume> <pages> pp. 448-472. </pages>
Reference: <author> Madigan, D., and Raftery, A. E. </author> <title> (1994) Model Selection and Accounting for Model Uncertainty in Graphical Models using Occam's Window" Journal of the American Statistical Association, </title> <journal> vol. </journal> <volume> 89, </volume> <pages> pp. 1535-1546. </pages>
Reference: <author> Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H. and Teller, E. </author> <title> (1953) Equations of state calculations by fast computing machines. </title> <journal> J. Chem. Pys., </journal> <volume> vol. 21, </volume> <pages> pp. 1087-1091. </pages>
Reference: <author> Neal, R. </author> <title> (1993) Probabilistic inference using Markov chain Monte Carlo methods, </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Toronto. </institution>
Reference: <author> Neal, R. </author> <title> (1996) Bayesian Learning for Neural Networks. Springer. </title> <note> 23 Roberts, </note> <author> G. O. and Gilks, W. R. </author> <title> (1994) Convergence of adaptive direction sampling. </title> <journal> Journal of Multivariate Analysis, </journal> <volume> vol. 49, </volume> <pages> pp. 287-298. </pages>
Reference: <author> Roberts, G. O. and Tweedie, R. L. </author> <title> (1995) Stability of Langevin algorithms. </title> <note> In preparation. </note>
Reference-contexts: During simulation these continuous algorithms must be discretised and hence a Metropolis-Hastings rejection step is required to ensure recurrence. While this preserves stationarity the algorithm can often be rendered non-geometric <ref> (Roberts and Tweedie, 1995) </ref>. There is another potential problem with the gradient based methods. At each update step the sampler requires partial derivatives of the density evaluated at the current state. For many distributions analytical derivatives do not exist.
Reference: <author> Smith, M. and Kohn, R. </author> <title> (1995) Nonparametric regression using Bayesian variable selection. </title> <journal> Journal of Econometrics, </journal> <volume> vol. 75, </volume> <pages> pp. 317-344. </pages>
Reference: <author> Smith, A.F.M. and Roberts, </author> <title> G.O. (1993) Bayesian computation via Gibbs sampler and related Markov chain Monte Carlo methods. </title> <journal> J. R. Statist. Soc. B, </journal> <volume> vol. 55, </volume> <pages> pp. 2-24. </pages>
Reference: <author> Syswerda, G. </author> <title> (1989) Uniform crossover in Genetic Algorithms. </title> <booktitle> In Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <editor> Schaffer, J. D., ed. </editor> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: That is, C x t is a random mix of 8 the varaibles in C i t and C t . This uniform operator is known to have benefits over the one point crossover scheme described in section 2 <ref> (Syswerda, 1989) </ref>. We now consider two move types based around the crossover state. The first is a random sampler along the crossover direction (C x t C a other is a reflection of C a t about C x t . These moves are now described.

References-found: 29

