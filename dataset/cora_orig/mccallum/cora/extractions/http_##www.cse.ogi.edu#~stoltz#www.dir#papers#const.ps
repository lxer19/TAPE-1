URL: http://www.cse.ogi.edu/~stoltz/www.dir/papers/const.ps
Refering-URL: http://www.cse.ogi.edu/~stoltz/
Root-URL: http://www.cse.ogi.edu
Title: Constant Propagation: A Fresh, Demand-Driven Look  
Author: Eric Stoltz, Michael Wolfe, and Michael P. Gerlek 
Keyword: constant propagation, compiler optimization, SSA, demand-driven analysis  
Address: Technology  
Affiliation: Department of Computer Science, Oregon Graduate Institute of Science  
Abstract: In this paper, we present a new method for detecting constants, based upon an optimistic demand-driven recursive solver, as opposed to more traditional iterative solvers. The problem with iterative solvers is that they may evaluate an expression many times, while our technique evaluates each expression only once. To consider conditional code, we augment the standard Static Single Assignment (SSA) form with merge operators called fl-functions, adapted from the interpretable Gated Single Assignment (GSA) model. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. A. Ballance, A. B. Maccabe, and K. J. Ottenstein. </author> <title> The Program Dependence Web: A representation supporting control-, data-, and demand-driven interpretation of imperative languages. </title> <booktitle> In Proc. ACM SIGPLAN '90 Conf. on Programming Language Design and Implementation, </booktitle> <pages> pp. 257-271, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Examine Figure 4 (b). When attempting to classify x 1 , the value is demanded from the use-def SSA link of y 2 , which points to the -function. However, a -function is not interpretable <ref> [1] </ref>. Thus, we have no information about which path may or may not be taken. Since the predicate P in our example determines the path taken, if P is constant we can determine which argument of the - function to evaluate.
Reference: [2] <author> R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K. Zadeck. </author> <title> Efficiently computing Static Single Assignment form and the control dependence graph. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 451-490, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: It is clear that propagating information about each symbol to every node in a graph is inefficient, since not all nodes contain references or definitions of the symbol under consideration. Sparse representations, on the other hand, such as def-use or use-def chains, Static Single Assignment (SSA) <ref> [2] </ref>, Dependence Flow Graphs (DFG) [6], or Program Dependence Graphs (PDG) [3], have all shown the virtue of operating on a sparse graph for analysis. The distinction between simple (all paths) constants and conditional constants can be seen in Figure 3. <p> The -function is itself considered a new definition of the variable. For details on SSA graph construction the reader is referred to the paper by Cytron et al. <ref> [2] </ref>. A sample program converted into SSA form is shown in Figure 4 (a) and (b).
Reference: [3] <author> J. Ferrante, K. J. Ottenstein, and J. D. Warren. </author> <title> The Program Dependence Graph and its use in optimization. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: Sparse representations, on the other hand, such as def-use or use-def chains, Static Single Assignment (SSA) [2], Dependence Flow Graphs (DFG) [6], or Program Dependence Graphs (PDG) <ref> [3] </ref>, have all shown the virtue of operating on a sparse graph for analysis. The distinction between simple (all paths) constants and conditional constants can be seen in Figure 3.
Reference: [4] <author> M. P. Gerlek, E. Stoltz, and M. Wolfe. </author> <title> Beyond induction variables: Detecting and classifying sequences using a demand-driven SSA form. </title> <note> submitted for publication, </note> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: We are able to propagate constants through loops (single and nested) by taking advantage of specialized solvers which detect and classify a large assortment of linear and nonlinear induction variables <ref> [4] </ref>. 8 t 2 tuples, lattice ( t ) = &gt; unvisited ( t ) = true Visit all basic blocks B in the program Visit all tuples t within B if unvisited ( t ) then propagate ( t ) propagate ( tuple t ) unvisited ( t ) =
Reference: [5] <author> D. Grove and L. Torczon. </author> <title> Interprocedural constant propagation: A study of jump function implementations. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pp. 90-99, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Although in general constant propagation is an undecidable problem, it is nonetheless extremely useful and profitable for a number of optimizations. These include dead code elimination [10], array- and loop-bound propagation, and procedure integration (inlining), which we believe to be a major source of detectable constants <ref> [5] </ref>. Due to these benefits, constant propagation is an integral component of modern optimizing commercial compilers. The paper is organized as follows. We first examine the standard framework employed to perform constant propagation and relate it to previous methods and algorithms. <p> After analysis is complete, all symbols will have lattice value equal to bottom (?) when it cannot be determined to be constant, a constant value, or &gt; for unexecutable code. These foundations, originally introduced by Kildall [7], are standard for many constant propagation methods <ref> [5, 10] </ref>. We note that values can only move down in the lattice, due to the meet operator. By initializing lattice values to &gt;, an optimistic approach is taken, which assumes all symbols can be determined to be constant until proven otherwise.
Reference: [6] <author> R. Johnson and K. Pingali. </author> <title> Dependence-based program analysis. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pp. 78-89, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Sparse representations, on the other hand, such as def-use or use-def chains, Static Single Assignment (SSA) [2], Dependence Flow Graphs (DFG) <ref> [6] </ref>, or Program Dependence Graphs (PDG) [3], have all shown the virtue of operating on a sparse graph for analysis. The distinction between simple (all paths) constants and conditional constants can be seen in Figure 3. <p> Practically, however, this is undesirable (managing the symbol table explosion alone precludes this option), so the SSA properties are maintained by providing links between each use and its one reaching definition. Instead of providing def-use links, as is the common implementation <ref> [6, 10] </ref>, we provide use-def links, giving rise to an SSA graph comprising factored use-def chains (FUD chains). This approach yields several advantages, such as constant space per node and an ideal form with which to perform demand-driven analysis [8].
Reference: [7] <author> G. A. Kildall. </author> <title> A unified approach to global program optimization. </title> <booktitle> In Conference Record of the First ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pp. 194-206, </pages> <month> Oct. </month> <year> 1973. </year>
Reference-contexts: After analysis is complete, all symbols will have lattice value equal to bottom (?) when it cannot be determined to be constant, a constant value, or &gt; for unexecutable code. These foundations, originally introduced by Kildall <ref> [7] </ref>, are standard for many constant propagation methods [5, 10]. We note that values can only move down in the lattice, due to the meet operator. By initializing lattice values to &gt;, an optimistic approach is taken, which assumes all symbols can be determined to be constant until proven otherwise.
Reference: [8] <author> E. Stoltz, M. P. Gerlek, and M. Wolfe. </author> <title> Extended SSA with factored use-def chains to support optimization and parallelism. </title> <booktitle> In 1994 ACM Conf. Proceedings Hawaii International Conference on System Sciences, </booktitle> <month> Jan. </month> <year> 1994. </year> <note> to appear. </note>
Reference-contexts: Instead of providing def-use links, as is the common implementation [6, 10], we provide use-def links, giving rise to an SSA graph comprising factored use-def chains (FUD chains). This approach yields several advantages, such as constant space per node and an ideal form with which to perform demand-driven analysis <ref> [8] </ref>. Our analysis of programs begins within a framework consisting of the CFG and an SSA data-flow graph. Each basic block contains a list of intermediate code tuples, which themselves are linked together as part of the data-flow graph.
Reference: [9] <author> E. Stoltz, M. Wolfe, and M. P. Gerlek. </author> <title> Demand-driven constant propagation. </title> <type> Technical Report 93-023, </type> <institution> Oregon Graduate Institute, </institution> <year> 1993. </year>
Reference-contexts: In this form, the fl-function represents an if-then-else construct, but it is also extended to include more complex branch conditions, such as case statements. We provide the complete algorithm to convert -functions to and fl-functions in our technical report <ref> [9] </ref>. Multiple levels of conditionals result in nested fl-functions. Examine Figure 6 (a), which is an unstructured code fragment (although structured code with nested if-then constructs also result in nested fl-functions). Figure 6 (b) shows the program translated into GSA form. <p> We have preliminary data on the number of intraprocedural constants found in scientific Fortran programs <ref> [9] </ref>, and are extending this work to include interprocedural analysis and procedure integra tion. Although some work has already been done in this area, we are interested in applying our demand-driven style to the problem.
Reference: [10] <author> M. N. Wegman and F. K. Zadeck. </author> <title> Constant propagation with conditional branches. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 13(2) </volume> <pages> 181-210, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Although in general constant propagation is an undecidable problem, it is nonetheless extremely useful and profitable for a number of optimizations. These include dead code elimination <ref> [10] </ref>, array- and loop-bound propagation, and procedure integration (inlining), which we believe to be a major source of detectable constants [5]. Due to these benefits, constant propagation is an integral component of modern optimizing commercial compilers. The paper is organized as follows. <p> After analysis is complete, all symbols will have lattice value equal to bottom (?) when it cannot be determined to be constant, a constant value, or &gt; for unexecutable code. These foundations, originally introduced by Kildall [7], are standard for many constant propagation methods <ref> [5, 10] </ref>. We note that values can only move down in the lattice, due to the meet operator. By initializing lattice values to &gt;, an optimistic approach is taken, which assumes all symbols can be determined to be constant until proven otherwise. <p> Classification of Methods As explained by Wegman and Zadeck <ref> [10] </ref>, constant propagation algorithms can be classified in two ways: (i) using the entire graph or a sparse graph representation, and (ii) detecting simple or conditional constants. This naturally creates four classes of algorithms. <p> The distinction between the four types of algorithms is explained well by Wegman and Zadeck <ref> [10] </ref>, and the reader is referred to their paper for more detail. We will look at the algorithm that they present, since it incorporates both sparse graph representation and conditional code. The sparse graph employed is the SSA form, described next. <p> The destination node for these edges also have their -functions evaluated by taking the meet of all the arguments whose corresponding CFG predecessors are marked executable. More detail can be found in their paper <ref> [10] </ref>. This algorithm finds all simple constants, plus additional constants that can be discovered when the predicate controlling a branch node is determined to be constant. The time complexity is proportional to the size of the SSA graph, and each SSA edge can be processed at most twice. <p> Practically, however, this is undesirable (managing the symbol table explosion alone precludes this option), so the SSA properties are maintained by providing links between each use and its one reaching definition. Instead of providing def-use links, as is the common implementation <ref> [6, 10] </ref>, we provide use-def links, giving rise to an SSA graph comprising factored use-def chains (FUD chains). This approach yields several advantages, such as constant space per node and an ideal form with which to perform demand-driven analysis [8].
Reference: [11] <author> M. Wolfe. </author> <title> Beyond induction variables. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pp. 162-174, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Induction variables are traditionally detected as a precursor to strength reduction, and more recently for dependence analysis with regard to subscript expressions. We have developed methods for detecting and classifying induction variables based on strongly-connected regions in the SSA data-flow graph <ref> [11] </ref>. These techniques make use of an exit function, the -function, which holds the exit value of a variable assigned within the loop.
References-found: 11

