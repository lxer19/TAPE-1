URL: http://www.csl.sri.com/~livio/CENG-93-02.ps.Z
Refering-URL: http://www.csl.sri.com/~livio/papers.html
Root-URL: 
Title: THE DETECTION AND ELIMINATION OF USELESS MISSES IN MULTIPROCESSORS  
Author: Michel Dubois, Jonas Skeppstedt Livio Ricciulli, Krishnan Ramamurthy, and Per Stenstrm 
Keyword: Shared memory multiprocessor, distributed shared memory, cache coherence, consis tency models, performance evaluation  
Note: To Appear in the 1993 Intl. Symp. on Computer Architecture  
Address: Los Angeles, CA90089-2562, U.S.A.  P.O. Box 118, S-221 00 LUND, Sweden  
Affiliation: Department of Electrical Engineering-Systems University of Southern California  Department of Computer Engineering Lund University  
Pubnum: USC Technical Report No. CENG 93-02  
Email: dubois@paris.usc.edu  
Phone: (213)740-4475  
Date: 46-46-107-523  
Abstract: In this paper we introduce a classification of misses in shared-memory multiprocessors based on inter processor communication. We identify the set of essential misses, i.e., the smallest set of misses necessary for correct execution. Essential misses include cold misses and true sharing misses. All other misses are useless misses and can be ignored without affecting program execution. Based on the new classification we evaluate miss reduction techniques in hardware, based on delaying and combining invalidations. We compare the effectiveness of five different protocols for combining invalidations leading to useless misses for cache-based multiprocessors and for multiprocessors with virtual shared memory. In cache based systems these techniques are very effective and lead to miss rates which are close to the minimum. In virtual shared memory systems, the techniques are also effective but leave room for additional improvements. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bennett, J.K., Carter, J.B., and Zwaenepoel, W. </author> <title> Adaptive Software Cache Management for Distributed Shared Memory Architectures, </title> <booktitle> Proc. of the 17th Annual Int. Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1990, </year> <pages> pp. 125-134. </pages>
Reference: [2] <author> Bitar, P., </author> <title> A Critique of Trace-Driven Simulation for Shared-Memory Multiprocessors, in Cache and Interconnect Architectures in Multiprocessors, </title> <editor> M. Dubois and S. Thakkar ed., </editor> <publisher> Kluwer Academic Publishers, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: Note that we never violate the dependencies in the trace when we apply different schedules of invalidations in our simulations. Therefore the trace never becomes absurd, as may happen in other studies <ref> [2] </ref>. We have collected traces from six benchmark programs and two different data set sizes. All benchmarks were run for 16 processors and infinite cache sizes.
Reference: [3] <author> Borrmann, L., and Herdieckerhoff, M., </author> <title> A Coherency Model for Virtual Shared Memory, </title> <booktitle> Proc. of Int. Conf. on Parallel Processing, </booktitle> <volume> Vol. 2, pp.252-257, </volume> <month> June </month> <year> 1990. </year>
Reference: [4] <author> Boyle, J., et al. </author> <title> Portable Programs for Parallel Processors. </title> <publisher> Holt, Rinehart, and Winston Inc. </publisher> <year> 1987. </year>
Reference-contexts: The first three benchmarks are parallel applications developed at Stanford University (MP3D, Water, and LU) of which the first two are also contained in the SPLASH suite [20]. These applications are written in C using the Argonne National Laboratory macro package <ref> [4] </ref>. and compiled with the gcc compiler (version 2.0) using optimization level -O2. <p> There are two serialization points in the algorithm where the job queue is updated. We have run QSORT on arrays of 5,000 randomly selected 32-bit integers. Finally, JACOBI was written by us using the ANL macros <ref> [4] </ref> provided with the SPLASH benchmark suite. JACOBI is an iterative algorithm for solving partial differential equations [24]. Two 64x64 grid arrays of 8 bytes double precision floating point numbers are modified 16 in turn in each iteration.
Reference: [5] <author> Brorsson, M., Dahlgren, F., Nilsson, H., and Stenstrm, </author> <title> P.,The CacheMire Test Bench --- A Flexible and Effective Approach for Simulation of Multiprocessors. </title> <type> Technical Report, </type> <institution> Dept. of Computer Engineering, Lund University, Sweden, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: These applications are written in C using the Argonne National Laboratory macro package [4]. and compiled with the gcc compiler (version 2.0) using optimization level -O2. Traces from these benchmarks have been captured by the CacheMire Test Bench, a tracing and simulation tool for shared-memory multiprocessors <ref> [5] </ref>. 15 MP3D is a 3-dimensional particle simulator used by aerospace researchers to study the pressure and temperature profiles created as an object flies at hypersonic speeds through the upper atmosphere. The overall computation consists of calculating the positions and velocities of particles during a number of time steps.
Reference: [6] <author> Bray, K.B. and Flynn, M.J., </author> <title> Write Caches as an Alternative to Write Buffers, </title> <type> Technical report No. </type> <institution> CSL-TR-91-470, Stanford University, </institution> <month> Apr. </month> <year> 1991. </year>
Reference-contexts: To avoid these two problems we can try to delay the sending of the invalidation. SD: Send Delayed Protocol Each processor has a buffer for sending invalidations. This buffer can be a write cache similar to the one described in <ref> [6] </ref>. A write cache is similar to a write buffer but contains entire blocks with 1 dirty bit per word to signal modified words. If the processor is the owner at the time of the store, the store is completed without delay.
Reference: [7] <author> Censier, L.M., and Feautrier, P., </author> <title> A New Solution to Coherence Problems in Multicache Systems, </title> <journal> IEEE Trans. on Computers, </journal> <volume> Vol. C-27, No. 12, </volume> <pages> pp. 1112-1118, </pages> <month> Dec. </month> <year> 1978. </year>
Reference: [8] <editor> Digital Signal Processing Committee, editor. </editor> <title> Programs for Digital Signal Processing. </title> <publisher> IEEE 27 Press, </publisher> <year> 1979. </year>
Reference-contexts: We allow the simulator to run with as many processors as threads to avoid thread migration and simplify the analysis. The two benchmarks are NSFFT and QSORT. NSFFT is a parallel implementation of the Discrete Fourier Transform on an array of 16-byte complex floating-point numbers <ref> [8] </ref>. The workload is partitioned by assigning an equal part of the array to each processor. Each processor reads values from other processors partitions and then updates its partition with these new values. We have run NSFFT with 512 complex numbers.
Reference: [9] <author> Dubnicki, C., and LeBlanc, </author> <title> T.J.,Adjustable Block Size Coherent Caches, </title> <booktitle> Proc. of the 19th Ann. Int. Symp. on Computer Architecture, </booktitle> <month> May </month> <year> 1991, </year> <pages> pp. 170-180. </pages>
Reference-contexts: Because of the discrepancy between the miss rates of WBWI and MIN (but not between RD and WBWI), it appears that any improvement will have to deal with the problem of block ownership. This line of thought leads to systems with multiple block sizes <ref> [9] </ref>, or even systems in which coherence is maintained on words. 6.3 Worst case schedule The MAX scheduling of invalidations always yields more misses than any other schedule, Fig. 11 Effect of invalidation scheduling on the miss rate (%). Benchmarks with small data sets.
Reference: [10] <author> Dubois, M., Barroso, L., Wang, J.C., and Chen, Y.S., </author> <title> Delayed Consistency and its Effects on the Miss Rate of Parallel Programs, </title> <booktitle> Supercomputing91, </booktitle> <pages> pp. 197-206, </pages> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: The resulting additional false sharing misses are the performance cost of relying on synchronization to prevent the reading of stale words. We have simulated various schedules of invalidations, in order to understand their effects on the miss rate. We also adopt the terminology introduced in <ref> [10] </ref>. Similar protocols have been published under different names in [1,3,17]. They are: MIN, OTF, RD, SD, SRD, WBWI, and MAX. MIN: Write-through with Word Invalidation This is the ideal write-through protocol of Section 2.5. It has no false sharing and yields Ref. <p> Received delayed protocols can be implemented with a physical buffer or with a stale bit per block frame in the cache. The stale bit is set when the invalidation is received, and then, at the following acquire, the stale bit is ORed with the Invalid bit <ref> [10] </ref>. The invalidation rate of RD is lower than that of WBWI because invalidations target entire blocks instead of words.
Reference: [11] <author> Dubois, M., Scheurich, C., </author> <title> Memory Access Dependencies in Shared Memory Multiprocessors, </title> <journal> IEEE Trans. on Soft. Eng., </journal> <volume> 16(6), </volume> <pages> pp. 660-674, </pages> <month> June </month> <year> 1990. </year>
Reference: [12] <author> Eggers, S. J., and Jeremiassen, T. E., </author> <title> Eliminating False Sharing, </title> <booktitle> Proc. of the 1991 Int. Conf. on Par. Processing, </booktitle> <pages> pp. </pages> <address> I-377-I-381, </address> <month> Aug. </month> <year> 1991. </year> <note> Also published as TR 90-12-01, </note> <institution> Univ. of Washington, Dept. of Computer Science and Engineering. </institution>
Reference-contexts: Unfortunately, there is no agreement in the current literature about what a false sharing miss should be. No fundamental definition of a false sharing miss has been given; current proposals to detect and count cold and coherence misses, by Eggers and Jeremiassen <ref> [12] </ref> and by Torrellas, Lam and Hennessy [22] 1 yield different outcomes. Another drawback of current proposals is that true sharing misses are not directly related to the notion of data communication among processes in a parallel computation.
Reference: [13] <author> Francis, R., </author> <title> The PRISM Multiprocessor Simulator, High Performance Computation Project, </title> <institution> Division of Information Technology, C.S.I.R.O., </institution> <address> 723 Swanston St., Carlton 3053, Australia. </address>
Reference-contexts: Each processor waits until a column has been produced and then uses it to modify all its columns. We have run LU with a 32x32 (LU32) and a 200x200 random matrix (LU200). The next two traces were produced by the Prism Simulator <ref> [13] </ref>, an execution-driven simulator. ModulaP [14] source code is compiled to produce intermediate C code which consists of a number of slices (or procedures) which represent the atomic actions performed in turn by the different threads.
Reference: [14] <author> Francis, R., </author> <title> ModulaP Language Reference Manual, High Performance Computation Project, </title> <institution> Division of Information Technlology, C.S.I.R.O., </institution> <address> 723 Swanston St., Carlton 3053, Australia. </address>
Reference-contexts: Each processor waits until a column has been produced and then uses it to modify all its columns. We have run LU with a 32x32 (LU32) and a 200x200 random matrix (LU200). The next two traces were produced by the Prism Simulator [13], an execution-driven simulator. ModulaP <ref> [14] </ref> source code is compiled to produce intermediate C code which consists of a number of slices (or procedures) which represent the atomic actions performed in turn by the different threads.
Reference: [15] <author> Gustavson, D. B., </author> <title> The Scalable Coherent Interface and Related Standards Projects, </title> <journal> IEEE Micro, </journal> <volume> Vol. 12, No. 1, </volume> <pages> pp. 10-22, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: In the caching range, we have selected to display results for block sizes of 16, 32, 64, and 128 bytes. These block sizes are the ones of the caches of the DASH multiprocessor [18](and of the SGI cluster), of the Sequent Symmetry, of the IEEE Scalable Interface standard <ref> [15] </ref> and of the IBM RS6000 workstation, respectively.
Reference: [16] <author> Hill, </author> <title> M.D., Aspects of Cache Memory and Instruction Buffer Performance, </title> <type> Tech. Rep. UCB 87/381, </type> <institution> University of California, Berkeley, </institution> <month> November </month> <year> 1987. </year>
Reference-contexts: In Section 4, we present and justify the experimental methodology. Finally, in Sections 5, 6 and 7 we present and analyze our simulation results and we then conclude. 2. CLASSIFICATION OF MISSES IN MULTIPROCESSORS Mark Hill proposed a classification of misses in uniprocessor caches <ref> [16] </ref>. Misses are categorized into compulsory, capacity and conflict misses. Such a classification is useful because it helps explain the effects of a design decision on the miss rate. The same type of classification is sorely needed for multiprocessor caches.
Reference: [17] <author> Keleher,P., Cox,A.L., </author> <title> and Zwaenepoel,W.,Lazy Release Consistency for Software Distributed Shared Memory, </title> <booktitle> Proc. of the 19th Ann. Int. Symp. on Computer Architecture, </booktitle> <month> May </month> <year> 1991, </year> <pages> pp. 13-21. </pages>
Reference: [18] <author> Lenoski, D., Laudon, J.P., Gharachorloo, K., Gupta, A., and Hennessy, </author> <title> J.L.The Directory-based Cache Coherence Protocol for the DASH Multiprocessor, </title> <booktitle> Proc. of the 17th Ann. Int. Symp. on Comp. Arch., </booktitle> <pages> pp. 148-159, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Moreover, by identifying the minimum possible miss rate for a given execution, we can understand how close we are to the minimum miss rate and whether further improvements are possible. Aggressive techniques to tolerate memory latency tend to change the timings of invalidations. For example, in the DASH machine <ref> [18] </ref>, stores are issued by the processor immediately in a store buffer and are executed later on in the cache and in the system. Therefore invalidations are delayed both in the local processor and later on when they are propagated in the system.
Reference: [19] <author> Sedgewick, R., </author> <title> Quicksort, </title> <address> New York: </address> <publisher> Garland Publishing, Inc., </publisher> <year> 1980. </year>
Reference-contexts: The workload is partitioned by assigning an equal part of the array to each processor. Each processor reads values from other processors partitions and then updates its partition with these new values. We have run NSFFT with 512 complex numbers. QSORT is a parallel divide and conquer sorting algorithm <ref> [19] </ref>. It is synchronized through a dynamic job queue. Each process obtains exclusive access to a share of the array to sort, splits it into two sub array and dynamically posts unsorted portions to the job queue. <p> This block size is 1024 bytes. QSORT as expected has a large component of cold misses which nicely decreases with the block size. The threshold for insertion sort <ref> [19] </ref> was selected at 15 data items, which means that little false sharing is observed for block sizes under 64 bytes.
Reference: [20] <author> Singh, J. P., Weber, W-D, and Gupta., A.,SPLASH: </author> <title> Stanford Parallel Applications for Shared-Memory. </title> <journal> Computer Architecture News, </journal> <volume> 20(1) </volume> <pages> 5-44, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: All benchmarks were run for 16 processors and infinite cache sizes. The first three benchmarks are parallel applications developed at Stanford University (MP3D, Water, and LU) of which the first two are also contained in the SPLASH suite <ref> [20] </ref>. These applications are written in C using the Argonne National Laboratory macro package [4]. and compiled with the gcc compiler (version 2.0) using optimization level -O2.
Reference: [21] <author> Stenstrom, P., </author> <title> A Survey of Cache Coherence Scheme for Multiprocessors, </title> <journal> IEEE Computer, </journal> <volume> Vol. 23, No. 6, </volume> <pages> pp. 12-24, </pages> <month> Jun </month> <year> 1990. </year>
Reference: [22] <author> Torrellas, J., Lam, M.S., and Hennessy, J.L., </author> <title> Shared Data Placement Optimizations to Reduce Multiprocessor Cache Misses, </title> <booktitle> Proc. of the 1990 Int. Conf. on Parallel Proc., </booktitle> <month> Aug </month> <year> 1990, </year> <pages> pp. 266-270. </pages> <note> Also published as Measurement, </note> <author> Analysis, </author> <title> and Improvement of the Cache Behavior of Shared Data in Cache Coherent Multiprocessors Technical report CSL-TR-90-412, </title> <institution> Stanford University, </institution> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: Unfortunately, there is no agreement in the current literature about what a false sharing miss should be. No fundamental definition of a false sharing miss has been given; current proposals to detect and count cold and coherence misses, by Eggers and Jeremiassen [12] and by Torrellas, Lam and Hennessy <ref> [22] </ref> 1 yield different outcomes. Another drawback of current proposals is that true sharing misses are not directly related to the notion of data communication among processes in a parallel computation. <p> The essential miss rate--even in its more fundamental form introduced in this paper- is not an intrinsic property of an application, as previously believed <ref> [22] </ref>: it is only a property of a particular execution (or a particular interleaved trace) and is timing dependent, as is shown by the sequences in Fig. 6. The two sequences are equivalent executions but the second one yields less essential misses, in any existing classification.
Reference: [23] <author> Weber, W-D, and Gupta, </author> <title> A.,Analysis of Cache Invalidation Patterns in Multiprocessors, </title> <booktitle> Proc. of the 3rd Int. Conf. on Arch. Support for Prog. Languages and Systems(ASPLOS), </booktitle> <address> pp.243-256, </address> <month> Apr </month> <year> 1989. </year>
Reference: [24] <author> Young, D., </author> <title> Iterative Solution of Large Linear Systems, </title> <publisher> Academic Press: </publisher> <address> New York, </address> <year> 1971. </year>
Reference-contexts: We have run QSORT on arrays of 5,000 randomly selected 32-bit integers. Finally, JACOBI was written by us using the ANL macros [4] provided with the SPLASH benchmark suite. JACOBI is an iterative algorithm for solving partial differential equations <ref> [24] </ref>. Two 64x64 grid arrays of 8 bytes double precision floating point numbers are modified 16 in turn in each iteration. A component in one grid is updated by taking the average of the four neighbors of the same component in the other grid.
References-found: 24

