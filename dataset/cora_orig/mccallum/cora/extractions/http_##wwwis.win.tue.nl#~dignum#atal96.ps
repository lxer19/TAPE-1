URL: http://wwwis.win.tue.nl/~dignum/atal96.ps
Refering-URL: http://wwwis.win.tue.nl/~dignum/papers.html
Root-URL: http://www.win.tue.nl
Email: dignum@win.tue.nl  bernd@cs.ruu.nl  
Title: Modelling Social Agents: Communication as Action  
Author: Frank Dignum Bernd van Linder 
Address: P.O. Box 513, 5600 MB Eindhoven, The Netherlands  P.O. Box 80.089 Utrecht, The Netherlands  
Affiliation: Faculty of Mathematics Computer Science, Eindhoven University of Technology  Department of Computer Science, Utrecht University  
Abstract: In this paper we present a formal framework for social agents. The social agents consist of four components: the information component (containing knowledge and belief), the action component, the motivational component (where goals, intentions, etc. play arole) and the social component (containing aspects of speech acts and relations between agents). The main aim of this work was to describe all components in a uniform way, such that it is possible to verify each component separately but also formally describe the interactions between the different components. E.g. the effect of a speech act on the believes of an agent or on the commitment to a goal it pursues. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> P. Bretier and M. D. Sadek. </author> <title> A rational agent as the kernel of a cooperative spoken dialogue system: Implementing a logical theory of interaction. </title> <editor> In J. P. Muller, M. J. Wooldridge, and N. R. Jennings, editors, </editor> <booktitle> Intelligent Agents III Proceedings of the Third International Work--shop on Agent Theories, Architectures, and Languages (ATAL-96), Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1996. </year> <note> In this volume. </note>
Reference-contexts: Of course, an obligation can lead to a goal, but only if the hearer places the directive above the plan it is currently performing. How does our work compare with the other current work on communicating agents? From the papers in this volume, only Bretier & Sadek <ref> [1] </ref> formally define the effects of communicative actions. However, this theory is limited to effects on the believes and intentions of agents. We have shown that the concept of obligation also forms an important ingredient of the effects of some speech acts. <p> We have shown that the concept of obligation also forms an important ingredient of the effects of some speech acts. That is, directives and commissives always result in obligations. It must be remarked that the application for which the theory in <ref> [1] </ref> is used does not need these illocutions. Another difference between our work and that of [1] is that our theory is geared to communication between agents while their theory is geared towards the management of human-agent dialogue. The same holds for the theory of Traum [22]. <p> That is, directives and commissives always result in obligations. It must be remarked that the application for which the theory in <ref> [1] </ref> is used does not need these illocutions. Another difference between our work and that of [1] is that our theory is geared to communication between agents while their theory is geared towards the management of human-agent dialogue. The same holds for the theory of Traum [22]. Although many aspects are compatible, there are also some differences.
Reference: 2. <author> P. Cohen and H. Levesque. </author> <title> Intention is choice with commitment. </title> <journal> Artificial Intelligence, </journal> <volume> vol.42, </volume> <pages> pages 213-261, </pages> <year> 1990. </year>
Reference-contexts: Research on this subject has held the limelight ever since the pioneering work of Moore [15] in which knowledge and actions are considered. Over the years contributions have been made on both informational attitudes like knowledge and belief [14] and motivational attitudes like intentions and commitments <ref> [2, 5] </ref>. In our basic framework [8, 12] we modelled the informational attitudes of agents as well as various aspects of action by means of a theory about the knowledge, belief and abilities of agents, as well as the opportunities for, and the results of their actions. <p> The semantics will be based on Kripke structures with a variety of relations imposed on the states. We characterise this integrated framework by pointing out some differences with the formalizations proposed by Cohen & Levesque <ref> [2] </ref> and Rao & Georgeff [19]. In this extended abstract we will describe the different components and their relationships informally. <p> This implies that K j B i f holds in the resulting model. 4 Related Approaches In this section we very briefly indicate the main differences between our approach and three other approaches to model rational agents, viz. the framework proposed by Cohen & Levesque <ref> [2] </ref>, the BDI-framework of Rao & Georgeff [19] and the theoretical framework for multi-agent systems of M. Singh [21]. After that we will shortly compare our approach with the other work in this volume on communicating agents.
Reference: 3. <author> F. Dignum. </author> <title> Using Transactions in Integrity Constraints: Looking forward or backwards, what is the difference? In First International Workshop on Applied Logic: Logic at Work, </title> <address> Amsterdam, </address> <year> 1992. </year>
Reference-contexts: That is, we can use true &lt; ff &gt; to indicate that the present state can have been reached by performing ff in a previous state. However, to denote the actual previous action a new operator is needed! See <ref> [3] </ref> for a more in depth discussion of this issue. The same holds for the N EXT operator for actions. We also define a more traditional N EXT operator on formulas in terms of the N EXT operator on events.
Reference: 4. <author> F. Dignum and H. Weigand. </author> <title> Modelling communication between cooperative systems In J. </title> <editor> Iivari et al., </editor> <booktitle> Advanced information systems engineering, </booktitle> <pages> pages 140-153, </pages> <publisher> Springer, </publisher> <year> 1995. </year>
Reference-contexts: Furthermore it can be mod-elled that after an agent commits itself to achieve a goal it is obliged to perform those actions that bring about its goal. Finally, in <ref> [4, 10] </ref> we formalized communication between agents. In this theory we can show both the communication itself as well as the consequences of communication. For instance, if some authorised agent gives orders to another agent to perform a certain action, the latter agent will be obliged to perform the action. <p> This concept is also part of the social level if the commitment is made towards another agent. As the result of i performing a COM M IT (i; j; ff) action the formula O ij ff becomes true. (See <ref> [4] </ref> for more details.) I.e. by committing itself to an action, an agent i obliges itself towards j to perform the action ff. The commitment can be a private one if j is the same as i.
Reference: 5. <author> F. Dignum, J.-J.Ch. Meyer, R. Wieringa and R. Kuiper. </author> <title> A modal approach to intentions, commitments and obligations: intention plus commitment yields obligation. </title> <booktitle> DEON'96 Workshop on deontic logic in computer science, </booktitle> <address> Lisbon, </address> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: Research on this subject has held the limelight ever since the pioneering work of Moore [15] in which knowledge and actions are considered. Over the years contributions have been made on both informational attitudes like knowledge and belief [14] and motivational attitudes like intentions and commitments <ref> [2, 5] </ref>. In our basic framework [8, 12] we modelled the informational attitudes of agents as well as various aspects of action by means of a theory about the knowledge, belief and abilities of agents, as well as the opportunities for, and the results of their actions. <p> In this framework it can for instance be modelled that an agent knows that it is able to perform an action and that it knows that it is correct to perform that action to bring about some result. In <ref> [5, 11] </ref> we dealt with the motivational attitudes of agents. In these papers we defined the concepts of wishes, goals, intentions, and commitments or obligations. <p> In this paper we intend to bring the different fragments of the framework together in one all-embracing formal system. That is, we will define a model for the following concepts: belief, knowledge, action, wish, goal, decision, intention, commitment, obligation and communication. Following <ref> [5, 11] </ref> we base this model on dynamic logic [7], which is extended with epistemic, doxastic, temporal and deontic (motivational) operators. The semantics will be based on Kripke structures with a variety of relations imposed on the states. <p> The registration of the violation is done through the introduction of a deontic relation between the worlds. This relation connects each world with the set of ideal worlds with respect to that world. More details about the formal semantics of this deontic operator can be found in <ref> [5] </ref>. Secondly, an obligation to perform an action leads to the goal of having performed the action.
Reference: 6. <author> F. Dignum. </author> <title> Social Interactions of Autonomous Agents; Private and Global Views on Communication. </title> <note> Submitted to ModelAge'97 workshop. </note>
Reference-contexts: For the basic illocutions used in the ADEPT system [18] this has been done in <ref> [6] </ref> and has led to the discovery that the seemingly simple ACCEPT message has unexpected results. Also we want to define an agent architecture for communicating agents that adhere to our theory. Some groundwork in this respect has been done in [23].
Reference: 7. <author> D. Harel. </author> <title> First Order Dynamic Logic. </title> <publisher> LNCS 68 Springer, </publisher> <year> 1979. </year>
Reference-contexts: That is, we will define a model for the following concepts: belief, knowledge, action, wish, goal, decision, intention, commitment, obligation and communication. Following [5, 11] we base this model on dynamic logic <ref> [7] </ref>, which is extended with epistemic, doxastic, temporal and deontic (motivational) operators. The semantics will be based on Kripke structures with a variety of relations imposed on the states. <p> Following [8, 24] we use parameterised actions to describe the event consisting of a particular agent's execution of an action. We let ff (i) indicate that agent i performs the action ff. The results of actions are modelled using dynamic logic as described by Harel in <ref> [7] </ref>. We use [ff (i)]OE to indicate that if agent i performs the action indicated by ff the result will be OE. Note that it does not state anything about whether the action will actually be performed.
Reference: 8. <author> W. van der Hoek, B. van Linder and J.-J.Ch. Meyer. </author> <title> A logic of capabilities. </title> <editor> In Nerode and Matiyasevich, eds, </editor> <booktitle> Proceedings of LFCS'94, </booktitle> <volume> LNCS 813, </volume> <pages> pages 366-378. </pages>
Reference-contexts: Over the years contributions have been made on both informational attitudes like knowledge and belief [14] and motivational attitudes like intentions and commitments [2, 5]. In our basic framework <ref> [8, 12] </ref> we modelled the informational attitudes of agents as well as various aspects of action by means of a theory about the knowledge, belief and abilities of agents, as well as the opportunities for, and the results of their actions. <p> The main dynamic notion that we consider is that of actions, which we interpret as functions that map some some state of affairs into another one. Following <ref> [8, 24] </ref> we use parameterised actions to describe the event consisting of a particular agent's execution of an action. We let ff (i) indicate that agent i performs the action ff. The results of actions are modelled using dynamic logic as described by Harel in [7]. <p> This is done through the predicate OP P : OP P (ff (i)) indicates that agent i has the opportunity to do ff, i.e. the event ff (i) will possibly take place. In <ref> [8] </ref> we also used an ability predicate. This predicate was used to indicate that an agent has the inherent possibility to perform a certain action (at a certain place and time).
Reference: 9. <author> D. Kinny and M. Georgeff. </author> <title> Commitment and Effectiveness of Situated Agents. </title> <booktitle> In Proceedings International Joint Conferenceon Artificial Intelligence, </booktitle> <address> Sydney, Australia, </address> <pages> pages 82-88. </pages>
Reference-contexts: The last point also shows one of the main differences between our framework and that of Rao & Georgeff. In their framework it holds that if an agent intends to perform an action it will also actually perform the action. They weaken this assumption in <ref> [9] </ref>, where they investigate different strategies with respect to commitment to a goal. An agent can be single minded when it always performs its intended actions and open minded when it discards its goals on the basis of new information it receives.
Reference: 10. <author> B. van Linder, W. van der Hoek and J.-J.Ch. Meyer. </author> <title> Communicating rational agents. </title> <editor> In Nebel and Dreschler-Fisher, eds, </editor> <booktitle> Proceedings of KI'95, </booktitle> <volume> LNCS 861, </volume> <pages> pages 202-213. </pages>
Reference-contexts: Furthermore it can be mod-elled that after an agent commits itself to achieve a goal it is obliged to perform those actions that bring about its goal. Finally, in <ref> [4, 10] </ref> we formalized communication between agents. In this theory we can show both the communication itself as well as the consequences of communication. For instance, if some authorised agent gives orders to another agent to perform a certain action, the latter agent will be obliged to perform the action.
Reference: 11. <author> B. van Linder, W. van der Hoek and J.-J.Ch. Meyer. </author> <title> How to motivate your agents. On making promises that you can keep. </title> <editor> In Wooldridge, Muller and Tambe, eds, </editor> <booktitle> Intelligent Agents II, </booktitle> <volume> LNCS 1037, </volume> <pages> pages 17-32. </pages>
Reference-contexts: In this framework it can for instance be modelled that an agent knows that it is able to perform an action and that it knows that it is correct to perform that action to bring about some result. In <ref> [5, 11] </ref> we dealt with the motivational attitudes of agents. In these papers we defined the concepts of wishes, goals, intentions, and commitments or obligations. <p> In this paper we intend to bring the different fragments of the framework together in one all-embracing formal system. That is, we will define a model for the following concepts: belief, knowledge, action, wish, goal, decision, intention, commitment, obligation and communication. Following <ref> [5, 11] </ref> we base this model on dynamic logic [7], which is extended with epistemic, doxastic, temporal and deontic (motivational) operators. The semantics will be based on Kripke structures with a variety of relations imposed on the states.
Reference: 12. <author> B. </author> <title> van Linder Modal Logics for Rational Agents, </title> <type> PhD Thesis, </type> <institution> Utrecht University, </institution> <year> 1996. </year>
Reference-contexts: Over the years contributions have been made on both informational attitudes like knowledge and belief [14] and motivational attitudes like intentions and commitments [2, 5]. In our basic framework <ref> [8, 12] </ref> we modelled the informational attitudes of agents as well as various aspects of action by means of a theory about the knowledge, belief and abilities of agents, as well as the opportunities for, and the results of their actions.
Reference: 13. <author> J.-J.Ch. Meyer. </author> <title> A different approach to deontic logic. </title> <journal> In Notre Dame Journal of Formal Logic, </journal> <volume> vol.29, </volume> <pages> pages 109-136, </pages> <year> 1988. </year>
Reference-contexts: Ri (i; s) fff j Sf (i; ff; s) 6= ;g and for all s 2 some s 0 2 exists with (s; s 0 ) 2 Ro. The complete semantics contains an algebraic semantics of action expresses, based on the action semantics of Meyer <ref> [13] </ref>. In this abstract we will abstract from the algebraic interpretation of actions and instead interpret actions as functions on states of affairs. For the meta-actions the state-transition interpretation is not adequate, because meta-actions do not change states but they change relations between states.
Reference: 14. <author> J.-J.Ch. Meyer and W. van der Hoek. </author> <title> Epistemic Logic for AI and computer science, </title> <publisher> CUP, </publisher> <year> 1995. </year>
Reference-contexts: Research on this subject has held the limelight ever since the pioneering work of Moore [15] in which knowledge and actions are considered. Over the years contributions have been made on both informational attitudes like knowledge and belief <ref> [14] </ref> and motivational attitudes like intentions and commitments [2, 5].
Reference: 15. <author> R. Moore. </author> <title> A formal theory of knowledge and action. </title> <editor> In J. Hobbs and R. Moore, eds, </editor> <booktitle> Formal theories of the commonsense world, </booktitle> <pages> pages 319-358, </pages> <publisher> Ablex Publ. </publisher> <address> Comp., </address> <year> 1985. </year>
Reference-contexts: 1 Introduction The formalization of rational agents is a topic of continuing interest in AI. Research on this subject has held the limelight ever since the pioneering work of Moore <ref> [15] </ref> in which knowledge and actions are considered. Over the years contributions have been made on both informational attitudes like knowledge and belief [14] and motivational attitudes like intentions and commitments [2, 5].
Reference: 16. <author> J. P. Muller. </author> <title> A cooperation model for autonomous agents. </title> <editor> In J. P. Muller, M. J. Wooldridge, and N. R. Jennings, editors, </editor> <booktitle> Intelligent Agents III Proceedings of the Third International Workshop on Agent Theories, Architectures, and Languages (ATAL-96), Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1996. </year> <note> In this volume. </note>
Reference-contexts: However, it is easy to define suitable abbreviations for standard formulas. At least, working this way, it is clear what these abbreviations mean exactly! In subsequent work we want to show how communication protocols that are used in more practical work like <ref> [16, 18] </ref> can be given a formal semantics in our framework. For the basic illocutions used in the ADEPT system [18] this has been done in [6] and has led to the discovery that the seemingly simple ACCEPT message has unexpected results.
Reference: 17. <author> P. Noriega and C. Sierra. </author> <title> Towards layered dialogical agents. </title> <editor> In J. P. Muller, M. J. Wooldridge, and N. R. Jennings, editors, </editor> <booktitle> Intelligent Agents III Proceedings of the Third International Workshop on Agent Theories, Architectures, and Languages (ATAL-96), Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1996. </year> <note> In this volume. </note>
Reference-contexts: Besides mutual knowledge and believe this is an important relation, because it indicates the expectations that the participants have of each other. Finally the work of Noriega & Sierra <ref> [17] </ref> comes very close in spirit to our work. They also try to give one formal framework for the different components of communicating agents. <p> The relation between the components is given by so-called bridge rules. We assume a uniform language for all agents and components. This provides for an automatic integration of the components. The main point in which the theory in <ref> [17] </ref> is lacking compared to ours is the semantics of the speech acts themselves and their effects. 5 Conclusions In this paper we presented an informal overview and a sketchy formalization of the concepts that we consider essential to model rational agents.
Reference: 18. <author> T. J. Norman, N. R. Jennings, P. Faratin, and E. H. Mamdani. </author> <title> Designing and implementing a multi-agent architecture for business process management. </title> <editor> In J. P. Muller, M. J. Wooldridge, and N. R. Jennings, editors, </editor> <booktitle> Intelligent Agents III Proceedings of the Third International Workshop on Agent Theories, Architectures, and Languages (ATAL-96), Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1996. </year> <note> In this volume. </note>
Reference-contexts: However, it is easy to define suitable abbreviations for standard formulas. At least, working this way, it is clear what these abbreviations mean exactly! In subsequent work we want to show how communication protocols that are used in more practical work like <ref> [16, 18] </ref> can be given a formal semantics in our framework. For the basic illocutions used in the ADEPT system [18] this has been done in [6] and has led to the discovery that the seemingly simple ACCEPT message has unexpected results. <p> For the basic illocutions used in the ADEPT system <ref> [18] </ref> this has been done in [6] and has led to the discovery that the seemingly simple ACCEPT message has unexpected results. Also we want to define an agent architecture for communicating agents that adhere to our theory. Some groundwork in this respect has been done in [23].
Reference: 19. <author> A.S. Rao and M.P. Georgeff. </author> <title> Modeling rational agents within a BDI-architecture. </title> <editor> In J. Allen et al., eds, </editor> <booktitle> Proceedings of KR'91, </booktitle> <pages> pages 473-484, </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: The semantics will be based on Kripke structures with a variety of relations imposed on the states. We characterise this integrated framework by pointing out some differences with the formalizations proposed by Cohen & Levesque [2] and Rao & Georgeff <ref> [19] </ref>. In this extended abstract we will describe the different components and their relationships informally. <p> that K j B i f holds in the resulting model. 4 Related Approaches In this section we very briefly indicate the main differences between our approach and three other approaches to model rational agents, viz. the framework proposed by Cohen & Levesque [2], the BDI-framework of Rao & Georgeff <ref> [19] </ref> and the theoretical framework for multi-agent systems of M. Singh [21]. After that we will shortly compare our approach with the other work in this volume on communicating agents.
Reference: 20. <author> J.R. Searle. </author> <title> Speech Acts. </title> <publisher> CUP, </publisher> <year> 1969. </year>
Reference-contexts: sincere agents and therefore we assume that an agent can only commit itself to actions that it intends to do eventually, i.e. intention provides a precondition for commitment. 2.4 The Social Level The COM M IT described in the previous section is one of the four types of speech acts <ref> [20] </ref> that play a role at the social level. Speech acts are used to communicate between agents. The result of a speech act is a change in the doxastic or deontic state of an agent, or in some cases a change in the state of the world.
Reference: 21. <author> M. Singh. </author> <title> Multiagent Systems. </title> <publisher> LNAI 799, Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: Singh <ref> [21] </ref>. After that we will shortly compare our approach with the other work in this volume on communicating agents. The main difference between our approach and the one of Cohen & Levesque is that they define intentions in terms of goals and beliefs.
Reference: 22. <author> D. R. Traum. </author> <title> A reactive-deliberative model of dialogue agency. </title> <editor> In J. P. Muller, M. J. Wooldridge, and N. R. Jennings, editors, </editor> <booktitle> Intelligent Agents III Proceedings of the Third International Workshop on Agent Theories, Architectures, and Languages (ATAL-96), Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1996. </year> <note> In this volume. </note>
Reference-contexts: Another difference between our work and that of [1] is that our theory is geared to communication between agents while their theory is geared towards the management of human-agent dialogue. The same holds for the theory of Traum <ref> [22] </ref>. Although many aspects are compatible, there are also some differences. One of the main differences is that in the communication between humans and agents the detection of the illocution of messages is not trivial and important to steer the dialogue in a natural way.
Reference: 23. <author> E. Verhagen, F. Dignum and H. Weigand. </author> <title> A Language/Action Perspective on Cooperative Information Agents. </title> <editor> In F. Dignum at al., eds, </editor> <booktitle> Communication Modeling The Language/Action Perspective (LAP-96), electronic Workshops in Computing, </booktitle> <publisher> Springer-Verlag, </publisher> <address> London, </address> <year> 1996. </year>
Reference-contexts: Also we want to define an agent architecture for communicating agents that adhere to our theory. Some groundwork in this respect has been done in <ref> [23] </ref>. Currently we are working on an implementation of this framework to test the ideas. Acknowledgements We would like to thank the anonymous referees for their useful remarks and the workshop participants whose remarks contributed to this greatly improved final version of the paper.
Reference: 24. <author> R. Wieringa, J.-J.Ch. Meyer and H. Weigand. </author> <title> Specifying dynamic and deontic integrity constraints. </title> <journal> Data & knowledge engineering, </journal> <volume> vol.4, </volume> <pages> pages 157-189, </pages> <year> 1989. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: The main dynamic notion that we consider is that of actions, which we interpret as functions that map some some state of affairs into another one. Following <ref> [8, 24] </ref> we use parameterised actions to describe the event consisting of a particular agent's execution of an action. We let ff (i) indicate that agent i performs the action ff. The results of actions are modelled using dynamic logic as described by Harel in [7].
References-found: 24

