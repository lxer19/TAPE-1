URL: http://www.cs.berkeley.edu/~yelick/yelick/phd.ps.Z
Refering-URL: http://www.cs.berkeley.edu/~yelick/papers.html
Root-URL: 
Title: Using Abstraction in Explicitly Parallel Programs  
Author: by Katherine Anne Yelick 
Address: 1990  
Affiliation: c Massachusetts Institute of Technology,  
Abstract: This report is a revised version of the author's thesis, which was submitted to the Department of Electrical Engineering and Computer Science on December 31, 1990 in partial fulfillment of the requirements for the degree of Doctor of Philosophy at the Massachusetts Institute of Technology. The thesis was supervised by John V. Guttag. The author's current address is the Computer Science Division, University of California, Berkeley, CA 94720. 
Abstract-found: 1
Intro-found: 1
Reference: [ABC + 87] <author> Frances Allen, Michael Burke, Philippe Charles, Ron Cytron, and Jeanne Ferrante. </author> <title> An overview of the PTRAN analysis system for multiprocessing. </title> <booktitle> In Proceedings of the 1987 International Conference on Supercomputing, </booktitle> <year> 1987. </year>
Reference-contexts: The most significant effort has been in the area of parallelizing Fortran programs, where signifi 124 cant progress has occurred in developing algorithms to detect parallelism for both numerical <ref> [ABC + 87, PGH + 89] </ref> and symbolic [LH88] programs. These techniques are most promising for numerical programs, most of the techniques focus on parallelizing loops. The payoffs for these compilation techniques on complete application programs running on existing machines are not yet known.
Reference: [ABLL90] <author> Thomas Anderson, Brian Bershad, Edward Lazoswka, and Henry Levy. </author> <title> Scheduler activations: Kernel support for effective user-level thread management. </title> <type> Technical Report 90-04-02, </type> <institution> University of Washington, </institution> <address> Seattle, Washington, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: A more complete solution to the problem of operating system interaction is given in recent work by Anderson and others <ref> [ABLL90] </ref>. They modify the operating system interface to allow the application scheduler to communicate with the operating system scheduler, making it possible to maintain the invariant that the number of threads is no greater than the number of available processors. <p> A different operating system interface could prevent this problem by allowing the operating system sched-uler to communicate with the application scheduler; if communication is sufficiently limited, this interface need not incur the full cost of operating system scheduling <ref> [ABLL90] </ref>. Using our method, program performance depends on the number of threads being no greater than the number of processors, but program correctness does not depend on this assumption.
Reference: [AH90a] <author> Sarita V. Adve and Mark D. Hill. </author> <title> Implementing sequential consistency in cache-based systems. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <month> April </month> <year> 1990. </year>
Reference-contexts: Although many shared memory implementations are actually linearizable, there are proposals for sequentially consistent memory that is not linearizable, so we used the weaker assumption that memory is sequentially consistent. See <ref> [AH90a, GLL + 90, BR90, DS88, SS88] </ref> for examples of memory implementations that are sequentially consistent but not necessarily linearizable. 43 44 Chapter 3 Implementing Concurrent Data Types In this chapter we present specifications and implementations of a number of concurrent data types.
Reference: [AH90b] <author> Sarita V. Adve and Mark D. Hill. </author> <title> Weak ordering-a new definition. </title> <booktitle> In 17th International Symposium on Computer Architecture, </booktitle> <month> April </month> <year> 1990. </year>
Reference-contexts: We show that with parallelism, basic units of abstraction must be restricted, notions of correctness changed, and specifications augmented. In particular, we examine correctness notions that have been proposed by others <ref> [Lam80, Lam79, HW90, AH90b] </ref>, compare them on practical grounds, and offer a new correctness notion of our own. Our notion is based on linearizability [HW90], but is strictly weaker. <p> Conditional correctness notions have appeared in the multiprocessor literature for implementations of weak shared memory, where memory is shown to be sequentially consistent given certain assumptions about how memory operations are used <ref> [DS88, AH90b, SS88] </ref>. We generalize these concepts to arbitrary shared data types and give a linguistic mechanism for specifying the restrictions on use. In this section we assume that the user of an abstraction is willing to make promises about how the operations will be used. <p> This demonstrates the practical power of sequentially consistent memory, as opposed to weaker models of memory that assume the programmer will use synchronization around all shared memory accesses <ref> [DS88, AH90b] </ref>. 45 * The implementation of the mapping type uses a novel backoff strategy for avoiding colli- sions in the space of keys being mapped. * Taken as a whole, the set of data types demonstrate the power of a simple class of abstractions.
Reference: [AL88] <author> Martn Abadi and Leslie Lamport. </author> <title> The existence of refinement mappings. </title> <type> Research Report 29, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <address> Palo Alto, CA, </address> <year> 1988. </year>
Reference-contexts: Thus, in addition to the actions just described, all three axioms have stuttering actions as instances, where a stuttering action is one in which the pre and post states are equal <ref> [AL88] </ref>. Transition axioms, and the state machines they define, are useful as specifications, but they cannot express every interesting property of programs. Transition axioms define safety properties, which make a statement about what bad things cannot happen in an execution, e.g., what states cannot be reached. <p> A precise definition of satisfaction requires identification of the external states as in <ref> [AL88] </ref> or external actions as in [LT87], where the external states or actions are things observable by the user of the 84 State Components E : container [equation] + no match Initially E = (pattern : = target) Transition Axioms decomposition ((p = t) 2 E) & (:is var (p)) & <p> Notions of satisfaction between transition axiom specifications have been extensively studied in the literature; the notions have been formalized in various models, and techniques for proving satisfaction, based on the idea of a refinement mapping have been described <ref> [Lam80, AL88, LF81, LT87, CM88] </ref>. In Section 4.3.5, we discuss satisfaction in more detail and give correctness arguments using refinement mappings [AL88]. In this section, we include only those ideas that are relevant to understanding what the various specifications mean, and how they differ. <p> In Section 4.3.5, we discuss satisfaction in more detail and give correctness arguments using refinement mappings <ref> [AL88] </ref>. In this section, we include only those ideas that are relevant to understanding what the various specifications mean, and how they differ. Specification 4-4 has universal weak fairness as its liveness property, which is sufficient, in part, because stuttering actions are not legal. <p> The correctness arguments for matching use standard refinement mapping proof techniques <ref> [AL88] </ref>. Correctness of the Transition-Axiom Specifications In Section 4.3.1 we argued that specification 4-3 solves the matching problem. <p> The usual notion of satisfaction between transition axiom specifications requires preservation of whatever states (or actions) are externally visible. For example, in the state-based approach of <ref> [AL88] </ref>, certain components of the state are designated as external; one specification is said to satisfy another if for any live execution of the first, there is a live execution of the second such that the histories restricted to external states are identical (modulo finite stuttering actions). <p> The reader is referred to <ref> [AL88] </ref> for a precise definition of satisfaction; similar notions of satisfaction are defined for the I/O Automata model [LT87] and for Unity programs [CM88]. 108 Technically, our series of specifications, 4-4 through 4-6 do not satisfy specificaton 4-3 be-cause the initial and final states differ in minor ways. <p> An abstraction function maps states of a refined specification to states of the original (abstract) specification. Abstraction functions have been used extensively in the context of abstract data types for sequential programs [LG86], and by others in reasoning about parallel and distributed programs <ref> [AL88, LT87, HW90] </ref>. 3 In our use, the state machine part of a specification is viewed as an abstract data type, where the state components contain the type's values, and the transition axioms specify the type's operations. <p> To prove that S 1 is a refinement of S 2 , there are three steps <ref> [AL88] </ref>: 1. Define an abstraction function, A, from the states of S 1 to states of S 2 . 2. Prove that S 1 ensures the safety property of S 2 . <p> The complication comes from the possibility of interleaving of low-level actions from different high-level actions, representing overlaps in the execution of high-level actions. It is not alway possible to define an abstraction function on indiviual states, since the abstract value may depend on the history (or even future <ref> [AL88] </ref>) of the execution. To make the abstraction function definable, auxiliary information is added to the specification state to record an execution's history [OG76]. The auxiliary information does not change the specification; neither the transition axioms nor the liveness property in the augmented specification depend on auxiliary values.
Reference: [Ame87] <author> Pierre America. </author> <title> Inheritance and subtyping in a parallel object-oriented language. </title> <booktitle> In Proceedings of the ECOOP, </booktitle> <pages> pages 234-242. </pages> <publisher> Springer-Verlag, </publisher> <month> June </month> <year> 1987. </year>
Reference-contexts: The payoffs for these compilation techniques on complete application programs running on existing machines are not yet known. All of the implicit techniques are conservative, and they typically do not generate the kind of parallelism in which concurrent tasks mutate data concurrently. Message-passing paradigms, as exemplified by <ref> [CD90, Ame87] </ref>, are popular for distributed memory machines. In the simplest of these, a program is organized around objects, and communication is done by sending messages to objects.
Reference: [And89] <author> Thomas Anderson. </author> <title> The performance implications of lock management alternatives for shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 1989 International Conference on Parallel Processing. IEEE, </booktitle> <year> 1989. </year> <month> 161 </month>
Reference-contexts: The reset operation releases the spinlock . The specification of spinlocks includes a test operation to read the value of a spinlock without modifying it. Our applications do not use test , but it is available through a memory read and can be useful implementing test-and-test&set style synchronization. See <ref> [And89] </ref> for a description 52 spinlock = datatype has create; test&set; reset create = procedure () returns (spinlock) ensures: returns an unlocked spinlock test&set = procedure (s: spinlock) returns (bool) ensures: if s is unlocked then lock s and return true else leave s locked and return false test = procedure <p> Thus, the programming model involves a single parallel module (the scheduler) invoking operations (the transition procedures) on a concurrent object (the program state). Application-specific scheduling has been demonstrated to result in better performance than when systems schedulers are used directly <ref> [And89] </ref>, and in particular, the worker model of application scheduling has been used successfully in a number of parallel applications [MNS87, CG89, RV89, JW90].
Reference: [ANP87] <author> Arvind, Rishiyur S. Nikhil, and Keshav K. Pingali. I-structures: </author> <title> Data structures for parallel computing. Computation Structures Group Memo 269, </title> <institution> Massachusetts Institute of Technology Laboratory for Computer Science, Cambridge, Massachusetts, </institution> <month> February </month> <year> 1987. </year>
Reference-contexts: A more familiar parallel programming technique that relies on a trivial kind of monotonicity is the use of objects that are initially undefined, but once they become defined they are never mutated <ref> [ANP87] </ref>. An even more degenerate case of monotonicity is an immutable object. 3.3.5 Mappings A mapping type stores a set of domain/range pairs for arbitrary types of domain and range elements. There are interesting features of our mapping type in both its specification and its implementation. <p> For some programs, object mutations are mainly instantiations, i.e., an object may be created in some partially constructed form, and parallel threads fill in the missing pieces. This form of mutation can be handled by futures [Hal85], I-structures <ref> [ANP87] </ref>, and logical variables in logic programs [Rin89]. Since objects cannot be mutated after instantiation, the only kind of race condition arises from whether or not an object has been computed. Special hardware or software checks can prevent threads from observing uninstantiated objects.
Reference: [AW91] <author> Hagit Attiya and Jennifer L. Welch. </author> <title> Sequential consistency versus linearizability. </title> <booktitle> In Symposium on Parallel Algorithms. ACM SIGACT-SIGARCH, </booktitle> <year> 1991. </year>
Reference-contexts: Attiya and Welch <ref> [AW91] </ref> prove that linearizable memory is, for a particular abstract machine model, more expensive than sequentially consistent memory. For these reasons we assume that a machine provides sequentially consistent built-in operations, but require that software operations built on top are linearizable.
Reference: [BDH86] <author> Leo Bachmair, Nachum Dershowitz, and Jeih Hsiang. </author> <title> Orderings for equational proofs. </title> <booktitle> In Proceedings of the Symposium on Logic in Computer Science, </booktitle> <pages> pages 346-357. </pages> <publisher> IEEE, </publisher> <year> 1986. </year>
Reference-contexts: In section 5.2 we define the completion problem, and in Section 5.3 we present a transition-axiom specification for completion that is adapted from the presentation of <ref> [BDH86] </ref>. <p> a complete term) and parallelizing within critical pairing (of a single pair of rules) are less clear, but we did not parallelize either of those 132 operations because we found sufficient parallelism at a higher level. 5.2 Problem Statement The definitions presented here are consistent with Bachmair, Dershowitz, and Hsiang <ref> [BDH86] </ref>. We assume a familiarity with the notions of terms, equations, and substitutions, as defined in Chapter 4, and we also continue the convention that, with possible subscripts, x is a variable, a and b are constants, f and g are arbitrary function symbols, and s and t are terms. <p> Completion procedures can be made failure resistant by allowing the reduction ordering to be modified in certain restricted ways during the completion process [DF85]. Completion procedures can be made unfailing by leaving some equations unordered and restricting the domain of terms to which rules can be applied <ref> [BDH86] </ref>. Because these generalizations complicate the completion process, we restrict our attention to completion procedures in which a fixed ordering (&gt;) is given. <p> Failure conditions will be discussed again after we describe the process through which new equations arise during completion. 5.3 A Transition-Axiom Specification The transition axiom specification presented in this section is adapted from the description of standard completion by Bachmair, Dershowitz and Hsiang <ref> [BDH86] </ref>. It reformulates the original completion procedure of Knuth and Bendix [KB70] as a set of non-deterministically applied transition axioms. The transition-axiom specification for completion relies on the following definitions. An occurrence is a location in a term and is denoted by a finite sequence of integers. <p> 1 is older than r 2 , then r 1 and r 2 satisfy an age restriction, which we denote by the predicate age restrict (r 1 ; r 2 ). 137 Using the age of rules to solve the technical problem is mentioned in the original inference rule formulation <ref> [BDH86] </ref>, and the validity of this solution was confirmed by Dershowitz [Der90]. <p> A transition-axiom specification for a completion procedure is given in Figure 5-3. It is similar to the inference rule description given in <ref> [BDH86] </ref>. The state consists of a container of equations E and a container of rewrite rules R. <p> Our procedure is significant from an algorithmic standpoint as well: the completion process is complicated and the parallel procedure differs in non-trivial ways from sequential ones. 154 We used the abstract description of completion given by Bachmair et al <ref> [BDH86] </ref> as a start-ing point for our design, but there is a large step between their description and the directly implementable transition-axiom specification that describes our procedure.
Reference: [BGHL87] <author> Andrew D. Birrell, John V. Guttag, James J. Horning, and Roy Levin. </author> <title> Synchronization primitives for multiprocessor: A formal specification. </title> <type> Technical Report 20, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <address> Palo Alto, CA, </address> <year> 1987. </year>
Reference-contexts: Our specifications are informal although they have a similar structure to interface specifications written in the Larch family of formal specification languages [GHW85, Win83]. Others have used Larch-style specifications to specify concurrent operations <ref> [HW90, BGHL87] </ref>. <p> The lock specification is not safe, in that any thread may release a lock held by another thread; it is only programming convention that prevents this from happening. A safer locking abstraction could be defined <ref> [BGHL87] </ref>, or, alternatively, programming language restrictions could enforce the programming convention that locks are always released by the thread that acquired them [Bir89].
Reference: [BHJ + 87] <author> A. Black, N. Hutchinson, E. Jul, H. Levy, and L. Carter. </author> <title> Distribution and abstract types in emerald. </title> <journal> IEEE Transactions on Software Engineering, </journal> <pages> pages 65-76, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: The most common example of a distributed object is a memory cell in a multiprocessor with caches, but many others have been designed and implemented for both distributed systems <ref> [Ell85, BT88, BHJ + 87] </ref> and for multiprocessors [Luc87b, Dal86, CD90]. To access a distributed object, these systems provide sophisticated run-time support so that each object is given a single name; the run-time system must determine what node in the distributed object should be used for a particular operation.
Reference: [Bir89] <author> Andrew D. Birrell. </author> <title> An introduction to programming with threads. </title> <type> Technical Report 35, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <address> Palo Alto, CA, </address> <year> 1989. </year>
Reference-contexts: A safer locking abstraction could be defined [BGHL87], or, alternatively, programming language restrictions could enforce the programming convention that locks are always released by the thread that acquired them <ref> [Bir89] </ref>. The locks in our programs are implemented using spinlocks : the acquire operation repeatedly calls test&set until it successfully sets the spinlock and the release procedure calls reset .
Reference: [BR90] <author> Roberto Bisiani and Mosur Ravishankar. </author> <title> PLUS: A distributed shared-memory system. </title> <booktitle> In 17th International Symposium on Computer Architecture, </booktitle> <pages> pages 115-124, </pages> <year> 1990. </year>
Reference-contexts: Although many shared memory implementations are actually linearizable, there are proposals for sequentially consistent memory that is not linearizable, so we used the weaker assumption that memory is sequentially consistent. See <ref> [AH90a, GLL + 90, BR90, DS88, SS88] </ref> for examples of memory implementations that are sequentially consistent but not necessarily linearizable. 43 44 Chapter 3 Implementing Concurrent Data Types In this chapter we present specifications and implementations of a number of concurrent data types.
Reference: [BT88] <author> H. Bal and A. Tannenbaum. </author> <title> Distributed programming with shared data. </title> <booktitle> In International Conference on Computer Languages, </booktitle> <year> 1988. </year>
Reference-contexts: The most common example of a distributed object is a memory cell in a multiprocessor with caches, but many others have been designed and implemented for both distributed systems <ref> [Ell85, BT88, BHJ + 87] </ref> and for multiprocessors [Luc87b, Dal86, CD90]. To access a distributed object, these systems provide sophisticated run-time support so that each object is given a single name; the run-time system must determine what node in the distributed object should be used for a particular operation.
Reference: [Buc85] <author> B. </author> <title> Buchberger. Basic features and development of the critical pair completion procedure. </title> <booktitle> In Proceedings of the First International Conference on Rewriting Techniques and Applications, Dijon, France, </booktitle> <pages> pages 1-45. </pages> <publisher> Springer-Verlag, LNCS 202, </publisher> <month> May </month> <year> 1985. </year> <month> 162 </month>
Reference-contexts: The Knuth-Bendix procedure, a sequential solution to the completion problem, has been extensively studied, modified, and extended. (See <ref> [Buc85] </ref> for a historical survey of completion procedures, with more than 200 references that include algorithms, applications, and implementations.) Our procedure is significant from an algorithmic standpoint, since the parallel procedure differs in non-trivial ways from sequential ones. <p> The original completion procedure was discovered by Knuth and Bendix [KB70], and has since been studied, modified, and extended. See <ref> [Buc85] </ref>, for a historical survey of completion procedures, with more than 200 references that include algorithms, applications, and implementations. A careful statement of the completion problem requires term rewriting theory that is unrelated to the problems of parallel program development.
Reference: [CD90] <author> Andrew A. Chien and William J. Dally. </author> <title> Experience with concurrent aggregates (CA): </title> <booktitle> Implementation and programming. In Proceedings of the Fifth Distributed Memory Conference, </booktitle> <month> April </month> <year> 1990. </year>
Reference-contexts: We refer to such objects as multi-ported objects and to each thread's version as a port. Implementations of this kind are prevalent in implementations of shared and distributed objects but we know of no other work that describes the specifications of the procedures that access these object. (See <ref> [Ell85, Her90, CD90, WW90] </ref> for some examples of objects that contain thread-specific data.) The specification of a multi-ported object typically has an interference specification that depends on the port being used, which is important because it means that a multi-ported object looks different than a normal object, even at the abstract <p> The most common example of a distributed object is a memory cell in a multiprocessor with caches, but many others have been designed and implemented for both distributed systems [Ell85, BT88, BHJ + 87] and for multiprocessors <ref> [Luc87b, Dal86, CD90] </ref>. To access a distributed object, these systems provide sophisticated run-time support so that each object is given a single name; the run-time system must determine what node in the distributed object should be used for a particular operation. <p> The payoffs for these compilation techniques on complete application programs running on existing machines are not yet known. All of the implicit techniques are conservative, and they typically do not generate the kind of parallelism in which concurrent tasks mutate data concurrently. Message-passing paradigms, as exemplified by <ref> [CD90, Ame87] </ref>, are popular for distributed memory machines. In the simplest of these, a program is organized around objects, and communication is done by sending messages to objects. <p> Computation at a single object is sequential, so the programmer is left with the options of refraining from abstraction, i.e., not building any large objects, or of producing programs with little parallelism. In <ref> [CD90] </ref>, objects can be grouped together into a multi-object abstraction. Our approach could be used with a message-passing language, although some of the low-level implementations would be different.
Reference: [CG89] <author> Nicholas Carriero and David Gelernter. </author> <title> Linda in context. </title> <journal> Communications of the ACM, </journal> <volume> 32(4) </volume> <pages> 444-458, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: However, the high-level approach does influence the low-level implementations in one regard: we assume there is application-specific scheduling, which means the application program schedules tasks (short-lived computations) on top of the system-level threads (long-lived computations) <ref> [RV89, CG89, JW90] </ref>. The scheduling model will be discussed further in Chapter 4, but for now, the important issue is the interaction between scheduling and synchronization. <p> Application-specific scheduling has been demonstrated to result in better performance than when systems schedulers are used directly [And89], and in particular, the worker model of application scheduling has been used successfully in a number of parallel applications <ref> [MNS87, CG89, RV89, JW90] </ref>. The worker model is an example of a user-level scheduling paradigm; it's definitive characteristic is that the tasks being scheduled are short-lived, so each is allowed run until it either blocks or finishes. Thus, the worker model avoids the complication and overhead of time-slicing schedulers. <p> The solution to both problems is to start a fixed number of threads at the beginning of a program's execution, and to schedule tasks onto these threads. Examples of this approach 100 include tuple spaces <ref> [CG89] </ref>, work crews [RV89], and supervisors [JW90]; the approaches differ in the kinds of synchronization allowed between tasks, and the underlying scheduling algorithm. A task is a procedure invocation (a procedure plus input arguments) that is guaranteed to terminate. <p> In [CD90], objects can be grouped together into a multi-object abstraction. Our approach could be used with a message-passing language, although some of the low-level implementations would be different. The Linda programming language <ref> [CG89] </ref> gives a uniform treatment to scheduling issues and synchronization, but includes a global space of dynamically created objects as part of the programming model. The scheduling strategies we use in the transition-based approach use a similar idea, i.e., tasks are placed in a shared heap.
Reference: [CL88] <author> Hubert Comon and Pierre Lescanne. </author> <title> Equational programs and disunification. </title> <type> Research Report 904, </type> <institution> Unite de Recherche INRIA-Lorraine, Domaine de Voluceau Roc-quencourt, </institution> <address> B.P. 105, 78153 Le Chesnay Cedex, France, </address> <month> September </month> <year> 1988. </year>
Reference-contexts: Figure 4-3 gives an example specification for matching, in which the problem is viewed as a transformation on a container of equations <ref> [CL88] </ref>, and each transformation is one of the actions from the sequential code. (The symbol : is used as part of an equation literal, to avoid confusion with expressions that contain equality tests.) The container starts with the single equation to be solved, and when a match exists, it ends with
Reference: [CM88] <author> K. Mani Chandy and Jayadev Misra. </author> <title> A Foundation of Parallel Program Design. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1988. </year>
Reference-contexts: The examples are developed starting from the initial design phase and extending through low-level coding decisions and performance tuning. The examples show that 15 good performance can be achieved in modular programs. The early stages of the approach use the same refinement methods that are proposed for Unity <ref> [CM88] </ref>, but our goals in refinement are different. Unity is used as a programming language, and the presumption is that Unity compilers can be developed to generate efficient parallel code from an appropriately refined Unity program, but the practicality of the approach has not been demonstrated. <p> One reason for using transition-axiom specifications as a design language is that standard techniques exist for reasoning about such specifications. Correctness arguments can be made at various stages in program development using abstraction functions and invariants <ref> [Lam83, LT87, CM88] </ref>. We include examples of correctness arguments to illustrate their integration into the development process. <p> Transition axioms specifications are used commonly to describe systems with concurrency, e.g., <ref> [Lam89, Lam90, LF81, LT87, CM88] </ref>. Our transition axiom specifications do not differ significantly from any of these. However, we allow a general class of liveness properties as in Lamport's language [Lam90], rather than the fixed notion of weak fairness in Unity [CM88] and the I/O Automata model [LT87]. <p> Our transition axiom specifications do not differ significantly from any of these. However, we allow a general class of liveness properties as in Lamport's language [Lam90], rather than the fixed notion of weak fairness in Unity <ref> [CM88] </ref> and the I/O Automata model [LT87]. Moreover, our specifications require a richer semantic model than provided by the formal languages of [CM88] and [Lam90], because, for example, we allow sharing among objects in the state [GL90]. <p> However, we allow a general class of liveness properties as in Lamport's language [Lam90], rather than the fixed notion of weak fairness in Unity <ref> [CM88] </ref> and the I/O Automata model [LT87]. Moreover, our specifications require a richer semantic model than provided by the formal languages of [CM88] and [Lam90], because, for example, we allow sharing among objects in the state [GL90]. The emphasis in most of these methods is on reasoning, rather than development, and on algorithms, rather than large programs. <p> The goals of refinement are: simple guards, an appropriate granularity of transition axioms, and a weak liveness property. We postpone making these goals precise or giving examples until after 1 Chandy and Misra address performance concerns in Unity <ref> [CM88] </ref>; the differences between their approach and ours, with regard to performance, appear in the later steps of our approach. 73 presenting steps 3 and 4, since the goals of specification refinement are tied to the question of what it means for a program to implement a specification. <p> Furthermore, the liveness properties describe properties of infinite executions, not procedures for ensuring those properties. It is popular in the literature to refer to lower-level specifications as implementations of higher-level ones <ref> [Lam89, CM88, LT89] </ref>, 74 but we reserve the word implementation for programs written in a language that runs on a real machine. In step 3, a set of procedures called transition procedures are implemented. The procedures are themselves sequential, but are run concurrently with one another. <p> Notions of satisfaction between transition axiom specifications have been extensively studied in the literature; the notions have been formalized in various models, and techniques for proving satisfaction, based on the idea of a refinement mapping have been described <ref> [Lam80, AL88, LF81, LT87, CM88] </ref>. In Section 4.3.5, we discuss satisfaction in more detail and give correctness arguments using refinement mappings [AL88]. In this section, we include only those ideas that are relevant to understanding what the various specifications mean, and how they differ. <p> The reader is referred to [AL88] for a precise definition of satisfaction; similar notions of satisfaction are defined for the I/O Automata model [LT87] and for Unity programs <ref> [CM88] </ref>. 108 Technically, our series of specifications, 4-4 through 4-6 do not satisfy specificaton 4-3 be-cause the initial and final states differ in minor ways. For example, the container E in specification 4-4 holds the user's input in the initial state and the answer in the final state. <p> A general conclusion is that thinking about nondeterministic transitions during program design is a good way to uncover program level parallelism. While transition axioms have been used to reason about parallel and distributed programs <ref> [CM88, LT87, Lam89] </ref>, we know of no other work that defines a link between the transition axiom specification and a parallel program written in a conventional language. 122 4.4.2 Extensions There are two aspects of the transition-based approach that limit its use.
Reference: [Dal86] <author> William J. Dally. </author> <title> A VLSI Architecture for Concurrent Data Structures. </title> <type> PhD thesis, </type> <institution> California Institute of Technology, Pasadena, California, </institution> <month> March </month> <year> 1986. </year>
Reference-contexts: The most common example of a distributed object is a memory cell in a multiprocessor with caches, but many others have been designed and implemented for both distributed systems [Ell85, BT88, BHJ + 87] and for multiprocessors <ref> [Luc87b, Dal86, CD90] </ref>. To access a distributed object, these systems provide sophisticated run-time support so that each object is given a single name; the run-time system must determine what node in the distributed object should be used for a particular operation.
Reference: [Der82] <author> Nachum Dershowitz. </author> <title> Orderings for term-rewriting systems. </title> <journal> Theoretical Computer Science, </journal> <volume> 17 </volume> <pages> 279-301, </pages> <year> 1982. </year>
Reference-contexts: Certain equations, like the commutative axiom cannot be ordered into a rewrite rule if we desire a noetherian system. The most common method for proving that a system is noetherian is to use a reduction ordering on terms, i.e., a monotonic well-founded ordering that is stable under substitution <ref> [Der82] </ref>. If for every rule in the system, the left side is greater than the right side by a reduction ordering, then the system is noetherian.
Reference: [Der90] <author> Nachum Dershowitz, </author> <year> 1990. </year> <title> Private communication. </title>
Reference-contexts: r 2 satisfy an age restriction, which we denote by the predicate age restrict (r 1 ; r 2 ). 137 Using the age of rules to solve the technical problem is mentioned in the original inference rule formulation [BDH86], and the validity of this solution was confirmed by Dershowitz <ref> [Der90] </ref>. Associating an age with each rule will also solve the problem in the parallel implementation that was mentioned in Section 5.1 as the problem rewriting two rules to triviality by using each other; we will use rule age to keep one of the rewritings from taking place.
Reference: [DF85] <author> Dave Detlefs and Randy Forgaard. </author> <title> A procedure for automatically proving termination of a set of rewrite rules. </title> <booktitle> In Proceedings of the First International Conference on Rewriting Techniques and Applications, Dijon, France, </booktitle> <pages> pages 255-270. </pages> <publisher> Springer-Verlag, LNCS 202, </publisher> <month> May </month> <year> 1985. </year>
Reference-contexts: Completion procedures can be made failure resistant by allowing the reduction ordering to be modified in certain restricted ways during the completion process <ref> [DF85] </ref>. Completion procedures can be made unfailing by leaving some equations unordered and restricting the domain of terms to which rules can be applied [BDH86]. Because these generalizations complicate the completion process, we restrict our attention to completion procedures in which a fixed ordering (&gt;) is given.
Reference: [Dij65] <author> E.W. Dijkstra. </author> <title> Solution of a problem in concurrent programming control. </title> <journal> Communications of the ACM, </journal> <volume> 8(9):569, </volume> <month> September </month> <year> 1965. </year>
Reference-contexts: Throughout the chapter we also give general techniques for implementing concurrent objects. For example, the announcement board structure that is used in the mapping implementation appears in some of Herlihy's wait-free algorithms [Her90], and the algorithm used for assignment generalizes Dijkstra's mutual exclusion algorithm <ref> [Dij65] </ref>. Some of the problems that arise in the examples are also general. The need for thread-specific data within objects can reduce contention and improve locality, but it complicates the interface of the object.
Reference: [Dij76] <author> E. W. Dijkstra. </author> <title> A Discipline of Programming. </title> <publisher> Prentice-Hall, </publisher> <year> 1976. </year>
Reference-contexts: For example, a specification of a program that sorts an array, A, might state that any pair of elements, (A [i]; A [j]), can be swapped if i &lt; j and A [i] &gt; A [j]. Transitions are specified using transition axioms, which are guarded commands <ref> [Dij76] </ref>. In our use the commands are flat, that is, there is no nesting of guards. For example, a specification of the sorting program contains a single axiom, written (i &lt; j)&(A [i] &gt; A [j]) ! (A [i] := A [j])&(A [j] := A [i]).
Reference: [DKM84] <author> Cynthia Dwork, Paris C. Kanellakis, and John C. Mitchell. </author> <title> On the sequential nature of unification. </title> <journal> Journal of Logic Programming, </journal> <volume> 1 </volume> <pages> 35-50, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: The unification problem, has a linear time sequential algorithm, and is known to be P-Space complete, so it is unlikely to have a faster than polynomial time parallel algorithm <ref> [DKM84] </ref>. The matching problem has a logarithmic time algorithm on a polynomial number of processors [RR87, DKS88], but cannot be done in onstant time algorithm [VR90].
Reference: [DKS88] <author> Cynthia Dwork, Paris C. Kanellakis, and Larry Stockmeyer. </author> <title> Parallel algorithms for term matching. </title> <journal> SIAM Journal of Computing, </journal> <volume> 17(4) </volume> <pages> 711-731, </pages> <month> August </month> <year> 1988. </year> <month> 163 </month>
Reference-contexts: The unification problem, has a linear time sequential algorithm, and is known to be P-Space complete, so it is unlikely to have a faster than polynomial time parallel algorithm [DKM84]. The matching problem has a logarithmic time algorithm on a polynomial number of processors <ref> [RR87, DKS88] </ref>, but cannot be done in onstant time algorithm [VR90]. All of these results were shown using the PRAM model, which has limited applicability to real machines, because the model is synchronous, ignores communication overhead, and only bounds processor utilization within a polynomial of the input.
Reference: [DL90] <author> Nachum Dershowitz and Namoi Lindenstrauss. </author> <title> An abstract machine for concurrent term rewriting. </title> <booktitle> In Proceedings of the 2nd International Conference on Algebraic and Logic Programming, </booktitle> <address> Berlin, </address> <month> October </month> <year> 1990. </year> <title> LNCS, </title> <publisher> Springer. </publisher>
Reference-contexts: For example, rewriting a single term requires that all rules be applied to every subterm of the term. Parallel rewriting has been studied by others, including Dershowitz and Lindenstrauss <ref> [DL90] </ref>, who presented an parallel implementation and then discuss some of the behavioral differences between parallel and sequential rewriting. In addition, parallel matching, which is used within rewriting, and parallel unification, which is used within critical pairing, have both been studied theoretically.
Reference: [DS88] <author> Michel Dubois and Christoph Scheurich. </author> <title> Synchronization, coherence, and event ordering in multiprocessors. </title> <journal> IEEE Computer, </journal> <volume> 21(2) </volume> <pages> 9-21, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Conditional correctness notions have appeared in the multiprocessor literature for implementations of weak shared memory, where memory is shown to be sequentially consistent given certain assumptions about how memory operations are used <ref> [DS88, AH90b, SS88] </ref>. We generalize these concepts to arbitrary shared data types and give a linguistic mechanism for specifying the restrictions on use. In this section we assume that the user of an abstraction is willing to make promises about how the operations will be used. <p> Although many shared memory implementations are actually linearizable, there are proposals for sequentially consistent memory that is not linearizable, so we used the weaker assumption that memory is sequentially consistent. See <ref> [AH90a, GLL + 90, BR90, DS88, SS88] </ref> for examples of memory implementations that are sequentially consistent but not necessarily linearizable. 43 44 Chapter 3 Implementing Concurrent Data Types In this chapter we present specifications and implementations of a number of concurrent data types. <p> This demonstrates the practical power of sequentially consistent memory, as opposed to weaker models of memory that assume the programmer will use synchronization around all shared memory accesses <ref> [DS88, AH90b] </ref>. 45 * The implementation of the mapping type uses a novel backoff strategy for avoiding colli- sions in the space of keys being mapped. * Taken as a whole, the set of data types demonstrate the power of a simple class of abstractions.
Reference: [Ell85] <author> Carla Schlatter Ellis. </author> <title> Distributed data structures: A case study. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-34(12):1178-1185, </volume> <month> December </month> <year> 1985. </year>
Reference-contexts: We refer to such objects as multi-ported objects and to each thread's version as a port. Implementations of this kind are prevalent in implementations of shared and distributed objects but we know of no other work that describes the specifications of the procedures that access these object. (See <ref> [Ell85, Her90, CD90, WW90] </ref> for some examples of objects that contain thread-specific data.) The specification of a multi-ported object typically has an interference specification that depends on the port being used, which is important because it means that a multi-ported object looks different than a normal object, even at the abstract <p> The most common example of a distributed object is a memory cell in a multiprocessor with caches, but many others have been designed and implemented for both distributed systems <ref> [Ell85, BT88, BHJ + 87] </ref> and for multiprocessors [Luc87b, Dal86, CD90]. To access a distributed object, these systems provide sophisticated run-time support so that each object is given a single name; the run-time system must determine what node in the distributed object should be used for a particular operation.
Reference: [GGH90] <author> Steven J. Garland, John V. Guttag, and James L. Horning. </author> <title> Debugging larch shared language specifications. </title> <type> Technical Report 607, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <address> Palo Alto, CA, </address> <year> 1990. </year>
Reference-contexts: Completion procedures have been used for doing data type induction [Mus80], interpreting equational logic programs [GM86], proving theorems in first order theories [HD83], debugging specifications <ref> [GGH90] </ref>, proving equivalence of algebras [Mar86], and automatically generating equational unification algorithms [Hul80]. The original completion procedure was discovered by Knuth and Bendix [KB70], and has since been studied, modified, and extended. <p> Although the process of completion is not guaranteed to terminate, it is sometimes useful to perform completion for a fixed amount of time to compute an approximation to the infinite answer <ref> [GGH90] </ref>. All of these applications of term rewriting systems solve one of the following related problems. Definition. Given a term rewriting system R, the convergence decision problem is to determine whether or not R is convergent. Definition. <p> This was much more difficult for completion, and we eventually abandoned the sequential program as a baseline. One indication that our implementation is reasonably fast in an absolute sense is a comparison to the implementation of completion in the Larch Prover <ref> [GGH90] </ref>. The Larch Prover implementation has been used for a number of large examples, and is consistently slower than our implementation running on one processor.
Reference: [GHW85] <author> John Guttag, James Horning, and Jeannette Wing. </author> <title> Larch in five easy pieces. </title> <type> Research Report 5, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <month> July </month> <year> 1985. </year>
Reference-contexts: Our specifications are informal although they have a similar structure to interface specifications written in the Larch family of formal specification languages <ref> [GHW85, Win83] </ref>. Others have used Larch-style specifications to specify concurrent operations [HW90, BGHL87].
Reference: [GJLS87] <author> David Gifford, Pierre Jouvelot, John Lucassen, and Mark Sheldon. </author> <title> Fx-87 reference manual. </title> <type> Technical Report 407, </type> <institution> Massachusetts Institute of Technology Laboratory for Computer Science, </institution> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: The algorithm requires data flow analysis to determine which interfering operations may actually execute concurrently, which may limit its practicality. The FX programming language <ref> [GJLS87] </ref> uses a kind of interference specification on procedures to determine whether two procedures may be executed in parallel. The approach in FX is conservative-two procedures are not executed concurrently if they contain interfering memory operations.
Reference: [GL90] <author> Kenneth Goldman and Nancy Lynch. </author> <title> Modelling shared state in a shared action model. </title> <booktitle> In Proceedings of the 5th Annual IEEE Symposium on Logic in Computer Science, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: A more precise characterization of states for a real programming language, and interpretations of predicates in those states, would require a formal language and a richer model than we wish to pursue here. Wing [Win83] gives such an interpretation for formal specifications in sequential CLU programs, and Goldman <ref> [GL90] </ref> gives a detailed model of shared state for concurrent operations. 27 Given a specification for some procedure P , a state pair hpre; posti is said to be a legal execution of P if either: 1. the requires clause is false in pre, or 2. the when clause is true <p> Moreover, our specifications require a richer semantic model than provided by the formal languages of [CM88] and [Lam90], because, for example, we allow sharing among objects in the state <ref> [GL90] </ref>. The emphasis in most of these methods is on reasoning, rather than development, and on algorithms, rather than large programs.
Reference: [GLL + 90] <author> Kaourosh Gharachorloo, Daniel Lenoski, James Laudon, Anoop Gupta, and John Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In 17th International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <year> 1990. </year>
Reference-contexts: Although many shared memory implementations are actually linearizable, there are proposals for sequentially consistent memory that is not linearizable, so we used the weaker assumption that memory is sequentially consistent. See <ref> [AH90a, GLL + 90, BR90, DS88, SS88] </ref> for examples of memory implementations that are sequentially consistent but not necessarily linearizable. 43 44 Chapter 3 Implementing Concurrent Data Types In this chapter we present specifications and implementations of a number of concurrent data types.
Reference: [GLR83] <author> Allan Gottlieb, B.D. Lubachevsky, and Larry Rudolph. </author> <title> Basic techniques for the efficient coordination of very large numbers of cooperating sequential processes. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <pages> pages 164-189, </pages> <month> April </month> <year> 1983. </year>
Reference-contexts: on the following key invariants. * 0 low high + 1 * 1 high max alloc * 1 defined high high * size = high low + 1, where size = 0 ) is empty The idea of using an indivisible inc operation (often called fetch-and-add ) has appeared elsewhere <ref> [GLR83, HW90] </ref>. Our implementation is unique in two respects: space is allocated dynamically, and access to individual slots in the queue is controlled by a pointer, defined high, rather than relying on presence bits or other synchronization of individual locations. <p> Technically, the size is bounded by the total available memory on the machine, but this is a more generous bound than other published implementations. The implementation in <ref> [GLR83] </ref> uses a circular buffer, so there is a bound on how many elements may be stored in the queue at a given time, while the implementation in [HW90] is bounded in the total number of enqueues that may be performed. <p> In general, we prefer to avoid reliance on this aspect of the memory allocator since it incurs a overhead on all allocations. A number of concurrent queue implementations are also described in <ref> [GLR83] </ref>, each of them providing a different solution to the the problem of preventing unfilled slots from being read . All of the solutions involve an explicit flag (or some kind of counter) associated with each slot to denote whether the slot is empty or full. <p> Each enqueue operation waits for all previous slots to be filled before returning, and thus our implementation is not wait-free, unlike the implementations that rely on presence bits or locks [HW90] and <ref> [GLR83] </ref>. In our implementation, if processors run at different rates, threads running on fast processors will be slowed to the pace of slower ones when accessing the queue. <p> We give up the advantages of a wait-free implementation in return for fewer synchronization operations in one case <ref> [GLR83] </ref>, and a less sophisticated (and poten 60 dyn array = datatype [t: type] has create; addh; fetch; size; print interference between: (addh; print) create = procedure () returns (dyn array) ensures: returns an empty array addh = procedure (a: dyn array; e: t) ensures: adds e to the top of
Reference: [GM86] <author> Joseph A. Goguen and Jose Meseguer. </author> <title> EQLOG: Equality, types, and generic mod-ules for logic programming. </title> <editor> In Doug DeGroot and Gary Lindstrom, editors, </editor> <title> Logic Programming. Functions, Relations, </title> <booktitle> and Equations, </booktitle> <pages> pages 295-363. </pages> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1986. </year>
Reference-contexts: In the worst case, there is no finite complete solution, so the procedure generates an infinite sequence of successively closer approximations to the infinite solution. Completion procedures have been used for doing data type induction [Mus80], interpreting equational logic programs <ref> [GM86] </ref>, proving theorems in first order theories [HD83], debugging specifications [GGH90], proving equivalence of algebras [Mar86], and automatically generating equational unification algorithms [Hul80]. The original completion procedure was discovered by Knuth and Bendix [KB70], and has since been studied, modified, and extended. <p> When term rewriting techniques are applied to theorem proving [HD83], knowledge representation [Sch88], and logic programming <ref> [GM86] </ref>, the property of convergence is often essential. In some applications, convergence is established by adding new rules to the system in a completion process, while in other applications convergence is a property that is tested for a fixed set of rules.
Reference: [Hal85] <author> Robert Halstead. </author> <title> Multilisp: A language for concurrent symbolic computation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <month> October </month> <year> 1985. </year>
Reference-contexts: For some programs, object mutations are mainly instantiations, i.e., an object may be created in some partially constructed form, and parallel threads fill in the missing pieces. This form of mutation can be handled by futures <ref> [Hal85] </ref>, I-structures [ANP87], and logical variables in logic programs [Rin89]. Since objects cannot be mutated after instantiation, the only kind of race condition arises from whether or not an object has been computed. Special hardware or software checks can prevent threads from observing uninstantiated objects.
Reference: [HD83] <author> Jieh Hsiang and Nachum Dershowitz. </author> <title> Rewrite methods for clausal and non-clausal theorem proving. </title> <booktitle> In Proceedings of the 10th International Colloquium on Automata, Languages, and Programming, </booktitle> <pages> pages 331-346. </pages> <note> EATCS, </note> <year> 1983. </year>
Reference-contexts: In the worst case, there is no finite complete solution, so the procedure generates an infinite sequence of successively closer approximations to the infinite solution. Completion procedures have been used for doing data type induction [Mus80], interpreting equational logic programs [GM86], proving theorems in first order theories <ref> [HD83] </ref>, debugging specifications [GGH90], proving equivalence of algebras [Mar86], and automatically generating equational unification algorithms [Hul80]. The original completion procedure was discovered by Knuth and Bendix [KB70], and has since been studied, modified, and extended. <p> When term rewriting techniques are applied to theorem proving <ref> [HD83] </ref>, knowledge representation [Sch88], and logic programming [GM86], the property of convergence is often essential. In some applications, convergence is established by adding new rules to the system in a completion process, while in other applications convergence is a property that is tested for a fixed set of rules.
Reference: [Her88] <author> Maurice P. Herlihy. </author> <title> Impossibility and universality of wait-free synchronization. </title> <booktitle> In 7th Symposium on Principles of Distributed Computing. ACM, </booktitle> <month> August </month> <year> 1988. </year>
Reference-contexts: Non-stopping is strictly weaker than the related notion of wait-freeness defined by Herlihy <ref> [Her88] </ref>. A key difference between the two notions is that wait-freeness requires termination in the presence of processor failures, whereas non-stopping places no constraints on termination in the presence of failures. <p> The converse is not true, i.e., H may be stopped at some objects and still be an infinite execution. Our notion of non-stopping is weaker than two other liveness notions for concurrent objects: non-blocking and wait-free <ref> [Her88, Her90] </ref>. Both of those notions require forward progress in the presence of failures, whereas our model of computation does not admit failures.
Reference: [Her90] <author> Maurice P. Herlihy. </author> <title> A methodology for constructing highly concurrent data structures. </title> <booktitle> In ACM Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> March </month> <year> 1990. </year>
Reference-contexts: The most widely accepted method for implementing concurrent data types is the use of critical regions. For parallel programs in which most computation involves shared objects, placing all accesses in critical regions results in fake parallelism, since threads must wait for access to any shared object. <ref> [Her90] </ref> gives a different technique for implementing concurrent objects; it allows both mutating and non-mutating operations to proceed in parallel, but mutating operations may have to redo their work if another mutating operation is executing concurrently. Both techniques as useful in certain situations, but neither should be used exclusively. <p> The converse is not true, i.e., H may be stopped at some objects and still be an infinite execution. Our notion of non-stopping is weaker than two other liveness notions for concurrent objects: non-blocking and wait-free <ref> [Her88, Her90] </ref>. Both of those notions require forward progress in the presence of failures, whereas our model of computation does not admit failures. <p> This is in contrast to richer process-oriented programming models. Throughout the chapter we also give general techniques for implementing concurrent objects. For example, the announcement board structure that is used in the mapping implementation appears in some of Herlihy's wait-free algorithms <ref> [Her90] </ref>, and the algorithm used for assignment generalizes Dijkstra's mutual exclusion algorithm [Dij65]. Some of the problems that arise in the examples are also general. The need for thread-specific data within objects can reduce contention and improve locality, but it complicates the interface of the object. <p> We refer to such objects as multi-ported objects and to each thread's version as a port. Implementations of this kind are prevalent in implementations of shared and distributed objects but we know of no other work that describes the specifications of the procedures that access these object. (See <ref> [Ell85, Her90, CD90, WW90] </ref> for some examples of objects that contain thread-specific data.) The specification of a multi-ported object typically has an interference specification that depends on the port being used, which is important because it means that a multi-ported object looks different than a normal object, even at the abstract
Reference: [HT90] <author> Maurice P. Herlihy and Mark R. Tuttle. </author> <title> Wait-free computation in message-passing systems. </title> <booktitle> In 9th Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 347-362. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1990. </year>
Reference-contexts: The correctness notions are defined in Sections 2.3 through 2.5. Section 2.3 gives two definitions from the literature: sequential consistency [Lam79] and linearizability [HW90]. We compare the two notions and explain our choice of linearizability as the basis of correctness 1 Herlihy and Tuttle <ref> [HT90] </ref> show theoretical lower bounds on the performance of wait-free data types. 24 for concurrent data types in this thesis. In Section 2.4, we argue that the original definition of linearizability is too restrictive, and therefore add the ability to qualify linearizability by adding an interference specification.
Reference: [Hue80] <author> Gerard Huet. </author> <title> Confluent reductions: Abstract properties and applications to term rewriting systems. </title> <journal> Journal of the ACM, </journal> <volume> 27(4) </volume> <pages> 797-821, </pages> <month> October </month> <year> 1980. </year>
Reference-contexts: Other variations on the completion includes narrowing [Hul80] and completion modulo equations <ref> [Hue80, PS81] </ref>. Although these problems fall in the class addressed by our approach, we consider only traditional completion in this thesis. 134 All these variations on completion are unsolvable, and in fact the problem of determining whether a set of rules is noetherian is undecidable.
Reference: [Hul80] <author> Jean-Marie Hullot. </author> <title> Canonical forms and unification. </title> <editor> In W. Bibel and Robert A. Kowalski, editors, </editor> <booktitle> Proceedings of the Fifth Conference on Automated Deduction, </booktitle> <pages> pages 318-334. </pages> <publisher> LNCS 87, Springer-Verlag, </publisher> <month> July </month> <year> 1980. </year>
Reference-contexts: Completion procedures have been used for doing data type induction [Mus80], interpreting equational logic programs [GM86], proving theorems in first order theories [HD83], debugging specifications [GGH90], proving equivalence of algebras [Mar86], and automatically generating equational unification algorithms <ref> [Hul80] </ref>. The original completion procedure was discovered by Knuth and Bendix [KB70], and has since been studied, modified, and extended. See [Buc85], for a historical survey of completion procedures, with more than 200 references that include algorithms, applications, and implementations. <p> Other variations on the completion includes narrowing <ref> [Hul80] </ref> and completion modulo equations [Hue80, PS81]. Although these problems fall in the class addressed by our approach, we consider only traditional completion in this thesis. 134 All these variations on completion are unsolvable, and in fact the problem of determining whether a set of rules is noetherian is undecidable.
Reference: [HW90] <author> Maurice Herlihy and Jeannette Wing. </author> <title> Linearizability: A correctness condition for concurrent objects. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <pages> pages 463-492, </pages> <month> July </month> <year> 1990. </year> <note> A preliminary version appeared in the proceedings of the 14th ACM Symposium on Principles of Programming Languages, </note> <year> 1987, </year> <title> under the title: Axioms for concurrent objects. </title> <type> 165 </type>
Reference-contexts: We show that with parallelism, basic units of abstraction must be restricted, notions of correctness changed, and specifications augmented. In particular, we examine correctness notions that have been proposed by others <ref> [Lam80, Lam79, HW90, AH90b] </ref>, compare them on practical grounds, and offer a new correctness notion of our own. Our notion is based on linearizability [HW90], but is strictly weaker. <p> In particular, we examine correctness notions that have been proposed by others [Lam80, Lam79, HW90, AH90b], compare them on practical grounds, and offer a new correctness notion of our own. Our notion is based on linearizability <ref> [HW90] </ref>, but is strictly weaker. It incorporates interference specifications, which constrain the use of an abstraction in order to admit implementations that are simpler and more efficient. <p> A key to making abstraction work is choosing the right notion of correctness. Many correctness notions have been defined for systems involving concurrency. We consider sequential consistency [Lam79] and linearizability <ref> [HW90] </ref>, and compare them from the perspective of both user and implementor. Our conclusion is that sequential consistency is adequate for defining the interface of shared memory, but that linearizability, which is strictly stronger, is needed for program modules. <p> There are a number of concepts in this chapter that are essential to the rest of the thesis. The first is a notion of correctness for concurrent data types, linearizability modulo an interference specification, which generalizes the notion of linearizability defined by Herlihy and Wing <ref> [HW90] </ref>. Linearizability places a requirement on all operations of a data type, implicitly assuming that all operations may be invoked concurrently. <p> The final piece of background material in this chapter is a formal model for concurrent data types, which is an adaptation of the model used by Herlihy and Wing <ref> [HW90] </ref>. The model is presented in Section 2.2, along with an intuitive pictorial version that is used for the examples. We have tried to include sufficiently detailed informal descriptions and enough examples that the reader may skip the formal definitions and still read the rest of the thesis. <p> The correctness notions are defined in Sections 2.3 through 2.5. Section 2.3 gives two definitions from the literature: sequential consistency [Lam79] and linearizability <ref> [HW90] </ref>. We compare the two notions and explain our choice of linearizability as the basis of correctness 1 Herlihy and Tuttle [HT90] show theoretical lower bounds on the performance of wait-free data types. 24 for concurrent data types in this thesis. <p> Our specifications are informal although they have a similar structure to interface specifications written in the Larch family of formal specification languages [GHW85, Win83]. Others have used Larch-style specifications to specify concurrent operations <ref> [HW90, BGHL87] </ref>. <p> We present an object-based model in which a set of threads (light-weight processes with shared address space) apply procedures to individual objects. The model, which is adapted from <ref> [HW90] </ref>, is simple, yet rich enough to support the definition of most correctness notions. <p> The history is not sequential because operations of T 1 and T 2 overlap in time. 2.3 Strong Correctness We begin by presenting two correctness notions from the literature, sequential consistency [Lam79] and linearizability <ref> [HW90] </ref>. These definitions extend the notion of correct sequential executions, which were called legal executions in the sequential case, to parallel executions. <p> For pedagogical reasons, we also define local sequential consistency, which requires that individual objects are sequentially consistent. Definition. H is locally sequentially consistent if for each object x, H jx is sequentially consistent. Any history that is sequentially consistent is also locally sequentially consistent. However, examples given in <ref> [HW90] </ref> and below demonstrate that the converse is not true, so local sequential consistency is strictly weaker than sequential consistency. 31 Linearizability Linearizability is stronger than sequential consistency. It was proposed by Herlihy and Wing [HW90] as a correctness criterion for abstract data types in parallel programs, and Lamport used it <p> However, examples given in <ref> [HW90] </ref> and below demonstrate that the converse is not true, so local sequential consistency is strictly weaker than sequential consistency. 31 Linearizability Linearizability is stronger than sequential consistency. It was proposed by Herlihy and Wing [HW90] as a correctness criterion for abstract data types in parallel programs, and Lamport used it as a condition on shared memory registers, which were called "atomic" registers [Lam80]. Definition. <p> The property of linearizability that makes this possible is called compositionality and given in Theorem 1. The proof of this theorem was presented by Herlihy and Wing <ref> [HW90] </ref>, although the result was shown in a more abstract framework by Lamport [Lam80]. Theorem 1 [HW90] H is linearizable iff for all objects x, Hjx is linearizable. Thus, implementations of linearizable objects can be composed and generic object implementations for common data types can be reused between different applications. <p> The property of linearizability that makes this possible is called compositionality and given in Theorem 1. The proof of this theorem was presented by Herlihy and Wing <ref> [HW90] </ref>, although the result was shown in a more abstract framework by Lamport [Lam80]. Theorem 1 [HW90] H is linearizable iff for all objects x, Hjx is linearizable. Thus, implementations of linearizable objects can be composed and generic object implementations for common data types can be reused between different applications. <p> on the following key invariants. * 0 low high + 1 * 1 high max alloc * 1 defined high high * size = high low + 1, where size = 0 ) is empty The idea of using an indivisible inc operation (often called fetch-and-add ) has appeared elsewhere <ref> [GLR83, HW90] </ref>. Our implementation is unique in two respects: space is allocated dynamically, and access to individual slots in the queue is controlled by a pointer, defined high, rather than relying on presence bits or other synchronization of individual locations. <p> The implementation in [GLR83] uses a circular buffer, so there is a bound on how many elements may be stored in the queue at a given time, while the implementation in <ref> [HW90] </ref> is bounded in the total number of enqueues that may be performed. Dynamic object growth is particularly important in symbolic applications, where the size of data structures is difficult to predict in advance. <p> Herlihy and Wing's implementation depends on memory being cleared when allocated, because dequeue tests slots 59 to determine whether they are full or empty <ref> [HW90] </ref>. Our implementation runs correctly even if the allocator returns uncleared memory. We implemented a version that depended on cleared memory in place of the defined high pointer, but found no measurable performance difference between the two implementations. <p> Each enqueue operation waits for all previous slots to be filled before returning, and thus our implementation is not wait-free, unlike the implementations that rely on presence bits or locks <ref> [HW90] </ref> and [GLR83]. In our implementation, if processors run at different rates, threads running on fast processors will be slowed to the pace of slower ones when accessing the queue. <p> 0 i &lt; size (a) ensures: replace i th element of a by e size = procedure (a: dyn array) returns (int) ensures: returns the size of a print = procedure (a: dyn array) ensures prints the elements of a in order tially more efficient) memory allocator in another case <ref> [HW90] </ref>. While the notion of a wait-free implementation is semantically quite powerful, the practical importance has not been proved. Wait-free implementations depend on synchronization primitives that are themselves wait-free, yet these do not exist on current architectures. <p> An abstraction function maps states of a refined specification to states of the original (abstract) specification. Abstraction functions have been used extensively in the context of abstract data types for sequential programs [LG86], and by others in reasoning about parallel and distributed programs <ref> [AL88, LT87, HW90] </ref>. 3 In our use, the state machine part of a specification is viewed as an abstract data type, where the state components contain the type's values, and the transition axioms specify the type's operations. <p> Let A be an abstraction function on some set of states S. If hs 1 ; s 2 ; :::i is an execution of 3 [LT87] and <ref> [HW90] </ref> use the related notion of a possibilities mapping, which maps a single to state to a set of states. 109 states in S, then its abstracted execution is the sequence hA (s 1 ); A (s 2 ); :::i.
Reference: [JW90] <author> M. D. Junkin and D. B. Wortman. </author> <title> Compiling concurrently. </title> <type> Technical Report CSRI--235, </type> <institution> Computer Systems Research Institute, University of Toronto, Toronto, </institution> <address> Ontario, CA, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: However, the high-level approach does influence the low-level implementations in one regard: we assume there is application-specific scheduling, which means the application program schedules tasks (short-lived computations) on top of the system-level threads (long-lived computations) <ref> [RV89, CG89, JW90] </ref>. The scheduling model will be discussed further in Chapter 4, but for now, the important issue is the interaction between scheduling and synchronization. <p> Application-specific scheduling has been demonstrated to result in better performance than when systems schedulers are used directly [And89], and in particular, the worker model of application scheduling has been used successfully in a number of parallel applications <ref> [MNS87, CG89, RV89, JW90] </ref>. The worker model is an example of a user-level scheduling paradigm; it's definitive characteristic is that the tasks being scheduled are short-lived, so each is allowed run until it either blocks or finishes. Thus, the worker model avoids the complication and overhead of time-slicing schedulers. <p> A second problem with having more threads than processors is that scheduling of threads is done by the system scheduler; application-specific scheduling usually yields much better performance <ref> [RV89, JW90] </ref>. The solution to both problems is to start a fixed number of threads at the beginning of a program's execution, and to schedule tasks onto these threads. <p> The solution to both problems is to start a fixed number of threads at the beginning of a program's execution, and to schedule tasks onto these threads. Examples of this approach 100 include tuple spaces [CG89], work crews [RV89], and supervisors <ref> [JW90] </ref>; the approaches differ in the kinds of synchronization allowed between tasks, and the underlying scheduling algorithm. A task is a procedure invocation (a procedure plus input arguments) that is guaranteed to terminate. A scheduler for a set of transition procedures is a multi-threaded program that concurrently invokes the procedures.
Reference: [KB70] <author> Donald E. Knuth and Peter B. Bendix. </author> <title> Simple Word Problems in Universal Algebras, </title> <address> pages 263-297. </address> <publisher> Pergamon, Oxford, </publisher> <year> 1970. </year>
Reference-contexts: Completion procedures have been used for doing data type induction [Mus80], interpreting equational logic programs [GM86], proving theorems in first order theories [HD83], debugging specifications [GGH90], proving equivalence of algebras [Mar86], and automatically generating equational unification algorithms [Hul80]. The original completion procedure was discovered by Knuth and Bendix <ref> [KB70] </ref>, and has since been studied, modified, and extended. See [Buc85], for a historical survey of completion procedures, with more than 200 references that include algorithms, applications, and implementations. A careful statement of the completion problem requires term rewriting theory that is unrelated to the problems of parallel program development. <p> It reformulates the original completion procedure of Knuth and Bendix <ref> [KB70] </ref> as a set of non-deterministically applied transition axioms. The transition-axiom specification for completion relies on the following definitions. An occurrence is a location in a term and is denoted by a finite sequence of integers.
Reference: [LAB + 81] <author> Barbara Liskov, Russell Atkinson, Toby Bloom, Eliot Moss, J. Craig Schaffert, Robert Scheifler, and Alan Snyder. </author> <title> CLU Reference Manual. </title> <publisher> LNCS 114, Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1981. </year>
Reference-contexts: Others have used Larch-style specifications to specify concurrent operations [HW90, BGHL87]. We describe the meaning of our specifications and a serial correctness notion through an example. our programs in a variant of the CLU programming language <ref> [LAB + 81] </ref>, discussed in further detail in Chapter 3.) The container specification is polymorphic; the type parameter is used to 2 In Chapters 4 and 5 we use another kind of specification, transition axiom specifications, that specify parallel algorithms. <p> The programming language that is used throughout this chapter and Chapter 4 is a hybrid of existing programming languages, CLU <ref> [LAB + 81] </ref> and C. From C we take explicit memory allocation, since dynamic memory allocation is an important feature of our queue implementation. We also take curly braces for grouping statements, since they save space on a written page.
Reference: [Lam79] <author> Leslie Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multiprocess programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-28(9):690-691, </volume> <month> September </month> <year> 1979. </year>
Reference-contexts: We show that with parallelism, basic units of abstraction must be restricted, notions of correctness changed, and specifications augmented. In particular, we examine correctness notions that have been proposed by others <ref> [Lam80, Lam79, HW90, AH90b] </ref>, compare them on practical grounds, and offer a new correctness notion of our own. Our notion is based on linearizability [HW90], but is strictly weaker. <p> A key to making abstraction work is choosing the right notion of correctness. Many correctness notions have been defined for systems involving concurrency. We consider sequential consistency <ref> [Lam79] </ref> and linearizability [HW90], and compare them from the perspective of both user and implementor. Our conclusion is that sequential consistency is adequate for defining the interface of shared memory, but that linearizability, which is strictly stronger, is needed for program modules. <p> We have tried to include sufficiently detailed informal descriptions and enough examples that the reader may skip the formal definitions and still read the rest of the thesis. The correctness notions are defined in Sections 2.3 through 2.5. Section 2.3 gives two definitions from the literature: sequential consistency <ref> [Lam79] </ref> and linearizability [HW90]. We compare the two notions and explain our choice of linearizability as the basis of correctness 1 Herlihy and Tuttle [HT90] show theoretical lower bounds on the performance of wait-free data types. 24 for concurrent data types in this thesis. <p> The history is not sequential because operations of T 1 and T 2 overlap in time. 2.3 Strong Correctness We begin by presenting two correctness notions from the literature, sequential consistency <ref> [Lam79] </ref> and linearizability [HW90]. These definitions extend the notion of correct sequential executions, which were called legal executions in the sequential case, to parallel executions. <p> We justify this lack of uniformity in the discussion following the definitions. Sequential Consistency The notion of sequential consistency was proposed in <ref> [Lam79] </ref> as a requirement on shared memory for multiprocessors. It depends on the following definition of equivalence for histories. Definition.
Reference: [Lam80] <author> Leslie Lamport. </author> <title> On interprocess communication, parts I and II. </title> <journal> Distributed Computing, </journal> <volume> 1 </volume> <pages> 77-101, </pages> <month> October </month> <year> 1980. </year>
Reference-contexts: We show that with parallelism, basic units of abstraction must be restricted, notions of correctness changed, and specifications augmented. In particular, we examine correctness notions that have been proposed by others <ref> [Lam80, Lam79, HW90, AH90b] </ref>, compare them on practical grounds, and offer a new correctness notion of our own. Our notion is based on linearizability [HW90], but is strictly weaker. <p> It was proposed by Herlihy and Wing [HW90] as a correctness criterion for abstract data types in parallel programs, and Lamport used it as a condition on shared memory registers, which were called "atomic" registers <ref> [Lam80] </ref>. Definition. H is linearizable if there exists a response extension H res of H , and a legal sequential history H seq , such that H seq is equivalent to nonpending (H res ) and H res g:t: g:t: . <p> The property of linearizability that makes this possible is called compositionality and given in Theorem 1. The proof of this theorem was presented by Herlihy and Wing [HW90], although the result was shown in a more abstract framework by Lamport <ref> [Lam80] </ref>. Theorem 1 [HW90] H is linearizable iff for all objects x, Hjx is linearizable. Thus, implementations of linearizable objects can be composed and generic object implementations for common data types can be reused between different applications. <p> Notions of satisfaction between transition axiom specifications have been extensively studied in the literature; the notions have been formalized in various models, and techniques for proving satisfaction, based on the idea of a refinement mapping have been described <ref> [Lam80, AL88, LF81, LT87, CM88] </ref>. In Section 4.3.5, we discuss satisfaction in more detail and give correctness arguments using refinement mappings [AL88]. In this section, we include only those ideas that are relevant to understanding what the various specifications mean, and how they differ.
Reference: [Lam83] <author> Leslie Lamport. </author> <title> Specifying concurrent program modules. </title> <journal> ACM Transactions of Porgramming Languages and Systems, </journal> <volume> 5(2) </volume> <pages> 190-222, </pages> <month> April </month> <year> 1983. </year>
Reference-contexts: One reason for using transition-axiom specifications as a design language is that standard techniques exist for reasoning about such specifications. Correctness arguments can be made at various stages in program development using abstraction functions and invariants <ref> [Lam83, LT87, CM88] </ref>. We include examples of correctness arguments to illustrate their integration into the development process. <p> We employ this approach here. It is similar to Lamport's approach to specifying concurrent program modules <ref> [Lam83, Lam89] </ref>, except that his specifications include a type-specific liveness constraint, while we use a fixed liveness property on all types. <p> In proofs of this type of refinement, where one action is being replaced by a sequence, the trick is to define an abstraction function that maps exactly one low-level action in each sequence to the appropriate high-level action, and all others to stuttering actions <ref> [Lam83] </ref>. The complication comes from the possibility of interleaving of low-level actions from different high-level actions, representing overlaps in the execution of high-level actions.
Reference: [Lam89] <author> Leslie Lamport. </author> <title> A simple approach to specifying concurrent systems. </title> <journal> Communications of the ACM, </journal> <volume> 32(1) </volume> <pages> 32-45, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: We employ this approach here. It is similar to Lamport's approach to specifying concurrent program modules <ref> [Lam83, Lam89] </ref>, except that his specifications include a type-specific liveness constraint, while we use a fixed liveness property on all types. <p> Transition axioms specifications are used commonly to describe systems with concurrency, e.g., <ref> [Lam89, Lam90, LF81, LT87, CM88] </ref>. Our transition axiom specifications do not differ significantly from any of these. However, we allow a general class of liveness properties as in Lamport's language [Lam90], rather than the fixed notion of weak fairness in Unity [CM88] and the I/O Automata model [LT87]. <p> Furthermore, the liveness properties describe properties of infinite executions, not procedures for ensuring those properties. It is popular in the literature to refer to lower-level specifications as implementations of higher-level ones <ref> [Lam89, CM88, LT89] </ref>, 74 but we reserve the word implementation for programs written in a language that runs on a real machine. In step 3, a set of procedures called transition procedures are implemented. The procedures are themselves sequential, but are run concurrently with one another. <p> A general conclusion is that thinking about nondeterministic transitions during program design is a good way to uncover program level parallelism. While transition axioms have been used to reason about parallel and distributed programs <ref> [CM88, LT87, Lam89] </ref>, we know of no other work that defines a link between the transition axiom specification and a parallel program written in a conventional language. 122 4.4.2 Extensions There are two aspects of the transition-based approach that limit its use.
Reference: [Lam90] <author> Leslie Lamport. </author> <title> A temporal logic of actions. </title> <type> Research Report 57, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <address> Palo Alto, CA, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: Liveness properties can be formalized in a temporal logic, of which there are many examples, including Lamport's Temporal Logic of Actions, which was designed to be simple and usable in real world examples <ref> [Lam90] </ref>. In Chapters 4 and 5, where entire parallel programs are described at an abstract level, some examples of application-specific liveness properties are informally stated. For the concurrent objects discussed here and implemented in Chapter 3, we choose a particular liveness property, non-stopping, for all data types. <p> Transition axioms specifications are used commonly to describe systems with concurrency, e.g., <ref> [Lam89, Lam90, LF81, LT87, CM88] </ref>. Our transition axiom specifications do not differ significantly from any of these. However, we allow a general class of liveness properties as in Lamport's language [Lam90], rather than the fixed notion of weak fairness in Unity [CM88] and the I/O Automata model [LT87]. <p> Transition axioms specifications are used commonly to describe systems with concurrency, e.g., [Lam89, Lam90, LF81, LT87, CM88]. Our transition axiom specifications do not differ significantly from any of these. However, we allow a general class of liveness properties as in Lamport's language <ref> [Lam90] </ref>, rather than the fixed notion of weak fairness in Unity [CM88] and the I/O Automata model [LT87]. Moreover, our specifications require a richer semantic model than provided by the formal languages of [CM88] and [Lam90], because, for example, we allow sharing among objects in the state [GL90]. <p> However, we allow a general class of liveness properties as in Lamport's language <ref> [Lam90] </ref>, rather than the fixed notion of weak fairness in Unity [CM88] and the I/O Automata model [LT87]. Moreover, our specifications require a richer semantic model than provided by the formal languages of [CM88] and [Lam90], because, for example, we allow sharing among objects in the state [GL90]. The emphasis in most of these methods is on reasoning, rather than development, and on algorithms, rather than large programs. <p> In matching we use a notion of universal weak fairness, which requires only that a state machine continue taking steps as long as it has legal steps to take. Lamport describes this notion 82 (without naming it) as "the weakest liveness property that appears in practice" <ref> [Lam90] </ref>. 2. Simple transition axioms allow for efficient implementations of the transition procedures. In particular, the transition axioms guards should be quickly computable.
Reference: [Les] <author> Pierre Lescanne. </author> <title> Completion procedures as transition rules + control. </title> <institution> Centre de Recherche en Informatique de Nancy, France (unpublished). </institution>
Reference-contexts: Similarly, to guarantee that all critical pairs are eventually added, rules that have had their critical pairs computed are stored in a state component having that property as an invariant. Our parallel implementations resembles a sequential transition rule implementation by Lescanne <ref> [Les] </ref>, but our data structure are concurrent and have more control information to allow for the additional executions that come from parallelism. Note that the liveness property does not require rules to be in normal form.
Reference: [LF81] <author> Nancy Lynch and Michael Fischer. </author> <title> On describing the behavior and implementation of distributed systems. </title> <journal> Theoretical Computer Science, </journal> <volume> 13 </volume> <pages> 17-43, </pages> <year> 1981. </year>
Reference-contexts: Transition axioms specifications are used commonly to describe systems with concurrency, e.g., <ref> [Lam89, Lam90, LF81, LT87, CM88] </ref>. Our transition axiom specifications do not differ significantly from any of these. However, we allow a general class of liveness properties as in Lamport's language [Lam90], rather than the fixed notion of weak fairness in Unity [CM88] and the I/O Automata model [LT87]. <p> Notions of satisfaction between transition axiom specifications have been extensively studied in the literature; the notions have been formalized in various models, and techniques for proving satisfaction, based on the idea of a refinement mapping have been described <ref> [Lam80, AL88, LF81, LT87, CM88] </ref>. In Section 4.3.5, we discuss satisfaction in more detail and give correctness arguments using refinement mappings [AL88]. In this section, we include only those ideas that are relevant to understanding what the various specifications mean, and how they differ.
Reference: [LG86] <author> Barbara Liskov and John Guttag. </author> <title> Abstraction and Specification in Program Development. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year> <month> 166 </month>
Reference-contexts: An abstraction function maps states of a refined specification to states of the original (abstract) specification. Abstraction functions have been used extensively in the context of abstract data types for sequential programs <ref> [LG86] </ref>, and by others in reasoning about parallel and distributed programs [AL88, LT87, HW90]. 3 In our use, the state machine part of a specification is viewed as an abstract data type, where the state components contain the type's values, and the transition axioms specify the type's operations.
Reference: [LH88] <author> James R. Larus and Paul L. Hilfinger. </author> <title> Restructuring lisp programs for concurrent execution. In Parallel Programming: Experience with Applications, </title> <booktitle> Languages, and Systems, </booktitle> <pages> pages 100-110, </pages> <year> 1988. </year>
Reference-contexts: The most significant effort has been in the area of parallelizing Fortran programs, where signifi 124 cant progress has occurred in developing algorithms to detect parallelism for both numerical [ABC + 87, PGH + 89] and symbolic <ref> [LH88] </ref> programs. These techniques are most promising for numerical programs, most of the techniques focus on parallelizing loops. The payoffs for these compilation techniques on complete application programs running on existing machines are not yet known.
Reference: [LT87] <author> Nancy Lynch and Mark Tuttle. </author> <title> Hierarchical correctness proofs for distributed algorithms. </title> <type> Technical Report MIT/LCS/TR-387, </type> <institution> MIT Laboratory for Computer Science, </institution> <address> Cambridge, MA, </address> <month> April </month> <year> 1987. </year>
Reference-contexts: One reason for using transition-axiom specifications as a design language is that standard techniques exist for reasoning about such specifications. Correctness arguments can be made at various stages in program development using abstraction functions and invariants <ref> [Lam83, LT87, CM88] </ref>. We include examples of correctness arguments to illustrate their integration into the development process. <p> Transition axioms specifications are used commonly to describe systems with concurrency, e.g., <ref> [Lam89, Lam90, LF81, LT87, CM88] </ref>. Our transition axiom specifications do not differ significantly from any of these. However, we allow a general class of liveness properties as in Lamport's language [Lam90], rather than the fixed notion of weak fairness in Unity [CM88] and the I/O Automata model [LT87]. <p> Our transition axiom specifications do not differ significantly from any of these. However, we allow a general class of liveness properties as in Lamport's language [Lam90], rather than the fixed notion of weak fairness in Unity [CM88] and the I/O Automata model <ref> [LT87] </ref>. Moreover, our specifications require a richer semantic model than provided by the formal languages of [CM88] and [Lam90], because, for example, we allow sharing among objects in the state [GL90]. <p> A precise definition of satisfaction requires identification of the external states as in [AL88] or external actions as in <ref> [LT87] </ref>, where the external states or actions are things observable by the user of the 84 State Components E : container [equation] + no match Initially E = (pattern : = target) Transition Axioms decomposition ((p = t) 2 E) & (:is var (p)) & (p:head = t:head) ) E := <p> Notions of satisfaction between transition axiom specifications have been extensively studied in the literature; the notions have been formalized in various models, and techniques for proving satisfaction, based on the idea of a refinement mapping have been described <ref> [Lam80, AL88, LF81, LT87, CM88] </ref>. In Section 4.3.5, we discuss satisfaction in more detail and give correctness arguments using refinement mappings [AL88]. In this section, we include only those ideas that are relevant to understanding what the various specifications mean, and how they differ. <p> The reader is referred to [AL88] for a precise definition of satisfaction; similar notions of satisfaction are defined for the I/O Automata model <ref> [LT87] </ref> and for Unity programs [CM88]. 108 Technically, our series of specifications, 4-4 through 4-6 do not satisfy specificaton 4-3 be-cause the initial and final states differ in minor ways. <p> An abstraction function maps states of a refined specification to states of the original (abstract) specification. Abstraction functions have been used extensively in the context of abstract data types for sequential programs [LG86], and by others in reasoning about parallel and distributed programs <ref> [AL88, LT87, HW90] </ref>. 3 In our use, the state machine part of a specification is viewed as an abstract data type, where the state components contain the type's values, and the transition axioms specify the type's operations. <p> Let A be an abstraction function on some set of states S. If hs 1 ; s 2 ; :::i is an execution of 3 <ref> [LT87] </ref> and [HW90] use the related notion of a possibilities mapping, which maps a single to state to a set of states. 109 states in S, then its abstracted execution is the sequence hA (s 1 ); A (s 2 ); :::i. <p> A general conclusion is that thinking about nondeterministic transitions during program design is a good way to uncover program level parallelism. While transition axioms have been used to reason about parallel and distributed programs <ref> [CM88, LT87, Lam89] </ref>, we know of no other work that defines a link between the transition axiom specification and a parallel program written in a conventional language. 122 4.4.2 Extensions There are two aspects of the transition-based approach that limit its use.
Reference: [LT89] <author> Nancy A. Lynch and Mark R. Tuttle. </author> <title> An introduction to input/output automata. </title> <journal> CWI-Quarterly, </journal> <volume> 2(3), </volume> <year> 1989. </year>
Reference-contexts: Furthermore, the liveness properties describe properties of infinite executions, not procedures for ensuring those properties. It is popular in the literature to refer to lower-level specifications as implementations of higher-level ones <ref> [Lam89, CM88, LT89] </ref>, 74 but we reserve the word implementation for programs written in a language that runs on a real machine. In step 3, a set of procedures called transition procedures are implemented. The procedures are themselves sequential, but are run concurrently with one another.
Reference: [Luc87a] <author> John Lucassen. </author> <title> Type and effects: Towards the integration of functional and imperative programming. </title> <type> Technical Report MIT/LCS/TR-408, </type> <institution> MIT Laboratory for Computer Science, </institution> <address> Cambridge, MA, </address> <month> August </month> <year> 1987. </year>
Reference-contexts: In theory, the evaluation of P 2 may begin while P 1 is computing, but in practice it may have to wait for P 1 to finish computing its result. The FX programming language is a hybrid of the functional and imperative styles <ref> [Luc87a] </ref>. The type system distinguishes between purely functional expressions and mutating ones, so the compiler can automatically parallelize certain pieces of a program, while allowing the programmer the expressive power of assignment when it is necessary.
Reference: [Luc87b] <author> S. Lucco. </author> <title> Parallel programming in a vitual object space. </title> <booktitle> In Conference on Object Oriented Programming Systems, Languages, and Applications, </booktitle> <month> October </month> <year> 1987. </year>
Reference-contexts: The most common example of a distributed object is a memory cell in a multiprocessor with caches, but many others have been designed and implemented for both distributed systems [Ell85, BT88, BHJ + 87] and for multiprocessors <ref> [Luc87b, Dal86, CD90] </ref>. To access a distributed object, these systems provide sophisticated run-time support so that each object is given a single name; the run-time system must determine what node in the distributed object should be used for a particular operation.
Reference: [Mar86] <author> Ursula Martin. </author> <title> Doing algebra with REVE. </title> <type> Technical report, </type> <institution> University of Manch-ester, </institution> <address> Manchester, England, </address> <year> 1986. </year>
Reference-contexts: Completion procedures have been used for doing data type induction [Mus80], interpreting equational logic programs [GM86], proving theorems in first order theories [HD83], debugging specifications [GGH90], proving equivalence of algebras <ref> [Mar86] </ref>, and automatically generating equational unification algorithms [Hul80]. The original completion procedure was discovered by Knuth and Bendix [KB70], and has since been studied, modified, and extended. See [Buc85], for a historical survey of completion procedures, with more than 200 references that include algorithms, applications, and implementations. <p> An interesting aspect of these numbers is that the grp56 example gets super-linear speedup. The performance of this example is highly dependent on the order in which critical pairs are computed, because there is one critical pair that eliminates most of the other rules <ref> [Mar86] </ref>. That explains why the speedup is super-linear. The other interesting point about the grp56 example is that while the speedup is much better for the round-robin scheduler than for the scheduler in Figure 5-8, the absolute performance is not.
Reference: [MNS87] <author> Peter Moller-Nielsen and Jorgen Staunstrup. Problem-heap: </author> <title> A paradigm for multiprocessor algorithms. </title> <journal> Parallel Computing, </journal> <volume> 4 </volume> <pages> 63-74, </pages> <year> 1987. </year>
Reference-contexts: Application-specific scheduling has been demonstrated to result in better performance than when systems schedulers are used directly [And89], and in particular, the worker model of application scheduling has been used successfully in a number of parallel applications <ref> [MNS87, CG89, RV89, JW90] </ref>. The worker model is an example of a user-level scheduling paradigm; it's definitive characteristic is that the tasks being scheduled are short-lived, so each is allowed run until it either blocks or finishes. Thus, the worker model avoids the complication and overhead of time-slicing schedulers.
Reference: [Mus80] <author> David R. Musser. </author> <title> On proving inductive properties of abstract data types. </title> <booktitle> In 2nd ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 154-163, </pages> <month> January </month> <year> 1980. </year>
Reference-contexts: In the worst case, there is no finite complete solution, so the procedure generates an infinite sequence of successively closer approximations to the infinite solution. Completion procedures have been used for doing data type induction <ref> [Mus80] </ref>, interpreting equational logic programs [GM86], proving theorems in first order theories [HD83], debugging specifications [GGH90], proving equivalence of algebras [Mar86], and automatically generating equational unification algorithms [Hul80]. The original completion procedure was discovered by Knuth and Bendix [KB70], and has since been studied, modified, and extended.
Reference: [OG76] <author> Susan Owicki and David Gries. </author> <title> An axiomatic proof technique for parallel programs I. </title> <journal> Acta Informatica, </journal> <volume> 6(4) </volume> <pages> 319-340, </pages> <month> August </month> <year> 1976. </year>
Reference-contexts: The auxiliary objects have the flavor of history variables that are useful in correctness proofs of parallel programs <ref> [OG76] </ref>, but the auxiliary objects in our implementation actually exist. The state in Figure 4-8 uses four different linearizable data types: queues of equations (eq queue), accumulators, memory locations , and mappings . <p> Specification 4-6 is a classic refinement of specification 4-5, because a consistency action in the first is replaced by a sequence of smaller actions in the second; the proof makes use of history variables <ref> [OG76] </ref>, a proof technology known to be useful for such refinments. The usual notion of satisfaction between transition axiom specifications requires preservation of whatever states (or actions) are externally visible. <p> It is not alway possible to define an abstraction function on indiviual states, since the abstract value may depend on the history (or even future [AL88]) of the execution. To make the abstraction function definable, auxiliary information is added to the specification state to record an execution's history <ref> [OG76] </ref>. The auxiliary information does not change the specification; neither the transition axioms nor the liveness property in the augmented specification depend on auxiliary values.
Reference: [Pap79] <author> C. H. Papadimitriou. </author> <title> The seriablizability of concurrent database updates. </title> <journal> Journal of the ACM, </journal> <pages> pages 631-653, </pages> <month> October </month> <year> 1979. </year>
Reference-contexts: Both correctness notions have analogs in the theory for distributed transactions. If each transaction is equated with a single operation in our model, sequential consistency corresponds to serializability and linearizability corresponds to the histories in class Q <ref> [Pap79] </ref>. The fundamental difference between the two problem domains is that transactions are generally an arbitrary sequence of operations terminated by a special commit operation. Serialization is done on an entire transaction (i.e., a sequence of operations) rather than on individual operations.
Reference: [PGH + 89] <author> C. D. Polychronopoulos, M. Gikar, M. R. Haghighat, C. L. Lee, B. Leung, and D. Schouten. </author> <title> Parafrase-2: An environment for parallelizing, partitioning, synchro 167 nizing, and scheduling programs on multiprocessors. </title> <journal> International Journal of High Speed Computing, </journal> <volume> 1(1) </volume> <pages> 45-72, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: The most significant effort has been in the area of parallelizing Fortran programs, where signifi 124 cant progress has occurred in developing algorithms to detect parallelism for both numerical <ref> [ABC + 87, PGH + 89] </ref> and symbolic [LH88] programs. These techniques are most promising for numerical programs, most of the techniques focus on parallelizing loops. The payoffs for these compilation techniques on complete application programs running on existing machines are not yet known.
Reference: [Pon88] <author> Carl Ponder. </author> <title> Evaluation of performance enhancements in algebraic manipulation systems. </title> <type> Technical Report UCB/CSD-88/438, </type> <institution> Computer Science Division, University of California, Berkeley, </institution> <address> CA 94720, </address> <year> 1988. </year>
Reference-contexts: Figure 5-2 shows the relative time for the two stages of the pipeline, given typical input. 2 In parallelizing Buchberger's algorithm for computing Grobner bases, which is similar to the completion problem, Ponder notes the same phenomenon <ref> [Pon88] </ref>. 130 norm (ms): 0 369 0 160 139 21 481 2781 170 922 1841 2897 4768 crit (ms): 28 0 19 32 15 47 151 35 48 94 117 180 67 norm/crit: 0 1 0 5 9 0 3 79 3 9 15 16 71 Each column is a separate
Reference: [PS81] <author> G. E. Peterson and M. E. Stickel. </author> <title> Complete sets of reductions for some equational theories. </title> <journal> Journal of the ACM, </journal> <volume> 28(2) </volume> <pages> 233-264, </pages> <month> April </month> <year> 1981. </year>
Reference-contexts: Other variations on the completion includes narrowing [Hul80] and completion modulo equations <ref> [Hue80, PS81] </ref>. Although these problems fall in the class addressed by our approach, we consider only traditional completion in this thesis. 134 All these variations on completion are unsolvable, and in fact the problem of determining whether a set of rules is noetherian is undecidable.
Reference: [Rin89] <author> G. A. </author> <title> Ringwood. </title> <journal> Parlog85 and the dining logicians. Communications of the ACM, </journal> <volume> 31(1) </volume> <pages> 10-25, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: For some programs, object mutations are mainly instantiations, i.e., an object may be created in some partially constructed form, and parallel threads fill in the missing pieces. This form of mutation can be handled by futures [Hal85], I-structures [ANP87], and logical variables in logic programs <ref> [Rin89] </ref>. Since objects cannot be mutated after instantiation, the only kind of race condition arises from whether or not an object has been computed. Special hardware or software checks can prevent threads from observing uninstantiated objects.
Reference: [RR87] <author> R. Ramesh and I.V. Ramakrishnan. </author> <title> Optimal speedups for parallel pattern matching in trees. </title> <editor> In Pierre Lescanne, editor, </editor> <booktitle> Proceedings of the 2nd International Conference on Rewriting Techniques and Applications, Bordeaux, France, </booktitle> <pages> pages 274-285. </pages> <publisher> Springer-Verlag, LNCS 256, </publisher> <month> May </month> <year> 1987. </year>
Reference-contexts: The unification problem, has a linear time sequential algorithm, and is known to be P-Space complete, so it is unlikely to have a faster than polynomial time parallel algorithm [DKM84]. The matching problem has a logarithmic time algorithm on a polynomial number of processors <ref> [RR87, DKS88] </ref>, but cannot be done in onstant time algorithm [VR90]. All of these results were shown using the PRAM model, which has limited applicability to real machines, because the model is synchronous, ignores communication overhead, and only bounds processor utilization within a polynomial of the input.
Reference: [RV89] <author> Eric Roberts and Mark Vandevoorde. </author> <title> Work crews: An abstraction for controlling parallelism. </title> <type> Technical Report 42, </type> <institution> Digital Equipment Corporation Systems Research Center, Palo Alto, California, </institution> <year> 1989. </year>
Reference-contexts: However, the high-level approach does influence the low-level implementations in one regard: we assume there is application-specific scheduling, which means the application program schedules tasks (short-lived computations) on top of the system-level threads (long-lived computations) <ref> [RV89, CG89, JW90] </ref>. The scheduling model will be discussed further in Chapter 4, but for now, the important issue is the interaction between scheduling and synchronization. <p> Application-specific scheduling has been demonstrated to result in better performance than when systems schedulers are used directly [And89], and in particular, the worker model of application scheduling has been used successfully in a number of parallel applications <ref> [MNS87, CG89, RV89, JW90] </ref>. The worker model is an example of a user-level scheduling paradigm; it's definitive characteristic is that the tasks being scheduled are short-lived, so each is allowed run until it either blocks or finishes. Thus, the worker model avoids the complication and overhead of time-slicing schedulers. <p> A second problem with having more threads than processors is that scheduling of threads is done by the system scheduler; application-specific scheduling usually yields much better performance <ref> [RV89, JW90] </ref>. The solution to both problems is to start a fixed number of threads at the beginning of a program's execution, and to schedule tasks onto these threads. <p> The solution to both problems is to start a fixed number of threads at the beginning of a program's execution, and to schedule tasks onto these threads. Examples of this approach 100 include tuple spaces [CG89], work crews <ref> [RV89] </ref>, and supervisors [JW90]; the approaches differ in the kinds of synchronization allowed between tasks, and the underlying scheduling algorithm. A task is a procedure invocation (a procedure plus input arguments) that is guaranteed to terminate.
Reference: [Sch88] <author> James G. Schmolze. </author> <title> Parallel algorithms for knowledge representation. </title> <type> unpublished manuscript, </type> <year> 1988. </year>
Reference-contexts: When term rewriting techniques are applied to theorem proving [HD83], knowledge representation <ref> [Sch88] </ref>, and logic programming [GM86], the property of convergence is often essential. In some applications, convergence is established by adding new rules to the system in a completion process, while in other applications convergence is a property that is tested for a fixed set of rules.
Reference: [SS88] <author> Dennis Shasha and Marc Snir. </author> <title> Efficient and correct execution of parallel programs that share memory. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 10(2) </volume> <pages> 282-312, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: Conditional correctness notions have appeared in the multiprocessor literature for implementations of weak shared memory, where memory is shown to be sequentially consistent given certain assumptions about how memory operations are used <ref> [DS88, AH90b, SS88] </ref>. We generalize these concepts to arbitrary shared data types and give a linguistic mechanism for specifying the restrictions on use. In this section we assume that the user of an abstraction is willing to make promises about how the operations will be used. <p> The notion of interference between operations has been exploited in various ways in related work. As noted earlier, some multiprocessor memory implementations make use of interference information to schedule the operations. In particular, the algorithm of <ref> [SS88] </ref> schedules memory operations so that memory that is not sequentially consistent at the hardware level appears sequentially consistent to the programmer. The algorithm requires data flow analysis to determine which interfering operations may actually execute concurrently, which may limit its practicality. <p> Although many shared memory implementations are actually linearizable, there are proposals for sequentially consistent memory that is not linearizable, so we used the weaker assumption that memory is sequentially consistent. See <ref> [AH90a, GLL + 90, BR90, DS88, SS88] </ref> for examples of memory implementations that are sequentially consistent but not necessarily linearizable. 43 44 Chapter 3 Implementing Concurrent Data Types In this chapter we present specifications and implementations of a number of concurrent data types.
Reference: [TSJ87] <author> Chuck Thacker, Lawrence C. Stewart, and Edwin H. Satterthwaite Jr. Firefly: </author> <title> A multiprocessor workstation. </title> <type> Research Report 23, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <address> Palo Alto, CA, </address> <month> December </month> <year> 1987. </year>
Reference-contexts: We present careful correctness arguments for pieces of the design, demonstrating a modular approach to reasoning about this style of program. Performance numbers are presented based on experiments run on a five processor Firefly <ref> [TSJ87] </ref>. 1.3.4 Parallel Completion Chapter 5 contains a proof of concept for the transition-based approach. We give a parallel solution to the completion problem for term rewriting systems, bringing together the work in the earlier chapters. <p> Our approach to building applications would well-suited to their two-level model of scheduling. 3.2 Specifications of the Hardware Abstractions We start by specifying the abstractions provided by the Firefly hardware <ref> [TSJ87] </ref>. The Firefly has coherent caches that implement sequentially consistent memory. 1 In addition to read and write operations, the hardware also has a small set of interlocked instructions, instructions that are indivisible with respect to each other. <p> The transformations themselves are useful in other applications, and the effect they have on performance is significant. Performance Tuning Before describing the scheduler transformations, some comments about the performance numbers are timely. All performance numbers are taken on a Firefly multi-processor <ref> [TSJ87] </ref>, using up to five CVAX processors. The input to the matching program is a pair of terms, and in discussing performance, we work with a set of inputs that characterizes various classes.
Reference: [VR90] <author> Rakesh M. Verma and I.V. Ramakrishnan. </author> <title> Tight complexity bounds for term matching problems. </title> <booktitle> Information and Computation, </booktitle> <year> 1990. </year> <month> 168 </month>
Reference-contexts: The matching problem has a logarithmic time algorithm on a polynomial number of processors [RR87, DKS88], but cannot be done in onstant time algorithm <ref> [VR90] </ref>. All of these results were shown using the PRAM model, which has limited applicability to real machines, because the model is synchronous, ignores communication overhead, and only bounds processor utilization within a polynomial of the input.
Reference: [Win83] <author> Jeannette M. Wing. </author> <title> A two-tiered approach to specifying programs. </title> <type> Technical Report MIT/LCS/TR-299, </type> <institution> MIT Laboratory for Computer Science, </institution> <address> Cambridge, MA, </address> <year> 1983. </year>
Reference-contexts: Our specifications are informal although they have a similar structure to interface specifications written in the Larch family of formal specification languages <ref> [GHW85, Win83] </ref>. Others have used Larch-style specifications to specify concurrent operations [HW90, BGHL87]. <p> A more precise characterization of states for a real programming language, and interpretations of predicates in those states, would require a formal language and a richer model than we wish to pursue here. Wing <ref> [Win83] </ref> gives such an interpretation for formal specifications in sequential CLU programs, and Goldman [GL90] gives a detailed model of shared state for concurrent operations. 27 Given a specification for some procedure P , a state pair hpre; posti is said to be a legal execution of P if either: 1.
Reference: [WW90] <author> William E. Weihl and Paul Wang. </author> <title> Multi-version memory: Software cache management for concurrent B-trees. </title> <booktitle> In Proceedings of the Symposium on Parallel and Distributed Processing, </booktitle> <month> December </month> <year> 1990. </year> <month> 169 </month>
Reference-contexts: We refer to such objects as multi-ported objects and to each thread's version as a port. Implementations of this kind are prevalent in implementations of shared and distributed objects but we know of no other work that describes the specifications of the procedures that access these object. (See <ref> [Ell85, Her90, CD90, WW90] </ref> for some examples of objects that contain thread-specific data.) The specification of a multi-ported object typically has an interference specification that depends on the port being used, which is important because it means that a multi-ported object looks different than a normal object, even at the abstract
References-found: 79

