URL: ftp://ftp.cs.man.ac.uk/pub/TR/UMCS-96-11-1.ps.Z
Refering-URL: http://www.cs.man.ac.uk/cstechrep/Abstracts/UMCS-96-11-1.html
Root-URL: http://www.cs.man.ac.uk
Title: A ROBUST, PERCEPTIONBASED LOCALISATION METHOD FOR A MOBILE ROBOT  
Author: T. Duckett and U. Nehmzow 
Affiliation: Computer Science University of Manchester  
Pubnum: ISSN 1361 6161  
Abstract: Department of Computer Science University of Manchester Technical Report Series UMCS-96-11-1 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Atiya and G. D. Hager, </author> <title> "Real-Time Vision-Based Robot Localization", </title> <journal> IEEE Trans. Robotics and Automation, </journal> <volume> Vol. 9, No. 6, </volume> <pages> pp. 785-800, </pages> <year> 1993. </year>
Reference-contexts: A further approach effectively uses dead reckoning to disambiguate similar looking locations. The estimate of position provided by dead reckoning is corrected by matching observed features of the environment against an internal world model <ref> [1] </ref> [5] [8] [9] [10] [22] [23]. For example, Kuipers and Byun [9] move the robot itself towards locally distinctive places as a means of correcting the drift error due to odometry.
Reference: [2] <author> A. Buhlmeier, H. Durer, J. Monnerjahn, M. Nolte and U. Nehmzow, </author> <title> "Learning by Tuition, Experiments with the Manchester `FortyTwo' ", Dept. </title> <institution> Computer Science, University of Manchester, </institution> <type> Technical Report Series UMCS-96-1-2, </type> <year> 1996. </year>
Reference-contexts: Some authors make no provision for perceptual ambiguity, assuming a one-to-one mapping between (unique) perceptual signatures and physical locations. Others attempt to distinguish similar looking locations by using more and more sensory information from an increasing number of sensor modalities. Buhlmeier et al <ref> [2] </ref> have successfully used this method. However, increasing the robot's perceptual resolution will not solve the more general relocalisation problem because the absence of perceptual aliasing can never be assumed with certainty in complex environments. Navigation strategies based on this assumption are bound to fail sooner or later. <p> These sensors are mounted on a turret, which can be rotated separately from the base of the robot (see figure 7). The robot has three separate motors for translational, rotational and turret motion. In previous work, e.g., <ref> [2] </ref> [18], the rotational and turret motors have been controlled in unison, so that the sensors always point in the same direction relative to the heading of the robot.
Reference: [3] <author> P. Calter, </author> <title> "Technical mathematics with calculus", 3rd edition, </title> <publisher> Prentice-Hall, </publisher> <year> 1994. </year>
Reference-contexts: This means that that the weight vectors are moved to the fullest extent possible, allowing locations to be remembered by the robot after a single visit. The Runge-Kutta method <ref> [3] </ref> was used to solve the differential equations used for carrying out the weight adjustment.
Reference: [4] <author> G. Carpenter and S. Grossberg, "ART2: </author> <title> Self-Organization of Stable Category Recognition Codes for Analog Input Patterns", </title> <journal> Applied Optics, </journal> <volume> Vol. 26, No. 23, </volume> <pages> pp. 4919-4930, </pages> <year> 1987. </year>
Reference-contexts: In accordance with the general principle of autonomous learning by the robot, a self-organising classification system is used. The neural network architecture ART2 <ref> [4] </ref> is responsible for clustering input patterns into distinct classes or categories, such that similar patterns are grouped into the same class and dissimilar patterns are grouped into separate classes. <p> In addition to the basic architecture, an extra pre-processing layer (F0), consisting of a subnetwork of four nodes per unit, was added to further reduce noise and enhance the contrast of the input patterns, as suggested by Carpenter and Grossberg <ref> [4] </ref>. Full details of the architecture and equations describing the dynamics of ART2 may be found in Appendix A. In ART2, adaptive learning is carried out by moving the stored weight vectors in the direction of the input vector (the magnitude of vectors is ignored due to vector normalisation).
Reference: [5] <author> T. Edlinger and G. Weiss, </author> <title> "Exploration, Navigation and Self-Localization in an Autonomous Mobile Robot", Autonome mobile Systeme '95, </title> <address> Karlsruhe, Germany, </address> <month> Nov 30 - Dec 1 </month> <year> 1995. </year>
Reference-contexts: A further approach effectively uses dead reckoning to disambiguate similar looking locations. The estimate of position provided by dead reckoning is corrected by matching observed features of the environment against an internal world model [1] <ref> [5] </ref> [8] [9] [10] [22] [23]. For example, Kuipers and Byun [9] move the robot itself towards locally distinctive places as a means of correcting the drift error due to odometry.
Reference: [6] <author> S. Engelson, </author> <title> "Passive map learning and visual place recognition", </title> <type> Ph.D. thesis, </type> <institution> Dept. Computer Science, Yale University, </institution> <address> New Haven, CT, </address> <year> 1994. </year>
Reference-contexts: In particular, this paper is concerned with the worst case of relocalising after becoming lost through whatever circumstance. This is equivalent to Engelson's "kidnapped robot problem" <ref> [6] </ref>, where the robot is picked up and moved to an arbitrary location while being deprived of any sensory input. Thus, no a priori estimate of position is available to the robot.
Reference: [7] <author> S. Grossberg, </author> <booktitle> "Neural Networks and Natural Intelligence", </booktitle> <publisher> MIT Bradford Press, </publisher> <year> 1988. </year>
Reference-contexts: This prevents any pattern that is a subset of another from being classified in the same category. Thus, patterns which share common features but are in different classes can still be distinguished. Grossberg <ref> [7] </ref> calls this "the discovery of critical features in a context sensitive manner". However, ART does have some disadvantages too. <p> If none of the stored prototypes is similar enough to the given input, then a new prototype will be created corresponding to the input pattern. In earlier clustering experiments, the ART1 network <ref> [7] </ref> was tried, but was found to be unreliable because of the requirement of binary inputs. The individual sensor readings had to be coarse coded into "bins" (i.e., `0' or `1') according to a threshold level.
Reference: [8] <author> J. Horn and G. Schmidt, </author> <title> "Continuous localization of a mobile robot based on 3D laser range data, predicted sensor images, </title> <booktitle> and dead-reckoning", Robotics and Autonomous Systems 14, </booktitle> <pages> pp. 99-118, </pages> <year> 1995. </year>
Reference-contexts: A further approach effectively uses dead reckoning to disambiguate similar looking locations. The estimate of position provided by dead reckoning is corrected by matching observed features of the environment against an internal world model [1] [5] <ref> [8] </ref> [9] [10] [22] [23]. For example, Kuipers and Byun [9] move the robot itself towards locally distinctive places as a means of correcting the drift error due to odometry.
Reference: [9] <author> B. J. Kuipers and Y.-T. Byun. </author> <title> "A Robust, Qualitative Method for Robot Spatial Learning", </title> <booktitle> Proc. AAAI 1988. </booktitle>
Reference-contexts: A further approach effectively uses dead reckoning to disambiguate similar looking locations. The estimate of position provided by dead reckoning is corrected by matching observed features of the environment against an internal world model [1] [5] [8] <ref> [9] </ref> [10] [22] [23]. For example, Kuipers and Byun [9] move the robot itself towards locally distinctive places as a means of correcting the drift error due to odometry. <p> A further approach effectively uses dead reckoning to disambiguate similar looking locations. The estimate of position provided by dead reckoning is corrected by matching observed features of the environment against an internal world model [1] [5] [8] <ref> [9] </ref> [10] [22] [23]. For example, Kuipers and Byun [9] move the robot itself towards locally distinctive places as a means of correcting the drift error due to odometry.
Reference: [10] <author> A. Kurz, </author> <title> "Constructing Maps for Mobile Robot Navigation Based on Ultrasonic Range Data", </title> <journal> IEEE Trans. Systems, Man, and Cybernetics Part B: Cybernetics, </journal> <volume> Vol. 26, No. 2, </volume> <month> April </month> <year> 1996. </year>
Reference-contexts: The current estimate of position may be explicit, being anchored to some global reference frame <ref> [10] </ref> [22] [23], or implicit [18] [20], e.g., Owen [18] directly associates sensor patterns with motor actions, obviating the need for any symbolic representation of position. Similarly, the robot may or may not possess an explicit world model. <p> A further approach effectively uses dead reckoning to disambiguate similar looking locations. The estimate of position provided by dead reckoning is corrected by matching observed features of the environment against an internal world model [1] [5] [8] [9] <ref> [10] </ref> [22] [23]. For example, Kuipers and Byun [9] move the robot itself towards locally distinctive places as a means of correcting the drift error due to odometry. <p> The maps used in these localisation methods are often graph-based, using topologically connected "place" nodes. Metric information, corresponding to the relative translational and rotational displacement of the robot between places, may be added <ref> [10] </ref> [22] [23]. Position updates may be continuous [10] or episodic [22]. <p> The maps used in these localisation methods are often graph-based, using topologically connected "place" nodes. Metric information, corresponding to the relative translational and rotational displacement of the robot between places, may be added <ref> [10] </ref> [22] [23]. Position updates may be continuous [10] or episodic [22]. <p> Suitable perceptual landmarks emerge rather than being defined arbitrarily by a human designer. ART (Adaptive Resonance Theory) is not the only methodology that could be used for the localisation task. Other possible clustering techniques would include Self-Organising Feature Maps <ref> [10] </ref> [15] [18], Restricted Coulomb Energy networks [10], Growing Cell Structures [23], Vector Quantization networks, etc. The specific advantages and disadvantages of using ART are discussed in the next section. <p> Suitable perceptual landmarks emerge rather than being defined arbitrarily by a human designer. ART (Adaptive Resonance Theory) is not the only methodology that could be used for the localisation task. Other possible clustering techniques would include Self-Organising Feature Maps <ref> [10] </ref> [15] [18], Restricted Coulomb Energy networks [10], Growing Cell Structures [23], Vector Quantization networks, etc. The specific advantages and disadvantages of using ART are discussed in the next section. <p> Adapted from Kurz <ref> [10] </ref>, figure 7. 4 Map Building After perceptual clustering has been carried out, the next stage is to build a map of the locations visited during exploration. The map created contains stored "locations", where a location is an ART category associated with an (x; y) coordinate obtained by dead reckoning. <p> Whenever the robot moves into a different perceptual region, a new location point is created. This point will keep moving towards the approximate centre of the cluster due to the averaging process, until a new cluster is formed. This is similar to the map building system described by Kurz <ref> [10] </ref>. In addition, when the displacement of the robot from the current (nearest) point location exceeds the distance threshold D, a new point location is also created. This leads to multiple point locations within large perceptual regions (see figure 6). <p> This issue is discussed further in the conclusions. See also Kurz <ref> [10] </ref> and Zimmer [23] for some interesting work on this problem. 10 5 Localisation The basic principle of the localisation method is similar to that of ART and other competitive learning schemes; the location point in the map with the highest "activation" or confidence level is selected as the winner. <p> After localisation has been achieved, the error between the actual and estimated position should therefore vary between zero and D (see next section). In future work, the localisation error could be smoothed out by merging successive position estimates, e.g., using the Extended Kalman Filter <ref> [10] </ref> [11], rather than by simply replacing an existing estimate with one taken directly from the map.
Reference: [11] <author> D. C. Lee, </author> <title> "The Map-Building and Exploration Strategies of a Simple, Sonar- Equipped Mobile Robot; An Experimental, Qualitative Evaluation", </title> <type> Ph.D. thesis, </type> <institution> University College London, Eng-land, </institution> <year> 1995. </year>
Reference-contexts: Similarly, the robot may or may not possess an explicit world model. Lee <ref> [11] </ref> provides a useful taxonomy of world models, distinguishing Recognisable Locations, Topological Maps, Metric Topological Maps and Full Metric Maps. Perhaps the most useful categorisation can be made according to the approach used in handling perceptual aliasing. <p> The stored locations could therefore be said to correspond to "place prototypes". The representation accommodates perceptual aliasing because there may be a one-to-many relationship between perceptual signatures (ART categories) and stored locations in the map. In Lee's taxonomy <ref> [11] </ref>, the world model might be described as "Recognisable Locations", except that metric information is also represented. <p> After localisation has been achieved, the error between the actual and estimated position should therefore vary between zero and D (see next section). In future work, the localisation error could be smoothed out by merging successive position estimates, e.g., using the Extended Kalman Filter [10] <ref> [11] </ref>, rather than by simply replacing an existing estimate with one taken directly from the map.
Reference: [12] <author> M. J. Mataric, </author> <title> "Integration of Representation Into Goal-Driven Behaviour-Based Robots", </title> <journal> IEEE Trans. Robotics and Automation, </journal> <volume> Vol. 8, No. 3, </volume> <month> June </month> <year> 1992. </year>
Reference-contexts: The map used is similar to the graph-based models described above (detailed in section 4). An explicit world model was used partly because of the growing consensus over the need for some form of representation, even amongst strongly behaviour-based researchers, e.g, <ref> [12] </ref>, and partly because this particular representation made possible the development of the algorithm for evidence accumulation (see section 5). The work is also related to hippocampal models of localisation [19]. The map used consists of a discrete set of distinct locations; these are analogous to place cells.
Reference: [13] <author> U. Nehmzow, </author> <title> "Experiments in Competence Acquisition for Autonomous Mobile Robots", </title> <type> PhD thesis, </type> <institution> Dept. Artificial Intelligence, University of Edinburgh, </institution> <year> 1992. </year>
Reference-contexts: Both the map building and localisation competences operate independently of the exploration strategy used. In this paper, performance is demonstrated using two different exploration behaviours (contour following and wandering), both having been acquired autonomously by the robot using instinct rules (see Nehmzow <ref> [13] </ref> for details). The system as a whole is composed of a hierarchy of behaviours (see figure 1), each being resilient to a significant degree of error in the preceding levels. <p> Attention is drawn to these "magic numbers" in the intepretation of results wherever their effect was found to be most critical. Two different exploration behaviours, wall following and wandering (both incorporating obstacle avoidance), were implemented in a Perceptron-like neural network, which was trained using instinct rules (see Nehmzow <ref> [13] </ref> for details). At the moment, the controller is completely reactive, directly associating different perceptions from the sonar and infrared sensors with appropriate actions for the translational and rotational motors. <p> The wandering behaviour used was based on learned smooth, continuous obstacle avoidance (see <ref> [13] </ref> for details). To prevent the robot from getting stuck in loops around one part of the environment, random noise was added to the output vector of the neural controller.
Reference: [14] <author> U. Nehmzow, </author> <title> "Animal and Robot Navigation", </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> Vol. 15, No. 1 - 2, </volume> <pages> pp. 71-81, </pages> <year> 1995. </year>
Reference-contexts: However, significantly better results were achieved in both map building and localisation when using the wall follower, indicating a big advantage in exploration using canonical paths over random movement (see also Nehmzow <ref> [14] </ref> for a more detailed discussion of this aspect). In particular, map building is far more efficient, using much fewer location points in a similar sized area.
Reference: [15] <author> U. Nehmzow and T. Smithers, </author> <title> "Mapbuilding using Self-Organising Networks", </title> <editor> in J. A. Meyer and S. Wilson (eds.), </editor> <booktitle> "From Animals to Animats", Proc. SAB90 Paris, </booktitle> <pages> pp. 152-159, </pages> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Furthermore, some degree of perceptual aliasing is actually desirable, in that it provides a generalisation on perception. Another approach for dealing with perceptual ambiguity is to incorporate history of local sensor sequences into the recognition of locations. Nehmzow and Smithers <ref> [15] </ref> combine past and present sensorimotor experience of the robot in the input to a self-organising feature map. Similarly, Tani and Fukumara [20] add previous sensor patterns to the input field of a neural network controller. <p> Suitable perceptual landmarks emerge rather than being defined arbitrarily by a human designer. ART (Adaptive Resonance Theory) is not the only methodology that could be used for the localisation task. Other possible clustering techniques would include Self-Organising Feature Maps [10] <ref> [15] </ref> [18], Restricted Coulomb Energy networks [10], Growing Cell Structures [23], Vector Quantization networks, etc. The specific advantages and disadvantages of using ART are discussed in the next section.
Reference: [16] <author> U. Nehmzow, T. Smithers and J. Hallam, </author> <title> "Location Recognition in a Mobile Robot Using Self-Organising Feature Maps", </title> <editor> in G. Schmidt (ed.), </editor> <booktitle> "Information Processing in Autonomous Mobile Robots", </booktitle> <publisher> Springer Verlag, </publisher> <year> 1991. </year>
Reference-contexts: A disadvantage of this approach is that the identical set of previously stored locations must be revisited for matching of history information to be possible. In complex environments, this can only be achieved by restricting the navigational behaviour of the robot, often to following fixed paths. Nehmzow et al <ref> [16] </ref> showed that a range of temporal horizons or "time windows" of history is required to localise in an environment containing perceptual aliasing, i.e., one fixed length of history was shown to be insufficient.
Reference: [17] <author> U. Nehmzow and T. Mitchell, </author> <title> "The Prospective Student's Introduction to the Robot Learning Problem", </title> <institution> Dept. Computer Science, University of Manchester, </institution> <type> Technical Report Series UMCS-95-12-6, </type> <year> 1995. </year>
Reference-contexts: Thus, no a priori estimate of position is available to the robot. People inevitably observe the world differently to robots, a problem described as perceptual discrepancy by Nehmzow and Mitchell <ref> [17] </ref>. We therefore believe that the robot itself should acquire its knowledge of the world, e.g., avoiding the use of pre-installed maps wherever possible.
Reference: [18] <author> C. Owen, "Landmarks, </author> <title> Topological Maps and Robot Navigation", M.Sc. </title> <type> thesis, </type> <institution> Dept. Computer Science, University of Manchester, </institution> <address> England, </address> <year> 1996. </year> <month> 26 </month>
Reference-contexts: The current estimate of position may be explicit, being anchored to some global reference frame [10] [22] [23], or implicit <ref> [18] </ref> [20], e.g., Owen [18] directly associates sensor patterns with motor actions, obviating the need for any symbolic representation of position. Similarly, the robot may or may not possess an explicit world model. <p> The current estimate of position may be explicit, being anchored to some global reference frame [10] [22] [23], or implicit <ref> [18] </ref> [20], e.g., Owen [18] directly associates sensor patterns with motor actions, obviating the need for any symbolic representation of position. Similarly, the robot may or may not possess an explicit world model. Lee [11] provides a useful taxonomy of world models, distinguishing Recognisable Locations, Topological Maps, Metric Topological Maps and Full Metric Maps. <p> Suitable perceptual landmarks emerge rather than being defined arbitrarily by a human designer. ART (Adaptive Resonance Theory) is not the only methodology that could be used for the localisation task. Other possible clustering techniques would include Self-Organising Feature Maps [10] [15] <ref> [18] </ref>, Restricted Coulomb Energy networks [10], Growing Cell Structures [23], Vector Quantization networks, etc. The specific advantages and disadvantages of using ART are discussed in the next section. <p> These sensors are mounted on a turret, which can be rotated separately from the base of the robot (see figure 7). The robot has three separate motors for translational, rotational and turret motion. In previous work, e.g., [2] <ref> [18] </ref>, the rotational and turret motors have been controlled in unison, so that the sensors always point in the same direction relative to the heading of the robot.
Reference: [19] <author> M. Recce and K. D. Harris, </author> <title> "Memory for places: A navigational model in support of Marr's theory of hippocampal function", Dept. Anatomy and Developmental Biology, </title> <address> University College London, England. </address> <publisher> In press Hippocampus, </publisher> <year> 1996. </year>
Reference-contexts: The work is also related to hippocampal models of localisation <ref> [19] </ref>. The map used consists of a discrete set of distinct locations; these are analogous to place cells. <p> Thus, the location points are analogous to the "place cells" found in hippocampal models of localisation, e.g., see Recce and Harris <ref> [19] </ref>. The confidence levels are adjusted by accumulating evidence based on relative odometry between locations.
Reference: [20] <author> J. Tani and N. Fukumara, </author> <title> "Learning Goal-Directed Sensory-Based Navigation of a Mobile Robot", </title> <booktitle> Neural Networks, </booktitle> <volume> Vol. 7, No. 3, </volume> <pages> pp. 553-563, </pages> <year> 1994. </year>
Reference-contexts: The current estimate of position may be explicit, being anchored to some global reference frame [10] [22] [23], or implicit [18] <ref> [20] </ref>, e.g., Owen [18] directly associates sensor patterns with motor actions, obviating the need for any symbolic representation of position. Similarly, the robot may or may not possess an explicit world model. <p> Another approach for dealing with perceptual ambiguity is to incorporate history of local sensor sequences into the recognition of locations. Nehmzow and Smithers [15] combine past and present sensorimotor experience of the robot in the input to a self-organising feature map. Similarly, Tani and Fukumara <ref> [20] </ref> add previous sensor patterns to the input field of a neural network controller. A disadvantage of this approach is that the identical set of previously stored locations must be revisited for matching of history information to be possible.
Reference: [21] <author> G. Weiss and E. v. Puttkamer, </author> <title> "A Map Based on Laserscans Without Geometric Interpretation", </title> <booktitle> Intelligent Autonomous Systems-4 (IAS-4), </booktitle> <address> Karlsruhe, Germany, </address> <month> March </month> <year> 1995, </year> <pages> pp. 403-407. </pages>
Reference-contexts: The robot might then only need to take a couple of "snapshots" in a given room to successfully map the whole of the surrounding space. Weiss and von Puttkamer <ref> [21] </ref> use cross-correlation of range-finder scans for this purpose. We propose to investigate this technique for the application discussed here. 7.3.4 Scaling It All Up Along with the other related work reviewed earlier, the system developed has only been used in relatively small, carefully controlled test environments.
Reference: [22] <author> B. Yamauchi and R. Beer, </author> <title> "Spatial Learning for Navigation in Dynamic Environments", </title> <journal> IEEE Trans. Systems, Man, and Cybernetics Part B: Cybernetics, </journal> <volume> Vol. 26, No. 3, </volume> <month> June </month> <year> 1996. </year>
Reference-contexts: The current estimate of position may be explicit, being anchored to some global reference frame [10] <ref> [22] </ref> [23], or implicit [18] [20], e.g., Owen [18] directly associates sensor patterns with motor actions, obviating the need for any symbolic representation of position. Similarly, the robot may or may not possess an explicit world model. <p> A further approach effectively uses dead reckoning to disambiguate similar looking locations. The estimate of position provided by dead reckoning is corrected by matching observed features of the environment against an internal world model [1] [5] [8] [9] [10] <ref> [22] </ref> [23]. For example, Kuipers and Byun [9] move the robot itself towards locally distinctive places as a means of correcting the drift error due to odometry. <p> The maps used in these localisation methods are often graph-based, using topologically connected "place" nodes. Metric information, corresponding to the relative translational and rotational displacement of the robot between places, may be added [10] <ref> [22] </ref> [23]. Position updates may be continuous [10] or episodic [22]. Some methods are capable of dealing with dynamic environments [22] [23], and even of distinguishing transient changes such as moving people from lasting changes in the environment [22]. 3 The research presented in this paper incorporates aspects of both of <p> The maps used in these localisation methods are often graph-based, using topologically connected "place" nodes. Metric information, corresponding to the relative translational and rotational displacement of the robot between places, may be added [10] <ref> [22] </ref> [23]. Position updates may be continuous [10] or episodic [22]. Some methods are capable of dealing with dynamic environments [22] [23], and even of distinguishing transient changes such as moving people from lasting changes in the environment [22]. 3 The research presented in this paper incorporates aspects of both of the latter approaches to resolving perceptual aliasing. <p> Metric information, corresponding to the relative translational and rotational displacement of the robot between places, may be added [10] <ref> [22] </ref> [23]. Position updates may be continuous [10] or episodic [22]. Some methods are capable of dealing with dynamic environments [22] [23], and even of distinguishing transient changes such as moving people from lasting changes in the environment [22]. 3 The research presented in this paper incorporates aspects of both of the latter approaches to resolving perceptual aliasing. <p> and rotational displacement of the robot between places, may be added [10] <ref> [22] </ref> [23]. Position updates may be continuous [10] or episodic [22]. Some methods are capable of dealing with dynamic environments [22] [23], and even of distinguishing transient changes such as moving people from lasting changes in the environment [22]. 3 The research presented in this paper incorporates aspects of both of the latter approaches to resolving perceptual aliasing. Evidence based on past sensory experience is used to mediate between competing position estimates, which are corrected by matching current perceptions to an autonomously acquired world model. <p> The map building process would need to more flexible, incorporating deletion as well as addition to the map, perhaps utilising variable confidence levels as in Zimmer [23] or Yamauchi <ref> [22] </ref>. However, distinguishing transient changes in the environment, e.g., people walking past, people in wheelchairs, other robots, etc., would be a problem, as it would be undesirable to include such things in the map.
Reference: [23] <author> U. R. Zimmer, </author> <title> "Self-Localization in Dynamic Environments", </title> <booktitle> IEEE/SOFT International Workshop BIES'95, </booktitle> <address> Tokyo, Japan, </address> <month> May 30-31 </month> <year> 1995. </year> <month> 27 </month>
Reference-contexts: The current estimate of position may be explicit, being anchored to some global reference frame [10] [22] <ref> [23] </ref>, or implicit [18] [20], e.g., Owen [18] directly associates sensor patterns with motor actions, obviating the need for any symbolic representation of position. Similarly, the robot may or may not possess an explicit world model. <p> A further approach effectively uses dead reckoning to disambiguate similar looking locations. The estimate of position provided by dead reckoning is corrected by matching observed features of the environment against an internal world model [1] [5] [8] [9] [10] [22] <ref> [23] </ref>. For example, Kuipers and Byun [9] move the robot itself towards locally distinctive places as a means of correcting the drift error due to odometry. <p> The maps used in these localisation methods are often graph-based, using topologically connected "place" nodes. Metric information, corresponding to the relative translational and rotational displacement of the robot between places, may be added [10] [22] <ref> [23] </ref>. Position updates may be continuous [10] or episodic [22]. Some methods are capable of dealing with dynamic environments [22] [23], and even of distinguishing transient changes such as moving people from lasting changes in the environment [22]. 3 The research presented in this paper incorporates aspects of both of the <p> Metric information, corresponding to the relative translational and rotational displacement of the robot between places, may be added [10] [22] <ref> [23] </ref>. Position updates may be continuous [10] or episodic [22]. Some methods are capable of dealing with dynamic environments [22] [23], and even of distinguishing transient changes such as moving people from lasting changes in the environment [22]. 3 The research presented in this paper incorporates aspects of both of the latter approaches to resolving perceptual aliasing. <p> ART (Adaptive Resonance Theory) is not the only methodology that could be used for the localisation task. Other possible clustering techniques would include Self-Organising Feature Maps [10] [15] [18], Restricted Coulomb Energy networks [10], Growing Cell Structures <ref> [23] </ref>, Vector Quantization networks, etc. The specific advantages and disadvantages of using ART are discussed in the next section. <p> This issue is discussed further in the conclusions. See also Kurz [10] and Zimmer <ref> [23] </ref> for some interesting work on this problem. 10 5 Localisation The basic principle of the localisation method is similar to that of ART and other competitive learning schemes; the location point in the map with the highest "activation" or confidence level is selected as the winner. <p> The map building process would need to more flexible, incorporating deletion as well as addition to the map, perhaps utilising variable confidence levels as in Zimmer <ref> [23] </ref> or Yamauchi [22]. However, distinguishing transient changes in the environment, e.g., people walking past, people in wheelchairs, other robots, etc., would be a problem, as it would be undesirable to include such things in the map.
References-found: 23

