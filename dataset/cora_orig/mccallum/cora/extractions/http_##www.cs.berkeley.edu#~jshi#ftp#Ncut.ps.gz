URL: http://www.cs.berkeley.edu/~jshi/ftp/Ncut.ps.gz
Refering-URL: http://elib.cs.berkeley.edu:8080/admin/quarterly_reports/report.97.html
Root-URL: 
Email: fjshi,malikg@cs.berkeley.edu  
Title: Normalized Cuts and Image Segmentation  
Author: Jianbo Shi and Jitendra Malik 
Address: Berkeley, Berkeley, CA 94720  
Affiliation: Computer Science Division University of California at  
Date: June 1997  
Note: Proc. of the IEEE Conf. on Comp. Vision and Pattern Recognition, San Juan, Puerto Rico,  
Abstract: We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H.D. Simon A. Pothen and K.P. Liou. </author> <title> Partitioning sparse matrices with eigenvectors of graphs. </title> <journal> SIAM Journal of Matrix Anal. Appl., </journal> <volume> 11 </volume> <pages> 430-452, </pages> <year> 1990. </year>
Reference-contexts: One can easily verify that z 0 = D 1 is an eigenvector of equation (7) with eigenvalue of 0. Furthermore, D 1 2 (D W)D 1 2 is symmetric semi-positive definite, since (D W), also called the Lapla-cian matrix, is known to be semi-positive definite <ref> [1] </ref>. Hence z 0 is in fact the smallest eigenvector of equation (7), and all eigenvectors of equation (7) are perpendicular to each other. In particular, z 1 the second smallest eigenvector is perpendicular to z 0 . <p> In fact the second smallest eigenvalue is called the Fiedler value, and corrsponding eigenvector the Fiedler vector. This spectral partitioning idea has been revived and further developed by several other researchers, and recently popularized by the work of <ref> [1] </ref>, particularly in the area of parallel scientific computing. In applications to several different areas, many authors have noted that the spectral partition method indeed provides good partitions of graphs [1]. <p> spectral partitioning idea has been revived and further developed by several other researchers, and recently popularized by the work of <ref> [1] </ref>, particularly in the area of parallel scientific computing. In applications to several different areas, many authors have noted that the spectral partition method indeed provides good partitions of graphs [1]. Most of the theoretical work done in this area has been focused on the connection between the ratio of cut and the Fiedler value.
Reference: [2] <author> Blake and Zisserman. </author> <title> Visual Reconstruction. </title> <publisher> The MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: The hierarchical divisive approach that we are advocating produces a tree, the dendrogram. While most of these ideas go back to the 70s (and earlier), the 1980s brought in the use of Markov Random Fields [7] and variational formulations <ref> [13, 2, 11] </ref>.
Reference: [3] <author> I.J. Cox, S.B. Rao, and Y. Zhong. </author> <title> Ratio regions: a technique for image segmentation. </title> <type> working paper, </type> <institution> NEC Research Institute, </institution> <year> 1996. </year>
Reference-contexts: Their algorithm is motivated by [10]'s paper on representing a hypergraph in a Euclidean Space. In the computer vision community, there are a few related approaches for image segmentation. Wu&Leahy [18] use the minimum cut criterion for their segmentation. Cox et.al. <ref> [3] </ref> seek to minimize the ratio cut (A;V A) weight (A) ; A V , where weight (A) is some function of the set A.
Reference: [4] <author> W.E. Donath and A.J. Hoffman. </author> <title> Lower bounds for the partitioning of graphs. </title> <journal> IBM Journal of Research and Development, </journal> <pages> pages 420-425, </pages> <year> 1973. </year>
Reference-contexts: Preliminary work in this direction may be found in [15]. 5 Related graph partition algorithms The idea of using eigenvalue problems for finding partitions of graphs originated in the work of Donath & Hoffman <ref> [4] </ref>, and Fiedler [6]. Fiedler suggested that the eigenvector with the second smallest eigenvalue of the system (D W)x = x could be used to split a graph. In fact the second smallest eigenvalue is called the Fiedler value, and corrsponding eigenvector the Fiedler vector.
Reference: [5] <author> R. Van Driessche and D. Roose. </author> <title> An improved spectral bisection algorithm and its application to dynamic load balancing. </title> <journal> Parallel Computing, </journal> <volume> 21 </volume> <pages> 29-48, </pages> <year> 1995. </year>
Reference-contexts: When we applied both techniques to the image segmentation problem, we found that the normalized cut produces better results in practice. The generalized eigenvalue approach was first applied to graph partitioning by <ref> [5] </ref> for dynamically balancing computational load in a parallel computer. Their algorithm is motivated by [10]'s paper on representing a hypergraph in a Euclidean Space. In the computer vision community, there are a few related approaches for image segmentation. Wu&Leahy [18] use the minimum cut criterion for their segmentation.
Reference: [6] <author> M. Fiedler. </author> <title> A property of eigenvectors of nonnegative symmetric matrices and its applications to graph theory. Czech. </title> <journal> Mathematical Journal, </journal> <volume> 25(100) </volume> <pages> 619-633, </pages> <year> 1975. </year>
Reference-contexts: Preliminary work in this direction may be found in [15]. 5 Related graph partition algorithms The idea of using eigenvalue problems for finding partitions of graphs originated in the work of Donath & Hoffman [4], and Fiedler <ref> [6] </ref>. Fiedler suggested that the eigenvector with the second smallest eigenvalue of the system (D W)x = x could be used to split a graph. In fact the second smallest eigenvalue is called the Fiedler value, and corrsponding eigenvector the Fiedler vector.
Reference: [7] <author> S. Geman and D. Geman. </author> <title> Stochastic relaxation, gibbs distributions, and the bayesian restoration of images. </title> <journal> PAMI, </journal> <volume> 6 </volume> <pages> 721-741, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: The hierarchical divisive approach that we are advocating produces a tree, the dendrogram. While most of these ideas go back to the 70s (and earlier), the 1980s brought in the use of Markov Random Fields <ref> [7] </ref> and variational formulations [13, 2, 11].
Reference: [8] <author> Golub and Van Loan. </author> <title> Matrix computations. </title> <publisher> John Hopkins Press, </publisher> <year> 1989. </year>
Reference-contexts: Note that the above expression is the Rayleigh quotient <ref> [8] </ref>. If y is relaxed to take on real values, we can minimize equation (5) by solving the generalized eigenvalue system, (D W)y = Dy: (6) However, we have two constraints on y, which come from the condition on the corresponding indicator vec tor x. <p> Translat ing this statement back into the general eigensystem (6), we have 1) y 0 = (0; 1) is the smallest eigenvector, and 2) 0 = z T 1 D1, where y 1 is the second smallest eigenvector of (6). Now recall a simple fact about the Rayleigh quotient <ref> [8] </ref>: Let A be a real symmetric matrix. <p> Lanczos algorithm is O (mn) + O (mM (n))<ref> [8] </ref>, where m is the maximum number of matrix-vector computations allowed, and M (n) is the cost of a matrix-vector computation. In the case where (D W) is sparse, matrix-vector takes only O (n) time. The number m depends on many factors [8]. In our experiments on image segmentations, m is typically less than O (n 1 Once the eigenvectors are computed, we can partition the graph into two pieces using the second smallest eigenvector.
Reference: [9] <author> A.K. Jain and R.C. Dubes. </author> <title> Algorithms for Clustering Data. </title> <publisher> Prentice Hall, </publisher> <year> 1988. </year>
Reference-contexts: The key point is that image partitioning is to be done from the big picture downwards, rather like a painter first marking out the major areas and then filling in the details. Prior literature on the related problems of clustering, grouping and image segmentation is huge. The clustering community <ref> [9] </ref> has offered us agglomerative and divisive algorithms; in image segmentation we have region-based merge and split algorithms. The hierarchical divisive approach that we are advocating produces a tree, the dendrogram.
Reference: [10] <author> K.Fukunaga, S. Yamada, H.S. Stone, and T. Kasai. </author> <title> A representationof hypergraphs in the euclidean space. </title> <journal> IEEE Trans. Comput., </journal> <volume> C-33:364-367, </volume> <month> April </month> <year> 1984. </year>
Reference: [11] <author> Y.G. Leclerc. </author> <title> Constructing simple stable descriptions for image partitioning. </title> <journal> International Journal of Computer Vision, </journal> <volume> 3 </volume> <pages> 73-102, </pages> <year> 1989. </year>
Reference-contexts: The hierarchical divisive approach that we are advocating produces a tree, the dendrogram. While most of these ideas go back to the 70s (and earlier), the 1980s brought in the use of Markov Random Fields [7] and variational formulations <ref> [13, 2, 11] </ref>.
Reference: [12] <author> J. Malik and P. Perona. </author> <title> Preattentive texture discrimination with early vision mechanisms. </title> <journal> Journal of Optical Society of America, </journal> <volume> 7(2) </volume> <pages> 923-932, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: s sin (h); v s cos (h)] (i), where h; s; v are the HSV values, for color segmentation, * F (i) = [jI fl f 1 j; :::; jI fl f n j] (i), where the f i are DOOG filters at various scales and orientations as used in <ref> [12] </ref>, in the case of texture segmentation. Note that the weight w ij = 0 for any pair of nodes i and j that are more than r pixels apart. We first tested our grouping algorithm on spatial point sets similar to the one shown in figure (2).
Reference: [13] <author> D. Mumford and J. Shah. </author> <title> Optimal approximations by piecewise smooth functions, and associated variational problems. </title> <journal> Comm. Pure Math., </journal> <pages> pages 577-684, </pages> <year> 1989. </year>
Reference-contexts: The hierarchical divisive approach that we are advocating produces a tree, the dendrogram. While most of these ideas go back to the 70s (and earlier), the 1980s brought in the use of Markov Random Fields [7] and variational formulations <ref> [13, 2, 11] </ref>.
Reference: [14] <author> S. Sarkar and K.L. Boyer. </author> <title> Quantitative measures of change based on feature organization: Eigenvalues and eigenvec-tors. </title> <booktitle> In CVPR 96, </booktitle> <year> 1996. </year>
Reference-contexts: Cox et. al. use an efficient discrete algorithm to solve their optimization problem assuming the graph is planar. Sarkar & Boyer <ref> [14] </ref> use the eigenvector with the largest eigenvalue of the system Wx = x for finding the most coherent region in an edge map.
Reference: [15] <author> J. Shi and J. Malik. </author> <title> Normalized cuts and image segmentation. </title> <type> Technical Report CSD-97-940, </type> <institution> UC Berkeley, </institution> <year> 1997. </year>
Reference-contexts: Clearly these can be combined, as also a show the major components of the partition. The texture features used corresponde to convolutions with DOOG filters at 6 orientations and 5 scales. with disparity and motion infomation. Preliminary work in this direction may be found in <ref> [15] </ref>. 5 Related graph partition algorithms The idea of using eigenvalue problems for finding partitions of graphs originated in the work of Donath & Hoffman [4], and Fiedler [6].
Reference: [16] <author> D.A. Spielman and S.H. Teng. </author> <title> Disk packings and planar separators. </title> <booktitle> In Proceedings of 12th ACM Symposium on Computational Geometry, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: A ratio of cut of a partition of V , P = (A; V A) is defined as cut (A;V A) shown that if the Fiedler value is small, partitioning graph based on the Fiedler vector will lead to good ratio of cut <ref> [16] </ref>.
Reference: [17] <author> M. Wertheimer. </author> <title> Laws of organization in perceptual forms(partial translation). </title> <editor> In W.B. Ellis, editor, </editor> <booktitle> A Source-book of Gestalt Psycychology, </booktitle> <pages> pages 71-88. </pages> <publisher> Harcourt, Brace and Company, </publisher> <year> 1938. </year>
Reference-contexts: 1 Introduction Nearly 75 years ago, Wertheimer <ref> [17] </ref> launched the Gestalt approach which laid out the importance of perceptual grouping and organization in visual perception. For our purposes, the problem of grouping can be well motivated by considering the set of points shown in the figure (1).
Reference: [18] <author> Z. Wu and R. Leahy. </author> <title> An optimal graph theoretic approach to data clustering: Theory and its application to image segmentation. </title> <journal> PAMI, </journal> <volume> 11 </volume> <pages> 1101-1113, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: Although there are exponential number of such partitions, finding the minimum cut of a graph is a well studied problem, and there exist efficient algorithms for solving it. Wu and Leahy <ref> [18] </ref> proposed a clustering method based on this minimum cut criterion. In particular, they seek to partition a graph into k-subgraphs, such that the maximum cut across the subgroups is minimized. This problem can be efficiently solved by recursively finding the minimum cuts that bisect the existing segments. <p> Their algorithm is motivated by [10]'s paper on representing a hypergraph in a Euclidean Space. In the computer vision community, there are a few related approaches for image segmentation. Wu&Leahy <ref> [18] </ref> use the minimum cut criterion for their segmentation. Cox et.al. [3] seek to minimize the ratio cut (A;V A) weight (A) ; A V , where weight (A) is some function of the set A.
References-found: 18

