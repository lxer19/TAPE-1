URL: http://rakaposhi.eas.asu.edu/crc-chapter.ps
Refering-URL: http://rakaposhi.eas.asu.edu/yochan.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Planning and Scheduling  
Author: Thomas Dean, Brown 
Affiliation: University Subbarao Kambhampati, Arizona State University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Allen, J. F., Kautz, H. A., Pelavin, R. N., and Tenenberg, J. D., </author> <title> Reasoning about Plans, </title> <publisher> (Morgan-Kaufmann, </publisher> <address> San Francisco, California, </address> <year> 1991). </year>
Reference-contexts: The above descriptions of dynamical systems provide the semantics for a planning system embedded in a dynamic environment. There remains the question of syntax: specifically, how do you represent the dynamical system? In artificial intelligence, the answer varies widely. Researchers have used first-order logic <ref> [1] </ref>, dynamic logic [34], state-space operators [13], and factored probabilistic state-transition functions [9]. In the later sections, we examine some of these representations in more detail. In some variants of job-shop scheduling the dynamics are relatively simple.
Reference: [2] <editor> Allen, James F., Hendler, James, and Tate, Austin, (Eds.), </editor> <booktitle> Readings in Planning, </booktitle> <publisher> (Morgan Kaufmann, </publisher> <address> San Francisco, California, </address> <year> 1990). </year>
Reference: [3] <author> Backstrom, C. and Klein, I., </author> <title> Parallel Non-Binary Planning in Polynomial Time, </title> <booktitle> Proceedings IJCAI 12, </booktitle> <address> Sydney, Australia, IJCAII, </address> <year> 1991, </year> <pages> 268-273. </pages>
Reference-contexts: Dean and Boddy [8] show that the problem of evaluating plans represented as sets of partially ordered actions is NP-hard in all but the simplest cases. Backstrom and Klein <ref> [3] </ref> provide some examples of easy 10 (polynomial time) planning problems, but these problems are of marginal practical interest. Regarding closed-loop, deterministic planning, Papadimitriou and Tsitsiklis [29] discuss polynomial-time algorithms for finding an optimal conditional plan for a variety of performance functions.
Reference: [4] <author> Bylander, Tom, </author> <title> Complexity Results for Planning, </title> <booktitle> Proceedings IJCAI 12, </booktitle> <address> Sydney, Aus-tralia, IJCAII, </address> <year> 1991, </year> <pages> 274-279. 34 </pages>
Reference-contexts: Lawler et al. [26] survey results for the traveling salesperson problem, a special case of our travel planning problem. Here again the prospects for optimal, exact algorithms are not good, but there is some hope for approximate algorithms. With regard to open-loop, deterministic planning, Chapman [5], Bylander <ref> [4] </ref>, and Gupta and Nau [18] have shown that most problems in this general class are hard. Dean and Boddy [8] show that the problem of evaluating plans represented as sets of partially ordered actions is NP-hard in all but the simplest cases.
Reference: [5] <author> Chapman, David, </author> <title> Planning for Conjunctive Goals, </title> <journal> Artificial Intelligence, </journal> <note> 32 (1987) 333--377. </note>
Reference-contexts: Lawler et al. [26] survey results for the traveling salesperson problem, a special case of our travel planning problem. Here again the prospects for optimal, exact algorithms are not good, but there is some hope for approximate algorithms. With regard to open-loop, deterministic planning, Chapman <ref> [5] </ref>, Bylander [4], and Gupta and Nau [18] have shown that most problems in this general class are hard. Dean and Boddy [8] show that the problem of evaluating plans represented as sets of partially ordered actions is NP-hard in all but the simplest cases.
Reference: [6] <author> Dagum, P., Karp, R., Luby, M., and Ross, Sheldon M., </author> <title> An Optimal Stopping Rule for Monte Carlo Estimation, </title> <booktitle> Proceedings of the 1995 Symposium on the Foundations of Computer Science, </booktitle> <year> 1995. </year>
Reference-contexts: Return J K () = S=T The above algorithm terminates after generating E [T ] samples, where E [T ] 4 log (2=ffi)(1 + *) J K ()* 2 so that the entire algorithm for approximating J 1 () runs in expected time polynomial in 1=ffi, 1=*, 1=(1 fl) (see <ref> [6] </ref> for a detailed analysis). Approximating J 1 () is only one possible step in an algorithm for computing an optimal or near-optimal plan. In most iterative repair-based algorithms, the algorithm evaluates the current policy and then tries to improve it on each iteration.
Reference: [7] <author> Dean, Thomas, Allen, James, and Aloimonos, Yiannis, </author> <booktitle> Artificial Intelligence: Theory and Practice, </booktitle> <publisher> (Benjamin/Cummings Publishing Company, </publisher> <address> Redwood City, California, </address> <year> 1995). </year>
Reference: [8] <author> Dean, Thomas and Boddy, Mark, </author> <title> Reasoning About Partially Ordered Events, </title> <journal> Artificial Intelligence, </journal> <month> 36(3) </month> <year> (1988) </year> <month> 375-399. </month>
Reference-contexts: Here again the prospects for optimal, exact algorithms are not good, but there is some hope for approximate algorithms. With regard to open-loop, deterministic planning, Chapman [5], Bylander [4], and Gupta and Nau [18] have shown that most problems in this general class are hard. Dean and Boddy <ref> [8] </ref> show that the problem of evaluating plans represented as sets of partially ordered actions is NP-hard in all but the simplest cases. Backstrom and Klein [3] provide some examples of easy 10 (polynomial time) planning problems, but these problems are of marginal practical interest.
Reference: [9] <author> Dean, Thomas and Kanazawa, Keiji, </author> <title> A Model for Reasoning About Persistence and Causation, </title> <booktitle> Computational Intelligence, </booktitle> <month> 5(3) </month> <year> (1989) </year> <month> 142-150. </month>
Reference-contexts: There remains the question of syntax: specifically, how do you represent the dynamical system? In artificial intelligence, the answer varies widely. Researchers have used first-order logic [1], dynamic logic [34], state-space operators [13], and factored probabilistic state-transition functions <ref> [9] </ref>. In the later sections, we examine some of these representations in more detail. In some variants of job-shop scheduling the dynamics are relatively simple.
Reference: [10] <author> Dean, Thomas and Wellman, Michael, </author> <title> Planning and Control, </title> <publisher> (Morgan Kaufmann, </publisher> <address> San Francisco, California, </address> <year> 1991). </year>
Reference: [11] <author> Etzioni, Oren, Hanks, Steve, Weld, Daniel, Draper, Denise, Lesh, Neal, and Williamson, Mike, </author> <title> An Approach to Planning with Incomplete Information, </title> <booktitle> Proceedings of the 1992 International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <year> 1992. </year>
Reference-contexts: These operators have preconditions and postconditions similar to other operators, but some of the postconditions, those corresponding to the consequences of information gathering, are nondeterministic; we will not know the actual value of these postconditions until after we have executed the action <ref> [11] </ref>. The approach to conditional planning sketched above theoretically extends to arbitrary sources of uncertainty, but in practice search has to be limited to consider only outcomes that are likely to have a significant impact on performance.
Reference: [12] <author> Fiechter, Claude-Nicolas, </author> <title> Efficient Reinforcement Learning, </title> <booktitle> Proceedings of the Seventh Annual ACM Conference on Computational Learning Theory, </booktitle> <year> 1994, </year> <pages> 88-97. </pages>
Reference-contexts: Let be any plan, J 1 () = J (j0) be the performance of accounting for an infinite sequence of state transitions, and J K () the performance of accounting for only K state transitions. We can bound the difference between these two measures of performance as follows (see <ref> [12] </ref> for a proof ). jJ 1 () J K ()j fl K C max =(1 fl) The above result implies that if we are willing to sacrifice a (maximum) error of fl K C max =(1 fl) in measuring the performance of plans, we need only concern ourselves with histories
Reference: [13] <author> Fikes, Richard and Nilsson, Nils J., </author> <title> STRIPS: A new approach to the application of theorem proving to problem solving, </title> <journal> Artificial Intelligence, </journal> <month> 2 </month> <year> (1971) </year> <month> 189-208. </month>
Reference-contexts: There remains the question of syntax: specifically, how do you represent the dynamical system? In artificial intelligence, the answer varies widely. Researchers have used first-order logic [1], dynamic logic [34], state-space operators <ref> [13] </ref>, and factored probabilistic state-transition functions [9]. In the later sections, we examine some of these representations in more detail. In some variants of job-shop scheduling the dynamics are relatively simple.
Reference: [14] <author> Garey, Michael R. and Johnson, David S., </author> <title> Computers and Intractibility: A Guide to the Theory of NP-Completeness, </title> <editor> (W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979). </year>
Reference-contexts: Our discussion begins with a quick survey of what is known about the complexity of planning and scheduling problems. 3.1 Complexity Results Garey and Johnson <ref> [14] </ref> provide an extensive listing of NP-hard problems, including a great many scheduling problems. They also provide numerous examples of how a hard problem can be rendered easy by relaxing certain assumptions. For example, most variants of job-shop scheduling are NP-hard.
Reference: [15] <author> Georgeff, Michael P., </author> <title> Planning, </title> <editor> Traub, J. F., (Ed.), </editor> <booktitle> Annual Review of Computer Science, Volume 2, (Annual Review Incorporated, </booktitle> <year> 1987). </year> <month> 35 </month>
Reference: [16] <author> Ginsberg, Matthew L. and McAllester, David, </author> <title> GSAT and Dynamic Backtracking, </title> <booktitle> Pro--ceedings of the 1994 International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <address> Bonn, Germany, </address> <year> 1994. </year>
Reference-contexts: Iterative methods do not have this problem since they do not do any bookkeeping about the current state of the search. Recent work on partial order dynamic backtracking algorithms <ref> [16] </ref> provides an elegant way of keeping both systematicity and freedom of movement. 3.4 Improving Efficiency While the previous sections surveyed the methods used to organize the search for plans and discussed their relative advantages, as observed in Section 3.1, most planning problems are computationally hard.
Reference: [17] <author> Graham, R. L., Lawler, E. L., Lenstra, J. K., and Rinnooy Kan, A. H. G., </author> <title> Optimization and Approximation in Deterministic Sequencing and Scheduling: A Survey, </title> <booktitle> Proceedings Discrete Optimization, </booktitle> <address> Vancouver, British Columbia, </address> <year> 1977. </year>
Reference-contexts: With this assumption, some hard problems become easy. Unfortunately, most real scheduling problems are NP-hard. Graham et al. <ref> [17] </ref> provide a somewhat more comprehensive survey of scheduling problems with a similarly dismal conclusion. Lawler et al. [26] survey results for the traveling salesperson problem, a special case of our travel planning problem.
Reference: [18] <author> Gupta, Naresh and Nau, Dana S., </author> <title> Complexity Results for Blocks-World Planning, </title> <booktitle> Proceedings AAAI-91, </booktitle> <address> Anaheim, California, </address> <publisher> AAAI, </publisher> <year> 1991, </year> <pages> 629-633. </pages>
Reference-contexts: Here again the prospects for optimal, exact algorithms are not good, but there is some hope for approximate algorithms. With regard to open-loop, deterministic planning, Chapman [5], Bylander [4], and Gupta and Nau <ref> [18] </ref> have shown that most problems in this general class are hard. Dean and Boddy [8] show that the problem of evaluating plans represented as sets of partially ordered actions is NP-hard in all but the simplest cases.
Reference: [19] <author> Hammond, Kristian J., </author> <title> Case-Based Planning, </title> <publisher> (Academic Press, </publisher> <address> New York, </address> <year> 1989). </year>
Reference-contexts: This explanation can then be used to focus the repair activity <ref> [35, 19] </ref>. <p> We briefly survey some of these methods below. One of the simplest ways of improving performance over time involves "caching" plans for frequently occurring problems and subproblems, and reusing them in subsequent planning scenarios. This approach is called case-based planning (scheduling) <ref> [19, 22] </ref> and is motivated by similar considerations to those motivating task-reduction refinements. In storing a previous planning experience, we have two choices: store the final plan, or store the plan along with the search decisions that lead to the plan.
Reference: [20] <author> Hendler, James, Tate, Austin, and Drummond, Mark, </author> <title> AI Planning: Systems and techniques, </title> <journal> AI Magazine, </journal> <month> 11(2) </month> <year> (1990) </year> <month> 61-77. </month>
Reference: [21] <author> Kambhampati, Subbarao, </author> <title> A comparative analysis of partial-order planning and task-reduction planning, </title> <journal> ACM SIGART Bulletin, </journal> <month> 6(1) </month> <year> (1995). </year>
Reference-contexts: Finally, if the operator ff 4 is a non-primitive operator, we can also use task reduction refinement to replace ff 4 with its reduction schema. There is some evidence that planners using multiple refinement strategies intelligently can outperform those using single refinement strategies <ref> [21] </ref>. However, the question as to which refinement strategy should be preferred when is still largely open.
Reference: [22] <author> Kambhampati, Subbarao and Hendler, James, </author> <title> A Validation Structure Based Theory of Plan Modification and Reuse, </title> <journal> Artificial Intelligence, </journal> <month> 55(2-3) </month> <year> (1992) </year> <month> 193-258. </month>
Reference-contexts: We briefly survey some of these methods below. One of the simplest ways of improving performance over time involves "caching" plans for frequently occurring problems and subproblems, and reusing them in subsequent planning scenarios. This approach is called case-based planning (scheduling) <ref> [19, 22] </ref> and is motivated by similar considerations to those motivating task-reduction refinements. In storing a previous planning experience, we have two choices: store the final plan, or store the plan along with the search decisions that lead to the plan.
Reference: [23] <author> Kambhampati, Subbarao, Knoblock, Craig, and Yang, Qiang, </author> <title> Refinement Search as a unifying framework for evaluating design tradeoffs in partial order planning, </title> <journal> Artificial Intelligence, </journal> <year> (1995). </year>
Reference-contexts: We define a generic refinement procedure, Refine (), as follows <ref> [23] </ref>. 1.
Reference: [24] <author> Kirkpatrick, S., Gelatt, C. D., and Vecchi, M. P., </author> <title> Optimization by Simulated Annealing, </title> <booktitle> Science, </booktitle> <month> 220 </month> <year> (1983) </year> <month> 671-680. </month>
Reference-contexts: In many cases, these local extrema correspond to very poor solutions. To improve performance and reduce the risk of becoming stuck in local extrema corresponding to badly suboptimal solutions, some schedulers employ stochastic techniques that occasionally choose to make repairs other than those suggested by their heuristics. Simulated annealing <ref> [24] </ref> is one example of a stochastic search method used to escape local extrema in scheduling. In simulated annealing, there is a certain probability that the scheduler will choose a repair other than the one suggested by the scheduler's heuristics.
Reference: [25] <author> Kushmerick, Nicholas, Hanks, Steve, and Weld, Daniel, </author> <title> An Algorithm for Probabilistic Planning, </title> <booktitle> Proceedings AAAI-94, </booktitle> <address> Seattle, Washington, </address> <publisher> AAAI, </publisher> <year> 1994. </year>
Reference-contexts: For more on planning in stochastic domains using probabilistic state space operators, see <ref> [25] </ref>. There are well known methods for computing an optimal plan for the problem described above [33]. Most of these methods proceed using iterative repair-based methods that work by improving an existing plan using the computed function J (ji).
Reference: [26] <author> Lawler, E.L., Lenstra, J.K., Rinnooy Kan, A.H.G., and Shmoys, </author> <title> D.B., The Travelling Salesman Problem, </title> <publisher> (Wiley, </publisher> <address> New York, </address> <year> 1985). </year>
Reference-contexts: With this assumption, some hard problems become easy. Unfortunately, most real scheduling problems are NP-hard. Graham et al. [17] provide a somewhat more comprehensive survey of scheduling problems with a similarly dismal conclusion. Lawler et al. <ref> [26] </ref> survey results for the traveling salesperson problem, a special case of our travel planning problem. Here again the prospects for optimal, exact algorithms are not good, but there is some hope for approximate algorithms.
Reference: [27] <author> Lin, S. and Kernighan, B. W., </author> <title> An Effective Heuristic for the Travelling Salesman Problem, </title> <journal> Operations Research, </journal> <volume> 21 (1973) 498-516. </volume> <pages> 36 </pages>
Reference-contexts: Continue to make repairs in this manner until no improvement (reduction 27 in the length of the resulting tour) is possible. Lin and Kernighan's algorithm <ref> [27] </ref> which is based on this local repair method generates solutions that are within 10% of the length of the optimal tour on a large class of practical problems.
Reference: [28] <author> Minton, Steve, (Ed.), </author> <title> Machine Learning Methods for Planning and Scheduling, </title> <publisher> (Morgan Kaufmann, </publisher> <address> San Francisco, California, </address> <year> 1992). </year>
Reference-contexts: By analyzing the search failures and using explanation-based learning techniques, it is possible to learn search control rules that, for example, can be used to advise a planner as to which refinement or repair to pursue under what circumstances. For more about the connections between planning and learning see <ref> [28] </ref>. 3.5 Approximation in Stochastic Domains In this section, we consider a planning problem involving stochastic dynamics.
Reference: [29] <author> Papadimitriou, Christos H. and Tsitsiklis, John N., </author> <title> The Complexity of Markov Chain Decision Processes, </title> <institution> Mathematics of Operations Research, </institution> <month> 12(3) </month> <year> (1987) </year> <month> 441-450. </month>
Reference-contexts: Backstrom and Klein [3] provide some examples of easy 10 (polynomial time) planning problems, but these problems are of marginal practical interest. Regarding closed-loop, deterministic planning, Papadimitriou and Tsitsiklis <ref> [29] </ref> discuss polynomial-time algorithms for finding an optimal conditional plan for a variety of performance functions. Unfortunately, the polynomial is in the size of the state space. As mentioned earlier, we assume that the size of the state space is exponential in the number of state variables.
Reference: [30] <author> Pednault, Edwin P. D., </author> <title> Synthesizing Plans that Contain Actions with Context-Dependent Effects, </title> <booktitle> Computational Intelligence, </booktitle> <month> 4(4) </month> <year> (1988) </year> <month> 356-372. </month>
Reference-contexts: This can be done by posting R as a precondition of Step 3. Since R is not a normal precondition of ff 3 , and is being posted only to guarantee one of its conditional effects, it is called a secondary precondition <ref> [30] </ref>. Now that we have introduced Step 3 and ensured that it produces Q as a postcondition, we need to make sure that Q is not violated by any steps possibly intervening between Steps 3 and 2. This phase of plan-space refinement is called arbitration.
Reference: [31] <author> Penberthy, J. S. and Weld, Daniel S., UCPOP: </author> <title> A Sound, Complete, Partial Order Planner for ADL, </title> <booktitle> Proceedings of the 1992 International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <year> 1992, </year> <pages> 103-114. </pages>
Reference: [32] <author> Peot, Mark and Shachter, Ross, </author> <title> Fusion and Propagation with Multiple Observations in Belief Networks, </title> <journal> Artificial Intelligence, </journal> <month> 48(3) </month> <year> (1991) </year> <month> 299-318. </month>
Reference-contexts: There exist methods for extending refinement strategies so that instead of working on K unconditional 22 plans with significant overlap, a single, multi-threaded conditional plan is generated <ref> [32] </ref>. Conditional planning can be very expensive in situations in which the unspecified variable has a large set of possible values or there are several unspecified variables.
Reference: [33] <author> Puterman, Martin L., </author> <title> Markov Decision Processes, </title> <publisher> (John Wiley & Sons, </publisher> <address> New York, </address> <year> 1994). </year>
Reference-contexts: For more on planning in stochastic domains using probabilistic state space operators, see [25]. There are well known methods for computing an optimal plan for the problem described above <ref> [33] </ref>. Most of these methods proceed using iterative repair-based methods that work by improving an existing plan using the computed function J (ji). On each iteration, we end up with a new plan 0 and must calculate J ( 0 ji) for all i.
Reference: [34] <author> Rosenschein, Stan, </author> <title> Plan Synthesis: A Logical Perspective, </title> <booktitle> Proceedings IJCAI 7, </booktitle> <address> IJCAII, </address> <year> 1981, </year> <pages> 331-337. </pages>
Reference-contexts: The above descriptions of dynamical systems provide the semantics for a planning system embedded in a dynamic environment. There remains the question of syntax: specifically, how do you represent the dynamical system? In artificial intelligence, the answer varies widely. Researchers have used first-order logic [1], dynamic logic <ref> [34] </ref>, state-space operators [13], and factored probabilistic state-transition functions [9]. In the later sections, we examine some of these representations in more detail. In some variants of job-shop scheduling the dynamics are relatively simple.
Reference: [35] <author> Simmons, Reid and Davis, Randall, </author> <title> Generate, Test and Debug: Combining Associational Rules and Causal Models, </title> <booktitle> Proceedings IJCAI 10, </booktitle> <address> Milan, Italy, IJCAII, </address> <year> 1987, </year> <pages> 1071-1078. </pages>
Reference-contexts: This explanation can then be used to focus the repair activity <ref> [35, 19] </ref>.
Reference: [36] <author> Tsang, Edward, </author> <title> Foundations of Constraint Satisfaction, </title> <publisher> (Academic Press, </publisher> <address> San Diego, California, </address> <year> 1993). </year>
Reference-contexts: A schedule is then represented as an assignment of values to all of the variables that satisfies all the constraints. The resulting formulation of scheduling problems is called a constraint satisfaction problem <ref> [36] </ref>. <p> Other ways of improving search efficiency include using look ahead techniques to prune inconsistent partial 26 assignments ahead of time, to process the domains of the remaining variables so that any infeasible values are removed, or using dependency directed backtracking techniques to recover from inconsistent partial assignments intelligently. See <ref> [36] </ref> for a description of these techniques and their tradeoffs.

References-found: 36

