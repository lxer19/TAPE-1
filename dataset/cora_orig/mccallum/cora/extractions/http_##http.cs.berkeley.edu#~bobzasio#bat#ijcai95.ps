URL: http://http.cs.berkeley.edu/~bobzasio/bat/ijcai95.ps
Refering-URL: http://http.cs.berkeley.edu/~bobzasio/bat/
Root-URL: 
Title: The BATmobile: Towards a Bayesian Automated Taxi  
Author: Jeff Forbes, Tim Huang, Keiji Kanazawa, Stuart Russell 
Keyword: Robotic systems (unmanned vehicles);  Keywords: Intelligent vehicle, uncertainty, Bayesian network, partially observable Markov decision process.  
Note: Areas: Reasoning under uncertainty (probability);  Planning and reasoning about action (planning under uncertainty).  
Address: Berkeley, CA 94720, USA  
Affiliation: Computer Science Division University of California  
Email: jforbes,tthuang,kanazawa,russell@cs.berkeley.edu  
Phone: Tel: (510) 642-4964, Fax: (510) 642-5775  
Abstract: The problem of driving an autonomous vehicle in normal traffic engages many areas of AI research and has substantial economic significance. We describe a new approach to this problem based on a decision-theoretic architecture using dynamic probabilistic networks. The architecture provides a sound solution to the problems of sensor noise, sensor failure, and uncertainty about the behavior of other vehicles and about the effects of one's own actions. We report on several advances in the theory and practice of inference and decision making in dynamic, partially observable domains. Our approach has been implemented in a simulation system, and the autonomous vehicle successfully negotiates a variety of difficult situations. Multiple submissions: This paper has not already been accepted by and is not currently under review for a journal or another conference. Nor will it be submitted for such during IJCAI's review period. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Dean, T. and Kanazawa, K. </author> <year> (1988). </year> <title> Probabilistic temporal reasoning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence (AAAI-88), </booktitle> <pages> pages 524-528. </pages> <booktitle> American Association for Artificial Intelligence. </booktitle>
Reference-contexts: The extension to continuous variables is straightforward, and stochastic sampling provides a simple way to perform inference with such variables. DPNs allow for reasoning in domains where variables take on different values over time <ref> (Dean and Kanazawa, 1988) </ref>. Figure 2 shows the general structure of a DPN. Typically, observations are taken at regular `time slices,' and a given network structure is replicated for each slice.
Reference: <author> Dickmanns, E. D. and Zapp, A. </author> <year> (1987). </year> <title> Autonomous high speed road vehicle guidance by computer vision. </title> <editor> In Isermann, R., editor, </editor> <booktitle> Automatic ControlWorld Congress, 1987: Selected Papers from the 10th Triennial World Congress of the International Federation of Automatic Control, </booktitle> <pages> pages 221-226, </pages> <address> Munich. </address> <publisher> Pergamon. </publisher>
Reference: <author> Huang, T., Koller, D., Malik, J., Ogasawara, G., Rao, B., Russell, S., and Weber, J. </author> <year> (1994). </year> <title> Automatic symbolic traffic scene analysis using belief networks. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), </booktitle> <address> Seattle, Washington. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: This is either a disadvantage or an advantage, depending on one's viewpoint. Because the necessary low-level capabilities such as visual vehicle monitoring <ref> (Huang et al., 1994) </ref> 1 and lane-following (Dickmanns and Zapp, 1987; Pomerleau, 1993) are reaching maturity, we have decided to confront this challenge.
Reference: <author> Kjaerulff, U. </author> <year> (1992). </year> <title> A computational scheme for reasoning in dynamic probabilistic networks. </title> <booktitle> In Proceedings of the Eighth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 121-129. </pages>
Reference-contexts: By rolling up the network in this fashion, evidence accumulated over time is always integrated into the current probabilistic network model <ref> (Kjaerulff, 1992) </ref>. In general, the current time slice along with the current percepts completely determines the current belief state. Clearly, real-time temporal inference requires efficient rollup. Any method for rolling up one slice of a network is equivalent to performing a sequence of node eliminations (Kjaerulff, 1992). <p> the current probabilistic network model <ref> (Kjaerulff, 1992) </ref>. In general, the current time slice along with the current percepts completely determines the current belief state. Clearly, real-time temporal inference requires efficient rollup. Any method for rolling up one slice of a network is equivalent to performing a sequence of node eliminations (Kjaerulff, 1992). Node elimination may introduce additional links into the network; thus the network structure may change as a result of rollup. This complicates maintaining the belief state in three ways. First, different node elimination sequences can result in drastically different connectivity in the resulting networks.
Reference: <author> Lehner, P. E. and Sadigh, A. </author> <year> (1993). </year> <title> Two procedures for compiling influence diagrams. </title> <booktitle> In Proceedings of the Ninth Conference on Uncertainty in Artificial Intelligence (UAI-93), </booktitle> <address> Washington, D. C. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Each leaf of the tree is a decision. This obviously yields an effective, real-time policy, but constructing the decision tree is a difficult task. Other researchers, for example Lehner and Sadigh <ref> (Lehner and Sadigh, 1993) </ref>, have examined the creation of decision trees from influence diagrams, but only for static problems. In such cases, the decision tree nodes test fully determined evidence variables. If this method is applied to dynamic problems, one may be forced to test the entire percept sequence.
Reference: <author> Niehaus, A. and Stengel, R. F. </author> <year> (1991). </year> <title> Rule-based guidance for vehicle highway driving in the presence of uncertainty. </title> <booktitle> In Proceedings of the 1991 American Control Conference, </booktitle> <volume> volume 3, </volume> <pages> pages 3119-24, </pages> <address> Boston, Massachusetts. </address>
Reference-contexts: One exception is the work of Niehaus and Sten-gel <ref> (Niehaus and Stengel, 1991) </ref>, who have recently incorporated a somewhat ad hoc form of probabilistic reasoning into their rule-based driving controller. Since their system assumes worst-case outcomes in looking ahead, and does not integrate 2 percepts over time in assessing the current state, its performance is limited.
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California. </address>
Reference-contexts: Probabilistic networks are directed acyclic graphs in which nodes represent random variables (typically discrete) and arcs represent causal connections among the variables <ref> (Pearl, 1988) </ref>. Associated with each node is a CPT (conditional probability table) that provides conditional probabilities of the node's possible states given each possible state of its parents (or the prior probabilities if the node has no parents). Probabilistic networks offer a mathematically sound basis for making inferences under uncertainty. <p> When specific values are observed for some of the nodes in a probabilistic network, posterior probability distributions can be computed efficiently for any of the other nodes using a variety of inference algorithms <ref> (Pearl, 1988) </ref>. The extension to continuous variables is straightforward, and stochastic sampling provides a simple way to perform inference with such variables. DPNs allow for reasoning in domains where variables take on different values over time (Dean and Kanazawa, 1988). Figure 2 shows the general structure of a DPN.
Reference: <author> Pomerleau, D. A. </author> <year> (1993). </year> <title> Neural Network Perception for Mobile Robot Guidance. </title> <publisher> Kluwer, </publisher> <address> Dordrecht, The Netherlands. </address>
Reference: <author> Russell, S. J., Binder, J., and Koller, D. </author> <year> (1994). </year> <title> Adaptive probabilistic networks. </title> <type> Technical Report UCB/CSD-94-824, </type> <institution> Computer Science Division, University of California at Berkeley. </institution>
Reference: <author> Tatman, J. A. and Shachter, R. D. </author> <year> (1990). </year> <title> Dynamic programming and influence diagrams. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 20(2) </volume> <pages> 365-379. 15 </pages>
Reference-contexts: Instead, we enforce the convention that a decision at time t is made with all evidence 9 gained up to and including time t, and we identify a particular set of the chance nodes as evidence nodes that will be instantiated at each time step. Tatman and Shachter <ref> (Tatman and Shachter, 1990) </ref> provide an algorithm for computing the policy for a DDN. In the case of driving, which is a partially observable problem, only a subset of the variables in a given time slice will be instantiated as evidence.
References-found: 10

