URL: ftp://ftp.cis.ufl.edu/cis/tech-reports/tr93/tr93-017.ps
Refering-URL: http://www.cis.ufl.edu/tech-reports/tech-reports/tr93-abstracts.html
Root-URL: http://www.cis.ufl.edu
Title: Interruptible Critical Sections for Real-time Systems  
Author: Theodore Johnson 
Affiliation: Dept. of Computer and Information Science University of Florida  
Abstract: In this paper, we present a new approach to synchronization in real-time systems. Existing methods for synchronization in real-time systems are pessimistic, and use blocking to enforce concurrency control. Protocols such as the priority ceiling protocol have been proposed to reduce the priority inversion that occurs when low priority tasks block high priority tasks. However, the priority ceiling protocol still allows a low priority task to block a high priority task, and requires the use of a static-priority scheduler. We propose optimistic synchronization methods as an alternative to pessimistic synchronization methods. Our synchronization algorithms never allow a low priority task to block a high priority task, and can be used with dynamic-priority schedulers. We show how the current research in non-blocking concurrent objects and in low-overhead uniprocessor synchronization can be synthesized to implement low-overhead optimistic synchronization.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T.E. Anderson, B.N. Bershad, E.D. Lazowska, and H.M. Levy. </author> <title> Scheduler activations: Effective kernel support for the user-level management of parallelism. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 10(1) </volume> <pages> 53-79, </pages> <year> 1992. </year>
Reference-contexts: We note that the idea of kernel support for critical sections is well established. In 4.3BSD UNIX, a system call that is interrupted by a signal is restarted using the longjump instruction [13]. Anderson et al. <ref> [1] </ref> argue that the operaing system support for parallel threads should recognize that a pre-empted thread is executing in a critical section, and execute the pre-empted thread until the thread exits the critical section.
Reference: [2] <author> T.P. Baker. </author> <title> A stack-based resource allocation policy for realtime processes. </title> <booktitle> In Real Time Systems Symposium, </booktitle> <pages> pages 191-200, </pages> <year> 1990. </year>
Reference-contexts: In addition, blocking for even the duration of one critical section may be excessive. Rajkumar, Sha, and Lehoczky have extended the Priority Inheritance Protocol to work in a multiprocessor system [18]. Blocking-based synchronization algorithms have been extended to work with dynamic-priority schedulers. Baker <ref> [2] </ref> presents a pre-allocation based synchronization algorithm that can manages resources with multiple instances. A task's execution is delayed until the scheduler can guarantee that the task can execute without 1 blocking a higher priority task. <p> Second, dynamic-priority scheduling algorithms are feasible with much higher CPU utilizations than static-priority scheduling algorithms [7], and dynamic-priority schedulers mught be required for aperiodic tasks. The simple Priority Inheritance Protocol of Rajkumar, Sha, and Lehoczky [19] can be applied to static-priority schedulers only. The dynamic-priority synchronization protocols <ref> [5, 6, 2] </ref> are complex, and must be closely integrated with the scheduling algorithm. In this paper, we present a different approach to synchronization, one which guarantees that a high-priority task never waits for a low-priority task at a critical section. <p> An ICS cannot be directly used to reserve access to a resource. The code that reserves a resource can be protected by an ICS, but contention for the resource might cause blocking, and thus priority inversion. A blocking-based protocol (such as those in <ref> [19, 2, 6] </ref>) should be applied in this instance. Alternatively, resources can be pre-allocated, or enough resources supplied to the system to ensure that no process will block. Similarly, an ICS cannot be used to ensure exclusive access to a device. <p> commit record [instruction].lhs != NULL) *(commit record [instruction].lhs)=commit record [instruction].rhs valid=FALSE calculate modifications load modifications into commit record valid=true g For example, the following code can implement a double linked list: struct list elemf data item; struct list elem *forward,*backward; g *head; struct commit record elementf word *lhs,rhsg commit record <ref> [2] </ref> boolean valid insert (elem) list elem *elem list elem *prev,*next restartablef if (valid) instruction=0 while (instruction&lt;2 and commit record [instruction].lhs != NULL) 10 *(commit record [instruction].lhs)=commit record [instruction].rhs valid=FALSE prev=NULL; next=head while (not found position (next)) prev=next next=next! forward // Found the insertion point elem!forward=next elem!backward=prev if (prev==NULL) commit record
Reference: [3] <author> B.N. Bershad, D.D. Redell, and J.R. Ellis. </author> <title> Fast mutual exclusion for uniprocessors. </title> <booktitle> In 5th Intl. Conference on ASPLOS, </booktitle> <pages> pages 223-232, </pages> <year> 1992. </year>
Reference-contexts: Though high priority operations are never blocked, low priority operations can be aborted, leading to an increase in critical section execution times. We provide some estimates on this increase. 2 Restartable Atomic Sequences We build our optimistic synchronization methods on Restartable Atomic Sequences (RAS) <ref> [3] </ref>. An RAS is a section of code that is re-executed from the beginning if a context occurs while a process is executing in the code section. The re-execution of an RAS is enforced by the kernel context-switch mechanism. <p> Bershad et al. show that an RAS implementation of an atomic test-and-set has better performance than a hardware test-and-set on many architectures, and is much faster than kernel-level synchronization <ref> [3] </ref>. We note that the idea of kernel support for critical sections is well established. In 4.3BSD UNIX, a system call that is interrupted by a signal is restarted using the longjump instruction [13]. <p> 13 record *getbuf (record **current) buffer *temp temp=*current *current=(*current)!next The procedure to declare that a node is garbage is given by: garbage (record *elem,**g head,**g tail) if (*g tail==NULL) *g tail=elem elem!next=*g head *g head=elem A typical critical section is given by: struct commit record elementf word *lhs,rhsg commit record <ref> [3] </ref> boolean valid Global record *pool critical section () record *current,*g head,*g tail restartablef if (valid) instruction=0 while (instruction&lt;3 and commit record [instruction].lhs != NULL) *(commit record [instruction].lhs)=commit record [instruction].rhs valid=FALSE // Initialize the list pointers current=pool g head=g tail=NULL Compute the modifications to the data structure using the getbuf and <p> However, a task that is executing in a critical section needs to re-execute only if it is pre-empted by a task that performs a conflicting operation. Bershad et al.'s proposal for restartable atomic sequences <ref> [3] </ref> assumed that the protected region would be very short, and did not plan implementations for real-time systems. To better support the implementation of interruptible critical sections, we propose the idea of pre-emptable locks. A pre-emptable lock protects a critical section.
Reference: [4] <author> H. Tokuda C.D. Locke and E.D. Jensen. </author> <title> A time-driven scheduling model for real-time operating systems. </title> <type> Technical report, </type> <institution> Carnegie Mellon University, </institution> <year> 1991. </year>
Reference-contexts: 1 Introduction The scheduling of independent real-time tasks is well understood, as optimal scheduling algorithms have been proposed for periodic and aperiodic tasks on uniprocessor [7, 9] and multiprocessor systems <ref> [8, 4, 15] </ref>. However, if the tasks communicate through shared critical sections, a low-priority task that holds a lock may block a high priority that requires the lock, causing a priority inversion. In this paper, we present a method for real-time synchronization that avoids priority inversions.
Reference: [5] <author> M.I. Chen and K.J. Lin. </author> <title> Dynamic priority ceiling: A concurrency control protocol for real-time systems. </title> <journal> Real-Time Systems Journal, </journal> <volume> 2(4) </volume> <pages> 325-346, </pages> <year> 1990. </year>
Reference-contexts: A task's execution is delayed until the scheduler can guarantee that the task can execute without 1 blocking a higher priority task. Tripathi and Nirkhe [21], and Faulk and Parnas [10] also discuss pre--allocation based scheduling methods. Chen and Lin <ref> [5] </ref> extend the Priority Inheritance Protocol to permit dynamically-assigned priorities. Chen and Lin [6] extend the protocol in [5] to account for multiple resource instances. Previous approaches to real-time synchronization suffer from several drawbacks. <p> Tripathi and Nirkhe [21], and Faulk and Parnas [10] also discuss pre--allocation based scheduling methods. Chen and Lin <ref> [5] </ref> extend the Priority Inheritance Protocol to permit dynamically-assigned priorities. Chen and Lin [6] extend the protocol in [5] to account for multiple resource instances. Previous approaches to real-time synchronization suffer from several drawbacks. First, a high-priority task might be forced to wait for a low-priority task to complete a critical section. <p> Second, dynamic-priority scheduling algorithms are feasible with much higher CPU utilizations than static-priority scheduling algorithms [7], and dynamic-priority schedulers mught be required for aperiodic tasks. The simple Priority Inheritance Protocol of Rajkumar, Sha, and Lehoczky [19] can be applied to static-priority schedulers only. The dynamic-priority synchronization protocols <ref> [5, 6, 2] </ref> are complex, and must be closely integrated with the scheduling algorithm. In this paper, we present a different approach to synchronization, one which guarantees that a high-priority task never waits for a low-priority task at a critical section.
Reference: [6] <author> M.I. Chen and K.J. Lin. </author> <title> A priority ceiling protocol for multiple-instance resources. </title> <booktitle> In Real Time Systems Symposium, </booktitle> <pages> pages 140-149, </pages> <year> 1990. </year>
Reference-contexts: Tripathi and Nirkhe [21], and Faulk and Parnas [10] also discuss pre--allocation based scheduling methods. Chen and Lin [5] extend the Priority Inheritance Protocol to permit dynamically-assigned priorities. Chen and Lin <ref> [6] </ref> extend the protocol in [5] to account for multiple resource instances. Previous approaches to real-time synchronization suffer from several drawbacks. First, a high-priority task might be forced to wait for a low-priority task to complete a critical section. <p> Second, dynamic-priority scheduling algorithms are feasible with much higher CPU utilizations than static-priority scheduling algorithms [7], and dynamic-priority schedulers mught be required for aperiodic tasks. The simple Priority Inheritance Protocol of Rajkumar, Sha, and Lehoczky [19] can be applied to static-priority schedulers only. The dynamic-priority synchronization protocols <ref> [5, 6, 2] </ref> are complex, and must be closely integrated with the scheduling algorithm. In this paper, we present a different approach to synchronization, one which guarantees that a high-priority task never waits for a low-priority task at a critical section. <p> An ICS cannot be directly used to reserve access to a resource. The code that reserves a resource can be protected by an ICS, but contention for the resource might cause blocking, and thus priority inversion. A blocking-based protocol (such as those in <ref> [19, 2, 6] </ref>) should be applied in this instance. Alternatively, resources can be pre-allocated, or enough resources supplied to the system to ensure that no process will block. Similarly, an ICS cannot be used to ensure exclusive access to a device.
Reference: [7] <author> C.L.Liu and W.J. Leyland. </author> <title> Scheduling algorithms for multiprogramming in a hard real-time environment. </title> <journal> JACM, </journal> <volume> 20(1) </volume> <pages> 46-63, </pages> <year> 1973. </year>
Reference-contexts: 1 Introduction The scheduling of independent real-time tasks is well understood, as optimal scheduling algorithms have been proposed for periodic and aperiodic tasks on uniprocessor <ref> [7, 9] </ref> and multiprocessor systems [8, 4, 15]. However, if the tasks communicate through shared critical sections, a low-priority task that holds a lock may block a high priority that requires the lock, causing a priority inversion. <p> Jeffay [12] discusses the additional feasibility conditions required if tasks have pre-emption constraints. Second, dynamic-priority scheduling algorithms are feasible with much higher CPU utilizations than static-priority scheduling algorithms <ref> [7] </ref>, and dynamic-priority schedulers mught be required for aperiodic tasks. The simple Priority Inheritance Protocol of Rajkumar, Sha, and Lehoczky [19] can be applied to static-priority schedulers only. The dynamic-priority synchronization protocols [5, 6, 2] are complex, and must be closely integrated with the scheduling algorithm.
Reference: [8] <author> S. Davari and S.K. Dhall. </author> <title> An on-line algorithm ofr real-time task allocation. </title> <booktitle> In IEEE Real-Time Systems Symposium, </booktitle> <year> 1986. </year>
Reference-contexts: 1 Introduction The scheduling of independent real-time tasks is well understood, as optimal scheduling algorithms have been proposed for periodic and aperiodic tasks on uniprocessor [7, 9] and multiprocessor systems <ref> [8, 4, 15] </ref>. However, if the tasks communicate through shared critical sections, a low-priority task that holds a lock may block a high priority that requires the lock, causing a priority inversion. In this paper, we present a method for real-time synchronization that avoids priority inversions.
Reference: [9] <author> M. Dertouzos. </author> <title> Control robotics: The procedural control of physical processes. </title> <booktitle> In Proc. of the IFIP Congress, </booktitle> <year> 1974. </year>
Reference-contexts: 1 Introduction The scheduling of independent real-time tasks is well understood, as optimal scheduling algorithms have been proposed for periodic and aperiodic tasks on uniprocessor <ref> [7, 9] </ref> and multiprocessor systems [8, 4, 15]. However, if the tasks communicate through shared critical sections, a low-priority task that holds a lock may block a high priority that requires the lock, causing a priority inversion.
Reference: [10] <author> S.R. Faulk and D.L. Parnas. </author> <title> On synchronization in hard real-time systems. </title> <journal> Communications of the ACM, </journal> <volume> 31(3) </volume> <pages> 274-287, </pages> <year> 1988. </year>
Reference-contexts: Baker [2] presents a pre-allocation based synchronization algorithm that can manages resources with multiple instances. A task's execution is delayed until the scheduler can guarantee that the task can execute without 1 blocking a higher priority task. Tripathi and Nirkhe [21], and Faulk and Parnas <ref> [10] </ref> also discuss pre--allocation based scheduling methods. Chen and Lin [5] extend the Priority Inheritance Protocol to permit dynamically-assigned priorities. Chen and Lin [6] extend the protocol in [5] to account for multiple resource instances. Previous approaches to real-time synchronization suffer from several drawbacks.
Reference: [11] <author> M. Herlihy. </author> <title> Apologizing versus asking permission: Optimistic concurrency control for abstract data types. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 15(1) </volume> <pages> 96-124, </pages> <year> 1990. </year>
Reference-contexts: Setting locks to avoid pre-emption is unacceptable, since the goal is to create arbitrarily interruptible critical sections. We will instead make use of non-blocking synchronization algorithms. Herlihy <ref> [11] </ref> introduces the idea of non-blocking concurrent objects. An algorithm for a non-blocking object provides the guarantee that one of the process which accesses the object makes progress in a finite 4 number of steps. <p> If an operation performs a substantial modification and the number of modifications that an operation commits might vary widely, then a high priority operation might spend a substantial amount of time performing a low priority operation's updates to the data structure. In <ref> [11] </ref>, Herlihy proposes a `shadow-page' method for implementing a non-blocking concurrent data structure. An operation calculates its modifications to the data structure in set of privately allocated (shadow) records, then links its records into the data structure in its decisive instruction. The process is illustrated in figure 2.
Reference: [12] <author> K. Jeffay. </author> <title> Analysis of a synchronization and scheduling discipline for real-time tasks with pre-emption constraints. </title> <booktitle> In Real Time Systems Symposium, </booktitle> <pages> pages 295-305, </pages> <year> 1989. </year> <month> 19 </month>
Reference-contexts: First, a high-priority task might be forced to wait for a low-priority task to complete a critical section. Mercer and Tokuda [14] note that the blocking of high-priority tasks must be kept to a minimum in order to ensure the responsiveness of the real-time system. Jeffay <ref> [12] </ref> discusses the additional feasibility conditions required if tasks have pre-emption constraints. Second, dynamic-priority scheduling algorithms are feasible with much higher CPU utilizations than static-priority scheduling algorithms [7], and dynamic-priority schedulers mught be required for aperiodic tasks.
Reference: [13] <editor> S.J. Le*er, M.K. McKusick, M.J. Karels, and J.S. </editor> <title> Quarterman. The Design and Implementation of the 4.3 BSD UNIX Operating System. </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: We note that the idea of kernel support for critical sections is well established. In 4.3BSD UNIX, a system call that is interrupted by a signal is restarted using the longjump instruction <ref> [13] </ref>. Anderson et al. [1] argue that the operaing system support for parallel threads should recognize that a pre-empted thread is executing in a critical section, and execute the pre-empted thread until the thread exits the critical section.
Reference: [14] <author> C.W. Mercer and H. Tokuda. </author> <booktitle> Preemptibility in real-time operating systems. In Real Time Systems Symposuim, </booktitle> <pages> pages 78-87, </pages> <year> 1992. </year>
Reference-contexts: Chen and Lin [6] extend the protocol in [5] to account for multiple resource instances. Previous approaches to real-time synchronization suffer from several drawbacks. First, a high-priority task might be forced to wait for a low-priority task to complete a critical section. Mercer and Tokuda <ref> [14] </ref> note that the blocking of high-priority tasks must be kept to a minimum in order to ensure the responsiveness of the real-time system. Jeffay [12] discusses the additional feasibility conditions required if tasks have pre-emption constraints.
Reference: [15] <author> A.K. </author> <title> Mok and M.L. Dertouzos. Multiprocessor on-line scheduling of hard real-time tasks. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 15(12) </volume> <pages> 1497-1506, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction The scheduling of independent real-time tasks is well understood, as optimal scheduling algorithms have been proposed for periodic and aperiodic tasks on uniprocessor [7, 9] and multiprocessor systems <ref> [8, 4, 15] </ref>. However, if the tasks communicate through shared critical sections, a low-priority task that holds a lock may block a high priority that requires the lock, causing a priority inversion. In this paper, we present a method for real-time synchronization that avoids priority inversions.
Reference: [16] <author> E. Moss and W.H. Kohler. </author> <title> Concurrency features for the trellis/owl language. </title> <booktitle> In European Conference on Object-Oriented Programming, </booktitle> <pages> pages 171-180, </pages> <year> 1987. </year> <note> Appears as Springer-Verlag Computer Science Lecture Note number 276. </note>
Reference-contexts: In addition, Moss and Kohler coded several of the run-time support calls of the Trellis/Owl language so that they could be restarted if interrupted <ref> [16] </ref>. We indicate a restartable region by explicitly declaring it so: restartablef stmt1; : stmtn; g Bershad et al. propose the RAS as a mechanism for fast user-level synchronization in a uniprocessor system.
Reference: [17] <author> S. Prakash, Y.H. Lee, and T. Johnson. </author> <title> A non-blocking algorithm for shared queues using compare-and-swap. </title> <booktitle> In Proc. Int'l Conf. on Parallel Processing, </booktitle> <pages> pages II68-II75, </pages> <year> 1991. </year>
Reference-contexts: Herlihy provides a method for implementing non-blocking objects that swaps in the new value of the object in a single write. Prakash, Lee, and Johnson <ref> [17] </ref> devise a non-blocking queue that permits enqueuers to work concurrently with dequeuers. The enqueue operation requires two writes: one write to attach the new element and one write to move the tail pointer. <p> The typical execution sequence of an ICS will be for an operation to cleanup after any previous operation executions, to calculate the decisive instruction, then to perform the decisive instruction as the last instruction in the restartable region. 3.1 Prakash-style Interruptible Critical Section In <ref> [17] </ref>, Prakash, Lee and Johnson present a simple shared non-blocking linked-list queue that is Their queue is decisive instruction serializable Their technique uses the compare-and-swap instruction to atomically commit 5 changes to the data structure. 1 The enqueue operation requires two writes to the global data, as a newly inserted record <p> The actions that must be taken to complete the defined by the current state of the queue. We can use a technique similar to that developed in <ref> [17] </ref> to write an ICS in which the operations might need to perform several global writes. A set of object states are defined, along with a set of transitions on the states. <p> The two execution costs balance. Since the states are well defined, and the cleanup phase takes the queue from one well defined state to another, we can see that the queue is correct. The code for the ICS queue differs from the code for the non-blocking queue <ref> [17] </ref> in several details. First, the non-blocking queue must take an atomic snapshot of the variables that define the queue state (by using a special protocol). The ICS queue needs only to read the variables since an ICS operation executes serially and is guaranteed of taking an atomic snapshot.
Reference: [18] <author> R. Rajkumar, L. Sha, and J.P. Lehoczky. </author> <title> Real-time synchronization protocols for multiprocessors. </title> <booktitle> In Real Time Systems Symposium, </booktitle> <year> 1988. </year>
Reference-contexts: However, the tasks must have static priorities in order to apply the Priority Ceiling Protocol. In addition, blocking for even the duration of one critical section may be excessive. Rajkumar, Sha, and Lehoczky have extended the Priority Inheritance Protocol to work in a multiprocessor system <ref> [18] </ref>. Blocking-based synchronization algorithms have been extended to work with dynamic-priority schedulers. Baker [2] presents a pre-allocation based synchronization algorithm that can manages resources with multiple instances. A task's execution is delayed until the scheduler can guarantee that the task can execute without 1 blocking a higher priority task.
Reference: [19] <author> R. Rajkumar, L. Sha, and J.P. Lehoczky. </author> <title> Priority inheritance protocols: An approach to real-time synchronization. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 39(9) </volume> <pages> 1175-1185, </pages> <year> 1990. </year>
Reference-contexts: However, if the tasks communicate through shared critical sections, a low-priority task that holds a lock may block a high priority that requires the lock, causing a priority inversion. In this paper, we present a method for real-time synchronization that avoids priority inversions. Rajkumar, Sha, and Lehoczky <ref> [19] </ref> have proposed the Priority Ceiling Protocol (PCP) to minimize the effect of priority inversion. The priority ceiling of a semaphore S is the priority of the highest priority task that will ever lock S. <p> Jeffay [12] discusses the additional feasibility conditions required if tasks have pre-emption constraints. Second, dynamic-priority scheduling algorithms are feasible with much higher CPU utilizations than static-priority scheduling algorithms [7], and dynamic-priority schedulers mught be required for aperiodic tasks. The simple Priority Inheritance Protocol of Rajkumar, Sha, and Lehoczky <ref> [19] </ref> can be applied to static-priority schedulers only. The dynamic-priority synchronization protocols [5, 6, 2] are complex, and must be closely integrated with the scheduling algorithm. <p> An ICS cannot be directly used to reserve access to a resource. The code that reserves a resource can be protected by an ICS, but contention for the resource might cause blocking, and thus priority inversion. A blocking-based protocol (such as those in <ref> [19, 2, 6] </ref>) should be applied in this instance. Alternatively, resources can be pre-allocated, or enough resources supplied to the system to ensure that no process will block. Similarly, an ICS cannot be used to ensure exclusive access to a device.
Reference: [20] <author> D. Shasha and N. Goodman. </author> <title> Concurrent search structure algorithms. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 13(1) </volume> <pages> 53-90, </pages> <year> 1988. </year>
Reference-contexts: We present methods for implementing interruptible critical sections based on each of the above three non-blocking techniques. The three methods that we propose are decisive instruction serializable <ref> [20] </ref>. A concurrent execution sequence of a set of operations has an equivalent serial execution if the execution is equivalent (with respect to return values and final value) to a serial execution of the operations.
Reference: [21] <author> S.K. Tripathi and V. Nirkhe. </author> <title> Pre-scheduling for synchronization in hard real-time systems. </title> <booktitle> In Operating Systems of the '90s and Beyond, Int'l Workshop, </booktitle> <pages> pages 102-108, </pages> <year> 1991. </year> <note> Appears as Springer-Verlag Computer Science Lecture Note number 563. </note>
Reference-contexts: Baker [2] presents a pre-allocation based synchronization algorithm that can manages resources with multiple instances. A task's execution is delayed until the scheduler can guarantee that the task can execute without 1 blocking a higher priority task. Tripathi and Nirkhe <ref> [21] </ref>, and Faulk and Parnas [10] also discuss pre--allocation based scheduling methods. Chen and Lin [5] extend the Priority Inheritance Protocol to permit dynamically-assigned priorities. Chen and Lin [6] extend the protocol in [5] to account for multiple resource instances. Previous approaches to real-time synchronization suffer from several drawbacks.
Reference: [22] <author> J. Turek, D. Shasha, and S. Prakash. </author> <title> Locking without blocking: Making lock based concurrent data structure algorithms nonblocking. </title> <booktitle> In ACM Symp. on Principles of Database Systems, </booktitle> <pages> pages 212-222, </pages> <year> 1992. </year>
Reference-contexts: The enqueue operation requires two writes: one write to attach the new element and one write to move the tail pointer. If an operation detects that it is blocked by a half-finished operation, the new operation will altruistically complete the half-finished operation and unblock itself. Turek, Shasha, and Prakash <ref> [22] </ref> propose a general transformation for creating non-blocking data structure algorithms from lock-based data structure algorithms. Instead of setting a lock, a process posts a pointer to its own program. <p> A more complex structure, such as a linked list or a binary search tree, is much harder to describe. For these data structures a more powerful technique, one which explicitly specifies the cleanup actions, is needed. In <ref> [22] </ref>, Turek et al. propose a method for transforming locking data structures into non-blocking data structures. The key to the transformation is to post a continuation instead of a lock. The continuation contains the modifications that the process intends to perform.
References-found: 22

