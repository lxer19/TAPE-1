URL: http://l2r.cs.uiuc.edu/~danr/Other-papers/Topics/Learning/ILP/Flach-survey.ps.gz
Refering-URL: http://l2r.cs.uiuc.edu/~danr/Teaching/CS491-98/491-list.html
Root-URL: http://www.cs.uiuc.edu
Email: Peter.Flach@cs.bris.ac.uk,  
Title: The logic of learning: a brief introduction to Inductive Logic Programming  
Author: Peter A. Flach 
Date: August 5, 1998  
Web: http://www.cs.bris.ac.uk/flach/  
Address: Merchant Venturers Building, Woodland Road, Bristol BS8 1UB, UK  
Affiliation: Department of Computer Science, University of Bristol  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> D. Angluin, M. Frazier & L. Pitt. </author> <title> Learning conjunctions of Horn clauses. </title> <booktitle> Machine Learning, </booktitle> <address> 9(2/3):147164, </address> <year> 1992. </year>
Reference-contexts: From this viewpoint induction of integrity constraints is more a descendant of one of the typical problems studied in computational learning theory, viz. learning arbitrary Boolean expressions from some of its satisfying and falsifying assignments <ref> [42, 1] </ref>. Secondly, there is often a close link between descriptive induction and nonmonotonic or closed-world reasoning, in that both involve some form of Closed World Assumption (CWA). However, the inductive CWA has a slightly different interpretation: `everything I haven't seen behaves like the things I have seen' [17].
Reference: [2] <author> I. Bratko & S. Muggleton. </author> <title> Applications of Inductive Logic Programming. </title> <journal> Comm. ACM 38(11):6570, </journal> <month> November </month> <year> 1995. </year>
Reference-contexts: Recent years have seen a steady increase in ILP research, as well as numerous applications to practical problems like data mining and scientific discovery see <ref> [2, 6] </ref> for an overview of recent applications. This paper is intended to provide an introduction to ILP.
Reference: [3] <author> L. De Raedt & M. Bruynooghe. </author> <title> A theory of clausal discovery. </title> <booktitle> Proc. 13th Int. Joint Conf. on Artificial Intelligence, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> pp.10581063, </address> <year> 1993. </year> <title> 4 Prime implicants uncovering system. </title> <type> 14 </type>
Reference-contexts: The positive cover can then be constructed from the negative cover, without reference to the tuples. 3.3 Clausal discovery CLAUDIEN (clausal discovery engine) is a system for discovery of full clausal theories <ref> [3, 5] </ref>. Each example is a Herbrand interpretation, and the system searches for most general clauses that are true in all interpretations. The following example is taken from [5]. Examples: gorilla (liz). gorilla (richard). gorilla (ginger). gorilla (fred). female (liz). male (richard). female (ginger). male (fred).
Reference: [4] <author> L. De Raedt, </author> <title> editor. </title> <booktitle> Advances in Inductive Logic Programming. </booktitle> <publisher> IOS Press, </publisher> <year> 1996. </year>
Reference-contexts: Both Horn clause induction and learning of integrity constraints have been reviewed. More detailed surveys are provided by [22, 30], while [24] offers an extensive overview of on-line available systems and datasets, as well as a bibliography with nearly 600 entries. <ref> [29, 4] </ref> are collections of research papers. http://www-ai.ijs.si/ilpnet.html is a good starting place for web searches. Acknowledgements An extended version of this paper, with emphasis on applications in Deductive Databases, will be published as [14].
Reference: [5] <author> L. De Raedt & L. Dehaspe. </author> <title> Clausal discovery. </title> <booktitle> Machine Learning, </booktitle> <address> 26(2/3):99146, </address> <year> 1997. </year>
Reference-contexts: For instance, a refinement operator can easily be modified to 7 generate only singly-recursive or tail-recursive clauses. DLAB (declarative language bias) is a powerful language for specifying language bias <ref> [5] </ref>. Finally, I mention the use of clause schemata as a language bias. These are second-order clauses with predicate variables: Q (X,Y):-P (X,Y). <p> The positive cover can then be constructed from the negative cover, without reference to the tuples. 3.3 Clausal discovery CLAUDIEN (clausal discovery engine) is a system for discovery of full clausal theories <ref> [3, 5] </ref>. Each example is a Herbrand interpretation, and the system searches for most general clauses that are true in all interpretations. The following example is taken from [5]. Examples: gorilla (liz). gorilla (richard). gorilla (ginger). gorilla (fred). female (liz). male (richard). female (ginger). male (fred). <p> Each example is a Herbrand interpretation, and the system searches for most general clauses that are true in all interpretations. The following example is taken from <ref> [5] </ref>. Examples: gorilla (liz). gorilla (richard). gorilla (ginger). gorilla (fred). female (liz). male (richard). female (ginger). male (fred). Hypothesis: gorilla (X):-female (X) gorilla (X):-male (X) 11 Table 1: A feature table. <p> The task addressed by the CLAUDIEN system is a kind of unsupervised learning closely related to data mining. An important difference with the classification-oriented form of ILP is that here each clause can be discovered independently of the others. Not only does this allow a parallel implementation <ref> [5] </ref>, it also means that the approach can be implemented as an any-time algorithm, at any time maintaining a hypothesis that is meaningful as an approximate solution, the sequence of hypotheses converging to the correct solution over time. 12 Table 2: A 3-dimensional contingency table. son (X,Y) :son (X,Y) total daughter
Reference: [6] <author> S. Dzeroski & I. Bratko. </author> <booktitle> Applications of Inductive Logic Programming. In [4], </booktitle> <address> pp.6581. </address>
Reference-contexts: Recent years have seen a steady increase in ILP research, as well as numerous applications to practical problems like data mining and scientific discovery see <ref> [2, 6] </ref> for an overview of recent applications. This paper is intended to provide an introduction to ILP.
Reference: [7] <author> P. Flach. </author> <title> Simply Logical intelligent reasoning by example. </title> <publisher> John Wiley, </publisher> <year> 1994. </year>
Reference-contexts: Shapiro called his specialisation operator a refinement operator, a term that is still in use today (see [21] for an extensive analysis of refinement operators). A much simplified Prolog implementation of MIS can be found in <ref> [7] </ref>. Another well-known top-down system is Quinlan's FOIL [36]. 3 2.2 Generality As the previous example shows, clauses can be specialised in two ways: by applying a substitution, and by adding a body literal. More formally, the underlying structure can be defined as follows. <p> The approach illustrated here is essentially the one taken by Muggleton and Feng's Golem system [27] (again, a much simplified Prolog implementation can be found in <ref> [7] </ref>). Although Golem has been successfully applied to a range of practical problems, it has a few shortcomings. One serious restriction is that it requires ground background knowledge.
Reference: [8] <author> P.A. Flach. </author> <title> Inductive characterisation of database relations. </title> <booktitle> Proc. Fifth Int. Symp. on Methodologies for Intelligent Systems ISMIS'90, </booktitle> <editor> Z.W. Ras, M. Zemankowa & M.L. Emrich (editors), </editor> <publisher> North-Holland, </publisher> <address> pp.371378, </address> <year> 1990. </year> <note> Full version appeared as ITK Research Report 23, </note> <institution> Inst. for Language Technology & Artificial Intelligence, Tilburg University. </institution>
Reference-contexts: Clearly in the non-incremental approach negative tuples are obtained through the Closed World Assumption. Attribute dependencies, being logical formulae, can be ordered according to generality (a simplified form of -subsumption). As in the case of explanatory induction, one can therefore have top-down and bottom-up approaches. In the top-down approach <ref> [8] </ref> one starts with the set of most general dependencies, specialising them until they are no longer violated by the data. In this way one obtains a cover for the set of satisfied dependencies (although the cover may contain some redundant elements). An alternative bottom-up approach runs as follows [38].
Reference: [9] <author> P.A. Flach. </author> <title> Predicate invention in Inductive Data Engineering. </title> <booktitle> Proc. Eur. Conf. on Machine Learning ECML'93, </booktitle> <editor> P.B. Brazdil (editor), </editor> <booktitle> Lecture Notes in Artificial Intelligence 667, </booktitle> <publisher> Springer-Verlag, </publisher> <address> pp.8394, </address> <year> 1993. </year>
Reference-contexts: Induction of attribute dependencies thus calls for the alternative framework of descriptive induction. Here I will briefly introduce my own work on induction of functional and multivalued dependencies (see <ref> [9] </ref> or [10, Chapter 8] for details; [26, 18] give alternative algorithms for discovery of functional dependencies). Typically it is sufficient to learn functional and multivalued dependencies from single relations. The tuples can be supplied incrementally one-by-one or as a complete relation.
Reference: [10] <author> P.A. Flach. </author> <title> Conjectures an inquiry concerning the logic of induction. </title> <type> PhD thesis, </type> <institution> Tilburg University, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: Sometimes this enables one to treat the data as specifying one preferred or minimal model, and develop the hypothesis from that starting point. Metalogical properties of this form of inductive reasoning are therefore similar to those of reasoning with rules that tolerate exceptions <ref> [10, 11] </ref>. 3.2 Induction of attribute dependencies Attribute dependencies such as functional dependencies are forms of intensional knowledge that can be successfully induced from extensional data. <p> Induction of attribute dependencies thus calls for the alternative framework of descriptive induction. Here I will briefly introduce my own work on induction of functional and multivalued dependencies (see [9] or <ref> [10, Chapter 8] </ref> for details; [26, 18] give alternative algorithms for discovery of functional dependencies). Typically it is sufficient to learn functional and multivalued dependencies from single relations. The tuples can be supplied incrementally one-by-one or as a complete relation.
Reference: [11] <author> P.A. Flach. </author> <title> Rationality postulates for induction. </title> <booktitle> Proc. 6th Int. Conf. on Theoretical Aspects of Rationality and Knowledge, </booktitle> <editor> Yoav Shoham (ed.), pp.267-281. </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1996. </year>
Reference-contexts: Sometimes this enables one to treat the data as specifying one preferred or minimal model, and develop the hypothesis from that starting point. Metalogical properties of this form of inductive reasoning are therefore similar to those of reasoning with rules that tolerate exceptions <ref> [10, 11] </ref>. 3.2 Induction of attribute dependencies Attribute dependencies such as functional dependencies are forms of intensional knowledge that can be successfully induced from extensional data.
Reference: [12] <author> P.A. Flach. </author> <title> Normal forms for Inductive Logic Programming. </title> <booktitle> Proc. 7th Int. Worksh. on Inductive Logic Programming ILP-97, </booktitle> <editor> N. Lavrac & S. Dzeroski (eds.), </editor> <booktitle> Lecture Notes in Artificial Intelligence 1297, </booktitle> <address> pp.149156. </address> <publisher> Springer-Verlag, </publisher> <year> 1997. </year>
Reference-contexts: One way to see that is by means of DNF to CNF conversion <ref> [12] </ref>. From the examples we construct a feature table, which is a sort of generalised truth-table (Table 1). The rows without an entry for X indicate that one cannot find a substitution for X such that the three ground atoms obtain the required truth value these represent the so-called countermodels.
Reference: [13] <author> P.A. Flach & N. Lachiche. </author> <title> Cooking up integrity constraints with PRIMUS. </title> <type> Technical Report, </type> <institution> Department of Computer Science, University of Bristol, </institution> <year> 1997. </year>
Reference-contexts: If we take a logic programming perspective the approach can be simplified to 2-dimensional tables that assess the dependence between body and head. The approach is currently being implemented in the Primus 4 system <ref> [13] </ref>. 4 Concluding remarks In this paper I have attempted to give an accessible introduction ton Inductive Logic Programming. Both Horn clause induction and learning of integrity constraints have been reviewed.
Reference: [14] <author> P.A. Flach. </author> <title> From extensional to intensional knowledge: Inductive Logic Programming techniques and their application to Deductive Databases. In Transactions and Change in Logic Databases, </title> <editor> H. Decker, B. Freitag, M. Kifer & A. Voronkov (eds.), </editor> <booktitle> Lecture Notes in Computer Science. </booktitle> <pages> Springer-Verlag, </pages> <note> to appear. </note>
Reference-contexts: Acknowledgements An extended version of this paper, with emphasis on applications in Deductive Databases, will be published as <ref> [14] </ref>. This work was partially supported by ESPRIT IV Long Term Research Project 20237 Inductive Logic Programming 2.
Reference: [15] <editor> H. Gallaire, J. Minker & J.-M. Nicolas. </editor> <title> Logic and databases: a deductive approach. </title> <journal> Computing Surveys 16 (2): </journal> <volume> 153185, </volume> <year> 1984. </year>
Reference: [16] <author> G. Gottlob. </author> <title> Subsumption and implication. </title> <journal> Inf. Proc. Letters 24:109111, </journal> <year> 1987. </year>
Reference-contexts: Every model of the first clause is necessarily a model of the other two, both of which are therefore entailed by the first. However, the first clause -subsumes the third (substitute s (Z) for X) but not the second. Gottlob characterises the distinction between -subsumption and entailment <ref> [16] </ref>: basically, C 1 -subsumes C 2 without entailing it if the resolution proof of C 2 from C 1 requires to use C 1 more than once. It seems that the entailment ordering is the one to use, in particular when learning recursive clauses.
Reference: [17] <author> N. Helft. </author> <title> Induction as nonmonotonic inference. </title> <booktitle> Proc. First Int. Conf. on Knowledge Representation and Reasoning KR'89, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> pp.149156, </address> <year> 1989. </year>
Reference-contexts: Secondly, there is often a close link between descriptive induction and nonmonotonic or closed-world reasoning, in that both involve some form of Closed World Assumption (CWA). However, the inductive CWA has a slightly different interpretation: `everything I haven't seen behaves like the things I have seen' <ref> [17] </ref>. Sometimes this enables one to treat the data as specifying one preferred or minimal model, and develop the hypothesis from that starting point.
Reference: [18] <author> Y. Huhtala, J. Karkkainen, P. Porkka & H. Toivonen. </author> <title> Efficient Discovery of Functional and Approximate Dependencies Using Partitions. </title> <booktitle> Proc. 14th Int. Conf. on Data Engineering, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <month> February </month> <year> 1998. </year> <month> 15 </month>
Reference-contexts: Induction of attribute dependencies thus calls for the alternative framework of descriptive induction. Here I will briefly introduce my own work on induction of functional and multivalued dependencies (see [9] or [10, Chapter 8] for details; <ref> [26, 18] </ref> give alternative algorithms for discovery of functional dependencies). Typically it is sufficient to learn functional and multivalued dependencies from single relations. The tuples can be supplied incrementally one-by-one or as a complete relation.
Reference: [19] <author> P. Idestam-Almquist. </author> <title> Generalization of clauses. </title> <type> PhD thesis, </type> <institution> Stockholm University, </institution> <month> October </month> <year> 1993. </year> <month> IdestamPhD93 </month>
Reference-contexts: Finally, entailment between clauses is undecidable, whereas -subsumption is decidable (but NP-complete). For these reasons, ILP systems usually employ -subsumption rather than entailment. Idestam-Almquist defines a stronger form of entailment called T-implication, which remedies some of the shortcomings of entailment <ref> [19, 20] </ref>. 2 This definition, and the term -subsumption, was introduced in the context of induction by Plotkin [34, 35].
Reference: [20] <author> P. Idestam-Almquist. </author> <title> Generalization of Clauses under Implication. </title> <journal> J. AI Research, </journal> <volume> 3:467 489, </volume> <year> 1995. </year>
Reference-contexts: Finally, entailment between clauses is undecidable, whereas -subsumption is decidable (but NP-complete). For these reasons, ILP systems usually employ -subsumption rather than entailment. Idestam-Almquist defines a stronger form of entailment called T-implication, which remedies some of the shortcomings of entailment <ref> [19, 20] </ref>. 2 This definition, and the term -subsumption, was introduced in the context of induction by Plotkin [34, 35].
Reference: [21] <author> P. van der Laag. </author> <title> An analysis of refinement operators in Inductive Logic Programming. </title> <type> PhD Thesis, </type> <institution> Erasmus University Rotterdam, </institution> <month> December </month> <year> 1995. </year>
Reference-contexts: MIS is an incremental top-down system that performs a complete breadth-first search of the space of possible clauses. Shapiro called his specialisation operator a refinement operator, a term that is still in use today (see <ref> [21] </ref> for an extensive analysis of refinement operators). A much simplified Prolog implementation of MIS can be found in [7].
Reference: [22] <author> N. Lavrac & S. Dzeroski. </author> <title> Inductive Logic Programming: techniques and applications. </title> <publisher> Ellis Horwood, </publisher> <year> 1994. </year>
Reference-contexts: Experience shows that this is too inefficient except for relatively restricted induction problems. In general every ILP system needs heuristics to direct the search. Furthermore, heuristics have the additional benefit of making an induction algorithm noise-tolerant. We can only scratch the surface of the topic here for overviews see <ref> [22, Chapter 8] </ref> or [23]. Accuracy estimates. There are basically three approaches to heuristics in machine learning. The statistical approach treats the examples as a sample drawn from a larger population. <p> The approach is currently being implemented in the Primus 4 system [13]. 4 Concluding remarks In this paper I have attempted to give an accessible introduction ton Inductive Logic Programming. Both Horn clause induction and learning of integrity constraints have been reviewed. More detailed surveys are provided by <ref> [22, 30] </ref>, while [24] offers an extensive overview of on-line available systems and datasets, as well as a bibliography with nearly 600 entries. [29, 4] are collections of research papers. http://www-ai.ijs.si/ilpnet.html is a good starting place for web searches.
Reference: [23] <author> N. Lavrac, S. Dzeroski & I. Bratko. </author> <title> Handling imperfect data in Inductive Logic Programming. </title> <booktitle> In [4], </booktitle> <address> pp.4864. </address>
Reference-contexts: In general every ILP system needs heuristics to direct the search. Furthermore, heuristics have the additional benefit of making an induction algorithm noise-tolerant. We can only scratch the surface of the topic here for overviews see [22, Chapter 8] or <ref> [23] </ref>. Accuracy estimates. There are basically three approaches to heuristics in machine learning. The statistical approach treats the examples as a sample drawn from a larger population.
Reference: [24] <author> N. Lavrac, I. Weber, D. Zupanic, D. Kazakov, O. c fltepankova & S. Dzeroski. </author> <title> ILPNET repositories on WWW: Inductive Logic Programming systems, datasets and bibliography. </title> <journal> AI Communications 9(4):157206, </journal> <year> 1996. </year>
Reference-contexts: Both Horn clause induction and learning of integrity constraints have been reviewed. More detailed surveys are provided by [22, 30], while <ref> [24] </ref> offers an extensive overview of on-line available systems and datasets, as well as a bibliography with nearly 600 entries. [29, 4] are collections of research papers. http://www-ai.ijs.si/ilpnet.html is a good starting place for web searches.
Reference: [25] <author> D.W. Loveland & G. Nadathur. </author> <title> Proof procedures for logic programming. </title> <booktitle> Handbook of Logic in Artificial Intelligence and Logic Programming, </booktitle> <volume> Vol. 5, </volume> <editor> D.M. Gabbay, C.J. Hogger & J.A. Robinson (editors), </editor> <publisher> Oxford University Press, </publisher> <address> pp.163234, </address> <year> 1998. </year>
Reference-contexts: In theorem proving the above version is termed subsumption, whereas -subsumption indicates a special case in which the number of literals of the subsumant does not exceed the number of literals of the subsumee <ref> [25] </ref>. 4 2.3 Bottom-up induction While top-down approaches successively specialise a very general starting clause, bottom-up approaches generalise a very specific bottom clause. Again I illustrate the main ideas by means of a simple example. Consider the following four ground facts: a ([1,2],[3,4],[1,2,3,4]). a ([2],[3,4],[2,3,4]).
Reference: [26] <author> H. Mannila & K.-J. Raiha. </author> <title> Algorithms for inferring functional dependencies from relations. </title> <journal> Data & Knowledge Engineering 12:8399, </journal> <year> 1994. </year>
Reference-contexts: Induction of attribute dependencies thus calls for the alternative framework of descriptive induction. Here I will briefly introduce my own work on induction of functional and multivalued dependencies (see [9] or [10, Chapter 8] for details; <ref> [26, 18] </ref> give alternative algorithms for discovery of functional dependencies). Typically it is sufficient to learn functional and multivalued dependencies from single relations. The tuples can be supplied incrementally one-by-one or as a complete relation.
Reference: [27] <author> S. Muggleton & C. Feng. </author> <title> Efficient induction of logic programs. </title> <booktitle> Proc. First Conf. on Algorithmic Learning Theory, </booktitle> <publisher> Ohmsha, </publisher> <address> Tokyo, </address> <year> 1990. </year> <note> Also in [29], pp.281298. </note>
Reference-contexts: For instance, we may require that they are determinate, i.e. have only one possible instantiation given an instantiation of the head variables and preceding determinate literals. The approach illustrated here is essentially the one taken by Muggleton and Feng's Golem system <ref> [27] </ref> (again, a much simplified Prolog implementation can be found in [7]). Although Golem has been successfully applied to a range of practical problems, it has a few shortcomings. One serious restriction is that it requires ground background knowledge. <p> The approach of Golem is to restrict the introduction of existential variables by means of ij-determinacy, which enforces that every existential variable is uniquely determined by the preceding variables (i and j are depth parameters) <ref> [27] </ref>. Mode declarations are a well-known device from logic programming to describe possible input-output behaviour of a predicate definition. For instance, a sorting program will have a mode declaration of sort (+list,-list), meaning that the first argument must be instantiated to a list.
Reference: [28] <author> S. Muggleton. </author> <title> Inductive Logic Programming. New Generation Computing, </title> <address> 8(4):295317, </address> <year> 1991. </year> <note> Also in [29], pp.327. </note>
Reference-contexts: Notice that this approach would succeed here as well because of the second positive example. The approach illustrated here is basically that of Shapiro's Model Inference System [39, 40], an ILP system avant la lettre (the term `inductive logic programming' was coined in 1990 by Muggleton <ref> [28] </ref>). MIS is an incremental top-down system that performs a complete breadth-first search of the space of possible clauses. Shapiro called his specialisation operator a refinement operator, a term that is still in use today (see [21] for an extensive analysis of refinement operators).
Reference: [29] <editor> S. Muggleton, editor. </editor> <booktitle> Inductive Logic Programming. </booktitle> <publisher> Academic Press, </publisher> <year> 1992. </year> <month> Muggleton-Book92 </month>
Reference-contexts: Both Horn clause induction and learning of integrity constraints have been reviewed. More detailed surveys are provided by [22, 30], while [24] offers an extensive overview of on-line available systems and datasets, as well as a bibliography with nearly 600 entries. <ref> [29, 4] </ref> are collections of research papers. http://www-ai.ijs.si/ilpnet.html is a good starting place for web searches. Acknowledgements An extended version of this paper, with emphasis on applications in Deductive Databases, will be published as [14].
Reference: [30] <author> S. Muggleton & L. De Raedt. </author> <title> Inductive Logic Programming: theory and methods. </title> <journal> J. Logic Programming, </journal> <volume> 19/20:629679, </volume> <year> 1994. </year>
Reference-contexts: The approach is currently being implemented in the Primus 4 system [13]. 4 Concluding remarks In this paper I have attempted to give an accessible introduction ton Inductive Logic Programming. Both Horn clause induction and learning of integrity constraints have been reviewed. More detailed surveys are provided by <ref> [22, 30] </ref>, while [24] offers an extensive overview of on-line available systems and datasets, as well as a bibliography with nearly 600 entries. [29, 4] are collections of research papers. http://www-ai.ijs.si/ilpnet.html is a good starting place for web searches.
Reference: [31] <author> S. Muggleton. </author> <title> Inverse entailment and Progol. New Generation Computing, </title> <address> 13:245286, </address> <year> 1995. </year>
Reference-contexts: Furthermore, all ground facts are lumped together, whereas it is generally possible to partition them according to the examples (e.g. the fact a ([a],[],[a]) has clearly nothing to do with the fact a ([2],[3,4],[2,3,4])). Both restrictions are lifted in Muggleton's current ILP system Progol <ref> [31] </ref>. Essentially, Progol constructs a bottom clause for a selected example by adding its negation to the (non-ground) background theory and deriving all entailed negated body literals.
Reference: [32] <author> C. Nedellec, C. Rouveirol, H. Ade, F. Bergadano & B. Tausend. </author> <title> Declarative bias in Inductive Logic Programming. </title> <booktitle> In [4], pp.82103. </booktitle> <pages> 16 </pages>
Reference-contexts: Practical ILP systems fight the inherent complexity of the problem by imposing all sorts of constraints, mostly syntactic in nature, on candidate hypotheses. Such constraints are grouped under the heading of language bias (there are other forms of biases that influence hypothesis selection; see <ref> [32] </ref> for an overview of declarative bias in ILP). Essentially, the main source of complexity in ILP derives from the variables in hypothesis clauses. In top-down systems, the branching factor of the specialisation operator increases with the number of variables in the clause.
Reference: [33] <author> J. Paredaens, P. De Bra, M. Gyssens & D. Van Guch. </author> <title> The structure of the relational database model. </title> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference: [34] <author> G. Plotkin. </author> <title> A note on inductive generalisation. </title> <booktitle> Machine Intelligence 5, </booktitle> <editor> B. Meltzer & D. Michie (editors), </editor> <publisher> North-Holland, </publisher> <address> pp.153163, </address> <year> 1970. </year>
Reference-contexts: For these reasons, ILP systems usually employ -subsumption rather than entailment. Idestam-Almquist defines a stronger form of entailment called T-implication, which remedies some of the shortcomings of entailment [19, 20]. 2 This definition, and the term -subsumption, was introduced in the context of induction by Plotkin <ref> [34, 35] </ref>.
Reference: [35] <author> G. Plotkin. </author> <title> A further note on inductive generalisation. </title> <booktitle> Machine Intelligence 6, </booktitle> <editor> B. Meltzer & D. Michie (editors), </editor> <publisher> North-Holland, </publisher> <address> pp.101124, </address> <year> 1971. </year>
Reference-contexts: For these reasons, ILP systems usually employ -subsumption rather than entailment. Idestam-Almquist defines a stronger form of entailment called T-implication, which remedies some of the shortcomings of entailment [19, 20]. 2 This definition, and the term -subsumption, was introduced in the context of induction by Plotkin <ref> [34, 35] </ref>.
Reference: [36] <author> J.R. Quinlan. </author> <title> Learning logical definitions from relations. </title> <booktitle> Machine Learning, </booktitle> <address> 5(3):239266, </address> <year> 1990. </year>
Reference-contexts: Shapiro called his specialisation operator a refinement operator, a term that is still in use today (see [21] for an extensive analysis of refinement operators). A much simplified Prolog implementation of MIS can be found in [7]. Another well-known top-down system is Quinlan's FOIL <ref> [36] </ref>. 3 2.2 Generality As the previous example shows, clauses can be specialised in two ways: by applying a substitution, and by adding a body literal. More formally, the underlying structure can be defined as follows.
Reference: [37] <author> C. </author> <title> Rouveirol. Flattening and saturation: two representation changes for generalization. </title> <booktitle> Machine Learning, </booktitle> <address> 14(2):219232, </address> <year> 1994. </year>
Reference: [38] <author> I. </author> <title> Savnik & P.A. Flach. Bottom-up induction of functional dependencies from relations. </title> <booktitle> Proc. AAAI '93 Workshop Knowledge Discovery in Databases, </booktitle> <editor> G. Piatetsky-Shapiro (editor), pp.174185, </editor> <year> 1993. </year>
Reference-contexts: In this way one obtains a cover for the set of satisfied dependencies (although the cover may contain some redundant elements). An alternative bottom-up approach runs as follows <ref> [38] </ref>. From the data one first constructs a negative cover, which is the set of least general violated dependencies (this can be done in O (n 2 ) steps in the case of functional dependencies, and O (n 3 ) steps in the case of multivalued dependencies).
Reference: [39] <author> E.Y. Shapiro. </author> <title> Inductive inference of theories from facts. </title> <type> Techn. rep. 192, </type> <institution> Comp. Sc. Dep., Yale University, </institution> <year> 1981. </year>
Reference-contexts: An alternative approach, known as extensional coverage, is to query the predicate to be learned against the examples. Notice that this approach would succeed here as well because of the second positive example. The approach illustrated here is basically that of Shapiro's Model Inference System <ref> [39, 40] </ref>, an ILP system avant la lettre (the term `inductive logic programming' was coined in 1990 by Muggleton [28]). MIS is an incremental top-down system that performs a complete breadth-first search of the space of possible clauses.
Reference: [40] <author> E.Y. Shapiro. </author> <title> Algorithmic program debugging. </title> <publisher> MIT Press, </publisher> <year> 1983. </year>
Reference-contexts: An alternative approach, known as extensional coverage, is to query the predicate to be learned against the examples. Notice that this approach would succeed here as well because of the second positive example. The approach illustrated here is basically that of Shapiro's Model Inference System <ref> [39, 40] </ref>, an ILP system avant la lettre (the term `inductive logic programming' was coined in 1990 by Muggleton [28]). MIS is an incremental top-down system that performs a complete breadth-first search of the space of possible clauses.
Reference: [41] <author> I. Stahl. </author> <title> Compression measures in ILP. </title> <booktitle> In [4], </booktitle> <address> pp.295307. </address>
Reference-contexts: Since they influence the posterior probability, they should be meaningful and justifiable. For instance, using a uniform prior distribution (all hypotheses are a priori equally likely) maybe technically simple but hard to justify. Compression-based heuristics. Finally, there is the compression approach <ref> [41] </ref>. The idea here is that the best hypothesis is the one which most compresses the data (for instance because the learner wants to transmit the examples over a communication channel in the most efficient way). One therefore compares the size of the examples with the size of the hypothesis.
Reference: [42] <author> L. Valiant. </author> <title> A theory of the learnable. </title> <journal> Comm. ACM 27:11341142, </journal> <year> 1984. </year> <month> 17 </month>
Reference-contexts: From this viewpoint induction of integrity constraints is more a descendant of one of the typical problems studied in computational learning theory, viz. learning arbitrary Boolean expressions from some of its satisfying and falsifying assignments <ref> [42, 1] </ref>. Secondly, there is often a close link between descriptive induction and nonmonotonic or closed-world reasoning, in that both involve some form of Closed World Assumption (CWA). However, the inductive CWA has a slightly different interpretation: `everything I haven't seen behaves like the things I have seen' [17].
References-found: 42

