URL: ftp://ftp.cs.brandeis.edu/pub/faculty/tim/Papers/fspn_exp.ps
Refering-URL: http://tigereye.cs.brandeis.edu/~tim/logic_programming/clp_papers.html
Root-URL: http://www.cs.brandeis.edu
Title: Fast, Sound and Precise Narrowing of the Exponential Function  
Author: Timothy Hickey and Qun Ju 
Date: March 13, 1996  
Address: Waltham MA, 02254  
Affiliation: Michtom School of Computer Science Volen Center for Complex Systems Brandeis University,  
Abstract: In this paper we present an algorithm for narrowing the constraint y = e x . The algorithm has been designed to be fast by using only IEEE multiplication. The main difficulty is to design algorithms which soundly, rapidly, and precisely compute upper and lower bounds on e x and ln(y). We prove that our algorithms are correct and produce upper and lower bounds which differ by at most 2 ULP. The method we describe is a modification of the standard range reduction algorithm found in the literature, but is considerably more complex due to the necessity of guaranteeing that the algorithm computes tight upper and lower bounds for all inputs x. The algorithm assumes that the arithmetic operations (+,-,*,/) are implemented in hardware and that rounding control can be specified by the user (e.g. the IEEE 754 specifications of single, double, and extended precision arithmetic all satisfy these assumptions). The bounds for exp and log are computed using the native floating point arithmetic to guarantee soundness and speed. Precision is attained by using precomputed tables of upper and lower bounds of the exponential and logarithm functions at predetermined points. Experiments reveal that in an experiment with N random inputs, the fraction which are 2 ULP apart is approximately N=2 M2 and our analysis suggests that in general this fraction will be inversely proportional to the size of the table. In the final remarks we discuss a method for extending this technique to the narrowing of the trigonometric and hyperbolic functions. fl This research was partially supported by NSF grant CCR-9403427
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bate, R. and Mueller, D. and White, J., </author> <title> Fundamentals of Astrodynamics. </title> <publisher> Dover, </publisher> <year> 1971. </year>
Reference-contexts: Consider now the case where jaj 2jfij. We may assume without loss of generality, that a &gt; 0 and fi &lt; 0. Again letting c = s (a + fi), we find that a c a=2 a c 0 Thus, we see that (c) 2 (a) + <ref> [0; 1] </ref> and (a c) (a) 1. Since (a c) (c) we must be able to represent a c with a fractional part of at most F bits and with the position of its last nonzero bit no smaller than (c). <p> on M ,B,and C are: F &gt; F E C B + 3 &gt; B E + 4 &gt; E 11 C E 1 M 3 D 52=(M 1) + 2 In our experiments, we selected C = 32 and B = 16 and let M range in the interval <ref> [1; 10] </ref>.
Reference: [2] <editor> Benhamou, F. and Older, W., </editor> <title> Applying interval arithmetic to real, integer, and boolean constraints. </title> <journal> Journal of Logic Programming, </journal> <note> (To Appear), </note> <year> 1994. </year>
Reference-contexts: These new CLP languages allow the user to solve complex arithmetic constraints involving not just the algebraic functions (+,-,*,/), but a wide range of other functions as well <ref> [2] </ref>.
Reference: [3] <author> Cohen, H. </author> <note> PARI reference manual 1996. </note>
Reference-contexts: The second drawback can be attacked by using the standard range reduction methods (described below), but the deleterious effect on the execution speed is unavoidable with this approach. The next simplest approach is to use a multiprecision arithmetic package such as PARI <ref> [3] </ref>. The main disadvantage of this approach is again that an unavoidable slowdown in execution speed will result since each multiprecision arithmetic operation requires several machine cycles to execute.
Reference: [4] <author> Colmerauer, A., </author> <title> Solving Equations and Inequations on Finite and Infinite Trees. </title> <booktitle> in Proceedings of the Conference on Fifth Generations Computer Systems, </booktitle> <editor> K.L. Clark and S.A. Tarnlund (eds.), </editor> <year> 1984. </year>
Reference: [5] <author> Colmerauer, A., </author> <title> An Introduction to Prolog III. </title> <journal> Communications of the ACM, </journal> <month> july </month> <year> 1990. </year>
Reference: [6] <author> Eckmann, J-P. and Wittwer, P., </author> <title> Computer Methods and Borel Summabil-ity Applied to Feigenbaum's Equation. Springer-Verlag, </title> <booktitle> Lecture Notes in Physics, </booktitle> <volume> 227, </volume> <year> 1985. </year>
Reference: [7] <institution> Computer Evaluation of Mathematical Functions Fike, </institution> <address> C.T. </address> <publisher> Prentice Hall Series in Automatic Computation, Prentic-Hall Inc., </publisher> <year> 1968. </year>
Reference-contexts: The main disadvantage of this approach is again that an unavoidable slowdown in execution speed will result since each multiprecision arithmetic operation requires several machine cycles to execute. Another approach is to simply use a standard numerical methods approach <ref> [7, 8] </ref> provided one can prove that the error in the computed result is at most k unites in the last place (ULP).
Reference: [8] <author> Gal S., </author> <title> Computing Elementary Functions: A New Approach for Achieving High Accuracy and Good Performance, in Accurate Scientific Computations, </title> <editor> (eds. Miranker, W.L., and Toupin, R.A.), </editor> <booktitle> Springer-Verlag Lecture Notes in Computer Science No. </booktitle> <volume> 235, </volume> <publisher> Springer-Verlag, </publisher> <year> 1985. </year>
Reference-contexts: The main disadvantage of this approach is again that an unavoidable slowdown in execution speed will result since each multiprecision arithmetic operation requires several machine cycles to execute. Another approach is to simply use a standard numerical methods approach <ref> [7, 8] </ref> provided one can prove that the error in the computed result is at most k unites in the last place (ULP).
Reference: [9] <author> Goldberg, D. </author> <title> What Every Computer Scientist Should Know About Floating-Point Arithmetic ACM Computing Surveys, </title> <journal> Vol. </journal> <volume> 23, No. 1, </volume> <year> 1991. </year>
Reference-contexts: Our goal in the following section is to show how to compute upper and lower bounds for these functions with a provably small error using the arithmetic operations as described by the IEEE standard. A good introduction to floating point arithmetic is Goldberg's survey <ref> [9] </ref>. 3.2 Overview of the IEEE 754 standard IEEE 754 is a standard for binary floating-point arithmetic, which specifies the precise layout in different precisions such as single and double precisions.
Reference: [10] <author> Hickey, T. </author> <title> CLP(F) and Constrained ODEs ECRC Technical report Proceedings of the Workshop and Constraints and Modelling Ithica, </title> <address> NY, </address> <year> 1994 </year>
Reference-contexts: 1 Introduction One of the most exciting advances in constraint logic programming over the last few years has been the incorporation of the relational interval arithmetic constraint solving algorithm in CLP systems (see CLP (BNR) [15] and CLP (F) <ref> [10] </ref>). These new CLP languages allow the user to solve complex arithmetic constraints involving not just the algebraic functions (+,-,*,/), but a wide range of other functions as well [2]. <p> on M ,B,and C are: F &gt; F E C B + 3 &gt; B E + 4 &gt; E 11 C E 1 M 3 D 52=(M 1) + 2 In our experiments, we selected C = 32 and B = 16 and let M range in the interval <ref> [1; 10] </ref>.
Reference: [11] <editor> IEEE standard 754-1985 for Binary Floating-Point Arithmetic IEEE. </editor> <booktitle> Reprinted in SIGPLAN 22(2), </booktitle> <pages> pp. 9-25, </pages> <year> 1985 </year>
Reference-contexts: For the narrowing of addition and multiplication, this is a relatively straightforward problem, since the IEEE 754 standard <ref> [11] </ref> for double precision arithmetic allows the user to specify the rounding mode for the primary operations (+,-,*,/) and the square root. In this paper we show how to implement a sound narrowing algorithm for constraint y = x x .
Reference: [12] <author> Jaffar, J. and Lassez, J. L., </author> <title> Constraint Logic Programming. </title> <booktitle> in Proceedings of the 14th ACM Symposium on the Principles of Programming Languages, </booktitle> <year> 1987. </year>
Reference: [13] <author> Jaffar, J. and Michaylov, S., </author> <title> Methodology and Implementation of a Con--straint Logic Programming System. </title> <booktitle> in Proceedings of the Fourth International Conference on Logic Programming, </booktitle> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference: [14] <author> Moore, R. E., </author> <title> Interval Analysis. </title> <publisher> Prentice-Hall, </publisher> <year> 1966. </year>
Reference-contexts: We consider three alternate approaches in this section. The easiest method to implement is to use a sound interval arithmetic package <ref> [14] </ref> to evaluate the Taylor polynomial (with a sound estimate of the remainder term) of the function f (x) being computed.
Reference: [15] <author> Older, W. and Vellino, A., </author> <title> Constraint Arithmetic on Real Intervals, in Constraint Logic Programming: Selected Research Colmerauer, </title> <editor> A. and Ben-hamou, F. (eds), </editor> <publisher> MIT Press 1993. </publisher>
Reference-contexts: 1 Introduction One of the most exciting advances in constraint logic programming over the last few years has been the incorporation of the relational interval arithmetic constraint solving algorithm in CLP systems (see CLP (BNR) <ref> [15] </ref> and CLP (F) [10]). These new CLP languages allow the user to solve complex arithmetic constraints involving not just the algebraic functions (+,-,*,/), but a wide range of other functions as well [2].
References-found: 15

