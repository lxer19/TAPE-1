URL: http://www.cs.Helsinki.FI/research/pmdm/datamining/pubs/C-1996-7.ps.gz
Refering-URL: http://www.cs.helsinki.fi/~ronkaine/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Rule Discovery in Alarm Databases  
Author: Kimmo Hatonen, Mika Klemettinen, Heikki Mannila, Pirjo Ronkainen, Hannu Toivonen P. O. Box (Teollisuuskatu ) 
Address: Helsinki, Finland  
Date: Helsinki, March 1996  
Note: Series of Publications C, No. C-1996-7  The papers in the series are intended for internal use and are distributed by the author. Copies may be ordered from the library  
Affiliation: University of Helsinki Department of Computer Science  Department of Computer Science  University of  of Department of Computer Science.  
Pubnum: FIN-00014  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Rakesh Agrawal, Heikki Mannila, Ramakrishnan Srikant, Hannu Toivo-nen, and A. Inkeri Verkamo. </author> <title> Fast discovery of association rules. </title> <editor> In Usama M. Fayyad, Gregory Piatetsky-Shapiro, Padhraic Smyth, and Ramasamy Uthurusamy, editors, </editor> <booktitle> Advances in Knowledge Discovery and Data Mining, </booktitle> <pages> pages 307 - 328. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1996. </year>
Reference-contexts: The algorithm for discovering episodes is presented in more detail in [16] for a slightly simpler setting; the association rule algorithm is presented in more detail, e.g., in <ref> [1, 15] </ref>. The episode rule discovery task in the TASA system can be formalized as follows (see Figure 4).
Reference: [2] <author> Elja Arjas, Heikki Mannila, Marko Salmenkivi, Riikka Suramo, and Hannu Toivonen. BASS: </author> <title> Bayesian analysis of event sequences. </title> <booktitle> In XII Symposium on Computational Statistics (COMPSTAT'96), </booktitle> <address> Barcelona, Spain, </address> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: Comprehensibility: such rules are easy to understand. 1 We are, however, experimenting on Markov Chain Monte Carlo methods for Bayesian analysis of alarm data <ref> [2] </ref>. 4 2. Characteristics of the domain: such rules can be representations of simple small causal relationships. 3.
Reference: [3] <author> Ronald J. Brachman, Peter G. Selfridge, Loren G. Terveen, Boris Alt-man, Alex Borgida, Fern Halper, Thomas Kirk, Alan Lazar, Doborah L. McGuinness, and Lori Alperin Resnick. </author> <title> Integrated support for data archaeology. In Knowledge Discovery in Databases, </title> <booktitle> Papers from the 1993 AAAI Workshop (KDD'93), </booktitle> <pages> pages 197 - 211, </pages> <address> Washington, D.C., </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Putting the discovered knowledge into use. The TASA system incorporates components for two parts of the KDD process: pattern discovery (or data mining) and presentation of the knowledge. KDD is an iterative and interactive process <ref> [3, 4] </ref>. No realistic KDD system can be expected to discover useful knowledge without interaction with the user: knowing the interests and using the background knowledge of users is vital for succesful knowledge discovery.
Reference: [4] <author> Usama M. Fayyad, Gregory Piatetsky-Shapiro, and Padhraic Smyth. </author> <title> From data mining to knowledge discovery: An overview. </title> <editor> In Usama M. Fayyad, Gregory Piatetsky-Shapiro, Padhraic Smyth, and Ramasamy Uthurusamy, editors, </editor> <booktitle> Advances in Knowledge Discovery and Data Mining, pages 1 -34. </booktitle> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1996. </year>
Reference-contexts: Putting the discovered knowledge into use. The TASA system incorporates components for two parts of the KDD process: pattern discovery (or data mining) and presentation of the knowledge. KDD is an iterative and interactive process <ref> [3, 4] </ref>. No realistic KDD system can be expected to discover useful knowledge without interaction with the user: knowing the interests and using the background knowledge of users is vital for succesful knowledge discovery.
Reference: [5] <editor> Usama M. Fayyad, Gregory Piatetsky-Shapiro, Padhraic Smyth, and Ramasamy Uthurusamy, editors. </editor> <booktitle> Advances in Knowledge Discovery and Data Mining. </booktitle> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1996. </year>
Reference-contexts: In this article we consider the use of knowledge discovery methods to automatically find useful patterns in the alarms. Knowledge discovery in databases (KDD), also called data mining, has recently attracted a lot of interest in the database community (for overviews, see <ref> [5, 19] </ref>). KDD can be loosely defined as the task of obtaining useful and interesting knowledge from large collections of data. It combines methods and tools from machine learning, statistics, and databases. We use novel KDD methods to discover effectively very large sets of rules from alarm databases.
Reference: [6] <author> J. Goldman, P. Hong, C. Jeromnimon, G. Louit, J. Min, and P. Sen. </author> <title> Integrated fault management in interconnected networks. </title> <editor> In B. Meandz-ija and J. Westcott, editors, </editor> <title> Integrated Network Management, </title> <booktitle> I, </booktitle> <pages> pages 333 - 344. </pages> <publisher> Elsevier, </publisher> <year> 1989. </year>
Reference-contexts: software: how to show the data to the users so that the appropriate decisions can be made. 1 To alleviate the risk of overlooking important alarms or misinterpret-ing them, filtering and correlation methods are used to reduce the number of messages shown and to improve their information content (see, e.g., <ref> [6, 7, 9, 10, 11, 18] </ref>). For this one needs knowledge about the alarms and their interrelationships, and filtering and correlation systems are often implemented as expert systems with carefully hand-crafted knowledge bases.
Reference: [7] <author> R. M. Goodman, B. E. Ambrose, H. W. Latin, and C. T. Ulmer. </author> <title> Noaa an expert system managing the telephone network. </title> <booktitle> In Integrated Network Management IV, </booktitle> <pages> pages 316 - 327. </pages> <publisher> Chapman & Hall, </publisher> <address> London, </address> <year> 1995. </year>
Reference-contexts: software: how to show the data to the users so that the appropriate decisions can be made. 1 To alleviate the risk of overlooking important alarms or misinterpret-ing them, filtering and correlation methods are used to reduce the number of messages shown and to improve their information content (see, e.g., <ref> [6, 7, 9, 10, 11, 18] </ref>). For this one needs knowledge about the alarms and their interrelationships, and filtering and correlation systems are often implemented as expert systems with carefully hand-crafted knowledge bases.
Reference: [8] <author> R. M. Goodman and H. </author> <title> Latin. Automated knowledge acquisition from network management databases. </title> <editor> In I. Krishnan and W. Zimmer, editors, </editor> <title> Integrated Network Management, </title> <booktitle> II, </booktitle> <pages> pages 541 - 549. </pages> <publisher> Elsevier Science Publishers B.V (North-Holland), </publisher> <address> Amsterdam, </address> <year> 1991. </year>
Reference-contexts: We then use iterative information retrieval methods to examine interactively the discovered rules and to find the most interesting and useful ones. A related algorithm for discovering rules from alarms has been presented in <ref> [8] </ref>. Patterns discovered in an alarm database can be useful in several ways. They can be employed in real time alarm handling software for filtering uninformative alarms, for correlating alarms to construct hypothesis of faults, or for prediction of faults.
Reference: [9] <author> Gabriel Jakobson and Mark Weissman. </author> <title> Real-time telecommunication network management: Extending event correlation with temporal constraints. </title> <booktitle> In Integrated Network Management IV, </booktitle> <pages> pages 290 - 301. </pages> <publisher> Chap-man & Hall, </publisher> <address> London, </address> <year> 1995. </year>
Reference-contexts: software: how to show the data to the users so that the appropriate decisions can be made. 1 To alleviate the risk of overlooking important alarms or misinterpret-ing them, filtering and correlation methods are used to reduce the number of messages shown and to improve their information content (see, e.g., <ref> [6, 7, 9, 10, 11, 18] </ref>). For this one needs knowledge about the alarms and their interrelationships, and filtering and correlation systems are often implemented as expert systems with carefully hand-crafted knowledge bases.
Reference: [10] <author> Gabriel Jakobson and Mark D. Weissman. </author> <title> Alarm correlation. </title> <journal> IEEE Network, </journal> <volume> 7(6):52 - 59, </volume> <month> November </month> <year> 1993. </year>
Reference-contexts: software: how to show the data to the users so that the appropriate decisions can be made. 1 To alleviate the risk of overlooking important alarms or misinterpret-ing them, filtering and correlation methods are used to reduce the number of messages shown and to improve their information content (see, e.g., <ref> [6, 7, 9, 10, 11, 18] </ref>). For this one needs knowledge about the alarms and their interrelationships, and filtering and correlation systems are often implemented as expert systems with carefully hand-crafted knowledge bases.
Reference: [11] <author> J. F. Jordaan and M. E. Paterok. </author> <title> Event correlation in heteroge-nous networks using OSI management framework. </title> <editor> In H.-G. Hegering and Y. Yemini, editors, </editor> <title> Integrated Network Management, </title> <booktitle> III, </booktitle> <pages> pages 683 - 695. </pages> <publisher> Elsevier Science Publishers B.V (North-Holland), </publisher> <address> Amster-dam, </address> <year> 1993. </year>
Reference-contexts: software: how to show the data to the users so that the appropriate decisions can be made. 1 To alleviate the risk of overlooking important alarms or misinterpret-ing them, filtering and correlation methods are used to reduce the number of messages shown and to improve their information content (see, e.g., <ref> [6, 7, 9, 10, 11, 18] </ref>). For this one needs knowledge about the alarms and their interrelationships, and filtering and correlation systems are often implemented as expert systems with carefully hand-crafted knowledge bases.
Reference: [12] <author> J. D. Kalbfleisch and R. L. Prentice. </author> <title> The Statistical Analysis of Failure Time Data. </title> <publisher> John Wiley Inc., </publisher> <address> New York, NY, </address> <year> 1980. </year> <month> 17 </month>
Reference-contexts: This rules out the simple-minded use of neural networks. Other possible methods include viewing an alarm sequence as a marked point process and using the hazard rate based methods of analysis of failure-time data <ref> [12] </ref>. Combined with the Bayesian paradigm, the statistical machinery for these types of models is very powerful, and elaborate simulation mechanisms exist for their analysis (e.g., the EM and Gibbs methods, see [21]).
Reference: [13] <author> Mika Klemettinen, Heikki Mannila, Pirjo Ronkainen, Hannu Toivonen, and A. Inkeri Verkamo. </author> <title> Finding interesting rules from large sets of discovered association rules. </title> <booktitle> In Proceedings of the Third International Conference on Information and Knowledge Management (CIKM'94), </booktitle> <pages> pages 401 - 407, </pages> <address> Gaithersburg, MD, </address> <month> November </month> <year> 1994. </year> <note> ACM. </note>
Reference-contexts: The point of focus can be changed by selecting or removing rules with templates <ref> [13] </ref>. Templates are simple regular expressions that describe, in 12 terms of alarm predicates, the form of rules that are to be selected (inclusive template) or removed (restrictive template). This simple technique is surprisingly powerful.
Reference: [14] <author> Willi Klosgen. </author> <title> Efficient discovery of interesting statements in databases. </title> <journal> Journal of Intelligent Information Systems, </journal> <volume> 4(1):53 - 69, </volume> <year> 1995. </year>
Reference-contexts: What is interesting varies from one situation to another. The interestingness criteria | such as what is on the right-hand sides of the rules, or how significant the rules should be | are in many KDD systems given as inputs to the pattern extraction process <ref> [14, 20] </ref>. If the user wants to change his or her point of view, the data has to be analyzed anew. This can require a lot of computational effort and cause delays in the KDD process.
Reference: [15] <author> Heikki Mannila, Hannu Toivonen, and A. Inkeri Verkamo. </author> <title> Efficient algorithms for discovering association rules. </title> <editor> In Usama M. Fayyad and Ramasamy Uthurusamy, editors, </editor> <booktitle> Knowledge Discovery in Databases, Papers from the 1994 AAAI Workshop (KDD'94), </booktitle> <pages> pages 181 - 192, </pages> <address> Seattle, Washington, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: The algorithm for discovering episodes is presented in more detail in [16] for a slightly simpler setting; the association rule algorithm is presented in more detail, e.g., in <ref> [1, 15] </ref>. The episode rule discovery task in the TASA system can be formalized as follows (see Figure 4). <p> Therefore, the candidate collection C i of episodes is built (Step 5) to contain only episodes whose all subepisodes occur often enough. For more details, see [16]. To find frequent predicate sets, essentially the same algorithm and the same observation hold <ref> [15] </ref>. Candidates are now sets of predicates, and instead of considering the alarm database as a sequence, it is seen as a set of alarms. In Step 4, "recognition", for each candidate set the number of satisfying alarms is computed and compared to the frequency threshold. <p> In Step 4, "recognition", for each candidate set the number of satisfying alarms is computed and compared to the frequency threshold. In Step 5, "building", new candidate sets are constructed such that every subset of a candidate set is frequent. For more details, see <ref> [15] </ref>. We have analyzed with these methods alarm databases from different fixed and cellular networks. Running times on a Pentium-based PC range from few seconds to an hour, depending on the database and the parameters.
Reference: [16] <author> Heikki Mannila, Hannu Toivonen, and A. Inkeri Verkamo. </author> <title> Discovering frequent episodes in sequences. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Discovery and Data Mining (KDD'95), </booktitle> <pages> pages 210 - 215, </pages> <address> Montreal, Canada, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: In association rules, in turn, a large variety of predicates can be useful. 5 Discovering all rules In this section we outline the algorithms that are used in TASA to discover all rules satisfying the user-given conditions. The algorithm for discovering episodes is presented in more detail in <ref> [16] </ref> for a slightly simpler setting; the association rule algorithm is presented in more detail, e.g., in [1, 15]. The episode rule discovery task in the TASA system can be formalized as follows (see Figure 4). <p> Given S, E, E, W , and c as above, find the frequencies of all episodes from E such that the frequency is at least 9 c. The following algorithm will output all such episodes <ref> [16] </ref>. 1. <p> If an episode does not occur often enough, then its superepisodes | which are more specific | cannot occur often enough. Therefore, the candidate collection C i of episodes is built (Step 5) to contain only episodes whose all subepisodes occur often enough. For more details, see <ref> [16] </ref>. To find frequent predicate sets, essentially the same algorithm and the same observation hold [15]. Candidates are now sets of predicates, and instead of considering the alarm database as a sequence, it is seen as a set of alarms.
Reference: [17] <author> R. Milne, C. Nicol, M. Ghallab, L. Trave-Massuyes, K. Bousson, C. Dousson, J. Quevedo, J. Aguilar, and A. Guasch. TIGER: </author> <title> real-time situation assessment of dynamic systems. </title> <journal> Intelligent Systems Engineering, </journal> <volume> (Autumn):103 - 124, </volume> <year> 1994. </year>
Reference-contexts: The discovered patterns can also help to reveal anomalies in the behaviour of the network. Similar approaches have been used successfully in process control tasks <ref> [17] </ref>. The ideas expressed in this article have been implemented in the TASA (Telecommunication Network Alarm Sequence Analyzer) system for discovering knowledge from large alarm databases.
Reference: [18] <author> Y. A. Nygate. </author> <title> Event correlation using rule and object based techniques. </title> <booktitle> In Integrated Network Management IV, </booktitle> <pages> pages 278 - 289. </pages> <publisher> Chapman & Hall, </publisher> <address> London, </address> <year> 1995. </year>
Reference-contexts: software: how to show the data to the users so that the appropriate decisions can be made. 1 To alleviate the risk of overlooking important alarms or misinterpret-ing them, filtering and correlation methods are used to reduce the number of messages shown and to improve their information content (see, e.g., <ref> [6, 7, 9, 10, 11, 18] </ref>). For this one needs knowledge about the alarms and their interrelationships, and filtering and correlation systems are often implemented as expert systems with carefully hand-crafted knowledge bases.
Reference: [19] <editor> Gregory Piatetsky-Shapiro and William J. Frawley, editors. </editor> <title> Knowledge Discovery in Databases. </title> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1991. </year>
Reference-contexts: In this article we consider the use of knowledge discovery methods to automatically find useful patterns in the alarms. Knowledge discovery in databases (KDD), also called data mining, has recently attracted a lot of interest in the database community (for overviews, see <ref> [5, 19] </ref>). KDD can be loosely defined as the task of obtaining useful and interesting knowledge from large collections of data. It combines methods and tools from machine learning, statistics, and databases. We use novel KDD methods to discover effectively very large sets of rules from alarm databases.
Reference: [20] <author> Gregory Piatetsky-Shapiro and Christopher J. Matheus. </author> <title> The interestingness of deviations. </title> <editor> In Usama M. Fayyad and Ramasamy Uthurusamy, editors, </editor> <booktitle> Knowledge Discovery in Databases, Papers from the 1994 AAAI Workshop (KDD'94), </booktitle> <pages> pages 25 - 36, </pages> <address> Seattle, Washington, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: What is interesting varies from one situation to another. The interestingness criteria | such as what is on the right-hand sides of the rules, or how significant the rules should be | are in many KDD systems given as inputs to the pattern extraction process <ref> [14, 20] </ref>. If the user wants to change his or her point of view, the data has to be analyzed anew. This can require a lot of computational effort and cause delays in the KDD process. <p> Note that the episode rule formalism does not capture the details of such relationships. User interface For the user interface system we have adopted the method used in <ref> [20] </ref>: we have based the implementation of the rule browsing system on the use of the HTML language and standard WWW browsers for HTML documents. This gives several immediate benefits, both in terms of added functionality and in terms of ease of implementation.
Reference: [21] <author> Martin A. Tanner. </author> <title> Tools for Statistical Inference | Methods for the Exploration of Posterior Distributions and Likelihood Functions. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1993. </year> <month> 18 </month>
Reference-contexts: Combined with the Bayesian paradigm, the statistical machinery for these types of models is very powerful, and elaborate simulation mechanisms exist for their analysis (e.g., the EM and Gibbs methods, see <ref> [21] </ref>). However, these methods require a lot of human effort in building the statistical models, as well as enormous amounts of computational resources.
Reference: [22] <author> Hannu Toivonen, Mika Klemettinen, Pirjo Ronkainen, Kimmo Hatonen, and Heikki Mannila. </author> <title> Pruning and grouping of discovered association rules. </title> <booktitle> In Workshop Notes of the ECML-95 Workshop on Statistics, Machine Learning, and Knowledge Discovery in Databases, </booktitle> <pages> pages 47 - 52, </pages> <address> Heraklion, Crete, Greece, </address> <month> April </month> <year> 1995. </year> <month> 19 </month>
Reference-contexts: Clustering methods can be used to assign rules to groups so that two rules with right-hand side link unavailable belong to the same cluster if they often explain or predict link unavailable in similar situations <ref> [22] </ref>. This can be useful in pointing out potentially related rules. For visualization the TASA system offers some simple facilities.
References-found: 22

