URL: http://dimacs.rutgers.edu/~dbwilson/exact.html/haggstrom-nelander.ps.gz
Refering-URL: http://dimacs.rutgers.edu/~dbwilson/exact.html/
Root-URL: http://www.cs.rutgers.edu
Title: Exact sampling from anti-monotone systems  
Author: Olle Hggstrm Karin Nelander 
Date: February 4, 1997  
Affiliation: Chalmers University of Technology and University of Gteborg  
Abstract: A new approach to Markov chain Monte Carlo simulation was recently proposed by Propp and Wilson. This approach, unlike traditional ones, yields samples which have exactly the desired distribution. The Propp Wilson algorithm requires this distribution to have a certain structure called monotonicity. In this paper, it is shown how the algorithm can be extended to the case where monotonicity is replaced by anti-monotonicity. As illustrating examples, simulations of the hard-core model and the random cluster model are presented.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Asmussen, S., Glynn, P.W. and Thorisson, H. </author> <title> (1992) Stationary detection in the initial transient problem, </title> <journal> ACM Trans. Model. Comp. Simul. </journal> <volume> 2, 130157. </volume> <editor> [2] van den Berg, J. </editor> <title> (1993) A uniqueness condition for Gibbs measures, with application to the 2-dimensional Ising antiferromagnet, </title> <journal> Commun. Math. Phys. </journal> <volume> 152, 161166. </volume> <editor> [3] van den Berg, J. and Steif, J. </editor> <title> (1994) Percolation and the hard core lattice gas model, </title> <journal> Stoch. Proc. Appl. </journal> <volume> 49, </volume> <pages> 179197. </pages>
Reference-contexts: The trst such algorithm is due to Asmussen et al. <ref> [1] </ref>, and has been followed by 1 other, simpler, algorithms e.g. in [20] (see [27] for a short survey). <p> Each edge can be in one of the states 0 and 1, where a 1 (resp. 0) represents the presence (resp. absence) of an edge. The random-cluster measure 4 p;q G for G with parameters p 2 <ref> [0; 1] </ref> and q &gt; 0 is the probability measure on the set of subgraphs of G given by p;q 1 G Y p (e) (1 p) 1 (e) q k () for all 2 f0; 1g E . <p> the new state of the chain, X t+1 , is obtained from the old, X t , using the following rules: X t+1 (w) = X t (w) for w 6= v D This can be realized concretely by letting U t be an independent random variable uniformly distributed on <ref> [0; 1] </ref>, and setting X t+1 (v) = maxfs 2 S : (X (v) s j X (V n fvg)) U t g: The resulting Markov chain fX t g is ergodic if it satistes the following conditions: (i ) the set of elements of S V that have positive -measure <p> Let fU t g t=0;1;2;::: and fW t g t=0;1;2;::: be independent i.i.d. sequences such that U t is uniformly distributed on <ref> [0; 1] </ref> and W t is equidistributed on V . If the chain at time t is in state ~ 2 S V , let the next state be given by (~; U t ; W t ), where the 6 (deterministic) function : S V fi [0; 1] fi V <p> uniformly distributed on <ref> [0; 1] </ref> and W t is equidistributed on V . If the chain at time t is in state ~ 2 S V , let the next state be given by (~; U t ; W t ), where the 6 (deterministic) function : S V fi [0; 1] fi V ! S V is detned by letting (~; u; w) equal ~ at all locations except w, where it gets value maxfs 2 S : ( X (w) s j X (V n fwg) = ~(V n fwg) ) ug: This yields transition probabilities identical to those <p> In order to make this more precise, we trst generalize to the function ~ : S V fi S V fi <ref> [0; 1] </ref> fi V ! S V by letting ~ (~; ~ 0 ; u; w) equal ~ at all locations except at w, where it gets value maxfs 2 S : (X (w) s j X (V n fwg) = ~ 0 (V n fwg)) ug: Note that ~ (~;
Reference: [4] <author> Fortuin, C.M. and Kasteleyn, P.W. </author> <title> (1972) On the random-cluster model.. I. Introduction and relation to other models, </title> <journal> Physica 57, </journal> <volume> 536564. </volume>
Reference-contexts: Example 1.3: The q &lt; 1 random-cluster model. Another name for the random-cluster model is the FK model after its inventors Fortuin and Kasteleyn <ref> [4] </ref> (see e.g. [11] and [13] for up-to-date discussions). The model lives on the edge set rather than the vertex set of G, and should be thought of as dealing with random subsets of E.
Reference: [5] <author> Gelman, A. and Rubin, </author> <title> D.B. (1992) Inference from iterative simulation using multiple sequences (with discussion), </title> <journal> Statist. Sci. </journal> <volume> 7, 457472 and 483511. </volume>
Reference-contexts: For this reason, much of today's Markov chain Monte Carlo practice lacks rigorous theoretical justitcation. This is of course highly unsatisfactory, and has even caused some controversy (see e.g. the tandem discussion papers <ref> [5] </ref> and [8]).
Reference: [6] <author> Geman, S. and Geman, D. </author> <title> (1984) Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images, </title> <journal> IEEE Trans. Pattern Anal. Machine Intelligence 6, </journal> <volume> 721741. </volume>
Reference-contexts: It is the most famous and frequently used of all Markov chain Monte Carlo algorithms. Its name was introduced by Geman and Geman <ref> [6] </ref>, who used it for analysing Gibbs distributions on lattices. In statistical physics the method is also known as the heat bath algorithm. As declared in the introduction, we are interested in drawing samples from , where is a probability measure on S V .
Reference: [7] <author> Georgii, H-O. </author> <title> (1988) Gibbs Measures and Phase Transitions, </title> <publisher> de Gruyter, </publisher> <address> New York. </address>
Reference-contexts: In all of the examples, the most common choice of G is a large portion of the cubic lattice Z d , with edges connecting nearest neighbours. Example 1.1: The hard-core model. The hard-core model (see e.g. <ref> [7] </ref> and [3]) was introduced in statistical mechanics as a crude model for a gas whose particles have non-negligible radii. It has also been studied in operations research, where it arises in the study of certain communication networks [15]. <p> Example 1.2: The Ising antiferromagnet. One of the most studied models in statistical mechanics is the Ising model, in which each vertex v of G can be in state 1 or 1 (see e.g. <ref> [7] </ref> and [18] for general discussions). In the original interpretation of the model, the vertices are thought of as atoms, and the two states represent two dierent spin orientations. A number of other interpretations have since been suggested in various physical and engineering contexts. <p> Both simulations were carried out on a 50fi50 lattice. The longer running times for large a may also be related to the phase transition phenomenon which occurs for large a, see e.g. Georgii <ref> [7] </ref>. In the systems studied so far, every interior vertex had 4 neighbours (north, south, east and west). This makes the graph bipartite, so these 4-neighbour systems can be translated into monotone systems by the arguments in Section 3.
Reference: [8] <author> Geyer, C.J. </author> <year> (1992), </year> <title> Practical Markov chain Monte Carlo (with discussion), </title> <journal> Statist. Sci. </journal> <volume> 7, </volume> <pages> 473511. </pages>
Reference-contexts: For this reason, much of today's Markov chain Monte Carlo practice lacks rigorous theoretical justitcation. This is of course highly unsatisfactory, and has even caused some controversy (see e.g. the tandem discussion papers [5] and <ref> [8] </ref>).
Reference: [9] <author> Gilks, W.R., Richardson, S. and Spiegelhalter, </author> <title> D.J. (1996) Markov Chain Monte Carlo in Practice, </title> <publisher> Chapman and Hall, London. </publisher>
Reference-contexts: 1. Introduction In many situations, it is important to be able to sample from some, often very complicated, multivariate probability distribution . One approach is the Markov chain Monte Carlo method, which originates from statistical mechanics [21] and which currently is very fashionable in statistics <ref> [9] </ref>. The idea is to detne an ergodic Markov chain with stationary distribution , to start the chain in some arbitrary state, to run it for a long time, and to output the tnal state.
Reference: [10] <author> Grimmett, G. </author> <title> (1989) Percolation, </title> <publisher> Springer, </publisher> <address> New York. </address> <month> 21 </month>
Reference-contexts: By means of the self-duality of the quadratic lattice (well known in percolation theory; see <ref> [10] </ref>), one can argue intuitively that approximately half of the edges will be present in these graphs, although with dierent dependence structures for the dierent values of p and q. Let us now study Figure 4. It contains four examples of random-cluster models on a 70fi70 lattice.
Reference: [11] <author> Grimmett, G. </author> <title> (1995) The stochastic random-cluster process, and the unique-ness of random-cluster measures, </title> <journal> Ann. Probab. </journal> <volume> 23, </volume> <pages> 14611510. </pages>
Reference-contexts: Example 1.3: The q &lt; 1 random-cluster model. Another name for the random-cluster model is the FK model after its inventors Fortuin and Kasteleyn [4] (see e.g. <ref> [11] </ref> and [13] for up-to-date discussions). The model lives on the edge set rather than the vertex set of G, and should be thought of as dealing with random subsets of E. <p> Hence, the random-cluster model is monotone when q 1 and anti-monotone when q 1. The random-cluster model is reasonably well understood in the monotone regime of the parameter space, but much less so in the anti monotone regime (although see <ref> [11] </ref> and [12] for some results). 2. The algorithms 2.1. The Gibbs sampler A building block of the ProppWilson algorithm, as well as of our moditcation, is the so called Gibbs sampler which we now go on to describe.
Reference: [12] <author> Hggstrm, O. </author> <title> (1995) Random-cluster measures and uniform spanning trees, </title> <journal> Stoch. Proc. Appl. </journal> <volume> 59, </volume> <pages> 267275. </pages>
Reference-contexts: Hence, the random-cluster model is monotone when q 1 and anti-monotone when q 1. The random-cluster model is reasonably well understood in the monotone regime of the parameter space, but much less so in the anti monotone regime (although see [11] and <ref> [12] </ref> for some results). 2. The algorithms 2.1. The Gibbs sampler A building block of the ProppWilson algorithm, as well as of our moditcation, is the so called Gibbs sampler which we now go on to describe. <p> The structure is notably more ordered than in the two contgurations above. There is even more order in the last of the four pictures. It is a realization from the uniform spanning tree measure, which arises in the limit of q ! 0 on the self-dual curve (see <ref> [12] </ref>). The contguration was produced using the famous random walk algorithm described e.g. in [22] and implemented by Segerberg [24]. As opposed to in the hard-core model, the evaluation of the conditional probabilities in the random-cluster model is computationally non-trivial.
Reference: [13] <author> Hggstrm, O. </author> <title> (1996) Random-cluster representations in the study of phase transitions, </title> <type> preprint. </type>
Reference-contexts: Example 1.3: The q &lt; 1 random-cluster model. Another name for the random-cluster model is the FK model after its inventors Fortuin and Kasteleyn [4] (see e.g. [11] and <ref> [13] </ref> for up-to-date discussions). The model lives on the edge set rather than the vertex set of G, and should be thought of as dealing with random subsets of E.
Reference: [14] <author> Hggstrm, O., van Lieshout, M.N.M. and Mller, J. </author> <title> (1996) Characterisation results and Markov chain Monte Carlo algorithms including exact simulation for some spatial point processes, </title> <type> preprint. </type>
Reference-contexts: This monotonicity structure does hold for many important models, such as the ferromagnetic Ising and Potts models and certain random tilings. The ProppWilson algorithm provides the trst computationally tractable way of obtaining unbiased samples from these models. In Kendall [16] and Hggstrm et al. <ref> [14] </ref>, the algorithm has also been successfully adapted to point process settings (this direction is currently being pursued further in [17]). The ProppWilson algorithm will be carefully described in Section 2. It is based on so called coupling-from-the-past.
Reference: [15] <author> Kelly, </author> <title> F.P. (1985) Stochastic models of computer communication systems, </title> <journal> J. Roy. Statist. Soc. Ser. </journal> <volume> B 47, </volume> <pages> 379395. </pages>
Reference-contexts: Example 1.1: The hard-core model. The hard-core model (see e.g. [7] and [3]) was introduced in statistical mechanics as a crude model for a gas whose particles have non-negligible radii. It has also been studied in operations research, where it arises in the study of certain communication networks <ref> [15] </ref>. Each vertex of the graph G can be in one of two states, 0 and 1. In the gas interpretation of the model, a 1 represents the presence of a particle at a vertex, and a 0 means that the vertex is not occupied by a particle.
Reference: [16] <author> Kendall, W. </author> <title> (1996) Perfect simulation for the area-interaction point process, </title> <booktitle> Proceedings of the Symposium on Probability towards the year 2000, </booktitle> <editor> (L. Accardi and C. Heyde, eds), </editor> <address> Springer, </address> <note> to appear. </note>
Reference-contexts: This monotonicity structure does hold for many important models, such as the ferromagnetic Ising and Potts models and certain random tilings. The ProppWilson algorithm provides the trst computationally tractable way of obtaining unbiased samples from these models. In Kendall <ref> [16] </ref> and Hggstrm et al. [14], the algorithm has also been successfully adapted to point process settings (this direction is currently being pursued further in [17]). The ProppWilson algorithm will be carefully described in Section 2. It is based on so called coupling-from-the-past. <p> Our contribution is to demonstrate how the ProppWilson algorithm, via a simple moditcation, can be used for discrete systems which are anti-monotone rather than monotone. The moditcation is based on an idea that Kendall <ref> [16] </ref> came up with in a point process context. The anti-monotone setting contains several interesting and important examples, such as the hard-core model and the Ising antiferromagnet. <p> The idea for anti-monotone systems is to have the two chains look at each other's contgurations on V nfwg, rather than their own, when updating the value at w. A similar exchange of contgurations appears in an algorithm of Kendall <ref> [16] </ref> for simulation of a certain class of spatial point processes.
Reference: [17] <author> Kendall, W. and Mller, J. </author> <title> (1997) Perfect MetropolisHastings simulation of locally stable spatial point processes, </title> <note> in preparation. </note>
Reference-contexts: The ProppWilson algorithm provides the trst computationally tractable way of obtaining unbiased samples from these models. In Kendall [16] and Hggstrm et al. [14], the algorithm has also been successfully adapted to point process settings (this direction is currently being pursued further in <ref> [17] </ref>). The ProppWilson algorithm will be carefully described in Section 2. It is based on so called coupling-from-the-past. By a coupling, we here mean the joint construction of two or more realizations of the Markov chain; see [19] for a broad treatment of coupling methods in probability theory.
Reference: [18] <author> Liggett, </author> <title> T.M. (1985) Interacting Particle Systems, </title> <publisher> Springer, </publisher> <address> New York. </address>
Reference-contexts: We believe that the need for ecient simulation algorithms may be even greater for anti-monotone than for monotone systems, the reason being the following. For monotone systems, several powerful mathematical tools, such as Holley's Theorem and the FKG inequalities, are available (see Section II.2 of <ref> [18] </ref> for an overview). At present, these tools do not have counterparts for anti-monotone systems. Therefore, it is more dicult to obtain theoretical results for anti-monotone systems, for which one thus has to resort to computer simulations to a larger extent. <p> Example 1.2: The Ising antiferromagnet. One of the most studied models in statistical mechanics is the Ising model, in which each vertex v of G can be in state 1 or 1 (see e.g. [7] and <ref> [18] </ref> for general discussions). In the original interpretation of the model, the vertices are thought of as atoms, and the two states represent two dierent spin orientations. A number of other interpretations have since been suggested in various physical and engineering contexts.
Reference: [19] <author> Lindvall, T. </author> <title> (1992) Lectures on the Coupling Method, </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: The ProppWilson algorithm will be carefully described in Section 2. It is based on so called coupling-from-the-past. By a coupling, we here mean the joint construction of two or more realizations of the Markov chain; see <ref> [19] </ref> for a broad treatment of coupling methods in probability theory.
Reference: [20] <author> Lovsz, L. and Winkler, P. </author> <title> (1995) Exact mixing in an unknown Markov chain, </title> <institution> Electr. </institution> <note> J. Combinatorics 2, paper #R15. </note>
Reference-contexts: The trst such algorithm is due to Asmussen et al. [1], and has been followed by 1 other, simpler, algorithms e.g. in <ref> [20] </ref> (see [27] for a short survey). These algo-rithms work for any irreducible tnite state Markov chain, but have astronomical running times for all but the very simplest chains (i.e. those with very few states) and are therefore of limited practical value.
Reference: [21] <author> Metropolis, N., Rosenbluth, A.W., Rosenbluth, M.N., Teller, A.H. and Teller, E. </author> <title> (1953) Equations of state calculations by fast computing machine, </title> <journal> J. Chem. Phys. </journal> <volume> 21, </volume> <pages> 10871091. </pages>
Reference-contexts: 1. Introduction In many situations, it is important to be able to sample from some, often very complicated, multivariate probability distribution . One approach is the Markov chain Monte Carlo method, which originates from statistical mechanics <ref> [21] </ref> and which currently is very fashionable in statistics [9]. The idea is to detne an ergodic Markov chain with stationary distribution , to start the chain in some arbitrary state, to run it for a long time, and to output the tnal state.
Reference: [22] <author> Pemantle, R. </author> <title> (1995) Uniform random spanning trees, Topics in Contemporary Probability and its Applications (ed. </title> <journal> J.L. Snell), </journal> <volume> 154, </volume> <publisher> CRC, </publisher> <address> Boca Raton. </address>
Reference-contexts: It is a realization from the uniform spanning tree measure, which arises in the limit of q ! 0 on the self-dual curve (see [12]). The contguration was produced using the famous random walk algorithm described e.g. in <ref> [22] </ref> and implemented by Segerberg [24]. As opposed to in the hard-core model, the evaluation of the conditional probabilities in the random-cluster model is computationally non-trivial. We have used a slightly simplited version of an algorithm by Sweeny [25] to determine the connectivity necessary to evaluate (1.2).
Reference: [23] <author> Propp, J.G. and Wilson, </author> <title> D.B. (1996) Exact sampling with coupled Markov chains and applications to statistical mechanics, Random Structures Algorithms 9, </title> <type> 223252. </type>
Reference-contexts: These algo-rithms work for any irreducible tnite state Markov chain, but have astronomical running times for all but the very simplest chains (i.e. those with very few states) and are therefore of limited practical value. In contrast, Propp and Wilson <ref> [23] </ref> recently devised an algorithm for exact sampling which is fast enough to be useful in practice. The price they have to pay for this is that the Markov chain (still with tnite state space) has to possess a certain monotonicity structure. <p> The ProppWilson algorithm consists of running these coupled Markov chains from time t to time 0 for larger and larger t until the two chains produce the same value at time 0, and to output this common value. Propp and Wilson <ref> [23] </ref> prove that this gives an unbiased sample from ; below, we shall give a slightly dierent proof of this fact (Theorem 2.1). <p> If T were a txed time, this would indeed yield unbiased samples from , but since T is a random stopping time, this is in general not the case. See <ref> [23] </ref> for further discussion. <p> One implication of all this is that in the bipartite Markov random teld case, results proved for monotone systems concerning e.g. speed of convergence (see <ref> [23] </ref>), translate directly to anti-monotone systems. 4. Some simulation results We will now show how the algorithm performs on some instances of the hardcore model and of the random-cluster model. We have chosen not to include any simulations of the Ising antiferromagnet. <p> Some simulation results We will now show how the algorithm performs on some instances of the hardcore model and of the random-cluster model. We have chosen not to include any simulations of the Ising antiferromagnet. Readers interested in this particular example may turn to <ref> [23] </ref>, where the Ising ferromagnet is studied, and translate the results to the antiferromagnetic case using the methods of Section 3. The implementation of the algorithm was done in the programming language C. <p> The actual number of iterations needed in the algorithm comes within a factor 4 of T fl , as argued in Section 2.2. It is easy to see that T fl and T fl are governed by the same probability distribution (see <ref> [23] </ref>) and hence we can concentrate on T fl when studying running time. The pictures of the various contgurations were, however, of course accomplished using the correct coupling-from-the-past protocol. 4.1.
Reference: [24] <author> Segerberg, U. </author> <title> (1994) Generating uniform spanning trees from random walks, </title> <type> Master's thesis, </type> <institution> Department of Mathematics, Chalmers University of Technology. </institution>
Reference-contexts: It is a realization from the uniform spanning tree measure, which arises in the limit of q ! 0 on the self-dual curve (see [12]). The contguration was produced using the famous random walk algorithm described e.g. in [22] and implemented by Segerberg <ref> [24] </ref>. As opposed to in the hard-core model, the evaluation of the conditional probabilities in the random-cluster model is computationally non-trivial. We have used a slightly simplited version of an algorithm by Sweeny [25] to determine the connectivity necessary to evaluate (1.2).
Reference: [25] <author> Sweeny, M. </author> <title> (1983) Monte Carlo study of weighted percolation clusters relevant to the Potts model, </title> <journal> Phys. Rev. </journal> <volume> B 27, 44454455. </volume> <pages> 22 </pages>
Reference-contexts: As opposed to in the hard-core model, the evaluation of the conditional probabilities in the random-cluster model is computationally non-trivial. We have used a slightly simplited version of an algorithm by Sweeny <ref> [25] </ref> to determine the connectivity necessary to evaluate (1.2). The algorithm relies on the fact that we are dealing with Z 2 , since it uses the dual lattice.
Reference: [26] <author> Welsh, D.J.A. </author> <title> (1993) Percolation in the random cluster process and Q-state Potts model, </title> <journal> J. Phys. A: Math. Gen. </journal> <volume> 26, </volume> <pages> 24712483. </pages>
Reference-contexts: We have chosen to simulate the random-cluster model for values of p and q on the so called self-dual curve p = p q 1+ p q , see Welsh <ref> [26] </ref>. If we let p 0 = p p+(1p)q , we have that p + p 0 = 1 for these values of p and q.
Reference: [27] <author> Wilson, D.B. and Propp, J.G. </author> <title> (1996) How to get a perfectly random sample from a generic Markov chain and generate a random spanning tree of a directed graph, </title> <journal> J. </journal> <note> Algorithms, to appear. 23 </note>
Reference-contexts: The trst such algorithm is due to Asmussen et al. [1], and has been followed by 1 other, simpler, algorithms e.g. in [20] (see <ref> [27] </ref> for a short survey). These algo-rithms work for any irreducible tnite state Markov chain, but have astronomical running times for all but the very simplest chains (i.e. those with very few states) and are therefore of limited practical value.
References-found: 25

