URL: ftp://ic.eecs.berkeley.edu/pub/Thesis/villa.ps.Z
Refering-URL: http://www-cad.eecs.berkeley.edu/Respep/Research/Thesis/thesis.html
Root-URL: http://www.cs.berkeley.edu
Title: Encoding Problems in Logic Synthesis  
Author: by Tiziano Villa 
Degree: Laurea in  M.S. (University of California at Berkeley) 1987 A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in Engineering: Electrical Engineering and Computer Sciences in the GRADUATE DIVISION of the UNIVERSITY of CALIFORNIA at BERKELEY Committee in charge: Professor Alberto Sangiovanni-Vincentelli, Chair Professor Robert Brayton Professor Shmuel Oren  
Note: Mathematical Tripos, Part III, D.A.M.T.P., Cambridge University, U.K.,  
Date: 1977  1982  1995  
Address: Milano, Italy),  
Affiliation: Matematica (Universita Statale di  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> R. Amann and U. Baitinger. </author> <title> Optimal state chains and state codes in finite state machines. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <month> February </month> <year> 1989. </year>
Reference-contexts: It is legitimate to ask what kind of constraints cannot be naturally solved using dichotomies. Such an example of unwieldy encoding constraints are chain constraints <ref> [1] </ref> used to derive area-optimal finite state machine implementations that use counter-based PLA structures. State assignment in [1] consists of a step of deriving face and chain constraints and a step of satisfying them. <p> It is legitimate to ask what kind of constraints cannot be naturally solved using dichotomies. Such an example of unwieldy encoding constraints are chain constraints <ref> [1] </ref> used to derive area-optimal finite state machine implementations that use counter-based PLA structures. State assignment in [1] consists of a step of deriving face and chain constraints and a step of satisfying them. A chain constraint requires that increasing binary numbers be assigned to the codes of the ordered sequence of states. The first element in the chain can be given any code.
Reference: [2] <author> D. Armstrong. </author> <title> On the efficient assignment of internal codes to sequential machines. </title> <journal> IRE Transactions on Electronic Computers, </journal> <pages> pages 611-622, </pages> <month> October </month> <year> 1962. </year>
Reference-contexts: Then the problem was reduced to a graph embedding problem, where a graph represents adjacency relations between the codes of the states, to be preserved by a subgraph isomorphism on the encoding cube. The method was then refined in <ref> [2] </ref>. <p> A "scoring procedure" was defined requiring the comparison of each base entry column with the next state entries on a column-by-column basis and allocating a score according to given criteria. Armstrong argued in <ref> [2] </ref> that the scoring array of [41] could be read in the framework that he proposed.
Reference: [3] <author> D. Armstrong. </author> <title> A programmed algorithm for assigning internal codes to sequential machines. </title> <journal> IRE Transactions on Electronic Computers, </journal> <pages> pages 466-472, </pages> <month> August </month> <year> 1962. </year>
Reference-contexts: The former based his theory of input encoding on partitions and set systems. The latter tried to minimize the variable dependency of the output functions and studied the problem of the minimum number of variables required for a good encoding. In <ref> [3] </ref> Armstrong described one of the first programmed algorithms to assign internal codes to FSM's, with the goal of obtaining economical realizations of the combinational logic of an FSM.
Reference: [4] <author> P. Ashar. </author> <title> Synthesis of sequential circuits for VLSI design. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1992. </year>
Reference-contexts: Such constraints are called face or input constraints and finding codes that satisfy them is the face 2 Moreover the same symbols appear both in the input and in the output part. 4.1. ALGORITHMS FOR OPTIMAL ENCODING 49 embedding problem. An example from <ref> [4] </ref> of a tabular representation of an FSM is shown in Figure 4.1 (a). Multiple-valued minimization of this FSM where the states are the possible values of a multiple-valued variable yields the cover shown in Figure 4.1 (b).
Reference: [5] <author> P. Ashar, S. Devadas, and A. R. </author> <title> Newton. A unified approach to the decomposition and re-decomposition of sequential machines. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 601-606, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: One can see state assignment as producing an FSM decomposition: there is a component FSM of two states (1 memory element) for each encoding bit, and each component FSM depends on the the state of the other components. Connections between state assignment and FSM decomposition have been considered in <ref> [34, 37, 6, 5] </ref>. 4.2.2 State Assignment and State Minimization A sequential behavior may be represented by many different STG's, and different STG's of the same behavior may lead to different logical implementations. This makes elusive the goal of obtaining the best implementation of a given sequential behavior. <p> The number of submachines (number of bits), topology of interconnections and distribution of the proper outputs are all unknowns that an optimal state assignment decides , thereby producing an optimal decomposition. 208 CHAPTER 8. MINIMIZATION OF GPI'S Redecomposition of interconnected FSM's via GPI's is briefly touched upon in <ref> [5] </ref>. The claim is that one can generate the GPI's of the submachines and after some operations deduce from them GPI's of the overall FSM.
Reference: [6] <author> P. Ashar, S. Devadas, and A. R. </author> <title> Newton. Optimum and heuristic algorithms for an approach to finite state machine decomposition. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <pages> pages 296-310, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: One can see state assignment as producing an FSM decomposition: there is a component FSM of two states (1 memory element) for each encoding bit, and each component FSM depends on the the state of the other components. Connections between state assignment and FSM decomposition have been considered in <ref> [34, 37, 6, 5] </ref>. 4.2.2 State Assignment and State Minimization A sequential behavior may be represented by many different STG's, and different STG's of the same behavior may lead to different logical implementations. This makes elusive the goal of obtaining the best implementation of a given sequential behavior. <p> A formulation of FSM decomposition targeting two-level logic as symbolic-output partitioning has been proposed in <ref> [6] </ref>. The algorithm proposed requires the generation of GPI's of submachines and the solution of a constrained covering problem. We refer the interested reader to the original paper. Here the novel aspects of this application of GPI's are outlined. 204 CHAPTER 8. <p> This is an instance of state assignment of a network of FSM's, for which no good algorithm is known up to now. It is not mentioned in <ref> [6] </ref> how the problem of encoding mutually interacting FSM's has been solved in the reported experiments. It is only stated that a state-of-art state assignment tool for single FSM's (nova) has been somehow used. The following example shows the main steps of a decomposition.
Reference: [7] <author> M. Beardslee and A. Sangiovanni-Vincentelli. </author> <title> An algorithm for improving partitions of pin-limited multi-chip systems. </title> <booktitle> In The Proceedings of the International Conference on Computer-Aided Design, </booktitle> <month> November </month> <year> 1993. </year>
Reference-contexts: In the general case the number of evaluations can be restricted to some fixed number to reduce the search space. This heuristic algorithm has shown promising results and has been successfully applied to other encoding constraint satisfaction problems <ref> [97, 7] </ref>. 6.8 Other Applications In this section we illustrate that the formulation presented in Section 6.6 provides a uniform framework for the satisfaction of various other encoding problems. 6.8.1 Input Encoding Don't Cares The notion of an encoding don't care was first described in [91], and an example of how <p> The unused codes are used as don't cares for simplifying the sub-functions. An average improvement of over 20% is achieved when encoding is used while performing the decomposition. The encoding is performed using the heuristic algorithm described in Section 6.7.1. 6.8.5 Logic Partitioning In <ref> [7] </ref> the problem of encoding the communication between two logic blocks is studied. Two separate blocks of logic can communicate unidirectionally through a channel that consists of a number of communication lines.
Reference: [8] <author> D. Bostick, G. Hachtel, R. Jacoby, M. Lightner, P. Moceyunas, C. Morrison, and D. Raven-scroft. </author> <title> The Boulder optimal logic design system. </title> <booktitle> In The Proceedings of the International Conference on Computer-Aided Design, </booktitle> <month> November </month> <year> 1987. </year>
Reference-contexts: Figure 4.7 shows output encoding based on GPI's with a simple example taken from [39]. 4.1.3 Encoding for Multi-level Implementation Automatic multi-level logic synthesis programs are now available to the logic designer <ref> [52, 12, 8] </ref>), since sometimes a PLA implementation of the circuit does not satisfy the area/timing specifications.
Reference: [9] <author> D. Bovet and P. Crescenzi. </author> <title> Introduction to the theory of complexity. </title> <publisher> Prentice Hall, </publisher> <year> 1994. </year> <note> BIBLIOGRAPHY 323 </note>
Reference-contexts: DEFINITIONS 33 Chapter 3 Complexity Issues 3.1 Computational Complexity In this section we will present some results on the computational complexity of state assignment for minimum area. We refer to <ref> [46, 104, 9] </ref> as standard references on computational complexity and the theory of N P -completness in particular. Computational complexity of logic optimization problems has been discussed in [69], from which we will draw results. An instance of a problem is encoded as a string (or word) of a language. <p> This is in part due to the lack of fine tuning of the complexity classes of the polynomial hierarchy. It would be worthy to see if a finer classification can be achieved looking into approximation complexity classes <ref> [46, 104, 9] </ref>. Similar results could be obtained for other optimization objectives, like minimum number of literals of multi-level implementations [69].
Reference: [10] <author> K. Brace, R. Rudell, and R. Bryant. </author> <title> Efficient implementation of a BDD package. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 40-45, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Since now on, by BDD of a set we will denote the BDD of the characteristic function of the set over an appropriate Boolean space. A BDD <ref> [16, 10] </ref> is a canonical directed acyclic graph data structure that represents logic functions. The items that a BDD can represent are determined by the number of paths of the BDD, while the size of the BDD is determined by the number of nodes of the DAG. <p> STG's have been usually represented in two-level form where state transitions are stored explicitly, one by one. Alternatively, STG's can be represented implicitly with Binary Decision Diagrams (BDD's) <ref> [16, 10] </ref>. BDD's represent Boolean functions (e.g. characteristic functions of sets and relations) and have been amply reported in the literature [16, 10], to which we refer. 11.1.1 Implicit FSM Representation A Finite State Machine (FSM) can be represented by a 5-tuple (I; O; S; T ; O). <p> STG's have been usually represented in two-level form where state transitions are stored explicitly, one by one. Alternatively, STG's can be represented implicitly with Binary Decision Diagrams (BDD's) <ref> [16, 10] </ref>. BDD's represent Boolean functions (e.g. characteristic functions of sets and relations) and have been amply reported in the literature [16, 10], to which we refer. 11.1.1 Implicit FSM Representation A Finite State Machine (FSM) can be represented by a 5-tuple (I; O; S; T ; O). I and O are the sets of input patterns and output patterns. S is the set of states.
Reference: [11] <author> R. Brayton, G. Hachtel, C. McMullen, and A. Sangiovanni-Vincentelli. </author> <title> Logic Minimization Algorithms for VLSI Synthesis. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1984. </year>
Reference-contexts: An example is demonstrated in Section 5.8, and experiments are reported in Section 5.9, with final conclusions drawn in Section 5.10. 5.2 Encoding for Two-level Implementations 5.2.1 Multi-valued Minimization Advances in the state assignment problem, reported in <ref> [93, 11, 92] </ref>, made a key connection to multiple-valued logic minimization, by representing the states of a FSM as the set of possible values of a single multiple-valued variable. A multiple-valued minimizer, such as [114], can be invoked on the symbolic representation of the FSM. <p> At last, codes satisfying the given encoding constraints are generated. The accuracy of the synthesis procedure can be measured by the fact that the cardinality of the symbolic minimized cover is very close to the cardinality of the original encoded FSM minimized by ESPRESSO <ref> [11] </ref>. This will be shown in the section of results. <p> The second step of encoding is the generation of prime dichotomies from the dichotomies. [143] describes an approach similar to the process of iterated consensus for prime generation in two-level logic minimization <ref> [11] </ref>. However, the number of iterations required to generate all the prime dichotomies may be formidable even for small problems. Using this approach, several different compatible merges often yield the same prime dichotomy. This results in a substantial waste of computation time [154]. <p> The two product terms, x expr and cs (reduced expr), are multiplied and single cube-containment is used to obtain the minimum sum-of-products expression. Again single cube-containment can be used to find the minimum expression since the function is unate <ref> [11] </ref>. This algorithm replaces exponential (in the number of dichotomies) calls as required in the worst-case by a Shannon expansion based approach by a linear number of them. <p> In particular, researchers at Bull and UCB [25, 79, 53] investigated implicit computations of prime implicants of a two-valued or multi-valued function. In some examples all primes could be computed implicitly, even when explicit techniques implemented in ESPRESSO <ref> [11] </ref> failed to do so. Moreover, implicit algorithms have been designed to reduce the unate table of the Quine-McCluskey procedure to its cyclic core [29, 53], and to solve the binate covering problem associated with exact state minimization [66]. <p> Later work at Bull [25, 79] has shown how implicants, primes and essential primes of a two-valued or multi-valued function can also be computed implicitly. Reported experiments show a suite of examples where all primes could be computed, whereas explicit techniques implemented in ESPRESSO <ref> [11] </ref> failed to do so. Finally, the fixed-point dominance computation in the covering step of the Quine-McCluskey procedure has been made implicit in current work [29, 53]. The experiments reported show that the cyclic core of all logic functions of the ESPRESSO benchmark can be successfully computed. <p> We report the number of primes of the companion function and the number of GPI's. Comparisons of run times to generate the primes of the companion function *only* are made with ESPRESSO <ref> [11] </ref>. Both programs were timed out at 7200 seconds of CPU time. <p> Experiments show that the encoded covers produced by our procedure are usually smaller or equal than those of the best option of state-of-art tools like NOVA [147]. An improvement to the procedure would be to introduce some iterated expansion and reduction scheme, as in ESPRESSO <ref> [11] </ref>, to escape from local minima. Currently the algorithm builds a minimal symbolic cover, exploring a neighborhood of the original FSM cover, with variations of one single expansion and reduction for each slice of the FSM. A weak point of the current algorithm 320 CHAPTER 12.
Reference: [12] <author> R. Brayton, R. Rudell, A. Sangiovanni-Vincentelli, and A. Wang. </author> <title> MIS: A multiple-level logic optimization system. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <month> November </month> <year> 1987. </year>
Reference-contexts: Further, some of the variables in may be classified as primary inputs or primary outputs. 30 CHAPTER 2. DEFINITIONS These are the inputs and outputs (respectively) of the MV-network. The MV-network is an extension of the well-known Boolean network <ref> [12] </ref> to permit MV input variables; in fact the latter reduces to the former when all variables have binary values. Since each node in the network has a binary-valued output, the non-binary (MV) inputs to any node must be primary inputs to the network. <p> Figure 4.7 shows output encoding based on GPI's with a simple example taken from [39]. 4.1.3 Encoding for Multi-level Implementation Automatic multi-level logic synthesis programs are now available to the logic designer <ref> [52, 12, 8] </ref>), since sometimes a PLA implementation of the circuit does not satisfy the area/timing specifications. <p> Table 4.2 reports the number of literals after running through the standard boolean optimization script in the multi-level logic synthesis system MISII <ref> [12] </ref> with encodings obtained by NOVA, MUSTANG [36], JEDI [77] and random state assignments. In the case of NOVA only the best minimum code-length two-level result was given to MISII . MUSTANG was run with -p, -n, -pt, -nt options and minimum code-length.
Reference: [13] <author> R. Brayton, A. Sangiovanni-Vincentelli, G. Hachtel, and R. Rudell. </author> <title> Multi-level logic synthesis. Unpublished book, </title> <year> 1992. </year>
Reference-contexts: This technique has been described in <ref> [51, 50, 13, 14] </ref>, and implemented in successful computer programs [112, 108, 130]. The branch-and-bound solution of minimum binate covering is based on a recursive procedure. A run of the algorithm can be described by its computation tree. <p> Even though more complex criteria of dominance have been investigated (for instance, Section 10.5.12), the previous ones are basic in any table covering solver. Reduction rules have previously been stated for the binate covering case <ref> [50, 51, 14, 13] </ref>, and also for the unate covering case [87, 113, 13]. Here we will present the known reduction rules directly for binate covering and indicate how they simplify for unate covering, when applicable. <p> Even though more complex criteria of dominance have been investigated (for instance, Section 10.5.12), the previous ones are basic in any table covering solver. Reduction rules have previously been stated for the binate covering case [50, 51, 14, 13], and also for the unate covering case <ref> [87, 113, 13] </ref>. Here we will present the known reduction rules directly for binate covering and indicate how they simplify for unate covering, when applicable. For each of them, we will first define the reduction rule, and then a theorem showing how that rule is applied. <p> For each of them, we will first define the reduction rule, and then a theorem showing how that rule is applied. Proofs for the correctness of these reduction rules have been given in <ref> [50, 51, 14, 13] </ref>, and they will not be repeated here, except for a few less common ones. We will provide a survey comparing different related reduction rules used in the literature. The effect of reductions depends on the order of their application. <p> dominance), * similar to column dominance (Rule 3) in [51], except that the labels of dominator row, R i , and dominated row, R j , are reversed (i.e., reverse definition of dominance), * equivalent to row dominance (Definition 10) in [14], * identical to row dominance (Definition 2.11) in <ref> [13] </ref>. <p> first half of Rule 4 in [51]: (a) C j has all the 1's of C k and (b1) C k has all the 0's of C j , * identical to column dominance (Definition 11, Theorem 3) in [14], * identical to column dominance (Definition 2.12, Theorem 2.4.1) in <ref> [13] </ref>. <p> 0, such that disregarding entries in row C i and C j , R p dominates R q (with reverse definition of row dominance), noticing that by mistake the condition that C i does not have a 0 in row R q was omitted, * not mentioned in [14] and <ref> [13] </ref>. 10.5.5 Column Dominance Definition 10.5.6 A column C i dominates another column C j if either C i ff-dominates C j or C i fi-dominates C j . Theorem 10.5.5 Let M be satisfiable. <p> definition of essential column is * identical to essential row (Rule 2) in [50], * identical to Rule 1 in [51], * included in Definition 9 in [14]: the row R i in the above definition corresponds to a singleton-1 essential row in [14], * included in Definition 2.10 in <ref> [13] </ref>: the row R i in the above definition corresponds to a singleton-1 essential row in [13]. <p> to Rule 1 in [51], * included in Definition 9 in [14]: the row R i in the above definition corresponds to a singleton-1 essential row in [14], * included in Definition 2.10 in <ref> [13] </ref>: the row R i in the above definition corresponds to a singleton-1 essential row in [13]. <p> definition of unacceptable column is * identical to that of nonselectionable row in [50], * identical to Rule 2 in [51], * included in Definition 9 in [14]: the row R i in the above definition corresponds to a singleton-0 essential row in [14], * included in Definition 2.10 in <ref> [13] </ref>: the row R i in the above definition corresponds to a singleton-0 essential row in [13]. 10.5.9 Unnecessary Column Definition 10.5.11 A column of only 0's and 2's is an unnecessary column. Notice that there is no symmetric rule for columns of 1's and 2's. <p> to Rule 2 in [51], * included in Definition 9 in [14]: the row R i in the above definition corresponds to a singleton-0 essential row in [14], * included in Definition 2.10 in <ref> [13] </ref>: the row R i in the above definition corresponds to a singleton-0 essential row in [13]. 10.5.9 Unnecessary Column Definition 10.5.11 A column of only 0's and 2's is an unnecessary column. Notice that there is no symmetric rule for columns of 1's and 2's. <p> This definition of unnecessary column is * identical to Rule 4 in [50], * identical to Rule 5 in [51], * not mentioned in [14] and <ref> [13] </ref>. 10.5.10 Trial Rule Theorem 10.5.10 If there exists in a covering table M a row R i having a 0 in column C j , a 1 in column C k and 2's in the rest, then apply the following test: * eliminate C k together with the rows in <p> This definition of infeasibility is * not mentioned in [50] and [51], * briefly mentioned in [14], * identical to the unfeasible problem in <ref> [13] </ref>. 10.5.12 Gimpel's Reduction Step Another heuristic for solving the minimum cover problem has been suggested by Gim-pel [48]. Gimpel proposed a reduction step which simplifies the covering matrix when it has a special form.
Reference: [14] <author> R. Brayton and F. Somenzi. </author> <title> An exact minimizer for Boolean relations. </title> <booktitle> In The Proceedings of the International Conference on Computer-Aided Design, </booktitle> <pages> pages 316-319, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: The columns are the prime implicants, the rows are the minterms and there is a 1 entry in the matrix when a prime contains a minterm. Various techniques have been proposed to solve binate covering problems. A class of them <ref> [14, 72] </ref> are branch-and-bound techniques that build explicitly the table of the constraints expressed as product-of-sum expressions and explore in the worst-case all possible solutions, but avoid the generation of some of the suboptimal solutions by a clever use of reduction steps and bounding of search space for solutions. <p> This technique has been described in <ref> [51, 50, 13, 14] </ref>, and implemented in successful computer programs [112, 108, 130]. The branch-and-bound solution of minimum binate covering is based on a recursive procedure. A run of the algorithm can be described by its computation tree. <p> Even though more complex criteria of dominance have been investigated (for instance, Section 10.5.12), the previous ones are basic in any table covering solver. Reduction rules have previously been stated for the binate covering case <ref> [50, 51, 14, 13] </ref>, and also for the unate covering case [87, 113, 13]. Here we will present the known reduction rules directly for binate covering and indicate how they simplify for unate covering, when applicable. <p> For each of them, we will first define the reduction rule, and then a theorem showing how that rule is applied. Proofs for the correctness of these reduction rules have been given in <ref> [50, 51, 14, 13] </ref>, and they will not be repeated here, except for a few less common ones. We will provide a survey comparing different related reduction rules used in the literature. The effect of reductions depends on the order of their application. <p> R j , are reversed (i.e., reverse definition of dominance), * similar to column dominance (Rule 3) in [51], except that the labels of dominator row, R i , and dominated row, R j , are reversed (i.e., reverse definition of dominance), * equivalent to row dominance (Definition 10) in <ref> [14] </ref>, * identical to row dominance (Definition 2.11) in [13]. <p> REDUCTION TECHNIQUES 247 * equivalent to first half of Rule 4 in [51]: (a) C j has all the 1's of C k and (b1) C k has all the 0's of C j , * identical to column dominance (Definition 11, Theorem 3) in <ref> [14] </ref>, * identical to column dominance (Definition 2.12, Theorem 2.4.1) in [13]. <p> has a 0, such that disregarding entries in row C i and C j , R p dominates R q (with reverse definition of row dominance), noticing that by mistake the condition that C i does not have a 0 in row R q was omitted, * not mentioned in <ref> [14] </ref> and [13]. 10.5.5 Column Dominance Definition 10.5.6 A column C i dominates another column C j if either C i ff-dominates C j or C i fi-dominates C j . Theorem 10.5.5 Let M be satisfiable. <p> Column C j must then be deleted together with all the rows in which it has 1's. This definition of essential column is * identical to essential row (Rule 2) in [50], * identical to Rule 1 in [51], * included in Definition 9 in <ref> [14] </ref>: the row R i in the above definition corresponds to a singleton-1 essential row in [14], * included in Definition 2.10 in [13]: the row R i in the above definition corresponds to a singleton-1 essential row in [13]. <p> This definition of essential column is * identical to essential row (Rule 2) in [50], * identical to Rule 1 in [51], * included in Definition 9 in <ref> [14] </ref>: the row R i in the above definition corresponds to a singleton-1 essential row in [14], * included in Definition 2.10 in [13]: the row R i in the above definition corresponds to a singleton-1 essential row in [13]. <p> This definition of unacceptable column is * identical to that of nonselectionable row in [50], * identical to Rule 2 in [51], * included in Definition 9 in <ref> [14] </ref>: the row R i in the above definition corresponds to a singleton-0 essential row in [14], * included in Definition 2.10 in [13]: the row R i in the above definition corresponds to a singleton-0 essential row in [13]. 10.5.9 Unnecessary Column Definition 10.5.11 A column of only 0's and <p> This definition of unacceptable column is * identical to that of nonselectionable row in [50], * identical to Rule 2 in [51], * included in Definition 9 in <ref> [14] </ref>: the row R i in the above definition corresponds to a singleton-0 essential row in [14], * included in Definition 2.10 in [13]: the row R i in the above definition corresponds to a singleton-0 essential row in [13]. 10.5.9 Unnecessary Column Definition 10.5.11 A column of only 0's and 2's is an unnecessary column. <p> This definition of unnecessary column is * identical to Rule 4 in [50], * identical to Rule 5 in [51], * not mentioned in <ref> [14] </ref> and [13]. 10.5.10 Trial Rule Theorem 10.5.10 If there exists in a covering table M a row R i having a 0 in column C j , a 1 in column C k and 2's in the rest, then apply the following test: * eliminate C k together with the <p> Theorem 10.5.11 A covering problem M is infeasible if there exists a column C j which is both essential and unacceptable (implying x j = 1 and x j = 0). This definition of infeasibility is * not mentioned in [50] and [51], * briefly mentioned in <ref> [14] </ref>, * identical to the unfeasible problem in [13]. 10.5.12 Gimpel's Reduction Step Another heuristic for solving the minimum cover problem has been suggested by Gim-pel [48]. Gimpel proposed a reduction step which simplifies the covering matrix when it has a special form.
Reference: [15] <author> F. M. Brown. </author> <title> Boolean Reasoning. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1990. </year>
Reference-contexts: BOOLEAN ALGEBRAS AND BOOLEAN FUNCTIONS 21 2.5 Boolean Algebras and Boolean Functions This section provides a brief review of the background material on Boolean algebras and Boolean functions. There are many classical expositions of it. We refer to <ref> [15, 32] </ref> for a complete treatment. Definition 2.5.1 Consider a quintuple (B; +; ; 0; 1) in which B is a set, called the carrier, + and are binary operations on B, and 0 and 1 are distinct members of B. <p> These are also referred to as switching functions <ref> [15] </ref>. The fact that all switching functions are also Boolean functions [15] enables all properties of Boolean functions to be directly applied to switching functions. However not all functions that arise in the context of circuit specification and design are switching functions. <p> These are also referred to as switching functions <ref> [15] </ref>. The fact that all switching functions are also Boolean functions [15] enables all properties of Boolean functions to be directly applied to switching functions. However not all functions that arise in the context of circuit specification and design are switching functions.
Reference: [16] <author> R. Bryant. </author> <title> Graph based algorithm for Boolean function manipulation. </title> <journal> In IEEE Transactions on Computers, </journal> <pages> pages C-35(8):667-691, </pages> <year> 1986. </year>
Reference-contexts: In the implementation, we represent a characteristic function by using a multi-valued decision diagram (MDD, see [64, 136]). An MDD is a data structure to represent a function with multiple-valued input variables and a single binary output, which employs a BDD <ref> [16] </ref> as the internal data structure. <p> Since now on, by BDD of a set we will denote the BDD of the characteristic function of the set over an appropriate Boolean space. A BDD <ref> [16, 10] </ref> is a canonical directed acyclic graph data structure that represents logic functions. The items that a BDD can represent are determined by the number of paths of the BDD, while the size of the BDD is determined by the number of nodes of the DAG. <p> Implicit formulations of such operations were instead reported first in [66]. In [30] it is stated that the usage of Zero-Suppressed BDD's by Minato [95] instead of ROBDD's <ref> [16] </ref> resulted in more efficient implicit representations of the computations of the problem. 278 CHAPTER 10. BINATE COVERING 279 Chapter 11 Implicit Minimization of GPI's 11.1 Implicit Representations and Manipulations Algorithms for sequential synthesis have been developed primarily for State Transition Graphs (STG's). <p> STG's have been usually represented in two-level form where state transitions are stored explicitly, one by one. Alternatively, STG's can be represented implicitly with Binary Decision Diagrams (BDD's) <ref> [16, 10] </ref>. BDD's represent Boolean functions (e.g. characteristic functions of sets and relations) and have been amply reported in the literature [16, 10], to which we refer. 11.1.1 Implicit FSM Representation A Finite State Machine (FSM) can be represented by a 5-tuple (I; O; S; T ; O). <p> STG's have been usually represented in two-level form where state transitions are stored explicitly, one by one. Alternatively, STG's can be represented implicitly with Binary Decision Diagrams (BDD's) <ref> [16, 10] </ref>. BDD's represent Boolean functions (e.g. characteristic functions of sets and relations) and have been amply reported in the literature [16, 10], to which we refer. 11.1.1 Implicit FSM Representation A Finite State Machine (FSM) can be represented by a 5-tuple (I; O; S; T ; O). I and O are the sets of input patterns and output patterns. S is the set of states.
Reference: [17] <author> N. Calazans. </author> <title> Boolean constrained encoding: a new formulation and a case study. </title> <booktitle> In The Proceedings of the International Conference on Computer-Aided Design, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: PREVIOUS AND RELATED WORK We will mention later that by using symbolic relations some cases of the interaction of state minimization and state assignment can be modeled exactly, but with little hope of practical solutions. Recently Calazans <ref> [17] </ref> proposed an heuristic algorithm to use information about compatible states of ISFSM's while doing state assignment. 4.2.3 State Assignment and Testability Unate state assignments to guarantee testability by construction were proposed first in [140].
Reference: [18] <author> K-T. Cheng and V.D. Agrawal. </author> <title> State assignment for initializable synthesis. </title> <booktitle> In The Proceedings of the International Conference on Computer-Aided Design, </booktitle> <month> November </month> <year> 1989. </year>
Reference-contexts: SYMBOLIC MINIMIZATION 109 Chapter 6 Encoding Constraints 6.1 Introduction The various techniques for exact and heuristic encoding based on multiple-valued or symbolic minimization of two-level and multi-level logic, reported in <ref> [92, 91, 115, 39, 85, 18] </ref>, produce various types of encoding constraints. By encoding constraints we mean requirements on the codes to be assigned to the symbols. A first type are face-embedding constraints generated by the multiple-valued input variables (input constraints).
Reference: [19] <author> S.M. Chiu. </author> <title> Exact state assignment via binate covering. EE290ls Project, </title> <month> May </month> <year> 1990. </year>
Reference-contexts: The idea has been advanced further in [133, 132], to cast the whole problem of selecting a minimum encodeable cover of GPI's, for a fixed code-length, as a binate covering problem. An implementation has been described in <ref> [19] </ref>. A binate covering problem asks for the minimum solution of a formula written as a POS. <p> REDUCTION OF GPI MINIMIZATION TO BINATE COVERING 197 It is reported in <ref> [19] </ref> that a distributive method, which recursively generates clauses and immediately eliminates those duplicated and subsumed, reduces very effectively the number of clauses. The clauses of a reported example went down from 631; 000 to 184. No description of the algorithm is provided in the report. <p> But in this case it happens rarely that simplifications can be made, differently from next-state covering clauses (the only simplification that occurs here is of clauses with a literal and its negation). The experimental fact is that these clauses are a bottleneck of the binate covering approach. For instance, <ref> [19] </ref> reports the following data: from 256; 000 clauses 198 CHAPTER 8. MINIMIZATION OF GPI'S for an FSM of 4 states and a code of length 2, to 11; 764; 900 clauses for an FSM of 8 states and a code of length 3. <p> use a covering table with entries to 1 iff a GPI contains a minterm, as in ordinary unate covering. 229 Chapter 10 Binate Covering 10.1 Introduction It is not feasible to generate GPI's and to set up a related unate or binate covering table by explicit techniques on non-trivial examples <ref> [19] </ref>. By means of techniques as in [79, 53, 30], GPI's can be generated using BDD-based (alias implicit) representations. The next step is to select an encodeable cover of GPI's using implicit representations.
Reference: [20] <author> M. Ciesielski, J-J. Shen, and M. Davio. </author> <title> A unified approach to input-output encoding for FSM state assignment. </title> <booktitle> The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 176-181, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: SYMBOLIC MINIMIZATION BY EXAMPLE 93 OnCov: on-set of st2 0010000 on-set of st4 0000100 OffCov: on-set of st2 0001100 on-set of st4 0011000 on-set of st5 0011100 established in [154]. Other contributions on the subject can be found in <ref> [126, 20] </ref> and more recently in [44, 45]. 5.8 Symbolic Minimization by Example In this section we clarify with an example the mechanics by which the oring effects plays an important role in the minimization of symbolic logic. <p> A solution to P-1, when both input and output constraints (including disjunctive constraints) are present, is described in [39], and corrected in [38]. A solution to problem P-2 based on compatible graph coloring is provided for input constraints in [154] and extended to output constraints in <ref> [20] </ref>. To date, to the best of our knowledge, no efficient algorithms exist for solving all three problems when all types of constraints occur. In most previous contributions, techniques to generate constraints and to satisfy them were intermixed. Instead, we concentrate only on the problem of satisfying encoding constraints. <p> This definition of dichotomy differs from the one in [143, 154], which allows the left block of a dichotomy to assume either the encoding bit 0 or 1, and it is equivalent to the definition of fixed dichotomy given in <ref> [20] </ref>. A dichotomy is complete if each symbol appears in either block. A completion of a dichotomy (l; r) is a dichotomy (l 0 ; r 0 ) such that l 0 l, r 0 r, and each symbol appears exactly once in either l 0 or r 0 .
Reference: [21] <author> M. Ciesielski and S. Yang. PLADE: </author> <title> a two stage PLA decomposition. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <pages> pages 943-954, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: A variety of other applications may also generate similar constraints satisfaction problems, as in the case of synthesis for sequential testability [35], and optimal re-encoding and decomposition of PLA's <ref> [40, 21, 122, 120, 119, 121, 123] </ref>. Given a PLA, it is possible to group the inputs into pairs and replace the input buffers with two-bit decoders to yield a bit-paired PLA with the same number of columns and no more product-terms than the original PLA. <p> The encoding problem consists of finding the codes of the signals between the PLA's, so that the constraints imposed by the multiple-valued cover are satisfied. This problem is usually approximated as an input encoding problem <ref> [40, 21] </ref>, but in its generality is an input-output encoding problem referred in [39] as four-level Boolean minimization. Exact Encoding with Generalized Prime Implicants An exact procedure for output encoding has been reported in [39].
Reference: [22] <author> O. Coudert. </author> <title> Two-level logic minimization: an overview. Integration, </title> <address> 17-2:97-140, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: Transform the computation of the primes, unate table and the table reduction operations into operations on boolean functions defined on the boolean space of the problem. An whole suite of papers has been produced by the French group <ref> [25, 79, 27, 26, 24, 28, 29, 30, 22] </ref>. Here we will outline only the key steps of this approach. We remind that a literal is a propositional variable x k or its negation x k .
Reference: [23] <author> O. Coudert, C. Berthet, and J. C. Madre. </author> <title> Verification of sequential machines using functional Boolean vectors. </title> <booktitle> IFIP Conference, </booktitle> <month> November </month> <year> 1989. </year> <note> 324 BIBLIOGRAPHY </note>
Reference-contexts: Special care must be exercised with quantifications, that bring more danger of BDD blowups. All of this goes often under the name of implicit representations and computations. The previous insight has already been tested in a series of applications. Research at Bull <ref> [23] </ref> and UC Berkeley [142] produced powerful techniques for implicit enumeration of subsets of states of a Finite State Machine (FSM). Later work at Bull [25, 79] has shown how implicants, primes and essential primes of a two-valued or multi-valued function can also be computed implicitly.
Reference: [24] <author> O. Coudert, H.Fraisse, and J.C. Madre. </author> <title> Towards a symbolic logic minimization algorithm. </title> <booktitle> In The Proceedings of the VLSI Design 1993 Conference, </booktitle> <pages> pages 329-334, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Transform the computation of the primes, unate table and the table reduction operations into operations on boolean functions defined on the boolean space of the problem. An whole suite of papers has been produced by the French group <ref> [25, 79, 27, 26, 24, 28, 29, 30, 22] </ref>. Here we will outline only the key steps of this approach. We remind that a literal is a propositional variable x k or its negation x k .
Reference: [25] <author> O. Coudert and J.C. Madre. </author> <title> Implicit and incremental computation of prime and essential prime implicants of Boolean functions. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 36-39, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Here, loosely, we consider a representation as explicit if it requires space lineraly proportional to the size of the represented set. In particular, researchers at Bull and UCB <ref> [25, 79, 53] </ref> investigated implicit computations of prime implicants of a two-valued or multi-valued function. In some examples all primes could be computed implicitly, even when explicit techniques implemented in ESPRESSO [11] failed to do so. <p> The previous insight has already been tested in a series of applications. Research at Bull [23] and UC Berkeley [142] produced powerful techniques for implicit enumeration of subsets of states of a Finite State Machine (FSM). Later work at Bull <ref> [25, 79] </ref> has shown how implicants, primes and essential primes of a two-valued or multi-valued function can also be computed implicitly. Reported experiments show a suite of examples where all primes could be computed, whereas explicit techniques implemented in ESPRESSO [11] failed to do so. <p> Transform the computation of the primes, unate table and the table reduction operations into operations on boolean functions defined on the boolean space of the problem. An whole suite of papers has been produced by the French group <ref> [25, 79, 27, 26, 24, 28, 29, 30, 22] </ref>. Here we will outline only the key steps of this approach. We remind that a literal is a propositional variable x k or its negation x k .
Reference: [26] <author> O. Coudert and J.C. Madre. </author> <title> A new implicit graph based prime and essential prime computation technique. </title> <booktitle> In Proceedings of the International Symposium on Information Sciences, </booktitle> <pages> pages 124-131, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Transform the computation of the primes, unate table and the table reduction operations into operations on boolean functions defined on the boolean space of the problem. An whole suite of papers has been produced by the French group <ref> [25, 79, 27, 26, 24, 28, 29, 30, 22] </ref>. Here we will outline only the key steps of this approach. We remind that a literal is a propositional variable x k or its negation x k .
Reference: [27] <author> O. Coudert and J.C. Madre. </author> <title> A new method to compute prime and essential prime implicants of boolean functions. </title> <booktitle> In Advanced Research in VLSI and Parallel Systems, </booktitle> <pages> pages 113-128. </pages> <publisher> The MIT Press, </publisher> <editor> T. Knight and J. Savage Editors, </editor> <month> March </month> <year> 1992. </year>
Reference-contexts: Transform the computation of the primes, unate table and the table reduction operations into operations on boolean functions defined on the boolean space of the problem. An whole suite of papers has been produced by the French group <ref> [25, 79, 27, 26, 24, 28, 29, 30, 22] </ref>. Here we will outline only the key steps of this approach. We remind that a literal is a propositional variable x k or its negation x k .
Reference: [28] <author> O. Coudert and J.C. Madre. </author> <title> A new viewpoint on two-level logic minimization. </title> <journal> Bull Research Report N. </journal> <volume> 92026, </volume> <month> November </month> <year> 1992. </year>
Reference-contexts: Transform the computation of the primes, unate table and the table reduction operations into operations on boolean functions defined on the boolean space of the problem. An whole suite of papers has been produced by the French group <ref> [25, 79, 27, 26, 24, 28, 29, 30, 22] </ref>. Here we will outline only the key steps of this approach. We remind that a literal is a propositional variable x k or its negation x k .
Reference: [29] <author> O. Coudert, J.C. Madre, and H.Fraisse. </author> <title> A new viewpoint on two-level logic minimization. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 625-630, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: In some examples all primes could be computed implicitly, even when explicit techniques implemented in ESPRESSO [11] failed to do so. Moreover, implicit algorithms have been designed to reduce the unate table of the Quine-McCluskey procedure to its cyclic core <ref> [29, 53] </ref>, and to solve the binate covering problem associated with exact state minimization [66]. In the present work we capitalize on these algorithmic technologies to propose a complete procedure to generate and select GPI's based on implicit computations. This approach combines 146 CHAPTER 7. <p> Reported experiments show a suite of examples where all primes could be computed, whereas explicit techniques implemented in ESPRESSO [11] failed to do so. Finally, the fixed-point dominance computation in the covering step of the Quine-McCluskey procedure has been made implicit in current work <ref> [29, 53] </ref>. The experiments reported show that the cyclic core of all logic functions of the ESPRESSO benchmark can be successfully computed. For some of them ESPRESSO failed the task. This chapter describes an implicit formulation of the binate covering problem and presents an implementation. <p> The set of all primes and minterms may be exponential in the number of input variables. Manipulating a table with an exponential number of rows and columns may add another exponential blow-up. To overcome these problems, researchers at Bull <ref> [29, 30] </ref> and UCB [53] have represented the set of primes and the unate table with logic functions implemented with ROBDD's. The key steps have been: 10.10. IMPLICIT TWO-LEVEL LOGIC MINIMIZATION 271 1. Define a boolean space where all those sets could be represented. 2. <p> Transform the computation of the primes, unate table and the table reduction operations into operations on boolean functions defined on the boolean space of the problem. An whole suite of papers has been produced by the French group <ref> [25, 79, 27, 26, 24, 28, 29, 30, 22] </ref>. Here we will outline only the key steps of this approach. We remind that a literal is a propositional variable x k or its negation x k .
Reference: [30] <author> O. Coudert, J.C. Madre, H.Fraisse, and H. Touati. </author> <title> Implicit prime cover computation: an overview. </title> <booktitle> In The Proceedings of the SASIMI Conference, </booktitle> <pages> pages 413-422, </pages> <year> 1993. </year>
Reference-contexts: By means of techniques as in <ref> [79, 53, 30] </ref>, GPI's can be generated using BDD-based (alias implicit) representations. The next step is to select an encodeable cover of GPI's using implicit representations. This motivates the development of new algorithms to solve covering problems based on the representation and manipulation of covering tables represented with BDD's. <p> The set of all primes and minterms may be exponential in the number of input variables. Manipulating a table with an exponential number of rows and columns may add another exponential blow-up. To overcome these problems, researchers at Bull <ref> [29, 30] </ref> and UCB [53] have represented the set of primes and the unate table with logic functions implemented with ROBDD's. The key steps have been: 10.10. IMPLICIT TWO-LEVEL LOGIC MINIMIZATION 271 1. Define a boolean space where all those sets could be represented. 2. <p> Transform the computation of the primes, unate table and the table reduction operations into operations on boolean functions defined on the boolean space of the problem. An whole suite of papers has been produced by the French group <ref> [25, 79, 27, 26, 24, 28, 29, 30, 22] </ref>. Here we will outline only the key steps of this approach. We remind that a literal is a propositional variable x k or its negation x k . <p> Notice that in the papers by the researchers at Bull no implicitization is reported of the choice of a branching column and of a lower bound computation. Implicit formulations of such operations were instead reported first in [66]. In <ref> [30] </ref> it is stated that the usage of Zero-Suppressed BDD's by Minato [95] instead of ROBDD's [16] resulted in more efficient implicit representations of the computations of the problem. 278 CHAPTER 10. <p> A very fruitful recent research effort <ref> [53, 30] </ref> succeeded in finding efficiently by implicit computations the prime implicants of a boolean function. 284 CHAPTER 11. IMPLICIT MINIMIZATION OF GPI'S We refer to [53, 30] for a complete treatment of the topic and we report here a few facts required in our application. <p> A very fruitful recent research effort <ref> [53, 30] </ref> succeeded in finding efficiently by implicit computations the prime implicants of a boolean function. 284 CHAPTER 11. IMPLICIT MINIMIZATION OF GPI'S We refer to [53, 30] for a complete treatment of the topic and we report here a few facts required in our application.
Reference: [31] <author> G. Cybenko, D. Krumme, and K. Venkataraman. </author> <title> Fixed hypercube embedding. </title> <journal> Information Processing Letters, </journal> <month> April </month> <year> 1987. </year>
Reference-contexts: The problem of deciding whether a given graph is embeddable into an arbitrary dimension hypercube has been shown to be NP-complete [71]. It has also been proved that even the problem of deciding whether a graph can be embedded into a fixed-size hypercube is NP-complete <ref> [31] </ref>. The proof in [31] actually shows that the problem of determining whether a graph of 2 k nodes can be embedded in a k-cube is NP-complete. This result can be used to prove that face hypercube embedding is NP-complete. Theorem 6.2.1 Face hypercube embedding is NP-complete. <p> The problem of deciding whether a given graph is embeddable into an arbitrary dimension hypercube has been shown to be NP-complete [71]. It has also been proved that even the problem of deciding whether a graph can be embedded into a fixed-size hypercube is NP-complete <ref> [31] </ref>. The proof in [31] actually shows that the problem of determining whether a graph of 2 k nodes can be embedded in a k-cube is NP-complete. This result can be used to prove that face hypercube embedding is NP-complete. Theorem 6.2.1 Face hypercube embedding is NP-complete. Proof: Face hypercube embedding is in NP. <p> Notice that in this case the concept of face embedding reduces to the familiar notion of graph adjacency. The problem of determining whether a graph of 2 k nodes is a subgraph of a k-cube is NP-complete by reduction from 3-partition <ref> [31] </ref>. Therefore the problem of determining whether for 2 k symbols a set of face constraints each with exactly two symbols can be embedded into a k-cube is NP-complete.
Reference: [32] <author> M. Davio, J.-P. Deschamps, and A. Thayse. </author> <title> Discrete and Switching Functions. </title> <publisher> Georgi Publishing Co. and McGraw-Hill International Book Company, </publisher> <year> 1978. </year>
Reference-contexts: BOOLEAN ALGEBRAS AND BOOLEAN FUNCTIONS 21 2.5 Boolean Algebras and Boolean Functions This section provides a brief review of the background material on Boolean algebras and Boolean functions. There are many classical expositions of it. We refer to <ref> [15, 32] </ref> for a complete treatment. Definition 2.5.1 Consider a quintuple (B; +; ; 0; 1) in which B is a set, called the carrier, + and are binary operations on B, and 0 and 1 are distinct members of B.
Reference: [33] <author> W. Davis. </author> <title> An approach to the assignment of input codes. </title> <journal> IEEE Transactions on Electronic Computers, </journal> <month> August </month> <year> 1967. </year>
Reference-contexts: Here we will review the key contributions. Among the first to define input and output encoding problems for combinational networks were <ref> [33] </ref> and [100]. The former based his theory of input encoding on partitions and set systems. The latter tried to minimize the variable dependency of the output functions and studied the problem of the minimum number of variables required for a good encoding. <p> Armstrong argued in [2] that the scoring array of [41] could be read in the framework that he proposed. Story, Harrison et al. [141, 138] proposed algorithms to derive minimal-cost assignments based on the lower-bound approach first described by Davis <ref> [33] </ref> and extending the technique to find the cost of an assignment proposed by Torng [141]. A set of columns, each composed of a binary element for each row of a partially assigned state table, is derived. From this matrix it is possible to generate all possible distinct state assignments.
Reference: [34] <author> S. Devadas. </author> <title> General decomposition of sequential machines: Relationships to state assignment. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 314-320, </pages> <month> June </month> <year> 1989. </year> <note> BIBLIOGRAPHY 325 </note>
Reference-contexts: One can see state assignment as producing an FSM decomposition: there is a component FSM of two states (1 memory element) for each encoding bit, and each component FSM depends on the the state of the other components. Connections between state assignment and FSM decomposition have been considered in <ref> [34, 37, 6, 5] </ref>. 4.2.2 State Assignment and State Minimization A sequential behavior may be represented by many different STG's, and different STG's of the same behavior may lead to different logical implementations. This makes elusive the goal of obtaining the best implementation of a given sequential behavior.
Reference: [35] <author> S. Devadas, H-T. Ma, R. Newton, and A. Sangiovanni-Vincentelli. </author> <title> Synthesis and optimization procedures for fully and easily testable sequential machines. </title> <booktitle> In The Proceedings of the International Conference on Computer-Aided Design, </booktitle> <month> November </month> <year> 1987. </year>
Reference-contexts: The translation of a cover obtained by extended symbolic minimization into a compatible boolean representation induces a face embedding, output dominance and output disjunction satisfaction problem. A variety of other applications may also generate similar constraints satisfaction problems, as in the case of synthesis for sequential testability <ref> [35] </ref>, and optimal re-encoding and decomposition of PLA's [40, 21, 122, 120, 119, 121, 123]. <p> Note that the satisfia-bility check algorithm described in [39] cannot be easily extended to handle encoding don't cares without a significant penalty in run-time. The encoding algorithm presented in [147] also cannot be extended to handle don't cares. 6.8.2 Distance-2 Constraints In <ref> [135, 134, 35] </ref> a condition for easy and full sequential testability requires an encoding such that the codes assigned to a selected pair of states, say a and b, must be at least distance-2 apart.
Reference: [36] <author> S. Devadas, H-T. Ma, R. Newton, and A. Sangiovanni-Vincentelli. Mustang: </author> <title> state assignment of finite state machines targeting multi-level logic implementations. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <month> December </month> <year> 1988. </year>
Reference-contexts: There are two main classes of multi-level encoding algorithms: 1. Estimation-based algorithms, that define a distance measure between symbols, such that if "close" symbols are assigned "close" (in terms of Hamming distance) codes it is likely that multi-level synthesis will give good results. Programs such as MUSTANG <ref> [36] </ref>, JEDI [77] and PESTO [57] belong to this class. 2. Synthesis-based algorithms, that use the result of a multi-level optimization on the unencoded or one-hot encoded symbolic cover to drive the encoding process. Programs such as MIS-MV [85] and MUSE [42] belong to this class. <p> Table 4.2 reports the number of literals after running through the standard boolean optimization script in the multi-level logic synthesis system MISII [12] with encodings obtained by NOVA, MUSTANG <ref> [36] </ref>, JEDI [77] and random state assignments. In the case of NOVA only the best minimum code-length two-level result was given to MISII . MUSTANG was run with -p, -n, -pt, -nt options and minimum code-length. JEDI was run with all available options and minimum code-length [76]. <p> We report two kinds of experiments to verify the validity of MIS-MV as input encoder: * Compare the relative importance of the various multi-valued optimization steps. * Compare MIS-MV with some existing state assignment programs, such as JEDI [77], MUSE [42], MUSTANG <ref> [36] </ref> and NOVA [147].
Reference: [37] <author> S. Devadas and A. R. </author> <title> Newton. Decomposition and factorization of sequential finite state machines. </title> <journal> In IEEE Transactions on CAD, </journal> <pages> pages 1206-1217, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: One can see state assignment as producing an FSM decomposition: there is a component FSM of two states (1 memory element) for each encoding bit, and each component FSM depends on the the state of the other components. Connections between state assignment and FSM decomposition have been considered in <ref> [34, 37, 6, 5] </ref>. 4.2.2 State Assignment and State Minimization A sequential behavior may be represented by many different STG's, and different STG's of the same behavior may lead to different logical implementations. This makes elusive the goal of obtaining the best implementation of a given sequential behavior.
Reference: [38] <author> S. Devadas and R. </author> <title> Newton. Corrections to "Exact algorithms for output encoding, state assignment and four-level Boolean minimization". </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 10(11) </volume> <pages> 1469-1469, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: A solution to P-1, when both input and output constraints (including disjunctive constraints) are present, is described in [39], and corrected in <ref> [38] </ref>. A solution to problem P-2 based on compatible graph coloring is provided for input constraints in [154] and extended to output constraints in [20]. To date, to the best of our knowledge, no efficient algorithms exist for solving all three problems when all types of constraints occur.
Reference: [39] <author> S. Devadas and R. </author> <title> Newton. Exact algorithms for output encoding, state assignment and four-level Boolean minimization. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <pages> pages 13-27, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: The encoding problem consists of finding the codes of the signals between the PLA's, so that the constraints imposed by the multiple-valued cover are satisfied. This problem is usually approximated as an input encoding problem [40, 21], but in its generality is an input-output encoding problem referred in <ref> [39] </ref> as four-level Boolean minimization. Exact Encoding with Generalized Prime Implicants An exact procedure for output encoding has been reported in [39]. A notion of generalized prime implicants (GPI's), as an extension of prime implicants defined in [87], is introduced, and appropriate rules of cancellation are given. <p> This problem is usually approximated as an input encoding problem [40, 21], but in its generality is an input-output encoding problem referred in <ref> [39] </ref> as four-level Boolean minimization. Exact Encoding with Generalized Prime Implicants An exact procedure for output encoding has been reported in [39]. A notion of generalized prime implicants (GPI's), as an extension of prime implicants defined in [87], is introduced, and appropriate rules of cancellation are given. Each GPI carries a tag with some output symbols. <p> This can be achieved by solving repeated covering problems that return minimum covers of increasing cardinality, until an encodable cover is found, i.e. the minimum cover that is also encodable. Figure 4.7 shows output encoding based on GPI's with a simple example taken from <ref> [39] </ref>. 4.1.3 Encoding for Multi-level Implementation Automatic multi-level logic synthesis programs are now available to the logic designer [52, 12, 8]), since sometimes a PLA implementation of the circuit does not satisfy the area/timing specifications. <p> This means that output encoding is more important than input encoding on the quality of final results. Comparisons for some of the approaches mentioned above <ref> [124, 39] </ref> have not been carried out for the lack of an available implementation. The Multi-level Case We report a set of experiments that correlate good two-level state assignment to the corresponding multi-level logic implementation, comparing against an estimation-based multi-level encoding algorithm. <p> Then constraints are extracted and a constraints satisfaction problem is set up. Using the paradigm of symbolic minimization followed by constraints satisfaction, the most common types of constraints that may be generated <ref> [92, 91, 39, 116] </ref> are four. The first type, generated by the input variables, are face-embedding constraints. The three types generated by the output variables are dominance, disjunctive and disjunctive-conjunctive constraints. <p> The rest of the reasoning goes as in the previous theorem. Disjunctive-conjunctive constraints were introduced for the first time in <ref> [39] </ref>, as the constraints induced by generalized prime implicants. Our derivation shows that they arise naturally when one wants to find a complete class of encoding constraints. In our symbolic minimization algorithm we used as the class of encoding constraints face constraints, dominance constraints and disjunctive constraints. <p> The treatment of disjunctive constraints is a novelty of this work. Conditions on the completness of sets of encoding constraints and a bridge to disjunctive-conjunctive constraints (presented in <ref> [39] </ref>) are given. A key feature of the algorithm is that it keeps as invariant the property that the minimal symbolic cover under construction is encodeable, by means of efficient procedures that check encodeability of the encoding constraints induced by a candidate cover. <p> SYMBOLIC MINIMIZATION 109 Chapter 6 Encoding Constraints 6.1 Introduction The various techniques for exact and heuristic encoding based on multiple-valued or symbolic minimization of two-level and multi-level logic, reported in <ref> [92, 91, 115, 39, 85, 18] </ref>, produce various types of encoding constraints. By encoding constraints we mean requirements on the codes to be assigned to the symbols. A first type are face-embedding constraints generated by the multiple-valued input variables (input constraints). <p> A disjunctive constraint specifies that the code of a symbol (the parent symbol) is the bit-wise disjunction, denoted by _, e.g., a = b _ c, of the codes of two or more other symbols (the children symbols). The minimization procedure described in <ref> [39] </ref> produces disjunctive-conjunctive constraints. They require that the code of a symbol is the bit-wise disjunction (denoted by _) of the conjunctions, denoted by ^), of the codes of two or more symbols. <p> A solution to P-1, when both input and output constraints (including disjunctive constraints) are present, is described in <ref> [39] </ref>, and corrected in [38]. A solution to problem P-2 based on compatible graph coloring is provided for input constraints in [154] and extended to output constraints in [20]. <p> A minimum cover of 3 primes can be extracted out of them, as shown before. The algorithms described for the feasibility check and exact encoding, shown in Figures 9.1, 9.2 and ?? respectively, extend naturally to encoding don't cares. Note that the satisfia-bility check algorithm described in <ref> [39] </ref> cannot be easily extended to handle encoding don't cares without a significant penalty in run-time. <p> This framework has also been used for solving a variety of encoding constraint satisfaction problems generated by other applications. 145 Chapter 7 Generalized Prime Implicants 7.1 Introduction A method for exploring globally the solution space of optimal two-level encodings was proposed by Devadas and Newton in <ref> [39] </ref>. Their key contribution was the definition of Generalized Prime Implicants (GPI's), as a counterpart of prime implicants in two-level minimization. <p> After 1-hot encoding the onsets of the minterms (values) of a symbolic output are minimized separately. To handle the minimization problem of functions with multi-valued input and multi-valued output variables the concept of generalized prime implicants has been introduced <ref> [39] </ref>. Consider a discrete (alias symbolic) function whose domain and range are finite sets. The previous theory of multi-valued minimization does not take into account the effect of encoding the symbolic output variables to get a minimum two-level encoded function. More precisely it does 7.3. <p> More precisely it does 7.3. GENERALIZED PRIME IMPLICANTS 151 not model the fact that after encoding the onsets of the symbolic outputs are not anymore disjoint. To overcome this limitation a concept of generalized prime implicants has been introduced in <ref> [39] </ref>. Even though the concept can be defined for functions with many symbolic inputs and many symbolic outputs, for simplicity we will restrict most of the discussion to the case of a function with binary inputs, one symbolic input variable, one symbolic output variable and binary outputs. <p> A similar theorem holds replacing prime implicant with implicant. The given definition does not tell us how to compute the GPI's. GPI's can be obtained by a symbolic equivalent of the consensus operation. Actually this is how they were first introduced in <ref> [39] </ref>, as we will see in the next section. <p> Generalized Implicants (GI's) extend the definition of multiple-output implicants to the case that some output variables are symbolic. In analogy to an output tag, the notion of symbolic tag has been introduced in <ref> [39] </ref>. A GI can be written as a cube with associated tags for the multiple-valued and binary-valued output functions. The tag of a cube for a multiple-valued output variable gives the output symbol to whose onset the cube belongs. <p> Therefore any encoding that satisfies the given GI's satisfies also the GPI's of the new cover and therefore encodeability is preserved. 7.4 Reduction of GPI's Computation to MV Primes Computation The next question is how to compute efficiently GPI's. In <ref> [39] </ref> it is shown how to reduce the computation of GPI's to the computation of the primes of a multiple-valued function obtained by transformation of the given FSM. We will generalize the transformation to the case of ISFSM's and prove the correctness of the reduction. <p> One must prove that for every GPI there is a prime of the function (modulo a post-processing step) and viceversa. In the sequel, unless otherwise stated, we will call MV primes those left after the post-processing step applied to the set of primes of the MV function. In <ref> [39] </ref> the rules for consensus and cancellation originally defined for binary cubes (e.g., in [94]) were extended to symbolic cubes. We call them GPI consensus and GPI cancellation. <p> An approach reduces the problem to unate covering with encodeability and it has been proposed in <ref> [39] </ref>. A reduction to binate covering, where encodeability is translated into binate clauses, has been outlined in [133, 132]. Here we introduce the two approaches and discuss their respective merits. We start with reduction of GPI minimization to unate covering. In [39] it is summarily proposed a modification of unate covering <p> covering with encodeability and it has been proposed in <ref> [39] </ref>. A reduction to binate covering, where encodeability is translated into binate clauses, has been outlined in [133, 132]. Here we introduce the two approaches and discuss their respective merits. We start with reduction of GPI minimization to unate covering. In [39] it is summarily proposed a modification of unate covering to solve the problem of selecting a minimum encodeable set of GPI's. Here we present a more complete version of it, clarifying issues arising in the case of state assignment. <p> The next-state table is shown in Fig. 8.6. This table defines a constrained unate covering problem. This table is covered iff some columns are selected that satisfy the encoding constraints (next state constraints, input constraints and uniqueness constraints). The next state constraints are 2 In <ref> [39] </ref> the "same present state" condition is overlooked. 186 CHAPTER 8. <p> Therefore removing row r 1 as row dominated by row r 2 would not guarantee a correct solution of the original problem. A new lower bound will be later defined, based on a maximal independent set of violated encoding dichotomies (similar to the notion of disjoint violations in <ref> [39] </ref>). A solution of the example. Let us select a set of encodeable GPI's that cover the output and next state tables. The output table can be covered by choosing columns 3,5,6,17. <p> There is no backtacking to improve the solution (and no usage of a lower bound). 8.2 Reduction of GPI Minimization to Binate Covering The encodeability check for a set of GPI's, given a bound on the number of encoding bits, was already formulated in <ref> [39] </ref> as a Boolean satisfiability problem. The idea has been advanced further in [133, 132], to cast the whole problem of selecting a minimum encodeable cover of GPI's, for a fixed code-length, as a binate covering problem. An implementation has been described in [19]. <p> Indeed the methods in [82, 62] may succeed in handling huge numbers of clauses, but they are still limited by the numbers of columns, which are the support variables of the required BDD's. 8.3 GPI's and Non-Determinism 8.3.1 Symbolic Don't Cares and Beyond In <ref> [39] </ref> mention is made of symbolic don't cares. In the state assignment context, they arise when more than one next state is allowed for a transition (don't care transitions). <p> r j ) is represented by a pair of positional sets (l; r). 11.2 Implicit Generation of GPI's and Minterms 11.2.1 Implicit Generation of GPI's The step of computing the set of GPI's can be reduced to computing the prime implicants of a boolean function associated to the given FSM <ref> [39] </ref>. A very fruitful recent research effort [53, 30] succeeded in finding efficiently by implicit computations the prime implicants of a boolean function. 284 CHAPTER 11. <p> The next step is to search efficiently encodeable cover of GPI's for specific applications. 11.7.2 Evaluation of the Experiments We have presented a complete algorithm to compute implicitly minimal covers of GPI's. After the seminal contribution in <ref> [39] </ref>, this is the first in-depth algorithmic study that probes the feasibility of generating and selecting sets of GPI's. Since even small symbolic covers generate large sets of GPI's, implicit techniques have been used to generate GPI's, solve table covering problems and verify encodeability. <p> Further computational optimizations and improvements to the quality of the search will make it competitive with the best existing tools. 11.8 Conclusions We have presented a complete procedure to generate and select GPI's <ref> [39] </ref> based on implicit computations. This approach combines techniques for implicit enumeration of primes and implicit solution of covering tables together with a new formulation of the problem of selecting an encodeable cover of GPI's. The proposed algorithms have been implemented using state assignment of FSM's as a test case. <p> The treatment of disjunctive constraints is a novelty of this work. Conditions on the completness of sets of encoding constraints and a bridge to disjunctive-conjunctive constraints (presented in <ref> [39] </ref>) have been given. An invariant of the algorithm is that the minimal symbolic cover under construction is always guaranteed to be encodeable. Encodeability is checked efficiently using the procedures described in Chapter 6. <p> In the multi-level case, only a very time-consuming algorithm based on simulated annealing was known before. This framework has also been used for solving a variety of encoding constraints generated by other applications. In Chapter 11 we have presented a complete procedure to generate and select GPI's <ref> [39] </ref> based on implicit computations. This approach combines techniques for implicit enumeration of primes and implicit solution of covering tables together with a new formulation of the problem of selecting an encodeable cover of GPI's. A novel theory of encodeability of GPI's has been developed in Chapter 9.
Reference: [40] <author> S. Devadas, A. Wang, R. Newton, and A. Sangiovanni-Vincentelli. </author> <title> Boolean decomposition in multilevel logic optimization. </title> <journal> IEEE Journal of solid-state circuits, </journal> <month> April </month> <year> 1989. </year>
Reference-contexts: A variety of other applications may also generate similar constraints satisfaction problems, as in the case of synthesis for sequential testability [35], and optimal re-encoding and decomposition of PLA's <ref> [40, 21, 122, 120, 119, 121, 123] </ref>. Given a PLA, it is possible to group the inputs into pairs and replace the input buffers with two-bit decoders to yield a bit-paired PLA with the same number of columns and no more product-terms than the original PLA. <p> The encoding problem consists of finding the codes of the signals between the PLA's, so that the constraints imposed by the multiple-valued cover are satisfied. This problem is usually approximated as an input encoding problem <ref> [40, 21] </ref>, but in its generality is an input-output encoding problem referred in [39] as four-level Boolean minimization. Exact Encoding with Generalized Prime Implicants An exact procedure for output encoding has been reported in [39].
Reference: [41] <author> T. Dolotta and E. McCluskey. </author> <title> The coding of internal states of sequential machines. </title> <journal> IEEE Transactions on Electronic Computers, </journal> <month> October </month> <year> 1964. </year>
Reference-contexts: The method was then refined in [2]. As a partial solution to the fact that enumerating all encodings and measuring their cost is not a practical solution, Dolotta and McCluskey in <ref> [41] </ref> proposed a method based on the concept of codable columns, that are fewer in number than the possible codes, and whose combinations give the actual encodings. <p> A "scoring procedure" was defined requiring the comparison of each base entry column with the next state entries on a column-by-column basis and allocating a score according to given criteria. Armstrong argued in [2] that the scoring array of <ref> [41] </ref> could be read in the framework that he proposed. Story, Harrison et al. [141, 138] proposed algorithms to derive minimal-cost assignments based on the lower-bound approach first described by Davis [33] and extending the technique to find the cost of an assignment proposed by Torng [141].
Reference: [42] <author> X. Du, G.D.Hachtel, B. Lin, and A.R.Newton. </author> <title> MUSE:a MUltilevel Symbolic Encoding algorithm for state assignment. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <pages> pages CAD-10(1):28-38, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Programs such as MUSTANG [36], JEDI [77] and PESTO [57] belong to this class. 2. Synthesis-based algorithms, that use the result of a multi-level optimization on the unencoded or one-hot encoded symbolic cover to drive the encoding process. Programs such as MIS-MV [85] and MUSE <ref> [42] </ref> belong to this class. Mustang MUSTANG uses the state transition graph to assign a weight to each pair of symbols. This weight measures the desirability of giving the two symbols codes that are "as close as possible". <p> We report two kinds of experiments to verify the validity of MIS-MV as input encoder: * Compare the relative importance of the various multi-valued optimization steps. * Compare MIS-MV with some existing state assignment programs, such as JEDI [77], MUSE <ref> [42] </ref>, MUSTANG [36] and NOVA [147]. <p> The present contribution shows how to extract a minimal encodeable cover from a large set of GPI's, allowing inline of principle theexploration of all minimal encodeable covers. This advances the state-of-art of symbolic minimization, which up to now has been done with various heuristic tools <ref> [92, 147, 42, 77] </ref>, often very well-tuned for their domain of application, but lacking a rigorous connection beween an exact theory and the approximations made. <p> The present contribution shows how to extract a minimal encodeable cover from a large set of GPI's, allowing inline of principle theexploration of all minimal encodeable covers. This advances the state-of-art of symbolic minimization, which up to now has been done with various heuristic tools <ref> [92, 147, 42, 77] </ref>, often very well-tuned for their domain of application, but lacking a rigorous 314 CHAPTER 11. IMPLICIT MINIMIZATION OF GPI'S connection beween an exact theory and the approximations made.
Reference: [43] <author> C. </author> <type> Duff. </type> <institution> Codage d'automates et theorie des cubes intersectants. Th ese, Institut National Polytechnique de Grenoble, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: Exact algorithms and efficient heuristics (restricted to input and dominance constraints) for solving problems P-2 and P-3 are reported in [147]. An approximate solution to P-3 for input constraints based on a theory of intersecting cubes is described in <ref> [126, 43] </ref> and a solution based on simulated annealing is reported in [81]. An exact solution to P-2 for input constraints based on the notion of prime sections is described in [44, 45].
Reference: [44] <author> E.I.Goldberg. </author> <title> Matrix formulation of constrained encoding problems in optimal PLA synthesis. </title> <type> Preprint No. 19, </type> <institution> Institute of Engineering Cybernetics, Academy of Sciences of Belarus, </institution> <year> 1993. </year>
Reference-contexts: SYMBOLIC MINIMIZATION BY EXAMPLE 93 OnCov: on-set of st2 0010000 on-set of st4 0000100 OffCov: on-set of st2 0001100 on-set of st4 0011000 on-set of st5 0011100 established in [154]. Other contributions on the subject can be found in [126, 20] and more recently in <ref> [44, 45] </ref>. 5.8 Symbolic Minimization by Example In this section we clarify with an example the mechanics by which the oring effects plays an important role in the minimization of symbolic logic. <p> An approximate solution to P-3 for input constraints based on a theory of intersecting cubes is described in [126, 43] and a solution based on simulated annealing is reported in [81]. An exact solution to P-2 for input constraints based on the notion of prime sections is described in <ref> [44, 45] </ref>. This approach seems very promising because of the claim that prime sections are fewer than prime dichotomies, the latter being the building blocks of encodings in the theory that we are going to use in this chapter.
Reference: [45] <author> E.I.Goldberg. </author> <title> Face embedding by componentwise construction of intersecting cubes. </title> <type> Preprint No. 1, </type> <institution> Institute of Engineering Cybernetics, Academy of Sciences of Belarus, </institution> <year> 1995. </year> <note> 326 BIBLIOGRAPHY </note>
Reference-contexts: SYMBOLIC MINIMIZATION BY EXAMPLE 93 OnCov: on-set of st2 0010000 on-set of st4 0000100 OffCov: on-set of st2 0001100 on-set of st4 0011000 on-set of st5 0011100 established in [154]. Other contributions on the subject can be found in [126, 20] and more recently in <ref> [44, 45] </ref>. 5.8 Symbolic Minimization by Example In this section we clarify with an example the mechanics by which the oring effects plays an important role in the minimization of symbolic logic. <p> An approximate solution to P-3 for input constraints based on a theory of intersecting cubes is described in [126, 43] and a solution based on simulated annealing is reported in [81]. An exact solution to P-2 for input constraints based on the notion of prime sections is described in <ref> [44, 45] </ref>. This approach seems very promising because of the claim that prime sections are fewer than prime dichotomies, the latter being the building blocks of encodings in the theory that we are going to use in this chapter.
Reference: [46] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <year> 1979. </year>
Reference-contexts: DEFINITIONS 33 Chapter 3 Complexity Issues 3.1 Computational Complexity In this section we will present some results on the computational complexity of state assignment for minimum area. We refer to <ref> [46, 104, 9] </ref> as standard references on computational complexity and the theory of N P -completness in particular. Computational complexity of logic optimization problems has been discussed in [69], from which we will draw results. An instance of a problem is encoded as a string (or word) of a language. <p> More simply one wants a reduction R that can be computed in polynomial time. 3.1. COMPUTATIONAL COMPLEXITY 35 A fundamental result due to Cook <ref> [46] </ref> shows that SAT is as hard as any problem in N P , i.e. knowing how to solve SAT efficiently (in polynomial time) would enable us to solve efficiently any other problem in N P . <p> S and a positive integer k jCj, does C contain a cover for S of size k, i.e. a subset C 0 C with jC 0 j k such that every element of S belongs to at least one member of C 0 ? It shown to be NP-complete in <ref> [46] </ref>. 3.1. COMPUTATIONAL COMPLEXITY 39 and the set S are specified by a matrix whose columns are the subsets in C and whose rows are the elements of S, such that entry (i; j) is a 1 iff element i is in subset j and 0 otherwise. <p> This is in part due to the lack of fine tuning of the complexity classes of the polynomial hierarchy. It would be worthy to see if a finer classification can be achieved looking into approximation complexity classes <ref> [46, 104, 9] </ref>. Similar results could be obtained for other optimization objectives, like minimum number of literals of multi-level implementations [69]. <p> If A is given in product-of-sums form, finding a satisfying assignment is exactly the problem SAT, the prototypical N P -complete problem <ref> [46] </ref>. In this case it also possible to write A as an array of cubes (that form a matrix with coefficients from the set f0; 1; 2g).
Reference: [47] <author> J. Gimpel. </author> <title> A method of producing a boolean function having an arbitrarily prescribed prime implicant table. </title> <journal> IRE Transactions on Electronic Computers, </journal> <volume> EC-14:485-488, </volume> <month> June </month> <year> 1965. </year>
Reference-contexts: Say that there are n rows and m columns. It has been shown by Gimpel <ref> [47] </ref> that one can build an incompletely specified Boolean function on the set of variables x 1 ; x 2 ; ; x m+n .
Reference: [48] <author> J. Gimpel. </author> <title> A reduction technique for prime implicant tables. </title> <journal> IRE Transactions on Electronic Computers, </journal> <volume> EC-14:535-541, </volume> <month> August </month> <year> 1965. </year>
Reference-contexts: This definition of infeasibility is * not mentioned in [50] and [51], * briefly mentioned in [14], * identical to the unfeasible problem in [13]. 10.5.12 Gimpel's Reduction Step Another heuristic for solving the minimum cover problem has been suggested by Gim-pel <ref> [48] </ref>. Gimpel proposed a reduction step which simplifies the covering matrix when it has a special form. This simplification is possible without further branching, and hence is useful at each step of the branch and bound algorithm. <p> Robinson and House [60] showed that the reduction remains valid even for weighted covering problems if the cost of the column c 1 equals the cost of the column c 2 , as it has been presented here. Gimpel's rule has been first proposed in <ref> [48] </ref> and then implemented in [112]. In [108, 130] Gimpel's rule has been extended to handle the binate case. This extension has been described in [131]. 10.6.
Reference: [49] <author> G.N.Raney. </author> <title> Sequential functions. </title> <journal> Journal of the Association of Computing Machinery, </journal> <pages> pages 177-180, </pages> <year> 1958. </year>
Reference: [50] <author> A. Grasselli and F. Luccio. </author> <title> A method for minimizing the number of internal states in incompletely specified sequential networks. </title> <journal> IRE Transactions on Electronic Computers, </journal> <volume> EC-14(3):350-359, </volume> <month> June </month> <year> 1965. </year>
Reference-contexts: A binate covering problem can be set up, where each column of the table is a prime compatible and each row is one of the covering or closure clauses of the problem <ref> [50] </ref>. There are as many covering clauses as states of the original machine and each of them requires that a state is covered by selecting any of the prime compatibles in which it is contained. <p> This technique has been described in <ref> [51, 50, 13, 14] </ref>, and implemented in successful computer programs [112, 108, 130]. The branch-and-bound solution of minimum binate covering is based on a recursive procedure. A run of the algorithm can be described by its computation tree. <p> Even though more complex criteria of dominance have been investigated (for instance, Section 10.5.12), the previous ones are basic in any table covering solver. Reduction rules have previously been stated for the binate covering case <ref> [50, 51, 14, 13] </ref>, and also for the unate covering case [87, 113, 13]. Here we will present the known reduction rules directly for binate covering and indicate how they simplify for unate covering, when applicable. <p> For each of them, we will first define the reduction rule, and then a theorem showing how that rule is applied. Proofs for the correctness of these reduction rules have been given in <ref> [50, 51, 14, 13] </ref>, and they will not be repeated here, except for a few less common ones. We will provide a survey comparing different related reduction rules used in the literature. The effect of reductions depends on the order of their application. <p> Theorem 10.5.1 If a row R j is dominated by another row R i , R j can be eliminated without affecting the solutions to the covering problem. This definition of row dominance is * similar to column dominance (Rule 3) in <ref> [50] </ref>, except that the labels of dominator row, R i , and dominated row, R j , are reversed (i.e., reverse definition of dominance), * similar to column dominance (Rule 3) in [51], except that the labels of dominator row, R i , and dominated row, R j , are reversed <p> This definition of column ff-dominance is * an extension to row ff-dominance (Rule 1) in <ref> [50] </ref>, because the latter doesn't include the case M i;j = 0 and M i;k = 0, 10.5. <p> This definition of column fi-dominance is * strictly stronger than column ff-dominance given in 10.5.3, * more general than row fi-dominance (Rule 5) in <ref> [50] </ref>, because the latter assumes that the covering table contains only rows with no or one 0, * equivalent to second half of Rule 4 in [51]: (a) C i has all the 1's of C j and (b2) for every row R p in which C i has a 0, <p> Column C j must then be deleted together with all the rows in which it has 1's. This definition of essential column is * identical to essential row (Rule 2) in <ref> [50] </ref>, * identical to Rule 1 in [51], * included in Definition 9 in [14]: the row R i in the above definition corresponds to a singleton-1 essential row in [14], * included in Definition 2.10 in [13]: the row R i in the above definition corresponds to a singleton-1 essential <p> BINATE COVERING Theorem 10.5.8 If C j is an unacceptable column, it must be eliminated (x j = 0) in every solution, together with all the rows in which it has 0's. This definition of unacceptable column is * identical to that of nonselectionable row in <ref> [50] </ref>, * identical to Rule 2 in [51], * included in Definition 9 in [14]: the row R i in the above definition corresponds to a singleton-0 essential row in [14], * included in Definition 2.10 in [13]: the row R i in the above definition corresponds to a singleton-0 essential <p> Theorem 10.5.9 If C j is an unnecessary column, it may be eliminated (x j = 0), together with all the rows in which it has 0's. This definition of unnecessary column is * identical to Rule 4 in <ref> [50] </ref>, * identical to Rule 5 in [51], * not mentioned in [14] and [13]. 10.5.10 Trial Rule Theorem 10.5.10 If there exists in a covering table M a row R i having a 0 in column C j , a 1 in column C k and 2's in the rest, <p> Therefore, C k can be deleted together with all the columns in which it has 1's. This reduction rule is * identical to Rule 6 in <ref> [50] </ref>, * not mentioned in other papers. 10.5.11 Infeasible Subproblem Unlike the unate covering problem, the binate covering problem may be infeasible. In particular, an intermediate covering matrix M may found to be unsatisfiable by the following theorem. <p> Theorem 10.5.11 A covering problem M is infeasible if there exists a column C j which is both essential and unacceptable (implying x j = 1 and x j = 0). This definition of infeasibility is * not mentioned in <ref> [50] </ref> and [51], * briefly mentioned in [14], * identical to the unfeasible problem in [13]. 10.5.12 Gimpel's Reduction Step Another heuristic for solving the minimum cover problem has been suggested by Gim-pel [48]. Gimpel proposed a reduction step which simplifies the covering matrix when it has a special form. <p> = Choose Column (R; C) S 1 = mincov (R c i ; C c i ; U ) S 0 = mincov (R c i ; C c i ; U ) return Best Solution (S 1 [ fc i g; S 0 ) g The classical branch-and-bound algorithm <ref> [50, 51] </ref> for minimum-cost binate covering has been described in previous sections, and implemented by means of efficient computer programs (ESPRESSO and STAMINA). These state-of-the-art binate table solvers represent binate tables efficiently using sparse matrix packages.
Reference: [51] <author> A. Grasselli and F. Luccio. </author> <title> Some covering problems in switching theory. </title> <booktitle> In Networks and Switching Theory, </booktitle> <pages> pages 536-557. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1968. </year>
Reference-contexts: This technique has been described in <ref> [51, 50, 13, 14] </ref>, and implemented in successful computer programs [112, 108, 130]. The branch-and-bound solution of minimum binate covering is based on a recursive procedure. A run of the algorithm can be described by its computation tree. <p> Even though more complex criteria of dominance have been investigated (for instance, Section 10.5.12), the previous ones are basic in any table covering solver. Reduction rules have previously been stated for the binate covering case <ref> [50, 51, 14, 13] </ref>, and also for the unate covering case [87, 113, 13]. Here we will present the known reduction rules directly for binate covering and indicate how they simplify for unate covering, when applicable. <p> For each of them, we will first define the reduction rule, and then a theorem showing how that rule is applied. Proofs for the correctness of these reduction rules have been given in <ref> [50, 51, 14, 13] </ref>, and they will not be repeated here, except for a few less common ones. We will provide a survey comparing different related reduction rules used in the literature. The effect of reductions depends on the order of their application. <p> This definition of row dominance is * similar to column dominance (Rule 3) in [50], except that the labels of dominator row, R i , and dominated row, R j , are reversed (i.e., reverse definition of dominance), * similar to column dominance (Rule 3) in <ref> [51] </ref>, except that the labels of dominator row, R i , and dominated row, R j , are reversed (i.e., reverse definition of dominance), * equivalent to row dominance (Definition 10) in [14], * identical to row dominance (Definition 2.11) in [13]. <p> This definition of column ff-dominance is * an extension to row ff-dominance (Rule 1) in [50], because the latter doesn't include the case M i;j = 0 and M i;k = 0, 10.5. REDUCTION TECHNIQUES 247 * equivalent to first half of Rule 4 in <ref> [51] </ref>: (a) C j has all the 1's of C k and (b1) C k has all the 0's of C j , * identical to column dominance (Definition 11, Theorem 3) in [14], * identical to column dominance (Definition 2.12, Theorem 2.4.1) in [13]. <p> This definition of column fi-dominance is * strictly stronger than column ff-dominance given in 10.5.3, * more general than row fi-dominance (Rule 5) in [50], because the latter assumes that the covering table contains only rows with no or one 0, * equivalent to second half of Rule 4 in <ref> [51] </ref>: (a) C i has all the 1's of C j and (b2) for every row R p in which C i has a 0, there exists a row R q in which C j has a 0, such that disregarding entries in row C i and C j , R <p> Column C j must then be deleted together with all the rows in which it has 1's. This definition of essential column is * identical to essential row (Rule 2) in [50], * identical to Rule 1 in <ref> [51] </ref>, * included in Definition 9 in [14]: the row R i in the above definition corresponds to a singleton-1 essential row in [14], * included in Definition 2.10 in [13]: the row R i in the above definition corresponds to a singleton-1 essential row in [13]. <p> This definition of unacceptable column is * identical to that of nonselectionable row in [50], * identical to Rule 2 in <ref> [51] </ref>, * included in Definition 9 in [14]: the row R i in the above definition corresponds to a singleton-0 essential row in [14], * included in Definition 2.10 in [13]: the row R i in the above definition corresponds to a singleton-0 essential row in [13]. 10.5.9 Unnecessary Column Definition <p> Theorem 10.5.9 If C j is an unnecessary column, it may be eliminated (x j = 0), together with all the rows in which it has 0's. This definition of unnecessary column is * identical to Rule 4 in [50], * identical to Rule 5 in <ref> [51] </ref>, * not mentioned in [14] and [13]. 10.5.10 Trial Rule Theorem 10.5.10 If there exists in a covering table M a row R i having a 0 in column C j , a 1 in column C k and 2's in the rest, then apply the following test: * eliminate <p> Theorem 10.5.11 A covering problem M is infeasible if there exists a column C j which is both essential and unacceptable (implying x j = 1 and x j = 0). This definition of infeasibility is * not mentioned in [50] and <ref> [51] </ref>, * briefly mentioned in [14], * identical to the unfeasible problem in [13]. 10.5.12 Gimpel's Reduction Step Another heuristic for solving the minimum cover problem has been suggested by Gim-pel [48]. Gimpel proposed a reduction step which simplifies the covering matrix when it has a special form. <p> = Choose Column (R; C) S 1 = mincov (R c i ; C c i ; U ) S 0 = mincov (R c i ; C c i ; U ) return Best Solution (S 1 [ fc i g; S 0 ) g The classical branch-and-bound algorithm <ref> [50, 51] </ref> for minimum-cost binate covering has been described in previous sections, and implemented by means of efficient computer programs (ESPRESSO and STAMINA). These state-of-the-art binate table solvers represent binate tables efficiently using sparse matrix packages.
Reference: [52] <author> D. Gregory, K. Bartlett, A. DeGeus, and G. Hachtel. SOCRATES: </author> <title> A system for automatically synthesizing and optimizing combinational logic. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <year> 1986. </year>
Reference-contexts: Figure 4.7 shows output encoding based on GPI's with a simple example taken from [39]. 4.1.3 Encoding for Multi-level Implementation Automatic multi-level logic synthesis programs are now available to the logic designer <ref> [52, 12, 8] </ref>), since sometimes a PLA implementation of the circuit does not satisfy the area/timing specifications.
Reference: [53] <author> G.Swamy, R.Brayton, and P.McGeer. </author> <title> A fully implicit Quine-McCluskey procedure using BDD's. </title> <type> Tech. Report No. </type> <institution> UCB/ERL M92/127, </institution> <year> 1992. </year>
Reference-contexts: Here, loosely, we consider a representation as explicit if it requires space lineraly proportional to the size of the represented set. In particular, researchers at Bull and UCB <ref> [25, 79, 53] </ref> investigated implicit computations of prime implicants of a two-valued or multi-valued function. In some examples all primes could be computed implicitly, even when explicit techniques implemented in ESPRESSO [11] failed to do so. <p> In some examples all primes could be computed implicitly, even when explicit techniques implemented in ESPRESSO [11] failed to do so. Moreover, implicit algorithms have been designed to reduce the unate table of the Quine-McCluskey procedure to its cyclic core <ref> [29, 53] </ref>, and to solve the binate covering problem associated with exact state minimization [66]. In the present work we capitalize on these algorithmic technologies to propose a complete procedure to generate and select GPI's based on implicit computations. This approach combines 146 CHAPTER 7. <p> We will generalize the transformation to the case of ISFSM's and prove the correctness of the reduction. This reduction is of great interest because it allows to exploit existing efficient algorithms for prime generation <ref> [114, 53] </ref>. We will describe briefly in Section 11.2 efficient algorithms for generation of large sets of primes and report on their application to this problem. 4 GPI cancellation when the present state part of the cancelling cube is full preserves encodeability because it actually relaxes input constraints. 7.4. <p> By means of techniques as in <ref> [79, 53, 30] </ref>, GPI's can be generated using BDD-based (alias implicit) representations. The next step is to select an encodeable cover of GPI's using implicit representations. This motivates the development of new algorithms to solve covering problems based on the representation and manipulation of covering tables represented with BDD's. <p> Reported experiments show a suite of examples where all primes could be computed, whereas explicit techniques implemented in ESPRESSO [11] failed to do so. Finally, the fixed-point dominance computation in the covering step of the Quine-McCluskey procedure has been made implicit in current work <ref> [29, 53] </ref>. The experiments reported show that the cyclic core of all logic functions of the ESPRESSO benchmark can be successfully computed. For some of them ESPRESSO failed the task. This chapter describes an implicit formulation of the binate covering problem and presents an implementation. <p> The set of all primes and minterms may be exponential in the number of input variables. Manipulating a table with an exponential number of rows and columns may add another exponential blow-up. To overcome these problems, researchers at Bull [29, 30] and UCB <ref> [53] </ref> have represented the set of primes and the unate table with logic functions implemented with ROBDD's. The key steps have been: 10.10. IMPLICIT TWO-LEVEL LOGIC MINIMIZATION 271 1. Define a boolean space where all those sets could be represented. 2. <p> A very fruitful recent research effort <ref> [53, 30] </ref> succeeded in finding efficiently by implicit computations the prime implicants of a boolean function. 284 CHAPTER 11. IMPLICIT MINIMIZATION OF GPI'S We refer to [53, 30] for a complete treatment of the topic and we report here a few facts required in our application. <p> A very fruitful recent research effort <ref> [53, 30] </ref> succeeded in finding efficiently by implicit computations the prime implicants of a boolean function. 284 CHAPTER 11. IMPLICIT MINIMIZATION OF GPI'S We refer to [53, 30] for a complete treatment of the topic and we report here a few facts required in our application. <p> The program ISA computes the primes of the companion function (from which GPI's are obtained after a reduction process) using routines kindly provided by G.M.Swamy from her two-level logic minimizer <ref> [53] </ref>. Then ISA selects a cover of GPI's calling the implicit table solver described in [66]. As a next step, we have implemented the computations shown in Figure 11.5 to obtain a minimal encodeable cover of GPI's.
Reference: [54] <author> J. Hartmanis. </author> <title> On the state assignment problem for sequential machines - 1. </title> <journal> IRE Transactions on Electronic Computers, </journal> <month> June </month> <year> 1961. </year>
Reference-contexts: PREVIOUS AND RELATED WORK taken into consideration in the optimization procedure. This work was refined and commented by other contributions [101, 102, 103]. Others, as <ref> [54, 137, 67] </ref>, proposed algebraic methods based on the algebra of partitions and on the criterion of reduced dependency.
Reference: [55] <author> J. Hartmanis and R. E. Stearns. </author> <title> Some dangers in the state reduction of sequential machines. </title> <journal> In Information and Control, </journal> <volume> volume 5, </volume> <pages> pages 252-260, </pages> <month> September </month> <year> 1962. </year>
Reference-contexts: So one could think that by doing state minimization and then state assignment the best implementation could be obtained. It is not always so, as it was recognized long ago by Hartmanis and Stearns, who gave in <ref> [55] </ref> an example of an FSM whose best implementation has fewer product-terms than the best implementation obtained after state minimization of the original machine. Therefore in order to get a minimum implementation one should merge the steps of state minimization and state assignment. <p> Currently it is common to do state minimization first and then to perform state assignment, since an STG with minimum number of states is usually a good starting point for state assignment. But it is a suboptimal procedure, as pointed out first in <ref> [55] </ref>. Given a CSFSM, state minimization returns a unique reduced FSM (up to state renaming). State minimization of CSFSM's merges all equivalent states into one state.
Reference: [56] <author> J. Hartmanis and R. E. Stearns. </author> <title> Algebraic Structure Theory of Sequential Machines. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N. J., </address> <year> 1966. </year>
Reference-contexts: The properties depend on the chosen topology. In the case of a general decomposition it is sufficient the minimum requirement that the product of the partitions be the zero-partition; for a parallel decomposition every partition must be closed. Instead of partitions one could look for set systems <ref> [56] </ref> (states may be in more than one block) and explore a larger solution space, but it is not done in the referred project. Suppose that one looks for a general decomposition into two submachines (it always exists).
Reference: [57] <author> B. Holmer. </author> <title> What are the ingredients for a good state assignment program ? Tech. </title> <type> Report No. </type> <institution> CSE-95-002, EECS Department, Northwestern University, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: Estimation-based algorithms, that define a distance measure between symbols, such that if "close" symbols are assigned "close" (in terms of Hamming distance) codes it is likely that multi-level synthesis will give good results. Programs such as MUSTANG [36], JEDI [77] and PESTO <ref> [57] </ref> belong to this class. 2. Synthesis-based algorithms, that use the result of a multi-level optimization on the unencoded or one-hot encoded symbolic cover to drive the encoding process. Programs such as MIS-MV [85] and MUSE [42] belong to this class. <p> The greedy embedding algorithm chooses at each step the symbol that has the strongest weight connection with already assigned symbols, and assigns to it a code that minimizes the above cost function. Pesto PESTO <ref> [57] </ref> is a new tool that resembles JEDI with respect to the basic model, but by means of very skilled algorithmic engineering obtains codes that produce often (as of today) the best starting points for multi-level implementations.
Reference: [58] <author> J. E. Hopcroft and J. D. Ullman. </author> <title> Introduction to Automata Theory, Languages, and Computation. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1979. </year> <note> BIBLIOGRAPHY 327 </note>
Reference: [59] <author> R. W. House and D.W. Stevens. </author> <title> A new rule for reducing cc tables. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-19:1108-1111, </volume> <month> November </month> <year> 1970. </year>
Reference-contexts: In that case the last application of row consensus is potentially faulty and should not be done. Row consensus is applied in [108]. This criterion generalizes the one given in <ref> [59] </ref>. 10.5.3 Column ff-Dominance Definition 10.5.3 A column C j ff-dominates another column C k if * c j c k , * C k has all the 0's of C j ; i.e., c j c k , and for each row R i of M, none of the following
Reference: [60] <author> S. Robinson III and R. House. </author> <title> Gimpel's reduction technique extended to the covering problem with costs. </title> <journal> IRE Transactions on Electronic Computers, </journal> <volume> EC-16:509-514, </volume> <month> August </month> <year> 1967. </year>
Reference-contexts: The resulting cover is a minimum cover for p. A proof can be found in [113], where a more extended discussion is presented. Gimpel's reduction step was originally stated for covering problems where each column had cost 1. Robinson and House <ref> [60] </ref> showed that the reduction remains valid even for weighted covering problems if the cost of the column c 1 equals the cost of the column c 2 , as it has been presented here. Gimpel's rule has been first proposed in [48] and then implemented in [112].
Reference: [61] <author> S.-W. Jeong and F. Somenzi. </author> <title> A new algorithm for 0-1 programming based on binary decision diagrams. </title> <booktitle> In Proceedings of ISKIT-92, Inter. symp. on logic synthesis and microproc. arch., Iizuka, Japan, </booktitle> <pages> pages 177-184, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: In that case the number of variables of the BDD is the number of columns of the binate table. Recently, a mixed technique has been proposed in <ref> [61] </ref>. It is a branch-and-bound algorithm, where the clauses are represented as a conjunction of BDD's. The usage of BDD's leads to an effective method to compute a lower bound on the cost of the solution. Notice that unate covering is a special case of binate covering. <p> ) I 1 = ( j6=i w j x j T w i ) P f 1 = LI to BDD (I 1 ) return f = x i f 1 + x i f 0 g As an example of reduction from ILP to BCP, a procedure (taken from <ref> [61] </ref>) that derives the Boolean expression corresponding to P n j=1 w j :x j T is shown in Figure 10.1.
Reference: [62] <author> S.-W. Jeong and F. Somenzi. </author> <title> A new algorithm for the binate covering problem and its application to the minimization of boolean relations. </title> <booktitle> In The Proceedings of the International Conference on Computer-Aided Design, </booktitle> <month> November </month> <year> 1992. </year>
Reference-contexts: Since both the number of columns (roughly, the number of GPI's) and of rows (even larger than the number of columns) become quickly very large, even approaches that solve binate covering by means of a shortest path computation of the clauses represented by BDD's as in <ref> [82, 62] </ref> have been unable to solve non-trivial instances. Indeed the methods in [82, 62] may succeed in handling huge numbers of clauses, but they are still limited by the numbers of columns, which are the support variables of the required BDD's. 8.3 GPI's and Non-Determinism 8.3.1 Symbolic Don't Cares and <p> of GPI's) and of rows (even larger than the number of columns) become quickly very large, even approaches that solve binate covering by means of a shortest path computation of the clauses represented by BDD's as in <ref> [82, 62] </ref> have been unable to solve non-trivial instances. Indeed the methods in [82, 62] may succeed in handling huge numbers of clauses, but they are still limited by the numbers of columns, which are the support variables of the required BDD's. 8.3 GPI's and Non-Determinism 8.3.1 Symbolic Don't Cares and Beyond In [39] mention is made of symbolic don't cares.
Reference: [63] <author> T. Kam. </author> <title> State minimization of finite state machines using implicit techniques. </title> <type> Ph.D. Thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1995. </year>
Reference-contexts: Since covering problems are ubiquitous in logic synthesis and combinatorial optimization, in this chapter we will develop a general theory of implicit solutions of binate covering problems. It is a development of large applicability, as shown by its successful application to an host of problems in state minimization <ref> [63] </ref>. In the next chapter we will see how this formulation is employed in the GPI minimization problem. <p> The implicit binate solver has been tested for the selection of an encodable set of 10.2. RELATION TO 0-1 INTEGER LINEAR PROGRAMMING 233 GPI's, as reported in Chapter 11, and for state minimization of ISFSM's and pseudo NDFSM's <ref> [63] </ref>. The reported experiments show that implicit techniques have pushed the frontier of instances where binate covering problems can be solved exactly, resulting in better optimizations in key steps of sequential logic synthesis. <p> For example, we would not expect these binate solvers to handle examples requiring over 10 6 columns (up to 2 1500 columns), reported in state minimization of FSM's <ref> [63] </ref>. To keep with our stated objective, the binate table has to be represented implicitly. We do not represent (even implicitly) the elements of the table, but we make use only of a set of row labels and a set of column labels, each represented implicitly as a BDD. <p> In Chapter 11 we will see how the covering tables occurring in GPI minimization are generated. In <ref> [63] </ref> it is shown how covering tables occurring in state minimization of FSM's are constructed. In the next section, we will describe how a binate covering table can be manipulated implicitly so as to solve the minimum cost binate covering problem. 1.
Reference: [64] <author> T. Kam and R.K. Brayton. </author> <title> Multi-valued decision diagrams. </title> <type> Tech. Report No. </type> <institution> UCB/ERL M90/125, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: We represent a relation R by its characteristic function R : D fi B m ! B such that R (x; y) = 1 if and only if (x; y) 2 R. In the implementation, we represent a characteristic function by using a multi-valued decision diagram (MDD, see <ref> [64, 136] </ref>). An MDD is a data structure to represent a function with multiple-valued input variables and a single binary output, which employs a BDD [16] as the internal data structure.
Reference: [65] <author> T. Kam, T. Villa, R. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> A fully implicit algorithm for exact state minimization. </title> <type> Tech. Report No. </type> <institution> UCB/ERL M93/79, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: By imposing restrictions on the way in which rows and columns are labeled and entries are defined, one gets representations with varying degrees of generality. Historically the third (less general) way was implemented first to solve exact state minimization of ISFSM's <ref> [65] </ref>. It is applicable to other problems whose covering table can be represented in the same way, e.g., the exact formulation of technology mapping for area minimization [113]. <p> (r) = Lmax (R (r) C (c) 01 (r; c) ; c) C k (c) = C (c) 9r fR k1 (r) 01 (r; c)g This sub-block is extracted from the table (R; C) and the above iteration is applied again to the remaining table, until the table becomes empty. <ref> [65] </ref> provides a more detailed explanation. Given a covering table, a single row R 0 (r), which has the maximum number of nonempty entries, is first picked using Lmax (). The set of columns C 1 (c) intersecting this row at 0 or 1 270 CHAPTER 10. <p> A BDD representing S (x) will contain minterms, each corresponding to a state set in S. 11.1.3 Operations on Positional-sets With our definitions of relations and positional-set notation for representing set of states, useful operators on sets and sets of sets can be derived. We have proposed in <ref> [65] </ref> a unified notational framework for set manipulation, extending the work by Lin et al. in [79]. Here we define some basic operators.
Reference: [66] <author> T. Kam, T. Villa, R. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> A fully implicit algorithm for exact state minimization. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 684-690, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Moreover, implicit algorithms have been designed to reduce the unate table of the Quine-McCluskey procedure to its cyclic core [29, 53], and to solve the binate covering problem associated with exact state minimization <ref> [66] </ref>. In the present work we capitalize on these algorithmic technologies to propose a complete procedure to generate and select GPI's based on implicit computations. This approach combines 146 CHAPTER 7. <p> The procedure is patterned on the branch-and-bound algorithm used to find an exact solution to unate covering <ref> [66] </ref>. Theorem 8.1.1 The algorithm of Figure 8.7 finds a minimum cardinality selection of GPI's that is a cover of the original FSM and that is encodeable. <p> Notice that in the papers by the researchers at Bull no implicitization is reported of the choice of a branching column and of a lower bound computation. Implicit formulations of such operations were instead reported first in <ref> [66] </ref>. In [30] it is stated that the usage of Zero-Suppressed BDD's by Minato [95] instead of ROBDD's [16] resulted in more efficient implicit representations of the computations of the problem. 278 CHAPTER 10. <p> For instance T uple jxj (x) gives the universe set on the support x, T uple 0 (x) gives the empty set on the support x. Finally we need the operators of the family Lmin and Lmax, first proposed in <ref> [66] </ref>, to which we refer for detailed explanations. Besides those already described in [66], we introduce a new operator Multi Lmin, that is a variant of Lmin. <p> Finally we need the operators of the family Lmin and Lmax, first proposed in <ref> [66] </ref>, to which we refer for detailed explanations. Besides those already described in [66], we introduce a new operator Multi Lmin, that is a variant of Lmin. Given a binary relation F (r; c) as a BDD, Lmin (F (r; c); r) computes F Lm (c), the set of c's which relate to the minimum number of r's in F (r; c). <p> The table is unate, i.e., either an entry is 1 or it is empty. We will use an implicit table solver to select a subset of GPI's that cover the minterms. Implicit algorithms to solve binate covering problems were presented in <ref> [66] </ref>. We implemented two implicit binate solvers: a specialized one with a fixed table definition rule and a general one, where one specifies by means of functions how entries are evaluated. <p> First, we know that the set fag is contained in the set fabcg and thus the latter conjunct is redundant in the right hand-side. Such redundancies can be removed by the M inimal n 0 operator <ref> [66] </ref>. The constraint is then simplified to a = a which is trivially satisfiable. <p> ; n 0 ) (i 0 i) (p 0 p)g: A lower bound on the number of additional GPI's to make the problem satisfiable can be found by computing the maximal independent set of rows in table T 2 , by means of the M ax I ndep Set operator <ref> [66] </ref> as follows: lower bound = M ax I ndep Set (T 2 ; (x; y); (i 0 ; p 0 ; n 0 )): 298 CHAPTER 11. <p> The program ISA computes the primes of the companion function (from which GPI's are obtained after a reduction process) using routines kindly provided by G.M.Swamy from her two-level logic minimizer [53]. Then ISA selects a cover of GPI's calling the implicit table solver described in <ref> [66] </ref>. As a next step, we have implemented the computations shown in Figure 11.5 to obtain a minimal encodeable cover of GPI's. The core computations are based on the representation of the characteristic functions of relations by means of BDD's. <p> Also the covering problems faced to select covers of GPI's and of prime encoding dichotomies, even though they are unate, are often tougher than those encountered in the ESPRESSO benchmark and in the state minimization of FSM's <ref> [66] </ref>, a reason being the larger variable support of the BDD representations of columns and rows. To be able to solve the examples of the previous tables, the package described in [66] had to be further optimized and inadequacies still remain to be addressed. <p> are unate, are often tougher than those encountered in the ESPRESSO benchmark and in the state minimization of FSM's <ref> [66] </ref>, a reason being the larger variable support of the BDD representations of columns and rows. To be able to solve the examples of the previous tables, the package described in [66] had to be further optimized and inadequacies still remain to be addressed. The implicit check of feasibility has not been a bottleneck in experiments tried so far.
Reference: [67] <author> R. Karp. </author> <title> Some techniques for state assignment for synchronous sequential machines. </title> <journal> IEEE Transactions on Electronic Computers, </journal> <month> October </month> <year> 1964. </year>
Reference-contexts: PREVIOUS AND RELATED WORK taken into consideration in the optimization procedure. This work was refined and commented by other contributions [101, 102, 103]. Others, as <ref> [54, 137, 67] </ref>, proposed algebraic methods based on the algebra of partitions and on the criterion of reduced dependency.
Reference: [68] <author> B. Kernighan and S. Lin. </author> <title> An efficient heuristic procedure for partitioning graphs. </title> <journal> Bell System Technical Journal, </journal> <month> February </month> <year> 1970. </year>
Reference-contexts: Splitting of symbols: We are interested in obtaining two sub-problems, each using one less code bit than the given problem does. In splitting the symbols into disjoint partitions, the fewest constraints should be violated. This is achieved by using a modification of the Kernighan-Lin <ref> [68] </ref> algorithm for partitioning 3 . 3 This step can also be performed by using the notion of incompatibility between dichotomies. The prime dichotomy that covers the maximum number of dichotomies is desired. <p> If the number of literals (or cubes) is being minimized, then P is chosen such that the maximum number of restricted initial dichotomies are covered by d P . This corresponds to minimizing the number of uncovered initial dichotomies. Thus, for the partitioning algorithm <ref> [68] </ref>, the nodes are the symbols being partitioned and the nets are either face constraints or initial dichotomies. The procedure is performed recursively on each resulting partition. Each partition again yields candidate dichotomies restricted to the subset of symbols that appear in it.
Reference: [69] <author> K. Keutzer and D. Richards. </author> <title> Computational complexity of logic optimization. </title> <type> Unpublished manuscript, </type> <month> March </month> <year> 1994. </year>
Reference-contexts: We refer to [46, 104, 9] as standard references on computational complexity and the theory of N P -completness in particular. Computational complexity of logic optimization problems has been discussed in <ref> [69] </ref>, from which we will draw results. An instance of a problem is encoded as a string (or word) of a language. So the solution of a problem is equivalent to decide whether a given string (an instance of the problem) is in that language or not. <p> So, unless a theoretical breakthrough proves that the two classes coincide, it is useful to classify precisely a problem as belonging into one vs. the other, as it is recommended in <ref> [69] </ref>, reacting against sloppy statements in the literature on algorithms for computer-aided design. Beyond P and N P there is a whole world of complexity classes. We are going to introduce the rudiments of the polynomial hierarchy because they are needed to classify correctly some versions of state assignment. <p> Definition 3.1.2 Given a sum-of-products (SOP) representation of a Boolean function F and positive integers k and l, MIN-SOP-2 is the problem "is there a SOP representation of F with k or fewer product-terms and l or fewer literals ?". Theorem 3.1.5 <ref> [69] </ref> MIN-SOP-2 is in co N P -hard (lower bound). Proof: We show that VALIDITY for SOP forms reduces to MIN-SOP-2. We already stated the well-known result that VALIDITY is co N P -hard (precisely it is co N P -complete). <p> The next theorem shows that MIN-SOP-2 can be solved in polynomial time by a nondeterministic Turing machine with an oracle in N P . Theorem 3.1.6 <ref> [69] </ref> MIN-SOP-2 is in S p 2 (upper bound). Proof: Consider a nondeterministic Turing machine equipped with SAT as an oracle. Notice that we need a version of SAT for general Boolean expressions (it is still in N P ). <p> It would be worthy to see if a finer classification can be achieved looking into approximation complexity classes [46, 104, 9]. Similar results could be obtained for other optimization objectives, like minimum number of literals of multi-level implementations <ref> [69] </ref>. Also the introduction of don't care conditions in the original representations, allowing for choices in the encoded implementations, can be handled with minor variant of the previous techniques. 42 CHAPTER 3.
Reference: [70] <author> Z. Kohavi. </author> <title> Switching and Finite Automata Theory. </title> <publisher> McGraw-Hill Book Company, </publisher> <address> New York, New York, </address> <note> second edition, 1978. 328 BIBLIOGRAPHY </note>
Reference: [71] <author> D. Krumme, K. Venkataraman, and G. Cybenko. </author> <title> Hypercube embedding is NP-complete. </title> <booktitle> In Proceedings of SIAM Hypercube Conference, </booktitle> <month> September </month> <year> 1985. </year>
Reference-contexts: G can be embedded in an n-cube if G is a subgraph of the n-cube. The problem of deciding whether a given graph is embeddable into an arbitrary dimension hypercube has been shown to be NP-complete <ref> [71] </ref>. It has also been proved that even the problem of deciding whether a graph can be embedded into a fixed-size hypercube is NP-complete [31].
Reference: [72] <author> L. Lavagno. </author> <title> Heuristic and exact methods for binate covering. </title> <type> EE290ls Report, </type> <month> May </month> <year> 1989. </year>
Reference-contexts: The columns are the prime implicants, the rows are the minterms and there is a 1 entry in the matrix when a prime contains a minterm. Various techniques have been proposed to solve binate covering problems. A class of them <ref> [14, 72] </ref> are branch-and-bound techniques that build explicitly the table of the constraints expressed as product-of-sum expressions and explore in the worst-case all possible solutions, but avoid the generation of some of the suboptimal solutions by a clever use of reduction steps and bounding of search space for solutions.
Reference: [73] <author> L. Lavagno, S. Malik, R. Brayton, and A. Sangiovanni-Vincentelli. MIS-MV: </author> <title> Optimization of multi-level logic with multiple valued inputs. </title> <booktitle> In The Proceedings of the International Conference on Computer-Aided Design, </booktitle> <month> November </month> <year> 1990. </year>
Reference-contexts: Encode the symbolic input so that the total number of literals in the encoded network is minimal (simulated annealing is used for this purpose, while extensions of constrained embedding algorithms from the two level case are being studied). A set of theorems, proved in <ref> [73] </ref>, guarantees that step 2 of the above algorithm is complete, i.e. that all possible optimizations in all possible encodings can be performed in multiple-valued mode provided that the appropriate cost function is available.
Reference: [74] <author> L. Lavagno, C. W. Moon, R. K. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> Solving the state assignment problem for signal transition graphs. </title> <booktitle> The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 568-572, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: OTHER APPLICATIONS 137 where b 1 and b 2 are two new columns of the covering table. 6.8.3 Asynchronous State Assignment The state assignment algorithm proposed by Tracey [143] may also be applied in performing state assignment for asynchronous state machines <ref> [74] </ref>. The basic idea is that whenever a pair of state transitions occur under the same input (so that the input values cannot be used to distinguish among them), at least one state signal must remain constant during both transitions and have a different value for each transition. <p> Tracey was the first to propose the concept of dichotomy as corresponding informally to the idea of a column (bit) in the binary encoding of the internal states. It distinguishes one set of states from another by a single bit in the corresponding encodings. The implementation in <ref> [74] </ref> successfully uses our exact input encoding algorithm (cf. Section 6.5). 6.8.4 Logic Decomposition In [97] it is investigated the problem of decomposing a function so that the resulting sub-functions have a small number of cubes or literals. The decomposition problem is formulated as an encoding problem.
Reference: [75] <author> D. Lewin. </author> <title> Computer-Aided Design of Digital Systems. </title> <address> Russak-Arnold, </address> <year> 1977. </year>
Reference-contexts: in some sense it subsumes the other encoding problems, and "minimum area" because it has been the most studied objective, even though we will survey also contributions for other problems and objectives 1 . 4.1.1 Early Contributions A well-written survey of early literature on state assignment can be found in <ref> [75] </ref>. Here we will review the key contributions. Among the first to define input and output encoding problems for combinational networks were [33] and [100]. The former based his theory of input encoding on partitions and set systems.
Reference: [76] <author> B. Lin. </author> <title> Experiments with jedi. </title> <type> Private communication, </type> <month> October </month> <year> 1989. </year>
Reference-contexts: In the case of NOVA only the best minimum code-length two-level result was given to MISII . MUSTANG was run with -p, -n, -pt, -nt options and minimum code-length. JEDI was run with all available options and minimum code-length <ref> [76] </ref>. In all cases ESPRESSO was run before MISII. The final literal counts in a factored form of the logic encoded by NOVA average 30% less than the literal counts of the best of a number of random state assignments.
Reference: [77] <author> B. Lin. </author> <title> Synthesis of multiple level logic from symbolic high-level description languages. </title> <booktitle> Proceedings of the IFIP International Conference on VLSI, </booktitle> <pages> pages 187-196, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: There are two main classes of multi-level encoding algorithms: 1. Estimation-based algorithms, that define a distance measure between symbols, such that if "close" symbols are assigned "close" (in terms of Hamming distance) codes it is likely that multi-level synthesis will give good results. Programs such as MUSTANG [36], JEDI <ref> [77] </ref> and PESTO [57] belong to this class. 2. Synthesis-based algorithms, that use the result of a multi-level optimization on the unencoded or one-hot encoded symbolic cover to drive the encoding process. Programs such as MIS-MV [85] and MUSE [42] belong to this class. <p> Table 4.2 reports the number of literals after running through the standard boolean optimization script in the multi-level logic synthesis system MISII [12] with encodings obtained by NOVA, MUSTANG [36], JEDI <ref> [77] </ref> and random state assignments. In the case of NOVA only the best minimum code-length two-level result was given to MISII . MUSTANG was run with -p, -n, -pt, -nt options and minimum code-length. JEDI was run with all available options and minimum code-length [76]. <p> We report two kinds of experiments to verify the validity of MIS-MV as input encoder: * Compare the relative importance of the various multi-valued optimization steps. * Compare MIS-MV with some existing state assignment programs, such as JEDI <ref> [77] </ref>, MUSE [42], MUSTANG [36] and NOVA [147]. <p> The present contribution shows how to extract a minimal encodeable cover from a large set of GPI's, allowing inline of principle theexploration of all minimal encodeable covers. This advances the state-of-art of symbolic minimization, which up to now has been done with various heuristic tools <ref> [92, 147, 42, 77] </ref>, often very well-tuned for their domain of application, but lacking a rigorous connection beween an exact theory and the approximations made. <p> The present contribution shows how to extract a minimal encodeable cover from a large set of GPI's, allowing inline of principle theexploration of all minimal encodeable covers. This advances the state-of-art of symbolic minimization, which up to now has been done with various heuristic tools <ref> [92, 147, 42, 77] </ref>, often very well-tuned for their domain of application, but lacking a rigorous 314 CHAPTER 11. IMPLICIT MINIMIZATION OF GPI'S connection beween an exact theory and the approximations made.
Reference: [78] <author> B. Lin. </author> <title> Synthesis of VLSI designs with symbolic techniques. </title> <type> Tech. Report No. </type> <institution> UCB/ERL M91/105, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: In this way, a family of equivalent STGs, complete under state merging and state re-direction, is explored during state assignment. Such a combined state minimization and encoding procedure has been proposed in <ref> [78] </ref>, in the following form: 7 Anticipating a future discussion, we say that the selection of encodeable GPI's reduces to binate covering and encodeability when there are don't care transitions. <p> In [133], the problem of mapping the implied classes into compatibles in the reduced FSM (problem of unique mapped representation) has been modelled with don't cares transitions in the reduced FSM. The introduction of don't care transitions is a special case of symbolic relations, pioneered in <ref> [82, 78] </ref>. Symbolic relations tie together the notion of GPI (that accounts for symbolic in the name) with the notion of relation. <p> q Q q 0 , (8p 2 P (q 0 p) ) (q p)) Moreover, if there are rows that intersect exactly the same set of columns, i.e. they are equivalent, one should compute this equivalence relation and then replace each equivalence class with one representative (called sometimes projection operation <ref> [78] </ref>). Row dominance should then be applied to these representatives only. Instead of using such a projection and then applying the definition of dominance relation, one can define a row transposing function that maps the rows on objects whose manipulation can be done more efficiently.
Reference: [79] <author> B. Lin, O. Coudert, and J.C. Madre. </author> <title> Symbolic prime generation for multiple-valued functions. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 40-44, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Here, loosely, we consider a representation as explicit if it requires space lineraly proportional to the size of the represented set. In particular, researchers at Bull and UCB <ref> [25, 79, 53] </ref> investigated implicit computations of prime implicants of a two-valued or multi-valued function. In some examples all primes could be computed implicitly, even when explicit techniques implemented in ESPRESSO [11] failed to do so. <p> By means of techniques as in <ref> [79, 53, 30] </ref>, GPI's can be generated using BDD-based (alias implicit) representations. The next step is to select an encodeable cover of GPI's using implicit representations. This motivates the development of new algorithms to solve covering problems based on the representation and manipulation of covering tables represented with BDD's. <p> The previous insight has already been tested in a series of applications. Research at Bull [23] and UC Berkeley [142] produced powerful techniques for implicit enumeration of subsets of states of a Finite State Machine (FSM). Later work at Bull <ref> [25, 79] </ref> has shown how implicants, primes and essential primes of a two-valued or multi-valued function can also be computed implicitly. Reported experiments show a suite of examples where all primes could be computed, whereas explicit techniques implemented in ESPRESSO [11] failed to do so. <p> Transform the computation of the primes, unate table and the table reduction operations into operations on boolean functions defined on the boolean space of the problem. An whole suite of papers has been produced by the French group <ref> [25, 79, 27, 26, 24, 28, 29, 30, 22] </ref>. Here we will outline only the key steps of this approach. We remind that a literal is a propositional variable x k or its negation x k . <p> We have proposed in [65] a unified notational framework for set manipulation, extending the work by Lin et al. in <ref> [79] </ref>. Here we define some basic operators. Proposition 11.1.1 Set equality, mirroring, containment, and strict-containment between two positional-sets x and y can be computed by: (x = y) Q n k=1 (x k , y k ); compl (x; y) Q n Q n 11.1.
Reference: [80] <author> B. Lin and A.R. </author> <title> Newton. Implicit manipulation of equivalence classes using binary decision diagrams. </title> <booktitle> In The Proceedings of the International Conference on Computer Design, </booktitle> <pages> pages 81-85, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: From now on, sometimes we will blur the distinction between a column (row) label and the column (row) itself, but the context should say clearly which one it is meant. 3 Alternatively, one could have used the cproject BDD operator introduced in <ref> [80] </ref> to pick a representative column out of each set of duplicated columns. 260 CHAPTER 10. BINATE COVERING 10.8.3 Column Dominance Some columns need not be considered in a binate table, if they are dominated by others. Classically, there are two notions of column dominance: ff-dominance and fi-dominance.
Reference: [81] <author> B. Lin and R. </author> <title> Newton. A generalized approach to the constrained cubical embedding problem. </title> <booktitle> In The Proceedings of the International Conference on Computer Design, </booktitle> <year> 1989. </year>
Reference-contexts: An approximate solution to P-3 for input constraints based on a theory of intersecting cubes is described in [126, 43] and a solution based on simulated annealing is reported in <ref> [81] </ref>. An exact solution to P-2 for input constraints based on the notion of prime sections is described in [44, 45].
Reference: [82] <author> B. Lin and F. Somenzi. </author> <title> Minimization of symbolic relations. </title> <booktitle> In The Proceedings of the International Conference on Computer-Aided Design, </booktitle> <month> November </month> <year> 1990. </year>
Reference-contexts: Since both the number of columns (roughly, the number of GPI's) and of rows (even larger than the number of columns) become quickly very large, even approaches that solve binate covering by means of a shortest path computation of the clauses represented by BDD's as in <ref> [82, 62] </ref> have been unable to solve non-trivial instances. Indeed the methods in [82, 62] may succeed in handling huge numbers of clauses, but they are still limited by the numbers of columns, which are the support variables of the required BDD's. 8.3 GPI's and Non-Determinism 8.3.1 Symbolic Don't Cares and <p> of GPI's) and of rows (even larger than the number of columns) become quickly very large, even approaches that solve binate covering by means of a shortest path computation of the clauses represented by BDD's as in <ref> [82, 62] </ref> have been unable to solve non-trivial instances. Indeed the methods in [82, 62] may succeed in handling huge numbers of clauses, but they are still limited by the numbers of columns, which are the support variables of the required BDD's. 8.3 GPI's and Non-Determinism 8.3.1 Symbolic Don't Cares and Beyond In [39] mention is made of symbolic don't cares. <p> In [133], the problem of mapping the implied classes into compatibles in the reduced FSM (problem of unique mapped representation) has been modelled with don't cares transitions in the reduced FSM. The introduction of don't care transitions is a special case of symbolic relations, pioneered in <ref> [82, 78] </ref>. Symbolic relations tie together the notion of GPI (that accounts for symbolic in the name) with the notion of relation. <p> We will refer to these methods as explicit. A second approach <ref> [82] </ref> formulates the problem with Binary Decision Diagrams (BDD's) and reduces finding a minimum cost assignment to a shortest path computation. In that case the number of variables of the BDD is the number of columns of the binate table. Recently, a mixed technique has been proposed in [61].
Reference: [83] <author> C. Y. Liu. </author> <title> A system for for synthesis of area-efficient testable FSM's. </title> <type> Ph.D. Thesis, </type> <institution> University of Wisconsin, </institution> <year> 1994. </year> <note> BIBLIOGRAPHY 329 </note>
Reference-contexts: Half-hot encodings have exactly half the total number of state variables set to 1. The penalty on the number of necessary product terms was not addressed. The issue of encoding for testable implementations of small area using (k; p) codes was addressed recently in <ref> [83] </ref>. (k; p) codes have length p with exactly k bits set to 1 and they result in unate realizations of the encoded FSM.
Reference: [84] <author> S. Malik. </author> <title> Combinational logic optimization techniques in sequential logic synthesis. </title> <type> Tech. Report No. </type> <institution> UCB/ERL M90/115, </institution> <month> November </month> <year> 1990. </year>
Reference-contexts: This association can be done both if one takes the relational or functional view of a discrete function. This section is heavily indebted to the exposition in <ref> [84] </ref>. Let f : P 0 fi P 1 fi : : : fi P n1 7! P n be a discrete function with P j = f0; 1; : : : ; p j1 g. <p> First one derives a Boolean formula for each factored form expression. Then these Boolean formulas are combined to give ~(x). So all properties for Boolean formulas hold for factored form expressions and they need not be proven separately. We refer to <ref> [84] </ref> for a detailed derivation, that we simply demonstrate on an example.
Reference: [85] <author> S. Malik, L. Lavagno, R. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> Symbolic minimization of multilevel logic and the input encoding problem. </title> <journal> In IEEE Transactions on Computer-Aided Design, volume vol.11, </journal> <volume> (no.7), </volume> <pages> pages 825-43, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Programs such as MUSTANG [36], JEDI [77] and PESTO [57] belong to this class. 2. Synthesis-based algorithms, that use the result of a multi-level optimization on the unencoded or one-hot encoded symbolic cover to drive the encoding process. Programs such as MIS-MV <ref> [85] </ref> and MUSE [42] belong to this class. Mustang MUSTANG uses the state transition graph to assign a weight to each pair of symbols. This weight measures the desirability of giving the two symbols codes that are "as close as possible". <p> MIS-MV, unlike the previous programs, performs a full multi-level multiple-valued minimization of a network with a symbolic input. Its algorithms are an extension to the multiple-valued case of those used by MISII (the interested reader is referred to <ref> [85] </ref> for a detailed explanation of these algorithms). Its overall strategy is as follows: 1. Read the symbolic cover. The symbolic output is encoded one-hot, the symbolic input is left as a multiple-valued variable. 2. Perform multi-level optimization (simplification, common subexpression extraction, decom position) of the multiple-valued network. 4.1. <p> SYMBOLIC MINIMIZATION 109 Chapter 6 Encoding Constraints 6.1 Introduction The various techniques for exact and heuristic encoding based on multiple-valued or symbolic minimization of two-level and multi-level logic, reported in <ref> [92, 91, 115, 39, 85, 18] </ref>, produce various types of encoding constraints. By encoding constraints we mean requirements on the codes to be assigned to the symbols. A first type are face-embedding constraints generated by the multiple-valued input variables (input constraints). <p> We solve P-3 with different cost functions, such as the number of constraints satisfied and the number of cubes or literals required in the encoded 6.2. STATEMENT AND COMPLEXITY OF THE ENCODING PROBLEMS 111 implementation. These algorithms also handle encoding don't cares <ref> [91, 85] </ref> and can be easily extended to other types of constraints. We also prove the NP-completeness of problems P-2 and P-3. This result has not been shown previously, though it has been conjectured [91]. <p> There are three cost functions that are useful in such applications: * the number of constraints satisfied; * the number of product-terms in a sum-of-product representation of the encoded constraints; and, * the number of literals in a sum-of-product representation of the encoded constraints <ref> [85] </ref>. We illustrate the meaning and technique of computation of these cost functions with an example. Consider the following input constraints: (e; f; c), (e; d; g), (a; b; d), (a; g; f; d). To satisfy all the constraints, an encoding of 4 bits is required. <p> Encoding don't cares have been shown to be essential for determining good factors in deriving a multi-level implementation of a given multi-valued description <ref> [85] </ref>. A simple example shows that suboptimal solutions of P-2 are computed when input encoding don't cares are disregarded. <p> However, there are many more cubes in the FSM that do not generate input constraints, and are not reflected in the table. Table 3 compares our approach to simulated annealing for multi-level examples. Input constraints with don't cares are generated by the multiple valued multi-level synthesis program MIS-MV <ref> [85] </ref> with the number of factored form literals in the encoded implementation as cost function (in practice, the number of literals in a sum-of-product representation of the encoded constraints is used as an approximation to this cost function). <p> Minimum-length encoding is always used. MIS-MV is run using a script that invokes the constraints satisfaction routine six times; five times to perform a cost evaluation that drives the multi-valued multi-level optimization steps and one final time to produce the actual codes that replace the symbolic inputs <ref> [85] </ref>. Simulated annealing is called the first five times with 1 pairwise code swap per temperature point, while the last call performed 10 pairwise code swaps per temperature point. Simulated annealing does not complete on the larger examples with 10 pairwise swaps per step. <p> These examples are marked with a y in the table, and only 4 swaps were allowed per temperature step for these examples. When using our heuristic algorithm, the full-fledged encoder is called all six times. See <ref> [85] </ref> for a detailed explanation of the scripts. As can be seen from Table 3, our algorithm on average performs a little better than simulated annealing in terms of literal count. <p> 68 327 322 860 1013 yvmecont 32 378 364 2074 2883 SA: Simulated annealing (5 calls with 1 move per step and 1 call with 10 moves per step) ENC: Heuristic encoding in minimum code length (6 calls) Time SA : Time for SA; includes run time for minimization script <ref> [85] </ref> Time ENC : Time for ENC; includes run time for minimization script [85] y: SA does not complete in 10 hours with 10 moves per step; SA limited to 4 steps per move *: Does not complete in 10 hours Table 3 : Multi-level heuristic minimum code length input encoding <p> annealing (5 calls with 1 move per step and 1 call with 10 moves per step) ENC: Heuristic encoding in minimum code length (6 calls) Time SA : Time for SA; includes run time for minimization script <ref> [85] </ref> Time ENC : Time for ENC; includes run time for minimization script [85] y: SA does not complete in 10 hours with 10 moves per step; SA limited to 4 steps per move *: Does not complete in 10 hours Table 3 : Multi-level heuristic minimum code length input encoding 144 CHAPTER 6. ENCODING CONSTRAINTS known before.
Reference: [86] <author> M. Marcus. </author> <title> Derivation of maximal compatibles using Boolean algebra. </title> <journal> IBM Journal of Research and Development, </journal> <month> November </month> <year> 1964. </year>
Reference-contexts: As in <ref> [86] </ref>, an incompatibility between two dichotomies represented by the literals a and b, is written as (a + b). <p> When the product of the sum terms representing all the pairwise incompatibilities is written as an irredundant sum-of-products expression, a maximal compatible is generated as the union of those dichotomies whose literals are missing in any product term <ref> [86] </ref>. For example, assume that we wish to find the maximal compatibles for five dichotomies, a; b; c; d; e. Assume that the incompatibilities are (a + b)(a + c)(b + c)(c + d)(d + e).
Reference: [87] <author> E. McCluskey. </author> <title> Minimization of Boolean functions. </title> <journal> Bell Laboratories Technical Journal, </journal> <month> November </month> <year> 1956. </year>
Reference-contexts: Exact Encoding with Generalized Prime Implicants An exact procedure for output encoding has been reported in [39]. A notion of generalized prime implicants (GPI's), as an extension of prime implicants defined in <ref> [87] </ref>, is introduced, and appropriate rules of cancellation are given. Each GPI carries a tag with some output symbols. If a GPI is accepted in a cover, it asserts as output the intersection (bit-wise and) of the codes of the symbols in the tag. <p> A special case of binate covering problem is a unate covering problem, where no literal in the negative phase is present. Exact two-level minimization <ref> [87, 113] </ref> can be cast as a unate covering problem. The columns are the prime implicants, the rows are the minterms and there is a 1 entry in the matrix when a prime contains a minterm. Various techniques have been proposed to solve binate covering problems. <p> Even though more complex criteria of dominance have been investigated (for instance, Section 10.5.12), the previous ones are basic in any table covering solver. Reduction rules have previously been stated for the binate covering case [50, 51, 14, 13], and also for the unate covering case <ref> [87, 113, 13] </ref>. Here we will present the known reduction rules directly for binate covering and indicate how they simplify for unate covering, when applicable. For each of them, we will first define the reduction rule, and then a theorem showing how that rule is applied.
Reference: [88] <author> E.J. McCluskey and S.H. Unger. </author> <title> A note on the number of internal variable assignments for sequential switching circuits. </title> <journal> IRE Transactions on Electronic Computers, </journal> <pages> pages 439-440, </pages> <month> December </month> <year> 1959. </year>
Reference-contexts: Instead, with other types of flip-flops, state encodings that differ only by complementation of some columns can be considered equivalent. The number of equivalence classes of state assignments, where equivalence is by permutation and complementation of columns, and 2 n1 &lt; v 2 n , was computed in <ref> [88] </ref> as: A (v) = (2 n v)!n! The number of equivalence classes of state assignments, where equivalence is only by permutation of columns, and 2 n1 &lt; v 2 n , was computed in [149] as: B (v) = (2 n v)!n! The fact that A (v) is correct for
Reference: [89] <author> P. McGeer, J. Sanghavi, R. Brayton, and A. Sangiovanni-Vincenetelli. Espresso-signature: </author> <title> a new exact minimizer for logic functions. </title> <journal> IEEE Transactions on VLSI Systems, </journal> <pages> pages 432-440, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: The basic idea is that each row of a covering table corresponds to a cube, called signature cube, that is the intersection of the primes covering the minterm associated to the row. This was noticed first in [99]. A rigorous theory and an efficient algorithm were developed at UCB <ref> [89] </ref>. The steps of the algorithm follow. Compute the signature cube of the each cube of an arbitrary initial cover and make irredundant the resulting cover.
Reference: [90] <author> C. Mead and L. Conway. </author> <title> Introduction to VLSI Systems, </title> <booktitle> chapter 3, </booktitle> <pages> pages 85-86. </pages> <publisher> Addison Wesley, </publisher> <year> 1980. </year>
Reference: [91] <author> G. De Micheli. </author> <title> Symbolic design of combinational and sequential logic circuits implemented by two-level logic macros. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <month> October </month> <year> 1986. </year>
Reference-contexts: It is worth mentioning that the face constraints obtained through straightforward symbolic minimization are sufficient, but not necessary to find a two-valued implementation matching the upper bound of the multi-valued minimized cover. As it was already pointed out in <ref> [91] </ref>, for each implicant of a minimal (or minimum) multi-valued cover, one can compute an expanded implicant, whose literals have maximal (maximum) cardinality and a reduced implicant whose literals have minimal (minimum) cardinality. <p> Sharing of logic is crucial to obtain minimum encoded two-level implementations. Therefore extensions of multiple-valued minimization have been proposed in <ref> [91, 147] </ref>. These extensions replace a single multiple-valued minimization of the whole symbolic cover by a sequence of minimization operations on parts of the symbolic cover in such a way as to recognize sharing of logic among next states, if some constraints on their codes are satisfied. <p> These extensions of multiple-valued minimization have been called symbolic minimization. In <ref> [91, 147] </ref> symbolic minimization was introduced to exploit bit-wise dominance relations between the binary codes assigned to different values of a symbolic output variable. The fact is that the input cubes of a dominating code can be used as don't cares for covering the input cubes of a dominated code. <p> The third step is assigning to the symbols codes of minimum length that satisfy these constraints, if the latter imply a set of non-contradictory bit-wise logic relations. When the target implementation is two-level logic, the first step may consist of one or more calls <ref> [92, 91] </ref> to a multiple-valued minimizer [114], after representing the symbolic variables with positional cube notation [139, 114]. Then constraints are extracted and a constraints satisfaction problem is set up. <p> Then constraints are extracted and a constraints satisfaction problem is set up. Using the paradigm of symbolic minimization followed by constraints satisfaction, the most common types of constraints that may be generated <ref> [92, 91, 39, 116] </ref> are four. The first type, generated by the input variables, are face-embedding constraints. The three types generated by the output variables are dominance, disjunctive and disjunctive-conjunctive constraints. <p> This problem is called face embedding problem. It is worth mentioning that the face constraints obtained through straightforward symbolic minimization are sufficient, but not necessary to find a two-valued implementation matching the upper bound of the multi-valued minimized cover. As it was already pointed out in <ref> [91] </ref>, for each implicant of a minimal (or minimum) multi-valued cover, one can compute an expanded implicant, whose literals have maximal (maximum) cardinality and a reduced implicant whose literals have minimal (minimum) cardinality. <p> We will see now more powerful schemes to deal with both input and output encoding. In <ref> [91, 147] </ref> a new scheme was proposed, called symbolic minimization. Symbolic minimization was introduced to exploit bit-wise dominance relations between the binary codes assigned to different values of a symbolic output variable. <p> We did not use disjunctive-conjunctive constraints in the heuristic procedure presented here. 5.3 A New Symbolic Minimization Algorithm 5.3.1 Structure of the Algorithm In this section a new more powerful paradigm of symbolic minimization is presented. An intuitive explanation of symbolic minimization as proposed in <ref> [91] </ref> and enhanced in [147] has been given in Section 5.2. To help in highlighting the differences of the two schemes, the one in [147] is summarized in Figure 5.3. The new scheme of symbolic minimization features the following novelties. * Symbolic oring. <p> CONCLUSIONS 107 5.10 Conclusions We have presented a symbolic minimization procedure that advances theory and practice with respect to the seminal contribution in <ref> [91] </ref>. The algorithm described here is capable of exploring minimal symbolic covers by using face, dominance and disjunctive constraints to guarantee that they can be mapped into encoded covers. The treatment of disjunctive constraints is a novelty of this work. <p> SYMBOLIC MINIMIZATION 109 Chapter 6 Encoding Constraints 6.1 Introduction The various techniques for exact and heuristic encoding based on multiple-valued or symbolic minimization of two-level and multi-level logic, reported in <ref> [92, 91, 115, 39, 85, 18] </ref>, produce various types of encoding constraints. By encoding constraints we mean requirements on the codes to be assigned to the symbols. A first type are face-embedding constraints generated by the multiple-valued input variables (input constraints). <p> The answer to Problem P-1 is always affirmative for input constraints only. A solution to P-1 and a heuristic algorithm to solve P-3 when both input and output dominance constraints occur are provided in <ref> [91] </ref>, extending an algorithm for input constraints described in [92]. A solution to P-1, when both input and output constraints (including disjunctive constraints) are present, is described in [39], and corrected in [38]. <p> We solve P-3 with different cost functions, such as the number of constraints satisfied and the number of cubes or literals required in the encoded 6.2. STATEMENT AND COMPLEXITY OF THE ENCODING PROBLEMS 111 implementation. These algorithms also handle encoding don't cares <ref> [91, 85] </ref> and can be easily extended to other types of constraints. We also prove the NP-completeness of problems P-2 and P-3. This result has not been shown previously, though it has been conjectured [91]. <p> These algorithms also handle encoding don't cares [91, 85] and can be easily extended to other types of constraints. We also prove the NP-completeness of problems P-2 and P-3. This result has not been shown previously, though it has been conjectured <ref> [91] </ref>. The approach used here is based on a formulation provided in [154], which in turn is related to the state assignment technique employed by Tracey in 1966 [143]. We first demonstrate the difficulty of finding codes that satisfy encoding constraints by proving it NP-complete in Section 6.2. <p> other encoding constraint satisfaction problems [97, 7]. 6.8 Other Applications In this section we illustrate that the formulation presented in Section 6.6 provides a uniform framework for the satisfaction of various other encoding problems. 6.8.1 Input Encoding Don't Cares The notion of an encoding don't care was first described in <ref> [91] </ref>, and an example of how encoding don't cares are generated in the two-level case is given in [145]. A face constraint containing symbols a, b and e and with symbols c and d as encoding don't cares is denoted (a; b; [c; d]; e). <p> These constraints are generated using an extension of the procedure described in <ref> [91] </ref> that also generates good disjunctive constraints. The procedure has been described in Chapter 5. The procedure for generating encoding constraints ensures that the constraints are satisfiable by calling the algorithm in Figure 9.3. The number of valid prime encoding-dichotomies is shown in the third column.
Reference: [92] <author> G. De Micheli, R. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> Optimal state assignment for finite state machines. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <month> July </month> <year> 1985. </year>
Reference-contexts: the internal variables and an encoding algorithm tries to satisfy most of these constraints. 4.1.2 Encoding for Two-level Implementation Reduction of Input Encoding to Multiple-Valued Minimization A major step towards an exact solution of encoding problems was the reduction of input encoding to multiple-valued minimization followed by input constraints satisfaction <ref> [92] </ref>. Efficient algorithms have been devised both for multiple-valued minimization [114] and input constraints satisfaction [92, 145, 116]. Even though state encoding is an input-output encoding problem 2 , it can be approximated as an input encoding problem [92] and solved by a two-step process. <p> Efficient algorithms have been devised both for multiple-valued minimization [114] and input constraints satisfaction <ref> [92, 145, 116] </ref>. Even though state encoding is an input-output encoding problem 2 , it can be approximated as an input encoding problem [92] and solved by a two-step process. <p> reduction of input encoding to multiple-valued minimization followed by input constraints satisfaction <ref> [92] </ref>. Efficient algorithms have been devised both for multiple-valued minimization [114] and input constraints satisfaction [92, 145, 116]. Even though state encoding is an input-output encoding problem 2 , it can be approximated as an input encoding problem [92] and solved by a two-step process. In the first step, a tabular representation of the FSM is optimized at the symbolic level, e.g., using the program ESPRESSO by Rudell. Multiple-valued minimization generates constraints on the codes that can be assigned to the states. <p> For the experiments we used the MCNC '89 set of benchmark FSM's. The Two-level Case We report one set of experiments that compare programs for two-level state assignments. Table 4.1 summarizes the results obtained running the algorithms of NOVA [147], KISS <ref> [92] </ref> and random state assignments. <p> Here we concentrate on problems in class D for optimal two-level implementations. In particular we will refer mostly to the problem of encoding FSM's, since there is no loss of generality and they are of great practical interest. We will build on the paradigm started by <ref> [92] </ref>. It involves optimizing the symbolic representation (symbolic minimization), and then transforming the optimized symbolic description into a compatible two-valued representation, by satisfying encoding constraints (bit-wise logic relations) imposed on the binary codes that replace the symbols. <p> The third step is assigning to the symbols codes of minimum length that satisfy these constraints, if the latter imply a set of non-contradictory bit-wise logic relations. When the target implementation is two-level logic, the first step may consist of one or more calls <ref> [92, 91] </ref> to a multiple-valued minimizer [114], after representing the symbolic variables with positional cube notation [139, 114]. Then constraints are extracted and a constraints satisfaction problem is set up. <p> Then constraints are extracted and a constraints satisfaction problem is set up. Using the paradigm of symbolic minimization followed by constraints satisfaction, the most common types of constraints that may be generated <ref> [92, 91, 39, 116] </ref> are four. The first type, generated by the input variables, are face-embedding constraints. The three types generated by the output variables are dominance, disjunctive and disjunctive-conjunctive constraints. <p> An example is demonstrated in Section 5.8, and experiments are reported in Section 5.9, with final conclusions drawn in Section 5.10. 5.2 Encoding for Two-level Implementations 5.2.1 Multi-valued Minimization Advances in the state assignment problem, reported in <ref> [93, 11, 92] </ref>, made a key connection to multiple-valued logic minimization, by representing the states of a FSM as the set of possible values of a single multiple-valued variable. A multiple-valued minimizer, such as [114], can be invoked on the symbolic representation of the FSM. <p> SYMBOLIC MINIMIZATION 109 Chapter 6 Encoding Constraints 6.1 Introduction The various techniques for exact and heuristic encoding based on multiple-valued or symbolic minimization of two-level and multi-level logic, reported in <ref> [92, 91, 115, 39, 85, 18] </ref>, produce various types of encoding constraints. By encoding constraints we mean requirements on the codes to be assigned to the symbols. A first type are face-embedding constraints generated by the multiple-valued input variables (input constraints). <p> The answer to Problem P-1 is always affirmative for input constraints only. A solution to P-1 and a heuristic algorithm to solve P-3 when both input and output dominance constraints occur are provided in [91], extending an algorithm for input constraints described in <ref> [92] </ref>. A solution to P-1, when both input and output constraints (including disjunctive constraints) are present, is described in [39], and corrected in [38]. A solution to problem P-2 based on compatible graph coloring is provided for input constraints in [154] and extended to output constraints in [20]. <p> The present contribution shows how to extract a minimal encodeable cover from a large set of GPI's, allowing inline of principle theexploration of all minimal encodeable covers. This advances the state-of-art of symbolic minimization, which up to now has been done with various heuristic tools <ref> [92, 147, 42, 77] </ref>, often very well-tuned for their domain of application, but lacking a rigorous connection beween an exact theory and the approximations made. <p> If one generates only GPI's whose tag has a cardinality less than a given bound, one has an approximate algorithm for the state assignment problem. By setting the bound to 1, a disjoint minimization problem is defined, equivalent to approximating state assignment as an input encoding problem as in <ref> [92] </ref>. <p> The present contribution shows how to extract a minimal encodeable cover from a large set of GPI's, allowing inline of principle theexploration of all minimal encodeable covers. This advances the state-of-art of symbolic minimization, which up to now has been done with various heuristic tools <ref> [92, 147, 42, 77] </ref>, often very well-tuned for their domain of application, but lacking a rigorous 314 CHAPTER 11. IMPLICIT MINIMIZATION OF GPI'S connection beween an exact theory and the approximations made. <p> This advances the state-of-art of symbolic minimization, otherwise restricted to the use of heuristic tools. that do not guarantee a complete exploration of the solution space. It is true, though, that competing algorithms <ref> [92, 147, 146] </ref> are often well-tuned for their domain of application, while our prototype of GPI minimization is not yet mature for field applications. In Chapter 10 we have presented an implicit procedure to solve binate covering problems.
Reference: [93] <author> G. De Micheli, T. Villa, and A. Sangiovanni-Vincentelli. </author> <title> Computer-aided synthesis of PLA-based finite state machines. </title> <booktitle> In The Proceedings of the International Conference on Computer-Aided Design, </booktitle> <month> September </month> <year> 1983. </year>
Reference-contexts: An example is demonstrated in Section 5.8, and experiments are reported in Section 5.9, with final conclusions drawn in Section 5.10. 5.2 Encoding for Two-level Implementations 5.2.1 Multi-valued Minimization Advances in the state assignment problem, reported in <ref> [93, 11, 92] </ref>, made a key connection to multiple-valued logic minimization, by representing the states of a FSM as the set of possible values of a single multiple-valued variable. A multiple-valued minimizer, such as [114], can be invoked on the symbolic representation of the FSM.
Reference: [94] <author> R. E. Miller. </author> <title> Switching theory. Volume I: combinational circuits. </title> <editor> J. </editor> <publisher> Wiley and & Co., </publisher> <address> N.Y., </address> <year> 1965. </year>
Reference-contexts: GENERALIZED PRIME IMPLICANTS 153 7.3.2 Generalized Prime Implicants by Consensus Operation In old textbooks <ref> [94] </ref> it was common to represent a multiple-output function by a cover of the function consisting of a set of cubes in the common input space, with an output tag attached to each cube to specify the functions to whose onset the cube belongs. We call it functional view. <p> Prime implicants are maximal implicants of a Boolean function. Implicants of multiple-output functions (multiple-output implicants) can cover 0-cubes in more than one output function. A multi-output prime implicant is a maximal implicant for a set of output functions. Prime implicants can be computed by the consensus method <ref> [107, 94] </ref>. Maximality of a multiple-output prime means that its input part cannot be expanded without intersecting the offset of at least one function in the output tag, nor any new function can be added to the output tag without the input part intersecting the offset of this added function. <p> In the sequel, unless otherwise stated, we will call MV primes those left after the post-processing step applied to the set of primes of the MV function. In [39] the rules for consensus and cancellation originally defined for binary cubes (e.g., in <ref> [94] </ref>) were extended to symbolic cubes. We call them GPI consensus and GPI cancellation. GPI's are defined as the fixed point of the computation that takes an initial symbolic cover and iteratively applies to it GPI consensus and cancellation.
Reference: [95] <author> S. Minato. </author> <title> Zero-suppressed BDD's for set manipulation in combinatorial problems. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 272-277, </pages> <month> June </month> <year> 1993. </year> <note> 330 BIBLIOGRAPHY </note>
Reference-contexts: Implicit formulations of such operations were instead reported first in [66]. In [30] it is stated that the usage of Zero-Suppressed BDD's by Minato <ref> [95] </ref> instead of ROBDD's [16] resulted in more efficient implicit representations of the computations of the problem. 278 CHAPTER 10. BINATE COVERING 279 Chapter 11 Implicit Minimization of GPI's 11.1 Implicit Representations and Manipulations Algorithms for sequential synthesis have been developed primarily for State Transition Graphs (STG's).
Reference: [96] <author> E. Moore. </author> <title> Gedanken-experiments on sequential machines. </title> <editor> In C. Shannon and J. McCarthy, editors, </editor> <title> Automata Studies. </title> <publisher> Princeton University Press, </publisher> <year> 1956. </year>
Reference: [97] <author> R. Murgai, R. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> Using encoding in functional decomposition. </title> <note> Submitted for publication, </note> <year> 1993. </year>
Reference-contexts: In the general case the number of evaluations can be restricted to some fixed number to reduce the search space. This heuristic algorithm has shown promising results and has been successfully applied to other encoding constraint satisfaction problems <ref> [97, 7] </ref>. 6.8 Other Applications In this section we illustrate that the formulation presented in Section 6.6 provides a uniform framework for the satisfaction of various other encoding problems. 6.8.1 Input Encoding Don't Cares The notion of an encoding don't care was first described in [91], and an example of how <p> It distinguishes one set of states from another by a single bit in the corresponding encodings. The implementation in [74] successfully uses our exact input encoding algorithm (cf. Section 6.5). 6.8.4 Logic Decomposition In <ref> [97] </ref> it is investigated the problem of decomposing a function so that the resulting sub-functions have a small number of cubes or literals. The decomposition problem is formulated as an encoding problem. In general, an input-output encoding formulation has to be employed to solve the problem.
Reference: [98] <author> R. Narasimhan. </author> <title> Minimizing incompletely specified sequential switching functions. </title> <journal> IRE Transactions on Electronic Computers, </journal> <volume> EC-10:531-532, </volume> <month> September </month> <year> 1961. </year>
Reference-contexts: To every STG containing unspecified next-states one can construct an equivalent STG where all unspecified next states are replaced by a trap state T , as in <ref> [98] </ref>. The transitions from T under any input go to T itself and their outputs are unspecified. The new STG describes exactly the same behaviours as the old one. 1 Suppose that 3 symbolic states are encoded with 2 bits, then there are 4 hardware states. 148 CHAPTER 7.
Reference: [99] <author> L. Nguyen, M. Perkowski, and N. Goldstein. </author> <title> Palmini fast boolean minimizer for personal computers. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <pages> pages 615-621, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: The maximal elements of the transposed objects are the dominating rows. The basic idea is that each row of a covering table corresponds to a cube, called signature cube, that is the intersection of the primes covering the minterm associated to the row. This was noticed first in <ref> [99] </ref>. A rigorous theory and an efficient algorithm were developed at UCB [89]. The steps of the algorithm follow. Compute the signature cube of the each cube of an arbitrary initial cover and make irredundant the resulting cover.
Reference: [100] <author> A. Nichols and A. Bernstein. </author> <title> State assignments in combinational networks. </title> <journal> IEEE Transactions on Electronic Computers, </journal> <month> June </month> <year> 1965. </year>
Reference-contexts: Here we will review the key contributions. Among the first to define input and output encoding problems for combinational networks were [33] and <ref> [100] </ref>. The former based his theory of input encoding on partitions and set systems. The latter tried to minimize the variable dependency of the output functions and studied the problem of the minimum number of variables required for a good encoding.
Reference: [101] <author> P.S. Noe. </author> <title> Remarks on the SHR-optimal state assignment procedure. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 873-875, </pages> <month> September </month> <year> 1973. </year>
Reference-contexts: PREVIOUS AND RELATED WORK taken into consideration in the optimization procedure. This work was refined and commented by other contributions <ref> [101, 102, 103] </ref>. Others, as [54, 137, 67], proposed algebraic methods based on the algebra of partitions and on the criterion of reduced dependency.
Reference: [102] <author> P.S. Noe and V.T. Rhyne. </author> <title> A modification to the SHR-optimal state assignment procedure. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 327-329, </pages> <month> March </month> <year> 1974. </year>
Reference-contexts: PREVIOUS AND RELATED WORK taken into consideration in the optimization procedure. This work was refined and commented by other contributions <ref> [101, 102, 103] </ref>. Others, as [54, 137, 67], proposed algebraic methods based on the algebra of partitions and on the criterion of reduced dependency.
Reference: [103] <author> P.S. Noe and V.T. Rhyne. </author> <title> Optimum state assignment for the D flip-flop. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 306-311, </pages> <month> March </month> <year> 1976. </year>
Reference-contexts: PREVIOUS AND RELATED WORK taken into consideration in the optimization procedure. This work was refined and commented by other contributions <ref> [101, 102, 103] </ref>. Others, as [54, 137, 67], proposed algebraic methods based on the algebra of partitions and on the criterion of reduced dependency.
Reference: [104] <author> C. Papadimitriou. </author> <title> Computational complexity. </title> <publisher> Addison Wesley, </publisher> <year> 1994. </year>
Reference-contexts: DEFINITIONS 33 Chapter 3 Complexity Issues 3.1 Computational Complexity In this section we will present some results on the computational complexity of state assignment for minimum area. We refer to <ref> [46, 104, 9] </ref> as standard references on computational complexity and the theory of N P -completness in particular. Computational complexity of logic optimization problems has been discussed in [69], from which we will draw results. An instance of a problem is encoded as a string (or word) of a language. <p> This is in part due to the lack of fine tuning of the complexity classes of the polynomial hierarchy. It would be worthy to see if a finer classification can be achieved looking into approximation complexity classes <ref> [46, 104, 9] </ref>. Similar results could be obtained for other optimization objectives, like minimum number of literals of multi-level implementations [69].
Reference: [105] <author> C. H. Papadimitriou, J.D. Ullman, and K. Steiglitz. </author> <title> Combinatorial Optimization: Algorithms and Complexity. </title> <publisher> Prentice Hall, </publisher> <year> 1982. </year>
Reference: [106] <author> R. Parchman. </author> <title> The number of state assignments for sequential machines. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 613-614, </pages> <month> June </month> <year> 1972. </year>
Reference-contexts: The formulas for the general case, i.e., where v is not restricted to 2 n1 &lt; v 2 n , were published by Harrison and Parchman ( <ref> [109, 106] </ref>). They introduced the definition of degenerate state assignments, i.e., those where a column is constant or two or more columns are equal. Let the following definitions hold: 3.2. COUNTING STATE ASSIGNMENTS 43 1.
Reference: [107] <author> W. Quine. </author> <title> A way to simplify truth functions. </title> <journal> Amer. Math. Monthly, </journal> <volume> 62 </volume> <pages> 627-631, </pages> <month> November </month> <year> 1955. </year>
Reference-contexts: Prime implicants are maximal implicants of a Boolean function. Implicants of multiple-output functions (multiple-output implicants) can cover 0-cubes in more than one output function. A multi-output prime implicant is a maximal implicant for a set of output functions. Prime implicants can be computed by the consensus method <ref> [107, 94] </ref>. Maximality of a multiple-output prime means that its input part cannot be expanded without intersecting the offset of at least one function in the output tag, nor any new function can be added to the output tag without the input part intersecting the offset of this added function.
Reference: [108] <editor> J.-K. Rho and F. Somenzi. Stamina. </editor> <booktitle> Computer Program, </booktitle> <year> 1991. </year>
Reference-contexts: This technique has been described in [51, 50, 13, 14], and implemented in successful computer programs <ref> [112, 108, 130] </ref>. The branch-and-bound solution of minimum binate covering is based on a recursive procedure. A run of the algorithm can be described by its computation tree. <p> Bi-partitioning is implemented in <ref> [108, 130] </ref> as follows. When checking for a partition of the problem (line 7), the routine sm mincov is called recursively on two independents subproblems (lines 8 and 10), if they exist. <p> Since finding a maximum independent set is an NP-complete problem, in practice an heuristic is used that provides a weaker lower bound. Notice that even the lower bound provided by solving exactly maximum independent set is not sharp. In <ref> [112, 108, 130] </ref>, the adjacency matrix B of a graph whose nodes correspond to rows in the cover matrix M is created. In the binate case, only rows are taken into consideration which do not contain any 0 element. <p> Since the time taken by the selection is a significant part of the total, a trade-off must be made between quality and efficiency. In <ref> [112, 108, 130] </ref>, the selection of the branching variable is restricted to columns intersecting the rows of the independent set, because a unique column must eventually be selected from each row of the maximal independent set. <p> The effect of reductions depends on the order of their application. Reductions are usually attempted in a given order, until nothing changes any more (i.e., the covering matrix has been reduced to a cyclic core). Figure 10.5 shows how reductions are applied in <ref> [112, 108, 130] </ref> 1 . 10.5.1 Row Dominance Definition 10.5.1 A row R i dominates another row R j if R j has all the 1's and 0's of R i ; i.e., for each column C k of M , one of the following occurs: * M i;k = 1 <p> row R j if R j has all the 1's and 0's of R i ; i.e., for each column C k of M , one of the following occurs: * M i;k = 1 and M j;k = 1, 1 The reductions fi-dominance and row consensus are only in <ref> [108] </ref> and the reduction by implication is only in [130]. 244 CHAPTER 10. <p> In that case the last application of row consensus is potentially faulty and should not be done. Row consensus is applied in <ref> [108] </ref>. <p> Gimpel's rule has been first proposed in [48] and then implemented in [112]. In <ref> [108, 130] </ref> Gimpel's rule has been extended to handle the binate case. This extension has been described in [131]. 10.6.
Reference: [109] <author> V.T. Rhyne and P.S. Noe. </author> <title> On equivalence of state assignments. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 55-57, </pages> <month> January </month> <year> 1968. </year> <note> BIBLIOGRAPHY 331 </note>
Reference-contexts: The formulas for the general case, i.e., where v is not restricted to 2 n1 &lt; v 2 n , were published by Harrison and Parchman ( <ref> [109, 106] </ref>). They introduced the definition of degenerate state assignments, i.e., those where a column is constant or two or more columns are equal. Let the following definitions hold: 3.2. COUNTING STATE ASSIGNMENTS 43 1.
Reference: [110] <author> V.T. Rhyne and P.S. Noe. </author> <title> On the number of distinct state assignments for a sequential machine. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 73-75, </pages> <month> January </month> <year> 1977. </year>
Reference-contexts: classes of state assignments, where equivalence is only by permutation of columns, and 2 n1 &lt; v 2 n , was computed in [149] as: B (v) = (2 n v)!n! The fact that A (v) is correct for SR, J K and T flip-flops was pointed out first in <ref> [110] </ref>. This does not extend to D flip-flops, for which B (v) is the correct formula, because in a D flip-flop the excitation expression for the complemented state variable is the complement of the expression for the uncomplemented state variable.
Reference: [111] <author> D. Rosenkrantz. </author> <title> Half-hot state assignments for finite state machines. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <month> May </month> <year> 1990. </year>
Reference-contexts: In <ref> [111] </ref> a case was made for a variation of unate encoding called half-hot encoding that may allow sometimes savings in the number of columns of the encoded PLA. Half-hot encodings have exactly half the total number of state variables set to 1.
Reference: [112] <author> R. Rudell. </author> <title> Espresso. </title> <booktitle> Computer Program, </booktitle> <year> 1987. </year>
Reference-contexts: This technique has been described in [51, 50, 13, 14], and implemented in successful computer programs <ref> [112, 108, 130] </ref>. The branch-and-bound solution of minimum binate covering is based on a recursive procedure. A run of the algorithm can be described by its computation tree. <p> Since finding a maximum independent set is an NP-complete problem, in practice an heuristic is used that provides a weaker lower bound. Notice that even the lower bound provided by solving exactly maximum independent set is not sharp. In <ref> [112, 108, 130] </ref>, the adjacency matrix B of a graph whose nodes correspond to rows in the cover matrix M is created. In the binate case, only rows are taken into consideration which do not contain any 0 element. <p> Since the time taken by the selection is a significant part of the total, a trade-off must be made between quality and efficiency. In <ref> [112, 108, 130] </ref>, the selection of the branching variable is restricted to columns intersecting the rows of the independent set, because a unique column must eventually be selected from each row of the maximal independent set. <p> The effect of reductions depends on the order of their application. Reductions are usually attempted in a given order, until nothing changes any more (i.e., the covering matrix has been reduced to a cyclic core). Figure 10.5 shows how reductions are applied in <ref> [112, 108, 130] </ref> 1 . 10.5.1 Row Dominance Definition 10.5.1 A row R i dominates another row R j if R j has all the 1's and 0's of R i ; i.e., for each column C k of M , one of the following occurs: * M i;k = 1 <p> Gimpel's rule has been first proposed in [48] and then implemented in <ref> [112] </ref>. In [108, 130] Gimpel's rule has been extended to handle the binate case. This extension has been described in [131]. 10.6.
Reference: [113] <author> R. Rudell. </author> <title> Logic synthesis for VLSI design. </title> <type> Tech. Report No. </type> <institution> UCB/ERL M89/49, </institution> <month> April </month> <year> 1989. </year>
Reference-contexts: Hence, s 0 does not cover s 1 in this bit. The dichotomy (s 0 s 1 ; s 2 ) does not violate this constraint. 6.4 Abstraction of the Problem Satisfaction of encoding constraints may be abstracted as a binate covering problem (BCP) <ref> [113] </ref>. Suppose that a set S = fs 1 ; : : : ; s n g is given. The cost of s i is c i where c i 0. <p> The final step of encoding is to obtain a cover of the initial dichotomies using a minimum number of primes. This is a classical unate covering problem and efficient branch and bound techniques, both for exact and heuristic solutions, are well known <ref> [113] </ref>. 6.5.1 Efficient Generation of Prime Dichotomies By definition, each prime dichotomy is a maximal compatible of the dichotomies since it is not compatible with any dichotomy that it does not cover. <p> A special case of binate covering problem is a unate covering problem, where no literal in the negative phase is present. Exact two-level minimization <ref> [87, 113] </ref> can be cast as a unate covering problem. The columns are the prime implicants, the rows are the minterms and there is a 1 entry in the matrix when a prime contains a minterm. Various techniques have been proposed to solve binate covering problems. <p> Even though more complex criteria of dominance have been investigated (for instance, Section 10.5.12), the previous ones are basic in any table covering solver. Reduction rules have previously been stated for the binate covering case [50, 51, 14, 13], and also for the unate covering case <ref> [87, 113, 13] </ref>. Here we will present the known reduction rules directly for binate covering and indicate how they simplify for unate covering, when applicable. For each of them, we will first define the reduction rule, and then a theorem showing how that rule is applied. <p> The resulting cover is a minimum cover for p. A proof can be found in <ref> [113] </ref>, where a more extended discussion is presented. Gimpel's reduction step was originally stated for covering problems where each column had cost 1. <p> Historically the third (less general) way was implemented first to solve exact state minimization of ISFSM's [65]. It is applicable to other problems whose covering table can be represented in the same way, e.g., the exact formulation of technology mapping for area minimization <ref> [113] </ref>. The difference between the first and second formulation is only in some computation simplification in the latter one, for tables that have at most one 0 per row.
Reference: [114] <author> R. Rudell and A. Sangiovanni-Vincentelli. </author> <title> Multiple-valued minimization for PLA optimization. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> CAD-6:727-750, </volume> <month> September </month> <year> 1987. </year>
Reference-contexts: For a more complete treatment the reader is referred to <ref> [114] </ref>. Definition 2.7.1 Let p i ; i = 1; : : :; n be positive integers. Define P i = f0; : : : ; p i 1g for i = 1; : : : ; n, and B = f0; 1; flg. <p> Efficient algorithms have been devised both for multiple-valued minimization <ref> [114] </ref> and input constraints satisfaction [92, 145, 116]. Even though state encoding is an input-output encoding problem 2 , it can be approximated as an input encoding problem [92] and solved by a two-step process. <p> Multiple-valued minimization of this FSM where the states are the possible values of a multiple-valued variable yields the cover shown in Figure 4.1 (b). This can be done by representing the symbolic variables using the positional cube notation <ref> [139, 114] </ref>, and then invoking a multiple-valued minimizer, such as [114]. <p> Multiple-valued minimization of this FSM where the states are the possible values of a multiple-valued variable yields the cover shown in Figure 4.1 (b). This can be done by representing the symbolic variables using the positional cube notation [139, 114], and then invoking a multiple-valued minimizer, such as <ref> [114] </ref>. The minimized cover is output disjoint and all the reduction in the cardinality of the symbolic cover is due to the input part, i.e. due to the fact that some present states fan out to the same next state for certain primary inputs. <p> The Two-level Case We report one set of experiments that compare programs for two-level state assignments. Table 4.1 summarizes the results obtained running the algorithms of NOVA [147], KISS [92] and random state assignments. The results of NOVA were obtained running ESPRESSO <ref> [114] </ref> to obtain the input constraints and the symbolic minimizer of NOVA built on top of ESPRESSO to obtain the mixed input/output constraints, NOVA to satisfy the constraints on the codes of the states and of the 4.1. <p> When the target implementation is two-level logic, the first step may consist of one or more calls [92, 91] to a multiple-valued minimizer <ref> [114] </ref>, after representing the symbolic variables with positional cube notation [139, 114]. Then constraints are extracted and a constraints satisfaction problem is set up. Using the paradigm of symbolic minimization followed by constraints satisfaction, the most common types of constraints that may be generated [92, 91, 39, 116] are four. <p> When the target implementation is two-level logic, the first step may consist of one or more calls [92, 91] to a multiple-valued minimizer [114], after representing the symbolic variables with positional cube notation <ref> [139, 114] </ref>. Then constraints are extracted and a constraints satisfaction problem is set up. Using the paradigm of symbolic minimization followed by constraints satisfaction, the most common types of constraints that may be generated [92, 91, 39, 116] are four. <p> A multiple-valued minimizer, such as <ref> [114] </ref>, can be invoked on the symbolic representation of the FSM. This can be done by representing the symbolic variables using the positional cube notation [139, 114]. <p> A multiple-valued minimizer, such as [114], can be invoked on the symbolic representation of the FSM. This can be done by representing the symbolic variables using the positional cube notation <ref> [139, 114] </ref>. The effect of multiple-valued logic minimization is to group together the states that are mapped by some input into the same next-state and assert the same output. <p> NOVA is a state assignment program for two-level implementations, that features a variety of constraint satisfaction algorithms. The input constraints are generated by calling the two-level multiple-valued logic minimizer ESPRESSO <ref> [114] </ref>. The number of satisfied face constraints and the number of cubes in a two-level implementation of the constraints using the minimum possible length for encoding are compared in the table. <p> GENERALIZED PRIME IMPLICANTS 7.2.2 Multi-valued Functions We review the definitions used for multi-valued (also known as symbolic) input binary-valued functions. For a more complete treatment the reader is referred to <ref> [114] </ref>. Definition 7.2.1 Let p i ; i = 1; : : :; n be positive integers. Define P i = f0; : : : ; p i 1g for i = 1; : : : ; n, and B = f0; 1; flg. <p> We call it functional view. Instead in the more modern relational view the outputs are treated as one more multi-valued variable <ref> [118, 114] </ref>. <p> We will generalize the transformation to the case of ISFSM's and prove the correctness of the reduction. This reduction is of great interest because it allows to exploit existing efficient algorithms for prime generation <ref> [114, 53] </ref>. We will describe briefly in Section 11.2 efficient algorithms for generation of large sets of primes and report on their application to this problem. 4 GPI cancellation when the present state part of the cancelling cube is full preserves encodeability because it actually relaxes input constraints. 7.4. <p> At the end, when a minimum solution of the original problem has been found, codes of minimum length that satisfy the encoding constraints of the optimal solution must be determined. In the output table we must solve an ordinary unate covering problem, for which well-known algorithms exist <ref> [114] </ref>. In the next state table we must solve a constrained covering problem: choose a minimum number of columns such that all encoding constraints are satisfied. An exact algorithm can be designed using a branch-and-bound scheme as for table covering. <p> IMPLICIT MINIMIZATION OF GPI'S We refer to [53, 30] for a complete treatment of the topic and we report here a few facts required in our application. If a multiple-valued function is represented in positional notation <ref> [114] </ref>, cubes of the onset (or dcset or offset) of the function can be mapped into vertices of a suitable Boolean space (extended Boolean space), which has as many variables as the length of a positional vector.
Reference: [115] <author> A. Saldanha and R. Katz. </author> <title> PLA optimization using output encoding. </title> <booktitle> In The Proceedings of the International Conference on Computer-Aided Design, </booktitle> <month> November </month> <year> 1988. </year>
Reference-contexts: The translation of a cover obtained by symbolic minimization into a compatible boolean representation defines simultaneously a face embedding problem and an output dominance satisfaction problem. Any output encoding problem can be solved by symbolic minimization. Symbolic minimization was applied also in <ref> [115] </ref>, where a particular form of PLA partitioning is examined, by which the outputs are encoded to create a reduced PLA that is cascaded with a decoder. However, to mimic the full power of two-valued logic minimization, another fact must be taken into account. <p> The translation of a cover obtained by symbolic minimization into a compatible boolean representation defines simultaneously a face embedding problem and an output dominance satisfaction problem. Notice that any output encoding problem can be solved by symbolic minimization. Symbolic minimization was applied also in <ref> [115] </ref>, where a particular form of PLA partitioning is examined, by which the outputs are encoded to create a reduced PLA that is cascaded with a decoder. However, to mimic the full power of two-valued logic minimization, another fact must be taken into account. <p> SYMBOLIC MINIMIZATION 109 Chapter 6 Encoding Constraints 6.1 Introduction The various techniques for exact and heuristic encoding based on multiple-valued or symbolic minimization of two-level and multi-level logic, reported in <ref> [92, 91, 115, 39, 85, 18] </ref>, produce various types of encoding constraints. By encoding constraints we mean requirements on the codes to be assigned to the symbols. A first type are face-embedding constraints generated by the multiple-valued input variables (input constraints).
Reference: [116] <author> A. Saldanha, T. Villa, R. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> Satisfaction of input and output encoding constraints. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 13 </volume> <pages> 589-602, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Efficient algorithms have been devised both for multiple-valued minimization [114] and input constraints satisfaction <ref> [92, 145, 116] </ref>. Even though state encoding is an input-output encoding problem 2 , it can be approximated as an input encoding problem [92] and solved by a two-step process. <p> Then constraints are extracted and a constraints satisfaction problem is set up. Using the paradigm of symbolic minimization followed by constraints satisfaction, the most common types of constraints that may be generated <ref> [92, 91, 39, 116] </ref> are four. The first type, generated by the input variables, are face-embedding constraints. The three types generated by the output variables are dominance, disjunctive and disjunctive-conjunctive constraints. <p> We used the algorithms reported in <ref> [116] </ref>, to which we refer for a complete description. They are based on the notion of encoding dichotomies that are candidate encoding columns. The notion of encoding dichotomy was pioneered in [143] and the connection with satisfaction of face constraints was 5.8. <p> The FSM's come from the MCNC suite and other benchmarks. The experiments were run on a DEC 3100 work-station. Our program ESP SA uses a library of routines described in <ref> [116] </ref> to check encodeability of constraints and produce minimum-length codes that satisfy them. Table 5.1 shows the statistics of the FSM's used. <p> When there are input constraints only, the notions of valid prime dichotomies and of valid complete dichotomies coincide. In general, there are two ways of computing all valid complete dichotomies: 1. In generate initial dichotomies add all uniqueness constraints to I, as done in <ref> [116] </ref>. 2. After the prime encoding dichotomies have been generated, make them complete, by adding in all possible ways the missing symbols to the right and left blocks. We will adopt here the first option because it is more practical in this algorithmic frame. <p> Given the structure of the encoding constraints, they can always be satisfied by adding more columns to a given selection that solves the ordinary covering problem. 3 . Every input and uniqueness constraint yields a set of initial encoding dichotomies <ref> [116] </ref>. For each initial encoding dichotomy there is a companion one, where the same blocks of states appear moved from left to right and viceversa. Only one of two companion encoding-dichotomies must be satisfied. Next state constraints can be viewed as deleting encoding dichotomies. <p> If so, codes of minimum length that satisfy the constraints must be found in order to convert the cover of encodeable GPI's into a two-valued cover that implements the original FSM. Theory and algorithms to check satisfiability of encoding constraints have been proposed in <ref> [116] </ref>, to which we refer for details. Here we review necessary definitions and theorems. Moreover, we present novel results on encodeability of GPI's that will be the basis for a new feasibility check algorithm very suitable for a BDD-based representation. <p> A dichotomy i 0 = (l 0 ; r 0 ) orderly or block-wise covers another dichotomy i = (l; r), noted as i 0 i, iff l 0 l and r 0 r. Notice that this definition differs from the one given in <ref> [116] </ref>, where it is said that a dichotomy i 1 covers a dichotomy i 2 if the left and right blocks of i 2 are subsets respectively either of the left and right blocks, or of the right and left blocks of i 1 . <p> A valid dichotomy is one that does not violate any next-state encoding constraint. The notion of valid and complete dichotomy coincides with the notion of prime dichotomy proposed in <ref> [116] </ref>, but here we will not use the latter term since we do not rely on iterated union to generate valid and complete dichotomies. A dichotomy is raised by adding states into either its left or right block as implied by the next-state encoding constraints. <p> I = duality equivalence (I) foreach (free dichotomy i = fi L ; i R g 2 I) if ( i is not covered by d (i L ) 2 D or by d (i R ) 2 D) return (INFEASIBLE) return (FEASIBLE) g The procedure check feasible (modified from <ref> [116] </ref>) generates initial dichotomies from face constraints and uniqueness constraints, raises and deletes them using the next state constraints (procedures raise dichotomy and remove invalid dichotomies) and finally reports the unsatisfied initial dichotomies. <p> of minimum length is dropped, then it is sufficient to take the valid maximally raised dichotomies, make each of them complete by adding to the right block any state absent from the dichotomy and then choose a minimal set of complete maximally raised dichotomies that cover all free initial dichotomies <ref> [116] </ref>. Note that by adding absent states to the right block no invalid dichotomy can be produced, since no existing encoding constraints become applicable to the complete maximally raised dichotomies so obtained. We will now discuss the case where codes of minimum length are wanted. <p> GPI to improve satisfiability and to compute a lower bound on the number of GPI's to be added to make the problem feasible. They differ significantly from those proposed in <ref> [116] </ref> because the fact of using a BDD-base representation has motivated a different formulation of the encodeability check. The encodeability problem is such that the number of encoding constraints is proportional to the number of minterms. <p> To test for termination, one checks if a dichotomy is invalid or not. As compared with the explicit algorithm in <ref> [116] </ref>, raising is stopped once an invalid dichotomy is detected by a simpler way of testing invalidity.
Reference: [117] <author> S.C. De Sarkar, A.K. Basu, and A.K. Choudhury. </author> <title> Simplification of incompletely specified flow tables with the help of prime closed sets. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 953-956, </pages> <month> October </month> <year> 1969. </year>
Reference-contexts: Therefore techniques for the latter solve also the former. In the other direction, exact state minimization, a problem naturally formulated as a binate covering problem, can be reduced to a unate covering problem, after the generation of irredundant prime closed sets <ref> [117] </ref>. But there is a catch here: the cost function is not any more additive, so that the reduction techniques so convenient to solve covering problems, are not any more applicable as they are. In this chapter, we are interested in exact solutions of binate covering.
Reference: [118] <author> T. Sasao. </author> <title> An application of multiple-valued logic to a design of Programmable Logic Arrays. </title> <booktitle> In The Proceedings of the International Symposium on Multiple-Valued Logic, </booktitle> <year> 1978. </year>
Reference-contexts: We call it functional view. Instead in the more modern relational view the outputs are treated as one more multi-valued variable <ref> [118, 114] </ref>.
Reference: [119] <author> T. Sasao. </author> <title> Multiple-valued decomposition of generalized Boolean functions and the complexity of Programmable Logic Arrays. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-30:635-643, </volume> <month> September </month> <year> 1981. </year>
Reference-contexts: The minimization problem for multiple-output functions is equivalent to the minimization of a multiple-valued function of this form <ref> [119] </ref>. Definition 2.7.2 Let X i be a variable taking a value from the set P i , and let S i be a subset of P i . <p> A variety of other applications may also generate similar constraints satisfaction problems, as in the case of synthesis for sequential testability [35], and optimal re-encoding and decomposition of PLA's <ref> [40, 21, 122, 120, 119, 121, 123] </ref>. Given a PLA, it is possible to group the inputs into pairs and replace the input buffers with two-bit decoders to yield a bit-paired PLA with the same number of columns and no more product-terms than the original PLA. <p> The minimization problem for multiple-output functions is equivalent to the minimization of a multiple-valued function of this form <ref> [119] </ref>. Definition 7.2.2 Let X i be a variable taking a value from the set P i , and let S i be a subset of P i .
Reference: [120] <author> T. Sasao. </author> <title> Input variable assignment and output phase optimization of PLA's. </title> <journal> In IEEE Transactions on Computers, </journal> <month> October </month> <year> 1984. </year>
Reference-contexts: A variety of other applications may also generate similar constraints satisfaction problems, as in the case of synthesis for sequential testability [35], and optimal re-encoding and decomposition of PLA's <ref> [40, 21, 122, 120, 119, 121, 123] </ref>. Given a PLA, it is possible to group the inputs into pairs and replace the input buffers with two-bit decoders to yield a bit-paired PLA with the same number of columns and no more product-terms than the original PLA.
Reference: [121] <author> T. Sasao. </author> <title> Multiple-valued logic and optimization of programmable logic arrays. </title> <booktitle> Computer, </booktitle> <pages> pages 71-80, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: A variety of other applications may also generate similar constraints satisfaction problems, as in the case of synthesis for sequential testability [35], and optimal re-encoding and decomposition of PLA's <ref> [40, 21, 122, 120, 119, 121, 123] </ref>. Given a PLA, it is possible to group the inputs into pairs and replace the input buffers with two-bit decoders to yield a bit-paired PLA with the same number of columns and no more product-terms than the original PLA.
Reference: [122] <author> T. Sasao. </author> <title> Application of multiple-valued logic to a serial decomposition of PLA's. </title> <booktitle> In The Proceedings of the International Symposium on Multiple-Valued Logic, </booktitle> <month> June </month> <year> 1989. </year> <note> 332 BIBLIOGRAPHY </note>
Reference-contexts: A variety of other applications may also generate similar constraints satisfaction problems, as in the case of synthesis for sequential testability [35], and optimal re-encoding and decomposition of PLA's <ref> [40, 21, 122, 120, 119, 121, 123] </ref>. Given a PLA, it is possible to group the inputs into pairs and replace the input buffers with two-bit decoders to yield a bit-paired PLA with the same number of columns and no more product-terms than the original PLA.
Reference: [123] <author> T. Sasao. </author> <title> On the optimal design of multiple-valued PLA's. </title> <journal> IEEE Transactions on Computers, C-38, </journal> <volume> n.4:582-592, </volume> <month> April </month> <year> 1989. </year>
Reference-contexts: A variety of other applications may also generate similar constraints satisfaction problems, as in the case of synthesis for sequential testability [35], and optimal re-encoding and decomposition of PLA's <ref> [40, 21, 122, 120, 119, 121, 123] </ref>. Given a PLA, it is possible to group the inputs into pairs and replace the input buffers with two-bit decoders to yield a bit-paired PLA with the same number of columns and no more product-terms than the original PLA.
Reference: [124] <author> G. Saucier, M. Crastes de Paulet, and P. Sicard. Asyl: </author> <title> a rule-based system for controller synthesis. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <month> November </month> <year> 1987. </year>
Reference-contexts: In general reduced dependency has various advantages that included better testability features, but suffers from a weak connection with the logic optimization steps after the encoding. More recent approaches <ref> [124, 125] </ref> rely on local optimization rules defined on a control flowgraph. <p> This means that output encoding is more important than input encoding on the quality of final results. Comparisons for some of the approaches mentioned above <ref> [124, 39] </ref> have not been carried out for the lack of an available implementation. The Multi-level Case We report a set of experiments that correlate good two-level state assignment to the corresponding multi-level logic implementation, comparing against an estimation-based multi-level encoding algorithm.
Reference: [125] <author> G. Saucier, C. Duff, and F. Poirot. </author> <title> A new embedding method for state assignment. </title> <booktitle> The Proceedings of the International Workshop on Logic Synthesis, </booktitle> <month> May </month> <year> 1989. </year>
Reference-contexts: In general reduced dependency has various advantages that included better testability features, but suffers from a weak connection with the logic optimization steps after the encoding. More recent approaches <ref> [124, 125] </ref> rely on local optimization rules defined on a control flowgraph.
Reference: [126] <author> G. Saucier, C. Duff, and F. Poirot. </author> <title> State assignment using a new embedding method based on an intersecting cube theory. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <year> 1989. </year>
Reference-contexts: SYMBOLIC MINIMIZATION BY EXAMPLE 93 OnCov: on-set of st2 0010000 on-set of st4 0000100 OffCov: on-set of st2 0001100 on-set of st4 0011000 on-set of st5 0011100 established in [154]. Other contributions on the subject can be found in <ref> [126, 20] </ref> and more recently in [44, 45]. 5.8 Symbolic Minimization by Example In this section we clarify with an example the mechanics by which the oring effects plays an important role in the minimization of symbolic logic. <p> Exact algorithms and efficient heuristics (restricted to input and dominance constraints) for solving problems P-2 and P-3 are reported in [147]. An approximate solution to P-3 for input constraints based on a theory of intersecting cubes is described in <ref> [126, 43] </ref> and a solution based on simulated annealing is reported in [81]. An exact solution to P-2 for input constraints based on the notion of prime sections is described in [44, 45].
Reference: [127] <author> R. B. Segal. BDSYN: </author> <title> Logic description translator; BDSIM: Switch level simulator. </title> <type> Master's Thesis M87/33, </type> <institution> Electronics Research Lab., University of California, Berkeley, </institution> <month> May </month> <year> 1987. </year>
Reference: [128] <author> M. Servit and J. Zamazal. </author> <title> Exact approaches to binate covering problem. </title> <note> Manuscript in preparation, </note> <month> October </month> <year> 1992. </year>
Reference-contexts: This definition of column mutual dominance is * identical to rule for mutually reducible variables in <ref> [128] </ref>, * not mentioned in other papers. 10.5.7 Essential Column Definition 10.5.8 A column C j is an essential column if there exists a row R i having a 1 in column C j and 2's everywhere else.
Reference: [129] <author> C.-J. Shi and J. Brzozowski. </author> <title> An efficient algorithm for constrained encoding and its applications. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <pages> pages 1813-1826, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: An approximate solution to P-2 and P-3 for input constraints based on a greedy strategy to find an encoding bit by bit and on an iterative method to improve the obtained solution is reported in <ref> [129] </ref>. The answer to Problem P-1 is always affirmative for input constraints only. A solution to P-1 and a heuristic algorithm to solve P-3 when both input and output dominance constraints occur are provided in [91], extending an algorithm for input constraints described in [92].
Reference: [130] <editor> F. Somenzi. Cookie. </editor> <booktitle> Computer Program, </booktitle> <year> 1989. </year>
Reference-contexts: This technique has been described in [51, 50, 13, 14], and implemented in successful computer programs <ref> [112, 108, 130] </ref>. The branch-and-bound solution of minimum binate covering is based on a recursive procedure. A run of the algorithm can be described by its computation tree. <p> Bi-partitioning is implemented in <ref> [108, 130] </ref> as follows. When checking for a partition of the problem (line 7), the routine sm mincov is called recursively on two independents subproblems (lines 8 and 10), if they exist. <p> Since finding a maximum independent set is an NP-complete problem, in practice an heuristic is used that provides a weaker lower bound. Notice that even the lower bound provided by solving exactly maximum independent set is not sharp. In <ref> [112, 108, 130] </ref>, the adjacency matrix B of a graph whose nodes correspond to rows in the cover matrix M is created. In the binate case, only rows are taken into consideration which do not contain any 0 element. <p> Since the time taken by the selection is a significant part of the total, a trade-off must be made between quality and efficiency. In <ref> [112, 108, 130] </ref>, the selection of the branching variable is restricted to columns intersecting the rows of the independent set, because a unique column must eventually be selected from each row of the maximal independent set. <p> The effect of reductions depends on the order of their application. Reductions are usually attempted in a given order, until nothing changes any more (i.e., the covering matrix has been reduced to a cyclic core). Figure 10.5 shows how reductions are applied in <ref> [112, 108, 130] </ref> 1 . 10.5.1 Row Dominance Definition 10.5.1 A row R i dominates another row R j if R j has all the 1's and 0's of R i ; i.e., for each column C k of M , one of the following occurs: * M i;k = 1 <p> 1's and 0's of R i ; i.e., for each column C k of M , one of the following occurs: * M i;k = 1 and M j;k = 1, 1 The reductions fi-dominance and row consensus are only in [108] and the reduction by implication is only in <ref> [130] </ref>. 244 CHAPTER 10. <p> Gimpel's rule has been first proposed in [48] and then implemented in [112]. In <ref> [108, 130] </ref> Gimpel's rule has been extended to handle the binate case. This extension has been described in [131]. 10.6.
Reference: [131] <author> F. Somenzi. </author> <title> Gimpel's reduction technique extended to the binate covering problem. </title> <type> Unpublished manuscript, </type> <year> 1989. </year>
Reference-contexts: Gimpel's rule has been first proposed in [48] and then implemented in [112]. In [108, 130] Gimpel's rule has been extended to handle the binate case. This extension has been described in <ref> [131] </ref>. 10.6.
Reference: [132] <author> F. Somenzi. </author> <title> Binate covering formulation of exact two-level encoding. </title> <type> Unpublished manuscript, </type> <month> March </month> <year> 1990. </year>
Reference-contexts: An approach reduces the problem to unate covering with encodeability and it has been proposed in [39]. A reduction to binate covering, where encodeability is translated into binate clauses, has been outlined in <ref> [133, 132] </ref>. Here we introduce the two approaches and discuss their respective merits. We start with reduction of GPI minimization to unate covering. In [39] it is summarily proposed a modification of unate covering to solve the problem of selecting a minimum encodeable set of GPI's. <p> The idea has been advanced further in <ref> [133, 132] </ref>, to cast the whole problem of selecting a minimum encodeable cover of GPI's, for a fixed code-length, as a binate covering problem. An implementation has been described in [19]. A binate covering problem asks for the minimum solution of a formula written as a POS.
Reference: [133] <author> F. Somenzi. </author> <title> An example of symbolic relations applied to state encoding. </title> <type> Unpublished manuscript, </type> <month> May </month> <year> 1990. </year>
Reference-contexts: An approach reduces the problem to unate covering with encodeability and it has been proposed in [39]. A reduction to binate covering, where encodeability is translated into binate clauses, has been outlined in <ref> [133, 132] </ref>. Here we introduce the two approaches and discuss their respective merits. We start with reduction of GPI minimization to unate covering. In [39] it is summarily proposed a modification of unate covering to solve the problem of selecting a minimum encodeable set of GPI's. <p> The idea has been advanced further in <ref> [133, 132] </ref>, to cast the whole problem of selecting a minimum encodeable cover of GPI's, for a fixed code-length, as a binate covering problem. An implementation has been described in [19]. A binate covering problem asks for the minimum solution of a formula written as a POS. <p> We do not know of an exact procedure that explores at the same time state minimization and state assignment of ISFSM's. In <ref> [133] </ref>, the problem of mapping the implied classes into compatibles in the reduced FSM (problem of unique mapped representation) has been modelled with don't cares transitions in the reduced FSM. The introduction of don't care transitions is a special case of symbolic relations, pioneered in [82, 78]. <p> In this thesis we only consider symbolic don't cares arising with a next state AN Y . They can be handled in the frame of GPI's, without a need to extend the theory to GCPI's. Before leaving the topic of symbolic don't cares, we report an example from <ref> [133] </ref> of unique mapped representation modelled using GCPI's.
Reference: [134] <author> P. Srimani. </author> <title> MOS networks and fault-tolerant sequential machines. </title> <journal> Computers and Electrical Engineering, </journal> <volume> 8(4), </volume> <year> 1981. </year>
Reference-contexts: Note that the satisfia-bility check algorithm described in [39] cannot be easily extended to handle encoding don't cares without a significant penalty in run-time. The encoding algorithm presented in [147] also cannot be extended to handle don't cares. 6.8.2 Distance-2 Constraints In <ref> [135, 134, 35] </ref> a condition for easy and full sequential testability requires an encoding such that the codes assigned to a selected pair of states, say a and b, must be at least distance-2 apart.
Reference: [135] <author> P. Srimani and B. Sinha. </author> <title> Fail-safe realisation of sequential machines with a new two-level MOS module. </title> <journal> Computers and Electrical Engineering, </journal> <volume> 7, </volume> <year> 1980. </year> <note> BIBLIOGRAPHY 333 </note>
Reference-contexts: Note that the satisfia-bility check algorithm described in [39] cannot be easily extended to handle encoding don't cares without a significant penalty in run-time. The encoding algorithm presented in [147] also cannot be extended to handle don't cares. 6.8.2 Distance-2 Constraints In <ref> [135, 134, 35] </ref> a condition for easy and full sequential testability requires an encoding such that the codes assigned to a selected pair of states, say a and b, must be at least distance-2 apart.
Reference: [136] <author> A. Srinivasan, T. Kam, S. Malik, and R. Brayton. </author> <title> Algorithms for discrete function manipulation. </title> <booktitle> Proc. Int. Conf. CAD (ICCAD-90), </booktitle> <pages> pages 92-95, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: We represent a relation R by its characteristic function R : D fi B m ! B such that R (x; y) = 1 if and only if (x; y) 2 R. In the implementation, we represent a characteristic function by using a multi-valued decision diagram (MDD, see <ref> [64, 136] </ref>). An MDD is a data structure to represent a function with multiple-valued input variables and a single binary output, which employs a BDD [16] as the internal data structure.
Reference: [137] <author> R. Stearns and J. Hartmanis. </author> <title> On the state assignment problem for sequential machines - 2. </title> <journal> IRE Transactions on Electronic Computers, </journal> <month> December </month> <year> 1961. </year>
Reference-contexts: PREVIOUS AND RELATED WORK taken into consideration in the optimization procedure. This work was refined and commented by other contributions [101, 102, 103]. Others, as <ref> [54, 137, 67] </ref>, proposed algebraic methods based on the algebra of partitions and on the criterion of reduced dependency.
Reference: [138] <author> J. Storey, H. Harrison, and E. Reinhard. </author> <title> Optimum state assignment for synchronous sequential machines. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 1365-1373, </pages> <month> December </month> <year> 1972. </year>
Reference-contexts: Armstrong argued in [2] that the scoring array of [41] could be read in the framework that he proposed. Story, Harrison et al. <ref> [141, 138] </ref> proposed algorithms to derive minimal-cost assignments based on the lower-bound approach first described by Davis [33] and extending the technique to find the cost of an assignment proposed by Torng [141].
Reference: [139] <author> Y. Su and P. Cheung. </author> <title> Computer minimization of multi-valued switching functions. </title> <journal> IEEE Transactions on Computers, </journal> <month> September </month> <year> 1972. </year>
Reference-contexts: Multiple-valued minimization of this FSM where the states are the possible values of a multiple-valued variable yields the cover shown in Figure 4.1 (b). This can be done by representing the symbolic variables using the positional cube notation <ref> [139, 114] </ref>, and then invoking a multiple-valued minimizer, such as [114]. <p> When the target implementation is two-level logic, the first step may consist of one or more calls [92, 91] to a multiple-valued minimizer [114], after representing the symbolic variables with positional cube notation <ref> [139, 114] </ref>. Then constraints are extracted and a constraints satisfaction problem is set up. Using the paradigm of symbolic minimization followed by constraints satisfaction, the most common types of constraints that may be generated [92, 91, 39, 116] are four. <p> A multiple-valued minimizer, such as [114], can be invoked on the symbolic representation of the FSM. This can be done by representing the symbolic variables using the positional cube notation <ref> [139, 114] </ref>. The effect of multiple-valued logic minimization is to group together the states that are mapped by some input into the same next-state and assert the same output.
Reference: [140] <author> Y. Tohma, Y. Ohyama, and R. Sakai. </author> <title> Realization of fail-safe sequential machines by using a k-out-of-n code. </title> <journal> IEEE Transactions on Computers, </journal> <month> November </month> <year> 1971. </year>
Reference-contexts: Recently Calazans [17] proposed an heuristic algorithm to use information about compatible states of ISFSM's while doing state assignment. 4.2.3 State Assignment and Testability Unate state assignments to guarantee testability by construction were proposed first in <ref> [140] </ref>. The logic to compute the outputs and the encoding of the next state is said to be unate in a given state variable, if the output and next state functions can be expressed as sums of products where the given variable appears either uncomplemented or complemented, but not both.
Reference: [141] <author> H.C. Torng. </author> <title> An algorithm for finding secondary assignments of synchronous sequential circuits. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 461-469, </pages> <month> May </month> <year> 1968. </year>
Reference-contexts: Armstrong argued in [2] that the scoring array of [41] could be read in the framework that he proposed. Story, Harrison et al. <ref> [141, 138] </ref> proposed algorithms to derive minimal-cost assignments based on the lower-bound approach first described by Davis [33] and extending the technique to find the cost of an assignment proposed by Torng [141]. <p> Story, Harrison et al. [141, 138] proposed algorithms to derive minimal-cost assignments based on the lower-bound approach first described by Davis [33] and extending the technique to find the cost of an assignment proposed by Torng <ref> [141] </ref>. A set of columns, each composed of a binary element for each row of a partially assigned state table, is derived. From this matrix it is possible to generate all possible distinct state assignments.
Reference: [142] <author> H. Touati, H. Savoj, B. Lin, R. K. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> Implicit state enumeration of finite state machines using BDD's. </title> <booktitle> The Proceedings of the International Conference on Computer-Aided Design, </booktitle> <pages> pages 130-133, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Special care must be exercised with quantifications, that bring more danger of BDD blowups. All of this goes often under the name of implicit representations and computations. The previous insight has already been tested in a series of applications. Research at Bull [23] and UC Berkeley <ref> [142] </ref> produced powerful techniques for implicit enumeration of subsets of states of a Finite State Machine (FSM). Later work at Bull [25, 79] has shown how implicants, primes and essential primes of a two-valued or multi-valued function can also be computed implicitly.
Reference: [143] <author> J. Tracey. </author> <title> Internal state assignment for asynchronous sequential machines. </title> <journal> IRE Transactions on Electronic Computers, </journal> <month> August </month> <year> 1966. </year>
Reference-contexts: We used the algorithms reported in [116], to which we refer for a complete description. They are based on the notion of encoding dichotomies that are candidate encoding columns. The notion of encoding dichotomy was pioneered in <ref> [143] </ref> and the connection with satisfaction of face constraints was 5.8. SYMBOLIC MINIMIZATION BY EXAMPLE 93 OnCov: on-set of st2 0010000 on-set of st4 0000100 OffCov: on-set of st2 0001100 on-set of st4 0011000 on-set of st5 0011100 established in [154]. <p> This result has not been shown previously, though it has been conjectured [91]. The approach used here is based on a formulation provided in [154], which in turn is related to the state assignment technique employed by Tracey in 1966 <ref> [143] </ref>. We first demonstrate the difficulty of finding codes that satisfy encoding constraints by proving it NP-complete in Section 6.2. Section 6.3 provides some definitions. In Section 6.4 an abstraction of the problem is presented. In Section 6.5 we describe a new algorithm to satisfy input constraints only. <p> For example, (s 0 s 1 ; s 2 s 3 ) is a dichotomy in which s 0 and s 1 are associated with the bit 0 and s 2 and s 3 with the bit 1. This definition of dichotomy differs from the one in <ref> [143, 154] </ref>, which allows the left block of a dichotomy to assume either the encoding bit 0 or 1, and it is equivalent to the definition of fixed dichotomy given in [20]. A dichotomy is complete if each symbol appears in either block. <p> Otherwise, d 1 and d 2 are incompatible. Note again that this definition differs from the definition of compatibility described in <ref> [143, 154] </ref>. The union of two compatible dichotomies, d 1 and d 2 , is the dichotomy whose left and right blocks are the union of the left and right blocks of d 1 and d 2 respectively. The union 114 CHAPTER 6. <p> A minimum column cover of the given rows gives a minimum set of encoding columns that satisfy all given constraints. This requires the solution of a binate covering problem. However, the problem reduces to a unate covering problem when only face constraints are present <ref> [143] </ref>. 1 000 and 111 are excluded because they do not carry useful information. 116 CHAPTER 6. ENCODING CONSTRAINTS Although BCP offers a unified framework for solving encoding constraints, the design of efficient algorithms requires exploiting specific features of the problems at hand. <p> We need to add only those uniqueness constraints that are not covered by the dichotomies generated from the face-embedding constraints, because any encoding that satisfies the covering dichotomy satisfies also the covered dichotomy. The second step of encoding is the generation of prime dichotomies from the dichotomies. <ref> [143] </ref> describes an approach similar to the process of iterated consensus for prime generation in two-level logic minimization [11]. However, the number of iterations required to generate all the prime dichotomies may be formidable even for small problems. <p> OTHER APPLICATIONS 137 where b 1 and b 2 are two new columns of the covering table. 6.8.3 Asynchronous State Assignment The state assignment algorithm proposed by Tracey <ref> [143] </ref> may also be applied in performing state assignment for asynchronous state machines [74].
Reference: [144] <author> D. Varma and E.A. Trachtenberg. </author> <title> Design automation tools for efficient implementation of logic functions by decomposition. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <volume> 8-8:901-916, </volume> <month> August </month> <year> 1989. </year>
Reference-contexts: Pesto PESTO [57] is a new tool that resembles JEDI with respect to the basic model, but by means of very skilled algorithmic engineering obtains codes that produce often (as of today) the best starting points for multi-level implementations. The model starts form the observation, justified in <ref> [144] </ref>, that if x and y are two binary input vectors, f (x) is a single output boolean function, and P = f (x; y) j hamming distance (x; y) = 1 and f (x) = f (y)g; then, within a class of "related" functions, the larger the size of P,
Reference: [145] <author> T. Villa, L. Lavagno, and A. Sangiovanni-Vincentelli. </author> <title> Advances in encoding for logic synthesis. In Digital Logic Analysis and Design, </title> <editor> G. Zobrist ed. </editor> <publisher> Ablex, </publisher> <address> Norwood, </address> <year> 1995. </year>
Reference-contexts: Efficient algorithms have been devised both for multiple-valued minimization [114] and input constraints satisfaction <ref> [92, 145, 116] </ref>. Even though state encoding is an input-output encoding problem 2 , it can be approximated as an input encoding problem [92] and solved by a two-step process. <p> presented in Section 6.6 provides a uniform framework for the satisfaction of various other encoding problems. 6.8.1 Input Encoding Don't Cares The notion of an encoding don't care was first described in [91], and an example of how encoding don't cares are generated in the two-level case is given in <ref> [145] </ref>. A face constraint containing symbols a, b and e and with symbols c and d as encoding don't cares is denoted (a; b; [c; d]; e).
Reference: [146] <author> T. Villa, A. Saldanha, R. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> Symbolic two-level minimization. </title> <note> Submitted for publication, </note> <year> 1995. </year>
Reference-contexts: This advances the state-of-art of symbolic minimization, otherwise restricted to the use of heuristic tools. that do not guarantee a complete exploration of the solution space. It is true, though, that competing algorithms <ref> [92, 147, 146] </ref> are often well-tuned for their domain of application, while our prototype of GPI minimization is not yet mature for field applications. In Chapter 10 we have presented an implicit procedure to solve binate covering problems.
Reference: [147] <author> T. Villa and A. Sangiovanni-Vincentelli. </author> <title> NOVA: State assignment for optimal two-level logic implementations. </title> <booktitle> In IEEE Transactions on Computer-Aided Design, </booktitle> <pages> pages 905-924, </pages> <month> September </month> <year> 1990. </year> <note> 334 BIBLIOGRAPHY </note>
Reference-contexts: Sharing of logic is crucial to obtain minimum encoded two-level implementations. Therefore extensions of multiple-valued minimization have been proposed in <ref> [91, 147] </ref>. These extensions replace a single multiple-valued minimization of the whole symbolic cover by a sequence of minimization operations on parts of the symbolic cover in such a way as to recognize sharing of logic among next states, if some constraints on their codes are satisfied. <p> These extensions of multiple-valued minimization have been called symbolic minimization. In <ref> [91, 147] </ref> symbolic minimization was introduced to exploit bit-wise dominance relations between the binary codes assigned to different values of a symbolic output variable. The fact is that the input cubes of a dominating code can be used as don't cares for covering the input cubes of a dominated code. <p> For the experiments we used the MCNC '89 set of benchmark FSM's. The Two-level Case We report one set of experiments that compare programs for two-level state assignments. Table 4.1 summarizes the results obtained running the algorithms of NOVA <ref> [147] </ref>, KISS [92] and random state assignments. <p> We report two kinds of experiments to verify the validity of MIS-MV as input encoder: * Compare the relative importance of the various multi-valued optimization steps. * Compare MIS-MV with some existing state assignment programs, such as JEDI [77], MUSE [42], MUSTANG [36] and NOVA <ref> [147] </ref>. Notice that we want to compare only the input encoding algorithms of these programs and so we need to "shut off" all effects due to the encoding of the output part, captured by purpose (these programs embody also heuristics for the output encoding problem) or by chance. <p> We will see now more powerful schemes to deal with both input and output encoding. In <ref> [91, 147] </ref> a new scheme was proposed, called symbolic minimization. Symbolic minimization was introduced to exploit bit-wise dominance relations between the binary codes assigned to different values of a symbolic output variable. <p> We did not use disjunctive-conjunctive constraints in the heuristic procedure presented here. 5.3 A New Symbolic Minimization Algorithm 5.3.1 Structure of the Algorithm In this section a new more powerful paradigm of symbolic minimization is presented. An intuitive explanation of symbolic minimization as proposed in [91] and enhanced in <ref> [147] </ref> has been given in Section 5.2. To help in highlighting the differences of the two schemes, the one in [147] is summarized in Figure 5.3. The new scheme of symbolic minimization features the following novelties. * Symbolic oring. <p> An intuitive explanation of symbolic minimization as proposed in [91] and enhanced in <ref> [147] </ref> has been given in Section 5.2. To help in highlighting the differences of the two schemes, the one in [147] is summarized in Figure 5.3. The new scheme of symbolic minimization features the following novelties. * Symbolic oring. Disjunctive constraints are generated corresponding to the case of transitions of the initial cover implicitly expressed by other transitions in the encoded two-level 5.3. A NEW SYMBOLIC MINIMIZATION ALGORITHM 79 1. <p> Previous work on encoding constraint satisfaction has dealt mostly, but not exclusively, with input constraints. Exact algorithms and efficient heuristics (restricted to input and dominance constraints) for solving problems P-2 and P-3 are reported in <ref> [147] </ref>. An approximate solution to P-3 for input constraints based on a theory of intersecting cubes is described in [126, 43] and a solution based on simulated annealing is reported in [81]. <p> In the sequel we demonstrate this fact by developing exact and heuristic algorithms. 6.5 Input Constraint Satisfaction We first present a new algorithm for satisfying input encoding constraints that, compared to previous approaches <ref> [147, 154] </ref>, significantly improves the efficiency of the input encoding process. The encoding constraint satisfaction problem is a three-step process. The first is the generation of the dichotomies that represent the face embedding constraints [154]. Each face embedding constraint generates several dichotomies, called initial dichotomies. <p> Note that the satisfia-bility check algorithm described in [39] cannot be easily extended to handle encoding don't cares without a significant penalty in run-time. The encoding algorithm presented in <ref> [147] </ref> also cannot be extended to handle don't cares. 6.8.2 Distance-2 Constraints In [135, 134, 35] a condition for easy and full sequential testability requires an encoding such that the codes assigned to a selected pair of states, say a and b, must be at least distance-2 apart. <p> 26 scf 121 14 11 * 21 * viterbi 68 6 6 6 6 6 vmecont 32 40 24 25 81 67 # Constraints: Number of constraints to be satisfied Constraints: Number of satisfied constraints Cubes: Number of cubes in a two-level implementation of the constraints NOVA: Encoding using NOVA <ref> [147] </ref>, minimum code length ENC: Heuristic encoding, minimum code length * : Out of memory Table 2 : Two-level heuristic minimum code length input encoding less than 50000 primes completed in very little CPU time on a DEC 3100 workstation. <p> The previous approach suggested for prime generation in [154] does not complete on any of the examples. 6.9. RESULTS 141 Table 2 compares an implementation of the heuristic algorithm described in Section 6.7.1 with the best bounded-length input encoding algorithm implemented in NOVA <ref> [147] </ref> (option -e ih). NOVA is a state assignment program for two-level implementations, that features a variety of constraint satisfaction algorithms. The input constraints are generated by calling the two-level multiple-valued logic minimizer ESPRESSO [114]. <p> The number of cubes listed in Table 2 under the column NOVA, is not the same as the number of cubes of the final FSM implementation obtained by NOVA <ref> [147] </ref>. NOVA performs additional encoding tasks to approximate the input-output encoding problem that arises in FSM's. Instead, we compare only the quality of the input encoding algorithms. For instance, we report 284 cubes for tbk using NOVA and 237 cubes for our algorithm. <p> The present contribution shows how to extract a minimal encodeable cover from a large set of GPI's, allowing inline of principle theexploration of all minimal encodeable covers. This advances the state-of-art of symbolic minimization, which up to now has been done with various heuristic tools <ref> [92, 147, 42, 77] </ref>, often very well-tuned for their domain of application, but lacking a rigorous connection beween an exact theory and the approximations made. <p> Other applications can be handled by simple modifications. All run times are reported in CPU seconds on a DEC DS5900/260 with 440 Mb of memory, unless otherwise stated. The objective of the current implementation has not been to compete with existing state assignment programs like NOVA <ref> [147] </ref> that have been heavily optimized, but to show that implicit techniques are mature enough to generate and select encodeable sets of GPI's. <p> It is an open problem how to drive the selection of GPI's with a more global view, in order to obtain encodeable covers of cardinality less or equal to the best encoded covers obtained by various tools <ref> [147] </ref>. This was not an objective of this work, even though the experience gained here will be very useful to attack the issue. The demonstrated techniques exhibit a window of small-medium examples where it is possible to compute minimal symbolic covers using GPI's. <p> The present contribution shows how to extract a minimal encodeable cover from a large set of GPI's, allowing inline of principle theexploration of all minimal encodeable covers. This advances the state-of-art of symbolic minimization, which up to now has been done with various heuristic tools <ref> [92, 147, 42, 77] </ref>, often very well-tuned for their domain of application, but lacking a rigorous 314 CHAPTER 11. IMPLICIT MINIMIZATION OF GPI'S connection beween an exact theory and the approximations made. <p> Experiments show that the encoded covers produced by our procedure are usually smaller or equal than those of the best option of state-of-art tools like NOVA <ref> [147] </ref>. An improvement to the procedure would be to introduce some iterated expansion and reduction scheme, as in ESPRESSO [11], to escape from local minima. <p> This advances the state-of-art of symbolic minimization, otherwise restricted to the use of heuristic tools. that do not guarantee a complete exploration of the solution space. It is true, though, that competing algorithms <ref> [92, 147, 146] </ref> are often well-tuned for their domain of application, while our prototype of GPI minimization is not yet mature for field applications. In Chapter 10 we have presented an implicit procedure to solve binate covering problems.
Reference: [148] <author> Y. Watanabe and R. K. Brayton. </author> <title> State minimization of pseudo non-deterministic fsm's. </title> <booktitle> In European Conference on Design Automation, </booktitle> <pages> pages 184-191, </pages> <year> 1994. </year>
Reference: [149] <author> P. Weiner and E.J. Smith. </author> <title> On the number of state assignments for synchronous sequential machines. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 220-221, </pages> <month> April </month> <year> 1967. </year>
Reference-contexts: and complementation of columns, and 2 n1 &lt; v 2 n , was computed in [88] as: A (v) = (2 n v)!n! The number of equivalence classes of state assignments, where equivalence is only by permutation of columns, and 2 n1 &lt; v 2 n , was computed in <ref> [149] </ref> as: B (v) = (2 n v)!n! The fact that A (v) is correct for SR, J K and T flip-flops was pointed out first in [110].
Reference: [150] <author> W. Wolf. </author> <title> Recoding-derived bounds for input encoding. </title> <note> Submitted for publication, </note> <month> January </month> <year> 1990. </year>
Reference-contexts: These data show that a state assignment that gives a good two-level implementation provides a good starting point for a multi-level implementation, but it does not match the quality reached by algorithms specialized for multi-level implementations. Early claims in <ref> [151, 152, 150] </ref> that two-level tools were good enough also for multi-level implementations reflected mainly a temporary lack of good tools for multi-level implementations.
Reference: [151] <author> W. Wolf, K. Keutzer, and J. Akella. </author> <title> A kernel-finding state assignment algorithm for multilevel logic. </title> <booktitle> In The Proceedings of the Design Automation Conference, </booktitle> <month> June </month> <year> 1988. </year>
Reference-contexts: These data show that a state assignment that gives a good two-level implementation provides a good starting point for a multi-level implementation, but it does not match the quality reached by algorithms specialized for multi-level implementations. Early claims in <ref> [151, 152, 150] </ref> that two-level tools were good enough also for multi-level implementations reflected mainly a temporary lack of good tools for multi-level implementations.
Reference: [152] <author> W. Wolf, K. Keutzer, and J. Akella. </author> <title> Addendum to "A kernel-finding state assignment algorithm for multi-level logic". </title> <booktitle> In IEEE Transactions on Computer-Aided Design, </booktitle> <month> August </month> <year> 1989. </year>
Reference-contexts: These data show that a state assignment that gives a good two-level implementation provides a good starting point for a multi-level implementation, but it does not match the quality reached by algorithms specialized for multi-level implementations. Early claims in <ref> [151, 152, 150] </ref> that two-level tools were good enough also for multi-level implementations reflected mainly a temporary lack of good tools for multi-level implementations.
Reference: [153] <author> C-C. Yang. </author> <title> On the equivalence of two algorithms for finding all maximal compatibles. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 977-979, </pages> <month> October </month> <year> 1975. </year>
Reference-contexts: The problem is how to efficiently derive the equivalent sum-of-products expression from 118 CHAPTER 6. ENCODING CONSTRAINTS the product-of-sums expression representing the incompatibilities. In the past, this has been performed using an approach based on Shannon decomposition <ref> [153] </ref>: f (x 1 ; ; x i ; ; x n ) = x i f (x 1 ; ; 1; ; x n ) + x i f (x 1 ; ; 0; ; x n ) Basically one splits on a variable at a time and generates recursively
Reference: [154] <author> S. Yang and M. Ciesielski. </author> <title> Optimum and suboptimum algorithms for input encoding and its relationship to logic minimization. </title> <journal> IEEE Transactions on Computer-Aided Design, </journal> <month> January </month> <year> 1991. </year>
Reference-contexts: The notion of encoding dichotomy was pioneered in [143] and the connection with satisfaction of face constraints was 5.8. SYMBOLIC MINIMIZATION BY EXAMPLE 93 OnCov: on-set of st2 0010000 on-set of st4 0000100 OffCov: on-set of st2 0001100 on-set of st4 0011000 on-set of st5 0011100 established in <ref> [154] </ref>. Other contributions on the subject can be found in [126, 20] and more recently in [44, 45]. 5.8 Symbolic Minimization by Example In this section we clarify with an example the mechanics by which the oring effects plays an important role in the minimization of symbolic logic. <p> A solution to P-1, when both input and output constraints (including disjunctive constraints) are present, is described in [39], and corrected in [38]. A solution to problem P-2 based on compatible graph coloring is provided for input constraints in <ref> [154] </ref> and extended to output constraints in [20]. To date, to the best of our knowledge, no efficient algorithms exist for solving all three problems when all types of constraints occur. In most previous contributions, techniques to generate constraints and to satisfy them were intermixed. <p> We also prove the NP-completeness of problems P-2 and P-3. This result has not been shown previously, though it has been conjectured [91]. The approach used here is based on a formulation provided in <ref> [154] </ref>, which in turn is related to the state assignment technique employed by Tracey in 1966 [143]. We first demonstrate the difficulty of finding codes that satisfy encoding constraints by proving it NP-complete in Section 6.2. Section 6.3 provides some definitions. <p> For example, (s 0 s 1 ; s 2 s 3 ) is a dichotomy in which s 0 and s 1 are associated with the bit 0 and s 2 and s 3 with the bit 1. This definition of dichotomy differs from the one in <ref> [143, 154] </ref>, which allows the left block of a dichotomy to assume either the encoding bit 0 or 1, and it is equivalent to the definition of fixed dichotomy given in [20]. A dichotomy is complete if each symbol appears in either block. <p> Otherwise, d 1 and d 2 are incompatible. Note again that this definition differs from the definition of compatibility described in <ref> [143, 154] </ref>. The union of two compatible dichotomies, d 1 and d 2 , is the dichotomy whose left and right blocks are the union of the left and right blocks of d 1 and d 2 respectively. The union 114 CHAPTER 6. <p> For example, c 6 = 110 places a and b in the 1-block and c in the 0-block. For each face constraint consider the encoding dichotomies that have the symbols of the face constraint in one block, and have one of the remaining symbols in the other block <ref> [154] </ref>. In the example, this is (ab; c) or (c; ab). This means that by covering either (ab; c) or (c; ab), the face constraint (a; b) is satisfied. <p> In the sequel we demonstrate this fact by developing exact and heuristic algorithms. 6.5 Input Constraint Satisfaction We first present a new algorithm for satisfying input encoding constraints that, compared to previous approaches <ref> [147, 154] </ref>, significantly improves the efficiency of the input encoding process. The encoding constraint satisfaction problem is a three-step process. The first is the generation of the dichotomies that represent the face embedding constraints [154]. Each face embedding constraint generates several dichotomies, called initial dichotomies. <p> The encoding constraint satisfaction problem is a three-step process. The first is the generation of the dichotomies that represent the face embedding constraints <ref> [154] </ref>. Each face embedding constraint generates several dichotomies, called initial dichotomies. The symbols that are to be on a face are placed in one block of each dichotomy representing that constraint, while the other block contains one of the symbols not on the face. <p> However, the number of iterations required to generate all the prime dichotomies may be formidable even for small problems. Using this approach, several different compatible merges often yield the same prime dichotomy. This results in a substantial waste of computation time <ref> [154] </ref>. In Section 6.5.1, we describe a method of generating all prime dichotomies and demonstrate its effectiveness in determining an exact solution. The final step of encoding is to obtain a cover of the initial dichotomies using a minimum number of primes. <p> Thousands of satisfiability checks on input and output encoding constraints can be performed routinely in a matter of seconds, showing the efficiency of our algorithm. The previous approach suggested for prime generation in <ref> [154] </ref> does not complete on any of the examples. 6.9. RESULTS 141 Table 2 compares an implementation of the heuristic algorithm described in Section 6.7.1 with the best bounded-length input encoding algorithm implemented in NOVA [147] (option -e ih). <p> We have shown that the problem of determining a minimum length encoding to satisfy both input and output constraints is NP-complete. Based on an earlier method for satisfying input constraints <ref> [154] </ref>, we have provided an efficient formulation of an algorithm that determines the minimum length encoding that satisfies both input and output constraints. <p> In Chapter 6 we have presented a comprehensive solution to the problem of satisfying encoding constraints. We have shown that the problem of determining a minimum length encoding to satisfy face constraints is NP-complete. Based on an earlier method for satisfying face constraints <ref> [154] </ref>, we have provided an efficient algorithm that determines the minimum length encoding that satisfies both input (face) and output (dominance, disjunctive and disjunctive-conjunctive) constraints.
References-found: 154

