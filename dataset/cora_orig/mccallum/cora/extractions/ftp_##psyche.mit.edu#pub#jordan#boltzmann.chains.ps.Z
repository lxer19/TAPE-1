URL: ftp://psyche.mit.edu/pub/jordan/boltzmann.chains.ps.Z
Refering-URL: http://www.ai.mit.edu/projects/jordan.html
Root-URL: 
Email: lksaul@psyche.mit.edu, jordan@psyche.mit.edu  
Title: Boltzmann Chains and Hidden Markov Models  
Author: Lawrence K. Saul and Michael I. Jordan 
Address: 79 Amherst Street, E10-243 Cambridge, MA 02139  
Affiliation: Center for Biological and Computational Learning Massachusetts Institute of Technology  
Abstract: We propose a statistical mechanical framework for the modeling of discrete time series. Maximum likelihood estimation is done via Boltzmann learning in one-dimensional networks with tied weights. We call these networks Boltzmann chains and show that they contain hidden Markov models (HMMs) as a special case. Our framework also motivates new architectures that address particular shortcomings of HMMs. We look at two such architectures: parallel chains that model feature sets with disparate time scales, and looped networks that model long-term dependencies between hidden states. For these networks, we show how to implement the Boltzmann learning rule exactly, in polynomial time, without resort to simulated or mean-field annealing. The necessary computations are done by exact decimation procedures from statistical mechanics.
Abstract-found: 1
Intro-found: 1
Reference: <author> D. H. Ackley, G. E. Hinton, and T. J. Sejnowski. </author> <title> (1985) A Learning Algorithm for Boltzmann Machines. Cog. </title> <journal> Sci. </journal> <volume> 9: </volume> <pages> 147-160. </pages>
Reference-contexts: The EM procedure is an alternating two-step method for maximum likelihood estimation in probability models with hidden and observed variables. For Boltzmann machines in general, neither the E-step nor the M-step can be done exactly; one must estimate the necessary statistics by Monte Carlo simulation <ref> (Ackley et al., 1985) </ref> or mean-field theory (Peterson & Anderson, 1987). In certain special cases (e.g. trees and chains), however, the necessary statistics can be computed to perform an exact E-step (as shown below).
Reference: <author> P. Baldi, Y. Chauvin, T. Hunkapiller, and M. A. McClure. </author> <booktitle> (1992) Proc. </booktitle> <institution> Nat. Acad. Sci. </institution> <address> (USA) 91: </address> <month> 1059-1063. </month> <title> with 4-state hidden units, 6-state visible units, and 100 hidden-visible unit pairs. </title>
Reference-contexts: 1 INTRODUCTION AND SUMMARY Statistical models of discrete time series have a wide range of applications, most notably to problems in speech recognition (Juang & Rabiner, 1991) and molecular biology <ref> (Baldi, Chauvin, Hunkapiller, & McClure, 1992) </ref>. A common problem in these fields is to find a probabilistic model, and a set of model parameters, that account for sequences of observed data. Hidden Markov models (HMMs) have been particularly successful at modeling discrete time series.
Reference: <author> L. Baum. </author> <title> (1972) An Inequality and Associated Maximization Technique in Statistical Estimation of Probabilistic Functions of Markov Processes, </title> <booktitle> Inequalities 3 </booktitle> <pages> 1-8. </pages>
Reference-contexts: A common problem in these fields is to find a probabilistic model, and a set of model parameters, that account for sequences of observed data. Hidden Markov models (HMMs) have been particularly successful at modeling discrete time series. One reason for this is the powerful learning rule <ref> (Baum, 1972) </ref>, a special case of the Expectation-Maximization (EM) procedure for maximum likelihood estimation (Dempster, Laird, & Rubin, 1977). In this work, we develop a statistical mechanical framework for the modeling of discrete time series.
Reference: <author> Byrne, W. </author> <title> (1992) Alternating Minimization and Boltzmann Machine Learning. </title> <journal> IEEE Trans. Neural Networks 3 </journal> <pages> 612-620. </pages>
Reference: <author> A. P. Dempster, N. M. Laird, and D. B. Rubin. </author> <title> (1977) Maximum Likelihood from Incomplete Data via the EM Algorithm. </title> <journal> J. Roy. Statist. Soc. B, </journal> <volume> 39 </volume> <pages> 1-38. </pages>
Reference-contexts: Hidden Markov models (HMMs) have been particularly successful at modeling discrete time series. One reason for this is the powerful learning rule (Baum, 1972), a special case of the Expectation-Maximization (EM) procedure for maximum likelihood estimation <ref> (Dempster, Laird, & Rubin, 1977) </ref>. In this work, we develop a statistical mechanical framework for the modeling of discrete time series. The framework enables us to relate HMMs to a large family of exactly solvable models in statistical mechanics.
Reference: <author> C. Itzykson and J. Drouffe. </author> <title> (1991) Statistical Field Theory, </title> <publisher> Cambridge: Cambridge University Press. </publisher>
Reference: <author> B. H. Juang and L. R. Rabiner. </author> <title> (1991) Hidden Markov Models for Speech Recognition, </title> <type> Technometrics 33: </type> <pages> 251-272. </pages>
Reference-contexts: 1 INTRODUCTION AND SUMMARY Statistical models of discrete time series have a wide range of applications, most notably to problems in speech recognition <ref> (Juang & Rabiner, 1991) </ref> and molecular biology (Baldi, Chauvin, Hunkapiller, & McClure, 1992). A common problem in these fields is to find a probabilistic model, and a set of model parameters, that account for sequences of observed data. <p> Conversely, they can be used to design networks that are computationally tractable. This section looks at two networks designed to address particular shortcomings of HMMs. 4.1 PARALLEL CHAINS AND DISPARATE TIME SCALES An important problem in speech recognition <ref> (Juang et al., 1991) </ref> is how to "combine feature sets with fundamentally different time scales." Spectral parameters, such as the cepstrum and delta-cepstrum, vary on a time scale of 10 msec; on the other hand, prosodic parameters, such as the signal energy and pitch, vary on a time scale of 100 <p> The first is redundancy|in particular, the rather lame solution of oversampling the nonspectral features. The second is overfitting. How might this arise? Suppose we have trained two separate HMMs on sequences of spectral and prosodic features, knowing that the different features "may not warrant a single, unified Markov chain" <ref> (Juang et al., 1991) </ref>. To exploit the correlation between feature sets, we must now couple the two HMMs. A naive solution is to form the Cartesian product of their hidden state spaces and resume training. <p> The second jump in log-likelihood occurred at the onset of Boltzmann learning (see text). (b) Percent gain in log-likelihood versus built-in correlation between feature sets. 4.2 LOOPS AND LONG-TERM DEPENDENCIES Another shortcoming of first-order HMMs is that they cannot exhibit long-term dependencies between the hidden states <ref> (Juang et al., 1991) </ref>. Higher-order and duration-based HMMs have been used in this regard with varying degrees of success. The rules of section 3 suggest another approach|namely, designing tractable networks with limited long-range connectivity.
Reference: <author> D. J. MacKay. </author> <title> (1994) Equivalence of Boltzmann Chains and Hidden Markov Models, </title> <note> submitted to Neural Comp. </note>
Reference-contexts: This example represents the simplest possible Boltzmann "chain", one that is essentially equivalent to a first-order HMM unfolded in time <ref> (MacKay, 1994) </ref>. The transition weights A ii 0 connect adjacent hidden units, while the emission weights B ij connect each hidden unit to its visible counterpart. In addition, boundary weights i model an extra bias on the first hidden unit.
Reference: <author> C. Peterson and J. R. Anderson. </author> <title> (1987) A Mean Field Theory Learning Algorithm for Neural Networks, </title> <booktitle> Complex Systems 1 </booktitle> <pages> 995-1019. </pages>
Reference-contexts: For Boltzmann machines in general, neither the E-step nor the M-step can be done exactly; one must estimate the necessary statistics by Monte Carlo simulation (Ackley et al., 1985) or mean-field theory <ref> (Peterson & Anderson, 1987) </ref>. In certain special cases (e.g. trees and chains), however, the necessary statistics can be computed to perform an exact E-step (as shown below). While the M - step in these Boltzmann machines cannot be done exactly, the weight updates can be approximated by gradient descent.
Reference: <author> L. Saul and M. Jordan. </author> <title> (1994) Learning in Boltzmann Trees. </title> <journal> Neural Comp. </journal> <volume> 6: </volume> <pages> 1174-1184. </pages>
Reference: <author> N. Sourlas. </author> <title> (1989) Spin Glass Models as Error Correcting Codes. </title> <booktitle> Nature 339: </booktitle> <pages> 693-695. </pages>
Reference: <author> P. Stolorz. </author> <title> (1994) Links Between Dynamic Programming and Statistical Physics for Heterogeneous Systems, </title> <type> JPL/Caltech preprint. </type>
Reference: <author> C. Williams and G. E. Hinton. </author> <title> (1990) Mean Field Networks That Learn To Discriminate Temporally Distorted Strings. </title> <booktitle> Proc. Connectionist Models Summer School: </booktitle> <pages> 18-22. </pages>
Reference-contexts: For now, however, let us continue to develop the example of figure 1, making explicit the connection to HMMs. 2.3 LEARNING RULES In the framework of Boltzmann learning <ref> (Williams & Hinton, 1990) </ref>, the data for our problem consist of sequences of states over the visible units; the goal is to find the weights (A ii 0 ; B ij ; i ) that maximize the likelihood of the observed data.
References-found: 13

