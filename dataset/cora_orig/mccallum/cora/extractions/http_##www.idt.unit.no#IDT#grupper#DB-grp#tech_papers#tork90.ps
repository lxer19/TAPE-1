URL: http://www.idt.unit.no/IDT/grupper/DB-grp/tech_papers/tork90.ps
Refering-URL: http://www.idt.unit.no/IDT/grupper/DB-grp/tech_papers/tech_papers.html
Root-URL: 
Email: e-mail: runetor@idt.unit.no  
Title: Two algorithms for the numerical factorization of large symmetric positive definite matrices for a hypercube
Author: Rune Torkildsen 
Date: June 8, 1990  
Address: N-7034 Trondheim, Norway  
Affiliation: Program Systems Group Department of Computer Systems The Norwegian Institute of Technology  
Abstract: This paper present two algorithms for the numerical factorization of large matrices. The matrices are assumed to be symmetrical positive definite which are typical matrices evolving from finite element method problems. The algorithms are designed to run on a hypercube multiprocessor.
Abstract-found: 1
Intro-found: 1
Reference: [Duff86] <author> I.S. Duff, </author> <title> Parallel implementation of multifrontal schemes, </title> <booktitle> Parallel Computing, 3 (1986), </booktitle> <pages> pp. 193-204 </pages>
Reference-contexts: The symbolic factorization is supposed to consist of the following two parts: 1: Symbolic factorization of the processors internal nodes, which equals the symbolic factorization performed by sequential algorithms. One way to carry out this task is to make use of corollary 2 in Duff's article <ref> [Duff86] </ref>: Statement 1: "The structure of any column, k say, of L is the union of the sparsity structure of all the previous columns of L whose first nonzero beneath the diagonal is in row k." 2: To determine the data structure of all border nodes the processor is responsible for.
Reference: [Geor81] <author> J.A. George og J.W.H. Liu, </author> <title> Computer solution of large sparse positive definte systems, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1981 </year>
Reference-contexts: The matrix A will for many boundary-value problems be a symmetric positive definite matrix. This assumption will be utilized when solving the system of linear equations. A symmetric positive definite matrix may be factorized such that A = LL T where L is a lower triangular matrix. In <ref> [Geor81] </ref>, George and Liu discuss four stages in the solution of large spares symmetric systems of equations: 1. Ordering: Find a 'good' symmetric permutation P of the coefficient matrix A which reduces the amount of fill-in which occurs during the factorization process. 2. <p> It is so that some of the well known fill-in reducible ordering algorithms like "nested dissection" and "minimum degree" generates fine 5) elimination trees. These ordering algorithms are described by George and Liu in <ref> [Geor81] </ref>. The example in the figure 7 shows a finite element grid with two different orderings. The one to the left corresponds to the "nested dissection" ordering algorithm, the one to the left to a band-oriented method 6) . <p> This may be verified by a corollary to theorem 5.1.2 i the book <ref> [Geor81] </ref> by George and Liu: Statement 2: "If there exists a path of nodes r between the node j and k, where and , node j will have an influence on node k." Since the border nodes belonging to a subcube always will have higher ordering number than its internal nodes,
Reference: [Geor88] <author> J.A. George, M. Heath, J.W.H. Liu og E. Ng, </author> <title> Sparse Cholesky factorization on a local-memory multiprosessor, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 9 (1988), </volume> <pages> pp. 327-340 </pages>
Reference-contexts: This part is based on the paper <ref> [Geor88] </ref> by George et. al. and is submitted here in order to clarify concepts in later sections. 3.1 The sequential column-Cholesky factorization algorithm The sequential Cholesky factorization algorithm is shown in the figure below. <p> George et. al. illustrates in <ref> [Geor88] </ref> these precedence relations by a precedence graph as shown in the figure below. As seen from the dependencies and the precedence graph the cdiv operations have to be done in a purely sequential manner. <p> To fully utilize the structural parallelism it is necessary to find a good ordering P for A. This ordering should also try to minimize the number of fill-ins. As said by George et.al. in <ref> [Geor88] </ref> these objectives turn out to be mutually complementary. 3.4 The elimination tree and the effect of ordering In order to identify the structural parallelism corresponding to a specific ordering, elimination trees are useful. An elimination tree visualises the structure of L such that the column dependencies can be identified. <p> An elimination tree visualises the structure of L such that the column dependencies can be identified. In <ref> [Geor88] </ref>, the elimination tree corresponding to the structure of L is defined in the following manner. cdiv (j) cmod (j+1,j) cmod (j+2,j) cmod (n,j) ... cmod (j,1) cmod (j,2) cmod (j,j-1) ... <p> The data structure and message protocol is mainly submitted here in order to show how the relative numbering scheme may be utilized. The first algorithm presented is based on an algorithm given by George et. al. in <ref> [Geor88] </ref>. The second algorithm tries to improve on the first one in the way the communication is performed and by splitting the cmod operation into two parts. Both algorithms is designed for a hypercube multiprocessor. <p> The third primary data is going to modify L (4.6),(2.2) . The second and fourth primary data is identified by using the sequence assumption described in the previous section. 5.6 A numerical factorization algorithm The first proposed factorization algorithm is based on an algorithm by George et. al. in <ref> [Geor88] </ref>. This algorithm is adjusted to suit an FEM problem. The algorithm will also take advantage of how the nodes are distributed and the relative ordering scheme. In contrast to the algorithm in [Geor88], this algorithm assumes that the three preprosessing stages are completed by the processors. <p> factorization algorithm The first proposed factorization algorithm is based on an algorithm by George et. al. in <ref> [Geor88] </ref>. This algorithm is adjusted to suit an FEM problem. The algorithm will also take advantage of how the nodes are distributed and the relative ordering scheme. In contrast to the algorithm in [Geor88], this algorithm assumes that the three preprosessing stages are completed by the processors. That is, the factorization algorithm may start without any communication with the host. The algorithm may be described in the following way: (x.y ) (c .d ) Dest. Status Node no.
Reference: [Geor89] <author> J.A. George, J.W.H. Liu og E. Ng, </author> <title> Communication results for parallel sparse Cholesky factorization on a hypercube, </title> <booktitle> Parallel Computing, 10 (1989), </booktitle> <pages> pp. 287-298 </pages>
Reference-contexts: that belongs to the two-dimensional hypercube (00xx) (figure 10) will be distributed among the processors 0-3 in the following manner: 7 7 2.1 2.2 2.3 Node number Processor number Numerical factorization algorithms for a hypercube 12 This distribution method is similar to a method used by George et. al. in <ref> [Geor89] </ref> which yields good results. The method scatter cdiv and cmod operations equally among the processors. 5.2 The numerical integration Every processor calculates and generates the element matrices for its elements.
Reference: [Gilb88] <author> J.R. Gilbert og H. Hafsteinsson, </author> <title> Parallel solution of sparse linear systems, </title> <booktitle> Proceedings of the SWAT-88 conferance, Springer-Verlag lecture notes in computer science, </booktitle> <volume> vol. 318, </volume> <pages> pp. 145-153 </pages>
Reference-contexts: In some parallel versions of the Cholesky algorithm this stage will also compute the elimination tree corresponding to the structure of L for utilizing this information during the factorization phase. A good description of such an algorithm is found in the paper <ref> [Gilb88] </ref> by Gilbert and Hafsteinsson. The proposed factorization algorithms are not dependant on computation of the elimination tree since this information is stored implicit in the way the nodes are distributed and ordered.
Reference: [Liu86] <author> J.W.H. Liu, </author> <title> Computational models and task scheduling for parallel sparse Cholesky factorization, </title> <booktitle> Parallel Computing, 3 (1986), </booktitle> <volume> 327-342 24 Index @[Duff86], 12 @[Geor81], 1, 7, 12 @[Geor88], 5, 6, 11, 15 @[Geor89], 12 @[Gilb88], 12 @[Liu86], </volume> <pages> 5 </pages>
Reference-contexts: Notice that A is overwritten by L in the code. for j:=1 to n do begin for k:=1 to j-1 do for k:=j+1 to n do As described by Liu in <ref> [Liu86] </ref>, a parallel version of this algorithm is well suited for medium- and large-grained multiprocessors.
References-found: 6

