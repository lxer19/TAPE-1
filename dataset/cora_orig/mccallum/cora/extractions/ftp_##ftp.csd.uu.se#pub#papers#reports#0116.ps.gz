URL: ftp://ftp.csd.uu.se/pub/papers/reports/0116.ps.gz
Refering-URL: http://www.csd.uu.se/papers/reports.html
Root-URL: 
Email: e-mail: fthomasl,perm,jbg@csd.uu.se  
Phone: Phone: +481818 25 00 Fax: +461851 19 25  
Title: Taylor's Scheme for Unbound Variables by Taylor: that aliased unbound variables are represented as circular
Author: Thomas Lindgren Per Mildner Johan Bevemyr 
Address: Box 311, S-751 05 Uppsala, Sweden  
Affiliation: Computing Science Department, Uppsala University  
Note: On  A novel scheme for representing unbound variables was proposed  
Abstract: UPMAIL Technical Report No. 116 October 25, 1995 ISSN 1100-0686 Abstract We compare the proposed scheme to that of Warren's abstract machine, and find that Taylor's scheme (a) leads to increased trailing, (b) makes stack allocation more difficult, (c) requires more expensive copying of heap cells at times, and (d) has a more expensive variable binding mechanism. On the positive side, a very strong advantage is that Taylor's scheme entirely dispenses with pointer chain dereferenc-ing. We conclude by enumerating the data flow properties a global an alyzer should find in order to eliminate these difficulties.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Bevemyr, T. Lindgren, </author> <title> A simple and efficient copying garbage collector for Prolog, in PLILP'94, </title> <publisher> LNCS 844, Springer Verlag 1994. </publisher>
Reference-contexts: X); We assume that TrailedStore (X,Y) trails X as needed, then writes Y to that location, and that Next () follows the pointer chain one step. #define TrailedStore (addr,val) - Trail (addr); *addr = val; - #define Trail (addr) " if (MustTrail (addr)) " - tp [0] = addr; tp <ref> [1] </ref> = *addr; tp += 2 - #define Next (x) *(UntagThe (REF,(x))) 3 4 2.1.2 Variable-variable binding When variables X and Y are bound to each other, the following constant-time operation seems natural. <p> Now, there are two cases. If X is bound, then C can simply copy X: C = REF (hp+0); hp <ref> [1] </ref> = X; hp += 3; But this code is invalid when X is unbound in that case, the new occurrence of X would not be part of the variable chain. Instead, we must generate this code when X is unbound: ... TrailedStore (X,REF (hp+1)); hp [1] = REF (X); When <p> = REF (hp+0); hp <ref> [1] </ref> = X; hp += 3; But this code is invalid when X is unbound in that case, the new occurrence of X would not be part of the variable chain. Instead, we must generate this code when X is unbound: ... TrailedStore (X,REF (hp+1)); hp [1] = REF (X); When the mode of X is unknown, we get the following code. if (Unbound (X)) - TrailedStore (X,REF (hp+1)); hp [1] = REF (X); else/* X bound */ - hp [1] = X; This case is similar to when unbound variables are represented with a special `unbound' <p> Instead, we must generate this code when X is unbound: ... TrailedStore (X,REF (hp+1)); hp <ref> [1] </ref> = REF (X); When the mode of X is unknown, we get the following code. if (Unbound (X)) - TrailedStore (X,REF (hp+1)); hp [1] = REF (X); else/* X bound */ - hp [1] = X; This case is similar to when unbound variables are represented with a special `unbound' tag. <p> Instead, we must generate this code when X is unbound: ... TrailedStore (X,REF (hp+1)); hp <ref> [1] </ref> = REF (X); When the mode of X is unknown, we get the following code. if (Unbound (X)) - TrailedStore (X,REF (hp+1)); hp [1] = REF (X); else/* X bound */ - hp [1] = X; This case is similar to when unbound variables are represented with a special `unbound' tag. In the WAM, a simple copy (as for the bound case) is sufficient whatever the mode of X. 2.1.4 Stack allocation Stack allocation is traditionally a tricky subject in the WAM. <p> The total ordering is then given by comparing their addresses. This feature is made less useful when we consider copying collectors, such as the Bevemyr-Lindgren generational top-down collector <ref> [1] </ref>, where variable order is not maintained over collections. In this case, there are some options in the WAM: * Put ordered variables on a stack that is collected using compaction and so retains the desired ordering [1]. * Attach an ordering number to each ordered variable. * When variable X <p> useful when we consider copying collectors, such as the Bevemyr-Lindgren generational top-down collector <ref> [1] </ref>, where variable order is not maintained over collections. In this case, there are some options in the WAM: * Put ordered variables on a stack that is collected using compaction and so retains the desired ordering [1]. * Attach an ordering number to each ordered variable. * When variable X is ordered, create an ordering structure ord (T,Y) on the heap, where T is an ordering number and Y is a fresh unbound variable, and bind X to Y.
Reference: [2] <author> P. Tarau, </author> <title> Low level issues in implementing a high-performance continuation passing binary prolog engine. </title> <editor> In M.-M. Corsini, editor, </editor> <booktitle> Proceedings of JFPL'94. </booktitle>
Reference: [3] <author> A. Taylor, </author> <title> Removal of dereferencing and trailing in Prolog compilation, in ICLP'89, </title> <publisher> MIT Press. </publisher>
Reference-contexts: number of unbound stack variables that appear throughout execution can be substantially reduced. 2.1.5 Avoiding deallocation The problems detailed above disappear if we move to a heap-based implementation, where `stack frames' are allocated on the heap and unbound variables are moved out of dead stack frames by the garbage collector <ref> [3] </ref>. 11 A similar approach is to allocate all stack variables on the heap and ensure that stack references to these variables are handled properly [8]. 2.2 Ordering variables. Applications occasionally demand a global and total ordering of unbound variables using @&lt;/2, ==/2 and other similar primitives.
Reference: [4] <author> A. Taylor, </author> <title> High Performance Prolog Implementation, </title> <type> Ph.D. Thesis, </type> <institution> Basser Dept. of Comp.Sci., University of Sydney, </institution> <year> 1991. </year>
Reference-contexts: Van Roy and Despain [7] found that, on a range of medium-sized benchmarks, 17% of the predicate arguments were recursively dereferenced, and a further 23% were uninitialized variables. Taylor considered a more powerful analysis to remove dereferencing operations <ref> [4] </ref>, which found that only 8-33% of the predicate arguments of a small set of programs required general dereferencing. However, he subsequently abandoned that approach in favor of that examined in this paper.
Reference: [5] <author> H. Touati, A. Despain, </author> <title> An empirical study of the Warren abstract machine, </title> <publisher> IEEE SLP, IEEE Press, </publisher> <year> 1987. </year>
Reference-contexts: 1 Introduction Taylor presented an intriguing representation of unbound logic variables in his thesis <ref> [5] </ref>. The standard WAM scheme [9] represents variables as pointers and unbound variables as self-pointers. Variable binding means dereferenc-ing the pointer chain until an unbound variable appears and performing a trailed assignment (i.e., which is reversible on backtracking).
Reference: [6] <author> P. Van Roy, A. Despain, </author> <title> The benefit of global dataflow analysis for an optimizing Prolog compiler, in NACLP'90, </title> <publisher> MIT Press. </publisher>
Reference-contexts: A second reason may be that module boundaries again introduce conservative assumptions, since nothing is known about the dereferencing chains in the input arguments. The cost of dereferencing operations. Measurements show that most dereferencing chains are short, zero or one step in length <ref> [6] </ref>, which means most dereferencing operations are trivial. In a native code implementation, it is vexing to emit dereferencing loops at many points: it increases compile times, it pollutes the instruction cache with unnecessary instructions and it may reduce the efficiency of low-level routines.
Reference: [7] <author> P. Van Roy, </author> <title> Can Logic Programming Execute as Fast as Imperative Programming, </title> <type> Ph.D. Thesis, </type> <institution> University of California (Berkeley), </institution> <year> 1990. </year>
Reference-contexts: The execution machinery must be ready to handle pointer-chain dereferencing at most points when the value of a variable is sought. 1 Previous work. Some native code compilers attempt to remove pointer dereferencing operations (e.g., Van Roy's Aquarius Prolog compiler <ref> [7] </ref>). The Aquarius Prolog compiler takes a conservative stance: once a dereferencing chain may have appeared in a term, every subterm needs dereferencing. Van Roy and Despain [7] found that, on a range of medium-sized benchmarks, 17% of the predicate arguments were recursively dereferenced, and a further 23% were uninitialized variables. <p> Some native code compilers attempt to remove pointer dereferencing operations (e.g., Van Roy's Aquarius Prolog compiler <ref> [7] </ref>). The Aquarius Prolog compiler takes a conservative stance: once a dereferencing chain may have appeared in a term, every subterm needs dereferencing. Van Roy and Despain [7] found that, on a range of medium-sized benchmarks, 17% of the predicate arguments were recursively dereferenced, and a further 23% were uninitialized variables.
Reference: [8] <author> D.H.D Warren, </author> <title> An Abstract Prolog Instruction Set, </title> <type> SRI technical note 309, </type> <year> 1983. </year> <month> 14 </month>
Reference-contexts: We note that this role can be subsumed by returning such (uninitialized) arguments in registers instead <ref> [8] </ref>. <p> a heap-based implementation, where `stack frames' are allocated on the heap and unbound variables are moved out of dead stack frames by the garbage collector [3]. 11 A similar approach is to allocate all stack variables on the heap and ensure that stack references to these variables are handled properly <ref> [8] </ref>. 2.2 Ordering variables. Applications occasionally demand a global and total ordering of unbound variables using @&lt;/2, ==/2 and other similar primitives. The conventional implementation of the WAM uses a compacting collector, which ensures that the relative positions of variables remains the same throughout execution.
References-found: 8

