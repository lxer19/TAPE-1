URL: ftp://ftp.cs.umass.edu/pub/osl/papers/lsc94.ps.Z
Refering-URL: http://spa-www.cs.umass.edu/bibliography.html
Root-URL: 
Title: Measuring the Cost of Storage Management  
Author: David Tarditi Amer Diwan 
Address: 5000 Forbes Avenue Pittsburgh, PA 15213  Amherst, MA 01003  
Affiliation: School of Computer Science Carnegie Mellon University  Department of Computer Science University of Massachusetts  
Abstract: We study the cost of storage management for garbage-collected programs compiled with the Standard ML of New Jersey compiler. We show that the cost of storage management is not the same as the time spent garbage collecting. For many of the programs, the time spent garbage collecting is less than the time spent doing other storage management tasks. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Andrew W. Appel. </author> <title> Simple generational garbage collection and fast allocation. </title> <journal> Software Practice and Experience, </journal> <volume> 19(2) </volume> <pages> 171-184, </pages> <month> February </month> <year> 1989. </year> <pages> Page 11 </pages>
Reference-contexts: The SML/NJ system uses heap-only allocation: all allocation is done on the heap. In particular, all activation records are allocated on the heap rather than on a call stack. The heap is managed automatically using generational copying garbage collection <ref> [22, 1, 2] </ref>. In copying garbage collection [17, 7], an area of memory is reclaimed by copying the live (non-garbage) data to another area of memory. All data in the garbage-collected area becomes garbage and the area can be reused. <p> In copying garbage collection [17, 7], an area of memory is reclaimed by copying the live (non-garbage) data to another area of memory. All data in the garbage-collected area becomes garbage and the area can be reused. The SML/NJ system uses a simple variant of generational copying garbage collection <ref> [1] </ref>. Memory is divided into an old generation and an allocation area. New objects are created in the allocation area. When the allocation area becomes full, the live data in the allocation area is copied to the old generation in a minor collection. <p> However, they give data for only Knuth-Bendix and YACC in their paper. 3.5 Garbage collection sizing parameters We used the default strategy for sizing the allocation area and the old generation <ref> [1] </ref>. The heap is sized as r times the size of the old generation after the old generation is collected, where r is the desired ratio of heap size to live data. We used the default system value (r=5).
Reference: [2] <author> Andrew W. Appel. </author> <title> A Runtime System. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 3(4) </volume> <pages> 343-380, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: The SML/NJ system uses heap-only allocation: all allocation is done on the heap. In particular, all activation records are allocated on the heap rather than on a call stack. The heap is managed automatically using generational copying garbage collection <ref> [22, 1, 2] </ref>. In copying garbage collection [17, 7], an area of memory is reclaimed by copying the live (non-garbage) data to another area of memory. All data in the garbage-collected area becomes garbage and the area can be reused.
Reference: [3] <author> Andrew W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction We study the cost of storage management for garbage-collected programs compiled with the Standard ML of New Jersey compiler <ref> [3] </ref>. There are two motivations for conducting this study. First, we want to better understand the cost of storage management. Since costs due to storage management occur throughout the entire execution of a program, it is not adequate to measure only the time spent garbage collecting. <p> The SML/NJ compiler <ref> [3] </ref> is a state-of-the-art compiler for SML. We used version 0.91. The compiler concentrates on making allocation cheap and function calls fast. 2.3 Storage management in the SML/NJ sys tem Storage management in the SML/NJ system has many components. One component is garbage collection. <p> Generational garbage collection is efficient because most allocated objects die young (about 99% <ref> [3, p. 206] </ref>) and few objects are copied from the allocation area. Before an object can be allocated, the mutator must check whether there is sufficient space on the heap to allocate the object. If not, a garbage collection is needed. <p> Table 4 describes the benchmark programs 5 . Knuth-Bendix, Lexgen, Life, Simple, VLIW, and YACC are identical to the programs measured by Appel <ref> [3] </ref> 6 . <p> source code size in lines, its maximum heap size 4 Partial-word writes are treated differently, but since there are so few in our programs, we can ignore them in our discussion without loss of accuracy. 5 Available from the authors. 6 The description of these programs has been taken from <ref> [3] </ref>. Page 4 in kilobytes, its compiled code size in kilobytes, 7 and its running time in seconds on a DECstation 5000/200. The source code size excludes comments and blank lines. The maximum heap size is the largest size of the heap during the execution of the program.
Reference: [4] <author> Andrew W. Appel, James S. Mattson, and David Tarditi. </author> <title> A lexical analyzer generator for Standard ML. Distributed with Standard ML of New Jersey, </title> <year> 1989. </year>
Reference-contexts: The input is the sample session from Section 7.5 of [8]. Knuth-Bendix An implementation of the Knuth-Bendix completion algorithm, implemented by Gerard Huet, processing some axioms of geometry. Lexgen A lexical-analyzer generator, implemented by James S. Mattson and David R. Tarditi <ref> [4] </ref>, processing the lexical description of Standard ML. Life The game of Life, written by Chris Reade [25], running 50 generations of a glider gun. It is implemented using lists. PIA A perspective inversion algorithm [32], deciding the location of an object in a perspective video image.
Reference: [5] <author> Thomas Ball and James R. Larus. </author> <title> Optimally profiling and tracing programs. </title> <booktitle> In Proceedings of the 19th Annual ACM Symposium on Principles of Programming Languages. ACM, </booktitle> <month> January </month> <year> 1992. </year>
Reference-contexts: an assignment x := t, we say that x is the target of the assignment and t is the source of the assignment. code the table gives relative offsets and the address of the target must also be computed. 3.2 Trace generation We extended QPT (Quick Program Profiler and Tracer) <ref> [5, 21, 20] </ref> to produce memory traces for SML/NJ programs. QPT rewrites an executable program to produce compressed trace information; QPT also produces a corresponding regeneration program that expands the compressed trace into a full address trace.
Reference: [6] <author> David R. Chase. </author> <title> Safety considerations for storage allocation optimizations. </title> <booktitle> Proceedings of the SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <volume> 23(7) </volume> <pages> 1-10, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: The first three entries are the cost of garbage collection. The remaining rows are the storage managementt costs in the mutator. The one instruction-level cost of storage management that we do not measure is the effect of storage management on program optimization <ref> [6] </ref>. Diwan et al. [13] have presented techniques that allow extensive optimization even using copying collection with unambiguous roots. However, we do not measure this cost. Storage management also affects the memory-system cost incurred during mutation. We were unable to measure this effect directly.
Reference: [7] <author> C.J. </author> <title> Cheney. A nonrecursive list compacting algorithm. </title> <journal> Communications of the ACM, </journal> <volume> 13(11) </volume> <pages> 677-678, </pages> <month> November </month> <year> 1970. </year>
Reference-contexts: The SML/NJ system uses heap-only allocation: all allocation is done on the heap. In particular, all activation records are allocated on the heap rather than on a call stack. The heap is managed automatically using generational copying garbage collection [22, 1, 2]. In copying garbage collection <ref> [17, 7] </ref>, an area of memory is reclaimed by copying the live (non-garbage) data to another area of memory. All data in the garbage-collected area becomes garbage and the area can be reused. The SML/NJ system uses a simple variant of generational copying garbage collection [1]. <p> When the size of the old generation becomes sufficiently large, the entire heap is collected in a major collection. Live objects are copied using a Cheney scan <ref> [7] </ref>, which copies objects in a breadth-first order.
Reference: [8] <author> Rance Cleaveland, Joachim Parrow, and Bernhard Steffen. </author> <title> The Concurrency Workbench: A semantics-based tool for the verification of concurrent systems. </title> <journal> Transactions on Programming Languages and Systems, </journal> <volume> 15(1) </volume> <pages> 36-72, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: The cost of adding elements to the store list was negligible for most programs, so it is omitted from the graph. Page 5 Program Description CW The Concurrency Workbench <ref> [8] </ref> is a tool for analyzing networks of finite state processes expressed in Milner's Calculus of Communicating Systems. The input is the sample session from Section 7.5 of [8]. Knuth-Bendix An implementation of the Knuth-Bendix completion algorithm, implemented by Gerard Huet, processing some axioms of geometry. <p> Page 5 Program Description CW The Concurrency Workbench <ref> [8] </ref> is a tool for analyzing networks of finite state processes expressed in Milner's Calculus of Communicating Systems. The input is the sample session from Section 7.5 of [8]. Knuth-Bendix An implementation of the Knuth-Bendix completion algorithm, implemented by Gerard Huet, processing some axioms of geometry. Lexgen A lexical-analyzer generator, implemented by James S. Mattson and David R. Tarditi [4], processing the lexical description of Standard ML.
Reference: [9] <author> W. P. Crowley, C. P. Hendrickson, and T. E. Rudy. </author> <title> The SIMPLE code. </title> <type> Technical Report UCID 17715, </type> <institution> Lawrence Livermore Laboratory, Livermore, </institution> <address> CA, </address> <month> February </month> <year> 1978. </year>
Reference-contexts: It is implemented using lists. PIA A perspective inversion algorithm [32], deciding the location of an object in a perspective video image. Simple A spherical fluid-dynamics program, developed as a realistic FORTRAN benchmark <ref> [9] </ref>, translated into ID [16], and then translated into Standard ML by Lal George. VLIW A Very-Long-Instruction-Word instruction scheduler written by John Danskin. YACC An LALR (1) parser generator, implemented by David R. Tarditi [30], processing the grammar of Standard ML.
Reference: [10] <author> Cypress Semiconductor, Ross Technology Subsidiary. </author> <title> SPARC RISC User's Guide, </title> <note> second edition, </note> <month> February </month> <year> 1990. </year>
Reference-contexts: For the DECStation 5000/200 memory-system organization, which is favorable to heap allocation, increasing the allocation area size is unlikely to change the memory-system cost. Halving the cache size for the DECStation 5000/200 organization affects performance little [14, 15]. Some other memory-system organizations, such as the SPARCStationII <ref> [10] </ref>, are more sensitive to cache size. Increasing the allocation area size can increase the memory-system cost greatly.
Reference: [11] <author> David Detlefs, Al Dosser, and Benjamin Zorn. </author> <title> Memory allocation costs in large C and C++ programs. </title> <type> Technical Report CU-CS-665-93, </type> <institution> University of Colorado, </institution> <year> 1993. </year>
Reference-contexts: He finds that tag insertion and removal costs about 4.5% with the best software scheme. There have been several studies of the cost of storage management in languages with explicitly managed heap storage and stack allocation of procedure activation records. Detlefs <ref> [11] </ref> measures time spent in allocation and deallocation routines, but does not measure the cost of managing the stack.
Reference: [12] <author> Digital Equipment Corporation. </author> <title> DS5000/200 KN02 System Module Functional Specification. </title>
Reference-contexts: Second, we want to identify bottlenecks in the storage-management strategy of the SML/NJ compiler and suggest potential improvements. We measure the cost of storage management for eight programs on a DECstation 5000/200 <ref> [12] </ref>. The measurements include most of the instruction-level and memory-system costs of storage management. <p> We made the measurements using trace-driven simulation. This allowed us to count the instructions spent performing various tasks, such as tagging integers and implementing the write barrier. The memory simulator modelled the entire memory system of the DECStation 5000/200 <ref> [12] </ref>, which is favorable to programs which heap allocate intensively. A less favorable memory-system organization would increase the cost of storage management by increasing the cost of allocation [14, 15]. The remainder of the paper is organized as follows.
Reference: [13] <author> Amer Diwan, J. Eliot B. Moss, and Richard L. Hudson. </author> <title> Compiler support for garbage collection in a statically typed language. </title> <booktitle> In Proceedings of the SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 273-282, </pages> <address> San Francisco, California, </address> <month> June </month> <year> 1992. </year> <title> SIGPLAN, </title> <publisher> ACM Press. </publisher>
Reference-contexts: The first three entries are the cost of garbage collection. The remaining rows are the storage managementt costs in the mutator. The one instruction-level cost of storage management that we do not measure is the effect of storage management on program optimization [6]. Diwan et al. <ref> [13] </ref> have presented techniques that allow extensive optimization even using copying collection with unambiguous roots. However, we do not measure this cost. Storage management also affects the memory-system cost incurred during mutation. We were unable to measure this effect directly.
Reference: [14] <author> Amer Diwan, David Tarditi, and Eliot Moss. </author> <title> Memory subsystem performance of programs with intensive heap allocation. </title> <note> Submitted for publication, </note> <month> November </month> <year> 1993. </year>
Reference-contexts: The memory simulator modelled the entire memory system of the DECStation 5000/200 [12], which is favorable to programs which heap allocate intensively. A less favorable memory-system organization would increase the cost of storage management by increasing the cost of allocation <ref> [14, 15] </ref>. The remainder of the paper is organized as follows. Section 2 introduces terminology and describes the storage-management strategy used by the SML/NJ compiler. Section 3 describes the measurement techniques and benchmark programs. Section 4 presents measurements for eight SML/NJ programs. Section 5 reviews related work. <p> We extended QPT in two ways. First, we modified QPT and the SML/NJ system to produce traces for SML/NJ programs. Second, we added an event tracing facility to QPT. The changes to QPT and the SML/NJ system are described elsewhere <ref> [14, 15] </ref>. One important change we made to the SML/NJ system was to place code outside the heap so that it was not moved by garbage collection. In the original system, code was placed in the heap and it was moved by garbage collection. <p> The extensions to Tycho, described in <ref> [14, 15] </ref>, allow us to measure costs due to the entire memory system, not just the cache. Table 2 summarizes the memory system of the DECstation 5000/200. The DECstation 5000/200 has a split instruction and data cache. <p> The DECstation also has a write buffer to avoid stalling the CPU on a write; the CPU needs to stall on a write only when the write-buffer fills up. This memory system is favorable to allocation-intensive programs <ref> [14, 15] </ref>. 3.4 Benchmark Programs The material in this section originally appeared elsewhere [15] and is repeated here to keep this paper self-contained. Table 4 describes the benchmark programs 5 . Knuth-Bendix, Lexgen, Life, Simple, VLIW, and YACC are identical to the programs measured by Appel [3] 6 . <p> For the DECStation 5000/200 memory-system organization, which is favorable to heap allocation, increasing the allocation area size is unlikely to change the memory-system cost. Halving the cache size for the DECStation 5000/200 organization affects performance little <ref> [14, 15] </ref>. Some other memory-system organizations, such as the SPARCStationII [10], are more sensitive to cache size. Increasing the allocation area size can increase the memory-system cost greatly. <p> If there were a penalty for write misses 10 , the programs would run 24% to 72% slower than they do now <ref> [14, 15] </ref>. In other words, with a penalty for cache write misses, most of the cost of storage management would be for initializing newly-allocated objects.
Reference: [15] <author> Amer Diwan, David Tarditi, and Eliot Moss. </author> <title> Memory subsystem performance of programs with copying garbage collection. </title> <booktitle> In Proceedings of the 21st Annual ACM Symposium on Principles of Programming languages, </booktitle> <pages> pages 1-14, </pages> <address> Portland, Oregon, </address> <month> January </month> <year> 1994. </year> <note> ACM. </note>
Reference-contexts: The memory simulator modelled the entire memory system of the DECStation 5000/200 [12], which is favorable to programs which heap allocate intensively. A less favorable memory-system organization would increase the cost of storage management by increasing the cost of allocation <ref> [14, 15] </ref>. The remainder of the paper is organized as follows. Section 2 introduces terminology and describes the storage-management strategy used by the SML/NJ compiler. Section 3 describes the measurement techniques and benchmark programs. Section 4 presents measurements for eight SML/NJ programs. Section 5 reviews related work. <p> The objects tracked by the write barrier must be regarded as live when only the 1 An extended basic block is a block of code with only forward jumps. 2 This figure originally appeared elsewhere <ref> [15] </ref>. Page 2 allocation area is collected; otherwise collection of the allo-cation area could create dangling pointers. The write barrier is implemented using a store list. <p> We extended QPT in two ways. First, we modified QPT and the SML/NJ system to produce traces for SML/NJ programs. Second, we added an event tracing facility to QPT. The changes to QPT and the SML/NJ system are described elsewhere <ref> [14, 15] </ref>. One important change we made to the SML/NJ system was to place code outside the heap so that it was not moved by garbage collection. In the original system, code was placed in the heap and it was moved by garbage collection. <p> The extensions to Tycho, described in <ref> [14, 15] </ref>, allow us to measure costs due to the entire memory system, not just the cache. Table 2 summarizes the memory system of the DECstation 5000/200. The DECstation 5000/200 has a split instruction and data cache. <p> The DECstation also has a write buffer to avoid stalling the CPU on a write; the CPU needs to stall on a write only when the write-buffer fills up. This memory system is favorable to allocation-intensive programs <ref> [14, 15] </ref>. 3.4 Benchmark Programs The material in this section originally appeared elsewhere [15] and is repeated here to keep this paper self-contained. Table 4 describes the benchmark programs 5 . Knuth-Bendix, Lexgen, Life, Simple, VLIW, and YACC are identical to the programs measured by Appel [3] 6 . <p> This memory system is favorable to allocation-intensive programs [14, 15]. 3.4 Benchmark Programs The material in this section originally appeared elsewhere <ref> [15] </ref> and is repeated here to keep this paper self-contained. Table 4 describes the benchmark programs 5 . Knuth-Bendix, Lexgen, Life, Simple, VLIW, and YACC are identical to the programs measured by Appel [3] 6 . <p> For the DECStation 5000/200 memory-system organization, which is favorable to heap allocation, increasing the allocation area size is unlikely to change the memory-system cost. Halving the cache size for the DECStation 5000/200 organization affects performance little <ref> [14, 15] </ref>. Some other memory-system organizations, such as the SPARCStationII [10], are more sensitive to cache size. Increasing the allocation area size can increase the memory-system cost greatly. <p> If there were a penalty for write misses 10 , the programs would run 24% to 72% slower than they do now <ref> [14, 15] </ref>. In other words, with a penalty for cache write misses, most of the cost of storage management would be for initializing newly-allocated objects. <p> If data does not fit in the cache, increasing the size of the data leads to proportionately more cache misses. The effect of cache size on SML/NJ programs is explored thoroughly elsewhere <ref> [15] </ref>. There were no dramatic boundary conditions for SML/NJ programs on the DECStation 5000/200. Just as header words increase the size of data, storage management instructions increase the size of a program. This may cause additional instruction-cache misses. <p> Zorn [34] compares the cost of two simulated garbage-collection algorithms. In contrast, we measure an actual implementation. He measures the memory-system cost using the cache miss ratio, which is an inaccurate indicator of performance because it does not separate the cost of read and write misses <ref> [15] </ref>. Wilson et al.[33] and Peng and Sohi [24] also measure the memory-system cost of garbage collection using the cache miss ratio. They do not measure the instruction-level cost of garbage collection or costs incurred during mutation.
Reference: [16] <author> K. Ekanadham and Arvind. </author> <title> SIMPLE: An exercise in future scientific programming. Technical Report Computation Structures Group Memo 273, </title> <publisher> MIT, </publisher> <address> Cambridge, MA, </address> <month> July </month> <year> 1987. </year> <note> Simultaneously published as IBM/T. J. </note> <institution> Watson Research Center Research Report 12686, Yorktown Heights, NY. </institution>
Reference-contexts: It is implemented using lists. PIA A perspective inversion algorithm [32], deciding the location of an object in a perspective video image. Simple A spherical fluid-dynamics program, developed as a realistic FORTRAN benchmark [9], translated into ID <ref> [16] </ref>, and then translated into Standard ML by Lal George. VLIW A Very-Long-Instruction-Word instruction scheduler written by John Danskin. YACC An LALR (1) parser generator, implemented by David R. Tarditi [30], processing the grammar of Standard ML.
Reference: [17] <author> Robert R. Fenichel and Jerome C. Yochelson. </author> <title> A LISP garbage-collector for virtual-memory computer systems. </title> <journal> Communications of the ACM, </journal> <volume> 12(11) </volume> <pages> 611-612, </pages> <month> November </month> <year> 1969. </year>
Reference-contexts: The SML/NJ system uses heap-only allocation: all allocation is done on the heap. In particular, all activation records are allocated on the heap rather than on a call stack. The heap is managed automatically using generational copying garbage collection [22, 1, 2]. In copying garbage collection <ref> [17, 7] </ref>, an area of memory is reclaimed by copying the live (non-garbage) data to another area of memory. All data in the garbage-collected area becomes garbage and the area can be reused. The SML/NJ system uses a simple variant of generational copying garbage collection [1].
Reference: [18] <author> Dirk Grunwald, Benjamin Zorn, and Robert Henderson. </author> <title> Improving the cache locality of memory allocation. </title> <booktitle> In Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 177-186, </pages> <address> Albuquerque, New Mexico, </address> <month> June </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: There have been several studies of the cost of storage management in languages with explicitly managed heap storage and stack allocation of procedure activation records. Detlefs [11] measures time spent in allocation and deallocation routines, but does not measure the cost of managing the stack. Grunwald et al. <ref> [18] </ref> finds that the implementation of explicit heap management can affect the performance of allocation intensive C programs significantly. 6 Conclusion We have studied the cost of storage management for programs compiled with the SML/NJ compiler.
Reference: [19] <author> M.D. Hill and A.J. Smith. </author> <title> Evaluating associativity in CPU caches. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(12) </volume> <pages> 1612-1630, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Table 2: Summary of the DECstation 5000/200 memory system The tracing mechanism is non-intrusive: the traces produced by QPT correspond to addresses in the original programs rather than those in the instrumented programs. 3.3 Memory system simulation We simulated the DECstation 5000/200 memory system using an extended version of Tycho <ref> [19] </ref>, a cache simulator. The extensions to Tycho, described in [14, 15], allow us to measure costs due to the entire memory system, not just the cache. Table 2 summarizes the memory system of the DECstation 5000/200. The DECstation 5000/200 has a split instruction and data cache.
Reference: [20] <author> James R. Larus. </author> <title> Abstract Execution: A technique for efficiently tracing programs. </title> <journal> Software Practice and Experience, </journal> 20(12) 1241-1258, December 1990. 
Reference-contexts: an assignment x := t, we say that x is the target of the assignment and t is the source of the assignment. code the table gives relative offsets and the address of the target must also be computed. 3.2 Trace generation We extended QPT (Quick Program Profiler and Tracer) <ref> [5, 21, 20] </ref> to produce memory traces for SML/NJ programs. QPT rewrites an executable program to produce compressed trace information; QPT also produces a corresponding regeneration program that expands the compressed trace into a full address trace.
Reference: [21] <author> James R. Larus and Thomas Ball. </author> <title> Rewriting executable files to measure program behavior. </title> <type> Technical Report Wis 1083, </type> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: an assignment x := t, we say that x is the target of the assignment and t is the source of the assignment. code the table gives relative offsets and the address of the target must also be computed. 3.2 Trace generation We extended QPT (Quick Program Profiler and Tracer) <ref> [5, 21, 20] </ref> to produce memory traces for SML/NJ programs. QPT rewrites an executable program to produce compressed trace information; QPT also produces a corresponding regeneration program that expands the compressed trace into a full address trace.
Reference: [22] <author> H. Lieberman and C. Hewitt. </author> <title> A real-time garbage collector based on the lifetimes of objects. </title> <journal> Communications of the ACM, </journal> <volume> 26(6) </volume> <pages> 419-429, </pages> <year> 1983. </year>
Reference-contexts: The SML/NJ system uses heap-only allocation: all allocation is done on the heap. In particular, all activation records are allocated on the heap rather than on a call stack. The heap is managed automatically using generational copying garbage collection <ref> [22, 1, 2] </ref>. In copying garbage collection [17, 7], an area of memory is reclaimed by copying the live (non-garbage) data to another area of memory. All data in the garbage-collected area becomes garbage and the area can be reused.
Reference: [23] <author> Robin Milner, Mads Tofte, and Robert Harper. </author> <title> The Definition of Standard ML. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: The number of instructions executed to perform a task is the instruction-level cost of that task. The time spent by the processor waiting for memory while performing a task is the memory-system cost of that task. 2.2 Standard ML and the SML/NJ system Standard ML (SML) <ref> [23] </ref> is a call-by-value, lexically scoped language with higher-order functions, garbage collection, polymorphic static typing, provable safety properties, a sophisticated module system, and a dynamically-scoped exception mechanism. The SML/NJ compiler [3] is a state-of-the-art compiler for SML. We used version 0.91.
Reference: [24] <author> Chih-Jui Peng and Gurindar S. Sohi. </author> <title> Cache memory design considerations to support languages with dynamic heap allocation. </title> <type> Technical Report 860, </type> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <month> July </month> <year> 1989. </year>
Reference-contexts: In contrast, we measure an actual implementation. He measures the memory-system cost using the cache miss ratio, which is an inaccurate indicator of performance because it does not separate the cost of read and write misses [15]. Wilson et al.[33] and Peng and Sohi <ref> [24] </ref> also measure the memory-system cost of garbage collection using the cache miss ratio. They do not measure the instruction-level cost of garbage collection or costs incurred during mutation.
Reference: [25] <author> Chris Reade. </author> <title> Elements of Functional Programming. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: Knuth-Bendix An implementation of the Knuth-Bendix completion algorithm, implemented by Gerard Huet, processing some axioms of geometry. Lexgen A lexical-analyzer generator, implemented by James S. Mattson and David R. Tarditi [4], processing the lexical description of Standard ML. Life The game of Life, written by Chris Reade <ref> [25] </ref>, running 50 generations of a glider gun. It is implemented using lists. PIA A perspective inversion algorithm [32], deciding the location of an object in a perspective video image.
Reference: [26] <author> Mark B. Reinhold. </author> <title> Cache Performance of Garbage-Collected Programming Languages. </title> <type> PhD thesis, </type> <institution> Laboratory for Computer Science, MIT, </institution> <month> September </month> <year> 1993. </year> <pages> Page 12 </pages>
Reference-contexts: Wilson et al.[33] and Peng and Sohi [24] also measure the memory-system cost of garbage collection using the cache miss ratio. They do not measure the instruction-level cost of garbage collection or costs incurred during mutation. Reinhold <ref> [26] </ref> measures the cost of garbage collection for a Scheme system, including the change in memory-system performance of entire programs, but does not measure costs incurred during mutation. Steenkiste [28] studies ways to reduce the cost of tagging in Lisp. He also studies instructions used for stack allocation.
Reference: [27] <author> John H. Reppy. </author> <title> Asynchronous Signals in Standard ML. </title> <type> Technical Report 90-1144, </type> <institution> Department of Computer Science, Cornell University, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: Checks are placed on many extended basic blocks that do not allocate, since these checks are also used to implement asynchronous signals <ref> [27] </ref>. Allocation is done in-line, except for the allocation of arrays and strings. Since the entire allocation area is always reclaimed, objects can be allocated sequentially from the allocation area in only two instructions. <p> This is despite the fact that the check and allocating an object both take two instructions on the MIPS, and that a check is sometimes for multiple allocations. We speculate that this is because the SML/NJ compiler overloads checks to implement asynchronous signals <ref> [27] </ref>.
Reference: [28] <author> Peter Steenkiste. </author> <title> LISP on a Reduced-Instruction-Set Processor: Characterization and Optimization. </title> <type> PhD thesis, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <address> Stanford,CA 94305, </address> <month> March </month> <year> 1987. </year>
Reference-contexts: They do not measure the instruction-level cost of garbage collection or costs incurred during mutation. Reinhold [26] measures the cost of garbage collection for a Scheme system, including the change in memory-system performance of entire programs, but does not measure costs incurred during mutation. Steenkiste <ref> [28] </ref> studies ways to reduce the cost of tagging in Lisp. He also studies instructions used for stack allocation. He is primarily concerned with hardware support to improve tag checking required for dynamic typing. He finds that tag insertion and removal costs about 4.5% with the best software scheme.
Reference: [29] <author> Darko Stefanovic and Eliot Moss. </author> <title> Characterisation of object behavior in Standard ML of New Jersey. </title> <booktitle> In Proceedings of the 1994 ACM Conference on Lisp and Functional Programming, </booktitle> <year> 1994. </year>
Reference-contexts: The percent of total allocation in the other column for PIA and Simple is large because those programs are floating point intensive. Stefanovic and Moss <ref> [29] </ref> find that the allocation of callee-save continuation closures on the heap has a profound impact on the young-object dynamics of ML programs. In the programs they measured 9 , most objects are short-lived. They attribute the high mortality rate to the allocation of callee-save continuation closures on the heap.
Reference: [30] <author> David Tarditi and Andrew W. Appel. ML-YACC, </author> <title> version 2.0. Distributed with Standard ML of New Jersey, </title> <month> April </month> <year> 1990. </year>
Reference-contexts: Simple A spherical fluid-dynamics program, developed as a realistic FORTRAN benchmark [9], translated into ID [16], and then translated into Standard ML by Lal George. VLIW A Very-Long-Instruction-Word instruction scheduler written by John Danskin. YACC An LALR (1) parser generator, implemented by David R. Tarditi <ref> [30] </ref>, processing the grammar of Standard ML.
Reference: [31] <author> David Ungar. </author> <title> The design and evaluation of a high performance Smalltalk system. </title> <publisher> ACM Distinguished Dissertation. MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1987. </year>
Reference-contexts: Ungar <ref> [31] </ref> measures the time spent garbage collecting and the cost of integer tagging in a Smalltalk system, but does not measure other costs incurred during mutation. Zorn [34] compares the cost of two simulated garbage-collection algorithms. In contrast, we measure an actual implementation.
Reference: [32] <author> Kevin G. Waugh, Patrick McAndrew, and Greg Michaelson. </author> <title> Parallel implementations from function prototypes: a case study. </title> <institution> Technical Report Computer Science 90/4, Heriot-Watt University, Edinburgh, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: Lexgen A lexical-analyzer generator, implemented by James S. Mattson and David R. Tarditi [4], processing the lexical description of Standard ML. Life The game of Life, written by Chris Reade [25], running 50 generations of a glider gun. It is implemented using lists. PIA A perspective inversion algorithm <ref> [32] </ref>, deciding the location of an object in a perspective video image. Simple A spherical fluid-dynamics program, developed as a realistic FORTRAN benchmark [9], translated into ID [16], and then translated into Standard ML by Lal George. VLIW A Very-Long-Instruction-Word instruction scheduler written by John Danskin.
Reference: [33] <author> Paul R. Wilson, Michael S. Lam, and Thomas G. Moher. </author> <title> Caching considerations for generational garbage collection: a case for large and set-associative caches. </title> <type> Technical Report EECS-90-5, </type> <institution> University of Illinios at Chicago, </institution> <month> December </month> <year> 1990. </year>
Reference: [34] <author> Benjamin G. Zorn. </author> <title> Comparative Performance evaluation of garbage collection algorithms. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <address> CA 94720, </address> <month> December </month> <year> 1989. </year> <pages> Page 13 </pages>
Reference-contexts: Ungar [31] measures the time spent garbage collecting and the cost of integer tagging in a Smalltalk system, but does not measure other costs incurred during mutation. Zorn <ref> [34] </ref> compares the cost of two simulated garbage-collection algorithms. In contrast, we measure an actual implementation. He measures the memory-system cost using the cache miss ratio, which is an inaccurate indicator of performance because it does not separate the cost of read and write misses [15].
References-found: 34

