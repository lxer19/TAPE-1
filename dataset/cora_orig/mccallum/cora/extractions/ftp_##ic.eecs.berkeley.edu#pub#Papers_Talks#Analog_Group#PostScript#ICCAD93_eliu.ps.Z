URL: ftp://ic.eecs.berkeley.edu/pub/Papers_Talks/Analog_Group/PostScript/ICCAD93_eliu.ps.Z
Refering-URL: http://www-cad.eecs.berkeley.edu:80/~charbon/publications/analog-group-publications.html
Root-URL: http://www.cs.berkeley.edu
Title: Nyquist Data Converter Testing and Yield Analysis using Behavioral Simulation  
Author: Edward W. Y. Liu Alberto L. Sangiovanni-Vincentelli 
Address: Berkeley, CA 94720  
Affiliation: Department of EECS, University of California,  
Abstract: This paper presents a strategy for testing all DC performance of Nyquist data converters including offset error, full scale gain error, integral nonlinearity, and differential nonlinearity. In contrast to previous testing strategies based on linear models that require accurate measurements of circuit performance, our strategy uses a simpler measurement to verify that a circuit performance parameter falls within certain detection thresholds in the presence of measurement noise. Using the proposed strategy, we can evaluate tradeoffs between test set size, test coverage, detection thresholds, measurement noise, chip performance, and estimated yield. Our results support the obvious that smaller measurement noise, stricter detection thresholds, and lower chip performance would require smaller test set and reduce test time. Stricter detection thresholds, on the other hand, would decrease estimated yield. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Liu, A. Sangiovanni-Vincentelli, G. Gielen, and P. Gray. </author> <title> A behavioral representation for nyquist rate A/D converters. </title> <booktitle> In Proc. IEEE ICCAD, </booktitle> <pages> pages 386-389, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: From the information contained in the behavioral model, engineers can evaluate the tradeoffs between test set size, test coverage, detection thresholds, measurement noise, chip performance, and estimated yield. To achieve this goal, we propose a new converter testing strategy for data converters from a behavioral model <ref> [1] </ref>. We present previous work in Section 2, a new testing strategy in Section 3, a yield analysis algorithm in Section 4, and experimental results in Section 5. 2 Previous Work In [2, 3] a linear model for data converters along with a test selection strategy was presented. <p> Our strategy focuses on testing all DC performance of Nyquist data converters including offset error, full scale gain error, integral nonlinearity, and differential nonlinearity. To achieve this goal, we present in the next section a behavioral model <ref> [1] </ref> for data converters that is useful for testing DC performance. 3.1 Behavioral model for data converters 3.1.1 Model derivation A memoryless Nyquist A/D operating at a certain environment such as fixed sampling frequency and temperature can be described by its transfer curve, which plots the output code on the range
Reference: [2] <author> T. Souders and G. Stenbakken. </author> <title> Modeling and test point selection for data converter testing. </title> <booktitle> IEEE International Test Conference, </booktitle> <year> 1985. </year>
Reference-contexts: We present previous work in Section 2, a new testing strategy in Section 3, a yield analysis algorithm in Section 4, and experimental results in Section 5. 2 Previous Work In <ref> [2, 3] </ref> a linear model for data converters along with a test selection strategy was presented.
Reference: [3] <author> T. Souders and G. Stenbakken. </author> <title> Cutting the high cost of testing. </title> <journal> IEEE Spectrum, </journal> <pages> pages 48-51, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: We present previous work in Section 2, a new testing strategy in Section 3, a yield analysis algorithm in Section 4, and experimental results in Section 5. 2 Previous Work In <ref> [2, 3] </ref> a linear model for data converters along with a test selection strategy was presented. <p> The columns of U t are called the error signatures <ref> [3] </ref> and form a set of orthonormal vectors spanning the error space. <p> For storage and computational efficiency d is expressed as the following equation, d = U d c d + d (26) where c d ~ normal (0; cd ) is a small, zero mean multivariate normal distribution with r d statistically independent variates. The model proposed in <ref> [3] </ref> is deterministic and hence does not represent statistical effects. We represent electronic noise as well as process variation effects. Moreover, our model has distributions for INL and DNL. <p> We will show that these are essential to developing a testing strategy that tradeoffs between test set size, test coverage, detection thresholds, measurement noise, chip performance, and estimated yield. 3.2 Measurement and Detection Threshold As mentioned in Section 2, previous testing strategies <ref> [3, 7] </ref> have difficulty in accurate measurements of circuit performance such as A/D converter transition points in the presence of measurement noise. To circumvent the problem, we propose a simpler measurement that is robust against noise. <p> Also, the size drops below the rank of 38 for INL larger than 3.2 LSB, where the rank is the number of INL signatures. This occurs because some INL signatures with small magnitudes do not contribute significantly to large INL errors. In contrast, previous testing strategy <ref> [3] </ref> uses the same number of tests as the rank because such strategy does not take into consideration the magnitudes of the signatures. In Figure 4, we plotted the DEC ALPHA CPU times for test generation against INL.
Reference: [4] <author> M. Box and N. Draper. </author> <title> Factorial designs, the jx 0 xj criterion, and some related matters. </title> <journal> Technometrics, </journal> <volume> 13, </volume> <year> 1971. </year>
Reference-contexts: The objective is to find the optimal subset of the full set of 2 N 1 test points that minimizes the prediction variance of m. This problem falls in the category of Optimal Design of Experiments. It has been shown under the D-Optimality criterion <ref> [4] </ref> that in the limit where the number of test points is large, an optimal selection is S 0 v , an m by m matrix formed by selected rows of S v .
Reference: [5] <author> G. Stenbakken and T. Souders. </author> <title> Test-point selection and testability measures via QR factorization of linear models. </title> <journal> IEEE Transactions on Instrumentation and Measurement, </journal> <month> June </month> <year> 1987. </year>
Reference-contexts: Under this criterion, the prediction variance of v is minimized by maximizing jS 0T v S 0 where j j is the determinant. While the D-Optimality criterion gives the optimal solution, the computational complexity prevents its use for large models. Stenbakken <ref> [5] </ref> introduced an algorithm for a near optimal solution based on QR factorization with pivoting. <p> As a result, the optimum test selection problem is likely intractable. Thus, we propose a heuristic solution. First, we rank the tests according to the algorithm proposed in <ref> [5] </ref> based on QR factorization with pivoting. * (a) Choose the row of U s with the largest norm, * (b) Orthogonalize all remaining rows to it using a modified Gram-Schmidt orthogonalization procedure, * (c) Choose the row of largest L 2 norm of those remaining, * (d) Repeat (b) and
Reference: [6] <author> W. Press, B. Flannery, S. Teukolsky, and W. Vetterling. </author> <title> Numerical Recipes in C. </title> <booktitle> The Art of Scientific Computing. </booktitle> <publisher> Cam-bridge University Press, </publisher> <year> 1989. </year>
Reference-contexts: For example, an A/D produces a discrete output code from a continuous input. Under the previous testing strategy, we measure the transitions between adjacent output codes using a bisection search algorithm <ref> [6] </ref>. In this algorithm, we guess initial lower bound, t l (i), and upper bound, t u (i), for the transition t (i). <p> Due to linear dependence, we use linear programming <ref> [6] </ref> to check the bounds on untested INL, s (i), in (42). We formulate the problem as follows.
Reference: [7] <author> G. Hemink, B. Meijer, and H. Kerkhoff. </author> <title> Testability analysis of analog systems. </title> <journal> IEEE Trans. on CAD, </journal> <month> June </month> <year> 1990. </year>
Reference-contexts: Moreover, measurement noise poses a significant problem because it corrupts the estimated parameters. To reduce measurement noise problems, Hemink <ref> [7] </ref> presented algorithms for testability analysis and optimal test selection in the presence of measurement noise. On the other hand, Souders [8] proposed adding more test points to reduce noise effects by creating an overdeter-mined system of equations to be solved by least square techniques. <p> We will show that these are essential to developing a testing strategy that tradeoffs between test set size, test coverage, detection thresholds, measurement noise, chip performance, and estimated yield. 3.2 Measurement and Detection Threshold As mentioned in Section 2, previous testing strategies <ref> [3, 7] </ref> have difficulty in accurate measurements of circuit performance such as A/D converter transition points in the presence of measurement noise. To circumvent the problem, we propose a simpler measurement that is robust against noise.
Reference: [8] <author> T. Souders and G. Stenbakken. </author> <title> A comprehensive approach for modeling and testing analog and mixed-signal devices. </title> <booktitle> IEEE International Test Conference, </booktitle> <year> 1990. </year>
Reference-contexts: Moreover, measurement noise poses a significant problem because it corrupts the estimated parameters. To reduce measurement noise problems, Hemink [7] presented algorithms for testability analysis and optimal test selection in the presence of measurement noise. On the other hand, Souders <ref> [8] </ref> proposed adding more test points to reduce noise effects by creating an overdeter-mined system of equations to be solved by least square techniques.
Reference: [9] <author> E. Liu and A. Sangiovanni-Vincentelli. </author> <title> Behavioral simulation for noise in mixed-mode sampled-data systems. </title> <booktitle> In Proc. IEEE ICCAD, </booktitle> <pages> pages 322-326, </pages> <month> Nov </month> <year> 1992. </year>
Reference-contexts: In our model, noise and process variation effects are separated. The distribution t captures process variation effects, while the joint density function f () captures noise effects. The function f () is computed using either direct techniques <ref> [9] </ref> or Monte Carlo techniques. The process variation effects can be derived by making assumption: Assumption 3.1 Process variations are the cumulative effects of many integrated circuit fabrication steps. Thus, according to the Central Limit Theorem in probability theory, the distribution of the process variations, v, is approximately multivariate normal.
Reference: [10] <author> Analog Devices. </author> <title> Data converter reference manual volume II. </title> <address> Norwood, MA 02062-9106, </address> <year> 1992. </year>
Reference-contexts: Intuitively, Definition 3.5 means that we transform t using constants a and b such that the two end-points are ideal. In this case, we have adopted the end-point method for linear error compensation <ref> [10] </ref>. The motivation behind the transformation is to compensate for the offset and gain errors before calculation of nonlinearity. In many applications, offset and gain errors are irrelevant as they do not contribute to distortion.
Reference: [11] <author> W. Lam, A. Saldanha, R. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> Delay fault coverage and performance tradeoffs. </title> <booktitle> Proc. Design Automation Conference, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Typically, we choose k = 5 for a 10 statistical limit. If c s is unbounded, then the statistical information provided by the distribution of c s is lost. In a different context of delay fault testing <ref> [11] </ref>, a similar problem formulation has been applied to check bounds on delays of digital circuits. In both formulations, the problems seem to be analytically intractable.
Reference: [12] <author> H. Chang, A. Sangiovanni-Vincentelli, F. Balarin, E. Char-bon, U. Choudhury, G. Jusuf, E. Liu, E. Malavasi, R. Neff, and P. Gray. </author> <title> A top-down, constraint-driven design methodology for analog integrated circuits. </title> <booktitle> In Proc. IEEE Custom Integrated Circuits Conference, </booktitle> <pages> pages 841-846, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Because Monte Carlo integration is used, our estimate Y improves with the number of trials, k. The variance of our estimate is inversely proportional to k 2 . 5 Experimental Results We have applied the new strategy to the automatic test generation for a 10 bit current-switched, interpolative D/A <ref> [12] </ref> shown in expected process variation parameters. Behavioral simulation of the D/A and automatic test generation have been integrated into a single software package to facilitate design-for-testability. <p> The average DEC ALPHA CPU times for each data point is 582 seconds. Next, we apply the proposed testing strategy to the actual testing of twelve 10-bit D/A converter chips of the same design synthesized by a top-down design methodology <ref> [12] </ref>. Figure 8 shows the measured INL for all 1024 input codes for two sample silicon chips.
Reference: [13] <author> E. Liu, H. Chang, and A. Sangiovanni-Vincentelli. </author> <title> Analog system verification in the presence of parasitics using behavioral simulation. </title> <booktitle> In Proc. Design Automation Conference, </booktitle> <month> June </month> <year> 1993. </year>
References-found: 13

