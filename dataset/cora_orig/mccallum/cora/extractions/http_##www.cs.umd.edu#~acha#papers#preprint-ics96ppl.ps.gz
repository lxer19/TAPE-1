URL: http://www.cs.umd.edu/~acha/papers/preprint-ics96ppl.ps.gz
Refering-URL: http://www.cs.umd.edu/~acha/papers/ics96ppl.html
Root-URL: 
Email: acha@cs.umd.edu  
Title: Eliminating Redundant Barrier Synchronizations in Rule-based Programs  
Author: Anurag Acharya 
Address: College Park 20742  
Affiliation: Department of Computer Science University of Maryland,  
Abstract: A rule-based program consists of a set of if-then rules and a tuple-space. The rules are the code for the program and the tuple-space contains the data being processed by the program. Previous efforts to parallelize rule-based programs have achieved limited speedups. The main reason for these disappointing results is a high frequency of barrier synchronizations. Since little work is done between successive barrier synchronizations, the number of processors that can be effectively utilized is bounded. Even though required by language semantics, a large fraction of the barrier synchronizations are not necessary for most programs. This paper proposes a pair of simple language extensions that allow an implementation to efficiently detect and eliminate redundant barrier synchronizations. Simulation results based on a real implementation show that for a set of five benchmarks, this scheme is able to eliminate between 95.6% and 99.9% of the barrier synchronizations. This results in a multiplicative speedup of between 2.2 and 52.3 fold over and above the speedup achieved by a parallelizing compiler. For the programs studied, simulations indicate that speedups up to 115 fold relative to an optimized sequential version are possible. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Acharya. </author> <title> Scalability in Production System Programs. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> November </month> <year> 1994. </year> <note> Also available as Tech Rep CMU-CS-94-211. Available on the web at http://www.cs.umd.edu/users/acha/thesis.html. </note>
Reference-contexts: Not surprisingly, parallelization efforts based on compile-time analysis have had limited success. Several publications have claimed small reductions in the number of msa cycles [12, 17, 22, 27]. As the execution time of individual msa cycles varies greatly <ref> [1, 3, 6, 7, 26] </ref>, it is not clear if these 3 Strictly speaking, this definition holds only for instantiations of rules with no negated conditions. It has been simplified for illustration and can easily be extended to full generality. reductions translate to significant reductions in end-to-end execution time. <p> It incorporates several new compiler and runtime algorithms, including canoni 4 cal conditions, constraint propagation, type inference, hashed equality tests and two-level heaps <ref> [1] </ref>. On a Decstation 5000/200 with 64 MB, pplc achieves between 1.7 and 90 times better performance, on a set of six benchmarks, than existing implementations of OPS5 [1]. 4 On the same platform and for the same test programs, pplc requires between 2 and 4 times less space. <p> incorporates several new compiler and runtime algorithms, including canoni 4 cal conditions, constraint propagation, type inference, hashed equality tests and two-level heaps <ref> [1] </ref>. On a Decstation 5000/200 with 64 MB, pplc achieves between 1.7 and 90 times better performance, on a set of six benchmarks, than existing implementations of OPS5 [1]. 4 On the same platform and for the same test programs, pplc requires between 2 and 4 times less space. On parallel machines, pplc provides automatic paral-lelization of match and select phases. <p> The benchmark versions are between 1.9 and 18.5 times faster than the original versions. All benchmark programs are long-running (the largest trace being over 50 billion instructions) and perform a large number of barrier synchronizations. Table 1 characteristics of the benchmarks. For more details, see <ref> [1] </ref>. Circuit simulator (circuit): This program simulates a gate-level circuit with a constant-delay model. Execution of circuit cycles between two phases the first simulates the gates and the second propagates the values. <p> An alternative rule-based computational model which allows individual conditions to match arbitrarily large collections of tuples and, as a side effect eliminates this inefficiency, has been proposed in <ref> [1] </ref>. 6 Conclusions The results presented in this paper show that a very large fraction of the barrier synchronizations in parallel rule-based programs are redundant and can be eliminated providing significant multiplicative speedups.
Reference: [2] <author> A. Acharya and D. Kalp. </author> <note> Release notes for CParaOPS5 5.3 and ParaOPS5 4.4. This is distributed with the CParaOPS5 release at ftp://ftp.isi.edu/soar/CParaOPS/, </note> <year> 1990. </year>
Reference-contexts: On parallel machines, pplc provides automatic paral-lelization of match and select phases. Unlike existing par-allelizing implementations <ref> [2, 7, 18, 26] </ref>, pplc is fully par-allelized and overlaps all operations between two barrier synchronizations. For matching, it uses the parallel Rete algorithm described in [6].
Reference: [3] <author> A. Acharya, M. Tambe, and A. Gupta. </author> <title> Implementations of production systems on message passing computers. </title> <journal> IEEE Transactions on Parallel and Distributed Computing, </journal> <volume> 3(4) </volume> <pages> 477-87, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Rule-based programs are computationally intensive. Several research efforts have investigated the use of parallelism to speed up rule-based programs <ref> [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31] </ref>. These investigations indicated that the amount of parallelism available in rule-based programs is small. <p> Not surprisingly, parallelization efforts based on compile-time analysis have had limited success. Several publications have claimed small reductions in the number of msa cycles [12, 17, 22, 27]. As the execution time of individual msa cycles varies greatly <ref> [1, 3, 6, 7, 26] </ref>, it is not clear if these 3 Strictly speaking, this definition holds only for instantiations of rules with no negated conditions. It has been simplified for illustration and can easily be extended to full generality. reductions translate to significant reductions in end-to-end execution time.
Reference: [4] <author> L. Brownston, R. Farrell, E. Kant, and N. Martin. </author> <title> Programming Expert Systems in OPS5: An Introduction to Rule-based Programming. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mas-sachusetts, </address> <year> 1985. </year>
Reference-contexts: These extensions have been incorporated in an efficient, state-of-the-art shared memory implementation of the well-known OPS5 rule language <ref> [4] </ref>.
Reference: [5] <author> P. L. Butler, J. D. Allen, and D. W. Bouldin. </author> <title> Parallel architecture for OPS5. </title> <booktitle> In Proceedings of the Fifteenth International Symposium on Computer Architecture, </booktitle> <pages> pages 452-7, </pages> <year> 1988. </year> <title> Program circuit life waltz hotel spam Average task size (instrs) 92.2 162.0 440.5 23858.3 47820.1 Table 4: Average task size </title>
Reference-contexts: Rule-based programs are computationally intensive. Several research efforts have investigated the use of parallelism to speed up rule-based programs <ref> [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31] </ref>. These investigations indicated that the amount of parallelism available in rule-based programs is small.
Reference: [6] <author> A. Gupta. </author> <title> Parallelism in Production Systems. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Carnegie Mellon University, </institution> <month> March </month> <year> 1986. </year>
Reference-contexts: Rule-based programs are computationally intensive. Several research efforts have investigated the use of parallelism to speed up rule-based programs <ref> [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31] </ref>. These investigations indicated that the amount of parallelism available in rule-based programs is small. <p> Several research efforts have investigated the use of parallelism to speed up rule-based programs [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31]. These investigations indicated that the amount of parallelism available in rule-based programs is small. Based on an analysis of six programs, Gupta <ref> [6] </ref> concluded that there is an empirical bound of between 20 and 30 fold on the parallelism available in rule-based programs. He further concluded that communication and scheduling overheads limit the achievable speedup to under 20 fold. Results of other investigations have borne out this conclusion. <p> Not surprisingly, parallelization efforts based on compile-time analysis have had limited success. Several publications have claimed small reductions in the number of msa cycles [12, 17, 22, 27]. As the execution time of individual msa cycles varies greatly <ref> [1, 3, 6, 7, 26] </ref>, it is not clear if these 3 Strictly speaking, this definition holds only for instantiations of rules with no negated conditions. It has been simplified for illustration and can easily be extended to full generality. reductions translate to significant reductions in end-to-end execution time. <p> On parallel machines, pplc provides automatic paral-lelization of match and select phases. Unlike existing par-allelizing implementations [2, 7, 18, 26], pplc is fully par-allelized and overlaps all operations between two barrier synchronizations. For matching, it uses the parallel Rete algorithm described in <ref> [6] </ref>.
Reference: [7] <author> A. Gupta, M. Tambe, D. Kalp, C. Forgy, and A. Newell. </author> <title> Parallel implementation of OPS5 on the Encore multiprocessor: Results and analysis. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 17(2) </volume> <pages> 95-124, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: Rule-based programs are computationally intensive. Several research efforts have investigated the use of parallelism to speed up rule-based programs <ref> [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31] </ref>. These investigations indicated that the amount of parallelism available in rule-based programs is small. <p> The primary cause for the limited speedups is the uniformly high frequency of barrier synchronizations in parallel execution of rule-based programs. Investigations studying parallel implementations of rule languages report that a large fraction of the barrier synchronizations occur after 25,000-125,000 instructions (250 tasks of between 100 and 500 instructions) <ref> [7, 26] </ref>. Since little work is done between successive barrier synchronizations, the number of processors that can be effectively utilized is bounded. Barrier synchronizations are necessary in rule-based programs to ensure that all changes to the tuple-space are completed before trying to decide what to do next. <p> Not surprisingly, parallelization efforts based on compile-time analysis have had limited success. Several publications have claimed small reductions in the number of msa cycles [12, 17, 22, 27]. As the execution time of individual msa cycles varies greatly <ref> [1, 3, 6, 7, 26] </ref>, it is not clear if these 3 Strictly speaking, this definition holds only for instantiations of rules with no negated conditions. It has been simplified for illustration and can easily be extended to full generality. reductions translate to significant reductions in end-to-end execution time. <p> On parallel machines, pplc provides automatic paral-lelization of match and select phases. Unlike existing par-allelizing implementations <ref> [2, 7, 18, 26] </ref>, pplc is fully par-allelized and overlaps all operations between two barrier synchronizations. For matching, it uses the parallel Rete algorithm described in [6]. <p> The first occurs usually if there is a large variance in the number of conditions per rule. This leads to a period at the end of a match stage with few tasks to process. This has been referred to as the long chain effect <ref> [7, 26] </ref>. The second occurs when the first condition in a rule matches a single tuple and the second condition matches a large number of tuples. The tasks to match the second condition are generated sequentially and only a small number of tasks are available at any given time.
Reference: [8] <author> E. N. Hanson and J. Widom. </author> <title> An overview of production rules in database systems. </title> <journal> Knowledge Engineering Review, </journal> <volume> 8(2) </volume> <pages> 121-43, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: For example, programs that need to react to changes in their environment, programs that maintain a large library of cases and determine the processing needed for each input by matching its features with one or more of the cases, programs that monitor databases for inconsistencies or other alarm patterns <ref> [8, 15, 24, 29] </ref>. Rule-based programs are computationally intensive. Several research efforts have investigated the use of parallelism to speed up rule-based programs [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31]. These investigations indicated that the amount of parallelism available in rule-based programs is small.
Reference: [9] <author> W. Harvey, D. Kalp, M. Tambe, D. McKeown, and A. Newell. </author> <title> Measuring the effectiveness of task-level parallelism for high-level vision. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13(4) </volume> <pages> 395-411, </pages> <year> 1991. </year>
Reference-contexts: Rule-based programs are computationally intensive. Several research efforts have investigated the use of parallelism to speed up rule-based programs <ref> [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31] </ref>. These investigations indicated that the amount of parallelism available in rule-based programs is small.
Reference: [10] <author> B. K. Hillyer and D. E. Shaw. </author> <title> Execution of OPS5 production systems on a massively parallel machine. </title> <journal> Journal of Parallel and Distributed Processing, </journal> <volume> 3 </volume> <pages> 236-268, </pages> <year> 1986. </year>
Reference-contexts: Rule-based programs are computationally intensive. Several research efforts have investigated the use of parallelism to speed up rule-based programs <ref> [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31] </ref>. These investigations indicated that the amount of parallelism available in rule-based programs is small.
Reference: [11] <author> T. Ishida. </author> <title> Parallel rule firing in production systems. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 3(1) </volume> <pages> 11-7, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: Since there is no limit on the depth of the lookahead that might needed, such analyses could be prohibitively expensive even for small conflict sets. Run-time analyses have been proposed in <ref> [11] </ref> and [21]. 3.1 Specifying information about the tuple-space An obvious way to specify information about tuple-space contents would be via assertions which would identify the sets embedded in the flat tuple-space, specify their cardi-nality, their relationship with other sets and so forth.
Reference: [12] <author> T. Ishida and S. Stolfo. </author> <title> Towards the parallel execution of rules in production system programs. </title> <booktitle> In Proceedings of the International Conference on Parallel Programming, </booktitle> <pages> pages 568-74, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: Rule-based programs are computationally intensive. Several research efforts have investigated the use of parallelism to speed up rule-based programs <ref> [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31] </ref>. These investigations indicated that the amount of parallelism available in rule-based programs is small. <p> In the absence of run-time information, there is no way for it to do so. Not surprisingly, parallelization efforts based on compile-time analysis have had limited success. Several publications have claimed small reductions in the number of msa cycles <ref> [12, 17, 22, 27] </ref>. As the execution time of individual msa cycles varies greatly [1, 3, 6, 7, 26], it is not clear if these 3 Strictly speaking, this definition holds only for instantiations of rules with no negated conditions.
Reference: [13] <author> M. A. Kelly and R. A. Seviora. </author> <title> Performance of OPS5 matching on CUPID. </title> <journal> Microprocessing and Microprogramming, </journal> <volume> 27 </volume> <pages> 397-404, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: Rule-based programs are computationally intensive. Several research efforts have investigated the use of parallelism to speed up rule-based programs <ref> [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31] </ref>. These investigations indicated that the amount of parallelism available in rule-based programs is small.
Reference: [14] <author> C. Koelbel, D. Loveman, R. Schreiber, G. Steele, Jr., and M. Zosel. </author> <title> The High Performance Fortran Handbook. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference: [15] <author> J. McDermott. </author> <title> R1: A rule-based configurer of computer systems. </title> <journal> Artificial Intelligence, </journal> <volume> 19(2) </volume> <pages> 39-88, </pages> <year> 1982. </year>
Reference-contexts: For example, programs that need to react to changes in their environment, programs that maintain a large library of cases and determine the processing needed for each input by matching its features with one or more of the cases, programs that monitor databases for inconsistencies or other alarm patterns <ref> [8, 15, 24, 29] </ref>. Rule-based programs are computationally intensive. Several research efforts have investigated the use of parallelism to speed up rule-based programs [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31]. These investigations indicated that the amount of parallelism available in rule-based programs is small.
Reference: [16] <author> D. McKeown, W. Harvey, and J. McDermott. </author> <title> Rule based interpretation of aerial imagery. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 7(5) </volume> <pages> 570-85, </pages> <year> 1985. </year>
Reference-contexts: They limit the amount of work that can be done between successive branch points. Rule-based programs that process large datasets often proceed in phases and use dynamic determination of control-flow only at phase boundaries and then only to select the next phase. Examples of such programs include SPAM <ref> [16] </ref> which interprets aerial images and Alexsys [23] which processes large volume mortgage transactions. In each phase, a small subset of rules are repeatedly applied to a large volume of data. All barrier synchronizations within a phase are redundant. <p> The version used as a benchmark is 8.4 times faster than the original (on a Decsta-tion 5000/200). For these experiments, the hotel is assumed to have 1000 rooms with 66% occupancy. Interpretation of aerial images (spam): This program interprets aerial images of airports <ref> [16] </ref>. The input to spam is a list of image regions, their positions and properties and the output is a model of the airport which can then be compared with known models to identify the airport.
Reference: [17] <author> D. P. Miranker, C.-M. Kuo, and J. C. Browne. </author> <title> Parallelizing transforms for a concurrent rule execution language. </title> <type> Technical Report TR-89-30, </type> <institution> Department of Computer Science, University of Texas at Austin, </institution> <month> October </month> <year> 1989. </year>
Reference-contexts: In the absence of run-time information, there is no way for it to do so. Not surprisingly, parallelization efforts based on compile-time analysis have had limited success. Several publications have claimed small reductions in the number of msa cycles <ref> [12, 17, 22, 27] </ref>. As the execution time of individual msa cycles varies greatly [1, 3, 6, 7, 26], it is not clear if these 3 Strictly speaking, this definition holds only for instantiations of rules with no negated conditions.
Reference: [18] <author> D. P. Miranker and B. Lofaso. </author> <title> The organization and performance of a TREAT-based production system compiler. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 3(1) </volume> <pages> 3-10, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: On parallel machines, pplc provides automatic paral-lelization of match and select phases. Unlike existing par-allelizing implementations <ref> [2, 7, 18, 26] </ref>, pplc is fully par-allelized and overlaps all operations between two barrier synchronizations. For matching, it uses the parallel Rete algorithm described in [6].
Reference: [19] <author> D. I. Moldovan. RUBIC:: </author> <title> A multiprocessor for rule-based systems. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 19(4) </volume> <pages> 699-706, </pages> <month> July/August </month> <year> 1989. </year>
Reference-contexts: Rule-based programs are computationally intensive. Several research efforts have investigated the use of parallelism to speed up rule-based programs <ref> [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31] </ref>. These investigations indicated that the amount of parallelism available in rule-based programs is small.
Reference: [20] <author> D. E. Neiman. </author> <title> Control issues in parallel rule-firing production systems. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 310-6, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Rule-based programs are computationally intensive. Several research efforts have investigated the use of parallelism to speed up rule-based programs <ref> [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31] </ref>. These investigations indicated that the amount of parallelism available in rule-based programs is small.
Reference: [21] <author> A. Oshisanwo and P. Dasiewicz. </author> <title> A parallel model and architecture for production systems. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages 147-53, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: Since there is no limit on the depth of the lookahead that might needed, such analyses could be prohibitively expensive even for small conflict sets. Run-time analyses have been proposed in [11] and <ref> [21] </ref>. 3.1 Specifying information about the tuple-space An obvious way to specify information about tuple-space contents would be via assertions which would identify the sets embedded in the flat tuple-space, specify their cardi-nality, their relationship with other sets and so forth.
Reference: [22] <author> J. G. Schmolze and S. Goel. </author> <title> A parallel asynchronous distributed production system. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 65-71, </pages> <year> 1990. </year>
Reference-contexts: In the absence of run-time information, there is no way for it to do so. Not surprisingly, parallelization efforts based on compile-time analysis have had limited success. Several publications have claimed small reductions in the number of msa cycles <ref> [12, 17, 22, 27] </ref>. As the execution time of individual msa cycles varies greatly [1, 3, 6, 7, 26], it is not clear if these 3 Strictly speaking, this definition holds only for instantiations of rules with no negated conditions.
Reference: [23] <author> S. Stolfo, P. Chan, L. Woodbury, J. Glazier, and D. Ohsie. </author> <title> The ALEXSYS mortgage pool allocation system. </title> <booktitle> In Proceedings of the First International Conference on Artificial Intelligence on Wall Street, </booktitle> <pages> pages 79-84, </pages> <month> Oct </month> <year> 1991. </year>
Reference-contexts: Rule-based programs that process large datasets often proceed in phases and use dynamic determination of control-flow only at phase boundaries and then only to select the next phase. Examples of such programs include SPAM [16] which interprets aerial images and Alexsys <ref> [23] </ref> which processes large volume mortgage transactions. In each phase, a small subset of rules are repeatedly applied to a large volume of data. All barrier synchronizations within a phase are redundant.
Reference: [24] <author> M. Stonebraker. </author> <title> Integration of rule systems and database systems. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 4(5) </volume> <pages> 415-23, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: For example, programs that need to react to changes in their environment, programs that maintain a large library of cases and determine the processing needed for each input by matching its features with one or more of the cases, programs that monitor databases for inconsistencies or other alarm patterns <ref> [8, 15, 24, 29] </ref>. Rule-based programs are computationally intensive. Several research efforts have investigated the use of parallelism to speed up rule-based programs [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31]. These investigations indicated that the amount of parallelism available in rule-based programs is small.
Reference: [25] <author> M. Tambe. </author> <type> Personal communication, </type> <year> 1988. </year>
Reference-contexts: The effect of using uniprocessor traces for parallel execution is expected to be limited. Previous research indicates that the difference in execution time due to a change in the processing order is under 10% <ref> [25] </ref>. This simulator allows the task processing order to be changed. Experiments indicated that the difference in execution time is under 5%. The effect of uniform memory access assumption is hard to quantify, particularly for long-running programs like the ones used in these experiments.
Reference: [26] <author> M. Tambe, D. Kalp, A. Gupta, C. Forgy, B. Milnes, and A. Newell. Soar/PSM-E: </author> <title> Investigating match parallelism in a learning production system. </title> <booktitle> In Proceedings of the ACM/SIGPLAN Symposium on Parallel Programming: Experience with Applications, Languages and Systems, </booktitle> <pages> pages 146-60, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: The primary cause for the limited speedups is the uniformly high frequency of barrier synchronizations in parallel execution of rule-based programs. Investigations studying parallel implementations of rule languages report that a large fraction of the barrier synchronizations occur after 25,000-125,000 instructions (250 tasks of between 100 and 500 instructions) <ref> [7, 26] </ref>. Since little work is done between successive barrier synchronizations, the number of processors that can be effectively utilized is bounded. Barrier synchronizations are necessary in rule-based programs to ensure that all changes to the tuple-space are completed before trying to decide what to do next. <p> Not surprisingly, parallelization efforts based on compile-time analysis have had limited success. Several publications have claimed small reductions in the number of msa cycles [12, 17, 22, 27]. As the execution time of individual msa cycles varies greatly <ref> [1, 3, 6, 7, 26] </ref>, it is not clear if these 3 Strictly speaking, this definition holds only for instantiations of rules with no negated conditions. It has been simplified for illustration and can easily be extended to full generality. reductions translate to significant reductions in end-to-end execution time. <p> On parallel machines, pplc provides automatic paral-lelization of match and select phases. Unlike existing par-allelizing implementations <ref> [2, 7, 18, 26] </ref>, pplc is fully par-allelized and overlaps all operations between two barrier synchronizations. For matching, it uses the parallel Rete algorithm described in [6]. <p> The first occurs usually if there is a large variance in the number of conditions per rule. This leads to a period at the end of a match stage with few tasks to process. This has been referred to as the long chain effect <ref> [7, 26] </ref>. The second occurs when the first condition in a rule matches a single tuple and the second condition matches a large number of tuples. The tasks to match the second condition are generated sequentially and only a small number of tasks are available at any given time.
Reference: [27] <author> M. F. M. Tenorio and D. E. Moldovan. </author> <title> Mapping production systems into multiprocessors. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages 56-62, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: In the absence of run-time information, there is no way for it to do so. Not surprisingly, parallelization efforts based on compile-time analysis have had limited success. Several publications have claimed small reductions in the number of msa cycles <ref> [12, 17, 22, 27] </ref>. As the execution time of individual msa cycles varies greatly [1, 3, 6, 7, 26], it is not clear if these 3 Strictly speaking, this definition holds only for instantiations of rules with no negated conditions.
Reference: [28] <author> D. Waltz. </author> <title> Generating semantic descriptions from drawings of scenes with shadows. </title> <type> Technical Report AI-TR-271, </type> <institution> Project MAC, Massachusetts Institute of Technology, </institution> <year> 1972. </year> <note> (Reprinted in P. </note> <editor> Winston (Ed.) </editor> <booktitle> 1975. The psychology of computer vision. </booktitle> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <pages> 19-92). </pages>
Reference-contexts: For these experiments, life was run for 200 steps on a 2400 cell matrix with an initial state that leads to oscillations. Waltz labeling (waltz): This program implements the Waltz labeling algorithm for interpreting line drawings <ref> [28] </ref>. The input consists of vertices and lines between them, the output is a labeling for the vertices and lines which uniquely determines the orientation of the planes in the drawing. Execution of waltz consists of a sequence of constraint propagation phases.
Reference: [29] <author> D. Waterman and F. Hayes-Roth. </author> <title> Pattern-directed Inference Systems. </title> <publisher> Academic Press, </publisher> <year> 1978. </year>
Reference-contexts: For example, programs that need to react to changes in their environment, programs that maintain a large library of cases and determine the processing needed for each input by matching its features with one or more of the cases, programs that monitor databases for inconsistencies or other alarm patterns <ref> [8, 15, 24, 29] </ref>. Rule-based programs are computationally intensive. Several research efforts have investigated the use of parallelism to speed up rule-based programs [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31]. These investigations indicated that the amount of parallelism available in rule-based programs is small.
Reference: [30] <author> M. Wolfe. </author> <title> High Performance Compilers for Parallel Computing. </title> <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference-contexts: An instantiation is said to read a tuple if it contains the tuple. 3 An instantiation is said to write a tuple if firing the instantiation causes the tuple to be deleted or modified. A read-write dependency (or a true dependency <ref> [30] </ref>) occurs between two instantiations if one of them writes a tuple read by the other and a write-write dependency (or an output dependency [30]) occurs between two instantiations if both of them write the same tuple. <p> A read-write dependency (or a true dependency <ref> [30] </ref>) occurs between two instantiations if one of them writes a tuple read by the other and a write-write dependency (or an output dependency [30]) occurs between two instantiations if both of them write the same tuple. A pair of instantiations are said to interfere if there is a dependency of some sort between them.
Reference: [31] <author> S.-Y. Wu and J. C. Browne. </author> <title> Explicit parallel structuring for rule-based programming. </title> <booktitle> In Proceedings of the Seventh International Parallel Processing Symposium, </booktitle> <pages> pages 479-88, </pages> <month> April </month> <year> 1993. </year> <month> 8 </month>
Reference-contexts: Rule-based programs are computationally intensive. Several research efforts have investigated the use of parallelism to speed up rule-based programs <ref> [3, 5, 6, 7, 9, 10, 12, 13, 19, 20, 31] </ref>. These investigations indicated that the amount of parallelism available in rule-based programs is small.
References-found: 31

