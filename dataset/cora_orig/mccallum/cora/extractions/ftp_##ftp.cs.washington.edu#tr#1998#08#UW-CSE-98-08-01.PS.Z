URL: ftp://ftp.cs.washington.edu/tr/1998/08/UW-CSE-98-08-01.PS.Z
Refering-URL: http://www.cs.washington.edu/research/tr/tr-by-date.html
Root-URL: http://www.cs.washington.edu
Title: SPINE: An Operating System for Intelligent Network Adapters  
Author: Marc E. Fiuczynski Brian N. Bershad Richard P. Martin David E. Culler 
Address: Seattle, WA  Berkeley, CA  
Affiliation: Computer Science and Engineering University of Washington  Electrical Engineering and Computer Science University of California at Berkeley  
Abstract: The emergence of fast, cheap embedded processors presents the opportunity for processing to occur on the network adapter. We are investigating how a system design incorporating such an intelligent network adapter can be used for applications that benefit from being tightly integrated with the network subsystem. We are developing a safe, extensible operating system, called SPINE, which enables applications to compute directly on the network adapter. We demonstrate the feasibility of our approach with two applications: a video client and an Internet Protocol router. As a result of our system structure, image data is transferred only once over the I/O bus and places no load on the host CPU to display video at aggregate rates exceeding 100 Mbps. Similarly, the IP router can forward roughly 10,000 packets per second on each network adapter, while placing no load on the host CPU. Based on our experiences, we describe three hardware features useful for improving performance. Finally, we conclude that offloading work to the network adapter can make sense, even using current embedded processor technology. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. von Eicken, D.E. Culler, S.C. Goldstein and K.E. Schauser. </author> <title> "Active Messages: A Mechanism for Integrated Communication and Computation." </title> <booktitle> In Proceedings of the Nineteenth Annual International Symposium on Computer Architecture (ISCA). </booktitle> <year> 1992. </year>
Reference-contexts: At the next level, we are defining the operating system interfaces that enable applications to compute on an intelligent network adapter. Our operating system services uses two technologies previously developed as a springboard: applications and extensions communicate via a message-passing model based on Active Messages <ref> [1] </ref>, and, the extensions run in a safe execution environment, called SPINE, that is derived from the SPIN operating system [2]. The SPINE software architecture offers the following three features that are key to the efficient implementation of I/O intensive applications: Device-to-device transfers. <p> An intelligent network adapter not only moves data; it reacts and applies transformations to it as well. On message arrival, the adapter may have to operate on the data in addition to moving it. This style of processing is captured well by the Active Message <ref> [1] </ref> programming model, which we use to program SPINE extensions on the network adapter. Briefly, an Active Message is a message that carries data as well as an index to a code sequence to execute on message arrival. The code sequence is called a handler.
Reference: [2] <author> B.N. Bershad, S. Savage, P. Pardyak, E.G. Sirer, M.E. Fiuczynski, D. Becker, S. Eggers and C. Chambers. </author> <title> "Extensibility, Safety and Performance in the SPIN Operating System." </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Operating Systems Principles (SOSP). </booktitle> <year> 1995. </year>
Reference-contexts: Our operating system services uses two technologies previously developed as a springboard: applications and extensions communicate via a message-passing model based on Active Messages [1], and, the extensions run in a safe execution environment, called SPINE, that is derived from the SPIN operating system <ref> [2] </ref>. The SPINE software architecture offers the following three features that are key to the efficient implementation of I/O intensive applications: Device-to-device transfers. Avoiding unnecessary indirection through host memory reduces memory bandwidth as well as bandwidth over a shared I/O bus. <p> The linker resolves any unresolved symbols in the extension against logical protection domains <ref> [2] </ref> with which the extension is being linked. A logical protection domain (henceforth referred to simply as a domain) defines a set of visible interfaces that provide access to procedures and variables. This is similar to a Java class name space.
Reference: [3] <author> E.K. Lee and C.A. Thekkath. </author> <title> "Petal: Distributed Virtual Disks." </title> <booktitle> In Proceedings of the Seventh International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS). </booktitle> <year> 1996. </year> <month> 13 </month>
Reference-contexts: Device-level memory management. Transferring data directly between buffers on the device and the application's virtual address space reduces data movement and improves system performance. There are a number of I/O intensive applications and system services that benefit from the use of these features. For example, cluster based storage management <ref> [3] </ref>, multimedia applications [4, 5], and host based IP routers [6], benefit from being able to transfer data directly between devices in an applicationspecific manner.
Reference: [4] <author> W.J. Bolosky, J. S. Barrera III, R.P. Draves, R.P. Fitzgerald, G.A. Gibson, </author> <title> M.B. </title> <editor> Jones, S.P. Levi, N.P. Myhrvold and R.F. Rashid. </editor> <booktitle> "The Tiger Video Fileserver." In Proceedings of the Sixth Network and Operating System Support for Digital Audio Video (NOSSDAV) workshop. </booktitle> <year> 1996. </year>
Reference-contexts: Transferring data directly between buffers on the device and the application's virtual address space reduces data movement and improves system performance. There are a number of I/O intensive applications and system services that benefit from the use of these features. For example, cluster based storage management [3], multimedia applications <ref> [4, 5] </ref>, and host based IP routers [6], benefit from being able to transfer data directly between devices in an applicationspecific manner.
Reference: [5] <author> T.D. Nguyen and J. Zahorjan. </author> <title> "Scheduling Policies to Support Distributed 3D Multimedia Applications." </title> <booktitle> In SIGMETRICS'98 / PERFORMANCE'98 Joint International Conference on Measurement and Modeling of Computer Systems. </booktitle> <year> 1998. </year>
Reference-contexts: Transferring data directly between buffers on the device and the application's virtual address space reduces data movement and improves system performance. There are a number of I/O intensive applications and system services that benefit from the use of these features. For example, cluster based storage management [3], multimedia applications <ref> [4, 5] </ref>, and host based IP routers [6], benefit from being able to transfer data directly between devices in an applicationspecific manner.
Reference: [6] <author> S. Walton, A. Hutton and J. </author> <title> Touch. "Efficient High-Speed Data Paths for IP Forwarding using Host Based Routers." </title> <booktitle> In Proceedings of the Ninth IEEE Workshop on Local and Metropolitan Area Networks. </booktitle> <year> 1998. </year>
Reference-contexts: There are a number of I/O intensive applications and system services that benefit from the use of these features. For example, cluster based storage management [3], multimedia applications [4, 5], and host based IP routers <ref> [6] </ref>, benefit from being able to transfer data directly between devices in an applicationspecific manner. Host/Device protocol partitioning has been shown to be beneficial for applicationspecific multicast [7] and quality of service [8], and it may be useful for distributed memory management systems [9, 10]. <p> In comparison, a host based IP forwarding system using identical hardware (i.e., multiple LANai adapters plugged into a 200MHz Pentium Pro PC) built at USC/ISI achieves 12,000 packets per second over PCI while utilizing 100% of the host CPU <ref> [6] </ref>. The USC/ISI host based IP router implementation optimizes the data path and only the IP packet header is copied into the host system, while the remaining IP packet is transferred directly using device-to-device DMA between the source and destination LANai adapters.
Reference: [7] <author> H. Bal, R. Bhoedjang, R. Hofman, C. Jacobs, K. Langendoen, T. Ruhl and K. Verstoep. </author> <title> "Performance of a High-Level Parallel Language on a HighSpeed Network." </title> <journal> Journal of Parallel and Distributed Computing. </journal> <year> 1997. </year>
Reference-contexts: For example, cluster based storage management [3], multimedia applications [4, 5], and host based IP routers [6], benefit from being able to transfer data directly between devices in an applicationspecific manner. Host/Device protocol partitioning has been shown to be beneficial for applicationspecific multicast <ref> [7] </ref> and quality of service [8], and it may be useful for distributed memory management systems [9, 10]. Finally, device-level memory management has been investigated in the context of cluster-based parallel processing systems [11-13], which all require applicationspecific processing on the network adapter.
Reference: [8] <author> P. Druschel and B. Gaurav. </author> <title> "Lazy Receive Processing (LRP): A Network Subsystem Architecture for Server Systems." </title> <booktitle> In Proceedings of the Second USENIX Symposium on Operating System Design and Implementation (OSDI). </booktitle> <year> 1996. </year>
Reference-contexts: For example, cluster based storage management [3], multimedia applications [4, 5], and host based IP routers [6], benefit from being able to transfer data directly between devices in an applicationspecific manner. Host/Device protocol partitioning has been shown to be beneficial for applicationspecific multicast [7] and quality of service <ref> [8] </ref>, and it may be useful for distributed memory management systems [9, 10]. Finally, device-level memory management has been investigated in the context of cluster-based parallel processing systems [11-13], which all require applicationspecific processing on the network adapter. <p> There has been a great deal of work, however, in offloading pieces of network protocols. For example, there has been work to offload Internet checksum calculations [30, 39, 40], link layer processing [41-45], and packet filtering <ref> [8, 46] </ref>. Interestingly, the tide might be turning again: recently published results show that offloading TCP/IP to intelligent network adapters yields better performance for an enterprise-wide server system running Windows NT [47].
Reference: [9] <author> M.D. Dahlin, R.Y. Wang, T.E. Anderson and D.A. Patterson. </author> <title> "Cooperative Caching: Using Remote Client Memory to Improve File System Performance." </title> <booktitle> In Proceedings of the First USENIX Conference on Operating System Design and Implementation (OSDI). </booktitle> <year> 1994. </year>
Reference-contexts: Host/Device protocol partitioning has been shown to be beneficial for applicationspecific multicast [7] and quality of service [8], and it may be useful for distributed memory management systems <ref> [9, 10] </ref>. Finally, device-level memory management has been investigated in the context of cluster-based parallel processing systems [11-13], which all require applicationspecific processing on the network adapter.
Reference: [10] <author> M.J. Feeley, W.E. Morgan, F. Pighin, A. Karlin and H.M. Levy. </author> <title> "Implementing Global Memory Management in a Workstation Cluster." </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Operating Systems Principles (SOSP). </booktitle> <year> 1995. </year>
Reference-contexts: Host/Device protocol partitioning has been shown to be beneficial for applicationspecific multicast [7] and quality of service [8], and it may be useful for distributed memory management systems <ref> [9, 10] </ref>. Finally, device-level memory management has been investigated in the context of cluster-based parallel processing systems [11-13], which all require applicationspecific processing on the network adapter.
Reference: [11] <author> Y. Chen, C. Dubnicki, S. Damianakis, A. Bilas and K. Li. "UTLB: </author> <title> A Mechanism for Address Translation on Network Interfaces." </title> <booktitle> In Proceedings of the Eighth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS). </booktitle> <year> 1998. </year>
Reference: [12] <author> B.N. Chun, A.M. Mainwaring and D.E. Culler. </author> <title> "A General-Purpose Protocol Architecture for a Low-Latency, Multi-gigabit System Area Network." </title> <booktitle> In Proceedings of the Fifth Hot Interconnects Symposium. </booktitle> <year> 1997. </year>
Reference: [13] <author> M. Welsh, A. Basu and T. vonEicken. </author> <title> "Incorporating Memory Management into User-Level Network Interfaces." </title> <booktitle> In Proceedings of the Fifth Hot Interconnects Symposium. </booktitle> <year> 1997. </year>
Reference: [14] <author> J.L. Hennessy and D.A. Patterson, </author> <title> "Computer Architecture: A Quantitative Approach, Second Edition". </title> <publisher> 1996 Kaufman Publishers. </publisher>
Reference-contexts: Indeed, I/O is often the orphan of computer architecture <ref> [14] </ref>. For example, Sun Microsystems significantly improved the memory subsystem for its UltraSparc workstations over older generation Sparcs, yet neglected to improve its I/O bus (the SBUS). Historically, I/O interconnects (primarily busses or serial lines) have been orders of magnitude faster than the attached I/O devices.
Reference: [15] <author> G. Nelson, ed. </author> <title> "System Programming in Modula-3". 1991, </title> <publisher> Prentice Hall. </publisher>
Reference-contexts: Hsieh et al. [16, 17] describes these language enhancements in further detail. SPINE and its extensions use the following two Modula-3 language enhancements: type safe casting and isolation from untrusted code. The former allows data created outside of the language to be given a Modula-3 1 Although Modula-3 <ref> [15] </ref> is less popular compared to Java, it enables us to focus on system design issues using a high-level language rather than on interpretation efficiency.
Reference: [16] <author> W.C. Hsieh, M.E. Fiuczynski, P. Pardyak and B.N. Bershad. </author> <title> "Type-Safe Casting." </title> <journal> Software Practice and Experience. </journal> <year> 1998. </year>
Reference-contexts: In particular, a program cannot access or jump to arbitrary memory locations, and cannot use values in ways not prescribed by the language. As our typesafe language we are using a version of Modula-3 1 that has been enhanced to support efficient, low-level, systems code. Hsieh et al. <ref> [16, 17] </ref> describes these language enhancements in further detail. SPINE and its extensions use the following two Modula-3 language enhancements: type safe casting and isolation from untrusted code.
Reference: [17] <author> W.C. Hsieh, M.E. Fiuczynski, C. Garrett, S. Savage, D. Becker and B.N. Bershad. </author> <title> "Language Support for Extensible Operating Systems." </title> <booktitle> In Proceedings of the First Workshop on Compiler Support for System Software. </booktitle> <year> 1996. </year>
Reference-contexts: In particular, a program cannot access or jump to arbitrary memory locations, and cannot use values in ways not prescribed by the language. As our typesafe language we are using a version of Modula-3 1 that has been enhanced to support efficient, low-level, systems code. Hsieh et al. <ref> [16, 17] </ref> describes these language enhancements in further detail. SPINE and its extensions use the following two Modula-3 language enhancements: type safe casting and isolation from untrusted code.
Reference: [18] <author> M.E. Fiuczynski and B.N. Bershad. </author> <title> "An Extensible Protocol Architecture for ApplicationSpecific Networking." </title> <booktitle> In Proceedings of the Winter 1996 USENIX Technical Conference. </booktitle> <address> San Diego, CA. </address> <year> 1996. </year>
Reference-contexts: We have previously used these mechanisms for similar purposes in the context of an extensible protocol architecture for application-specific networking <ref> [18] </ref>. 3.3.2 Guarding Against Excessive Execution Time To prevent a misbehaving active message handler from stalling the system, it is necessary to asynchronously terminate such a handler. Before invoking an extension handler, the runtime sets a watchdog timer interrupt.
Reference: [19] <author> E.G. Sirer, M.E. Fiuczynski, P. Pardyak and B.N. Bershad. </author> <title> "Safe Dynamic Linking in an Extensible Operating System." </title> <booktitle> In Proceedings of the First Workshop on Compiler Support for System Software. </booktitle> <year> 1996. </year>
Reference-contexts: This mechanism prevents extension code from accessing low-level system functionality or state that it could use to violate system safety. Sirer et al. <ref> [19] </ref> describes the name space management provided by domains and safe dynamic linking in further detail. To economize network adapter resources, the dynamic linker implementation as well as domain and symbol table information is left on the host system. Only code/data sections are downloaded onto the adapter.
Reference: [20] <institution> Lucent. "Inferno: la Commedia Interattiva." </institution> <note> Available from www.lucent-inferno.com. 1996. </note>
Reference-contexts: The compiler will generate an error when compiling Illegalhandler since it calls a procedure that is not ephemeral. 6 <ref> [20] </ref>. In the future, it may be possible to use Proof Carrying Code [21] generated by a Certifying Compiler [22] to ensure that extensions are typesafe.
Reference: [21] <author> G.C. Necula and P. Lee. </author> <title> "Safe Kernel Extensions Without RunTime Checking." </title> <booktitle> In Proceedings of the Second USENIX Conference on Operating System Design and Implementation (OSDI). </booktitle> <address> Seattle, WA. </address> <year> 1996. </year>
Reference-contexts: The compiler will generate an error when compiling Illegalhandler since it calls a procedure that is not ephemeral. 6 [20]. In the future, it may be possible to use Proof Carrying Code <ref> [21] </ref> generated by a Certifying Compiler [22] to ensure that extensions are typesafe.
Reference: [22] <author> G.C. Necula and P. Lee. </author> <title> "The Design and Implementation of a Certifying Compiler." </title> <booktitle> In Symposium on Programming Language Design and Implementation (PLDI). </booktitle> <address> Montreal, Canada. </address> <year> 1998. </year>
Reference-contexts: The compiler will generate an error when compiling Illegalhandler since it calls a procedure that is not ephemeral. 6 [20]. In the future, it may be possible to use Proof Carrying Code [21] generated by a Certifying Compiler <ref> [22] </ref> to ensure that extensions are typesafe. In either case, a dynamic check is necessary by the SPINE linker to ensure that compile-time restrictions (such as type safety) are obeyed by the submitted object code. 3.4 Memory Management To simplify resource management, extensions may not allocate memory dynamically.
Reference: [23] <author> S. Nilsson and G. Karlsson. </author> <title> "Fast Address Lookup for Internet Routers." In Broadband Communications: The future of telecommunications. </title> <year> 1998. </year>
Reference-contexts: The router demonstrates the distributed systems nature of SPINE. That is, extensions can communicate with the host, peer devices, or via the network. load. We used algorithms for forwarding table compression and fast IP lookup described in <ref> [23] </ref>, and inserted one thousand routes into less than 20Kbytes of memory on the adapter. The experiment was to forward two million packets at a maximum rate such that the percentage of dropped packets was less than 0.5%.
Reference: [24] <author> R. Martin, A. Vahdat, D. Culler and T. Anderson. </author> <title> "Effects of Communication Latency, Overhead, and Bandwidth in a Cluster Architecture." </title> <booktitle> In International Symposium on Computer Architecture (ISCA). </booktitle> <address> Denver, CO. </address> <year> 1997. </year>
Reference-contexts: The current SPINE runtime optimizes for high throughput of small messages. Part of this motivation comes from recent work demonstrating that with low software overhead, many applications have a high degree of latency tolerance <ref> [24] </ref>. At the same time however, it must be general enough to support user extensions. The SPINE I/O runtime is constructed as a generic event handler. Recall from Section 3.2 that all SPINE processing is ultimately decomposed into internal Active Message handlers.
Reference: [25] <author> G. Buzzard, D. Jacobson, M. Mackey, S. Marovich and J. Wilkes. </author> <title> "An Implementation of the Hamlyn Sender-Managed Interface Architecture." </title> <booktitle> In Proceedings of the Second USENIX Conference on Operating System Design and Implementation (OSDI). </booktitle> <address> Seattle, WA. </address> <year> 1996. </year>
Reference: [26] <author> S. Pakin, M. Lauria and A. Chien. </author> <title> "High Performance Messaging on Workstations: Illinois Fast Messages (FM) for Myrinet." </title> <booktitle> In Proceedings of the 1995 ACM/IEEE Supercomputing Conference. </booktitle> <year> 1995. </year>
Reference-contexts: A common method of eliminating the operating system protocols was to use a programmable network adapter. This strategy allows the networking layers to expose the adapter directly to applications <ref> [26, 27, 48] </ref>. The elimination of the operating system yields a factor of 10 improvement in software overhead over conventional protocol stacks, and peak bandwidths thus become achievable with small packets [49]. Our work was originally motivated by these results of offloading overhead from the host system.
Reference: [27] <author> D.E. Culler, T.L. Lok, R.P. Martin and C.O. Yoshikawa. </author> <title> "Assessing Fast Network Interfaces." </title> <journal> IEEE Micro. </journal> <volume> 16(1): </volume> <pages> p. 35-43. </pages> <year> 1996. </year>
Reference-contexts: A common method of eliminating the operating system protocols was to use a programmable network adapter. This strategy allows the networking layers to expose the adapter directly to applications <ref> [26, 27, 48] </ref>. The elimination of the operating system yields a factor of 10 improvement in software overhead over conventional protocol stacks, and peak bandwidths thus become achievable with small packets [49]. Our work was originally motivated by these results of offloading overhead from the host system.
Reference: [28] <author> D. Anderson, J. Chase, S. Gadde, A. Gallatin, K. Yocum and M. Feeley. </author> <title> "Cheating the I/O Bottleneck: Network Storage with Trapeze/Myrinet." </title> <booktitle> In Proceedings of the Usenix Technical Conference. </booktitle> <address> New Orleans, LA. </address> <year> 1998. </year>
Reference: [29] <author> L. Pryllli and B. Tourancheau. "Bip: </author> <title> a new protocol designed for high performance networking on myrinet." </title> <booktitle> In Workshop PC-NOW, </booktitle> <address> IPPS/SPDP. Orlando, FL. </address> <year> 1998. </year>
Reference: [30] <author> C. Dalton, G. Watson, D. Banks, C. Calamvokis, A. Edwards and J. Lumley. </author> <title> "Afterburner." </title> <journal> IEEE Network. </journal> <volume> 7(4): </volume> <pages> p. 35-43. </pages> <year> 1993. </year>
Reference-contexts: One that fills the buffer and the other that drains it. The drain removes the oldest entry first. SPINE incurs a substantial performance penalty, as it has to emulate these FIFOs in software for the LANai adapter. Using hardware FIFOs for synchronized messaging, much like those found in <ref> [30, 31] </ref>, would substantially reduce communication costs over the shared bus. It would improve communication performance with peer devices as well as communication with the host. <p> There has been a great deal of work, however, in offloading pieces of network protocols. For example, there has been work to offload Internet checksum calculations <ref> [30, 39, 40] </ref>, link layer processing [41-45], and packet filtering [8, 46]. Interestingly, the tide might be turning again: recently published results show that offloading TCP/IP to intelligent network adapters yields better performance for an enterprise-wide server system running Windows NT [47].
Reference: [31] <author> I2O Special Interest Group. </author> <title> "Intelligent I/O (I 2 O) Architecture Specification v1.5." </title> <note> Available from www.i2osig.org. 1997. 14 </note>
Reference-contexts: One that fills the buffer and the other that drains it. The drain removes the oldest entry first. SPINE incurs a substantial performance penalty, as it has to emulate these FIFOs in software for the LANai adapter. Using hardware FIFOs for synchronized messaging, much like those found in <ref> [30, 31] </ref>, would substantially reduce communication costs over the shared bus. It would improve communication performance with peer devices as well as communication with the host. <p> Our work was originally motivated by these results of offloading overhead from the host system. I 2 O is a recent technology providing a general architecture for coupling host systems with I/O devices <ref> [31] </ref>. The primary goals of the I 2 O work are the elimination of multitudes of device drivers and improved 12 performance by reducing device related processing and resource requirements from the host.
Reference: [32] <author> Packet Engines. </author> <title> "PowerRail Enterprise Routing Switch Architecture." </title> <note> Available from www.packetengines.com. 1998. </note>
Reference-contexts: Although this rate does not approach specialized forwarding ASICs (such as those used in Packet Engines routing switches <ref> [32] </ref>), it is much faster than a host-based router and would allow routers to be constructed with cheaper, slower, primary processors. However, unlike the ASIC-based approach, SPINE gives the programmer nearly the same flexibility as a traditional host-based system.
Reference: [33] <author> G. </author> <title> Powers. "A front-end telnet/rlogin server implementation." </title> <booktitle> In Proceedings of Uniforum 1986 Conference. </booktitle> <year> 1986. </year>
Reference-contexts: There were two reasons for such an approach, which, due to its complexity, required an I/O processor. First, many host operating systems did not support the range of protocols that existed at the time (e.g., TCP/IP, telnet, and rlogin) <ref> [33] </ref>. Writing these protocols once for an intelligent network adapter was an effective method of quickly incorporating protocols into a variety of operating systems. Second, the host processors of the time were not powerful enough to run both multitasking jobs and network protocol stacks efficiently [34-36].
Reference: [34] <author> S. Bal. </author> <title> "Networked Systems (the architecture for multiuser computing)." DEC Professional. </title> <booktitle> 5(2): p. </booktitle> <pages> 48-52. </pages> <year> 1986. </year>
Reference: [35] <author> D. </author> <title> Way. "Front-end processors smooth local network-computer integration." </title> <journal> Electronics. </journal> <volume> 57(3): </volume> <pages> p. 135-9. </pages> <year> 1984. </year>
Reference: [36] <author> L. Gross. </author> <title> "Architecture of an Ethernet Interface." </title> <journal> Elektronik. </journal> <volume> 34(7): </volume> <pages> p. 124-6. </pages> <year> 1984. </year>
Reference: [37] <author> D. Hitz, G. Harris, J.K. Lay and A.M. Schwartz. </author> <title> "Using Unix as One Component of a Lightweight Distributed Kernel for a Multiprocessor File Server." </title> <booktitle> In Proceedings of the Winter 1990 USENIX Conference. </booktitle> <year> 1990. </year>
Reference-contexts: Second, the host processors of the time were not powerful enough to run both multitasking jobs and network protocol stacks efficiently [34-36]. The logical apex of the greater and greater inclusion of protocol into the adapter is best exemplified by the Auspex NFS server <ref> [37] </ref>. Each component of the Auspex server (disk, network, NFS cache) has an I/O processor that is specialized for NFS services. A lightweight kernel running on each I/O processor controls the communication among the functional I/O components of the NFS server.
Reference: [38] <author> P. Trautman, B. Nelson and Auspex Engineering. </author> <title> "The Myth of MIPS for I/O." </title> <note> Available from www.auspex.com/tr10.pdf. 1997. </note>
Reference-contexts: A lightweight kernel running on each I/O processor controls the communication among the functional I/O components of the NFS server. This separation of NFS services from the host operating system enables higher performance, scalability, and resilience to host failure <ref> [38] </ref>. By the late 1980s however, the tide had turned, with only support for very common protocol operations included in the adapter. The migration of common protocols into commodity operating systems and the exponential growth of processor speed eliminated the original motivations for intelligent network adapters at the time.
Reference: [39] <author> J. Touch and B. Parham. </author> <title> "Implementing the Internet checksum in hardware." Internet RFC 1936. </title> <year> 1996. </year>
Reference-contexts: There has been a great deal of work, however, in offloading pieces of network protocols. For example, there has been work to offload Internet checksum calculations <ref> [30, 39, 40] </ref>, link layer processing [41-45], and packet filtering [8, 46]. Interestingly, the tide might be turning again: recently published results show that offloading TCP/IP to intelligent network adapters yields better performance for an enterprise-wide server system running Windows NT [47].
Reference: [40] <author> V. Jacobson. </author> <title> "Efficient protocol implementation." </title> <booktitle> ACM SIGCOMM'90 Tutorial. </booktitle> <year> 1990. </year>
Reference-contexts: There has been a great deal of work, however, in offloading pieces of network protocols. For example, there has been work to offload Internet checksum calculations <ref> [30, 39, 40] </ref>, link layer processing [41-45], and packet filtering [8, 46]. Interestingly, the tide might be turning again: recently published results show that offloading TCP/IP to intelligent network adapters yields better performance for an enterprise-wide server system running Windows NT [47].
Reference: [41] <author> P. Druschel, L.L. Peterson and B.S. Davie. </author> <title> "Experience with a highspeed Network Adapter: A Software Perspective." </title> <booktitle> In Proceedings of the ACM SIGCOMM '94 Symposium on Communication Architectures and Protocols. </booktitle> <year> 1994. </year>
Reference: [42] <author> E.C. Cooper, P.A. Steenkiste, R.D. Sansom and B.D. Zill. </author> <title> "Protocol Implementation on the Nectar Communication Processor." </title> <booktitle> In Proceedings of the ACM SIGCOMM '90 Symposium on Communication Architectures and Protocols. </booktitle> <year> 1994. </year>
Reference: [43] <author> B.S. Davie. </author> <title> "A Host/Network Interface Architecture for ATM." </title> <booktitle> In Proceedings of the ACM SIGCOMM '91 Symposium on Communication Architectures and Protocols. </booktitle> <year> 1991. </year>
Reference: [44] <author> H. Kanakia and D.R. Cheriton. </author> <title> "The VMP Network Adapter Board (NAB): High-performance Network Communication for Multiprocessors." </title> <booktitle> In Proceedings of the ACM SIGCOMM '88 Symposium on Communication Architectures and Protocols. </booktitle> <year> 1988. </year>
Reference: [45] <author> C.B. Traw and J.M. Smith. </author> <title> "A High-performance Host Interface for ATM Networks." </title> <booktitle> In Proceedings of the ACM SIGCOMM '91 Symposium on Communication Architectures and Protocols. </booktitle> <year> 1991. </year>
Reference: [46] <author> M.L. Bailey, M.A. Pagels and L.L. Peterson. </author> <title> "The x-chip; An experiment in hardware demultiplexing." </title> <booktitle> In Proceedings of the IEEE Workshop on High Performance communications Subsystems. </booktitle> <year> 1991. </year>
Reference-contexts: There has been a great deal of work, however, in offloading pieces of network protocols. For example, there has been work to offload Internet checksum calculations [30, 39, 40], link layer processing [41-45], and packet filtering <ref> [8, 46] </ref>. Interestingly, the tide might be turning again: recently published results show that offloading TCP/IP to intelligent network adapters yields better performance for an enterprise-wide server system running Windows NT [47].
Reference: [47] <author> T. </author> <title> Matters. "Offloading TCP/IP to Intelligent Adapters." </title> <booktitle> Slides from PC Developers Conference. </booktitle> <year> 1998. </year>
Reference-contexts: Interestingly, the tide might be turning again: recently published results show that offloading TCP/IP to intelligent network adapters yields better performance for an enterprise-wide server system running Windows NT <ref> [47] </ref>. In recent years, researchers from the parallel processing community have taken a different strategy all together: eliminate protocols as much as possible. The motivation behind this work was an attempt to replicate the communication performance of Massively Parallel Processors (MPPs) on stock hardware.
Reference: [48] <author> T. von Eicken, A. Basu, V. Buch and W. Vogels. "U-Net: </author> <title> A User-Level Network Interface for Parallel and Distributed Computing." </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Operating Systems Principles (SOSP). </booktitle> <year> 1995. </year>
Reference-contexts: A common method of eliminating the operating system protocols was to use a programmable network adapter. This strategy allows the networking layers to expose the adapter directly to applications <ref> [26, 27, 48] </ref>. The elimination of the operating system yields a factor of 10 improvement in software overhead over conventional protocol stacks, and peak bandwidths thus become achievable with small packets [49]. Our work was originally motivated by these results of offloading overhead from the host system.
Reference: [49] <author> K.K. Ramakrishnan. </author> <title> "Performance Considerations in Designing Network Interfaces." </title> <journal> IEEE Journal on Selected Areas in Communications. </journal> <volume> 11(2): </volume> <pages> p. 2030-219. </pages> <year> 1993. </year>
Reference-contexts: This strategy allows the networking layers to expose the adapter directly to applications [26, 27, 48]. The elimination of the operating system yields a factor of 10 improvement in software overhead over conventional protocol stacks, and peak bandwidths thus become achievable with small packets <ref> [49] </ref>. Our work was originally motivated by these results of offloading overhead from the host system. I 2 O is a recent technology providing a general architecture for coupling host systems with I/O devices [31].
Reference: [50] <author> S. Muir and J. Smith. </author> <title> "Functional divisions in the Piglet multiprocessor operating system." </title> <booktitle> In Proceedings of the ACM SIGOPS European Workshop. </booktitle> <year> 1998. </year>
Reference-contexts: The Piglet OS project suggests an alternative approach to intelligent I/O from SPINE. Piglet partitions the processors of a symmetric multiprocessor (SMP) system into functional groups with the goal of improving system performance for I/O intensive applications <ref> [50] </ref>. However, such processors are unavailable for user-applications. We believe, for the architectural reasons outlined in Section 2, that using an integrated I/O processor will yield similar or better performance at a much lower cost. Perhaps the closest work to SPINE is the U-net/SLE (safe language environment) project [51].
Reference: [51] <author> D. Oppenheimer and M. Welsh. </author> <title> "User Customization of Virtual Network Interfaces with U-Net/SLE." </title> <type> TR CSD-98-995, </type> <institution> Department of Electrical Engineering and Computer Science, University of California, Berkeley. </institution> <year> 1998. </year>
Reference-contexts: However, such processors are unavailable for user-applications. We believe, for the architectural reasons outlined in Section 2, that using an integrated I/O processor will yield similar or better performance at a much lower cost. Perhaps the closest work to SPINE is the U-net/SLE (safe language environment) project <ref> [51] </ref>. U-net/SLE implemented a subset of the Java Virtual Machine (JVM) for the LANai; thereby allowing customized packet processing to occur on the network adapter. Because the LANai processor is slow, the primary focus of their work was on the performance of the JVM.
Reference: [52] <author> D. Patterson and K. Keeton. </author> <title> "Hardware Technology Trends and Database Opportunities." Slides from SIGMOD'98 Keynote Address. </title> <year> 1998. </year>
Reference-contexts: The use of machine binaries enables us to focus on system design issues using a high-level language rather than on interpreter efficiency. The two languages are sufficiently similar that many of our results may be applicable to the Java language as well. The IDISK <ref> [52] </ref> and Active Disks [53] projects are investigating how to add application processing to the disk subsystems.
Reference: [53] <author> A. Acharya, M. Uysal and J. Saltz. </author> <title> "Active Disks." </title> <type> TR CS98-06, </type> <institution> Computer Science Department, University of California, Santa Barbara. </institution> <year> 1998. </year>
Reference-contexts: The use of machine binaries enables us to focus on system design issues using a high-level language rather than on interpreter efficiency. The two languages are sufficiently similar that many of our results may be applicable to the Java language as well. The IDISK [52] and Active Disks <ref> [53] </ref> projects are investigating how to add application processing to the disk subsystems.
Reference: [54] <author> K. Keeton, R. Apraci-Dusseau and D.A. Patterson. "IRAM and SmartSIMM: </author> <title> Overcoming the I/O Bus Bottleneck." In Workshop on Mixing Logic and DRAM: Chips that Compute and Remember. </title> <year> 1997. </year>
Reference-contexts: A faster CPU, for example, would allow the use of a virtual machine interpreter (e.g., Java), enabling transparent execution of extensions regardless of the instruction set. Using a vector processor, as suggested in <ref> [54] </ref> of the IRAM project, would enable data touching intensive applications, such as encryption, compression, video decoding, and data filtering, to be implemented on the network adapter.
Reference: [55] <institution> Alteon Networks. "Gigabit Ethernet Technology Brief." </institution> <note> Available from www.alteon.com. 1998. </note>
Reference-contexts: We expect that a system using a current high-end I/O processor (clocked at roughly 200 MHz and with a cache size of 32KB) could improve performance by a factor of five over our current system. We hope to explore applications using more powerful network adapters. For example, Alteon's ACEnic <ref> [55] </ref>, which is equipped with two 100MHz MIPS processors, would make an excellent candidate for future research in placing applicationspecific functionality onto an adapter.
References-found: 55

