URL: ftp://wol.ra.phy.cam.ac.uk/pub/www/mackay/thesis.ps.gz
Refering-URL: http://www.cs.helsinki.fi/research/cosco/Projects/NONE/aera98/
Root-URL: 
Title: Bayesian Methods for Adaptive Models  
Author: David J.C. MacKay 
Degree: Thesis by  In Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy  
Date: December 10, 1991)  
Note: c fl1992 (Submitted  
Address: Pasadena, California  
Affiliation: California Institute of Technology  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> Y.S. </author> <title> Abu-Mostafa (1990). The Vapnik-Chervonenkis dimension: information versus complexity in learning, </title> <booktitle> Neural Computation 1 3, </booktitle> <pages> 312-317. </pages>
Reference-contexts: Neural networks can also be trained to perform classification tasks. A future publication [52] will demonstrate that the Bayesian framework for model comparison can be applied to these problems too. Relation to V-C dimension Some papers advocate the use of V-C dimension <ref> [1] </ref> as a criterion for penalising overcomplex models [2, 42]. V-C dimension is most often applied to classification problems; the evidence, on the other hand, can be evaluated equally easily for both interpolation and classification problems.
Reference: [2] <author> Y.S. </author> <title> Abu-Mostafa (1990). Learning from hints in neural networks, </title> <journal> J. </journal> <volume> Complexity 6, </volume> <pages> 192-198. </pages>
Reference-contexts: It is moderately common for extra regularising terms E W (w) to be added to E D ; for example, terms which penalise large weights may be introduced, in the hope of achieving a smoother or simpler mapping [33, 39, 57, 67, 87]. Some of the `hints' in <ref> [2] </ref> also fall into the category of additive weight-dependent energies. <p> A future publication [52] will demonstrate that the Bayesian framework for model comparison can be applied to these problems too. Relation to V-C dimension Some papers advocate the use of V-C dimension [1] as a criterion for penalising overcomplex models <ref> [2, 42] </ref>. V-C dimension is most often applied to classification problems; the evidence, on the other hand, can be evaluated equally easily for both interpolation and classification problems. V-C dimension is a worst case measure, so it yields different results from Bayesian analysis [32].
Reference: [3] <author> H. </author> <title> Akaike (1970). Statistical predictor identification, </title> <journal> Ann. Inst. Statist. Math. </journal> <volume> 22, </volume> <pages> 203-217. </pages>
Reference-contexts: The log evidence log 2 P (DjH i ) is the number of bits in the ideal shortest message that encodes the data D using model H i . Akaike's criterion, originally derived as a predictor of generalisation error <ref> [3] </ref>, can be viewed, like Schwartz's `B.I.C.', as an approximation to MDL and Bayes [68, 89]. Any implementation of MDL necessitates approximations in evaluating the length of the ideal shortest message. <p> There are theories which attempt to directly predict generalisation ability, leading to Akaike's FPE criterion, and Moody's GPE <ref> [3, 54] </ref>. But for the toy problems I have studied, neither of these criteria has a better correlation with the generalisation error than that achieved by the evidence. Theories based on the V-C dimension lead to structural risk minimisation criteria [30], which seem better correlated with generalisation error.
Reference: [4] <author> J.R.P. Angel, P. Wizinowich, M. Lloyd-Hart, and D. </author> <title> Sandler (1990). Adaptive optics for array telescopes using neural-network techniques, </title> <booktitle> Nature 348, </booktitle> <pages> 221-224. </pages>
Reference-contexts: The backpropagation algorithm has been applied to many other tasks (the text pronunciation example above is one of the earliest successes), and a performance equalling the ability of human experts is often obtained. Recently, especially impressive results have been obtained for adaptive optics <ref> [4] </ref>. However, the performance of these algorithms depends on a considerable number of design choices, most of which are currently made by rules of thumb and trial and error.
Reference: [5] <author> E.B. </author> <title> Baum (1991). Neural net algorithms that learn in polynomial time from examples and queries, </title> <journal> IEEE Trans. on neural networks 2 1, </journal> <pages> 5-19. </pages>
Reference-contexts: This work was directly stimulated by a presentation given by John Skilling at Maxent 91 [76]. Recent work in the neural networks literature on active data selection, also known as `query learning', has concentrated on slightly different problems: The work of Baum <ref> [5] </ref> and Hwang et al. [35] relates to perfectly separable classification problems only; in both these papers a sensible query-based learning algorithm is proposed, and empirical results of the algorithm are reported; Baum also gives a convergence proof. <p> Several papers have suggested strategies for this active learning problem, for example Hwang et al. [35] propose that samples should be made on and near the current decision boundaries. This strategy and that of Baum <ref> [5] </ref> are both human-designed strategies and it is not clear what objective function if any they optimise, nor is it clear how the strategies could be improved.
Reference: [6] <author> T. </author> <title> Bayes (1763). An essay towards solving a problem in the doctrine of chances, </title> <journal> Philos. Trans. R. Soc. </journal> <volume> London 53, </volume> <pages> 370-418, </pages> <note> reprinted in Biometrika (1958) 45, 293-315. </note>
Reference-contexts: Complex models are automatically self-penalising under Bayes' rule. Figure 2.2 gives the basic intuition for why this should be expected; the rest of this chapter will explore this property in depth. Bayesian methods, simultaneously conceived by Bayes <ref> [6] </ref> and Laplace [80], were first laid out in depth by the Cambridge geophysicist Sir Harold Jeffreys [38].
Reference: [7] <author> S. Becker and Y. </author> <title> Le Cun (1988). Improving the convergence of back-propagation learning with second order methods, </title> <booktitle> in Proc. of the connectionist models Summer school, </booktitle> <editor> Ed. D.S. Touretzky et al., </editor> <volume> 29, </volume> <publisher> Morgan Kaufmann. </publisher>
Reference: [8] <author> J. </author> <title> Berger (1985). Statistical decision theory and Bayesian analysis, </title> <publisher> Springer. </publisher>
Reference-contexts: To some, the word Bayesian denotes a decision strategy that minimises the expectation of a cost [24]; to others, a Bayesian is someone who tries to incorporate prior knowledge into their inference and decision process <ref> [8] </ref>. In fact, according to Good, there are 46656 varieties of Bayesian! 1 This thesis presents a flavour of Bayesianism in which decisions are not involved. Inference and decision are cleanly separated. The terms `Bayes risk' and `Bayes optimal' are not in the vocabulary of this thesis. <p> For a general review of Bayesian philosophy the reader is encouraged to read the excellent papers by Jaynes and Loredo [36, 47], and the recently reprinted text of Box and Tiao [13]. Since Jeffreys, the emphasis of most Bayesian probability theory has been `to formally utilize prior information' <ref> [8] </ref>, i.e., to perform inference in a way that makes explicit the prior knowledge and ignorance that we have, which orthodox methods omit. <p> Bayesian inference is consistent with this principle; there is no need to undo biases introduced by the data collecting strategy, because it is not possible for such biases to be introduced | as long as we perform inference using all the data gathered <ref> [8, 47] </ref>. When the models are concerned with estimating the distribution of output variables t given input variables x, we are allowed to look at the x value of a datum, and decide whether or not to include the datum in the data set.
Reference: [9] <author> C.M. </author> <title> Bishop (1992). Exact calculation of the Hessian matrix for the multilayer perceptron, </title> <booktitle> Neural Computation 4 4, </booktitle> <pages> 494-501. </pages>
Reference-contexts: Denker et al. have already discussed how to approximate the Hessian of E D for the purpose of evaluating weight saliency and for assigning error bars to weights and network outputs [19, 41]. The Hessian can be evaluated in the same way that backpropagation evaluates rE D (see <ref> [9] </ref> for a complete algorithm and the appendix of this chapter for a useful approximation). Alternatively A can be evaluated by numerical methods, for example second differences. <p> I expect an exact analytic evaluation of the second derivatives <ref> [9] </ref> would resolve this. To save programming effort I instead used second differences, which is computationally more demanding (~ kN backprops) than the analytic approach (~ N backprops). <p> Gradient: If y (x (m) ) = f (a (x (m) )) as defined above, the gradient of G with respewct to the parameters w is rG = m where g (m) = @a=@wj x=x (m) . Hessian: The Hessian can be analytically evaluated <ref> [9] </ref>, but a useful approximation ne glecting terms in @ 2 a=@ 2 w is: rrG ' m (m) : (5.5) This approximation is expected to be adequate for the evaluation of error bars, for use in data selection and for the evaluation of the number of well-determined parameters fl.
Reference: [10] <author> G.E.P. </author> <title> Box and G.C. Tiao (1962). A further look at robustness via Bayes' theorem, </title> <journal> Biometrika 49, </journal> <pages> 419-432. </pages>
Reference-contexts: Since the 1960s, Jeffreys' model comparison methods have been applied and 10 BAYESIAN METHODS FOR ADAPTIVE MODELS extended in the economics literature [89] and by a small number of statisticians <ref> [10, 11, 12] </ref>. Only recently has this aspect of Bayesian analysis been further developed and applied to more complex problems in other fields. This chapter will review Bayesian model comparison, `regularisation', and noise estimation, by studying the problem of interpolating noisy data. <p> Then the evidence can be approximated by the height of the peak of the integrand P (Djw; H i )P (wjH i ) times its width, w: 3 Under this use of the word, Box and Tiao <ref> [10, 11, 12] </ref> must be counted as `modern' Bayesians. CHAPTER 2. BAYESIAN INTERPOLATION 13 w MP 0 w P (wjH i ) This figure shows the quantities that determine the Occam factor for a hypothesis H i having a single parameter w. <p> misfit, rather than 2 D = 2fiE D . 9 These error bars represent the uncertainty of the interpolant, and should not be confused with the typical scatter of noisy data points relative to the interpolant. 10 Bayesian inference of a slightly non-Gaussian distribution is performed in Box and Tiao <ref> [10, 12] </ref>. CHAPTER 2. BAYESIAN INTERPOLATION 17 a) c) These figures introduce a data set, `X', which is interpolated with a variety of models in this chapter. Notice that the density of data points is not uniform on the x-axis. <p> Bayesians adopt the healthy attitude of not sweeping them under the carpet. (b) With some thought, reasonable values can usually be assigned to subjective priors, and the degree of reasonable subjectivity in these assignments can be quantified, and the sensitivity of our inferences to these priors can be quantified <ref> [10, 12] </ref>. For example, a reasonable prior on an unknown standard deviation states that is unknown over a range of (32) orders of magnitude. This prior contributes a subjectivity of about 1 to the value of the log evidence. <p> The latter problem would also be relevant to regression problems where non-Gaussian noise models are thought appropriate; a definitive Bayesian attack on the problem of inferring a slightly non-Gaussian distribution has been made by Box and Tiao <ref> [10, 12] </ref>. Further applications in neural networks It remains to be investigated whether these methods scale up to real, larger problems. Also this framework has yet to be applied to more sophisticated regularisers such as the mixture decay models of Hinton and Nowlan [57].
Reference: [11] <author> G.E.P. </author> <title> Box and G.C. Tiao (1964). A Bayesian approach to the importance of assumptions applied to the comparison of variances, </title> <journal> Biometrika 51, </journal> <pages> 153-167. </pages>
Reference-contexts: Since the 1960s, Jeffreys' model comparison methods have been applied and 10 BAYESIAN METHODS FOR ADAPTIVE MODELS extended in the economics literature [89] and by a small number of statisticians <ref> [10, 11, 12] </ref>. Only recently has this aspect of Bayesian analysis been further developed and applied to more complex problems in other fields. This chapter will review Bayesian model comparison, `regularisation', and noise estimation, by studying the problem of interpolating noisy data. <p> Then the evidence can be approximated by the height of the peak of the integrand P (Djw; H i )P (wjH i ) times its width, w: 3 Under this use of the word, Box and Tiao <ref> [10, 11, 12] </ref> must be counted as `modern' Bayesians. CHAPTER 2. BAYESIAN INTERPOLATION 13 w MP 0 w P (wjH i ) This figure shows the quantities that determine the Occam factor for a hypothesis H i having a single parameter w.
Reference: [12] <author> G.E.P. </author> <title> Box and G.C. Tiao (1968). A Bayesian approach to some outlier problems, </title> <journal> Biometrika 55, </journal> <pages> 119-129. </pages>
Reference-contexts: Since the 1960s, Jeffreys' model comparison methods have been applied and 10 BAYESIAN METHODS FOR ADAPTIVE MODELS extended in the economics literature [89] and by a small number of statisticians <ref> [10, 11, 12] </ref>. Only recently has this aspect of Bayesian analysis been further developed and applied to more complex problems in other fields. This chapter will review Bayesian model comparison, `regularisation', and noise estimation, by studying the problem of interpolating noisy data. <p> Then the evidence can be approximated by the height of the peak of the integrand P (Djw; H i )P (wjH i ) times its width, w: 3 Under this use of the word, Box and Tiao <ref> [10, 11, 12] </ref> must be counted as `modern' Bayesians. CHAPTER 2. BAYESIAN INTERPOLATION 13 w MP 0 w P (wjH i ) This figure shows the quantities that determine the Occam factor for a hypothesis H i having a single parameter w. <p> misfit, rather than 2 D = 2fiE D . 9 These error bars represent the uncertainty of the interpolant, and should not be confused with the typical scatter of noisy data points relative to the interpolant. 10 Bayesian inference of a slightly non-Gaussian distribution is performed in Box and Tiao <ref> [10, 12] </ref>. CHAPTER 2. BAYESIAN INTERPOLATION 17 a) c) These figures introduce a data set, `X', which is interpolated with a variety of models in this chapter. Notice that the density of data points is not uniform on the x-axis. <p> Bayesians adopt the healthy attitude of not sweeping them under the carpet. (b) With some thought, reasonable values can usually be assigned to subjective priors, and the degree of reasonable subjectivity in these assignments can be quantified, and the sensitivity of our inferences to these priors can be quantified <ref> [10, 12] </ref>. For example, a reasonable prior on an unknown standard deviation states that is unknown over a range of (32) orders of magnitude. This prior contributes a subjectivity of about 1 to the value of the log evidence. <p> The latter problem would also be relevant to regression problems where non-Gaussian noise models are thought appropriate; a definitive Bayesian attack on the problem of inferring a slightly non-Gaussian distribution has been made by Box and Tiao <ref> [10, 12] </ref>. Further applications in neural networks It remains to be investigated whether these methods scale up to real, larger problems. Also this framework has yet to be applied to more sophisticated regularisers such as the mixture decay models of Hinton and Nowlan [57].
Reference: [13] <author> G.E.P. </author> <title> Box and G.C. Tiao (1973). Bayesian inference in statistical analysis, </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: For a general review of Bayesian philosophy the reader is encouraged to read the excellent papers by Jaynes and Loredo [36, 47], and the recently reprinted text of Box and Tiao <ref> [13] </ref>. Since Jeffreys, the emphasis of most Bayesian probability theory has been `to formally utilize prior information' [8], i.e., to perform inference in a way that makes explicit the prior knowledge and ignorance that we have, which orthodox methods omit. <p> The central problem is that our Bayesian inferences are obtained assuming that the hypothesis space is right, but we have no Bayesian way of assessing whether our hypothesis space is right, apart from coming up with alternative hypothesis spaces with which comparisons can be made. Box and Tiao <ref> [13] </ref> share the view that `model criticism', an essential part of the modelling process, is not addressed by Bayesian inference. For example, the error bars discussed throughout this thesis are evaluated assuming that the model is true.
Reference: [14] <author> G.L. </author> <title> Bretthorst (1990). Bayesian Analysis. I. Parameter Estimation Using Quadrature NMR Models. II. Signal Detection and Model Selection. III. Applications to NMR, </title> <journal> J. </journal> <volume> Magnetic Resonance 88 3, </volume> <pages> 533-595. 88 BIBLIOGRAPHY </pages>
Reference-contexts: The same approach to regularisation has also been developed in part by Szeliski [81]. Bayesian model comparison is also discussed by Smith and Spiegelhalter [77] and by Bretthorst <ref> [14] </ref>, who has used Bayesian methods to push back the limits of NMR signal detection. The same Bayesian theory underlies the unsupervised classification system, AutoClass [31]. <p> has discontinuities in derivative (figure 2.4), and the second is a smoother 13 This approximation is valid when fl 1, and, in the spectrum of eigenvalues of fiB, the number of eigenvalues within e-fold of ^ff is t fl. 14 There are analytic methods for performing such integrals over fi <ref> [14] </ref>. CHAPTER 2. BAYESIAN INTERPOLATION 25 data set, `Y' (figure 2.8). In all the demonstrations, fi was not left as a free parameter, but was fixed to its known true value.
Reference: [15] <author> J.S. </author> <title> Bridle (1989). Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition, in Neuro-computing: algorithms, architectures and applications, </title> <editor> F. Fougelman-Soulie and J. Herault, editors, </editor> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Let the data set be D = fx (m) ; t m g, m = 1 : : : N . In a classification problem, each target t m is a binary (0/1) variable (more than two classes can also be handled <ref> [15] </ref>), and the activity of the output of a classifier is viewed as an estimate of the probability that t = 1. <p> It is well known that the natural objective function in this case is an information-based distance measure, rather than the sum of squared errors <ref> [15, 33, 34, 78] </ref>. A classification model H consists of a specification of its architecture A and the reg-ulariser R for its parameters w. <p> The calculation of the gradient and Hessian of G is as easy as for a quadratic E D , if the output unit's activation function is the traditional logistic f (a) = 1=(1 + e a ), or the generalised `softmax' in the case of more than two classes <ref> [15] </ref>. The appropriateness of a logisitic output function for a classifier is well known: it is the function that converts a log probability ratio a into a probability f (a).
Reference: [16] <editor> M.K. </editor> <title> Charter (1991). Quantifying drug absorption, </title> <booktitle> in [25], </booktitle> <pages> 245-252. </pages>
Reference-contexts: This radial basis function model is the same as the `intrinsic correlation' model of Charter, Gull, Skilling and Sibisi <ref> [16, 27, 70] </ref>. that for these models there is not an increasing Occam penalty for large numbers of parameters. The reason for this is that these extra parameters do not make the model any more powerful (for fixed ff and r). <p> I think that in principle this is the right thing to do (and, to their credit, some Bayesians have shown that it can be done <ref> [16] </ref>), but it is an approach that involves introducing and then eliminating a large amount of irrelevant baggage (the explicit parameterised form for the density). The details of this parameterisation will probably be hard to justify, and anyway the answer that we obtain is unlikely to depend sensitively on them.
Reference: [17] <author> R.T. </author> <title> Cox (1946). Probability, frequency, and reasonable expectation, </title> <journal> Am. J. Physics 14, </journal> <pages> 1-13. </pages>
Reference-contexts: to gather next Gather more data Decide whether to create new models Create new models Choose future actions 6 6 @ @R ? The two central boxes are the inference steps, where Bayesian methods can be applied. the philosophical argument, which goes deep down to the meaning of a probability <ref> [17, 36] </ref>; rather, this thesis will demonstrate that it is possible using Bayesian methods to solve problems in neural networks which have otherwise been found laborious or impossible. Since the 1960's, the Bayesian minority has been steadily growing, especially in the fields of economics [89] and pattern processing [20]. <p> Inference and decision are cleanly separated. The terms `Bayes risk' and `Bayes optimal' are not in the vocabulary of this thesis. The genealogy of this flavour is Laplace-Jeffreys-Cox-Jaynes-Gull <ref> [80, 38, 17, 36, 26] </ref>. A further difference between this approach and other work known as Bayesian is that the emphasis is on inverse rather than forward probability. Forward probability uses probabilities and priors, but it does not make use of Bayes' rule. <p> A Bayesian addresses any inference problem by using this equation. The hard line Bayesian position is that the Cox axioms <ref> [17] </ref> prove that consistent inference can only be Bayesian, and no other inference methods should be used, on pain of inconsistency [75]. However, I will develop the more moderate position that the Bayesian method is an important tool which should be used alongside other pragmatic modelling tools. <p> Bayesian methods, simultaneously conceived by Bayes [6] and Laplace [80], were first laid out in depth by the Cambridge geophysicist Sir Harold Jeffreys [38]. The logical basis for the Bayesian use of probabilities as measures of plausibility was subsequently established by Cox <ref> [17] </ref>, who proved that consistent inference in a closed hypothesis space can be mapped onto probabilities. For a general review of Bayesian philosophy the reader is encouraged to read the excellent papers by Jaynes and Loredo [36, 47], and the recently reprinted text of Box and Tiao [13].
Reference: [18] <author> A.R. Davies and R.S. </author> <title> Anderssen (1986). Optimization in the regularization of ill-posed problems, </title> <journal> J. Austral. Mat. Soc. Ser. </journal> <volume> B 28, </volume> <pages> 114-133. </pages>
Reference-contexts: If a poor regulariser is used, for example, one that is ill-matched to the statistics of the world, then the Bayesian choice of ff will often not be the best in terms of generalisation error; Bayesian methods are more sensitive to poor model assumptions than, say, cross-validation <ref> [18, 27, 32] </ref>. Such a failure occurs in chapter 3. What is our attitude to such a failure of Bayesian prediction? The failure of the evidence does not mean that we should discard Bayes' rule and use the generalisation error as our criterion for choosing ff.
Reference: [19] <author> J.S. Denker and Y. </author> <title> Le Cun (1991). Transforming neural-net output levels to probability distributions, </title> <booktitle> in Advances in neural information processing systems 3, </booktitle> <editor> ed. R.P. Lipp-mann et al., </editor> <address> 853-859, </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However, no stopping rule for weight deletion was offered other than measuring performance on a test set. Also Denker and Le Cun demonstrated how the Hessian of M can be used to assign error bars to the parameters of a network and to its outputs <ref> [19] </ref>. However, these error bars can only be quantified once fi is quantified, and how to do this without prior knowledge or extra data has not been demonstrated. <p> Notice that the error bars get much larger around the perimeter. They also increase slightly in the gap between the training regions. These pleasing properties are not obtained if the diagonal Hessian approximation of <ref> [19] </ref> is used. The above solution was created by a three layer network with 19 hidden units. Denker et al. have already discussed how to approximate the Hessian of E D for the purpose of evaluating weight saliency and for assigning error bars to weights and network outputs [19, 41]. <p> The above solution was created by a three layer network with 19 hidden units. Denker et al. have already discussed how to approximate the Hessian of E D for the purpose of evaluating weight saliency and for assigning error bars to weights and network outputs <ref> [19, 41] </ref>. The Hessian can be evaluated in the same way that backpropagation evaluates rE D (see [9] for a complete algorithm and the appendix of this chapter for a useful approximation). Alternatively A can be evaluated by numerical methods, for example second differences.
Reference: [20] <author> R. Duda and P. </author> <title> Hart (1973). Pattern Classification and Scene Analysis, </title> <publisher> Wiley. </publisher>
Reference-contexts: Since the 1960's, the Bayesian minority has been steadily growing, especially in the fields of economics [89] and pattern processing <ref> [20] </ref>.
Reference: [21] <author> M.A. </author> <month> El-Gamal </month> <year> (1991). </year> <title> The role of priors in active Bayesian learning in the sequential statistical decision framework, </title> <booktitle> in [25], </booktitle> <pages> 33-38. </pages>
Reference-contexts: Both these scenarios will benefit if we have ways of objectively estimating the utility of candidate data points. The problem of `active learning' or `sequential design' has been extensively studied in economic theory and statistics <ref> [21, 23] </ref>. Experimental design within a Bayesian framework using the Shannon information as an objective function has been studied by Lindley [44] and by Luttrell [48].
Reference: [22] <author> R.L. </author> <month> Eubank </month> <year> (1988). </year> <title> Spline smoothing and non-parametric regression, </title> <publisher> Marcel Dekker. </publisher>
Reference-contexts: Gull has demonstrated why the popular use of misfit criteria is incorrect and how Bayes sets these parameters [27]. The use of test data may be an unreliable technique unless large quantities of data are available. Cross-validation, the orthodox `method of choice' <ref> [22] </ref>, will be discussed more in section 2.6 and chapter 3. I will explain the Bayesian method of inferring ff and fi after first reviewing some statistics of misfit.
Reference: [23] <author> V.V. </author> <month> Fedorov </month> <year> (1972). </year> <title> Theory of optimal experiments, </title> <publisher> Academic press. </publisher>
Reference-contexts: Both these scenarios will benefit if we have ways of objectively estimating the utility of candidate data points. The problem of `active learning' or `sequential design' has been extensively studied in economic theory and statistics <ref> [21, 23] </ref>. Experimental design within a Bayesian framework using the Shannon information as an objective function has been studied by Lindley [44] and by Luttrell [48]. <p> This chapter uses similar information-based objective functions and discusses the problem of optimal data selection within the Bayesian framework for interpolation described in chapters 2 and 3. Most of the results in this chapter have direct analogs in Fedorov <ref> [23] </ref>, though the quantities involved have different 0 Chapter 4 of Ph.D. thesis `Bayesian Methods for Adaptive Models' by David MacKay, California Institute of Technology, submitted December 10 1991. 54 BAYESIAN METHODS FOR ADAPTIVE MODELS interpretations: for example, Fedorov's dispersion of an estimator becomes the Bayesian's posterior variance of the parameter. <p> The more complex task of selecting multiple new data points will not be addressed here, but the methods used can be generalised to solve this task, as is discussed in <ref> [23, 48] </ref>. CHAPTER 4. INFORMATION-BASED OBJECTIVE FUNCTIONS 55 The similar problem of choosing the x N+1 at which a vector of outputs t N+1 is measured will not be addressed either. The first and third definitions of information gain have both been studied in the abstract by Lindley [44]. <p> The first and third definitions of information gain have both been studied in the abstract by Lindley [44]. All three cases have been studied by Fedorov <ref> [23] </ref>, mainly in non-Bayesian terms. In this chapter, solutions will be obtained for the interpolation problem by using a Gaussian approximation and in some cases assuming that the new datum is a relatively weak piece of information. <p> Let us now see what property of a datum causes it to be maximally informative. The new entropy S N+1 is equal to 1 2 log m 2 det A N+1 , neglecting additive constants. This determinant can be analytically evaluated <ref> [23] </ref>, using the identities [A + figg T ] 1 fiA 1 gg T A 1 and det [A + figg T ] = (det A)(1+fig T A 1 g); (4.8) from which we obtain: Total information gain = 1 log m 2 det A = 2 In the product fig <p> This rule is the same as that resulting from the `D-optimal' and `minimax' design criteria <ref> [23] </ref>. For many interpolation models, the error bars are largest beyond the most extreme points where data have been gathered. <p> This case also includes the generalisation to more than one output variable y; however the full generalisation, to optimisation of an experiment in which many measurements are made, will not be made here (see Fedorov <ref> [23] </ref> and Luttrell [48]). The preceding objective function, the information about y (u) , can be generalised in several ways, some of which lead to dissatisfactory results. First objective function for multiple points An obvious objective function is the joint entropy of the output variables that we are interested in. <p> This is the same as the `Q-optimal' design <ref> [23] </ref>. <p> The first term favours measurements where 1 and 2 are well separated; the second term favours places where 2 1 and 2 2 differ. Thus the third task has been solved. Fedorov <ref> [23] </ref> makes a similar derivation but he uses a poor approximation which loses the second term. 4.6 Demonstration and Discussion A data set consisting of 21 points from a one-dimensional interpolation problem was interpolated with an eight hidden unit neural network. <p> The solutions apply to linear and non-linear interpolation models, but depend on the validity of a local Gaussian approximation. Each solution has a direct analog in the non-Bayesian literature <ref> [23] </ref>, and generalisations to multiple measurements and multiple output variables can be found there, and also in [48]. In each case a function of x has been derived that predicts the information gain for a measurement at that x.
Reference: [24] <author> K. </author> <title> Fukunaga (1972). Introduction to statistical pattern recognition, </title> <publisher> Academic press. </publisher>
Reference-contexts: This thesis therefore takes some time to thoroughly review the flavour of Bayesianism that I am using. To some, the word Bayesian denotes a decision strategy that minimises the expectation of a cost <ref> [24] </ref>; to others, a Bayesian is someone who tries to incorporate prior knowledge into their inference and decision process [8]. In fact, according to Good, there are 46656 varieties of Bayesian! 1 This thesis presents a flavour of Bayesianism in which decisions are not involved. <p> It is here that Bayesian methods are totally different from orthodox sampling theory methods. Indeed, when regression and density estimation are discussed in most statistics texts (for example <ref> [24] </ref>), the task of model comparison is virtually ignored; no general orthodox method exists for solving this problem.
Reference: [25] <editor> W.T. Grandy, Jr. and L.H. Schick, eds. </editor> <year> (1991). </year> <title> Maximum Entropy and Bayesian Methods, </title> <type> Laramie, </type> <institution> Wyoming, </institution> <address> 1990, </address> <publisher> Kluwer. </publisher>
Reference: [26] <author> S.F. </author> <title> Gull (1988). Bayesian inductive inference and maximum entropy, </title> <booktitle> in Maximum Entropy and Bayesian Methods in science and engineering, </booktitle> <volume> vol. 1: </volume> <booktitle> Foundations, </booktitle> <editor> G.J. Er-ickson and C.R. Smith, eds., </editor> <publisher> Kluwer. </publisher>
Reference-contexts: quantify this intuitive principle so as to make it an objective part of our modelling method? Bayesian probability theory provides a framework for inductive inference which has been called `common sense reduced to calculation'; it is a poorly known fact that Bayesian methods actually embody Occam's razor automatically and quantitatively <ref> [26, 38] </ref>. Bayesian model comparison is the central theme of this thesis. In particular, the power of the Bayesian Occam's razor is demonstrated on `neural networks'. Neural networks are novel modelling tools capable of `learning from examples'. <p> Inference and decision are cleanly separated. The terms `Bayes risk' and `Bayes optimal' are not in the vocabulary of this thesis. The genealogy of this flavour is Laplace-Jeffreys-Cox-Jaynes-Gull <ref> [80, 38, 17, 36, 26] </ref>. A further difference between this approach and other work known as Bayesian is that the emphasis is on inverse rather than forward probability. Forward probability uses probabilities and priors, but it does not make use of Bayes' rule. <p> Bayesian methods automatically and quantitatively embody Occam's razor <ref> [26, 38] </ref>, without the introduction of ad hoc penalty terms. Complex models are automatically self-penalising under Bayes' rule. Figure 2.2 gives the basic intuition for why this should be expected; the rest of this chapter will explore this property in depth. <p> This chapter will review Bayesian model comparison, `regularisation', and noise estimation, by studying the problem of interpolating noisy data. The Bayesian framework I will describe for these tasks is due to Gull and Skilling <ref> [26, 27, 29, 70, 74] </ref>, who have used Bayesian methods to achieve the state of the art in image reconstruction. The same approach to regularisation has also been developed in part by Szeliski [81]. <p> i ) ' P (D jw MP ; H i ) P (w MP jH i ) w : Evidence ' Best fit likelihood Occam factor (2.5) Thus the evidence is found by taking the best fit likelihood that the model can achieve and multiplying it by an `Occam factor' <ref> [26] </ref>, which is a term with magnitude less than one that penalises H i for having the parameter w. Interpretation of the Occam factor The quantity w is the posterior uncertainty in w. <p> (w MP jH i ) = 1 0 w , and Occam factor = w ; i.e., the ratio of the posterior accessible volume of H i 's parameter space to the prior accessible volume, or the factor by which H i 's hypothesis space collapses when the data arrive <ref> [26, 38] </ref>. The model H i can be viewed as being composed of a certain number of equivalent submodels, of which only one survives when the data arrive. The Occam factor is the inverse of that number. <p> Rather, we invent as many priors (regularisers) as we want, and allow the data to tell us which prior is most probable. Having said this, experience recommends that the `maximum entropy principle' and other respected guides should be consulted when inventing these priors (see <ref> [26] </ref>, for example). Evaluating the evidence for H As ff and fi vary, a single evidence maximum is obtained, at ^ff; ^ fi (at least for quadratic E D and E W ). <p> We note in table 2.1 the value of the maximum evidence achieved by these models, and move on to alternative models. The choice of orthonormal Legendre polynomials described above was motivated by a maximum entropy argument <ref> [26] </ref>. Models using other polynomial basis sets have also been tried. For less well motivated basis sets such as Hermite polynomials, it was found that the Occam factors were far bigger and the evidence was substantially smaller.
Reference: [27] <author> S.F. </author> <title> Gull (1989). Developments in Maximum entropy data analysis, </title> <booktitle> in [71], </booktitle> <pages> 53-71. </pages>
Reference-contexts: This chapter will review Bayesian model comparison, `regularisation', and noise estimation, by studying the problem of interpolating noisy data. The Bayesian framework I will describe for these tasks is due to Gull and Skilling <ref> [26, 27, 29, 70, 74] </ref>, who have used Bayesian methods to achieve the state of the art in image reconstruction. The same approach to regularisation has also been developed in part by Szeliski [81]. <p> Neither the second nor the third level of inference can be successfully executed without Occam's razor. The Bayesian theory of the second and third levels of inference has only recently been worked out <ref> [27] </ref>; this chapter's goal is to review that framework. Section 2.4 will describe the Bayesian method of inferring ff and fi; section 2.5 will describe Bayesian model comparison for the interpolation problem. <p> Orthodox statistics has ways of assigning values to such parameters, based for example on misfit criteria, the use of test data, and cross-validation. Gull has demonstrated why the popular use of misfit criteria is incorrect and how Bayes sets these parameters <ref> [27] </ref>. The use of test data may be an unreliable technique unless large quantities of data are available. Cross-validation, the orthodox `method of choice' [22], will be discussed more in section 2.6 and chapter 3. <p> ff; fi? It is not satisfactory to simply maximise the likelihood or the posterior probability simultaneously over w, ff and fi; the posterior and likelihood both have skew peaks such that the maximum likelihood value for the parameters is not in the same place as most of the posterior probability <ref> [27] </ref>. To get a feeling for this here is a more familiar problem: examine the posterior probability for the parameters of a Gaussian (; ) given N samples: the maximum likelihood value for is N , but the most probable value for (found by integrating over ) is N1 . <p> This means that Z M is the Gaussian integral: Z M = e M MP (2) k=2 det 1 In many cases where the regulariser is not quadratic (for example, entropy-based), this Gaussian approximation is still servicable <ref> [27] </ref>. <p> Properties of the evidence maximum The maximum over ff; fi of P (Djff; fi; H) = Z M (ff; fi)=(Z W (ff)Z D (fi)) has some remarkable properties which give deeper insight into this Bayesian approach. The results of this section are useful both numerically and intuitively. Following Gull <ref> [27] </ref>, we transform to the basis in which the Hessian of E W is the identity, rrE W = I. <p> The quantity N fl may be called the effective number of degrees of freedom. Note that the value of 2 D only enters into the determination of fi: misfit criteria have no role in the Bayesian choice of ff <ref> [27] </ref>. In summary, at the optimum value of ff and fi, 2 W = fl, 2 D = N fl. Notice that this implies that the total misfit M = ffE W +fiE D satisfies the simple equation 2M = N . <p> Inference of an input-dependent noise level fi (x) will be demonstrated in a future publication. These results generalise to the case where there are two or more separate regularisers with independent regularising constants fff c g <ref> [27] </ref>. In this case, each regulariser has a number of good parameter measurements fl c associated with it. Multiple regularisers will be used for neural networks in chapter 3. <p> This radial basis function model is the same as the `intrinsic correlation' model of Charter, Gull, Skilling and Sibisi <ref> [16, 27, 70] </ref>. that for these models there is not an increasing Occam penalty for large numbers of parameters. The reason for this is that these extra parameters do not make the model any more powerful (for fixed ff and r). <p> If a poor regulariser is used, for example, one that is ill-matched to the statistics of the world, then the Bayesian choice of ff will often not be the best in terms of generalisation error; Bayesian methods are more sensitive to poor model assumptions than, say, cross-validation <ref> [18, 27, 32] </ref>. Such a failure occurs in chapter 3. What is our attitude to such a failure of Bayesian prediction? The failure of the evidence does not mean that we should discard Bayes' rule and use the generalisation error as our criterion for choosing ff. <p> If one only uses the generalisation error as a criterion for model comparison, one is denied this mechanism for learning. The development of maximum entropy image deconvolution was held up for years because no-one used the Bayesian choice of ff; once the Bayesian choice of ff was used <ref> [27] </ref>, the results obtained were most dissatisfactory, making clear what a poor regulariser was being used; this motivated an immediate search for alternative priors; the new, more probable priors discovered by this search are now at the heart of the state of the art in image deconvolution [88]. <p> My work is based on the same probabilistic framework, and extends it using concepts and techniques adapted from Gull and Skilling's Bayesian image reconstruction methods <ref> [27] </ref>. This chapter also adopts a shift in emphasis from Tishby et al.'s paper. Their work concentrated on predicting the average generalisation ability of one network trained on a task drawn from a known prior ensemble of tasks. This is called forward probability.
Reference: [28] <author> S.F. </author> <title> Gull (1989). Bayesian data analysis: straight-line fitting, </title> <booktitle> in [71], </booktitle> <pages> 511-518. </pages>
Reference-contexts: A modern Bayesian approach to priors It should be pointed out that the emphasis of this modern 3 Bayesian approach is not on the inclusion of priors into inference. There is not one significant `subjective prior' in this entire chapter. (For problems where significant subjective priors do arise see <ref> [28, 73] </ref>.) The emphasis is on the idea that consistent degrees of preference for alternative hypotheses are represented by probabilities, and relative preferences for models are assigned by evaluating those probabilities. <p> I am not examining the case where the independent variables are also noisy. This different and more difficult problem has been studied for the case of straight line-fitting by Gull <ref> [28] </ref>. Let us assume that the data set to be interpolated is a set of pairs D = fx m ; t m g, where m = 1 : : : N is a label running over the pairs.
Reference: [29] <author> S.F. Gull and J. </author> <title> Skilling (1991). Quantified Maximum Entropy. MemSys5 User's manual, M.E.D.C., 33 North End, Royston, </title> <address> SG8 6NR, England. </address>
Reference-contexts: This chapter will review Bayesian model comparison, `regularisation', and noise estimation, by studying the problem of interpolating noisy data. The Bayesian framework I will describe for these tasks is due to Gull and Skilling <ref> [26, 27, 29, 70, 74] </ref>, who have used Bayesian methods to achieve the state of the art in image reconstruction. The same approach to regularisation has also been developed in part by Szeliski [81].
Reference: [30] <author> I. Guyon, V.N. Vapnik, B.E. Boser, L.Y. Bottou and S.A. </author> <month> Solla </month> <year> (1992). </year> <title> Structural risk minimization for character recognition, </title> <booktitle> in Advances in neural information processing systems 4, </booktitle> <editor> ed. J.E. Moody, S.J. Hanson and R.P. Lippmann, </editor> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: But for the toy problems I have studied, neither of these criteria has a better correlation with the generalisation error than that achieved by the evidence. Theories based on the V-C dimension lead to structural risk minimisation criteria <ref> [30] </ref>, which seem better correlated with generalisation error.
Reference: [31] <author> R. Hanson, J. Stutz and P. </author> <title> Cheeseman (1991). Bayesian classification theory, </title> <institution> NASA Ames TR FIA-90-12-7-01. </institution>
Reference-contexts: Bayesian model comparison is also discussed by Smith and Spiegelhalter [77] and by Bretthorst [14], who has used Bayesian methods to push back the limits of NMR signal detection. The same Bayesian theory underlies the unsupervised classification system, AutoClass <ref> [31] </ref>. The fact that Bayesian model comparison embodies Occam's razor has been rediscovered by Kashyap in the context of modelling time series [40]; his paper includes a thorough discussion of how Bayesian model comparison is different from orthodox `Hypothesis testing'. <p> For more general statistical models we still expect the posterior to be dominated by locally Gaussian peaks on account of the central limit theorem [84]. Multiple maxima which arise in more complex models complicate the analysis, but Bayesian methods can still successfully be applied <ref> [31, 50, 55] </ref>. 12 BAYESIAN METHODS FOR ADAPTIVE MODELS the `Sure Thing' hypothesis, c fl E.T Jaynes, which is the hypothesis that the data set will be D, the precise data set that actually occurred; the evidence for the Sure Thing hypothesis is huge. <p> The same method of chopping up a complex model space is used in the unsupervised classification system, AutoClass <ref> [31] </ref>. Having adopted this slight shift in objective, it turns out that to set ff and fi and to compare alternative solutions to a learning problem, the integral we now need to evaluate is a local version of Z M .
Reference: [32] <author> D. Haussler, M. Kearns and R. </author> <title> Schapire (1991). Bounds on the sample complexity of Bayesian learning using information theory and the V-C dimension, </title> <type> preprint. </type>
Reference-contexts: Forward probability uses probabilities and priors, but it does not make use of Bayes' rule. Forward probability is used for example to evaluate the typical performance of a modelling procedure averaged over different data sets from a defined ensemble <ref> [82, 32] </ref>. Here the philosophy is, using inverse probability, to evaluate the relative plausibilities of several alternative models in the light of the single data set that we actually observe. 1 Good was unaware of the Bayesian Occam's razor. CHAPTER 1. <p> If a poor regulariser is used, for example, one that is ill-matched to the statistics of the world, then the Bayesian choice of ff will often not be the best in terms of generalisation error; Bayesian methods are more sensitive to poor model assumptions than, say, cross-validation <ref> [18, 27, 32] </ref>. Such a failure occurs in chapter 3. What is our attitude to such a failure of Bayesian prediction? The failure of the evidence does not mean that we should discard Bayes' rule and use the generalisation error as our criterion for choosing ff. <p> V-C dimension is most often applied to classification problems; the evidence, on the other hand, can be evaluated equally easily for both interpolation and classification problems. V-C dimension is a worst case measure, so it yields different results from Bayesian analysis <ref> [32] </ref>. For example, V-C dimension is indifferent to the use of regularisers like (3.2), and to the value of ff, because the use of such regularisers does not rule out absolutely any particular network parameters.
Reference: [33] <author> G.E. Hinton and T.J. </author> <title> Sejnowski (1986). Learning and relearning in Boltzmann machines, in Parallel Distributed Processing, </title> <editor> Rumelhart et al., </editor> <publisher> MIT Press. BIBLIOGRAPHY 89 </publisher>
Reference-contexts: It is moderately common for extra regularising terms E W (w) to be added to E D ; for example, terms which penalise large weights may be introduced, in the hope of achieving a smoother or simpler mapping <ref> [33, 39, 57, 67, 87] </ref>. Some of the `hints' in [2] also fall into the category of additive weight-dependent energies. <p> It is well known that the natural objective function in this case is an information-based distance measure, rather than the sum of squared errors <ref> [15, 33, 34, 78] </ref>. A classification model H consists of a specification of its architecture A and the reg-ulariser R for its parameters w.
Reference: [34] <author> J.J. </author> <title> Hopfield (1987). Learning algorithms and probability distributions in feed-forward and feed-back networks, </title> <booktitle> Proc. </booktitle> <institution> Natl. Acad. Sci. </institution> <address> USA 84, </address> <pages> 8429-33. </pages>
Reference-contexts: It is well known that the natural objective function in this case is an information-based distance measure, rather than the sum of squared errors <ref> [15, 33, 34, 78] </ref>. A classification model H consists of a specification of its architecture A and the reg-ulariser R for its parameters w.
Reference: [35] <author> J-N. Hwang, J.J. Choi, S. Oh, </author> <title> and R.J. Marks II (1991). Query-based learning applied to partially trained multilayer perceptrons, </title> <journal> IEEE Trans. on neural networks 2 1, </journal> <pages> 131-136. </pages>
Reference-contexts: This work was directly stimulated by a presentation given by John Skilling at Maxent 91 [76]. Recent work in the neural networks literature on active data selection, also known as `query learning', has concentrated on slightly different problems: The work of Baum [5] and Hwang et al. <ref> [35] </ref> relates to perfectly separable classification problems only; in both these papers a sensible query-based learning algorithm is proposed, and empirical results of the algorithm are reported; Baum also gives a convergence proof. <p> Several papers have suggested strategies for this active learning problem, for example Hwang et al. <ref> [35] </ref> propose that samples should be made on and near the current decision boundaries. This strategy and that of Baum [5] are both human-designed strategies and it is not clear what objective function if any they optimise, nor is it clear how the strategies could be improved.
Reference: [36] <author> E.T. </author> <title> Jaynes (1986). Bayesian methods: general background, in Maximum Entropy and Bayesian Methods in applied statistics, </title> <editor> ed. J.H. Justice, </editor> <publisher> C.U.P.. </publisher>
Reference-contexts: to gather next Gather more data Decide whether to create new models Create new models Choose future actions 6 6 @ @R ? The two central boxes are the inference steps, where Bayesian methods can be applied. the philosophical argument, which goes deep down to the meaning of a probability <ref> [17, 36] </ref>; rather, this thesis will demonstrate that it is possible using Bayesian methods to solve problems in neural networks which have otherwise been found laborious or impossible. Since the 1960's, the Bayesian minority has been steadily growing, especially in the fields of economics [89] and pattern processing [20]. <p> Inference and decision are cleanly separated. The terms `Bayes risk' and `Bayes optimal' are not in the vocabulary of this thesis. The genealogy of this flavour is Laplace-Jeffreys-Cox-Jaynes-Gull <ref> [80, 38, 17, 36, 26] </ref>. A further difference between this approach and other work known as Bayesian is that the emphasis is on inverse rather than forward probability. Forward probability uses probabilities and priors, but it does not make use of Bayes' rule. <p> For a general review of Bayesian philosophy the reader is encouraged to read the excellent papers by Jaynes and Loredo <ref> [36, 47] </ref>, and the recently reprinted text of Box and Tiao [13]. <p> This is the way in which alternative regularisers are compared, for example. If we try one model and obtain awful predictions, we have learnt something. `A failure of Bayesian prediction is an opportunity to learn' <ref> [36] </ref>, and we are able to come back to the same data set with new models, using new priors for example. Evaluating the evidence Let us now explicitly study the evidence to gain insight into how the Bayesian Occam's razor works. <p> However, there are two scenarios in which we are able to actively select training data. In the first, data measurements are relatively expensive or slow, and we want to know where to look next so as to learn as much as possible. According to Jaynes <ref> [36] </ref>, Bayesian reasoning was first applied to this problem two centuries ago by Laplace, who in consequence made more important discoveries in celestial mechanics than anyone else.
Reference: [37] <author> W.H. Jefferys and J.O. </author> <title> Berger (1992). Ockham's razor and Bayesian analysis, </title> <journal> American Scientist 80, </journal> <pages> 64-72. </pages>
Reference-contexts: It is pleasing to note the current appearance of an increasing number of publications using Bayesian model comparison <ref> [37, 53] </ref>. As the quantities of data collected throughout science and engineering continue to increase, and the computational power and techniques available to model that data also multiply, I believe Bayesian methods will prove an ever more important tool for refining our modelling abilities.
Reference: [38] <author> H. </author> <title> Jeffreys (1939). Theory of Probability, </title> <publisher> Oxford Univ. Press. </publisher>
Reference-contexts: quantify this intuitive principle so as to make it an objective part of our modelling method? Bayesian probability theory provides a framework for inductive inference which has been called `common sense reduced to calculation'; it is a poorly known fact that Bayesian methods actually embody Occam's razor automatically and quantitatively <ref> [26, 38] </ref>. Bayesian model comparison is the central theme of this thesis. In particular, the power of the Bayesian Occam's razor is demonstrated on `neural networks'. Neural networks are novel modelling tools capable of `learning from examples'. <p> In the process several enhancements to current neural network methods arise. 1.2 What is Bayesian modelling? Bayesian methods for inductive inference were first developed in detail early this century by the Cambridge geophysicist, Sir Harold Jeffreys <ref> [38] </ref>. At that time, Jeffreys' ideas were opposed by Fisher and others, and since then a debate has persisted between the `orthodox' view of statistics and the minority Bayesian camp. <p> Inference and decision are cleanly separated. The terms `Bayes risk' and `Bayes optimal' are not in the vocabulary of this thesis. The genealogy of this flavour is Laplace-Jeffreys-Cox-Jaynes-Gull <ref> [80, 38, 17, 36, 26] </ref>. A further difference between this approach and other work known as Bayesian is that the emphasis is on inverse rather than forward probability. Forward probability uses probabilities and priors, but it does not make use of Bayes' rule. <p> Bayesian methods automatically and quantitatively embody Occam's razor <ref> [26, 38] </ref>, without the introduction of ad hoc penalty terms. Complex models are automatically self-penalising under Bayes' rule. Figure 2.2 gives the basic intuition for why this should be expected; the rest of this chapter will explore this property in depth. <p> Figure 2.2 gives the basic intuition for why this should be expected; the rest of this chapter will explore this property in depth. Bayesian methods, simultaneously conceived by Bayes [6] and Laplace [80], were first laid out in depth by the Cambridge geophysicist Sir Harold Jeffreys <ref> [38] </ref>. The logical basis for the Bayesian use of probabilities as measures of plausibility was subsequently established by Cox [17], who proved that consistent inference in a closed hypothesis space can be mapped onto probabilities. <p> (w MP jH i ) = 1 0 w , and Occam factor = w ; i.e., the ratio of the posterior accessible volume of H i 's parameter space to the prior accessible volume, or the factor by which H i 's hypothesis space collapses when the data arrive <ref> [26, 38] </ref>. The model H i can be viewed as being composed of a certain number of equivalent submodels, of which only one survives when the data arrive. The Occam factor is the inverse of that number.
Reference: [39] <author> C. Ji, R.R. Snapp and D. </author> <title> Psaltis (1990). Generalizing smoothness constraints from discrete samples, </title> <booktitle> Neural Computation 2 2, </booktitle> <pages> 188-197. </pages>
Reference-contexts: It is moderately common for extra regularising terms E W (w) to be added to E D ; for example, terms which penalise large weights may be introduced, in the hope of achieving a smoother or simpler mapping <ref> [33, 39, 57, 67, 87] </ref>. Some of the `hints' in [2] also fall into the category of additive weight-dependent energies. <p> What is lacking The above procedures include a host of free parameters such as the choice of neural network architecture, and of the regularising constant ff. There are not yet established ways of objectively setting these parameters, though there are many rules of thumb (see <ref> [39, 87] </ref> for examples). One popular way of comparing networks trained with different parameter values is to assess their performance by measuring the error on an unseen test set or by similar cross validation techniques. <p> Thus the true width of the component at the origin ought to be zero; it is only set to a non-zero value as a computational artifice. This view, that weight decay is intended to switch off weights, is apparently shared by other workers <ref> [39, 87] </ref>. Under this interpretation, there is no reason to suppose that the Bayesian choice of the width of this component should be appropriate. 1 (The width of the other broad compo 1 All the same, Nowlan and Hinton have applied the Bayesian procedure to networks predicting sunspot CHAPTER 7.
Reference: [40] <author> R.L. </author> <title> Kashyap (1977). A Bayesian comparison of different classes of dynamic models using empirical data, </title> <journal> IEEE Transactions on Automatic Control AC-22 5, </journal> <pages> 715-727. </pages>
Reference-contexts: The same Bayesian theory underlies the unsupervised classification system, AutoClass [31]. The fact that Bayesian model comparison embodies Occam's razor has been rediscovered by Kashyap in the context of modelling time series <ref> [40] </ref>; his paper includes a thorough discussion of how Bayesian model comparison is different from orthodox `Hypothesis testing'.
Reference: [41] <author> Y. Le Cun, J.S. Denker and S.S. </author> <month> Solla </month> <year> (1990). </year> <title> Optimal Brain Damage, </title> <booktitle> in Advances in neural information processing systems 2, </booktitle> <editor> ed. David S. Touretzky, </editor> <address> 598-605, </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However, it is not clear whether this will lead to a practical technique for choosing between alternative network architectures for real data sets. Le Cun et al. have demonstrated how to estimate the `saliency' of a weight, which is the change in M when the weight is deleted <ref> [41] </ref>. They have used this measure successfully to simplify large neural networks. However, no stopping rule for weight deletion was offered other than measuring performance on a test set. <p> The above solution was created by a three layer network with 19 hidden units. Denker et al. have already discussed how to approximate the Hessian of E D for the purpose of evaluating weight saliency and for assigning error bars to weights and network outputs <ref> [19, 41] </ref>. The Hessian can be evaluated in the same way that backpropagation evaluates rE D (see [9] for a complete algorithm and the appendix of this chapter for a useful approximation). Alternatively A can be evaluated by numerical methods, for example second differences.
Reference: [42] <author> W.T. Lee and M.F. </author> <title> Tenorio (1991). On Optimal Adaptive Classifier Design Criterion | How many hidden units are necessary for an optimal neural network classifier?, </title> <institution> Purdue University TR-EE-91-5. </institution>
Reference-contexts: A future publication [52] will demonstrate that the Bayesian framework for model comparison can be applied to these problems too. Relation to V-C dimension Some papers advocate the use of V-C dimension [1] as a criterion for penalising overcomplex models <ref> [2, 42] </ref>. V-C dimension is most often applied to classification problems; the evidence, on the other hand, can be evaluated equally easily for both interpolation and classification problems. V-C dimension is a worst case measure, so it yields different results from Bayesian analysis [32].
Reference: [43] <author> E. Levin, N. Tishby and S. </author> <month> Solla </month> <year> (1989). </year> <title> A statistical approach to learning and generalization in layered neural networks, </title> <booktitle> COLT '89: 2nd workshop on computational learning theory, </booktitle> <pages> 245-260. </pages>
Reference-contexts: The error bars at a single point x are given by var y (x) = T A 1 . These error bars are directly related to the expected generalisation error at x, assuming that the model is true, evaluated in <ref> [43, 82] </ref>. The error bars are also related to the expected information gain per data point (chapter 4). Actually we have access to the full covariance information for the entire interpolant, not just the pointwise error bars. <p> This framework offers some partial enhancements for backprop methods: The work of Levin et al. <ref> [43] </ref> makes it possible to predict the average generalisation ability of neural networks trained on one of a defined class of problems. However, it is not clear whether this will lead to a practical technique for choosing between alternative network architectures for real data sets.
Reference: [44] <author> D.V. </author> <title> Lindley (1956). On a measure of the information provided by an experiment, </title> <journal> Ann. Math. Statist. </journal> <volume> 27, </volume> <pages> 986-1005. </pages>
Reference-contexts: The problem of `active learning' or `sequential design' has been extensively studied in economic theory and statistics [21, 23]. Experimental design within a Bayesian framework using the Shannon information as an objective function has been studied by Lindley <ref> [44] </ref> and by Luttrell [48]. A distinctive feature of this approach is that it renders the optimisation of the experimental design independent of the `tests' that are to be applied to the data and the loss functions associated with any decisions. <p> CHAPTER 4. INFORMATION-BASED OBJECTIVE FUNCTIONS 55 The similar problem of choosing the x N+1 at which a vector of outputs t N+1 is measured will not be addressed either. The first and third definitions of information gain have both been studied in the abstract by Lindley <ref> [44] </ref>. All three cases have been studied by Fedorov [23], mainly in non-Bayesian terms. In this chapter, solutions will be obtained for the interpolation problem by using a Gaussian approximation and in some cases assuming that the new datum is a relatively weak piece of information. <p> CHAPTER 4. INFORMATION-BASED OBJECTIVE FUNCTIONS 57 Thus the two candidate information measures are equivalent for our purposes. This proof also implicitly demonstrates that E (S) is independent of the measure m (w). Other properties of E (S) are proved in <ref> [44] </ref>. The rest of this chapter will use S as the information measure, with m (w) set to a constant. 4.3 Maximising total information gain Let us now solve the first task: how to choose x N+1 so that the expected information gain about w is maximised. <p> Then the parameter vector w and the values of the interpolant fy (u) g are in one to one (locally) linear correspondence with each other. This means that the change in entropy of P (fy (u) g) is identical to the change in entropy of P (w) <ref> [44] </ref>. This can be confirmed by substitution of Y 1 = G 1 AG 1 T into (4.12), which yields (4.9). <p> And this function could form the basis of a stopping rule, i.e., a rule for deciding whether to gather more data, given a desired exchange rate of information gain per measurement <ref> [44] </ref>. A possible weakness of these information-based approaches is that they estimate the utility of a measurement assuming that the model is correct. This might lead to undesirable results.
Reference: [45] <author> D.V. </author> <title> Lindley (1970). Bayesian analysis in regression problems, in Bayesian statistics, D.L. </title> <editor> Meyer and R.O. Collier, eds., </editor> <publisher> Peacock publishers. </publisher>
Reference-contexts: Thirdly, Bayes' rule provides no mechanism for `alternative-free tests' of a hypothesis space. This reservation about Bayesian methods has also been expressed by Lindley <ref> [45] </ref>. Hard line Bayesians would retort that there is no such thing as an alternative-free test, and certainly most classical alternative-free tests do have an implicit alternative. <p> to that of the evidence! More work is called for on the relationship between the evidence, cross-validation and generalisation ability to understand these results. 7.3 Having to make too much explicit Statistical problems that are precisely enough stated for the sampling theory school can be too vague for a Bayesian <ref> [45] </ref>. When the Bayesian adds additional constraints to such a problem to make it solveable, he comes under fire for making assumptions that may be, in detail, not justified. `Order statistics' provide an example of such a problem.
Reference: [46] <author> D.V. </author> <title> Lindley (1972). Bayesian statistics, a review, </title> <institution> Society for Industrial and Applied Mathematics, </institution> <address> Philadelphia. </address>
Reference-contexts: Here are some answers to this question. (a) Any coherent method of assigning a preference to alternatives must implicitly assign such priors <ref> [46] </ref>.
Reference: [47] <author> T.J. </author> <month> Loredo </month> <year> (1989). </year> <title> From Laplace to supernova SN 1987A: Bayesian inference in astrophysics, in Maximum Entropy and Bayesian Methods, </title> <editor> ed. P. Fougere, </editor> <publisher> Kluwer. </publisher>
Reference-contexts: For a general review of Bayesian philosophy the reader is encouraged to read the excellent papers by Jaynes and Loredo <ref> [36, 47] </ref>, and the recently reprinted text of Box and Tiao [13]. <p> Bayesian inference is consistent with this principle; there is no need to undo biases introduced by the data collecting strategy, because it is not possible for such biases to be introduced | as long as we perform inference using all the data gathered <ref> [8, 47] </ref>. When the models are concerned with estimating the distribution of output variables t given input variables x, we are allowed to look at the x value of a datum, and decide whether or not to include the datum in the data set. <p> For example, a classical test of a parameter being zero has as an implicit alternative the hypothesis that the parameter has a value in an interval with a derivable prior width <ref> [47] </ref>. But I do believe that we perform alternative-free tests. Often, we become dissatisfied with a theory because it seems to be making unusually poor predictions. This prompts us to start searching for superior theories.
Reference: [48] <author> S.P.Luttrell (1985). </author> <title> The use of transinformation in the design of data sampling schemes for inverse problems, Inverse Problems 1, </title> <type> 199-218. </type>
Reference-contexts: The problem of `active learning' or `sequential design' has been extensively studied in economic theory and statistics [21, 23]. Experimental design within a Bayesian framework using the Shannon information as an objective function has been studied by Lindley [44] and by Luttrell <ref> [48] </ref>. A distinctive feature of this approach is that it renders the optimisation of the experimental design independent of the `tests' that are to be applied to the data and the loss functions associated with any decisions. <p> The more complex task of selecting multiple new data points will not be addressed here, but the methods used can be generalised to solve this task, as is discussed in <ref> [23, 48] </ref>. CHAPTER 4. INFORMATION-BASED OBJECTIVE FUNCTIONS 55 The similar problem of choosing the x N+1 at which a vector of outputs t N+1 is measured will not be addressed either. The first and third definitions of information gain have both been studied in the abstract by Lindley [44]. <p> This case also includes the generalisation to more than one output variable y; however the full generalisation, to optimisation of an experiment in which many measurements are made, will not be made here (see Fedorov [23] and Luttrell <ref> [48] </ref>). The preceding objective function, the information about y (u) , can be generalised in several ways, some of which lead to dissatisfactory results. First objective function for multiple points An obvious objective function is the joint entropy of the output variables that we are interested in. <p> The solutions apply to linear and non-linear interpolation models, but depend on the validity of a local Gaussian approximation. Each solution has a direct analog in the non-Bayesian literature [23], and generalisations to multiple measurements and multiple output variables can be found there, and also in <ref> [48] </ref>. In each case a function of x has been derived that predicts the information gain for a measurement at that x. This function can be used to search for an optimal value of x (which in large-dimensional input spaces may not be a trivial task).
Reference: [49] <author> D.J.C. </author> <title> MacKay (1991). Bayesian interpolation, </title> <note> Neural Computation 4 3 415-447; Chapter 2 of this dissertation. </note>
Reference-contexts: What obstacles remain to prevent us from evaluating the local Z fl M ? We need to evaluate or approximate the inverse Hessian of M , and we need to evaluate or approximate its determinant and/or trace <ref> [49] </ref>. 3 Bayesian model comparison is performed by evaluating and comparing the evidence for alternative models. Gull and Skilling defined the evidence for a model H to be P (DjH). The existence of multiple minima in neural network parameter space complicates model comparison.
Reference: [50] <author> D.J.C. </author> <title> MacKay (1991). A practical Bayesian framework for backprop networks, </title> <note> Neural Computation 4 3 448-472; Chapter 3 of this dissertation. 90 BIBLIOGRAPHY </note>
Reference-contexts: For more general statistical models we still expect the posterior to be dominated by locally Gaussian peaks on account of the central limit theorem [84]. Multiple maxima which arise in more complex models complicate the analysis, but Bayesian methods can still successfully be applied <ref> [31, 50, 55] </ref>. 12 BAYESIAN METHODS FOR ADAPTIVE MODELS the `Sure Thing' hypothesis, c fl E.T Jaynes, which is the hypothesis that the data set will be D, the precise data set that actually occurred; the evidence for the Sure Thing hypothesis is huge.
Reference: [51] <author> D.J.C. </author> <title> MacKay (1991). Information-based objective functions for active data selection, </title> <note> Neural Computation 4 4 589-603; Chapter 4 of this dissertation. </note>
Reference: [52] <author> D.J.C. </author> <title> MacKay (1991). The evidence framework applied to classification networks, </title> <note> Neural Computation 4 5 698-714; Chapter 5 of this dissertation. </note>
Reference-contexts: Application to classification problems This chapter has thus far discussed the evaluation of the evidence for backprop networks trained on interpolation problems. Neural networks can also be trained to perform classification tasks. A future publication <ref> [52] </ref> will demonstrate that the Bayesian framework for model comparison can be applied to these problems too. Relation to V-C dimension Some papers advocate the use of V-C dimension [1] as a criterion for penalising overcomplex models [2, 42].
Reference: [53] <author> K.E. Mark and M.I. </author> <title> Miller (1992). Bayesian model selection and minimum description length estimation of auditory-nerve discharge rates, </title> <journal> J. Acoust. Soc. Am. </journal> <volume> 91 2, </volume> <pages> 989-1002. </pages>
Reference-contexts: It is pleasing to note the current appearance of an increasing number of publications using Bayesian model comparison <ref> [37, 53] </ref>. As the quantities of data collected throughout science and engineering continue to increase, and the computational power and techniques available to model that data also multiply, I believe Bayesian methods will prove an ever more important tool for refining our modelling abilities.
Reference: [54] <author> J.E. </author> <title> Moody (1991). Note on generalization, regularization and architecture selection in nonlinear learning systems, </title> <booktitle> First IEEE-SP Workshop on neural networks for signal processing.IEEE Computer society press </booktitle>
Reference-contexts: Neither can substitute for the other. Future tasks Further work is needed to formalise the relationship of this framework to the pragmatic model comparison technique of cross-validation. Moody's work on `generalised prediction error' (GPE) is an interesting contribution in this direction <ref> [54] </ref>. His sampling theory approach predicts that the generalisation error, in 2 units, will be 1 N ( 2 D + 2fl). However, I have evaluated the GPE for the interpolation models in this chapter's demonstration, and found the correlation between GPE and the actual test error was poor. <p> There are theories which attempt to directly predict generalisation ability, leading to Akaike's FPE criterion, and Moody's GPE <ref> [3, 54] </ref>. But for the toy problems I have studied, neither of these criteria has a better correlation with the generalisation error than that achieved by the evidence. Theories based on the V-C dimension lead to structural risk minimisation criteria [30], which seem better correlated with generalisation error.
Reference: [55] <author> R.M. </author> <title> Neal (1991). Bayesian mixture modelling by Monte Carlo simulation, </title> <type> Technical Report CRG-TR-91-2 Dept. </type> <institution> of Computer Science, University of Toronto. </institution>
Reference-contexts: For more general statistical models we still expect the posterior to be dominated by locally Gaussian peaks on account of the central limit theorem [84]. Multiple maxima which arise in more complex models complicate the analysis, but Bayesian methods can still successfully be applied <ref> [31, 50, 55] </ref>. 12 BAYESIAN METHODS FOR ADAPTIVE MODELS the `Sure Thing' hypothesis, c fl E.T Jaynes, which is the hypothesis that the data set will be D, the precise data set that actually occurred; the evidence for the Sure Thing hypothesis is huge. <p> It will be interesting if Bayesian methods can be developed which avoid having to explicitly handle detailed parameterisations that are then marginalised away again. Perhaps Monte Carlo methods like Radford Neal's <ref> [55] </ref> are a step in this direction. 7.4 An alternative interpretation of weight decay Geoff Hinton (personal communication) has suggested an alternative view of mixture weight decay.
Reference: [56] <author> R.M. </author> <title> Neal (1992). Bayesian training of backpropagation networks by the hybrid Monte Carlo method, </title> <type> Technical Report CRG-TR-92-1 Dept. </type> <institution> of Computer Science, University of Toronto. </institution>
Reference-contexts: It is likely that an implementation of marginalisation that will scale up well to large problems will involve Monte Carlo methods <ref> [56] </ref>. Evidence: The evidence has been found to be well correlated with generalisation ability. This depends on having a sufficiently large amount of data.
Reference: [57] <author> S.J. </author> <title> Nowlan (1991). Soft competitive adaptation: neural network learning algorithms based on fitting statistical mixtures, </title> <institution> Carnegie Mellon University Doctoral thesis CS-91-126. </institution>
Reference-contexts: It is moderately common for extra regularising terms E W (w) to be added to E D ; for example, terms which penalise large weights may be introduced, in the hope of achieving a smoother or simpler mapping <ref> [33, 39, 57, 67, 87] </ref>. Some of the `hints' in [2] also fall into the category of additive weight-dependent energies. <p> The term ffE W is replaced by P W , where E c W = i2c w 2 i =2. Hinton and Nowlan <ref> [57] </ref> have used 48 BAYESIAN METHODS FOR ADAPTIVE MODELS 2 1 Bias Bias Output layer Hidden layer Input layer 1: Hidden unit weights. 2: Hidden unit biases. 3: Output unit weights and biases. The weights in one class c share the same decay constant ff c . <p> Further applications in neural networks It remains to be investigated whether these methods scale up to real, larger problems. Also this framework has yet to be applied to more sophisticated regularisers such as the mixture decay models of Hinton and Nowlan <ref> [57] </ref>. The power and unifying perspective of Bayesian methods are becoming more widely appreciated. This thesis has demonstrated their utility for adaptive models such as neural networks. There are thousands more data modelling tasks waiting for the `evidence' to be evaluated.
Reference: [58] <author> S.J. Nowlan and G.E. </author> <title> Hinton (1991). Soft weight sharing, </title> <type> preprint. </type>
Reference-contexts: This model also achieves better performance on the task of sunspot time series prediction than any published model <ref> [58] </ref>. Using the second prior, each regularising constant is independently adapted to its most probable value by evaluating the number of well-measured parameters fl c associated with each regularising function, and finding the optimum where 2ff c E c W = fl c . <p> what if we are stuck with a particular model space, either because of computational constraints or because of lack of creativity? Combining discriminative training with unlabelled data seems to me to be one of the current frontiers of Bayesian methods. time series, and obtained better performance than any published model <ref> [58] </ref>. 86 BAYESIAN METHODS FOR ADAPTIVE MODELS Other applications The concepts of Bayesian data modelling described in this thesis have great generality and should be relevant to any experimental scientist.
Reference: [59] <author> D.B. Osteyee and I.J. </author> <title> Good (1974). Information, weight of evidence, the singularity between probability measures and signal detection, </title> <publisher> Springer. </publisher>
Reference-contexts: To be precise, the expectation over possible data sets of the log evidence for the true model is greater than the expectation of the log evidence for any other fixed model <ref> [59] </ref>. 15 Proof. Suppose that the truth is actually H 1 . A single data set arrives and we compare the evidences for H 1 and H 2 , a different fixed model. Both models may have free parameters, but this will be irrelevant to the argument.
Reference: [60] <author> J.D. Patrick and C.S. </author> <title> Wallace (1982). Stone circle geometries: an information theory approach, in Archaeoastronomy in the Old World, D.C. </title> <editor> Heggie, editor, </editor> <publisher> Cambridge Univ. Press. </publisher>
Reference-contexts: One of the earliest applications of these sophisticated Bayesian methods of model comparison to real data is by Patrick and Wallace <ref> [60] </ref>; in this fascinating paper, competing models accounting for megalithic stone circle geometry are compared within the description length framework, which is equivalent to Bayes. It is pleasing to note the current appearance of an increasing number of publications using Bayesian model comparison [37, 53]. <p> Patrick and Wallace, studying the geometry of ancient stone circles (about which some people have proposed extremely elaborate theories!), discuss a practical method of assigning relative prior probabilities to alternative models by evaluating the lengths of the computer programs that decode data previously encoded under each model <ref> [60] </ref>. This procedure introduces a second sort of Occam's razor into the inference, namely a prior bias against complex models. However, we will not include such prior biases here; we will address only the data's preference for the alternative models, i.e., the evidence, and the Occam's razor that it embodies. <p> Any implementation of MDL necessitates approximations in evaluating the length of the ideal shortest message. Although some of the earliest work on complex model comparison involved the MDL framework <ref> [60] </ref>, MDL has no apparent advantages, and in my work I approximate the evidence directly. * It should be emphasised that the Occam factor has nothing to do with how compu-tationally complex it is to use a model. The evidence is a measure of plausibility of a model.
Reference: [61] <author> F.J. </author> <month> Pineda </month> <year> (1989). </year> <title> Recurrent back-propagation and the dynamical approach to adaptive neural computation, </title> <booktitle> Neural Computation 1, </booktitle> <pages> 161-172. </pages>
Reference-contexts: Alternatively, Radford Neal has suggested that the gradients @E val =@ff c could be more efficiently calculated using `recurrent backpropagation' <ref> [61] </ref>, viewing w as the vector of activities of a recurrent network, and w MP as the fixed point whose error E val we wish to minimise. 6 However, E. Levin and I.Guyon et al.[30] have developed a measure of `effective V-C dimension' of a regularised model.
Reference: [62] <author> M. Plutowski and H. </author> <title> White (1991). Active selection of training examples for network learning in noiseless environments, </title> <institution> Dept. Computer Science, </institution> <type> UCSD TR 90-011. </type>
Reference-contexts: In contrast, this chapter (which discusses noisy interpolation problems) derives criteria from defined objective functions; each objective function leads to a different data selection criterion. Chapter 5 will discuss the application of the same ideas to classification problems. Plutowski and White <ref> [62] </ref> study a different problem from the above, in the context of noise-free interpolation: they assume that a large amount of data has already been gathered, and work on principles for selecting a subset of that data for efficient training; the entire data set (inputs and targets) is consulted at each <p> It could also be used for selection of a subset of a large quantity of data, as a filter to weed out fractions of the data which are unlikely to be informative. Unlike Plutowski and White's approach <ref> [62] </ref> this filter only depends on the input variables in the candidate data. A strategy that selectively omits data on the basis of their output values would violate the likelihood principle and risk leading to inconsistent inferences.
Reference: [63] <author> T. Poggio, V. Torre and C. </author> <title> Koch (1985). Computational vision and regularization theory, </title> <booktitle> Nature 317 6035, </booktitle> <pages> 314-319. </pages>
Reference-contexts: Error bars on the best fit interpolant 9 can be obtained from the Hessian of M , A = rrM , evaluated at w MP . This is the well known Bayesian view of regularisation <ref> [63, 83] </ref>, also known as `maximum penalised likelihood' or `ridge regression'. Bayesian methods provide far more than just an interpretation for regularisation.
Reference: [64] <author> W.H. Press, B.P. Flannery, S.A. Teukolsky and W.T. </author> <title> Vetterling (1988). Numerical Recipes in C, </title> <publisher> Cambridge. </publisher>
Reference-contexts: Demonstrations The demonstrations were performed as follows: Initial weights: random weights drawn from a Gaussian with W = 0:3. Optimisation algorithm for M (w): variable metric methods, using code from <ref> [64] </ref>, used several times in sequence with values of the fractional tolerance decreasing from 10 4 to 10 8 .
Reference: [65] <author> J. </author> <title> Rissanen (1978). Modeling by shortest data description, </title> <type> Automatica 14, </type> <pages> 465-471. </pages>
Reference-contexts: In these cases, the right hand side of equation (2.6) should be multiplied by the degeneracy of w MP to give the correct estimate of the evidence. * `Minimum description length' (MDL) methods are closely related to this Bayesian framework <ref> [65, 85, 86] </ref>. The log evidence log 2 P (DjH i ) is the number of bits in the ideal shortest message that encodes the data D using model H i .
Reference: [66] <author> D.E. Rumelhart, G.E. Hinton and R.J. </author> <title> Williams (1986). Learning representations by back-propagating errors, </title> <booktitle> Nature 323, </booktitle> <pages> 533-536. </pages>
Reference-contexts: The most popular neural network algorithm is `backpropagation', which is capable of `learning from examples' <ref> [66] </ref>. In this case, a neural network can be viewed as a black box which produces an output when we give it an input. <p> For learning models well matched to a problem, a good correlation between generalisation ability and the Bayesian evidence is obtained. 3.1 The gaps in backprop There are many knobs on the black box of `backprop' (learning by back-propagation of errors <ref> [66] </ref>). Generally these knobs are set by rules of thumb, trial and error, and the use of reserved test data to assess generalisation ability (or more sophisticated cross-validation).
Reference: [67] <author> D.E. </author> <note> Rumelhart (1987). Cited in [39]. </note>
Reference-contexts: It is moderately common for extra regularising terms E W (w) to be added to E D ; for example, terms which penalise large weights may be introduced, in the hope of achieving a smoother or simpler mapping <ref> [33, 39, 57, 67, 87] </ref>. Some of the `hints' in [2] also fall into the category of additive weight-dependent energies.
Reference: [68] <author> G. </author> <title> Schwarz (1978). Estimating the dimension of a model, </title> <journal> Ann. Stat. </journal> <volume> 6 2, </volume> <pages> 461-464. BIBLIOGRAPHY 91 </pages>
Reference-contexts: Akaike's criterion, originally derived as a predictor of generalisation error [3], can be viewed, like Schwartz's `B.I.C.', as an approximation to MDL and Bayes <ref> [68, 89] </ref>. Any implementation of MDL necessitates approximations in evaluating the length of the ideal shortest message.
Reference: [69] <author> H.S. Seung, H. Sompolinsky and N. </author> <month> Tishby </month> <year> (1991). </year> <title> Statistical mechanics of learning from examples, </title> <type> preprint. </type>
Reference-contexts: There is presumably a relationship of this concept to the work of Seung et al. <ref> [69] </ref> on generalisation `at non-zero temperature'. If the suggested approximation to the moderated output and its derivative is found dissatisfactory, a simple brute force solution would be to set up a look-up table of values of (a; s 2 ) and 0 (a; s 2 ).
Reference: [70] <author> S. </author> <month> Sibisi </month> <year> (1991). </year> <title> Bayesian interpolation, </title> <booktitle> in [25], </booktitle> <pages> 349-355. </pages>
Reference-contexts: This chapter will review Bayesian model comparison, `regularisation', and noise estimation, by studying the problem of interpolating noisy data. The Bayesian framework I will describe for these tasks is due to Gull and Skilling <ref> [26, 27, 29, 70, 74] </ref>, who have used Bayesian methods to achieve the state of the art in image reconstruction. The same approach to regularisation has also been developed in part by Szeliski [81]. <p> Once the probabilities described above have been inferred, optimal actions can be chosen using standard decision theory with a suitable utility function. CHAPTER 2. BAYESIAN INTERPOLATION 15 2.3 The noisy interpolation problem Bayesian interpolation through noise-free data has been studied by Skilling and Sibisi <ref> [70] </ref>. In this chapter I study the problem of interpolating through data where the dependent variables are assumed to be noisy (a task also known as `regression', `curve-fitting', `signal estimation', or, in the neural networks community, `learning'). I am not examining the case where the independent variables are also noisy. <p> to P ( ^ff; ^ fijH); I assume that it is a flat prior (flat over log ff and log fi, since ff and fi are scale parameters) which cancels out when we compare alternative interpolation models. 2.6 Demonstration These demonstrations will use two one-dimensional data sets, in imitation of <ref> [70] </ref>. <p> It is possible to visualise the joint error bars on the interpolant by making typical samples from the posterior distribution, performing a random walk around the posterior `bubble' in parameter space <ref> [70, 74] </ref>. Figure 2.8 shows data set Y interpolated by three typical interpolants found by random sampling from the posterior distribution. <p> This radial basis function model is the same as the `intrinsic correlation' model of Charter, Gull, Skilling and Sibisi <ref> [16, 27, 70] </ref>. that for these models there is not an increasing Occam penalty for large numbers of parameters. The reason for this is that these extra parameters do not make the model any more powerful (for fixed ff and r).
Reference: [71] <author> J. Skilling, </author> <title> editor (1989). Maximum Entropy and Bayesian Methods, </title> <address> Cambridge 1988, </address> <publisher> Kluwer. </publisher>
Reference: [72] <author> J. </author> <title> Skilling (1989). The eigenvalues of mega-dimensional matrices, </title> <booktitle> in [71], </booktitle> <pages> 455-466. </pages>
Reference-contexts: For large-dimensional problems where this task is demanding, Skilling has developed methods for estimating TraceA 1 statistically in k 2 time <ref> [72] </ref>. 2.5 Model comparison To rank alternative basis sets A, noise models N and regularisers (priors) R in the light of the data, we examine the posterior probabilities for alternative models H = fA; N ; Rg: P (HjD) / P (DjH)P (H): (2.25) 24 BAYESIAN METHODS FOR ADAPTIVE MODELS The <p> However, for large problems it may be too demanding to evaluate the determinant of the Hessian. If this is the case, numerical methods are available to approximate the determinant or trace of a matrix in k 2 time <ref> [72] </ref>. Application to classification problems This chapter has thus far discussed the evaluation of the evidence for backprop networks trained on interpolation problems. Neural networks can also be trained to perform classification tasks.
Reference: [73] <author> J. </author> <title> Skilling (1991). On parameter estimation and quantified MaxEnt, </title> <booktitle> in [25], </booktitle> <pages> 267-273. </pages>
Reference-contexts: A modern Bayesian approach to priors It should be pointed out that the emphasis of this modern 3 Bayesian approach is not on the inclusion of priors into inference. There is not one significant `subjective prior' in this entire chapter. (For problems where significant subjective priors do arise see <ref> [28, 73] </ref>.) The emphasis is on the idea that consistent degrees of preference for alternative hypotheses are represented by probabilities, and relative preferences for models are assigned by evaluating those probabilities. <p> Furthermore, Skilling demonstrated that with some data sets a free form (maximum entropy) model can have greater evidence than the truth <ref> [73] </ref>; but is it possible for this to happen in the typical case, as Skilling seems to claim? I will show that the answer is no, that the effect that Skilling demonstrated cannot be systematic.
Reference: [74] <author> J. Skilling, D.R.T. Robinson, </author> <title> and S.F. Gull (1991). Probabilistic displays, </title> <booktitle> in [25], </booktitle> <pages> 365-368. </pages>
Reference-contexts: This chapter will review Bayesian model comparison, `regularisation', and noise estimation, by studying the problem of interpolating noisy data. The Bayesian framework I will describe for these tasks is due to Gull and Skilling <ref> [26, 27, 29, 70, 74] </ref>, who have used Bayesian methods to achieve the state of the art in image reconstruction. The same approach to regularisation has also been developed in part by Szeliski [81]. <p> It is possible to visualise the joint error bars on the interpolant by making typical samples from the posterior distribution, performing a random walk around the posterior `bubble' in parameter space <ref> [70, 74] </ref>. Figure 2.8 shows data set Y interpolated by three typical interpolants found by random sampling from the posterior distribution.
Reference: [75] <author> J. </author> <title> Skilling (1991). Fundamentals of MaxEnt in data analysis, in Maximum Entropy in action, </title> <editor> B. Buck and V.A. MacAulay, eds., </editor> <publisher> Oxford, 19-40.. </publisher>
Reference-contexts: A Bayesian addresses any inference problem by using this equation. The hard line Bayesian position is that the Cox axioms [17] prove that consistent inference can only be Bayesian, and no other inference methods should be used, on pain of inconsistency <ref> [75] </ref>. However, I will develop the more moderate position that the Bayesian method is an important tool which should be used alongside other pragmatic modelling tools.
Reference: [76] <author> J. </author> <title> Skilling (1992). Bayesian solution of ordinary differential equations, in Maximum Entropy and Bayesian Methods, Seattle 1991, </title> <editor> G.J. Erickson and C.R. Smith, eds., </editor> <publisher> Kluwer. </publisher>
Reference-contexts: This work was directly stimulated by a presentation given by John Skilling at Maxent 91 <ref> [76] </ref>.
Reference: [77] <author> A.F.M. Smith and D.J. </author> <month> Spiegelhalter </month> <year> (1980). </year> <title> Bayes factors and choice criteria for linear models, </title> <journal> Journal of the Royal Statistical Society B 42 2, </journal> <pages> 213-220. </pages>
Reference-contexts: The same approach to regularisation has also been developed in part by Szeliski [81]. Bayesian model comparison is also discussed by Smith and Spiegelhalter <ref> [77] </ref> and by Bretthorst [14], who has used Bayesian methods to push back the limits of NMR signal detection. The same Bayesian theory underlies the unsupervised classification system, AutoClass [31].
Reference: [78] <author> S.A. Solla, E. Levin and M. </author> <month> Fleisher </month> <year> (1988). </year> <title> Accelerated learning in layered neural networks, </title> <booktitle> Complex systems 2, </booktitle> <pages> 625-640. </pages>
Reference-contexts: It is well known that the natural objective function in this case is an information-based distance measure, rather than the sum of squared errors <ref> [15, 33, 34, 78] </ref>. A classification model H consists of a specification of its architecture A and the reg-ulariser R for its parameters w.
Reference: [79] <author> D.J. Spiegelhalter and S.L. </author> <title> Lauritzen (1990). Sequential updating of conditional probabilities on directed graphical structures, </title> <booktitle> Networks 20, </booktitle> <pages> 579-605. </pages>
Reference-contexts: Of course this idea of averaging over the hidden parameters is not new: marginalisation goes back to Laplace. More recently, and in a context closer to the present one, the same message can be found for example in <ref> [79] </ref>. But it seems that most practitioners of adaptive classification do not currently use marginalisation. I suggest that any classifier should have two sets of outputs. <p> A representative of this approximation is given in figure 5.1 which compares and 0 with numerical evaluations of and 0 . A similar approximation in terms of the error function is suggested in <ref> [79] </ref>. 3 Conditioning variables such as A; R; fff c g will be omitted in this section, since the emphasis is not on model comparison. CHAPTER 5. THE EVIDENCE APPLIED TO CLASSIFICATION 69 (a) (b) (d) (a) The function (a; s 2 ), evaluated numerically.
Reference: [80] <author> S.M. </author> <title> Stigler (1986). Laplace's 1774 memoir on inverse probability, </title> <journal> Stat. Sci. </journal> <volume> 1 3, </volume> <pages> 359-378. </pages>
Reference-contexts: Inference and decision are cleanly separated. The terms `Bayes risk' and `Bayes optimal' are not in the vocabulary of this thesis. The genealogy of this flavour is Laplace-Jeffreys-Cox-Jaynes-Gull <ref> [80, 38, 17, 36, 26] </ref>. A further difference between this approach and other work known as Bayesian is that the emphasis is on inverse rather than forward probability. Forward probability uses probabilities and priors, but it does not make use of Bayes' rule. <p> Complex models are automatically self-penalising under Bayes' rule. Figure 2.2 gives the basic intuition for why this should be expected; the rest of this chapter will explore this property in depth. Bayesian methods, simultaneously conceived by Bayes [6] and Laplace <ref> [80] </ref>, were first laid out in depth by the Cambridge geophysicist Sir Harold Jeffreys [38]. The logical basis for the Bayesian use of probabilities as measures of plausibility was subsequently established by Cox [17], who proved that consistent inference in a closed hypothesis space can be mapped onto probabilities. <p> some cases, including the linear models of this chapter, the integral (2.17) can be performed 11 Since ff and fi are scale parameters, this prior should be understood as a flat prior over log ff and log fi. 12 It is remarkable that Laplace almost got this right in 1774 <ref> [80] </ref>; when inferring the mean of a Laplacian distribution, he both inferred the posterior probability of a nuisance parameter like fi in (2.15), and then attempted to integrate out the nuisance parameter as in equation (2.17). 20 BAYESIAN METHODS FOR ADAPTIVE MODELS a) The evidence as a function of ff: Using
Reference: [81] <author> R. </author> <month> Szeliski </month> <year> (1989). </year> <title> Bayesian modeling of uncertainty in low level vision, </title> <publisher> Kluwer. </publisher>
Reference-contexts: The Bayesian framework I will describe for these tasks is due to Gull and Skilling [26, 27, 29, 70, 74], who have used Bayesian methods to achieve the state of the art in image reconstruction. The same approach to regularisation has also been developed in part by Szeliski <ref> [81] </ref>. Bayesian model comparison is also discussed by Smith and Spiegelhalter [77] and by Bretthorst [14], who has used Bayesian methods to push back the limits of NMR signal detection. The same Bayesian theory underlies the unsupervised classification system, AutoClass [31].
Reference: [82] <author> N. Tishby, E. Levin and S.A. </author> <month> Solla </month> <year> (1989). </year> <title> Consistent inference of probabilities in layered networks: predictions and generalization, </title> <booktitle> Proc. IJCNN, </booktitle> <address> Washington. </address>
Reference-contexts: Forward probability uses probabilities and priors, but it does not make use of Bayes' rule. Forward probability is used for example to evaluate the typical performance of a modelling procedure averaged over different data sets from a defined ensemble <ref> [82, 32] </ref>. Here the philosophy is, using inverse probability, to evaluate the relative plausibilities of several alternative models in the light of the single data set that we actually observe. 1 Good was unaware of the Bayesian Occam's razor. CHAPTER 1. <p> The error bars at a single point x are given by var y (x) = T A 1 . These error bars are directly related to the expected generalisation error at x, assuming that the model is true, evaluated in <ref> [43, 82] </ref>. The error bars are also related to the expected information gain per data point (chapter 4). Actually we have access to the full covariance information for the entire interpolant, not just the pointwise error bars. <p> Objective choice of regularising function E W . 4. Objective criteria for choosing between a neural network solution and a solution using a different learning or interpolation model, for example, splines or radial basis functions. The probability connection Tishby et al. <ref> [82] </ref> introduced a probabilistic view of learning which is an important step towards solving the problems listed above. The idea is to force a probabilistic interpretation onto the neural network technique so as to be able to make objective statements. This CHAPTER 3.
Reference: [83] <author> D. </author> <month> Titterington </month> <year> (1985). </year> <title> Common structure of smoothing techniques in statistics, </title> <journal> Int. Statist. Rev. </journal> <volume> 53, </volume> <pages> 141-170. </pages>
Reference-contexts: Error bars on the best fit interpolant 9 can be obtained from the Hessian of M , A = rrM , evaluated at w MP . This is the well known Bayesian view of regularisation <ref> [63, 83] </ref>, also known as `maximum penalised likelihood' or `ridge regression'. Bayesian methods provide far more than just an interpretation for regularisation.
Reference: [84] <author> A.M. </author> <title> Walker (1967). On the asymptotic behaviour of posterior distributions, </title> <journal> J. R. Stat. Soc. </journal> <volume> B 31, </volume> <pages> 80-88. </pages>
Reference-contexts: For the interpolation models discussed in this chapter, there is only a single maximum in the posterior distribution, and the Gaussian approximation is exact. For more general statistical models we still expect the posterior to be dominated by locally Gaussian peaks on account of the central limit theorem <ref> [84] </ref>. <p> As the amount of data collected, N , increases, this Gaussian approximation is expected to become increasingly accurate on account of the central limit theorem <ref> [84] </ref>. For the linear interpolation models discussed in this chapter, this Gaussian expression is exact for any N . Comments * Bayesian model selection is a simple extension of maximum likelihood model selection: the evidence is obtained by multiplying the best fit likelihood by the Occam factor. <p> The regime in which this approximation will definitely break down is when the number of constraints, N , is small relative to the number of free parameters, k. For large N=k the central limit theorem encourages us to use the Gaussian approximation <ref> [84] </ref>. It is a matter for further research to establish how large N=k must be for this approximation to be reliable.
Reference: [85] <author> C. S. Wallace and D. M. </author> <title> Boulton (1968). An information measure for classification, </title> <journal> Comput. J. </journal> <volume> 11 2, </volume> <pages> 185-194. </pages>
Reference-contexts: In these cases, the right hand side of equation (2.6) should be multiplied by the degeneracy of w MP to give the correct estimate of the evidence. * `Minimum description length' (MDL) methods are closely related to this Bayesian framework <ref> [65, 85, 86] </ref>. The log evidence log 2 P (DjH i ) is the number of bits in the ideal shortest message that encodes the data D using model H i .
Reference: [86] <author> C. S. Wallace and P. R. </author> <title> Freeman (1987). Estimation and Inference by Compact Coding, </title> <journal> J. R. Statist. Soc. </journal> <volume> B 49 3, </volume> <pages> 240-265. </pages>
Reference-contexts: In these cases, the right hand side of equation (2.6) should be multiplied by the degeneracy of w MP to give the correct estimate of the evidence. * `Minimum description length' (MDL) methods are closely related to this Bayesian framework <ref> [65, 85, 86] </ref>. The log evidence log 2 P (DjH i ) is the number of bits in the ideal shortest message that encodes the data D using model H i .
Reference: [87] <author> A.S. Weigend, D.E. Rumelhart and B.A. </author> <title> Huberman (1991). Generalization by weight-elimination with applications to forecasting, </title> <booktitle> in Advances in neural information processing systems 3, </booktitle> <editor> ed. R.P. Lippmann et al., </editor> <address> 875-882, </address> <publisher> Morgan Kaufmann. 92 BIBLIOGRAPHY </publisher>
Reference-contexts: It is moderately common for extra regularising terms E W (w) to be added to E D ; for example, terms which penalise large weights may be introduced, in the hope of achieving a smoother or simpler mapping <ref> [33, 39, 57, 67, 87] </ref>. Some of the `hints' in [2] also fall into the category of additive weight-dependent energies. <p> What is lacking The above procedures include a host of free parameters such as the choice of neural network architecture, and of the regularising constant ff. There are not yet established ways of objectively setting these parameters, though there are many rules of thumb (see <ref> [39, 87] </ref> for examples). One popular way of comparing networks trained with different parameter values is to assess their performance by measuring the error on an unseen test set or by similar cross validation techniques. <p> Thus the true width of the component at the origin ought to be zero; it is only set to a non-zero value as a computational artifice. This view, that weight decay is intended to switch off weights, is apparently shared by other workers <ref> [39, 87] </ref>. Under this interpretation, there is no reason to suppose that the Bayesian choice of the width of this component should be appropriate. 1 (The width of the other broad compo 1 All the same, Nowlan and Hinton have applied the Bayesian procedure to networks predicting sunspot CHAPTER 7.
Reference: [88] <author> N. </author> <title> Weir (1991). Applications of maximum entropy techniques to HST data, </title> <booktitle> in Proceedings of the ESO/ST-ECF Data Analysis Workshop, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: ff was used [27], the results obtained were most dissatisfactory, making clear what a poor regulariser was being used; this motivated an immediate search for alternative priors; the new, more probable priors discovered by this search are now at the heart of the state of the art in image deconvolution <ref> [88] </ref>. The similarity between regularisation and `early stopping' While an over-parameterised model is fitted to a data set using gradient descent on the data error, it is sometimes noted that the model's generalisation error passes through a minimum, rather than decreasing monotonically.
Reference: [89] <author> A. </author> <title> Zellner (1984). Basic issues in econometrics, </title> <publisher> Chicago. </publisher>
Reference-contexts: Since the 1960's, the Bayesian minority has been steadily growing, especially in the fields of economics <ref> [89] </ref> and pattern processing [20]. <p> Jeffreys applied this theory to simple model comparison problems in geophysics, for example testing whether a single additional parameter is justified by the data. Since the 1960s, Jeffreys' model comparison methods have been applied and 10 BAYESIAN METHODS FOR ADAPTIVE MODELS extended in the economics literature <ref> [89] </ref> and by a small number of statisticians [10, 11, 12]. Only recently has this aspect of Bayesian analysis been further developed and applied to more complex problems in other fields. This chapter will review Bayesian model comparison, `regularisation', and noise estimation, by studying the problem of interpolating noisy data. <p> Akaike's criterion, originally derived as a predictor of generalisation error [3], can be viewed, like Schwartz's `B.I.C.', as an approximation to MDL and Bayes <ref> [68, 89] </ref>. Any implementation of MDL necessitates approximations in evaluating the length of the ideal shortest message.
References-found: 89

