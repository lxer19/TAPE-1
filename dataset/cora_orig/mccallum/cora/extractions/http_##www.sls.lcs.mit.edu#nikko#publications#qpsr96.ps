URL: http://www.sls.lcs.mit.edu/nikko/publications/qpsr96.ps
Refering-URL: http://www.sls.lcs.mit.edu/nikko/publications/index.html
Root-URL: 
Title: Continuous speech recognition in the WAXHOLM dialogue system  
Author: Nikko Strm 
Date: 67  
Address: 4/1996  
Affiliation: TMH-QPSR  
Abstract: This paper presents the status of the continuous speech recognition engine of the WAXHOLM project. The engine is a software only system written in portable C code. The design is flexible and different modes for phonetic pattern matching are available. In particular, artificial neural networks and standard multiple Gaussian mixtures are implemented for phone probability estimation, and for research purposes, a general mode where the input consists of a phone-graph also exists. A lexicon with multiple pronunciations for many words and a class bigram-grammar is used. The lexicon and grammar constraints are represented by a lexical graph, optimised for efficient lexical decoding. The decoding is performed in a two-pass search. The first pass is a Viterbi beamsearch and the second is an A* stack-decoding search. Pruning-strategies and memory management in the two passes are discussed in the report. Several different output formats are available. Results can be reported either on the word or phoneme level with or without the time alignment information. Multiple hypotheses can be output either as standard N-best lists or in a more compact word-graph format. Continuous speech recognition can be performed on a standard UNIX workstation in real-time with a lexicon of about 1000 words. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aust H, Oerder M, </author> <title> Seide F & Steinbiss V (1994) . Experience with the Philips Automatic Train Timetable Information System . Proc of IEEE Workshop on Interactive Voice Technology for Telecommunications Applications (IVTTA94); 67-72. Bergland GD & Dolan MT (1979) . Fast Fourier Transform Algorithms in Programs for Digital Signal Processing . Ed. by the DSP committee IEEE Acoustics, Speech and Signal Processing Society, </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference: <author> Bertenstam J, Blomberg M, Carlson R, Elenius K, Granstrm B, Gustafson J, Hunnicutt S, Hgberg J, Lindell R, Neovius L, </author> <title> de Serpa-Leitao A & Strm N (1995a). </title> <booktitle> The Waxholm Application Database , Proc of EUROSPEECH '95 Madrid; 833-836. </booktitle>
Reference: <author> Bertenstam J, Blomberg M, Carlson R, Elenius K, Granstrm B, Gustafson J, Hunnicutt S, Hgberg J, Lindell R, Neovius L, de Serpa-Leitao A, </author> <title> Nord L & Strm N (1995b). Spoken dialogue data collection in the Waxholm project, </title> <journal> STL-QPSR, </journal> <volume> KTH, </volume> <pages> 1/1995 : 50-73. </pages>
Reference: <author> Blomberg M, Carlson R, Elenius K, Granstrm B, Gustafson J, Hunnicut S, </author> <title> Lindell R & Neovius L (1993). An experimental dialogue system: Waxholm. Proc of EUROSPEECH '93; 1867-1870. Bourlard H & Morgan N (1993). Continuous speech recognition by connectionist statistical methods. </title> <journal> IEEE trans. on Neural Networks; 4/6: </journal> <pages> 893-909. </pages>
Reference: <author> Carlson R (1996). </author> <title> The dialog component in the Waxholm system. </title> <booktitle> Proc of Twente Workshop on Language Technology (TWLT11). Dialogue Management in Natural Language Systems , University of Twente, </booktitle> <address> the Netherlands. </address>
Reference-contexts: The generic versus domainspecific aspects of the system is discussed more thoroughly in <ref> (Carlson & Hunnicut, 1996) </ref>. A special class of nonlinguistic words is also defined in the lexicon. It includes acoustic events such as breath pauses, coughs and laughs. The nonlinguistic words are composed by special purpose phonemes trained on the database.
Reference: <author> Carlson R & Hunnicut S (1996). </author> <title> Generic and domainspecific aspects of the Waxholm NLP and dialog modules. </title> <booktitle> Proc of ICSLP 1996; 677-680. </booktitle>
Reference-contexts: The generic versus domainspecific aspects of the system is discussed more thoroughly in <ref> (Carlson & Hunnicut, 1996) </ref>. A special class of nonlinguistic words is also defined in the lexicon. It includes acoustic events such as breath pauses, coughs and laughs. The nonlinguistic words are composed by special purpose phonemes trained on the database.
Reference: <author> Cohen M, Franco H, Morgan N, </author> <title> Rumelhart D & Abrash V (1992). Hybrid neural network/Hidden Markov Model continuous-speech recognition. </title> <booktitle> Proc of ICSLP '92; 915-918. </booktitle>

Reference: <author> Glass J, Flammia G, Goodine D, Phillips M, Polifroni J, Sakai S, Seneff S & Zue V (1995). </author> <title> Multilingual spoken language understanding in the MIT voyager system. </title> <type> Speech Communication 17/1-2: </type> <pages> 1-18. </pages>
Reference-contexts: The user input to the system is spoken language exclusively, but the responses from the system include synthetic speech as well as pictures, maps, charts and timetables (Figure 1). The application has similarities to the ATIS domain within the ARPA community, the Voyager system from MIT <ref> (Glass et al., 1995) </ref> and European systems such as SUNDIAL (Peckham, 1993), Philipss train timetable information system (Aust et al., 1994; Oerder & Aust, 1994) and the Danish dialogue project (Dalsgaard & Baekgaard, 1994).
Reference: <author> Glass J & Zue V (1988). </author> <title> Multilevel acoustic segmentation of continuous speech. Proc of ICASSP 88; 429-432. Gish H (1990). A probabilistic approach to the understanding and training of neural network classifiers. </title> <booktitle> Proc of IEEE ICASSP '90; 1361-1364. </booktitle>
Reference-contexts: TMH-QPSR 4/1996 74 The phone graph mode of the WAXHOLM system is a powerful tool for evaluating new methods for feature extraction and has been used with some success in a study of phone graphs computed in an external phonetic analysis procedure (Lewin, 1996) based on dendrograms <ref> (Glass & Zue, 1988) </ref>.
Reference: <author> Greenberg S (1988). </author> <title> Acoustic transduction in the auditory periphery. </title> <type> J Phonetics 16/1: </type> <pages> 3-18. </pages>
Reference: <author> Hetherington IL, Phillips MS, Glass JR & Zue VW (1993). </author> <title> A* word network search for continuous speech recognition. </title> <booktitle> Proc of IEEE ICASSP '93 ; 1533-1536. </booktitle>
Reference-contexts: It is a directed, acyclic graph with a word-label on each arc and time-points on the nodes. The word-lattice is built during the stack search by associating a potential lattice-node with each node of the product graph <ref> (Hetherington et al., 1993) </ref>. When an expansion from a node in the search tree occurs, for all new branches created in the tree, arcs are created in the lattice.
Reference: <author> Hopcroft JE & Ullman JD (1979). </author> <title> Introduction to automata theory, </title> <publisher> languages and computation . Addison & Wesley Publ Co Inc. </publisher>
Reference-contexts: The size of the lattice can be reduced extensively without altering the set of generated wordstrings. In Strm (1995b) we proposed to use graph minimisation algorithms <ref> (Hopcroft & Ullman, 1979) </ref>, well known in computer science, to reduce the lattice to a minimal deterministic graph generating exactly the same word sequences as the lattice.
Reference: <author> Huang XD, </author> <title> Ariki Y & Jack MA (1990). Hidden Markov Models for Speech Recognition . Edinburgh: </title> <publisher> University Press. </publisher> <editor> Hgberg J & Sjlander K (1996). </editor> <title> Cross phone state clustering using lexical stress and context . Proc of ICSLP 96; 474-477. </title>
Reference: <author> Kenny P, Hollan V, Gupta V, Lennig M, </author> <title> Mermel - stiein P & OShaughnessy D (1991). A* - admissible heuristics for rapid lexical access. </title> <booktitle> Proc of IEEE ICASSP '91; 689-692. </booktitle>
Reference-contexts: To be able to work with different graphs in the two phases, the concept of quotient graphs is introduced. Quotient graphs By defining an equivalence relation, ~, on the nodes of the lexical graph the very useful concept of quotient graphs can be introduced. Quotient graphs was used by <ref> (Kenny et al., 1991) </ref>, and we follow their definition, but use a slightly different terminology.
Reference: <author> Lee KF (1989). </author> <title> Automatic Speech Recognition; The Development of the SPHINX System . Dordrecht: </title> <publisher> Kluwer Academic Publishers, </publisher> <address> ISBN 0-89838-296-3. </address>
Reference-contexts: We have chosen the standard continuous density HMM paradigm, i.e, the models estimate the probability density functions (pdf) for the observed energy, cepstrum and derivative features given the hypothesized phonetic class for each frame <ref> (Lee, 1989) </ref>. For a feature vector o, and a class c i , the probability to estimate is: p (o|c ). Again following the standard HMM paradigm, the temporal patterns are modelled by a probabilistic finite state automaton (FSA) (Fig. 9).
Reference: <author> Levin E (1990). </author> <title> Word recognition using hidden control neural architecture. </title> <booktitle> Proc of IEEE ICASSP '90; 1: </booktitle> <month> 433-436. </month> <title> Lewin E (1996). Dendrogram-based Segmentation of Speech and Recognition of Segmented Speech , MS Thesis, </title> <institution> KTH (Royal Institute of Technology), Dept of Speech, Music and Hearing, Sweden. </institution>
Reference: <author> Li W (1992). </author> <title> Random texts exhibit Zipfs law-like word frequency distribution. </title> <journal> IEEE Trans Info Theory 38: </journal> <volume> 5. </volume>
Reference: <author> Lowerre B & Reddy R (1980). </author> <title> The Harpy Speech Understanding System . Lea WA, </title> <editor> ed. </editor> <address> New Jersey: </address> <publisher> Prentice Hall Inc. </publisher>
Reference-contexts: This is unsatis - factory from a computational point of view in all but special cases. The standard solution is beam-pruning <ref> (Lowerre & Reddy, 1980) </ref>. The idea is to process only the most promising lexical nodes i at each frame. Common termi - nology is that those nodes are alive at the particular frame and that they are inside the beam.

Reference: <author> Nilsson N (1971). </author> <booktitle> ProblemSolving Methods in Artificial Intelligence. </booktitle> <publisher> Morgan Kaufman Publ, Inc. </publisher>
Reference: <author> Pearlmutter BA (1990). </author> <title> Dynamic recurrent neural networks. </title> <institution> Technical Report CMU-CS-88-191 , Carnegie-Mellon University, Computer Science Dept. Pittsburg, </institution> <address> PA. </address> <month> Peckham J </month> <year> (1993). </year> <title> A new generation of spoken dialog systems: results and lessons from the SUNDIAL Project. </title> <booktitle> Proc of Eurospeech 93; 33-40. </booktitle>
Reference-contexts: To handle the recurrent connections, the backpropagation algorithm is extended by propagating errors not only in the spatial dimension, but also backwards in time (backpropagation through time, <ref> (Pearlmutter, 1990) </ref>. Learning is speeded up by restarting the propagation-through-time every 20th-30th frame (200-300 ms) and updating the weights. This procedure is also used by Robinson (1994).
Reference: <author> Pierce JR (1961). </author> <title> Symbols, Signals and Noice: the Nature and Process of Communication , New York: Harper. Press WH, Teukolsky AT, Vetterling WT & Flannery BP (1992). Numerical Recipes in C (2nd edition), </title> <address> New York: Cambridge University Press; 512-514. </address> <booktitle> Rabiner LR & Juang B-H (1993). Fundamentals of Speech Recognition, </booktitle> <address> Eaglewood Cliffs NJ, </address> <publisher> Prentice Hall. </publisher>
Reference: <author> Rabiner LR & Schafer RW (1978). </author> <title> Digital Processing of Speech Signals, </title> <publisher> Prentice Hall. </publisher>
Reference-contexts: The filterbank outputs of the speech signal are statistically highly correlated, indicating that further data reduction is possible. Therefore, the cosine transform (in this context often called the cepstrum transform) <ref> (Rabiner & Schafer, 1978) </ref>. is applied to the output vector, i.e, the cepstrum coefficients c i are computed from the filterbank outputs o j using ( ) N i j j = - 2 1 p where N is the number of filters.
Reference: <author> Robinson AJ (1994). </author> <title> An application of recurrent nets to phone probability estimation. </title> <journal> IEEE trans on Neural Networks 5 / 2: </journal> <pages> 298-305. </pages>
Reference: <author> Robinson T & Fallside F (1991). </author> <title> A recurrent error propagation network speech recognition system. </title> <booktitle> Computer Speech & Language 5 / 3: </booktitle> <pages> 259-274. </pages>
Reference-contexts: We see that the estimates on the training data are very similar to the real probabilities, indicating that the conditions of the result of Gish (1990) are fulfilled. The ANN has both a timedelay window, first suggested by (Waibel et al., 1987) and recurrent timedelayed connections <ref> (Robinson & Fallside, 1991) </ref> in the hidden layer (Strm, 1992, 1994b, 1995b, 1996).
Reference: <author> Rumelhart DE, Hinton GE & Williams RJ (1986). </author> <title> Learning internal representations by error propagation. </title> <editor> In: Rumelhart DE & Hinton GE, eds. </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition . Vol. 1 Foundations, </booktitle> <address> Chapt 8. Cambridge, MA: </address> <publisher> Bradford Books/MIT Press. </publisher> <editor> Schroeder MR, Atal BS & Hall JL (1979). </editor> <title> Objective measure of certain speech signal degradations based on masking properties of the human auditory perception. </title> <editor> In: Lindblom B & hman S, eds. </editor> <title> Frontiers of Speech Communication Research , Academic Press; 217-229. </title>
Reference-contexts: The topology of a typical ANN is shown in Figure 7. The node activations and the error gradient are computed in the same way as the classic ANNs of <ref> (Rumelhart et al., 1986) </ref>, with the exception that the sigmoid function is replaced by the computationally more convenient tanhyp func - tion.
Reference: <author> Sedgewick R (1988). </author> <title> Algorithms, 2nd edition, </title> <publisher> Addison-Wesley Publishing Company Inc. </publisher> <address> Seneff S (1988). </address> <booktitle> A joint synchrony/mean-rate model of auditory speech processing. </booktitle> <volume> J Phonetics 16/1: </volume> <pages> 55-76. </pages>
Reference-contexts: To keep track of the current best path in the search tree, a priority queue (the stack) is used. The stack can be efficiently implemented using the heap data structure that requires only logarithmic time both for insertions and for retrieval of the best path <ref> (Sedgewick, 1988) </ref>. Basic stack decoding is illustrated in Figure 16. A problem with stack decoding in this form is that all extensions lower the observation probability of the path.
Reference: <author> Soong F & Huang E (1991). </author> <title> A tree-trellis based fast search for finding the n best sentence hypotheses in continuous speech recogniton. Proc of ICASSP '91; 705-708. Steinbiss V, Tran B-H & Ney H (1994). Improve - ments in Beam Search. </title> <booktitle> Proc of ICSLP 94 ; 2143-2146. </booktitle>
Reference-contexts: Now we define an A* heuristic, f* = g + h* ti . This very useful heuristic was first used in ASR by <ref> (Soong & Huang, 1991) </ref> and it has the property that it is greater than or equal to any other complete path containing the partial path. This is called A*- admissibility and it will be clear in the following why it is an important property.

Reference: <author> Waibel A & Lee K-F (1990). </author> <title> Readings in Speech Recognition. </title> <address> San Mateo: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Waibel A, Hanazawa T, Hinton G, </author> <title> Shikano K & Lang K (1987). Phoneme recognition using time-delay neural networks. </title> <type> ATR Technical Report TR-006, </type> <institution> ATR, </institution> <address> Japan. </address>
Reference-contexts: We see that the estimates on the training data are very similar to the real probabilities, indicating that the conditions of the result of Gish (1990) are fulfilled. The ANN has both a timedelay window, first suggested by <ref> (Waibel et al., 1987) </ref> and recurrent timedelayed connections (Robinson & Fallside, 1991) in the hidden layer (Strm, 1992, 1994b, 1995b, 1996).
Reference: <author> Woodland PC, Odell JJ, </author> <title> Valtchev V & Young SJ (1990). Large vocabulary continuous speech recognition using HTK. </title> <booktitle> Proc of IEEE ICASSP '94; II: </booktitle> <pages> 125-128. </pages>
Reference: <author> Young S, Jansen J, Odell J, </author> <title> Ollason D & Woodland P (1995). HTK Hidden Markov Toolkit, </title> <institution> Entropic Cambridge Research Laboratory; 71-72. </institution> <month> Zipf GK </month> <year> (1949). </year> <title> Human Behavior and Principle of Least Effort: An Introductiont to Human Ecology . Cambridge, </title> <address> MA: </address> <publisher> Addison Wesley. </publisher>
Reference-contexts: the frame is also computed using the formula E s n = 1 Both the energy computation and the magni - tude spectrum computation have been designed so that if appropriate values are chosen for the parameters, the processing of the feature extrac - tion in the widespread HTK toolkit <ref> (Young et al., 1995) </ref> can be reproduced. This is useful for comparisons with mainstream ASR technology. <p> The Bark scale (Zwicker & Feltkeller, 1967) is approximated by the formula 7 * sinha f where f is the frequency in Herz, and 2595 1 * log + is used for the Mel scale <ref> (Young et al., 1995, p. 69) </ref>. This is similar to the formula given by Schroeder, Atal & Hall (1979). Currently, 24 Mel spaced filters covering the frequency range 0-8000 Hz are used. <p> In both formulae, d t is the estimate of the time-derivative at time t of the coefficient c. The first formula is used by default in the HTK toolkit <ref> (Young et al., 1995) </ref> and is derived from linear regression analysis, i.e, the inclusion of points further from t (c t +2 t -2 ) serve the purpose of reducing local errors in the measurement of c. <p> Currently this module is dependent on the HTK toolkit for training the parameters (Sjlander, 1995). Multiple mixture Gaussian pdfs and the transition matrices are trained using the toolkit and the parameters are then transferred to our system for real time decoding. We refer to the HTK documentation <ref> (Young et al., 1995) </ref> or a text book on HMM (Rabiner & Juang, 1993; Huang et al., 1990; Waibel & Lee, 1990) for the training of the model parameters.
Reference: <author> Zue V, Glass J, Goodine D, Leung H, Phillips M, Polifroni J & Seneff S (1991). </author> <booktitle> Integration of speech recognition and natural language processing in the MIT Voyager System . Proc of IEEE ICASSP '91 ; 713-716. </booktitle>
Reference: <author> Zue V, Glass J, Phillips M & Seneff S (1989). </author> <title> Acoustic segmentation and phonetic classification in the SUMMIT system. </title> <booktitle> Proc of ICASSP 1989 ; 389-392. Zwicker E & Feltkeller R (1967) . Das Ohr als Nachrichtenempfnger. </booktitle> <address> Stuttgart: S Hirtzel Verlag. TMH-QPSR 4/1996 96 </address>
References-found: 33

