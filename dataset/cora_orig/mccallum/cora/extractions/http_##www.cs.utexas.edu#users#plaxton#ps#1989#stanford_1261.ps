URL: http://www.cs.utexas.edu/users/plaxton/ps/1989/stanford_1261.ps
Refering-URL: http://www.cs.utexas.edu/users/plaxton/html/abc.html
Root-URL: 
Title: Pipelined Parallel Prefix Computations, and Sorting on a Pipelined Hypercube log p which is asymptotically
Author: Ernst W. Mayr C. Greg Plaxton 
Address: W. Goethe University, Frankfurt, West Germany.  CA 94305.  
Affiliation: Fachbereich Informatik, J.  Sciences and Engineering Research Council of Canada. Department of Computer Science, Stanford University, Stanford  
Note: log  This work was supported in part by a grant from the AT&T Foundation, NSF grant DCR-8351757 and ONR grant N00014-88-K-0166.  Primarily supported by a 1967 Science and Engineering Scholarship from the Natural  
Abstract: This paper brings together a number of previously known techniques in order to obtain practical and efficient implementations of the prefix operation for the complete binary tree, hypercube and shu*e exchange families of networks. For each of these networks, we also provide a "pipelined" scheme for performing k prefix operations in O(k + log p) time on p processors. This implies a similar pipelining result for the "data distribution" operation of Ullman [16]. The data distribution primitive leads to a simplified implementation of the optimal merging algorithm of Varman and Doshi, which runs on a pipelined model of the hypercube [17]. Finally, a pipelined version of the multi-way merge sort of Nassimi and Sahni [10], running on the pipelined hypercube model, is described. Given p processors and n &lt; p log p values to be sorted, the running time of the pipelined algorithm is O(log 2 p= log((p log p)=n)). Note that for the interesting case n = p this yields a running time of O( log 2 p
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal and M.-D. A. Huang. </author> <title> Network complexity of sorting and graph problems and simulating CRCW PRAMs by interconnection networks. </title> <editor> In J. H. Reif, editor, </editor> <booktitle> Lecture Notes in Computer Science: VLSI Algorithms and Architectures (AWOC 88), </booktitle> <volume> vol. 319, </volume> <pages> pages 339-350. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year> <month> 13 </month>
Reference-contexts: There has been a great deal of previous research related to the problem of sorting on the hypercube. For the 1-port model of the hypercube that we have been considering thus far, see <ref> [1] </ref>, [4], [7], [9], [10] and [12]. For examples of results based on other assumptions, we refer the reader to [13], [15], [17] and [18].
Reference: [2] <author> R. J. Anderson, E. W. Mayr, and M. K. Warmuth. </author> <title> Parallel approximation algorithms for bin packing. </title> <type> Technical Report STAN-CS-88-1200, </type> <institution> Stanford University, Department of Computer Science, </institution> <month> March </month> <year> 1988. </year>
Reference-contexts: The algorithm is similar to that proposed by Varman and Doshi [17], but is somewhat simpler. The optimal merging algorithm of Anderson, Mayr and Warmuth for the EREW PRAM also takes a similar approach <ref> [2] </ref>. For expository purposes, we make the (avoidable) assumption that all of the 2pk input values are distinct. For both X and Y , the values with ranks (numbered from 0) in the range ik to (i + 1)k 1 are initially stored at processor i, 0 i &lt; p.
Reference: [3] <author> K. E. Batcher. </author> <title> Sorting networks and their applications. </title> <booktitle> In Proceedings of the AFIPS Spring Joint Computer Conference, </booktitle> <volume> vol. 32, </volume> <pages> pages 307-314, </pages> <year> 1968. </year>
Reference: [4] <author> G. Baudet and D. Stevenson. </author> <title> Optimal sorting algorithms for parallel computers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-27:84-87, </volume> <year> 1978. </year>
Reference-contexts: There has been a great deal of previous research related to the problem of sorting on the hypercube. For the 1-port model of the hypercube that we have been considering thus far, see [1], <ref> [4] </ref>, [7], [9], [10] and [12]. For examples of results based on other assumptions, we refer the reader to [13], [15], [17] and [18].
Reference: [5] <author> S. N. Bhatt, F. R. K. Chung, F. T. Leighton, and A. L. Rosenberg. </author> <title> Optimal simulations of tree machines. </title> <booktitle> In Proceedings of the 27th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 274-282, </pages> <year> 1986. </year>
Reference-contexts: To achieve pipelined speedup we can make use of the dilation 2 inorder complete binary tree embedding <ref> [5] </ref>. p 1) has been added as an extra level above the root. The edges depicted in Figure 2 are physical hypercube edges. The left child of a non-leaf processor is connected directly to its parent, while the right child is connected to its parent via the left child.
Reference: [6] <author> G. E. Blelloch. </author> <title> Scans as primitive parallel operations. </title> <booktitle> In Proceedings of the 1987 IEEE International Conference on Parallel Processing, </booktitle> <pages> pages 355-362, </pages> <year> 1987. </year>
Reference-contexts: 1 ) = (a 0 or a 1 ; if a 1 then b 1 else b 0 or b 1 ; if a 1 or not b 0 then x 1 else x 0 ): Note that the above formulation allows bit pipelining in the sense described by Blelloch <ref> [6] </ref>. In other words, as each bit of the two operands is received, the next output bit can be computed. This holds not only for the Copy operator, but also for any other single-pass operator, as defined in [6]. <p> the above formulation allows bit pipelining in the sense described by Blelloch <ref> [6] </ref>. In other words, as each bit of the two operands is received, the next output bit can be computed. This holds not only for the Copy operator, but also for any other single-pass operator, as defined in [6]. Finally, we observe that the data distribution operation defined by Ullman [16] is equivalent to a segmented Prefix operation with the Copy operator.
Reference: [7] <author> R. E. Cypher and J. L. C. Sanz. Cubesort: </author> <title> An optimal sorting algorithm for feasible parallel computers. </title> <editor> In J. H. Reif, editor, </editor> <booktitle> Lecture Notes in Computer Science: VLSI Algorithms and Architectures (AWOC 88), </booktitle> <volume> vol. 319, </volume> <pages> pages 456-464. </pages> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: There has been a great deal of previous research related to the problem of sorting on the hypercube. For the 1-port model of the hypercube that we have been considering thus far, see [1], [4], <ref> [7] </ref>, [9], [10] and [12]. For examples of results based on other assumptions, we refer the reader to [13], [15], [17] and [18].
Reference: [8] <author> C.-T. Ho and S. L. Johnsson. </author> <title> Distributed routing algorithms for broadcasting and personalized communication in hypercubes. </title> <booktitle> In Proceedings of the 1986 IEEE International Conference on Parallel Processing, </booktitle> <pages> pages 640-648, </pages> <year> 1986. </year>
Reference-contexts: Although such operations can be performed using Prefix, other implementations exist which are more efficient by a constant factor. For example, using the multiple spanning binomial tree (MSBT) embedding of Ho and Johnsson <ref> [8] </ref> it is possible to perform k broadcasts in k + log p time steps. Similarly, k sums can be performed in k + log p time steps.
Reference: [9] <author> S. L. Johnsson. </author> <title> Combining parallel and sequential sorting on a Boolean n-cube. </title> <booktitle> In Proceedings of the 1984 IEEE International Conference on Parallel Processing, </booktitle> <pages> pages 444-448, </pages> <year> 1984. </year>
Reference-contexts: There has been a great deal of previous research related to the problem of sorting on the hypercube. For the 1-port model of the hypercube that we have been considering thus far, see [1], [4], [7], <ref> [9] </ref>, [10] and [12]. For examples of results based on other assumptions, we refer the reader to [13], [15], [17] and [18].
Reference: [10] <author> D. Nassimi and S. Sahni. </author> <title> Parallel permutation and sorting algorithms and a new generalized connection network. </title> <journal> JACM, </journal> <volume> 29 </volume> <pages> 642-667, </pages> <year> 1982. </year>
Reference-contexts: hypercube and shu*e exchange network families. 4 Sorting on a Pipelined Hypercube In this section, we describe a simplified implementation of the optimal merging algorithm of Varman and Doshi [17], and show how this can be used to develop a pipelined version of the sorting algorithm of Nassimi and Sahni <ref> [10] </ref> for a pipelined model of the hypercube. The Sort operation is defined as follows. <p> There has been a great deal of previous research related to the problem of sorting on the hypercube. For the 1-port model of the hypercube that we have been considering thus far, see [1], [4], [7], [9], <ref> [10] </ref> and [12]. For examples of results based on other assumptions, we refer the reader to [13], [15], [17] and [18]. <p> It is interesting to note that we do not require pipelined concentration routes, nor do we require the pipelined inverse concentration with copy operation of Varman and Doshi. Concentration and inverse concentration routes were defined by Nassimi and Sahni <ref> [10] </ref>, and it is easy to show that k such operations can be performed in k + log p time steps on the pipelined hypercube model. <p> We now describe a pipelined version of the multi-way merging procedure of Nassimi and Sahni <ref> [10] </ref> that runs on the pipelined hypercube. The input consists of 2 l sorted lists of length k2 m , and the output is a single sorted list of length k2 l+m .
Reference: [11] <author> D. Peleg. </author> <type> Personal communication. </type>
Reference-contexts: It should be mentioned that for permutation routing, an important special case of the sorting problem, there is a much simpler O (log 2 p= log log p) time algorithm for the case n = p than MultiWayMergeSort <ref> [11] </ref>. The idea is to route packets in a greedy fashion over sets of log log p dimensions at a time.
Reference: [12] <author> C. G. Plaxton. </author> <title> Load balancing, selection and sorting on the hypercube. </title> <booktitle> In Proceedings of the 1st Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 64-73, </pages> <year> 1989. </year>
Reference-contexts: There has been a great deal of previous research related to the problem of sorting on the hypercube. For the 1-port model of the hypercube that we have been considering thus far, see [1], [4], [7], [9], [10] and <ref> [12] </ref>. For examples of results based on other assumptions, we refer the reader to [13], [15], [17] and [18]. The time bounds for the merging and sorting algorithms described in this section do not apply to the 1-port model of computation that we have been considering up to this point.
Reference: [13] <author> J. H. Reif and L. G. Valiant. </author> <title> A logarithmic time sort for linear size networks. </title> <journal> JACM, </journal> <volume> 34 </volume> <pages> 60-76, </pages> <year> 1987. </year>
Reference-contexts: For the 1-port model of the hypercube that we have been considering thus far, see [1], [4], [7], [9], [10] and [12]. For examples of results based on other assumptions, we refer the reader to <ref> [13] </ref>, [15], [17] and [18]. The time bounds for the merging and sorting algorithms described in this section do not apply to the 1-port model of computation that we have been considering up to this point.
Reference: [14] <author> J. T. Schwartz. </author> <title> Ultracomputers. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 2 </volume> <pages> 484-521, </pages> <year> 1980. </year>
Reference-contexts: 1 The Prefix Operation We begin by reviewing the basic definitions necessary to understand the prefix and segmented prefix operations. These operations were first introduced by Schwartz, where they are referred to as "summing" and "summing by groups" <ref> [14] </ref>. Let denote a binary associative operation mapping X fiX to X , for some domain X .
Reference: [15] <author> S. R. Seidel and W. L. George. </author> <title> Binsorting on hypercubes with d-port communication. </title> <type> Technical Report CS-TR 99-01, </type> <institution> Michigan Technological University, </institution> <month> January </month> <year> 1988. </year> <month> 14 </month>
Reference-contexts: For the 1-port model of the hypercube that we have been considering thus far, see [1], [4], [7], [9], [10] and [12]. For examples of results based on other assumptions, we refer the reader to [13], <ref> [15] </ref>, [17] and [18]. The time bounds for the merging and sorting algorithms described in this section do not apply to the 1-port model of computation that we have been considering up to this point.
Reference: [16] <author> J. D. Ullman. </author> <title> Computational Aspects of VLSI. </title> <publisher> Computer Science Press, </publisher> <address> Rockville, MD, </address> <year> 1984. </year>
Reference-contexts: In other words, as each bit of the two operands is received, the next output bit can be computed. This holds not only for the Copy operator, but also for any other single-pass operator, as defined in [6]. Finally, we observe that the data distribution operation defined by Ullman <ref> [16] </ref> is equivalent to a segmented Prefix operation with the Copy operator.
Reference: [17] <author> P. Varman and K. Doshi. </author> <title> Sorting with linear speedup on a pipelined hypercube. </title> <type> Technical Report TR-8802, </type> <institution> Rice University, Department of Electrical and Computer Engineering, </institution> <month> February </month> <year> 1988. </year>
Reference-contexts: the techniques outlined in this paper immediately lead to efficient pipelined implementations of this primitive for the complete inorder binary tree, hypercube and shu*e exchange network families. 4 Sorting on a Pipelined Hypercube In this section, we describe a simplified implementation of the optimal merging algorithm of Varman and Doshi <ref> [17] </ref>, and show how this can be used to develop a pipelined version of the sorting algorithm of Nassimi and Sahni [10] for a pipelined model of the hypercube. The Sort operation is defined as follows. <p> For the 1-port model of the hypercube that we have been considering thus far, see [1], [4], [7], [9], [10] and [12]. For examples of results based on other assumptions, we refer the reader to [13], [15], <ref> [17] </ref> and [18]. The time bounds for the merging and sorting algorithms described in this section do not apply to the 1-port model of computation that we have been considering up to this point. <p> This model, which we refer to as the pipelined hypercube model, was originally 8 defined by Varman and Doshi <ref> [17] </ref>, and we refer the reader to their paper for both the strict definition as well as the hardware implementation details. We only need the pipelined model of the hypercube for performing pipelined inverse concentration routes. <p> We now describe a pipelined algorithm for merging two sorted lists X and Y , each of length pk, on p processors. The algorithm is similar to that proposed by Varman and Doshi <ref> [17] </ref>, but is somewhat simpler. The optimal merging algorithm of Anderson, Mayr and Warmuth for the EREW PRAM also takes a similar approach [2]. For expository purposes, we make the (avoidable) assumption that all of the 2pk input values are distinct.
Reference: [18] <author> B. Wagar. Hyperquicksort: </author> <title> A fast sorting algorithm for hypercubes. </title> <booktitle> In Proceedings of the Second Conference on Hypercube Multiprocessors, </booktitle> <pages> pages 292-299, </pages> <year> 1986. </year> <month> 15 </month>
Reference-contexts: For the 1-port model of the hypercube that we have been considering thus far, see [1], [4], [7], [9], [10] and [12]. For examples of results based on other assumptions, we refer the reader to [13], [15], [17] and <ref> [18] </ref>. The time bounds for the merging and sorting algorithms described in this section do not apply to the 1-port model of computation that we have been considering up to this point.
References-found: 18

