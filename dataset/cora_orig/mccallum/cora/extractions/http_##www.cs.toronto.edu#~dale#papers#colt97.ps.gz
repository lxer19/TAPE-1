URL: http://www.cs.toronto.edu/~dale/papers/colt97.ps.gz
Refering-URL: http://www.cs.toronto.edu/~dale/
Root-URL: 
Email: fgrove,nickl,daleg@research.nj.nec.com  
Author: Adam J. Grove Nick Littlestone Dale Schuurmans 
Date: July 1997.  
Note: To appear in Proceedings of the Tenth Annual Conference on Computational Learning Theory (COLT-97), Nashville,  
Address: 4 Independence Way Princeton NJ 08540, USA  
Affiliation: NEC Research Institute  
Abstract: General convergence results for linear discriminant updates Abstract The problem of learning linear discriminant concepts can be solved by various mistake-driven update procedures, including the Winnow family of algorithms and the well-known Perceptron algorithm. In this paper we define the general class of quasi-additive algorithms, which includes Perceptron and Winnow as special cases. We give a single proof of convergence that covers much of this class, including both Perceptron and Winnow but also many novel algorithms. Our proof introduces a generic measure of progress that seems to capture much of when and how these algorithms converge. Using this measure, we develop a simple general technique for proving mistake bounds, which we apply to the new algorithms as well as existing algorithms. When applied to known algorithms, our technique automatically produces close variants of existing proofs (and we generally obtain the known bounds, to within constants) thus showing, in a certain sense, that these seem ingly diverse results are fundamentally isomorphic. 
Abstract-found: 1
Intro-found: 1
Reference: [Blo62] <author> H. D. </author> <title> Block. The perceptron: a model for brain functioning. </title> <journal> Reviews of Modern Physics, </journal> <volume> 34(1) </volume> <pages> 123-135, </pages> <year> 1962. </year>
Reference: [CFH + 93] <author> Nicolo Cesa-Bianchi, Yoav Freund, David P. Helmbold, David Haussler, Robert E Schapire, and Manfred K Warmuth. </author> <title> How to use expert advice. </title> <booktitle> In Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 382-391, </pages> <year> 1993. </year>
Reference: [CHP96] <author> Nicolo Cesa-Bianchi, David P. Helmbold, and Sandra Panizza. </author> <title> On bayes methods for on-line boolean prediction. </title> <booktitle> In Proceedings of the Ninth Annual Conference on Computational Learning Theory, </booktitle> <pages> pages 314-324, </pages> <year> 1996. </year>
Reference: [DH73] <author> R. O. Duda and P. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: The analysis (whose details we omit, but which is related to the proof of Theorem 6.1) turns out to essentially isomorphic to another standard proof of Perceptron convergencesee <ref> [DH73] </ref>. This other proof gives the same bound. We have been able to show, using Legendre-Fenchel transforms as an important tool, that in this and various other cases, varying from g (1) (subject to certain conditions) in fact cannot lead to better bounds.
Reference: [Ell85] <author> R. Ellis. </author> <title> Entropy, Large Deviations, and Statistical Mechanics. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Neither convexity nor differentiability is essential for this, though differentiability may be useful at other stages (in particular, in proving that progress is made at updates). The theory and language of Legendre-Fenchel transforms <ref> [Ell85] </ref> (also called conjugate functions in convex analysis [Roc70]) seems particularly useful here. Briefly, the Legendre-Fenchel transform of H ( z) is the function H fl ( u) equal to the largest value such that H ( z) u z + H fl ( u) is non-negative for all z.
Reference: [HKW96] <author> D. Helmbold, J. Kivinen, and M. Warmuth. </author> <title> Worst-case loss bounds for single neurons. </title> <booktitle> In Proceedings of NIPS-8, </booktitle> <pages> pages 309-315, </pages> <year> 1996. </year>
Reference-contexts: base predictions on w x for some weight vector w and instance x, but their predictions can be some continuous function of w x and the loss can be a continuous function L of the true label y and ( w x). (The choice of these functions is discussed in <ref> [HKW96] </ref>.) This is sometimes referred to as a regression problem, as compared to the classification problem we consider. Kivinen and Warmuth give a very general construction for deriving various learning algorithms, which we now briefly describe.
Reference: [KW95] <author> Jyrki Kivinen and Manfred K. Warmuth. </author> <title> The perceptron algorithm vs. winnow: linear vs. logarithmic mistake bounds when few input variables are relevant. </title> <booktitle> In Proceedings of the 1995 Workshop on Computational Learning Theory, </booktitle> <pages> pages 289-296, </pages> <year> 1995. </year>
Reference-contexts: On the other hand, as the parameter p increases, the family tends to look more and more like a Winnow algorithm. This interpolating property is potentially significant because it is known, from both experiment and theory (e.g. <ref> [KW95] </ref>), that Perceptron and Winnow-like algorithms can perform very differently on various types of problem. It might therefore be useful if we could trade-off their relative strengths in a flexible and principled way. Thus, this family could be extremely interesting from a practical point of view.
Reference: [KW97a] <author> Katy Kazoury and Manfred K. Warmuth. </author> <title> Relative loss bounds and the exponential family of distributions. </title> <type> (unpublished manuscript), </type> <year> 1997. </year>
Reference-contexts: The distance function d used in [KW97b] also relates dual parameters (in their setting, the precise definition of the parameter corresponding to z depends on the loss that is being considered); Warmuth and Kazoury plan to discuss this duality, and a motivation based on the exponential family of distributions, in <ref> [KW97a] </ref>. In their setting the update rule changes as the distance function is varied. In [KW97b], they discuss distance extremely generally, and then study certain specific examples; a class corresponding to our quasi-additive algorithms does not arise, and they do not include any general convergence result analogous to ours.
Reference: [KW97b] <author> J. Kivinen and M. Warmuth. </author> <title> Exponentiated gradient versus gradient descent for linear predictors. </title> <journal> Information and Computation, </journal> <volume> 132(1) </volume> <pages> 1-63, </pages> <year> 1997. </year> <note> An earlier version appeared in Proceedings of the Twenty-Seventh Annual ACM Symposium on Theory of Computing (STOC 1995). </note>
Reference-contexts: The approach seems very different in spirit from the framework we discuss in this paper, and we suspect that the two are largely unrelated to each other. There appears to be a closer connection with Kivinen and Warmuth's <ref> [KW97b] </ref> and other related papers. <p> Focusing on this particular family has allowed us to obtain explicit general convergence results (Theorems 4.1 and 4.2), which help identify which of the algorithms suggested by the framework will converge. The distance function d used in <ref> [KW97b] </ref> also relates dual parameters (in their setting, the precise definition of the parameter corresponding to z depends on the loss that is being considered); Warmuth and Kazoury plan to discuss this duality, and a motivation based on the exponential family of distributions, in [KW97a]. <p> In their setting the update rule changes as the distance function is varied. In <ref> [KW97b] </ref>, they discuss distance extremely generally, and then study certain specific examples; a class corresponding to our quasi-additive algorithms does not arise, and they do not include any general convergence result analogous to ours. <p> Another obvious question is to consider the regression model discussed in Section 7; not only is this an inherently important problem but may also help us understand the connection with <ref> [KW97b] </ref> more completely. We suspect that the analysis suggested in this paper has not yet reached its final form, even for the straightforward case of pure quasi-additive classification algorithms. Here we briefly describe just one of the directions we are pursuing.
Reference: [KW97c] <author> Jyrki Kivinen and Manfred Warmuth. </author> <title> Relative loss bounds for multiclass regression problems. </title> <type> (unpublished manuscript), </type> <year> 1997. </year>
Reference: [Lit88] <author> N. Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: A new linear threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: This is true even for infinite sequences of examples. However, beyond mere convergence, the classical proofs of Perceptron convergence (for instance [MP69,DH73]) and Littlestone's proofs for members of the Winnow family <ref> [Lit88] </ref> [Lit89] also provide bounds on the number of mistakes made before a perfect classifier is found for the sequence. (In all cases, this bound depends on the width of the gap, and is independent of the number of examples in the sequence.) Interestingly, these proofs all have the same overall
Reference: [Lit89] <author> N. Littlestone. </author> <title> Mistake bounds and linear-threshold learning algorithms. </title> <type> PhD thesis, </type> <institution> University of California, Santa Cruz, </institution> <year> 1989. </year> <note> Technical Report UCSC-CRL-89-11. </note>
Reference-contexts: This is true even for infinite sequences of examples. However, beyond mere convergence, the classical proofs of Perceptron convergence (for instance [MP69,DH73]) and Littlestone's proofs for members of the Winnow family [Lit88] <ref> [Lit89] </ref> also provide bounds on the number of mistakes made before a perfect classifier is found for the sequence. (In all cases, this bound depends on the width of the gap, and is independent of the number of examples in the sequence.) Interestingly, these proofs all have the same overall structure: <p> For example, for Perceptron, two different instantiations of our approach correspond to two of the most famous proofs of Percetron convergence. One of these instantiations, when applied to the Winnow family, leads to almost exactly the same measures of progress used by Littlestone in <ref> [Lit89] </ref>. Our results thus show that, in a certain sense, all these previous proofs are closely related. In Section 6 we introduce a new family of quasi-additive algorithms, which we call p-norm Perceptron algorithms, whose convergence is assured by the results in Section 4. <p> We call this general family of algorithms quasi-additive, as they essentially involve an additive update at their core. In particular, we can express the other algorithms in the Winnow family in essentially this fashion. For example, 2 To compare this with the presentation in <ref> [Lit89] </ref>, note that the parameter fi there is here 1 ff . 3 Recall that the hyperbolic sine function sinh is defined by sinh x = e x e x 2 . the algorithm called Weighted Majority in [LW89,Lit89] is equivalent 4 to another quasi-additive procedure defined by choosing f (z) <p> We can also apply the technique to derive mistake bounds for Balanced Winnow (i.e., f (z) = 2 sinh z), which again achieves bounds that are comparable to Littlestone's <ref> [Lit89] </ref> in an equally short argument. Next, we consider the Perceptron Algorithm. Here f (z) = z, the identity function, so g (z) = z 2 =2, g (1) (z) = p and H = i z 2 i = k zk 2 .
Reference: [Lit91] <author> N. Littlestone. </author> <title> Redundant noisy attributes, attribute errors, and linear-threshold learning using Winnow. </title> <booktitle> In Proceedings COLT-91, </booktitle> <pages> pages 147-156, </pages> <year> 1991. </year>
Reference: [Lit95] <author> N. Littlestone. </author> <title> Comparing several linear-threshold learning algorithms on tasks involving superfluous attributes. </title> <booktitle> In Proceedings ML-95, </booktitle> <pages> pages 353-361, </pages> <year> 1995. </year>
Reference: [Lit97] <author> N. Littlestone. </author> <title> An apobayesian relative of winnow. </title> <booktitle> In Advances in Neural Information Processing Systems 9, </booktitle> <year> 1997. </year>
Reference-contexts: However, we emphasize that these results are very preliminary, and more thorough experiments are important future work. 7 Related work We are aware of two other explicitly proposed schemes to unify additive (Perceptron-like) algorithms with multiplicative algorithms such as Winnow. Littlestone <ref> [Lit97] </ref> has shown that they can be viewed as apobayesian algorithms.
Reference: [LW89] <author> N. Littlestone and M. Warmuth. </author> <title> The weighted majority algorithm. </title> <booktitle> In Proceedings FOCS-89, </booktitle> <pages> pages 256-261, </pages> <year> 1989. </year>
Reference: [MP69] <author> M. L. Minsky and S. A. Papert. </author> <title> Perceptrons. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1969. </year>
Reference: [Nil65] <author> N. J. Nilsson. </author> <title> Learning Machines. </title> <publisher> Morgan Kauf-mann, </publisher> <address> San Mateo, CA, </address> <year> 1965. </year>
Reference: [Pap61] <author> S. Papert. </author> <title> Some mathematical models of learning. </title> <booktitle> In Proceedings of the Fourth London Symposium on Information Theory, </booktitle> <year> 1961. </year>
Reference: [Roc70] <author> R. Rockafellar. </author> <title> Convex Analysis. </title> <publisher> Princeton University Press, </publisher> <year> 1970. </year>
Reference-contexts: Neither convexity nor differentiability is essential for this, though differentiability may be useful at other stages (in particular, in proving that progress is made at updates). The theory and language of Legendre-Fenchel transforms [Ell85] (also called conjugate functions in convex analysis <ref> [Roc70] </ref>) seems particularly useful here. Briefly, the Legendre-Fenchel transform of H ( z) is the function H fl ( u) equal to the largest value such that H ( z) u z + H fl ( u) is non-negative for all z.
Reference: [Ros62] <author> F. Rosenblatt. </author> <title> Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms. </title> <publisher> Spartan Books, </publisher> <address> Washington, D. C., </address> <year> 1962. </year>
Reference: [Vov90] <author> Volodimir G. Vovk. </author> <title> Aggregating strategies. </title> <booktitle> In Proceedings of the 1990 Workshop on Computational Learning Theory, </booktitle> <pages> pages 371-383, </pages> <year> 1990. </year>
Reference: [War97] <author> Manfred Warmuth. </author> <type> Personal communication, </type> <year> 1997. </year>
Reference-contexts: But this loss function is not continuous and thus does not fit into the class of loss functions that are discussed in [KW97b,HKW96]. However, Warmuth has been exploring a generalization of their approach that does include classification problems <ref> [War97] </ref>. Conversely, we hope that our framework could be extended to give new understanding of regression problems.
Reference: [WJ97] <author> Manfred K. Warmuth and Arun Jagota. </author> <title> Continuous time non-linear gradient descent: Convergence and relative loss bounds. </title> <type> (unpublished manuscript), </type> <year> 1997. </year>
References-found: 24

