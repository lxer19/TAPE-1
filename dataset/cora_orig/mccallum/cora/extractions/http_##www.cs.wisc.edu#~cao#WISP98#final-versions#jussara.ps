URL: http://www.cs.wisc.edu/~cao/WISP98/final-versions/jussara.ps
Refering-URL: http://www.cs.wisc.edu/~cao/WISP98-program.html
Root-URL: http://www.cs.wisc.edu
Email: fjussara,dabu,manikuti,caog@cs.wisc.edu  
Title: Providing Differentiated Levels of Service in Web Content Hosting  
Author: Jussara Almeida, Mihaela Dabu, Anand Manikutty and Pei Cao 
Affiliation: Computer Sciences Department University of Wisconsin-Madison  
Abstract: Web content hosting, in which a Web server stores and provides Web access to documents for different customers, is becoming increasingly common. Due to the variety of customers (corporate, individuals, etc.), providing differentiated levels of service is often an important issue for the hosts. Most server implementations, however, are not structured to service requests based on different levels of quality of service (QoS). This paper presents our attempts at augmenting a popular server implementation with differentiated QoS features. We explore priority-based request scheduling at both user and kernel levels. We find that simple strategies such as controlling the numbers of processes can improve the response time of high-priority requests notably while preserving the system throughput. We also find that the kernel-level approach tends to penalize low-priority requests less significantly than the user-level approach, while improving the performance of high-priority requests similarly. Based on our experiments, we discuss the bottlenecks and limitations from kernel implementations that prevent the augmented server from achieving better performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Anderson, E., Patterson, D., Brewer E., </author> <title> The Magicrouter, an Application of Fast Packet Interposing, </title> <booktitle> Second Symposium on Operating Systems Design and Implementation, </booktitle> <month> May, </month> <year> 1996. </year>
Reference-contexts: Previous works have addressed the general problem of quality of service by using different techniques such as data prefetching [4] and image compression [11]. Other approaches <ref> [1, 8] </ref> address the problem in the context of a distributed web server. In [1], the authors developed a system that implements fast packet interposing that can be used to balance the load across a cluster of servers. <p> Previous works have addressed the general problem of quality of service by using different techniques such as data prefetching [4] and image compression [11]. Other approaches [1, 8] address the problem in the context of a distributed web server. In <ref> [1] </ref>, the authors developed a system that implements fast packet interposing that can be used to balance the load across a cluster of servers. In [8], the authors address the problem of load balancing in a cluster of servers by using secondary IP addresses.
Reference: [2] <author> Arlitt, M. and Williamson, C., </author> <title> Web Server Workload Characterization, </title> <booktitle> Proceedings of the 1996 SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: In our experiments, we set the number of client processes as 30 and use two different work-loads, described in Table 1. The parameters that define workload WB are representative of the kinds of workload typically found in busy WWW servers <ref> [2] </ref>. 5 Results This section discusses the results obtained for both user and kernel level approaches. Recall that the performance metric is the average latency of a request as perceived by the server.
Reference: [3] <author> Gaurav Banga and Peter Druschel, </author> <title> Measuring the Capacity of a Web Server, </title> <booktitle> Proceedings of 1997 USENIX Symposium on Internet Technology and Systems, </booktitle> <month> Dec, </month> <year> 1997. </year>
Reference-contexts: We choose to study process-per-request Web servers because Apache uses this architecture and Apache is the most popular Web server software in use. Finally, Webstone is a simplistic benchmark and cannot drive the Web server to overload <ref> [3] </ref>. We need to perform tests under other kinds of bursty loads with various mix of high-priority and low-priority requests. This is part of our future work. 7 Conclusions We have investigated approaches to provide differentiated quality of service by assigning priorities to requests based on the requested documents.
Reference: [4] <author> Banatre, M., Issamy, V., Leleu F. and Char-piot B., </author> <title> Providing Quality of Service over the Web: A Newspaper-based Approach, </title> <booktitle> Proceedings of the Sixth International World Wide Web Conference, </booktitle> <address> California, </address> <month> April, </month> <year> 1997. </year>
Reference-contexts: Here, we focus on the end systems, and investigate issues such as process scheduling and OS resource scheduling that are not typically addressed in the networking QoS studies. Previous works have addressed the general problem of quality of service by using different techniques such as data prefetching <ref> [4] </ref> and image compression [11]. Other approaches [1, 8] address the problem in the context of a distributed web server. In [1], the authors developed a system that implements fast packet interposing that can be used to balance the load across a cluster of servers.
Reference: [5] <author> Beck, M., Bohme, H., Dziadzka, M., Kunitz, U., Magnus, R. and Verworner, D., </author> <title> Linux Kernel Internals, </title> <publisher> Addison-Wesley, </publisher> <year> 1996. </year>
Reference-contexts: In the user-level approach, Apache is modified to include a scheduler process, responsible for deciding the order in which the requests should be handled. The scheduler restricts the maximum number of concurrent processes servicing requests of each priority. In the kernel-level approach, the Linux kernel <ref> [5] </ref> is modified such that request priorities are mapped into priorities of the HTTP processes handling them. Using the Webstone benchmark suite, we measure the effect of the approaches on request latency.
Reference: [6] <author> John Bruno, Eran Gabber, Banu Ozden and Abraham Silberschatz, </author> <title> The Eclipse Operating System: Providing Quality of Service via Reservation Domains, </title> <booktitle> Proceedings of the 1998 USENIX Technical Conference, </booktitle> <month> June </month> <year> 1998. </year>
Reference-contexts: Only schemes that directly control the resource scheduling at the three subsystems can provide robust quality-of-service. Investigation of such schemes is out of the scope of this paper. However, we do note that <ref> [6] </ref> and [17] are recent attempts in this area. Though we have only studied process-per-request Web servers, the principle of providing differentiated QoS through restricting the number of concurrent low-priority requests applies to other types of Web servers.
Reference: [7] <author> Crovella, M., and Bestavros, A., </author> <title> Self-similarity in World Wide Web Traffic: Evidence and Possible Causes, </title> <booktitle> Proceedings of the 1996 SIGMET-RICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1996. </year>
Reference: [8] <author> Damani, O., Chung, P., Huang, Y., Kintala, C., Wang, Y., ONE-IP: </author> <title> Techniques for Hosting a Service on a Cluster of Machines, </title> <booktitle> 6th International World Wide Web Conference, </booktitle> <month> April </month> <year> 1997. </year> <pages> Page 11 </pages>
Reference-contexts: Previous works have addressed the general problem of quality of service by using different techniques such as data prefetching [4] and image compression [11]. Other approaches <ref> [1, 8] </ref> address the problem in the context of a distributed web server. In [1], the authors developed a system that implements fast packet interposing that can be used to balance the load across a cluster of servers. <p> Other approaches [1, 8] address the problem in the context of a distributed web server. In [1], the authors developed a system that implements fast packet interposing that can be used to balance the load across a cluster of servers. In <ref> [8] </ref>, the authors address the problem of load balancing in a cluster of servers by using secondary IP addresses.
Reference: [9] <author> Peter Druschel and Gaurav Banga, </author> <title> Lazy Re--ceiver Processing (LRP): A Network Subsystem Architecture for Server Systems, </title> <booktitle> Second Symposium on Operating Systems Design and Implementation, </booktitle> <month> May, </month> <year> 1996. </year>
Reference-contexts: It has not addressed issues such as kernel implementations that circumvent QoS schemes, coordination among scheduling of different resources, and workloads that are more representative of real-life Web server traffic. Implementation features in traditional kernel networking subsystem can easily defeat any QoS scheme. For example, [14] and <ref> [9] </ref> point out several problems in traditional kernel TCP/IP implementation that render any user-level QoS scheme a failure under heavy-load. Only a new networking implementation scheme such as the Lazy Receiver Processing [9] can solve the problems. Lazy Receiver Processing would also work well with our priority-based approaches. <p> Implementation features in traditional kernel networking subsystem can easily defeat any QoS scheme. For example, [14] and <ref> [9] </ref> point out several problems in traditional kernel TCP/IP implementation that render any user-level QoS scheme a failure under heavy-load. Only a new networking implementation scheme such as the Lazy Receiver Processing [9] can solve the problems. Lazy Receiver Processing would also work well with our priority-based approaches. Combinding the two is part of our future work. For servers with small main memory, the kernel's file and disk I/O subsystems also affect QoS schemes.
Reference: [10] <institution> Internet Domain Survey, Network Wizards, Jan-uary, </institution> <year> 1997. </year> <note> URL: http://www.nw.cm/zone/summary-reports/report-9701.doc. </note>
Reference-contexts: 1 Introduction Due to the explosive growth of the Web and the ever-increasing resource demands on the servers <ref> [12, 13, 10] </ref>, Web content hosting is an increasingly common practice.
Reference: [11] <author> Fox, A., and Brewer, E., </author> <title> Reducing WWW Latency and Bandwidth Requirements by Real-Time Distillation, </title> <booktitle> Proceedings of the Fifth International World Wide Web Conference, </booktitle> <address> Paris, France, </address> <month> May, </month> <year> 1996. </year>
Reference-contexts: Previous works have addressed the general problem of quality of service by using different techniques such as data prefetching [4] and image compression <ref> [11] </ref>. Other approaches [1, 8] address the problem in the context of a distributed web server. In [1], the authors developed a system that implements fast packet interposing that can be used to balance the load across a cluster of servers.
Reference: [12] <author> Mogul, J., </author> <title> Network Behavior of a Busy Web Server and its Clients, </title> <type> Research Report 95/5, </type> <institution> DEC Western Research Laboratory, </institution> <month> October </month> <year> 1995 </year>
Reference-contexts: 1 Introduction Due to the explosive growth of the Web and the ever-increasing resource demands on the servers <ref> [12, 13, 10] </ref>, Web content hosting is an increasingly common practice.
Reference: [13] <author> Mogul, J., </author> <title> Operating System Support for Busy Internet Servers, </title> <booktitle> Proceedings of the Fifth Workshop on Hot Topics in Operating Systems, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Due to the explosive growth of the Web and the ever-increasing resource demands on the servers <ref> [12, 13, 10] </ref>, Web content hosting is an increasingly common practice.
Reference: [14] <author> J. C. Mogul and K. K. Ramakrishnan. </author> <title> Eliminating receive livelock in an interrupt-driven kernel. </title> <booktitle> Proceedings of the 1996 Usenix Technical Conference, </booktitle> <pages> pages 99-111, </pages> <year> 1996. </year>
Reference-contexts: It has not addressed issues such as kernel implementations that circumvent QoS schemes, coordination among scheduling of different resources, and workloads that are more representative of real-life Web server traffic. Implementation features in traditional kernel networking subsystem can easily defeat any QoS scheme. For example, <ref> [14] </ref> and [9] point out several problems in traditional kernel TCP/IP implementation that render any user-level QoS scheme a failure under heavy-load. Only a new networking implementation scheme such as the Lazy Receiver Processing [9] can solve the problems. Lazy Receiver Processing would also work well with our priority-based approaches.
Reference: [15] <author> Robinnson, D. </author> <title> and the Apache Group, APACHE An HTTP Server, Reference Manual, </title> <note> 1995. URL: http://www.apache.org. </note>
Reference-contexts: However, most Web servers today do not provide support for differentiated quality of service. To do so would require the incoming requests be classified into different categories and different levels of service be applied to each category. Apache <ref> [15] </ref>, one of the most used Web servers, handles incoming requests in a first-come first-served manner. All the requests correctly received are eventually handled, regardless of the type of requests and the load on the system. <p> For the kernel-level approach, we used the Linux 2.1.54 operating system on a DEC Cele-bris XL590 90MHz Pentium machine with 32 MB of main memory. The server software for both setups was Apache, version 1.3b2, a public domain HTTP server <ref> [15] </ref>. Our Apache server was configured to run in standalone mode. The KeepAlive option was deactivated (only one HTTP request was serviced per connection) and all other parameters are set as the default values.
Reference: [16] <author> Trent, G. & Sake, M. WebSTONE: </author> <title> The First Generation in HTTP Server Benchmark-ing, </title> <month> February </month> <year> 1995. </year> <note> URL: http://www.sgi.com/ Products/WebFORCE/WebStone. </note>
Reference-contexts: Our Apache server was configured to run in standalone mode. The KeepAlive option was deactivated (only one HTTP request was serviced per connection) and all other parameters are set as the default values. To generate a WWW workload, we use WebStone <ref> [16] </ref> (version 2.0.0), an industry-standard benchmark for generating HTTP requests. WebStone is a configurable client-server benchmark that uses workload parameters and client processes to generate Web requests. This allows a server to be evaluated in a number of different ways.
Reference: [17] <author> Carl A. Waldspurger and William E. Weihl, </author> <title> Lottery Scheduling: Flexible Proportional-Share Resource Management, </title> <booktitle> Proceedings of First Symposium on Operating Systems Design and Implementation (OSDI), </booktitle> <pages> pages 1-12, </pages> <month> November </month> <year> 1994. </year> <pages> Page 12 </pages>
Reference-contexts: Only schemes that directly control the resource scheduling at the three subsystems can provide robust quality-of-service. Investigation of such schemes is out of the scope of this paper. However, we do note that [6] and <ref> [17] </ref> are recent attempts in this area. Though we have only studied process-per-request Web servers, the principle of providing differentiated QoS through restricting the number of concurrent low-priority requests applies to other types of Web servers.
References-found: 17

