URL: http://www.cs.purdue.edu/coast/archive/clife/ES/papers/ecal95.ps.gz
Refering-URL: http://www.cs.purdue.edu/coast/archive/clife/ES/papers/
Root-URL: http://www.cs.purdue.edu
Phone: 2  
Title: Contemporary Evolution Strategies  
Author: Hans-Paul Schwefel and Gunter Rudolph 
Address: D-44221 Dortmund  Dortmund, D-44227 Dortmund  
Affiliation: 1 University of Dortmund, Department of Computer Science,  Informatik Centrum Dortmund at the University of  
Abstract: After an outline of the history of evolutionary algorithms, a new (; ; ; ) variant of the evolution strategies is introduced formally. Though not comprising all degrees of freedom, it is richer in the number of features than the meanwhile old (; ) and (+) versions. Finally, all important theoretically proven facts about evolution strategies are briefly summarized and some of many open questions concerning evolutionary algorithms in general are pointed out.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> De Jong, K. (Ed.) </author> <year> (1993), </year> <title> Evolutionary computation (journal), </title> <publisher> MIT Press, </publisher> <address> Cam-bridge MA </address>
Reference-contexts: Finally, all important theoretically proven facts about evolution strategies are briefly summarized and some of many open questions concerning evolutionary algorithms in general are pointed out. 1 A Brief History of Evolutionary Computation Since the spring of 1993, when the first issue of the international journal on Evolutionary Computation <ref> [1] </ref> appeared, more and more people have become aware of computer algorithms known to insiders since nearly thirty years as Genetic Algorithms (GAs), Evolution Strategies (ESs), and Evolutionary Programming (EP). As a common denominator the term Evolutionary Algorithms (EAs) has become rather widespread meanwhile.
Reference: 2. <author> Ashby, W.R. </author> <year> (1960), </year> <title> Design for a brain, 2nd ed., </title> <publisher> Wiley, </publisher> <address> New York </address>
Reference-contexts: Artificial neural nets, homeostatic controllers, predictors and optimizers emerged, and if their environment could not easily be modeled in simple analytical terms, random number generators became attractive in order to bridge the knowledge gap towards deciding upon the next action within the circuits. Ashby's homeostat <ref> [2] </ref>, Brooks' [3] and Rastrigin's [4] optimizers are witnesses of those days. The first digital computers, however, were not that fast as often called in papers of that time.
Reference: 3. <author> Brooks, S.H. </author> <year> (1958), </year> <title> A discussion of random methods for seeking maxima, </title> <journal> Oper. Res. </journal> <volume> 6, </volume> <pages> 244-251 </pages>
Reference-contexts: Artificial neural nets, homeostatic controllers, predictors and optimizers emerged, and if their environment could not easily be modeled in simple analytical terms, random number generators became attractive in order to bridge the knowledge gap towards deciding upon the next action within the circuits. Ashby's homeostat [2], Brooks' <ref> [3] </ref> and Rastrigin's [4] optimizers are witnesses of those days. The first digital computers, however, were not that fast as often called in papers of that time.
Reference: 4. <author> Rastrigin, L.A. </author> <year> (1960), </year> <title> Extremal control by the method of random scanning, </title> <booktitle> Automation and Remote Control 21, </booktitle> <pages> 891-896 </pages>
Reference-contexts: Ashby's homeostat [2], Brooks' [3] and Rastrigin's <ref> [4] </ref> optimizers are witnesses of those days. The first digital computers, however, were not that fast as often called in papers of that time.
Reference: 5. <author> Favreau, R.F., R. </author> <title> Franks (1958), Random optimization by analogue techniques, </title> <booktitle> Proceedings of the IInd Analogue Computation Meeting, </booktitle> <address> Strasbourg, </address> <month> Sept. </month> <year> 1958, </year> <pages> pp. 437-443 </pages>
Reference-contexts: Ashby's homeostat [2], Brooks' [3] and Rastrigin's [4] optimizers are witnesses of those days. The first digital computers, however, were not that fast as often called in papers of that time. Thus artificial or simulated evolutionary processes to solve real-world problems <ref> [5, 6] </ref> had to give way to quicker problem solving methods relying upon simple computational models like linear or quadratic input-output relations. Another reason for the dominance of greedy algorithms has been their strong backing from theory.
Reference: 6. <author> Bremermann, H.J. </author> <year> (1962), </year> <title> Optimization through evolution and recombination, </title> <editor> in: Yovits, M.C., G.T. Jacobi, D.G. Goldstein (Eds.), </editor> <title> Self-organizing systems, </title> <publisher> Spartan, </publisher> <address> Washington, DC, </address> <pages> pp. 93-106 </pages>
Reference-contexts: Ashby's homeostat [2], Brooks' [3] and Rastrigin's [4] optimizers are witnesses of those days. The first digital computers, however, were not that fast as often called in papers of that time. Thus artificial or simulated evolutionary processes to solve real-world problems <ref> [5, 6] </ref> had to give way to quicker problem solving methods relying upon simple computational models like linear or quadratic input-output relations. Another reason for the dominance of greedy algorithms has been their strong backing from theory. <p> That is why rather often problems have been fitted to the abilities of solution algorithms by rigorous simplification. Besides Bremermann's simulated evolution <ref> [6] </ref>, used for solving nonlinear systems of equations, for example, L. Fogel [7] devised a finite state automaton for prediction tasks by simulating evolutionary mechanisms. The current version of this approach, called Evolutionary Programming (EP), is due to D. Fogel [8] and is used for continuous parameter optimization.
Reference: 7. <author> Fogel, L.J. </author> <year> (1962), </year> <title> Autonomous automata, Ind. </title> <booktitle> Research 4, </booktitle> <pages> 14-19 </pages>
Reference-contexts: That is why rather often problems have been fitted to the abilities of solution algorithms by rigorous simplification. Besides Bremermann's simulated evolution [6], used for solving nonlinear systems of equations, for example, L. Fogel <ref> [7] </ref> devised a finite state automaton for prediction tasks by simulating evolutionary mechanisms. The current version of this approach, called Evolutionary Programming (EP), is due to D. Fogel [8] and is used for continuous parameter optimization.
Reference: 8. <author> Fogel, </author> <title> D.B. </title> <booktitle> (1995), Evolutionary Computation|toward a new philosophy of machine intelligence, </booktitle> <publisher> IEEE Press, </publisher> <address> Piscataway NJ </address>
Reference-contexts: Besides Bremermann's simulated evolution [6], used for solving nonlinear systems of equations, for example, L. Fogel [7] devised a finite state automaton for prediction tasks by simulating evolutionary mechanisms. The current version of this approach, called Evolutionary Programming (EP), is due to D. Fogel <ref> [8] </ref> and is used for continuous parameter optimization. Discrete, even combinatorial search, adaptation, and optimization is the domain of Holland's [9] Genetic Algorithm (GA) which comprises many different versions nowadays.
Reference: 9. <author> Holland, J.H. </author> <year> (1975), </year> <title> Adaptation in natural and artificial systems, </title> <publisher> University of Michigan Press, </publisher> <address> Ann Arbor MI </address>
Reference-contexts: Fogel [7] devised a finite state automaton for prediction tasks by simulating evolutionary mechanisms. The current version of this approach, called Evolutionary Programming (EP), is due to D. Fogel [8] and is used for continuous parameter optimization. Discrete, even combinatorial search, adaptation, and optimization is the domain of Holland's <ref> [9] </ref> Genetic Algorithm (GA) which comprises many different versions nowadays. Independently of both these origins, Evolution Strategies (ESs) came to the fore as experimental optimization techniques [10, 11], e.g., to drive a flexible pipe bending or changeable nozzle contour successively into a form with minimal loss of energy.
Reference: 10. <author> Rechenberg, I. </author> <year> (1964), </year> <title> Cybernetic solution path of an experimental problem, Royal Aircraft Establishment, Library Translation 1122, </title> <address> Farnborough, Hants, </address> <month> Aug. </month> <year> 1965, </year> <title> English translation of the unpublished written summary of the lecture "Kyberne-tische Losungsansteuerung einer experimentellen Forschungsaufgabe", </title> <booktitle> delivered at the joint annual meeting of the WGLR and DGRR, </booktitle> <address> Berlin, </address> <year> 1964 </year>
Reference-contexts: Fogel [8] and is used for continuous parameter optimization. Discrete, even combinatorial search, adaptation, and optimization is the domain of Holland's [9] Genetic Algorithm (GA) which comprises many different versions nowadays. Independently of both these origins, Evolution Strategies (ESs) came to the fore as experimental optimization techniques <ref> [10, 11] </ref>, e.g., to drive a flexible pipe bending or changeable nozzle contour successively into a form with minimal loss of energy. Similar to Evolutionary Operation (EVOP [12]) the variables were changed in discrete steps, but stochastically instead of deterministically.
Reference: 11. <editor> Klockgether, J., H.-P. Schwefel (1970), Two-phase nozzle and hollow core jet experiments, in: Elliott, D.G. (Ed.), </editor> <booktitle> Proceedings of the 11th Symposium on Engineering Aspects of Magnetohydrodynamics, </booktitle> <address> Caltech, March 24-26, </address> <year> 1970, </year> <institution> California Institute of Technology, </institution> <address> Pasadena CA, </address> <pages> pp. 141-148 </pages>
Reference-contexts: Fogel [8] and is used for continuous parameter optimization. Discrete, even combinatorial search, adaptation, and optimization is the domain of Holland's [9] Genetic Algorithm (GA) which comprises many different versions nowadays. Independently of both these origins, Evolution Strategies (ESs) came to the fore as experimental optimization techniques <ref> [10, 11] </ref>, e.g., to drive a flexible pipe bending or changeable nozzle contour successively into a form with minimal loss of energy. Similar to Evolutionary Operation (EVOP [12]) the variables were changed in discrete steps, but stochastically instead of deterministically.
Reference: 12. <author> Box, G.E.P. </author> <year> (1957), </year> <title> Evolutionary operation|a method for increasing industrial productivity, </title> <journal> Appl. Stat. </journal> <volume> 6, </volume> <pages> 81-101 </pages>
Reference-contexts: Independently of both these origins, Evolution Strategies (ESs) came to the fore as experimental optimization techniques [10, 11], e.g., to drive a flexible pipe bending or changeable nozzle contour successively into a form with minimal loss of energy. Similar to Evolutionary Operation (EVOP <ref> [12] </ref>) the variables were changed in discrete steps, but stochastically instead of deterministically. The earliest ES version operated on the basis of two individuals only, one parent and one descendant per generation.
Reference: 13. <author> Rechenberg, I. </author> <year> (1973), </year> <title> Evolutionsstrategie|Optimierung technischer Systeme nach Prinzipien der biologischen Evolution, </title> <publisher> Frommann-Holzboog, Stuttgart </publisher>
Reference-contexts: One basic assumption for the proof has been the maintenance of the corresponding optimal mutation variances. For the (1+1) ES this can be approximately 13 achieved by applying the so-called 1=5 success rule. Following Rechenberg <ref> [13] </ref> the mutation variance should be increased as soon as the observed success rate is greater than 1=5 and decreased if it turns out to be less than 1=5 (for a critique, see [17]).
Reference: 14. <author> Schwefel, H.-P. </author> <year> (1977), </year> <title> Numerische Optimierung von Computer-Modellen mittels der Evolutionsstrategie, </title> <publisher> Birkhauser, </publisher> <address> Basle, Switzerland </address>
Reference: 15. <author> Schwefel, H.-P. </author> <year> (1981), </year> <title> Numerical optimization of computer models, </title> <publisher> Wiley, </publisher> <address> Chichester </address>
Reference: 16. <author> Rechenberg, I. </author> <year> (1994), </year> <type> Evolutionsstrategie '94, </type> <institution> Frommann-Holzboog, Stuttgart </institution>
Reference-contexts: This is not the place to go into more details, but proportional control according to that rule has proven to lead to oscillatory behavior with some factor loss in convergence velocity against the optimal case. Linear convergence order, however, is maintained. Rechenberg <ref> [16] </ref> claims linear convergence order for the (; ) ES on the sphere model in case of optimal mutation variances. <p> That 15 is why the recombination type and frequency should be incorporated into the set of internal strategy parameters, too. In nature there is no higher instance for controlling internal parameters in the way which has been proposed with the so-called nested or meta-evolution approach <ref> [16] </ref>. More natural seem to be simulations with several subpopulations, a concept that has been used for EA incarnations on parallel computers [28].
Reference: 17. <author> Schwefel, H.-P. </author> <year> (1995), </year> <title> Evolution and optimum seeking, </title> <publisher> Wiley, </publisher> <address> New York </address>
Reference-contexts: Neither parallel nor multiobjective, neither discrete nor mixed-integer special forms are considered in the following though they exist and have been used already in applications. A recent overview may be found in <ref> [17] </ref>. In the beginning, there existed two different forms of the multimembered evolution strategy, namely the ( + ) and the (; ) ESs. The symbol denotes the number of parents appearing at a time in a population of imaginary individuals. <p> k such that 8 b 2 B k : a k &gt; b : (27) Finally, P (T +1) := k=1 (T+1) 2.4 The termination criterion t (") The termination of the new evolution strategy should be handled in the same way as has been done within the older versions <ref> [17] </ref>: All digital computers handle data only in the form of a finite number of units of information (bits). The number of significant figures and the range of numbers is thereby limited. <p> results are valid not only for this spherical situation, but also for functions like f 2 (x) = e f 1 (x) (a nightmare for quasi-Newton methods, which diverge everywhere in this case) and, approximately at least, also in case of higher even exponents than two in function f 1 <ref> [17] </ref>. One basic assumption for the proof has been the maintenance of the corresponding optimal mutation variances. For the (1+1) ES this can be approximately 13 achieved by applying the so-called 1=5 success rule. <p> Following Rechenberg [13] the mutation variance should be increased as soon as the observed success rate is greater than 1=5 and decreased if it turns out to be less than 1=5 (for a critique, see <ref> [17] </ref>). <p> If one interprets ' as an approximation to the differential _r = dr=dt (literally: the velocity of approaching the optimum x fl of the sphere 14 model function <ref> [17] </ref>) one arrives at concluding K = ' fl for the still open constant in relation (12).
Reference: 18. <author> Rudolph, G. </author> <year> (1994), </year> <title> An evolutionary algorithm for integer programming, </title> <editor> in: Dav-idor, Y., H.-P. Schwefel, R. Manner (Eds.), </editor> <booktitle> Parallel problem solving from nature 16 3, Proceedings of the 3rd PPSN Conference, </booktitle> <address> Jerusalem, </address> <month> Oct. </month> <pages> 9-14, </pages> <year> 1994, </year> <title> vol. </title> <booktitle> 866 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer, Berlin, </publisher> <pages> pp. 139-148 </pages>
Reference-contexts: Though in the first ES experiments the object variables were restricted to discrete values, computerized ESs have mostly been formulated for the continuous case. An exception may be found in Rudolph <ref> [18] </ref>.
Reference: 19. <author> Rudolph, G. </author> <year> (1992), </year> <title> On correlated mutation in evolution strategies, </title> <editor> in: Manner, R., B. Manderick (Eds.), </editor> <booktitle> Parallel problem solving from nature 2, Proceedings of the 2nd PPSN Conference, </booktitle> <address> Brussels, </address> <month> Sept. </month> <pages> 28-30, </pages> <address> 1992, </address> <publisher> North-Holland, Amsterdam, </publisher> <pages> pp. 105-114 </pages>
Reference-contexts: The components of cor can be calculated as follows <ref> [19] </ref>: cor = T z (16) where z = (z 1 ; : : : ; z n ) with z i 2 N (0; ~ 2 i ) 8 i = 1; : : : ; n and n 1 Y n Y T pq ( ~ff j ) (17)
Reference: 20. <author> Born, J. </author> <year> (1978), </year> <title> Evolutionsstrategien zur numerischen Losung von Adaptations-aufgaben, Dr. </title> <type> rer. </type> <institution> nat. Diss., Humboldt University at Berlin </institution>
Reference-contexts: The results will be summarized briefly in the following. A very early global convergence proof for a (1 + 1) ES with one parent and one descendant per generation, elitist selection, no recombination and normally distributed mutations without correlation has been given by Born <ref> [20] </ref>. No continuity, differentiability, or unimodality assumptions must be made. Except for singular solutions, global convergence with probability one in the limit of infinitely many mutations is guaranteed as long as the mutation variance is greater than zero in all directions.
Reference: 21. <author> Back, T., G. Rudolph, H.-P. </author> <title> Schwefel (1993), Evolutionary programming and evolution strategies|similarities and differences, </title> <editor> in: Fogel, D.B., J.W. Atmar (Eds.), </editor> <booktitle> Proceedings of the 2nd Annual Conference on Evolutionary Programming, </booktitle> <address> San Diego, </address> <month> Feb. </month> <pages> 25-26, </pages> <year> 1993, </year> <booktitle> Evolutionary Programming Society, </booktitle> <address> La Jolla CA, </address> <pages> pp. 11-22 </pages>
Reference-contexts: Except for singular solutions, global convergence with probability one in the limit of infinitely many mutations is guaranteed as long as the mutation variance is greater than zero in all directions. The same holds for the more general ( + ) ES <ref> [21] </ref>. More delicate is the non-elitist case of a (1; ) ES for which Rudolph [22] has developed sufficient conditions under which convergence is maintained. <p> An approximation with respect to , when ; ; and equal one, has been found to be as simple as <ref> [21] </ref>: C 2 ln : (46) Beyer [26] has investigated both uniform crossover and global intermediary multi-recombination with = .
Reference: 22. <author> Rudolph, G. </author> <year> (1994), </year> <title> Convergence of non-elitist strategies, </title> <editor> in: Michalewicz, Z., J.D. Schaffer, H.-P. Schwefel, and D.B. Fogel (Eds.), </editor> <booktitle> Proceedings of the 1st IEEE Conference on Evolutionary Computation, IEEE World Congress on Computational Intelligence, </booktitle> <address> Orlando FL, June 27-29, </address> <booktitle> 1994, </booktitle> <volume> vol. 1, </volume> <pages> pp. 63-66 </pages>
Reference-contexts: The same holds for the more general ( + ) ES [21]. More delicate is the non-elitist case of a (1; ) ES for which Rudolph <ref> [22] </ref> has developed sufficient conditions under which convergence is maintained. Like the canonical GA, the (1; ) ES with fixed mutation variances finally stagnates at a distance from the optimum that depends on (actually, it fluctuates around that position).
Reference: 23. <author> Back, T. </author> <year> (1994), </year> <title> Evolutionary algorithms in theory and practice, Dr. </title> <type> rer. </type> <institution> nat. Diss., University of Dortmund, Department of Computer Science, </institution> <month> Feb. </month> <year> 1994 </year>
Reference-contexts: More interesting than all that is an answer to the question of the approximation velocity. Whereas this question is still open for GAs, except for a very special case (see <ref> [23] </ref>), the situation is somewhat better for ESs now.
Reference: 24. <author> Rappl, G. </author> <year> (1984), </year> <title> Konvergenzraten von Random-Search-Verfahren zur globalen Optimierung, Dr. </title> <type> rer. </type> <institution> nat. Diss., Hochschule der Bundeswehr, Munich-Neubiberg, Department of Computer Science, </institution> <month> Nov. </month> <year> 1984 </year>
Reference-contexts: Linear convergence order, that is a constant increase of accurate figures of the object parameter or objective function values over the number of mutations or generations, has been proved by Rappl <ref> [24] </ref> for the (1 + 1) ES when applied to a strongly convex fitness function like f 1 (x) = c 0 + i=1 i ) 2 (42) which has been called spherical model if c i = 1 8i = 1; : : :; n.
Reference: 25. <author> Beyer, H.-G. </author> <year> (1995), </year> <title> Toward a theory of evolution strategies|the (; )-theory, </title> <note> submitted to Evolutionary Computation </note>
Reference-contexts: His law ' = Efrg = C n 2 (44) for the expected difference r = r (g1) r (g) between the Euclidean distances r = r (g1) before and r (g) after one generation is an approximation to the very high-dimensional case (n 1), as Beyer <ref> [25] </ref> has elaborated.
Reference: 26. <author> Beyer, H.-G. </author> <year> (1994), </year> <title> Towards a theory of `evolution strategies'|results from the N - dependent (; ) and the multi-recombinant (=; ) theory, </title> <type> technical report SYS-5/94, </type> <institution> Systems Analysis Research Group, University of Dortmund, Department of Computer Science, </institution> <month> Oct. </month> <year> 1994 </year>
Reference-contexts: An approximation with respect to , when ; ; and equal one, has been found to be as simple as [21]: C 2 ln : (46) Beyer <ref> [26] </ref> has investigated both uniform crossover and global intermediary multi-recombination with = . <p> might speculate about putting together what we know so far to the rather simple formula (for large n and , as well as not too small ): ' fl ~ ln the first factor () being due to the diversity of the population and exploited by recombination (so-called genetic repair <ref> [26] </ref>), the latter ( ) due to the selection pressure two processes that compete with one another. A proof is still missing, however.
Reference: 27. <author> Schwefel, H.-P. </author> <year> (1987), </year> <title> Collective phenomena in evolutionary systems, </title> <editor> in: Check-land, P., I. Kiss (Eds.), </editor> <title> Problems of constancy and change|the complementarity of systems approaches to complexity, </title> <booktitle> papers presented at the 31st Annual Meeting of the International Society for General System Research, </booktitle> <address> Budapest, Hungary, </address> <month> June 1-5, </month> <journal> International Society for General System Research, </journal> <volume> vol. 2, </volume> <pages> pp. 1025-1033 </pages>
Reference-contexts: It even allows for on-line learning of up to n different i and n 2 (n1) different ff j , thus presenting the ultimate degree of freedom for normally distributed mutations. No theory is available for that process, only a few experiments <ref> [27] </ref> have demonstrated that self-adaptation is possible under certain conditions. If these conditions are not observed the process fails and the resulting ES may not converge, even diverge in case of small values for .
Reference: 28. <author> Rudolph, G. </author> <year> (1991), </year> <title> Global optimization by means of distributed evolution strategies, </title> <editor> in: Schwefel, H.-P. and R. Manner (Eds.), </editor> <title> Parallel problem solving from nature, </title> <booktitle> Proceedings of the 1st PPSN Conference, </booktitle> <address> Dortmund, </address> <month> Oct. </month> <pages> 1-3, </pages> <year> 1990, </year> <title> vol. </title> <booktitle> 496 of Lecture Notes in Computer Science, </booktitle> <publisher> Springer, Berlin, </publisher> <editor> pp. </editor> <title> 209-213 This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: In nature there is no higher instance for controlling internal parameters in the way which has been proposed with the so-called nested or meta-evolution approach [16]. More natural seem to be simulations with several subpopulations, a concept that has been used for EA incarnations on parallel computers <ref> [28] </ref>.
References-found: 28

