URL: http://www.csc.ncsu.edu/faculty/mpsingh/papers/mas/commit.ps
Refering-URL: http://www.csc.ncsu.edu/faculty/mpsingh/papers/mas/
Root-URL: http://www.csc.ncsu.edu
Email: singh@ncsu.edu  
Title: A Conceptual Analysis of Commitments in Multiagent Systems Organizational Levels. An invited presentation in a
Author: Munindar P. Singh 
Note: This is a considerably revised version of a DFKI Technical Memo. Parts of it were presented at a panel discussion at the 1991 AAAI Fall Symposium on Knowledge and Action at the Social and  at the 1995 International Conference on Multiagent Systems (ICMAS) is also incorporated.  
Date: May 16, 1996  
Address: Raleigh, NC 27695-8206, USA  
Affiliation: Department of Computer Science North Carolina State University  
Abstract: The notion of commitment is central to understanding agents and multi-agent systems. At least two kinds of commitment can be identified in the AI literature|the internal or psychological and the external or social. While these notions must not be conflated with each other, they are not entirely unrelated. We review the historical development of commitments in AI and distributed computing, and show the various roles they might play in multiagent systems. We discuss the key interrelationships among these concepts, and study their implementational aspects, both in traditional individual agents, and in agents that are recursively created as systems of other agents. We close with a discus sion of the key research challenges. 
Abstract-found: 1
Intro-found: 1
Reference: [ Bratman, 1987 ] <author> Bratman, Michael E.; </author> <year> 1987. </year> <title> Intention, Plans, and Practical Reason. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: The agent is liable for not acting up on them. The other sense of commitment involves an agent by himself. The agent is committed to his intentions or beliefs, but is not liable (to anyone else) <ref> [ Bratman, 1987, ch. 2 ] </ref> [ Harman, 1986, p. 94 ] [ Cohen & Levesque, 1990, p. 217 ] [ Singh, 1991b ] . This is related to epistemic entrenchment [ Gardenfors, 1988 ] . <p> Perhaps their salient property is that they involve a commitment on the part of agents. Intentions are taken to be causes of actions, and can involve actions in the future. This requires some persistence or commitment. This has been supported by several researchers <ref> [ Bratman, 1987, ch. 2 ] </ref> , [ Harman, 1986, p. 94 ] , [ Pol-lack, 1992 ] , and [ Cohen & Levesque, 1990, p. 217 ] .
Reference: [ Castelfranchi, 1993 ] <author> Castelfranchi, </author> <title> Cristiano; 1993. Commitments: From individual intentions to groups and organizations. </title> <booktitle> In Proceedings of the AAAI-93 Workshop on AI and Theories of Groups and Organizations: Conceptual and Empirical Research. </booktitle>
Reference-contexts: Castelfranchi proposes that S-commitments are established in the presence of a witness, who as it were officiates at the event <ref> [ Castelfranchi, 1993 ] </ref> . In addition, in many cases when several agents are simultaneously entering into related S-commitments with each other, it is appropriate to include a cancelation clause, which limits the liability of the participants, and determines how the deal is to be broken if ever. <p> Gasser reviews some of the sociological issues underlying multiagent systems [ Gasser, 1991 ] . His notion of the multiple simultaneous roles played by social agents inspired part of our discussion above. Castelfranchi studies concepts similar to those here <ref> [ Castelfranchi, 1993 ] </ref> . However, he does not discuss the rationality and computational aspects of commitments. Also, he distinguishes a notion of collective commitment, which is subsumed by our concept of S-commitment through the orthogonal representation of the structure of multiagent systems.
Reference: [ Cohen & Levesque, 1990 ] <author> Cohen, Philip R. and Levesque, Hector J.; </author> <year> 1990. </year> <title> Intention is choice with commitment. </title> <booktitle> Artificial Intelligence 42 </booktitle> <pages> 213-261. 11 </pages>
Reference-contexts: The agent is liable for not acting up on them. The other sense of commitment involves an agent by himself. The agent is committed to his intentions or beliefs, but is not liable (to anyone else) [ Bratman, 1987, ch. 2 ] [ Harman, 1986, p. 94 ] <ref> [ Cohen & Levesque, 1990, p. 217 ] </ref> [ Singh, 1991b ] . This is related to epistemic entrenchment [ Gardenfors, 1988 ] . We call the first kind of commitment S-commitment (for social) and the second kind P-commitment (for psychological). Historically, commitments were of the psychological, intra-agent variety. <p> Intentions are taken to be causes of actions, and can involve actions in the future. This requires some persistence or commitment. This has been supported by several researchers [ Bratman, 1987, ch. 2 ] , [ Harman, 1986, p. 94 ] , [ Pol-lack, 1992 ] , and <ref> [ Cohen & Levesque, 1990, p. 217 ] </ref> . An agent who has an intention is in some way committed to it|not only does he intend to achieve the relevant condition right now, but would also intend to achieve it later, even as the circumstances changed, perhaps for the worse.
Reference: [ Elmagarmid, 1992 ] <editor> Elmagarmid, Ahmed K., editor. </editor> <title> Database Transaction Models for Advanced Applications. </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However, the above hardwired commitment is at a low level of abstraction. It provides no flexibility in terms of behavior. Typically, even the physical representation is fixed. Not only AI, but also traditional applications, e.g., collaborative computing and workflows, demand greater organizational flexibility <ref> [ Elmagarmid, 1992; Papazoglou et al., 1992 ] </ref> . A higher level of abstraction must involve agents. Agents are systems that can be understood through psychological and social abstractions with the intentional stance [ McCarthy, 1979 ] or equivalently at the knowledge level [ Newell, 1982 ] .
Reference: [ Gardenfors, 1988 ] <author> Gardenfors, </author> <title> Peter; 1988. Knowledge in Flux. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA. </address>
Reference-contexts: The agent is committed to his intentions or beliefs, but is not liable (to anyone else) [ Bratman, 1987, ch. 2 ] [ Harman, 1986, p. 94 ] [ Cohen & Levesque, 1990, p. 217 ] [ Singh, 1991b ] . This is related to epistemic entrenchment <ref> [ Gardenfors, 1988 ] </ref> . We call the first kind of commitment S-commitment (for social) and the second kind P-commitment (for psychological). Historically, commitments were of the psychological, intra-agent variety. They were procedurally|and unwittingly|encoded in planning algorithms, which led to suboptimal solutions. <p> Agents can also be committed toward their beliefs. This commitment corresponds to doxastic or epistemic entrenchment <ref> [ Gardenfors, 1988, ch. 3 ] </ref> , which means that the more committed an agent is, the more he will resist reconsideration, even as he receives new evidence.
Reference: [ Gasser, 1991 ] <author> Gasser, </author> <title> Les; 1991. Social conceptions of knowledge and action: DAI foundations and open systems semantics. </title> <booktitle> Artificial Intelligence 47 </booktitle> <pages> 107-138. </pages>
Reference-contexts: We referred to [ Castelfranchi, 1993; Levesque et al., 1990; Grosz & Sidner, 1990; Shoham, 1993 ] in the body of the paper. Gasser reviews some of the sociological issues underlying multiagent systems <ref> [ Gasser, 1991 ] </ref> . His notion of the multiple simultaneous roles played by social agents inspired part of our discussion above. Castelfranchi studies concepts similar to those here [ Castelfranchi, 1993 ] . However, he does not discuss the rationality and computational aspects of commitments.
Reference: [ Gray & Reuter, 1993 ] <author> Gray, Jim and Reuter, </author> <title> Andreas; 1993. Transaction Processing: Concepts and Techniques. </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Mutual commit protocols ensure that a number of distributed processes agree on some important action. An important application is whether a given distributed database transaction should commit at all sites, which is essential to preserving the integrity of distributed data <ref> [ Gray & Reuter, 1993 ] </ref> . The most famous of these protocols is two-phase commit (2PC). In 2PC, there is a voting phase in which each process votes Yes or No. The votes are collected by a coordinator process.
Reference: [ Grosz & Sidner, 1990 ] <author> Grosz, Barbara and Sidner, </author> <title> Candace; 1990. Plans for discourse. </title> <editor> In Cohen, P.; Morgan, J.; and Pollack, M., editors, </editor> <title> SDF Benchmark Series: Intentions in Communication. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: This enables capturing the common social situations, where one often speaks of abstract agents that other agents are committed to; these abstract agents include teams, nations, and other such entities. Traditional construals of group action require the agents to have mutual beliefs about the joint action <ref> [ Levesque et al., 1990; Grosz & Sidner, 1990 ] </ref> . Mutual beliefs arise when each of a set of agents believes something, and believes that each of the other does so, and so on ad infinitum.
Reference: [ Harman, 1986 ] <author> Harman, </author> <title> Gilbert; 1986. Change in View. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: The agent is liable for not acting up on them. The other sense of commitment involves an agent by himself. The agent is committed to his intentions or beliefs, but is not liable (to anyone else) [ Bratman, 1987, ch. 2 ] <ref> [ Harman, 1986, p. 94 ] </ref> [ Cohen & Levesque, 1990, p. 217 ] [ Singh, 1991b ] . This is related to epistemic entrenchment [ Gardenfors, 1988 ] . We call the first kind of commitment S-commitment (for social) and the second kind P-commitment (for psychological). <p> Intentions are taken to be causes of actions, and can involve actions in the future. This requires some persistence or commitment. This has been supported by several researchers [ Bratman, 1987, ch. 2 ] , <ref> [ Harman, 1986, p. 94 ] </ref> , [ Pol-lack, 1992 ] , and [ Cohen & Levesque, 1990, p. 217 ] .
Reference: [ Levesque et al., 1990 ] <author> Levesque, H. J.; Cohen, P. R.; and Nunes, J. T.; </author> <year> 1990. </year> <title> On acting together. </title> <booktitle> In AAAI. </booktitle>
Reference-contexts: This enables capturing the common social situations, where one often speaks of abstract agents that other agents are committed to; these abstract agents include teams, nations, and other such entities. Traditional construals of group action require the agents to have mutual beliefs about the joint action <ref> [ Levesque et al., 1990; Grosz & Sidner, 1990 ] </ref> . Mutual beliefs arise when each of a set of agents believes something, and believes that each of the other does so, and so on ad infinitum.
Reference: [ McCarthy, 1979 ] <author> McCarthy, </author> <title> John; 1979. Ascribing mental qualities to machines. </title> <editor> In Ringle, Martin, editor, </editor> <booktitle> Philosophical Perspectives in Artificial Intelligence. </booktitle> <publisher> Harvester Press. </publisher> <pages> Page nos. </pages> <note> from a revised version, issued as a report in 1987. </note>
Reference-contexts: Not only AI, but also traditional applications, e.g., collaborative computing and workflows, demand greater organizational flexibility [ Elmagarmid, 1992; Papazoglou et al., 1992 ] . A higher level of abstraction must involve agents. Agents are systems that can be understood through psychological and social abstractions with the intentional stance <ref> [ McCarthy, 1979 ] </ref> or equivalently at the knowledge level [ Newell, 1982 ] . This view, which justifies our present terminology of P-commitments and S-commitments, is crucial to the AI enterprise.
Reference: [ Newell, 1982 ] <author> Newell, </author> <title> Allen; 1982. The knowledge level. </title> <booktitle> Artificial Intelligence 18(1) </booktitle> <pages> 87-127. </pages>
Reference-contexts: A higher level of abstraction must involve agents. Agents are systems that can be understood through psychological and social abstractions with the intentional stance [ McCarthy, 1979 ] or equivalently at the knowledge level <ref> [ Newell, 1982 ] </ref> . This view, which justifies our present terminology of P-commitments and S-commitments, is crucial to the AI enterprise. We submit that P-commitments and S-commitments will provide two of the most important abstractions in characterizing, understanding, analyzing, and designing multiagent systems.
Reference: [ Papazoglou et al., 1992 ] <author> Papazoglou, Mike P.; Laufmann, Steven C.; and Sellis, Timothy K.; </author> <year> 1992. </year> <title> An organizational framework for cooperating intelligent information systems. </title> <journal> International Journal on Intelligent and Cooperative Information Systems 1(1) </journal> <pages> 169-202. </pages>
Reference-contexts: However, the above hardwired commitment is at a low level of abstraction. It provides no flexibility in terms of behavior. Typically, even the physical representation is fixed. Not only AI, but also traditional applications, e.g., collaborative computing and workflows, demand greater organizational flexibility <ref> [ Elmagarmid, 1992; Papazoglou et al., 1992 ] </ref> . A higher level of abstraction must involve agents. Agents are systems that can be understood through psychological and social abstractions with the intentional stance [ McCarthy, 1979 ] or equivalently at the knowledge level [ Newell, 1982 ] .
Reference: [ Perry, 1979 ] <author> Perry, </author> <title> John; 1979. The problem of the essential indexical. </title> <booktitle> Nous 13 </booktitle> <pages> 3-21. </pages>
Reference-contexts: This reduction defines the commitment or obligation of x to x the same way it defines the obligation of x to y. This misses the crucial intuition of the representation of self, called the essential indexical in <ref> [ Perry, 1979 ] </ref> . Perry shows how an agent's actions depend on whether he knows the "other" party is himself. Thus the reduction can succeed only if an additional primitive of self is added. 3 Commitments and Structure Commitments have an intimate relationship with the structure of multiagent systems.
Reference: [ Pollack, 1992 ] <author> Pollack, Martha E.; </author> <year> 1992. </year> <title> The uses of plans. </title> <booktitle> Artificial Intelligence. Computers and Thought Award Lecture. </booktitle>
Reference: [ Sacerdoti, 1977 ] <author> Sacerdoti, </author> <title> Earl; 1977. The Structure of Plans and Behavior. </title> <publisher> Elsevier Science Publishers. </publisher>
Reference-contexts: We call the first kind of commitment S-commitment (for social) and the second kind P-commitment (for psychological). Historically, commitments were of the psychological, intra-agent variety. They were procedurally|and unwittingly|encoded in planning algorithms, which led to suboptimal solutions. This generated a research interest in least-commitment planning <ref> [ Sacerdoti, 1977 ] </ref> , wherein commitments were actively avoided. But, as the reasoning limitations of agents were recognized, commitments became recognized as a means to control search and obtain satisficing, instead of optimal, solutions.
Reference: [ Shoham, 1993 ] <author> Shoham, </author> <title> Yoav; 1993. Agent-oriented programming. </title> <booktitle> Artificial Intelligence 60 </booktitle> <pages> 51-92. 12 </pages>
Reference-contexts: Some researchers, however, have proposed formal definitions that assume that S-commitments can be reduced to statements involving mutual beliefs among the participating agents. We review these suggestions in section 3. In the opposite direction, it has been proposed to P-commitments reduce to S-commitments to oneself <ref> [ Shoham, 1993 ] </ref> . This reduction defines the commitment or obligation of x to x the same way it defines the obligation of x to y. This misses the crucial intuition of the representation of self, called the essential indexical in [ Perry, 1979 ] .
Reference: [ Singh, 1991a ] <author> Singh, Munindar P.; </author> <year> 1991a. </year> <title> Group ability and structure. </title> <editor> In Demazeau, Y. and Muller, J.-P., editors, </editor> <booktitle> Decentralized Artificial Intelligence, </booktitle> <volume> Volume 2. </volume> <publisher> Else-vier Science Publishers B.V. / North-Holland, Amsterdam, Holland. </publisher> <pages> 127-145. </pages>
Reference-contexts: Although it is obvious that multiagent systems are structured, relatively few theories can actually accommodate it. We have identified two principles in <ref> [ Singh, 1991a ] </ref> that are relevant here. * Heterogeneity. Systems are composed of a diverse mix of agents and other systems; the members may have different knowledge, know-how, intentions, etc.
Reference: [ Singh, 1991b ] <author> Singh, Munindar P.; </author> <year> 1991b. </year> <title> Intentions, commitments and rationality. </title> <booktitle> In 13th Annual Conference of the Cognitive Science Society. </booktitle>
Reference-contexts: The other sense of commitment involves an agent by himself. The agent is committed to his intentions or beliefs, but is not liable (to anyone else) [ Bratman, 1987, ch. 2 ] [ Harman, 1986, p. 94 ] [ Cohen & Levesque, 1990, p. 217 ] <ref> [ Singh, 1991b ] </ref> . This is related to epistemic entrenchment [ Gardenfors, 1988 ] . We call the first kind of commitment S-commitment (for social) and the second kind P-commitment (for psychological). Historically, commitments were of the psychological, intra-agent variety.
Reference: [ Singh, 1994 ] <author> Singh, Munindar P.; </author> <year> 1994. </year> <title> Multiagent Systems: A Theoretical Framework for Intentions, Know-How, and Communications. </title> <publisher> Springer Verlag, </publisher> <address> Heidel-berg, Germany. </address>
Reference-contexts: Interaction protocols, e.g., for various kinds of negotiation, between different agents may be defined so that the interacting agents have the relevant S-commitments. This generalizes the idea of <ref> [ Singh, 1994 ] </ref> that participating agents have the requisite intentions and know-how. <p> Groups such as teams, armies, nations and corporations may all be (and are in fact) profitably treated as being single, though potentially complex, agents. We developed a rigorous theory of abstractions for multiagent systems in which the structure is indirectly captured through constraints on the communications among member agents <ref> [ Singh, 1994 ] </ref> . Those results can be refined through the use of S-commitments, related to the proposal on communications in section 2.2. Thus the structure of a system might be captured directly through the S-commitments among its members. In fact, behaviorally identical systems could have vastly differing structures.
Reference: [ Tuomela, 1991 ] <author> Tuomela, </author> <month> Raimo; </month> <year> 1991. </year> <title> We will do it. an analysis of group-intentions. Philosophy and Phenomenological Research LI(2):249-277. [ von Martial, 1992 ] von Martial, Frank; 1992. Coordinating Plans of Autonomous Agents. </title> <publisher> Springer Verlag, </publisher> <address> Berlin, Germany. </address>
Reference-contexts: Also, he distinguishes a notion of collective commitment, which is subsumed by our concept of S-commitment through the orthogonal representation of the structure of multiagent systems. Tuomela develops an interesting theory of joint action and intention that bears similarities to collective commitments <ref> [ Tuomela, 1991 ] </ref> . Several researchers are building systems that embody versions of S-commitment and exhibit the usefulness of this program of research [ von Martial, 1992; Wittig, 1992 ] .
Reference: [ Wittig, 1992 ] <editor> Wittig, Thies, editor. ARCHON: </editor> <title> An Architecture for Multi-agent Systems. </title> <publisher> Ellis Horwood Limited, </publisher> <address> West Sussex, UK. </address> <month> 13 </month>
Reference-contexts: Tuomela develops an interesting theory of joint action and intention that bears similarities to collective commitments [ Tuomela, 1991 ] . Several researchers are building systems that embody versions of S-commitment and exhibit the usefulness of this program of research <ref> [ von Martial, 1992; Wittig, 1992 ] </ref> . We have sought to present the unifying principles behind two major notions of commitment for single-agent and multiagent systems.
References-found: 22

