URL: ftp://ftp.cs.rice.edu/public/preston/thesis.ps.gz
Refering-URL: http://www.cs.rice.edu/MSCP/preston.html
Root-URL: 
Title: Register Allocation via Graph Coloring  
Author: by Preston Briggs Keith D. Cooper, Linda Torczon, Senior Research Associate Robert Michael Lewis, 
Degree: A Thesis Submitted in Partial Fulfillment of the Requirements for the Degree Doctor of Philosophy Approved, Thesis Committee:  Associate Professor, Chair Computer Science Ken Kennedy, Noah Harding Professor Computer Science  Computer Science John Bennett, Assistant Professor Electrical and Computer Engineering  
Date: April, 1992  
Address: Houston, Texas  
Affiliation: RICE UNIVERSITY  Research Associate Mathematical Sciences  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1974. </year>
Reference-contexts: To perform coalescing efficiently, we establish equivalence classes for each live range. As live ranges are coalesced, their equivalence classes are unioned, using a fast disjoint-set union algorithm <ref> [1, pages 129-139] </ref>. 3 The reasoning was that the vectors offered quicker traversal and better locality. 15 ? z x y xy z xy xy When two live ranges l x and l y are coalesced, we must update the interference graph so that l xy interferes with the neighbors of <p> We use an incremental style (due to Chaitin [18]) to specify the number of each parameter. For example, the add instruction defines one register and uses two registers the defined register is found in parm [0] and the used registers are found in parm <ref> [1] </ref> and parm [2]. This style of specification avoids the need for many additions when examining instructions. The details field is simply used as a small bit vector for compactly representing a variety of useful facts. <p> This requirement is distressing when the average number of members in a set is small, but the universe is relatively large. We have developed an alternative implementation that supports these operations efficiently. Using the matrix initialization idea suggested in a homework problem by Aho, Hopcroft, and Ullman <ref> [1, problem 2.12] </ref>, we are able to achieve constant-time operations for clear-set, add-member, delete-member, member?, choose-one, and cardinal-ity. Furthermore, the following operations may be performed in O (n) time, where n is the number of members: set-union, set-intersection, set-difference, set-copy, set-equality, and enumeration of the members. <p> Live ranges are composed of values connected by common uses. In the pruned SSA graph, values are connected only by -nodes. To determine live ranges, we union the operands of each -node together with the value defined by the node, using a fast disjoint-set union <ref> [1, Section 7.4] </ref>. Once all unions have been performed, the -nodes can be discarded. To determine the live range for a given value, we would perform a find operation. <p> Each instruction is handled by making any defined live ranges interfere with all the members of live. Then all defined live ranges are removed from live and all used live ranges are added to live. ik = i-&gt;kind; if (ik-&gt;details & COPY) deleteMember (live, find (i-&gt;parm <ref> [1] </ref>)); for (p=0; p&lt;ik-&gt;defs; p++) addEdges (graph, live, find (i-&gt;parm [p])); for (p=0; p&lt;ik-&gt;defs; p++) deleteMember (live, find (i-&gt;parm [p])); while (p &lt; ik-&gt;uses) addMember (live, find (i-&gt;parm [p++])); Note the use of find to compute the live range number from the values stored in each instruction. <p> Because some coalesces can preclude others, we visit high-priority blocks first, where priority is determined by loop-nesting depth. For each instruction i, we perform the following steps: if (i-&gt;kind->details & COPY) f dst = pathCompress (i-&gt;parm [0]); src = pathCompress (i-&gt;parm <ref> [1] </ref>); if (src == dst) hunlink i from the blocki else (!interfere (graph, src, dst)) f father = min (src, dst); son = max (src, dst); union (father, son); hupdate graph so that father contains all the edges from soni hunlink i from the blocki g Deleting redundant copy instructions from
Reference: [2] <author> Alfred V. Aho and Steven C. Johnson. </author> <title> Optimal code generation for expression trees. </title> <journal> Journal of the ACM, </journal> <volume> 23(3) </volume> <pages> 488-501, </pages> <month> March </month> <year> 1976. </year>
Reference-contexts: This technique is a form of instruction scheduling, with the goal of reducing register requirements. Work by Aho, Johnson, Sethi, and Ullman considers how to minimize register requirements by careful ordering of expression evaluation <ref> [60, 2] </ref>. * More aggressive allocators can manage registers over a complete basic block. Work by Freiburghouse suggests one practical approach [37]. <p> We use an incremental style (due to Chaitin [18]) to specify the number of each parameter. For example, the add instruction defines one register and uses two registers the defined register is found in parm [0] and the used registers are found in parm [1] and parm <ref> [2] </ref>. This style of specification avoids the need for many additions when examining instructions. The details field is simply used as a small bit vector for compactly representing a variety of useful facts.
Reference: [3] <author> Alfred V. Aho, Steven C. Johnson, and Jeffrey D. Ullman. </author> <title> Code generation for expressions with common subexpressions. </title> <journal> Journal of the ACM, </journal> <volume> 24(1) </volume> <pages> 146-160, </pages> <month> January </month> <year> 1977. </year>
Reference-contexts: Work by Freiburghouse suggests one practical approach [37]. Further work by Aho, Johnson, and Ullman proves the difficulty of generating optimal code in the presence of common subexpressions <ref> [3] </ref>. * Global allocators work over an entire routine. Chaitin's allocator operates at this level. Other examples include work by Chow and Hennessy and work by Callahan and Koblenz [26, 16]. * Interprocedural register allocation works over a collection of routines, usually an entire program.
Reference: [4] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: We are interested in global optimizations; that is, optimizations that use information gathered from an entire routine to guide transformations. Common global optimizations include strength reduction, loop-invariant code motion, and common subexpression elimination <ref> [4] </ref>. The optimizer is intended to be both language and machine independent. The back-end translates the intermediate form into a machine-specific form, usually object code. This translation, also called code generation, may require several passes, including instruction selection, instruction scheduling, and register allo cation. <p> in practice, including: * immediate loads of integer constants and floating-point constants, * computing a constant offset from the frame pointer or the static data pointer, * loads from a constant location in the stack frame or the static data area, and * loading non-local frame pointers from a display <ref> [4, Section 7.4] </ref>. <p> given subroutine. 95 typedef struct f Labels labels; Edges preds; Edges succs; Blocks next; Insts inst; : : : g Block, *Blocks; typedef struct f Blocks pred; Blocks succ; Edges nextPred; Edges nextSucc; : : : g Edge, *Edges; typedef struct f Insts prevInst; Insts nextInst; Kinds kind; short parm <ref> [4] </ref>; : : : g Inst, *Insts; 96 instructions are declared. Parameters are stored in a short vector at the end of the structure. If more than four are required, we simply allocate extra space and address beyond the end of the array. <p> Note however, that the computation of live virtual registers must be repeated after each invocation of spill code, since spilling alters the results. Our early implementations employed iterative data-flow analysis to solve the live-ness problem <ref> [4, Section 10.6] </ref>. We used a traditional bit-vector representation for sets of live registers, where the liveness of each virtual register was represented by a bit. This approach requires two bit vectors per basic block, with dn=32e words per bit vector, where n is the number of virtual registers.
Reference: [5] <author> Russ Atkinson, Alan Demers, Carl Hauser, Christian Jacobi, Peter Kessler, and Mark Weiser. </author> <title> Experiences creating a portable Cedar. </title> <journal> SIGPLAN Notices, </journal> <volume> 24(7) </volume> <pages> 322-329, </pages> <month> July </month> <year> 1989. </year> <booktitle> Proceedings of the ACM SIGPLAN '89 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: The idea was originally suggested to us by Hans Boehm as a way to avoid having to retarget the compiler for every new architecture we encountered (this approach was used by researchers at Xerox PARC to aid in porting Cedar <ref> [5] </ref>). We were further influenced by Mills et al., who describe a compiled instruction set simulator [55]. During the translation into C, we are able to add instrumentation to accumulate the dynamic occurrences of any class of ILOC instruction.
Reference: [6] <author> Marc A. Auslander and Martin E. Hopkins. </author> <title> An overview of the PL.8 compiler. </title> <journal> SIGPLAN Notices, </journal> <volume> 17(6) </volume> <pages> 22-31, </pages> <month> June </month> <year> 1982. </year> <booktitle> Proceedings of the ACM SIGPLAN '82 Symposium on Compiler Construction. </booktitle>
Reference-contexts: This important, perhaps essential, separation of concerns enables optimization to proceed in a relatively simple fashion, optimistically avoiding difficult choices caused by limited resources. This point of view was promoted by John Cocke and led to the development of the influential PL.8 compiler and 801 computers <ref> [50, 6] </ref>. When there are enough registers, this separation of concerns looks like a good idea. <p> be found, some live ranges are spilled; that is, kept in memory rather than registers. 2.2 The Yorktown Allocator The first implementation of a global register allocator based on graph coloring was done by Chaitin and his colleagues as part of the PL.8 compiler at IBM Research in Yorktown Heights <ref> [6] </ref>. Further work by Chaitin yielded an improved coloring heuristic that attacked the problems of coloring and spilling in an integrated fashion [18]. <p> During optimization, the high-level operations may be expanded to a sequence of lower-level operations or subroutine calls if required. The design of ILOC and the entire optimizer was heavily influenced by the PL.8 compiler <ref> [6] </ref>. Each register allocator is built around the same basic framework. An ILOC routine that assumes an infinite register set is rewritten in terms of the target machine's register set, with spill code added as necessary. <p> Intermediate Representation The Yorktown allocator works on code that has already been massaged into its final form; all optimization, address mode selection, and instruction scheduling has been completed (though instruction scheduling will be repeated after allocation) <ref> [6] </ref>. Chow's implementation of priority-based coloring runs much earlier in the compilation process, on a relatively high-level intermediate language [22]. This seems like a mere detail of implementation rather than a requirement of either allocation scheme. <p> It resembles the assembly language for a simple RISC machine, with the addition of hooks for interprocedural information and certain higher-level operations representing FORTRAN intrinsics. The design of ILOC and the entire optimizer was heavily influenced by the PL.8 compiler <ref> [6] </ref>. A multi-pass design, with many simple passes reading and writing ILOC, is not efficient in terms of compile time; however, it is ideal for our work. We are able to experiment with high-level issues involving the ordering of optimizations and with asymptotically efficient implementations of the individual optimizations.
Reference: [7] <author> John Backus. </author> <title> The history of Fortran I, II, and III. </title> <editor> In Wexelblat, editor, </editor> <booktitle> History of Programming Languages, </booktitle> <pages> pages 25-45. </pages> <publisher> Academic Press, </publisher> <year> 1981. </year>
Reference-contexts: It is in connection with optimization that register allocation becomes crucially important. During the development of the first FORTRAN compiler, John Backus suggested that the optimization of subscript expressions should be considered separately from the question of allocating index registers <ref> [7] </ref>. This idea has since been extended beyond the problems of optimizing subscript expressions; our approach to the design of optimizing compilers says: During optimization, assume an infinite set of registers; treat register allocation as a separate problem.
Reference: [8] <author> Richard A. Becker, John M. Chambers, and Allan R. Wilks. </author> <title> The New S Language: A Programming Environment for Data Analysis and Graphics. </title> <publisher> Wadsworth and Brooks/Cole, </publisher> <address> Pacific Grove, California, </address> <year> 1988. </year>
Reference-contexts: Results allocation; the horizontal axis reflects the object code size (the size of the .text segment, as reported by the size command). The curves are created from the points of the scatter plot, smoothed by the lowess function provided as part of the S data analysis package <ref> [8, pages 497-498] </ref>. Each test was repeated ten times on an unloaded machine and the resulting times were averaged; each point in the scatter plot represents the average allocation time for a single routine. The timer granularity was 10 milliseconds. Reported times include cache miss times, but exclude paging [24].
Reference: [9] <author> David Bernstein, Dina Q. Goldin, Martin C. Golumbic, Hugo Krawczyk, Yishay Mansour, Itai Nahshon, and Ron Y. Pinter. </author> <title> 138 Spill code minimization techniques for optimizing compilers. </title> <journal> SIGPLAN Notices, </journal> <volume> 24(7) </volume> <pages> 258-263, </pages> <month> July </month> <year> 1989. </year> <booktitle> Proceedings of the ACM SIGPLAN '89 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: Due in part to these pessimistic results, there has been little study in the area of optimal coloring for global register allocation. Instead, researchers have concentrated on finding efficient heuristic approaches <ref> [18, 46, 9] </ref>. Useful heuristics extend naturally to help solve the spill problem; that is, they provide guidance when live ranges must be spilled. In Chapter 3, we present a refinement to Chaitin's coloring heuristic. Our heuristic may be considered optimistic in contrast to Chaitin's pessimistic approach. <p> This metric reflects a desire to minimize total spill costs coupled with a desire to simplify the graph by lowering the degree of many nodes (the neighbors of node n). Later work by Bernstein et al. at Haifa explores other spill choice metrics <ref> [9] </ref>. <p> There has been a fair amount of work building on the foundation provided by Chaitin. We have reported an improvement to Chaitin's coloring heuristic [12]. Other improvements were introduced by Bernstein et al. <ref> [9] </ref>. Extensions to enable allocation of register pairs have been discovered by Nickerson and as part of our own work [57, 13]. Recently, we have described a technique for improving the accuracy of spill code estimation and placement [14]. <p> Therefore, any neighbor of n is relatively constrained and there is only a small chance that limited backtracking will be able to free a color. 3.4 Alternative Spill-Choice Metrics In Section 2.2.6, we introduced the "best of 3" heuristic originally suggested by Bernstein et al. <ref> [9] </ref>. In essence, they run simplify three times, each time using a different spill choice metric, and choose the ordering that gives the lowest spill cost. 11 We have never seen it lose, though such situations are conceivable.
Reference: [10] <author> Hans-J. Boehm and Mark Weiser. </author> <title> Garbage collection in an uncooperative environment. </title> <journal> Software Practice and Experience, </journal> <volume> 18(9) </volume> <pages> 807-820, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: Storage management is therefore an important concern. We have tried several schemes. Initially, we used a variety of ad hoc approaches, handling each problem as it appeared. When this proved difficult to maintain, we took advantage of a conservative garbage collector, suitable for use with arbitrary C programs <ref> [10] </ref>.
Reference: [11] <author> David G. Bradlee, Susan J. Eggers, and Robert R. Henry. </author> <title> Integrating register allocation and instruction scheduling for RISCs. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 122-131, </pages> <year> 1991. </year>
Reference-contexts: For example, Leverett attacks the problem of combining register allocation with instruction selection [53]. Others have explored 117 the possibility of combining instruction scheduling (in one of several possible flavors) with register allocation, recognizing that extensive motion due to scheduling can dramatically increase register pressure <ref> [11] </ref>. Callahan et al. perform aggressive loop transformations while accounting for register pressure to avoid over-optimization [15]. In each of these cases, we could argue that consideration of register pressure unnecessarily complicates the optimizer; the correct solution to the problem of over-optimization is more registers.
Reference: [12] <author> Preston Briggs, Keith D. Cooper, Ken Kennedy, and Linda Torczon. </author> <title> Coloring heuristics for register allocation. </title> <journal> SIGPLAN Notices, </journal> <volume> 24(7) </volume> <pages> 275-284, </pages> <month> July </month> <year> 1989. </year> <booktitle> Proceedings of the ACM SIGPLAN '89 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: Chaitin later described an improved coloring heuristic that handled the problems of coloring and spilling in a natural and coordinated fashion [18]. There has been a fair amount of work building on the foundation provided by Chaitin. We have reported an improvement to Chaitin's coloring heuristic <ref> [12] </ref>. Other improvements were introduced by Bernstein et al. [9]. Extensions to enable allocation of register pairs have been discovered by Nickerson and as part of our own work [57, 13]. Recently, we have described a technique for improving the accuracy of spill code estimation and placement [14]. <p> In 1990, Nickerson published a method for allocating structures into an aggregate set of adjacent registers. He observed that an allocator based on our 1989 paper (see Chapter 3) produced good allocations under his scheme <ref> [57, 12] </ref>. This chapter describes work performed independently of Nickerson and completed at approximately the same time. We consider various ways to represent register pairs in the interference graph.
Reference: [13] <author> Preston Briggs, Keith D. Cooper, and Linda Torczon. </author> <title> Coloring register pairs. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <note> 1992. To appear. </note>
Reference-contexts: We have reported an improvement to Chaitin's coloring heuristic [12]. Other improvements were introduced by Bernstein et al. [9]. Extensions to enable allocation of register pairs have been discovered by Nickerson and as part of our own work <ref> [57, 13] </ref>. Recently, we have described a technique for improving the accuracy of spill code estimation and placement [14]. An alternative form of global register allocation via graph coloring is described by Chow and Hennessy [22, 25, 26].
Reference: [14] <author> Preston Briggs, Keith D. Cooper, and Linda Torczon. </author> <title> Rematerialization. </title> <journal> SIGPLAN Notices, </journal> <volume> 27, </volume> <booktitle> 1992. To appear in Proceedings of the ACM SIGPLAN '92 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: Other improvements were introduced by Bernstein et al. [9]. Extensions to enable allocation of register pairs have been discovered by Nickerson and as part of our own work [57, 13]. Recently, we have described a technique for improving the accuracy of spill code estimation and placement <ref> [14] </ref>. An alternative form of global register allocation via graph coloring is described by Chow and Hennessy [22, 25, 26]. Their work, while based on coloring, differs in many respects from the work of Chaitin and his successors. <p> The difficulty is avoiding the introduction of additional register pressure in the attempt to save a spill (which was due to excess pressure in the first place). 18 Inspired by a draft of our paper <ref> [14] </ref>, Brian Koblenz has added rematerialization to their allocator. 53 Chapter 6 Aggressive Live Range Splitting Consider the example shown in Figure 6.1. The left side sketches a pair of loops, each updating a variable.
Reference: [15] <author> David Callahan, Steve Carr, and Ken Kennedy. </author> <title> Improving register allocation for subscripted variables. </title> <journal> SIGPLAN Notices, </journal> <volume> 25(6) </volume> <pages> 53-65, </pages> <month> June </month> <year> 1990. </year> <booktitle> Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: Others have explored 117 the possibility of combining instruction scheduling (in one of several possible flavors) with register allocation, recognizing that extensive motion due to scheduling can dramatically increase register pressure [11]. Callahan et al. perform aggressive loop transformations while accounting for register pressure to avoid over-optimization <ref> [15] </ref>. In each of these cases, we could argue that consideration of register pressure unnecessarily complicates the optimizer; the correct solution to the problem of over-optimization is more registers.
Reference: [16] <author> David Callahan and Brian Koblenz. </author> <title> Register allocation via hierarchical graph coloring. </title> <journal> SIGPLAN Notices, </journal> <volume> 26(6) </volume> <pages> 192-203, </pages> <month> June </month> <year> 1991. </year> <booktitle> Proceedings of the ACM SIGPLAN '91 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: Further work by Aho, Johnson, and Ullman proves the difficulty of generating optimal code in the presence of common subexpressions [3]. * Global allocators work over an entire routine. Chaitin's allocator operates at this level. Other examples include work by Chow and Hennessy and work by Callahan and Koblenz <ref> [26, 16] </ref>. * Interprocedural register allocation works over a collection of routines, usually an entire program. Examples include work by Wall and work by Santhanam and Odnert [63, 58]. <p> Extensions and improvements have been reported by Larus and Hilfinger, Chow, and by Gupta, Soffa, and Steele [51, 23, 41]. A recent paper by Callahan and Koblenz describes a hierarchical approach to global register allocation via coloring <ref> [16] </ref>. Their approach decomposes the control-flow graph into a tree of tiles, colors each tile individually, and merges the results in two passes over the tree. It represents an attempt to gain the precision of Chaitin's approach to allocation together with a structured approach to live range splitting. <p> The third column illustrates the code that would be produced by the Yorktown allocator. The entire live range of p has been spilled to memory, with loads inserted before the uses and stores inserted after the definitions. The final column shows code we would expect from a "splitting" allocator <ref> [26, 51, 41, 16] </ref>; the actual code might be worse. 15 Unfortunately, examples of this sort are not discussed in the literature on splitting allocators and it is unclear how best to extend these techniques to achieve the Ideal solution. 14 The notation [p] means "the contents of the memory location <p> Nevertheless, their work might be considered a direct ancestor of our approach. It is also interesting to compare our approach to other published alternatives; for example, the splitting allocator of Chow and Hennessy and the hierarchical coloring allocator of Callahan and Koblenz <ref> [26, 16] </ref>. The published work does not indicate how they handle rematerialization. It is possible that they make no special provisions, trusting their splitting algorithm to do an adequate job. 18 Some colleagues have suggested the possibility of more extensive rematerialization, perhaps recomputing entire expressions to avoid excess spilling. <p> Redundant stores are discovered and removed immediately after spill code has been inserted, in a separate phase called cleanup. Partially redundant stores are still a problem; see Note that this problem is apparently shared by other allocators that attempt splitting <ref> [26, 16] </ref>. <p> There are other approaches to live range splitting. Chow and Hennessy are able to accomplish splitting by sacrificing much of the precision and efficiency offered by Chaitin's approach (see Section 7.2). Callahan and Koblenz also describe an approach based on a hierarchical decomposition of the control-flow graph <ref> [16] </ref>. However, our experience suggests that other approaches to splitting may not be achieving the high-quality code they desire. <p> Therefore, it becomes interesting to consider other approaches to the problem global register allocation. Our work with live range splitting is one possibility. Other possibilities include priority-based coloring, by Chow and Hennessy [26], and the hierarchical graph coloring allocator of Callahan and Koblenz <ref> [16] </ref>. 9.3 Contributions The work described in this thesis may be divided into three parts: 1. improvements to the Yorktown allocator, working within the basic framework established by Chaitin et al., 2. exploration of aggressive live range splitting, extending Chaitin's framework to enable more precise spill code, and 3. practical work,
Reference: [17] <author> Alan Carle, Keith D. Cooper, Robert T. Hood, Ken Kennedy, Linda Torczon, and Scott K. Warren. </author> <title> A practical environment for Fortran programming. </title> <journal> IEEE Computer, </journal> 20(11) 75-89, November 1987. <volume> 139 </volume>
Reference-contexts: The examples inspired a variation to Chaitin's heuristic, reported in Section 3.2, which offers significant improvements. The final two sections describe two further variations enabled by our new heuristic. 3.1 Problems As a part of the IR n programming environment, we built an optimizing FORTRAN compiler <ref> [27, 17] </ref>. When the project was begun (many years ago), Chaitin's approach was new and elegant, so we decided to use it in our new compiler.
Reference: [18] <author> Gregory J. Chaitin. </author> <title> Register allocation and spilling via graph coloring. </title> <journal> SIGPLAN Notices, </journal> <volume> 17(6) </volume> <pages> 98-105, </pages> <month> June </month> <year> 1982. </year> <booktitle> Proceedings of the ACM SIGPLAN '82 Symposium on Compiler Construction. </booktitle>
Reference-contexts: Due in part to these pessimistic results, there has been little study in the area of optimal coloring for global register allocation. Instead, researchers have concentrated on finding efficient heuristic approaches <ref> [18, 46, 9] </ref>. Useful heuristics extend naturally to help solve the spill problem; that is, they provide guidance when live ranges must be spilled. In Chapter 3, we present a refinement to Chaitin's coloring heuristic. Our heuristic may be considered optimistic in contrast to Chaitin's pessimistic approach. <p> Further work by Chaitin yielded an improved coloring heuristic that attacked the problems of coloring and spilling in an integrated fashion <ref> [18] </ref>. <p> It requires O (n + e) time, where n is the number of live ranges to be colored and e is the number of edges in the interference graph. Chaitin also shows how his heuristic can be used to accomplish both coloring and spilling in an integrated fashion <ref> [18] </ref>. In our framework, Chaitin's coloring heuristic is distributed between simplify and select. Why does it work? Simplify repeatedly removes nodes from the graph and pushes them on a stack. In select, the nodes are popped from the stack and added back to the graph. <p> Chaitin later described an improved coloring heuristic that handled the problems of coloring and spilling in a natural and coordinated fashion <ref> [18] </ref>. There has been a fair amount of work building on the foundation provided by Chaitin. We have reported an improvement to Chaitin's coloring heuristic [12]. Other improvements were introduced by Bernstein et al. [9]. <p> Each kind of instruction has a string representation and defines zero or more registers, uses zero or more registers, and employs zero or more constants. We use an incremental style (due to Chaitin <ref> [18] </ref>) to specify the number of each parameter. For example, the add instruction defines one register and uses two registers the defined register is found in parm [0] and the used registers are found in parm [1] and parm [2].
Reference: [19] <author> Gregory J. Chaitin. </author> <type> Personal communication. E-mail message, </type> <month> January </month> <year> 1992. </year>
Reference-contexts: Schwartz presents two algorithms (one attributed to Cocke, the other to Ershov) illustrating some of the early attempts [59, pages 327-329]. The heuristic employed in the Yorktown allocator was devised by Chaitin <ref> [19] </ref>. It requires O (n + e) time, where n is the number of live ranges to be colored and e is the number of edges in the interference graph. Chaitin also shows how his heuristic can be used to accomplish both coloring and spilling in an integrated fashion [18]. <p> On the other hand, register allocation is a much closer fit to coloring. 2.3.2 Register Allocation The idea of managing global register allocation via graph coloring is apparently due to Cocke <ref> [49, 19] </ref>. We find some limited discussion of graph coloring in the early 1970's; however, it seems to concentrate more on the search for useful coloring heuristics than on the problems arising in register allocation [59]. <p> Chaitin points out that early work was fatally hampered by the relatively small memories available at the time <ref> [19] </ref>. 22 The first complete global register allocator based on graph coloring was built by Chaitin and his colleagues at IBM [20]. Chaitin later described an improved coloring heuristic that handled the problems of coloring and spilling in a natural and coordinated fashion [18].
Reference: [20] <author> Gregory J. Chaitin, Marc A. Auslander, Ashok K. Chandra, John Cocke, Martin E. Hopkins, and Peter W. Markstein. </author> <title> Register allocation via coloring. </title> <journal> Computer Languages, </journal> <volume> 6 </volume> <pages> 47-57, </pages> <month> January </month> <year> 1981. </year>
Reference-contexts: See Section 2.2.2 for more discussion. 4 a k-coloring cannot be discovered, then the code must be modified and a new coloring attempted. A global register allocator based on this approach was developed by Greg Chaitin and his colleagues at IBM <ref> [20] </ref>. 1.3.1 Minimizing Register Usage Informally, the goal of register allocation is to minimize the number of loads and stores that must be executed. Reducing the register allocation problem to the graph coloring problem subtly changes the goal; instead of minimizing memory traffic, the "reduced" goal is minimizing register usage. <p> While optimal solution of either of these problems is certainly NP-hard, Chapter 6 extends the ideas introduced in Chapter 5 to attack both of these problems. 7 Chapter 2 Background The first implementation of a graph coloring register allocator was described by Chaitin et al. <ref> [20] </ref>. This chapter explains their allocator in some detail. The first section introduces the general concept of register allocation via graph coloring. The second concentrates on the Yorktown allocator, including explanations of the individual phases. <p> Chaitin points out that early work was fatally hampered by the relatively small memories available at the time [19]. 22 The first complete global register allocator based on graph coloring was built by Chaitin and his colleagues at IBM <ref> [20] </ref>. Chaitin later described an improved coloring heuristic that handled the problems of coloring and spilling in a natural and coordinated fashion [18]. There has been a fair amount of work building on the foundation provided by Chaitin. We have reported an improvement to Chaitin's coloring heuristic [12]. <p> We give a high-level view of our approach in Section 5.2 and describe the necessary low-level modifications to the allocator in Section 5.3. Results are discussed in Section 5.4. 5.1 Introduction Chaitin et al. discuss several ideas for improving the quality of spill code <ref> [20] </ref>. They point out that certain values can be recomputed in a single instruction and that the required operands will always be available for the recomputation. They call these exceptional values never-killed and note that such values should be recalculated instead of being spilled and reloaded.
Reference: [21] <author> Jong-Deok Choi, Ron Cytron, and Jeanne Ferrante. </author> <title> Automatic construction of sparse data flow evaluation graphs. </title> <booktitle> In Conference Record of the Eighteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 55-66, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: To achieve this goal, the construction technique inserts special definitions called -nodes at those points where control-flow paths join and different values merge. We actually use the pruned SSA, with dead -nodes (-nodes with no uses) eliminated <ref> [21] </ref>. A natural way to view the SSA graph for a procedure is as a collection of values, each composed of a single definition and one or more uses. Each value's definition is either a single instruction or a -node that merges two or more values. <p> Long before our interest in rematerialization, we adopted an implementation strategy for renumber based on the pruned SSA graph. The old implementation has four conceptual steps: 1. Determine liveness at each basic block using a sparse data-flow evaluation graph <ref> [21] </ref>. 2. Insert -nodes based on dominance frontiers. Avoid inserting dead -nodes. 48 3. Renumber the operands in every instruction to refer to values instead of the original virtual registers. At the same time, accumulate availability information for each block. <p> While we can use the set representation discussed in Section 8.2 for handling basic blocks efficiently, we must somehow convert between representations. Choi, Cytron, and Ferrante describe a method for performing data-flow analysis using sparse data-flow graphs <ref> [21] </ref>. Their approach is closely related to the work on SSA, but allows solution of forward and backward data-flow problems. Our positive experiences with SSA and our frustration with the bit-vector approach prompted consideration of their sparse approach. <p> This same information is used to speed construction of the pruned SSA graph. * We build all the sparse graphs at once, using a single walk of the dominator tree (the procedure Search <ref> [21, Figure 3] </ref>). This speeds construction, but requires more space. 32 In limited tests, the sparse approach seems to be slightly faster than the bit-vector implementation. The exact tradeoff depends on the machine (the bit-vector approach benefits from long cache lines) and the code being analyzed. <p> Finally, after successfully coloring the interference graph, the routine is rewritten in terms of machine registers. Values and live ranges are determined by renumber. Our implementation is based upon construction and manipulation of the pruned SSA graph <ref> [21] </ref>. The SSA form is constructed as described by Cytron et al., except that no dead -nodes are inserted [29]. Furthermore, when renaming the virtual registers, we simply use distinct integers for each definition [29, Figure 12].
Reference: [22] <author> Fred C. </author> <note> Chow. </note>
Reference-contexts: Recently, we have described a technique for improving the accuracy of spill code estimation and placement [14]. An alternative form of global register allocation via graph coloring is described by Chow and Hennessy <ref> [22, 25, 26] </ref>. Their work, while based on coloring, differs in many respects from the work of Chaitin and his successors. They introduce the concept of live range splitting as an alternative to the spilling techniques originally used by Chaitin et al. <p> For our experimental comparisons (see Chapter 7), we have been careful to implement both versions so they remove nodes in the same order. 10 9 Early versions of priority-based coloring considered only degree when assigning colors, despite having a single-pass algorithm where the actual colorings are available <ref> [22, 25] </ref>. Later descriptions correct this mistake [26]. 10 At least, the order will be identical on the first trip through the build-color-spill loop. Later iterations will present different graphs for coloring. 29 Results Optimistic coloring helps generate better allocations. <p> Chow's implementation of priority-based coloring runs much earlier in the compilation process, on a relatively high-level intermediate language <ref> [22] </ref>. This seems like a mere detail of implementation rather than a requirement of either allocation scheme. Certainly Larus and Hilfinger demonstrate that it is possible to do priority-based coloring on low-level code [51]. <p> In priority-based coloring, these parameters are handled by a special-purpose mechanism called precoloring [26, Section 7.1]. * Coalescing removes unnecessary copies; Chow relies on a separate optimization called copy propagation <ref> [22, pages 39-41] </ref>. We note that coalescing is copy propagation. Furthermore, coalescing is a particularly effective form of copy propagation because it is performed at a very late stage of compilation. <p> There are two reasons. First, it was impossible to separate the cost of local copy propagation from other local optimizations. Second, Chow's copy propagator actually propagates expressions, achieving a larger effect than that achieved by simply coalescing <ref> [22, pages 39-41] </ref>. Discussion While there are a variety of points to be made about the data shown in Figure 7.2, the speed comparisons are the prime concern.
References-found: 22

