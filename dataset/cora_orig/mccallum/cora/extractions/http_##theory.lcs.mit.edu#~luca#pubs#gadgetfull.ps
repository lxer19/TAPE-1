URL: http://theory.lcs.mit.edu/~luca/pubs/gadgetfull.ps
Refering-URL: http://theory.lcs.mit.edu/~luca/papers.html
Root-URL: 
Title: Gadgets, Approximation, and Linear Programming  
Author: Luca Trevisan Gregory B. Sorkin Madhu Sudan David P. Williamson 
Date: May 21, 1997  
Abstract: We present a linear-programming based method for finding "gadgets", i.e., combinatorial structures reducing constraints of one optimization problem to constraints of another. A key step in this method is a simple observation which limits the search space to a finite one. Using this new method we present a number of new, computer-constructed gadgets for several different reductions. This method also answers a question posed by Bellare, Goldreich and Sudan [1] on how to prove the optimality of gadgets: we show how LP duality gives such proofs. The new gadgets improve hardness results for MAX CUT and MAX DICUT, showing that approximating these problems to within factors of 16=17 + * and 12=13 + * respectively is NP-hard (improving upon the hardness of 18=19+* for both problems that would follow from [1, 8]). We also use the gadgets to obtain an improved approximation algorithm for MAX 3SAT which guarantees an approximation ratio of :801. This improves upon the previous best bound (implicit in [7, 4]) of :7704.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Bellare, O. Goldreich, and M. Sudan. </author> <title> Free bits, PCPs and non-approximability towards tight results (version 4). Technical Report TR95-024, </title> <booktitle> Electronic Colloquium on Computational Complexity, </booktitle> <year> 1996. </year> <note> See http://www.eccc.uni-trier.de/eccc/. </note>
Reference-contexts: Despite their importance, the construction of gadgets has always been a "black art", with no known uniform methods. In fact, until recently no one had even proposed a concrete definition of a gadget; Bellare, Goldreich and Sudan <ref> [1] </ref> finally did so, with a view to quantifying the role of gadgets in non-approximability results. Their definition is accompanied by a seemingly natural "cost" measure for a gadget. The more "costly" the gadget, the weaker the reduction. <p> (and with a bit of luck) we can often get the bounds to match, thereby producing optimal gadgets with even greater efficiency! Armed with this tool for finding gadgets (and an RS/6000, OSL, and often APL2 1 ), we examine some of the known gadgets and construct many new ones. <ref> [1] </ref> presented gadgets reducing the computation of a verifier to several problems, including MAX 3SAT, MAX 2SAT, and MAX CUT. We examine these in turn and show that the gadgets in [1] for MAX 3SAT and MAX 2SAT were optimal, but the MAX CUT gadget was not. <p> RS/6000, OSL, and often APL2 1 ), we examine some of the known gadgets and construct many new ones. <ref> [1] </ref> presented gadgets reducing the computation of a verifier to several problems, including MAX 3SAT, MAX 2SAT, and MAX CUT. We examine these in turn and show that the gadgets in [1] for MAX 3SAT and MAX 2SAT were optimal, but the MAX CUT gadget was not. We improve on the efficiency of the last, thereby improving on the factor to which approximating MAX CUT can be shown to be NP-hard. <p> We also construct a new gadget for the MAX DICUT problem, thereby strengthening its hardness. Our final result, obtained by plugging our gadget into the proof of <ref> [1] </ref>, shows that approximating MAX CUT to within a factor of 60=61 is NP-hard, as is approximating MAX DICUT to within a factor of 44=45. (For both problems, the hardness factor proved in [1] was 71=72.) 2 The PCP 1 respectively, an IBM RiscSystem/6000 workstation, the IBM Optimization Subroutine Library, which <p> Our final result, obtained by plugging our gadget into the proof of <ref> [1] </ref>, shows that approximating MAX CUT to within a factor of 60=61 is NP-hard, as is approximating MAX DICUT to within a factor of 44=45. (For both problems, the hardness factor proved in [1] was 71=72.) 2 The PCP 1 respectively, an IBM RiscSystem/6000 workstation, the IBM Optimization Subroutine Library, which includes a linear programming package, and (not that we're partisan) IBM's APL2 programming language 2 Note that approximation ratios in this paper for maximization problems are less than 1, and represent the weight <p> The PCP 1 respectively, an IBM RiscSystem/6000 workstation, the IBM Optimization Subroutine Library, which includes a linear programming package, and (not that we're partisan) IBM's APL2 programming language 2 Note that approximation ratios in this paper for maximization problems are less than 1, and represent the weight 2 machinery of <ref> [1] </ref> has since been improved by H-astad [8]. Our gadgets and H-astad's result show that approximating MAX CUT to within a factor of 16=17 + * is NP-hard, as is approximating MAX DICUT to within a factor of 12=13 + *. Using H-astad's result in combination with the gadgets of [1] <p> <ref> [1] </ref> has since been improved by H-astad [8]. Our gadgets and H-astad's result show that approximating MAX CUT to within a factor of 16=17 + * is NP-hard, as is approximating MAX DICUT to within a factor of 12=13 + *. Using H-astad's result in combination with the gadgets of [1] would have given a hardness factor of 18=19 + * for both problems. Obtaining better reductions between problems can also yield improved approximation algorithms for some problems (if the reduction goes the right way!). We illustrate the point by constructing a gadget reducing MAX 3SAT to MAX 2SAT. <p> We show: first, for any * &gt; 0, there exist constants c and s, c=s &gt; 10=9 *, such that NP PCP c;s [log; 2]; and second, for all c; s with c=s &gt; 2:7214, PCP c;s [log; 3] P. The best bound for the former result obtainable from <ref> [1, 8] </ref> is 22=21 *; the best previous bound for the latter was 4 [11]. All the gadgets we use are computer-constructed. <p> Section 7 presents proofs of optimality of the gadgets for some problems and lower bounds on the cost of others. It includes a mix of computer-generated and hand-generated lower bounds. 2 Definitions We begin with some definitions we will need before giving the definition of a gadget from <ref> [1] </ref>. Definition 2.1 A (k-ary) constraint function is a boolean function f : f0; 1g k ! f0; 1g. <p> This is the reciprocal of the factors mentioned in <ref> [1] </ref> and exactly the factors as stated in [12, 6, 7, 4]. 3 Definition 2.2 A constraint family F is a finite collection of constraint functions. The arity of F is the maximum number of arguments of the functions in F. <p> We can now formally define a gadget. Definition 2.4 [Gadget <ref> [1] </ref>] For ff 2 R + , a constraint function f : f0; 1g k ! f0; 1g, and a constraint family F: an ff-gadget (or "gadget with performance ff") reducing f to F is a finite collection of real weights w j 0, and associated constraints C j from F <p> The above list of constraint families includes both sources and targets of reductions. Our interest in gadget construction, and in the PC and RMBC families originally arose from the following result by Bellare, Goldreich and Sudan. Theorem 2.7 <ref> [1] </ref> For any family F, if there exists an ff 1 -gadget reducing every function in PC to F and an ff 2 -gadget reducing every function in RMBC to F, then for any * &gt; 0, MAX F is hard to approximate to within 1 :15 :6ff 1 +:4ff 2 <p> The sole exception (y) is the best possible strict gadget; there is a non-strict 3-gadget. All previous results quoted are interpretations of the results in <ref> [1] </ref>, except the gadget reducing 3SAT to 2SAT, which is due to [5], and the gadget reducing PC to 3SAT, which is folklore. occurrence of X j 0 by an occurrence of X j . <p> A gadget over 7 variables can thus be identified with the vector (w 1 ; : : : ; w 98 ) of the weights of the constraints. Since in <ref> [1] </ref> it is shown that an 11-gadget exists reducing PC 0 to 2SAT, it follows that in an optimum gadget no constraint will have a weight larger than 11. <p> An optimal LP solution yields an optimal ff-gadget (one where ff is as small as possible). In particular, (LP1) has optimal solution ff = 11, proving the optimality of the <ref> [1] </ref> gadget. In the remaining sections we give applications of some gadgets and then report the best possible constructions. <p> Following <ref> [1] </ref>, we use instead the fact that MAX CUT and MAX CUT/0 are equivalent with respect to approximation and thus look for reductions to CUT/0. Notice that the CUT=0 constraint family is hereditary, since identifying the two variables in a CUT constraint yields the constant function 0. <p> Theorem 4.8 For any * &gt; 0, constants c and s exist such that NP PCP c;s [log; 2] and c=s &gt; 10=9*. The previously known gap between the completeness and soundness achievable reading two bits was 74=73 <ref> [1] </ref>. It would be 22=21 * using H-astad's result [8] in combination with the argument of [1]. (Actually the reduction from constraint satisfaction problems to probabilistically checkable proofs is reversible. <p> The previously known gap between the completeness and soundness achievable reading two bits was 74=73 <ref> [1] </ref>. It would be 22=21 * using H-astad's result [8] in combination with the argument of [1]. (Actually the reduction from constraint satisfaction problems to probabilistically checkable proofs is reversible. <p> The previous best trade-off between completeness and soundness for polynomial-time PCP classes was c=s &gt; 4 [11]. 7 Lower Bounds for Gadget Constructions In this section we shall show that some of the gadget constructions mentioned in this paper and in <ref> [1] </ref> are optimal, and we shall prove lower bounds for some other gadget constructions. The following result is useful to prove lower bounds for the RMBC family.
Reference: [2] <author> P. Crescenzi, R. Silvestri, and L. Trevisan. </author> <title> To weight or not to weight: Where is the question? In Proc. </title> <booktitle> of the 4th Israel Symposium on Theory of Computing and Systems, </booktitle> <pages> pages 68-77, </pages> <year> 1996. </year>
Reference-contexts: is the idea of working with weighted versions of optimization problems rather than unweighted ones. (Weighted versions result in LPs, while unweighted versions would result in integer programs, IPs.) This seemingly helps only in showing hardness of weighted optimization problems, but a new result due to Crescenzi, Silvestri and Trevisan <ref> [2] </ref> shows that for a large class of optimization problems (including all the ones considered in this paper), the weighted versions are exactly as hard with respect to approximation as the unweighted ones. Therefore, working with a weighted version is as good as working with an unweighted one. <p> We show: first, for any * &gt; 0, there exist constants c and s, c=s &gt; 10=9 *, such that NP PCP c;s <ref> [log; 2] </ref>; and second, for all c; s with c=s &gt; 2:7214, PCP c;s [log; 3] P. The best bound for the former result obtainable from [1, 8] is 22=21 *; the best previous bound for the latter was 4 [11]. All the gadgets we use are computer-constructed. <p> The above theorem has implications for probabilistically checkable proofs. Using the well known reduction from constraint satisfaction problems to probabilistically checkable proofs, Theorem 4.7 implies the following theorem. Theorem 4.8 For any * &gt; 0, constants c and s exist such that NP PCP c;s <ref> [log; 2] </ref> and c=s &gt; 10=9*. The previously known gap between the completeness and soundness achievable reading two bits was 74=73 [1].
Reference: [3] <author> P. Crescenzi and L. Trevisan. </author> <title> MAX NP-completeness made easy. </title> <type> Manuscript, </type> <year> 1996. </year> <month> 20 </month>
Reference-contexts: We show: first, for any * &gt; 0, there exist constants c and s, c=s &gt; 10=9 *, such that NP PCP c;s [log; 2]; and second, for all c; s with c=s &gt; 2:7214, PCP c;s <ref> [log; 3] </ref> P. The best bound for the former result obtainable from [1, 8] is 22=21 *; the best previous bound for the latter was 4 [11]. All the gadgets we use are computer-constructed. <p> The variables X 1 ; X 2 ; X 3 are primary variables and Y is an auxiliary variable. 2 Theorem 6.9 MAX 3ConjSAT has a polynomial-time .367-approximation algorithm. It is shown by Trevisan [11] that the above theorem has consequences for PCP c;s <ref> [log; 3] </ref>. This is because the computation of the verifier in such a proof system can be described by a decision tree of depth 3, for every choice of random string. <p> Further, there is a 1-gadget reducing every function which can be computed by a decision tree of depth k to kConjSAT. Thus we get the following corollary for PCP systems using 3 bits of queries. Corollary 6.10 PCP c;s <ref> [log; 3] </ref> P provided that c=s &gt; 2:7214. <p> More generally, there cannot be an approximation-preserving gadget reduction from MAX SAT to, say, MAX (log n)SAT. In partial contrast with this lower bound, Khanna et al. [9] have given an approximation preserving reduction from MAX SAT to MAX 3SAT and Crescenzi and Trevisan <ref> [3] </ref> have provided a tight reduction between MAX SAT and MAX (log n)SAT, showing that the two problems have the same approximation threshold. (The ap proximation threshold of a problem A is defined as supfr : an rapproximate algorithm for A existsg.) Acknowledgements We thank Pierluigi Crescenzi and Oded Goldreich for
Reference: [4] <author> U. Feige and M. X. Goemans. </author> <title> Approximating the value of two prover proof systems, with applications to MAX 2SAT and MAX DICUT. </title> <booktitle> In Proc. of the 3rd Israel Symposium on Theory of Computing and Systems, </booktitle> <pages> pages 182-189, </pages> <year> 1995. </year>
Reference-contexts: We illustrate the point by constructing a gadget reducing MAX 3SAT to MAX 2SAT. Using this new reduction in combination with a technique of Goemans and Williamson [6, 7] and the state-of-the-art :931-approximation algorithm for MAX 2SAT due to Feige and Goemans <ref> [4] </ref> (which improves upon the previous :878-approximation algorithm of [7]), we obtain a :801-approximation algorithm for MAX 3SAT. The best result that could be obtained previously, by combining the technique of [6, 7] and the bound of [4], was :7704. (This is not mentioned explicitly anywhere but why would we lie. <p> and the state-of-the-art :931-approximation algorithm for MAX 2SAT due to Feige and Goemans <ref> [4] </ref> (which improves upon the previous :878-approximation algorithm of [7]), we obtain a :801-approximation algorithm for MAX 3SAT. The best result that could be obtained previously, by combining the technique of [6, 7] and the bound of [4], was :7704. (This is not mentioned explicitly anywhere but why would we lie. See also the :769-approximation algorithm in the paper of Ono, Hirata, and Asano [10].) Finally, our reductions have implications for probabilistically checkable proof systems. <p> This is the reciprocal of the factors mentioned in [1] and exactly the factors as stated in <ref> [12, 6, 7, 4] </ref>. 3 Definition 2.2 A constraint family F is a finite collection of constraint functions. The arity of F is the maximum number of arguments of the functions in F. <p> We also use 2SAT as a target to obtain new approximation algorithms for the source (by a reduction to MAX 2SAT and using the algorithm of <ref> [4] </ref> to approximate this problem). The two families reduced to 2SAT in this way are 3SAT and 3ConjSAT. 3 The Basic Procedure In this section we shall illustrate our technique by constructing a gadget reducing PC 0 to 2SAT. <p> Theorem 4.7 For every * &gt; 0, MAX 2CSP is hard to approximate to within 9=10 + *. MAX 2CSP can be approximated within :859 <ref> [4] </ref>. The above theorem has implications for probabilistically checkable proofs. Using the well known reduction from constraint satisfaction problems to probabilistically checkable proofs, Theorem 4.7 implies the following theorem. <p> Lemma 6.2 <ref> [4] </ref> There exists a polynomial-time (:976; :931)-approximation algorithm for MAX 2SAT. 6.1 MAX 3SAT In this section we show how to derive an improved approximation algorithm for MAX 3SAT. <p> By restricting techniques in [7] from MAX SAT to MAX 3SAT and using a :931-approximation algorithm for MAX 2SAT due to Feige and Goemans <ref> [4] </ref>, one can obtain a :7704-approximation algorithm for MAX 3SAT. The basic idea of [7] is to reduce each clause of length 3 to the three possible subclauses of length 2, give each new length-2 clause one-third the original weight, and then apply an approximation algorithm for MAX 2SAT.
Reference: [5] <author> M. Garey, D. Johnson, and L. Stockmeyer. </author> <title> Some simplified NP-complete graph problems. </title> <journal> Theoretical Computer Science, </journal> <volume> 1 </volume> <pages> 237-267, </pages> <year> 1976. </year>
Reference-contexts: 1 Introduction A "gadget" is a finite combinatorial structure which translates constraints of one optimization problem into a set of constraints of a second optimization problem. A typical example is in the reduction from 3SAT to MAX 2SAT <ref> [5] </ref> in which a clause C k = X 1 _ X 2 _ X 3 is replaced by ten clauses X 1 ; X 2 ; X 3 ; :X 1 _ :X 2 ; :X 2 _ :X 3 ; :X 3 _ :X 1 ; If clause C <p> The sole exception (y) is the best possible strict gadget; there is a non-strict 3-gadget. All previous results quoted are interpretations of the results in [1], except the gadget reducing 3SAT to 2SAT, which is due to <ref> [5] </ref>, and the gadget reducing PC to 3SAT, which is folklore. occurrence of X j 0 by an occurrence of X j . If C did not originally involve X j , then r ed (C) is a valid constraint from F.
Reference: [6] <author> M. X. Goemans and D. P. Williamson. </author> <title> New 3/4-approximation algorithms for the maximum satisfiability problem. </title> <journal> SIAM Journal on Discrete Mathematics, </journal> <volume> 7 </volume> <pages> 656-666, </pages> <year> 1994. </year>
Reference-contexts: Obtaining better reductions between problems can also yield improved approximation algorithms for some problems (if the reduction goes the right way!). We illustrate the point by constructing a gadget reducing MAX 3SAT to MAX 2SAT. Using this new reduction in combination with a technique of Goemans and Williamson <ref> [6, 7] </ref> and the state-of-the-art :931-approximation algorithm for MAX 2SAT due to Feige and Goemans [4] (which improves upon the previous :878-approximation algorithm of [7]), we obtain a :801-approximation algorithm for MAX 3SAT. The best result that could be obtained previously, by combining the technique of [6, 7] and the bound <p> of Goemans and Williamson <ref> [6, 7] </ref> and the state-of-the-art :931-approximation algorithm for MAX 2SAT due to Feige and Goemans [4] (which improves upon the previous :878-approximation algorithm of [7]), we obtain a :801-approximation algorithm for MAX 3SAT. The best result that could be obtained previously, by combining the technique of [6, 7] and the bound of [4], was :7704. (This is not mentioned explicitly anywhere but why would we lie. See also the :769-approximation algorithm in the paper of Ono, Hirata, and Asano [10].) Finally, our reductions have implications for probabilistically checkable proof systems. <p> This is the reciprocal of the factors mentioned in [1] and exactly the factors as stated in <ref> [12, 6, 7, 4] </ref>. 3 Definition 2.2 A constraint family F is a finite collection of constraint functions. The arity of F is the maximum number of arguments of the functions in F.
Reference: [7] <author> M. X. Goemans and D. P. Williamson. </author> <title> Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming. </title> <journal> Journal of the ACM, </journal> <volume> 42 </volume> <pages> 1115-1145, </pages> <year> 1995. </year>
Reference-contexts: Obtaining better reductions between problems can also yield improved approximation algorithms for some problems (if the reduction goes the right way!). We illustrate the point by constructing a gadget reducing MAX 3SAT to MAX 2SAT. Using this new reduction in combination with a technique of Goemans and Williamson <ref> [6, 7] </ref> and the state-of-the-art :931-approximation algorithm for MAX 2SAT due to Feige and Goemans [4] (which improves upon the previous :878-approximation algorithm of [7]), we obtain a :801-approximation algorithm for MAX 3SAT. The best result that could be obtained previously, by combining the technique of [6, 7] and the bound <p> Using this new reduction in combination with a technique of Goemans and Williamson [6, 7] and the state-of-the-art :931-approximation algorithm for MAX 2SAT due to Feige and Goemans [4] (which improves upon the previous :878-approximation algorithm of <ref> [7] </ref>), we obtain a :801-approximation algorithm for MAX 3SAT. The best result that could be obtained previously, by combining the technique of [6, 7] and the bound of [4], was :7704. (This is not mentioned explicitly anywhere but why would we lie. <p> of Goemans and Williamson <ref> [6, 7] </ref> and the state-of-the-art :931-approximation algorithm for MAX 2SAT due to Feige and Goemans [4] (which improves upon the previous :878-approximation algorithm of [7]), we obtain a :801-approximation algorithm for MAX 3SAT. The best result that could be obtained previously, by combining the technique of [6, 7] and the bound of [4], was :7704. (This is not mentioned explicitly anywhere but why would we lie. See also the :769-approximation algorithm in the paper of Ono, Hirata, and Asano [10].) Finally, our reductions have implications for probabilistically checkable proof systems. <p> This is the reciprocal of the factors mentioned in [1] and exactly the factors as stated in <ref> [12, 6, 7, 4] </ref>. 3 Definition 2.2 A constraint family F is a finite collection of constraint functions. The arity of F is the maximum number of arguments of the functions in F. <p> Lemma 6.2 [4] There exists a polynomial-time (:976; :931)-approximation algorithm for MAX 2SAT. 6.1 MAX 3SAT In this section we show how to derive an improved approximation algorithm for MAX 3SAT. By restricting techniques in <ref> [7] </ref> from MAX SAT to MAX 3SAT and using a :931-approximation algorithm for MAX 2SAT due to Feige and Goemans [4], one can obtain a :7704-approximation algorithm for MAX 3SAT. The basic idea of [7] is to reduce each clause of length 3 to the three possible subclauses of length 2, <p> By restricting techniques in <ref> [7] </ref> from MAX SAT to MAX 3SAT and using a :931-approximation algorithm for MAX 2SAT due to Feige and Goemans [4], one can obtain a :7704-approximation algorithm for MAX 3SAT. The basic idea of [7] is to reduce each clause of length 3 to the three possible subclauses of length 2, give each new length-2 clause one-third the original weight, and then apply an approximation algorithm for MAX 2SAT.
Reference: [8] <author> J. H-astad. </author> <title> Some optimal inapproximability results. </title> <booktitle> In Proc. of the 29th ACM Symposium on Theory of Computing, </booktitle> <pages> pages 1-10, </pages> <year> 1997. </year>
Reference-contexts: workstation, the IBM Optimization Subroutine Library, which includes a linear programming package, and (not that we're partisan) IBM's APL2 programming language 2 Note that approximation ratios in this paper for maximization problems are less than 1, and represent the weight 2 machinery of [1] has since been improved by H-astad <ref> [8] </ref>. Our gadgets and H-astad's result show that approximating MAX CUT to within a factor of 16=17 + * is NP-hard, as is approximating MAX DICUT to within a factor of 12=13 + *. <p> We show: first, for any * &gt; 0, there exist constants c and s, c=s &gt; 10=9 *, such that NP PCP c;s [log; 2]; and second, for all c; s with c=s &gt; 2:7214, PCP c;s [log; 3] P. The best bound for the former result obtainable from <ref> [1, 8] </ref> is 22=21 *; the best previous bound for the latter was 4 [11]. All the gadgets we use are computer-constructed. <p> In this paper we will use the following, stronger, result by H-astad. Theorem 2.8 <ref> [8] </ref> For any family F, if there exists an ff 0 -gadget reducing PC 0 to F and an ff 1 -gadget reducing PC 1 to F, then for any * &gt; 0, MAX F is hard to approximate to within 1 1 ff 0 +ff 1 Thus, using CUT, DICUT, <p> It is also easy to see that MAX CUT/0 and MAX CUT/1 are equivalent to MAX CUT hence we will also be interested in using CUT=0 as target of reductions. Due to H-astad's result <ref> [8] </ref>, gadget constructions reducing RMBC members to natural problems have no more applications, and will not be described in detail, but we shall mention them for the sake of completeness. <p> Theorem 4.8 For any * &gt; 0, constants c and s exist such that NP PCP c;s [log; 2] and c=s &gt; 10=9*. The previously known gap between the completeness and soundness achievable reading two bits was 74=73 [1]. It would be 22=21 * using H-astad's result <ref> [8] </ref> in combination with the argument of [1]. (Actually the reduction from constraint satisfaction problems to probabilistically checkable proofs is reversible. <p> The hardest computations were those for gadgets reducing from RMBC, which on an RS/6000 workstation took up to half an hour and memory of 500MB or so. However, the strength of <ref> [8] </ref> makes PC virtually the sole source function of contemporary interest, and all the reductions from PC can be run in seconds on a ThinkPad, with very modest memory requirements. 13 6 Improved Positive Results In this section we show that we can use gadgets to improve approximation algorithms.
Reference: [9] <author> S. Khanna, R. Motwani, M. Sudan, and U. Vazirani. </author> <title> On syntactic versus computational views of approximability. </title> <booktitle> In Proc. of the 35th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 819-830, </pages> <year> 1994. </year>
Reference-contexts: More generally, there cannot be an approximation-preserving gadget reduction from MAX SAT to, say, MAX (log n)SAT. In partial contrast with this lower bound, Khanna et al. <ref> [9] </ref> have given an approximation preserving reduction from MAX SAT to MAX 3SAT and Crescenzi and Trevisan [3] have provided a tight reduction between MAX SAT and MAX (log n)SAT, showing that the two problems have the same approximation threshold. (The ap proximation threshold of a problem A is defined as
Reference: [10] <author> T. Ono, T. Hirata, and T. Asano. </author> <title> Approximation algorithms for the maximum satisfiability problem. </title> <booktitle> In Proc. of the 5th Scandinavian Workshop on Algorithm Theory, </booktitle> <pages> pages 100-111. </pages> <publisher> LNCS 1097, Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: The best result that could be obtained previously, by combining the technique of [6, 7] and the bound of [4], was :7704. (This is not mentioned explicitly anywhere but why would we lie. See also the :769-approximation algorithm in the paper of Ono, Hirata, and Asano <ref> [10] </ref>.) Finally, our reductions have implications for probabilistically checkable proof systems.
Reference: [11] <author> L. Trevisan. </author> <title> Positive linear programming, parallel approximation, </title> <booktitle> and PCP's. In Proc. of the 4th European Symposium on Algorithms, </booktitle> <pages> pages 62-75. </pages> <publisher> LNCS 1136, Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: The best bound for the former result obtainable from [1, 8] is 22=21 *; the best previous bound for the latter was 4 <ref> [11] </ref>. All the gadgets we use are computer-constructed. <p> The variables X 1 ; X 2 ; X 3 are primary variables and Y is an auxiliary variable. 2 Theorem 6.9 MAX 3ConjSAT has a polynomial-time .367-approximation algorithm. It is shown by Trevisan <ref> [11] </ref> that the above theorem has consequences for PCP c;s [log; 3]. This is because the computation of the verifier in such a proof system can be described by a decision tree of depth 3, for every choice of random string. <p> Thus we get the following corollary for PCP systems using 3 bits of queries. Corollary 6.10 PCP c;s [log; 3] P provided that c=s &gt; 2:7214. The previous best trade-off between completeness and soundness for polynomial-time PCP classes was c=s &gt; 4 <ref> [11] </ref>. 7 Lower Bounds for Gadget Constructions In this section we shall show that some of the gadget constructions mentioned in this paper and in [1] are optimal, and we shall prove lower bounds for some other gadget constructions.
Reference: [12] <author> M. Yannakakis. </author> <title> On the approximation of maximum satisfiability. </title> <journal> Journal of Algorithms, </journal> <volume> 17 </volume> <pages> 475-502, </pages> <year> 1994. </year>
Reference-contexts: This is the reciprocal of the factors mentioned in [1] and exactly the factors as stated in <ref> [12, 6, 7, 4] </ref>. 3 Definition 2.2 A constraint family F is a finite collection of constraint functions. The arity of F is the maximum number of arguments of the functions in F.
References-found: 12

