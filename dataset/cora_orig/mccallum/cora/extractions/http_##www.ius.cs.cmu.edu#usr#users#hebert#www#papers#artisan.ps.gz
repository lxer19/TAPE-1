URL: http://www.ius.cs.cmu.edu/usr/users/hebert/www/papers/artisan.ps.gz
Refering-URL: http://www.cs.cmu.edu/~hebert/home.html
Root-URL: 
Title: 3-D Object Modeling and Recognition for Telerobotic Manipulation  
Author: Andrew Johnson Patrick Leger Regis Hoffman Martial Hebert James Osborn 
Address: Pittsburgh, PA 15213  
Affiliation: The Robotics Institute Carnegie Mellon University  
Abstract: This paper describes a system that semi-automatically builds a virtual world for remote operations by constructing 3-D models of a robots work environment. With a minimum of human interaction, planar and quadric surface representations of objects typically found in manmade facilities are generated from laser rangefinder data. The surface representations are used to recognize complex models of objects in the scene. These object models are incorporated into a larger world model that can be viewed and analyzed by the operator, accessed by motion planning and robot safeguarding algorithms, and ultimately used by the operator to command the robot through graphical programming and other high level constructs. Limited operator interaction, combined with assumptions about the robots task environment, make the problem of modeling and recognizing objects tractable and yields a solution that can be readily incorporated into many telerobotic control schemes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B.K. Christensen, et al. </author> <title> Graphic Model Based Control of Robotics Systems for Waste Remediation. </title> <booktitle> Proceedings of the ANS Fifth Topical Meeting on Robotics and Remote Systems, </booktitle> <pages> pp. 89-96, </pages> <year> 1993. </year>
Reference-contexts: The reliance on cameras limits the effectiveness of such teleoperated systems because video images provide only 2-D information. For many complex tasks, 3-D information is vital. Previous work uses a variety of sensors and representations to construct models of interior workspaces. Christensen <ref> [1] </ref> describes a supervised teleoperated system with a world model that includes a priori knowledge, the robot configuration, and information gathered by the robots sensors.
Reference: [2] <author> M. Trivedi and C. X. Chen. </author> <title> Developing Sensor-based Robotics Systems Using Virtual Reality Concepts. </title> <booktitle> Proceedings of the ANS Fifth Topical Meeting on Robotics and Remote Systems, </booktitle> <pages> pp. 165-172, </pages> <year> 1993. </year>
Reference-contexts: The world model allows the operator to preview the operation, have the computer automatically plan an end-effector trajectory, and view the task from many different viewing positions. Trivedi <ref> [2] </ref> reports on another model-based system using range sensors; this system allows testing of robot plans in simulation. Azarbayejani [3] has a system to semiautomatically construct CAD models from uncalibrated video images.
Reference: [3] <editor> A.J. Azarbayejani et al. </editor> <title> Recursive Estimation for CAD Model Recovery. </title> <booktitle> Proceedings of the Second CAD-Based Vision Workshop, IEEE Computer Society, </booktitle> <pages> pp. 90-97, </pages> <year> 1994. </year>
Reference-contexts: The world model allows the operator to preview the operation, have the computer automatically plan an end-effector trajectory, and view the task from many different viewing positions. Trivedi [2] reports on another model-based system using range sensors; this system allows testing of robot plans in simulation. Azarbayejani <ref> [3] </ref> has a system to semiautomatically construct CAD models from uncalibrated video images. Thayer [4] computes an objects location and orientation using stereo vision; the operator performs the stereo matching of some points on the object and the system computes the pose of the object.
Reference: [4] <author> S. Thayer et al. </author> <title> On-line Stereo Vision and Graphical Interface for Decontamination and Decommissioning Applications Using the Advanced Servo Manipulator. </title> <booktitle> Proceedings of the ANS Fifth Topical Meeting on Robotics and Remote Systems, </booktitle> <pages> pp. 287-294, </pages> <year> 1993. </year>
Reference-contexts: Trivedi [2] reports on another model-based system using range sensors; this system allows testing of robot plans in simulation. Azarbayejani [3] has a system to semiautomatically construct CAD models from uncalibrated video images. Thayer <ref> [4] </ref> computes an objects location and orientation using stereo vision; the operator performs the stereo matching of some points on the object and the system computes the pose of the object.
Reference: [5] <institution> Environmental Restoration and Waste Management Five-Year Plan Fiscal Years 1994-1995 Report # DOE/5-00097P, US Department of Energy, </institution> <year> 1993. </year>
Reference-contexts: This capability is critical for future efforts in which teleoperated systems evolve into telerobotic and autonomous systems. 2 Telerobotics and 3-D object modeling The Department of Energy has declared that robots and remote systems will play crucial roles in future decontamination and decommissioning (D&D) of nuclear weapons facilities <ref> [5] </ref>. Mobile worksystems will be used in the near term for selective equipment removal, in which some part of an apparatus is extricated while minimally disturbing the surrounding objects. An example of a mobile pipe (left).
Reference: [6] <author> L. Conley, W. Hamel, and B. Thompson. Rosie: </author> <title> A Mobile Worksystem for Decontamination and Dismantlement Operations. </title> <booktitle> Proceedings of the ANS Sixth Topical Meeting on Robotics and Remote Systems, </booktitle> <pages> pp. 231-238, </pages> <year> 1995. </year>
Reference-contexts: An example of a mobile pipe (left). The IODOX facility, a DOE test site for selective equipment removal (right). worksystem is Rosie, an advanced prototype for testing, evaluating and demonstrating robotic selective equipment removal <ref> [6] </ref>. Rosie includes a locomotor, a heavy manipulator, an operator control center, and a control system for robot operation. An key component of the operator control center is the 3-D object modeling and recognition system.
Reference: [7] <author> M. Hebert and E. Krotkov. </author> <title> 3-D Measurements from Imaging Laser Radars: How Good Are They? International Journal of Image and Vision Computing, </title> <booktitle> 10(3), </booktitle> <pages> pp. 170-178, </pages> <year> 1992. </year>
Reference-contexts: It acquires 256 x 256 pixel range and intensity images over a vertical and horizontal field of view of 60 degrees at a frame rate of 2 Hz. The scanners range is 2 to 40 meters and its range precision is 5-7 cm <ref> [7] </ref>; the sensor that will be used in the final system will have much better accuracy and precision. To map a facility, the scanner is remotely positioned by a mobile worksystem and commanded by the human operator to acquire a sequence of images.
Reference: [8] <author> O.D. Faugeras and M. Hebert. </author> <title> The Representation, Recognition and Locating of 3-D Objects. </title> <journal> International Journal of Robotics Research, </journal> <volume> 5 (3), </volume> <pages> pp. 27-52, </pages> <year> 1986. </year>
Reference-contexts: This and reectance image (right) of experimental testbed. n x d+ 0= t t parametric description of surface patches makes the task of object recognition more efficient. Our algorithm, which is based on the algorithm for segmenting range images presented by Faugeras and Hebert <ref> [8] </ref>, is presented in detail in [9]. It is a generalization of their technique because it performs the segmentation using the arbitrary connectivity of a surface mesh. Furthermore, the similarity measure that defines when to merge two regions can be easily changed to measure any property of the surface. <p> Hence, there exists twenty four possible rotations for the transformation of model to scene. Once the twenty four matches between model and scene eigenvectors have been enumerated, the corresponding twenty four rotation matrices are generated using the quaternion representation presented in <ref> [8] </ref>. For each of these twenty four rotations, Equation 7 is solved for T, resulting in twenty four (R,T) pairs.
Reference: [9] <author> M. Hebert, R. Hoffman, A. Johnson, and J. Osborn. </author> <title> Sensor-Based Interior Modeling. </title> <booktitle> Proceedings of the ANS Sixth Topical Meeting on Robotics and Remote Systems, </booktitle> <pages> pp. 731-737, </pages> <year> 1995. </year> <editor> [10]P. J. Besl and N. D. </editor> <title> McKay A Method for Registration of 3-D Shapes. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14 (2), </volume> <pages> pp. 239-256, </pages> <year> 1992. </year> <note> [11]I. </note> <author> Kweon, R. Hoffman, and M. Hebert. </author> <title> Experimental Characterization of the Perceptron Laser Rangefinder. </title> <type> Technical Report# CMU-RI-TR-91-1, </type> <institution> The Robotics Institute, Carnegie Mellon University, </institution> <year> 1991. </year>
Reference-contexts: Our algorithm, which is based on the algorithm for segmenting range images presented by Faugeras and Hebert [8], is presented in detail in <ref> [9] </ref>. It is a generalization of their technique because it performs the segmentation using the arbitrary connectivity of a surface mesh. Furthermore, the similarity measure that defines when to merge two regions can be easily changed to measure any property of the surface.
References-found: 9

