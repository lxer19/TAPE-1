URL: http://www.cs.brandeis.edu/~glen/papers/HofDNA.ps
Refering-URL: http://www.cs.brandeis.edu/~cs170a/projects.html
Root-URL: http://www.cs.brandeis.edu
Title: Examination of Entropic Bounds for Human DNA Sequences  
Author: Glen Pritchett 
Date: May 1, 1998  
Abstract-found: 0
Intro-found: 1
Reference: [Hum98] <institution> Oak Ridge National Laboratory (1998, </institution> <month> April 2). </month> <title> Human Genome Project Information. Retrieved April 20, 1998 from the World Wide Web: </title> <address> http://www.ornl.gov/TechResources/Human_Genome/ </address>
Reference-contexts: Under the broad assumption that all pairings are equally likely, a rough upper bound on the entropy of human DNA can be easily computed as follows. The number of base pairs for a complete human DNA sequence is estimated at 3,000,000,000 <ref> [Hum98] </ref>. With all pairings equally likely, using the 2 bits necessary to represent each of the four possible values for each base pair, the resulting upper bound for the entropy of a random human DNA sequence is 6,000,000,000 bits. <p> This is counterintuitive because we imagine DNA to be a highly ordered sequence, and furthermore, we know that the average difference between two human genomes is about 0.1% <ref> [Hum98] </ref>. So why can't we distinguish DNA from a random string? One reason is our current lack of knowledge about DNA. At the time of this paper, only the 16th and 19th chromosomes have been completely sequenced. <p> As suggested by Grumbach and Tahi [Gru93] a DNA sequence could be compressed relative to a "sequence of reference." Given that the average difference between two haploid human genomes is about 0.1% (3 million base-pairs) <ref> [Hum98] </ref> the entropy of the differences between two human genomes is a smaller problem by orders of magnitude. A counting argument for a lower entropy To demonstrate the application of this analysis, we will examine a specific gene, the gene for Hemoglobin alpha 1.
Reference: [Mut98] <institution> Institute of Medical Genetics, Cardiff. HBA1. </institution> <note> [Known Mutations of Hemoglobin alpha 1]. Retrieved April 20, 1998 from the World Wide Web: http://www.uwcm.ac.uk/uwcm/mg/search/119293.html </note>
Reference-contexts: The most common expression of this gene consists of 2685 base pairs [Nat98]. There are 31 known variants (of which, only 18 are normal/healthy variations) of this gene <ref> [Mut98] </ref>. As the relative distributions of the Hemoglobin alpha 1 gene and its variants in the human population are unknown at this point in time, we will assume the worst case for our analysis, in which the distributions of this gene and its variants are equal to each other.
Reference: [Nat98] <institution> National Center for Biotechnology Information (1998, </institution> <month> March 5). </month> <title> GenBank Database Document Reader. [DNA sequence information for Hemoglobin alpha 1]. Retrieved April 20, 1998 from the World Wide Web: </title> <address> http://www.ncbi.nlm.nih.gov/irx/cgi-bin/birx_doc?genbank+73801 </address>
Reference-contexts: This gene is chosen because it is common to all humans 16th chromosome and several variations of its sequence data are known. The most common expression of this gene consists of 2685 base pairs <ref> [Nat98] </ref>. There are 31 known variants (of which, only 18 are normal/healthy variations) of this gene [Mut98]. <p> Standard compression techniques (see appendix) all actually perform worse than the full representation. Scalability The question to ask at this point is whether this technique is scalable over the 60,000 to 80,000 genes present in human DNA <ref> [Nat98] </ref>. It very well may not be. The gene for Hemoglobin alpha 1 does not number among the largest or the smallest genes in the human genome; it is estimated to be slightly smaller than the average gene.
Reference: [Loe96] <author> Loewenstern, David & Yianilos, Peter. </author> <title> Significantly lower entropy estimates for natural DNA sequences. </title> <type> DIMACS Technical Report 96-51. </type> <month> December </month> <year> 1996. </year>
Reference-contexts: Unfortunately, analysis of many DNA sequences, including large portions of the human genome, cannot be considered to significantly differ from random sequences over DNA's four letter alphabet <ref> [Loe96] </ref>, [Gru93], [Bre86]. This is counterintuitive because we imagine DNA to be a highly ordered sequence, and furthermore, we know that the average difference between two human genomes is about 0.1% [Hum98].
Reference: [Gru93] <author> Grumbach, Stephane & Tahi, Fariza. </author> <title> Compression of DNA sequences. </title> <journal> IEEE Transactions on Information Theory, </journal> <pages> 340-350, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Unfortunately, analysis of many DNA sequences, including large portions of the human genome, cannot be considered to significantly differ from random sequences over DNA's four letter alphabet [Loe96], <ref> [Gru93] </ref>, [Bre86]. This is counterintuitive because we imagine DNA to be a highly ordered sequence, and furthermore, we know that the average difference between two human genomes is about 0.1% [Hum98]. <p> Changing the problem space Rather than examining the entropy of human DNA with respect to a random alphabet over 4 letters, it might be better to compare the differences between actual human DNA sequences. As suggested by Grumbach and Tahi <ref> [Gru93] </ref> a DNA sequence could be compressed relative to a "sequence of reference." Given that the average difference between two haploid human genomes is about 0.1% (3 million base-pairs) [Hum98] the entropy of the differences between two human genomes is a smaller problem by orders of magnitude.
Reference: [Sal92] <author> Salamon, Peter & Konopka, Andrzej. </author> <title> A maximum entropy principle for the distribution of local complexity in naturally occurring nucleotide sequences. </title> <booktitle> Computers Chem 16(2) </booktitle> <pages> 117-124, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: So, any given base-pair may differ from a general DNA sequence in a random position. Additionally, according to Salamon and Konopka <ref> [Sal92] </ref> "The distribution of complexity in short oligo-nucleotides is as random as possible, consistent with a given mean value of complexity." Thus, without knowledge of the actual distributions of the variance in base-pairs for each position, a random string must be assumed.
Reference: [Cov91] <author> Cover, Thomas. & Thomas, Joy. </author> <title> Elements of Information Theory. </title> <publisher> John Wiley & Sons, Inc. </publisher> <year> 1991. </year>
Reference: [Bre86] <author> Brendel, V, Beckman, J, & Trifinov, E. </author> <title> Linguistics of nucleotide sequences: morphology and comparison of vocabularies. Journal of Biomolecular Structure & Dynamics 4(1) </title> <type> 11-21, </type> <year> 1986. </year>
Reference-contexts: Unfortunately, analysis of many DNA sequences, including large portions of the human genome, cannot be considered to significantly differ from random sequences over DNA's four letter alphabet [Loe96], [Gru93], <ref> [Bre86] </ref>. This is counterintuitive because we imagine DNA to be a highly ordered sequence, and furthermore, we know that the average difference between two human genomes is about 0.1% [Hum98]. So why can't we distinguish DNA from a random string? One reason is our current lack of knowledge about DNA.
Reference: [Win86] <author> Winter, William. </author> <title> Phylogeny of normal and abnormal hemoglobin genes. DNA Systematics, </title> <address> 169-188. </address> <publisher> CRC press. </publisher> <year> 1986. </year>
References-found: 9

