URL: ftp://ftp.cs.rochester.edu/pub/papers/ai/93.tr421.computational_theory_of_lexical_relatedness.ps.Z
Refering-URL: http://www.cs.rochester.edu/trs/ai-trs.html
Root-URL: 
Title: A Computational Theory of Lexical Relatedness  
Author: Marc Light 
Note: This work was funded by NSF grant no. IRI-9013160.  
Date: February 1993  
Address: Rochester, New York 14627  
Affiliation: The University of Rochester Computer Science Department  
Pubnum: Technical Report 421  
Abstract: Lexicon coverage is often the limiting factor in natural language processing systems. Recent work has attempted to remedy this situation by extracting information from machine readable dictionaries. Unfortunately, no NLP lexicon system or dictionary could possibly list all the potential words of English. However, humans are often able to interpret novel word forms (that is, words they have not seen before) without difficulty. One way we do this, if the word is complex (e.g. undecidability), is by using cues from the internal structure of the word. Relations in phonological form often correspond to relations in meaning. For example, if someone knows what the verb open means, a number of educated guesses can be made about the meaning of reopen. Exceptions abound in lexical data and any system that attempts to use lexical generalizations must be able to handle exceptions in a principled fashion. In this report, I will describe the preliminary design of a system that uses relations in form to derive relations in meaning. For a new word, the system will produce meaning postulates that represent an educated guess about the meaning of the new word. These meaning postulates will be written in Episodic Logic [Schubert and Hwang, 1990] and the entire system will be a module of the TRAINS system [Allen and Schubert, 1991]. 
Abstract-found: 1
Intro-found: 1
Reference: [Allen and Schubert, 1991] <author> J. Allen and L. K. Schubert, </author> <title> "The TRAINS Project," </title> <type> Technical Report 382, </type> <institution> Department of Computer Science, University of Rochester, </institution> <year> 1991. </year>
Reference-contexts: In this report, I will discuss the preliminary design of a lexicon system that can make such educated guesses. This system will utilize the knowledge representation language Episodic Logic [Schubert and Hwang, 1990] and will be a module of the TRAINS system <ref> [Allen and Schubert, 1991] </ref>. In Figure 1, the placement of the lexicon system within a natural language processing system such as TRAINS is illustrated. <p> The tasks involving trains, cities, factories, products, and deadlines. Spoken discourse was recorded by microphone and tape recorder. For an overview of the TRAINS project see <ref> [Allen and Schubert, 1991] </ref>. 2 Here and throughout this report new will have a relative meaning: new to whatever system or human we are discussing. Whether or not a word is in some dictionary somewhere will most often be irrelevant to the discussion. 1 the knowledge base in Figure 1.
Reference: [Anderson, 1991] <author> Stephen R. Anderson, </author> <title> "A-Morphous Morphology". </title> <type> Manuscript, </type> <month> April </month> <year> 1991. </year>
Reference-contexts: This separation between the phonological/morphological aspects of a word formation process and its lexical rule which relates two entries is a response to the results of researchers such as Siegel, Selkirk, and Lieber and the data discussed in <ref> [Anderson, 1991] </ref>. As discussed above, their work suggests that word formation processes have both a morphosyntactic and a morphosemantic aspect and that these aspects are independent in some ways. An example of the type of information to be stored in WF marker entries is that -ness only applies to adjectives.
Reference: [Aronoff, 1976] <author> M. Aronoff, </author> <title> Word Formation in Generative Grammar, </title> <publisher> MIT press, </publisher> <year> 1976. </year>
Reference: [Baker, 1988] <author> M. Baker, </author> <title> Incorporation, </title> <publisher> MIT press, </publisher> <year> 1988. </year>
Reference: [Bear, 1988] <author> J Bear, </author> <title> "Morphology with Two-Level Rules and Negative Rule Features," </title> <booktitle> in COLING, </booktitle> <pages> pages 272-276, </pages> <year> 1988. </year>
Reference-contexts: Most of the systems in use today use a formalism related to that used by KIMMO for segmentation <ref> [Black et al., 1986; Domenig, 1988; Bear, 1988] </ref>. These systems are quite successful at the segmentation task. Large subsets of morphologically complicated languages such a Finnish can be successfully segmented by such systems.
Reference: [Berube et al., 1982] <author> M. Berube, D. Neely, and P. DeVinne, </author> <title> American Heritage dictionary second college edition, </title> <publisher> Houghton Miffin, </publisher> <year> 1982. </year>
Reference-contexts: I spent twenty minutes searching through a magazine and found the following words: uncontaminated, titleless, mini-series, underretailed, megamall, and unfussy. None of the words are listed in my 200,000 definition American Heritage dictionary <ref> [Berube et al., 1982] </ref>. Such examples are not restricted to written language. While searching through the TRAINS dialogues, 1 I found mishear, shallowly, and reformulate. None of these words are in the dictionary. These cases illustrate the futility of trying to develop a list of all English words.
Reference: [Black et al., 1986] <author> A.W. Black, S.G. Pulman, G.D. Ritchie, and G.J. Russell, </author> <title> "A Dictionary and Morphological Analyser for English," </title> <booktitle> in COLING, </booktitle> <pages> pages 277-279, </pages> <year> 1986. </year>
Reference-contexts: Most of the systems in use today use a formalism related to that used by KIMMO for segmentation <ref> [Black et al., 1986; Domenig, 1988; Bear, 1988] </ref>. These systems are quite successful at the segmentation task. Large subsets of morphologically complicated languages such a Finnish can be successfully segmented by such systems.
Reference: [Byrd, 1983] <author> R.J. Byrd, </author> <title> "Word Formation in Natural Language Processing Systems," </title> <booktitle> in COLING, </booktitle> <pages> pages 704-706, </pages> <year> 1983. </year>
Reference-contexts: The lexicon of the ALVEY project uses a chart parser and a GPSG-inspired set of percolation constraints to perform the word parsing task [Ritchie et al., 1992]. Byrd's work <ref> [Byrd, 1983] </ref> combines parsing and segmentation into a single process based on Aronoff's conception of word formation rules. For an insightful review of the literature on segmentation and parsing see [Sproat, 1992].
Reference: [Carnap, 1956] <author> Rudolf Carnap, </author> <title> Meaning and Necessity, </title> <publisher> University of Chicago Press, </publisher> <year> 1956. </year>
Reference-contexts: This claim is implemented by treating every word as denoting a unique atomic symbol in the underlying logic. New words are assigned a unique atomic symbol when they are first encountered. The meaning of these atomic symbols is encoded in meaning postulates <ref> [Carnap, 1956] </ref> which represent the entailments of an atomic symbol. 8 An attempt will be made to use only one-way entailments in such meaning postulates. Thus kill 0 (x; y) will entail something like cause (x; die 0 (y)) but not vice versa.
Reference: [Chierchia and McConnell-Ginet, 1990] <author> Gennaro Chierchia and Sally McConnell-Ginet, </author> <title> Meaning and Grammar: An Introduction To Semantics, </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1990. </year>
Reference-contexts: This new atom can then be constrained by meaning postulates created by the lexical rule. For example, in <ref> [Chierchia and McConnell-Ginet, 1990] </ref> the translation rule in (6) is rewritten as (7b). The constraint (or meaning postulate) in (7b) can be used to ensure the same entailments for the -able form of a verb. 11 (7) a. <p> The MP schemata, which are used to produce MP's for new entries produced by lexical rules, are the main novel aspect of this system. They are an implementation of the suggestion from <ref> [Chierchia and McConnell-Ginet, 1990] </ref> discussed above. MP schemata encode semantic generalizations that correspond to the lexical rule. They enable the system to guess what some of the entailments of a new atomic symbol are.
Reference: [Chomsky, 1970] <author> Noam Chomsky, </author> <title> "Remarks on Nominalization," </title> <editor> in R. Jacobs and P. Rosenbaum, editors, </editor> <title> Readings in English Transformational Grammar. </title> <publisher> Ginn: </publisher> <address> Waltham, Massachusetts, </address> <year> 1970. </year>
Reference: [Domenig, 1988] <author> M. Domenig, </author> <title> "Word Manager: A System for the Definition, Access and Maintenance of Lexical Data bases," </title> <booktitle> in COLING, </booktitle> <pages> pages 154-159, </pages> <year> 1988. </year>
Reference-contexts: Most of the systems in use today use a formalism related to that used by KIMMO for segmentation <ref> [Black et al., 1986; Domenig, 1988; Bear, 1988] </ref>. These systems are quite successful at the segmentation task. Large subsets of morphologically complicated languages such a Finnish can be successfully segmented by such systems.
Reference: [Downing, 1977] <author> Pamela Downing, </author> <title> "On the Creation and Use of English Compound Nouns," </title> <booktitle> Language, </booktitle> <volume> 53(4) </volume> <pages> 663-682, </pages> <year> 1977. </year>
Reference-contexts: This fact suggests that word formation processes have both a morphosyntactic and a morphosemantic aspect and that these aspects are independent in some ways. 11;12 2.2 Research Methodology: Downing Downing's paper on novel compound nouns <ref> [Downing, 1977] </ref> contains an insightful discussion of methodological flaws that can cause a researcher to make false generalizations about compounding processes. First, a supposed linguistic generalization may actually be derivative of a generalization about the world. <p> They involve deriving the compounds from underlying sentences or relative clauses, reduction to a set of primitive relations, or both. As Downing shows, such approaches are plagued by "indeterminacy of analysis and irrecoverable deletion of meaningful material" <ref> [Downing, 1977] </ref>. For the approaches involving primitive predicates, Downing gives compounds that do not fit into the classification scheme set up by the primitives and yet were judged as `possible English compounds' by the subjects of her experiments.
Reference: [Dowty, 1979] <author> David Dowty, </author> <title> Word Meaning and Montague Grammar, </title> <address> D. </address> <publisher> Reidel Publishing, </publisher> <year> 1979. </year>
Reference: [Doyle, 1979] <author> J. Doyle, </author> <title> "A Truth Maintenance System," </title> <journal> Artificial Intelligence, </journal> <volume> 12(3) </volume> <pages> 231-272, </pages> <year> 1979. </year>
Reference-contexts: Discovering exceptionality is a more difficult problem and I have only outlined a rough approach here. Another problem is that of retracting all inferences based on faulty meaning postulates. I hope to apply standard truth maintenance techniques <ref> [Doyle, 1979] </ref> to solve this problem. 4 The Meaning Postulates for Verbs Starting with the Pre fix re Now that we have seen the pieces of the system and how they fit together, I will discuss in detail the semantics of the verbal prefix re.
Reference: [Evans and Gazdar, 1990] <author> R. Evans and G. Gazdar, </author> <title> "The DATR Papers," </title> <type> Technical report, </type> <institution> University of Sussex, Cognitive Science Research Reports, </institution> <year> 1990. </year>
Reference: [Flickinger, 1987] <author> Dan Flickinger, </author> <title> Lexical Rules in the Hierarchical Lexicon, </title> <type> PhD thesis, </type> <institution> Stanford, </institution> <year> 1987. </year> <month> 39 </month>
Reference-contexts: These nodes encode information about how features cluster. The inheritance mechanism enables one to reduce the redundancy in the lexicon. Irregularity is handled by preferring information specified lower in the hierarchy to that specified higher in the hierarchy when a conflict occurs. An example hierarchy adopted 14 from <ref> [Flickinger, 1987] </ref> is given in Figure 6. It stores information about subcategorization constraints. Consider the node for the transitive class in Figure 7 [Flickinger, 1987]. All of the information specified here is inherited by the OBJECT-EQUI, OBJECT-RAISING, DITRANS-TO, and DITRANS nodes. <p> An example hierarchy adopted 14 from <ref> [Flickinger, 1987] </ref> is given in Figure 6. It stores information about subcategorization constraints. Consider the node for the transitive class in Figure 7 [Flickinger, 1987]. All of the information specified here is inherited by the OBJECT-EQUI, OBJECT-RAISING, DITRANS-TO, and DITRANS nodes. For example, all verbs that are members of the above classes will assign accusative case to their direct objects unless they override this inheritance locally. <p> The most relevant idea to the goal of this research project that comes out of such work is that a lexical rule can be seen as representing a relationship between two lexical classes (i.e. nodes in a hierarchy) <ref> [Pollard and Sag, 1987; Flickinger, 1987] </ref>. Each lexical rule can apply to any of the entries that are members of one of the related classes or a subclass of these classes. <p> The syntax slot is filled with a set of syntactic features that all the member lexical entries inherit. See the example telic, stative, verb, and adjective classes in Lexical rules Following <ref> [Flickinger, 1987] </ref>, lexical rules relate lexical classes. More specifically, they relate members of one lexical class to members of another lexical class. A lexical rule is made of four parts.
Reference: [Flickinger and Nerbonne, 1991] <author> Dan Flickinger and John Nerbonne, </author> <title> "Inheritance and Complementation: A case study of easy adjectives and related nouns". </title> <booktitle> course material for the 1991 LLI summer school, </booktitle> <year> 1991. </year>
Reference: [Flickinger et al., 1985] <author> Daniel Flickinger, Carl Pollard, and Thomas Wasow, </author> <title> "Structure-sharing in lexical representation," </title> <booktitle> in Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics, </booktitle> <year> 1985. </year>
Reference: [Halle, 1990] <author> Morris Halle, </author> <title> "An approach to Morphology," </title> <booktitle> in Proceedings of the 20th NELS conference, </booktitle> <year> 1990. </year>
Reference-contexts: Baker concentrates mostly on syntactic features of polysynthetic languages. 11 The existence of morphemes (i.e. minimal sound-meaning pairs) is hotly contested in the morphology literature today. Halle [1990] exemplifies the morpheme-based approach and Anderson [1991] the "a-morphous" approach. Pullum & Zwicky [1991] address directly the arguments contained in <ref> [Halle, 1990] </ref>. Halle argues that the morpheme-based approach is a more constrained theory (i.e. makes fewer stipulations) than an a-morphous theory. Thus, by Occam's razor, it should be preferred.
Reference: [Jackendoff, 1972] <author> R. Jackendoff, </author> <title> Semantic Interpretation in Generative Grammar, </title> <publisher> MIT press, </publisher> <year> 1972. </year>
Reference-contexts: However, I argue that we do not need to stipulate two entries for again. Instead, we can treat again as having exactly the same presuppositions as re. The crucial observation is that intonation forces a focus shift and this focus shift produces presuppositions <ref> [Jackendoff, 1972] </ref>. Consider the examples taken from Jackendoff in (58). (58) a. Did John kill Frank with a HAMMER? b. Did JOHN kill Frank with a hammer? c. John killed Frank with a HAMMER.
Reference: [Jackendoff, 1975] <author> R. Jackendoff, </author> <title> "Morphological an Semantic Regularities in the Lexicon," </title> <booktitle> Language, </booktitle> <volume> 51 </volume> <pages> 639-671, </pages> <year> 1975. </year>
Reference-contexts: A grammar that expresses this fact should be more highly valued than one that does not." <ref> [Jackendoff, 1975] </ref> Jackendoff introduces the notion of the lexical redundancy rule to provide this functionality. An example redundancy rule taken from [Jackendoff, 1975] is given in Figure (3). <p> A grammar that expresses this fact should be more highly valued than one that does not." <ref> [Jackendoff, 1975] </ref> Jackendoff introduces the notion of the lexical redundancy rule to provide this functionality. An example redundancy rule taken from [Jackendoff, 1975] is given in Figure (3). Quoting Jackendoff, "the rule thus can be read: `A lexical entry x having such-and-such properties is related to a lexical entry w having such-and-such properties.' " Jackendoff uses redundancy rules to relate fully specified entries.
Reference: [Jackendoff, 1983] <author> Ray Jackendoff, </author> <title> Semantics and Cognition, </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1983. </year>
Reference-contexts: Thus a researcher should attempt to use a wide set of sources and be aware of the possible limitations of these sources. 2.3 Lexical Semantics Most of the work in lexical semantics focuses on deriving syntactic behavior of verbs from their semantics (e.g. [Pinker, 1990] and <ref> [Jackendoff, 1983] </ref>). 13 Verb meanings are decomposed into structured definitions which utilize a finite set of primitives and a finite set of combination mechanisms (see Figure 4 adopted from [Pinker, 1990]). 14 One important use of the decompositional definitions is to derive the argument structure of a verb from its definition. <p> defect of linguistic semantics that it is all but impossible to know whether a putative counterexample or misclassification really is that or not, since Levi gives us no specification of just what the meanings of CAUSE, USE, FOR, etc. are supposed to be." The same critisism can be levied against <ref> [Jackendoff, 1983] </ref> and [Pinker, 1990].
Reference: [Karttunen, 1983] <author> L. Karttunen, "KIMMO: </author> <title> A General Morphological Processor," </title> <journal> Texas Linguistic Forum, </journal> <volume> 22 </volume> <pages> 165-278, </pages> <year> 1983. </year>
Reference: [Keenan, 1972] <author> Edward Keenan, </author> <title> "On Semantically Based Grammar," Linguistic Inquiry, </title> <address> 3.4:413-462, </address> <year> 1972. </year>
Reference-contexts: After each set of works has been discussed, I will summarize the important concepts. 2.1 Theoretical Linguistics Some of the earliest work done on semantics of the lexicon in the generative grammar tradition was by the generative semantics movement. (e.g. <ref> [Lakoff, 1968; Lakoff, 1972; McCawley, 1973; Keenan, 1972] </ref>).
Reference: [Koskenniemi, 1984] <author> K. Koskenniemi, </author> <title> "A General Computational Model For Word-Form Recognition and Production," </title> <booktitle> in COLING, </booktitle> <pages> pages 178-181, </pages> <year> 1984. </year>
Reference-contexts: Example (13) contains a complex word, its segmentation, and its parse. (13) a. undecidability b. un-decide-able-ity c. [[un- [decide -able]] -ity] The most influential segmentation system is the KIMMO system originally developed by Kimmo Koskenniemi <ref> [Koskenniemi, 1984] </ref> and expanded upon by Karttunen [1983]. Most of the systems in use today use a formalism related to that used by KIMMO for segmentation [Black et al., 1986; Domenig, 1988; Bear, 1988]. These systems are quite successful at the segmentation task.
Reference: [Lakoff, 1968] <author> George Lakoff, </author> <title> "Instrumental Adverbs and the Concept of Deep Structure," </title> <booktitle> Foundations of Language, </booktitle> <volume> 4 </volume> <pages> 4-29, </pages> <year> 1968. </year>
Reference-contexts: After each set of works has been discussed, I will summarize the important concepts. 2.1 Theoretical Linguistics Some of the earliest work done on semantics of the lexicon in the generative grammar tradition was by the generative semantics movement. (e.g. <ref> [Lakoff, 1968; Lakoff, 1972; McCawley, 1973; Keenan, 1972] </ref>).
Reference: [Lakoff, 1972] <author> George Lakoff, </author> <title> "Linguistics and Natural Logic," </title> <editor> in Donald Davidson and Gilbert Harmon, editors, </editor> <booktitle> Semantics of Natural Lanuguage. </booktitle> <publisher> Reidel, </publisher> <address> Dordrecht, </address> <year> 1972. </year>
Reference-contexts: After each set of works has been discussed, I will summarize the important concepts. 2.1 Theoretical Linguistics Some of the earliest work done on semantics of the lexicon in the generative grammar tradition was by the generative semantics movement. (e.g. <ref> [Lakoff, 1968; Lakoff, 1972; McCawley, 1973; Keenan, 1972] </ref>).
Reference: [Lees, 1960] <author> Robert B. Lees, </author> <title> The grammar of English nominalizations. (IJAL 26:3, Part II.), </title> <institution> Indiana University, Bloomington, </institution> <year> 1960. </year>
Reference: [Levi, 1978] <author> Judith Levi, </author> <title> The Syntax and Semantics of Complex Nominals, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1978. </year>
Reference: [Li, 1971] <author> Charles Li, </author> <title> Semantics and the structure of compounds in Chinese, </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1971. </year>
Reference: [Lieber, 1980] <author> R. Lieber, </author> <title> On the Organization of the Lexicon, </title> <type> PhD thesis, </type> <institution> MIT, </institution> <year> 1980. </year>
Reference-contexts: They are not "on line"." For our purposes, Aronoff 's WFR's do not differ substantially from Jackendoff 's redundancy rules. Before summarizing the above work, let us review a group of works ([Siegel, 1974], [Selkirk, 1982], and <ref> [Lieber, 1980] </ref>) which concentrate more on the phonological aspects of word formation.
Reference: [Light, 1991] <author> M. </author> <title> Light, "Taking the Paradoxes Out of Bracketing in Morphology," </title> <booktitle> in Proceedings of the Second Formal Linguistics Society of Mid-America Conference. </booktitle> <institution> University of Michigan, </institution> <year> 1991. </year>
Reference-contexts: These conflicts are called bracketing paradoxes. In <ref> [Light, 1991] </ref>, I argue that the supposed bracketing paradoxes dissolve when the relevant constraints are refined.
Reference: [Light, 1992] <author> M. Light, "Rehashing Re," </author> <booktitle> in Proceedings of the Eastern States Conference on Linguistics. </booktitle> <institution> University of Cornell, </institution> <year> 1992. </year> <month> 40 </month>
Reference-contexts: From this point on, I will refer to these works by the name of the author only. What I am presenting here is derivative 26 This section is a slightly modified version of <ref> [Light, 1992] </ref>. 23 of these works. However, it refutes a number of their claims, introduces new data, and presents a new framework for representing the semantics of word formation processes. This section will be structured as follows.
Reference: [Light, 1993] <author> Marc Light, </author> <title> "Is Decomposition a Rotten Idea?". </title> <type> unpublished manuscript, </type> <year> 1993. </year>
Reference-contexts: When the system guesses at the meaning of a new word, it should know that there is only partial information about the definition of the new word. Thus, the meaning postulate framework is better suited for the representation of word formation semantics. See <ref> [Light, 1993] </ref> for a more in depth discussion. 12 (10) John F. Kennedy was assassinated. Logical truths are a further subclass of analytic truths and are exemplified by (11). (11) is true by virtue of `logical' words such as not and or.
Reference: [Marchand, 1969] <author> Hans Marchand, </author> <title> The Categories and Types of Present-Day English Word-Formation. 2nd Ed., </title> <type> Beck, </type> <institution> Muenchen, </institution> <year> 1969. </year>
Reference-contexts: The lexical relationships that I will be concerned with are those produced by word formation processes. Examples of word formation processes are derivational affixation (derivable), argument structure alternations (see (1)), compounding (steamboat ), blends (chunnel ), clippings (lab), back-formation (televise). 3;4 3 See <ref> [Marchand, 1969] </ref> for an insightful description of English word formation. 4 I will assume that inflectional processes (e.g. walk-s, bike-s) are not word formation processes. 2 (1) a. The glass broke. b. John broke the glass.
Reference: [McCawley, 1973] <author> James D. McCawley, </author> <title> "Syntactic and Logical Arguments for Semantic Structures," in Osamu Farjimura, editor, Three Dimensions in Linguistic Theory. </title> <publisher> TEC Corp., </publisher> <address> Tokyo, </address> <year> 1973. </year>
Reference-contexts: After each set of works has been discussed, I will summarize the important concepts. 2.1 Theoretical Linguistics Some of the earliest work done on semantics of the lexicon in the generative grammar tradition was by the generative semantics movement. (e.g. <ref> [Lakoff, 1968; Lakoff, 1972; McCawley, 1973; Keenan, 1972] </ref>).
Reference: [Pesetsky, 1985] <author> D. Pesetsky, </author> <title> "Morphology and Logical Form," </title> <journal> Linguistic Inquiry, </journal> <volume> 16(2) </volume> <pages> 193-246, </pages> <year> 1985. </year>
Reference-contexts: In short, a more general correspondence between process and meaning seems to exist where the process might involve multiple sound units. 12 A number of conflicts between the constraints of the morphosyntactic and the morphosemantic have been noted in the liturature <ref> [Pesetsky, 1985; Sproat, 1985] </ref>. These conflicts are called bracketing paradoxes. In [Light, 1991], I argue that the supposed bracketing paradoxes dissolve when the relevant constraints are refined.
Reference: [Pinker, 1990] <author> Steven Pinker, </author> <title> Learnability and Cognition: The Acquisition of Argument Structure, </title> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1990. </year>
Reference-contexts: Thus a researcher should attempt to use a wide set of sources and be aware of the possible limitations of these sources. 2.3 Lexical Semantics Most of the work in lexical semantics focuses on deriving syntactic behavior of verbs from their semantics (e.g. <ref> [Pinker, 1990] </ref> and [Jackendoff, 1983]). 13 Verb meanings are decomposed into structured definitions which utilize a finite set of primitives and a finite set of combination mechanisms (see Figure 4 adopted from [Pinker, 1990]). 14 One important use of the decompositional definitions is to derive the argument structure of a verb <p> Most of the work in lexical semantics focuses on deriving syntactic behavior of verbs from their semantics (e.g. <ref> [Pinker, 1990] </ref> and [Jackendoff, 1983]). 13 Verb meanings are decomposed into structured definitions which utilize a finite set of primitives and a finite set of combination mechanisms (see Figure 4 adopted from [Pinker, 1990]). 14 One important use of the decompositional definitions is to derive the argument structure of a verb from its definition. <p> Unlike the work in Generative Semantics such modifications are posited to occur in the lexicon as lexical rules. Figure 5 contains the rule for the causative alternation proposed in <ref> [Pinker, 1990] </ref>. Since the verbs mean something slightly different when used in the different argument structure, the meanings of the different sentences should be different. The sentence in (4b) has the obvious entailment that someone broke the glass, namely John. However, (4a) does not entail an agent. <p> semantics that it is all but impossible to know whether a putative counterexample or misclassification really is that or not, since Levi gives us no specification of just what the meanings of CAUSE, USE, FOR, etc. are supposed to be." The same critisism can be levied against [Jackendoff, 1983] and <ref> [Pinker, 1990] </ref>.
Reference: [Pollard and Sag, 1987] <author> C. Pollard and I. Sag, </author> <title> Information-Based Syntax and Semantics Vol. I, </title> <publisher> University of Chicago Press, </publisher> <year> 1987. </year>
Reference-contexts: The most relevant idea to the goal of this research project that comes out of such work is that a lexical rule can be seen as representing a relationship between two lexical classes (i.e. nodes in a hierarchy) <ref> [Pollard and Sag, 1987; Flickinger, 1987] </ref>. Each lexical rule can apply to any of the entries that are members of one of the related classes or a subclass of these classes.
Reference: [Pullum and Zwicky, 1991] <author> Geoffrey k. Pullum and Arnold M. </author> <title> Zwicky, "A Misconceived Approach to Morphology," </title> <booktitle> in Proceedings of the 10th West Coast Conference on Formal Linguistics, </booktitle> <year> 1991. </year>
Reference: [Pustejovsky, 1991] <author> James Pustejovsky, </author> <title> "The Generative Lexicon," </title> <journal> Computational Linguistics, </journal> <volume> 17 </volume> <pages> 409-441, </pages> <year> 1991. </year>
Reference: [Pustejovsky and Anick, 1988] <author> James Pustejovsky and Peter Anick, </author> <title> "On the Semantics of Nominals," </title> <booktitle> in COLING, </booktitle> <year> 1988. </year>
Reference: [Ritchie et al., 1992] <author> Graeme D. Ritchie, Graham J. Russell, Alan W. Black, and Steve G. Pulman, </author> <title> Computational Morphology: practical mechanisms for the English lexicon, </title> <publisher> MIT press, </publisher> <year> 1992. </year>
Reference-contexts: The lexicon of the ALVEY project uses a chart parser and a GPSG-inspired set of percolation constraints to perform the word parsing task <ref> [Ritchie et al., 1992] </ref>. Byrd's work [Byrd, 1983] combines parsing and segmentation into a single process based on Aronoff's conception of word formation rules. For an insightful review of the literature on segmentation and parsing see [Sproat, 1992].
Reference: [Russell et al., 1991] <author> Graham Russell, Afzal Ballim, John Carroll, and Susan Warwick-Armstrong, </author> <title> "A Practical Approach to Multiple Default Inheritance for Unification-Based Lexicons". </title> <note> to appear in Computational Linguistics, </note> <year> 1991. </year>
Reference: [Schubert, 1982] <author> L. Schubert, </author> <title> "An Approach to the Syntax and Semantics of Affixes in Conventionalized Phrase Structure Grammar," </title> <booktitle> in Proceedings of the Fourth Bienn. Conference of the CSCSI/SCEIO, </booktitle> <pages> pages 189-195, </pages> <year> 1982. </year>
Reference-contexts: It is unclear whether semantic information will benefit from such hierarchies. I will briefly discuss segmentation and parsing, simply listing the relevant references, and then move on to the work on storage. 16 <ref> [Schubert, 1982] </ref> is a notable exception. 13 Segmentation and Parsing A large amount of work in computational linguistics has concentrated on word recognition. This amounts to developing systems that can undo the phonological rules of a language.
Reference: [Schubert and Hwang, 1990] <author> L. K. Schubert and C. H. Hwang, </author> <title> "An Episodic Knowledge Representation for Narrative Texts," </title> <type> Technical Report 345, </type> <institution> Department of Computer Science, University of Rochester, </institution> <year> 1990. </year>
Reference-contexts: In this report, I will discuss the preliminary design of a lexicon system that can make such educated guesses. This system will utilize the knowledge representation language Episodic Logic <ref> [Schubert and Hwang, 1990] </ref> and will be a module of the TRAINS system [Allen and Schubert, 1991]. In Figure 1, the placement of the lexicon system within a natural language processing system such as TRAINS is illustrated.
Reference: [Selkirk, 1982] <author> E.O. Selkirk, </author> <title> The Syntax of Words, </title> <publisher> MIT Press, </publisher> <year> 1982. </year>
Reference-contexts: They are not "on line"." For our purposes, Aronoff 's WFR's do not differ substantially from Jackendoff 's redundancy rules. Before summarizing the above work, let us review a group of works ([Siegel, 1974], <ref> [Selkirk, 1982] </ref>, and [Lieber, 1980]) which concentrate more on the phonological aspects of word formation.
Reference: [Siegel, 1974] <author> D. Siegel, </author> <title> Topics in English Morphology, </title> <type> PhD thesis, </type> <institution> MIT, </institution> <year> 1974. </year>
Reference: [Sproat, 1985] <author> R. Sproat, </author> <title> On Deriving the Lexicon, </title> <type> PhD thesis, </type> <institution> MIT, </institution> <year> 1985. </year> <month> 41 </month>
Reference-contexts: In short, a more general correspondence between process and meaning seems to exist where the process might involve multiple sound units. 12 A number of conflicts between the constraints of the morphosyntactic and the morphosemantic have been noted in the liturature <ref> [Pesetsky, 1985; Sproat, 1985] </ref>. These conflicts are called bracketing paradoxes. In [Light, 1991], I argue that the supposed bracketing paradoxes dissolve when the relevant constraints are refined.
Reference: [Sproat, 1988] <author> R. Sproat, </author> <title> "On Anaphoric Islandhood," </title> <editor> in Michael Hammond and Michael Noonan, editors, </editor> <title> Theoretical Morphology: Approaches in Modern Linguistics. </title> <publisher> Academic Press, </publisher> <year> 1988. </year>
Reference-contexts: So the relation between decide and decision is to be represented solely in the lexicon. I call the lexicalist hypothesis a suggestion since it seems to be a purely theory internal entity. It is very difficult to bring empirical data to bear directly on the question of its correctness <ref> [Sproat, 1988] </ref>. 4 Jackendoff [1975], assuming the lexicalist hypothesis, proposed a lexicon whose basic unit is a lexeme. A lexeme corresponds intuitively to an entry in a printed dictionary. Such an approach can be contrasted with a morpheme-based system where the basic unit is a morpheme.
Reference: [Sproat, 1992] <author> R. Sproat, </author> <title> Morphology and Computation, </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Byrd's work [Byrd, 1983] combines parsing and segmentation into a single process based on Aronoff's conception of word formation rules. For an insightful review of the literature on segmentation and parsing see <ref> [Sproat, 1992] </ref>. Storage Schemes A body of work concerned with storing both regular and irregular morphological information has developed out of unification-based approaches to computational linguistics [Flickinger et al., 1985; Pollard and Sag, 1987; Russell et al., 1991; Flickinger, 1987; Flickinger and Nerbonne, 1991; Evans and Gazdar, 1990].
Reference: [Vendler, 1967] <editor> Zeno Vendler, </editor> <booktitle> Linguistics in Philosophy, </booktitle> <publisher> Cornell University Press, </publisher> <address> Ithaca, New York, </address> <year> 1967. </year> <month> 42 </month>
Reference-contexts: and possible) situations where they have a determinate truth value. 21 Here and throughout this report, I provide an English description of the basic ideas of the given MP that are relevant to the current discussion. 22 Here and throughout this report I use the aspectual classification of verbs of <ref> [Vendler, 1967] </ref>. The crucial aspect of this classification is the partitioning of verbs into telic and non-telic verbs. A telic verb is roughly a verb that encodes the culmination or endpoint of the action it describes. <p> modifier rstate which, when applied to a telic predicate, returns its result state. (31) For V 0 a dyadic telic predicate: (8x,y,e [[[x V 0 y]flfle] -&gt; (9e1: [[e1 at-end-of e] & [e cause e1]] [[y (rstate V 0 )]flfle1])]) 27 I will use the aspectual classification of verbs of <ref> [Vendler, 1967] </ref>. 28 A verb must be telic to have reform. However, being telic is not sufficient. Slap is an example of a telic verb that does not have a reform (i.e. *Mary reslapped John). Another example is put: *John reput the book on the table.
References-found: 53

