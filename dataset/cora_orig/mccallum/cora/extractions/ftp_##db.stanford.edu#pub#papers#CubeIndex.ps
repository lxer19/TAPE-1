URL: ftp://db.stanford.edu/pub/papers/CubeIndex.ps
Refering-URL: http://www.cs.toronto.edu/~mendel/dwbib.html
Root-URL: 
Email: ullmang@db.stanford.edu.  
Title: Index Selection for OLAP  
Author: Himanshu Gupta Venky Harinarayan Anand Rajaraman Jeffrey D. Ullman fhgupta, venky, anand, V. Harinarayan and A. Rajaraman: Jun-glee 
Note: This work was supported by NSF grant IRI-92-23405, ARO grant DAAH04-95-1-0192, and Air Force Contract F33615-93-1-1339. Present address of  
Address: Stanford CA 94305  Palo Alto, CA.  
Affiliation: Department of Computer Science Stanford University  Corp.,  
Abstract: On-line analytical processing (OLAP) is a recent and important application of database systems. Typically, OLAP data is presented as a multidimensional "data cube." OLAP queries are complex and can take many hours or even days to run, if executed directly on the raw data. The most common method of reducing execution time is to precompute some of the queries into summary tables (subcubes of the data cube) and then to build indexes on these summary tables. In most commercial OLAP systems today, the summary tables that are to be precomputed are picked first, followed by the selection of the appropriate indexes on them. A trial-and-error approach is used to divide the space available between the summary tables and the indexes. This two-step process can perform very poorly. Since both summary tables and indexes consume the same resource |space | their selection should be done together for the most efficient use of space. In this paper, we give algorithms that automate the selection of summary tables and indexes. In particular, we present a family of algorithms of increasing time complexities, and prove strong performance bounds for them. The algorithms with higher complexities have better performance bounds. However, the increase in the performance bound is diminishing, and we show that an algorithm of moderate complexity can perform fairly close to the optimal. 
Abstract-found: 1
Intro-found: 1
Reference: [ADS96] <institution> Archer Decision Sciences. </institution> <note> Star Schema 101. White Paper. Available at URL http://members.aol.com/nraden/str101.htm. </note>
Reference-contexts: When we abbreviate the dimensions, we just concatenate the abbreviations in specifying the subcubes | the subcube above could also be written as pc. Note that the order of the dimensions is irrelevant. In practice too, such a partitioning scheme is common. The popular "snowflake schema" <ref> [ADS96] </ref> is an example of this partitioning scheme.
Reference: [GBLP95] <author> J. Gray, A. Bosworth, A. Layman, H. Pi-rahesh. </author> <title> Data Cube: A Relational Aggregation Operator Generalizing Group-By, Cross-Tab, and Sub-Totals. </title> <type> Microsoft Technical Report No. </type> <institution> MSR-TR-95-22. </institution>
Reference-contexts: This interactive decision-support process is called OLAP (On-line Analytical Processing) to distinguish it from conventional OLTP (On-line Transaction Processing) applications. OLAP applications require viewing the data from many different business perspectives (dimensions). Data cube <ref> [GBLP95] </ref> is a multidimensional view of a databases where a critical value, e.g., sales, is organized by several dimensions, for example, sales of automobiles organized by model, color, day of sale and so on. The metric of interest is called the measure attribute, which is sales in the example. <p> Each cell of the data cube corresponds to a unique set of values for the different dimensions and contains the value of the measure for this set of values. As mentioned in <ref> [GBLP95] </ref>, the domain of each dimension is augmented with the special value "ALL." In order to present this multidimensional view, the data is usually stored in the form of "summary tables" corresponding to the subcubes of the data cube. 1 In [HRU96], the efficient implementation of "data 1 This approach of <p> Our conclusion is that we can, with small degradation of performance compared with the no-index case considered in [HRU96], incorporate indexes into the framework of data cube design. 1.1 Related Work Gray et al. in <ref> [GBLP95] </ref> introduce the data cube operator as a generalization of the SQL groupby operator. The key to this generalization is the introduction of the "ALL" keyword. In many commercial systems, subcubes of this data cube are precomputed to improve performance.
Reference: [G97] <author> H. Gupta. </author> <title> Selection of Views to Materialize in a Data Warehouse. </title> <note> To appear in ICDT, </note> <month> January, </month> <year> 1997, </year> <title> Delphi, </title> <address> Greece. </address>
Reference-contexts: In many commercial systems, subcubes of this data cube are precomputed to improve performance. In [HRU96], Harinarayan et al. look into the problem of determining which subcubes to precom-pute. They give a simple greedy algorithm to select subcubes, and prove a strong performance guarantee for the algorithm. Gupta <ref> [G97] </ref> develops a framework for the general problem of selecting views to materialize in a datawarehouse. Johnson and Shasha in [JS96] introduce a new index structure that reduces the number of index accesses in data cube queries.
Reference: [HNSS95] <author> P. J. Haas, J. F. Naughton, S. Seshadri, L. </author> <title> Stokes. Sampling-Based Estimation of the Number of Distinct Values of an Attribute. </title> <booktitle> In Proceedings of the 21st International VLDB Conference, </booktitle> <pages> pages 311-320, </pages> <year> 1995. </year>
Reference-contexts: Thus for example, the size of the view that groups by part and supplier is the number of distinct values of part,supplier in the raw data. There are many well-known sampling techniques that we can use to determine the number of distinct values of attributes in a relation <ref> [HNSS95] </ref>. 4.2.2 Estimating Index Sizes Given the view sizes, we can estimate index sizes. The size of each view in our cost model is the number of rows in the view. For indexes too, we follow a similar model to estimate the space cost.
Reference: [HRU96] <author> V. Harinarayan, A. Rajaraman, and J. D. Ullman. </author> <title> Implementing Data Cubes Efficiently. </title> <booktitle> ACM SIGMOD 1996, </booktitle> <pages> pages 205-216, </pages> <year> 1996. </year>
Reference-contexts: As mentioned in [GBLP95], the domain of each dimension is augmented with the special value "ALL." In order to present this multidimensional view, the data is usually stored in the form of "summary tables" corresponding to the subcubes of the data cube. 1 In <ref> [HRU96] </ref>, the efficient implementation of "data 1 This approach of storing a data cube is known as ROLAP (Relational OLAP). The other approach in which the data cube is stored as a multidimensional array is known as MD-OLAP. <p> Our conclusion is that we can, with small degradation of performance compared with the no-index case considered in <ref> [HRU96] </ref>, incorporate indexes into the framework of data cube design. 1.1 Related Work Gray et al. in [GBLP95] introduce the data cube operator as a generalization of the SQL groupby operator. The key to this generalization is the introduction of the "ALL" keyword. <p> The key to this generalization is the introduction of the "ALL" keyword. In many commercial systems, subcubes of this data cube are precomputed to improve performance. In <ref> [HRU96] </ref>, Harinarayan et al. look into the problem of determining which subcubes to precom-pute. They give a simple greedy algorithm to select subcubes, and prove a strong performance guarantee for the algorithm. Gupta [G97] develops a framework for the general problem of selecting views to materialize in a datawarehouse. <p> An important problem is dividing the space available between the subcubes and the indexes. One possibility is dividing the space available equally between the sub-cubes and indexes. In this example, we use a greedy algorithm as given in <ref> [HRU96] </ref> to pick the best sub-cubes and indexes in each step. <p> Thus any available space which is less than the size of the entire data cube is wasted. It is important that we strike a balance between these two extremes. A commonly used ROLAP partitioning scheme <ref> [HRU96] </ref>, is to associate a subcube with every element of the power set of the set of dimensions, as was mentioned in Section 2. The subcubes when specified in SQL differ only in the groupby clause. <p> In this paper, we choose the simplest possible cost model: * The cost of answering Q is the number of rows of the table for V that must be processed to construct the result of Q. This "linear cost model" was presented in <ref> [HRU96] </ref> and is also used in the MetaCube product [STG95]. Let Q be a slice query such that Q t V , and consider answering Q using V . <p> Proof: The proof is almost identical to the proof of Theorem 5.1. The only difference is that in the case of Inner-level greedy algorithm the value of k 0 is 0.63 and is independent of the sizes of the views and indexes. This follows from the result in <ref> [HRU96] </ref> on the performance guarantee of the simple greedy algorithm under space constraint. As the value of k 0 is independent of the relative sizes of structures, the result holds for arbitrary sizes of views and indexes. 6 Performance of the Algorithms family of r-greedy algorithms against r. <p> Thus Inner-greedy is preferable to 2-greedy because it gives a better guarantee than 2-greedy for approximately the same running time. We experimented with the r-greedy family of algorithms on cubes of dimension up to 6, for r = 1; 2; 3. We generated cubes using the analytical model in <ref> [HRU96] </ref>, extended to incorporate indexes and slice queries.
Reference: [JS96] <author> T. Johnson and D. Shasha. </author> <title> Hierarchically Split Cube Forests for Decision Support: description and tuned design. </title> <type> Personal Communication. </type>
Reference-contexts: They give a simple greedy algorithm to select subcubes, and prove a strong performance guarantee for the algorithm. Gupta [G97] develops a framework for the general problem of selecting views to materialize in a datawarehouse. Johnson and Shasha in <ref> [JS96] </ref> introduce a new index structure that reduces the number of index accesses in data cube queries. The issue of what indexes to build has not been investigated before from a research perspective. A two-step process | picking subcubes first, followed by the indexes | is typically adopted [MS95]. <p> If the view V is ( C), the exactly the set of indexes is fI ~ D (V ) j ~ D is a permutation of Cg. This result is similar to that in <ref> [JS96] </ref>, where they consider only fat indexes.
Reference: [MS95] <author> Microstrategy Inc. </author> <title> The Case for Relational OLAP. </title> <note> White Paper. Available at http://www.strategy.com. </note>
Reference-contexts: The issue of what indexes to build has not been investigated before from a research perspective. A two-step process | picking subcubes first, followed by the indexes | is typically adopted <ref> [MS95] </ref>. An ad hoc approach is used in dividing the space and in picking indexes. For example, [MS95] builds indexes on the most frequently used dimensions. <p> The issue of what indexes to build has not been investigated before from a research perspective. A two-step process | picking subcubes first, followed by the indexes | is typically adopted <ref> [MS95] </ref>. An ad hoc approach is used in dividing the space and in picking indexes. For example, [MS95] builds indexes on the most frequently used dimensions. This paper is the first to explore the index-selection problem and automate it with provably near-optimal algorithms. 1.2 Paper Organization The rest of the paper is organized as follows. <p> In most practical situations there is not enough space (or equivalently load time) to pre-compute everything. For this example, assume that we have around 25M rows worth of space available. The Two-Step Approach. The two-step process <ref> [MS95] </ref> would divide this available space between subcubes and indexes.
Reference: [TPCD95] <author> F. Raab, </author> <title> editor. TPC Benchmark(tm) D (Decision Support), Proposed Revision 1.0. Transaction Processing Performance Council, </title> <address> San Jose, CA 95112, </address> <month> 4 April </month> <year> 1995. </year>
Reference-contexts: The cost model is introduced in Section 4. We present the algorithms along with the analysis of their performance guarantees in the following section. Experimental results are stated in Section 6. Finally, we present our conclusions in Section 7. 2 Motivating Examples We use an example taken from TPC-D <ref> [TPCD95] </ref>, a decision-support benchmark to motivate the index-selection problem. The example illustrates the complexity of this problem, and the difficulty of doing the selection well in the two-step selection process.
Reference: [STG95] <institution> Stanford Technology Group, Inc. </institution> <note> Designing the Data Warehouse On Relational Databases. White Paper. </note>
Reference-contexts: This "linear cost model" was presented in [HRU96] and is also used in the MetaCube product <ref> [STG95] </ref>. Let Q be a slice query such that Q t V , and consider answering Q using V . For example, suppose Q is a query about the sales of a single part "widget," and V is the view part, supplier. That is, Q = fl none p .
References-found: 9

