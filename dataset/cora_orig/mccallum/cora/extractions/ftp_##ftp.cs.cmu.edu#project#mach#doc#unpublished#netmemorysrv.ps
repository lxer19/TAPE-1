URL: ftp://ftp.cs.cmu.edu/project/mach/doc/unpublished/netmemorysrv.ps
Refering-URL: http://c.gp.cs.cmu.edu:5103/afs/cs/project/mach/public/www/doc/publications.html
Root-URL: 
Title: Design, Implementation, and Performance Evaluation of a Distributed Shared Memory Server for Mach  
Author: Alessandro Forin, Joseph Barrera, Michael Young, Richard Rashid Alessandro Forin, Joseph Barrera, Michael Young, Richard Rashid 
Note: Copyright 1988  
Address: Pittsburgh, PA 15213  
Affiliation: Computer Science Department Carnegie-Mellon University  
Date: August 1988  
Pubnum: CMU-CS-88-165  
Abstract: A shorter version of this report will appear in the 1988 Winter USENIX conference, San Diego, January 1989 This research was sponsored by the Defense Advanced Research Projects Agency (DOD), Arpa Order No. 4864, monitored by the Space and Naval Warfare Systems Command under contract number N00039-87-C-0251. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Defense Advanced Research Projects Agency or the US Government. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Arnould, E. A., Bitz, F. J., Cooper, E. C., Kung, H. T., Sansom, R. D., Steenkiste, P. A. </author> <title> The Design of Nectar: A Network Backplane for Heterogeneous Multicomputers. April, </title> <booktitle> 1989. To appear in the Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-III). </booktitle>
Reference-contexts: More motivation for a distributed shared memory facility comes from the increasing interest that hardware designers show in non-shared memory multiprocessors: the Nectar project <ref> [1] </ref> at CMU for instance uses fast fiber optic links. This will reduce the end-to-end time to send a 1 kilobyte data packet from the tens of milliseconds range of the current ethernet to the tens of microseconds range of the fiber.
Reference: [2] <author> Bisiani, R. and Forin, A. </author> <title> Multilanguage Parallel Programming of Heterogeneous Machines. </title> <journal> IEEE Transactions on Computers , August, </journal> <year> 1988. </year>
Reference-contexts: Example uses of a distributed shared memory facility include operating system services such as file systems and process migration, distributed databases, parallel languages like Ada or Multilisp, and systems for parallel and distributed programming <ref> [11, 2, 10] </ref>. More motivation for a distributed shared memory facility comes from the increasing interest that hardware designers show in non-shared memory multiprocessors: the Nectar project [1] at CMU for instance uses fast fiber optic links. <p> Only a few processors implement some form of data tagging in hardware. Solving the heterogeneity problem is difficult because it requires that the server has knowledge of the application's data types. This leads to undesirable close links with the application's runtime system and programming language <ref> [2] </ref>. On the other hand, the problem can be separated in two sub-problems: hardware data types (e.g. integers) and software data types (e.g. C records). A general purpose server solves the problems for the first class of types, and can be extended to cope with the second class of types. <p> Our work is concerned with Operating System level distributed shared memory, where it is implemented as shared pages of virtual memory. Other approaches to user-level shared memory objects are possible, for example providing shared data structures as in the Agora <ref> [2] </ref> system. Other references can be found in [2]. 7. Performance Evaluation The performance of the server was evaluated along a number of dimensions. Fundamental are the average times to service a fault, in both cases of single machine and multi-machine applications. <p> Our work is concerned with Operating System level distributed shared memory, where it is implemented as shared pages of virtual memory. Other approaches to user-level shared memory objects are possible, for example providing shared data structures as in the Agora <ref> [2] </ref> system. Other references can be found in [2]. 7. Performance Evaluation The performance of the server was evaluated along a number of dimensions. Fundamental are the average times to service a fault, in both cases of single machine and multi-machine applications. These are affected by the various special features of the server.
Reference: [3] <author> Cheriton, D. </author> <title> Unified Management of Memory and File Caching Using the V Virtual Memory System. </title> <type> Tech. Report STAN-CS-88-1192, </type> <institution> Stanford University, Computer Science Department, </institution> <year> 1988. </year>
Reference-contexts: In this paper it was only assumed that the underlying architecture provides efficient point-to-point communication, with quasi-uniform cost. The cost of sending a message to N recipients is therefore greater than or equal to N times the cost of a message to a single recipient. Cheriton <ref> [3] </ref> has recently extended the V kernel to support user-level data and caching servers, which can be used to provide distributed shared memory. His facility has many similarities with Mach's external pager facility, although it is described in terms of file abstractions rather than memory object abstractions.
Reference: [4] <author> Fleisch, B. D. </author> <title> Distributed Shared Memory in a Loosely Coupled Distributed System. </title> <booktitle> In Compcon Spring 1988. IEEE, </booktitle> <address> San Francisco, CA, </address> <month> February, </month> <year> 1988. </year>
Reference-contexts: The implementation uses a scheme analogous to the simple scheduler presented above, but might add considerable extra message traffic by polling and forcing page flushes every T-milliseconds to provide T-consistent files for transaction support. Fleisch <ref> [4] </ref> has extended the Locus kernel to provide distributed shared memory, with a SystemV interface. The scheme he describes seems geared to maintaining consistency at the segment rather than page level. A report on the implementation work will be necessary to better evaluate his approach.
Reference: [5] <author> Forin, A., Bisiani, R., Correrini, F. </author> <title> Parallel Processing with Agora. </title> <type> Tech. Report CMU-CS-87-183, </type> <institution> Carnegie-Mellon University, Computer Science Department, </institution> <month> December, </month> <year> 1987. </year>
Reference-contexts: A dynamic solution 8 requires the use of runtime type descriptors that the server uses for data translation. This approach is described in <ref> [5] </ref>, and solves the problem of software data types as well. It is certainly possible to extend our server in this way. Finally, note that an approach similar to the one used for data translation might be used for other problems.
Reference: [6] <author> Johnson, </author> <title> D.B. Efficient Algorithms For Shortest Path Is Sparse Networks. </title> <journal> JACM 24(1) </journal> <pages> 1-13, </pages> <month> January, </month> <year> 1977. </year>
Reference-contexts: In this way it is easy to compute large matrices with few processors. The Shortest Path program is a parallel version of a sequential algorithm which shows Nlog (N) complexity for planar graphs <ref> [6] </ref>. The program evaluates in parallel the possible extensions to the most promising paths, and each activity only looks in the neighborhood of a point and queues the new extensions to other activities.
Reference: [7] <author> Kai Li. </author> <title> Shared Virtual Memory on Loosely Coupled Multiprocessors. </title> <type> PhD thesis, </type> <institution> Yale, </institution> <month> September, </month> <year> 1986. </year>
Reference-contexts: The overhead of a fault tolerance guard can therefore be quite limited, about 1% of our servers' time when heavily used. 12 6. Related Work Forwarding creates a new need: the need of forwarding page faults to the current owner of a page. Li <ref> [7] </ref> looked at the problem of locating a page and provided various algorithms to solve it, and analyzed their costs. Our distributed algorithm must be compared against the "Distributed Manager Algorithm 2.6", with the optimizations indicated at pages 61-63 that page invalidations are sent in a divide-and-conquer fashion.
Reference: [8] <author> McDonald, </author> <note> J. </note>
Reference-contexts: The other two programs have been used for architectural simulations, on the assumption that they are representatives of a large class of parallel programs. Mp3d is a particle simulator <ref> [8] </ref> and LocusRoute is a parallel VLSI router [9]. 16 The experiments were performed on machines under standard multi-user operating conditions, including any necessary disk paging. Measures were taken of elapsed and per-thread CPU times.
References-found: 8

