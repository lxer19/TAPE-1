URL: ftp://ftp.mbfys.kun.nl/snn/pub/reports/Heskes.icml.ps.Z
Refering-URL: http://www.cs.wisc.edu/icml98/schedule.html
Root-URL: 
Email: tom@mbfys.kun.nl  
Title: Solving a huge number of similar tasks: a combination of multi-task learning and a hierarchical
Author: Tom Heskes 
Note: To appear in Proceedings of the  
Address: Geert Grooteplein 21, 6525 EZ Nijmegen, The Netherlands  ICML-98, Madison, Wisconsin.  
Affiliation: Foundation for Neural Networks  
Abstract: In this paper, we propose a machine-learning solution to problems consisting of many similar prediction tasks. Each of the individual tasks has a high risk of overfitting. We combine two types of knowledge transfer between tasks to reduce this risk: multi-task learning and hierarchical Bayesian modeling. Multi-task learning is based on the assumption that there exist features typical to the task at hand. To find these features, we train a huge two-layered neural network. Each task has its own output, but shares the weights from the input to the hidden units with all other tasks. In this way a relatively large set of possible explanatory variables (the network inputs) is reduced to a smaller and easier to handle set of features (the hidden units). Given this set of features and after an appropriate scale transformation, we assume that the tasks are exchangeable. This assumption allows for a hierarchical Bayesian analysis in which the hyperparameters can be estimated from the data. Effectively, these hyperpa-rameters act as regularizers and prevent over-fitting. We describe how to make the system robust against nonstationarities in the time series and give directions for further improvement. We illustrate our ideas on a database regarding the prediction of newspaper sales. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Baxter. </author> <title> A Bayesian/information theoretic model of learning to learn via multiple task sampling. </title> <journal> Machine Learning, </journal> <volume> 28 </volume> <pages> 7-39, </pages> <year> 1997. </year>
Reference-contexts: In <ref> [1] </ref> the advantage of combining several tasks is investigated theoretically, under the assumption that a feature matrix B common to all tasks indeed exists. In most approaches to multi-task learning (see e.g. [2] and references therein), all tasks receive the same input information, i.e., all inputs are nonspecific.
Reference: [2] <author> R. Caruana. </author> <title> Multitask learning. </title> <journal> Machine Learn ing, </journal> <volume> 28 </volume> <pages> 41-75, </pages> <year> 1997. </year>
Reference-contexts: In [1] the advantage of combining several tasks is investigated theoretically, under the assumption that a feature matrix B common to all tasks indeed exists. In most approaches to multi-task learning (see e.g. <ref> [2] </ref> and references therein), all tasks receive the same input information, i.e., all inputs are nonspecific. As in our case, the different tasks are forced to share the same hidden unit representation. Often, but not always, this leads to a better generalization performance [2]. <p> most approaches to multi-task learning (see e.g. <ref> [2] </ref> and references therein), all tasks receive the same input information, i.e., all inputs are nonspecific. As in our case, the different tasks are forced to share the same hidden unit representation. Often, but not always, this leads to a better generalization performance [2]. The problems considered in the literature are mostly artificial and combine on the order of 10 or less tasks. An exception is [7], where different tasks concerning stock selection and portfolio management are combined in various ways.
Reference: [3] <author> C. Chatfield. </author> <title> The Analysis of Time Series: an Introduction. </title> <publisher> Chapman & Hall, </publisher> <address> London, </address> <note> fourth edition, </note> <year> 1989. </year>
Reference-contexts: It seems reasonable to choose the same ff for all tasks. Furthermore, it is well-known (see e.g. <ref> [3] </ref>) that the precise setting of the smoothing parameter in exponential smoothing hardly affects the prediction performance (see also Figure 4).
Reference: [4] <author> B. Efron and C. Morris. </author> <title> Data analysis using Stein's estimator and its generalizations. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 70 </volume> <pages> 311-319, </pages> <year> 1975. </year>
Reference-contexts: Our approach is quite similar in spirit to the use of empirical Bayesian techniques in law school validity studies, described and discussed in [9]. James-Stein estimation can be viewed as the frequentists' equivalent of hierarchical Bayesian modeling. A nice link is provided in <ref> [4] </ref>. In the neural-network community, hierarchical Bayes is often referred to as the evidence framework [8].
Reference: [5] <author> J. de Freitas, M. Niranjan, and A. Gee. </author> <title> Regular isation in sequential learning algorithms. </title> <booktitle> In Advances in Neural Information Processing Systems 10, </booktitle> <address> Cambridge, 1998. </address> <publisher> MIT Press. </publisher>
Reference-contexts: About integrating nonstationarity and the Bayesian hierarchical analysis, we may be somewhat more positive. There has been some recent work, which can be viewed as a first attempt to combine Kalman filtering and the Bayesian evidence framework <ref> [5] </ref>. In this approach the hyperparameters are recomputed every time step. Similar ideas may be applicable to our multi-task situation, although also here we have to worry about the computational feasibility.
Reference: [6] <author> A. Gelman, J. Carlin, H. Stern, and D. Rubin. </author> <title> Bayesian data analysis. </title> <publisher> Chapman & Hall, </publisher> <address> Lon-don, </address> <year> 1995. </year>
Reference-contexts: fl MP is in fact equivalent to the set of maximum likelihood hyperparameters fl ML . 3.2 RELEVANT LITERATURE A nice overview of hierarchical (also called empirical) Bayesian modeling, with both a discussion of its underlying assumptions and lots of references to its applications in statistics, can be found in <ref> [6] </ref>. Our approach is quite similar in spirit to the use of empirical Bayesian techniques in law school validity studies, described and discussed in [9]. James-Stein estimation can be viewed as the frequentists' equivalent of hierarchical Bayesian modeling. A nice link is provided in [4]. <p> One way of doing this is through an EM algorithm (see e.g. <ref> [6] </ref>). The multi-task situation allows for quite a lot of simplifications, which in the end lead to update equations for fl (n). <p> The second term on the righthand side measures the variance between the most probable solutions [given fl (n)] for the different tasks, the first term the variance of P (AjD i ; fl (n)) around these most probable solutions, averaged over all tasks. We can use Laplace's method (see <ref> [6] </ref>), based on a quadratic Taylor expansion of log P (AjD i ; fl (n)) around its mode, to find approximations for A i (n) and 2 i (n): A i (n) argmax A and 2 where the Hessian matrix H i (n) of the error E (AjD i ) has
Reference: [7] <author> J. Ghosn and Y. Bengio. </author> <title> Multi-task learning for stock selection. </title> <editor> In M. Mozer, M. Jordan, and T. Petsche, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 9, </booktitle> <pages> pages 946-952, </pages> <address> Cam-bridge, 1997. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Often, but not always, this leads to a better generalization performance [2]. The problems considered in the literature are mostly artificial and combine on the order of 10 or less tasks. An exception is <ref> [7] </ref>, where different tasks concerning stock selection and portfolio management are combined in various ways. This experimental study is probably closest in spirit to our multi-tasking approach, but its number of tasks (36) is still much smaller than the 343 real-world tasks that we use in our simulation.
Reference: [8] <author> D. MacKay. </author> <title> Bayesian interpolation. </title> <journal> Neural Com putation, </journal> <volume> 4 </volume> <pages> 415-447, </pages> <year> 1992. </year>
Reference-contexts: James-Stein estimation can be viewed as the frequentists' equivalent of hierarchical Bayesian modeling. A nice link is provided in [4]. In the neural-network community, hierarchical Bayes is often referred to as the evidence framework <ref> [8] </ref>. The focus is on learning a single task, where the prior distribution of the weights (usually a diagonal matrix and m equal to zero) is chosen to reflect the belief that weights should be small. This yields the Bayesian justification for weight decay or ridge regression. <p> This is the approximation frequently applied in the evidence framework for neural networks (see e.g. <ref> [8] </ref>).
Reference: [9] <author> D. Rubin. </author> <title> Using empirical Bayesian techniques in the law school validity studies (with discussion). </title> <journal> Journal of the American Statistical Association, </journal> <volume> 75 </volume> <pages> 801-827, </pages> <year> 1980. </year>
Reference-contexts: Our approach is quite similar in spirit to the use of empirical Bayesian techniques in law school validity studies, described and discussed in <ref> [9] </ref>. James-Stein estimation can be viewed as the frequentists' equivalent of hierarchical Bayesian modeling. A nice link is provided in [4]. In the neural-network community, hierarchical Bayes is often referred to as the evidence framework [8].
Reference: [10] <author> S. Thrun and L. Pratt, </author> <title> editors. Machine Learn ing. </title> <booktitle> Second Special Issue on Inductive Transfer, </booktitle> <address> Dordrecht, 1997. </address> <publisher> Kluwer Academic. </publisher>
Reference-contexts: averaged over all n tasks tasks and obtain the maximum likelihood solutions B ML , A ML i i . 2.2 SIMILAR IDEAS There has been quite a lot of interesting research in the area of inductive transfer, yielding both empirical and theoretical evidence that multi-task learning improves performance (see <ref> [10] </ref> for collections of papers on multi-task learning). In [1] the advantage of combining several tasks is investigated theoretically, under the assumption that a feature matrix B common to all tasks indeed exists.
References-found: 10

