URL: http://www.cs.duke.edu/~jsv/Papers/ViN93.hierarchies.ps.gz
Refering-URL: http://www.cs.duke.edu/~jsv/Papers/catalog/node6.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Large-Scale Sorting in Uniform Memory Hierarchies  
Author: Jeffrey Scott Vitter and Mark H. Nodine 
Date: December 19, 1991  
Address: Providence, R. I. 02912-1910  
Affiliation: Dept. of Computer Science Brown University  
Abstract: We present several efficient algorithms for sorting on the uniform memory hierarchy (UMH), introduced by Alpern, Carter, and Feig, and its paral-lelization P-UMH. We give optimal and nearly-optimal algorithms for a wide range of bandwidth degradations, including a parsimonious algorithm for constant bandwidth. We also develop optimal sorting algorithms for all bandwidths for other versions of UMH and P-UMH, including natural restrictions we introduce called RUMH and P-RUMH, which more closely correspond to current programming languages. 
Abstract-found: 1
Intro-found: 1
Reference: [AAC] <author> A. Aggarwal, B. Alpern, A. K. Chandra, and M. Snir, </author> <title> "A Model for Hierarchical Memory," </title> <booktitle> Proceedings of 19th Annual ACM Symposium on Theory of Computing (May 1987), </booktitle> <pages> 305-314. </pages> <address> 12 4 CONCLUSIONS </address>
Reference-contexts: Several interesting and elegant hierarchical memory models have been proposed recently to model the many levels of memory typically found in large-scale computer systems. The HMM model of Aggarwal, Alpern, Chandra, and Snir <ref> [AAC] </ref> allows access to individual location x in time f (x). <p> Optimal sorting algorithms for each of these models have been developed <ref> [AAC, ACSa, LuP] </ref>. In this paper we concentrate on a newer hierarchical memory model introduced by Alpern, Carter, and Feig [ACF, ACSb], called the uniform memory hierarchy (UMH), which offers an alternative model of blocked multilevel memories. <p> Vitter and Shriver introduced optimal randomized sorting algorithms for P-HMM and P-BT [ViSa]. The algorithms were based on their randomized two-level partitioning technique applied to the optimal single-hierarchy algorithms for HMM and BT developed in <ref> [AAC, ACSa] </ref>. <p> Theorems 5 and 6 in [ViSa]); accordingly the upper and lower bounds combine in an interesting way several techniques from <ref> [AAC, ACSa, AgV, ViSa] </ref>. Theorem 3 The running times mentioned in Theorem 2 are matching upper and lower bounds for sorting in P-RUMH. The algorithms for nonconstant P for the first two bandwidth cases are randomized.
Reference: [ACSa] <author> A. Aggarwal, A. Chandra, and M. Snir, </author> <title> "Hierarchical Memory with Block Transfer," </title> <booktitle> Proceedings of 28th Annual IEEE Symposium on Foundations of Computer Science (October 1987), </booktitle> <pages> 204-216. </pages>
Reference-contexts: The HMM model of Aggarwal, Alpern, Chandra, and Snir [AAC] allows access to individual location x in time f (x). The BT model of Aggarwal, Chandra, and Snir <ref> [ACSa] </ref> represents a notion of block transfer applied to HMM; in the BT model, access to the t + 1 records at locations x t, x t + 1, . . . , x takes time f (x) + t. <p> Optimal sorting algorithms for each of these models have been developed <ref> [AAC, ACSa, LuP] </ref>. In this paper we concentrate on a newer hierarchical memory model introduced by Alpern, Carter, and Feig [ACF, ACSb], called the uniform memory hierarchy (UMH), which offers an alternative model of blocked multilevel memories. <p> Vitter and Shriver introduced optimal randomized sorting algorithms for P-HMM and P-BT [ViSa]. The algorithms were based on their randomized two-level partitioning technique applied to the optimal single-hierarchy algorithms for HMM and BT developed in <ref> [AAC, ACSa] </ref>. <p> Theorems 5 and 6 in [ViSa]); accordingly the upper and lower bounds combine in an interesting way several techniques from <ref> [AAC, ACSa, AgV, ViSa] </ref>. Theorem 3 The running times mentioned in Theorem 2 are matching upper and lower bounds for sorting in P-RUMH. The algorithms for nonconstant P for the first two bandwidth cases are randomized.
Reference: [AgV] <author> A. Aggarwal and J. S. Vitter, </author> <title> "The Input/Output Complexity of Sorting and Related Problems," </title> <journal> Communications of the ACM (September 1988), </journal> <pages> 1116-1127, </pages> <booktitle> also appears in Proceedings of 14th Annual International Colloquium on Automata, Languages, and Programming (ICALP), </booktitle> <publisher> LNCS 267, Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1987. </year>
Reference-contexts: Recently other authors announced an efficient UMH sorting algorithm for the case b (`) = 1=(` + 1), based on the optimal two-level distribution sort algorithm of <ref> [AgV] </ref>, but their UMH 1=(`+1) algorithm turned out to be inefficient, with a running time of (N log c N ), for c &gt; 3. Whether or not an O (N log N )-time UMH 1=(`+1) algorithm exists is still open. <p> Theorems 5 and 6 in [ViSa]); accordingly the upper and lower bounds combine in an interesting way several techniques from <ref> [AAC, ACSa, AgV, ViSa] </ref>. Theorem 3 The running times mentioned in Theorem 2 are matching upper and lower bounds for sorting in P-RUMH. The algorithms for nonconstant P for the first two bandwidth cases are randomized. <p> The sequential time can be at most P times the P-SUMH running time. We superimpose on the P-SUMH model a sequence of one-disk, two-level memories of the type studied in <ref> [AgV, ViSb] </ref>, in the following way: For 1 ` 1 2 log (N=ffP ), the `th two-level memory has one disk, internal memory size M ` = P ff ( 2 (`+1) 1)=( 2 1), and block size B ` = ` . <p> The minimum number of I/Os required for sorting in the `th two-level memory is @ N log N log M ` B ` A ; as shown in <ref> [AgV] </ref>. Each such I/O contributes C i to the sequential time in the P SUMH model, since in the P-SUMH model only one level can be active at a time in each hierarchy.
Reference: [Akl] <author> S. G. Akl, </author> <title> Parallel Sorting Algorithms, </title> <booktitle> Notes and Reports in Computer Science and Applied Mathematics #12, </booktitle> <publisher> Academic Press, Inc., </publisher> <address> Orlando, </address> <year> 1985. </year>
Reference-contexts: The fastest oblivious algorithm we have found for sorting in UMH 1=(`+1) is based on a simple schedule of Batcher's bitonic sort <ref> [Akl] </ref> where each of the log 2 N parallel time steps is implemented in O (N log N ) time for an overall running time of O (N log 3 N ).
Reference: [ACF] <author> B. Alpern, L. Carter, and E. Feig, </author> <title> "Uniform Memory Hierarchies," </title> <booktitle> Proceedings of the 31st Annual IEEE Symposium on Foundations of Computer Science (October 1990), </booktitle> <pages> 600-608. </pages>
Reference-contexts: Optimal sorting algorithms for each of these models have been developed [AAC, ACSa, LuP]. In this paper we concentrate on a newer hierarchical memory model introduced by Alpern, Carter, and Feig <ref> [ACF, ACSb] </ref>, called the uniform memory hierarchy (UMH), which offers an alternative model of blocked multilevel memories. <p> We can consider parallel UMH hierarchies (analogous to P-HMM and P-BT), and we call the resulting model P-UMH. (This is fundamentally different from the parallel type of UMH called UPHM mentioned in <ref> [ACF] </ref>.) The initial input of N elements resides at level s = d 1 2 log ffP e. A UMH or P-UMH "program" consists of a schedule of choreographed block transfers and computations. <p> For the special case of constant bandwidth, we present a parsimonious algorithm. Since optimal sorting seems to require nonoblivious UMH programs, the oblivious UMH model of <ref> [ACF] </ref> must be modified in a reasonable way. In Theorem 1, we assume that the `th level of the hierarchy can initiate a transfer from the (` + 1)st level without involving the CPU when one of its blocks becomes empty. <p> An earlier version of <ref> [ACF] </ref> introduced a sequential UMH model, appropriately called SUMH, that allowed at most one bus to be active at a time. However, the SUMH restriction can be regarded as too severe, since it forfeits much power of the UMH model.
Reference: [ACSb] <author> B. Alpern, L. Carter, and T. Selker, </author> <title> "Visualizing Computer Memory Architectures," </title> <booktitle> Proceedings of the 1990 IEEE Visualization Conference Foundations of Computer Science (October 1990). </booktitle>
Reference-contexts: Optimal sorting algorithms for each of these models have been developed [AAC, ACSa, LuP]. In this paper we concentrate on a newer hierarchical memory model introduced by Alpern, Carter, and Feig <ref> [ACF, ACSb] </ref>, called the uniform memory hierarchy (UMH), which offers an alternative model of blocked multilevel memories.
Reference: [Lei] <author> T. Leighton, </author> <title> "Tight Bounds on the Complexity of Parallel Sorting," </title> <journal> IEEE Transactions on Computers C-34 (April 1985), </journal> <pages> 344-354, </pages> <booktitle> also appears in Proceedings of the 16th Annual ACM Symposium on Theory of Computing, </booktitle> <month> (April </month> <year> 1983), </year> <pages> 71-80. </pages>
Reference-contexts: It is also possible to schedule a recursive version of Columnsort <ref> [Lei] </ref> on UMH 1=(`+1) in a manner that is efficient with respective to the RAM algorithm, but this observation is not very useful since both algorithms have running time that is O (N log c N ), where c 3:4. 6 2 SORTING IN UMH AND ITS PARALLELIZATION 2.1 Parsimonious sorting
Reference: [LuP] <author> F. Luccio and L. Pagli, </author> <title> "A Model of Sequential Computation Based on a Pipelined Access to Memory," </title> <booktitle> Proceedings of the 27th Annual Allerton Conference on Communication, Control, and Computing (September 1989). </booktitle>
Reference-contexts: Typical access cost functions are f (x) = log x and f (x) = x ff , for some ff &gt; 0. 1 A model similar to the BT model that allows pipelined access to memory in O (log n) time was developed independently by Luccio and Pagli <ref> [LuP] </ref>. Optimal sorting algorithms for each of these models have been developed [AAC, ACSa, LuP]. In this paper we concentrate on a newer hierarchical memory model introduced by Alpern, Carter, and Feig [ACF, ACSb], called the uniform memory hierarchy (UMH), which offers an alternative model of blocked multilevel memories. <p> Optimal sorting algorithms for each of these models have been developed <ref> [AAC, ACSa, LuP] </ref>. In this paper we concentrate on a newer hierarchical memory model introduced by Alpern, Carter, and Feig [ACF, ACSb], called the uniform memory hierarchy (UMH), which offers an alternative model of blocked multilevel memories.
Reference: [ReV] <author> J. H. Reif and L. G. Valiant, </author> <title> "A Logarithmic Time Sort on Linear Size Networks," </title> <journal> Journal of the ACM 34 (January 1987), </journal> <pages> 60-76, </pages> <booktitle> also appears in Proceedings of the 15th Annual ACM Symposium on Theory of Computing (April 1983), </booktitle> <pages> 10-16. </pages>
Reference-contexts: Each level ` block can be randomly accessed and transferred to level ` + 1 at a bandwidth of b (`) (that is, in ` =b (`) time). in O (log P ) time (perhaps via a randomized algorithm <ref> [ReV] </ref>). Vitter and Shriver introduced optimal randomized sorting algorithms for P-HMM and P-BT [ViSa]. The algorithms were based on their randomized two-level partitioning technique applied to the optimal single-hierarchy algorithms for HMM and BT developed in [AAC, ACSa].
Reference: [ViSa] <author> J. S. Vitter and E. A. M. Shriver, </author> <title> "Optimal Disk I/O with Parallel Block Transfer," </title> <booktitle> Proceedings of the 22nd Annual ACM Symposium on Theory of Computing (May 1990), </booktitle> <pages> 159-169. </pages>
Reference-contexts: Vitter and Shriver introduced optimal randomized sorting algorithms for P-HMM and P-BT <ref> [ViSa] </ref>. The algorithms were based on their randomized two-level partitioning technique applied to the optimal single-hierarchy algorithms for HMM and BT developed in [AAC, ACSa]. <p> The structures of the formulas in Theorems 3 and 4 suggest several different relationships between the RUMH and SUMH models on the one hand and the HMM, BT, and two-level models on the other hand (cf. Theorems 5 and 6 in <ref> [ViSa] </ref>); accordingly the upper and lower bounds combine in an interesting way several techniques from [AAC, ACSa, AgV, ViSa]. Theorem 3 The running times mentioned in Theorem 2 are matching upper and lower bounds for sorting in P-RUMH. <p> Theorems 5 and 6 in [ViSa]); accordingly the upper and lower bounds combine in an interesting way several techniques from <ref> [AAC, ACSa, AgV, ViSa] </ref>. Theorem 3 The running times mentioned in Theorem 2 are matching upper and lower bounds for sorting in P-RUMH. The algorithms for nonconstant P for the first two bandwidth cases are randomized.
Reference: [ViSb] <author> J. S. Vitter and E. A. M. Shriver, </author> <title> "Algorithms for Parallel Memory II: Hierarchical Multilevel Memories," </title> <institution> Brown University, CS-90-22, </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: The algorithm that achieves the upper bound for the first case b (`) = 1 is based on a simulation of the P-BT algorithm for access cost function f (x) = p x given in <ref> [ViSb] </ref>. The time for the simulation is bounded by a constant times the P-BT running time. <p> The algorithms given in <ref> [ViSb] </ref> all meet this constraint. For the second case b (`) = 1=(` + 1), the upper bound is related to the P-HMM approach for f (x) = log x [ViSb]. <p> The algorithms given in <ref> [ViSb] </ref> all meet this constraint. For the second case b (`) = 1=(` + 1), the upper bound is related to the P-HMM approach for f (x) = log x [ViSb]. The P-HMM algorithm needs to be modified to 8 3 SORTING IN SUMH AND RUMH AND THEIR PARALLELIZATIONS reblock the buckets prior to sorting them recursively by substituting Step 8 of the P-BT algorithm of [ViSb] into the P-HMM algorithm. <p> upper bound is related to the P-HMM approach for f (x) = log x <ref> [ViSb] </ref>. The P-HMM algorithm needs to be modified to 8 3 SORTING IN SUMH AND RUMH AND THEIR PARALLELIZATIONS reblock the buckets prior to sorting them recursively by substituting Step 8 of the P-BT algorithm of [ViSb] into the P-HMM algorithm. <p> Hence, the lower bound for P-HMM for f (x) = log x given in <ref> [ViSb] </ref> also holds for P-RUMH 1=(`+1) . 2 10 3 SORTING IN SUMH AND RUMH AND THEIR PARALLELIZATIONS Theorem 4 The following bounds are matching upper and lower bounds for sorting in P-SUMH. <p> Proof : We prove the lower bounds using an approach similar to that of <ref> [ViSb] </ref>. Let us define the "sequential time" of a P-SUMH algorithm to be the sum of its time costs for each of the P hierarchies. The sequential time can be at most P times the P-SUMH running time. <p> The sequential time can be at most P times the P-SUMH running time. We superimpose on the P-SUMH model a sequence of one-disk, two-level memories of the type studied in <ref> [AgV, ViSb] </ref>, in the following way: For 1 ` 1 2 log (N=ffP ), the `th two-level memory has one disk, internal memory size M ` = P ff ( 2 (`+1) 1)=( 2 1), and block size B ` = ` . <p> The upper bounds for the first two cases b (`) = 1 and b (`) = 1=(` + 1) are achieved by simulating the optimal P-HMM algorithm of <ref> [ViSb] </ref>, for access cost functions f (x) = log x and f (x) = log 2 x, respectively.
References-found: 11

