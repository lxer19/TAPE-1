URL: http://www.isi.edu/~koehn/resources/magerman.ps
Refering-URL: http://www.isi.edu/~koehn/resources/index.html
Root-URL: http://www.isi.edu
Title: NATURAL LANGUAGE PARSING AS STATISTICAL PATTERN RECOGNITION  
Author: David M. Magerman 
Degree: a dissertation submitted to the department of computer science and the committee on graduate studies of stanford university in partial fulfillment of the requirements for the degree of doctor of philosophy By  
Date: February 1994  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. Alshawi and et. al. </author> <title> Interim report on the sri core language engine. </title> <type> Technical Report CCSRC-5, </type> <year> 1988. </year>
Reference-contexts: Traditionally, disambiguation problems in parsing have been solved by enumerating possibilities and explicitly declaring knowledge which might aid the disambiguation process. This declarative knowledge takes the form of semantic restrictions (e.g. Hirschman et.al. [32]), free-form logical expressions (e.g. Alshawi et.al. <ref> [1] </ref>), or a combination of these methods (e.g. Black, Garside, and Leech [7]). Some have used probabilistic (e.g. Seneff [59]) or non-probabilistic (e.g. Hobbs et.al. [33]) weighting systems to accumulate disambiguation decisions throughout the processing of a sentence into a single score for each interpretation. <p> Similarly, the grammar-based systems with complete syntactic, semantic and pragmatic analysis designed for spoken language applications, such as SRI's Core Language Engine (CLE) <ref> [1] </ref> and MIT's VOYAGER system [69], have been dominated by newer finite-state template-based systems. These template-based systems, using essentially the same technology as exhibited in Schank's SAD analyzer, benefits from a data-driven design methodology to achieve better coverage and accuracy. <p> The node feature value of the ith node of INITNODE is set to the ith word in the sentence, with the word each assigned to INITNODE [0], character assigned to INITNODE <ref> [1] </ref>, etc. This initial state is added to the STATES set. The algorithm's main loop begins by trying to advance this initial state, now called NODE. Since NODE is not completed, the algorithm tries to advance the first two active nodes of NODE. <p> The FEATURE array is set to the value fTag, Tag, Tag, Tag, Tag, Tag, Tag, Tagg and the ACTIVE array is set to the value f0; 1; 2; 3; 4; 5; 6; 7g: Using DW C = 2; the tag feature for NODE [0] and NODE <ref> [1] </ref> are assigned. This means that for all possible tags t, a new state is generated with the tag feature value of NODE [0] set to t, and another new state is generated with the tag feature value of NODE [1] set to t: Since there are 196 part-of-speech tags, a <p> = 2; the tag feature for NODE [0] and NODE <ref> [1] </ref> are assigned. This means that for all possible tags t, a new state is generated with the tag feature value of NODE [0] set to t, and another new state is generated with the tag feature value of NODE [1] set to t: Since there are 196 part-of-speech tags, a total of 392 new states are generated in this step. All of these states are added to the STATES set. The main loop continues with one of these states. <p> The order in which states are expanded are determined by the stack decoder algorithm, described in section 5.4.2. For the sake of the example, assume that the next state extended is the state which has the tag feature value for NODE <ref> [1] </ref> set to the correct tag, NN1. For this state, the FEATURE array is set to the value fTag, Extend, Tag, Tag, Tag, Tag, Tag, Tagg and the ACTIVE array is set to the value f0; 1; 2; 3; 4; 5; 6; 7g: For this state, the 74 CHAPTER 5. <p> SPATTER PARSING tag feature value of NODE [0] and the extend feature value of NODE <ref> [1] </ref> are assigned. Since there are 4 possible extension values, 200 new states are generated in this step. Consider the four states added in this step which had their NODE [1] extend feature value assigned. <p> SPATTER PARSING tag feature value of NODE [0] and the extend feature value of NODE <ref> [1] </ref> are assigned. Since there are 4 possible extension values, 200 new states are generated in this step. Consider the four states added in this step which had their NODE [1] extend feature value assigned. Using the terminology of the AssignFeature procedure in of these states contains a sequence of completed nodes which forms a constituent. The state for which the NEWNODE [1] extend feature was assigned the value unary contains a constituent consisting of the word character. <p> Consider the four states added in this step which had their NODE <ref> [1] </ref> extend feature value assigned. Using the terminology of the AssignFeature procedure in of these states contains a sequence of completed nodes which forms a constituent. The state for which the NEWNODE [1] extend feature was assigned the value unary contains a constituent consisting of the word character. For this state, a new parse node is created with unassigned feature values, and this new empty node replaces NEWNODE [1], with the old completed node becoming this node's child. <p> The state for which the NEWNODE <ref> [1] </ref> extend feature was assigned the value unary contains a constituent consisting of the word character. For this state, a new parse node is created with unassigned feature values, and this new empty node replaces NEWNODE [1], with the old completed node becoming this node's child. Consider what happens when the state being advanced is the one where the tag feature value of NODE [1] is set to NN1 and the extension feature value of NODE [1] is set to up. <p> For this state, a new parse node is created with unassigned feature values, and this new empty node replaces NEWNODE <ref> [1] </ref>, with the old completed node becoming this node's child. Consider what happens when the state being advanced is the one where the tag feature value of NODE [1] is set to NN1 and the extension feature value of NODE [1] is set to up. <p> unassigned feature values, and this new empty node replaces NEWNODE <ref> [1] </ref>, with the old completed node becoming this node's child. Consider what happens when the state being advanced is the one where the tag feature value of NODE [1] is set to NN1 and the extension feature value of NODE [1] is set to up. In this case, the FEATURE array is set to the value fTag, NONE, Tag, Tag, Tag, Tag, Tag, Tagg and the ACTIVE array is set to the value f0; 0; 1; 2; 3; 4; 5; 6g: Since NODE [1] is completed, the active nodes which are <p> and the extension feature value of NODE <ref> [1] </ref> is set to up. In this case, the FEATURE array is set to the value fTag, NONE, Tag, Tag, Tag, Tag, Tag, Tagg and the ACTIVE array is set to the value f0; 0; 1; 2; 3; 4; 5; 6g: Since NODE [1] is completed, the active nodes which are advanced in this step are NODE [0] and NODE [2]. 5.4.2 Managing the Search: Stack Decoding In SPATTER parsing, a state is defined as a sequence of n-ary labeled trees which together span the sentence.
Reference: [2] <author> L. R. Bahl, P. F. Brown, P. V. deSouza, and R. L. Mercer. </author> <title> A tree-based statistical language model for natural language speech recognition. </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> Vol. 36, No. 7, </volume> <pages> pages 1001-1008, </pages> <year> 1989. </year>
Reference-contexts: The growing algorithm is an adaptation of the CART algorithm in Breiman et.al.[13]. The IBM growing and smoothing algorithm were first published in Lucassen's 1983 dissertation [40]. Bahl, et.al., <ref> [2] </ref> is an excellent discussion of these algorithms applied to the language modeling problem. For this dissertation, I explored variations of these algorithms to improve the performance of the decision trees on the parsing task. <p> array is set to the value fTag, NONE, Tag, Tag, Tag, Tag, Tag, Tagg and the ACTIVE array is set to the value f0; 0; 1; 2; 3; 4; 5; 6g: Since NODE [1] is completed, the active nodes which are advanced in this step are NODE [0] and NODE <ref> [2] </ref>. 5.4.2 Managing the Search: Stack Decoding In SPATTER parsing, a state is defined as a sequence of n-ary labeled trees which together span the sentence. Since all possible feature values are generated at each node with some probability, the search space for this parser is immense.
Reference: [3] <author> L. R. Bahl, F. Jelinek, and R. L. Mercer. </author> <title> A maximum likelihood approach to continuous speech recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. PAMI-5, No. 2, </volume> <pages> pages 179-190, </pages> <year> 1983. </year>
Reference: [4] <author> J. K. Baker. </author> <title> Stochastic modeling for automatic speech understanding. </title> <booktitle> Speech Recognition, </booktitle> <pages> pages 521-542, </pages> <year> 1975. </year>
Reference-contexts: Pratt [51]); but using very large corpora and the inside-outside algorithm, they can now be trained automatically, instead of assigning the parameters by hand. A P-CFG model can be trained in a completely unsupervised mode, by considering all possible parses of the sentences in a training corpus (e.g. Baker <ref> [4] </ref> and Kupiec [39]), or it can be trained in a constrained mode, maximizing the probability of the parse trees in a parsed corpus (e.g. Black et.al. [10] and Schabes and Pereira [48]).
Reference: [5] <author> L. E. Baum. </author> <title> An inequality and associated maximization technique in statistical estimation of probabilistic functions of markov processes. </title> <journal> Inequalities, </journal> <volume> Vol. 3, </volume> <pages> pages 1-8, </pages> <year> 1972. </year>
Reference-contexts: + (1 n ) 1 : (3:42) If it turns out that a node n should not have been split, then the smoothing algorithm can assign n l = n r = 0; effectively pruning the children of n: 3.4.1 The Forward-Backward Algorithm for Decision Trees The Forward-Backward (F-B) algorithm <ref> [5] </ref> can be used to search for the optimal parameter settings for fl = f 1 ; 2 ; . . . ; m g: Given a held-out corpus C h , the F-B 3.4.
Reference: [6] <author> E. Black and et. al. </author> <title> A procedure for quantitatively comparing the syntactic coverage of english grammars. </title> <booktitle> Proceedings of the February 1991 DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 306-311, </pages> <year> 1991. </year>
Reference: [7] <author> E. Black, R. Garside, and G. Leech. </author> <title> Statistically-driven Computer Grammars of English: The IBM/Lancaster Approach. </title> <address> Rodopi, Atlanta, Georgia, </address> <year> 1993. </year>
Reference-contexts: This declarative knowledge takes the form of semantic restrictions (e.g. Hirschman et.al. [32]), free-form logical expressions (e.g. Alshawi et.al. [1]), or a combination of these methods (e.g. Black, Garside, and Leech <ref> [7] </ref>). Some have used probabilistic (e.g. Seneff [59]) or non-probabilistic (e.g. Hobbs et.al. [33]) weighting systems to accumulate disambiguation decisions throughout the processing of a sentence into a single score for each interpretation. Each of these approaches has resulted in some degree of success in accurately parsing sentences. <p> Thus, the earliest work on grammar induction involved either completely unsupervised learning, or, using the Tagged Brown Corpus, learning from a corpus tagged for parts of speech. Following the same path of the speech community, a number of parsing researchers (e.g. Black et.al. [10] <ref> [7] </ref>, Kupiec [39], and Schabes and Pereira [48]), have applied the inside-outside algorithm, a special case of the expectation-maximization algorithm for CFGs, to probabilistic context-free grammar (P-CFG) estimation. <p> Using these guidelines, the domain I selected to use for the history-based parsing experiments, as well as my dissertation experiments, is the Computer Manuals domain, and the training and test data I used is the Lancaster Computer Manuals 48 CHAPTER 4. PRELIMINARY EXPERIMENTS Treebank. Black, Garside, and Leech <ref> [7] </ref> provides detailed reports on experiments performed using his P-CFG, some of which is described in this section. <p> The Lancaster treebank uses 195 part-of-speech tags and 19 non-terminal labels. A complete list of the tags and labels is included in Appendix B. The definitions of these tags and labels are given in <ref> [7] </ref>. 4.2.2 The History-based Grammar Model A generative probabilistic grammar model estimates the joint probability of a derivation tree T and the observed sentence, S; denoted by p (T; S): The P-CFG model estimates this probability by assuming all derivational steps in T are independent. <p> The history-based grammar model makes the opposite assumption, namely that the probability of each derivational step depends on all previous steps. 1 The notion of a token is not clearly defined in <ref> [7] </ref>. However, since there are over 7,000 unique words in the treebank training set, a token is not the same as a word. I believe that each word is made up of one or more tokens, and the extra 4,000 words in the training data are multi-token words. 4.2. <p> There are 672 rule templates of which 400 are actually exercised when we parse a corpus of 15,000 sentences. The number of productions that are realized in this training corpus is several hundred thousand. For a complete description of this grammar, see Black, Garside, and Leech <ref> [7] </ref>. P-CFG A non-terminal in the above grammar is a feature vector. For the purposes of parameterizing a P-CFG model of this grammar, several non-terminals are grouped into a single class called a mnemonic. A mnemonic is represented by the one non-terminal that is the least specified in its class. <p> It would be difficult for human treebankers to assign constituent labels to text consistently, accurately, and efficiently if the labels conveyed subtle nuances of meaning. For example, the Lancaster Treebank uses only 17 constituent labels, whereas the grammar described in Black, Garside, and Leech <ref> [7] </ref> covering the same domain assigns over 13,000 unique 2 Since each node of the parse tree must be assigned an extension value, there must be a fifth extension value for the root node. I call this value root. <p> using the DeMoivre Laplace approximation, which is much easier to compute than the binomial. 8.3 Basic Experiment The idea behind the basic experiment is to construct the best parser possible and to perform experiments using the same training and test data as the experiment reported in Black, Garside, and Leech <ref> [7] </ref>, which I refer to as the P-CFG experiment. The basic experiment consists of constructing SPATTER's decision tree models as described in Chapter 6 using the treebank data, and training these models nearly to convergence. 2 The training procedure for the basic experiment is described in section 6.3.4. <p> The test set included 1,473 sentences, whose lengths range from 3 to 30 words, with a mean length of 13.7 words. These sentences are the same test sentences used in the experiments reported for the P-CFG parser in Black, Garside, and Leech <ref> [7] </ref>. Since [7] only reports results using the sentence-based crossing-brackets measure, I am reporting the same measure for the sake of comparison. <p> The test set included 1,473 sentences, whose lengths range from 3 to 30 words, with a mean length of 13.7 words. These sentences are the same test sentences used in the experiments reported for the P-CFG parser in Black, Garside, and Leech <ref> [7] </ref>. Since [7] only reports results using the sentence-based crossing-brackets measure, I am reporting the same measure for the sake of comparison. <p> By some measures, in terms of both technology and performance, it is an improvement over the state-of-the-art in parsing. The state-of-the-art in statistical parsing technology includes P-CFGs trained using the Inside-Outside algorithm (Schabes and Pereira [48], Kupiec [39], and Black, Garside, and Leech <ref> [7] </ref>, parsers which generate unlabeled bracketing using correct tag sequences as input (Brill [16], Schabes and Pereira [48], and grammar induction strategies which attempt to acquire grammars by extracting context-free productions from treebanks. <p> To request electronic verisions of any of the SPATTER vocabularies, send electronic mail to mager-man@cs.stanford.edu. The descriptions of the non-terminal label set and part-of-speech tag set can be found in Black, Garside, and Leech <ref> [7] </ref>. B.1 Part-of-Speech Tag Vocabulary Here is the part-of-speech tag vocabulary, sorted by frequency of occurrence in the Lancaster Computer Manuals Treebank: NN1 AT .
Reference: [8] <author> E. Black, F. Jelinek, J. Lafferty, D. M. Magerman, R. Mercer, and S. Roukos. </author> <title> Towards history-based grammars: Using richer models for probabilistic parsing. </title> <booktitle> 136 BIBLIOGRAPHY 137 Proceedings of the February 1992 DARPA Speech and Natural Language Workshop, </booktitle> <year> 1992. </year>
Reference-contexts: As illustrated in Magerman and Marcus [42], Black et.al. <ref> [8] </ref>, and Magerman and Weir [43], probabilistic parsers are much more accurate when their models incorporate lexical information from the context, and when the applications of the models are not assumed to be independent.
Reference: [9] <author> E. Black, F. Jelinek, J. Lafferty, R. Mercer, and S. Roukos. </author> <title> Development and evaluation of a broad-coverage probabilistic grammar of english-language computer manuals. </title> <booktitle> Proceedings of the February 1992 DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 117-121, </pages> <year> 1992. </year>
Reference-contexts: At BBN, Weischedel [44] explored the behavior of HMM tagging algorithms when trained on limited data, and reports experimental results using various models designed to account for weaknesses of the simple HMM trigram word-tag model. Lafferty <ref> [9] </ref> uses decision tree techniques similar to those described in Chapter 3 in his paper on decision tree part-of-speech tagging. His work was an attempt to extend the usual three-word window made available to a trigram part-of-speech tagger.
Reference: [10] <author> E. Black, J. Lafferty, and S. Roukos. </author> <title> Development and evaluation of a broad-coverage probabilistic grammar of english-language computer manuals. </title> <booktitle> Proceedings of the Association for Computational Linguistics, </booktitle> <year> 1992, 1992. </year>
Reference-contexts: Thus, the earliest work on grammar induction involved either completely unsupervised learning, or, using the Tagged Brown Corpus, learning from a corpus tagged for parts of speech. Following the same path of the speech community, a number of parsing researchers (e.g. Black et.al. <ref> [10] </ref> [7], Kupiec [39], and Schabes and Pereira [48]), have applied the inside-outside algorithm, a special case of the expectation-maximization algorithm for CFGs, to probabilistic context-free grammar (P-CFG) estimation. <p> Baker [4] and Kupiec [39]), or it can be trained in a constrained mode, maximizing the probability of the parse trees in a parsed corpus (e.g. Black et.al. <ref> [10] </ref> and Schabes and Pereira [48]). More evidence that the availability of corpora has influenced the direction of research is in the study of parsing tagged sentences using statistical methods (Magerman and Marcus [41], Brill [16], and Bod [12]). The motivation behind this work was twofold. <p> Sharman, Jelinek and Mercer [61], Black, Garside, and Leech <ref> [10] </ref>), which assigns a probability to each rule in a context-free grammar and computes the probability of the parse tree by assuming that each grammar rule application is independent of all other rule applications in the sentence.
Reference: [11] <author> D. G. Bobrow. </author> <title> Natural language input for a computer problem-solving system. </title> <booktitle> Semantic Information Processing, </booktitle> <pages> pages 146-226, </pages> <year> 1968. </year>
Reference-contexts: The work in the 1960s on natural language processing consisted primarily of keyword analysis or pattern matching. Systems such as Green's BASEBALL [26], Raphael's SIR [52], and Bobrow's STUDENT <ref> [11] </ref> search for simple patterns or regular expressions which indicate useful information. All information in the text which does not conform to these patterns is ignored.
Reference: [12] <author> R. </author> <title> Bod. Monte carlo parsing. </title> <booktitle> Proceedings of the August 1993 International Workshop on Parsing Technologies, </booktitle> <year> 1993. </year>
Reference-contexts: Black et.al. [10] and Schabes and Pereira [48]). More evidence that the availability of corpora has influenced the direction of research is in the study of parsing tagged sentences using statistical methods (Magerman and Marcus [41], Brill [16], and Bod <ref> [12] </ref>). The motivation behind this work was twofold. First, since part-of-speech taggers and tagged corpora were readily available, it seemed reasonable to attempt to parse a tagged corpus, under the assumption that part-of-speech taggers would eventually be accurate enough to be used as automatic 2.5. <p> Based on the number and types of errors, these sentences clearly had not been corrected by treebankers. Using Data Representative of the Problem Recently, there have been a number of papers, such as Schabes and Pereira [48], Brill [16], and Bod <ref> [12] </ref>, citing work based on parsing using sentences tagged for part of speech. While it is true that part-of-speech taggers have very low error rates, some below 3%, parsing from manually assigned tags is not the same as parsing from automatically assigned tags. <p> Otherwise, the results cannot be reproduced by other members of community. Altering training data can also cause confusion. As was mentioned earlier, the UPenn treebank has a very low internal consistency rate. In his recent paper <ref> [12] </ref>, Bod reports achieving a 96% exact match accuracy rate parsing UPenn treebank data from the ATIS domain. <p> Model X Model Y p (X = Y ) p (X ' Y ) F 1.0 10 14 0.12 Table 8.15: Significance analysis of EXACT and EXNOTAG results from experiments F and G. Experiments F and G mimic the experiments performed by Brill [16] and by Bod <ref> [12] </ref>, respectively. Experiment F parses assuming the words in the sentence and their correct tags are known. Experiment G parses assuming the correct tags are known, but the decision trees are not permitted to ask about the words in the sentence. <p> As indicated in the figure, SPATTER finds both analyses but assigns the incorrect one a higher probability. SPATTER might be improved by representing constituents, but how should this be implemented? One solution might be to model multiple levels of constituent structure, as Bod does in <ref> [12] </ref>. The main problem with this approach is that, given the limited amount of training data, it is likely that this approach would overtrain on the constituents in the treebank, and closely mimic a P-CFG.
Reference: [13] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth and Brooks, </publisher> <address> Pacific Grove, California, </address> <year> 1984. </year>
Reference: [14] <author> M. R. Brent. </author> <title> Automatic acquisition of subcategorization frames from untagged free-text corpora. </title> <booktitle> Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, </booktitle> <year> 1991. </year>
Reference-contexts: Work on language acquisition attempts to discover semantic selection preferences (e.g. Resnik [53]) and verb subcategorization information (e.g. Brent <ref> [14] </ref>). Schuetze [57] has developed a vector-based representation for language which aids in word sense disambiguation. A significant application of statistical modeling technology is the Candide system [17], developed by the IBM Machine Translation group.
Reference: [15] <author> E. Brill. </author> <type> Doctoral dissertation. </type> <institution> University of Pennsylvania, </institution> <address> Philadelphia, Penn-sylvania, </address> <year> 1993. </year>
Reference-contexts: His results, however, were not much better than those of existing taggers. Brill's dissertation work <ref> [15] </ref> explored using a corpus to acquire a rule-based tagger automatically. His tagger preprocessed a corpus using a simple HMM tagger and, based on the correct tagging provided by human taggers, learned a small set of rules which corrected the output of the HMM tagger.
Reference: [16] <author> E. Brill. </author> <title> Transformation-based error-driven parsing. </title> <booktitle> Proceedings of the August 1993 International Workshop on Parsing Technologies, </booktitle> <year> 1993. </year>
Reference-contexts: Black et.al. [10] and Schabes and Pereira [48]). More evidence that the availability of corpora has influenced the direction of research is in the study of parsing tagged sentences using statistical methods (Magerman and Marcus [41], Brill <ref> [16] </ref>, and Bod [12]). The motivation behind this work was twofold. First, since part-of-speech taggers and tagged corpora were readily available, it seemed reasonable to attempt to parse a tagged corpus, under the assumption that part-of-speech taggers would eventually be accurate enough to be used as automatic 2.5. <p> Based on the number and types of errors, these sentences clearly had not been corrected by treebankers. Using Data Representative of the Problem Recently, there have been a number of papers, such as Schabes and Pereira [48], Brill <ref> [16] </ref>, and Bod [12], citing work based on parsing using sentences tagged for part of speech. While it is true that part-of-speech taggers have very low error rates, some below 3%, parsing from manually assigned tags is not the same as parsing from automatically assigned tags. <p> Model X Model Y p (X = Y ) p (X ' Y ) F 1.0 10 14 0.12 Table 8.15: Significance analysis of EXACT and EXNOTAG results from experiments F and G. Experiments F and G mimic the experiments performed by Brill <ref> [16] </ref> and by Bod [12], respectively. Experiment F parses assuming the words in the sentence and their correct tags are known. Experiment G parses assuming the correct tags are known, but the decision trees are not permitted to ask about the words in the sentence. <p> The state-of-the-art in statistical parsing technology includes P-CFGs trained using the Inside-Outside algorithm (Schabes and Pereira [48], Kupiec [39], and Black, Garside, and Leech [7], parsers which generate unlabeled bracketing using correct tag sequences as input (Brill <ref> [16] </ref>, Schabes and Pereira [48], and grammar induction strategies which attempt to acquire grammars by extracting context-free productions from treebanks.
Reference: [17] <author> P. Brown and et. al. </author> <title> A statistical approach to machine translation. </title> <journal> Computational Linguistics, </journal> <volume> Vol. 16, No. 2, </volume> <pages> pages 79-85, </pages> <year> 1990. </year>
Reference-contexts: Work on language acquisition attempts to discover semantic selection preferences (e.g. Resnik [53]) and verb subcategorization information (e.g. Brent [14]). Schuetze [57] has developed a vector-based representation for language which aids in word sense disambiguation. A significant application of statistical modeling technology is the Candide system <ref> [17] </ref>, developed by the IBM Machine Translation group. Candide translates French to English using a source-channel model, where it is assumed that the French sentence was actually originally an English sentence passed through a noisy channel.
Reference: [18] <author> P. F. Brown, V. J. Della Pietra, P. V. deSouza, J. C. Lai, and R. L. Mercer. </author> <title> Class-based n-gram models of natural language. </title> <booktitle> Proceedings of the IBM Natural Language ITL, </booktitle> <month> March </month> <year> 1990, 1990. </year> <note> 138 BIBLIOGRAPHY </note>
Reference: [19] <author> N. Chomsky. </author> <title> Syntactic Structures. </title> <publisher> Mouton, </publisher> <address> The Hague, </address> <year> 1957. </year>
Reference-contexts: Chomsky's work in the late 1950s and early 1960s in transformational grammars and formal language theory <ref> [19] </ref> [20] provided much of the machinery for the next generation of natural language processing research. Context-free grammar parsers, such as Lindsay's SAD-SAM [56], took advantage of Chomsky's formalization to improve upon the simpler single-state and finite-state models.
Reference: [20] <author> N. Chomsky. </author> <title> Aspects of the Theory of Syntax. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mas-sachusetts, </address> <year> 1965. </year>
Reference-contexts: Chomsky's work in the late 1950s and early 1960s in transformational grammars and formal language theory [19] <ref> [20] </ref> provided much of the machinery for the next generation of natural language processing research. Context-free grammar parsers, such as Lindsay's SAD-SAM [56], took advantage of Chomsky's formalization to improve upon the simpler single-state and finite-state models.
Reference: [21] <author> K. Church. </author> <title> A stochastic parts program and noun phrase parser for unrestricted text. </title> <booktitle> Proceedings of the Second Conference on Applied Natural Language Processing, </booktitle> <year> 1988. </year>
Reference-contexts: WORK IN STATISTICAL NL 15 syntactic analysis, such as part-of-speech tagging and grammar induction, but some projects have begun involving probabilistic understanding models and statistical machine translation as well. 2.5.1 Part-of-speech Tagging Statistical part-of-speech tagging has been a hot topic since the 1988 ACL paper by Church on HMM tagging <ref> [21] </ref>. The problem in part-of-speech tagging is to assign to each word in a sentence a part-of-speech label which indicates the linguistic category (e.g. noun, verb, adjective, etc.) to which that word belongs in the context of the sentence.
Reference: [22] <author> T. M. Cover and J. A. Thomas. </author> <title> Elements of Information Theory. </title> <publisher> John Wiley and Sons, Inc., </publisher> <address> New York, New York, </address> <year> 1991. </year>
Reference-contexts: In this section, I introduce some basic concepts from information theory which are necessary 20 CHAPTER 3. STATISTICAL DECISION TREE MODELING to understand decision trees. A more complete introduction to information theory can be found in Cover and Thomas <ref> [22] </ref>. 3.1.1 Entropy Entropy is a measure of uncertainty about a random variable.
Reference: [23] <author> A. Derouault and B. Merialdo. </author> <title> Probabilistic grammar for phonetic to french transcription. </title> <booktitle> ICASSP 85 Proceedings, </booktitle> <pages> pages 1577-1580, </pages> <year> 1985. </year>
Reference-contexts: Actually, HMM tagging was suggested a few years earlier during a lecture by Mercer at MIT, which Church attended, and Merialdo published a more obscure paper on the subject in 1986 <ref> [23] </ref>. At BBN, Weischedel [44] explored the behavior of HMM tagging algorithms when trained on limited data, and reports experimental results using various models designed to account for weaknesses of the simple HMM trigram word-tag model.
Reference: [24] <author> Jack Ferguson. </author> <title> Hidden Markov Models for Speech. </title> <address> IDA-CRD, Princeton, New Jersey, </address> <year> 1980. </year>
Reference-contexts: This revolution in speech technology can be traced back to a seminar given by researchers at IDA in October, 1980, on Hidden Markov Models (HMMs) <ref> [24] </ref>. A Markov process is finite-state process for which the probability of going from one state to another on a given input depends only on a finite history.
Reference: [25] <author> G. Gazdar, E. Klein, G. K. Pullum, and I. A. Sag. </author> <title> Generalized Phrase Structure Grammar. </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1982. </year>
Reference-contexts: nature of ATNs, in the early 1980s a number of grammatical formalisms appeared which attempted to account for the power of the functional augmentations of ATNs in a more formal theoretical framework: Definite-Clause Grammar (DCG) [49], Functional Unification Grammar (FUG) [38], Lexical-Functional Grammar (LFG) [37], Generalized Phrase Structure Grammar (GPSG) <ref> [25] </ref>, and others. 1 This is a bit of an oversimplification. SHRDLU implemented a set of predicates which were defined to be the blocks-world. There were many gaps in the representation of the blocks-world.
Reference: [26] <author> B. F. Green, A. K. Wolf, C. Chomsky, and Laughery. K. Baseball: </author> <title> An automatic question answerer. </title> <booktitle> Computers and Thought, </booktitle> <pages> pages 207-216, </pages> <year> 1963. </year>
Reference-contexts: The failure of superficial "dictionary lookup" solutions to the MT problem suggested the need for a higher level of knowledge representation. The work in the 1960s on natural language processing consisted primarily of keyword analysis or pattern matching. Systems such as Green's BASEBALL <ref> [26] </ref>, Raphael's SIR [52], and Bobrow's STUDENT [11] search for simple patterns or regular expressions which indicate useful information. All information in the text which does not conform to these patterns is ignored.
Reference: [27] <author> R. Grishman. </author> <title> PROTEUS Project Memorandum No. </title> <address> 4-C. New York University, New York, New York, </address> <year> 1990. </year>
Reference-contexts: Some examples of this type of system development are Unisys' PUNDIT system 2 Excellent descriptions of these theories can be found in Sells [58] and Shieber [62]. 10 CHAPTER 2. RELATED WORK [32] and NYU's PROTEUS system <ref> [27] </ref>. Both of these systems are descendants of the Linguistic String Project (LSP) [54], an early effort to develop grammar-based parsers for sublanguages. Both systems use a string grammar, consisting of a context-free grammar backbone augmented with functional restrictions on the application of the grammar's productions.
Reference: [28] <author> M. A. K. Halliday. </author> <title> Language structure and language function. </title> <booktitle> New Horizons in Linguistics, </booktitle> <pages> pages 140-165, </pages> <year> 1970. </year>
Reference-contexts: This approach suffered from some of the same deficiencies that exist in systems today, in particular the limited coverage of the grammar and vocabulary. In contrast to the decomposition of syntax and semantics in SAD-SAM, Halliday's 8 CHAPTER 2. RELATED WORK systemic grammar <ref> [28] </ref> proposed a formalism that encoded the functional relationships in a sentence. His theory was illustrated in Winograd's blocks-world system, SHRDLU [67]. SHRDLU demonstrated the effectiveness of functional representations on a small problem, but it also implicitly revealed one of its weaknesses.
Reference: [29] <author> M. A. Harrison. </author> <title> Introduction to Formal Language Theory. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1978. </year>
Reference: [30] <author> D. Hindle and M. Rooth. </author> <title> Structural ambiguity and lexical relations. </title> <booktitle> Proceedings of the June 1990 DARPA Speech and Natural Language Workshop, </booktitle> <year> 1990. </year> <note> BIBLIOGRAPHY 139 </note>
Reference: [31] <author> L. Hirschman. </author> <title> Multi-site data collection for a spoken language corpus. </title> <booktitle> Proceedings of the February 1992 DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 7-14, </pages> <year> 1992. </year>
Reference-contexts: It is important that this data set be an unbiased random sample of the typical events in the domain being modeled. Data Collection An example of biased data collection comes from the ARPA ATIS project <ref> [31] </ref>. This project involves building a spoken language interface to an airline reservation system.
Reference: [32] <author> L. Hirschman and et. al. </author> <title> The pundit natural-language processing system. </title> <booktitle> Proceedings of the AI Systems in Government Conference, </booktitle> <year> 1989. </year>
Reference-contexts: Traditionally, disambiguation problems in parsing have been solved by enumerating possibilities and explicitly declaring knowledge which might aid the disambiguation process. This declarative knowledge takes the form of semantic restrictions (e.g. Hirschman et.al. <ref> [32] </ref>), free-form logical expressions (e.g. Alshawi et.al. [1]), or a combination of these methods (e.g. Black, Garside, and Leech [7]). Some have used probabilistic (e.g. Seneff [59]) or non-probabilistic (e.g. <p> Some examples of this type of system development are Unisys' PUNDIT system 2 Excellent descriptions of these theories can be found in Sells [58] and Shieber [62]. 10 CHAPTER 2. RELATED WORK <ref> [32] </ref> and NYU's PROTEUS system [27]. Both of these systems are descendants of the Linguistic String Project (LSP) [54], an early effort to develop grammar-based parsers for sublanguages. <p> This work was published in Magerman and Weir [43]. In this section, I describe the Pearl model including the correction made in the Picky work. 4.1.1 The PUNDIT String Grammar The grammar to which this experiment was applied is the PUNDIT string grammar developed at Unisys <ref> [32] </ref>. The PUNDIT string grammar consists of a set of context-free rules, referred to as the context-free backbone of the grammar, and a set of restrictions on the applications of these rules. For instance, one restriction might 4.1.
Reference: [33] <author> J. Hobbs. </author> <title> The dialogic parser. </title> <year> 1982. </year>
Reference-contexts: This declarative knowledge takes the form of semantic restrictions (e.g. Hirschman et.al. [32]), free-form logical expressions (e.g. Alshawi et.al. [1]), or a combination of these methods (e.g. Black, Garside, and Leech [7]). Some have used probabilistic (e.g. Seneff [59]) or non-probabilistic (e.g. Hobbs et.al. <ref> [33] </ref>) weighting systems to accumulate disambiguation decisions throughout the processing of a sentence into a single score for each interpretation. Each of these approaches has resulted in some degree of success in accurately parsing sentences.
Reference: [34] <author> J. Hobbs. </author> <title> Sri international: Description of the tacitus system as used for muc-3. </title> <booktitle> Proceedings of the Third Message Understanding Conference (MUC-3), </booktitle> <year> 1991. </year>
Reference-contexts: Heuristic scoring functions implement various preference mechanisms, including preferring the closest attachment, disfavoring headless noun phrases, and evaluating semantic selection. The parser uses a best-first search strategy to discover the highest-scoring analysis. SRI's TACITUS system <ref> [34] </ref> is another descendant of the Linguistic String Project. It uses the DIALOGIC parser, which is a union of the LSP grammar and the DIAGRAM grammar, a grammar developed for SRI's speech understanding research.
Reference: [35] <author> J. R. Hobbs, D. E. Appelt, J. S. Bear, D. J. Israel, and W. M. Tyson. Fastus: </author> <title> A system for extracting information from natural-language text. </title> <note> Technical Note No. 519, </note> <year> 1993. </year>
Reference-contexts: TACITUS included a relevance filter which allowed the 2.4. THE TOY PROBLEM SYNDROME 11 system to ignore sentences which it deemed statistically "irrelevant" to the information extraction task. These systems gave way to more refined information extraction systems, such as SRI's FASTUS system <ref> [35] </ref>, which abandons the grammar-based parsing strategy in favor of a finite-state machine approach, specifying flexible templates for identifying the critical information necessary for accomplishing the information extraction task.
Reference: [36] <author> F. Jelinek. </author> <title> A fast sequential decoding algorithm using a stack. </title> <journal> IBM Journal of Research and Development, </journal> <volume> Vol. 13, </volume> <pages> pages 675-685, </pages> <year> 1969. </year>
Reference-contexts: The search algorithm which SPATTER uses to explore the search graph and prune intelligently is the stack decoding algorithm. The stack decoding algorithm was introduced by Jelinek in 1969 <ref> [36] </ref> for solving the graph search problem in speech recognition. Other discussions of stack decoding in speech recognition are found in Bahl et.al.[3] and Paul [47]. Like other AI search procedures, the stack decoding algorithm uses a scoring 5.4. SPATTER PARSING: THE ALGORITHM 75 76 CHAPTER 5.
Reference: [37] <author> R. Kaplan and J. Bresnan. </author> <title> Lexical-functional grammar: A formal system for grammatical representation. The Mental Representation of Grammatical Relations, </title> <year> 1983. </year>
Reference-contexts: Perhaps in response to the ad-hoc nature of ATNs, in the early 1980s a number of grammatical formalisms appeared which attempted to account for the power of the functional augmentations of ATNs in a more formal theoretical framework: Definite-Clause Grammar (DCG) [49], Functional Unification Grammar (FUG) [38], Lexical-Functional Grammar (LFG) <ref> [37] </ref>, Generalized Phrase Structure Grammar (GPSG) [25], and others. 1 This is a bit of an oversimplification. SHRDLU implemented a set of predicates which were defined to be the blocks-world. There were many gaps in the representation of the blocks-world.
Reference: [38] <author> M. Kay. </author> <title> Parsing in functional unification grammar. Natural Language Parsing: Psychological, </title> <booktitle> Computational and Theoretical Perspectives, </booktitle> <year> 1985. </year>
Reference-contexts: 2.2 Computational Grammatical Formalisms Perhaps in response to the ad-hoc nature of ATNs, in the early 1980s a number of grammatical formalisms appeared which attempted to account for the power of the functional augmentations of ATNs in a more formal theoretical framework: Definite-Clause Grammar (DCG) [49], Functional Unification Grammar (FUG) <ref> [38] </ref>, Lexical-Functional Grammar (LFG) [37], Generalized Phrase Structure Grammar (GPSG) [25], and others. 1 This is a bit of an oversimplification. SHRDLU implemented a set of predicates which were defined to be the blocks-world. There were many gaps in the representation of the blocks-world.
Reference: [39] <author> J. Kupiec. </author> <title> A trellis-based algorithm for estimating the parameters of a hidden stochastic context-free grammar. </title> <booktitle> Proceedings of the February 1991 DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 241-246, </pages> <year> 1991. </year>
Reference-contexts: Thus, the earliest work on grammar induction involved either completely unsupervised learning, or, using the Tagged Brown Corpus, learning from a corpus tagged for parts of speech. Following the same path of the speech community, a number of parsing researchers (e.g. Black et.al. [10] [7], Kupiec <ref> [39] </ref>, and Schabes and Pereira [48]), have applied the inside-outside algorithm, a special case of the expectation-maximization algorithm for CFGs, to probabilistic context-free grammar (P-CFG) estimation. <p> A P-CFG model can be trained in a completely unsupervised mode, by considering all possible parses of the sentences in a training corpus (e.g. Baker [4] and Kupiec <ref> [39] </ref>), or it can be trained in a constrained mode, maximizing the probability of the parse trees in a parsed corpus (e.g. Black et.al. [10] and Schabes and Pereira [48]). <p> By some measures, in terms of both technology and performance, it is an improvement over the state-of-the-art in parsing. The state-of-the-art in statistical parsing technology includes P-CFGs trained using the Inside-Outside algorithm (Schabes and Pereira [48], Kupiec <ref> [39] </ref>, and Black, Garside, and Leech [7], parsers which generate unlabeled bracketing using correct tag sequences as input (Brill [16], Schabes and Pereira [48], and grammar induction strategies which attempt to acquire grammars by extracting context-free productions from treebanks.
Reference: [40] <author> J. </author> <title> Lucassen. </title> <type> Doctoral dissertation. </type> ??? <institution> University, </institution> ???, ???, <year> 1983. </year>
Reference-contexts: The decision tree algorithms used in this work were developed over the past 15 years by the IBM Speech Recognition group. The growing algorithm is an adaptation of the CART algorithm in Breiman et.al.[13]. The IBM growing and smoothing algorithm were first published in Lucassen's 1983 dissertation <ref> [40] </ref>. Bahl, et.al., [2] is an excellent discussion of these algorithms applied to the language modeling problem. For this dissertation, I explored variations of these algorithms to improve the performance of the decision trees on the parsing task. <p> l (x) 0 n 62 N (x) Let Pr fl (y; njx) be the probability of generating y from state n on input x: Then Pr fl (y; njx) = ff n (x) n p n (yjx): (3:44) 3 This smoothing algorithm was first published in Lucassen's dissertation in 1983 <ref> [40] </ref>. It was also mentioned briefly in Bahl et.al.[2]. 36 CHAPTER 3.
Reference: [41] <author> D. M. Magerman and M. P. Marcus. </author> <title> Parsing a natural language using mutual information statistics. </title> <booktitle> Proceedings of AAAI-90, </booktitle> <year> 1990. </year>
Reference-contexts: RELATED WORK 2.5.2 Grammar Induction Much of the work in grammar induction has been a function of the availability of parsed and unparsed corpora. For instance, in 1990, I published my undergraduate thesis with Marcus <ref> [41] </ref> on parsing without a grammar using mutual information statistics from a tagged corpus. I originally intended to do this work on supervised learning from a pre-parsed corpus, but no such corpus existed in the public domain. <p> Black et.al. [10] and Schabes and Pereira [48]). More evidence that the availability of corpora has influenced the direction of research is in the study of parsing tagged sentences using statistical methods (Magerman and Marcus <ref> [41] </ref>, Brill [16], and Bod [12]). The motivation behind this work was twofold. First, since part-of-speech taggers and tagged corpora were readily available, it seemed reasonable to attempt to parse a tagged corpus, under the assumption that part-of-speech taggers would eventually be accurate enough to be used as automatic 2.5.
Reference: [42] <author> D. M. Magerman and M. P. Marcus. Pearl: </author> <title> A probabilistic chart parser. </title> <booktitle> Proceedings of the European ACL Conference, </booktitle> <month> March </month> <year> 1991, 1991. </year> <note> 140 BIBLIOGRAPHY </note>
Reference-contexts: The product of this initial experiment was the Pearl parser, developed at Unisys in collaboration with Dr. Mitch Marcus of the University of Pennsylvania. Preliminary experimental results using Pearl were published in Magerman and Marcus <ref> [42] </ref>. To test the Pearl model further, and to correct an error in the implementation of the Pearl model, the Picky parser was developed two years later at Stanford in collaboration with Dr. Carl Weir of Unisys. This work was published in Magerman and Weir [43]. <p> See Magerman and Marcus <ref> [42] </ref> for a more detailed description of this model. 4.1. A CONTEXT-SENSITIVE PROBABILISTIC PARSER 45 4.1.4 Experimental Results Experiments were performed which tested whether or not the Pearl parsing model could represent the same information encoded in the restriction set. <p> As illustrated in Magerman and Marcus <ref> [42] </ref>, Black et.al. [8], and Magerman and Weir [43], probabilistic parsers are much more accurate when their models incorporate lexical information from the context, and when the applications of the models are not assumed to be independent. <p> Another violation of test data etiquette is more subtle: separating training and test data from a corpus by random sampling. It goes without saying that one should not test on data which was used in training. Recently, a number of parsing papers, including two of my own <ref> [42] </ref> [43], have reported results using test sets were randomly sampled from a corpus, using the remainder of the corpus as training material. While this technique seems benign, it actually ensures that the test data will be as statistically similar to the training data as possible.
Reference: [43] <author> D. M. Magerman and C. Weir. </author> <title> Efficiency, robustness, and accuracy in picky chart parsing. </title> <booktitle> Proceedings of the Association for Computational Linguistics, </booktitle> <year> 1992, 1992. </year>
Reference-contexts: To test the Pearl model further, and to correct an error in the implementation of the Pearl model, the Picky parser was developed two years later at Stanford in collaboration with Dr. Carl Weir of Unisys. This work was published in Magerman and Weir <ref> [43] </ref>. In this section, I describe the Pearl model including the correction made in the Picky work. 4.1.1 The PUNDIT String Grammar The grammar to which this experiment was applied is the PUNDIT string grammar developed at Unisys [32]. <p> As illustrated in Magerman and Marcus [42], Black et.al. [8], and Magerman and Weir <ref> [43] </ref>, probabilistic parsers are much more accurate when their models incorporate lexical information from the context, and when the applications of the models are not assumed to be independent. <p> Another violation of test data etiquette is more subtle: separating training and test data from a corpus by random sampling. It goes without saying that one should not test on data which was used in training. Recently, a number of parsing papers, including two of my own [42] <ref> [43] </ref>, have reported results using test sets were randomly sampled from a corpus, using the remainder of the corpus as training material. While this technique seems benign, it actually ensures that the test data will be as statistically similar to the training data as possible.
Reference: [44] <author> M. Meteer, R. Schwartz, and R. Weischedel. </author> <title> Studies in part of speech labelling. </title> <booktitle> Proceedings of the February 1991 DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 331-336, </pages> <year> 1991. </year>
Reference-contexts: Actually, HMM tagging was suggested a few years earlier during a lecture by Mercer at MIT, which Church attended, and Merialdo published a more obscure paper on the subject in 1986 [23]. At BBN, Weischedel <ref> [44] </ref> explored the behavior of HMM tagging algorithms when trained on limited data, and reports experimental results using various models designed to account for weaknesses of the simple HMM trigram word-tag model.
Reference: [45] <author> A. Newell. </author> <title> Harpy: Production systems and human cognition. </title> <address> CMU-CS-78-140, </address> <year> 1978. </year>
Reference-contexts: No other aspects of the system were constrained. The goal of the project was to achieve a breakthrough in speech recognition technology. In fact, what resulted from the ARPA speech effort was an exercise in ad-hoc engineering. The most extreme example of this is the HARPY system <ref> [45] </ref>, developed at 2.4. THE TOY PROBLEM SYNDROME 13 Carnegie-Mellon University. The HARPY system used a precompiled network which computed all possible sentences which HARPY could expect to recognize. While this solution satisfied the letter of their ARPA contract, it certainly violated its spirit.
Reference: [46] <author> A. Newell and et. al. </author> <title> Speech Understanding Systems: Final Report of a Study Group. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1973. </year>
Reference-contexts: Their solution serves as an excellent model for the NL parsing community to emulate. In 1971, the Advanced Research Projects Agency (ARPA) of the Defense Department asked five speech research groups to build demonstration systems to solve a simple speech recognition task <ref> [46] </ref>. The systems were expected to recognize a 1000-word vocabulary from a constrained domain reasonably quickly with less than a 10% error rate. No other aspects of the system were constrained. The goal of the project was to achieve a breakthrough in speech recognition technology.
Reference: [47] <author> D. B. Paul. </author> <title> Algorithms for an optimal a fl search and linearizing the search in the stack decoder. </title> <booktitle> Proceedings of the June 1990 DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 200-204, </pages> <year> 1990. </year>
Reference-contexts: The stack decoding algorithm was introduced by Jelinek in 1969 [36] for solving the graph search problem in speech recognition. Other discussions of stack decoding in speech recognition are found in Bahl et.al.[3] and Paul <ref> [47] </ref>. Like other AI search procedures, the stack decoding algorithm uses a scoring 5.4. SPATTER PARSING: THE ALGORITHM 75 76 CHAPTER 5. SPATTER PARSING function to evaluate a state based on the path from the initial state.
Reference: [48] <author> F. Pereira and Y. Schabes. </author> <title> Inside-outside reestimation from partially bracketed corpora. </title> <booktitle> Proceedings of the February 1992 DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 122-127, </pages> <year> 1992. </year>
Reference-contexts: Following the same path of the speech community, a number of parsing researchers (e.g. Black et.al. [10] [7], Kupiec [39], and Schabes and Pereira <ref> [48] </ref>), have applied the inside-outside algorithm, a special case of the expectation-maximization algorithm for CFGs, to probabilistic context-free grammar (P-CFG) estimation. A P-CFG is a context-free grammar with probabilities assigned to each production in the grammar, where the probability assigned to a production, X ! Y 1 . . . <p> Baker [4] and Kupiec [39]), or it can be trained in a constrained mode, maximizing the probability of the parse trees in a parsed corpus (e.g. Black et.al. [10] and Schabes and Pereira <ref> [48] </ref>). More evidence that the availability of corpora has influenced the direction of research is in the study of parsing tagged sentences using statistical methods (Magerman and Marcus [41], Brill [16], and Bod [12]). The motivation behind this work was twofold. <p> Based on the number and types of errors, these sentences clearly had not been corrected by treebankers. Using Data Representative of the Problem Recently, there have been a number of papers, such as Schabes and Pereira <ref> [48] </ref>, Brill [16], and Bod [12], citing work based on parsing using sentences tagged for part of speech. While it is true that part-of-speech taggers have very low error rates, some below 3%, parsing from manually assigned tags is not the same as parsing from automatically assigned tags. <p> By some measures, in terms of both technology and performance, it is an improvement over the state-of-the-art in parsing. The state-of-the-art in statistical parsing technology includes P-CFGs trained using the Inside-Outside algorithm (Schabes and Pereira <ref> [48] </ref>, Kupiec [39], and Black, Garside, and Leech [7], parsers which generate unlabeled bracketing using correct tag sequences as input (Brill [16], Schabes and Pereira [48], and grammar induction strategies which attempt to acquire grammars by extracting context-free productions from treebanks. <p> The state-of-the-art in statistical parsing technology includes P-CFGs trained using the Inside-Outside algorithm (Schabes and Pereira <ref> [48] </ref>, Kupiec [39], and Black, Garside, and Leech [7], parsers which generate unlabeled bracketing using correct tag sequences as input (Brill [16], Schabes and Pereira [48], and grammar induction strategies which attempt to acquire grammars by extracting context-free productions from treebanks.
Reference: [49] <author> F. C. N. Pereira and D. H. D. Warren. </author> <title> Definite clause grammars for language analysis a survey of the formalism and a comparison with augmented transition networks. </title> <journal> Artificial Intelligence, </journal> <volume> Vol. 13, </volume> <pages> pages 231-278, </pages> <year> 1980. </year>
Reference-contexts: a solution to any others. 2.2 Computational Grammatical Formalisms Perhaps in response to the ad-hoc nature of ATNs, in the early 1980s a number of grammatical formalisms appeared which attempted to account for the power of the functional augmentations of ATNs in a more formal theoretical framework: Definite-Clause Grammar (DCG) <ref> [49] </ref>, Functional Unification Grammar (FUG) [38], Lexical-Functional Grammar (LFG) [37], Generalized Phrase Structure Grammar (GPSG) [25], and others. 1 This is a bit of an oversimplification. SHRDLU implemented a set of predicates which were defined to be the blocks-world. There were many gaps in the representation of the blocks-world.
Reference: [50] <author> A. B. Poritz. </author> <title> Hidden markov models: A guided tour. </title> <booktitle> Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <year> 1988, 1988. </year>
Reference-contexts: For proofs concerning this and other properties of the forward-backward algorithm, see Poritz <ref> [50] </ref>. The intuition behind the F-B algorithm is that when there are multiple paths from an initial state to a goal state, the different paths should contribute to the model according to their relative probabilities.
Reference: [51] <author> V. Pratt. </author> <title> A linguistics oriented programming language. </title> <booktitle> Proceedings of the Third International Joint Conference on Artificial Intelligence, </booktitle> <year> 1973. </year>
Reference-contexts: Y n ; represents the probability that the non-terminal category X is rewritten as Y 1 . . . Y n in the parse of a sentence. P-CFGs have been around since at least the early 1970s (e.g. Pratt <ref> [51] </ref>); but using very large corpora and the inside-outside algorithm, they can now be trained automatically, instead of assigning the parameters by hand. A P-CFG model can be trained in a completely unsupervised mode, by considering all possible parses of the sentences in a training corpus (e.g.
Reference: [52] <author> B. Raphael. </author> <title> Sir: A computer program for semantic information retrieval. </title> <booktitle> Semantic Information Processing, </booktitle> <pages> pages 33-145, </pages> <year> 1968. </year> <note> BIBLIOGRAPHY 141 </note>
Reference-contexts: The failure of superficial "dictionary lookup" solutions to the MT problem suggested the need for a higher level of knowledge representation. The work in the 1960s on natural language processing consisted primarily of keyword analysis or pattern matching. Systems such as Green's BASEBALL [26], Raphael's SIR <ref> [52] </ref>, and Bobrow's STUDENT [11] search for simple patterns or regular expressions which indicate useful information. All information in the text which does not conform to these patterns is ignored.
Reference: [53] <author> P. </author> <title> Resnik. Wordnet and distributional analysis: A class-based approach to lexical discovery. Statistically-Based NLP Techniques, </title> <booktitle> AAAI-92, </booktitle> <year> 1992. </year>
Reference-contexts: Finally, with greater access to very large parsed corpora, training parsing models is possible even with more direct estimation methods. 2.5.3 Other Work in Statistical NL Statistical natural language research extends far beyond tagging and parsing. Work on language acquisition attempts to discover semantic selection preferences (e.g. Resnik <ref> [53] </ref>) and verb subcategorization information (e.g. Brent [14]). Schuetze [57] has developed a vector-based representation for language which aids in word sense disambiguation. A significant application of statistical modeling technology is the Candide system [17], developed by the IBM Machine Translation group.
Reference: [54] <author> N. Sager. </author> <title> Natural Language Information Processing. </title> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <address> Reading, Massachusetts, </address> <year> 1981. </year>
Reference-contexts: RELATED WORK [32] and NYU's PROTEUS system [27]. Both of these systems are descendants of the Linguistic String Project (LSP) <ref> [54] </ref>, an early effort to develop grammar-based parsers for sublanguages. Both systems use a string grammar, consisting of a context-free grammar backbone augmented with functional restrictions on the application of the grammar's productions. Although the grammars in these two systems are similar, they handle ambiguity resolution in very different ways.
Reference: [55] <author> Y. Schabes and R. Waters. </author> <title> Stochastic lexicalized context-free grammar. </title> <booktitle> Proceedings of the August 1993 International Workshop on Parsing Technologies, </booktitle> <year> 1993. </year>
Reference-contexts: None of these parsing techniques considers lexical information in its models, with the exception of probabilistic lexicalized tree-adjoining grammar (Schabes and Waters <ref> [55] </ref>), which has yet to be implemented and tested on a large scale.
Reference: [56] <author> R. C. Schank. </author> <title> Sam a story understander. </title> <type> Research Report 43, </type> <year> 1975. </year>
Reference-contexts: Chomsky's work in the late 1950s and early 1960s in transformational grammars and formal language theory [19] [20] provided much of the machinery for the next generation of natural language processing research. Context-free grammar parsers, such as Lindsay's SAD-SAM <ref> [56] </ref>, took advantage of Chomsky's formalization to improve upon the simpler single-state and finite-state models. The SAD component of this system generates full syntactic analyses for sentences, accepting a vocabulary of about 1700 words and a subset of English grammar.
Reference: [57] <author> Hinrich Schutze. </author> <title> Distributed syntactic representations with an application to part-of-speech tagging. </title> <booktitle> In Proceedings of the IEEE International Conference on Neural Networks, </booktitle> <year> 1993. </year>
Reference-contexts: Work on language acquisition attempts to discover semantic selection preferences (e.g. Resnik [53]) and verb subcategorization information (e.g. Brent [14]). Schuetze <ref> [57] </ref> has developed a vector-based representation for language which aids in word sense disambiguation. A significant application of statistical modeling technology is the Candide system [17], developed by the IBM Machine Translation group.
Reference: [58] <author> P. Sells. </author> <title> Lectures on Contemporary Syntactic Theories. </title> <publisher> CSLI, Stanford, </publisher> <address> Califor-nia, </address> <year> 1985. </year>
Reference-contexts: Some examples of this type of system development are Unisys' PUNDIT system 2 Excellent descriptions of these theories can be found in Sells <ref> [58] </ref> and Shieber [62]. 10 CHAPTER 2. RELATED WORK [32] and NYU's PROTEUS system [27]. Both of these systems are descendants of the Linguistic String Project (LSP) [54], an early effort to develop grammar-based parsers for sublanguages.
Reference: [59] <author> Stephanie Seneff. Tina: </author> <title> A probabilistic parser for speech understanding systems. </title> <booktitle> Proceedings of the August 1989 International Workshop on Parsing Technologies, </booktitle> <year> 1989. </year>
Reference-contexts: This declarative knowledge takes the form of semantic restrictions (e.g. Hirschman et.al. [32]), free-form logical expressions (e.g. Alshawi et.al. [1]), or a combination of these methods (e.g. Black, Garside, and Leech [7]). Some have used probabilistic (e.g. Seneff <ref> [59] </ref>) or non-probabilistic (e.g. Hobbs et.al. [33]) weighting systems to accumulate disambiguation decisions throughout the processing of a sentence into a single score for each interpretation. Each of these approaches has resulted in some degree of success in accurately parsing sentences.
Reference: [60] <author> C. E. Shannon. </author> <title> Prediction and entropy of printed english. </title> <journal> Bell Systems Technical Journal, </journal> <volume> Vol. 30, </volume> <pages> pages 50-64, </pages> <year> 1951. </year>
Reference-contexts: Finally, I address some of the problems associated with maximum-likelihood (M-L) decision tree training. 3.1 Information Theory The algorithms for growing and smoothing decision trees depend upon the quantification of information. Information theory, developed by Shannon <ref> [60] </ref> and Wiener [66], is concerned with the compression of information when transmitted through a channel. Information theory formalizes the notion of information in terms of entropy. In this section, I introduce some basic concepts from information theory which are necessary 20 CHAPTER 3.
Reference: [61] <author> R. A. Sharman, F. Jelinek, and R. Mercer. </author> <title> Generating a grammar for statistical training. </title> <booktitle> Proceedings of the June 1990 DARPA Speech and Natural Language Workshop, </booktitle> <year> 1990. </year>
Reference-contexts: Sharman, Jelinek and Mercer <ref> [61] </ref>, Black, Garside, and Leech [10]), which assigns a probability to each rule in a context-free grammar and computes the probability of the parse tree by assuming that each grammar rule application is independent of all other rule applications in the sentence.
Reference: [62] <author> S. Shieber. </author> <title> An Introduction to Unification-based Approaches to Grammar. </title> <publisher> CSLI, Stanford, </publisher> <address> California, </address> <year> 1986. </year>
Reference-contexts: Some examples of this type of system development are Unisys' PUNDIT system 2 Excellent descriptions of these theories can be found in Sells [58] and Shieber <ref> [62] </ref>. 10 CHAPTER 2. RELATED WORK [32] and NYU's PROTEUS system [27]. Both of these systems are descendants of the Linguistic String Project (LSP) [54], an early effort to develop grammar-based parsers for sublanguages.
Reference: [63] <author> W. Weaver. </author> <title> Translation. </title> <booktitle> Machine Translation of Languages, </booktitle> <pages> pages 15-23, </pages> <year> 1955. </year> <note> 142 BIBLIOGRAPHY </note>
Reference-contexts: Finally, I discuss the development of decision tree modeling, from early AI machine learning to current speech recognition and natural language applications. 2.1 Early Natural Language Parsing Automatic natural language processing research can be traced back to the early 1950s, to Weaver's early work on machine translation (MT) <ref> [63] </ref>. The failure of superficial "dictionary lookup" solutions to the MT problem suggested the need for a higher level of knowledge representation. The work in the 1960s on natural language processing consisted primarily of keyword analysis or pattern matching.
Reference: [64] <author> R. Weischedel, S. Ayuso, D. amd Boisen, H. Fox, and R. Ingria. </author> <title> A new approach to text understanding. </title> <booktitle> Proceedings of the February 1992 DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 316-322, </pages> <year> 1992. </year>
Reference-contexts: While this model may offend the francophile, it has resulted in a state-of-the-art translation system. Following this model, researchers at BBN are working on generating semantic analyses for sentences using statistical models. Their Probabilistic Language Understanding Model <ref> [64] </ref> defines a semantic language and attempts to translate the natural language sentence into the semantic language. A system developed at CRIN, a Cana-dian natural language company, takes a similar approach to the problem of database retrieval, using the SQL database query language as their semantic language.
Reference: [65] <author> J. Weizenbaum. </author> <title> Eliza a computer program for the study of natural language communication between man and machine. </title> <journal> CACM, </journal> <volume> Vol. 9, </volume> <pages> pages 36-45, </pages> <year> 1966. </year>
Reference-contexts: All information in the text which does not conform to these patterns is ignored. This attribute makes pattern-matching systems more robust, but it also makes them easy to identify, as they will happily process gibberish as long as some subset of the input matches a known pattern. Weizenbaum's ELIZA <ref> [65] </ref> is a famous example of this "technology," reviled in some corners of the community for falsely encouraging the already widely-held belief that natural language processing would be solved within a decade.
Reference: [66] <author> N. Wiener. </author> <title> The Extracpolation, Interpolation, and Smoothing of Stationary Time Series. </title> <publisher> John WIley and Sons, </publisher> <address> New York, New York, </address> <year> 1949. </year>
Reference-contexts: Finally, I address some of the problems associated with maximum-likelihood (M-L) decision tree training. 3.1 Information Theory The algorithms for growing and smoothing decision trees depend upon the quantification of information. Information theory, developed by Shannon [60] and Wiener <ref> [66] </ref>, is concerned with the compression of information when transmitted through a channel. Information theory formalizes the notion of information in terms of entropy. In this section, I introduce some basic concepts from information theory which are necessary 20 CHAPTER 3. STATISTICAL DECISION TREE MODELING to understand decision trees.
Reference: [67] <author> T. Winograd. </author> <title> Understanding Natural Language. </title> <publisher> Academic Press, </publisher> <address> New York, New York, </address> <year> 1972. </year>
Reference-contexts: In contrast to the decomposition of syntax and semantics in SAD-SAM, Halliday's 8 CHAPTER 2. RELATED WORK systemic grammar [28] proposed a formalism that encoded the functional relationships in a sentence. His theory was illustrated in Winograd's blocks-world system, SHRDLU <ref> [67] </ref>. SHRDLU demonstrated the effectiveness of functional representations on a small problem, but it also implicitly revealed one of its weaknesses. Systemic grammar works when applied to the very constrained blocks-world because the relationships among objects and the possible actions could be completely and unambiguously specified.
Reference: [68] <author> W. A. Woods. </author> <title> Transition network grammars for natural language analysis. </title> <journal> CACM, </journal> <volume> Vol. 13, </volume> <pages> pages 457-471, </pages> <year> 1970. </year>
Reference-contexts: The development of Augmented Transition Networks (ATNs) by Woods in the early 1970s <ref> [68] </ref> improved upon the power of regular expressions and context-free grammars by augmenting a finite-state automaton with register variables and functional constraints, allowing an ATN to consider more contextual information when generating an analysis while maintaining the computational simplicity of a finite-state machine.
Reference: [69] <author> V. Zue, J. Glass, D. Goodine, H. Leung, M. Phillips, J. Polifroni, and S. Seneff. </author> <title> The voyager speech understanding system: A progress report. </title> <booktitle> Proceedings of the October 1989 DARPA Speech and Natural Language Workshop, </booktitle> <pages> pages 51-59, </pages> <year> 1989. </year>
Reference-contexts: Similarly, the grammar-based systems with complete syntactic, semantic and pragmatic analysis designed for spoken language applications, such as SRI's Core Language Engine (CLE) [1] and MIT's VOYAGER system <ref> [69] </ref>, have been dominated by newer finite-state template-based systems. These template-based systems, using essentially the same technology as exhibited in Schank's SAD analyzer, benefits from a data-driven design methodology to achieve better coverage and accuracy. <p> These experiments evaluated for what percentage of the test sentences the parser would be able to select a correct parse from the space of grammatical parses. In the original experiment, the Pearl parser was trained on 1,100 sentences from the Voyager direction-finding domain <ref> [69] </ref> and tested on 40 test sentences from the same domain. Of these 40 sentences, Pearl produced parse trees for 38 of them, and 35 of these parse trees were equivalent to the correct parse produced by Pundit, for an overall accuracy rate of 88%.
References-found: 69

