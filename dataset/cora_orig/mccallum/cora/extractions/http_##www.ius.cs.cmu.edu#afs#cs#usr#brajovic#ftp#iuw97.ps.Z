URL: http://www.ius.cs.cmu.edu/afs/cs/usr/brajovic/ftp/iuw97.ps.Z
Refering-URL: http://www.ius.cs.cmu.edu/afs/cs/usr/brajovic/www/lab/vlsi.html
Root-URL: 
Title: Abstract  
Abstract: The need for robust selfcontained and low-latency vision systems is growing: high speed visual servo-ing and visionbased human computer interface. Conventional vision systems can hardly meet this need because 1) the latency is incurred in a data transfer and computational bottlenecks, and 2) there is no topdown feedback to adapt sensor performance for improved robustness. In this paper we present a tracking computational sensor a VLSI implementation of a sensory attention. The tracking sensor focuses attention on a salient feature in its receptive field and maintains this attention in the world coordinates. Using both low-latency massive parallel processing and topdown sensory adaptation, the sensor reliably tracks features of interest while it suppresses other irrelevant features that may interfere with the task at hand. 
Abstract-found: 1
Intro-found: 1
Reference: [Allport, 1989] <author> Allport, A. </author> <title> Visual Attention, Foundation of Cognitive Science, </title> <editor> M. Posner (ed.), </editor> <publisher> MIT Press, </publisher> <year> 1989, </year> <pages> pp. 631682. </pages>
Reference-contexts: So it does in machines. Attention funnels only relevant information and protects the limited communication and processing resources from the information overload. Second, it has been shown that the visual attention improves performance, and is needed for maintaining coherent behavior while interacting with the environment (i.e., attentionforaction) <ref> [Allport, 1989] </ref>. Unlike eye movement (i.e., overt shifts), the attention shifts (i.e., covert shifts) do not require any motor action, but occur internally on a fixed retinal image. For this reason, attention shifts are faster and play an important role in lowlatency vision systems. <p> Depending on the biasing condition, the circuit is able to roam between the peaks in the stationary saliency map. In the attentionforaction model, Allport sug gested that attention goes beyond protecting the limited processing resources during complex object recognition: attention is needed to ensure behavioral coherence <ref> [Allport, 1989] </ref>. Since visual perception is the means for allowing a subject to interact with the environment (e.g., manipulate, avoid, etc.), it must produce actions consistent with the subjects goals. Selective processing is necessary in order to isolate the information that defines parameters for the appropriate action.
Reference: [Andreou et al. 1992] <author> A.G. Andreou, et al., </author> <title> Current-Mode Subthreshold MOS Circuits for Analog VLSI Neural Systems, </title> <journal> IEEE Trans. on NN, </journal> <volume> Vol. 2, No. 2, </volume> <pages> pp. 205-213, </pages> <month> March </month> <year> 1992 </year>
Reference-contexts: The generated photo currents are fed to the winnertakeall (WTA) circuit which is responsible for the detection of the maximum point. The selected location is called a feature. Our design is based on a WTA circuit originally proposed in <ref> [Andreou et al. 1992] </ref> and [Lazzaro et al., 1988] shown is Figure 1. Currents are the input photo currents, while currents are the outputs of the WTA circuit. The cell receiving the largest photo current responds with nonzero output current , while other cells respond with zero currents, i.e., .
Reference: [Brajovic and Kanade, 1994] <author> Brajovic, V. and T. Kanade, </author> <title> Computational Sensors for Global Operations, </title> <booktitle> IUS Proceedings, </booktitle> <pages> pp. 621-630, </pages> <year> 1994. </year>
Reference-contexts: Our recent work has been concerned with efficient implementation of global operations over a large group of image data using the computational sensor paradigm <ref> [Brajovic and Kanade, 1994] </ref>. We have formulated two mechanisms for implementing global operations in computational sensors: (1) intensitytotime processing paradigm [Brajovic and Kanade, 1996], and (2) sensory attention presented in this paper. 2. <p> The static performance has been tested on an early 1D prototype with 20 cells fabricated in 2m CMOS technology. The findings have been reported earlier in <ref> [Brajovic and Kanade, 1994] </ref>. The temporal response of the WTA circuit is important when tracking moving features within dynamic saliency map.
Reference: [Brajovic and Kanade, 1996] <author> Brajovic, V. and T. Kanade, </author> <title> A Sorting Image Sensor: An Example of Massively Parallel Intensity-to-Time Processing for Low-Latency Computational Sensors, </title> <booktitle> Proc. of the 1996 IEEE Intl. Conf. on Robotics and Automation, </booktitle> <address> April 1996, Minneapolis, MN. </address>
Reference-contexts: Our recent work has been concerned with efficient implementation of global operations over a large group of image data using the computational sensor paradigm [Brajovic and Kanade, 1994]. We have formulated two mechanisms for implementing global operations in computational sensors: (1) intensitytotime processing paradigm <ref> [Brajovic and Kanade, 1996] </ref>, and (2) sensory attention presented in this paper. 2. Approach The sensory attention is based on the premise that salient features within the retinal image represent important global features of the entire image.
Reference: [DeWeerth, 1992] <author> DeWeerth, </author> <title> S.P., Analog VLSI Circuits for Stimulus Localization and Centroid Computation, </title> <booktitle> Intl. Jour. of Comp. Vision, </booktitle> <volume> Vol. 8, No. 3, </volume> <year> 1992, </year> <pages> pp. 191-202. </pages>
Reference-contexts: A digital on-chip decoder easily converts this code to any other binary code such as a natural binary or BCD code. In addition, there are efficient analog means for winner localization <ref> [DeWeerth, 1992] </ref>.
Reference: [Horn, 1986] <author> Horn, B., </author> <title> Robot Vision, </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: By reading these peripheral components, the location of the winning cell is found. The WTA cells can be physically laid out in a twodimensional array. Using the method of projections <ref> [Horn, 1986] </ref>, the position of this current in two dimensions is found by solving two onedimensional problems. Two copies of the output current are summed into the horizontal and vertical bus, respectively. The total current in these buses represents the desired projections onto the x and y axes.
Reference: [Kanade and Bajcsy, 1993] <author> Kanade, T. and R. </author> <title> Bajcsy, Computational Sensors: A Report from DARPA workshop, </title> <booktitle> IUS Proceedings, </booktitle> <year> 1993. </year>
Reference-contexts: 1. Introduction The computational sensor paradigm <ref> [Kanade and Bajcsy, 1993] </ref> has the potential to greatly reduce latency and provide topdown sensory adaptation to vision systems. <p> For this reason, attention shifts are faster and play an important role in lowlatency vision systems. It is interesting to note that foveating computational sensors <ref> [Kanade and Bajcsy, 1993] </ref> try to emulate this kind of data compression. For example, Van der Spiegels logpolar sensor samples images within fovea with high acuity, while maintaining sparse representation at the periphery. This sensor simulates overt shifts, since it requires motor action for foveating.
Reference: [Koch and Ullman, 1987] <author> Koch, C. and S. Ullman, </author> <title> Shifts in Selective Visual Attention: Toward the Underlying Neural Circuitry. </title> <booktitle> In L.M. Vaina (edt.), Matters of Intelligence, </booktitle> <publisher> Reidel Publishing, </publisher> <year> 1987, </year> <pages> pp. 115-141. </pages>
Reference-contexts: To apply attention selection in machines, several issues must be solved: (1) the problem of selecting an interesting location, (2) the problem of shifting to another location, and (3) the problem of transferring local data for further processing. In a very inuential paper <ref> [Koch and Ullman, 1987] </ref>, Koch and Ullman address these issues. The selection process utilizes a saliency map that encodes conspicuousness or the level of interest throughout the retinal image. The saliency map can be derived from image features, including: intensity, color, spatial and temporal derivatives, motion, and orientation.
Reference: [Lazzaro et al., 1988] <author> J. Lazzaro, S. Ryckebusch, M.A. Mahowald and C. Mead, </author> <title> Winner-Take-All Networks of O(n) Complexity, </title> <booktitle> in Adv. in Neural Inf. Proc. Sys. </booktitle> <volume> Vol. </volume> <pages> 1, </pages> <address> D. Tourestzky, </address> <publisher> ed., </publisher> <pages> pp. 703-711, </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: The generated photo currents are fed to the winnertakeall (WTA) circuit which is responsible for the detection of the maximum point. The selected location is called a feature. Our design is based on a WTA circuit originally proposed in [Andreou et al. 1992] and <ref> [Lazzaro et al., 1988] </ref> shown is Figure 1. Currents are the input photo currents, while currents are the outputs of the WTA circuit. The cell receiving the largest photo current responds with nonzero output current , while other cells respond with zero currents, i.e., .
Reference: [Milanese, 1993] <author> R. Milanese, </author> <title> Detecting Salient regions in an Image: From Biological Evidence to Computer Implementation, </title> <type> Ph.D., </type> <institution> Dept. of Com. Sci., U. of Genova, Switzerland, </institution> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: The problem of shifting to another location is somewhat more challenging. It is observed in humans that interesting visual stimulation initially (i.e., during the first 100ms) captures the attention; later (i.e., after 300ms) it has inhibitory effects which can last up to 1.5 seconds <ref> [Milanese, 1993] </ref>. The inhibitory effect prevents the subject from returning to previously visited locations. The inhibition is stored in environmental coordinates rather than in image coordinates; therefore, reliable operation is maintained even in the presence of ocular or object movement. <p> We need more control over attention shifts, possibly by employing the central inhibition mechanism in combination with the voluntary focus of attention directed toward desired goals. For robust operation, such shifts must maintain the location of attention in the presence of ocular or object motion <ref> [Milanese, 1993] </ref>. 3. Implementation In the prototype implementation of the sensory attention proposed by this work, our concern is not how to compute the saliency map, but rather how to quickly and reliably locate and maintain an interesting location in the saliency map.
Reference: [Morris and DeWeerth, 1996] <author> T.G. Morris and S.P. DeWeerth, </author> <title> Analog VLSI Circuits for Covert Attentional Shifts, MicroNeuro 1996, Lausanne, Switzerland. attention shifts as a function of the relative feature intensity. dynamic rate feature intensity </title>
Reference-contexts: The local inhibition mechanism mimics the automatic attention shift, while the central mechanism can initiate voluntary attention shifts. Recently, Morris et al. <ref> [Morris and DeWeerth, 1996] </ref> reported an analog VLSI circuit implementation of covert attention shifts as suggested by the Koch and Ullman model. <p> It is not hard to imagine that if the attention is allowed to arbitrarily roam from one location to another, as suggested by Koch and Ull-mans model and implemented in <ref> [Morris and DeWeerth, 1996] </ref>, it may take a long time before the global processor encounters the relevant information for an appropriate action. We need more control over attention shifts, possibly by employing the central inhibition mechanism in combination with the voluntary focus of attention directed toward desired goals.
References-found: 11

