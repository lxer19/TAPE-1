URL: file://ftp.it.kth.se/Reports/paradis/FunDparLang.ps.Z
Refering-URL: http://www.it.kth.se/~lisper/
Root-URL: http://www.it.kth.se
Email: perham@nada.kth.se  lisper@it.kth.se  
Title: On the Relation between Functional and Data Parallel Programming Languages  
Author: Per Hammarlundy and Bjorn Lisper 
Address: S-100 44 Stockholm, SWEDEN  204, S-164 40 Kista, SWEDEN  
Affiliation: ySANS|Studies of Artificial Neural Systems NADA|Department or Numerical Analysis and Computing Science Royal Institute of Technology,  Department of Teleinformatics Royal Institute of Technology, Electrum  
Abstract: Data parallel programming is becoming an increasingly important tool for exploiting parallelism in data-intensive applications, especially on SIMD and vector computers. Many algorithms appearing in such applications are very succinctly expressed in data parallel languages: this indicates that data parallel programming can be a powerful abstract programming paradigm rather than just a syntax for explicit programming of SIMD computers. The data parallel languages in practical use today are, however, exponents of exactly the latter point of view: even though they incorporate some elements of abstraction, their semantics are all to some extent based on a SIMD execution model. Therefore it is hard to use these languages to express algorithms in the problem domain in an abstract, machine-independent way. This is likely to make programming in these languages more error-prone and programs less portable than if they had been designed with a more clean-cut abstract semantics. Here, we present some mathematical definitions of data parallel primitives that can be used to guide the design of data parallel languages with a higher level of abstraction. The key idea is to view data parallel entities as tabulated functions where the tables are stored in a distributed fashion. Operations on data parallel entities are then simply operations on functions, just as operations in pure functional languages. An interesting observation is that also traditional data structures, like lists and arrays, are covered by our view. This illustrates the level of abstraction achieved. An especially interesting possibility is to integrate data parallel and higher order functional languages. Data parallel entities are then just a particular class of functions that can be represented in a particular way. We believe that such languages are very suitable as specification languages for data parallel algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Eugene Albert, Joan D. Lukas, and Guy L. Steele Jr. </author> <title> Data Parallel Computers and the FORALL Statement. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13 </volume> <pages> 185-192, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: With -abstraction we can, however, specify the indented meaning either as hi; ji:(m (i; j) + v (i)) or as hi; ji:(m (i; j) + v (j)). -abstraction and the FORALL-construct The FORALL-construct in Fortran 8x, HPF, and CM Fortran <ref> [1, 15, 33] </ref> is an imperative special case of the -abstraction.
Reference: [2] <author> Steven Anderson and Paul Hudak. </author> <title> Compilation of Haskell array comprehensions for scientific computing. </title> <booktitle> In Proceedings of the ACM SIGPLAN'90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 137-149. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: Functional programs are also amenable to formal transformations [20], which facilitates the transformation of abstract algorithm specifications to functionally equivalent programs closer to the target architecture. There is, however, considerable research in compiling functional or nearly functional languages with data parallel flavor to parallel and vector machines <ref> [2, 6, 7, 8, 14, 25, 32] </ref>. An interesting area for further research is how their efforts can be extended to higher-order lazy data parallel functional languages. Acknowledgements We would like to thank Claes Thornberg, Fredrik Nou, and the anonymous referees for their valuable comments.
Reference: [3] <author> John Backus. </author> <title> Can Programming Be Liberated from the von Neuman Style? A Functional Style and Its Algebra of Programs. </title> <journal> Communications of the ACM, </journal> <volume> 21(8) </volume> <pages> 613-641, </pages> <month> August </month> <year> 1978. </year>
Reference-contexts: SISAL is a call-by-value functional language intended for scientific computing applications. EPL is an equational language for the same purposes. Like APL, they employ the array as the potentially parallel data type. Backus' FP <ref> [3] </ref> should also be mentioned here, since it has operations on sequences that clearly can be seen as data parallel.
Reference: [4] <author> Richard Bird. </author> <title> Constructive functional programming. </title> <editor> In M. Broy, editor, </editor> <booktitle> Marktoberdorf International Summer school on Constructive Methods in Computer Science, NATO Advanced Science Institute Series. </booktitle> <publisher> Springer Ver-lag, </publisher> <year> 1989. </year>
Reference-contexts: A virtue of this theory is the consistent han dling of singularities, e.g. empty arrays. Another example is the Bird-Meertens formalism. Here an algebra with unary and binary functions form a base for a set of theories for different data types <ref> [4] </ref>. Parallelism comes from evaluating the operations over the data types in parallel; Skillicorn [30] shows how parallel evaluation is done over lists. <p> For arrays and lists the enumeration is most often given implicitly by the less-than or greater-than ordering on the respective integer intervals that form their index sets. The "foldl " and "foldr " primitives in the Bird-Meertens formalism <ref> [4] </ref> are "forwards" and "backwards" reductions over lists. These can be seen as specialized instances of our more general operations. Reduction and scan according to Definition 5 are opera tions on data fields. They are defined only if their arguments 4 have certain properties.
Reference: [5] <editor> Dines Bjorner, Andrei P. Ershov, and Neil D. Jones, editors. </editor> <title> Partial Evaluation and Mixed Computation, </title> <address> Amsterdam, 1988. </address> <publisher> IFIP, North-Holland. </publisher>
Reference-contexts: The function can be completely instantiated, i.e. the value of the function is calculated and stored for all valid points in the index domain. Specializing a function is for pure functional languages called partial evaluation <ref> [5] </ref>, and can sometimes result in a substantial speedup. The "trick" of specializing a function with respect to certain arguments is especially beneficial on a parallel machine where the number of processing units is close to the number of resulting specialized functions.
Reference: [6] <author> Guy E. Blelloch and Gary W. Sabot. </author> <title> Compiling Collection-Oriented Languages onto Massively Parallel Computers. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8 </volume> <pages> 119-134, </pages> <year> 1990. </year>
Reference-contexts: Functional programs are also amenable to formal transformations [20], which facilitates the transformation of abstract algorithm specifications to functionally equivalent programs closer to the target architecture. There is, however, considerable research in compiling functional or nearly functional languages with data parallel flavor to parallel and vector machines <ref> [2, 6, 7, 8, 14, 25, 32] </ref>. An interesting area for further research is how their efforts can be extended to higher-order lazy data parallel functional languages. Acknowledgements We would like to thank Claes Thornberg, Fredrik Nou, and the anonymous referees for their valuable comments.
Reference: [7] <author> Timothy A. Budd. </author> <title> A New Approach to Vector Code Generation for Applicative Languages. </title> <type> Technical report, </type> <institution> Department of Computer Science, Oregon State University, Corvallis, Oregon 97331, </institution> <month> August </month> <year> 1988. </year>
Reference-contexts: Functional programs are also amenable to formal transformations [20], which facilitates the transformation of abstract algorithm specifications to functionally equivalent programs closer to the target architecture. There is, however, considerable research in compiling functional or nearly functional languages with data parallel flavor to parallel and vector machines <ref> [2, 6, 7, 8, 14, 25, 32] </ref>. An interesting area for further research is how their efforts can be extended to higher-order lazy data parallel functional languages. Acknowledgements We would like to thank Claes Thornberg, Fredrik Nou, and the anonymous referees for their valuable comments.
Reference: [8] <author> Timothy A. Budd. </author> <title> Composition and Compilation in Functional Programming Languages. </title> <type> Technical report, </type> <institution> Department of Computer Science, Oregon State University, Corvallis, Oregon 97331, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: Functional programs are also amenable to formal transformations [20], which facilitates the transformation of abstract algorithm specifications to functionally equivalent programs closer to the target architecture. There is, however, considerable research in compiling functional or nearly functional languages with data parallel flavor to parallel and vector machines <ref> [2, 6, 7, 8, 14, 25, 32] </ref>. An interesting area for further research is how their efforts can be extended to higher-order lazy data parallel functional languages. Acknowledgements We would like to thank Claes Thornberg, Fredrik Nou, and the anonymous referees for their valuable comments.
Reference: [9] <author> R. M. Burstall and J. Darlington. </author> <title> A transformation system for developing recursive programs. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 24(1) </volume> <pages> 44-67, </pages> <month> January </month> <year> 1977. </year>
Reference-contexts: Since sets are unordered, this avoids the possible overspecification above. Formalism A more abstract approach to data parallelism is to define a formalism in which data parallel algorithms can be expressed. This makes it possible to transform programs in a provably correct way <ref> [9] </ref>, which is important when deriving correct parallel implementations. An example of such a formalism is Trenchard More, Jr's Array Theory [26]. This is an attempt to define an axiomatic theory of arrays. The axioms closely model the array concept of APL.
Reference: [10] <author> B. Carpentieri and Z. G. Mou. </author> <title> A formal approach to Divide-and-Conquer parallel computation and its applications on the Connection Machine. </title> <booktitle> In Proceedings of the First Italian Conference: Algorithms and Complexity, </booktitle> <pages> pages 13-44. </pages> <publisher> World Scientific Publ., </publisher> <month> October </month> <year> 1990. </year>
Reference-contexts: A different approach is Carpentieri's and Mou's algebraic model for Divide-and-Conquer algorithms [11]. Here, Divide-and-Conquer is expressed as a certain form of recursion. The parallel functional programming language Di-vacon <ref> [10] </ref> is based on this model: it is targeted towards efficient implementation of Divide-and-Conquer algorithms on hypercube SIMD architectures. 2 Preliminaries In this paper we will consider functions defined over some typed language.
Reference: [11] <author> B. Carpentieri and Z. G. Mou. </author> <title> Compile-time transformations and optimization of parallel Divide-and-Conquer algorithms. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 26(10) </volume> <pages> 19-28, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: A different approach is Carpentieri's and Mou's algebraic model for Divide-and-Conquer algorithms <ref> [11] </ref>. Here, Divide-and-Conquer is expressed as a certain form of recursion. The parallel functional programming language Di-vacon [10] is based on this model: it is targeted towards efficient implementation of Divide-and-Conquer algorithms on hypercube SIMD architectures. 2 Preliminaries In this paper we will consider functions defined over some typed language.
Reference: [12] <author> Siddharta Chatterjee, John R. Gilbert, Robert Schreiber, and Shang-Hua Teng. </author> <title> Automatic array alignment in data-parallel programs. </title> <booktitle> In Proceedings of the Twentieth Annual ACM SIGACT/SIGPLAN Symposium on Principles of Programming Languages, </booktitle> <address> Charleston, SC, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: Thus, the mapping of a data field to memory locations should enable such access patterns when possible. A discussion of mappings of data fields to memory is outside the scope of this paper. For work in this area, see for instance <ref> [12, 22] </ref>. 6 Conclusions Existing data parallel programming languages are often used in highly demanding production environments. They are, however, intended for particular hardware platforms and model the underlying hardware closely.
Reference: [13] <author> A.D. Falkoff and K.E. Iverson. </author> <title> The Design of APL. </title> <journal> IBM Journal of Research and Development, </journal> <pages> pages 324-333, </pages> <month> July </month> <year> 1973. </year>
Reference-contexts: More abstract notions of parallel data Some languages use more abstract data types over which data parallel operations can be performed: the best known is APL <ref> [13] </ref>. Incidentally, APL started out as a formalism used on the blackboard to describe parallel algorithms. APL uses the array as a carrier of parallel data. Arrays are either nested or have elements of some simple predefined basic data types, like integers and characters.
Reference: [14] <author> John T. Feo, David C. Cann, and Rodney R. Oldehoeft. </author> <title> A report on the SISAL language project. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 10 </volume> <pages> 349-366, </pages> <year> 1990. </year>
Reference-contexts: Arrays are either nested or have elements of some simple predefined basic data types, like integers and characters. Most array operators of APL can be evaluated in parallel. A modern successor to APL is J [21]. Two other languages with a more abstract view of parallel data are SISAL <ref> [14] </ref> and EPL [25, 32]. SISAL is a call-by-value functional language intended for scientific computing applications. EPL is an equational language for the same purposes. Like APL, they employ the array as the potentially parallel data type. <p> Functional programs are also amenable to formal transformations [20], which facilitates the transformation of abstract algorithm specifications to functionally equivalent programs closer to the target architecture. There is, however, considerable research in compiling functional or nearly functional languages with data parallel flavor to parallel and vector machines <ref> [2, 6, 7, 8, 14, 25, 32] </ref>. An interesting area for further research is how their efforts can be extended to higher-order lazy data parallel functional languages. Acknowledgements We would like to thank Claes Thornberg, Fredrik Nou, and the anonymous referees for their valuable comments.
Reference: [15] <author> High Performance Fortran Forum. </author> <title> High performance fortran language specification, </title> <note> version 1.0. Technical Report CRC-TR-92225, Center for Research on Parallel Computations, </note> <month> May </month> <year> 1993. </year>
Reference-contexts: With -abstraction we can, however, specify the indented meaning either as hi; ji:(m (i; j) + v (i)) or as hi; ji:(m (i; j) + v (j)). -abstraction and the FORALL-construct The FORALL-construct in Fortran 8x, HPF, and CM Fortran <ref> [1, 15, 33] </ref> is an imperative special case of the -abstraction.
Reference: [16] <author> Per Hammarlund and Anders Lansner. </author> <title> Implementations of very large recurrent ANNs on massively parallel SIMD computers. </title> <editor> In Igor Aleksander and John Taylor, editors, </editor> <booktitle> Proceedings of the 1992 International Conference on Artificial Neural Networks, </booktitle> <pages> pages 1287-1290, </pages> <address> Amsterdam, </address> <month> September </month> <year> 1992. </year> <title> ICANN-92, </title> <publisher> North-Holland. </publisher>
Reference-contexts: A parallel implementation will therefore benefit from communicating differences between new and old outputs rather than the absolute output levels: most differences will be zero and need therefore not be sent, which greatly reduces the communication and also the arithmetic needed when updating the activities. See <ref> [16] </ref>.
Reference: [17] <author> Robert Harper, Robin Milner, and Mads Tofte. </author> <title> The definition of Standard ML, </title> <type> version 2. Technical Report ECS-LFCS-88-62, </type> <institution> Dept. of Computer Science, Univ. of Edinburgh, </institution> <month> August </month> <year> 1988. </year> <month> 9 </month>
Reference-contexts: This is analogous to our use of the where-operation, or formally according to Definition 3: hi; ji:(m (i; j) + v (i)) n hi; ji:(1 i M ^ 1 j N ) Polymorphic Types We can allow a polymorphic type sys-tem much like in Standard ML <ref> [17] </ref>. Actually, this seems to be vital for increasing the level of abstraction and the clarity of algorithm descriptions.
Reference: [18] <author> W. Daniel Hillis and Guy L. Steele, Jr. </author> <title> Data parallel algorithms. </title> <journal> Comm. ACM, </journal> <volume> 29(12) </volume> <pages> 1170-1183, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: Also when the restrictions are dependent on data successively becoming known during evaluation, it can payoff to propagate restrictions as soon as they become known, and perform a runtime allocation of the resulting data fields. 3.5 Reductions and Scans Reductions and scans with respect to binary, associative operations <ref> [18] </ref> are important operations on data fields. Due to the associativity, they can always be implemented in logarithmic time. If the operation is not commutative, then some order is required on the elements of the data field to make the reductions and scans well-defined.
Reference: [19] <author> Seema Hiranandani, Joel Saltz, Piyush Merothra, and Harry Berryman. </author> <title> Performance of hashed cache data migration schemes on multicomputers. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 12(4) </volume> <pages> 415-422, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: Also, the problem how to map indices to processors efficiently is hard in general, especially since it may have to be done at run-time. (Here, recently developed techniques for run-time loop scheduling and dynamic handling of distributed data should however be applicable, <ref> [19, 29] </ref>.) Therefore, we believe that data parallel functional languages as sketched here have their most direct use as abstract specification languages for data parallel algorithms. They allow succinct descriptions, free from implementation details, where crucial properties of the algorithms can be pinpointed.
Reference: [20] <author> Paul Hudak. </author> <title> Conception, evolution, and application of functional programming languages. </title> <journal> ACM Computing Surveys, </journal> <volume> 21(3) </volume> <pages> 359-411, </pages> <year> 1989. </year>
Reference-contexts: They allow succinct descriptions, free from implementation details, where crucial properties of the algorithms can be pinpointed. Functional programs are also amenable to formal transformations <ref> [20] </ref>, which facilitates the transformation of abstract algorithm specifications to functionally equivalent programs closer to the target architecture. There is, however, considerable research in compiling functional or nearly functional languages with data parallel flavor to parallel and vector machines [2, 6, 7, 8, 14, 25, 32].
Reference: [21] <author> Kenneth E. Iverson. </author> <note> Programming in J. </note> <institution> Iverson Software Inc., Toronto, </institution> <year> 1991. </year>
Reference-contexts: APL uses the array as a carrier of parallel data. Arrays are either nested or have elements of some simple predefined basic data types, like integers and characters. Most array operators of APL can be evaluated in parallel. A modern successor to APL is J <ref> [21] </ref>. Two other languages with a more abstract view of parallel data are SISAL [14] and EPL [25, 32]. SISAL is a call-by-value functional language intended for scientific computing applications. EPL is an equational language for the same purposes.
Reference: [22] <author> K. Knobe, J. D. Lukas, and G. L. Steele Jr. </author> <title> Data Optimization: Allocation of Arrays to Reduce Communication on SIMD Machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8 </volume> <pages> 102-118, </pages> <year> 1990. </year>
Reference-contexts: Thus, the mapping of a data field to memory locations should enable such access patterns when possible. A discussion of mappings of data fields to memory is outside the scope of this paper. For work in this area, see for instance <ref> [12, 22] </ref>. 6 Conclusions Existing data parallel programming languages are often used in highly demanding production environments. They are, however, intended for particular hardware platforms and model the underlying hardware closely.
Reference: [23] <author> Anders Lansner and Orjan Ekeberg. </author> <title> A one-layer feedback, artificial neural network with a Bayesian learning rule. </title> <journal> Int. J. Neural Systems, </journal> <volume> 1(1) </volume> <pages> 77-87, </pages> <year> 1989. </year>
Reference-contexts: Actually, this seems to be vital for increasing the level of abstraction and the clarity of algorithm descriptions. Note that all the particular data parallel program constructs defined here, such as computable reductions, scans etc. are polymorphic higher-order operations. 4 An Example Artificial neural networks in the SANS model <ref> [23] </ref> can, when stimulated with an input, recall a stored pattern by an iterative relaxation method. Let I be the set of units in the network. The patterns are stored as biases fi i and weights w ij , for i; j 2 I.
Reference: [24] <author> Zohar Manna. </author> <title> Mathematical Theory of Computation. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1974. </year>
Reference-contexts: For any recursively defined function f we define [[f]] as the least fixpoint of its definition, completely in the standard way. See, for instance, <ref> [24] </ref>. 3 Abstract Definitions of Data Parallel Concepts We believe that a suitably abstract and yet simple view of data parallelism results if data parallel concepts are defined in terms of functions and operations on functions. <p> a simple case analysis from the definition of the conditional function, using the fact that b (i) and :b (i) are mutually exclusive, and that :: B ? ! B ? must be strict. (The latter is a consequence of ":" being a unary function over a flat domain, see <ref> [24, p. 360] </ref>.) So, for instance, if [[a]]# is a data field [18 : : : 4711] ! A and [[b]]# is a data field [1 : : : 17] ! A, then [[if i &gt; 17 then a else b]]# is a data field [1 : : : 4711] !
Reference: [25] <author> Bruce McKenney and Boleslaw Szymanski. </author> <title> Generating parallel code for simd machines. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 1(1) </volume> <pages> 59-73, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Most array operators of APL can be evaluated in parallel. A modern successor to APL is J [21]. Two other languages with a more abstract view of parallel data are SISAL [14] and EPL <ref> [25, 32] </ref>. SISAL is a call-by-value functional language intended for scientific computing applications. EPL is an equational language for the same purposes. Like APL, they employ the array as the potentially parallel data type. <p> Functional programs are also amenable to formal transformations [20], which facilitates the transformation of abstract algorithm specifications to functionally equivalent programs closer to the target architecture. There is, however, considerable research in compiling functional or nearly functional languages with data parallel flavor to parallel and vector machines <ref> [2, 6, 7, 8, 14, 25, 32] </ref>. An interesting area for further research is how their efforts can be extended to higher-order lazy data parallel functional languages. Acknowledgements We would like to thank Claes Thornberg, Fredrik Nou, and the anonymous referees for their valuable comments.
Reference: [26] <author> Trenchard More, Jr. </author> <title> Axioms and theorems for a theory of arrays. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 17(2) </volume> <pages> 135-175, </pages> <month> March </month> <year> 1973. </year>
Reference-contexts: This makes it possible to transform programs in a provably correct way [9], which is important when deriving correct parallel implementations. An example of such a formalism is Trenchard More, Jr's Array Theory <ref> [26] </ref>. This is an attempt to define an axiomatic theory of arrays. The axioms closely model the array concept of APL. A virtue of this theory is the consistent han dling of singularities, e.g. empty arrays. Another example is the Bird-Meertens formalism.
Reference: [27] <author> John R. Rose and Guy L. Steele Jr. </author> <title> C*: An Extended C Language for Data Parallel Programming. </title> <booktitle> In Proceedings of the 1987 Second International Conference on Supercomputing, </booktitle> <volume> volume II, </volume> <pages> pages 2-16. </pages> <booktitle> International Supercomputing Institute, </booktitle> <year> 1987. </year>
Reference-contexts: Semantics of imperative programs relies on a complete serialization of execution: otherwise, read/write conflicts can make the program nondeterministic. Thus, a problem of extended imperative languages is how to handle sequential code in parallel control structures modeling SIMD execution. (This is treated in <ref> [27] </ref>.) An example is the "parallel if"-statement, where a parallel condition is evaluated and the respective branch is taken for each location depending on the local outcome.
Reference: [28] <author> Gary W. Sabot. </author> <title> Paralation Lisp Reference Manual. </title> <type> Technical Report PL87-11, </type> <institution> Thinking Machines Corporation, Thinking Machines Corporation, </institution> <address> 245 First Street, Cambridge, Massachusetts 02142, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: For example, a two-dimensional data field f : (I 1 fi I 2 ) ! A can be seen as a curried data field f curried : I 1 ! (I 2 ! A). Conceptually this can be considered a data field containing data fields. In Paralation Lisp <ref> [28] </ref> parallel data, called paralations, are always one-dimensional; multi-dimensional data fields are constructed as nested paralations, which is basically currying.
Reference: [29] <author> Joel Saltz, Kathleen Crowley, Ravi Mirchandaney, and Harry Berryman. </author> <title> Run-time scheduling and execution of loops on message passing machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8(4) </volume> <pages> 303-312, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Also, the problem how to map indices to processors efficiently is hard in general, especially since it may have to be done at run-time. (Here, recently developed techniques for run-time loop scheduling and dynamic handling of distributed data should however be applicable, <ref> [19, 29] </ref>.) Therefore, we believe that data parallel functional languages as sketched here have their most direct use as abstract specification languages for data parallel algorithms. They allow succinct descriptions, free from implementation details, where crucial properties of the algorithms can be pinpointed.
Reference: [30] <author> David B. Skillicorn. </author> <title> Architecture-independent parallel computation. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 38-50, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Another example is the Bird-Meertens formalism. Here an algebra with unary and binary functions form a base for a set of theories for different data types [4]. Parallelism comes from evaluating the operations over the data types in parallel; Skillicorn <ref> [30] </ref> shows how parallel evaluation is done over lists. Formalisms using lists and arrays both suffer from the problem mentioned above: operations on lists and arrays are defined from the "natural" ordering on list and array elements, respectively, which can make them overspecified in the data parallel context.
Reference: [31] <author> Guy L. Steele Jr. and W. Daniel Hillis. </author> <title> Connection Machine Lisp: Fine-Grained Parallel Symbolic Processing. </title> <type> Technical Report PL86-2, </type> <institution> Thinking Machine Corporation, Thinking Machines Corporation, </institution> <address> 245 First Street, Cambridge, Massachusetts 02142, </address> <month> May </month> <year> 1986. </year>
Reference-contexts: Many data parallel operations can indeed be defined independently of any ordering of locations. Array and sequence primitives can therefore be overspecified when regarded as data parallel operations. A different view of parallel data appears in Connection Machine Lisp <ref> [31] </ref>. Here, the parallel data type is the xap-ping, which is a set of pairs of lisp objects where the first component of a pair cannot occur in another pair. Thus, xappings are really set-theoretical functions over a finite domain. Since sets are unordered, this avoids the possible overspecification above. <p> Cf. the corresponding definition for Crystal [37]: there, index sets are restricted to such constructed from integer intervals, cartesian product, coproduct (direct sum) and restriction with boolean predicate. Our definition is more general and is rather a mathematical counterpart to the xappings of Connection Machine Lisp <ref> [31] </ref>. Index sets for data fields correspond to "geometries" for data parallel entities in existing data parallel languages. For any data field f : I ! A we define D (f ) = I. Furthermore, if j =2 D (f ), we define f (j) = ?.
Reference: [32] <editor> Boleslaw Szymanski, editor. </editor> <booktitle> Parallel Functional Languages and Compilers. </booktitle> <publisher> ACM Press, </publisher> <year> 1991. </year>
Reference-contexts: Most array operators of APL can be evaluated in parallel. A modern successor to APL is J [21]. Two other languages with a more abstract view of parallel data are SISAL [14] and EPL <ref> [25, 32] </ref>. SISAL is a call-by-value functional language intended for scientific computing applications. EPL is an equational language for the same purposes. Like APL, they employ the array as the potentially parallel data type. <p> Functional programs are also amenable to formal transformations [20], which facilitates the transformation of abstract algorithm specifications to functionally equivalent programs closer to the target architecture. There is, however, considerable research in compiling functional or nearly functional languages with data parallel flavor to parallel and vector machines <ref> [2, 6, 7, 8, 14, 25, 32] </ref>. An interesting area for further research is how their efforts can be extended to higher-order lazy data parallel functional languages. Acknowledgements We would like to thank Claes Thornberg, Fredrik Nou, and the anonymous referees for their valuable comments.
Reference: [33] <institution> TMC, Thinking Machines Corporation, </institution> <address> 245 First Street, Cambridge, Massachusetts 02142. </address> <note> CM Fortran Reference Manual, 1.0 edition. </note> <year> 1991. </year>
Reference-contexts: With -abstraction we can, however, specify the indented meaning either as hi; ji:(m (i; j) + v (i)) or as hi; ji:(m (i; j) + v (j)). -abstraction and the FORALL-construct The FORALL-construct in Fortran 8x, HPF, and CM Fortran <ref> [1, 15, 33] </ref> is an imperative special case of the -abstraction.
Reference: [34] <institution> TMC, Thinking Machines Corporation, </institution> <address> 245 First Street, Cambridge, Massachusetts 02142. </address> <booktitle> Connection Machine: Parallel Instruction Set (Paris), </booktitle> <address> 6.1 edition, </address> <year> 1991. </year>
Reference-contexts: A reason why the extensions may not blend in is that they often closely model the particular hardware for which the parallel language is intended. *Lisp and C* are for instance modeled after the PARIS programming model <ref> [34] </ref> of the Connection Machine and must therefore behave according to the idiosyncrasies of that model. Programs in a data parallel language modeling a specific hardware architecture are usually not easy to port to other parallel computer architectures.
Reference: [35] <institution> TMC, Thinking Machines Corporation, </institution> <address> 245 First Street, Cambridge, Massachusetts 02142. </address> <booktitle> Connection Machine: Programming in C*, </booktitle> <address> 6.1 edition, </address> <year> 1991. </year>
Reference-contexts: The border between (1) and (2) is not sharp. Examples from the last class are often not completely implemented. Extensions to Sequential Languages Two examples of parallel languages extending sequential languages are *Lisp and C* for the Connection Machine, extending Common Lisp and ANSI C respectively <ref> [35, 36] </ref>. A benefit of this approach is that extensions of well-known languages become familiar for many users. A drawback is that the extensions may not blend in well with the original language and thus can cause semantical confusion.
Reference: [36] <institution> TMC, Thinking Machines Corporation, </institution> <address> 245 First Street, Cambridge, Massachusetts 02142. </address> <booktitle> Connection Machine: Programming in *Lisp, </booktitle> <address> 6.1 edition, </address> <year> 1991. </year>
Reference-contexts: The border between (1) and (2) is not sharp. Examples from the last class are often not completely implemented. Extensions to Sequential Languages Two examples of parallel languages extending sequential languages are *Lisp and C* for the Connection Machine, extending Common Lisp and ANSI C respectively <ref> [35, 36] </ref>. A benefit of this approach is that extensions of well-known languages become familiar for many users. A drawback is that the extensions may not blend in well with the original language and thus can cause semantical confusion. <p> Segmented scan is a variant where all partial reductions, in each respective partitioning, are paired with their original indices. Some data parallel languages, e.g. *Lisp on the Connection Machine <ref> [36] </ref>, support quite general segmented operations in this spirit. However, they have some restrictions that allow them to have an efficient implementation on the Connection Machine. Here, we give a definition of a general segmented scan.
Reference: [37] <author> J. Allan Yang and Young-il Choo. </author> <title> Data fields as parallel programs. </title> <booktitle> In Proceedings of the Second International Workshop on Array Structures, </booktitle> <address> Montreal, Canada, </address> <month> June/July </month> <year> 1992. </year> <month> 10 </month>
Reference-contexts: Our view is close to the ideas underlying the language Crystal <ref> [37] </ref>, but the concepts found there can be developed still further to provide abstract versions of most data parallel operations found in practice. <p> See Figure 1. The range is a cpo, and the index set may or may not be a cpo. Data fields provide an abstract model of data parallel values. Cf. the corresponding definition for Crystal <ref> [37] </ref>: there, index sets are restricted to such constructed from integer intervals, cartesian product, coproduct (direct sum) and restriction with boolean predicate. Our definition is more general and is rather a mathematical counterpart to the xappings of Connection Machine Lisp [31]. <p> The conventional solution is to restrict data field definitions to such expressed by a given set of finiteness-ensuring primitives. This is the route taken in e.g. Crystal <ref> [37] </ref>. The drawback of this approach is that one is forever confined to use these primitives. Data fields ranging over other index sets than those of the primitives cannot be directly expressed, but have to be mapped by hand into data fields constructed from the primitives.
References-found: 37

