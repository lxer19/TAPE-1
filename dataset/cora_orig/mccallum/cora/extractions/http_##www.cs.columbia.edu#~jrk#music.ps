URL: http://www.cs.columbia.edu/~jrk/music.ps
Refering-URL: http://www.cs.columbia.edu/~jrk/
Root-URL: http://www.cs.columbia.edu
Title: Video Scene Segmentation Via Continuous Video Coherence  
Author: John R. Kender Boon-Lock Yeo 
Address: P.O.Box 704 New York, NY 10027 Yorktown Heights, NY 10598  
Affiliation: Department of Computer Science IBM T.J.Watson Research Center Columbia University  
Abstract: In extended video sequences, individual frames are grouped into shots which are defined as a sequence taken by a single camera, and related shots are grouped into scenes which are defined as a single dramatic event taken by a small number of related cameras. This hierarchical structure is deliberately constructed, dictated by the limitations and preferences of the human visual and memory systems. We present three novel high-level segmentation results derived from these considerations, some of which are analogous to those involved in the perception of the structure of music. First and primarily, we derive and demonstrate a method for measuring probable scene boundaries, by calculating a short term memory-based model of shot-to-shot "coherence". The detection of local minima in this continuous measure permits robust and flexible segmentation of the video into scenes, without the necessity for first aggregating shots into clusters. Second, and independently of the first, we then derive and demonstrate a one-pass on-the-fly shot clustering algorithm. Third, we demonstrate partially successful results on the application of these two new methods to the next higher, "theme", level of video structure. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. S. Bregman, </author> <title> Auditory Scene Analysis: The Perceptual Organization of Sound, </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: However, this problem in visual temporal structure does have an analogue in auditory perception, where its limits have been extensively investigated <ref> [1] </ref>. Composers of music often produce chord-like sounds from instruments capable of only a single note. Rapidly alternated single notes give rise to the impression of multiple parallel streams; such trills and arpeggios are then temporally succeeded by structurally different trills and arpeggios.
Reference: [2] <author> D. Arjon, </author> <title> Grammar of the Film Language, </title> <publisher> Silman-James Press, </publisher> <year> 1976. </year>
Reference-contexts: 1 Introduction The creation of an extended video sequence, such as a newscast, a situation comedy, or a drama, is not a random act. The underlying high-level organizational structures, as presented in various textbooks on production, cinematography, and film editing <ref> [2] </ref>, depend on many definite human expectations about the placement and timing of camera shots within a single physical scene.
Reference: [3] <author> W. R. Garner, </author> <title> The Processing of Information and Structure, </title> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1974. </year>
Reference-contexts: At any shot boundary, then, coherence is defined to be the total recall of all the shots older than the boundary by all the shots newer than boundary. 3.1 Modeling the Recall of a Single Shot In keeping with common models in psychology of sensory buffers as "leaky integrators" <ref> [3] </ref>, we model the short term visual memory buffer of frame perception as having a limited capacity, as preserving the order of visual stimulus, and as losing older frames uniformly throughout the buffer at the same aggregate rate as new frames are perceived.
Reference: [4] <author> M. Yeung and B.L. Yeo, </author> <title> "Time-constrained clustering for segmentation of video into story units", </title> <journal> ICPR'96, </journal> <volume> Vol. C, </volume> <pages> pp. 375-380, </pages> <year> 1996. </year>
Reference-contexts: between any frame in the first shot S i , and any frame in the second shot S j : D (S i ; S j ) = min D (f ki ; f lj ) where f ki is frame k of shot i. 2.3 Scene Detection Prior work <ref> [4] </ref> has exploited these definitions to define a discrete, graph-based algorithm for the detection of scene boundaries. First, shots are clustered together into sets that each consists of those shots most probably taken from a given single camera position.
Reference: [5] <author> M. Yeung and B. </author> <title> Liu "Efficient matching and clustering of video shots," </title> <journal> ICIP'96, </journal> <volume> Volume I, </volume> <pages> pages 338-341, </pages> <year> 1995. </year>
Reference-contexts: In summary, what we seek is a transform, rather than a parse. 2 Prior Work 2.1 Frame Dissimilarity We adopt the result of <ref> [5] </ref> which found that over a variety of videos, normalized color histogram difference was a satisfactory measure of frame dissimilarity, even where colors were quantized into only 128 bins (8 green by 8 red by 4 blue).
References-found: 5

