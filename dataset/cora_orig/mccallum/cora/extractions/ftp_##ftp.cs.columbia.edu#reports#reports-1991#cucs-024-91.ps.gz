URL: ftp://ftp.cs.columbia.edu/reports/reports-1991/cucs-024-91.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1991.html
Root-URL: http://www.cs.columbia.edu
Title: Execution Autonomy in Distributed Transaction Processing  
Author: Calton Pu and Avraham Leff 
Keyword: Index terms: epsilon-serializability, autonomy, asynchronous transaction processing, divergence control, consistency restoration.  
Address: New York, NY 10027  
Affiliation: Department of Computer Science Columbia University  
Pubnum: Technical Report No. CUCS-024-91  
Abstract: We study the feasibility of execution autonomy in systems with asynchronous transaction processing based on epsilon-serializability (ESR). The abstract correctness criteria defined by ESR are implemented by techniques such as asynchronous divergence control and asynchronous consistency restoration. Concrete application examples in a distributed environment, such as banking, are described in order to illustrate the advantages of using ESR to support execution autonomy. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Barghouti and G.E. Kaiser. </author> <title> Concurrency control in advanced database applications. </title> <journal> ACM Computing Surveys, </journal> <month> September </month> <year> 1991. </year>
Reference-contexts: Another example is using the Escrow Method [22] to improve system performance. The Escrow Method requires the programmers to accommodate the whole-data-item uncertainty explicitly, which may interact with degree 2 (in)consistency in subtle ways. As we move into more advanced applications <ref> [1] </ref> and heterogeneous databases [7], the integration of different kinds of concurrency control becomes increasingly important. In contrast to degree 2 consistency, ESR |by definition| provides a smooth integration between SR and any degree of inconsistency.
Reference: [2] <author> P.A. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> first edition, </address> <year> 1987. </year>
Reference-contexts: T 1 is called a compensated-for transaction and T 2 a dependent transaction with respect to T 1 . The goal of their recovery paradigm is to undo the compensated-for transaction but leave the effects of the dependent transactions intact. An important definition is that of soundness. (As usual <ref> [2] </ref>, a history is a sequence of database operations.) If X is the history of transactions T , CT , and their set of dependent transactions dep (T ), and Y is some history of only the dependent transactions dep (T ), then X is said to be sound if for
Reference: [3] <author> P.A. Bernstein, M. Hsu, and B. Mann. </author> <title> Implementing recoverable requests using queues. </title> <booktitle> In Proceedings of 1990 SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 112-122, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: One way to use independent updates is to emulate the bank practice. An update is made locally and immediately, but the update is sent to the central site in a reliable message <ref> [3] </ref>. The update in the central site satisfies the necessary rigor in consistency constraints, for example, serializability. Periodically the central site propagates the official updates known to be consistent to the local sites.
Reference: [4] <author> A.D. Birrell, R. Levin, R.M. Needham, and M.D. Schroeder. Grapevine: </author> <title> An exercise in distributed computing. </title> <journal> Communications of ACM, </journal> <volume> 25(4) </volume> <pages> 260-274, </pages> <month> April </month> <year> 1982. </year>
Reference-contexts: In these cases, an independent source of consistent data is available. From time to time the consistent data is used to overwrite potentially inconsistent data. The first important example of this method is the propagation of replica updates in primary copy methods, such as Grapevine <ref> [4] </ref>. Since all the updates are performed first in the primary copy, the secondary copies may be allowed to diverge (within bounds specified by each dET). A similar situation occurs with bank accounts. The bank database is processed in batch mode at night, at which time the updates are made.
Reference: [5] <author> Y. Breitbart, A. Silberschatz, and G. Thompson. </author> <title> Reliable transaction management in a multidatabase system. </title> <booktitle> In Proceedings of 1990 SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 215-224, </pages> <month> May </month> <year> 1990. </year>
Reference: [6] <author> W. Du and A. Elmagarmid. </author> <title> Quasi serializability: a correctness criterion for global concur-rency control in InterBase. </title> <booktitle> In Proceedings of the International Conference on Very Large Data Bases, </booktitle> <pages> pages 347-355, </pages> <address> Amsterdam, The Netherlands, </address> <month> August </month> <year> 1989. </year>
Reference-contexts: In an ESR-based TP system, the Escrow Method and Data-value Partitioning may be introduced as optimization techniques that are transparent to the application programs. 7 Related Work Besides ESR, notions of correctness weaker than SR have been proposed. We have already discussed QSR <ref> [6] </ref> and degree 2 [11]. Garcia-Molina et al. [9] proposed sagas that use semantic atomicity [8] which rely on transaction semantics to define correctness. Sagas differ from ESR because an unlimited amount of inconsistency (revealed before a compensation) may propagate and persist in the database.
Reference: [7] <editor> A.K. Elmagarmid and C. Pu, editors. </editor> <title> Special Issue on Heterogeneous Databases, </title> <journal> volume 22:3 of ACM Computing Surveys. ACM, </journal> <month> September </month> <year> 1990. </year>
Reference-contexts: Another example is using the Escrow Method [22] to improve system performance. The Escrow Method requires the programmers to accommodate the whole-data-item uncertainty explicitly, which may interact with degree 2 (in)consistency in subtle ways. As we move into more advanced applications [1] and heterogeneous databases <ref> [7] </ref>, the integration of different kinds of concurrency control becomes increasingly important. In contrast to degree 2 consistency, ESR |by definition| provides a smooth integration between SR and any degree of inconsistency.
Reference: [8] <author> H. Garcia-Molina. </author> <title> Using semantic knowledge for transactions processing in a distributed database. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 8(2) </volume> <pages> 186-213, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: We have already discussed QSR [6] and degree 2 [11]. Garcia-Molina et al. [9] proposed sagas that use semantic atomicity <ref> [8] </ref> which rely on transaction semantics to define correctness. Sagas differ from ESR because an unlimited amount of inconsistency (revealed before a compensation) may propagate and persist in the database. Levy et al [18] defined relaxed atomicity to model non-atomic transactions similar to sagas.
Reference: [9] <author> H. Garcia-Molina and K. Salem. Sagas. </author> <booktitle> In Proceedings of ACM SIGMOD Conference on Management of Data, </booktitle> <pages> pages 249-259, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: However, if we take into account higher levels of abstraction for the operations (e.g., increment and decrement), compensation actions may be used to roll back sophisticated updates more cheaply. This is especially relevant at the transaction level. Sagas <ref> [9] </ref> and Compensating Transactions [16] are good examples. The most important property in operation semantics to reduce rollback overhead is commutativity. 5.2 Semantics-Based Compensation As mentioned above, Sagas [9] and Compensating Transactions [16] rely on commutativity to reduce the rollback overhead in compensations. <p> This is especially relevant at the transaction level. Sagas <ref> [9] </ref> and Compensating Transactions [16] are good examples. The most important property in operation semantics to reduce rollback overhead is commutativity. 5.2 Semantics-Based Compensation As mentioned above, Sagas [9] and Compensating Transactions [16] rely on commutativity to reduce the rollback overhead in compensations. The idea is that if we are applying only commutative transactions then we can shu*e them all the way back to the original transaction introducing the inconsistency, thus avoiding the rollback. <p> Note that we have identified the places where potential inconsistency may arise and made explicit the references to these situations. This type of analysis is facilitated by ESR because it is semantics-independent. This does not prevent ESR from incorporating the explicit specification of semantics-dependent inconsistency. In contrast, sagas <ref> [9] </ref> as proposed are implicitly dependent on application semantics for the maintenance of database consistency. 5.4 Independent Updates Besides compensations, a second method of consistency restoration is independent updates. In these cases, an independent source of consistent data is available. <p> We have already discussed QSR [6] and degree 2 [11]. Garcia-Molina et al. <ref> [9] </ref> proposed sagas that use semantic atomicity [8] which rely on transaction semantics to define correctness. Sagas differ from ESR because an unlimited amount of inconsistency (revealed before a compensation) may propagate and persist in the database.
Reference: [10] <author> D. Georgakopoulos and M. Rusinkiewicz. </author> <title> On serializability of multidatabase transactions through forced local conflitcs. </title> <booktitle> In Proceedings of the Seventh International Conference on Data Engineering, </booktitle> <address> Kobe, Japan, </address> <month> April </month> <year> 1991. </year>
Reference: [11] <author> J.N. Gray, R.A. Lorie, </author> <title> G.R. Putzolu, and I.L. Traiger. Granularity of locks and degrees of consistency in a shared data base. </title> <booktitle> In Proceedings of the IFIP Working Conference on Modeling of Data Base Management Systems, </booktitle> <pages> pages 1-29, </pages> <year> 1979. </year>
Reference-contexts: In an ESR-based TP system, the Escrow Method and Data-value Partitioning may be introduced as optimization techniques that are transparent to the application programs. 7 Related Work Besides ESR, notions of correctness weaker than SR have been proposed. We have already discussed QSR [6] and degree 2 <ref> [11] </ref>. Garcia-Molina et al. [9] proposed sagas that use semantic atomicity [8] which rely on transaction semantics to define correctness. Sagas differ from ESR because an unlimited amount of inconsistency (revealed before a compensation) may propagate and persist in the database.
Reference: [12] <author> T. Haerder and A. Reuter. </author> <title> Principles of transaction-oriented database recovery. </title> <journal> ACM Computing Surveys, </journal> <volume> 15(4) </volume> <pages> 287-317, </pages> <month> December </month> <year> 1983. </year>
Reference-contexts: Once information on disk may differ from the main memory, we need to maintain enough information for resynchroniza-tion at recovery time. Remember that in classic TP, we have Read/Write operations without sophisticated semantics. The model of inconsistency repair based on Read/Write compensations using REDO and UNDO <ref> [12] </ref> consists of three steps. First is the inconsistency detection where a specific operation is found to have introduced inconsistency. Second is the undoing of the effects of the offending operation. Third is the REDO of the other operations that have been undone as a side-effect during UNDO.
Reference: [13] <author> P.M. Herlihy and J.M. Wing. </author> <title> Linearizability: A correctness condition for concurrent objects. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(3) </volume> <pages> 463-492, </pages> <month> July </month> <year> 1990. </year>
Reference: [14] <author> M. Hsu and A. Silberschatz. </author> <title> Unilateral commit: A new paradigm for reliable distributed transaction processing. </title> <booktitle> In Proceedings of the Seventh International Conference on Data Engineering, </booktitle> <address> Kobe, Japan, </address> <month> February </month> <year> 1990. </year>
Reference-contexts: ESR also allows a larger number of execution histories. The Polarized Protocol, for example, does not allow global state from an incomplete transaction to be seen by other transactions. An implementation issue in asynchronous TP is to guarantee uniform outcome of distributed transactions running asynchronously. Unilateral Commit <ref> [14] </ref> is a protocol that uses reliable message transmission to guarantee that a uniform decision is correctly carried out. Optimistic Commit [17] is a protocol that uses Compensating Transactions [16] to undo the effects of partial results to reach a uniform decision.
Reference: [15] <author> D.R. Jefferson. </author> <title> Virtual time. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(3) </volume> <pages> 404-425, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: When * &gt; 0, the need for roll back is lessened by an amount roughly proportional to the *-spec. This is explained in more detail in Section 5.3 using commutativity. For operation-level compensation such as Time Warp <ref> [15] </ref> and classic TP crash recovery, the overhead of undoing the entire history is accepted as inevitable for the Read/Write model. The transaction-level equivalent of undoing the entire history is called cascaded aborts.
Reference: [16] <author> H. Korth, E. Levy, and A. Silberschatz. </author> <title> A formal approach to recovery by compensating transactions. </title> <booktitle> In Proceedings of the 16th International Conference on Very Large Data Bases, </booktitle> <address> Brisbane, Australia, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: However, if we take into account higher levels of abstraction for the operations (e.g., increment and decrement), compensation actions may be used to roll back sophisticated updates more cheaply. This is especially relevant at the transaction level. Sagas [9] and Compensating Transactions <ref> [16] </ref> are good examples. The most important property in operation semantics to reduce rollback overhead is commutativity. 5.2 Semantics-Based Compensation As mentioned above, Sagas [9] and Compensating Transactions [16] rely on commutativity to reduce the rollback overhead in compensations. <p> This is especially relevant at the transaction level. Sagas [9] and Compensating Transactions <ref> [16] </ref> are good examples. The most important property in operation semantics to reduce rollback overhead is commutativity. 5.2 Semantics-Based Compensation As mentioned above, Sagas [9] and Compensating Transactions [16] rely on commutativity to reduce the rollback overhead in compensations. The idea is that if we are applying only commutative transactions then we can shu*e them all the way back to the original transaction introducing the inconsistency, thus avoiding the rollback. <p> They depend on general "application semantics", which include commutativity, as the underlying assumptions that allow compensations without rolling back the entire history. To simplify the presentation we use the notation of Korth et al. <ref> [16] </ref> in the description of Compensating Transactions. When the updates of transaction T 1 are read by some other transaction T 2 , T 1 is said to have been externalized . If we want to undo the effects of T 1 , a Compensating Transaction CT 1 is run. <p> We think that alternative (1) is a viable choice, even though most researchers (including Korth et al <ref> [16] </ref>) define a Compensating Transaction as non-abortable. The main reason they do not consider the possibility of aborting a Compensating Transaction is because the abort would introduce some inconsistency into the database, which is not tractable in the classic TP theory. <p> An implementation issue in asynchronous TP is to guarantee uniform outcome of distributed transactions running asynchronously. Unilateral Commit [14] is a protocol that uses reliable message transmission to guarantee that a uniform decision is correctly carried out. Optimistic Commit [17] is a protocol that uses Compensating Transactions <ref> [16] </ref> to undo the effects of partial results to reach a uniform decision. This is but one aspect of the autonomous TP problem. Sheth et al [26] use the notion of eventual consistency to define current copy serializability (CPSR) for replicated data.
Reference: [17] <author> E. Levy, H. Korth, and A. Silberschatz. </author> <title> An optimistic commit protocol for distributed transaction management. </title> <booktitle> In Proceedings of the 1991 ACM SIGMOD International Conference on Management of Data, </booktitle> <address> Denver, Colorado, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: An implementation issue in asynchronous TP is to guarantee uniform outcome of distributed transactions running asynchronously. Unilateral Commit [14] is a protocol that uses reliable message transmission to guarantee that a uniform decision is correctly carried out. Optimistic Commit <ref> [17] </ref> is a protocol that uses Compensating Transactions [16] to undo the effects of partial results to reach a uniform decision. This is but one aspect of the autonomous TP problem. Sheth et al [26] use the notion of eventual consistency to define current copy serializability (CPSR) for replicated data.
Reference: [18] <author> E. Levy, H. Korth, and A. Silberschatz. </author> <title> A theory of relaxed atomicity. </title> <booktitle> In Proceedings of the 1991 ACM Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: Garcia-Molina et al. [9] proposed sagas that use semantic atomicity [8] which rely on transaction semantics to define correctness. Sagas differ from ESR because an unlimited amount of inconsistency (revealed before a compensation) may propagate and persist in the database. Levy et al <ref> [18] </ref> defined relaxed atomicity to model non-atomic transactions similar to sagas. Non-atomic transactions are composed of steps, which may be a forward step or a recovery step. They also describe the Polarized Protocol to implement Relaxed Atomicity.
Reference: [19] <author> B. Lindsay, L.M. Haas, C. Mohan, P.F. Wilms, and R.A. Yost. </author> <title> Computation and communication in R fl : a distributed database manager. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(1) </volume> <pages> 24-38, </pages> <month> February </month> <year> 1984. </year>
Reference: [20] <author> W. Litwin, L. Mark, and N. Roussopoulos. </author> <title> Interoperability of multiple autonomous databases. </title> <journal> ACM Computing Surveys, </journal> <volume> 22(3) </volume> <pages> 267-293, </pages> <month> September </month> <year> 1990. </year>
Reference: [21] <author> H. G. Molina and Kogan B. </author> <title> Node autonomy in distributed systems. </title> <booktitle> In International Symposium on Databases in Parallel and Distributed Systems, </booktitle> <pages> pages 158-166, </pages> <month> December </month> <year> 1988. </year>
Reference: [22] <author> P. E. O'Neil. </author> <title> The escrow transactional method. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 11(4) </volume> <pages> 405-430, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: If update values also increase then the fortuitous bound on inconsistency may quickly become meaningless and degree 2 no longer useful. Therefore, for scalability reasons we need a more abstract and precise integration with classic TP. Another example is using the Escrow Method <ref> [22] </ref> to improve system performance. The Escrow Method requires the programmers to accommodate the whole-data-item uncertainty explicitly, which may interact with degree 2 (in)consistency in subtle ways. As we move into more advanced applications [1] and heterogeneous databases [7], the integration of different kinds of concurrency control becomes increasingly important. <p> Furthermore, because ESR guarantees a bound on inconsistency, applications will not produce increasingly inconsistent results when more processing power or nodes are added to the system. 6.4 Network Partitions Another advantage of ESR-based distributed TP is the transparency of the ET interface. For example, the Escrow Method <ref> [22] </ref> increases the TP system throughput by implicitly reserving part of an aggregate field (e.g., a numerical value) for processing. The reason the Escrow Method obtains more concurrency is its ability to release the lock on the data item once the partial value has been put in "escrow". <p> For both the Escrow Method and the Data-value Partitioning, this uncertainty is inevitable. 14 ESR can capture this uncertainty. For example, instead of having the application program-mer look at the maximum and minimum possible values (as suggested in <ref> [22] </ref>), an *-spec in a read ET is enforced by the system, so the ET programmer will not have to deal with the data value uncertainty explicitly. The same way the transaction interface hides details of concurrency control and crash recovery, the ET interface hides details of uncertainty.
Reference: [23] <author> C. Pu and A. Leff. </author> <title> Replica control in distributed systems: An asynchronous approach. </title> <booktitle> In Proceedings of the 1991 ACM SIGMOD International Conference on Management of Data, </booktitle> <address> Denver, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: The work based on ESR is called Generalized Transaction Processing, several aspects of which are currently under development. One application of ESR is an asynchronous approach 15 for replication <ref> [23] </ref>. An important part of ESR implementation is the divergence control meth-ods [28]. We are now evaluating the performance benefits of divergence control methods resulting from added concurrency and decreased deadlock frequency.
Reference: [24] <author> C. Pu, A. Leff, and S.W.F. Chen. </author> <title> Heterogeneous and autonomous transaction processing. </title> <type> Technical Report CUCS-008-91, </type> <institution> Department of Computer Science, Columbia University, </institution> <month> April </month> <year> 1991. </year>
Reference: [25] <author> Calton Pu. </author> <title> Superdatabases for composition of heterogeneous databases. </title> <editor> In Amar Gupta, editor, </editor> <booktitle> Integration of Information Systems: Bridging Heterogeneous Databases, </booktitle> <pages> pages 150-157. </pages> <publisher> IEEE Press, </publisher> <year> 1989. </year> <booktitle> Also appeared in Proceedings of Fourth International Conference on Data Engineering, 1988, </booktitle> <address> Los Angeles. </address>
Reference: [26] <author> A. Sheth, Yungho Leu, and Ahmed Elmagarmid. </author> <title> Maintaining consistency of interdependent data in multidatabase systems. </title> <type> Technical Report CSD-TR-91-016, </type> <institution> Computer Science Department, Purdue University, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: Optimistic Commit [17] is a protocol that uses Compensating Transactions [16] to undo the effects of partial results to reach a uniform decision. This is but one aspect of the autonomous TP problem. Sheth et al <ref> [26] </ref> use the notion of eventual consistency to define current copy serializability (CPSR) for replicated data. Each update is done on a current copy and asynchronously propagated to the other replicas.
Reference: [27] <author> N. Soparkar and A. Silberschatz. </author> <title> Data-value partitioning and virtual messages. </title> <booktitle> In Proceedings of the Ninth ACM Symposium on Principles of Database Systems, </booktitle> <address> Nashville, Tennessee, </address> <month> April </month> <year> 1990. </year> <month> 17 </month>
Reference-contexts: The reason the Escrow Method obtains more concurrency is its ability to release the lock on the data item once the partial value has been put in "escrow". More relevant to this paper, the Data-value Partitioning method <ref> [27] </ref> increases the distributed TP system availability and autonomy by explicitly separating parts of the value of a data item into different sites. Since the different parts may operate asynchronously even during network partitions, Data-value Partitioning increases autonomy because of its non-blocking character.
Reference: [28] <author> K.L. Wu, P. S. Yu, and C. Pu. </author> <title> Divergence control for epsilon-serializability. </title> <type> Technical Report CUCS-002-91, </type> <institution> Department of Computer Science, Columbia University, </institution> <month> February </month> <year> 1991. </year> <note> Also available as IBM Tech Report No. RC16598. 18 </note>
Reference-contexts: Each asET and compensation asET is a single operation and we have an ADC method derived from two-phase locking. Table 2 shows the lock compatibility matrix for dirty objects. ACR uses the usual two-phase locking compatibility table <ref> [28] </ref> to handle clean objects. The main difference is in squares marked LOK-1 (reading uncommitted data), LOK-2 (overwriting data read by uncommitted query -degree 2), and Commu-1 (if operations commute). <p> In the stock market example, the inconsistency is represented by the time lag between the reported price and the last transaction update. Using ESR with fixed time bounds (explained in <ref> [28] </ref>), the stock exchange can offer the brokers some firm guarantees of the inconsistency level. Even if the system breaks down due to overload, it can still return the amount of inconsistency (in terms of time lag in this case) so brokers may judge the value of its information. <p> The work based on ESR is called Generalized Transaction Processing, several aspects of which are currently under development. One application of ESR is an asynchronous approach 15 for replication [23]. An important part of ESR implementation is the divergence control meth-ods <ref> [28] </ref>. We are now evaluating the performance benefits of divergence control methods resulting from added concurrency and decreased deadlock frequency.
References-found: 28

