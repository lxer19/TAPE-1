URL: ftp://ftp.cs.umass.edu/pub/lesser/decker-89-115.ps
Refering-URL: http://dis.cs.umass.edu/research/dtt.html
Root-URL: 
Title: Extending a Blackboard Architecture for Approximate Processing  
Author: K. S. Decker V. R. Lesser R. C. Whitehair 
Affiliation: Computer and Information Science Department University of Massachusetts  
Abstract: COINS Technical Report 89-115 April 21, 1994 Abstract Approximate processing is an approach to real-time AI problem solving systems in domains where there are a range of acceptable answers in terms of certainty, accuracy, and completeness. Such a system needs to evaluate the current situation, make time predictions about the likelihood of achieving current objectives, monitor the processing and pursuit of those objectives, and if necessary choose new objectives and associated processing strategies that are achievable in the available time. In this approach, the system is performing satisficing problem solving, in that it is attempting to generate the best possible solutions within available time and computational resource constraints. Previously published work[1] has dealt with this approach to real-time; however, an important aspect was not fully developed: the problem solver must be very flexible in its ability to represent and efficiently implement a variety of processing strategies. Extensions to the blackboard model of problem solving that facilitate approximate processing are demonstrated for the task of knowledge-based signal interpretation. This is accomplished by extending the blackboard model of problem solving to include data, knowledge, and control approximations. With minimal overhead, the problem solver dynamically responds to the current situation by altering its operators and state space abstraction to produce a range of acceptable answers. Initial experiments with this approach show promising results in both providing a range of processing algorithms and in controlling this dynamic system with low overhead. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Lesser, J. Pavlin, and E. Durfee, </author> <title> Approximate processing in real-time problem solving, </title> <journal> AI Magazine, </journal> <volume> vol. 9, </volume> <pages> pp. 49-61, </pages> <month> Spring </month> <year> 1988. </year>
Reference-contexts: The lack of fixed time bounds on algorithms can be overcome in domains in which a range of acceptable answers (in terms of certainty, accuracy, and completeness) can be computed (using a range of computational resources). When applied to real-time problems in AI systems, this satisficing approach <ref> [2, 1] </ref> can be viewed as an attempt to construct problem-solving systems that produce the best possible answer in a given amount of time. <p> The progress of these tasks is monitored, and this may trigger re-evaluation of the situation and new predictions, resulting in the choice of new, less acceptable objectives for the system. While previous work <ref> [1] </ref> has discussed ways of making predictions and monitoring tasks, this work is concerned with the architectural features of a problem solver that permit a smooth integration of a diverse set of task solution methods. Satisficing problem solving can be accomplished through the use of approximate processing techniques. <p> Plan modifications involve making tradeoffs between the resource requirements needed to generate a solution, such as time, and solution characteristics that define a range of potentially acceptable solutions, such as certainty, precision and completeness <ref> [1] </ref>. The choice of tradeoffs is based on domain specific knowledge of the utility associated with each member of the range of potentially acceptable solutions.
Reference: [2] <editor> H. A. Simon, </editor> <booktitle> The Sciences of the Artificial. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1968. </year>
Reference-contexts: The lack of fixed time bounds on algorithms can be overcome in domains in which a range of acceptable answers (in terms of certainty, accuracy, and completeness) can be computed (using a range of computational resources). When applied to real-time problems in AI systems, this satisficing approach <ref> [2, 1] </ref> can be viewed as an attempt to construct problem-solving systems that produce the best possible answer in a given amount of time.
Reference: [3] <author> M. Boddy and T. Dean, </author> <title> Solving time-dependent planning problems, </title> <booktitle> in Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <month> Aug. </month> <year> 1989. </year>
Reference-contexts: Many iterative numerical approximation algorithms will produce a more precise answer with more time. A class of algorithms 1 The real time response required at the level of these large, complex algorithms is on the order of hundreds of milliseconds to tens of seconds. 1 called anytime algorithms <ref> [3, 4, 5, 6] </ref>, exhibit these characteristics: they can be preemptively sched-uled; they can be terminated at any time and produce an answer; and the answers returned improve in some well-behaved manner with respect to time.
Reference: [4] <author> K. Kanazawa and T. Dean, </author> <title> A model for projection and action, </title> <booktitle> in Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <month> Aug. </month> <year> 1989. </year>
Reference-contexts: Many iterative numerical approximation algorithms will produce a more precise answer with more time. A class of algorithms 1 The real time response required at the level of these large, complex algorithms is on the order of hundreds of milliseconds to tens of seconds. 1 called anytime algorithms <ref> [3, 4, 5, 6] </ref>, exhibit these characteristics: they can be preemptively sched-uled; they can be terminated at any time and produce an answer; and the answers returned improve in some well-behaved manner with respect to time. <p> We must also develop techniques for determining given a prediction that deadlines will be missed if we continue the current strategy and set of approximations what the new control strategies and set of approximations are in the current context that will allow the system to meet the deadline <ref> [4] </ref>. To accomplish this, a more complex and flexible mechanism for expressing control plans is needed, as well as work on how to dynamically move between strategies and build control plans dynamically during problem solving.
Reference: [5] <author> E. J. Horvitz, </author> <title> Reasoning under varying and uncertain resource constraints, </title> <booktitle> in Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: Many iterative numerical approximation algorithms will produce a more precise answer with more time. A class of algorithms 1 The real time response required at the level of these large, complex algorithms is on the order of hundreds of milliseconds to tens of seconds. 1 called anytime algorithms <ref> [3, 4, 5, 6] </ref>, exhibit these characteristics: they can be preemptively sched-uled; they can be terminated at any time and produce an answer; and the answers returned improve in some well-behaved manner with respect to time.
Reference: [6] <author> T. Dean and M. Boddy, </author> <title> An analysis of time-dependent planning, </title> <booktitle> in Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: Many iterative numerical approximation algorithms will produce a more precise answer with more time. A class of algorithms 1 The real time response required at the level of these large, complex algorithms is on the order of hundreds of milliseconds to tens of seconds. 1 called anytime algorithms <ref> [3, 4, 5, 6] </ref>, exhibit these characteristics: they can be preemptively sched-uled; they can be terminated at any time and produce an answer; and the answers returned improve in some well-behaved manner with respect to time.
Reference: [7] <author> P. P. Bonissone, S. S. Gans, and K. S. Decker, RUM: </author> <title> A layered architecture for reasoning with uncertainty, </title> <booktitle> in Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <month> Aug. </month> <year> 1987. </year> <month> 28 </month>
Reference-contexts: Figure 2 part (a) is an example of a grammar used in the DVMT. The grammar is represented as a modified AND-OR-XOR tree with a domain specific belief combination function associated with each AND-OR-XOR node 2 <ref> [7] </ref> and with a domain event associated with each leaf node. <p> To represent uncertainty caused by the use of approximate search, data, and knowledge, the DVMT has expanded its representation of belief to a four-valued system. The new belief system was derived from evidential reasoning [10] and is similar to that in RUM <ref> [7] </ref>. The belief in a hypothesis is now represented by a measure of positive belief (certainty) and of negative belief (refutation). To represent the completeness of the solution, the positive and negative beliefs are further divided into upper and lower bounds.
Reference: [8] <author> D. D. Corkill, V. R. Lesser, and E. </author> <title> Hudlick a, Unifying data-directed and goal-directed con-trol: An example and experiments, </title> <booktitle> in Proceedings of the National Conference on Artificial Intelligence, </booktitle> <address> (Pittsburgh, Pennsylvania), </address> <pages> pp. 143-147, </pages> <month> Aug. </month> <year> 1982. </year>
Reference-contexts: Deciding how to go about achieving them (goal-to-KSI mapping), 4. Choosing which of these potential activities to execute (managing the agenda). When a hypothesis is formed, goals are created to represent the possible extensions and abstractions of that hypothesis <ref> [8] </ref>. The goals are stored on a separate goal blackboard with levels that mirror those on the hypothesis blackboard, and each goal is given a rating. <p> The highest rated KSI is then executed. 3 This is a simplistic explanation of goal processing in the DVMT. For more details on subgoaling and goal merging, see <ref> [8] </ref>. 6 3.2 Approximate Processing in the DVMT Approximate processing strategies can be used to reduce the expected cost of a problem-solving activity, c , and to bound problem-solving resource requirements by limiting the variance, 2 c , of c .
Reference: [9] <author> P. P. Bonissone and K. S. Decker, </author> <title> Selecting uncertainty calculi and granularity: An experiment in trading-off precision and complexity, </title> <booktitle> in Uncertainty in Artificial Intelligence (L. </booktitle> <editor> N. Karnak and J. F. Lemmer, eds.), </editor> <publisher> North Holland, </publisher> <year> 1986. </year> <note> Also Technical Report 85-CRD-171, </note> <institution> GE Corporate Research and Development, </institution> <year> 1985. </year>
Reference-contexts: effects of ill-defined approximations. 4.3 Belief Representation and Uncertainty Uncertainty arises in any system from the reliability of the initial data, the imprecision of that data or the language used to represent it, the incompleteness of the data, and the aggregation of the data from data approximations or multiple sources <ref> [9] </ref>. Additional uncertainty is introduced with the use of approximate search, data and knowledge. For example, the credibility of a partial result constructed by ignoring potentially corroborating data must be distinguishable from the credibility of a similar partial result constructed using all available data.
Reference: [10] <author> J. D. Lowrance and T. D. Garvey, </author> <title> Evidential reasoning: A developing concept, </title> <booktitle> IEE 1982 Proceedings of the International Conference on Cybernetics and Society, </booktitle> <pages> pp. 6-9, </pages> <year> 1982. </year>
Reference-contexts: To represent uncertainty caused by the use of approximate search, data, and knowledge, the DVMT has expanded its representation of belief to a four-valued system. The new belief system was derived from evidential reasoning <ref> [10] </ref> and is similar to that in RUM [7]. The belief in a hypothesis is now represented by a measure of positive belief (certainty) and of negative belief (refutation). To represent the completeness of the solution, the positive and negative beliefs are further divided into upper and lower bounds. <p> Figure 6 introduces a graphic representation of the four-valued belief system that will be used in subsequent sections to present experimental results. Furthermore, second-order relationships between the elements of the belief system can also be used to control problem solving. Specifically, various measures of ignorance <ref> [10] </ref> and conflict can be computed. Ignorance measures, such as (plausibility certainty), (doubt ref utation), (1 plausibility), (1 doubt) and (1 (certainty + ref utation)), indicate the amount of useful work that can be done to refine the belief in a hypothesis.
Reference: [11] <author> B. Hayes-Roth, </author> <title> A blackboard architecture for control, </title> <journal> Artificial Intelligence, </journal> <volume> vol. 26, </volume> <pages> pp. 251-321, </pages> <year> 1985. </year>
Reference-contexts: Each of these steps is parameterized so that the system can react flexibly to changes in the current situation, which is necessary for our model of real-time problem solving. In this initial implementation, the low-level loop is controlled by a BB1-style meta-control mechanism <ref> [11] </ref>, modified so that all aspects of the low-level control loop can be controlled what activities are placed on the agenda, why they get there, and the amount of effort involved in making these decisions. <p> BB1 prescription KSs <ref> [11] </ref> are used as control plans that indicated when to change focus, and strategy and focus goals also examined the DVMT agenda and blackboards. Heuristic control KSs are free to modify any of the low-level control loop parameters, not just the agenda rating mechanism.
Reference: [12] <author> B. Hayes-Roth, </author> <title> A multi-processor interrupt-driven architecture for adaptive intelligent systems, </title> <booktitle> in Proceedings of the Third Annual AAAI Workshop on Blackboard Systems, </booktitle> <address> (Detroit), </address> <month> Aug. </month> <year> 1989. </year> <note> Also KSL-87-31. </note>
Reference-contexts: In more recent work, B. Hayes-Roth has also proposed extensions similar in character to some developed here for controlling other aspects of agenda maintenance <ref> [12] </ref>. Here is a summary of a few of the major modifiable control parameters that were used in the experiments detailed in Section 5: Hypothesis Filter: The hypothesis filter takes as input the hypotheses created by a KSI execution and outputs hypotheses to be processed by the hyp-to-goal mapping.
Reference: [13] <author> K. S. Decker, M. A. Humphrey, and V. R. Lesser, </author> <title> Experimenting with control in the DVMT, </title> <booktitle> in Proceedings of the Third Annual AAAI Workshop on Blackboard Systems, </booktitle> <address> (Detroit), </address> <month> Aug. </month> <year> 1989. </year> <note> Also COINS TR-89-85. </note>
Reference-contexts: These parameters determine the character of the search process in terms of the granularity of the operations and the overhead involved in choosing the most appropriate KSI to execute on the agenda. The complete details of these parameters can be found in <ref> [13] </ref>. After changing a parameter, the meta-controller may re-run the low-level control loop from any point usually from just before the point that was changed. The meta-controller has the option to reintroduce filtered data at this time as well, from either the hypothesis or goal filter or both. <p> This strategy assumes that there is too much data to process individually, and so it clusters data at each time and then processes the clusters in a data-directed manner. For a complete description of both strategies see <ref> [13] </ref>. 5 Experiments A number of experiments in the Distributed Vehicle Monitoring Testbed (DVMT) have been carried out demonstrating how the extensions proposed to the blackboard model of problem solving permit efficient implementation and integration of a variety of approximate processing strategies. <p> This statistic shows that filtering does not add a significant amount of overhead. In summary, the parameterization of the low-level control loop permits a larger percentage of a node's processing time to be used in executing KSIs. For a more complete description, see <ref> [13] </ref>. 6 Summary and Future Work We have demonstrated experimentally that approximate processing is a useful technique for decreasing the processing time of an algorithm while generating acceptable (but less certain, less precise, or less complete) solutions.
Reference: [14] <author> A. Collinot, </author> <title> Revising the BB1 basic control loop to control the behavior of knowledge sources, in Blackboard Architectures and Applications (V. Jagannathan, </title> <editor> R. Dodhiawala, and L. S. Baum, </editor> <booktitle> eds.), </booktitle> <pages> pp. 27-43, </pages> <publisher> Academic Press, Inc., </publisher> <year> 1989. </year>
Reference-contexts: The meta-controller currently runs synchronously with the low-level control loop, so that it could, for example, examine the KSI queue after a KSI is chosen but before it is run and execute a different KSI instead <ref> [14] </ref>. It is postulated (and currently being implemented) that the low-level control mechanism can run asynchronously with respect to the meta-controller. Examples The real-time DVMT meta-controller was developed to control experiments in soft real-time approximate processing using approximate knowledge and data effectively.
Reference: [15] <author> E. H. Durfee and V. R. Lesser, </author> <title> Incremental planning to control a time-constrained, blackboard-based problem solver, </title> <journal> IEEE Transactions on Aerospace and Electronic Systems, </journal> <volume> vol. 24, </volume> <month> Sept. </month> <year> 1988. </year>
Reference-contexts: This will require us to generate initial time bounds estimations, revise them, and recognize when a deadline will be missed, based on the current processing strategy and set of approximations. A model of plan monitoring and time estimation for the DVMT has already been developed by Durfee <ref> [15] </ref>. Our first approach to hard deadlines will involve extending this work to the revised blackboard architecture.
References-found: 15

