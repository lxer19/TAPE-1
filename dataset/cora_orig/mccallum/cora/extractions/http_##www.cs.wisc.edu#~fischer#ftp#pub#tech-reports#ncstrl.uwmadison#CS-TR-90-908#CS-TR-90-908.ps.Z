URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-90-908/CS-TR-90-908.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-90-908/
Root-URL: http://www.cs.wisc.edu
Title: On the Complexity of Event Ordering for Shared-Memory Parallel Program Executions  
Author: Robert H. B. Netzer Barton P. Miller 
Keyword: Key Words Event ordering, nondeterminacy, parallel processing, race conditions, synchronization.  
Address: 1210 W. Dayton Street Madison, Wisconsin 53706  
Affiliation: Computer Sciences Department University of Wisconsin-Madison  
Note: TR  
Email: netzer@cs.wisc.edu  bart@cs.wisc.edu  
Date: 908 January 19, 1990  
Abstract: This paper presents results on the complexity of computing event orderings for shared-memory parallel program executions. Given a program execution, we formally define the problem of computing orderings that the execution must have exhibited or could have exhibited, and prove that computing such orderings is an intractable problem. We present a formal model of a shared-memory parallel program execution on a sequentially consistent processor, and discuss event orderings in terms of this model. Programs are considered that use fork/join and either counting semaphores or event style synchronization. We define a feasible program execution to be an execution of the program that performs the same events as an observed execution, but which may exhibit different orderings among those events. Any program execution exhibiting the same data dependences among the shared data as the observed execution is feasible. We define several relations that capture the orderings present in all (or some) of these feasible program executions. The happened-before, concurrent-with, and ordered-with relations are defined to show events that execute in a certain order, that execute concurrently, or that execute in either order but not concurrently. Each of these ordering relations is defined in two ways. In the must-have sense they show the orderings that are guaranteed to be present in all feasible program executions, and in the could-have sense they show the orderings that could potentially occur in at least one feasible program execution due to timing variations. We prove that computing any of the must-have ordering relations is a co-NP-hard problem and that computing any of the could-have ordering relations is an NP-hard problem. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh Research supported in part by National Science Foundation grant CCR-8815928, Office of Naval Research grant N00014-89-J-1222, and a Digital Equipment Corporation External Research Grant. Copyright 1990 Robert H. B. Netzer, Barton P. Miller. A condensed version of this paper appears in Proc. of the 1990 Int'l Conference on Parallel Processing, St Charles, IL, August 1990, pp. II-93-II-97. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Callahan, David and Jaspal Subhlok, </author> <title> ``Static Analysis of Low-Level Synchronization,'' </title> <booktitle> Proc. of the SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging, </booktitle> <address> Madison, WI, </address> <month> (May </month> <year> 1988). </year> <note> Also appears in SIGPLAN Notices 24(1) (January 1989). </note>
Reference-contexts: The happened-before relations show events that execute in a specific order, the concurrent-with relations show events that execute concurrently, and the ordered-with relations show events that execute in either order but not concurrently. 4. Related Work The problem of computing event orderings has been previously addressed by several researchers <ref> [1, 2, 5] </ref>. Given a program execution, Emrath, Ghosh, and Padua [2], and Helmbold, McDowell, and Wang [5] attempt to compute orderings that are guaranteed to occur in any other execution exhibiting the same events, irrespective of the original shared-data dependences. <p> Given a program execution, Emrath, Ghosh, and Padua [2], and Helmbold, McDowell, and Wang [5] attempt to compute orderings that are guaranteed to occur in any other execution exhibiting the same events, irrespective of the original shared-data dependences. Callahan and Subhlok <ref> [1] </ref> consider event orderings in the context of static analysis of parallel FORTRAN programs. Emrath, Ghosh, and Padua [2] attempt to compute a graph that shows the must-have and could-have orderings for programs that use event style synchronization. <p> However, since they do not consider the ordering constraints imposed by the shared-data dependences, their method sometimes overlooks some orderings. Helmbold, McDowell, and Wang [5] consider programs that use counting semaphores, and present algorithms for computing only some of the must-have orderings. Callahan and Subhlok <ref> [1] </ref> prove that computing orderings that are guaranteed to occur in all executions of a given program is a co-NP-hard problem, and present a data-flow framework for computing some of these orderings. <p> The resulting order ing relation is therefore a subset of our MHB relation. In the next section we prove that computing the entire MHB relation is a co-NP-hard problem. Callahan and Subhlok <ref> [1] </ref> consider the problem of static analysis of FORTRAN programs without loops that use parallel DO and CASE and event style synchronization (without Clear operations). They prove that determining the orderings that are guaranteed to occur in all executions of such a program is a co-NP-hard problem.
Reference: [2] <author> Emrath, Perry A., Sanjoy Ghosh, and David A. Padua, </author> <title> ``Event Synchronization Analysis for Debugging Parallel Programs,'' </title> <booktitle> Supercomputing '89, </booktitle> <pages> pp. </pages> <address> 580-588 Reno, NV, </address> <month> (November </month> <year> 1989). </year>
Reference-contexts: The happened-before relations show events that execute in a specific order, the concurrent-with relations show events that execute concurrently, and the ordered-with relations show events that execute in either order but not concurrently. 4. Related Work The problem of computing event orderings has been previously addressed by several researchers <ref> [1, 2, 5] </ref>. Given a program execution, Emrath, Ghosh, and Padua [2], and Helmbold, McDowell, and Wang [5] attempt to compute orderings that are guaranteed to occur in any other execution exhibiting the same events, irrespective of the original shared-data dependences. <p> Related Work The problem of computing event orderings has been previously addressed by several researchers [1, 2, 5]. Given a program execution, Emrath, Ghosh, and Padua <ref> [2] </ref>, and Helmbold, McDowell, and Wang [5] attempt to compute orderings that are guaranteed to occur in any other execution exhibiting the same events, irrespective of the original shared-data dependences. Callahan and Subhlok [1] consider event orderings in the context of static analysis of parallel FORTRAN programs. <p> Callahan and Subhlok [1] consider event orderings in the context of static analysis of parallel FORTRAN programs. Emrath, Ghosh, and Padua <ref> [2] </ref> attempt to compute a graph that shows the must-have and could-have orderings for programs that use event style synchronization. However, since they do not consider the ordering constraints imposed by the shared-data dependences, their method sometimes overlooks some orderings. <p> Callahan and Subhlok [1] prove that computing orderings that are guaranteed to occur in all executions of a given program is a co-NP-hard problem, and present a data-flow framework for computing some of these orderings. Emrath, Ghosh, and Padua <ref> [2] </ref> describe a method for computing the ``guaranteed run-time ordering'' between events in program executions that use fork/join and event style synchronization (using Post, Wait, and Clear operations). They construct a graph (called a task graph) that contains a single node for each synchronization event in the program execution.
Reference: [3] <author> Ferrante, J., Karl J. Ottenstein, and Joe D. Warren, </author> <title> ``The Program Dependence Graph and its Use in Optimization,'' </title> <journal> ACM Trans. on Programming Languages and Systems 9(3) pp. </journal> <month> 319-349 </month> <year> (1987). </year>
Reference-contexts: This definition of data dependence is different from the standard ones <ref> [3, 6] </ref> in that our definition combines the notions of flow-, anti-, and output-dependence, and does not explicitly state the variable involved. 2 TR 908 January 19, 1990 execute exactly the same events as P This result can be proven by showing that the execution result of each state ment instance
Reference: [4] <author> Garey, Michael R. and David S. Johnson, </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness, </title> <editor> W. H. </editor> <publisher> Freeman and Co. </publisher> <year> (1979). </year>
Reference-contexts: Proof. We present a proof only for the must-have-happened-before relation ( MHB ); proofs for the other relations are analogous. We give a reduction from 3CNFSAT <ref> [4] </ref> such that any Boolean formula is not satisfiable iff a b for two events, a and b, defined in the reduction. <p> In addition, the above results can be shown to hold for a program execution that uses a single counting semaphore by a reduction from the problem of sequencing to minimize maximum cumulative cost <ref> [4] </ref>. 5.2. Event Style Synchronization Theorem 3. Given a program execution, P = E, T D , that uses event style synchronization (with Post, Wait, and Clear primitives), the problem of deciding whether a MHB MCW MOW must-have ordering relations) is co-NP-hard. Proof.
Reference: [5] <author> Helmbold, David P., Charles E. McDowell, and Jian-Zhong Wang, </author> <title> ``Analyzing Traces with Anonymous Synchronization,'' </title> <booktitle> Proc. of the 1990 Intl. Conf. on Parallel Processing, </booktitle> <pages> pp. </pages> <address> 70-77 St. Charles, IL, </address> <month> (August </month> <year> 1990). </year>
Reference-contexts: The happened-before relations show events that execute in a specific order, the concurrent-with relations show events that execute concurrently, and the ordered-with relations show events that execute in either order but not concurrently. 4. Related Work The problem of computing event orderings has been previously addressed by several researchers <ref> [1, 2, 5] </ref>. Given a program execution, Emrath, Ghosh, and Padua [2], and Helmbold, McDowell, and Wang [5] attempt to compute orderings that are guaranteed to occur in any other execution exhibiting the same events, irrespective of the original shared-data dependences. <p> Related Work The problem of computing event orderings has been previously addressed by several researchers [1, 2, 5]. Given a program execution, Emrath, Ghosh, and Padua [2], and Helmbold, McDowell, and Wang <ref> [5] </ref> attempt to compute orderings that are guaranteed to occur in any other execution exhibiting the same events, irrespective of the original shared-data dependences. Callahan and Subhlok [1] consider event orderings in the context of static analysis of parallel FORTRAN programs. <p> Emrath, Ghosh, and Padua [2] attempt to compute a graph that shows the must-have and could-have orderings for programs that use event style synchronization. However, since they do not consider the ordering constraints imposed by the shared-data dependences, their method sometimes overlooks some orderings. Helmbold, McDowell, and Wang <ref> [5] </ref> consider programs that use counting semaphores, and present algorithms for computing only some of the must-have orderings. <p> We prove in the next section that exhaustively computing the orderings for program executions that use event style synchronization (with Clear operations) is an intractable problem. Given a trace of a program that uses counting semaphores, Helmbold, McDowell, and Wang <ref> [5] </ref> present an algorithm to compute some of the must-have orderings by computing safe orderings. A ordering is safe if the ord-erings it contains are guaranteed to occur in all executions that exhibit the same events (regardless of the shared-data dependences). Their algorithm operates in three phases.
Reference: [6] <author> Kuck, D. J., R. H. Kuhn, B. Leasure, D. A. Padua, and M. Wolfe, </author> <title> ``Dependence Graphs and Compiler Optimizations,'' </title> <booktitle> Conf. Record of the Eighth ACM Symp. on Principles of Programming Languages, </booktitle> <pages> pp. </pages> <address> 207-218 Williamsburg, VA, </address> <month> (January </month> <year> 1981). </year>
Reference-contexts: This definition of data dependence is different from the standard ones <ref> [3, 6] </ref> in that our definition combines the notions of flow-, anti-, and output-dependence, and does not explicitly state the variable involved. 2 TR 908 January 19, 1990 execute exactly the same events as P This result can be proven by showing that the execution result of each state ment instance
Reference: [7] <author> Lamport, Leslie, </author> <title> ``How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs,'' </title> <journal> IEEE Trans. on Computers C-28(9) pp. </journal> <month> 690-691 (September </month> <year> 1979). </year>
Reference-contexts: TR 908 January 19, 1990 not assume the existence of atomic operations. We consider the class of shared-memory parallel programs that execute on sequentially consistent processors <ref> [7] </ref> and that use fork/join and either counting semaphores or event style synchronization. A program execution is described by a collection of events and two relations over those events. Each event represents an execution instance of a set of (consecutively executed) program statements.
Reference: [8] <author> Lamport, Leslie, </author> <title> ``The Mutual Exclusion Problem: Part I A Theory of Interprocess Communication,'' </title> <journal> Journal of the ACM 33(2) pp. </journal> <month> 313-326 (April </month> <year> 1986). </year>
Reference-contexts: Our model provides a formalism for reasoning about shared-memory parallel program executions that does hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh This section is a brief presentation of the model that was first presented by us in an earlier paper [10], and is based on Lamport's theory of concurrent systems <ref> [8] </ref>. TR 908 January 19, 1990 not assume the existence of atomic operations. We consider the class of shared-memory parallel programs that execute on sequentially consistent processors [7] and that use fork/join and either counting semaphores or event style synchronization.
Reference: [9] <author> Mellor-Crummey, John M., </author> <title> ``Debugging and Analysis of Large-Scale Parallel Programs,'' </title> <type> Ph.D. Thesis, </type> <institution> also available as Computer Science Dept. </institution> <type> Tech. Rep. 312, </type> <institution> Univ. of Rochester, </institution> <month> (September </month> <year> 1989). </year>
Reference-contexts: same events as P This result can be proven by showing that the execution result of each state ment instance depends only upon the values of the variables it reads, and that the program's input and the shared data dependences uniquely characterize these values for each step in the computation <ref> [9] </ref>. Therefore, a program execution P = E , T D is a feasible program execution for P = E, T D (F1) E = E, and (F2) P satisfies the axioms of the model [10], and (F3) a b fi a b.
Reference: [10] <author> Netzer, Robert H. B. and Barton P. Miller, </author> <title> ``Detecting Data Races in Parallel Program Executions,'' in Languages and Compilers for Parallel Computing, </title> <editor> ed. D. Gelernter, T. Gross, A. Nicolau, and D. Padua, </editor> <title> MIT Press (1991). </title> <booktitle> Also appears in Proc. of the 3rd Workshop on Programming Languages and Compilers for Parallel Computing, </booktitle> <address> Irvine, CA, </address> <month> (Aug. </month> <year> 1990). </year>
Reference-contexts: Our model provides a formalism for reasoning about shared-memory parallel program executions that does hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh This section is a brief presentation of the model that was first presented by us in an earlier paper <ref> [10] </ref>, and is based on Lamport's theory of concurrent systems [8]. TR 908 January 19, 1990 not assume the existence of atomic operations. We consider the class of shared-memory parallel programs that execute on sequentially consistent processors [7] and that use fork/join and either counting semaphores or event style synchronization. <p> The temporal ordering and shared-data dependence relations must satisfy several axioms that describe properties a valid program execution must possess <ref> [10] </ref>. We omit these axioms here as they are not required to prove our results. 3. Problem Statement In a given program execution, the temporal ordering between some events is not always ``guaranteed''. <p> Therefore, a program execution P = E , T D is a feasible program execution for P = E, T D (F1) E = E, and (F2) P satisfies the axioms of the model <ref> [10] </ref>, and (F3) a b fi a b. These conditions state that any valid program execution (i.e., a program execution obeying the axioms mentioned in Section 2) possessing the same events and shared-data dependences as P describes an execution that is guaranteed to have potentially occurred. <p> An implication of these results is that exhaustively detecting all data races potentially exhibited by a given program execution <ref> [10] </ref> is an intractable problem. 10 TR 908 January 19, 1990
Reference: [11] <author> Taylor, Richard N., </author> <title> ``Complexity of Analyzing the Synchronization Structure of Concurrent Programs,'' </title> <note> Acta Informatica 19 pp. 57-84 (1983). 11 </note>
Reference-contexts: Semaphores are used to represent the truth values of each variable and clause. As we will show, the execution exhibits certain orderings iff B is not satisfiable. For each variable, X i , construct the following three processes: hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh This reduction was motivated by the ones Taylor <ref> [11] </ref> constructed to prove that certain static analysis problems are NP-complete. 6 TR 908 January 19, 1990 P (A i ) P (A i ) V (A i ) hh i ) P (Pass 2) . .
References-found: 11

