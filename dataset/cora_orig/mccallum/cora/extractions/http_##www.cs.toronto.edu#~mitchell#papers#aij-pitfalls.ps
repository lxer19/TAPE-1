URL: http://www.cs.toronto.edu/~mitchell/papers/aij-pitfalls.ps
Refering-URL: http://www.cs.toronto.edu/~mitchell/
Root-URL: http://www.cs.toronto.edu
Title: Some Pitfalls for Experimenters with Random SAT  
Author: David G. Mitchell Hector J. Levesque 
Address: Toronto, Toronto, Ontario M5S 1A4, Canada  
Affiliation: Department of Computer Science, University of  
Abstract: We consider the use of random CNF formulas in evaluating the performance of SAT testing algorithms, and in particular the role that the phase transition phenomenon plays in this use. Examples from the literature illustrate the importance of understanding the properties of formula distributions prior to designing an experiment. We expect this to be of increasing importance in the field. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bengt Aspvall, Michael F. Plass, and Robert Endre Tarjan. </author> <title> A linear-time algorithm for testing the truth of certain quantified boolean formulas. </title> <journal> Information Processing Letters, </journal> <volume> 8(3) </volume> <pages> 121-123, </pages> <month> March </month> <year> 1979. </year>
Reference-contexts: Random 2-SAT does not exhibit a hard region in the sense that is seen when k is larger 5 , which is perhaps not surprising since 2-SAT is solvable in time O (n + m) <ref> [1] </ref>. Table 1 shows median DP steps, and the ratio of median DP steps to n, to test random 2-SAT with c = 1 and n up to 250. At least over this range the median number of steps is smaller than n, and grows no faster than n.
Reference: [2] <author> M. Chao and J. Franco. </author> <title> Probabilistic analysis of a generalization of the unit-clause literal selection heuristics for the k satisfiability problem. </title> <journal> Information Sciences, </journal> <volume> 51 </volume> <pages> 289-314, </pages> <year> 1990. </year>
Reference: [3] <author> Peter Cheeseman, Bob Kanefsky, and William M. Taylor. </author> <title> Where the really hard problems are. </title> <booktitle> In Proc. IJCAI-91, </booktitle> <year> 1991. </year>
Reference-contexts: The transition region becomes narrower (that is, occurs over a smaller range of c) as n is increased. The peak hardness for DP occurs at approximately the point where 40% of the formulas are satisfiable, and shifts 5 Cheeseman et al. <ref> [3] </ref> hypothesized that phase transitions might not occur for problems in P. Random 2-SAT is one of several counterexamples, but the present observation suggests a revised version of the hypothesis. 5 0.0 1.0 10 1000 100000 DP Steps Ratio of Clauses to Variables n=25 n=75 Fig. 3.
Reference: [4] <author> James M. Crawford and Andrew B. Baker. </author> <title> Experimental results on the application of satisfiability algorithms to scheduling problems. </title> <booktitle> In Proc. AAAI-94, </booktitle> <year> 1994. </year>
Reference: [5] <author> J.M. Crawford and L.D. Auton. </author> <title> Experimental results on the cross-over point in satisfiability problems. </title> <booktitle> In Proc. AAAI-93, </booktitle> <pages> pages 21-29, </pages> <year> 1993. </year>
Reference: [6] <author> A. d'Anjou, M. Gra~na, F.J. Torrealdea, and M.C. Hernandez. </author> <title> Solving satisfiability via Boltzmann machines. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(5), </volume> <month> May </month> <year> 1993. </year> <month> 16 </month>
Reference-contexts: At lower ratios even fewer backtracks were needed. These formulas, despite being very large, are trivial to test on average. 6 Interaction of Parameters In <ref> [6] </ref> d'Anjou and his colleagues report tests using a variety of random formulas to demonstrate the performance of a Boltzmann Machine method for SAT testing (which we will refer to as BM). <p> Our data suggests that none of the formula sets used in <ref> [6] </ref> are harder than random 2-SAT, and so all experiments reported there are examples of "missing the hard region", as discussed in Section 5. However, there are additional issues involved here. We don't know how BM would perform on hard formulas, but the results in [6] seem to be an artifact <p> the formula sets used in <ref> [6] </ref> are harder than random 2-SAT, and so all experiments reported there are examples of "missing the hard region", as discussed in Section 5. However, there are additional issues involved here. We don't know how BM would perform on hard formulas, but the results in [6] seem to be an artifact of the easy formulas, and unfortunate parameter choices, rather than indicative of positive performance characteristics of BM. Increasing n while m is fixed leads to small values of c, and thus easy instances.
Reference: [7] <author> M. Davis, G. Logemann, and D. Loveland. </author> <title> A machine program for theorem--proving. </title> <journal> Communications of the ACM, </journal> <volume> 5 </volume> <pages> 394-397, </pages> <year> 1962. </year>
Reference-contexts: The procedure DP. DP is essentially the splitting variant of the Davis-Putnam Procedure as described in <ref> [7] </ref>, but without the pure literal rule. It uses no heuristics other than 2 unit propagation. This is perhaps the simplest complete SAT testing proce-dure that performs well enough to be useful, and so provides a kind of baseline for performance of many related methods.
Reference: [8] <author> M. Davis and H. Putnam. </author> <title> A computing procedure for quantification theory. </title> <journal> Journal of the ACM, </journal> <volume> 7 </volume> <pages> 201-215, </pages> <year> 1960. </year>
Reference-contexts: In Section 8 we summarize. 2 Materials and Methods We assume the reader is familiar with the problem SAT as defined in [12]. The data for our analysis was produced by testing randomly generated SAT instances with a simple version of the Davis-Putnam Procedure <ref> [8] </ref>. Our procedure, which we refer to as "DP", is shown in Figure 1. In the figure, ! denotes a CNF formula and !np denotes the formula that results when we simplify ! by setting the variable p true.
Reference: [9] <author> John Franco. </author> <title> On the probabilistic performance of algorithms for the satisfiability problem. </title> <journal> Information Processing Letters, </journal> <volume> 23 </volume> <pages> 103-106, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: Distributions with clause lengths distributed uniformly over some fixed range [k,l]. We will call such distributions "[k,l]-SAT". 3 A clause is trivial if it contains both a variable and its negation. 4 Moreover, Wu and Tang [27] extending work by Franco <ref> [9] </ref> and others presented an algorithm which solves instances of this family with probability not less than 1 *, for any constant * &gt; 0, in polynomial expected time.
Reference: [10] <author> A. Frieze and S. Suen. </author> <title> Analysis of three simple heuristics on a random instance of k-SAT. </title> <type> Manuscript, </type> <year> 1992. </year>
Reference-contexts: The asymptotic location of the transition region is analytically bounded above and below: For k = 3, the currently known bounds are c = 4:758 [18] and c = 3:003 <ref> [10] </ref> respectively. The lower graph of Figure 2 shows the median number of DP steps required to test the same formulas. Note the logarithmic y-axis, necessitated by the dramatic increase of peak difficulty with increasing k. As expected, the peak at each k lines up with the corresponding transition region.
Reference: [11] <author> Giorgio Gallo and Giampaolo Urbani. </author> <title> Algorithms for testing the satisfiability of propositional formulae. </title> <journal> Journal of Logic Programming, </journal> <volume> 7 </volume> <pages> 45-61, </pages> <year> 1989. </year>
Reference-contexts: Yet DP which can be expressed as a resolution strategy [15] required almost no backtracking (less than 3 backtracks on average) to test them, and consistently solves them in a small fraction of a second. Gallo and Urbani <ref> [11] </ref> compared the performance of several enhancements to the Davis-Putnam Procedure on [1,7]-SAT. We again generated a range of these formulas and tested them with DP. <p> In this section we consider whether this approach is adequate in the common situation in which the experimenter cannot precisely determine the location of peak hardness. To begin, we consider an experiment by Gallo and Urbani <ref> [11] </ref>, in which performance of several SAT procedures were compared on 5 sets of random 3-SAT formulas, for which partial results are shown in Table 2. <p> We would claim that all the ratios used in <ref> [11] </ref> are well within this hard region. So can it matter that much if we test exactly at the peak? If we are reasonably close, and if we are only interested in dramatic performance improvements, perhaps not.
Reference: [12] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freeman, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Sections 4 to 7 examine individual experiments, in light of what we now know about the formulas used. Additional data is presented as needed. In Section 8 we summarize. 2 Materials and Methods We assume the reader is familiar with the problem SAT as defined in <ref> [12] </ref>. The data for our analysis was produced by testing randomly generated SAT instances with a simple version of the Davis-Putnam Procedure [8]. Our procedure, which we refer to as "DP", is shown in Figure 1.
Reference: [13] <author> I.P. Gent and T. Walsh. </author> <title> The hardest random SAT problems. </title> <booktitle> In Proceedings, KI-94, </booktitle> <year> 1994. </year>
Reference-contexts: The harder formulas occur so rarely we would not expect to see them in studies with small sample sizes such as the examples in this section. Gent and Walsh <ref> [13] </ref> have studied apparently harder, but rarer still, formulas in this region.
Reference: [14] <author> I.P. Gent and T. Walsh. </author> <title> The SAT phase transition. </title> <booktitle> In Proceedings, ECAI-94, </booktitle> <pages> pages 103-109, </pages> <year> 1994. </year>
Reference: [15] <author> A. Goldberg. </author> <title> On the complexity of the satisfiability problem. </title> <institution> Courant Computer Science Report No. </institution> <address> 16., 1979. New York University. </address>
Reference-contexts: Hooker noted that the cutting plane algorithm required only a very small number of iterations to solve these problems, while his resolution procedure performed so poorly that he was unable to report completion times for most conditions. Yet DP which can be expressed as a resolution strategy <ref> [15] </ref> required almost no backtracking (less than 3 backtracks on average) to test them, and consistently solves them in a small fraction of a second. Gallo and Urbani [11] compared the performance of several enhancements to the Davis-Putnam Procedure on [1,7]-SAT.
Reference: [16] <author> Jun Gu. </author> <title> Efficient local search for very large-scale satisfiability problems. </title> <journal> SIGART Bulletin, </journal> <volume> 3(1) </volume> <pages> 8-12, </pages> <year> 1992. </year>
Reference-contexts: In this section we will see that experimenters have often used formulas from this distribution, but from below the hard region, which are trivial in spite of their large size. Gu <ref> [16] </ref> and Kamath et al. [19] evaluated their procedures (based on local search and interior point programming, respectively) by testing large random E3-SAT formulas, Gu with n 2 f50; 500; 1000g and Kamath with n = 1000, in all cases with c = 2. <p> The first is that size alone (or number of variables) is not a useful measure of hardness (cf Section 5). This is important because in evaluating algorithm performance we are most interested in what happens as problem size increases. Formulas with 5000 variables, 50,000 clauses and 500,000 literals <ref> [16] </ref> sound impressively large, but when they are from a distribution like the one we called random E10-SAT, they can be solved very easily by a simple procedure like DP, with less than one backtrack on average.
Reference: [17] <author> J.N. Hooker. </author> <title> Resolution vs. cutting plane solution of inference problems: some computational experience. </title> <journal> Operations Research Letters, </journal> <volume> 7(1) </volume> <pages> 1-7, </pages> <year> 1988. </year>
Reference-contexts: Median DP steps for formulas used by Hooker. Hooker <ref> [17] </ref> compared the performance of a resolution-based procedure with that of one based on cutting planes, using constant density formulas with unit clauses allowed, but empty and trivial clauses prohibited. <p> We confirmed this behavior up to n = 1000, where the peak remains smaller than that of random 2-SAT. Virtually no backtracking is required to test these formulas. We conclude that formula distributions such as [1,7]-SAT and those used by Hooker in <ref> [17] </ref> are no harder on average than random 2-SAT, and thus of little use in SAT algorithm evaluation. 5 Missing the Hard Region We observed in Section 3 that random Ek-SAT does exhibit a hard region, although orders of magnitude easier than comparable random k-SAT formulas.
Reference: [18] <author> Anil Kamath, Rajeev Motwani, Krishna Palem, and Paul Spirakis. </author> <title> Tail bounds for occupancy and the satisfiability threshold conjecture. </title> <booktitle> In Proc. </booktitle> <address> FOCS-94, </address> <year> 1994. </year>
Reference-contexts: The asymptotic location of the transition region is analytically bounded above and below: For k = 3, the currently known bounds are c = 4:758 <ref> [18] </ref> and c = 3:003 [10] respectively. The lower graph of Figure 2 shows the median number of DP steps required to test the same formulas. Note the logarithmic y-axis, necessitated by the dramatic increase of peak difficulty with increasing k.
Reference: [19] <author> A.P. Kamath, N.K. Karmarkar, K.G. Ramakrishnan, and M.G.C. Resende. </author> <title> Computational experience with an interior point algorithm on the satisfiability problem. </title> <booktitle> In Integer Programming and Combinatorial Optimization, </booktitle> <pages> pages 333-349. </pages> <publisher> Mathematical Programming Society, </publisher> <month> May </month> <year> 1990. </year>
Reference-contexts: In this section we will see that experimenters have often used formulas from this distribution, but from below the hard region, which are trivial in spite of their large size. Gu [16] and Kamath et al. <ref> [19] </ref> evaluated their procedures (based on local search and interior point programming, respectively) by testing large random E3-SAT formulas, Gu with n 2 f50; 500; 1000g and Kamath with n = 1000, in all cases with c = 2.
Reference: [20] <author> Scott Kirkpatrick and Bart Selman. </author> <title> Critical behavior in the satisfiability of random boolean expressions. </title> <journal> Science, </journal> <volume> 264, </volume> <month> may 27 </month> <year> 1994. </year>
Reference: [21] <author> Kurt Konolige. </author> <title> Easy to be hard: Difficult problems for greedy algorithms. </title> <booktitle> In Proc. KR-94, </booktitle> <pages> pages 374-378, </pages> <year> 1994. </year>
Reference-contexts: While it might be argued that it is too easy to point the finger at previous work in light of our current state of knowledge, there is an important lesson for future work, especially regarding "more structured" random distributions, such as those used in <ref> [21] </ref>, or those used by workers in scheduling or constraint satisfaction. Similar pitfalls should be expected with any non-trivial parame 15 terized distribution of random problems, and in fact will likely become even more troublesome.
Reference: [22] <author> T. Larrabee and Y. Tsuji. </author> <title> Evidence for a satisfiability threshold for random 3CNF formulas. </title> <type> Technical Report UCSC-CRL-92-42, CRL, </type> <institution> University of California, Santa Cruz, </institution> <month> November </month> <year> 1992. </year> <month> 17 </month>
Reference: [23] <author> David Mitchell, Bart Selman, and Hector .J. Levesque. </author> <title> Generating hard satisfiability problems. This volume. </title>
Reference-contexts: Randomly generated CNF formulas are a popular class of test problems for evaluating the performance of SAT testing programs. Not surprisingly, the choice of formula distribution is crucial to the validity of any investigation using random formulas. In <ref> [23] </ref>, we argued that some families of distributions were more useful sources of test material than others, and suggested choosing formulas from the "hard region" associated with the satisfiable-to-unsatisfiable phase transition which occurs as the number of clauses is increased. <p> In <ref> [23] </ref> we suggested that peak hardness of random 3-SAT for the Davis-Putnam Procedure was near the ratio where about half the instances were satisfiable, but the algorithms in each of [23,22,5] appear to peak at slightly different ratios. 3.2 Random Ek-SAT for testing random Ek-SAT with n = 25 variables, for
Reference: [24] <author> P. Purdom. </author> <title> A survey of average time analyses of satisfiability algorithms. </title> <journal> Journal of Information Processing, </journal> <volume> 13(4), </volume> <year> 1990. </year>
Reference: [25] <author> Bart Selman, Henry Kautz, and Bram Cohen. </author> <title> Noise strategies for improving local search. </title> <booktitle> In Proceedings, AAAI-94, </booktitle> <pages> pages 337-343, </pages> <year> 1994. </year>
Reference-contexts: These have been used with considerable success for 14 finding satisfying truth assignments for satisfiable formulas [26,16,25]. Random 3-SAT formulas have been among the primary test sets used in this work, and success has been reported with formulas near the hard region and having thousands of variables <ref> [25] </ref>.
Reference: [26] <author> Bart Selman, Hector Levesque, and David Mitchell. </author> <title> A new method for solving hard satisfiability problems. </title> <booktitle> In Proceedings, AAAI-92, </booktitle> <address> San Jose, CA, </address> <year> 1992. </year>
Reference: [27] <author> L.C. Wu and C. Y. Tang. </author> <title> Solving the satisfiability problem by using randomized approach. </title> <journal> Information Processing Letters, </journal> <volume> 41 </volume> <pages> 187-190, </pages> <year> 1992. </year> <month> 18 </month>
Reference-contexts: Distributions with clause lengths distributed uniformly over some fixed range [k,l]. We will call such distributions "[k,l]-SAT". 3 A clause is trivial if it contains both a variable and its negation. 4 Moreover, Wu and Tang <ref> [27] </ref> extending work by Franco [9] and others presented an algorithm which solves instances of this family with probability not less than 1 *, for any constant * &gt; 0, in polynomial expected time.
References-found: 27

