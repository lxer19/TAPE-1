URL: ftp://ftp.cs.wisc.edu/computer-vision/cvpr94-2-kutulakos.ps.gz
Refering-URL: http://www.cs.wisc.edu/computer-vision/pubs.html
Root-URL: 
Email: kyros@cs.wisc.edu  dyer@cs.wisc.edu  
Title: Global Surface Reconstruction by Purposive Control of Observer Motion  
Author: Kiriakos N. Kutulakos Charles R. Dyer 
Address: Madison, Wisconsin 53706  
Affiliation: Computer Sciences Department University of Wisconsin  
Note: To appear in: Proc. CVPR'94, Seattle, WA  
Abstract: What real-time, qualitative viewpoint-control behaviors are important for performing global visual exploration tasks such as searching for specific surface markings, building a global model of an arbitrary object, or recognizing an object? In this paper we consider the task of purposefully controlling the motion of an active, monocular observer in order to recover a global description of a smooth, arbitrarily-shaped object using the occluding contour. By studying the epipolar parameterization, we develop two basic behaviors that allow reconstruction of a patch around any point in a reconstructible surface region. These behaviors rely only on information extracted directly from images (e.g., tangents to the occluding contour), and are simple enough to be executed in real time. We then show how global surface reconstruction can be provably achieved by (1) integrating these behaviors to iteratively grow the reconstructed regions, and (2) obeying four simple rules. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Cipolla and A. Blake, </author> <title> Surface shape from the deforma tion of apparent contours, </title> <journal> IJCV, </journal> <volume> 9(2): </volume> <pages> 83-112, </pages> <year> 1992. </year>
Reference-contexts: We consider this task for smooth surfaces of arbitrary shape; the object is unknown, can be non-convex, and can self-occlude. We use a shape-from-motion module for extracting surface shape information <ref> [1] </ref>; we assume that the object is stationary and the observer is able to freely move on a sphere around it. Our goal is to control the observer's viewpoint so that global surface reconstruction is guaranteed. <p> This makes the reconstructed regions unpredictable. Moreover, in the context of animate [3] and purposive [2] vision, their major drawback is their inability to exploit real-time viewpoint control to simplify the reconstruction process (e.g., by utilizing shape-from-motion approaches, which have been shown to considerably simplify shape recovery computations <ref> [1] </ref>), as well as to simplify the viewpoint control process itself. (a) (b) (c) in (a), to slide over the dark curve drawn on the torus. In this paper we use the occluding contour to control viewpoint and to derive shape information. <p> use sophisticated sensing mechanisms to reconstruct the scene from a single viewpoint or a small number of viewpoints [9, 10], recent results demonstrate that the occluding contour can be reliably detected in edge images [13], and that shape (e.g., curvature) can be efficiently and accurately recovered from the occluding contour <ref> [1, 7] </ref>. <p> The shape and topology of the visible rim and the occluding contour depends on S and the observer's viewpoint. A suitable surface parameterization relating the shapes of S, the visible rim, and the occluding contour is the epipolar parameterization <ref> [1, 11] </ref>. Intuitively, the epipolar param p c (t + t) 0 D x (s ,t) 0 epipolar plane P x (s; t 0 + t) are curves on the visible rim of the surface corresponding to observer positions c (t 0 ) and c (t 0 + t), respectively. <p> This allows the non-concave parts of the surface to be considered as a collection of patches, each of which is a family of visible rim curves (Figure 2). The epipolar parameterization was used in <ref> [1, 11] </ref> to recover the fundamental forms of all points in from the deformation of the occluding contour during the observer's motion. <p> Point p occ must not be the endpoint of an occluding contour curve. Step 2: Compute the surface normal at p. The normal is given by T ^ p occ , where T is the tangent to the occluding contour at p occ <ref> [1] </ref>. Step 3: (Reconstructing the occluded points near p.) Select a direction v 1 for moving on the motion sphere that satisfies the inequality n (p) v 1 &gt; 0.
Reference: [2] <author> Y. Aloimonos, </author> <title> Active vision revisited, </title> <booktitle> in Active Perception, </booktitle> <pages> pp. 1-18, </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1993. </year>
Reference-contexts: When trying to perform tasks that depend on an object's appearance, provable correctness is critical: The appearance of objects can drastically change depending on the observer's viewpoint, making ad hoc viewpoint control mechanisms unpredictable and incomplete. Furthermore, like many others (e.g., <ref> [2, 3] </ref>), we are interested in mechanisms that tightly couple sensing The support of the National Science Foundation under Grant No. IRI-9220782 is greatfully acknowledged. and action and allow real-time execution. <p> Another disadvantage of such mechanisms is that they do not take into account how the global geometry of the surface (e.g., self-occlusions) affects the correctness of the global reconstruction algorithms. This makes the reconstructed regions unpredictable. Moreover, in the context of animate [3] and purposive <ref> [2] </ref> vision, their major drawback is their inability to exploit real-time viewpoint control to simplify the reconstruction process (e.g., by utilizing shape-from-motion approaches, which have been shown to considerably simplify shape recovery computations [1]), as well as to simplify the viewpoint control process itself. (a) (b) (c) in (a), to slide
Reference: [3] <author> D. H. Ballard and C. M. Brown, </author> <booktitle> Principles of animate vi sion, in Active Perception, </booktitle> <pages> pp. 245-282, </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1993. </year>
Reference-contexts: When trying to perform tasks that depend on an object's appearance, provable correctness is critical: The appearance of objects can drastically change depending on the observer's viewpoint, making ad hoc viewpoint control mechanisms unpredictable and incomplete. Furthermore, like many others (e.g., <ref> [2, 3] </ref>), we are interested in mechanisms that tightly couple sensing The support of the National Science Foundation under Grant No. IRI-9220782 is greatfully acknowledged. and action and allow real-time execution. <p> IRI-9220782 is greatfully acknowledged. and action and allow real-time execution. This is because our purpose is to exploit the ability to quickly control viewpoint to achieve simple and efficient solutions for a given task, rather than rely on the availability of large amounts of computational power <ref> [3] </ref>. To emphasize this point we refer to such mechanisms as viewpoint control behaviors. Very little work has been published on the use of viewpoint control behaviors for reconstruction, exploration or recognition tasks. However, the few recent approaches taking advantage of viewpoint-control behaviors demonstrate their importance and generality. <p> Another disadvantage of such mechanisms is that they do not take into account how the global geometry of the surface (e.g., self-occlusions) affects the correctness of the global reconstruction algorithms. This makes the reconstructed regions unpredictable. Moreover, in the context of animate <ref> [3] </ref> and purposive [2] vision, their major drawback is their inability to exploit real-time viewpoint control to simplify the reconstruction process (e.g., by utilizing shape-from-motion approaches, which have been shown to considerably simplify shape recovery computations [1]), as well as to simplify the viewpoint control process itself. (a) (b) (c) in
Reference: [4] <author> K. N. Kutulakos and C. R. Dyer, </author> <title> Recovering shape by pur posive viewpoint adjustment, </title> <journal> IJCV, </journal> <volume> 12(2): </volume> <pages> 113-136, </pages> <year> 1994. </year>
Reference-contexts: Very little work has been published on the use of viewpoint control behaviors for reconstruction, exploration or recognition tasks. However, the few recent approaches taking advantage of viewpoint-control behaviors demonstrate their importance and generality. We showed in an earlier paper <ref> [4] </ref> that the shape recovery problem for smooth surfaces becomes considerably simplified if the observer uses a simple viewpoint-control behavior to move to a special viewpoint, which for the case of surfaces of revolution corresponds to their side view.
Reference: [5] <author> D. Wilkes and J. K. Tsotsos, </author> <title> Active object recognition, </title> <booktitle> in Proc. CVPR, </booktitle> <pages> pp. 136-141, </pages> <year> 1992. </year>
Reference-contexts: The work of Wilkes and Tsotsos <ref> [5] </ref> illustrates how the ability to purposefully and quickly change viewpoint can simplify the task of object recognition in a simple world of Origami objects. Grosso and Ballard [6] are currently designing a head-eye system capable of implementing such viewpoint controls.
Reference: [6] <author> E. Grosso and D. H. Ballard, </author> <title> Head-centered orientation strategies in animate vision, </title> <booktitle> in Proc. 4th ICCV, </booktitle> <year> 1993. </year>
Reference-contexts: The work of Wilkes and Tsotsos [5] illustrates how the ability to purposefully and quickly change viewpoint can simplify the task of object recognition in a simple world of Origami objects. Grosso and Ballard <ref> [6] </ref> are currently designing a head-eye system capable of implementing such viewpoint controls. Recent work by Blake et al. [7] showed that shorter paths can be achieved in robotic navigation tasks if the shape of the obstacles is taken into account during navigation.
Reference: [7] <author> A. Blake, A. Zisserman, and R. Cipolla, </author> <title> Visual exploration of free-space, </title> <booktitle> in Active Vision, </booktitle> <pages> pp. 175-188, </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Grosso and Ballard [6] are currently designing a head-eye system capable of implementing such viewpoint controls. Recent work by Blake et al. <ref> [7] </ref> showed that shorter paths can be achieved in robotic navigation tasks if the shape of the obstacles is taken into account during navigation. <p> use sophisticated sensing mechanisms to reconstruct the scene from a single viewpoint or a small number of viewpoints [9, 10], recent results demonstrate that the occluding contour can be reliably detected in edge images [13], and that shape (e.g., curvature) can be efficiently and accurately recovered from the occluding contour <ref> [1, 7] </ref>.
Reference: [8] <author> C. I. Connoly, </author> <title> The determination of next best views, </title> <booktitle> in Proc. IEEE Robotics Automat. Conf., </booktitle> <pages> pp. 432-435, </pages> <year> 1985. </year>
Reference-contexts: Apart from the above approaches, viewpoint control for performing various tasks has been treated as a complex and computationally-intensive optimization problem (i.e., where to look next), where the best next viewpoint is searched for within the space of all possible viewpoints <ref> [8] </ref>. In tasks involving global surface reconstruction, the viewpoint-control mechanisms assumed that a three-dimensional representation of the visible surfaces can be recovered independently from each viewpoint [8-10], ruling out their applicability in more qualitative visual exploration tasks.
Reference: [9] <author> P. Whaite and F. P. Ferrie, </author> <title> From uncertainty to visual ex ploration, </title> <journal> IEEE T-PAMI, </journal> <volume> 13(10): </volume> <pages> 1038-1049, </pages> <year> 1991. </year>
Reference-contexts: The occluding contour is a rich source of shape information [11, 12]. Moreover, contrary to approaches that use sophisticated sensing mechanisms to reconstruct the scene from a single viewpoint or a small number of viewpoints <ref> [9, 10] </ref>, recent results demonstrate that the occluding contour can be reliably detected in edge images [13], and that shape (e.g., curvature) can be efficiently and accurately recovered from the occluding contour [1, 7].
Reference: [10] <author> J. Maver and R. </author> <title> Bajcsy, Occlusions as a guide for planning the next view, </title> <journal> IEEE T-PAMI, </journal> <volume> 15(5): </volume> <pages> 417-433, </pages> <year> 1993. </year>
Reference-contexts: The occluding contour is a rich source of shape information [11, 12]. Moreover, contrary to approaches that use sophisticated sensing mechanisms to reconstruct the scene from a single viewpoint or a small number of viewpoints <ref> [9, 10] </ref>, recent results demonstrate that the occluding contour can be reliably detected in edge images [13], and that shape (e.g., curvature) can be efficiently and accurately recovered from the occluding contour [1, 7].
Reference: [11] <author> P. Giblin and R. Weiss, </author> <title> Reconstruction of surfaces from profiles, </title> <booktitle> in Proc. 1st ICCV, </booktitle> <pages> pp. 136-144, </pages> <year> 1987. </year>
Reference-contexts: The occluding contour is the projection of the visible rim, the one-dimensional set of visible surface points at which the line of sight is tangent. The occluding contour is a rich source of shape information <ref> [11, 12] </ref>. <p> The shape and topology of the visible rim and the occluding contour depends on S and the observer's viewpoint. A suitable surface parameterization relating the shapes of S, the visible rim, and the occluding contour is the epipolar parameterization <ref> [1, 11] </ref>. Intuitively, the epipolar param p c (t + t) 0 D x (s ,t) 0 epipolar plane P x (s; t 0 + t) are curves on the visible rim of the surface corresponding to observer positions c (t 0 ) and c (t 0 + t), respectively. <p> This allows the non-concave parts of the surface to be considered as a collection of patches, each of which is a family of visible rim curves (Figure 2). The epipolar parameterization was used in <ref> [1, 11] </ref> to recover the fundamental forms of all points in from the deformation of the occluding contour during the observer's motion.
Reference: [12] <author> J. J. Koenderink, </author> <title> Solid Shape. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The occluding contour is the projection of the visible rim, the one-dimensional set of visible surface points at which the line of sight is tangent. The occluding contour is a rich source of shape information <ref> [11, 12] </ref>. <p> The occluding contour is the projection of the visible rim on the image. For almost all positions of the observer, the visible rim is a collection of closed and open smooth curves whose endpoints project to cusps or T-junctions on the occluding contour <ref> [12] </ref>. The shape and topology of the visible rim and the occluding contour depends on S and the observer's viewpoint. A suitable surface parameterization relating the shapes of S, the visible rim, and the occluding contour is the epipolar parameterization [1, 11]. <p> Results from singularity theory show that the space of viewpoints can be partitioned into a collection of maximal connected cells within which the occluding contour's topology remains constant <ref> [12, 15] </ref>. Visual events occur when the observer's viewpoint belongs to the boundaries of these cells. An infinitesimal perturbation of such a viewpoint results in changes in the occluding contour's topology. A catalog of the visual events can be found in [15]. <p> This can happen only if the line connecting c and p has a high order contact with the surface or if it contacts the surface at multiple points <ref> [12] </ref>, i.e., if and only if p belongs to a visual event curve.
Reference: [13] <author> R. Vaillant and O. D. Faugeras, </author> <title> Using extremal boundaries for 3-d object modeling, </title> <journal> IEEE T-PAMI, </journal> <volume> 14(2): </volume> <pages> 157-173, </pages> <year> 1992. </year>
Reference-contexts: Moreover, contrary to approaches that use sophisticated sensing mechanisms to reconstruct the scene from a single viewpoint or a small number of viewpoints [9, 10], recent results demonstrate that the occluding contour can be reliably detected in edge images <ref> [13] </ref>, and that shape (e.g., curvature) can be efficiently and accurately recovered from the occluding contour [1, 7].
Reference: [14] <author> K. N. Kutulakos, W. B. Seales, and C. R. Dyer, </author> <title> Building global object models by purposive viewpoint control, </title> <booktitle> in Proc. 2nd CAD-Based Vision Workshop, </booktitle> <pages> pp. 169-182, </pages> <year> 1994. </year>
Reference-contexts: In <ref> [14] </ref> we showed how the observer can control viewpoint to perform the local and incremental surface reconstruction tasks under the assumption that topological changes on the visible rim do not occur in the vicinity of the reconstructed patch. <p> Below we outline the behavior handling the case of ordinary points for completeness (see <ref> [14] </ref> for details), and focus on the case of degenerate points which is central for obtaining the global results of Sections 4 and 6. <p> Below we outline the behavior handling the case of ordinary points for completeness (see [14] for details), and focus on the case of degenerate points which is central for obtaining the global results of Sections 4 and 6. The interested reader is refered to <ref> [14, 16] </ref> for a detailed treatment of the remaining cases. 3.1 Reconstruction Around Ordinary Points Ordinary Patch Reconstruction Behavior Step 1: Select a point p on the visible rim that is not the endpoint of a visible rim curve. <p> To achieve this, we incrementally grow the patches initially reconstructed on the surface. The following composite behavior is based on the observation that the boundaries of the already-reconstructed patches were endpoints of the visible rim at previous viewpoints. See <ref> [14] </ref> for more details. Incremental Reconstruction Behavior Step 1: If there exists a portion of the surface that has not been reconstructed, select a point p on its boundary and let c be the viewpoint at which p projected to the occluding contour.
Reference: [15] <author> S. Petitjean, J. Ponce, and D. J. Kriegman, </author> <title> Computing exact aspect graphs of curved objects: Algebraic surfaces, </title> <journal> IJCV, </journal> <volume> 9(3): </volume> <pages> 231-255, </pages> <year> 1992. </year>
Reference-contexts: Results from singularity theory show that the space of viewpoints can be partitioned into a collection of maximal connected cells within which the occluding contour's topology remains constant <ref> [12, 15] </ref>. Visual events occur when the observer's viewpoint belongs to the boundaries of these cells. An infinitesimal perturbation of such a viewpoint results in changes in the occluding contour's topology. A catalog of the visual events can be found in [15]. <p> Visual events occur when the observer's viewpoint belongs to the boundaries of these cells. An infinitesimal perturbation of such a viewpoint results in changes in the occluding contour's topology. A catalog of the visual events can be found in <ref> [15] </ref>. <p> there are other viewpoints on p's tangent plane at which p is not the endpoint of a visible rim curve, i.e., at which Epipolar Reconstructibility Constraint C1 is satisfied. * The point p and the observer's viewpoint may be such that the occluding contour's topology changes in the 1 See <ref> [15] </ref> for details on the definition of these curves. neighborhood of p under an infinitesimal viewpoint perturbation.
Reference: [16] <author> K. N. Kutulakos and C. R. Dyer, </author> <title> Global surface reconstruc tion by purposive control of observer motion, </title> <type> Tech. Rep. 1141, </type> <institution> CS Department, University of Wisconsin Madison, </institution> <year> 1993. </year> <note> Available via ftp from ftp.cs.wisc.edu. </note>
Reference-contexts: Below we outline the behavior handling the case of ordinary points for completeness (see [14] for details), and focus on the case of degenerate points which is central for obtaining the global results of Sections 4 and 6. The interested reader is refered to <ref> [14, 16] </ref> for a detailed treatment of the remaining cases. 3.1 Reconstruction Around Ordinary Points Ordinary Patch Reconstruction Behavior Step 1: Select a point p on the visible rim that is not the endpoint of a visible rim curve. <p> For these points, there is no path the observer can follow that forces the visible rim to slide over their neighborhood. This leads directly to the following characterization of the reconstructible regions on the surface <ref> [16] </ref>: Reconstructible surface regions: The reconstructible surface regions are the maximal connected sets of points that are visible from a one-dimensional set of viewpoints on their tangent plane. <p> We keep our analysis at a fairly intuitive level, working through specific examples to motivate the rules used. Further insight into the theorems, an analysis of the global curve reconstruction task, and formal proofs of correctness can be found in <ref> [16] </ref>. 6.1 Semi-Global Curve Reconstruction Task Recall that during the execution of the Incremental Reconstruction Behavior the observer selects a point p on the boundary of the already-reconstructed regions and appropriately controls motion to reconstruct a new patch around p.
References-found: 16

