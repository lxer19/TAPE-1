URL: ftp://whitechapel.media.mit.edu/pub/jebara/icvs.ps
Refering-URL: http://jebara.www.media.mit.edu/people/jebara/arl.html
Root-URL: http://www.media.mit.edu
Email: g@media.mit.edu  
Title: Action Reaction Learning: Automatic Visual Analysis and Synthesis of Interactive Behaviour  
Author: Tony Jebara Alex Pentland f jebara, sandy 
Web: http://www.media.mit.edu/~jebara/arl  
Address: 20 Ames Street, Cambridge, MA, 02139  
Affiliation: Massachusetts Institute of Technology  
Pubnum: Perceptual Computing M.I.T. Media Laboratory  
Abstract: We propose Action-Reaction Learning as an approach for analyzing and synthesizing human be-haviour. This paradigm uncovers causal mappings between past and future events or between an action and its reaction by observing time sequences. We apply this method to analyze human interaction and to subsequently synthesize human behaviour. Using a time series of perceptual measurements, a system automatically uncovers correlations between past gestures from one human participant (an action) and a subsequent gesture (a reaction) from another participant. A probabilistic model is trained from data of the human interaction using a novel estimation technique, Conditional Expectation Maximization (CEM). The estimation uses general bounding and maximization to monotonically find the maximum conditional likelihood solution. The learning system drives a graphical interactive character which probabilistically predicts a likely response to a user's behaviour and performs it interactively. Thus, after analyzing human interaction in a pair of participants, the system is able to replace one of them and interact with a single remaining user. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Azarbayejani and A. Pentland. </author> <title> Real-time self-calibrating stereo person tracking using 3-d shape estimation from blob features. </title> <booktitle> In International Conference on Pattern Recognition (ICPR), </booktitle> <year> 1996. </year>
Reference-contexts: With these features alone, it is possible to engage in simple gestural games and interactions. The vision algorithm begins by forming a probabilistic model of skin colored regions <ref> [1] </ref>. During an o*ine process, a variety of skin-colored pixels are selected manually, forming a distribution in rgb space. This distribution can be described by a probability density function (pdf) which is used to estimate the likelihood of any subsequent pixel (x rgb ) being a skin colored pixel.
Reference: [2] <author> C. Bishop. </author> <title> Neural Networks for Pattern Recognition. </title> <publisher> Oxford Press, </publisher> <year> 1996. </year>
Reference-contexts: Thus, the dimensionality (T fi 30) is in the thousands. A dimensionality reduction of the input space is accomplished via Principal Components Analysis (PCA) <ref> [2] </ref>. Consider the input space as a large vector Y (t) composed of the concatenation of all the T vectors that were just observed y (t 1); :::y (t T ). Each vector Y represents a short term memory of the past (a 6 second chunk).
Reference: [3] <author> A. Blake and A. Yuille. </author> <title> Active vision. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: By learning correlations between gestures that have been observed perceptually (i.e. using a vision system), it is possible to imitate simple human behaviours. This is facilitated by the evolution of computer vision beyond static measurements to temporal analysis and dynamic models. For instance, Blake and others <ref> [3] </ref> discuss active vision beyond static imagery using includes Kalman filters and dynamical systems. More recently, visual tracking of human activity and other complex actions has included some learning algorithms and behavioural machinery that describe higher order control structures. <p> Typically, tracking algorithms use a variety of temporal dynamic models to assist the frame by frame vision computations. The most trivial of these is to use the last estimate in a nearest neighbour approach to initialize the next vision iteration. Kalman filtering and other dynamic models <ref> [3] </ref> involve more sophistication ranging from constant velocity models to very complex control systems. Here, the the feedback being used to constrain the vision system results from dynamics and behaviour modeling. This is similar in spirit to the mixed dynamic and behaviour models in [19].
Reference: [4] <author> C. Bregler. </author> <title> Learning and recognizing human dynamics in video sequences. </title> <booktitle> In IEEE Conf. on Computer Vision and Pattern Recognition, </booktitle> <year> 1997. </year>
Reference-contexts: Bobick and Wilson discuss learning hand dynamics using hidden Markov models in a state space [27] to learn complex gestures. Models which combine dynamics with learned Markov models are discussed by Pentland [19], and Bregler <ref> [4] </ref> for predicting and classifying human behaviour. Johnson [17] utilizes neural learning techniques to predict walking behaviours and discusses interactive behaviour synthesis as well. Thus, an important transition is taking place as automatic vision and perception allow the acquisition of behavioural models from observations.
Reference: [5] <author> R.A. Brooks. </author> <title> From earwigs to humans. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <pages> 20(2-4), </pages> <year> 1997. </year>
Reference-contexts: Important contributions in behaviour synthesis arise in robotics and animation. In the ALIVE system [15], body tracking allows users to interact with Silas, a graphical dog based on ethological models and competing behaviours. Terzopolous [22] describes an animated environment of synthetic fish based on dynamical models. In robotics, Brooks <ref> [5] </ref> points out the need for bottom-up robotics behaviour with perceptually grounded systems. Pirjanian [20] discusses objectives and decision making in robotic behaviour. Uchibe [24] trains robots to acquire soccer playing interactions using reinforcement learning. Mataric [16] presents interacting multi-agent robots inspired from biology, cognitive models and neuroscience.
Reference: [6] <author> A.P. Dempster, N.M. Laird, and D.B. Rubin. </author> <title> Maximum likelihood from incomplete data via the em algorithm. </title> <journal> Journal of the Royal Statistical Society, B39, </journal> <year> 1977. </year>
Reference-contexts: Gaussian mixture model as shown in Equation 1 (with M = 3 individual Gaussians typically). p (x rgb ) = i=1 (2) 2 j i j 2 (x rgb i ) T 1 The parameters of the pdf (p (i), i and i ) are estimated using the Expectation Maximization <ref> [6] </ref> algorithm to maximize the likelihood of the training rgb skin samples. This pdf forms a classifier and every pixel in an image is filtered through it. If the probability is above a threshold, the pixel belongs to the skin class, otherwise, it is considered non-skin. <p> Techniques such as Expectation Maximization <ref> [6] </ref> can be used to optimize the parameters of a probability density function such that its joint density is a good model of the data. In clustering, for instance, data is treated homogeneously without special considerations for the distinction between input x and output y.
Reference: [7] <author> S. Elliott and J. R. Anderson. </author> <title> The effect of memory decay on predictions from changing categories. </title> <journal> Journal of Experimental Psychology: Learning, Memory and Cognition, </journal> <year> 1995. </year>
Reference-contexts: This reflects our intuition that more temporally distant elements in the time series are less relevant for prediction. This decay agrees with some aspects of cognitive models obtained from psychological studies <ref> [7] </ref>. Once the vectors have been attenuated, they form a new 'exponentially decayed' short term memory window ^ Y (t). The process is shown in Figure 7 where a window is placed over the time series, generating a short term memory Y .
Reference: [8] <author> N. Gershenfeld and A. Weigend. </author> <title> Time Series Prediction: Forecasting the Future and Understanding the Past. </title> <publisher> Addison-Wesley, </publisher> <year> 1993. </year>
Reference-contexts: We discuss the representation of the multidimensional time series data which will be analyzed to predict and forecast its evolution, or equivalently, estimate the parameters of the 6 blobs in near future. An account of the Santa Fe competition is presented in <ref> [8] </ref> where issues in time series modeling and prediction are discussed. We consider the connectionist representation due to its explicit non-linear optimization of prediction accuracy and its promising performance against hidden Markov models, dynamic models, etc in the competition.
Reference: [9] <author> M. Isaard and A. Blake. </author> <title> A mixed-state condensation tracker with automatic model-switching. </title> <booktitle> In Sixth International Conference on Computer Vision, </booktitle> <year> 1998. </year>
Reference-contexts: More recently, visual tracking of human activity and other complex actions has included some learning algorithms and behavioural machinery that describe higher order control structures. Isaard describes how multiple hypothesis dynamical models can learn complex hand dynamics and exhibit better tracking <ref> [9] </ref>. Bobick and Wilson discuss learning hand dynamics using hidden Markov models in a state space [27] to learn complex gestures. Models which combine dynamics with learned Markov models are discussed by Pentland [19], and Bregler [4] for predicting and classifying human behaviour.
Reference: [10] <author> T. Jebara. </author> <title> Action-reaction learning: Analysis and synthesis of human behaviour. </title> <type> Master's thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1998. </year>
Reference-contexts: This forms a more discriminative model that concentrates modeling resources for the task at hand. L = i=1 We recently developed a variant of the EM algorithm called Conditional Expectation Maximization (CEM) for specifically optimizing conditional likelihood <ref> [10] </ref>. It essentially fits a probability density function (pdf) that maximizes the conditional likelihood of the response given the covariates. <p> In regression experiments on standardized databases, mixture models trained with CEM outperformed those trained with EM as well as conventional neural network architectures <ref> [10] </ref>. Thus, the CEM algorithm is used to estimate the conditional probability density (cpdf) relating past time series sequences (x) to their immediate future values (y) from training data (thousands of x; y pairs). A total of M Gaussians are fit to the data as a conditioned mixture model. <p> It is customary in Bayesian inference to use the expectation of a distribution as its representative. Using the pdf over y, we integrate as in Equation 6 to obtain the predicted ^ y, a likely reaction according to the model (we have also considered arg maximization and sampling methods <ref> [10] </ref> for obtaining ^ y candidates). ^ y = yp (yj ^ x)dy = m ^ y m p ( ^ y m j ^ x) m p ( ^ y m j ^ x) where ^ y m = y m + yx m ( ^ x x 7 Integration
Reference: [11] <author> T. Jebara, K. Russel, and A. Pentland. </author> <title> Mixtures of eigenfeatures for real-time structure from texture. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <year> 1998. </year>
Reference-contexts: This mode of operation is currently under investigation. Face modeling is also being considered as an alternate perceptual modality. A system which automatically detects the face and tracks it has been implemented <ref> [11] </ref>. It is capable of tracking the 3D rotations and movements of a face using normalized correlation coupled with structure from motion. In addition, at each moment in time, it computes an eigenspace model of the face's texture which is used to infer 3D deformations.
Reference: [12] <author> M.I. Jordan and R.A. Jacobs. </author> <title> Hierarchical mixtures of experts and the em algorithm. </title> <journal> Neural Computation, </journal> <volume> 6 </volume> <pages> 181-214, </pages> <year> 1994. </year>
Reference-contexts: The conditioned mixture of Gaussians is selected for its ability to model non-linear phenomena and its ease of use. The model can be interpreted as a mixture of experts with multiple linear regressors and ellipsoidal basis gating functions <ref> [12] </ref>.
Reference: [13] <author> E. W. </author> <title> Large, </title> <editor> H. I. Christensen, and R. Bajcsy. </editor> <title> Scaling dynamic planning and control: Cooperation through competition. </title> <booktitle> In IEEE International Conference on Robotics and Automation, </booktitle> <year> 1997. </year>
Reference-contexts: Pirjanian [20] discusses objectives and decision making in robotic behaviour. Uchibe [24] trains robots to acquire soccer playing interactions using reinforcement learning. Mataric [16] presents interacting multi-agent robots inspired from biology, cognitive models and neuroscience. Large <ref> [13] </ref> describes multiple competing dynamic models for synthesizing complex behaviour synthesis. We consider the integration of both behaviour acquisition and interactive synthesis. The Action-Reaction Learning framework is initially presented.
Reference: [14] <author> K.S. Lashley. </author> <title> The problem of serial order in behavior. In L.A. </title> <editor> Jefress, editor, </editor> <booktitle> Cerebral Mechanisms in Behavior, </booktitle> <pages> pages 112-136, </pages> <address> New York, </address> <year> 1951. </year> <booktitle> The Hixon Symposium, </booktitle> <publisher> John Wiley. </publisher>
Reference-contexts: The models were based on observation and empirical studies. These behaviourists came under criticism as cognitive science evolved beyond their over-simplified model and struggled with higher order issues (i.e. language, creativity, and attention) <ref> [14] </ref>. Nevertheless, much of the lower-order reactionary behaviour was still well modeled by the stimulus-response paradigm. To a casual observer, these simple models seem fine and it is only after closer examination that one realizes that far more complex underlying processes must be taking place.
Reference: [15] <author> P. Maes, T. Darrel, B. Blumberg, and A. Pentland. </author> <title> The alive system: Wireless, full-body interaction with autonomous agents. Special Issue on Multimedia and Multisensory Virtual Worlds, </title> <booktitle> ACM Multimedia Systems, </booktitle> <year> 1996. </year>
Reference-contexts: Once behavioural models are acquired, the ARL framework uses them to synthesize interactive behaviour with humans (again using real-time visual tracking). Important contributions in behaviour synthesis arise in robotics and animation. In the ALIVE system <ref> [15] </ref>, body tracking allows users to interact with Silas, a graphical dog based on ethological models and competing behaviours. Terzopolous [22] describes an animated environment of synthetic fish based on dynamical models. In robotics, Brooks [5] points out the need for bottom-up robotics behaviour with perceptually grounded systems.
Reference: [16] <author> M.J. Mataric. </author> <title> Behavior-based robotics as a tool for synthesis of artificial behavior and analysis of natural behavior. </title> <booktitle> Trends in Cognitive Science, </booktitle> <volume> 2(3), </volume> <year> 1998. </year>
Reference-contexts: In robotics, Brooks [5] points out the need for bottom-up robotics behaviour with perceptually grounded systems. Pirjanian [20] discusses objectives and decision making in robotic behaviour. Uchibe [24] trains robots to acquire soccer playing interactions using reinforcement learning. Mataric <ref> [16] </ref> presents interacting multi-agent robots inspired from biology, cognitive models and neuroscience. Large [13] describes multiple competing dynamic models for synthesizing complex behaviour synthesis. We consider the integration of both behaviour acquisition and interactive synthesis. The Action-Reaction Learning framework is initially presented.
Reference: [17] <author> Johnson N. and Hogg D. C. </author> <title> Learning the distribution of object trajectories for event recognition. </title> <journal> Image and Vision Computing, </journal> <volume> 14(8), </volume> <year> 1996. </year>
Reference-contexts: Bobick and Wilson discuss learning hand dynamics using hidden Markov models in a state space [27] to learn complex gestures. Models which combine dynamics with learned Markov models are discussed by Pentland [19], and Bregler [4] for predicting and classifying human behaviour. Johnson <ref> [17] </ref> utilizes neural learning techniques to predict walking behaviours and discusses interactive behaviour synthesis as well. Thus, an important transition is taking place as automatic vision and perception allow the acquisition of behavioural models from observations.
Reference: [18] <author> N. Oliver, A. Pentland, F. Berard, and J. Coutaz. Lafter: </author> <title> Lips and face tracker. </title> <booktitle> In Computer Vision and Pattern Recognition Conference '97, </booktitle> <year> 1997. </year>
Reference-contexts: Figure 3 displays such a stream (or time series). Let us assume that the stream is being generated by a vision algorithm which measures the openness of the mouth <ref> [18] </ref>. Two such algorithms are being run simultaneously on two different people. One person generates the dashed line and the other generates the solid line. Now, imagine that these two individuals are engaged in a conversation. Let us also name them Mr.
Reference: [19] <author> A. Pentland and A. Liu. </author> <title> Modeling and prediction of human behavior. </title> <booktitle> In IEEE Intelligent Vehicles 95, </booktitle> <year> 1995. </year>
Reference-contexts: Isaard describes how multiple hypothesis dynamical models can learn complex hand dynamics and exhibit better tracking [9]. Bobick and Wilson discuss learning hand dynamics using hidden Markov models in a state space [27] to learn complex gestures. Models which combine dynamics with learned Markov models are discussed by Pentland <ref> [19] </ref>, and Bregler [4] for predicting and classifying human behaviour. Johnson [17] utilizes neural learning techniques to predict walking behaviours and discusses interactive behaviour synthesis as well. Thus, an important transition is taking place as automatic vision and perception allow the acquisition of behavioural models from observations. <p> Here, the the feedback being used to constrain the vision system results from dynamics and behaviour modeling. This is similar in spirit to the mixed dynamic and behaviour models in <ref> [19] </ref>.
Reference: [20] <author> P. Pirjanian and H.I. Christensen. </author> <title> Behavior coordination using multiple-objective decision making. </title> <booktitle> In SPIE Conf. on Intelligent Systems and Advanced Manufacturing, </booktitle> <year> 1997. </year>
Reference-contexts: Terzopolous [22] describes an animated environment of synthetic fish based on dynamical models. In robotics, Brooks [5] points out the need for bottom-up robotics behaviour with perceptually grounded systems. Pirjanian <ref> [20] </ref> discusses objectives and decision making in robotic behaviour. Uchibe [24] trains robots to acquire soccer playing interactions using reinforcement learning. Mataric [16] presents interacting multi-agent robots inspired from biology, cognitive models and neuroscience. Large [13] describes multiple competing dynamic models for synthesizing complex behaviour synthesis.
Reference: [21] <author> A.C. Popat. </author> <title> Conjoint probabilistic subband modeling (phd. </title> <type> thesis). Technical Report 461, </type> <institution> M.I.T. Media Laboratory, </institution> <year> 1997. </year>
Reference-contexts: EM, on the other hand, typically optimizes p (x; y), the ability to model the data as a whole. Since resources (i.e. memory, complexity) are sparse and training examples are finite, it is preferable here to directly optimize the model's conditional likelihood <ref> [21] </ref> using CEM. In other words, we want the learning system to be good at figuring out what Mrs. Dash will do next (i.e. use x to predict y). We are not as interested in asking the system what past event would have provoked Mrs.
Reference: [22] <author> D. Terzopoulos, X. Tu, and Grzeszczukm R. </author> <title> Artificial fishes: Autonomous locomotion, perception, behavior, and learning in a simulated physical world. </title> <journal> Artificial Life, </journal> <volume> 1(4) </volume> <pages> 327-351, </pages> <year> 1994. </year>
Reference-contexts: Important contributions in behaviour synthesis arise in robotics and animation. In the ALIVE system [15], body tracking allows users to interact with Silas, a graphical dog based on ethological models and competing behaviours. Terzopolous <ref> [22] </ref> describes an animated environment of synthetic fish based on dynamical models. In robotics, Brooks [5] points out the need for bottom-up robotics behaviour with perceptually grounded systems. Pirjanian [20] discusses objectives and decision making in robotic behaviour. Uchibe [24] trains robots to acquire soccer playing interactions using reinforcement learning.
Reference: [23] <author> E.L. Thorndike. </author> <title> Animal intelligence. an experimental study of the associative process in animals. </title> <journal> Psychological Review, Monograph Supplements, 2(4):109, </journal> <volume> 1898. </volume>
Reference-contexts: The model is fundamentally empirical and is derived from what humans do externally, not from underlying behavioural architectures or hard wired cognitive knowledge and models. Earlier models of human behaviour proposed by cognitive scientists analyzed humans as an input-output or stimulus-response system [26] <ref> [23] </ref>. The models were based on observation and empirical studies. These behaviourists came under criticism as cognitive science evolved beyond their over-simplified model and struggled with higher order issues (i.e. language, creativity, and attention) [14]. Nevertheless, much of the lower-order reactionary behaviour was still well modeled by the stimulus-response paradigm.
Reference: [24] <author> E. Uchibe, M. Asada, and K. Hosoda. </author> <title> State space construction for behaviour acquisition in multi agent environments with vision and action. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <year> 1998. </year>
Reference-contexts: Terzopolous [22] describes an animated environment of synthetic fish based on dynamical models. In robotics, Brooks [5] points out the need for bottom-up robotics behaviour with perceptually grounded systems. Pirjanian [20] discusses objectives and decision making in robotic behaviour. Uchibe <ref> [24] </ref> trains robots to acquire soccer playing interactions using reinforcement learning. Mataric [16] presents interacting multi-agent robots inspired from biology, cognitive models and neuroscience. Large [13] describes multiple competing dynamic models for synthesizing complex behaviour synthesis. We consider the integration of both behaviour acquisition and interactive synthesis. <p> The system then operates in an unsupervised manner as it slides these windows across the data stream. Essentially, the learning uncovers a mapping between 5 past and future to later generate its best possible prediction. Interaction can be learned from a variety of approaches including reinforcement learning <ref> [24] </ref>. The objective here is is primarily an imitation-type learning of interaction. 3 Perceptual System A primary concern in the visual perceptual system is the recovery of action parameters which are particularly expressive and interactive.
Reference: [25] <author> E.A. Wan. </author> <title> Time series prediction by using a connectionist network with internal delay lines. In A.S. Weigend and N.A. Gershenfeld, editors, Time Series Prediction, </title> <year> 1993. </year>
Reference-contexts: We consider the connectionist representation due to its explicit non-linear optimization of prediction accuracy and its promising performance against hidden Markov models, dynamic models, etc in the competition. One of its proponents, Wan <ref> [25] </ref>, describes a nonlinear time series auto regression which computes an output vector y (t) from T previous input instances of the vector y (t 1); y (t 2); :::; y (t T ).
Reference: [26] <author> J.B. Watson. </author> <title> Psychology as the behaviorist views it. </title> <journal> Psychological Review, </journal> <volume> 20 </volume> <pages> 158-17, </pages> <year> 1913. </year>
Reference-contexts: The model is fundamentally empirical and is derived from what humans do externally, not from underlying behavioural architectures or hard wired cognitive knowledge and models. Earlier models of human behaviour proposed by cognitive scientists analyzed humans as an input-output or stimulus-response system <ref> [26] </ref> [23]. The models were based on observation and empirical studies. These behaviourists came under criticism as cognitive science evolved beyond their over-simplified model and struggled with higher order issues (i.e. language, creativity, and attention) [14].
Reference: [27] <author> A. Wilson and A. Bobick. </author> <title> Recognition and interpretation of parametric gesture. </title> <booktitle> In International Conference on Computer Vision, </booktitle> <year> 1998. </year> <month> 20 </month>
Reference-contexts: Isaard describes how multiple hypothesis dynamical models can learn complex hand dynamics and exhibit better tracking [9]. Bobick and Wilson discuss learning hand dynamics using hidden Markov models in a state space <ref> [27] </ref> to learn complex gestures. Models which combine dynamics with learned Markov models are discussed by Pentland [19], and Bregler [4] for predicting and classifying human behaviour. Johnson [17] utilizes neural learning techniques to predict walking behaviours and discusses interactive behaviour synthesis as well.
References-found: 27

