URL: ftp://ftp.research.microsoft.com/users/lomet/pub/trans-time.ps
Refering-URL: http://www.research.microsoft.com/users/lomet/pub/default.htm
Root-URL: http://www.research.microsoft.com
Title: Transaction-Time Databases  
Author: David Lomet Betty Salzberg 
Address: One Kendall Square, Bldg.700 Cambridge, MA 02139  Boston, MA. 1  
Affiliation: DEC Cambridge Research Lab  College of Computer Science Northeastern University  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> R. Baeza-Yates and P. Larson. </author> <title> Performance of B + -trees with Partial Expansions. </title> <journal> IEEE Trans. on Knowledge and Data Engineering 1,2 (June 1989) pp. </journal> <pages> 258-257. </pages>
Reference-contexts: That is not the case, even though our simulation employed uniformly distributed keys. When analyzing index-based access methods, the purpose of a uniform distribution is to realize the uniform growth assumption. This is a standard procedure. We used a form of fringe analysis <ref> [1, 4] </ref>. It involved computing a closure on node probabilities and produced asymptotic performance results directly. The analysis was confirmed by a detailed simulation entailing multiple trials, each trial involving the addition of 50,000 records.
Reference: [2] <author> P. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems, </title> <publisher> Addison-Wesley Publishing Co., </publisher> <address> Reading MA (1987). </address>
Reference-contexts: technology we have described can be used to advance that state, and what is required to adapt this technology to the problem of supporting valid time. 1.2 Timestamping in Transaction-Time Databases 1.2.1 The Timestamping of Data Traditional Timestamping Timestamps have a long history as a way of performing concurrency control <ref> [2] </ref>. Times-tamping methods impose the serialization at the point when the timestamp is chosen. If this is when the transaction starts [18], competing requests for the same data that are out of order result in one or the other of the competing transactions being aborted. <p> These large sequential writes are very important for both the execution path length and the elapsed time of the backup. Normal database activity is concurrent with the backup process, so that what is described constitutes a fuzzy backup for media failure <ref> [2] </ref>. That is, the historical nodes that result do not represent a transaction consistent view of the database in that some updates from some transactions may only be partially installed in history nodes. Originally, TSB-tree nodes were only split when they became full.
Reference: [3] <author> M. Easton. </author> <title> Key-sequence Data Sets on Indelible Storage. </title> <institution> IBM J. of R.D. </institution> <month> 30,3 (May </month> <year> 1986) </year> <month> 230-241. </month>
Reference-contexts: Choosing a Split Time The choice of a split time determines ISTART. In the absence of records of prepared (in-doubt) transactions, whose commit status and transaction time are unknown, current time can serve as the split time. This choice, which is like the choice in WOB-trees <ref> [3] </ref>, is possible even when there are versions from active transactions in the node. These transactions will commit (if they commit) after the current time, and hence their versions are never encountered in a search where the specified time is before or at the split time.
Reference: [4] <author> K. Eswaren, J. Gray, R. Lorie and I. Traiger. </author> <title> On the Notions of Consistency and Predicate Locks in a Database System. </title> <journal> Communications of the ACM 19,11 (Nov 1976) 624-633. </journal>
Reference-contexts: That is not the case, even though our simulation employed uniformly distributed keys. When analyzing index-based access methods, the purpose of a uniform distribution is to realize the uniform growth assumption. This is a standard procedure. We used a form of fringe analysis <ref> [1, 4] </ref>. It involved computing a closure on node probabilities and produced asymptotic performance results directly. The analysis was confirmed by a detailed simulation entailing multiple trials, each trial involving the addition of 50,000 records.
Reference: [5] <author> A. Guttman. R-trees: </author> <title> a Dynamic Index Structure for Spatial Searching. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Boston, MA (May 1984) 47-57. </address>
Reference-contexts: Neither are these versions retained any longer than needed by these specific transactions. Thus, there is no general ability to either index historical versions or to query them with timeslice queries. The most ambitious implementation effort to support transaction-time databases is the POSTGRES system [24]. POSTGRES uses the R-tree <ref> [5] </ref>, a general purpose multi-attribute index tree organization to index historical data by its key and transaction-time lifespan. The R-tree is only used to reference the historical data, not the current data. A separate (background) vacuuming" process migrates historical versions from the current database to the history database.
Reference: [6] <author> M. Herlihy. </author> <title> Optimistic Concurrency Control for Abstract Data Types. </title> <booktitle> Proc. Symp. on Principles of Distributed Computing, </booktitle> <year> (1986) </year> <month> 206-217. </month>
Reference-contexts: Further, all cohorts must be notified at commit time as to what a transaction's timestamp is. A method by which cohorts vote for a commit time has been suggested in <ref> [6, 9, 25] </ref>, and is explained next. It uses the two phase commit protocol for this. Two Phase Commit Two phase commit (2PC) is the protocol used by cohorts of a distributed transaction to reach agreement on whether to commit or abort the transaction. <p> The cohort then ACKs the disposition message. Voting for Transaction Time We extend the two phase commit protocol to enable cohorts to agree on and propagate the transaction time. This is done without extra message overhead, as suggested in <ref> [6, 25] </ref>. We augment the information conveyed on two of the 2PC messages. Each cohort informs the transaction coordinator of its requirements for transaction time on message two (the VOTE message). The coordinator then attempts to find a single time that satisfies all cohort requirements.
Reference: [7] <author> P. Lehman and S. Yao. </author> <title> Efficient Locking for Concurrent Operations on B-trees. </title> <journal> ACM Trans. </journal> <note> on Database Systems l6,4 (Dec 1981) 650-670. </note>
Reference-contexts: We use a technique that is a generalization of the B link -tree technique <ref> [7, 20, 21] </ref> which exploits what we call the P-tree [15]. This involves lazily posting index terms to index nodes sometime after a lower level node split. Search capability is preserved by leaving a forwarding address for the new, split-generated node in the original node.
Reference: [8] <author> D. Lomet. </author> <title> Process Structuring, Synchronization, and Recovery Using Atomic Actions. </title> <booktitle> Proc. ACM Conf. on Language Design for Reliable Software, SIGPLAN Notices 12,3 (Mar 1977) 128-137. </booktitle>
Reference-contexts: For key-splits, the lower key range node will contain a pointer to the higher key range sibling, forming a linked list of current nodes from lowest key to highest key. 1.4.3 Multiple Atomic Actions for Tree Growth P-tree structure changes consist of a sequence of atomic actions <ref> [8] </ref>. These actions are serializable and are guaranteed to have the all or nothing property by the recovery method. Searchers can see the intermediate states of the P-tree that exist between these atomic actions. Hence, complete structural changes are not serializable.
Reference: [9] <author> D. Lomet. </author> <title> Consistent Timestamping for Transactions in Distributed Systems. </title> <institution> Digital Equipment Corp. </institution> <type> Tech Report CRL90/3 (Sept. </type> <institution> 1990) Cambridge Research Lab, </institution> <address> Cambridge, MA. </address>
Reference-contexts: Probably the simplest is to make use of a clock and to use the clock time, at the time the transaction is to be committed, as this value. This time, since it is after all previously committed transactions, is surely also after all conflicting ones as well. See <ref> [9] </ref> for a discussion of other ways of determining a value for CON F LICT i (X). <p> Further, all cohorts must be notified at commit time as to what a transaction's timestamp is. A method by which cohorts vote for a commit time has been suggested in <ref> [6, 9, 25] </ref>, and is explained next. It uses the two phase commit protocol for this. Two Phase Commit Two phase commit (2PC) is the protocol used by cohorts of a distributed transaction to reach agreement on whether to commit or abort the transaction. <p> If successful, it propagates, on message three, to all of the cohorts, both the disposition of the transaction and, if the disposition is COMMIT, the transaction time chosen. We outline one of several options suggested in <ref> [9] </ref> to accomplish this. A cohort must determine, when it receives the PREPARE message, a time that is later than the time for any preceding transaction with which it may conflict. <p> This ensures that serialization order and timestamp order agree at each cohort. Since serialization order and timestamp order agree locally at each cohort, the common timestamps will agree with the global serialization order for all transactions, local and distributed. In <ref> [9] </ref>, a cohort may vote a time range [EARLIEST i (X); LAT EST i (X)]. The coordinator can pick any time that is within all time intervals voted by cohorts, if such a time exists. If no such time exists, the transaction is aborted.
Reference: [10] <author> D. Lomet. </author> <title> Grow and Post Trees: Role, Techniques, and Future Potential. in Advances in Spatial Databases", </title> <note> Lecture Notes in Computer Science 525 Springer-Verlag (1991) 183-206. </note>
Reference-contexts: Supporting these forms of temporal database requires a general purpose multi-attribute index, e.g. the hB-tree <ref> [10, 13] </ref>. <p> But it can be used with other secondary indexing that supports valid time by adding valid-time &lt; timestamp start ; timestamp end &gt; to each record. Any point-based multiattribute search structure, such as the hB-tree [13], can act as the secondary index. It is argued in <ref> [10] </ref> that mapping intervals to their endpoints is efficient for spatial search. The short intervals are clustered together if they are close and the longer intervals are clustered with other longer intervals with approximately similar boundaries.
Reference: [11] <author> D. Lomet and B. Salzberg. </author> <title> Access Methods for Multiversion Data. </title> <booktitle> Proc. ACM SIG-MOD Conf., </booktitle> <address> Portland, OR (May 1989) 315-324. 31 32 BIBLIOGRAPHY </address>
Reference-contexts: Historical data hence is data for which there is a version with a later timestamp. We call the collection of historical versions of data the historical database. Historical versions of data are never updated, and hence could be stored on stable write-once, read many (WORM) optical disks <ref> [11, 24] </ref>. An inexpensive WORM medium changes dramatically the functionality/cost trade-off and makes multiversion support interesting for a large number of applications. In this chapter, we discuss how to realize a transaction-time database. <p> with a slow access rate; (ii) the write accesses needed to restore the backups to the current database; and (iii) the read accesses to the media log when rolling the restored 1.6 Discussion 29 database forward. 1.6 Discussion 1.6.1 Current State Although many proposals for transaction-time databases have been made <ref> [11, 18, 23, 24] </ref>, we know of none that have been implemented in commercially available systems. The commercial versioning of which we are aware supports the ability to read a recent version without setting locks, even in the presence of ongoing update activity.
Reference: [12] <author> D. Lomet and B. Salzberg. </author> <title> The Performance of a Multiversion Access Method. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Atlantic City, NJ (May 1990) 353-363. </address>
Reference-contexts: Deciding whether to split by time, or by key, or by both time and key, impacts the performance characteristics of the resulting TSB-tree. The implications of splitting policy are explored in section 1.3.5, and treated in depth in <ref> [12] </ref>. Here we describe only the mechanics of the splitting process. A sequence of splits is illustrated in Figure 1.2. <p> We did this in <ref> [12] </ref> where we both analyzed and simulated the performance of the Time-Split B-tree, providing asymptotic performance results under two assumptions: Uniform Growth Assumption: A new record is equally likely to be between any two existing records. <p> Hence, TSB-tree space is linear in M , i.e. O (M ). This will not be true of any organization which makes an arbitrarily large number of timeslices. Our paper <ref> [12] </ref> describes several split policies, and presents results for these and other quantities with various update fractions. In all the policies that we analyzed, the fraction of redundant records was bounded.
Reference: [13] <author> D. Lomet and B. Salzberg. </author> <title> The hB-tree: a Multiattribute Indexing Method with Good Guaranteed Performance. </title> <journal> ACM Trans. </journal> <note> on Database Systems 15,4 (Dec 1990) 625-658. </note>
Reference-contexts: Supporting these forms of temporal database requires a general purpose multi-attribute index, e.g. the hB-tree <ref> [10, 13] </ref>. <p> But it can be used with other secondary indexing that supports valid time by adding valid-time &lt; timestamp start ; timestamp end &gt; to each record. Any point-based multiattribute search structure, such as the hB-tree <ref> [13] </ref>, can act as the secondary index. It is argued in [10] that mapping intervals to their endpoints is efficient for spatial search. The short intervals are clustered together if they are close and the longer intervals are clustered with other longer intervals with approximately similar boundaries.
Reference: [14] <author> D. Lomet and B. Salzberg. </author> <title> Media Recovery with Time-Split B-trees. </title> <institution> Digital Equipment Corp. Tech Report CRL 91/9 (Nov 1991) Cambridge Research Lab, </institution> <address> Cambridge, MA. </address>
Reference-contexts: This simplifies crash recovery. 3. Writing of the Index Node: The parent index node of the split node is updated to make the new historical node accessible. This updated index node is then subject to backup by writing it as an historical node, as described above. In <ref> [14] </ref>, we explain how these steps are accomplished and why the ordering is important. <p> We can read these regions in large sequential reads, spending some data transfer in order to save access times. Further, accessing the nodes from each backup sweep together results in small disk arm movements. We describe in <ref> [14] </ref> how the historical nodes are accessed to deal with different types of failures. We deal there with how to minimize the number of I/O accesses.
Reference: [15] <author> D. Lomet and B. Salzberg. </author> <title> Access Method Concurrency with Recovery.. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> San Diego, CA (June 1992) 351-360 </address>
Reference-contexts: We use a technique that is a generalization of the B link -tree technique [7, 20, 21] which exploits what we call the P-tree <ref> [15] </ref>. This involves lazily posting index terms to index nodes sometime after a lower level node split. Search capability is preserved by leaving a forwarding address for the new, split-generated node in the original node.
Reference: [16] <author> C. Mohan, D. Haderle, B. Lindsay, H. Pirahesh, and P. Schwarz. </author> <title> ARIES: a Transaction Recovery Method Supporting Fine-granularity Locking and Partial Rollbacks Using Write-ahead Logging. </title> <journal> ACM Trans. </journal> <note> on Database Systems 17,1 (Mar 1992) 94-162. </note>
Reference-contexts: Media failure recovery is essentially redo recovery in which actions on the log that might not be reflected in an available stable version of data (in the backup) are applied to that version to bring it up-to-date <ref> [16] </ref>. The part of the log containing actions that may need to be applied is bounded by the backup safe point, identifying the earliest possibly unapplied action, and the end of the log.
Reference: [17] <author> Mohan, C. and Levine, F. ARIES/IM: </author> <title> an Efficient and High Concurrency Index Management Method Using Write-ahead Logging. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> San Diego, CA (June 1992) 371-380 </address>
Reference-contexts: Non-leaf nodes in our concurrency algorithm do not have database locks (locks managed by the lock manager). Instead, index nodes have simple short-term semaphores we refer to as latches <ref> [17] </ref>. Latches can have S mode (share), X mode (exclusive) or U mode (update). Exclusive mode latches are not compatible with any other latches. Share mode latches are compatible with other share mode latches and with update mode latches.
Reference: [18] <author> D. Reed. </author> <title> Implementing Atomic Actions. </title> <booktitle> Proc. ACM Symp. on Operating System Principles(1979) and in ACM Trans. on Computer Systems 1,1 (Feb. </booktitle> <year> 1983) </year> <month> 3-23. </month>
Reference-contexts: Times-tamping methods impose the serialization at the point when the timestamp is chosen. If this is when the transaction starts <ref> [18] </ref>, competing requests for the same data that are out of order result in one or the other of the competing transactions being aborted. Timestamping concurrency control techniques have been suggested that require data to be stamped with the time of last read. <p> with a slow access rate; (ii) the write accesses needed to restore the backups to the current database; and (iii) the read accesses to the media log when rolling the restored 1.6 Discussion 29 database forward. 1.6 Discussion 1.6.1 Current State Although many proposals for transaction-time databases have been made <ref> [11, 18, 23, 24] </ref>, we know of none that have been implemented in commercially available systems. The commercial versioning of which we are aware supports the ability to read a recent version without setting locks, even in the presence of ongoing update activity.
Reference: [19] <author> T. Rengarajan, P. Spiro, and W. Wright. </author> <title> High Availability Mechanisms of VAX DBMS Software. </title> <note> Digital Technical Journal 8, </note> <month> (Feb. </month> <year> 1989), </year> <pages> 88-98. </pages>
Reference-contexts: This is called mixed multiversion concurrency. It is effective for the reading of recent data, even when locking is used otherwise. Indeed, Rdb/VMS <ref> [19] </ref> provides just such a capability. Nature of the Timestamp Attribute Versions of data are timestamped with the time of the transaction that produced them, and are valid until a subsequent version, with a later timestamp, is entered into the database. <p> The commercial versioning of which we are aware supports the ability to read a recent version without setting locks, even in the presence of ongoing update activity. This functionality is provided, e.g., in the snapshot feature of DEC's Rdb/VMS <ref> [19] </ref>. A snapshot is a transaction-consistent recent version. Snapshot versions are created only as needed for these transactions, and hence there is no complete history of versions. Neither are these versions retained any longer than needed by these specific transactions.
Reference: [20] <author> Y. Sagiv. </author> <title> Concurrent Operations on B* trees with Overtaking. </title> <journal> J Computer and System Sciences 33,2 (1986) 275-296. </journal>
Reference-contexts: We use a technique that is a generalization of the B link -tree technique <ref> [7, 20, 21] </ref> which exploits what we call the P-tree [15]. This involves lazily posting index terms to index nodes sometime after a lower level node split. Search capability is preserved by leaving a forwarding address for the new, split-generated node in the original node.
Reference: [21] <author> B. Salzberg. </author> <title> Restructuring the Lehman-Yao tree. </title> <institution> Tech Report TR BS-85-21 (1985) Northeastern University, </institution> <address> Boston, MA. </address>
Reference-contexts: We use a technique that is a generalization of the B link -tree technique <ref> [7, 20, 21] </ref> which exploits what we call the P-tree [15]. This involves lazily posting index terms to index nodes sometime after a lower level node split. Search capability is preserved by leaving a forwarding address for the new, split-generated node in the original node.
Reference: [22] <author> A. Silberschatz, M. Stonebraker, and J. Ullman (eds). </author> <title> Database Systems: Achievements and Opportunities. </title> <journal> Communications of the ACM 34,10 (Oct. </journal> <year> 1991) </year> <month> 110-120. </month>
Reference-contexts: Without time splitting (which exploits clipping), splitting by both start and end time is needed in order to partition the search space, requiring two stamps on each version (See the discussion below on valid time.). 1.6.2 Providing More Capability The Needs In <ref> [22] </ref>, the capabilities needed for next generation database systems were surveyed. Multi-versioning was one such capability. Another was the management of data on tertiary storage, and the ability to move data between levels of the storage hierarchy so as to be responsive to cost and performance trade-offs.
Reference: [23] <author> R. Snodgrass and I. Ahn. </author> <title> A Taxonomy of Time in Databases. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Austin, TX (May 1985), </address> <pages> 236-246. </pages>
Reference-contexts: 1.1 Introduction Over the last several years, multiversion databases have attracted increasing attention. Temporal databases, one form of multiversion database, have been studied with several notions of time <ref> [23] </ref>. Data is stamped" with the time of interest, and this timestamp can be queried along with the ordinary data. One time of interest is the time at which a transaction executes, called transaction time. <p> with a slow access rate; (ii) the write accesses needed to restore the backups to the current database; and (iii) the read accesses to the media log when rolling the restored 1.6 Discussion 29 database forward. 1.6 Discussion 1.6.1 Current State Although many proposals for transaction-time databases have been made <ref> [11, 18, 23, 24] </ref>, we know of none that have been implemented in commercially available systems. The commercial versioning of which we are aware supports the ability to read a recent version without setting locks, even in the presence of ongoing update activity.
Reference: [24] <author> M. Stonebraker. </author> <title> The Design of the POSTGRES Storage System. </title> <booktitle> Proc. Very Large Databases Conf., </booktitle> <address> Brighton, UK (Sept. </address> <year> 1987), </year> <pages> 289-300. </pages>
Reference-contexts: Historical data hence is data for which there is a version with a later timestamp. We call the collection of historical versions of data the historical database. Historical versions of data are never updated, and hence could be stored on stable write-once, read many (WORM) optical disks <ref> [11, 24] </ref>. An inexpensive WORM medium changes dramatically the functionality/cost trade-off and makes multiversion support interesting for a large number of applications. In this chapter, we discuss how to realize a transaction-time database. <p> with a slow access rate; (ii) the write accesses needed to restore the backups to the current database; and (iii) the read accesses to the media log when rolling the restored 1.6 Discussion 29 database forward. 1.6 Discussion 1.6.1 Current State Although many proposals for transaction-time databases have been made <ref> [11, 18, 23, 24] </ref>, we know of none that have been implemented in commercially available systems. The commercial versioning of which we are aware supports the ability to read a recent version without setting locks, even in the presence of ongoing update activity. <p> Neither are these versions retained any longer than needed by these specific transactions. Thus, there is no general ability to either index historical versions or to query them with timeslice queries. The most ambitious implementation effort to support transaction-time databases is the POSTGRES system <ref> [24] </ref>. POSTGRES uses the R-tree [5], a general purpose multi-attribute index tree organization to index historical data by its key and transaction-time lifespan. The R-tree is only used to reference the historical data, not the current data.
Reference: [25] <author> W. Weihl. </author> <title> Distributed Version Management for Read-Only Actions. </title> <journal> IEEE Trans. on Software Engineering SE-13,1 (Jan. </journal> <year> 1987), </year> <pages> 55-64. </pages>
Reference-contexts: Further, all cohorts must be notified at commit time as to what a transaction's timestamp is. A method by which cohorts vote for a commit time has been suggested in <ref> [6, 9, 25] </ref>, and is explained next. It uses the two phase commit protocol for this. Two Phase Commit Two phase commit (2PC) is the protocol used by cohorts of a distributed transaction to reach agreement on whether to commit or abort the transaction. <p> The cohort then ACKs the disposition message. Voting for Transaction Time We extend the two phase commit protocol to enable cohorts to agree on and propagate the transaction time. This is done without extra message overhead, as suggested in <ref> [6, 25] </ref>. We augment the information conveyed on two of the 2PC messages. Each cohort informs the transaction coordinator of its requirements for transaction time on message two (the VOTE message). The coordinator then attempts to find a single time that satisfies all cohort requirements.
References-found: 25

