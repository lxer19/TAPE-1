URL: ftp://ftp.cs.wisc.edu/computer-vision/sigg96-seitz.ps
Refering-URL: http://www.cs.wisc.edu/computer-vision/pubs.html
Root-URL: 
Title: View Morphing  
Author: Steven M. Seitz Charles R. Dyer 
Keyword: CR Categories and Subject Descriptors: I.3.3 [Computer Graphics]: Picture/Image Generation- viewing algorithms; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism- animation; I.4.3 [Image Processing]: Enhancement- geometric correction, registration. Additional Keywords: Morphing, image metamorphosis, view interpolation, view synthesis, image warping.  
Date: 96.  
Note: To appear in Proc. SIGGRAPH  
Address: Wisconsin|Madison 1  
Affiliation: Department of Computer Sciences University of  
Abstract: Image morphing techniques can generate compelling 2D transitions between images. However, differences in object pose or viewpoint often cause unnatural distortions in image morphs that are difficult to correct manually. Using basic principles of projective geometry, this paper introduces a simple extension to image morphing that correctly handles 3D projective camera and scene transformations. The technique, called view morphing, works by prewarping two images prior to computing a morph and then postwarping the interpolated images. Because no knowledge of 3D shape is required, the technique may be applied to photographs and drawings, as well as rendered scenes. The ability to synthesize changes both in viewpoint and image structure affords a wide variety of interesting 3D effects via simple image transformations. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Beier, T., and Neely, S. </author> <title> Feature-based image metamorphosis. </title> <booktitle> Proc. SIGGRAPH 92. In Computer Graphics (1992), </booktitle> <pages> pp. 35-42. </pages>
Reference-contexts: The prewarping step is performed automatically, while the postwarping procedure may be interactively controlled by means of a small number of user-specified control points. Any of several image morphing techniques, for instance <ref> [15, 1, 8] </ref>, may be used to compute the intermediate image interpolation. View morphing does not require knowledge of 3D shape, thereby allowing virtual manipulations of unknown objects or scenes given only as drawings or photographs. <p> Two maps are required because the correspondence may not be one-to-one. In practice, C 0 and C 1 are partially specified by having the user provide a sparse set of matching features or regions in the two images. The remaining correspondences are determined automatically by interpolation <ref> [15, 1, 8] </ref>. <p> usually based on linear interpolation: W 0 (p 0 ; s) = (1 s)p 0 + sC 0 (p 0 ) (1) W 0 and W 1 give the displacement of each point p 0 2 I 0 and p 1 2 I 1 as a function of s 2 <ref> [0; 1] </ref>. The in-between images I s are computed by warping the two original images and averaging the pixel colors of the warped images. Existing morphing methods vary principally in how the correspondence maps are computed. In addition, some techniques allow finer control over interpolation rates and methods. <p> Existing morphing methods vary principally in how the correspondence maps are computed. In addition, some techniques allow finer control over interpolation rates and methods. For instance, Beier et al. <ref> [1] </ref> suggested two different methods of interpolating line features, using linear interpolation of endpoints, per Eqs. (1) and (2), or of position and angle. In this paper, the term image morphing refers specifically to methods that use linear interpolation to compute feature positions in in-between images, including [15, 1, 8]. <p> In this paper, the term image morphing refers specifically to methods that use linear interpolation to compute feature positions in in-between images, including <ref> [15, 1, 8] </ref>. To illustrate the potentially severe 3D distortions incurred by image morphing, it is useful to consider interpolating be 2 tween two different views of a planar shape. <p> Resampling effects can be reduced by supersampling the input images [15] or by composing the image transformations into one aggregate warp for each image. The latter approach is especially compatible with image morphing techniques that employ inverse mapping, such as the Beier and Neely method <ref> [1] </ref>, since the inverse postwarp, morph, and prewarp can be directly concatenated into a single inverse map. <p> These features were used to automatically prewarp the images to achieve parallelism using the method described in the Appendix. Inspection of the prewarped images confirms that corresponding features do in fact occupy the same scanlines. An implementation of the Beier-Neely field-morphing algorithm <ref> [1] </ref> was used to compute the intermediate images, based on the same set of features used to prewarp the images. <p> The image morph was computed by linearly interpolating corresponding pixels in the two original images. The change in orientation between the original images caused the in-between images to contract. In addition, the bending effects seen in Fig. 2 are also present. Image morphing techniques such as <ref> [1] </ref> that preserve lines can reduce bending effects, but only when line features are present. An interesting side-effect is that a large hole appears in the image morph, between the stick and propeller, but not in the view morph, since the eye-level is constant throughout the transition.

Reference: [3] <author> Chen, S. E., and Williams, L. </author> <title> View interpolation for image synthesis. </title> <booktitle> Proc. SIGGRAPH 93. In Computer Graphics (1993), </booktitle> <pages> pp. 279-288. </pages>
Reference-contexts: View morphing does not require knowledge of 3D shape, thereby allowing virtual manipulations of unknown objects or scenes given only as drawings or photographs. In terms of its ability to achieve changes in viewpoint, view morphing is related to previous view-based techniques such as view synthesis <ref> [3, 7, 11, 12] </ref> and mosaics [10, 2, 14, 6]. However, this paper focuses on creating natural transitions between images rather than on synthesizing arbitrary views of an object or scene. This distinction has a number of important consequences. <p> Alternatively, we could produce the same two images by moving the camera instead of the object. Chen and Williams <ref> [3] </ref> previously considered this special case, arguing that linear image interpolation should produce new perspective views when the camera moves parallel to the image plane. <p> The opposite case, of an occluded surface suddenly becoming visible, gives rise to a hole; a region of I s having no correspondence in I 0 . Folds can be resolved using Z-buffer techniques <ref> [3] </ref>, provided depth information is available. In the absence of 3D shape information, we use point disparity instead. The disparity of corresponding points p 0 and p 1 in two parallel views is defined to be the difference of their x-coordinates. <p> An alternative method using a Painter's method instead of Z-buffering is presented in [10]. Unlike folds, holes cannot always be eliminated using image information alone. Chen and Williams <ref> [3] </ref> suggested different methods for filling holes, using a designated background color, interpolation with neighboring pixels, or additional images for better surface coverage.
Reference: [4] <author> Faugeras, O. </author> <title> Three-Dimensional Computer Vision, </title>
Reference-contexts: However, there exist a variety of techniques for obtaining the projection matrices from the images themselves and knowledge of either the internal camera parameters or the 3D positions of a small number of image points. For an overview of both types of techniques, consult <ref> [4] </ref>. In Section 4 we introduce a variant that does not require knowledge of the projection matrices and also allows interpolations between views of different 3D objects or scenes. The pixel correspondences are derived by a combination of user-interaction and automatic interpolation provided by existing morphing techniques. <p> Reprojection can also be performed through texture-mapping and can therefore exploit current graphics hardware. Image reprojection has been used previously in a number of applications [15]. Our use of reprojection is most closely related to the techniques used for rectifying stereo views to simplify 3D shape reconstruction <ref> [4] </ref>. Image mosaic techniques [10, 2, 14, 6] also rely heavily on reprojection methods to project images onto a planar, cylindrical, or spherical manifold. <p> The final positions of the control points for the image in the center of Fig. 6 were computed automatically by roughly calibrating the two images based on their known focal lengths and interpolating the changes in orientation <ref> [4] </ref>. Different images obtained by other settings of the control points are shown in Fig. 8. As these images indicate, a broad range of 3D projective effects may be achieved through the postwarping procedure.
References-found: 3

