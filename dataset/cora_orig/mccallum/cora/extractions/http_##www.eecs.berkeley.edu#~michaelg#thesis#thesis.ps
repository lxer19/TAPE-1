URL: http://www.eecs.berkeley.edu/~michaelg/thesis/thesis.ps
Refering-URL: http://www.eecs.berkeley.edu/~michaelg/thesis.html
Root-URL: http://www.cs.berkeley.edu
Title: Adaptive Signal Models: Theory, Algorithms, and Audio Applications  
Author: by Michael Mark Goodwin 
Degree: 1992 A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in Engineering|Electrical Engineering and Computer Science in the GRADUATE DIVISION of the UNIVERSITY of CALIFORNIA, BERKELEY Committee in charge: Professor Edward A. Lee, Chair Professor Martin Vetterli Professor David Wessel  
Date: Fall 1997  
Address: 1992  
Affiliation: S.B. (Massachusetts Institute of Technology)  S.M. (Massachusetts Institute of Technology)  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> L. R. Rabiner and R. W. Schafer, </author> <title> Digital Processing of Speech Signals. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall, </publisher> <year> 1978. </year>
Reference-contexts: The two formulations of the STFT have different interpretations with regards to signal modeling; this difference can be seen by relating the two STFT definitions <ref> [1, 112] </ref>: ~ X [k; n] = m=n = m=0 ~w [m]x [n + m]e j! k (m+n) (change of index) = e j! k n m=0 = e j! k n m=0 ~ X [k; n] = e j! k n X [k; n]: This formulation leads to two simple <p> This will become more apparent in Sections 2.3 and 2.4. 38 - Time F requency . . . . . . 6 Time-localized Fourier transform Filter bank localized spectra (vertical) and as a bank of bandpass filters (horizontal). Interpretations of the STFT In <ref> [111, 1] </ref> and other traditional treatments of the STFT, two interpretations are considered. First, the STFT can be viewed as a series of time-localized spectra; notationally, this corresponds to interpreting X [k; n] as a function of frequency k for a fixed n. <p> This constraint is similar to but somewhat more general than the perfect reconstruction constraints given in <ref> [1, 111, 116, 115, 112] </ref>. Note that throughout this section the analysis and synthesis windows will both be assumed to be real-valued. In cases where v [n] is not explicitly specified, the synthesis window is equivalently a rectangular window covering the same time span as w [n]. <p> The idea is straightforward: the signal can be reconstructed by modulating each of these envelopes to the appropriate frequency and summing the resulting signals. This construction is given by ^x [n] = k which can be manipulated to yield perfect reconstruction conditions <ref> [1, 111] </ref>; this non-subsampled case is not very general, however, so these constraints will not be derived here. Rather, Equation (2.21) is given to indicate the similarity of the STFT signal model and the sinusoidal model. <p> The use of oversampling, however, is contrary to the goal of data reduction. This problem is solved in the sinusoidal model by applying a parametric representation to the STFT to achieve compaction. Modifications of the STFT Various signal modifications based on the STFT have been discussed in the literature <ref> [1, 111, 114, 115, 112, 117, 128, 129] </ref>. In approaches where the modifications are based directly on the function X (k; i), the techniques are inherently restricted to a rigid framework because the signal is being modeled in terms of subbands which interact in complicated ways in the reconstruction process. <p> [n L] cos (! 0 ! 1 ) n 4 : (2.110) Examples of this amplitude distortion are given in Figure 2.19 (a) for j! 0 ! 1 j = =N with 2 [0; 5] and N = 512; the corresponding overlap-add phase function fi [n] is given for 2 <ref> [0; 1; 5] </ref> in Figures 2.19 (b,c,d). <p> This issue has been explored most extensively in the speech and audio processing communities <ref> [1, 53, 196, 197, 198] </ref>; the terminology is thus taken from these fields, but the methods apply to any pseudo-periodic signals. <p> Various fixes have been proposed to account for these problems; for instance, based on the a priori knowledge that a typical musical signal does not have impulsive pitch discontinuities, a median filter can be applied to the pitch estimates to remove outliers and provide a more robust estimate <ref> [1, 53, 197] </ref>. For a more detailed discussion of pitch detection algorithms, the reader is referred to [1, 53, 196]. <p> For a more detailed discussion of pitch detection algorithms, the reader is referred to <ref> [1, 53, 196] </ref>. For the purposes of this chapter, it is assumed that a reliable pitch detection algorithm is available, and that the algorithm is capable of acknowledging, perhaps according to some heuristic threshold, when no pitch can be reasonably assessed to the signal. <p> The overall model mixture then consisted of slowly-varying sinusoids and 157 broadband noise. A representation similar to the deterministic-plus-stochastic decomposition of Chapter 2 has been widely applied in linear predictive coding (LPC) of speech, where the speech is coded using a time-varying source-filter model <ref> [1, 23] </ref>. The filter is adapted in time to match the speech spectrum, while the source is chosen based on a classification of the local speech signal as voiced or unvoiced. <p> No resampling is necessary. Since this is computationally advantageous, 159 the target period P for a local pitch region is chosen as the mode of the original periods fQ i ; i 2 <ref> [1; R] </ref>g so that this case occurs frequently. * P &lt; Q i . The resampled output is to be shorter than the input, so the modified spectrum should have fewer bins than the original. <p> ) (6.64) 1 X x [n + t ] a n e j!n a L e j!L n=0 For w = 2k=K, the last two terms can be computed using the DFT: + (a; 2k=K; t ) = a e j! + (a; !; t ) (6.65) where n 2 <ref> [0; 1] </ref> in the latter terms, which could be combined into a single DFT. If truncation effects are ignored, the second DFT term is neglected and the relationship is again more straightforward. <p> The connec tion is discussed in Section 5.3, where it is shown that some of the difficulties in sinusoidal modeling can be overcome by applying the Fourier series in a pitch-synchronous manner. 241 Publications <ref> [1] </ref> M. Goodwin and M. Vetterli. Matching pursuit and signal models based on recursive filter banks. To be submitted to IEEE Transactions on Signal Processing. [2] M. Goodwin and M. Vetterli. Atomic signal models based on recursive filter banks.
Reference: [2] <author> M. Vetterli and J. Kovacevic, </author> <title> Wavelets and Subband Coding. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall, </publisher> <year> 1995. </year>
Reference-contexts: Perfect reconstruction constraints for such STFT filter banks are derived. In the literature, z-transform and matrix representations have been shown to be useful in analyzing the properties of such filter banks <ref> [2, 20, 120] </ref>. Here, for the sake of brevity, these methods are not explored; the STFT filter banks are treated using time-domain considerations. <p> In the early literature on time-frequency transforms, signal analysis-synthesis based on Gaussian windows was proposed by Gabor [71, 72]; given this historical foundation, the STFT is sometimes referred to as a Gabor transform <ref> [2] </ref>. The transform in Equation (2.3) can be expressed in a subsampled form which will be useful later: X (k; i) = m=0 where L is the analysis stride, the time distance between successive applications of the window to the data. <p> The STFT as a modulated filter bank Modulated filter banks, in which the filters are modulated versions of a prototype lowpass filter, have been of considerable interest in the recent literature <ref> [20, 2, 4] </ref>. In part, this interest has stemmed from the realization that the STFT can be implemented with a modulated filter bank structure. Indeed, the STFT of Equation (2.3) corresponds exactly to a modulated filter bank of the general form shown in Figure 2.3. <p> Then, the subband signals are real-valued, which is certainly desirable in some cases; here, however, it is problematic since the phase provided by the 47 complex filter bank is important for sinusoidal modeling as will be seen. While cosine-modulated filter banks have interesting and significant properties <ref> [2, 20, 4, 12, 59] </ref>, they are an offshoot of the progression of ideas that leads to the sinusoidal model and will not be considered in depth here because of this phase problem. <p> The critically sampled case L = K is of special interest since the representation and the original signal intrinsically contain the same amount of data. For critical sampling, however, it can be shown that the only FIR solutions correspond to windows with N = K nonzero coefficients <ref> [2, 120] </ref>. In the straightforward solution of this form, the N nonzero coefficients are all in the interval [0; N 1]. <p> On the other hand, the reason that there are no solutions for N &gt; K is less intuitive; this result is proved in <ref> [2, 120] </ref>. In the critically sampled case, then, the STFT in effect implements a block transform with block size N ; quantization then leads to discontinuities at the block boundaries, which results in undesirable frame rate artifacts in audio and blockiness in images. <p> The ability to use time-domain aliasing cancellation in a cosine-modulated filter bank is connected to the result that the expansion functions in a cosine-modulated filter bank can have good time and frequency localization <ref> [2] </ref>. Note that the lapped orthogonal transforms (LOT) mentioned in Section 1.4 belong to this class of filters. <p> Time-frequency localization As discussed above, the design of STFT filter banks is extremely limited in the critically sampled case. The only real-valued prototype windows that lead to orthogonal perfect reconstruction filter banks are rectangular windows <ref> [2] </ref>. <p> This problem motivates the use of cosine-modulated filter banks, which can achieve good time-frequency localization <ref> [2] </ref>. Further issues regarding time-frequency localization and filter banks are beyond the scope of this thesis; this issue will thus not be addressed further, with the exception of various considerations of signal expansions, which have a fundamental relationship to filter banks. <p> For the specific interval <ref> [0; 2] </ref>, the equation for signal synthesis is x [n] = 2 0 where the interval simply provides the limits for the integral. The DTFT is a continuous frequency-domain function that represents a discrete-time function; for finite-length signals, there is redundancy in the DTFT representation. <p> Here, the issue is developed further; this development is based on the discrete wavelet transform, which is inherently connected to the notion of multiresolution <ref> [2, 79] </ref>. 3.2.1 Wavelets and Filter Banks Wavelets and multiresolution are intrinsically related. <p> In many applications of such structures, h 0 [n] and h 1 [n] are respectively a lowpass and a highpass filter; likewise for g 0 [n] and g 1 [n]. (CWT); for a treatment of the CWT, the reader is referred to <ref> [2] </ref>. This treatment is not intended as an exhaustive review of wavelet theory but rather as a discussion of wavelets with a view to understanding multiresolution and related signal modeling issues. The treatment is restricted primarily to conceptual matters here; various mathematical details are provided in Appendix A. <p> It has thus been shown that filter banks compute signal expansions. Indeed, any critically sampled perfect reconstruction filter bank implements a signal expansion in a biorthogonal basis, and any filter bank that implements a biorthogonal expansion provides perfect reconstruction; biorthogonality and perfect reconstruction are equivalent conditions <ref> [2] </ref>. At this point, however, the notion of multiresolution has not yet entered the considerations; the atoms in the decomposition of Equation (3.12) do not have multireso-lution properties. In the next section, it is shown that multiresolution can be introduced by iterating two-channel filter banks. <p> Frequency-domain interpretations of aliasing cancellation and signal reconstruction based on this lowpass-highpass structure are given in <ref> [2, 20] </ref>. Arbitrary tree-structured filter banks that achieve perfect reconstruction can be constructed by iterating two-channel perfect reconstruction filter banks; indeed, the filter trees can be made to adapt to model nonstationary input signals while still satisfying the reconstruction constraint [60]. <p> As noted in Figure 3.4, the discrete wavelet transform corresponds to successive iterations on the lowpass branch. The discrete wavelet transform The discrete wavelet transform is perhaps the most common example of a tree-structured filter bank. It has been widely explored in the literature <ref> [2, 20] </ref>. Here, the discussion is limited to general signal modeling issues. The discrete wavelet transform is constructed by successive iterations on the lowpass branch. Given that H 0 (z) and H 1 (z) are respectively a lowpass and a highpass filter, the filtering operations can be readily interpreted. <p> Furthermore, it is important to keep in mind that the synthesis filter bank is required for aliasing cancellation. Atoms and filters Earlier, the atomic model of the subband signals in a two-channel filter bank was derived. A similar model can be arrived at for the discrete wavelet transform <ref> [2] </ref>. The transform can thus be interpreted as a filter bank or as an atomic decomposition; there is a similar duality here as in the interpretations of the STFT discussed in Section 2.2.1, and the interpretations are connected by way of the tiling diagram. <p> For the pyramid in Figure 3.7, the representation is oversampled by a factor of 1 + 1 2 + 1 4 ; for continued iterations, the oversampling factor asymptotically approaches two. Along with simplifying perfect reconstruction, this oversampling results in added robustness to quantization noise <ref> [2] </ref>. Note also that the synthesis filters are included in the analysis; the result is an analysis-by-synthesis process that can be made to resolve some of the difficulties in wavelet filter banks. <p> The pyramid structure can be generalized by applying arbitrary signal models on the levels of the pyramid rather than filtering and downsampling; for instance, in image coding it is common to apply nonlinear interpolation and decimation operators in such pyramid filters <ref> [2] </ref>. 3.3 Filter Bank Methods Filter bank methods for multiresolution sinusoidal modeling involve modeling the subband signals; a basic block diagram for this subband approach is given in Figure 3.8. <p> Due to the various advantages of subband processing, such filter bank approaches have been widely dealt with in the literature, but primarily for the case of uniform or octave-band filter banks <ref> [2, 20] </ref>. Some results on nonuniform critically sampled and oversampled perfect reconstruction filter banks have also been presented [188, 189, 190, 191, 192]. The design of a nonuniform filter bank for the noise perception model proposed in Section 4.2 differs from the perfect reconstruction problem discussed above. <p> i)j 2 = n=0 2 As will be seen, a similar summation does not generally apply in the filter bank case; the sum of the subband energies in a filter bank is not proportional to the energy of the original signal unless the filter bank corresponds to a tight frame <ref> [2] </ref>. In considering the filter bank approach, various restrictions must be imposed to allow for a meaningful comparison with the FFT method. <p> Parseval's theorem holds for any orthogonal basis, and a similar expression can be derived for the case of tight frames <ref> [2] </ref>. In this section, issues related to frequency domain signal energies are considered. It should be noted that the issues to be discussed are not intrinsically coupled to the application of residual modeling, but indeed apply to arbitrary signals. <p> By upsampling the wavelet filters, the spectral decomposition derived by the filter bank can be adjusted. The frequency-domain effect of upsampling is a compression of the spectrum by the upsampling factor, which admits spectral images into the range <ref> [0; 2] </ref>. The subband of a branch in the upsampled filter bank then includes both the original band and these images. This spectral decomposition is depicted in Figure 5.5 for the case of a depth-three wavelet filter bank and upsampling by factors of three and nine. <p> Perfect reconstruction can be achieved by incorporating all of the subband signals of each wavelet transform. Interpretation as a polyphase structure Polyphase methods have been of some interest in the literature, primarily as a tool for analyzing filter banks <ref> [2] </ref>. Here, it is noted that the multiplexed wavelet transform described above can be interpreted as a polyphase transform; a block diagram is given in Figure 5.8. <p> Similar ideas have been employed in compression algorithms based on more standard filter bank structures such as the discrete wavelet transform and uniform filter banks <ref> [2, 20] </ref>. 182 5.5 Applications Of course, pitch-synchronous methods such as the ones discussed in this chapter have immediate applications in audio processing. These have been considered throughout the chapter; a few further issues are treated in Section 5.5.1. <p> (z) H 0 (z) # " 0 2 : (A.8) This condition can be expressed in a shorthand form as G T in terms of the modulation matrices G m (z) and H m (z) and the identity matrix I; such modulation matrices are useful in multirate filter bank theory <ref> [2] </ref>. The design of a perfect reconstruction filter bank then amounts to the derivation of four polynomials G 0 (z); G 1 (z); H 0 (z), and H 1 (z) that satisfy the condition above; this issue is considered in detail in [2]. <p> matrices are useful in multirate filter bank theory <ref> [2] </ref>. The design of a perfect reconstruction filter bank then amounts to the derivation of four polynomials G 0 (z); G 1 (z); H 0 (z), and H 1 (z) that satisfy the condition above; this issue is considered in detail in [2]. Equations (A.6) and (A.7) can be manipulated to yield a general expression relating the constituent filters; this will be especially useful for interpreting the analysis-synthesis filter bank in terms of a time-domain signal expansion. The first step in the derivation, which basically mirrors the treatment given in [2], is to <p> detail in <ref> [2] </ref>. Equations (A.6) and (A.7) can be manipulated to yield a general expression relating the constituent filters; this will be especially useful for interpreting the analysis-synthesis filter bank in terms of a time-domain signal expansion. The first step in the derivation, which basically mirrors the treatment given in [2], is to rewrite Equation (A.7) as G 1 (z)H 1 (z) : (A.10) Substituting this expression into Equation (A.6) and solving for G 1 (z) yields G 1 (z) = H 0 (z)H 1 (z) H 0 (z)H 1 (z) 2H 0 (z) : (A.11) Similarly, G 0 (z) = <p> G 1 (z)H 0 (z) = 0; (A.19) where the last expression must hold at least where H 1 (z) is nonzero; indeed, no generality is actually lost here since the two-channel filter bank cannot achieve perfect reconstruction if H 0 (z) and H 1 (z) have any common zeros <ref> [2] </ref>. <p> Goodwin and M. Vetterli. Matching pursuit and signal models based on recursive filter banks. To be submitted to IEEE Transactions on Signal Processing. <ref> [2] </ref> M. Goodwin and M. Vetterli. Atomic signal models based on recursive filter banks. In Conference Record of the Thirty-First Asilomar Conference on Signals, Systems, and Computers, November 1997. [3] M. Goodwin and M. Vetterli. Atomic decompositions of audio signals.
Reference: [3] <author> K. R. Rao and P. Yip, </author> <title> Discrete Cosine Transform: Algorithms, Advantages, Applications. </title> <address> Boston, MA: </address> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: Vetterli. Matching pursuit and signal models based on recursive filter banks. To be submitted to IEEE Transactions on Signal Processing. [2] M. Goodwin and M. Vetterli. Atomic signal models based on recursive filter banks. In Conference Record of the Thirty-First Asilomar Conference on Signals, Systems, and Computers, November 1997. <ref> [3] </ref> M. Goodwin and M. Vetterli. Atomic decompositions of audio signals. In Proceedings of the IEEE Workshop on Applications of Signal Processing to Audio and Acoustics, October 1997. [4] M. Goodwin. Matching pursuit with damped sinusoids.
Reference: [4] <author> H. S. Malvar, </author> <title> Signal Processing With Lapped Transforms. </title> <address> Boston, MA: Artech House, </address> <year> 1992. </year>
Reference-contexts: The STFT as a modulated filter bank Modulated filter banks, in which the filters are modulated versions of a prototype lowpass filter, have been of considerable interest in the recent literature <ref> [20, 2, 4] </ref>. In part, this interest has stemmed from the realization that the STFT can be implemented with a modulated filter bank structure. Indeed, the STFT of Equation (2.3) corresponds exactly to a modulated filter bank of the general form shown in Figure 2.3. <p> Then, the subband signals are real-valued, which is certainly desirable in some cases; here, however, it is problematic since the phase provided by the 47 complex filter bank is important for sinusoidal modeling as will be seen. While cosine-modulated filter banks have interesting and significant properties <ref> [2, 20, 4, 12, 59] </ref>, they are an offshoot of the progression of ideas that leads to the sinusoidal model and will not be considered in depth here because of this phase problem. <p> In Conference Record of the Thirty-First Asilomar Conference on Signals, Systems, and Computers, November 1997. [3] M. Goodwin and M. Vetterli. Atomic decompositions of audio signals. In Proceedings of the IEEE Workshop on Applications of Signal Processing to Audio and Acoustics, October 1997. <ref> [4] </ref> M. Goodwin. Matching pursuit with damped sinusoids. In IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings, 3:2037 2040, May 1997. [5] P. Prandoni, M. Goodwin, and M. Vetterli. Optimal segmentation for signal modeling and compression.
Reference: [5] <author> N. Jayant, J. Johnston, and B. Safranek, </author> <title> "Signal compression based on models of human perception," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 81, </volume> <pages> pp. 1385-1422, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: ! 1 : A [n] = t [n] 2 + t [n L] 2 + 2t [n]t [n L] cos (! 0 ! 1 ) n 4 : (2.110) Examples of this amplitude distortion are given in Figure 2.19 (a) for j! 0 ! 1 j = =N with 2 <ref> [0; 5] </ref> and N = 512; the corresponding overlap-add phase function fi [n] is given for 2 [0; 1; 5] in Figures 2.19 (b,c,d). <p> [n L] cos (! 0 ! 1 ) n 4 : (2.110) Examples of this amplitude distortion are given in Figure 2.19 (a) for j! 0 ! 1 j = =N with 2 [0; 5] and N = 512; the corresponding overlap-add phase function fi [n] is given for 2 <ref> [0; 1; 5] </ref> in Figures 2.19 (b,c,d). <p> If the frequencies in adjacent frames are equal, there is no amplitude distortion and linear interpolation is achieved. In (a), the amplitude distortion is plotted for inter-frame frequency differences for =N , where 2 <ref> [0; 5] </ref> and N = 512. The distortion increases as the frequency difference increases. <p> Vetterli. Atomic decompositions of audio signals. In Proceedings of the IEEE Workshop on Applications of Signal Processing to Audio and Acoustics, October 1997. [4] M. Goodwin. Matching pursuit with damped sinusoids. In IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings, 3:2037 2040, May 1997. <ref> [5] </ref> P. Prandoni, M. Goodwin, and M. Vetterli. Optimal segmentation for signal modeling and compression. In IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings, 3:2029-2032, May 1997. [6] M. Goodwin. Nonuniform filter bank design for audio signal modeling.
Reference: [6] <editor> A. Gersho, </editor> <booktitle> "Advances in speech and audio compression," Proceedings of the IEEE, </booktitle> <volume> vol. 82, </volume> <pages> pp. 900-918, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: In IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings, 3:2037 2040, May 1997. [5] P. Prandoni, M. Goodwin, and M. Vetterli. Optimal segmentation for signal modeling and compression. In IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings, 3:2029-2032, May 1997. <ref> [6] </ref> M. Goodwin. Nonuniform filter bank design for audio signal modeling. In Conference Record of the Thirtieth Asilomar Conference on Signals, Systems, and Computers, 2:1229-1233, November 1996. [7] M. Goodwin and M. Vetterli. Time-frequency signal models for music analysis, transformation, and synthesis.
Reference: [7] <author> K. Brandenburg and G. Stoll, </author> <title> "ISO-MPEG-1 audio: A generic standard for coding of high-quality digital audio," </title> <journal> Journal of the Audio Engineering Society, </journal> <volume> vol. 42, </volume> <pages> pp. 780-791, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Furthermore, pre-echo distortion occurs in the reconstruction where the original signal has transient behavior; pre-echo is a common problem in near-perfect reconstruction signal models such as filter banks with subband quantization <ref> [7] </ref>. The requirement that N = K = L in the critically sampled case means that there are no critically sampled perfect reconstruction STFT filter banks that employ time-domain aliasing cancellation. <p> However, time-domain aliasing cancellation can be incorporated in critically sampled cosine-modulated filter banks; such filter banks are commonly used in audio coding <ref> [12, 7, 9, 16, 17] </ref>. The ability to use time-domain aliasing cancellation in a cosine-modulated filter bank is connected to the result that the expansion functions in a cosine-modulated filter bank can have good time and frequency localization [2]. <p> This approach is best described pictorially; Figure 3.16 shows a signal segmentation and the corresponding motif and interpolation windows. Note that the asymmetric transition windows are conceptually similar to the start and stop windows used in modern audio coding standards <ref> [7, 8] </ref>; in those methods, however, such asymmetric windows are used in conjunction with a filter bank analysis-synthesis and not with a parametric approach as in this consideration. 3.5 Conclusion In modeling nonstationary signals, it is generally useful to carry out analysis-synthesis in a multiresolution framework; appropriate time-frequency resolution tradeoffs can <p> Such filter bank models, which were first introduced in conjunction with the classical theory of resonance [182], are well justified by experimental work ranging from early masking tests for telephony applications [183, 184] to recent investigations in perceptual audio coding, where auditory models are incorporated to achieve transparent compression <ref> [8, 7, 9, 10, 11] </ref> These auditory filter banks can be characterized in terms of the classical critical bandwidths, which were derived in experiments on noise masking and perception of complex sounds; these are generally considered to be the bandwidths of the auditory filters at certain center frequencies [185]. <p> This section describes extensions in audio coding and provides suggestions for further work involving overcomplete expansions. 7.2.1 Audio Coding The current standard methods in audio coding, namely MPEG and related coding schemes, use cosine-modulated filter banks; perceptual criterion are applied to the subband signals to achieve data reduction <ref> [12, 7, 9, 8] </ref>. Some signal adaptivity is achieved by adjusting the filter lengths according to the signal behavior; in terms of the prototype window for the filter bank, a short window is used in the vicinity of transients and a long window is used for stationary regions. <p> Optimal segmentation for signal modeling and compression. In IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings, 3:2029-2032, May 1997. [6] M. Goodwin. Nonuniform filter bank design for audio signal modeling. In Conference Record of the Thirtieth Asilomar Conference on Signals, Systems, and Computers, 2:1229-1233, November 1996. <ref> [7] </ref> M. Goodwin and M. Vetterli. Time-frequency signal models for music analysis, transformation, and synthesis. In Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis, pp. 133-6, June 1996. [8] M. Goodwin. Residual modeling in music analysis-synthesis.
Reference: [8] <author> D. Pan, </author> <title> "A tutorial on MPEG/audio compression," </title> <journal> IEEE Multimedia, </journal> <volume> vol. 2, </volume> <pages> pp. 60-74, </pages> <month> Summer </month> <year> 1995. </year>
Reference-contexts: This approach is best described pictorially; Figure 3.16 shows a signal segmentation and the corresponding motif and interpolation windows. Note that the asymmetric transition windows are conceptually similar to the start and stop windows used in modern audio coding standards <ref> [7, 8] </ref>; in those methods, however, such asymmetric windows are used in conjunction with a filter bank analysis-synthesis and not with a parametric approach as in this consideration. 3.5 Conclusion In modeling nonstationary signals, it is generally useful to carry out analysis-synthesis in a multiresolution framework; appropriate time-frequency resolution tradeoffs can <p> Such filter bank models, which were first introduced in conjunction with the classical theory of resonance [182], are well justified by experimental work ranging from early masking tests for telephony applications [183, 184] to recent investigations in perceptual audio coding, where auditory models are incorporated to achieve transparent compression <ref> [8, 7, 9, 10, 11] </ref> These auditory filter banks can be characterized in terms of the classical critical bandwidths, which were derived in experiments on noise masking and perception of complex sounds; these are generally considered to be the bandwidths of the auditory filters at certain center frequencies [185]. <p> This section describes extensions in audio coding and provides suggestions for further work involving overcomplete expansions. 7.2.1 Audio Coding The current standard methods in audio coding, namely MPEG and related coding schemes, use cosine-modulated filter banks; perceptual criterion are applied to the subband signals to achieve data reduction <ref> [12, 7, 9, 8] </ref>. Some signal adaptivity is achieved by adjusting the filter lengths according to the signal behavior; in terms of the prototype window for the filter bank, a short window is used in the vicinity of transients and a long window is used for stationary regions. <p> In Conference Record of the Thirtieth Asilomar Conference on Signals, Systems, and Computers, 2:1229-1233, November 1996. [7] M. Goodwin and M. Vetterli. Time-frequency signal models for music analysis, transformation, and synthesis. In Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis, pp. 133-6, June 1996. <ref> [8] </ref> M. Goodwin. Residual modeling in music analysis-synthesis. In IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceed ings, 2:1005-1008, May 1996. [9] G. Chang, M. Goodwin, V. Goyal, T. Kalker. Solutions Manual for Wavelets and Subband Coding by M. Vetterli and J. Kovacevic Prentice-Hall, 1995. [10] M.
Reference: [9] <editor> C. Todd et al., "AC-3: </editor> <title> Flexible perceptual coding for audio transmission and storage," </title> <booktitle> in Proceedings of the 96th Convention of the Audio Engineering Society, </booktitle> <month> Febru-ary </month> <year> 1994. </year> <type> Preprint 3796. </type>
Reference-contexts: However, time-domain aliasing cancellation can be incorporated in critically sampled cosine-modulated filter banks; such filter banks are commonly used in audio coding <ref> [12, 7, 9, 16, 17] </ref>. The ability to use time-domain aliasing cancellation in a cosine-modulated filter bank is connected to the result that the expansion functions in a cosine-modulated filter bank can have good time and frequency localization [2]. <p> Such filter bank models, which were first introduced in conjunction with the classical theory of resonance [182], are well justified by experimental work ranging from early masking tests for telephony applications [183, 184] to recent investigations in perceptual audio coding, where auditory models are incorporated to achieve transparent compression <ref> [8, 7, 9, 10, 11] </ref> These auditory filter banks can be characterized in terms of the classical critical bandwidths, which were derived in experiments on noise masking and perception of complex sounds; these are generally considered to be the bandwidths of the auditory filters at certain center frequencies [185]. <p> This section describes extensions in audio coding and provides suggestions for further work involving overcomplete expansions. 7.2.1 Audio Coding The current standard methods in audio coding, namely MPEG and related coding schemes, use cosine-modulated filter banks; perceptual criterion are applied to the subband signals to achieve data reduction <ref> [12, 7, 9, 8] </ref>. Some signal adaptivity is achieved by adjusting the filter lengths according to the signal behavior; in terms of the prototype window for the filter bank, a short window is used in the vicinity of transients and a long window is used for stationary regions. <p> Time-frequency signal models for music analysis, transformation, and synthesis. In Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis, pp. 133-6, June 1996. [8] M. Goodwin. Residual modeling in music analysis-synthesis. In IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceed ings, 2:1005-1008, May 1996. <ref> [9] </ref> G. Chang, M. Goodwin, V. Goyal, T. Kalker. Solutions Manual for Wavelets and Subband Coding by M. Vetterli and J. Kovacevic Prentice-Hall, 1995. [10] M. Goodwin and A. Kogon. Overlap-add synthesis of nonstationary sinusoids. In Proceedings of the International Computer Music Conference, pp. 355-356, September 1995. [11] M.
Reference: [10] <author> K. Gosse et al., </author> <title> "Subband audio coding with synthesis filters minimizing a perceptual criterion," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 1, </volume> <pages> pp. 347-350, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: Such filter bank models, which were first introduced in conjunction with the classical theory of resonance [182], are well justified by experimental work ranging from early masking tests for telephony applications [183, 184] to recent investigations in perceptual audio coding, where auditory models are incorporated to achieve transparent compression <ref> [8, 7, 9, 10, 11] </ref> These auditory filter banks can be characterized in terms of the classical critical bandwidths, which were derived in experiments on noise masking and perception of complex sounds; these are generally considered to be the bandwidths of the auditory filters at certain center frequencies [185]. <p> Goodwin. Residual modeling in music analysis-synthesis. In IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceed ings, 2:1005-1008, May 1996. [9] G. Chang, M. Goodwin, V. Goyal, T. Kalker. Solutions Manual for Wavelets and Subband Coding by M. Vetterli and J. Kovacevic Prentice-Hall, 1995. <ref> [10] </ref> M. Goodwin and A. Kogon. Overlap-add synthesis of nonstationary sinusoids. In Proceedings of the International Computer Music Conference, pp. 355-356, September 1995. [11] M. Goodwin and X. Rodet. Efficent Fourier synthesis of nonstationary sinusoids.
Reference: [11] <author> K. Gosse, O. Pothier, and P. Duhamel, </author> <title> "Optimizing the synthesis filter bank in audio coding for minimum distortion using a frequency weighted psychoacoustic criterion," </title> <booktitle> in Proceedings of the IEEE ASSP Workshop on Applications of Signal Processing to Audio and Acoustics, </booktitle> <pages> pp. 191-194, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: Such filter bank models, which were first introduced in conjunction with the classical theory of resonance [182], are well justified by experimental work ranging from early masking tests for telephony applications [183, 184] to recent investigations in perceptual audio coding, where auditory models are incorporated to achieve transparent compression <ref> [8, 7, 9, 10, 11] </ref> These auditory filter banks can be characterized in terms of the classical critical bandwidths, which were derived in experiments on noise masking and perception of complex sounds; these are generally considered to be the bandwidths of the auditory filters at certain center frequencies [185]. <p> Chang, M. Goodwin, V. Goyal, T. Kalker. Solutions Manual for Wavelets and Subband Coding by M. Vetterli and J. Kovacevic Prentice-Hall, 1995. [10] M. Goodwin and A. Kogon. Overlap-add synthesis of nonstationary sinusoids. In Proceedings of the International Computer Music Conference, pp. 355-356, September 1995. <ref> [11] </ref> M. Goodwin and X. Rodet. Efficent Fourier synthesis of nonstationary sinusoids. In Proceeedings of the International Computer Music Conference, pp. 333-334, Septem ber 1994. 242 [12] M. Goodwin. Frequency-independent beamforming.
Reference: [12] <author> J. P. Princen and A. B. Bradley, </author> <title> "Analysis/synthesis filter bank design based on time domain aliasing cancellation," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 34, </volume> <pages> pp. 1153 - 1161, </pages> <month> October </month> <year> 1986. </year> <month> 244 </month>
Reference-contexts: The condition K N is imposed at this point to simplify the formulation; time-domain aliasing is introduced in the undersampled case K &lt; N , meaning that the formulation must be revised to provide for time-domain aliasing cancellation <ref> [12] </ref>. The issue of time-domain aliasing cancellation is discussed in Section 2.2.2. <p> Then, the subband signals are real-valued, which is certainly desirable in some cases; here, however, it is problematic since the phase provided by the 47 complex filter bank is important for sinusoidal modeling as will be seen. While cosine-modulated filter banks have interesting and significant properties <ref> [2, 20, 4, 12, 59] </ref>, they are an offshoot of the progression of ideas that leads to the sinusoidal model and will not be considered in depth here because of this phase problem. <p> However, time-domain aliasing cancellation can be incorporated in critically sampled cosine-modulated filter banks; such filter banks are commonly used in audio coding <ref> [12, 7, 9, 16, 17] </ref>. The ability to use time-domain aliasing cancellation in a cosine-modulated filter bank is connected to the result that the expansion functions in a cosine-modulated filter bank can have good time and frequency localization [2]. <p> This section describes extensions in audio coding and provides suggestions for further work involving overcomplete expansions. 7.2.1 Audio Coding The current standard methods in audio coding, namely MPEG and related coding schemes, use cosine-modulated filter banks; perceptual criterion are applied to the subband signals to achieve data reduction <ref> [12, 7, 9, 8] </ref>. Some signal adaptivity is achieved by adjusting the filter lengths according to the signal behavior; in terms of the prototype window for the filter bank, a short window is used in the vicinity of transients and a long window is used for stationary regions. <p> Goodwin and A. Kogon. Overlap-add synthesis of nonstationary sinusoids. In Proceedings of the International Computer Music Conference, pp. 355-356, September 1995. [11] M. Goodwin and X. Rodet. Efficent Fourier synthesis of nonstationary sinusoids. In Proceeedings of the International Computer Music Conference, pp. 333-334, Septem ber 1994. 242 <ref> [12] </ref> M. Goodwin. Frequency-independent beamforming. In Proceedings of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics, pp. 60-3, October 1993. [13] M. Goodwin and G. Elko. Constant beamwidth beamforming. In IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings, 1:169-72, April 1993.
Reference: [13] <author> J. Princen and J. Johnston, </author> <title> "Audio coding with signal adaptive filterbanks," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 5, </volume> <pages> pp. 3071-3074, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Goodwin and X. Rodet. Efficent Fourier synthesis of nonstationary sinusoids. In Proceeedings of the International Computer Music Conference, pp. 333-334, Septem ber 1994. 242 [12] M. Goodwin. Frequency-independent beamforming. In Proceedings of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics, pp. 60-3, October 1993. <ref> [13] </ref> M. Goodwin and G. Elko. Constant beamwidth beamforming. In IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings, 1:169-72, April 1993. Also in IEEE Techology Update Series: Signal Processing Applications and Technology, ed. J. Ackenhausen, pp. 499-502, 1995. [14] G. Elko and M. Goodwin.
Reference: [14] <author> D. Sinha and A. H. Tewfik, </author> <title> "Low bit rate transparent audio compression using adapted wavelets," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 41, </volume> <pages> pp. 3463-3479, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Goodwin and G. Elko. Constant beamwidth beamforming. In IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings, 1:169-72, April 1993. Also in IEEE Techology Update Series: Signal Processing Applications and Technology, ed. J. Ackenhausen, pp. 499-502, 1995. <ref> [14] </ref> G. Elko and M. Goodwin. Beam dithering: Acoustic feedback control using a modulated-directivity loudspeaker array. In IEEE International Conference on Acous tics, Speech, and Signal Processing Conference Proceedings, 1:173-6, April 1993. [15] M. Goodwin and G. Elko. Beam dithering: Acoustic feedback reduction using a modulated-directivity loudspeaker array.
Reference: [15] <author> D. Sinha and J. Johnston, </author> <title> "Audio compression at low bit rates using a signal adaptive switched filterbank," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 2, </volume> <pages> pp. 1053-1056, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Also in IEEE Techology Update Series: Signal Processing Applications and Technology, ed. J. Ackenhausen, pp. 499-502, 1995. [14] G. Elko and M. Goodwin. Beam dithering: Acoustic feedback control using a modulated-directivity loudspeaker array. In IEEE International Conference on Acous tics, Speech, and Signal Processing Conference Proceedings, 1:173-6, April 1993. <ref> [15] </ref> M. Goodwin and G. Elko. Beam dithering: Acoustic feedback reduction using a modulated-directivity loudspeaker array. Presented at the 92nd Meeting of the Audio Engineering Society, October 1992. Preprint 3384. [16] G. Elko, M. Goodwin, R. Kubli, J. West. Electret Transducer Array and Fabrication Technique. AT&T Bell Labs, 1992.
Reference: [16] <author> K. Tsutsui et al., "ATRAC: </author> <title> Adaptive transform acoustic coding for MiniDisc," </title> <booktitle> in Proceedings of the 93rd Convention of the Audio Engineering Society, </booktitle> <month> October </month> <year> 1992. </year> <type> Preprint 3456. </type>
Reference-contexts: However, time-domain aliasing cancellation can be incorporated in critically sampled cosine-modulated filter banks; such filter banks are commonly used in audio coding <ref> [12, 7, 9, 16, 17] </ref>. The ability to use time-domain aliasing cancellation in a cosine-modulated filter bank is connected to the result that the expansion functions in a cosine-modulated filter bank can have good time and frequency localization [2]. <p> In IEEE International Conference on Acous tics, Speech, and Signal Processing Conference Proceedings, 1:173-6, April 1993. [15] M. Goodwin and G. Elko. Beam dithering: Acoustic feedback reduction using a modulated-directivity loudspeaker array. Presented at the 92nd Meeting of the Audio Engineering Society, October 1992. Preprint 3384. <ref> [16] </ref> G. Elko, M. Goodwin, R. Kubli, J. West. Electret Transducer Array and Fabrication Technique. AT&T Bell Labs, 1992. Patent number 5388163. [17] M. Goodwin. Implementation and Applications of Electroacoustic Array Beamform ers. S.M. Thesis, MIT, 1992. 243
Reference: [17] <author> S. Shlien, </author> <title> "The modulated lapped transform, its time-varying forms, and its application to audio coding standards," </title> <journal> IEEE Transactions on Speech and Audio Processing, </journal> <volume> vol. 5, </volume> <pages> pp. 359-366, </pages> <month> July </month> <year> 1997. </year>
Reference-contexts: However, time-domain aliasing cancellation can be incorporated in critically sampled cosine-modulated filter banks; such filter banks are commonly used in audio coding <ref> [12, 7, 9, 16, 17] </ref>. The ability to use time-domain aliasing cancellation in a cosine-modulated filter bank is connected to the result that the expansion functions in a cosine-modulated filter bank can have good time and frequency localization [2]. <p> Elko. Beam dithering: Acoustic feedback reduction using a modulated-directivity loudspeaker array. Presented at the 92nd Meeting of the Audio Engineering Society, October 1992. Preprint 3384. [16] G. Elko, M. Goodwin, R. Kubli, J. West. Electret Transducer Array and Fabrication Technique. AT&T Bell Labs, 1992. Patent number 5388163. <ref> [17] </ref> M. Goodwin. Implementation and Applications of Electroacoustic Array Beamform ers. S.M. Thesis, MIT, 1992. 243
Reference: [18] <author> J. M. Shapiro, </author> <title> "Embedded image coding using zerotrees of wavelet coefficients," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 41, </volume> <pages> pp. 3445-3462, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: The octave bands provide details that can be added to successively refine the signal; perfect reconstruction is achieved if all of the subbands are included. This lowpass-plus-details model is appropriate for signals which are primarily lowpass; the wavelet transform has thus been applied successfully in image compression <ref> [18, 19] </ref>. However, for signals with wideband spectral content, such as high-quality audio, a lowpass estimate is a poor approximation. For any pseudo-periodic signals with high-frequency harmonic content, a lowpass estimate does not incorporate the high-frequency harmonics. <p> This type of modeling has proven quite useful for image coding <ref> [18, 19] </ref>. For audio, however, a lowpass estimate neglects high frequency content and thus tends to yield a low-quality reconstruction. Building from this observation, the pitch-synchronous wavelet transform estimates the signal in terms of its spectral content around its harmonic frequencies.
Reference: [19] <author> A. Said and W. A. Pearlman, </author> <title> "An image multiresolution representation for lossless and lossy compression," </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> vol. 5, </volume> <pages> pp. 1303-1310, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: The octave bands provide details that can be added to successively refine the signal; perfect reconstruction is achieved if all of the subbands are included. This lowpass-plus-details model is appropriate for signals which are primarily lowpass; the wavelet transform has thus been applied successfully in image compression <ref> [18, 19] </ref>. However, for signals with wideband spectral content, such as high-quality audio, a lowpass estimate is a poor approximation. For any pseudo-periodic signals with high-frequency harmonic content, a lowpass estimate does not incorporate the high-frequency harmonics. <p> This type of modeling has proven quite useful for image coding <ref> [18, 19] </ref>. For audio, however, a lowpass estimate neglects high frequency content and thus tends to yield a low-quality reconstruction. Building from this observation, the pitch-synchronous wavelet transform estimates the signal in terms of its spectral content around its harmonic frequencies.
Reference: [20] <author> P. P. Vaidyanathan, </author> <title> Multirate Systems and Filter Banks. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall, </publisher> <year> 1993. </year>
Reference-contexts: Perfect reconstruction constraints for such STFT filter banks are derived. In the literature, z-transform and matrix representations have been shown to be useful in analyzing the properties of such filter banks <ref> [2, 20, 120] </ref>. Here, for the sake of brevity, these methods are not explored; the STFT filter banks are treated using time-domain considerations. <p> a way that the transforms X [k; n] and ~ X [k; n] refer to the same N -point segment of the signal and can thus be compared; it should be noted that in some treatments the STFT is expressed as in Equation (2.5) but without time-reversal of the window <ref> [20] </ref>. It will be shown that this reversal of the time index affects the interpretation of the transform as a filter bank; more importantly, however, the interpretation is affected by the time reference of the expansion functions. <p> This latter design method will come into play in the frequency-domain sinusoidal synthesizer to be discussed in Section 2.5. The STFT as a heterodyne filter bank In <ref> [111, 115, 116, 20] </ref>, where the STFT is defined as in Equation (2.5) and the expansion functions have an absolute time reference, the transform can be interpreted as 41 a filter bank with a heterodyne structure. <p> Note that in the phase-localized STFT formulated in Equation (2.3), the corresponding reconstruction formula is ^x [n] = k where the STFT X [k; n] corresponds to a partial at frequency ! k rather than its amplitude envelope. equivalent structure based on modulated filters <ref> [20] </ref>. Mathematically, the equivalence is 42 @ e j! k n x [n] - ~w [n]e j! k n - + 6 - ~ X 2 (k; n) defined in Equation (2.5). The two structures are equivalent as indicated in Equation (2.23). <p> The STFT as a modulated filter bank Modulated filter banks, in which the filters are modulated versions of a prototype lowpass filter, have been of considerable interest in the recent literature <ref> [20, 2, 4] </ref>. In part, this interest has stemmed from the realization that the STFT can be implemented with a modulated filter bank structure. Indeed, the STFT of Equation (2.3) corresponds exactly to a modulated filter bank of the general form shown in Figure 2.3. <p> Then, the subband signals are real-valued, which is certainly desirable in some cases; here, however, it is problematic since the phase provided by the 47 complex filter bank is important for sinusoidal modeling as will be seen. While cosine-modulated filter banks have interesting and significant properties <ref> [2, 20, 4, 12, 59] </ref>, they are an offshoot of the progression of ideas that leads to the sinusoidal model and will not be considered in depth here because of this phase problem. <p> Frequency-domain interpretations of aliasing cancellation and signal reconstruction based on this lowpass-highpass structure are given in <ref> [2, 20] </ref>. Arbitrary tree-structured filter banks that achieve perfect reconstruction can be constructed by iterating two-channel perfect reconstruction filter banks; indeed, the filter trees can be made to adapt to model nonstationary input signals while still satisfying the reconstruction constraint [60]. <p> As noted in Figure 3.4, the discrete wavelet transform corresponds to successive iterations on the lowpass branch. The discrete wavelet transform The discrete wavelet transform is perhaps the most common example of a tree-structured filter bank. It has been widely explored in the literature <ref> [2, 20] </ref>. Here, the discussion is limited to general signal modeling issues. The discrete wavelet transform is constructed by successive iterations on the lowpass branch. Given that H 0 (z) and H 1 (z) are respectively a lowpass and a highpass filter, the filtering operations can be readily interpreted. <p> Due to the various advantages of subband processing, such filter bank approaches have been widely dealt with in the literature, but primarily for the case of uniform or octave-band filter banks <ref> [2, 20] </ref>. Some results on nonuniform critically sampled and oversampled perfect reconstruction filter banks have also been presented [188, 189, 190, 191, 192]. The design of a nonuniform filter bank for the noise perception model proposed in Section 4.2 differs from the perfect reconstruction problem discussed above. <p> Similar ideas have been employed in compression algorithms based on more standard filter bank structures such as the discrete wavelet transform and uniform filter banks <ref> [2, 20] </ref>. 182 5.5 Applications Of course, pitch-synchronous methods such as the ones discussed in this chapter have immediate applications in audio processing. These have been considered throughout the chapter; a few further issues are treated in Section 5.5.1.
Reference: [21] <author> J. O. Smith, </author> <title> "Physical modeling synthesis update," </title> <journal> Computer Music Journal, </journal> <volume> vol. 20, </volume> <pages> pp. 44-56, </pages> <month> Summer </month> <year> 1996. </year>
Reference: [22] <author> J. O. Smith, </author> <title> Techniques for Digital Filter Design and System Identification With Application to the Violin. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> June </month> <year> 1983. </year>
Reference: [23] <author> J. Makhoul, </author> <title> "Linear prediction: A tutorial review," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 63, </volume> <pages> pp. 561-580, </pages> <month> April </month> <year> 1975. </year>
Reference-contexts: The overall model mixture then consisted of slowly-varying sinusoids and 157 broadband noise. A representation similar to the deterministic-plus-stochastic decomposition of Chapter 2 has been widely applied in linear predictive coding (LPC) of speech, where the speech is coded using a time-varying source-filter model <ref> [1, 23] </ref>. The filter is adapted in time to match the speech spectrum, while the source is chosen based on a classification of the local speech signal as voiced or unvoiced.
Reference: [24] <author> A. Gersho, </author> <title> "Speech coding," in Speech Analysis and Synthesis and Man-Machine Speech Communications for Air Operations, </title> <journal> pp. </journal> <pages> 3/1-3/14, </pages> <month> May </month> <year> 1990. </year>
Reference: [25] <author> D. Griffin and J. Lim, </author> <title> "Multiband excitation vocoder," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 36, </volume> <pages> pp. 1223-1235, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: The model thus adapts to a nonstationary signal by choosing the appropriate excitation. In some variations of the algorithm, a mixed excitation is used to account for concurrent voiced and unvoiced signal behavior; using a mixture enables modeling of a wider variety of signals than with a switched excitation <ref> [25, 179] </ref>. The voiced-unvoiced model, especially in the case of a mixed excitation, is similar to the deterministic-plus-stochastic sinusoidal model decomposition proposed in [36, 100] and explored further in [97, 110, 178, 109, 180].
Reference: [26] <author> J. A. Moorer, </author> <title> "The use of linear prediction of speech in computer music applications," </title> <journal> Journal of the Audio Engineering Society, </journal> <volume> vol. 27, </volume> <pages> pp. 134-140, </pages> <month> March </month> <year> 1979. </year>
Reference: [27] <author> X. Rodet, </author> <title> "Time-domain formant-wave-function synthesis," </title> <journal> Computer Music Journal, </journal> <volume> vol. 8, </volume> <pages> pp. 9-14, </pages> <month> Fall </month> <year> 1984. </year> <month> 245 </month>
Reference: [28] <author> K. Karplus and A. </author> <title> Strong, "Digital synthesis of plucked-string and drum timbres," </title> <journal> Computer Music Journal, </journal> <volume> vol. 7, </volume> <pages> pp. 43-55, </pages> <month> Summer </month> <year> 1983. </year>
Reference: [29] <author> D. A. Jaffe and J. O. Smith, </author> <title> "Extensions of the Karplus-Strong plucked-string algorithm," </title> <journal> Computer Music Journal, </journal> <volume> vol. 7, </volume> <pages> pp. 56-69, </pages> <month> Summer </month> <year> 1983. </year>
Reference: [30] <author> G. Evangelista and S. Cavaliere, </author> <title> "Karplus-Strong parameter estimation," </title> <booktitle> in Proceedings of the Workshop on Physical Model Synthesis, </booktitle> <month> June </month> <year> 1996. </year>
Reference: [31] <author> J.-C. Risset and M. V. Matthews, </author> <title> "Analysis of musical-instrument tones," </title> <journal> Physics Today, </journal> <volume> vol. 22, </volume> <pages> pp. 23-30, </pages> <month> February </month> <year> 1969. </year>
Reference-contexts: This notion was previously depicted in Figure 2.7; the simple structure of the synthesis bank is given again in Figure 2.12 to emphasize a few key points. First, banks of oscillators have been widely explored in the computer music field as an additive synthesis tool <ref> [31, 35, 34] </ref>. Early considerations, however, were restricted to synthesis of artificial sounds based on simple parameter control functions since corresponding analyses of natural signals were unavailable and since computational capabilities were limited.
Reference: [32] <author> M. D. Freedman, </author> <title> "Analysis of musical instrument tones," </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> vol. 41, </volume> <pages> pp. 793-806, </pages> <month> April </month> <year> 1967. </year>
Reference: [33] <author> C. Roads, </author> <title> "Introduction to granular synthesis," </title> <journal> Computer Music Journal, </journal> <volume> vol. 12, </volume> <pages> pp. 11-13, </pages> <month> Summer </month> <year> 1988. </year>
Reference: [34] <author> C. Roads, </author> <title> The Computer Music Tutorial. </title> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: This notion was previously depicted in Figure 2.7; the simple structure of the synthesis bank is given again in Figure 2.12 to emphasize a few key points. First, banks of oscillators have been widely explored in the computer music field as an additive synthesis tool <ref> [31, 35, 34] </ref>. Early considerations, however, were restricted to synthesis of artificial sounds based on simple parameter control functions since corresponding analyses of natural signals were unavailable and since computational capabilities were limited. <p> For instance, the clarinet and the bassoon would be fairly close together in this space, while the piano or guitar would not be nearby. Such categorization is referred to as multidimensional scaling <ref> [35, 34, 108] </ref>. It has been observed that timbre, which corresponds loosely to the evolution and shape of the spectral envelope, is an important feature in subjective evaluations of the similarity of sounds; if two sounds have the same timbre, they are generally judged to be similar [108].
Reference: [35] <author> F. R. Moore, </author> <title> Elements of Computer Music. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1990. </year>
Reference-contexts: This notion was previously depicted in Figure 2.7; the simple structure of the synthesis bank is given again in Figure 2.12 to emphasize a few key points. First, banks of oscillators have been widely explored in the computer music field as an additive synthesis tool <ref> [31, 35, 34] </ref>. Early considerations, however, were restricted to synthesis of artificial sounds based on simple parameter control functions since corresponding analyses of natural signals were unavailable and since computational capabilities were limited. <p> For instance, the clarinet and the bassoon would be fairly close together in this space, while the piano or guitar would not be nearby. Such categorization is referred to as multidimensional scaling <ref> [35, 34, 108] </ref>. It has been observed that timbre, which corresponds loosely to the evolution and shape of the spectral envelope, is an important feature in subjective evaluations of the similarity of sounds; if two sounds have the same timbre, they are generally judged to be similar [108].
Reference: [36] <author> X. Serra and J. Smith, </author> <title> "Spectral modeling synthesis: A sound analysis/synthesis system based on a deterministic plus stochastic decomposition," </title> <journal> Computer Music Journal, </journal> <volume> vol. 14, </volume> <pages> pp. 12-24, </pages> <month> Winter </month> <year> 1990. </year>
Reference-contexts: introduction to the discussion of the sinusoidal model. 2.1 The Sinusoidal Signal Model A variety of sinusoidal modeling techniques have been explored in the literature <ref> [106, 96, 95, 98, 57, 36, 102, 101, 97] </ref>. These methods share fundamental common points, but also have substantial but sometimes subtle differences. <p> These methods share fundamental common points, but also have substantial but sometimes subtle differences. For the sake of simplicity, this treatment adheres primarily to the approaches presented in the early literature on sinusoidal modeling <ref> [57, 36] </ref>, and not on the many variations that have since been proposed [103, 97, 98]; comments on some other techniques such as [101, 107] are indeed included, but these inclusions are limited to techniques that are directly concerned with the modeling issues at hand. <p> It should be noted that the issues to be discussed herein apply to sinusoidal modeling in general; their relevance is not limited by the adherence to the particular methods of <ref> [57, 36] </ref>. <p> Since it describes the primary musical information about the signal in a simple, compact form, the parameterization provides not only a reasonable coding representation but also a framework for carrying out desirable modifications such as pitch-shifting, time-scaling, and a wide variety of spectral transformations such as cross-synthesis <ref> [93, 94, 36, 102, 103, 108] </ref>. 2.1.2 Deterministic-plus-Stochastic Decomposition The approximation symbol in Equation (2.1) is included to imply that the sum-of-partials model does not provide an exact reconstruction of the signal. <p> Since these features are important for high-fidelity synthesis, an additional component is often included in the signal model to account for broadband processes: x [n] = ^x [n] + r [n] = d [n] + s [n]: (2.2) 35 The resultant deterministic-plus-stochastic decomposition was introduced in <ref> [36, 100] </ref> and has been discussed in several later efforts [109, 110]. <p> As mentioned, these parameters are assumed to be slowly varying with respect to the sample rate, so the estimation process can be reliably carried out at a subsampled rate. In <ref> [57, 36] </ref>, this analysis is done using a short-time Fourier transform followed by spectral peak picking; this procedure was conceptually motivated in the preceding discussion of the STFT. <p> Since Hanning and other similarly constructed windows have been commonly used, it has become a heuristic in STFT analysis to use windows of length two to three times the signal period. Modeling arbitrary signals Analysis based on the DFT has been used in numerous sinusoidal modeling applications <ref> [57, 36, 100] </ref>. These methods incorporate the constraints discussed above for resolution of harmonics and have been successfully applied to modeling signals with harmonic structure. <p> For complicated signals with many evolving partials, the problem of line tracking is obviously difficult. One important fix, proposed in <ref> [36, 100] </ref>, is the use of backward line tracking when necessary; this technique can be used to track the partials of a note from the sustain region back to their origins in the note attack, which helps with the difficulties previously discussed. <p> Another observation is that line tracking can be aided by considering harmonicity; if the partials are roughly harmonic, the data sets can be coupled more readily than in the general case <ref> [57, 36] </ref>. A number of more complex methods have been explored in the literature. <p> Typically, interpolation is done using low-order polynomial models such as linear amplitude and cubic total phase; the specific approach of [57] is presented here, but other interpolation methods have been considered <ref> [36, 107, 148, 149, 150] </ref>. <p> As discussed, the sinusoidal model is ineffective for representing broadband processes. This shortcoming motivates the inclusion of the stochastic component proposed in <ref> [36] </ref> to account for musically relevant stochastic features such as breath noise in a flute or bow noise in a violin; these must be incorporated if realistic synthesis is desired. This approach assumes that the original signal is a clean recording of a natural instrument. <p> Thus, it is necessary to separately model the analysis-synthesis residual if high-quality synthesis is desired; this requirement was the motivation for the deterministic-plus-stochastic decomposition proposed in <ref> [36, 100] </ref>. This chapter discusses a parametric approach for perceptually modeling the noiselike residual for both time-domain and frequency-domain synthesis. Earlier versions of this work have been presented in the literature [110, 178]. 4.1 Mixed Models Mixed models have been applied in many signal processing algorithms. <p> The voiced-unvoiced model, especially in the case of a mixed excitation, is similar to the deterministic-plus-stochastic sinusoidal model decomposition proposed in <ref> [36, 100] </ref> and explored further in [97, 110, 178, 109, 180]. The components in these latter models are concurrent in time; the models are thus capable of representing a wide variety of signals. <p> It is necessary to incorporate these processes into the reconstruction to achieve realistic or natural-sounding synthesis. In <ref> [36, 100] </ref>, the residual is modeled using a piecewise-linear spectral estimate; a random phase is applied to this spectrum, and an inverse discrete Fourier transform (IDFT) followed by overlap-add (OLA) is used for synthesis.
Reference: [37] <author> H. Lee and K. Buckley, </author> <title> "Heart beat data compression using temporal beats alignment and 2-d transforms," </title> <booktitle> in Conference Record of the Thirtieth Asilomar Conference on Signals, Systems, and Computers, </booktitle> <volume> vol. 2, </volume> <pages> pp. 1224-1228, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: To account for both types of redundancy, the PSR can be processed by a two-dimensional wavelet transform; for separable two-dimensional wavelets, this amounts to coupling the PSWT and the DWT. A similar approach has been applied successfully to ECG data compression <ref> [37] </ref>. It is an open question, however, if this method can be used for high-quality compression of speech or audio. 5.4.3 Coding and Modification In this section, applications of the pitch-synchronous wavelet transform for signal coding and modification are considered. <p> Various methods of ambulatory ECG signal compression have been presented in the literature; these rely on either the redundancy between neighboring samplings of the signal or the redundancy between adjacent periods [208, 209]. Recently, a method exploiting both forms of redundancy was proposed <ref> [37] </ref>; here, the signal is segmented into pulses and arranged into a structure resembling a PSR matrix. Then, this structure is interpreted as an image and compressed using a two-dimensional discrete cosine transform (DCT); the compression is structured such that important features of the pulse shape are represented accurately.
Reference: [38] <author> S. Mallat and Z. Zhang, </author> <title> "Matching pursuits with time-frequency dictionaries," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 41, </volume> <pages> pp. 3397-3415, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: In this chapter, signal-adaptive parametric models based on overcomplete dictionaries of time-frequency atoms are considered. Such overcomplete expansions can be derived using the matching pursuit algorithm <ref> [38] </ref>. The resulting representations are signal-adaptive in that the atoms for the model are chosen to match the signal behavior; furthermore, the models are parametric in that the atoms can be described in terms of simple parameters. <p> This shortcoming results from the attempt to model arbitrary signals in terms of a limited and fixed set of functions. To overcome the difficulties of basis expansions, signals can instead be modeled using an overcomplete set of atoms that exhibits a wide range of time-frequency behaviors <ref> [38, 68, 42, 43, 211] </ref>. Such overcomplete expansions allow for compact representation of arbitrary signals for the sake of compression or analysis [38, 92]. <p> To overcome the difficulties of basis expansions, signals can instead be modeled using an overcomplete set of atoms that exhibits a wide range of time-frequency behaviors [38, 68, 42, 43, 211]. Such overcomplete expansions allow for compact representation of arbitrary signals for the sake of compression or analysis <ref> [38, 92] </ref>. With respect to the interpretation of signal modeling as an inverse problem, when the functions fd m [n]g constitute an overcomplete or redundant set (M &gt; N ), the dictionary matrix D is of rank N and the linear system in Equation (6.2) is underdetermined. <p> Such approaches can be roughly grouped into two categories: parallel methods such as the method of frames [63, 70], basis pursuit [42, 43], and FOCUSS [68, 67], in which computation of the various expansion components is coupled; and, sequential methods such as matching pursuit and its variations <ref> [38, 68, 211, 212, 213, 214] </ref>, in which models are computed one component at a time. All of these methods can be interpreted as approaches to solving inverse problems. <p> All of these methods can be interpreted as approaches to solving inverse problems. For compact signal modeling, sparse approximate solutions are of interest; the matching pursuit algorithm of <ref> [38] </ref> is particularly useful since it is amenable to task of modeling arbitrary signals using parameterized time-frequency atoms in a successive refinement framework. After a brief review of the singular value decomposition and the pseudo-inverse, nonlinear approaches such as matching pursuit are motivated. <p> For this reason, it is necessary to narrow the considerations to methods that either derive sparse approximate solutions according to suboptimal criteria or derive exact solutions that are not optimally sparse. The matching pursuit algorithm introduced in <ref> [38] </ref> is an example of the former category; it is the method of choice here since it provides a framework for deriving sparse approximate models with successive refinements and since it can be implemented with low cost as will be seen. <p> While this framework is fundamentally different from that of traditional parametric models, the signal models in the two cases have similar properties. 6.2 Matching Pursuit Matching pursuit is a greedy iterative algorithm for deriving signal decompositions in terms of expansion functions chosen from a dictionary <ref> [38] </ref>. To achieve compact representation of arbitrary signals, it is necessary that the dictionary elements or atoms exhibit a wide range of time-frequency behaviors and that the appropriate atoms from the dictionary be chosen to decompose a particular signal. <p> When a well-designed overcom-plete dictionary is used in matching pursuit, the nonlinear nature of the algorithm leads to compact signal-adaptive models <ref> [38, 211, 92] </ref>. A dictionary can be likened to the matrix D in Equation (6.2) by considering the atoms to be the matrix columns; then, matching pursuit can be interpreted as an approach for computing sparse approximate solutions to inverse problems [69, 215]. <p> As discussed in Section 6.1.2, sparse approximate solutions are useful for signal analysis, compression, and enhancement. Since such solutions are not provided by traditional linear methods such as the SVD, a nonlinear approximation paradigm such as matching pursuit is called for <ref> [38, 215, 69, 92] </ref>. 6.2.1 One-Dimensional Pursuit The greedy iteration in the matching pursuit algorithm is carried out as follows. First, the atom that best approximates the signal is chosen, where the two-norm is used as the approximation metric because of its mathematical convenience. <p> After I iterations, the pursuit provides the sparse approximate model x [n] i=1 I X ff i d m (i) [n]: (6.14) As indicated in Equation (6.11), the mean-squared error of the model decreases as the number of iterations increases <ref> [38] </ref>. This convergence implies that I iterations will yield a reasonable I -term model; this model, however, is in general not optimal in the mean-squared sense because of the term-by-term greediness of the algorithm. <p> To enable representation of a wide range of signal features, a large dictionary of time-frequency atoms is used in the matching pursuit algorithm. The computation of the correlations hg; r i i for all g 2 D is thus costly. As noted in <ref> [38] </ref>, this computation can be substantially reduced using an update formula based on Equation (6.6); the correlations at stage i + 1 are given by hg; r i+1 i = hg; r i i ff i hg; g i i; (6.15) where the only new computation required for the correlation update <p> The decompositions that result from considering conjugate subspaces are of the form x 2 i=1 This approach provides real decompositions of real signals using an underlying complex dictionary. The same notion is discussed briefly in <ref> [38] </ref> based on a different computational framework. <p> In this light, parametric overcomplete dictionaries consisting of atoms that exhibit a wide range of localized time and frequency behaviors are of great interest; matching pursuit then provides a compact, adaptive, and parametric time-frequency representation of a signal <ref> [38] </ref>. Such localized time-frequency atoms were introduced by Gabor from a theoretical standpoint and according to psychoacoustic motivations [71, 72]. 6.3.1 Gabor Atoms The literature on matching pursuit has focused on applications involving dictionaries of Gabor atoms since these are appropriate expansion functions for general time-frequency signal models [38]. 1 In <p> a signal <ref> [38] </ref>. Such localized time-frequency atoms were introduced by Gabor from a theoretical standpoint and according to psychoacoustic motivations [71, 72]. 6.3.1 Gabor Atoms The literature on matching pursuit has focused on applications involving dictionaries of Gabor atoms since these are appropriate expansion functions for general time-frequency signal models [38]. 1 In continuous time, such atoms are derived from a single unit-norm window function g (t) by scaling, modulation, and translation: g fs;!;t g (t) = p g n t This definition can be extended to discrete time by a sampling argument as in [38]; fundamentally, the extension simply indicates <p> for general time-frequency signal models <ref> [38] </ref>. 1 In continuous time, such atoms are derived from a single unit-norm window function g (t) by scaling, modulation, and translation: g fs;!;t g (t) = p g n t This definition can be extended to discrete time by a sampling argument as in [38]; fundamentally, the extension simply indicates that Gabor atoms can be represented in discrete 1 Atoms corresponding to wavelet and cosine packets have also been considered [42, 212]. 199 derived from a symmetric window by scaling, modulation, and translation operations as described in Equation (6.39). time as g fs;!;t g [n] <p> [n] 2 i=1 where f fa i ;b i ;J i g is as defined in Equation (6.46) and A i e j i = ff i (1) from Equation (6.19). 6.4.3 Computation Considerations This section compares the computational cost of two matching pursuit implementations: pursuit based on correlation updates <ref> [38] </ref> and pursuit based on recursive filter banks. In this comparison, the cost is measured in terms of memory requirements and multiplicative operations. Simple search operations, table lookups, and conditionals are neglected in the cost measure. <p> Preliminary formalizations of such tradeoffs have appeared in the literature, but there are many open questions [224]. With computation concerns in mind, it is of interest to consider simplifications of matching pursuit. For instance, in <ref> [38] </ref>, pursuit based on small subdictionaries is discussed; if the subdictionaries are well-chosen, this helps to reduce the computational requirements without substantially affecting the convergence of 229 the atomic model.
Reference: [39] <author> G. Davis, </author> <title> Adaptive Nonlinear Approximations. </title> <type> PhD thesis, </type> <address> New York University, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: Because of the complexity of the search, however, it is not computationally feasible to derive an optimal sparse expansion that perfectly models a signal. It is likewise not feasible to compute approximate sparse expansions that minimize the error for a given sparsity; this is an NP-hard problem <ref> [39] </ref>. For this reason, it is necessary to narrow the considerations to methods that either derive sparse approximate solutions according to suboptimal criteria or derive exact solutions that are not optimally sparse. <p> Computing the optimal I -term estimate using an overcomplete dictionary requires finding the minimum projection error over all I-dimensional dictionary subspaces, which is an NP-hard problem as mentioned earlier; this complexity result is established in <ref> [39] </ref> by relating the optimal approximation problem to the exact cover by 3-sets problem, which is known to be NP-complete. To enable representation of a wide range of signal features, a large dictionary of time-frequency atoms is used in the matching pursuit algorithm. <p> Matching pursuit is thus categorized as a greedy algorithm. It is well known that such greedy algorithms, when applied to overcomplete dictionaries, do not lead to optimal approximations, i.e. optimal compact models; however, greedy approaches are justified given the complexity of optimal approximation <ref> [39, 69] </ref>. Furthermore, it should be noted as in Section 6.1.2 that the use of a greedy algorithm inherently leads to successive refinement, which is a desirable property in signal models. <p> Methods for codebook optimization are still of interest for matching pursuit, however, since the codebook adaptation can be restricted to adhere to a parametric atomic structure. This connection is briefly explored in <ref> [39] </ref>; given the extent of work that has been devoted to vector quantization techniques, further investigations of applications to time-frequency atomic models are clearly merited [216]. <p> Then, such representation vectors can be added to the expansion while zeroing the corresponding components; in this way, the same signal reconstruction can be arrived at from a more compact model. The caveat here is that optimal compaction is still not feasible given the general complexity results presented in <ref> [39] </ref>; however, improved models may be achieved in some cases using such a method. In addition to refinement of overcomplete expansions to improve compaction, other modifications are also of interest.
Reference: [40] <author> R. Coifman and M. Wickerhauser, </author> <title> "Entropy-based algorithms for best basis selection," </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 38, </volume> <pages> pp. 713-718, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Examples include best basis methods and adaptive wavelet packets, where the overcomplete dictionary consists of a collection of bases; a basis for a signal expansion is chosen from the set of bases according to a metric such as entropy or rate-distortion <ref> [40, 41, 60] </ref>. In this chapter, signal decomposition using more general overcomplete sets is considered.
Reference: [41] <author> K. Ramchandran and M. Vetterli, </author> <title> "Best wavelet packet bases in a rate-distortion sense," </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> vol. 2, </volume> <pages> pp. 160-75, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: The brief description of multiresolution in tree-structured filter banks suggests why such methods might prove useful for processing arbitrary signals, especially if the filter bank is made adaptive; application examples include compression <ref> [41, 60] </ref> and spectral estimation [161]. Rather than focusing on such arbitrary tree-structured filter banks here, however, additional developments of the multiresolution concept will be formulated for the specific case of the discrete wavelet transform. <p> If the metric is additive and independent across segments, however, the computational cost can be substantially reduced using a dynamic program. This approach has been applied to wavelet packet and LPC models <ref> [41, 60, 134] </ref>; after a brief review of dynamic programming and the relevant literature, dynamic segmentation for sinusoidal modeling is considered. Dynamic programming Dynamic programming was first introduced for solving minimum path-length problems [172]. <p> Mean-squared error and rate-distortion metrics can be applied in this framework <ref> [41, 60, 134] </ref>. Computational cost of global search The globally optimum segmentation is simply the segmentation which minimizes the metric D (). Obviously, this minimization can be arrived at by a globally exhaustive search in which the metric is computed for every possible segmentation in turn. <p> In such cases, the algorithm is not guaranteed to find the globally optimal segmentation; in practice, however, the effect is negligible, so the dynamic segmentations can be justifiably referred to as optimal <ref> [41] </ref>. A further issue to note is that the dynamic segmentation method, as described, considers the entire signal before a final decision is made regarding the segmentation; in this form, it is only suitable for off-line computation. <p> Adaptive wavelet packets Early applications of dynamic programming to signal modeling involved models based on wavelet packets. In <ref> [41] </ref>, the best wavelet packet in a rate-distortion sense is chosen for the model for each segment; in [60], dynamic segmentation is added to allow for localization of transients. A similar technique was considered in [176]. <p> Examples include best basis methods and adaptive wavelet packets, where the overcomplete dictionary consists of a collection of bases; a basis for a signal expansion is chosen from the set of bases according to a metric such as entropy or rate-distortion <ref> [40, 41, 60] </ref>. In this chapter, signal decomposition using more general overcomplete sets is considered.
Reference: [42] <author> S. Chen, D. Donoho, and M. Saunders, </author> <title> "Atomic decomposition by basis pursuit," </title> <type> Tech. Rep. 479, </type> <institution> Stanford University, </institution> <month> February </month> <year> 1996. </year> <note> Available at play-fair.stanford.edu. </note>
Reference-contexts: This shortcoming results from the attempt to model arbitrary signals in terms of a limited and fixed set of functions. To overcome the difficulties of basis expansions, signals can instead be modeled using an overcomplete set of atoms that exhibits a wide range of time-frequency behaviors <ref> [38, 68, 42, 43, 211] </ref>. Such overcomplete expansions allow for compact representation of arbitrary signals for the sake of compression or analysis [38, 92]. <p> In this chapter, signal decomposition using more general overcomplete sets is considered. Such approaches can be roughly grouped into two categories: parallel methods such as the method of frames [63, 70], basis pursuit <ref> [42, 43] </ref>, and FOCUSS [68, 67], in which computation of the various expansion components is coupled; and, sequential methods such as matching pursuit and its variations [38, 68, 211, 212, 213, 214], in which models are computed one component at a time. <p> Methods of the latter type tend to be computationally costly and to lack an effective successive refinement framework <ref> [42, 67] </ref>. 6.1.3 Signal-Adaptive Parametric Models The set of expansion coefficients and functions in Equation (6.1) provides a model of the signal. If the model is compact or sparse, the decomposition indicates fundamental signal features and is useful for analysis and coding. <p> translation: g fs;!;t g (t) = p g n t This definition can be extended to discrete time by a sampling argument as in [38]; fundamentally, the extension simply indicates that Gabor atoms can be represented in discrete 1 Atoms corresponding to wavelet and cosine packets have also been considered <ref> [42, 212] </ref>. 199 derived from a symmetric window by scaling, modulation, and translation operations as described in Equation (6.39). time as g fs;!;t g [n] = f s [n t 0 ]e j!(nt ) ; (6.40) where f s [n] is a unit-norm window function supported on a scale s.
Reference: [43] <author> S. Chen and D. Donoho, </author> <title> "Basis pursuit," </title> <booktitle> in Proceedings of the Twenty-Eighth Asilo-mar Conference on Signals, Systems and Computers, </booktitle> <volume> vol. 1, </volume> <pages> pp. 41-44, </pages> <month> November </month> <year> 1994. </year> <month> 246 </month>
Reference-contexts: This shortcoming results from the attempt to model arbitrary signals in terms of a limited and fixed set of functions. To overcome the difficulties of basis expansions, signals can instead be modeled using an overcomplete set of atoms that exhibits a wide range of time-frequency behaviors <ref> [38, 68, 42, 43, 211] </ref>. Such overcomplete expansions allow for compact representation of arbitrary signals for the sake of compression or analysis [38, 92]. <p> In this chapter, signal decomposition using more general overcomplete sets is considered. Such approaches can be roughly grouped into two categories: parallel methods such as the method of frames [63, 70], basis pursuit <ref> [42, 43] </ref>, and FOCUSS [68, 67], in which computation of the various expansion components is coupled; and, sequential methods such as matching pursuit and its variations [38, 68, 211, 212, 213, 214], in which models are computed one component at a time.
Reference: [44] <author> B. Natarajan, </author> <title> "Filtering random noise from deterministic signals via data compression," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 43, </volume> <pages> pp. 2595-2605, </pages> <month> November </month> <year> 1995. </year>
Reference: [45] <author> S. F. Boll, </author> <title> "Suppression of acoustic noise in speech using spectral subtraction," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 27, </volume> <pages> pp. 113-120, </pages> <month> April </month> <year> 1979. </year>
Reference: [46] <author> D. L. Donoho, </author> <title> "De-noising by soft-thresholding," </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 41, </volume> <pages> pp. 613-627, </pages> <month> May </month> <year> 1995. </year>
Reference: [47] <author> J. Berger and C. Nichols, </author> <title> "Brahms at the piano: An analysis of data from the Brahms cylinder," </title> <journal> Leonardo Music Journal, </journal> <volume> vol. 4, </volume> <pages> pp. 23-30, </pages> <year> 1994. </year>
Reference: [48] <author> J. Berger, R. Coifman, and M. Goldberg, </author> <title> "Removing noise from music using local trigonometric bases and wavelet packets," </title> <journal> Journal of the Audio Engineering Society, </journal> <volume> vol. 42, </volume> <pages> pp. 808-818, </pages> <month> October </month> <year> 1994. </year>
Reference: [49] <author> S. G. Chang, B. Yu, and M. Vetterli, </author> <title> "Image denoising via lossy compression and wavelet thresholding," </title> <booktitle> in Proceedings of the International Conference on Image Processing, </booktitle> <volume> vol. 1, </volume> <pages> pp. 604-607, </pages> <month> October </month> <year> 1997. </year>
Reference: [50] <author> D. A. Berkeley and O. M. Mitchell, </author> <title> "Seeking the ideal in "hands-free" telephony," </title> <journal> Bell Laboratories Record, </journal> <volume> vol. 52, </volume> <pages> pp. 318-325, </pages> <month> November </month> <year> 1974. </year>
Reference: [51] <author> O. M. Mitchell and D. A. </author> <title> Berkeley, "Reduction of long-time reverberation by a center-clipping process," </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> vol. 47, </volume> <editor> p. </editor> <volume> 84, </volume> <year> 1970. </year>
Reference: [52] <author> J. Benesty, D. R. Morgan, and M. M. Sondhi, </author> <title> "A better understanding and an improved solution to the problems of stereophonic acoustic echo cancellation," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 1, </volume> <pages> pp. 303-306, </pages> <month> April </month> <year> 1997. </year>
Reference: [53] <author> M. M. Sonhdi, </author> <title> "New methods of pitch extraction," </title> <journal> IEEE Transactions on Audio and Electroacoustics, </journal> <volume> vol. 16, </volume> <pages> pp. 262-266, </pages> <month> June </month> <year> 1968. </year>
Reference-contexts: This issue has been explored most extensively in the speech and audio processing communities <ref> [1, 53, 196, 197, 198] </ref>; the terminology is thus taken from these fields, but the methods apply to any pseudo-periodic signals. <p> Various fixes have been proposed to account for these problems; for instance, based on the a priori knowledge that a typical musical signal does not have impulsive pitch discontinuities, a median filter can be applied to the pitch estimates to remove outliers and provide a more robust estimate <ref> [1, 53, 197] </ref>. For a more detailed discussion of pitch detection algorithms, the reader is referred to [1, 53, 196]. <p> For a more detailed discussion of pitch detection algorithms, the reader is referred to <ref> [1, 53, 196] </ref>. For the purposes of this chapter, it is assumed that a reliable pitch detection algorithm is available, and that the algorithm is capable of acknowledging, perhaps according to some heuristic threshold, when no pitch can be reasonably assessed to the signal.
Reference: [54] <author> P. Frampton, </author> <title> Frampton Comes Alive! A & M Records, </title> <publisher> Inc., </publisher> <year> 1976. </year>
Reference-contexts: Such cross-synthesis has been experimented with in music recording and performance; one of the early examples of cross-synthesis in popular music, mentioned in Chapter 1, is the cross-synthesized guitar in <ref> [54] </ref>, in which the signal from an electric guitar pickup is used as an excitation for a vocal tract filter, resulting in a guitar sound with a speech-like formant structure, the percept of which is a "talking" guitar. Parametric representations enable a wide class of cross-synthesis modifications.
Reference: [55] <author> J. Chowning, </author> <title> "The synthesis of complex audio spectra by means of frequency modulation," </title> <journal> Journal of the Audio Engineering Society, </journal> <volume> vol. 21, </volume> <pages> pp. 46-54, </pages> <month> September </month> <year> 1973. </year>
Reference: [56] <author> W. B. Kleijn, </author> <title> "Encoding speech using prototype waveforms," </title> <journal> IEEE Transactions on Speech and Audio Processing, </journal> <volume> vol. 1, </volume> <pages> pp. 386-399, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: In this chapter, a pitch-synchronous signal representation proposed in [195] is considered; similar representations have been applied in prototype waveform speech coders <ref> [56] </ref>. This pitch-dependent framework leads to simple sinusoidal models in which line tracking and peak detection are unnecessary because of the harmonic structure; furthermore, the representation leads to wavelet-based models that are more appropriate for pseudo-periodic signals than the lowpass-plus-details model of the standard discrete wavelet transform.
Reference: [57] <author> R. J. McAulay and T. F. Quatieri, </author> <title> "Speech analysis/synthesis based on a sinusoidal representation," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 34, </volume> <pages> pp. 744 - 754, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: introduction to the discussion of the sinusoidal model. 2.1 The Sinusoidal Signal Model A variety of sinusoidal modeling techniques have been explored in the literature <ref> [106, 96, 95, 98, 57, 36, 102, 101, 97] </ref>. These methods share fundamental common points, but also have substantial but sometimes subtle differences. <p> These methods share fundamental common points, but also have substantial but sometimes subtle differences. For the sake of simplicity, this treatment adheres primarily to the approaches presented in the early literature on sinusoidal modeling <ref> [57, 36] </ref>, and not on the many variations that have since been proposed [103, 97, 98]; comments on some other techniques such as [101, 107] are indeed included, but these inclusions are limited to techniques that are directly concerned with the modeling issues at hand. <p> It should be noted that the issues to be discussed herein apply to sinusoidal modeling in general; their relevance is not limited by the adherence to the particular methods of <ref> [57, 36] </ref>. <p> As mentioned, these parameters are assumed to be slowly varying with respect to the sample rate, so the estimation process can be reliably carried out at a subsampled rate. In <ref> [57, 36] </ref>, this analysis is done using a short-time Fourier transform followed by spectral peak picking; this procedure was conceptually motivated in the preceding discussion of the STFT. <p> Since Hanning and other similarly constructed windows have been commonly used, it has become a heuristic in STFT analysis to use windows of length two to three times the signal period. Modeling arbitrary signals Analysis based on the DFT has been used in numerous sinusoidal modeling applications <ref> [57, 36, 100] </ref>. These methods incorporate the constraints discussed above for resolution of harmonics and have been successfully applied to modeling signals with harmonic structure. <p> Line tracking can be carried out in a simple successive manner by associating the q-th parameter set in frame i, namely fA q;i ; ! q;i ; q;i g, to the set in frame i + 1 with frequency closest to ! q;i <ref> [57] </ref>. The tracking starts by making such an association for the pair of parameter sets with the smallest frequency difference across all possible pairs; frequency difference is used as the metric here, but other cost functions, perhaps including amplitude or a predicted rate of frequency change, are of course plausible. <p> Another observation is that line tracking can be aided by considering harmonicity; if the partials are roughly harmonic, the data sets can be coupled more readily than in the general case <ref> [57, 36] </ref>. A number of more complex methods have been explored in the literature. <p> Typically, interpolation is done using low-order polynomial models such as linear amplitude and cubic total phase; the specific approach of <ref> [57] </ref> is presented here, but other interpolation methods have been considered [36, 107, 148, 149, 150]. <p> fi q;i [n] = fi q;i + ! q;i n + ff q;i n 2 + fi q;i n 3 ; (2.83) where fi and ! enforce phase and frequency matching constraints at the frame boundaries, and ff and fi are chosen the make the total phase progression maximally smooth <ref> [57] </ref>. Such phase and frequency matching constraints are explored in greater detail in Section 2.5. Interpolation of the phase parameter is clearly more complex than the amplitude interpolation. For efficient synthesis, then, it is of interest to consider more simple models of the phase. <p> This approach provides various computational advantages over general time-domain synthesis [102, 132]. Frequency-domain synthesis was described in <ref> [57, 150, 151] </ref> and more fully presented in [102]. In this section, the algorithm in [102] is explored in detail. 2.5.1 The Algorithm The frequency-domain synthesis algorithm is fundamentally based on the relationship between the DTFT and the DFT and the resulting implications for representing short-time sinusoids. <p> The frequency resolution is thus limited not by the size of the synthesis IDFT but by the oversampling of the motif; in some other incarnations of frequency-domain synthesis, large IDFTs are required to achieve accurate frequency resolution <ref> [57, 150, 151] </ref>. In this algorithm, arbitrary frequency resolution can be achieved by increasing the factor , provided that enough memory is available for storage of the motif. <p> Figure 3.1 depicts a typical partial A q [t] cos fi q [t] synthesized using linear amplitude interpolation and cubic total phase as formulated in 94 partial A q [n] (radians) Time (samples) envelope (b) and cubic total phase (c). <ref> [57] </ref>. In the next section, this example is used to indicate the aforementioned granular interpretation of the sinusoidal model. The atomic interpretation of the sinusoidal model stems from considering the frame-to-frame nature of the approach.
Reference: [58] <author> G. Strang, </author> <title> Linear Algebra And Its Applications. </title> <publisher> Harcourt Brace Jovanovich, 3rd ed., </publisher> <year> 1988. </year> <month> 247 </month>
Reference-contexts: The SVD and the pseudo-inverse One solution to arbitrary inverse problems can be arrived at using the singular value decomposition of the dictionary matrix, from which the pseudo-inverse D + can be derived <ref> [58] </ref>. The coefficient vector ff = D + x has the minimum two-norm of all solutions [58]. This minimization of the two-norm is inappropriate for deriving signal models, however, in that it tends to spread energy throughout all of the elements of ff. Such spreading undermines the goal of compaction. <p> The SVD and the pseudo-inverse One solution to arbitrary inverse problems can be arrived at using the singular value decomposition of the dictionary matrix, from which the pseudo-inverse D + can be derived <ref> [58] </ref>. The coefficient vector ff = D + x has the minimum two-norm of all solutions [58]. This minimization of the two-norm is inappropriate for deriving signal models, however, in that it tends to spread energy throughout all of the elements of ff. Such spreading undermines the goal of compaction. An example of the dispersion of the SVD approach was given earlier in Figure 1.5.
Reference: [59] <author> H. S. Malvar and D. H. Staelin, </author> <title> "The LOT: Transform coding without blocking effects," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 37, </volume> <pages> pp. 553 - 559, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Then, the subband signals are real-valued, which is certainly desirable in some cases; here, however, it is problematic since the phase provided by the 47 complex filter bank is important for sinusoidal modeling as will be seen. While cosine-modulated filter banks have interesting and significant properties <ref> [2, 20, 4, 12, 59] </ref>, they are an offshoot of the progression of ideas that leads to the sinusoidal model and will not be considered in depth here because of this phase problem. <p> In cases where discontinuities across frame boundaries may be objectionable, the candidate models tend to have dependencies on adjacent frames; for instance, in the image processing application, where discontinuities result in blockiness, the candidate models are lapped orthogonal transforms which reduce the blocking artifacts incurred in the quantization <ref> [59, 177] </ref>. Because of the overlap, as mentioned before, the dynamic algorithm is not guaranteed to find the globally optimal model, but in practice the effect of the dependency is negligible.
Reference: [60] <author> C. Herley, J. Kovacevic, K. Ramchandran, and M. Vetterli, </author> <title> "Tilings of the time-frequency plane: Construction of arbitrary orthogonal bases and fast tiling algorithms," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 41, </volume> <pages> pp. 3341-3359, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Arbitrary tree-structured filter banks that achieve perfect reconstruction can be constructed by iterating two-channel perfect reconstruction filter banks; indeed, the filter trees can be made to adapt to model nonstationary input signals while still satisfying the reconstruction constraint <ref> [60] </ref>. In this treatment, the primary issue of interest is the manner in which iteration of two-channel subsampled filter banks leads to multiresolution. <p> The brief description of multiresolution in tree-structured filter banks suggests why such methods might prove useful for processing arbitrary signals, especially if the filter bank is made adaptive; application examples include compression <ref> [41, 60] </ref> and spectral estimation [161]. Rather than focusing on such arbitrary tree-structured filter banks here, however, additional developments of the multiresolution concept will be formulated for the specific case of the discrete wavelet transform. <p> If the metric is additive and independent across segments, however, the computational cost can be substantially reduced using a dynamic program. This approach has been applied to wavelet packet and LPC models <ref> [41, 60, 134] </ref>; after a brief review of dynamic programming and the relevant literature, dynamic segmentation for sinusoidal modeling is considered. Dynamic programming Dynamic programming was first introduced for solving minimum path-length problems [172]. <p> Mean-squared error and rate-distortion metrics can be applied in this framework <ref> [41, 60, 134] </ref>. Computational cost of global search The globally optimum segmentation is simply the segmentation which minimizes the metric D (). Obviously, this minimization can be arrived at by a globally exhaustive search in which the metric is computed for every possible segmentation in turn. <p> Adaptive wavelet packets Early applications of dynamic programming to signal modeling involved models based on wavelet packets. In [41], the best wavelet packet in a rate-distortion sense is chosen for the model for each segment; in <ref> [60] </ref>, dynamic segmentation is added to allow for localization of transients. A similar technique was considered in [176]. Arbitrary models In addition to the wavelet packet algorithms described, dynamic segmentation and model selection has been applied to image compression [177] and linear predictive coding [134]. <p> Examples include best basis methods and adaptive wavelet packets, where the overcomplete dictionary consists of a collection of bases; a basis for a signal expansion is chosen from the set of bases according to a metric such as entropy or rate-distortion <ref> [40, 41, 60] </ref>. In this chapter, signal decomposition using more general overcomplete sets is considered.
Reference: [61] <author> K. Dobson et al., </author> <title> "A low complexity wavelet based audio compression method," </title> <booktitle> in Proceedings of the Data Compression Conference, </booktitle> <address> p. 433, </address> <month> March </month> <year> 1996. </year>
Reference: [62] <author> M. Goodwin and M. Vetterli, </author> <title> "Atomic decompositions of audio signals," </title> <booktitle> in Proceedings of the IEEE ASSP Workshop on Applications of Signal Processing to Audio and Acoustics, </booktitle> <month> October </month> <year> 1997. </year>
Reference: [63] <author> I. Daubechies, </author> <title> Ten Lectures on Wavelets. </title> <address> Philadelphia, PA: </address> <institution> Society for Industrial and Applied Mathematics, </institution> <year> 1992. </year>
Reference-contexts: In this chapter, signal decomposition using more general overcomplete sets is considered. Such approaches can be roughly grouped into two categories: parallel methods such as the method of frames <ref> [63, 70] </ref>, basis pursuit [42, 43], and FOCUSS [68, 67], in which computation of the various expansion components is coupled; and, sequential methods such as matching pursuit and its variations [38, 68, 211, 212, 213, 214], in which models are computed one component at a time.
Reference: [64] <author> Z. Czetkovic, </author> <title> Overcomplete Expansions for Digital Signal Processing. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, </institution> <month> December </month> <year> 1995. </year>
Reference-contexts: The generality of this constraint is an example of the design flexibility that results from using oversampled or overcomplete approaches <ref> [70, 64, 125] </ref>. <p> Quantization effects can also be reduced by oversampling; one advantage of overcomplete representations is that they exhibit a robustness to quantization noise that is proportional to the redundancy of the representation <ref> [70, 64, 92, 125] </ref>. Time-frequency localization As discussed above, the design of STFT filter banks is extremely limited in the critically sampled case. The only real-valued prototype windows that lead to orthogonal perfect reconstruction filter banks are rectangular windows [2].
Reference: [65] <author> D. Donoho and I. Johnstone, </author> <title> "Ideal denoising in an orthonormal basis chosen from a library of bases," </title> <type> Tech. Rep. 461, </type> <institution> Stanford University, </institution> <month> September </month> <year> 1994. </year> <note> Available at playfair.stanford.edu. </note>
Reference: [66] <author> S. Mallat, D. Donoho, and A. Willsky, </author> <title> "Best basis algorithm for signal enhancement," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 3, </volume> <pages> pp. 1561-1564, </pages> <month> May </month> <year> 1995. </year>
Reference: [67] <author> B. Rao, </author> <title> "Analysis and extensions of the FOCUSS algorithm," </title> <booktitle> in Conference Record of the Thirtieth Asilomar Conference on Signals, Systems, and Computers, </booktitle> <volume> vol. 2, </volume> <pages> pp. 1218-1223, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: In this chapter, signal decomposition using more general overcomplete sets is considered. Such approaches can be roughly grouped into two categories: parallel methods such as the method of frames [63, 70], basis pursuit [42, 43], and FOCUSS <ref> [68, 67] </ref>, in which computation of the various expansion components is coupled; and, sequential methods such as matching pursuit and its variations [38, 68, 211, 212, 213, 214], in which models are computed one component at a time. <p> Methods of the latter type tend to be computationally costly and to lack an effective successive refinement framework <ref> [42, 67] </ref>. 6.1.3 Signal-Adaptive Parametric Models The set of expansion coefficients and functions in Equation (6.1) provides a model of the signal. If the model is compact or sparse, the decomposition indicates fundamental signal features and is useful for analysis and coding.
Reference: [68] <author> J. Adler, B. Rao, and K. Kreutz-Delgado, </author> <title> "Comparison of basis selection methods," </title> <booktitle> in Conference Record of the Thirtieth Asilomar Conference on Signals, Systems, and Computers, </booktitle> <volume> vol. 1, </volume> <pages> pp. 252-257, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: This shortcoming results from the attempt to model arbitrary signals in terms of a limited and fixed set of functions. To overcome the difficulties of basis expansions, signals can instead be modeled using an overcomplete set of atoms that exhibits a wide range of time-frequency behaviors <ref> [38, 68, 42, 43, 211] </ref>. Such overcomplete expansions allow for compact representation of arbitrary signals for the sake of compression or analysis [38, 92]. <p> In this chapter, signal decomposition using more general overcomplete sets is considered. Such approaches can be roughly grouped into two categories: parallel methods such as the method of frames [63, 70], basis pursuit [42, 43], and FOCUSS <ref> [68, 67] </ref>, in which computation of the various expansion components is coupled; and, sequential methods such as matching pursuit and its variations [38, 68, 211, 212, 213, 214], in which models are computed one component at a time. <p> Such approaches can be roughly grouped into two categories: parallel methods such as the method of frames [63, 70], basis pursuit [42, 43], and FOCUSS [68, 67], in which computation of the various expansion components is coupled; and, sequential methods such as matching pursuit and its variations <ref> [38, 68, 211, 212, 213, 214] </ref>, in which models are computed one component at a time. All of these methods can be interpreted as approaches to solving inverse problems. <p> In the literature, speech coding using orthogonal matching pursuit has been discussed [220]. Furthermore, a number of refinements of the algorithm have been proposed and explored <ref> [68, 214] </ref>. Such refinements basically involve different ways in which orthogonality is imposed or exploited; for instance, orthogonal components can be evaluated simultaneously as in basis expansions [214]. The following section discusses a method which employs the Gram-Schmidt procedure in a different way than the backward pursuit described above. <p> Useful predictive comparisons of the algorithms can be carried out using ensemble results based on random dictionaries <ref> [68] </ref>. In the preceding paragraph, as in most discussions of signal modeling, comparisons between models are phrased in terms of the amount of information required to 198 describe a certain model, i.e. the compaction, and the approximation error of the model.
Reference: [69] <author> B. Natarajan, </author> <title> "Sparse approximate solutions to linear systems," </title> <journal> SIAM Journal on Computing, </journal> <volume> vol. 24, </volume> <pages> pp. 227-234, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: An SVD-based expansion is by nature not sparse, and thresholding small expansion coefficients to improve the sparsity is not a useful approach <ref> [215, 69] </ref>. A more appropriate paradigm for deriving an overcomplete expansion is to apply an algorithm specifically designed to arrive at sparse solutions. Because of the complexity of the search, however, it is not computationally feasible to derive an optimal sparse expansion that perfectly models a signal. <p> A dictionary can be likened to the matrix D in Equation (6.2) by considering the atoms to be the matrix columns; then, matching pursuit can be interpreted as an approach for computing sparse approximate solutions to inverse problems <ref> [69, 215] </ref>. For an overcomplete dictionary, the linear system is underdetermined and an infinite number of solutions exist. As discussed in Section 6.1.2, sparse approximate solutions are useful for signal analysis, compression, and enhancement. <p> As discussed in Section 6.1.2, sparse approximate solutions are useful for signal analysis, compression, and enhancement. Since such solutions are not provided by traditional linear methods such as the SVD, a nonlinear approximation paradigm such as matching pursuit is called for <ref> [38, 215, 69, 92] </ref>. 6.2.1 One-Dimensional Pursuit The greedy iteration in the matching pursuit algorithm is carried out as follows. First, the atom that best approximates the signal is chosen, where the two-norm is used as the approximation metric because of its mathematical convenience. <p> Furthermore, such greedy approximation methods have been considered in linear algebra applications for some time <ref> [69, 219] </ref>. 6.2.2 Subspace Pursuit Though searching for the optimal high-dimensional subspace is not reasonable, it is worthwhile to consider the related problem of finding an optimal low-dimension subspace at each iteration of the pursuit, especially if the subspaces under consideration exhibit a simplifying structure. <p> Matching pursuit is thus categorized as a greedy algorithm. It is well known that such greedy algorithms, when applied to overcomplete dictionaries, do not lead to optimal approximations, i.e. optimal compact models; however, greedy approaches are justified given the complexity of optimal approximation <ref> [39, 69] </ref>. Furthermore, it should be noted as in Section 6.1.2 that the use of a greedy algorithm inherently leads to successive refinement, which is a desirable property in signal models.
Reference: [70] <author> Z. Czetkovic and M. Vetterli, </author> <title> "Oversampled filter banks," </title> <journal> IEEE Transactions on Signal Processing, </journal> <note> To appear. </note>
Reference-contexts: The generality of this constraint is an example of the design flexibility that results from using oversampled or overcomplete approaches <ref> [70, 64, 125] </ref>. <p> Quantization effects can also be reduced by oversampling; one advantage of overcomplete representations is that they exhibit a robustness to quantization noise that is proportional to the redundancy of the representation <ref> [70, 64, 92, 125] </ref>. Time-frequency localization As discussed above, the design of STFT filter banks is extremely limited in the critically sampled case. The only real-valued prototype windows that lead to orthogonal perfect reconstruction filter banks are rectangular windows [2]. <p> In this chapter, signal decomposition using more general overcomplete sets is considered. Such approaches can be roughly grouped into two categories: parallel methods such as the method of frames <ref> [63, 70] </ref>, basis pursuit [42, 43], and FOCUSS [68, 67], in which computation of the various expansion components is coupled; and, sequential methods such as matching pursuit and its variations [38, 68, 211, 212, 213, 214], in which models are computed one component at a time.
Reference: [71] <author> D. </author> <title> Gabor, </title> <journal> "Theory of communication," Journal of the Institution of Electrical Engineers, </journal> <volume> vol. 93, </volume> <pages> pp. 429-457, </pages> <month> November </month> <year> 1946. </year>
Reference-contexts: In the early literature on time-frequency transforms, signal analysis-synthesis based on Gaussian windows was proposed by Gabor <ref> [71, 72] </ref>; given this historical foundation, the STFT is sometimes referred to as a Gabor transform [2]. <p> Atoms based on damped sinusoids are shown to be more effective than symmetric Gabor atoms for representing transient signal behavior such as attacks in music. 6.1 Atomic Decompositions Time-frequency atomic signal representations have been of growing interest since their introduction by Gabor several decades ago <ref> [71, 72] </ref>. The fundamental notions of atomic modeling are that a signal can be decomposed into elementary functions that are localized in time-frequency and that such decompositions are useful for applications such as signal analysis and coding. This section provides an overview of the computation and properties of atomic models. <p> Such localized time-frequency atoms were introduced by Gabor from a theoretical standpoint and according to psychoacoustic motivations <ref> [71, 72] </ref>. 6.3.1 Gabor Atoms The literature on matching pursuit has focused on applications involving dictionaries of Gabor atoms since these are appropriate expansion functions for general time-frequency signal models [38]. 1 In continuous time, such atoms are derived from a single unit-norm window function g (t) by scaling, modulation, and
Reference: [72] <author> D. Gabor, </author> <title> "Acoustical quanta and the theory of hearing," </title> <journal> Nature, </journal> <volume> vol. 159, </volume> <pages> pp. 591-594, </pages> <month> May </month> <year> 1947. </year>
Reference-contexts: In the early literature on time-frequency transforms, signal analysis-synthesis based on Gaussian windows was proposed by Gabor <ref> [71, 72] </ref>; given this historical foundation, the STFT is sometimes referred to as a Gabor transform [2]. <p> Atoms based on damped sinusoids are shown to be more effective than symmetric Gabor atoms for representing transient signal behavior such as attacks in music. 6.1 Atomic Decompositions Time-frequency atomic signal representations have been of growing interest since their introduction by Gabor several decades ago <ref> [71, 72] </ref>. The fundamental notions of atomic modeling are that a signal can be decomposed into elementary functions that are localized in time-frequency and that such decompositions are useful for applications such as signal analysis and coding. This section provides an overview of the computation and properties of atomic models. <p> Such localized time-frequency atoms were introduced by Gabor from a theoretical standpoint and according to psychoacoustic motivations <ref> [71, 72] </ref>. 6.3.1 Gabor Atoms The literature on matching pursuit has focused on applications involving dictionaries of Gabor atoms since these are appropriate expansion functions for general time-frequency signal models [38]. 1 In continuous time, such atoms are derived from a single unit-norm window function g (t) by scaling, modulation, and
Reference: [73] <author> W. F. </author> <title> Heisenberg, Collected Works. </title> <editor> W. Blum, H.-P. Durr, and H. Rechenberg, eds. </editor> <publisher> Berlin: Springer-Verlag, </publisher> <year> 1984. </year> <month> 248 </month>
Reference: [74] <author> N. Wiener, </author> <title> "Spatio-temporal continuity, quantum theory, and music," in The Concepts of Space and Time (M. </title> <publisher> Capek, ed.), </publisher> <pages> pp. 539-546, </pages> <address> Boston, MA: D. </address> <publisher> Reidel Publishing Company, </publisher> <year> 1975. </year>
Reference: [75] <author> L. Cohen, </author> <title> "The uncertainty principle in signal analysis," </title> <booktitle> in Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis, </booktitle> <pages> pp. 182-185, </pages> <month> October </month> <year> 1994. </year>
Reference: [76] <author> D. L. Jones and T. W. Parks, </author> <title> "Generation and combination of grains for music synthesis," </title> <journal> Computer Music Journal, </journal> <volume> vol. 12, </volume> <pages> pp. 27-34, </pages> <month> Summer </month> <year> 1988. </year>
Reference: [77] <author> B. Truax, </author> <title> "Discovering inner complexity: Time shifting and transposition with a real-time granulation technique," </title> <journal> Computer Music Journal, </journal> <volume> vol. 18, </volume> <pages> pp. 38-48, </pages> <month> Summer </month> <year> 1994. </year>
Reference: [78] <author> B. Truax, </author> <title> "Real-time granular synthesis with a digital signal processor," </title> <journal> Computer Music Journal, </journal> <volume> vol. 12, </volume> <pages> pp. 14-26, </pages> <month> Summer </month> <year> 1988. </year>
Reference: [79] <author> S. Mallat, </author> <title> "A theory for multiresolution signal decomposition: The wavelet representation," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 11, </volume> <pages> pp. 674-693, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Here, the issue is developed further; this development is based on the discrete wavelet transform, which is inherently connected to the notion of multiresolution <ref> [2, 79] </ref>. 3.2.1 Wavelets and Filter Banks Wavelets and multiresolution are intrinsically related.
Reference: [80] <author> S. Mann and S. Haykin, </author> <title> "'Chirplets' and 'warblets': Novel time-frequency methods," </title> <journal> Electronics Letters, </journal> <volume> vol. 28, </volume> <pages> pp. 114-116, </pages> <month> January 16 </month> <year> 1992. </year>
Reference: [81] <author> R. G. Baraniuk and D. L. Jones, </author> <title> "Shear madness: New orthonormal bases and frames using chirp functions," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 41, </volume> <pages> pp. 3543-3549, </pages> <month> December </month> <year> 1993. </year>
Reference: [82] <author> G. Evangelista, </author> <title> "The discrete-time warped frequency wavelet transform," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 3, </volume> <pages> pp. 2105-2108, </pages> <month> April </month> <year> 1997. </year>
Reference: [83] <author> L. Cohen, </author> <title> "Time-frequency distributions a review," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 77, </volume> <pages> pp. 941-981, </pages> <month> July </month> <year> 1989. </year>
Reference: [84] <author> S. Kadambe and G. F. Boudreaux-Bartels, </author> <title> "A comparison of the existence of 'cross terms' in the Wigner distribution and the squared magnitude of the wavelet transform and the short time Fourier transform," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 40, </volume> <pages> pp. 2498-2517, </pages> <month> October </month> <year> 1992. </year>
Reference: [85] <author> F. Auger and P. Flandrin, </author> <title> "Improving the readibility of time-frequency and time-scale representations by the reassignment method," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 43, </volume> <pages> pp. 1068-1089, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Such techniques start with a standard distribution and apply various refinements in order to achieve compaction in the time-frequency plane; this improves the readability of the distribution since the nonlinear refinements lead to enhancement of the peaks in the representation and attenuation of the cross terms <ref> [85] </ref>. In cases where the resources are available to derive a dispersed but exact overcomplete expansion using the SVD pseudo-inverse (or some other method), some form of adaptive refinement may prove useful for improving the compaction without sacrificing the accuracy of the expansion.
Reference: [86] <author> W. Pielemeier and G. Wakefield, </author> <title> "A high resolution time-frequency representation for musical instrument signals," </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> vol. 99, </volume> <pages> pp. 2382-2396, </pages> <month> April </month> <year> 1996. </year>
Reference: [87] <author> W. Krattenthaler and F. Hlawatsch, </author> <title> "Time-frequency design and processing of signals via smoothed Wigner distributions," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 41, </volume> <pages> pp. 278-287, </pages> <month> January </month> <year> 1993. </year> <month> 249 </month>
Reference: [88] <author> F. Plante, G. Meyer, and W. Ainsworth, </author> <title> "Speech signal analysis with reallocated spectrogram," </title> <booktitle> in Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis, </booktitle> <pages> pp. 640-643, </pages> <month> October </month> <year> 1994. </year>
Reference: [89] <author> A. Bultan, </author> <title> "A four-parameter atomic decomposition of chirplets," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 5, </volume> <pages> pp. 3625-3628, </pages> <month> April </month> <year> 1997. </year>
Reference: [90] <author> E. Moulines and J. Laroche, </author> <title> "Non-parametric techniques for pitch-scale and time-scale modification of speech," </title> <journal> Speech Communication, </journal> <volume> vol. 16, </volume> <pages> pp. 175-205, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: Time-scale modifications can also be carried out using approaches traditionally referred to as nonparametric <ref> [90] </ref>. These involve either STFT magnitude modification followed by phase estimation as discussed earlier, or analyzing the signal for regions, e.g. pitch periods, which can be spliced out of the signal for time-scale compression or repeated for time-scale expansion. <p> Alternatively, the period lengths can be equalized by zero-padding all of the period signals to the maximum period length [195] or by viewing 160 each period as an impulse response and carrying out an extension procedure such as in pitch-synchronous overlap-add methods <ref> [90] </ref>. These approaches, however, do not yield the same smoothness as resampling; they do not necessarily preserve the zero-crossing synchronization and discontinuities may result in the reconstruction. A second issue concerns the unpitched regions.
Reference: [91] <author> M. Goodwin and M. Vetterli, </author> <title> "Time-frequency signal models for music analysis, transformation, and synthesis," </title> <booktitle> in Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis, </booktitle> <pages> pp. 133-136, </pages> <month> June </month> <year> 1996. </year>
Reference: [92] <author> V. Goyal, M. Vetterli, and N. Thao, </author> <title> "Quantized overcomplete expansions in &lt; n : Analysis, synthesis and algorithms," </title> <journal> IEEE Transactions on Information Theory, </journal> <note> To appear. </note>
Reference-contexts: Quantization effects can also be reduced by oversampling; one advantage of overcomplete representations is that they exhibit a robustness to quantization noise that is proportional to the redundancy of the representation <ref> [70, 64, 92, 125] </ref>. Time-frequency localization As discussed above, the design of STFT filter banks is extremely limited in the critically sampled case. The only real-valued prototype windows that lead to orthogonal perfect reconstruction filter banks are rectangular windows [2]. <p> To overcome the difficulties of basis expansions, signals can instead be modeled using an overcomplete set of atoms that exhibits a wide range of time-frequency behaviors [38, 68, 42, 43, 211]. Such overcomplete expansions allow for compact representation of arbitrary signals for the sake of compression or analysis <ref> [38, 92] </ref>. With respect to the interpretation of signal modeling as an inverse problem, when the functions fd m [n]g constitute an overcomplete or redundant set (M &gt; N ), the dictionary matrix D is of rank N and the linear system in Equation (6.2) is underdetermined. <p> When a well-designed overcom-plete dictionary is used in matching pursuit, the nonlinear nature of the algorithm leads to compact signal-adaptive models <ref> [38, 211, 92] </ref>. A dictionary can be likened to the matrix D in Equation (6.2) by considering the atoms to be the matrix columns; then, matching pursuit can be interpreted as an approach for computing sparse approximate solutions to inverse problems [69, 215]. <p> As discussed in Section 6.1.2, sparse approximate solutions are useful for signal analysis, compression, and enhancement. Since such solutions are not provided by traditional linear methods such as the SVD, a nonlinear approximation paradigm such as matching pursuit is called for <ref> [38, 215, 69, 92] </ref>. 6.2.1 One-Dimensional Pursuit The greedy iteration in the matching pursuit algorithm is carried out as follows. First, the atom that best approximates the signal is chosen, where the two-norm is used as the approximation metric because of its mathematical convenience.
Reference: [93] <author> T. F. Quatieri and R. J. McAulay, </author> <title> "Speech transformations based on a sinusoidal representation," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 34, </volume> <pages> pp. 1449 - 1464, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: Since it describes the primary musical information about the signal in a simple, compact form, the parameterization provides not only a reasonable coding representation but also a framework for carrying out desirable modifications such as pitch-shifting, time-scaling, and a wide variety of spectral transformations such as cross-synthesis <ref> [93, 94, 36, 102, 103, 108] </ref>. 2.1.2 Deterministic-plus-Stochastic Decomposition The approximation symbol in Equation (2.1) is included to imply that the sum-of-partials model does not provide an exact reconstruction of the signal. <p> Here, modifications based on the sinusoidal model are dealt with more explicitly. Specifically, time-scaling, pitch-shifting, and cross-synthesis are considered. The treatment here is quite general; formalized details about modifications in a specific version of the sinusoidal model can be found in the literature <ref> [93, 101, 154, 94] </ref>.
Reference: [94] <author> T. F. Quatieri and R. J. McAulay, </author> <title> "Shape invariant time-scale and pitch modification of speech," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 40, </volume> <pages> pp. 497-510, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Since it describes the primary musical information about the signal in a simple, compact form, the parameterization provides not only a reasonable coding representation but also a framework for carrying out desirable modifications such as pitch-shifting, time-scaling, and a wide variety of spectral transformations such as cross-synthesis <ref> [93, 94, 36, 102, 103, 108] </ref>. 2.1.2 Deterministic-plus-Stochastic Decomposition The approximation symbol in Equation (2.1) is included to imply that the sum-of-partials model does not provide an exact reconstruction of the signal. <p> Here, modifications based on the sinusoidal model are dealt with more explicitly. Specifically, time-scaling, pitch-shifting, and cross-synthesis are considered. The treatment here is quite general; formalized details about modifications in a specific version of the sinusoidal model can be found in the literature <ref> [93, 101, 154, 94] </ref>.
Reference: [95] <author> J. S. Marques and L. B. Almeida, </author> <title> "Frequency-varying sinusoidal modeling of speech," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 37, </volume> <pages> pp. 763-765, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: introduction to the discussion of the sinusoidal model. 2.1 The Sinusoidal Signal Model A variety of sinusoidal modeling techniques have been explored in the literature <ref> [106, 96, 95, 98, 57, 36, 102, 101, 97] </ref>. These methods share fundamental common points, but also have substantial but sometimes subtle differences.
Reference: [96] <author> L. B. Almeida and F. M. Silva, </author> <title> "Variable-frequency synthesis: An improved harmonic coding scheme," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 2, </volume> <pages> pp. </pages> <address> 27.5.1-27.5.4, </address> <month> March </month> <year> 1984. </year>
Reference-contexts: introduction to the discussion of the sinusoidal model. 2.1 The Sinusoidal Signal Model A variety of sinusoidal modeling techniques have been explored in the literature <ref> [106, 96, 95, 98, 57, 36, 102, 101, 97] </ref>. These methods share fundamental common points, but also have substantial but sometimes subtle differences.
Reference: [97] <author> J. S. Marques and A. J. Abrantes, </author> <title> "Hybrid harmonic coding of speech at low bit-rates," </title> <journal> Speech Communication, </journal> <volume> vol. 14, </volume> <pages> pp. 231-247, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: introduction to the discussion of the sinusoidal model. 2.1 The Sinusoidal Signal Model A variety of sinusoidal modeling techniques have been explored in the literature <ref> [106, 96, 95, 98, 57, 36, 102, 101, 97] </ref>. These methods share fundamental common points, but also have substantial but sometimes subtle differences. <p> These methods share fundamental common points, but also have substantial but sometimes subtle differences. For the sake of simplicity, this treatment adheres primarily to the approaches presented in the early literature on sinusoidal modeling [57, 36], and not on the many variations that have since been proposed <ref> [103, 97, 98] </ref>; comments on some other techniques such as [101, 107] are indeed included, but these inclusions are limited to techniques that are directly concerned with the modeling issues at hand. <p> the discrete wavelet transform. 3.1 Atomic Interpretation of the Sinusoidal Model The partials in the sinusoidal model can be interpreted as expansion functions that comprise an additive decomposition of the signal; this perspective provides a conceptual framework for several considerations of sinusoidal modeling that have been presented in the literature <ref> [97, 159, 160] </ref>. With this notion as a starting point, the sinusoidal model is here interpreted as a time-frequency atomic decomposition. This interpretation sheds some light on the fundamental modeling issues, and indicates a connection between sinusoidal modeling and granular analysis-synthesis. <p> The voiced-unvoiced model, especially in the case of a mixed excitation, is similar to the deterministic-plus-stochastic sinusoidal model decomposition proposed in [36, 100] and explored further in <ref> [97, 110, 178, 109, 180] </ref>. The components in these latter models are concurrent in time; the models are thus capable of representing a wide variety of signals.
Reference: [98] <author> J. Laroche, Y. Stylianou, and E. Moulines, "HNM: </author> <title> A simple, efficient harmonic + noise model for speech," </title> <booktitle> in Proceedings of the IEEE ASSP Workshop on Applications of Signal Processing to Audio and Acoustics, </booktitle> <pages> pp. 169-172, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: introduction to the discussion of the sinusoidal model. 2.1 The Sinusoidal Signal Model A variety of sinusoidal modeling techniques have been explored in the literature <ref> [106, 96, 95, 98, 57, 36, 102, 101, 97] </ref>. These methods share fundamental common points, but also have substantial but sometimes subtle differences. <p> These methods share fundamental common points, but also have substantial but sometimes subtle differences. For the sake of simplicity, this treatment adheres primarily to the approaches presented in the early literature on sinusoidal modeling [57, 36], and not on the many variations that have since been proposed <ref> [103, 97, 98] </ref>; comments on some other techniques such as [101, 107] are indeed included, but these inclusions are limited to techniques that are directly concerned with the modeling issues at hand.
Reference: [99] <author> J. M. Kates, </author> <title> "Speech enhancement based on a sinusoidal model," </title> <journal> Journal of Speech and Hearing Research, </journal> <volume> vol. 37, </volume> <pages> pp. 449-464, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: In addition to denoising, the sinusoidal model has been used for speech enhancement and dynamic range compression. These topics are discussed in the literature <ref> [155, 99] </ref> 2.7.2 Time-Scaling and Pitch-Shifting In Section 1.5.1, it is proposed that signal modifications can be carried out by modifying the components of a model of the signal. The sinusoidal model is particularly amenable to this approach because the modifications of interest are easy to carry out on sinusoids.
Reference: [100] <author> X. Serra, </author> <title> A System for Sound Analysis/Transformation/Synthesis Based On A Deterministic Plus Stochastic Decomposition. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> October </month> <year> 1989. </year> <month> 250 </month>
Reference-contexts: Since these features are important for high-fidelity synthesis, an additional component is often included in the signal model to account for broadband processes: x [n] = ^x [n] + r [n] = d [n] + s [n]: (2.2) 35 The resultant deterministic-plus-stochastic decomposition was introduced in <ref> [36, 100] </ref> and has been discussed in several later efforts [109, 110]. <p> Then, the sinusoid can be identified if the shape of the window transform can be detected in the spectrum; the performance of such methods has been considered in the literature for the general case of multiple sinusoids in noise <ref> [122, 100, 133] </ref>. This matching approach is particularly applicable when a Gaussian window is used since the window transform is then simply a parabola in the log-magnitude spectrum; by fitting a parabola to the spectral data, the location of a peak can be estimated. <p> Since Hanning and other similarly constructed windows have been commonly used, it has become a heuristic in STFT analysis to use windows of length two to three times the signal period. Modeling arbitrary signals Analysis based on the DFT has been used in numerous sinusoidal modeling applications <ref> [57, 36, 100] </ref>. These methods incorporate the constraints discussed above for resolution of harmonics and have been successfully applied to modeling signals with harmonic structure. <p> For complicated signals with many evolving partials, the problem of line tracking is obviously difficult. One important fix, proposed in <ref> [36, 100] </ref>, is the use of backward line tracking when necessary; this technique can be used to track the partials of a note from the sustain region back to their origins in the note attack, which helps with the difficulties previously discussed. <p> Thus, it is necessary to separately model the analysis-synthesis residual if high-quality synthesis is desired; this requirement was the motivation for the deterministic-plus-stochastic decomposition proposed in <ref> [36, 100] </ref>. This chapter discusses a parametric approach for perceptually modeling the noiselike residual for both time-domain and frequency-domain synthesis. Earlier versions of this work have been presented in the literature [110, 178]. 4.1 Mixed Models Mixed models have been applied in many signal processing algorithms. <p> The voiced-unvoiced model, especially in the case of a mixed excitation, is similar to the deterministic-plus-stochastic sinusoidal model decomposition proposed in <ref> [36, 100] </ref> and explored further in [97, 110, 178, 109, 180]. The components in these latter models are concurrent in time; the models are thus capable of representing a wide variety of signals. <p> It is necessary to incorporate these processes into the reconstruction to achieve realistic or natural-sounding synthesis. In <ref> [36, 100] </ref>, the residual is modeled using a piecewise-linear spectral estimate; a random phase is applied to this spectrum, and an inverse discrete Fourier transform (IDFT) followed by overlap-add (OLA) is used for synthesis. <p> In this light, the filter bank analysis-synthesis can be interpreted as a first-order subband linear predictive coding system. Higher order LPC methods, while designed to model locally stationary random processes, are not particularly useful for this modeling scenario since the parameterization is not tightly coupled to perceptual factors <ref> [100] </ref>. The formulation above can be rephrased in terms of the power spectral densities of the original and reconstructed processes. This provides a more intuitive explanation of the filter bank residual model than the variance matching framework, and relates the two interpretations given in the preceding paragraph.
Reference: [101] <author> E. B. George and M. J. T. Smith, </author> <title> "Analysis-by-synthesis/overlap-add sinudoidal modeling applied to the analysis and synthesis of musical tones," </title> <journal> Journal of the Audio Engineering Society, </journal> <volume> vol. 40, </volume> <pages> pp. 497-516, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: introduction to the discussion of the sinusoidal model. 2.1 The Sinusoidal Signal Model A variety of sinusoidal modeling techniques have been explored in the literature <ref> [106, 96, 95, 98, 57, 36, 102, 101, 97] </ref>. These methods share fundamental common points, but also have substantial but sometimes subtle differences. <p> For the sake of simplicity, this treatment adheres primarily to the approaches presented in the early literature on sinusoidal modeling [57, 36], and not on the many variations that have since been proposed [103, 97, 98]; comments on some other techniques such as <ref> [101, 107] </ref> are indeed included, but these inclusions are limited to techniques that are directly concerned with the modeling issues at hand. <p> Here, it suffices to note that analysis-by-synthesis has been applied effectively in sinusoidal modeling, especially in the case where the sinusoidal parameters are estimated directly from the time-domain signal <ref> [101] </ref>. The particular technique of [101] employs a dictionary of short-time sinusoids and is indeed an example of a method that bridges the gap between parametric and nonparametric approaches. <p> Here, it suffices to note that analysis-by-synthesis has been applied effectively in sinusoidal modeling, especially in the case where the sinusoidal parameters are estimated directly from the time-domain signal <ref> [101] </ref>. The particular technique of [101] employs a dictionary of short-time sinusoids and is indeed an example of a method that bridges the gap between parametric and nonparametric approaches. <p> Plots (c) and (d) depict the delocalized reconstructions, and plots (e) and (f) show the respective residuals. Note the pre-echoes and the artifacts near the onset times. frame size of 1024 implicit smoothing of the interpolation. One approach for preventing reconstruction artifacts is the method described in <ref> [101] </ref>, which accounts for the attack problem by separately modeling the overall amplitude envelope of the signal. The amplitude envelope is imposed on the sinusoidal reconstruction to improve the time localization. <p> Here, modifications based on the sinusoidal model are dealt with more explicitly. Specifically, time-scaling, pitch-shifting, and cross-synthesis are considered. The treatment here is quite general; formalized details about modifications in a specific version of the sinusoidal model can be found in the literature <ref> [93, 101, 154, 94] </ref>. <p> The approach taken here is to use multiresolution sinusoidal modeling to minimize such artifacts so that they do not appear in the residual and thus do not have to be accounted for in the residual model. A similar approach is taken in the algorithm in <ref> [101] </ref>, which estimates the time-domain envelope of the signal and applies it to the sinusoidal model to enhance the modeling of transients. <p> residual energy in the dynamic model is lower; as discussed in Section 3.4, the multiresolution model is adapted to minimize this energy given various constraints such as the number of sinusoids in the model; the notion of minimizing the residual energy is also incorporated in the analysis-by-synthesis algorithm discussed in <ref> [101] </ref> and in global parameter optimization methods [107].
Reference: [102] <author> X. Rodet and P. Depalle, </author> <title> "Spectral envelopes and inverse FFT synthesis," </title> <booktitle> Proceedings of the 93rd Convention of the Audio Engineering Society, </booktitle> <month> October </month> <year> 1992. </year> <type> Preprint 3393. </type>
Reference-contexts: introduction to the discussion of the sinusoidal model. 2.1 The Sinusoidal Signal Model A variety of sinusoidal modeling techniques have been explored in the literature <ref> [106, 96, 95, 98, 57, 36, 102, 101, 97] </ref>. These methods share fundamental common points, but also have substantial but sometimes subtle differences. <p> It should be noted that the issues to be discussed herein apply to sinusoidal modeling in general; their relevance is not limited by the adherence to the particular methods of [57, 36]. Also, note that the method of <ref> [102] </ref> is discussed at length in the section on frequency-domain synthesis, where various refinements are proposed. 2.1.1 The Sum-of-Partials Model In sinusoidal modeling, a discrete-time signal x [n] is modeled as a sum of evolving sinusoids called partials: x [n] ^x [n] = q=1 Q [n] X A q [n] cos <p> Since it describes the primary musical information about the signal in a simple, compact form, the parameterization provides not only a reasonable coding representation but also a framework for carrying out desirable modifications such as pitch-shifting, time-scaling, and a wide variety of spectral transformations such as cross-synthesis <ref> [93, 94, 36, 102, 103, 108] </ref>. 2.1.2 Deterministic-plus-Stochastic Decomposition The approximation symbol in Equation (2.1) is included to imply that the sum-of-partials model does not provide an exact reconstruction of the signal. <p> Windows that satisfy Equation (2.12) can be designed in a number of ways. The methods to be discussed rely on using familiar windows that satisfy (2.13) to jointly construct analysis and synthesis windows which satisfy (2.12); various analysis-synthesis window pairs designed in this way exhibit computational and modeling advantages <ref> [116, 115, 112, 102] </ref>. <p> This approach provides various computational advantages over general time-domain synthesis <ref> [102, 132] </ref>. Frequency-domain synthesis was described in [57, 150, 151] and more fully presented in [102]. <p> This approach provides various computational advantages over general time-domain synthesis [102, 132]. Frequency-domain synthesis was described in [57, 150, 151] and more fully presented in <ref> [102] </ref>. In this section, the algorithm in [102] is explored in detail. 2.5.1 The Algorithm The frequency-domain synthesis algorithm is fundamentally based on the relationship between the DTFT and the DFT and the resulting implications for representing short-time sinusoids. <p> This approach provides various computational advantages over general time-domain synthesis [102, 132]. Frequency-domain synthesis was described in [57, 150, 151] and more fully presented in <ref> [102] </ref>. In this section, the algorithm in [102] is explored in detail. 2.5.1 The Algorithm The frequency-domain synthesis algorithm is fundamentally based on the relationship between the DTFT and the DFT and the resulting implications for representing short-time sinusoids. <p> Spectral motifs In Equation (2.93) the spectral representation of a short-time sinusoid is computed by evaluating B at the frequencies 2k=K ! 0 . This computation is prohibitively expensive with regards to real-time synthesis, however, so it is necessary to pre compute and tabulate B <ref> [102, 132] </ref>. <p> This computation is prohibitively expensive with regards to real-time synthesis, however, so it is necessary to pre compute and tabulate B [102, 132]. Such tabulation requires approximating B in a discrete form; this approximation, which will be referred to as a spectral motif <ref> [102] </ref>, is considered here. 76 (1) Unmodulated k = 0; K = 16 (2) Bin modulation k = 2; K = 16 (3) Off-bin modulation k = 2:4; K = 16 Window modulated to 2k DTFT magnitude and samples (dB) DTFT magnitude and samples (linear) sinusoids. <p> In this algorithm, arbitrary frequency resolution can be achieved by increasing the factor , provided that enough memory is available for storage of the motif. In music synthesis, however, the resolution limits of the auditory system can be taken into account in choosing the oversampling <ref> [102] </ref>. discussed above. Note that if the frequency of a partial cannot be written as 2m q =M , the samples in the shifted motif will not align with the bins of the synthesis IDFT. <p> The result of this approximation is that the spectral representation does not correspond exactly to a sinusoid windowed by b [n]; furthermore, each different modulation of the motif actually corresponds to a slightly different window. In practice, these errors are negligible if the window is chosen appropriately <ref> [102] </ref>. 78 Spectral motif Motif sampling Frequency (radians) oversampled main lobe of the DTFT of some window b [n], which is precomputed and stored. <p> This feature is desirable since it enables the frequency-domain synthesizer to perform similarly to the time-domain method while taking advantage of the computational improvements that result from using the IFFT for synthesis <ref> [102, 132] </ref>. For the overall OLA window t [n] to be a triangular window, the hybrid window v [n] = t [n]=b [n] must be applied to the IDFT output prior to overlap-add.
Reference: [103] <author> K. Fitz and L. Haken, </author> <title> "Sinusoidal modeling and manipulation using Lemur," </title> <journal> Computer Music Journal, </journal> <volume> vol. 20, </volume> <pages> pp. 44-59, </pages> <month> Winter </month> <year> 1996. </year>
Reference-contexts: These methods share fundamental common points, but also have substantial but sometimes subtle differences. For the sake of simplicity, this treatment adheres primarily to the approaches presented in the early literature on sinusoidal modeling [57, 36], and not on the many variations that have since been proposed <ref> [103, 97, 98] </ref>; comments on some other techniques such as [101, 107] are indeed included, but these inclusions are limited to techniques that are directly concerned with the modeling issues at hand. <p> Since it describes the primary musical information about the signal in a simple, compact form, the parameterization provides not only a reasonable coding representation but also a framework for carrying out desirable modifications such as pitch-shifting, time-scaling, and a wide variety of spectral transformations such as cross-synthesis <ref> [93, 94, 36, 102, 103, 108] </ref>. 2.1.2 Deterministic-plus-Stochastic Decomposition The approximation symbol in Equation (2.1) is included to imply that the sum-of-partials model does not provide an exact reconstruction of the signal.
Reference: [104] <author> T. F. Quatieri, R. B. Dunn, R. J. McAulay, and T. Hanna, </author> <title> "Time-scale modification of complex acoustic signals in noise," </title> <type> Tech. Rep. 990, </type> <institution> Lincoln Laboratory, M.I.T., </institution> <month> February </month> <year> 1994. </year>
Reference: [105] <author> T. F. Quatieri, R. B. Dunn, and T. E. Hanna, </author> <title> "Time-scale modification with temporal envelope invariance," </title> <booktitle> in Proceedings of the IEEE ASSP Workshop on Applications of Signal Processing to Audio and Acoustics, </booktitle> <pages> pp. 127-130, </pages> <month> October </month> <year> 1993. </year>
Reference: [106] <author> L. B. Almeida and J. M. Tribolet, </author> <title> "Nonstationary spectral modeling of voiced speech," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 31, </volume> <pages> pp. 664-678, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: introduction to the discussion of the sinusoidal model. 2.1 The Sinusoidal Signal Model A variety of sinusoidal modeling techniques have been explored in the literature <ref> [106, 96, 95, 98, 57, 36, 102, 101, 97] </ref>. These methods share fundamental common points, but also have substantial but sometimes subtle differences.
Reference: [107] <author> Y. Ding and X. Qian, </author> <title> "Estimating sinusoidal parameters of musical tones based on global waveform fitting," </title> <booktitle> in Proceedings of the IEEE Workshop on Multimedia Signal Processing, </booktitle> <pages> pp. 95-100, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: For the sake of simplicity, this treatment adheres primarily to the approaches presented in the early literature on sinusoidal modeling [57, 36], and not on the many variations that have since been proposed [103, 97, 98]; comments on some other techniques such as <ref> [101, 107] </ref> are indeed included, but these inclusions are limited to techniques that are directly concerned with the modeling issues at hand. <p> If the entire signal is considered as a whole in the sinusoidal analysis, a globally optimal set of model parameters can be derived. Such optimization is a highly complex operation which requires intensive off-line computation <ref> [107] </ref>. This issue is related to the method to be discussed in Section 3.4, in which a slightly restricted global modeling problem is phrased in terms of dynamic programming to reduce the computational cost [134]. <p> Typically, interpolation is done using low-order polynomial models such as linear amplitude and cubic total phase; the specific approach of [57] is presented here, but other interpolation methods have been considered <ref> [36, 107, 148, 149, 150] </ref>. <p> lower; as discussed in Section 3.4, the multiresolution model is adapted to minimize this energy given various constraints such as the number of sinusoids in the model; the notion of minimizing the residual energy is also incorporated in the analysis-by-synthesis algorithm discussed in [101] and in global parameter optimization methods <ref> [107] </ref>.
Reference: [108] <author> D. L. Wessel, </author> <title> "Timbre space as a musical control structure," </title> <journal> Computer Music Journal, </journal> <volume> vol. 3, </volume> <pages> pp. 45-52, </pages> <month> Summer </month> <year> 1979. </year>
Reference-contexts: Since it describes the primary musical information about the signal in a simple, compact form, the parameterization provides not only a reasonable coding representation but also a framework for carrying out desirable modifications such as pitch-shifting, time-scaling, and a wide variety of spectral transformations such as cross-synthesis <ref> [93, 94, 36, 102, 103, 108] </ref>. 2.1.2 Deterministic-plus-Stochastic Decomposition The approximation symbol in Equation (2.1) is included to imply that the sum-of-partials model does not provide an exact reconstruction of the signal. <p> For instance, the clarinet and the bassoon would be fairly close together in this space, while the piano or guitar would not be nearby. Such categorization is referred to as multidimensional scaling <ref> [35, 34, 108] </ref>. It has been observed that timbre, which corresponds loosely to the evolution and shape of the spectral envelope, is an important feature in subjective evaluations of the similarity of sounds; if two sounds have the same timbre, they are generally judged to be similar [108]. <p> It has been observed that timbre, which corresponds loosely to the evolution and shape of the spectral envelope, is an important feature in subjective evaluations of the similarity of sounds; if two sounds have the same timbre, they are generally judged to be similar <ref> [108] </ref>. <p> This interpretation of a parametric timbre space as a musical control structure has been the focus of recent work in computer music <ref> [108] </ref>. 2.8 Conclusion In this chapter, the nonparametric short-time Fourier transform was discussed extensively. It was shown that the STFT can be interpreted as a modulated filter bank in which the subband signals can be likened to the partials in a sinusoidal signal model.
Reference: [109] <author> K. Hamdy, M. Ali, and A. Tewfik, </author> <title> "Low bit rate high quality audio coding with combined harmonic and wavelet representations," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 2, </volume> <pages> pp. 1045-1048, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: high-fidelity synthesis, an additional component is often included in the signal model to account for broadband processes: x [n] = ^x [n] + r [n] = d [n] + s [n]: (2.2) 35 The resultant deterministic-plus-stochastic decomposition was introduced in [36, 100] and has been discussed in several later efforts <ref> [109, 110] </ref>. <p> The voiced-unvoiced model, especially in the case of a mixed excitation, is similar to the deterministic-plus-stochastic sinusoidal model decomposition proposed in [36, 100] and explored further in <ref> [97, 110, 178, 109, 180] </ref>. The components in these latter models are concurrent in time; the models are thus capable of representing a wide variety of signals. <p> Furthermore, the model parameters allow for modifications of the residual; this capability is useful in that if the sinusoidal signal components are modified, the residual should undergo a corresponding transformation prior to synthesis [142]. In <ref> [109, 180] </ref> the models are more elaborate than the one presented in this chapter in that they have specific extensions to model attack artifacts present in the residual, which were discussed in Section 2.6.
Reference: [110] <author> M. Goodwin, </author> <title> "Residual modeling in music analysis-synthesis," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 2, </volume> <pages> pp. 1005-1008, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: high-fidelity synthesis, an additional component is often included in the signal model to account for broadband processes: x [n] = ^x [n] + r [n] = d [n] + s [n]: (2.2) 35 The resultant deterministic-plus-stochastic decomposition was introduced in [36, 100] and has been discussed in several later efforts <ref> [109, 110] </ref>. <p> This chapter discusses a parametric approach for perceptually modeling the noiselike residual for both time-domain and frequency-domain synthesis. Earlier versions of this work have been presented in the literature <ref> [110, 178] </ref>. 4.1 Mixed Models Mixed models have been applied in many signal processing algorithms. <p> The voiced-unvoiced model, especially in the case of a mixed excitation, is similar to the deterministic-plus-stochastic sinusoidal model decomposition proposed in [36, 100] and explored further in <ref> [97, 110, 178, 109, 180] </ref>. The components in these latter models are concurrent in time; the models are thus capable of representing a wide variety of signals. <p> It is thus useful to devise an FFT-based algorithm for modeling the residual; analysis, synthesis, and normalization issues are discussed below. These results were presented in <ref> [110] </ref>. 143 Residual analysis Analysis for the ERB residual model can be carried out using the FFT. As in the sinusoidal analysis, this uses a sliding window w [niL] of length N to extract frames of the residual s [n] at times spaced by the analysis hop size L.
Reference: [111] <author> J. Allen and L. Rabiner, </author> <title> "A unified approach to short-time Fourier analysis and synthesis," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 65, </volume> <pages> pp. 1558-1564, </pages> <month> November </month> <year> 1977. </year>
Reference-contexts: These methods and variations were developed and explored in a number of references <ref> [111, 112, 113, 114, 115, 116, 117, 118, 119] </ref>. <p> The definition of the STFT given in Equations (2.3) and (2.4) differ from that in traditional references on the STFT <ref> [111, 116, 115, 112] </ref>, where the transform is expressed as 1 X ~w [n m]x [m]e j! k m = m=n or in subsampled form as ~ X (k; i) = m=iL where ~w [m] is again a time-localized window. <p> This will become more apparent in Sections 2.3 and 2.4. 38 - Time F requency . . . . . . 6 Time-localized Fourier transform Filter bank localized spectra (vertical) and as a bank of bandpass filters (horizontal). Interpretations of the STFT In <ref> [111, 1] </ref> and other traditional treatments of the STFT, two interpretations are considered. First, the STFT can be viewed as a series of time-localized spectra; notationally, this corresponds to interpreting X [k; n] as a function of frequency k for a fixed n. <p> In the traditional formulation of the STFT, the reconstruction constraints are different for the two interpretations, but can be related by a duality argument <ref> [111] </ref>. In the phase-localized formulation of Equations (2.3) and (2.4), the two frameworks immediately yield the same perfect reconstruction condition; this is not particularly surprising since the representation of the STFT as a time-frequency tiling suggests that a distinction between the two interpretations is indeed artificial. <p> This constraint is similar to but somewhat more general than the perfect reconstruction constraints given in <ref> [1, 111, 116, 115, 112] </ref>. Note that throughout this section the analysis and synthesis windows will both be assumed to be real-valued. In cases where v [n] is not explicitly specified, the synthesis window is equivalently a rectangular window covering the same time span as w [n]. <p> This latter design method will come into play in the frequency-domain sinusoidal synthesizer to be discussed in Section 2.5. The STFT as a heterodyne filter bank In <ref> [111, 115, 116, 20] </ref>, where the STFT is defined as in Equation (2.5) and the expansion functions have an absolute time reference, the transform can be interpreted as 41 a filter bank with a heterodyne structure. <p> The idea is straightforward: the signal can be reconstructed by modulating each of these envelopes to the appropriate frequency and summing the resulting signals. This construction is given by ^x [n] = k which can be manipulated to yield perfect reconstruction conditions <ref> [1, 111] </ref>; this non-subsampled case is not very general, however, so these constraints will not be derived here. Rather, Equation (2.21) is given to indicate the similarity of the STFT signal model and the sinusoidal model. <p> Again, note that the subband signals are essentially the 44 partials of the signal model, and are not amplitude envelopes as in the heterodyne structure of the traditional STFT filter bank. In the framework of <ref> [111] </ref>, namely the STFT as given in Equation (2.5), the overlap-add and filter bank summation synthesis methods lead to different perfect reconstruction constraints which can be interpreted as duals. <p> The use of oversampling, however, is contrary to the goal of data reduction. This problem is solved in the sinusoidal model by applying a parametric representation to the STFT to achieve compaction. Modifications of the STFT Various signal modifications based on the STFT have been discussed in the literature <ref> [1, 111, 114, 115, 112, 117, 128, 129] </ref>. In approaches where the modifications are based directly on the function X (k; i), the techniques are inherently restricted to a rigid framework because the signal is being modeled in terms of subbands which interact in complicated ways in the reconstruction process. <p> The restrictive framework is exactly this: a modification is carried out on the subband signals and the effect of the modification on the output signal is then formulated <ref> [111, 115] </ref>. This approach is much different from the desired framework of simply carrying out a particular modification on the original signal.
Reference: [112] <author> R. Crochiere, </author> <title> "A weighted overlap-add method of short-time Fourier analysis/synthesis," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 28, </volume> <pages> pp. 99-102, </pages> <month> February </month> <year> 1980. </year>
Reference-contexts: These methods and variations were developed and explored in a number of references <ref> [111, 112, 113, 114, 115, 116, 117, 118, 119] </ref>. <p> The definition of the STFT given in Equations (2.3) and (2.4) differ from that in traditional references on the STFT <ref> [111, 116, 115, 112] </ref>, where the transform is expressed as 1 X ~w [n m]x [m]e j! k m = m=n or in subsampled form as ~ X (k; i) = m=iL where ~w [m] is again a time-localized window. <p> The two formulations of the STFT have different interpretations with regards to signal modeling; this difference can be seen by relating the two STFT definitions <ref> [1, 112] </ref>: ~ X [k; n] = m=n = m=0 ~w [m]x [n + m]e j! k (m+n) (change of index) = e j! k n m=0 = e j! k n m=0 ~ X [k; n] = e j! k n X [k; n]: This formulation leads to two simple <p> The issue of time-domain aliasing cancellation is discussed in Section 2.2.2. If the DFT is large enough that no aliasing occurs, reconstruction can be simply carried out by an overlap-add (OLA) process, possibly with a synthesis window, which will be denoted by v [n] <ref> [116, 115, 112] </ref>: ^x [n] = i Perfect reconstruction is thus achieved if the windows w [n] and v [n] satisfy the constraint X w [n iL]v [n iL] = 1 (2.12) or some other constant. <p> This constraint is similar to but somewhat more general than the perfect reconstruction constraints given in <ref> [1, 111, 116, 115, 112] </ref>. Note that throughout this section the analysis and synthesis windows will both be assumed to be real-valued. In cases where v [n] is not explicitly specified, the synthesis window is equivalently a rectangular window covering the same time span as w [n]. <p> Windows that satisfy Equation (2.12) can be designed in a number of ways. The methods to be discussed rely on using familiar windows that satisfy (2.13) to jointly construct analysis and synthesis windows which satisfy (2.12); various analysis-synthesis window pairs designed in this way exhibit computational and modeling advantages <ref> [116, 115, 112, 102] </ref>. <p> The use of oversampling, however, is contrary to the goal of data reduction. This problem is solved in the sinusoidal model by applying a parametric representation to the STFT to achieve compaction. Modifications of the STFT Various signal modifications based on the STFT have been discussed in the literature <ref> [1, 111, 114, 115, 112, 117, 128, 129] </ref>. In approaches where the modifications are based directly on the function X (k; i), the techniques are inherently restricted to a rigid framework because the signal is being modeled in terms of subbands which interact in complicated ways in the reconstruction process.
Reference: [113] <author> J. L. Flanagan and R. M. Golden, </author> <title> "Phase vocoder," </title> <journal> Bell System Technical Journal, </journal> <volume> vol. 45, </volume> <pages> pp. </pages> <address> 1493 -1509, </address> <month> November </month> <year> 1966. </year>
Reference-contexts: These methods and variations were developed and explored in a number of references <ref> [111, 112, 113, 114, 115, 116, 117, 118, 119] </ref>. <p> the term refers to a structure like the one shown in Figure 2.6, where the subband signals are parameterized in terms of magnitude envelopes and functions that describe the frequency and phase evolution; these serve as inputs to a bank of oscillators that reconstruct the signal from the parametric model <ref> [113, 118, 116, 119] </ref>. This approach has been widely applied to modification of speech signals; the success of such approaches substantiates the previous contention that modifications are enabled by the incorporation of a parametric model and a parametric synthesis.
Reference: [114] <author> J. Allen, </author> <title> "Short term spectral analysis, synthesis, and modification by discrete Fourier transform," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 25, </volume> <pages> pp. 235-238, </pages> <month> June </month> <year> 1977. </year> <month> 251 </month>
Reference-contexts: These methods and variations were developed and explored in a number of references <ref> [111, 112, 113, 114, 115, 116, 117, 118, 119] </ref>. <p> The use of oversampling, however, is contrary to the goal of data reduction. This problem is solved in the sinusoidal model by applying a parametric representation to the STFT to achieve compaction. Modifications of the STFT Various signal modifications based on the STFT have been discussed in the literature <ref> [1, 111, 114, 115, 112, 117, 128, 129] </ref>. In approaches where the modifications are based directly on the function X (k; i), the techniques are inherently restricted to a rigid framework because the signal is being modeled in terms of subbands which interact in complicated ways in the reconstruction process.
Reference: [115] <author> M. R. Portnoff, </author> <title> "Time-frequency representation of digital signals and systems based on short-time Fourier analysis," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 28, </volume> <pages> pp. 55-69, </pages> <month> February </month> <year> 1980. </year>
Reference-contexts: These methods and variations were developed and explored in a number of references <ref> [111, 112, 113, 114, 115, 116, 117, 118, 119] </ref>. <p> The definition of the STFT given in Equations (2.3) and (2.4) differ from that in traditional references on the STFT <ref> [111, 116, 115, 112] </ref>, where the transform is expressed as 1 X ~w [n m]x [m]e j! k m = m=n or in subsampled form as ~ X (k; i) = m=iL where ~w [m] is again a time-localized window. <p> The issue of time-domain aliasing cancellation is discussed in Section 2.2.2. If the DFT is large enough that no aliasing occurs, reconstruction can be simply carried out by an overlap-add (OLA) process, possibly with a synthesis window, which will be denoted by v [n] <ref> [116, 115, 112] </ref>: ^x [n] = i Perfect reconstruction is thus achieved if the windows w [n] and v [n] satisfy the constraint X w [n iL]v [n iL] = 1 (2.12) or some other constant. <p> This constraint is similar to but somewhat more general than the perfect reconstruction constraints given in <ref> [1, 111, 116, 115, 112] </ref>. Note that throughout this section the analysis and synthesis windows will both be assumed to be real-valued. In cases where v [n] is not explicitly specified, the synthesis window is equivalently a rectangular window covering the same time span as w [n]. <p> Windows that satisfy Equation (2.12) can be designed in a number of ways. The methods to be discussed rely on using familiar windows that satisfy (2.13) to jointly construct analysis and synthesis windows which satisfy (2.12); various analysis-synthesis window pairs designed in this way exhibit computational and modeling advantages <ref> [116, 115, 112, 102] </ref>. <p> This latter design method will come into play in the frequency-domain sinusoidal synthesizer to be discussed in Section 2.5. The STFT as a heterodyne filter bank In <ref> [111, 115, 116, 20] </ref>, where the STFT is defined as in Equation (2.5) and the expansion functions have an absolute time reference, the transform can be interpreted as 41 a filter bank with a heterodyne structure. <p> The use of oversampling, however, is contrary to the goal of data reduction. This problem is solved in the sinusoidal model by applying a parametric representation to the STFT to achieve compaction. Modifications of the STFT Various signal modifications based on the STFT have been discussed in the literature <ref> [1, 111, 114, 115, 112, 117, 128, 129] </ref>. In approaches where the modifications are based directly on the function X (k; i), the techniques are inherently restricted to a rigid framework because the signal is being modeled in terms of subbands which interact in complicated ways in the reconstruction process. <p> The restrictive framework is exactly this: a modification is carried out on the subband signals and the effect of the modification on the output signal is then formulated <ref> [111, 115] </ref>. This approach is much different from the desired framework of simply carrying out a particular modification on the original signal.
Reference: [116] <author> M. R. Portnoff, </author> <title> "Implementation of the digital phase vocoder using the fast Fourier transform," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 24, </volume> <pages> pp. 243-248, </pages> <month> June </month> <year> 1976. </year>
Reference-contexts: These methods and variations were developed and explored in a number of references <ref> [111, 112, 113, 114, 115, 116, 117, 118, 119] </ref>. <p> = m=0 36 where the DFT is of size K, meaning that ! k = 2k=K, and w [m] is a time-domain window with zero value outside the interval [0; N 1]; windows with infinite time support have been discussed in the literature, but these will not be considered here <ref> [116] </ref>. In the early literature on time-frequency transforms, signal analysis-synthesis based on Gaussian windows was proposed by Gabor [71, 72]; given this historical foundation, the STFT is sometimes referred to as a Gabor transform [2]. <p> The definition of the STFT given in Equations (2.3) and (2.4) differ from that in traditional references on the STFT <ref> [111, 116, 115, 112] </ref>, where the transform is expressed as 1 X ~w [n m]x [m]e j! k m = m=n or in subsampled form as ~ X (k; i) = m=iL where ~w [m] is again a time-localized window. <p> The issue of time-domain aliasing cancellation is discussed in Section 2.2.2. If the DFT is large enough that no aliasing occurs, reconstruction can be simply carried out by an overlap-add (OLA) process, possibly with a synthesis window, which will be denoted by v [n] <ref> [116, 115, 112] </ref>: ^x [n] = i Perfect reconstruction is thus achieved if the windows w [n] and v [n] satisfy the constraint X w [n iL]v [n iL] = 1 (2.12) or some other constant. <p> This constraint is similar to but somewhat more general than the perfect reconstruction constraints given in <ref> [1, 111, 116, 115, 112] </ref>. Note that throughout this section the analysis and synthesis windows will both be assumed to be real-valued. In cases where v [n] is not explicitly specified, the synthesis window is equivalently a rectangular window covering the same time span as w [n]. <p> Windows that satisfy Equation (2.12) can be designed in a number of ways. The methods to be discussed rely on using familiar windows that satisfy (2.13) to jointly construct analysis and synthesis windows which satisfy (2.12); various analysis-synthesis window pairs designed in this way exhibit computational and modeling advantages <ref> [116, 115, 112, 102] </ref>. <p> This latter design method will come into play in the frequency-domain sinusoidal synthesizer to be discussed in Section 2.5. The STFT as a heterodyne filter bank In <ref> [111, 115, 116, 20] </ref>, where the STFT is defined as in Equation (2.5) and the expansion functions have an absolute time reference, the transform can be interpreted as 41 a filter bank with a heterodyne structure. <p> the other sum; the perfect reconstruction constraint is thus X v [n iL]w [n + rK iL] = ffi [r]: (2.55) In the nonsubsampled case with v [n] = ffi [n], this simplifies to w [rK] = ffi [r]; (2.56) which is reminiscent of the constraint for designing interpolation filters <ref> [116, 127] </ref>. Note that since the time index is the start of the window in this treatment, the most appropriate synthesis window is actually given by v [n] = ffi [n n 0 ], where n 0 corresponds to the middle of the analysis window. <p> the term refers to a structure like the one shown in Figure 2.6, where the subband signals are parameterized in terms of magnitude envelopes and functions that describe the frequency and phase evolution; these serve as inputs to a bank of oscillators that reconstruct the signal from the parametric model <ref> [113, 118, 116, 119] </ref>. This approach has been widely applied to modification of speech signals; the success of such approaches substantiates the previous contention that modifications are enabled by the incorporation of a parametric model and a parametric synthesis.
Reference: [117] <author> D. Griffin and J. Lim, </author> <title> "Signal estimation from modified short-time Fourier transform," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 32, </volume> <pages> pp. 236-243, </pages> <month> April </month> <year> 1984. </year>
Reference-contexts: These methods and variations were developed and explored in a number of references <ref> [111, 112, 113, 114, 115, 116, 117, 118, 119] </ref>. <p> The use of oversampling, however, is contrary to the goal of data reduction. This problem is solved in the sinusoidal model by applying a parametric representation to the STFT to achieve compaction. Modifications of the STFT Various signal modifications based on the STFT have been discussed in the literature <ref> [1, 111, 114, 115, 112, 117, 128, 129] </ref>. In approaches where the modifications are based directly on the function X (k; i), the techniques are inherently restricted to a rigid framework because the signal is being modeled in terms of subbands which interact in complicated ways in the reconstruction process. <p> This approach is much different from the desired framework of simply carrying out a particular modification on the original signal. In some approaches, modifications are based on the STFT magnitude only; the magnitude is first modified and then a phase that will minimize synthesis discontinuities is derived <ref> [117, 128, 129] </ref>. This removal of the phase essentially results in a parametric representation that is more flexible than the complex subband signals.
Reference: [118] <author> M. Dolson, </author> <title> "The phase vocoder: A tutorial," </title> <journal> Computer Music Journal, </journal> <volume> vol. 10, </volume> <pages> pp. 14-27, </pages> <month> Winter </month> <year> 1986. </year>
Reference-contexts: These methods and variations were developed and explored in a number of references <ref> [111, 112, 113, 114, 115, 116, 117, 118, 119] </ref>. <p> the term refers to a structure like the one shown in Figure 2.6, where the subband signals are parameterized in terms of magnitude envelopes and functions that describe the frequency and phase evolution; these serve as inputs to a bank of oscillators that reconstruct the signal from the parametric model <ref> [113, 118, 116, 119] </ref>. This approach has been widely applied to modification of speech signals; the success of such approaches substantiates the previous contention that modifications are enabled by the incorporation of a parametric model and a parametric synthesis.
Reference: [119] <author> J. A. Moorer, </author> <title> "The use of the phase vocoder in computer music applications," </title> <journal> Journal of the Audio Engineering Society, </journal> <volume> vol. 26, </volume> <pages> pp. 42-45, </pages> <month> January/February </month> <year> 1978. </year>
Reference-contexts: These methods and variations were developed and explored in a number of references <ref> [111, 112, 113, 114, 115, 116, 117, 118, 119] </ref>. <p> the term refers to a structure like the one shown in Figure 2.6, where the subband signals are parameterized in terms of magnitude envelopes and functions that describe the frequency and phase evolution; these serve as inputs to a bank of oscillators that reconstruct the signal from the parametric model <ref> [113, 118, 116, 119] </ref>. This approach has been widely applied to modification of speech signals; the success of such approaches substantiates the previous contention that modifications are enabled by the incorporation of a parametric model and a parametric synthesis.
Reference: [120] <author> M. Vetterli, </author> <title> "Filter banks allowing perfect reconstruction," </title> <booktitle> Signal Processing, </booktitle> <volume> vol. 10, </volume> <pages> pp. 219-244, </pages> <month> April </month> <year> 1986. </year>
Reference-contexts: Perfect reconstruction constraints for such STFT filter banks are derived. In the literature, z-transform and matrix representations have been shown to be useful in analyzing the properties of such filter banks <ref> [2, 20, 120] </ref>. Here, for the sake of brevity, these methods are not explored; the STFT filter banks are treated using time-domain considerations. <p> The critically sampled case L = K is of special interest since the representation and the original signal intrinsically contain the same amount of data. For critical sampling, however, it can be shown that the only FIR solutions correspond to windows with N = K nonzero coefficients <ref> [2, 120] </ref>. In the straightforward solution of this form, the N nonzero coefficients are all in the interval [0; N 1]. <p> On the other hand, the reason that there are no solutions for N &gt; K is less intuitive; this result is proved in <ref> [2, 120] </ref>. In the critically sampled case, then, the STFT in effect implements a block transform with block size N ; quantization then leads to discontinuities at the block boundaries, which results in undesirable frame rate artifacts in audio and blockiness in images.
Reference: [121] <author> F. Leonard, </author> <title> "Referencing the phase to the centre of the spectral window. why?," </title> <journal> Mechanical Systems and Signal Processing, </journal> <volume> vol. 2, </volume> <pages> pp. 75-90, </pages> <month> January </month> <year> 1997. </year>
Reference-contexts: Note that the STFT can also be formulated such that the phase is referenced to the center of the time window, which is desirable in some cases <ref> [121] </ref>; this referencing is a straightforward extension that will play a role in sinusoidal modeling, but such phase-centering will not be used in the mathematical development of the STFT because of the slight complications it introduces.
Reference: [122] <author> F. J. Harris, </author> <title> "On the use of windows for harmonic analysis with the discrete Fourier transform," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 66, </volume> <pages> pp. 51-83, </pages> <month> January </month> <year> 1978. </year>
Reference-contexts: Equation (2.12) becomes X w [n iL] = 1: (2.13) The construction of windows with this property has been explored in the literature; a variety of perfect reconstruction windows have been proposed, for example rectangular and triangular windows and the Blackman-Harris family, which includes the familiar Hanning and Hamming windows <ref> [122, 123] </ref>. These are also referred to as windows with the overlap-add property, and will be denoted by w PR [n] in the following derivations. <p> Then, the sinusoid can be identified if the shape of the window transform can be detected in the spectrum; the performance of such methods has been considered in the literature for the general case of multiple sinusoids in noise <ref> [122, 100, 133] </ref>. This matching approach is particularly applicable when a Gaussian window is used since the window transform is then simply a parabola in the log-magnitude spectrum; by fitting a parabola to the spectral data, the location of a peak can be estimated. <p> Also note that in (1) and (2) the only nonzero points in the DFT occur in the main lobe since the frequency-domain samples are taken at zero crossings of the DTFT sidelobes. All of the windows in the Blackman-Harris family exhibit this property by construction <ref> [122, 123] </ref>; it is not a unique feature of the Hanning window. In some applications, this zero-crossing property is useful in that a window can be applied efficiently in the DFT domain by circular convolution [122]. <p> All of the windows in the Blackman-Harris family exhibit this property by construction [122, 123]; it is not a unique feature of the Hanning window. In some applications, this zero-crossing property is useful in that a window can be applied efficiently in the DFT domain by circular convolution <ref> [122] </ref>. Spectral motifs In Equation (2.93) the spectral representation of a short-time sinusoid is computed by evaluating B at the frequencies 2k=K ! 0 . This computation is prohibitively expensive with regards to real-time synthesis, however, so it is necessary to pre compute and tabulate B [102, 132]. <p> Example of such hybrid windows are given in Figure 2.16 for the case of a Hanning window, a Hamming window, and a Blackman-III window <ref> [122] </ref>; this shows that a Hanning window is actually unsuitable for this application given the discontinuities at the edges of the hybrid window. Frequency-domain synthesis and the STFT It was shown in Section 2.2.1 that the STFT synthesis can be interpreted as an inverse Fourier transform coupled with overlap-add process.
Reference: [123] <author> A. H. Nuttall, </author> <title> "Some windows with very good sidelobe behavior," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 29, </volume> <pages> pp. 84-91, </pages> <month> February </month> <year> 1981. </year>
Reference-contexts: Equation (2.12) becomes X w [n iL] = 1: (2.13) The construction of windows with this property has been explored in the literature; a variety of perfect reconstruction windows have been proposed, for example rectangular and triangular windows and the Blackman-Harris family, which includes the familiar Hanning and Hamming windows <ref> [122, 123] </ref>. These are also referred to as windows with the overlap-add property, and will be denoted by w PR [n] in the following derivations. <p> Also note that in (1) and (2) the only nonzero points in the DFT occur in the main lobe since the frequency-domain samples are taken at zero crossings of the DTFT sidelobes. All of the windows in the Blackman-Harris family exhibit this property by construction <ref> [122, 123] </ref>; it is not a unique feature of the Hanning window. In some applications, this zero-crossing property is useful in that a window can be applied efficiently in the DFT domain by circular convolution [122].
Reference: [124] <author> E. A. Lee and D. G. Messerschmitt, </author> <title> Digital Communication. </title> <address> Boston, MA: </address> <publisher> Kluwer Academic Publishers, </publisher> <year> 1988. </year>
Reference-contexts: Functions that satisfy Equation (2.13) are also of interest for digital communication; the Nyquist criterion for avoiding intersymbol interference corresponds to a frequency-domain overlap-add property <ref> [124] </ref>. Windows that satisfy Equation (2.12) can be designed in a number of ways. <p> This type of approach has found widespread use for sequence detection in digital communication, where it is referred to as the Viterbi algorithm <ref> [124] </ref>. <p> The second case is L &lt; N (and sometimes L &lt;< N ), which corresponds to the case of an implementation with finite memory. This restriction on L is somewhat analogous to the truncation depth commonly used to reduce the delay in Viterbi sequence detection <ref> [124] </ref>. Using a diverse set of segment lengths allows for flexibility in signal modeling. Additional signal adaptivity can be achieved by allowing for a choice of model for each segment. One example of such a model choice is the filter order in an LPC application [134]. <p> One useful choice for f [n] is the raised cosine pulse, common in digital communication applications <ref> [124] </ref>, which enables the filter responses to be controlled by way of the excess bandwidth parameter ff.
Reference: [125] <author> H. Bolcskei and F. Hlawatsch, </author> <title> "Oversampled filter banks: Optimal noise shaping, design freedom, and noise analysis," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 3, </volume> <pages> pp. 2453-2456, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: The generality of this constraint is an example of the design flexibility that results from using oversampled or overcomplete approaches <ref> [70, 64, 125] </ref>. <p> Quantization effects can also be reduced by oversampling; one advantage of overcomplete representations is that they exhibit a robustness to quantization noise that is proportional to the redundancy of the representation <ref> [70, 64, 92, 125] </ref>. Time-frequency localization As discussed above, the design of STFT filter banks is extremely limited in the critically sampled case. The only real-valued prototype windows that lead to orthogonal perfect reconstruction filter banks are rectangular windows [2].
Reference: [126] <author> M. Dolson, </author> <title> A tracking phase vocoder and its use in the analysis of ensemble sounds. </title> <type> PhD thesis, </type> <institution> University of California at San Diego, </institution> <year> 1983. </year>
Reference-contexts: The signals ^x k [n] correspond to those labeled in Figure 2.3 for k = f1; 2; 3; 4g. In the simulation, N = 128, K = 128, and L = 64; w [n] and v [n] are square-root Hanning windows. 49 <ref> [126] </ref>, signal adaptivity improves the model. A pitch-adaptive filter bank, however, does not account for the more general case of signals composed of nonharmonic partials with unrelated frequency evolution behavior, for instance a percussive sound such as a cymbal clash.
Reference: [127] <author> G. Oetken, T. W. Parks, and H. W. Schussler, </author> <title> "New results in the design of digital interpolators," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 23, </volume> <pages> pp. 301-308, </pages> <month> June </month> <year> 1975. </year>
Reference-contexts: the other sum; the perfect reconstruction constraint is thus X v [n iL]w [n + rK iL] = ffi [r]: (2.55) In the nonsubsampled case with v [n] = ffi [n], this simplifies to w [rK] = ffi [r]; (2.56) which is reminiscent of the constraint for designing interpolation filters <ref> [116, 127] </ref>. Note that since the time index is the start of the window in this treatment, the most appropriate synthesis window is actually given by v [n] = ffi [n n 0 ], where n 0 corresponds to the middle of the analysis window.
Reference: [128] <author> M. Slaney, D. Naar, and R. Lyon, </author> <title> "Auditory model inversion for sound separation," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 2, </volume> <pages> pp. 77-80, </pages> <month> April </month> <year> 1994. </year> <month> 252 </month>
Reference-contexts: The use of oversampling, however, is contrary to the goal of data reduction. This problem is solved in the sinusoidal model by applying a parametric representation to the STFT to achieve compaction. Modifications of the STFT Various signal modifications based on the STFT have been discussed in the literature <ref> [1, 111, 114, 115, 112, 117, 128, 129] </ref>. In approaches where the modifications are based directly on the function X (k; i), the techniques are inherently restricted to a rigid framework because the signal is being modeled in terms of subbands which interact in complicated ways in the reconstruction process. <p> This approach is much different from the desired framework of simply carrying out a particular modification on the original signal. In some approaches, modifications are based on the STFT magnitude only; the magnitude is first modified and then a phase that will minimize synthesis discontinuities is derived <ref> [117, 128, 129] </ref>. This removal of the phase essentially results in a parametric representation that is more flexible than the complex subband signals. <p> Both this DCT-based ECG compression algorithm and the PSWT itself are reminiscent of several other efforts involving multidimensional processing of one-dimensional signals, for instance image processing of audio <ref> [128, 210] </ref>. 5.6 Conclusion For pseudo-periodic signals, the redundancies between adjacent periods can be exploited to achieve compact signal models. This notion was the basic theme of this chapter, which opened with a discussion of estimation of signal periodicity and construction of a pitch-synchronous representation.
Reference: [129] <author> M. Slaney, M. Covell, and B. Lassiter, </author> <title> "Automatic audio morphing," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 2, </volume> <pages> pp. 1001-1004, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: The use of oversampling, however, is contrary to the goal of data reduction. This problem is solved in the sinusoidal model by applying a parametric representation to the STFT to achieve compaction. Modifications of the STFT Various signal modifications based on the STFT have been discussed in the literature <ref> [1, 111, 114, 115, 112, 117, 128, 129] </ref>. In approaches where the modifications are based directly on the function X (k; i), the techniques are inherently restricted to a rigid framework because the signal is being modeled in terms of subbands which interact in complicated ways in the reconstruction process. <p> This approach is much different from the desired framework of simply carrying out a particular modification on the original signal. In some approaches, modifications are based on the STFT magnitude only; the magnitude is first modified and then a phase that will minimize synthesis discontinuities is derived <ref> [117, 128, 129] </ref>. This removal of the phase essentially results in a parametric representation that is more flexible than the complex subband signals. <p> regions) and creating a map between these parametric features that can be traversed to synthesize a morphed image [158]. 92 Such morphing has also been used in the audio domain to carry out modifications based on the parametric representation provided by the spectrogram, i.e. the squared magnitude of the STFT <ref> [129] </ref>. In the fields of psychoacoustics and computer music, it has been of interest to categorize instrumental sounds according to their location in a perceptual space. For instance, the clarinet and the bassoon would be fairly close together in this space, while the piano or guitar would not be nearby.
Reference: [130] <author> D. Arfib and N. Delprat, </author> <title> "Musical transformations using the modification of time-frequency images," </title> <journal> Computer Music Journal, </journal> <volume> vol. 17, </volume> <pages> pp. 66-72, </pages> <month> Summer </month> <year> 1993. </year>
Reference-contexts: higher dimension than the signal space, meaning that some modifications in that space may have no effect on the signal or may produce an otherwise unexpected result; in deriving a phase for the STFT magnitude for synthesis in the overcomplete case, there are thus consistency or validity concerns that arise <ref> [130] </ref>. The issues of aliasing cancellation and validity, among others, indicate the fundamental point: the synthesis model limits the modification capability.
Reference: [131] <author> H. Dudley, </author> <title> "The vocoder," </title> <journal> Bell Laboratories Record, </journal> <volume> vol. 17, </volume> <pages> pp. 122-126, </pages> <year> 1939. </year>
Reference-contexts: The channel vocoder and the phase vocoder are the two fundamental steps in the progression from the STFT to the sinusoidal model. The channel vocoder The term vocoder, a contraction of voice and coder, was coined to describe an early speech analysis-synthesis algorithm <ref> [131] </ref>. In particular, the channel vocoder originated as a voice coder which represented a speech signal based on the characteristics of the STFT filter bank channels or subbands. Specifically, the speech is filtered into a large number of channels using an STFT analysis filter bank.
Reference: [132] <author> A. Freed, X. Rodet, and P. Depalle, </author> <title> "Synthesis and control of hundreds of sinusoidal partials on a desktop computer without custom hardware," </title> <booktitle> in Proceedings of the Fourth International Conference on Signal Processing Applications and Technology, </booktitle> <volume> vol. 2, </volume> <pages> pp. 1024-1030, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: the sinusoidal model such gaps can be filled in the reconstruction via parameter interpolation. 2.3 Sinusoidal Analysis The analysis for the sinusoidal model is responsible for deriving a set of time-varying model parameters, namely the number of partials Q [n], which may be constrained by rate or synthesis computation limits <ref> [132] </ref>, and the partial amplitudes fA q [n]g and total phases ffi q [n]g. As mentioned, these parameters are assumed to be slowly varying with respect to the sample rate, so the estimation process can be reliably carried out at a subsampled rate. <p> and phase control functions can be derived using an STFT analysis as depicted in Figure 2.7, or in other ways as described in the text. approach to modeling and modification of natural signals, and advances in computation technology have enabled such synthesis routines to be carried out in real time <ref> [132, 142] </ref>. The output of the q-th oscillator is A q [n] cos q [n]; this is dictated by sample-rate amplitude and total phase control functions that must be calculated in the synthesis process using the frame-rate (subsampled) analysis data. <p> This approach provides various computational advantages over general time-domain synthesis <ref> [102, 132] </ref>. Frequency-domain synthesis was described in [57, 150, 151] and more fully presented in [102]. <p> Spectral motifs In Equation (2.93) the spectral representation of a short-time sinusoid is computed by evaluating B at the frequencies 2k=K ! 0 . This computation is prohibitively expensive with regards to real-time synthesis, however, so it is necessary to pre compute and tabulate B <ref> [102, 132] </ref>. <p> This feature is desirable since it enables the frequency-domain synthesizer to perform similarly to the time-domain method while taking advantage of the computational improvements that result from using the IFFT for synthesis <ref> [102, 132] </ref>. For the overall OLA window t [n] to be a triangular window, the hybrid window v [n] = t [n]=b [n] must be applied to the IDFT output prior to overlap-add. <p> Zero-phase sinusoidal modeling In the standard sinusoidal model, the phase interpolation process at the synthesis stage is a high-complexity operation. Phase interpolation is thus one of the major obstacles in achieving real-time synthesis <ref> [132] </ref>. This difficulty is circumvented here by imposing a harmonic structure via the processes of pitch detection, segmentation, and resampling. In the pitch-synchronous sinusoidal model introduced above, the phase of the harmonics is preserved; phase interpolation from frame to frame is thus required, but this is problematic in several respects.
Reference: [133] <author> M. Bertocco, C. Offelli, and D. </author> <title> Petri, "Analysis of damped sinusoidal signals via a frequency-domain interpolation algorithm," </title> <journal> IEEE Transactions on Instrumentation and Measurement, </journal> <volume> vol. 43, </volume> <pages> pp. 245-250, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Then, the sinusoid can be identified if the shape of the window transform can be detected in the spectrum; the performance of such methods has been considered in the literature for the general case of multiple sinusoids in noise <ref> [122, 100, 133] </ref>. This matching approach is particularly applicable when a Gaussian window is used since the window transform is then simply a parabola in the log-magnitude spectrum; by fitting a parabola to the spectral data, the location of a peak can be estimated.
Reference: [134] <author> P. Prandoni, M. Goodwin, and M. Vetterli, </author> <title> "Optimal segmentation for signal modeling and compression," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 3, </volume> <pages> pp. 2029-2032, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: Such optimization is a highly complex operation which requires intensive off-line computation [107]. This issue is related to the method to be discussed in Section 3.4, in which a slightly restricted global modeling problem is phrased in terms of dynamic programming to reduce the computational cost <ref> [134] </ref>. Statistical estimation A wide variety of methods for estimating the parameters of sinusoidal and quasi-sinusoidal models have been presented in the spectral estimation literature. <p> If the metric is additive and independent across segments, however, the computational cost can be substantially reduced using a dynamic program. This approach has been applied to wavelet packet and LPC models <ref> [41, 60, 134] </ref>; after a brief review of dynamic programming and the relevant literature, dynamic segmentation for sinusoidal modeling is considered. Dynamic programming Dynamic programming was first introduced for solving minimum path-length problems [172]. <p> Using a diverse set of segment lengths allows for flexibility in signal modeling. Additional signal adaptivity can be achieved by allowing for a choice of model for each segment. One example of such a model choice is the filter order in an LPC application <ref> [134] </ref>. In the sinusoidal modeling case to be discussed, there is not a multiplicity of 112 candidate models for each segment. For this reason, model multiplicity is not considered here. <p> Mean-squared error and rate-distortion metrics can be applied in this framework <ref> [41, 60, 134] </ref>. Computational cost of global search The globally optimum segmentation is simply the segmentation which minimizes the metric D (). Obviously, this minimization can be arrived at by a globally exhaustive search in which the metric is computed for every possible segmentation in turn. <p> Note the regularity of the recursion after the startup; the cost of this algorithm grows linearly with the length of the signal. 119 sacrificing the optimality, then, the algorithm can be periodically terminated to derive blocks for coding <ref> [134] </ref>. Adaptive wavelet packets Early applications of dynamic programming to signal modeling involved models based on wavelet packets. In [41], the best wavelet packet in a rate-distortion sense is chosen for the model for each segment; in [60], dynamic segmentation is added to allow for localization of transients. <p> A similar technique was considered in [176]. Arbitrary models In addition to the wavelet packet algorithms described, dynamic segmentation and model selection has been applied to image compression [177] and linear predictive coding <ref> [134] </ref>. As long as the optimality metric is independent and additive across disjoint frames, the dynamic program can be used to efficiently find the optimal segmentation and model selections.
Reference: [135] <author> R. Kumaresan and D. Tufts, </author> <title> "Estimating the parameters of exponentially damped sinusoids and pole-zero modeling in noise," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 30, </volume> <pages> pp. 833-840, </pages> <month> December </month> <year> 1982. </year>
Reference-contexts: Key references for these other methods include <ref> [135, 136, 137, 138, 139, 140, 141] </ref>. 2.4 Time-Domain Synthesis Synthesis for the sinusoidal model is typically carried out in the time domain by accumulating the outputs of a bank of sinusoidal oscillators in direct accordance with the signal model of Equation (2.1).
Reference: [136] <author> D. Tufts and R. Kumaresan, </author> <title> "Estimation of frequencies of multiple sinusoids: Making linear prediction perform like maximum likelihood," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 70, </volume> <pages> pp. 975-989, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: Key references for these other methods include <ref> [135, 136, 137, 138, 139, 140, 141] </ref>. 2.4 Time-Domain Synthesis Synthesis for the sinusoidal model is typically carried out in the time domain by accumulating the outputs of a bank of sinusoidal oscillators in direct accordance with the signal model of Equation (2.1).
Reference: [137] <author> B. Friedlander and J. Francos, </author> <title> "Estimation of amplitude and phase parameters of multicomponent signals," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 43, </volume> <pages> pp. 917-925, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: Key references for these other methods include <ref> [135, 136, 137, 138, 139, 140, 141] </ref>. 2.4 Time-Domain Synthesis Synthesis for the sinusoidal model is typically carried out in the time domain by accumulating the outputs of a bank of sinusoidal oscillators in direct accordance with the signal model of Equation (2.1).
Reference: [138] <author> R. Roy and T. Kailath, </author> <title> "ESPRIT Estimation of signal parameters via rotational invariance techniques," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 37, </volume> <pages> pp. 984-995, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Key references for these other methods include <ref> [135, 136, 137, 138, 139, 140, 141] </ref>. 2.4 Time-Domain Synthesis Synthesis for the sinusoidal model is typically carried out in the time domain by accumulating the outputs of a bank of sinusoidal oscillators in direct accordance with the signal model of Equation (2.1).
Reference: [139] <author> S. Kay and S. Marple, </author> <title> "Spectrum analysis a modern perspective," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 69, </volume> <pages> pp. 1380-1419, </pages> <month> November </month> <year> 1981. </year>
Reference-contexts: Key references for these other methods include <ref> [135, 136, 137, 138, 139, 140, 141] </ref>. 2.4 Time-Domain Synthesis Synthesis for the sinusoidal model is typically carried out in the time domain by accumulating the outputs of a bank of sinusoidal oscillators in direct accordance with the signal model of Equation (2.1).
Reference: [140] <author> D. J. Thomson, </author> <title> "Spectrum estimation and harmonic analysis," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 70, </volume> <pages> pp. 1055-1096, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: Key references for these other methods include <ref> [135, 136, 137, 138, 139, 140, 141] </ref>. 2.4 Time-Domain Synthesis Synthesis for the sinusoidal model is typically carried out in the time domain by accumulating the outputs of a bank of sinusoidal oscillators in direct accordance with the signal model of Equation (2.1).
Reference: [141] <author> S. Kay, </author> <title> Modern Spectral Estimation: Theory and Application. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1988. </year>
Reference-contexts: Key references for these other methods include <ref> [135, 136, 137, 138, 139, 140, 141] </ref>. 2.4 Time-Domain Synthesis Synthesis for the sinusoidal model is typically carried out in the time domain by accumulating the outputs of a bank of sinusoidal oscillators in direct accordance with the signal model of Equation (2.1).
Reference: [142] <author> A. Freed, </author> <title> "Bring your own control to additive synthesis," </title> <booktitle> in Proceedings of the International Computer Music Conference, </booktitle> <pages> pp. 303-306, </pages> <month> September </month> <year> 1995. </year> <month> 253 </month>
Reference-contexts: and phase control functions can be derived using an STFT analysis as depicted in Figure 2.7, or in other ways as described in the text. approach to modeling and modification of natural signals, and advances in computation technology have enabled such synthesis routines to be carried out in real time <ref> [132, 142] </ref>. The output of the q-th oscillator is A q [n] cos q [n]; this is dictated by sample-rate amplitude and total phase control functions that must be calculated in the synthesis process using the frame-rate (subsampled) analysis data. <p> Furthermore, the model parameters allow for modifications of the residual; this capability is useful in that if the sinusoidal signal components are modified, the residual should undergo a corresponding transformation prior to synthesis <ref> [142] </ref>. In [109, 180] the models are more elaborate than the one presented in this chapter in that they have specific extensions to model attack artifacts present in the residual, which were discussed in Section 2.6.
Reference: [143] <author> X. Xie and R. J. Evans, </author> <title> "Multiple target tracking and multiple frequency line tracking using hidden Markov models," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 39, </volume> <pages> pp. 2659-2676, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: A number of more complex methods have been explored in the literature. One noteworthy technique involves using the Viterbi algorithm to find the best set of partial tracks <ref> [143, 144] </ref>; the cost of a given set of tracks is generally measured by summing the frame-to-frame absolute frequency differences along all of the tracks in the set.
Reference: [144] <author> R. F. Barrett and D. A. Holdsworth, </author> <title> "Frequency tracking using hidden Markov models with amplitude and phase information," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 41, </volume> <pages> pp. 2965-2976, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: A number of more complex methods have been explored in the literature. One noteworthy technique involves using the Viterbi algorithm to find the best set of partial tracks <ref> [143, 144] </ref>; the cost of a given set of tracks is generally measured by summing the frame-to-frame absolute frequency differences along all of the tracks in the set.
Reference: [145] <author> P. Depalle, G. Garcia, and X. Rodet, </author> <title> "Tracking of partials for additive sound synthesis using hidden Markov models," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 1, </volume> <pages> pp. 225-228, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: This method, which can be cast in the framework of hidden Markov models, has proven useful for sinusoidal modeling of complex sounds <ref> [145] </ref>. Furthermore, neural networks have been posed as a possible solution to the line tracking problem [146]; nonlinear methods have also proven useful for overcoming some of the difficulties in line tracking [147]. It should be noted that line tracking is sometimes considered part of the analysis rather than synthesis.
Reference: [146] <author> G. J. Adams and R. J. Evans, </author> <title> "Neural networks for frequency line tracking," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 42, </volume> <pages> pp. 936-941, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: This method, which can be cast in the framework of hidden Markov models, has proven useful for sinusoidal modeling of complex sounds [145]. Furthermore, neural networks have been posed as a possible solution to the line tracking problem <ref> [146] </ref>; nonlinear methods have also proven useful for overcoming some of the difficulties in line tracking [147]. It should be noted that line tracking is sometimes considered part of the analysis rather than synthesis. Then, the model includes a partial index or tag for each parameter set in each frame.
Reference: [147] <author> A. Wang, </author> <title> Instantaneous and Frequency-Warped Signal Processing Techniques for Auditory Source Separation. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: Furthermore, neural networks have been posed as a possible solution to the line tracking problem [146]; nonlinear methods have also proven useful for overcoming some of the difficulties in line tracking <ref> [147] </ref>. It should be noted that line tracking is sometimes considered part of the analysis rather than synthesis. Then, the model includes a partial index or tag for each parameter set in each frame. <p> In those cases it would be necessary to first carry out source separation to derive single voice components with well-defined pitches; source separation is a difficult problem that has been addressed in both the signal processing community and in the psychoacoustics literature in considerations of auditory scene analysis <ref> [147, 207] </ref>.
Reference: [148] <author> T. F. Quatieri and R. J. McAulay, </author> <title> "Phase modelling and its application to sinusoidal transform coding," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 3, </volume> <pages> pp. 1713-1715, </pages> <month> April </month> <year> 1986. </year>
Reference-contexts: Typically, interpolation is done using low-order polynomial models such as linear amplitude and cubic total phase; the specific approach of [57] is presented here, but other interpolation methods have been considered <ref> [36, 107, 148, 149, 150] </ref>.
Reference: [149] <author> R. J. McAulay and T. F. Quatieri, </author> <title> "Magnitude-only reconstruction using a sinusoidal speech model," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 2, </volume> <pages> pp. </pages> <address> 27.6.1-27.6.4, </address> <month> March </month> <year> 1984. </year>
Reference-contexts: Typically, interpolation is done using low-order polynomial models such as linear amplitude and cubic total phase; the specific approach of [57] is presented here, but other interpolation methods have been considered <ref> [36, 107, 148, 149, 150] </ref>. <p> Such variations will not be considered here; some related efforts involving zero-phase modeling, or magnitude-only reconstruction, have been discussed in the literature <ref> [149, 204] </ref>. The intent here is primarily to motivate the usefulness of parametric analysis and adaptivity for signal modeling; estimating the pitch parameter leads to simple sinusoidal models, and incorporating perfect reconstruction allows for accurate representation of transients.
Reference: [150] <author> R. J. McAulay and T. F. Quatieri, </author> <title> "Computationally efficient sine-wave synthesis and its application to sinusoidal transform coding," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 1, </volume> <pages> pp. 370-373, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: Typically, interpolation is done using low-order polynomial models such as linear amplitude and cubic total phase; the specific approach of [57] is presented here, but other interpolation methods have been considered <ref> [36, 107, 148, 149, 150] </ref>. <p> This approach provides various computational advantages over general time-domain synthesis [102, 132]. Frequency-domain synthesis was described in <ref> [57, 150, 151] </ref> and more fully presented in [102]. In this section, the algorithm in [102] is explored in detail. 2.5.1 The Algorithm The frequency-domain synthesis algorithm is fundamentally based on the relationship between the DTFT and the DFT and the resulting implications for representing short-time sinusoids. <p> The frequency resolution is thus limited not by the size of the synthesis IDFT but by the oversampling of the motif; in some other incarnations of frequency-domain synthesis, large IDFTs are required to achieve accurate frequency resolution <ref> [57, 150, 151] </ref>. In this algorithm, arbitrary frequency resolution can be achieved by increasing the factor , provided that enough memory is available for storage of the motif.
Reference: [151] <author> M. Tabei and M. Ueda, </author> <title> "FFT multi-frequency synthesizer," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 3, </volume> <pages> pp. 1431-1434, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: This approach provides various computational advantages over general time-domain synthesis [102, 132]. Frequency-domain synthesis was described in <ref> [57, 150, 151] </ref> and more fully presented in [102]. In this section, the algorithm in [102] is explored in detail. 2.5.1 The Algorithm The frequency-domain synthesis algorithm is fundamentally based on the relationship between the DTFT and the DFT and the resulting implications for representing short-time sinusoids. <p> The frequency resolution is thus limited not by the size of the synthesis IDFT but by the oversampling of the motif; in some other incarnations of frequency-domain synthesis, large IDFTs are required to achieve accurate frequency resolution <ref> [57, 150, 151] </ref>. In this algorithm, arbitrary frequency resolution can be achieved by increasing the factor , provided that enough memory is available for storage of the motif.
Reference: [152] <author> M. Goodwin and X. Rodet, </author> <title> "Efficient Fourier synthesis of nonstationary sinu-soids," </title> <booktitle> in Proceedings of the International Computer Music Conference, </booktitle> <pages> pp. 333-334, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Frequency matching and chirp synthesis In addition to phase matching, the synthesis frequencies in adjacent frames can be matched in the overlap region. Such frequency matching can be carried out by synthesizing chirps in each frame instead of constant-frequency sinusoids; the chirp rates are determined by a frequency-matching criterion <ref> [152, 153] </ref>. The caveat in this approach is that the motif must be adjusted to represent a chirp instead of a partial at a fixed frequency, which can be done by precomputing a motif for various chirp rates and interpolating in the precomputed table [152]. <p> The caveat in this approach is that the motif must be adjusted to represent a chirp instead of a partial at a fixed frequency, which can be done by precomputing a motif for various chirp rates and interpolating in the precomputed table <ref> [152] </ref>. Such chirp synthesis, however, has not been shown to be necessary for synthesis of natural signals, so the added cost of tabulation and interpolation is not readily justified.
Reference: [153] <author> M. Goodwin and A. Kogon, </author> <title> "Overlap-add synthesis of nonstationary sinusoids," </title> <booktitle> in Proceedings of the International Computer Music Conference, </booktitle> <pages> pp. 355-356, </pages> <month> Septem-ber </month> <year> 1995. </year>
Reference-contexts: Frequency matching and chirp synthesis In addition to phase matching, the synthesis frequencies in adjacent frames can be matched in the overlap region. Such frequency matching can be carried out by synthesizing chirps in each frame instead of constant-frequency sinusoids; the chirp rates are determined by a frequency-matching criterion <ref> [152, 153] </ref>. The caveat in this approach is that the motif must be adjusted to represent a chirp instead of a partial at a fixed frequency, which can be done by precomputing a motif for various chirp rates and interpolating in the precomputed table [152].
Reference: [154] <author> E. B. George and M. J. T. Smith, </author> <title> "Speech analysis/synthesis and modification using an analysis-by-synthesis/overlap-add sinusoidal model," </title> <journal> IEEE Transactions on Speech and Audio Processing, </journal> <volume> vol. 5, </volume> <pages> pp. 389-406, </pages> <month> September </month> <year> 1997. </year>
Reference-contexts: Here, modifications based on the sinusoidal model are dealt with more explicitly. Specifically, time-scaling, pitch-shifting, and cross-synthesis are considered. The treatment here is quite general; formalized details about modifications in a specific version of the sinusoidal model can be found in the literature <ref> [93, 101, 154, 94] </ref>. <p> In this sense, some improvements in sinusoidal modeling techniques may actually arise from the theory of overcomplete expansions. Note that a procedure similar to matching pursuit is used in <ref> [154] </ref> to estimate sinusoidal components; as discussed in Chapter 6, however, such pursuit does not yield an optimal compact representation, so some improvement can be achieved.
Reference: [155] <author> T. F. Quatieri and R. J. McAulay, </author> <title> "Peak-to-RMS reduction of speech based on a sinusoidal model," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 39, </volume> <pages> pp. 273-288, </pages> <month> February </month> <year> 1991. </year> <month> 254 </month>
Reference-contexts: In addition to denoising, the sinusoidal model has been used for speech enhancement and dynamic range compression. These topics are discussed in the literature <ref> [155, 99] </ref> 2.7.2 Time-Scaling and Pitch-Shifting In Section 1.5.1, it is proposed that signal modifications can be carried out by modifying the components of a model of the signal. The sinusoidal model is particularly amenable to this approach because the modifications of interest are easy to carry out on sinusoids.
Reference: [156] <author> J. Laroche and M. Dolson, </author> <title> "About this phasiness business," </title> <booktitle> in Proceedings of the IEEE ASSP Workshop on Applications of Signal Processing to Audio and Acoustics, </booktitle> <month> October </month> <year> 1997. </year>
Reference-contexts: Computational cost and quality comparisons between such approaches and modifications using the sinusoidal model have not been formally presented, but this is an area of growing interest in the literature and in the electronic music industry <ref> [156] </ref>. The sinusoidal model allows a much wider range of modifications than standard music synthesizers such as samplers, where the signal is constructed from stored sound segments and modifications are limited by the sample-based representation.
Reference: [157] <author> D. Wessel, </author> <month> June </month> <year> 1996. </year> <type> Personal communication. </type>
Reference-contexts: For instance, the formants in the spectral envelope can be adjusted to yield gender modifications; by moving the formants down in frequency, a female voice can be transformed into a male voice, and vice versa <ref> [157] </ref>. Also, the amplitude ratios of odd and even harmonics in a pitched signal can be adjusted.
Reference: [158] <author> G. Wolberg, </author> <title> "Recent advances in image morphing," </title> <booktitle> in Proceedings of Computer Graphics International, </booktitle> <pages> pp. 64-71, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: recently received considerable attention for the application of image morphing, which is carried out by parameterizing the salient features of an original image and a target image (such as edges or prominent regions) and creating a map between these parametric features that can be traversed to synthesize a morphed image <ref> [158] </ref>. 92 Such morphing has also been used in the audio domain to carry out modifications based on the parametric representation provided by the spectrogram, i.e. the squared magnitude of the STFT [129].
Reference: [159] <author> J. S. Marques and L. B. Almeida, </author> <title> "New basis functions for sinusoidal decompositions," </title> <booktitle> in Proceedings of the European Conference on Electrotechnics, </booktitle> <pages> pp. 48-51, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: the discrete wavelet transform. 3.1 Atomic Interpretation of the Sinusoidal Model The partials in the sinusoidal model can be interpreted as expansion functions that comprise an additive decomposition of the signal; this perspective provides a conceptual framework for several considerations of sinusoidal modeling that have been presented in the literature <ref> [97, 159, 160] </ref>. With this notion as a starting point, the sinusoidal model is here interpreted as a time-frequency atomic decomposition. This interpretation sheds some light on the fundamental modeling issues, and indicates a connection between sinusoidal modeling and granular analysis-synthesis.
Reference: [160] <author> J. S. Marques and L. B. Almeida, </author> <title> "Sinusoidal modeling of speech: Representation of unvoiced sounds with narrow-band basis functions," </title> <booktitle> in Proceedings of the European Signal Processing Conference, </booktitle> <volume> vol. 2, </volume> <pages> pp. 891-894, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: the discrete wavelet transform. 3.1 Atomic Interpretation of the Sinusoidal Model The partials in the sinusoidal model can be interpreted as expansion functions that comprise an additive decomposition of the signal; this perspective provides a conceptual framework for several considerations of sinusoidal modeling that have been presented in the literature <ref> [97, 159, 160] </ref>. With this notion as a starting point, the sinusoidal model is here interpreted as a time-frequency atomic decomposition. This interpretation sheds some light on the fundamental modeling issues, and indicates a connection between sinusoidal modeling and granular analysis-synthesis.
Reference: [161] <author> C. van den Branden Lambrecht and M. Karrakchou, </author> <title> "Wavelet packets-based high-resolution spectral estimation," </title> <booktitle> Signal Processing, </booktitle> <volume> vol. 47, </volume> <pages> pp. 135-144, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: The brief description of multiresolution in tree-structured filter banks suggests why such methods might prove useful for processing arbitrary signals, especially if the filter bank is made adaptive; application examples include compression [41, 60] and spectral estimation <ref> [161] </ref>. Rather than focusing on such arbitrary tree-structured filter banks here, however, additional developments of the multiresolution concept will be formulated for the specific case of the discrete wavelet transform. As noted in Figure 3.4, the discrete wavelet transform corresponds to successive iterations on the lowpass branch.
Reference: [162] <author> B. Moore, </author> <title> An Introduction to the Psychology of Hearing. </title> <address> San Diego, CA: </address> <publisher> Academic Press, </publisher> <year> 1997. </year>
Reference-contexts: This is exactly the time-frequency tradeoff provided by the discrete wavelet transform. Since the auditory system exhibits such frequency-dependent resolution, the wavelet approach has been considered for the application of auditory modeling <ref> [162, 163, 164] </ref>. The time-frequency localization in a given subband depends on its depth in the filter bank tree. A mathematical treatment of this is most easily carried out for a specific example. Consider a wavelet filter bank tree of depth three. <p> Note that the methods to be discussed generally involve octave-band filtering, which is perceptually reasonable since the auditory system exhibits roughly constant-Q resolution <ref> [162] </ref>. Such octave-band filtering is useful with regards to the pre-echo problem. As shown in Section 2.6, the pre-echo depends on the window length; by using smaller windows for higher frequencies, the pre-echo becomes proportional to frequency in these filter bank methods.
Reference: [163] <author> J. Benedetto and A. Teolis, </author> <title> "An auditory motivated time-scale signal representation," </title> <booktitle> in Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis, </booktitle> <pages> pp. 49-52, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: This is exactly the time-frequency tradeoff provided by the discrete wavelet transform. Since the auditory system exhibits such frequency-dependent resolution, the wavelet approach has been considered for the application of auditory modeling <ref> [162, 163, 164] </ref>. The time-frequency localization in a given subband depends on its depth in the filter bank tree. A mathematical treatment of this is most easily carried out for a specific example. Consider a wavelet filter bank tree of depth three.
Reference: [164] <author> M. Unser and A. Aldroubi, </author> <title> "A review of wavelets in biomedical applications," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 84, </volume> <pages> pp. 626-638, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: This is exactly the time-frequency tradeoff provided by the discrete wavelet transform. Since the auditory system exhibits such frequency-dependent resolution, the wavelet approach has been considered for the application of auditory modeling <ref> [162, 163, 164] </ref>. The time-frequency localization in a given subband depends on its depth in the filter bank tree. A mathematical treatment of this is most easily carried out for a specific example. Consider a wavelet filter bank tree of depth three.
Reference: [165] <author> P. J. Burt and E. H. Adelson, </author> <title> "The Laplacian pyramid as a compact image code," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. 31, </volume> <pages> pp. 532-540, </pages> <month> April </month> <year> 1983. </year>
Reference-contexts: These were originally introduced for multiresolution image processing <ref> [165] </ref>; the relationship to wavelets was realized shortly thereafter. The decomposition is again based on the idea of successive refinement; the signal is modeled as a sum of a coarse version (the top of the pyramid) plus detail signals. There are several interesting things to note about the pyramid approach.
Reference: [166] <author> N. Fliege and U. Zolzer, </author> <title> "Multi-complementary filter bank," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 3, </volume> <pages> pp. 193-196, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Note also that the synthesis filters are included in the analysis; the result is an analysis-by-synthesis process that can be made to resolve some of the difficulties in wavelet filter banks. For instance, a pyramid-structured filter bank can be defined such that the subband signals are free of aliasing <ref> [166, 167] </ref>. 104 #2 6 - H 0 (z) - "2 -G 0 (z) - k - the analysis filter bank of the pyramid approach, which actually incorporates the synthesis process to ensure perfect reconstruction; synthesis is carried out by a structure similar to the right side of the analysis pyramid. <p> Such wavelet packet vocoders have not been formally considered in the literature. Pyramid structures Octave-band filtering without subband aliasing can be carried out using a pyramid structure <ref> [166] </ref>. As in the pyramid structure of Figure 3.7, the subband representation is oversampled by a factor of two (asymptotically); here, the overcomplete representation provides an improvement over the critically sampled case in that the subbands are free of aliasing.
Reference: [167] <author> M. Schonle, N. Fliege, and U. Zolzer, </author> <title> "Parametric approximation of room impulse responses based on wavelet decomposition," </title> <booktitle> in Proceedings of the IEEE ASSP Workshop on Applications of Signal Processing to Audio and Acoustics, </booktitle> <pages> pp. 68-71, </pages> <month> Octo-ber </month> <year> 1993. </year>
Reference-contexts: Note also that the synthesis filters are included in the analysis; the result is an analysis-by-synthesis process that can be made to resolve some of the difficulties in wavelet filter banks. For instance, a pyramid-structured filter bank can be defined such that the subband signals are free of aliasing <ref> [166, 167] </ref>. 104 #2 6 - H 0 (z) - "2 -G 0 (z) - k - the analysis filter bank of the pyramid approach, which actually incorporates the synthesis process to ensure perfect reconstruction; synthesis is carried out by a structure similar to the right side of the analysis pyramid.
Reference: [168] <author> S. Levine, T. Verma, and J. Smith, "Alias-free, </author> <title> multiresolution sinusoidal modeling for polyphonic wideband audio," </title> <booktitle> in Proceedings of the IEEE ASSP Workshop on Applications of Signal Processing to Audio and Acoustics, </booktitle> <month> October </month> <year> 1997. </year>
Reference-contexts: as inputs to a synthesis filter bank, but this method has difficulties with aliasing cancellation. of pre-echo is seemingly dependent on frequency; for a given partial, the percept depends not on the absolute length of the pre-echo but rather on how many periods of the partial occur in the pre-echo <ref> [168] </ref>. <p> However, the analysis filtering process generally introduces aliasing, so the synthesis must incorporate aliasing cancellation to achieve a reasonable signal reconstruction. This aliasing leads to difficulties in the wavelet case that can be resolved by using a pyramid structure <ref> [168] </ref>; in Section 3.3.2, such issues are circumvented by using a nonsubsampled filter bank. Wavelets Sinusoidal modeling based on wavelet filter banks can be carried out in several ways. <p> This filter bank has recently been proposed as a front end for multiresolution sinusoidal modeling. The resulting algorithm has been shown to be effective for modeling a wide range of audio signals <ref> [168] </ref>. 3.3.2 Nonsubsampled Filter Banks In multirate filter banks, perfect reconstruction is achieved through the process of aliasing cancellation. In other words, there is inherently some degree of aliasing in 107 the subband signals that is cancelled by the synthesis filter bank.
Reference: [169] <author> M. Rodriguez-Hernandez and F. Casajus-Quiros, </author> <title> "Improving time-scale modification of audio signals using wavelets," </title> <booktitle> in Proceedings of the Fifth International Conference on Signal Processing Applications and Technology, </booktitle> <volume> vol. 2, </volume> <pages> pp. 1573-1577, </pages> <month> October </month> <year> 1994. </year> <month> 255 </month>
Reference-contexts: This modeling method thus results in a parametric signal representation with the multiresolution properties of the discrete wavelet transform. As noted in <ref> [169] </ref>, however, this method has difficulties because the sinusoidal model does not provide perfect reconstruction; aliasing cancellation is not guaranteed in the synthesis filter bank because the subbands are modified in the modeling process. <p> This difficulty can be circumvented by reconstructing the output from the subband models without using the synthesis filter bank; the full rate reconstruction is derived directly from the models of the downsampled subbands <ref> [169] </ref>. In this method, it is necessary to explicitly account for aliasing in the sinusoidal parameter estimation; aliasing cancellation is incorporated into the estimation of the subband spectral peaks, but this typically accounts for only the aliasing between adjacent bands [170]. <p> This method has reportedly proven useful for speech coding and time-scaling <ref> [169, 170] </ref>. An earlier hybrid algorithm involving wavelet-like filtering and sinusoidal subband modeling was reported in [171] for the application of source separation; here, the filter bank is oversampled in order to reduce the aliasing limitations.
Reference: [170] <author> D. Anderson, </author> <title> "Speech analysis and coding using a multi-resolution sinusoidal transform," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 2, </volume> <pages> pp. 1037-1040, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: In this method, it is necessary to explicitly account for aliasing in the sinusoidal parameter estimation; aliasing cancellation is incorporated into the estimation of the subband spectral peaks, but this typically accounts for only the aliasing between adjacent bands <ref> [170] </ref>. This method has reportedly proven useful for speech coding and time-scaling [169, 170]. An earlier hybrid algorithm involving wavelet-like filtering and sinusoidal subband modeling was reported in [171] for the application of source separation; here, the filter bank is oversampled in order to reduce the aliasing limitations. <p> This method has reportedly proven useful for speech coding and time-scaling <ref> [169, 170] </ref>. An earlier hybrid algorithm involving wavelet-like filtering and sinusoidal subband modeling was reported in [171] for the application of source separation; here, the filter bank is oversampled in order to reduce the aliasing limitations.
Reference: [171] <author> D. Ellis and B. Vercoe, </author> <title> "A wavelet-based sinusoid model of sound for auditory signal separation," </title> <booktitle> in Proceedings of the International Computer Music Conference, </booktitle> <pages> pp. 86-89, </pages> <year> 1991. </year>
Reference-contexts: This method has reportedly proven useful for speech coding and time-scaling [169, 170]. An earlier hybrid algorithm involving wavelet-like filtering and sinusoidal subband modeling was reported in <ref> [171] </ref> for the application of source separation; here, the filter bank is oversampled in order to reduce the aliasing limitations. Wavelet packets In the approaches discussed above, the subbands of a wavelet filter bank are represented with the sinusoidal model to allow for modifications and processing.
Reference: [172] <author> R. E. Bellman, </author> <title> Dynamic Programming. </title> <publisher> Princeton, </publisher> <address> NJ: </address> <publisher> Princeton University Press, </publisher> <year> 1957. </year>
Reference-contexts: This approach has been applied to wavelet packet and LPC models [41, 60, 134]; after a brief review of dynamic programming and the relevant literature, dynamic segmentation for sinusoidal modeling is considered. Dynamic programming Dynamic programming was first introduced for solving minimum path-length problems <ref> [172] </ref>. The notion is that the computational cost of some classes of problems can be reduced by solving the problems in sequential stages; redundant computation is avoided by phrasing a global decision in terms of successive local decisions.
Reference: [173] <author> L. R. Rabiner and B.-H. Juang, </author> <title> Fundamentals of Speech Recognition. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1993. </year>
Reference-contexts: This type of approach has found widespread use for sequence detection in digital communication, where it is referred to as the Viterbi algorithm [124]. Similar ideas play a role in hidden Markov modeling, which is central to many speech recognition systems <ref> [173, 174] </ref>. 111 The dynamic programming method can be outlined as follows [175]: * Consider the choice of a solution as a sequence of decisions. * Incorporate a metric for the decisions such that the metric for the overall solution is the sum of the metrics for the individual sequential decisions.
Reference: [174] <author> G. White, </author> <title> "Dynamic programming, the viterbi algorithm, and low cost speech recognition," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pp. 413-417, </pages> <month> April </month> <year> 1978. </year>
Reference-contexts: This type of approach has found widespread use for sequence detection in digital communication, where it is referred to as the Viterbi algorithm [124]. Similar ideas play a role in hidden Markov modeling, which is central to many speech recognition systems <ref> [173, 174] </ref>. 111 The dynamic programming method can be outlined as follows [175]: * Consider the choice of a solution as a sequence of decisions. * Incorporate a metric for the decisions such that the metric for the overall solution is the sum of the metrics for the individual sequential decisions.
Reference: [175] <author> D. Bertsimas and J. Tsitsiklis, </author> <title> Introduction to Linear Optimization. </title> <address> Belmont, MA: </address> <publisher> Athena Scientific, </publisher> <year> 1997. </year>
Reference-contexts: Similar ideas play a role in hidden Markov modeling, which is central to many speech recognition systems [173, 174]. 111 The dynamic programming method can be outlined as follows <ref> [175] </ref>: * Consider the choice of a solution as a sequence of decisions. * Incorporate a metric for the decisions such that the metric for the overall solution is the sum of the metrics for the individual sequential decisions. * Assuming that a subset of the necessary decisions has been made,
Reference: [176] <author> Z. Xiong, C. Herley, K. Ramchandran, and M. Orchard, </author> <title> "Flexible time segmentations for time-varying wavelet packets," </title> <booktitle> in Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis, </booktitle> <pages> pp. 9-12, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: In [41], the best wavelet packet in a rate-distortion sense is chosen for the model for each segment; in [60], dynamic segmentation is added to allow for localization of transients. A similar technique was considered in <ref> [176] </ref>. Arbitrary models In addition to the wavelet packet algorithms described, dynamic segmentation and model selection has been applied to image compression [177] and linear predictive coding [134].
Reference: [177] <author> K. Ramchandran, Z. Xiong, K. Asai, and M. Vetterli, </author> <title> "Adaptive transforms for image coding using spatially varying wavelet packets," </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> vol. 5, </volume> <pages> pp. 1197-1204, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: A similar technique was considered in [176]. Arbitrary models In addition to the wavelet packet algorithms described, dynamic segmentation and model selection has been applied to image compression <ref> [177] </ref> and linear predictive coding [134]. As long as the optimality metric is independent and additive across disjoint frames, the dynamic program can be used to efficiently find the optimal segmentation and model selections. <p> In cases where discontinuities across frame boundaries may be objectionable, the candidate models tend to have dependencies on adjacent frames; for instance, in the image processing application, where discontinuities result in blockiness, the candidate models are lapped orthogonal transforms which reduce the blocking artifacts incurred in the quantization <ref> [59, 177] </ref>. Because of the overlap, as mentioned before, the dynamic algorithm is not guaranteed to find the globally optimal model, but in practice the effect of the dependency is negligible.
Reference: [178] <author> M. Goodwin, </author> <title> "Nonuniform filter bank design for audio signal modeling," </title> <booktitle> in Conference Record of the Thirtieth Asilomar Conference on Signals, Systems, and Computers, </booktitle> <volume> vol. 2, </volume> <pages> pp. 1229-1233, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: This chapter discusses a parametric approach for perceptually modeling the noiselike residual for both time-domain and frequency-domain synthesis. Earlier versions of this work have been presented in the literature <ref> [110, 178] </ref>. 4.1 Mixed Models Mixed models have been applied in many signal processing algorithms. <p> The voiced-unvoiced model, especially in the case of a mixed excitation, is similar to the deterministic-plus-stochastic sinusoidal model decomposition proposed in [36, 100] and explored further in <ref> [97, 110, 178, 109, 180] </ref>. The components in these latter models are concurrent in time; the models are thus capable of representing a wide variety of signals. <p> Details of both approaches are given below. 4.3.1 Filter Bank Implementation The filter bank for the residual model is subject to looser design constraints than critically sampled filter banks. In this section, these constraints are discussed and a simple design approach is given; these formulations were originally presented in <ref> [178] </ref>. 138 Perfect reconstruction constraints Perfect reconstruction filter banks were discussed at length in Section 2.2.1; recall that in the subsampled case, time-domain and/or frequency-domain aliasing introduced by the analysis is cancelled in the synthesis filtering process.
Reference: [179] <author> S. Kwon and A. Goldberg, </author> <title> "An enhanced LPC vocoder with no voiced/unvoiced switch," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 32, </volume> <pages> pp. 851-858, </pages> <month> August </month> <year> 1984. </year>
Reference-contexts: The model thus adapts to a nonstationary signal by choosing the appropriate excitation. In some variations of the algorithm, a mixed excitation is used to account for concurrent voiced and unvoiced signal behavior; using a mixture enables modeling of a wider variety of signals than with a switched excitation <ref> [25, 179] </ref>. The voiced-unvoiced model, especially in the case of a mixed excitation, is similar to the deterministic-plus-stochastic sinusoidal model decomposition proposed in [36, 100] and explored further in [97, 110, 178, 109, 180].
Reference: [180] <author> T. Verma, S. Levine, and J. Smith, </author> <title> "TMS: Transient modeling synthesis," </title> <booktitle> in Proceedings of the International Computer Music Conference, </booktitle> <month> September </month> <year> 1997. </year>
Reference-contexts: The voiced-unvoiced model, especially in the case of a mixed excitation, is similar to the deterministic-plus-stochastic sinusoidal model decomposition proposed in [36, 100] and explored further in <ref> [97, 110, 178, 109, 180] </ref>. The components in these latter models are concurrent in time; the models are thus capable of representing a wide variety of signals. <p> Furthermore, the model parameters allow for modifications of the residual; this capability is useful in that if the sinusoidal signal components are modified, the residual should undergo a corresponding transformation prior to synthesis [142]. In <ref> [109, 180] </ref> the models are more elaborate than the one presented in this chapter in that they have specific extensions to model attack artifacts present in the residual, which were discussed in Section 2.6.
Reference: [181] <author> R. Neff, A. Zakhor, and M. Vetterli, </author> <title> "Very low bit rate video coding using matching pursuits," </title> <booktitle> in Proceedings of the SPIE Conference on Visual Communication and Image Processing, </booktitle> <volume> vol. 2308, </volume> <pages> pp. 47-60, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Such modeling of residuals is used in many audio applications as well as in other signal processing algorithms, for instance motion-compensated video coding <ref> [181] </ref>. These approaches are effective because the residuals tend to be "noiselike" in some cases such as LPC, the signal model is indeed designed with the very intent of leaving a white noise residual. In modeling such noiselike residuals, it is important to account for perceptual phenomena. <p> Beyond audio coding, another conceivable application of atomic modeling is to represent the residual of some independent analysis-synthesis process such as the sinusoidal model. An analogy is the compression technique described in <ref> [181] </ref>, where matching pursuit is used to derive a model of the residual in a motion-compensated video coder. In that approach, many simplifications arise due to the structure of the residual and the characteristics of visual perception; these enable real-time analysis.
Reference: [182] <author> H. </author> <title> Helmholtz, On the Sensations of Tone as a Physiological Basis for the Theory of Music. </title> <address> London: Longmans, Green, </address> <publisher> and Co., </publisher> <pages> 1875. </pages>
Reference-contexts: Such filter bank models, which were first introduced in conjunction with the classical theory of resonance <ref> [182] </ref>, are well justified by experimental work ranging from early masking tests for telephony applications [183, 184] to recent investigations in perceptual audio coding, where auditory models are incorporated to achieve transparent compression [8, 7, 9, 10, 11] These auditory filter banks can be characterized in terms of the classical critical
Reference: [183] <author> H. Fletcher, </author> <title> "Physical measurements of audition and their bearing on the theory of hearing," </title> <journal> Bell System Technical Journal, </journal> <volume> vol. 2, </volume> <pages> pp. 145-180, </pages> <month> October </month> <year> 1923. </year>
Reference-contexts: Such filter bank models, which were first introduced in conjunction with the classical theory of resonance [182], are well justified by experimental work ranging from early masking tests for telephony applications <ref> [183, 184] </ref> to recent investigations in perceptual audio coding, where auditory models are incorporated to achieve transparent compression [8, 7, 9, 10, 11] These auditory filter banks can be characterized in terms of the classical critical bandwidths, which were derived in experiments on noise masking and perception of complex sounds; these
Reference: [184] <author> H. Fletcher and W. A. Munson, </author> <title> "Loudness, its definition, measurement, and calculation," </title> <journal> Bell System Technical Journal, </journal> <volume> vol. 12, </volume> <pages> pp. 377-430, </pages> <month> October </month> <year> 1933. </year> <month> 256 </month>
Reference-contexts: Such filter bank models, which were first introduced in conjunction with the classical theory of resonance [182], are well justified by experimental work ranging from early masking tests for telephony applications <ref> [183, 184] </ref> to recent investigations in perceptual audio coding, where auditory models are incorporated to achieve transparent compression [8, 7, 9, 10, 11] These auditory filter banks can be characterized in terms of the classical critical bandwidths, which were derived in experiments on noise masking and perception of complex sounds; these
Reference: [185] <author> E. Zwicker and E. Terhardt, </author> <title> "Analytical expressions for critical-band rate and critical bandwidth as a function of frequency," </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> vol. 68, </volume> <pages> pp. 1523-1525, </pages> <month> November </month> <year> 1980. </year>
Reference-contexts: transparent compression [8, 7, 9, 10, 11] These auditory filter banks can be characterized in terms of the classical critical bandwidths, which were derived in experiments on noise masking and perception of complex sounds; these are generally considered to be the bandwidths of the auditory filters at certain center frequencies <ref> [185] </ref>. Early estimates of the critical bandwidth as a function of center frequency indicate a roughly constant value below 500 Hz and a linear increase for higher frequencies, resulting in the common interpretation of the auditory system as a constant-Q filter bank.
Reference: [186] <author> B. Moore and B. Glasberg, </author> <title> "Suggested formulae for calculating auditory-filter bandwidths and excitation patterns," </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> vol. 74, </volume> <pages> pp. 750-753, </pages> <month> September </month> <year> 1983. </year>
Reference-contexts: More recent experiments suggest that the low-frequency critical bandwidths are quadratically related to the center frequency <ref> [186] </ref>. Expressions for the equivalent rectangular bandwidths of the auditory filters differ somewhat from the bandwidth formulations in classical critical band theory; the difference is depicted in Figure 4.3.
Reference: [187] <author> A. Papoulis, </author> <title> Probability, Random Variables, and Stochastic Processes. </title> <address> New York: </address> <publisher> McGraw-Hill, Inc., </publisher> <year> 1991. </year>
Reference-contexts: The second interpretation is based on equalizing the short-time variances of the subband signal s r [n] and its estimate ^s r [n]. A slightly biased estimate of the variance of s r [n] in the i-th frame is given by <ref> [187] </ref>: var (s r;i [n]) = N n=0 E r (i) : (4.14) The variance of ^s r [n] in the i-th frame can be derived by considering the effect of a linear filter on the autocorrelation of a stochastic process: E f^s r [n]^s r [n + t]g = E
Reference: [188] <author> J. Princen, </author> <title> "The design of nonuniform modulated filter banks," </title> <booktitle> in Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis, </booktitle> <pages> pp. 112-115, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Due to the various advantages of subband processing, such filter bank approaches have been widely dealt with in the literature, but primarily for the case of uniform or octave-band filter banks [2, 20]. Some results on nonuniform critically sampled and oversampled perfect reconstruction filter banks have also been presented <ref> [188, 189, 190, 191, 192] </ref>. The design of a nonuniform filter bank for the noise perception model proposed in Section 4.2 differs from the perfect reconstruction problem discussed above.
Reference: [189] <author> J. Princen, </author> <title> "The design of nonuniform modulated filterbanks," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 43, </volume> <pages> pp. 2550-2560, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: Due to the various advantages of subband processing, such filter bank approaches have been widely dealt with in the literature, but primarily for the case of uniform or octave-band filter banks [2, 20]. Some results on nonuniform critically sampled and oversampled perfect reconstruction filter banks have also been presented <ref> [188, 189, 190, 191, 192] </ref>. The design of a nonuniform filter bank for the noise perception model proposed in Section 4.2 differs from the perfect reconstruction problem discussed above.
Reference: [190] <author> K. Nayebi, T. P. Barnwell, and M. J. T. Smith, </author> <title> "The design of perfect reconstruction nonuniform band filter banks," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 3, </volume> <pages> pp. 1781-1784, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Due to the various advantages of subband processing, such filter bank approaches have been widely dealt with in the literature, but primarily for the case of uniform or octave-band filter banks [2, 20]. Some results on nonuniform critically sampled and oversampled perfect reconstruction filter banks have also been presented <ref> [188, 189, 190, 191, 192] </ref>. The design of a nonuniform filter bank for the noise perception model proposed in Section 4.2 differs from the perfect reconstruction problem discussed above.
Reference: [191] <author> J. Kovacevic and M. Vetterli, </author> <title> "Perfect reconstruction filter banks with rational sampling rate changes," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 3, </volume> <pages> pp. 1785-1788, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Due to the various advantages of subband processing, such filter bank approaches have been widely dealt with in the literature, but primarily for the case of uniform or octave-band filter banks [2, 20]. Some results on nonuniform critically sampled and oversampled perfect reconstruction filter banks have also been presented <ref> [188, 189, 190, 191, 192] </ref>. The design of a nonuniform filter bank for the noise perception model proposed in Section 4.2 differs from the perfect reconstruction problem discussed above.
Reference: [192] <author> J. Li, T. Nguyen, and S. Tantaratana, </author> <title> "A simple design method for nonuniform mul-tirate filter banks," </title> <booktitle> in Conference Record of the Twenty-Ninth Asilomar Conference on Signals, Systems, and Computers, </booktitle> <volume> vol. 2, </volume> <pages> pp. 1015-1019, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Due to the various advantages of subband processing, such filter bank approaches have been widely dealt with in the literature, but primarily for the case of uniform or octave-band filter banks [2, 20]. Some results on nonuniform critically sampled and oversampled perfect reconstruction filter banks have also been presented <ref> [188, 189, 190, 191, 192] </ref>. The design of a nonuniform filter bank for the noise perception model proposed in Section 4.2 differs from the perfect reconstruction problem discussed above.
Reference: [193] <author> A. V. Oppenheim and R. W. Schafer, </author> <title> Discrete-Time Signal Processing. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall, </publisher> <year> 1989. </year>
Reference-contexts: realizable FIR filter bank that satisfies the subband perfect reconstruction constraint can be derived from the ideal filter bank by using the window method of FIR filter design; this method suggests that a realizable FIR approximation of an ideal filter can be obtained by time-windowing the ideal filter's impulse response <ref> [193] </ref>. <p> One method of resampling uses the familiar upsampling and downsampling operations. Changing the sampling rate of a sequence x [n] from f s to P Q f s is carried out by upsampling by P and then downsampling by Q, with some appropriate intermediate filtering to prevent aliasing <ref> [193] </ref>. The resulting sequence is P Q times as long as x [n]. A detailed consideration of this type of approach can be found in [200].
Reference: [194] <author> J. O. Smith, </author> <month> July </month> <year> 1994. </year> <type> Personal communication. </type>
Reference-contexts: Essentially, this condition holds because the signal is time-limited; the notion is analogous to the familiar result that a bandlimited signal can be perfectly reconstructed from an appropriate set of samples <ref> [194] </ref>. This issue is mostly an aside from the discussion of residual modeling, so it will not be considered further. Normalization To achieve perceptual losslessness in a deterministic-plus-stochastic or reconstruction-plus-residual model, it is necessary that the relative perceptual strengths of the two components be preserved by the system.
Reference: [195] <author> G. Evangelista, </author> <title> "Pitch-synchronous wavelet representations of speech and music signals," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 41, </volume> <pages> pp. 3313-3330, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: In cases where harmonic structure is prevalent, i.e. in periodic and pseudo-periodic signals, this can be exploited to improve the signal model with respect to data reduction in that only the fundamental frequency need be recorded. In this chapter, a pitch-synchronous signal representation proposed in <ref> [195] </ref> is considered; similar representations have been applied in prototype waveform speech coders [56]. <p> This segmentation leads to a pitch-synchronous representation similar to the one proposed in <ref> [195] </ref>; this representation will prove useful for signal modeling. 5.2.1 Segmentation In Section 4.1, mixed models of signals were discussed; this motivated considering the sinusoidal model in terms of a deterministic-plus-stochastic decomposition where the stochastic component accounted for signal features not well-represented by the sinusoidal model. <p> There are several noteworthy issues regarding the PSR. For one, the matrix need not be constructed via resampling. Alternatively, the period lengths can be equalized by zero-padding all of the period signals to the maximum period length <ref> [195] </ref> or by viewing 160 each period as an impulse response and carrying out an extension procedure such as in pitch-synchronous overlap-add methods [90]. These approaches, however, do not yield the same smoothness as resampling; they do not necessarily preserve the zero-crossing synchronization and discontinuities may result in the reconstruction. <p> Note that modifications 167 which involve resampling are accelerated in the pitch-synchronous sinusoidal model because the Fourier series representation can directly be used for resampling as described in Section 5.2.2. 5.4 Pitch-Synchronous Wavelet Transforms This section considers applying the wavelet transform in a pitch-synchronous fashion as originally proposed in <ref> [205, 195] </ref>. The pitch-synchronous wavelet transform (PSWT) is developed as an extension of the wavelet transform that is suitable for pseudo-periodic signals; the underlying signal models are discussed for both cases. <p> These are described below; the actual expansion functions in the various approaches are rigorously formalized in <ref> [205, 195] </ref>. Comb wavelets Based on the discussion on the spectral effect of upsampling a wavelet filter bank, a direct implementation of a pitch-synchronous wavelet transform simply involves upsampling by the pitch period P . <p> Figures 5.3 and 5.6 can be compared to indicate the relative performance of the DWT and the PSWT for modeling or estimation of pitched signals. Coding gain A full treatment of the multiplexed wavelet transform for signal coding is given in <ref> [195, 206] </ref>. The fundamental reason for the coding gain is that the periodic-plus-details signal model is much more appropriate for signals with pseudo-periodic behavior than standard lowpass-plus-details models. For the same amount of model data, the PSWT model is more accurate than the DWT model. <p> Similarly, the detail signals have a correspondence to the stochastic component of the sinusoidal model. Given this observation, it is reasonable to consider modeling the detail signals as a noiselike residual. Such approaches are discussed in <ref> [195] </ref>. This analogy between the sinusoidal model and the PSWT, of course, is limited to pseudo-periodic signals; for signals consisting of evolving harmonics plus noise, the deterministic-plus-stochastic (i.e. reconstruction-plus-residual) models are similar.
Reference: [196] <author> W. Hess, </author> <title> Pitch Determination of Speech Signals. </title> <address> New York, NY: </address> <publisher> Springer-Verlag, </publisher> <year> 1983. </year>
Reference-contexts: This issue has been explored most extensively in the speech and audio processing communities <ref> [1, 53, 196, 197, 198] </ref>; the terminology is thus taken from these fields, but the methods apply to any pseudo-periodic signals. <p> For a more detailed discussion of pitch detection algorithms, the reader is referred to <ref> [1, 53, 196] </ref>. For the purposes of this chapter, it is assumed that a reliable pitch detection algorithm is available, and that the algorithm is capable of acknowledging, perhaps according to some heuristic threshold, when no pitch can be reasonably assessed to the signal.
Reference: [197] <author> Y. Medan, E. Yair, and D. Chazan, </author> <title> "Super resolution pitch determination of speech signals," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 39, </volume> <pages> pp. 40-48, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: This issue has been explored most extensively in the speech and audio processing communities <ref> [1, 53, 196, 197, 198] </ref>; the terminology is thus taken from these fields, but the methods apply to any pseudo-periodic signals. <p> Various fixes have been proposed to account for these problems; for instance, based on the a priori knowledge that a typical musical signal does not have impulsive pitch discontinuities, a median filter can be applied to the pitch estimates to remove outliers and provide a more robust estimate <ref> [1, 53, 197] </ref>. For a more detailed discussion of pitch detection algorithms, the reader is referred to [1, 53, 196]. <p> To achieve this correspondence, pitch estimates from a standard algorithm can be "phase-locked" to the signal as proposed below. First, it is assumed that a robust pitch detector such as the one described in <ref> [197] </ref> is used to generate a moving estimate of the pitch period; the output of the pitch detector is specifically assumed to consist of pitch periods and their corresponding time indices. <p> It is assumed that initial pitch period estimates, denoted by P (iT ), are derived by a standard pitch detection algorithm such as the one described in <ref> [197] </ref>. The itemized description in the text gives additional details related to the operations carried out by the various blocks.
Reference: [198] <author> C. Wendt and A. Petropulu, </author> <title> "Pitch determination and speech segmentation using the discrete wavelet transform," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 2, </volume> <pages> pp. 45-48, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: This issue has been explored most extensively in the speech and audio processing communities <ref> [1, 53, 196, 197, 198] </ref>; the terminology is thus taken from these fields, but the methods apply to any pseudo-periodic signals. <p> Furthermore, it has also been reported that zero crossings are of physical significance in speech signals in that they are linked to instances when the glottis is closed <ref> [198] </ref>. 156 NO - save [iT ; ^ P (iT ) = 0] i = i + 1 ? t 0 = PSZC after iT Estimate P (t 0 ) YES NO t 1 = PSZC closest to t 0 + P (t 0 ) ? save [t 0 ; ^ <p> The itemized description in the text gives additional details related to the operations carried out by the various blocks. Some wavelet-based algorithms for pitch estimation based on zero crossings have been discussed in the literature <ref> [199, 198] </ref>; the corrective phase-locking described above is adhered to in this treatment, however, since it is simple and allows for a quick synchronization of pitch period estimates to zero crossings in the signal. 5.2 Pitch-Synchronous Signal Representation Using the time points from the simple phase-locked pitch detector presented above, the
Reference: [199] <author> S. Mallat and S. Zhong, </author> <title> "Characterization of signals from multiscale edges," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> vol. 14, </volume> <pages> pp. 710-732, </pages> <month> July </month> <year> 1992. </year> <month> 257 </month>
Reference-contexts: The itemized description in the text gives additional details related to the operations carried out by the various blocks. Some wavelet-based algorithms for pitch estimation based on zero crossings have been discussed in the literature <ref> [199, 198] </ref>; the corrective phase-locking described above is adhered to in this treatment, however, since it is simple and allows for a quick synchronization of pitch period estimates to zero crossings in the signal. 5.2 Pitch-Synchronous Signal Representation Using the time points from the simple phase-locked pitch detector presented above, the
Reference: [200] <author> J. O. Smith and P. Gossett, </author> <title> "A flexible sample-rate conversion method," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 2, </volume> <pages> pp. </pages> <address> 19.4.1-19.4.4, </address> <month> March </month> <year> 1984. </year>
Reference-contexts: The resulting sequence is P Q times as long as x [n]. A detailed consideration of this type of approach can be found in <ref> [200] </ref>. In the pitch-synchronous methods of this chapter, resampling is carried out for each pitch period of the signal so as to remove slight pitch variations; this enables construction of the pitch-synchronous signal representation discussed in the next section, which will prove useful for signal coding and modification.
Reference: [201] <author> J. Laroche, </author> <month> July </month> <year> 1996. </year> <type> Personal communication. </type>
Reference-contexts: An alternative method based on the discrete Fourier transform is more appropriate for this resampling application since it introduces fewer artifacts at signal boundaries. Resampling using the DFT is carried out as follows <ref> [201] </ref>. For a pitch period x i [n] of length Q i , a DFT of size Q i is computed, unless of course Q i is equal to the target period P .
Reference: [202] <author> F. F. Lee, </author> <title> "Time compression and expansion of speech by the sampling method," </title> <journal> Journal of the Audio Engineering Society, </journal> <volume> vol. 20, </volume> <pages> pp. 738-742, </pages> <month> November </month> <year> 1972. </year>
Reference-contexts: First, time-scaling can be carried out by deleting or repeating pitch period grains for time-scale compression or expansion, respectively; this can be done either in a structured fashion or pseudo-randomly. In speech processing and granular synthesis applications, similar techniques are referred to as deletion and repetition <ref> [202, 203] </ref>. Note that the time-scaling by deletion/repetition is accomplished without pitch-shifting, and that it is inherently made possible by the zero-crossing synchronization of the PSR; without this imposed smoothness of the model, discontinuities would result in the modified signal.
Reference: [203] <author> M. Asi and B. Saleh, </author> <title> "Filter-bank approach to time scaling of speech," </title> <booktitle> in Proceedings of the European Signal Processing Conference, </booktitle> <volume> vol. 2, </volume> <pages> pp. 1343-1346, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: First, time-scaling can be carried out by deleting or repeating pitch period grains for time-scale compression or expansion, respectively; this can be done either in a structured fashion or pseudo-randomly. In speech processing and granular synthesis applications, similar techniques are referred to as deletion and repetition <ref> [202, 203] </ref>. Note that the time-scaling by deletion/repetition is accomplished without pitch-shifting, and that it is inherently made possible by the zero-crossing synchronization of the PSR; without this imposed smoothness of the model, discontinuities would result in the modified signal.
Reference: [204] <author> T. F. Quatieri and R. J. McAulay, </author> <title> "Phase coherence in speech reconstruction for enhancement and coding applications," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 1, </volume> <pages> pp. 207-210, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: Such variations will not be considered here; some related efforts involving zero-phase modeling, or magnitude-only reconstruction, have been discussed in the literature <ref> [149, 204] </ref>. The intent here is primarily to motivate the usefulness of parametric analysis and adaptivity for signal modeling; estimating the pitch parameter leads to simple sinusoidal models, and incorporating perfect reconstruction allows for accurate representation of transients.
Reference: [205] <author> G. Evangelista, </author> <title> "Comb and multiplexed wavelet transforms and their applications to signal processing," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 42, </volume> <pages> pp. 292-303, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: Note that modifications 167 which involve resampling are accelerated in the pitch-synchronous sinusoidal model because the Fourier series representation can directly be used for resampling as described in Section 5.2.2. 5.4 Pitch-Synchronous Wavelet Transforms This section considers applying the wavelet transform in a pitch-synchronous fashion as originally proposed in <ref> [205, 195] </ref>. The pitch-synchronous wavelet transform (PSWT) is developed as an extension of the wavelet transform that is suitable for pseudo-periodic signals; the underlying signal models are discussed for both cases. <p> These are described below; the actual expansion functions in the various approaches are rigorously formalized in <ref> [205, 195] </ref>. Comb wavelets Based on the discussion on the spectral effect of upsampling a wavelet filter bank, a direct implementation of a pitch-synchronous wavelet transform simply involves upsampling by the pitch period P .
Reference: [206] <author> G. Evangelista, </author> <title> "The coding gain of multiplexed wavelet transforms," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 44, </volume> <pages> pp. 1681-1692, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: Figures 5.3 and 5.6 can be compared to indicate the relative performance of the DWT and the PSWT for modeling or estimation of pitched signals. Coding gain A full treatment of the multiplexed wavelet transform for signal coding is given in <ref> [195, 206] </ref>. The fundamental reason for the coding gain is that the periodic-plus-details signal model is much more appropriate for signals with pseudo-periodic behavior than standard lowpass-plus-details models. For the same amount of model data, the PSWT model is more accurate than the DWT model.
Reference: [207] <author> A. Bregman, </author> <title> Auditory Scene Analysis: The Perceptual Organization of Sound. </title> <address> Cam-bridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: In those cases it would be necessary to first carry out source separation to derive single voice components with well-defined pitches; source separation is a difficult problem that has been addressed in both the signal processing community and in the psychoacoustics literature in considerations of auditory scene analysis <ref> [147, 207] </ref>.
Reference: [208] <author> S. Jalaleddine et al., </author> <title> "ECG data compression techniques a unified approach," </title> <journal> IEEE Transactions on Biomedical Engineering, </journal> <volume> vol. 37, </volume> <pages> pp. 329-343, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Various methods of ambulatory ECG signal compression have been presented in the literature; these rely on either the redundancy between neighboring samplings of the signal or the redundancy between adjacent periods <ref> [208, 209] </ref>. Recently, a method exploiting both forms of redundancy was proposed [37]; here, the signal is segmented into pulses and arranged into a structure resembling a PSR matrix.
Reference: [209] <author> J. Lipeikiene, </author> <title> "Data compression methods. application to ECG," </title> <journal> Informatica, </journal> <volume> vol. 4, no. </volume> <pages> 1-2, pp. 57-80, </pages> <year> 1993. </year>
Reference-contexts: Various methods of ambulatory ECG signal compression have been presented in the literature; these rely on either the redundancy between neighboring samplings of the signal or the redundancy between adjacent periods <ref> [208, 209] </ref>. Recently, a method exploiting both forms of redundancy was proposed [37]; here, the signal is segmented into pulses and arranged into a structure resembling a PSR matrix.
Reference: [210] <author> L. Baghai-Ravary, S. Beet, and M. Tokhi, </author> <title> "The two-dimensional discrete cosine transform applied to speech data," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 1, </volume> <pages> pp. 244-247, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Both this DCT-based ECG compression algorithm and the PSWT itself are reminiscent of several other efforts involving multidimensional processing of one-dimensional signals, for instance image processing of audio <ref> [128, 210] </ref>. 5.6 Conclusion For pseudo-periodic signals, the redundancies between adjacent periods can be exploited to achieve compact signal models. This notion was the basic theme of this chapter, which opened with a discussion of estimation of signal periodicity and construction of a pitch-synchronous representation.
Reference: [211] <author> S. Qian and D. Chen, </author> <title> "Signal representation using adaptive normalized Gaussian functions," </title> <booktitle> Signal Processing, </booktitle> <volume> vol. 36, </volume> <pages> pp. 1-11, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: This shortcoming results from the attempt to model arbitrary signals in terms of a limited and fixed set of functions. To overcome the difficulties of basis expansions, signals can instead be modeled using an overcomplete set of atoms that exhibits a wide range of time-frequency behaviors <ref> [38, 68, 42, 43, 211] </ref>. Such overcomplete expansions allow for compact representation of arbitrary signals for the sake of compression or analysis [38, 92]. <p> Such approaches can be roughly grouped into two categories: parallel methods such as the method of frames [63, 70], basis pursuit [42, 43], and FOCUSS [68, 67], in which computation of the various expansion components is coupled; and, sequential methods such as matching pursuit and its variations <ref> [38, 68, 211, 212, 213, 214] </ref>, in which models are computed one component at a time. All of these methods can be interpreted as approaches to solving inverse problems. <p> When a well-designed overcom-plete dictionary is used in matching pursuit, the nonlinear nature of the algorithm leads to compact signal-adaptive models <ref> [38, 211, 92] </ref>. A dictionary can be likened to the matrix D in Equation (6.2) by considering the atoms to be the matrix columns; then, matching pursuit can be interpreted as an approach for computing sparse approximate solutions to inverse problems [69, 215].
Reference: [212] <author> Y. Pati, R. Rezaiifar, and P. Krishnaprasad, </author> <title> "Orthogonal matching pursuit: Recursive function approximation with applications to wavelet decomposition," </title> <booktitle> in Conference Record of the Twenty-Seventh Asilomar Conference on Signals, Systems, and Computers, </booktitle> <volume> vol. 1, </volume> <pages> pp. 40-44, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: Such approaches can be roughly grouped into two categories: parallel methods such as the method of frames [63, 70], basis pursuit [42, 43], and FOCUSS [68, 67], in which computation of the various expansion components is coupled; and, sequential methods such as matching pursuit and its variations <ref> [38, 68, 211, 212, 213, 214] </ref>, in which models are computed one component at a time. All of these methods can be interpreted as approaches to solving inverse problems. <p> This problem of readmission is addressed in orthogonal matching pursuit and its variations; the fundamental idea is to explicitly orthogonalize the functions chosen for the expansion. Backward orthogonal matching pursuit Orthogonal matching pursuit is a basic variation of the matching pursuit algorithm <ref> [212] </ref>. <p> The correlation metric for atom selection, however, is based on the residual signal as in one-dimensional pursuit. Note that the inverse i G i can be computed recursively using the matrix inversion lemma and the inverse i1 G i1 computed at the previous stage <ref> [212] </ref>. At any given stage of an orthogonal pursuit, derivation of the new set of expansion coefficients can be interpreted as a Gram-Schmidt orthogonalization carried out on the new atom chosen for the expansion. <p> The following section discusses a method which employs the Gram-Schmidt procedure in a different way than the backward pursuit described above. Forward orthogonal matching pursuit In orthogonal matching pursuit as proposed in <ref> [212] </ref>, which corresponds to the backward pursuit described above, the atom g i is chosen irrespective of the subspace spanned by the first i 1 atoms, i.e. the column space of G i1 , and then orthogonalization is carried out. <p> Given the preceding observation about the impact of computation and this supporting example, it is reasonable to assert that computation considerations are important in model comparisons. Examples of computation-distortion tradeoffs are given for the case of orthogonal matching pursuit in <ref> [212] </ref>; a preliminary treatment of general computation-rate-distortion theory is given in [224]. 6.3 Time-Frequency Dictionaries Matching pursuit yields a sparse approximate signal decomposition based on a dictionary of expansion functions. In a compact model, the atoms in the expansion necessarily correspond to basic signal features. <p> translation: g fs;!;t g (t) = p g n t This definition can be extended to discrete time by a sampling argument as in [38]; fundamentally, the extension simply indicates that Gabor atoms can be represented in discrete 1 Atoms corresponding to wavelet and cosine packets have also been considered <ref> [42, 212] </ref>. 199 derived from a symmetric window by scaling, modulation, and translation operations as described in Equation (6.39). time as g fs;!;t g [n] = f s [n t 0 ]e j!(nt ) ; (6.40) where f s [n] is a unit-norm window function supported on a scale s.
Reference: [213] <author> S. Jaggi et al., </author> <title> "High resolution pursuit for feature extraction," </title> <type> Tech. Rep. </type> <institution> LIDS-P-2371, MIT, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: Such approaches can be roughly grouped into two categories: parallel methods such as the method of frames [63, 70], basis pursuit [42, 43], and FOCUSS [68, 67], in which computation of the various expansion components is coupled; and, sequential methods such as matching pursuit and its variations <ref> [38, 68, 211, 212, 213, 214] </ref>, in which models are computed one component at a time. All of these methods can be interpreted as approaches to solving inverse problems. <p> The plots show (a) a damped sinusoidal signal, (b) the first atom chosen from a symmetric Gabor dictionary by matching pursuit, and (c) the residual. Note the pre-echo in the atomic model and the artifact in the residual at the onset time. proposed in <ref> [213, 225] </ref>, where symmetric atoms are generally still used but the selection metric is modified so that atoms that introduce drastic artifacts are not chosen for the decomposition. Fundamentally, however, symmetric functions are simply not well-suited for modeling asymmetric events.
Reference: [214] <author> H. Feichtinger, A. Turk, and T. Strohmer, </author> <title> "Hierarchical parallel matching pursuit," </title> <booktitle> in Proceedings of the SPIE The International Society for Optical Engineering, </booktitle> <volume> vol. 2302, </volume> <pages> pp. 222-232, </pages> <month> July </month> <year> 1994. </year> <month> 258 </month>
Reference-contexts: Such approaches can be roughly grouped into two categories: parallel methods such as the method of frames [63, 70], basis pursuit [42, 43], and FOCUSS [68, 67], in which computation of the various expansion components is coupled; and, sequential methods such as matching pursuit and its variations <ref> [38, 68, 211, 212, 213, 214] </ref>, in which models are computed one component at a time. All of these methods can be interpreted as approaches to solving inverse problems. <p> In the literature, speech coding using orthogonal matching pursuit has been discussed [220]. Furthermore, a number of refinements of the algorithm have been proposed and explored <ref> [68, 214] </ref>. Such refinements basically involve different ways in which orthogonality is imposed or exploited; for instance, orthogonal components can be evaluated simultaneously as in basis expansions [214]. The following section discusses a method which employs the Gram-Schmidt procedure in a different way than the backward pursuit described above. <p> Furthermore, a number of refinements of the algorithm have been proposed and explored [68, 214]. Such refinements basically involve different ways in which orthogonality is imposed or exploited; for instance, orthogonal components can be evaluated simultaneously as in basis expansions <ref> [214] </ref>. The following section discusses a method which employs the Gram-Schmidt procedure in a different way than the backward pursuit described above.
Reference: [215] <author> M. Goodwin, </author> <title> "Matching pursuit with damped sinusoids," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 3, </volume> <pages> pp. 2037-2040, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: An SVD-based expansion is by nature not sparse, and thresholding small expansion coefficients to improve the sparsity is not a useful approach <ref> [215, 69] </ref>. A more appropriate paradigm for deriving an overcomplete expansion is to apply an algorithm specifically designed to arrive at sparse solutions. Because of the complexity of the search, however, it is not computationally feasible to derive an optimal sparse expansion that perfectly models a signal. <p> A dictionary can be likened to the matrix D in Equation (6.2) by considering the atoms to be the matrix columns; then, matching pursuit can be interpreted as an approach for computing sparse approximate solutions to inverse problems <ref> [69, 215] </ref>. For an overcomplete dictionary, the linear system is underdetermined and an infinite number of solutions exist. As discussed in Section 6.1.2, sparse approximate solutions are useful for signal analysis, compression, and enhancement. <p> As discussed in Section 6.1.2, sparse approximate solutions are useful for signal analysis, compression, and enhancement. Since such solutions are not provided by traditional linear methods such as the SVD, a nonlinear approximation paradigm such as matching pursuit is called for <ref> [38, 215, 69, 92] </ref>. 6.2.1 One-Dimensional Pursuit The greedy iteration in the matching pursuit algorithm is carried out as follows. First, the atom that best approximates the signal is chosen, where the two-norm is used as the approximation metric because of its mathematical convenience.
Reference: [216] <author> A. Gersho and R. M. Gray, </author> <title> Vector Quantization and Signal Compression. </title> <address> Boston, MA: </address> <publisher> Kluwer Academic Publishers, </publisher> <year> 1992. </year>
Reference-contexts: This is discussed further in Section 6.4.3. It should be noted that matching pursuit is similar to some forms of vector quantization <ref> [216] </ref> and is related to the projection pursuit method investigated earlier 192 in the field of statistics for the task of finding compact models for data sets [217, 218]. <p> This connection is briefly explored in [39]; given the extent of work that has been devoted to vector quantization techniques, further investigations of applications to time-frequency atomic models are clearly merited <ref> [216] </ref>. Variations of matching pursuit Several variations of matching pursuit are described in Chapter 6; it is argued that comparison of such approaches calls for computation-rate-distortion considerations. Preliminary formalizations of such tradeoffs have appeared in the literature, but there are many open questions [224].
Reference: [217] <author> P. Huber, </author> <title> "Projection pursuit," </title> <journal> Annals of Statistics, </journal> <volume> vol. 13, no. 2, </volume> <pages> pp. 435-475, </pages> <year> 1985. </year>
Reference-contexts: This is discussed further in Section 6.4.3. It should be noted that matching pursuit is similar to some forms of vector quantization [216] and is related to the projection pursuit method investigated earlier 192 in the field of statistics for the task of finding compact models for data sets <ref> [217, 218] </ref>.
Reference: [218] <author> J. Friedman and W. Stuetzle, </author> <title> "Projection pursuit regression," </title> <journal> Journal of the American Statistical Assocation, </journal> <volume> vol. 76, </volume> <pages> pp. 817-823, </pages> <year> 1981. </year>
Reference-contexts: This is discussed further in Section 6.4.3. It should be noted that matching pursuit is similar to some forms of vector quantization [216] and is related to the projection pursuit method investigated earlier 192 in the field of statistics for the task of finding compact models for data sets <ref> [217, 218] </ref>.
Reference: [219] <author> G. Golub and C. V. Loan, </author> <title> Matrix Computations. </title> <address> Baltimore, MD: </address> <publisher> Johns Hopkins Press, </publisher> <year> 1983. </year>
Reference-contexts: Furthermore, such greedy approximation methods have been considered in linear algebra applications for some time <ref> [69, 219] </ref>. 6.2.2 Subspace Pursuit Though searching for the optimal high-dimensional subspace is not reasonable, it is worthwhile to consider the related problem of finding an optimal low-dimension subspace at each iteration of the pursuit, especially if the subspaces under consideration exhibit a simplifying structure.
Reference: [220] <author> R. Rezaiifar and H. Jafarkhani, </author> <title> "Wavelet based speech coding using orthogonal matching pursuit," </title> <booktitle> in Proceedings of the Twenty-Ninth Annual Conference on Information Sciences and Systems, </booktitle> <pages> pp. 88-92, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: This projection operation minimizes the error of the residual for approximating the signal using those particular expansion functions; this approximation is however not necessarily a globally optimal sparse model. In the literature, speech coding using orthogonal matching pursuit has been discussed <ref> [220] </ref>. Furthermore, a number of refinements of the algorithm have been proposed and explored [68, 214]. Such refinements basically involve different ways in which orthogonality is imposed or exploited; for instance, orthogonal components can be evaluated simultaneously as in basis expansions [214]. <p> One fundamental advance required for application of atomic modeling to audio coding is the ability to carry out matching pursuit effectively in a frame-by-frame manner so that signals of arbitrary length can be processed. Matching pursuit using fixed frames has been described in the literature <ref> [220] </ref>, but such an approach is unable to identify or model atomic components that overlap frame boundaries. There are several additional noteworthy points regarding atomic models and audio coding. First, an atomic signal model would allow complex time-frequency masking principles to be incorporated in the coding scheme.
Reference: [221] <author> R. A. DeVore and V. N. Temlyakov, </author> <title> "Some remarks on greedy algorithms," </title> <booktitle> Advances in Computational Mathematics, </booktitle> <volume> vol. 5, no. </volume> <pages> 2-3, pp. 173-187, </pages> <year> 1996. </year>
Reference-contexts: For the case of arbitrary i-term decompositions, however, no absolute comparison can be made between the algorithms. While error bounds can be established for the various greedy approximations, the relative performance for a given signal cannot be guaranteed a priori since the algorithms use different strategies for selecting atoms <ref> [221, 222, 223] </ref>. Useful predictive comparisons of the algorithms can be carried out using ensemble results based on random dictionaries [68].
Reference: [222] <author> R. A. DeVore and V. N. Temlyakov, </author> <title> "Nonlinear approximation by trigonometric sums," </title> <journal> The Journal of Fourier Analysis and Applications, </journal> <volume> vol. 2, no. 1, </volume> <pages> pp. 173-187, </pages> <year> 1995. </year>
Reference-contexts: For the case of arbitrary i-term decompositions, however, no absolute comparison can be made between the algorithms. While error bounds can be established for the various greedy approximations, the relative performance for a given signal cannot be guaranteed a priori since the algorithms use different strategies for selecting atoms <ref> [221, 222, 223] </ref>. Useful predictive comparisons of the algorithms can be carried out using ensemble results based on random dictionaries [68].
Reference: [223] <author> Z. Landau, </author> <month> December </month> <year> 1996. </year> <type> Personal communication. </type>
Reference-contexts: For the case of arbitrary i-term decompositions, however, no absolute comparison can be made between the algorithms. While error bounds can be established for the various greedy approximations, the relative performance for a given signal cannot be guaranteed a priori since the algorithms use different strategies for selecting atoms <ref> [221, 222, 223] </ref>. Useful predictive comparisons of the algorithms can be carried out using ensemble results based on random dictionaries [68].
Reference: [224] <author> V. Goyal and M. Vetterli, </author> <title> "Computation-distortion characteristics of block transform coding," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 4, </volume> <pages> pp. 2729-2732, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: Examples of computation-distortion tradeoffs are given for the case of orthogonal matching pursuit in [212]; a preliminary treatment of general computation-rate-distortion theory is given in <ref> [224] </ref>. 6.3 Time-Frequency Dictionaries Matching pursuit yields a sparse approximate signal decomposition based on a dictionary of expansion functions. In a compact model, the atoms in the expansion necessarily correspond to basic signal features. <p> Variations of matching pursuit Several variations of matching pursuit are described in Chapter 6; it is argued that comparison of such approaches calls for computation-rate-distortion considerations. Preliminary formalizations of such tradeoffs have appeared in the literature, but there are many open questions <ref> [224] </ref>. With computation concerns in mind, it is of interest to consider simplifications of matching pursuit. For instance, in [38], pursuit based on small subdictionaries is discussed; if the subdictionaries are well-chosen, this helps to reduce the computational requirements without substantially affecting the convergence of 229 the atomic model.
Reference: [225] <author> R. Gribonval et al., </author> <title> "Analysis of sound signals with high resolution matching pursuit," </title> <booktitle> in Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis, </booktitle> <pages> pp. 125-128, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: The plots show (a) a damped sinusoidal signal, (b) the first atom chosen from a symmetric Gabor dictionary by matching pursuit, and (c) the residual. Note the pre-echo in the atomic model and the artifact in the residual at the onset time. proposed in <ref> [213, 225] </ref>, where symmetric atoms are generally still used but the selection metric is modified so that atoms that introduce drastic artifacts are not chosen for the decomposition. Fundamentally, however, symmetric functions are simply not well-suited for modeling asymmetric events.
Reference: [226] <author> B. Friedlander and A. Zeira, </author> <title> "Oversampled Gabor representation for transient signals," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 43, </volume> <pages> pp. 2088-2094, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: Several approaches in the literature have dealt with time-frequency atoms having exponential behavior. In <ref> [226] </ref>, damped sinusoids are used to provide a time-frequency representation in which transients are identifiable. In the application outlined in [226], some prior knowledge of the damping factor is assumed, which is reasonable for detection applications but inappropriate for deriving decompositions of arbitrary signals; extensions of the algorithm, however, may prove <p> Several approaches in the literature have dealt with time-frequency atoms having exponential behavior. In <ref> [226] </ref>, damped sinusoids are used to provide a time-frequency representation in which transients are identifiable. In the application outlined in [226], some prior knowledge of the damping factor is assumed, which is reasonable for detection applications but inappropriate for deriving decompositions of arbitrary signals; extensions of the algorithm, however, may prove useful for signal modeling.
Reference: [227] <author> C. Herley and M. Vetterli, </author> <title> "Wavelets and recursive filter banks," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 41, </volume> <pages> pp. 2536-2556, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: In the application outlined in [226], some prior knowledge of the damping factor is assumed, which is reasonable for detection applications but inappropriate for deriving decompositions of arbitrary signals; extensions of the algorithm, however, may prove useful for signal modeling. In <ref> [227] </ref>, wavelets based on recursive filter banks are derived; these provide orthogonal expansions with respect to basis functions having infinite time support.
Reference: [228] <author> S. Tomazic, </author> <title> "On short-time Fourier transform with single-sided exponential window," </title> <booktitle> Signal Processing, </booktitle> <volume> vol. 55, </volume> <pages> pp. 141-148, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: If truncation effects are ignored, the second DFT term is neglected and the relationship is again more straightforward. Similar simplifications have been reported in the literature for short-time Fourier transforms using one-sided exponential windows <ref> [228] </ref> as well as more general cases [229].
Reference: [229] <author> M. Unser, </author> <title> "Recursion in short-time signal analysis," </title> <booktitle> Signal Processing, </booktitle> <volume> vol. 5, </volume> <pages> pp. 229-240, </pages> <month> May </month> <year> 1983. </year>
Reference-contexts: If truncation effects are ignored, the second DFT term is neglected and the relationship is again more straightforward. Similar simplifications have been reported in the literature for short-time Fourier transforms using one-sided exponential windows [228] as well as more general cases <ref> [229] </ref>.
Reference: [230] <author> I. Trancoso et al., </author> <title> "Quantization issues in harmonic coders," </title> <booktitle> in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. 1, </volume> <pages> pp. 382-385, </pages> <month> April </month> <year> 1988. </year> <month> 259 </month>
Reference-contexts: an open question whether the rate-distortion performance of this industry standard can be rivaled by parametric methods such as the sinusoidal model or overcomplete atomic models. 226 Sinusoidal modeling In the sinusoidal model, which has received recent attention for the application of audio coding, quantization is a primary open issue <ref> [230, 231] </ref>. For instance, it is of interest to incorporate perceptual resolution limits in the amplitude and frequency quantization schemes. Another important psychoacoustic consideration is the formal characterization of distortion artifacts such as pre-echo; such characterizations are required if the method is to be compared to standard techniques.
Reference: [231] <author> S. Levine, </author> <month> October </month> <year> 1997. </year> <type> Personal communication. </type>
Reference-contexts: an open question whether the rate-distortion performance of this industry standard can be rivaled by parametric methods such as the sinusoidal model or overcomplete atomic models. 226 Sinusoidal modeling In the sinusoidal model, which has received recent attention for the application of audio coding, quantization is a primary open issue <ref> [230, 231] </ref>. For instance, it is of interest to incorporate perceptual resolution limits in the amplitude and frequency quantization schemes. Another important psychoacoustic consideration is the formal characterization of distortion artifacts such as pre-echo; such characterizations are required if the method is to be compared to standard techniques. <p> Some modifications based on MPEG audio compression have been developed, but these are somewhat restricted in comparison to the rich class of modifications enabled by a sinusoidal signal model <ref> [231] </ref>. Atomic models Whereas there are clear indications that the sinusoidal model may be useful as an audio coding scheme, it has not yet been shown that atomic models based on overcomplete dictionaries are similarly promising.
Reference: [232] <author> S. Ahmadi, </author> <title> "New techniques for sinusoidal coding of speech at 2400 bps," </title> <booktitle> in Conference Record of the Thirtieth Asilomar Conference on Signals, Systems, and Computers, </booktitle> <volume> vol. 1, </volume> <pages> pp. 770-774, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: First, predictive models of the partial tracks in time and frequency may be useful for data reduction; linear prediction of the spectral envelope has been applied with some success to speech coding based on the sinusoidal model <ref> [232] </ref>. Such prediction may also prove useful for assisting with the estimation of sinusoidal parameters in upcoming signal frames.
Reference: [233] <author> F. Bergeaud and S. Mallat, </author> <title> "Matching pursuit of images," </title> <booktitle> in Proceedings of the International Conference on Image Processing, </booktitle> <volume> vol. 1, </volume> <pages> pp. 53-56, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: It is an open question whether similar improvements can be developed for audio residuals. Finally, it should be noted that matching pursuit has received some attention in the image coding literature <ref> [233, 234] </ref>.
Reference: [234] <author> S. Safavian et al., </author> <title> "Projection pursuit image compression with variable block size segmentation," </title> <journal> IEEE Signal Processing Letters, </journal> <volume> vol. 4, </volume> <pages> pp. 117-120, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: It is an open question whether similar improvements can be developed for audio residuals. Finally, it should be noted that matching pursuit has received some attention in the image coding literature <ref> [233, 234] </ref>.
References-found: 234

