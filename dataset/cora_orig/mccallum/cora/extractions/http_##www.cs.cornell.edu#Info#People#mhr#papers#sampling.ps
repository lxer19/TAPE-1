URL: http://www.cs.cornell.edu/Info/People/mhr/papers/sampling.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/mhr/project.html
Root-URL: 
Phone: 2  
Title: Improved Sampling with Applications to Dynamic Graph Algorithms.  
Author: Monika Rauch Henzinger and Mikkel Thorup ?? 
Address: 130 Lytton Ave, Palo Alto, CA  2100 Kbh. Denmark  
Affiliation: 1 Digital System Research Center,  Department of Computer Science, University of Copenhagen, Universitetsparken 1,  
Abstract: We state a new sampling lemma and use it to improve the running time of dynamic graph algorithms. For the dynamic connectivity problem the previously best randomized algorithm takes expected time O(log 3 n) per update, amortized over (m) updates. Using the new sampling lemma, we improve its running time to O(log 2 n). There exists a lower bound in the cell probe model for the time per operation of (log n= log log n) for this problem. Similarly improved running times are achieved for 2-edge connectivity, k-weight minimum spanning tree, and bipartiteness. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> N. Alon, J. Spencer, P. Erdos. </author> <title> The Probabilistic Method. </title> <publisher> Wiley-Interscience Series, Johan Wiley and Sons, Inc., </publisher> <year> 1992. </year>
Reference-contexts: Note that p P r (jR 2 j &lt; (1 ffi)) with ffi = 1=2: Using a Chernoff bound from <ref> [1] </ref>, P r (jR 1 j &lt; (1 ffi)) &lt; e ffi 2 =2 = e (1=2) 2 8 ln s=2 = 1=s; as desired. <p> However, the expected value of jR i1 j is at least n i1 (1 + n 1=4 Note that p i P r (jR i1 j &lt; (1 ffi)) with ffi = ( x)=: Using the Chernoff bound (according to <ref> [1] </ref>), P r (jR i1 j &lt; (1 ffi)) &lt; e ffi 2 =2 = e (x) 2 =(2) : For n i1 (1 + n i1 =2) this function is maximized for = n i1 (1 + n i1 =2).
Reference: 2. <author> D. Angluin, L. G. Valiant. </author> <title> Fast probabilistic algorithms for Hamiltonian circuits and matchings. </title> <journal> J. Comput. System Sci. </journal> <volume> 18 (2), </volume> <year> 1979, </year> <pages> 155-193. </pages>
Reference-contexts: However, the expected value of jR 2 j is at most 2 ln s. Note that p = P r (jR 2 j &gt; (1 + ffi)) with ffi = 1: Using a Chernoff bound from <ref> [2, 9] </ref>, P r (jR 2 j &gt; (1 + ffi)) &lt; e ffi 2 =3 = e 2 ln s=3 e 2 (e ln ln s)=3 &lt; 1= ln s: Above, it was used that x= ln x e for any real x &gt; 0. 2 We are now ready <p> However, the expected value of jR i j is at most n i (1 n 1=4 n i (1 1=(2:1 ln n i )). Note that p i P r (jR i1 j &gt; (1 + ffi)) with ffi = (x )=: Using the Chernoff bound (according to <ref> [2, 9] </ref>), P r (jR i1 j &gt; (1 + ffi)) &lt; e ffi 2 =3 = e (x) 2 =(3) : For n i (1 1=(2:1 ln n i )) this function is maximized for = n i (1 1=(2:1 ln n i )).
Reference: 3. <author> D. Eppstein, Z. Galil, G. F. </author> <title> Italiano. Improved Sparsification. </title> <type> Tech. Report 93-20, </type> <institution> Department of Information and Computer Science, University of California, </institution> <address> Irvine, CA 92717. </address>
Reference-contexts: The best deterministic algorithms for the above graph properties take time O ( p n) per update operation and O (1) or O (log n) per query <ref> [3, 4] </ref>. Recently [6], Henzinger and King gave algorithms with polylogarithmic amortized time per operation using (Las-Vegas type) randomization. Their algorithms achieve the following running times: 1. O (log 3 n) to maintain a spanning tree in a graph (the connectivity problem; 2.
Reference: 4. <author> D. Eppstein, Z. Galil, G. F. Italiano, A. Nissenzweig. </author> <title> Sparsification ATech-nique for Speeding up Dynamic Graph Algorithms. </title> <booktitle> Proc. 33rd Symp. on Foundations of Computer Science, </booktitle> <year> 1992, </year> <pages> 60-69. </pages>
Reference-contexts: The best deterministic algorithms for the above graph properties take time O ( p n) per update operation and O (1) or O (log n) per query <ref> [3, 4] </ref>. Recently [6], Henzinger and King gave algorithms with polylogarithmic amortized time per operation using (Las-Vegas type) randomization. Their algorithms achieve the following running times: 1. O (log 3 n) to maintain a spanning tree in a graph (the connectivity problem; 2.
Reference: 5. <author> M. L. Fredman and M. R. Henzinger. </author> <title> Lower Bounds for Fully Dynamic Connectivity Problems in Graphs. </title> <note> Submitted to Algorithmica. </note>
Reference-contexts: O (log 3 n) to test if the graph is bipartite (the bipartiteness-testing problem). Fredman and Henzinger showed lower bounds of (log n= log log n) in the cell probe model for the first four of these problems <ref> [5] </ref> (see also [8]). 1.3 New Results With our new sampling technique, we get the following improved running times: 1. O (log 2 n) for connectivity; 2. O (log 3 n) for 2-edge connectivity; 3. O (k log 2 n) for the k-weight minimum spanning tree problem; 4.
Reference: 6. <author> M. R. Henzinger and V. King. </author> <title> Randomized Dynamic Graph Algorithms with Polylogarithmic Time per Operation. </title> <booktitle> Proc. 27th ACM Symp. on Theory of Computing, </booktitle> <year> 1995, </year> <pages> 519-527. </pages>
Reference-contexts: This problem arises in the fastest dynamic graph algorithms for various graph problems (connectivity, two-edge connectivity, k-weight minimum spanning tree, (1 + * 0 )-approximate minimum spanning tree, and bipartiteness-testing) <ref> [6] </ref>. No deterministic algorithm of time less than (jSj) is possible. In [6] they address the problem by sampling O (r log jSj) from S, returning any element found from R. <p> This problem arises in the fastest dynamic graph algorithms for various graph problems (connectivity, two-edge connectivity, k-weight minimum spanning tree, (1 + * 0 )-approximate minimum spanning tree, and bipartiteness-testing) <ref> [6] </ref>. No deterministic algorithm of time less than (jSj) is possible. In [6] they address the problem by sampling O (r log jSj) from S, returning any element found from R. This is hence a Monte-Carlo type algorithm, running in time fi (r log jSj), whose type (ii) answer is wrong with probability 1=s fi (1) . <p> The best deterministic algorithms for the above graph properties take time O ( p n) per update operation and O (1) or O (log n) per query [3, 4]. Recently <ref> [6] </ref>, Henzinger and King gave algorithms with polylogarithmic amortized time per operation using (Las-Vegas type) randomization. Their algorithms achieve the following running times: 1. O (log 3 n) to maintain a spanning tree in a graph (the connectivity problem; 2. <p> O (log 2 n) for bipartiteness testing. 2 Improved sampling in dynamic graph algorithms Our improvements are achieved by locally improving a certain bottleneck in the approach by Henzinger and King <ref> [6] </ref>, henceforth referred to as the HK-approach. Rather than repeating their whole construction, we will confine ourselves to a reasonably self-contained description of this bottleneck. Our techniques for the bottleneck are of a general flavor and we expect them to be applicable in other contexts.
Reference: 7. <author> K. Mehlhorn. </author> <title> Data Structures and Algorithms 1: Sorting and Searching. </title> <booktitle> EATCS Monographs on Theoretical Computer Science, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1984. </year>
Reference: 8. <author> P.B. Miltersen, S. Subramanian, J.S. Vitter, and R. Tamassia. </author> <title> Complexity mod-els for incremental computation. </title> <journal> Theoretical Computer Science, </journal> <volume> 130, </volume> <year> 1994, </year> <pages> 203-236. </pages>
Reference-contexts: O (log 3 n) to test if the graph is bipartite (the bipartiteness-testing problem). Fredman and Henzinger showed lower bounds of (log n= log log n) in the cell probe model for the first four of these problems [5] (see also <ref> [8] </ref>). 1.3 New Results With our new sampling technique, we get the following improved running times: 1. O (log 2 n) for connectivity; 2. O (log 3 n) for 2-edge connectivity; 3. O (k log 2 n) for the k-weight minimum spanning tree problem; 4.
Reference: 9. <author> J. P. Schmidt, A. Siegel, A. Srinivasan. </author> <title> Chernoff-Hoeffding Bounds for Limited Independence. </title> <note> SIAM J. on Discrete Mathematics 8 (2), </note> <year> 1995, </year> <pages> 223-250. </pages>
Reference-contexts: However, the expected value of jR 2 j is at most 2 ln s. Note that p = P r (jR 2 j &gt; (1 + ffi)) with ffi = 1: Using a Chernoff bound from <ref> [2, 9] </ref>, P r (jR 2 j &gt; (1 + ffi)) &lt; e ffi 2 =3 = e 2 ln s=3 e 2 (e ln ln s)=3 &lt; 1= ln s: Above, it was used that x= ln x e for any real x &gt; 0. 2 We are now ready <p> However, the expected value of jR i j is at most n i (1 n 1=4 n i (1 1=(2:1 ln n i )). Note that p i P r (jR i1 j &gt; (1 + ffi)) with ffi = (x )=: Using the Chernoff bound (according to <ref> [2, 9] </ref>), P r (jR i1 j &gt; (1 + ffi)) &lt; e ffi 2 =3 = e (x) 2 =(3) : For n i (1 1=(2:1 ln n i )) this function is maximized for = n i (1 1=(2:1 ln n i )).
Reference: 10. <author> R.E. Tarjan and U. Vishkin. </author> <title> Finding biconnected components and computing tree functions in logarithmic parallel time. </title> <journal> SIAM J. Computing, </journal> <volume> 14(4): </volume> <pages> 862-874, </pages> <year> 1985. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
References-found: 10

