URL: ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1591.ps.Z
Refering-URL: http://www.ai.mit.edu/~viola/pub.html
Root-URL: 
Title: Complex Feature Recognition: A Bayesian Approach for Learning to Recognize Objects  
Author: Paul A. Viola 
Note: This publication can be retrieved by anonymous ftp to publications.ai.mit.edu. Copyright c Massachusetts Institute of Technology, 1996  
Date: 1591 November, 1996  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY  
Pubnum: A.I. Memo No.  
Abstract: We have developed a new Bayesian framework for visual object recognition which is based on the insight that images of objects can be modeled as a conjunction of local features. This framework can be used to both derive an object recognition algorithm and an algorithm for learning the features themselves. The overall approach, called complex feature recognition or CFR, is unique for several reasons: it is broadly applicable to a wide range of object types, it makes constructing object models easy, it is capable of identifying either the class or the identity of an object, and it is computationally efficient requiring time proportional to the size of the image. Instead of a single simple feature such as an edge, CFR uses a large set of complex features that are learned from experience with model objects. The response of a single complex feature contains much more class information than does a single edge. This significantly reduces the number of possible correspondences between the model and the image. In addition, CFR takes advantage of a type of image processing called oriented energy. Oriented energy is used to efficiently pre-process the image to eliminate some of the difficulties associated with changes in lighting and pose. This report describes research done at the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology. Support for this research was provided in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract N00014-96- 1-0311. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ballard, D. H. </author> <year> (1981). </year> <title> Generalizing the Hough transform to detect arbitrary shapes. </title> <journal> Pattern Recognition, </journal> <volume> 3(2) </volume> <pages> 836-840. </pages>
Reference-contexts: As a result, many researchers have eschewed the use of the image itself as the representation for recognition. In- stead they choose to define and identify simple image features that are supposed to capture the important characteristics of the image <ref> (Ballard, 1981) </ref>, (Bolles and Cain, 1982), (Grimson and Lozano-Perez, 1984). A typical example of such a feature is an intensity edge. There are three main motivations for using simple features. First, it is assumed that simple features are detectable under a wide variety of pose and lighting changes.
Reference: <author> Becker, S. </author> <year> (1993). </year> <title> Learning to categorize objects using temporal coherence. </title> <editor> In Hanson, S. J., Cowan, J. D., and Giles, C. L., editors, </editor> <booktitle> Advances in Neural Information Processing, volume 5, </booktitle> <address> Denver 1992. </address> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo. </address>
Reference-contexts: The third equation determines how probable changes in location are (changes in location are distributed as a gaussian around the previous location). Both (Foldiak, 1991) and <ref> (Becker, 1993) </ref> have suggested that temporal continuity may serve as a mechanism for learning object identity. These difference sources of information about the likelihood of a feature representation can then be combined.
Reference: <author> Beymer, D. </author> <year> (1993). </year> <title> Face recognition under varying pose. </title> <type> AI Memo 1461, </type> <institution> Artificial Intelligence Laboratory, Massachusetts Institute of Technology. </institution> <month> 19 November 11, </month> <editor> 1996 Paul A. Viola REFERENCES Bolles, R. C. and Cain, R. </editor> <year> (1982). </year> <title> Recognizing and locating partially visible objects: The local-feature-focus method. </title> <journal> International Journal of Robotics Research, </journal> <volume> 1(3) </volume> <pages> 57-82. </pages>
Reference-contexts: Learned Random Learned Features Features Features Features Objects 20 99 99 Faces 10 70 90 90 95 These results are about as good as the results that Nayar reports on his own data, but not as good as the results that Beymer reports on his data (Murase and Nayar, 1993) <ref> (Beymer, 1993) </ref>. In general CFR is very easy to use. For the most part CFR runs without requiring any intervention. The features are learned, the models are created and images are recognized without supervision. The exact same code runs on both the objects and the faces.
Reference: <author> Brunelli, R. and Poggio, T. </author> <year> (1992). </year> <title> Face recognition: Feature versus templates. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(10) </volume> <pages> 1042-1052. </pages>
Reference-contexts: We have shown a threshold for this type of 2 We use the maximal value of the normalized correlation between the feature and the image as a measure of image distance. Normalized correlation is a widely used matching metric that eliminates some of the dependency on lighting <ref> (Brunelli and Poggio, 1992) </ref>.
Reference: <author> Canny, J. F. </author> <year> (1986). </year> <title> A computational approach to edge detection. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-8(6):679-698. </journal>
Reference-contexts: As a result a large portion of the variation 5 In fact Freeman and Adelson used oriented energy as an input to a Canny edge detector and found that performance was significantly improved (Freeman and Adelson, 1991) <ref> (Canny, 1986) </ref>. 15 November 11, 1996 Paul A. Viola 6 EXPERIMENTS to production difficulties the white boarder between the oriented energy maps is not printed.) can be modeled locally, for the purposes of feature matching, as either an additive or multiplicative effect.
Reference: <author> Cover, T. M. and Thomas, J. A. </author> <year> (1991). </year> <title> Elements of Information Theory. </title> <publisher> John Wiley and Sons. </publisher>
Reference-contexts: By defining ^ d I G becomes a measure which compares the vectors ^ d I and ^ d M . There are a number of reasonable candidates for G, perhaps the best motivated is the cross entropy or asymmetric divergence (see <ref> (Cover and Thomas, 1991) </ref> for an excellent review entropy and divergence).
Reference: <author> Foldiak, P. </author> <year> (1991). </year> <title> Learning invariance from transformation sequences. </title> <journal> Neural Computation, </journal> <volume> 3(2) </volume> <pages> 194-200. </pages>
Reference-contexts: The third equation determines how probable changes in location are (changes in location are distributed as a gaussian around the previous location). Both <ref> (Foldiak, 1991) </ref> and (Becker, 1993) have suggested that temporal continuity may serve as a mechanism for learning object identity. These difference sources of information about the likelihood of a feature representation can then be combined.
Reference: <author> Freeman, W. T. and Adelson, E. H. </author> <year> (1991). </year> <title> The design and use of steerable filters. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, 13(9):891906. </journal>
Reference-contexts: We will assume that for the most part lighting varies slowly across a scene. As a result a large portion of the variation 5 In fact Freeman and Adelson used oriented energy as an input to a Canny edge detector and found that performance was significantly improved <ref> (Freeman and Adelson, 1991) </ref> (Canny, 1986). 15 November 11, 1996 Paul A. Viola 6 EXPERIMENTS to production difficulties the white boarder between the oriented energy maps is not printed.) can be modeled locally, for the purposes of feature matching, as either an additive or multiplicative effect.
Reference: <author> Grimson, W. E. L. and Lozano-Perez, T. </author> <year> (1984). </year> <title> Model-based recognition and loc-alization from sparse range or tactile data. </title> <journal> International Journal of Robotics Research, </journal> <volume> 3(3) </volume> <pages> 3-35. </pages>
Reference-contexts: As a result, many researchers have eschewed the use of the image itself as the representation for recognition. In- stead they choose to define and identify simple image features that are supposed to capture the important characteristics of the image (Ballard, 1981), (Bolles and Cain, 1982), <ref> (Grimson and Lozano-Perez, 1984) </ref>. A typical example of such a feature is an intensity edge. There are three main motivations for using simple features. First, it is assumed that simple features are detectable under a wide variety of pose and lighting changes.
Reference: <author> Kandel, E. and Schwartz, J. </author> <year> (1985). </year> <booktitle> Principles of Neural Science. </booktitle> <publisher> Elsevier, </publisher> <address> New York, </address> <note> second edition. </note>
Reference-contexts: Viola 2 A GENERATIVE PROCESS FOR IMAGES Similar pre-processing can be found in the visual cortex of primates (see <ref> (Kandel and Schwartz, 1985) </ref> for example) and underlies the computational definition of the intensity edge by (Marr and Hildreth, 1980). Rather than the discrete detection of intensity edges, CFR instead uses a continuous measure of the "edge-ness" of pixels.
Reference: <author> Le Cun, Y., Boser, B., Denker, J., Henderson, D., Howard, R., Hubbard, W., and Jackel, L. </author> <year> (1989). </year> <title> Backpropagation applied to handwritten zip code recognition. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 541-551. </pages>
Reference-contexts: Techniques that use complex global features come in a wide variety of types. Recent examples include color histograms (Swain and Ballard, 1991), shape measures such as those proposed in (Sclaroff and Pentland, 1995) or monolithic neural networks such as those proposed by <ref> (Le Cun et al., 1989) </ref>. These techniques are distinguished because they are capable of using many different types of information, like color and texture. They do, however, share a sensitivity to clutter and frequently assume that the object is segmented from the background.
Reference: <author> Marr, D. and Hildreth, E. </author> <year> (1980). </year> <title> Theory of edge detection. </title> <journal> Proceedings of the Royal Society of London, B(207):187-217. </journal>
Reference-contexts: Viola 2 A GENERATIVE PROCESS FOR IMAGES Similar pre-processing can be found in the visual cortex of primates (see (Kandel and Schwartz, 1985) for example) and underlies the computational definition of the intensity edge by <ref> (Marr and Hildreth, 1980) </ref>. Rather than the discrete detection of intensity edges, CFR instead uses a continuous measure of the "edge-ness" of pixels. The "edge-ness" of a pixel is proportional to the energy in a number of oriented band-pass filters centered on the pixel.
Reference: <author> Murase, H. and Nayar, S. K. </author> <year> (1993). </year> <title> Learning and recognition of 3-d objects from brightness images. </title> <booktitle> In AAAI Fall Symposium Series Working Notes. </booktitle> <publisher> AAAI. </publisher>
Reference-contexts: CFR-DISC CFR-MEM CFR-DISC Random Learned Random Learned Features Features Features Features Objects 20 99 99 Faces 10 70 90 90 95 These results are about as good as the results that Nayar reports on his own data, but not as good as the results that Beymer reports on his data <ref> (Murase and Nayar, 1993) </ref> (Beymer, 1993). In general CFR is very easy to use. For the most part CFR runs without requiring any intervention. The features are learned, the models are created and images are recognized without supervision. The exact same code runs on both the objects and the faces.
Reference: <author> Poggio, T., Torre, V., and Koch, C. </author> <year> (1985). </year> <title> Computational vision and regularization theory. </title> <journal> Nature, </journal> <volume> 317 </volume> <pages> 314-319. </pages>
Reference-contexts: One useful definition of "stable" is that as an object slowly changes pose, large changes in representation are rare while small changes in representation are more common. One can formulate this in a way that is very similar to a smoothness prior that is common in regularization theory <ref> (Poggio, Torre and Koch, 1985) </ref>.
Reference: <author> Rao, R. P. N. and Ballard, D. H. </author> <year> (1995). </year> <title> Object indexing using an iconic sparse distributed memory. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 24-31, </pages> <address> Cambridge, MA. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address> <month> 20 November 11, </month> <note> 1996 REFERENCES AI Memo 1591 Rumelhart, </note> <author> D. E., Hinton, G. E., and Williams, R. J. </author> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In Rumelhart, D. E. and McLelland, J. L., editors, </editor> <booktitle> Parallel Distributed Processing: Exploration in the Microstructure of Cognition, chapter 8. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: In fact the very concept of "global" pre-supposes that the extent of the object is known. We hope that CFR combines the best properties of both the global and local techniques. Recently, <ref> (Rao and Ballard, 1995) </ref> have proposed that a type of pre-processing similar to oriented energy be used on images before they are matched to models.
Reference: <author> Sclaroff, S. and Pentland, A. P. </author> <year> (1995). </year> <title> Modal matching for correspondence and recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17(6) </volume> <pages> 545-561. </pages>
Reference-contexts: Techniques that use complex global features come in a wide variety of types. Recent examples include color histograms (Swain and Ballard, 1991), shape measures such as those proposed in <ref> (Sclaroff and Pentland, 1995) </ref> or monolithic neural networks such as those proposed by (Le Cun et al., 1989). These techniques are distinguished because they are capable of using many different types of information, like color and texture.
Reference: <author> Swain, M. J. and Ballard, D. H. </author> <year> (1991). </year> <title> Color indexing. </title> <journal> International Journal of Computer Vision, </journal> <volume> 7 </volume> <pages> 11-32. </pages>
Reference-contexts: In addition, with appropriate 18 November 11, 1996 AI Memo 1591 features, CFR should be more efficient than a brute force matching of simple features. Techniques that use complex global features come in a wide variety of types. Recent examples include color histograms <ref> (Swain and Ballard, 1991) </ref>, shape measures such as those proposed in (Sclaroff and Pentland, 1995) or monolithic neural networks such as those proposed by (Le Cun et al., 1989). These techniques are distinguished because they are capable of using many different types of information, like color and texture.
Reference: <author> Wells III, W. M. </author> <year> (1991). </year> <title> MAP Model Matching. </title> <booktitle> In Proceedings of the Computer Society Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 486492, </pages> <address> Lahaina, Maui, Hawaii. </address> <publisher> IEEE. </publisher> <month> 21 November 11, </month> <year> 1996 </year>
Reference-contexts: The arrows between the five different features on the left and the five white boxes that lie over the image describe the positions of the features that best represent the image. for example <ref> (Wells III, 1991) </ref> which makes this analogy very explicit). Of course the details of these algorithms can be quite different. Some algorithms use the input image directly, comparing the input image and the predicted image directly. Most techniques that use correlation for image matching fall into this category.
References-found: 18

