URL: http://cobar.cs.umass.edu/pubfiles/ir-130.ps
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Email: tombrosa@dcs.gla.ac.uk  sanderso@cs.umass.edu  
Phone: CIIR,  
Title: Advantages of Query Biased Summaries in Information Retrieval  
Author: Anastasios Tombros Mark Sanderson 
Web: www.dcs.gla.ac.uk/~tombrosa/  www-ciir.cs.umass.edu/~sanderso/  
Address: Glasgow G12 8RZ Scotland  Amherst, MA 01003 U.S.A.  
Affiliation: Computing Science Department University of Glasgow  Computing Science Department University of Massachusetts  
Abstract: 1 This paper presents an investigation into the utility of document summarisation in the context of information retrieval, more specifically in the application of so called query biased (or user directed) summaries: summaries customised to reflect the information need expressed in a query. Employed in the retrieved document list displayed after a retrieval took place, the summaries utility was evaluated in a task-based environment by measuring users speed and accuracy in identifying relevant documents. This was compared to the performance achieved when users were presented with the more typical output of an IR system: a static predefined summary composed of the title and first few sentences of retrieved documents. The results from the evaluation indicate that the use of query biased summaries significantly improves both the accuracy and speed of user relevance judgements. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Abracos, J., and Lopes, </author> <title> G.P. 1997. Statistical methods for retrieving most significant paragraphs in newspaper articles. </title> <booktitle> In Proceedings of the ACL'97/EACL'97 Workshop on Intelligent Scalable Text Summarisation (ISTS '97), </booktitle> <pages> 51-57. </pages> <address> Madrid, Spain, </address> <month> July 11 </month> <year> 1997. </year>
Reference-contexts: This approach is in agreement with Luhns suggestions (Luhn 1958), as well as with more recent studies that show that in the English language 98% of the lexical relations occur between words within a span of 5 words in a sentence <ref> (Abracos and Lopes 1997) </ref>. The scheme that is used for computing the significance factor for a sentence was originally proposed by (Luhn 1958).
Reference: <author> Brandow, R., Mitze, K., and Rau, L.F. </author> <year> 1995. </year> <title> Automatic condensation of electronic publications by sentence selection. </title> <booktitle> Information Processing & Management 31(5): </booktitle> <pages> 675-685, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: This conclusion seemed to be in agreement with <ref> (Brandow et al. 1995) </ref>, who suggested that "improvements (to the autosummaries) can be achieved by weighting the sentences appearing in the beginning of the articles more heavily". In order to quantify this contribution, an ordinal weight was assigned to the first two sentences of each article. <p> This was defined to be 15% of the document's length up to a maximum of five sentences. Such a value seems to be in general agreement with suggestions made by (Edmundson 1964), and <ref> (Brandow et al. 1995) </ref>. 3 Experimental Design The aim of the specific experiment was to establish that the use of query biased summaries in a retrieved document list would have a positive effect on the process of relevance judgement by users.
Reference: <author> Callan, J.P. </author> <year> 1994. </year> <title> Passage-level evidence in document retrieval. </title> <editor> In Croft, W.B., and van Rijbergen, C.J. eds. </editor> <booktitle> Proceedings of the Seventeenth Annual ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> 302-310. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1994. </year>
Reference: <author> Edmundson, </author> <title> H.P. 1964. Problems in automatic abstracting. </title> <journal> Communications of the ACM 7(4) </journal> <pages> 259-263, </pages> <month> April </month> <year> 1964. </year>
Reference-contexts: This was defined to be 15% of the document's length up to a maximum of five sentences. Such a value seems to be in general agreement with suggestions made by <ref> (Edmundson 1964) </ref>, and (Brandow et al. 1995). 3 Experimental Design The aim of the specific experiment was to establish that the use of query biased summaries in a retrieved document list would have a positive effect on the process of relevance judgement by users.
Reference: <author> Edmundson, </author> <title> H.P. 1969. New methods in automatic abstracting. </title> <journal> Journal of the ACM 16(2) </journal> <pages> 264-285, </pages> <month> April </month> <year> 1969. </year>
Reference: <author> Hand, T.F. </author> <year> 1997. </year> <title> A proposal for a task-based evaluation of text summarisation systems. In Proceedings of the 1.5 1 3 5 Opinion of subjects using summaries Opinion of subjects using a typical IR output ACL'97/EACL'97 Workshop on Intelligent Scalable Text Summarisation (ISTS '97), </title> <address> 31-38. Madrid, Spain, </address> <month> July 11 </month> <year> 1997. </year>
Reference-contexts: Traditionally the evaluation of summarisation systems involves measuring quantitative attributes of the summaries (e.g. similarity between automatically generated summaries and human prepared ones) (Edmundson 1969; Kupiec et al. 1995; Salton et al. 1997). There have recently been proposals <ref> (Hand 1997) </ref> and attempts (Miike et al. 1994; Mani and Bloedorn 1997) to develop schemes that measure qualitative features of the systems in a task-based environment. However, these attempts have so far been limited as far as the experimental procedure is concerned.
Reference: <author> Harman, D. </author> <year> 1996. </year> <booktitle> Overview of the Fifth Text REtrieval Conference (TREC-5). In Proceedings of the Text Retrieval Conference (TREC-5), </booktitle> <institution> National Institute of Standards and Technology, Gaithersburg, MD 20899, USA. </institution>
Reference-contexts: It was based on a number of sentence extraction methods (Paice 1990) that utilise information both from the documents of the collection and from the queries used. The documents to be summarised were articles of the Wall Street Journal (WSJ) taken from the TREC collection (Text REtrieval Conferences) <ref> (Harman 1996) </ref>. In order to decide which aspects of the articles would provide utility to generating a summary, their characteristics were examined in a small scale study.
Reference: <author> Jacobs, P.S., and Rau, L.F. </author> <year> 1990. </year> <title> Scisor: Extracting information from online news. </title> <journal> Communications of the ACM 33(11) </journal> <pages> 88-97, </pages> <month> November </month> <year> 1990. </year>
Reference: <author> Keppel, G. </author> <year> 1973. </year> <title> Design and analysis: A researcher's handbook. </title> <address> New Jersey: </address> <publisher> Prentice Hall. </publisher>
Reference-contexts: However, relevant studies have shown that although there are risks in generalising experimental results in such cases, an investigator may feel safe in doing so since the statistical differences introduced are generally of a small scale <ref> (Keppel 1973) </ref>. Situational variables. Such variables are associated with the experimental situation itself (e.g. background noise, equipment settings, experimenters behaviour, etc.). Such factors can easily confound the effects of the independent variable if they change systematically from one condition to another.
Reference: <author> Knaus, D., Mittendorf, E., Schauble, P., and Sheridan, P. </author> <year> 1995. </year> <title> Highlighting relevant passages for users of the interactive SPIDER retrieval system. </title> <booktitle> In Proceedings of the Text Retrieval Conference (TREC-4), </booktitle> <institution> National Institute of Standards and Technology, Gaithersburg, MD 20899, USA. </institution>
Reference: <author> Kupiec, J., Pedersen, J., and Chen, F. </author> <year> 1995. </year> <title> A trainable document summariser. </title> <editor> In Fox, E.A., Ingwersen, P., and Fidel, R. eds. </editor> <booktitle> Proceedings of the Eighteenth Annual ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> 68-73. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1995. </year>
Reference: <author> Luhn, </author> <title> H.P. 1958. The automatic creation of literature abstracts. </title> <journal> IBM Journal of Research and Development 2(2): </journal> <pages> 159-165, </pages> <month> April </month> <year> 1958. </year>
Reference-contexts: Instead of merely assigning a weight to each term according to its frequency within the document, the system locates clusters of significant words <ref> (Luhn 1958) </ref> within sentences, and assigns scores to them accordingly. Based on the sample study of the WSJ collection, we concluded that a reasonable TO value for establishing the significance of a term was 7, and that this value should be adjusted according to the length of the document. <p> If in that way a sentence contains two or more clusters, the one with the highest significance factors is taken as the measure for that sentence. This approach is in agreement with Luhns suggestions <ref> (Luhn 1958) </ref>, as well as with more recent studies that show that in the English language 98% of the lexical relations occur between words within a span of 5 words in a sentence (Abracos and Lopes 1997). <p> The scheme that is used for computing the significance factor for a sentence was originally proposed by <ref> (Luhn 1958) </ref>.
Reference: <author> Maizell, R.E., Smith, J.F., and Singer, T.E.R. </author> <year> 1971. </year> <title> Abstracting scientific and technical literature: An introductory guide and text for scientists, </title> <booktitle> abstractors and management. </booktitle> <address> New York: Willey-Interscience, </address> <publisher> John Willey & Sons Inc. </publisher>
Reference-contexts: A document summary conventionally refers to an abstract-like condensation of a full text document, that presents succinctly the objectives, scope, and findings of the document <ref> (Maizell et al., 1971) </ref>. The minimal function that any useful summary should provide is being indicative of the sources content, thus helping a reader to decide whether looking at the whole document will be worthwhile.
Reference: <author> Mani, I., and Bloedorn, E. </author> <year> 1997. </year> <title> Multi-document summarisation by graph search and matching. </title> <booktitle> In Proceedings of AAAI-97, </booktitle> <address> Providence Rhode Island. </address>
Reference: <author> McKeown, K., and Radev, D.R. </author> <year> 1995. </year> <title> Generating summaries from multiple news articles. </title> <editor> In Fox, E.A., Ingwersen, P., and Fidel, R. eds. </editor> <booktitle> Proceedings of the Eighteenth Annual ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> 74-82. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1995. </year>
Reference: <author> Miike, S., Itoh, E., Ono, K., and Sumita, K. </author> <year> 1994. </year> <title> A full-text retrieval system with a dynamic abstract generation function. </title>
Reference: <editor> In Croft, W.B., and van Rijbergen, C.J. eds. </editor> <booktitle> Proceedings of the Seventeenth Annual ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> 152-161. </pages> <publisher> ACM Press, </publisher> <month> July </month> <year> 1994. </year>
Reference: <author> Miller, S. </author> <year> 1984. </year> <title> Experimental design and statistics (2nd edition). </title> <address> New York: </address> <publisher> Routledge. </publisher>
Reference-contexts: Groups of subjects. In the experiment described in this paper two groups consisting of 10 subjects each were employed. Subjects were randomly assigned to a group (by means of a draw), and each group was assigned to one experimental condition only (independent groups design <ref> (Miller 1984) </ref>). It is believed that the number of 20 subjects is sufficient for attributing significance to any results obtained. The subjects comprised mainly of postgraduate students doing a conversion course in computer science. Clearly, this population is not representative of that which we wish to generalise the conclusions to. <p> The data presented in Figures 4 and 5, were acquired by averaging the results for each query over the total number of queries, thus producing the average recall and precision values per query. In order to establish the statistical significance of these results, t-tests <ref> (Miller 1984) </ref> were performed on both these measures, indicating that, with a probability of error 0.05, the results are attributed to the change of level of the independent variable and not to chance factors.
Reference: <author> Paice, C.D. </author> <year> 1990. </year> <title> Constructing literature abstracts by computer: Techniques and prospects. </title> <booktitle> Information Processing & Management 26(1) </booktitle> <pages> 171-186. </pages>
Reference-contexts: Since its beginnings (Luhn, 1958; Edmundson, 1969), automatic text summarisation has been performed primarily by the selection of sentences from the original document; scores are assigned to sentences according to a set of extraction criteria <ref> (Paice, 1990) </ref>, and the best-scoring sentences are presented in the summary. This approach can be better termed as sentence extraction rather than summarisation, and although it does not perform an in-depth analysis of the source text it can produce indicative summaries, which can help users in relevance judgements. <p> Moreover, the summaries were to be user-directed: biased towards the user's query. With these factors in mind, we now describe the system. It was based on a number of sentence extraction methods <ref> (Paice 1990) </ref> that utilise information both from the documents of the collection and from the queries used. The documents to be summarised were articles of the Wall Street Journal (WSJ) taken from the TREC collection (Text REtrieval Conferences) (Harman 1996).
Reference: <author> Porter, M.F. </author> <year> 1980. </year> <title> An algorithm for suffix stripping. Program - automated library and information systems 14(3) </title> <type> 130-137. </type>
Reference-contexts: The retrieval system used to generate the retrieved document lists was a classic document ranking system employing a tfidf term weighting scheme with stop word removal and word stemming using the Porter stemmer <ref> (Porter 1980) </ref> 3.2 Operationalising the experiment The actual steps of the experimental procedure are as follows: Each subject was randomly assigned to one of the two levels of the independent variable in the way that was previously explained. In that way the task that each subject should perform was defined.
Reference: <author> Rush, J.E., Salvador, R., and Zamora, A. </author> <year> 1971. </year> <title> Automatic abstracting and indexing. II. Production of indicative abstracts by application of contextual inference and syntactic coherence criteria. </title> <journal> Journal of the American Society for Information Science 22(4) </journal> <pages> 260-274. </pages>
Reference-contexts: In this sense, summaries can serve as a preview format to support relevance assessments on the full text of documents <ref> (Rush et al., 1971) </ref>. Some summaries may also contain informative material, in which case they can be used as standalone document surrogates. <p> The proposed evaluation scheme judges the utility of a summarisation system in the context in which it will eventually be used, and for the purposes for which it has been built. According to this rationale, the indicative function <ref> (Rush et al. 1971) </ref> of a summary is the one which should be primarily evaluated.
Reference: <author> Salton, G., Singhal, A., Mitra, M., and Buckley, C. </author> <year> 1997. </year> <title> Automatic text structuring and summarisation. </title> <booktitle> Information Processing & Management 33(2) </booktitle> <pages> 193-20. </pages>
References-found: 22

