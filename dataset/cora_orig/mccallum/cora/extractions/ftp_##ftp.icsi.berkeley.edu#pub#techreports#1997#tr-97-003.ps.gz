URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1997/tr-97-003.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1997.html
Root-URL: http://www.icsi.berkeley.edu
Title: Exploiting temporal binding to learn relational rules within a connectionist network  
Author: Lokendra Shastri 
Note: This work was partially funded by ONR grants N00014-93-1-1149 and N00014-95-C-0182. Thanks to the L0 group for providing intellectual stimulation.  
Address: I 1947 Center St. Suite 600 Berkeley, California 94704-1198  
Affiliation: INTERNATIONAL COMPUTER SCIENCE INSTITUTE  
Pubnum: TR-97-003  
Email: E-mail: shastri@icsi.berkeley.edu  
Phone: (510) 643-9153 FAX (510) 643-7684  
Date: June 1997  
Abstract: Rules encoded by traditional rule-based systems are brittle and inflexible because it is difficult to specify the precise conditions under which a rule should fire. If the conditions are made too specific a rule does not always fire when it should. If the conditions are made too general, the rule fires even when it should not. In contrast, connectionist networks are considered to be capable of learning soft and robust rules. Work in connectionist learning however, has focused primarily on classification and feature formation, and the problem of learning rules involving relations and roles (variables) has received relatively little attention. We present a simple demonstration of rule learning involving relations and variables within a connectionist network. The network learns the appropriate correspondence between roles of antecedent and consequent relations as well as the features that role fillers must possess for a rule to be applicable in a given situation. Each rule can be viewed as a mapping from the symbolic level to the symbolic level mediated by a semantic filter embedded within a subsymbolic level. The network uses synchronous firing of nodes to express dynamic bindings. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ajjanagadde, V. & Shastri, L. </author> <title> (1990) Rules and variables in neural nets, </title> <journal> Neural Computation. </journal> <volume> 3, </volume> <pages> 121-134. </pages>
Reference: <author> Feldman, J. A. </author> <title> (1982) Dynamic connections in neural networks, </title> <journal> Bio-Cybernetics, </journal> <volume> 46 </volume> <pages> 27-39. </pages> <editor> von der Malsburg, C. </editor> <title> (1986) Am I thinking assemblies? In Brain Theory, </title> <editor> ed. G. Palm & A. Aertsen. </editor> <publisher> Springer-Verlag. </publisher>
Reference: <author> Lange, T. E., & Dyer, M. G. </author> <title> (1989) High-level Inferencing in a Connectionist Network. </title> <journal> Connection Science, </journal> <volume> Vol. 1, No. 2, </volume> <pages> 181-217. </pages>
Reference-contexts: own, and can-sell, the state of activation described by the pattern shown in Figure 2a leads to the activation pattern shown in Figure 2b where the firing pattern of nodes corresponds to the dynamic facts give (John,Mary,Book1), own (Mary,Book1), and 2 The model shares a number of features with ROBIN <ref> (Lange & Dyer 1989) </ref> which uses signatures instead of temporal synchrony to solve the dynamic binding problem. 2 own (y; z)], 8x; y [own (x; y) ) can-sell (x; y)], and 8x; y [buy (x; y) ) own (x; y)].
Reference: <author> Mani, D.R. & Shastri, L. </author> <title> (1993) Reflexive Reasoning with Multiple-Instantiation in in a Connectionist Reasoning System with a Typed Hierarchy, </title> <journal> Connection Science, </journal> <volume> Vol. 5, No. 3 & 4, </volume> <pages> 205-242. </pages>
Reference: <author> Shastri, L. & Ajjanagadde, V. </author> <title> (1993) From simple associations to systematic reasoning, </title> <journal> Behavioral and Brain Sciences Vol. </journal> <volume> 16, No. 3, </volume> <pages> 417-494. </pages>
Reference-contexts: As discussed in <ref> (Shastri & Ajjanagadde, 1993) </ref> reasoning involving n-ary predicates requires a solution to the dynamic binding problem (Feldman 1982; Malsburg 1986). shruti incorporates a neurally plausible solution to this problem. <p> Only aspects of shruti relevant to the current work are presented. Other details may be found in <ref> (Shastri & Ajjanagadde 1993) </ref>. shruti encodes an n-ary predicate as a cluster of nodes which includes n role nodes (these are the circular `nodes' shown in Figure 1, the rectangular nodes are not relevant to our discussion). <p> In <ref> (Shastri & Ajjanagadde 1993) </ref> it was shown that such filters can be hard-wired using -btu and t -or nodes if the restrictions on the role fillers are known. In the present work we demonstrate that a shruti-like system can automatically learn such filters from observations. <p> The latter make up the hidden structure. As discussed in <ref> (Shastri & Ajjanagadde, 1993) </ref>, the activation of an entity can be viewed as the activation of its handle node and other nodes representing its features and types.
Reference: <author> Shastri, L. & Grannes, </author> <title> D.J. (1996) A connectionist treatment of negation and inconsistency. </title> <booktitle> In Proceedings of the Eighteenth Conference of the Cognitive Science Society, </booktitle> <address> San Diego, CA. </address>
Reference: <author> Singer, W. & Gray, </author> <title> C.M. (1995) Visual feature integration and the temporal correlation hypothesis. </title> <journal> Annual Review of Neuroscience 18, </journal> <note> 555-586 (1995). 11 Watrous, R.L. </note> & <author> Shastri, L. </author> <title> (1987) Learning phonetic features using connectionist net-works. </title> <editor> R. L. Watrous and L. Shastri, </editor> <booktitle> Proceedings of IJCAI-87, the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Milan, Italy, </address> <month> August </month> <year> 1987. </year> <pages> pp. 851-854. </pages>
Reference-contexts: There is growing neurophysiological evidence that synchronous activity may play an important role in neural information processing <ref> (e.g., Singer & Gray, 1995) </ref>.
Reference: <author> Watrous, </author> <title> R.L. (1990) Phoneme discrimination using connectionist networks. </title> <journal> J. Accoust. Soc. Am. </journal> <volume> 87 (4) 1753-1772. </volume>
Reference: <author> Watrous, R.L. </author> <year> (1993) </year> <month> gradsim: </month> <title> A connectionist network simulator using gradient optimization techniques. </title> <type> Technical Report LS92-02, </type> <institution> Siemens Research Laboratory, Princeton, NJ. </institution> <month> 12 </month>
Reference-contexts: The interconnection scheme was as described in Section 3.1 Learning was carried out using gradsim | a system for applying nonlinear gradient optimization techniques to train connectionist networks from examples consisting of time-varying input output patterns 10 <ref> (Watrous 1993) </ref>. Barring a few runs in which the network got stuck at an unsatisfactory local minimum, the optimization lead to a desirable network using the second-order gradient descent algorithm, BFGS. An example run consisted of a training set of 257 patterns.
References-found: 9

