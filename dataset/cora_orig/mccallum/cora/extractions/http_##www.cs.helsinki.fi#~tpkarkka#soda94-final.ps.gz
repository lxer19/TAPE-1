URL: http://www.cs.helsinki.fi/~tpkarkka/soda94-final.ps.gz
Refering-URL: http://www.cs.helsinki.fi/research/pmdm/publications/
Root-URL: 
Title: Chapter 78 Two and higher dimensional pattern matching in optimal expected time on-line, using a
Author: Juha Karkkainen Esko Ukkonen 
Note: m 2 (k 1) log c m 2 provided that k m 2 =(4dlog c m 2 e). All algorithms need preprocessing of P which takes time and space O(m 2 log c m 2 or O(m 2 The text processing can be done  any d.  
Abstract: Algorithms with optimal expected running time are presented for searching the occurrences of a two-dimensional m fi m pattern P in a two-dimensional n fi n text T over an alphabet of size c. The algorithms are based on placing in the text a static grid of test points, determined only by n, m and c (not dynamically by earlier test results). Using test strings read from the test points the algorithms eliminate as many potential occurrences of P as possible. The remaining potential occurrences are separately checked for actual occurrences. By suitably choosing the test point set, we obtain algorithms with expected running time O( n 2 m 2 log c m 2 ) which is optimal by a lower bound result by Yao. The method is generalized for the k mismatches problem. The resulting algorithm has expected running time O( n 2 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A.V. Aho and M.J. Corasick: </author> <title> Efficient string matching: An aid to bibliographic search. </title> <booktitle> Comm. ACM 18 (1975), </booktitle> <pages> 333-340. </pages>
Reference-contexts: Test entry T [3; 6] = a eliminates all other occurrences of P that overlap T [3; 6] except those that have overlapping symbol a. The upper left corners of these potential occurrences of P are T <ref> [1; 5] </ref> (=I) and T [3; 4] (=II), because P [1; 3] = P [3; 2] = a. The checking phase then finds that there is an occurrence of P at T [1; 5] but not at T [3; 4]. <p> Test entry T [3; 6] = a eliminates all other occurrences of P that overlap T [3; 6] except those that have overlapping symbol a. The upper left corners of these potential occurrences of P are T [1; 5] (=I) and T [3; 4] (=II), because P <ref> [1; 3] </ref> = P [3; 2] = a. The checking phase then finds that there is an occurrence of P at T [1; 5] but not at T [3; 4]. <p> The upper left corners of these potential occurrences of P are T <ref> [1; 5] </ref> (=I) and T [3; 4] (=II), because P [1; 3] = P [3; 2] = a. The checking phase then finds that there is an occurrence of P at T [1; 5] but not at T [3; 4]. The fourth test entry T [6; 3] = b is least useful in the elimination because b has 7 occurrences in P . Hence we are left with 7 potential occurrences of P that overlap T [6; 3]. <p> We also need to find the matching pattern samples in constant time. To achieve this we replace the trie in Section 3 with an Aho-Corasick multipattern matching automaton AC (P; Q P ) (see <ref> [1] </ref>). The automaton can be built in the same asymptotic time as the trie; in fact AC (P; Q P ) is simply the trie augmented with the failure-transitions.
Reference: [2] <author> A. Amir and G. Benson: </author> <title> Two-dimensional periodicity and its applications. </title> <booktitle> Proc. 3rd ACM-SIAM SODA, </booktitle> <year> 1992, </year> <pages> 440-452. </pages>
Reference-contexts: In d-dimensional case P and T are d-dimensional arrays over . The applications are numerous. The exact one-dimensional pattern matching is well-understood. For two and higher dimensional versions several algorithms have been proposed, too, mainly aiming at good worst-case running time; see e.g. <ref> [6, 5, 14, 21, 2] </ref>. Recently, the two-dimensional problem has been solved in linear worst-case time with algo rithms that are alphabet-independent in the same sense as the one-dimensional Knuth-Morris-Pratt algorithm fl Work supported by the Academy of Finland. y tpkarkka@cs.Helsinki.FI, Department of Computer Science, P.O. <p> The upper left corners of these potential occurrences of P are T [1; 5] (=I) and T [3; 4] (=II), because P [1; 3] = P <ref> [3; 2] </ref> = a. The checking phase then finds that there is an occurrence of P at T [1; 5] but not at T [3; 4]. The fourth test entry T [6; 3] = b is least useful in the elimination because b has 7 occurrences in P . <p> The fourth test entry T [6; 3] = b is least useful in the elimination because b has 7 occurrences in P . Hence we are left with 7 potential occurrences of P that overlap T [6; 3]. Here we note that taking T <ref> [6; 2] </ref> = c as an additional test entry would eliminate all possible occurrences of P that overlap T [6; 2] and T [6; 3] because substring cb does not occur in P . <p> Hence we are left with 7 potential occurrences of P that overlap T [6; 3]. Here we note that taking T <ref> [6; 2] </ref> = c as an additional test entry would eliminate all possible occurrences of P that overlap T [6; 2] and T [6; 3] because substring cb does not occur in P .
Reference: [3] <author> A. Amir, G. Benson and M. Farach: </author> <title> Alphabet independent two dimensional matching. </title> <booktitle> Proc. 24th ACM STOC, </booktitle> <year> 1992, </year> <pages> 59-68. </pages>
Reference-contexts: Box 26 (Teollisuuskatu 23), SF-00014 University of Helsinki, Finland. z ukkonen@cs.Helsinki.FI, Department of Computer Science, P.O. Box 26 (Teollisuuskatu 23), SF-00014 University of Helsinki, Finland. <ref> [3, 11] </ref>. A space-economical solution is given in [9]. In the applications of one-dimensional matching the Boyer-Moore algorithm [7] whose expected running time is "sublinear" is clearly the most successful; see e.g. [13]. <p> The test entries in T are as follows I b c c As the first entry T <ref> [3; 3] </ref> equals c, and c does not occur in P at all, no occurrence of P in T can overlap T [3; 3]. This proves that there can not be an occurrence of P inside subarray T [1 : 5; 1 : 5]. <p> The test entries in T are as follows I b c c As the first entry T <ref> [3; 3] </ref> equals c, and c does not occur in P at all, no occurrence of P in T can overlap T [3; 3]. This proves that there can not be an occurrence of P inside subarray T [1 : 5; 1 : 5]. Test entry T [3; 6] = a eliminates all other occurrences of P that overlap T [3; 6] except those that have overlapping symbol a. <p> This proves that there can not be an occurrence of P inside subarray T [1 : 5; 1 : 5]. Test entry T <ref> [3; 6] </ref> = a eliminates all other occurrences of P that overlap T [3; 6] except those that have overlapping symbol a. <p> This proves that there can not be an occurrence of P inside subarray T [1 : 5; 1 : 5]. Test entry T <ref> [3; 6] </ref> = a eliminates all other occurrences of P that overlap T [3; 6] except those that have overlapping symbol a. The upper left corners of these potential occurrences of P are T [1; 5] (=I) and T [3; 4] (=II), because P [1; 3] = P [3; 2] = a. <p> Test entry T [3; 6] = a eliminates all other occurrences of P that overlap T [3; 6] except those that have overlapping symbol a. The upper left corners of these potential occurrences of P are T [1; 5] (=I) and T <ref> [3; 4] </ref> (=II), because P [1; 3] = P [3; 2] = a. The checking phase then finds that there is an occurrence of P at T [1; 5] but not at T [3; 4]. <p> Test entry T [3; 6] = a eliminates all other occurrences of P that overlap T [3; 6] except those that have overlapping symbol a. The upper left corners of these potential occurrences of P are T [1; 5] (=I) and T [3; 4] (=II), because P <ref> [1; 3] </ref> = P [3; 2] = a. The checking phase then finds that there is an occurrence of P at T [1; 5] but not at T [3; 4]. <p> The upper left corners of these potential occurrences of P are T [1; 5] (=I) and T [3; 4] (=II), because P [1; 3] = P <ref> [3; 2] </ref> = a. The checking phase then finds that there is an occurrence of P at T [1; 5] but not at T [3; 4]. The fourth test entry T [6; 3] = b is least useful in the elimination because b has 7 occurrences in P . <p> The upper left corners of these potential occurrences of P are T [1; 5] (=I) and T <ref> [3; 4] </ref> (=II), because P [1; 3] = P [3; 2] = a. The checking phase then finds that there is an occurrence of P at T [1; 5] but not at T [3; 4]. The fourth test entry T [6; 3] = b is least useful in the elimination because b has 7 occurrences in P . Hence we are left with 7 potential occurrences of P that overlap T [6; 3]. <p> The checking phase then finds that there is an occurrence of P at T [1; 5] but not at T [3; 4]. The fourth test entry T <ref> [6; 3] </ref> = b is least useful in the elimination because b has 7 occurrences in P . Hence we are left with 7 potential occurrences of P that overlap T [6; 3]. <p> The fourth test entry T <ref> [6; 3] </ref> = b is least useful in the elimination because b has 7 occurrences in P . Hence we are left with 7 potential occurrences of P that overlap T [6; 3]. Here we note that taking T [6; 2] = c as an additional test entry would eliminate all possible occurrences of P that overlap T [6; 2] and T [6; 3] because substring cb does not occur in P . <p> Hence we are left with 7 potential occurrences of P that overlap T <ref> [6; 3] </ref>. Here we note that taking T [6; 2] = c as an additional test entry would eliminate all possible occurrences of P that overlap T [6; 2] and T [6; 3] because substring cb does not occur in P .
Reference: [4] <author> R. Baeza-Yates and M. Regnier: </author> <title> Fast two-dimensional pattern matching. </title> <journal> Inform. Process. Lett. </journal> <volume> 45 (1993), </volume> <pages> 51-57. </pages>
Reference-contexts: Also in higher dimensions one should look at algorithms with good expected running time, not only the worst case. The recent algorithm by Baeza-Yates and Regnier <ref> [4] </ref> is a significant step in this direction; their algorithm finds the occurrences of a m fi m pattern in a n fi n text in expected time O (n 2 =m). <p> Test entry T [3; 6] = a eliminates all other occurrences of P that overlap T [3; 6] except those that have overlapping symbol a. The upper left corners of these potential occurrences of P are T [1; 5] (=I) and T <ref> [3; 4] </ref> (=II), because P [1; 3] = P [3; 2] = a. The checking phase then finds that there is an occurrence of P at T [1; 5] but not at T [3; 4]. <p> The upper left corners of these potential occurrences of P are T [1; 5] (=I) and T <ref> [3; 4] </ref> (=II), because P [1; 3] = P [3; 2] = a. The checking phase then finds that there is an occurrence of P at T [1; 5] but not at T [3; 4]. The fourth test entry T [6; 3] = b is least useful in the elimination because b has 7 occurrences in P . Hence we are left with 7 potential occurrences of P that overlap T [6; 3]. <p> Therefore this does not change the asymptotic behaviour of the algorithm. The algorithm of this section is quite similar to the (suboptimal) algorithm by Baeza-Yates & Regnier <ref> [4] </ref>, the main difference being that we use test samples with fixed size and location. 5 Lower bound In [20] Yao proved a lower bound of n the expected running time of one-dimensional pattern matching. In this section we present a generalization of Yao's result for d-dimensional hypercubic strings.
Reference: [5] <author> T.J. Baker: </author> <title> A technique for extending rapid exact-match string matching to arrays of more than one dimension. </title> <journal> SIAM J. on Comput. </journal> <volume> 7 (1978), </volume> <pages> 533-541. </pages>
Reference-contexts: In d-dimensional case P and T are d-dimensional arrays over . The applications are numerous. The exact one-dimensional pattern matching is well-understood. For two and higher dimensional versions several algorithms have been proposed, too, mainly aiming at good worst-case running time; see e.g. <ref> [6, 5, 14, 21, 2] </ref>. Recently, the two-dimensional problem has been solved in linear worst-case time with algo rithms that are alphabet-independent in the same sense as the one-dimensional Knuth-Morris-Pratt algorithm fl Work supported by the Academy of Finland. y tpkarkka@cs.Helsinki.FI, Department of Computer Science, P.O. <p> Test entry T [3; 6] = a eliminates all other occurrences of P that overlap T [3; 6] except those that have overlapping symbol a. The upper left corners of these potential occurrences of P are T <ref> [1; 5] </ref> (=I) and T [3; 4] (=II), because P [1; 3] = P [3; 2] = a. The checking phase then finds that there is an occurrence of P at T [1; 5] but not at T [3; 4]. <p> The upper left corners of these potential occurrences of P are T <ref> [1; 5] </ref> (=I) and T [3; 4] (=II), because P [1; 3] = P [3; 2] = a. The checking phase then finds that there is an occurrence of P at T [1; 5] but not at T [3; 4]. The fourth test entry T [6; 3] = b is least useful in the elimination because b has 7 occurrences in P . Hence we are left with 7 potential occurrences of P that overlap T [6; 3].
Reference: [6] <author> R.S. Bird: </author> <title> Two dimensional pattern matching. </title> <journal> Inform. Process. Lett. </journal> <volume> 6 (1977), </volume> <pages> 168-170. </pages>
Reference-contexts: In d-dimensional case P and T are d-dimensional arrays over . The applications are numerous. The exact one-dimensional pattern matching is well-understood. For two and higher dimensional versions several algorithms have been proposed, too, mainly aiming at good worst-case running time; see e.g. <ref> [6, 5, 14, 21, 2] </ref>. Recently, the two-dimensional problem has been solved in linear worst-case time with algo rithms that are alphabet-independent in the same sense as the one-dimensional Knuth-Morris-Pratt algorithm fl Work supported by the Academy of Finland. y tpkarkka@cs.Helsinki.FI, Department of Computer Science, P.O. <p> This proves that there can not be an occurrence of P inside subarray T [1 : 5; 1 : 5]. Test entry T <ref> [3; 6] </ref> = a eliminates all other occurrences of P that overlap T [3; 6] except those that have overlapping symbol a. <p> This proves that there can not be an occurrence of P inside subarray T [1 : 5; 1 : 5]. Test entry T <ref> [3; 6] </ref> = a eliminates all other occurrences of P that overlap T [3; 6] except those that have overlapping symbol a. The upper left corners of these potential occurrences of P are T [1; 5] (=I) and T [3; 4] (=II), because P [1; 3] = P [3; 2] = a. <p> The checking phase then finds that there is an occurrence of P at T [1; 5] but not at T [3; 4]. The fourth test entry T <ref> [6; 3] </ref> = b is least useful in the elimination because b has 7 occurrences in P . Hence we are left with 7 potential occurrences of P that overlap T [6; 3]. <p> The fourth test entry T <ref> [6; 3] </ref> = b is least useful in the elimination because b has 7 occurrences in P . Hence we are left with 7 potential occurrences of P that overlap T [6; 3]. Here we note that taking T [6; 2] = c as an additional test entry would eliminate all possible occurrences of P that overlap T [6; 2] and T [6; 3] because substring cb does not occur in P . <p> The fourth test entry T [6; 3] = b is least useful in the elimination because b has 7 occurrences in P . Hence we are left with 7 potential occurrences of P that overlap T [6; 3]. Here we note that taking T <ref> [6; 2] </ref> = c as an additional test entry would eliminate all possible occurrences of P that overlap T [6; 2] and T [6; 3] because substring cb does not occur in P . <p> Hence we are left with 7 potential occurrences of P that overlap T [6; 3]. Here we note that taking T <ref> [6; 2] </ref> = c as an additional test entry would eliminate all possible occurrences of P that overlap T [6; 2] and T [6; 3] because substring cb does not occur in P . <p> Hence we are left with 7 potential occurrences of P that overlap T <ref> [6; 3] </ref>. Here we note that taking T [6; 2] = c as an additional test entry would eliminate all possible occurrences of P that overlap T [6; 2] and T [6; 3] because substring cb does not occur in P .
Reference: [7] <author> R. Boyer and S. Moore: </author> <title> A fast string searching algorithm. </title> <booktitle> Comm. ACM 20 (1977), </booktitle> <pages> 762-772. </pages>
Reference-contexts: Box 26 (Teollisuuskatu 23), SF-00014 University of Helsinki, Finland. z ukkonen@cs.Helsinki.FI, Department of Computer Science, P.O. Box 26 (Teollisuuskatu 23), SF-00014 University of Helsinki, Finland. [3, 11]. A space-economical solution is given in [9]. In the applications of one-dimensional matching the Boyer-Moore algorithm <ref> [7] </ref> whose expected running time is "sublinear" is clearly the most successful; see e.g. [13]. Also in higher dimensions one should look at algorithms with good expected running time, not only the worst case. <p> A separate checking phase then examines whether or not a potential occurrence really contains P . This leads to fast algorithms because the elimination phase needs on the average to examine only a small fraction of T . The well-known Boyer-Moore algorithm <ref> [7] </ref> has this flavour. In this paper we develop algorithms based on the negative view further for two and higher dimensional pattern matching. We explain the idea of our algorithms using two dimensional P and T .
Reference: [8] <author> W. Chang and E. Lawler: </author> <title> Approximate string matching in sublinear expected time. </title> <booktitle> Proc. 31st IEEE FOCS, </booktitle> <year> 1990, </year> <pages> 116-124. </pages>
Reference-contexts: The algorithm requires that k m 2 =(4dlog c m 2 e). Under this condition the expected running time is at most linear in jT j; previously Chang and Lawler <ref> [8] </ref> (see also [19]) have given an algorithm with similar properties for the k differences problem of one-dimensional approximate matching. The two-dimensional k mismatches problem has also been studied in [17]. <p> Substituting this into the bound of the above theorem shows that whenever the algorithm works, it is at most linear in jT j. Chang and Lawler <ref> [8] </ref> have obtained similar results in one-dimensional case; their algorithm also works for the k differences problem. 7 Concluding remarks There are many possibilities for practical fine-tuning of our algorithms.
Reference: [9] <author> M. Crochemore, L. Gasieniec and W. Rytter: </author> <title> Two-dimensional pattern matching by sampling. </title> <journal> Inform. Process. Lett. </journal> <volume> 46 (1993), </volume> <pages> 159-162. </pages>
Reference-contexts: Box 26 (Teollisuuskatu 23), SF-00014 University of Helsinki, Finland. z ukkonen@cs.Helsinki.FI, Department of Computer Science, P.O. Box 26 (Teollisuuskatu 23), SF-00014 University of Helsinki, Finland. [3, 11]. A space-economical solution is given in <ref> [9] </ref>. In the applications of one-dimensional matching the Boyer-Moore algorithm [7] whose expected running time is "sublinear" is clearly the most successful; see e.g. [13]. Also in higher dimensions one should look at algorithms with good expected running time, not only the worst case.
Reference: [10] <author> M. Crochemore, W. Rytter: </author> <title> Efficient Algorithms on Texts. Manuscript of a monograph. </title>
Reference-contexts: This property helps in writing fast code for the algorithms, for both sequential and parallel environments. |After completing this paper we found out that the idea of using superalphabet of size fi (jP j) in two-dimensional matching has very recently appeared or will appear in <ref> [10, 15, 18] </ref>. Crochemore and Rytter [10] sketch an algorithm which comes close to one of our algorithms, while the algorithms in [15, 18] differ in that they determine the test entries dynamically. <p> Crochemore and Rytter <ref> [10] </ref> sketch an algorithm which comes close to one of our algorithms, while the algorithms in [15, 18] differ in that they determine the test entries dynamically. The above idea is formulated in Section 2 as a generic pattern matching algorithm in a very general setting.
Reference: [11] <author> Z. Galil and K. Park: </author> <title> Truly alphabet-independent two-dimensional pattern matching. </title> <booktitle> Proc. 33th IEEE FOCS, </booktitle> <year> 1992, </year> <pages> 247-256. </pages>
Reference-contexts: Box 26 (Teollisuuskatu 23), SF-00014 University of Helsinki, Finland. z ukkonen@cs.Helsinki.FI, Department of Computer Science, P.O. Box 26 (Teollisuuskatu 23), SF-00014 University of Helsinki, Finland. <ref> [3, 11] </ref>. A space-economical solution is given in [9]. In the applications of one-dimensional matching the Boyer-Moore algorithm [7] whose expected running time is "sublinear" is clearly the most successful; see e.g. [13].
Reference: [12] <author> G.H. Gonnet: </author> <title> Efficient searching of text and pictures (extended abstract). </title> <type> Tech. Rep. </type> <institution> OED-88-02, Centre for the new OED, University of Waterloo, </institution> <year> 1988. </year>
Reference-contexts: For example, in the algorithm of Two and higher dimensional pattern matching 723 Section 3 it is possible to combine the elimination and checking phases using spiral-shaped test strings of Gonnet <ref> [12] </ref>. The text processing in all algorithms can be performed on-line, with a relatively small window into the text. In the algorithms for exact matching a window of size O (m 2 ) suffices; the algorithm for k mismatches needs window size O (nm).
Reference: [13] <author> A. Hume and D. Sunday: </author> <title> Fast string searching. </title> <booktitle> Software | Practice and Experience 21 (1991), </booktitle> <pages> 1221-1248. </pages>
Reference-contexts: Box 26 (Teollisuuskatu 23), SF-00014 University of Helsinki, Finland. [3, 11]. A space-economical solution is given in [9]. In the applications of one-dimensional matching the Boyer-Moore algorithm [7] whose expected running time is "sublinear" is clearly the most successful; see e.g. <ref> [13] </ref>. Also in higher dimensions one should look at algorithms with good expected running time, not only the worst case.
Reference: [14] <author> R. Karp and M. Rabin: </author> <title> Efficient randomized pattern-matching algorithms. </title> <journal> IBM J. Res. Develop. </journal> <volume> 31 (1987), </volume> <pages> 249-260. </pages>
Reference-contexts: In d-dimensional case P and T are d-dimensional arrays over . The applications are numerous. The exact one-dimensional pattern matching is well-understood. For two and higher dimensional versions several algorithms have been proposed, too, mainly aiming at good worst-case running time; see e.g. <ref> [6, 5, 14, 21, 2] </ref>. Recently, the two-dimensional problem has been solved in linear worst-case time with algo rithms that are alphabet-independent in the same sense as the one-dimensional Knuth-Morris-Pratt algorithm fl Work supported by the Academy of Finland. y tpkarkka@cs.Helsinki.FI, Department of Computer Science, P.O.
Reference: [15] <author> J.Y. Kim and J. Shawe-Taylor: </author> <title> Fast expected two dimensional pattern matching. </title> <booktitle> Proc. First South American Workshop on String Processing (ed. </booktitle> <editor> R. Baeza-Yates and N. Ziviani), </editor> <year> 1993, </year> <pages> 77-92. </pages>
Reference-contexts: This property helps in writing fast code for the algorithms, for both sequential and parallel environments. |After completing this paper we found out that the idea of using superalphabet of size fi (jP j) in two-dimensional matching has very recently appeared or will appear in <ref> [10, 15, 18] </ref>. Crochemore and Rytter [10] sketch an algorithm which comes close to one of our algorithms, while the algorithms in [15, 18] differ in that they determine the test entries dynamically. <p> Crochemore and Rytter [10] sketch an algorithm which comes close to one of our algorithms, while the algorithms in <ref> [15, 18] </ref> differ in that they determine the test entries dynamically. The above idea is formulated in Section 2 as a generic pattern matching algorithm in a very general setting. The elimination of potential occurrences of P is based on reading test strings of length q from T .
Reference: [16] <author> D.E. Knuth, J.H. Morris and V.B. Pratt: </author> <title> Fast pattern matching in strings. </title> <journal> SIAM J. on Comput. </journal> <volume> 6 (1977), </volume> <pages> 323-350. </pages>
Reference-contexts: The algorithms are not dimensionality specific. For d-dimensional P of size m d and T of size n d they run in expected time O ( n d In [20], A. Yao confirmed a conjecture of Knuth <ref> [16] </ref> by proving a lower bound of O ( n m log c m) for one-dimensional case (when n 2m). Yao's argument generalizes for two and higher dimensional matching and gives a general lower bound O ( jT j jP j log c jP j). <p> The two-dimensional k mismatches problem has also been studied in [17]. The naive algorithm for pattern matching and its improvements such as the Knuth-Morris-Pratt algorithm <ref> [16] </ref> are based on a view of the problem that could be called positive: the algorithm tries to prove at each text location that there is an occurrence of P at that location. 715 716 Juha K arkk ainen and Esko Ukkonen In applications T often contains relatively few occurrences of
Reference: [17] <author> S. Ranka and T. Heywood: </author> <title> Two-dimensional pattern matching with k mismatches. </title> <booktitle> Pattern Recognition 24 (1991), </booktitle> <pages> 31-40. </pages>
Reference-contexts: Under this condition the expected running time is at most linear in jT j; previously Chang and Lawler [8] (see also [19]) have given an algorithm with similar properties for the k differences problem of one-dimensional approximate matching. The two-dimensional k mismatches problem has also been studied in <ref> [17] </ref>.
Reference: [18] <author> J. Tarhio: </author> <title> A Boyer-Moore approach for two-dimensional matching. </title> <type> Technical Report, </type> <institution> Division of Computer Science, University of California at Berkeley, </institution> <year> 1993. </year>
Reference-contexts: This property helps in writing fast code for the algorithms, for both sequential and parallel environments. |After completing this paper we found out that the idea of using superalphabet of size fi (jP j) in two-dimensional matching has very recently appeared or will appear in <ref> [10, 15, 18] </ref>. Crochemore and Rytter [10] sketch an algorithm which comes close to one of our algorithms, while the algorithms in [15, 18] differ in that they determine the test entries dynamically. <p> Crochemore and Rytter [10] sketch an algorithm which comes close to one of our algorithms, while the algorithms in <ref> [15, 18] </ref> differ in that they determine the test entries dynamically. The above idea is formulated in Section 2 as a generic pattern matching algorithm in a very general setting. The elimination of potential occurrences of P is based on reading test strings of length q from T .
Reference: [19] <author> E. Ukkonen: </author> <title> Approximate string-matching with q-grams and maximal matches. </title> <booktitle> Theoretical Computer Science 92 (1992), </booktitle> <pages> 191-211. </pages>
Reference-contexts: The algorithm requires that k m 2 =(4dlog c m 2 e). Under this condition the expected running time is at most linear in jT j; previously Chang and Lawler [8] (see also <ref> [19] </ref>) have given an algorithm with similar properties for the k differences problem of one-dimensional approximate matching. The two-dimensional k mismatches problem has also been studied in [17].
Reference: [20] <author> A.C. Yao: </author> <title> The complexity of pattern matching for a random string. </title> <journal> SIAM J. on Comput. </journal> <volume> 8 (1979), </volume> <pages> 368-387. </pages>
Reference-contexts: The algorithms are not dimensionality specific. For d-dimensional P of size m d and T of size n d they run in expected time O ( n d In <ref> [20] </ref>, A. Yao confirmed a conjecture of Knuth [16] by proving a lower bound of O ( n m log c m) for one-dimensional case (when n 2m). <p> Then the elimination phase can be implemented efficiently using one-dimensional multipattern matching. Section 5 reformulates the lower bound of Yao <ref> [20] </ref> for d-dimensional pattern matching. In Section 6 we generalize the algorithm for the k mismatches problem. The elimination is based on k + p non-overlapping test strings; here p is a parameter used to optimize the performance of the method. <p> Therefore this does not change the asymptotic behaviour of the algorithm. The algorithm of this section is quite similar to the (suboptimal) algorithm by Baeza-Yates & Regnier [4], the main difference being that we use test samples with fixed size and location. 5 Lower bound In <ref> [20] </ref> Yao proved a lower bound of n the expected running time of one-dimensional pattern matching. In this section we present a generalization of Yao's result for d-dimensional hypercubic strings. <p> Proof. The proof is a simple modification of Yao's proof in <ref> [20] </ref>. 2 Above theorem shows that for majority of patterns even the best case complexity of pattern matching is n d for a fixed d.
Reference: [21] <author> R.F. Zhu and T. Takaoka: </author> <title> A technique for two-dimensional pattern matching. </title> <booktitle> Comm. ACM 32 (1989), </booktitle> <pages> 1110-1120. </pages>
Reference-contexts: In d-dimensional case P and T are d-dimensional arrays over . The applications are numerous. The exact one-dimensional pattern matching is well-understood. For two and higher dimensional versions several algorithms have been proposed, too, mainly aiming at good worst-case running time; see e.g. <ref> [6, 5, 14, 21, 2] </ref>. Recently, the two-dimensional problem has been solved in linear worst-case time with algo rithms that are alphabet-independent in the same sense as the one-dimensional Knuth-Morris-Pratt algorithm fl Work supported by the Academy of Finland. y tpkarkka@cs.Helsinki.FI, Department of Computer Science, P.O.
References-found: 21

