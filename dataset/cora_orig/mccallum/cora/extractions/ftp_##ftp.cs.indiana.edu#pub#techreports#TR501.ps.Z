URL: ftp://ftp.cs.indiana.edu/pub/techreports/TR501.ps.Z
Refering-URL: http://www.cs.indiana.edu/ftp/techreports/index.html
Root-URL: http://www.cs.indiana.edu
Title: Exploiting implicit loop parallelism using multiple multithreaded servers in Java  
Author: Fabian Breg Aart Bik Dennis Gannon 
Date: December 16, 1997  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> U. Banerjee. </author> <title> Dependence Analysis. A book Series on Loop Transformations for Restructuring Compilers. </title> <publisher> Kluwer, </publisher> <address> Boston, </address> <year> 1997. </year>
Reference-contexts: Figure 1 shows the client, the servers and their workers. The parallelization is driven by annotations that have to be inserted manually in the source code. We propose a set of annotations which can be used to exploit parallelism in fully independent for-loops. Several techniques for dependency analysis exist <ref> [1, 11] </ref>, which can be used to detect loop parallelism. Currently, our compiler does not perform such dependency analysis, but instead relies on the annotations to correctly identify a parallel loop. Do-across like loops are not implemented, because the synchronization overhead in a distributed system tends to be too high. <p> The following examples show how data should be annotated in different kinds of loops. The array a in these examples are arrays of 100 elements. Example 1 We start with a simple example: /*dist hosts = 2, threads = 4, a <ref> [0, 1] </ref> block mod_inout */ a [i] = i; Each iteration uses only one element from the array, with the first iteration using the element 0 and every next iteration using the next element. <p> Example 2 The next example shows how to use the offset: /*dist hosts = 2, threads = 4, a <ref> [5, 1] </ref> block mod_inout */ a [i] = i; In this example, element 5 from the array is the element accessed in the first iteration so the offset has to be 5. Each iteration still accesses only one element. Also, in this example, only elements 5 to 65 are distributed. <p> private GlobalModIn smin; private PrivateUnmod [] punm = new PrivateUnmod [10]; private PrivateModIn [] pmin = new PrivateModIn [10]; private PrivateModInout [] pmio = new PrivateModInout [10]; ... public Loop () ... public void start () f /*dist block, hosts = 2, threads = 4, sunm unmod, smin mod_in, punm <ref> [0, 1] </ref> block unmod, pmin [0, 1] block mod_in, pmio [0, 1] block mod_inout */ ... = sunm... smin = ...; ... = punm [...]; pmin [...] = ...; pmio [...] = ...; g g public static void main (String [] Args) f Loop l = new Loop (); l.start (); <p> [] punm = new PrivateUnmod [10]; private PrivateModIn [] pmin = new PrivateModIn [10]; private PrivateModInout [] pmio = new PrivateModInout [10]; ... public Loop () ... public void start () f /*dist block, hosts = 2, threads = 4, sunm unmod, smin mod_in, punm <ref> [0, 1] </ref> block unmod, pmin [0, 1] block mod_in, pmio [0, 1] block mod_inout */ ... = sunm... smin = ...; ... = punm [...]; pmin [...] = ...; pmio [...] = ...; g g public static void main (String [] Args) f Loop l = new Loop (); l.start (); g 15 public interface Loopstart0Intf <p> [10]; private PrivateModIn [] pmin = new PrivateModIn [10]; private PrivateModInout [] pmio = new PrivateModInout [10]; ... public Loop () ... public void start () f /*dist block, hosts = 2, threads = 4, sunm unmod, smin mod_in, punm <ref> [0, 1] </ref> block unmod, pmin [0, 1] block mod_in, pmio [0, 1] block mod_inout */ ... = sunm... smin = ...; ... = punm [...]; pmin [...] = ...; pmio [...] = ...; g g public static void main (String [] Args) f Loop l = new Loop (); l.start (); g 15 public interface Loopstart0Intf extends distribute.DistributeServerIntf public void setShared <p> for (int counterK = curKlb; counterK &lt; curKub; counterK++) pmio [counterK] = pmioBlock [curItem++]; Loopstart0 [counterI % 2].deleteJob (jobId [counterI]); /* Remove job from worker */ g g catch (java.rmi.RemoteException e) f System.exit (1); g g 21 /*dist block, hosts = 2, threads = 4, b unmod, matsize unmod, a <ref> [0, 1] </ref> block mod_in, c [0, 1] block mod_out */ for (int i = 0; i &lt; matsize; i++) for (int j = 0; j &lt; matsize; j++) f c [i][j] = 0; for (int k = 0; k &lt; matsize; k++) c [i][j] += a [i][k] * b [k][j]; pieces <p> counterK &lt; curKub; counterK++) pmio [counterK] = pmioBlock [curItem++]; Loopstart0 [counterI % 2].deleteJob (jobId [counterI]); /* Remove job from worker */ g g catch (java.rmi.RemoteException e) f System.exit (1); g g 21 /*dist block, hosts = 2, threads = 4, b unmod, matsize unmod, a <ref> [0, 1] </ref> block mod_in, c [0, 1] block mod_out */ for (int i = 0; i &lt; matsize; i++) for (int j = 0; j &lt; matsize; j++) f c [i][j] = 0; for (int k = 0; k &lt; matsize; k++) c [i][j] += a [i][k] * b [k][j]; pieces of code are similar, however, <p> y * rowOffset; for (x = xMin; x &lt;= xMax; x++) f p1 = p2; p3 = (pixels2 [offset - rowOffset + 1] & 0xff); p4 = p5; p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); values <ref> [1] </ref> = p1; values [2] = p2; values [3] = p3; values [4] = p4; values [5] = p5; values [6] = p6; values [7] = p7; values [8] = p8; values [9] = p9; pixels [offset++] = (byte)(findMedian (values) & 0xff); g showProgress ((double)(y-roiY)/roiHeight); g hideProgress (); g void medianFilter <p> * rowOffset; for (int x = xMin; x &lt;= xMax; x++) f p1 = p2; p3 = (pixels2 [offset - rowOffset + 1] & 0xff); p4 = p5; p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); save <ref> [1] </ref> = p1; save [2] = p2; save [3] = p3; save [4] = p4; save [5] = p5; save [6] = p6; save [7] = p7; save [8] = p8; save [9] = p9; pixels [offset++] = (byte)(findMedian (save) & 0xff); g g 25 We have shown that applications may
Reference: [2] <author> A.J.C. Bik and D.B. Gannon. </author> <title> Automatically Exploiting Implicit Parallelism in Java. </title> <journal> Con-currency, Practice and Experience, </journal> <volume> 9(6), </volume> <year> 1997. </year>
Reference-contexts: Other attempts to make Java suitable for high performance computing consists of optimizing Java compilers and Java restructuring compilers. An example of the latter kind is Javar [3], which exploits loop parallelism as well as multi-way recursive method parallelism using the multithreading facilities of Java as described in <ref> [2] </ref>. This document describes the source code transformations needed to exploit loop parallelism using multiple multithreaded servers in a distributed system. We propose and implement a source code restructuring strategy, which uses multiple servers each, running a number of workers to execute a subset of iterations of parallel loops. <p> Currently, our compiler does not perform such dependency analysis, but instead relies on the annotations to correctly identify a parallel loop. Do-across like loops are not implemented, because the synchronization overhead in a distributed system tends to be too high. This project extends the work done in <ref> [2] </ref>. Javar, the compiler developed in this project, is extended to include the transformation of Java programs as described in this document. 1 The outline of this article is as follows: Section 2 describes Java's multithreading and communication features in some detail. <p> Loop f private Loopstart0Intf [] Loopstart0 = null; private GlobalUnmod sunm; private GlobalModIn smin; private PrivateUnmod [] punm = new PrivateUnmod [10]; private PrivateModIn [] pmin = new PrivateModIn [10]; private PrivateModInout [] pmio = new PrivateModInout [10]; Loop () f if (Loopstart0 == null) f Loopstart0 = new Loopstart0Intf <ref> [2] </ref>; distribute.Distribution.lookup (Loopstart0, "Loopstart0"); g public void start () f ... g public static void main (String [] Args) f Loop l = new Loop (); l.start (); g 20 public void start () f int blockIters = ((int) Math.ceil (((double) ((((10 - 0) - 1) + 1) / 1)) / <p> (x = xMin; x &lt;= xMax; x++) f p1 = p2; p3 = (pixels2 [offset - rowOffset + 1] & 0xff); p4 = p5; p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); values [1] = p1; values <ref> [2] </ref> = p2; values [3] = p3; values [4] = p4; values [5] = p5; values [6] = p6; values [7] = p7; values [8] = p8; values [9] = p9; pixels [offset++] = (byte)(findMedian (values) & 0xff); g showProgress ((double)(y-roiY)/roiHeight); g hideProgress (); g void medianFilter () f byte [] <p> x = xMin; x &lt;= xMax; x++) f p1 = p2; p3 = (pixels2 [offset - rowOffset + 1] & 0xff); p4 = p5; p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); save [1] = p1; save <ref> [2] </ref> = p2; save [3] = p3; save [4] = p4; save [5] = p5; save [6] = p6; save [7] = p7; save [8] = p8; save [9] = p9; pixels [offset++] = (byte)(findMedian (save) & 0xff); g g 25 We have shown that applications may show good speedup when
Reference: [3] <author> A.J.C. Bik, J.E. Villacis, and D.B. Gannon. </author> <title> JAVAR manual. </title> <institution> Computer Science Department, Indiana University, </institution> <year> 1997. </year> <note> This manual and the complete source of javar is made available at http://www.extreme.indiana.edu/hpjava/. </note>
Reference-contexts: Currently several Just In Time (JIT) compilers are available, which translate the Java Bytecode to native machine code just prior to execution. Other attempts to make Java suitable for high performance computing consists of optimizing Java compilers and Java restructuring compilers. An example of the latter kind is Javar <ref> [3] </ref>, which exploits loop parallelism as well as multi-way recursive method parallelism using the multithreading facilities of Java as described in [2]. This document describes the source code transformations needed to exploit loop parallelism using multiple multithreaded servers in a distributed system. <p> The code to execute the iterations in parallel can be generated by a Java restructuring compiler. We have implemented our transformations as a module in Javar <ref> [3] </ref>. Our approach is to divide the loop iterations among a number of workers, which run as a separate thread in a server process. To make this work, we also sent the required data to the workers. Data that is used by every worker is sent to each server once. <p> &lt;= xMax; x++) f p1 = p2; p3 = (pixels2 [offset - rowOffset + 1] & 0xff); p4 = p5; p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); values [1] = p1; values [2] = p2; values <ref> [3] </ref> = p3; values [4] = p4; values [5] = p5; values [6] = p6; values [7] = p7; values [8] = p8; values [9] = p9; pixels [offset++] = (byte)(findMedian (values) & 0xff); g showProgress ((double)(y-roiY)/roiHeight); g hideProgress (); g void medianFilter () f byte [] pixels2; int rowOffset; int <p> &lt;= xMax; x++) f p1 = p2; p3 = (pixels2 [offset - rowOffset + 1] & 0xff); p4 = p5; p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); save [1] = p1; save [2] = p2; save <ref> [3] </ref> = p3; save [4] = p4; save [5] = p5; save [6] = p6; save [7] = p7; save [8] = p8; save [9] = p9; pixels [offset++] = (byte)(findMedian (save) & 0xff); g g 25 We have shown that applications may show good speedup when the transformations described are
Reference: [4] <author> H.M. Deitel and P.J. Deitel. </author> <title> Java How to Program. </title> <publisher> Prentice Hall, </publisher> <address> Upper Sadle River, New York, </address> <year> 1997. </year>
Reference-contexts: Java provides constructs for synchronization in the form of monitors. This section describes the multithreading facilities used in this project. For a more elaborate introduction in Java's multithreading features we refer to <ref> [9, 4] </ref>. 2 A thread is created by creating an object of the Thread class or a subclass of this class. <p> p1 = p2; p3 = (pixels2 [offset - rowOffset + 1] & 0xff); p4 = p5; p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); values [1] = p1; values [2] = p2; values [3] = p3; values <ref> [4] </ref> = p4; values [5] = p5; values [6] = p6; values [7] = p7; values [8] = p8; values [9] = p9; pixels [offset++] = (byte)(findMedian (values) & 0xff); g showProgress ((double)(y-roiY)/roiHeight); g hideProgress (); g void medianFilter () f byte [] pixels2; int rowOffset; int low__ = yMin, up__ <p> p1 = p2; p3 = (pixels2 [offset - rowOffset + 1] & 0xff); p4 = p5; p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); save [1] = p1; save [2] = p2; save [3] = p3; save <ref> [4] </ref> = p4; save [5] = p5; save [6] = p6; save [7] = p7; save [8] = p8; save [9] = p9; pixels [offset++] = (byte)(findMedian (save) & 0xff); g g 25 We have shown that applications may show good speedup when the transformations described are applied.
Reference: [5] <author> J. Flanagan. </author> <title> Java in a Nutshell. O' Reilly, </title> <address> Sebastopol, California, </address> <note> second edition, 1997. 26 </note>
Reference-contexts: This project uses its concurrent and distributed features to parallelize loops, so these two features are first described in some detail. For a description of the Java language we refer <ref> [6, 5] </ref>. 2.1 Java threads Java has language support for multithreaded execution of programs. The Java API provides classes and interfaces to create and manipulate threads and methods to perform communication between them. Java provides constructs for synchronization in the form of monitors. <p> Example 2 The next example shows how to use the offset: /*dist hosts = 2, threads = 4, a <ref> [5, 1] </ref> block mod_inout */ a [i] = i; In this example, element 5 from the array is the element accessed in the first iteration so the offset has to be 5. Each iteration still accesses only one element. Also, in this example, only elements 5 to 65 are distributed. <p> = (pixels2 [offset - rowOffset + 1] & 0xff); p4 = p5; p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); values [1] = p1; values [2] = p2; values [3] = p3; values [4] = p4; values <ref> [5] </ref> = p5; values [6] = p6; values [7] = p7; values [8] = p8; values [9] = p9; pixels [offset++] = (byte)(findMedian (values) & 0xff); g showProgress ((double)(y-roiY)/roiHeight); g hideProgress (); g void medianFilter () f byte [] pixels2; int rowOffset; int low__ = yMin, up__ = yMax; pixels2 = <p> = (pixels2 [offset - rowOffset + 1] & 0xff); p4 = p5; p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); save [1] = p1; save [2] = p2; save [3] = p3; save [4] = p4; save <ref> [5] </ref> = p5; save [6] = p6; save [7] = p7; save [8] = p8; save [9] = p9; pixels [offset++] = (byte)(findMedian (save) & 0xff); g g 25 We have shown that applications may show good speedup when the transformations described are applied.
Reference: [6] <author> J. Gosling, B. Joy, and G. Steele. </author> <title> The Java Language Specification. The Java Series. </title> <publisher> Addison-Wesley Developers Press, </publisher> <year> 1996. </year>
Reference-contexts: To exploit this computing power the heterogeneous nature of the Internet has to be overcome. With the introduction of Java <ref> [6] </ref> and its accompanying Bytecode [7], true portable programs can be written in a high level language that can be downloaded to and run on any computer that hosts a Bytecode interpreter. <p> This project uses its concurrent and distributed features to parallelize loops, so these two features are first described in some detail. For a description of the Java language we refer <ref> [6, 5] </ref>. 2.1 Java threads Java has language support for multithreaded execution of programs. The Java API provides classes and interfaces to create and manipulate threads and methods to perform communication between them. Java provides constructs for synchronization in the form of monitors. <p> rowOffset + 1] & 0xff); p4 = p5; p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); values [1] = p1; values [2] = p2; values [3] = p3; values [4] = p4; values [5] = p5; values <ref> [6] </ref> = p6; values [7] = p7; values [8] = p8; values [9] = p9; pixels [offset++] = (byte)(findMedian (values) & 0xff); g showProgress ((double)(y-roiY)/roiHeight); g hideProgress (); g void medianFilter () f byte [] pixels2; int rowOffset; int low__ = yMin, up__ = yMax; pixels2 = new byte [width * <p> rowOffset + 1] & 0xff); p4 = p5; p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); save [1] = p1; save [2] = p2; save [3] = p3; save [4] = p4; save [5] = p5; save <ref> [6] </ref> = p6; save [7] = p7; save [8] = p8; save [9] = p9; pixels [offset++] = (byte)(findMedian (save) & 0xff); g g 25 We have shown that applications may show good speedup when the transformations described are applied.
Reference: [7] <author> T. Lindholm and F. Yellin. </author> <title> The Java Virtual Machine Specification. </title> <publisher> Addison Wesley, </publisher> <address> Massachusetts, </address> <year> 1996. </year>
Reference-contexts: To exploit this computing power the heterogeneous nature of the Internet has to be overcome. With the introduction of Java [6] and its accompanying Bytecode <ref> [7] </ref>, true portable programs can be written in a high level language that can be downloaded to and run on any computer that hosts a Bytecode interpreter. This feature, together with the communication that the API provides, makes Java a suitable language to implement distributed software systems. <p> 0xff); p4 = p5; p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); values [1] = p1; values [2] = p2; values [3] = p3; values [4] = p4; values [5] = p5; values [6] = p6; values <ref> [7] </ref> = p7; values [8] = p8; values [9] = p9; pixels [offset++] = (byte)(findMedian (values) & 0xff); g showProgress ((double)(y-roiY)/roiHeight); g hideProgress (); g void medianFilter () f byte [] pixels2; int rowOffset; int low__ = yMin, up__ = yMax; pixels2 = new byte [width * height]; System.arraycopy (pixels,0,pixels2,0,width*height); rowOffset <p> 0xff); p4 = p5; p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); save [1] = p1; save [2] = p2; save [3] = p3; save [4] = p4; save [5] = p5; save [6] = p6; save <ref> [7] </ref> = p7; save [8] = p8; save [9] = p9; pixels [offset++] = (byte)(findMedian (save) & 0xff); g g 25 We have shown that applications may show good speedup when the transformations described are applied.
Reference: [8] <author> W. Rasband. </author> <note> Image/J version 0.46. </note> <institution> National Institutes of Health, USA, </institution> <year> 1997. </year> <note> Package available at http://rsb.info.nih.gov/IJ/. </note>
Reference-contexts: f ... g public static void main (String [] Args) f Loop l = new Loop (); l.start (); g 20 public void start () f int blockIters = ((int) Math.ceil (((double) ((((10 - 0) - 1) + 1) / 1)) / ((double) 8))); int [] jobId = (new int <ref> [8] </ref>); PrivateModIn [] pminBlock = (new PrivateModIn [blockIters * (Math.abs (1) * Math.abs (1))]); PrivateModInout [] pmioBlock = (new PrivateModInout [blockIters * (Math.abs (1) * Math.abs (1))]); int curItem = 0, curJlb = 0, curJub = 0, curJst = 0, curKlb = 0, curKub = 0, curKst = 0; for (int <p> This is due to the lower processor speed, which makes serialization of doubles even more expensive and thus deteriorates performance. To assess whether our method can be used to parallelize other applications, we have tested 23 our method on the Image/J application <ref> [8] </ref>. Image/J is a prototype image processing program, which implements some well know image processing algorithms like smoothing. The method containing the loop is shown in Figure 21. The left side shows the original code, the right side shows the code somewhat modified with our annotations added. <p> p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); values [1] = p1; values [2] = p2; values [3] = p3; values [4] = p4; values [5] = p5; values [6] = p6; values [7] = p7; values <ref> [8] </ref> = p8; values [9] = p9; pixels [offset++] = (byte)(findMedian (values) & 0xff); g showProgress ((double)(y-roiY)/roiHeight); g hideProgress (); g void medianFilter () f byte [] pixels2; int rowOffset; int low__ = yMin, up__ = yMax; pixels2 = new byte [width * height]; System.arraycopy (pixels,0,pixels2,0,width*height); rowOffset = width; /*dist hosts <p> p6 = (pixels2 [offset + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); save [1] = p1; save [2] = p2; save [3] = p3; save [4] = p4; save [5] = p5; save [6] = p6; save [7] = p7; save <ref> [8] </ref> = p8; save [9] = p9; pixels [offset++] = (byte)(findMedian (save) & 0xff); g g 25 We have shown that applications may show good speedup when the transformations described are applied.
Reference: [9] <author> K.S. Siyan and J.L. Weaver. </author> <title> Inside Java. </title> <publisher> New Riders Publishing, </publisher> <address> Indianapolis, Indiana, </address> <year> 1997. </year>
Reference-contexts: Java provides constructs for synchronization in the form of monitors. This section describes the multithreading facilities used in this project. For a more elaborate introduction in Java's multithreading features we refer to <ref> [9, 4] </ref>. 2 A thread is created by creating an object of the Thread class or a subclass of this class. <p> We will now briefly describe how Java RMI works. For a more elaborate description we refer to <ref> [9] </ref>. An overview of RMI is shown in Figure 2. First, a server creates a remote object and registers it at the registry, which is represented by arrows (1) in the figure. The client can obtain references to objects stored in the registry as shown by arrows (2). <p> + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); values [1] = p1; values [2] = p2; values [3] = p3; values [4] = p4; values [5] = p5; values [6] = p6; values [7] = p7; values [8] = p8; values <ref> [9] </ref> = p9; pixels [offset++] = (byte)(findMedian (values) & 0xff); g showProgress ((double)(y-roiY)/roiHeight); g hideProgress (); g void medianFilter () f byte [] pixels2; int rowOffset; int low__ = yMin, up__ = yMax; pixels2 = new byte [width * height]; System.arraycopy (pixels,0,pixels2,0,width*height); rowOffset = width; /*dist hosts = 2, threads = <p> + 1] & 0xff); p7 = p8; p9 = (pixels2 [offset + rowOffset + 1] & 0xff); save [1] = p1; save [2] = p2; save [3] = p3; save [4] = p4; save [5] = p5; save [6] = p6; save [7] = p7; save [8] = p8; save <ref> [9] </ref> = p9; pixels [offset++] = (byte)(findMedian (save) & 0xff); g g 25 We have shown that applications may show good speedup when the transformations described are applied.
Reference: [10] <author> Sun Microsystems. </author> <title> Java Remote Method Invocation Specification, </title> <month> feb </month> <year> 1997. </year>
Reference-contexts: Although the Java API provides a simple interface for programming sockets, applications still have to implement a protocol for encoding and decoding messages, which is a cumbersome and error-prone task. Java RMI <ref> [10] </ref> is designed to simplify the communication between two objects on separate machines by allowing an object to invoke the methods of an object on a remote machine in the same way as methods on local objects are invoked. <p> Each iteration still accesses only one element. Also, in this example, only elements 5 to 65 are distributed. Example 3 In the next example, every iteration accesses 10 elements: /*dist hosts = 2, threads = 4, a <ref> [50, 10] </ref> block mod_inout */ for (int j = 0; j &lt; 10; j++) Note that in this example the outer loop is being parallelized. The blocksize is set to 10, since the inner loop accesses 10 elements. <p> The first element of the first block accessed is element 50, so offset is 50. 8 Example 4 The next example is the same as the previous one, except for the different parallel loop stride: /*dist hosts = 2, threads = 4, a <ref> [50, 10] </ref> block mod_inout */ for (int j = 0; j &lt; 10; j++) Changing the loop stride makes no difference in the annotation, however, since every iteration still accesses 10 elements. In this example, each workers receives 20 elements, because the stride is now 2. <p> Since a method can have multiple parallel loops an additional unique number is also in the name. 14 public class Loop f private GlobalUnmod sunm; private GlobalModIn smin; private PrivateUnmod [] punm = new PrivateUnmod <ref> [10] </ref>; private PrivateModIn [] pmin = new PrivateModIn [10]; private PrivateModInout [] pmio = new PrivateModInout [10]; ... public Loop () ... public void start () f /*dist block, hosts = 2, threads = 4, sunm unmod, smin mod_in, punm [0, 1] block unmod, pmin [0, 1] block mod_in, pmio [0, <p> Since a method can have multiple parallel loops an additional unique number is also in the name. 14 public class Loop f private GlobalUnmod sunm; private GlobalModIn smin; private PrivateUnmod [] punm = new PrivateUnmod <ref> [10] </ref>; private PrivateModIn [] pmin = new PrivateModIn [10]; private PrivateModInout [] pmio = new PrivateModInout [10]; ... public Loop () ... public void start () f /*dist block, hosts = 2, threads = 4, sunm unmod, smin mod_in, punm [0, 1] block unmod, pmin [0, 1] block mod_in, pmio [0, 1] block mod_inout */ ... = sunm... smin <p> a method can have multiple parallel loops an additional unique number is also in the name. 14 public class Loop f private GlobalUnmod sunm; private GlobalModIn smin; private PrivateUnmod [] punm = new PrivateUnmod <ref> [10] </ref>; private PrivateModIn [] pmin = new PrivateModIn [10]; private PrivateModInout [] pmio = new PrivateModInout [10]; ... public Loop () ... public void start () f /*dist block, hosts = 2, threads = 4, sunm unmod, smin mod_in, punm [0, 1] block unmod, pmin [0, 1] block mod_in, pmio [0, 1] block mod_inout */ ... = sunm... smin = ...; ... = punm [...]; pmin [...] <p> java.rmi.Naming.rebind ("//" + hostname + ":" + PORT + "/Loopstart0", new Loopstart0 ()); System.out.println ("Server ready."); g catch (Exception e) f e.printStackTrace (); System.exit (1); g g public class Loop f private Loopstart0Intf [] Loopstart0 = null; private GlobalUnmod sunm; private GlobalModIn smin; private PrivateUnmod [] punm = new PrivateUnmod <ref> [10] </ref>; private PrivateModIn [] pmin = new PrivateModIn [10]; private PrivateModInout [] pmio = new PrivateModInout [10]; Loop () f if (Loopstart0 == null) f Loopstart0 = new Loopstart0Intf [2]; distribute.Distribution.lookup (Loopstart0, "Loopstart0"); g public void start () f ... g public static void main (String [] Args) f Loop l <p> + "/Loopstart0", new Loopstart0 ()); System.out.println ("Server ready."); g catch (Exception e) f e.printStackTrace (); System.exit (1); g g public class Loop f private Loopstart0Intf [] Loopstart0 = null; private GlobalUnmod sunm; private GlobalModIn smin; private PrivateUnmod [] punm = new PrivateUnmod <ref> [10] </ref>; private PrivateModIn [] pmin = new PrivateModIn [10]; private PrivateModInout [] pmio = new PrivateModInout [10]; Loop () f if (Loopstart0 == null) f Loopstart0 = new Loopstart0Intf [2]; distribute.Distribution.lookup (Loopstart0, "Loopstart0"); g public void start () f ... g public static void main (String [] Args) f Loop l = new Loop (); l.start (); g 20 <p> g catch (Exception e) f e.printStackTrace (); System.exit (1); g g public class Loop f private Loopstart0Intf [] Loopstart0 = null; private GlobalUnmod sunm; private GlobalModIn smin; private PrivateUnmod [] punm = new PrivateUnmod <ref> [10] </ref>; private PrivateModIn [] pmin = new PrivateModIn [10]; private PrivateModInout [] pmio = new PrivateModInout [10]; Loop () f if (Loopstart0 == null) f Loopstart0 = new Loopstart0Intf [2]; distribute.Distribution.lookup (Loopstart0, "Loopstart0"); g public void start () f ... g public static void main (String [] Args) f Loop l = new Loop (); l.start (); g 20 public void start () f int blockIters = <p> in the form of comments ignored by other compilers. 24 void medianFilter () f byte [] pixels2; int x, y, offset, rowOffset; int p1, p2, p3, p4, p5, p6, p7, p8, p9; pixels2 = new byte [width * height]; System.arraycopy (pixels,0,pixels2,0,width*height); rowOffset = width; int [] values = new int <ref> [10] </ref>; for (y = yMin; y &lt;= yMax; y++) f offset = xMin + y * rowOffset + 1; p2 = (pixels2 [offset width- 2] & 0xff); p3 = (pixels2 [offset width- 1] & 0xff); p5 = (pixels2 [offset] & 0xff - 2); p6 = (pixels2 [offset - 1] & 0xff); <p> up__ = yMax; pixels2 = new byte [width * height]; System.arraycopy (pixels,0,pixels2,0,width*height); rowOffset = width; /*dist hosts = 2, threads = 4, xMin unmod, xMax unmod, rowOffset unmod, width unmod, pixels2 unmod, low__ unmod, pixels [xMin + (low__ * rowOffset), rowOffset] block mod_inout */ int [] save = new int <ref> [10] </ref>; int offset = xMin + y * rowOffset + 1; int p1, p2 = (pixels2 [offset width- 2] & 0xff); int p3 = (pixels2 [offset width- 1] & 0xff); int p4, p5 = (pixels2 [offset] & 0xff - 2); int p6 = (pixels2 [offset - 1] & 0xff); int p7,
Reference: [11] <author> M.J. Wolfe. </author> <title> High Performance Compilers for Parallel Computers. </title> <publisher> Addison-Wesley, </publisher> <address> Redwood City, California, </address> <year> 1996. </year> <month> 27 </month>
Reference-contexts: Figure 1 shows the client, the servers and their workers. The parallelization is driven by annotations that have to be inserted manually in the source code. We propose a set of annotations which can be used to exploit parallelism in fully independent for-loops. Several techniques for dependency analysis exist <ref> [1, 11] </ref>, which can be used to detect loop parallelism. Currently, our compiler does not perform such dependency analysis, but instead relies on the annotations to correctly identify a parallel loop. Do-across like loops are not implemented, because the synchronization overhead in a distributed system tends to be too high. <p> Using an orthogonal approach, this yields a total of six kinds of data. Data that is global to all workers and which has to be copied back to client after loop execution gives rise to an output dependence <ref> [11] </ref> on that data item, which prevents loop parallelization. This kind of data is therefore not considered further. Data global to all workers can be annotated as follows: * &lt;varname&gt; &lt;access&gt;, where access is either unmod or mod in. <p> The upper bound in this example is given by the expression (10 - 0 - 1 + 1). Loop normalization is described extensively in literature, see for instance <ref> [11] </ref>. After having performed loop normalization the index variable in the loop body is replaced accordingly. The variable blockIters holds the number of loop iterations to be executed by each worker. This number is calculated by dividing the upper bound of the normalized loop by the number of workers.
References-found: 11

