URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-93-28.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Scheduling Hard Real-Time Tasks with Tolerance of multiple processor failures  
Author: Yingfeng Oh and Sang H. Son 
Abstract: Technical Report No. CS-93-28 May 24, 1993 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Avizienis, A. </author> <title> The N-version approach to fault-tolerant software, </title> <journal> IEEE Transactions on Software Engineering 11, </journal> <year> 1985, </year> <pages> pp. 1491-1501. </pages>
Reference-contexts: These mission critical systems are mainly parallel or distributed systems that are embedded into complex, even hazardous environments, under tight constraints on timeliness and dependability of operations. A great deal of efforts has been invested to make computer systems highly dependable and predictable, just to cite a few, <ref> [1] </ref> [10] [12] [17] [18] [21] [22] [24] [27]. Yet, conspicuously lacking in this scenario is a formal approach towards supporting timeliness (real-time) and dependability (fault-tolerance) simultaneously in a system at the level of task scheduling.
Reference: [2] <author> Balaji, S. et al. </author> <title> Workload redistribution for fault-tolerance in a hard real-time distributed computing system, </title> <address> FTCS-19, Chicago, Illinois, </address> <month> June </month> <year> 1989, </year> <pages> pp. 366-373. 15 </pages>
Reference-contexts: It is obvious from our studies that research efforts in this area has been quite limited, and it should be noted that these resultes reviewed below are remotely related to the problem we are considering. Balaji et al <ref> [2] </ref> presented an algorithm to dynamically distribute the workload of a failed processor to other operable processors. The tolerance of some processor failures is achieved under the condition that the task set is fixed, and enough processing power is available to execute it.
Reference: [3] <author> Bannister, J.A. and K. S. Trivedi. </author> <title> Task allocation in fault-tolerant distributed systems, </title> <journal> Acta Informatica, </journal> <volume> 20, </volume> <publisher> Springer-Verlag, </publisher> <year> 1983, </year> <pages> pp. 261-281. </pages>
Reference-contexts: Balaji et al [2] presented an algorithm to dynamically distribute the workload of a failed processor to other operable processors. The tolerance of some processor failures is achieved under the condition that the task set is fixed, and enough processing power is available to execute it. Bannister and Trivedi <ref> [3] </ref> considered the allocation of a set of periodic tasks, each of which has the same number of clones, onto a number of processors, so that a certain number of processor failures can be sustained.
Reference: [4] <author> Coffman, E.G., Jr. </author> <title> Computer and Job Shop Scheduling Theory, </title> <address> New York: </address> <publisher> Wiley, </publisher> <year> 1975. </year>
Reference: [5] <author> Coffman, E.G., Jr. and R. Sethi. </author> <title> A generalized bound on LPT sequencing, </title> <journal> Revue Francaise dAutomatique Informatique Recherche Operationelle, </journal> <volume> Vol. 10, No. 5, </volume> <year> 1976, </year> <pages> Suppl., pp. 17-25. </pages>
Reference-contexts: However, that bound is only achievable by a pathological example, where, with the exception of one processor, the number of tasks scheduled on each processor is only two. Coffman and Sethi <ref> [5] </ref> later generalized Grahams bound to be (k+1)/k - 1/(km), where m is the number of processors, and k is the least number of tasks on any processor, or k is the number of tasks on a processor whose last task terminates the schedule.
Reference: [6] <author> Coffman, E.G., Jr., M.R. Garey, and D.S. Johnson. </author> <title> An application of bin-packing to multiprocessor scheduling, </title> <journal> SIAM J. Computing 7, </journal> <year> 1978, </year> <pages> pp. 1-17. </pages>
Reference-contexts: Since the scheduling to minimize the makespan of a schedule is NP-complete, several scheduling heuristics have been developed, among which LPT [8] and MULTIFIT <ref> [6] </ref> are notable ones.
Reference: [7] <author> Garey, </author> <title> M.R. and D.S. Johnson. Computers and Intractability: A guide to the theory of NP-completeness, W.H. </title> <publisher> Freeman and Company, </publisher> <address> NY, </address> <year> 1978. </year>
Reference-contexts: Proof: It is sufficient to prove that this scheduling problem is NP-complete even in the case of m = 3. It is easy to verify that this problem is in NP. We next transform the PARTITION problem - an NP-complete problem - to the scheduling problem. The PARTITION problem <ref> [7] </ref> is stated as follows: Given a finite set A and a size for each , is there a subset such that = ? Given an instance of A = of the PARTITION problem, we construct a task set using the primary-backup copy approach to run on three processors for the
Reference: [8] <author> Graham, </author> <title> R.L. Bounds on multiprocessing timing anomalies, </title> <journal> SIAM J. Appl. Math., </journal> <volume> 17, </volume> <year> 1969, </year> <pages> pp. 416-429. </pages>
Reference-contexts: This scheduling problem, at a first glance, seems very much to resemble the scheduling problem of minimizing the makespan of a schedule in a multiprocessor system. Since the scheduling to minimize the makespan of a schedule is NP-complete, several scheduling heuristics have been developed, among which LPT <ref> [8] </ref> and MULTIFIT [6] are notable ones. <p> Thus it is concluded that the performance of the algorithm is near-optimal. The performance of the scheduling heuristic - Algorithm 1 may seem surprisingly good at the first glance. However, it is not surprising at all if we take a closer look at the performance of the heuristic. Graham <ref> [8] </ref> proved that the worst case performance of LPT was tightly bounded by 2Sum D 14 4/3 - 1/3m, where m is the number of processors.
Reference: [9] <author> Hopkins, A.L. et al. </author> <title> FTMP-A highly reliable fault-tolerant multiprocessor for aircraft, </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> Vol. 66, No. 10, </volume> <month> October, </month> <year> 1978. </year>
Reference-contexts: These applications require not only long duration of reliable services, but also timeliness of operations. Computer systems that are built to support these applications include SIFT [28], FTMP <ref> [9] </ref>, the space shuttle primary computer system [26], and MAFT [11]. These mission critical systems are mainly parallel or distributed systems that are embedded into complex, even hazardous environments, under tight constraints on timeliness and dependability of operations.
Reference: [10] <author> Johnson, B.W. </author> <title> Design and Analysis of Fault Tolerant Digital Systems, </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: These mission critical systems are mainly parallel or distributed systems that are embedded into complex, even hazardous environments, under tight constraints on timeliness and dependability of operations. A great deal of efforts has been invested to make computer systems highly dependable and predictable, just to cite a few, [1] <ref> [10] </ref> [12] [17] [18] [21] [22] [24] [27]. Yet, conspicuously lacking in this scenario is a formal approach towards supporting timeliness (real-time) and dependability (fault-tolerance) simultaneously in a system at the level of task scheduling. <p> The task redundancy scheme specified in the above case actually corresponds to the primary-backup copy approach or recovery block approach. Primary-backup copy approach requires the multiple implementation of a specification <ref> [10] </ref>. The first implementation is called the primary copy, and the other implementations are called the backup copies. The primary and if necessary, the backup copies, execute in series. If the primary copy fails, one of the backup copies is switched in to perform the computation again.
Reference: [11] <author> Kieckhafer, R.M., C.J. Walter, </author> <title> A.M. Finn, and P.M. Thambidurai. THe MAFT Architecture for distributed fault tolerance, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 37, No. 4, </volume> <month> April </month> <year> 1988, </year> <pages> pp. 398-405. </pages>
Reference-contexts: These applications require not only long duration of reliable services, but also timeliness of operations. Computer systems that are built to support these applications include SIFT [28], FTMP [9], the space shuttle primary computer system [26], and MAFT <ref> [11] </ref>. These mission critical systems are mainly parallel or distributed systems that are embedded into complex, even hazardous environments, under tight constraints on timeliness and dependability of operations.
Reference: [12] <author> Knight, J.C. and P.E. Ammann. </author> <title> Design fault tolerance, Reliability Engineering and System Safety 32, </title> <booktitle> 1991, </booktitle> <pages> pp. 25-49. </pages>
Reference-contexts: A great deal of efforts has been invested to make computer systems highly dependable and predictable, just to cite a few, [1] [10] <ref> [12] </ref> [17] [18] [21] [22] [24] [27]. Yet, conspicuously lacking in this scenario is a formal approach towards supporting timeliness (real-time) and dependability (fault-tolerance) simultaneously in a system at the level of task scheduling.
Reference: [13] <author> Krishna, C.M. and K.C Shin. </author> <title> On scheduling tasks with a quick recovery from failure, </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-35(5), </volume> <month> May </month> <year> 1986, </year> <pages> pp. 448-454. </pages>
Reference-contexts: Their allocation algorithm is based on the assumption that sufficient processors are available to accommodate the scheduling of tasks. Krishna and Shin <ref> [13] </ref> proposed a dynamic programming algorithm that ensures that backup, or contingency, schedules can be efficiently embedded within the original, primary schedule to ensure that hard deadlines continue to be met even in the face of processor failures. <p> However, the algorithm in <ref> [13] </ref> has a severe drawback for the following reason: the problem to schedule a set of independent and preemptive tasks with different release times and deadlines and different weighted functions to minimize the total cost on a single processor is NP-hard [14].
Reference: [14] <author> Labetoulle, J., E.L. Lawler, J.K. Lenstra, and A.H.G. Rinnooy Kan. </author> <title> Preemptive scheduling of uniform machines subject to release dates, </title> <type> Report BW 99, </type> <institution> Mathematisch Centrum, </institution> <address> Amsterdam, </address> <year> 1979. </year>
Reference-contexts: However, the algorithm in [13] has a severe drawback for the following reason: the problem to schedule a set of independent and preemptive tasks with different release times and deadlines and different weighted functions to minimize the total cost on a single processor is NP-hard <ref> [14] </ref>. This implies that it is unlikely to find an efficient algorithm P, which was assumed to exist and used as the base algorithm for Q. Furthermore, no such algorithm as P has yet been found, that can be split into two subalgorithms that are both optimal.
Reference: [15] <author> Leung, J.Y.T. and J. Whitehead. </author> <title> On the complexity of fixed-priority scheduling of periodic, real-time tasks, </title> <journal> Performance Evaluation, </journal> <volume> Vol. 2, </volume> <pages> pp. 237-250, </pages> <year> 1982. </year>
Reference: [16] <author> Liestman, A.L. and R.H. Campbell. </author> <title> A fault tolerant scheduling problem, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-12(11), </volume> <month> November </month> <year> 1986, </year> <pages> pp. 1089-1095. </pages>
Reference: [17] <author> Liu, C.L., and J. Layland. </author> <title> Scheduling algorithms for multiprogramming in a hard real-time environment, </title> <type> JACM 10(1), </type> <year> 1973. </year>
Reference-contexts: A great deal of efforts has been invested to make computer systems highly dependable and predictable, just to cite a few, [1] [10] [12] <ref> [17] </ref> [18] [21] [22] [24] [27]. Yet, conspicuously lacking in this scenario is a formal approach towards supporting timeliness (real-time) and dependability (fault-tolerance) simultaneously in a system at the level of task scheduling.
Reference: [18] <author> Liu. J.W.S., K-J. Lin, W-K. Shih, A. Yu, A-Y. Chung, and W. </author> <title> Zhao Algorithms for scheduling imprecise computations, </title> <journal> Computer, </journal> <volume> Vol. 24, No. 5, </volume> <month> May </month> <year> 1991, </year> <pages> pp. 58-69. </pages>
Reference-contexts: A great deal of efforts has been invested to make computer systems highly dependable and predictable, just to cite a few, [1] [10] [12] [17] <ref> [18] </ref> [21] [22] [24] [27]. Yet, conspicuously lacking in this scenario is a formal approach towards supporting timeliness (real-time) and dependability (fault-tolerance) simultaneously in a system at the level of task scheduling.
Reference: [19] <author> Oh, Y., and S.H. Son. </author> <title> Multiprocessor support for real-time fault-tolerant scheduling, </title> <booktitle> IEEE 1991 Workshop on Architectural Aspects of Real-Time Systems, </booktitle> <address> San Antonio, Texas, </address> <pages> pp. 76-80, </pages> <month> Dec. 3, </month> <year> 1991. </year> <month> 16 </month>
Reference-contexts: Furthermore, no such algorithm as P has yet been found, that can be split into two subalgorithms that are both optimal. We have investigated several special cases of the real-time fault-tolerant scheduling problem. Two scheduling algorithms <ref> [19] </ref> [20] have been proposed to obtain approximate solutions to those special cases. The complexity result presented in this paper is the first solid evidence that even for a very simple case of the scheduling problem, it is intractable. The heuristic thus devised is an improvement over the previous ones.
Reference: [20] <author> Oh, Y., and S.H. Son. </author> <title> An algorithm for real-time fault-tolerant scheduling in multiprocessor systems, </title> <booktitle> 4th Euromicro Workshop on Real-Time Systems, </booktitle> <address> Athens, Greece, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Furthermore, no such algorithm as P has yet been found, that can be split into two subalgorithms that are both optimal. We have investigated several special cases of the real-time fault-tolerant scheduling problem. Two scheduling algorithms [19] <ref> [20] </ref> have been proposed to obtain approximate solutions to those special cases. The complexity result presented in this paper is the first solid evidence that even for a very simple case of the scheduling problem, it is intractable. The heuristic thus devised is an improvement over the previous ones. III. <p> The following Lemmas guarantee that having one backup copy for each task is sufficient for the tolerance of one arbitrary processor failure. The proofs of these Lemmas can be found in <ref> [20] </ref>.
Reference: [21] <author> Pradhan, D.K. </author> <title> Fault-Tolerant Computing -- Theory and Techniques, Volumes I and II, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1986. </year>
Reference-contexts: A great deal of efforts has been invested to make computer systems highly dependable and predictable, just to cite a few, [1] [10] [12] [17] [18] <ref> [21] </ref> [22] [24] [27]. Yet, conspicuously lacking in this scenario is a formal approach towards supporting timeliness (real-time) and dependability (fault-tolerance) simultaneously in a system at the level of task scheduling.
Reference: [22] <author> Ramamritham, K. and J.A. Stankovic. </author> <title> Scheduling strategies adopted in Spring: a overview, Chapter in Foundations of Real-Time Computing: Scheduling and Resource Allocation (ed.) by A.M. </title> <editor> van Tilborg and G.M. Koob, </editor> <year> 1991. </year>
Reference-contexts: A great deal of efforts has been invested to make computer systems highly dependable and predictable, just to cite a few, [1] [10] [12] [17] [18] [21] <ref> [22] </ref> [24] [27]. Yet, conspicuously lacking in this scenario is a formal approach towards supporting timeliness (real-time) and dependability (fault-tolerance) simultaneously in a system at the level of task scheduling.
Reference: [23] <author> Ramos-Thuel, S., and J.K. Strosnider. </author> <title> The transient server approach to scheduling time-critical recovery operations, </title> <address> RTSS, </address> <year> 1991, </year> <pages> pp. 286-295. </pages>
Reference-contexts: These two assumptions have been challenged recently by several researchers [25], arguing that real-time and fault-tolerant requirements are not orthogonal. Consequently, some efforts <ref> [23] </ref> have been made to address the joint requirement of timeliness and dependability. However, the approaches adopted so far have either been ad hoc or limited to specific case studies.
Reference: [24] <author> Sha, L., and J.B. Goodenough. </author> <title> Real-time scheduling theory and Ada, </title> <booktitle> Computer, </booktitle> <month> April </month> <year> 1990, </year> <pages> pp. 53-65. </pages>
Reference-contexts: A great deal of efforts has been invested to make computer systems highly dependable and predictable, just to cite a few, [1] [10] [12] [17] [18] [21] [22] <ref> [24] </ref> [27]. Yet, conspicuously lacking in this scenario is a formal approach towards supporting timeliness (real-time) and dependability (fault-tolerance) simultaneously in a system at the level of task scheduling.
Reference: [25] <author> Shin, K.G., G. Koob, and F. Jahanian. </author> <title> Fault-tolerance in real-time systems, </title> <journal> IEEE Real-Time Systems Newsletter, </journal> <volume> Vol. 7, No. 3, </volume> <year> 1991, </year> <pages> pp. 28-34. </pages>
Reference-contexts: These two assumptions have been challenged recently by several researchers <ref> [25] </ref>, arguing that real-time and fault-tolerant requirements are not orthogonal. Consequently, some efforts [23] have been made to address the joint requirement of timeliness and dependability. However, the approaches adopted so far have either been ad hoc or limited to specific case studies.
Reference: [26] <author> Spector, A., and D. Gifford. </author> <title> The space shuttle primary computer system, </title> <journal> CACM, </journal> <month> Sep-tember </month> <year> 1984, </year> <pages> pp. 874-900. </pages>
Reference-contexts: These applications require not only long duration of reliable services, but also timeliness of operations. Computer systems that are built to support these applications include SIFT [28], FTMP [9], the space shuttle primary computer system <ref> [26] </ref>, and MAFT [11]. These mission critical systems are mainly parallel or distributed systems that are embedded into complex, even hazardous environments, under tight constraints on timeliness and dependability of operations.
Reference: [27] <author> Stankovic, </author> <title> J.A. </title> <booktitle> Misconception of real-time computing, IEEE Computer, </booktitle> <month> October </month> <year> 1988, </year> <pages> pp. 10-19. </pages>
Reference-contexts: A great deal of efforts has been invested to make computer systems highly dependable and predictable, just to cite a few, [1] [10] [12] [17] [18] [21] [22] [24] <ref> [27] </ref>. Yet, conspicuously lacking in this scenario is a formal approach towards supporting timeliness (real-time) and dependability (fault-tolerance) simultaneously in a system at the level of task scheduling.
Reference: [28] <author> Wensley, et.al. SIFT: </author> <title> design and analysis of a fault-tolerant computer for aircraft control, </title> <journal> Proc.of the IEEE, </journal> <volume> Vol. 66, No. 10, </volume> <month> October </month> <year> 1978, </year> <pages> pp. 1240-1255. </pages>
Reference-contexts: These applications require not only long duration of reliable services, but also timeliness of operations. Computer systems that are built to support these applications include SIFT <ref> [28] </ref>, FTMP [9], the space shuttle primary computer system [26], and MAFT [11]. These mission critical systems are mainly parallel or distributed systems that are embedded into complex, even hazardous environments, under tight constraints on timeliness and dependability of operations.
References-found: 28

