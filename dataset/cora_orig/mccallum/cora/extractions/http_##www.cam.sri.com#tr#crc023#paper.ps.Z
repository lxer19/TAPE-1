URL: http://www.cam.sri.com/tr/crc023/paper.ps.Z
Refering-URL: http://www.cam.sri.com/tr/ABSTRACTS.html
Root-URL: 
Title: LATTICE-BASED WORD IDENTIFICATION IN CLARE  
Author: David M. Carter 
Address: 23 Millers Yard Cambridge CB2 1RQ, U.K.  
Affiliation: SRI International Cambridge Computer Science Research Centre  
Note: conference,  
Email: dmc@cam.sri.com  
Web: URL: http://www.cam.sri.com/tr/crc023/paper.ps.ZACL  
Date: 1992  
Abstract: I argue that because of spelling and typing errors and other properties of typed text, the identification of words and word boundaries in general requires syntactic and semantic knowledge. A lattice representation is therefore appropriate for lexical analysis. I show how the use of such a representation in the CLARE system allows different kinds of hypothesis about word identity to be integrated in a uniform framework. I then describe a quantitative evaluation of CLARE's performance on a set of sentences into which typographic errors have been introduced. The results show that syntax and semantics can be applied as powerful sources of constraint on the possible corrections for misspelled words. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Abe, M., Y. Oshima, K. Yuura and N. </author> <title> Take-ichi (1986) "A Kana-Kanji Translation System for Non-Segmented Input Sentences Based on Syntactic and Semantic Analysis", </title> <booktitle> Proceedings of the Eleventh International Conference on Computational Linguistics, </booktitle> <pages> pp 280-285. </pages>
Reference-contexts: are also often used in the task of converting Japanese text typed in kana (syllabic symbols) to kanji; the lack of in-terword spacing in written Japanese and the complex morphology of the language mean that lexical items and their boundaries cannot be reliably identified without applying syntactic and semantic knowledge <ref> (Abe et al, 1986) </ref>.
Reference: <author> Alshawi, H. </author> <title> (1990) "Resolving Quasi Logical Forms", </title> <booktitle> Computational Linguistics 16:3, </booktitle> <pages> pp. 133-144. </pages>
Reference: <author> Alshawi, H. (ed.) </author> <title> (1992) The Core Language Engine, </title> <publisher> M.I.T. Press. </publisher> <editor> van Berkel, B., and K. </editor> <title> De Smedt (1988) "Tri-phone Analysis: A Combined Method for the Correction of Orthographical and Typographical Errors", </title> <booktitle> Proceedings of the Second Conference on Applied Natural Language Processing, </booktitle> <pages> pp. 77-83. </pages>
Reference: <author> Carter, </author> <title> D.M. (1987) "An Information-theoretic Analysis of Phonetic Dictionary Access", </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 2 </volume> <pages> 1-11. </pages>
Reference: <author> Carter, </author> <title> D.M. (1989) "Lexical Acquisition in the Core Language Engine", </title> <booktitle> Proceedings of the Fourth Conference of the European Chapter of the Association for Computational Linguistics, </booktitle> <pages> pp 137-144. </pages>
Reference-contexts: for inferring entries through access to an external machine-readable dictionary; for defining sequences of capitalized tokens as proper names; for spelling correction (described in detail in the next section); and for interacting with the user who may suggest a replacement word or phrase or enter the VEX lexical acquisition subsystem <ref> (Carter, 1989) </ref> to create the required entries. After a method has been applied, the lattice is, if possible, pruned: edges labelled by unanalysed tokens are provisionally removed, as are other edges and vertices that then do not lie on a complete path.
Reference: <author> Emirkanian, L., </author> <title> and L.H. Bouchard (1988) "Knowledge Integration in a Robust and Efficient Morpho-syntactic Analyser for French", </title> <booktitle> Proceedings of the Twelfth International Conference on Computational Linguistics, </booktitle> <pages> pp 166-171. </pages>
Reference-contexts: One major advantage of the simplicity of the affix-stripping mechanism is that spelling correction can be interleaved directly with it. Root forms in the lexicon are represented in a discrimination net for efficient access <ref> (cf Emirkanian and Bouchard, 1988) </ref>. When the spelling corrector is called to suggest possible corrections for a word, the number of simple errors (of deletion, insertion, substitution and transposition; e.g. Pollock and Zamora, 1984) to assume is given.
Reference: <author> Futrelle, R.P., C.E. Dunn, D.S. Ellis and M.J. Pescitelli, Jr. </author> <title> (1991) "Preprocessing and Lexicon Design for Parsing Technical Text", </title> <booktitle> Proceedings of the Second International Workshop on Parsing Technologies, </booktitle> <pages> pp. 31-40. </pages>
Reference-contexts: The specific task considered in this paper is the process of mapping single sentences from character strings to QLF. Two kinds of issue are therefore not discussed here. These are the problem of segmenting a text into sentences and dealing with any markup instructions <ref> (cf Futrelle et al, 1991) </ref>, which is logically prior to producing character strings; and possible context-dependence of the lexical phenomena discussed, which would need to be dealt with after the creation of QLFs. In the analysis direction, CLARE's front end processing stages are as follows. 1.
Reference: <author> Grosz, B. J., D. E. Appelt, P. Martin, and F. </author> <title> Pereira (1987). "TEAM: An Experiment in the Design of Transportable Natural-Language Interfaces". </title> <booktitle> Artificial Intelligence 32: </booktitle> <pages> 173-243. </pages>
Reference-contexts: For example, "special" forms such as telephone numbers or e-mail addresses, which are common in many domains, may contain spaces. In CLARE, these are analysed using regular ex pressions <ref> (cf Grosz et al, 1987) </ref>, which may include space characters. When such an expression is realised, an analysis of it, connecting non-adjacent vertices if it contains spaces, is added to the lattice.
Reference: <institution> Kernighan, M.D., K.W. Church, and W.A. </institution>
Reference: <author> Gale (1990). </author> <title> "A Spelling Correction Program Based on a Noisy Channel Model", </title> <booktitle> Proceedings of the Thirteenth International Conference on Computational Linguistics, </booktitle> <pages> pp 205-210. </pages>
Reference: <author> Koskenniemi, K. </author> <title> (1983) Two-level morphology: a general computational model for word-form recognition and production. </title> <institution> University of Helsinki, Department of General Linguistics, Publications, </institution> <note> No. 11. </note>
Reference-contexts: This option would be useful if, in a given application, two sources of knowledge were deemed to be about equally reliable in their predictions. cause inflectional morphological changes in English tend not to be complex enough to warrant more powerful, and potentially less efficient, treatments such as two-level morphology <ref> (Koskenniemi, 1983) </ref>. Derivational morphological relationships typically involve semantic peculiarities as well, necessitating the definition of derived words in the lexicon in their own right. The rules for dividing clusters into tokens have the same form as those for segmenting tokens into morphemes, and are processed by the same mechanism.
Reference: <author> Pollock, J.J., and A. </author> <title> Zamora (1984) "Automatic Spelling Correction in Scientific and Scholarly Text", </title> <journal> Communications of the ACM, </journal> <volume> 27:4, </volume> <pages> pp 358-368. </pages>
Reference: <author> Veronis, J. </author> <title> (1988) "Morphosyntactic Correction in Natural Language Interfaces", </title> <booktitle> Proceedings of the Twelfth International Conference on Computational Linguistics, </booktitle> <pages> pp 708-713. </pages>
References-found: 13

