URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-94-1221/CS-TR-94-1221.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-94-1221/
Root-URL: http://www.cs.wisc.edu
Title: QUERY PROCESSING IN FIRM REAL-TIME DATABASE SYSTEMS  
Author: by HWEE HWA PANG 
Degree: A thesis submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Sciences) at the  
Date: 1994  
Address: WISCONSIN MADISON  
Affiliation: UNIVERSITY OF  
Abstract-found: 0
Intro-found: 1
Reference: [Abbo88a] <author> R. Abbott, H. Garcia-Molina, </author> <title> "Scheduling Real-Time Transactions", </title> <journal> ACM SIGMOD Record, </journal> <volume> Vol. 17, No. 1, </volume> <month> March </month> <year> 1988. </year>
Reference-contexts: INTRODUCTION A number of emerging database applications, including aircraft control, stock trading, network management, and factory automation, have to manipulate vast quantities of shared data. Moreover, these applications may generate jobs that have to be completed by certain deadlines for the results to be of value in providing decision-support <ref> [Abbo88a, Stan88] </ref>. For example, in a factory automation system, a quality inspection must be completed within a specified time frame in order to undertake any necessary corrective actions. <p> Over the past five years, a number of studies have investigated the problems of real-time concurrency control <ref> [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] </ref> and disk scheduling [Abbo89, Abbo90, Care89, Chen91, Kim91]. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines.
Reference: [Abbo88b] <author> R. Abbott, H. Garcia-Molina, </author> <title> "Scheduling Real-Time Transactions: A Performance Evaluation", </title> <booktitle> Proc. of the 14th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1988. </year>
Reference-contexts: Over the past five years, a number of studies have investigated the problems of real-time concurrency control <ref> [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] </ref> and disk scheduling [Abbo89, Abbo90, Care89, Chen91, Kim91]. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines. <p> For firm-deadline applications, jobs that have missed their deadlines are of no value, and should therefore be aborted and discarded [Hari90a]. In the case of soft-deadline workloads, however, there is some diminished value to completing a job even after its deadline has expired <ref> [Abbo88b] </ref>. Financial and manufacturing applications usually have either firm or soft deadlines. In this thesis, we will focus on providing database support for firm deadline applications. <p> It services concurrency control requests according to a chosen protocol; these requests can be for read access, write access, committing a job, or aborting a job. We have written separate Concurrency Control Manager modules based on two-phase locking with high-priority conflict resolution <ref> [Abbo88b] </ref> and optimistic concurrency control with broadcast commit [Mena82, Robi82, Hari90a]. These modules were used in our transaction scheduling studies [Pang92]. For the purposes of this dissertation, which focuses on query scheduling issues, the choice of concurrency control protocol does not matter. <p> The Earliest Deadline policy [Liu73], which gives higher priority to queries whose deadlines are more imminent, is used to guide the admission and memory allocation decisions of PMM. 5.1. Related Scheduling Work While a number of studies have addressed real-time transaction scheduling <ref> [eg., Abbo88b, Hari90a, Huan89] </ref> and disk scheduling [Abbo89, Abbo90, Care89, Chen91, Kim91], to the best of our knowledge no work has dealt with query scheduling issues in RTDBSs. The work that is most relevant to our work here is reported in [Corn89, Yu93].
Reference: [Abbo89] <author> R. Abbott, H. Garcia-Molina, </author> <title> "Scheduling Real-Time Transactions with Disk Resident Data", </title> <booktitle> Proc. of the 15th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1989. </year>
Reference-contexts: Over the past five years, a number of studies have investigated the problems of real-time concurrency control <ref> [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] </ref> and disk scheduling [Abbo89, Abbo90, Care89, Chen91, Kim91]. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines. <p> Over the past five years, a number of studies have investigated the problems of real-time concurrency control [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] and disk scheduling <ref> [Abbo89, Abbo90, Care89, Chen91, Kim91] </ref>. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines. These are the challenges addressed in this dissertation. 3 1.1. <p> The Earliest Deadline policy [Liu73], which gives higher priority to queries whose deadlines are more imminent, is used to guide the admission and memory allocation decisions of PMM. 5.1. Related Scheduling Work While a number of studies have addressed real-time transaction scheduling [eg., Abbo88b, Hari90a, Huan89] and disk scheduling <ref> [Abbo89, Abbo90, Care89, Chen91, Kim91] </ref>, to the best of our knowledge no work has dealt with query scheduling issues in RTDBSs. The work that is most relevant to our work here is reported in [Corn89, Yu93].
Reference: [Abbo90] <author> R. Abbott, H. Garcia-Molina, </author> <title> "Scheduling I/O Requests with Deadlines: A Performance Evaluation", </title> <booktitle> Proc. of the 11th IEEE Real-Time Systems Symposium (RTSS), </booktitle> <month> December </month> <year> 1990. </year>
Reference-contexts: Over the past five years, a number of studies have investigated the problems of real-time concurrency control [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] and disk scheduling <ref> [Abbo89, Abbo90, Care89, Chen91, Kim91] </ref>. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines. These are the challenges addressed in this dissertation. 3 1.1. <p> The Earliest Deadline policy [Liu73], which gives higher priority to queries whose deadlines are more imminent, is used to guide the admission and memory allocation decisions of PMM. 5.1. Related Scheduling Work While a number of studies have addressed real-time transaction scheduling [eg., Abbo88b, Hari90a, Huan89] and disk scheduling <ref> [Abbo89, Abbo90, Care89, Chen91, Kim91] </ref>, to the best of our knowledge no work has dealt with query scheduling issues in RTDBSs. The work that is most relevant to our work here is reported in [Corn89, Yu93].
Reference: [Baru91] <author> S. Baruah, L. Rosier, </author> <title> "Limitations Concerning On-Line Scheduling Algorithms for Overloaded Real-Time Systems", </title> <booktitle> Proc. of the 8th IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: To date, a number of real-time task scheduling policies have been proposed, and numerous research results have been obtained for both uniprocessor and multiprocessor systems <ref> [Liu73, Dert74, Mok78, Jens85, Lock86, Panw88, Baru91] </ref>. However, these studies have ignored the need to manage substantial amounts of data.
Reference: [Bitt88] <author> D. Bitton, J. Gray, </author> <title> "Disk Shadowing", </title> <booktitle> Proc. of the 14th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1989. </year>
Reference-contexts: The access characteristics of the disks are also given in Table 2.4. Using the parameters in this table, the total time required to complete a disk access is computed as: Disk Access Time = Seek Time + Rotational Delay + Transfer Time As in <ref> [Bitt88] </ref>, the time required to seek across n tracks is computed as: Seek Time (n) = SeekFactor dd n The rotational delay is the spinning time that is needed for the start of the first requested page to be positioned under the disk head.
Reference: [Blas77] <author> M.W. Blasgen, </author> <title> K.P. Eswaran, "Storage and Access in Relational Databases", </title> <journal> IBM Systems Journal, </journal> <volume> Vol. 16, No. 4, </volume> <year> 1977. </year>
Reference-contexts: Sorting is frequently used in database systems to produce ordered query results. It is also the basis of sort-merge join <ref> [Blas77] </ref>, a join algorithm employed by many existing database systems, and it is used in some systems for processing group-by queries.
Reference: [Brat84] <author> K. Bratbergsengen, </author> <title> "Hashing Methods and Relational Algebra Operations", </title> <booktitle> Proc. of the 10th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1984. </year>
Reference-contexts: Dynamic splitting therefore appears to be a promising merge-phase adaptation strategy in practice. 4.4. Sort-Merge Joins Sort-merge join is a join algorithm employed by many existing database systems. Although recent work has shown hash join to often be superior to sort-merge join in performing ad-hoc join operations <ref> [Brat84, DeWi84, Shap86] </ref>, sort-merge join is still useful under certain conditions, e.g. when significant data skew is present, or when the results need to be presented in sorted order [Grae91]. Hence sort-merge join is likely to continue to be offered as one of the alternative join algorithms in future DBMSs.
Reference: [Brow93] <author> K.P. Brown, M.J. Carey, M. Livny, </author> <title> "Managing Memory to Meet Multiclass Workload Response Time Goals", </title> <booktitle> Proc. of the 19th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: We have considered only workloads involving mixes of queries in this thesis; RTDBS workloads are likely to contain transactions as well as queries. Thus, it would be useful to combine long-term data buffering techniques, such as those proposed in <ref> [Brow93] </ref>, with PAQS in order to provide a truly complete memory manager for RTDBSs. The concurrent execution of long-running queries and short transactions also raises concurrency control issues that need to be resolved.
Reference: [Care88] <author> M.J. Carey, M. Livny, </author> <title> "Parallelism and Concurrency Control Performance in Distributed Database Machines", </title> <booktitle> Proc. of the 14th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1988. </year>
Reference-contexts: Another avenue for future work on query processing techniques is to introduce intra-query parallelism. While intra-query parallelism is not likely to be beneficial for systems that operate under heavy loads <ref> [Care88] </ref>, it can be extremely useful in harnessing an RTDBS's resources under light load conditions. In fact, parallel query execution may be the only feasible alternative in situations where an RTDBS is presented with queries that have very tight deadlines.
Reference: [Care89] <author> M.J. Carey, R. Jauhari, M. Livny, </author> <title> "Priority in DBMS Resource Scheduling", </title> <booktitle> Proc. of the 15th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1989. </year>
Reference-contexts: Over the past five years, a number of studies have investigated the problems of real-time concurrency control [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] and disk scheduling <ref> [Abbo89, Abbo90, Care89, Chen91, Kim91] </ref>. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines. These are the challenges addressed in this dissertation. 3 1.1. <p> The Earliest Deadline policy [Liu73], which gives higher priority to queries whose deadlines are more imminent, is used to guide the admission and memory allocation decisions of PMM. 5.1. Related Scheduling Work While a number of studies have addressed real-time transaction scheduling [eg., Abbo88b, Hari90a, Huan89] and disk scheduling <ref> [Abbo89, Abbo90, Care89, Chen91, Kim91] </ref>, to the best of our knowledge no work has dealt with query scheduling issues in RTDBSs. The work that is most relevant to our work here is reported in [Corn89, Yu93].
Reference: [Chen91] <author> S. Chen, J.A. Stankovic, J.F. Kurose, D. Towsley, </author> <title> "Performance Evaluation of Two New Disk Scheduling Algorithms for Real-Time Systems", </title> <journal> The Journal of Real-Time Systems, </journal> <volume> Vol. 3, No. 3, </volume> <month> September </month> <year> 1991. </year>
Reference-contexts: Over the past five years, a number of studies have investigated the problems of real-time concurrency control [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] and disk scheduling <ref> [Abbo89, Abbo90, Care89, Chen91, Kim91] </ref>. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines. These are the challenges addressed in this dissertation. 3 1.1. <p> The Earliest Deadline policy [Liu73], which gives higher priority to queries whose deadlines are more imminent, is used to guide the admission and memory allocation decisions of PMM. 5.1. Related Scheduling Work While a number of studies have addressed real-time transaction scheduling [eg., Abbo88b, Hari90a, Huan89] and disk scheduling <ref> [Abbo89, Abbo90, Care89, Chen91, Kim91] </ref>, to the best of our knowledge no work has dealt with query scheduling issues in RTDBSs. The work that is most relevant to our work here is reported in [Corn89, Yu93].
Reference: [Corn89] <author> D. Cornell, P. Yu, </author> <title> "Integration of Buffer Management and Query Optimization in a Relational Database Environment", </title> <booktitle> Proc. of the 15th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1989. </year>
Reference-contexts: In addition, the effectiveness of memory allocation in reducing individual queries' response times should be considered so as to make the best use of the available memory <ref> [Corn89, Yu93] </ref>. This thesis introduces a priority-cognizant algorithm that dynamically chooses a target multiprogramming level and a memory allocation strategy for queries to balance the demands on the system's memory, CPU, and disks. <p> The work that is most relevant to our work here is reported in <ref> [Corn89, Yu93] </ref>. In that work, the authors examined the effect of memory allocations on query response times in traditional (non-real-time) database systems, and they concluded that giving some of the queries their maximum required memory, while allocating the minimum possible memory to the rest, leads to near-optimal memory usage. <p> The reason for doing MinMax allocation, as opposed to simply dividing the available memory proportionally among the admitted queries, is that MinMax leads to more effective use of memory then proportional allocation (as was shown in <ref> [Corn89, Yu93] </ref>); this will be verified quantitatively in Section 5.3.1. The MinMax allocation process is conceptually carried out in two passes. Starting from the highest-priority query, PMM first gives each query just enough memory for it to begin execution. <p> This increases the queries' reliance on the CPU and disks, resulting in further increases in the queries' execution times. Consequently, Proportional utilizes memory much less effectively than MinMax. As mentioned earlier, similar observations about the inferiority of Proportional-style policies were made in <ref> [Corn89, Yu93] </ref> in a non-real-time context. We now turn our attention to the PMM algorithm.
Reference: [Dert74] <author> M. Dertouzos, </author> <title> "Control Robotics: the procedural control of physical processes", </title> <booktitle> Proc. of IFIP Congress, </booktitle> <year> 1974. </year>
Reference-contexts: To date, a number of real-time task scheduling policies have been proposed, and numerous research results have been obtained for both uniprocessor and multiprocessor systems <ref> [Liu73, Dert74, Mok78, Jens85, Lock86, Panw88, Baru91] </ref>. However, these studies have ignored the need to manage substantial amounts of data.
Reference: [Devo91] <author> J.L. Devore, </author> <title> Probability and Statistics for Engineering and the Sciences, </title> <publisher> Brooks/Cole Pub. Co., </publisher> <year> 1991, </year> <pages> pp. 283-301, 326-335. </pages>
Reference-contexts: In checking for condition (3), PMM carries out a large-sample test <ref> [Devo91] </ref> for the mean waiting time at a confidence level of Adapt ConfLevel . Condition (4) is tested in a similar fashion, except that here the test is performed on the difference between the execution time and time constraint. After switching to MinMax, PMM then monitors the target MPL. <p> After every SampleSize query completions, PMM carries out a large-sample test with a confidence level of Change ConfLevel <ref> [Devo91] </ref> on each monitored workload characteristic to see if its present value differs significantly from its last observed value. If so, PMM concludes that a workload change has taken place. <p> Upon activation, PM3 carries out a t-test on each monitored class characteristic to see if its present value is different from its last observed value at a confidence level of Change ConfLevel <ref> [Devo91] </ref>. If so, PM3 reacts to the workload change by discarding the statistics that it has gathered and by re-adapting itself to the new workload composition. The differences between PM3 and PMM are summarized in Table 6.2. 6.1.2.
Reference: [DeWi84] <author> D.J. DeWitt, R.H. Katz, F. Olken, L.D. Shapiro, M. Stonebraker, D. Wood, </author> <title> "Implementation Techniques for Main Memory Database Systems", </title> <booktitle> Proc. of the ACM SIGMOD Conf., </booktitle> <month> June </month> <year> 1984. </year>
Reference-contexts: For instance, a hash join can either execute with its maximum required memory, which is slightly greater than the size of its inner relation, or it can run in an additional pass with as few buffer pages as the square root of its inner relation size <ref> [DeWi84, Shap86] </ref>. In order to derive the benefits of multiprogramming, it may be necessary for an RTDBS to admit some queries with less than their maximum memory allocations. <p> Depending on the specific algorithm used, the number of buffers that a hash join utilizes ranges anywhere from the square root of the size of its inner relation up to its inner relation size <ref> [DeWi84, Shap86] </ref>, which can be a substantial portion of the system memory. Consequently, a real-time or priority-driven database management system (DBMS) may have to preempt large hash joins in order to satisfy the memory requirements of higher-priority jobs. <p> Excess buffers are used to hold subsets of R and/or S so they need not be written to disk. A shortcoming of the GRACE Hash Join algorithm is that it does not effectively utilize memory that is in excess of the minimum requirement of ddddd F||R|| buffers. In <ref> [DeWi84] </ref>, DeWitt et al proposed the Hybrid Hash Join algorithm, which follows the same three phases that GRACE goes through but uses excess memory more effectively. <p> The Hybrid Hash Join algorithm was shown to have performance superior to that of GRACE <ref> [DeWi84] </ref>. The Hybrid Hash Join algorithm is designed to make full use of the memory that a join has available when it first starts execution. <p> Dynamic splitting therefore appears to be a promising merge-phase adaptation strategy in practice. 4.4. Sort-Merge Joins Sort-merge join is a join algorithm employed by many existing database systems. Although recent work has shown hash join to often be superior to sort-merge join in performing ad-hoc join operations <ref> [Brat84, DeWi84, Shap86] </ref>, sort-merge join is still useful under certain conditions, e.g. when significant data skew is present, or when the results need to be presented in sorted order [Grae91]. Hence sort-merge join is likely to continue to be offered as one of the alternative join algorithms in future DBMSs.
Reference: [DeWi91] <author> D.J. DeWitt, J.F. Naughton, D.A. Schneider, </author> <title> "Parallel Sorting on a Shared-Nothing Architecture using Probabilistic Splitting", </title> <booktitle> Proc. of the Int. Conf. on Parallel and Distributed Information Systems, </booktitle> <month> December </month> <year> 1991. </year>
Reference-contexts: A nice discussion of the details involved in implementing replacement selection can be found in [Salz90]. Although using replacement selection instead of Quicksort can shorten the merge phase, replacement selection is not always the preferred choice because it can also lead to a longer split phase <ref> [Grae90, DeWi91] </ref>. With Quicksort, there is a cycle of reading several pages from the source relation, sorting them, and then writing them to disk. In contrast, replacement selection alternates between reading a page from the source relation and writing a page to the current run. <p> Quicksort therefore has a much shorter split phase than repl 1, which more than offsets the longer merge phase that results from the larger number of runs that Quicksort generates. (Similar observations about the relative trade-offs between Quicksort and repl 1 were made in [Grae90] and <ref> [DeWi91] </ref>.) By writing multiple pages instead of only a single page each time as in repl 1, repl 6 is able to significantly reduce the number of disk seeks in replacement selection, bringing the duration of its split phase much closer to that of quick.
Reference: [Drap81] <author> N.R. Draper, H. Smith, </author> <title> Applied Regression Analysis, 2nd Edition, </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1981. </year> <month> 135 </month>
Reference-contexts: After every SampleSize query completions, PMM measures the miss ratio, miss i , that the current MPL, mpl i , produces. Based on this pair of values, together with past miss ratios and their associated MPL settings, a new quadratic equation is calculated according to the least squares method <ref> [Drap81] </ref>. <p> Conceptually, PMM computes the average utilization at the current MPL, denoted as Util Current in the formula above, by first obtaining a straight line from every pair &lt;util i , mpl i &gt; of observed utilization values and their associated MPLs by using the least squares method <ref> [Drap81] </ref>, again applying the linearity assumption. The average utilization is then taken from the fitted line as the rate that corresponds to the current MPL.
Reference: [Eswa76] <author> K. Eswaran, et al, </author> <title> "The Notions of Consistency and Predicate Locks in a Database System", </title> <journal> Communications of ACM, </journal> <month> November </month> <year> 1976. </year>
Reference-contexts: Such a situation, known as priority inversion, causes priority scheduling to be counterproductive to system performance [Sha90]. For example, if the CPU and disks of an RTDBS are scheduled by priority but a standard two-phase locking protocol <ref> [Eswa76, Gray79] </ref> is used, a high-priority job may be given precedence at the CPU and disks but still get blocked by a lower-priority job because the latter is allowed to hold onto a lock that the high-priority job is waiting for.
Reference: [Grae90] <author> G. Graefe, </author> <title> "Parallel External Sorting in Volcano", </title> <type> Technical Report CU-CS-459-90, </type> <institution> University of Colorado, Boulder, </institution> <month> March </month> <year> 1990. </year>
Reference-contexts: A nice discussion of the details involved in implementing replacement selection can be found in [Salz90]. Although using replacement selection instead of Quicksort can shorten the merge phase, replacement selection is not always the preferred choice because it can also lead to a longer split phase <ref> [Grae90, DeWi91] </ref>. With Quicksort, there is a cycle of reading several pages from the source relation, sorting them, and then writing them to disk. In contrast, replacement selection alternates between reading a page from the source relation and writing a page to the current run. <p> In contrast, replacement selection alternates between reading a page from the source relation and writing a page to the current run. When the source relation and the run reside on the same disk, this results in many more disk seeks than in the case of Quicksort <ref> [Grae90] </ref>. <p> An alternate strategy is to merge just enough runs in the first step so that each of the subsequent steps merges m - 1 runs. second strategy is called "optimized" merging <ref> [Grae90] </ref>. From Figures 4.1 (a) and 4.1 (b), it should be apparent that "naive" merging is more expensive than "optimized" merging, as the final step has to process all of the tuples in the relation in both strategies. <p> Quicksort therefore has a much shorter split phase than repl 1, which more than offsets the longer merge phase that results from the larger number of runs that Quicksort generates. (Similar observations about the relative trade-offs between Quicksort and repl 1 were made in <ref> [Grae90] </ref> and [DeWi91].) By writing multiple pages instead of only a single page each time as in repl 1, repl 6 is able to significantly reduce the number of disk seeks in replacement selection, bringing the duration of its split phase much closer to that of quick.
Reference: [Grae91] <author> G. Graefe, A. Linville, L.D. Shapiro, </author> <title> "Sort versus Hash Revisited", </title> <type> Technical Report CU-CS-534-91, </type> <institution> University of Colorado, Boulder, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: By merging more runs, "naive" merging increases the cost of the preliminary steps unnecessarily. Thus, the R 1-10 R 1 R 4 (b) "Optimized" Merging R 1-10 R 1 R 7 (a) "Naive" Merging Step 2: Step 1: 53 general rule is to adopt "optimized" merging <ref> [Grae91] </ref>. Another important aspect of the merging strategy concerns the choice of input runs. All of the merge steps, other than the final merge, have a choice of input runs and should thus merge the shortest possible runs. <p> The decision of naive to include more runs in the first preliminary step thus leads to an increase in the cost of each of these affected steps <ref> [Grae91] </ref>. The 63 more merge steps there are, the larger the number of affected steps becomes, and consequently the higher the penalty of naive gets. <p> Although recent work has shown hash join to often be superior to sort-merge join in performing ad-hoc join operations [Brat84, DeWi84, Shap86], sort-merge join is still useful under certain conditions, e.g. when significant data skew is present, or when the results need to be presented in sorted order <ref> [Grae91] </ref>. Hence sort-merge join is likely to continue to be offered as one of the alternative join algorithms in future DBMSs. In this section, we address the issue of extending the techniques that we have explored earlier to handle sort-merge joins, thus making them memory-adaptive. 4.4.1.
Reference: [Gray79] <author> J. Gray, </author> <title> "Notes on Database Operating Systems", in Operating Systems: An Advanced Course, </title> <editor> R. Bayer, R.Graham, G. Seegmuller, eds., </editor> <publisher> Springer-Verlag, </publisher> <year> 1979. </year>
Reference-contexts: Such a situation, known as priority inversion, causes priority scheduling to be counterproductive to system performance [Sha90]. For example, if the CPU and disks of an RTDBS are scheduled by priority but a standard two-phase locking protocol <ref> [Eswa76, Gray79] </ref> is used, a high-priority job may be given precedence at the CPU and disks but still get blocked by a lower-priority job because the latter is allowed to hold onto a lock that the high-priority job is waiting for.
Reference: [Haas93] <author> L. Haas, M.J. Carey, M. Livny, </author> <title> "SEEKing the Truth About Ad Hoc Join Costs", </title> <type> Technical Report #1148, </type> <institution> Computer Sciences Department, University of Wisconsin - Madison, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: One possible strategy would be to dynamically adjust the buffer size (i.e., the I/O block size) according to memory availability. Since the use of larger buffer sizes can lead to significant reductions in queries' response times <ref> [Haas93] </ref>, a combination of buffer size adjustment and our proposed memory-adaptive techniques would likely yield even more effective 133 solutions to the memory fluctuation problem. Another avenue for future work on query processing techniques is to introduce intra-query parallelism.
Reference: [Hari90a] <author> J.R. Haritsa, M.J. Carey, M. Livny, </author> <title> "On Being Optimistic about Real-Time Constraints", </title> <booktitle> Proc. of the ACM PODS Symposium, </booktitle> <month> April </month> <year> 1990. </year>
Reference-contexts: Over the past five years, a number of studies have investigated the problems of real-time concurrency control <ref> [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] </ref> and disk scheduling [Abbo89, Abbo90, Care89, Chen91, Kim91]. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines. <p> The distinction between firm- and soft-deadline applications lies in the way that late jobs are treated. For firm-deadline applications, jobs that have missed their deadlines are of no value, and should therefore be aborted and discarded <ref> [Hari90a] </ref>. In the case of soft-deadline workloads, however, there is some diminished value to completing a job even after its deadline has expired [Abbo88b]. Financial and manufacturing applications usually have either firm or soft deadlines. In this thesis, we will focus on providing database support for firm deadline applications. <p> We have written separate Concurrency Control Manager modules based on two-phase locking with high-priority conflict resolution [Abbo88b] and optimistic concurrency control with broadcast commit <ref> [Mena82, Robi82, Hari90a] </ref>. These modules were used in our transaction scheduling studies [Pang92]. For the purposes of this dissertation, which focuses on query scheduling issues, the choice of concurrency control protocol does not matter. Hence, we arbitrarily chose the module that is based on the locking protocol. 2.2. <p> The Earliest Deadline policy [Liu73], which gives higher priority to queries whose deadlines are more imminent, is used to guide the admission and memory allocation decisions of PMM. 5.1. Related Scheduling Work While a number of studies have addressed real-time transaction scheduling <ref> [eg., Abbo88b, Hari90a, Huan89] </ref> and disk scheduling [Abbo89, Abbo90, Care89, Chen91, Kim91], to the best of our knowledge no work has dealt with query scheduling issues in RTDBSs. The work that is most relevant to our work here is reported in [Corn89, Yu93]. <p> This result is incorporated in the memory allocation strategies of PMM. 5.2. Priority Memory Management In firm real-time database systems <ref> [Hari90a] </ref>, queries become worthless if they fail to complete by their deadlines. Consequently, the primary performance objective of an RTDBS is to minimize the number of missed deadlines without intentionally discriminating against any particular type of queries.
Reference: [Hari90b] <author> J.R. Haritsa, M.J. Carey, M. Livny, </author> <title> "Dynamic Real-Time Optimistic Concurrency Control", </title> <booktitle> Proc. of the 11th IEEE Real-Time Systems Symposium (RTSS), </booktitle> <month> December </month> <year> 1990. </year>
Reference-contexts: Over the past five years, a number of studies have investigated the problems of real-time concurrency control <ref> [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] </ref> and disk scheduling [Abbo89, Abbo90, Care89, Chen91, Kim91]. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines.
Reference: [Hari91] <author> J.R. Haritsa, M. Livny, M.J. Carey, </author> <title> "Earliest Deadline Scheduling for Real-Time Database Systems", </title> <booktitle> Proc. of the 12th IEEE Real-Time Systems Symposium (RTSS), </booktitle> <month> December </month> <year> 1991. </year>
Reference-contexts: Over the past five years, a number of studies have investigated the problems of real-time concurrency control <ref> [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] </ref> and disk scheduling [Abbo89, Abbo90, Care89, Chen91, Kim91]. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines. <p> Roughly speaking, PAQS accomplishes this regulation using a multi-class variant of the Adaptive Earliest Deadline scheduling policy proposed in <ref> [Hari91] </ref>. PAQS divides all queries into two priority groups a regular group and a reserve group and a quota of regular queries is chosen for each class of query. <p> The reason that RP is chosen for the reserve group is because its queries essentially "see" a heavily loaded 112 system due to their lower priorities, and RP delivers good performance under heavy loads <ref> [Hari91] </ref>. PAQS attempts to meet the target miss ratio distribution by elevating the priority of classes that suffer from higher-than-desired miss ratios, thus helping their queries to gain admission and compete for system resources. <p> As noted earlier, the two-tier priority assignment scheme adopted by PAQS follows the same concept as the Adaptive Earliest Deadline (AED) algorithm proposed in <ref> [Hari91] </ref>. AED maintains a "hit" group and a "miss" group, which correspond to the regular group and reserve group in PAQS, and AED controls "hit" group assignments by a HitSize parameter. The distinction between the two algorithms lies in the goals that they hope to reach with the two-tier scheme.
Reference: [Hari92] <author> J.R. Haritsa, M.J. Carey, M. Livny, </author> <title> "Data Access Scheduling in Firm Real-Time Database Systems", </title> <journal> Real-Time Systems Journal, </journal> <volume> Vol. 4, No. 3, </volume> <month> September </month> <year> 1992. </year>
Reference-contexts: Over the past five years, a number of studies have investigated the problems of real-time concurrency control <ref> [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] </ref> and disk scheduling [Abbo89, Abbo90, Care89, Chen91, Kim91]. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines.
Reference: [Hari93] <author> J.R. Haritsa, M.J. Carey, M. Livny, </author> <title> "Value-Based Scheduling in Real-Time DBS", </title> <journal> VLDB Journal, </journal> <volume> Vol. 2, No. 2, </volume> <month> April </month> <year> 1993. </year>
Reference: [Hong93] <author> D. Hong, T. Johnson, S. Chakravarthy, </author> <title> "Real-Time Transaction Scheduling: A Cost Conscious Approach", </title> <booktitle> Proc. of the ACM SIGMOD Conf., </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: Over the past five years, a number of studies have investigated the problems of real-time concurrency control <ref> [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] </ref> and disk scheduling [Abbo89, Abbo90, Care89, Chen91, Kim91]. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines.
Reference: [Huan89] <author> J. Huang, J.A. Stankovic, D. Towsley, K. Ramamritham, </author> <title> "Experimental Evaluation of Real-Time Transaction Processing", </title> <booktitle> Proc. of the 10th IEEE Real-Time Systems Symposium (RTSS), </booktitle> <month> December </month> <year> 1989. </year>
Reference-contexts: Over the past five years, a number of studies have investigated the problems of real-time concurrency control <ref> [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] </ref> and disk scheduling [Abbo89, Abbo90, Care89, Chen91, Kim91]. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines. <p> The Earliest Deadline policy [Liu73], which gives higher priority to queries whose deadlines are more imminent, is used to guide the admission and memory allocation decisions of PMM. 5.1. Related Scheduling Work While a number of studies have addressed real-time transaction scheduling <ref> [eg., Abbo88b, Hari90a, Huan89] </ref> and disk scheduling [Abbo89, Abbo90, Care89, Chen91, Kim91], to the best of our knowledge no work has dealt with query scheduling issues in RTDBSs. The work that is most relevant to our work here is reported in [Corn89, Yu93].
Reference: [Huan91] <author> J. Huang, J.A. Stankovic, D. Towsley, </author> <title> "Experimental Evaluation of Real-Time Optimistic Con-currency Control Schemes", </title> <booktitle> Proc. of the 17th Int. Conf. on Very Large Data Bases, </booktitle> <month> September </month> <year> 1991. </year>
Reference-contexts: Over the past five years, a number of studies have investigated the problems of real-time concurrency control <ref> [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] </ref> and disk scheduling [Abbo89, Abbo90, Care89, Chen91, Kim91]. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines.
Reference: [Jauh90] <author> R. Jauhari, M.J. Carey, M. Livny, </author> <title> "Priority Hints: An Algorithm for Priority-Based Buffer Management", </title> <booktitle> Proc. of the 16th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1990. </year>
Reference: [Jens85] <author> E. Jensen, C. Locke, H. Tokuda, </author> <title> "A Time-Driven Scheduling Model for Real-Time Operating Systems", </title> <booktitle> Proc. of the 6th IEEE Real-Time Systems Symposium (RTSS), </booktitle> <month> December </month> <year> 1985. </year>
Reference-contexts: To date, a number of real-time task scheduling policies have been proposed, and numerous research results have been obtained for both uniprocessor and multiprocessor systems <ref> [Liu73, Dert74, Mok78, Jens85, Lock86, Panw88, Baru91] </ref>. However, these studies have ignored the need to manage substantial amounts of data. <p> For hard-deadline applications, missing a deadline may have catastrophic consequences, and hence it is necessary to guarantee that all jobs meet their deadlines <ref> [Jens85] </ref>. Applications like flight control systems and missile guidance systems belong to this category. In contrast, missing a firm deadline or a soft deadline may involve a performance penalty, but it does not have disastrous effects.
Reference: [Kim91] <author> W. Kim, J. Srivastava, </author> <title> "Enhancing Real-Time DBMS Performance with Multiversion Data and Priority Based Disk Scheduling", </title> <booktitle> Proc. of the 12th IEEE Real-Time Systems Symposium (RTSS), </booktitle> <month> December </month> <year> 1991. </year>
Reference-contexts: Over the past five years, a number of studies have investigated the problems of real-time concurrency control <ref> [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] </ref> and disk scheduling [Abbo89, Abbo90, Care89, Chen91, Kim91]. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines. <p> Over the past five years, a number of studies have investigated the problems of real-time concurrency control [Abbo88a, Abbo88b, Abbo89, Hari90a, Hari90b, Hari91, Hari92, Hong93, Huan89, Huan91, Kim91] and disk scheduling <ref> [Abbo89, Abbo90, Care89, Chen91, Kim91] </ref>. However, to the best of our knowledge, no work has met the admission control and memory management challenges that arise in processing queries with deadlines. These are the challenges addressed in this dissertation. 3 1.1. <p> The Earliest Deadline policy [Liu73], which gives higher priority to queries whose deadlines are more imminent, is used to guide the admission and memory allocation decisions of PMM. 5.1. Related Scheduling Work While a number of studies have addressed real-time transaction scheduling [eg., Abbo88b, Hari90a, Huan89] and disk scheduling <ref> [Abbo89, Abbo90, Care89, Chen91, Kim91] </ref>, to the best of our knowledge no work has dealt with query scheduling issues in RTDBSs. The work that is most relevant to our work here is reported in [Corn89, Yu93].
Reference: [Kits83] <author> M. Kitsuregawa, H. Tanaka, T. Moto-oka, </author> <title> "Application of Hash to Data Base Machine and Its Architecture", </title> <journal> New Generation Computing, </journal> <volume> Vol. 1, No. 1, </volume> <year> 1983. </year>
Reference-contexts: We also use a "fudge factor", F, to represent the overhead for a hash table. For example, a hash table for R is assumed to require F||R|| pages. This notation is summarized in Table 3.1. Some of the earliest work on joins using hashing is reported in <ref> [Kits83] </ref>. The GRACE Hash Join algorithm was introduced in that study. In GRACE Hash Join, a join is processed in three phases. First, the inner relation R is split into ddddd F||R|| disk-resident partitions that are approximately equal in size.
Reference: [Kits89] <author> M. Kitsuregawa, M. Nakayama, M. Takagi, </author> <title> "The Effect of Bucket Size Tuning in the Dynamic Hybrid GRACE Hash Join Method", </title> <booktitle> Proc. of the 15th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1989. </year>
Reference-contexts: The next two phases proceed exactly as in the Hybrid (or GRACE) Hash Join algorithm. Through a series of experiments, this modified algorithm was shown to outperform Hybrid Hash Join when the hash attribute distribution cannot be accurately determined <ref> [Kits89] </ref>.
Reference: [Klei76] <author> L. Kleinrock, </author> <title> Queueing Systems, </title> <booktitle> Volume II: Computer Applications, </booktitle> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1976, </year> <pages> pp. 166-170. </pages>
Reference-contexts: The need for all of the components of an RTDBS to be priority-driven requires several changes in the ways that traditional database systems, which are not designed to handle the notion of priority, service their jobs. While existing priority preemptive-resume [Pete86] or priority head-of-the-line <ref> [Klei76] </ref> scheduling techniques can be used to schedule the CPU in an RTDBS, priority-based algorithms for concurrency control, disk scheduling, admission control, and memory management have to be developed for such a system. <p> CPU and Disk Managers The parameters that specify the CPU and disk resources of our model are listed in Table 2.4. A priority head-of-the-line scheduling discipline <ref> [Klei76] </ref> is used for the CPU. The MIPS rating of the CPU is given by CPUSpeed. Turning to the disk model parameters, NumDisks specifies the number of disks attached to the system. Every disk has its own queue that is scheduled by the priority head-of-the-line discipline [Klei76]; any disk requests that <p> priority head-of-the-line scheduling discipline <ref> [Klei76] </ref> is used for the CPU. The MIPS rating of the CPU is given by CPUSpeed. Turning to the disk model parameters, NumDisks specifies the number of disks attached to the system. Every disk has its own queue that is scheduled by the priority head-of-the-line discipline [Klei76]; any disk requests that share the same priority value are serviced according to the elevator algorithm. Each disk has a 256-KByte cache for use in prefetching pages. The access characteristics of the disks are also given in Table 2.4.
Reference: [Knut73] <author> D. Knuth, </author> <title> The Art of Computer Programming, Vol. III: Sorting and Searching, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA., </address> <year> 1973. </year>
Reference-contexts: When none of the tuples in the heap satisfy this condition, the current run ends and a new run is started. On the average, the length of the runs produced by replacement selection is twice the memory allocated for the split phase <ref> [Knut73] </ref>, i.e. twice 51 as long as the runs generated with Quicksort. Hence, replacement selection creates only half as many runs as Quicksort. This could significantly shorten the merge phase that follows. A nice discussion of the details involved in implementing replacement selection can be found in [Salz90].
Reference: [Kort90] <author> H.F. Korth, N. Soparkar, A. Silberschatz, </author> <title> "Triggered Real-Time Databases with Consistency Constraints", </title> <booktitle> Proc. of the 16th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1990. </year> <month> 136 </month>
Reference: [Liu73] <author> C. Liu, J. Layland, </author> <title> "Scheduling Algorithms for Multiprogramming in a Hard Real-Time Environment", </title> <journal> Journal of the ACM, </journal> <month> January </month> <year> 1973. </year>
Reference-contexts: To date, a number of real-time task scheduling policies have been proposed, and numerous research results have been obtained for both uniprocessor and multiprocessor systems <ref> [Liu73, Dert74, Mok78, Jens85, Lock86, Panw88, Baru91] </ref>. However, these studies have ignored the need to manage substantial amounts of data. <p> Both the target MPL and the memory allocation policy are 79 80 chosen based on past system behavior. The Earliest Deadline policy <ref> [Liu73] </ref>, which gives higher priority to queries whose deadlines are more imminent, is used to guide the admission and memory allocation decisions of PMM. 5.1. <p> The Priority Memory Management (PMM) algorithm is a priority-cognizant algorithm designed to regulate memory usage for firm real-time query workloads. The PMM algorithm consists of an admission control component and a memory allocation component. Both components employ the Earliest Deadline (ED) scheduling policy <ref> [Liu73] </ref>, so queries that are more urgent are given higher priority in admission and memory allocation decisions than queries whose deadlines are further away. <p> PAQS divides all queries into two priority groups a regular group and a reserve group and a quota of regular queries is chosen for each class of query. Priority values are assigned to regular queries based on the Earliest Deadline policy <ref> [Liu73] </ref>, while reserve queries are assigned random priorities that are 107 108 lower than those of any regular query; regular queries are always admitted and allotted resources ahead of reserve queries. <p> The differences between PM3 and PMM are summarized in Table 6.2. 6.1.2. Priority Adaptation Query Scheduling While PM3 is designed to pick its MPL and memory allocation strategy according to the target miss ratio distribution, it does not control the bias of the Earliest Deadline (ED) scheduling policy <ref> [Liu73] </ref> that RTDBSs use to prioritize their queries.
Reference: [Livn87] <author> M. Livny, S. Khoshafian, H. Boral, </author> <title> "Multi-Disk Management Algorithms", </title> <booktitle> Proc. of the ACM SIGMETRICS Conf., </booktitle> <month> May </month> <year> 1987. </year>
Reference-contexts: A related problem is that of physical data placement in RTDBSs. In a multi-disk RTDBS, relations can be declustered <ref> [Ries78, Livn87] </ref> to exploit the I/O bandwidth of the disks and to achieve load balancing.
Reference: [Livn90] <author> M. Livny, </author> <note> "DeNet User's Guide, Version 1.5", </note> <institution> Computer Sciences Department, University of Wisconsin - Madison, </institution> <year> 1990. </year>
Reference-contexts: To aid in evaluating the performance of the various algorithms that will be developed in subsequent chapters, we have implemented a detailed simulation model of a firm real-time database system in the DeNet <ref> [Livn90] </ref> discrete event simulation language. The simulation model captures a centralized database system, based on the architecture depicted in Figure 1.1. This chapter describes the simulation model and concludes with a discussion of the experimental methodology and performance metrics that underly our experiments. 2.1.
Reference: [Lock86] <author> C. Locke, </author> <title> "Best Effort Decision Making for Real-Time Scheduling", </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Science, Carnegie-Mellon University, </institution> <month> May </month> <year> 1986. </year>
Reference-contexts: To date, a number of real-time task scheduling policies have been proposed, and numerous research results have been obtained for both uniprocessor and multiprocessor systems <ref> [Liu73, Dert74, Mok78, Jens85, Lock86, Panw88, Baru91] </ref>. However, these studies have ignored the need to manage substantial amounts of data.
Reference: [Mena82] <author> D. Menasce, T. Nakanishi, </author> <title> "Optimistic versus Pessimistic Concurrency Control Mechanisms in Database Management Systems", </title> <journal> Information Systems, </journal> <volume> Vol. 7, No. 1, </volume> <year> 1982. </year>
Reference-contexts: We have written separate Concurrency Control Manager modules based on two-phase locking with high-priority conflict resolution [Abbo88b] and optimistic concurrency control with broadcast commit <ref> [Mena82, Robi82, Hari90a] </ref>. These modules were used in our transaction scheduling studies [Pang92]. For the purposes of this dissertation, which focuses on query scheduling issues, the choice of concurrency control protocol does not matter. Hence, we arbitrarily chose the module that is based on the locking protocol. 2.2.
Reference: [Mok78] <author> A. Mok, M. Dertouzos, </author> <title> "Multi-processor Scheduling in a Hard Real-Time Environment", </title> <booktitle> Proc. of the 7th Texas Conf. on Computing Systems, </booktitle> <month> October </month> <year> 1978. </year>
Reference-contexts: To date, a number of real-time task scheduling policies have been proposed, and numerous research results have been obtained for both uniprocessor and multiprocessor systems <ref> [Liu73, Dert74, Mok78, Jens85, Lock86, Panw88, Baru91] </ref>. However, these studies have ignored the need to manage substantial amounts of data.
Reference: [Naka88] <author> M. Nakayama, M. Kitsuregawa, M. Takagi, </author> <title> "Hash-Partitioned Join Method Using Dynamic Destaging Strategy", </title> <booktitle> Proc. of the 14th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1988. </year>
Reference-contexts: One possible cause of this discrepancy is due to incorrect estimation of the hash attribute distribution. This results in a situation where some R partitions are larger than the allocated memory, while other R partitions are under-sized. In <ref> [Naka88] </ref>, a modification of Hybrid Hash Join was proposed to deal with this memory misfit problem. Instead of deciding on the number of partitions at the beginning, the proposed modification splits the inner relation into smaller subsets, called buckets, which will later be grouped into partitions. <p> Zeller and Gray first addressed this situation in [Zell90]. Like the algorithm in <ref> [Naka88] </ref>, the algorithm that they proposed divides the inner relation into many buckets. Unlike the Nakayama et al algorithm, the Zeller and Gray algorithm immediately groups these buckets into tentative partitions. The total number of buckets and the number of buckets per partition are both parameters of the algorithm. <p> First, Partially Preemptible Hash Join (PPHJ), a new family of hash join algorithms that dynami 23 cally alter the memory usage of joins according to buffer availability, is introduced. We then relate the algorithms proposed in <ref> [Naka88] </ref> and [Zell90] to PPHJ. Finally, we describe how our implementations of the basic GRACE and Hybrid Hash Join algorithms cope with memory fluctuations. 3.2.1. <p> Thus, PPHJ (early,noexp,lru) denotes the basic PPHJ, which uses early contraction, no expansion and LRU spooling; PPHJ (late,exp,prio) denotes the fully enhanced PPHJ, with late contraction, expansion and prioritized spooling, and so on. 3.2.2. Other Algorithms 3.2.2.1. Nakayama et al The algorithm proposed in <ref> [Naka88] </ref>, which we will call NKT from here on, delays the decision to contract buckets as long as possible. When a bucket has to be contracted, all of its memory-resident pages are flushed to disk without going through the spool area. <p> Thus expansion appears to be a generally useful mechanism. 3.3.7. Discussion of Other Alternatives As described in Section 3.2.2, we have extended the algorithms in <ref> [Naka88] </ref> and [Zell90] to allow partition contractions during the second phase of a join. <p> The exception was when 48 memory availability fluctuates extremely rapidly. Moreover, further savings can be achieved by late contraction and priority spooling, though the savings are not nearly as significant as those due to expansion. These findings are important in two ways. First, previous studies <ref> [Naka88, Zell90] </ref> have proposed algorithms that rely solely on late contraction. Our study showed that expanding partitions while the outer relation S is being scanned leads to more effective utilization of excess memory, and hence to lower response times.
Reference: [Pang92] <author> H. Pang, M. Livny, M.J. Carey, </author> <title> "Transaction Scheduling in Multiclass Real-Time Database Systems", </title> <booktitle> Proc. of the 13th IEEE Real-Time Systems Symposium (RTSS), </booktitle> <month> December </month> <year> 1992. </year>
Reference-contexts: We have written separate Concurrency Control Manager modules based on two-phase locking with high-priority conflict resolution [Abbo88b] and optimistic concurrency control with broadcast commit [Mena82, Robi82, Hari90a]. These modules were used in our transaction scheduling studies <ref> [Pang92] </ref>. For the purposes of this dissertation, which focuses on query scheduling issues, the choice of concurrency control protocol does not matter. Hence, we arbitrarily chose the module that is based on the locking protocol. 2.2. <p> In order to achieve such controlled performance, the query scheduler must intervene on behalf of classes that, either because of stricter timing requirements or larger resource demands, are in a disadvantaged position if allowed to compete unaided for resources (e.g., see <ref> [Pang92] </ref>). Since resource allocation decisions are priority-driven, the most effective way to help disadvantaged classes is to boost their priorities relative to the advantaged classes. <p> As a result, Small queries are able to enjoy relatively short admission waiting and response times at the expense of the Medium class under PMM. Another source of PMM's biased behavior is the Earliest Deadline policy used for resource scheduling <ref> [Pang92] </ref>. When treated on par with the Small queries, Medium queries are assigned lower priorities by ED most of the time because their deadlines are much further in the future.
Reference: [Pang93a] <author> H. Pang, M.J. Carey, M. Livny, </author> <title> "Partially Preemptible Hash Joins", </title> <booktitle> Proc. of the ACM SIGMOD Conf., </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: It should be noted that, in <ref> [Pang93a] </ref>, spooled pages are written out one page at a time. This accounts for the different performance figures reported there. However, the relative performance between different algorithms/mechanisms remains the same. 25 (2) Scan R. Hash each tuple with h. <p> Instead, an RTDBS needs to be willing to run queries at memory allocations that are below their maximum requirements so that enough queries can be admitted to take advantage of the RTDBS's disk and CPU resources. This is facilitated by memory-adaptive query processing techniques (such as those of <ref> [Pang93a, Pang93b] </ref>) that permit queries to execute efficiently in the face of memory fluctuations. Among the algorithms that do not insist on maximum memory allocations, Proportional allocation leads to very large miss ratios and should be avoided.
Reference: [Pang93b] <author> H. Pang, M.J. Carey, M. Livny, </author> <title> "Memory-Adaptive External Sorting", </title> <booktitle> Proc. of the 19th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: Instead, an RTDBS needs to be willing to run queries at memory allocations that are below their maximum requirements so that enough queries can be admitted to take advantage of the RTDBS's disk and CPU resources. This is facilitated by memory-adaptive query processing techniques (such as those of <ref> [Pang93a, Pang93b] </ref>) that permit queries to execute efficiently in the face of memory fluctuations. Among the algorithms that do not insist on maximum memory allocations, Proportional allocation leads to very large miss ratios and should be avoided.
Reference: [Pang94] <author> H. Pang, M.J. Carey, M. Livny, </author> <title> "Managing Memory for Real-Time Queries", </title> <booktitle> Proc. of the ACM SIGMOD Conf., to appear, </booktitle> <year> 1994. </year>
Reference: [Panw88] <author> S. Panwar, D. Towsley, </author> <title> "On the Optimality of the STE Rule for Multiple Server Queues that Serve Customers with Deadlines", </title> <type> COINS Technical Report 88-81, </type> <institution> University of Mas-sachusetts, Amherst, </institution> <month> July </month> <year> 1988. </year>
Reference-contexts: To date, a number of real-time task scheduling policies have been proposed, and numerous research results have been obtained for both uniprocessor and multiprocessor systems <ref> [Liu73, Dert74, Mok78, Jens85, Lock86, Panw88, Baru91] </ref>. However, these studies have ignored the need to manage substantial amounts of data.
Reference: [Pete86] <author> J.L. Peterson, A. Silberschatz, </author> <title> Operation System Concepts, </title> <publisher> Addison Wesley, </publisher> <year> 1986. </year>
Reference-contexts: The need for all of the components of an RTDBS to be priority-driven requires several changes in the ways that traditional database systems, which are not designed to handle the notion of priority, service their jobs. While existing priority preemptive-resume <ref> [Pete86] </ref> or priority head-of-the-line [Klei76] scheduling techniques can be used to schedule the CPU in an RTDBS, priority-based algorithms for concurrency control, disk scheduling, admission control, and memory management have to be developed for such a system.
Reference: [Ries78] <author> D. Ries, R. Epstein, </author> <title> "Evaluation of Distribution Criteria for Distributed Database Systems", </title> <type> UCB/ERL Technical Report M78/22, </type> <institution> UC Berkeley, </institution> <month> May </month> <year> 1978. </year>
Reference-contexts: A related problem is that of physical data placement in RTDBSs. In a multi-disk RTDBS, relations can be declustered <ref> [Ries78, Livn87] </ref> to exploit the I/O bandwidth of the disks and to achieve load balancing.
Reference: [Robi82] <author> J. Robinson, </author> <title> "Design of Concurrency Controls for Transaction Processing Systems", </title> <type> Ph.D. Thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1982. </year>
Reference-contexts: We have written separate Concurrency Control Manager modules based on two-phase locking with high-priority conflict resolution [Abbo88b] and optimistic concurrency control with broadcast commit <ref> [Mena82, Robi82, Hari90a] </ref>. These modules were used in our transaction scheduling studies [Pang92]. For the purposes of this dissertation, which focuses on query scheduling issues, the choice of concurrency control protocol does not matter. Hence, we arbitrarily chose the module that is based on the locking protocol. 2.2.
Reference: [RTS92] <institution> Real-Time Systems, </institution> <note> 4(3), Special Issue on Real-Time Databases, </note> <month> September </month> <year> 1992. </year>
Reference: [Salz90] <author> B. Salzberg, A. Tsukerman, J. Gray, M. Stewart, S. Uren, B. Vaughan, "FastSort: </author> <title> A Distributed Single-Input Single-Output External Sort", </title> <booktitle> Proc. of the ACM SIGMOD Conf., </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: Hence, replacement selection creates only half as many runs as Quicksort. This could significantly shorten the merge phase that follows. A nice discussion of the details involved in implementing replacement selection can be found in <ref> [Salz90] </ref>. Although using replacement selection instead of Quicksort can shorten the merge phase, replacement selection is not always the preferred choice because it can also lead to a longer split phase [Grae90, DeWi91].
Reference: [Sarg76] <author> R. Sargent, </author> <title> "Statistical Analysis of Simulation Output Data", </title> <booktitle> Proc. of the 4th Annual Symposium on the Simulation of Computer Systems, </booktitle> <month> August </month> <year> 1976. </year>
Reference-contexts: To ensure the statistical validity of our results, we will verify that the 90% confidence intervals for the primary performance metric (average query response times or system miss ratios), computed using the batch means approach <ref> [Sarg76] </ref>, are sufficiently tight. For the results presented, the size of the confidence intervals turn out to be within a few percent of the mean in almost all cases, which is more than sufficient for our purposes. Throughout the thesis we discuss only statistically significant performance differences. <p> Unless stated otherwise, each experiment was run for 10 hours of simulated time, allowing a minimum of 2000 query completions. We also verified that the size of the 90% confidence intervals for miss ratios (computed using the batch means approach <ref> [Sarg76] </ref>) was within a few percent of the mean in almost all cases, thus ensuring that our results are statistically valid. 5.3.1.
Reference: [Sha90] <author> L. Sha, R. Rajkumar, J.P. Lehoczky, </author> <title> "Priority Inheritance Protocols: An Approach to Real-Time Synchronization", </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 39, No. 9, </volume> <month> September </month> <year> 1990. </year>
Reference-contexts: Such a situation, known as priority inversion, causes priority scheduling to be counterproductive to system performance <ref> [Sha90] </ref>.
Reference: [Shap86] <author> L.D. Shapiro, </author> <title> "Join Processing in Database Systems with Large Main Memories", </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol. 11, No. 3, </volume> <month> September </month> <year> 1986. </year>
Reference-contexts: For instance, a hash join can either execute with its maximum required memory, which is slightly greater than the size of its inner relation, or it can run in an additional pass with as few buffer pages as the square root of its inner relation size <ref> [DeWi84, Shap86] </ref>. In order to derive the benefits of multiprogramming, it may be necessary for an RTDBS to admit some queries with less than their maximum memory allocations. <p> Depending on the specific algorithm used, the number of buffers that a hash join utilizes ranges anywhere from the square root of the size of its inner relation up to its inner relation size <ref> [DeWi84, Shap86] </ref>, which can be a substantial portion of the system memory. Consequently, a real-time or priority-driven database management system (DBMS) may have to preempt large hash joins in order to satisfy the memory requirements of higher-priority jobs. <p> In the variation of the GRACE algorithm that is presented in <ref> [Shap86] </ref>, a join requires only ddddd F||R|| output buffers throughout its lifetime. Excess buffers are used to hold subsets of R and/or S so they need not be written to disk. <p> Dynamic splitting therefore appears to be a promising merge-phase adaptation strategy in practice. 4.4. Sort-Merge Joins Sort-merge join is a join algorithm employed by many existing database systems. Although recent work has shown hash join to often be superior to sort-merge join in performing ad-hoc join operations <ref> [Brat84, DeWi84, Shap86] </ref>, sort-merge join is still useful under certain conditions, e.g. when significant data skew is present, or when the results need to be presented in sorted order [Grae91]. Hence sort-merge join is likely to continue to be offered as one of the alternative join algorithms in future DBMSs. <p> The maximum memory requirement of an external sort is the size of its operand relation <ref> [Shap86] </ref>, whereas it can run with as few as three memory pages by doing multiple merge passes. <p> In the case of a hash join, the maximum memory requirement and the minimum memory demand for two-pass operation are F||R|| and ddddd F||R|| , respectively, where ||R|| is the inner (building) relation size and F is a fudge factor that reflects the overhead of a hash table <ref> [Shap86] </ref>. 85 When the total maximum memory requirement of the admitted queries exceeds the available memory, the memory allocation component is responsible for determining the amount of memory to allot to each query.
Reference: [SIGM88] <editor> ACM SIGMOD Record, </editor> <volume> Vol. 17, No. </volume> <month> 1, </month> <title> Special Issue on Real-Time Data Base Systems, </title> <editor> S. Son, editor, </editor> <month> March </month> <year> 1988. </year>
Reference: [Stan88] <author> J.A. Stankovic, W. Zhao, </author> <title> "On Real-Time Transactions", </title> <journal> ACM SIGMOD Record, </journal> <volume> Vol. 17, No. 1, </volume> <month> March </month> <year> 1988. </year>
Reference-contexts: INTRODUCTION A number of emerging database applications, including aircraft control, stock trading, network management, and factory automation, have to manipulate vast quantities of shared data. Moreover, these applications may generate jobs that have to be completed by certain deadlines for the results to be of value in providing decision-support <ref> [Abbo88a, Stan88] </ref>. For example, in a factory automation system, a quality inspection must be completed within a specified time frame in order to undertake any necessary corrective actions.
Reference: [Ston81] <author> M. Stonebraker, </author> <title> "Operating System Support for Database Management", </title> <journal> Comm. of the ACM, </journal> <volume> Vol. 24, No. 7, </volume> <year> 1981. </year> <month> 137 </month>
Reference: [Yu93] <author> P.S. Yu, D.W. Cornell, </author> <title> "Buffer Management Based on Return on Consumption In a Multi-Query Environment", </title> <journal> VLDB Journal, </journal> <volume> Vol. 2, No. 1, </volume> <month> January </month> <year> 1993. </year>
Reference-contexts: In addition, the effectiveness of memory allocation in reducing individual queries' response times should be considered so as to make the best use of the available memory <ref> [Corn89, Yu93] </ref>. This thesis introduces a priority-cognizant algorithm that dynamically chooses a target multiprogramming level and a memory allocation strategy for queries to balance the demands on the system's memory, CPU, and disks. <p> The work that is most relevant to our work here is reported in <ref> [Corn89, Yu93] </ref>. In that work, the authors examined the effect of memory allocations on query response times in traditional (non-real-time) database systems, and they concluded that giving some of the queries their maximum required memory, while allocating the minimum possible memory to the rest, leads to near-optimal memory usage. <p> The reason for doing MinMax allocation, as opposed to simply dividing the available memory proportionally among the admitted queries, is that MinMax leads to more effective use of memory then proportional allocation (as was shown in <ref> [Corn89, Yu93] </ref>); this will be verified quantitatively in Section 5.3.1. The MinMax allocation process is conceptually carried out in two passes. Starting from the highest-priority query, PMM first gives each query just enough memory for it to begin execution. <p> This increases the queries' reliance on the CPU and disks, resulting in further increases in the queries' execution times. Consequently, Proportional utilizes memory much less effectively than MinMax. As mentioned earlier, similar observations about the inferiority of Proportional-style policies were made in <ref> [Corn89, Yu93] </ref> in a non-real-time context. We now turn our attention to the PMM algorithm.

References-found: 63

