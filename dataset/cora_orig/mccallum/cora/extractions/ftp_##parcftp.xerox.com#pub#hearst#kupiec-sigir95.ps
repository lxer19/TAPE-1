URL: ftp://parcftp.xerox.com/pub/hearst/kupiec-sigir95.ps
Refering-URL: http://www.csi.uottawa.ca/~debruijn/irbib.html
Root-URL: 
Email: fkupiec,pedersen,fcheng@parc.xerox.com  
Title: A Trainable Document Summarizer  
Author: Julian Kupiec, Jan Pedersen and Francine Chen 
Keyword: summary sentence, original documents, summary pairs, training corpus, document extracts  
Note: Document extracts consisting of roughly 20% of the original can be as informative as the full text of a document, which suggests that even shorter extracts may be useful indicative summaries.  
Address: 3333 Coyote Hill Road, Palo Alto, CA 94304  
Affiliation: Xerox Palo Alto Research Center  
Abstract: This paper focusses on document extracts, a particular kind of computed document summary. * The trends in our results are in agreement with those of Ed-mundson who used a subjectively weighted combination of features as opposed to training the feature weights using a cor pus. * We have developed a trainable summarization program that is grounded in a sound statistical framework. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. B. Baxendale. </author> <title> Man-made index for technical literature an experiment. </title> <journal> IBM J. Res. Develop., </journal> <volume> 2(4) </volume> <pages> 354-361, </pages> <year> 1958. </year>
Reference-contexts: The scoring criteria employed include participation in predefined semantic roles [ 11 ] , rhetorical relations [ 8 ] , inclusion of phrasal index terms [ 16 ] , document-specific keyword frequencies [ 7 ] , location heuristics <ref> [ 1 ] </ref> , and the assessment of sentence similarity structure [ 17, 15 ] . Methods either assume the document exists in isolation, or in the context of a larger collection, which al lows term weights to depend on corpus statistics [ 14, 15 ] . <p> The title-keyword heuristic assumes that important sentences contain content words that are present in the title and major headings of a document. Location heuristics assume that important sentences lie at the beginning and end of a document, in the first and last sentences of paragraphs <ref> [ 1, 4 ] </ref> , and also immediately below section headings. Indicator phrases contain words that are likely to accompany indicative or informative summary material (e.g., This report...). A related heuristic involves cue words.
Reference: [2] <author> F.R. Chen and M.M. Withgott. </author> <title> The use of emphasis to automatically summarize a spoken discourse. </title> <booktitle> In Proceedings of the IEEE Intl. Conf. on Acoust., Speech and Signal Proc., </booktitle> <volume> volume 1, </volume> <pages> pages 229-232, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Document extracts consisting of roughly 20% of the original can be as informative as the full text of a document [ 9 ] , which suggests that even shorter extracts may be useful indicative summaries. However, other studies <ref> [ 12, 2 ] </ref> suggest that the optimal extract can be far from unique. Numerous heuristics have been proposed to guide the selection of document extracts [ 7, 4, 17, 14 ] , yet no clear criterion has been proposed to choose among them. <p> The summarizer thus replicates 35% of the information in the manual summaries. This assumes that only one correct summary exists for a document which is very unlikely to be the case. Indeed, it has been observed that subjects differ greatly when asked to select summary sentences <ref> [ 2 ] </ref> . In particular, Rath et al. [ 12 ] found that extracts selected by four different human judges had only 25% overlap, and for a given judge over time only 55% overlap.
Reference: [3] <author> G. DeJong. </author> <title> An overview of the FRUMP system. In W.G. </title> <editor> Lehnert and M. H. Ringle, editors, </editor> <booktitle> Strategies for Natural Language Parsing, </booktitle> <pages> pages 149-176, </pages> <year> 1982. </year>
Reference-contexts: The nominal task of generating a coherent narrative summarizing a document is currently considered too problematic since it encompasses discourse understanding, abstraction, and language generation [ 6 ] . Nonetheless, knowledge intensive methods have had some successin restricted domains <ref> [ 11, 5, 3, 13, 18 ] </ref> . For example, a filled template produced by a message understanding system can be thought of as a targetted document summary.
Reference: [4] <author> H. P. Edmundson. </author> <title> New methods in automatic abstracting. </title> <journal> Journal of the ACM, </journal> <volume> 16(2) </volume> <pages> 264-285, </pages> <month> April </month> <year> 1969. </year>
Reference-contexts: However, other studies [ 12, 2 ] suggest that the optimal extract can be far from unique. Numerous heuristics have been proposed to guide the selection of document extracts <ref> [ 7, 4, 17, 14 ] </ref> , yet no clear criterion has been proposed to choose among them. Existing evidence [ 4 ] suggests that combinations of individual heuristics have the best performance. We approach extract selection as a statistical classification problem. <p> However, other studies [ 12, 2 ] suggest that the optimal extract can be far from unique. Numerous heuristics have been proposed to guide the selection of document extracts [ 7, 4, 17, 14 ] , yet no clear criterion has been proposed to choose among them. Existing evidence <ref> [ 4 ] </ref> suggests that combinations of individual heuristics have the best performance. We approach extract selection as a statistical classification problem. Given a training set of documents with hand-selected document extracts, develop a classification function that estimates the probability a given sentence is included in an extract. <p> Frequency-keyword heuristics use the most common content words as indicators of the main themes in the document. Sentences containing these words are scored using functions of their frequency counts <ref> [ 4, 19 ] </ref> . The title-keyword heuristic assumes that important sentences contain content words that are present in the title and major headings of a document. <p> The title-keyword heuristic assumes that important sentences contain content words that are present in the title and major headings of a document. Location heuristics assume that important sentences lie at the beginning and end of a document, in the first and last sentences of paragraphs <ref> [ 1, 4 ] </ref> , and also immediately below section headings. Indicator phrases contain words that are likely to accompany indicative or informative summary material (e.g., This report...). A related heuristic involves cue words. <p> Indicator phrases contain words that are likely to accompany indicative or informative summary material (e.g., This report...). A related heuristic involves cue words. These may include two sets of bonus and stigma words <ref> [ 4 ] </ref> which are positively and negatively correlated with summary sentences. Example bonus words are greatest and significant. Stigma words are exemplified by hardly and impossible. Through experimentation we settled on the following feature set, which are all discrete in nature. <p> By analogy, 25% of the average document length (86 sentences) in our corpus is about 20 sentences. Reference to the table indicates performance at 84%. 5 Discussion The trends in our results are in agreement with those of Edmund-son <ref> [ 4 ] </ref> who used a subjectively weighted combination of features as opposed to training the feature weights using a corpus. He also found that location-based heuristics gave best performance. His best combination of heuristics were based on location, title-keywords and cue words.
Reference: [5] <author> P.S. Jacobs and L. F. Rau. Scisor: </author> <title> Extracting information from on-line news. </title> <journal> Communications of the ACM, </journal> <volume> 33(11) </volume> <pages> 88-97, </pages> <year> 1990. </year>
Reference-contexts: The nominal task of generating a coherent narrative summarizing a document is currently considered too problematic since it encompasses discourse understanding, abstraction, and language generation [ 6 ] . Nonetheless, knowledge intensive methods have had some successin restricted domains <ref> [ 11, 5, 3, 13, 18 ] </ref> . For example, a filled template produced by a message understanding system can be thought of as a targetted document summary.
Reference: [6] <author> K. Sparck Jones. </author> <title> Discourse modelling for automatic sum-marising. </title> <type> Technical Report 29D, </type> <institution> Computer Laboratory, University of Cambridge, </institution> <year> 1993. </year>
Reference-contexts: Numerous researchers have addressed automatic document summarization (see [ 10 ] for an overview). The nominal task of generating a coherent narrative summarizing a document is currently considered too problematic since it encompasses discourse understanding, abstraction, and language generation <ref> [ 6 ] </ref> . Nonetheless, knowledge intensive methods have had some successin restricted domains [ 11, 5, 3, 13, 18 ] . For example, a filled template produced by a message understanding system can be thought of as a targetted document summary.
Reference: [7] <author> H.P. Luhn. </author> <title> The automatic creation of literature abstracts. </title> <journal> IBM J. Res. Develop., </journal> <volume> 2 </volume> <pages> 159-165, </pages> <year> 1959. </year>
Reference-contexts: For example, a filled template produced by a message understanding system can be thought of as a targetted document summary. A simpler, more generic approach avoids the central difficulties of natural language processing by redefining the task to be summary by extraction <ref> [ 7 ] </ref> . That is, the goal is to find a subset of the document that is indicative of its contents, typically by scoring sentences and presenting those with the best scores. <p> However, other studies [ 12, 2 ] suggest that the optimal extract can be far from unique. Numerous heuristics have been proposed to guide the selection of document extracts <ref> [ 7, 4, 17, 14 ] </ref> , yet no clear criterion has been proposed to choose among them. Existing evidence [ 4 ] suggests that combinations of individual heuristics have the best performance. We approach extract selection as a statistical classification problem. <p> The scoring criteria employed include participation in predefined semantic roles [ 11 ] , rhetorical relations [ 8 ] , inclusion of phrasal index terms [ 16 ] , document-specific keyword frequencies <ref> [ 7 ] </ref> , location heuristics [ 1 ] , and the assessment of sentence similarity structure [ 17, 15 ] .
Reference: [8] <author> S. Miike, E. Itoh, K. Ono, and K. Sumita. </author> <title> A full-text retrieval system with a dynamic abstract generation function. </title> <editor> In W. Bruce Croft and C.J. van Rijsbergen, editors, </editor> <booktitle> Proceedings of Seventeenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 152-161, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: The scoring criteria employed include participation in predefined semantic roles [ 11 ] , rhetorical relations <ref> [ 8 ] </ref> , inclusion of phrasal index terms [ 16 ] , document-specific keyword frequencies [ 7 ] , location heuristics [ 1 ] , and the assessment of sentence similarity structure [ 17, 15 ] .
Reference: [9] <author> A. H. Morris, G. M. Kasper, and D. A. Adams. </author> <title> The effects and limitations of automated text condensing on reading comprehension performance. </title> <journal> Information Systems Research, </journal> <pages> pages 17-35, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: These sorts of summaries are not guaranteed to have narrative coherence, yet may be useful for rapid relevance assessment. Document extracts consisting of roughly 20% of the original can be as informative as the full text of a document <ref> [ 9 ] </ref> , which suggests that even shorter extracts may be useful indicative summaries. However, other studies [ 12, 2 ] suggest that the optimal extract can be far from unique.
Reference: [10] <author> C. D. Paice. </author> <title> Constructing literature abstracts by computer: Techniques and prospects. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 26 </volume> <pages> 171-186, </pages> <year> 1990. </year>
Reference-contexts: A traditional author-supplied indicative abstract clearly fulfills this objective, but it is hoped that other, more easily computed condensations may also serve. Numerous researchers have addressed automatic document summarization (see <ref> [ 10 ] </ref> for an overview). The nominal task of generating a coherent narrative summarizing a document is currently considered too problematic since it encompasses discourse understanding, abstraction, and language generation [ 6 ] . <p> To pursue this approach, we need to establish the set of potential features, the classification method, and a training corpus of document/extract pairs. 2.1 Features Paice <ref> [ 10 ] </ref> groups sentence scoring features into seven categories. Frequency-keyword heuristics use the most common content words as indicators of the main themes in the document. Sentences containing these words are scored using functions of their frequency counts [ 4, 19 ] .
Reference: [11] <author> C. D. Paice and P. A. Jones. </author> <title> The identification of important concepts in highly structured technical papers. </title> <editor> In R. Korfhage, E. Rasmussen, and P. Willett, editors, </editor> <booktitle> Proceedings of Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 69-78. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1993. </year>
Reference-contexts: The nominal task of generating a coherent narrative summarizing a document is currently considered too problematic since it encompasses discourse understanding, abstraction, and language generation [ 6 ] . Nonetheless, knowledge intensive methods have had some successin restricted domains <ref> [ 11, 5, 3, 13, 18 ] </ref> . For example, a filled template produced by a message understanding system can be thought of as a targetted document summary. <p> The scoring criteria employed include participation in predefined semantic roles <ref> [ 11 ] </ref> , rhetorical relations [ 8 ] , inclusion of phrasal index terms [ 16 ] , document-specific keyword frequencies [ 7 ] , location heuristics [ 1 ] , and the assessment of sentence similarity structure [ 17, 15 ] .
Reference: [12] <author> G. J. Rath, A. Resnick, and T. R. Savage. </author> <title> The formation of abstracts by the selection of sentences. </title> <journal> American Documentation, </journal> <volume> 12(2) </volume> <pages> 139-143, </pages> <month> April </month> <year> 1961. </year>
Reference-contexts: Document extracts consisting of roughly 20% of the original can be as informative as the full text of a document [ 9 ] , which suggests that even shorter extracts may be useful indicative summaries. However, other studies <ref> [ 12, 2 ] </ref> suggest that the optimal extract can be far from unique. Numerous heuristics have been proposed to guide the selection of document extracts [ 7, 4, 17, 14 ] , yet no clear criterion has been proposed to choose among them. <p> This assumes that only one correct summary exists for a document which is very unlikely to be the case. Indeed, it has been observed that subjects differ greatly when asked to select summary sentences [ 2 ] . In particular, Rath et al. <ref> [ 12 ] </ref> found that extracts selected by four different human judges had only 25% overlap, and for a given judge over time only 55% overlap.
Reference: [13] <author> U. Reimer and U. Hahn. </author> <title> Text condensation as knowledge base abstraction. </title> <booktitle> In IEEE Conf. on AI Applications, </booktitle> <pages> pages 338-344, </pages> <year> 1988. </year>
Reference-contexts: The nominal task of generating a coherent narrative summarizing a document is currently considered too problematic since it encompasses discourse understanding, abstraction, and language generation [ 6 ] . Nonetheless, knowledge intensive methods have had some successin restricted domains <ref> [ 11, 5, 3, 13, 18 ] </ref> . For example, a filled template produced by a message understanding system can be thought of as a targetted document summary.
Reference: [14] <author> G. Salton, J. Alan, and C. Buckley. </author> <title> Approaches to passage retrieval in full text information systems. </title> <booktitle> In Proceedings of SIGIR'93, </booktitle> <pages> pages 49-58, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: However, other studies [ 12, 2 ] suggest that the optimal extract can be far from unique. Numerous heuristics have been proposed to guide the selection of document extracts <ref> [ 7, 4, 17, 14 ] </ref> , yet no clear criterion has been proposed to choose among them. Existing evidence [ 4 ] suggests that combinations of individual heuristics have the best performance. We approach extract selection as a statistical classification problem. <p> Methods either assume the document exists in isolation, or in the context of a larger collection, which al lows term weights to depend on corpus statistics <ref> [ 14, 15 ] </ref> . The precise formulation of the scoring rule is heuristic and empirical in nature. However, if one were given a training corpus of documents with matched extracts, it would be natural to approach the problem as one of statistical classification.
Reference: [15] <author> G. Salton, J. Allan, C. Buckley, and A. Singhal. </author> <title> Automatic analysis, theme generation, and summarization of machine-readable texts. </title> <journal> Science, </journal> <volume> 264(3) </volume> <pages> 1421-1426, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: The scoring criteria employed include participation in predefined semantic roles [ 11 ] , rhetorical relations [ 8 ] , inclusion of phrasal index terms [ 16 ] , document-specific keyword frequencies [ 7 ] , location heuristics [ 1 ] , and the assessment of sentence similarity structure <ref> [ 17, 15 ] </ref> . Methods either assume the document exists in isolation, or in the context of a larger collection, which al lows term weights to depend on corpus statistics [ 14, 15 ] . The precise formulation of the scoring rule is heuristic and empirical in nature. <p> Methods either assume the document exists in isolation, or in the context of a larger collection, which al lows term weights to depend on corpus statistics <ref> [ 14, 15 ] </ref> . The precise formulation of the scoring rule is heuristic and empirical in nature. However, if one were given a training corpus of documents with matched extracts, it would be natural to approach the problem as one of statistical classification.
Reference: [16] <author> C. Schwarz. </author> <title> Content based text handling. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 26(2) </volume> <pages> 219-226, </pages> <year> 1990. </year>
Reference-contexts: The scoring criteria employed include participation in predefined semantic roles [ 11 ] , rhetorical relations [ 8 ] , inclusion of phrasal index terms <ref> [ 16 ] </ref> , document-specific keyword frequencies [ 7 ] , location heuristics [ 1 ] , and the assessment of sentence similarity structure [ 17, 15 ] .
Reference: [17] <author> E. F. Skorokhod'ko. </author> <title> Adaptive method of automatic abstracting and indexing. </title> <booktitle> In IFIP Congress, </booktitle> <address> Ljubljana, Yugoslavia 71, </address> <pages> pages 1179-1182. </pages> <publisher> North Holland, </publisher> <year> 1972. </year>
Reference-contexts: However, other studies [ 12, 2 ] suggest that the optimal extract can be far from unique. Numerous heuristics have been proposed to guide the selection of document extracts <ref> [ 7, 4, 17, 14 ] </ref> , yet no clear criterion has been proposed to choose among them. Existing evidence [ 4 ] suggests that combinations of individual heuristics have the best performance. We approach extract selection as a statistical classification problem. <p> The scoring criteria employed include participation in predefined semantic roles [ 11 ] , rhetorical relations [ 8 ] , inclusion of phrasal index terms [ 16 ] , document-specific keyword frequencies [ 7 ] , location heuristics [ 1 ] , and the assessment of sentence similarity structure <ref> [ 17, 15 ] </ref> . Methods either assume the document exists in isolation, or in the context of a larger collection, which al lows term weights to depend on corpus statistics [ 14, 15 ] . The precise formulation of the scoring rule is heuristic and empirical in nature.
Reference: [18] <author> J. I. Tait. </author> <title> Generating summaries using a script-based language analyzer. </title> <editor> In L. Steels and J.A. Campbell, editors, </editor> <booktitle> Progress in Artificial Intelligence, </booktitle> <pages> pages 312-318. </pages> <publisher> Ellis Horwood, </publisher> <year> 1985. </year>
Reference-contexts: The nominal task of generating a coherent narrative summarizing a document is currently considered too problematic since it encompasses discourse understanding, abstraction, and language generation [ 6 ] . Nonetheless, knowledge intensive methods have had some successin restricted domains <ref> [ 11, 5, 3, 13, 18 ] </ref> . For example, a filled template produced by a message understanding system can be thought of as a targetted document summary.
Reference: [19] <author> L. C. Tong and S. L. Tan. </author> <title> A statistical approach to automatic text extraction. Asian Library Journal. </title>
Reference-contexts: Frequency-keyword heuristics use the most common content words as indicators of the main themes in the document. Sentences containing these words are scored using functions of their frequency counts <ref> [ 4, 19 ] </ref> . The title-keyword heuristic assumes that important sentences contain content words that are present in the title and major headings of a document.
References-found: 19

