URL: http://www.ius.cs.cmu.edu/IUS/har2/har/papers/cvpr96/cvpr.ps.gz
Refering-URL: http://www.cs.cmu.edu/~har/faces-old-papers.html
Root-URL: 
Email: har@cs.cmu.edu  baluja@cs.cmu.edu  tk@cs.cmu.edu  
Title: Neural Network-Based Face Detection  
Author: Henry A. Rowley Shumeet Baluja Takeo Kanade 
Date: 1996.  
Note: Appears in Computer Vision and Pattern Recognition,  
Address: Pittsburgh, PA 15213, USA  
Affiliation: School of Computer Science, Carnegie Mellon University,  
Abstract: We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image, and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates. 
Abstract-found: 1
Intro-found: 1
Reference: [ Hunke, 1994 ] <author> H. Martin Hunke. </author> <title> Locating and tracking of human faces with neural networks. </title> <type> Master's thesis, </type> <institution> University of Karlsruhe, </institution> <year> 1994. </year>
Reference-contexts: Other methods of improving system performance include obtaining more positive examples for training, or applying more sophisticated image preprocessing and normalization techniques. For instance, the color segmentation method used in <ref> [ Hunke, 1994 ] </ref> for color-based face tracking could be used to filter images. The face detector would then be applied only to portions of the image which contain skin color, which would speed up the algorithm as well as eliminating some false detections.
Reference: [ Le Cun et al., 1989 ] <author> Y. Le Cun, B. Boser, J. S. Denker, D. Hen-derson, R. E. Howard, W. Hubbard, and L. D. Jackel. </author> <title> Backpro-pogation applied to handwritten zip code recognition. </title> <booktitle> Neural Computation, </booktitle> <address> 1:541551, </address> <year> 1989. </year>
Reference-contexts: For the experiments which are described later, we use networks with two and three sets of these hidden units. Similar input connection patterns are commonly used in speech and character recognition tasks <ref> [ Waibel et al., 1989, Le Cun et al., 1989 ] </ref> . The network has a single, real-valued output, which indicates whether or not the window contains a face.
Reference: [ Rowley et al., 1995 ] <author> Henry A. Rowley, Shumeet Baluja, and Takeo Kanade. </author> <title> Human face detection in visual scenes. </title> <institution> CMU-CS-95-158R, Carnegie Mellon University, </institution> <month> November </month> <year> 1995. </year> <note> Also available at http://www.cs.cmu.edu/har/faces.html. </note>
Reference-contexts: Below we mention some techniques to reduce these errors; for more details the reader is referred to <ref> [ Rowley et al., 1995 ] </ref> . Because of a small amount of position and scale invari-ance in the filter, real faces are often detected at multiple nearby positions and scales, while false detections only appear at a single position. <p> The results for ANDing and ORing networks were based on Networks 1 and 2, while voting was based on Networks 1, 2, and 3. The table shows the percentage of faces correctly detected, and the number of false detections over the combination of Test Sets A, B, and C. <ref> [ Rowley et al., 1995 ] </ref> gives a breakdown of the performance of each of these system for each of the three test Table 1: Combined detection and error rates for Test Sets A, B, and C Missed Detect False False detect Type System faces rate detects rate 0) Ideal System <p> These outputs are accumulated over the entire image, and peaks are extracted to give candidate locations for license plates. In <ref> [ Rowley et al., 1995 ] </ref> , we show that a face detection network can also be made translation invariant. However, this translation invariant face detector makes many more false detections than one that detects only centered faces.
Reference: [ Sung and Poggio, 1994 ] <author> Kah-Kay Sung and Tomaso Poggio. </author> <title> Example-based learning for view-based human face detection. </title> <journal> A.I. </journal> <note> Memo 1521, CBCL Paper 112, </note> <institution> MIT, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: The size of the training set for the second class can grow very quickly. We avoid the problem of using a huge training set for non-faces by selectively adding images to the training set as training progresses <ref> [ Sung and Poggio, 1994 ] </ref> . Detailed descriptions of this training method, along with the network architecture are given in Section 2. In Section 3, the performance of the system is examined. <p> To detect faces larger than the window size, the input image is repeatedly subsampled by a factor of 1.2, and the filter is applied at each scale. The filtering algorithm is shown in Figure 1. First, a preprocessing step, adapted from <ref> [ Sung and Poggio, 1994 ] </ref> , is applied to a window of the image. The window is then passed through a neural network, which decides whether the window contains a face. The preprocessing first attempts to equalize the intensity values across the window. <p> However, collecting small yet a representative set of non-faces is difficult. Instead of collecting the images before training is started, the images are collected during training in the following manner, adapted from <ref> [ Sung and Poggio, 1994 ] </ref> : 1. Create an initial set of non-face images by generating 1000 images with random pixel intensities. Apply the preprocessing steps to each of these images. 2. <p> These images contain 169 frontal views of faces, and require the networks to examine 22,053,124 20x20 pixel windows. Test Set B consists of 23 images containing 155 faces (9,678,084 windows); it was used in <ref> [ Sung and Poggio, 1994 ] </ref> to measure the accuracy of their system. Test Set C is similar to Test Set A, but contains some images with more complex backgrounds and without any faces, to more accurately measure the false detection rate. <p> System 11 detects on average 85.4% of the faces, with an average of one false detection per 1,319,035 20x20 pixel windows examined. 4 Comparison to other systems <ref> [ Sung and Poggio, 1994 ] </ref> reports a face detection system based on clustering techniques. Their system, like ours, passes a small window over all portions of the image, and determines whether a face exists in each window. <p> The second distance metric is the Euclidean distance between the test pattern and its projection in the 75 dimensional subspace. These distance measures have close ties with Principal Components Analysis (PCA), as described in <ref> [ Sung and Poggio, 1994 ] </ref> . The last step in their system is to use either a perceptron or a neural network with a hidden in the image, the number of faces detected correctly, and the number of false detections. <p> The main computational cost in <ref> [ Sung and Poggio, 1994 ] </ref> is in computing the two distance measures from each new window to 12 clusters. <p> Table 2 shows the accuracy of their system on Test Set B, along with the our results using Systems 10, 11, and 12 in Table 1, and shows that for equal numbers of false detections, we can achieve higher detection rates. Table 2: Comparison of <ref> [ Sung and Poggio, 1994 ] </ref> and our system on Test Set B Missed Detect False False detect System faces rate detects rate 10) Networks 1 and 2 ! AND (0) ! threshold (2,3) ! overlap elimination 34 78.1% 3 1/3226028 11) Networks 1 and 2 ! threshold (2,2) ! overlap <p> ! threshold (2,3) ! overlap elimination 34 78.1% 3 1/3226028 11) Networks 1 and 2 ! threshold (2,2) ! overlap elimination ! AND (2) 20 87.1% 15 1/645206 12) Networks 1 and 2 ! threshold (2,2) ! overlap ! OR (2) ! threshold (2,1) ! overlap 11 92.9% 64 1/151220 <ref> [ Sung and Poggio, 1994 ] </ref> (Multi-layer network) 36 76.8% 5 1/1929655 [ Sung and Poggio, 1994 ] (Perceptron) 28 81.9% 13 1/742175 Although our system is less computationally expensive than [ Sung and Poggio, 1994 ] , the system described so far is not real-time because of the number of <p> 1 and 2 ! threshold (2,2) ! overlap elimination ! AND (2) 20 87.1% 15 1/645206 12) Networks 1 and 2 ! threshold (2,2) ! overlap ! OR (2) ! threshold (2,1) ! overlap 11 92.9% 64 1/151220 <ref> [ Sung and Poggio, 1994 ] </ref> (Multi-layer network) 36 76.8% 5 1/1929655 [ Sung and Poggio, 1994 ] (Perceptron) 28 81.9% 13 1/742175 Although our system is less computationally expensive than [ Sung and Poggio, 1994 ] , the system described so far is not real-time because of the number of windows which must be classified. <p> and 2 ! threshold (2,2) ! overlap ! OR (2) ! threshold (2,1) ! overlap 11 92.9% 64 1/151220 <ref> [ Sung and Poggio, 1994 ] </ref> (Multi-layer network) 36 76.8% 5 1/1929655 [ Sung and Poggio, 1994 ] (Perceptron) 28 81.9% 13 1/742175 Although our system is less computationally expensive than [ Sung and Poggio, 1994 ] , the system described so far is not real-time because of the number of windows which must be classified. In the related task of license plate detection, [ Umezaki, 1995 ] decreased the number of windows that must be processed.
Reference: [ Umezaki, 1995 ] <author> Tazio Umezaki. </author> <type> Personal communication, </type> <year> 1995. </year>
Reference-contexts: In the related task of license plate detection, <ref> [ Umezaki, 1995 ] </ref> decreased the number of windows that must be processed. The key idea was to have the neural network be invariant to translations of about 25% of the size of a license plate.
Reference: [ Vaillant et al., 1994 ] <author> R. Vaillant, C. Monrocq, and Y. Le Cun. </author> <title> Original approach for the localisation of objects in images. </title> <booktitle> IEE Proceedings on Vision, Image, and Signal Processing, </booktitle> <volume> 141(4), </volume> <month> August </month> <year> 1994. </year>
Reference-contexts: We use the centered face detector to verify candidates found by the translation invariant network. With this approach, we can process a 320x240 pixel image in less than 5 seconds on an SGI Indy workstation. This technique is related, at a high level, to the technique presented in <ref> [ Vaillant et al., 1994 ] </ref> . 5 Conclusions and future research Our algorithm can detect between 78.9% and 90.5% of faces in a set of 130 test images, with an acceptable number of false detections.
Reference: [ Waibel et al., 1989 ] <author> Alex Waibel, Toshiyuki Hanazawa, Geof-frey Hinton, Kiyohiro Shikano, and Kevin J. Lang. </author> <title> Phoneme recognition using time-delay neural networks. </title> <booktitle> Readings in Speech Recognition, </booktitle> <pages> pages 393404, </pages> <year> 1989. </year>
Reference-contexts: For the experiments which are described later, we use networks with two and three sets of these hidden units. Similar input connection patterns are commonly used in speech and character recognition tasks <ref> [ Waibel et al., 1989, Le Cun et al., 1989 ] </ref> . The network has a single, real-valued output, which indicates whether or not the window contains a face.
References-found: 7

