URL: http://www.cs.cornell.edu/home/kleinber/ht98.ps
Refering-URL: http://www.cs.cornell.edu/home/kleinber/kleinber.html
Root-URL: 
Email: dag@cs.berkeley.edu  kleinber@cs.cornell.edu  pragh@almaden.ibm.com  
Phone: +1 510 643 5425  +1 607 254 4636  +1 408 927 1804  
Title: Inferring Web Communities from Link Topology  
Author: David Gibson Jon Kleinberg Prabhakar Raghavan 
Address: Berkeley, CA 94720 USA  Ithaca, NY 14853 USA  San Jose, CA 95120 USA  
Affiliation: Dept. of Computer Science UC Berkeley  Dept. of Computer Science Cornell University  Almaden Research Center IBM  
Abstract: The World Wide Web grows through a decentralized, almost anarchic process, and this has resulted in a large hyperlinked corpus without the kind of logical organization that can be built into more traditionally-created hypermedia. To extract meaningful structure under such circumstances, we develop a notion of hyperlinked communities on the www through an analysis of the link topology. By invoking a simple, mathematically clean method for defining and exposing the structure of these communities, we are able to derive a number of themes: The communities can be viewed as containing a core of central, "authoritative" pages linked together by "hub pages"; and they exhibit a natural type of hierarchical topic generalization that can be inferred directly from the pattern of linkage. Our investigation shows that although the process by which users of the Web create pages and links is very difficult to understand at a "local" level, it results in a much greater degree of orderly high-level structure than has typically been assumed. Keywords: Hypertext communities, information exploration, World Wide Web, collabo rative annotation. fl A version of this paper appears in the Proceedings of the 9th ACM Conference on Hypertext and Hypermedia, 1998. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G.O. Arocena, A.O. Mendelzon, G.A. Mihaila, </author> <title> "Applications of a Web query language," </title> <booktitle> Proc. 6th International World Wide Web Conference, </booktitle> <year> 1997. </year>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing [2, 4, 13, 24], visualizing [7, 21] and searching <ref> [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] </ref> in hypermedia such as the www. <p> The use of link information to improve search performance on the www has been advanced in previous work; hyperlink analysis has been used for enhancing relevance judgments <ref> [1, 12, 14, 19, 26] </ref>, as well as for "ranking" www pages [5, 22, 23, 17]. Link structures have been studied in hypertext research that predates the www; in particular, Botafogo et al. [4] introduce graph-theoretic measures based on link density and node-to-node distances for clustering and searching in hypermedia.
Reference: [2] <author> M. Q Wang Baldonado, T. Winograd, "SenseMaker: </author> <title> An information-exploration interface supporting the contextual evaluation of a user's interests," </title> <booktitle> Proc. ACM SIGCHI Conference on Human Factors in Computing, </booktitle> <year> 1997. </year>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing <ref> [2, 4, 13, 24] </ref>, visualizing [7, 21] and searching [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] in hypermedia such as the www.
Reference: [3] <author> B. Bollobas, </author> <title> Random Graphs, </title> <publisher> Academic Press, </publisher> <year> 1985. </year>
Reference-contexts: We note that the emergence of regular structure in random networks is an active topic of research in combinatorics (see e.g. <ref> [3] </ref>), and we feel that it would be interesting to investigate such connections further in the context of hits and the www. 5 THE STRUCTURE OF COMMUNITIES We now detail our main findings on the structure of communities. Robustness.
Reference: [4] <author> R. Botafogo, E. Rivlin, B. Shneiderman, </author> <title> "Structural analysis of hypertext: Identifying hierarchies and useful metrics," </title> <journal> ACM Trans. Inf. Sys., </journal> <volume> 10(1992), </volume> <pages> pp. 142-180. 14 </pages>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing <ref> [2, 4, 13, 24] </ref>, visualizing [7, 21] and searching [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] in hypermedia such as the www. <p> Link structures have been studied in hypertext research that predates the www; in particular, Botafogo et al. <ref> [4] </ref> introduce graph-theoretic measures based on link density and node-to-node distances for clustering and searching in hypermedia.
Reference: [5] <author> J. Carriere, R. Kazman, "WebQuery: </author> <title> Searching and visualizing the Web through con-nectivity," </title> <booktitle> Proc. 6th International World Wide Web Conference, </booktitle> <year> 1997. </year>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing [2, 4, 13, 24], visualizing [7, 21] and searching <ref> [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] </ref> in hypermedia such as the www. <p> The use of link information to improve search performance on the www has been advanced in previous work; hyperlink analysis has been used for enhancing relevance judgments [1, 12, 14, 19, 26], as well as for "ranking" www pages <ref> [5, 22, 23, 17] </ref>. Link structures have been studied in hypertext research that predates the www; in particular, Botafogo et al. [4] introduce graph-theoretic measures based on link density and node-to-node distances for clustering and searching in hypermedia.
Reference: [6] <author> S. Chakrabarti, B. Dom, D. Gibson, J. Kleinberg, P. Raghavan, S. Rajagopalan. </author> <title> "Automatic resource list compilation by analyzing hyperlink structure and associated text." </title> <booktitle> Proc. 7th International World Wide Web Conference, </booktitle> <year> 1998. </year>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing [2, 4, 13, 24], visualizing [7, 21] and searching <ref> [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] </ref> in hypermedia such as the www. <p> We are currently investigating ways of using hits to improve performance on information retrieval tasks by combining text and the structure of hyperlinks; for work in this direction, see <ref> [6] </ref>.
Reference: [7] <author> C. Chen. </author> <title> Structuring and visualizing the WWW by generalised similarity analysis. </title> <booktitle> Proc. 8th ACM Conference on Hypertext, </booktitle> <pages> 177-186, </pages> <year> 1997. </year>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing [2, 4, 13, 24], visualizing <ref> [7, 21] </ref> and searching [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] in hypermedia such as the www.
Reference: [8] <author> S. Deerwester, S. Dumais, T. Landauer, G. Furnas, R. Harshman, </author> <title> "Indexing by latent semantic analysis," </title> <journal> J. American Soc. Info. Sci., </journal> <volume> 41(1990). </volume>
Reference-contexts: The method underlying hits is technically distinct from that of [10] (it does not partition the "Web graph"), though the heuristic intuition underlying both is clearly quite similar. For non-hyperlinked corpora, an information retrieval technique known as latent semantic indexing <ref> [8] </ref> makes use of the singular vectors of a matrix derived from the inverted index of the corpus. hits, on the 5 other hand, is operating purely on the link structure of a hyperlinked corpus, and makes no use of matrices with term weights.
Reference: [9] <institution> Digital Equipment Corporation, AltaVista search engine, altavista.digital.com/. </institution>
Reference-contexts: Starting from a user-supplied query, hits assembles a root set S of pages: typically, up 3 to 200 pages returned by a search engine such as AltaVista <ref> [9] </ref> on that query. <p> We have explored this by several direct methods, providing hits with a variety of different root sets relevant to the same topic. For example, we issue the same query string to multiple search engines (e.g. AltaVista <ref> [9] </ref>, Infoseek [16], and Excite [11]); this typically produces root sets with very little intersection. Similarly, one can obtain root sets that are nearly disjoint by issuing a query term in several different languages (e.g., "astrophysics" vs "astrophysik" vs "astrophysique").
Reference: [10] <author> W.E. Donath, A.J. Hoffman, </author> <title> "Algorithms for partitioning of graphs and computer logic based on eigenvectors of connections matrices," </title> <journal> IBM Technical Disclosure Bulletin, </journal> <volume> 15(1972). </volume>
Reference-contexts: in the base set because a query term has several meanings in different contexts; for example, the topic "geometry" produces communities on computational geometry, differential geometry, and seismic geometry. 3 RELATED WORK The use of eigenvectors for the purposes of partitioning a graph was introduced by Donath and Hoffman in <ref> [10] </ref> and has been studied extensively since. The method underlying hits is technically distinct from that of [10] (it does not partition the "Web graph"), though the heuristic intuition underlying both is clearly quite similar. <p> topic "geometry" produces communities on computational geometry, differential geometry, and seismic geometry. 3 RELATED WORK The use of eigenvectors for the purposes of partitioning a graph was introduced by Donath and Hoffman in <ref> [10] </ref> and has been studied extensively since. The method underlying hits is technically distinct from that of [10] (it does not partition the "Web graph"), though the heuristic intuition underlying both is clearly quite similar.
Reference: [11] <author> Excite Inc., Excite, </author> <note> www.excite.com. </note>
Reference-contexts: We have explored this by several direct methods, providing hits with a variety of different root sets relevant to the same topic. For example, we issue the same query string to multiple search engines (e.g. AltaVista [9], Infoseek [16], and Excite <ref> [11] </ref>); this typically produces root sets with very little intersection. Similarly, one can obtain root sets that are nearly disjoint by issuing a query term in several different languages (e.g., "astrophysics" vs "astrophysik" vs "astrophysique").
Reference: [12] <author> M.E. Frisse, </author> <title> "Searching for information in a hypertext medical handbook," </title> <journal> Communications of the ACM, </journal> <volume> 31(7), </volume> <pages> pp. 880-886. </pages>
Reference-contexts: The use of link information to improve search performance on the www has been advanced in previous work; hyperlink analysis has been used for enhancing relevance judgments <ref> [1, 12, 14, 19, 26] </ref>, as well as for "ranking" www pages [5, 22, 23, 17]. Link structures have been studied in hypertext research that predates the www; in particular, Botafogo et al. [4] introduce graph-theoretic measures based on link density and node-to-node distances for clustering and searching in hypermedia.
Reference: [13] <author> R. Furuta, F. M. Shipman III, C. C. Marshall, D. Brenner and H-W. Hsieh. </author> <title> Hypertext paths and the world-wide web: experiences with Walden's paths. </title> <booktitle> Proc. 8th ACM Conference on Hypertext, </booktitle> <pages> 167-176, </pages> <year> 1997. </year>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing <ref> [2, 4, 13, 24] </ref>, visualizing [7, 21] and searching [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] in hypermedia such as the www.
Reference: [14] <author> G. Golovchinsky. </author> <title> What the query told the link: the integration of Hypertext and Information Retrieval. </title> <booktitle> Proc. 8th ACM Conference on Hypertext, </booktitle> <pages> 67-74, </pages> <year> 1997. </year>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing [2, 4, 13, 24], visualizing [7, 21] and searching <ref> [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] </ref> in hypermedia such as the www. <p> The use of link information to improve search performance on the www has been advanced in previous work; hyperlink analysis has been used for enhancing relevance judgments <ref> [1, 12, 14, 19, 26] </ref>, as well as for "ranking" www pages [5, 22, 23, 17]. Link structures have been studied in hypertext research that predates the www; in particular, Botafogo et al. [4] introduce graph-theoretic measures based on link density and node-to-node distances for clustering and searching in hypermedia.
Reference: [15] <author> G. Golub, C.F. Van Loan, </author> <title> Matrix Computations, </title> <publisher> Johns Hopkins University Press, </publisher> <year> 1989. </year>
Reference: [16] <author> Infoseek Corporation, </author> <title> Infoseek search engine, </title> <address> www.infoseek.com. </address>
Reference-contexts: We have explored this by several direct methods, providing hits with a variety of different root sets relevant to the same topic. For example, we issue the same query string to multiple search engines (e.g. AltaVista [9], Infoseek <ref> [16] </ref>, and Excite [11]); this typically produces root sets with very little intersection. Similarly, one can obtain root sets that are nearly disjoint by issuing a query term in several different languages (e.g., "astrophysics" vs "astrophysik" vs "astrophysique").
Reference: [17] <author> J. Kleinberg, </author> <title> "Authoritative sources in a hyperlinked environment," </title> <booktitle> Proc. ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1998. </year> <note> Also appears as IBM Research Report RJ 10076(91892) May 1997, and at www.cs.cornell.edu/home/kleinber/. </note>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing [2, 4, 13, 24], visualizing [7, 21] and searching <ref> [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] </ref> in hypermedia such as the www. <p> Our study is based on experience with a hyperlink-oriented method for searching introduced by Kleinberg in <ref> [17] </ref>, and with hits (Hyperlink-Induced Topic Search), an experimental system built around this technique. The underlying technique is discussed in detail in [17]. Here we invoke this technique, developing it for our study of communities on the Web. <p> Our study is based on experience with a hyperlink-oriented method for searching introduced by Kleinberg in <ref> [17] </ref>, and with hits (Hyperlink-Induced Topic Search), an experimental system built around this technique. The underlying technique is discussed in detail in [17]. Here we invoke this technique, developing it for our study of communities on the Web. We begin with a brief summary (in the following section) of the main concepts from [17] that are necessary for understanding our study. <p> The underlying technique is discussed in detail in <ref> [17] </ref>. Here we invoke this technique, developing it for our study of communities on the Web. We begin with a brief summary (in the following section) of the main concepts from [17] that are necessary for understanding our study. <p> The interesting question arising in this context is: how can one determine, without human intervention, that www.harvard.edu is indeed a page that should be considered authoritative for the topic "Harvard"? The technique underlying hits stems from two premises <ref> [17] </ref>: first, that the implicit annotation provided by human creators of hyperlinks contains sufficient information to infer a notion of "authority"; and second, building on this, that sufficiently broad topics contain embedded communities of hyperlinked pages. <p> hits shows that such communities of hubs and authorities are a recurring consequence of the way in which creators of pages on the www link to one another in the context of topics of widespread interest. 2 OVERVIEW OF HITS We begin with a summary of the main concepts from <ref> [17] </ref> that are necessary for understanding the present work. 1. Starting from a user-supplied query, hits assembles a root set S of pages: typically, up 3 to 200 pages returned by a search engine such as AltaVista [9] on that query. <p> The updating operations are performed for all the pages, and the process is repeated (normalizing the weights after each iteration). It can be proved that this iterative process converges to stable sets of authority and hub weights <ref> [17] </ref>. <p> communities to have a size that is "manageable" for human users.) In fact it can be proved that the equilibrium values of the hub weights and authority weights correspond to coordinates in the principal eigenvectors of a pair of matrices M hub and M auth derived from the link structure <ref> [17] </ref>. Note that the method is extremely simple and mathematically clean: one can analyze its convergence properties in a rigorous fashion, and the only tunable parameter is the procedure for fixing the root set. <p> Many other examples of a similar nature, for a range of topics, can be found in <ref> [17] </ref>. Note the crucial fact that the textual content of the pages involved is only considered in the initial step, when a root set is assembled from a search engine. <p> In general, of course, the base set contains not only this densest community but a large number of other meaningful communities as well <ref> [17] </ref>. For example, hits also identifies, in the base set for the topic "Harvard", a large community of pages on bio-medical topics, drawn into the base set because of the strong linkage between these pages and the many biological and medical labs associated with Harvard. <p> It turns out that the first few non-principal eigenvectors of M hub and M auth have the same intuitive meaning as the principal eigenvector: they represent pairs of weight assignments exhibiting the mutually reinforcing relationship of hubs and authorities <ref> [17] </ref>. Thus, by computing several of the non-principal eigenvectors of M hub and M auth , hits can discover additional communities within the same base set of linked pages. <p> The use of link information to improve search performance on the www has been advanced in previous work; hyperlink analysis has been used for enhancing relevance judgments [1, 12, 14, 19, 26], as well as for "ranking" www pages <ref> [5, 22, 23, 17] </ref>. Link structures have been studied in hypertext research that predates the www; in particular, Botafogo et al. [4] introduce graph-theoretic measures based on link density and node-to-node distances for clustering and searching in hypermedia. <p> Their notions of index and reference nodes bear a relation to the notions of hubs and authorities used here; however, they are based purely on the out- and in-degrees of individual documents in the hyperlinked environment. (See <ref> [17] </ref> for a discussion of some of the difficulties in applying pure degree-counting methods to a domain on the scale of the www.) The field of bibliometrics studies the patterns of citation | an implicit type of "linkage" | among scientific papers. See [27] for a review. <p> This type of dissection can also be an effective way to separate out the "Web-centric" influences on a topic. An example from <ref> [17] </ref> shows this very cleanly: starting from a root set of pages in the 2-step vicinity of www.nytimes.com, the principal authorities consist of a mixture of on-line news organizations and popular Internet sites.
Reference: [18] <author> R. Larson, </author> <title> "Bibliometrics of the World Wide Web: An exploratory analysis of the intellectual structure of cyberspace," </title> <journal> Ann. Meeting of the American Soc. Info. Sci., </journal> <year> 1996. </year>
Reference-contexts: See [27] for a review. A number of their measures have meaning in the context of hypermedia; some of these connections are studied in <ref> [18] </ref>. One can also interpret the behavior of hits as relying on a type of community memory, as studied by Marshall et al. [20].
Reference: [19] <author> M. Marchiori, </author> <title> "The quest for correct information on the Web: Hyper search engines," </title> <booktitle> Proc. 6th International World Wide Web Conference, </booktitle> <year> 1997. </year>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing [2, 4, 13, 24], visualizing [7, 21] and searching <ref> [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] </ref> in hypermedia such as the www. <p> The use of link information to improve search performance on the www has been advanced in previous work; hyperlink analysis has been used for enhancing relevance judgments <ref> [1, 12, 14, 19, 26] </ref>, as well as for "ranking" www pages [5, 22, 23, 17]. Link structures have been studied in hypertext research that predates the www; in particular, Botafogo et al. [4] introduce graph-theoretic measures based on link density and node-to-node distances for clustering and searching in hypermedia.
Reference: [20] <author> C. C. Marshall, F. M. Shipman III, R. J. McCall, </author> <title> "Putting Digital Libraries to Work: Issues from Experience with Community Memories", </title> <booktitle> Proc. First Annual Conference on the Theory and Practice of Digital Libraries, </booktitle> <year> 1994. </year>
Reference-contexts: See [27] for a review. A number of their measures have meaning in the context of hypermedia; some of these connections are studied in [18]. One can also interpret the behavior of hits as relying on a type of community memory, as studied by Marshall et al. <ref> [20] </ref>.
Reference: [21] <author> S. Mukherjea and Y. Hara. </author> <title> Focus+Context Views of World-Wide Web Nodes. </title> <booktitle> Proc. 8th ACM Conference on Hypertext, </booktitle> <pages> 187-196, </pages> <year> 1997. </year>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing [2, 4, 13, 24], visualizing <ref> [7, 21] </ref> and searching [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] in hypermedia such as the www.
Reference: [22] <author> L. Page, "PageRank: </author> <title> Bringing order to the Web," Stanford Digital Libraries working paper 1997-0072. </title>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing [2, 4, 13, 24], visualizing [7, 21] and searching <ref> [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] </ref> in hypermedia such as the www. <p> The use of link information to improve search performance on the www has been advanced in previous work; hyperlink analysis has been used for enhancing relevance judgments [1, 12, 14, 19, 26], as well as for "ranking" www pages <ref> [5, 22, 23, 17] </ref>. Link structures have been studied in hypertext research that predates the www; in particular, Botafogo et al. [4] introduce graph-theoretic measures based on link density and node-to-node distances for clustering and searching in hypermedia.
Reference: [23] <author> L. Page, S. Brin, R. Motwani, T. Winograd, </author> <title> "The PageRank citation ranking: Bringing order to the Web," </title> <note> submitted for publication. </note>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing [2, 4, 13, 24], visualizing [7, 21] and searching <ref> [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] </ref> in hypermedia such as the www. <p> The use of link information to improve search performance on the www has been advanced in previous work; hyperlink analysis has been used for enhancing relevance judgments [1, 12, 14, 19, 26], as well as for "ranking" www pages <ref> [5, 22, 23, 17] </ref>. Link structures have been studied in hypertext research that predates the www; in particular, Botafogo et al. [4] introduce graph-theoretic measures based on link density and node-to-node distances for clustering and searching in hypermedia.
Reference: [24] <author> P. Pirolli, J. Pitkow, R. Rao, </author> <title> "Silk from a sow's ear: Extracting usable structures from 15 the Web," </title> <booktitle> Proc. ACM SIGCHI Conference on Human Factors in Computing, </booktitle> <year> 1996. </year>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing <ref> [2, 4, 13, 24] </ref>, visualizing [7, 21] and searching [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] in hypermedia such as the www.
Reference: [25] <author> E. Spertus, "ParaSite: </author> <title> Mining structural information on the Web," </title> <booktitle> Proc. 6th International World Wide Web Conference, </booktitle> <year> 1997. </year>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing [2, 4, 13, 24], visualizing [7, 21] and searching <ref> [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] </ref> in hypermedia such as the www.
Reference: [26] <author> R. Weiss, B. Velez, M. Sheldon, C. Nemprempre, P. Szilagyi, D.K. Gifford, </author> <month> "HyPursuit: </month>
Reference-contexts: There has been a growing amount of work directed at the integration of textual content and link information for the purpose of organizing [2, 4, 13, 24], visualizing [7, 21] and searching <ref> [1, 5, 6, 14, 17, 19, 22, 23, 25, 26] </ref> in hypermedia such as the www. <p> The use of link information to improve search performance on the www has been advanced in previous work; hyperlink analysis has been used for enhancing relevance judgments <ref> [1, 12, 14, 19, 26] </ref>, as well as for "ranking" www pages [5, 22, 23, 17]. Link structures have been studied in hypertext research that predates the www; in particular, Botafogo et al. [4] introduce graph-theoretic measures based on link density and node-to-node distances for clustering and searching in hypermedia.
References-found: 26

