URL: ftp://ftp.cs.bham.ac.uk/pub/tech-reports/1996/CSRP-96-17.ps.gz
Refering-URL: http://netq.rowland.org/sw/kovacs.html
Root-URL: 
Title: Evolving Optimal Populations with XCS Classifier Systems  
Author: Tim Kovacs 
Date: October 3, 1996  
Abstract-found: 0
Intro-found: 1
Reference: <author> Anderson, C. W., </author> <year> (1986). </year> <title> Learning and Problem Solving with Multilayer Connectionist Systems. </title> <type> Ph.D. Dissertation, </type> <institution> Computer and Information Science, Univ. of Massachusetts. </institution>
Reference-contexts: Further, they are useful as a common measure of performance for different systems as they have been used with a variety of systems including neural networks <ref> (Anderson 1986) </ref>, simple GAs (Goldberg, 1989), messy GAs (Skurikhin & Surkan), niche GAs (Booker 1989), perceptrons (Wilson 1990) and the BOOLE system (Wilson, 1987). All the experiments reported in this work were on forms of multiplexer problem.
Reference: <author> Booker, L. B., </author> <year> (1989). </year> <title> Triggered rule discovery in classifier systems, </title> <booktitle> in: Proc. Third International Conference on Genetic Algorithms, </booktitle> <editor> J. D. Schaffer, (ed.), </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: Further, they are useful as a common measure of performance for different systems as they have been used with a variety of systems including neural networks (Anderson 1986), simple GAs (Goldberg, 1989), messy GAs (Skurikhin & Surkan), niche GAs <ref> (Booker 1989) </ref>, perceptrons (Wilson 1990) and the BOOLE system (Wilson, 1987). All the experiments reported in this work were on forms of multiplexer problem.
Reference: <author> Cliff, D., & Ross, S., </author> <year> (1995). </year> <title> Adding Temporary Memory to ZCS. Adaptive Behavior, </title> <type> 3(2), 101-150. </type> <institution> Also University of Sussex School of Cognitive and Computing Sciences Technical Report CSRP 347, </institution> <month> February </month> <year> 1995. </year>
Reference: <author> Dorigo, M., & Bersini, H., </author> <year> (1994). </year> <title> A comparison of Q-learning and classifier systems. </title> <editor> In D. Cliff, P. Husbands, J.-A. Meyer, and S. W. Wilson (eds.), </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third Conference on Simulation of Adaptive Behavior (pp. </booktitle> <pages> 248-255). </pages> <address> Cambridge, MA: </address> <publisher> MIT Press/Bradford Books. </publisher>
Reference-contexts: Q-Learning and CS have traditionally been considered different approaches to reinforcement learning, possibly because of their different origins. However, the similarities between the two have recently been pointed out by a number of researchers <ref> (see Dorigo & Bersini 1994) </ref>. <p> No complementary guidance is provided for helping the exploration/exploitation of the problem space, and therefore the agent can rely only on a trial-and-error strategy." <ref> (Dorigo & Bersini 1994) </ref> ZCS and XCS are forms of CS in which the traditional bucket-brigade has been replaced with a system resembling Q-Learning, drawing the fields of Q-Learning and CS research closer together. Each field can gain from insights provided by the other. <p> As will be discussed, CS research can benefit from the Q-Learning approach of constructing complete mappings of the environment. In addition, it has been shown that in certain environments Q-Learning converges to an optimal policy (Watkins & Dayan 1992) and that a restricted form of CS does as well <ref> (Dorigo & Bersini 1994) </ref>. In return, Q-Learning can benefit from existing CS work on the uses of internal state, structural change, and generalization (effected in CS by the use of the don't care symbol #). These are all areas of recent work in Q-Learning.
Reference: <author> Goldberg, D. E., </author> <year> (1989). </year> <title> Genetic algorithms in search optimisation and machine learning. </title> <address> Reading, MA. </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Further, they are useful as a common measure of performance for different systems as they have been used with a variety of systems including neural networks (Anderson 1986), simple GAs <ref> (Goldberg, 1989) </ref>, messy GAs (Skurikhin & Surkan), niche GAs (Booker 1989), perceptrons (Wilson 1990) and the BOOLE system (Wilson, 1987). All the experiments reported in this work were on forms of multiplexer problem.
Reference: <author> Hayes, W., L., </author> <year> (1988). </year> <title> Statistics. 4 th Edition. Forth Worth: </title> <publisher> Harcourt Brace Jovanovich. </publisher>
Reference-contexts: Problems where input strings occur equiprobably, as in the boolean multiplexer experiments, satisfy this in the long run. 17 17 "In the long run" is a reference to Bernoulli's Theorem. <ref> (Hayes 1988) </ref> offers this "more or less precise statement" of the theorem: "If the probability of occurrence of the event X is p (X), and if N trials are made, independently and under exactly the same conditions, then the probability that the relative frequency of occurrence of X differs from p <p> Nonetheless, we cannot expect a system to construct mappings of regions of the payoff environment it never encounters (not when it learns solely on the basis of a scalar reward for actions by any amount, however small, approaches zero as the number of trials grows indefinitely large." <ref> (Hayes 1988) </ref> For practical purposes it may be a matter of establishing confidence limits for the evolution of a maximally general classifier by a certain number of cycles. 18 Saying that [O] is accurate means each classifier in [O] meets the accuracy criterion " o .
Reference: <author> Holland, J. J., </author> <year> (1975). </year> <booktitle> Adaptation in natural and artificial systems. </booktitle> <address> Ann Arbor, </address> <publisher> University of Michigan Press. </publisher>
Reference-contexts: This project can be seen as an examination of some of the uses of self-monitoring in a particular form of adaptive system, the classifier system. 3 Traditional Classifier Systems 3.1 A Brief Overview Classifier systems are a form of adaptive system introduced by John Holland in the mid-1970's <ref> (Holland 1975, see also Holland 1986) </ref> as a form of domain-independent learning system. The term "traditional" will be used to refer to those systems closely related to Holland's original system, primarily in order to distinguish them from the more recent XCS classifier system. <p> This has the effect of allocating resources (GA invocations) approximately equally to the different match sets. A number of other researchers have incorporated accuracy information in their classifier systems (for an overview see (Wilson 1995)). Indeed, Holland, in the original paper on classifier systems <ref> (Holland 1975) </ref>, suggested that accuracy information be incorporated in calculating classifier fitness, but he later focused on payoff based fitness. Unlike other systems, XCS has completely shifted to accuracy based fitness.
Reference: <author> Holland, J. H., </author> <year> (1976). </year> <title> Adaptation. </title> <editor> In R. Rosen & F. M. Snell (Eds.), </editor> <booktitle> Progress in theoretical biology, 4. </booktitle> <address> New York: </address> <publisher> Plenum. </publisher>
Reference: <author> Holland, J. H., </author> <year> (1986). </year> <title> Escaping brittleness: the possibilities of general-purpose learning algorithms applied to parallel rule-based systems. </title> <editor> In R. S. Michalski, J. G. Carbonell & T. M. Mitchell (Eds.), </editor> <booktitle> Machine learning, an artificial intelligence approach. Volume II. </booktitle> <address> Los Altos, California: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Kaelbling, L., Littman, M., & Moore, A., </author> <year> (1995). </year> <title> Reinforcement Learning: A Survey. </title> <booktitle> Practice and Future of Autonomous Agents Vol 1. Centro Stefano Franscini, </booktitle> <address> Monte Veita, Ticino, Switzerland. </address>
Reference-contexts: Otherwise, the limitations on the descriptive power of single conditions discussed in 5.3 may complicate matters. 29 It should be noted that various means of introducing generalizations into Q-Learning based systems have been investigated <ref> (see the survey of Kaelbling, Littman & Moore 1995) </ref>. 30 Although modified versions, as mentioned in 5.1, may be. 40 payoff landscape and reduce the number of concepts (classifiers) it employs.
Reference: <author> Minsky, M., </author> <year> (1987). </year> <title> The Society of Mind. </title> <publisher> Picador. </publisher>
Reference: <author> Riolo, R. L., </author> <year> (1988). </year> <title> CFS-C: A package of domain independent subroutines for implementing classifier systems in arbitrary, user-defined environments. Logic of Computers Group, </title> <institution> Division of Computer Science and Engineering. University of Michigan. </institution>
Reference-contexts: Single and multi step problems are explained in section 4. More complex forms of environmental feedback (e.g. supervised learning) are beyond the scope of this discussion. 6 Much of this section was drawn from (Wright 1995) with permission. Wright's work was based on <ref> (Riolo 1988) </ref>. 8 3.5 Some Forms of Self-Monitoring in Classifier Systems There are many ways in which a classifier system may make use of internal state to improve its operation in some respect.
Reference: <author> Riolo, R. L., </author> <year> (1989). </year> <title> The emergence of coupled sequences of classifiers. </title> <editor> In J. D. Schaffer (Ed.), </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> (pp. 256-264). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This has the potential to form adaptive chains of behaviour, although useful coupling of classifiers appears to be difficult to achieve and maintain in the traditional system <ref> (Riolo 1989) </ref>. The current work revolves around an even more fundamental form of self-monitoring in the classifier system, that of credit-assignment to classifiers in response to environmental reward. Many credit-assignment schemes have been implemented to date (e.g. the bucket-brigade, ZCS's "implicit bucket-brigade", tabular Q-Learning) using a variety of mechanisms.
Reference: <author> Skurikhin, A. N., & Surkan, A. J. </author> <title> Messy Genetic Algorithm Learns Classifier for Multiplexer Design. Email: </title> <note> alexei@tarzan.cr.cyco.com, </note> <author> surkan@cse.unl.edu Sloman, A., & Humphreys, G. </author> <year> (1992). </year> <title> The Attention and Affect Project. Appendix to JCI proposal. </title>
Reference: <author> Sloman, A. </author> <year> (1993). </year> <title> The Mind as a Control System, </title> <booktitle> in Philosophy and the Cognitive Sciences, </booktitle> <editor> (eds) C. Hookway and D. Peterson, </editor> <publisher> Cambridge University Press, </publisher> <pages> pp 69-110, </pages> <year> 1993. </year>
Reference-contexts: One way to compare these diverse systems is to conceptualise their architectures within a design space of functional systems. 2 Architecture dominates mechanism <ref> (Sloman 1993) </ref> sums up the view that architectures have a greater influence on the capacities of the system than the mechanisms it consists of. Designs map into a niche space of requirements, and understanding a design involves understanding how it maps into niche space.
Reference: <author> Sloman, A. </author> <year> (1994). </year> <title> Explorations in Design Space, </title> <booktitle> in Proceedings ECAI, </booktitle> <month> August </month> <year> 1994. </year>
Reference: <author> Sloman, A. </author> <year> (1995). </year> <title> Exploring design space and niche space. </title> <booktitle> Invited talk for 5th Scandinavian Conference on AI, </booktitle> <address> Trondheim, </address> <month> May </month> <year> 1995. </year> <booktitle> In Proceedings 5th Scandinavian Conference on AI, </booktitle> <publisher> IOS Press, Amsterdam. </publisher>
Reference: <author> Sloman, A. </author> <year> (1996). </year> <title> What sort of control system is able to have a personality? To appear in Proceedings Workshop on Designing personalities for synthetic actors. </title> <address> Vienna, </address> <month> June </month> <year> 1995. </year> <note> Robert Trappl (Ed). </note>
Reference: <author> Venturini, G., </author> <year> (1994). </year> <institution> Apprentissage Adaptatif et Apprentissage Supervise par Algorithme Genetique. These de Docteur en Science (Informatique), Universite de Paris-Sud. </institution>
Reference-contexts: The parameter list in section 10 reflects this. Some of Wilson's newer (post-(Wilson 1996a)) developments in the XCS architecture are included in this overview and hopefully some aspects of the system will be clarified. 5.5.1 The MAM Technique The MAM technique ("moyenne adaptive modifiee") was introduced in <ref> (Venturini 1994) </ref> as a means of speeding up the estimation of various classifier parameters based on information obtained on successive cycles. Using this technique, a parameter is updated using one method early on and a second method later.
Reference: <author> Watkins, C. </author> <year> (1989). </year> <title> Learning from Delayed Rewards. </title> <type> Ph.D. Dissertation, </type> <institution> Cambridge University. </institution>
Reference: <author> Watkins, C., & Dayan, P., </author> <year> (1992). </year> <title> Technical note: </title> <journal> Q-Learning. Machine Learning, </journal> <volume> 8, </volume> <pages> 279-292. </pages>
Reference-contexts: Each field can gain from insights provided by the other. As will be discussed, CS research can benefit from the Q-Learning approach of constructing complete mappings of the environment. In addition, it has been shown that in certain environments Q-Learning converges to an optimal policy <ref> (Watkins & Dayan 1992) </ref> and that a restricted form of CS does as well (Dorigo & Bersini 1994). In return, Q-Learning can benefit from existing CS work on the uses of internal state, structural change, and generalization (effected in CS by the use of the don't care symbol #).
Reference: <author> Wilson, S., </author> <year> (1987). </year> <title> Classifier systems and the animat problem. </title> <booktitle> Machine Learning 2, </booktitle> <pages> 199-228. </pages>
Reference-contexts: Further, they are useful as a common measure of performance for different systems as they have been used with a variety of systems including neural networks (Anderson 1986), simple GAs (Goldberg, 1989), messy GAs (Skurikhin & Surkan), niche GAs (Booker 1989), perceptrons (Wilson 1990) and the BOOLE system <ref> (Wilson, 1987) </ref>. All the experiments reported in this work were on forms of multiplexer problem. Multiplexer functions exist for strings of length L = k + 2 k with k &gt; 0, a series that begins f3, 6, 11, 20, 37 . . . g.
Reference: <author> Wilson, S., </author> <year> (1990). </year> <title> Perceptron Redux: Emergence of Structure. </title> <journal> Physica D, </journal> <pages> 42(1-3), 249-256. </pages> <note> Republished in Emergent Computation, </note> <editor> S. Forrest (ed.), </editor> <publisher> MIT Press/Bradford Books. </publisher>
Reference-contexts: Further, they are useful as a common measure of performance for different systems as they have been used with a variety of systems including neural networks (Anderson 1986), simple GAs (Goldberg, 1989), messy GAs (Skurikhin & Surkan), niche GAs (Booker 1989), perceptrons <ref> (Wilson 1990) </ref> and the BOOLE system (Wilson, 1987). All the experiments reported in this work were on forms of multiplexer problem.
Reference: <author> Wilson, S., </author> <year> (1994). </year> <title> ZCS: A zeroth level classifier system. </title> <journal> Evolutionary Computation, </journal> <volume> 2(1), </volume> <pages> 1-18. </pages> <note> 44 Wilson, </note> <author> S., </author> <year> (1995). </year> <title> Classifier Fitness Based on Accuracy. </title> <journal> Evolutionary Computation. </journal> <volume> Vol. 3, No. 2. </volume> <editor> 1995 Wilson, S., </editor> <year> (1996a). </year> <title> Generalization in XCS. </title> <booktitle> Submitted to ICML '96 Workshop on Evolutionary Computing and Machine Learning. </booktitle>
Reference-contexts: In addition, there are many more subtle differences between traditional classifier systems and XCS systems as the reader will discover later in this section. XCS has many features in common with Wilson's earlier ZCS work <ref> (Wilson 1994) </ref>. 11 Classifier systems have traditionally based fitness on classifier strength (i.e. a predictor of the payoff to be received if the classifier's action is taken).
Reference: <author> Wilson, S., </author> <year> (1996b). </year> <title> Explore/Exploit Strategies in Autonomy. To be published in From Animals to Animats 4: </title> <booktitle> Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior. </booktitle> <editor> P. Maes, M. Mataric, J. Pollack, J.-A. Meyer, and S. Wilson (eds.), </editor> <address> Cambridge, MA: </address> <publisher> The MIT Press/Bradford Books. </publisher>
Reference-contexts: In effect, for parents "known" to be accurate, the GA is constrained to generate and evaluate only offspring that are more general than the parents." <ref> (Wilson 1996b) </ref> The use of subsumption deletion is effective in reducing the population size of the system (see 6.1.2 for evaluation). 5.5.8 Explore vs. Exploit Behaviour Learning systems can engage in two forms of activity: exploration and exploitation. <p> On exploit cycles, action selection was deterministic (the action with the highest advocacy was chosen), but learning and rule discovery were disabled. Results were only recorded for the exploit cycles (as indicated on the graphs). 16 <ref> (Wilson 1996b) </ref> discusses various means of addressing this dilemma. 19 5.6 Wilson's Generalization Hypothesis It appears that the interaction of accuracy based fitness and a niche GA results in evolutionary pressure to generate classifiers that are both accurate and maximally general (as general as possible while remaining within some accuracy criterion). <p> As threshold levels for the plateaus seen in these statistics may vary from problem to problem, it would be better to make use of a rate of change statistic rather than using the value directly. For example, <ref> (Wilson 1996b) </ref> suggests using the rate of system error change to control allocation of explore/exploit cycles. 24 The system performance curve is not considered as suitable as those listed above as it does not appear to be sensitive to the evolution of [O] and apparently invariably reaches 1.0 before [O] is <p> Thus the figures shown here may be somewhat misleading in this respect. 24 This form of statistic has the added advantage of being suitable for stochastic environments with fixed probabilities, as the rate of change will be influenced only by the learning process <ref> (see Wilson 1996b) </ref>. 29 6.5 Dynamic Population Condensation Once a population has evolved a complete set of maximally general classifiers it would be advantageous to remove all other classifiers from the system, leaving it with an optimal population.
Reference: <author> Wilson, S., </author> <year> (1996c). </year> <type> Personal Communication. </type>
Reference-contexts: Action selection may occur in any of a number of ways. The chosen action is sent to the output interface and an environmental reward may be returned as a result. Wilson reports <ref> (Wilson 1996c) </ref> that he has begun to use a modified method of calculating the prediction array which is not mentioned in either of the XCS papers (Wilson 1995, 1996a). <p> For multi step problems, the previous cycle's action set [A] 1 is updated using the sum the of the previous cycle's reward and the discounted maximum of the prediction array. 14 P previous cycle 0 s reward + (fl fi max (P (a i ))) Wilson <ref> (Wilson 1996c) </ref> has experimented with the following parameter update order: 1. prediction error (with MAM) 2. prediction (with MAM) and 3. fitness (without MAM). (This is the order used in all work reported here.) This is a conservative order as the fitness begins at a low value and rises slowly.
Reference: <author> Wright, I., </author> <year> (1995). </year> <title> Draft of: Cognition and Currency Flow. Notes Toward a Circulation of Value Theory of Emotions. </title> <month> August </month> <year> 1995. </year>
Reference-contexts: Such a negative feedback control loop will tend to maintain the variable around the reference value equilibrium. A thermostat is a well-known example of this kind of system (temperature = environment variable, dial position = reference value, bi-metallic strip = comparator, turn heating on/off = effector signal)." <ref> (Wright 1995) </ref> Self-monitoring is a form of feedback in which the environmental variable is internal to the system, and includes cases where the variable is a statistic based on other variables. <p> Also, reward may be some scalar value rather than just a positive/negative signal. Single and multi step problems are explained in section 4. More complex forms of environmental feedback (e.g. supervised learning) are beyond the scope of this discussion. 6 Much of this section was drawn from <ref> (Wright 1995) </ref> with permission. Wright's work was based on (Riolo 1988). 8 3.5 Some Forms of Self-Monitoring in Classifier Systems There are many ways in which a classifier system may make use of internal state to improve its operation in some respect.
Reference: <author> Wright, I. P., </author> <year> (1996). </year> <title> Reinforcement Learning and Animat Emotions. To appear in From Animals to Animats 4: </title> <booktitle> Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior. </booktitle> <editor> P. Maes, M. Mataric, J. Pollack, J.-A. Meyer, and S. Wilson (eds.), </editor> <address> Cambridge, MA: The MIT Press/Bradford Books. </address> <note> A selection of Stewart Wilson's papers is also available at: http://netq.rowland.org/sw/swhp.html Useful questions and answers on XCS are available at: http://netq.rowland.ord/wilson/xcs/q.html 45 </note>
References-found: 28

