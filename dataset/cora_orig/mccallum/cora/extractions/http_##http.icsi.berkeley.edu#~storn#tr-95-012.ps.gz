URL: http://http.icsi.berkeley.edu/~storn/tr-95-012.ps.gz
Refering-URL: http://http.icsi.berkeley.edu/~storn/litera.html
Root-URL: http://http.icsi.berkeley.edu
Title: Differential Evolution A simple and efficient adaptive scheme for global optimization over continuous spaces  
Author: by Rainer Storn ) and Kenneth Price ) 
Note: On leave from Siemens AG, ZFE T SN 2, Otto-Hahn-Ring 6, D-81739  
Address: 1947 Center Street, Berkeley, CA 94704-1198, Suite 600,  Germany.  Vacaville, CA 95687,  
Affiliation: 1) International Computer Science Institute,  Muenchen,  Owl Circle,  
Pubnum: TR-95-012  
Email: Email: storn@icsi.berkeley.edu.  Email:rainer.storn@zfe.siemens.de.  kprice@solano.community.net.  
Phone: Fax: 510-643-7684.  Fax: 01149-636-44577,  2) 836  
Date: March 1995  
Abstract: A new heuristic approach for minimizing possibly nonlinear and non differentiable continuous space functions is presented. By means of an extensive testbed, which includes the De Jong functions, it will be demonstrated that the new method converges faster and with more certainty than Adaptive Simulated Annealing as well as the Annealed Nelder&Mead approach, both of which have a reputation for being very powerful. The new method requires few control variables, is robust, easy to use and lends itself very well to parallel computation. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Brayton, H., Hachtel, G. and Sangiovanni-Vincentelli, A., </author> <title> A Survey of Optimization Techniques for Integrated Circuit Design, </title> <booktitle> Proc. IEEE 69, </booktitle> <year> 1981, </year> <pages> pp. 1334 - 1362. </pages>
Reference-contexts: The standard approach to an optimization problem begins by designing an objective function that can model the problem's objectives while incorporating any constraints. Especially in the circuit design community, methods are in use which do not need an objective function <ref> [1] </ref>, [2], [3]. Although these methods can make formulating a problem simpler, they are usually inferior to techniques which make full use of an objective function. Consequently, we restrict ourselves to optimization methods which fully use the objective function. <p> For the objective function (7) and (10) this is true only if the region of realizability of x is convex <ref> [1] </ref>, [2], which in general does not apply in most technical problems. 3 The Method of Differential Evolution Differential Evolution (DE) is a novel parallel direct search method which utilizes NP parameter vectors x , i = 0, 1, 2, ... , NP-1. (11) as a population for each generation G.
Reference: 2. <author> Lueder, E., </author> <title> Optimization of Circuits with a Large Number of Parameters, </title> <editor> Archiv f. Elektr. u. Uebertr., </editor> <volume> Band 44, Heft 2, </volume> <year> 1990, </year> <pages> pp 131 - 138. </pages>
Reference-contexts: The standard approach to an optimization problem begins by designing an objective function that can model the problem's objectives while incorporating any constraints. Especially in the circuit design community, methods are in use which do not need an objective function [1], <ref> [2] </ref>, [3]. Although these methods can make formulating a problem simpler, they are usually inferior to techniques which make full use of an objective function. Consequently, we restrict ourselves to optimization methods which fully use the objective function. <p> All functions f m (x) can be combined into a single objective function z (x) <ref> [2] </ref>, [12], which usually is computed either via the weighted sum z x w f x m ( ) ( ) = + - 1 or via z x w f x ( ) max ( ) = (8) with w m &gt; 0. (9) The weighting factors w m are <p> The optimization task can now be restated as min z (x) (10) The min-max formulation (8) and (10) guarantees that all local minima, the Pareto critical points, including the possibly multiple global minima, the Pareto points, can at least theoretically be found <ref> [2] </ref>, [12]. For the objective function (7) and (10) this is true only if the region of realizability of x is convex [1], [2], which in general does not apply in most technical problems. 3 The Method of Differential Evolution Differential Evolution (DE) is a novel parallel direct search method which <p> (8) and (10) guarantees that all local minima, the Pareto critical points, including the possibly multiple global minima, the Pareto points, can at least theoretically be found <ref> [2] </ref>, [12]. For the objective function (7) and (10) this is true only if the region of realizability of x is convex [1], [2], which in general does not apply in most technical problems. 3 The Method of Differential Evolution Differential Evolution (DE) is a novel parallel direct search method which utilizes NP parameter vectors x , i = 0, 1, 2, ... , NP-1. (11) as a population for each generation G.
Reference: 3. <author> Storn, R., </author> <title> Contrained Optimization, </title> <journal> Dr. Dobbs Journal, </journal> <month> May </month> <year> 1995, </year> <pages> pp. 119 - 123. </pages>
Reference-contexts: The standard approach to an optimization problem begins by designing an objective function that can model the problem's objectives while incorporating any constraints. Especially in the circuit design community, methods are in use which do not need an objective function [1], [2], <ref> [3] </ref>. Although these methods can make formulating a problem simpler, they are usually inferior to techniques which make full use of an objective function. Consequently, we restrict ourselves to optimization methods which fully use the objective function. <p> We will compare both ANM and ASA to DE1 and DE2. During our research we also wrote an annealed version of the Hooke&Jeeves method [5] and tested two Monte Carlo methods <ref> [3] </ref> one of which used NP parallel vectors and the differential mutation scheme of DE. Although these approaches all worked, they quickly turned out not to be competitive.
Reference: 4. <author> Bunday, </author> <title> B.D. and Garside G.R., Optimisation Methods in Pascal, </title> <publisher> Edward Arnold Publ., </publisher> <year> 1987. </year>
Reference-contexts: To this end, we will limit our investigation in the following to minimization problems. When the objective function is nonlinear and non differentiable, direct search approaches are the methods of choice. The best known of these are the algorithms by Nelder&Mead <ref> [4] </ref>, by Hooke&Jeeves [4], genetic algorithms [5], and evolutionary algorithms [6], [7] with the latter being truly continuous counterparts of genetic algorithms. At the heart of every direct search method is a strategy that generates variations of the parameter vectors. <p> To this end, we will limit our investigation in the following to minimization problems. When the objective function is nonlinear and non differentiable, direct search approaches are the methods of choice. The best known of these are the algorithms by Nelder&Mead <ref> [4] </ref>, by Hooke&Jeeves [4], genetic algorithms [5], and evolutionary algorithms [6], [7] with the latter being truly continuous counterparts of genetic algorithms. At the heart of every direct search method is a strategy that generates variations of the parameter vectors.
Reference: 5. <author> Goldberg, D.E., </author> <title> Genetic Algorithms in Search, Optimization & Machine Learning, </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: To this end, we will limit our investigation in the following to minimization problems. When the objective function is nonlinear and non differentiable, direct search approaches are the methods of choice. The best known of these are the algorithms by Nelder&Mead [4], by Hooke&Jeeves [4], genetic algorithms <ref> [5] </ref>, and evolutionary algorithms [6], [7] with the latter being truly continuous counterparts of genetic algorithms. At the heart of every direct search method is a strategy that generates variations of the parameter vectors. <p> We will compare both ANM and ASA to DE1 and DE2. During our research we also wrote an annealed version of the Hooke&Jeeves method <ref> [5] </ref> and tested two Monte Carlo methods [3] one of which used NP parallel vectors and the differential mutation scheme of DE. Although these approaches all worked, they quickly turned out not to be competitive.
Reference: 6. <author> Rechenberg, I., </author> <title> Evolutionsstrategie: Optimierung technischer Systeme nach Prinzipien der biologischen Evolution. </title> <address> Frommann-Holzboog, Stuttgart, </address> <year> 1973. </year>
Reference-contexts: When the objective function is nonlinear and non differentiable, direct search approaches are the methods of choice. The best known of these are the algorithms by Nelder&Mead [4], by Hooke&Jeeves [4], genetic algorithms [5], and evolutionary algorithms <ref> [6] </ref>, [7] with the latter being truly continuous counterparts of genetic algorithms. At the heart of every direct search method is a strategy that generates variations of the parameter vectors. Once a variation is generated, a decision must be made whether or not to accept the newly derived parameters. <p> In the long run, this leads to the greedy criterion. While all direct search methods lend themselves to annealing, it has mostly been used just for the Random Walk, which itself is the simplest case of an evolutionary algorithm <ref> [6] </ref>. Nevertheless, attempts have been made to anneal other direct searches like the method of Nelder&Mead [10] and genetic algorithms [8], [11]. Users generally demand that a practical optimization technique should fulfill three requirements. First, the method should find the true global minimum, regardless of the initial system parameter values.
Reference: 7. <author> Voigt, H. M., </author> <title> Fuzzy Evolutionary Algorithms, </title> <type> Technical Report TR-92-038 at ICSI, </type> <institution> ftp.icsi.berkeley.edu, </institution> <year> 1992. </year>
Reference-contexts: When the objective function is nonlinear and non differentiable, direct search approaches are the methods of choice. The best known of these are the algorithms by Nelder&Mead [4], by Hooke&Jeeves [4], genetic algorithms [5], and evolutionary algorithms [6], <ref> [7] </ref> with the latter being truly continuous counterparts of genetic algorithms. At the heart of every direct search method is a strategy that generates variations of the parameter vectors. Once a variation is generated, a decision must be made whether or not to accept the newly derived parameters.
Reference: 8. <author> Ingber, L., </author> <title> Simulated Annealing: Practice Versus Theory, </title> <journal> J. Mathl. Comput. Modelling, </journal> <volume> Vol. 18, No. 11, </volume> <year> 1993, </year> <pages> pp. 29 - 57. </pages>
Reference-contexts: Inherently parallel search techniques like genetic and evolutionary algorithms have some built-in safeguards to forestall misconvergence. By running several vectors simultaneously, superior parameter configurations can help other vectors escape local minima. Another method which can extricate a parameter vector from a local minimum is Simulated Annealing <ref> [8] </ref>, [9], [10]. Annealing relaxes the greedy criterion by occasionally permitting an uphill move. Such moves potentially allow a parameter vector to climb out of a local minimum. As the number of iterations increases, the probability of accepting an uphill move decreases. <p> While all direct search methods lend themselves to annealing, it has mostly been used just for the Random Walk, which itself is the simplest case of an evolutionary algorithm [6]. Nevertheless, attempts have been made to anneal other direct searches like the method of Nelder&Mead [10] and genetic algorithms <ref> [8] </ref>, [11]. Users generally demand that a practical optimization technique should fulfill three requirements. First, the method should find the true global minimum, regardless of the initial system parameter values. Second, convergence should be fast. <p> The basic control variables in ANM are T, the starting temperature, TF, the temperature reduction factor and NV, the number of random variations at a given temperature level. The second method of interest was Adaptive Simulated Annealing (ASA) <ref> [8] </ref> which claims to converge very quickly and to outperform genetic algorithms on the De Jong test suite [9]. Although ASA provides more than a dozen control variables, it turned out that just two of them, TEMPERATURE_RATIO_SCALE (TRS) and TEMPERATURE_ANNEAL_SCALE (TAS), had significant impact on the minimization process. <p> (Shekel's Foxholes) f x j ij i 6 1 24 0 002 ( ) ( ) + = with a i0 i0 i mod 5, 0 as well as a i1 i1 i+k, 1 The global minimum for this function is f 6 (-32,-32) @ 0.998004. 8 6) Corana's parabola <ref> [8] </ref>, [13] f x j j otherwise z sgn z d if x z j 0 2 ( ) = - - &lt; S T = ; x j [-1000, 1000] (22) with z x j j M M Q 0 49999 0 2 . ( ) . f 6 (x) <p> Conclusion The Differential Evolution method (DE) for minimizing continuous space functions has been introduced and shown to be superior to Adaptive Simulated Annealing (ASA) <ref> [8] </ref> as well as the Annealed Nelder&Mead approach (ANM) [10]. DE was the only technique to converge for all of the functions in our test function suite. For those problems where ASA or ANM could find the minimum, DE usually converged faster, especially in the more difficult cases.
Reference: 9. <author> Ingber, L. and Rosen, B., </author> <title> Genetic Algorithms and Very Fast Simulated Reannealing: A Comparison, </title> <journal> J. Mathl. Comput. Modelling, </journal> <volume> Vol. 16, No. 11, </volume> <year> 1992, </year> <pages> pp. 87 - 100. </pages>
Reference-contexts: Inherently parallel search techniques like genetic and evolutionary algorithms have some built-in safeguards to forestall misconvergence. By running several vectors simultaneously, superior parameter configurations can help other vectors escape local minima. Another method which can extricate a parameter vector from a local minimum is Simulated Annealing [8], <ref> [9] </ref>, [10]. Annealing relaxes the greedy criterion by occasionally permitting an uphill move. Such moves potentially allow a parameter vector to climb out of a local minimum. As the number of iterations increases, the probability of accepting an uphill move decreases. <p> The second method of interest was Adaptive Simulated Annealing (ASA) [8] which claims to converge very quickly and to outperform genetic algorithms on the De Jong test suite <ref> [9] </ref>. Although ASA provides more than a dozen control variables, it turned out that just two of them, TEMPERATURE_RATIO_SCALE (TRS) and TEMPERATURE_ANNEAL_SCALE (TAS), had significant impact on the minimization process. We will compare both ANM and ASA to DE1 and DE2. <p> Although these approaches all worked, they quickly turned out not to be competitive. The Testbed Our function testbed contains the De Jong test functions as presented in <ref> [9] </ref> plus some additional functions which present further distinctive difficulties for a global minimizer: 7 1) First De Jong function (sphere) f x x j 2 2 = ; x j [-5.12, 5.12] (17) f 1 (x) is considered to be a very simple task for every serious minimization method. <p> In the original De Jong function, h is a random variable produced by Gaussian noise having the distribution N (0,1). According to <ref> [9] </ref>, this function appears to be flawed as no definite global minimum exists. In response to the problem, we followed the suggestion given in [9] and chose h to be a random variable with uniform distribution and bounded by [0,1). <p> In the original De Jong function, h is a random variable produced by Gaussian noise having the distribution N (0,1). According to <ref> [9] </ref>, this function appears to be flawed as no definite global minimum exists. In response to the problem, we followed the suggestion given in [9] and chose h to be a random variable with uniform distribution and bounded by [0,1). In contrast to the original version of De Jong's quartic function, we also included h inside the summation instead of just adding h to the summation result.
Reference: 10. <author> Press, W.H., Teukolsky, S.A., Vetterling, W.T. and Flannery, </author> <title> B.P., Numerical Recipes in C, </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: Inherently parallel search techniques like genetic and evolutionary algorithms have some built-in safeguards to forestall misconvergence. By running several vectors simultaneously, superior parameter configurations can help other vectors escape local minima. Another method which can extricate a parameter vector from a local minimum is Simulated Annealing [8], [9], <ref> [10] </ref>. Annealing relaxes the greedy criterion by occasionally permitting an uphill move. Such moves potentially allow a parameter vector to climb out of a local minimum. As the number of iterations increases, the probability of accepting an uphill move decreases. In the long run, this leads to the greedy criterion. <p> While all direct search methods lend themselves to annealing, it has mostly been used just for the Random Walk, which itself is the simplest case of an evolutionary algorithm [6]. Nevertheless, attempts have been made to anneal other direct searches like the method of Nelder&Mead <ref> [10] </ref> and genetic algorithms [8], [11]. Users generally demand that a practical optimization technique should fulfill three requirements. First, the method should find the true global minimum, regardless of the initial system parameter values. Second, convergence should be fast. <p> Two methods in particular piqued our interest. The first was the annealed version of the Nelder&Mead strategy (ANM) <ref> [10] </ref> which is appealing because of its adaptive scheme for generating random parameter deviations. When the annealing part is switched off, a fast converging direct search method remains which is especially useful for noncritical objective functions. <p> Conclusion The Differential Evolution method (DE) for minimizing continuous space functions has been introduced and shown to be superior to Adaptive Simulated Annealing (ASA) [8] as well as the Annealed Nelder&Mead approach (ANM) <ref> [10] </ref>. DE was the only technique to converge for all of the functions in our test function suite. For those problems where ASA or ANM could find the minimum, DE usually converged faster, especially in the more difficult cases.
Reference: 11. <author> Price, K., </author> <title> Genetic Annealing, </title> <journal> Dr. Dobbs Journal, </journal> <month> Oct. </month> <year> 1994, </year> <pages> pp. 127 - 132. </pages>
Reference-contexts: Nevertheless, attempts have been made to anneal other direct searches like the method of Nelder&Mead [10] and genetic algorithms [8], <ref> [11] </ref>. Users generally demand that a practical optimization technique should fulfill three requirements. First, the method should find the true global minimum, regardless of the initial system parameter values. Second, convergence should be fast.
Reference: 12. <author> Moebus, D., </author> <title> Algorithmen zur Optimierung von Schaltungenund zur Loesung nichtlinearer Differentialgleichungen, </title> <institution> Diss. am Inst. fuer Netzwerk- und Systemtheorie der Univ. Stuttgart, </institution> <year> 1990. </year>
Reference-contexts: All functions f m (x) can be combined into a single objective function z (x) [2], <ref> [12] </ref>, which usually is computed either via the weighted sum z x w f x m ( ) ( ) = + - 1 or via z x w f x ( ) max ( ) = (8) with w m &gt; 0. (9) The weighting factors w m are used <p> The optimization task can now be restated as min z (x) (10) The min-max formulation (8) and (10) guarantees that all local minima, the Pareto critical points, including the possibly multiple global minima, the Pareto points, can at least theoretically be found [2], <ref> [12] </ref>.
Reference: 13. <author> Corana, A., Marchesi, M., Martini, C. and Ridella, S., </author> <title> Minimizing Multimodal Functions of Continuous Variables with the "Simulated Annealing Algorithm", </title> <journal> ACM Trans. Mathl. Software, </journal> <month> March </month> <year> 1987, </year> <pages> pp. 272 - 280. </pages>
Reference-contexts: Foxholes) f x j ij i 6 1 24 0 002 ( ) ( ) + = with a i0 i0 i mod 5, 0 as well as a i1 i1 i+k, 1 The global minimum for this function is f 6 (-32,-32) @ 0.998004. 8 6) Corana's parabola [8], <ref> [13] </ref> f x j j otherwise z sgn z d if x z j 0 2 ( ) = - - &lt; S T = ; x j [-1000, 1000] (22) with z x j j M M Q 0 49999 0 2 . ( ) . f 6 (x) defines
Reference: 14. <author> Griewangk, </author> <title> A.O., Generalized Descent for Global Optimization, </title> <journal> JOTA, </journal> <volume> vol. 34, </volume> <year> 1981, </year> <pages> pp. 11 - 39. </pages>
Reference-contexts: Any minimization algorithm that goes strictly downhill will almost always be captured by the holes. The minimum here is f 6 (x) = 0, with |x j |&lt;0.05, j=0,1,2,3. 7) Griewangk's function <ref> [14] </ref> f x j jj 2 9 9 1 ( ) cos = - F G K == ; x j [-400, 400] (23) Like test function f 6 (x), f 7 (x) has many local minima so that it is very difficult to find the true minimum f 7 (0)
Reference: 15. <author> Zimmermann, W., </author> <note> Operations Research, Oldenbourg, </note> <year> 1990. </year>
Reference-contexts: 9 9 1 ( ) cos = - F G K == ; x j [-400, 400] (23) Like test function f 6 (x), f 7 (x) has many local minima so that it is very difficult to find the true minimum f 7 (0) = 0. 8) Zimmermann's problem <ref> [15] </ref> f x x x 9 ( ) = - ; x j &gt; 0, j=1,2 (24) with ( ) ( )x x 0 1 and x x 14 (26) Finding the minimum f 8 (7,2)=0 poses a special problem, because the minimum is located at the corner of the constrained
Reference: 16. <author> Rabiner, L.R. and Gold, B., </author> <title> Theory and Applications of Digital Signal Processing, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1975. </year> <month> 12 </month>
Reference-contexts: Outside this "tube" the polynomial rises steeply in direction of high positive ordinate values. The polynomial fitting problem has its roots in electronic filter design <ref> [16] </ref> and 9 challenges an optimization procedure by forcing it to find parameter values with grossly different magnitudes, something very common in technical systems.
References-found: 16

