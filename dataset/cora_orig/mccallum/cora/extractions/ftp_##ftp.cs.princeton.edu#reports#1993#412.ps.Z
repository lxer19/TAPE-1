URL: ftp://ftp.cs.princeton.edu/reports/1993/412.ps.Z
Refering-URL: http://www.cs.princeton.edu/~mjrg/
Root-URL: http://www.cs.princeton.edu
Email: appel@princeton.edu  mjrg@cs.princeton.edu  
Title: Hash-consing Garbage Collection  
Author: Andrew W. Appel Marcelo J. R. Gon~calves 
Note: a Supported in part by NSF Grant CCR-9200790 Supported by CNPQ Grant 200579/90.8  
Date: February 1993  
Affiliation: Princeton University  
Pubnum: CSTR-412-93  
Abstract: We describe an implementation of hash-consing for the Standard ML of New Jersey compiler. Hash-consing can eliminate replication among heap-allocated data, which may allow the use of fast equality checking and may also improve the locality of reference of a program. The cost of a hash table lookup for each record allocated may, however, offset any gains from the elimination of replication. Our hash-consing scheme is integrated with a generational garbage collector. Only records that survive a garbage collection are "hash-consed," thus avoiding the cost of a table lookup for short-lived records. We discuss some issues related with the implementation of this scheme and present a performance evaluation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Andrew Appel. </author> <title> Simple generational garbage collection and fast allocation. </title> <journal> Software Practice and Experience, </journal> <volume> 19(2) </volume> <pages> 171-183, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: For a more detailed description see Appel <ref> [1, 2] </ref>. The SML/NJ compiler uses a generational garbage collector, with two generations. <p> 1 to length (R) do if R [i] is a pointer into fromspace and record pointed to by R [i] is not marked then R [i] forward (R [i]) endif endfor f all of R's fields are already forwarded g copy record pointed to by R to location NEXT R <ref> [1] </ref> NEXT NEXT NEXT + length (R) return R [1] record in the fromspace. <p> a pointer into fromspace and record pointed to by R [i] is not marked then R [i] forward (R [i]) endif endfor f all of R's fields are already forwarded g copy record pointed to by R to location NEXT R <ref> [1] </ref> NEXT NEXT NEXT + length (R) return R [1] record in the fromspace. <p> is not marked do currentafield currentafield + 1 endwhile if currentafield &lt; length (R) then push (R; currentafield) R R [currentafield] mark record pointed to by R currentafield 1 continue endif f all of R's fields are already forwarded g copy record pointed to by R to location NEXT R <ref> [1] </ref> NEXT NEXT NEXT + length (R) if stack is empty then return R [1] else newaaddress R [1] (R; currentafield) pop () R [currentafield] newaaddress currentafield currentafield + 1 endif endloop record in the fromspace. NEXT is a pointer to the next free location of the reserve space. <p> then push (R; currentafield) R R [currentafield] mark record pointed to by R currentafield 1 continue endif f all of R's fields are already forwarded g copy record pointed to by R to location NEXT R <ref> [1] </ref> NEXT NEXT NEXT + length (R) if stack is empty then return R [1] else newaaddress R [1] (R; currentafield) pop () R [currentafield] newaaddress currentafield currentafield + 1 endif endloop record in the fromspace. NEXT is a pointer to the next free location of the reserve space. <p> R R [currentafield] mark record pointed to by R currentafield 1 continue endif f all of R's fields are already forwarded g copy record pointed to by R to location NEXT R <ref> [1] </ref> NEXT NEXT NEXT + length (R) if stack is empty then return R [1] else newaaddress R [1] (R; currentafield) pop () R [currentafield] newaaddress currentafield currentafield + 1 endif endloop record in the fromspace. NEXT is a pointer to the next free location of the reserve space. <p> The only problem now is how to find these updated ref-cells, but it turns out that the compiler already keeps a list of these cells (which it needs to handle updates to old objects in a generational garbage collector <ref> [1] </ref>) so this problem is very neatly solved. The method works as follows. First we scan the ref list, marking all the updated ref-cells. Then we proceed with the usual forwarding of all the roots. <p> Updatable records are simply copied, without neither a table lookup nor entry into the table. The implementation requires a modification of the following three lines of the Depth-first collector algorithm presented in Figure 3: copy record pointed to by R to location NEXT R <ref> [1] </ref> NEXT NEXT NEXT + length (R) these lines are replaced by: X lookup (R) if X is not null then R [1] X else copy record pointed to by R to location NEXT R [1] NEXT enter record pointed to by NEXT in the hash table NEXT NEXT + length <p> implementation requires a modification of the following three lines of the Depth-first collector algorithm presented in Figure 3: copy record pointed to by R to location NEXT R <ref> [1] </ref> NEXT NEXT NEXT + length (R) these lines are replaced by: X lookup (R) if X is not null then R [1] X else copy record pointed to by R to location NEXT R [1] NEXT enter record pointed to by NEXT in the hash table NEXT NEXT + length (R) endif We have used an open hashing scheme [15] to implement the hash table. <p> algorithm presented in Figure 3: copy record pointed to by R to location NEXT R <ref> [1] </ref> NEXT NEXT NEXT + length (R) these lines are replaced by: X lookup (R) if X is not null then R [1] X else copy record pointed to by R to location NEXT R [1] NEXT enter record pointed to by NEXT in the hash table NEXT NEXT + length (R) endif We have used an open hashing scheme [15] to implement the hash table. A second hash function is used to handle collisions.
Reference: [2] <author> Andrew Appel. </author> <title> A runtime system. Lisp and Symbolic Computation: </title> <journal> An International Journal, </journal> <volume> 3 </volume> <pages> 343-380, </pages> <year> 1990. </year>
Reference-contexts: For a more detailed description see Appel <ref> [1, 2] </ref>. The SML/NJ compiler uses a generational garbage collector, with two generations.
Reference: [3] <author> Andrew Appel and David MacQueen. </author> <title> A Standard ML compiler. </title> <editor> In Gilles Kahn, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 301-324. </pages> <publisher> Springer-Verlag, </publisher> <year> 1987. </year>
Reference-contexts: This could offset the gain in space introduced by sharing; worse yet, the hash table is now competing for the cache and main memory. In this paper we describe an experience with the implementation of a modi 2 fied hash-consing scheme for the Standard ML of New Jersey compiler <ref> [3] </ref>. The SML/NJ compiler divides the heap in two main areas, the newer generation, where records are initially allocated and the older generation which contains the records that survive garbage collections. In our new hash-consing implementation, only those records that survive at least one garbage collection are "hash-consed".
Reference: [4] <author> Andrew W. Appel, James S. Mattson, and David R. Tarditi. </author> <title> A lexical analyser. Distributed with Standard ML of New Jersey, </title> <month> December </month> <year> 1989. </year>
Reference-contexts: Boyer The Boyer theorem-proving benchmark [12] translated into SML by Kai Li and Andrew Appel. Knuth-Bendix An implementation by Gerard Huet of the Knuth-Bendix com pletion algorithm, translated into SML by Xavier Leroy. Lex A lexical-analyzer generator written by James S. Mattson and David R. Tarditi <ref> [4] </ref>. Life Reade's implementation of the game of Life [16]. Mandelbrot A program to generate Mandelbrot sets. Simple A spherical fluid-dynamics program [9, 10], translated into SML by Lal George. VLIW A VLIW scheduler written by John Danskin.
Reference: [5] <author> Henry Baker. </author> <title> The Boyer benchmark at warp speed. </title> <journal> Lisp Pointers, </journal> <volume> 5(3) </volume> <pages> 13-14, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Yacc has the worst performance, being 22 percent slower. The Boyer benchmark showed the highest increase in performance, almost 10 percent. This agrees with experiments made by Baker <ref> [5] </ref>, who shows that function memoization and hash-consing can greatly improve the performance of the Boyer program (memoization seems to be more important than hash-consing). The SML/NJ compiler uses a parameter|the heap ratio|that controls the ratio of total heap memory to live data size. <p> Thus, (f; x) 7! y can be entered in the memo table. No guarantee is implied that f is pure when applied to other arguments, but none is needed. Baker <ref> [5, 6, 7] </ref> has shown that memoization (in combination with hash-consing) is extremely powerful in improving the performance of programs such as the Boyer benchmark, which proves theorems by backtracking search. 9 Conclusion A hash-consing garbage collector is about a factor of two or three slower than an ordinary collector; but
Reference: [6] <author> Henry Baker. </author> <title> The Gabriel `Triangle' benchmark at warp speed. Lisp Pointers, </title> <type> 5(3), </type> <month> July </month> <year> 1992. </year>
Reference-contexts: Thus, (f; x) 7! y can be entered in the memo table. No guarantee is implied that f is pure when applied to other arguments, but none is needed. Baker <ref> [5, 6, 7] </ref> has shown that memoization (in combination with hash-consing) is extremely powerful in improving the performance of programs such as the Boyer benchmark, which proves theorems by backtracking search. 9 Conclusion A hash-consing garbage collector is about a factor of two or three slower than an ordinary collector; but
Reference: [7] <author> Henry Baker. A tachy `TAK'. </author> <title> Lisp Pointers, </title> <type> 5(3), </type> <month> July </month> <year> 1992. </year>
Reference-contexts: Thus, (f; x) 7! y can be entered in the memo table. No guarantee is implied that f is pure when applied to other arguments, but none is needed. Baker <ref> [5, 6, 7] </ref> has shown that memoization (in combination with hash-consing) is extremely powerful in improving the performance of programs such as the Boyer benchmark, which proves theorems by backtracking search. 9 Conclusion A hash-consing garbage collector is about a factor of two or three slower than an ordinary collector; but
Reference: [8] <author> Richard S. Bird. </author> <title> Tabulation techniques for recursive programs. </title> <journal> ACM Computing Surveys, </journal> <volume> 12(4) </volume> <pages> 403-417, </pages> <month> December </month> <year> 1980. </year>
Reference-contexts: Perhaps this is because the DECstation's four-word cache blocks are too small to hold much more than one object each (and our programs exhibit minimal virtual-memory paging). 8 Future Work Perhaps the real promise of hash-consing is that it can make function memoization <ref> [8] </ref> possible.
Reference: [9] <author> W. P. Crowley, C. P. Hendrickson, and T. E. Rudy. </author> <title> The SIMPLE code. </title> <type> Technical Report UCID 17715, </type> <institution> Lawrence Livermore Laboratory, Livermore, </institution> <address> CA, </address> <month> February </month> <year> 1978. </year>
Reference-contexts: Lex A lexical-analyzer generator written by James S. Mattson and David R. Tarditi [4]. Life Reade's implementation of the game of Life [16]. Mandelbrot A program to generate Mandelbrot sets. Simple A spherical fluid-dynamics program <ref> [9, 10] </ref>, translated into SML by Lal George. VLIW A VLIW scheduler written by John Danskin. Yacc A LALR (1) parser generator, written by David Tarditi [17] processing the grammar of Standard ML. the use of hash-consing. Times are normalized to the execution time without hash-consing.
Reference: [10] <author> K. Ekanadham and Arvind. </author> <title> SIMPLE: An exercise in future scientific programming. Technical Report Computation Structures Group Memo 273, </title> <publisher> MIT, </publisher> <address> Cambridge, MA, </address> <month> July </month> <year> 1987. </year> <note> Simultaneously published as IBM/T.J. </note> <institution> Watson Research Center Research Report 12686, Yorktown Heights, NY. </institution>
Reference-contexts: Lex A lexical-analyzer generator written by James S. Mattson and David R. Tarditi [4]. Life Reade's implementation of the game of Life [16]. Mandelbrot A program to generate Mandelbrot sets. Simple A spherical fluid-dynamics program <ref> [9, 10] </ref>, translated into SML by Lal George. VLIW A VLIW scheduler written by John Danskin. Yacc A LALR (1) parser generator, written by David Tarditi [17] processing the grammar of Standard ML. the use of hash-consing. Times are normalized to the execution time without hash-consing.
Reference: [11] <author> A. P. Ershov. </author> <title> On programming of arithmetic operations. </title> <journal> CACM, </journal> <volume> 1(8), </volume> <year> 1958. </year>
Reference-contexts: Moreover, the duplication of storage for values is likely to affect the locality of reference of the program, causing an increase in cache misses and virtual memory page faults, which may further increase its running time. Ershov <ref> [11] </ref> showed how to collapse trees to minimal DAGs by traversing trees bottom-up, using hashing to eliminate common subexpressions. Goto [13] implemented a Lisp system with a built-in hash-cons operation: his "h-cons" cells were rewrite protected and free of duplicate copies. <p> Updatable objects are copied in the usual way, without using the hash table. In order for this scheme to work correctly, we must be careful to copy objects in a bottom-up way <ref> [11] </ref>: given a DAG, we can only forward a node (i.e. a record) after we have forwarded all of its descendants. This bottom-up forwarding can be easily achieved with the use of a depth-first algorithm to traverse the live objects in the newer generation.
Reference: [12] <author> Richard P. Gabriel. </author> <title> Performance and Evaluation of Lisp Systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985. </year>
Reference-contexts: The experiments were made on a DECstation 5000/240, with 64Mbytes of main memory, using version 0.75 of the SML/NJ compiler. A brief description of the benchmark programs is given next. Boyer The Boyer theorem-proving benchmark <ref> [12] </ref> translated into SML by Kai Li and Andrew Appel. Knuth-Bendix An implementation by Gerard Huet of the Knuth-Bendix com pletion algorithm, translated into SML by Xavier Leroy. Lex A lexical-analyzer generator written by James S. Mattson and David R. Tarditi [4].
Reference: [13] <author> Eiichi Goto. </author> <title> Monocopy and associative algorithms in extended lisp. </title> <type> Technical Report TR 74-03, </type> <institution> University of Tokyo, </institution> <year> 1974. </year>
Reference-contexts: Ershov [11] showed how to collapse trees to minimal DAGs by traversing trees bottom-up, using hashing to eliminate common subexpressions. Goto <ref> [13] </ref> implemented a Lisp system with a built-in hash-cons operation: his "h-cons" cells were rewrite protected and free of duplicate copies. The technique of hash-consing guarantees that two identical objects will share the same records on the heap, and thus will be represented by the same pointer.
Reference: [14] <author> Donald E. Knuth. </author> <title> Fundamental Algorithms, </title> <booktitle> volume 1 of The Art of Computer Programming. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1973. </year>
Reference-contexts: A nice property of the breadth-first algorithm is that it can use the records just copied as an implicit queue and, thus, does not require any auxiliary storage. Depth-first algorithms require either an auxiliary stack or a complicated pointer-reversal scheme <ref> [14] </ref>. However, if we use the scheme described above, we need not allocate any additional memory area for the stack. It turns out that there is just enough space in the to-space to put the stack.
Reference: [15] <author> Donald E. Knuth. </author> <title> Sorting and Searching, </title> <booktitle> volume 3 of The Art of Computer Programming. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1973. </year>
Reference-contexts: replaced by: X lookup (R) if X is not null then R [1] X else copy record pointed to by R to location NEXT R [1] NEXT enter record pointed to by NEXT in the hash table NEXT NEXT + length (R) endif We have used an open hashing scheme <ref> [15] </ref> to implement the hash table. A second hash function is used to handle collisions. The two hash values are computed as a function of the first few words of a record. Each table entry is either empty or contains a pointer to a record on the heap.
Reference: [16] <author> Chris Reade. </author> <title> Elements of Functional Programming. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: Knuth-Bendix An implementation by Gerard Huet of the Knuth-Bendix com pletion algorithm, translated into SML by Xavier Leroy. Lex A lexical-analyzer generator written by James S. Mattson and David R. Tarditi [4]. Life Reade's implementation of the game of Life <ref> [16] </ref>. Mandelbrot A program to generate Mandelbrot sets. Simple A spherical fluid-dynamics program [9, 10], translated into SML by Lal George. VLIW A VLIW scheduler written by John Danskin. Yacc A LALR (1) parser generator, written by David Tarditi [17] processing the grammar of Standard ML. the use of hash-consing.
Reference: [17] <author> David R. Tarditi and Andrew W. Appel. ML-Yacc, </author> <title> version 2.0. Distributed with Standard ML of New Jersey, </title> <month> April </month> <year> 1990. </year>
Reference-contexts: Tarditi [4]. Life Reade's implementation of the game of Life [16]. Mandelbrot A program to generate Mandelbrot sets. Simple A spherical fluid-dynamics program [9, 10], translated into SML by Lal George. VLIW A VLIW scheduler written by John Danskin. Yacc A LALR (1) parser generator, written by David Tarditi <ref> [17] </ref> processing the grammar of Standard ML. the use of hash-consing. Times are normalized to the execution time without hash-consing. The total running time is divided into garbage-collection time (gc-time) and non-garbage-collection time (non-gc-time).
Reference: [18] <author> David M. Ungar. </author> <title> The Design and Evaluation of a High Performance Smalltalk System. </title> <publisher> MIT Press, </publisher> <address> Cambrigde, MA, </address> <year> 1986. </year>
Reference-contexts: The premise of generational garbage collection is that most allocated objects tend to have a very short life <ref> [18] </ref>. By eliminating replication, we reduce the size of the older generation. There will be no space savings in the newer generation, but we don't lose much here since the space of this generation will be reused after each "minor" garbage collection.
Reference: [19] <author> Paul R. Wilson, Michael S. Lam, and Thomas G. Moher. </author> <title> Effective "static-graph" reorganization to improve locality in garbage-collected systems. </title> <booktitle> In Proc. ACM SIGPLAN'91 Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 177-191, </pages> <month> June </month> <year> 1991. </year> <month> 18 </month>
Reference-contexts: The traversal algorithm may have an impact on the locality of references of the collected data and thus affect the performance of programs <ref> [19] </ref>. Our measurements do not show any significant differences.
References-found: 19

