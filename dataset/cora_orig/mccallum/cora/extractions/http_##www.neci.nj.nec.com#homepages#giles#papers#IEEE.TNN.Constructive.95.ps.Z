URL: http://www.neci.nj.nec.com/homepages/giles/papers/IEEE.TNN.Constructive.95.ps.Z
Refering-URL: http://www.neci.nj.nec.com/homepages/giles/html/CLG_pub.html
Root-URL: 
Title: Constructive Learning of Recurrent Neural Networks: Limitations of Recurrent Casade Correlation and a Simple Solution  
Author: C.L. Giles a;b D. Chen a G.Z. Sun a H.H. Chen a Y.C. Lee a M.W. Goudreau c 
Keyword: Recurrent Cascade Correlation method  
Note: is unable to learn.  
Address: College Park, MD 20742  4 Independence Way Princeton, NJ 08540  Orlando, FL 32816  
Affiliation: a Institute for Advanced Computer Studies University of Maryland  b NEC Research Institute  c Dept. of Computer Science University of Central Florida  
Abstract: It is often difficult to predict the optimal neural network size for a particular application. Constructive or destructive methods that add or subtract neurons, layers, connections, etc. might offer a solution to this problem. We prove that one method, Recurrent Cascade Correlation, due to its topology, has fundamental limitations in representation and thus in its learning capabilities. It cannot represent with monotone (i.e. sigmoid) and hard-threshold activation functions certain finite state automata. We give a "preliminary" approach on how to get around these limitations by devising a simple constructive training method that adds neurons during training while still preserving the powerful fully-recurrent structure. We illustrate this approach by simulations which learn many examples of regular grammars that the 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon, A. Dewdney, and T. Ott, </author> <title> "Efficient simulation of finite automata by neural nets," </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> vol. 38, no. 2, </volume> <pages> pp. 495-514, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: As the size of network grows, so does the size of the FSA it can represent. Thus, any simple expanding network that is "fully-connected" and large enough should be able to represent (or load) any FSA <ref> [1, 15] </ref>. The importance of using prior knowledge in neural network learning has been described by many, see the discussion by Shavlik [34]. Our further assumption is that prior knowledge gained from early training is important to effectively maintain some of the network's earlier knowledge.
Reference: [2] <author> T. Ash, </author> <title> "Dynamic node creation in backpropagation networks," </title> <journal> Connection Science, </journal> <volume> vol. 1, no. 4, </volume> <pages> pp. 365-375, </pages> <year> 1989. </year>
Reference-contexts: We propose an alternative method which eliminates these limitations. 2 Constructive Learning A constructive method dynamically grows the network structure during the network's training. Various constructive methods have been studied and various types of network growing methods have been proposed <ref> [2, 4, 6, 9, 10, 16, 20, 25, 26, 33, 37] </ref>. A good review of some of these algorithms is found in [19].
Reference: [3] <author> A. Cleeremans, D. Servan-Schreiber, and J. McClelland, </author> <title> "Finite state automata and simple recurrent recurrent networks," </title> <journal> Neural Computation, </journal> <volume> vol. 1, no. 3, </volume> <pages> pp. 372-381, </pages> <year> 1989. </year>
Reference-contexts: It is also possible to combine constructive and destructive methods. Recurrent Neural Networks have ability to process and store temporal information and sequential signals. For example recent work has shown that various recurrent networks are able to infer small regular grammars from examples <ref> [3, 11, 27, 36, 40] </ref>. However, one of the problems associated with recurrent networks is that the training scales badly with both network and problem size [41]. The convergence time can be very slow and 2 training errors are not always guaranteed to reduce to previously defined tolerances.
Reference: [4] <author> J. Diederich, </author> <title> "Connectionist recruitment learning," </title> <booktitle> in Proceedings of the 8th European Conference on Artificial Intelligence, </booktitle> <address> (London, UK), </address> <year> 1988. </year>
Reference-contexts: We propose an alternative method which eliminates these limitations. 2 Constructive Learning A constructive method dynamically grows the network structure during the network's training. Various constructive methods have been studied and various types of network growing methods have been proposed <ref> [2, 4, 6, 9, 10, 16, 20, 25, 26, 33, 37] </ref>. A good review of some of these algorithms is found in [19].
Reference: [5] <author> J. Elman, </author> <title> "Finding structure in time," </title> <journal> Cognitive Science, </journal> <volume> vol. 14, </volume> <pages> pp. 179-211, </pages> <year> 1990. </year>
Reference-contexts: A simple dynamically-driven recurrent neural network (RNN) consists of three parts: input layer, a simple recurrent layer and output layer <ref> [5] </ref>. We term the recurrent network "driven" to denote that it responds temporally to inputs. The hidden recurrent layer is activated by both the input neurons and the recurrent layer itself. The output neurons are in general activated by the input and recurrent neurons, or by only the recurrent neurons.
Reference: [6] <author> S. Fahlman, </author> <booktitle> "The cascade-correlation learning architecture," in Advances in Neural Information Processing Systems 2 (D. </booktitle> <editor> Touretzky, ed.), </editor> <address> (San Mateo, CA), </address> <pages> pp. 524-532, </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1990. </year>
Reference-contexts: We propose an alternative method which eliminates these limitations. 2 Constructive Learning A constructive method dynamically grows the network structure during the network's training. Various constructive methods have been studied and various types of network growing methods have been proposed <ref> [2, 4, 6, 9, 10, 16, 20, 25, 26, 33, 37] </ref>. A good review of some of these algorithms is found in [19]. <p> To our knowledge "all" constructive methods with the exception of recurrent cascade-correlation [7] are for feed-forward networks. 2.1 Recurrent Cascade-Correlation Recurrent cascade-correlation (RCC) is a "recurrent version" of cascade-correlation (CC). We first review the Cascade-Correlation constructive algorithm (figure 1). To quote Fahlman <ref> [6] </ref>: "Cascade-Correlation combines two key ideas: the first is the cascade architecture, in which hidden units are added to the network one at a time and do not change after they have been added. <p> The added hidden unit connects to the original inputs and all pre-existing hidden units. The trainable weights can be updated using the desired optimization algorithm such as backpropagation; for more details see <ref> [6] </ref>. The training time for this algorithm appears to be very fast since only the newly added weights are trained. The "recurrent" extension to cascade-correlation is straightforward [7]. Each added neuron has a time-delayed recurrent self-loop (see figure 2). This gives RCC state memory.
Reference: [7] <author> S. Fahlman, </author> <title> "The recurrent cascade-correlation architecture," </title> <booktitle> in Advances in Neural Information Pro--cessing Systems 3 (R. </booktitle> <editor> Lippmann, J. Moody, and D. Touretzky, eds.), </editor> <address> (San Mateo, CA), </address> <pages> pp. 190-196, </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1991. </year>
Reference-contexts: A good review of some of these algorithms is found in [19]. To our knowledge "all" constructive methods with the exception of recurrent cascade-correlation <ref> [7] </ref> are for feed-forward networks. 2.1 Recurrent Cascade-Correlation Recurrent cascade-correlation (RCC) is a "recurrent version" of cascade-correlation (CC). We first review the Cascade-Correlation constructive algorithm (figure 1). <p> The trainable weights can be updated using the desired optimization algorithm such as backpropagation; for more details see [6]. The training time for this algorithm appears to be very fast since only the newly added weights are trained. The "recurrent" extension to cascade-correlation is straightforward <ref> [7] </ref>. Each added neuron has a time-delayed recurrent self-loop (see figure 2). This gives RCC state memory. However, we will show that this self-loop state memory is restricted in the sense that it is insufficient to represent all finite state automata. <p> Again, all previous weights other than the newly added feedforward and recurrent ones are frozen. Since the representational restrictions of RCC are not due to the training procedure, we do not discuss them here and refer the interested reader to Fahlman <ref> [7] </ref>. 3 2.2 Criteria for Network Growth In addition to the normal updating and learning rules of the neural network, a constructive training scheme must also address how to architecturally (or topologically) change the network.
Reference: [8] <author> S. Fahlman and C. Lebiere, </author> <title> "The cascade-correlation learning architecture," </title> <type> Tech. Rep. </type> <institution> CMU-CS-90-100, School of Computer Science, Carnegie-Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> February </month> <year> 1990. </year>
Reference-contexts: More sophisticated criteria could be used <ref> [8] </ref>. The recurrent cascade-correlation construction method is certainly a step in the right direction, but it is incapable of representing and thus learning many finite state automata. The simple constructive method proposed avoids the limitations of Recurrent Cascade Correlation (RCC) networks.
Reference: [9] <author> M. Frean, </author> <title> "The upstart algorithm: A method for constructing and training feedforward neural networks," </title> <journal> Neural Computation, </journal> <volume> vol. 2, </volume> <editor> p. </editor> <volume> 198, </volume> <year> 1990. </year>
Reference-contexts: We propose an alternative method which eliminates these limitations. 2 Constructive Learning A constructive method dynamically grows the network structure during the network's training. Various constructive methods have been studied and various types of network growing methods have been proposed <ref> [2, 4, 6, 9, 10, 16, 20, 25, 26, 33, 37] </ref>. A good review of some of these algorithms is found in [19].
Reference: [10] <author> S. I. Gallant, </author> <title> "Three constructive algorithms for network learning," </title> <booktitle> in Proceedings, 8th Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp. 652-660, </pages> <year> 1986. </year>
Reference-contexts: We propose an alternative method which eliminates these limitations. 2 Constructive Learning A constructive method dynamically grows the network structure during the network's training. Various constructive methods have been studied and various types of network growing methods have been proposed <ref> [2, 4, 6, 9, 10, 16, 20, 25, 26, 33, 37] </ref>. A good review of some of these algorithms is found in [19]. <p> The second is the learning algorithm, which creates and installs the new hidden units." (The constructive architectural method of CC is very similar to the pyramid method proposed by Gallant <ref> [10] </ref>.) In CC a preset number of single layer neurons are initially trained until the error is no longer significantly reduced. If at this point the error is not satisfactory, a single hidden unit is added and the previously trained weights are frozen.
Reference: [11] <author> C. Giles, C. Miller, D. Chen, H. Chen, G. Sun, and Y. Lee, </author> <title> "Learning and extracting finite state automata with second-order recurrent neural networks," </title> <journal> Neural Computation, </journal> <volume> vol. 4, no. 3, </volume> <pages> pp. 393-405, </pages> <year> 1992. </year>
Reference-contexts: It is also possible to combine constructive and destructive methods. Recurrent Neural Networks have ability to process and store temporal information and sequential signals. For example recent work has shown that various recurrent networks are able to infer small regular grammars from examples <ref> [3, 11, 27, 36, 40] </ref>. However, one of the problems associated with recurrent networks is that the training scales badly with both network and problem size [41]. The convergence time can be very slow and 2 training errors are not always guaranteed to reduce to previously defined tolerances. <p> This system process is similar to that of a finite state automata (FSA) in that the network only keeps the "state" information of the last time step [30]. Connections between layers can be first, second, or even higher orders <ref> [11, 32, 40] </ref>. <p> Thus, the new network behaves very similarly to the old one immediately after the expansion and old knowledge learned is still preserved. We present a simple example of the above method. We train a second-order fully-recurrent neural network <ref> [11] </ref> to be a FSA by training it sequentially on positive and negative strings accepted by that FSA. For training we use a true-gradient real-time recurrent learning algorithm (RTRL), for further description see [11]. First we examine if the network can take advantage of its previous knowledge. <p> We present a simple example of the above method. We train a second-order fully-recurrent neural network <ref> [11] </ref> to be a FSA by training it sequentially on positive and negative strings accepted by that FSA. For training we use a true-gradient real-time recurrent learning algorithm (RTRL), for further description see [11]. First we examine if the network can take advantage of its previous knowledge. For Criteria 1) we require that the network train for some period of time. Admittedly, the amount of time could be crucial. However, this is an issue that remains to be examined.
Reference: [12] <author> C. Giles, C. Miller, D. Chen, G. Sun, H. Chen, and Y. Lee, </author> <title> "Extracting and learning an unknown grammar with recurrent neural networks," </title> <booktitle> in Advances in Neural Information Processing Systems 4 (J. </booktitle> <editor> Moody, S. Hanson, and R. Lippmann, eds.), </editor> <address> (San Mateo, CA), </address> <pages> pp. 317-324, </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1992. </year>
Reference-contexts: However, this is an issue that remains to be examined. More complex decision criteria might be based on entropy measures, network capacity, neuron activity distribution or others. We train the network to learn a 10-state randomly generated FSA (figure 8) as in <ref> [12] </ref>.
Reference: [13] <author> C. Giles and C. Omlin, </author> <title> "Extraction, insertion and refinement of symbolic rules in dynamically-driven recurrent neural networks," </title> <journal> Connection Science, </journal> <volume> vol. 5, no. 3,4, </volume> <pages> pp. 307-337, </pages> <year> 1993. </year> <title> Special Issue on Architectures for Integrating Symbolic and Neural Processes. </title>
Reference-contexts: For the third criterion, we propose that just as the network is about to grow, the network preserve as much previously acquired knowledge as possible. (Previous work where rules are encoded directly into the recurrent networks have shown that prior knowledge does improve the learning speed <ref> [14, 13] </ref>.) RCC accomplishes this by freezing all previous weight values after a new neuron is added.
Reference: [14] <author> C. Giles and C. Omlin, </author> <title> "Inserting rules into recurrent neural networks," in Neural Networks for Signal Processing II, </title> <booktitle> Proceedings of The 1992 IEEE Workshop (S. </booktitle> <editor> Kung, F. Fallside, J. A. Sorenson, and C. Kamm, eds.), </editor> <address> (Piscataway, NJ), </address> <pages> pp. 13-22, </pages> <publisher> IEEE Press, </publisher> <year> 1992. </year>
Reference-contexts: For the third criterion, we propose that just as the network is about to grow, the network preserve as much previously acquired knowledge as possible. (Previous work where rules are encoded directly into the recurrent networks have shown that prior knowledge does improve the learning speed <ref> [14, 13] </ref>.) RCC accomplishes this by freezing all previous weight values after a new neuron is added.
Reference: [15] <author> M. Goudreau, C. Giles, S. Chakradhar, and D. Chen, </author> <title> "First-order vs. second-order single layer recurrent neural networks," </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 5, no. 3, </volume> <pages> pp. 511-513, </pages> <year> 1994. </year>
Reference-contexts: As the size of network grows, so does the size of the FSA it can represent. Thus, any simple expanding network that is "fully-connected" and large enough should be able to represent (or load) any FSA <ref> [1, 15] </ref>. The importance of using prior knowledge in neural network learning has been described by many, see the discussion by Shavlik [34]. Our further assumption is that prior knowledge gained from early training is important to effectively maintain some of the network's earlier knowledge.
Reference: [16] <author> S. J. Hanson, </author> <title> "Meiosis networks," </title> <booktitle> in Advances in Neural Information Processing Systems, </booktitle> <volume> vol. 2, </volume> <pages> pp. 533-541, </pages> <year> 1990. </year>
Reference-contexts: We propose an alternative method which eliminates these limitations. 2 Constructive Learning A constructive method dynamically grows the network structure during the network's training. Various constructive methods have been studied and various types of network growing methods have been proposed <ref> [2, 4, 6, 9, 10, 16, 20, 25, 26, 33, 37] </ref>. A good review of some of these algorithms is found in [19].
Reference: [17] <author> S. A. Harp, T. Samad, and A. Guha, </author> <title> "Designing application-specific neural works using the genetic algorithm," </title> <booktitle> in Advances in Neural Information Processing Systems 2 (D. </booktitle> <editor> Touretzky, ed.), </editor> <address> (San Mateo, CA), </address> <pages> pp. 447-454, </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1990. </year> <month> 13 </month>
Reference: [18] <author> B. Hassibi and D. G. Stork, </author> <title> "Second order derivatives for network pruning: Optimal brain surgeon," </title> <booktitle> in Advances in Neural Information Processing Systems 5 (S. </booktitle> <editor> Hanson, J. Cowan, and C. Giles, eds.), </editor> <address> (San Mateo, CA), </address> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1993. </year>
Reference-contexts: Approaches include removing the smallest magnitude or insensitive weights or by adding a penalty term to the energy function to encourage weight decay. A recent approach, Optimal Brain Surgery <ref> [18] </ref>, slightly adjusts the remaining weights after other weights are removed. * Finally, there are constructive or growth methods where the network starts with a small size and grows when needed. The obvious advantage of this method is that it might require less computation than the destructive methods.
Reference: [19] <author> J. Hertz, A. Krogh, and R. Palmer, </author> <title> Introduction to the Theory of Neural Computation. </title> <address> Redwood City, CA: </address> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <year> 1991. </year>
Reference-contexts: Various constructive methods have been studied and various types of network growing methods have been proposed [2, 4, 6, 9, 10, 16, 20, 25, 26, 33, 37]. A good review of some of these algorithms is found in <ref> [19] </ref>. To our knowledge "all" constructive methods with the exception of recurrent cascade-correlation [7] are for feed-forward networks. 2.1 Recurrent Cascade-Correlation Recurrent cascade-correlation (RCC) is a "recurrent version" of cascade-correlation (CC). We first review the Cascade-Correlation constructive algorithm (figure 1). <p> Another way to do this is to set the new weights to very small values or zero; thus causing the newly added neurons to initially have little or no effect on training. 3 Simple Dynamically-Driven Recurrent Network We briefly review recurrent networks; for a more thorough discussion see <ref> [19, 22] </ref>. A simple dynamically-driven recurrent neural network (RNN) consists of three parts: input layer, a simple recurrent layer and output layer [5]. We term the recurrent network "driven" to denote that it responds temporally to inputs. <p> There are many recurrent training algorithms; for a discussion see <ref> [19, 22] </ref>. 4 Limitations of the Recurrent Cascade-Correlation Architec ture Recurrent Cascade-Correlation (RCC) is illustrated in (figure 2). Regardless of the training procedure, it differs from a fully-connected recurrent network in the sense that direct recurrent connections from the newly-added neurons to the old neurons are restricted - i.e. nonexistent.
Reference: [20] <author> Y. Hirose, K. Yamashita, and S. Hijiya, </author> <title> "Back-propagation algorithm which varies the number of hidden units," </title> <booktitle> Neural Networks, </booktitle> <volume> vol. 4, </volume> <pages> pp. 61-66, </pages> <year> 1991. </year>
Reference-contexts: We propose an alternative method which eliminates these limitations. 2 Constructive Learning A constructive method dynamically grows the network structure during the network's training. Various constructive methods have been studied and various types of network growing methods have been proposed <ref> [2, 4, 6, 9, 10, 16, 20, 25, 26, 33, 37] </ref>. A good review of some of these algorithms is found in [19].
Reference: [21] <author> J. Hopcroft and J. Ullman, </author> <title> Introduction to Automata Theory, </title> <booktitle> Languages, and Computation. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <year> 1979. </year>
Reference-contexts: We will show that this type of structure with a monotone (eg. sigmoid) updating function has only limited memory and is not capable of representing all finite state automata (FSA) <ref> [21] </ref>. (In this paper all FSA are deterministic.) We contend that the representation and learning of finite state automata is representative of a class of problems that are of interest in real-world problems, such as VLSI design or speech processing.
Reference: [22] <author> D. Hush and B. </author> <title> Horne, "Progress in supervised neural networks," </title> <journal> IEEE Signal Processing Magazine, </journal> <volume> vol. 10, no. 1, </volume> <pages> pp. 8-39, </pages> <year> 1993. </year>
Reference-contexts: Another way to do this is to set the new weights to very small values or zero; thus causing the newly added neurons to initially have little or no effect on training. 3 Simple Dynamically-Driven Recurrent Network We briefly review recurrent networks; for a more thorough discussion see <ref> [19, 22] </ref>. A simple dynamically-driven recurrent neural network (RNN) consists of three parts: input layer, a simple recurrent layer and output layer [5]. We term the recurrent network "driven" to denote that it responds temporally to inputs. <p> There are many recurrent training algorithms; for a discussion see <ref> [19, 22] </ref>. 4 Limitations of the Recurrent Cascade-Correlation Architec ture Recurrent Cascade-Correlation (RCC) is illustrated in (figure 2). Regardless of the training procedure, it differs from a fully-connected recurrent network in the sense that direct recurrent connections from the newly-added neurons to the old neurons are restricted - i.e. nonexistent.
Reference: [23] <author> E. Jackson, </author> <title> Perspectives of Nonlinear Dynamics, </title> <booktitle> vol. 1, </booktitle> <address> p. 149. Cambridge, UK: </address> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: A fixed point is simply a period-1 point <ref> [23] </ref>. Assume a and b are two neighboring fixed points of a monotonically increasing function f (x). In (a; b), either f (x) is always &gt; x or f (x) is always &lt; x.
Reference: [24] <author> S. Kleene, </author> <title> "Representation of events in nerve nets and finite automata," in Automata Studies (C. </title> <editor> Shan-non and J. McCarthy, </editor> <booktitle> eds.), </booktitle> <pages> pp. 3-42, </pages> <address> Princeton, N.J.: </address> <publisher> Princeton University Press, </publisher> <year> 1956. </year>
Reference-contexts: However, the recurrent layer is permitted to expand whenever needed and to keep its "full" connectivity. The only criterion for expansion is that the network spend some time learning. Previous work <ref> [24, 28] </ref> has shown that a large enough fully-connected, hard-threshold neuron recurrent network is capable of representing any finite state automaton and, more recently, with sigmoid-like neurons even more powerful 9 automaton [35]. As the size of network grows, so does the size of the FSA it can represent.
Reference: [25] <author> M. Marchand, M. Golea, and P. Rujan, </author> <title> "A convergence theorem for sequential learning in two-layer perceptrons," </title> <journal> Europhysics Letters, </journal> <volume> vol. 11, </volume> <editor> p. </editor> <volume> 487, </volume> <year> 1990. </year>
Reference-contexts: We propose an alternative method which eliminates these limitations. 2 Constructive Learning A constructive method dynamically grows the network structure during the network's training. Various constructive methods have been studied and various types of network growing methods have been proposed <ref> [2, 4, 6, 9, 10, 16, 20, 25, 26, 33, 37] </ref>. A good review of some of these algorithms is found in [19].
Reference: [26] <author> M. Mezard and J.-P. Nadal, </author> <title> "Learning in feedforward layered networks: The tiling algorithm," </title> <journal> Journal of Physics, </journal> <volume> vol. 21, </volume> <editor> p. </editor> <volume> 2191, </volume> <year> 1989. </year>
Reference-contexts: We propose an alternative method which eliminates these limitations. 2 Constructive Learning A constructive method dynamically grows the network structure during the network's training. Various constructive methods have been studied and various types of network growing methods have been proposed <ref> [2, 4, 6, 9, 10, 16, 20, 25, 26, 33, 37] </ref>. A good review of some of these algorithms is found in [19].
Reference: [27] <author> C. Miller and C. Giles, </author> <title> "Experimental comparison of the effect of order in recurrent neural networks," </title> <journal> International Journal of Pattern Recognition and Artifical Intelligence, </journal> <volume> vol. 7, no. 4, </volume> <pages> pp. 849-872, </pages> <year> 1993. </year> <title> Special Issue on Neural Networks and Pattern Recognition, </title> <editor> editors: I. Guyon , P.S.P. </editor> <publisher> Wang. </publisher>
Reference-contexts: However, the network topology directly affects the two most important factors of neural network training, e.g. generalization and training fl Published in IEEE Transactions on Neural Networks vol.6, no. 4, p. 829, 1995. Copyright IEEE. 1 time. Both theoretical studies [38] and simulations <ref> [27] </ref> show that larger than necessary networks tend to overfit the training data and thus have poor generalization; while too small a network will have difficulty learning the training samples. In general a large network will also require more computation than a smaller one. <p> It is also possible to combine constructive and destructive methods. Recurrent Neural Networks have ability to process and store temporal information and sequential signals. For example recent work has shown that various recurrent networks are able to infer small regular grammars from examples <ref> [3, 11, 27, 36, 40] </ref>. However, one of the problems associated with recurrent networks is that the training scales badly with both network and problem size [41]. The convergence time can be very slow and 2 training errors are not always guaranteed to reduce to previously defined tolerances.
Reference: [28] <author> M. Minsky, </author> <title> Computation: Finite and Infinite Machines. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall, Inc., </publisher> <year> 1967. </year> <title> Ch: Neural Networks. Automata Made up of Parts. </title>
Reference-contexts: However, the recurrent layer is permitted to expand whenever needed and to keep its "full" connectivity. The only criterion for expansion is that the network spend some time learning. Previous work <ref> [24, 28] </ref> has shown that a large enough fully-connected, hard-threshold neuron recurrent network is capable of representing any finite state automaton and, more recently, with sigmoid-like neurons even more powerful 9 automaton [35]. As the size of network grows, so does the size of the FSA it can represent.
Reference: [29] <author> M. C. Mozer and P. Smolensky, </author> <title> "Skeletonization: A technique for trimming the fat from a network via relevance assessment," </title> <journal> Connection Science, </journal> <volume> vol. 11, </volume> <pages> pp. 3-26, </pages> <year> 1989. </year>
Reference: [30] <author> O. Nerrand, P. Roussel-Ragot, G. D. L. Personnaz, and S. Marcos, </author> <title> "Neural networks and non-linear adaptive filtering: Unifying concepts and new algorithms," </title> <journal> Neural Computation, </journal> <volume> vol. 5, </volume> <pages> pp. 165-197, </pages> <year> 1993. </year>
Reference-contexts: This memory mechanism allows the recurrent network to handle temporal information of arbitrary length. This system process is similar to that of a finite state automata (FSA) in that the network only keeps the "state" information of the last time step <ref> [30] </ref>. Connections between layers can be first, second, or even higher orders [11, 32, 40].
Reference: [31] <author> T. Parker and L. Chua, </author> <title> Practical Numerical Algorithms for Chaotic Systems, </title> <editor> p. </editor> <address> 4. New York, N.Y.: </address> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: Again, an example of a FSA that RCC could not represent is Tomita-6, a FSA with a 8 3-cycle subcomponent. It is arguable that the RCC network can have more complex dynamics during the transient period <ref> [31] </ref>. (For most simulations, this period is very short, usually a few time steps.) The transient period is the time before the neuron's activation value reaches its period point. But for the neural network to correctly represent the FSA, it must recognize arbitrarily long input strings.
Reference: [32] <author> J. Pollack, </author> <title> "The induction of dynamical recognizers," </title> <journal> Machine Learning, </journal> <volume> vol. 7, no. 2/3, </volume> <pages> pp. 227-252, </pages> <year> 1991. </year>
Reference-contexts: This system process is similar to that of a finite state automata (FSA) in that the network only keeps the "state" information of the last time step [30]. Connections between layers can be first, second, or even higher orders <ref> [11, 32, 40] </ref>.
Reference: [33] <author> D. L. Reilly, C. Scofield, C. Elbaum, and L. N. Cooper, </author> <title> "Learning system architetures composed of multiple learning modules," </title> <booktitle> in Proceedings of the IEEE First International Conference On Neural Networks, </booktitle> <address> (San Diego), </address> <year> 1987. </year>
Reference-contexts: We propose an alternative method which eliminates these limitations. 2 Constructive Learning A constructive method dynamically grows the network structure during the network's training. Various constructive methods have been studied and various types of network growing methods have been proposed <ref> [2, 4, 6, 9, 10, 16, 20, 25, 26, 33, 37] </ref>. A good review of some of these algorithms is found in [19].
Reference: [34] <author> J. W. Shavlik, </author> <title> "Combining symbolic and neural learning," </title> <journal> Machine Learning, </journal> <volume> vol. 4, no. 3, </volume> <editor> p. </editor> <volume> 321, </volume> <year> 1994. </year>
Reference-contexts: Thus, any simple expanding network that is "fully-connected" and large enough should be able to represent (or load) any FSA [1, 15]. The importance of using prior knowledge in neural network learning has been described by many, see the discussion by Shavlik <ref> [34] </ref>. Our further assumption is that prior knowledge gained from early training is important to effectively maintain some of the network's earlier knowledge. To do this we require the network to be "expanded smoothly," i.e. the newly added weights should be zero or very small random numbers.
Reference: [35] <author> H. Siegelmann and E. Sontag, </author> <title> "Turing computability with neural nets," </title> <journal> Applied Mathematics Letters, </journal> <volume> vol. 4, no. 6, </volume> <pages> pp. 77-80, </pages> <year> 1991. </year>
Reference-contexts: The only criterion for expansion is that the network spend some time learning. Previous work [24, 28] has shown that a large enough fully-connected, hard-threshold neuron recurrent network is capable of representing any finite state automaton and, more recently, with sigmoid-like neurons even more powerful 9 automaton <ref> [35] </ref>. As the size of network grows, so does the size of the FSA it can represent. Thus, any simple expanding network that is "fully-connected" and large enough should be able to represent (or load) any FSA [1, 15].
Reference: [36] <author> H. Siegelmann, E. Sontag, and C. Giles, </author> <title> "The complexity of language recognition by neural networks," </title> <booktitle> in Algorithms, Software, Architecture Information Processing 92, </booktitle> <volume> Vol 1 (J. </volume> <editor> van Leeuwen, </editor> <publisher> ed.), </publisher> <pages> pp. 329-335, </pages> <address> Amsterdam, The Netherlands: </address> <publisher> Elsevier Science, </publisher> <year> 1992. </year>
Reference-contexts: It is also possible to combine constructive and destructive methods. Recurrent Neural Networks have ability to process and store temporal information and sequential signals. For example recent work has shown that various recurrent networks are able to infer small regular grammars from examples <ref> [3, 11, 27, 36, 40] </ref>. However, one of the problems associated with recurrent networks is that the training scales badly with both network and problem size [41]. The convergence time can be very slow and 2 training errors are not always guaranteed to reduce to previously defined tolerances. <p> However, by avoiding training all different size networks, the constructive method does appear to save time in finding the smallest size network for each of these grammars. Table 1 compares the minimum network size found by trail and error <ref> [36] </ref> for each of Tomita's grammars and the various sizes of the networks trained by our constructive method for 5 different runs with random initial conditions. The number of neurons required for the "trail and error" method and the constructive method described above is comparable.
Reference: [37] <author> J.-A. Sirat and J.-P. Nadal, </author> <title> "Neural tree: A new tool for classification," </title> <type> tech. rep., </type> <institution> Laboratories d'Electronique Philips, Limeil-Brevannes, France, </institution> <year> 1990. </year>
Reference-contexts: We propose an alternative method which eliminates these limitations. 2 Constructive Learning A constructive method dynamically grows the network structure during the network's training. Various constructive methods have been studied and various types of network growing methods have been proposed <ref> [2, 4, 6, 9, 10, 16, 20, 25, 26, 33, 37] </ref>. A good review of some of these algorithms is found in [19].
Reference: [38] <author> S. Solla, </author> <title> "Capacity control in classifiers for pattern recognition," in Neural Networks for Signal Processing II, </title> <booktitle> Proceedings of The 1992 IEEE Workshop (S. </booktitle> <editor> Kung, F. Fallside, J. A. Sorenson, and C. Kamm, </editor> <booktitle> eds.), </booktitle> <pages> pp. 255-266, </pages> <publisher> IEEE Press, </publisher> <year> 1992. </year>
Reference-contexts: However, the network topology directly affects the two most important factors of neural network training, e.g. generalization and training fl Published in IEEE Transactions on Neural Networks vol.6, no. 4, p. 829, 1995. Copyright IEEE. 1 time. Both theoretical studies <ref> [38] </ref> and simulations [27] show that larger than necessary networks tend to overfit the training data and thus have poor generalization; while too small a network will have difficulty learning the training samples. In general a large network will also require more computation than a smaller one.
Reference: [39] <author> M. Tomita, </author> <title> "Dynamic construction of finite-state automata from examples using hill-climbing," </title> <booktitle> in Proceedings of the Fourth Annual Cognitive Science Conference, </booktitle> <address> (Ann Arbor, Mi), </address> <pages> pp. 105-108, </pages> <year> 1982. </year>
Reference-contexts: From above proof, the simplest subcomponent of a FSA 7 that RCC cannot represent is the 3-cycle digraph shown in figure 4. An example of such a FSA with this subcomponent is the (Tomita-6) automaton <ref> [39] </ref>. 4.2 Sigmoid Neurons We now prove for a monotonic activation function RCC is not capable of representing some finite state automata. The limitations of RCC can be shown by studying the network's dynamics. First we show a well known result from nonlinear dynamics. <p> Thus, 10 if the resultant network has 5 neurons, it trained for 200 epochs. Again, this will probably generate a slightly larger network than that generated by a more sophisticated growth criterion. In training very small grammars (those of <ref> [39] </ref>), we found that the constructive method quickly converges when the network size grows up to the minimal size required. The convergence time was not significantly less than that for training corresponding fixed-size networks.
Reference: [40] <author> R. Watrous and G. Kuhn, </author> <title> "Induction of finite-state languages using second-order recurrent networks," </title> <journal> Neural Computation, </journal> <volume> vol. 4, no. 3, </volume> <editor> p. </editor> <volume> 406, </volume> <year> 1992. </year>
Reference-contexts: It is also possible to combine constructive and destructive methods. Recurrent Neural Networks have ability to process and store temporal information and sequential signals. For example recent work has shown that various recurrent networks are able to infer small regular grammars from examples <ref> [3, 11, 27, 36, 40] </ref>. However, one of the problems associated with recurrent networks is that the training scales badly with both network and problem size [41]. The convergence time can be very slow and 2 training errors are not always guaranteed to reduce to previously defined tolerances. <p> This system process is similar to that of a finite state automata (FSA) in that the network only keeps the "state" information of the last time step [30]. Connections between layers can be first, second, or even higher orders <ref> [11, 32, 40] </ref>.
Reference: [41] <author> R. Williams and D. Zipser, </author> <title> "Experimental analysis of the real-time recurrent learning algorithm," </title> <journal> Connection Science, </journal> <volume> vol. 1, no. 1, </volume> <pages> pp. 87-111, </pages> <year> 1989. </year>
Reference-contexts: For example recent work has shown that various recurrent networks are able to infer small regular grammars from examples [3, 11, 27, 36, 40]. However, one of the problems associated with recurrent networks is that the training scales badly with both network and problem size <ref> [41] </ref>. The convergence time can be very slow and 2 training errors are not always guaranteed to reduce to previously defined tolerances. Thus, pure destructive--based methods are at a disadvantage since an oversized network must first be trained.
Reference: [42] <author> R. Williams and D. Zipser, </author> <title> "A learning algorithm for continually running fully recurrent neural networks," </title> <journal> Neural Computation, </journal> <volume> vol. 1, no. 2, </volume> <pages> pp. 270-280, </pages> <year> 1989. </year>
Reference-contexts: A typical learning rule might use gradient descent <ref> [42] </ref> to adjust the weights W; U so as to minimize the error function , E = E ( (T 1 ; O 1 ); (T 2 ; O 2 ); ; (T t ; O t ) ); where T t is the desired output at each time step t.

References-found: 42

