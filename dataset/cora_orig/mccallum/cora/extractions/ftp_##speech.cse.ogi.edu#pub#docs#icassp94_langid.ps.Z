URL: ftp://speech.cse.ogi.edu/pub/docs/icassp94_langid.ps.Z
Refering-URL: http://www.cse.ogi.edu/~berkling/vitae.html
Root-URL: http://www.cse.ogi.edu
Title: ANALYSIS OF PHONEME-BASED FEATURES FOR LANGUAGE IDENTIFICATION  
Author: Kay M. Berkling, Takayuki Arai, and Etienne Barnard 
Address: 20000 N.W. Walker Road, P.O. Box 91000, Portland, OR 97291-1000 USA  
Affiliation: Center for Spoken Language Understanding, Oregon Graduate Institute of Science a nd Technology,  
Abstract: This paper presents an analysis of the phonemic language identification system introduced in [5], now extended to recognize German in addition to English and Japanese. In this system language identification is based on features derived from a superset of phonemes of all three languages. As we increase the number of languages, the need to reduce the feature space becomes apparent. Practical analysis of single-feature statistics in conjunction with linguistic knowledge leads to 90% reduction of the feature space with only a 5% loss in performance. Thus, the system discriminates between Japanese and English with 84.1% accuracy based on only 15 features compared to 84.6% based on the complete set of 318 phonemic features (or 83.6% using 333 broad-category features [4]). Results indicate that a language identification system may be designed based on linguistic knowledge and then implemented with a neural network of appropriate complexity. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bernard Comrie. </author> <title> The World's Major Languages. </title> <publisher> Oxford University Press, </publisher> <address> 1 edition, </address> <year> 1990. </year>
Reference-contexts: Mono-phonemes Phonemes known to have different acoustic realizations in the languages to be identified are expected to contribute to the LID process. Below we list some of the mono-phonemes found in our set of three languages <ref> [1] </ref>. English vs.
Reference: [2] <author> P. Dalsgaard and O. Andersen. </author> <title> Identification of mono- and poly-phonemes using acoustic-phonetic features derived by a self-organizing neural network. </title> <booktitle> In International Conference on Spoken Language Processing, </booktitle> <pages> pages 547-550, </pages> <address> Banff, </address> <month> oct </month> <year> 1992. </year>
Reference-contexts: Results obtained with these approaches are reported in section 5 followed by a discussion in section 6. 2. LINGUISTIC BACKGROUND The superset of all phonemes spanning the three languages treated in this paper may be divided into the following two groups <ref> [2] </ref>, 1. mono-phonemes: phonemes whose acoustic realizations in one language overlap little or not at all with those in another language (e.g. the English r vs. the German r). 2. poly-phonemes: phonemes whose acoustic realizations are similar enough across the languages to be equated (e.g. sh in English and German). 2.1.
Reference: [3] <author> Peter Ladefoged. </author> <title> The revised international phonetic alphabet. </title> <journal> Journal of the International Phonetic Association, </journal> <volume> 19(2) </volume> <pages> 67-80, </pages> <year> 1990. </year>
Reference: [4] <author> Y. K. Muthusamy. </author> <title> A Segmental Approach to Automatic Language Identification. </title> <type> PhD thesis, </type> <institution> Oregon Graduate Institute, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: Performance Analysis 5.2.1. Language Identification with Complete Feature Set Table 4 displays system performance using unigram features separately and combined with bigram features. When applicable our approach is compared to that of Zissman [8] (who uses ergodic HMMs) and Muthusamy <ref> [4] </ref> (broad-category segmentation) For trilingual LID a different architecture combining three bilingual experts was also employed in order to let the architecture reflect the structure of the problem (Fig. 2). Performance improved slightly from 73.2% to 74.5% (unigrams only). Classifier Unigrams Uni+Big Muth. Ziss.
Reference: [5] <author> Y. K. Muthusamy, K. Berkling, T. Arai, R. Cole, and E. Barnard. </author> <title> A comparison of approaches to automatic language identification using telephone speech. </title> <booktitle> In Eurospeech, </booktitle> <volume> volume 2, </volume> <pages> pages 1307-1310, </pages> <month> sep </month> <year> 1993. </year>
Reference-contexts: 1. INTRODUCTION In <ref> [5] </ref> we introduced a language-identification system based on phoneme recognition. In that system we employed a separate phonemic front end for each language to be recognized, and computed features based on the outputs of all these front ends. <p> The three features extracted from each output of the first-stage classifiers are the average output activation AVG across the complete utterance, the maximum output activation MAX, and variation in output activation VARH as explained in <ref> [5] </ref>. Bigrams: The frame-by-frame outputs of the English phoneme classifier described above were converted into a time-aligned sequence of the phoneme labels by applying minimum and maximum duration constraints of 3 msec. and 300 msec., respectively, using the abovementioned Viterbi search. <p> The transition probabilities of 200 pairs (chosen for optimal performance <ref> [5] </ref>) were used as input to a neural-net classifier, trained to produce a language classification as output. Combining unigram and bigram features, the input feature vector to the language classifier now consists of the 318 unigram features concatenated with the 200 occurrence frequencies of the most common pairs. 4.
Reference: [6] <author> Y. K. Muthusamy, R. A. Cole, and B. T. Oshika. </author> <title> The OGI multi-language telephone speech corpus. </title> <booktitle> In International Conference on Spoken Language Processing, </booktitle> <pages> pages 895-898, </pages> <month> oct </month> <year> 1992. </year>
Reference-contexts: RESULTS 5.1. Training and test data 5.1.1. Multi-Language Telephone Speech Corpus The classification algorithms were developed and evaluated using the OGI Multi-language Telephone Speech Corpus, described in <ref> [6] </ref>. 1 The labels used here are similar to TIMIT labels. In addition cl stands for closure, xy and xw are dipthongs ending in a closed front vowel and closed back vowel, respectively.
Reference: [7] <author> Y. K. Muthusamy, Neena Jain, and Ronald A. Cole. </author> <title> Perceptual benchmarks for automatic language identification. </title> <booktitle> In International Conference on Speech and Signal Processing, </booktitle> <address> Alberta, Australia, </address> <month> apr </month> <year> 1994. </year>

References-found: 7

