URL: ftp://ftp.cnl.salk.edu/pub/iris/papers/cc.ps.Z
Refering-URL: http://www.cnl.salk.edu/cgi-bin/pub-search/
Root-URL: 
Title: Theory of Correlations in Stochastic Neural Networks  
Author: Iris Ginzburg Beverly and Raymond Sackler Haim Sompolinsky 
Date: 50, 3171-3191  
Note: (1994) Physical Review E.  
Address: Tel-Aviv University, Tel-Aviv 69978, Israel  Jerusalem 91904, Israel  Murray Hill, NJ 07974, USA  
Affiliation: School of Physics and Astronomy  Faculty of Exact Sciences  Racah Institute of Physics and Center for Neural Computation Hebrew University,  and AT&T Bell Laboratories,  
Abstract: One of the main experimental tools in probing the interactions between neurons has been the measurement of the correlations in their activity. In general, however the interpretation of the observed correlations is difficult, since the correlation between a pair of neurons is influenced not only by the direct interaction between them but also by the dynamic state of the entire network to which they belong. Thus, a comparison between the observed correlations and the predictions from specific model networks is needed. In this paper we develop the theory of neuronal correlation functions in large networks comprising of several highly connected subpopulations, and obeying stochastic dynamic rules. When the networks are in asynchronous states, the cross-correlations are relatively weak, i.e., their amplitude relative to that of the auto-correlations is of order of 1=N , N being the size of the interacting populations. Using the weakness of the cross-correlations, general equations which express the matrix of cross-correlations in terms of the mean neuronal activities, and the effective interaction matrix are presented. The effective interactions are the synaptic efficacies multiplied by the the gain of the postsynaptic neurons. The time-delayed cross-correlation matrix can be expressed as a sum of exponentially decaying modes that correspond to the (non-orthogonal) eigenvectors of the effective interaction matrix. The theory is extended to networks with random connectivity, such as randomly dilute networks. This allows for the comparison between the contribution from the internal common input and that from the direct 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Fetz, K. Toyama, and W. Smith, </author> <title> in Cerebral Cortex, edited by A. </title> <editor> Peters and G. </editor> <publisher> Jones (Plenum Press, </publisher> <address> NY, </address> <year> 1991), </year> <note> Vol. 9. </note>
Reference-contexts: 1 Introduction Cross-correlation (CC) measurements are among the major experimental tools for studying the synaptic interactions between neurons. For review of the experimental methods and results see refs. <ref> [1, 2] </ref>. Time-delayed CCs between proximal neurons often exhibit a pronounced delay, and are usually interpreted as resulting from a direct interaction between the correlated pair. The majority of CCs between distal neurons in cortex exhibit a "central peak".
Reference: [2] <author> M. Abeles, Corticonics: </author> <title> Neural Circuits of the Cerebral Cortex (Cambridge University Press, </title> <year> 1991). </year>
Reference-contexts: 1 Introduction Cross-correlation (CC) measurements are among the major experimental tools for studying the synaptic interactions between neurons. For review of the experimental methods and results see refs. <ref> [1, 2] </ref>. Time-delayed CCs between proximal neurons often exhibit a pronounced delay, and are usually interpreted as resulting from a direct interaction between the correlated pair. The majority of CCs between distal neurons in cortex exhibit a "central peak". <p> Moreover, the synchrony may be utilized to encode or transmit information, as suggested by recent studies of spatiotemporal patterns of neuronal responses in olfactory [5, 6], visual [7, 8, 9, 10], and association areas <ref> [2, 11] </ref> in cortex. Lastly, understanding of the correlations in neuronal activity is important for uncovering some of the mechanisms underlying plasticity and learning [12]. Unfortunately, very little is known theoretically about the properties of CCs in large 2 networks. <p> The degree of connectivity is estimated to be roughly 10% <ref> [27, 2] </ref>. Hence we set f kl = 0:1 for all kl. The model neurons have two possible states, 0 or 1, corresponding to a quiet state and an active one, respectively. <p> The integral over time can be approximated by the peak value of the EPSP, which is in the range of 0:1 0:5 mV, times the typical synaptic integration time, which we take to be approximately 10 msec [27]. Since one neuron receives about 5; 000 excitatory synapses <ref> [2] </ref>, J EE and J IE should lie in the range of 1000 5000 mV. Although the number of inhibitory synapses is approximately 0:1 of that of the excitatory synapses, their IPSP is larger than the EPSP.
Reference: [3] <author> K. H. Britten, M. N. Shadlen, W. T. Newsome, and J. A. Movshon, J. Neurosci. </author> <year> (1993). </year>
Reference-contexts: Neuronal correlations serve as convenient measure of the temporal synchrony of the activities of neurons. This synchrony may have important implications on the function of the network. First, it affects the utility of using population codes to overcome the noise in the neural responses to external stimuli <ref> [3, 4] </ref>. Moreover, the synchrony may be utilized to encode or transmit information, as suggested by recent studies of spatiotemporal patterns of neuronal responses in olfactory [5, 6], visual [7, 8, 9, 10], and association areas [2, 11] in cortex.
Reference: [4] <author> H. S. Seung and H. Sompolinsky, </author> <title> Neuronal correlations and population codes, </title> <note> to appear. </note>
Reference-contexts: Neuronal correlations serve as convenient measure of the temporal synchrony of the activities of neurons. This synchrony may have important implications on the function of the network. First, it affects the utility of using population codes to overcome the noise in the neural responses to external stimuli <ref> [3, 4] </ref>. Moreover, the synchrony may be utilized to encode or transmit information, as suggested by recent studies of spatiotemporal patterns of neuronal responses in olfactory [5, 6], visual [7, 8, 9, 10], and association areas [2, 11] in cortex.
Reference: [5] <author> C. A. Skarda and W. J. Freeman, </author> <type> Behav. </type> <institution> Brain Sci. </institution> <month> 10 161 </month> <year> (1987). </year>
Reference-contexts: First, it affects the utility of using population codes to overcome the noise in the neural responses to external stimuli [3, 4]. Moreover, the synchrony may be utilized to encode or transmit information, as suggested by recent studies of spatiotemporal patterns of neuronal responses in olfactory <ref> [5, 6] </ref>, visual [7, 8, 9, 10], and association areas [2, 11] in cortex. Lastly, understanding of the correlations in neuronal activity is important for uncovering some of the mechanisms underlying plasticity and learning [12]. Unfortunately, very little is known theoretically about the properties of CCs in large 2 networks.
Reference: [6] <author> Z. Li and J. J. </author> <title> Hopfield, </title> <journal> Biol. Cybern. </journal> <volume> 61 379 (1989). </volume>
Reference-contexts: First, it affects the utility of using population codes to overcome the noise in the neural responses to external stimuli [3, 4]. Moreover, the synchrony may be utilized to encode or transmit information, as suggested by recent studies of spatiotemporal patterns of neuronal responses in olfactory <ref> [5, 6] </ref>, visual [7, 8, 9, 10], and association areas [2, 11] in cortex. Lastly, understanding of the correlations in neuronal activity is important for uncovering some of the mechanisms underlying plasticity and learning [12]. Unfortunately, very little is known theoretically about the properties of CCs in large 2 networks. <p> Networks similar to the present one have been studied previously, mainly in the context of the possible generation of coherent oscillations <ref> [25, 26, 6, 10] </ref>. Here we focus on the case of a stable fixed point with low rates. There are two population-averaged activities, S E , S I , for excitatory and inhibitory populations, respectively. <p> Examples are systems that code for orientation or direction of sensory or motor signals [36]. In addition, in some cases operating near a bifurcation point may be functionally important, such as in the case of olfaction <ref> [6] </ref> or the vestibuoccular system [37]. Learning mechanism may be responsible for maintaining these systems near the bifurcation point [37, 38]. The above 31 theory can then be used to predict the behavior of the dominant mode of fluctuations.
Reference: [7] <author> C. M. Gray, P. Konig, A. K. Engel, and W. Singer, </author> <booktitle> Nature (London) 338, </booktitle> <month> 334 </month> <year> (1989). </year>
Reference-contexts: First, it affects the utility of using population codes to overcome the noise in the neural responses to external stimuli [3, 4]. Moreover, the synchrony may be utilized to encode or transmit information, as suggested by recent studies of spatiotemporal patterns of neuronal responses in olfactory [5, 6], visual <ref> [7, 8, 9, 10] </ref>, and association areas [2, 11] in cortex. Lastly, understanding of the correlations in neuronal activity is important for uncovering some of the mechanisms underlying plasticity and learning [12]. Unfortunately, very little is known theoretically about the properties of CCs in large 2 networks.
Reference: [8] <editor> R. Eckhorn et al. Biol. Cybern. </editor> <volume> 60, </volume> <month> 121 </month> <year> (1988). </year>
Reference-contexts: First, it affects the utility of using population codes to overcome the noise in the neural responses to external stimuli [3, 4]. Moreover, the synchrony may be utilized to encode or transmit information, as suggested by recent studies of spatiotemporal patterns of neuronal responses in olfactory [5, 6], visual <ref> [7, 8, 9, 10] </ref>, and association areas [2, 11] in cortex. Lastly, understanding of the correlations in neuronal activity is important for uncovering some of the mechanisms underlying plasticity and learning [12]. Unfortunately, very little is known theoretically about the properties of CCs in large 2 networks.
Reference: [9] <author> H. Sompolinsky, D. Golomb, and D. Kleinfeld, </author> <booktitle> Proc. </booktitle> <institution> Natl. Acad. Sci. USA 87 7200 (1990); Phys. </institution> <note> Rev. A 15 43 6990 (1991). </note>
Reference-contexts: First, it affects the utility of using population codes to overcome the noise in the neural responses to external stimuli [3, 4]. Moreover, the synchrony may be utilized to encode or transmit information, as suggested by recent studies of spatiotemporal patterns of neuronal responses in olfactory [5, 6], visual <ref> [7, 8, 9, 10] </ref>, and association areas [2, 11] in cortex. Lastly, understanding of the correlations in neuronal activity is important for uncovering some of the mechanisms underlying plasticity and learning [12]. Unfortunately, very little is known theoretically about the properties of CCs in large 2 networks. <p> Finally, although we have focussed here only on asynchronous states, analytic calculation of the correlation functions in certain synchronous states may be possible. An example is the case of stochastic phase oscillators studied in refs. <ref> [9, 10] </ref>. Thus, generalizing the present approach to calculate the correlation functions of weakly synchronized states in systems with mean-field architecture is an important challenge for future research. Acknowledgement We are grateful to M.
Reference: [10] <author> E. Grannan D. Kleinfeld, and H. </author> <title> Sompolinsky, </title> <journal> Neural Comput. </journal> <volume> 4, </volume> <month> 550 </month> <year> (1992). </year>
Reference-contexts: First, it affects the utility of using population codes to overcome the noise in the neural responses to external stimuli [3, 4]. Moreover, the synchrony may be utilized to encode or transmit information, as suggested by recent studies of spatiotemporal patterns of neuronal responses in olfactory [5, 6], visual <ref> [7, 8, 9, 10] </ref>, and association areas [2, 11] in cortex. Lastly, understanding of the correlations in neuronal activity is important for uncovering some of the mechanisms underlying plasticity and learning [12]. Unfortunately, very little is known theoretically about the properties of CCs in large 2 networks. <p> Networks similar to the present one have been studied previously, mainly in the context of the possible generation of coherent oscillations <ref> [25, 26, 6, 10] </ref>. Here we focus on the case of a stable fixed point with low rates. There are two population-averaged activities, S E , S I , for excitatory and inhibitory populations, respectively. <p> Finally, although we have focussed here only on asynchronous states, analytic calculation of the correlation functions in certain synchronous states may be possible. An example is the case of stochastic phase oscillators studied in refs. <ref> [9, 10] </ref>. Thus, generalizing the present approach to calculate the correlation functions of weakly synchronized states in systems with mean-field architecture is an important challenge for future research. Acknowledgement We are grateful to M.
Reference: [11] <author> M. Abeles, H. Bergman, E. Margalit, and E. Vaadia, J. Neurophysiol. </author> <month> 70, </month> <year> (1993). </year>
Reference-contexts: Moreover, the synchrony may be utilized to encode or transmit information, as suggested by recent studies of spatiotemporal patterns of neuronal responses in olfactory [5, 6], visual [7, 8, 9, 10], and association areas <ref> [2, 11] </ref> in cortex. Lastly, understanding of the correlations in neuronal activity is important for uncovering some of the mechanisms underlying plasticity and learning [12]. Unfortunately, very little is known theoretically about the properties of CCs in large 2 networks.
Reference: [12] <author> E. Ahissar, E. Vaadia, M. Ahissar, H. Bergman, A. Arieli, and M. Abeles, </author> <note> Science 257, 1412 (1992) </note>
Reference-contexts: Lastly, understanding of the correlations in neuronal activity is important for uncovering some of the mechanisms underlying plasticity and learning <ref> [12] </ref>. Unfortunately, very little is known theoretically about the properties of CCs in large 2 networks. Hence, the interpretation of the observed features of the CCs remains an open challenge, and is the topic of this paper.
Reference: [13] <author> I. Ginzburg and H. Sompolinsky, </author> <title> Correlation Functions on a Large Stochastic Neural Network, </title> <booktitle> Advances in Neural Information Processing systems edited by J. </booktitle> <editor> D. Cowan, G. Tesauro, and J. Alspector, </editor> <publisher> (Morgan Kaufmann, </publisher> <year> 1994), </year> <note> Vol. 6. </note>
Reference-contexts: In Section 9 we apply the general theory to a randomly diluted network composed of excitatory and inhibitory populations. The results of the paper are discussed in Section 10. Preliminary results of part of the work has been reported in Ref. <ref> [13] </ref>. 2 Asynchronous states in large networks In most of the interesting neural networks, the degree of connectivity is such that the overwhelming majority of the neurons are interacting at least indirectly, the temporal fluctuations in their activity will always be at least partially correlated.
Reference: [14] <author> S. Kirkpatrick and D. </author> <title> Sherrington, </title> <journal> Phys. Rev. </journal> <volume> B17, </volume> <month> 4384 </month> <year> (1978). </year>
Reference-contexts: There are special circumstances in which the correlations are larger than that of Eq. (2.2), even in asynchronous states. An example is the case where there is a precise balance between positive and negative connections in the networks. Such is the case in infinite-range spin-glasses <ref> [14] </ref> or in the Hopfield model of associative memory near saturation [15].
Reference: [15] <author> D. J. Amit, H. Gutfreund, and H. Sompolinsky, Annal. </author> <title> Phys. </title> <address> NY. 173, </address> <month> 30 </month> <year> (1987). </year>
Reference-contexts: An example is the case where there is a precise balance between positive and negative connections in the networks. Such is the case in infinite-range spin-glasses [14] or in the Hopfield model of associative memory near saturation <ref> [15] </ref>. In these cases, the connections and the CCs scale as C / p ; N ! 1 (2:3) However, the mean-field theory of these networks, even for the average activities, is complicated, and is outside the scope of the present work.
Reference: [16] <author> T. Bohr, G. Grinstein, Y. He, and C. </author> <title> Jayaprakash, </title> <journal> Phys. Rev. Lett. </journal> <volume> 58, </volume> <month> 558 </month> <year> (1987). </year>
Reference-contexts: Synchronous states can appear in both short-range and long-range systems. However, in large short-range systems, stable synchronous states are in most cases periodic or quasiperiodic; stable chaotic synchronized states are rare <ref> [16, 17] </ref>. On the other hand systems with long-range interactions can have periodic or chaotic synchronous states. The nature of the correlations in synchronous states in fully connected networks are discussed elsewhere [18].
Reference: [17] <author> I. Aranson, D. Golomb, and H. </author> <title> Sompolinsky, </title> <journal> Phys. Rev. Lett. </journal> <volume> 68, </volume> <month> 3495 </month> <year> (1992). </year> <month> 37 </month>
Reference-contexts: Synchronous states can appear in both short-range and long-range systems. However, in large short-range systems, stable synchronous states are in most cases periodic or quasiperiodic; stable chaotic synchronized states are rare <ref> [16, 17] </ref>. On the other hand systems with long-range interactions can have periodic or chaotic synchronous states. The nature of the correlations in synchronous states in fully connected networks are discussed elsewhere [18].
Reference: [18] <author> D. Hansel and H. </author> <title> Sompolinsky, </title> <journal> Phys. Rev. Lett. </journal> <volume> 68, </volume> <month> 718 </month> <year> (1992), </year> <note> and to appear. </note>
Reference-contexts: On the other hand systems with long-range interactions can have periodic or chaotic synchronous states. The nature of the correlations in synchronous states in fully connected networks are discussed elsewhere <ref> [18] </ref>. The above characterization of asynchronous states is difficult to check in experimental systems, since it requires reliable estimates of such parameters as the size of the network and the strength of connections. An alternative characterization is based on the behavior of population averages.
Reference: [19] <author> N. G. Van Kampen, </author> <title> Stochastic Processes in Physics and Chemistry (North Holland, </title> <year> 1981). </year>
Reference-contexts: Throughout the work we will assume that there is no self-coupling, i.e., that J ij = 0. The above transition rates define a first order Markov process <ref> [19] </ref>.
Reference: [20] <author> R.J. </author> <title> Glauber, </title> <journal> J. Math. Phys. </journal> <volume> 4, </volume> <month> 294 </month> <year> (1963). </year>
Reference-contexts: i ; : : : S N ; t) : 3.2 General equations for averages and correlations Using the above Master equation, a hierarchy of equations for the time-evolution of moments of fS i g can be derived in a manner similar to that used in models with thermal equilibrium <ref> [20, 21] </ref>. Here we present the equations for the first and second moments. For derivation of these equations see Appendix A. <p> Our theory is an extension of the mean-field theory of the Kinetic Ising models near thermal equilibrium <ref> [21, 20, 30] </ref>. The systems studied here do not obey the detailed-balance conditions, hence their statistics is not described by thermal equilibrium.
Reference: [21] <author> M. Suzuki and R. Kubo, J. </author> <title> Phys. </title> <publisher> Soc. </publisher> <address> Japan 24, </address> <month> 51 </month> <year> (1968). </year>
Reference-contexts: i ; : : : S N ; t) : 3.2 General equations for averages and correlations Using the above Master equation, a hierarchy of equations for the time-evolution of moments of fS i g can be derived in a manner similar to that used in models with thermal equilibrium <ref> [20, 21] </ref>. Here we present the equations for the first and second moments. For derivation of these equations see Appendix A. <p> Our theory is an extension of the mean-field theory of the Kinetic Ising models near thermal equilibrium <ref> [21, 20, 30] </ref>. The systems studied here do not obey the detailed-balance conditions, hence their statistics is not described by thermal equilibrium. <p> Using Eq. (A.1), we obtain t 0 dt A similar derivation for a system at thermal equilibrium is is presented in <ref> [21] </ref>. Using Eqs. (A.8) and (3.4) one obtains the result of Eq. (3.7). 34 B Appendix B In this Appendix we derive approximations of the results of Appendix A which are exact for highly connected networks in the limit of large networks.
Reference: [22] <author> J. Guckenheimer and P. Holmes, </author> <title> Nonlinear oscillations, dynamic systems, and bifurcations of vector fields (Springer, </title> <address> New York, </address> <year> 1983). </year>
Reference-contexts: Our analysis shows that in this case, the system will exhibit anomalously large fluctuations about the (stable) fixed point, and the fluctuations will have anomalously long correlation time. Let us suppose that the system is near a saddle-node bifurcation, which is characterized by a single critical mode <ref> [22] </ref>. In this case, at the bifurcation point, 1 = 1 while 0 - &lt; 1 for - &gt; 1. <p> The range ff &lt; 0 corresponds to the regime where the low rate fixed point becomes unstable. The Hopf bifurcation at Eq. (9.26) is a super-critical Hopf bifurcation <ref> [22] </ref>, meaning that the stable fixed point is surrounded by an unstable limit cycle that collapses onto the fixed point as ff decreases to 0. This is shown in Fig. 7. where we plot the unstable limit cycle that surrounds the fixed-point, for ff = 0:05 and 0:03.
Reference: [23] <author> K. Binder and D. N. Heerman, </author> <title> Monte Carlo Simulation in Statistical Physics (Springer-Verlag, </title> <address> Berlin, </address> <year> 1988). </year>
Reference-contexts: The actual magnitude of the equal-time CCs at the bifurcation point depends on the nature of the bifurcation. On the basis of finite-size scaling arguments <ref> [23, 24] </ref> it is expected that at a saddle-node bifurcation or a super-critical Hopf bifurcation the correlations grow to C (0) = O (1) ; * 0 : (7:3) On the other hand, it is expected that a subcritical Hopf bifurcation, the correlations grow only to C (0) = O (1=
Reference: [24] <author> H. Sompolinsky, </author> <note> unpublished. </note>
Reference-contexts: The actual magnitude of the equal-time CCs at the bifurcation point depends on the nature of the bifurcation. On the basis of finite-size scaling arguments <ref> [23, 24] </ref> it is expected that at a saddle-node bifurcation or a super-critical Hopf bifurcation the correlations grow to C (0) = O (1) ; * 0 : (7:3) On the other hand, it is expected that a subcritical Hopf bifurcation, the correlations grow only to C (0) = O (1=
Reference: [25] <author> H. R. Wilson and J. D. Cowan, Biophy. J. </author> <month> 12, 1 </month> <year> (1972). </year>
Reference-contexts: Networks similar to the present one have been studied previously, mainly in the context of the possible generation of coherent oscillations <ref> [25, 26, 6, 10] </ref>. Here we focus on the case of a stable fixed point with low rates. There are two population-averaged activities, S E , S I , for excitatory and inhibitory populations, respectively.
Reference: [26] <author> H. G. Schuster and P. </author> <title> Wagner, </title> <journal> Biol. Cybern. </journal> <volume> 64, </volume> <month> 77 </month> <year> (1990). </year>
Reference-contexts: Networks similar to the present one have been studied previously, mainly in the context of the possible generation of coherent oscillations <ref> [25, 26, 6, 10] </ref>. Here we focus on the case of a stable fixed point with low rates. There are two population-averaged activities, S E , S I , for excitatory and inhibitory populations, respectively.
Reference: [27] <author> A. Mason, A. Nicoll, and K. Stratford, J. Neurosci. </author> <month> 11, 72 </month> <year> (1991). </year>
Reference-contexts: The degree of connectivity is estimated to be roughly 10% <ref> [27, 2] </ref>. Hence we set f kl = 0:1 for all kl. The model neurons have two possible states, 0 or 1, corresponding to a quiet state and an active one, respectively. <p> The integral over time can be approximated by the peak value of the EPSP, which is in the range of 0:1 0:5 mV, times the typical synaptic integration time, which we take to be approximately 10 msec <ref> [27] </ref>. Since one neuron receives about 5; 000 excitatory synapses [2], J EE and J IE should lie in the range of 1000 5000 mV. Although the number of inhibitory synapses is approximately 0:1 of that of the excitatory synapses, their IPSP is larger than the EPSP.
Reference: [28] <editor> J. D. Cowan, </editor> <booktitle> in Advances in Neural Information Processing Systems Vol. </booktitle> <volume> 3, </volume> <editor> edited by R. P. Lippman, J. E. Moody, and D. S. </editor> <publisher> Touretzky (Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1991), </year> <note> p. 62. </note>
Reference-contexts: The master equation formalism of stochastic neural networks has been studied also by Cowan <ref> [28] </ref> and Ohira and Cowan [29]. They derive specific results for the correlations in a one-dimensional system with nearest-neighbor interactions.
Reference: [29] <author> T. Ohira and J. D. </author> <title> Cowan, </title> <journal> Phys. Rev. </journal> <volume> E 48, </volume> <month> 2259 </month> <year> (1993). </year>
Reference-contexts: The master equation formalism of stochastic neural networks has been studied also by Cowan [28] and Ohira and Cowan <ref> [29] </ref>. They derive specific results for the correlations in a one-dimensional system with nearest-neighbor interactions. Here we have focused on networks with high degree of connectivity, which enabled us to derive explicit expressions for the correlation and response functions using a systematic expansion in the inverse of the system size.
Reference: [30] <author> K. Kawasaki, </author> <title> in Phase Transitions and Critical Phenomena, edited by C. </title> <editor> Domb and M. S. </editor> <publisher> Green (Academic Press, </publisher> <year> 1972), </year> <note> Vol. 2. </note>
Reference-contexts: Our theory is an extension of the mean-field theory of the Kinetic Ising models near thermal equilibrium <ref> [21, 20, 30] </ref>. The systems studied here do not obey the detailed-balance conditions, hence their statistics is not described by thermal equilibrium.
Reference: [31] <author> S.-K. Ma, </author> <title> Modern Theory of Critical Phenomena (Benjamin, </title> <year> 1976). </year>
Reference-contexts: The fundamental eigenmodes of the fluctuations are orthogonal, and their eigenvalues are real. Thus, the resultant time-dependence of the correlation and response functions is relatively simple, as they are composed of a sum of pure, exponentially decaying orthogonal modes. In addition, systems with detailed-balance obey the Fluctuation Dissipation Theorem <ref> [31] </ref> which establishes a direct relationship between the time-dependent response and the correlations. In contrast, in the present work, symmetry of the connection matrix has not been assumed, nor have we restricted the detailed form of the sigmoidal transfer function.
Reference: [32] <author> L. N. Trefethen, A. E. Trefethen, S. C. Reddy, and T. A. Driscoll, </author> <note> Science 261, 587 (1993). </note>
Reference-contexts: Furthermore, although each mode is decaying exponentially at all times the response to certain small perturbations may initially grow in time. This phenomenon may lead to a substantial transient amplification of certain perturbations, although at long time the total response will decay exponentially <ref> [32] </ref>. Such a behavior cannot occur if the eigenmodes are orthogonal, as is the case with systems at thermodynamic equilibrium. Despite these differences, there are some important similarities between the equilibrium case and the more general case considered here.
Reference: [33] <author> B. L. McNaughton and R. G. M. Morris, </author> <booktitle> Trends in Neurosci. </booktitle> <volume> 10, </volume> <month> 408 </month> <year> (1987). </year>
Reference-contexts: A simple example is the case of excitatory-inhibitory network studied in Section 9. This architecture is commonly used in modeling local neuronal circuits in the brain. Our theory can be used to calculate the neuronal correlations in recurrent, associative-memory networks modeling hyppocampal <ref> [33] </ref> or extrastriatal visual areas [34]. Provided that the number of embedded memories is far below the capacity [35], these networks have a connectivity patterns that falls within the framework of this work.
Reference: [34] <author> M. Griniasty, M. Tsodyks, and D. J. </author> <title> Amit, </title> <journal> Neural Comput. </journal> <volume> 5, </volume> <month> 1 </month> <year> (1993). </year>
Reference-contexts: A simple example is the case of excitatory-inhibitory network studied in Section 9. This architecture is commonly used in modeling local neuronal circuits in the brain. Our theory can be used to calculate the neuronal correlations in recurrent, associative-memory networks modeling hyppocampal [33] or extrastriatal visual areas <ref> [34] </ref>. Provided that the number of embedded memories is far below the capacity [35], these networks have a connectivity patterns that falls within the framework of this work.
Reference: [35] <author> D. J. Amit, H. Gutfreund, and H. </author> <title> Sompolinsky, </title> <journal> Phys. Rev. </journal> <volume> A32, </volume> <month> 1007 </month> <year> (1985). </year>
Reference-contexts: This architecture is commonly used in modeling local neuronal circuits in the brain. Our theory can be used to calculate the neuronal correlations in recurrent, associative-memory networks modeling hyppocampal [33] or extrastriatal visual areas [34]. Provided that the number of embedded memories is far below the capacity <ref> [35] </ref>, these networks have a connectivity patterns that falls within the framework of this work. Another potential area of applications is in the study of sensory or motor cortical systems, where the gross organization of the intrinsic connections is known.
Reference: [36] <author> R. Ben-Yishai, R. Lev Bar-Or, and H. Sompolinsky, </author> <title> Orientation tuning by recurrent networks in visual and motor cortex, </title> <note> preprint (1994). 38 </note>
Reference-contexts: Such a fine-tuning may seem unlikely in many realistic situations. However, there are interesting cases, where symmetry considerations dictate that the system is near a bifurcation point. Examples are systems that code for orientation or direction of sensory or motor signals <ref> [36] </ref>. In addition, in some cases operating near a bifurcation point may be functionally important, such as in the case of olfaction [6] or the vestibuoccular system [37]. Learning mechanism may be responsible for maintaining these systems near the bifurcation point [37, 38].
Reference: [37] <author> S. C. Cannon , D. A. Robinson, and S. </author> <title> Shamma, </title> <journal> Biol. Cybern. </journal> <volume> 49, </volume> <month> 127 </month> <year> (1983). </year>
Reference-contexts: Examples are systems that code for orientation or direction of sensory or motor signals [36]. In addition, in some cases operating near a bifurcation point may be functionally important, such as in the case of olfaction [6] or the vestibuoccular system <ref> [37] </ref>. Learning mechanism may be responsible for maintaining these systems near the bifurcation point [37, 38]. The above 31 theory can then be used to predict the behavior of the dominant mode of fluctuations. <p> In addition, in some cases operating near a bifurcation point may be functionally important, such as in the case of olfaction [6] or the vestibuoccular system [37]. Learning mechanism may be responsible for maintaining these systems near the bifurcation point <ref> [37, 38] </ref>. The above 31 theory can then be used to predict the behavior of the dominant mode of fluctuations. It is important to emphasize that our dynamic model is at best a crude coarse-grained account of the neuronal dynamics, on time scales large compared to 1 msec.
Reference: [38] <author> D. Lehmann and E. Binenstock, </author> <note> to appear. </note>
Reference-contexts: In addition, in some cases operating near a bifurcation point may be functionally important, such as in the case of olfaction [6] or the vestibuoccular system [37]. Learning mechanism may be responsible for maintaining these systems near the bifurcation point <ref> [37, 38] </ref>. The above 31 theory can then be used to predict the behavior of the dominant mode of fluctuations. It is important to emphasize that our dynamic model is at best a crude coarse-grained account of the neuronal dynamics, on time scales large compared to 1 msec.

References-found: 38

