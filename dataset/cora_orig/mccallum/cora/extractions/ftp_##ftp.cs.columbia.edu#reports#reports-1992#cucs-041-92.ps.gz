URL: ftp://ftp.cs.columbia.edu/reports/reports-1992/cucs-041-92.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1992.html
Root-URL: http://www.cs.columbia.edu
Title: Fast Parallel String Prefix-Matching  
Author: Dany Breslauer 
Address: CUCS-041-92  
Affiliation: Columbia University  
Abstract: log log m processors. These results improve on the running time of the best previous algorithm for both problems, which was O(log m), while preserving the same number of operations.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Apostolico and D. Breslauer. </author> <title> An Optimal O(log log n) Time Parallel Algorithm for Detecting all Squares in a String. </title> <type> manuscript, </type> <year> 1992. </year>
Reference-contexts: Note that both problems can be solved even in a constant time if more processors are available. The string prefix matching algorithm follows techniques that were used in solving several other parallel string problems <ref> [1, 2, 5, 6, 9] </ref>. In particular, it uses the parallel string matching algorithm of Breslauer and Galil [7] as a procedure that solves several string matching problems simultaneously and then combines the results of the string matching problems into an answer to the string prefix-matching problem.
Reference: [2] <author> A. Apostolico, D. Breslauer, and Z. Galil. </author> <title> Optimal Parallel Algorithms for Periods, Palindromes and Squares. </title> <booktitle> In Proc. 19th International Colluquium on Automata, Languages, and Programming. </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, Germany, </address> <year> 1992. </year> <pages> 296-307. </pages>
Reference-contexts: Note that both problems can be solved even in a constant time if more processors are available. The string prefix matching algorithm follows techniques that were used in solving several other parallel string problems <ref> [1, 2, 5, 6, 9] </ref>. In particular, it uses the parallel string matching algorithm of Breslauer and Galil [7] as a procedure that solves several string matching problems simultaneously and then combines the results of the string matching problems into an answer to the string prefix-matching problem.
Reference: [3] <author> O. Berkman, B. Schieber, and U. Vishkin. </author> <title> Some doubly logarithmic optimal parallel algorithms based on finding nearest smallers. </title> <type> manuscript, </type> <year> 1988. </year>
Reference-contexts: For the computation of the KMP failure function we use an algorithm that computes the prefix maxima of a sequence. Berkmen, Schieber and Vishkin <ref> [3] </ref> noticed that the parallel maxima algorithm of Shiloach and Vishkin [14] can be modified to find the maxima of each prefix of an n element sequence in O (log log n) time on a n log log n -processor CRCW-PRAM. 2 One of the major issues in the design of <p> Compute the [1::m] function. [i] = max fB [k]g: Note that both maxima computations can be done by Berkman, Schieber and Vishkin's <ref> [3] </ref> prefix maxima algorithm. 2 For the computation of the ^ [1::m] function we use a more powerful CRCW-PRAM model which is called the priority CRCW-PRAM. In this model each processor has a pre assigned priority and simultaneous writes of different values to a memory cell are allowed.
Reference: [4] <author> R. P. Brent. </author> <title> Evaluation of general arithmetic expressions. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 21 </volume> <pages> 201-206, </pages> <year> 1974. </year>
Reference-contexts: We ignore this issue in this paper and use a general theorem that states that the assignment can be done. Theorem 2.1 (Brent <ref> [4] </ref>) Any synchronous parallel algorithm of time t that consists of a total of x elementary operations can be implemented on p processors in dx=pe + t time.
Reference: [5] <author> D. Breslauer. </author> <title> A Parallel String Superprimitivity Test. </title> <type> manuscript, </type> <year> 1992. </year>
Reference-contexts: Note that both problems can be solved even in a constant time if more processors are available. The string prefix matching algorithm follows techniques that were used in solving several other parallel string problems <ref> [1, 2, 5, 6, 9] </ref>. In particular, it uses the parallel string matching algorithm of Breslauer and Galil [7] as a procedure that solves several string matching problems simultaneously and then combines the results of the string matching problems into an answer to the string prefix-matching problem.
Reference: [6] <author> D. Breslauer. </author> <title> Efficient String Algorithmics. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Columbia University, </institution> <address> New York, NY, </address> <year> 1992. </year> <month> 9 </month>
Reference-contexts: Note that both problems can be solved even in a constant time if more processors are available. The string prefix matching algorithm follows techniques that were used in solving several other parallel string problems <ref> [1, 2, 5, 6, 9] </ref>. In particular, it uses the parallel string matching algorithm of Breslauer and Galil [7] as a procedure that solves several string matching problems simultaneously and then combines the results of the string matching problems into an answer to the string prefix-matching problem.
Reference: [7] <author> D. Breslauer and Z. Galil. </author> <title> An optimal O(log log n) time parallel string matching algo-rithm. </title> <journal> SIAM J. Comput., </journal> <volume> 19(6) </volume> <pages> 1051-1058, </pages> <year> 1990. </year>
Reference-contexts: We refer to this problem as string prefix-matching. In parallel, the string matching problem can be solved in O (log log m) time on a n log log m - processor CRCW-PRAM as shown by Breslauer and Galil <ref> [7] </ref>. <p> The string prefix matching algorithm follows techniques that were used in solving several other parallel string problems [1, 2, 5, 6, 9]. In particular, it uses the parallel string matching algorithm of Breslauer and Galil <ref> [7] </ref> as a procedure that solves several string matching problems simultaneously and then combines the results of the string matching problems into an answer to the string prefix-matching problem. The paper is organized as follows. Section 2 overviews some parallel algorithms and tools that are used in the new algorithms. <p> The input to the string matching algorithm consists of two strings, pattern [1::m] and text [1::n], and the output is a Boolean array match [1::n] that has a "true" value at each position where an occurrence of the pattern starts in the text. We use Breslauer and Galil's <ref> [7] </ref> parallel string matching algorithm that takes O (log log m) time on a n log log m -processor CRCW-PRAM. This algorithm is the fastest optimal parallel string matching algorithm possible over a general alphabet as shown by Breslauer and Galil [8]. <p> The number of operations in stage is O = T P . In the next section it is shown that each stage can be computed in T = O (log log 2 ) time and O = O (n) operations using Breslauer and Galil's <ref> [7] </ref> parallel string matching algorithm. Since the stages of the algorithm are computed simultaneously, the total number of operations performed in all stages is P O = O (n log m) and the time is max T = O (log log m). <p> Lemma 3.7 Stage number correctly computes all entries of the output array [1::n] that are in the range 2 2 +1 1. It takes O (log log 2 ) time and a total of n operations. Proof: The calls to Breslauer and Galil's <ref> [7] </ref> string matching algorithm take O (log log 2 ) time and n operations.
Reference: [8] <author> D. Breslauer and Z. Galil. </author> <title> A Lower Bound for Parallel String Matching. </title> <journal> SIAM J. Comput., </journal> <volume> 21(5) </volume> <pages> 856-862, </pages> <year> 1992. </year>
Reference-contexts: Both algorithms are the fastest possible with the number of processors used as implied by a lower bound that was given by Breslauer and Galil <ref> [8] </ref> for the string matching problem. Note that both problems can be solved even in a constant time if more processors are available. The string prefix matching algorithm follows techniques that were used in solving several other parallel string problems [1, 2, 5, 6, 9]. <p> We use Breslauer and Galil's [7] parallel string matching algorithm that takes O (log log m) time on a n log log m -processor CRCW-PRAM. This algorithm is the fastest optimal parallel string matching algorithm possible over a general alphabet as shown by Breslauer and Galil <ref> [8] </ref>. We also use an algorithm of Fich, Ragde and Wigderson [10] to compute the minima of n integers from the range 1 n in a constant time using an n-processor CRCW-PRAM.
Reference: [9] <author> D. Breslauer and Z. Galil. </author> <title> Finding all periods and initial palindromes of a string in parallel. </title> <type> manuscript, </type> <year> 1992. </year>
Reference-contexts: Note that both problems can be solved even in a constant time if more processors are available. The string prefix matching algorithm follows techniques that were used in solving several other parallel string problems <ref> [1, 2, 5, 6, 9] </ref>. In particular, it uses the parallel string matching algorithm of Breslauer and Galil [7] as a procedure that solves several string matching problems simultaneously and then combines the results of the string matching problems into an answer to the string prefix-matching problem.
Reference: [10] <author> F. E. Fich, R. L. Ragde, and A. Wigderson. </author> <title> Relations between concurrent-write models of parallel computation. </title> <booktitle> In Proc. 3rd ACM Symp. on Principles of Distributed Computing, </booktitle> <pages> pages 179-189, </pages> <year> 1984. </year>
Reference-contexts: This algorithm is the fastest optimal parallel string matching algorithm possible over a general alphabet as shown by Breslauer and Galil [8]. We also use an algorithm of Fich, Ragde and Wigderson <ref> [10] </ref> to compute the minima of n integers from the range 1 n in a constant time using an n-processor CRCW-PRAM. <p> The successful comparisons up to the first comparison that failed correspond to the longest pattern prefix that occurs starting at this text position. This step takes a constant time on m processors using the Fich, Ragde and Wigderson <ref> [10] </ref> integer minima algorithm. <p> This representation can be easily computed from the output of the string matching problem using Fich, Ragde and Wigderson's <ref> [10] </ref> minima algorithm in a constant time and 2 processors. Let be the position where the period P [1::] of P [1::2 ] terminates in the pattern prefix P [1::2 +1 ] and 2 +1 + 1 if it does not terminate in this prefix.
Reference: [11] <author> Z. Galil. </author> <title> Optimal parallel algorithms for string matching. </title> <journal> Inform. and Control, </journal> <volume> 67 </volume> <pages> 144-157, </pages> <year> 1985. </year>
Reference-contexts: However, the best parallel algorithms for the string prefix-matching problem and for computing the KMP failure function were simple derivations of Galil's <ref> [11] </ref> O (log m) time n-processor string matching algorithm. (The KMP failure function is a table that is computed in the pattern processing step of the Knuth-Morris-Pratt string matching algorithm and is used to guide that algorithm when comparisons fail.) These bounds are over a general alphabet where the only access <p> In fact, Galil's <ref> [11] </ref> algorithm can be implemented using only n log m processors if the size of the alphabet is a constant. This paper presents a new algorithm for the string prefix-matching problem over a general alphabet. <p> The new algorithms that are presented in this paper are still a factor of log m processors away from optimality, but they have the same time-processor product as the best previous parallel algorithms <ref> [11] </ref> for the two problems. Both algorithms are the fastest possible with the number of processors used as implied by a lower bound that was given by Breslauer and Galil [8] for the string matching problem.
Reference: [12] <author> D. E. Knuth, J. H. Morris, and V. R. Pratt. </author> <title> Fast pattern matching in strings. </title> <journal> SIAM J. Comput., </journal> <volume> 6 </volume> <pages> 322-350, </pages> <year> 1977. </year>
Reference-contexts: 1 Introduction String matching is the problem of finding all occurrences of a short pattern string P [1::m] in a longer text string T [1::n]. The classical sequential algorithm of Knuth, Morris and Pratt <ref> [12] </ref> solves the string matching problem in time that is linear in the length of the input strings. The Knuth-Morris-Pratt [12] string matching algorithm can be easily generalized to find the longest pattern prefix that starts at each text position within the same time bound. <p> The classical sequential algorithm of Knuth, Morris and Pratt <ref> [12] </ref> solves the string matching problem in time that is linear in the length of the input strings. The Knuth-Morris-Pratt [12] string matching algorithm can be easily generalized to find the longest pattern prefix that starts at each text position within the same time bound. We refer to this problem as string prefix-matching. <p> The rest of the work in each block also takes a constant time and 2 operations. There are n b2 1 c+1 blocks and thus, stage takes O (log log 2 ) time and O (n) operations. 2 4 The KMP Failure Function The Knuth-Morris-Pratt <ref> [12] </ref> string matching algorithm computes in its pattern preprocessing step a table that is used later to guide the text processing step when comparisons fail. This table is often called the KMP failure function. Knuth, Morris and Pratt [12] actually define two function: F [1::m] and next [1::m]. <p> and O (n) operations. 2 4 The KMP Failure Function The Knuth-Morris-Pratt <ref> [12] </ref> string matching algorithm computes in its pattern preprocessing step a table that is used later to guide the text processing step when comparisons fail. This table is often called the KMP failure function. Knuth, Morris and Pratt [12] actually define two function: F [1::m] and next [1::m]. Both function can be used to guide the comparisons that fail, but the next [] function has more information and therefore it is more efficient.
Reference: [13] <author> R. C. Lyndon and M. P. Schutzenberger. </author> <title> The equation a m = b n c p in a free group. </title> <journal> Michigan Math. J., </journal> <volume> 9 </volume> <pages> 289-298, </pages> <year> 1962. </year>
Reference-contexts: The shortest period of a string S is called the period of S. Alternatively, a string S [1::m] has a period of length if S [i] = S [i + ], for i = 1::m . Lemma 3.3 (Lyndon and Schutzenberger <ref> [13] </ref>) If a string of length m has two periods of lengths p and q and p + q m, then it also has a period of length gcd (p; q). Lemma 3.4 Assume that the period length of a string A [1::l] is p.
Reference: [14] <author> Y. Shiloach and U. Vishkin. </author> <title> Finding the maximum, merging and sorting in a parallel computation model. </title> <journal> J. Algorithms, </journal> <volume> 2 </volume> <pages> 88-102, </pages> <year> 1981. </year> <month> 10 </month>
Reference-contexts: For the computation of the KMP failure function we use an algorithm that computes the prefix maxima of a sequence. Berkmen, Schieber and Vishkin [3] noticed that the parallel maxima algorithm of Shiloach and Vishkin <ref> [14] </ref> can be modified to find the maxima of each prefix of an n element sequence in O (log log n) time on a n log log n -processor CRCW-PRAM. 2 One of the major issues in the design of a PRAM algorithms is the assignment of proces-sors to their tasks.
References-found: 14

