URL: http://www.cs.cmu.edu/~thrun/papers/thrun.icra98-map.ps.gz
Refering-URL: http://www.cs.cmu.edu/~thrun/papers/full.html
Root-URL: 
Title: Probabilistic Mapping Of An Environment By A Mobile Robot  
Author: Sebastian Thrun Dieter Fox Wolfram Burgard 
Address: Pittsburgh, PA 15213 D53117 Bonn, Germany  
Affiliation: Computer Science Department Computer Science Department III Carnegie Mellon University University of Bonn  
Abstract: This paper addresses the problem of building large-scale maps of indoor environments with mobile robots. It proposes a statistical approach that phrases the map building problem as a constrained maximum-likelihood estimation problem, for which it devises a practical algorithm. Experimental results in large, cyclic environments illustrate the appropriateness of the approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. Burgard, D. Fox, D. Hennig, and T. Schmidt. </author> <title> Estimating the absolute position of a mobile robot using position probability grids. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <address> Menlo Park, </address> <month> August </month> <year> 1996. </year> <booktitle> AAAI, </booktitle> <publisher> AAAI Press/MIT Press. </publisher>
Reference-contexts: The reader should notice that the computation of the ff-values is a version of Markov localization, which has recently been used with great success by various researchers <ref> [1, 6, 12, 17] </ref>. The fi-values add additional knowledge to the robot's position, typically not captured in Markov-localization. They are, however, essential for revising past belief based on sensor data that was received later in time, which is a necessary prerequisite of building large-scale maps.
Reference: [2] <author> R. Chatila and J.-P. Laumond. </author> <title> Position referencing and consistent world modeling for mobile robots. </title> <booktitle> In Proceedings of the 1985 IEEE International Conference on Robotics and Automation, </booktitle> <year> 1985. </year>
Reference-contexts: The final result is a accurate map. No experiments were performed using the raw dataset. More results can be found in [19]. 6 Related Work Over the last decade, there has been a flurry of work on map building for mobile robots (see e.g., <ref> [2, 8, 18] </ref>). As noticed by Lu and Milios [9], the dominating paradigm in the field is incremental: Robot locations are estimated as they occur; the majority of approaches lacks the ability to use sensor data for revising past location estimates.
Reference: [3] <author> H. Choset. </author> <title> Sensor Based Motion Planning: The Hierarchical Generalized Voronoi Graph. </title> <type> PhD thesis, </type> <institution> California Institute of Technology, </institution> <year> 1996. </year>
Reference-contexts: More specifically, we assume that the robot is given a method for estimating the type, the relative angle and an approximate distance of nearby landmarks. For example, such landmarks might be Choset's meet points <ref> [3] </ref> (see also Kuipers's and Mataric's work [7, 10]), which correspond to intersections or dead ends in corridors and which can be detected very robustly. In our probabilistic framework, landmarks are not necessarily distinguishable; in the most difficult case, landmarks are entirely indistinguishable. <p> Data was collected by joy-sticking the robot through its environment and using odometry (shaft encoders) to re-compute the corresponding control. While joy-sticking the robot, a human chose and marked a collection of significant locations (which roughly corresponded to the meet-points described in <ref> [3, 7] </ref>), and informed the robot by pressing a button every time the robot crossed a landmark location. To test the most difficult case, we assumed that the landmarks were generally indistinguishable. university buildings. The circles mark landmark locations. <p> Thus, the approach can be combined with one of the known sensor-based exploration techniques. One possibility, which has not yet been implemented, would be to combine the current approach with Choset's sensor-based covering algorithm <ref> [3] </ref>. Our current implementation also relies on humans to identify landmarks. While this is reasonable when mapping an environment collaboratively with a human, it is impractical if the robot is to operate autonomously. <p> While this is reasonable when mapping an environment collaboratively with a human, it is impractical if the robot is to operate autonomously. The lack of a landmark-recognizing routine is purely a limitation of our current implementation, not of the general algorithm. For example, Choset's sensor-based covering algorithm <ref> [3] </ref> automatically detects and navigates to so-called meet-points. Meet-points correspond to intersections, corners, and dead-ends (see also [7]). We conjecture that a combined algorithm, using Choset's approach for exploration and meet-point detection and our approach for mapping, would yield an algorithm for fully autonomous exploration and mapping.
Reference: [4] <author> A. Elfes. </author> <title> Occupancy Grids: A Probabilistic Framework for Robot Perception and Navigation. </title> <type> PhD thesis, </type> <institution> Department of Electrical and Computer Engineering, Carnegie Mellon University, </institution> <year> 1989. </year>
Reference-contexts: The result of the estimation routine can be used to build more accurate occupancy grid maps <ref> [4, 11] </ref>. Figure 4b shows an occupancy grid map constructed from sonar measurements (using a ring of 24 Polaroid sonar sensors), using the guessed maximum likelihood positions as input to the mapping software described in [18]. In comparison, Figure 3b shows the same map using the raw, uncorrected data.
Reference: [5] <author> J.-S. Gutmann. </author> <title> Vergleich von algorithmen zur selbstlokalisierung eines mobilen roboters. </title> <type> Master's thesis, </type> <institution> University of Ulm, Ulm, Germany, </institution> <year> 1996. </year> <note> (in German). </note>
Reference-contexts: The final odometric error is approximately 70 meters and 180 degree; the two marked locations (arrows) are actually identical. drift and then applying the algorithm described here. This map is approximately 85 meters long. Recently, several groups have proposed algorithms that revise estimates backwards in time <ref> [5, 6, 15, 9] </ref>. These approaches are similar to the one proposed here in that they use similar statistical methods for constructing maps. They differ in the way the represent locations and maps. <p> They differ in the way the represent locations and maps. The approaches in [6, 15] use Hidden Markov Models as their baseline representation, which make it difficult to embed geometry in a mathematically correct way. The approaches in <ref> [5, 9] </ref>, on the other hand, represent locations of the robot and the obstacles using Kalman filters. While those approaches can generate maps with floating-point accuracy, they are limited in their ability to represent ambiguities.
Reference: [6] <author> S. Koenig and R. Simmons. </author> <title> Passive distance learning for robot navigation. </title> <editor> In L. Saitta, editor, </editor> <booktitle> Proceedings of the Thirteenth International Conference on Machine Learning, </booktitle> <year> 1996. </year>
Reference-contexts: Our approach poses the problem of map building is as a maximum likelihood estimation problem, where both the location of landmarks and the robot's position have to be estimated. Likelihood is maximized under probabilistic constraints that arise from the physics of robot motion and perception. Following <ref> [6, 15, 16] </ref>, the high-dimensional maximum likelihood estimation problem is solved efficiently using the Baum-Welch (or alpha-beta) algorithm [13]. Baum-Welch alternates an expectation step (E-step) and a maximization step (M-step). In the E-step, the current map is held constant, the probability distributions are calculated for past and current robot locations. <p> The reader should notice that the computation of the ff-values is a version of Markov localization, which has recently been used with great success by various researchers <ref> [1, 6, 12, 17] </ref>. The fi-values add additional knowledge to the robot's position, typically not captured in Markov-localization. They are, however, essential for revising past belief based on sensor data that was received later in time, which is a necessary prerequisite of building large-scale maps. <p> The final odometric error is approximately 70 meters and 180 degree; the two marked locations (arrows) are actually identical. drift and then applying the algorithm described here. This map is approximately 85 meters long. Recently, several groups have proposed algorithms that revise estimates backwards in time <ref> [5, 6, 15, 9] </ref>. These approaches are similar to the one proposed here in that they use similar statistical methods for constructing maps. They differ in the way the represent locations and maps. <p> Recently, several groups have proposed algorithms that revise estimates backwards in time [5, 6, 15, 9]. These approaches are similar to the one proposed here in that they use similar statistical methods for constructing maps. They differ in the way the represent locations and maps. The approaches in <ref> [6, 15] </ref> use Hidden Markov Models as their baseline representation, which make it difficult to embed geometry in a mathematically correct way. The approaches in [5, 9], on the other hand, represent locations of the robot and the obstacles using Kalman filters.
Reference: [7] <author> B. Kuipers and Y.-T. Byun. </author> <title> A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations. </title> <journal> Journal of Robotics and Autonomous Systems, </journal> <volume> 8:4763, </volume> <year> 1991. </year>
Reference-contexts: More specifically, we assume that the robot is given a method for estimating the type, the relative angle and an approximate distance of nearby landmarks. For example, such landmarks might be Choset's meet points [3] (see also Kuipers's and Mataric's work <ref> [7, 10] </ref>), which correspond to intersections or dead ends in corridors and which can be detected very robustly. In our probabilistic framework, landmarks are not necessarily distinguishable; in the most difficult case, landmarks are entirely indistinguishable. <p> Data was collected by joy-sticking the robot through its environment and using odometry (shaft encoders) to re-compute the corresponding control. While joy-sticking the robot, a human chose and marked a collection of significant locations (which roughly corresponded to the meet-points described in <ref> [3, 7] </ref>), and informed the robot by pressing a button every time the robot crossed a landmark location. To test the most difficult case, we assumed that the landmarks were generally indistinguishable. university buildings. The circles mark landmark locations. <p> The lack of a landmark-recognizing routine is purely a limitation of our current implementation, not of the general algorithm. For example, Choset's sensor-based covering algorithm [3] automatically detects and navigates to so-called meet-points. Meet-points correspond to intersections, corners, and dead-ends (see also <ref> [7] </ref>). We conjecture that a combined algorithm, using Choset's approach for exploration and meet-point detection and our approach for mapping, would yield an algorithm for fully autonomous exploration and mapping. Acknowledgment This research benefited from discussions with Howie Choset, Keiji Nagatani, and Hagit Shatkay, which are gratefully acknowledged.
Reference: [8] <author> J.J. Leonard, H.F. Durrant-Whyte, and I.J. Cox. </author> <title> Dynamic map building for an autonomous mobile robot. </title> <journal> International Journal of Robotics Research, </journal> <volume> 11(4):8996, </volume> <year> 1992. </year>
Reference-contexts: The final result is a accurate map. No experiments were performed using the raw dataset. More results can be found in [19]. 6 Related Work Over the last decade, there has been a flurry of work on map building for mobile robots (see e.g., <ref> [2, 8, 18] </ref>). As noticed by Lu and Milios [9], the dominating paradigm in the field is incremental: Robot locations are estimated as they occur; the majority of approaches lacks the ability to use sensor data for revising past location estimates.
Reference: [9] <author> F. Lu and E. Milios. </author> <title> Globally consistent range scan alignment for environment mapping. </title> <booktitle> Autonomous Robots, </booktitle> <address> 4:333349, </address> <year> 1997. </year>
Reference-contexts: No experiments were performed using the raw dataset. More results can be found in [19]. 6 Related Work Over the last decade, there has been a flurry of work on map building for mobile robots (see e.g., [2, 8, 18]). As noticed by Lu and Milios <ref> [9] </ref>, the dominating paradigm in the field is incremental: Robot locations are estimated as they occur; the majority of approaches lacks the ability to use sensor data for revising past location estimates. A detailed survey of recent literature on map building can be found in [18]. <p> The final odometric error is approximately 70 meters and 180 degree; the two marked locations (arrows) are actually identical. drift and then applying the algorithm described here. This map is approximately 85 meters long. Recently, several groups have proposed algorithms that revise estimates backwards in time <ref> [5, 6, 15, 9] </ref>. These approaches are similar to the one proposed here in that they use similar statistical methods for constructing maps. They differ in the way the represent locations and maps. <p> They differ in the way the represent locations and maps. The approaches in [6, 15] use Hidden Markov Models as their baseline representation, which make it difficult to embed geometry in a mathematically correct way. The approaches in <ref> [5, 9] </ref>, on the other hand, represent locations of the robot and the obstacles using Kalman filters. While those approaches can generate maps with floating-point accuracy, they are limited in their ability to represent ambiguities.
Reference: [10] <author> M.J. Mataric. </author> <title> Interaction and intelligent behavior. </title> <type> Technical Report AI-TR-1495, </type> <institution> Massachusetts Institute of Technology, Artificial Intelligence Laboratory, </institution> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: More specifically, we assume that the robot is given a method for estimating the type, the relative angle and an approximate distance of nearby landmarks. For example, such landmarks might be Choset's meet points [3] (see also Kuipers's and Mataric's work <ref> [7, 10] </ref>), which correspond to intersections or dead ends in corridors and which can be detected very robustly. In our probabilistic framework, landmarks are not necessarily distinguishable; in the most difficult case, landmarks are entirely indistinguishable.
Reference: [11] <author> H. P. Moravec. </author> <title> Sensor fusion in certainty grids for mobile robots. </title> <journal> AI Magazine, </journal> <pages> pages 6174, </pages> <month> Summer </month> <year> 1988. </year>
Reference-contexts: The result of the estimation routine can be used to build more accurate occupancy grid maps <ref> [4, 11] </ref>. Figure 4b shows an occupancy grid map constructed from sonar measurements (using a ring of 24 Polaroid sonar sensors), using the guessed maximum likelihood positions as input to the mapping software described in [18]. In comparison, Figure 3b shows the same map using the raw, uncorrected data.
Reference: [12] <author> I. Nourbakhsh, R. Powers, and S. Birchfield. </author> <title> DERVISH an office-navigating robot. </title> <journal> AI Magazine, </journal> <volume> 16(2):5360, </volume> <month> Summer </month> <year> 1995. </year>
Reference-contexts: The reader should notice that the computation of the ff-values is a version of Markov localization, which has recently been used with great success by various researchers <ref> [1, 6, 12, 17] </ref>. The fi-values add additional knowledge to the robot's position, typically not captured in Markov-localization. They are, however, essential for revising past belief based on sensor data that was received later in time, which is a necessary prerequisite of building large-scale maps.
Reference: [13] <author> L. R. Rabiner. </author> <title> A tutorial on hidden markov models and selected applications in speech recognition. </title> <booktitle> In Proceedings of the IEEE. IEEE, 1989. IEEE Log Number 8825949. </booktitle>
Reference-contexts: Likelihood is maximized under probabilistic constraints that arise from the physics of robot motion and perception. Following [6, 15, 16], the high-dimensional maximum likelihood estimation problem is solved efficiently using the Baum-Welch (or alpha-beta) algorithm <ref> [13] </ref>. Baum-Welch alternates an expectation step (E-step) and a maximization step (M-step). In the E-step, the current map is held constant, the probability distributions are calculated for past and current robot locations. In the M-step, the most likely map is computed based on the estimation result of the E-step. <p> The M-step computes the most likely map under the assumption that ff (t) (t) ~ accurately reflects the likelihood that the robot was at ~ (t) at time t. Following <ref> [13] </ref>, the maximum likelihood map is computed according to the weighted likelihood ratio P (m xy = ljd) = # of times l was observed at hx; yi # of times something was observed hx; yi which is obtained by T X Z (t) (t) T X X Z (t) (t) <p> Frequency counts are maximum likelihood estimators. Thus, the M-step determines the most likely map from the position estimates computed in the E-step. By alternating both steps, both the localization estimates and the map are gradually improved (see also <ref> [13] </ref>). 4 Efficiency Considerations In our implementation, all probabilities are represented by discrete grids. Thus, all integrals are replaced by sums in all equations above.
Reference: [14] <author> N. Roy and S. Thrun. </author> <title> Online self-calibration for mobile robots. </title> <note> Submitted for publication, </note> <year> 1998. </year>
Reference-contexts: During data collection, the robot suffered a final odometric error of 70 meters and 180 degrees. This dataset was first pre-filtered by a recently developed routine for self-calibrating of kinematic models <ref> [14] </ref>, then processed using the algorithm described in this paper. The final result is a accurate map. No experiments were performed using the raw dataset.
Reference: [15] <author> H Shatkay and L. Kaelbling. </author> <title> Learning topological maps with weak local odometric information. </title> <booktitle> In Proceedings of IJCAI-97. IJCAI, </booktitle> <publisher> Inc., </publisher> <year> 1997. 1997. </year>
Reference-contexts: Our approach poses the problem of map building is as a maximum likelihood estimation problem, where both the location of landmarks and the robot's position have to be estimated. Likelihood is maximized under probabilistic constraints that arise from the physics of robot motion and perception. Following <ref> [6, 15, 16] </ref>, the high-dimensional maximum likelihood estimation problem is solved efficiently using the Baum-Welch (or alpha-beta) algorithm [13]. Baum-Welch alternates an expectation step (E-step) and a maximization step (M-step). In the E-step, the current map is held constant, the probability distributions are calculated for past and current robot locations. <p> The final odometric error is approximately 70 meters and 180 degree; the two marked locations (arrows) are actually identical. drift and then applying the algorithm described here. This map is approximately 85 meters long. Recently, several groups have proposed algorithms that revise estimates backwards in time <ref> [5, 6, 15, 9] </ref>. These approaches are similar to the one proposed here in that they use similar statistical methods for constructing maps. They differ in the way the represent locations and maps. <p> Recently, several groups have proposed algorithms that revise estimates backwards in time [5, 6, 15, 9]. These approaches are similar to the one proposed here in that they use similar statistical methods for constructing maps. They differ in the way the represent locations and maps. The approaches in <ref> [6, 15] </ref> use Hidden Markov Models as their baseline representation, which make it difficult to embed geometry in a mathematically correct way. The approaches in [5, 9], on the other hand, represent locations of the robot and the obstacles using Kalman filters.
Reference: [16] <author> H. </author> <title> Shatkay and L.P. Kaelbling. Learning hidden markov models with geometric information. </title> <type> Technical Report CS-97-04, </type> <institution> Computer Science Department, Brown University, Providence, RI, </institution> <month> April </month> <year> 1997. </year>
Reference-contexts: Our approach poses the problem of map building is as a maximum likelihood estimation problem, where both the location of landmarks and the robot's position have to be estimated. Likelihood is maximized under probabilistic constraints that arise from the physics of robot motion and perception. Following <ref> [6, 15, 16] </ref>, the high-dimensional maximum likelihood estimation problem is solved efficiently using the Baum-Welch (or alpha-beta) algorithm [13]. Baum-Welch alternates an expectation step (E-step) and a maximization step (M-step). In the E-step, the current map is held constant, the probability distributions are calculated for past and current robot locations.
Reference: [17] <author> R. Simmons and S. Koenig. </author> <title> Probabilistic robot navigation in partially observable environments. </title> <booktitle> In Proceedings of IJCAI-95, </booktitle> <pages> pages 1080 1087, </pages> <address> Montreal, Canada, </address> <month> August </month> <year> 1995. </year> <title> IJCAI, </title> <publisher> Inc. </publisher>
Reference-contexts: The reader should notice that the computation of the ff-values is a version of Markov localization, which has recently been used with great success by various researchers <ref> [1, 6, 12, 17] </ref>. The fi-values add additional knowledge to the robot's position, typically not captured in Markov-localization. They are, however, essential for revising past belief based on sensor data that was received later in time, which is a necessary prerequisite of building large-scale maps.
Reference: [18] <author> S. Thrun. </author> <title> Learning maps for indoor mobile robot navigation. </title> <journal> Artificial Intelligence, </journal> <note> to appear. </note>
Reference-contexts: One of the environments contains a cycle of size 60 by 25 meter, which has been mapped successfully despite significant odometric error. The approach has been integrated into a conventional method for building occupancy grid maps <ref> [18] </ref>, for which results are reported as well. 2 The Probabilistic Model This section describes our probabilistic model of the two basic aspects involved in mapping: motion and perception. <p> Figure 4b shows an occupancy grid map constructed from sonar measurements (using a ring of 24 Polaroid sonar sensors), using the guessed maximum likelihood positions as input to the mapping software described in <ref> [18] </ref>. In comparison, Figure 3b shows the same map using the raw, uncorrected data. <p> The final result is a accurate map. No experiments were performed using the raw dataset. More results can be found in [19]. 6 Related Work Over the last decade, there has been a flurry of work on map building for mobile robots (see e.g., <ref> [2, 8, 18] </ref>). As noticed by Lu and Milios [9], the dominating paradigm in the field is incremental: Robot locations are estimated as they occur; the majority of approaches lacks the ability to use sensor data for revising past location estimates. <p> A detailed survey of recent literature on map building can be found in <ref> [18] </ref>. The approach proposed there, however, is also incremental and therefore incapable of dealing with situations such as the ones described in this paper. @ landmark observations and 2,667 controls.
Reference: [19] <author> S. Thrun, D. Fox, and W. Burgard. </author> <title> A probabilistic approach to concurrent mapping and localization for mobile robots. Machine Learning and Autonomous Robots (joint issue), </title> <note> to appear. </note>
Reference-contexts: A detailed derivation of (8), which follows directly from (2) and (4), can be found in <ref> [19] </ref>. Computation of the fi-values: The computation of fi (t) completely analogous, but backwards in time. The initial fi ~ , which expresses the probability that the robot's final position is ~ is uniformly distributed (fi (T ) ~ does not depend on data). <p> This dataset was first pre-filtered by a recently developed routine for self-calibrating of kinematic models [14], then processed using the algorithm described in this paper. The final result is a accurate map. No experiments were performed using the raw dataset. More results can be found in <ref> [19] </ref>. 6 Related Work Over the last decade, there has been a flurry of work on map building for mobile robots (see e.g., [2, 8, 18]).
References-found: 19

