URL: http://www.cs.berkeley.edu/~padmanab/research/papers/ccr-july96.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~padmanab/research/ms-thesis.html
Root-URL: 
Email: padmanab@cs.berkeley.edu  mogul@pa.dec.com  
Title: Using Predictive Prefetching to Improve World Wide Web Latency  
Author: Venkata N. Padmanabhan Jeffrey C. Mogul 
Keyword: (satellite) links.  
Address: Berkeley  
Affiliation: University of California at  Digital Equipment Corporation Western Research Laboratory  
Abstract: The long-term success of the World Wide Web depends on fast response time. People use the Web to access information from remote sites, but do not like to wait long for their results. The latency of retrieving a Web document depends on several factors such as the network bandwidth, propagation time and the speed of the server and client computers. Although several proposals have been made for reducing this latency, it is difficult to push it to the point where it becomes insignificant. This motivates our work, where we investigate a scheme for reducing the latency perceived by users by predicting and prefetching files that are likely to be requested soon, while the user is browsing through the currently displayed page. In our scheme the server, which gets to see requests from several clients, makes predictions while individual clients initiate prefetching. We evaluate our scheme based on trace-driven simulations of prefetching over both high-bandwidth and low-bandwidth links. Our results indicate that prefetching is quite beneficial in both cases, resulting in a significant reduction in the average access time at the cost of an increase in network traffic by a similar fraction. We expect prefetching to be particularly profitable over non-shared (dialup) links and high-bandwidth, high-latency 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Berners-Lee, R. Fielding, and H. Frystyk. </author> <title> "Hypertext Transfer Protocol - HTTP/1.0", RFC 1945, </title> <month> May, </month> <year> 1996. </year>
Reference-contexts: However, other components such as propagation delay, which is basically determined by the physical distance traversed, cannot be reduced beyond a point. The Hypertext Transport Protocol (HTTP) version 1.0 <ref> [1] </ref>, as it is currently used in the Web, is simple, but far from optimal as far as latency is concerned. Several researchers ([6],[8],[9],[11]) have analyzed the inefficiencies in use of the network by HTTP, and have proposed modifications to reduce retrieval latency significantly. <p> Each HTTP interaction consists of a request sent from the client to the server, followed by a response sent back from the server to the client. Requests and responses are expressed in a simple ASCII format. Most existing implementations conform to the original version of the protocol, HTTP/1.0 <ref> [1] </ref>. The next version, HTTP/1.1, is presently in draft form [2].
Reference: [2] <author> R. Fielding, J. Gettys, J. C. Mogul, H. Frystyk, and T. Berners-Lee. </author> <title> "Hypertext Transfer Protocol HTTP/1.1", Internet Draft draft-ietf-http-v11-spec-01.txt, </title> <type> IETF,, </type> <month> June, </month> <year> 1996. </year> <note> This is a working draft. </note>
Reference-contexts: Requests and responses are expressed in a simple ASCII format. Most existing implementations conform to the original version of the protocol, HTTP/1.0 [1]. The next version, HTTP/1.1, is presently in draft form <ref> [2] </ref>. <p> P-HTTP uses a single, long-lived TCP connection for multiple HTTP transactions. The connection stays open for all the inline images of a single document, and across multiple HTML retrievals. This helps solve the first problem mentioned above. The HTTP/1.1 protocol <ref> [2] </ref> also defines a persistent connection mechanism to solve the same problem. To avoid the second problem, [8] proposes two new HTTP methods (primitives), GETALL and GETLIST, that allow pipelining requests and responses between a client and a server.
Reference: [3] <author> James Griffioen and Randy Appleton. </author> <title> "Reducing File System Latency using a Predictive Approach", </title> <booktitle> Proceedings of the 1994 Summer USENIX Technical Conference, </booktitle> <address> Cambridge MA, </address> <month> June, </month> <year> 1994. </year>
Reference-contexts: Clients initiate prefetching based on advice from servers. Clearly, the effectiveness of prefetching critically depends on how good the predictions are. We use a prediction algorithm patterned after that proposed by Griffioen and Appleton <ref> [3] </ref> in the context of file systems, though there are a few noteworthy differences. The results from our trace-driven simulations indicate that prefetching helps significantly decrease the average access time at the cost of an increase in network traffic. <p> Also, if multiple requests are being scheduled in any way, this request could be assigned a lower priority than explicit fetch requests. 3.2 Prediction Algorithm Our prediction algorithm is based on that described by Griffioen and Appleton <ref> [3] </ref>. However, there are a few noteworthy differences. <p> Thus, our scheme does not require any kernel modifications. Second, the scheme described in <ref> [3] </ref> does not try to maintain a distinction between accesses by different processes (the clients in the context of a file system). Thus, independent accesses (by different processes), that occur close together in time, could incorrectly be considered as related.
Reference: [4] <author> Raj Jain. </author> <title> "The Art of Computer Systems Performance Analysis", </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1991. </year>
Reference-contexts: The prefetching system also yields more points with an access time of zero. These trends are evident from the distribution of access times shown in Table 1. We quantify the variability in file access times in terms of the standard deviation of errors, s 2 e <ref> [4] </ref>. Given a collection of n data-points, f (x; y)g, a simple linear regression with parameters b 0 and b 1 can be constructed (as described in section 4.1).
Reference: [5] <author> David M. Kristol. </author> <title> "Proposed HTTP State-Info Mechanism", Internet Draft draft-kristol-http-state info-01.txt, </title> <type> IETF, </type> <month> September, </month> <year> 1995. </year> <note> This is a working draft. </note>
Reference-contexts: However, in some cases, such as clients located behind a proxy cache, predictd will not be able to distinguish between accesses from different clients. One way of getting around this problem is to use mechanisms (such as those proposed in <ref> [5] </ref>) to pass session-state identification between clients and servers even when there is a proxy between them. Predictd bases its predictions on the dependency graph.
Reference: [6] <author> Jeffrey C. </author> <title> Mogul. </title> <booktitle> "The Case for Persistent-Connection HTTP", Proceedings of the ACM SIGCOMM Conference, </booktitle> <address> Boston, MA, </address> <month> August, </month> <year> 1995. </year>
Reference-contexts: These result in considerable delays. 2.2 Persistent Connection HTTP (P-HTTP) We briefly discuss persistent connection HTTP (P-HTTP) proposed by Padmanabhan and Mogul [8] (the term P-HTTP is from <ref> [6] </ref>). P-HTTP uses a single, long-lived TCP connection for multiple HTTP transactions. The connection stays open for all the inline images of a single document, and across multiple HTML retrievals. This helps solve the first problem mentioned above.
Reference: [7] <author> Netscape Communications Corporations, </author> <note> http://www.netscape.com, 1996. </note>
Reference-contexts: The fixed startup latency of a file retrieval, which largely arises due to network round-trip delays, could be overlapped with on-going transfers. This models the effect of multiple parallel connections used by Netscape Navigator <ref> [7] </ref> or pipelined requests described in [8]. Finally, for simplicity we ignore the interaction between data transfers to different clients. While this could introduce inaccuracies, we believe that this is a plausible assumption for the following reason.
Reference: [8] <author> Venkata N. Padmanabhan and Jeffrey C. Mogul. </author> <title> "Improving HTTP Latency", </title> <booktitle> Proceedings of the Second International World Wide Web Conference, </booktitle> <address> Chicago, IL, </address> <pages> pages 995-1005, </pages> <month> October, </month> <year> 1994. </year> <note> (An updated version appeared in Computer Networks and ISDN Systems, v.28, nos.1&2, </note> <month> December </month> <year> 1995, </year> <pages> pp. 25-35.) </pages>
Reference-contexts: The rest of this paper is organized as follows. In section 2, we briefly discuss the basics of HTTP that are needed to understand the rest of this paper. In that section we also briefly describe the modifications to HTTP proposed in <ref> [8] </ref>. In section 3, we present our scheme for predictive prefetching. The methodology used for the simulation experiments is described in section 4, and the results are presented in 5. In section 6, we discuss some issues pertaining to prefetching. <p> These result in considerable delays. 2.2 Persistent Connection HTTP (P-HTTP) We briefly discuss persistent connection HTTP (P-HTTP) proposed by Padmanabhan and Mogul <ref> [8] </ref> (the term P-HTTP is from [6]). P-HTTP uses a single, long-lived TCP connection for multiple HTTP transactions. The connection stays open for all the inline images of a single document, and across multiple HTML retrievals. This helps solve the first problem mentioned above. <p> The connection stays open for all the inline images of a single document, and across multiple HTML retrievals. This helps solve the first problem mentioned above. The HTTP/1.1 protocol [2] also defines a persistent connection mechanism to solve the same problem. To avoid the second problem, <ref> [8] </ref> proposes two new HTTP methods (primitives), GETALL and GETLIST, that allow pipelining requests and responses between a client and a server. GETALL is a request to fetch the specified HTML file and all inline images that reside on the server. <p> Together, these modifications result in considerably reduced retrieval latency, in some cases less than half the original latency. 3 Predictive Prefetching It is clear from section 2.1 that the retrieval of a typical Web page involves several network round trips using HTTP/1.0. P-HTTP reduces this cost considerably, but as <ref> [8] </ref> reports image-rich Web pages still suffer from multi-second retrieval latencies. In light of this, we decided to investigate techniques that do not actually reduce retrieval time, but still improve response time perceived by the user. Users usually browse the Web by following hyperlinks from one Web page to another. <p> The fixed startup latency of a file retrieval, which largely arises due to network round-trip delays, could be overlapped with on-going transfers. This models the effect of multiple parallel connections used by Netscape Navigator [7] or pipelined requests described in <ref> [8] </ref>. Finally, for simplicity we ignore the interaction between data transfers to different clients. While this could introduce inaccuracies, we believe that this is a plausible assumption for the following reason.
Reference: [9] <author> Venkata N. Padmanabhan. </author> <title> "Improving World Wide Web Latency", </title> <type> Technical Report UCB/CSD-95 875, </type> <institution> Computer Science Division, University of California, Berkeley, </institution> <address> CA, </address> <month> May, </month> <year> 1995 </year>
Reference: [10] <author> J.Postel. </author> <title> "Transmission Control Protocol", </title> <type> RFC 793, </type> <institution> Network Information Center, SRI International, </institution> <month> September, </month> <year> 1981. </year>
Reference-contexts: In section 6, we discuss some issues pertaining to prefetching. We present our conclusions in section 7. 2 HTTP Protocol Elements The HTTP protocol is layered over a reliable bidirectional byte stream, normally TCP <ref> [10] </ref>. Each HTTP interaction consists of a request sent from the client to the server, followed by a response sent back from the server to the client. Requests and responses are expressed in a simple ASCII format. Most existing implementations conform to the original version of the protocol, HTTP/1.0 [1].
Reference: [11] <author> Simon E. Spero. </author> <title> "Analysis of HTTP Performance Problems", </title> <address> URL http://sunsite.unc.edu/mdma-release/http-prob.html, July, </address> <year> 1994. </year>
References-found: 11

