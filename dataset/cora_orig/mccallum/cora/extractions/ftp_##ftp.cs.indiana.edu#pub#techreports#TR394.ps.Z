URL: ftp://ftp.cs.indiana.edu/pub/techreports/TR394.ps.Z
Refering-URL: http://www.cs.indiana.edu/trindex.html
Root-URL: 
Title: Incomplete Cholesky Factorization with Sparsity Pattern Modification  
Author: Xiaoge Wang Kyle Gallivan Randall Bramley 
Date: December 21, 1993  
Address: Bloomington  Illinois- Urbana  Bloomington  
Affiliation: Department of Computer Science Indiana University  Department of Electrical and Computer Engineering University of  Department of Computer Science Indiana University  
Abstract: This paper proposes, analyzes, and numerically tests methods to assure the existence of incomplete Cholesky (IC) factorization preconditioners, based solely on the target sparsity pattern for the triangular factor R. If the sparsity pattern has a simple property (called property C+), then the IC factor exists in exact arithmetic. Two algorithms for modifying the target sparsity pattern to have property C+ are proposed, one based on adding elements into the set of retained elements and the other based on dropping elements. Tests show that the modifications do ensure the numerical existence of the IC factor, and the resulting preconditioners are effective in accelerating the conjugate gradient iteration method.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Chu, A. George, J. Liu, and E. Ng, SPARSPAK: </author> <title> Waterloo sparse matrix package, user's guide for SPARSPAK-A, </title> <type> Tech. Rep. </type> <institution> CS-84-36, Department of Computer Science, University of Waterloo, </institution> <year> 1984. </year>
Reference-contexts: Our experiments also tested the effect of matrix reorderings on the quality of preconditioning in terms of storage and time. We tested 4 orderings: minimum degree MD, nested dissection ND, and reverse nested dissection RND. We used the SPARSPAK-A package <ref> [1] </ref> for the reorderings. These orderings can be effective in reducing storage for Cholesky factorization and so also reduce the amount of computation.
Reference: [2] <author> I. S. Duff and G. A. Meurand, </author> <title> The effect of ordering on preconditioned conjugate gradients, </title> <journal> BIT, </journal> <volume> 29 (1989), </volume> <pages> pp. 635-657. </pages>
Reference-contexts: We tested 4 orderings: minimum degree MD, nested dissection ND, and reverse nested dissection RND. We used the SPARSPAK-A package [1] for the reorderings. These orderings can be effective in reducing storage for Cholesky factorization and so also reduce the amount of computation. Testing and analysis by other researchers <ref> [2, 3] </ref> has shown that orderings which favor parallelism may degrade the quality of IC preconditioner by causing an increase in the number of iterations. Our testing in part is to see if such an ordering degrades the quality of the preconditioner even when the pattern is modified.
Reference: [3] <author> V. Eijkhout, </author> <title> Beware of unperturbed modified incomplete factorizations, </title> <type> Tech. Rep. CSRD Report No. 1109, </type> <institution> CSRD, University of Illinois at Urbana-Champaign, </institution> <year> 1991. </year>
Reference-contexts: We tested 4 orderings: minimum degree MD, nested dissection ND, and reverse nested dissection RND. We used the SPARSPAK-A package [1] for the reorderings. These orderings can be effective in reducing storage for Cholesky factorization and so also reduce the amount of computation. Testing and analysis by other researchers <ref> [2, 3] </ref> has shown that orderings which favor parallelism may degrade the quality of IC preconditioner by causing an increase in the number of iterations. Our testing in part is to see if such an ordering degrades the quality of the preconditioner even when the pattern is modified.
Reference: [4] <author> G. H. Golub and C. F. Van Loan, </author> <title> Matrix Computations, </title> <publisher> Johns Hopkins, </publisher> <editor> 2nd ed., </editor> <year> 1989. </year>
Reference-contexts: 1 Introduction The incomplete Cholesky (IC) factorization is one of the most important and commonly used preconditioners for iterative methods of solving large sparse symmetric positive definite linear systems <ref> [4] </ref>. Its major weakness is a lack of robustness, by which we mean the failure of fl Work supported by NSF grants CDA-9309746 and CCR-9120105 1 the factorization due to nonpositive pivots. To overcome this difficulty, several modification methods have been suggested [6][5][9].
Reference: [5] <author> A. Jennings and G. M. Malik, </author> <title> Partial elimination, </title> <journal> Journal of the Institute of Mathematics and Its Applications, </journal> <volume> 20 (1977), </volume> <pages> pp. 307-316. </pages>
Reference: [6] <author> T. A. Manteuffel, </author> <title> Shifted incomplete Choleski factorization, in Sparse Matrix Proceedings 1978, </title> <editor> I. S. Duff and G. Stewart, eds., Philadelphia,PA, </editor> <booktitle> 1979, </booktitle> <publisher> SIAM Publications. </publisher>
Reference: [7] <author> X. Wang, </author> <title> Incomplete factorization preconditioning for linear least squares problems, </title> <type> PhD thesis, </type> <institution> University of Illinois Urbana-Champaign, </institution> <year> 1993. </year> <note> Also available as Technical Report # UIUCDCS-R-93-1834, </note> <institution> Department of Computer Science, University of Illinois at Urbana - Champaign. </institution>
Reference-contexts: Since the IMGS factorization always exists when A is full rank, this guarantees the robustness of IC factorization (proofs of these results can be found in <ref> [8, 7] </ref>). In this paper we present this strategy independent from the IMGS algorithm and instead base it on an understanding of the relationship between complete and incomplete Cholesky factorization. In the next section, we define the requisite sparsity pattern characteristics Property C and Property C+. <p> How should we adjust the original pattern so that the output of the modification algorithms is optimal? For example, we can use the 18 19 numerical or structural strategies suggested in <ref> [7] </ref> to reduce the density of the initial target sparsity pattern before applying MPADD. We can also use the technique of allowing a given number of levels of fill-in (the so-called IC (s) preconditioners) to increase the density of original pattern before applying MPDROP. <p> A better understanding of this pattern modification issue will probably come from further delineating the relation between elimination trees and C-trees and the relation between MPADD and a symbolic analysis of compressed incomplete modified Gram-Schmidt factorization (see <ref> [7] </ref>). The reordering strategies examined here all are derived from efforts to reduce the fill-in during complete factorization.
Reference: [8] <author> X. Wang, K. A. Gallivan, and R. Bramley, CIMGS: </author> <title> A incomplete orthogonaliza-tion preconditioner, </title> <type> Tech. Rep. 393, </type> <institution> Department of Computer Science, Indiana University, Bloomington, </institution> <note> IN 47405, </note> <year> 1993. </year>
Reference-contexts: Since the IMGS factorization always exists when A is full rank, this guarantees the robustness of IC factorization (proofs of these results can be found in <ref> [8, 7] </ref>). In this paper we present this strategy independent from the IMGS algorithm and instead base it on an understanding of the relationship between complete and incomplete Cholesky factorization. In the next section, we define the requisite sparsity pattern characteristics Property C and Property C+.
Reference: [9] <author> G. Wittum and F. Liebau, </author> <title> On truncated incomplete decompositions, </title> <journal> BIT, </journal> <volume> 29 (1989), </volume> <pages> pp. 719-740. </pages>
References-found: 9

