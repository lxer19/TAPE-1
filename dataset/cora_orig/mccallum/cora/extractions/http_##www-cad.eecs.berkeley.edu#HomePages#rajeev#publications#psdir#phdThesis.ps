URL: http://www-cad.eecs.berkeley.edu/HomePages/rajeev/publications/psdir/phdThesis.ps
Refering-URL: http://www-cad.eecs.berkeley.edu/HomePages/rajeev/publications/publications.html
Root-URL: http://www.cs.berkeley.edu
Title: Design and Implementation Verification of Finite State Systems  
Author: by Rajeev Kumar Ranjan 
Degree: B.Tech. (Indian Institute of Technology, Kanpur) 1990 M.S.  1992 A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in EngineeringElectrical Engineering and Computer Sciences in the GRADUATE DIVISION of the UNIVERSITY of CALIFORNIA, Berkeley Committee in charge: Professor Robert K. Brayton, Chair Professor Alberto Sangiovanni-Vincentelli Professor Ilan Adler  
Date: Fall 1997  
Affiliation: (University of Illinois at Urbana-Champaign)  
Abstract-found: 0
Intro-found: 1
Reference: [AC94] <author> P. Ashar and M. Cheong. </author> <title> Efficient Breadth-First Manipulation of Binary Decision Diagrams. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer-Aided Design, </booktitle> <pages> pages 62227, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Ochi et al. [OYY93] proposed the breadth-first implementation approach to regularize memory accesses, which leads to fewer page faults. As a result, BDDs of very large size (up to 12 million nodes) can be handled. Ashar et al. <ref> [AC94] </ref> have presented an improved breadth-first algorithm, which enables manipulation of BDDs with up to 100 million nodes. 1.5. <p> In Chapter 3, we discuss new algorithms for BDD manipulation that exploit the memory hierarchy by reorganizing the overall computation. The algorithms described in this chapter extend the ideas presented by Ochi et al. [OIY91, OYY93] and Ashar et al. <ref> [AC94] </ref>. The new techniques based on the iterative breadth-first algorithm enable manipulation of very large BDDs by localizing the memory accesses. <p> The basis of our work is the iterative breadth-first BDD manipulation algorithm proposed by Ochi et al. [OYY93] and later improved by Ashar et al. <ref> [AC94] </ref>. <p> However, their approach has two disadvantages: i) it is observed that the QRBDD is several times larger than the corresponding BDD <ref> [AC94] </ref>, which makes this approach impractical for manipulating very large BDDs, and ii) because of larger number of 48 CHAPTER 3. BREADTH-FIRST BDD MANIPULATION nodes in the operand BDDs, the total computation increases. <p> BREADTH-FIRST BDD MANIPULATION nodes in the operand BDDs, the total computation increases. Due to these problems, this approach performed poorly compared to the conventional depth-first approach for BDD sizes that fit the main memory. Ashar and Cheong <ref> [AC94] </ref>, use a BLOCK-INDEX table to determine the variable index from a BDD pointer by performing an associative lookup. <p> This approach overcomes the size problem of the previous approach by employing BDDs instead of QRBDDs. However, it suffers from significant overhead (about a factor of 2.65) as compared to a depth-first based algorithm for manipulating BDDs which fit within the main memory <ref> [AC94] </ref>. 3.3 Our Approach Our approach to handling the variable index determination problem differs from the works of Ashar et al. and Ochi et al. in the following aspects: 1. A new BDD node data structure is introduced to determine the variable index while preserving the locality of accesses. <p> Use of a customized memory manager to allocate BDD nodes which are quad-word aligned. The quad-word alignment improves the cache performance by fl Since the difference in the index of a node and its child node can be arbitrary in a BDD, strictly speaking, the traversal proposed in <ref> [AC94] </ref> is level-by-level and not breadth-first. However, in this dis sertation, we overload the term breadth-first manipulation to mean level-by-level traversal [Shi97]. 3.4. MEMORY ACCESS PATTERN 49 mapping a BDD node to a single cache line. These three techniques eliminate the overheads associated with the previous breadth-first approaches. <p> To overload the use of the REQUEST data structure with the BDD node data structure <ref> [AC94] </ref>, the REQUEST data structure is limited to 16 bytes. Before the APPLY phase, each REQUEST represents operand BDDs, each of which requires 6 bytes. Therefore, we allow only two operand operations. <p> We use dfs-ordering in SIS to order the variables. The number of BDD nodes needed to represent a particular circuit may be significantly different from those reported in the literature (e.g. <ref> [AC94] </ref>) due to a different variable ordering. However, this issue is orthogonal to demonstrating the performance of our package for a given variable ordering. The following set of experiments were carried out to demonstrate the performance of our BDD package: 1. <p> It is seen that BDDs with more than 23 million nodes are built in less than nine hours. We also made a black box comparison with the BFS algorithm (developed at NEC) <ref> [AC94] </ref> on SUN Sparc2 workstation with 40MB main memory. The results for creating output BDDs for C6288 sub-circuits are shown in Table 3.4. On average our 3.9. <p> Since it is very expensive to access the data across the network compared to the workstation main memory, any attempt to use depth-first manipulation algorithm on a NOW will meet limited success. The breadth-first iterative algorithm <ref> [OYY93, AC94, SRBS96] </ref> (see Figures 3.10, 3.11, and 3.12) attempts to regularize the memory access pattern by traversing the operand BDDs on a level-by-level basis and by using a customized memory allocator that allocates the BDD nodes for a specific variable id from the same page. <p> In fact, dynamic ordering is established as a critical component for any BDD package to be used for practical-sized problems. In the last three chapters (Chapters 3, 4, and 5), we saw how the breadth-first manipulation <ref> [OYY93, AC94, SRBS96] </ref> techniques exploit memory hierarchy in a computer system to efficiently manipulate very large BDDs which do not fit in the main memory. <p> The first implementation of breadth-first manipulation ([OYY93]) used padding nodes to overcome the cofactor index determination problem, i.e., their algorithm manipulated quasi-reduced BDDs and indices of cofactors were always one more than the indices of the corresponding nodes. As reported in <ref> [AC94] </ref>, this approach has significant memory and computational overheads. Moreover, an arbitrary overwriting of nodes during variable swapping would result in the loss of locality (nodes of an index would belong to the several different pages in the memory, sharing with nodes of other indices). The approach in [AC94] uses a <p> reported in <ref> [AC94] </ref>, this approach has significant memory and computational overheads. Moreover, an arbitrary overwriting of nodes during variable swapping would result in the loss of locality (nodes of an index would belong to the several different pages in the memory, sharing with nodes of other indices). The approach in [AC94] uses a table which maps the page address of a node to its index, i.e., each page address is uniquely associated to an index. This mapping breaks down if we arbitrarily overwrite the content of an address during variable swapping.
Reference: [ACM96] <author> P. Arunachalam, C. Chase, and D. Moundanos. </author> <title> Distributed Binary Decision Diagrams for Verification of Large Circuits. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer Design, </booktitle> <pages> pages 36570, </pages> <year> 1996. </year>
Reference-contexts: Our approach will take advantage of performance enhancements achieved by NOW research community. 102 CHAPTER 4. BDDS ON A NETWORK OF WORKSTATIONS 4.6 Related Work Arunachalam et al. <ref> [ACM96] </ref> have presented a technique to manipulate BDDs on a network of workstations. They also target alleviating the memory consumption problem by exploiting the memory available in a cluster of workstations. However, in their approach, the distribution of BDD nodes on the workstations is random.
Reference: [ACP94] <author> T. E. Anderson, D. E. Culler, and D. A. Patterson. </author> <title> A Case for NOW: Network of Workstations. </title> <type> Technical Report UCB/ERL M94/58, </type> <institution> Electronics Research Lab, Univ. of Cali-fornia, Berkeley, </institution> <address> CA 94720, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Over the next few years, the networks are expected to become faster in terms of the latency, the software overhead, and the bandwidth <ref> [ACP94] </ref>. However, the ratio of time to access the remote memory which involves a network transaction vs. the time to access the main memory is still expected to be the order of 1000. This qualitative analysis has important implication when distributing the BDD nodes across the several workstation memories. <p> Hence, the performance of our approach is significantly dominated by the penalty incurred during message transfers. The hope is that with the ongoing research in NOW community <ref> [ACP94] </ref> which includes using asynchronous transfer mode, parallel file server, and active message passing will result in low network latency and overhead. Our approach will take advantage of performance enhancements achieved by NOW research community. 102 CHAPTER 4.
Reference: [ADG91] <author> P. Ashar, S. Devadas, and A. Ghosh. </author> <title> Boolean Satisfiability and Equivalence Checking Using General Binary Decision Diagrams. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer Design, </booktitle> <pages> pages 25964, </pages> <year> 1991. </year>
Reference-contexts: Some of them are OFDD [KSR92] and OKFDD [DST + 94]. Relaxing the ordering requirement: For some functions all variable orderings result in exponential BDD sizes in the number of variables [Bry91]. In <ref> [ADG91] </ref>, the decision diagram is modified to allow variables to appear (possibly multiple times) in different orders for different paths. However, with this generalization, the canonicity of BDDs is lost and the algorithmic complexity of some common operations is exponential.
Reference: [AG89] <author> G. S. Almasi and A. Gottleib. </author> <title> Highly Parallel Computing. </title> <address> Benjamin/Cummings, Redwood, CA, </address> <year> 1989. </year>
Reference-contexts: Finally, we conclude by indicating the potential for further improvements. 5.1 Parallel Computer Architectures The classic definition of a parallel computer is captured in following quote from <ref> [AG89] </ref>: A parallel computer is a collection of processing elements that cooperate and communicate to solve large problems fast. These days parallel architectures have become the mainstay of scientific computing, including physics, chemistry, material science, biology, astronomy, earth sciences, and others.
Reference: [AGM96] <author> P. Ashar, A. Gupta, and S. Malik. </author> <title> Using Complete-1-Distinguishability for FSM Equivalence Checking. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer-Aided Design, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: In this approach, the sequential optimization is constrained in order to reduce the verification complexity. In particular, by making all the latches observable, the sequential synthesis reduces to combinational optimization leading to combinational verification problem. Solution proposed in <ref> [AGM96] </ref> falls in this category. We propose a practical verification technique for transformations which include arbitrary combination of retiming and combinational optimization operations on a con 22 CHAPTER 1. INTRODUCTION strained form of the circuit. <p> We show that implementation verification after performing repeated retiming and synthesis on this class of circuit reduces to a combinational verification problem. Our methodology can also be viewed as offering another point in the tradeoff curve between constraints-on-synthesis versus complexity of verification <ref> [AGM96] </ref>. 1.7 Thesis Organization This thesis is organized into three parts. In the first part of the thesis (Chapters 3, 4, 5, and 6), we present a set of computer architecture based techniques which target the efficient manipulation of BDDs. <p> Although, the state-of-the-art symbolic methods can deal with circuits with up to a few hundred latches, their capability falls below the smallest size designs being optimized in industry. In <ref> [AGM96] </ref>, a technique is described where sequential optimization is performed on a modified circuit (where each pair of states can be distinguished by applying an input in a single clock cycle). <p> In this approach, the sequential optimization is constrained in order to reduce the verification complexity. In the limit, by making all the latches observable, the sequential synthesis reduces to combinational optimization leading to combinational verification problems. The solution proposed in <ref> [AGM96] </ref> falls in this category. Our methodology can also be viewed as offering another point in the tradeoff curve between constraints-on-synthesis versus complexity-of-verification. We propose a technique which reduces the sequential equivalence problem to an instance of combinational equivalence; hence it can be applied in practical verification 9.3.
Reference: [Ake78] <author> S. B. Akers. </author> <title> Binary Decision Diagrams. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-37:50916, </volume> <month> June </month> <year> 1978. </year>
Reference-contexts: The notation and terminology used in the work on sequential verification (Chapters 8 and 9) is described in Section 2.2. 2.1 Binary decision diagrams The origin of Binary Decision Diagram (BDD) goes back to the seminal paper by Ak-ers <ref> [Ake78] </ref>, in which Boolean functions were represented by decision graphs. However their widespread usage has started only after 1986, when a set of algorithms were proposed to construct and manipulate these data structures [Bry86].
Reference: [Amd67] <author> G. </author> <title> Amdahl. Validity of the Single Processor Approach to Achieving Large Scale Computing Capabilities. </title> <booktitle> In AFIPS Spring Joint Computer Conference, </booktitle> <pages> pages 48385, </pages> <year> 1967. </year>
Reference-contexts: Every program has some serial part and some parallel parts. Ignoring the effect of multiple caches and main memories, the total available speedup S is limited by Am-dahl's law <ref> [Amd67] </ref> which roughly states that the speedup cannot exceed the reciprocal of fraction of serial computation S = (T s + T p =N) where T s and T p represent time for serial and parallel computations, respectively.
Reference: [ASB93] <author> A. Aziz, V. Singhal, and R. K. Brayton. </author> <title> Verifying Interacting Finite State Machines: Complexity Issues. </title> <type> Technical Report UCB/ERL M93/68, </type> <institution> Electronics Research Lab, Univ. of California, Berkeley, </institution> <address> CA 94720, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: Hence algorithms that directly manipulate states will have time and space complexity that is exponential in the size of the system description. Indeed, the computational complexity of state transition graph related problems is known to be PSPACEcomplete <ref> [ASB93] </ref>. The complexity introduced by concurrent interaction is popularly referred to as the state explosion problem. The quest for heuristic solutions to this problem forms the forefront of research in formal verification [ASS + 94, BCMD90, CHM + 93, CM90b, Gra94].
Reference: [ASS + 94] <author> A. Aziz, T. R. Shiple, V. Singhal, R. K. Brayton, and A. L. Sangiovanni-Vincentelli. </author> <title> Formula-Dependent Equivalence for Compositional CTL Model Checking. </title> <booktitle> In Computer Aided Verification, volume 818 of Lecture Notes in Computer Science, </booktitle> <pages> pages 324337. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: Indeed, the computational complexity of state transition graph related problems is known to be PSPACEcomplete [ASB93]. The complexity introduced by concurrent interaction is popularly referred to as the state explosion problem. The quest for heuristic solutions to this problem forms the forefront of research in formal verification <ref> [ASS + 94, BCMD90, CHM + 93, CM90b, Gra94] </ref>. Transition relations and sets of states can be represented using BDDs of their characteristic functions, which can be used for efficient fixed-point computations [BCMD90, CM90b, Pix90]. <p> EFFICIENT TECHNIQUES FOR STATE SPACE TRAVERSAL variable ordering. Other data structures might be useful in these cases. There is also a wide class of heuristics, orthogonal to the approaches we have taken, for coping with the state explosion problem; such as property-specific reductions <ref> [ASS + 94] </ref>, abstrac tions [Gra94], and conservative approximations to reached state sets [CHM + 93].
Reference: [Bai91] <author> D. Bailey. </author> <title> Twelve Ways to Fool the Masses When Giving Performance Results on Parallel Computers. </title> <booktitle> In Supercomputing Review, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: The amount of serial work may be constant or increasing very slowly with the problem size, hence increasing the problem size decreases the fraction of serial computation, thereby improving the chances for obtaining high speedups <ref> [Bai91] </ref>. The amount of parallelism in the application depends on the level of abstraction that determines the granularity. Usually, the finer the granularity the higher the parallelism. However, finer granularity, usually results in higher volume of communication.
Reference: [BBDG + 94] <author> I. Beer, S. Ben-David, D. Geist, R. Gewirtzman, and M. Yoeli. </author> <title> Methodology and System for Practical Formal Verification of Reactive Hardware. </title> <booktitle> In Computer Aided Verification, volume 818 of Lecture Notes in Computer Science, </booktitle> <pages> pages 18293. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year> <note> 283 284 BIBLIOGRAPHY </note>
Reference-contexts: At the end of the algorithm, the next-state functions of latches do not contain present-state variables corresponding to redundant latches. These variables are not considered for further BDD manipulations. In a related work Beer et al. <ref> [BBDG + 94] </ref> also mentioned a constant-elimination technique to reduce the number of inputs and memory elements. 7.6.2 Latch Removal by Retiming Retiming rearranges the storage elements in a circuit to reduce its cycle time or to reduce the number of storage elements, without changing its functionality.
Reference: [BBJR97] <author> G. P. Bischoff, K. S. Brace, S. Jain, and R. Razdan. </author> <title> Formal Implementation Verification of the Bus Interface Unit for the Alpha 21164 Microprocessor. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer Design, </booktitle> <year> 1997. </year>
Reference-contexts: Experimental results indicate that imposing constraints does not result in significant optimization penalty. Our strategy can be used to obtain faster circuits by allowing the retiming transformations while performing fast verification as indicated by our experimental results. In <ref> [BBJR97] </ref>, implementation verification of the bus interface unit for the Alpha 21264 microprocessor is performed. More specifically, gate-level extraction of custom-designed transistor level schematics is verified against the RTL. They used a retiming comparison algorithm for verifying acyclic sequential circuits.
Reference: [BC95] <author> R. E. Bryant and Y.-A. Chen. </author> <title> Verification of Arithmetic Circuits with Binary Momemt Diagrams. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <pages> pages 53541, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: In particular, allowing arbitrary values on the terminal nodes (MTBDD [CMZ + 93], ADD [BFG + 93]), incorporating numeric weights on the edges (EVBDD [LS92]), changing the function decomposition with respect to its variables (BMD and flBMD <ref> [BC95] </ref>), or a combination of some of the above techniques (HDD [CFZ95]) have been proposed. These techniques differ in their representation sizes and the manipulation complexity.
Reference: [BCL91a] <author> J. R. Burch, E. M. Clarke, and D. E. </author> <title> Long. Representing Circuits More Efficiently in Symbolic Model Checking. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: If there are K clusters C 1 ;C 2 ; C k of latches, then the image computation can be equivalently written as, Image (A (~x)) = 9~x; ~u [ A (~x) i=k i=1 where T C i = j2C i T j (~x;~u; y j ). In <ref> [BCL91a] </ref>, Burch also proposed the use of clustered transition relations to represent circuits more efficiently. Latches were grouped together to form clusters but no automatic way to form clusters was given. Their technique possibly required user expertise, based on circuit structure. <p> This range computation is performed using a balanced binary tree leaves correspond to terms and variables at nodes of the tree that do not appear in the support of nodes elsewhere are existentially quantified. Burch <ref> [BCL91a] </ref> criticized this approach on the grounds that generalized co-factor may introduce new variables in the supports of the terms and delay the ability to quantify out variables. Heuristically, this would lead to larger BDD size of the intermediate product terms. <p> Thus the space requirement and the efficiency of image and pre-image computations become dependent on the order in which these clusters are processed. In <ref> [BCL91a] </ref>, an ordering scheme of the partitioned transition relation is proposed, based on the semantics of the underlying model. However, this requires detailed understanding of the semantics of 7.3.
Reference: [BCL91b] <author> J. R. Burch, E. M. Clarke, and D. E. </author> <title> Long. Symbolic Model Checking with Partitioned Transition Relations. </title> <booktitle> In Proc. Intl. Conf. on VLSI, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: Sequential verification: In BDD-based sequential verification the goal is to represent the behavior of the finite state machine and to traverse the corresponding state-transition graph. Partitioned transition relations are used instead of monolithic transition relation to control the BDD sizes <ref> [TSL + 90, BCL91b, RAP + 95] </ref>. The state-space traversal, which requires image/pre-image computation as the core operations, can be made efficient by proper use of early variable quantification [TSL + 90, BCL91b, RAP + 95, GB94, KHB96]. <p> Partitioned transition relations are used instead of monolithic transition relation to control the BDD sizes [TSL + 90, BCL91b, RAP + 95]. The state-space traversal, which requires image/pre-image computation as the core operations, can be made efficient by proper use of early variable quantification <ref> [TSL + 90, BCL91b, RAP + 95, GB94, KHB96] </ref>. Approximation techniques can also be used for reachability analysis [CHM + 93, CHM + 94, RS95, SRSB97] where exact analysis is not feasible. 18 CHAPTER 1. <p> Some approaches keep the BDD sizes under control while increasing the number of BDD computations (e.g., network partitioning [Mat96, KK97, JNC + 96], partitioned transition relation <ref> [TSL + 90, BCL91b, RAP + 95] </ref>, etc.). These approaches trade-off memory consumption with computation time. BDD-based techniques are quite general and they are applicable to a broad range of problems.
Reference: [BCMD90] <author> J. R. Burch, E. M. Clarke, K. L. McMillan, and D. L. Dill. </author> <title> Sequential Circuit Verification Using Symbolic Model Checking. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: However, due to the explicit nature of this technique, it is limited to only a small number of state elements. Symbolic techniques, which model the sets of states and the transitions between them as Boolean functions, have been widely used <ref> [CBM89, Kuk89, BCMD90, TSL + 90] </ref>. A salient feature of these techniques is that the size of the underlying data structure (some form of decision diagram) does not depend on the number of states or the state elements in the circuit. <p> Part I Computer Architecture and BDD Manipulation 33 Chapter 3 Breadth-First BDD Manipulation T HE manipulation of very large BDDs is the key to success for BDD-based al gorithms for simulation [Bry91], synthesis [CBM89, TSL + 90], and verification <ref> [BCMD90, McM93, BSA + 96a] </ref> of integrated circuits and systems. <p> Indeed, the computational complexity of state transition graph related problems is known to be PSPACEcomplete [ASB93]. The complexity introduced by concurrent interaction is popularly referred to as the state explosion problem. The quest for heuristic solutions to this problem forms the forefront of research in formal verification <ref> [ASS + 94, BCMD90, CHM + 93, CM90b, Gra94] </ref>. Transition relations and sets of states can be represented using BDDs of their characteristic functions, which can be used for efficient fixed-point computations [BCMD90, CM90b, Pix90]. <p> The quest for heuristic solutions to this problem forms the forefront of research in formal verification [ASS + 94, BCMD90, CHM + 93, CM90b, Gra94]. Transition relations and sets of states can be represented using BDDs of their characteristic functions, which can be used for efficient fixed-point computations <ref> [BCMD90, CM90b, Pix90] </ref>. BDDs are now extensively used for both design and implementation verification of hardware systems and many non-trivial design examples have been verified using BDDs [CYF94, McM93]. Still, there are many instances of medium sized circuits that cannot be verified using existing BDD techniques. <p> Monolithic Transition Relation: In this representation, the transition relation of the system is represented by a single BDD <ref> [BCMD90] </ref> which is the conjunction of the transition relations of the individual latches. As the circuit complexity grows, the size of the transition relation usually explodes. Hence this approach becomes infeasible for large, complex circuits. <p> Equivalence between two circuits implies identical values of corresponding outputs in all reachable states. Explicit state enumeration techniques perform an explicit traversal of the state space [DMN88, DDHY92]. Due to the explicit nature of this technique, it is limited to only a small number of state elements. Symbolic techniques <ref> [CBM89, BCMD90] </ref> implicitly perform state-space traversal on the product machine. A salient feature of these techniques is that the size of the underlying decision diagram data structures does not depend on the number of states or the state elements in the circuit.
Reference: [BFG + 93] <author> R. I. Bahar, E. A. Frohm, C. M. Gaona, G. D. Hachtel, E. Macii, A. Pardo, and F. Somenzi. </author> <title> Algebraic Decision Diagrams and Their Applications. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer-Aided Design, </booktitle> <pages> pages 18891, </pages> <year> 1993. </year>
Reference-contexts: INTRODUCTION Representing numeric valued functions: For functions of Boolean variables with non Boolean ranges, a series of representation schemes have been proposed. In particular, allowing arbitrary values on the terminal nodes (MTBDD [CMZ + 93], ADD <ref> [BFG + 93] </ref>), incorporating numeric weights on the edges (EVBDD [LS92]), changing the function decomposition with respect to its variables (BMD and flBMD [BC95]), or a combination of some of the above techniques (HDD [CFZ95]) have been proposed. These techniques differ in their representation sizes and the manipulation complexity.
Reference: [Bra93] <author> D. Brand. </author> <title> Verification of Large Synthesized Designs. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer-Aided Design, </booktitle> <pages> pages 5347, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: An orthogonal set of techniques, called structure-based techniques, use structural information about the circuit and the nature of transformations performed on it to obtain efficient verification algorithms. It has been established that a combination of functional and structure-based techniques provides a robust methodology for combinational verification <ref> [KK97, Mat96, RWK95, Bra93] </ref>. For sequential circuits, however, attempts to combine structural and functional techniques have been limited to smaller size examples or relatively minor transformations [HCC96b, HCC97]. In the next two chapters we investigate the implementation verification problem for circuits which have undergone repeated retiming and combinational synthesis transformations.
Reference: [BRB90] <author> K. S. Brace, R. L. Rudell, and R. E. Bryant. </author> <title> Efficient Implementation of a BDD Package. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <pages> pages 4045, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: However their widespread usage has started only after 1986, when a set of algorithms were proposed to construct and manipulate these data structures [Bry86]. For a complete description on various kinds of decision diagrams and the related terminology, please refer to <ref> [BRB90, Bry91, DB97] </ref>. Here we present a brief description of the data structure and the relevant terminology. The BDD of a function is a rooted, directed, acyclic graph. <p> In the last decade, extensive research has been done on variations of BDDs and the corresponding efficiency of representation and manipulation. A good survey can be found in [Bry95]. Below we briefly describe some of the terminology used in this work. For further details, refer to <ref> [BRB90] </ref>. Unique table: The unique table stores all the BDD nodes and facilitates the canonical representation of a function. For a given variable order, each Boolean function can be canonically represented by the top variable of the function and its two child nodes.
Reference: [BRSW87] <author> R. K. Brayton, R. Rudell, A. L. Sangiovanni-Vincentelli, and A. R. Wang. </author> <title> MIS: A Multiple-Level Logic Optimization System. </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits, </journal> <volume> CAD-6(6):106281, </volume> <month> November </month> <year> 1987. </year>
Reference-contexts: Our goal is to benefit from these results in establishing practical retiming and resynthesis logic optimization and verification methodologies. In the next chapter we propose a practical algorithm for this implementation verification problem. 8.1 Introduction In combinational synthesis <ref> [BRSW87, SSL + 92] </ref>, the positions of the latches are fixed and the logic is optimized. In retiming [LRS83, LS91], the latches are moved across fixed combinational gates.
Reference: [Bry86] <author> R. Bryant. </author> <title> Graph-based Algorithms for Boolean Function Manipulation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-35:67791, </volume> <month> August </month> <year> 1986. </year>
Reference-contexts: However their widespread usage has started only after 1986, when a set of algorithms were proposed to construct and manipulate these data structures <ref> [Bry86] </ref>. For a complete description on various kinds of decision diagrams and the related terminology, please refer to [BRB90, Bry91, DB97]. Here we present a brief description of the data structure and the relevant terminology. The BDD of a function is a rooted, directed, acyclic graph. <p> This is because in the parallelization of depth-first algorithm, the cofactors need to be processed in parallel (otherwise there would not be any concurrency). This is done by following some variant of two phase scheme APPLY followed by REDUCE as given in <ref> [Bry86] </ref>. This implies that some place holder is used to store the information about the child nodes (identical to the approach in breadth-first technique). 5.6 Related Work In this section, we describe a related work presented in [YO97].
Reference: [Bry87] <author> R. E. Bryant. </author> <title> Boolean Analysis of MOS Circuits. </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits, </journal> <pages> pages 63449, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: At each simulation step, the simulator computes the values of signals as Boolean functions of these variables, rather than as definite Boolean values. The Boolean functions obtained at the outputs of a circuit can be compared against the desired functions <ref> [Bry87] </ref>. This technique is primarily used to verify the combinational equivalence of two designs. Model checking is another method of property verification that is somewhat more abstract than symbolic simulation.
Reference: [Bry91] <author> R. Bryant. </author> <title> A methodology for hardware verification based on logic simulation. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 38(2):299328, </volume> <month> April </month> <year> 1991. </year>
Reference-contexts: Some of them are OFDD [KSR92] and OKFDD [DST + 94]. Relaxing the ordering requirement: For some functions all variable orderings result in exponential BDD sizes in the number of variables <ref> [Bry91] </ref>. In [ADG91], the decision diagram is modified to allow variables to appear (possibly multiple times) in different orders for different paths. However, with this generalization, the canonicity of BDDs is lost and the algorithmic complexity of some common operations is exponential. <p> However their widespread usage has started only after 1986, when a set of algorithms were proposed to construct and manipulate these data structures [Bry86]. For a complete description on various kinds of decision diagrams and the related terminology, please refer to <ref> [BRB90, Bry91, DB97] </ref>. Here we present a brief description of the data structure and the relevant terminology. The BDD of a function is a rooted, directed, acyclic graph. <p> All elementary set operations can thus be evaluated with a quadratic complexity on BDDs [CM95]. Part I Computer Architecture and BDD Manipulation 33 Chapter 3 Breadth-First BDD Manipulation T HE manipulation of very large BDDs is the key to success for BDD-based al gorithms for simulation <ref> [Bry91] </ref>, synthesis [CBM89, TSL + 90], and verification [BCMD90, McM93, BSA + 96a] of integrated circuits and systems.
Reference: [Bry95] <author> R. E. Bryant. </author> <title> Binary decision diagrams and beyond: enabling technologies for formal verification. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer-Aided Design, </booktitle> <pages> pages 23643, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: memory consumption can increase due to the overhead of maintaining arrays and large caches to store the results. 1.5.4 Solutions Based on Modification of Decision Diagrams In the last decade, research in the area of decision diagrams (DDs) has resulted in various kinds of DDs resulting in an alphabet soup <ref> [Bry95] </ref>. Different decision diagrams target reduction in DD size, simpler DD manipulation, etc. However, in general there is a trade-off between representation size and the manipulation complexity. <p> In the last decade, extensive research has been done on variations of BDDs and the corresponding efficiency of representation and manipulation. A good survey can be found in <ref> [Bry95] </ref>. Below we briefly describe some of the terminology used in this work. For further details, refer to [BRB90]. Unique table: The unique table stores all the BDD nodes and facilitates the canonical representation of a function.
Reference: [BSA + 96a] <author> R. K. Brayton, A. Sangiovanni-Vincentelli, A. Aziz, S.-T. Cheng, S. Edwards, S. Khatri, Y. Kukimoto, S. Qadeer, R. K. Ranjan, T. R. Shiple, G. Swamy, T. Villa, G. D. Hachtel, F. Somenzi, A. Pardo, and S. Sarwary. </author> <title> VIS: A System for Verification and Synthesis. </title> <booktitle> In Proc. of the 8th International Conference on Computer Aided Verification, volume 1102 of Lecture Notes in Computer Science, </booktitle> <pages> pages 428432. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: In Appendix A, we describe some of the software engineering aspects of CAL and its integration with synthesis and verification tools. In addition, our work on efficient state-space traversal and has been integrated inside the verification tool VIS <ref> [BSA + 96a] </ref> as one of the core engines. In Appendix B, we briefly discuss the VIS package and integration of our work inside it. Chapter 2 Preliminaries I N this chapter we will preview some background material required to understand various chapters of this thesis. <p> Part I Computer Architecture and BDD Manipulation 33 Chapter 3 Breadth-First BDD Manipulation T HE manipulation of very large BDDs is the key to success for BDD-based al gorithms for simulation [Bry91], synthesis [CBM89, TSL + 90], and verification <ref> [BCMD90, McM93, BSA + 96a] </ref> of integrated circuits and systems. <p> This package has been chosen for three main reasons: (i) in [SRBS96], it has been clearly shown to outperform other breadth-first based implementations, (ii) CAL is integrated with the synthesis tool SIS [SSL + 92] and verification tool VIS <ref> [BSA + 96a] </ref> making it easier to 148 CHAPTER 6. <p> The efficacy of these algorithms was demonstrated on ISCAS/MCNC sequential circuits as well as some industrial designs. Almost all the algorithms described in this chapter have been implemented in the verification tool VIS <ref> [BSA + 96a] </ref>. In particular, the image/pre-image computation techniques form the core engine for model checking. A brief description of the tool is given in Appendix B. Other BDD-based techniques which look promising include the existscofactor of [CC93], and the implicitly conjoined invariants of [HYD94]. <p> The VIS tool has been integrated with three different BDD packages [Som97, RS97, Lon93]. So far three releases of VIS have taken place. The latest release of VIS can be obtained from http://www-cad.eecs.berkeley.edu/vis fl For a detailed description of VIS architecture please refer to <ref> [BSA + 96b, BSA + 96a] </ref>. 279 280 APPENDIX B. VIS: VERIFICATION INTERACTING WITH SYNTHESIS Figure B.1 VIS Overview. 281 Figure B.2 Verification and Synthesis inside VIS. 282 APPENDIX B. VIS: VERIFICATION INTERACTING WITH SYNTHESIS VIS has found world-wide success in both industry and academic worlds.
Reference: [BSA + 96b] <author> R. K. Brayton, A. Sangiovanni-Vincentelli, A. Aziz, S.-T. Cheng, S. Edwards, S. Kha-tri, Y. Kukimoto, S. Qadeer, R. K. Ranjan, T. R. Shiple, G. Swamy, T. Villa, G. D. Hachtel, F. Somenzi, A. Pardo, and S. Sarwary. </author> <title> VIS: Tutorial. </title> <booktitle> In Proc. Formal Method in Computer-Aided Design, volume 1166 of Lecture Notes in Computer Science, </booktitle> <pages> pages 24856. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> BIBLIOGRAPHY 285 </note>
Reference-contexts: The VIS tool has been integrated with three different BDD packages [Som97, RS97, Lon93]. So far three releases of VIS have taken place. The latest release of VIS can be obtained from http://www-cad.eecs.berkeley.edu/vis fl For a detailed description of VIS architecture please refer to <ref> [BSA + 96b, BSA + 96a] </ref>. 279 280 APPENDIX B. VIS: VERIFICATION INTERACTING WITH SYNTHESIS Figure B.1 VIS Overview. 281 Figure B.2 Verification and Synthesis inside VIS. 282 APPENDIX B. VIS: VERIFICATION INTERACTING WITH SYNTHESIS VIS has found world-wide success in both industry and academic worlds.
Reference: [BW97] <author> B. Bollig and I. Wegener. </author> <title> Partitioned BDDs vs. Other BDD Models. </title> <booktitle> In Proc. IEEE/ACM Intl. Workshop on Logic Synthesis, </booktitle> <year> 1997. </year>
Reference-contexts: BDD partitioning: This approach is similar to the partitioned transition relation method or to creating a cutset in the network. However, the techniques proposed in this category are application independent. In particular, techniques are proposed to represent a function as a set of BDDs <ref> [NJFS96, BW97] </ref>. Avoiding intermediate BDD computation: In many BDD applications (symbolic sim ulation, reachability, etc.), some intermediate BDDs are obtained on the way to computing the final result. In some cases, the sizes of the intermediate BDDs could be large even though the final BDD size is small.
Reference: [CBM89] <author> O. Coudert, C. Berthet, and J. C. Madre. </author> <title> Verification of Sequential Machines Based on Symbolic Execution. </title> <editor> In J. Sifakis, editor, </editor> <booktitle> Proc. of the Workshop on Automatic Verification Methods for Finite State Systems, volume 407 of Lecture Notes in Computer Science, </booktitle> <pages> pages 36573, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: However, due to the explicit nature of this technique, it is limited to only a small number of state elements. Symbolic techniques, which model the sets of states and the transitions between them as Boolean functions, have been widely used <ref> [CBM89, Kuk89, BCMD90, TSL + 90] </ref>. A salient feature of these techniques is that the size of the underlying data structure (some form of decision diagram) does not depend on the number of states or the state elements in the circuit. <p> All elementary set operations can thus be evaluated with a quadratic complexity on BDDs [CM95]. Part I Computer Architecture and BDD Manipulation 33 Chapter 3 Breadth-First BDD Manipulation T HE manipulation of very large BDDs is the key to success for BDD-based al gorithms for simulation [Bry91], synthesis <ref> [CBM89, TSL + 90] </ref>, and verification [BCMD90, McM93, BSA + 96a] of integrated circuits and systems. <p> Equivalence between two circuits implies identical values of corresponding outputs in all reachable states. Explicit state enumeration techniques perform an explicit traversal of the state space [DMN88, DDHY92]. Due to the explicit nature of this technique, it is limited to only a small number of state elements. Symbolic techniques <ref> [CBM89, BCMD90] </ref> implicitly perform state-space traversal on the product machine. A salient feature of these techniques is that the size of the underlying decision diagram data structures does not depend on the number of states or the state elements in the circuit.
Reference: [CC93] <author> G. Cabodi and P. Camurati. </author> <title> Exploiting Cofactoring for Efficient FSM Symbolic Traversal Based on the Transition Relation. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer Design, </booktitle> <pages> pages 299303, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: In [BCL91a], an ordering scheme of the partitioned transition relation is proposed, based on the semantics of the underlying model. However, this requires detailed understanding of the semantics of 7.3. ORDERING OF CLUSTERED TRANSITION RELATIONS 169 the model and hence is not easily automated. <ref> [CC93] </ref> introduces a new exist generalized cofactor which allows for distribution of conjunction and quantification. <p> In particular, the image/pre-image computation techniques form the core engine for model checking. A brief description of the tool is given in Appendix B. Other BDD-based techniques which look promising include the existscofactor of <ref> [CC93] </ref>, and the implicitly conjoined invariants of [HYD94]. Certain limitations of BDD-based formal design verification cannot be solved by the techniques described in this work. For example, the BDD size of the reached set may be large under any 192 CHAPTER 7. EFFICIENT TECHNIQUES FOR STATE SPACE TRAVERSAL variable ordering.
Reference: [CCQ94] <author> G. Cabodi, P. Camurati, and S. Quer. </author> <title> Auxiliary Variables for Extending Symbolic Traversal Techniques to Data Paths. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <pages> pages 28993, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: The algorithm is shown in Figure 7.3. The resulting structural partition is shown in Figure 7.4. A related technique is also presented in [JNC + 96]. The idea of controlling BDD sizes by introducing variables has appeared in literature before <ref> [CM90a, CCQ94] </ref>.
Reference: [CES86] <author> E. M. Clarke, E. A. Emerson, and A. P. Sistla. </author> <title> Automatic Verification of Finite-State Concurrent Systems Using Temporal Logic Specifications. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 8(2):24463, </volume> <year> 1986. </year>
Reference-contexts: The model checker then checks automatically that the specification is satisfied <ref> [CES86] </ref>. In the last couple of years few commercial model checking tools have emerged Formal Check from Lucent Technologies, RuleBase from IBM, CheckOff from Abstract Hardware Ltd. to name a few. The most general and powerful methods of verification are based on general purpose theorem provers. <p> In both cases the underlying design is characterized by a Kripke structure <ref> [CES86] </ref>. fl For a brief background on FSM and the terminology used in this chapter, please refer Section 2.3. 7.1. MOTIVATION 161 fag fbg fag fbg fg s 4 s 3 s 6 fa; bg. <p> We can make use of the following fact: 9 ~x (T (~x;~u;~y)A (~x)) = 9 ~x T (~x;~u;~y)j A (~x) A (~x) (7.13) For a detailed description on the syntax and semantics of CTL, please refer to <ref> [CES86] </ref>. 176 CHAPTER 7. EFFICIENT TECHNIQUES FOR STATE SPACE TRAVERSAL where T (~x;~u;~y)j A (~x) denotes the generalized cofactor of T (~x;~u;~y) with respect to A (~x).
Reference: [CFZ95] <author> E. Clarke, M. Fujita, and X. Zhao. </author> <title> Hybrid Decision Diagrams: Overcoming the Limitations of MTBDDs and BMDs. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer-Aided Design, </booktitle> <month> November </month> <year> 1995. </year>
Reference-contexts: In particular, allowing arbitrary values on the terminal nodes (MTBDD [CMZ + 93], ADD [BFG + 93]), incorporating numeric weights on the edges (EVBDD [LS92]), changing the function decomposition with respect to its variables (BMD and flBMD [BC95]), or a combination of some of the above techniques (HDD <ref> [CFZ95] </ref>) have been proposed. These techniques differ in their representation sizes and the manipulation complexity. In general, any approach which targets BDD size, thereby reducing the memory consumption will also reduce the computation time, since the operand sizes, which determine the computation complexity, will reduce.
Reference: [CGRR94] <author> G. Cabodi, S. Gai, M. Rebaudengo, and M. S. Reordea. </author> <title> A Data Parallel Approach to Boolean Function Manipulation using BDDs. </title> <booktitle> In International Conference on Massively Parallel Computer Systems, </booktitle> <year> 1994. </year>
Reference-contexts: Several other researchers have made use of distributed shared memory architecture [PSC94, SB96] and data-parallel architecture <ref> [CGRR94] </ref>. 1.5.2 Application Specific Solutions In this approach, particular domains are targeted and their characteristics are exploited to limit BDD sizes and intermediate BDD size blow up. <p> Task synchronization was done using global broadcast and the communication was implemented using the active messages library. They presented results on small ISCAS examples with speed-ups of 20 to 32 on a 32-node CM-5. <ref> [CGRR94] </ref> used a massively-parallel computer (CM-200) in a data parallel approach where BDD nodes were distributed to the processing elements. Parallelism was achieved by allocating one processing element for each BDD node. <p> Scheme Generation Distrib ution P aradigm V olume [KC90 Shared-memorymultiprocessor ($) ApplyReduce High le el operations Highly coarse Locks Light [OIY91 V ector proces sor Breadth-first T emporary nodes process ing Fine grain Locks Medium [PSC94] Distrib uted Shared Memory ($$$$) ApplyReduce BDD nodes Fine grain Message pass ing vy <ref> [CGRR94] </ref> Massi v par allel processor ($$$$$$) ApplyReduce BDD nodes Fine grain Message P ing vy ] Distrib uted shared-memorymultiprocessor ($$$$) ApplyReduce BDD nodes Fine grain Message pass ing vy able 5.1 vious w in parallel BDD manipulation: a summary . Indicates the relati v cost of hardw are. 5.4. <p> Concurrent processing of the cofactors: In this case a place holder for the results of the cofactors is created and processing of the cofactors continues in parallel on different processors <ref> [PSC94, CGRR94, SB96] </ref>. 3. Breadth-first processing: In this case, breadth-first manipulation scheme is used. The set of temporary nodes (similar to REQUESTs) are maintained at each index, processors divide the set of temporary nodes equally.
Reference: [CHM + 93] <author> H. Cho, G. D. Hachtel, E. Macii, B. Plessier, and F. Somenzi. </author> <title> Algorithms for Approximate FSM Traversal. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <pages> pages 2530, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: The state-space traversal, which requires image/pre-image computation as the core operations, can be made efficient by proper use of early variable quantification [TSL + 90, BCL91b, RAP + 95, GB94, KHB96]. Approximation techniques can also be used for reachability analysis <ref> [CHM + 93, CHM + 94, RS95, SRSB97] </ref> where exact analysis is not feasible. 18 CHAPTER 1. INTRODUCTION Design verification: Partitioned transition relations and efficient image computation techniques used for sequential implementation verification are also applicable in design verification. <p> Indeed, the computational complexity of state transition graph related problems is known to be PSPACEcomplete [ASB93]. The complexity introduced by concurrent interaction is popularly referred to as the state explosion problem. The quest for heuristic solutions to this problem forms the forefront of research in formal verification <ref> [ASS + 94, BCMD90, CHM + 93, CM90b, Gra94] </ref>. Transition relations and sets of states can be represented using BDDs of their characteristic functions, which can be used for efficient fixed-point computations [BCMD90, CM90b, Pix90]. <p> Other data structures might be useful in these cases. There is also a wide class of heuristics, orthogonal to the approaches we have taken, for coping with the state explosion problem; such as property-specific reductions [ASS + 94], abstrac tions [Gra94], and conservative approximations to reached state sets <ref> [CHM + 93] </ref>.
Reference: [CHM + 94] <author> H. Cho, G. D. Hachtel, E. Macii, M. Poncino, and F. Somenzi. </author> <title> A Structural Approach to State Space Decomposition for Approximate Reachability Analysis. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer Design, </booktitle> <month> October </month> <year> 1994. </year>
Reference-contexts: The state-space traversal, which requires image/pre-image computation as the core operations, can be made efficient by proper use of early variable quantification [TSL + 90, BCL91b, RAP + 95, GB94, KHB96]. Approximation techniques can also be used for reachability analysis <ref> [CHM + 93, CHM + 94, RS95, SRSB97] </ref> where exact analysis is not feasible. 18 CHAPTER 1. INTRODUCTION Design verification: Partitioned transition relations and efficient image computation techniques used for sequential implementation verification are also applicable in design verification.
Reference: [CM90a] <author> E. Cerny and C. Mauras. </author> <title> Tautology Checking Using Cross-Controllability and Cross-Observability Relations. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer-Aided Design, </booktitle> <pages> pages 3437, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: The algorithm is shown in Figure 7.3. The resulting structural partition is shown in Figure 7.4. A related technique is also presented in [JNC + 96]. The idea of controlling BDD sizes by introducing variables has appeared in literature before <ref> [CM90a, CCQ94] </ref>.
Reference: [CM90b] <author> O. Coudert and J. C. Madre. </author> <title> A Unified Framework for the Formal Verification of Sequential Circuits. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer-Aided Design, </booktitle> <pages> pages 1269, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Indeed, the computational complexity of state transition graph related problems is known to be PSPACEcomplete [ASB93]. The complexity introduced by concurrent interaction is popularly referred to as the state explosion problem. The quest for heuristic solutions to this problem forms the forefront of research in formal verification <ref> [ASS + 94, BCMD90, CHM + 93, CM90b, Gra94] </ref>. Transition relations and sets of states can be represented using BDDs of their characteristic functions, which can be used for efficient fixed-point computations [BCMD90, CM90b, Pix90]. <p> The quest for heuristic solutions to this problem forms the forefront of research in formal verification [ASS + 94, BCMD90, CHM + 93, CM90b, Gra94]. Transition relations and sets of states can be represented using BDDs of their characteristic functions, which can be used for efficient fixed-point computations <ref> [BCMD90, CM90b, Pix90] </ref>. BDDs are now extensively used for both design and implementation verification of hardware systems and many non-trivial design examples have been verified using BDDs [CYF94, McM93]. Still, there are many instances of medium sized circuits that cannot be verified using existing BDD techniques. <p> As the circuit complexity grows, the size of the transition relation usually explodes. Hence this approach becomes infeasible for large, complex circuits. Partitioned Transition Relation: In this case, a vector of transition relations is used; each element of the vector represents the next-state relation for a latch. Coud-ert <ref> [CM90b] </ref> proposed reducing image computations to range computations by exploiting the property of the constrain operator; the range computation is performed by recursive co-factoring. The efficiency of this approach comes from caching intermediate results and exploiting disjoint support. <p> A lot of research work has gone into simplifying the BDD rep 7.5. BDD MINIMIZATION USING DON'T CARES 175 resentation of a function f with respect to a care-set c <ref> [TSL + 90, CM90b, SHSB94, HBBM97] </ref>. By reducing the BDD sizes via usage of don't cares, the computation time of various BDD operations improves. Here we outline various scenarios where the don't cares arise in BDD-based formal verification. 1. <p> (~y) = R k (~y) [ 9 ~x ;~u [ T (~x;~u;~y) ^ R k (~x)] (7.12) Observe that in Equation 7.12, any set of states between R k n R k1 and R k can be used in place of R k while preserving the result for R k+1 <ref> [CM90b] </ref>. Thus R k1 can be used as a don't care set to minimize the BDD size of the states of which the image is taken. 3. Simplification of the transition relation during image computation. <p> For our purposes, we will overload the j 00 operator and use f j g to indicate the minimization of BDD representation of the function f with respect to the don't care set flg. The constraint method (proposed in <ref> [CM90b, TSL + 90] </ref>) is image preserving, i.e., if constraint is employed to simplify the BDD of T (~x;~u;~y) in Equation 7.13 and the simplified BDD is given as T (~x;~u;~y), then Equation 7.13 simplifies to the following: 9 ~x (T (~x;~u;~y)A (~x)) = 9 ~x T (~x;~u;~y) Note that, there <p> That means, we would need to pay the price of finding the obtaining the optimal schedule for each different value of A (~x). This is found to be computationally expensive. Hence, in our approach we make use of another BDD minimization technique restrict (proposed in <ref> [CM90b] </ref>). This method does not introduces any new variables. The overall motivation is 7.6. REMOVING REDUNDANT LATCHES 177 that co-factoring and simplifying each transition relation will result in simpler BDDs and hence faster manipulation. 4. <p> Application of their approach to optimized circuits obtained by a sequence of retiming and resynthesis operations seems difficult. Proposed solutions to the sequential equivalence problem can be broadly divided into two categories. The solutions in the first category attempt to solve the general sequential equivalence problem <ref> [TSL + 90, CM90b, HCC97, SK97] </ref>. However, due to the complexity of the problem, the proposed solutions are either limited to relatively small size circuits or to circuits which have undergone relatively fewer optimization transformations. The second approach is to trade off the optimization capability with the verification complexity.
Reference: [CM95] <author> O. Coudert and J. C. Madre. </author> <title> The Implicit Set Paradigm: A New Approach to Finite State System Verification. </title> <editor> In R. K. Brayton, E. M. Clarke, and P. A. Subrahmanyam, editors, </editor> <booktitle> Formal Methods in System Design, </booktitle> <pages> pages 133145, </pages> <year> 1995. </year>
Reference-contexts: Boolean operators correspond with set operators, e.g., disjunction corresponds with union, and negation with complementation. All elementary set operations can thus be evaluated with a quadratic complexity on BDDs <ref> [CM95] </ref>. Part I Computer Architecture and BDD Manipulation 33 Chapter 3 Breadth-First BDD Manipulation T HE manipulation of very large BDDs is the key to success for BDD-based al gorithms for simulation [Bry91], synthesis [CBM89, TSL + 90], and verification [BCMD90, McM93, BSA + 96a] of integrated circuits and systems.
Reference: [CMZ + 93] <author> E. Clarke, K. L. McMillan, X. Zhao, M. Fujita, and J.-Y. Yang. </author> <title> Spectral Transforms for Large Boolean Functions with Application to Technology Mapping. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <pages> pages 5460, </pages> <year> 1993. </year>
Reference-contexts: INTRODUCTION Representing numeric valued functions: For functions of Boolean variables with non Boolean ranges, a series of representation schemes have been proposed. In particular, allowing arbitrary values on the terminal nodes (MTBDD <ref> [CMZ + 93] </ref>, ADD [BFG + 93]), incorporating numeric weights on the edges (EVBDD [LS92]), changing the function decomposition with respect to its variables (BMD and flBMD [BC95]), or a combination of some of the above techniques (HDD [CFZ95]) have been proposed.
Reference: [CSG97] <author> D. Culler, J. P. Singh, and A. Gupta. </author> <title> Parallel Computer Architecture: A Harware/Software Approach. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1997. </year> <note> 286 BIBLIOGRAPHY </note>
Reference-contexts: In particular, the clock rate for x86 family from In-tel has increased from 16MHz in 1986 for i386 to 300MHz in 1997 for Pentium II. fl Some of the material in this section has been derived from <ref> [HP90, San96, CSG97] </ref>. 4 CHAPTER 1. INTRODUCTION * Transistor density: The rate of increase of number of transistors in a chip is about 40% per year. <p> In Section 5.3, we discuss previous works on parallel manipulation of BDDs and analyze their trade-offs in a common framework. We present our technique in Section 5.5. Due to fl Introductory material on parallel architectures and their performance has been obtained from <ref> [HP90, San96, CSG97] </ref>. Most of the material in this section has been taken from [Eng95, SS94]. 105 106 CHAPTER 5. PARALLEL BDD MANIPULATION lack of time we did not implement our technique.
Reference: [CYF94] <author> B. Chen, M. Yamazaki, and M. Fujita. </author> <title> Bug Identification of a Real Chip Design by Symbolic Model Checking. </title> <booktitle> In Proc. European Conf. on Design Automation, </booktitle> <address> Paris, France, </address> <month> February </month> <year> 1994. </year>
Reference-contexts: BDDs are now extensively used for both design and implementation verification of hardware systems and many non-trivial design examples have been verified using BDDs <ref> [CYF94, McM93] </ref>. Still, there are many instances of medium sized circuits that cannot be verified using existing BDD techniques. In the next five sections, we describe various techniques which enable state transition graph representation and state-space enumeration for large designs. These are: 164 CHAPTER 7.
Reference: [DB97] <author> R. Drechsler and B. Becker. </author> <title> Overview of Decision Diagrams. </title> <booktitle> In IEE Proceedings-Computers and Digital Techniques, </booktitle> <pages> pages 18793, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: However their widespread usage has started only after 1986, when a set of algorithms were proposed to construct and manipulate these data structures [Bry86]. For a complete description on various kinds of decision diagrams and the related terminology, please refer to <ref> [BRB90, Bry91, DB97] </ref>. Here we present a brief description of the data structure and the relevant terminology. The BDD of a function is a rooted, directed, acyclic graph.
Reference: [DDHY92] <author> D. L. Dill, A. J. Drexler, A. J. Hu, and C. H. Yang. </author> <title> Protocol Verification as a Hardware Design Aid. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer Design, </booktitle> <pages> pages 5225, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: The composed design is modeled as a finite state machine and starting from some initial state (defined by the values of the latches), all the states are visited. At each state the equality of the outputs is checked. Explicit state enumeration technique visits one state at a time <ref> [DMN88, DDHY92] </ref>. However, due to the explicit nature of this technique, it is limited to only a small number of state elements. Symbolic techniques, which model the sets of states and the transitions between them as Boolean functions, have been widely used [CBM89, Kuk89, BCMD90, TSL + 90]. <p> Equivalence between two circuits implies identical values of corresponding outputs in all reachable states. Explicit state enumeration techniques perform an explicit traversal of the state space <ref> [DMN88, DDHY92] </ref>. Due to the explicit nature of this technique, it is limited to only a small number of state elements. Symbolic techniques [CBM89, BCMD90] implicitly perform state-space traversal on the product machine.
Reference: [DMN88] <author> S. Devadas, H.-K. T. Ma, and A. R. </author> <title> Newton. On the Verification of Sequential Machines at Differing Levels of Abstraction. </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits, </journal> <pages> pages 71322, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: The composed design is modeled as a finite state machine and starting from some initial state (defined by the values of the latches), all the states are visited. At each state the equality of the outputs is checked. Explicit state enumeration technique visits one state at a time <ref> [DMN88, DDHY92] </ref>. However, due to the explicit nature of this technique, it is limited to only a small number of state elements. Symbolic techniques, which model the sets of states and the transitions between them as Boolean functions, have been widely used [CBM89, Kuk89, BCMD90, TSL + 90]. <p> Equivalence between two circuits implies identical values of corresponding outputs in all reachable states. Explicit state enumeration techniques perform an explicit traversal of the state space <ref> [DMN88, DDHY92] </ref>. Due to the explicit nature of this technique, it is limited to only a small number of state elements. Symbolic techniques [CBM89, BCMD90] implicitly perform state-space traversal on the product machine.
Reference: [DST + 94] <author> R. Drechsler, A. Sarabi, M. Theobald, B. Becker, and M. A. Perkowski. </author> <title> Efficient Representation and Manipulation of Switching Functions Based on Ordered Kronecker Functional Decision Diagrams. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <year> 1994. </year>
Reference-contexts: Some methods of generating different decision diagrams are given below: Changing decomposition method: By changing the interpretation of the decomposition method one can obtain a significantly smaller representation. Some of them are OFDD [KSR92] and OKFDD <ref> [DST + 94] </ref>. Relaxing the ordering requirement: For some functions all variable orderings result in exponential BDD sizes in the number of variables [Bry91]. In [ADG91], the decision diagram is modified to allow variables to appear (possibly multiple times) in different orders for different paths.
Reference: [Eic93] <author> T. H. V. Eicken. </author> <title> Active Messages: An Efficient Communication Architecture for Multiprocessors. </title> <type> PhD thesis, </type> <institution> University of California Berkeley, </institution> <year> 1993. </year>
Reference-contexts: All the comparisons are with the fastest breadth-first code running on the MIPS DEC 5000 workstations. The NRAM uses four workstations; the client main memory is 30 MBytes and 3 servers have main memory of 40 MBytes each. The remote memory pager for NRAM uses active-messages <ref> [Eic93] </ref> as the basic communication primitive. For C6288 sub-circuits with less than three million nodes, the speedup is due to faster processing speed on SPARC10 used as a building blocks for NOW. For more 4.5.
Reference: [EL85] <author> E. A. Emerson and C. L. Lei. </author> <title> Modalities for Model Checking: Branching Time Strikes Back. </title> <booktitle> In Proc. ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 8496, </pages> <year> 1985. </year>
Reference-contexts: Verification consists of finding a path in a Kripke structure which starts at the initial state and leads to a fair cycle i.e. a cycle which includes at least one state from a designated subset of fair states F <ref> [EL85] </ref>. Conceptually, this check may be performed by first finding the set of states F fl which reach a fair cycle.
Reference: [Eme90] <author> E. A. Emerson. </author> <title> Temporal and Modal Logic. </title> <editor> In J. van Leeuwen, editor, </editor> <title> Formal Models and Semantics, </title> <booktitle> volume B of Handbook of Theoretical Computer Science, </booktitle> <pages> pages 996 1072. </pages> <publisher> Elsevier Science, </publisher> <year> 1990. </year>
Reference-contexts: Truth of the formulae is interpreted over states in Kripke structures; determining the truth value of a formula over a state in the structure is referred to as model checking and can be algorithmically performed using fixed point calculations. Precise syntax and semantics are given in <ref> [Eme90] </ref>. As an example, state s 0 in the Kripke structure of Figure 7.1 models the formula EF (a ^ b) (there exists a path to a state where both a and b hold).
Reference: [Eng95] <author> S. D. </author> <title> Engineering. Solaris Porting Guide. </title> <publisher> Sunsoft Press, </publisher> <year> 1995. </year>
Reference-contexts: We present our technique in Section 5.5. Due to fl Introductory material on parallel architectures and their performance has been obtained from [HP90, San96, CSG97]. Most of the material in this section has been taken from <ref> [Eng95, SS94] </ref>. 105 106 CHAPTER 5. PARALLEL BDD MANIPULATION lack of time we did not implement our technique. However, in Section 5.6 we present a detailed analysis of closely related work by Yang et al. [YO97] that has been fully implemented.
Reference: [FFK88] <author> M. Fujita, H. Fujisawa, and N. Kawato. </author> <title> Evaluation and Improvements of Boolean Comparison Method Based on Binary Decision Diagrams. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer-Aided Design, </booktitle> <pages> pages 25, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: In some cases, there could be an exponential difference in the BDD sizes of a function for two different variable orders. Finding the optimal variable ordering is co-NP complete. A lot of research has been done on this issue <ref> [MWBS88, FFK88] </ref> and recently dynamic variable ordering [FMK91, Rud93] has emerged as enabling technology in this area. BDD partitioning: This approach is similar to the partitioned transition relation method or to creating a cutset in the network. However, the techniques proposed in this category are application independent. <p> The ordering plays a significant role in determining the size of BDDs, which is crucial for their efficient manipulation. The problem of finding an optimal ordering is intractable and several heuristics have been proposed which statically determine a good ordering of variables based on the circuit information <ref> [FFK88, MWBS88] </ref>. Recently, dynamic ordering [Rud93] has become a popular alternative to static ordering. The salient features of this technique are the transparent nature of the algorithm (user need not be aware of it) and the in-place swapping of variables.
Reference: [FMK91] <author> M. Fujita, Y. Matsunaga, and T. Kakuda. </author> <title> On Variable Ordering of Binary Decision Diagrams for the Application of Multi-level Logic Synthesis. </title> <booktitle> In Proc. European Conf. on Design Automation, </booktitle> <pages> pages 5054, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: In some cases, there could be an exponential difference in the BDD sizes of a function for two different variable orders. Finding the optimal variable ordering is co-NP complete. A lot of research has been done on this issue [MWBS88, FFK88] and recently dynamic variable ordering <ref> [FMK91, Rud93] </ref> has emerged as enabling technology in this area. BDD partitioning: This approach is similar to the partitioned transition relation method or to creating a cutset in the network. However, the techniques proposed in this category are application independent. <p> DYNAMIC REORDERING : WINDOW TECHNIQUE 145 6.6 Dynamic Reordering : Window Technique The window permutation algorithm proceeds by choosing a level i in the DAG and exhaustively searching all k! permutations of the k adjacent variables starting at level i <ref> [FMK91, ISY91] </ref>. Typically this operation is repeated starting from each level until no improvement in the size is seen. Based on the observations in Section 6.3.2, we make the following optimizations: 1.
Reference: [GB94] <author> D. Geist and I. Beer. </author> <title> Efficient Model Checking by Automated Ordering of Transition Relation Partitions. </title> <booktitle> In Computer Aided Verification, volume 818 of Lecture Notes in Computer Science, </booktitle> <pages> pages 5271. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: Partitioned transition relations are used instead of monolithic transition relation to control the BDD sizes [TSL + 90, BCL91b, RAP + 95]. The state-space traversal, which requires image/pre-image computation as the core operations, can be made efficient by proper use of early variable quantification <ref> [TSL + 90, BCL91b, RAP + 95, GB94, KHB96] </ref>. Approximation techniques can also be used for reachability analysis [CHM + 93, CHM + 94, RS95, SRSB97] where exact analysis is not feasible. 18 CHAPTER 1. <p> Their technique for the early quantification problem is quadratic in the number of relations, and becomes impractical when the number of relations is large. <ref> [GB94] </ref> give a simple automated way to order the relations when each relation consists of the next-state function of a single latch. <p> EXPERIMENTAL RESULTS 185 7.7.2 Cluster Ordering Table 7.3 compares the performance (CPU time in seconds) of our ordering heuristic with the heuristics proposed in <ref> [GB94, TSL + 90] </ref>. Specifically we report the time taken in the reached state computation. The weights chosen after some experimentation in our heuristic were W 1 = 2;W 2 = 1;W 3 = 1;W 4 = 1. <p> Specifically we report the time taken in the reached state computation. The weights chosen after some experimentation in our heuristic were W 1 = 2;W 2 = 1;W 3 = 1;W 4 = 1. Various Heuristics Example [TSL + 90] <ref> [GB94] </ref> Proposed BIU 305 326 315 Every 6087 5857 5788 2MDLC 176 244 179 BDLC* 140 191 144 BDLC space out 3023 2231 Gigamax 4.8 7.4 4.8 sbc 116 135 118 Table 7.3 Comparison of CPU time (in seconds) for different cluster ordering heuristics. <p> The above results indicate that the proposed approach always outperforms that in <ref> [GB94] </ref>. Improvements up to 25% were achieved. Although in some examples (BIU, BDLC*, 2MDLC, sbc) Touati's heuristic [TSL + 90] performs marginally better than ours, on BDLC, Touati's approach ran out of memory. 7.7.3 Network Partitioning In Table 7.4, we present results on network partitioning based on BDD-size heuristic.
Reference: [GBD + 94] <author> A. Geist, A. Beguelin, J. Dongarra, W. Jiang, R. Manchek, and V. Sunderam. </author> <title> PVM 3 User's Guide and Reference Manual. </title> <institution> Oak Ridge National Laboratory, </institution> <month> September </month> <year> 1994. </year>
Reference-contexts: This environment contains approximately 60 workstations with 64MB (about 40MB available) main memory and 256MB (about 200MB available) disk space and MIPS-R4000 processor. We have used PVM <ref> [GBD + 94] </ref> (Parallel Virtual Machine) software to provide the communication between the workstations in the cluster during a BDD operation.
Reference: [GJ79] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability. </title> <editor> W. H. </editor> <publisher> Freeman and Co., </publisher> <year> 1979. </year>
Reference-contexts: RETIMING AND RESYNTHESIS: COMPLEXITY ISSUES 8.4. VERIFICATION COMPLEXITY 229 230 CHAPTER 8. RETIMING AND RESYNTHESIS: COMPLEXITY ISSUES apply the technique given in Section 8.4.2. The complexity of the overall verification problem falls in S 2 class <ref> [GJ79] </ref> in the polynomial hierarchy. 8.4.5 Verification After RetimingResynthesisResynthesis The transformation obtained via retimingresynthesisresynthesis is shown in Fig ure 8.28. The analysis follows along the lines of that in Section 8.4.4. 8.5 Summary and Open Issues In summary we have been able to establish the following: 8.6. CONCLUSION 231 1.
Reference: [GL91] <author> O. Grumberg and D. E. </author> <title> Long. Model Checking and Modular Verification. </title> <editor> In J. C. M. Baeten and J. F. Groote, editors, </editor> <booktitle> Proc. of CONCUR '91: 2nd Inter. Conf. on Concur-rency Theory, volume 527 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1991. </year> <note> BIBLIOGRAPHY 287 </note>
Reference-contexts: In addition, appropriate abstraction of the original design can be used to prevent the blow-up in BDD size [Gra94, Kur93]. Also, compositional techniques can be used to break the original problem into tractable sub-problems to keep the BDD size small <ref> [GL91] </ref>. 1.5.3 Algorithmic Solutions In this approach, various algorithmic techniques are used to control BDD size of the functions obtained at the end of some manipulation. In addition, some techniques are used to control the BDD size of functions which represent partial results in a complex computation.
Reference: [GM94] <author> J. Gergov and C. Meinel. </author> <title> Efficient Boolean Manipulation with OBDDs can be Extended to FBDDs. </title> <journal> In IEEE Transactions on Computers, </journal> <pages> pages 11791209, </pages> <year> 1994. </year>
Reference-contexts: A slightly less generalized version allows different variable orderings along different paths but requires the variables to appear at most once along any path. Even though efficient manipulation techniques were presented in <ref> [GM94, SW95] </ref>, this representation has not yet gained popularity. 20 CHAPTER 1. INTRODUCTION Representing numeric valued functions: For functions of Boolean variables with non Boolean ranges, a series of representation schemes have been proposed.
Reference: [Gra94] <author> S. Graf. </author> <title> Verification of a Distributed Cache Memory by Using Abstractions. </title> <booktitle> In Computer Aided Verification, volume 818 of Lecture Notes in Computer Science, pages 207219. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: INTRODUCTION Design verification: Partitioned transition relations and efficient image computation techniques used for sequential implementation verification are also applicable in design verification. In addition, appropriate abstraction of the original design can be used to prevent the blow-up in BDD size <ref> [Gra94, Kur93] </ref>. Also, compositional techniques can be used to break the original problem into tractable sub-problems to keep the BDD size small [GL91]. 1.5.3 Algorithmic Solutions In this approach, various algorithmic techniques are used to control BDD size of the functions obtained at the end of some manipulation. <p> Indeed, the computational complexity of state transition graph related problems is known to be PSPACEcomplete [ASB93]. The complexity introduced by concurrent interaction is popularly referred to as the state explosion problem. The quest for heuristic solutions to this problem forms the forefront of research in formal verification <ref> [ASS + 94, BCMD90, CHM + 93, CM90b, Gra94] </ref>. Transition relations and sets of states can be represented using BDDs of their characteristic functions, which can be used for efficient fixed-point computations [BCMD90, CM90b, Pix90]. <p> EFFICIENT TECHNIQUES FOR STATE SPACE TRAVERSAL variable ordering. Other data structures might be useful in these cases. There is also a wide class of heuristics, orthogonal to the approaches we have taken, for coping with the state explosion problem; such as property-specific reductions [ASS + 94], abstrac tions <ref> [Gra94] </ref>, and conservative approximations to reached state sets [CHM + 93].
Reference: [Gup92] <author> A. Gupta. </author> <title> Formal Hardware Verification Methods: A Survey. </title> <booktitle> In Formal Methods in System Design, </booktitle> <pages> pages 151238. </pages> <publisher> Kluwer Academic Publishers, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: In this thesis we will focus on the design verification (Is what I specified what I wanted?) and the gate-level implementation verification (Is the optimized gate For a survey on various formal techniques, refer to <ref> [Gup92] </ref>. 14 CHAPTER 1. INTRODUCTION level design functionally equivalent to the original gate-level design?). We notice that a large number of automated verification methods make use of symbolic techniques as the core engine. Also, structural techniques are heavily used for implementation verification.
Reference: [HBBM97] <author> Y. Hong, P. A. Beerel, J. R. Burch, and K. L. McMillan. </author> <title> Safe BDD Minimization Using Don't Cares. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <pages> pages 20813, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: A lot of research work has gone into simplifying the BDD rep 7.5. BDD MINIMIZATION USING DON'T CARES 175 resentation of a function f with respect to a care-set c <ref> [TSL + 90, CM90b, SHSB94, HBBM97] </ref>. By reducing the BDD sizes via usage of don't cares, the computation time of various BDD operations improves. Here we outline various scenarios where the don't cares arise in BDD-based formal verification. 1.
Reference: [HCC96a] <author> S.-Y. Huang, K.-T. Cheng, and K.-C. Chen. </author> <title> An ATPG-based Framework for Verifying Sequential Equivalence. </title> <booktitle> In Proc. Intl. Test Conf., </booktitle> <year> 1996. </year>
Reference-contexts: For circuits with an unknown initial state, several notions of equivalence have been proposed: post-synchronization equivalence [Pix92], safe-replaceability [PSAB94], circuit-covering <ref> [HCC96a] </ref>, and 3-valued equivalence, to name a few. Similar to 3-valued equivalence, we do not assume a power-up initial state for the latches. Instead, we assume that at power-up, each latch has a non-deterministic Boolean value.
Reference: [HCC96b] <author> S.-Y. Huang, K.-T. Cheng, and K.-C. Chen. </author> <title> On Verifying the Correctness of Retimed Circuits. </title> <booktitle> In Proceedings. The Great Lakes Symposium on VLSI, </booktitle> <pages> pages 27780, </pages> <year> 1996. </year>
Reference-contexts: It has been established that a combination of functional and structure-based techniques provides a robust methodology for combinational verification [KK97, Mat96, RWK95, Bra93]. For sequential circuits, however, attempts to combine structural and functional techniques have been limited to smaller size examples or relatively minor transformations <ref> [HCC96b, HCC97] </ref>. In the next two chapters we investigate the implementation verification problem for circuits which have undergone repeated retiming and combinational synthesis transformations. In this chapter, we attempt to formalize the notions of the optimization capability of retiming and resynthesis operations. <p> However, on a practical note, their technique requires state space traversal of individual machines as opposed to the product machine. They produced results on relatively small MCNC and ISCAS benchmarks because it was not possible to perform single machine state space traversal for large ones. In <ref> [HCC96b] </ref>, a technique for verifying the equivalence of two circuits after retiming and synthesis transformations was given. Their technique relies on finding the corre 236 CHAPTER 9. VERIFYING RETIMED AND RESYNTHESIZED CIRCUITS spondence between latches by retiming them appropriately.
Reference: [HCC97] <author> S.-Y. Huang, K.-T. Cheng, and K.-C. Chen. AQUILA: </author> <title> An Equivalence Verifier for Large Sequential Circuits. </title> <booktitle> In Proc. of Asian and South Pacific Design Automation Conf., </booktitle> <year> 1997. </year>
Reference-contexts: It has been established that a combination of functional and structure-based techniques provides a robust methodology for combinational verification [KK97, Mat96, RWK95, Bra93]. For sequential circuits, however, attempts to combine structural and functional techniques have been limited to smaller size examples or relatively minor transformations <ref> [HCC96b, HCC97] </ref>. In the next two chapters we investigate the implementation verification problem for circuits which have undergone repeated retiming and combinational synthesis transformations. In this chapter, we attempt to formalize the notions of the optimization capability of retiming and resynthesis operations. <p> Their technique relies on finding the corre 236 CHAPTER 9. VERIFYING RETIMED AND RESYNTHESIZED CIRCUITS spondence between latches by retiming them appropriately. They presented results for ISCAS benchmarks by comparing circuits which have undergone one step of retiming after combinational optimization. In <ref> [HCC97] </ref>, a combination of BDD-based and ATPG-based technique is presented. This approach relies on finding equivalent points in the two circuits and the symbolic justification requires the computation of the transition relation for the product machine. They gave results on circuits optimized by script.rugged inside SIS. <p> Application of their approach to optimized circuits obtained by a sequence of retiming and resynthesis operations seems difficult. Proposed solutions to the sequential equivalence problem can be broadly divided into two categories. The solutions in the first category attempt to solve the general sequential equivalence problem <ref> [TSL + 90, CM90b, HCC97, SK97] </ref>. However, due to the complexity of the problem, the proposed solutions are either limited to relatively small size circuits or to circuits which have undergone relatively fewer optimization transformations. The second approach is to trade off the optimization capability with the verification complexity. <p> If the constraints are not met in the original circuit, we make a minimum number of latches observable in order to satisfy the constraints. We allow arbitrary sequences of retiming and synthesis operations for logic optimization. Also, unlike structure-based approaches <ref> [HCC97, SK97] </ref>, our technique does not rely on the structural similarity between the circuits and we can deal with circuits which have gone through a sequence of retiming and synthesis optimizations. The techniques proposed apply to circuits containing edge-triggered latches (both regular and load-enabled).
Reference: [HDB96] <author> A. Hett, R. Drechsler, and B. Becker. </author> <title> MORE: An Alternative Implementation of BDD Packages by Multi-Operand Synthesis. </title> <booktitle> In Proc. European Design Automation Conf., </booktitle> <pages> pages 1649, </pages> <year> 1996. </year>
Reference-contexts: In some cases, the sizes of the intermediate BDDs could be large even though the final BDD size is small. Some techniques are proposed to avoid the computation of intermediate results. In <ref> [HDB96] </ref>, new variables are introduced (called operational variables) which capture the desired operation to be performed on the operands. Then these variables are successively moved down in order until they reach the bottom.
Reference: [HK90] <author> Z. Har'El and R. P. Kurshan. </author> <title> Software for Analytical Development of Communication Protocols. </title> <journal> AT&T Technical Journal, </journal> <pages> pages 4559, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Verification consists of checking whether all design behavior is acceptable, i.e., checking L D L P , which in turn is equivalent to checking that L D " fl L P is empty. Kurshan <ref> [HK90] </ref> observed that for certain classes of properties (namely deterministic L-automata) the set fl L P is efficiently computable. Both L D and L P are modeled as Kripke structures and a new Kripke structure is formed by composing them appropriately.
Reference: [Hor96] <author> S. Horeth. </author> <title> Compilation of Optimized OBDD-Algorithms. </title> <booktitle> In Proc. European Design Automation Conf., </booktitle> <pages> pages 1527, </pages> <year> 1996. </year>
Reference-contexts: BDD-BASED TECHNIQUES 19 operation. Even though no intermediate results are computed in this approach, the size of the whole BDD when the operational nodes are dynamically shifted down can be large. In other approaches <ref> [SBS93b, Hor96] </ref>, a technique is proposed to compute the result of a Boolean expression by extending the traditional two-operand operations. By maintaining an array of operands and operations, one can perform depth-first traversal while computing the new operands and finding the terminal conditions along the way.
Reference: [HP90] <author> J. L. Hennessy and D. A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufman, </publisher> <year> 1990. </year>
Reference-contexts: In particular, the clock rate for x86 family from In-tel has increased from 16MHz in 1986 for i386 to 300MHz in 1997 for Pentium II. fl Some of the material in this section has been derived from <ref> [HP90, San96, CSG97] </ref>. 4 CHAPTER 1. INTRODUCTION * Transistor density: The rate of increase of number of transistors in a chip is about 40% per year. <p> In Section 5.3, we discuss previous works on parallel manipulation of BDDs and analyze their trade-offs in a common framework. We present our technique in Section 5.5. Due to fl Introductory material on parallel architectures and their performance has been obtained from <ref> [HP90, San96, CSG97] </ref>. Most of the material in this section has been taken from [Eng95, SS94]. 105 106 CHAPTER 5. PARALLEL BDD MANIPULATION lack of time we did not implement our technique.
Reference: [HYD94] <author> A. J. Hu, G. York, and D. L. Dill. </author> <title> New Techniques for Efficient Verification with Implicitly Conjoined BDD's. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <pages> pages 276282, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: In particular, the image/pre-image computation techniques form the core engine for model checking. A brief description of the tool is given in Appendix B. Other BDD-based techniques which look promising include the existscofactor of [CC93], and the implicitly conjoined invariants of <ref> [HYD94] </ref>. Certain limitations of BDD-based formal design verification cannot be solved by the techniques described in this work. For example, the BDD size of the reached set may be large under any 192 CHAPTER 7. EFFICIENT TECHNIQUES FOR STATE SPACE TRAVERSAL variable ordering.
Reference: [HYHD95] <author> R. C. Ho, C. H. Yang, M. A. Horowitz, and D. L. Dill. </author> <title> Architectural Validation for Processors. </title> <booktitle> In Proc. of the International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: Both have serious draw 10.1. ANALYSIS AND FUTURE DIRECTIONS 273 backs making them infeasible for verifying large designs. Another hybrid method is to bring formal techniques into the world of simulation. Some effort in this di rection has been made by few researchers <ref> [HYHD95, YSAA97] </ref>. 274 CHAPTER 10. CONCLUSIONS AND FUTURE DIRECTIONS Part IV Appendix 275 Appendix A CAL BDD Package T HE work on breadth-first BDD manipulation and dynamic ordering (described in Chapters 3 and 6 respectively) has been successfully implemented inside a comprehensive BDD package named CAL [RS97].
Reference: [ISY91] <author> N. Ishiura, H. Sawada, and S. Yajima. </author> <title> Minimization of Binary Decision Diagrams Based on Exchanges of Variables. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer-Aided Design, </booktitle> <pages> pages 4725, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: DYNAMIC REORDERING : WINDOW TECHNIQUE 145 6.6 Dynamic Reordering : Window Technique The window permutation algorithm proceeds by choosing a level i in the DAG and exhaustively searching all k! permutations of the k adjacent variables starting at level i <ref> [FMK91, ISY91] </ref>. Typically this operation is repeated starting from each level until no improvement in the size is seen. Based on the observations in Section 6.3.2, we make the following optimizations: 1.
Reference: [JMF97] <author> J. Jain, R. Mukherjee, and M. Fujita. FLOVER: </author> <title> Filtering Oriented Combinational Verification Approach. </title> <booktitle> In Proc. IEEE/ACM Intl. Workshop on Logic Synthesis, </booktitle> <pages> pages 26368, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: BDDs play an important role in the implementation verification of combinational circuits, since they provide a canonical representation of the functions. Many successful combinational verification techniques use BDDs as the basic data structure <ref> [RWK95, Mat96, KK97, JMF97] </ref>. For sequential circuits, in addition to representing the behavior of the circuit, we need to represent and traverse the state transition graph (STG). States are represented and manipulated using BDDs. State enumeration forms the core operation in this case. <p> On the other hand, the verification problem for combinational logic optimization is a relatively easier problem in practice. Much work has gone into combining structural and functional techniques to obtain verification algorithms that can deal with reasonably large industrial circuits <ref> [Mat96, JMF97, KK97] </ref>. We propose a methodology which reduces a sequential verification problem into an equivalent combinational verification problem for a class of circuits. This allows exploitation of the advancements made in the field of combinational verification and use of its powerful techniques to perform verification.
Reference: [JNC + 96] <author> J. Jain, A. Narayan, C. Coelho, S. Khatri, M. Fujita, and A. L. Sangiovanni-Vincentelli. </author> <title> Decomposition Techniques for Rfficient ROBDD Construction. </title> <booktitle> In Proc. Formal Method in Computer-Aided Design, </booktitle> <pages> pages 41934, </pages> <year> 1996. </year> <note> 288 BIBLIOGRAPHY </note>
Reference-contexts: This requires appropriate handling of false negatives. The other technique is to introduce intermediate variables while building the BDDs and appropriately compose them at the end <ref> [JNC + 96] </ref>. This approach prevents the blowup in the intermediate BDD sizes. Sequential verification: In BDD-based sequential verification the goal is to represent the behavior of the finite state machine and to traverse the corresponding state-transition graph. <p> Different decomposition schemes, and new decision diagrams however do not necessarily reduce the computation time since in some cases the corresponding manipulation complexity is much higher than for BDDs. Some approaches keep the BDD sizes under control while increasing the number of BDD computations (e.g., network partitioning <ref> [Mat96, KK97, JNC + 96] </ref>, partitioned transition relation [TSL + 90, BCL91b, RAP + 95], etc.). These approaches trade-off memory consumption with computation time. BDD-based techniques are quite general and they are applicable to a broad range of problems. <p> The algorithm is shown in Figure 7.3. The resulting structural partition is shown in Figure 7.4. A related technique is also presented in <ref> [JNC + 96] </ref>. The idea of controlling BDD sizes by introducing variables has appeared in literature before [CM90a, CCQ94].
Reference: [KC90] <author> S. Kimura and E. M. Clarke. </author> <title> A Parallel Algorithm for Constructing Binary Decision Diagrams. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer Design, </booktitle> <pages> pages 220223, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: As a result, BDDs of very large size (up to 12 million nodes) can be handled. Ashar et al. [AC94] have presented an improved breadth-first algorithm, which enables manipulation of BDDs with up to 100 million nodes. 1.5. BDD-BASED TECHNIQUES 17 Parallel computation: Kimura et al. <ref> [KC90] </ref> have presented a parallel algorithm to construct BDDs that uses a shared-memory multiprocessor to divide the tasks that can be performed concurrently on several processors. Shared-memory machine allows the use of a single global hash table to maintain canonicity. <p> for each processor? Communication paradigm: How is the validity of the shared data structures maintained? How do processors communicate with each other message passing vs. synchronizing primitives (lock, barrier, mutex, etc.)? With this perspective, we analyze previous research efforts to parallelize BDD manipulation in the following section. 5.3 Previous work <ref> [KC90] </ref> used a shared-memory multiprocessor (Encore multimax). They used a two-phase (Apply and Reduce) BDD traversal technique to generate the result. Parallel jobs were created through either multiple Boolean operations or through unrolling of recursive calls for few steps. Interlocks were used for process synchronization. Due 5.3. <p> We analyze this summary below: Load generation: Concurrency in BDD manipulation is achieved in three ways: 1. High level operations: If there are multiple Boolean operations to be per formed, they are started on different processors <ref> [KC90] </ref>. 2. Concurrent processing of the cofactors: In this case a place holder for the results of the cofactors is created and processing of the cofactors continues in parallel on different processors [PSC94, CGRR94, SB96]. 3. Breadth-first processing: In this case, breadth-first manipulation scheme is used.
Reference: [Keu96] <author> K. Keutzer. </author> <title> The Need for Formal Methods for Integrated Circuit Design. </title> <booktitle> In Proc. Formal Method in Computer-Aided Design, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: Of these three, functional correctness is the most fundamental requirement because the speed and reliability of an incorrectly functioning electronic system is of no interest. Moreover, of these three requirements, functional correctness is becoming the largest bottleneck in design <ref> [Keu96] </ref>. It has been widely estimated that over 70% of the design time for integrated circuits is spent in performing various kinds of verification tasks and the effort devoted to this process eclipses all other aspects of the design process. <p> These factors combined together significantly affect the performance demands on the verification technology. Another way to look at the affect of increasing design complexity on verification is by examining the following equation that gives the number of bugs per 1 2 CHAPTER 1. INTRODUCTION chip <ref> [Keu96] </ref>: bugs chip = logic transistors chip fi lines in design logic transistors fi bugs lines in design Assuming that number of logic transistors per line of the high-level code is constant, since the number of logic transistors doubles every 18 months, we must reduce the number of bugs per line
Reference: [KHB96] <author> S. Krishnan, R. Hojati, and R. K. Brayton. </author> <title> Early Quantification and Partitioned Transition Relation. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer Design, </booktitle> <pages> pages 12 19, </pages> <address> Austin, TX, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: Partitioned transition relations are used instead of monolithic transition relation to control the BDD sizes [TSL + 90, BCL91b, RAP + 95]. The state-space traversal, which requires image/pre-image computation as the core operations, can be made efficient by proper use of early variable quantification <ref> [TSL + 90, BCL91b, RAP + 95, GB94, KHB96] </ref>. Approximation techniques can also be used for reachability analysis [CHM + 93, CHM + 94, RS95, SRSB97] where exact analysis is not feasible. 18 CHAPTER 1.
Reference: [KK97] <author> A. Kuehlmann and F. Krohm. </author> <title> Equivalence Checking Using Cuts and Heaps. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <pages> pages 2638, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: BDDs play an important role in the implementation verification of combinational circuits, since they provide a canonical representation of the functions. Many successful combinational verification techniques use BDDs as the basic data structure <ref> [RWK95, Mat96, KK97, JMF97] </ref>. For sequential circuits, in addition to representing the behavior of the circuit, we need to represent and traverse the state transition graph (STG). States are represented and manipulated using BDDs. State enumeration forms the core operation in this case. <p> However, the size of the output BDDs grows large for a complex design. The BDD size can be controlled by creating a cutset in the circuit and treating the intermediate signals as the primary inputs <ref> [Mat96, KK97] </ref>. This requires appropriate handling of false negatives. The other technique is to introduce intermediate variables while building the BDDs and appropriately compose them at the end [JNC + 96]. This approach prevents the blowup in the intermediate BDD sizes. <p> Different decomposition schemes, and new decision diagrams however do not necessarily reduce the computation time since in some cases the corresponding manipulation complexity is much higher than for BDDs. Some approaches keep the BDD sizes under control while increasing the number of BDD computations (e.g., network partitioning <ref> [Mat96, KK97, JNC + 96] </ref>, partitioned transition relation [TSL + 90, BCL91b, RAP + 95], etc.). These approaches trade-off memory consumption with computation time. BDD-based techniques are quite general and they are applicable to a broad range of problems. <p> An orthogonal set of techniques, called structure-based techniques, use structural information about the circuit and the nature of transformations performed on it to obtain efficient verification algorithms. It has been established that a combination of functional and structure-based techniques provides a robust methodology for combinational verification <ref> [KK97, Mat96, RWK95, Bra93] </ref>. For sequential circuits, however, attempts to combine structural and functional techniques have been limited to smaller size examples or relatively minor transformations [HCC96b, HCC97]. In the next two chapters we investigate the implementation verification problem for circuits which have undergone repeated retiming and combinational synthesis transformations. <p> On the other hand, the verification problem for combinational logic optimization is a relatively easier problem in practice. Much work has gone into combining structural and functional techniques to obtain verification algorithms that can deal with reasonably large industrial circuits <ref> [Mat96, JMF97, KK97] </ref>. We propose a methodology which reduces a sequential verification problem into an equivalent combinational verification problem for a class of circuits. This allows exploitation of the advancements made in the field of combinational verification and use of its powerful techniques to perform verification. <p> In practice, a modified combinational equivalence checker could be used which would not require generation of such circuits and hence no blow-up would occur. The combinational verification was performed by an in-house tool similar to the ones presented in <ref> [Mat96, KK97] </ref>. 9.7.
Reference: [KOKD96] <author> M. Kumanoya, T. Ogawa, Y. Konishi, and K. Dosaka. </author> <title> Trends in High-Speed DRAM Architectures. </title> <journal> IEICE Transactions on Electronics, </journal> <pages> pages 47281, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: Figure 1.2 shows a performance improvement in row access time of about 7% per year. To compensate for the low rate of access time and cycle time improvement for standard DRAMs, innovative operating modes, novel memory architectures, and application-specific DRAMs have emerged <ref> [KOKD96] </ref>. Despite these advances, for memory accesses that show little or no correlation, the access time remains the measure of DRAM performance that characterizes the main memory performance. Secondary Memory (Disks) Disk capacity has grown at an enormous rate in the last ten years as shown in Figure 1.3.
Reference: [KR97] <author> N. Klarlund and T. Rauhe. </author> <title> BDD algorithms and Cache Misses. </title> <booktitle> In Dagstuhl Seminar, Computer-Aided Design and Test, </booktitle> <month> January </month> <year> 1997. </year>
Reference-contexts: It seems that with proper implementation, this approach may outperform either the pure depth-first or breadth-first approaches for BDD manipulation. Many researchers have looked into optimizing cache misses during BDD operations. In <ref> [KR97] </ref>, a new data structure is presented which minimizes cache misses during the 3.10.
Reference: [KSR92] <author> U. Kebschull, E. Schubert, and W. Rosentiel. </author> <title> Multilevel Logic Bsed on Functional Decision Diagrams. </title> <booktitle> In Proc. European Conf. on Design Automation, </booktitle> <pages> pages 60813, </pages> <year> 1992. </year>
Reference-contexts: However, in general there is a trade-off between representation size and the manipulation complexity. Some methods of generating different decision diagrams are given below: Changing decomposition method: By changing the interpretation of the decomposition method one can obtain a significantly smaller representation. Some of them are OFDD <ref> [KSR92] </ref> and OKFDD [DST + 94]. Relaxing the ordering requirement: For some functions all variable orderings result in exponential BDD sizes in the number of variables [Bry91]. In [ADG91], the decision diagram is modified to allow variables to appear (possibly multiple times) in different orders for different paths.
Reference: [Kuk89] <author> J. H. Kukula. </author> <title> A Technique for Verifying Finite-state Machines. </title> <type> Technical Report 3A, IBM Technical Disclosure Bulletin, </type> <year> 1989. </year>
Reference-contexts: However, due to the explicit nature of this technique, it is limited to only a small number of state elements. Symbolic techniques, which model the sets of states and the transitions between them as Boolean functions, have been widely used <ref> [CBM89, Kuk89, BCMD90, TSL + 90] </ref>. A salient feature of these techniques is that the size of the underlying data structure (some form of decision diagram) does not depend on the number of states or the state elements in the circuit.
Reference: [Kur93] <author> R. P. Kurshan. </author> <title> Automata-Theoretic Verification of Coordinating Processes. </title> <publisher> Princeton University Press, </publisher> <year> 1993. </year>
Reference-contexts: INTRODUCTION Design verification: Partitioned transition relations and efficient image computation techniques used for sequential implementation verification are also applicable in design verification. In addition, appropriate abstraction of the original design can be used to prevent the blow-up in BDD size <ref> [Gra94, Kur93] </ref>. Also, compositional techniques can be used to break the original problem into tractable sub-problems to keep the BDD size small [GL91]. 1.5.3 Algorithmic Solutions In this approach, various algorithmic techniques are used to control BDD size of the functions obtained at the end of some manipulation.
Reference: [Kur97] <author> R. P. Kurshan. </author> <title> Formal Verification in a Commercial Setting. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <pages> pages 25862, </pages> <year> 1997. </year>
Reference-contexts: Most theorem provers are interactive, requiring guidance from the user in order to generate proofs [McM94]. Due to this reason, theorem-provers have not achieved the broad level of acceptance despite their impressive demonstration in some government pilot projects <ref> [Kur97] </ref>. In this thesis we will focus on the design verification (Is what I specified what I wanted?) and the gate-level implementation verification (Is the optimized gate For a survey on various formal techniques, refer to [Gup92]. 14 CHAPTER 1. INTRODUCTION level design functionally equivalent to the original gate-level design?).
Reference: [Lam93] <author> W. Lam. </author> <title> Algebraic Methods for Timing Analysis and Testing in High Performance Designs. </title> <type> PhD thesis, </type> <institution> University of California Berkeley, </institution> <month> April </month> <year> 1993. </year> <note> Memorandum No. UCB/ERL M94/19. </note>
Reference-contexts: This notion is very similar to the notion of Timed Boolean Function given in <ref> [Lam93] </ref>. In [Lam93], similar expressions are obtained for the signals which integrate both timing and logical functionality and generalize the conventional Boolean functions to the temporal domain. These expressions were used in timing analysis, analysis and optimization of wave-pipelined circuits, and performance validation of circuits and systems. <p> This notion is very similar to the notion of Timed Boolean Function given in <ref> [Lam93] </ref>. In [Lam93], similar expressions are obtained for the signals which integrate both timing and logical functionality and generalize the conventional Boolean functions to the temporal domain. These expressions were used in timing analysis, analysis and optimization of wave-pipelined circuits, and performance validation of circuits and systems.
Reference: [LE92] <author> B. Lockyear and C. Ebeling. </author> <title> Retiming of Multi-phase, </title> <booktitle> Level-clocked Circuits. In Advanced Research in VLSI and Parallel Systems: Proceedings of the 1992 Brown/MIT Conference, </booktitle> <pages> pages 265280, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: In particular, techniques given in [SR94, MS97] can be applied to large sequential circuits. Retiming of level-sensitive latches was addressed in <ref> [SBS93a, LE92] </ref>. Recently, Legl et al. proposed retiming techniques for edge-triggered circuits with multiple clocks and load enables [LVW97]. They introduced the notion of a latch class cl = (CLK; LE), which is all latches connected to clock signal CLK and load signal LE.
Reference: [Lin91] <author> B. Lin. </author> <title> Synthesis of VLSI Design with Symbolic Techniques. </title> <type> PhD thesis, </type> <institution> University of California Berkeley, </institution> <year> 1991. </year>
Reference-contexts: Hence, if we substitute one variable (say y) by another variable (say z), we can replace F by G. As shown in Figure 7.8, we are able to share the logic if C 2 C 3 . A similar approach was proposed in <ref> [Lin91] </ref> who described an algorithm to remove a maximal set of state variables without affecting the uniqueness of the reachable states. The problem with that approach is that the set of reachable states has to be pre-computed.
Reference: [Lon93] <author> D. E. </author> <title> Long. BDD Manipulation Library. </title> <month> June </month> <year> 1993. </year> <month> ftp://emc.cs.cmu.edu/pub/bdd/bddlib.tar.Z. </month>
Reference-contexts: In cases where the BDD size exceeds the main memory capacity, we have found performance improvement of a factor of more than 10 compared to state-of-the-art packages (Long's <ref> [Lon93] </ref> and CUDD [Som97]). In Chapter 4, we present distributed algorithms on a network of workstations that 1.7. <p> In this section we demonstrate the performance of our package. For experimental purposes, we integrated our package within SIS [SSL + 92], and compared the performance against two depth-first manipulation based packages Long's BDD package <ref> [Lon93] </ref> and Colorado decision diagram package [Som97]. 72 CHAPTER 3. <p> A complete package consisting of an entire suite of BDD operations based on these techniques has been built. We demonstrate the performance of our package by i) comparing with state-of-the-art BDD package <ref> [Lon93] </ref>, and 2) performing a comprehensive set of experiments to substantiate the capability of our package. We show that our package provides competitive performance on small examples and a performance ratio of more than 100 on large examples. <p> This makes the integration of our work on dynamic reordering worthwhile, making it directly applicable to practical problems. For comparison purposes we have used the CMU package developed by Long <ref> [Lon93] </ref> and the CU package [Som97] developed at University of Colorado at Boulder. Both of these packages are publicly available and are being widely used in industry and academia. We have used the standard ISCAS and MCNC benchmark examples for our experiments. <p> The modularity allows a developer to integrate and investigate new ideas for various algorithms inside VIS in a clean fashion. The VIS tool has been integrated with three different BDD packages <ref> [Som97, RS97, Lon93] </ref>. So far three releases of VIS have taken place. The latest release of VIS can be obtained from http://www-cad.eecs.berkeley.edu/vis fl For a detailed description of VIS architecture please refer to [BSA + 96b, BSA + 96a]. 279 280 APPENDIX B.
Reference: [LR90] <author> D. H. Lee and S. M. Reddy. </author> <title> On Determining Scan Flip-Flops in Partial-Scan Designs. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer-Aided Design, </booktitle> <pages> pages 3225, </pages> <year> 1990. </year>
Reference-contexts: The problem of finding the minimum set of vertices to make the circuit acyclic minimum feedback vertex set problem which is NP-complete. We used a modified version of the heuristics given in <ref> [LR90] </ref>. 9.7.2 Retiming Retiming was done using Minaret [MS97]. This tool only supports the constant delay model (we could not find any efficient public domain retiming tools, which supported better delay models). Retiming was performed in two modes.
Reference: [LRS83] <author> C. E. Leiserson, F. M. Rose, and J. B. Saxe. </author> <title> Optimizing Synchronous Circuitry by Re-timing. </title> <booktitle> In Advanced Research in VLSI: Proc. of the Third Caltech Conf., </booktitle> <pages> pages 86116. </pages> <publisher> Computer Science Press, </publisher> <year> 1983. </year>
Reference-contexts: In the next chapter we propose a practical algorithm for this implementation verification problem. 8.1 Introduction In combinational synthesis [BRSW87, SSL + 92], the positions of the latches are fixed and the logic is optimized. In retiming <ref> [LRS83, LS91] </ref>, the latches are moved across fixed combinational gates. The effects of retiming are changes in the number of latches (thereby leading to increase/decrease in area) and increase/decrease in the cycle 195 196 CHAPTER 8. RETIMING AND RESYNTHESIS: COMPLEXITY ISSUES time (leading to slower/faster clock rate).
Reference: [LS91] <author> C. E. Leiserson and J. B. Saxe. </author> <title> Retiming Synchronous Circuitry. </title> <booktitle> In Algorithmica, </booktitle> <pages> pages 535, </pages> <year> 1991. </year> <note> BIBLIOGRAPHY 289 </note>
Reference-contexts: In the next chapter we propose a practical algorithm for this implementation verification problem. 8.1 Introduction In combinational synthesis [BRSW87, SSL + 92], the positions of the latches are fixed and the logic is optimized. In retiming <ref> [LRS83, LS91] </ref>, the latches are moved across fixed combinational gates. The effects of retiming are changes in the number of latches (thereby leading to increase/decrease in area) and increase/decrease in the cycle 195 196 CHAPTER 8. RETIMING AND RESYNTHESIS: COMPLEXITY ISSUES time (leading to slower/faster clock rate). <p> A sequence of retiming and combinational resynthesis steps can provide powerful optimization of a sequential circuit. In [MSBS91], it has been shown that retiming combined with synthesis can be used to optimize sequential networks. After the initial retiming algorithm proposed in <ref> [LS91] </ref> for a simple circuit containing single clock edge-triggered latches, many advancements have been made in terms of efficient implementation and applicability of retiming with more complex memory elements. In particular, techniques given in [SR94, MS97] can be applied to large sequential circuits.
Reference: [LS92] <author> Y.-T. Lai and S. Sastry. </author> <title> Edge-valued Binary Decision Diagrams for Multi-level Hierarchical Verification. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <pages> pages 608613, </pages> <year> 1992. </year>
Reference-contexts: INTRODUCTION Representing numeric valued functions: For functions of Boolean variables with non Boolean ranges, a series of representation schemes have been proposed. In particular, allowing arbitrary values on the terminal nodes (MTBDD [CMZ + 93], ADD [BFG + 93]), incorporating numeric weights on the edges (EVBDD <ref> [LS92] </ref>), changing the function decomposition with respect to its variables (BMD and flBMD [BC95]), or a combination of some of the above techniques (HDD [CFZ95]) have been proposed. These techniques differ in their representation sizes and the manipulation complexity.
Reference: [LVW97] <author> C. Legl, P. Vanbekbergen, and A. Wang. </author> <title> Retiming of Edge-Triggered Circuits with Mulit-ple Clocks and Load Enables. </title> <booktitle> In Proc. IEEE/ACM Intl. Workshop on Logic Synthesis, </booktitle> <year> 1997. </year>
Reference-contexts: In particular, techniques given in [SR94, MS97] can be applied to large sequential circuits. Retiming of level-sensitive latches was addressed in [SBS93a, LE92]. Recently, Legl et al. proposed retiming techniques for edge-triggered circuits with multiple clocks and load enables <ref> [LVW97] </ref>. They introduced the notion of a latch class cl = (CLK; LE), which is all latches connected to clock signal CLK and load signal LE. <p> For a latch without any load-enable signal (also referred to as regular latch in this paper), we assume e = 1. Similar to the notion in <ref> [LVW97] </ref>, we define a latch class cl = (e), which is all latches that have the the same load-enable signal e. This classification is important during retiming transformations, since latches can merge as the result of a move only if they belong to the same class. 238 CHAPTER 9. <p> In <ref> [LVW97] </ref>, a retiming technique was proposed to handle latches with different enable signals and different clocks. In this work, we propose a verification methodology where all the latches are driven by the same clock but can have different enable signals. Extension to circuits with multiple clocks is straightforward. <p> SEQUENTIAL CIRCUITS WITHOUT FEEDBACK 249 (ovals). sequence of enabling signals of the latches along the path is invariant during retiming (ala <ref> [LVW97] </ref>) and synthesis optimization steps. Proof: Let us first consider the retiming transformation. Suppose fG 1 ; G 2 ; :::; G k g is a path of gates between an input I and output O. Assume that the latches cannot be retimed across input and output ports. <p> In the second mode, the delay obtained through combinational optimization was used as the timing constraint and then constrained minimum area retiming was performed. We could not find a public domain retiming tool which could handle latches with enable signals as proposed in <ref> [LVW97] </ref> and shown in Figure 9.16. 9.7.3 Combinational Optimization We perform combinational optimization to obtain a minimum delay circuit. SIS [SSL + 92] was used for synthesis purposes.
Reference: [Mal90] <author> S. Malik. </author> <title> Combinational Logic Optimization Techniques in Sequential Logic Synthesis. </title> <type> PhD thesis, </type> <institution> University of California Berkeley, </institution> <month> November </month> <year> 1990. </year> <note> Memorandum No. UCB/ERL M90/115. </note>
Reference-contexts: State encoding 2. State minimization 3. Logic optimization using information about unreachable states 4. Logic optimization using input/output don't care sequences Let us now see which ones of these can be implemented using retiming and synthesis transformations alone. In <ref> [Mal90] </ref>, an attempt has been made to characterize the optimization power of retiming and resynthesis transformations, which we discuss next. 8.2.9 Exposition in Malik's Thesis The following theorem asserts the state encoding power of retiming and resynthesis operations. Theorem 3 [Mal90] Given a machine implementation M 1 , corresponding to a <p> In <ref> [Mal90] </ref>, an attempt has been made to characterize the optimization power of retiming and resynthesis transformations, which we discuss next. 8.2.9 Exposition in Malik's Thesis The following theorem asserts the state encoding power of retiming and resynthesis operations. Theorem 3 [Mal90] Given a machine implementation M 1 , corresponding to a state transition graph G, with a state assignment S 1 , it is always possible to derive a machine M 2 corresponding to the same state transition graph G, and a state assignment S 2 by applying only a series <p> The proof of the theorem makes use of one-to-one mapping between the states of M 1 and M 2 , thereby transforming one state assignment to another using appropriate logic. <ref> [Mal90] </ref> also discusses the case where the STGs of M 1 and M 2 are different. It is asserted that under restricted state-transformations of the STG, the final circuit can be obtained from the initial circuit using retiming and resynthesis operations. 8.2. OPTIMIZATION POWER 207 using 2-way split and merge. <p> Definition 6 A cycle preserving (CP) transformation does not create or destroy a labeled cycle of equivalent states. A non cycle preserving transformation (NON-CP) creates or destroys a labeled cycle of equivalent states. Theorem 4 <ref> [Mal90] </ref> Let M 1 be an implementation corresponding to the state assignment S 1 and STG G 1 and M 2 be an implementation corresponding to the state assignment S 2 and STG G 2 . <p> The figure shows how the circuit may be retimed resulting in a circuit that corresponds to G 2 . This may be further resynthesized to any circuit M 2 that corresponds to state assignment S 2 . 8.2.10 Interpretation and Extensions In the exposition given in <ref> [Mal90] </ref> of the synthesis capability of retiming and synthesis, we came across some aspects that needed either correct interpretation or correction. These are enumerated below: 1. The conditions under which merger of two states can be implemented with re timing and synthesis was not clearly stated. 2. <p> However, in transformations. The transformation in Figure 8.14 involves merging the state 01 with 10 and state 00 with 11. However, since these states are not 1-step equivalent (they are 2-step equivalent), the STG transformation cannot be implemented with retiming and synthesis transformation. This violates the assertion <ref> [Mal90] </ref> that all valid transformations are some sequence or combination of splits, merges and switches, where these terms are interpreted appropriately. 3. <p> Now we can retime the latches appropriately to obtain Figure 8.17 (d). Performing a final resynthesis step results in machine N as shown in Figure 8.17 (e). We should note, however, that this is a practical rather than theoretical problem. 5. In <ref> [Mal90] </ref>, no condition was given for splitting a state with a self-loop. In Figure 8.18 we show the transformation for splitting a state with a self-loop. The rationale behind this transformation is that we want to be able to perform 2-way merge of the states obtained via 2-way splitting. <p> However, as discussed earlier, we can implement this STG transformation using retiming and resynthesis. Next we look at the examples of non-CP transformation given in <ref> [Mal90] </ref> shown in Figure 8.19. The merger of states s 11 and s 12 shown in Figure 8.19a is not a valid 2-way merge because states s 11 and s 12 are not 1-step equivalent. This invalidates the classification of this transformation as non-CP. <p> This is followed by floating latch elimination. In general, this transformation will allow us to implement STG transformations, where some redundant state bits are removed and the STG is reduced in size. 8.3.2 Allowing Negative Retiming Retiming can be extended by introducing the concept of negative latch <ref> [Mal90] </ref>. Allowing a negative edge weight n on a peripheral edge (an edge that connects either an input pin to a logic block or connects a logic block that computes the value of an output to the corresponding output pin) is equivalent to borrowing n latches from the environment. <p> VERIFICATION COMPLEXITY 221 retiming synthesis retiming). The question arises, whether negative retiming adds any optimization power to conventional retiming, i.e., are there circuit instances where optimization using negative retiming combined with synthesis cannot be implemented with conventional retiming and synthesis? In <ref> [Mal90] </ref>, it is claimed that allowing negative edge weights on the peripheral edges allows retiming operations and subsequent optimizations that would otherwise not be possible. To illustrate this assertion, an example was given which is reproduced in Figure 8.23.
Reference: [Mat96] <author> Y. Matsunaga. </author> <title> An Efficient Equivalence Checker for Combinational Circuits. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <pages> pages 62934, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: BDDs play an important role in the implementation verification of combinational circuits, since they provide a canonical representation of the functions. Many successful combinational verification techniques use BDDs as the basic data structure <ref> [RWK95, Mat96, KK97, JMF97] </ref>. For sequential circuits, in addition to representing the behavior of the circuit, we need to represent and traverse the state transition graph (STG). States are represented and manipulated using BDDs. State enumeration forms the core operation in this case. <p> However, the size of the output BDDs grows large for a complex design. The BDD size can be controlled by creating a cutset in the circuit and treating the intermediate signals as the primary inputs <ref> [Mat96, KK97] </ref>. This requires appropriate handling of false negatives. The other technique is to introduce intermediate variables while building the BDDs and appropriately compose them at the end [JNC + 96]. This approach prevents the blowup in the intermediate BDD sizes. <p> Different decomposition schemes, and new decision diagrams however do not necessarily reduce the computation time since in some cases the corresponding manipulation complexity is much higher than for BDDs. Some approaches keep the BDD sizes under control while increasing the number of BDD computations (e.g., network partitioning <ref> [Mat96, KK97, JNC + 96] </ref>, partitioned transition relation [TSL + 90, BCL91b, RAP + 95], etc.). These approaches trade-off memory consumption with computation time. BDD-based techniques are quite general and they are applicable to a broad range of problems. <p> An orthogonal set of techniques, called structure-based techniques, use structural information about the circuit and the nature of transformations performed on it to obtain efficient verification algorithms. It has been established that a combination of functional and structure-based techniques provides a robust methodology for combinational verification <ref> [KK97, Mat96, RWK95, Bra93] </ref>. For sequential circuits, however, attempts to combine structural and functional techniques have been limited to smaller size examples or relatively minor transformations [HCC96b, HCC97]. In the next two chapters we investigate the implementation verification problem for circuits which have undergone repeated retiming and combinational synthesis transformations. <p> On the other hand, the verification problem for combinational logic optimization is a relatively easier problem in practice. Much work has gone into combining structural and functional techniques to obtain verification algorithms that can deal with reasonably large industrial circuits <ref> [Mat96, JMF97, KK97] </ref>. We propose a methodology which reduces a sequential verification problem into an equivalent combinational verification problem for a class of circuits. This allows exploitation of the advancements made in the field of combinational verification and use of its powerful techniques to perform verification. <p> In practice, a modified combinational equivalence checker could be used which would not require generation of such circuits and hence no blow-up would occur. The combinational verification was performed by an in-house tool similar to the ones presented in <ref> [Mat96, KK97] </ref>. 9.7.
Reference: [McM93] <author> K. L. McMillan. </author> <title> Symbolic Model Checking. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference-contexts: Part I Computer Architecture and BDD Manipulation 33 Chapter 3 Breadth-First BDD Manipulation T HE manipulation of very large BDDs is the key to success for BDD-based al gorithms for simulation [Bry91], synthesis [CBM89, TSL + 90], and verification <ref> [BCMD90, McM93, BSA + 96a] </ref> of integrated circuits and systems. <p> BDDs are now extensively used for both design and implementation verification of hardware systems and many non-trivial design examples have been verified using BDDs <ref> [CYF94, McM93] </ref>. Still, there are many instances of medium sized circuits that cannot be verified using existing BDD techniques. In the next five sections, we describe various techniques which enable state transition graph representation and state-space enumeration for large designs. These are: 164 CHAPTER 7. <p> Example # Latches # Gates Description sbc 28 927 ISCAS'89 sequential benchmark (a snooping bus controller). Gigamax 45 994 Cache coherency protocol description for hardware implementation of Gigamax distributed multiprocessor <ref> [McM93] </ref>. Abstracted Byte Data Link Controller (BDLC); BDLC* Manages the transmit-receive protocol between microprocessor 144 4775 and a serial bus. Contains the abstract description of BIT module. Part of a commercial chip.
Reference: [McM94] <author> K. L. McMillan. </author> <title> Fitting Formal Methods into the Design Cycle. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <pages> pages 31619, </pages> <year> 1994. </year>
Reference-contexts: A logic is equipped with a proof system a set of axioms and inference rules that make it possible to reason in a step-by-step manner from premises to conclusions. Most theorem provers are interactive, requiring guidance from the user in order to generate proofs <ref> [McM94] </ref>. Due to this reason, theorem-provers have not achieved the broad level of acceptance despite their impressive demonstration in some government pilot projects [Kur97].
Reference: [MGS97] <author> S. Manne, D. C. Grunwald, and F. Somenzi. </author> <title> Remembrance of Things Past: Locality and Memory in BDDs. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <pages> pages 196201, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: However, their technique is highly specialized and not amenable for integration in a general purpose BDD package. In <ref> [MGS97] </ref>, it has been empirically established that breadth-first manipulation does not have any advantage over depth-first manipulation in terms of cache locality. A different result is reported in [MQRK97] in which a study is done to benchmark various computer architectures for CAD applications.
Reference: [MQRK97] <author> A. Mehrotra, S. Qadeer, R. K. Ranjan, and R. H. Katz. </author> <title> Benchmarking and Analysis of Architectures for CAD Applications. </title> <booktitle> In Proc. IEEE/ACM Intl. Conf. on Computer Design, </booktitle> <address> Austin, Texas, USA, </address> <month> October </month> <year> 1997. </year>
Reference-contexts: However, their technique is highly specialized and not amenable for integration in a general purpose BDD package. In [MGS97], it has been empirically established that breadth-first manipulation does not have any advantage over depth-first manipulation in terms of cache locality. A different result is reported in <ref> [MQRK97] </ref> in which a study is done to benchmark various computer architectures for CAD applications. One of the outcome shown in that work is that cache miss rate for CAL package is 50% less than that in Long's package.
Reference: [MS97] <author> N. Maheshwari and S. S. Sapatnekar. </author> <title> An Improved Algorithm for Minimum-Area Retim-ing. </title> <booktitle> In Proc. of the IEEE/ACM Design Automation Conf., </booktitle> <year> 1997. </year>
Reference-contexts: After the initial retiming algorithm proposed in [LS91] for a simple circuit containing single clock edge-triggered latches, many advancements have been made in terms of efficient implementation and applicability of retiming with more complex memory elements. In particular, techniques given in <ref> [SR94, MS97] </ref> can be applied to large sequential circuits. Retiming of level-sensitive latches was addressed in [SBS93a, LE92]. Recently, Legl et al. proposed retiming techniques for edge-triggered circuits with multiple clocks and load enables [LVW97]. <p> The problem of finding the minimum set of vertices to make the circuit acyclic minimum feedback vertex set problem which is NP-complete. We used a modified version of the heuristics given in [LR90]. 9.7.2 Retiming Retiming was done using Minaret <ref> [MS97] </ref>. This tool only supports the constant delay model (we could not find any efficient public domain retiming tools, which supported better delay models). Retiming was performed in two modes. First, the minimum feasible period was obtained and the area of the circuit was optimized for this period.
Reference: [MSBS91] <author> S. Malik, E. M. Sentovich, R. K. Brayton, and A. L. Sangiovanni-Vincentelli. </author> <title> Retiming and Resynthesis: Optimization of Sequential Networks with Combinational Techniques. </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits, </journal> <volume> 10(1):7484, </volume> <month> Jan-uary </month> <year> 1991. </year>
Reference-contexts: Hence retiming followed by combinational synthesis enables logic optimization which is not possible by combinational optimization alone. Combinational synthesis generates new possibilities for the latch locations perhaps leading to further optimization. A sequence of retiming and combinational resynthesis steps can provide powerful optimization of a sequential circuit. In <ref> [MSBS91] </ref>, it has been shown that retiming combined with synthesis can be used to optimize sequential networks.
Reference: [MSSS95] <author> P. McGeer, A. Saldanha, A. L. Sangiovanni-Vincentelli, and P. Scaglia. </author> <title> Fast Discrete Function Evaluation Using Decision Diagrams. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer-Aided Design, </booktitle> <year> 1995. </year>
Reference-contexts: In Figure 1.9, we present various BDD-based verification techniques and identify the core operations and data structures. Cycle-based simulation using decision diagrams is emerging as a new technology for fast simulations of large designs. An example is <ref> [MSSS95] </ref> which uses the Multi-valued Decision Diagram (MDD) [SKMB90], which is a wrapper around the BDD. BDDs play an important role in the implementation verification of combinational circuits, since they provide a canonical representation of the functions.
Reference: [Mur93] <author> R. Murgai. </author> <title> Logic Synthesis for Field Programmable Gate Arrays. </title> <type> PhD thesis, </type> <institution> University of California Berkeley, </institution> <month> December </month> <year> 1993. </year> <note> Memorandum No. UCB/ERL M93/98. </note>
Reference: [MWBS88] <author> S. Malik, A. R. Wang, R. K. Brayton, and A. L. Sangiovanni-Vincentelli. </author> <title> Logic Verification using Binary Decision Diagrams in a Logic Synthesis Environment. </title> <booktitle> In Proc. IEEE/ACM International Conference on Computer-Aided Design, </booktitle> <pages> pages 69, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: In some cases, there could be an exponential difference in the BDD sizes of a function for two different variable orders. Finding the optimal variable ordering is co-NP complete. A lot of research has been done on this issue <ref> [MWBS88, FFK88] </ref> and recently dynamic variable ordering [FMK91, Rud93] has emerged as enabling technology in this area. BDD partitioning: This approach is similar to the partitioned transition relation method or to creating a cutset in the network. However, the techniques proposed in this category are application independent. <p> The ordering plays a significant role in determining the size of BDDs, which is crucial for their efficient manipulation. The problem of finding an optimal ordering is intractable and several heuristics have been proposed which statically determine a good ordering of variables based on the circuit information <ref> [FFK88, MWBS88] </ref>. Recently, dynamic ordering [Rud93] has become a popular alternative to static ordering. The salient features of this technique are the transparent nature of the algorithm (user need not be aware of it) and the in-place swapping of variables.
Reference: [NJFS96] <author> A. Narayan, J. Jain, M. Fujita, and A. L. Sangiovanni-Vincentelli. </author> <title> Partitioned ROBDDs </title>
Reference-contexts: BDD partitioning: This approach is similar to the partitioned transition relation method or to creating a cutset in the network. However, the techniques proposed in this category are application independent. In particular, techniques are proposed to represent a function as a set of BDDs <ref> [NJFS96, BW97] </ref>. Avoiding intermediate BDD computation: In many BDD applications (symbolic sim ulation, reachability, etc.), some intermediate BDDs are obtained on the way to computing the final result. In some cases, the sizes of the intermediate BDDs could be large even though the final BDD size is small.
References-found: 103

