URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/finkem/www/ps/asru97-fta.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/finkem/www/publications.html
Root-URL: 
Title: Flexible Transcription Alignment  
Author: Michael Finke and Alex Waibel 
Address: Pittsburgh, PA 15213 (USA)  
Affiliation: Interactive Systems Laboratories Carnegie Mellon University  
Abstract: In this paper we present a set of techniques we employed in our Janus Recognition Toolkit (JRTk) Switchboard and CallHome recognizer in order to deal with imperfections in the transcriptions: inconsistent transcription of pronunciations and contractions as well as errors in utterance segmentations. These techniques consist of a dynamic, speaking mode dependent pronunciation model and a flexible utterance alignment procedure which is based on speaker adapted models (label boosting). The idea is (a) to automatically retranscribe the training corpus based on these models and procedures, (b) to train a recognizer based on these flexible transcription graphs and (c) to decode with a dynamic speaking mode dependent dictionary. The framework is successfully applied to increase the performance of our state-of-the-art JRTk Switchboard recognizer significantly. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Finke, J. Fritsch, P. Geutner, K. Ries, T. Zeppenfeld, and A. Waibel. </author> <title> The JanusRTk Switchboard/Callhome 1997 Evaluation System. </title> <booktitle> In Proceedings of LVCSR Hub 5-e Workshop, </booktitle> <month> May </month> <year> 1997. </year>
Reference-contexts: of the bigram criterion but since there is no significant context dependent pronunciation variation involved, MCA ranks them lower. 4 Flexible Alignment of Transcription Graphs 4.1 Utterance Transcription Graphs In order to train our speech recognizer based on unreliable transcriptions we implemented a Flexible Transcription Alignment (FTA) procedure in JRTk <ref> [1, 3] </ref>. <p> The speaker dependent forced alignment is then used to determine a new transcription of the training corpus in terms of pronunciation variation and utterance segmentation (see Figure 3) <ref> [6, 1] </ref>. Table 2 shows the resulting alignment for a Switchboard utterance. The underlined words were part of the original Switchboard transcription. Parentheses mark pronunciation variants with the rule numbers that they were derived from attached.
Reference: [2] <author> Michael Finke. </author> <title> The JanusRTk Switchboard/Callhome 1997 Evaluation System: Pronunciation Modeling. </title> <booktitle> In Proceedings of LVCSR Hub 5-e Workshop, </booktitle> <month> May </month> <year> 1997. </year>
Reference-contexts: All test runs used the JRTk Switchboard recognizer <ref> [2] </ref>. The preprocessing of the system consists of extracting an MFCC based feature vector every 10 ms. The final feature vector is computed by a truncated LDA transformation of a concatenation of MFCCs and their first and second order derivatives.
Reference: [3] <author> Michael Finke and Alex Waibel. </author> <title> Speaking Mode Dependent Pronunciation Mod eling in Large Vocabulary Conversational Speech Recognition. </title> <booktitle> In Proceedings of Eurospeech-97, </booktitle> <month> September </month> <year> 1997. </year>
Reference-contexts: Similar to Tajchman et al. [5] we developed a probabilistic model based on context dependent phonetic rewrite rules (see Table 1) to come up with a list of possible pronunciations for all words or sequences of words <ref> [3] </ref>. In order to reduce the con-fusability of this expanded dictionary the idea is to annotate each variant of a word with an observation probability. To this aim we automatically retranscribe the corpus based on all the variants allowed. <p> For decoding, the probability of encountering pronunciation variants is then defined to be a function of the speaking style (phonetic context, linguistic context, speaking rate and durations). The probability function is learned through decision trees from rule based generated pronunciation variants as observed on the Switchboard corpus <ref> [3] </ref>. 1 [AX IX] N ! (E)N 3 [AX IX] L ! (E)L 5 [T D] ! DX / [+VOWEL] [AX IX AXR] 6 [T D] R ! DX 8 IY ! Y / [AX IX AXR] 10 HH ! 0 / WB 12 DH ! 0 / WB 13 [T <p> We could either train our language model on a text file where sequences of words are replaced by multiwords or split multiwords when it comes to compute the LM probability for a given sequence of words. In <ref> [3] </ref> we presented evidence that on Switchboard and Callhome not modelling multiwords in the language model yields significantly better performance. This raises the question on how we should pick the list of multiwords. <p> of the bigram criterion but since there is no significant context dependent pronunciation variation involved, MCA ranks them lower. 4 Flexible Alignment of Transcription Graphs 4.1 Utterance Transcription Graphs In order to train our speech recognizer based on unreliable transcriptions we implemented a Flexible Transcription Alignment (FTA) procedure in JRTk <ref> [1, 3] </ref>.
Reference: [4] <author> M. Ostendorf, B. Byrne, M. Bacchiani, M. Finke, A. Gunawardana, K. Ross, S. Roweis, E. Shriberg, D. Talkin, A.Waibel, B. Wheatley, and T. Zeppen-feld. </author> <title> Systematic Variations in Pronunciation via a Language-Dependent Hidden Speaking Mode. </title> <booktitle> In International Conference on Spoken Language Processing, </booktitle> <address> Philadelphia, USA, </address> <year> 1996. </year>
Reference-contexts: flexible alignment and utterance segmentation yields a significant improvement in terms of word error rate of our Switchboard/CallHome recognizer. 2 Speaking Mode Dependent Pronunciation Modelling In spontaneous conversational speech there is a large amount of variability due to accents, speaking styles and speaking rates (also known as the speaking mode) <ref> [4] </ref>. Because current recognition systems usually use only a relatively small number of pronunciation variants for the words in their dictionaries, the amount of variability that can be modelled is limited. Increasing the number of variants per dictionary entry is the obvious solution.
Reference: [5] <author> G. Tajchman, E. Fossler, and D. Jurafsky. </author> <title> Building Multiple Pronunciation Models for Novel Words using Exploratory Computational Phonology. </title> <booktitle> In Proceedings Eurospeech, </booktitle> <pages> pages 2247-2250, </pages> <year> 1995. </year>
Reference-contexts: Increasing the number of variants per dictionary entry is the obvious solution. Unfortunately, this also means increasing the confus-ability between the dictionary entries, and thus often leads to an actual performance decrease. Similar to Tajchman et al. <ref> [5] </ref> we developed a probabilistic model based on context dependent phonetic rewrite rules (see Table 1) to come up with a list of possible pronunciations for all words or sequences of words [3].
Reference: [6] <author> Torsten Zeppenfeld, Michael Finke, Klaus Ries, Martin Westphal, and Alex Waibel. </author> <title> Recognition of Conversational Telephone Speech using the JANUS Speech Engine. </title> <booktitle> In IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Munich, Germany, 1997. </address> <publisher> IEEE. </publisher>
Reference-contexts: The speaker dependent forced alignment is then used to determine a new transcription of the training corpus in terms of pronunciation variation and utterance segmentation (see Figure 3) <ref> [6, 1] </ref>. Table 2 shows the resulting alignment for a Switchboard utterance. The underlined words were part of the original Switchboard transcription. Parentheses mark pronunciation variants with the rule numbers that they were derived from attached.
References-found: 6

