URL: http://http.cs.berkeley.edu/~asah/papers/other/printed/preemptible-hashjoin.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~asah/papers/other/printed/
Root-URL: http://www.cs.berkeley.edu
Title: Partially Preemptible Hash Joins  
Author: HweeHwa Pang Michael J. Carey Miron Livny 
Note: This work was partially supported by a scholarship from the Institute of Systems Science, National University of Singapore, and by an IBM Research Initiation Grant.  
Address: Wisconsin Madison  
Affiliation: Computer Sciences Department University of  
Abstract: With the advent of real-time and goal-oriented database systems, priority scheduling is likely to be an important feature in future database management systems. A consequence of priority scheduling is that a transaction may lose its buffers to higher-priority transactions, and may be given additional memory when higher-priority transactions leave the system. Due to their heavy reliance on main memory, hash joins are especially vulnerable to fluctuations in memory availability. Previous studies have proposed modifications to the hash join algorithm to cope with these fluctuations, but the proposed algorithms have not been extensively evaluated or compared with each other. This paper contains a performance study of these algorithms. In addition, we introduce a family of memory-adaptive hash join algorithms that turns out to offer even better solutions to the memory fluctuation problem that hash joins experience. An abridged version of this paper appears in the proceedings of the ACM SIGMOD Conference, May 1993. hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh
Abstract-found: 1
Intro-found: 1
Reference: [Abbo88] <author> R. Abbott, H. Garcia-Molina, </author> <title> "Scheduling Real-Time Transactions: A Performance Evaluation", </title> <booktitle> Proc. of the 14th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1988. </year>
Reference-contexts: 1. Introduction Database management systems (DBMS) are faced with increasingly demanding performance objectives. These objectives could be time constraint requirements, as in real-time database systems <ref> [SIGM88, Abbo88, Huan89, Hari90, Kort90, Kim91, RTS92] </ref>, or administration defined performance goals as in goal-oriented database systems [Ferg93, Brow93].
Reference: [Bitt88] <author> D. Bitton, J. Gray, </author> <title> "Disk Shadowing", </title> <booktitle> Proc. of the 14th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1989. </year> <month> - 29 </month> - 
Reference-contexts: The characteristics of the disks are also given in Table 3. Using the parameters in this table, the total time required to complete a disk access is computed as: Disk Access Time = Seek Time + Rotational Delay + Transfer Time As in <ref> [Bitt88] </ref>, the time required to seek across n tracks is given by: Seek Time (n) = SeekFactor dd n - 12 - iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii Parameter Meaning Parameter Meaning iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii CPUSpeed MIPS rating of CPU CylinderSize Number of pages per cylinder NumDisks Number of disks PageSize Number of bytes per page SeekFactor Seek
Reference: [Blas77] <author> M.W. Blasgen, </author> <title> K.P. Eswaran, "Storage and Access in Relational Databases", </title> <journal> IBM Systems Journal, </journal> <volume> Vol. 16,4, </volume> <year> 1977. </year>
Reference-contexts: With priority scheduling, the DBMS may preempt a transaction that is currently allocated a resource when that resource is requested by a higher-priority transaction. To avoid severe performance degradation, e.g. due to convoys that arise when transactions holding critical resources are suspended <ref> [Blas77] </ref>, it is desirable to preempt a transaction only at a preemption-safe point, where the transaction is not holding any critical resources and the preemption cost is minimal [Ston81]. Scans and updates, which acquire and release resources repeatedly throughout their lifetimes, have frequent preemption-safe points.
Reference: [Brow93] <author> K.P. Brown, M.J. Carey, M. Livny, </author> <title> "Managing Memory to Meet Multiclass Workload Response Time Goals", </title> <booktitle> Proc. of the 19th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1993. </year>
Reference-contexts: 1. Introduction Database management systems (DBMS) are faced with increasingly demanding performance objectives. These objectives could be time constraint requirements, as in real-time database systems [SIGM88, Abbo88, Huan89, Hari90, Kort90, Kim91, RTS92], or administration defined performance goals as in goal-oriented database systems <ref> [Ferg93, Brow93] </ref>. Traditional first-come-first-serve or round-robin scheduling policies are no longer adequate to meet such objectives; a DBMS has to prioritize transactions that are competing for system resources according to the system objectives and the resource requirements of the transactions.
Reference: [DeWi84] <author> D.J. DeWitt, R.H. Katz, F. Olken, L.D. Shapiro, M. Stonebraker, D. Wood, </author> <title> "Implementation Techniques for Main Memory Database Systems", </title> <booktitle> Proc. of the ACM 1984 SIGMOD Conf., </booktitle> <month> June </month> <year> 1984. </year>
Reference-contexts: Depending on the specific algorithm used, the number of buffers that a hash join utilizes ranges anywhere from the square root of the size of the inner relation to the inner relation size <ref> [DeWi84, Shap86] </ref>, which can be a substantial portion of the system memory. Moreover, this hash table has to be kept in memory for a long period of time. <p> Excess buffers are used to hold subsets of R and/or S so they need not be written to disk. A shortcoming of the GRACE Hash Join algorithm is that it does not effectively utilize memory that is in excess of the minimum requirement of ddddd F||R|| buffers. In <ref> [DeWi84] </ref>, DeWitt et al proposed the Hybrid Hash Join algorithm, which follows the same three phases that GRACE goes through but uses excess memory more effectively.
Reference: [DeWi90] <author> D.J. DeWitt, S. Ghandeharizadeh, D.A. Schneider, A. Bricker, H.-I Hsiao, R. Rasmussen, </author> <title> "The Gamma Database Machine Project", </title> <journal> IEEE Trans. on Knowledge and Data Engineering, </journal> <volume> Vol. 2,1, </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: The MIPS rating of the CPU is given by CPUSpeed. Table 4 gives the cost of various CPU operations that are involved in the execution of a join. These CPU costs are based on instruction counts taken from the Gamma database machine <ref> [DeWi90] </ref>. Turning to the disk model parameters in Table 3, NumDisks specifies the number of disks attached to the system. Each disk has its own queue and disk requests are serviced according to the elevator algorithm. The characteristics of the disks are also given in Table 3.
Reference: [Ferg93] <author> D. Ferguson, C. Nikolaou, L. Georgiadis, </author> <title> "Goal Oriented, Adaptive Transaction Routing for High Performance Transaction Processing Systems", </title> <booktitle> Proc. of the 2nd Int. Conf. on Parallel and Distributed Information Systems, </booktitle> <month> January </month> <year> 1989. </year>
Reference-contexts: 1. Introduction Database management systems (DBMS) are faced with increasingly demanding performance objectives. These objectives could be time constraint requirements, as in real-time database systems [SIGM88, Abbo88, Huan89, Hari90, Kort90, Kim91, RTS92], or administration defined performance goals as in goal-oriented database systems <ref> [Ferg93, Brow93] </ref>. Traditional first-come-first-serve or round-robin scheduling policies are no longer adequate to meet such objectives; a DBMS has to prioritize transactions that are competing for system resources according to the system objectives and the resource requirements of the transactions.
Reference: [Hari90] <author> J. Haritsa, M. Carey, M. Livny, </author> <title> "On Being Optimistic about Real-Time Constraints", </title> <booktitle> Proc. of the 1990 ACM PODS Symposium, </booktitle> <month> April </month> <year> 1990. </year>
Reference-contexts: 1. Introduction Database management systems (DBMS) are faced with increasingly demanding performance objectives. These objectives could be time constraint requirements, as in real-time database systems <ref> [SIGM88, Abbo88, Huan89, Hari90, Kort90, Kim91, RTS92] </ref>, or administration defined performance goals as in goal-oriented database systems [Ferg93, Brow93].
Reference: [Huan89] <author> J. Huang, J.A. Stankovic, D. Towsley, K. Ramamritham, </author> <title> "Experimental Evaluation of Real-Time Transaction Processing", </title> <booktitle> Proc. of the 1989 IEEE 10th Real-Time Systems Symposium (RTSS). </booktitle>
Reference-contexts: 1. Introduction Database management systems (DBMS) are faced with increasingly demanding performance objectives. These objectives could be time constraint requirements, as in real-time database systems <ref> [SIGM88, Abbo88, Huan89, Hari90, Kort90, Kim91, RTS92] </ref>, or administration defined performance goals as in goal-oriented database systems [Ferg93, Brow93].
Reference: [Kim91] <author> W. Kim, J. Srivastava, </author> <title> "Enhancing Real-Time DBMS Performance with Multiversion Data and Priority Based Disk Scheduling", </title> <booktitle> Proc. of the 1991 IEEE 12th Real-Time Systems Symposium (RTSS). </booktitle>
Reference-contexts: 1. Introduction Database management systems (DBMS) are faced with increasingly demanding performance objectives. These objectives could be time constraint requirements, as in real-time database systems <ref> [SIGM88, Abbo88, Huan89, Hari90, Kort90, Kim91, RTS92] </ref>, or administration defined performance goals as in goal-oriented database systems [Ferg93, Brow93].
Reference: [Kits83] <author> M. Kitsuregawa, H. Tanaka, T. Moto-oka, </author> <title> "Application of Hash to Data Base Machine and Its Architecture", </title> <journal> New Generation Computing, </journal> <volume> Vol. 1,1, </volume> <year> 1983. </year>
Reference-contexts: We also use a "fudge factor", F, to represent the overhead for a hash table. For example, a hash table for R is assumed to require F||R|| pages. This notation is summarized in Table 1. Some of the earliest work on joins using hashing is reported in <ref> [Kits83] </ref>. The GRACE Hash Join algorithm was introduced in that study. In GRACE Hash Join, a join is processed in three phases. First, the inner relation R is split into ddddd F||R|| disk-resident partitions that are approximately equal in size.
Reference: [Kits89] <author> M. Kitsuregawa, M. Nakayama, M. Takagi, </author> <title> "The Effect of Bucket Size Tuning in the Dynamic Hybrid GRACE Hash Join Method", </title> <booktitle> Proc. of the 15th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1989. </year>
Reference-contexts: The next two phases proceed exactly as in the Hybrid (or GRACE) Hash Join algorithm. Through a series of experiments, this modified algorithm was shown to outperform Hybrid Hash Join when the hash attribute distribution cannot be accurately determined <ref> [Kits89] </ref>.
Reference: [Kort90] <author> H.F. Korth, N. Soparkar, A. Silberschatz, </author> <title> "Triggered Real-Time Databases with Consistency Constraints", </title> <booktitle> Proc. of the 16th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: 1. Introduction Database management systems (DBMS) are faced with increasingly demanding performance objectives. These objectives could be time constraint requirements, as in real-time database systems <ref> [SIGM88, Abbo88, Huan89, Hari90, Kort90, Kim91, RTS92] </ref>, or administration defined performance goals as in goal-oriented database systems [Ferg93, Brow93].
Reference: [Livn87] <author> M. Livny, S. Khoshafian, H. Boral, </author> <title> "Multi-Disk Management Algorithms", </title> <booktitle> Proc. of the ACM 1987 SIG-METRICS Conf., </booktitle> <month> May </month> <year> 1987. </year>
Reference-contexts: Each relation i,j (i = 1, 2; 1 j NumRel i ), in turn, has a size of RelSize i, j MBytes and occupies contiguous pages on disk. If there are multiple disks, all relations are declustered (horizontally partitioned) <ref> [Ries78, Livn87] </ref> across all of the disks.
Reference: [Livn90] <author> M. Livny, </author> <note> "DeNet User's Guide, Version 1.5", </note> <institution> Computer Sciences Department, University of Wisconsin, Madison, </institution> <year> 1990. </year>
Reference-contexts: The simulator is written in the DeNet - 10 - Transaction Manager Source Buffer Manager Disk Manager CPU Manager request CPU reply page request page reply request CPU reply processed transaction transaction new page reply page request simulation language <ref> [Livn90] </ref>. 4.1. Database and Workload Model Table 2 summarizes the database and workload model parameters that are relevant to this study. Our objective is to simulate a stream of binary hash joins on different source relations. To facilitate this, the database consists of two groups of relations.
Reference: [Naka88] <author> M. Nakayama, M. Kitsuregawa, M. Takagi, </author> <title> "Hash-Partitioned Join Method Using Dynamic Destaging Strategy", </title> <booktitle> Proc. of the 14th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1988. </year>
Reference-contexts: One possible cause of this discrepancy is due to incorrect estimation of the hash attribute distribution. This results in a situation where some R partitions are larger than the allocated memory, while other R partitions are under-sized. In <ref> [Naka88] </ref>, a modification of Hybrid Hash Join was proposed to deal with this memory misfit problem. Instead of deciding on the number of partitions at the beginning, the proposed modification splits the inner relation into smaller subsets, called buckets, which will later be grouped into partitions. <p> Zeller and Gray first addressed this situation in [Zell90]. Like the algorithm in <ref> [Naka88] </ref>, the algorithm that they proposed divides the inner relation into many buckets. Unlike the Nakayama et al algorithm, the Zeller and Gray algorithm immediately groups these buckets into tentative partitions. The total number of buckets and the number of buckets per partition are both parameters of the algorithm. <p> First, Partially Preemptible Hash Join (PPHJ), a new family of hash join algorithms that dynamically alter the memory usage of joins according to buffer availability, is introduced. We then relate the algorithms proposed in <ref> [Naka88] </ref> and [Zell90] to PPHJ. Finally, we describe how our implementations of the basic GRACE and Hybrid Hash Join algorithms cope with memory fluctuations. 3.1. <p> Thus, PPHJ (early,noexp,lru) denotes the basic PPHJ, which uses early contraction, no expansion and LRU spooling; PPHJ (late,exp,prio) denotes the fully enhanced PPHJ, with late contraction, expansion and prioritized spooling, and so on. - 8 - 3.2. Other Algorithms 3.2.1. Nakayama et al The algorithm proposed in <ref> [Naka88] </ref>, which we will call NKT from here on, delays the decision to contract buckets as long as possible. When a bucket has to be contracted, all of its memory-resident pages are flushed to disk without going through the spool area. <p> Thus expansion appears to be a generally useful mechanism. 5.6. Discussion of Other Alternatives As described in Section 3, we have extended the algorithms in <ref> [Naka88] </ref> and [Zell90] to allow partition contractions during the second phase of a join. <p> The exception was when memory availability fluctuates extremely rapidly. Moreover, further savings can be achieved by late contraction and priority spooling, though the savings are not nearly as significant. These findings are important in two ways. First, previous studies <ref> [Naka88, Zell90] </ref> have proposed algorithms that rely on late contraction. Our study showed that expanding partitions while the outer relation S is being scanned leads to more effective utilization of excess memory, and hence to lower response times.
Reference: [Pang93] <author> H. Pang, M.J. Carey, M. Livny, </author> <title> "Partially Preemptible Hash Joins", </title> <booktitle> Proc. of the ACM 1993 SIGMOD Conf., </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: It should be noted that, in <ref> [Pang93] </ref>, spooled pages are written out one page at a time. This accounts for the different performance figures reported there. However, the relative performance between different algorithms/mechanisms remains the same. - 7 - 1. Contraction.
Reference: [Ries78] <author> D. Ries, R. Epstein, </author> <title> "Evaluation of Distribution Criteria for Distributed Database Systems", </title> <type> UCB/ERL Technical Report M78/22, </type> <institution> UC Berkeley, </institution> <month> May </month> <year> 1978. </year>
Reference-contexts: Each relation i,j (i = 1, 2; 1 j NumRel i ), in turn, has a size of RelSize i, j MBytes and occupies contiguous pages on disk. If there are multiple disks, all relations are declustered (horizontally partitioned) <ref> [Ries78, Livn87] </ref> across all of the disks.
Reference: [RTS92] <institution> Real-Time Systems, </institution> <note> 4(3), Special Issue on Real-Time Databases, </note> <month> September </month> <year> 1992. </year>
Reference-contexts: 1. Introduction Database management systems (DBMS) are faced with increasingly demanding performance objectives. These objectives could be time constraint requirements, as in real-time database systems <ref> [SIGM88, Abbo88, Huan89, Hari90, Kort90, Kim91, RTS92] </ref>, or administration defined performance goals as in goal-oriented database systems [Ferg93, Brow93].
Reference: [Sarg76] <author> R. Sargent, </author> <title> "Statistical Analysis of Simulation Output Data", </title> <booktitle> Proc. of the 4th Annual Symposium on the Simulation of Computer Systems, </booktitle> <month> August </month> <year> 1976. </year>
Reference-contexts: For ease of reference, the indicator for the algorithms are summarized in Table 5. To ensure the statistical validity of our results, we verified that the 90% confidence intervals for join response times (computed using the batch means approach <ref> [Sarg76] </ref>) were sufficiently tight.
Reference: [Shap86] <author> L.D. Shapiro, </author> <title> "Join Processing in Database Systems with Large Main Memories", </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol. 11,3, </volume> <month> September </month> <year> 1986. </year>
Reference-contexts: Depending on the specific algorithm used, the number of buffers that a hash join utilizes ranges anywhere from the square root of the size of the inner relation to the inner relation size <ref> [DeWi84, Shap86] </ref>, which can be a substantial portion of the system memory. Moreover, this hash table has to be kept in memory for a long period of time. <p> In the second phase, the outer relation S is partitioned using the same split function. Finally, the R and S tuples of each disk-resident partition are joined in memory. In the variation of the GRACE algorithm that is presented in <ref> [Shap86] </ref>, a join requires only ddddd F||R|| output buffers throughout its lifetime. Excess buffers are used to hold subsets of R and/or S so they need not be written to disk.
Reference: [SIGM88] <editor> SIGMOD Record, </editor> <volume> Vol. </volume> <month> 17,1, </month> <title> Special Issue on Real-Time Data Base Systems, </title> <editor> S. Son, editor, </editor> <month> March </month> <year> 1988. </year>
Reference-contexts: 1. Introduction Database management systems (DBMS) are faced with increasingly demanding performance objectives. These objectives could be time constraint requirements, as in real-time database systems <ref> [SIGM88, Abbo88, Huan89, Hari90, Kort90, Kim91, RTS92] </ref>, or administration defined performance goals as in goal-oriented database systems [Ferg93, Brow93].
Reference: [Ston81] <author> M. Stonebraker, </author> <title> "Operating System Support for Database Management", </title> <journal> Comm. of the ACM, </journal> <volume> Vol. 24,7, </volume> <year> 1981. </year>
Reference-contexts: To avoid severe performance degradation, e.g. due to convoys that arise when transactions holding critical resources are suspended [Blas77], it is desirable to preempt a transaction only at a preemption-safe point, where the transaction is not holding any critical resources and the preemption cost is minimal <ref> [Ston81] </ref>. Scans and updates, which acquire and release resources repeatedly throughout their lifetimes, have frequent preemption-safe points. In contrast, large joins, especially hash joins, hold on to their buffers for an extended period each time.
Reference: [Teng84] <author> J. Teng, R.A. Gumaer, </author> <title> "Managing IBM Database 2 Buffers to Maximize Performance", </title> <journal> IBM Systems Journal, </journal> <volume> Vol. 23,2, </volume> <year> 1984. </year>
Reference-contexts: This lengthens the time that is needed to satisfy the waiting buffer request, and should be avoided if possible. For this reason, an asyn chronous memory write process is provided to flush dirty pages to disk periodically <ref> [Teng84] </ref>. The write process is activated every SleepTime seconds. Upon activation, the process flushes all of the dirty pages that are older than FlushThreshold. The reason for flushing only the "old" dirty pages is to prevent unnecessary writes of pages that are frequently updated. 5.
Reference: [Zell90] <author> H. Zeller, J. Gray, </author> <title> "An Adaptive Hash Join Algorithm for Multiuser Environments", </title> <booktitle> Proc. of the 16th Int. Conf. on Very Large Data Bases, </booktitle> <month> August </month> <year> 1990. </year> <month> - 30 </month> - 
Reference-contexts: Zeller and Gray first addressed this situation in <ref> [Zell90] </ref>. Like the algorithm in [Naka88], the algorithm that they proposed divides the inner relation into many buckets. Unlike the Nakayama et al algorithm, the Zeller and Gray algorithm immediately groups these buckets into tentative partitions. <p> First, Partially Preemptible Hash Join (PPHJ), a new family of hash join algorithms that dynamically alter the memory usage of joins according to buffer availability, is introduced. We then relate the algorithms proposed in [Naka88] and <ref> [Zell90] </ref> to PPHJ. Finally, we describe how our implementations of the basic GRACE and Hybrid Hash Join algorithms cope with memory fluctuations. 3.1. <p> to every expanded partition at once, we could let each partition start off with only 1 page, and allocate additional pages to a partition only when the pages that it currently owns are full; all the pages that a partition owns are linked to form a hash chain, as in <ref> [Zell90] </ref>. This allows all partitions to be "expanded" initially. Under this variation, contraction occurs when an expanded partition requires an additional page and none is available. <p> Zeller and Gray Like the Nakayama et al algorithm, the algorithm of Zeller and Gray (which we will refer to as ZG) allows contractions to occur only during the first phase of a join <ref> [Zell90] </ref>. Our implementation relaxes this restriction so that contractions may occur in both phase 1 and phase 2. The total number of buckets, a parameter of the algorithm, is set to ddddd F||R|| for the same reason as in NKT . <p> Thus expansion appears to be a generally useful mechanism. 5.6. Discussion of Other Alternatives As described in Section 3, we have extended the algorithms in [Naka88] and <ref> [Zell90] </ref> to allow partition contractions during the second phase of a join. <p> The exception was when memory availability fluctuates extremely rapidly. Moreover, further savings can be achieved by late contraction and priority spooling, though the savings are not nearly as significant. These findings are important in two ways. First, previous studies <ref> [Naka88, Zell90] </ref> have proposed algorithms that rely on late contraction. Our study showed that expanding partitions while the outer relation S is being scanned leads to more effective utilization of excess memory, and hence to lower response times.
References-found: 25

