URL: ftp://ftp.cc.gatech.edu/pub/coc/tech_reports/1993/GIT-CC-93-68.ps.Z
Refering-URL: http://www.cs.gatech.edu/tech_reports/index.93.html
Root-URL: 
Title: The Complexity of Almost-Optimal Coordination  
Author: Rida A. Bazzi Gil Neiger 
Note: This work was supported in part by the National Science Foundation under grants CCR-9106627 and CCR-9301454. This author was supported in part by a scholarship from the Hariri Foundation.  
Address: Atlanta, Georgia 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  
Date: November 30, 1993  
Pubnum: GIT-CC-93/68  
Abstract: The problem of fault-tolerant coordination is fundamental in distributed computing. In the past, researchers have considered the complexity of achieving optimal simultaneous coordination under various failure assumptions. This paper studies the complexity of achieving simultaneous coordination in synchronous systems in the presence of send/receive omission failures. It had been shown earlier that achieving optimal simultaneous coordination in these systems requires NP-hard local computation. In this paper, we study almost-optimal coordination, which requires processors to coordinate within a constant additive or multiplicative number of rounds of the coordination time of an optimal protocol. We show that achieving almost-optimal coordination also requires NP-hard computation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Rida Bazzi and Gil Neiger. </author> <title> Optimally simulating crash failures in a Byzantine environment. </title> <editor> In S. Toueg, P. G. Spirakis, and L. Kirousis, editors, </editor> <booktitle> Proceedings of the Fifth International Workshop on Distributed Algorithms, volume 579 of Lecture Notes on Computer Science, </booktitle> <pages> pages 108-128. </pages> <publisher> Springer-Verlag, </publisher> <month> October </month> <year> 1991. </year>
Reference: [2] <author> Rida A. Bazzi and Gil Neiger. </author> <title> Simulating crash failures with many faulty pro-cessors. </title> <editor> In A. Segall and S. Zaks, editors, </editor> <booktitle> Proceedings of the Sixth International Workshop on Distributed Algorithms, number 647 in Lecture Notes on Computer Science, </booktitle> <pages> pages 166-184. </pages> <publisher> Springer-Verlag, </publisher> <month> November </month> <year> 1992. </year>
Reference: [3] <author> Piotr Berman and Juan A. Garay. Cloture votes: n=4-resilient, </author> <title> polynomial time distributed consensus in t + 1 rounds. </title> <journal> Mathematical Systems Theory, </journal> <volume> 26(1) </volume> <pages> 3-20, </pages> <year> 1993. </year>
Reference: [4] <author> Brian A. Coan. </author> <title> A compiler that increases the fault-tolerance of asynchronous protocols. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(12) </volume> <pages> 1541-1553, </pages> <month> December </month> <year> 1988. </year>
Reference: [5] <author> Cynthia Dwork and Yoram Moses. </author> <title> Knowledge and common knowledge in a Byzantine environment: Crash failures. </title> <journal> Information and Computation, </journal> <volume> 88(2) </volume> <pages> 156-186, </pages> <month> October </month> <year> 1990. </year>
Reference: [6] <author> Michael J. Fischer. </author> <title> The consensus problem in unreliable distributed systems (a brief survey). </title> <editor> In M. Karpinsky, editor, </editor> <booktitle> Foundations of Computation Theory, vol-ume 158 of Lecture Notes on Computer Science, </booktitle> <pages> pages 127-140. </pages> <publisher> Springer-Verlag, </publisher> <year> 1983. </year>
Reference-contexts: Fault-tolerant coordination requires that the nonfaulty processors successfully coordinate their actions despite the failures of others. There is a large body of literature within computer science that has studied fault-tolerant coordination problems, such as Reliable Broadcast and Distributed Consensus. Fischer <ref> [6] </ref> provides a survey of many such problems. This paper considers simultaneous coordination problems in synchronous systems in which algorithms operate in rounds of communication (simultaneous coordination is not possible in asynchronous systems).
Reference: [7] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> New York, New York, </address> <year> 1979. </year> <month> 10 </month>
Reference-contexts: Neiger and Tuttle [17] subsequently showed related results considering stronger forms of coordination and of common knowledge. It is known that many NP-complete problems can be solved approximately in polynomial time <ref> [7] </ref>. Perhaps almost-optimal algorithms for simultaneous coordination might require only polynomial-time local computation (in systems with general omission failures). A simultaneous coordination algorithm is almost-optimal if processors decide within a constant additive or multiplicative number of rounds of the decision time of an optimal algorithm. <p> The Vertex Cover problem is known to be NP-hard <ref> [7] </ref>. The intuition behind the reduction is that the faulty processors form a vertex cover of the graph defined by the missing messages in any round. The following is an algorithm for Vertex Cover.
Reference: [8] <author> Vassos Hadzilacos. </author> <title> A knowledge theoretic analysis of atomic commitment proto-cols. </title> <booktitle> In Proceedings of the Sixth Symposium on Principles of Database Systems, </booktitle> <pages> pages 129-134. </pages> <publisher> ACM Press, </publisher> <month> March </month> <year> 1987. </year>
Reference: [9] <author> Joseph Y. Halpern and Yoram Moses. </author> <title> Knowledge and common knowledge in a distributed environment. </title> <journal> Journal of the ACM, </journal> <volume> 37(3) </volume> <pages> 549-587, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: This paper considers simultaneous coordination problems in synchronous systems in which algorithms operate in rounds of communication (simultaneous coordination is not possible in asynchronous systems). The results in this paper are based on the relationship between coordination and different forms of processor knowledge <ref> [9] </ref>. It is well-established that knowledge can be used to characterize and improve solutions to various problems in distributed computing [3,5,8,10-14,17]. <p> Therefore, in what follows, we can restrict our study to full-information protocols. 4 Knowledge and Coordination Processor knowledge was first defined by Halpern and Moses <ref> [9] </ref> as follows. <p> One way to prove that a fact is common knowledge is to use the induction rule for common knowledge <ref> [9] </ref>. The induction rule says that, if ' ) E' is valid in a system, then so is ' ) C'.
Reference: [10] <author> Joseph Y. Halpern, Yoram Moses, and Orli Waarts. </author> <title> A characterization of eventual Byzantine agreement. </title> <booktitle> In Proceedings of the Ninth ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 333-346. </pages> <publisher> ACM Press, </publisher> <month> August </month> <year> 1990. </year>
Reference: [11] <author> Murray S. Mazer. </author> <title> A knowledge theoretic account of recovery in distributed sys-tems: The case of negotiated commitment. </title> <editor> In Moshe Y. Vardi, editor, </editor> <booktitle> Proceedings of the Second Conference on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pages 309-324. </pages> <publisher> Morgan-Kaufmann, </publisher> <month> March </month> <year> 1988. </year>
Reference: [12] <author> Ruben Michel. </author> <title> Knowledge in Distributed Byzantine Environments. </title> <type> Ph.D. </type> <institution> disser-tation, Yale University, </institution> <month> December </month> <year> 1989. </year>
Reference: [13] <author> Yoram Moses and Mark R. Tuttle. </author> <title> Programming simultaneous actions using com-mon knowledge. </title> <journal> Algorithmica, </journal> <volume> 3(1) </volume> <pages> 121-169, </pages> <year> 1988. </year>
Reference-contexts: The results in this paper are based on the relationship between coordination and different forms of processor knowledge [9]. It is well-established that knowledge can be used to characterize and improve solutions to various problems in distributed computing [3,5,8,10-14,17]. For example, Moses and Tuttle <ref> [13] </ref> showed that common knowledge is necessary for the solution of simultaneous coordination problems and used this fact to derive optimal solutions to such problems. <p> We note that our definition of simultaneous coordination problems is the same as the definition that Moses and Tuttle <ref> [13] </ref> give for simultaneous choice problems. In this paper, we study coordination problems whose enabling condition are nontrivial facts about the input and the existence of failures. A fact is nontrivial if neither it nor its negation is valid in the system. <p> Because this paper deals with coordination among the nonfaulty processors, we are specifically interested in the knowledge possessed by the set N of nonfaulty processors. Everyone in N knows ', denoted E', is defined as V p2N B p '. (Moses and Tuttle <ref> [13] </ref> and Neiger and Tuttle [17] explain why belief, and not knowledge, is appropriate for the problems considered here.) Fact ' is common knowledge, denoted C', if V A useful tool for reasoning about knowledge is the similarity graph. <p> It is not hard to see that a fact is common knowledge at a point (; `) if and only if it holds at all points that are similar to it <ref> [13] </ref>. One way to prove that a fact is common knowledge is to use the induction rule for common knowledge [9]. The induction rule says that, if ' ) E' is valid in a system, then so is ' ) C'. <p> An almost-optimal action function with multiplicative constant k requires processors to take some action in round r when some enabling condition has been common knowledge since round br=kc. 5 Complexity Results In this section, we study the complexity of almost-optimal simultaneous coordination. Moses and Tuttle <ref> [13] </ref> proved that processors running an optimal protocol may be required to perform NP-hard local computation between rounds of communication. We show that processors running an almost-optimal protocol would still be required to perform NP-hard local computation between rounds of communication. <p> Since jAj = 2t &gt; t, at least one processor in A is correct, so ' cannot be common knowledge at the end of round 2. In what follows we will need the following lemma of Moses and Tuttle <ref> [13, Lemma 11] </ref>. Lemma 1 (Moses and Tuttle): Let and 0 be runs differing only in the (faulty) behavior displayed by processor p after time k, and suppose that no more than f processors fail in either or 0 . <p> As noted above, our results can be extended to general nontrivial facts about the input and the existence of failures using standard techniques. 6 Conclusions The results of this paper extend those shown earlier by Moses and Tuttle <ref> [13] </ref>. They can also be applied to the consistent simultaneous choice problems of Neiger and Tuttle [17]; solutions to such problems require that faulty processors, if they act, do so consistently and simultaneous with the nonfaulty ones.
Reference: [14] <author> Gil Neiger and Rida Bazzi. </author> <title> Using knowledge to optimally achieve coordination in distributed systems. </title> <editor> In Yoram Moses, editor, </editor> <booktitle> Proceedings of the Fourth Conference on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pages 43-59. </pages> <address> MorganKaufmann, </address> <month> March </month> <year> 1992. </year>
Reference: [15] <author> Gil Neiger and Sam Toueg. </author> <title> Automatically increasing the fault-tolerance of dis-tributed algorithms. </title> <journal> Journal of Algorithms, </journal> <volume> 11(3) </volume> <pages> 374-419, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: The possibility of such an algorithm in the multiplicative case is suggested by studies of translations between models of failures [1,2,4,15,18]. For example, Moses and Tuttle showed the existence of optimal algorithms that tolerate crash failures. Neiger and Toueg <ref> [15] </ref> showed how algorithms tolerant of crash failures could be converted to tolerate general omission failures by doubling the number of rounds used; local computation time was increased only by a polynomial amount.
Reference: [16] <author> Gil Neiger and Sam Toueg. </author> <title> Simulating synchronized clocks and common knowledge in distributed systems. </title> <journal> Journal of the ACM, </journal> <volume> 40(2) </volume> <pages> 334-367, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Consider, for example, systems with crash failures. Moses and Tuttle showed that polynomial- time optimal solutions exist for such systems. Neiger and Toueg <ref> [16] </ref> showed how crash-tolerant algorithms could be converted to tolerate general omission failures by only doubling the number of rounds used and with only a polynomial increase in local computation.
Reference: [17] <author> Gil Neiger and Mark R. Tuttle. </author> <title> Common knowledge and consistent simultaneous coordination. </title> <journal> Distributed Computing, </journal> <volume> 6(3) </volume> <pages> 181-192, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: In particular, they proved that achieving optimal coordination in the presence of general omission failures requires processors to perform NP-hard local computation between rounds of communication. Neiger and Tuttle <ref> [17] </ref> subsequently showed related results considering stronger forms of coordination and of common knowledge. It is known that many NP-complete problems can be solved approximately in polynomial time [7]. Perhaps almost-optimal algorithms for simultaneous coordination might require only polynomial-time local computation (in systems with general omission failures). <p> Because this paper deals with coordination among the nonfaulty processors, we are specifically interested in the knowledge possessed by the set N of nonfaulty processors. Everyone in N knows ', denoted E', is defined as V p2N B p '. (Moses and Tuttle [13] and Neiger and Tuttle <ref> [17] </ref> explain why belief, and not knowledge, is appropriate for the problems considered here.) Fact ' is common knowledge, denoted C', if V A useful tool for reasoning about knowledge is the similarity graph. <p> They can also be applied to the consistent simultaneous choice problems of Neiger and Tuttle <ref> [17] </ref>; solutions to such problems require that faulty processors, if they act, do so consistently and simultaneous with the nonfaulty ones. They show that the earlier NP-hardness results, which applied to optimal solutions in systems with general omission failures, also hold for almost-optimal solutions.
Reference: [18] <author> T. K. Srikanth and Sam Toueg. </author> <title> Simulating authenticated broadcasts to derive simple fault-tolerant algorithms. </title> <journal> Distributed Computing, </journal> <volume> 2(2) </volume> <pages> 80-94, </pages> <year> 1987. </year>
References-found: 18

