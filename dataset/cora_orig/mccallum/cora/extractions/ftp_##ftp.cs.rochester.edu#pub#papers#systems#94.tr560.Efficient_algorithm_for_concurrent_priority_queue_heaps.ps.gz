URL: ftp://ftp.cs.rochester.edu/pub/papers/systems/94.tr560.Efficient_algorithm_for_concurrent_priority_queue_heaps.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/gchunt/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fgchunt,michael,srini,scottg@cs.rochester.edu  
Title: An Efficient Algorithm for Concurrent Priority Queue Heaps  
Author: Galen C. Hunt Maged M. Michael Srinivasan Parthasarathy Michael L. Scott 
Date: December 1994  
Address: Rochester, Rochester, NY 14627-0226  
Affiliation: Department of Computer Science, University of  
Abstract: We present a new algorithm for concurrent access to array-based priority queue heaps. Deletions proceed top-down as they do in a previous algorithm due to Rao and Kumar [6], but insertions proceed bottom-up, and consecutive insertions use a bit-reversal technique to scatter accesses across the fringe of the tree, to reduce contention. Because insertions do not have to traverse the entire height of the tree (as they do in previous work), as many as O(M ) operations can proceed in parallel, rather than O(log M ) on a heap of size M . Experimental results on a Silicon Graphics Challenge multiprocessor demonstrate good overall performance for the new algorithm on small heaps, and significant performance improvements over known alternatives on large heaps with mixed insertion/deletion workloads. fl This work was supported in part by NSF grants nos. CDA-8822724 and CCR-9319445, and by ONR research grant no. N00014-92-J-1801 (in conjunction with the DARPA Research in Information Science and Technology|High Performance Computing, Software Science and Technology program, ARPA Order no. 8930). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Biswas and J. C. Browne. </author> <title> Simultaneous Update of Priority Structures. </title> <booktitle> In Proceedings of the 1987 International Conference on Parallel Processing, </booktitle> <pages> pages 124-131, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: Since updates to the heap typically modify only a small fraction of the nodes, more concurrency should be achievable by allowing processes to access the heap concurrently as long as they do not interact with each other. Biswas and Browne <ref> [1] </ref> proposed a scheme that allows many insertions and deletions to pro ceed concurrently. Their scheme relies on the presence of maintenance processes that dequeue 2 sub-operations from a FIFO work queue. Sub-operations are placed on the work queue by the processes performing insert and delete operations. <p> The tags serve to allow (bottom-up) insertions and (top-down) deletions to proceed in opposite directions without the need for a work queue or extra service processes <ref> [1] </ref>. The tags in the new algorithm allow a process to efficiently identify the item it is moving up or down the heap even if the item has been swapped by another process. <p> 4 int concurrent_delete (int *priority, int *data, heap_t *heap) - LOCK (heap-&gt;lock); if (heap-&gt;size &lt; 1)- UNLOCK (heap-&gt;lock); return 0; - last = BIT_REVERSE (heap-&gt;size--); lastp = &heap-&gt;item [i]; LOCK (lastp-&gt;lock); UNLOCK (heap-&gt;lock); captive_pri = lastp-&gt;pri; captive_dat = lastp-&gt;dat; lastp-&gt;tag = EMPTY; UNLOCK (lastp-&gt;lock); i = 1; ip = &heap-&gt;item <ref> [1] </ref>; LOCK (ip-&gt;lock); if (ip-&gt;tag == EMPTY)- UNLOCK (ip-&gt;lock); *priority = captive_pri; *data = captive_dat; return 1; - *priority = ip-&gt;pri; *data = ip-&gt;dat; ip-&gt;pri = captive_pri; ip-&gt;dat = captive_dat; ip-&gt;tag = PRESENT; left = i&lt;<1; while (left &lt; MAX_SIZE)- right = left+1; lp = &heap-&gt;item [left]; rp = &heap-&gt;item [right]; <p> The new algorithm avoids deadlock among 9 concurrent accesses without forcing insertions to proceed top-down [6] or introducing a work queue and extra processes <ref> [1] </ref>. Bottom-up insertions reduce contention for the topmost nodes of the heap, and avoid the need for a full-height traversal in many cases. The new algorithm also uses bit-reversal to increase concurrency among consecutive insertions, allowing them to follow mostly-disjoint paths.
Reference: [2] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: 1 Introduction The heap data structure is widely used as a priority queue <ref> [2] </ref>. The basic operations on a priority queue are insert and delete. Insert inserts a new item in the queue and delete removes and returns the highest priority (lowest numbered) item from the queue. <p> Another advantage of the new algorithm is that unlike top-down insertions, bottom-up insertions do not necessarily have to traverse the whole height of the heap to complete the operation, thus reducing traversal overhead, and contention on topmost nodes. In some definitions of heaps <ref> [2] </ref>, all nodes in the last level of the heap to the left of the last item have to be non-empty. This is not required by priority queue semantics, or heap logarithmic complexity. In the new algorithm, we relax this restriction. <p> This is not required by priority queue semantics, or heap logarithmic complexity. In the new algorithm, we relax this restriction. Consecutive insertions traverse different sub-trees by using a bit reversal technique similar to that of an FFT computation <ref> [2] </ref>. For example, in the 3rd level of a heap (nodes 8-15, if the root is node 1), eight consecutive insertions would start from the nodes 8, 12, 10, 14, 9, 13, 11, and 15, respectively.
Reference: [3] <author> D. W. Jones. </author> <title> Concurrent Operations on Priority Queues. </title> <journal> Communications of the ACM, </journal> <volume> 32(1) </volume> <pages> 132-137, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: The need for a work queue and maintenance processes causes this scheme to incur substantial overhead. Rao and Kumar [6] present another scheme that avoids deadlock by using top-down insertions, where an inserted item has to traverse a path through the whole height of the heap. Jones <ref> [3] </ref> presents a concurrent priority queue algorithm using skew heaps. He notes that top-down insertions in array-based heaps are inefficient, while bottom-up insertions would cause deadlock if they collide with top-down deletions without using extra server processes.
Reference: [4] <author> J. Mohan. </author> <title> Experience with Two Parallel Programs Solving the Travelling Salesman Problem. </title> <booktitle> In Proceedings of the 1983 International Conference on Parallel Processing, </booktitle> <pages> pages 191-193, </pages> <year> 1983. </year>
Reference-contexts: No items exist in level l of the tree unless level l 1 is completely full. Many applications (e.g. heuristic search algorithms, graph search, and discrete event simula tion <ref> [4, 5] </ref>) on shared memory multiprocessors use shared priority queues to schedule sub-tasks. In these applications, items can be simultaneously inserted and deleted from the heap by any of the participating processes.
Reference: [5] <author> M. J. Quinn and N. Deo. </author> <title> Parallel Graph Algorithms. </title> <journal> ACM Computing Surveys, </journal> <volume> 16(3) </volume> <pages> 319-348, </pages> <month> September </month> <year> 1984. </year>
Reference-contexts: No items exist in level l of the tree unless level l 1 is completely full. Many applications (e.g. heuristic search algorithms, graph search, and discrete event simula tion <ref> [4, 5] </ref>) on shared memory multiprocessors use shared priority queues to schedule sub-tasks. In these applications, items can be simultaneously inserted and deleted from the heap by any of the participating processes.
Reference: [6] <author> V. N. Rao and V. Kumar. </author> <title> Concurrent Access of Priority Queues. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(12) </volume> <pages> 1657-1665, </pages> <month> December </month> <year> 1988. </year> <month> 10 </month>
Reference-contexts: The work queue is used to avoid deadlock due to insertions and deletions proceeding in opposite directions in the tree. The need for a work queue and maintenance processes causes this scheme to incur substantial overhead. Rao and Kumar <ref> [6] </ref> present another scheme that avoids deadlock by using top-down insertions, where an inserted item has to traverse a path through the whole height of the heap. Jones [3] presents a concurrent priority queue algorithm using skew heaps. <p> The new algorithm avoids deadlock among 9 concurrent accesses without forcing insertions to proceed top-down <ref> [6] </ref> or introducing a work queue and extra processes [1]. Bottom-up insertions reduce contention for the topmost nodes of the heap, and avoid the need for a full-height traversal in many cases. The new algorithm also uses bit-reversal to increase concurrency among consecutive insertions, allowing them to follow mostly-disjoint paths. <p> The new algorithm also uses bit-reversal to increase concurrency among consecutive insertions, allowing them to follow mostly-disjoint paths. We compared the performance of the new algorithm, the single-lock algorithm, and Rao and Kumar's top-down insertion algorithm <ref> [6] </ref> on a 12-node SGI Challenge multiprocessor. The results show that the new algorithm provides reasonable performance on small heaps, and significantly superior performance on large heaps under high levels of contention.
References-found: 6

