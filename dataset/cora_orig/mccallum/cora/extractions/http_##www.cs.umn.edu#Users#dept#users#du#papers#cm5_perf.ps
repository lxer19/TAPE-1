URL: http://www.cs.umn.edu/Users/dept/users/du/papers/cm5_perf.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/du/papers/
Root-URL: http://www.cs.umn.edu
Title: Performance Evaluation of the CM-5 Interconnection Network 2  
Author: Mengjou Lin, Rose Tsang and David H.C. Du Alan E. Klietz and Stephen Saroff 
Address: 200 Union Street SE Minneapolis, MN 55455  1200 Washington Avenue South Minneapolis, MN 55415  
Affiliation: Computer Science Department University of Minnesota  Minnesota Supercomputer Center  
Abstract: This paper presents performance characteristics of the CM-5 data network with respect to bandwidth and latency. We present the maximum effective network bandwidth as a function of (1) message size, (2) varying data path through different levels of the network hierarchy, and (3) system load. We also present latency as a function of message size and network hierarchy. In the second part of our evaluation, we present the maximum effective network bandwidth as a function of data flow pattern (2-d and 3-d mesh, stencils, ring, tree, and hypercube) using several variant embedding schemes. Measurements were obtained using CMMD V 1.3.1, Thinking Machine Corporation's message-passing library, and CMNF V 1.1, a fast message-passing library developed by the Minnesota Supercomputer Center (MSC) for the Army High Performance Research Center (AHPCRC). Using CMNF we were able to observe measurements which were very close to actual hardware capabilities. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S.G. Akl. </author> <title> The design and analysis of parallel algorithms. </title> <publisher> Prentice-Hall, </publisher> <year> 1989. </year>
Reference-contexts: Note that all these schemes are 1-1 mappings. We embedded 2-d and 3-d meshes <ref> [1, 2] </ref> with "end-around" cyclic connections using linear, interleaved and random embedding schemes. The linear embeddings corresponds to the layout the CM Fortan compiler uses for meshes (multi-dimensional arrays). Mea surements for each scheme are shown individually for each dimension of the mesh (see 15 Table 5 and 6). <p> Semi-linear Random 2 9.828 9.773 9.780 6.865 7.016 7.154 4 3.622 4.675 4.691 3.280 4.872 4.691 6 3.464 3.685 2.232 3.075 3.509 2.864 8 3.004 2.955 1.393 2.735 2.929 1.978 Table 8: Effective bandwidth per PN of different hypercube embeddings for CMMD V 1.3.1 (unit = MB/s) 18 A hypercube <ref> [1, 7] </ref> was embedded using linear, random and semi-linear schemes ( see Table 8). A semi-linear scheme (see Figure 9) involves swapping one processing node in each group of 4 nodes with another processing node in a neighboring group of 4 (PN3 $ Vertex4, PN4 $ Vertex3).
Reference: [2] <author> R.F. Van de Velde. </author> <title> Multicomputer matrix computations:theory and practice. </title> <booktitle> In Proceedings of the 1989 Conference on Hypercubes, Concurrent Computers and Applications, </booktitle> <pages> pages 1303-1308, </pages> <year> 1989. </year>
Reference-contexts: Note that all these schemes are 1-1 mappings. We embedded 2-d and 3-d meshes <ref> [1, 2] </ref> with "end-around" cyclic connections using linear, interleaved and random embedding schemes. The linear embeddings corresponds to the layout the CM Fortan compiler uses for meshes (multi-dimensional arrays). Mea surements for each scheme are shown individually for each dimension of the mesh (see 15 Table 5 and 6).
Reference: [3] <author> M. Flynn. </author> <title> Very high-speed computing systems. </title> <booktitle> In Proceedings IEEE, v.54, </booktitle> <pages> pages 1901-1909, </pages> <month> December </month> <year> 1966. </year>
Reference-contexts: The CM-5 extends TMC's existing Data Parallel programming model beyond the Single Instruction Multiple Data (SIMD) style, supported by the previous Connection Machines, CM-1, CM-2, and CM-200, to the Single Program Multiple Data (SPMD) <ref> [3] </ref> model. In the SPMD model, every processor executes different sections of the same program based on its processor address and state.
Reference: [4] <author> Charles E. Leiserson. Fat-trees: </author> <title> Universal networks for hardware-efficient supercomputing. </title> <booktitle> In ICPP, </booktitle> <pages> pages 393-402. </pages> <publisher> IEEE, </publisher> <year> 1985. </year>
Reference-contexts: We speak of NI's rather than just processing nodes because I/O devices and the PM can also be attached to the Data Network. A hypertree [14] is a variation of the fat-tree network <ref> [4] </ref>. A fat-tree network has the characteristic that as we go up the leaves of the tree the channel capacity increases. 5 plified representation. 6 This design accommodates the heavier loads usually found at the upper levels of a tree.
Reference: [5] <author> M.J. Quinn. </author> <title> Designing efficient algorithms for parallel computers. </title> <publisher> McGraw Hill, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: The infix embedding scheme was chosen to take advantage of the communication locality principle. The results in Table 7 reflect this i.e. the infix embedding scheme yields a flat effective bandwidth of approximately 7.3 MB/s (Cmd Type 3) for all tree sizes. A one-dimensional ring <ref> [5, 6] </ref>, or circular shift was simulated. For a linear embedding, we observed a flat effective bandwidth of 6.9 MB/s for rings composed of 4 to 512 nodes (Cmd Type 3). The linear embedding exploits the communication locality property of the CM-5 network.
Reference: [6] <author> I.V. Ramakrishnan and P.J. Varman. </author> <title> Modular matrix multiplication on a linear array. </title> <journal> In IEEE Transactions on Computers, </journal> <volume> Vol. C-33, No.11, </volume> <pages> pages 952-958, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: The infix embedding scheme was chosen to take advantage of the communication locality principle. The results in Table 7 reflect this i.e. the infix embedding scheme yields a flat effective bandwidth of approximately 7.3 MB/s (Cmd Type 3) for all tree sizes. A one-dimensional ring <ref> [5, 6] </ref>, or circular shift was simulated. For a linear embedding, we observed a flat effective bandwidth of 6.9 MB/s for rings composed of 4 to 512 nodes (Cmd Type 3). The linear embedding exploits the communication locality property of the CM-5 network.
Reference: [7] <author> S. Ranka and S. Sahni. </author> <title> Hypercube algorithms for image processing and pattern recognition. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: Semi-linear Random 2 9.828 9.773 9.780 6.865 7.016 7.154 4 3.622 4.675 4.691 3.280 4.872 4.691 6 3.464 3.685 2.232 3.075 3.509 2.864 8 3.004 2.955 1.393 2.735 2.929 1.978 Table 8: Effective bandwidth per PN of different hypercube embeddings for CMMD V 1.3.1 (unit = MB/s) 18 A hypercube <ref> [1, 7] </ref> was embedded using linear, random and semi-linear schemes ( see Table 8). A semi-linear scheme (see Figure 9) involves swapping one processing node in each group of 4 nodes with another processing node in a neighboring group of 4 (PN3 $ Vertex4, PN4 $ Vertex3).
Reference: [8] <author> SPARC International. </author> <title> The SPARC Architecture Manual, </title> <address> 8 edition, </address> <year> 1992. </year>
Reference-contexts: The node is designed around a standard 64-bit M-bus <ref> [8] </ref>. A SPARC processor, the CM-5 NI, a memory controller, and the standard DRAMS which make up the memory are attached to this node (see Figure 1). As noted earlier, computational performance will rely on the upcoming installation of 4 vector units. <p> Currently the caches are configured for write-through mode. Thus the effective network bandwidth will fall short of the 20 MB/s provided by the raw NI hardware <ref> [10, 8] </ref>. It is possible to directly access the NI interface. TMC provides a CM-5 component, CMNA [13], which allows a programmer to directly manipulate the low-level network hardware.
Reference: [9] <author> V.S. Sunderam. </author> <title> PVM : A framework for parallel distributed computing. </title> <journal> In Concur-rency : Practice and Experience, </journal> <pages> pages 315-339, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: We have begun our plans by developing CMNF as a base layer for the Parallel Virtual Machine (PVM). PVM is a software package which allows a network of computing elements to operate as a single computational resource. It is rapidly becoming a de facto standard for distributed scientific computing <ref> [9] </ref>. Our next step is to implement a model which will initially be limited to a nonhierarchical (flat) parallel model and synchronous message-passing. Then we plan to implement an arbitration scheme for access to shared resources, which would allow us 20 to support hierarchical parallelism.
Reference: [10] <institution> Thinking Machine Corp. </institution> <note> The Connection Machine CM-5 Technical Sumarry, Octo-ber 1991. </note>
Reference-contexts: results and a description of future work. 2 CM-5 Overview The Connection Machine model CM-5 consists of tens, hundreds or thousands of computational processing nodes, one or more control processors, and I/O units which interface to mass storage, graphic display devices, and VME and HIPPI (High Performance Parallel Interface) peripherals <ref> [10] </ref>. The system may be subdivided into disjoint, independent subsets of PN's. These subsets are called partitions, and are under the control of scalar control processors (CP's), which are referred to as partition managers (PM's). A processing node (PN) is the basic computational unit of the CM-5 (see Figure 1). <p> Messages are not guaranteed to arrive in order. Once the Data Network has accepted a message, it takes on responsibility for its eventual delivery. The sending processor can then perform other computations while the message is in transit <ref> [10] </ref>. Message recipients may poll for messages or be notified via interrupt. The Control Network is a low-latency network which distributes and coordinates control signals to/from the PNs. It supports cooperative operations, such as broadcast, reduction, some parallel-prefix operations, and synchronization primitives such as barrier synchronization. <p> Currently the caches are configured for write-through mode. Thus the effective network bandwidth will fall short of the 20 MB/s provided by the raw NI hardware <ref> [10, 8] </ref>. It is possible to directly access the NI interface. TMC provides a CM-5 component, CMNA [13], which allows a programmer to directly manipulate the low-level network hardware.
Reference: [11] <institution> Thinking Machine Corp. </institution> <note> The CMMD Reference Manual, 1.1 edition, </note> <month> January </month> <year> 1992. </year>
Reference-contexts: All nodes are assumed to participate in Control Network tasks unless they explicitly abstain (set an abstain flag). Nodes may change their abstain bits only when the network 9 is quiescent. 2.4 CMMD CMMD <ref> [11, 12] </ref> is the CM-5 message-passing library designed for node-level interprocessor communications. It supports the host/node programming model. In this model, the initiator program, or host code, runs on the partition manager (the front-end).
Reference: [12] <institution> Thinking Machine Corp. </institution> <note> The CMMD User Guide, 1.1 edition, </note> <month> January </month> <year> 1992. </year>
Reference-contexts: All nodes are assumed to participate in Control Network tasks unless they explicitly abstain (set an abstain flag). Nodes may change their abstain bits only when the network 9 is quiescent. 2.4 CMMD CMMD <ref> [11, 12] </ref> is the CM-5 message-passing library designed for node-level interprocessor communications. It supports the host/node programming model. In this model, the initiator program, or host code, runs on the partition manager (the front-end).
Reference: [13] <institution> Thinking Machine Corp. </institution> <note> Programming the NI, 7.1 edition, </note> <month> March </month> <year> 1992. </year>
Reference-contexts: Currently the caches are configured for write-through mode. Thus the effective network bandwidth will fall short of the 20 MB/s provided by the raw NI hardware [10, 8]. It is possible to directly access the NI interface. TMC provides a CM-5 component, CMNA <ref> [13] </ref>, which allows a programmer to directly manipulate the low-level network hardware. CMNF uses this low-level library but implements its message passing primitives using SPARC assembly language. 2.3 Control Network The Control Network is intended to support the SIMD model.
Reference: [14] <author> C. E. Leiserson. Z. S. Abuhamdeh. D. C. Douglas. C. R. Feynman. M. N. Ganmukhi. J. V. Hill. W. D. Hillis. B. C. Kuszmaul. M. A. St. Pierre. D. S. Wells. M. C. Wong. S Yang. R. Zak. </author> <title> The network architecture of the connection machine CM-5. </title> <booktitle> In Proceeding of Parallel Algorithms and Architectures Symposium 92', </booktitle> <month> June 29 - July 1 </month> <year> 1992. </year>
Reference-contexts: The NI's are located at the leaves of the hypertree and the Data Router (DR) chips are located at the internal nodes. We speak of NI's rather than just processing nodes because I/O devices and the PM can also be attached to the Data Network. A hypertree <ref> [14] </ref> is a variation of the fat-tree network [4]. A fat-tree network has the characteristic that as we go up the leaves of the tree the channel capacity increases. 5 plified representation. 6 This design accommodates the heavier loads usually found at the upper levels of a tree.
References-found: 14

