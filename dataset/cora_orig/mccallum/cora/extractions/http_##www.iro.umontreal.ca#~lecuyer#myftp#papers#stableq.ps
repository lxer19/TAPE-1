URL: http://www.iro.umontreal.ca/~lecuyer/myftp/papers/stableq.ps
Refering-URL: http://www.iro.umontreal.ca/~lecuyer/papers.html
Root-URL: http://www.iro.umontreal.ca
Title: Stochastic Stability of Queueing Networks  
Author: Qian-Yu Tang Pierre L'Ecuyer 
Keyword: STOCHASTIC LYAPUNOV FUNCTION CRITERIA, STOCHASTIC STABILITY, CLOSED AND OPEN QUEUEING NETWORKS, HARRIS RECURRENT MARKOV CHAINS  
Note: AMS 1991 SUBJECT CLASSIFICATION: PRIMARY 60k25, 60J27 This work was supported by NSERC-Canada grants ODGP0110050 and SMF0169893, and FCAR-Quebec grant 93ER1654  
Date: March 26, 1997  
Address: C.P.6128, Succ. Centre-Ville, Montreal, Quebec H3C 3J7, Canada  
Affiliation: Departement d'IRO, Universite de Montreal  
Abstract: This paper investigates geometric stability and L p -stability of discrete-time Markov chains associated with closed and open queueing networks with Markovian routing. By geometric stability (resp. L p -stability) we mean that the chain is regenerative in the Harris-recurrent sense and that the times between the successive regeneration points have a bounded moment generating function (resp. a bounded pth moment). We show that the closed queueing networks are geometrically stable (resp. L p -stable) if the service times have a bounded moment generation function (resp. a bounded pth moment), and that the open queueing networks are geometrically stable (resp. L p -stable) if the service times have a bounded moment generating function (resp. a bounded maxfp; 2g-th moment) and the interarrival times have a bounded second moment (resp. a bounded pth moment). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Asmussen, S. </author> <title> (1987) Applied Probability and Queues. </title> <publisher> John Wiley and Sons, </publisher> <address> New York. </address>
Reference-contexts: When these methods are applied to estimate the gradient of a steady-state average over an infinite horizon, the strong consistency of the resulting estimator is usually established under the assumption that the system is regenerative in a wide sense <ref> [1] </ref>, and that the times between the successive regeneration points have a bounded moment generating function or a bounded pth moment for a certain value of p 1 which depends on the context (see, e.g., [6] and [7]). <p> In this section, we quickly recall some basic definitions and facts. We refer the reader to <ref> [1, 15, 16, 18, 27] </ref> for more elaborate coverages. Let X = fX n ; n 0g be a Markov chain living on a state space S, a separable metric space with Borel oe-field B (S).
Reference: [2] <author> Borovkov, A.A. </author> <title> (1987) Limit theorems for queueing networks. </title> <journal> Theory Probab. Appl. </journal> <volume> 31, </volume> <pages> 413-427. </pages>
Reference-contexts: Borovkov <ref> [2] </ref> gives sufficient conditions for the geometric stability of a queueing network, but these conditions are more restrictive than ours, and his proof of stability for the open queueing network case assumes a priori that the long-run departure rate of customers from each node is equal to the arrival rate (see <p> Related results have been obtained by Borovkov <ref> [2] </ref>. <p> The condition (A5) in Theorem 3.4 appears stronger than necessary. This is because the stochastic Lyapunov function criterion in Proposition 2.4 for the L p -stability is only a sufficient condition. Borovkov <ref> [2] </ref> and Meyn and Down [14] used the following conditions (B1) and (B2), respectively, on the service times, instead of our condition (A2): (B1).
Reference: [3] <author> Chang, C.-S., Thomas., J. A., and Kiang S.-H. </author> <title> (1994) On the stability of open networks: A unified approach by stochastic dominance. </title> <booktitle> Queueing Systems 15, </booktitle> <pages> 239-260. </pages>
Reference-contexts: Proofs of L 1 -stability are also given in these papers for two-nodes closed and open queueing networks. The proof of [24] for the closed case can be generalized to networks with an arbitrary number of nodes. Chang, Thomas, and Kiang <ref> [3] </ref> and Meyn and Down [14] have analyzed the stability of the continuous-time queue length process associated with an open queueing network. They proved different forms of convergence for this process, under different sets of assumptions. Here, we study the embedded discrete-time chain instead.
Reference: [4] <author> Chong, E. K. P. and Ramadge, P. J. </author> <title> (1994) Stochastic optimization of regenerative systems using infinitesimal perturbation analysis. </title> <journal> IEEE Trans. Automat. Contr. </journal> <volume> 39, </volume> <pages> 1400-1410, </pages> <year> 1994. </year>
Reference-contexts: Similar assumptions are often made to prove the strong consistency and to derive the convergence rates of stochastic approximation algorithms based on those gradient estimators to optimize continuous system parameters; see, e.g., <ref> [4, 12, 13, 26] </ref>. In [4], for instance, the pth moment (p 6) of the regenerative cycle length is assumed to be finite. <p> Similar assumptions are often made to prove the strong consistency and to derive the convergence rates of stochastic approximation algorithms based on those gradient estimators to optimize continuous system parameters; see, e.g., [4, 12, 13, 26]. In <ref> [4] </ref>, for instance, the pth moment (p 6) of the regenerative cycle length is assumed to be finite.
Reference: [5] <author> Foss, S.G. </author> <title> (1989) Some properties of open queueing networks. </title> <journal> Problems Inform. </journal> <volume> Transmission 25, </volume> <pages> 241-246. </pages>
Reference: [6] <author> Glasserman, P. </author> <title> (1991) Gradient Estimation via Perturbation Analysis. </title> <publisher> Kluwer Academic Pub., </publisher> <address> Boston. </address> <month> 26 </month>
Reference-contexts: is usually established under the assumption that the system is regenerative in a wide sense [1], and that the times between the successive regeneration points have a bounded moment generating function or a bounded pth moment for a certain value of p 1 which depends on the context (see, e.g., <ref> [6] </ref> and [7]). Similar assumptions are often made to prove the strong consistency and to derive the convergence rates of stochastic approximation algorithms based on those gradient estimators to optimize continuous system parameters; see, e.g., [4, 12, 13, 26].
Reference: [7] <author> Glynn, P.W. and L'Ecuyer, P. </author> <title> (1995) Likelihood ratio gradient estimation for stochastic recur-sions. </title> <journal> Adv. Appl. Prob. </journal> <volume> 27, </volume> <pages> 1019-1053. </pages>
Reference-contexts: established under the assumption that the system is regenerative in a wide sense [1], and that the times between the successive regeneration points have a bounded moment generating function or a bounded pth moment for a certain value of p 1 which depends on the context (see, e.g., [6] and <ref> [7] </ref>). Similar assumptions are often made to prove the strong consistency and to derive the convergence rates of stochastic approximation algorithms based on those gradient estimators to optimize continuous system parameters; see, e.g., [4, 12, 13, 26].
Reference: [8] <author> Gut, A. </author> <title> (1988) Stopped Random Walks: Limit Theorems and Applications. </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference-contexts: Let oe (n) 1 = minfoe 1 ; ng. We distinguish between the two cases 1 p 2 and p &gt; 2. 1). Let 1 p 2. By the Burkholder inequality (see, e.g., <ref> [8] </ref> and [10]) and the C r inequality, there exists a constant c p such that for all x 2 A fl , E x 6 fi fi fi fi 1 X (jJ i j E [jJ i j jF i1 ]) fi fi fi p 3 5 c p E <p> By Theorem II.5.1 of Gut <ref> [8] </ref>, we know that f ((n)=n) r ; n 1g is uniformly integrable for any r &gt; 0, which implies the uniform integrability of f (1=n) P (n) i ; n 1g by Theorem I.6.1 of Gut [8]. <p> By Theorem II.5.1 of Gut <ref> [8] </ref>, we know that f ((n)=n) r ; n 1g is uniformly integrable for any r &gt; 0, which implies the uniform integrability of f (1=n) P (n) i ; n 1g by Theorem I.6.1 of Gut [8]. Since 1 u fl 1 (n) X u fl the uniform integrability of fu fl (n) =n; n 1g follows. Thus the second part of (C.2) holds. 22 2). We now prove that lim n!1 (1=n)E [W t R ff (n) ] = 0.
Reference: [9] <author> Heyde, </author> <title> C.C. (1964) Two probability theorems and their application to some first passage problem. </title> <journal> The J. of the Austral. Math. Soc. </journal> <volume> 4, </volume> <pages> 214-222. </pages>
Reference-contexts: and if the stability conditions on the interarrival times, service times, or routing probabilities hold uniformly in , then the stability results also hold uniformly in , which is what we typically need in the context of stochastic optimization. 1 The earlier work on this topic goes back to Heyde <ref> [9] </ref>, who gave necessary and sufficient conditions for the geometric stability of a single queue. <p> We conclude that (A2) is weaker than (B1) or (B2) by providing a counterexample, in Appendix E, which satisfies (A2) but violates (B1) and (B2). Condition (A2) is reasonable for the geometric stability of queueing networks, since Heyde <ref> [9] </ref> has shown that it is a necessary and sufficient condition on the service times in the case of a GI=GI=1 queue. 4 Proofs of Stochastic Stability for Closed Queueing Networks In this section we prove Theorems 3.1 and 3.2.
Reference: [10] <author> Hall, P. and Heyde, </author> <title> C.C. (1980) Martingale Limit Theory and Its Application. </title> <publisher> Acad. Press, </publisher> <address> New York. </address>
Reference-contexts: Let oe (n) 1 = minfoe 1 ; ng. We distinguish between the two cases 1 p 2 and p &gt; 2. 1). Let 1 p 2. By the Burkholder inequality (see, e.g., [8] and <ref> [10] </ref>) and the C r inequality, there exists a constant c p such that for all x 2 A fl , E x 6 fi fi fi fi 1 X (jJ i j E [jJ i j jF i1 ]) fi fi fi p 3 5 c p E x 6
Reference: [11] <author> Kalashnikov, V.V. </author> <title> (1994) Mathematical Methods in Queueing Theory. </title> <publisher> Kluwer Acad. Pub., </publisher> <address> Boston. </address>
Reference-contexts: The following three stochastic Lyapunov function criteria are often easier to verify. The first two are proved, for example, in <ref> [11] </ref>, [16], and [18]. They are usually stated with m = 1, but it is easily seen that the positive recurrence of the m-skeleton chain fX nm ; n 0g implies the positive recurrence of X , and similarly for geometric or L p -stability. <p> V : S ! [0; 1), a fixed integer m 1, and two constants fi 2 (0; 1) and b &gt; 0 such that E x [V (X m )] fiV (x) b; 8 x 62 A fl ; (2.8) x2A fl The next proposition follows from Theorem 5.2.2 of <ref> [11] </ref>, p.116.
Reference: [12] <author> L'Ecuyer, P. and Glynn, P. W. </author> <title> (1994) Stochastic optimization by simulation: convergence proofs for the GI/G/1 queue in steady-state. </title> <journal> Management Sci. </journal> <volume> 40, </volume> <pages> 1562-1578. </pages>
Reference-contexts: Similar assumptions are often made to prove the strong consistency and to derive the convergence rates of stochastic approximation algorithms based on those gradient estimators to optimize continuous system parameters; see, e.g., <ref> [4, 12, 13, 26] </ref>. In [4], for instance, the pth moment (p 6) of the regenerative cycle length is assumed to be finite.
Reference: [13] <author> L'Ecuyer, P. and Yin, G. </author> <title> (1995) Budget-dependent convergence rate of stochastic approximation. </title> <note> to appear in SIAM J. on Optim.. </note>
Reference-contexts: Similar assumptions are often made to prove the strong consistency and to derive the convergence rates of stochastic approximation algorithms based on those gradient estimators to optimize continuous system parameters; see, e.g., <ref> [4, 12, 13, 26] </ref>. In [4], for instance, the pth moment (p 6) of the regenerative cycle length is assumed to be finite.
Reference: [14] <author> Meyn, S.P. and Down, D. </author> <title> (1994) Stability of generalized Jackson networks. </title> <journal> The Ann. Appl. Probab. </journal> <volume> 4, </volume> <pages> 124-148. </pages>
Reference-contexts: In other words, as noted by Meyn and Down <ref> [14, p.143] </ref>, some form of stability has already been assumed before establishing the geometric stability results. We do not make such an a priori assumption. Our proof relies on the representation of the queueing networks as Harris-recurrent Markov chains. <p> Proofs of L 1 -stability are also given in these papers for two-nodes closed and open queueing networks. The proof of [24] for the closed case can be generalized to networks with an arbitrary number of nodes. Chang, Thomas, and Kiang [3] and Meyn and Down <ref> [14] </ref> have analyzed the stability of the continuous-time queue length process associated with an open queueing network. They proved different forms of convergence for this process, under different sets of assumptions. Here, we study the embedded discrete-time chain instead. <p> The condition (A5) in Theorem 3.4 appears stronger than necessary. This is because the stochastic Lyapunov function criterion in Proposition 2.4 for the L p -stability is only a sufficient condition. Borovkov [2] and Meyn and Down <ref> [14] </ref> used the following conditions (B1) and (B2), respectively, on the service times, instead of our condition (A2): (B1). <p> B 0 E i=2 fi fi fi # " c X T 0; t m (i)I [A c fi fi fi # 0 ]jB 0 ] + i=2 " c X T 0; t m (i)I [A 0 ] fi fi B 0 : (5.12) As in Meyn and Down <ref> [14] </ref>, we introduce a slow system with (c1) nodes, labeled 2, 3, ..., c. Customers arrive at rate r i from outside to node i. <p> Then it is easy to verify that there is a constant L fl 0 &gt; 0 such that E slow 0; t m (i) 2 m ae i L fl m ae i + L fl It is shown in Meyn and Down <ref> [14] </ref> that T 0; t (i) T slow 0; t (i) a.s. for t 0 if node 1 never empties. We now continue (5.12) as follows.
Reference: [15] <author> Meyn, S.P. and Tweedie, </author> <title> R.L. (1992) Stability of Markovian processes I: Criteria for discrete-time chains. </title> <journal> Adv. Appl. Prob. </journal> <volume> 24, </volume> <pages> 542-574. </pages>
Reference-contexts: In this section, we quickly recall some basic definitions and facts. We refer the reader to <ref> [1, 15, 16, 18, 27] </ref> for more elaborate coverages. Let X = fX n ; n 0g be a Markov chain living on a state space S, a separable metric space with Borel oe-field B (S).
Reference: [16] <author> Meyn, S.P. and Tweedie, </author> <title> R.L. (1993) Markov Chains and Stochastic Stability. </title> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference-contexts: Geometric ergodicity of Harris chains is well-covered, e.g., in <ref> [16] </ref> and [18]. A closed or open queueing network can be represented as a Markov process with an embedded discrete-time chain X = fX n ; n 0g, and conditions for this chain to be Harris-recurrent have been given in the literature. <p> In this section, we quickly recall some basic definitions and facts. We refer the reader to <ref> [1, 15, 16, 18, 27] </ref> for more elaborate coverages. Let X = fX n ; n 0g be a Markov chain living on a state space S, a separable metric space with Borel oe-field B (S). <p> to sup E x [exp (so fl )] &lt; 1; 8 u 2 [0; u fl for some small set A fl and constant u fl 1 &gt; 0, where X satisfying (2.4) is called geometrically recurrent in [18] and A fl satisfying (2.4) is called a Kendall set in <ref> [16] </ref>. Geometric ergodicity is a very strong form of stability. It implies that the distribution of X n converges to an invariant measure at a geometric rate, as n ! 1. See, e.g., [16, 18, 19] for other equivalent definitions and an extensive analysis of geometric ergodicity. <p> Geometric ergodicity is a very strong form of stability. It implies that the distribution of X n converges to an invariant measure at a geometric rate, as n ! 1. See, e.g., <ref> [16, 18, 19] </ref> for other equivalent definitions and an extensive analysis of geometric ergodicity. For the L p -stability, we have the following equivalent condition; see [20] for the proof. Proposition 2.1 Let p 1 be fixed. <p> The following three stochastic Lyapunov function criteria are often easier to verify. The first two are proved, for example, in [11], <ref> [16] </ref>, and [18]. They are usually stated with m = 1, but it is easily seen that the positive recurrence of the m-skeleton chain fX nm ; n 0g implies the positive recurrence of X , and similarly for geometric or L p -stability.
Reference: [17] <author> Nummelin, E. </author> <title> (1981) Regeneration in tandem queues. </title> <journal> Adv. Appl. Prob. </journal> <volume> 13, </volume> <pages> 221-230. </pages>
Reference-contexts: We do not make such an a priori assumption. Our proof relies on the representation of the queueing networks as Harris-recurrent Markov chains. This approach was pioneered by Nummelin <ref> [17] </ref>, who found explicit regeneration points for tandem queues, and was pursued in [22, 23, 24, 25]. Explicit regeneration points are provided in [24] for the closed queueing network and in [25] for the open one.
Reference: [18] <author> Nummelin, E. </author> <title> (1984) General Irreducible Markov Chains and Non-negative Operators. </title> <publisher> Cambridge Univ. Press, </publisher> <address> New York. </address>
Reference-contexts: Geometric ergodicity of Harris chains is well-covered, e.g., in [16] and <ref> [18] </ref>. A closed or open queueing network can be represented as a Markov process with an embedded discrete-time chain X = fX n ; n 0g, and conditions for this chain to be Harris-recurrent have been given in the literature. <p> In this section, we quickly recall some basic definitions and facts. We refer the reader to <ref> [1, 15, 16, 18, 27] </ref> for more elaborate coverages. Let X = fX n ; n 0g be a Markov chain living on a state space S, a separable metric space with Borel oe-field B (S). <p> (S) with (A fl ) &gt; 0, P x fX n 2 A fl i.o. g = 1 for all x 2 S; (2.1) P x fX m fl 2 g ffi fl () for all x 2 A fl ; (2.2) where A fl is called a small set <ref> [18] </ref>. From (2.1) and (2.2) it is seen that the set A fl is visited i.o. and that whenever such a visit occurs, the state of the chain m fl steps later is distributed according to with probability at least ffi fl . <p> We note that geometric stability of a HRMC is equivalent to sup E x [exp (so fl )] &lt; 1; 8 u 2 [0; u fl for some small set A fl and constant u fl 1 &gt; 0, where X satisfying (2.4) is called geometrically recurrent in <ref> [18] </ref> and A fl satisfying (2.4) is called a Kendall set in [16]. Geometric ergodicity is a very strong form of stability. It implies that the distribution of X n converges to an invariant measure at a geometric rate, as n ! 1. <p> Geometric ergodicity is a very strong form of stability. It implies that the distribution of X n converges to an invariant measure at a geometric rate, as n ! 1. See, e.g., <ref> [16, 18, 19] </ref> for other equivalent definitions and an extensive analysis of geometric ergodicity. For the L p -stability, we have the following equivalent condition; see [20] for the proof. Proposition 2.1 Let p 1 be fixed. <p> The following three stochastic Lyapunov function criteria are often easier to verify. The first two are proved, for example, in [11], [16], and <ref> [18] </ref>. They are usually stated with m = 1, but it is easily seen that the positive recurrence of the m-skeleton chain fX nm ; n 0g implies the positive recurrence of X , and similarly for geometric or L p -stability.
Reference: [19] <author> Nummelin, E. and Tuominen, </author> <title> P.(1982) Geometric ergodicity of Harris recurrent Markov chains with applications to renewal theory. </title> <booktitle> Stochastic Processes and their Applications 12, </booktitle> <pages> 187-202. </pages>
Reference-contexts: Geometric ergodicity is a very strong form of stability. It implies that the distribution of X n converges to an invariant measure at a geometric rate, as n ! 1. See, e.g., <ref> [16, 18, 19] </ref> for other equivalent definitions and an extensive analysis of geometric ergodicity. For the L p -stability, we have the following equivalent condition; see [20] for the proof. Proposition 2.1 Let p 1 be fixed.
Reference: [20] <author> Nummelin, E. and Tuominen, </author> <title> P.(1983) The rate of convergence in Orey's theorem for Harris recurrent Markov chains with applications to renewal theory. </title> <booktitle> Stochastic Processes and their Applications 15, </booktitle> <pages> 295-311. </pages>
Reference-contexts: It implies that the distribution of X n converges to an invariant measure at a geometric rate, as n ! 1. See, e.g., [16, 18, 19] for other equivalent definitions and an extensive analysis of geometric ergodicity. For the L p -stability, we have the following equivalent condition; see <ref> [20] </ref> for the proof. Proposition 2.1 Let p 1 be fixed.
Reference: [21] <author> Shanthikumar, J.G. and Yao, </author> <title> D.D. (1989) Stochastic monotonicity in general queueing networks. </title> <journal> J. Appl. Prob. </journal> <volume> 26, </volume> <pages> 413-417. </pages>
Reference: [22] <author> Sigman, K. </author> <title> (1988a) Regeneration in tandem queues with multi-server stations. </title> <journal> J. Appl. Probab. </journal> <volume> 25, </volume> <pages> 391-403. </pages>
Reference-contexts: We do not make such an a priori assumption. Our proof relies on the representation of the queueing networks as Harris-recurrent Markov chains. This approach was pioneered by Nummelin [17], who found explicit regeneration points for tandem queues, and was pursued in <ref> [22, 23, 24, 25] </ref>. Explicit regeneration points are provided in [24] for the closed queueing network and in [25] for the open one. Proofs of L 1 -stability are also given in these papers for two-nodes closed and open queueing networks.
Reference: [23] <author> Sigman, K. </author> <title> (1988b) Queues as Harris recurrent Markov chains. </title> <booktitle> Queueing Systems 3, </booktitle> <pages> 179-198. </pages>
Reference-contexts: We do not make such an a priori assumption. Our proof relies on the representation of the queueing networks as Harris-recurrent Markov chains. This approach was pioneered by Nummelin [17], who found explicit regeneration points for tandem queues, and was pursued in <ref> [22, 23, 24, 25] </ref>. Explicit regeneration points are provided in [24] for the closed queueing network and in [25] for the open one. Proofs of L 1 -stability are also given in these papers for two-nodes closed and open queueing networks.
Reference: [24] <author> Sigman, K. </author> <title> (1989) Notes on the stability of closed queueing networks. </title> <journal> J. Appl. Probab. </journal> <volume> 26, </volume> <pages> 678-682; Corrections. </pages> <note> J. Appl. Probab. 27, 735. </note>
Reference-contexts: We do not make such an a priori assumption. Our proof relies on the representation of the queueing networks as Harris-recurrent Markov chains. This approach was pioneered by Nummelin [17], who found explicit regeneration points for tandem queues, and was pursued in <ref> [22, 23, 24, 25] </ref>. Explicit regeneration points are provided in [24] for the closed queueing network and in [25] for the open one. Proofs of L 1 -stability are also given in these papers for two-nodes closed and open queueing networks. <p> Our proof relies on the representation of the queueing networks as Harris-recurrent Markov chains. This approach was pioneered by Nummelin [17], who found explicit regeneration points for tandem queues, and was pursued in [22, 23, 24, 25]. Explicit regeneration points are provided in <ref> [24] </ref> for the closed queueing network and in [25] for the open one. Proofs of L 1 -stability are also given in these papers for two-nodes closed and open queueing networks. The proof of [24] for the closed case can be generalized to networks with an arbitrary number of nodes. <p> Explicit regeneration points are provided in <ref> [24] </ref> for the closed queueing network and in [25] for the open one. Proofs of L 1 -stability are also given in these papers for two-nodes closed and open queueing networks. The proof of [24] for the closed case can be generalized to networks with an arbitrary number of nodes. Chang, Thomas, and Kiang [3] and Meyn and Down [14] have analyzed the stability of the continuous-time queue length process associated with an open queueing network. <p> y 1 ; : : : ; y c ) : 0 q i N and 0 y i &lt; 1 for each i, and q 1 + + q c = N g: We introduce the following condition, which is restrictive but similar to that of Theorem 1 in <ref> [24] </ref>. Assumption (A1) There is a node i 0 such that for all nodes i, ii 0 &gt; 0. Without loss of generality, suppose that i 0 = 1. <p> (q 1 ; : : : ; q c ; y 1 ; : : : ; y c ) 2 S : y i b 0 for all ig: (3.2) Under the assumption that ij &gt; 0 for all i; j, and that the service times have finite expectations, <ref> [24] </ref> shows that there are three positive constants b 0 , m fl , and ffi fl such that whenever X n 2 B (b 0 ), the probability that X will regenerate during the next m fl steps is at least ffi fl .
Reference: [25] <author> Sigman, K. </author> <title> (1990) The stability of open queueing networks. </title> <journal> Stoch. Processes and their Appls. </journal> <volume> 35, </volume> <pages> 11-25. </pages>
Reference-contexts: We do not make such an a priori assumption. Our proof relies on the representation of the queueing networks as Harris-recurrent Markov chains. This approach was pioneered by Nummelin [17], who found explicit regeneration points for tandem queues, and was pursued in <ref> [22, 23, 24, 25] </ref>. Explicit regeneration points are provided in [24] for the closed queueing network and in [25] for the open one. Proofs of L 1 -stability are also given in these papers for two-nodes closed and open queueing networks. <p> This approach was pioneered by Nummelin [17], who found explicit regeneration points for tandem queues, and was pursued in [22, 23, 24, 25]. Explicit regeneration points are provided in [24] for the closed queueing network and in <ref> [25] </ref> for the open one. Proofs of L 1 -stability are also given in these papers for two-nodes closed and open queueing networks. The proof of [24] for the closed case can be generalized to networks with an arbitrary number of nodes. <p> define the bounded rectangle B (k 0 ; b 0 ) = f (q 1 ; : : : ; q c ; y 1 ; : : : ; y c ) 2 S : q i k 0 and y i b 0 for all ig: (3.3) Sigman <ref> [25] </ref> has shown that if the service times at all nodes have finite expectation, then the Markov chain fX n g is Harris-recurrent and there exist positive constants k 0 , b 0 , m fl , and ffi fl such that whenever X n 2 B (k 0 ; b
Reference: [26] <author> Tang, Q. Y. and Chen, H. F. </author> <title> (1994) Convergence of perturbation analysis based optimization algorithm with fixed number of customers period. Discrete Event Dynamic Systems: </title> <journal> Theory and Appl. </journal> <volume> 4, </volume> <pages> 359-375. </pages>
Reference-contexts: Similar assumptions are often made to prove the strong consistency and to derive the convergence rates of stochastic approximation algorithms based on those gradient estimators to optimize continuous system parameters; see, e.g., <ref> [4, 12, 13, 26] </ref>. In [4], for instance, the pth moment (p 6) of the regenerative cycle length is assumed to be finite.
Reference: [27] <author> Tweedie, </author> <title> R.L. (1976) Criteria for classifying general Markov chains. </title> <journal> Adv. Appl. Prob. </journal> <volume> 8, </volume> <pages> 737-771. 27 </pages>
Reference-contexts: In this section, we quickly recall some basic definitions and facts. We refer the reader to <ref> [1, 15, 16, 18, 27] </ref> for more elaborate coverages. Let X = fX n ; n 0g be a Markov chain living on a state space S, a separable metric space with Borel oe-field B (S).
References-found: 27

