URL: http://www.caip.rutgers.edu/~yuk/papers/icslp96.ps
Refering-URL: 
Root-URL: 
Email: email: qlin@watson.ibm.com, cche@caip.rutgers.edu  
Title: SELECTIVE USE OF THE SPEECH SPECTRUM AND A VQ-GMM METHOD FOR SPEAKER ID  
Author: Qiguang Lin Ea-Ee Jan ChiWei Che, Dong-Suk Yuk, and James Flanagan 
Address: Yorktown Heights, NY 10598, USA  Campus, NJ 08855, USA  
Affiliation: IBM Watson Research Center,  CAIP Center, Rutgers University, Busch  
Abstract: This paper describes two separate sets of speaker identification experiments. In the first set of experiments, the speech spectrum is selectively used for speaker identification. The results show that the higher portion of the speech spectrum contains more reliable idiosyncratic information on speakers than does the lower portion of equal bandwidth. In the second set of experiments, a vector-quantization based Gaussian mixture models (VQGMMs) is developed for text-independent speaker identification. The system has been evaluated in the recent speaker identification evaluation organized by NIST. In this paper, details of the system design are given and the evaluation results are presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Reynolds, D. </author> <title> "A Gaussian mixture modeling approach to text-independent speaker identification," </title> <type> Technical Report 967, </type> <institution> Lincoln Laboratory, MIT, </institution> <year> 1993. </year>
Reference-contexts: In the second part of the present paper, recent efforts to improve Gaussian mixture modeling (GMM) techniques are described. GMM techniques have been commonly adopted for text-independent speaker recognition and good performance has been reported (see e.g., <ref> [1] </ref>). Conventional GMMs generate a Gaussian mixture model for each enrolled speaker. The model statistics is estimated using acoustic features covering the entire acoustic space. We argue that the statistics can be better estimated by first clustering (vector-quantizing) the acoustic space into sev eral subspaces.
Reference: [2] <author> Martin, A., Przybocki, M., Fiscus, J., and Pallet D., </author> <title> "Evaluation on SWITCHBOARD corpus selected segments," Notebook of 1996 NIST Speaker Recognition Workshop, </title> <address> Maryland, </address> <year> 1996. </year>
Reference-contexts: We refer the new system to as vector-quantization based Gaussian mixture models (VQGMMs). Our experiments show that VQGMMs work better than conventional GMMs. The system has recently been used in 1996 NIST Speaker Identification Evaluation. From the official evaluation results <ref> [2] </ref>, the system generally produces top scores among all the partici-pating sites. For some test subsets (short utterances), the VQGMM system yields the best scores. Details of the VQGMM system design and evaluation results are presented in the paper. 2. <p> The speech data were collected using different handsets and unknown telephone transmission networks. Detailed specification of the evaluation can be found in <ref> [2] </ref>. 9 sites from USA and other countries participated in the evaluation. The Rutgers University team used the above described VQGMM in the evaluation [8]. The system employed 19 mel-frequency cepstral coefficients (MFCCs) as the measured feature (that is, no delta or detal delta MFCCs). <p> In the speaker identification evaluation, all systems are evaluated based on a detection cost function (DCF) defined by the evaluation organizor. From the official result report <ref> [2] </ref>, the Rutgers VQGMM system produced top scores. For some test subsets, especially the 3-sec set, the VQGMM system gave the best performance.
Reference: [3] <author> Kohonen, T. et al, </author> <title> "LVQ PAK: A program package for the correct application of Learning Vector Quantization algorithms", </title> <booktitle> Proc. Intern. Joint Conf. NN, </booktitle> <year> 1992, </year> <pages> pp. 1725-1730. </pages>
Reference-contexts: The TIMIT database covers a frequency range up to 8 kHz and hence enables us to fully study various portions of the speech spectrum. In the subset, there are 38 speakers (24 males and 14 females). For each of the speakers, a Learning Vector-Quantization (LVQ <ref> [3] </ref>) codebook is generated using 5 training sentences for each of the speakers. During testing, the minimum L2 norm distance between the testing feature vectors and centroids of the codebook is accumulated. The person whose code-book produces the least L2 distance is considered as the identification result (closed-set, text-independent experiments).
Reference: [4] <author> Soong, F., Rosenberg, A., Rabiner, L., and Juang B.-H., </author> <title> "A vector quantization approach to speaker recognition," </title> <booktitle> ICASSP 1985, </booktitle> <pages> pp. 387-390. </pages>
Reference-contexts: The person whose code-book produces the least L2 distance is considered as the identification result (closed-set, text-independent experiments). For more details on VQ-approaches to speaker identification, the reader is referred to <ref> [4, 5] </ref>. There are different ways to select a portion of the speech spectrum. In our implementation, the selection is conducted in the frequency domain after FFT computation. Figure 1 illustrates the selection process.
Reference: [5] <author> Lin, Q., Jan, E., and Flanagan, J., </author> <title> "Microphone arrays and speaker identification," </title> <booktitle> IEEE-Trans Speech & Audio Processing, </booktitle> <year> 1994, </year> <pages> pp. 622-629. </pages>
Reference-contexts: The person whose code-book produces the least L2 distance is considered as the identification result (closed-set, text-independent experiments). For more details on VQ-approaches to speaker identification, the reader is referred to <ref> [4, 5] </ref>. There are different ways to select a portion of the speech spectrum. In our implementation, the selection is conducted in the frequency domain after FFT computation. Figure 1 illustrates the selection process.
Reference: [6] <author> Lin, Q., Jan, E., and Flanagan, J. </author> <title> "Speaker recognition using selective spectrum information," </title> <institution> Rutgers Invention Disclosure Docket #94-0309-1, </institution> <month> December </month> <year> 1993. </year>
Reference: [7] <author> Hayakawa, S. and Itakura F., </author> <title> "The influence of noise on the speaker recognition performance using the higher frequency band," </title> <booktitle> ICASSP 1985, </booktitle> <pages> pp. 321-324. </pages>
Reference-contexts: However, when the interval of F h F l (refer to Figure 1) is narrowed to 3.3 kHz, the approach may be used for telephone speech with modulation techniques. Incidentally, we recently came across a paper <ref> [7] </ref> where it was found that better speaker identification performance could be achieved when increasing the frequency range of the spectrum.
Reference: [8] <author> Che, C, Yuk, D.-S., Flanagan J., and Lin, Q.' </author> <title> "Development of the 1996 RU Speaker Recognition System," Notebook of 1996 NIST Speaker Recognition Workshop, </title> <address> Maryland, </address> <year> 1996. </year>
Reference-contexts: The speech data were collected using different handsets and unknown telephone transmission networks. Detailed specification of the evaluation can be found in [2]. 9 sites from USA and other countries participated in the evaluation. The Rutgers University team used the above described VQGMM in the evaluation <ref> [8] </ref>. The system employed 19 mel-frequency cepstral coefficients (MFCCs) as the measured feature (that is, no delta or detal delta MFCCs). First, the VQGMM is compared with GMM using the male portion of the Devset for different numbers of mixtures.
Reference: [9] <author> Che, C. and Lin, Q., </author> <title> "Speaker recognition using HMM with experiments on the YOHO database," </title> <booktitle> Proc. 4th Eurospeech, </booktitle> <address> Spain, </address> <year> 1995, </year> <pages> pp. 625-628. </pages>
Reference-contexts: It is found that the third approach works best. In on-line determined, can be studied. It is noted that least error rates are obtained when N is between 5 and 10. This result conforms with our previous speaker verification experiments on the YOHO database <ref> [9] </ref>. Error rate in % 4.00 6.00 X X X Number of background speakers 0 10 20 30 40 50 60 on speaker recognition performance. In the speaker identification evaluation, all systems are evaluated based on a detection cost function (DCF) defined by the evaluation organizor.
References-found: 9

