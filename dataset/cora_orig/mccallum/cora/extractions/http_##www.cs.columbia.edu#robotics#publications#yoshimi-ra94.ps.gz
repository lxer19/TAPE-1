URL: http://www.cs.columbia.edu/robotics/publications/yoshimi-ra94.ps.gz
Refering-URL: http://www.cs.columbia.edu/robotics/publications/publications.html
Root-URL: http://www.cs.columbia.edu
Title: ACTIVE, UNCALIBRATED VISUAL SERVOING  
Author: Billibon H. Yoshimi and Peter K. Allen 
Address: New York, NY 10027  
Affiliation: Center for Research in Intelligent Systems Columbia University  
Abstract: We propose a method for visual control of a robotic system which does not require the formulation of an explicit calibration between image space and the world coordinate system. Calibration is known to be a difficult and error prone process. By extracting control information directly from the image, we free our technique from the errors normally associated with a fixed calibration. We demonstrate this by performing a peg-in-hole alignment using an uncalibrated camera to control the positioning of the peg. The algorithm utilizes feedback from a simple geometric effect, rotational invariance, to control the positioning servo loop. The method uses an approximation to the Image Jacobian to provide smooth, near-continuous control. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Blake and A. Yuille, </author> <title> editors. Active Vision. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Due to space constraints, we are unable to document the full gamut of literature pertaining to visual servoing; for a representative overview of the field, see Blake and Yuille <ref> [1] </ref>. 2 OVERVIEW OF METHOD Research in peg-in-hole servoing tasks is rich and varied.
Reference: [2] <author> A. Castano and S. Hutchinson. </author> <title> Visual compliance: Task-directed visual servo control. </title> <type> Technical Report UIUC-BI-AI-RCV-93-01, </type> <institution> The Beckman Inst.: University of Illinois, </institution> <year> 1993. </year>
Reference: [3] <author> F. Chaumette, P. Rives, and B. Espiau. </author> <title> Classification and realization of the different vision-based tasks. </title> <editor> In K. Hashimoto, editor, </editor> <booktitle> Visual Servoing, </booktitle> <pages> pages 199-228. </pages> <publisher> World Scientific, </publisher> <year> 1994. </year>
Reference: [4] <author> J. Feddema, C. S. G. Lee, and O. Mitchell. </author> <title> Weighted selection of image features for resolved rate visual feedback control. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 7(1) </volume> <pages> 31-47, </pages> <month> Feb. </month> <year> 1991. </year>
Reference: [5] <author> K. Hashimoto, T. Kimoto, T. Ebine, and H. Kimura. </author> <title> Manipulator control with image-based visual servo. </title> <booktitle> In Proceedings of the IEEE Conference on Robotics and Automation, </booktitle> <pages> pages 2267-2271, </pages> <year> 1991. </year>
Reference: [6] <author> A. Koivo and N. Houshangi. </author> <title> Real-time vision feedback for servoing robotic manipulator with self-tuning controller. </title> <journal> IEEE Transactions on System, Man, and Cybernetics, </journal> <volume> 21, No. 1 </volume> <pages> 134-142, </pages> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: These methods track feature points and effect servoing movements using an Image Jacobian which relates Cartesian movements with positional errors derived from the tracked features. Other methods include the work of Papanikopolous et al. [9], Koivo et al. <ref> [6] </ref> and Miller [12]. The basic idea behind the Image Jacobian is to model the differential relationship between the camera system and the robotic control system in order to accurately predict the effects of small changes in one system on the other. It is a linear, position-dependent (i.e. non-constant) transform.
Reference: [7] <author> T. Lozano-Perez, M. Mason, and R. Taylor. </author> <title> Automatic synthesis of fine-motion strategies for robots. </title> <journal> Int'l Journal of Robotics Research, </journal> <volume> 3(1) </volume> <pages> 3-24, </pages> <year> 1984. </year>
Reference: [8] <author> S. Nevins and D. Whitney. </author> <title> Computer-controlled assembly. </title> <journal> Scientific American, </journal> <volume> 238 </volume> <pages> 62-74, </pages> <month> February </month> <year> 1978. </year>
Reference-contexts: Some of the classical techniques include the work of Nevins and Whitney <ref> [8] </ref> in Remote-Center-Compliance (RCC) and the work of Lozano-P erez et al.[7] with back-projections. 1 These works try to solve the peg-in-hole problem primarily as a navigation problem (first, determining if a route exists from the peg to the hole, and second, determining what is the best path from the peg
Reference: [9] <author> N. Papanikolopoulos, P. Khosla, and T. Kanade. </author> <title> Vision and control techniques for robotic visual tracking. </title> <booktitle> In IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 1, </volume> <pages> pages 857-864, </pages> <month> April 7-12 </month> <year> 1991. </year>
Reference-contexts: These methods track feature points and effect servoing movements using an Image Jacobian which relates Cartesian movements with positional errors derived from the tracked features. Other methods include the work of Papanikopolous et al. <ref> [9] </ref>, Koivo et al. [6] and Miller [12]. The basic idea behind the Image Jacobian is to model the differential relationship between the camera system and the robotic control system in order to accurately predict the effects of small changes in one system on the other.
Reference: [10] <author> R. Safaee-Rad, I. Tchoukanov, K. C. Smith, and B. Benhabib. </author> <title> Three-dimensional location estimation of circular features for machine vision. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 8 </volume> <pages> 624-640, </pages> <year> 1992. </year>
Reference-contexts: and we do not require the optical axis of the camera to intersect the final rotational axis of the robot. 1 3 RECOVERY OF IMAGE-ELLIPSE PA RAMETERS A number of other researchers have created a body of literature on the recovery of ellipses from point data (see Safaee-Rad et al. <ref> [10] </ref> and Sawhney et al. [11].) These algorithms typically use data sampled from the full circumference of the ellipse (i.e. sampled over 2 radians). While these methods work very well, sampling over a complete rotation about the robot's axis is very slow, and precludes real-time use of these methods.
Reference: [11] <author> H. S. Sawhney. </author> <title> Spatial and Temporal Grouping in the Interpretation of Image Motion. </title> <type> PhD thesis, </type> <institution> Univ. of Mass.-Amherst, </institution> <month> Feb </month> <year> 1992. </year>
Reference-contexts: the optical axis of the camera to intersect the final rotational axis of the robot. 1 3 RECOVERY OF IMAGE-ELLIPSE PA RAMETERS A number of other researchers have created a body of literature on the recovery of ellipses from point data (see Safaee-Rad et al. [10] and Sawhney et al. <ref> [11] </ref>.) These algorithms typically use data sampled from the full circumference of the ellipse (i.e. sampled over 2 radians). While these methods work very well, sampling over a complete rotation about the robot's axis is very slow, and precludes real-time use of these methods.
Reference: [12] <author> I. W. Thomas Miller. </author> <title> Sensor-based control of robotic manipulators using a general learning algorithm. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-3(2):157-165, </volume> <month> April </month> <year> 1987. </year>
Reference-contexts: These methods track feature points and effect servoing movements using an Image Jacobian which relates Cartesian movements with positional errors derived from the tracked features. Other methods include the work of Papanikopolous et al. [9], Koivo et al. [6] and Miller <ref> [12] </ref>. The basic idea behind the Image Jacobian is to model the differential relationship between the camera system and the robotic control system in order to accurately predict the effects of small changes in one system on the other. It is a linear, position-dependent (i.e. non-constant) transform.
Reference: [13] <author> L. Weiss, A. Sanderson, and C. Neuman. </author> <title> Dynamic sensor-based control of robots with visual feedback. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-3(5):404-417, </volume> <month> Oct. </month> <year> 1987. </year>
Reference-contexts: The Image Jacobian has been used by a number of other researchers including Weiss et al. <ref> [13] </ref>, Feddema et al.[4], Hashimoto et al.[5], Chaumette et al.[3], and Casta no et al.[2]. These methods track feature points and effect servoing movements using an Image Jacobian which relates Cartesian movements with positional errors derived from the tracked features.
References-found: 13

