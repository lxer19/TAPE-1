URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/TM158.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts92.htm
Root-URL: http://www.mcs.anl.gov
Email: bischof@mcs.anl.gov  hovland@mcs.anl.gov  
Title: ADIFOR Working Note #2: Using ADIFOR to Compute Dense and Sparse Jacobians  
Author: Christian H. Bischof Paul Hovland 
Date: October 1991  
Address: Argonne, IL 60439-4801  
Affiliation: Mathematics and Computer Science Division Argonne National Laboratory  
Pubnum: Technical Memorandum MCS-TM-158  
Abstract: ADIFOR is a source translator that, given a collection of Fortran subroutines for the computation of a "function," produces Fortran code for the computation of the derivatives of this function. More specifically, ADIFOR produces code to compute the matrix-matrix product JS, where J is the Jacobian of the "function" with respect to the user-defined independent variables, and S is the composition of the derivative objects corresponding to the independent variables. This interface is flexible; by setting S = x, one can compute the matrix-vector product Jx, or by setting S = I, one can compute the whole Jacobian J. Other initializations of S allow one to exploit a known sparsity structure of J. This paper illustrates the proper initialization of ADIFOR-generated derivative codes and the exploitation of a known sparsity structure of J. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Brett Averick, Richard G. Carter, and Jorge J. </author> <title> More. The MINPACK-2 test problem collection (preliminary version). </title> <type> Technical Report ANL/MCS-TM-150, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1991. </year>
Reference-contexts: Note that the ADIFOR-generated code remains unchanged. As a more realistic example, we consider the swirling flow problem, part of the MINPACK-2 test problem collection <ref> [1] </ref>. Here we solve a nonlinear system of equations F (x) = 0 for F : R n ! R n .
Reference: [2] <author> Christian Bischof, Alan Carle, George Corliss, and Andreas Griewank. </author> <title> ADIFOR-generating derivative codes from Fortran programs. </title> <note> ADIFOR Working Note #1, </note> <institution> MCS-P263-0991, Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1991. </year>
Reference-contexts: In this paper, we shall not concern ourselves with the way code is generated or with the input provided to ADIFOR. For these details, the reader is referred to <ref> [2] </ref>. Even though the ADIFOR interface conceptually never changes, the actual initialization of ADIFOR code may vary depending on context. <p> A primary reason is that the forward mode of automatic differentiation upon which ADIFOR is mainly based (see <ref> [2] </ref>) requires roughly g$p operations for every assignment statement in the original function.
Reference: [3] <author> D. Callahan, K. Cooper, R.T. Hood, K. Kennedy, and L.M. Torczon. </author> <title> ParaScope: a parallel programming environment. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 2(4), </volume> <month> December </month> <year> 1988. </year>
Reference-contexts: The user then selects the variables (either in parameter lists or in common blocks) that correspond to the independent and dependent variables. By using the powerful interprocedural analysis tools of the ParaScope programming environment <ref> [3] </ref>, ADIFOR then automatically determines which other variables throughout the program must have derivative information associated with them. Interactive Interface: An X-windows interface for ADIFOR (called xadifor) is also provided. <p> Dependent and independent variables are always active, and integer variables are always passive. The user need not specify as passive or active variables local to foo or parameters or local variables in routines called by foo. Using the powerful interprocedural analysis tools available in the ParaScope environment <ref> [3] </ref>, we can determine all active variables from a definition of the independent and dependent ones. This allows for a simple user interface that corresponds as much as possible to the mathematical intuition underlying foo. The derivative codes produced by ADIFOR have a gradient object associated with every active variable.
Reference: [4] <author> Thomas F. Coleman. </author> <title> Large Sparse Numerical Optimization, </title> <booktitle> volume 165 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: As it turns out, less than 7 % of the total operations performed with gradient objects in the ADIFOR code involve nonzeros. On the other hand, by using a graph-coloring algorithm designed to identify structurally orthogonal columns (we used the one described in <ref> [4] </ref>), we can determine that this Jacobian can be grouped into 14 sets of structurally orthogonal columns, independent of the size of the problem.
Reference: [5] <author> Thomas F. Coleman, Burton S. Garbow, and Jorge J. </author> <title> More. Software for estimating sparse Jacobian matrices. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 10(3) </volume> <pages> 329-345, </pages> <year> 1984. </year>
Reference: [6] <author> A. R. Conn, N. I. M. Gould, and Ph. L. Toint. </author> <title> An introduction to the structure of large scale nonlinear optimization problems and the LANCELOT project. </title> <type> Report 89-19, </type> <institution> Namur University, </institution> <address> Namur, Belgium, </address> <year> 1989. </year>
Reference: [7] <author> Wayne H. Enright and John D. Pryce. </author> <title> Two FORTRAN packages for assessing initial value methods. </title> <journal> ACM Trans. Math. Software, </journal> <volume> 13(1) </volume> <pages> 1-22, </pages> <year> 1987. </year>
Reference-contexts: separable functions In most of these cases, a "variable" denotes an array; thus, we shall be dealing with vector-valued functions. 3 2 Case 1: Dense Jacobian, one independent, one dependent variable Our first example is adapted from Problem C2 in the STDTST set of test problems for stiff ODE solvers <ref> [7] </ref> and was brought to our attention by George Corliss.
Reference: [8] <author> D. Goldfarb and P.L. Toint. </author> <title> Optimal estimation of Jacobian and Hessian matrices that arise in finite difference calculations. </title> <journal> Mathematics of Computation, </journal> <volume> 43 </volume> <pages> 69-88, </pages> <year> 1984. </year>
Reference: [9] <author> Andreas Griewank. </author> <title> On automatic differentiation. In: Mathematical Programming: Recent Developments and Applications, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Amsterdam, </address> <year> 1989, </year> <pages> pages 83-108. </pages>
Reference-contexts: Department of Energy, under Contract W-31-109-Eng-38 and through NSF Cooperative Agreement No. CCR 8809615. Efficiency: While primarily based on the so-called forward mode of automatic differentiation, AD--IFOR uses the so-called reverse mode to process assignment statements with composite right-hand sides <ref> [9, 10] </ref>. In addition to saving storage, this approach significantly enhances perfor mance. Parallelism and Vectorization: The code produced by ADIFOR respects the data-flow structure of the original program. That is, if the code vectorizes and parallelizes well, so does the ADIFOR-generated derivative code.
Reference: [10] <author> Andreas Griewank. </author> <title> The chain rule revisited in scientific computing. </title> <type> Preprint MCS-P227-0491, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1991. </year>
Reference-contexts: Department of Energy, under Contract W-31-109-Eng-38 and through NSF Cooperative Agreement No. CCR 8809615. Efficiency: While primarily based on the so-called forward mode of automatic differentiation, AD--IFOR uses the so-called reverse mode to process assignment statements with composite right-hand sides <ref> [9, 10] </ref>. In addition to saving storage, this approach significantly enhances perfor mance. Parallelism and Vectorization: The code produced by ADIFOR respects the data-flow structure of the original program. That is, if the code vectorizes and parallelizes well, so does the ADIFOR-generated derivative code.
Reference: [11] <author> Andreas Griewank and Philippe L. Toint. </author> <title> On the unconstrained optimization of partially separable objective functions. In: Nonlinear Optimization 1981, </title> <editor> M.J.D. Powell, editor, </editor> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1981, </year> <pages> pages 301-312. </pages>
Reference: [12] <author> Andreas Griewank and Philippe L. Toint. </author> <title> Partitioned variable metric updates for large structured optimization problems. </title> <journal> Numerische Mathematik, </journal> <volume> 39 </volume> <pages> 119-137, </pages> <year> 1982. </year>
Reference: [13] <author> David Juedes. </author> <title> A taxonomy of automatic differentiation tools. In: Proceedings of the Workshop on Automatic Differentiation of Algorithms: Theory, Implementation, and Application, </title> <editor> Andreas Griewank and George Corliss, eds., </editor> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1991. </year> <note> To appear. </note>
Reference-contexts: That is, given a collection of Fortran subroutines for the computation of a "function," ADIFOR produces Fortran code for the computation of the derivatives of this function. ADIFOR differs from previous approaches to automatic differentiation (see <ref> [13] </ref> for a recent survey) in several ways: Generality: The "function" can be composed of many subroutines, and these subroutines may communicate via parameter lists and/or common blocks. In general, almost all of Fortran-77 is supported.
Reference: [14] <author> M. Lescrenier. </author> <title> Partially separable optimization and parallel computing. </title> <journal> Ann. Oper. Res., </journal> <volume> 14 </volume> <pages> 213-224, </pages> <year> 1988. </year>
Reference: [15] <author> J. J. </author> <title> More. On the performance of algorithms for large-scale bound constrained problems. In: Large-Scale Numerical Optimization, </title> <editor> F. Coleman and Y. Li, editors, </editor> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1991. </year>
Reference: [16] <author> J. M. Smith and H. C. Van Ness. </author> <title> Introduction to Chemical Engineering. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1975. </year> <month> 24 </month>
Reference-contexts: Thus, it is usually best to compute as large a slice of the Jacobian as memory restrictions will allow. 3 Case 2: Dense Jacobian, multiple independent and multiple dependent variables The second example involves a code that models adiabatic flow <ref> [16] </ref>, a commonly used module in chemical engineering. This code models the separation of a pressurized mixture of hydrocarbons into liquid and vapor components in a distillation column, where pressure (and, as a result, temperature) decrease. This example was communicated to us by Larry Biegler.
References-found: 16

