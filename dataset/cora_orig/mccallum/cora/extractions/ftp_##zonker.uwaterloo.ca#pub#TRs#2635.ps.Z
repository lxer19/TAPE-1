URL: ftp://zonker.uwaterloo.ca/pub/TRs/2635.ps.Z
Refering-URL: http://www.cs.umd.edu/users/akyurek/papers.html
Root-URL: 
Title: Management of Partially-Safe Buffers  
Author: Sedat Akyurek Kenneth Salem 
Address: College Park, Maryland 20742  College Park, Maryland 20742  
Affiliation: Department of Computer Science University of Maryland  Department of Computer Science and Institute for Advanced Computer Studies University of Maryland  
Date: March, 1991, Revised May, 1993  
Pubnum: CS-TR-2635 UMIACS-TR-91-43  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Baker, Mary, S. Asami, E. Deprit, and J. Ousterhout, </author> <title> "Non-Volatile Memory for Fast Reliable File Systems", </title> <booktitle> Proc. Int'l Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October, </month> <year> 1992, </year> <pages> pp. 10-22. </pages>
Reference-contexts: Updated objects can be buffered temporarily in safe RAM in case they are updated again. Should this occur, two (or more) disk writes will have been combined into one when the object is finally written to the disk. The disadvantage of safe RAM is its cost. A recent study <ref> [1] </ref> found that non-volatile RAM was about five times as expensive as DRAM, although this cost differential is likely to drop over time. <p> Furthermore, direct transfer of data between the safe RAM and the disks is not possible. The focus of that work is on comparing the alternative safe RAM configurations, and not on buffer management. Two recent studies have used trace-driven simulations to evaluate safe buffers in operating systems. One study <ref> [1] </ref> was based on traces from the Sprite file system, while the second used traces from Unix file systems [13]. The traces used in [13] are block level traces similar to our own, while the Sprite traces are captured at a higher level. <p> However, we do not consider such extensions here. Finally, several proposed memory-resident transaction processing system designs [4, 10, 6] rely on safe memory to commit transaction updates quickly. Small safe memories have also been used to provide 2 The policy in <ref> [1] </ref> copies data from the safe cache to the volatile cache in some situations. The policies described here do not. fast recovery in the Sprite file system [2]. In those systems, safe memory management is tied closely to the transaction manager or the file system. <p> This problem can be eliminated by making the safe buffer larger. Another possibility is move data to the volatile buffer when it is replaced in the safe buffer. This latter technique is used in the Sprite studies described in <ref> [1] </ref>. 4.3 Trace Dependencies One of the most striking features of Figure 7 is the difference between the client and server traces. For the traces from the server, the LRU Global policy is sometimes superior to LRU Volatile.
Reference: [2] <author> Baker, Mary, and Mark Sullivan, </author> <title> "The Recovery Box: Using Fast Recovery to Provide High Availability in the UNIX Environment", </title> <booktitle> Proc. USENIX Technical Conference, </booktitle> <month> June, </month> <year> 1992, </year> <pages> pp. 31-44. </pages>
Reference-contexts: Small safe memories have also been used to provide 2 The policy in [1] copies data from the safe cache to the volatile cache in some situations. The policies described here do not. fast recovery in the Sprite file system <ref> [2] </ref>. In those systems, safe memory management is tied closely to the transaction manager or the file system. In contrast, the techniques described in this paper are not tied to the semantics of any particular data manager.
Reference: [3] <author> Copeland, George, Ravi Krishnamurty and Marc Smith, </author> <title> "The Case For Safe RAM," </title> <booktitle> Proceedings of the 15th VLDB Conference, </booktitle> <address> Amsterdam, </address> <year> 1989, </year> <pages> pp. 327-336. </pages>
Reference-contexts: XPRS [18], a POSTGRES-based transaction processing system, buffers frequently updated data blocks in safe RAM to provide fast recovery. The techniques used to manage the safe buffer are not described there. The Phoenix file system [5] maintains an entire file system in safe RAM. In <ref> [3] </ref>, the use of partially-safe buffers in transaction processing systems is discussed. <p> Under this configuration, the safe RAM handles all update requests, but it cannot be used to satisfy read requests. This configuration is similar to that implemented by the IBM 3990 disk controller and the model studied in <ref> [3] </ref>. The Sprite study also considered a unified configuation similar to the one used in this study Under the unified model, read requests can be satisfied from either the safe buffer or the volatile buffer. <p> Its buffer state is simply synchronized with its state on disk. Staging operations are initiated by the buffer manager, allowing many I/O operations to be removed from the critical paths of write (and possibly read) requests. Asynchronous staging from the safe buffer has been suggested in <ref> [3] </ref> and has been implemented in some systems, including the IBM 3990 storage manager. In the following experiments, we consider the impact of asynchronous staging on response times, and show how it affects the performance of the buffer management policies. Staging can be implemented in a variety of ways. <p> Even for that trace, a 3%-safe buffer coupled with immediate staging reduces the write response time to zero. In qualitative terms, the data in Table 4 confirm the predictions of analytic model of <ref> [3] </ref>: small, staged safe buffers can reduce write response times to near zero. It might be expected that asynchronous staging would increase read response times because of contention for the disk.
Reference: [4] <author> Eich, Margaret H., </author> <title> "A Classification and Comparison of Main Memory Database Recovery Techniques," </title> <booktitle> Proc. International Conference on Data Engineering, IEEE, </booktitle> <month> February, </month> <year> 1987, </year> <pages> pp. 332-339. </pages>
Reference-contexts: Either of these techniques can be combined easily with the buffer management techniques described in this paper. However, we do not consider such extensions here. Finally, several proposed memory-resident transaction processing system designs <ref> [4, 10, 6] </ref> rely on safe memory to commit transaction updates quickly. Small safe memories have also been used to provide 2 The policy in [1] copies data from the safe cache to the volatile cache in some situations.
Reference: [5] <author> Gait, Jason, </author> <title> "Phoenix: A Safe In-Memory File System," </title> <journal> Communications of the ACM, </journal> <volume> 33, 1, </volume> <month> January, </month> <year> 1990, </year> <pages> pp. 81-86. </pages>
Reference-contexts: Dirty data in the safe buffer is staged to disk asynchronously when possible. XPRS [18], a POSTGRES-based transaction processing system, buffers frequently updated data blocks in safe RAM to provide fast recovery. The techniques used to manage the safe buffer are not described there. The Phoenix file system <ref> [5] </ref> maintains an entire file system in safe RAM. In [3], the use of partially-safe buffers in transaction processing systems is discussed.
Reference: [6] <author> Garcia-Molina, Hector, Kenneth Salem, </author> <title> "High Performance Transaction Processing with Memory-Resident Data," </title> <booktitle> Proceedings of the International Symposium on High Performance Computer Systems, </booktitle> <address> Paris, </address> <month> December, </month> <title> 1987, </title> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: Either of these techniques can be combined easily with the buffer management techniques described in this paper. However, we do not consider such extensions here. Finally, several proposed memory-resident transaction processing system designs <ref> [4, 10, 6] </ref> rely on safe memory to commit transaction updates quickly. Small safe memories have also been used to provide 2 The policy in [1] copies data from the safe cache to the volatile cache in some situations.
Reference: [7] <author> Haerder, Theo, Andreas Reuter, </author> <title> "Principles of Transaction-Oriented Database Recovery," </title> <journal> ACM Computing Surveys, </journal> <volume> 15, 4, </volume> <month> December, </month> <year> 1983, </year> <pages> pp. 287-317. 32 </pages>
Reference-contexts: Instead, buffered updates are synchronized (i.e., copied back to the disks) periodically. A failure may cause updates that occur after the most recent synchronization point to be lost. In database management systems, buffer managers that permit unsafe updates are said to use a :FORCE <ref> [7] </ref> policy. Such buffer managers are often used in conjunction with a separate mechanism, such as after-image (REDO) logging [7] and periodic checkpointing, to guarantee the safety of all updates. 1 The combination of logging, checkpointing, and a :FORCE volatile buffer provides advantages similar to those of partially-safe buffers: write response <p> In database management systems, buffer managers that permit unsafe updates are said to use a :FORCE <ref> [7] </ref> policy. Such buffer managers are often used in conjunction with a separate mechanism, such as after-image (REDO) logging [7] and periodic checkpointing, to guarantee the safety of all updates. 1 The combination of logging, checkpointing, and a :FORCE volatile buffer provides advantages similar to those of partially-safe buffers: write response times are fast and the safety of updates is guaranteed.
Reference: [8] <author> IBM, </author> <title> IBM 3990 Storage Control Introduction, Manual No. </title> <address> GA37-0098-0, </address> <year> 1987. </year>
Reference-contexts: These include both main memory buffers, e.g., in the Postgres storage system [17], and controller buffers such as the partially-safe buffer implemented in the IBM 3990 storage controller <ref> [8] </ref>. This paper addresses two issues. First, we consider the management of partially-safe buffers, with emphasis on replacement policies. Common (and effective) replacement policies, e.g., least-recently-used (LRU), are blind to the safety or volatility of the buffer. <p> As we have already noted, the IBM 3990 disk controller <ref> [8] </ref> is capable of buffering updates in its non-volatile memory. Both volatile and non-volatile buffers are maintained, and updates appear in both. Dirty data in the safe buffer is staged to disk asynchronously when possible.
Reference: [9] <author> Le*er, Samuel J., M. K. McKusick, M. J. Karels, and J. S. Quarterman, </author> <title> The Design and Implementation of the 4.3BSD UNIX Operating System, </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: The traces used in [13] are block level traces similar to our own, while the Sprite traces are captured at a higher level. In particular, the Sprite traces do not include requests for file system meta-data, such as i-nodes <ref> [9] </ref>. Such references account for a substantial fraction of the requests (particularly 4 write requests) in our traces and in those of [13]. Both of these studies considered a safe RAM configuration called write-aside, which we did not consider in our study.
Reference: [10] <author> Lehman, Tobin J., Michael J. Carey, </author> " <title> A Recovery Algorithm for a High-Performance Memory-Resident Database System," </title> <booktitle> Proceedings of the ACM SIGMOD Int'l Conference on the Management of Data, </booktitle> <address> San Francisco, </address> <year> 1987, </year> <pages> pp. 104-117. </pages>
Reference-contexts: Either of these techniques can be combined easily with the buffer management techniques described in this paper. However, we do not consider such extensions here. Finally, several proposed memory-resident transaction processing system designs <ref> [4, 10, 6] </ref> rely on safe memory to commit transaction updates quickly. Small safe memories have also been used to provide 2 The policy in [1] copies data from the safe cache to the volatile cache in some situations.
Reference: [11] <author> Ng, S. W., </author> <title> "Improving Disk Performance Via Latency Reduction," </title> <journal> IEEE Transactions on Computers, </journal> <volume> 40, 1, </volume> <month> January, </month> <year> 1991, </year> <pages> pp. 22-30. </pages>
Reference-contexts: This is the primary focus of our study. Several techniques have been suggested for improving the disk performance, assuming that updates are temporarily buffered. Safe RAM is ideal for use in combination with these techniques, since buffered updates will not be lost in the event of a failure. Ng <ref> [11] </ref> suggests that safe RAM can be used to eliminate the write penalty associated with duplexed disks. Buffered writes can also be "piggy-backed" onto read operations [16], allowing the disk to be updated with very little cost.
Reference: [12] <author> Rahm, Erhard, </author> <title> "Performance Evaluation of Extended Storage Architectures for Transaction Processing," </title> <booktitle> Proceedings of the ACM SIGMOD Int'l Conference on the Management of Data, </booktitle> <year> 1992, </year> <pages> pp. 308-317. </pages>
Reference-contexts: Our model incorporates the impact of the safe buffer and the buffer management policies on read response times as well as write response times, and is based on trace-driven simulations rather than an analytic model. Stochastic simulations described in <ref> [12] </ref> compare several alternative safe RAM configurations in database systems. Safe extended main memory, solid state disk, and safe disk (controller) buffers are considered. That work uses a different safe RAM model than ours. In [12], read-referenced data that is located in the safe extended main memory must be transferred to <p> Stochastic simulations described in <ref> [12] </ref> compare several alternative safe RAM configurations in database systems. Safe extended main memory, solid state disk, and safe disk (controller) buffers are considered. That work uses a different safe RAM model than ours. In [12], read-referenced data that is located in the safe extended main memory must be transferred to volatile main memory to be read. Furthermore, direct transfer of data between the safe RAM and the disks is not possible.
Reference: [13] <author> Ruemmler, Chris, and J. Wilkes, </author> <title> "UNIX disk access patterns", </title> <booktitle> Usenix Conference Proceedings, </booktitle> <month> January, </month> <year> 1993, </year> <pages> pp. 405-420. </pages>
Reference-contexts: Two recent studies have used trace-driven simulations to evaluate safe buffers in operating systems. One study [1] was based on traces from the Sprite file system, while the second used traces from Unix file systems <ref> [13] </ref>. The traces used in [13] are block level traces similar to our own, while the Sprite traces are captured at a higher level. In particular, the Sprite traces do not include requests for file system meta-data, such as i-nodes [9]. <p> Two recent studies have used trace-driven simulations to evaluate safe buffers in operating systems. One study [1] was based on traces from the Sprite file system, while the second used traces from Unix file systems <ref> [13] </ref>. The traces used in [13] are block level traces similar to our own, while the Sprite traces are captured at a higher level. In particular, the Sprite traces do not include requests for file system meta-data, such as i-nodes [9]. <p> In particular, the Sprite traces do not include requests for file system meta-data, such as i-nodes [9]. Such references account for a substantial fraction of the requests (particularly 4 write requests) in our traces and in those of <ref> [13] </ref>. Both of these studies considered a safe RAM configuration called write-aside, which we did not consider in our study. Under this configuration, the safe RAM handles all update requests, but it cannot be used to satisfy read requests.
Reference: [14] <author> Schwetman, Herb, </author> <title> "CSIM Reference Manual (Revision 14)", </title> <type> MCC Technical Report Number ACT-ST-252-87, </type> <institution> MCC, 3500 West Balcones Center Drive, Austin, TX, </institution> <month> March, </month> <year> 1990. </year>
Reference-contexts: The simulator reports a variety of statistics for each run, including counts of I/O operations, mean response times for read and write requests, and utilization, service time, and waiting time at the disk server. It is implemented using the CSIM simulation library <ref> [14] </ref>. 3.1 The Traces The traces were gathered from workstations running a customized version of the SunOS 3.2 operating system kernel. The kernel was modified to produce a trace record for each block I/O request (read or write) to file systems residing on the workstation's disk (s).
Reference: [15] <author> Smith, Alan J., </author> <title> "Disk Cache Miss Ratio Analysis and Design Considerations," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3, 3, </volume> <month> August, </month> <year> 1985, </year> <pages> pp. 161-203. </pages>
Reference: [16] <author> Solworth, J. A., C. U. Orji, </author> <title> "Write-Only Disk Caches," </title> <booktitle> Proceedings of the ACM SIGMOD Int'l Conference on the Management of Data, </booktitle> <month> May, </month> <year> 1990, </year> <pages> pp. 123-132. </pages>
Reference-contexts: Ng [11] suggests that safe RAM can be used to eliminate the write penalty associated with duplexed disks. Buffered writes can also be "piggy-backed" onto read operations <ref> [16] </ref>, allowing the disk to be updated with very little cost. Either of these techniques can be combined easily with the buffer management techniques described in this paper. However, we do not consider such extensions here. <p> Piggy-backed updates, as suggested in <ref> [16] </ref>, can be used, or the buffer manager can attempt to delay updates until the disk is idle. We expect that such enhancements would be most beneficial when the disk is heavily loaded, which was not the case in our study.
Reference: [17] <author> Stonebraker, M., </author> <booktitle> "The Design of the Postgress Storage Sysytem," Proceedings of the 13th VLDB Conference, </booktitle> <address> Brighton, </address> <year> 1987, </year> <pages> pp. 289-300. </pages>
Reference-contexts: These include both main memory buffers, e.g., in the Postgres storage system <ref> [17] </ref>, and controller buffers such as the partially-safe buffer implemented in the IBM 3990 storage controller [8]. This paper addresses two issues. First, we consider the management of partially-safe buffers, with emphasis on replacement policies. <p> If write response times can be made sufficiently small by introducing safe buffers, then one of the principal motivations for logging will have been removed. (One version of this idea is currently being explored in the Postgres storage system <ref> [17] </ref>.) Aside from the elimination of the complexities of logging, an advantage of the safe-buffer approach is that failure recovery is very fast, since there is no need to reconstruct the state of the database from the log. 31 It may be possible to further enhance the performance of partially-safe buffers
Reference: [18] <editor> Stonebraker, M., et. al. </editor> <booktitle> "The Design of XPRS," Proceedings of the 14th VLDB Conference, </booktitle> <address> Los Angeles, California, </address> <year> 1988, </year> <pages> pp. 318-330. 33 </pages>
Reference-contexts: As we have already noted, the IBM 3990 disk controller [8] is capable of buffering updates in its non-volatile memory. Both volatile and non-volatile buffers are maintained, and updates appear in both. Dirty data in the safe buffer is staged to disk asynchronously when possible. XPRS <ref> [18] </ref>, a POSTGRES-based transaction processing system, buffers frequently updated data blocks in safe RAM to provide fast recovery. The techniques used to manage the safe buffer are not described there. The Phoenix file system [5] maintains an entire file system in safe RAM.
References-found: 18

