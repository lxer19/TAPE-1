URL: file://ftp.cs.utexas.edu/pub/mooney/papers/scope-msl-96.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/estlin/pubs.html
Root-URL: 
Email: festlin,mooneyg@cs.utexas.edu  
Title: Integrating EBL and ILP to Acquire Control Rules for Planning  
Author: Tara A. Estlin and Raymond J. Mooney 
Address: Austin, TX 78712  
Affiliation: Department of Computer Sciences University of Texas at Austin  
Note: Appears in the Proceedings of the Third International Workshop on Multi-Strategy Learning (MSL-96)  
Abstract: Most approaches to learning control information in planning systems use explanation-based learning to generate control rules. Unfortunately, EBL alone often produces overly complex rules that actually decrease planning efficiency. This paper presents a novel learning approach for control knowledge acquisition that integrates explanation-based learning with techniques from inductive logic programming. EBL is used to constrain an inductive search for selection heuristics that help a planner choose between competing plan refinements. Scope is one of the few systems to address learning control information in the newer partial-order planners. Specifically, Scope learns domain-specific control rules for a version of the UCPOP planning algorithm. The resulting system is shown to produce significant speedup in two different planning domains. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Barrett, A., and Weld, D. </author> <year> 1994. </year> <title> Partial order planning: Evaluating possible efficiency gains. </title> <booktitle> Artificial Intelligence 67 </booktitle> <pages> 71-112. </pages>
Reference: <author> Bhatnagar, N., and Mostow, J. </author> <year> 1994. </year> <title> On-line learning from search failure. </title> <booktitle> Machine Learning 15 </booktitle> <pages> 69-117. </pages>
Reference: <author> Borrajo, D., and Veloso, M. </author> <year> 1994a. </year> <title> Incremental learning of control knowledge for nonlinear problem solving. </title> <booktitle> In Proceedings of the European Conference on Machine Learning, ECML-94, </booktitle> <pages> 64-82. </pages>
Reference-contexts: These results are particularly significant since UCPOP+EBL uses additional domain axioms which were not provided to Scope. Most other related learning systems have been evaluated on different planning algorithms, thus direct system comparisons are difficult. The Hamlet <ref> (Borrajo & Veloso 1994a) </ref> system learns control knowledge for the nonlinear planner underlying Prodigy4.0. Hamlet acquires rules by explaining past planning decisions and then incrementally refining them. It is difficult to directly compare Hamlet and Scope for several reasons.
Reference: <author> Borrajo, D., and Veloso, M. </author> <year> 1994b. </year> <title> Incremental learning of control knowledge for improvement of planning efficieny and plan quality. </title> <booktitle> In AAAI-94 Fall Symposium on Planning and Learning, </booktitle> <pages> 5-9. </pages>
Reference: <author> Cohen, W. W. </author> <year> 1990. </year> <title> Learning approximate control rules of high utility. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> 268-276. </pages>
Reference: <author> DeJong, G. F., and Mooney, R. J. </author> <year> 1986. </year> <title> Explanation-based learning: An alternative view. </title> <booktitle> Machine Learning 1(2) </booktitle> <pages> 145-176. </pages> <note> Reprinted in Readings in Machine Learning, </note> <editor> J. W. Shavlik and T. G. Dietterich (eds.), </editor> <publisher> Morgan Kaufman, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference: <author> Estlin, T. A. </author> <year> 1996. </year> <title> Integrating explanation-based and inductive learning techniques to acquire search-control for planning. </title> <type> Technical report, </type> <institution> Department of Computer Sciences, University of Texas, Austin, TX. </institution> <note> Forthcoming. URL: http://net.cs.utexas.edu/ml/ Gratch, </note> <author> J., and DeJong, G. </author> <year> 1992. </year> <title> COMPOSER: A probabilistic solution to the utility problem in speedup learning. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> 235-240. </pages>
Reference-contexts: Scope uses the examples to induce a set of control heuristics which are then incorporated into the original planner. Figure 2 shows the three main phases of Scope's algorithm, which are explained in the next few sections. A more detailed description can be found in <ref> (Estlin 1996) </ref>.
Reference: <author> Kambhampati, S., and Chen, J. </author> <year> 1993. </year> <title> Relative utility of EBG based plan reuse in partial ordering vs. total ordering. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> 514-519. </pages>
Reference: <author> Kambhampati, S.; Katukam, S.; and Qu, Y. </author> <year> 1996. </year> <title> Failure driven search control for partial order planners: An explanation based approach. </title> <journal> Artificial Intelligence. Forthcoming. </journal>
Reference-contexts: For the logistics domain, Scope produced programs that were an average of 5.3 times faster. These results indicate that Scope can significantly improve the performance of a partial-order planner. Related Work A closely related system to Scope is UCPOP+EBL <ref> (Kambhampati, Katukam, & Qu 1996) </ref>, which also learns search control rules for UCPOP, but uses a purely explanation-based approach. Specifically, UCPOP+EBL employs the standard EBL techniques of regression, explanation propagation and rule generation to acquire search-control rules. Rules are learned only in response to past planning failures.
Reference: <author> Katukam, S., and Kambhampati, S. </author> <year> 1994. </year> <title> Learning explanation-based search control for partial order planning. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> 582-587. </pages>
Reference-contexts: Though partial-order planners are considered a more proficient planning strategy, they are not a panacea for efficient planning. Added control knowledge can still dramatically effect the their performance. However, there has been little work on learning control for current partial-order planning systems <ref> (Katukam & Kambhampati 1994) </ref>. Scope learns control rules for a partial-order planner in the form of selection heuristics. These heuristics greatly reduce backtracking by directing a planner to immediately select appropriate plan refinements. Scope is implemented in Prolog, which provides a good framework for learning control knowledge.
Reference: <author> Langley, P., and Allen, J. </author> <year> 1991. </year> <title> The acquisition of human planning expertise. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> 80-84. </pages>
Reference: <author> Lavrac, N., and Dzeroski, S., eds. </author> <year> 1994. </year> <title> Inductive Logic Programming: Techniques and Applications. </title> <publisher> El-lis Horwood. </publisher>
Reference: <author> Leckie, C., and Zuckerman, I. </author> <year> 1993. </year> <title> An inductive approach to learning search control rules for planning. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 1100-1105. </pages>
Reference: <author> Minton, S.; Drummond, M.; Bresina, J. L.; and Phillips, A. B. </author> <year> 1992. </year> <title> Total order vs. partial order planning: Factors influencing performance. </title> <booktitle> In Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> 83-92. </pages>
Reference: <author> Minton, S. </author> <year> 1988. </year> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> 564-569. </pages>
Reference-contexts: Past systems have often employed explanation-based learning (EBL) to learn search-control knowledge. Unfortunately, standard EBL can frequently produce complex, overly-specific control rules that decrease rather than improve overall planning performance <ref> (Minton 1988) </ref>. By incorporating induction to learn simpler, approximate control rules, we can greatly improve the utility of acquired knowledge (Cohen 1990; Leckie & Zuckerman 1993).
Reference: <author> Minton, S. </author> <year> 1989. </year> <title> Explanation-based learning: A problem solving perspective. </title> <booktitle> Artificial Intelligence 40 </booktitle> <pages> 63-118. </pages>
Reference: <author> Mitchell, T. M.; Keller, R. M.; and Kedar-Cabelli, S. T. </author> <year> 1986. </year> <title> Explanation-based generalization: A unifying view. </title> <booktitle> Machine Learning 1(1) </booktitle> <pages> 47-80. </pages>
Reference: <author> Mooney, R. J., and Califf, M. E. </author> <year> 1995. </year> <title> Induction of first-order decision lists: Results on learning the past tense of English verbs. </title> <journal> Journal of Artificial Intelli--gence Research 3 </journal> <pages> 1-24. </pages>
Reference-contexts: Scope uses an intensional version of Foil where background predicates can be defined as Prolog predicates instead of requiring an extensional represen tation <ref> (Mooney & Califf 1995) </ref>. Any predicates that can be used as rule antecedents must be introduced as background knowledge.
Reference: <editor> Muggleton, S. H., ed. </editor> <booktitle> 1992. Inductive Logic Programming. </booktitle> <address> New York, NY: </address> <publisher> Academic Press. </publisher>
Reference: <author> Pazzani, M., and Kibler, D. </author> <year> 1992. </year> <title> The utility of background knowledge in inductive learning. </title> <booktitle> Machine Learning 9 </booktitle> <pages> 57-94. </pages>
Reference-contexts: Second, Foil has a "most general" bias which tends to produce simple definitions. Such a bias is important for learning rules with a low match cost, which helps avoid the utility problem. Third, it is relatively easy to bias Foil with prior knowledge <ref> (Pazzani & Kibler 1992) </ref>. In our case, we can utilize the information contained in the generalized proof trees of planning solution traces. FOIL Algorithm Foil attempts to learn a concept definition in terms of a given set of background predicates.
Reference: <author> Penberthy, J., and Weld, D. S. </author> <year> 1992. </year> <title> UCPOP: A sound, complete, partial order planner for ADL. </title> <booktitle> In Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> 113-114. </pages>
Reference-contexts: These heuristics greatly reduce backtracking by directing a planner to immediately select appropriate plan refinements. Scope is implemented in Prolog, which provides a good framework for learning control knowledge. A ver sion of the UCPOP planning algorithm <ref> (Penberthy & Weld 1992) </ref> was implemented as a Prolog program to provide a testbed for Scope. Experimental results are presented on two domains that demonstrate Scope can significantly increase partial-order planning efficiency. The remainder of this paper is organized as follows.
Reference: <author> Perez, M. A., and Carbonell, J. </author> <year> 1994. </year> <title> Control knowledge to improve the plan quality. </title> <booktitle> In Proceedings of the Second International Conference of AI Planning Systems. </booktitle>
Reference: <author> Quinlan, J. </author> <year> 1990. </year> <title> Learning logical definitions from relations. </title> <booktitle> Machine Learning 5(3) </booktitle> <pages> 239-266. </pages>
Reference: <author> Silverstein, G., and Pazzani, M. J. </author> <year> 1991. </year> <title> Relational cliches: Constraining constructive induction during relational learning. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> 203-207. </pages>
Reference-contexts: Scope also considers several other types of control rule antecedents during induction. Besides pulling literals directly from generalized proof trees, Scope can use negated proof literals, determinate literals (Mug-gleton 1992), variable codesignation constraints, and relational cliches <ref> (Silverstein & Pazzani 1991) </ref>. Incorporating different antecedent types helps Scope learn expressive control rules that can describe partial-order planning situations. Program Specialization Phase Once refinement selection rules have been learned, they are passed to the program specialization phase which adds this control information into the original planner.
Reference: <author> Veloso, M. M. </author> <year> 1992. </year> <title> Learning by Analogical Reasoning in General Problem Solving. </title> <type> Ph.D. Dissertation, </type> <institution> School of Computer Science, Carnegie Mellon University. </institution>
Reference-contexts: The second and third rule allow Putdown (A) to be applied only when A should be placed on the table and not stacked on another block. Experimental Evaluation The blocksworld and logistics transportation domains were used to test the Scope learning system. In the logistics domain <ref> (Veloso 1992) </ref>, packages must be delivered to different locations in several cities. Packages are transported between cities by airplane and within a city by truck. In both domains, a test set of 100 independently generated problems was used to evaluate performance.
Reference: <author> Zelle, J. M., and Mooney, R. J. </author> <year> 1993. </year> <title> Combining FOIL and EBG to speed-up logic programs. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 1106-1111. </pages>
Reference-contexts: Scope is then used to learn refinement-selection rules which are incorporated into the original planning program in the form of clause-selection heuristics. The Scope Learning System Scope is based on the Dolphin speedup learning system <ref> (Zelle & Mooney 1993) </ref>, which optimizes logic programs by learning clause-selection rules. Dolphin has been shown successful at improving program performance in several different domains, including planning domains which employed a simple state-based planner.
Reference: <author> Zelle, J. M., and Mooney, R. J. </author> <year> 1994. </year> <title> Combining top-down and bottom-up methods in inductive logic programming. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> 343-351. </pages>
References-found: 27

