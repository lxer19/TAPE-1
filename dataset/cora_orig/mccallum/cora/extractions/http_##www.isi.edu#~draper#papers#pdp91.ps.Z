URL: http://www.isi.edu/~draper/papers/pdp91.ps.Z
Refering-URL: http://www.isi.edu/~draper/papers/papers.html
Root-URL: http://www.isi.edu
Title: The M-Cache: A Message-Retrieving Mechanism for Multicomputer Systems  
Author: Jeffrey T. Draper Joydeep Ghosh William C. Athas 
Address: One Research Park Austin, TX 78712-1084 Austin, TX 78712-1084 Palos Verdes Peninsula, CA 90274  
Affiliation: Department of ECE Department of ECE Northrop Research Tech. Center The University of Texas The University of Texas  
Abstract: This paper presents the design and evaluation of the M-cache, a small, fast and intelligent memory for handling messages at the processing nodes of multi-computer systems. The M-cache provides hardware support for the message search operation often performed in message-directed programming. It also provides a mechanism for bandwidth matching between the interconnection network and local memory of a node. Through simulation experiments, we have studied the execution of concurrent algorithms on systems with and without M-caches to obtain relative speedup measures. The results show that a modest investment in silicon is sufficient to effect over an order of magnitude reduction in message-retrieval time. Such hardware support is needed to make the cost-effective implementation of fine-grain concurrent programs a reality. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Ametek 2010 Product Description, Ametek Computer Research Division, 606 E. </institution> <address> Huntington Drive, Monrovia, CA 91016. </address>
Reference-contexts: For current hardware and software, the overhead for software delivery is orders of magnitude greater than the hardware overhead [3]. An example is the Symult Systems s2010 <ref> [1] </ref>. This multicomputer uses VLSI-based routing automata of the Symult Systems s2010 and a native operating system, called the Reactive Kernel, which is streamlined for message passing. The network transit time for messages smaller than 256 bytes is a few microseconds.
Reference: [2] <author> William Athas, "Physically-Compact, </author> <title> High-Performance Multicomputers," </title> <booktitle> Sixth MIT Conference on Advanced Research in VLSI, </booktitle> <month> April </month> <year> 1990. </year>
Reference-contexts: The situation is comparable for the Intel iPSC/2. Clearly there is a tremendous mismatch between the software abstractions and the underlying hardware mechanisms that implement the abstractions. The situation will continue to grow worse as the VLSI chips are optimized for their throughput rates <ref> [2] </ref>. Aside from the obvious impact to user performance, there is also an impact to the system performance because messages that cannot be delivered as fast as they are sent will block the networks and cause network congestion, particularly when wormhole routing is used [3].
Reference: [3] <author> William Athas and Charles Seitz, "Multicomput-ers: </author> <title> Message-Passing Concurrent Computers," </title> <journal> Computer, </journal> <volume> Vol. 21, </volume> <month> August </month> <year> 1988, </year> <pages> pp. 9-24. </pages>
Reference-contexts: For current hardware and software, the overhead for software delivery is orders of magnitude greater than the hardware overhead <ref> [3] </ref>. An example is the Symult Systems s2010 [1]. This multicomputer uses VLSI-based routing automata of the Symult Systems s2010 and a native operating system, called the Reactive Kernel, which is streamlined for message passing. The network transit time for messages smaller than 256 bytes is a few microseconds. <p> Aside from the obvious impact to user performance, there is also an impact to the system performance because messages that cannot be delivered as fast as they are sent will block the networks and cause network congestion, particularly when wormhole routing is used <ref> [3] </ref>. The M-cache, when used in conjunction with the message-directed programming style, will reduce the selection overhead to levels comparable to that of the network hardware. Message-directed programming is a style of programming in which message selection is template driven. <p> For example, based on data gathered from the execution of various Cantor programs on the Symult 2010, a row length of 64 bytes would allow almost all messages in a Cosmic Cube/Cantor programming system to be cacheable <ref> [3] </ref>. An M-cache with 50 rows and 64 columns would occupy approximately 48 M 2 area in silicon. It is projected to provide at least a twenty-fold speedup in message handling in the Cosmic Cube/Cantor environment.
Reference: [4] <author> Nicholas Carriero and David Gelernter, </author> <title> "Linda in Context," </title> <journal> Communications of the ACM, </journal> <volume> Vol. 32, </volume> <month> April </month> <year> 1989, </year> <pages> pp. 444-58. </pages>
Reference-contexts: Similarly, a field in the search template can be used to ensure that messages matching the same template are consumed in the order in which the messages arrived at a given node. This scheme is similar to the one defined for the representation of vectors in Linda <ref> [4] </ref>. The second implication concerns the area of multiprocessing. When more than one process resides on a node, a consuming process must include its process identifier as a field in the search template to ensure the message it consumes was indeed addressed to it.
Reference: [5] <author> William J. Dally, et al., </author> <title> "Architecture of a Message-Driven Processor," </title> <booktitle> Proceedings of the 14th Annual International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1987, </year> <pages> pp. 189-96. </pages>
Reference-contexts: Several hardware mechanisms have been proposed for reducing the message-handling overhead in message-based systems. The use of a Smart Bus in conjunction with a coprocessor that executes the message-passing kernel has been demonstrated as offering improved performance in message-based, distributed operating systems [12]. The Message-Driven Processor (MDP) <ref> [5] </ref> allows message processing to occur without interruption of the computation processor. Hardware support for Ethernet is available for off-loading communications protocols onto front-end processors [10]. A message passing coprocessor with a virtual channel router is presented in [9].
Reference: [6] <author> Jeffrey Draper, </author> <title> "The M-Cache: A Message Cache for Message-Passing Multicomputers," M.S.E. </title> <type> Thesis, </type> <institution> The University of Texas at Austin, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: The finite state machine is the sequencer for the M-cache. It performs the necessary handshaking with the network interface, communicates with the processor, and controls/monitors all signals to/from other elements within the M-cache. More details about the finite state machine are given in <ref> [6] </ref>. The mask register selects columns for the matching operation and also the reading out of a message. The column selected is the one corresponding to the first bit in the mask register which is set. This bit is then reset for subsequent operations. <p> The results of a typical simulation run for one consumer and one producer are shown in Figure 4. The results of other runs for one consumer and one producer with varying values of are given in <ref> [6] </ref>. The predicted values based on Equation 1 are also shown in these figures. Single consumer, multiple producers: For this case, the simulator randomly selects the producer from which the consumer receives its next message. Therefore, the consumption of messages is not necessarily in an FCFS (first-come-first-served) order.
Reference: [7] <author> G. Fox, et al., </author> <title> Solving Problems on Concurrent Processors, </title> <publisher> Prentice-Hall, </publisher> <year> 1988. </year>
Reference-contexts: There are some apparent differences between the simulation model and real execution of concurrent programs. In the model, processes are assumed to perform message operations at Poisson rates. Processes of 0:95 most programs perform message operations in a very regular manner <ref> [7] </ref>. For instance, the controlling process in a divide-and-conquer algorithm sends messages to each of the computational child processes and later receives results encapsulated in messages from each of the processes. This procedure may be repeated any number of times during execution of the algorithm.
Reference: [8] <author> Robert Golla, </author> <title> "Design and Development of a Pattern-Addressable Cache Simulator," M.S.E. </title> <type> Report, </type> <institution> The University of Texas at Austin, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: (senders) * mean of the Poisson distribution governing the message production rate * number of consumer processes (receivers) * mean of the Poisson distribution governing the message consumption rate * message length distribution * length of time between successive task switches More details about the simulator can be found in <ref> [8] </ref>. 3.1 Results of the Simulation Experi ments Two basic scenarios were tested. A situation in which the processor node has a single active process which communicates with processes running on other nodes is modeled as a single consumer, multiple producer system.
Reference: [9] <author> Jiun-Ming Hsu and Prithviraj Banerjee, </author> <title> "Hardware Support for Message Routing in a Distributed Memory Multicomputer," </title> <booktitle> Proceedings of the International Conference on Parallel Processing, August 1990, </booktitle> <volume> Vol. I, </volume> <pages> pp. 508-15. </pages>
Reference-contexts: The Message-Driven Processor (MDP) [5] allows message processing to occur without interruption of the computation processor. Hardware support for Ethernet is available for off-loading communications protocols onto front-end processors [10]. A message passing coprocessor with a virtual channel router is presented in <ref> [9] </ref>. This scheme uses circuit switching and provides for the caching of most recently used routing paths. Although all of these techniques aid in message handling, no previous work has suggested hardware support for message selection or an intelligent memory dedicated for message storage and retrieval.
Reference: [10] <editor> Interlan, N3010A Multibus Ethernet Communi--cations Controller, </editor> <year> 1983. </year>
Reference-contexts: The Message-Driven Processor (MDP) [5] allows message processing to occur without interruption of the computation processor. Hardware support for Ethernet is available for off-loading communications protocols onto front-end processors <ref> [10] </ref>. A message passing coprocessor with a virtual channel router is presented in [9]. This scheme uses circuit switching and provides for the caching of most recently used routing paths.
Reference: [11] <author> T. F. Knight, </author> <title> "Technology for Low Latency Interconnection Switches," </title> <booktitle> Proceedings of the ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1989. </year>
Reference: [12] <author> Umakishore Ramachandran, et al., </author> <title> "Hardware Support for Interprocess Communication," </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> Vol. 1, </volume> <month> July </month> <year> 1990, </year> <pages> pp. 318-29. </pages>
Reference-contexts: Several hardware mechanisms have been proposed for reducing the message-handling overhead in message-based systems. The use of a Smart Bus in conjunction with a coprocessor that executes the message-passing kernel has been demonstrated as offering improved performance in message-based, distributed operating systems <ref> [12] </ref>. The Message-Driven Processor (MDP) [5] allows message processing to occur without interruption of the computation processor. Hardware support for Ethernet is available for off-loading communications protocols onto front-end processors [10]. A message passing coprocessor with a virtual channel router is presented in [9].
Reference: [13] <author> Ian Robinson, "Chameleon: </author> <title> A Pattern Matching Memory System," </title> <type> Hewlett-Packard Technical Report, </type> <institution> HPL-SAL-89-24, </institution> <month> April </month> <year> 1989. </year>
Reference-contexts: A similar scheme in which a comparator is shared among memory words is used in the associative memory sub-system Chameleon, of the Mayfly project <ref> [13] </ref>. Also shown in Fig. 3 is a finite state machine, mask register, and memory address register. The finite state machine is the sequencer for the M-cache. It performs the necessary handshaking with the network interface, communicates with the processor, and controls/monitors all signals to/from other elements within the M-cache.
Reference: [14] <author> Ronald W. Wolff, </author> <title> Stochastic Modeling and the Theory of Queues, </title> <publisher> Prentice-Hall, </publisher> <year> 1989. </year>
Reference-contexts: For given Poisson arrival and departure rates, the queue activity is given by where p n denotes the percentage of the time the queue is of length n, represents the mean arrival rate, and denotes the mean departure rate <ref> [14] </ref>. This equation holds only if &lt; 1. In other words, the consumption rate must be faster than the production rate.
References-found: 14

