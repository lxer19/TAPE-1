URL: ftp://ftp.cs.sandia.gov/pub/papers/dewombl/parallel_io_scl93.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/pario/examples.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Out of Core, Out of Mind: Practical Parallel I/O  
Author: D. E. Womble, D. S. Greenberg, R. E. Riesen, S. R. Wheat 
Date: October 6-8, 1993,  10-16.)  
Note: (Proceedings of the Scalable Libraries Conference,  pp.  
Address: Albuquerque, NM 87185-5800  
Affiliation: Sandia National Laboratories  Mississippi State University,  
Abstract: Parallel computers are becoming more powerful and more complex in response to the demand for computing power by scientists and engineers. Inevitably, new and more complex I/O systems will be developed for these systems. In particular we believe that the I/O system must provide the programmer with the ability to explicitly manage storage (despite the trend toward complex parallel file systems and caching schemes). One method of doing so is to have a partitioned secondary storage in which each processor owns a logical disk. Along with operating system enhancements which allow overheads such as buffer copying to be avoided and libraries to support optimal remapping of data, this sort of I/O system meets the needs of high performance computing. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. M. Burns, R. H. Kuhn, and E. J. Werme, </author> <title> "Low copy message passing on the alliant CAMPUS/800", </title> <booktitle> in Proceedings of Supercomputer '92, </booktitle> <year> 1992, </year> <pages> pp. 760-769. </pages>
Reference: [2] <author> T. H. Cormen, </author> <title> "Virtual Memory for Data-Parallel Computing", </title> <type> PhD thesis, </type> <institution> MIT, </institution> <year> 1993. </year>
Reference-contexts: let n denote the size of the matrix A, M the size of memory and B the size of an I/O request across all processors, then the I/O complexities to compute the products L 1 1;1 A 1;2 , A 2;1 U 1 are O (n 3 =B M ) <ref> [2, 6, 8] </ref>. <p> When data is needed in a new format, the interconnection network can be used to reorder the data, and then write to the disks in the new format <ref> [2] </ref>. In our most efficient implementation of column-oriented LU factorization, we use two formats. The first is used for the unfactored blocks of the matrix where the matrix is stored by columns. The second is used to store intermediate results and the final (factored) matrix. <p> Many (if not most) change of format changes can be written as bit-permute-complement (BPC) or bit-matrix-multiply-complement (BMMC) transformations. These have been examined in detail in <ref> [2] </ref> and under other names by several other authors. Another task of such a library would be to transfer to or from destinations other than disk. For example, the destination might be main processor memory, a HiPPI channel or a graphics frame buffer.
Reference: [3] <author> J. M. del Rosario, R. Bordawekar, and A. Choud-hary, </author> <title> "Improving parallel I/O performance using a two-phase access strategy", </title> <type> Tech. Report SCCS-406, </type> <institution> Northeast Parallel Architectures Center, </institution> <year> 1993. </year>
Reference-contexts: Several reports have examined this issue and found that pre- or post-permutations of data lead to a substantially reduced running time for many computations <ref> [3] </ref>. Sometimes a single computation will require data in different formats for different subcomputations. At other times, the input or output interface may require data in a different format from that which is optimal for the computation. Thus the ability to convert between formats can be important.
Reference: [4] <author> G. H. Golub and C. F. Van Loan, </author> <title> Matrix Computations, </title> <publisher> Johns Hopkins University Press, </publisher> <editor> 2nd ed., </editor> <year> 1989. </year>
Reference-contexts: We also subdivide the matrices A, L and U into four submatrices and denote these submatrices with subscripts. The LU factorization algorithm can then be written as follows <ref> [4] </ref>. [L 1;1 ; U 1;1 ] = LU (A 1;1 ) 1;1 A 1;2 U 2;1 = 0 1;1 If we let n denote the size of the matrix A, M the size of memory and B the size of an I/O request across all processors, then the I/O complexities
Reference: [5] <author> B. A. Hendrickson and D. E. Womble, </author> <title> "The torus-wrap mapping for dense matrix calculations on massively parallel computers", </title> <note> SIAM J. Sci. Com-put., (to appear). </note>
Reference: [6] <author> J.-W. Hong and H. T. Kung, </author> <title> "I/O complexity: The red-blue pebble game", </title> <booktitle> in Proceedings of the Symposium on the Theory of Computing, </booktitle> <year> 1981, </year> <pages> pp. 326-332. </pages>
Reference-contexts: let n denote the size of the matrix A, M the size of memory and B the size of an I/O request across all processors, then the I/O complexities to compute the products L 1 1;1 A 1;2 , A 2;1 U 1 are O (n 3 =B M ) <ref> [2, 6, 8] </ref>.
Reference: [7] <author> A. B. Maccabe and S. R. Wheat, </author> <title> "Message passing in SUNMOS". Overview of the Sandia/University of New Mexico OS, now called PUMA., </title> <month> Jan. </month> <year> 1993. </year>
Reference-contexts: For each machine we have developed versions that run under the vendor-supplied operating systems and versions that run under PUMA, an operating system developed jointly by Sandia National laboratories and the University of New Mexico <ref> [7] </ref>, which implements PSS. The results given later in this section are taken from the nCUBE/PUMA version of the code. The status of the other implementations is as follows. * nCUBE/Vertex.
Reference: [8] <author> J. S. Vitter and E. A. M. Shriver, </author> <title> "Algorithms for parallel memory I: Two-level memories", </title> <type> Tech. Report CS-92-04, </type> <institution> Brown University, </institution> <year> 1992. </year>
Reference-contexts: let n denote the size of the matrix A, M the size of memory and B the size of an I/O request across all processors, then the I/O complexities to compute the products L 1 1;1 A 1;2 , A 2;1 U 1 are O (n 3 =B M ) <ref> [2, 6, 8] </ref>.
References-found: 8

