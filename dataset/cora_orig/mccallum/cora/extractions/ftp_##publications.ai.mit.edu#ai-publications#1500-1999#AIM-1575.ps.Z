URL: ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1575.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/nl-acq/paper-history.html
Root-URL: 
Title: A Computational Model for the Acquisition and Use of Phonological Knowledge  
Author: Kenneth Yip Gerald Jay Sussman 
Note: This publication can be retrieved by anonymous ftp to publications.ai.mit.edu. Copyright c Massachusetts Institute of Technology, 1996  
Date: 1575 March, 1996  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY  
Pubnum: A.I. Memo No.  
Abstract: Does knowledge of language consist of symbolic rules? How do children learn and use their linguistic knowledge? To elucidate these questions, we present a computational model that acquires phonological knowledge from a corpus of common English nouns and verbs. In our model the phonological knowledge is encapsulated as boolean constraints operating on classical linguistic representations of speech sounds in term of distinctive features. The learning algorithm compiles a corpus of words into increasingly sophisticated constraints. The algorithm is incremental, greedy, and fast. It yields one-shot learning of phonological constraints from a few examples. Our system exhibits behavior similar to that of young children learning phonological knowledge. As a bonus the constraints can be interpreted as classical linguistic rules. The computational model can be implemented by a surprisingly simple hardware mechanism. Our mechanism also sheds light on a fundamental AI question: How are signals related to symbols? This report describes research done at the Artificial Intelligence Laboratory of the Massachusetts Institute of Technology. Support for this research is provided in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract N00014-92-J-4097, by the National Science Foundation under grant number MIP-9001651, and by an National Science Foundation NYI Award ECS-9357773. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Berko. </author> <title> The child's learning of English morphology. Word, </title> <type> 14, </type> <year> 1958. </year>
Reference-contexts: They do not need to hear the same words repeated over and over again. They do not need to be corrected very often. The mystery deepens when we notice that children learn many new words without ever hearing them. In a classic experiment by Berko <ref> [1] </ref>, a number of English-speaking children were shown representations of a fanciful being called a "wug." When asked to say something about a situation with more than one of these beings, the children correctly pluralized the novel word to make "wugz" (not "wugs").
Reference: [2] <author> Noam Chomsky and Morris Halle. </author> <title> The Sound Pattern of English. </title> <publisher> Harper and Row, </publisher> <year> 1968. </year>
Reference-contexts: We do not attack the problem of how an acoustic waveform is processed. We start with an abstraction from linguistics (as developed by Roman Jakobson, Nikolai Trubetzkoy, Morris Halle, and Noam Chomsky) <ref> [2] </ref>: Speech sounds (phonemes) are not atomic but are encoded as combinations of more primitive structures, called distinctive features, that control the configuration of the major speech organs (such as 1 tongue, lips, and vocal cords). <p> These eight sounds are said to be [+strident]. The most widely used distinctive feature system is the one described in The Sound Pattern of English <ref> [2] </ref>. This feature system uses 14 distinctive features. Table 1 below shows the distinctive features for a subset of English vowels and consonants. Each phoneme is a particular combination of the 14 features. Languages arrive at different inventories of phonemes by using some subset of these 2 14 possibilities.
Reference: [3] <author> Harold Clahsen, Monika Rothweiler, and Andreas Woest. </author> <title> Regular and irregular inflection of German noun plurals. </title> <journal> Cognition, </journal> <volume> 45(3), </volume> <year> 1992. </year>
Reference-contexts: But there is evidence that the statistical property may not be essential to the acquisition of regular rules. For example, Marcus et. al. [7] and Clahsen <ref> [3] </ref> showed that the German -s plural behaves like a regular rule despite the fact that the rule applies to fewer than 30 common nouns. This observation raises the question of how a child can acquire regular rules from very few examples.
Reference: [4] <author> Susan Ervin. </author> <title> Imitation and structural change in childrren's language. In New Directions in the Study of Language. </title> <publisher> MIT Press, </publisher> <year> 1964. </year>
Reference-contexts: In another experiment <ref> [4] </ref>, Ervin showed that young children who first use an irregular verb properly (such as "came") would later err on the same verb (such as "comed") before they use the verb correctly again.
Reference: [5] <author> Michael Kenstowicz. </author> <title> Phonology in Generative Grammar. </title> <publisher> Blackwell Publishers, </publisher> <year> 1994. </year>
Reference-contexts: English uses 40. 2 In recent phonological theories, the distinctive features of a speech sound are not simply an unordered bundle; they are organized in a hierarchical tree structure. The hierarchical grouping of features is used to explain observed restrictions on feature combinations in phonological processes. See <ref> [5] </ref> for a discussion of some recent feature models. 5 feature [i] [ae] [k] [t] [s] [z] __________________________________________ syllabic 1 1 0 0 0 0 consonantal 0 0 1 1 1 1 sonorant 1 1 0 0 0 0 high 1 0 1 0 0 0 back 0 0 1 0
Reference: [6] <author> Brian MacWhinney and Jared Leinbach. </author> <title> Implementations are not conceptual-izations: Revising the verb learning model. </title> <journal> Cognition, </journal> <volume> 40, </volume> <year> 1991. </year>
Reference-contexts: The goal of the acquisition procedure is to compile a corpus of English words into a series of increasingly sophisticated phonological constraints. Our theory of acquisition differs significantly from those based on statistics (such as <ref> [12, 6] </ref>). The acquisition process is rather simple. It is incremental, greedy, and fast. It has almost no parameters to adjust.
Reference: [7] <author> Gary Marcus, Steven Pinker, Michael Ullman, Michelle Hollander, T. John Rosen, and Fei Xu. </author> <title> Overregularization in Language Acquisition, </title> <booktitle> volume 57. Monographs of the Society for research in child development, </booktitle> <year> 1992. </year>
Reference-contexts: The nouns are the singular and 25 plural forms of common animals and everyday objects (e.g., cat, cats, dog, dogs, cup, cups, man, men). The corpus includes most of the regular and irregular verbs used in the psycholinguistic experiments of Marcus et. al. <ref> [7] </ref> on English tenses (e.g., go, went, play, played, kick, kicked). Consistent with the observation that a human learner receives little explicit correction, the corpus contains only positive examples. <p> But there is evidence that the statistical property may not be essential to the acquisition of regular rules. For example, Marcus et. al. <ref> [7] </ref> and Clahsen [3] showed that the German -s plural behaves like a regular rule despite the fact that the rule applies to fewer than 30 common nouns. This observation raises the question of how a child can acquire regular rules from very few examples.
Reference: [8] <author> Tom Mitchell. </author> <title> Generalization as search. </title> <journal> Artificial Intelligence Journal, </journal> <volume> 18, </volume> <year> 1982. </year>
Reference-contexts: If the number of correlations of the same type (i.e. same grammar 7 A rule-classifier is applicable to a second-order correlation if its grammar and control components match those of the correlation. 8 Unlike the version space algorithm <ref> [8] </ref>, our algorithm does not maintain all the most general and most specific generalizations consistent with the current set of examples.
Reference: [9] <author> Steven Pinker. </author> <title> Rules of language. </title> <journal> Science, </journal> <volume> 253, </volume> <year> 1991. </year>
Reference-contexts: It may be the case that the linguistic representation is necessarily sparse because that is the key to making a simple, efficient, one-shot learning algorithm. Thus 11 Debate in the context of a specific problem|learning phonological knowledge|is documented in <ref> [12, 10, 9, 11] </ref>. sparseness of the representation, and the attendant possibility of symbolic description is just a consequence of the fact that human language is learnable and understandable by mechanisms that are evolvable and implementable in realistic biological systems.
Reference: [10] <author> Steven Pinker and Alan Prince. </author> <title> On language and connectionism: Analysis of a parallel distributed processing model of language acquisition. </title> <journal> Cognition, </journal> <volume> 28, </volume> <year> 1988. </year>
Reference-contexts: It may be the case that the linguistic representation is necessarily sparse because that is the key to making a simple, efficient, one-shot learning algorithm. Thus 11 Debate in the context of a specific problem|learning phonological knowledge|is documented in <ref> [12, 10, 9, 11] </ref>. sparseness of the representation, and the attendant possibility of symbolic description is just a consequence of the fact that human language is learnable and understandable by mechanisms that are evolvable and implementable in realistic biological systems.
Reference: [11] <author> Sandeep Prasada and Steven Pinker. </author> <title> Generalization of regular and irregular morphological patterns. </title> <journal> Cognition, </journal> <volume> 45(3), </volume> <year> 1992. </year>
Reference-contexts: It may be the case that the linguistic representation is necessarily sparse because that is the key to making a simple, efficient, one-shot learning algorithm. Thus 11 Debate in the context of a specific problem|learning phonological knowledge|is documented in <ref> [12, 10, 9, 11] </ref>. sparseness of the representation, and the attendant possibility of symbolic description is just a consequence of the fact that human language is learnable and understandable by mechanisms that are evolvable and implementable in realistic biological systems.
Reference: [12] <author> D Rumelhart and J.L. McClelland. </author> <title> On learning the past tenses of English verbs. In Parallel Distributed Processing: Exploration in the microstructure of cognition. </title> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: The goal of the acquisition procedure is to compile a corpus of English words into a series of increasingly sophisticated phonological constraints. Our theory of acquisition differs significantly from those based on statistics (such as <ref> [12, 6] </ref>). The acquisition process is rather simple. It is incremental, greedy, and fast. It has almost no parameters to adjust. <p> It may be the case that the linguistic representation is necessarily sparse because that is the key to making a simple, efficient, one-shot learning algorithm. Thus 11 Debate in the context of a specific problem|learning phonological knowledge|is documented in <ref> [12, 10, 9, 11] </ref>. sparseness of the representation, and the attendant possibility of symbolic description is just a consequence of the fact that human language is learnable and understandable by mechanisms that are evolvable and implementable in realistic biological systems.
Reference: [13] <author> David Waltz. </author> <title> Understanding line drawings of scenes with shadows. </title> <booktitle> In The Psychology of Computer Vision. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1975. </year>
Reference-contexts: The theory also exhibits the "Waltz" effect <ref> [13] </ref> that learning becomes more effective when the learner is exposed to more varieties of constraints. 30 Experiment 5: How irregular past tense patterns are learned This experiment aims to show what our learner can learn from irregular verbs.
Reference: [14] <author> Patrick Winston. </author> <title> Learning structural descriptions from examples. </title> <booktitle> In The Psychology of Computer Vision. </booktitle> <publisher> McGraw-Hill, </publisher> <year> 1975. </year> <month> 34 </month>
Reference-contexts: Basically the learner assumes there is only one plural form for each noun. Since it already knows [k.ae.t.s] is the correct one, [k.ae.t.z] must be wrong. Near misses, as we shall see, greatly speed up the discovery of correct generalizations. 9 9 Winston <ref> [14] </ref> emphasized the usefulness of near misses in his ARCH learning program. In our program, the near misses are not supplied by a teacher or given in the input.
References-found: 14

