URL: ftp://ftp.cs.wisc.edu/wwt/computer95_cost.ps
Refering-URL: http://www.cs.wisc.edu/~markhill/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fdavid,markhillg@cs.wisc.edu  
Title: Cost-Effective Parallel Computing  
Author: David A. Wood and Mark D. Hill 
Address: 1210 West Dayton Street Madison, WI 53706 USA  
Affiliation: Computer Sciences Department University of Wisconsin-Madison  
Note: To Appear in IEEE Computer, 1995.  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Peter J. Denning. </author> <title> Virtual Memory. </title> <journal> ACM Computing Surveys, </journal> <volume> 2(3) </volume> <pages> 153-189, </pages> <month> September </month> <year> 1970. </year>
Reference-contexts: This result may also call into question the wisdom of time-sharing large-memory jobs without considering memory-processor interaction metrics like the space-time product <ref> [1] </ref>. Related Work Few papers address the cost-effectiveness of parallel computing. Fuller [3] compared the multiprocessor CMU C.mmp (based on the DEC PDP 11/20 and 11/40 processors) with the uniprocessor DEC PDP-10.
Reference: [2] <author> Babak Falsafi and David A. Wood. </author> <title> Cost/Performance of a Parallel Computer Simulator. </title> <booktitle> In Proceedings of PADS '94, </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: He found C.mmp to be three to four times more cost-effective; however, his results were dependent upon the specific processor and (differing) memory costs of these systems. Falsafi and Wood <ref> [2] </ref> investigated the cost-effectiveness of the Wisconsin Wind Tunnel (WWT) parallel simulator. WWT runs on a Thinking Machines CM-5 (the host), but models the processors and memories of alternative cache-coherent shared-memory machines (the targets) with enough detail to run target executables. <p> Acknowledgements This work was performed as part of the Wis-consin Wind Tunnel project, which is co-led by Profs. Mark Hill, James Larus, and David Wood (http://www.cs.wisc.edu/p/wwt/Mosaic/wwt.html or ftp ftp.cs.wisc.edu; cd wwt). Babak Falsafi was a co-author of the paper that inspired this work <ref> [2] </ref>. Vi-ranjit Madan provided SGI price data. Doug Burger, Babak Falsafi, Jim Goodman, Shubu Mukherjee, David Nicol, Anne Rogers, Guri Sohi, and Jim Smith gave valuable feedback. 4
Reference: [3] <author> Samuel H. Fuller. </author> <title> Price/Performance Comparison of C.mmp and the PDP-10. </title> <booktitle> In Proc. Third International Symposium on Computer Architecture, </booktitle> <pages> pages 195-202, </pages> <month> January </month> <year> 1976. </year>
Reference-contexts: This model assumes that memory costs the same in a uniprocessor or a parallel system of any size. While this assumption seems reasonable given current technologies, marketing considerations can make parallel system memory more expensive <ref> [3] </ref>. Using this model, costup is: costup (p; m; m 0 ) = f (p) + g (m 0 ) : If memory costs are negligible, then costup is f (p). <p> This result may also call into question the wisdom of time-sharing large-memory jobs without considering memory-processor interaction metrics like the space-time product [1]. Related Work Few papers address the cost-effectiveness of parallel computing. Fuller <ref> [3] </ref> compared the multiprocessor CMU C.mmp (based on the DEC PDP 11/20 and 11/40 processors) with the uniprocessor DEC PDP-10. He found C.mmp to be three to four times more cost-effective; however, his results were dependent upon the specific processor and (differing) memory costs of these systems.
Reference: [4] <author> John L. Hennessy and David A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: This is because the parallel system does not need p times the memory of the uniprocessor, since parallelizing a job rarely multiplies its memory requirements by p. Three decades ago Amdahl argued that each million-instructions-per-second (MIPS) of processing power should be accompanied by 1 megabyte of memory <ref> [4] </ref> (p. 17). Our results can be interpreted as the converse of Amdahl's dictum: Each 1 megabyte of memory should be accompanied by 1 MIPS of processing power.
Reference: [5] <author> Ed Reidenbach. </author> <title> CHALLENGE Server Perdiodic Table. </title> <institution> Silicon Graphics Computer Systems, </institution> <month> October </month> <year> 1993. </year> <month> 5 </month>
Reference-contexts: We consider hardware costs, but not software ones since we do not know how to non-controversially measure the latter. All prices are list prices in U.S. dollars as of July 15, 1994 <ref> [5] </ref>. We ignore the volume discounts that may favor uniprocessors. Since we take the ratio of two list prices, our quantitative results also hold exactly when a vendor gives a customer the same discount on both systems. Silicon Graphics products range from low-cost desktop workstations to million-dollar shared-memory multiprocessors.
References-found: 5

