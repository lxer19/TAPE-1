URL: ftp://ftp.cscs.ch/pub/CSCS/techreports/1994/CSCS-TR-94-07.ps.gz
Refering-URL: 
Root-URL: 
Title: Design and realization of the Annai integrated parallel programming environment performance monitor and analyzer  
Author: J. N. Wylie, Akiyoshi Endo 
Address: CH-6928 Manno, Switzerland  SX-Center, Switzerland  
Affiliation: CSCS-ETH, Section of Research and Development (SeRD), Centro Svizzero di Calcolo Scientifico,  NEC  
Note: Brian  
Pubnum: CSCS-TR-94-07  Technical Report  
Email: wylie@serd.cscs.ch endo@cscs.ch  
Date: August 25, 1994  
Abstract: A portable integrated tool environment for distributed-memory parallel computers is currently being developed as part of the Joint CSCS-ETH/NEC Collaboration in Parallel Processing. As they are designed and implemented, prototypes of the compiler, debugger and performance tools are used and evaluated by a team developing applications and libraries to exploit the inherent power of parallel computers. Key design aspects of the performance monitor and analyzer component were usability, scalability and portability. Integration within a unified tool environment allows the user analyzing performance to interact with the high-level source code and distributed arrays during program execution on the same terms as when using the parallel debugger. Detailed data distribution and other program information furnished by the parallelization support and compilation systems can also be exploited for additional insight. Scalability has been considered by providing powerful, directed analysis and OSF/Motif interactive graphical displays within a familiar hierarchical framework for (C/Fortran) message-passing programs, and transformed HPF programs, using MPI for the low-level machine interface. Finally, portability is being addressed through support for a 128-processor NEC Cenju-3 parallel computer and clusters of workstations. 
Abstract-found: 1
Intro-found: 1
Reference: <institution> Acknowledgments The design and development of the Annai tool environment has been a joint effort with Christian Clemencon, </institution> <note> Josef Fritscher, </note> <author> Andreas M uller and Roland R uhl. Other project members, Karsten M. Decker, Gabriele Jost, Norio Masuda, Will Sawyer, </author> <title> Eric de Sturler and Frank Zimmermann have generously been patient while using and evaluating our prototypes. Additional tool development work directly related to PMA was also performed by Maung Ting Nyeu and Umesh Krishnaswamy during the course of the 1993 & 1994 CSCS Summer Student Internship Programs. References </title>
Reference: [CDE + 94] <author> Christian Clemencon, Karsten M. Decker, Akiyoshi Endo, Josef Fritscher, Norio Masuda, Andreas M uller, Roland R uhl, William Sawyer, Eric de Sturler, Brian J. N. Wylie, and Frank Zimmermann. </author> <title> Application-Driven Development of an Integrated Tool Environment for Distributed Memory Parallel Processors. </title> <editor> In Ramesh Rao and C. P. Ravikumar, editors, </editor> <booktitle> Proceedings of the First International Workshop on Parallel Processing (Bangalore, </booktitle> <address> India, </address> <month> December 27-30), </month> <year> 1994. </year> <note> (To appear). Also available as technical report CSCS-TR-94-01. </note>
Reference-contexts: 1 Introduction To demonstrate that comfortable programming of distributed-memory parallel computing systems using standardized programming languages is possible, the integrated tool environment `Annai' is being developed as part of the Joint CSCS-ETH/NEC Collaboration in Parallel Processing <ref> [Dec93, CDE + 94] </ref>. The environment supports high-level parallel programming based on High Performance Fortran (HPF) [HPF93], as well as low-level programming with the MPI message-passing interface [MPI94]; interactive debugging and performance analysis are possible on both levels of abstraction. <p> Use of early PMA and tool environment prototypes for development and tuning of a number of applications and benchmark kernels has been reported in <ref> [CEF + 94, CDE + 94] </ref>. 4 Example Annai/PMA User Session debugging and performance analysis. Part of the main Annai UI, the program source browser provides the central focus during these activities. The program has halted at a breakpoint previously defined by the user with PDT (now iconized).
Reference: [CEF + 94] <author> Christian Clemencon, Akiyoshi Endo, Josef Fritscher, Andreas M uller, Roland R uhl, and Brian J. N. Wylie. </author> <title> An Environment for Portable Distributed Memory Parallel Programming. </title> <booktitle> In [DR94], </booktitle> <pages> pages 159-170, </pages> <year> 1994. </year> <note> Full version available as technical report CSCS-TR-93-05. </note>
Reference-contexts: This development process has allowed rapid feedback and requests of the application developers for functionality enhancements can be immediately considered for inclusion in future tool prototypes. After a summary of the design objectives and a brief overview of the tool environment (which is described in greater detail in <ref> [CEF + 95, CEF + 94] </ref>), this paper concentrates on the detailed design and realization of the performance monitor and analyzer component. 2 Tool Environment Overview Major objectives in the design of the tool environment are summarized as follows: * User- and application-oriented tool design, through development of the tools in <p> Use of early PMA and tool environment prototypes for development and tuning of a number of applications and benchmark kernels has been reported in <ref> [CEF + 94, CDE + 94] </ref>. 4 Example Annai/PMA User Session debugging and performance analysis. Part of the main Annai UI, the program source browser provides the central focus during these activities. The program has halted at a breakpoint previously defined by the user with PDT (now iconized).
Reference: [CEF + 95] <author> Christian Clemencon, Akiyoshi Endo, Josef Fritscher, Andreas M uller, Roland R uhl, and Brian J. N. Wylie. </author> <title> The Annai Environment for Portable Distributed Parallel Programming. </title> <editor> In Hesham El-Rewini and Bruce D. Shriver, editors, </editor> <booktitle> Proceedings of the 28th Hawaii International Conference on System Sciences, Volume II (Maui, Hawaii, </booktitle> <address> USA, </address> <month> 3-6 January, </month> <title> 1995). </title> <publisher> IEEE Computer Society Press, </publisher> <month> January </month> <year> 1995. </year>
Reference-contexts: This development process has allowed rapid feedback and requests of the application developers for functionality enhancements can be immediately considered for inclusion in future tool prototypes. After a summary of the design objectives and a brief overview of the tool environment (which is described in greater detail in <ref> [CEF + 95, CEF + 94] </ref>), this paper concentrates on the detailed design and realization of the performance monitor and analyzer component. 2 Tool Environment Overview Major objectives in the design of the tool environment are summarized as follows: * User- and application-oriented tool design, through development of the tools in
Reference: [CFR94] <author> Christian Clemencon, Josef Fritscher, and Roland R uhl. </author> <title> Execution Control, Visualization and Replay of Massively Parallel Programs with Annai's Debugging Tool. </title> <type> Technical report CSCS-TR-94-09, </type> <institution> Centro Svizzero di Calcolo Scientifico, CH-6928 Manno, Switzerland, </institution> <year> 1994. </year> <note> (In preparation). </note>
Reference-contexts: Debugging of single node programs is supported at the source level through to high-level support of the parallel distributed program (mostly) presented as a single-thread. Extended functionality includes visualization of distributed data and its decomposition, and detection of deadlocks and potential race conditions. <ref> [CFR94] </ref> PMA exploits trace information from interactively specified source code regions, where instrumentation is inserted and data collected during the execution of a parallel program. It then assists with the performance tuning and interpretation of program execution through visualization and analysis of this information.
Reference: [Dec93] <author> Karsten M. Decker. </author> <title> Methods and Tools for Programming Massively Parallel Distributed Systems. </title> <journal> SPEEDUP Journal, </journal> <volume> 7(2), </volume> <month> November </month> <year> 1993. </year>
Reference-contexts: 1 Introduction To demonstrate that comfortable programming of distributed-memory parallel computing systems using standardized programming languages is possible, the integrated tool environment `Annai' is being developed as part of the Joint CSCS-ETH/NEC Collaboration in Parallel Processing <ref> [Dec93, CDE + 94] </ref>. The environment supports high-level parallel programming based on High Performance Fortran (HPF) [HPF93], as well as low-level programming with the MPI message-passing interface [MPI94]; interactive debugging and performance analysis are possible on both levels of abstraction.
Reference: [DR94] <editor> Karsten M. Decker and Rene M. Rehmann, editors. </editor> <booktitle> Proceedings of the IFIP WG10.3 Working Conference on Programming Environments for Massively Parallel Distributed Systems (Monte Verit a, </booktitle> <address> Ascona, Switzerland, April 25-29, 1994). </address> <publisher> Birkhauser (Basel, </publisher> <address> Switzerland), </address> <month> July </month> <year> 1994. </year> <note> ISBN 3-7643-5090-3. </note>
Reference: [ENW93] <author> Akiyoshi Endo, Maung Ting Nyeu, and Brian J. N. Wylie. </author> <title> MPIX Tracing Library User Guide. </title> <type> Technical Note SeRD-CSCS-TN-93-13, </type> <institution> Centro Svizzero di Calcolo Scientifico, CH-6928 Manno, Switzerland, </institution> <month> December </month> <year> 1993. </year> <title> Based on SSIP'93 internship project report. </title>
Reference-contexts: By default, no instrumentation is provided with the MPI communications library nor from PST's source analysis. Specifying appropriate compile-time flags ensures that our instrumented MPI library (MPIX <ref> [ENW93] </ref>) is used as a drop-in replacement for the non-instrumented (and optimized) one, and that PST provides additional program structure information. PST can also provide valuable information about memory utilization in a number of categories, and run-time distribution analysis and routing overheads associated with data mappings.
Reference: [GHPW90] <author> G. Al Geist, Michael T. Heath, Bruce T. Peyton, and Patrick H. Worley. </author> <title> A User's Guide to PICL: A Portable Instrumented Communication Library. </title> <type> Technical Report ORNL/TM-11616, </type> <institution> Oak Ridge National Laboratory, TN, USA, </institution> <month> October </month> <year> 1990. </year>
Reference-contexts: A library of communication tracing functions, which could be used to instrument our MPI communications library, was our first goal. The functions generate trace records in PICL format <ref> [GHPW90] </ref> for straightforward analysis and display by the public-domain trace visualization tool ParaGraph [HE91]. Similar approaches have previously been followed by Meiko with CSNgraph for their CSN communications system [Mei92] and Intel who provide ParaGraph as part of their ParAide environment [RAA + 93].
Reference: [HE91] <author> Michael T. Heath and Jennifer A. Etheridge. </author> <title> Visualizing the Performance of Parallel Programs. </title> <journal> IEEE Software, </journal> <volume> 8(5) </volume> <pages> 29-39, </pages> <month> September </month> <year> 1991. </year> <note> Technical reports and user guides available from UIUC/ORNL. </note>
Reference-contexts: A library of communication tracing functions, which could be used to instrument our MPI communications library, was our first goal. The functions generate trace records in PICL format [GHPW90] for straightforward analysis and display by the public-domain trace visualization tool ParaGraph <ref> [HE91] </ref>. Similar approaches have previously been followed by Meiko with CSNgraph for their CSN communications system [Mei92] and Intel who provide ParaGraph as part of their ParAide environment [RAA + 93].
Reference: [HPF93] <author> HPFF (High Performance Fortran Forum). </author> <title> High Performance Fortran Language Specification: Version 1.0. </title> <journal> Scientific Programming, </journal> <volume> 2(1&2), </volume> <month> June </month> <year> 1993. </year> <note> Also available as technical report CRPC-TR92225 from Rice University, </note> <institution> Houston, TX, USA. </institution>
Reference-contexts: The environment supports high-level parallel programming based on High Performance Fortran (HPF) <ref> [HPF93] </ref>, as well as low-level programming with the MPI message-passing interface [MPI94]; interactive debugging and performance analysis are possible on both levels of abstraction.
Reference: [IM94] <author> R. Bruce Irvin and Barton P. Miller. </author> <title> A Performance Tool for High-Level Parallel Programming Languages. </title> <booktitle> In [DR94], </booktitle> <pages> pages 299-313, </pages> <year> 1994. </year> <note> CSCS-TR-94-07 13 REFERENCES </note>
Reference-contexts: Significant research areas are also planned for investigation in later prototypes. One such aspect concerns the provision of a performance break-down related to operations on distributed arrays, similar to that described in <ref> [IM94] </ref>, based on tagged data movements provided by the compilation system. The quantification of instrumentation intrusion is important for usability, and it should also allow for intrusion compensation and eventual minimization.
Reference: [Kri94] <author> Umesh Krishnaswamy. </author> <title> Program Structure Browser for the Annai Integrated Tool Environment. </title> <type> Technical Note SeRD-CSCS-TN-94-17, </type> <institution> Centro Svizzero di Calcolo Scientifico, CH-6928 Manno, Switzerland, </institution> <month> October </month> <year> 1994. </year> <note> SSIP'94 internship project report. </note>
Reference-contexts: Annai's UI also provides a program structure browser <ref> [Kri94] </ref>, which displays structural information about the current program in a concise, customizable format. Figure 3 shows this display, with the central part containing a representation of example application routine interp with its first loop opened to reveal internal structure.
Reference: [Mei92] <institution> Meiko Ltd., Bristol, UK. </institution> <month> CSNgraph: </month> <title> A Tool for Visualising Performance of Parallel Programs, 1992. Part of the CSTools manual set. </title>
Reference-contexts: The functions generate trace records in PICL format [GHPW90] for straightforward analysis and display by the public-domain trace visualization tool ParaGraph [HE91]. Similar approaches have previously been followed by Meiko with CSNgraph for their CSN communications system <ref> [Mei92] </ref> and Intel who provide ParaGraph as part of their ParAide environment [RAA + 93]. Complementary publicly-available experimental toolkits can also be exploited to provide additional analysis and visualization support, based on processed trace files, such as Pablo [ROA + 91] and AIMS VK [Yan94].
Reference: [MPI94] <author> MPIF (Message Passing Interface Forum). </author> <title> MPI: A Message-Passing Interface Standard. </title> <type> Technical Report CS-94-230, </type> <institution> University of Tennessee, Knoxville, TN, USA, </institution> <month> April </month> <year> 1994. </year> <journal> (To appear in the International Journal of Supercomputer Applications, </journal> <volume> Vol. 8, No. 3/4, </volume> <year> 1994). </year>
Reference-contexts: The environment supports high-level parallel programming based on High Performance Fortran (HPF) [HPF93], as well as low-level programming with the MPI message-passing interface <ref> [MPI94] </ref>; interactive debugging and performance analysis are possible on both levels of abstraction. Validation of this approach, and testing the usability of the tools, is achieved through the design and implementation of a sequence of prototypes which are used and evaluated by a team of application developers.
Reference: [MR94] <author> Andreas M uller and Roland R uhl. </author> <title> Extending High Performance Fortran for the Support of Unstructured Computations. </title> <type> Technical report CSCS-TR-94-08, </type> <institution> Centro Svizzero di Calcolo Scientifico, CH-6928 Manno, Switzerland, </institution> <year> 1994. </year> <note> (In preparation). </note>
Reference-contexts: PST aims to provide extensive run-time support for scientific applications currently considered difficult to parallelize on massively parallel distributed systems. <ref> [MR94] </ref> Working as a preprocessor on source programs, the application sources are instrumented to generate both debugging information for PDT and performance information for PMA. PDT allows debugging at different levels of abstraction.
Reference: [RAA + 93] <author> Bernhard Ries, Ray Anderson, W. Auld, Don Breazeal, Karla Callaghan, Eric Richards, and W. D. Smith. </author> <title> The Paragon Performance Monitoring Environment. </title> <booktitle> In Proceedings of Supercomputing'93 (Portland, </booktitle> <address> Oregon, USA, </address> <month> November 15-19), </month> <pages> pages 850-859. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1993. </year> <note> ParAide manuals also available from Intel SSD, </note> <institution> Beaverton, </institution> <address> OR, USA. </address>
Reference-contexts: The functions generate trace records in PICL format [GHPW90] for straightforward analysis and display by the public-domain trace visualization tool ParaGraph [HE91]. Similar approaches have previously been followed by Meiko with CSNgraph for their CSN communications system [Mei92] and Intel who provide ParaGraph as part of their ParAide environment <ref> [RAA + 93] </ref>. Complementary publicly-available experimental toolkits can also be exploited to provide additional analysis and visualization support, based on processed trace files, such as Pablo [ROA + 91] and AIMS VK [Yan94].
Reference: [ROA + 91] <author> Daniel A. Reed, Robert D. Olsen, Ruth A. Aydt, Tara M. Madhyastha, Thomas Birkett, David W. Jensen, Bobby A. A. Nazief, and Brian K. Totty. </author> <title> Scalable Performance Environments for Parallel Systems. </title> <editor> In Quentin Stout and Michael Wolfe, editors, </editor> <booktitle> Proceedings of the Sixth Distributed Memory Computing Conference (April 28 May 1, Portland, Oregon), </booktitle> <pages> pages 562-569. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1991. </year> <note> Pablo documentation and reports also available from the Dept. </note> <institution> of Computer Science, University of Illinois at Urbana-Champaign, IL, USA. </institution>
Reference-contexts: Complementary publicly-available experimental toolkits can also be exploited to provide additional analysis and visualization support, based on processed trace files, such as Pablo <ref> [ROA + 91] </ref> and AIMS VK [Yan94]. Linking with the instrumented communications library automatically enabled a complete execution trace to be collected when the program was run.
Reference: [SAB + 92] <author> Steve Sistare, Don Allen, Rich Bowker, Karen Jourdenais, Josh Simons, and Rich Title. </author> <title> Data Visualization and Performance Analysis in the Prism Programming Environment. </title> <editor> In Nigel Topham, Roland Ibbett, and Thomas Bemmerl, editors, </editor> <booktitle> Programming Environments for Parallel Computing, </booktitle> <pages> pages 37-52. </pages> <publisher> North-Holland, </publisher> <year> 1992. </year> <title> Additional documentation available from Thinking Machines Corp., </title> <address> Cambridge, MA, USA. </address>
Reference-contexts: Tools such as Thinking Machines' Prism environment <ref> [SAB + 92] </ref> and Cray Research's MPP Apprentice [WHP94] are extremely usable and powerful in this regard. A simple example of this is an execution summary framed in terms of the program routine structure, similar to a standard profile, e.g., such as those of the standard Unix prof tool family.
Reference: [WHP94] <author> Winifred Williams, Tim Hoel, and Doug Pase. </author> <title> The MPP Apprentice performance tool. </title> <booktitle> In [DR94], </booktitle> <pages> pages 333-345, </pages> <year> 1994. </year> <institution> Additional information available from Cray Research Inc., Eagan, MN, USA. </institution>
Reference-contexts: Tools such as Thinking Machines' Prism environment [SAB + 92] and Cray Research's MPP Apprentice <ref> [WHP94] </ref> are extremely usable and powerful in this regard. A simple example of this is an execution summary framed in terms of the program routine structure, similar to a standard profile, e.g., such as those of the standard Unix prof tool family.
Reference: [Yan94] <author> Jerry C. Yan. </author> <title> Performance Tuning with AIMS An Automated Instrumentation and Monitoring System for Multicomputers. </title> <editor> In Hesham El-Rewini and Bruce D. Shriver, editors, </editor> <booktitle> Proceedings of the 27th Hawaii International Conference on System Sciences (Volume II), </booktitle> <pages> pages 625-633. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1994. </year> <note> 14 CSCS-TR-94-07 </note>
Reference-contexts: Complementary publicly-available experimental toolkits can also be exploited to provide additional analysis and visualization support, based on processed trace files, such as Pablo [ROA + 91] and AIMS VK <ref> [Yan94] </ref>. Linking with the instrumented communications library automatically enabled a complete execution trace to be collected when the program was run. Additional trace control functions incorporated within the same library enabled direct control of tracing and how traces were buffered and processed prior to transfer to ParaGraph.
References-found: 21

