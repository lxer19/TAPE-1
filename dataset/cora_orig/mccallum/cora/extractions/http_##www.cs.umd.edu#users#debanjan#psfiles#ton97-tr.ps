URL: http://www.cs.umd.edu/users/debanjan/psfiles/ton97-tr.ps
Refering-URL: http://www.cs.umd.edu/users/debanjan/pages/onepage.html
Root-URL: 
Email: fwuchang,kgshing@eecs.umich.edu fkandlur,debanjang@watson.ibm.com  
Title: On Providing Minimum Rate Guarantees over the Internet  
Author: Wu-chang Fengy Dilip D. Kandlurz Debanjan Sahaz Kang G. Shiny 
Keyword: Index Terms|Integrated services Internet, controlled-load service, TCP, traffic management, queue  
Note: management for QoS  
Address: Ann Arbor, MI 63130 Yorktown Heights, NY 10598  
Affiliation: yDepartment of EECS zNetwork Systems Department University of Michigan IBM T.J. Watson Research Center  
Abstract: A large number of Internet applications are sensitive to overload conditions in the network. While these applications have been designed to adapt somewhat to the varying conditions in the Internet, they can benefit greatly from an increased level of predictability in network services. We propose minor extensions to the packet queueing and discard mechanisms used in routers, coupled with simple control mechanisms at the source that enable the network to guarantee minimal levels of throughput to different sessions while sharing the residual network capacity in a cooperative manner. The service realized by the proposed mechanisms is an interpretation of the controlled-load service being standardized by the ietf. Although controlled-load service can be used in conjunction with any transport protocol, our focus in this paper is on understanding its interaction with tcp. Specifically, we study the dynamics of tcp traffic in an integrated services network that simultaneously supports both best-effort and controlled-load sessions. In light of this study, we propose and experiment with several variations to tcp's control mechanisms with the objective of fine-tuning them for an integrated services environment. We then investigate the effect of network transients, such as changes in traffic load and in service levels, on the performance of controlled-load as well as best-effort connections. To capture the evolution of integrated services in the Internet, we also consider situations where only a selective set of routers are capable of providing service differentiation between best-effort and controlled-load traffic. Finally, we show how the service mechanisms proposed here can be embedded within more elaborate packet and link scheduling frameworks in a fully-evolved integrated services Internet. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Braden, D. Clark, and S. Shenker. </author> <title> Integrated Services in the Internet Architecture: An Overview. </title> <type> RFC 1633, </type> <month> June </month> <year> 1994. </year> <month> ISI/MIT/PARC. </month>
Reference-contexts: 1 Introduction A large class of Internet applications, referred to as tolerant playback applications in <ref> [1, 16] </ref>, can greatly benefit from an increased level of predictability in network services. These applications typically buffer a portion of the data on the client before starting the playback, and then operate in a streaming mode to prevent buffer underflow. <p> Shin were supported in part by the Office of Naval Research under Grant N00014-94-1-0229. of throughput at all times, but allows for the possibility of higher throughput during periods of light loads. Such a service is also useful to more traditional, elastic applications <ref> [1, 16] </ref>, such as ftp and telnet. Tasks such as booting a disk-less workstation over the network, backing up remote files, and synchronizing web proxies can be performed with more predictability and within a bounded time by guaranteeing a minimal bandwidth to the underlying sessions. <p> For a systematic deployment of the full portfolio of services in the Internet, a number of sophisticated mechanisms, such as class-based queueing [5] and weighted fair queueing <ref> [1, 2, 6, 7, 15-17] </ref>, have been proposed. In Section 8, we discuss how the ered mechanism can be embedded in a more elaborate packet queueing and scheduling architecture. 3 Understanding TCP Dynamics This section is devoted to the study of tcp dynamics in an integrated services environment. <p> The queues are serviced in different priority order based on the allocation given to the associated traffic class. The use of per-session fair queueing mechanisms, including the weighted fair queueing (wfq) <ref> [1, 2, 6, 7, 15-17] </ref>, has also been considered in this context. One possible way to realize controlled-load service is to treat each controlled-load connection as a separate session and reserve a rate of service commensurate with its Tspec.
Reference: [2] <author> A. Demers, S. Keshav, and S. Shenker. </author> <title> Analysis and Simulation of Fair Queuing Algorithm. </title> <booktitle> In Proceedings of SIGCOMM, </booktitle> <year> 1989. </year>
Reference-contexts: For a systematic deployment of the full portfolio of services in the Internet, a number of sophisticated mechanisms, such as class-based queueing [5] and weighted fair queueing <ref> [1, 2, 6, 7, 15-17] </ref>, have been proposed. In Section 8, we discuss how the ered mechanism can be embedded in a more elaborate packet queueing and scheduling architecture. 3 Understanding TCP Dynamics This section is devoted to the study of tcp dynamics in an integrated services environment. <p> The queues are serviced in different priority order based on the allocation given to the associated traffic class. The use of per-session fair queueing mechanisms, including the weighted fair queueing (wfq) <ref> [1, 2, 6, 7, 15-17] </ref>, has also been considered in this context. One possible way to realize controlled-load service is to treat each controlled-load connection as a separate session and reserve a rate of service commensurate with its Tspec.
Reference: [3] <author> W. Feng, D. Kandlur, D. Saha, and K. Shin. </author> <title> TCP Enhancements for an Integrated Services Internet. </title> <type> Technical Report RC 20618, </type> <institution> IBM Research, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: In addition, this scheme reduces the probability of the packets getting dropped inside the network since holding back packets increases the probability that they are sent as marked packets. While the delayed transmissions work reasonably well when the reverse path is lightly-loaded <ref> [3] </ref>, additional experiments have 9 (a) Aggregate and compliant throughput. (b) Share of Excess Bandwidth. shown that it is not very effective in the presence of reverse path congestion. The second mechanism we examine involves the use of a periodic timer.
Reference: [4] <author> S. Floyd and V. Jacobson. </author> <title> Random Early Detection Gateways for Congestion Avoidance. </title> <journal> ACM/IEEE Transactions on Networking, </journal> <volume> 1(4) </volume> <pages> 397-413, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: In this scheme, each reserved session is associated with a traffic envelope. Traffic is policed at the source and packets conforming to the envelope are marked. Non-conformant traffic and best-effort traffic is injected into the network unmarked. At the routers we use an enhanced random early detection (red) <ref> [4] </ref> and discard mechanism. Both marked and unmarked packets share the same fifo queue. When the queue length at the router exceeds a certain threshold, packets are dropped randomly as done in red gateways. <p> Enhanced Random Early Detection (ered) is a minor modification to the original red algorithm. In ered, the drop probabilities of marked packets are lower than that of unmarked packets. Studies have shown that red gateways are better than traditional drop-tail routers in terms of fairness to bursty traffic <ref> [4] </ref>. It can also be parameterized to control the queue size, and hence, the queueing delay. Note that ered guarantees low loss rate to conformant controlled-load traffic. However, since it uses a common fifo queue, the queueing delay experienced by the conformant controlled-load traffic and best-effort traffic are the same.
Reference: [5] <author> S. Floyd and V. Jacobson. </author> <title> Link-sharing and Resource Management Models for Packet Networks. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 3(4), </volume> <month> August </month> <year> 1995. </year>
Reference-contexts: Our objective is to study how we can offer a particularly useful network service with minimal changes to the routers and the end-hosts. For a systematic deployment of the full portfolio of services in the Internet, a number of sophisticated mechanisms, such as class-based queueing <ref> [5] </ref> and weighted fair queueing [1, 2, 6, 7, 15-17], have been proposed. <p> In this section, we examine the different approaches to traffic management in the Internet and the role the ered mechanism can play in such an environment. Class-based queueing (cbq) <ref> [5] </ref> is one of the most popular mechanisms proposed for packet and link scheduling in an integrated services Internet. In cbq, datagrams belonging to different classes are put in 17 (a) Network Topology. (b) Throughput. different queues in the routers.
Reference: [6] <author> S. Golestani. </author> <title> A Self-Clocked Fair Queuing Scheme for Broadband Applications. </title> <booktitle> In Proceedings of INFOCOM, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: For a systematic deployment of the full portfolio of services in the Internet, a number of sophisticated mechanisms, such as class-based queueing [5] and weighted fair queueing <ref> [1, 2, 6, 7, 15-17] </ref>, have been proposed. In Section 8, we discuss how the ered mechanism can be embedded in a more elaborate packet queueing and scheduling architecture. 3 Understanding TCP Dynamics This section is devoted to the study of tcp dynamics in an integrated services environment. <p> The queues are serviced in different priority order based on the allocation given to the associated traffic class. The use of per-session fair queueing mechanisms, including the weighted fair queueing (wfq) <ref> [1, 2, 6, 7, 15-17] </ref>, has also been considered in this context. One possible way to realize controlled-load service is to treat each controlled-load connection as a separate session and reserve a rate of service commensurate with its Tspec.
Reference: [7] <author> P. Goyal, H. Vin, and H. Cheng. </author> <title> Start-time Fair Queuing: A Scheduling Algorithm for Integrated Services Packet Switching Networks. </title> <booktitle> In Proceedings of ACM SIGCOMM, </booktitle> <pages> pages 157-168, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: For a systematic deployment of the full portfolio of services in the Internet, a number of sophisticated mechanisms, such as class-based queueing [5] and weighted fair queueing <ref> [1, 2, 6, 7, 15-17] </ref>, have been proposed. In Section 8, we discuss how the ered mechanism can be embedded in a more elaborate packet queueing and scheduling architecture. 3 Understanding TCP Dynamics This section is devoted to the study of tcp dynamics in an integrated services environment. <p> The queues are serviced in different priority order based on the allocation given to the associated traffic class. The use of per-session fair queueing mechanisms, including the weighted fair queueing (wfq) <ref> [1, 2, 6, 7, 15-17] </ref>, has also been considered in this context. One possible way to realize controlled-load service is to treat each controlled-load connection as a separate session and reserve a rate of service commensurate with its Tspec.
Reference: [8] <author> R. Goyal, R. Jain, S. Kalyanaraman, and S. Fahmy. UBR+: </author> <title> Improving Performance of TCP over ATM-UBR Service. </title> <note> Submitted to ICC 1997: http://www.cis.ohio-state.edu/ jain/icc97.ps, </note> <year> 1996. </year>
Reference-contexts: Integrated services in the Internet is a relatively new area of research. To the best of our knowledge, no published work addresses the specific issues discussed in this paper. In a more general sense, studies on supporting tcp over abr/ubr services in atm networks <ref> [8, 13] </ref> address similar issues. However, due to significant differences between the service architectures of atm and the Internet, the nature and the focus of these studies are quite different. <p> In a more general sense, studies on supporting tcp over abr/ubr services in atm networks [8, 13] address similar issues. However, due to significant differences between the service architectures of atm and the Internet, the nature and the focus of these studies are quite different. In <ref> [8] </ref>, the authors propose using a modified switch buffer allocation policy in order to obtain peak throughput and fairness among tcp connections over atm. In particular, 2 each connection is effectively provided with a weighted fair share of the buffers in the switch.
Reference: [9] <author> J. C. Hoe. </author> <title> Improving the Start-up Behavior of a Congestion Control Scheme for TCP. </title> <booktitle> In Proceedings of ACM SIGCOMM, </booktitle> <pages> pages 270-280, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: While the simulator does not use production tcp code, it implements congestion and error control algorithms used in different implementations of tcp with remarkable accuracy. For most of the experiments reported here, we use a Reno-variant of tcp <ref> [9] </ref>. We modified the simulator by adding policing and extending the red queueing discipline. For the experiments in this section, we consider a simple network topology shown in Figure 1. The capacity of each bi-directional link is labeled and has a transmission delay of 10ms.
Reference: [10] <author> V. Jacobson. </author> <title> Congestion Avoidance and Control. </title> <booktitle> In Proceedings of ACM SIGCOMM, </booktitle> <pages> pages 314-329, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: As shown in the figure, the bandwidth received by the connection reacts slowly to increases in the reservation while it reacts quickly to the decrease in reservation. This is directly attributed to the additive increase/multiplicative decrease property of tcp's windowing algorithm <ref> [10] </ref>. Figure 10 (b) shows the congestion window trace for the normal tcp source. The graph shows the congestion window linearly increasing in response to an increase in reservation level at times t=0s, t=40s, and t=80s.
Reference: [11] <author> V. Jacobson, R. Braden, and D. </author> <title> Borman. TCP Extensions for High Performance. Internet Draft draft-ietf-tcplw-high-performance-00.txt, </title> <month> February </month> <year> 1997. </year> <month> LBL/ISI/BSDI. </month>
Reference-contexts: Note that the reserved part of cwnd is a function of the round-trip time. While we currently use the common tcp round-trip measurements to estimate this, measurements using the proposed tcp timestamps option (rttm) <ref> [11] </ref> can provide a more accurate estimate. Let us assume that the size of the reservation window is rwnd. Hence, the size of the variable window is cwnd-rwnd.
Reference: [12] <author> S. McCanne and S. Floyd. </author> <title> http://www-nrg.ee.lbl.gov/ns/. ns-LBNL Network Simulator, </title> <year> 1996. </year>
Reference-contexts: For the purpose of the experiments, we modified the ns <ref> [12] </ref> simulator. The ns simulator has been used extensively in a number of studies reported in the literature. While the simulator does not use production tcp code, it implements congestion and error control algorithms used in different implementations of tcp with remarkable accuracy.
Reference: [13] <author> P. Mishra. </author> <title> Effect of Leaky Bucket Policing on TCP over ATM performance. </title> <booktitle> In Proceedings of ICC, </booktitle> <year> 1996. </year>
Reference-contexts: Integrated services in the Internet is a relatively new area of research. To the best of our knowledge, no published work addresses the specific issues discussed in this paper. In a more general sense, studies on supporting tcp over abr/ubr services in atm networks <ref> [8, 13] </ref> address similar issues. However, due to significant differences between the service architectures of atm and the Internet, the nature and the focus of these studies are quite different.
Reference: [14] <author> E. Rathgeb. </author> <title> Modeling and Performance Comparison of Policing Mechanisms for ATM Networks. </title> <journal> IEEE Journal on Selected Areas of Communication, </journal> <volume> 9(3), </volume> <year> 1991. </year>
Reference-contexts: The service priority given to 3 a packet is a function of the Tspec, and in the case of some service classes, a separate service specification known as Rspec. For controlled-load service, no Rspec is specified. In order to police traffic at the source, we use token buckets <ref> [14] </ref>. The token generation process follows the Tspec advertised by the source. That is, the long-term average rate of token generation is t m , the short-term peak rate of token generation is t p , and the depth of the token bucket is b.
Reference: [15] <author> J. Rexford, A. Greenberg, and F. Bonomi. </author> <title> Hardware-Efficient Fair Queueing Architecture for High-Speed Networks. </title> <booktitle> In Proceedings of INFOCOM, </booktitle> <month> March </month> <year> 1996. </year>
Reference: [16] <author> S. Shenker, D. Clark, and L. Zhang. </author> <title> A Scheduling Service Model and a Scheduling Architecture for an Integrated Services Packet Network. </title> <type> Unpublished, </type> <year> 1993. </year>
Reference-contexts: 1 Introduction A large class of Internet applications, referred to as tolerant playback applications in <ref> [1, 16] </ref>, can greatly benefit from an increased level of predictability in network services. These applications typically buffer a portion of the data on the client before starting the playback, and then operate in a streaming mode to prevent buffer underflow. <p> Shin were supported in part by the Office of Naval Research under Grant N00014-94-1-0229. of throughput at all times, but allows for the possibility of higher throughput during periods of light loads. Such a service is also useful to more traditional, elastic applications <ref> [1, 16] </ref>, such as ftp and telnet. Tasks such as booting a disk-less workstation over the network, backing up remote files, and synchronizing web proxies can be performed with more predictability and within a bounded time by guaranteeing a minimal bandwidth to the underlying sessions.
Reference: [17] <author> M. Shreedhar and G. Varghese. </author> <title> Efficient Fair Queuing using Deficit Round Robin. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 4(3), </volume> <month> June </month> <year> 1996. </year>
Reference: [18] <author> J. Wroclawski. </author> <title> Specification of controlled-load network element service. Internet Draft draft-ietf-intserv-ctrl-load-svc-04.txt, November 1996. </title> <publisher> MIT. </publisher>
Reference-contexts: This service can also be used to set up a virtual overlay network in the Internet, connecting business-critical servers and clients with virtual links of a minimum guaranteed bandwidth. The controlled-load service <ref> [18] </ref> currently being standardized by the Internet Engineering Task Force (ietf) fits very well into the scenarios sketched above. It is part of an ambitious goal of defining a service architecture that is suitable for a diversity of applications.
Reference: [19] <author> L. Zhang, S. Shenker, and D. Clark. </author> <title> Observations on the Dynamics of a Congestion Control Algorithm: The Effects of Two-Way Traffic. </title> <booktitle> In Proceedings of ACM SIGCOMM, </booktitle> <pages> pages 133-148, </pages> <month> August </month> <year> 1991. </year> <month> 20 </month>
Reference-contexts: Another cause for token loss is the presence of persistent gaps in the acknowledgment stream. Such gaps are part of a phenomenon commonly referred to as ack-compression <ref> [19] </ref>. Since tcp uses acknowledgments to trigger transmissions, any significant time gap between the receipt of successive acknowledgments causes the token bucket to overflow and results in a loss of transmission credits.
References-found: 19

