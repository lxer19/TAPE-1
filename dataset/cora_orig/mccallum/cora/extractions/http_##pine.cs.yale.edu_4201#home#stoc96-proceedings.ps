URL: http://pine.cs.yale.edu:4201/home/stoc96-proceedings.ps
Refering-URL: http://pine.cs.yale.edu:4201/home/modular-abstract.html
Root-URL: http://www.cs.yale.edu
Email: Email: aspnes-james@cs.yale.edu  E-Mail: waarts@cs.berkeley.edu  
Title: Modular Competitiveness for Distributed Algorithms  
Author: James Aspnes Orli Waarts 
Note: Supported by NSF grants CCR-9410228 and CCR-9415410.  Supported in part by an NSF postdoctoral fellowship.  
Address: Prospect Street/P.O. Box 208285, New Haven CT 06520-8285.  
Affiliation: Yale University, Department of Computer Science, 51  Computer Science Division, U. C. Berkeley.  
Abstract: We define a novel measure of competitive performance for distributed algorithms based on throughput, the number of tasks that an algorithm can carry out in a fixed amount of work. An important property of the throughput measure is that it is modular: we define a notion of relative competitiveness with the property that a k-relatively competitive implementation of an object T using a subroutine U , combined with an l-competitive implementation of U , gives a kl-competitive algorithm for T . We prove the throughput-competitiveness of an algorithm for a fundamental building block of many well-known distributed algorithms: the cooperative collect primitive. This permits a straightforward construction of competitive versions of these algorithms| the first examples of algorithms obtained through a general method for modular construction of competitive distributed algorithms. Moreover, we provide a lower bound that shows that the throughput competitiveness of the cooperative collect algorithm we study is nearly optimal. Thus, we see our paper as making two main contributions: one is the introduction of a modular measurement for competitiveness, whose interest is justified by the throughput competitiveness of the cooperative collect algorithms; and the other is a technique for proving throughput competitiveness, which may apply to other distributed problems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Abrahamson. </author> <title> On achieving consensus using a shared memory. </title> <booktitle> In Proc. 7th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 291-302, </pages> <month> August </month> <year> 1988. </year>
Reference: [2] <author> Y. Afek, H. Attiya, D. Dolev, E. Gafni, M. Merritt, and N. Shavit. </author> <title> Atomic Snapshots of Shared Memory. </title> <journal> In Journal of the ACM, </journal> <volume> Vol. 40, No. 4, </volume> <pages> pages 872-890, </pages> <month> September </month> <year> 1993. </year> <title> Preliminary version appears in Proc. </title> <booktitle> 9th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 1-13, </pages> <year> 1990. </year>
Reference-contexts: Examples include snap shot algorithms <ref> [2, 5, 8, 11, 13, 23] </ref>, the bounded round numbers abstraction [29], concurrent timestamping systems [25, 28, 32, 34, 35, 40], and time-lapse snapshot [28]. Here we elaborate on some simple examples. Atomic snapshots. <p> Snapshot objects are very useful tools for constructing more complicated shared-memory algorithms, and they have been extensively studied <ref> [2, 5, 8, 11, 23] </ref> culminating in the protocol of Attiya and Rachman [13] which uses only O (log n) alternating writes and collects to complete a scan-update operation. We will apply Theorem 3 to get a competitive snapshot. Let T be a snapshot object and U a write-collect object.
Reference: [3] <author> M. Ajtai, J. Aspnes, C. Dwork, and O. Waarts. </author> <title> A theory of competitive analysis for distributed algorithms. </title> <booktitle> In Proc. 33rd IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 401-411, </pages> <month> November </month> <year> 1994. </year> <note> Full version available. </note>
Reference-contexts: The additional handicap imposed on the on-line distributed algorithm is that it is evaluated against the off-line algorithm that does not pay for overhead of control needed to make an intelligent decision. Ajtai, Aspnes, Dwork, and Waarts <ref> [3] </ref> argued that in some cases a more refined measure is necessary, and that to achieve this the handicap of incomplete system information should be imposed not only on the distributed on-line algorithm but also on the optimal algorithm with which the on-line algorithm is compared. <p> If each process reads every register, then this condition is trivially satisfied; however, this algorithm will perform a lot of redundant work when 2 Much of this discussion is taken from <ref> [3] </ref>. there is high concurrency. <p> Thus the competitive measure of [17, 19] does not allow one to distinguish between the nave algorithm and algorithms that totally dominate it. Competitive Latency. Observing the above was what led <ref> [3] </ref> to define a competitive measure for distributed algorithms, called latency competitiveness. The competitiveness presented in [3] allows such a distinction, i.e. between the nave cooperative collect algorithm and algorithms that dominate it. <p> Thus the competitive measure of [17, 19] does not allow one to distinguish between the nave algorithm and algorithms that totally dominate it. Competitive Latency. Observing the above was what led <ref> [3] </ref> to define a competitive measure for distributed algorithms, called latency competitiveness. The competitiveness presented in [3] allows such a distinction, i.e. between the nave cooperative collect algorithm and algorithms that dominate it. To characterize the behavior of an algorithm over a range of possible schedules they define the competitive latency of an algorithm. <p> Using the trivial collect algorithm, even if n processes perform collects concurrently, there are a total of n 2 reads, i.e. the collective latency of the trivial algorithm is O (n 2 ). <ref> [3] </ref> presents the first algorithms that cross this barrier. Their principal technical achievement is providing these nontrivial bounds on the collective latency of their algorithms. The techniques they present offer rather deep insight into the combinatorial structure of the problem and may be of more general use. <p> Their principal technical achievement is providing these nontrivial bounds on the collective latency of their algorithms. The techniques they present offer rather deep insight into the combinatorial structure of the problem and may be of more general use. Competitive analysis and modularity. The Ajtai et al. <ref> [3] </ref> approach was successful: it distinguishes between the naive algorithm and faster cooperative collect algorithms; moreover, they provide such faster cooperative collect algorithms. <p> The competitive latency model of <ref> [3] </ref> applies the same input and schedule to both the on-line and the off-line algorithms. <p> As mentioned above, the principal technical difficulty of Ajtai et al. <ref> [3] </ref> was bounding the collective latency of their cooperative collects. They used this bound in order to provide a bound on the competitive latency of the cooperative collects. To use a bound on collective latency in order to bound the throughput competitiveness, one needs new, nontrivial ideas. <p> One way to do this is to join cheap operations to succeeding expensive operations. An example of this technique is given by the write-collect primitive described in Section 5. a slightly stronger primitive, a write-collect. For the fastest algorithm of <ref> [3] </ref> our result gives a throughput competitive ratio of O (n 3=4 log 2 n). This is high, but the algorithms of [3] are the only ones that cross the trivial bound of O (n) and hence the fastest current algorithms available. <p> An example of this technique is given by the write-collect primitive described in Section 5. a slightly stronger primitive, a write-collect. For the fastest algorithm of <ref> [3] </ref> our result gives a throughput competitive ratio of O (n 3=4 log 2 n). This is high, but the algorithms of [3] are the only ones that cross the trivial bound of O (n) and hence the fastest current algorithms available. Moreover we show that they are nearly optimal: no cooperative collect algorithm can obtain a throughput competitiveness better than ( p n). <p> Currently throughput competitiveness, introduced here, is the most refined measure for evaluating throughput of distributed algorithms: the standard worst case measure and the approach of comparing a distributed algorithm with an ideal global control algorithm, will both give (n) performance; and as described above the measure of <ref> [3] </ref> does not allow modularity. <p> does a write followed by n reads.) The write-collect operation is motivated by the fact that many shared-memory algorithms execute collects interspersed with write operations (some examples are given in Section 8. 6 A Throughput-Competitive Implementation of Write-Collect To implement a write-collect we start with the cooperative collect algorithm of <ref> [3] </ref>. This algorithm has several desirable properties: 1. All communication is through a set of single-writer registers, one for each process, and the first operation of the cooperative collect is a write operation. 2. No collect operation ever requires more than 2n steps to complete. 3. <p> For any schedule, and any set of collects that are in progress at some time t, there is a bound on the total number of steps required to complete these collects. (Showing this bound is nontrivial; a proof can be found in <ref> [3] </ref>). These properties are what we need from a cooperative collect implementation to prove that it gives a throughput-competitive write-collect. <p> In effect, our throughput-competitive write-collect algorithm is simply the latency-competitive collect of <ref> [3] </ref>, augmented by merging the write in a write-collect with the first write done as part of the collect implementation. <p> If this quantity is bounded for all , p, and t, denote the bound by UPL (A). Similarly, given an algorithm A, the collective latency at time t is defined <ref> [3] </ref> as the sum over all processes p of the private latency for p at time t, and is denoted by CL (A; t). If this quantity is bounded for all A and , denote the bound by UCL (A). <p> If this quantity is bounded for all A and , denote the bound by UCL (A). Note that UCL (A) may be much smaller than n UPL (A) as concurrent processes may cooperate to finish their collects quickly; for example, in the cooperative collect protocol of <ref> [3] </ref>, UPL = 2n but UCL = O (n 3=2 log 2 n). We denote by FCTh p (A; t) the fractional collective throughput in algorithm A of a process p at point t in time, and define it inductively as follows. <p> The theorem can be applied to give an immediate upper bound on the throughput-competitiveness of any cooperative collect algorithm A for which the private and collective latencies are always bounded. For example, plugging the bounds on the private and collective latencies of the faster algorithm of <ref> [3] </ref> into the formula in Theorem 7, it immediately follows that this algorithm is O (n 3=4 log 2 n)-throughput-competitive. <p> This bound is the first to cross the trivial n bound, and, as implied by the lower bound of the following section, this bound is nearly optimal. (A similar discussion applies to the slower algorithm of <ref> [3] </ref>.) 7 Lower Bound on Throughput Competitiveness of Collect Theorem 8 No cooperative collect protocol has a throughput competitiveness less than ( p Sketch of Proof: To overcome the additive constant, we build up an arbitrarily-long schedule out of phases, where in each phase the ratio of champion to candidate collects
Reference: [4] <author> N. Alon, G. Kalai, M. Ricklin, and L. Stockmeyer. </author> <title> Lower bounds on the competitive ratio for mobile user tracking and distributed job scheduling. </title> <booktitle> In Proc. 33rd IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 334-343, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Awerbuch, Kutten, and Peleg [17], and Bartal, Fiat, and Rabani [19] took the first steps in this direction. Their work was in the context of job scheduling and data management. In these papers, and in subsequent work <ref> [4, 14, 15, 21] </ref>, the cost of a distributed on-line algorithm 1 is compared to the cost of an optimal global 1 Because most distributed algorithms have an on-line flavor, we use the terms distributed algorithm and distributed on-line algorithm interchangeably. control algorithm. (This is also done implicitly in the earlier <p> The work that compares a distributed algorithm with global control algorithm <ref> [4, 14, 15, 17, 18, 19, 21] </ref> implicitly makes this distinction by having the on-line and off-line algorithms compete only on the same input, generally hiding the details of the schedule in a worst-case assumption applied only to the on-line algorithm. <p> The competitive latency model of [3] applies the same input and schedule to both the on-line and the off-line algorithms. In the present work the key insight is to preserve the split between the input and the schedule, as implicitly done in <ref> [4, 14, 15, 17, 18, 19, 21] </ref>, but to reverse the approach of this previous work by assuming a worst-case input but a competitive schedule.
Reference: [5] <author> J. Anderson. </author> <title> Composite Registers. </title> <booktitle> In Distributed Computing, </booktitle> <volume> Vol. 6, No. 3, </volume> <pages> pages 141-154. </pages> <booktitle> Preliminary version appears in Proc. 9th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 15-30, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: Examples include snap shot algorithms <ref> [2, 5, 8, 11, 13, 23] </ref>, the bounded round numbers abstraction [29], concurrent timestamping systems [25, 28, 32, 34, 35, 40], and time-lapse snapshot [28]. Here we elaborate on some simple examples. Atomic snapshots. <p> Snapshot objects are very useful tools for constructing more complicated shared-memory algorithms, and they have been extensively studied <ref> [2, 5, 8, 11, 23] </ref> culminating in the protocol of Attiya and Rachman [13] which uses only O (log n) alternating writes and collects to complete a scan-update operation. We will apply Theorem 3 to get a competitive snapshot. Let T be a snapshot object and U a write-collect object.
Reference: [6] <author> J. Aspnes. </author> <title> Time- and space-efficient randomized consensus. </title> <journal> Journal of Algorithms 14(3) </journal> <pages> 414-431, </pages> <month> May </month> <year> 1993. </year> <title> An earlier version appeared in Proc. </title> <booktitle> 9th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 325-331, </pages> <month> August </month> <year> 1990. </year>
Reference: [7] <author> J. Aspnes and M.P. Herlihy. </author> <title> Fast randomized consensus using shared memory. </title> <note> In Journal of Algorithms 11(3), pp.441-461, </note> <month> September </month> <year> 1990. </year>
Reference: [8] <author> J. Aspnes and M.P. Herlihy. </author> <title> Wait-free data structures in the Asyn--chronous PRAM Model. </title> <booktitle> In Proceedings of the 2nd Annual Symposium on Parallel Algorithms and Architectures, </booktitle> <month> July </month> <year> 1990, </year> <pages> pp. 340-349, </pages> <address> Crete, Greece. </address>
Reference-contexts: Examples include snap shot algorithms <ref> [2, 5, 8, 11, 13, 23] </ref>, the bounded round numbers abstraction [29], concurrent timestamping systems [25, 28, 32, 34, 35, 40], and time-lapse snapshot [28]. Here we elaborate on some simple examples. Atomic snapshots. <p> Snapshot objects are very useful tools for constructing more complicated shared-memory algorithms, and they have been extensively studied <ref> [2, 5, 8, 11, 23] </ref> culminating in the protocol of Attiya and Rachman [13] which uses only O (log n) alternating writes and collects to complete a scan-update operation. We will apply Theorem 3 to get a competitive snapshot. Let T be a snapshot object and U a write-collect object.
Reference: [9] <author> J. Aspnes and O. Waarts. </author> <title> Randomized consensus in expected O(n log 2 n) operations per processor. </title> <booktitle> In Proc. 33rd IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 137-146, </pages> <month> October </month> <year> 1992. </year> <note> To appear, SIAM Journal on Computing. </note>
Reference: [10] <author> J. Aspnes and O. Waarts. </author> <title> Modular competitiveness for distributed algorithms. </title> <type> Manuscript 1995. </type>
Reference-contexts: Due to lack of space, proofs are omitted or only sketched. A full version including detailed proofs is available <ref> [10] </ref>. 1.2 Other Related Work A notion related to allowing only correct distributed algorithms as champions is the very nice idea of comparing algorithms with partial information only against other algorithms with partial information.
Reference: [11] <author> H. Attiya, M.P. Herlihy, and O. Rachman. </author> <title> Efficient atomic snapshots using lattice agreement. </title> <type> Technical report, </type> <institution> Technion, Haifa, Is-rael, </institution> <year> 1992. </year> <note> A preliminary version appeared in proceedings of the 6th International Workshop on Distributed Algorithms, Haifa, Israel, Novem-ber 1992, </note> <editor> (A. Segall and S. Zaks, eds.), </editor> <booktitle> Lecture Notes in Computer Science #647, </booktitle> <publisher> Springer-Verlag, </publisher> <pages> pp. 35-53. </pages>
Reference-contexts: Examples include snap shot algorithms <ref> [2, 5, 8, 11, 13, 23] </ref>, the bounded round numbers abstraction [29], concurrent timestamping systems [25, 28, 32, 34, 35, 40], and time-lapse snapshot [28]. Here we elaborate on some simple examples. Atomic snapshots. <p> Snapshot objects are very useful tools for constructing more complicated shared-memory algorithms, and they have been extensively studied <ref> [2, 5, 8, 11, 23] </ref> culminating in the protocol of Attiya and Rachman [13] which uses only O (log n) alternating writes and collects to complete a scan-update operation. We will apply Theorem 3 to get a competitive snapshot. Let T be a snapshot object and U a write-collect object.
Reference: [12] <author> H. Attiya, A. Herzberg, and S. Rajsbaum. </author> <title> Optimal clock synchronization under different delay assumptions. </title> <booktitle> In Proc. 12th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 109-120, </pages> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: In addition, there is a long history of interest in optimality of a distributed algorithm given certain conditions, such as a particular pattern of failures [26, 31, 37, 43, 44, 45], or a particular pattern of message delivery <ref> [12, 33, 47] </ref>.
Reference: [13] <author> H. Attiya and O. Rachman. </author> <title> Atomic snapshots in O(n log n) operations. </title> <booktitle> In Proc. 12th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 29-40, </pages> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: It is the modularity property of throughput competitiveness that allows us to derive competitive versions of well-known shared-memory algorithms that are structured around the collect primitive, among which are the fastest known atomic snapshot algorithm, due to Attiya and Rachman <ref> [13] </ref>, and the bounded round numbers abstraction due to Dwork, Herlihy, and Waarts [29]. An important consequence of the modularity of the throughput-competitive measure is that better algorithms for doing collects will immediately give better algorithms that use collects. <p> Examples include snap shot algorithms <ref> [2, 5, 8, 11, 13, 23] </ref>, the bounded round numbers abstraction [29], concurrent timestamping systems [25, 28, 32, 34, 35, 40], and time-lapse snapshot [28]. Here we elaborate on some simple examples. Atomic snapshots. <p> Snapshot objects are very useful tools for constructing more complicated shared-memory algorithms, and they have been extensively studied [2, 5, 8, 11, 23] culminating in the protocol of Attiya and Rachman <ref> [13] </ref> which uses only O (log n) alternating writes and collects to complete a scan-update operation. We will apply Theorem 3 to get a competitive snapshot. Let T be a snapshot object and U a write-collect object.
Reference: [14] <author> B. Awerbuch and Y. Azar. </author> <title> Local optimization of global objectives: Competitive distributed deadlock resolution and resource allocation. </title> <booktitle> In Proc. 35th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 240-249, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Awerbuch, Kutten, and Peleg [17], and Bartal, Fiat, and Rabani [19] took the first steps in this direction. Their work was in the context of job scheduling and data management. In these papers, and in subsequent work <ref> [4, 14, 15, 21] </ref>, the cost of a distributed on-line algorithm 1 is compared to the cost of an optimal global 1 Because most distributed algorithms have an on-line flavor, we use the terms distributed algorithm and distributed on-line algorithm interchangeably. control algorithm. (This is also done implicitly in the earlier <p> The work that compares a distributed algorithm with global control algorithm <ref> [4, 14, 15, 17, 18, 19, 21] </ref> implicitly makes this distinction by having the on-line and off-line algorithms compete only on the same input, generally hiding the details of the schedule in a worst-case assumption applied only to the on-line algorithm. <p> The competitive latency model of [3] applies the same input and schedule to both the on-line and the off-line algorithms. In the present work the key insight is to preserve the split between the input and the schedule, as implicitly done in <ref> [4, 14, 15, 17, 18, 19, 21] </ref>, but to reverse the approach of this previous work by assuming a worst-case input but a competitive schedule.
Reference: [15] <author> B. Awerbuch, Y. Bartal, and A. Fiat. </author> <title> Competitive distributed file allocation. </title> <booktitle> In Proc. 25th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 164-173, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Awerbuch, Kutten, and Peleg [17], and Bartal, Fiat, and Rabani [19] took the first steps in this direction. Their work was in the context of job scheduling and data management. In these papers, and in subsequent work <ref> [4, 14, 15, 21] </ref>, the cost of a distributed on-line algorithm 1 is compared to the cost of an optimal global 1 Because most distributed algorithms have an on-line flavor, we use the terms distributed algorithm and distributed on-line algorithm interchangeably. control algorithm. (This is also done implicitly in the earlier <p> to the cost of an optimal global 1 Because most distributed algorithms have an on-line flavor, we use the terms distributed algorithm and distributed on-line algorithm interchangeably. control algorithm. (This is also done implicitly in the earlier work of Awerbuch and Peleg [18].) As has been observed elsewhere (see, e.g. <ref> [15] </ref>, paraphrased here), this imposes an additional handicap on the distributed on-line algorithm in comparison to the optimal algorithm: In the distributed algorithm the decisions are made based solely on local information. <p> The work that compares a distributed algorithm with global control algorithm <ref> [4, 14, 15, 17, 18, 19, 21] </ref> implicitly makes this distinction by having the on-line and off-line algorithms compete only on the same input, generally hiding the details of the schedule in a worst-case assumption applied only to the on-line algorithm. <p> The competitive latency model of [3] applies the same input and schedule to both the on-line and the off-line algorithms. In the present work the key insight is to preserve the split between the input and the schedule, as implicitly done in <ref> [4, 14, 15, 17, 18, 19, 21] </ref>, but to reverse the approach of this previous work by assuming a worst-case input but a competitive schedule.
Reference: [16] <author> B. Awerbuch, Y. Bartal, and A. Fiat. </author> <title> Heat and Dump: competitive distributed paging. </title> <booktitle> In Proc. 34th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 22-31, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: Some examples of elegant specialized constructions of competitive algorithms from other competitive algorithms in a distributed setting are the natural potential function construction of Bartal, Fiat, and Rabani [19] and the distributed paging work of Awerbuch, Bartal, and Fiat <ref> [16] </ref>.
Reference: [17] <author> B. Awerbuch, S. Kutten, and D. Peleg. </author> <title> Competitive distributed job scheduling. </title> <booktitle> In Proc. 24th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 571-580, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Due to the additional type of nondeterminism in the distributed setting, it is not obvious how to extend the notion of competitive analysis to this environment. Awerbuch, Kutten, and Peleg <ref> [17] </ref>, and Bartal, Fiat, and Rabani [19] took the first steps in this direction. Their work was in the context of job scheduling and data management. <p> On the other hand, any distributed algorithm must read all n registers to be sure that new values have not appeared, which gives an infinite competitive ratio, for any distributed algorithm. Thus the competitive measure of <ref> [17, 19] </ref> does not allow one to distinguish between the nave algorithm and algorithms that totally dominate it. Competitive Latency. Observing the above was what led [3] to define a competitive measure for distributed algorithms, called latency competitiveness. <p> The work that compares a distributed algorithm with global control algorithm <ref> [4, 14, 15, 17, 18, 19, 21] </ref> implicitly makes this distinction by having the on-line and off-line algorithms compete only on the same input, generally hiding the details of the schedule in a worst-case assumption applied only to the on-line algorithm. <p> The competitive latency model of [3] applies the same input and schedule to both the on-line and the off-line algorithms. In the present work the key insight is to preserve the split between the input and the schedule, as implicitly done in <ref> [4, 14, 15, 17, 18, 19, 21] </ref>, but to reverse the approach of this previous work by assuming a worst-case input but a competitive schedule.
Reference: [18] <author> B. Awerbuch and D. Peleg. </author> <title> Sparse partitions. </title> <booktitle> In Proc. 31st IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 503-513, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: of a distributed on-line algorithm 1 is compared to the cost of an optimal global 1 Because most distributed algorithms have an on-line flavor, we use the terms distributed algorithm and distributed on-line algorithm interchangeably. control algorithm. (This is also done implicitly in the earlier work of Awerbuch and Peleg <ref> [18] </ref>.) As has been observed elsewhere (see, e.g. [15], paraphrased here), this imposes an additional handicap on the distributed on-line algorithm in comparison to the optimal algorithm: In the distributed algorithm the decisions are made based solely on local information. <p> The work that compares a distributed algorithm with global control algorithm <ref> [4, 14, 15, 17, 18, 19, 21] </ref> implicitly makes this distinction by having the on-line and off-line algorithms compete only on the same input, generally hiding the details of the schedule in a worst-case assumption applied only to the on-line algorithm. <p> The competitive latency model of [3] applies the same input and schedule to both the on-line and the off-line algorithms. In the present work the key insight is to preserve the split between the input and the schedule, as implicitly done in <ref> [4, 14, 15, 17, 18, 19, 21] </ref>, but to reverse the approach of this previous work by assuming a worst-case input but a competitive schedule.
Reference: [19] <author> Y. Bartal, A. Fiat, and Y. Rabani. </author> <title> Competitive algorithms for distributed data management. </title> <booktitle> In Proc. 24th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 39-50, </pages> <year> 1992. </year>
Reference-contexts: Due to the additional type of nondeterminism in the distributed setting, it is not obvious how to extend the notion of competitive analysis to this environment. Awerbuch, Kutten, and Peleg [17], and Bartal, Fiat, and Rabani <ref> [19] </ref> took the first steps in this direction. Their work was in the context of job scheduling and data management. <p> On the other hand, any distributed algorithm must read all n registers to be sure that new values have not appeared, which gives an infinite competitive ratio, for any distributed algorithm. Thus the competitive measure of <ref> [17, 19] </ref> does not allow one to distinguish between the nave algorithm and algorithms that totally dominate it. Competitive Latency. Observing the above was what led [3] to define a competitive measure for distributed algorithms, called latency competitiveness. <p> The work that compares a distributed algorithm with global control algorithm <ref> [4, 14, 15, 17, 18, 19, 21] </ref> implicitly makes this distinction by having the on-line and off-line algorithms compete only on the same input, generally hiding the details of the schedule in a worst-case assumption applied only to the on-line algorithm. <p> The competitive latency model of [3] applies the same input and schedule to both the on-line and the off-line algorithms. In the present work the key insight is to preserve the split between the input and the schedule, as implicitly done in <ref> [4, 14, 15, 17, 18, 19, 21] </ref>, but to reverse the approach of this previous work by assuming a worst-case input but a competitive schedule. <p> Some examples of elegant specialized constructions of competitive algorithms from other competitive algorithms in a distributed setting are the natural potential function construction of Bartal, Fiat, and Rabani <ref> [19] </ref> and the distributed paging work of Awerbuch, Bartal, and Fiat [16].
Reference: [20] <author> E. Borowsky and E. Gafni. </author> <title> Immediate atomic snapshots and fast renaming. </title> <booktitle> In Proc. 12th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 41-51, </pages> <month> August </month> <year> 1993. </year>
Reference: [21] <author> Y. Bartal and A. Rosen. </author> <title> The distributed k-server problem A competitive distributed translator for k-server algorithms. </title> <booktitle> In Proc. 33rd IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 344-353, </pages> <month> Octo-ber </month> <year> 1992. </year>
Reference-contexts: Awerbuch, Kutten, and Peleg [17], and Bartal, Fiat, and Rabani [19] took the first steps in this direction. Their work was in the context of job scheduling and data management. In these papers, and in subsequent work <ref> [4, 14, 15, 21] </ref>, the cost of a distributed on-line algorithm 1 is compared to the cost of an optimal global 1 Because most distributed algorithms have an on-line flavor, we use the terms distributed algorithm and distributed on-line algorithm interchangeably. control algorithm. (This is also done implicitly in the earlier <p> The work that compares a distributed algorithm with global control algorithm <ref> [4, 14, 15, 17, 18, 19, 21] </ref> implicitly makes this distinction by having the on-line and off-line algorithms compete only on the same input, generally hiding the details of the schedule in a worst-case assumption applied only to the on-line algorithm. <p> The competitive latency model of [3] applies the same input and schedule to both the on-line and the off-line algorithms. In the present work the key insight is to preserve the split between the input and the schedule, as implicitly done in <ref> [4, 14, 15, 17, 18, 19, 21] </ref>, but to reverse the approach of this previous work by assuming a worst-case input but a competitive schedule.
Reference: [22] <author> G. Bracha and O. Rachman. </author> <title> Randomized consensus in expected O(n 2 log n) operations. </title> <booktitle> Proceedings of the Fifth International Workshop on Distributed Algorithms. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference: [23] <author> T. Chandra and C. Dwork. </author> <title> Using consensus to solve atomic snapshots. </title> <note> Submitted for Publication </note>
Reference-contexts: Examples include snap shot algorithms <ref> [2, 5, 8, 11, 13, 23] </ref>, the bounded round numbers abstraction [29], concurrent timestamping systems [25, 28, 32, 34, 35, 40], and time-lapse snapshot [28]. Here we elaborate on some simple examples. Atomic snapshots. <p> Snapshot objects are very useful tools for constructing more complicated shared-memory algorithms, and they have been extensively studied <ref> [2, 5, 8, 11, 23] </ref> culminating in the protocol of Attiya and Rachman [13] which uses only O (log n) alternating writes and collects to complete a scan-update operation. We will apply Theorem 3 to get a competitive snapshot. Let T be a snapshot object and U a write-collect object.
Reference: [24] <author> B. Chor, A. Israeli, and M. Li. </author> <title> Wait-Free Consensus Using Asynchronous Hardware. </title> <journal> In SIAM Journal on Computing, </journal> <volume> Vol. 23, No. 4, </volume> <pages> pages 701-712, </pages> <month> August </month> <year> 1994. </year> <title> Preliminary version appears in Proc. </title> <booktitle> 6th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 86-97, </pages> <year> 1987. </year>
Reference: [25] <author> D. Dolev and N. Shavit. </author> <note> Bounded Concurrent Time-Stamp Systems are Constructible! To appear in SIAM Journal on Computing. Preliminary version appears in Proc. 21st ACM Symposium on Theory of Computing, pages 454-465, 1989. An extended version appears in IBM Research Report RJ 6785, </note> <month> March </month> <year> 1990. </year>
Reference-contexts: Examples include snap shot algorithms [2, 5, 8, 11, 13, 23], the bounded round numbers abstraction [29], concurrent timestamping systems <ref> [25, 28, 32, 34, 35, 40] </ref>, and time-lapse snapshot [28]. Here we elaborate on some simple examples. Atomic snapshots.
Reference: [26] <author> D. Dolev, R. Reischuk, and H.R. </author> <title> Strong. Early stopping in Byzan-tine agreement. </title> <journal> In Journal of the ACM, </journal> <volume> 34:7, </volume> <month> Oct. </month> <year> 1990, </year> <pages> pp. 720-741. </pages> <note> First appeared in: Eventual is Earlier than Immediate, </note> <institution> IBM RJ 3915, </institution> <year> 1983. </year>
Reference-contexts: A generalization of this approach has recently been described by Koutsoupias and Papadimitriou [41]. In addition, there is a long history of interest in optimality of a distributed algorithm given certain conditions, such as a particular pattern of failures <ref> [26, 31, 37, 43, 44, 45] </ref>, or a particular pattern of message delivery [12, 33, 47].
Reference: [27] <author> C. Dwork, J. Halpern, and O. Waarts. </author> <title> Accomplishing work in the presence of failures. </title> <booktitle> In Proc. 11th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 91-102, </pages> <year> 1992. </year>
Reference: [28] <author> C. Dwork, M.P. Herlihy, S. Plotkin, and O. Waarts. </author> <title> Time-lapse snapshots. </title> <booktitle> Proceedings of Israel Symposium on the Theory of Computing and Systems, </booktitle> <year> 1992. </year>
Reference-contexts: Examples include snap shot algorithms [2, 5, 8, 11, 13, 23], the bounded round numbers abstraction [29], concurrent timestamping systems <ref> [25, 28, 32, 34, 35, 40] </ref>, and time-lapse snapshot [28]. Here we elaborate on some simple examples. Atomic snapshots. <p> Examples include snap shot algorithms [2, 5, 8, 11, 13, 23], the bounded round numbers abstraction [29], concurrent timestamping systems [25, 28, 32, 34, 35, 40], and time-lapse snapshot <ref> [28] </ref>. Here we elaborate on some simple examples. Atomic snapshots. A snapshot object simulates an array of n single-writer registers that support a scan-update operation which writes a value to one of the registers (an "update") and returns a vector of values for all of the registers (a "scan").
Reference: [29] <author> C. Dwork, M.P. Herlihy, and O. Waarts. </author> <title> Bounded round numbers. </title> <booktitle> In Proc. 12th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 53-64, </pages> <year> 1993. </year>
Reference-contexts: modularity property of throughput competitiveness that allows us to derive competitive versions of well-known shared-memory algorithms that are structured around the collect primitive, among which are the fastest known atomic snapshot algorithm, due to Attiya and Rachman [13], and the bounded round numbers abstraction due to Dwork, Herlihy, and Waarts <ref> [29] </ref>. An important consequence of the modularity of the throughput-competitive measure is that better algorithms for doing collects will immediately give better algorithms that use collects. <p> Examples include snap shot algorithms [2, 5, 8, 11, 13, 23], the bounded round numbers abstraction <ref> [29] </ref>, concurrent timestamping systems [25, 28, 32, 34, 35, 40], and time-lapse snapshot [28]. Here we elaborate on some simple examples. Atomic snapshots. <p> Moreover, the process's actions are not affected by any process whose round number lags behind its own by more than a finite limit. The round numbers increase unboundedly over the lifetime of the system. Dwork, Herlihy and Waarts <ref> [29] </ref> introduced the bounded round numbers abstraction, which can be plugged into any algorithm that uses round numbers in this fashion, transforming it into a bounded algorithm. The bounded round numbers implementation in [29] provides four operations of varying difficulty; however, the use of these operations is restricted. <p> The round numbers increase unboundedly over the lifetime of the system. Dwork, Herlihy and Waarts <ref> [29] </ref> introduced the bounded round numbers abstraction, which can be plugged into any algorithm that uses round numbers in this fashion, transforming it into a bounded algorithm. The bounded round numbers implementation in [29] provides four operations of varying difficulty; however, the use of these operations is restricted. As a result, we can coalesce these operations into a single operation, an advance-collect, which advances the current process's round number to the next round and collects the round numbers of the other processes.
Reference: [30] <author> C. Dwork, M.P. Herlihy, and O. Waarts. </author> <title> Contention in shared memory algorithms. </title> <note> To appear in the Journal of the ACM. Preliminary version appears in Proc. 25th ACM Symposium on Theory of Computing, pages 174-183, May 1993. Expanded version: Digital Equipment Corporation Technical Report CRL 93/12. </note>
Reference-contexts: To incorporate contention one could simply make a process incur a stall step instead of a usual step in case of contention, following the lines of <ref> [30] </ref>. Note however that in the standard model considered in this paper, where a step is an atomic read or write to a single-writer n-reader register, the issue of contention is of lesser effect. Relative Competitiveness.
Reference: [31] <author> C. Dwork and Y. Moses. </author> <title> Knowledge and common knowledge in a Byzantine environment: crash failures. </title> <booktitle> In Information and Computation 88(2) (1990), originally in Proc. TARK 1986. </booktitle>
Reference-contexts: A generalization of this approach has recently been described by Koutsoupias and Papadimitriou [41]. In addition, there is a long history of interest in optimality of a distributed algorithm given certain conditions, such as a particular pattern of failures <ref> [26, 31, 37, 43, 44, 45] </ref>, or a particular pattern of message delivery [12, 33, 47].
Reference: [32] <author> C. Dwork and O. Waarts. </author> <title> Simple and efficient bounded concurrent timestamping or bounded concurrent timestamp systems are comprehensible! To appear in the Journal of the ACM. Preliminary version appears in Proc. </title> <booktitle> 24th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 655-666, </pages> <year> 1992. </year>
Reference-contexts: Examples include snap shot algorithms [2, 5, 8, 11, 13, 23], the bounded round numbers abstraction [29], concurrent timestamping systems <ref> [25, 28, 32, 34, 35, 40] </ref>, and time-lapse snapshot [28]. Here we elaborate on some simple examples. Atomic snapshots.
Reference: [33] <author> M. Fischer and A. Michael, </author> <title> Sacrificing serializability to attain high availability of data in an unreliable network. </title> <type> Research Report 221, </type> <institution> Yale U., </institution> <month> Feb. </month> <year> 1982. </year>
Reference-contexts: In addition, there is a long history of interest in optimality of a distributed algorithm given certain conditions, such as a particular pattern of failures [26, 31, 37, 43, 44, 45], or a particular pattern of message delivery <ref> [12, 33, 47] </ref>.
Reference: [34] <author> R. Gawlick, N. Lynch, and N. Shavit. </author> <title> Concurrent timestamping made simple. </title> <booktitle> Proceedings of Israel Symposium on Theory of Computing and Systems, </booktitle> <year> 1992. </year>
Reference-contexts: Examples include snap shot algorithms [2, 5, 8, 11, 13, 23], the bounded round numbers abstraction [29], concurrent timestamping systems <ref> [25, 28, 32, 34, 35, 40] </ref>, and time-lapse snapshot [28]. Here we elaborate on some simple examples. Atomic snapshots.
Reference: [35] <author> S. Haldar. </author> <title> Efficient bounded timestamping using traceable use abstraction Is writer's guessing better than reader's telling? Technical Report RUU-CS-93-28, </title> <institution> Department of Computer Science, Utrecht, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: Examples include snap shot algorithms [2, 5, 8, 11, 13, 23], the bounded round numbers abstraction [29], concurrent timestamping systems <ref> [25, 28, 32, 34, 35, 40] </ref>, and time-lapse snapshot [28]. Here we elaborate on some simple examples. Atomic snapshots.
Reference: [36] <author> J. Y. Halpern and Y. Moses. </author> <title> Knowledge and common knowledge in a distributed environment, </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> Vol 37, No 3, </volume> <month> January </month> <year> 1990, </year> <pages> pp. 549-587. </pages> <note> A preliminary version appeared in Proc. 3rd ACM Symposium on Principles of Distributed Computing, </note> <year> 1984. </year>
Reference: [37] <author> J.Y. Halpern, Y. Moses, and O. Waarts. </author> <title> A characterization of eventual Byzantine agreement. </title> <booktitle> In Proc. 9th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp. 333-346, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: A generalization of this approach has recently been described by Koutsoupias and Papadimitriou [41]. In addition, there is a long history of interest in optimality of a distributed algorithm given certain conditions, such as a particular pattern of failures <ref> [26, 31, 37, 43, 44, 45] </ref>, or a particular pattern of message delivery [12, 33, 47].
Reference: [38] <author> M.P. Herlihy. </author> <title> Randomized wait-free concurrent objects. </title> <booktitle> In Proc. 10th ACM Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1991. </year>
Reference: [39] <author> A. Israeli and M. Li. </author> <title> Bounded Time Stamps. </title> <booktitle> In Distributed Computing, </booktitle> <volume> Vol. 6, No. 4, </volume> <pages> pages 205-209. </pages> <note> Preliminary version appears in Proc. 28th IEEE Symposium on Foundations of Computer Science, pp. 371-382, </note> <month> October </month> <year> 1987. </year>
Reference: [40] <author> A. Israeli and M. Pinhasov. </author> <title> A Concurrent Time-Stamp Scheme which is Linear in Time and Space. </title> <booktitle> In Proceedings of the 6th International Workshop on Distributed Algorithms, </booktitle> <publisher> LNCS 647, Springer-Verlag, </publisher> <pages> pages 95-109, </pages> <year> 1992. </year>
Reference-contexts: Examples include snap shot algorithms [2, 5, 8, 11, 13, 23], the bounded round numbers abstraction [29], concurrent timestamping systems <ref> [25, 28, 32, 34, 35, 40] </ref>, and time-lapse snapshot [28]. Here we elaborate on some simple examples. Atomic snapshots.
Reference: [41] <author> E. Koutsoupias and C.H. Papadimitriou. </author> <title> Beyond competitive analysis. </title> <booktitle> In Proc. 33rd IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 394-400, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: This was introduced by Papadimitriou and Yannakakis [46] in the context of linear programming; their model corresponds to a distributed system with no communication. A generalization of this approach has recently been described by Koutsoupias and Papadimitriou <ref> [41] </ref>. In addition, there is a long history of interest in optimality of a distributed algorithm given certain conditions, such as a particular pattern of failures [26, 31, 37, 43, 44, 45], or a particular pattern of message delivery [12, 33, 47].
Reference: [42] <author> L. M. Kirousis, P. Spirakis and P. Tsigas. </author> <title> Reading many variables in one atomic operation: solutions with linear or sublinear complexity. </title> <booktitle> In Proceedings of the 5th International Workshop on Distributed Algorithms, </booktitle> <year> 1991. </year>
Reference: [43] <author> Y. Moses and M.R. Tuttle. </author> <title> Programming simultaneous actions using common knowledge. </title> <journal> Algorithmica 3(1), </journal> <pages> pp. 121-169, </pages> <note> 1988 Preliminary version appeared in Proc. 28th IEEE Symposium on Foundations of Computer Science, pp. 208-221, </note> <year> 1986. </year>
Reference-contexts: A generalization of this approach has recently been described by Koutsoupias and Papadimitriou [41]. In addition, there is a long history of interest in optimality of a distributed algorithm given certain conditions, such as a particular pattern of failures <ref> [26, 31, 37, 43, 44, 45] </ref>, or a particular pattern of message delivery [12, 33, 47].
Reference: [44] <author> G. Neiger. </author> <title> Using knowledge to achieve consistent coordination in distributed systems. </title> <type> Manuscript, </type> <year> 1990. </year>
Reference-contexts: A generalization of this approach has recently been described by Koutsoupias and Papadimitriou [41]. In addition, there is a long history of interest in optimality of a distributed algorithm given certain conditions, such as a particular pattern of failures <ref> [26, 31, 37, 43, 44, 45] </ref>, or a particular pattern of message delivery [12, 33, 47].
Reference: [45] <author> G. Neiger and M. R. Tuttle. </author> <title> Common knowledge and consistent simultaneous coordination. </title> <booktitle> In Proceedings of the 4th International Workshop on Distributed Algorithms, </booktitle> <year> 1990. </year>
Reference-contexts: A generalization of this approach has recently been described by Koutsoupias and Papadimitriou [41]. In addition, there is a long history of interest in optimality of a distributed algorithm given certain conditions, such as a particular pattern of failures <ref> [26, 31, 37, 43, 44, 45] </ref>, or a particular pattern of message delivery [12, 33, 47].
Reference: [46] <author> C.H. Papadimitriou and M. Yannakakis. </author> <title> Linear programming without the matrix. </title> <booktitle> In Proc. 25th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 121-129, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: A full version including detailed proofs is available [10]. 1.2 Other Related Work A notion related to allowing only correct distributed algorithms as champions is the very nice idea of comparing algorithms with partial information only against other algorithms with partial information. This was introduced by Papadimitriou and Yannakakis <ref> [46] </ref> in the context of linear programming; their model corresponds to a distributed system with no communication. A generalization of this approach has recently been described by Koutsoupias and Papadimitriou [41].
Reference: [47] <author> B. Patt-Shamir and S. Rajsbaum. </author> <title> A theory of clock synchronization. </title> <booktitle> In Proc. 26th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 810-819, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: In addition, there is a long history of interest in optimality of a distributed algorithm given certain conditions, such as a particular pattern of failures [26, 31, 37, 43, 44, 45], or a particular pattern of message delivery <ref> [12, 33, 47] </ref>.
Reference: [48] <author> Y. Riany, N. Shavit and D. Touitou. </author> <title> Practical Snapshots. </title> <booktitle> In Proceedings of Israel Symposium on Theory of Computing and Systems, </booktitle> <year> 1994. </year>
Reference-contexts: Intuitively, the competitive latency measures the ratio between the amount of work that an algorithm needs to perform in order to carry out a particular set of collects, to the work done by the best possible algo 3 <ref> [49, 48] </ref> present interesting collect algorithms that do not follow the pattern of the naive algorithm. Both works however consider considerably stronger models than the standard shared memory model considered here. rithm (champion) for carrying out those collects given the same schedule.
Reference: [49] <author> M. Saks, N. Shavit, and H. Woll. </author> <title> Optimal time randomized consensus | making resilient algorithms fast in practice. </title> <booktitle> In Proceedings of the 2nd ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pp. 351-362, </pages> <year> 1991. </year>
Reference-contexts: Cooperative Collect. To demonstrate the different notions of competitiveness, we study the problem of having processes repeatedly collect values by the cooperative collect primitive, first abstracted by Saks, Shavit, and Woll <ref> [49] </ref>, described below. 2 We assume the standard model for asynchronous shared-memory computation, in which n processes communicate by reading and writing to a set of single-writer n-reader registers. (We confine ourselves to single-writer registers because the construction of registers that can be written to by more than one process is <p> Intuitively, the competitive latency measures the ratio between the amount of work that an algorithm needs to perform in order to carry out a particular set of collects, to the work done by the best possible algo 3 <ref> [49, 48] </ref> present interesting collect algorithms that do not follow the pattern of the naive algorithm. Both works however consider considerably stronger models than the standard shared memory model considered here. rithm (champion) for carrying out those collects given the same schedule.
Reference: [50] <author> D. D. Sleator and R. E. Tarjan. </author> <title> Amortized efficiency of list update and paging rules. </title> <journal> Comm. of the ACM 28(2), </journal> <pages> pp. 202-208, </pages> <year> 1985. </year>
Reference-contexts: 1 Introduction Competitive analysis and distributed algorithms. The tool of competitive analysis was proposed by Sleator and Tarjan <ref> [50] </ref> to study problems that arise in an on-line setting, where an algorithm is given an unpredictable sequence of requests to perform operations, and must make decisions about how to satisfy its current request that may affect how efficiently it can satisfy future requests.
Reference: [51] <author> P.M.B. Vitanyi and B. Awerbuch. </author> <title> Atomic Shared Register Access by Asynchronous Hardware. </title> <booktitle> In Proc. 27th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 233-243, </pages> <year> 1986. </year> <booktitle> Errata in Proc. 28th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1987. </year>
References-found: 51

