URL: http://www.cs.nmsu.edu/lldap/download/jicslp/perron.ps.gz
Refering-URL: http://www.cs.nmsu.edu/lldap/jicslp/perr.html
Root-URL: http://www.cs.nmsu.edu
Email: perron@aloes.ens.fr  
Title: An implementation of Or-Parallelism based on direct access to the MMU  
Author: Laurent Perron 
Web: http://www.ens.fr/users/perron/  
Address: 45 Rue d'Ulm, 75005 Paris, France  
Affiliation: Ecole Normale Superieure  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> K. Ali. </author> <title> Or-parallel execution of prolog on BC-Machine. </title> <booktitle> In Fifth International Conference of Logic Programming, </booktitle> <pages> pages 1531-1545. </pages> <publisher> MIT Press, </publisher> <year> 1988. </year>
Reference-contexts: Two possible execution models have been proposed, Independent and-parallelism [9, 10, 17] which parallelize independent goals (goals which do not share variables) and Stream and-parallelism [23] which orders subgoals in a producer-consumer way. The second execution model relies on or-parallelism <ref> [2, 22, 1, 8, 7, 4, 3, 28, 6] </ref>. It consists exploring different branches of a choice point in parallel. In this case, since multiple agents coexist, the same variable may be used in different places with different values. <p> Conery's closed environments [8] reduce the copying cost by reorganizing the stack frame and by keeping every needed information on the same stack frame. This is achieved by a closing operation which implies a selective copying of the stack after each call. Ali's BC-machine <ref> [1] </ref> do not use this algorithm and incrementally copy parts of the WAM stacks when creating a new worker. Clocksin's Delphi model [7] is a model using recomputation.
Reference: [2] <author> K.A.M. Ali and R. Karlsson. </author> <title> Full prolog and scheduling or-parallelism in muse. </title> <note> In International Journal of Parralel Programming, number 19 in 6, page 445:475, </note> <year> 1991. </year>
Reference-contexts: Two possible execution models have been proposed, Independent and-parallelism [9, 10, 17] which parallelize independent goals (goals which do not share variables) and Stream and-parallelism [23] which orders subgoals in a producer-consumer way. The second execution model relies on or-parallelism <ref> [2, 22, 1, 8, 7, 4, 3, 28, 6] </ref>. It consists exploring different branches of a choice point in parallel. In this case, since multiple agents coexist, the same variable may be used in different places with different values. <p> The Muse model <ref> [2] </ref> or the ACE model [16, 17] is very different. Each node contains the memory segment which differs from their parent node, thus task switching involves overwriting the stack. This could be worse than the SRI model but selective copying reduces this overhead. <p> Comparison with vectors models The implementation of or-parallelism requires three basic operations which are the agent creation, agent switching and accessing (reading or writing) a variable. For vector models <ref> [27, 2, 16, 17] </ref>, an important notion is the distance between two tasks.
Reference: [3] <author> U. baron, J.C. de Kergommeaux, H. Hailperin, M. Ratcliffe, P. Robert, and J.C. Syre nad H. Westphal. </author> <title> The paraller ECRC prolog system PEPSys: an overview and evaluation results. </title> <booktitle> In International Conference on Fith Generation Computer Systems, </booktitle> <pages> pages 841-849, </pages> <address> Tokyo, 1988. </address> <publisher> ICOT. </publisher>
Reference-contexts: Two possible execution models have been proposed, Independent and-parallelism [9, 10, 17] which parallelize independent goals (goals which do not share variables) and Stream and-parallelism [23] which orders subgoals in a producer-consumer way. The second execution model relies on or-parallelism <ref> [2, 22, 1, 8, 7, 4, 3, 28, 6] </ref>. It consists exploring different branches of a choice point in parallel. In this case, since multiple agents coexist, the same variable may be used in different places with different values. <p> We will call these models the hashing models. Here are some examples: works by Ciepielewski and Haridi [5, 6], the Argonne model [4], the PEPSys system <ref> [3] </ref>, AKL [12] and Oz [24, 25]. If the answer is yes, then reading or writing the value of a variable requires only two more indirections ( one to the current process and one to the variable array of this process ) than direct access. <p> Furthermore the overhead induced by the context switch is independent of the mutable area size in the CC (M) project and linear in vectors models like the ACE system [16, 17]. 6.1.3. Comparison with hashing models When comparing the CC (M) language to hashing models <ref> [5, 6, 4, 3, 12, 24, 25] </ref>, the access time of a variable is so high that it justifies easily the overhead of the context switch.
Reference: [4] <author> R. Butler, E.L. Lusk, R. Olson, and R.A. Overbeek. ANLWAM: </author> <title> A parallel implementation of the warren abstract machine. </title> <type> Technical report, </type> <institution> MCS division, Argonne National Laboratory, </institution> <year> 1986. </year>
Reference-contexts: Two possible execution models have been proposed, Independent and-parallelism [9, 10, 17] which parallelize independent goals (goals which do not share variables) and Stream and-parallelism [23] which orders subgoals in a producer-consumer way. The second execution model relies on or-parallelism <ref> [2, 22, 1, 8, 7, 4, 3, 28, 6] </ref>. It consists exploring different branches of a choice point in parallel. In this case, since multiple agents coexist, the same variable may be used in different places with different values. <p> We will call these models the hashing models. Here are some examples: works by Ciepielewski and Haridi [5, 6], the Argonne model <ref> [4] </ref>, the PEPSys system [3], AKL [12] and Oz [24, 25]. If the answer is yes, then reading or writing the value of a variable requires only two more indirections ( one to the current process and one to the variable array of this process ) than direct access. <p> Furthermore the overhead induced by the context switch is independent of the mutable area size in the CC (M) project and linear in vectors models like the ACE system [16, 17]. 6.1.3. Comparison with hashing models When comparing the CC (M) language to hashing models <ref> [5, 6, 4, 3, 12, 24, 25] </ref>, the access time of a variable is so high that it justifies easily the overhead of the context switch.
Reference: [5] <author> A. Ciepielewski and S. Haridi. </author> <title> Storage models for or-paralles execution of logic programs. </title> <type> Technical report, </type> <institution> The Royal Institute of Technology, Stockholm, </institution> <year> 1983. </year>
Reference-contexts: It consists exploring different branches of a choice point in parallel. In this case, since multiple agents coexist, the same variable may be used in different places with different values. Thus the system has to cope with multiply bound variables and multiple environment <ref> [5] </ref>. Concurrent Constraint Programming [19, 18, 12, 24] is an elegant merging of CLP and of Concurrent programming. It allows a better control of the execution of processes and it incorporates parallel composition in its design. <p> We will call these models the hashing models. Here are some examples: works by Ciepielewski and Haridi <ref> [5, 6] </ref>, the Argonne model [4], the PEPSys system [3], AKL [12] and Oz [24, 25]. <p> Furthermore the overhead induced by the context switch is independent of the mutable area size in the CC (M) project and linear in vectors models like the ACE system [16, 17]. 6.1.3. Comparison with hashing models When comparing the CC (M) language to hashing models <ref> [5, 6, 4, 3, 12, 24, 25] </ref>, the access time of a variable is so high that it justifies easily the overhead of the context switch.
Reference: [6] <author> A. Ciepielewski, S. Haridi, and B. Hausman. </author> <title> Or-parallel prolog on shared memory multiprocessors. </title> <journal> Journal of Logic Programming, </journal> <volume> 7:125:147, </volume> <year> 1989. </year>
Reference-contexts: Two possible execution models have been proposed, Independent and-parallelism [9, 10, 17] which parallelize independent goals (goals which do not share variables) and Stream and-parallelism [23] which orders subgoals in a producer-consumer way. The second execution model relies on or-parallelism <ref> [2, 22, 1, 8, 7, 4, 3, 28, 6] </ref>. It consists exploring different branches of a choice point in parallel. In this case, since multiple agents coexist, the same variable may be used in different places with different values. <p> We will call these models the hashing models. Here are some examples: works by Ciepielewski and Haridi <ref> [5, 6] </ref>, the Argonne model [4], the PEPSys system [3], AKL [12] and Oz [24, 25]. <p> Furthermore the overhead induced by the context switch is independent of the mutable area size in the CC (M) project and linear in vectors models like the ACE system [16, 17]. 6.1.3. Comparison with hashing models When comparing the CC (M) language to hashing models <ref> [5, 6, 4, 3, 12, 24, 25] </ref>, the access time of a variable is so high that it justifies easily the overhead of the context switch.
Reference: [7] <author> W. Clocksin. </author> <title> Principles of the DelPhi paralle inference machine. </title> <journal> COmputer Journal, </journal> <volume> 30(5) </volume> <pages> 386-392, </pages> <year> 1987. </year>
Reference-contexts: Two possible execution models have been proposed, Independent and-parallelism [9, 10, 17] which parallelize independent goals (goals which do not share variables) and Stream and-parallelism [23] which orders subgoals in a producer-consumer way. The second execution model relies on or-parallelism <ref> [2, 22, 1, 8, 7, 4, 3, 28, 6] </ref>. It consists exploring different branches of a choice point in parallel. In this case, since multiple agents coexist, the same variable may be used in different places with different values. <p> This is achieved by a closing operation which implies a selective copying of the stack after each call. Ali's BC-machine [1] do not use this algorithm and incrementally copy parts of the WAM stacks when creating a new worker. Clocksin's Delphi model <ref> [7] </ref> is a model using recomputation. In these models, the good aspect is that the execution of an agent is as efficient as in a sequential implementation but the cost of creating a new agent is very high as it requires copying or recomputing the whole database.
Reference: [8] <author> J.S. Conery. </author> <title> Binding environments for parallel logic programs in nonshared memory multiprocessors. </title> <booktitle> In Proceedings of the 1987 Symposium on Logic Programming [11], </booktitle> <pages> pages 457-467. </pages>
Reference-contexts: Two possible execution models have been proposed, Independent and-parallelism [9, 10, 17] which parallelize independent goals (goals which do not share variables) and Stream and-parallelism [23] which orders subgoals in a producer-consumer way. The second execution model relies on or-parallelism <ref> [2, 22, 1, 8, 7, 4, 3, 28, 6] </ref>. It consists exploring different branches of a choice point in parallel. In this case, since multiple agents coexist, the same variable may be used in different places with different values. <p> But the cost of launching a new agent is very high because the whole data needed by the agent are to be copied from the parent agent to the child agent. Conery's closed environments <ref> [8] </ref> reduce the copying cost by reorganizing the stack frame and by keeping every needed information on the same stack frame. This is achieved by a closing operation which implies a selective copying of the stack after each call. <p> Moreover, the size of the area involved during a choice point is critical both from the point of view of memory consumption and from that of time consumption during an agent creation and during a task switching. Conery's closed environments <ref> [8] </ref> have shown that it was worthy reorganizing the stack after each function call in order to keep the mutable data area as small and as compact as possible.
Reference: [9] <author> D. </author> <title> DeGroot. Restricted AND-parallelism and side effects. </title> <booktitle> In International Conference on 5th Generation Computer Systems, </booktitle> <address> San Francisco, </address> <month> August </month> <year> 1987. </year> <journal> IEEE Computer Society. </journal>
Reference-contexts: But it requires some control since two cooperative workers may 1996 Compulog Net Meeting on Parallelism and Implementation Technology lead to inconsistent computations. Two possible execution models have been proposed, Independent and-parallelism <ref> [9, 10, 17] </ref> which parallelize independent goals (goals which do not share variables) and Stream and-parallelism [23] which orders subgoals in a producer-consumer way. The second execution model relies on or-parallelism [2, 22, 1, 8, 7, 4, 3, 28, 6].
Reference: [10] <author> M. Hermenegildo and K. Greene. </author> <title> &-prolog and its performance: Exploiting independant and-parallelism. </title> <booktitle> In 1990 International Conference on Logic Programming, </booktitle> <pages> pages 253-268. </pages> <publisher> MIT Press, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: There exist different solutions to help parallelize logic languages and their derivatives. In Prolog and in CLP languages, various execution models have been proposed. The first one relies on and-parallelism <ref> [10, 16, 17] </ref>. It consists in exploring subgoals in parallel. This technique is interesting because it is compatible with the trailing mechanism since only one node of the tree of hypotheses is explored at a time. <p> But it requires some control since two cooperative workers may 1996 Compulog Net Meeting on Parallelism and Implementation Technology lead to inconsistent computations. Two possible execution models have been proposed, Independent and-parallelism <ref> [9, 10, 17] </ref> which parallelize independent goals (goals which do not share variables) and Stream and-parallelism [23] which orders subgoals in a producer-consumer way. The second execution model relies on or-parallelism [2, 22, 1, 8, 7, 4, 3, 28, 6].
Reference: [11] <editor> IEEE. </editor> <booktitle> Proceedings of the 1987 Symposium on Logic Programming, </booktitle> <address> San Francisco, </address> <month> August - September </month> <year> 1987. </year> <institution> Computer Society Press. </institution>
Reference: [12] <author> Sverker Janson. AKL, </author> <title> A Multiparadigm Programming Language. </title> <type> SICS, </type> <institution> Uppsala University, </institution> <year> 1994. </year> <title> 1996 Compulog Net Meeting on Parallelism and Implementation Technology </title>
Reference-contexts: It consists exploring different branches of a choice point in parallel. In this case, since multiple agents coexist, the same variable may be used in different places with different values. Thus the system has to cope with multiply bound variables and multiple environment [5]. Concurrent Constraint Programming <ref> [19, 18, 12, 24] </ref> is an elegant merging of CLP and of Concurrent programming. It allows a better control of the execution of processes and it incorporates parallel composition in its design. <p> But the availability of both parallel composition and non-determinism forbids an implementation based on trailing since nothing can restrict an agent from backtracking while another is pushing some changes on the trailing stack. Thus the implementation of non-determinism has to use methods inherited from or-parallel languages. For instance, AKL <ref> [12] </ref> and Oz [13] use techniques inherited from or-parallelism languages. The CC (M) [14, 15] project is aimed at a generic implementation of the Concurrent Constraint class of languages [19, 18]. The CC (M) language is a kernel language and constraint domains are implemented as libraries of this language. <p> We will call these models the hashing models. Here are some examples: works by Ciepielewski and Haridi [5, 6], the Argonne model [4], the PEPSys system [3], AKL <ref> [12] </ref> and Oz [24, 25]. If the answer is yes, then reading or writing the value of a variable requires only two more indirections ( one to the current process and one to the variable array of this process ) than direct access. <p> The CC (M) project 4.1. Presentation of the CC (M) project The notion of a generic implementation of constraint domain is not new and it can be found for instance in the AKL project <ref> [12] </ref>. In this project, a few overloaded functions implement the interface between the generic constraint solver and specific constraint domain. These functions deal with the installation, the removal, the entailment test, the garbaging . . . of a constraint in the constraint domain. <p> Furthermore the overhead induced by the context switch is independent of the mutable area size in the CC (M) project and linear in vectors models like the ACE system [16, 17]. 6.1.3. Comparison with hashing models When comparing the CC (M) language to hashing models <ref> [5, 6, 4, 3, 12, 24, 25] </ref>, the access time of a variable is so high that it justifies easily the overhead of the context switch.
Reference: [13] <author> Michael Mehl, Ralf Scheidhauer, and Christian Schulte. </author> <title> An Abstract Machine for Oz. </title> <institution> Research Report RR-95-08, Deutsches Forschungszentrum fur Kunstliche Intelligenz, Stuhlsatzenhausweg 3, D66123 Saarbrucken, Germany, </institution> <month> June </month> <year> 1995. </year> <note> Also in: Proceedings of PLILP'95 , Springer-Verlag, LNCS, </note> <institution> Utrecht, The Netherlands. </institution>
Reference-contexts: Thus the implementation of non-determinism has to use methods inherited from or-parallel languages. For instance, AKL [12] and Oz <ref> [13] </ref> use techniques inherited from or-parallelism languages. The CC (M) [14, 15] project is aimed at a generic implementation of the Concurrent Constraint class of languages [19, 18]. The CC (M) language is a kernel language and constraint domains are implemented as libraries of this language.
Reference: [14] <author> Laurent Perron. cc(M), </author> <title> a kernel for implementing cc languages. </title> <booktitle> In Proc. of CCP'95, </booktitle> <year> 1995. </year>
Reference-contexts: Thus the implementation of non-determinism has to use methods inherited from or-parallel languages. For instance, AKL [12] and Oz [13] use techniques inherited from or-parallelism languages. The CC (M) <ref> [14, 15] </ref> project is aimed at a generic implementation of the Concurrent Constraint class of languages [19, 18]. The CC (M) language is a kernel language and constraint domains are implemented as libraries of this language. The CC (M) language is designed as a concurrent object language. <p> Moreover, this language must offer the same primitives of the CC class of languages, i.e. parallel composition, non-determinism. Therefore the kernel language should be a concurrent object language. As shown in a previous paper <ref> [14] </ref>, implementing a constraint domain over an object-like lan guage is a multi-stage process. This is summarized in figure 2. CC (X) representation CC M CC (M) (3) The first stage is the encoding of constraints in a class structure. This is the representation arrow.
Reference: [15] <author> Laurent Perron. </author> <title> A concurrent constraint kernel language based on messages. </title> <booktitle> In Proc. of ICLP'95, </booktitle> <year> 1995. </year> <note> Poster. </note>
Reference-contexts: Thus the implementation of non-determinism has to use methods inherited from or-parallel languages. For instance, AKL [12] and Oz [13] use techniques inherited from or-parallelism languages. The CC (M) <ref> [14, 15] </ref> project is aimed at a generic implementation of the Concurrent Constraint class of languages [19, 18]. The CC (M) language is a kernel language and constraint domains are implemented as libraries of this language. The CC (M) language is designed as a concurrent object language.
Reference: [16] <author> E. Pontelli, G. Gupta, and M. Hermenegildo. </author> <title> &ACE:a high performance parallel prolog system. </title> <booktitle> In IIPS 95, </booktitle> <address> Santa Barbara, CA, 1995. </address> <publisher> IEEE Computer Society. </publisher>
Reference-contexts: There exist different solutions to help parallelize logic languages and their derivatives. In Prolog and in CLP languages, various execution models have been proposed. The first one relies on and-parallelism <ref> [10, 16, 17] </ref>. It consists in exploring subgoals in parallel. This technique is interesting because it is compatible with the trailing mechanism since only one node of the tree of hypotheses is explored at a time. <p> The Muse model [2] or the ACE model <ref> [16, 17] </ref> is very different. Each node contains the memory segment which differs from their parent node, thus task switching involves overwriting the stack. This could be worse than the SRI model but selective copying reduces this overhead. <p> Conery's closed environments [8] have shown that it was worthy reorganizing the stack after each function call in order to keep the mutable data area as small and as compact as possible. In the ACE system <ref> [16] </ref>, selective copying has shown that keeping variable access as fast as in sequential prolog is profitable even if it means overwriting the stack during each context switch. The CC (M) memory model is inspired by all these experiences. But with a radical approach. <p> Comparison with vectors models The implementation of or-parallelism requires three basic operations which are the agent creation, agent switching and accessing (reading or writing) a variable. For vector models <ref> [27, 2, 16, 17] </ref>, an important notion is the distance between two tasks. <p> Furthermore the overhead induced by the context switch is independent of the mutable area size in the CC (M) project and linear in vectors models like the ACE system <ref> [16, 17] </ref>. 6.1.3. Comparison with hashing models When comparing the CC (M) language to hashing models [5, 6, 4, 3, 12, 24, 25], the access time of a variable is so high that it justifies easily the overhead of the context switch.
Reference: [17] <author> Enrico Pontelli, Goral Gupta, and Manuel Hermenegildo. </author> <title> &ACE, the and-parallel component of ACE ( a progess report on ACE). </title> <editor> In Jonas Barlklund, Bharat Jayaraman, and Jiro Tanaka, editors, </editor> <booktitle> Parallel and Datra Parallel Execution of Logic Programming, </booktitle> <volume> volume 78, </volume> <pages> pages 65-78. </pages> <address> UPMAIL, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: There exist different solutions to help parallelize logic languages and their derivatives. In Prolog and in CLP languages, various execution models have been proposed. The first one relies on and-parallelism <ref> [10, 16, 17] </ref>. It consists in exploring subgoals in parallel. This technique is interesting because it is compatible with the trailing mechanism since only one node of the tree of hypotheses is explored at a time. <p> But it requires some control since two cooperative workers may 1996 Compulog Net Meeting on Parallelism and Implementation Technology lead to inconsistent computations. Two possible execution models have been proposed, Independent and-parallelism <ref> [9, 10, 17] </ref> which parallelize independent goals (goals which do not share variables) and Stream and-parallelism [23] which orders subgoals in a producer-consumer way. The second execution model relies on or-parallelism [2, 22, 1, 8, 7, 4, 3, 28, 6]. <p> The Muse model [2] or the ACE model <ref> [16, 17] </ref> is very different. Each node contains the memory segment which differs from their parent node, thus task switching involves overwriting the stack. This could be worse than the SRI model but selective copying reduces this overhead. <p> Comparison with vectors models The implementation of or-parallelism requires three basic operations which are the agent creation, agent switching and accessing (reading or writing) a variable. For vector models <ref> [27, 2, 16, 17] </ref>, an important notion is the distance between two tasks. <p> Furthermore the overhead induced by the context switch is independent of the mutable area size in the CC (M) project and linear in vectors models like the ACE system <ref> [16, 17] </ref>. 6.1.3. Comparison with hashing models When comparing the CC (M) language to hashing models [5, 6, 4, 3, 12, 24, 25], the access time of a variable is so high that it justifies easily the overhead of the context switch.
Reference: [18] <author> Vijay Saraswat. </author> <title> Concurrent constraint programming. </title> <booktitle> In seventeenth ACM Symposium on Principles of Programming Languages, </booktitle> <year> 1990. </year>
Reference-contexts: It consists exploring different branches of a choice point in parallel. In this case, since multiple agents coexist, the same variable may be used in different places with different values. Thus the system has to cope with multiply bound variables and multiple environment [5]. Concurrent Constraint Programming <ref> [19, 18, 12, 24] </ref> is an elegant merging of CLP and of Concurrent programming. It allows a better control of the execution of processes and it incorporates parallel composition in its design. <p> Thus the implementation of non-determinism has to use methods inherited from or-parallel languages. For instance, AKL [12] and Oz [13] use techniques inherited from or-parallelism languages. The CC (M) [14, 15] project is aimed at a generic implementation of the Concurrent Constraint class of languages <ref> [19, 18] </ref>. The CC (M) language is a kernel language and constraint domains are implemented as libraries of this language. The CC (M) language is designed as a concurrent object language. <p> We will then conclude and present future direction of research. 2. Preliminaries In this article, V will denote a finite or countable set of variables. Elements of this set will be written using capital letters X or Y . A Constraint Domain <ref> [19, 18] </ref> is a structure hX; `i where ` is a monotonic entailment relation. This structure X is closed under existential quantification and conjunction. It contains two distinguished elements true and false.
Reference: [19] <author> Vijay Saraswat. </author> <title> Concurrent Constraint Programming Languages. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: It consists exploring different branches of a choice point in parallel. In this case, since multiple agents coexist, the same variable may be used in different places with different values. Thus the system has to cope with multiply bound variables and multiple environment [5]. Concurrent Constraint Programming <ref> [19, 18, 12, 24] </ref> is an elegant merging of CLP and of Concurrent programming. It allows a better control of the execution of processes and it incorporates parallel composition in its design. <p> Thus the implementation of non-determinism has to use methods inherited from or-parallel languages. For instance, AKL [12] and Oz [13] use techniques inherited from or-parallelism languages. The CC (M) [14, 15] project is aimed at a generic implementation of the Concurrent Constraint class of languages <ref> [19, 18] </ref>. The CC (M) language is a kernel language and constraint domains are implemented as libraries of this language. The CC (M) language is designed as a concurrent object language. <p> We will then conclude and present future direction of research. 2. Preliminaries In this article, V will denote a finite or countable set of variables. Elements of this set will be written using capital letters X or Y . A Constraint Domain <ref> [19, 18] </ref> is a structure hX; `i where ` is a monotonic entailment relation. This structure X is closed under existential quantification and conjunction. It contains two distinguished elements true and false.
Reference: [20] <author> Christian Schulte and Gert Smolka. </author> <title> Encapsulated search in higher-order concurrent constraint programming. </title> <editor> In Maurice Bruynooghe, editor, </editor> <booktitle> Logic Programming: Proceedings of the 1994 International Symposium, </booktitle> <pages> pages 505-520, </pages> <address> Ithaca, New York, USA, </address> <month> November </month> <year> 1994. </year> <pages> MIT-Press. </pages>
Reference-contexts: Every time a hypothesis is tried, a marker is positioned on the stack, thus allowing nested hypotheses and multi-level undoing. This technique is used in the Warren Abstract Machine implementation of Prolog [26]. Encapsulated search is another implementation scheme. It is found for instance in the Oz system <ref> [20, 21] </ref>. Instead of considering a unique store where results of computations are written, encapsulated search develops the notion of local stores. This means that different hypotheses will be tried on independent local stores.
Reference: [21] <author> Christian Schulte, Gert Smolka, and Jorg Wurtz. </author> <title> Encapsulated search and constraint programming in Oz. </title> <editor> In A.H. Borning, editor, </editor> <booktitle> Second Workshop on Principles and Practice of Constraint Programming, Lecture Notes in Computer Science, </booktitle> <volume> vol. 874, </volume> <pages> pages 134-150, </pages> <address> Orcas Island, Washington, USA, May 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Every time a hypothesis is tried, a marker is positioned on the stack, thus allowing nested hypotheses and multi-level undoing. This technique is used in the Warren Abstract Machine implementation of Prolog [26]. Encapsulated search is another implementation scheme. It is found for instance in the Oz system <ref> [20, 21] </ref>. Instead of considering a unique store where results of computations are written, encapsulated search develops the notion of local stores. This means that different hypotheses will be tried on independent local stores.
Reference: [22] <author> E. Shapiro. </author> <title> An or-parallel execution algorithm for prolog and its FCP implementation. </title> <booktitle> In Fourth International Comference of Logic Programming, </booktitle> <pages> pages 311-317. </pages> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: Two possible execution models have been proposed, Independent and-parallelism [9, 10, 17] which parallelize independent goals (goals which do not share variables) and Stream and-parallelism [23] which orders subgoals in a producer-consumer way. The second execution model relies on or-parallelism <ref> [2, 22, 1, 8, 7, 4, 3, 28, 6] </ref>. It consists exploring different branches of a choice point in parallel. In this case, since multiple agents coexist, the same variable may be used in different places with different values.
Reference: [23] <author> K. Shen. </author> <title> Studies in And/Or Parallelism in Prolog. </title> <type> PhD thesis, </type> <institution> University of Cambridge, </institution> <year> 1992. </year>
Reference-contexts: But it requires some control since two cooperative workers may 1996 Compulog Net Meeting on Parallelism and Implementation Technology lead to inconsistent computations. Two possible execution models have been proposed, Independent and-parallelism [9, 10, 17] which parallelize independent goals (goals which do not share variables) and Stream and-parallelism <ref> [23] </ref> which orders subgoals in a producer-consumer way. The second execution model relies on or-parallelism [2, 22, 1, 8, 7, 4, 3, 28, 6]. It consists exploring different branches of a choice point in parallel.
Reference: [24] <author> Gert Smolka. </author> <title> A calculus for higher-order concurrent constraint programming with deep guards. </title> <institution> Research Report RR-94-03, Deutsches Forschungszentrum fur Kunstliche Intelligenz, Stuhlsatzenhausweg 3, D-66123 Saarbrucken, Germany, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: It consists exploring different branches of a choice point in parallel. In this case, since multiple agents coexist, the same variable may be used in different places with different values. Thus the system has to cope with multiply bound variables and multiple environment [5]. Concurrent Constraint Programming <ref> [19, 18, 12, 24] </ref> is an elegant merging of CLP and of Concurrent programming. It allows a better control of the execution of processes and it incorporates parallel composition in its design. <p> We will call these models the hashing models. Here are some examples: works by Ciepielewski and Haridi [5, 6], the Argonne model [4], the PEPSys system [3], AKL [12] and Oz <ref> [24, 25] </ref>. If the answer is yes, then reading or writing the value of a variable requires only two more indirections ( one to the current process and one to the variable array of this process ) than direct access. This is a lot faster than accessing the hash table. <p> Furthermore the overhead induced by the context switch is independent of the mutable area size in the CC (M) project and linear in vectors models like the ACE system [16, 17]. 6.1.3. Comparison with hashing models When comparing the CC (M) language to hashing models <ref> [5, 6, 4, 3, 12, 24, 25] </ref>, the access time of a variable is so high that it justifies easily the overhead of the context switch.
Reference: [25] <author> Gert Smolka. </author> <title> The Oz programming model. </title> <editor> In Jan van Leeuwen, editor, </editor> <booktitle> Computer Science Today, Lecture Notes in Computer Science, </booktitle> <volume> vol. 1000, </volume> <pages> pages 324-343. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1995. </year>
Reference-contexts: We will call these models the hashing models. Here are some examples: works by Ciepielewski and Haridi [5, 6], the Argonne model [4], the PEPSys system [3], AKL [12] and Oz <ref> [24, 25] </ref>. If the answer is yes, then reading or writing the value of a variable requires only two more indirections ( one to the current process and one to the variable array of this process ) than direct access. This is a lot faster than accessing the hash table. <p> Furthermore the overhead induced by the context switch is independent of the mutable area size in the CC (M) project and linear in vectors models like the ACE system [16, 17]. 6.1.3. Comparison with hashing models When comparing the CC (M) language to hashing models <ref> [5, 6, 4, 3, 12, 24, 25] </ref>, the access time of a variable is so high that it justifies easily the overhead of the context switch.
Reference: [26] <author> D.H.D. Warren. </author> <title> An abstract prolog instruction set. </title> <type> Technical Report 209, </type> <institution> SRI International, </institution> <year> 1983. </year>
Reference-contexts: In practice, changes are pushed on a stack. Every time a hypothesis is tried, a marker is positioned on the stack, thus allowing nested hypotheses and multi-level undoing. This technique is used in the Warren Abstract Machine implementation of Prolog <ref> [26] </ref>. Encapsulated search is another implementation scheme. It is found for instance in the Oz system [20, 21]. Instead of considering a unique store where results of computations are written, encapsulated search develops the notion of local stores. This means that different hypotheses will be tried on independent local stores.
Reference: [27] <author> D.H.D. Warren. </author> <title> Or-parralel execution models of prolog. </title> <booktitle> In TATSOFT'87, pages 243,259. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1987. </year>
Reference-contexts: This is a lot faster than accessing the hash table. But this set of references has to be maintained during the context switch. We will call these models the vector models. Various implementations have been proposed. In the SRI model <ref> [27] </ref>, there is one array of references for the whole system. <p> Comparison with vectors models The implementation of or-parallelism requires three basic operations which are the agent creation, agent switching and accessing (reading or writing) a variable. For vector models <ref> [27, 2, 16, 17] </ref>, an important notion is the distance between two tasks.
Reference: [28] <author> D.H.D. Warren. </author> <title> The SRI model for or-parallel execution of Prolog: Abstract design and implementation. </title> <booktitle> In Proceedings of the 1987 Symposium on Logic Programming [11], </booktitle> <pages> pages 92-102. </pages>
Reference-contexts: Two possible execution models have been proposed, Independent and-parallelism [9, 10, 17] which parallelize independent goals (goals which do not share variables) and Stream and-parallelism [23] which orders subgoals in a producer-consumer way. The second execution model relies on or-parallelism <ref> [2, 22, 1, 8, 7, 4, 3, 28, 6] </ref>. It consists exploring different branches of a choice point in parallel. In this case, since multiple agents coexist, the same variable may be used in different places with different values.
References-found: 28

