URL: http://c.gp.cs.cmu.edu:5103/afs/cs/user/fp/public/papers/lfproc92.ps.gz
Refering-URL: http://c.gp.cs.cmu.edu:5103/afs/cs/user/fp/public/papers/
Root-URL: http://www.cs.cmu.edu
Email: rwh+@cs.cmu.edu and fp+@cs.cmu.edu  
Title: Modularity in the LF Logical Framework  
Author: Robert Harper and Frank Pfenning 
Date: November 1, 1991  
Note: Draft for the Proceedings of the Second Workshop on Logical Frameworks  
Address: Pittsburgh, Pennsylvania 15213-3890, U.S.A.  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Thierry Coquand. </author> <title> An algorithm for testing conversion in type theory. </title> <editor> In Gerard Huet and Gordon Plotkin, editors, </editor> <booktitle> Logical Frameworks, </booktitle> <pages> pages 255-279. </pages> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: The notion of definitional equality we consider here is fi-conversion. Harper et al. [8] formulate definitional equality only with fi-conversion and conjecture that the system resulting from adding the -rule would have the properties we list below. This has recently been proved by Coquand <ref> [1] </ref> and independently by Salvesen [22]. For practical purposes the formulation including the -rule is superior, since every term has an equivalent canonical form. Thus, for us, is the least congruence generated from fi-conversions in the usual manner. <p> ` M : B ` M : x:A: B ` N : A ` M : A A A 0 ` A 0 : Type ` M : A 0 We state a selection of the crucial properties of the LF type theory as given and proven in [8] and <ref> [1] </ref>. 1. (Unicity of Types) If ` M : A and ` M : A 0 then A A 0 . 2. (Strong Normalization) If ` M : A then M is strongly normalizing. 3. (Canonical Forms for Types) If ` A : Type then A x 1 :A 1 .
Reference: [2] <author> Thierry Coquand and Gerard Huet. </author> <title> The Calculus of Constructions. </title> <journal> Information and Computation, </journal> 76(2/3):95-120, February/March 1988. 
Reference-contexts: Modularity in LF 19 Much more powerful, impredicative type theories have been investigated by Luo [12] and are implemented within the LEGO system [13]. The basis for this work is the Calculus of Constructions <ref> [2] </ref> which is not intended as a logical framework, but a type theory in which constructive mathematics could be directly formalized and reasoned about internally. Explicit theory structuring is achieved through -types.
Reference: [3] <author> N. G. de Bruijn. </author> <title> Telescopic mapping in typed lambda calculus. </title> <journal> Information and Computation, </journal> <note> To appear. </note>
Reference-contexts: The problem of modularity in the presentation of theories and logical system has been addressed from the semantical [10, 9] and the type-theoretic <ref> [3, 4, 25] </ref> point of view. Our design has been guided by these ideas and the pragmatic principles of the ML module system [14, 17]. <p> Realizations only interpret the result of computations, which consist of a form of search over signatures. The problem of modularity in logical frameworks has previously been addressed in various typed -calculi. De Bruijn's telescopic mappings <ref> [3] </ref>, for example, provide for a first-class notion of contexts. Along similar lines, a type-theoretic calculus with explicit contexts called DEVA has been developed and applied to a number of interesting examples by de Groote [4] and Weber [25].
Reference: [4] <author> Philippe de Groote. </author> <title> Nederpelt's calculus extended with a notion of context as a logical framework. </title> <editor> In Gerard Huet and Gordon Plotkin, editors, </editor> <booktitle> Logical Frameworks, </booktitle> <pages> pages 69-86. </pages> <publisher> Cam-bridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: The problem of modularity in the presentation of theories and logical system has been addressed from the semantical [10, 9] and the type-theoretic <ref> [3, 4, 25] </ref> point of view. Our design has been guided by these ideas and the pragmatic principles of the ML module system [14, 17]. <p> De Bruijn's telescopic mappings [3], for example, provide for a first-class notion of contexts. Along similar lines, a type-theoretic calculus with explicit contexts called DEVA has been developed and applied to a number of interesting examples by de Groote <ref> [4] </ref> and Weber [25]. Our module calculus can be seen as a higher-level language which could be compiled into a lower-level type theory such as DEVA.
Reference: [5] <author> Conal M. Elliott. </author> <title> Extensions and Applications of Higher-Order Unification. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> May </month> <year> 1990. </year> <note> Available as Technical Report CMU-CS-90-134. </note>
Reference-contexts: The framework was intentionally kept weak (by excluding, for example, polymorphism and impredicative constructs) in order to better support mechanization and to allow a simple meta-theory. This has proved auspicious: algorithms for unification have been developed <ref> [5, 21] </ref> and the type theory underlying LF has been amenable to an operational interpretation which is realized in the Elf programming language [18, 19].
Reference: [6] <author> William M. Farmer, Joshua D. Guttman, and F. Javier Thayer. IMPS: </author> <title> An interactive mathematical proof system. </title> <editor> In M. E. Stickel, editor, </editor> <booktitle> 10th International Conference on Automated Deductions, </booktitle> <pages> pages 653-654, </pages> <year> 1990. </year>
Reference-contexts: In the remainder of this section we give another example of an interpretation, which makes the symmetry of conjunction explicit. Similar duality interpretations have been investigated and used in the IMPS system <ref> [6] </ref>. Such an interpretation is characterized by the fact that the language under consideration is interpreted in itself in a non-trivial fashion.
Reference: [7] <author> Phillippa Gardner. </author> <booktitle> Lecture given at the 1991 Workshop on Logical Frameworks. </booktitle> <address> Edinburgh. </address> <month> May, </month> <year> 1991. </year> <note> Modularity in LF 22 </note>
Reference-contexts: Local declarations introduce problems of adequacy that are rectified by ad hoc techniques that segregate types that represent judgements from other types. Subsequently, Gardner <ref> [7] </ref> introduced a more refined notion of framework that enforces such a segregation; it seems plausible that in this setting the aforementioned problems of adequacy do not arise. The possibility of introducing local declarations in the present setting requires further investigation.
Reference: [8] <author> Robert Harper, Furio Honsell, and Gordon Plotkin. </author> <title> A framework for defining logics. </title> <journal> Journal of the ACM, </journal> <note> To appear. A preliminary version appeared in Symposium on Logic in Computer Science, pages 194-204, </note> <month> June </month> <year> 1987. </year>
Reference-contexts: Firstly, they are used to specify logics, type systems, operational semantics and other aspects of languages. Secondly, they form the basis for the implementation of such deductive systems. Thirdly, they provide an appropriate language for the formulation and proof of meta-theorems of programming languages. The LF Logical Framework <ref> [8] </ref> has been designed to provide an appropriate language for the high-level specification of deductive systems as they occur in logic and computer science. Its basic principle is often summarized by saying that judgments (the basic unit of deductive systems) are represented as types and deductions as objects. <p> We conclude with a brief summary of related work in Section 7 and a recapitulation of the concrete syntax in Appendix A. 2 The Core Language We briefly review the LF logical framework <ref> [8] </ref> as realized in Elf [18, 19]. A tutorial introduction to the Elf core language can be found in [15]. The LF calculus is a three-level calculus for objects, families, and kinds. Families are classified by kinds, and objects are classified by types, that is, families of kind Type. <p> Similary, A ! K can stand for x:A: K when x does not appear free in K. The notion of definitional equality we consider here is fi-conversion. Harper et al. <ref> [8] </ref> formulate definitional equality only with fi-conversion and conjecture that the system resulting from adding the -rule would have the properties we list below. This has recently been proved by Coquand [1] and independently by Salvesen [22]. <p> ; x:A ` M : B ` M : x:A: B ` N : A ` M : A A A 0 ` A 0 : Type ` M : A 0 We state a selection of the crucial properties of the LF type theory as given and proven in <ref> [8] </ref> and [1]. 1. (Unicity of Types) If ` M : A and ` M : A 0 then A A 0 . 2. (Strong Normalization) If ` M : A then M is strongly normalizing. 3. (Canonical Forms for Types) If ` A : Type then A x 1 :A <p> The transcription of these into Elf follows the standard LF methodology and is discussed in <ref> [8] </ref>.
Reference: [9] <author> Robert Harper, Donald Sannella, and Andrzej Tarlecki. </author> <title> Logic representation. </title> <booktitle> In Proceedings of the Workshop on Category Theory and Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1989. </year>
Reference-contexts: The problem of modularity in the presentation of theories and logical system has been addressed from the semantical <ref> [10, 9] </ref> and the type-theoretic [3, 4, 25] point of view. Our design has been guided by these ideas and the pragmatic principles of the ML module system [14, 17]. <p> These methods were generalized to an arbitrary logic, considered as an abstract family of consequence relations, by Harper, Sannella, and Tarlecki <ref> [10, 9] </ref>, where their behavior under representation in a logical framework is also considered. Local declarations introduce problems of adequacy that are rectified by ad hoc techniques that segregate types that represent judgements from other types.
Reference: [10] <author> Robert Harper, Donald Sannella, and Andrzej Tarlecki. </author> <title> Structure and representation in LF. </title> <booktitle> In Fourth Annual Symposium on Logic in Computer Science, </booktitle> <pages> pages 226-237. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1989. </year>
Reference-contexts: The problem of modularity in the presentation of theories and logical system has been addressed from the semantical <ref> [10, 9] </ref> and the type-theoretic [3, 4, 25] point of view. Our design has been guided by these ideas and the pragmatic principles of the ML module system [14, 17]. <p> These methods were generalized to an arbitrary logic, considered as an abstract family of consequence relations, by Harper, Sannella, and Tarlecki <ref> [10, 9] </ref>, where their behavior under representation in a logical framework is also considered. Local declarations introduce problems of adequacy that are rectified by ad hoc techniques that segregate types that represent judgements from other types.
Reference: [11] <author> Gerard Huet. </author> <title> The calculus of constructions, documentation and user's guide. Rapport technique 110, </title> <institution> INRIA, Rocquencourt, France, </institution> <year> 1989. </year>
Reference-contexts: Such implicit quantifiers are tied to a form of argument synthesis (as used in systems such as LEGO [20] or the Calculus of Constructions <ref> [11] </ref>) in that the constant K has two implicit arguments which are determined through term reconstruction. 1 Parameterized signatures can be instantiated by providing a definition for the parameter. In the example below this has the form realizor realid = realexp which simply instantiates realid to realexp.
Reference: [12] <author> Zhaohui Luo. </author> <title> ECC, an extended Calculus of Constructions. </title> <booktitle> In Fourth Annual Symposium on Logic in Computer Science, </booktitle> <pages> pages 386-395. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> June </month> <year> 1989. </year>
Reference-contexts: Modularity in LF 19 Much more powerful, impredicative type theories have been investigated by Luo <ref> [12] </ref> and are implemented within the LEGO system [13]. The basis for this work is the Calculus of Constructions [2] which is not intended as a logical framework, but a type theory in which constructive mathematics could be directly formalized and reasoned about internally.
Reference: [13] <author> Zhaohui Luo, Robert Pollack, and Paul Taylor. </author> <title> How to use LEGO. </title> <type> Technical Report LFCS-TN-27, </type> <institution> Laboratory for Foundations of Computer Science, University of Edinburgh, </institution> <year> 1989. </year>
Reference-contexts: Modularity in LF 19 Much more powerful, impredicative type theories have been investigated by Luo [12] and are implemented within the LEGO system <ref> [13] </ref>. The basis for this work is the Calculus of Constructions [2] which is not intended as a logical framework, but a type theory in which constructive mathematics could be directly formalized and reasoned about internally. Explicit theory structuring is achieved through -types.
Reference: [14] <author> David MacQueen. </author> <title> Using dependent types to express modular structure. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 277-286. </pages> <publisher> ACM SIGPLAN/SIGACT, </publisher> <year> 1986. </year>
Reference-contexts: The problem of modularity in the presentation of theories and logical system has been addressed from the semantical [10, 9] and the type-theoretic [3, 4, 25] point of view. Our design has been guided by these ideas and the pragmatic principles of the ML module system <ref> [14, 17] </ref>. For further discussion of related work, the reader is referred to Section 7. 1 Modularity in LF 2 The remainder of this paper is organized as follows. In Section 2 we review the LF Logical Framework as it is realized within the Elf programming language. <p> We first consider Modularity in LF 5 explicit parametrization. This is a more verbose, but more basic, alternative to sharing constraints as they are available within the ML module system <ref> [14] </ref>. We are considering the possibility of adding sharing constraints to the language in a future version of the module calculus. Typically, a signature will be parameterized by a realization of another signature. <p> We leave it to the reader to write out the appropriate realizor. 7 Related and Future Work The design of the module system owes a great deal to the ML module system <ref> [14, 17] </ref>. We have replaced sharing equations by explicit parametrization, at the cost of some verbosity, but with the gain of semantic simplicity. While the similarities to the ML module system are striking in some respects, emphasis has shifted significantly.
Reference: [15] <author> Spiro Michaylov and Frank Pfenning. </author> <title> Natural semantics and some of its meta-theory in Elf. </title> <type> Technical Report MPI-I-91-211, </type> <institution> Max-Planck-Institute for Computer Science, Saarbrucken, Germany, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: Furthermore, it also seems possible to express a wide range of meta-theoretic properties of deductive systems within LF, though this line of research is only in its initial stages <ref> [15] </ref>. We believe that for all three tasks, specification, implementation, and meta-theory of deductive systems, substantial benefits can be derived from explicit structuring mechanisms for the presentation of such systems. <p> A tutorial introduction to the Elf core language can be found in <ref> [15] </ref>. The LF calculus is a three-level calculus for objects, families, and kinds. Families are classified by kinds, and objects are classified by types, that is, families of kind Type.
Reference: [16] <author> Dale Miller. </author> <title> A logical analysis of modules in logic programming. </title> <journal> Journal of Logic Programming, </journal> <volume> 6(1-2):57-77, </volume> <month> January </month> <year> 1989. </year>
Reference-contexts: None of the calculi mentioned above give an integral treatment to search control, which is provided within our framework. In the context of more traditional logic programming, this has been in addressed by Miller <ref> [16] </ref>, but he does not provide any form of name-space management besides local declarations through existential quantification.
Reference: [17] <author> Robin Milner, Mads Tofte, and Robert Harper. </author> <title> The Definition of Standard ML. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: The problem of modularity in the presentation of theories and logical system has been addressed from the semantical [10, 9] and the type-theoretic [3, 4, 25] point of view. Our design has been guided by these ideas and the pragmatic principles of the ML module system <ref> [14, 17] </ref>. For further discussion of related work, the reader is referred to Section 7. 1 Modularity in LF 2 The remainder of this paper is organized as follows. In Section 2 we review the LF Logical Framework as it is realized within the Elf programming language. <p> We leave it to the reader to write out the appropriate realizor. 7 Related and Future Work The design of the module system owes a great deal to the ML module system <ref> [14, 17] </ref>. We have replaced sharing equations by explicit parametrization, at the cost of some verbosity, but with the gain of semantic simplicity. While the similarities to the ML module system are striking in some respects, emphasis has shifted significantly.
Reference: [18] <author> Frank Pfenning. </author> <title> Elf: A language for logic definition and verified meta-programming. </title> <booktitle> In Fourth Annual Symposium on Logic in Computer Science, </booktitle> <pages> pages 313-322. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1989. </year> <note> Also available as Ergo Report 89-067, </note> <institution> School of Computer Science, Carnegie Mellon University, Pittsburgh. </institution>
Reference-contexts: This has proved auspicious: algorithms for unification have been developed [5, 21] and the type theory underlying LF has been amenable to an operational interpretation which is realized in the Elf programming language <ref> [18, 19] </ref>. Furthermore, it also seems possible to express a wide range of meta-theoretic properties of deductive systems within LF, though this line of research is only in its initial stages [15]. <p> We conclude with a brief summary of related work in Section 7 and a recapitulation of the concrete syntax in Appendix A. 2 The Core Language We briefly review the LF logical framework [8] as realized in Elf <ref> [18, 19] </ref>. A tutorial introduction to the Elf core language can be found in [15]. The LF calculus is a three-level calculus for objects, families, and kinds. Families are classified by kinds, and objects are classified by types, that is, families of kind Type. <p> We will only sketch it here by means of an example|details and further discussion can be found in <ref> [18, 19] </ref>. We begin by defining a system of natural deduction for the minimal propositional calculus we have considered so far.
Reference: [19] <author> Frank Pfenning. </author> <title> Logic programming in the LF logical framework. </title> <editor> In Gerard Huet and Gordon Plotkin, editors, </editor> <booktitle> Logical Frameworks, </booktitle> <pages> pages 149-181. </pages> <publisher> Cambridge University Press, </publisher> <year> 1991. </year>
Reference-contexts: This has proved auspicious: algorithms for unification have been developed [5, 21] and the type theory underlying LF has been amenable to an operational interpretation which is realized in the Elf programming language <ref> [18, 19] </ref>. Furthermore, it also seems possible to express a wide range of meta-theoretic properties of deductive systems within LF, though this line of research is only in its initial stages [15]. <p> We conclude with a brief summary of related work in Section 7 and a recapitulation of the concrete syntax in Appendix A. 2 The Core Language We briefly review the LF logical framework [8] as realized in Elf <ref> [18, 19] </ref>. A tutorial introduction to the Elf core language can be found in [15]. The LF calculus is a three-level calculus for objects, families, and kinds. Families are classified by kinds, and objects are classified by types, that is, families of kind Type. <p> Term reconstruction fills in the omitted types in quantifications -xand abstractions [x] and omitted types or objects indicated by an underscore _. In case of ambiguity a warning or error message results. For a description of Elf's term reconstruction phase see <ref> [19] </ref>. 3 Signatures In a typical application of the LF methodology of representing deductive systems, an object language and its rules of deduction are defined through a signature. Well-typed objects, constructed from constants over a fixed signature, represent well-formed object language expressions and deductions. <p> In the example below this has the form realizor realid = realexp which simply instantiates realid to realexp. Such instantiations are checked for type-correctness through signature matching. This ensures that every constant required by the signature ascribed to a formal parameter realid is in 1 See <ref> [19] </ref> for a more complete discussion of this aspect of the Elf front-end. Modularity in LF 6 fact provided by the realizor realexp. If realexp provides additional definitions, those are no longer accessible; that is, signature matching is coercive as in ML. <p> We will only sketch it here by means of an example|details and further discussion can be found in <ref> [18, 19] </ref>. We begin by defining a system of natural deduction for the minimal propositional calculus we have considered so far.
Reference: [20] <author> Randy Pollack. </author> <title> Implicit syntax. </title> <editor> In G. Huet and G. Plotkin, editors, </editor> <booktitle> Proceedings of the First Workshop on Logical Frameworks, Antibes, </booktitle> <pages> pages 421-434. </pages> <note> Preliminary Version, </note> <month> May </month> <year> 1990. </year>
Reference-contexts: Such implicit quantifiers are tied to a form of argument synthesis (as used in systems such as LEGO <ref> [20] </ref> or the Calculus of Constructions [11]) in that the constant K has two implicit arguments which are determined through term reconstruction. 1 Parameterized signatures can be instantiated by providing a definition for the parameter.
Reference: [21] <author> David Pym. </author> <title> Proofs, Search and Computation in General Logic. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, </institution> <year> 1990. </year> <note> Available as CST-69-90, also published as ECS-LFCS-90-125. </note>
Reference-contexts: The framework was intentionally kept weak (by excluding, for example, polymorphism and impredicative constructs) in order to better support mechanization and to allow a simple meta-theory. This has proved auspicious: algorithms for unification have been developed <ref> [5, 21] </ref> and the type theory underlying LF has been amenable to an operational interpretation which is realized in the Elf programming language [18, 19].
Reference: [22] <author> Anne Salvesen. </author> <title> The Church-Rosser theorem for LF with fi-reduction. Unpublished notes to a talk given at the First Workshop on Logical Frameworks in Antibes, </title> <month> May </month> <year> 1990. </year>
Reference-contexts: The notion of definitional equality we consider here is fi-conversion. Harper et al. [8] formulate definitional equality only with fi-conversion and conjecture that the system resulting from adding the -rule would have the properties we list below. This has recently been proved by Coquand [1] and independently by Salvesen <ref> [22] </ref>. For practical purposes the formulation including the -rule is superior, since every term has an equivalent canonical form. Thus, for us, is the least congruence generated from fi-conversions in the usual manner.
Reference: [23] <author> D. Sannella and R. Burstall. </author> <title> Structured theories in LCF. </title> <type> Technical Report CSR-129-83, </type> <institution> University of Edinburgh, </institution> <year> 1983. </year> <note> Modularity in LF 23 </note>
Reference-contexts: In the context of more traditional logic programming, this has been in addressed by Miller [16], but he does not provide any form of name-space management besides local declarations through existential quantification. Sannella and Burstall <ref> [23] </ref> introduced a notion of modular presentation for LCF theories, with an associated search procedure that takes advantage of the structure of a theory presentation to cut down the search space.
Reference: [24] <author> D. T. Sannella and L. A. Wallen. </author> <title> A calculus for the construction of modular Prolog programs. </title> <journal> Journal of Logic Programming, </journal> <note> To appear. A preliminary version appears in the Proceedings of the 4th Symposium on Logic Programming, San Francisco, </note> <month> September </month> <year> 1987. </year>
Reference-contexts: Subsequently, Gardner [7] introduced a more refined notion of framework that enforces such a segregation; it seems plausible that in this setting the aforementioned problems of adequacy do not arise. The possibility of introducing local declarations in the present setting requires further investigation. Sannella and Wallen's proposal <ref> [24] </ref> for a module system for Prolog bears certain similarities to ours as both have been inspired by ML. In their system, signatures provide declarations of arities for predicate and function symbols and structures contain clauses.
Reference: [25] <author> Matthias Weber. </author> <title> A Meta-Calculus for Formal System Development. </title> <editor> R. </editor> <publisher> Oldenbourg Verlag, </publisher> <address> Munchen/Wien, </address> <year> 1991. </year>
Reference-contexts: The problem of modularity in the presentation of theories and logical system has been addressed from the semantical [10, 9] and the type-theoretic <ref> [3, 4, 25] </ref> point of view. Our design has been guided by these ideas and the pragmatic principles of the ML module system [14, 17]. <p> De Bruijn's telescopic mappings [3], for example, provide for a first-class notion of contexts. Along similar lines, a type-theoretic calculus with explicit contexts called DEVA has been developed and applied to a number of interesting examples by de Groote [4] and Weber <ref> [25] </ref>. Our module calculus can be seen as a higher-level language which could be compiled into a lower-level type theory such as DEVA.
References-found: 25

