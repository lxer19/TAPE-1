URL: ftp://ftp.cs.ucsd.edu/pub/team/groupCommunication.ps.Z
Refering-URL: http://www.cs.ucsd.edu/users/flaviu/
Root-URL: http://www.cs.ucsd.edu
Email: flaviu@cs.ucsd.edu  
Title: Synchronous and Asynchronous Group Communication (Long Version)  
Author: Flaviu Cristian 
Address: San Diego  
Affiliation: Deptm of Computer Science and Engineering University of California,  
Abstract: In distributed systems, high service availability can be achieved by letting a group of servers replicate the service state; if some servers fail, the surviving ones know the service state and can continue to provide the service. Group communication services, such as membership and atomic broadcast, have been proposed to solve the problem of maintaining server state replica consistency. Group membership achieves agreement on the history of server groups that provide the service over time, while atomic broadcast achieves agreement on the history of state updates performed in each group. Since many highly available systems must support both hard real-time and soft real-time services, it is of interest to understand how synchronous (hard real-time) and asynchronous (soft real-time) group communication services can be integrated. We contribute towards this goal by proposing a common framework for describing properties of synchronous and asynchronous group communication services and by comparing the properties that such services can provide to simplify the task of replicated programming. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Birman, A. Schiper, and P. Stephenson. </author> <title> Lightweight causal and atomic group multicast. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 9(3) </volume> <pages> 272-314, </pages> <month> Aug </month> <year> 1991. </year>
Reference-contexts: We believe that most implemented asynchronous group communication systems are (implicitly) based on variants of the timed asynchronous system model <ref> [5, 2, 23, 1, 26, 22, 25, 33, 27, 17] </ref>. This model does not assume anything about the distribution of communication delays: a correct protocol based on it always satisfies its safety invariants, and makes guaranteed progress whenever the underlying system satisfies certain stability conditions.
Reference: [2] <author> R. Carr. </author> <title> The Tandem global update protocol. </title> <journal> Tandem Systems Review, </journal> <month> Jun </month> <year> 1985. </year>
Reference-contexts: We believe that most implemented asynchronous group communication systems are (implicitly) based on variants of the timed asynchronous system model <ref> [5, 2, 23, 1, 26, 22, 25, 33, 27, 17] </ref>. This model does not assume anything about the distribution of communication delays: a correct protocol based on it always satisfies its safety invariants, and makes guaranteed progress whenever the underlying system satisfies certain stability conditions.
Reference: [3] <author> D. Chandra, V. Hadzilacos, S. Toueg, and B. Charron-Bost. </author> <title> On the impossibility of group membership. </title> <type> Technical Report 95-1548, </type> <institution> Computer Science Department, Cornell University, </institution> <address> Ithaca, New York 14853, </address> <month> October </month> <year> 1995. </year>
Reference-contexts: This very weak definition of correctness makes it impossible for a processor to decide if another processor is correct, crashed, or just slow. A consequence of this weak definition of correctness is the impossibility of implementing fundamental fault-tolerant services such as consensus and membership in time-free asynchronous systems <ref> [20, 3] </ref>. These services are, however, implementable in timed asynchronous systems in which certain stability conditions hold [16, 19]. Practical systems are often required to be fault-tolerant, so they are naturally timed and make use of timeouts 4 . Thus, most existing distributed systems are timed asynchronous.
Reference: [4] <author> T. Chandra, V. Hadzilacos, and S. Toueg. </author> <title> The weakest failure detector for solving consensus. </title> <booktitle> In Proceedings of the 11th ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 147-158, </pages> <month> Aug </month> <year> 1992. </year>
Reference-contexts: Asynchronous programming, based on communication uncertainty, is in fact an umbrella for several programming paradigms that differ in their underlying system models. Examples of such models are the time-free model of [20], the time-free model augmented with various "failure detectors" <ref> [4] </ref>, and the timed model considered implicitly in [6] and named in [16]. We believe that most implemented asynchronous group communication systems are (implicitly) based on variants of the timed asynchronous system model [5, 2, 23, 1, 26, 22, 25, 33, 27, 17].
Reference: [5] <author> J. Chang and N. Maxemchuk. </author> <title> Reliable broadcast protocols. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(3) </volume> <pages> 251-273, </pages> <month> Aug </month> <year> 1984. </year>
Reference-contexts: We believe that most implemented asynchronous group communication systems are (implicitly) based on variants of the timed asynchronous system model <ref> [5, 2, 23, 1, 26, 22, 25, 33, 27, 17] </ref>. This model does not assume anything about the distribution of communication delays: a correct protocol based on it always satisfies its safety invariants, and makes guaranteed progress whenever the underlying system satisfies certain stability conditions.
Reference: [6] <author> F. Cristian. </author> <title> Probabilistic clock synchronization. </title> <journal> Distributed Computing, </journal> <volume> 3 </volume> <pages> 146-158, </pages> <year> 1989. </year> <note> Early version: </note> <institution> IBM Research Report, </institution> <address> San Jose, RJ 6432, </address> <year> 1988. </year>
Reference-contexts: They communicate only by exchanging messages and by measuring the passage of time. Processors exchange messages via a datagram communication service. Messages can get lost and communication delays are unbounded, although most 2 messages arrive at their destination within a known timeout delay constant d <ref> [6] </ref>. Thus, datagram communication has omission/performance failure semantics [10]. Processors have access to stable storage and hardware clocks. Clocks measure time with a known accuracy by running within a linear envelope of real-time. <p> Most existing distributed systems are timed asynchronous. Previously (e.g. <ref> [6, 10, 15] </ref>) we called such systems simply asynchronous, as opposed to the synchronous systems investigated in [12, 9, 7, 11]. This has created confusion, since other authors (e.g. [20]) have used the adjective "asynchronous" with another meaning. <p> Asynchronous programming, based on communication uncertainty, is in fact an umbrella for several programming paradigms that differ in their underlying system models. Examples of such models are the time-free model of [20], the time-free model augmented with various "failure detectors" [4], and the timed model considered implicitly in <ref> [6] </ref> and named in [16]. We believe that most implemented asynchronous group communication systems are (implicitly) based on variants of the timed asynchronous system model [5, 2, 23, 1, 26, 22, 25, 33, 27, 17].
Reference: [7] <author> F. Cristian. </author> <title> Synchronous atomic broadcast for redundant broadcast channels. </title> <journal> The Journal of Real Time Systems, </journal> <volume> 2 </volume> <pages> 195-212, </pages> <year> 1990. </year> <note> Early version: </note> <institution> IBM Research Report, </institution> <address> San Jose, RJ7203, </address> <year> 1989. </year>
Reference-contexts: Most existing distributed systems are timed asynchronous. Previously (e.g. [6, 10, 15]) we called such systems simply asynchronous, as opposed to the synchronous systems investigated in <ref> [12, 9, 7, 11] </ref>. This has created confusion, since other authors (e.g. [20]) have used the adjective "asynchronous" with another meaning. The difference comes from the fact that the services of interest to us are timed, while those investigated in [20] are time-free. <p> H4) The rate at which diffusions are initiated is limited by flow control methods; this rate is smaller than the rate at which processors and servers can correctly receive and process diffusion messages. Methods for implementing real-time diffusion in point-to-point and broadcast networks are discussed in <ref> [12, 7, 21] </ref>, where it is shown that, under assumptions H1-H4, any message m diffused by p is received and processed at q within a computable network delay time constant N (which depends on F, network topology, and ffi). <p> To highlight commonalities between synchronous and asynchronous group communication protocols, this paper will not always distinguish between real-time and synchronized clock time. It is important however to remember that in a synchronous context, such as section 4, time means clock time (as in <ref> [12, 9, 7] </ref>), while in an asynchronous context, such as section 5, time means real-time (as in [16, 19]), unless otherwise specified. <p> Diffusion and clock synchronization enable the implementation of a synchronous reliable broadcast service <ref> [12, 7, 21] </ref> which, for some constant D (depending on N and *), ensures the following properties: 1) if a processor p starts broadcasting message m at (local) time t, then at (their local) times t + D either all correct processors deliver m or none of them delivers m (atomicity), <p> When one adds to the above broadcast requirements the order requirement that all messages delivered by correct processors be delivered in the same order, one obtains a synchronous atomic broadcast service <ref> [12, 7] </ref>. Since the protocols for synchronous reliable and atomic broadcast are so similar, we will assume that they have the same termination time . <p> when s is awaken to process e is at most t. 9 4.3 Synchronous Group Broadcast Properties A synchronous group broadcast service can be implemented by the members of any group g created by a membership protocol satisfying the previous specification if they add to the atomic broadcast protocols of <ref> [12, 7] </ref> the following restriction: any update u delivered by a g member p is applied by p (to its local state replica) only if the sender of u is a member of g. The resulting group atomic broadcast service has the following interface.
Reference: [8] <author> F. Cristian. </author> <title> Asynchronous atomic broadcast. </title> <journal> IBM Technical Disclosure Bulletin, </journal> <volume> 33(9) </volume> <pages> 115-116, </pages> <month> Feb </month> <year> 1991. </year> <booktitle> Presented at the First IEEE Workshop on Management of Replicated Data, </booktitle> <address> Houston, TX, </address> <month> (Nov </month> <year> 1990). </year> <month> 18 </month>
Reference-contexts: Thus, this protocol allows no "branches" in the history at all. If one were to use the first two membership protocols of [16] and allow state updates to occur in both minority and majority groups to achieve group agreement <ref> [8] </ref>, the state views held by team members joined to different groups that co-exist in time could diverge. The three-round with partition detection protocol enables team members to detect all potential divergences between the states of merging groups. <p> If updates are allowed to occur only in the completed majority groups created by the three-round majority (or the more expensive five-round) protocol, one can achieve (either majority or strict) agreement on a unique history of updates <ref> [8] </ref>. Majority agreement ensures that all team members currently joined to a completed majority group agree on a unique history of updates; other correct team members not joined to this group might have divergent views on the history of updates. <p> Strict agreement guarantees that all correct team members p agree on a linear history h of updates by ensuring that, at any time, any team member p sees a prefix of h. Issues related to achieving partial (that is, group and majority) agreement on update histories are discussed in <ref> [8, 16] </ref>. <p> Finaly, the groups created by an asynchronous membership service reflect the "is connected" rather than the "is correct" physical process reality. 14 5.2 Agreeing on a Linear History of Updates Perhaps the strict agreement broadcast protocol easiest to understand is the "two-round" train protocol of <ref> [8] </ref>. In this protocol, for any majority group g, a train of updates circulates among g members according to a fixed cyclic order.
Reference: [9] <author> F. Cristian. </author> <title> Reaching agreement on processor-group membership in synchronous dis-tributed systems. </title> <journal> Distributed Computing, </journal> <volume> 4 </volume> <pages> 175-187, </pages> <year> 1991. </year> <note> Early version: FTCS-18, 1988, Kyoto. </note>
Reference-contexts: Most existing distributed systems are timed asynchronous. Previously (e.g. [6, 10, 15]) we called such systems simply asynchronous, as opposed to the synchronous systems investigated in <ref> [12, 9, 7, 11] </ref>. This has created confusion, since other authors (e.g. [20]) have used the adjective "asynchronous" with another meaning. The difference comes from the fact that the services of interest to us are timed, while those investigated in [20] are time-free. <p> To highlight commonalities between synchronous and asynchronous group communication protocols, this paper will not always distinguish between real-time and synchronized clock time. It is important however to remember that in a synchronous context, such as section 4, time means clock time (as in <ref> [12, 9, 7] </ref>), while in an asynchronous context, such as section 5, time means real-time (as in [16, 19]), unless otherwise specified. <p> An earlier paper <ref> [9] </ref> has proposed that a synchronous membership service should achieve agreement on the history of all groups that exist in a system over time and on the membership of each such group. <p> A process calls "join-request" when starting. The first upcall, to a client supplied "state?" procedure, asks for the value of the client's local state (to transfer it, if necessary, to newly started processes, according to the synchronous join protocol of <ref> [9] </ref>). A process that starts responds to a "state?" upcall by supplying the initial service state s 0 . The other upcall, to a "new-group" client supplied procedure, notifies the client (in our case the S-server) that it has just joined a new group g. <p> If no process failures or joins occur in [t; t 0 ], then no server leaves its group in [t + max (D; J ); t 0 ]. The synchronous membership protocols of <ref> [9] </ref>, which depend on the synchronous reliable broadcast specified earlier, satisfy the safety and timeliness properties above. <p> The protocols use local clock times for group identifiers, and ensure lockstep progress, in the sense that all members joining a new group g join it at the same local time g + . The values of the D and J constants for the first protocol of <ref> [9] </ref> are for example: + and 2, respectively, where is the period for broadcasting "I-am-alive" messages. To ensure that servers will not be confused by too close failures and joins, it is sufficient that the delay between a server crash and its restart be at least max (D; J). <p> Thus, synchronous membership provides accurate, up-to-date information on which processes are correct and which are not. In particular, the service can be used to implement another frequently needed service, the highly available leadership service <ref> [9] </ref>. A synchronous leadership service is required to ensure: 1) the existence of at most one leader at any point in real time 2) the existence of a real-time constant E such that, if the current leader fails at real-time t, a new leader exists by t+E. <p> the memberships of successive groups contains several deletions or additions, these can be ordered following an arbitrary convention, for example by using the total order on team member names. 9 Such performance failures can be detected and transformed into crashes or requests for re-joining a new group as suggested in <ref> [9] </ref> by letting a server s process an event e scheduled to be processed by local deadline t only if the local clock value when s is awaken to process e is at most t. 9 4.3 Synchronous Group Broadcast Properties A synchronous group broadcast service can be implemented by the
Reference: [10] <author> F. Cristian. </author> <title> Understanding fault-tolerant distributed systems. </title> <journal> Communications of ACM, </journal> <volume> 34(2) </volume> <pages> 56-78, </pages> <month> Feb </month> <year> 1991. </year>
Reference-contexts: Processors exchange messages via a datagram communication service. Messages can get lost and communication delays are unbounded, although most 2 messages arrive at their destination within a known timeout delay constant d [6]. Thus, datagram communication has omission/performance failure semantics <ref> [10] </ref>. Processors have access to stable storage and hardware clocks. Clocks measure time with a known accuracy by running within a linear envelope of real-time. Servers are scheduled to run on processors in response to trigger events such as message arrivals or timeouts. <p> installed in Great Britain and Taiwan, and are scheduled to be deployed in the US by January 1997. 2 For a discussion on how to decide what "most" means in order to achieve a certain failure semantics, the interested reader is referred to the section "Choosing a Failure Semantics" of <ref> [10] </ref>. 2 communications a timed asynchronous system 3 . Most existing distributed systems are timed asynchronous. Previously (e.g. [6, 10, 15]) we called such systems simply asynchronous, as opposed to the synchronous systems investigated in [12, 9, 7, 11]. <p> Most existing distributed systems are timed asynchronous. Previously (e.g. <ref> [6, 10, 15] </ref>) we called such systems simply asynchronous, as opposed to the synchronous systems investigated in [12, 9, 7, 11]. This has created confusion, since other authors (e.g. [20]) have used the adjective "asynchronous" with another meaning. <p> Introducing the d and s likely time bounds makes processor and communication service specifications timed: they prescribe not only which state transitions/outputs should occur in response to trigger events, such as message arrivals or timeouts, but also the real-time intervals within which they are expected to occur <ref> [10] </ref>. In contrast, the specifications considered in [20] are time-free: they specify, for each state and input, only the next state/output, without imposing any constraint on the real-time it takes a state transition/output to occur.
Reference: [11] <author> F. Cristian. </author> <title> Automatic reconfiguration in the presence of failures. </title> <journal> Software Engineering Journal, </journal> <pages> pages 53-60, </pages> <month> Mar </month> <year> 1993. </year>
Reference-contexts: Most existing distributed systems are timed asynchronous. Previously (e.g. [6, 10, 15]) we called such systems simply asynchronous, as opposed to the synchronous systems investigated in <ref> [12, 9, 7, 11] </ref>. This has created confusion, since other authors (e.g. [20]) have used the adjective "asynchronous" with another meaning. The difference comes from the fact that the services of interest to us are timed, while those investigated in [20] are time-free. <p> This easy-to-understand property substantially simplifies the programming of replicated applications (see <ref> [11] </ref> for an example).
Reference: [12] <author> F. Cristian, H. Aghili, R. Strong, and D. Dolev. </author> <title> Atomic broadcast: From simple message diffusion to Byzantine agreement. </title> <journal> Information and Computation, </journal> <volume> 118 </volume> <pages> 158-179, </pages> <month> April </month> <year> 1995. </year> <note> Early version: FTCS15, </note> <month> June </month> <year> 1985. </year>
Reference-contexts: Servers are scheduled to run on processors in response to trigger events such as message arrivals or timeouts. Scheduling delays are unbounded; however, most actual scheduling delays are shorter than a known constant s. When scheduling delays exceed s, servers suffer performance failures <ref> [12] </ref>. Processors and servers use self-checking mechanisms so it is very unlikely that they produce functionally erroneous outputs. Thus, servers have crash/performance failure semantics. Since we are interested in highly available applications, we assume that all crashed servers eventually restart. <p> Most existing distributed systems are timed asynchronous. Previously (e.g. [6, 10, 15]) we called such systems simply asynchronous, as opposed to the synchronous systems investigated in <ref> [12, 9, 7, 11] </ref>. This has created confusion, since other authors (e.g. [20]) have used the adjective "asynchronous" with another meaning. The difference comes from the fact that the services of interest to us are timed, while those investigated in [20] are time-free. <p> H4) The rate at which diffusions are initiated is limited by flow control methods; this rate is smaller than the rate at which processors and servers can correctly receive and process diffusion messages. Methods for implementing real-time diffusion in point-to-point and broadcast networks are discussed in <ref> [12, 7, 21] </ref>, where it is shown that, under assumptions H1-H4, any message m diffused by p is received and processed at q within a computable network delay time constant N (which depends on F, network topology, and ffi). <p> To highlight commonalities between synchronous and asynchronous group communication protocols, this paper will not always distinguish between real-time and synchronized clock time. It is important however to remember that in a synchronous context, such as section 4, time means clock time (as in <ref> [12, 9, 7] </ref>), while in an asynchronous context, such as section 5, time means real-time (as in [16, 19]), unless otherwise specified. <p> Diffusion and clock synchronization enable the implementation of a synchronous reliable broadcast service <ref> [12, 7, 21] </ref> which, for some constant D (depending on N and *), ensures the following properties: 1) if a processor p starts broadcasting message m at (local) time t, then at (their local) times t + D either all correct processors deliver m or none of them delivers m (atomicity), <p> When one adds to the above broadcast requirements the order requirement that all messages delivered by correct processors be delivered in the same order, one obtains a synchronous atomic broadcast service <ref> [12, 7] </ref>. Since the protocols for synchronous reliable and atomic broadcast are so similar, we will assume that they have the same termination time . <p> Since 6 no update commutativity is assumed, to maintain replica consistency all g members need to agree on a unique order in which they apply the updates. An earlier paper <ref> [12] </ref> has proposed that the role of a synchronous atomic broadcast service is to achieve agreement on a unique history of updates. <p> when s is awaken to process e is at most t. 9 4.3 Synchronous Group Broadcast Properties A synchronous group broadcast service can be implemented by the members of any group g created by a membership protocol satisfying the previous specification if they add to the atomic broadcast protocols of <ref> [12, 7] </ref> the following restriction: any update u delivered by a g member p is applied by p (to its local state replica) only if the sender of u is a member of g. The resulting group atomic broadcast service has the following interface.
Reference: [13] <author> F. Cristian, B. Dancey, and J. Dehn. </author> <title> Fault-tolerance in the Advanced Automation System. </title> <booktitle> In Proceedings of the Twentieth Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 6-17, </pages> <address> Newcastle-upon-Tyne, UK, </address> <month> Jun </month> <year> 1990. </year>
Reference-contexts: The paper reflects our practical experience with the design of synchronous and asynchronous group communication services for a complex system for air traffic control, the Advanced Automation System 1 <ref> [13] </ref>. For simplicity, we consider a unique application service S implemented by servers replicated on a fixed set of processors P . The servers (one per processor) form the team of S-servers.
Reference: [14] <author> F. Cristian and C. </author> <title> Fetzer. Timed asynchronous systems: A formal model. </title> <type> Technical Report CSE95-454, UCSD, </type> <year> 1995. </year> <note> Available via anonymous ftp at cs.ucsd.edu as /pub/team/timedAsynchronousModel.ps.Z. </note>
Reference-contexts: Communication between any two processors p and q can only be in one of the above abstract `prophecy' modes: connected, disconnected or partially connected. These are being 3 For a formal definition of the timed asynchronous system model, see <ref> [14] </ref>. 4 While it is true that many of the services encountered in practice do not have explicitly-defined response-time promises, it is also true that all such services become "timed" whenever a higher level service that depends on them, in the worst case the human user, fixes a timeout delay for
Reference: [15] <author> F. Cristian and S. Mishra. </author> <title> Automatic service availability management in asynchronous distributed systems. </title> <booktitle> In Proceedings of the Second International Workshop on Configurable Distributed Systems, </booktitle> <address> Pittsburgh, PA, </address> <month> Mar </month> <year> 1994. </year>
Reference-contexts: Most existing distributed systems are timed asynchronous. Previously (e.g. <ref> [6, 10, 15] </ref>) we called such systems simply asynchronous, as opposed to the synchronous systems investigated in [12, 9, 7, 11]. This has created confusion, since other authors (e.g. [20]) have used the adjective "asynchronous" with another meaning. <p> to be quite reasonable in practice for any well-tuned asyn chronous system, is similar to the majority-stability assumption of [19]. 16 Even though the asynchronous group communication properties are more difficult to un-derstand than the synchronous ones, they can still substantially contribute to simplifying distributed programming (see for an example <ref> [15] </ref>), whenever the H1-H4 hypotheses used to render communication certain cannot be guaranteed to be true at run-time. 6 Discussion Synchronous and asynchronous programming are different system design philosophies, the first assuming that communication is certain, the second assuming that it is not.
Reference: [16] <author> F. Cristian and F. Schmuck. </author> <title> Agreeing on processor-group membership in aynchronous distributed systems. </title> <type> Technical Report CSE95-428, UCSD, </type> <year> 1995. </year> <note> Available via anonymous ftp at cs.ucsd.edu as /pub/team/asyncmembership.ps.Z. </note>
Reference-contexts: A consequence of this weak definition of correctness is the impossibility of implementing fundamental fault-tolerant services such as consensus and membership in time-free asynchronous systems [20, 3]. These services are, however, implementable in timed asynchronous systems in which certain stability conditions hold <ref> [16, 19] </ref>. Practical systems are often required to be fault-tolerant, so they are naturally timed and make use of timeouts 4 . Thus, most existing distributed systems are timed asynchronous. Since this paper only examines timed asynchronous systems, we will refer to them simply as asynchronous in the following text. <p> It is important however to remember that in a synchronous context, such as section 4, time means clock time (as in [12, 9, 7]), while in an asynchronous context, such as section 5, time means real-time (as in <ref> [16, 19] </ref>), unless otherwise specified. <p> this paper is system stability as defined in section 2. (Weaker stability conditions, such as majority stability and -stability are investigated in [19, 18].) Third, because delays are unbounded in asynchronous systems, ensuring agreement on initial group states requires more work than in the synchronous case. 11 An earlier paper <ref> [16] </ref> explored a suite of four increasingly strong asynchronous membership specifications. All protocols described in [16] generate both minority and majority groups, but while the first two expose all these groups to membership service users, the last two restrict the groups visible to users to be majority groups only. <p> majority stability and -stability are investigated in [19, 18].) Third, because delays are unbounded in asynchronous systems, ensuring agreement on initial group states requires more work than in the synchronous case. 11 An earlier paper <ref> [16] </ref> explored a suite of four increasingly strong asynchronous membership specifications. All protocols described in [16] generate both minority and majority groups, but while the first two expose all these groups to membership service users, the last two restrict the groups visible to users to be majority groups only. <p> The last (five-round) protocol, achieves agreement on a linear history of all majority groups. Thus, this protocol allows no "branches" in the history at all. If one were to use the first two membership protocols of <ref> [16] </ref> and allow state updates to occur in both minority and majority groups to achieve group agreement [8], the state views held by team members joined to different groups that co-exist in time could diverge. <p> Strict agreement guarantees that all correct team members p agree on a linear history h of updates by ensuring that, at any time, any team member p sees a prefix of h. Issues related to achieving partial (that is, group and majority) agreement on update histories are discussed in <ref> [8, 16] </ref>. <p> The D' and J' constants provided by the three-round majority protocol of <ref> [16] </ref> are 9ffi + max ( + (jP j + 3)ffi, ), where is the period for "probing" the network connectivity. <p> In <ref> [16] </ref> it is shown how to implement this service by adding to the three-round majority membership protocol the following leader designation rule: if g is a majority group, the process with smallest identifier in g becomes leader D" time units after it joins g. <p> Examples of such models are the time-free model of [20], the time-free model augmented with various "failure detectors" [4], and the timed model considered implicitly in [6] and named in <ref> [16] </ref>. We believe that most implemented asynchronous group communication systems are (implicitly) based on variants of the timed asynchronous system model [5, 2, 23, 1, 26, 22, 25, 33, 27, 17].
Reference: [17] <author> P. Ezhilchelvan, R. Macedo, and S. Shrivastava. Newtop: </author> <title> a fault-tolerant group communication protocol. </title> <booktitle> In Proceedings of the 15th International Conference on Distributed Systems, </booktitle> <address> Vancouver, Canada., </address> <month> May </month> <year> 1995. </year>
Reference-contexts: We believe that most implemented asynchronous group communication systems are (implicitly) based on variants of the timed asynchronous system model <ref> [5, 2, 23, 1, 26, 22, 25, 33, 27, 17] </ref>. This model does not assume anything about the distribution of communication delays: a correct protocol based on it always satisfies its safety invariants, and makes guaranteed progress whenever the underlying system satisfies certain stability conditions.
Reference: [18] <author> C. Fetzer and F. Cristian. </author> <title> Fail-awareness in timed asynchronous systems. </title> <type> Technical Report CSE95-453, UCSD, </type> <year> 1995. </year> <note> Available via anonymous ftp at cs.ucsd.edu as /pub/team/failAwareness.ps.Z. </note>
Reference-contexts: The stability condition considered in this paper is system stability as defined in section 2. (Weaker stability conditions, such as majority stability and -stability are investigated in <ref> [19, 18] </ref>.) Third, because delays are unbounded in asynchronous systems, ensuring agreement on initial group states requires more work than in the synchronous case. 11 An earlier paper [16] explored a suite of four increasingly strong asynchronous membership specifications.
Reference: [19] <author> C. Fetzer and F. Cristian. </author> <title> On the possibility of consensus in asynchronous systems. </title> <booktitle> In 1995 Pacific Rim International Symposium on Fault-Tolerant Systems, </booktitle> <address> Newport Beach, CA, </address> <month> Dec </month> <year> 1995. </year>
Reference-contexts: A consequence of this weak definition of correctness is the impossibility of implementing fundamental fault-tolerant services such as consensus and membership in time-free asynchronous systems [20, 3]. These services are, however, implementable in timed asynchronous systems in which certain stability conditions hold <ref> [16, 19] </ref>. Practical systems are often required to be fault-tolerant, so they are naturally timed and make use of timeouts 4 . Thus, most existing distributed systems are timed asynchronous. Since this paper only examines timed asynchronous systems, we will refer to them simply as asynchronous in the following text. <p> It is important however to remember that in a synchronous context, such as section 4, time means clock time (as in [12, 9, 7]), while in an asynchronous context, such as section 5, time means real-time (as in <ref> [16, 19] </ref>), unless otherwise specified. <p> The stability condition considered in this paper is system stability as defined in section 2. (Weaker stability conditions, such as majority stability and -stability are investigated in <ref> [19, 18] </ref>.) Third, because delays are unbounded in asynchronous systems, ensuring agreement on initial group states requires more work than in the synchronous case. 11 An earlier paper [16] explored a suite of four increasingly strong asynchronous membership specifications. <p> member g broadcasts u then either (a) u is applied by all team members or (b) u is not applied by any team member. 10 This progress assumption, which we believe to be quite reasonable in practice for any well-tuned asyn chronous system, is similar to the majority-stability assumption of <ref> [19] </ref>. 16 Even though the asynchronous group communication properties are more difficult to un-derstand than the synchronous ones, they can still substantially contribute to simplifying distributed programming (see for an example [15]), whenever the H1-H4 hypotheses used to render communication certain cannot be guaranteed to be true at run-time. 6 Discussion
Reference: [20] <author> M. J. Fischer, N. A. Lynch, and M. S. Paterson. </author> <title> Impossibility of distributed consensus with one faulty process. </title> <journal> Journal of the ACM, </journal> <volume> 32(2) </volume> <pages> 374-382, </pages> <month> Apr </month> <year> 1985. </year>
Reference-contexts: Most existing distributed systems are timed asynchronous. Previously (e.g. [6, 10, 15]) we called such systems simply asynchronous, as opposed to the synchronous systems investigated in [12, 9, 7, 11]. This has created confusion, since other authors (e.g. <ref> [20] </ref>) have used the adjective "asynchronous" with another meaning. The difference comes from the fact that the services of interest to us are timed, while those investigated in [20] are time-free. <p> This has created confusion, since other authors (e.g. <ref> [20] </ref>) have used the adjective "asynchronous" with another meaning. The difference comes from the fact that the services of interest to us are timed, while those investigated in [20] are time-free. <p> In contrast, the specifications considered in <ref> [20] </ref> are time-free: they specify, for each state and input, only the next state/output, without imposing any constraint on the real-time it takes a state transition/output to occur. <p> This very weak definition of correctness makes it impossible for a processor to decide if another processor is correct, crashed, or just slow. A consequence of this weak definition of correctness is the impossibility of implementing fundamental fault-tolerant services such as consensus and membership in time-free asynchronous systems <ref> [20, 3] </ref>. These services are, however, implementable in timed asynchronous systems in which certain stability conditions hold [16, 19]. Practical systems are often required to be fault-tolerant, so they are naturally timed and make use of timeouts 4 . Thus, most existing distributed systems are timed asynchronous. <p> Asynchronous programming, based on communication uncertainty, is in fact an umbrella for several programming paradigms that differ in their underlying system models. Examples of such models are the time-free model of <ref> [20] </ref>, the time-free model augmented with various "failure detectors" [4], and the timed model considered implicitly in [6] and named in [16].
Reference: [21] <author> V. Hadzilacos and S. Toueg. </author> <title> Fault-tolerant broadcasts and related problems. </title> <editor> In S. Mul-lender, editor, </editor> <booktitle> Distributed Systems, </booktitle> <pages> pages 97-145. </pages> <publisher> Addison-Wesley, </publisher> <year> 1993. </year> <month> 19 </month>
Reference-contexts: H4) The rate at which diffusions are initiated is limited by flow control methods; this rate is smaller than the rate at which processors and servers can correctly receive and process diffusion messages. Methods for implementing real-time diffusion in point-to-point and broadcast networks are discussed in <ref> [12, 7, 21] </ref>, where it is shown that, under assumptions H1-H4, any message m diffused by p is received and processed at q within a computable network delay time constant N (which depends on F, network topology, and ffi). <p> Diffusion and clock synchronization enable the implementation of a synchronous reliable broadcast service <ref> [12, 7, 21] </ref> which, for some constant D (depending on N and *), ensures the following properties: 1) if a processor p starts broadcasting message m at (local) time t, then at (their local) times t + D either all correct processors deliver m or none of them delivers m (atomicity),
Reference: [22] <author> F. Jahanian, S. Fakhouri, and R. Rajkumar. </author> <title> Processor group membership protocols: Specification, </title> <booktitle> design and implementation. In Proc. 12th Symposium on Reliable Distributed Systems, </booktitle> <month> Oct </month> <year> 1993. </year>
Reference-contexts: We believe that most implemented asynchronous group communication systems are (implicitly) based on variants of the timed asynchronous system model <ref> [5, 2, 23, 1, 26, 22, 25, 33, 27, 17] </ref>. This model does not assume anything about the distribution of communication delays: a correct protocol based on it always satisfies its safety invariants, and makes guaranteed progress whenever the underlying system satisfies certain stability conditions.
Reference: [23] <author> F. Kaashoek and A. Tanenbaum. </author> <title> Group communication in the Amoeba distributed system. </title> <booktitle> In Proc. 11th Int. Conf. on Distributed Computing Systems, </booktitle> <pages> pages 882-891, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: We believe that most implemented asynchronous group communication systems are (implicitly) based on variants of the timed asynchronous system model <ref> [5, 2, 23, 1, 26, 22, 25, 33, 27, 17] </ref>. This model does not assume anything about the distribution of communication delays: a correct protocol based on it always satisfies its safety invariants, and makes guaranteed progress whenever the underlying system satisfies certain stability conditions.
Reference: [24] <author> L. Lamport. </author> <title> Time, clocks, and the ordering of events in a distributed system. </title> <journal> Communications of ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <month> Jul </month> <year> 1978. </year>
Reference-contexts: Let p, q be team members that have both applied updates u 1 and u 2 . If p has applied u 1 before u 2 , then q has also applied u 1 before u 2 . (B s c ) Causality. If u 2 depends causally <ref> [24] </ref> upon u 1 , and u 2 is applied by some correct team member, then u 1 is applied before u 2 by all team members. (B t t ) Termination.
Reference: [25] <author> D. Malki, Y. Amir, D. Dolev, and S. Kramer. </author> <title> The Transis approach to high availability cluster communication. </title> <type> Technical Report CS94-14, </type> <institution> Computer Science Department, The Hebrew University of Jerusalem, Israel, </institution> <year> 1994. </year>
Reference-contexts: We believe that most implemented asynchronous group communication systems are (implicitly) based on variants of the timed asynchronous system model <ref> [5, 2, 23, 1, 26, 22, 25, 33, 27, 17] </ref>. This model does not assume anything about the distribution of communication delays: a correct protocol based on it always satisfies its safety invariants, and makes guaranteed progress whenever the underlying system satisfies certain stability conditions. <p> The price is often a higher message and time complexity. Conversely, the weaker the agreement provided by an asynchronous protocol, 17 the more difficult is its understanding and usage. Protocols that achieve weak forms of agreement, such as group agreement (also called disconnected or partitionable operation <ref> [30, 25] </ref> ) may even require human intervention to solve the conflicts created by diverging replicas. Group agreement protocols compensate for such user unfriendliness by providing lower message and time complexity and higher update availability.
Reference: [26] <author> S. Mishra, L. Peterson, and R. Schlichting. </author> <title> Consul: A communication substrate for fault-tolerant distributed programs. </title> <journal> Distributed Systems Engineering Journal, </journal> <year> 1993. </year>
Reference-contexts: We believe that most implemented asynchronous group communication systems are (implicitly) based on variants of the timed asynchronous system model <ref> [5, 2, 23, 1, 26, 22, 25, 33, 27, 17] </ref>. This model does not assume anything about the distribution of communication delays: a correct protocol based on it always satisfies its safety invariants, and makes guaranteed progress whenever the underlying system satisfies certain stability conditions.
Reference: [27] <author> L. E. Moser, P. M. Melliar-Smith, D. A. Agarwal, R. K. Budhia, and C. A. Lingley-Papadopoulos. Totem: </author> <title> A fault-tolerant multicast group communication system. </title> <journal> Communications of the ACM, </journal> <note> this issue. </note>
Reference-contexts: We believe that most implemented asynchronous group communication systems are (implicitly) based on variants of the timed asynchronous system model <ref> [5, 2, 23, 1, 26, 22, 25, 33, 27, 17] </ref>. This model does not assume anything about the distribution of communication delays: a correct protocol based on it always satisfies its safety invariants, and makes guaranteed progress whenever the underlying system satisfies certain stability conditions.
Reference: [28] <author> Z. Ping and J. Hooman. </author> <title> Formal specification and compositional verification of an atomic broadcast protocol. </title> <booktitle> Real-Time Systems, </booktitle> <volume> 9 </volume> <pages> 119-145, </pages> <year> 1995. </year>
Reference-contexts: The above "instantaneity" assumption allows us to simplify the description of group communication by ignoring delays added by process structuring (for a more rigorous analysis that takes into account delays between message delivery deadlines and actual message delivery times, the interested reader is referred to <ref> [28] </ref>). 4 Synchronous Group Communication We motivate the requirements for synchronous membership and group broadcast informally by making use of the generic service S and team P introduced earlier.
Reference: [29] <author> D. Powell. </author> <title> Failure mode assumptions and assumption coverage. </title> <booktitle> In Proc of the 22d Symp. on Fault-Tolerant Computing, </booktitle> <pages> pages 386-395, </pages> <address> Boston, MA, </address> <month> Jun </month> <year> 1992. </year>
Reference-contexts: The price is the real-time scheduling and hardware redundancy techniques that need to be used to make the probability of violating the hypotheses H1-H4 at run-time sufficiently small (or equivalently, make the coverage of these assumptions be sufficiently high <ref> [29] </ref>). Asynchronous programming, based on communication uncertainty, is in fact an umbrella for several programming paradigms that differ in their underlying system models.
Reference: [30] <author> M. Satyanarayanan, J. Kistler, P. Kumar, M. Okasaki, E. Siegel, and D. Steere. Coda: </author> <title> A highly available file system for a distributed workstation environment. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(4), </volume> <month> Apr </month> <year> 1990. </year>
Reference-contexts: However, since for most practical applications, such automatic conflict resolution is not feasible, the price generally paid for allowing updates in minority groups is the need to have manual conflict resolution <ref> [30] </ref>. If updates are allowed to occur only in the completed majority groups created by the three-round majority (or the more expensive five-round) protocol, one can achieve (either majority or strict) agreement on a unique history of updates [8]. <p> The price is often a higher message and time complexity. Conversely, the weaker the agreement provided by an asynchronous protocol, 17 the more difficult is its understanding and usage. Protocols that achieve weak forms of agreement, such as group agreement (also called disconnected or partitionable operation <ref> [30, 25] </ref> ) may even require human intervention to solve the conflicts created by diverging replicas. Group agreement protocols compensate for such user unfriendliness by providing lower message and time complexity and higher update availability.
Reference: [31] <author> A. Schiper and M. Raynal. </author> <title> From group communication to transactions in distributed systems. </title> <journal> Communications of the ACM, </journal> <note> this issue. </note>
Reference-contexts: Some applications, however, cannot tolerate any replica state divergence at all <ref> [31] </ref>. These require the stronger strict agreement. Strict agreement guarantees that all correct team members p agree on a linear history h of updates by ensuring that, at any time, any team member p sees a prefix of h.
Reference: [32] <author> R. Strong, D. Skeen, F. Cristian, and H. Aghili. </author> <title> Handshake protocols. </title> <booktitle> In Proceedings of the Seventh International Conference on Distributed Computing Systems, </booktitle> <pages> pages 521-528, </pages> <address> Berlin, </address> <month> Sep </month> <year> 1987. </year>
Reference-contexts: The three-round with partition detection protocol enables team members to detect all potential divergences between the states of merging groups. Once such potential conflicts are detected, the methods of <ref> [32] </ref> can be used to automatically merge group states, for example when updates are commutative or when only the most recent update to a replicated variable is of importance.
Reference: [33] <author> R. van Renesse, K. Birman, and T. Hickey. </author> <title> Design and performance of Horus: a lightweight group communication system. </title> <type> TR 94-1442, </type> <institution> Cornell Univ, dept. of Computer Science, </institution> <month> Aug </month> <year> 1994. </year> <month> 20 </month>
Reference-contexts: We believe that most implemented asynchronous group communication systems are (implicitly) based on variants of the timed asynchronous system model <ref> [5, 2, 23, 1, 26, 22, 25, 33, 27, 17] </ref>. This model does not assume anything about the distribution of communication delays: a correct protocol based on it always satisfies its safety invariants, and makes guaranteed progress whenever the underlying system satisfies certain stability conditions.
References-found: 33

