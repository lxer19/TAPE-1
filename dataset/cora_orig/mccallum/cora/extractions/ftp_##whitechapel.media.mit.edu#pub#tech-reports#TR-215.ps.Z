URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-215.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: picard@media.mit.edu tkabir@rp.csiro.au fliu@media.mit.edu  
Phone: 76  
Title: Real-time Recognition with the entire Brodatz Texture Database  
Author: Rosalind W. Picard Tanweer Kabir Fang Liu 
Address: PO Box  Cambridge, MA 02139 Epping, NSW 2121 Cambridge, MA 02139  
Affiliation: MIT Media Lab Perceptual Computing  MIT Media Lab CSIRO;  MIT Media Lab  
Note: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition New York, June 1993, pp 638-639.  TR 215  
Abstract: The Brodatz Album has become the de facto standard for evaluating texture algorithms, with hundreds of studies having been applied to small sets of its images. This paper compares two powerful recognition algorithms, principal components analysis and multiscale autoregressive models, by evaluating them on a 999-image database derived from the entire Brodatz Album. The variety of homogeneous and non-homogeneous images studied is thus nearly an order of magnitude larger than has been compared before, giving one snapshot of the "state of the art" in real-time texture recognition. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Brodatz. </author> <title> Textures: A Photographic Album for Artists and Designers. </title> <publisher> Dover, </publisher> <address> New York, </address> <year> 1966. </year>
Reference-contexts: This paper examines and compares two powerful recognition methods in a new multimedia search environment where real-time discrimination between over a hundred competing classes is important. 2 Brodatz texture database The "Brodatz texture database" is derived from the Brodatz Album <ref> [1] </ref>. It was formed by cropping nine 128 fi 128 subimages from the centers of 111 1 different original 8-bit 512 fi 512 images received on tape from the Georgia Institute of Technology.
Reference: [2] <author> R. W. Picard and T. Kabir. </author> <title> Finding similar patterns in large image databases. </title> <booktitle> In Proc. ICASSP, pages V-161-V-164, </booktitle> <address> Minneapolis, MN, </address> <year> 1993. </year>
Reference-contexts: By including the non-homogeneous Brodatz images in the database, a much more difficult and realistic scenario is obtained. We have found subsets of the Bro-datz database which reach 100% classification accuracy with no false alarms <ref> [2] </ref>, but performance drops significantly when considering the whole database. For a very inhomogeneous Brodatz image, humans might not classify its 9 database images as being from the same class. <p> The training and evaluation for this method, its implementation in the image database environment, and its use in ranking "how easy" each Brodatz image is to classify are described in <ref> [2] </ref>. The features produced for each database image consist of 99 projection coefficients onto a set of eigenfunctions. The eigenfunctions are from the pooled covariance matrix of a randomly-chosen training set of 100 images.
Reference: [3] <author> M. Unser. </author> <title> Local linear transforms for texture measurements. </title> <booktitle> Signal Processing, </booktitle> <volume> 11 </volume> <pages> 61-78, </pages> <year> 1986. </year>
Reference-contexts: Consequently, it provides an important benchmark for evaluating progress in texture recognition. 3 Two recognition methods Principal component analysis is an important tool in pattern recognition, and has been successfully applied to small sets of textures <ref> [3] </ref> as well as many other patterns for representation, recognition and discrimination. The key difference in the method used here is that it has been made shift-invariant which greatly improves its performance on textures. <p> It may seem surprising that fifteen SAR features achieved greater than 90% accuracy with the "in view=success" criterion while twenty principal components achieved less than 80%. Eigenfilter-based features have been found to perform as well as co-occurrence features on small sets of Brodatz images <ref> [3] </ref>. Since co-occurrences contain more information than correlations, and since basic SAR features are estimated from correlations, it seems that significant improvement is due to the multi-scale information. The multi-scale SAR should be compared with other filter-banks such as Gabor, wavelet, and steerable pyramid.
Reference: [4] <author> S. Akamatsu, T. Sasaki, H. Fukamachi, and Y. Sue-naga. </author> <title> A robust face identification scheme - KL expansion of an invariant feature space. </title> <booktitle> In Proc. SPIE Conf. on Intell. Robots and Comp. Vis., </booktitle> <volume> volume 1607, </volume> <pages> pages 71-84, </pages> <address> Boston, MA, </address> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: The key difference in the method used here is that it has been made shift-invariant which greatly improves its performance on textures. The shift-invariance is a consequence of discarding the phase of the patterns in a method similar to that used for face recognition by Akamatsu, et. al. <ref> [4] </ref>. The training and evaluation for this method, its implementation in the image database environment, and its use in ranking "how easy" each Brodatz image is to classify are described in [2]. The features produced for each database image consist of 99 projection coefficients onto a set of eigenfunctions.
Reference: [5] <author> J. Mao and A. K. Jain. </author> <title> Texture classification and segmentation using multiresolution simultaneous autoregressive models. </title> <booktitle> Patt. Rec., </booktitle> <volume> 25(2) </volume> <pages> 173-188, </pages> <year> 1984. </year>
Reference-contexts: This is a second-order noncausal model characterized by five parameters at each resolution level. At any one scale, the model is shift-invariant in its assumption that the parameters are not spatially varying. The model used here is equivalent to that of Mao and Jain <ref> [5] </ref> with the exception of not including their rotation-invariant averaging. Parameters and parameter covariances for this model were estimated for each of the 999 images.
References-found: 5

