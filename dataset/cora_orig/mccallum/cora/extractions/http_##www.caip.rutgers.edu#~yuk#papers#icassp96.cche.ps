URL: http://www.caip.rutgers.edu/~yuk/papers/icassp96.cche.ps
Refering-URL: 
Root-URL: 
Title: AN HMM APPROACH TO TEXT-PROMPTED SPEAKER VERIFICATION  
Author: ChiWei Che Qiguang Lin Dong-Suk Yuk 
Address: University,Piscataway, NJ, USA  
Affiliation: CAIP Center, Rutgers  
Abstract: This paper presents a speaker recognition system based on Hidden Markov Modes (HMM). The system utilizes concatenated phoneme HMMs and works in a text-prompted mode. Each registered speaker has a separate set of HMMs which are trained using the Baum-Welch algorithm. The speaker recognition system has been evaluated with the YOHO voice verification corpus in terms of both speaker verification and closed-set speaker identification. It is shown that by using 10 seconds of testing speech, an error rate of 0.09% for male and 0.29% for female are obtained for speaker identification with a total population of 138 talkers. For speaker verification, under the 0% false rejection condition, the system achieves a false acceptance rate of 0.09% for male and 0% for female. This paper also studies effects of various factors (such as the mixture number and cohort selection) on the performance of speaker recognition. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Campbell, J. Jr., </author> <title> "Testing with the YOHO CO-ROM Voice Verification Corpus," </title> <booktitle> Proc. </booktitle> <volume> IEEE-ICASSP 95, </volume> <pages> pp. 341-345 </pages>
Reference-contexts: All waveforms are low-pass filtered at 3.8 kHz and sampled at 8 kHz. More detailed description of the corpus is found in <ref> [4, 1] </ref>. 2.1. Phone Coverage There are 20 monophones for English digits which occur in the YOHO database. Their corresponding ARPAbets are listed in Table 1. <p> It should be noted that in all the following verification experiments, cohort speakers are excluded from all impostor tests and that there are no inter-gender tests, following the suggestion outlined in <ref> [1] </ref>. Utt. length M M norm F F norm 2.5 (s) 7.79 0.71 7.77 0.32 10. (s) 4.67 0.09/0.0 3.12 0.00/0.0 Table 4. Speaker verification error rate (%) for both Male and Female portion of YOHO. <p> The results is also shown as the receiver Operating Curve/Points (ROC) in Figure 3. The present system thus meets the U.S. Government's performance requirement of 0.1% FA and 1% FR. Compared with available performance reports on the YOHO database up todate, the present system gives the best performance <ref> [1, 5, 2] </ref>. False Acceptance or Type I Error (in %) False Rejection or Type II Error (in %) Receiver Operating Curve/Points 0.01 1 0.1 0.30.03 0.001 0.001 1 0.2 0.5% Equal Error Rate US Gov't Req US Gov't Goal The CAIP HMM system Figure 3.
Reference: [2] <author> Douglas, A. Reynolds and Beth, A. </author> <title> Carlson "Text Dependent Speaker Verification Using Decoupled and Integrated Speaker and Speech Recognizers," </title> <booktitle> Proc. </booktitle> <volume> Eu-roSpeech 95, </volume> <pages> pp. 647-650. </pages>
Reference-contexts: The results is also shown as the receiver Operating Curve/Points (ROC) in Figure 3. The present system thus meets the U.S. Government's performance requirement of 0.1% FA and 1% FR. Compared with available performance reports on the YOHO database up todate, the present system gives the best performance <ref> [1, 5, 2] </ref>. False Acceptance or Type I Error (in %) False Rejection or Type II Error (in %) Receiver Operating Curve/Points 0.01 1 0.1 0.30.03 0.001 0.001 1 0.2 0.5% Equal Error Rate US Gov't Req US Gov't Goal The CAIP HMM system Figure 3.
Reference: [3] <author> Furui, S., </author> <title> "An Overview of Speaker Recognition Tech nology," </title> <booktitle> Proc. ESCA Workshop on Automatic Speaker Recognition, </booktitle> <year> 1994, </year> <pages> pp. 1-9. </pages>
Reference-contexts: Each time the user is asked to say a phrase/sentence which is randomly prompted by the system and which can not be predicted in advance. Recent studies show that high performance of text-prompted speaker recognition can be achieved using HMM techniques <ref> [3] </ref>. For example, Matsui and Furui [6, 7] demonstrated that a concatenated phone HMM system outperforms conventional template matching and vector-quantization approaches.
Reference: [4] <author> Higgins, A., J. Porter, and L. Bahler, </author> <title> "YOHO Speaker Authentication," </title> <type> Final Report, </type> <institution> ITT Defense Communications Division, </institution> <year> 1989. </year>
Reference-contexts: All waveforms are low-pass filtered at 3.8 kHz and sampled at 8 kHz. More detailed description of the corpus is found in <ref> [4, 1] </ref>. 2.1. Phone Coverage There are 20 monophones for English digits which occur in the YOHO database. Their corresponding ARPAbets are listed in Table 1.
Reference: [5] <author> Liou, H.-S., and Mammone, R. </author> <title> "A Subword Neural Tree Network Approach to Text-Dependent Speaker Verification," </title> <booktitle> Proc. </booktitle> <volume> IEEE-ICASSP 95, </volume> <pages> pp. 357-360. </pages>
Reference-contexts: The results is also shown as the receiver Operating Curve/Points (ROC) in Figure 3. The present system thus meets the U.S. Government's performance requirement of 0.1% FA and 1% FR. Compared with available performance reports on the YOHO database up todate, the present system gives the best performance <ref> [1, 5, 2] </ref>. False Acceptance or Type I Error (in %) False Rejection or Type II Error (in %) Receiver Operating Curve/Points 0.01 1 0.1 0.30.03 0.001 0.001 1 0.2 0.5% Equal Error Rate US Gov't Req US Gov't Goal The CAIP HMM system Figure 3.
Reference: [6] <author> Matsui, T., and Furui, S., </author> <title> "Speaker Recognition Using Concatenated Phoneme HMMs," </title> <booktitle> Proc. Int. Conf. Spoken Language Processing, </booktitle> <address> Banff, Th.s AM.4.3, </address> <year> 1992. </year>
Reference-contexts: Each time the user is asked to say a phrase/sentence which is randomly prompted by the system and which can not be predicted in advance. Recent studies show that high performance of text-prompted speaker recognition can be achieved using HMM techniques [3]. For example, Matsui and Furui <ref> [6, 7] </ref> demonstrated that a concatenated phone HMM system outperforms conventional template matching and vector-quantization approaches.
Reference: [7] <author> Matsui, T., and Furui, S., </author> <title> "Concatenated Phoneme Models for Text-Variable Speaker Recognition," </title> <booktitle> Proc. </booktitle> <volume> IEEE-ICASSP 93, </volume> <pages> pp. </pages> <month> II-391-394. </month>
Reference-contexts: Each time the user is asked to say a phrase/sentence which is randomly prompted by the system and which can not be predicted in advance. Recent studies show that high performance of text-prompted speaker recognition can be achieved using HMM techniques [3]. For example, Matsui and Furui <ref> [6, 7] </ref> demonstrated that a concatenated phone HMM system outperforms conventional template matching and vector-quantization approaches.
Reference: [8] <author> Rabiner, L. R. and Juang, B.-H. </author> <title> Fundamentals of Speech Recognition, </title> <publisher> Prentice Hall, </publisher> <address> New Jersey, </address> <year> 1993. </year>
Reference-contexts: For example, Matsui and Furui [6, 7] demonstrated that a concatenated phone HMM system outperforms conventional template matching and vector-quantization approaches. HMM based speaker recognition systems have several advantages, including that the modeling technique is well established <ref> [8] </ref> and that there is no need to explicitly segment the incoming speech signal into speech and non-speech parts, because HMMs incorporate silence models. Furthermore, the same system can be used to recognize the spoken text to check whether the speaker is indeed saying what he/she is supposed to say.
Reference: [9] <author> Rosenberg, A. E., Lee, C. H., and Soong, F. K., </author> <title> "Sub Word Unit Talker Verification Using Hidden Markov Models," </title> <booktitle> Proc. </booktitle> <volume> IEEE-ICASSP 90, </volume> <pages> pp. 269-272. </pages>
Reference-contexts: The best results of speaker identification is 0.09% for male and 0.29% for female. In the following speaker verification experiments, the 3-mixture/state HMM system will be used. 4.3. Cohort Speaker Cohort normalization for speaker verification is nowadays commonly used <ref> [9] </ref>. Before discussing results of speaker verification, the relationship between the equal error rate (EER) and the cohort size is first studied in Figure 2. The closest K-speakers are chosen as the cohort speakers. From size increases up to 5 speakers.
Reference: [10] <author> Young S. J., Woodland, P, C., and Byrne, W, J., </author> <title> "HTK Version 1.5: User, Reference and Programmer Manual," </title> <institution> Cambridge University Engineering Department & Entropic Research Laboratory Inc., </institution> <year> 1993 </year>
Reference-contexts: HMM RECOGNIZER 3.1. Front-end And Acoustic Modeling The current system is developed based on the Entropic HTK V1.5 toolkit <ref> [10] </ref>. The front-end analysis includes (1) preemphasis of the speech signal, (2) FFT-calculation of speech frames windowed by a 25 ms-long Hamming window (moving at every 10 ms), and (3) Inverse cosine transform to determine mel-frequency cepstrum coefficients (MFCC).
References-found: 10

