URL: ftp://ftp.speech.sri.com/pub/people/fuliang/papers/eurospeech97-multilingual.ps
Refering-URL: http://www.speech.sri.com/people/fuliang/fuliang.html
Root-URL: 
Title: A STUDY OF MULTILINGUAL SPEECH RECOGNITION  
Author: Fuliang Weng, Harry Bratt, Leonardo Neumeyer, and Andreas Stolcke 
Web: http://www.speech.sri.com  
Address: Menlo Park, California  
Affiliation: Speech Technology And Research Laboratory SRI International  
Abstract: This paper describes our work in developing multilingual (Swedish and English) speech recognition systems in the ATIS domain. The acoustic component of the multilingual systems is realized through sharing Gaussian codebooks across Swedish and English allophones. The language model (LM) components are constructed by training a statistical bigram model, with a common backoff node, on bilingual texts, and by combining two monolingual LMs into a probabilistic finite state grammar. This system uses a single decoder for Swedish and English sentences, and is capable of recognizing sentences with words from both languages. Preliminary experiments show that sharing acoustic models across the two languages has not resulted in improved performance, while sharing a backoff node at the LM component provides flexibility and ease in recognizing bilingual sentences at the expense of a slight increase in word error rate in some cases. As a by-product, the bilingual decoder also achieves good performance on language identification (LID). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Carter, J. Kaja, L. Neumeyer, M. Rayner, F. Weng, and M. Wiren. </author> <title> Handling compound nouns in a Swedish speechunderstanding system. </title> <booktitle> In Proceedings of ICSLP-96, </booktitle> <year> 1996. </year>
Reference-contexts: To build the Swedish version of the ATIS database, the English transcriptions were translated to Swedish. The Swedish prompts were then read by 100 subjects (50 male, 50 female). For rapid experimentation we used 4000 male utterances per language as training data <ref> [1] </ref>. Our main motivation for sharing acoustic parameters across the two languages is to make better use of available data in training Gaussian codebooks.
Reference: [2] <author> V. Digalakis, P. Monaco, and H. Murveit. Genones: </author> <title> Generalized mixture tying in continuous hidden Markov model-based speech recognizers. </title> <journal> IEEE Transactions on Speech and Audio Processing, </journal> <pages> pp. 281289, </pages> <year> 1996. </year>
Reference-contexts: In addition to the two sets of PTM acoustic models just described, two sets of genonic acoustic models were trained <ref> [2] </ref>. Notice that in a genonic system, HMM allophones of a given class share the same Gaussian codebook, and the sets of HMM states that share the same mixture components are determined automatically using agglomerative clustering techniques. These two genonic acoustic models were booted from their corresponding PTM acoustic models.
Reference: [3] <author> J. Hieronymus and S. Kadambe. </author> <title> Robust spoken language identification using large vocabulary speech recognition. </title> <booktitle> In Proceedings of ICASSP-97, </booktitle> <year> 1997. </year>
Reference-contexts: Effectively, this approach allows us to run the two language-specific recognizers in parallel, choosing the language whose best hypothesis gives the higher score <ref> [5, 3] </ref>. We will discuss it further in Section 4. 3. MULTILINGUAL RECOGNITION In the recognition experiments, six PTM and eight genonic speech systems were constructed. <p> The constrained LM also achieves very good LID performance (Table 7), although our task is not directly comparable to those commonly used in LID research [7]. Compared with LID systems using multiple large vocabulary continuous speech recognizers <ref> [5, 3] </ref>, our system uses a single Viterbi algorithm to prune hypotheses in a multilingual space, which enables us to eliminate unlikely language candidates at an early stage. Furthermore, because of the sharing of acoustic models, our system is more compact and offers real time performance. 5.
Reference: [4] <author> S. M. Katz. </author> <title> Estimation of probabilities from sparse data for the language model component of a speech recognizer. </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing, </journal> <volume> 35(3), </volume> <year> 1987. </year>
Reference-contexts: Language Model Training Issues In the construction of the LM components of the recognition systems, statistical grammars were trained in the form of bigram backoff models <ref> [4] </ref>. For the purpose of comparison, monolingual and bilingual LMs were created separately. The monolingual LMs were trained using text from a single language. The bilingual LMs were trained using the pooled English and Swedish data. The latter resulted in a bilingual LM with a single backoff node.
Reference: [5] <author> S. Lowe, A. Demedts, L. Gillick, M. Mandel, and B. Peskin. </author> <title> Language identification via large vocabulary speaker inde-pendent continuous speech recognition. </title> <booktitle> In Proceedings of ARPA Human Language Technology Workshop, </booktitle> <year> 1994. </year>
Reference-contexts: Effectively, this approach allows us to run the two language-specific recognizers in parallel, choosing the language whose best hypothesis gives the higher score <ref> [5, 3] </ref>. We will discuss it further in Section 4. 3. MULTILINGUAL RECOGNITION In the recognition experiments, six PTM and eight genonic speech systems were constructed. <p> The constrained LM also achieves very good LID performance (Table 7), although our task is not directly comparable to those commonly used in LID research [7]. Compared with LID systems using multiple large vocabulary continuous speech recognizers <ref> [5, 3] </ref>, our system uses a single Viterbi algorithm to prune hypotheses in a multilingual space, which enables us to eliminate unlikely language candidates at an early stage. Furthermore, because of the sharing of acoustic models, our system is more compact and offers real time performance. 5.
Reference: [6] <author> P. J. Price. </author> <title> Evaluation of spoken language systems: the ATIS domain. </title> <booktitle> In Proceedings of 1990 DARPA Workshop on Speech and Natural Language, </booktitle> <year> 1990. </year>
Reference-contexts: Section 4 presents LID related results. Section 5 gives a brief summary of our work and future directions. 2. MULTILINGUAL TRAINING ISSUES 2.1. Acoustic Training Issues In this work, we experimented with bilingual (En- glish/Swedish) recognition systems for the Air Travel Information System (ATIS) domain <ref> [6] </ref>. To build the Swedish version of the ATIS database, the English transcriptions were translated to Swedish. The Swedish prompts were then read by 100 subjects (50 male, 50 female). For rapid experimentation we used 4000 male utterances per language as training data [1].
Reference: [7] <author> M. Zissman and A. Martin. </author> <title> Language identification overview. </title> <booktitle> In Proceedings of the Fifteenth Annual Speech Research Symposium, </booktitle> <year> 1995. </year>
Reference-contexts: Language identification errors when using the constrained LM. obtained by taking a simple majority of the words in a hypothesis (Table 6). The constrained LM also achieves very good LID performance (Table 7), although our task is not directly comparable to those commonly used in LID research <ref> [7] </ref>. Compared with LID systems using multiple large vocabulary continuous speech recognizers [5, 3], our system uses a single Viterbi algorithm to prune hypotheses in a multilingual space, which enables us to eliminate unlikely language candidates at an early stage.
References-found: 7

