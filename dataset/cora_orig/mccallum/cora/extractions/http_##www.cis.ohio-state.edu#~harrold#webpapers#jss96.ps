URL: http://www.cis.ohio-state.edu/~harrold/webpapers/jss96.ps
Refering-URL: http://www.cis.ohio-state.edu/~harrold/allpapers.html
Root-URL: 
Email: harrold@cis.ohio-state.edu ofut@isse.gmu.edu kanu@eng.sun.com  
Title: An Approach to Fault Modeling and Fault Seeding Using the Program Dependence Graph 1  
Author: Mary Jean Harrold A. Jefferson Offutt Kanupriya Tewary 
Keyword: Fault, fault modeling, fault seeding, mutation testing, dataflow testing.  
Address: MS-UMPK16-303 Columbus, OH Fairfax, VA Mountain View, CA  
Affiliation: Computer and Information Sciences ISSE Sun Microsystems Ohio State University George Mason University  
Abstract: We present a fault-classification scheme and a fault-seeding method that are based on the manifestation of faults in the program dependence graph (PDG). We enhance the domain/computation fault-classification scheme developed by Howden to further characterize faults as structural and statement-level, depending on the differences between the PDG for the original program and the PDG for the faulty program. We perform transformations on the PDG to produce the different types of faults described in our PDG-based fault-classification scheme. To demonstrate the usefulness of our technique, we implemented a fault seeder to embed faults in C programs. Our fault seeder makes controlled fault transformations to the PDG for a C program, and generates C code from the transformed PDG. The current version of the fault seeder creates multiple fault-seeded versions of the original program, each with one known fault. To demonstrate the operation of the fault seeder, we used it to perform a study of the effectiveness of dataflow testing and mutation testing using a set of faulty programs generated by our fault seeder. We also used the faulty programs to determine the mutation and dataflow adequacy of the fault-detecting test sets. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Agrawal, R. DeMillo, R. Hathaway, Wm. Hsu, Wynne Hsu, E. Krauser, R. J. Martin, A. Mathur, and E. Spafford. </author> <title> Design of mutant operators for the C programming language. </title> <type> Technical report SERC-TR-41-P, </type> <institution> Software Engineering Research Center, Purdue University, West Lafayette IN, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: The Mothra system [9, 13], was developed for Fortran-77. Mothra uses a set of mutant operators, described by King and Offutt [25], that were based on earlier mutation systems [3, 6]. More recent efforts have focused on mutation systems for the C language. Reference <ref> [1] </ref> describes a set of mutant operators for C, which we henceforth call the Purdue C operators. To date, there are two publicized systems that use these operators. Delamaro et al. developed Proteum [8, 7], and Untch implemented TUMS [35, 36] to implement the schema-based execution model [36].
Reference: [2] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers, Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: Dataflow analysis <ref> [2, 26] </ref> is used to gather dataflow information. The DDS represents the data dependencies in the program. In Figure 1, the dashed lines are data dependence edges for variable j. Dataflow Testing Dataflow testing considers the associations between variable definitions and variable uses.
Reference: [3] <author> D. M. St. Andre. </author> <title> Pilot mutation system (PIMS) user's manual. </title> <type> Technical report GIT-ICS-79/04, </type> <institution> Georgia Institute of Technology, </institution> <month> April </month> <year> 1979. </year>
Reference-contexts: Mutation analysis has been applied to several languages, and several tools have been developed to implement mutation analysis systems. The Mothra system [9, 13], was developed for Fortran-77. Mothra uses a set of mutant operators, described by King and Offutt [25], that were based on earlier mutation systems <ref> [3, 6] </ref>. More recent efforts have focused on mutation systems for the C language. Reference [1] describes a set of mutant operators for C, which we henceforth call the Purdue C operators. To date, there are two publicized systems that use these operators.
Reference: [4] <author> V. R. Basili and R. W. Selby. </author> <title> Comparing the effectiveness of software testing strategies. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 13(12), </volume> <month> December </month> <year> 1987. </year>
Reference-contexts: We measure the effectiveness of a testing technique in terms of its ability to detect certain types of faults; we also measure the effectiveness of a testing technique relative to the effectiveness of other testing techniques. Although there have been studies of fault categories <ref> [4, 11, 18, 22] </ref>, there is no established correlation between categories of faults and testing techniques that expose those faults. <p> Although there have been studies of fault categories [4, 11, 18, 22], there is no established correlation between categories of faults and testing techniques that expose those faults. Furthermore, although there have been formal and empirical studies <ref> [4, 17, 18, 30] </ref> on the relative effectiveness of testing techniques, there is no conclusive evidence that one testing technique is superior in fault-detection ability. <p> Zeil [40] later detailed Howden's categorization. We have extended the domain/computation fault categorization so that it can be easily translated to a well-defined program representation and hence, automated. Basili and Selby <ref> [4] </ref> classified faults according to two schemes. The first scheme separates faults of commission from faults of omission, and the second scheme partitions faults into six classes: initialization, computation, control, interface, data, and cosmetic.
Reference: [5] <author> T. A. Budd. </author> <title> Mutation analysis: Ideas, examples, problems, and prospects in computer program testing. </title> <editor> In B. Chandrasekaran and S. Radicchi, editors, </editor> <booktitle> Computer Program Testing, </booktitle> <pages> pages 129-148. </pages> <publisher> North-Holland, </publisher> <year> 1981. </year>
Reference-contexts: In Figure 3, mutant 3 is an equivalent mutant because, if the value of X is 8, it makes no difference whether we check X &gt; 0 or X &gt;= 0. Budd <ref> [5] </ref> defined mutation analysis as a method for evaluating the degree to which a set of tests exercise a program. His suggested procedure extends the test set until all nonequivalent mutants have been killed.
Reference: [6] <author> T. A. Budd, R. Hess, and F. G. Sayward. </author> <title> EXPER implementor's guide. </title> <type> Technical report, </type> <institution> Department of Computer Science, Yale University, </institution> <year> 1980. </year>
Reference-contexts: Mutation analysis has been applied to several languages, and several tools have been developed to implement mutation analysis systems. The Mothra system [9, 13], was developed for Fortran-77. Mothra uses a set of mutant operators, described by King and Offutt [25], that were based on earlier mutation systems <ref> [3, 6] </ref>. More recent efforts have focused on mutation systems for the C language. Reference [1] describes a set of mutant operators for C, which we henceforth call the Purdue C operators. To date, there are two publicized systems that use these operators.
Reference: [7] <author> M. E. Delamaro and J. C. Maldonado. Proteum: </author> <title> A mutation testing tool for C programs. </title> <note> Appeared in Purdue SERC newsletter, </note> <year> 1995. </year>
Reference-contexts: More recent efforts have focused on mutation systems for the C language. Reference [1] describes a set of mutant operators for C, which we henceforth call the Purdue C operators. To date, there are two publicized systems that use these operators. Delamaro et al. developed Proteum <ref> [8, 7] </ref>, and Untch implemented TUMS [35, 36] to implement the schema-based execution model [36]. The Pisces system [37] also uses mutation to assess testability and to perform weak mutation [23].
Reference: [8] <author> M. E. Delamaro, J. C. Maldonado, M. Jino, and M. Chaim. Proteum: Uma ferramenta de teste baseada na analise de mutantes (Proteum: </author> <title> A testing tool based on mutation analysis). </title> <booktitle> In 7th Brazilian Symposium on Software Engineering, </booktitle> <pages> pages 31-33, </pages> <address> Rio de Janeiro, Brazil, </address> <month> October </month> <year> 1993. </year> <note> In Portuguese. </note>
Reference-contexts: More recent efforts have focused on mutation systems for the C language. Reference [1] describes a set of mutant operators for C, which we henceforth call the Purdue C operators. To date, there are two publicized systems that use these operators. Delamaro et al. developed Proteum <ref> [8, 7] </ref>, and Untch implemented TUMS [35, 36] to implement the schema-based execution model [36]. The Pisces system [37] also uses mutation to assess testability and to perform weak mutation [23].
Reference: [9] <author> R. A. DeMillo, D. S. Guindi, K. N. King, W. M. McCracken, and A. J. Offutt. </author> <title> An extended overview of the Mothra software testing environment. </title> <booktitle> In Proceedings of the Second Workshop on Software Testing, Verification, and Analysis, </booktitle> <pages> pages 142-151, </pages> <address> Banff Alberta, July 1988. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: We then used Combat [20] to dataflow test each C program, and we used Mothra <ref> [9] </ref> to mutation test equivalent Fortran-77 versions of the subject programs. We now describe the steps involved in the case study. Step 1 In the first step of the case study, we prepared the subject programs. <p> Our fault categorization method provides a clear distinction between statement and structural faults, where statement faults are modeled as first-order or multi-order mutations, or are interface faults. Mutation analysis has been applied to several languages, and several tools have been developed to implement mutation analysis systems. The Mothra system <ref> [9, 13] </ref>, was developed for Fortran-77. Mothra uses a set of mutant operators, described by King and Offutt [25], that were based on earlier mutation systems [3, 6]. More recent efforts have focused on mutation systems for the C language.
Reference: [10] <author> R. A. DeMillo, R. J. Lipton, and F. G. Sayward. </author> <title> Hints on test data selection: Help for the practicing programmer. </title> <journal> IEEE Computer, </journal> <volume> 11(4) </volume> <pages> 34-41, </pages> <month> April </month> <year> 1978. </year>
Reference-contexts: Performing studies on fault detection is difficult because of the lack of fault-seeding techniques that automatically and systematically insert faults into a program One fault-seeding method, mutation testing, inserts small syntactic changes or faults into a program <ref> [10] </ref>. However, this approach is expensive and results in a large number of 1 This work was partially supported by grants from Microsoft, Inc., Data General Corp., by NSF under Grants CCR-9109531 and CCR-9357811 to Clemson University and Ohio State University. <p> The marks the statement at which the mutation is applied. Mutation Testing Mutation testing is a fault-based testing technique <ref> [10, 19] </ref> that is based on the assumption that a program is well tested if all simple faults are predicted and removed; complex faults are coupled to simple faults and are thus, detected by tests that detects simple faults [10, 28, 38]. Mutation operators introduce simple faults into the program. <p> Mutation Testing Mutation testing is a fault-based testing technique [10, 19] that is based on the assumption that a program is well tested if all simple faults are predicted and removed; complex faults are coupled to simple faults and are thus, detected by tests that detects simple faults <ref> [10, 28, 38] </ref>. Mutation operators introduce simple faults into the program. Each change or mutation that is performed by a mutation operator produces a mutant program or simply, a mutant. A mutant is killed by a test that forces it to produce output that is different from the original program. <p> It appears from our results that both dataflow and mutation testing are nearly 100% effective in detecting most types of PDG structural faults. For mutation testing, our results indicate that the coupling effect, which was suggested and empirically investigated by mutation testing researchers <ref> [10, 29] </ref>, may hold for structural faults as well. Thus, although mutation operators have 22 been designed to find simple syntactic faults, the coupling effect results in complex faults being linked to simple ones, and hence in their being discovered.
Reference: [11] <author> R. A. DeMillo and A. P. Mathur. </author> <title> A grammar based fault classification scheme and its application to the classification of the errors of tex. </title> <type> Private communication, </type> <institution> Software Engineering Research Center, Purdue University, West Lafayette IN. </institution>
Reference-contexts: We measure the effectiveness of a testing technique in terms of its ability to detect certain types of faults; we also measure the effectiveness of a testing technique relative to the effectiveness of other testing techniques. Although there have been studies of fault categories <ref> [4, 11, 18, 22] </ref>, there is no established correlation between categories of faults and testing techniques that expose those faults.
Reference: [12] <author> R. A. DeMillo and A. P. Mathur. </author> <title> On the use of software artifacts to evaluate the effectiveness of mutation analysis for detecting errors in production software. </title> <type> Technical report SERC-TR-92-P, </type> <institution> Software Engineering Research Center, Purdue University, West Lafayette IN, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: Howden [22] originally classified program faults, and Zeil [40] extended Howden's classification. There have been other fault classifications based on observed instances of faults and on the complexity of faults <ref> [12] </ref>. According to the Howden/Zeil classifications, program faults 2 are categorized as domain faults or computation faults. A domain fault occurs when, due to an error in control flow, a program generates incorrect output. <p> The authors state that the fault categorization for their experimental programs was based on a "consistent interpretation" of the faults and that it is possible for another analyst to categorize the faults in a given program differently. DeMillo and Mathur <ref> [12] </ref> presented a fault categorization scheme based on their investigation of Knuth's Tex error log. According to their categorization, faults are "simple" or "complex". They defined simple faults as those that are modeled by mutation operators.
Reference: [13] <author> R. A. DeMillo and A. J. Offutt. </author> <title> Constraint-based automatic test data generation. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(9) </volume> <pages> 900-910, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Our fault categorization method provides a clear distinction between statement and structural faults, where statement faults are modeled as first-order or multi-order mutations, or are interface faults. Mutation analysis has been applied to several languages, and several tools have been developed to implement mutation analysis systems. The Mothra system <ref> [9, 13] </ref>, was developed for Fortran-77. Mothra uses a set of mutant operators, described by King and Offutt [25], that were based on earlier mutation systems [3, 6]. More recent efforts have focused on mutation systems for the C language.
Reference: [14] <author> S.N. Weiss E.J. Weyuker and Dick Hamlet. </author> <title> Comparison of program testing strategies. </title> <booktitle> In Proceedings of the Fourth Symposium on Software Testing, Analysis, and Verification, </booktitle> <address> Victoria, British Columbia, </address> <month> October </month> <year> 1991. </year> <booktitle> ACM SIGSOFT 91. </booktitle>
Reference-contexts: Detecting program faults, which are sections of code that may result in incorrect output, is an important goal of software testing. A meaningful measure of a testing technique is its fault-detection ability or effectiveness <ref> [14] </ref>. We measure the effectiveness of a testing technique in terms of its ability to detect certain types of faults; we also measure the effectiveness of a testing technique relative to the effectiveness of other testing techniques.
Reference: [15] <author> J. Ferrante, K. J. Ottenstein, and J. D. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: Our program representation is a program dependence graph (PDG) that explicitly represents both data and control dependencies in a program <ref> [15] </ref>. We enhanced the domain/computation fault-classification scheme that was developed by Howden [22] to further characterize faults as structural or statement-level, depending on the differences between the PDG for the original program and the PDG for the faulty program. <p> We shall use the term fault because we are referring to sections of code that may result in failures. 3 The Program Dependence Graph The program dependence graph (PDG) explicitly represents both data dependencies and control dependencies for a program <ref> [15] </ref>. In a PDG, nodes represent statements and predicate expressions, and edges represent either data dependencies or control dependencies. Thus, the PDG actually consists of a data-dependence subgraph (DDS) and a control-dependence subgraph (CDS).
Reference: [16] <author> P. G. Frankl and E. J. Weyuker. </author> <title> An applicable family of data flow testing criteria. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-14(10):1483-1498, </volume> <month> October </month> <year> 1988. </year>
Reference-contexts: A definition-use pair is an association of a definition of a variable and a use of that variable that the definition reaches. Dataflow testing is a family of adequacy criteria <ref> [16] </ref> that includes all-nodes, all-edges, and all-uses. A test set satisfies the all-nodes criterion if every node in the control flow graph 4 is executed by some test in the test set.
Reference: [17] <author> P. G. Frankl and E. J. Weyuker. </author> <title> A formal analysis of the fault-detecting ability of testing methods. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-19(3):202-213, </volume> <month> March </month> <year> 1993. </year>
Reference-contexts: Although there have been studies of fault categories [4, 11, 18, 22], there is no established correlation between categories of faults and testing techniques that expose those faults. Furthermore, although there have been formal and empirical studies <ref> [4, 17, 18, 30] </ref> on the relative effectiveness of testing techniques, there is no conclusive evidence that one testing technique is superior in fault-detection ability.
Reference: [18] <author> M. R. Girgis and M. R. Woodward. </author> <title> An experimental comparison of the error exposing ability of program testing criteria. </title> <booktitle> In Proceedings of the Workshop on Software Testing, </booktitle> <pages> pages 64-73. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> July </month> <year> 1986. </year>
Reference-contexts: We measure the effectiveness of a testing technique in terms of its ability to detect certain types of faults; we also measure the effectiveness of a testing technique relative to the effectiveness of other testing techniques. Although there have been studies of fault categories <ref> [4, 11, 18, 22] </ref>, there is no established correlation between categories of faults and testing techniques that expose those faults. <p> Although there have been studies of fault categories [4, 11, 18, 22], there is no established correlation between categories of faults and testing techniques that expose those faults. Furthermore, although there have been formal and empirical studies <ref> [4, 17, 18, 30] </ref> on the relative effectiveness of testing techniques, there is no conclusive evidence that one testing technique is superior in fault-detection ability.
Reference: [19] <author> R. G. Hamlet. </author> <title> Testing programs with the aid of a compiler. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 3(4) </volume> <pages> 279-290, </pages> <month> July </month> <year> 1977. </year> <month> 26 </month>
Reference-contexts: The marks the statement at which the mutation is applied. Mutation Testing Mutation testing is a fault-based testing technique <ref> [10, 19] </ref> that is based on the assumption that a program is well tested if all simple faults are predicted and removed; complex faults are coupled to simple faults and are thus, detected by tests that detects simple faults [10, 28, 38]. Mutation operators introduce simple faults into the program.
Reference: [20] <author> M. J. Harrold and P. Kolte. </author> <title> Combat: A compiler based data flow testing system. </title> <booktitle> Proceedings of the 10 th Pacific Northwest Software Quality Conference, </booktitle> <pages> pages 311-323, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: We then used Combat <ref> [20] </ref> to dataflow test each C program, and we used Mothra [9] to mutation test equivalent Fortran-77 versions of the subject programs. We now describe the steps involved in the case study. Step 1 In the first step of the case study, we prepared the subject programs.
Reference: [21] <author> M. J. Harrold, L. Larsen, J. Lloyd, D. Nedved, M. Page, G. Rothermel, M. Singh, and M. Smith. Aristotle: </author> <title> A system for development of program analysis based tools. </title> <booktitle> Proceedings of the 33rd Annual ACM Southeast Conference, </booktitle> <pages> pages 110-119, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: We developed our fault seeder in C on Sun SPARC machines 5 , using our analysis system, Aristotle <ref> [21] </ref>, to gather program information and generate the faulty programs. Figure 17 shows a dataflow diagram representing our fault seeder, and illustrates its use of some of Aristotle's components. Aristotle's parser/analyzer, CParse, takes the C program, pgm.c, as the input to be seeded with faults.
Reference: [22] <author> W. E. Howden. </author> <title> Reliability of the path analysis testing strategy. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 2(3) </volume> <pages> 208-215, </pages> <month> September </month> <year> 1976. </year>
Reference-contexts: We measure the effectiveness of a testing technique in terms of its ability to detect certain types of faults; we also measure the effectiveness of a testing technique relative to the effectiveness of other testing techniques. Although there have been studies of fault categories <ref> [4, 11, 18, 22] </ref>, there is no established correlation between categories of faults and testing techniques that expose those faults. <p> Our program representation is a program dependence graph (PDG) that explicitly represents both data and control dependencies in a program [15]. We enhanced the domain/computation fault-classification scheme that was developed by Howden <ref> [22] </ref> to further characterize faults as structural or statement-level, depending on the differences between the PDG for the original program and the PDG for the faulty program. <p> The failure in this case may be a memory violation and core dump. If the incorrectly accessed location array [50] contains a numerical value that is used in some computation, the output will be different from the expected output, and this difference is an error. Howden <ref> [22] </ref> originally classified program faults, and Zeil [40] extended Howden's classification. There have been other fault classifications based on observed instances of faults and on the complexity of faults [12]. According to the Howden/Zeil classifications, program faults 2 are categorized as domain faults or computation faults. <p> Because the method of test generation is not significant here, we use the terms mutation analysis and mutation testing interchangeably. 3 Modeling Faults using the PDG We characterize the types of faults that we model using the PDG as extensions to the domain/computation classification scheme developed by Howden <ref> [22] </ref>. Our goal in extending this scheme is to establish a relationship between existing fault categories and their PDG representations not to provide an exhaustive fault classification. Section 3.1 details our extensions to the domain/computation classification that are based on fault manifestations in the PDG. <p> Despite this variation in dataflow and mutation adequacy scores, and the recognized need for extended experimentation, the results of the conducted experiments clearly show that it is feasible to use the structural fault seeder in conjunction with established testing methods, for many applications. 6 Related Work Howden <ref> [22] </ref> categorized faults as domain and computation faults. In his classification, domain faults were further categorized as missing path or path selection faults, and path selection faults were categorized as predicate faults or assignment faults. Zeil [40] later detailed Howden's categorization.
Reference: [23] <author> W. E. Howden. </author> <title> Weak mutation testing and completeness of test sets. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 8(4) </volume> <pages> 371-379, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: To date, there are two publicized systems that use these operators. Delamaro et al. developed Proteum [8, 7], and Untch implemented TUMS [35, 36] to implement the schema-based execution model [36]. The Pisces system [37] also uses mutation to assess testability and to perform weak mutation <ref> [23] </ref>. The Pisces system is partially based on the Purdue operators, and it is, to date, the only commercial tool that is based on mutation. Offutt et al. [32] defined a set of mutant operators for the Ada language.
Reference: [24] <institution> IEEE Standard Glossary of Software Engineering Terminology, IEEE Std 610.12.1990. Institute of Electrical and Electronics Engineering, </institution> <address> New York, </address> <year> 1990. </year>
Reference-contexts: Finally, the section describes dataflow testing and mutation testing, which are the two types of unit testing that we used for our case study. Faults and Fault Categories According to the IEEE standard definitions <ref> [24] </ref>, a fault or "bug" is an incorrect step, instruction or data definition in a program. A fault may result in a failure, which is observed when the system exhibits incorrect external behavior.
Reference: [25] <author> K. N. King and A. J. Offutt. </author> <title> A Fortran language system for mutation-based software testing. </title> <journal> Software-Practice and Experience, </journal> <volume> 21(7) </volume> <pages> 685-718, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Mutation analysis has been applied to several languages, and several tools have been developed to implement mutation analysis systems. The Mothra system [9, 13], was developed for Fortran-77. Mothra uses a set of mutant operators, described by King and Offutt <ref> [25] </ref>, that were based on earlier mutation systems [3, 6]. More recent efforts have focused on mutation systems for the C language. Reference [1] describes a set of mutant operators for C, which we henceforth call the Purdue C operators.
Reference: [26] <author> W. A. Landi and B.G. Ryder. </author> <title> A safe approximation algorithm for interprocedural pointer aliasing. </title> <booktitle> In Proceedings of SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 235-248, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Dataflow analysis <ref> [2, 26] </ref> is used to gather dataflow information. The DDS represents the data dependencies in the program. In Figure 1, the dashed lines are data dependence edges for variable j. Dataflow Testing Dataflow testing considers the associations between variable definitions and variable uses.
Reference: [27] <author> A. P. Mathur and W. E. Wong. </author> <title> An empirical comparison of data flow and mutation-based test adequacy criteria. The Journal of Software Testing, Verification, </title> <journal> and Reliability, </journal> <volume> 4(1) </volume> <pages> 9-31, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: In the first part of our study, we compared the fault-detection abilities of dataflow testing and mutation testing; in particular, we compared the all-uses dataflow criterion to mutation testing. Several previous studies <ref> [31, 27] </ref> have compared the relative effectiveness of dataflow testing and mutation testing. However, none of these studies used an automatic fault-seeding tool to insert faults into the subject programs.
Reference: [28] <author> A. J. Offutt. </author> <title> Investigations of the software testing coupling effect. </title> <journal> ACM Transactions on Software Engineering Methodology, </journal> <volume> 1(1) </volume> <pages> 3-18, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: Mutation Testing Mutation testing is a fault-based testing technique [10, 19] that is based on the assumption that a program is well tested if all simple faults are predicted and removed; complex faults are coupled to simple faults and are thus, detected by tests that detects simple faults <ref> [10, 28, 38] </ref>. Mutation operators introduce simple faults into the program. Each change or mutation that is performed by a mutation operator produces a mutant program or simply, a mutant. A mutant is killed by a test that forces it to produce output that is different from the original program.
Reference: [29] <author> A. J. Offutt. </author> <title> Investigations of the software testing coupling effect. </title> <journal> ACM Transactions on Software Engineering Methodology, </journal> <volume> 1(1) </volume> <pages> 3-18, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: It appears from our results that both dataflow and mutation testing are nearly 100% effective in detecting most types of PDG structural faults. For mutation testing, our results indicate that the coupling effect, which was suggested and empirically investigated by mutation testing researchers <ref> [10, 29] </ref>, may hold for structural faults as well. Thus, although mutation operators have 22 been designed to find simple syntactic faults, the coupling effect results in complex faults being linked to simple ones, and hence in their being discovered.
Reference: [30] <author> A. J. Offutt and J. H. Hayes. </author> <title> A semantic model of program faults. </title> <booktitle> In Proceedings of the 1996 International Symposium on Software Testing, and Analysis, </booktitle> <pages> pages 195-200, </pages> <address> San Diego, CA, </address> <month> January </month> <year> 1996. </year> <note> ACM Press. </note>
Reference-contexts: Although there have been studies of fault categories [4, 11, 18, 22], there is no established correlation between categories of faults and testing techniques that expose those faults. Furthermore, although there have been formal and empirical studies <ref> [4, 17, 18, 30] </ref> on the relative effectiveness of testing techniques, there is no conclusive evidence that one testing technique is superior in fault-detection ability. <p> For fault-seeding purposes, faults should be "representative" of naturally-occurring faults; otherwise, any results obtained from the seeded faults may to be inaccurate or biased. Unfortunately, to date, there is no accepted model with which to determine whether seeded faults are representative. Offutt and Hayes <ref> [30] </ref> suggest a model for program faults that they use to identify representative collections of faults. <p> Finally, the transposition within region fault is not related to any operator for Fortran-77, C, or Ada. Perhaps the biggest difference between our fault seeder and mutation systems is based on the semantic fault model summarized earlier. Offutt and Hayes <ref> [30] </ref> point out a key difference between fault seeding and mutation analysis. When fault seeding, we want faults that approximate natural faults as closely as possible; by exhibiting a distribution of semantic fault sizes that matches the distribution of natural faults.
Reference: [31] <author> A. J. Offutt, J. Pan, K.Tewary, and T.Zhang. </author> <title> An experimental evaluation of data flow and mutation testing. </title> <journal> Software-Practice and Experience, </journal> <volume> 26(2) </volume> <pages> 165-176, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: We used our fault seeder to seed faults into a set of programs, and tested the programs using both dataflow testing and mutation testing. We also determined mutation adequacy and dataflow adequacy of the fault-detecting test sets; these studies replicate earlier, more extensive studies <ref> [31, 39] </ref>, and our results agree with theirs. The advantage of our extended characterization of the domain/computation scheme is that we classify each fault type on the basis of its manifestation in the PDG. This fault representation is easy to apply to the implementation of a fault-seeding tool. <p> In the first part of our study, we compared the fault-detection abilities of dataflow testing and mutation testing; in particular, we compared the all-uses dataflow criterion to mutation testing. Several previous studies <ref> [31, 27] </ref> have compared the relative effectiveness of dataflow testing and mutation testing. However, none of these studies used an automatic fault-seeding tool to insert faults into the subject programs.
Reference: [32] <author> A. J. Offutt, Jeff Payne, and Jeffrey M. Voas. </author> <title> Mutation operators for Ada. </title> <type> Technical report ISSE-TR-96-06, </type> <institution> Department of Information and Software Systems Engineering, George Mason University, Fairfax VA, </institution> <month> March </month> <year> 1996. </year>
Reference-contexts: The Pisces system [37] also uses mutation to assess testability and to perform weak mutation [23]. The Pisces system is partially based on the Purdue operators, and it is, to date, the only commercial tool that is based on mutation. Offutt et al. <ref> [32] </ref> defined a set of mutant operators for the Ada language.
Reference: [33] <author> I. Sommerville. </author> <title> Software Engineering, third edition. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> New York NY, </address> <year> 1989. </year>
Reference-contexts: 1 Introduction Software testing is an expensive component of the software development cycle <ref> [33] </ref> that exercises a program to demonstrate the presence of errors and to provide confidence in the program's correctness. Detecting program faults, which are sections of code that may result in incorrect output, is an important goal of software testing.
Reference: [34] <author> K. Tewary and M. J. Harrold. </author> <title> Fault modeling using the program dependence graph. </title> <booktitle> IEEE International Symposium on Software Reliability '94 (ISSRE'94), </booktitle> <pages> pages 126-135, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: To facilitate the study of testing techniques, we developed a fault classification and fault-seeding approach that models both simple and complex program faults; we described our preliminary results in Reference <ref> [34] </ref>. Our program representation is a program dependence graph (PDG) that explicitly represents both data and control dependencies in a program [15].
Reference: [35] <author> R. Untch. </author> <title> Schema-based Mutation Analysis: A New Test Data Adequacy Assessment Method. </title> <type> PhD thesis, </type> <institution> Clemson University, Clemson SC, 1995. Clemson Department of Computer Science Technical report 95-115. </institution>
Reference-contexts: Reference [1] describes a set of mutant operators for C, which we henceforth call the Purdue C operators. To date, there are two publicized systems that use these operators. Delamaro et al. developed Proteum [8, 7], and Untch implemented TUMS <ref> [35, 36] </ref> to implement the schema-based execution model [36]. The Pisces system [37] also uses mutation to assess testability and to perform weak mutation [23]. The Pisces system is partially based on the Purdue operators, and it is, to date, the only commercial tool that is based on mutation.
Reference: [36] <author> R. Untch, A. J. Offutt, and M. J. Harrold. </author> <title> Mutation analysis using program schemata. </title> <booktitle> In Proceedings of the 1993 International Symposium on Software Testing, and Analysis, </booktitle> <pages> pages 139-148, </pages> <address> Cambridge MA, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Reference [1] describes a set of mutant operators for C, which we henceforth call the Purdue C operators. To date, there are two publicized systems that use these operators. Delamaro et al. developed Proteum [8, 7], and Untch implemented TUMS <ref> [35, 36] </ref> to implement the schema-based execution model [36]. The Pisces system [37] also uses mutation to assess testability and to perform weak mutation [23]. The Pisces system is partially based on the Purdue operators, and it is, to date, the only commercial tool that is based on mutation. <p> Reference [1] describes a set of mutant operators for C, which we henceforth call the Purdue C operators. To date, there are two publicized systems that use these operators. Delamaro et al. developed Proteum [8, 7], and Untch implemented TUMS [35, 36] to implement the schema-based execution model <ref> [36] </ref>. The Pisces system [37] also uses mutation to assess testability and to perform weak mutation [23]. The Pisces system is partially based on the Purdue operators, and it is, to date, the only commercial tool that is based on mutation.
Reference: [37] <author> J. M. Voas, L. Morell, and K. W. Miller. </author> <title> Predicting where faults can hide from testing. </title> <journal> IEEE Software, </journal> <volume> 8(2), </volume> <month> March </month> <year> 1991. </year>
Reference-contexts: To date, there are two publicized systems that use these operators. Delamaro et al. developed Proteum [8, 7], and Untch implemented TUMS [35, 36] to implement the schema-based execution model [36]. The Pisces system <ref> [37] </ref> also uses mutation to assess testability and to perform weak mutation [23]. The Pisces system is partially based on the Purdue operators, and it is, to date, the only commercial tool that is based on mutation.
Reference: [38] <author> K. S. </author> <title> How Tai Wah. Fault coupling in finite bijective functions. The Journal of Software Testing, Verification, </title> <journal> and Reliability, </journal> <volume> 5(1) </volume> <pages> 3-47, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: Mutation Testing Mutation testing is a fault-based testing technique [10, 19] that is based on the assumption that a program is well tested if all simple faults are predicted and removed; complex faults are coupled to simple faults and are thus, detected by tests that detects simple faults <ref> [10, 28, 38] </ref>. Mutation operators introduce simple faults into the program. Each change or mutation that is performed by a mutation operator produces a mutant program or simply, a mutant. A mutant is killed by a test that forces it to produce output that is different from the original program.
Reference: [39] <author> W. E. Wong and A. P. Mathur. </author> <title> Fault detection effectiveness of mutation and data flow testing. </title> <journal> Software Quality Journal, </journal> <volume> 4(1) </volume> <pages> 69-83, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: We used our fault seeder to seed faults into a set of programs, and tested the programs using both dataflow testing and mutation testing. We also determined mutation adequacy and dataflow adequacy of the fault-detecting test sets; these studies replicate earlier, more extensive studies <ref> [31, 39] </ref>, and our results agree with theirs. The advantage of our extended characterization of the domain/computation scheme is that we classify each fault type on the basis of its manifestation in the PDG. This fault representation is easy to apply to the implementation of a fault-seeding tool.
Reference: [40] <author> S. J. Zeil. </author> <title> Perturbation techniques for detecting domain errors. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 15 </volume> <pages> 737-746, </pages> <month> June </month> <year> 1989. </year> <month> 27 </month>
Reference-contexts: If the incorrectly accessed location array [50] contains a numerical value that is used in some computation, the output will be different from the expected output, and this difference is an error. Howden [22] originally classified program faults, and Zeil <ref> [40] </ref> extended Howden's classification. There have been other fault classifications based on observed instances of faults and on the complexity of faults [12]. According to the Howden/Zeil classifications, program faults 2 are categorized as domain faults or computation faults. <p> In his classification, domain faults were further categorized as missing path or path selection faults, and path selection faults were categorized as predicate faults or assignment faults. Zeil <ref> [40] </ref> later detailed Howden's categorization. We have extended the domain/computation fault categorization so that it can be easily translated to a well-defined program representation and hence, automated. Basili and Selby [4] classified faults according to two schemes.
References-found: 40

