URL: http://http.icsi.berkeley.edu/ftp/global/pub/ai/jurafsky/acl95-ecp.ps.Z
Refering-URL: http://http.icsi.berkeley.edu/ftp/global/pub/ai/jurafsky/
Root-URL: http://http.icsi.berkeley.edu
Email: ftajchman,jurafsky,foslerg@icsi.berkeley.edu  
Title: Learning Phonological Rule Probabilities from Speech Corpora with Exploratory Computational Phonology  
Author: Gary Tajchman Daniel Jurafsky, and Eric Fosler 
Address: Berkeley  
Affiliation: International Computer Science Institute and University of California at  
Note: To appear in ACL-95  
Abstract: This paper presents an algorithm for learning the probabilities of optional phonological rules from corpora. The algorithm is based on using a speech recognition system to discover the surface pronunciations of words in speech corpora; using an automatic system obviates expensive phonetic labeling by hand. We describe the details of our algorithm and show the probabilities the system has learned for ten common phonological rules which model reductions and coarticulation effects. These probabilities were derived from a corpus of 7203 sentences of read speech from the Wall Street Journal, and are shown to be a reasonably close match to probabilities from phonetically hand-transcribed data (TIMIT). Finally, we analyze the probability differences between rule use in male versus female speech, and suggest that the differences are caused by differing average rates of speech. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bourlard, H., & N. Morgan. </author> <year> 1991. </year> <title> Merging multilayer perceptrons & Hidden Markov Models: 7 Some experiments in continuous speech recog-nition. </title> <booktitle> In Artificial Neural Networks: Advances and Applications, </booktitle> <editor> ed. by E. Gelenbe. </editor> <publisher> North Hol-land Press. </publisher>
Reference: <author> Chen, F. </author> <year> 1990. </year> <title> Identification of contextual factors for pronounciation networks. </title> <booktitle> In IEEE ICASSP-90 , 753-756. </booktitle> <address> CMU, </address> <year> 1993. </year> <institution> The Carnegie Mellon Pronouncing Dictionary v0.1. Carnegie Mellon University. </institution>
Reference: <author> Cohen, M. H., </author> <year> 1989. </year> <title> Phonological Structures for Speech Recognition. </title> <institution> University of California, Berkeley dissertation. </institution>
Reference: <author> Cole, R. A., K. Roginski, & M. Fanty., </author> <year> 1994. </year> <title> The OGI Numbers Database. </title> <institution> Oregon Graduate Institute. COMLEX, </institution> <year> 1994. </year> <title> The COMLEX English Pronouncing Dictionary. </title> <institution> copyright Trustees of the University of Pennsylvania. </institution>
Reference-contexts: These were 13,362 hand-transcribed pronunciations of 5871 words from TIMIT (TIMIT 1990), and 230 pronunciations of 36 words derived in-house from the OGI Numbers database <ref> (Cole et al. 1994) </ref>. erate phone sequences from word orthography as an additional source of pronunciations.
Reference: <author> Daelemans, Walter, Steven Gillis, & Gert Durieux. </author> <year> 1994. </year> <title> The acquisition of stress: A data-oriented approach. </title> <note> Computational Linguistics 208.421-451. </note>
Reference: <author> Ellison, T. Mark, </author> <year> 1992. </year> <title> The Machine Learning of Phonological Structure. </title> <institution> University of Western Australia dissertation. </institution>
Reference: <author> Gasser, Michael, </author> <year> 1993. </year> <title> Learning words in time: Towards a modular connectionist account of the acquisition of receptive morphology. </title> <type> Draft. </type>
Reference: <author> Hermansky, H. </author> <year> 1990. </year> <title> Perceptual linear predictive (plp) analysis of speech. </title> <journal> J. Acoustical Society of America 87. </journal>
Reference-contexts: The estimator consists of a simple three-layer feed forward MLP trained with the back-propagation algorithm (see of speech, is typically encoded by 9 PLP <ref> (Hermansky 1990) </ref> coefficients, 9 delta-PLP coefficients, 9 delta-delta PLP coefficients, delta-energy and delta-delta-energy terms. Typically, we use 500-4000 hidden units. The output layer has one unit for each phone.
Reference: <author> Lamel, Lori, </author> <year> 1993. </year> <title> The Limsi Dictionary. NIST, 1993. Continuous Speech Recognition Corpus (WSJ 0). </title> <journal> National Institute of Standards and Technology Speech Disc 11-1.1 to 11-3.1. </journal>
Reference-contexts: Source Words Base Prons All Prons CMU 95,781 99,279 399,265 LIMSI 32,873 37,936 49,597 PRONLEX 30,353 30,354 81,936 BRITPRON 77,685 85,450 108,834 TTS 77,383 83,297 111,028 Table 1: Pronunciation sources used to build fully expanded lexicon. For further information about these sources please refer to CMU (CMU 1993), LIMSI <ref> (Lamel 1993) </ref>, PRONLEX (COMLEX 1994), BRITPRON (Robin-son 1994). A text-to-speech system was used to gen 2 Although it was not relevant to the experiments described here, our lexicon also included two sources which directly supply surface forms.
Reference: <author> Renals, S., N. Morgan, H. Bourlard, M. Co-hen, H. Franco, C. Wooters, & P. Kohn. </author> <year> 1991. </year> <title> Connectionist speech recognition: Status and prospects. </title> <type> Technical Report TR-91-070, ICSI, </type> <institution> Berkeley, </institution> <address> CA. </address>
Reference: <author> Riley, Michael D. </author> <year> 1991. </year> <title> A statistical model for generating pronunciation networks. </title> <note> In IEEE ICASSP-91 , 737-740. </note>
Reference: <author> Robinson, Anthony, </author> <year> 1994. </year> <title> The British English Example Pronunciation Dictionary, </title> <publisher> v0.1. Cam-bridge University. </publisher>
Reference: <author> Tajchman, Gary, Eric Fosler, & Daniel Ju-rafsky. </author> <year> 1995. </year> <title> Building multiple pronunciation models for novel words using exploratory computational phonology. </title> <note> To appear in Eurospeech-95 . TIMIT, </note> <year> 1990. </year> <title> TIMIT Acoustic-Phonetic Continuous Speech Corpus. </title> <journal> National Institute of Standards and Technology Speech Disc 1-1.1. </journal> <note> NTIS Order No. </note> <author> PB91-505065. Wesenick, Maria-Barbara, & Florian Schiel. </author> <year> 1994. </year> <title> Applying speech verification to a large data base of German to obtain a statistical survey about rules of pronunciation. </title> <note> In ICSLP-94 , 279-282. </note>
Reference: <author> Wooters, Charles C., </author> <year> 1993. </year> <title> Lexical Modeling in a Speaker Independent Speech Understanding System. </title> <institution> Berkeley: University of California dissertation. </institution> <note> Available as ICSI TR-92-062. </note>
Reference-contexts: that females had an average of 71 ms/phone, while males had an average of 68 ms/phone, a difference of about 4%, quite correlated with the similar differences in reduction and flapping. 4 Related Work Our algorithm for phonological rule probability estimation synthesizes and extends earlier work by (Co-hen 1989) and <ref> (Wooters 1993) </ref>. The idea of using optional phonological rules to construct a speech-recognition lexicon derives from Cohen (1989), who applied optional phonological rules to a baseform dictionary to produce a surface lexicon and then used TIMIT to assign probabilities for each pronunciation.
Reference: <author> Wooters, Chuck, & Andreas Stolcke. </author> <year> 1994. </year> <title> Multiple-pronunciation lexical modeling in a speaker-independent speech understanding system. </title> <booktitle> In ICSLP-94 . 8 </booktitle>
Reference-contexts: We plan in future work to address a number of shortcomings of these experiments, for example including some spontaneous speech corpora, and looking at a wider variety of rules. In addition, we have extended our algorithm to induce new pronunciations which generalize over pronunciations seen in the corpus <ref> (Wooters & Stolcke 1994) </ref>. We now plan to augment our probability estimation to use the pronunciations from this new HMM-induction-based generalization step. This will require extending our tag-based probability estimation step to parse the phone strings from the forced-Viterbi.
References-found: 15

