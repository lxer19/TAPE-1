URL: http://www.di.unito.it/~neri/papers/mulstr.ps.gz
Refering-URL: http://www.di.unito.it/~neri/papers/neribib.html
Root-URL: 
Email: attilio@di.unito.it  neri@di.unito.it  saitta@di.unito.it  botta@di.unito.it  
Title: Machine Learning Journal, 1-35 Integrating Multiple Learning Strategies in First Order Logics  
Author: A. GIORDANA F. NERI L. SAITTA M. BOTTA 
Keyword: Learning Relations, Multistrategy Learning, Learning from Databases  
Address: Torino, C.so Svizzera 185, 10149 Torino, Italy  Torino, C.so Svizzera 185, 10149 Torino, Italy  Torino, C.so Svizzera 185, 10149 Torino, Italy  Torino, C.so Svizzera 185, 10149 Torino, Italy  
Affiliation: Dipartimento di Informatica, Universita di  Dipartimento di Informatica, Universita di  Dipartimento di Informatica, Universita di  Dipartimento di Informatica, Universita di  
Abstract: This paper describes a representation framework, that offers a unifying platform for alternative systems, which learn concepts in First Order Logic. The main aspects of this framework are discussed. First of all, the separation between the hypothesis logical language (a version of the V L 21 language) and the representation of data by means of a relational database is motivated. Then, the functional layer between data and hypotheses, which makes the data accessible by the logical level through a set of abstract properties. A novelty, in the hypothesis representation language, is the introduction of the construct of internal disjunction; such a construct, first used by the AQ and Induce systems, is here made operational via a set of algorithms, capable to learn it, for both the discrete and the continuous-valued attributes case. These algorithms are embedded in learning systems (SMART+, REGAL, SNAP, WHY, RTL) using different paradigms (symbolic, genetic or connectionist), thus realizing an effective integration among them; in fact, categorical and numerical attributes can be handled in a uniform way. In order to exemplify the effectiveness of the representation framework and of the multistrategy integration, the results obtained by the systems in some application domains are summarized. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ade, H., Raedt, L. D., and Bruynooghe, M. </author> <year> (1995). </year> <title> Declarative bias for specific-to-general ILP systems. </title> <journal> Machine Learning, </journal> <volume> 20 </volume> <pages> 119-154. </pages>
Reference-contexts: INTEGRATING MULTIPLE STRATEGIES IN FOL 3 ILP stems from two sources: its goal recalls Shapiro's work, aimed at synthesizing logic programs (Shapiro, 1983), whereas its theoretical background focuses on logical theories of induction. Actually, as acknowledged in <ref> (Ade et al., 1995) </ref>, most ILP systems have dealt with concept learning from examples, so that the differences between ILP and previous research in learning in FOL loose sharpness. <p> There are basically two ways to deal with this problem: the first is to reduce the search by adding various kinds of bias in the learning process (Gordon and desJardins, 1995), both declarative (syntactic and semantic <ref> (Ade et al., 1995) </ref>) and procedural ones. The second one is to increase the search power of the learning algorithm (Muggleton, 1995). <p> semantic <ref> (Ade et al., 1995) </ref>) and procedural ones. The second one is to increase the search power of the learning algorithm (Muggleton, 1995). Constraining the search by adding a strong declarative bias, aimed at reducing the expressive power of the hypothesis language, is the solution most frequently adopted in ILP (Ade et al., 1995). Systems like SMART+, instead, have a much weaker declarative bias, but they widely exploits procedural biases in the form of search heuristics (Botta and Giordana, 1993). <p> A scenario can be considered as a kind of semantic declarative bias <ref> (Ade et al., 1995) </ref>. Let us now consider the concrete representation of a scenario. Let us keep in mind that a scenario is a set of atomic objects possibly belonging to different concept instances. Figure 1 contains 6 scenarios. <p> Finally, new predicates and terms can be built up through an abstraction mechanisms in SMART+ (Giordana and Saitta, 1990; Giordana et al., 1991). Most FOL concept learners use a form or other of logical language for representing hypotheses. In <ref> (Ade et al., 1995) </ref> a description of the language used to describe biases in general, and in ILP systems in particular, is described. Language biases of ILP systems are rather variables, including normality, ij-determinacy, range-restriction, limitation on the number of variables, and so on.
Reference: <author> Apt, K., Blair, H., and Walker, A. </author> <year> (1988). </year> <title> Towards a theory of declarative knowledge. </title> <editor> In Minker, J., editor, </editor> <booktitle> Foundations of Deductive Databases and Logic Programming, </booktitle> <pages> pages 89-148. </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address>
Reference-contexts: A well-formed HDL formula is any range-restricted, non recursive, normal clause. Starting from this core, both stronger and weaker biases can be used, depending on the specific learning task. For instance, in the system RTL (Giordana et al., 1993a; Baroglio and Botta, 1995) stratified recursive theories <ref> (Apt et al., 1988) </ref> can be learned, and in SMART+ existential and numerical quantification (Michal-ski, 1983) is allowed. On the other hand, a form of determinacy (extensionally controlled) can be imposed for limiting the growth of too large relations.
Reference: <author> Bala, J., Jong, K. D., and Pachowicz, P. </author> <year> (1991). </year> <title> Learning noise tolerant classification procedures by integrating inductive learning and genetic algorithms. </title> <booktitle> In First International Workshop on Multistrategy Learning, </booktitle> <pages> pages 316-323, </pages> <address> Harpers Ferry, WV. </address>
Reference: <author> Baroglio, C. and Botta, M. </author> <year> (1995). </year> <title> Multiple predicate learning with RTL. </title> <booktitle> In 4th Congress of the Italian Association for Artificial Intelligence AI*IA'95, </booktitle> <pages> pages 44-55, </pages> <address> Florence, Italy. </address>
Reference: <author> Baroglio, C., Botta, M., and Saitta, L. </author> <year> (1994). </year> <title> Why: A system that learns using causal models and examples. </title> <editor> In Michalski, R. and Tecuci, G., editors, </editor> <title> Machine Learning: A Multistrategy Approach, </title> <booktitle> volume IV, </booktitle> <pages> pages 319-347. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA. </address>
Reference: <author> Baroglio, C., Giordana, A., Kaiser, M., Nuttin, M., and Piola, R. </author> <year> (1996). </year> <title> Learning controllers for industrial robots. </title> <journal> Machine Learning, </journal> <volume> 23 </volume> <pages> 221-250. </pages>
Reference-contexts: This approach has been adopted in (Sammut et al., 1992) to learn a flight controller for a simulator. More recently, a similar method has been proposed in <ref> (Baroglio et al., 1996) </ref> to synthesize fuzzy controllers. Here we adopted the same approach in combination with the methodology described in Section 3.4 for tuning numeric intervals. The Mackey-Glass domain has been divided into 12 equal intervals. <p> Table 2 shows the results of two experiments, in terms of the Non-Dimensional Error Index (ratio between the average square root error and the standard deviation). The first two lines reports the result obtained with CART, reported in <ref> (Baroglio et al., 1996) </ref>, and the result obtained by (Moody and Darken, 1988) using a RBFN constructed with an enhaced version of the k-means.
Reference: <author> Back, T. </author> <year> (1995). </year> <title> Generalized convergence models for tournament- and (; ) -selection. </title> <booktitle> In 6th International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-8, </pages> <address> Pittsburg, PA. </address>
Reference-contexts: In this way, special crossover and mutation operators, capable of combining real numbers, must be used. For instance, in the (; )-model <ref> (Back, 1995) </ref>, the crossover works as in the following: 1. Randomly select a pair of chromosomes. 2. Randomly select a gene position, say n. 3. A new chromosome is created by taking the genes in position different from n in part from one parent and in part from the other.
Reference: <author> Berenji, H. </author> <year> (1992). </year> <title> An architecture for designing fuzzy controllers with neural networks. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> 6(2) </volume> <pages> 267-292. </pages>
Reference: <author> Bergadano, F. and Giordana, A. </author> <year> (1988). </year> <title> A knowledge intensive approach to concept induction. </title> <booktitle> In Proceedings of the 5th International Conference on Machine Learning, </booktitle> <pages> pages 305-317, </pages> <address> Ann Arbor, MI. </address> <publisher> Morgan Kauffman. </publisher>
Reference-contexts: An important aspect of ML-SMART was its interface to a database, from which the examples were extracted, and in which both the generated hypotheses and their extensions were stored <ref> (Bergadano et al., 1988) </ref>. This feature proved to be essential in learning an industrial troubleshooter (Giordana et al., 1993b) used in field. <p> Originally, learning relations, as exemplified by the system FOIL (Quinlan, 1990), was an extension to FOL of the top-down construction of a decision tree, similar to the method presented in <ref> (Bergadano and Giordana, 1988) </ref>. <p> On the other hand, complex mechanisms to handle possibly large bodies of domain theories have been implemented and used, inte INTEGRATING MULTIPLE STRATEGIES IN FOL 29 grating induction and deduction, both in <ref> (Bergadano and Giordana, 1988) </ref> and in SMART+. Moreover, in the system WHY, also a causal model of the domain can be used in an abuctive way (Baroglio et al., 1994; Saitta et al., 1993).
Reference: <author> Bergadano, F., Giordana, A., and Saitta, L. </author> <year> (1988). </year> <title> Learning concepts in noisy environment. </title> <journal> IEEE Transaction on Pattern Analysis and Machine Intelligence, PAMI-10:555-578. </journal>
Reference-contexts: An important aspect of ML-SMART was its interface to a database, from which the examples were extracted, and in which both the generated hypotheses and their extensions were stored <ref> (Bergadano et al., 1988) </ref>. This feature proved to be essential in learning an industrial troubleshooter (Giordana et al., 1993b) used in field. <p> Originally, learning relations, as exemplified by the system FOIL (Quinlan, 1990), was an extension to FOL of the top-down construction of a decision tree, similar to the method presented in <ref> (Bergadano and Giordana, 1988) </ref>. <p> On the other hand, complex mechanisms to handle possibly large bodies of domain theories have been implemented and used, inte INTEGRATING MULTIPLE STRATEGIES IN FOL 29 grating induction and deduction, both in <ref> (Bergadano and Giordana, 1988) </ref> and in SMART+. Moreover, in the system WHY, also a causal model of the domain can be used in an abuctive way (Baroglio et al., 1994; Saitta et al., 1993).
Reference: <author> Bergadano, F., Giordana, A., and Saitta, L. </author> <year> (1991). </year> <title> Machine Learning: An Integrated Framework and its Applications. </title> <publisher> Hellis Horwood, </publisher> <address> Chichester, UK. </address>
Reference-contexts: For every 2 that is consistent, declare covered the instances verifying , update the frontier and restart. The process stops when either all positive instances are covered or no more promising formulas are in the frontier. Detailed examples of hypothesis tree generations can be found in <ref> (Bergadano et al., 1991) </ref>. As it appears from the algorithm, many heuristics and biases are involved, which have been widely investigated in other papers. In principle, any heuristics suggested in the literature can be used within this framework without any special restriction.
Reference: <author> Blanzieri, E. and Katenkamp, P. </author> <year> (1996). </year> <title> Learning radial basis function networks on-line. </title> <booktitle> In 13th International Conference on Machine Learning, </booktitle> <pages> pages 37-45, </pages> <address> Bari, Italy. </address>
Reference-contexts: Then, interpreting the logical (inclusive) disjunction as an arithmetic sum <ref> (Blanzieri and Katenkamp, 1996) </ref>, a continuous valued semantics for a classification theory composed of rules like (14) can be defined through a network of radial basis functions (RBFN) of the type: f (~x) = j X w j i=1 20 GIORDANA, NERI, SAITTA, BOTTA where the weights w j play the
Reference: <author> Blockeel, H. and De Raedt, L. </author> <year> (1996). </year> <title> Relational knowledge discovery in databases. </title> <booktitle> In Proc. of the MLnet Familiarization Workshop, </booktitle> <pages> pages 111-124, </pages> <address> Bari, Italy. </address>
Reference: <author> Botta, M. </author> <year> (1994). </year> <title> Learning first order theories. </title> <booktitle> In 8th International Symposium on Methodologies for Intelligent Systems, volume LNAI-869, </booktitle> <pages> pages 356-365, </pages> <address> Charlotte, NC. </address>
Reference-contexts: Using a learning set of 1000 examples it learned the concept of safe black king with an accuracy of 99.75%, evaluated on a test set of 2000 instances. The King-Rook-King end-game problem has been discussed in <ref> (Botta, 1994) </ref>. Using 160 learning examples (scenarios) and 1000 test examples, a simplified version of SMART+ was able to reach 99.4% accuracy without any a-priori knowledge. As INTEGRATING MULTIPLE STRATEGIES IN FOL 27 a comparison, FOIL required 1000 examples to reach the same accuracy.
Reference: <author> Botta, M. and Giordana, A. </author> <year> (1993). </year> <title> SMART+: A multi-strategy learning tool. </title> <booktitle> In IJCAI-93, Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 937-943, </pages> <address> Chambery, France. </address>
Reference-contexts: This feature proved to be essential in learning an industrial troubleshooter (Giordana et al., 1993b) used in field. ML-SMART evolved later into two new systems, both including inductive and deductive components: SMART+ <ref> (Botta and Giordana, 1993) </ref>, which emphasizes handling noise and continuous attributes by exploiting powerful heuristics for controlling the search in the hypothesis space, and WHY (Baroglio et al., 1994; Saitta et al., 1993), which stresses the importance of exploiting background knowledge, in the form of a causal model of the application <p> Systems like SMART+, instead, have a much weaker declarative bias, but they widely exploits procedural biases in the form of search heuristics <ref> (Botta and Giordana, 1993) </ref>. Increasing the search power has been tried for the first time (in FOL) in the system REGAL, which learns relations via a genetic algorithm (Giordana and Sale, 1992; Giordana and Saitta, 1994; Giordana and Neri, 1996). <p> Moreover, the HDL we used allows predicates to contain one internal disjunction. Even though a more complex version of this language, including numerical quantifiers and unrestricted negation has been used in SMART+ <ref> (Botta and Giordana, 1993) </ref> and Enigma (Giordana et al., 1993b), we will consider here this simpler form that allows a direct comparison with the languages used in other systems such as FOIL, FOCL and most ILP programs. <p> The considered approaches are the symbolic one, exploited in the systems SMART+, SNAP, WHY and RTL, the genetic one, in REGAL (Giordana and Saitta, 1994) and SMART+ <ref> (Botta and Giordana, 1993) </ref>, and the connectionist one, in SNAP (Botta and Giordana, 1996). The multistrategy cooperation framework is hierarchically structured. At the higher level, we pose a symbolic relational learner like SMART+, which is responsible for constructing a first order classification theory. <p> In both cases, the problem is to evaluate a formula = '^P (::; V ), obtained by AND-ing ' with a literal containing an internal disjunction V . The evaluation ( ) is the weighted sum of two terms <ref> (Botta and Giordana, 1993) </ref>: where 1 ('; ) is the information gain (Quinlan, 1990) of with respect to ', and 2 ( ) an evaluation of the absolute completeness and consistency of formula . <p> Return &lt; V; ( ) &gt;. Even though Algorithm 1 is not optimal, it is relatively fast, because it is linear with the number of v i 's, and in practice it gives good results. In order to deal with continuous intervals a different algorithm has been designed <ref> (Botta and Giordana, 1993) </ref>: Algorithm 2 Let V =&lt; v m ; v M &gt; be the template of the interval to be determined; let moreover k be an assigned integer, and = (v M v m )=k. 1. <p> This kind of transformation is described in (Goldberg, 1989) and has been used in a version of SMART+ <ref> (Botta and Giordana, 1993) </ref>. A different approach can be taken, following the tendency of the Evolutionary Computation approach, using 18 GIORDANA, NERI, SAITTA, BOTTA a chromosome composed of "real" genes (see Figure 5 (b)). In this way, special crossover and mutation operators, capable of combining real numbers, must be used. <p> obtained with three systems, each one exploiting one or more of the algorithms described in Section 3: * REGAL (Giordana and Sale, 1992; Giordana and Saitta, 1993; Giordana and Neri, 1996), which is based on a genetic algorithm and makes use of predicates containing only discrete internal disjunctions. * SMART+ <ref> (Botta and Giordana, 1993) </ref>, a multistrategy system per se, which combines symbolic learning strategies (both inductive and deductive) with the algorithms for learning internal disjunctions also in continuous domains. <p> More specifically, it shows how the different algorithms described in Sections 3.2 and 3.3 cooperate, producing a very accurate knowledge base. This domain, even though artificial, is quite complex and bears many features of a real world one. It has been described in <ref> (Botta and Giordana, 1993) </ref>, in order to illustrate the learning strategies of SMART+. Ten capital letters of the English alphabet have been chosen, and have been described as they could appear after segmenting the patterns produced by an electric pen. <p> Search Methods In the basic framework, several search methods and strategies can be applied. In particular, inductive hill-climbing, best-first, depth-first and beam search, controlled by a variety of heuristic evaluations <ref> (Botta and Giordana, 1993) </ref>, can be used in SMART+. Genetic search in used in REGAL, and backpropagation or -rule are used in SNAP (Botta and Giordana, 1996). All the above search strategies have been used in one or anther learning system.
Reference: <author> Botta, M. and Giordana, A. </author> <year> (1996). </year> <title> Combining symbolic and numeric methods for learning to predict temporal series. </title> <booktitle> In 3nd Multistrategy Learning Workshop, </booktitle> <pages> pages 234-249, </pages> <address> Harpers Ferry, WV. </address>
Reference-contexts: The considered approaches are the symbolic one, exploited in the systems SMART+, SNAP, WHY and RTL, the genetic one, in REGAL (Giordana and Saitta, 1994) and SMART+ (Botta and Giordana, 1993), and the connectionist one, in SNAP <ref> (Botta and Giordana, 1996) </ref>. The multistrategy cooperation framework is hierarchically structured. At the higher level, we pose a symbolic relational learner like SMART+, which is responsible for constructing a first order classification theory. <p> Moreover, SMART+ is provided with a postprocessor, based on a genetic algorithm, which accomplishes the refinement of the continuous intervals previously learned. * SNAP <ref> (Botta and Giordana, 1996) </ref>, a variant of SMART+, which has been designed for learning to predict temporal series, and combines the symbolic learning paradigm with the connectionist one, according to the method described in Section 3.4. 4.1. <p> In particular, inductive hill-climbing, best-first, depth-first and beam search, controlled by a variety of heuristic evaluations (Botta and Giordana, 1993), can be used in SMART+. Genetic search in used in REGAL, and backpropagation or -rule are used in SNAP <ref> (Botta and Giordana, 1996) </ref>. All the above search strategies have been used in one or anther learning system. Most ILP systems use hill-climbing, but also beam search (Pompe and Kononenko, 1995) and bi-directional search (Muggleton, 1995) have been used.
Reference: <author> Botta, M., Saitta, L., Brancadori, F., De Marchi, D., and Radicchi, S. </author> <year> (1992). </year> <title> Automatic construction of second generation diagnostic expert systems. </title> <journal> International Journal of Expert Systems, </journal> <volume> 4 </volume> <month> 389-400. </month> <title> INTEGRATING MULTIPLE STRATEGIES IN FOL 33 Bratko, </title> <editor> I. and Dzeroski, S. </editor> <year> (1995). </year> <title> Engineering applications of ILP. </title> <journal> New Generation Computing, </journal> 13:313-333. 
Reference: <author> Brockhausen, P. and Morik, K. </author> <year> (1996). </year> <title> Direct access of an ILP algorithm to a database management system. </title> <booktitle> In Proc. of the MLnet Familiarization Workshop, </booktitle> <pages> pages 95-110, </pages> <address> Bari, Italy. </address>
Reference: <author> Buntine, W. </author> <year> (1988). </year> <title> Generalized subsumption and its application to induction and redundancy. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 149-176. </pages>
Reference: <author> Cameron-Jones, R. and Quinlan, R. </author> <year> (1993). </year> <title> Avoiding pitfalls when learning recursive theories. </title> <booktitle> In IJCAI-93, Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1050-1055, </pages> <address> Chambery, France. </address>
Reference: <author> Clark, K. </author> <year> (1978). </year> <title> Negation as failure. </title> <editor> In Gallaire, H. and Minker, J., editors, </editor> <booktitle> Logic and Data Bases, </booktitle> <pages> pages 293-322. </pages> <publisher> Plenum Press, </publisher> <address> New York, NY. </address>
Reference-contexts: If we consider concept Black (x), the corresponding relation (also reported in Figure 2) contains all the black blocks occurring in the various scenarios. Negative examples are implicitly defined using the Closed World Assumption <ref> (Clark, 1978) </ref>: every tuple not occurring in a relation describing a target concept is a negative example, of it. Then, in our framework, we adopt the same non-monotonic semantics of De Raedt and Dzeroski (De Raedt and Dzeroski, 1994). <p> In the non-monotonic semantic setting (De Raedt and Dzeroski, 1994), instead, the Closed World Assumption <ref> (Clark, 1978) </ref> is done, and, hence, what is not declared true, is false. As a consequence, in the non-monotonic setting the space of acceptable hypotheses is more constrained.
Reference: <author> De Jong, K. A., Spears, W. M., and Gordon, F. D. </author> <year> (1993). </year> <title> Using genetic algorithms for concept learning. </title> <journal> Machine Learning, </journal> <volume> 13 </volume> <pages> 161-188. </pages>
Reference: <author> De Raedt, L. and Dzeroski, S. </author> <year> (1994). </year> <title> First-order jk-clausal theories are PAC -learnable. </title> <journal> Artificial Intelligence, </journal> <volume> 70 </volume> <pages> 375-392. </pages>
Reference-contexts: Negative examples are implicitly defined using the Closed World Assumption (Clark, 1978): every tuple not occurring in a relation describing a target concept is a negative example, of it. Then, in our framework, we adopt the same non-monotonic semantics of De Raedt and Dzeroski <ref> (De Raedt and Dzeroski, 1994) </ref>. The same scheme easily handles the problem of representing multiple target concepts. In this case it is sufficient to define a relation for each one of them. Finally, heterogeneous objects, with different types, can be stored in different Objects relations. <p> In the HDL, the range-restriction bias is assumed <ref> (De Raedt and Dzeroski, 1994) </ref>, i.e. the variables occurring in the head of a clause must also occur in the body. <p> A comment is in order about the semantic setting. In the normal ILP setting, hypotheses are only required to be consistent with the negative instances, so that what is not explicitely stated as true is unknown, and hypotheses covering unknown facts can be accepted. In the non-monotonic semantic setting <ref> (De Raedt and Dzeroski, 1994) </ref>, instead, the Closed World Assumption (Clark, 1978) is done, and, hence, what is not declared true, is false. As a consequence, in the non-monotonic setting the space of acceptable hypotheses is more constrained. <p> As a consequence, in the non-monotonic setting the space of acceptable hypotheses is more constrained. In our framework we also accept the same assumption and, then, we work in the same setting as <ref> (De Raedt and Dzeroski, 1994) </ref>. Also, in their approach, each example is a separate mini-database (a finite interpretation of a clausal theory), similar to our scenario. Hypothesis Description Language (HDL) A set of operational predicates (Mitchell et al., 1986) are supplied.
Reference: <author> DeJong, G. and Mooney, R. </author> <year> (1986). </year> <title> Explanation based learning: an alternative view. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 145-176. </pages>
Reference: <author> Dietterich, T. and Michalski, R. </author> <year> (1983). </year> <title> A comparative review of selected methods for learning from examples. </title> <editor> In Carbonell, J., Michalski, R., and Mitchell, T., editors, </editor> <booktitle> Machine Learning, an Artificial Intelligence Approach. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Faure, C., Frediani, S., and Saitta, L. </author> <year> (1993). </year> <title> A semiautomated methodology for knowledge elicitation. </title> <journal> IEEE Transaction on Systems, Man, and Cybernetics, SMC-23:346-356. </journal>
Reference: <author> Flach, P. </author> <year> (1995). </year> <title> Conjectures: An Inquiry Concerning the Logic of Induction. </title> <type> PhD thesis, </type> <institution> Tilburg University (Netherlands), CIP-Gegevens KoninKlijke Bibliotheek, Den Haag. </institution>
Reference: <author> Gardin, G. and Simon, E. </author> <year> (1987). </year> <title> Les systemes de gestion de bases des donnees deductives. </title> <journal> Synthese, </journal> <volume> 6. </volume>
Reference: <author> Gemello, R., Mana, F., and Saitta, L. </author> <year> (1991). </year> <title> Rigel: An inductive learning system. </title> <journal> Machine Learning, </journal> <volume> 6 </volume> <pages> 7-36. </pages>
Reference-contexts: More recently, a number of new learning applications in FOL have been reported (see, among others, (Bratko and Dzeroski, 1995)). The development of other systems (see, for instance, MOBAL (Morik, 1991) and RIGEL <ref> (Gemello et al., 1991) </ref>), and the theoretical work on generalization and complexity (Buntine, 1988; Haussler, 1988; Helft, 1989; Michalski, 1991; Flach, 1995) contributed to a deeper understanding of this difficult and challenging task.
Reference: <author> Giordana, A. and Neri, F. </author> <year> (1996). </year> <title> Search-intensive concept induction. </title> <journal> Evolutionary Computation, </journal> <volume> 3 </volume> <pages> 375-416. </pages>
Reference-contexts: The considered approaches are the symbolic one, exploited in the systems SMART+, SNAP, WHY and RTL, the genetic one, in REGAL (Giordana and Saitta, 1994) and SMART+ (Botta and Giordana, 1993), and the connectionist one, in SNAP <ref> (Botta and Giordana, 1996) </ref>. The multistrategy cooperation framework is hierarchically structured. At the higher level, we pose a symbolic relational learner like SMART+, which is responsible for constructing a first order classification theory. <p> Moreover, SMART+ is provided with a postprocessor, based on a genetic algorithm, which accomplishes the refinement of the continuous intervals previously learned. * SNAP <ref> (Botta and Giordana, 1996) </ref>, a variant of SMART+, which has been designed for learning to predict temporal series, and combines the symbolic learning paradigm with the connectionist one, according to the method described in Section 3.4. 4.1. <p> Even if they started from the same language, the knowledge base generated by SMART+ is much more detailed and complex than the one generated by REGAL. In fact, as discussed in <ref> (Giordana and Neri, 1996) </ref>, REGAL has a large generalization capacity, which usually allows it to find classification theories very much compact and simple. On the contrary, SMART+ has other advantages, such as the possibility of guiding induction with large bodies of a priori knowledge. <p> In particular, inductive hill-climbing, best-first, depth-first and beam search, controlled by a variety of heuristic evaluations (Botta and Giordana, 1993), can be used in SMART+. Genetic search in used in REGAL, and backpropagation or -rule are used in SNAP <ref> (Botta and Giordana, 1996) </ref>. All the above search strategies have been used in one or anther learning system. Most ILP systems use hill-climbing, but also beam search (Pompe and Kononenko, 1995) and bi-directional search (Muggleton, 1995) have been used.
Reference: <author> Giordana, A. and Saitta, L. </author> <year> (1990). </year> <title> Abstraction: a general framework for learning. </title> <booktitle> In Working Notes of the AGAA-90 Workshop, </booktitle> <pages> pages 245-256, </pages> <address> Boston, MA. </address>
Reference: <author> Giordana, A. and Saitta, L. </author> <year> (1993). </year> <title> Regal: an integrated system for learning relations using genetic algorithms. </title> <booktitle> In 2nd Multistrategy Learning Workshop, </booktitle> <pages> pages 234-249, </pages> <address> Harpers Ferry, WV. </address>
Reference-contexts: This feature proved to be essential in learning an industrial troubleshooter (Giordana et al., 1993b) used in field. ML-SMART evolved later into two new systems, both including inductive and deductive components: SMART+ <ref> (Botta and Giordana, 1993) </ref>, which emphasizes handling noise and continuous attributes by exploiting powerful heuristics for controlling the search in the hypothesis space, and WHY (Baroglio et al., 1994; Saitta et al., 1993), which stresses the importance of exploiting background knowledge, in the form of a causal model of the application <p> Systems like SMART+, instead, have a much weaker declarative bias, but they widely exploits procedural biases in the form of search heuristics <ref> (Botta and Giordana, 1993) </ref>. Increasing the search power has been tried for the first time (in FOL) in the system REGAL, which learns relations via a genetic algorithm (Giordana and Sale, 1992; Giordana and Saitta, 1994; Giordana and Neri, 1996). <p> Moreover, the HDL we used allows predicates to contain one internal disjunction. Even though a more complex version of this language, including numerical quantifiers and unrestricted negation has been used in SMART+ <ref> (Botta and Giordana, 1993) </ref> and Enigma (Giordana et al., 1993b), we will consider here this simpler form that allows a direct comparison with the languages used in other systems such as FOIL, FOCL and most ILP programs. <p> The considered approaches are the symbolic one, exploited in the systems SMART+, SNAP, WHY and RTL, the genetic one, in REGAL (Giordana and Saitta, 1994) and SMART+ <ref> (Botta and Giordana, 1993) </ref>, and the connectionist one, in SNAP (Botta and Giordana, 1996). The multistrategy cooperation framework is hierarchically structured. At the higher level, we pose a symbolic relational learner like SMART+, which is responsible for constructing a first order classification theory. <p> In both cases, the problem is to evaluate a formula = '^P (::; V ), obtained by AND-ing ' with a literal containing an internal disjunction V . The evaluation ( ) is the weighted sum of two terms <ref> (Botta and Giordana, 1993) </ref>: where 1 ('; ) is the information gain (Quinlan, 1990) of with respect to ', and 2 ( ) an evaluation of the absolute completeness and consistency of formula . <p> Return &lt; V; ( ) &gt;. Even though Algorithm 1 is not optimal, it is relatively fast, because it is linear with the number of v i 's, and in practice it gives good results. In order to deal with continuous intervals a different algorithm has been designed <ref> (Botta and Giordana, 1993) </ref>: Algorithm 2 Let V =&lt; v m ; v M &gt; be the template of the interval to be determined; let moreover k be an assigned integer, and = (v M v m )=k. 1. <p> This kind of transformation is described in (Goldberg, 1989) and has been used in a version of SMART+ <ref> (Botta and Giordana, 1993) </ref>. A different approach can be taken, following the tendency of the Evolutionary Computation approach, using 18 GIORDANA, NERI, SAITTA, BOTTA a chromosome composed of "real" genes (see Figure 5 (b)). In this way, special crossover and mutation operators, capable of combining real numbers, must be used. <p> obtained with three systems, each one exploiting one or more of the algorithms described in Section 3: * REGAL (Giordana and Sale, 1992; Giordana and Saitta, 1993; Giordana and Neri, 1996), which is based on a genetic algorithm and makes use of predicates containing only discrete internal disjunctions. * SMART+ <ref> (Botta and Giordana, 1993) </ref>, a multistrategy system per se, which combines symbolic learning strategies (both inductive and deductive) with the algorithms for learning internal disjunctions also in continuous domains. <p> More specifically, it shows how the different algorithms described in Sections 3.2 and 3.3 cooperate, producing a very accurate knowledge base. This domain, even though artificial, is quite complex and bears many features of a real world one. It has been described in <ref> (Botta and Giordana, 1993) </ref>, in order to illustrate the learning strategies of SMART+. Ten capital letters of the English alphabet have been chosen, and have been described as they could appear after segmenting the patterns produced by an electric pen. <p> Then, each train has been classified using a set of disjunctive rules. The challenge for REGAL was to discover the original rules or a set of equivalent ones. The formulation of this problem dates to <ref> (Giordana and Saitta, 1993) </ref> and the current best results obtained by REGAL have been published in (Giordana and Saitta, 1994). The concept description language used by REGAL is very similar to the one described in (Michalski, 1983). <p> Search Methods In the basic framework, several search methods and strategies can be applied. In particular, inductive hill-climbing, best-first, depth-first and beam search, controlled by a variety of heuristic evaluations <ref> (Botta and Giordana, 1993) </ref>, can be used in SMART+. Genetic search in used in REGAL, and backpropagation or -rule are used in SNAP (Botta and Giordana, 1996). All the above search strategies have been used in one or anther learning system.
Reference: <author> Giordana, A. and Saitta, L. </author> <year> (1994). </year> <title> Learning disjunctive concepts by means of genetic algorithms. </title> <booktitle> In 11th International Conference on Machine Learning, </booktitle> <pages> pages 96-104, </pages> <address> New Brunswick, NJ. </address>
Reference-contexts: The considered approaches are the symbolic one, exploited in the systems SMART+, SNAP, WHY and RTL, the genetic one, in REGAL <ref> (Giordana and Saitta, 1994) </ref> and SMART+ (Botta and Giordana, 1993), and the connectionist one, in SNAP (Botta and Giordana, 1996). The multistrategy cooperation framework is hierarchically structured. At the higher level, we pose a symbolic relational learner like SMART+, which is responsible for constructing a first order classification theory. <p> As an example, the template for the predicate Color shall enumerate all considered color values. If the attribute has a continuous range of values, as, for instance, the predicate Height, the template shall denote the maximum range allowed for the values <ref> (Giordana and Saitta, 1994) </ref>. 3.2. Learning Internal Disjunctions Locally In the general-to-specific learning strategy described in Section 3.1 it has been assumed that an algorithm for determining the best predicate to add to a formula ' is available. <p> The challenge for REGAL was to discover the original rules or a set of equivalent ones. The formulation of this problem dates to (Giordana and Saitta, 1993) and the current best results obtained by REGAL have been published in <ref> (Giordana and Saitta, 1994) </ref>. The concept description language used by REGAL is very similar to the one described in (Michalski, 1983). REGAL found 5 disjuncts covering completely and consistently both the learning set and the test set.
Reference: <author> Giordana, A., Saitta, L., and Baroglio, C. </author> <year> (1993a). </year> <title> Learning simple recursive theories. </title> <booktitle> In Methodologies for Intelligent Systems, Proc. of the 7th International Symposium, </booktitle> <address> ISMIS-93, Trondheim, Norway. </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Giordana, A., Saitta, L., and Bergadano, F. </author> <year> (1993b). </year> <title> Enigma: a system that learns diagnostic knowledge. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 5(1) </volume> <pages> 15-28. </pages>
Reference-contexts: An important aspect of ML-SMART was its interface to a database, from which the examples were extracted, and in which both the generated hypotheses and their extensions were stored (Bergadano et al., 1988). This feature proved to be essential in learning an industrial troubleshooter <ref> (Giordana et al., 1993b) </ref> used in field. <p> Moreover, the HDL we used allows predicates to contain one internal disjunction. Even though a more complex version of this language, including numerical quantifiers and unrestricted negation has been used in SMART+ (Botta and Giordana, 1993) and Enigma <ref> (Giordana et al., 1993b) </ref>, we will consider here this simpler form that allows a direct comparison with the languages used in other systems such as FOIL, FOCL and most ILP programs. <p> First of all, we will briefly recall how inductive inference, specified via a high level strategy, can be realized on a database by means of relational algebra (Ullman, 1982). The main advantage of this approach, already discussed in <ref> (Giordana et al., 1993b) </ref> and applied in various systems, is the possibility of directly embedding learning abilities into a database manager. This possibility, which is important for data mining applications, is a common platform for all the learning approaches exploiting the described HDL, and allows a natural cooperation among them. <p> The obtained results are reported in (Neri and Saitta, 1996). A successful application of Enigma, the direct ancestor of SMART+ that was already provided with an earlier version of the algorithm for learning continuous intervals, was the automated generation of a troubleshooter <ref> (Giordana et al., 1993b) </ref>. This represented a real application, in industry, of a learning system based on FOL. In fact, the troubleshooter was used for several years in field for maintenance and training purposes. <p> approaches: * The database technology allows very large datasets, as they are usually found in the archives, to be handled without any need of format conversion. * The possibility of using SQL or other languages for "real programmers" makes it easier to bring a machine learning tool inside a company <ref> (Giordana et al., 1993b) </ref>. * The functional layer, filling the semantic gap between logics and data, offers an abstraction mechanism, which can be exploited by multistrategy learners integrating heterogeneous algorithms, possibly implemented in different languages.
Reference: <author> Giordana, A., Saitta, L., and Roverso, D. </author> <year> (1991). </year> <title> Abstracting concepts with inverse resolution. </title> <booktitle> In 8th International Workshop on Machine Learning, </booktitle> <pages> pages 142-146, </pages> <address> Evanston, IL. </address>
Reference: <author> Giordana, A. and Sale, C. </author> <year> (1992). </year> <title> Genetic algorithms for learning relations. </title> <booktitle> In 9th International Conference on Machine Learning, </booktitle> <pages> pages 169-178, </pages> <address> Aberdeen, UK. </address>
Reference-contexts: Other Examples Other examples of applications are reported in this section, to provide the reader with a feeling of the application range available to the proposed framework. In the chess domain, the chess-endgame KR-KR problem (Quinlan, 1983) was one of the first handled by an early REGAL's prototype <ref> (Giordana and Sale, 1992) </ref>. Using a learning set of 1000 examples it learned the concept of safe black king with an accuracy of 99.75%, evaluated on a test set of 2000 instances. The King-Rook-King end-game problem has been discussed in (Botta, 1994).
Reference: <author> Goldberg, D. </author> <year> (1989). </year> <title> Genetic Algorithms. </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: The star denotes the possible completion of a set of values. For a continuous interval, defined by a pair of reals, a different approach has been adopted. A first solution, in agreement with the most classical GA approach <ref> (Goldberg, 1989) </ref>, is to transform the real numbers into discrete integers that can be encoded as binary numbers; in this way, the chromosome becomes a bit string. This kind of transformation is described in (Goldberg, 1989) and has been used in a version of SMART+ (Botta and Giordana, 1993). <p> A first solution, in agreement with the most classical GA approach <ref> (Goldberg, 1989) </ref>, is to transform the real numbers into discrete integers that can be encoded as binary numbers; in this way, the chromosome becomes a bit string. This kind of transformation is described in (Goldberg, 1989) and has been used in a version of SMART+ (Botta and Giordana, 1993). A different approach can be taken, following the tendency of the Evolutionary Computation approach, using 18 GIORDANA, NERI, SAITTA, BOTTA a chromosome composed of "real" genes (see Figure 5 (b)).
Reference: <author> Gordon, D. and desJardins, M. </author> <year> (1995). </year> <title> Evaluation and selection of biasesi in machine learning. </title> <journal> Machine Learning, </journal> <volume> 20 </volume> <pages> 5-22. </pages>
Reference-contexts: The matching problem has been proved to be an NP-complete problem (Haussler, 1988) even in very simple cases. There are basically two ways to deal with this problem: the first is to reduce the search by adding various kinds of bias in the learning process <ref> (Gordon and desJardins, 1995) </ref>, both declarative (syntactic and semantic (Ade et al., 1995)) and procedural ones. The second one is to increase the search power of the learning algorithm (Muggleton, 1995).
Reference: <author> Greene, D. and Smith, S. </author> <year> (1993). </year> <title> Competition-based induction of decision models from examples. </title> <journal> Machine Learning, </journal> <volume> 13 </volume> <pages> 229-258. </pages>
Reference: <author> Grefenstette, J., Ramsey, C., and Schultz, A. </author> <year> (1990). </year> <title> Learning sequential decision rules using simulation models and competition. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 355-381. </pages>
Reference: <author> Haussler, D. </author> <year> (1988). </year> <title> Learning conjunctive concepts in structural domains. </title> <journal> Machine Learning, </journal> <volume> 4 </volume> <pages> 7-40. </pages> <note> 34 GIORDANA, </note> <author> NERI, SAITTA, BOTTA Hayes-Roth, F. and McDermott, J. </author> <year> (1978). </year> <title> An interference matching technique for inducing abstractions. </title> <journal> Communications of the ACM, </journal> 21:401-411. 
Reference-contexts: Whatever the name under which learning in FOL is performed, a major issue to be tamed is computational complexity. The matching problem has been proved to be an NP-complete problem <ref> (Haussler, 1988) </ref> even in very simple cases. There are basically two ways to deal with this problem: the first is to reduce the search by adding various kinds of bias in the learning process (Gordon and desJardins, 1995), both declarative (syntactic and semantic (Ade et al., 1995)) and procedural ones.
Reference: <author> Helft, N. </author> <year> (1989). </year> <title> Induction as nonmonotonic inference. </title> <booktitle> In 1st Conference on Knowledge Representation and Reasoning, </booktitle> <pages> pages 149-156, </pages> <address> Boston, MA. </address>
Reference: <author> Henschen, L. J. and Naqvi, S. A. </author> <year> (1984). </year> <title> On compiling queries in recursive, first order databases. </title> <journal> Journal of ACM, </journal> <volume> 31. </volume>
Reference: <author> Janikow, C. </author> <year> (1993). </year> <title> A knowledge intensive genetic algorithm for supervised learning. </title> <journal> Machine Learning, </journal> <volume> 13 </volume> <pages> 198-228. </pages>
Reference: <author> Kodratoff, Y. and Ganascia, J. </author> <year> (1986). </year> <title> Improving the generalization step in learning. </title> <editor> In J.G.Carbonell, Michalski, R., and Mitchell, T. M., editors, </editor> <booktitle> Machine Learning, an Artificial Intelligence Approach, </booktitle> <volume> volume II, </volume> <pages> pages 215-244. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Lavrac, N., Dzeroski, S., and Grobelnik, M. </author> <year> (1991). </year> <title> Learing nonrecursive definitions of relations with LINUS. </title> <booktitle> In Proceedings of the 5th European Working Session on Learning, </booktitle> <pages> pages 265-281. </pages>
Reference-contexts: In several applications we performed, the number of useful different bindings turned out to be few tens. A different mapping between formulas and propositional calculus is presented in the system LINUS <ref> (Lavrac et al., 1991) </ref>, where the atomic predicates are transformed into sets of positive and negative literals, which then play the role of attributes. 4.
Reference: <author> Lindner, G. and Morik, K. </author> <year> (1995). </year> <title> Coupling a relational learning algorithm with a database system. </title> <booktitle> In Proc. of the MLnet Familiarization Workshop, </booktitle> <pages> pages 163-168, </pages> <address> Heraklion, Crete. </address>
Reference: <author> McCallum, R. and Spackman, K. </author> <year> (1990). </year> <title> Using genetic algorithm to learn disjunctive rules from examples. </title> <booktitle> In International Conference on Machine Learning, </booktitle> <pages> pages 149-152, </pages> <address> Austin, Texas. </address>
Reference: <author> Michalski, R. </author> <year> (1980). </year> <title> Pattern recognition as a rule-guided inductive inference. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-2:349-361. </journal>
Reference: <author> Michalski, R. </author> <year> (1983). </year> <title> A theory and methodology of inductive learning. </title> <editor> In Michalski, R., Car-bonell, J., and Mitchell, T., editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <pages> pages 83-134, </pages> <address> Los Altos, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The HDL is a clausal language in annotated predicate calculus, equivalent to the V L 21 language <ref> (Michalski, 1983) </ref> without numerical quantifiers but with negation on atoms. Moreover, the HDL we used allows predicates to contain one internal disjunction. <p> By adding a domain theory, it was able to reach 100% accuracy. Another case study, designed explicitly for challenging REGAL, is the Thousand trains dataset, extending the well known train set used by Michalski <ref> (Michalski, 1983) </ref>. There are two concepts to discriminate: "Trains going East" and "Trains going West". Thousands of trains have been generated by a program which selects at random the values of the attributes. Then, each train has been classified using a set of disjunctive rules. <p> The formulation of this problem dates to (Giordana and Saitta, 1993) and the current best results obtained by REGAL have been published in (Giordana and Saitta, 1994). The concept description language used by REGAL is very similar to the one described in <ref> (Michalski, 1983) </ref>. REGAL found 5 disjuncts covering completely and consistently both the learning set and the test set.
Reference: <author> Michalski, R. </author> <year> (1991). </year> <title> Inferential learning theory as a basis for multistrategy task-adaptive learning. </title> <booktitle> In 1st Multistrategy Learning Workshop, </booktitle> <pages> pages 3-18, </pages> <address> Harpers Ferry, WV. </address>
Reference: <author> Michalski, R. and Chilauski, R. </author> <year> (1980). </year> <title> Learning by being told and learning from examples: an experimental comparison of the two methods of knowledge acquisition in the context of developing an expert system for soybean disease diagnosis. </title> <journal> International Journal of Policy Analysis and Information Systems, </journal> <volume> 4 </volume> <pages> 125-126. </pages>
Reference: <author> Minker, J., </author> <title> editor (1988). Foundations of Deductive Databases and Logic Programming. </title> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address>
Reference: <author> Mitchell, T., Keller, R., and Kedar-Cabelli, S. </author> <year> (1986). </year> <title> Explanation based generalization: an unifying view. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 47-80. </pages>
Reference-contexts: Also, in their approach, each example is a separate mini-database (a finite interpretation of a clausal theory), similar to our scenario. Hypothesis Description Language (HDL) A set of operational predicates <ref> (Mitchell et al., 1986) </ref> are supplied. They can be constraint predicates, with no internal disjunction, or learnable predicates, with one term in disjunctive form. The semantic of the predicates is defined in terms of properties, and negation of atoms is allowed. <p> Several among the described methodological aspects are not new; for INTEGRATING MULTIPLE STRATEGIES IN FOL 31 example, internal disjunction has been introduced by Michalski (Michalski, 1983; Michalski and Chilauski, 1980). The idea of introducing a semantic gap between the concept description language and the instance representation derives from EBL <ref> (Mitchell et al., 1986) </ref>; in fact, the functional layer, which abstracts the object properties from the basic descriptions, can be seen as a domain theory that makes operational the predicates defined in the concept description language.
Reference: <author> Moody, J. and Darken, C. </author> <year> (1988). </year> <title> Learning with localized receptive fields. </title> <editor> In Sejnowski, T., Touretzky, D., and Hinton, G., editors, </editor> <booktitle> Connectionist Models Summer School, </booktitle> <institution> Carnegie Mellon University. </institution>
Reference-contexts: Table 2 shows the results of two experiments, in terms of the Non-Dimensional Error Index (ratio between the average square root error and the standard deviation). The first two lines reports the result obtained with CART, reported in (Baroglio et al., 1996), and the result obtained by <ref> (Moody and Darken, 1988) </ref> using a RBFN constructed with an enhaced version of the k-means.
Reference: <author> Morik, K. </author> <year> (1991). </year> <title> Balanced cooperative modeling. </title> <booktitle> In Proc. of the 1st Multistrategy Learning Workshop, </booktitle> <pages> pages 65-80, </pages> <address> Harpers Ferry, WV. </address>
Reference-contexts: More recently, a number of new learning applications in FOL have been reported (see, among others, (Bratko and Dzeroski, 1995)). The development of other systems (see, for instance, MOBAL <ref> (Morik, 1991) </ref> and RIGEL (Gemello et al., 1991)), and the theoretical work on generalization and complexity (Buntine, 1988; Haussler, 1988; Helft, 1989; Michalski, 1991; Flach, 1995) contributed to a deeper understanding of this difficult and challenging task. <p> This can be seen as a specific learning subtask. In the following subsection, implemented solutions to this subtask will be described. All of them use the notion of predicate template, which plays a role similar to that of schemata <ref> (Morik, 1991) </ref> or relational cliche (Pazzani and Kibler, 1992).
Reference: <author> Muggleton, S. </author> <year> (1991). </year> <title> Inductive logic programming. </title> <journal> New Generation Computing, </journal> <volume> 8 </volume> <pages> 295-318. </pages>
Reference-contexts: In the last years, learning in FOL has been re-proposed as "Learning Relations" (Quinlan, 1990) and Inductive Logic Programming (ILP) <ref> (Muggleton, 1991) </ref>. Originally, learning relations, as exemplified by the system FOIL (Quinlan, 1990), was an extension to FOL of the top-down construction of a decision tree, similar to the method presented in (Bergadano and Giordana, 1988).
Reference: <author> Muggleton, S. </author> <year> (1995). </year> <title> Inverse entailment and Progol. </title> <journal> New Generation Computing, </journal> <volume> 13 </volume> <pages> 245-286. </pages>
Reference-contexts: The second one is to increase the search power of the learning algorithm <ref> (Muggleton, 1995) </ref>. Constraining the search by adding a strong declarative bias, aimed at reducing the expressive power of the hypothesis language, is the solution most frequently adopted in ILP (Ade et al., 1995). <p> Genetic search in used in REGAL, and backpropagation or -rule are used in SNAP (Botta and Giordana, 1996). All the above search strategies have been used in one or anther learning system. Most ILP systems use hill-climbing, but also beam search (Pompe and Kononenko, 1995) and bi-directional search <ref> (Muggleton, 1995) </ref> have been used.
Reference: <author> Muggleton, S. and Feng, C. </author> <year> (1990). </year> <title> Efficient induction of logic programs. </title> <booktitle> In Proc. of the 1st Conference on Algorithmic Learning Theory, </booktitle> <pages> pages 368-381, </pages> <address> Japan. </address>
Reference-contexts: The Knowledge Representation Framework Many learning algorithms in FOL describe the learning instances using a subset of the hypothesis description language in ground form. This was the method adopted, for instance, by Induce (Michalski, 1980; Michalski, 1983), and, more recently, by GOLEM <ref> (Muggleton and Feng, 1990) </ref>. This method has the advantage that the truth of a formula in the hypothesis description language can be proved using logical resolution only. In the framework we present, on the contrary, we keep separate the hypothesis description language (HDL) and the instance description language (IDL).
Reference: <author> Neri, F. and Saitta, L. </author> <year> (1996). </year> <title> Exploring the power of genetic search in learning symbolic classifiers. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, PAMI-18:1135-1142. </journal>
Reference-contexts: Even if they started from the same language, the knowledge base generated by SMART+ is much more detailed and complex than the one generated by REGAL. In fact, as discussed in <ref> (Giordana and Neri, 1996) </ref>, REGAL has a large generalization capacity, which usually allows it to find classification theories very much compact and simple. On the contrary, SMART+ has other advantages, such as the possibility of guiding induction with large bodies of a priori knowledge. <p> Other test-beds for REGAL have been the Mushrooms and the Splice Junctions datasets from Irvine repository. The obtained results are reported in <ref> (Neri and Saitta, 1996) </ref>. A successful application of Enigma, the direct ancestor of SMART+ that was already provided with an earlier version of the algorithm for learning continuous intervals, was the automated generation of a troubleshooter (Giordana et al., 1993b).
Reference: <author> Opitz, D. and Shavlik, J. </author> <year> (1993). </year> <title> Heuristically expanding knowledge-based neural networks. </title> <booktitle> In IJCAI '93: Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <volume> volume 2, </volume> <pages> pages 1360-1365, </pages> <address> Chambery, France. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Opitz, D. and Shavlik, J. </author> <year> (1995). </year> <title> Dynamically adding symbolically meaningful nodes to knowledge-based neural networks. </title> <journal> Knowledge Based Systems, </journal> <volume> 8 </volume> <pages> 301-311. </pages>
Reference: <author> Pagallo, G. </author> <year> (1989). </year> <title> Learning dnf by decision trees. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 639-644, </pages> <address> Detroit, MI. </address>
Reference-contexts: Notice how some constructive induction mechanism (Wnek and Michalski, 1993), such as Fringe <ref> (Pagallo, 1989) </ref>, builds new predicates on disjunctive atomic expressions, so reproducing something similar to what is immediately available in annotated predicate calculus. Predicates in HDL are of two kinds: constraint predicates, which do not contain the internal disjunction term, and learnable predicates, containing an internal disjunction.
Reference: <author> Pazzani, M. and Kibler, D. </author> <year> (1992). </year> <title> The utility of knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 57-94. </pages>
Reference-contexts: Notwithstanding the above difficulties, some systems, such as ML-SMART (Bergadano et al., 1988; Bergadano et al., 1991) and FOCL <ref> (Pazzani and Kibler, 1992) </ref> have shown that FOL concept learning is not only abstractly interesting, but feasible. The system ML-SMART, in particular, has been applied to a number of real world problems (Bergadano et al., 1991; Giordana et al., 1993b), and suggested effective solutions for many of the encountered problems. <p> This can be seen as a specific learning subtask. In the following subsection, implemented solutions to this subtask will be described. All of them use the notion of predicate template, which plays a role similar to that of schemata (Morik, 1991) or relational cliche <ref> (Pazzani and Kibler, 1992) </ref>. Given a predicate P , containing an internal disjunction, the template T P associated to P , is the maximum internal disjunction allowed for P : any internal disjunction occurring in an instance of P can only be a subset of T P . <p> Following the proposal of using an Explanation-Based approach to learning (Mitchell et al., 1986; DeJong and Mooney, 1986), the ability to handle background knowledge has been incorporated in several systems (only as an example, we can mention FOCL <ref> (Pazzani and Kibler, 1992) </ref>). In some ILP systems the background knowledge is nothing else than a list of known facts, i.e., ground literals; in others, a background knowledge, expressed in clausal form, can also be exploited. Search Methods In the basic framework, several search methods and strategies can be applied.
Reference: <author> Plotkin, G. </author> <year> (1970). </year> <title> A note in inductive generalization. </title> <editor> In Meltzer, B. and Michie, D., editors, </editor> <booktitle> Machine Intelligence, volume V, </booktitle> <pages> pages 153-163. </pages>
Reference: <author> Poggio, T. and Girosi, F. </author> <year> (1990). </year> <title> Networks for approximation and learning. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 78(9) </volume> <pages> 1481-1497. </pages> <booktitle> INTEGRATING MULTIPLE STRATEGIES IN FOL 35 Pompe, </booktitle> <editor> U. and Kononenko, I. </editor> <year> (1995). </year> <title> Linear space induction in first order logic with relief. </title> <booktitle> In ISSEK Workshop, volume CISM Lecture Notes. </booktitle> <publisher> Springer-Verlag. </publisher>
Reference-contexts: In (Baroglio et al., 1996; Blanzieri and Katenkamp, 1996; Tresp et al., 1993) it has been widely discussed how a propositional logic theory can be translated into a Radial Basis Function Network (RBFN) <ref> (Poggio and Girosi, 1990) </ref> that can be tuned following the quadratic error gradient descent. The underlying idea is very simple. A set of n continuous attributes defines an n dimensional space X n , where the ith attribute corresponds to an axis x i in X n . <p> Interpreting the logical conjunction as an arithmetic product, the hypercube A j is transformed into a Hypergaussian having the general format: G j (~x) = i=1 n Y e x i c ji = e P n x i c ji (15) According to <ref> (Poggio and Girosi, 1990) </ref>, expression (15), is a Factorizable Radial Basis Function.
Reference: <author> Quinlan, R. </author> <year> (1983). </year> <title> Efficient classification procedures. </title> <editor> In Carbonell, J., Michalski, R., and Mitchell, T., editors, </editor> <booktitle> Machine Learning, an Artificial Intelligence Approach. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Other Examples Other examples of applications are reported in this section, to provide the reader with a feeling of the application range available to the proposed framework. In the chess domain, the chess-endgame KR-KR problem <ref> (Quinlan, 1983) </ref> was one of the first handled by an early REGAL's prototype (Giordana and Sale, 1992). Using a learning set of 1000 examples it learned the concept of safe black king with an accuracy of 99.75%, evaluated on a test set of 2000 instances.
Reference: <author> Quinlan, R. </author> <year> (1990). </year> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 239-266. </pages>
Reference-contexts: In the last years, learning in FOL has been re-proposed as "Learning Relations" <ref> (Quinlan, 1990) </ref> and Inductive Logic Programming (ILP) (Muggleton, 1991). Originally, learning relations, as exemplified by the system FOIL (Quinlan, 1990), was an extension to FOL of the top-down construction of a decision tree, similar to the method presented in (Bergadano and Giordana, 1988). <p> In the last years, learning in FOL has been re-proposed as "Learning Relations" <ref> (Quinlan, 1990) </ref> and Inductive Logic Programming (ILP) (Muggleton, 1991). Originally, learning relations, as exemplified by the system FOIL (Quinlan, 1990), was an extension to FOL of the top-down construction of a decision tree, similar to the method presented in (Bergadano and Giordana, 1988). <p> The evaluation ( ) is the weighted sum of two terms (Botta and Giordana, 1993): where 1 ('; ) is the information gain <ref> (Quinlan, 1990) </ref> of with respect to ', and 2 ( ) an evaluation of the absolute completeness and consistency of formula . <p> In many ILP systems, instances as represented as ground clauses (facts), and this is true also for Induce-like learners. FOIL represents instances as tuples in a table <ref> (Quinlan, 1990) </ref>. A comment is in order about the semantic setting. In the normal ILP setting, hypotheses are only required to be consistent with the negative instances, so that what is not explicitely stated as true is unknown, and hypotheses covering unknown facts can be accepted.
Reference: <author> Rumelhart, D., Hinton, G., and Williams, R. </author> <year> (1985). </year> <title> Learning internal representations by error propagation. </title> <type> Technical Report 8506, </type> <institution> Institute for Cognitive Science, La Jolla: University of California, </institution> <address> San Diego. </address>
Reference: <author> Rumelhart, D. E. and McClelland, J. L. </author> <year> (1986). </year> <title> Parallel Distributed Processing : Explorations in the Microstructure of Cognition, Parts I & II. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts. </address>
Reference-contexts: In the case of a multi-class classification theory, it is immediate to extend this neural architecture in order to have multiple output units, i.e., one for every class, as it is done in other neural networks <ref> (Rumelhart and McClelland, 1986) </ref>. Even though transforming a propositional theory into a RBFN does not preserve the original logical rigor, we obtain the important advantage that a RBFN can be finely tuned by means of the -rule (Rumelhart and McClelland, 1986). <p> i.e., one for every class, as it is done in other neural networks <ref> (Rumelhart and McClelland, 1986) </ref>. Even though transforming a propositional theory into a RBFN does not preserve the original logical rigor, we obtain the important advantage that a RBFN can be finely tuned by means of the -rule (Rumelhart and McClelland, 1986).
Reference: <author> Saitta, L., Botta, M., and Neri, F. </author> <year> (1993). </year> <title> Multistrategy learning and theory revision. </title> <journal> Machine Learning, </journal> <volume> 11 </volume> <pages> 153-172. </pages>
Reference-contexts: Then, each train has been classified using a set of disjunctive rules. The challenge for REGAL was to discover the original rules or a set of equivalent ones. The formulation of this problem dates to <ref> (Giordana and Saitta, 1993) </ref> and the current best results obtained by REGAL have been published in (Giordana and Saitta, 1994). The concept description language used by REGAL is very similar to the one described in (Michalski, 1983).
Reference: <author> Saitta, L., Giordana, A., and Neri, F. </author> <year> (1995). </year> <title> What is the "Real World"? In Proc. </title> <booktitle> of Workshop on Applying Machine Learning in Practice, </booktitle> <pages> pages 34-40, </pages> <address> Lake Tahoe, CA. </address>
Reference: <author> Sammut, C., Hurst, S., Kedzier, D., and Michie, D. </author> <year> (1992). </year> <title> Learning to fly. </title> <editor> In Sleeman, D. and Edwards, P., editors, </editor> <booktitle> Machine Learning Proceedings of the Ninth International Workshop (ML92), </booktitle> <pages> pages 385-393. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Numerical series prediction is a regression task, but it can be reduced to a classification task by discretizing the domain of the target function and considering each discrete value as a class. This approach has been adopted in <ref> (Sammut et al., 1992) </ref> to learn a flight controller for a simulator. More recently, a similar method has been proposed in (Baroglio et al., 1996) to synthesize fuzzy controllers. Here we adopted the same approach in combination with the methodology described in Section 3.4 for tuning numeric intervals.
Reference: <author> Shapiro, E. </author> <year> (1983). </year> <title> Algorithmic Program Debugging. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: INTEGRATING MULTIPLE STRATEGIES IN FOL 3 ILP stems from two sources: its goal recalls Shapiro's work, aimed at synthesizing logic programs <ref> (Shapiro, 1983) </ref>, whereas its theoretical background focuses on logical theories of induction. Actually, as acknowledged in (Ade et al., 1995), most ILP systems have dealt with concept learning from examples, so that the differences between ILP and previous research in learning in FOL loose sharpness.
Reference: <author> Towell, G., Shavlik, J., and Noordwier, M. </author> <year> (1990). </year> <title> Refinement of approximate domain theories by knowledge-based neural networks. </title> <booktitle> In Proceedings of the 8 th National Conference on Artificial Intelligence AAAI'90, </booktitle> <pages> pages 861-866. </pages>
Reference: <author> Tresp, V., Hollatz, J., and Ahmad, S. </author> <year> (1993). </year> <title> Network structuring and training using rule-based knowledge. </title> <booktitle> In Advances in Neural Information Processing Systems 5 (NIPS-5). </booktitle>
Reference: <author> Ullman, J. </author> <year> (1982). </year> <title> Principles of Databases. </title> <institution> Computer Science, Baltimore, MD. </institution>
Reference-contexts: for IDL, we will first describe the Hypothesis Description Language from an abstract point of view, and, then, we will show, step by step, how a formula of HDL can be evaluated, in an efficient way, on the adopted learning instance representation by applying a sequence of relational algebra operators <ref> (Ullman, 1982) </ref>. The HDL is a clausal language in annotated predicate calculus, equivalent to the V L 21 language (Michalski, 1983) without numerical quantifiers but with negation on atoms. Moreover, the HDL we used allows predicates to contain one internal disjunction. <p> First of all, we will briefly recall how inductive inference, specified via a high level strategy, can be realized on a database by means of relational algebra <ref> (Ullman, 1982) </ref>. The main advantage of this approach, already discussed in (Giordana et al., 1993b) and applied in various systems, is the possibility of directly embedding learning abilities into a database manager. <p> Notice that, doing in this way, the object properties necessary to the selection operator are computed on demand, exiting so from the scheme of pure relational algebra <ref> (Ullman, 1982) </ref> 3. We remember that a model of a theory is a binding which verifies the theory.
Reference: <author> Vafaie, H. and Jong, K. D. </author> <year> (1991). </year> <title> Improving the performance of rule induction system using genetic algorithms. </title> <booktitle> In 1st International Workshop on Multistrategy Learning, </booktitle> <pages> pages 305-315, </pages> <address> Harpers Ferry, WV. </address>
Reference: <author> Vere, S. </author> <year> (1978). </year> <title> Inductive learning of relational production. </title> <booktitle> In Pattern-Directed Inference System, </booktitle> <pages> pages 281-295. </pages> <publisher> Academic Press, </publisher> <address> London, UK. </address>
Reference: <author> Vieille, L. </author> <year> (1986). </year> <title> Recursive axioms in deductive databases: the query subquery approach. </title> <booktitle> In Proc. of First International Conference on Expert Database Systems, </booktitle> <address> Charleston, SC. </address>
Reference: <author> Winston, P. </author> <year> (1975). </year> <title> Learning structural descriptions from example. </title> <editor> In Winston, P., editor, </editor> <booktitle> The psychology of computer vision, </booktitle> <pages> pages 157-209. </pages> <address> McGraw Hill, New York, NY. </address>
Reference: <author> Wnek, J. and Michalski, R. </author> <year> (1993). </year> <title> Hypothesis-driven constructive induction in aq17-hci: A method and experiments. </title> <journal> Machine Learning, </journal> <volume> 14(2) </volume> <pages> 139-168. </pages>
Reference-contexts: Notice how some constructive induction mechanism <ref> (Wnek and Michalski, 1993) </ref>, such as Fringe (Pagallo, 1989), builds new predicates on disjunctive atomic expressions, so reproducing something similar to what is immediately available in annotated predicate calculus. <p> This feature is widely exploited, for instance, by the algorithms learning continuous intervals. * A last benefit, not described here, is the possibility of defining new features, or constructing new objects, as it is done in a constructive learning approach <ref> (Wnek and Michalski, 1993) </ref>. A more technical contribution of the paper resides in the algorithms for learning internal disjunctions.
Reference: <author> Zadeh, L. </author> <year> (1965). </year> <title> Fuzzy sets. </title> <journal> Information Control, </journal> <volume> 8 </volume> <pages> 338-353. </pages>
Reference: <author> Zadeh, L. </author> <year> (1992). </year> <title> Knowledge representation in fuzzy logic. </title> <editor> In Yager, R. and Zadeh, L., editors, </editor> <title> An Introduction to Fuzzy Logic Applications in Intelligent Systems. </title> <publisher> Kluver Academic Publishers. </publisher>
References-found: 85

