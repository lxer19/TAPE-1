URL: http://www.eecs.umich.edu/PPP/ICS94a.ps
Refering-URL: http://www.eecs.umich.edu/PPP/publist.html
Root-URL: http://www.cs.umich.edu
Title: Communication in the KSR1 MPP: Performance Evaluation Using Synthetic Workload Experiments  
Author: Eric L. Boyd and Edward S. Davidson 
Keyword: careful binding of threads to processors.  
Affiliation: Advanced Computer Architecture Laboratory Department of Electrical Engineering and Computer Science University of Michigan  
Note: The University of Michigan Center for Parallel Computing, site of the KSR1, is partially funded by NSF grant CDA-92-14296. Appeared in Proceedings of the 1994 International Conference on Supercomputing Manchester, England, pp. 166-175.  
Abstract: We have developed an automatic technique for evaluating the communication performance of massively parallel processors (MPPs). Both communication latency and the amount of communication are investigated as a function of a few basic parameters that characterize an application workload. Parameter values are captured in an automatically generated sparse matrix that multiplies a dense vector in the synthetic workload. Our approach is capable of explaining the degradation of processor performance caused by communication. Using the Kendall Square Research KSR1 MPP as a case study, we demonstrate the effectiveness of the technique through a series of experiments used to characterize the communication performance. We show that read and write communication latencies vary from 150 to 180 and from 80 to 100 processor cycles, respectively. We show that the read communication latency approximates a linear function of the total system communication (in subpages), write communication approximates a linear function of the number of distinct shared subpages, and that KSRs automatic update feature is effective in reducing the number of read communications given 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. L. Boyd, E. S. Davidson. </author> <title> Hierarchical Performance Modeling with MACS: A Case Study of the Convex C-240, </title> <booktitle> Proceedings of the 20th International Symposium on Computer Architecture , May, </booktitle> <year> 1993, </year> <pages> pp. 203-212. </pages>
Reference-contexts: The MACS hierarchical performance bounds model has been developed for and applied to simple uniprocessor architectures, decoupled access-execute architectures, superscalar architectures, vector architectures, and VLIW architectures such as a single processor of the KSR1. <ref> [1] </ref> [2] [3] [4] [5] [6] The MACS model bounds performance by consider ing the M achiness processor architecture, and successively expos ing performance gaps introduced by the pplication workload, the ompiler-generated workload, and the compiler cheduled workload.
Reference: [2] <author> J. Tang, E.S. Davidson, J. Tong, </author> <title> Polycyclic Vector Scheduling vs. Chaining on 1Port Vector Supercomputers, </title> <booktitle> Proceedings of Supercomputing 88 , CS Press, </booktitle> <address> Los Alamitos, California, </address> <publisher> Order No. </publisher> <address> FJ882, </address> <month> Nov., </month> <year> 1988, </year> <pages> pp. 122-129. </pages>
Reference-contexts: The MACS hierarchical performance bounds model has been developed for and applied to simple uniprocessor architectures, decoupled access-execute architectures, superscalar architectures, vector architectures, and VLIW architectures such as a single processor of the KSR1. [1] <ref> [2] </ref> [3] [4] [5] [6] The MACS model bounds performance by consider ing the M achiness processor architecture, and successively expos ing performance gaps introduced by the pplication workload, the ompiler-generated workload, and the compiler cheduled workload.
Reference: [3] <author> W. H. MangioneSmith, S. G. Abraham, E. S. </author> <title> Davidson, </title>
Reference-contexts: The MACS hierarchical performance bounds model has been developed for and applied to simple uniprocessor architectures, decoupled access-execute architectures, superscalar architectures, vector architectures, and VLIW architectures such as a single processor of the KSR1. [1] [2] <ref> [3] </ref> [4] [5] [6] The MACS model bounds performance by consider ing the M achiness processor architecture, and successively expos ing performance gaps introduced by the pplication workload, the ompiler-generated workload, and the compiler cheduled workload.
References-found: 3

