URL: http://www.eecs.umich.edu/~lefurgy/Publications/proposal.ps
Refering-URL: http://www.eecs.umich.edu/~lefurgy/Publications/index.html
Root-URL: http://www.cs.umich.edu
Title: Space-efficient Executable Program Representations for Embedded Microprocessors  
Author: by Charles Robert Lefurgy 
Degree: A thesis proposal submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy (Computer Science and Engineering) in The  Doctoral Committee: Professor Trevor Mudge, Chair Professor Richard Brown Assistant Professor Steve Reinhardt Assistant Professor Gary Tyson  
Date: 1998  
Affiliation: University of Michigan  
Abstract-found: 0
Intro-found: 1
Reference: [Abelson85] <author> H. Abelson and G. J. Sussman, </author> <title> Structure and Interpretation of Computer Programs, </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1985. </year>
Reference-contexts: Function memoization is a code optimization that caches the results of recent function invocations. The next time that the function is called with the same arguments, the result can be quickly provided from the cache instead of computing it <ref> [Abelson85] </ref>. Sodani [Sodani97] presents a method of improving execution time by memoizing individual machine instructions. He keeps the results of instruction execution in a table and uses these results if the instructions are encountered again with the same source values.
Reference: [ARM95] <institution> Advanced RISC Machines Ltd., </institution> <note> An Introduction to Thumb, </note> <month> March </month> <year> 1995. </year>
Reference-contexts: Thumb <ref> [ARM95, Turley95] </ref> and MIPS-16 [Kissell97] are two recently proposed instruction set modifications which define reduced instruction word sizes in an effort to reduce the overall size of compiled programs. Thumb and MIPS-16 are defined as subsets of the ARM and MIPS-III architectures. <p> The original 32-bit wide instructions have been re-encoded to be 16-bits wide. Thumb and MIPS-16 are reported to achieve code reductions of 30% and 40%, respectively <ref> [ARM95, Kissell97] </ref>. Thumb and MIPS-16 instructions have a one-to-one correspondence to instructions in the base architectures. In each case, a 16-bit instruction is fetched from the instruction memory, decoded to the equivalent 32-bit wide instruction, and passed to the base processor core for execution. <p> Therefore, programs require more instructions to accomplish the same tasks. This requires a program to execute more instructions, which reduces performance. For example, Thumb code runs 15% - 20% slower on systems with ideal instruction memories (32-bit buses and no wait states) <ref> [ARM95] </ref>. 2.2 Interpreted programs 2.2.1 Directly Executed Languages Flynn introduced the notion of Directly Executed Languages (DELs) whose representation could be specifically tailored to a particular application and language [Flynn83]. A DEL is program representation that is between the level of the source language and machine language. <p> Therefore, we plan to measure the effects of our program representations on the instruction cache. Many of the program representations that we reviewed obtained smaller programs at the cost of execution speed. Some previous studies <ref> [ARM95, Fraser95, Liao95] </ref> have proposed to balance this trade-off by only applying their representations to the portions of the program that are not frequently executed. This allows the highly executed parts of the program to proceed at the usual execution speed.
Reference: [Bell90] <author> T. Bell, J. Cleary, I. Witten, </author> <title> Text Compression, </title> <publisher> Prentice Hall, </publisher> <year> 1990. </year>
Reference-contexts: They are particularly tailored to use a linear data stream. These properties make text compression applicable to computer programs. Text compression methods fall into two general categories: statistical and dictionary <ref> [Bell90] </ref>. Statistical compression uses the frequency of singleton characters to choose the size of the codewords that will replace them. Frequent characters are encoded using shorter codewords so that the overall length of the compressed text is minimized. Huffman encoding of text is a well-known example. <p> It can be shown that for every dictionary method there is an equivalent statistical method which achieves equal compression and can be improved upon to give better compression <ref> [Bell90] </ref>. Thus statistical methods can always achieve better compression than dictionary methods albeit at the expense of additional computation requirements for decompression. It should be noted, however, that dictionary compression yields good results in systems with memory and time constraints because one entry expands to several characters.
Reference: [Benes97] <author> M. Benes, A. Wolfe, S. M. Nowick, </author> <title> A High-Speed Asynchronous Decompression Circuit for Embedded Processors, </title> <booktitle> Proceedings of the 17th Conference on Advanced Research in VLSI, </booktitle> <month> September </month> <year> 1997. </year>
Reference-contexts: The LAT limits compressed programs to only execute on processors that have the same line size for which they were compiled. The authors report a 73% compression ratio for MIPS instructions. A working demonstration of CCRP has been completed <ref> [Benes97] </ref>.
Reference: [Bird96] <author> P. Bird and T. Mudge, </author> <title> An Instruction Stream Compression Technique, </title> <type> Technical report CSE-TR-319-96, </type> <institution> EECS Department, University of Michigan, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: Figure 3.1 illustrates the relationship between the uncompressed code, the compressed code, and the dictionary. A complete description of our compression method is presented in Figure 3. 3.2.1 Algorithm Our compression method is based on the technique introduced in <ref> [Bird96, Chen97b] </ref>. A dictionary compression algorithm is applied after the compiler has generated the program. We search the program object modules to find common sequences of instructions to place in the dictionary. Our algorithm has 3 parts: 1. Building the dictionary 2. Replacing instruction sequences with codewords 3.
Reference: [Chen97a] <author> I. Chen, P. Bird, and T. Mudge, </author> <title> The Impact of Instruction Compression on I-cache Performance, </title> <type> Technical report CSE-TR-330-97, </type> <institution> EECS Department, University of Michigan, </institution> <year> 1997. </year>
Reference-contexts: This problem is exacerbated by the growing gap between the cycle time of microprocessors and the access time of commodity DRAM. Reducing program size is one way to reduce instruction cache misses and provide higher instruction bandwidth <ref> [Chen97a] </ref>. Our contribution Both low-cost embedded systems and high-performance microprocessors can benefit from small program sizes. This thesis proposal focuses on program representations of embedded applications, where execution speed can be traded for code size. <p> These candidates will be added at the MIRV IR level as functions called with the appropriate arguments. All backends for the MIRV compiler will be able to use this code reducing technique. 4.6 Improving execution-time Compressed programs use less memory and can result in fewer instruction cache misses <ref> [Chen97a] </ref>. If the reduction of instruction cache misses offsets the extra decoding time for compressed instructions, then there will be a performance improvement. Therefore, we plan to measure the effects of our program representations on the instruction cache.
Reference: [Chen97b] <author> I. Chen, </author> <title> Enhancing Instruction Fetching Mechanism Using Data Compression, </title> <type> Ph.D. Dissertation, </type> <institution> University of Michigan, </institution> <year> 1997. </year>
Reference-contexts: Figure 3.1 illustrates the relationship between the uncompressed code, the compressed code, and the dictionary. A complete description of our compression method is presented in Figure 3. 3.2.1 Algorithm Our compression method is based on the technique introduced in <ref> [Bird96, Chen97b] </ref>. A dictionary compression algorithm is applied after the compiler has generated the program. We search the program object modules to find common sequences of instructions to place in the dictionary. Our algorithm has 3 parts: 1. Building the dictionary 2. Replacing instruction sequences with codewords 3.
Reference: [Ernst97] <author> J. Ernst, W. Evans, C. W. Fraser, S. Lucco, and T. A. Proebsting, </author> <title> Code compression, </title> <booktitle> Proceedings of the ACM SIGPLAN97 Conference on Programming Language Design and Implementation (PLDI), </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: The overhead for this interpreter is only 4-8 KB. Fraser showed that this compression method is able to reduce the size of programs by half when compared to SPARC representation. However, the programs execute 20 times slower than the original SPARC representations. 2.2.3 BRISC Ernst et al. <ref> [Ernst97] </ref> developed BRISC which is an interpretable compressed program format for the Omniware virtual machine (OmniVM). BRISC adds macro-instructions to the OmniVM RISC instruction set. BRISC achieves small code size by replacing repeated sequences of instructions in the OmniVM RISC code with a byte codeword that refers to a macro-instruction. <p> There is no program size benefit at run-time because a full size native binary must be created to run the program. The only size benefit is during the time the program is stored on disk or being transmitted over a network. 2.5.2 Wire Codes Ernst et al. <ref> [Ernst97] </ref> also introduced an encoding scheme that is suitable for transmitting programs over networks. The authors compress the abstract syntax tree of the program in the following manner. First, the tree is linearized and split into separate streams of operators and literal operands. <p> Therefore, sequence C is not compressed. Assuming that codewords are each 2 bytes long, then the size of the code and dictionary is 44 bytes. This saves 16 bytes over the original code. Ernst et al. <ref> [Ernst97] </ref> do code compression by using codewords that represent sequences of instructions. The sequences are actually templates that specify the operation to be performed, but some register and immediate values may not be specified. <p> Template compression works well for large patterns that have very few varying inputs. 4.3 A template compression compiler Template compression has been used as a means of compressing programs after the code generation step of the compiler <ref> [Ernst97] </ref>. Their code generator does not purposefully create code sequences that are suitable for a template representation. We propose to do template compression inside the compiler and let the compiler directly generate code for a compression based instruction set. <p> We are also interested in exploring compression options that do not require hardware modification. This would allow com pression to be widely applicable to available microprocessors. Some studies have already borrowed the concept of procedure abstraction <ref> [Fraser95, Liao95, Ernst97, Lefurgy97] </ref>. However, these previous attempts limited the size of the abstracted procedures to a few 39 instructions or single basic blocks. We are not aware of any study that has measured the applicability of procedure abstraction on a larger level.
Reference: [Flynn83] <author> M. J. Flynn and L. W. Hoevel, </author> <title> Execution Architecture: The DELtran Experiment, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. C-32, No. 2, </volume> <month> Feb-ruary </month> <year> 1983. </year>
Reference-contexts: For example, Thumb code runs 15% - 20% slower on systems with ideal instruction memories (32-bit buses and no wait states) [ARM95]. 2.2 Interpreted programs 2.2.1 Directly Executed Languages Flynn introduced the notion of Directly Executed Languages (DELs) whose representation could be specifically tailored to a particular application and language <ref> [Flynn83] </ref>. A DEL is program representation that is between the level of the source language and machine language. DEL programs are executed by a DEL-interpreter which is written in the machine language. The advantage of DELs are that they provide an efficient method to represent programs.
Reference: [Franz94] <author> M. Franz, </author> <title> Code-Generation On-the-Fly: A Key for Portable Software, </title> <type> PhD dissertation, </type> <institution> Institute for Computer Systems, ETH Zurich, </institution> <year> 1994. </year>
Reference-contexts: Their compression results are based on benchmarks compiled for the Texas Instruments TMS320C25 DSP. 2.5 Load-time representations 2.5.1 Slim Binaries Franz and Kistler developed a machine-independent distribution format called slim binaries <ref> [Franz94, Franz97] </ref>. The slim binary format is a compressed version of the abstract syntax tree (AST) in the compiler. The compression is done by using a dictionary of sub-trees previously seen in the AST. When the program is run, the loader reads the slim binary and generates native code on-the-y.
Reference: [Franz97] <author> M. Franz and T. Kistler, </author> <title> Slim binaries, </title> <journal> Communications of the ACM, </journal> <volume> 40(12):8794, </volume> <month> December </month> <year> 1997. </year>
Reference-contexts: Their compression results are based on benchmarks compiled for the Texas Instruments TMS320C25 DSP. 2.5 Load-time representations 2.5.1 Slim Binaries Franz and Kistler developed a machine-independent distribution format called slim binaries <ref> [Franz94, Franz97] </ref>. The slim binary format is a compressed version of the abstract syntax tree (AST) in the compiler. The compression is done by using a dictionary of sub-trees previously seen in the AST. When the program is run, the loader reads the slim binary and generates native code on-the-y. <p> The time for code-generation is partially hidden because it can be done at the same time that the program is being loaded. Franz and Kistler have reported that loading and generating code for a slim binary is nearly as fast as loading a native binary <ref> [Franz97] </ref>. 13 Even though the slim binary format represents programs in a very small format (smaller than 1/3 the size of a PowerPC binary), this size does not include the cost of the code generator.
Reference: [Fraser84] <author> C. W. Fraser, E. W. Myers, A. L. Wendt, </author> <title> Analyzing and Compressing Assembly Code, </title> <booktitle> Proceedings of the ACM SIGPLAN 84 Symposium on Compiler Construction, SIGPLAN Notices, </booktitle> <volume> Vol. 19, No. 6, </volume> <month> June </month> <year> 1984. </year>
Reference: [Fraser95] <author> C. W. Fraser, T. A. Proebsting, </author> <title> Custom Instruction Sets for Code Compression, unpublished, </title> <address> http://www.cs.arizona.edu/people/todd/papers/ pldi2.ps, </address> <month> October </month> <year> 1995. </year>
Reference-contexts: Flynn measured conventional machine language representations of programs and found them to be between 2.6 to 5.5 times larger than the DEL representation. N 2 log N 9 2.2.2 Custom instruction sets Whereas Flynn used the high level language as a basis for the operators in DELs, Fraser <ref> [Fraser95] </ref> used a bottom-up approach and created macro-instructions from instructions in the compiler intermediate representation (IR). He found repeating patterns in the IR tree and used these as macro-instructions in his compressed code. The code generator emits byte code which is interpreted when executed. <p> One way that we approach ideal representations using existing languages is to write procedures for the operations that the language cannot express. The procedures are built using the operators of the language. Procedurization methods <ref> [Standish76, Fraser95, Fraser97, Liao95] </ref> try to discover the appropriate functions to specify that will yield a space-efficient representation. They are useful in cases where the repetition in a program is not obvious to the programmer. <p> We hope these code transformations will lead to dictionaries with fewer, larger templates that can represent more code. Template compression has already been applied at the compiler IR level <ref> [Fraser95] </ref>. However, the size of templates was limited to 10 nodes in the LCC IR. <p> We are also interested in exploring compression options that do not require hardware modification. This would allow com pression to be widely applicable to available microprocessors. Some studies have already borrowed the concept of procedure abstraction <ref> [Fraser95, Liao95, Ernst97, Lefurgy97] </ref>. However, these previous attempts limited the size of the abstracted procedures to a few 39 instructions or single basic blocks. We are not aware of any study that has measured the applicability of procedure abstraction on a larger level. <p> Therefore, we plan to measure the effects of our program representations on the instruction cache. Many of the program representations that we reviewed obtained smaller programs at the cost of execution speed. Some previous studies <ref> [ARM95, Fraser95, Liao95] </ref> have proposed to balance this trade-off by only applying their representations to the portions of the program that are not frequently executed. This allows the highly executed parts of the program to proceed at the usual execution speed.
Reference: [Kirovski97] <author> D. Kirovski, J. Kin, and W. H. Mangione-Smith, </author> <title> Procedure Based Program Compression, </title> <booktitle> Proceedings of the 30th Annual International Symposium on Microarchitecture, </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: If the size of the interpreter is small enough so that the interpreter and the BRISC program are smaller than a native version of the program, then this system could be useful for achieving small code size in embedded systems. 10 2.3 Frequency-based coding 2.3.1 Procedure Compression Kirovski et al. <ref> [Kirovski97] </ref> describes a compression method that works at the granularity of procedures. Each procedure in the program is compressed using a Ziv-Lem-pel compression algorithm. A segment of memory is reserved as a procedure cache for decompressed procedures.
Reference: [Kissell97] <author> K. Kissell, MIPS16: </author> <title> High-density MIPS for the Embedded Market, </title> <type> 42 Technical report, </type> <institution> Silicon Graphics MIPS Group, </institution> <year> 1997. </year>
Reference-contexts: Thumb [ARM95, Turley95] and MIPS-16 <ref> [Kissell97] </ref> are two recently proposed instruction set modifications which define reduced instruction word sizes in an effort to reduce the overall size of compiled programs. Thumb and MIPS-16 are defined as subsets of the ARM and MIPS-III architectures. <p> The original 32-bit wide instructions have been re-encoded to be 16-bits wide. Thumb and MIPS-16 are reported to achieve code reductions of 30% and 40%, respectively <ref> [ARM95, Kissell97] </ref>. Thumb and MIPS-16 instructions have a one-to-one correspondence to instructions in the base architectures. In each case, a 16-bit instruction is fetched from the instruction memory, decoded to the equivalent 32-bit wide instruction, and passed to the base processor core for execution.
Reference: [Kozuch94] <author> M. Kozuch and A. Wolfe, </author> <title> Compression of Embedded System Programs, </title> <booktitle> IEEE International Conference on Computer Design, </booktitle> <year> 1994. </year>
Reference-contexts: One appealing point of this technique is that it can use existing instruction sets and be implemented with minimal hardware support (an on-chip RAM for the procedure cache). 2.3.2 Compressed Code RISC Processor The Compressed Code RISC Processor (CCRP) <ref> [Wolfe92, Kozuch94] </ref> is an interesting approach that employs an instruction cache that is modified to run compressed programs. At compile-time, the cache line bytes are Huffman encoded. <p> Although there is a higher decode penalty for using variable-length codewords, they make possible better compression. By restricting the codewords to integer multiples of 4 bits, we still retain some of the decoding process regularity that the 1-bit aligned Huffman encoding in <ref> [Kozuch94] </ref> lacks. Our choice of encoding is based on CINT95 benchmarks. We present only the best encoding choice we have discovered. We use codewords that are 8-bits, 12-bits, and 16-bits in length. Other programs may benefit from different encodings. <p> Our approach combines elements of two previous proposals. First we use a dictionary compression method (as in [Liao95]) that allows codewords to expand to several instructions. Second, we allow the codewords to be smaller than a single instruction (as in <ref> [Kozuch94] </ref>). We find that the size of the dictionary is the single most important parameter in attaining a better compression ratio. The second most important factor is reducing the codeword size below the size of a single instruction.
Reference: [Lefurgy97] <author> C. Lefurgy, P. Bird, I.-C. Chen, and T. Mudge, </author> <title> Improving code density using compression techniques, </title> <booktitle> Proceedings of the 30th Annual International Symposium on Microarchitecture, </booktitle> <month> December </month> <year> 1997. </year>
Reference-contexts: We are also interested in exploring compression options that do not require hardware modification. This would allow com pression to be widely applicable to available microprocessors. Some studies have already borrowed the concept of procedure abstraction <ref> [Fraser95, Liao95, Ernst97, Lefurgy97] </ref>. However, these previous attempts limited the size of the abstracted procedures to a few 39 instructions or single basic blocks. We are not aware of any study that has measured the applicability of procedure abstraction on a larger level.
Reference: [Liao95] <author> S. Liao, S. Devadas, K. Keutzer, </author> <title> Code Density Optimization for Embedded DSP Processors Using Data Compression Techniques, </title> <booktitle> Proceedings of the 15th Conference on Advanced Research in VLSI, </booktitle> <month> March </month> <year> 1995. </year>
Reference-contexts: Sequences of code that are identical, except for the values used, can be bound to the same abstracted function and supplied with arguments for the appropriate values. 2.4.2 Mini-subroutines Liao et al. propose a software method for supporting compressed code <ref> [Liao95, Liao96] </ref>. They find mini-subroutines which are common sequences of instructions in the program. Each instance of a mini-subroutine is removed from the program and replaced with a call instruction. The mini-subroutine is placed once in the text of the program and ends with a return instruction. <p> One way that we approach ideal representations using existing languages is to write procedures for the operations that the language cannot express. The procedures are built using the operators of the language. Procedurization methods <ref> [Standish76, Fraser95, Fraser97, Liao95] </ref> try to discover the appropriate functions to specify that will yield a space-efficient representation. They are useful in cases where the repetition in a program is not obvious to the programmer. <p> It is interesting to consider what improvements might be seen if the LZ coding algorithms accounted for the width of fields in instructions. 15 Chapter 3 Preliminary Work 3.1 Introduction This chapter details an experiment to analyze one method of compression. We start with a method similar to <ref> [Liao95] </ref>. We find common sequences of native instructions in object code and replace them with a codeword. We extend this work by considering the advantages from using smaller instruction (codeword) sizes. In [Liao95], the call-dictionary instruction is considered to be the size of 1 or 2 instruction words. <p> We start with a method similar to <ref> [Liao95] </ref>. We find common sequences of native instructions in object code and replace them with a codeword. We extend this work by considering the advantages from using smaller instruction (codeword) sizes. In [Liao95], the call-dictionary instruction is considered to be the size of 1 or 2 instruction words. This requires the dictionary to contain sequences with at least 2 or 3 instructions, respectively, since shorter sequences would be no bigger than the call-dictionary instruction and no compression would result. <p> Therefore, we can always obtain a program smaller than the MIPS-16 version. 3.4 Discussion We have proposed a method of compressing programs for embedded microprocessors where program size is limited. Our approach combines elements of two previous proposals. First we use a dictionary compression method (as in <ref> [Liao95] </ref>) that allows codewords to expand to several instructions. Second, we allow the codewords to be smaller than a single instruction (as in [Kozuch94]). We find that the size of the dictionary is the single most important parameter in attaining a better compression ratio. <p> We are also interested in exploring compression options that do not require hardware modification. This would allow com pression to be widely applicable to available microprocessors. Some studies have already borrowed the concept of procedure abstraction <ref> [Fraser95, Liao95, Ernst97, Lefurgy97] </ref>. However, these previous attempts limited the size of the abstracted procedures to a few 39 instructions or single basic blocks. We are not aware of any study that has measured the applicability of procedure abstraction on a larger level. <p> Therefore, we plan to measure the effects of our program representations on the instruction cache. Many of the program representations that we reviewed obtained smaller programs at the cost of execution speed. Some previous studies <ref> [ARM95, Fraser95, Liao95] </ref> have proposed to balance this trade-off by only applying their representations to the portions of the program that are not frequently executed. This allows the highly executed parts of the program to proceed at the usual execution speed.
Reference: [Liao96] <author> S. Liao, </author> <title> Code Generation and Optimization for Embedded Digital Signal Processors, </title> <type> Ph.D. Dissertation, </type> <institution> Massachusetts Institute of Technology, </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: Sequences of code that are identical, except for the values used, can be bound to the same abstracted function and supplied with arguments for the appropriate values. 2.4.2 Mini-subroutines Liao et al. propose a software method for supporting compressed code <ref> [Liao95, Liao96] </ref>. They find mini-subroutines which are common sequences of instructions in the program. Each instance of a mini-subroutine is removed from the program and replaced with a call instruction. The mini-subroutine is placed once in the text of the program and ends with a return instruction. <p> Figure 3.7 shows which dictionary entries contribute the most to compression. Dic tionary entries with 1 instruction achieve between 46% and 60% of the compression savings. The short entries contribute to a larger portion of the savings as the size of the dic tionary increases. The compression method in <ref> [Liao96] </ref> cannot take advantage of this since the codewords are the size of single instructions, so single instructions are not com pressed.
Reference: [MPR95] <institution> Thumb Squeezes ARM Code Size, </institution> <type> Microprocessor Report 9(4), </type> <month> 27 March </month> <year> 1995. </year>
Reference: [Perl96] <author> S. Perl and R. </author> <title> Sites, Studies of Windows NT Performance Using Dynamic Execution Traces, </title> <booktitle> Proceedings of the USENIX 2nd Symposium on Operating Systems Design and Implementation, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: Thus, the ability to compile programs to a small representation is important to reduce both software development costs and manufacturing costs. High performance systems are also impacted by program size due to the delays incurred by instruction cache misses. A study at Digital <ref> [Perl96] </ref> measured the performance of an SQL server on a DEC 21064 Alpha. Due to instruction cache misses, the application could have used twice as much instruction bandwidth as the processor was able to provide.
Reference: [Sodani97] <author> A. Sodani and G. S. Sohi, </author> <title> Dynamic Instruction Reuse, </title> <booktitle> Proceedings of the 24th Annual International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: Function memoization is a code optimization that caches the results of recent function invocations. The next time that the function is called with the same arguments, the result can be quickly provided from the cache instead of computing it [Abelson85]. Sodani <ref> [Sodani97] </ref> presents a method of improving execution time by memoizing individual machine instructions. He keeps the results of instruction execution in a table and uses these results if the instructions are encountered again with the same source values.
Reference: [SPEC95] <institution> SPEC CPU95, </institution> <note> Technical Manual, </note> <month> August </month> <year> 1995. </year>
Reference-contexts: Indeed, we found that a small number of instruction encodings are highly reused in most programs. To illustrate the repetition of instruction encodings, we profiled the SPEC CINT95 benchmarks <ref> [SPEC95] </ref>. The benchmarks were compiled for PowerPC with GCC 2.7.2 using -O2 optimization.
Reference: [Standish76] <author> T. A. Standish, D. C. Harriman, D. F. Kibler, and J. M. Neighbors, </author> <title> The Irvine Program Transformation Catalogue, </title> <institution> Department of Information and Computer Science, University of California, Irvine, </institution> <month> January </month> <year> 1976. </year>
Reference-contexts: The authors report a 73% compression ratio for MIPS instructions. A working demonstration of CCRP has been completed [Benes97]. Implemented in 0.8m CMOS, it occupies 0.75 mm 2 , and can decompress 560 Mbit/s. 2.4 Procedurization 2.4.1 Procedure abstraction Procedure abstraction <ref> [Standish76] </ref> is a program optimization for procedure oriented languages that replaces repeated sequences of common code with function calls to a single function that performs the required computation. This is an optimization that the programmer can apply to the source language. <p> One way that we approach ideal representations using existing languages is to write procedures for the operations that the language cannot express. The procedures are built using the operators of the language. Procedurization methods <ref> [Standish76, Fraser95, Fraser97, Liao95] </ref> try to discover the appropriate functions to specify that will yield a space-efficient representation. They are useful in cases where the repetition in a program is not obvious to the programmer.
Reference: [Storer77] <author> J. Storer, </author> <title> NP-completeness Results Concerning Data Compression, </title> <type> Technical report 234, </type> <institution> Department of Electrical Engineering and Computer Science, Princeton University, </institution> <year> 1977. </year>
Reference-contexts: Our algorithm has 3 parts: 1. Building the dictionary 2. Replacing instruction sequences with codewords 3. Encoding codewords Building the dictionary For an arbitrary text, choosing those entries of a dictionary that achieve maximum compression is NP-complete in the size of the text <ref> [Storer77] </ref>. As with most dictionary methods, we use a greedy algorithm to quickly determine the dictionary entries. On every iteration of the algorithm, we examine each potential dictionary entry and find the one that results in the largest immediate savings.
Reference: [Szymanski78] <author> T. G. Szymanski, </author> <title> Assembling code for machines with span-dependent instructions, </title> <journal> Communications of the ACM 21:4, </journal> <pages> pp. 300-308, </pages> <month> April </month> <year> 1978. </year>
Reference-contexts: If we allowed compression of relative branches, we might need to rewrite codewords representing relative branches after a compression pass; but this would affect relative branch targets thus requiring a rewrite of codewords, etc. The result is again an NP-complete problem <ref> [Szymanski78] </ref>. Indirect branches are compressed in our study. Since these branches take their target from a register, the branch instruction itself does not need to be patched after compression, so it cannot create the codeword rewriting problem outlined above.
Reference: [Turley95] <author> J. L. Turley. </author> <title> Thumb squeezes arm code size. </title> <type> Microprocessor Report, 9(4), </type> <month> 27 March </month> <year> 1995. </year>
Reference-contexts: Thumb <ref> [ARM95, Turley95] </ref> and MIPS-16 [Kissell97] are two recently proposed instruction set modifications which define reduced instruction word sizes in an effort to reduce the overall size of compiled programs. Thumb and MIPS-16 are defined as subsets of the ARM and MIPS-III architectures.
Reference: [Wolfe92] <author> A. Wolfe and A. Chanin, </author> <title> Executing Compressed Programs on an Embedded RISC Architecture, </title> <booktitle> Proceedings of the 25th Annual International Symposium on Microarchitecture, </booktitle> <month> December </month> <year> 1992. </year>
Reference-contexts: One appealing point of this technique is that it can use existing instruction sets and be implemented with minimal hardware support (an on-chip RAM for the procedure cache). 2.3.2 Compressed Code RISC Processor The Compressed Code RISC Processor (CCRP) <ref> [Wolfe92, Kozuch94] </ref> is an interesting approach that employs an instruction cache that is modified to run compressed programs. At compile-time, the cache line bytes are Huffman encoded. <p> This token is replaced with an efficient encoding in the encoding step. Encoding codewords Encoding refers to the representation of the codewords in the compressed program. As discussed in Section 2.3.2, variable-length codewords, (such as those used in the Huff man encoding in <ref> [Wolfe92] </ref>) are expensive to decode. A fixed-length codeword, on the other hand, can be used directly as an index into the dictionary making decoding a simple table lookup operation. Our baseline compression method uses a fixed-length codeword to enable fast decoding. We also investigate a variable-length scheme.
References-found: 28

