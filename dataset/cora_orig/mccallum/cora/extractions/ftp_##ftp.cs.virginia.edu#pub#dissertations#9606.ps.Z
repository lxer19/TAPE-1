URL: ftp://ftp.cs.virginia.edu/pub/dissertations/9606.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/dissertations/README.html
Root-URL: http://www.cs.virginia.edu
Title: A Dissertation  On the Acceleration of Simulated Annealing  
Author: James M. Varanelli 
Degree: Presented to the Faculty of the School of Engineering and Applied Science at the University of Virginia In Partial Fulfillment of the Requirements for the Degree Doctor of Philosophy (Computer Science)  
Date: May, 1996  
Note: by  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> E.H.L Aarts and P.J.M. van Laarhoven, </author> <title> A New Polynomial-Time Cooling Schedule, </title> <booktitle> Proc. IEEE ICCAD-85, </booktitle> <address> Santa Clara, CA, 206-208, </address> <year> 1985. </year>
Reference-contexts: As mentioned previously, crossover simulates the recombination of the genetic material of the two selected parents in the resulting offspring. Holland introduces a method called single-point crossover [45]. Assuming a string length l, single-point crossover chooses an integer k uniformly at random in the range <ref> [1, l - 1] </ref>. Two new offspring are created by first copying the characters in bit positions 1 to k of each parent string to each respective offspring. <p> It should be noted that the SGA does not require crossover to occur between two selected parent strings. Holland specifies that crossover only occur between two selected strings if a random number over the range <ref> [0, 1] </ref> is less than some specified parameter p c , called the crossover rate [45]. 1001110 crossover point 1001110110 Parent Strings Offspring 101 87 If the random number is greater than p c , then crossover is not performed.
Reference: [2] <author> E.H.L. Aarts, F.M.J. de Bont, E.H.A. Habers, and P.J.M. van Laarhoven, </author> <title> Parallel Implementations of the Statistical Cooling Algorithm, </title> <journal> Integration, </journal> <volume> vol. 4, </volume> <pages> 209-238, </pages> <year> 1986. </year>
Reference-contexts: introduction of errors into the cost calculations. An interesting characteristic of the parallel moves approach is its changing performance at different temperatures <ref> [2, 4, 49, 50, 58, 87, 103] </ref>. The speedup factor is much higher at the low temperatures when using a parallel moves approach. This is the direct result of the dynamic nature of the solution acceptance probabilities at different temperatures of the employed annealing schedule. <p> However, as the temperature is lowered, the solution acceptance probabilities decrease to the point where almost no solution transitions are accepted. This corresponds to an almost 1:1 speedup with the number of available processors for both the exact and chaotic schemes, due to the extremely low communications requirements <ref> [2, 4, 49, 50, 58, 87, 103] </ref>. In addition, temporary errors in chaotic methods are shown to vanish at the low temperatures, again due to the lack of solution acceptances [4, 8, 50, 58]. <p> An application-independent parallel implementation is appealing due to the fact that applicability to a wide range of problems is a major advantage of the sequential version of the algorithm. Only a few researchers have focused on truly application-independent parallel implementations of the SA paradigm <ref> [2, 50, 58, 86, 103] </ref>. 82 4.2 Genetic Algorithms As seen in Section 4.1, the parallelization of SA has been largely unsuccessful. An application-independent parallel implementation that is both efficient in its parallelization and scalable to massively parallel architectures has yet to be demonstrated in the literature.
Reference: [3] <author> E.H.L. Aarts, J.H.M. Korst, and P.J.M. van Laarhoven, </author> <title> Solving Traveling Salesman Problems by Simulated Annealing, </title> <journal> J. Stat. Phys., </journal> <volume> vol. 50, </volume> <pages> 187-206, </pages> <year> 1988. </year>
Reference: [4] <author> R. Azencott, Ed., </author> <title> Simulated Annealing: Parallelization Techniques, </title> <publisher> John Wiley and Sons, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference-contexts: introduction of errors into the cost calculations. An interesting characteristic of the parallel moves approach is its changing performance at different temperatures <ref> [2, 4, 49, 50, 58, 87, 103] </ref>. The speedup factor is much higher at the low temperatures when using a parallel moves approach. This is the direct result of the dynamic nature of the solution acceptance probabilities at different temperatures of the employed annealing schedule. <p> This communications overhead is lessened slightly by a chaotic approach, but at the cost of introduced errors. In addition, studies indicate that the relative size of the errors for chaotic parallel moves increases at the higher temperatures <ref> [4, 12, 50, 58] </ref>. However, as the temperature is lowered, the solution acceptance probabilities decrease to the point where almost no solution transitions are accepted. <p> However, as the temperature is lowered, the solution acceptance probabilities decrease to the point where almost no solution transitions are accepted. This corresponds to an almost 1:1 speedup with the number of available processors for both the exact and chaotic schemes, due to the extremely low communications requirements <ref> [2, 4, 49, 50, 58, 87, 103] </ref>. In addition, temporary errors in chaotic methods are shown to vanish at the low temperatures, again due to the lack of solution acceptances [4, 8, 50, 58]. <p> In addition, temporary errors in chaotic methods are shown to vanish at the low temperatures, again due to the lack of solution acceptances <ref> [4, 8, 50, 58] </ref>. As a result, chaotic parallel moves schemes are generally shown experimentally to have similar convergence characteristics as the sequential SA algorithm, but this cannot be guaranteed in the general case since its validity has turned out to be difficult to prove [4, 8, 50, 58]. <p> the lack of solution acceptances <ref> [4, 8, 50, 58] </ref>. As a result, chaotic parallel moves schemes are generally shown experimentally to have similar convergence characteristics as the sequential SA algorithm, but this cannot be guaranteed in the general case since its validity has turned out to be difficult to prove [4, 8, 50, 58]. A parallel moves approach, independent of any type of move decomposition, is an application-independent way to parallelize the SA paradigm.
Reference: [5] <author> L.J. Bain and M. Englehardt, </author> <title> Introduction to Probability and Mathematical Statistics, </title> <publisher> Dux-bury Press, </publisher> <address> Belmont, CA, </address> <year> 1992. </year>
Reference: [6] <author> S. Bapat and J.P. Cohoon, </author> <title> Sharp-Looking Partitioning, </title> <booktitle> Proc. 2nd IEEE EDAC, </booktitle> <address> Amster-dam, Netherlands, 172-176, </address> <year> 1991. </year>
Reference: [7] <author> W.H. Beyer, Ed., </author> <title> CRC Standard Mathematical Tables and Formulae, </title> <publisher> CRC Press, </publisher> <address> Boca Raton, FL, </address> <year> 1992. </year>
Reference: [8] <author> R. Bianchini and C.M. Brown, </author> <title> Parallel Genetic Algorithms on Distributed-Memory Architectures, </title> <booktitle> Proc. Sixth Conf. North American Transputer Users Group, </booktitle> <address> Vancouver, Canada, 67-82, </address> <year> 1993. </year>
Reference-contexts: In addition, temporary errors in chaotic methods are shown to vanish at the low temperatures, again due to the lack of solution acceptances <ref> [4, 8, 50, 58] </ref>. As a result, chaotic parallel moves schemes are generally shown experimentally to have similar convergence characteristics as the sequential SA algorithm, but this cannot be guaranteed in the general case since its validity has turned out to be difficult to prove [4, 8, 50, 58]. <p> the lack of solution acceptances <ref> [4, 8, 50, 58] </ref>. As a result, chaotic parallel moves schemes are generally shown experimentally to have similar convergence characteristics as the sequential SA algorithm, but this cannot be guaranteed in the general case since its validity has turned out to be difficult to prove [4, 8, 50, 58]. A parallel moves approach, independent of any type of move decomposition, is an application-independent way to parallelize the SA paradigm. <p> The population distribution method commonly used by researchers utilizing GAs on distributed architectures is typically some subspeciation technique, in which each processor independently evolves a subpopulation of strings <ref> [8, 15, 16, 17, 23, 33] </ref>. Since larger populations tend to produce better GA solution quality through improved diversity, all of these population distribution schemes involve some mechanism for the migration of solutions between processors. <p> This is the approach taken in the distributed versions of the proposed POSA heuristic. An important aspect in the distribution of the population is the amount of centralization employed <ref> [8] </ref>. A maximally-centralized distributed GA has the entire population managed by a master process, simply sending pairs of solutions to each of the auxiliary processors for the application of the genetic operators. <p> A minimally-centralized distributed GA is one in which the population is evenly distributed amongst the available processors with no migration of solutions between processors during evolution. Bianchini and Brown <ref> [8] </ref> present an experimental study of distributed GAs finding that a more centralized population can produce better quality solutions than a more distributed population given an equal number of GA generations. However, the trade-off is clear.
Reference: [9] <author> K.D. Boese and A.B. Kahng, </author> <title> Best-So-far vs. Where-You-Are: Implications for Optimal Finite-Time Annealing, </title> <journal> Sys. and Control Letters, </journal> <volume> vol. 22, </volume> <pages> 71-78, </pages> <year> 1994. </year>
Reference: [10] <author> T. Boseniuk and W. Ebeling, Boltzmann-, Darwin-, </author> <title> and Haeckel-Strategies in Optimization Problems, </title> <booktitle> Lecture Notes in Comp. Sci.: Parallel Prob. Solving from Nature, </booktitle> <volume> vol. 496, </volume> <pages> 430-444, </pages> <year> 1991. </year>
Reference-contexts: They follow crossover and mutation with a conceptually simple greedy neighborhood operator. In both cases, convergence times are much reduced in the case of the hybrid systems. The introduction of hybrid genetic systems has led a number of researchers to propose SA/ GA hybrids <ref> [10, 11, 34, 66, 71, 92, 98] </ref>. The main purpose for this type of system is two-fold. First, it allows for a simple and efficient alternative parallelization of SA, which as pointed out in Section 4.1 is a major drawback of the traditional SA algorithm. <p> Recently, researchers have been investigating hybrid algorithms that attempt to mix GA and SA techniques in an attempt to combine the respective advantages of the two paradigms, namely the convergence control of SA and the efficient par-allelization of the GA <ref> [10, 11, 34, 66, 71, 92, 98] </ref>. In this section we present previous related work with SA/GA hybrids. Some of the earliest work done in the area of SA/GA hybrids is that of Sirag and Weisser [92]. <p> The proposed algorithm is also tested on three TSPs from the literature to confirm its performance. The proposed algorithm was on average able to find solutions with cost only 0-3% above optimal. Boseniuk and Ebeling <ref> [10] </ref> compare three different parallel SA/GA hybrid approaches for 99 solving the TSP. The first of these methods is a very simple GA running several copies of SA in parallel.
Reference: [11] <author> D.E. Brown, C.L. Huntley, and A.R. Spillane, </author> <title> A Parallel Genetic Heuristic for the Quadratic Assignment Problem, </title> <booktitle> Proc. Third Int. Conf. Genetic Algs.and Their Apps. </booktitle> , <address> Fairfax, VA, </address> <month> 127 </month>
Reference-contexts: They follow crossover and mutation with a conceptually simple greedy neighborhood operator. In both cases, convergence times are much reduced in the case of the hybrid systems. The introduction of hybrid genetic systems has led a number of researchers to propose SA/ GA hybrids <ref> [10, 11, 34, 66, 71, 92, 98] </ref>. The main purpose for this type of system is two-fold. First, it allows for a simple and efficient alternative parallelization of SA, which as pointed out in Section 4.1 is a major drawback of the traditional SA algorithm. <p> Recently, researchers have been investigating hybrid algorithms that attempt to mix GA and SA techniques in an attempt to combine the respective advantages of the two paradigms, namely the convergence control of SA and the efficient par-allelization of the GA <ref> [10, 11, 34, 66, 71, 92, 98] </ref>. In this section we present previous related work with SA/GA hybrids. Some of the earliest work done in the area of SA/GA hybrids is that of Sirag and Weisser [92]. <p> In addition, the authors found that they were able to reduce the population size significantly without affecting convergence performance [92]. Brown, Huntley, and Spillane <ref> [11] </ref> introduce a parallel SA/GA hybrid system for solving the quadratic assignment problem (QAP). Their hybrid is a GA that uses low-temperature SA as a local search procedure. The GA uses non-standard variations of the traditional genetic operators. The selection scheme is rank-based. <p> The assumption behind such 29046 crossover point 2904651873 Parent Strings Offspring 35718 98 rank-based selection methods is that the additional overhead of maintaining a sorted list is typically counterbalanced by the increased greediness of the GA <ref> [11] </ref>. The crossover operator is similar to the PMX operator of Grefenstette [23], an extension of the inversion operator of Holland [45] originally proposed for permutation problems such as the QAP.
Reference: [12] <author> A. Casotto, F. Romeo, and A. Sangiovanni-Vincentelli, </author> <title> A Parallel Simulated Annealing Algorithm for the Placement of Macro-Cells, </title> <journal> IEEE Trans. CADICS, </journal> <volume> vol. 6, </volume> <pages> 838-847, </pages> <year> 1987. </year>
Reference-contexts: This communications overhead is lessened slightly by a chaotic approach, but at the cost of introduced errors. In addition, studies indicate that the relative size of the errors for chaotic parallel moves increases at the higher temperatures <ref> [4, 12, 50, 58] </ref>. However, as the temperature is lowered, the solution acceptance probabilities decrease to the point where almost no solution transitions are accepted.
Reference: [13] <author> A. Casotto and A. Sangiovanni-Vincentelli, </author> <title> Placement of Standard Cells Using Simulated Annealing on the Connection Machine, </title> <booktitle> Proc. IEEE ICCD, </booktitle> <pages> 350-353, </pages> <year> 1987. </year>
Reference: [14] <author> V. Cerny, </author> <title> Thermodynamical Approach to the Traveling Salesman Problem: An Efficient Simulation Algorithm, </title> <journal> J. Optimization Th. and Appl., </journal> <volume> vol. 45, </volume> <pages> 41-51, </pages> <year> 1985. </year>
Reference: [15] <author> J.P. Cohoon, S.U. Hegde, W.N. Martin, and D.S. Richards, </author> <title> Punctuated Equilibria: A Parallel Genetic Algorithm, </title> <booktitle> Proc. Second Int. Conf. Genetic Algs.and Their Apps., </booktitle> <address> Cambridge, MA, 148-154, </address> <year> 1987. </year>
Reference-contexts: As with SA, the GA exhibits elements of both randomization and local search. Likewise, it has proven to be quite effective for approximating global solutions to many types of NP-hard combinatorial problems, and indeed has been successfully applied to a number of VLSI design automation problems <ref> [15, 16, 17, 23, 33, 64, 81] </ref>. Section 4.2.1 introduces the terminology of genetic algorithms as inspired by the analogy with natural evolution. Section 4.2.2 introduces the original simple genetic algorithm of Holland [45]. <p> The population distribution method commonly used by researchers utilizing GAs on distributed architectures is typically some subspeciation technique, in which each processor independently evolves a subpopulation of strings <ref> [8, 15, 16, 17, 23, 33] </ref>. Since larger populations tend to produce better GA solution quality through improved diversity, all of these population distribution schemes involve some mechanism for the migration of solutions between processors.
Reference: [16] <author> J.P. Cohoon, W.N. Martin, and D.S. Richards, </author> <title> A Multi-Population Genetic Algorithm for Solving the K-Partition Problem on Hyper-cubes, </title> <booktitle> Proc. Fourth Int. Conf. Genetic Algs.and Their Apps., </booktitle> <address> San Diego, CA, 244-248, </address> <year> 1991. </year>
Reference-contexts: As with SA, the GA exhibits elements of both randomization and local search. Likewise, it has proven to be quite effective for approximating global solutions to many types of NP-hard combinatorial problems, and indeed has been successfully applied to a number of VLSI design automation problems <ref> [15, 16, 17, 23, 33, 64, 81] </ref>. Section 4.2.1 introduces the terminology of genetic algorithms as inspired by the analogy with natural evolution. Section 4.2.2 introduces the original simple genetic algorithm of Holland [45]. <p> The population distribution method commonly used by researchers utilizing GAs on distributed architectures is typically some subspeciation technique, in which each processor independently evolves a subpopulation of strings <ref> [8, 15, 16, 17, 23, 33] </ref>. Since larger populations tend to produce better GA solution quality through improved diversity, all of these population distribution schemes involve some mechanism for the migration of solutions between processors.
Reference: [17] <author> J.P. Cohoon, S.U. Hegde, W.N. Martin, and D.S. Richards, </author> <title> Distributed Genetic Algorithms for the Floorplan Design Problem, </title> <journal> IEEE Trans. CADICS, </journal> <volume> vol. 10, </volume> <pages> 483-492, </pages> <year> 1991. </year>
Reference-contexts: As with SA, the GA exhibits elements of both randomization and local search. Likewise, it has proven to be quite effective for approximating global solutions to many types of NP-hard combinatorial problems, and indeed has been successfully applied to a number of VLSI design automation problems <ref> [15, 16, 17, 23, 33, 64, 81] </ref>. Section 4.2.1 introduces the terminology of genetic algorithms as inspired by the analogy with natural evolution. Section 4.2.2 introduces the original simple genetic algorithm of Holland [45]. <p> The population distribution method commonly used by researchers utilizing GAs on distributed architectures is typically some subspeciation technique, in which each processor independently evolves a subpopulation of strings <ref> [8, 15, 16, 17, 23, 33] </ref>. Since larger populations tend to produce better GA solution quality through improved diversity, all of these population distribution schemes involve some mechanism for the migration of solutions between processors.
Reference: [18] <author> R.J. Collins and D.R. Jefferson, </author> <title> Selection in Massively Parallel Genetic Algorithms, </title> <booktitle> Proc. Fourth Int. Conf. Genetic Algs.and Their Apps., </booktitle> <address> San Diego, CA, 249-256, </address> <year> 1991. </year>
Reference: [19] <author> T.H. Cormen, C.E. Leiserson, and R.L. Rivest, </author> <title> Introduction to Algorithms, </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1990. </year>
Reference: [20] <author> G.A. Croes, </author> <title> A Method for Solving Traveling-Salesman Problems, </title> <journal> Operations Research, </journal> <volume> vol. 5, </volume> <pages> 791-812, </pages> <year> 1958. </year>
Reference: [21] <author> G.B. Dantzig, D.R. Fulkerson, and S.M. Johnson, </author> <title> Solution of a Large Scale Traveling-Salesman Problem, </title> <journal> Operations Research, </journal> <volume> vol. 2, </volume> <pages> 393-410, </pages> <year> 1954. </year>
Reference: [22] <author> F. Darema, S. Kirkpatrick, and V.A. Norton, </author> <title> Parallel Techniques for Chip Placement by Simulated Annealing, </title> <booktitle> Proc. IEEE ICCD, </booktitle> <pages> 87-90, </pages> <year> 1987. </year>
Reference: [23] <author> L. Davis, Ed., </author> <title> Genetic Algorithms and Simulated Annealing, </title> <publisher> Pitman Publishers, </publisher> <address> London, England, </address> <year> 1987. </year>
Reference-contexts: As with SA, the GA exhibits elements of both randomization and local search. Likewise, it has proven to be quite effective for approximating global solutions to many types of NP-hard combinatorial problems, and indeed has been successfully applied to a number of VLSI design automation problems <ref> [15, 16, 17, 23, 33, 64, 81] </ref>. Section 4.2.1 introduces the terminology of genetic algorithms as inspired by the analogy with natural evolution. Section 4.2.2 introduces the original simple genetic algorithm of Holland [45]. <p> Section 4.2.4 describes some improvements to the simple genetic algorithm that have been proposed in the recent literatureincluding hybrid genetic systemsmotivating the development of the thermodynamic/genetic hybrid optimization technique described in Chapter 5. 4.2.1 Terminology and the Natural Analogy The genetic algorithm (GA) was first introduced by Holland in 1975 <ref> [23, 33, 45] </ref>. It was intended to mimic the natural selection process for the purpose of solving optimization problems. Solutions to the optimization problem being solved represent individuals of a population of similarly structured solutions. <p> In nature, there is competition amongst members of a species for the resources necessary to survival. Only the fittest individuals tend to survive and reproduce so that their genetic material is propagated into the next generation <ref> [23, 33, 45] </ref>. In other words, the genes of the fittest individuals tend to survive into the next generation, while the genes of the weaker individuals tend to die out. Genes are propagated through reproduction. Reproduction combines the genes of two individuals. <p> In the GA, it is simply said that string positions may take on any value contained in the defining alphabet. For the GA, solutions are associated with a fitness value that is a quantitative measure of the comparative quality of the solution with the rest of the population <ref> [23, 33, 45] </ref>. The higher a solutions fitness value, the higher its chances of reproducing and passing its genes onto the next generation. The GA simulates genetic crossover through some string recombination operator after individuals have been selected and paired off for mating. <p> Obviously, there are many different options available for each of these parameters, and indeed many have been proposed in the literature. The next subsection presents the choices made by Holland in the design of the first genetic algorithm, often called the simple genetic algorithm (SGA) <ref> [23, 33, 45] </ref>. <p> The specific scheme used by Hollands SGA to implement proportionate selection is often referred to as roulette wheel selection <ref> [23, 33, 45] </ref>. Each string i in the population is allocated a sector on a circle of angular size 2pf i / m f , where f i is the fitness of solution i. <p> It has been noted in the literature that the number of offspring allocated to a 86 particular string using the roulette wheel selection scheme can deviate significantly from the expected number of offspring for smaller-sized populations <ref> [23, 33] </ref>. For this reason, many alternative selection schemes have been proposed. Holland then considers a crossover operator for the SGA. As mentioned previously, crossover simulates the recombination of the genetic material of the two selected parents in the resulting offspring. Holland introduces a method called single-point crossover [45]. <p> Hollands SGA specifies a generational replacement policy, in which the entire population is replaced during each generation [45]. Some later GA proposals in the literature advocate a steady-state replacement policy, in which only select individuals of the population are replaced by offspring during each generation <ref> [23, 33] </ref>. Holland next specifies the mutation operator for the SGA. He proposes what is called bitwise mutation [45]. <p> Bitwise mutation used as a neighborhood operator leads to very slow convergence to high-quality solutions in the SGA <ref> [23, 33, 45] </ref>. This has sometimes resulted in prohibitively long computation times. For this reason, recent GA literature has focused on more aggressive local search operators. <p> Holland simply stops the SGA after a specified number of generations [45]. Other proposals for stop criteria include stopping after a solution of given cost has been found or after a certain degree of homogeneity amongst the population strings has been observed <ref> [23, 33] </ref>. Given the above information, pseudo-code for Hollands SGA is given in Figure 4.2. The next subsection gives a mathematical basis as to why GAs function the way they do. 4.2.3 Mathematical Model Unlike SA, theoretical work for GAs has been quite slow. <p> This is because of the fact that the 0 in the first bit position and the 1 in the fifth bit position will be placed in different offspring. This situation is often referred to as disruption <ref> [23, 33, 45] </ref>. It should be clear that the schema *11*** will not be disrupted by a crossover at the third bit position, since both 1s will be intact in the same offspring. Clearly the probability of a schema surviving crossover without disruption is directly related to its defining length. <p> This is the final piece of information needed to approximate the expected number of a given schema H to be found in the next generation. The complete calculation can be described by the following theorem, usually referred to as the fundamental theorem of genetic algorithms, or the schema theorem <ref> [23, 33, 45] </ref>. <p> Theses types of high-performance schemata are often referred to as building blocks <ref> [23, 33, 45] </ref>. Recall that a given string can simultaneously represent up to k l different schemata. The GA does not explicitly process them all, but instead implicitly processes them concurrently through selection, crossover, and mutation. This is often referred to as implicit parallelism [23, 33, 45]. <p> often referred to as building blocks <ref> [23, 33, 45] </ref>. Recall that a given string can simultaneously represent up to k l different schemata. The GA does not explicitly process them all, but instead implicitly processes them concurrently through selection, crossover, and mutation. This is often referred to as implicit parallelism [23, 33, 45]. Goldberg showed that in a given generation the SGA explicitly processes n population strings, but implicitly processes approximately n 3 schemata [33]. 4.2.4 Performance Improvements The previous subsection demonstrated why the SGA is able to produce high-quality solutions to combinatorial optimization problems through implicit schemata processing. <p> However, the SGA typically suffers from prohibitive computational cost <ref> [23, 33, 45] </ref>. There have been many proposals in the literature for improving the performance of the SGA. Three of the most common will N H t 1+,( ) N H t,( ) f m - 1 p d H ( ) oH () p 93 be discussed here. <p> There have been two major problems noted in the literature with the usual roulette wheel proportionate selection scheme <ref> [23, 33] </ref>. The first of these problems lies in the fact that early generations of the SGA tend to have very low average fitness with a few strings exhibiting well-above average fitness. <p> In this case, roulette wheel selection will allocate an approximately equal number of offspring to all population strings, deterring the increased sampling of high-performance schemata. One proposed solution to this problem is a technique known as rank-based selection <ref> [23, 33] </ref>. Offspring are allocated to a fitness-based ranking of the population strings. The higher the fitness, the higher the rank of the string. In this scenario, offspring allocation is no longer directly controlled by a strings fitness, but rather by its rank in the population. <p> The major drawback to rank-based selection is the overhead associated with sorting the population according to fitness. Another improvement to the SGA that has been proposed in the literature is optimization of the control parameters <ref> [23, 26, 33, 36] </ref>. Recall that the control parameters are comprised of the crossover rate p c , the mutation rate p m , and the size of the population n. <p> These considerations have typically led researchers to adopt one of two approaches to choosing control parameters: a small population size with high mutation and crossover rates, or a large population size with smaller crossover and mutation rates <ref> [23, 26, 33, 36] </ref>. Although the above two approaches do indeed produce performance improvements in the SGA, the amount of improvement is small. A more radical approach is the hybrid genetic algorithm [33, 64, 71, 81, 98]. <p> The assumption behind such 29046 crossover point 2904651873 Parent Strings Offspring 35718 98 rank-based selection methods is that the additional overhead of maintaining a sorted list is typically counterbalanced by the increased greediness of the GA [11]. The crossover operator is similar to the PMX operator of Grefenstette <ref> [23] </ref>, an extension of the inversion operator of Holland [45] originally proposed for permutation problems such as the QAP. Bitwise mutation is replaced by the possibility of randomly interchanging two of the allele values in each of the population strings. <p> A problem is GA-deceptive if the schema partition containing the optimal solution does not have the highest average fitness of all other schemata <ref> [23, 33, 71] </ref>. In addition, one of the GA-deceptive problems is loosely encoded, or GA-loose, while the other is tightly encoded, or GA-tight [23, 33, 71]. GA-loose problems have groups of dependent bits, or hyperplanes, that are spaced widely apart over the solution strings. <p> A problem is GA-deceptive if the schema partition containing the optimal solution does not have the highest average fitness of all other schemata <ref> [23, 33, 71] </ref>. In addition, one of the GA-deceptive problems is loosely encoded, or GA-loose, while the other is tightly encoded, or GA-tight [23, 33, 71]. GA-loose problems have groups of dependent bits, or hyperplanes, that are spaced widely apart over the solution strings. These types of problems are typically difficult for GAs due to the high amount of disruption associated with crossover. <p> For this reason, Hollands crossover operator for permutation problems [45] previously illustrated in Figure 5.1 is used for the TSP system. On the other hand, the VLSI-NPP uses a more traditional binary string encoding, greatly increasing the crossover possibilities. The VLSI-NPP is a GA-loose problem <ref> [23, 33, 71] </ref>, with many hyperplanes approaching the entire length of the string. For problems of this sort, multi-point crossover is generally desirable over the standard single-point crossover. However, Spears and De Jong [93] present evidence indicating that uniform crossover may also be advantageous with certain loosely-coded problems. <p> The population distribution method commonly used by researchers utilizing GAs on distributed architectures is typically some subspeciation technique, in which each processor independently evolves a subpopulation of strings <ref> [8, 15, 16, 17, 23, 33] </ref>. Since larger populations tend to produce better GA solution quality through improved diversity, all of these population distribution schemes involve some mechanism for the migration of solutions between processors.
Reference: [24] <author> T.E. Davis and J.C. Principe, </author> <title> A Simulated Annealing Like Convergence Theory for the Simple Genetic Algorithm, </title> <booktitle> Proc. Fourth Int. Conf. Genetic Algs.and Their Apps., </booktitle> <address> San Diego, CA, 174-181, </address> <year> 1991. </year>
Reference: [25] <author> A.E. Dunlop and B.W. Kernighan, </author> <title> A Procedure for Placement of Standard-Cell VLSI Cir 128 cuits, </title> <journal> IEEE Trans. CADICS, </journal> <volume> vol. 4, </volume> <pages> 92-98, </pages> <year> 1985. </year>
Reference: [26] <author> L.J. Eshelman, </author> <title> The CHC Adaptive Search Algorithm: How to Have Safe Search When Engaging in Nontraditional Genetic Recombination, </title> <editor> in G. Rawlins, ed., </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, 265-283, </address> <year> 1991. </year>
Reference-contexts: The major drawback to rank-based selection is the overhead associated with sorting the population according to fitness. Another improvement to the SGA that has been proposed in the literature is optimization of the control parameters <ref> [23, 26, 33, 36] </ref>. Recall that the control parameters are comprised of the crossover rate p c , the mutation rate p m , and the size of the population n. <p> These considerations have typically led researchers to adopt one of two approaches to choosing control parameters: a small population size with high mutation and crossover rates, or a large population size with smaller crossover and mutation rates <ref> [23, 26, 33, 36] </ref>. Although the above two approaches do indeed produce performance improvements in the SGA, the amount of improvement is small. A more radical approach is the hybrid genetic algorithm [33, 64, 71, 81, 98].
Reference: [27] <author> E. Felten, S. Karlin, and S.W. Otto, </author> <title> The Traveling Salesman Problem on a Hypercubic, MIMD Computer, </title> <booktitle> Proc. Int. Conf. Parallel Processing, </booktitle> <pages> 6-10, </pages> <year> 1985. </year>
Reference: [28] <author> C.M. Fiduccia and R.M. Mattheyses, </author> <title> A Linear-Time Heuristic for Improving Network Partitions, </title> <booktitle> Proc. 19th ACM/IEEE DAC, </booktitle> <address> Las Vegas, NV, 241-247, </address> <year> 1985. </year>
Reference-contexts: The solution quality of the sequential version of the proposed POSA heuristic is compared with three other heuristic methods for the VLSI-NPPthe algorithm of Fiduccia and Mattheyses (F-M) <ref> [28] </ref>, the classic SA implementation of Kirkpatrick, Gelatt, and Vecchi [57] using the SA parameter settings discussed in the previous section, and the SGA [45] using two-point crossover and the other GA parameter settings discussed in the previous section.
Reference: [29] <author> M.R. Garey and D.S. Johnson, </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness, W.H. </title> <publisher> Freeman and Co., </publisher> <address> San Francisco, CA, </address> <year> 1979. </year>
Reference: [30] <author> S.B. Gelfand and S.K. Mitter, </author> <title> Analysis of Simulated Annealing for Optimization, </title> <booktitle> Proc. 24th Conf. </booktitle> <month> Dec. </month> <title> and Control, </title> <address> Ft. Lauderdale, FL, 779-886, </address> <year> 1985. </year>
Reference: [31] <author> S. Geman and D. Geman, </author> <title> Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images, </title> <journal> IEEE Trans. PAMI, </journal> <volume> vol. 6, </volume> <pages> 721-741, </pages> <year> 1984. </year>
Reference: [32] <author> B. Gidas, </author> <title> Non-Stationary Markov Chains and Convergence of the Annealing Algorithm, </title> <journal> J. Stat. Phys., </journal> <volume> vol. 39, </volume> <pages> 73-131, </pages> <year> 1985. </year>
Reference: [33] <author> D.E. Goldberg, </author> <title> Genetic Algorithms in Search, Optimization, </title> <booktitle> and Machine Learning, </booktitle> <address> Addi-son-Wesley, Reading, MA, </address> <year> 1989. </year>
Reference-contexts: As with SA, the GA exhibits elements of both randomization and local search. Likewise, it has proven to be quite effective for approximating global solutions to many types of NP-hard combinatorial problems, and indeed has been successfully applied to a number of VLSI design automation problems <ref> [15, 16, 17, 23, 33, 64, 81] </ref>. Section 4.2.1 introduces the terminology of genetic algorithms as inspired by the analogy with natural evolution. Section 4.2.2 introduces the original simple genetic algorithm of Holland [45]. <p> Section 4.2.4 describes some improvements to the simple genetic algorithm that have been proposed in the recent literatureincluding hybrid genetic systemsmotivating the development of the thermodynamic/genetic hybrid optimization technique described in Chapter 5. 4.2.1 Terminology and the Natural Analogy The genetic algorithm (GA) was first introduced by Holland in 1975 <ref> [23, 33, 45] </ref>. It was intended to mimic the natural selection process for the purpose of solving optimization problems. Solutions to the optimization problem being solved represent individuals of a population of similarly structured solutions. <p> In nature, there is competition amongst members of a species for the resources necessary to survival. Only the fittest individuals tend to survive and reproduce so that their genetic material is propagated into the next generation <ref> [23, 33, 45] </ref>. In other words, the genes of the fittest individuals tend to survive into the next generation, while the genes of the weaker individuals tend to die out. Genes are propagated through reproduction. Reproduction combines the genes of two individuals. <p> In the GA, it is simply said that string positions may take on any value contained in the defining alphabet. For the GA, solutions are associated with a fitness value that is a quantitative measure of the comparative quality of the solution with the rest of the population <ref> [23, 33, 45] </ref>. The higher a solutions fitness value, the higher its chances of reproducing and passing its genes onto the next generation. The GA simulates genetic crossover through some string recombination operator after individuals have been selected and paired off for mating. <p> Obviously, there are many different options available for each of these parameters, and indeed many have been proposed in the literature. The next subsection presents the choices made by Holland in the design of the first genetic algorithm, often called the simple genetic algorithm (SGA) <ref> [23, 33, 45] </ref>. <p> The specific scheme used by Hollands SGA to implement proportionate selection is often referred to as roulette wheel selection <ref> [23, 33, 45] </ref>. Each string i in the population is allocated a sector on a circle of angular size 2pf i / m f , where f i is the fitness of solution i. <p> It has been noted in the literature that the number of offspring allocated to a 86 particular string using the roulette wheel selection scheme can deviate significantly from the expected number of offspring for smaller-sized populations <ref> [23, 33] </ref>. For this reason, many alternative selection schemes have been proposed. Holland then considers a crossover operator for the SGA. As mentioned previously, crossover simulates the recombination of the genetic material of the two selected parents in the resulting offspring. Holland introduces a method called single-point crossover [45]. <p> Hollands SGA specifies a generational replacement policy, in which the entire population is replaced during each generation [45]. Some later GA proposals in the literature advocate a steady-state replacement policy, in which only select individuals of the population are replaced by offspring during each generation <ref> [23, 33] </ref>. Holland next specifies the mutation operator for the SGA. He proposes what is called bitwise mutation [45]. <p> Bitwise mutation used as a neighborhood operator leads to very slow convergence to high-quality solutions in the SGA <ref> [23, 33, 45] </ref>. This has sometimes resulted in prohibitively long computation times. For this reason, recent GA literature has focused on more aggressive local search operators. <p> Holland simply stops the SGA after a specified number of generations [45]. Other proposals for stop criteria include stopping after a solution of given cost has been found or after a certain degree of homogeneity amongst the population strings has been observed <ref> [23, 33] </ref>. Given the above information, pseudo-code for Hollands SGA is given in Figure 4.2. The next subsection gives a mathematical basis as to why GAs function the way they do. 4.2.3 Mathematical Model Unlike SA, theoretical work for GAs has been quite slow. <p> This is because of the fact that the 0 in the first bit position and the 1 in the fifth bit position will be placed in different offspring. This situation is often referred to as disruption <ref> [23, 33, 45] </ref>. It should be clear that the schema *11*** will not be disrupted by a crossover at the third bit position, since both 1s will be intact in the same offspring. Clearly the probability of a schema surviving crossover without disruption is directly related to its defining length. <p> This is the final piece of information needed to approximate the expected number of a given schema H to be found in the next generation. The complete calculation can be described by the following theorem, usually referred to as the fundamental theorem of genetic algorithms, or the schema theorem <ref> [23, 33, 45] </ref>. <p> Theses types of high-performance schemata are often referred to as building blocks <ref> [23, 33, 45] </ref>. Recall that a given string can simultaneously represent up to k l different schemata. The GA does not explicitly process them all, but instead implicitly processes them concurrently through selection, crossover, and mutation. This is often referred to as implicit parallelism [23, 33, 45]. <p> often referred to as building blocks <ref> [23, 33, 45] </ref>. Recall that a given string can simultaneously represent up to k l different schemata. The GA does not explicitly process them all, but instead implicitly processes them concurrently through selection, crossover, and mutation. This is often referred to as implicit parallelism [23, 33, 45]. Goldberg showed that in a given generation the SGA explicitly processes n population strings, but implicitly processes approximately n 3 schemata [33]. 4.2.4 Performance Improvements The previous subsection demonstrated why the SGA is able to produce high-quality solutions to combinatorial optimization problems through implicit schemata processing. <p> This is often referred to as implicit parallelism [23, 33, 45]. Goldberg showed that in a given generation the SGA explicitly processes n population strings, but implicitly processes approximately n 3 schemata <ref> [33] </ref>. 4.2.4 Performance Improvements The previous subsection demonstrated why the SGA is able to produce high-quality solutions to combinatorial optimization problems through implicit schemata processing. However, the SGA typically suffers from prohibitive computational cost [23, 33, 45]. <p> However, the SGA typically suffers from prohibitive computational cost <ref> [23, 33, 45] </ref>. There have been many proposals in the literature for improving the performance of the SGA. Three of the most common will N H t 1+,( ) N H t,( ) f m - 1 p d H ( ) oH () p 93 be discussed here. <p> There have been two major problems noted in the literature with the usual roulette wheel proportionate selection scheme <ref> [23, 33] </ref>. The first of these problems lies in the fact that early generations of the SGA tend to have very low average fitness with a few strings exhibiting well-above average fitness. <p> In this case, roulette wheel selection will allocate an approximately equal number of offspring to all population strings, deterring the increased sampling of high-performance schemata. One proposed solution to this problem is a technique known as rank-based selection <ref> [23, 33] </ref>. Offspring are allocated to a fitness-based ranking of the population strings. The higher the fitness, the higher the rank of the string. In this scenario, offspring allocation is no longer directly controlled by a strings fitness, but rather by its rank in the population. <p> The major drawback to rank-based selection is the overhead associated with sorting the population according to fitness. Another improvement to the SGA that has been proposed in the literature is optimization of the control parameters <ref> [23, 26, 33, 36] </ref>. Recall that the control parameters are comprised of the crossover rate p c , the mutation rate p m , and the size of the population n. <p> These considerations have typically led researchers to adopt one of two approaches to choosing control parameters: a small population size with high mutation and crossover rates, or a large population size with smaller crossover and mutation rates <ref> [23, 26, 33, 36] </ref>. Although the above two approaches do indeed produce performance improvements in the SGA, the amount of improvement is small. A more radical approach is the hybrid genetic algorithm [33, 64, 71, 81, 98]. <p> Although the above two approaches do indeed produce performance improvements in the SGA, the amount of improvement is small. A more radical approach is the hybrid genetic algorithm <ref> [33, 64, 71, 81, 98] </ref>. In a hybrid genetic system, the traditional genetic operators are used in conjunction with a more aggressive local search operator in order for the population to converge more quickly than the traditional SGA. <p> A problem is GA-deceptive if the schema partition containing the optimal solution does not have the highest average fitness of all other schemata <ref> [23, 33, 71] </ref>. In addition, one of the GA-deceptive problems is loosely encoded, or GA-loose, while the other is tightly encoded, or GA-tight [23, 33, 71]. GA-loose problems have groups of dependent bits, or hyperplanes, that are spaced widely apart over the solution strings. <p> A problem is GA-deceptive if the schema partition containing the optimal solution does not have the highest average fitness of all other schemata <ref> [23, 33, 71] </ref>. In addition, one of the GA-deceptive problems is loosely encoded, or GA-loose, while the other is tightly encoded, or GA-tight [23, 33, 71]. GA-loose problems have groups of dependent bits, or hyperplanes, that are spaced widely apart over the solution strings. These types of problems are typically difficult for GAs due to the high amount of disruption associated with crossover. <p> For this reason, Hollands crossover operator for permutation problems [45] previously illustrated in Figure 5.1 is used for the TSP system. On the other hand, the VLSI-NPP uses a more traditional binary string encoding, greatly increasing the crossover possibilities. The VLSI-NPP is a GA-loose problem <ref> [23, 33, 71] </ref>, with many hyperplanes approaching the entire length of the string. For problems of this sort, multi-point crossover is generally desirable over the standard single-point crossover. However, Spears and De Jong [93] present evidence indicating that uniform crossover may also be advantageous with certain loosely-coded problems. <p> The population distribution method commonly used by researchers utilizing GAs on distributed architectures is typically some subspeciation technique, in which each processor independently evolves a subpopulation of strings <ref> [8, 15, 16, 17, 23, 33] </ref>. Since larger populations tend to produce better GA solution quality through improved diversity, all of these population distribution schemes involve some mechanism for the migration of solutions between processors.
Reference: [34] <author> D.E Goldberg, </author> <title> A Note On Boltzmann Tournament Selection for Genetic Algorithms and Population-Oriented Simulated Annealing, </title> <journal> Complex Systems, </journal> <volume> vol. 4, </volume> <pages> 445-460, </pages> <year> 1990. </year>
Reference-contexts: They follow crossover and mutation with a conceptually simple greedy neighborhood operator. In both cases, convergence times are much reduced in the case of the hybrid systems. The introduction of hybrid genetic systems has led a number of researchers to propose SA/ GA hybrids <ref> [10, 11, 34, 66, 71, 92, 98] </ref>. The main purpose for this type of system is two-fold. First, it allows for a simple and efficient alternative parallelization of SA, which as pointed out in Section 4.1 is a major drawback of the traditional SA algorithm. <p> Recently, researchers have been investigating hybrid algorithms that attempt to mix GA and SA techniques in an attempt to combine the respective advantages of the two paradigms, namely the convergence control of SA and the efficient par-allelization of the GA <ref> [10, 11, 34, 66, 71, 92, 98] </ref>. In this section we present previous related work with SA/GA hybrids. Some of the earliest work done in the area of SA/GA hybrids is that of Sirag and Weisser [92]. <p> These types of problems are typically difficult for GAs due to the high amount of disruption associated with crossover. Each of the above systems is essentially a GA with varying degrees of coupling with SA operators. However as stated by Goldberg <ref> [34] </ref>, SA/GA hybrid designs would benefit from closer resemblance to SA than to the GA. This is a direct consequence of the increased convergence control offered by a SA temperature schedule. Of the above GA/SA hybrids, the approach of Mahfoud 100 and Goldberg most closely resembles SA. <p> For the proposed heuristic, we replace the single-state perturb-compare-accept/reject Metropolis SA model with the population-oriented select-cross-mutate-evaluate model of the GA. The proposed parallel POSA heuristic is shown in Figure 5.2. Goldberg <ref> [34] </ref> showed that a near-Boltzmann temporal distribution can be achieved over a population at a given constant temperature with the use of a selection technique called Boltzmann Tournament Selection (BTS).
Reference: [35] <author> D.E. Goldberg and P. Segrest, </author> <title> Finite Markov Chain Analysis of Genetic Algorithms, </title> <booktitle> Proc. Second Int. Conf. Genetic Algs.and Their Apps., </booktitle> <address> Cambridge, MA, 1-8, </address> <year> 1987. </year>
Reference: [36] <author> J.J. Grefenstette, </author> <title> Optimization of Control Parameters for Genetic Algorithms, </title> <journal> IEEE Trans. Systems, Man, and Cybernetics, </journal> <volume> vol. SMC-16, </volume> <pages> 122-128, </pages> <year> 1986. </year>
Reference-contexts: The major drawback to rank-based selection is the overhead associated with sorting the population according to fitness. Another improvement to the SGA that has been proposed in the literature is optimization of the control parameters <ref> [23, 26, 33, 36] </ref>. Recall that the control parameters are comprised of the crossover rate p c , the mutation rate p m , and the size of the population n. <p> Recall that the control parameters are comprised of the crossover rate p c , the mutation rate p m , and the size of the population n. The optimal values for these parameters are application-dependent <ref> [36] </ref>, but a number of considerations in choosing appropriate parameter values have been presented. <p> These considerations have typically led researchers to adopt one of two approaches to choosing control parameters: a small population size with high mutation and crossover rates, or a large population size with smaller crossover and mutation rates <ref> [23, 26, 33, 36] </ref>. Although the above two approaches do indeed produce performance improvements in the SGA, the amount of improvement is small. A more radical approach is the hybrid genetic algorithm [33, 64, 71, 81, 98].
Reference: [37] <author> J.W. Greene and K.J. Supowit, </author> <title> Simulated Annealing Without Rejected Moves, </title> <journal> IEEE Trans. CADICS, </journal> <volume> vol. 5, </volume> <pages> 221-228, </pages> <year> 1986. </year>
Reference: [38] <author> A.S. Grimshaw, </author> <title> Easy to Use Object-Oriented Parallel Programming with Mentat, </title> <journal> IEEE Computer, </journal> <volume> vol. 26, </volume> <month> May, </month> <year> 1993. </year>
Reference-contexts: The distributed POSA prototypes are implemented within the Mentat distributed computing environment <ref> [38] </ref>, using C++ as the basis for its command Cities Classic SA (750, 500 runs) Simple GA (5 runs - both instances) Avg. tour Best tour Avg. (sec) tour Best tour Avg. (sec) 76 578 559 3.6 688 654 346 Table 5.5a: Experimental results comparing the newly proposed POSA heuristic with
Reference: [39] <author> L.K. Grover, </author> <title> A New Simulated Annealing Algorithm for Standard Cell Placement, </title> <booktitle> Proc. IEEE ICCAD-86, </booktitle> <address> Santa Clara, CA, 378-380, </address> <year> 1986. </year>
Reference: [40] <author> L.K. Grover, </author> <title> Standard Cell Placement Using Simulated Sintering, </title> <booktitle> Proc. 24th ACM/IEEE 129 DAC, </booktitle> <address> Miami Beach, FL, 56-59, </address> <year> 1987. </year>
Reference: [41] <author> B. Hajek, </author> <title> A Tutorial Survey of Theory and Applications of Simulated Annealing, </title> <booktitle> Proc. 24th IEEE Conf. Decision and Control, </booktitle> <address> Ft. Lauderdale, FL, 755-760, </address> <year> 1985. </year>
Reference: [42] <author> B. Hajek, </author> <title> Cooling Schedules for Optimal Annealing, </title> <journal> Math. Op. Res., </journal> <volume> vol. 13, </volume> <pages> 311-329, </pages> <year> 1988. </year>
Reference: [43] <author> B. Hajek and G. Sasaki, </author> <title> Simulated Annealing - To Cool or Not, </title> <journal> Sys. and Control Letters, </journal> <volume> vol. 12, </volume> <pages> 443-447, </pages> <year> 1989. </year>
Reference: [44] <author> M. Hanan, </author> <title> On Steiners Problem With Rectilinear Distance, </title> <journal> SIAM J. Appl. Math., </journal> <volume> vol. 14, </volume> <pages> 255-265, </pages> <year> 1966. </year>
Reference: [45] <author> J.H. Holland, </author> <booktitle> Adaption in Natural and Artificial Systems, </booktitle> <publisher> University of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1975. </year>
Reference-contexts: Section 4.2.1 introduces the terminology of genetic algorithms as inspired by the analogy with natural evolution. Section 4.2.2 introduces the original simple genetic algorithm of Holland <ref> [45] </ref>. Section 4.2.3 provides a theoretical basis for the operation of simple genetic algorithm with the introduction of the schema theorem [45]. <p> Section 4.2.1 introduces the terminology of genetic algorithms as inspired by the analogy with natural evolution. Section 4.2.2 introduces the original simple genetic algorithm of Holland <ref> [45] </ref>. Section 4.2.3 provides a theoretical basis for the operation of simple genetic algorithm with the introduction of the schema theorem [45]. <p> Section 4.2.4 describes some improvements to the simple genetic algorithm that have been proposed in the recent literatureincluding hybrid genetic systemsmotivating the development of the thermodynamic/genetic hybrid optimization technique described in Chapter 5. 4.2.1 Terminology and the Natural Analogy The genetic algorithm (GA) was first introduced by Holland in 1975 <ref> [23, 33, 45] </ref>. It was intended to mimic the natural selection process for the purpose of solving optimization problems. Solutions to the optimization problem being solved represent individuals of a population of similarly structured solutions. <p> In nature, there is competition amongst members of a species for the resources necessary to survival. Only the fittest individuals tend to survive and reproduce so that their genetic material is propagated into the next generation <ref> [23, 33, 45] </ref>. In other words, the genes of the fittest individuals tend to survive into the next generation, while the genes of the weaker individuals tend to die out. Genes are propagated through reproduction. Reproduction combines the genes of two individuals. <p> In the GA, it is simply said that string positions may take on any value contained in the defining alphabet. For the GA, solutions are associated with a fitness value that is a quantitative measure of the comparative quality of the solution with the rest of the population <ref> [23, 33, 45] </ref>. The higher a solutions fitness value, the higher its chances of reproducing and passing its genes onto the next generation. The GA simulates genetic crossover through some string recombination operator after individuals have been selected and paired off for mating. <p> Obviously, there are many different options available for each of these parameters, and indeed many have been proposed in the literature. The next subsection presents the choices made by Holland in the design of the first genetic algorithm, often called the simple genetic algorithm (SGA) <ref> [23, 33, 45] </ref>. <p> details three performance improvements to the SGA, motivating the introduction of the thermodynamic/ genetic hybrid optimization technique presented in Chapter 5. 4.2.2 The Simple Genetic Algorithm Holland chose to use a binary encoding for the population strings, since solutions to most optimization problems can easily be mapped to binary strings <ref> [45] </ref>. An example of this can be seen in the encoding for the TSP. Each bit position in the binary string represents the inclusion or exclusion of the corresponding edge of the graph in the Hamiltonian circuit describing the current tour. <p> Since there is great variability in these values from problem to problem, Holland introduced the concept of a fitness function to normalize the objective function to some specified range <ref> [45] </ref>. This normalized fitness is then used as the basis for selecting individuals from the population to mate. The natural premise is to mate the fittest individuals with each other based on some probabilistic selection method. <p> m f may contain a fractional part, it is necessary that some solutions are selected for mating more than f / m f times and others less than f / m f times, according to some randomized allocation criterion that attempts to eliminate biases toward any particular set of strings <ref> [45] </ref>. The specific scheme used by Hollands SGA to implement proportionate selection is often referred to as roulette wheel selection [23, 33, 45]. <p> The specific scheme used by Hollands SGA to implement proportionate selection is often referred to as roulette wheel selection <ref> [23, 33, 45] </ref>. Each string i in the population is allocated a sector on a circle of angular size 2pf i / m f , where f i is the fitness of solution i. <p> For this reason, many alternative selection schemes have been proposed. Holland then considers a crossover operator for the SGA. As mentioned previously, crossover simulates the recombination of the genetic material of the two selected parents in the resulting offspring. Holland introduces a method called single-point crossover <ref> [45] </ref>. Assuming a string length l, single-point crossover chooses an integer k uniformly at random in the range [1, l - 1]. Two new offspring are created by first copying the characters in bit positions 1 to k of each parent string to each respective offspring. <p> Holland specifies that crossover only occur between two selected strings if a random number over the range [0, 1] is less than some specified parameter p c , called the crossover rate <ref> [45] </ref>. 1001110 crossover point 1001110110 Parent Strings Offspring 101 87 If the random number is greater than p c , then crossover is not performed. As the number of population strings becomes large, the crossover rate will approach the percentage of strings to be crossed in the population. <p> This discussion of crossover motivates the question of choosing an appropriate population-handling technique. The population handling technique specifies the actual number of matings to occur in a given generation. Hollands SGA specifies a generational replacement policy, in which the entire population is replaced during each generation <ref> [45] </ref>. Some later GA proposals in the literature advocate a steady-state replacement policy, in which only select individuals of the population are replaced by offspring during each generation [23, 33]. Holland next specifies the mutation operator for the SGA. He proposes what is called bitwise mutation [45]. <p> replaced during each generation <ref> [45] </ref>. Some later GA proposals in the literature advocate a steady-state replacement policy, in which only select individuals of the population are replaced by offspring during each generation [23, 33]. Holland next specifies the mutation operator for the SGA. He proposes what is called bitwise mutation [45]. Essentially bitwise mutation is the linear scan of each string in the population, subjecting each bit independently to the possibility of ipping (i.e. changing the bits value from 0 to 1 or vice versa) with probability p m , called the mutation rate. <p> The mutation rate, along with the crossover rate and the chosen size of the population are often referred to collectively as the GA control parameters <ref> [45] </ref>. There have been many proposals for choosing appropriate values for the control parameters in order to improve performance of the SGA. Mutation is a neighborhood operator. It allows for the reintroduction of diversity into the population. <p> Bitwise mutation used as a neighborhood operator leads to very slow convergence to high-quality solutions in the SGA <ref> [23, 33, 45] </ref>. This has sometimes resulted in prohibitively long computation times. For this reason, recent GA literature has focused on more aggressive local search operators. <p> This will be discussed in more detail in Section 4.2.4. Lastly, Holland specifies the stop criterion for the SGA. Like SA, the stop criterion specifies 88 conditions under which the execution of the GA should be terminated. Holland simply stops the SGA after a specified number of generations <ref> [45] </ref>. Other proposals for stop criteria include stopping after a solution of given cost has been found or after a certain degree of homogeneity amongst the population strings has been observed [23, 33]. Given the above information, pseudo-code for Hollands SGA is given in Figure 4.2. <p> Holland originally noted that many high-fitness strings in a given population tend to have many similarities. Specifically, certain string patterns seem to be associated with high fitness. Hol-land called these similarity templates or schemata <ref> [45] </ref>. Schemata describe a subset of strings from the population that contain similarities at certain bit positions. Schemata are essentially pattern matching devices, specified by the chosen string alphabet plus a dont care symbol *. <p> The schema 00*11 matches exactly the set of two strings -00011, 00111-. The schema 0**11 matches the set of four strings -00011, 00111, 01011, 01111-. Each of the matched strings is referred to as an instance of the schema <ref> [45] </ref>. In general, the number of possible schemata for a given alphabet of cardinality k is (k + 1) l , where l is the length of the population strings. The k + 1 term takes into account the dont care symbol. <p> Given the above, it can bee seen that a population of size n will contain anywhere from k l to nk l schemata, depending upon the diversity of the population strings <ref> [45] </ref>. How the GA processes this possibly extremely large number of schemata in the context of a guided randomized search is the next question considered by Holland. Holland examines the effects of mating, crossover, and mutation on the schemata contained in a given population of strings. <p> (4.2) can be rewritten as . (4.3) If c is assumed to retain the same value after each generation, then Equation (4.3) can be rewritten as , (4.4) which implies that mating either increases or decreases exponentially the sampling of schemata depending upon the value of the corresponding constant c <ref> [45] </ref>. p f f n -= m H ( ) j j 1= m H ( ) f N H t 1+,( ) N H t,( ) f f m - 1 c+( ) N H t,( )= = t 91 It is now necessary to consider the effect of crossover <p> This is because of the fact that the 0 in the first bit position and the 1 in the fifth bit position will be placed in different offspring. This situation is often referred to as disruption <ref> [23, 33, 45] </ref>. It should be clear that the schema *11*** will not be disrupted by a crossover at the third bit position, since both 1s will be intact in the same offspring. Clearly the probability of a schema surviving crossover without disruption is directly related to its defining length. <p> Holland points out that for small values of p m , i.e. 0 &lt; p m &lt;< 1, the probability of schema survival can be approximated by 1 - o (H)p m <ref> [45] </ref>. This is the final piece of information needed to approximate the expected number of a given schema H to be found in the next generation. <p> This is the final piece of information needed to approximate the expected number of a given schema H to be found in the next generation. The complete calculation can be described by the following theorem, usually referred to as the fundamental theorem of genetic algorithms, or the schema theorem <ref> [23, 33, 45] </ref>. <p> Theses types of high-performance schemata are often referred to as building blocks <ref> [23, 33, 45] </ref>. Recall that a given string can simultaneously represent up to k l different schemata. The GA does not explicitly process them all, but instead implicitly processes them concurrently through selection, crossover, and mutation. This is often referred to as implicit parallelism [23, 33, 45]. <p> often referred to as building blocks <ref> [23, 33, 45] </ref>. Recall that a given string can simultaneously represent up to k l different schemata. The GA does not explicitly process them all, but instead implicitly processes them concurrently through selection, crossover, and mutation. This is often referred to as implicit parallelism [23, 33, 45]. Goldberg showed that in a given generation the SGA explicitly processes n population strings, but implicitly processes approximately n 3 schemata [33]. 4.2.4 Performance Improvements The previous subsection demonstrated why the SGA is able to produce high-quality solutions to combinatorial optimization problems through implicit schemata processing. <p> However, the SGA typically suffers from prohibitive computational cost <ref> [23, 33, 45] </ref>. There have been many proposals in the literature for improving the performance of the SGA. Three of the most common will N H t 1+,( ) N H t,( ) f m - 1 p d H ( ) oH () p 93 be discussed here. <p> Because the TSP is under consideration, a variation of Hollands crossover operator for permutation problems is used <ref> [45] </ref>. Hollands operator specifies that a crossover point be selected at random. The genes to the left of the crossover point in the first parent are transcribed to the offspring. <p> The crossover operator is similar to the PMX operator of Grefenstette [23], an extension of the inversion operator of Holland <ref> [45] </ref> originally proposed for permutation problems such as the QAP. Bitwise mutation is replaced by the possibility of randomly interchanging two of the allele values in each of the population strings. For each generation of the GA, selection and crossover are followed by a full schedule of low-temperature SA. <p> There are many options available for the crossover operator. As noted earlier, the choice of crossover operator is generally based on the problem being solved. However, this choice of crossover operator is limited for permutation problems such as the TSP. For this reason, Hollands crossover operator for permutation problems <ref> [45] </ref> previously illustrated in Figure 5.1 is used for the TSP system. On the other hand, the VLSI-NPP uses a more traditional binary string encoding, greatly increasing the crossover possibilities. The VLSI-NPP is a GA-loose problem [23, 33, 71], with many hyperplanes approaching the entire length of the string. <p> quality of the sequential version of the proposed POSA heuristic is compared with three other heuristic methods for the VLSI-NPPthe algorithm of Fiduccia and Mattheyses (F-M) [28], the classic SA implementation of Kirkpatrick, Gelatt, and Vecchi [57] using the SA parameter settings discussed in the previous section, and the SGA <ref> [45] </ref> using two-point crossover and the other GA parameter settings discussed in the previous section. These three methods are used due to the superior solution quality of each. <p> The solution quality of the sequential version of the proposed POSA heuristic is compared with two other heuristic methods for the TSPthe classic SA implementation of Kirk-patrick, Gelatt, and Vecchi [57] using the SA parameter settings discussed in the previous section and the SGA <ref> [45] </ref> using Hollands crossover operator for permutation problems [45] and the other GA parameter settings discussed in the previous section. These two methods are used due to the superior solution quality of each. <p> quality of the sequential version of the proposed POSA heuristic is compared with two other heuristic methods for the TSPthe classic SA implementation of Kirk-patrick, Gelatt, and Vecchi [57] using the SA parameter settings discussed in the previous section and the SGA <ref> [45] </ref> using Hollands crossover operator for permutation problems [45] and the other GA parameter settings discussed in the previous section. These two methods are used due to the superior solution quality of each.
Reference: [46] <author> M.D. Huang, F. Romeo, and A. Sangiovanni-Vincentelli, </author> <title> An Efficient General Cooling Schedule for Simulated Annealing, </title> <booktitle> Proc. IEEE ICCAD-86, </booktitle> <address> Santa Clara, CA, 381-384, </address> <year> 1986. </year>
Reference: [47] <author> F.K. Hwang, D.S. Richards, and P. Winter, </author> <title> The Steiner Tree Problem, </title> <publisher> North-Holland, </publisher> <address> Amsterdam, Netherlands, </address> <year> 1992. </year>
Reference: [48] <author> L. Ingber and B. Rosen, </author> <title> Genetic Algorithms and Very Fast Reannealing: A Comparison, </title> <journal> Math. Comput. Modelling, </journal> <volume> vol. 16, </volume> <pages> 87-100, </pages> <year> 1992. </year>
Reference: [49] <author> R. Jayaraman and R. Rutenbar, </author> <title> Floorplanning by Annealing on a Hypercube Multiprocessor, </title> <publisher> IEEE ICCAD-87, </publisher> <address> Santa Clara, CA, 346-349, </address> <year> 1987. </year>
Reference-contexts: introduction of errors into the cost calculations. An interesting characteristic of the parallel moves approach is its changing performance at different temperatures <ref> [2, 4, 49, 50, 58, 87, 103] </ref>. The speedup factor is much higher at the low temperatures when using a parallel moves approach. This is the direct result of the dynamic nature of the solution acceptance probabilities at different temperatures of the employed annealing schedule. <p> However, as the temperature is lowered, the solution acceptance probabilities decrease to the point where almost no solution transitions are accepted. This corresponds to an almost 1:1 speedup with the number of available processors for both the exact and chaotic schemes, due to the extremely low communications requirements <ref> [2, 4, 49, 50, 58, 87, 103] </ref>. In addition, temporary errors in chaotic methods are shown to vanish at the low temperatures, again due to the lack of solution acceptances [4, 8, 50, 58].
Reference: [50] <author> R. Jayaraman and F. Darema, </author> <title> Error Tolerance in Parallel Simulated Annealing Techniques, </title> <booktitle> Proc. IEEE ICCD, </booktitle> <address> Rye Brook, NY, 545-548, </address> <year> 1988. </year>
Reference-contexts: introduction of errors into the cost calculations. An interesting characteristic of the parallel moves approach is its changing performance at different temperatures <ref> [2, 4, 49, 50, 58, 87, 103] </ref>. The speedup factor is much higher at the low temperatures when using a parallel moves approach. This is the direct result of the dynamic nature of the solution acceptance probabilities at different temperatures of the employed annealing schedule. <p> This communications overhead is lessened slightly by a chaotic approach, but at the cost of introduced errors. In addition, studies indicate that the relative size of the errors for chaotic parallel moves increases at the higher temperatures <ref> [4, 12, 50, 58] </ref>. However, as the temperature is lowered, the solution acceptance probabilities decrease to the point where almost no solution transitions are accepted. <p> However, as the temperature is lowered, the solution acceptance probabilities decrease to the point where almost no solution transitions are accepted. This corresponds to an almost 1:1 speedup with the number of available processors for both the exact and chaotic schemes, due to the extremely low communications requirements <ref> [2, 4, 49, 50, 58, 87, 103] </ref>. In addition, temporary errors in chaotic methods are shown to vanish at the low temperatures, again due to the lack of solution acceptances [4, 8, 50, 58]. <p> In addition, temporary errors in chaotic methods are shown to vanish at the low temperatures, again due to the lack of solution acceptances <ref> [4, 8, 50, 58] </ref>. As a result, chaotic parallel moves schemes are generally shown experimentally to have similar convergence characteristics as the sequential SA algorithm, but this cannot be guaranteed in the general case since its validity has turned out to be difficult to prove [4, 8, 50, 58]. <p> the lack of solution acceptances <ref> [4, 8, 50, 58] </ref>. As a result, chaotic parallel moves schemes are generally shown experimentally to have similar convergence characteristics as the sequential SA algorithm, but this cannot be guaranteed in the general case since its validity has turned out to be difficult to prove [4, 8, 50, 58]. A parallel moves approach, independent of any type of move decomposition, is an application-independent way to parallelize the SA paradigm. <p> An application-independent parallel implementation is appealing due to the fact that applicability to a wide range of problems is a major advantage of the sequential version of the algorithm. Only a few researchers have focused on truly application-independent parallel implementations of the SA paradigm <ref> [2, 50, 58, 86, 103] </ref>. 82 4.2 Genetic Algorithms As seen in Section 4.1, the parallelization of SA has been largely unsuccessful. An application-independent parallel implementation that is both efficient in its parallelization and scalable to massively parallel architectures has yet to be demonstrated in the literature.
Reference: [51] <author> D.S. Johnson, </author> <title> Local Optimization and the Traveling Salesman Problem, </title> <booktitle> Proc. 17th ICALP, </booktitle> <pages> 446-461, </pages> <year> 1990. </year>
Reference-contexts: These two methods are used due to the superior solution quality of each. Johnson <ref> [51] </ref> presents an extensive empirical study comparing SA, the 3-opt TSP heuristic of Lin [67], and the k-opt TSP heuristic of Lin and Kernighan (L-K). The Johnson study validates SA as being significantly more effective than the 3-opt heuristic and nearly as effective as the L-K heuristic for the TSP. <p> The Johnson study validates SA as being significantly more effective than the 3-opt heuristic and nearly as effective as the L-K heuristic for the TSP. Additionally, Johnson provides evidence indicating that GAs are capable of producing state-of-the-art solutions to the TSP given appropriate amounts of computation time <ref> [51] </ref>. For these reasons, SA and the SGA are used for solution quality analysis. For this study, as with the VLSI-NPP, each method is given approximately an equal amount of CPU time.
Reference: [52] <author> D.S. Johnson, C.R. Aragon, L.A. McGeoch, and C. Schevon, </author> <title> Optimization by Simulated Annealing: An Experimental Evaluation; Part 1, Graph Partitioning, </title> <journal> Operations Research, </journal> <volume> vol. 37, </volume> <pages> 865-892, </pages> <year> 1989. </year>
Reference-contexts: These three methods are used due to the superior solution quality of each. Johnson, Aragon, McGeoch, and Schevon <ref> [52] </ref> present an extensive empirical study comparing SA and the GPP heuristic of Kernighan and Lin (K-L) [56]. The implementation of the F-M heuristic used in this section is a generalization of the K-L technique to hypergraph partitioning, i.e. the VLSI-NPP.
Reference: [53] <author> M. Jones and P. Banerjee, </author> <title> Performance of a Parallel Algorithm for Standard Cell Placement on the Intel Hypercube, </title> <booktitle> 24th IEEE/ACM DAC, </booktitle> <address> Miami Beach, FL, 807-813, </address> <year> 1987. </year>
Reference: [54] <author> A.B. Kahng and G. Robins, </author> <title> A New Class of Iterative Steiner Tree Heuristics with Good Performance, </title> <journal> IEEE Trans. CADICS, </journal> <volume> vol. 11, </volume> <pages> 893-902, </pages> <year> 1992. </year> <month> 130 </month>
Reference: [55] <author> R.L Karg and G.L. Thompson, </author> <title> A Heuristic Approach to Solving Traveling-Salesman Problems, </title> <journal> Management Science, </journal> <volume> vol. 10, </volume> <pages> 225-247, </pages> <year> 1964. </year>
Reference: [56] <author> B.W. Kernighan and S. Lin, </author> <title> An Efficient Heuristic Procedure for Partitioning Graphs, </title> <journal> Bell System Tech. J., </journal> <volume> vol. 49, </volume> <pages> 291-307, </pages> <year> 1973. </year>
Reference-contexts: In a hybrid genetic system, the traditional genetic operators are used in conjunction with a more aggressive local search operator in order for the population to converge more quickly than the traditional SGA. For example, von Laszewski [64] uses a variant of Kernighan and Lins network partitioning algorithm <ref> [56] </ref> to improve a solution after it has been subjected to crossover and mutation. Another example is that of Rabaudengo and Sonza Reorda [81]. They consider the oorplan optimization problem. They follow crossover and mutation with a conceptually simple greedy neighborhood operator. <p> These three methods are used due to the superior solution quality of each. Johnson, Aragon, McGeoch, and Schevon [52] present an extensive empirical study comparing SA and the GPP heuristic of Kernighan and Lin (K-L) <ref> [56] </ref>. The implementation of the F-M heuristic used in this section is a generalization of the K-L technique to hypergraph partitioning, i.e. the VLSI-NPP. The Johnson, Aragon, McGeoch, and Schevon study validates SA and F-M as the two best available methods for hypergraph partitioning. <p> Their findings indicate that given an equal amount of computation time, K-L and SA have very comparable performance in terms of solution quality, with SA slightly outperforming F-M on sparse, low edge-degree instances that are common to real-world VLSI circuits such as PrimarySC1 and PrimarySC2 <ref> [56] </ref>. For this reason, SA and F-M along with the SGA are used for solution quality analysis.
Reference: [57] <author> S. Kirkpatrick, </author> <title> C.D. Gelatt, and M.P. Vecchi, Optimization by Simulated Annealing, </title> <journal> Science, </journal> <volume> vol. 220, </volume> <pages> 45-54, </pages> <year> 1983. </year>
Reference-contexts: In this section we describe the various SA and GA implementation details for the proposed POSA heuristic. The chosen SA cooling schedule is based upon the classic Kirkpatrick, Gelatt, and Vecchi schedule <ref> [57] </ref>. The classic schedule employs a constant temperature decrement rule. For the proposed POSA implementation, a = 0.95. The initial temperature is set such that t 0 = s , the standard deviation of the cost over the solution space [101]. <p> The solution quality of the sequential version of the proposed POSA heuristic is compared with three other heuristic methods for the VLSI-NPPthe algorithm of Fiduccia and Mattheyses (F-M) [28], the classic SA implementation of Kirkpatrick, Gelatt, and Vecchi <ref> [57] </ref> using the SA parameter settings discussed in the previous section, and the SGA [45] using two-point crossover and the other GA parameter settings discussed in the previous section. These three methods are used due to the superior solution quality of each. <p> The solution quality of the sequential version of the proposed POSA heuristic is compared with two other heuristic methods for the TSPthe classic SA implementation of Kirk-patrick, Gelatt, and Vecchi <ref> [57] </ref> using the SA parameter settings discussed in the previous section and the SGA [45] using Hollands crossover operator for permutation problems [45] and the other GA parameter settings discussed in the previous section. These two methods are used due to the superior solution quality of each.
Reference: [58] <author> S.A. Kravitz and R.A. Rutenbar, </author> <title> Placement by Simulated Annealing on a Multiprocessor, </title> <journal> IEEE Trans. CADICS, </journal> <volume> vol. 6, </volume> <pages> 534-549, </pages> <year> 1987. </year>
Reference-contexts: introduction of errors into the cost calculations. An interesting characteristic of the parallel moves approach is its changing performance at different temperatures <ref> [2, 4, 49, 50, 58, 87, 103] </ref>. The speedup factor is much higher at the low temperatures when using a parallel moves approach. This is the direct result of the dynamic nature of the solution acceptance probabilities at different temperatures of the employed annealing schedule. <p> This communications overhead is lessened slightly by a chaotic approach, but at the cost of introduced errors. In addition, studies indicate that the relative size of the errors for chaotic parallel moves increases at the higher temperatures <ref> [4, 12, 50, 58] </ref>. However, as the temperature is lowered, the solution acceptance probabilities decrease to the point where almost no solution transitions are accepted. <p> However, as the temperature is lowered, the solution acceptance probabilities decrease to the point where almost no solution transitions are accepted. This corresponds to an almost 1:1 speedup with the number of available processors for both the exact and chaotic schemes, due to the extremely low communications requirements <ref> [2, 4, 49, 50, 58, 87, 103] </ref>. In addition, temporary errors in chaotic methods are shown to vanish at the low temperatures, again due to the lack of solution acceptances [4, 8, 50, 58]. <p> In addition, temporary errors in chaotic methods are shown to vanish at the low temperatures, again due to the lack of solution acceptances <ref> [4, 8, 50, 58] </ref>. As a result, chaotic parallel moves schemes are generally shown experimentally to have similar convergence characteristics as the sequential SA algorithm, but this cannot be guaranteed in the general case since its validity has turned out to be difficult to prove [4, 8, 50, 58]. <p> the lack of solution acceptances <ref> [4, 8, 50, 58] </ref>. As a result, chaotic parallel moves schemes are generally shown experimentally to have similar convergence characteristics as the sequential SA algorithm, but this cannot be guaranteed in the general case since its validity has turned out to be difficult to prove [4, 8, 50, 58]. A parallel moves approach, independent of any type of move decomposition, is an application-independent way to parallelize the SA paradigm. <p> An application-independent parallel implementation is appealing due to the fact that applicability to a wide range of problems is a major advantage of the sequential version of the algorithm. Only a few researchers have focused on truly application-independent parallel implementations of the SA paradigm <ref> [2, 50, 58, 86, 103] </ref>. 82 4.2 Genetic Algorithms As seen in Section 4.1, the parallelization of SA has been largely unsuccessful. An application-independent parallel implementation that is both efficient in its parallelization and scalable to massively parallel architectures has yet to be demonstrated in the literature.
Reference: [59] <author> J.B. Kruskal, </author> <title> On the Shortest Spanning Subtree of a Graph and the Traveling Salesman Problem, </title> <journal> Proc. American Math. Soc., </journal> <volume> vol. 7, </volume> <pages> 48-50, </pages> <year> 1956. </year>
Reference: [60] <author> P.J.M. van Laarhoven, </author> <title> Theoretical and Computational Aspects of Simulated Annealing, </title> <institution> Center for Mathematics and Computer Science, </institution> <address> Amsterdam, Netherlands, </address> <year> 1988. </year>
Reference: [61] <author> P.J.M. van Laarhoven and E.H.L. Aarts, </author> <title> Simulated Annealing: Theory and Applications, </title> <publisher> Reidel Publishing, </publisher> <address> Dordrecht, Netherlands, </address> <year> 1987. </year>
Reference: [62] <author> J. Lam and J.-M. Delosme, </author> <title> Performance of a New Annealing Schedule, </title> <booktitle> Proc. 25th ACM/ IEEE DAC, </booktitle> <address> Anaheim, CA, 306-311, </address> <year> 1988. </year>
Reference: [63] <author> J. Lam and J.-M. Delosme, </author> <title> Simulated Annealing: A Fast Heuristic for Some Generic Layout Problems, </title> <booktitle> Proc. IEEE ICCAD-88, </booktitle> <address> Santa Clara, CA, 510-513, </address> <year> 1988. </year>
Reference: [64] <author> G. von Laszewski, </author> <title> Intelligent Structural Operators for the K-way Graph Partitioning Problem, </title> <booktitle> Proc. Fourth Int. Conf. Genetic Algs.and Their Apps., </booktitle> <address> San Diego, CA, 45-52, </address> <year> 1991. </year>
Reference-contexts: As with SA, the GA exhibits elements of both randomization and local search. Likewise, it has proven to be quite effective for approximating global solutions to many types of NP-hard combinatorial problems, and indeed has been successfully applied to a number of VLSI design automation problems <ref> [15, 16, 17, 23, 33, 64, 81] </ref>. Section 4.2.1 introduces the terminology of genetic algorithms as inspired by the analogy with natural evolution. Section 4.2.2 introduces the original simple genetic algorithm of Holland [45]. <p> Although the above two approaches do indeed produce performance improvements in the SGA, the amount of improvement is small. A more radical approach is the hybrid genetic algorithm <ref> [33, 64, 71, 81, 98] </ref>. In a hybrid genetic system, the traditional genetic operators are used in conjunction with a more aggressive local search operator in order for the population to converge more quickly than the traditional SGA. <p> In a hybrid genetic system, the traditional genetic operators are used in conjunction with a more aggressive local search operator in order for the population to converge more quickly than the traditional SGA. For example, von Laszewski <ref> [64] </ref> uses a variant of Kernighan and Lins network partitioning algorithm [56] to improve a solution after it has been subjected to crossover and mutation. Another example is that of Rabaudengo and Sonza Reorda [81]. They consider the oorplan optimization problem.
Reference: [65] <author> E.L Lawler, J.K. Lenstra, A.H.G Rinnooy Kan, and D.B. Shmoys, Ed., </author> <title> The Traveling Salesman Problem: A Guided Tour of Combinatorial Optimization, </title> <publisher> John Wiley and Sons, </publisher> <address> New York, NY, </address> <year> 1985. </year>
Reference: [66] <author> F.-T. Lin, C.-Y. Kao, and C.-C. Hsu, </author> <title> Incorporating Genetic Algorithms into Simulated Annealing, </title> <booktitle> Proc. Fourth Int. Symp. on AI, </booktitle> <pages> 290-297, </pages> <year> 1991. </year>
Reference-contexts: They follow crossover and mutation with a conceptually simple greedy neighborhood operator. In both cases, convergence times are much reduced in the case of the hybrid systems. The introduction of hybrid genetic systems has led a number of researchers to propose SA/ GA hybrids <ref> [10, 11, 34, 66, 71, 92, 98] </ref>. The main purpose for this type of system is two-fold. First, it allows for a simple and efficient alternative parallelization of SA, which as pointed out in Section 4.1 is a major drawback of the traditional SA algorithm. <p> Recently, researchers have been investigating hybrid algorithms that attempt to mix GA and SA techniques in an attempt to combine the respective advantages of the two paradigms, namely the convergence control of SA and the efficient par-allelization of the GA <ref> [10, 11, 34, 66, 71, 92, 98] </ref>. In this section we present previous related work with SA/GA hybrids. Some of the earliest work done in the area of SA/GA hybrids is that of Sirag and Weisser [92]. <p> The replacement function is called and the GA is restarted with the new population. Empirical results show the algorithm is able to outperform a leading QAP algorithm in terms of solution quality for two major benchmark problems from the literature. Lin, Kao, and Hsu <ref> [66] </ref> use a SA/GA hybrid approach similar to Brown et al. to solve the TSP. Their approach involves performing the standard GA operations after each temperature of the SA cooling schedule. The population is first initialized with randomly generated strings and one generation of the standard GA operators is performed.
Reference: [67] <author> S. Lin, </author> <title> Computer Solutions of the Traveling Salesman Problem, </title> <journal> Bell System Tech. J., </journal> <volume> vol. 44, </volume> <pages> 2245-2269, </pages> <year> 1965. </year>
Reference-contexts: These two methods are used due to the superior solution quality of each. Johnson [51] presents an extensive empirical study comparing SA, the 3-opt TSP heuristic of Lin <ref> [67] </ref>, and the k-opt TSP heuristic of Lin and Kernighan (L-K). The Johnson study validates SA as being significantly more effective than the 3-opt heuristic and nearly as effective as the L-K heuristic for the TSP.
Reference: [68] <author> S. Lin and B.W. Kernighan, </author> <title> An Effective Heuristic Algorithm for the Traveling Salesman Problem, </title> <journal> Operations Research, </journal> <volume> vol. 21, </volume> <pages> 498-516, </pages> <year> 1973. </year>
Reference: [69] <author> M. Lundy and A. Mees, </author> <title> Convergence of an Annealing Algorithm, </title> <journal> Math. Programming, </journal> <volume> vol. 34, </volume> <pages> 111-124, </pages> <year> 1986. </year> <month> 131 </month>
Reference: [70] <author> S.W. Mahfoud, </author> <title> Finite Markov Chain Models of an Alternative Selection Strategy for the Genetic Algorithm, </title> <type> Technical Report 91007, </type> <institution> Illinois Genetic Algorithms Laboratory, University of Illinois at Urbana-Champaign, </institution> <year> 1991. </year>
Reference-contexts: Under this assumption, the use of BTS in the proposed POSA heuristic would then carry over the asymptotic convergence guarantees of SA. However, BTS has several drawbacks limiting its practical application. Mahfoud and Goldberg <ref> [70, 71] </ref> show that certain variations of population-oriented SA systems are actually special cases of standard SA for which the asymptotic claims are valid.
Reference: [71] <author> S.W. Mahfoud and D.E. Goldberg, </author> <title> Parallel Recombinative Simulated Annealing: A Genetic Algorithm, </title> <journal> Parallel Computing, </journal> <volume> vol. 21, </volume> <pages> 1-28, </pages> <year> 1995. </year>
Reference-contexts: Although the above two approaches do indeed produce performance improvements in the SGA, the amount of improvement is small. A more radical approach is the hybrid genetic algorithm <ref> [33, 64, 71, 81, 98] </ref>. In a hybrid genetic system, the traditional genetic operators are used in conjunction with a more aggressive local search operator in order for the population to converge more quickly than the traditional SGA. <p> They follow crossover and mutation with a conceptually simple greedy neighborhood operator. In both cases, convergence times are much reduced in the case of the hybrid systems. The introduction of hybrid genetic systems has led a number of researchers to propose SA/ GA hybrids <ref> [10, 11, 34, 66, 71, 92, 98] </ref>. The main purpose for this type of system is two-fold. First, it allows for a simple and efficient alternative parallelization of SA, which as pointed out in Section 4.1 is a major drawback of the traditional SA algorithm. <p> Recently, researchers have been investigating hybrid algorithms that attempt to mix GA and SA techniques in an attempt to combine the respective advantages of the two paradigms, namely the convergence control of SA and the efficient par-allelization of the GA <ref> [10, 11, 34, 66, 71, 92, 98] </ref>. In this section we present previous related work with SA/GA hybrids. Some of the earliest work done in the area of SA/GA hybrids is that of Sirag and Weisser [92]. <p> All three methods were able to outperform standard SA in terms of solution quality. As expected, the life cycle/crossover method was able to produce the best tours, followed by the life cycle method and the random selection method. Mahfoud and Goldberg <ref> [71] </ref> also present a parallel SA/GA hybrid system. Their approach runs a number of SA procedures in parallel, using mutation as the SA neighborhood operator and crossover as a way of reconciling solutions across the processors. <p> A problem is GA-deceptive if the schema partition containing the optimal solution does not have the highest average fitness of all other schemata <ref> [23, 33, 71] </ref>. In addition, one of the GA-deceptive problems is loosely encoded, or GA-loose, while the other is tightly encoded, or GA-tight [23, 33, 71]. GA-loose problems have groups of dependent bits, or hyperplanes, that are spaced widely apart over the solution strings. <p> A problem is GA-deceptive if the schema partition containing the optimal solution does not have the highest average fitness of all other schemata <ref> [23, 33, 71] </ref>. In addition, one of the GA-deceptive problems is loosely encoded, or GA-loose, while the other is tightly encoded, or GA-tight [23, 33, 71]. GA-loose problems have groups of dependent bits, or hyperplanes, that are spaced widely apart over the solution strings. These types of problems are typically difficult for GAs due to the high amount of disruption associated with crossover. <p> Under this assumption, the use of BTS in the proposed POSA heuristic would then carry over the asymptotic convergence guarantees of SA. However, BTS has several drawbacks limiting its practical application. Mahfoud and Goldberg <ref> [70, 71] </ref> show that certain variations of population-oriented SA systems are actually special cases of standard SA for which the asymptotic claims are valid. <p> For this reason, Hollands crossover operator for permutation problems [45] previously illustrated in Figure 5.1 is used for the TSP system. On the other hand, the VLSI-NPP uses a more traditional binary string encoding, greatly increasing the crossover possibilities. The VLSI-NPP is a GA-loose problem <ref> [23, 33, 71] </ref>, with many hyperplanes approaching the entire length of the string. For problems of this sort, multi-point crossover is generally desirable over the standard single-point crossover. However, Spears and De Jong [93] present evidence indicating that uniform crossover may also be advantageous with certain loosely-coded problems.
Reference: [72] <author> N. Metropolis, A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller, </author> <title> Equation of State Calculations by Fast Computing Machines, </title> <journal> J. Chem. Phys., </journal> <volume> vol. 21, </volume> <pages> 1087-1092, </pages> <year> 1953. </year>
Reference: [73] <author> D. Mitra, F. Romeo, and A. Sangiovanni-Vincentelli, </author> <title> Convergence and Finite-Time Behavior of Simulated Annealing, </title> <journal> Adv. Appl. Prob., </journal> <volume> vol. 18, </volume> <pages> 747-771, </pages> <year> 1986. </year>
Reference: [74] <author> R.H.J.M Otten and L.P.P.P. van Ginneken, </author> <title> Floorplan Design Using Simulated Annealing, </title> <booktitle> Proc. IEEE ICCAD-84, </booktitle> <address> Santa Clara, CA, 96-98, </address> <year> 1984. </year>
Reference: [75] <author> R.H.J.M. Otten and L.P.P.P. van Ginneken, </author> <title> Annealing Applied to Floorplan Design in a Layout Compiler, </title> <booktitle> Proc. Automation 86, </booktitle> <address> Houston, TX, 185-228, </address> <year> 1986. </year>
Reference: [76] <author> R.H.J.M. Otten and L.P.P.P. van Ginneken, </author> <title> Stop Criteria in Simulated Annealing, </title> <booktitle> Proc. IEEE ICCD, </booktitle> <address> Rye Brook, NY, 549-552, </address> <year> 1988. </year>
Reference: [77] <author> R.H.J.M. Otten and L.P.P.P. Ginneken, </author> <title> The Annealing Algorithm, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1989. </year>
Reference: [78] <author> W. Padberg and G. Rinaldi, </author> <title> Optimization of a 532-City Symmetric TSP, Op. </title> <journal> Res. Lett., </journal> <volume> vol. 6, </volume> <pages> 1-7, </pages> <year> 1987. </year>
Reference: [79] <author> C.H. Papadimitriou and K. Steiglitz, </author> <title> Combinatorial Optimization: Algorithms and Complexity, </title> <publisher> Prentice-Hall, </publisher> <address> New York, NY, </address> <year> 1982. </year>
Reference: [80] <author> B. Preas, </author> <title> Benchmarks for Cell-Based Layout Systems, </title> <booktitle> Proc. 24th ACM/IEEE DAC, </booktitle> <address> Miami Beach, FL, 319-320, </address> <year> 1987. </year>
Reference-contexts: Results are presented for two of the larger instances of the VLSI-NPP. The problem instances are the SIGDA standard cell benchmark circuits PrimarySC1 and PrimarySC2 <ref> [80] </ref>. The results are presented in Tables 5.1a-5.1c. As can be seen in the tables, uniform crossover appears to be more effective than either single or 104 two-point crossover early in the GA run, but is quickly affected by disruption.
Reference: [81] <author> M. Rabaudengo and M. Sonza Reorda, </author> <title> Floorplan Area Optimization Using Genetic Algorithms, </title> <booktitle> Proc. Fourth GLSVLSI, </booktitle> <address> South Bend, IN,22-25, </address> <year> 1994. </year>
Reference-contexts: As with SA, the GA exhibits elements of both randomization and local search. Likewise, it has proven to be quite effective for approximating global solutions to many types of NP-hard combinatorial problems, and indeed has been successfully applied to a number of VLSI design automation problems <ref> [15, 16, 17, 23, 33, 64, 81] </ref>. Section 4.2.1 introduces the terminology of genetic algorithms as inspired by the analogy with natural evolution. Section 4.2.2 introduces the original simple genetic algorithm of Holland [45]. <p> Although the above two approaches do indeed produce performance improvements in the SGA, the amount of improvement is small. A more radical approach is the hybrid genetic algorithm <ref> [33, 64, 71, 81, 98] </ref>. In a hybrid genetic system, the traditional genetic operators are used in conjunction with a more aggressive local search operator in order for the population to converge more quickly than the traditional SGA. <p> For example, von Laszewski [64] uses a variant of Kernighan and Lins network partitioning algorithm [56] to improve a solution after it has been subjected to crossover and mutation. Another example is that of Rabaudengo and Sonza Reorda <ref> [81] </ref>. They consider the oorplan optimization problem. They follow crossover and mutation with a conceptually simple greedy neighborhood operator. In both cases, convergence times are much reduced in the case of the hybrid systems.
Reference: [82] <author> Reinelt, G., </author> <title> The Traveling Salesman: Computational Solutions for TSP Applications, </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: 110 user the power to trade off the desired level of solution quality for the desired range of computation time. 5.3.2 POSA Solution Quality: TSP Results for average-case and best-case solution quality of the proposed POSA heuristic are presented for the 51- and 76-city TSP benchmarks of Christofides and Eilon <ref> [82] </ref> found at the TSPLIB FTP site. <p> In light of this analysis, the probable efficacy of a parallel implementation is illustrated, especially under the assumption of a dedicated parallel architecture with an unshared communications network and efficient message-passing mechanism. 5.4.2 Distributed POSA: TSP The 51- and 76-city TSP benchmarks of Christofides and Eilon <ref> [82] </ref> are again used as the test instances.
Reference: [83] <author> F. Romeo and A. Sangiovanni-Vincentelli, </author> <title> A Theoretical Framework for Simulated Annealing, </title> <journal> Algorithmica, </journal> <volume> vol. 6, </volume> <pages> 302-345, </pages> <year> 1991. </year>
Reference: [84] <author> J.S. Rose, W.M. Snelgrove, and Z.G. Vranesic, </author> <title> Parallel Standard Cell Placement with Quality Equivalent to Simulated Annealing, </title> <journal> IEEE Trans. CADICS, </journal> <volume> vol. 7, </volume> <pages> 387-396, </pages> <year> 1988. </year> <month> 132 </month>
Reference: [85] <author> J.S. Rose, W. Klebsch, and J. Wolf, </author> <title> Temperature Measurement and Equilibrium Dynamics of Simulated Annealing Placements, </title> <journal> IEEE Trans. CADICS, </journal> <volume> vol. 9, </volume> <pages> 253-259, </pages> <year> 1990. </year>
Reference: [86] <author> S.M. Ross, </author> <title> Introduction to Probability Models, </title> <publisher> Academic Press, </publisher> <address> Boston, MA, </address> <year> 1989. </year>
Reference-contexts: An application-independent parallel implementation is appealing due to the fact that applicability to a wide range of problems is a major advantage of the sequential version of the algorithm. Only a few researchers have focused on truly application-independent parallel implementations of the SA paradigm <ref> [2, 50, 58, 86, 103] </ref>. 82 4.2 Genetic Algorithms As seen in Section 4.1, the parallelization of SA has been largely unsuccessful. An application-independent parallel implementation that is both efficient in its parallelization and scalable to massively parallel architectures has yet to be demonstrated in the literature.
Reference: [87] <author> P. Roussel-Ragot and G. Dreyfus, </author> <title> A Problem Independent Parallel Implementation of Simulated Annealing: Models and Experiments, </title> <journal> IEEE Trans. CADICS, </journal> <volume> vol.9, </volume> <pages> 827-835, </pages> <year> 1990. </year>
Reference-contexts: introduction of errors into the cost calculations. An interesting characteristic of the parallel moves approach is its changing performance at different temperatures <ref> [2, 4, 49, 50, 58, 87, 103] </ref>. The speedup factor is much higher at the low temperatures when using a parallel moves approach. This is the direct result of the dynamic nature of the solution acceptance probabilities at different temperatures of the employed annealing schedule. <p> However, as the temperature is lowered, the solution acceptance probabilities decrease to the point where almost no solution transitions are accepted. This corresponds to an almost 1:1 speedup with the number of available processors for both the exact and chaotic schemes, due to the extremely low communications requirements <ref> [2, 4, 49, 50, 58, 87, 103] </ref>. In addition, temporary errors in chaotic methods are shown to vanish at the low temperatures, again due to the lack of solution acceptances [4, 8, 50, 58].
Reference: [88] <author> S. Sahni, A. Bhatt, and R. Raghavan, </author> <title> The Complexity of Design Automation Problems, </title> <booktitle> Proc. Automation 86, </booktitle> <address> Houston, TX, 82-98, </address> <year> 1986. </year>
Reference: [89] <author> J.S. Sargent and P. Banerjee, </author> <title> A Parallel Row-Based Algorithm for Standard Cell Placement With Integrated Error Control, </title> <booktitle> Proc. 26th ACM/IEEE DAC, </booktitle> <pages> 590-593, </pages> <year> 1989. </year>
Reference: [90] <author> C. Sechen and A. Sangiovanni-Vincentelli, </author> <title> The TimberWolf Placement and Routing Package, </title> <journal> IEEE J. Solid-State Circuits, </journal> <volume> vol. 20, </volume> <pages> 510-522, </pages> <year> 1985. </year>
Reference: [91] <author> P. Sibani, J.M. Pedersen, K.H. Hoffmann, and P. Salamon, </author> <title> Monte Carlo Dynamics of Optimization Problems: A Scaling Description, </title> <journal> Phys. Rev. A, </journal> <volume> vol. 42, </volume> <pages> 7080-7086, </pages> <year> 1990. </year>
Reference: [92] <author> D.J. Sirag and P.T. Weisser, </author> <title> Toward A Unified Thermodynamic Genetic Operator, </title> <booktitle> Proc. Second Int. Conf. Genetic Algs.and Their Apps., </booktitle> <address> Cambridge, MA, 116-122, </address> <year> 1987. </year>
Reference-contexts: They follow crossover and mutation with a conceptually simple greedy neighborhood operator. In both cases, convergence times are much reduced in the case of the hybrid systems. The introduction of hybrid genetic systems has led a number of researchers to propose SA/ GA hybrids <ref> [10, 11, 34, 66, 71, 92, 98] </ref>. The main purpose for this type of system is two-fold. First, it allows for a simple and efficient alternative parallelization of SA, which as pointed out in Section 4.1 is a major drawback of the traditional SA algorithm. <p> Recently, researchers have been investigating hybrid algorithms that attempt to mix GA and SA techniques in an attempt to combine the respective advantages of the two paradigms, namely the convergence control of SA and the efficient par-allelization of the GA <ref> [10, 11, 34, 66, 71, 92, 98] </ref>. In this section we present previous related work with SA/GA hybrids. Some of the earliest work done in the area of SA/GA hybrids is that of Sirag and Weisser [92]. <p> In this section we present previous related work with SA/GA hybrids. Some of the earliest work done in the area of SA/GA hybrids is that of Sirag and Weisser <ref> [92] </ref>. The authors propose a unified thermodynamic genetic operator that introduces the concept of 96 an SA temperature to the traditional GA operations of crossover and mutation. The standard proportionate selection scheme is used to select parents for mating. Their thermodynamically-based crossover operator works as follows. <p> Thus, the proposed ther e c e m e i 97 modynamic operator for the TSP is specified by the 3-tuple [Q c , Q m , Q i ] <ref> [92] </ref>. The proposed thermodynamic/genetic operator of Sirag and Weisser typically introduces greater solution diversity at the high temperatures and less solution diversity at the low temperatures. The convergence control afforded by the addition of a SA-like temperature is empirically shown to increase performance of the GA. <p> In addition, the authors found that they were able to reduce the population size significantly without affecting convergence performance <ref> [92] </ref>. Brown, Huntley, and Spillane [11] introduce a parallel SA/GA hybrid system for solving the quadratic assignment problem (QAP). Their hybrid is a GA that uses low-temperature SA as a local search procedure. The GA uses non-standard variations of the traditional genetic operators. The selection scheme is rank-based.
Reference: [93] <author> W.M. Spears and K.A. De Jong, </author> <title> On the Virtues of Parameterized Uniform Crossover, </title> <booktitle> Proc. Fourth ICGA, </booktitle> <pages> 230-236, </pages> <year> 1991. </year>
Reference-contexts: The VLSI-NPP is a GA-loose problem [23, 33, 71], with many hyperplanes approaching the entire length of the string. For problems of this sort, multi-point crossover is generally desirable over the standard single-point crossover. However, Spears and De Jong <ref> [93] </ref> present evidence indicating that uniform crossover may also be advantageous with certain loosely-coded problems.
Reference: [94] <author> P.N. Strenski and S. Kirkpatrick, </author> <title> Analysis of Finite Length Annealing Schedules, </title> <journal> Algorith-mica, </journal> <volume> vol. 6, </volume> <pages> 346-366, </pages> <year> 1991. </year>
Reference: [95] <author> J.M. Varanelli and J.P. Cohoon, </author> <title> Two-Stage Simulated Annealing, </title> <booktitle> Proc. 4th ACM/SIGDA Phys. Des. </booktitle> <address> Wksp., Lake Arrowhead, CA, 1-10, </address> <year> 1993. </year>
Reference: [96] <author> J.M. Varanelli and J.P. Cohoon, </author> <title> A Fast Method for Generalized Starting Temperature Determination in Two-Stage Simulated Annealing Systems, </title> <type> Technical Report CS-93-52, </type> <institution> Department of Computer Science, University of Virginia, </institution> <year> 1993. </year> <note> Submitted to IEEE Trans. CADICS. </note>
Reference: [97] <author> J.M. Varanelli and J.P. Cohoon, </author> <title> A Two-Stage Simulated Annealing Methodology, </title> <type> Technical Report CS-94-46, </type> <institution> Department of Computer Science, University of Virginia, </institution> <year> 1994. </year>
Reference: [98] <author> J.M. Varanelli and J.P. Cohoon, </author> <title> Population-Oriented Simulated Annealing: A Genetic/Thermodynamic Approach to Optimization, </title> <booktitle> Proceedings ICGA 95, </booktitle> <pages> 174-181, </pages> <address> Pittsburgh, PA, </address> <year> 1995. </year>
Reference-contexts: Although the above two approaches do indeed produce performance improvements in the SGA, the amount of improvement is small. A more radical approach is the hybrid genetic algorithm <ref> [33, 64, 71, 81, 98] </ref>. In a hybrid genetic system, the traditional genetic operators are used in conjunction with a more aggressive local search operator in order for the population to converge more quickly than the traditional SGA. <p> They follow crossover and mutation with a conceptually simple greedy neighborhood operator. In both cases, convergence times are much reduced in the case of the hybrid systems. The introduction of hybrid genetic systems has led a number of researchers to propose SA/ GA hybrids <ref> [10, 11, 34, 66, 71, 92, 98] </ref>. The main purpose for this type of system is two-fold. First, it allows for a simple and efficient alternative parallelization of SA, which as pointed out in Section 4.1 is a major drawback of the traditional SA algorithm. <p> The second reason for this type of hybrid is the added convergence control possible with an SA cooling schedule, since convergence control is a serious problem with GAs as pointed out in Section 4.2. These reasons have led to the development of a new thermodynamic/genetic hybrid system <ref> [98] </ref>, to be presented in the next chapter. 95 Chapter 5 A Population-Oriented Simulated Annealing Heuristic This chapter presents a new general-purpose thermodynamic/genetic hybrid stochastic optimization algorithm. Section 5.1 presents related work with early thermodynamic/genetic systems. Section 5.2 presents the proposed POSA heuristic. <p> Recently, researchers have been investigating hybrid algorithms that attempt to mix GA and SA techniques in an attempt to combine the respective advantages of the two paradigms, namely the convergence control of SA and the efficient par-allelization of the GA <ref> [10, 11, 34, 66, 71, 92, 98] </ref>. In this section we present previous related work with SA/GA hybrids. Some of the earliest work done in the area of SA/GA hybrids is that of Sirag and Weisser [92].
Reference: [99] <author> J.M. Varanelli and J.P. Cohoon, </author> <title> A Fast Method for Generalized Starting Temperature Determination in Monotonically Cooling Two-Stage Simulated Annealing Systems, </title> <type> Technical 133 Report CS-95-08, </type> <institution> Department of Computer Science, University of Virginia, </institution> <year> 1995. </year>
Reference: [100] <author> J.M. Varanelli and J.P. Cohoon, </author> <title> A Two-Stage Simulated Annealing Methodology, </title> <booktitle> Proc. 5th Great Lakes Symp. on VLSI, </booktitle> <address> Buffalo, NY, 50-53, </address> <year> 1995. </year>
Reference: [101] <author> S.R. White, </author> <title> Concepts of Scale in Simulated Annealing, </title> <booktitle> Proc. IEEE ICCD, Port Chester, </booktitle> <address> NY, 646-651, </address> <year> 1984. </year>
Reference-contexts: The classic schedule employs a constant temperature decrement rule. For the proposed POSA implementation, a = 0.95. The initial temperature is set such that t 0 = s , the standard deviation of the cost over the solution space <ref> [101] </ref>. The standard SA Metropolis trial is replaced by a single mating with some probabilistic population replacement strategy. As noted above, the two parents are chosen at random and the crossover and mutation operators are applied to produce the two new offspring.
Reference: [102] <author> D. Whitley and J. Kauth, </author> <title> GENITOR: A Different Genetic Algorithm, </title> <booktitle> Proc. Rocky Mtn. Conf. on AI, </booktitle> <pages> 118-130, </pages> <year> 1988. </year>
Reference: [103] <author> E.E. Witte, R.D. Chamberlain, and M.A. Franklin, </author> <title> Parallel Simulated Annealing Using Speculative Computation, </title> <journal> IEEE Trans. Parallel and Dist. Sys., </journal> <volume> vol. 2, </volume> <pages> 483-494, </pages> <year> 1991. </year>
Reference-contexts: introduction of errors into the cost calculations. An interesting characteristic of the parallel moves approach is its changing performance at different temperatures <ref> [2, 4, 49, 50, 58, 87, 103] </ref>. The speedup factor is much higher at the low temperatures when using a parallel moves approach. This is the direct result of the dynamic nature of the solution acceptance probabilities at different temperatures of the employed annealing schedule. <p> However, as the temperature is lowered, the solution acceptance probabilities decrease to the point where almost no solution transitions are accepted. This corresponds to an almost 1:1 speedup with the number of available processors for both the exact and chaotic schemes, due to the extremely low communications requirements <ref> [2, 4, 49, 50, 58, 87, 103] </ref>. In addition, temporary errors in chaotic methods are shown to vanish at the low temperatures, again due to the lack of solution acceptances [4, 8, 50, 58]. <p> An application-independent parallel implementation is appealing due to the fact that applicability to a wide range of problems is a major advantage of the sequential version of the algorithm. Only a few researchers have focused on truly application-independent parallel implementations of the SA paradigm <ref> [2, 50, 58, 86, 103] </ref>. 82 4.2 Genetic Algorithms As seen in Section 4.1, the parallelization of SA has been largely unsuccessful. An application-independent parallel implementation that is both efficient in its parallelization and scalable to massively parallel architectures has yet to be demonstrated in the literature.
Reference: [104] <author> D.F. Wong, H.W. Leong, and C.L. Liu, </author> <title> Simulated Annealing for VLSI Design, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1988. </year>
References-found: 104

