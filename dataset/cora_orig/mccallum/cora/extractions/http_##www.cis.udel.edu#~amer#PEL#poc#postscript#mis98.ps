URL: http://www.cis.udel.edu/~amer/PEL/poc/postscript/mis98.ps
Refering-URL: http://www.cis.udel.edu/~amer/PEL/poc/
Root-URL: http://www.cis.udel.edu
Email: Email: firen,amerg@cis.udel.edu  Email: conrad@acm.org  
Phone: 2  
Title: NETCICATS: Network-Conscious Image Compression and Transmission System  
Author: Sami Iren Paul D. Amer and Phillip T. Conrad 
Address: 19716 USA  Philadelphia, PA 19122 USA  
Affiliation: 1 Department of Computer and Information Sciences University of Delaware, Newark, DE  Department of Computer and Information Sciences Temple University  
Abstract: NETCICATS is a software system for empirically evaluating network-conscious image compression, an approach that does not simply optimize compression, but which optimizes overall performance when compressed images are transmitted over a lossy packet-switched network such as the Internet. Based on Application Level Framing, an image is compressed into path-MTU-size Application Data Units (ADUs) at the application layer. Each ADU contains enough information to be processed independently of all other ADUs. Each ADU can be delivered to the receiving application out-of-order, thereby enabling faster progressive display of images. NETCICATS allows the empirical investigation of the combination of transport protocol features and compression algorithms that perform best over a lossy packet-switched network. It includes software components from the network layer (e.g., lossy router), transport layer (e.g., innovative transport protocols), and application layer (e.g., compression algorithms, browsers, etc.). We describe each component of the system and explain how the whole system is used. This paper also presents two network-conscious image compression algorithms: network conscious GIF and wavelet zerotree encoding.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> P. Amer, S. Iren, G. Sezen, P. Conrad, M. Taube, and A. Caro. </author> <title> Network-conscious GIF image transmission over the Internet. </title> <booktitle> In 4th International Workshop on High Performance Protocol Architectures (HIPPARCH'98), </booktitle> <month> June </month> <year> 1998. </year>
Reference-contexts: Sections 4 and 5 talk about two such algorithms. 4 Network-Conscious GIF We have modified the GIF89a standard to make it network-conscious. The result, called GIFNCa <ref> [1] </ref>, removes the ordered delivery requirement (and for some applications the reliability requirement) of GIF89a by framing image data at the compression phase (i.e., application level). The tradeoff between GIFNCa and GIF89a is one of compression vs. progressive display performance. GIF89a's advantage is its expected better compression.
Reference: 2. <author> D. Clark and D. Tennenhouse. </author> <title> Architectural considerations for a new generation of protocols. </title> <booktitle> In ACM SIGCOMM '90, </booktitle> <pages> pages 200-208, </pages> <address> Philadelphia, PA, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: This work also supported, in part, by ARO (DAAH04-94-G-0093). We apply the concept of network-consciousness [8] to image compression, an approach that takes network Quality of Service (QoS) into consideration when designing image compression. Network-conscious image compression is based on the philosophy of Application Level Framing (ALF) <ref> [2] </ref>. An image is divided into path-MTU-size 1 pieces, called Application Data Units (ADUs), at the application layer. Each ADU contains enough semantic information to be processed independently of all other ADUs.
Reference: 3. <author> P. Conrad, P. Amer, E. Golden, S. Iren, R. Marasli, and A. Caro. </author> <title> Transport qos over unreliable networks: No guarantees, no free lunch! In Nahrstedt Camp-bell, editor, Building QoS into Distributed Systems. </title> <publisher> Chapman and Hall, </publisher> <year> 1998. </year> <note> www.cis.udel.edu/~amer/PEL/poc/postscript/iwqos97.ps. </note>
Reference-contexts: One of the authors' motivations when designing NETCICATS was to develop a system for a hypothetical military communications system for transmitting images of either (1) wounded soldiers for telemedicine, or (2) images of equipment such as tanks, airplanes, etc. for intelligence gathering <ref> [3] </ref>. Therefore, we have run experiments primarily with military-related images such as tanks, airplanes, missiles, etc. Here are some of the author's initial observations on using NETCICATS. These observations support our hypothesis on network-conscious image compression.
Reference: 4. <author> P. Conrad, P. Amer, M. Taube, G. Sezen, S. Iren, and A. Caro. </author> <title> Testing environment for innovative transport protocols. </title> <booktitle> In MILCOM '98, </booktitle> <address> Bedford, MA, </address> <month> October </month> <year> 1998. </year> <note> (To appear). </note>
Reference-contexts: This feature allows cancellation of messages that have already been submitted to the transport layer. The application specifies an Application Data Name (ADN) for each message, and can cancel the transmission of any message (or group of messages) by specifying its (their) ADN <ref> [4] </ref>. ADN-cancel is a service that is not supported by either TCP or UDP. In the University of Delaware Protocol Engineering Lab (PEL), the image sender and image receiver run on two different stations on the same Ethernet. <p> quality and size are decided, the NETCICATS' user selects among several different transport protocols and QoS via the Universal Transport Library (UTL), a library of transport protocols that provides application programmers the ability to write to a single Application Programming Interface, then test their application with many different transport protocols <ref> [4] </ref>. UTL is a library of C functions that a programmer can link with an application. The application can then vary the transport protocol used by altering a single parameter on the "listen" call (passive open) or the "connect" call (active open).
Reference: 5. <author> C.D. Creusere. </author> <title> A family of image compression algorithms wich are robust to transmission errors. </title> <booktitle> In IS&T/SPIE Wavelet Applications in Signal and Image Processing IV, </booktitle> <volume> volume 2825, </volume> <pages> pages 890-900, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: Most of these studies are based on the idea of dividing the bitstream into several sub-streams each of which receive different amounts of error protection based on their noise sensitivity [12], or interleaving separately encoded substreams in so that any single bit error will corrupt only one substream <ref> [5, 6] </ref>. Recently, Rogers and Cosman [14] introduced a packetized zerotree encoding method on still images that produces fixed 53-byte packets and is robust against packet erasure. A similar study by Crump and Fischer [7] produced variable-length independent packets for video transmission.
Reference: 6. <author> C.D. Creusere. </author> <title> Image coding using parallel implementations of the embedded zerotree wavelet algorithm. </title> <booktitle> In IS&T/SPIE Symposium on Electronic Imaging, volume 2668, </booktitle> <address> San Jose, CA, </address> <year> 1996. </year>
Reference-contexts: Since wavelet-based image and video coding has become popular, we based our compression algorithms on wavelet transformation. Recently, several wavelet-based encoding schemes have been developed which outperform DCT-based algorithms in terms of both objective criteria (bit rate versus distortion) and subjective criteria <ref> [6] </ref>. <p> Most of these studies are based on the idea of dividing the bitstream into several sub-streams each of which receive different amounts of error protection based on their noise sensitivity [12], or interleaving separately encoded substreams in so that any single bit error will corrupt only one substream <ref> [5, 6] </ref>. Recently, Rogers and Cosman [14] introduced a packetized zerotree encoding method on still images that produces fixed 53-byte packets and is robust against packet erasure. A similar study by Crump and Fischer [7] produced variable-length independent packets for video transmission.
Reference: 7. <author> V.J. Crump and T.R. Fischer. </author> <title> Intraframe low bitrate video coding robust to packet erasure. </title> <booktitle> In DCC '97, </booktitle> <address> Snowbird, Utah, 1997. </address> <publisher> IEEE. </publisher>
Reference-contexts: Recently, Rogers and Cosman [14] introduced a packetized zerotree encoding method on still images that produces fixed 53-byte packets and is robust against packet erasure. A similar study by Crump and Fischer <ref> [7] </ref> produced variable-length independent packets for video transmission. Our algorithm differs since these previous studies do not consider progressive display. They solely optimize for robustness, and only the final image quality is a concern. Robustness is one of the primary features of network-conscious compression approach.
Reference: 8. <author> W. Dabbous and C. Diot. </author> <title> High performance protocol architecture. </title> <booktitle> In IFIP Performance of Computer Networks Conference (PCN '95), Istanbul, Turkey, </booktitle> <month> October </month> <year> 1995. </year> <pages> IFIP. </pages>
Reference-contexts: S. Army Research Laboratory under the Fed Lab Program, Agreement DAAL01-96-2 0002. This work also supported, in part, by ARO (DAAH04-94-G-0093). We apply the concept of network-consciousness <ref> [8] </ref> to image compression, an approach that takes network Quality of Service (QoS) into consideration when designing image compression. Network-conscious image compression is based on the philosophy of Application Level Framing (ALF) [2]. An image is divided into path-MTU-size 1 pieces, called Application Data Units (ADUs), at the application layer.
Reference: 9. <author> C. Diot and F. Gagnon. </author> <title> Impact of out-of-sequence processing on data transmission performance. </title> <type> Technical Report Project RODEO RR-3216, </type> <institution> INRIA - Sophia Antipolis, France, </institution> <month> July </month> <year> 1997. </year> <month> ftp://www.inria.fr/rodeo/diot/rr-oos.ps.gz. </month>
Reference-contexts: When missing ADUs finally arrive, ADUs waiting in the buffer are delivered as a group to the application. This approach makes the delivery of ADUs to the application more bursty. The burstiness may result in bottlenecks at the receiving application <ref> [9] </ref>. Another advantage of compressing an image into ADUs is that their transmission can be tailored to each ADU characteristic. Not all parts of image data are uniform and require the same QoS. For example, low frequency coefficients (i.e., important data) of a wavelet image require a reliable service.
Reference: 10. <author> S. Iren. </author> <title> Network-conscious image compression. </title> <type> PhD Dissertation, </type> <institution> CIS Dept., University of Delaware, </institution> <note> (in progress). </note>
Reference-contexts: a summary. 2 Network-Conscious Image Compression A network-conscious compressed image is one that is encoded not simply to give the smallest size for a specified image quality, but to give the best (i.e., smallest) response time image quality combination to an end user retrieving the image over a packet-switched network <ref> [10, 11] </ref>. The basic characteristics of a network-conscious compressed image are: (1) application level framing, (2) progressive display (preferably multi-layered), and (3) robustness and adaptiveness to different user needs and various networking conditions.
Reference: 11. <author> S. Iren, P. Amer, and P. Conrad. </author> <title> Network-conscious compressed images over wireless networks. </title> <booktitle> In 5th International Workshop on Interactive Distributed Multimedia Systems and Telecommu nication Services (IDMS'98), </booktitle> <address> Oslo, Norway, </address> <month> September </month> <year> 1998. </year>
Reference-contexts: a summary. 2 Network-Conscious Image Compression A network-conscious compressed image is one that is encoded not simply to give the smallest size for a specified image quality, but to give the best (i.e., smallest) response time image quality combination to an end user retrieving the image over a packet-switched network <ref> [10, 11] </ref>. The basic characteristics of a network-conscious compressed image are: (1) application level framing, (2) progressive display (preferably multi-layered), and (3) robustness and adaptiveness to different user needs and various networking conditions. <p> ADUs permit the use of a more efficient transport protocol that does not need to preserve order. Having simpler transport protocols is especially important for wireless environments because of their hosts' limited power supply <ref> [11] </ref>. Assuming some loss, the expected buffer requirements at the transport receiver for an unordered protocol are always less than the buffer requirements for ordered protocols [13]. Furthermore, out-of-order delivery of ADUs reduces the jitter at the receiving application.
Reference: 12. <author> S.H. Man and F. Kossentini. </author> <title> Robust EZW image coding for noisy channels. </title> <journal> IEEE Signal Processing Letters, </journal> <volume> 4(8) </volume> <pages> 227-229, </pages> <month> August </month> <year> 1997. </year>
Reference-contexts: Recent studies concentrate on composing noise-robust zerotree encoders. Most of these studies are based on the idea of dividing the bitstream into several sub-streams each of which receive different amounts of error protection based on their noise sensitivity <ref> [12] </ref>, or interleaving separately encoded substreams in so that any single bit error will corrupt only one substream [5, 6]. Recently, Rogers and Cosman [14] introduced a packetized zerotree encoding method on still images that produces fixed 53-byte packets and is robust against packet erasure.
Reference: 13. <author> R. Marasli, P. Amer, and P. Conrad. </author> <title> An analytic model of partially ordered transport service. </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> 29(6) </volume> <pages> 675-699, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: Having simpler transport protocols is especially important for wireless environments because of their hosts' limited power supply [11]. Assuming some loss, the expected buffer requirements at the transport receiver for an unordered protocol are always less than the buffer requirements for ordered protocols <ref> [13] </ref>. Furthermore, out-of-order delivery of ADUs reduces the jitter at the receiving application. In ordered transport protocols, ADUs that are received out-of-order are kept in the buffers. When missing ADUs finally arrive, ADUs waiting in the buffer are delivered as a group to the application.
Reference: 14. <author> J. Rogers and P. Cosman. </author> <title> Robust wavelet zerotree image compression with fixed-length packetization. </title> <booktitle> In Data Compression Conference (DCC'98), </booktitle> <month> March </month> <year> 1998. </year>
Reference-contexts: Recently, Rogers and Cosman <ref> [14] </ref> introduced a packetized zerotree encoding method on still images that produces fixed 53-byte packets and is robust against packet erasure. A similar study by Crump and Fischer [7] produced variable-length independent packets for video transmission. Our algorithm differs since these previous studies do not consider progressive display.
Reference: 15. <author> A. </author> <title> Said and W.A. Pearlman. A new, fast, and efficient image codec based on set partitioning in hierarchical trees. </title> <type> 6(3), </type> <month> June </month> <year> 1996. </year>
Reference-contexts: We want to see how different compression techniques behave when combined with different transport QoS at different loss rates. In phase two of our research, we modified two popular image compression techniques, namely GIF89a 2 and SPIHT <ref> [15] </ref> (wavelet zerotree encoding), to make them network-conscious. <p> Furthermore, a decoder can stop decoding at any point in the bit stream, and still produce exactly the same image that would have been encoded at the bit rate corresponding to the truncated bit rate. Set Partitioning in Hierarchical Trees (SPIHT), introduced by Said and Pearl-man <ref> [15] </ref> as a refinement to EZW, differs from EZW in the way subsets of coefficients are partitioned and in the way significance information is conveyed. Fig. 6. <p> Fig. 6. Comparison of GIF89a and GIFNCa at Various Loss Rates SPIHT is so effective that even binary uncoded transmission achieves about the same or better performance than EZW <ref> [15] </ref>. Both EZW and SPIHT are highly state-dependent, and therefore susceptible to bit errors. Even a single bit error ruins the decoding process thereby destroying an entire image. Recent studies concentrate on composing noise-robust zerotree encoders.
Reference: 16. <author> J. Shapiro. </author> <title> Embedded image coding using zerotrees of wavelet coefficients. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 41(12) </volume> <pages> 3445-3462, </pages> <month> December </month> <year> 1993. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: anomalies and trends can be analyzed on an equal footing." This framework is important in image processing because, "edges, which can be thought of as anomalies in the spatial domain, represent extremely important information despite the fact that they are represented in only a tiny fraction of the image samples" <ref> [16] </ref>. sender, (2) an image receiver, (3) a lossy router, and (4) a reflector. Fig. 1. Network-Conscious Image Compression and Transmission System The image sender allows a user to flexibly control an image's quality and size, and the transport QoS between server and client. <p> 5 Network-Conscious Wavelet Zerotree Encoding Wavelet zerotree encoding is based on the hypothesis that, at a given threshold level, if a wavelet coefficient at a coarse scale is insignificant, then all wavelet coefficients of the same orientation in the same spatial location at finer scales are likely to be insignificant <ref> [16] </ref>. The embedded zerotree (EZW) encoding, originally introduced by Shapiro [16], has been proven to be a very efficient yet not complex encoding scheme. <p> on the hypothesis that, at a given threshold level, if a wavelet coefficient at a coarse scale is insignificant, then all wavelet coefficients of the same orientation in the same spatial location at finer scales are likely to be insignificant <ref> [16] </ref>. The embedded zerotree (EZW) encoding, originally introduced by Shapiro [16], has been proven to be a very efficient yet not complex encoding scheme. The embedded nature of the algorithm, a representation in which a high resolution image contains all coarser resolutions, effectively sorts bits in order of importance, thus yielding an effective progressive display when transmitted over low-bandwidth networks.
References-found: 16

