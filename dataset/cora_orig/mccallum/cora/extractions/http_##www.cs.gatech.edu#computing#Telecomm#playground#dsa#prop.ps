URL: http://www.cs.gatech.edu/computing/Telecomm/playground/dsa/prop.ps
Refering-URL: http://www.cs.gatech.edu/computing/Telecomm/playground/dsa/index.html
Root-URL: 
Title: Structuring and Destructuring Protocols  
Degree: A Dissertation Proposal Presented to The Faculty of the Division of Graduate Studies by R. Clayton In Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy in Computer Science  
Note: Copyright c 1997 by R. Clayton  
Date: January 1997  
Affiliation: College of Computing Georgia Institute of Technology  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> Mark B. Abbott and Larry L. Peterson. </author> <title> A language-based approach to protocol implementation. </title> <journal> Computer Communications Review (SIGCOMM '92 Proceedings), </journal> <volume> 23(4) </volume> <pages> 27-38, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: As a result of problems like those given in the previous paragraph, the x -kernel developers rethought the object-oriented aspects of protocol development and came up with Morpheus, an object-oriented language intended to support protocol development <ref> [1] </ref>. Morpheus rigidly defined the object interface, constraining the protocol developer's externally visible actions, which is expected to have benefits both for insuring compatibility among independently developed objects and allowing inter-object optimizations.
Reference: [2] <author> Harold Abelson, Gerald Jay Sussman, and Julie Sussman. </author> <title> Structure and Interpretation of Computer Programs. </title> <publisher> The MIT Electrical Engineering and Computer Science Series. MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1985. </year>
Reference-contexts: Functional programming languages, particularly those supporting lazy evaluation, can quite naturally implement data-stream computations using lists [11]. Lisp, another language with strong list-processing support, can also comfortably and profitably implement data-stream computations <ref> [2] </ref>. The interest in iterators in object-oriented languages indicates of the value of having data-stream-like computations [27]; also, the difficulty of implementing a general-purpose iterator indicates the subtleties involved with defining and implementing mechanisms for data-stream computations.
Reference: [3] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers, Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1986. </year>
Reference-contexts: The third set of transformations go from imperative code to code suitable for the host-machine architecture. Here too, as in the imperative-to-imperative transformations, more or less standard techniques are used <ref> [3] </ref>, but the data-stream code and its application to protocols allow for fine tuning. For example, many protocol manipulations are byte-by-byte, e.g. message digest functions. <p> Proebsting and Watterson have developed a fusion algorithm that combines adjacent co-routines into a single co-routine, eliminating the common buffer [34]. Repeated applications of the fusion algorithm to a pipeline results in a single co-routine The compiler uses the Proebsting/Watterson fusion algorithm surrounded by standard compiler technology <ref> [3] </ref>. The compiler consists of a front-end and a back end. The front end translates the data-stream programs into an intermediate form, fuses each pipeline into a procedure into conventional control and data structures, and flags them so the data-stream-related parts can be recognized by the back end.
Reference: [4] <author> John Backus. </author> <title> Can programming be liberated from the Von Neuman style? Communications of the ACM, </title> <booktitle> 21(8) </booktitle> <pages> 613-237, </pages> <month> August </month> <year> 1978. </year>
Reference-contexts: Files are one example of a near-data-stream type, as are lists and variable-length vectors. Data streams are useful in programming formalizations. Landin used data streams to help explain parameter passing in Algol 60 [28]. Backus and others have developed an algebra for 9 manipulating the FP programming language <ref> [4] </ref>; Bird, concentrating on lists themselves, has developed a powerful and expressive calculus of lists [9]. Programming languages provide varying levels of support for data streams and their computations. Again, the value of directly supporting data stream computations was recognized early [26].
Reference: [5] <author> David F. Bacon, Susan L. Graham, and Oliver J. Sharp. </author> <title> Compiler transformations for high-performance computing. </title> <journal> ACM Computing Surveys, </journal> <volume> 26(4) </volume> <pages> 345-420, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: The second set of transformations go from imperative code to imperative code. These translations can be thought of as source-to-source transformations implementing host-independent optimizations. These optimizations are drawn from the standard set of high-level compiler optimizations <ref> [5] </ref>. An interesting aspect of this work is tailoring the optimizations to take advantage of the information derived from the data-steam origins of the code.
Reference: [6] <author> Subodh Bapat. </author> <title> Object-Oriented Networks: Models for Architecture, Operations, and Management. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1994. </year>
Reference-contexts: This compromises the ability to assemble individually developed protocols into a graph, and tends to frustrate optimizations due to uncertain semantics. 4.1.2 Object-Oriented Efforts for Protocol Software Structuring Not surprisingly, object-oriented techniques have drawn the attention of those interested in protocol structuring issues <ref> [6] </ref>. The interest ranges from adapting current object-oriented languages for protocol development to creating new object-oriented languages specifically to support protocol development. One issue overarching all these interests is generating efficient code [35]. The most popular object-oriented language suitable for wide-spread protocol development is C ++ [19].
Reference: [7] <author> Brian N. Bershad, Stefan Savage, Przemyslaw Pardyak, Emin Gun Sirer, Marc E. Fiuczynski, David Becker, Craig Chambers, and Susan Eggers. </author> <title> Extensibility, safety and performance in the SPIN operating system. </title> <booktitle> Operating Systems Review (Proceedings of the Fifteenth ACM Symposium on Operating Systems Principles), </booktitle> <volume> 29(5) </volume> <pages> 267-284, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: Although concerned with the full set of system software, initial work in the Fox Project has concentrated on protocol software and, in particular, TCP/IP [8]. SPIN, undergoing development at the University of Washington, also applies a modern programming language to systems development <ref> [7] </ref>. The objectives of the project are similar to those of the Fox Project, but SPIN places a greater emphasis on being able to move code into and out of the operating system kernel to enhance performance. SPIN uses Modula-3 as its system implementation language [33].
Reference: [8] <author> Edoardo Biagioni. </author> <title> A structured TCP in Standard ML. </title> <journal> Computer Communications Review (SIG-COMM '94 Proceedings), </journal> <volume> 24(4) </volume> <pages> 36-45, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: The SML used in the project has been extended to include continuations, providing extended control structures, and threads, providing concurrent execution. Although concerned with the full set of system software, initial work in the Fox Project has concentrated on protocol software and, in particular, TCP/IP <ref> [8] </ref>. SPIN, undergoing development at the University of Washington, also applies a modern programming language to systems development [7].
Reference: [9] <author> Richard S. Bird. </author> <title> An introduction to the theory of lists. </title> <editor> In Manfred Broy, editor, </editor> <booktitle> Logic of Programming and Calculi of Discrete Design, volume 36 of Computer and Systems Science, </booktitle> <pages> pages 5-42, </pages> <address> Berlin, Germany, 29 July-10 August 1986. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Data streams are useful in programming formalizations. Landin used data streams to help explain parameter passing in Algol 60 [28]. Backus and others have developed an algebra for 9 manipulating the FP programming language [4]; Bird, concentrating on lists themselves, has developed a powerful and expressive calculus of lists <ref> [9] </ref>. Programming languages provide varying levels of support for data streams and their computations. Again, the value of directly supporting data stream computations was recognized early [26].
Reference: [10] <author> Per Brinch Hansen. </author> <title> Joyce a programming language for distributed systems. </title> <journal> Software|Practice And Experience, </journal> <volume> 17(1) </volume> <pages> 29-50, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: While not supporting data streams directly, concurrent programming languages support many of the features needed to implement data stream computations. This support is perhaps most obvious in the CSP family of languages, including CSP itself [23], Joyce <ref> [10] </ref>, and occam [39]. Most general purpose programming languages do not support data stream computations, but many languages support structures similar to data streams, such structures include lists or dynamic vectors. Functional programming languages, particularly those supporting lazy evaluation, can quite naturally implement data-stream computations using lists [11].
Reference: [11] <author> W. H. Burge. </author> <title> Stream processing functions. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 19(1) </volume> <pages> 12-25, </pages> <month> January </month> <year> 1975. </year>
Reference-contexts: Most general purpose programming languages do not support data stream computations, but many languages support structures similar to data streams, such structures include lists or dynamic vectors. Functional programming languages, particularly those supporting lazy evaluation, can quite naturally implement data-stream computations using lists <ref> [11] </ref>. Lisp, another language with strong list-processing support, can also comfortably and profitably implement data-stream computations [2].
Reference: [12] <author> Kenneth L. Calvert. </author> <title> Beyond layering: Modularity considerations for protocol architectures. </title> <booktitle> In International Conference on Network Protocols, </booktitle> <pages> pages 90-97, </pages> <address> San Francisco, Calif., 19-22 October 1993. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Implementations supporting the claims made for a data-stream architecture can be done stand-alone in user space. However, even more convincing support comes about when the data-stream architecture is part of a larger protocol subsystem. For example, data streams could be added to Transport and Up (tau) protocol subsystem <ref> [12] </ref>. Tau represents a good choice because it emphasizes the control aspects of protocol processing, in contrast to the data-handling aspects emphasized by data streams. Another possibility would be to make data streams the core of a system supporting application-layer framing (ALF) [13].
Reference: [13] <author> David D. Clark and David L. Tennenhouse. </author> <title> Architectural considerations for a new generation of protocols. </title> <booktitle> In SIGCOMM '90 Symposium on Communication Architectures and Protocols, </booktitle> <pages> pages 200-208, </pages> <address> Philadelphia, Penn., </address> <month> 24-27 September </month> <year> 1990. </year> <note> ACM Press. </note>
Reference-contexts: Tau represents a good choice because it emphasizes the control aspects of protocol processing, in contrast to the data-handling aspects emphasized by data streams. Another possibility would be to make data streams the core of a system supporting application-layer framing (ALF) <ref> [13] </ref>. The result of hosting would be a complete protocol subsystem using data streams as its principle data-touching mechanism.
Reference: [14] <author> I. A. Clark. STREMA: </author> <title> Specifying application processes using streams. </title> <journal> The Computer Journal, </journal> <volume> 21(1) </volume> <pages> 25-30, </pages> <year> 1978. </year>
Reference-contexts: Data structures most obviously demonstrate the importance of streams. Many common data processing tasks can be expressed in terms of successively transforming a sequence of data items <ref> [14] </ref>. Structuring programs to run as if they were operating on data streams has long been recognized as a useful software structuring technique [16]. The prevalence of pipe-and-filter patterns in software architectures [22] indicates the continued importance of data stream structuring in program design.
Reference: [15] <author> Douglas E. Comer and John C. Lin. </author> <title> Probing TCP implementations. </title> <booktitle> In Proceedings of the USENIX Summer Technical Conference, </booktitle> <pages> pages 245-255, </pages> <address> Boston, Mass., </address> <month> 6-10 June </month> <year> 1994. </year>
Reference-contexts: This no-win situation isn't enough to frustrate protocol development, but it does mean the widely accepted, working protocols generally either perform simple functions (the Macintosh AppleTalk protocols [37], for example) or have gone through a decades long beta test (see <ref> [15] </ref> for example). This paper proposes a solution to the structure/performance trade-off (chapter 2) and describes the main ideas used (chapter 3).
Reference: [16] <author> Melvin E. Conway. </author> <title> Design of a separable transition-diagram compiler. </title> <journal> Communications of the ACM, </journal> <volume> 6(7) </volume> <pages> 396-408, </pages> <month> July </month> <year> 1964. </year> <month> 24 </month>
Reference-contexts: Many common data processing tasks can be expressed in terms of successively transforming a sequence of data items [14]. Structuring programs to run as if they were operating on data streams has long been recognized as a useful software structuring technique <ref> [16] </ref>. The prevalence of pipe-and-filter patterns in software architectures [22] indicates the continued importance of data stream structuring in program design. While few languages provide direct support for data streams themselves, many languages support near-data-stream types. Files are one example of a near-data-stream type, as are lists and variable-length vectors.
Reference: [17] <author> Eric Cooper, Robert Harper, and Peter Lee. </author> <title> The Fox project: Advanced development of systems software. </title> <type> Technical Report CMU-CS-91-178, </type> <institution> School of Computer Science, Carnegie Mellon University, Pittsburgh, Penn., </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: The Fox Project began at Carnegie Mellon University as an experiment to determine if a modern, high-level programming language could serve as a systems implementation language <ref> [17] </ref>. The project has two objectives: to determine how the features of a modern programming language | such as polymorphism and first-order modules | might help systems developers. The second objective is to determine how the extra structure imposed by the language can be exploited to generate efficient code.
Reference: [18] <author> Jack B. Dennis. </author> <title> Stream data types for signal processing. Computation Structures Group Memo 362, </title> <institution> Laboratory for Computer Science, Massachusetts Institute of Technology, </institution> <address> Cambridge, Mass., </address> <month> 27 October </month> <year> 1994. </year>
Reference-contexts: Again, the value of directly supporting data stream computations was recognized early [26]. Direct support is likely to be found in special purpose programming languages associated with areas in which data stream computations are most natural; such areas include business data processing and signal processing <ref> [18] </ref>. While not supporting data streams directly, concurrent programming languages support many of the features needed to implement data stream computations. This support is perhaps most obvious in the CSP family of languages, including CSP itself [23], Joyce [10], and occam [39].
Reference: [19] <author> Margaret A. Ellis and Bjarne Stroustrup. </author> <title> The Annotated C++ Reference Manual. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1990. </year>
Reference-contexts: The interest ranges from adapting current object-oriented languages for protocol development to creating new object-oriented languages specifically to support protocol development. One issue overarching all these interests is generating efficient code [35]. The most popular object-oriented language suitable for wide-spread protocol development is C ++ <ref> [19] </ref>. Lavender has looked at the issues involved in establishing in C ++ object-oriented mechanisms suitable for layered protocol development [29]. These mechanisms are based on lambda functions for concurrency and type structures for protocol implementation layers.
Reference: [20] <author> Marc E. Fiuczynski and Brian N. Bershad. </author> <title> An extensible protocol architecture for application-specific networking. </title> <booktitle> In USENIX Winter Conference, </booktitle> <address> San Diego, California, </address> <month> 22-26 January </month> <year> 1996. </year>
Reference-contexts: SPIN uses Modula-3 as its system implementation language [33]. Modula-3 is a procedural, general purpose programming language with features such as a module system, polymorphism, objects, threads, and garbage collection. Plexus is the part of SPIN concerned with protocol programming <ref> [20] </ref>. Protocol code in Plexus is organized as a protocol graph similar to that used in the x -kernel.
Reference: [21] <author> Christopher W. Fraser, Eugene W. Myers, and Alan L. Wendt. </author> <title> Analyzing and compressing assembly code. </title> <booktitle> ACM SIGPLAN Notices (Proceedings of the '84 Symposium on Compiler Construction), </booktitle> <volume> 19(6) </volume> <pages> 117-121, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: An interesting aspect of this work is tailoring the optimizations to take advantage of the information derived from the data-steam origins of the code. For example, the current translations from data-stream code to imperative code introduces large sections of replicated 11 code; this may make anti-inlining optimization techniques <ref> [21] </ref> more valuable then they usually are the standard optimization suites. The third set of transformations go from imperative code to code suitable for the host-machine architecture.
Reference: [22] <author> David Garlan and Mary Shaw. </author> <title> An introduction to software architecture. </title> <booktitle> In Advances in Software Engineering and Knowledge Engineering. </booktitle> <publisher> World Scientific Publishing Co., </publisher> <year> 1993. </year>
Reference-contexts: Structuring programs to run as if they were operating on data streams has long been recognized as a useful software structuring technique [16]. The prevalence of pipe-and-filter patterns in software architectures <ref> [22] </ref> indicates the continued importance of data stream structuring in program design. While few languages provide direct support for data streams themselves, many languages support near-data-stream types. Files are one example of a near-data-stream type, as are lists and variable-length vectors. Data streams are useful in programming formalizations.
Reference: [23] <author> C. A. R. Hoare. </author> <title> Communicating Sequential Processes. </title> <booktitle> International Series in Computer Science. </booktitle> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1985. </year>
Reference-contexts: While not supporting data streams directly, concurrent programming languages support many of the features needed to implement data stream computations. This support is perhaps most obvious in the CSP family of languages, including CSP itself <ref> [23] </ref>, Joyce [10], and occam [39]. Most general purpose programming languages do not support data stream computations, but many languages support structures similar to data streams, such structures include lists or dynamic vectors. Functional programming languages, particularly those supporting lazy evaluation, can quite naturally implement data-stream computations using lists [11].
Reference: [24] <author> Norman C. Hutchinson and Larry L. Peterson. </author> <title> The x -kernel: An architecture for implementing network protocols. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(1) </volume> <pages> 64-75, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Streams currently doesn't perform any inter- or intra-module optimizations, and the dynamic nature of Streams protocols mitigates against such optimizations. The x -kernel protocol subsystem <ref> [24] </ref> is one of the more successful attempts at striking a balance between performance and structure in protocol code.
Reference: [25] <author> Barton S. Kaliski Jr. </author> <title> The MD2 message-digest algorithm. Request for Comments 1319, RSA Data Security, </title> <month> April </month> <year> 1992. </year>
Reference-contexts: A message-digest function is a hash function that reduces a byte vector of arbitrary length into a small, fixed-sized byte vector. MD2 <ref> [25] </ref> is one of a family of message-digest functions defined by RSA Inc. <p> The reference implementation md2ref is taken from the appendix of <ref> [25] </ref>; the other implementation is a fully fused version of the p2 pipeline. Given the code generation and optimization problems described in the previous section, it is not surprising that the reference implementation is the faster of the two versions of MD2.
Reference: [26] <author> John L. Kelly, Jr., Carol Lochbaum, and V. A. Vyssotsky. </author> <title> A block diagram compiler. </title> <journal> Bell System Technical Journal, </journal> <volume> 40 </volume> <pages> 669-676, </pages> <month> May </month> <year> 1961. </year>
Reference-contexts: Programming languages provide varying levels of support for data streams and their computations. Again, the value of directly supporting data stream computations was recognized early <ref> [26] </ref>. Direct support is likely to be found in special purpose programming languages associated with areas in which data stream computations are most natural; such areas include business data processing and signal processing [18]. <p> Because of its simplicity, work on translating a data-stream language to co-routines in an Imperative language is quite common, appearing in one of the earliest attempts at translating data-stream computations <ref> [26] </ref>. There also has been some work on translating a data-stream language directly into an imperative language, although such work usually places restrictions on how data-stream computations may be interconnected [32] or the internal structure of a data-stream computation [41].
Reference: [27] <author> T. Kofler. </author> <title> Robust iterators in ET++. </title> <journal> Structured Programming, </journal> <volume> 14(2) </volume> <pages> 62-85, </pages> <year> 1993. </year>
Reference-contexts: Functional programming languages, particularly those supporting lazy evaluation, can quite naturally implement data-stream computations using lists [11]. Lisp, another language with strong list-processing support, can also comfortably and profitably implement data-stream computations [2]. The interest in iterators in object-oriented languages indicates of the value of having data-stream-like computations <ref> [27] </ref>; also, the difficulty of implementing a general-purpose iterator indicates the subtleties involved with defining and implementing mechanisms for data-stream computations.
Reference: [28] <author> P. J. Landin. </author> <title> A correspondence between ALGOL 60 and Church's lambda-notation: Part I. </title> <journal> Communications of the ACM, </journal> <volume> 8(2) </volume> <pages> 89-101, </pages> <month> February </month> <year> 1965. </year>
Reference-contexts: While few languages provide direct support for data streams themselves, many languages support near-data-stream types. Files are one example of a near-data-stream type, as are lists and variable-length vectors. Data streams are useful in programming formalizations. Landin used data streams to help explain parameter passing in Algol 60 <ref> [28] </ref>. Backus and others have developed an algebra for 9 manipulating the FP programming language [4]; Bird, concentrating on lists themselves, has developed a powerful and expressive calculus of lists [9]. Programming languages provide varying levels of support for data streams and their computations.
Reference: [29] <author> R. Gregory Lavender. </author> <title> Polymorphic Types for Constructing Concurrent Objects and Layered Communication Protocols. </title> <type> PhD thesis, </type> <institution> Virginia Polytechnic Institute and State University, Blacksburg, Virginia, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: One issue overarching all these interests is generating efficient code [35]. The most popular object-oriented language suitable for wide-spread protocol development is C ++ [19]. Lavender has looked at the issues involved in establishing in C ++ object-oriented mechanisms suitable for layered protocol development <ref> [29] </ref>. These mechanisms are based on lambda functions for concurrency and type structures for protocol implementation layers. Both mechanisms use polymorphism and inheritance to share structure and information among the protocol implementation entities. The x -kernel developers noticed some structuring difficulties arising from their quasi-object-oriented approach. <p> The data-stream architecture. This work as argued for and developed a data-stream architecture for protocols. A lightly explored area in protocol software development, data-stream architectures offer easier optimization targets and a clearer separation between data and control issues than do object-oriented architectures such as adaptive [36] and Lavender's work <ref> [29] </ref>. The data-stream architecture, as used in this work, is smaller in scope and simpler in execution than are whole-language approaches such as the Fox Project and Plexus/Spin. 2. The data-stream compiler. This work has instantiated the data-stream architecture as a language and compiler.
Reference: [30] <author> R. Milner, M. Tofte, and R. Harper. </author> <title> The Definition of Standard ML. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1990. </year>
Reference-contexts: The second objective is to determine how the extra structure imposed by the language can be exploited to generate efficient code. The Fox Project uses the Standard Metalanguage (SML) as the systems implementation language <ref> [30] </ref>. SML is a functional programming language with features that include first-order functions, polymorphism, exceptions, and a module system. The SML used in the project has been extended to include continuations, providing extended control structures, and threads, providing concurrent execution.
Reference: [31] <author> Ikuo Nakata and Masataka Sassa. </author> <title> Programming with streams. </title> <type> Technical Report RJ 3751, </type> <institution> IBM Research Laboratory, </institution> <address> San Jose, California, </address> <month> 18 January </month> <year> 1983. </year>
Reference-contexts: output values will be written; the return value of the function is a pointer to the byte immediately following the last byte written in dst. 5.2 The Compiler The general compilation technique for data streams is to translate pipeline of data-stream functions into a set of co-routines and a scheduler <ref> [31] </ref>. Each data-stream function is translated 14 into a co-routine, and adjacent stream functions in a pipeline share a fixed-length buffer. Each co-routine executes until it's blocked by either an empty input buffer or a full output buffer.
Reference: [32] <author> Ikuo Nakata and Masataka Sassa. </author> <title> Programming with streams in a Pascal-like language. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(1) </volume> <pages> 1-9, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: There are a number of techniques to translate data-stream code into executable code <ref> [32] </ref>. One technique is to translate data stream code into a concurrent language, with each stream function being mapped into to a process and each data streams being mapped into the language's inter-process communication mechanism. <p> There also has been some work on translating a data-stream language directly into an imperative language, although such work usually places restrictions on how data-stream computations may be interconnected <ref> [32] </ref> or the internal structure of a data-stream computation [41]. The second set of transformations go from imperative code to imperative code. These translations can be thought of as source-to-source transformations implementing host-independent optimizations. These optimizations are drawn from the standard set of high-level compiler optimizations [5].
Reference: [33] <author> Greg Nelson. </author> <title> Systems Programming with Modula-3. Series in Innovative Technology. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1991. </year>
Reference-contexts: The objectives of the project are similar to those of the Fox Project, but SPIN places a greater emphasis on being able to move code into and out of the operating system kernel to enhance performance. SPIN uses Modula-3 as its system implementation language <ref> [33] </ref>. Modula-3 is a procedural, general purpose programming language with features such as a module system, polymorphism, objects, threads, and garbage collection. Plexus is the part of SPIN concerned with protocol programming [20].
Reference: [34] <author> Todd A. Proebsting and Scott A. Watterson. </author> <title> Filter fusion. </title> <booktitle> In Symposium on Principles of Programming Languages, </booktitle> <pages> pages 119-129, </pages> <address> St. Petersburg, Flordia, </address> <year> 1996. </year>
Reference-contexts: The scheduler also detects termination, either normally or through deadlock. Although conceptually simple, the co-routine implementation is unacceptably inefficient due to excessive data copying. Proebsting and Watterson have developed a fusion algorithm that combines adjacent co-routines into a single co-routine, eliminating the common buffer <ref> [34] </ref>. Repeated applications of the fusion algorithm to a pipeline results in a single co-routine The compiler uses the Proebsting/Watterson fusion algorithm surrounded by standard compiler technology [3]. The compiler consists of a front-end and a back end.
Reference: [35] <author> Doglas Schmidt, Tim Harrison, and Ehab Al-Shaer. </author> <title> Object-oriented programming for high-speed network programming. </title> <booktitle> In USENIX Conference on Object-Oriented Technologies, </booktitle> <address> Monterey, Califor-nia, </address> <month> 26-29 June </month> <year> 1995. </year> <month> 25 </month>
Reference-contexts: The interest ranges from adapting current object-oriented languages for protocol development to creating new object-oriented languages specifically to support protocol development. One issue overarching all these interests is generating efficient code <ref> [35] </ref>. The most popular object-oriented language suitable for wide-spread protocol development is C ++ [19]. Lavender has looked at the issues involved in establishing in C ++ object-oriented mechanisms suitable for layered protocol development [29].
Reference: [36] <author> Douglas C. Schmidt, Donald F. Box, and Tatsuya Suda. </author> <title> ADAPTIVE: A dynamically assembled protocol transformation, integration, and evaluation environment. </title> <journal> Journal of Concurrency: Practice and Experience, </journal> <volume> 5(4) </volume> <pages> 269-286, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: The data-stream architecture. This work as argued for and developed a data-stream architecture for protocols. A lightly explored area in protocol software development, data-stream architectures offer easier optimization targets and a clearer separation between data and control issues than do object-oriented architectures such as adaptive <ref> [36] </ref> and Lavender's work [29]. The data-stream architecture, as used in this work, is smaller in scope and simpler in execution than are whole-language approaches such as the Fox Project and Plexus/Spin. 2. The data-stream compiler. This work has instantiated the data-stream architecture as a language and compiler.
Reference: [37] <author> Grusharan S. Sidhu, Richard F. Andrews, and Alan B. Oppenheimer. </author> <title> Inside AppleTalk. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1989. </year>
Reference-contexts: This no-win situation isn't enough to frustrate protocol development, but it does mean the widely accepted, working protocols generally either perform simple functions (the Macintosh AppleTalk protocols <ref> [37] </ref>, for example) or have gone through a decades long beta test (see [15] for example). This paper proposes a solution to the structure/performance trade-off (chapter 2) and describes the main ideas used (chapter 3).
Reference: [38] <author> Richard M. Stallman. </author> <title> Using and Porting GNU CC (ver. 2.7). Free Software Foundation, </title> <address> Cambridge, Mass., </address> <month> 14 June </month> <year> 1995. </year>
Reference-contexts: The compiler has two back ends, each differing from the other in the type of code analysis done and the output produced. One back end | the high-level back end | does host-architecture independent analysis and produces Gnu extended ANSI C code <ref> [38] </ref>. The other, low-level back end does host-architecture specific analysis and produces assembly code. The high-level back end performs host-architecture independent optimizations such as code motion and loop fusion.
Reference: [39] <author> Andrew M. Tyrrell and David J. Holding. </author> <title> Design of reliable software in distributed systems using the conversion scheme. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-12(9):921-928, </volume> <month> September </month> <year> 1986. </year>
Reference-contexts: While not supporting data streams directly, concurrent programming languages support many of the features needed to implement data stream computations. This support is perhaps most obvious in the CSP family of languages, including CSP itself [23], Joyce [10], and occam <ref> [39] </ref>. Most general purpose programming languages do not support data stream computations, but many languages support structures similar to data streams, such structures include lists or dynamic vectors. Functional programming languages, particularly those supporting lazy evaluation, can quite naturally implement data-stream computations using lists [11].
Reference: [40] <author> Unix Press. </author> <title> STREAMS Modules and Drivers, </title> <year> 1992. </year>
Reference-contexts: Streams is a protocol subsystem originally developed for Unix <ref> [40] </ref>. It began as a way of giving programs control over I/O; a program implemented various tty line disciplines by pushing and popping code on a kernel-resident processing stack. Adding the ability to multiplex data and control among several processing stacks makes Streams suitable for network protocol processing.
Reference: [41] <author> Richard C. Waters. </author> <title> Automatic transformation of series expressions into loops. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(1) </volume> <pages> 52-98, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: There also has been some work on translating a data-stream language directly into an imperative language, although such work usually places restrictions on how data-stream computations may be interconnected [32] or the internal structure of a data-stream computation <ref> [41] </ref>. The second set of transformations go from imperative code to imperative code. These translations can be thought of as source-to-source transformations implementing host-independent optimizations. These optimizations are drawn from the standard set of high-level compiler optimizations [5].
Reference: [42] <author> Martina Zitterbart and Ahmed N. Tantawy. </author> <title> Transport service and protocols for high-speed networks. </title> <editor> In Kadiresan Annamalai, editor, </editor> <booktitle> Proceedings of the Conference on High-Speed Fiber Networks and Channels, </booktitle> <volume> volume 1577, </volume> <pages> pages 266-275, </pages> <address> Boston, Mass., </address> <month> 4-6 September </month> <year> 1991. </year> <journal> Society of Photo-Optical Instrumentation Engineers. </journal> <volume> 26 </volume>
Reference-contexts: Inefficiently implemented protocol code is only one of the many factors degrading protocol performance. Other factors include, for example, the operating system in which the protocol runs, 2 the hardware interface shuttling packets between the protocol and the network, and occasion-ally even the protocol itself <ref> [42] </ref>.
References-found: 42

