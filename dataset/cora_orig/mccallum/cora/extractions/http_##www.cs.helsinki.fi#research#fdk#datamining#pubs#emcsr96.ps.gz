URL: http://www.cs.helsinki.fi/research/fdk/datamining/pubs/emcsr96.ps.gz
Refering-URL: http://www.cs.helsinki.fi/research/pmdm/datamining/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Hannu.Toivonen@Helsinki.FI  
Title: On an algorithm for finding all interesting sentences Extended abstract  
Author: Heikki Mannila Hannu Toivonen 
Web: mannila@mpi-sb.mpg.de  
Address: D-66123 Saarbrucken, Germany  FIN-00014 Helsinki, Finland  
Affiliation: MPI Informatik Im Stadtwaldt  University of Helsinki Department of Computer Science  
Abstract: Knowledge discovery in databases (KDD), also called data mining, has recently received wide attention from practitioners and researchers. One of the basic problems in KDD is the following: given a data set r, a class L of sentences defining subgroups or properties of r, and an interestingness predicate, find all sentences of L deemed interesting by the interestingness predicate. In this paper we analyze a simple and well-known levelwise algorithm for finding all such descriptions. We give bounds for the number of database accesses that the algorithm makes. We also consider the verification problem of a KDD process: given r and a set of sentences T L, determine whether T is exactly the set of interesting statements about r. We show strong connections between the verification problem and the hypergraph transversal problem. The verification problem arises in a natural way when using sampling to speed up the pattern discovery step in KDD.
Abstract-found: 1
Intro-found: 1
Reference: [ 1 ] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Mining association rules between sets of items in large databases. </title> <booktitle> In Proceedings of ACM SIG-MOD Conference on Management of Data (SIG-MOD'93), </booktitle> <pages> pages 207 - 216, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: For the above formulation to make sense, the language L has to be defined carefully. Example 1 Given a relation r with n rows over binary-valued attributes R, an association rule <ref> [ 1 ] </ref> is an expression of the form X ) A, where X R and A 2 R.
Reference: [ 2 ] <author> R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and A. I. Verkamo. </author> <title> Fast discovery of association rules. </title> <editor> In U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, editors, </editor> <booktitle> Advances in Knowledge Discovery and Data Mining. </booktitle> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: The roots of this approach are in the use of diagrams of models in model theory (see, e.g., [ 5 ] ). The approach has been used in various forms for example in <ref> [ 2; 6; 7; 13; 15; 18 ] </ref> One should note that in contrast with, e.g., [ 6 ] our emphasis is on very simple representation languages. <p> A set X R is frequent, if s (X) exceeds the given threshold; for variations of the algorithm, see <ref> [ 2 ] </ref> and references there. The problem of finding all frequent sets can be described in our framework as follows. The description language L consists of all subsets X of elements of R. <p> The central idea is to start from the most general sentences, and then to generate and evaluate more and more special predicates, but not to generate those candidate sentences that cannot be interesting given all the information obtained in earlier iterations <ref> [ 2; 22 ] </ref> . The method is as follows. Algorithm 3 The levelwise algorithm for finding all interesting statements. Input: A database r, a language L with specialization relation , and a quality function q. Output: The set T h (L; r; q). Method: 1. <p> Note that the computation to determine the candidate collection does not involve the database (Step 5). For example, in computations of frequent sets Step 5 used only a negligible amount of time <ref> [ 2 ] </ref> . Lemma 4 Algorithm 3 computes T h (L; r; q) cor rectly. 2 For Algorithm 3 to be applicable, several conditions have to be fulfilled. <p> Example 5 For association rules, the specification ordering was already given above. The algorithm will perform k iterations of the outermost loop, i.e., read the database k times, where k 1 is the size of the largest subset X such that s (X) exceeds the given threshold. See <ref> [ 2; 11; 22; 28 ] </ref> for various implementation methods. 2 Example 6 Strong rules [ 26 ] are rules of the form if expression then expression, where the expressions are, e.g., of the form A &lt; 40, B = 1, etc. <p> Theorem 9 Algorithm 3 uses jT h (L; r; q) [ Bd (T h (L; r; q))j evaluations of the interestingness predicate q. 2 Some straightforward lower bounds for the problem of finding all frequent sets are given in <ref> [ 2; 22 ] </ref> . Now we consider the problem of lower bounds in more realistic models of computation. The main effort in finding interesting sets is in the step where the interestingness of subgroups are evaluated against the database. Thus we consider the following model of computation.
Reference: [ 3 ] <author> S. Bell. </author> <title> Discovery and maintenance of functional dependencies by independencies. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Discovery and Data Mining (KDD'95), </booktitle> <pages> pages 27 - 32, </pages> <address> Montreal, Canada, </address> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: Such a dependency is true in the relation r, if for all pairs of rows t; u 2 r we have: if t and u have the same value for all attributes in X, they have the same value for B. For various algorithms for finding such dependencies, see <ref> [ 3; 19; 20; 21; 25 ] </ref> .
Reference: [ 4 ] <author> C. Berge. </author> <title> Hypergraphs. Combinatorics of Finite Sets. </title> <publisher> North-Holland Publishing Company, </publisher> <address> Ams-terdam, </address> <year> 1989. </year>
Reference-contexts: Thus Tr (H (S)) = ffAg; fB; Cgg, and f 1 (Tr (H (S))) = ffB; C; Dg; fA; Dgg. 2 The advantage of Theorem 14 is that there is a wealth of material known about transversals of hy-pergraphs (see, e.g., <ref> [ 4 ] </ref> ). The relevance of transversals to computing the theory of a model has long been known in the context of finding functional dependencies [ 21 ] ; see [ 8 ] for a variety of other problems where this concept turns up.
Reference: [ 5 ] <author> C. C. Chang and H. J. Keisler. </author> <title> Model Theory. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1973. </year> <note> 3rd ed., </note> <year> 1990. </year>
Reference-contexts: For some applications, q (r; ') could mean that ' is true or almost true in r, or that ' defines (in some way) an interesting subgroup of r. The roots of this approach are in the use of diagrams of models in model theory (see, e.g., <ref> [ 5 ] </ref> ). The approach has been used in various forms for example in [ 2; 6; 7; 13; 15; 18 ] One should note that in contrast with, e.g., [ 6 ] our emphasis is on very simple representation languages.
Reference: [ 6 ] <author> L. De Raedt and M. Bruynooghe. </author> <title> A theory of clausal discovery. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93), </booktitle> <pages> pages 1058 - 1053, </pages> <address> Chambery, France, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The roots of this approach are in the use of diagrams of models in model theory (see, e.g., [ 5 ] ). The approach has been used in various forms for example in <ref> [ 2; 6; 7; 13; 15; 18 ] </ref> One should note that in contrast with, e.g., [ 6 ] our emphasis is on very simple representation languages. <p> The roots of this approach are in the use of diagrams of models in model theory (see, e.g., [ 5 ] ). The approach has been used in various forms for example in [ 2; 6; 7; 13; 15; 18 ] One should note that in contrast with, e.g., <ref> [ 6 ] </ref> our emphasis is on very simple representation languages. Obviously, if L is infinite and q (r; ') is satisfied for infinitely many sentences, (an explicit representation of) T h (L; r; q) cannot be computed.
Reference: [ 7 ] <author> L. De Raedt and S. Dzeroski. </author> <title> First-order jk-clausal theories are PAC-learnable. </title> <journal> Artificial Intelligence, </journal> <volume> 70:375 - 392, </volume> <year> 1994. </year>
Reference-contexts: The roots of this approach are in the use of diagrams of models in model theory (see, e.g., [ 5 ] ). The approach has been used in various forms for example in <ref> [ 2; 6; 7; 13; 15; 18 ] </ref> One should note that in contrast with, e.g., [ 6 ] our emphasis is on very simple representation languages.
Reference: [ 8 ] <author> T. Eiter and G. Gottlob. </author> <title> Identifying the minimal transversals of a hypergraph and related problems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 24(6):1278 - 1304, </volume> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: The relevance of transversals to computing the theory of a model has long been known in the context of finding functional dependencies [ 21 ] ; see <ref> [ 8 ] </ref> for a variety of other problems where this concept turns up. The complexity of computing the transversal of a hypergraph has long been open: see [ 10; 23 ] for recent breakthroughs.
Reference: [ 9 ] <editor> U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, editors. </editor> <booktitle> Advances in Knowledge Discovery and Data Mining. </booktitle> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: There are several attractive application areas for KDD, and it seems that techniques from machine learning, statistics, and databases can be profitably combined to obtain useful methods and systems for KDD. See, e.g., <ref> [ 9; 27 ] </ref> for general descriptions of the area. The KDD area is and should be largely guided by (succesful) applications. n this paper we take some steps towards theoretical KDD.
Reference: [ 10 ] <author> V. Gurvich and L. Khachiyan. </author> <title> On generating the irredundant conjunctive and disjunctive normal forms of monotone boolean functions. </title> <type> Technical Report LCSR-TR-251, </type> <institution> Rutgers University, </institution> <year> 1995. </year>
Reference-contexts: The complexity of computing the transversal of a hypergraph has long been open: see <ref> [ 10; 23 ] </ref> for recent breakthroughs. Acknowledgements Discussions with and comments from Willi Klosgen, Katarina Morik, Arno Siebes, and Inkeri Verkamo have been most useful.
Reference: [ 11 ] <author> M. Holsheimer, M. Kersten, H. Mannila, and H. Toivonen. </author> <title> A perspective on databases and data mining. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Discovery and Data Mining (KDD'95), </booktitle> <pages> pages 150 - 155, </pages> <address> Montreal, Canada, </address> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: Example 5 For association rules, the specification ordering was already given above. The algorithm will perform k iterations of the outermost loop, i.e., read the database k times, where k 1 is the size of the largest subset X such that s (X) exceeds the given threshold. See <ref> [ 2; 11; 22; 28 ] </ref> for various implementation methods. 2 Example 6 Strong rules [ 26 ] are rules of the form if expression then expression, where the expressions are, e.g., of the form A &lt; 40, B = 1, etc.
Reference: [ 12 ] <author> M. Kantola, H. Mannila, K.-J. Raiha, and H. Siir-tola. </author> <title> Discovering functional and inclusion dependencies in relational databases. </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 7(7):591 - 607, </volume> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: Several choices of the specialization relation are possible, and the number of iterations in the outermost loop of the algorithm depends on that choice. 2 Example 7 Consider the discovery of all inclusion dependencies that hold in a given database instance <ref> [ 12; 16; 19 ] </ref> . Given a database schema R, an inclusion dependency (IND) over R is an expression R [X] S [Y ], where R and S are relation schemas of R, and X and Y are equal-length sequences of attributes of R and S, respectively.
Reference: [ 13 ] <author> J.-U. Kietz and S. Wrobel. </author> <title> Controlling the complexity of learning in logic through syntactic and task-oriented models. </title> <editor> In S. Muggleton, editor, </editor> <booktitle> Inductive Logic Programming, </booktitle> <pages> pages 335 - 359. </pages> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1992. </year>
Reference-contexts: The roots of this approach are in the use of diagrams of models in model theory (see, e.g., [ 5 ] ). The approach has been used in various forms for example in <ref> [ 2; 6; 7; 13; 15; 18 ] </ref> One should note that in contrast with, e.g., [ 6 ] our emphasis is on very simple representation languages.
Reference: [ 14 ] <author> M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A. I. Verkamo. </author> <title> Finding interesting rules from large sets of discovered association rules. </title> <booktitle> In Proceedings of the Third International Conference on Information and Knowledge Management (CIKM'94), </booktitle> <pages> pages 401 - 407, </pages> <address> Gaithers-burg, MD, </address> <month> Nov. </month> <year> 1994. </year> <note> ACM. </note>
Reference-contexts: such that the size of T h (L; r; q) is not too big. (It is not strictly necessary that all sentences in T h (L; r; q) are truly interesting to the user: T h (L; r; q) can be further pruned using, e.g., statistical significance or other criteria <ref> [ 14 ] </ref> . But T h (L; r; q) should not contain hundreds of thousands of useless rules.) 3 Examples Next we look at the applicability of the algorithm by considering some examples of KDD problems. Example 5 For association rules, the specification ordering was already given above.
Reference: [ 15 ] <author> W. Kloesgen. </author> <title> Efficient discovery of interesting statements in databases. </title> <journal> Journal of Intelligent Information Systems, </journal> <volume> 4(1):53 - 69, </volume> <year> 1995. </year>
Reference-contexts: The roots of this approach are in the use of diagrams of models in model theory (see, e.g., [ 5 ] ). The approach has been used in various forms for example in <ref> [ 2; 6; 7; 13; 15; 18 ] </ref> One should note that in contrast with, e.g., [ 6 ] our emphasis is on very simple representation languages.
Reference: [ 16 ] <author> A. J. Knobbe and P. W. Adriaans. </author> <title> Discovering foreign key relations in relational databases. </title> <booktitle> In Workshop Notes of the ECML-95 Workshop on Statistics, Machine Learning, and Knowledge Discovery in Databases, </booktitle> <pages> pages 94 - 99, </pages> <address> Heraklion, Crete, Greece, </address> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: Several choices of the specialization relation are possible, and the number of iterations in the outermost loop of the algorithm depends on that choice. 2 Example 7 Consider the discovery of all inclusion dependencies that hold in a given database instance <ref> [ 12; 16; 19 ] </ref> . Given a database schema R, an inclusion dependency (IND) over R is an expression R [X] S [Y ], where R and S are relation schemas of R, and X and Y are equal-length sequences of attributes of R and S, respectively.
Reference: [ 17 ] <author> P. Langley. </author> <title> Elements of Machine Learning. </title> <publisher> Mor-gan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1995. </year>
Reference-contexts: We show strong connections between the verification problem and the hypergraph transversal problem. 2 The algorithm In this section we present the simple algorithm for finding all interesting statements. As already considered by Mitchell [ 24 ] , we use a specialization/generalization relation between sentences. (See, e.g., <ref> [ 17 ] </ref> for an overview of approaches to related problems.) A specialization relation is a partial order on the sentences in L. We say that ' is more general than , if ' ; we also say that is more specific than '.
Reference: [ 18 ] <author> H. Mannila and K.-J. Raiha. </author> <title> Design by example: An application of Armstrong relations. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 33(2):126 - 141, </volume> <year> 1986. </year>
Reference-contexts: The roots of this approach are in the use of diagrams of models in model theory (see, e.g., [ 5 ] ). The approach has been used in various forms for example in <ref> [ 2; 6; 7; 13; 15; 18 ] </ref> One should note that in contrast with, e.g., [ 6 ] our emphasis is on very simple representation languages.
Reference: [ 19 ] <author> H. Mannila and K.-J. Raiha. </author> <title> Design of Relational Databases. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Wokingham, UK, </address> <year> 1992. </year>
Reference-contexts: Several choices of the specialization relation are possible, and the number of iterations in the outermost loop of the algorithm depends on that choice. 2 Example 7 Consider the discovery of all inclusion dependencies that hold in a given database instance <ref> [ 12; 16; 19 ] </ref> . Given a database schema R, an inclusion dependency (IND) over R is an expression R [X] S [Y ], where R and S are relation schemas of R, and X and Y are equal-length sequences of attributes of R and S, respectively. <p> Such a dependency is true in the relation r, if for all pairs of rows t; u 2 r we have: if t and u have the same value for all attributes in X, they have the same value for B. For various algorithms for finding such dependencies, see <ref> [ 3; 19; 20; 21; 25 ] </ref> . <p> (L; r; q) that accesses the data using only Is-interesting queries must use at least jBd (T h (L; r; q))j queries. 2 This result, simple as it seems, gives as a corollary a result about finding functional dependencies that in the more specific setting is not easy to find <ref> [ 19; 20 ] </ref> . For simplicity, we present the result here for the case of finding keys of a relation. Given a relation r over schema R, a key of r is a subset X of R such that no two rows agree on X.
Reference: [ 20 ] <author> H. Mannila and K.-J. Raiha. </author> <title> On the complexity of dependency inference. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 40:237 - 243, </volume> <year> 1992. </year>
Reference-contexts: Such a dependency is true in the relation r, if for all pairs of rows t; u 2 r we have: if t and u have the same value for all attributes in X, they have the same value for B. For various algorithms for finding such dependencies, see <ref> [ 3; 19; 20; 21; 25 ] </ref> . <p> (L; r; q) that accesses the data using only Is-interesting queries must use at least jBd (T h (L; r; q))j queries. 2 This result, simple as it seems, gives as a corollary a result about finding functional dependencies that in the more specific setting is not easy to find <ref> [ 19; 20 ] </ref> . For simplicity, we present the result here for the case of finding keys of a relation. Given a relation r over schema R, a key of r is a subset X of R such that no two rows agree on X. <p> Given a relation r over schema R, a key of r is a subset X of R such that no two rows agree on X. Note that a superset of a key is always a key, and that X Y if and only Y X. Corollary 11 ( <ref> [ 20 ] </ref> ) Given a relation r over schema R, finding the minimal keys that hold in r requires at least MAX (r) evaluations of the predicate "Is X a key", where MAX (r) is the set of all maximal subsets (w.r.t. set inclusion) of R that do not contain
Reference: [ 21 ] <author> H. Mannila and K.-J. Raiha. </author> <title> Algorithms for inferring functional dependencies. </title> <journal> Data & Knowledge Engineering, </journal> <volume> 12(1):83 - 99, </volume> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: Such a dependency is true in the relation r, if for all pairs of rows t; u 2 r we have: if t and u have the same value for all attributes in X, they have the same value for B. For various algorithms for finding such dependencies, see <ref> [ 3; 19; 20; 21; 25 ] </ref> . <p> The relevance of transversals to computing the theory of a model has long been known in the context of finding functional dependencies <ref> [ 21 ] </ref> ; see [ 8 ] for a variety of other problems where this concept turns up. The complexity of computing the transversal of a hypergraph has long been open: see [ 10; 23 ] for recent breakthroughs.
Reference: [ 22 ] <author> H. Mannila, H. Toivonen, and A. I. Verkamo. </author> <title> Efficient algorithms for discovering association rules. </title> <editor> In U. M. Fayyad and R. Uthurusamy, editors, </editor> <booktitle> Knowledge Discovery in Databases, Papers from the 1994 AAAI Workshop (KDD'94), </booktitle> <pages> pages 181 - 192, </pages> <address> Seattle, Washington, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: The central idea is to start from the most general sentences, and then to generate and evaluate more and more special predicates, but not to generate those candidate sentences that cannot be interesting given all the information obtained in earlier iterations <ref> [ 2; 22 ] </ref> . The method is as follows. Algorithm 3 The levelwise algorithm for finding all interesting statements. Input: A database r, a language L with specialization relation , and a quality function q. Output: The set T h (L; r; q). Method: 1. <p> Example 5 For association rules, the specification ordering was already given above. The algorithm will perform k iterations of the outermost loop, i.e., read the database k times, where k 1 is the size of the largest subset X such that s (X) exceeds the given threshold. See <ref> [ 2; 11; 22; 28 ] </ref> for various implementation methods. 2 Example 6 Strong rules [ 26 ] are rules of the form if expression then expression, where the expressions are, e.g., of the form A &lt; 40, B = 1, etc. <p> Theorem 9 Algorithm 3 uses jT h (L; r; q) [ Bd (T h (L; r; q))j evaluations of the interestingness predicate q. 2 Some straightforward lower bounds for the problem of finding all frequent sets are given in <ref> [ 2; 22 ] </ref> . Now we consider the problem of lower bounds in more realistic models of computation. The main effort in finding interesting sets is in the step where the interestingness of subgroups are evaluated against the database. Thus we consider the following model of computation.
Reference: [ 23 ] <author> N. Mishra and L. Pitt. </author> <title> On bounded-degree hy-pergraph transversal. </title> <type> Manuscript, </type> <year> 1995. </year>
Reference-contexts: The complexity of computing the transversal of a hypergraph has long been open: see <ref> [ 10; 23 ] </ref> for recent breakthroughs. Acknowledgements Discussions with and comments from Willi Klosgen, Katarina Morik, Arno Siebes, and Inkeri Verkamo have been most useful.
Reference: [ 24 ] <author> T. M. Mitchell. </author> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18:203 - 226, </volume> <year> 1992. </year>
Reference-contexts: We show strong connections between the verification problem and the hypergraph transversal problem. 2 The algorithm In this section we present the simple algorithm for finding all interesting statements. As already considered by Mitchell <ref> [ 24 ] </ref> , we use a specialization/generalization relation between sentences. (See, e.g., [ 17 ] for an overview of approaches to related problems.) A specialization relation is a partial order on the sentences in L. <p> Using this notation Step 5 of Algorithm 3 can be written as C i+1 := Bd ( S S 1 I.e., the positive border corresponds to the set "S" of <ref> [ 24 ] </ref> . Theorem 9 Algorithm 3 uses jT h (L; r; q) [ Bd (T h (L; r; q))j evaluations of the interestingness predicate q. 2 Some straightforward lower bounds for the problem of finding all frequent sets are given in [ 2; 22 ] .
Reference: [ 25 ] <author> B. Pfahringer and S. Kramer. </author> <title> Compression-based evaluation of partial determinations. </title> <booktitle> In Proceedings of the First International Conference on Knowledge Discovery and Data Mining (KDD'95), </booktitle> <pages> pages 234 - 239, </pages> <address> Montreal, Canada, </address> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: Such a dependency is true in the relation r, if for all pairs of rows t; u 2 r we have: if t and u have the same value for all attributes in X, they have the same value for B. For various algorithms for finding such dependencies, see <ref> [ 3; 19; 20; 21; 25 ] </ref> .
Reference: [ 26 ] <author> G. Piatetsky-Shapiro. </author> <title> Discovery, analysis, and presentation of strong rules. </title> <editor> In G. Piatetsky-Shapiro and W. J. Frawley, editors, </editor> <booktitle> Knowledge Discovery in Databases, </booktitle> <pages> pages 229 - 248. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1991. </year>
Reference-contexts: See [ 2; 11; 22; 28 ] for various implementation methods. 2 Example 6 Strong rules <ref> [ 26 ] </ref> are rules of the form if expression then expression, where the expressions are, e.g., of the form A &lt; 40, B = 1, etc. Such rules can be found using the above algorithm.
Reference: [ 27 ] <editor> G. Piatetsky-Shapiro and W. J. Frawley, editors. </editor> <title> Knowledge Discovery in Databases. </title> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA, </address> <year> 1991. </year>
Reference-contexts: There are several attractive application areas for KDD, and it seems that techniques from machine learning, statistics, and databases can be profitably combined to obtain useful methods and systems for KDD. See, e.g., <ref> [ 9; 27 ] </ref> for general descriptions of the area. The KDD area is and should be largely guided by (succesful) applications. n this paper we take some steps towards theoretical KDD.
Reference: [ 28 ] <author> A. Savasere, E. Omiecinski, and S. Navathe. </author> <title> An efficient algorithm for mining association rules in large databases. </title> <booktitle> In Proceedings of the 21st International Conference on Very Large Data Bases (VLDB'95), </booktitle> <pages> pages 432 - 444, </pages> <year> 1995. </year>
Reference-contexts: Example 5 For association rules, the specification ordering was already given above. The algorithm will perform k iterations of the outermost loop, i.e., read the database k times, where k 1 is the size of the largest subset X such that s (X) exceeds the given threshold. See <ref> [ 2; 11; 22; 28 ] </ref> for various implementation methods. 2 Example 6 Strong rules [ 26 ] are rules of the form if expression then expression, where the expressions are, e.g., of the form A &lt; 40, B = 1, etc. <p> For finding frequent sets and for finding functional dependencies one can show that sampling produces fairly good approximations. We omit the details. Another method for computing an initial approximation can be derived from the algorithm of <ref> [ 28 ] </ref> . The idea is to divide r into small datasets r i which can be handled in main memory and compute S i = T h (L; r i ; q).
References-found: 28

