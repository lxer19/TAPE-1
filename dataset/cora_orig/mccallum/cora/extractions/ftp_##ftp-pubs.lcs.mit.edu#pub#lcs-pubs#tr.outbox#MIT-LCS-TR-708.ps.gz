URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/tr.outbox/MIT-LCS-TR-708.ps.gz
Refering-URL: ftp://ftp-pubs.lcs.mit.edu/pub/lcs-pubs/listings/tr700.html
Root-URL: 
Title: MIT-LCS-TR-708 OPTIMISM VS. LOCKING: A STUDY OF CONCURRENCY CONTROL FOR CLIENT-SERVER OBJECT-ORIENTED DATABASES  
Author: Robert E. Gruber 
Date: February 1997  
Abstract: This technical report (TR) has been made available free of charge from the MIT Laboratory for Computer Science, at www.lcs.mit.edu. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Adya, R. Gruber, B. Liskov, and U. Maheshwari. </author> <title> Efficient optimistic concur-rency control using loosely synchronized clocks. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 23-34, </pages> <address> San Jose, CA, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: provides a detailed description of how we chose the default and "future" system parameter settings used in our experiments. 19 20 Chapter 2 Optimistic and Locking Designs This chapter describes two concurrency control schemes: * AOCC, a new optimistic scheme that we designed, is a variant of the "OCC" scheme <ref> [1] </ref> we developed for use in the Thor OODB [43]. <p> For low contention workloads, this low message cost results in excellent performance. 1 For a multi-server system, local validation at each server includes checks against other transactions that are also attempting to validate and commit. An efficient two-phase commit protocol for this case is described in <ref> [1] </ref>. 24 However, for high contention workloads, if aborts are frequent and restart execu-tions use as many messages as first-run executions, then the total cost per successful commit will be very high.
Reference: [2] <author> D. Agrawal, A. J. Bernstein, P. Gupta, and S. Sengupta. </author> <title> Distributed multi-version optimistic concurrency control with reduced rollback. </title> <journal> Distributed Computing, </journal> <volume> 2(1), </volume> <year> 1987. </year>
Reference-contexts: Optimistic schemes can be classified [33] into forward and backward validation schemes. Backward validation schemes such as AOCC validate a transaction against already-committed transactions, while forward validation schemes validate a transaction against active transactions. Multi-version concurrency control can be used for both locking schemes [59] and optimistic schemes <ref> [6, 2, 39, 41] </ref> to isolate read-only transactions from read-write transactions. Multi-version schemes ensure that read-only transactions always commit, but have higher space overheads than single-version schemes. An additional approach to concurrency control, not studied in this thesis, is timestamp-ordering. <p> For example, some multi-version concurrency control schemes (such as the scheme by Agrawal et. al. <ref> [2] </ref>) choose a start point T start at the start of read-only transaction T and then ensure that all of T's accesses are consistent with this time. Thus, T always commits by choosing this point as its serialization point.
Reference: [3] <author> V. Benzaken and C. Delobel. </author> <title> Enhancing performance in a persistent object store: Clustering strategies in O 2 . Technical Report 50-90, </title> <type> Altair, </type> <month> August </month> <year> 1990. </year>
Reference-contexts: them; objects within a cached page can be marked as "missing." Both schemes studied in the thesis use object-level marking. 1.2 Database and Workload Assumptions In addition to assuming that the normal case for an OODB is to have multiple objects per database page, we assume that a clustering algorithm <ref> [3, 14, 19, 51, 54, 55] </ref> is used to produce a well-clustered database with respect to common access patterns. In other words, a transaction accessing page P is likely to access multiple P objects. The database can be very large (much larger than the client or server caches). <p> Clustering and Write Probabilities We assume that the objects stored in the database have been placed onto pages by some clustering process that uses information about common access patterns or the links between objects to determine groups of objects that are likely to be accessed together <ref> [3, 14, 19, 51, 54, 55] </ref>. Clustering is important for performance; the objects on a page are read from disk as a group and are sent to a client as a group. We model the quality of clustering by specifying a range of cluster sizes.
Reference: [4] <author> P. Berstein and N. Goodman. </author> <title> Concurrency control in distributed database systems. </title> <journal> ACM Computing Surveys, </journal> <volume> 13(2) </volume> <pages> 185-222, </pages> <month> June </month> <year> 1981. </year>
Reference-contexts: An additional approach to concurrency control, not studied in this thesis, is timestamp-ordering. Timestamp schemes choose a serial order for transactions prior to their commit and use a combination of optimistic and pessimistic methods to try to commit the transactions in this order. Timestamp schemes are summarized in <ref> [4] </ref>. All of these mechanisms can be applied to a client-server OODB. For example, the GemStone [6] and Jasmine [39] OODBs use multi-version optimistic schemes. Below we focus on work directly related to this thesis: Sections 3.1-3.3 review three studies of single-version client-server schemes.
Reference: [5] <author> M. Blumrich, C. Dubnicki, E. W. Felton, and K. Li. </author> <title> Memory-mapped network interfaces. </title> <booktitle> IEEE Micro, </booktitle> <pages> pages 21-28, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: Newer approaches such as the ones described in <ref> [5, 20, 56] </ref> move most of the network code to user-level. For protection and fairness reasons, kernel interaction is still required to set up user-level communication. Shared memory regions are used to provide the required level of protection.
Reference: [6] <author> P. Butterworth, A. Otis, and J. Stein. </author> <title> The Gemstone database management system. </title> <journal> CACM, </journal> <volume> 34(10), </volume> <month> October </month> <year> 1991. </year>
Reference-contexts: For most client-server OODBs, including research prototypes such as ORION [37], EXODUS [26], SHORE [9], and Thor [43] and also commercially available systems like GemStone <ref> [6] </ref>, O2 [16, 17], ObjectStore [40], Ontos [46], Objectivity [45], Statice [60], and Versant [52], object accesses are performed at clients on cached copies of the persistent objects. Moving data to the applications has two main advantages. <p> Many commercial and research systems use per-application private caches, including systems that use optimism (see, e.g., GemStone <ref> [6] </ref>) and systems that use locking (see, e.g., SHORE [9]). 2.4.2 Adaptive Cache Maintenance The fundamental adaptive cache discard rule is this: discard the page if the current transaction is not using it; otherwise discard the object. ACBL and AOCC both apply this rule to callbacks and invalidations. <p> Optimistic schemes can be classified [33] into forward and backward validation schemes. Backward validation schemes such as AOCC validate a transaction against already-committed transactions, while forward validation schemes validate a transaction against active transactions. Multi-version concurrency control can be used for both locking schemes [59] and optimistic schemes <ref> [6, 2, 39, 41] </ref> to isolate read-only transactions from read-write transactions. Multi-version schemes ensure that read-only transactions always commit, but have higher space overheads than single-version schemes. An additional approach to concurrency control, not studied in this thesis, is timestamp-ordering. <p> Timestamp schemes are summarized in [4]. All of these mechanisms can be applied to a client-server OODB. For example, the GemStone <ref> [6] </ref> and Jasmine [39] OODBs use multi-version optimistic schemes. Below we focus on work directly related to this thesis: Sections 3.1-3.3 review three studies of single-version client-server schemes.
Reference: [7] <author> M. Carey, D. DeWitt, C. Kant, and J. Naughton. </author> <title> A status report on the OO7 OODBMS benchmarking effort. </title> <booktitle> In OOPSLA'94: 9th ACM Conference on Object-Oriented Programming Systems, Languages and Applications, </booktitle> <address> Portland, OR, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: The server stores database pages on a set of data disks. We assume that objects are small and that pages contain many objects. For example, in the OO7 benchmark <ref> [8, 7] </ref>, a widely accepted object-oriented database benchmark, most objects are smaller than 100 bytes. The clients share the objects stored at the server. Each client has a page cache that contains copies of some of the database pages. An application runs at each client, issuing a sequence of transactions. <p> A small object size was chosen because we expect many small objects to be present in real OODBs. For example, in the OO7 benchmark <ref> [8, 7] </ref>, a widely accepted object-oriented database benchmark, most objects are smaller than 100 bytes. Also, small objects are the most interesting case to study with respect to concurrency control.
Reference: [8] <author> M. Carey, D. DeWitt, and J. Naughton. </author> <title> The OO7 benchmark. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 12-21, </pages> <address> Washington, DC, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: The server stores database pages on a set of data disks. We assume that objects are small and that pages contain many objects. For example, in the OO7 benchmark <ref> [8, 7] </ref>, a widely accepted object-oriented database benchmark, most objects are smaller than 100 bytes. The clients share the objects stored at the server. Each client has a page cache that contains copies of some of the database pages. An application runs at each client, issuing a sequence of transactions. <p> In this case the undo log state represents 1% of the client cache size. Measurements of the Thor object-oriented database system [43] show that undo log maintenance has very low cost. For example, for the "T2b" traversal from the OO7 benchmark <ref> [8] </ref>, the overhead for maintaining an undo log was less than 2.5% of non-commit latency for a "hot" traversal that used no fetch requests, and less than 0.5% for a traversal that did use fetch requests [13]. <p> A small object size was chosen because we expect many small objects to be present in real OODBs. For example, in the OO7 benchmark <ref> [8, 7] </ref>, a widely accepted object-oriented database benchmark, most objects are smaller than 100 bytes. Also, small objects are the most interesting case to study with respect to concurrency control.
Reference: [9] <author> M. Carey et al. </author> <title> Shoring up persistent applications. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <address> Minneapolis, MN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: We focus on systems where servers provide the storage for a universe of shared persistent objects (persistent stores), while clients run application code that uses this object state. For most client-server OODBs, including research prototypes such as ORION [37], EXODUS [26], SHORE <ref> [9] </ref>, and Thor [43] and also commercially available systems like GemStone [6], O2 [16, 17], ObjectStore [40], Ontos [46], Objectivity [45], Statice [60], and Versant [52], object accesses are performed at clients on cached copies of the persistent objects. Moving data to the applications has two main advantages. <p> Many commercial and research systems use per-application private caches, including systems that use optimism (see, e.g., GemStone [6]) and systems that use locking (see, e.g., SHORE <ref> [9] </ref>). 2.4.2 Adaptive Cache Maintenance The fundamental adaptive cache discard rule is this: discard the page if the current transaction is not using it; otherwise discard the object. ACBL and AOCC both apply this rule to callbacks and invalidations.
Reference: [10] <author> M. Carey, M. Franklin, and M. Zaharioudakis. </author> <title> Fine-graned sharing in a page server OODBMS. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 359-370, </pages> <address> Minneapolis, MN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: OCC design but uses a different underlying architecture and a different client cache maintenance policy; these changes were required to perform a meaningful comparison to the ACBL design. * ACBL is an adaptive-granularity callback locking scheme that is based closely on the PS-AA scheme designed by Carey, Franklin, and Zaharioudakis <ref> [10] </ref>. PS-AA's design was inspired by the adaptive locking algorithm described by Joshi for the VAXCluster version of Rdb/VMS [35]. We use this scheme in our optimism vs. locking comparison study because previous client-server con-currency control studies suggest it is the best locking choice for a client-server OODB. <p> These studies used page-level conflict detection for all of the schemes compared. A later study introduced adaptive-granularity callback locking and demonstrated that using adaptive conflict detection is better than using either purely page-level conflict detection or purely object-level conflict detection <ref> [10] </ref>. In addition to describing the two schemes, this chapter presents a comparative design analysis. We define a simple model of the cost of executing a transaction. For low contention workloads, the model shows that message cost predicts performance. <p> This study shows that the MOB design has higher write absorption and makes more efficient use of the server disks for installations. In addition, message sizes are small relative to a scheme that sends page-level updates in commit requests. (The PS-AA study <ref> [10] </ref> uses page-level commit requests and a standard server cache. <p> These modules are written in C++. 1 The design of our system model is based in part on the the page-based simulation work of Franklin and Carey [23, 24] and the adaptive-granularity locking work of Carey, Franklin, and Zaharioudakis <ref> [10] </ref> (CFZ). <p> Appendix A discusses disk scheduling algorithms. It also describes how we chose the following settings for the CURRENT and FUTURE systems. We use the same CPU setup cost for both systems: 5000 instructions. (This is the same charge used in <ref> [10] </ref>.) Of course, FUTURE CPU speeds are 4 times faster, thus FUTURE disk setup times are 4 times faster. The CURRENT system has four disks, where each disk has a slow access time of 3322 secs/KB and a fast access time of 1288 secs/KB. <p> This section describes our reasons for choosing these workloads; the next section describes each workload. For reasons of continuity, we use workloads that others have used to study client-server systems. In particular, the client-server concurrency control studies of Franklin and Carey <ref> [10, 23, 24] </ref> are well known in the database research community; four of our workloads are derived from the workloads used in their studies: UNIFORM, PRIVATE, HOTCOLD, and HICON. These workloads began as page-based workloads [23, 24]. <p> Our use of a 50% restart change probability results in a fairer comparison between optimism and locking. 4.3 Related Experimental Framework This section discusses how our simulation framework differs from the framework used by Carey, Franklin, and Zaharioudakis (CFZ) in their study of adaptive-granularity callback locking schemes <ref> [10] </ref>. Four of our workloads (PRIVATE, HOTCOLD, UNIFORM, and HICON) are based on workloads with the same names used both in the CFZ study and also in several earlier client-server studies [23, 24]. Our workload generator has a number of features that are extensions of the CFZ generator. <p> Studying this issue is an area of future work. 6.2.3 Restart Behavior Most concurrency-control simulation studies (including the client-server studies most similar to our work <ref> [10, 23, 24, 57, 58] </ref>) use a "perfect restart" assumption: on an abort, the access pattern of the failed transaction is used without modification for the subsequent restart execution. <p> the simulator does not charge for the interrupt and event scheduling that occurs when a disk access completes, the setup cost should also reflect completion-based costs as well.) We use the same CPU setup cost for our CURRENT and FUTURE systems: 5000 instructions. (This is the same charge used in <ref> [10] </ref>.) Since the FUTURE CPU's are 4 times faster, FUTURE disk setup times are 4 times faster. A.3.1 Choosing the Disk Bandwidths We chose the slow and fast bandwidths for the CURRENT system using the characteristics of a Seagate Barracuda, an existing drive in common use.
Reference: [11] <author> M. Carey, S. Krishnamurthi, and M. Livny. </author> <title> Load control for locking: The `half-and-half' approach. </title> <booktitle> In 9th ACM Symposium on Principles of Database Systems, </booktitle> <pages> pages 72-84, </pages> <address> Nashville, TN, </address> <month> April </month> <year> 1990. </year> <month> 167 </month>
Reference-contexts: graphs show a degrading throughput beyond the client point where the peak value is achieved, it is possible to design an admission control policy for a database system that attempts to keep the system performing at near-peak performance at client points that are higher than the "ideal" number of clients. <ref> [11] </ref> A discussion of how one would implement admission control for either AOCC or ACBL is beyond the scope of this thesis.
Reference: [12] <author> M. Carey and M. Livny. </author> <title> Conflict detection tradeoffs for replicated data. </title> <journal> ACM TODS, </journal> <volume> 16(4) </volume> <pages> 703-746, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: Thus, it is natural to look to studies of shared-nothing concurrency control schemes for insights relevant to client-server concurrency control tradeoffs. (For example, the client-server O2PL scheme discussed in Section 3.1 was studied because Carey and Livny found that a parallel shared-nothing version of O2PL showed some promise <ref> [12] </ref>.) However, the nature of these two types of systems is sufficiently different that results for one system do not apply to the other. In this section we briefly present the important differences and discuss their impact on concurrency control tradeoffs.
Reference: [13] <author> M. Castro, </author> <month> March </month> <year> 1996. </year> <title> Private Communication. </title>
Reference-contexts: For example, for the "T2b" traversal from the OO7 benchmark [8], the overhead for maintaining an undo log was less than 2.5% of non-commit latency for a "hot" traversal that used no fetch requests, and less than 0.5% for a traversal that did use fetch requests <ref> [13] </ref>. For the T2b traversal, roughly one in four object accesses is a write; we expect most workloads have low undo log costs compared to this traversal. Given the low overhead of undo log maintenance, we decided not to introduce a CPU charge for copy-on-write in our simulation model.
Reference: [14] <author> E. Chang and R. Katz. </author> <title> Exploiting inheritance and structure semantics for effective clustering and buffering in an object-oriented DBMS. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 348-357, </pages> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: them; objects within a cached page can be marked as "missing." Both schemes studied in the thesis use object-level marking. 1.2 Database and Workload Assumptions In addition to assuming that the normal case for an OODB is to have multiple objects per database page, we assume that a clustering algorithm <ref> [3, 14, 19, 51, 54, 55] </ref> is used to produce a well-clustered database with respect to common access patterns. In other words, a transaction accessing page P is likely to access multiple P objects. The database can be very large (much larger than the client or server caches). <p> Clustering and Write Probabilities We assume that the objects stored in the database have been placed onto pages by some clustering process that uses information about common access patterns or the links between objects to determine groups of objects that are likely to be accessed together <ref> [3, 14, 19, 51, 54, 55] </ref>. Clustering is important for performance; the objects on a page are read from disk as a group and are sent to a client as a group. We model the quality of clustering by specifying a range of cluster sizes.
Reference: [15] <author> M. Dahlin, R. Wang, T. Anderson, and D. Patterson. </author> <title> Cooperative caching: Using remote client memory to improve file system performance. </title> <booktitle> In 1rst Usenix Symposium on Operating System Design and Implementation, </booktitle> <year> 1994. </year>
Reference-contexts: Main memory at clients will continue to increase. Furthermore, hybrid cache designs [36, 47] retain both useful pages and useful objects, resulting in more effective use of cache space. In addition, cooperative caching designs allow fetches to be serviced by other clients <ref> [15, 22, 25] </ref>, while main-memory databases (e.g., DaliJagadish94) are becoming more common; it is increasingly likely that additional fetches due to aborts will be serviced from client or server memory rather than server disk.
Reference: [16] <editor> O. Deux et al. </editor> <title> The story of O2. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1) </volume> <pages> 91-108, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: For most client-server OODBs, including research prototypes such as ORION [37], EXODUS [26], SHORE [9], and Thor [43] and also commercially available systems like GemStone [6], O2 <ref> [16, 17] </ref>, ObjectStore [40], Ontos [46], Objectivity [45], Statice [60], and Versant [52], object accesses are performed at clients on cached copies of the persistent objects. Moving data to the applications has two main advantages.
Reference: [17] <editor> O. Deux et al. </editor> <title> The O2 system. </title> <journal> CACM, </journal> <volume> 34(10), </volume> <month> October </month> <year> 1991. </year>
Reference-contexts: For most client-server OODBs, including research prototypes such as ORION [37], EXODUS [26], SHORE [9], and Thor [43] and also commercially available systems like GemStone [6], O2 <ref> [16, 17] </ref>, ObjectStore [40], Ontos [46], Objectivity [45], Statice [60], and Versant [52], object accesses are performed at clients on cached copies of the persistent objects. Moving data to the applications has two main advantages.
Reference: [18] <author> D. DeWitt, P. Futtersack, D. Maier, and F. Velez. </author> <title> A study of three alternative workstation architectures for object-oriented database systems. </title> <booktitle> In 16th International Conference on Very Large Data Bases (VLDB), </booktitle> <address> Brisbane, Australia, </address> <year> 1990. </year>
Reference-contexts: In other words, while Notify Locks as designed using reactive cache maintenance, it could be changed to use proactive cache maintenance. 3.4 Parallel Database Concurrency Control Shared-nothing parallel database systems are multiple processor systems where each processor has its own memory and disks (see, e.g., <ref> [18] </ref>). For these systems, data is partitioned across the processors, and access to the data "owned" by a processor normally involves running a sub-transaction at that processor. Some shared-nothing systems allow processors to cache copies of non-local state indefinitely, i.e., to "replicate" the data across more than one processor.
Reference: [19] <author> P. Drew and R. King. </author> <title> The performance and utility of the Cactis implementation algorithms. </title> <booktitle> In 16th International Conference on Very Large Data Bases (VLDB), </booktitle> <pages> pages 135-147, </pages> <address> Brisbane, Australia, </address> <year> 1990. </year>
Reference-contexts: them; objects within a cached page can be marked as "missing." Both schemes studied in the thesis use object-level marking. 1.2 Database and Workload Assumptions In addition to assuming that the normal case for an OODB is to have multiple objects per database page, we assume that a clustering algorithm <ref> [3, 14, 19, 51, 54, 55] </ref> is used to produce a well-clustered database with respect to common access patterns. In other words, a transaction accessing page P is likely to access multiple P objects. The database can be very large (much larger than the client or server caches). <p> Clustering and Write Probabilities We assume that the objects stored in the database have been placed onto pages by some clustering process that uses information about common access patterns or the links between objects to determine groups of objects that are likely to be accessed together <ref> [3, 14, 19, 51, 54, 55] </ref>. Clustering is important for performance; the objects on a page are read from disk as a group and are sent to a client as a group. We model the quality of clustering by specifying a range of cluster sizes.
Reference: [20] <author> P. Druschel, L. L. Peterson, and B. S. Davie. </author> <title> Experience with a high-speed network adaptor: A software perspective. </title> <booktitle> In ACM SIGCOMM Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication, </booktitle> <pages> pages 2-13, </pages> <address> London, England, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: Newer approaches such as the ones described in <ref> [5, 20, 56] </ref> move most of the network code to user-level. For protection and fairness reasons, kernel interaction is still required to set up user-level communication. Shared memory regions are used to provide the required level of protection.
Reference: [21] <author> K. Eswaran, J. Gray, R. Lorie, and I. Traiger. </author> <title> The notion of consistency and predicate locks in a database system. </title> <journal> CACM, </journal> 19(11) 624-633, November 1976. 
Reference-contexts: Concurrency control was originally invented for centralized single-version database systems; single-version systems maintain only one copy of each data item. Fundamentally, there are two kinds of concurrency control, pessimism (locking) and optimism. The seminal paper on standard two-phase locking is by Eswaran et. al. <ref> [21] </ref>. The seminal paper on optimism is by Kung and Robinson [38]. Bernstein et. al. and Gray and Reuter [30] both provide good overviews of concurrency control and recovery issues, including later work on distributed database concurrency control. Optimistic schemes can be classified [33] into forward and backward validation schemes.
Reference: [22] <author> M. Feeley, W. Morgan, F. Pighin, A. Karlin, H. Levy, and C. Thekkath. </author> <title> Implementing global memory management in a workstation cluster. </title> <booktitle> In 15th ACM Symposium on Operating System Principles, </booktitle> <year> 1995. </year>
Reference-contexts: Main memory at clients will continue to increase. Furthermore, hybrid cache designs [36, 47] retain both useful pages and useful objects, resulting in more effective use of cache space. In addition, cooperative caching designs allow fetches to be serviced by other clients <ref> [15, 22, 25] </ref>, while main-memory databases (e.g., DaliJagadish94) are becoming more common; it is increasingly likely that additional fetches due to aborts will be serviced from client or server memory rather than server disk.
Reference: [23] <author> M. Franklin. </author> <title> Caching and memory management in client-server database systems. </title> <type> Technical Report (Ph.D.) 1168, </type> <institution> Computer Sciences Dept., University of Wisconsin-Madison, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: However, previous work does not support this intuition. There are two client-server studies we know of that compare optimism with locking. One study shows that locking is always better [57, 58]; the other shows that optimism is slightly better, but only under low contention <ref> [23, 24] </ref>. 13 This thesis reverses these earlier results. It defines a new optimistic concurrency control scheme, Adaptive Optimistic Concurrecy Control (AOCC), and presents the results of detailed performance studies that compare AOCC to Adaptive-granularity CallBack Locking (ACBL). <p> Therefore, we study schemes that do not discard the client cache contents at end of each transaction. Previous studies have shown that such inter-transaction caching provides performance benefits for workloads with inter-transaction locality <ref> [23, 24, 57, 58, 61] </ref>. We study workloads with both low and high inter-transaction locality of reference. With respect to the interaction of transactions at different clients, we use three different sharing patterns (in different combinations) in our workloads. The patterns define different kinds of database regions. <p> We use this scheme in our optimism vs. locking comparison study because previous client-server con-currency control studies suggest it is the best locking choice for a client-server OODB. Comparative performance studies by both Franklin and Carey <ref> [23, 24] </ref> and Wang and Rowe [57, 58] conclude that callback locking is the best locking approach for low-to-moderate contention workloads. These studies used page-level conflict detection for all of the schemes compared. <p> The page-based callback locking design we describe caches read locks across transaction boundaries (while write locks revert to read locks on commit). Following Franklin and Carey we refer to this scheme as CBR <ref> [23, 24] </ref>. Under CBR, a page is cached at a client if and only if the client holds a lock on the page; any cached page that is not write-locked must be read-locked. <p> Since read accesses are normally more frequent than write accesses, the message tradeoff made by CBR should result in lower message costs when compared to a 2PL scheme. Several performance studies have demonstrated that CBR outperforms a 2PL scheme except when high contention workloads are used <ref> [23, 24, 57, 58] </ref>. CBR has excellent performance for read accesses, and moreover the cost of a write lock acquisition is amortized across accesses to multiple objects on a page. <p> All of these mechanisms can be applied to a client-server OODB. For example, the GemStone [6] and Jasmine [39] OODBs use multi-version optimistic schemes. Below we focus on work directly related to this thesis: Sections 3.1-3.3 review three studies of single-version client-server schemes. These studies, by Franklin and Carey <ref> [23, 24] </ref>, Wang and Rowe [58, 57], and Wilkinson and Neimat [61], examine nine different concurrency control schemes that use inter-transaction caching. These schemes use coarse-granularity (page-level) conflict detection. (AOCC and ACBL use fine-granularity conflict detection, as described in Chapter 2.) Figure 3-1 presents a brief description of each scheme. <p> Concurrency control for such systems requires cache maintenance, thus these systems are related to client-server systems. Section 3.4 summarizes the differences between such database systems and client-server systems, and discusses the impact of these differences on concurrency control tradeoffs. 3.1 Franklin and Carey Franklin and Carey <ref> [23, 24] </ref> studied a number of interesting design tradeoffs. We summarize the key tradeoffs, and also compare the semi-optimistic O2PL (Optimistic 50 2-Phase Locking) scheme used in this study with AOCC. 3.1.1 C2PL vs. CBR vs. CBA Three pure locking schemes are included in the study. <p> Franklin and Carey refer to proactive schemes as avoidance-based schemes and to other schemes as detection-based schemes <ref> [23] </ref>. Avoidance-based schemes always have consistent caches, while detection-based schemes do not. (Detection-based schemes must be able to detect invalid pages). For locking schemes, including deferred locking schemes, this distinction is useful: avoidance-based locking schemes do not need to use lock requests for read accesses. <p> These modules are written in C++. 1 The design of our system model is based in part on the the page-based simulation work of Franklin and Carey <ref> [23, 24] </ref> and the adaptive-granularity locking work of Carey, Franklin, and Zaharioudakis [10] (CFZ). <p> This section describes our reasons for choosing these workloads; the next section describes each workload. For reasons of continuity, we use workloads that others have used to study client-server systems. In particular, the client-server concurrency control studies of Franklin and Carey <ref> [10, 23, 24] </ref> are well known in the database research community; four of our workloads are derived from the workloads used in their studies: UNIFORM, PRIVATE, HOTCOLD, and HICON. These workloads began as page-based workloads [23, 24]. <p> In particular, the client-server concurrency control studies of Franklin and Carey [10, 23, 24] are well known in the database research community; four of our workloads are derived from the workloads used in their studies: UNIFORM, PRIVATE, HOTCOLD, and HICON. These workloads began as page-based workloads <ref> [23, 24] </ref>. While transactions now consist of object accesses, we have preserved the same sharing patterns and the same number of average page accesses per transaction. These four workloads capture important sharing patterns, as we describe below. <p> For all six workloads, we also studied many other combinations of cluster and object write probabilities. The impact of varying the cluster and object write probabilities is explored in Section 6.2.1. 74 UNIFORM Workload The UNIFORM workload is an object-based version of the page-based UNIFORM workload from <ref> [23, 24] </ref>. Its access pattern is depicted in Figure 4-3, which shows that every client views the working set in the same way: as a single 1,250 page shared region. In this workload transactions average 200 object accesses (20 pages are touched). <p> UNIFORM is used to examine how concurrency control schemes perform when there is little or no locality of reference across transaction boundaries. 75 PRIVATE Workload The PRIVATE workload is an object-based version of the page-based PRIVATE workload from <ref> [23, 24] </ref>. In this workload transactions average 160 object accesses (16 pages are touched). <p> CAD system, where users agree in advance to work on disjoint parts of the design; each user updates a disjoint region, while all the users access a shared library of components in read-only fashion. 76 HOTCOLD Workload The HOTCOLD workload is an object-based version of the page-based HOTCOLD workload from <ref> [23, 24] </ref>. Under HOTCOLD clients mostly access their own data but sometimes access each other's data. The access pattern of HOTCOLD is depicted in are 1,250 pages in the working set. <p> number of clients, thus the actual benefit derived from caching will depend on the effectiveness of cache maintenance (e.g., piggy-backed invalidations as used by AOCC) or cache consistency (e.g., callbacks as used by ACBL). 78 HICON Workload The HICON workload is an object-based version of the page-based HICON workload from <ref> [23, 24] </ref>. Skewed 80-20 workloads such as HICON have been used in many database studies, such as studies of shared-disk database systems. <p> Four of our workloads (PRIVATE, HOTCOLD, UNIFORM, and HICON) are based on workloads with the same names used both in the CFZ study and also in several earlier client-server studies <ref> [23, 24] </ref>. Our workload generator has a number of features that are extensions of the CFZ generator. We control both the net write probability and the clustering of writes onto pages; CFZ only control net write probability, thus writes are uniformly distributed across all accessed pages. <p> Studying this issue is an area of future work. 6.2.3 Restart Behavior Most concurrency-control simulation studies (including the client-server studies most similar to our work <ref> [10, 23, 24, 57, 58] </ref>) use a "perfect restart" assumption: on an abort, the access pattern of the failed transaction is used without modification for the subsequent restart execution.
Reference: [24] <author> M. Franklin and M. Carey. </author> <title> Client-server caching revisited. </title> <booktitle> In Int'l Workshop on Distributed Object Management, </booktitle> <address> Edmonton, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: However, previous work does not support this intuition. There are two client-server studies we know of that compare optimism with locking. One study shows that locking is always better [57, 58]; the other shows that optimism is slightly better, but only under low contention <ref> [23, 24] </ref>. 13 This thesis reverses these earlier results. It defines a new optimistic concurrency control scheme, Adaptive Optimistic Concurrecy Control (AOCC), and presents the results of detailed performance studies that compare AOCC to Adaptive-granularity CallBack Locking (ACBL). <p> Therefore, we study schemes that do not discard the client cache contents at end of each transaction. Previous studies have shown that such inter-transaction caching provides performance benefits for workloads with inter-transaction locality <ref> [23, 24, 57, 58, 61] </ref>. We study workloads with both low and high inter-transaction locality of reference. With respect to the interaction of transactions at different clients, we use three different sharing patterns (in different combinations) in our workloads. The patterns define different kinds of database regions. <p> We use this scheme in our optimism vs. locking comparison study because previous client-server con-currency control studies suggest it is the best locking choice for a client-server OODB. Comparative performance studies by both Franklin and Carey <ref> [23, 24] </ref> and Wang and Rowe [57, 58] conclude that callback locking is the best locking approach for low-to-moderate contention workloads. These studies used page-level conflict detection for all of the schemes compared. <p> The page-based callback locking design we describe caches read locks across transaction boundaries (while write locks revert to read locks on commit). Following Franklin and Carey we refer to this scheme as CBR <ref> [23, 24] </ref>. Under CBR, a page is cached at a client if and only if the client holds a lock on the page; any cached page that is not write-locked must be read-locked. <p> Since read accesses are normally more frequent than write accesses, the message tradeoff made by CBR should result in lower message costs when compared to a 2PL scheme. Several performance studies have demonstrated that CBR outperforms a 2PL scheme except when high contention workloads are used <ref> [23, 24, 57, 58] </ref>. CBR has excellent performance for read accesses, and moreover the cost of a write lock acquisition is amortized across accesses to multiple objects on a page. <p> All of these mechanisms can be applied to a client-server OODB. For example, the GemStone [6] and Jasmine [39] OODBs use multi-version optimistic schemes. Below we focus on work directly related to this thesis: Sections 3.1-3.3 review three studies of single-version client-server schemes. These studies, by Franklin and Carey <ref> [23, 24] </ref>, Wang and Rowe [58, 57], and Wilkinson and Neimat [61], examine nine different concurrency control schemes that use inter-transaction caching. These schemes use coarse-granularity (page-level) conflict detection. (AOCC and ACBL use fine-granularity conflict detection, as described in Chapter 2.) Figure 3-1 presents a brief description of each scheme. <p> Concurrency control for such systems requires cache maintenance, thus these systems are related to client-server systems. Section 3.4 summarizes the differences between such database systems and client-server systems, and discusses the impact of these differences on concurrency control tradeoffs. 3.1 Franklin and Carey Franklin and Carey <ref> [23, 24] </ref> studied a number of interesting design tradeoffs. We summarize the key tradeoffs, and also compare the semi-optimistic O2PL (Optimistic 50 2-Phase Locking) scheme used in this study with AOCC. 3.1.1 C2PL vs. CBR vs. CBA Three pure locking schemes are included in the study. <p> These modules are written in C++. 1 The design of our system model is based in part on the the page-based simulation work of Franklin and Carey <ref> [23, 24] </ref> and the adaptive-granularity locking work of Carey, Franklin, and Zaharioudakis [10] (CFZ). <p> This section describes our reasons for choosing these workloads; the next section describes each workload. For reasons of continuity, we use workloads that others have used to study client-server systems. In particular, the client-server concurrency control studies of Franklin and Carey <ref> [10, 23, 24] </ref> are well known in the database research community; four of our workloads are derived from the workloads used in their studies: UNIFORM, PRIVATE, HOTCOLD, and HICON. These workloads began as page-based workloads [23, 24]. <p> In particular, the client-server concurrency control studies of Franklin and Carey [10, 23, 24] are well known in the database research community; four of our workloads are derived from the workloads used in their studies: UNIFORM, PRIVATE, HOTCOLD, and HICON. These workloads began as page-based workloads <ref> [23, 24] </ref>. While transactions now consist of object accesses, we have preserved the same sharing patterns and the same number of average page accesses per transaction. These four workloads capture important sharing patterns, as we describe below. <p> For all six workloads, we also studied many other combinations of cluster and object write probabilities. The impact of varying the cluster and object write probabilities is explored in Section 6.2.1. 74 UNIFORM Workload The UNIFORM workload is an object-based version of the page-based UNIFORM workload from <ref> [23, 24] </ref>. Its access pattern is depicted in Figure 4-3, which shows that every client views the working set in the same way: as a single 1,250 page shared region. In this workload transactions average 200 object accesses (20 pages are touched). <p> UNIFORM is used to examine how concurrency control schemes perform when there is little or no locality of reference across transaction boundaries. 75 PRIVATE Workload The PRIVATE workload is an object-based version of the page-based PRIVATE workload from <ref> [23, 24] </ref>. In this workload transactions average 160 object accesses (16 pages are touched). <p> CAD system, where users agree in advance to work on disjoint parts of the design; each user updates a disjoint region, while all the users access a shared library of components in read-only fashion. 76 HOTCOLD Workload The HOTCOLD workload is an object-based version of the page-based HOTCOLD workload from <ref> [23, 24] </ref>. Under HOTCOLD clients mostly access their own data but sometimes access each other's data. The access pattern of HOTCOLD is depicted in are 1,250 pages in the working set. <p> number of clients, thus the actual benefit derived from caching will depend on the effectiveness of cache maintenance (e.g., piggy-backed invalidations as used by AOCC) or cache consistency (e.g., callbacks as used by ACBL). 78 HICON Workload The HICON workload is an object-based version of the page-based HICON workload from <ref> [23, 24] </ref>. Skewed 80-20 workloads such as HICON have been used in many database studies, such as studies of shared-disk database systems. <p> Four of our workloads (PRIVATE, HOTCOLD, UNIFORM, and HICON) are based on workloads with the same names used both in the CFZ study and also in several earlier client-server studies <ref> [23, 24] </ref>. Our workload generator has a number of features that are extensions of the CFZ generator. We control both the net write probability and the clustering of writes onto pages; CFZ only control net write probability, thus writes are uniformly distributed across all accessed pages. <p> Studying this issue is an area of future work. 6.2.3 Restart Behavior Most concurrency-control simulation studies (including the client-server studies most similar to our work <ref> [10, 23, 24, 57, 58] </ref>) use a "perfect restart" assumption: on an abort, the access pattern of the failed transaction is used without modification for the subsequent restart execution.
Reference: [25] <author> M. Franklin, M. Carey, and M. Livny. </author> <title> Global memory management in client-server DBMS architectures. </title> <booktitle> In 18th International Conference on Very Large Data Bases (VLDB), </booktitle> <year> 1992. </year> <month> 168 </month>
Reference-contexts: Main memory at clients will continue to increase. Furthermore, hybrid cache designs [36, 47] retain both useful pages and useful objects, resulting in more effective use of cache space. In addition, cooperative caching designs allow fetches to be serviced by other clients <ref> [15, 22, 25] </ref>, while main-memory databases (e.g., DaliJagadish94) are becoming more common; it is increasingly likely that additional fetches due to aborts will be serviced from client or server memory rather than server disk.
Reference: [26] <author> M. Franklin, M. Zwilling, C. Tan, M. Carey, and D. DeWitt. </author> <title> Crash recover in client-server EXODUS. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <address> San Diego, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: In particular, we study client-server object-oriented databases (OODBs). We focus on systems where servers provide the storage for a universe of shared persistent objects (persistent stores), while clients run application code that uses this object state. For most client-server OODBs, including research prototypes such as ORION [37], EXODUS <ref> [26] </ref>, SHORE [9], and Thor [43] and also commercially available systems like GemStone [6], O2 [16, 17], ObjectStore [40], Ontos [46], Objectivity [45], Statice [60], and Versant [52], object accesses are performed at clients on cached copies of the persistent objects. Moving data to the applications has two main advantages.
Reference: [27] <author> D. Gerson, </author> <month> May </month> <year> 1989. </year> <title> Private Communication. </title>
Reference-contexts: His implementation switches to two-phase locking for "hot" pages, thus attempting to avoid a high abort rate <ref> [27] </ref>. No performance study has examined this adaptive variant of NWL.) 3.2.3 NWL vs. NWL-Notify Wang and Rowe also experimented with NWL-Notify, a variant of NWL that uses eager reactive cache maintenance.
Reference: [28] <author> S. Ghemawat. </author> <title> The Modified Object Buffer: a Storage Manamement Technique for Object-Oriented Databases. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1995. </year>
Reference-contexts: Once page P's updates are safely on disk, they are discarded from the MOB. Ghemawat's dissertation includes a comparison of a MOB-based design and the more standard approach of installing updates in the server cache at the time of commit <ref> [28] </ref>. This study shows that the MOB design has higher write absorption and makes more efficient use of the server disks for installations.
Reference: [29] <author> C. G. Gray and D. R. Cheriton. Leases: </author> <title> An efficient fault-tolerant mechanism for distributed file cache consistency. </title> <booktitle> In 12th ACM Symposium on Operating System Principles, </booktitle> <address> Litchfield Park, Arizona, </address> <month> December 3-6 </month> <year> 1989. </year>
Reference-contexts: execution has high latency compared to a round-trip exchange, the difference in relative performance is small. 5 Supporting an immediate commit requires that the client has a guarantee that its read locks will not be unilaterally discarded by the server until some future time t; this time window (or lease <ref> [29] </ref>) is advanced as long as the client and server remain in contact. 47 While we describe read-only commit requests for AOCC and also use them in our simulation study, in fact AOCC does not need to use them in a single-server system.
Reference: [30] <author> J. Gray and A. Reuter. </author> <title> Transaction Processing: Concepts and Techniques. </title> <publisher> Mor-gan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Fundamentally, there are two kinds of concurrency control, pessimism (locking) and optimism. The seminal paper on standard two-phase locking is by Eswaran et. al. [21]. The seminal paper on optimism is by Kung and Robinson [38]. Bernstein et. al. and Gray and Reuter <ref> [30] </ref> both provide good overviews of concurrency control and recovery issues, including later work on distributed database concurrency control. Optimistic schemes can be classified [33] into forward and backward validation schemes.
Reference: [31] <author> M. Greenwald and D. Cheriton. </author> <title> The synergy between non-blocking synchronization and operating system structures. </title> <booktitle> In 2nd Usenix Symposium on Operating System Design and Implementation, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: Thus, optimism is more robust with respect to a high variance in the availability or performance properties of clients. (Similar arguments about the benefits of lock-free synchronization have been made at the multiprocessors and operating system level <ref> [31, 34] </ref>.) Due to this client-independence property, optimistic schemes are more easily extended to support a "disconnected client" semantics [32]. The remainder of this chapter is organized as follows. Section 1.1 discusses our system model assumptions, while Section 1.2 discusses our database and workload assumptions.
Reference: [32] <author> R. Gruber, F. Kaashoek, B. Liskov, and L. Shrira. </author> <title> Disconnected operation in the thor object-oriented database system. </title> <booktitle> In IEEE Workshop on Mobile Computing Systems and Applications, </booktitle> <address> Santa Cruz, CA, </address> <month> December </month> <year> 1994. </year>
Reference-contexts: respect to a high variance in the availability or performance properties of clients. (Similar arguments about the benefits of lock-free synchronization have been made at the multiprocessors and operating system level [31, 34].) Due to this client-independence property, optimistic schemes are more easily extended to support a "disconnected client" semantics <ref> [32] </ref>. The remainder of this chapter is organized as follows. Section 1.1 discusses our system model assumptions, while Section 1.2 discusses our database and workload assumptions. Section 1.3 then summarizes the contributions of the thesis in more detail.
Reference: [33] <author> T. Haerder. </author> <title> Observations on optimistic concurrency control schemes. </title> <journal> Information Systems, </journal> <volume> 9(2) </volume> <pages> 111-120, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: The seminal paper on optimism is by Kung and Robinson [38]. Bernstein et. al. and Gray and Reuter [30] both provide good overviews of concurrency control and recovery issues, including later work on distributed database concurrency control. Optimistic schemes can be classified <ref> [33] </ref> into forward and backward validation schemes. Backward validation schemes such as AOCC validate a transaction against already-committed transactions, while forward validation schemes validate a transaction against active transactions.
Reference: [34] <author> M. P. Herlihy and J. E. B. Moss. </author> <title> Transactional memory: Architectural support for lock-free data structures. </title> <type> Technical Report DEC/CRL 92/07, </type> <institution> Digital Equipment Corp. Cambridge Research Lab., </institution> <address> Cambridge, MA, </address> <month> December </month> <year> 1992. </year>
Reference-contexts: Thus, optimism is more robust with respect to a high variance in the availability or performance properties of clients. (Similar arguments about the benefits of lock-free synchronization have been made at the multiprocessors and operating system level <ref> [31, 34] </ref>.) Due to this client-independence property, optimistic schemes are more easily extended to support a "disconnected client" semantics [32]. The remainder of this chapter is organized as follows. Section 1.1 discusses our system model assumptions, while Section 1.2 discusses our database and workload assumptions.
Reference: [35] <author> A. Joshi. </author> <title> Adaptive locking strategies in a multi-node data sharing system. </title> <booktitle> In 17th International Conference on Very Large Data Bases (VLDB), </booktitle> <address> Barcelona, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: PS-AA's design was inspired by the adaptive locking algorithm described by Joshi for the VAXCluster version of Rdb/VMS <ref> [35] </ref>. We use this scheme in our optimism vs. locking comparison study because previous client-server con-currency control studies suggest it is the best locking choice for a client-server OODB.
Reference: [36] <author> A. Kemper and D. Kossmann. </author> <title> Dual-buffer strategies in object bases. </title> <booktitle> In 20th International Conference on Very Large Data Bases (VLDB), </booktitle> <address> Santiago, Chile, </address> <year> 1994. </year>
Reference-contexts: However, we believe that our results have wide applicability: the client cache assumption holds for many present-day systems and applications, and will encompass more cases in the future, due to improved cache designs and increasing cache sizes. Main memory at clients will continue to increase. Furthermore, hybrid cache designs <ref> [36, 47] </ref> retain both useful pages and useful objects, resulting in more effective use of cache space.
Reference: [37] <author> W. Kim, J. F. Garza, N. Ballou, and D. Woelk. </author> <title> Architecture of the ORION next-generation database system. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1) </volume> <pages> 109-124, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: In particular, we study client-server object-oriented databases (OODBs). We focus on systems where servers provide the storage for a universe of shared persistent objects (persistent stores), while clients run application code that uses this object state. For most client-server OODBs, including research prototypes such as ORION <ref> [37] </ref>, EXODUS [26], SHORE [9], and Thor [43] and also commercially available systems like GemStone [6], O2 [16, 17], ObjectStore [40], Ontos [46], Objectivity [45], Statice [60], and Versant [52], object accesses are performed at clients on cached copies of the persistent objects.
Reference: [38] <author> H. T. Kung and J. T. Robinson. </author> <title> On optimistic methods for concurrency control. </title> <journal> ACM TODS, </journal> <volume> 6(2) </volume> <pages> 213-226, </pages> <month> June </month> <year> 1981. </year>
Reference-contexts: Fundamentally, there are two kinds of concurrency control, pessimism (locking) and optimism. The seminal paper on standard two-phase locking is by Eswaran et. al. [21]. The seminal paper on optimism is by Kung and Robinson <ref> [38] </ref>. Bernstein et. al. and Gray and Reuter [30] both provide good overviews of concurrency control and recovery issues, including later work on distributed database concurrency control. Optimistic schemes can be classified [33] into forward and backward validation schemes. <p> In addition to this standard problem, there is design flaw specific to the Certification design that explains Certification's poor performance. Certification is a purely optimistic scheme that uses the original Kung/Robinson certification check to validate commit requests <ref> [38] </ref>. As with NWL, passive cache maintenance is used. Wang and Rowe decided that the use of passive cache maintenance made it likely that out-of-date state would be accessed, thus a pre-access version number check is used prior to allowing a cached page to be accessed. <p> The system can then rescue this transaction by holding a semaphore during its next restart execution that effectively locks the entire database, ensuring that the restart will succeed <ref> [38] </ref>. Thomasian and Rahm proposed a page-level variant of this idea: on abort, page-level locks can be acquired for the pages accessed by failed transaction T, ensuring that T's restart will succeed as long T does not access any new pages during restart [48].
Reference: [39] <author> M. Y. Lai and W. K. Wilkinson. </author> <title> Distributed transaction management in Jasmin. </title> <booktitle> In 10th International Conference on Very Large Data Bases (VLDB), </booktitle> <month> August </month> <year> 1984. </year>
Reference-contexts: Optimistic schemes can be classified [33] into forward and backward validation schemes. Backward validation schemes such as AOCC validate a transaction against already-committed transactions, while forward validation schemes validate a transaction against active transactions. Multi-version concurrency control can be used for both locking schemes [59] and optimistic schemes <ref> [6, 2, 39, 41] </ref> to isolate read-only transactions from read-write transactions. Multi-version schemes ensure that read-only transactions always commit, but have higher space overheads than single-version schemes. An additional approach to concurrency control, not studied in this thesis, is timestamp-ordering. <p> Timestamp schemes are summarized in [4]. All of these mechanisms can be applied to a client-server OODB. For example, the GemStone [6] and Jasmine <ref> [39] </ref> OODBs use multi-version optimistic schemes. Below we focus on work directly related to this thesis: Sections 3.1-3.3 review three studies of single-version client-server schemes.
Reference: [40] <author> C. Lamb, G. Landis, J. Orenstein, and D. Weinreb. </author> <title> The ObjectStore database system. </title> <journal> CACM, </journal> <volume> 34(10), </volume> <month> October </month> <year> 1991. </year>
Reference-contexts: For most client-server OODBs, including research prototypes such as ORION [37], EXODUS [26], SHORE [9], and Thor [43] and also commercially available systems like GemStone [6], O2 [16, 17], ObjectStore <ref> [40] </ref>, Ontos [46], Objectivity [45], Statice [60], and Versant [52], object accesses are performed at clients on cached copies of the persistent objects. Moving data to the applications has two main advantages.
Reference: [41] <author> G. Lausen. </author> <title> Formal aspects of optimistic concurrency control in a multi-version database system. </title> <journal> Information Systems, </journal> <volume> 8(4) </volume> <pages> 291-301, </pages> <year> 1983. </year>
Reference-contexts: Optimistic schemes can be classified [33] into forward and backward validation schemes. Backward validation schemes such as AOCC validate a transaction against already-committed transactions, while forward validation schemes validate a transaction against active transactions. Multi-version concurrency control can be used for both locking schemes [59] and optimistic schemes <ref> [6, 2, 39, 41] </ref> to isolate read-only transactions from read-write transactions. Multi-version schemes ensure that read-only transactions always commit, but have higher space overheads than single-version schemes. An additional approach to concurrency control, not studied in this thesis, is timestamp-ordering.
Reference: [42] <author> E. K. Lee. </author> <title> Software and performance issues in the implementation of a RAID prototype. </title> <type> Technical Report UCB/CSD 90/573, </type> <institution> University of California, Berke-ley, </institution> <year> 1990. </year>
Reference-contexts: If the schedule for the K reads is a good one, the schedule for the K + N writes should be as good, and possibly better, 1 A separate detailed disk simulator <ref> [42] </ref> was used to simulate random 4 KB reads for the Barracuda; the average access time was very close to our calculated value. 161 since there may be more operations (for N &gt; 0). There might be an additional seek between the read and write phase.
Reference: [43] <author> B. Liskov, A. Adya, M. Castro, M. Day, S. Ghemawat, R. Gruber, U. Mahesh-wari, A. C. Myers, and L. Shrira. </author> <title> Safe and efficient sharing of persistent objects in Thor. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 318-329, </pages> <address> Montreal, Quebec, Canada, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: We focus on systems where servers provide the storage for a universe of shared persistent objects (persistent stores), while clients run application code that uses this object state. For most client-server OODBs, including research prototypes such as ORION [37], EXODUS [26], SHORE [9], and Thor <ref> [43] </ref> and also commercially available systems like GemStone [6], O2 [16, 17], ObjectStore [40], Ontos [46], Objectivity [45], Statice [60], and Versant [52], object accesses are performed at clients on cached copies of the persistent objects. Moving data to the applications has two main advantages. <p> default and "future" system parameter settings used in our experiments. 19 20 Chapter 2 Optimistic and Locking Designs This chapter describes two concurrency control schemes: * AOCC, a new optimistic scheme that we designed, is a variant of the "OCC" scheme [1] we developed for use in the Thor OODB <ref> [43] </ref>. <p> In this case the undo log state represents 1% of the client cache size. Measurements of the Thor object-oriented database system <ref> [43] </ref> show that undo log maintenance has very low cost.
Reference: [44] <author> C. Maeda and B. N. Bershad. </author> <title> Protocol server decomposition for high-performance networking. </title> <booktitle> In 14th ACM Symposium on Operating System Principles, </booktitle> <pages> pages 244-255, </pages> <address> Asheville, NC, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: Cost (secs/KB) 404 361 398 378 SPECInt92 Rating 19.5 19.5 19.5 19.5 Fixed Cost (instr.) 5990 6448 6581 6776 Var. Cost (instr./KB) 7877 7041 7770 7379 Latencies taken from Table 2 in Maeda/Bershad <ref> [44] </ref>; note that our message sizes are an estimate of the total bytes sent. Figure A-6. Kernel-Based Messaging Costs We estimate the fixed and variable CPU costs associated with message processing using a simple back-of-the-envelope calculation. <p> Figure A-6 shows how this process works, by estimating fixed and variable CPU costs based on reported latencies from a Maeda/Bershad study <ref> [44] </ref> that used two DECStation 5000/200's and a 10 Mbps Ethernet. (Other studies report similar latencies for monolithic kernels, e.g., [53] reports similar Ethernet/Ultrix latencies for the 5000/200.) Each column shows one back-of-the-envelope calculation; the final estimated costs are at the bottom.
Reference: [45] <author> Objetivity. </author> <title> Inc. </title> <journal> objectivity/db documentation vol. </journal> <volume> 1, </volume> <year> 1991. </year>
Reference-contexts: For most client-server OODBs, including research prototypes such as ORION [37], EXODUS [26], SHORE [9], and Thor [43] and also commercially available systems like GemStone [6], O2 [16, 17], ObjectStore [40], Ontos [46], Objectivity <ref> [45] </ref>, Statice [60], and Versant [52], object accesses are performed at clients on cached copies of the persistent objects. Moving data to the applications has two main advantages.
Reference: [46] <author> ONTOS. Inc. </author> <title> ONTOS db 2.2 reference manual, </title> <year> 1992. </year>
Reference-contexts: For most client-server OODBs, including research prototypes such as ORION [37], EXODUS [26], SHORE [9], and Thor [43] and also commercially available systems like GemStone [6], O2 [16, 17], ObjectStore [40], Ontos <ref> [46] </ref>, Objectivity [45], Statice [60], and Versant [52], object accesses are performed at clients on cached copies of the persistent objects. Moving data to the applications has two main advantages.
Reference: [47] <author> J. O'Toole and L. Shrira. </author> <title> Hybrid caching for scalable object systems (think globally, act locally. </title> <booktitle> In 6th Int'l Workshop on Persistent Object Systems, </booktitle> <address> Tarascon, France, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: However, we believe that our results have wide applicability: the client cache assumption holds for many present-day systems and applications, and will encompass more cases in the future, due to improved cache designs and increasing cache sizes. Main memory at clients will continue to increase. Furthermore, hybrid cache designs <ref> [36, 47] </ref> retain both useful pages and useful objects, resulting in more effective use of cache space.
Reference: [48] <author> E. Rahm and A. Thomasian. </author> <title> A new distributed optimistic concurrency control method and a comparison of its performance with two-phase locking. </title> <booktitle> In 10th Int'l Conference on Distributed Computing Systems, </booktitle> <year> 1990. </year>
Reference-contexts: Thomasian and Rahm proposed a page-level variant of this idea: on abort, page-level locks can be acquired for the pages accessed by failed transaction T, ensuring that T's restart will succeed as long T does not access any new pages during restart <ref> [48] </ref>. The Thomasian/Rahm scheme uses locking on the very first abort; it attempts to avoid all multiple-restart scenarios. A possible area of future work is to use simulation to investigate the effectiveness of different starvation solutions.
Reference: [49] <author> C. Ruemmler and J. Wilkes. </author> <title> An introduction to disk drive modeling. </title> <journal> IEEE Computer, </journal> <volume> 27(3) </volume> <pages> 17-28, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: However, the seek-based algorithm is easier to implement, and is not dependent on the characteristics of a particular disk drive, so it is clearly the better choice from a practical standpoint.) The performance of FUTURE disk drives is hard to predict. Ruemmler and Wilkes <ref> [49] </ref> note that while rotational speed was stuck at 3600 RPM for many years, it has been steadily increasing (high performance disks are currently using 7200 RPM) and should continue to increase at a compound rate of 12% per year.
Reference: [50] <author> M. Seltzer, P. Chen, and J. Ousterhout. </author> <title> Disk scheduling revisited. </title> <booktitle> In Winter Usenix Technical Conference, </booktitle> <pages> pages 313-324, </pages> <address> Washington, DC, </address> <month> winter </month> <year> 1990. </year>
Reference-contexts: Using the units of our disk model, the slow 160 bandwidth is thus 3322 secs/KB. 1 Scheduler % of Total Bandwidth % of Average Seek Random 7% 100% Seek Based 17% 37% + Rotation Based 25% 23% Numbers Derived from Seltzer et. al. <ref> [50] </ref> Figure A-9. Results of Intelligent Disk Scheduling For the fast bandwidth, we need to determine the bandwidth one would expect from the Barracuda if an intelligent scheduling algorithm were used to install the object updates stored in the modified object buffer (MOB). <p> Fortunately, the problem of scheduling disk accesses out of a large pool of possible choices has already been studied. In Seltzer, Chen, and Ousterhout <ref> [50] </ref>, a detailed disk simulator is used to compare different scheduling algorithms for scheduling up to 1000 4 KB disk writes.
Reference: [51] <author> J. W. Stamos. </author> <title> Static grouping of small objects to enhance performance of a paged virtual memory. </title> <journal> ACM TOCS, </journal> <volume> 2(2) </volume> <pages> 155-180, </pages> <month> May </month> <year> 1984. </year>
Reference-contexts: them; objects within a cached page can be marked as "missing." Both schemes studied in the thesis use object-level marking. 1.2 Database and Workload Assumptions In addition to assuming that the normal case for an OODB is to have multiple objects per database page, we assume that a clustering algorithm <ref> [3, 14, 19, 51, 54, 55] </ref> is used to produce a well-clustered database with respect to common access patterns. In other words, a transaction accessing page P is likely to access multiple P objects. The database can be very large (much larger than the client or server caches). <p> Clustering and Write Probabilities We assume that the objects stored in the database have been placed onto pages by some clustering process that uses information about common access patterns or the links between objects to determine groups of objects that are likely to be accessed together <ref> [3, 14, 19, 51, 54, 55] </ref>. Clustering is important for performance; the objects on a page are read from disk as a group and are sent to a client as a group. We model the quality of clustering by specifying a range of cluster sizes.
Reference: [52] <author> V. O. </author> <title> Technology. VERSANT system reference manual, release 1.6, </title> <year> 1991. </year>
Reference-contexts: For most client-server OODBs, including research prototypes such as ORION [37], EXODUS [26], SHORE [9], and Thor [43] and also commercially available systems like GemStone [6], O2 [16, 17], ObjectStore [40], Ontos [46], Objectivity [45], Statice [60], and Versant <ref> [52] </ref>, object accesses are performed at clients on cached copies of the persistent objects. Moving data to the applications has two main advantages.
Reference: [53] <author> C. Thekkath, T. Nguyen, E. Moy, and E. Lazowska. </author> <title> Implementing network protocols at user level. </title> <booktitle> In ACM SIGCOMM Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication, </booktitle> <address> San Francisco, CA, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: Figure A-6 shows how this process works, by estimating fixed and variable CPU costs based on reported latencies from a Maeda/Bershad study [44] that used two DECStation 5000/200's and a 10 Mbps Ethernet. (Other studies report similar latencies for monolithic kernels, e.g., <ref> [53] </ref> reports similar Ethernet/Ultrix latencies for the 5000/200.) Each column shows one back-of-the-envelope calculation; the final estimated costs are at the bottom. We give the estimates for two monolithic kernels (Mach 2.5A and Ultrix 4.2) and two network protocols (TCP and UDP).
Reference: [54] <author> M. M. Tsangaris and J. F. Naughton. </author> <title> A stochastic approach to clustering. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 12-21, </pages> <address> Denver, CO, </address> <month> May </month> <year> 1991. </year> <month> 170 </month>
Reference-contexts: them; objects within a cached page can be marked as "missing." Both schemes studied in the thesis use object-level marking. 1.2 Database and Workload Assumptions In addition to assuming that the normal case for an OODB is to have multiple objects per database page, we assume that a clustering algorithm <ref> [3, 14, 19, 51, 54, 55] </ref> is used to produce a well-clustered database with respect to common access patterns. In other words, a transaction accessing page P is likely to access multiple P objects. The database can be very large (much larger than the client or server caches). <p> Clustering and Write Probabilities We assume that the objects stored in the database have been placed onto pages by some clustering process that uses information about common access patterns or the links between objects to determine groups of objects that are likely to be accessed together <ref> [3, 14, 19, 51, 54, 55] </ref>. Clustering is important for performance; the objects on a page are read from disk as a group and are sent to a client as a group. We model the quality of clustering by specifying a range of cluster sizes.
Reference: [55] <author> M. M. Tsangaris and J. F. Naughton. </author> <title> On the performance of object cluster-ing techniques. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 144-153, </pages> <address> San Diego, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: them; objects within a cached page can be marked as "missing." Both schemes studied in the thesis use object-level marking. 1.2 Database and Workload Assumptions In addition to assuming that the normal case for an OODB is to have multiple objects per database page, we assume that a clustering algorithm <ref> [3, 14, 19, 51, 54, 55] </ref> is used to produce a well-clustered database with respect to common access patterns. In other words, a transaction accessing page P is likely to access multiple P objects. The database can be very large (much larger than the client or server caches). <p> Clustering and Write Probabilities We assume that the objects stored in the database have been placed onto pages by some clustering process that uses information about common access patterns or the links between objects to determine groups of objects that are likely to be accessed together <ref> [3, 14, 19, 51, 54, 55] </ref>. Clustering is important for performance; the objects on a page are read from disk as a group and are sent to a client as a group. We model the quality of clustering by specifying a range of cluster sizes. <p> Accessing 10 out of 40 objects means that the clustering algorithm is doing a fairly good job. Better clustering is generally hard to achieve. For example, a study by Tsangaris and Naughton found that most practical clustering algorithms provide poor clustering <ref> [55] </ref>, while algorithms that provide good clustering were prohibitively expensive. Default Write Probabilities. For regions that are updated, the default net write probability is 10%. Average write clustering is used for this default, i.e., cluster write probability is 50% and object write probability is 20%).
Reference: [56] <author> T. von Eicken, A. Basu, V. Buch, and W. Vogels. U-Net: </author> <title> A user-level network interface for parallel and distributed comuting. </title> <booktitle> In 15th ACM Symposium on Operating System Principles, </booktitle> <address> Copper Mountain, CO, </address> <month> December </month> <year> 1995. </year>
Reference-contexts: Newer approaches such as the ones described in <ref> [5, 20, 56] </ref> move most of the network code to user-level. For protection and fairness reasons, kernel interaction is still required to set up user-level communication. Shared memory regions are used to provide the required level of protection. <p> For protection and fairness reasons, kernel interaction is still required to set up user-level communication. Shared memory regions are used to provide the required level of protection. However, once such regions are established, user-level processes can communicate without using kernel calls. As <ref> [56] </ref> points out, an ideal "zero copy" protocol would be possible if the network interface could "map in" arbitrary memory from the user-level address space (send and receive queues could contain arbitrary descriptors of message contents). Most current I/O architectures do not allow I/O devices to do arbitrary mapping. <p> Even such a 1-copy approach saves copying compared to a monolithic kernel that does not share message buffers with user-level processes. Von Eicken <ref> [56] </ref> gives a good summary of the advantages of the user-level approach. For backward compatibility, user-level libraries can implement the protocols commonly available in existing kernels (e.g., UDP and TCP). <p> Cost (secs/KB) 25 25 SPECInt92 Rating 98.2 98.2 Fixed Cost (instr.) 3615 3124 Var. Cost (instr./KB) 2484 2484 Latencies are from the Figure 9 graph in von Eicken et. al. <ref> [56] </ref>; the numbers we use are "best guesses" for some data points on this graph. Figure A-7. Reported Latencies: User-Level Messaging We now consider FUTURE system CPU costs. Figure A-7 shows our back-of-the-envelope calculations for TCP and UDP latencies over a prototype user-level messaging system [56] called UNet. <p> in von Eicken et. al. <ref> [56] </ref>; the numbers we use are "best guesses" for some data points on this graph. Figure A-7. Reported Latencies: User-Level Messaging We now consider FUTURE system CPU costs. Figure A-7 shows our back-of-the-envelope calculations for TCP and UDP latencies over a prototype user-level messaging system [56] called UNet. Note that the measured latencies have dropped dramatically from those in Figure A-6. The variable cost for both cases is only 25 secs per KB. The fixed cost is 32-37 secs.
Reference: [57] <author> Y. Wang. </author> <title> Performance Studies of Cache Consistency and Concurrency Control Algorithms in a Distributed Client/Server Architecture. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1992. </year>
Reference-contexts: Intuitively, optimism would seem to be the preferred approach for low contention workloads, since it uses fewer messages. However, previous work does not support this intuition. There are two client-server studies we know of that compare optimism with locking. One study shows that locking is always better <ref> [57, 58] </ref>; the other shows that optimism is slightly better, but only under low contention [23, 24]. 13 This thesis reverses these earlier results. <p> Therefore, we study schemes that do not discard the client cache contents at end of each transaction. Previous studies have shown that such inter-transaction caching provides performance benefits for workloads with inter-transaction locality <ref> [23, 24, 57, 58, 61] </ref>. We study workloads with both low and high inter-transaction locality of reference. With respect to the interaction of transactions at different clients, we use three different sharing patterns (in different combinations) in our workloads. The patterns define different kinds of database regions. <p> We use this scheme in our optimism vs. locking comparison study because previous client-server con-currency control studies suggest it is the best locking choice for a client-server OODB. Comparative performance studies by both Franklin and Carey [23, 24] and Wang and Rowe <ref> [57, 58] </ref> conclude that callback locking is the best locking approach for low-to-moderate contention workloads. These studies used page-level conflict detection for all of the schemes compared. <p> Since read accesses are normally more frequent than write accesses, the message tradeoff made by CBR should result in lower message costs when compared to a 2PL scheme. Several performance studies have demonstrated that CBR outperforms a 2PL scheme except when high contention workloads are used <ref> [23, 24, 57, 58] </ref>. CBR has excellent performance for read accesses, and moreover the cost of a write lock acquisition is amortized across accesses to multiple objects on a page. <p> For example, the GemStone [6] and Jasmine [39] OODBs use multi-version optimistic schemes. Below we focus on work directly related to this thesis: Sections 3.1-3.3 review three studies of single-version client-server schemes. These studies, by Franklin and Carey [23, 24], Wang and Rowe <ref> [58, 57] </ref>, and Wilkinson and Neimat [61], examine nine different concurrency control schemes that use inter-transaction caching. These schemes use coarse-granularity (page-level) conflict detection. (AOCC and ACBL use fine-granularity conflict detection, as described in Chapter 2.) Figure 3-1 presents a brief description of each scheme. <p> Passive schemes do not generate cache maintenance actions on either a per-write or per-commit basis; no attempt is made to keep caches from becoming arbitrarily out-of-date, and all maintenance actions occur due to accesses to invalid pages. 3.2 Wang and Rowe Wang and Rowe <ref> [58, 57] </ref> studied a number of client-server schemes. 3.2.1 C2PL vs. CBA Like Franklin and Carey, Wang and Rowe compare C2PL and CBA to determine the value of caching locks with pages. <p> Studying this issue is an area of future work. 6.2.3 Restart Behavior Most concurrency-control simulation studies (including the client-server studies most similar to our work <ref> [10, 23, 24, 57, 58] </ref>) use a "perfect restart" assumption: on an abort, the access pattern of the failed transaction is used without modification for the subsequent restart execution.
Reference: [58] <author> Y. Wang and L. A. Rowe. </author> <title> Cache consistency and concurrency control in a client/server DBMS architecture. </title> <booktitle> In ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 367-376, </pages> <address> Denver, CO, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Intuitively, optimism would seem to be the preferred approach for low contention workloads, since it uses fewer messages. However, previous work does not support this intuition. There are two client-server studies we know of that compare optimism with locking. One study shows that locking is always better <ref> [57, 58] </ref>; the other shows that optimism is slightly better, but only under low contention [23, 24]. 13 This thesis reverses these earlier results. <p> Therefore, we study schemes that do not discard the client cache contents at end of each transaction. Previous studies have shown that such inter-transaction caching provides performance benefits for workloads with inter-transaction locality <ref> [23, 24, 57, 58, 61] </ref>. We study workloads with both low and high inter-transaction locality of reference. With respect to the interaction of transactions at different clients, we use three different sharing patterns (in different combinations) in our workloads. The patterns define different kinds of database regions. <p> We use this scheme in our optimism vs. locking comparison study because previous client-server con-currency control studies suggest it is the best locking choice for a client-server OODB. Comparative performance studies by both Franklin and Carey [23, 24] and Wang and Rowe <ref> [57, 58] </ref> conclude that callback locking is the best locking approach for low-to-moderate contention workloads. These studies used page-level conflict detection for all of the schemes compared. <p> Since read accesses are normally more frequent than write accesses, the message tradeoff made by CBR should result in lower message costs when compared to a 2PL scheme. Several performance studies have demonstrated that CBR outperforms a 2PL scheme except when high contention workloads are used <ref> [23, 24, 57, 58] </ref>. CBR has excellent performance for read accesses, and moreover the cost of a write lock acquisition is amortized across accesses to multiple objects on a page. <p> For example, the GemStone [6] and Jasmine [39] OODBs use multi-version optimistic schemes. Below we focus on work directly related to this thesis: Sections 3.1-3.3 review three studies of single-version client-server schemes. These studies, by Franklin and Carey [23, 24], Wang and Rowe <ref> [58, 57] </ref>, and Wilkinson and Neimat [61], examine nine different concurrency control schemes that use inter-transaction caching. These schemes use coarse-granularity (page-level) conflict detection. (AOCC and ACBL use fine-granularity conflict detection, as described in Chapter 2.) Figure 3-1 presents a brief description of each scheme. <p> Passive schemes do not generate cache maintenance actions on either a per-write or per-commit basis; no attempt is made to keep caches from becoming arbitrarily out-of-date, and all maintenance actions occur due to accesses to invalid pages. 3.2 Wang and Rowe Wang and Rowe <ref> [58, 57] </ref> studied a number of client-server schemes. 3.2.1 C2PL vs. CBA Like Franklin and Carey, Wang and Rowe compare C2PL and CBA to determine the value of caching locks with pages. <p> Studying this issue is an area of future work. 6.2.3 Restart Behavior Most concurrency-control simulation studies (including the client-server studies most similar to our work <ref> [10, 23, 24, 57, 58] </ref>) use a "perfect restart" assumption: on an abort, the access pattern of the failed transaction is used without modification for the subsequent restart execution.
Reference: [59] <author> W. Weihl. </author> <title> Distributed version management for read-only actions. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-13(1), </volume> <month> January </month> <year> 1987. </year>
Reference-contexts: Optimistic schemes can be classified [33] into forward and backward validation schemes. Backward validation schemes such as AOCC validate a transaction against already-committed transactions, while forward validation schemes validate a transaction against active transactions. Multi-version concurrency control can be used for both locking schemes <ref> [59] </ref> and optimistic schemes [6, 2, 39, 41] to isolate read-only transactions from read-write transactions. Multi-version schemes ensure that read-only transactions always commit, but have higher space overheads than single-version schemes. An additional approach to concurrency control, not studied in this thesis, is timestamp-ordering.
Reference: [60] <author> D. Weinreb, N. Feinberg, D. Gerson, and C. Lamb. </author> <title> An object-oriented database system to support an integrated programming environment. </title> <journal> Database Engineering, </journal> <volume> 7(1) </volume> <pages> 85-95, </pages> <year> 1988. </year>
Reference-contexts: For most client-server OODBs, including research prototypes such as ORION [37], EXODUS [26], SHORE [9], and Thor [43] and also commercially available systems like GemStone [6], O2 [16, 17], ObjectStore [40], Ontos [46], Objectivity [45], Statice <ref> [60] </ref>, and Versant [52], object accesses are performed at clients on cached copies of the persistent objects. Moving data to the applications has two main advantages. <p> Thus, both the blocking rate and the abort rate increase as contention increases. As discussed for O2PL, a scheme that can simultaneously incur both a high blocking rate and a high abort rate will have poor high-contention performance. (Gerson implemented no-wait locking for the Statice system <ref> [60] </ref>. His implementation switches to two-phase locking for "hot" pages, thus attempting to avoid a high abort rate [27]. No performance study has examined this adaptive variant of NWL.) 3.2.3 NWL vs. NWL-Notify Wang and Rowe also experimented with NWL-Notify, a variant of NWL that uses eager reactive cache maintenance.
Reference: [61] <author> K. Wilkinson and M. Neimat. </author> <title> Maintaining consistency of client-cached data. </title> <booktitle> In 16th International Conference on Very Large Data Bases (VLDB), </booktitle> <pages> pages 122-133, </pages> <address> Brisbane, Australia, </address> <year> 1990. </year> <month> 171 </month>
Reference-contexts: Therefore, we study schemes that do not discard the client cache contents at end of each transaction. Previous studies have shown that such inter-transaction caching provides performance benefits for workloads with inter-transaction locality <ref> [23, 24, 57, 58, 61] </ref>. We study workloads with both low and high inter-transaction locality of reference. With respect to the interaction of transactions at different clients, we use three different sharing patterns (in different combinations) in our workloads. The patterns define different kinds of database regions. <p> For example, the GemStone [6] and Jasmine [39] OODBs use multi-version optimistic schemes. Below we focus on work directly related to this thesis: Sections 3.1-3.3 review three studies of single-version client-server schemes. These studies, by Franklin and Carey [23, 24], Wang and Rowe [58, 57], and Wilkinson and Neimat <ref> [61] </ref>, examine nine different concurrency control schemes that use inter-transaction caching. These schemes use coarse-granularity (page-level) conflict detection. (AOCC and ACBL use fine-granularity conflict detection, as described in Chapter 2.) Figure 3-1 presents a brief description of each scheme. <p> This analysis is consistent with the results presented by Wang and Rowe. 3.3 Wilkinson and Neimat Wilkinson and Neimat <ref> [61] </ref> performed the first client-server concurrency control study to examine schemes that use inter-transaction caching. Two such schemes are described, Cache Locks and Notify Locks. The simulation results presented by Wilkinson and Neimat are hard to interpret: a different client cache model is used for the two schemes.
References-found: 61

