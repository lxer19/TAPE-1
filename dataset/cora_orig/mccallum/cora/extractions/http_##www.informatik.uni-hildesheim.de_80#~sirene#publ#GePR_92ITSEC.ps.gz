URL: http://www.informatik.uni-hildesheim.de:80/~sirene/publ/GePR_92ITSEC.ps.gz
Refering-URL: http://www.informatik.uni-hildesheim.de:80/~sirene/lit/sirene.lit.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Information Technology Security Evaluation Criteria (ITSEC) a Contribution to Vulnerability?  
Author: Michael Gehrke a Andreas Pfitzmann b and Kai Rannenberg c b 
Keyword: Keyword Codes: K.7.3; K.6.5; D.4.6 Keywords: The Computing Profession, Certification, and Licensing; Management of Computing and Informa tion Systems, Security and Protection; Operating Systems, Security and Protection  
Address: Sekr. FR  Franklinstr. 28/29, W-1000 Berlin 10, Germany,  Hildesheim, Samelsonplatz 1, W-3200 Hildesheim, Germany,  Sekr. FR  Berlin,  
Affiliation: a Institute for Applied Informatics,  Technical University Berlin,  Institute for Informatics, University  c Institute for Applied Informatics,  Technical University  
Note: Education and Society, R. Aiken (ed.), Proc. 12th IFIP World Computer Congress 1992, Information Processing 92, Vol. II, Elsevier Science Publishers B.V. (North-Holland),  panying discussion are criticized and improvements are proposed.  
Email: EMail: micky@cs.tu-berlin.de  EMail: pfitza@informatik.uni-hildesheim.de  
Phone: 5-9,  5-10,  
Date: 1992 579  
Abstract: Franklinstr. 28/29, W-1000 Berlin 10, Germany, EMail: kara@cs.tu-berlin.de Abstract On initiative of the Commission of the European Communities, the Information Technology Security Evaluation Criteria (ITSEC) are designed to provide a yardstick for the evaluation and certification of the security of IT systems. To improve the usefulness of resulting evaluations and certificates for procurers, users, and manufacturers the ITSEC are intended to undergo further extensive review. We discuss weaknesses, remaining questions, and possible improvements concerning the current version 1.2 of ITSEC. Our criticism focusses on the intended scope, the functionality aspects, the assessment of effectiveness and correctness, and problems arising after the evaluation of IT systems. Additionally, the ITSEC development and the accom 
Abstract-found: 1
Intro-found: 1
Reference: [Brk, Pfitzmann 1990] <author> Holger Brk, Andreas Pfitzmann: </author> <title> Value Exchange Systems Enabling Security and Unobservability; Computers & Security 9/8 (1990) 715-721 </title>
Reference-contexts: In theory nearly any application can be realized that way [Chaum 1990 and references there] and in practice many essential applications can, e.g., communication networks, payment systems, authorization systems or value exchange systems <ref> [Chaum 1985; Pfitzmann, Pfitzmann, Waidner 1991; Brk, Pfitzmann 1990] </ref>. (2) In distributed systems one cannot prevent unauthorized modification of data, e.g., in transit on a network, but one can detect unauthorized modification with cryptographical means. <p> Protection of Users in Communication Systems: Neither the generic headings nor the proposed functionality classes give guidance for the adequate classification and certification of TOEs which provide anonymity, pseudonymity, and freeness from observability to their users <ref> [Chaum 1985; Pfitzmann, Pfitzmann, Waidner 1991; Brk, Pfitzmann 1990] </ref>. ITSEC V1.2 do not give any help for evaluation and certification of TOEs which work without the need or enforcement of any gathering of unnecessary person-related information.
Reference: [CEC 1991_1] <editor> (Informal) EC advisory group SOG-IS: </editor> <title> Information Technology Security Evaluation Criteria (ITSEC) Provisional Harmonised Criteria; Version 1.2, </title> <month> 28 June </month> <year> 1991, </year> <institution> 163 pages (obtainable free of charge from CEC; Directorate XIII/F; SOG-IS Secretariat; Rue de la Loi, </institution> <address> 200; B-1049 Brussels; Belgium) </address>
Reference-contexts: Secondly, increasing information flow enhances the possibilities for misuse, e.g., by eavesdropping, modification of information, or information flow analysis. In the following, we understand "security" as the property of IT to withstand accidental and intentional threats. To increase the security of IT systems the ITSEC <ref> [CEC 1991_1] </ref> have been developed. This paper deals with weaknesses, remaining questions, and possible improvements found during review of the current version of ITSEC. Its purpose is to stimulate the discussion about the intended scope, the functionality aspects, assurance of effectiveness and correctness, and post-evaluation problems of ITSEC. <p> Additionally, the desired evaluation level is specified (see below). Security enforcing functions may be either specified individually or by referencing one of 10 predefined "functionality classes" <ref> [CEC 1991_1, Annex A] </ref>.
Reference: [CEC 1991_2] <editor> (Informal) EC advisory group SOG-IS: ITSEC V1.1 Revision: </editor> <booktitle> Adressing the Main Issues, </booktitle> <month> June </month> <year> 1991, </year> <title> 9 pages (obtainable free of charge like [CEC 1991_1]) </title>
Reference-contexts: The ultimate level would require verified design for all used tools (recursive definition!), i.e., one needs some form of secure bootstrap in generating these tools. Even if the suggested levels E7 and E8 might be not achievable considering today's "state of the art" <ref> [CEC 1991_2] </ref> criteria should define or at least mention possible targets. What the criteria makers believe to be "the state of the art" might be more a matter of expense than "art". Even if it was "art" hopefully the "state of the art" emerges faster than (hopefully stable) criteria. <p> This has been asked for unanimously at VIS'91, an international scientific conference on dependable computer systems organized by the GI (German IFIP Full Member) in March 1991 [Rannenberg 1991]. <ref> [CEC 1991_2] </ref> and its predecessor are only a first step as they do not contain all critical points and give very few answers.
Reference: [CESG 1989] <institution> UK Systems Security Confidence Levels, CESG Memorandum No.3, Communications-Electronics Security Group, </institution> <address> United Kingdom, </address> <month> January </month> <year> 1989 </year>
Reference-contexts: As is indicated by the participation of four countries in publishing ITSEC several documents preceded and provided input to the ITSEC. These documents are: Catal. de Crit. Dest. valuer le Degr de Confiance d. Syst. d'Info. [SCSSI 1989] UK Systems Security Confidence Levels <ref> [CESG 1989] </ref> DTI Commercial Computer Security Centre Evaluation Manual [DTI 1989_1] DTI Commercial Computer Security Centre Functionality Manual [DTI 1989_2] ITSecurity Criteria (ZSISEC) [GISA 1989]. Additionally, the Netherlands contributed to ITSEC.
Reference: [Chaum 1985] <author> David Chaum, </author> <title> Security without Identification: Transaction Systems to make Big Brother Obsolete; Communications of the ACM 28/10 (1985) 1030-1044 </title>
Reference-contexts: In theory nearly any application can be realized that way [Chaum 1990 and references there] and in practice many essential applications can, e.g., communication networks, payment systems, authorization systems or value exchange systems <ref> [Chaum 1985; Pfitzmann, Pfitzmann, Waidner 1991; Brk, Pfitzmann 1990] </ref>. (2) In distributed systems one cannot prevent unauthorized modification of data, e.g., in transit on a network, but one can detect unauthorized modification with cryptographical means. <p> Protection of Users in Communication Systems: Neither the generic headings nor the proposed functionality classes give guidance for the adequate classification and certification of TOEs which provide anonymity, pseudonymity, and freeness from observability to their users <ref> [Chaum 1985; Pfitzmann, Pfitzmann, Waidner 1991; Brk, Pfitzmann 1990] </ref>. ITSEC V1.2 do not give any help for evaluation and certification of TOEs which work without the need or enforcement of any gathering of unnecessary person-related information. <p> TOEs which protect users by keeping their data confidential can only be classified by negating the generic headings. The same is true for TOEs which protect usees by making them users operating their own individual computers <ref> [Chaum 1985] </ref> ("Usees" are people, whose data "users" are working with, potentially putting them at risk). So the ITSEC seem to be focussed neither on the issues of the users nor of the usees. Generic Headings: The 8 generic headings for the security enforcing functions are incom M. Gehrke, A. <p> Gehrke, A. Pfitzmann, and K. Rannenberg: ITSEC a Contribution to Vulnerability? 584 plete and unsystematic. They are incomplete as essential counterparts to the given classes are missing. For some services, Identification and Authentication are wanted, for other services, one needs the corresponding counterparts Anonymity and Pseudonymity, cf. <ref> [Chaum 1985] </ref>. The same relationship exists between Audit and its counterpart Freeness from observability. The generic headings are unsystematic as "Data Exchange" is no generic heading at the same level of abstraction as the other 7 generic headings given, e.g., there is no generic heading "Data Storage".
Reference: [Chaum 1990] <author> David Chaum: </author> <title> The Spymasters double-agent problem: Multiparty computations secure unconditionally from minorities and cryptographically from majorities; Crypto '89, </title> <publisher> LNCS 435, Springer-Verlag, </publisher> <address> Heidelberg 1990, </address> <pages> 591-602 </pages>
Reference: [Dierstein 1990] <author> Rdiger Dierstein: </author> <title> The Concept of Secure Information Processing Systems and their Basic Functions; IFIP/Sec'90, </title> <publisher> Helsinki, </publisher> <address> May 1990; North-Holland; Amsterdam 1990 </address>
Reference-contexts: Although [Rihaczek 1991] is related to ITSEC V1.0, at the level of its treatment, all critical remarks remain true for V1.2. 3 . 2 Criticism by Rdiger Dierstein Although Rdiger Dierstein does not mention ITSEC at all (since <ref> [Dierstein 1990] </ref> has been written before the first publication of ITSEC), this is an implicit, but especially severe criticism.
Reference: [DTI 1989_1] <institution> DTI Commercial Computer Security Centre Evaluation Manual, V22; DTI, UK, </institution> <month> February </month> <year> 1989 </year>
Reference-contexts: These documents are: Catal. de Crit. Dest. valuer le Degr de Confiance d. Syst. d'Info. [SCSSI 1989] UK Systems Security Confidence Levels [CESG 1989] DTI Commercial Computer Security Centre Evaluation Manual <ref> [DTI 1989_1] </ref> DTI Commercial Computer Security Centre Functionality Manual [DTI 1989_2] ITSecurity Criteria (ZSISEC) [GISA 1989]. Additionally, the Netherlands contributed to ITSEC. The U.S. catalogue, the "Trusted Computer Systems Evaluation Criteria" (TCSEC) of the Department of Defense [US_DOD 1983, 1985], is a predecessor which influenced all documents above.
Reference: [DTI 1989_2] <institution> DTI Commercial Computer Security Centre Functionality Manual, V21; DTI, UK, </institution> <month> February </month> <year> 1989 </year>
Reference-contexts: These documents are: Catal. de Crit. Dest. valuer le Degr de Confiance d. Syst. d'Info. [SCSSI 1989] UK Systems Security Confidence Levels [CESG 1989] DTI Commercial Computer Security Centre Evaluation Manual [DTI 1989_1] DTI Commercial Computer Security Centre Functionality Manual <ref> [DTI 1989_2] </ref> ITSecurity Criteria (ZSISEC) [GISA 1989]. Additionally, the Netherlands contributed to ITSEC. The U.S. catalogue, the "Trusted Computer Systems Evaluation Criteria" (TCSEC) of the Department of Defense [US_DOD 1983, 1985], is a predecessor which influenced all documents above.
Reference: [GISA 1989] <author> ITSecurity Criteria, </author> <title> Criteria for the Evaluation of Trustworthiness of Information Technology (IT) Systems, </title> <institution> ISBN 3-88784-200-6, German Information Security Agency, FR of Germany, </institution> <month> January </month> <year> 1989 </year>
Reference-contexts: These documents are: Catal. de Crit. Dest. valuer le Degr de Confiance d. Syst. d'Info. [SCSSI 1989] UK Systems Security Confidence Levels [CESG 1989] DTI Commercial Computer Security Centre Evaluation Manual [DTI 1989_1] DTI Commercial Computer Security Centre Functionality Manual [DTI 1989_2] ITSecurity Criteria (ZSISEC) <ref> [GISA 1989] </ref>. Additionally, the Netherlands contributed to ITSEC. The U.S. catalogue, the "Trusted Computer Systems Evaluation Criteria" (TCSEC) of the Department of Defense [US_DOD 1983, 1985], is a predecessor which influenced all documents above. Despite several similarities between different national evaluation criteria a couple of main differences can be extracted. <p> This is a trivial condition and only suited to characterize basic and not at all high. The highest rating has to be called, e.g., "unbreakable". One gets it from the highest rating in <ref> [GISA 1989] </ref>, "virtually unbreakable", which "prevents all violations of the security policy and according to the present state of the art it is practically impossible to overcome. []". Omitting "according to [] art" results in a time-independent definition for "unbreakable". <p> Examples of mechanisms rated "unbreakable" are the onetime pad [Shannon 1949] or information-theoretic authentication codes [Simmons 1988]. The discrimination between strengths of mechanisms in only three ratings (basic, medium, or high) is very poor and not adequate. There must be more ratings, see, e.g., <ref> [GISA 1989] </ref> for more ratings and good definitions. Few ratings imply relatively big rounding errors which stimulates subjectivity. With many classes one can handle the problem of subjectivity by giving one class as expectation and two further classes as an upper and lower bound. <p> It is also an aspect of the correctness as Covert Channels can be introduced into a system during the implementation. Neither in the Chapters 0-6 of ITSEC, nor in the proposed functionality classes, there are limits imposed on the bandwidth of covert channels. Compared with [US_DOD 1983, 1985] and <ref> [GISA 1989] </ref> this is a large step backward. M. Gehrke, A. Pfitzmann, and K. <p> Further on the current definition of E4 might restrict the evaluation of all TOEs of the near future to only three levels. Evaluation Levels beyond E6 Consideration of Tools: As in <ref> [GISA 1989] </ref>, it must be stated clearly that evaluation levels beyond E6 are possible, very desirable, and might be defined in the future. One reason for this is the existence of transitive Trojan Horses [Thomp-son 1984]. <p> Vulnerability increases if the ITSEC are used by unexperienced persons as certain threats are ignored without any documentation of this fact. An example are the recommended generic headings in combination with the 10 example functionality classes derived from the ZSISEC <ref> [GISA 1989] </ref> which can give the false impression every security issue is covered. A decrease of vulnerability caused by ITSEC is only possible if experienced people knowing the weaknesses of ITSEC use the criteria.
Reference: [Pfitzmann 1991] <author> Andreas Pfitzmann: </author> <title> Statement of Observations concerning the Information Technology Security Evaluation Criteria (ITSEC) Version 1.2, </title> <institution> 28 June 1991; Institut fr Informatik, University of Hildesheim, Germany, </institution> <month> November 29, </month> <year> 1991 </year>
Reference-contexts: Post-evaluation problems are addressed in 4.5, weaknesses of the ITSEC development and discussion process in 4.6. More detailed criticism <ref> [Pfitzmann 1991] </ref> can be obtained from the authors. 4 . 1 Title and Scope The ITSEC do not address the scope suggested by their title and their scope section and needed in an information society.
Reference: [Pfitzmann, Pfitzmann, Waidner 1991] <author> Andreas Pfitzmann, Birgit Pfitzmann, Michael Waidner: </author> <title> ISDN-MIXes Untraceable Communication with very small Bandwidth Overhead; Proc. </title> <address> IFIP/Sec'91, Brighton, UK, May 1991; North-Holland; Amsterdam 1991; 245-258 </address>
Reference-contexts: In theory nearly any application can be realized that way [Chaum 1990 and references there] and in practice many essential applications can, e.g., communication networks, payment systems, authorization systems or value exchange systems <ref> [Chaum 1985; Pfitzmann, Pfitzmann, Waidner 1991; Brk, Pfitzmann 1990] </ref>. (2) In distributed systems one cannot prevent unauthorized modification of data, e.g., in transit on a network, but one can detect unauthorized modification with cryptographical means. <p> Protection of Users in Communication Systems: Neither the generic headings nor the proposed functionality classes give guidance for the adequate classification and certification of TOEs which provide anonymity, pseudonymity, and freeness from observability to their users <ref> [Chaum 1985; Pfitzmann, Pfitzmann, Waidner 1991; Brk, Pfitzmann 1990] </ref>. ITSEC V1.2 do not give any help for evaluation and certification of TOEs which work without the need or enforcement of any gathering of unnecessary person-related information.
Reference: [Rannenberg 1991] <author> Kai Rannenberg: VIS'91: </author> <note> ITSicherheit Bewertungskriterien; Computer & Recht 7/11 (1991) 699-701 </note>
Reference-contexts: This has been asked for unanimously at VIS'91, an international scientific conference on dependable computer systems organized by the GI (German IFIP Full Member) in March 1991 <ref> [Rannenberg 1991] </ref>. [CEC 1991_2] and its predecessor are only a first step as they do not contain all critical points and give very few answers.
Reference: [Rihaczek 1991] <author> Karl Rihaczek: </author> <title> The Harmonized ITSEC Evaluation Criteria; Comp. </title> & <type> Sec. </type> <month> 10 </month> <year> (1991) </year> <month> 101-110 </month>
Reference-contexts: a report to the national certification authority, which will provide a certificate to the sponsor at least stating the evaluation level reached. 3 SUMMARY OF FORMER CRITICISMS ON ITSEC This section summarizes criticism already published and hence not repeated in detail. 3 . 1 Criticism by Karl Rihaczek Karl Rihaczek <ref> [Rihaczek 1991] </ref> pointed out that standardization of evaluation criteria despite all M. Gehrke, A. Pfitzmann, and K. Rannenberg: ITSEC a Contribution to Vulnerability? 582 advantages has the drawback that manufacturers will try to adhere to a standard because of marketing reasons. <p> He states that non-repudiation, which can be seen as a fourth basic security property at the side of confidentiality, integrity, and availability, is not really covered. This makes ITSEC unsuitable for Open Systems. Moreover, he raises the question of the legal relevance of evaluation certificates. Although <ref> [Rihaczek 1991] </ref> is related to ITSEC V1.0, at the level of its treatment, all critical remarks remain true for V1.2. 3 . 2 Criticism by Rdiger Dierstein Although Rdiger Dierstein does not mention ITSEC at all (since [Dierstein 1990] has been written before the first publication of ITSEC), this is an
Reference: [SCSSI 1989] <institution> Catalogue de Critres Destins valuer le Degr de Confiance des Systmes d'Information, 692/SGDN/DISSI/SCSSI, Service Central de la Scurit des Systmes d'Information, </institution> <month> Juillet </month> <year> 1989. </year>
Reference-contexts: The experience gained shall then be used to further develop ITSEC. As is indicated by the participation of four countries in publishing ITSEC several documents preceded and provided input to the ITSEC. These documents are: Catal. de Crit. Dest. valuer le Degr de Confiance d. Syst. d'Info. <ref> [SCSSI 1989] </ref> UK Systems Security Confidence Levels [CESG 1989] DTI Commercial Computer Security Centre Evaluation Manual [DTI 1989_1] DTI Commercial Computer Security Centre Functionality Manual [DTI 1989_2] ITSecurity Criteria (ZSISEC) [GISA 1989]. Additionally, the Netherlands contributed to ITSEC.
Reference: [Shannon 1949] <author> Claude E. </author> <title> Shannon, </title> <journal> Communication Theory of Secrecy Systems; The Bell System Technical Journal 28/4 (1949) 656-715 </journal>
Reference-contexts: Omitting "according to [] art" results in a time-independent definition for "unbreakable". Examples of mechanisms rated "unbreakable" are the onetime pad <ref> [Shannon 1949] </ref> or information-theoretic authentication codes [Simmons 1988]. The discrimination between strengths of mechanisms in only three ratings (basic, medium, or high) is very poor and not adequate. There must be more ratings, see, e.g., [GISA 1989] for more ratings and good definitions.
Reference: [Simmons 1988] <author> G. J. Simmons, </author> <title> A Survey of Information Authentication; Proc. </title> <note> IEEE 76/5 (1988) 603-620 </note>
Reference-contexts: Omitting "according to [] art" results in a time-independent definition for "unbreakable". Examples of mechanisms rated "unbreakable" are the onetime pad [Shannon 1949] or information-theoretic authentication codes <ref> [Simmons 1988] </ref>. The discrimination between strengths of mechanisms in only three ratings (basic, medium, or high) is very poor and not adequate. There must be more ratings, see, e.g., [GISA 1989] for more ratings and good definitions. Few ratings imply relatively big rounding errors which stimulates subjectivity.
Reference: [Thompson 1984] <author> Ken Thompson, </author> <note> Reflections on Trusting Trust; CACM 27/8 (1984) 761-763 </note>
Reference: [US_DOD 1983, 1985] <institution> DoD Standard: Department of Defense Trusted Computer System Evaluation Criteria; December 1985, DOD 5200.28-STD, Supersedes CSC-STD-001-83, </institution> <address> dtd 15 Aug 83, Library No. S225,711 </address>
Reference-contexts: Additionally, the Netherlands contributed to ITSEC. The U.S. catalogue, the "Trusted Computer Systems Evaluation Criteria" (TCSEC) of the Department of Defense <ref> [US_DOD 1983, 1985] </ref>, is a predecessor which influenced all documents above. Despite several similarities between different national evaluation criteria a couple of main differences can be extracted. For readers familiar with the above evaluation criteria the differences are compiled in Table 1. <p> It is also an aspect of the correctness as Covert Channels can be introduced into a system during the implementation. Neither in the Chapters 0-6 of ITSEC, nor in the proposed functionality classes, there are limits imposed on the bandwidth of covert channels. Compared with <ref> [US_DOD 1983, 1985] </ref> and [GISA 1989] this is a large step backward. M. Gehrke, A. Pfitzmann, and K.
References-found: 19

