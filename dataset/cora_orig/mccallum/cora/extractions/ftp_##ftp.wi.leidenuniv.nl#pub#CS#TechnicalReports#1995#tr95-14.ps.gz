URL: ftp://ftp.wi.leidenuniv.nl/pub/CS/TechnicalReports/1995/tr95-14.ps.gz
Refering-URL: http://www.wi.leidenuniv.nl/TechRep/tr95-14.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Evolving Artificial Neural Networks using the Baldwin Effect  
Author: E.J.W. Boers, M.V. Borst and I.G. Sprinkhuizen-Kuyper 
Abstract: This paper describes how through simple means a genetic search towards optimal neural network architectures can be improved, both in the convergence speed as in the quality of the final result. This result can be theoretically explained with the Baldwin effect, which is implemented here not just by the learning process of the network alone, but also by changing the network architecture as part of the learning procedure. This can be seen as a combination of two different techniques, both help ing and improving on simple genetic search.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.M. </author> <title> Baldwin; A new factor in evolution. In: </title> <journal> American Naturalist, </journal> <volume> 30, 441451, </volume> <pages> 1896. </pages>
Reference-contexts: This local search, applied at each fitness evaluation of the evolutionary computation, decreases the time needed to find an approximation. This is called the Baldwin effect, named after the one that first observed this in biology <ref> [1] </ref>. 2 Evolutionary Computation This section will outline the three mainstreams in simulated evolution used for optimization, see e.g. [8]. All three kinds of evolutionary computation are based on the same principle: they work on a population of individuals, each representing a possible solution to the problem to be optimized. <p> More experiments are described in [5]. the two hidden modules. what 1 18 where 6 5 Initiating the Baldwin effect Baldwin was the first to recognize the impact of adaptive behavior of individuals on evolution <ref> [1] </ref>. He showed that Lamarckism was not necessary to explain that learned behaviour seems to propagate through the genes of successive generations, but that instead, the inherited character was the ability to learn, with a profitable effect on the fitness of the individual.
Reference: [2] <author> R.K. </author> <title> Belew; When both individuals and populations search: adding simple learning to the genetic algorithm. </title> <editor> In: J.D. Schaffer (Ed.); </editor> <booktitle> Proceedings of the third International Conference on Genetic Algorithms, </booktitle> <volume> 3441, </volume> <publisher> Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: The same effect can be used in evolutionary computation applied to neural networks. When learning is part of the fitness evaluation when searching for a good set of weights for a given architecture, a significant speed-up and final quality of solution can be achieved <ref> [2, 15] </ref>. Also when using evolutionary computation to optimize architectures, learning can increase performance [3,12], but sofar these attempts have been restricted to learning weights.
Reference: [3] <author> E.J.W. Boers and H. </author> <title> Kuiper; Biological Metaphors and the Design of Modular Artificial Neural Networks. MSc. </title> <type> Thesis, </type> <institution> Leiden University, </institution> <year> 1992. </year>
Reference-contexts: There are many ways to represent the different aspects of artificial neural networks in the genetic material of the evolutionary computation algorithms. These ways range from blueprints to codings which make use of a kind of recipe describing only the generation of the network <ref> [3, 4] </ref>. This last method is more scalable towards real-life problems: one recipe can be used to generate the appropriate networks for a whole class of problems. Furthermore, very large architectures can be generated with just a small recipe, reducing the search space of the evolutionary computation algorithm. In: D.W. <p> Boers et al. <ref> [3, 4] </ref> used L-systems, coded in the chromosomes of a genetic algorithm, to grow the architecture of feedforward networks. The fitness was calculated by looking at the generalization of the resulting networks after training. Gruau [11] proposed a similar approach, using cellular encoding. <p> Only the size of the produced architecture varies. Since the architecture of a network greatly affects its performance, this is a serious restriction. Here, we propose a constructive method that is able to work on modular architectures <ref> [3, 4, 13] </ref>, the initial architecture of which is found using evolutionary computation. This algorithm determines during training where to perform the adaptation [5]. We considered the following possibilities: adding nodes to existing modules, adding connections between modules and adding modules.
Reference: [4] <author> E.J.W. Boers, H. Kuiper, B.L.M. Happel and I.G. </author> <title> Sprinkhuizen-Kuy-per; Designing modular artificial neural networks. </title> <booktitle> In: H.A. Wijshoff; Computing Science in The Netherlands: Proceedings (CSN93), </booktitle> <editor> Ed.: H.A. Wijshoff, </editor> <volume> 8796, </volume> <publisher> Stichting Mathematisch Centrum, </publisher> <address> Amsterdam, </address> <year> 1993. </year>
Reference-contexts: There are many ways to represent the different aspects of artificial neural networks in the genetic material of the evolutionary computation algorithms. These ways range from blueprints to codings which make use of a kind of recipe describing only the generation of the network <ref> [3, 4] </ref>. This last method is more scalable towards real-life problems: one recipe can be used to generate the appropriate networks for a whole class of problems. Furthermore, very large architectures can be generated with just a small recipe, reducing the search space of the evolutionary computation algorithm. In: D.W. <p> Boers et al. <ref> [3, 4] </ref> used L-systems, coded in the chromosomes of a genetic algorithm, to grow the architecture of feedforward networks. The fitness was calculated by looking at the generalization of the resulting networks after training. Gruau [11] proposed a similar approach, using cellular encoding. <p> Only the size of the produced architecture varies. Since the architecture of a network greatly affects its performance, this is a serious restriction. Here, we propose a constructive method that is able to work on modular architectures <ref> [3, 4, 13] </ref>, the initial architecture of which is found using evolutionary computation. This algorithm determines during training where to perform the adaptation [5]. We considered the following possibilities: adding nodes to existing modules, adding connections between modules and adding modules.
Reference: [5] <author> M.V. </author> <title> Borst; Local Structure Optimization in Evolutionairy Generated Neural Network Architectures. MSc. </title> <type> Thesis, </type> <institution> Leiden University, </institution> <year> 1994. </year>
Reference-contexts: Here, we propose a constructive method that is able to work on modular architectures [3, 4, 13], the initial architecture of which is found using evolutionary computation. This algorithm determines during training where to perform the adaptation <ref> [5] </ref>. We considered the following possibilities: adding nodes to existing modules, adding connections between modules and adding modules. Adding a module, in most architectures, is not a small adaptation; i.e. it inuences the predefined modular structure in a major way. <p> An other important issue is the initialization of the weights of the added 5 node, and the possible ways to treat the existing weights. Ideas taken from cascaded-correlation [7], and growing cell-structures [10] were tried, which increased the learning speed compared with random initializations <ref> [5] </ref>. To give an impression of the results of this relatively simple algorithm we show some experiments we did with the What/Where problem [22], where 9 different 3x3 patterns are presented on all 9 possible positions in a 5x5 grid, giving a total of 81 different input/output patterns. <p> It is easy to see that our algorithm follows the optimal path, and learns the task, which demonstrates that it is correctly determining the module where the next node should be added. More experiments are described in <ref> [5] </ref>. the two hidden modules. what 1 18 where 6 5 Initiating the Baldwin effect Baldwin was the first to recognize the impact of adaptive behavior of individuals on evolution [1].
Reference: [6] <author> Y.L. Cun, J. Denker and S. </author> <title> Solla; Optimal brain damage. </title> <booktitle> In: Advances in Neural Information Processing Systems, </booktitle> <volume> 2, 598605, </volume> <year> 1990. </year>
Reference-contexts: Nodes or edges are removed until the network is no longer able to perform its task. Then the last removal is undone <ref> [6, 20, 21] </ref>. Destructive algorithms leave us with the problem of finding an initial architecture. Existing constructive algorithms produce architectures that, with respect to their shape, are problem independent. Only the size of the produced architecture varies.
Reference: [7] <author> S.E. Fahlman and C. </author> <booktitle> Lebiere; The Cascaded-Correlation Learning Architecture. In: Advances in Neural Information Processing Systems, </booktitle> <volume> 2, </volume> <pages> 524-532, </pages> <year> 1990. </year>
Reference-contexts: When the remaining error is sufficiently low, this process is halted <ref> [7, 9, 17, 18] </ref>. destructive algorithms, which start with large architectures and remove complexity, usually to improve generalization, by decreasing the number of free variables of the network. Nodes or edges are removed until the network is no longer able to perform its task. <p> This rarely led to differences in the path followed by the algorithm, indicating the robusteness of the method. An other important issue is the initialization of the weights of the added 5 node, and the possible ways to treat the existing weights. Ideas taken from cascaded-correlation <ref> [7] </ref>, and growing cell-structures [10] were tried, which increased the learning speed compared with random initializations [5].
Reference: [8] <author> D.B. </author> <title> Fogel; An introduction to simulated evolutionary optimization. In: </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 5, 314, </volume> <year> 1994. </year>
Reference-contexts: This is called the Baldwin effect, named after the one that first observed this in biology [1]. 2 Evolutionary Computation This section will outline the three mainstreams in simulated evolution used for optimization, see e.g. <ref> [8] </ref>. All three kinds of evolutionary computation are based on the same principle: they work on a population of individuals, each representing a possible solution to the problem to be optimized.
Reference: [9] <author> M. </author> <title> Fran; The Upstart algorithm: a method for constructing and training feedforward neural networks. </title> <booktitle> In: Neural Computations, </booktitle> <volume> 2, 198 209, </volume> <year> 1990. </year>
Reference-contexts: When the remaining error is sufficiently low, this process is halted <ref> [7, 9, 17, 18] </ref>. destructive algorithms, which start with large architectures and remove complexity, usually to improve generalization, by decreasing the number of free variables of the network. Nodes or edges are removed until the network is no longer able to perform its task.
Reference: [10] <author> B. </author> <title> Fritzke; Growing cell structures - A self-organizing network for unsupervised and supervised Learning. </title> <address> TR-93-026, </address> <year> 1993. </year>
Reference-contexts: An other important issue is the initialization of the weights of the added 5 node, and the possible ways to treat the existing weights. Ideas taken from cascaded-correlation [7], and growing cell-structures <ref> [10] </ref> were tried, which increased the learning speed compared with random initializations [5].
Reference: [11] <author> F. </author> <title> Gruau; Neural Network Synthesis Using Cellular Encoding and the Genetic Algorithm. </title> <type> PhD. Thesis, </type> <institution> lEcole Normale Suprieure de Lyon, </institution> <year> 1994. </year> <month> 8 </month>
Reference-contexts: Boers et al. [3, 4] used L-systems, coded in the chromosomes of a genetic algorithm, to grow the architecture of feedforward networks. The fitness was calculated by looking at the generalization of the resulting networks after training. Gruau <ref> [11] </ref> proposed a similar approach, using cellular encoding. His method uses the tree representation of genetic programming to store grammar trees, containing instructions which describe the architecture as well as the weights of the network.
Reference: [12] <author> F. Gruau and D. </author> <title> Whitley; Adding learning to the cellular development of neural networks: evolution and the Baldwin effect. In: </title> <journal> Evolutionary Computation, </journal> <volume> 1, 213233, </volume> <year> 1993. </year>
Reference: [13] <author> B.L.M. Happel and J.M.J. </author> <title> Murre; Design and evolution of modular neural network architectures. </title> <booktitle> In: Neural Networks, </booktitle> <volume> 7, 9851004, </volume> <year> 1994. </year>
Reference-contexts: 1 Introduction Recently, several papers appeared which describe the optimization of artificial neural networks using evolutionary computation, e.g. <ref> [13, 15] </ref>. There are many approaches to this mixture of biologically inspired methods. Various aspects of artificial neural networks can be optimized, and several varieties of evolutionary computation exist. <p> Only the size of the produced architecture varies. Since the architecture of a network greatly affects its performance, this is a serious restriction. Here, we propose a constructive method that is able to work on modular architectures <ref> [3, 4, 13] </ref>, the initial architecture of which is found using evolutionary computation. This algorithm determines during training where to perform the adaptation [5]. We considered the following possibilities: adding nodes to existing modules, adding connections between modules and adding modules.
Reference: [14] <author> S.A. Harp, T. Samad and A. </author> <title> Guha; Towards the genetic synthesis of neural networks. </title> <editor> In: J.D. Schaffer (Ed.); </editor> <booktitle> Proceedings of the third International Conference on Genetic Algorithms (ICGA), </booktitle> <volume> 360369, </volume> <publisher> Kaufmann, </publisher> <address> San Mateo, CA, 1989.. </address>
Reference-contexts: The different coding schemes for representing artificial neural networks in the genes of a population are strongly related to the type of evolutionary computation and the neural network training paradigm. 3.1 Blueprint representations Here, a complete one-to-one relation exists between the networks weight and/or architecture and its genetic representation, e.g. <ref> [14] </ref>. 3.2 Recipes In this approach, not the complete network is coded, but just an algorithmic description of how to create the network. Boers et al. [3, 4] used L-systems, coded in the chromosomes of a genetic algorithm, to grow the architecture of feedforward networks.
Reference: [15] <author> G.E. Hinton and S.J. </author> <title> Nowlan; How learning can guide evolution. In: </title> <journal> Complex Systems, </journal> <volume> 1, 495502, </volume> <year> 1987 </year>
Reference-contexts: 1 Introduction Recently, several papers appeared which describe the optimization of artificial neural networks using evolutionary computation, e.g. <ref> [13, 15] </ref>. There are many approaches to this mixture of biologically inspired methods. Various aspects of artificial neural networks can be optimized, and several varieties of evolutionary computation exist. <p> The same effect can be used in evolutionary computation applied to neural networks. When learning is part of the fitness evaluation when searching for a good set of weights for a given architecture, a significant speed-up and final quality of solution can be achieved <ref> [2, 15] </ref>. Also when using evolutionary computation to optimize architectures, learning can increase performance [3,12], but sofar these attempts have been restricted to learning weights.
Reference: [16] <author> H. </author> <title> Kitano; Designing neural network using genetic algorithm with graph generation system. </title> <journal> Complex Systems, </journal> <volume> 4, 461476, </volume> <year> 1990. </year>
Reference-contexts: His method uses the tree representation of genetic programming to store grammar trees, containing instructions which describe the architecture as well as the weights of the network. This has the consequence that when recursion is used, all weights conform to the same layout. The philosophy behind these and other <ref> [16, 19] </ref> rewriting systems is the scalability of the process, which can not be achieved using blueprint methods. 4 On-line adaptation of architecture An other way to find the correct network architecture is to incorporate online architectural change in the learning algorithm.
Reference: [17] <author> M. Marchand, M. Golea and P. </author> <title> Rujn; A convergence theorem for sequential learning in two-layer perceptrons. In: </title> <journal> Europhysics Letters, </journal> <volume> 11, 487492, </volume> <year> 1990. </year>
Reference-contexts: When the remaining error is sufficiently low, this process is halted <ref> [7, 9, 17, 18] </ref>. destructive algorithms, which start with large architectures and remove complexity, usually to improve generalization, by decreasing the number of free variables of the network. Nodes or edges are removed until the network is no longer able to perform its task.
Reference: [18] <author> M. Mezard and J.-P. </author> <title> Nadal; Learning in feedforward layered networks: the Tiling algorithm. In: </title> <journal> Journal of Physics A, </journal> <volume> 22, 21912204, </volume> <year> 1989. </year>
Reference-contexts: When the remaining error is sufficiently low, this process is halted <ref> [7, 9, 17, 18] </ref>. destructive algorithms, which start with large architectures and remove complexity, usually to improve generalization, by decreasing the number of free variables of the network. Nodes or edges are removed until the network is no longer able to perform its task.
Reference: [19] <author> E. </author> <title> Mjolsness; Bayesian interference on visual grammars by neural nets that optimize. </title> <type> Technical Report YALEU-DCS-TR-854, </type> <institution> Yale University, </institution> <year> 1990. </year>
Reference-contexts: His method uses the tree representation of genetic programming to store grammar trees, containing instructions which describe the architecture as well as the weights of the network. This has the consequence that when recursion is used, all weights conform to the same layout. The philosophy behind these and other <ref> [16, 19] </ref> rewriting systems is the scalability of the process, which can not be achieved using blueprint methods. 4 On-line adaptation of architecture An other way to find the correct network architecture is to incorporate online architectural change in the learning algorithm.
Reference: [20] <author> M. Mozer and P. </author> <title> Smolensky; Skeletonization: a technique for trimming the fat from a network via relevance assessment. </title> <booktitle> In: Advances in Neural Information Processing Systems, </booktitle> <volume> 1, 107115, </volume> <year> 1989. </year>
Reference-contexts: Nodes or edges are removed until the network is no longer able to perform its task. Then the last removal is undone <ref> [6, 20, 21] </ref>. Destructive algorithms leave us with the problem of finding an initial architecture. Existing constructive algorithms produce architectures that, with respect to their shape, are problem independent. Only the size of the produced architecture varies.
Reference: [21] <author> C.W. Omlin and C.L. </author> <title> Giles; Pruning recurrent neural networks for improved generalization performance. </title> <type> Revised Technical Report No. 93-6, </type> <institution> Computer Science Department, Rensselaer Polytechnic Institute, </institution> <address> Troy, N.Y., </address> <year> 1993. </year>
Reference-contexts: Nodes or edges are removed until the network is no longer able to perform its task. Then the last removal is undone <ref> [6, 20, 21] </ref>. Destructive algorithms leave us with the problem of finding an initial architecture. Existing constructive algorithms produce architectures that, with respect to their shape, are problem independent. Only the size of the produced architecture varies.
Reference: [22] <author> J.G. Rueckl, K.R. </author> <title> Cave and S.M. Kosslyn; Why are what and where processed by separate cortical visual systems? A computational investigation. In: </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 1, 171 186, </volume> <year> 1989. </year>
Reference-contexts: Ideas taken from cascaded-correlation [7], and growing cell-structures [10] were tried, which increased the learning speed compared with random initializations [5]. To give an impression of the results of this relatively simple algorithm we show some experiments we did with the What/Where problem <ref> [22] </ref>, where 9 different 3x3 patterns are presented on all 9 possible positions in a 5x5 grid, giving a total of 81 different input/output patterns. The network has to learn which pattern is presented where. Strictly speaking, this problem can be learned without hidden layer.
Reference: [23] <author> D. Whitley, V.S. Gordon and K. </author> <title> Mathias; Lamarckian evolution, the Baldwin effect and function optimization. </title> <editor> In: Y Davidor, H.-P. Schwefel and R. Mnner (Eds.); </editor> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> 866, 615, </volume> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: With the algorithm presented in this paper, it will be possible to optimize modular artificial neural network architectures, implementing the Baldwin effect not just by learning weights, but by adapting the modular structure itself as well. However, as already observed by Whitley et al. <ref> [23] </ref>, the Baldwin effect usually results in better solutions than the Lamarckian approach, but it also takes more time.
References-found: 23

