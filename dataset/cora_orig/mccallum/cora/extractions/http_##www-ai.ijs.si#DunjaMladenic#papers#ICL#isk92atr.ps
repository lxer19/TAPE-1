URL: http://www-ai.ijs.si/DunjaMladenic/papers/ICL/isk92atr.ps
Refering-URL: http://www-ai.ijs.si/DunjaMladenic/bibICL.html
Root-URL: 
Email: nada.lavrac@ijs.ac.mail.yu  
Phone: Phone: (+38)(61) 159 199, Fax: (+38)(61) 161 029  
Title: Stochastic search in inductive concept learning  
Author: Dunja Mladenic, Darko Zupanic Marko Grobelnik and Nada Lavrac 
Keyword: Function: learning Knowledge: if-then rules  
Address: Jamova 39, 61000 Ljubljana, Slovenia  
Affiliation: Jozef Stefan Institute  
Abstract: Concept learning can be viewed as search of the space of concept descriptions. The hypothesis language determines the search space. In standard inductive learning algorithms, the structure of the search space is determined by generalization/specialization operators. Algorithms perform locally optimal search by using a hill-climbing and/or a beam-search strategy. To overcome this limitation, concept learning can be viewed as stochastic search of the space of concept descriptions. The proposed stochastic search method is based on simulated annealing which is known as a successful means for solving combinatorial optimization problems. The stochastic search method, implemented in a rule learning system ATRIS, is based on a compact and efficient representation of the problem and the appropriate operators for structuring the search space. Furthermore, by heuristic pruning of the search space, the method enables also handling of imperfect data. The paper introduces the stochastic search method, describes the ATRIS learning algorithm and gives results of the experiments. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Brunk, C.A. and Pazzani, M.J. </author> <title> (1991) An investigation of noise-tolerant relation concept learning algorithms. </title> <booktitle> Eighth International Workshop on Machine Learning. </booktitle> <address> Evanston, IL: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: value of Bit else change Bit to the old value 7 endif endfor endfor endfor The way of post-processing hypotheses is non-standard; usually, in domains with imperfect data, post-processing is performed by removing selectors from a rule and by removing rules, which is referred to as the reduced error pruning <ref> [13, 1] </ref>.
Reference: [2] <author> Cestnik, B. </author> <title> (1990) Estimating probabilities: A crucial task in machine learning. </title> <booktitle> Proc. of ECAI 90, </booktitle> <address> Stockholm, Sweden. </address>
Reference-contexts: On the other hand, to handle noise, the selected stochastic search strategy is based on the heuristics used to minimize the expected classification error of induced rules by applying the m-estimate <ref> [2] </ref>. The paper describes the stochastic search method implemented in a rule induction system ATRIS. Section 2 introduces the concept learning problem and the VL1-like concept description language. Section 3 describes the method of stochastic search based on Markovian neural networks. Section 4 describes the ATRIS stochastic rule learning system. <p> To alleviate this problem, the Laplace estimate can be used. This estimate, however, relies on the assumption that the prior probability of each class 6 is uniformly distributed [10], which is rarely true in practice. To avoid this assumption, Cestnik <ref> [2] </ref> proposed the m-estimate which was successfully used in the `naive' Bayesian classifier [2] and in tree pruning [4]. What follows is a formula for computing the expected classification accuracy p (C) using the m-estimate: p (C) = N + m This estimate takes into account prior probabilities of classes. <p> This estimate, however, relies on the assumption that the prior probability of each class 6 is uniformly distributed [10], which is rarely true in practice. To avoid this assumption, Cestnik <ref> [2] </ref> proposed the m-estimate which was successfully used in the `naive' Bayesian classifier [2] and in tree pruning [4]. What follows is a formula for computing the expected classification accuracy p (C) using the m-estimate: p (C) = N + m This estimate takes into account prior probabilities of classes.
Reference: [3] <author> Cestnik, B., Kononenko, I. and Bratko, I. </author> <title> (1987) ASSISTANT 86: A knowledge elicitation tool for sophisticated users. </title> <editor> In: Bratko, I. and Lavrac, N. (eds.) </editor> <booktitle> Progress in machine learning. </booktitle> <address> Wilmslow: </address> <publisher> Sigma Press. </publisher>
Reference-contexts: Search can proceed bottom-up or top-down. In top-down search, based on specialization operators, various search strategies can be applied. Usually, only locally optimal search is performed by using a hill-climbing and/or a beam-search strategy. For example, a tree induction system ASSISTANT <ref> [3] </ref> performs hill-climbing, and rule induction systems AQ15 [9] and CN2 [5] perform beam-search. Their success in dealing with real-world problems lies also in the choice of heuristics used to guide the search and to stop the construction of trees/rules. The goal of this research is twofold.
Reference: [4] <author> Cestnik, B. and Bratko, I. </author> <title> (1991) On estimating probabilities in tree pruning. </title> <booktitle> Fifth European Working Session on Learning, EWSL 91. Porto, </booktitle> <address> Portugal: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: This estimate, however, relies on the assumption that the prior probability of each class 6 is uniformly distributed [10], which is rarely true in practice. To avoid this assumption, Cestnik [2] proposed the m-estimate which was successfully used in the `naive' Bayesian classifier [2] and in tree pruning <ref> [4] </ref>. What follows is a formula for computing the expected classification accuracy p (C) using the m-estimate: p (C) = N + m This estimate takes into account prior probabilities of classes.
Reference: [5] <author> Clark, P. and Boswell, R. </author> <title> (1991) Rule induction with CN2: Some recent improvements. </title> <booktitle> Proc. of EWSL 91. Porto, </booktitle> <address> Portugal: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: In top-down search, based on specialization operators, various search strategies can be applied. Usually, only locally optimal search is performed by using a hill-climbing and/or a beam-search strategy. For example, a tree induction system ASSISTANT [3] performs hill-climbing, and rule induction systems AQ15 [9] and CN2 <ref> [5] </ref> perform beam-search. Their success in dealing with real-world problems lies also in the choice of heuristics used to guide the search and to stop the construction of trees/rules. The goal of this research is twofold.
Reference: [6] <author> De Jongh , K.A. and Spears, W.M. </author> <title> (1991) Learning concept classification rules using genetic algorithms. </title> <booktitle> Proc. IJCAI-91. </booktitle> <address> Australia: Sydney. </address> <publisher> Morgan Kaufmann. </publisher> <pages> 10 </pages>
Reference-contexts: A solution of this problem is given in Section 5. In the internal bit representation, similar to the one used by De Jongh and Spears <ref> [6] </ref>, an example complex [Is smiling = yes] V [Holding = balloon _ flag ] is represented as follows: A1 A2 A3 A4 A5 A6 In addition, ATRIS can also use background knowledge. This is done in preprocessing.
Reference: [7] <author> Kovacic, M. </author> <title> (1991) Markovian neural networks. </title> <booktitle> Biological Cybernetics 64, </booktitle> <address> 337--342. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Furthermore, in order to cope with imperfect data, appropriate heuristics are used to stop the search of rules. The search method is based on a variant of simulated annealing [12], named Markovian neural network <ref> [7] </ref>, which has proved successful in solving combinatorial optimization problems. On the other hand, to handle noise, the selected stochastic search strategy is based on the heuristics used to minimize the expected classification error of induced rules by applying the m-estimate [2]. <p> For a selected evaluation function, which is to be minimized, the method performs stochastic search in a discrete state space; the search space is typically factorially large so that it cannot be explored exhaustively. This section presents a method of stochastic search based on Markovian neural networks <ref> [7] </ref> which perform `Markovian' simulated annealing. An optimization problem can be formulated as follows [7]: Let S be a state space consisting of a finite set of states s i , and f : S ! &lt; an evaluation function called energy. <p> This section presents a method of stochastic search based on Markovian neural networks <ref> [7] </ref> which perform `Markovian' simulated annealing. An optimization problem can be formulated as follows [7]: Let S be a state space consisting of a finite set of states s i , and f : S ! &lt; an evaluation function called energy. <p> To do so, a successor of the current state is randomly selected; however, the algorithm assures that successors with a lower value of f have a higher probability of selection. Kovacic <ref> [7] </ref> has implemented the algorithm as a neural network. He has given a convergence proof for the Markovian neural network that asynchroneously updates its neurons' states. Furthermore, he has shown that an asynchronous Markovian neural network is equivalent to an inhomogenous Markov chain.
Reference: [8] <author> Lavrac, N., Dzeroski, S. and Grobelnik, M. </author> <title> (1991) Learning nonrecursive definitions of relations with LINUS. </title> <booktitle> Proc. of EWSL 91. Porto, </booktitle> <address> Portugal: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: In our domain, ATRIS will introduce two new attributes A1 = A2 and A3 = A6, which will be named A7 and A8, respectively. Using this idea, originating from the LINUS relation learning system <ref> [8] </ref>, an extended set of tuples is generated and used in learning.
Reference: [9] <author> Michalski, R.S., Mozetic, I., Hong, J. and Lavrac. N. </author> <title> (1986) The multipurpose incremental learning system AQ15 and its testing application to three medical domains. </title> <booktitle> Proc. of AAAI-86, </booktitle> <pages> 1041-1045. </pages> <address> PA: Philadelphia. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Search can proceed bottom-up or top-down. In top-down search, based on specialization operators, various search strategies can be applied. Usually, only locally optimal search is performed by using a hill-climbing and/or a beam-search strategy. For example, a tree induction system ASSISTANT [3] performs hill-climbing, and rule induction systems AQ15 <ref> [9] </ref> and CN2 [5] perform beam-search. Their success in dealing with real-world problems lies also in the choice of heuristics used to guide the search and to stop the construction of trees/rules. The goal of this research is twofold.
Reference: [10] <author> Mingers, J. </author> <title> (1989) An empirical comparison of pruning methods for decision tree induction. </title> <booktitle> Machine Learning 4 (2). </booktitle> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: This is unreliable when estimating probabilities from a small training set. To alleviate this problem, the Laplace estimate can be used. This estimate, however, relies on the assumption that the prior probability of each class 6 is uniformly distributed <ref> [10] </ref>, which is rarely true in practice. To avoid this assumption, Cestnik [2] proposed the m-estimate which was successfully used in the `naive' Bayesian classifier [2] and in tree pruning [4].
Reference: [11] <author> Mitchell, T. </author> <title> (1982) Generalization as search. </title> <booktitle> Artificial Intelligence 18, </booktitle> <pages> 203-226. </pages>
Reference-contexts: 1 Introduction Concept learning can be viewed as search of the space of concept descriptions <ref> [11] </ref>. The choice of the description language of concepts L C determines the search space, called the hypothesis space. Depending on the choice of the hypothesis language, inductive learning systems can learn either attribute descriptions or first-order relational descriptions.
Reference: [12] <author> Press, W.H., Flannery, B.P., Teukolsky, S.A. and Vetterling, W.T. (19..) </author> <title> Combinatorial minimization: Method of simulated annealing. In Numerical Recipes: </title> <booktitle> The art of scientific computing, </booktitle> <pages> 326-334. </pages> <publisher> Cambridge University Press. </publisher>
Reference-contexts: Furthermore, in order to cope with imperfect data, appropriate heuristics are used to stop the search of rules. The search method is based on a variant of simulated annealing <ref> [12] </ref>, named Markovian neural network [7], which has proved successful in solving combinatorial optimization problems. On the other hand, to handle noise, the selected stochastic search strategy is based on the heuristics used to minimize the expected classification error of induced rules by applying the m-estimate [2].
Reference: [13] <author> Quinlan, J.R. </author> <title> (1987) Simplifying decision trees. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 27, </volume> <pages> 221-234. </pages>
Reference-contexts: value of Bit else change Bit to the old value 7 endif endfor endfor endfor The way of post-processing hypotheses is non-standard; usually, in domains with imperfect data, post-processing is performed by removing selectors from a rule and by removing rules, which is referred to as the reduced error pruning <ref> [13, 1] </ref>.
Reference: [14] <editor> Thrun, S.B. et al. </editor> <title> (1991) The MONK's problems: A performance comparison of different learning algorithms. </title> <type> Technical Report. </type> <institution> Carnegie Mellon University. </institution> <year> 1991. </year>
Reference-contexts: in classification accuracy can be obtained by using both local optimization and reduced error pruning. 5 Experiments and results The algorithm was tested in three toy robot domains, referred to as M onk1, M onk2 and M onk3, which were used to compare a number of different inductive learning algorithms <ref> [15, 14] </ref>. The learning task is to find a description of friendly and unfriendly robots from examples of robots described by six attributes Head shape, Body shape, Is smiling, Holding, Jacket color, and Has tie (see Section 4.2). The experimental method was the following. <p> Different values of the m parameter were tested, ranging from 0.1 to 64. For a fixed m, results are averaged over four runs. Results are given for the best m. Results of applying different learning systems <ref> [14] </ref>, together with the results of our experiments, are given in Table 1. In the M onk1 domain, from 432 possible examples 124 are given as the training set. <p> All of the systems are attribute-value rule/tree learning systems, except for: CLASSWEB (a clustering algorithm), Backpropagation and Cascade Correlation (neural networks), and mFOIL (inductive logic programming). The table, except for the last row, is reproduced from <ref> [14] </ref>. 6 Discussion The paper presents a new search method to be applied in inductive rule learning. The method is based on a variant of simulated annealing, named Markovian neural network, which has proved successful in solving combinatorial optimization problems.
Reference: [15] <author> Wnek, J., Sarma, J., Wahab, A., and Michalski, </author> <title> R.S. (1991) Comparison learning paradigms via diagramatic visualisation: A case study in single concept learning using symbolic, neural net and genetic algorithm methods. </title> <type> Technical Report. </type> <institution> George Mason University, Computer Science Department, </institution> <year> 1990. </year> <month> 11 </month>
Reference-contexts: Pre-processing, search of the `best' complex, stopping criteria and post-processing will be further elaborated in the sections that follow. 4.2 Pre-processing Suppose that the learning task is to find a description of friendly and unfriendly robots <ref> [15] </ref> from examples of robots described by six attributes: A1 Head shape 2 fround, square, octagong, A2 Body shape 2 fround, square, octagong, A3 Is smiling 2 fno, yesg, A4 Holding 2 fsword, balloon, flagg, A5 Jacket color 2 fred, yellow, green, blueg, and A6 Has tie 2 fno, yesg. <p> in classification accuracy can be obtained by using both local optimization and reduced error pruning. 5 Experiments and results The algorithm was tested in three toy robot domains, referred to as M onk1, M onk2 and M onk3, which were used to compare a number of different inductive learning algorithms <ref> [15, 14] </ref>. The learning task is to find a description of friendly and unfriendly robots from examples of robots described by six attributes Head shape, Body shape, Is smiling, Holding, Jacket color, and Has tie (see Section 4.2). The experimental method was the following.
References-found: 15

