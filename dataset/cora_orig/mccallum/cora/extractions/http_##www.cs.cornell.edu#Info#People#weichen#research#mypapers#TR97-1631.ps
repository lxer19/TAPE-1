URL: http://www.cs.cornell.edu/Info/People/weichen/research/mypapers/TR97-1631.ps
Refering-URL: http://www.cs.cornell.edu/Info/People/weichen/research.htm
Root-URL: 
Email: aguilera,weichen,sam@cs.cornell.edu  
Title: Heartbeat: A Timeout-Free Failure Detector for Quiescent Reliable Communication  
Author: Marcos Kawazoe Aguilera Wei Chen Sam Toueg 
Date: May 30, 1997  
Address: Upson Hall,  Ithaca, NY 14853-7501, USA.  
Affiliation: Department of Computer Science  Cornell University  
Abstract: We study the problem of achieving reliable communication with quiescent algorithms (i.e., algorithms that eventually stop sending messages) in asynchronous systems with process crashes and lossy links. We first show that it is impossible to solve this problem without failure detectors. We then show how to solve it using a new failure detector, called heartbeat. In contrast to previous failure detectors that have been used to circumvent impossibility results, the heartbeat failure detector is implementable, and its implementation does not use timeouts. These results have wide applicability: they can be used to transform many existing algorithms that tolerate only process crashes into quiescent algorithms that tolerate both process crashes and message losses. This can be applied to consensus, atomic broadcast, k-set agreement, atomic commitment, etc. The heartbeat failure detector is novel: besides being implementable without timeouts, it does not output lists of suspects as typical failure detectors do. If we restrict failure detectors to output only lists of suspects, quiescent reliable communication requires 3P [ACT97a], which is not implementable. Combined with the results of this paper, this shows that traditional failure detectors that output only lists of suspects have fundamental limitations.
Abstract-found: 1
Intro-found: 1
Reference: [ACT97a] <author> Marcos Kawazoe Aguilera, Wei Chen, and Sam Toueg. </author> <title> On the weakest failure detector to achieve quiescence. </title> <type> Manuscript, </type> <month> April </month> <year> 1997. </year>
Reference-contexts: Note that this algorithm is quiescent: eventually no process sends or receives messages. In <ref> [ACT97a] </ref>, Aguilera et al. show that among all failure detectors that output lists of suspects, 3P is the weakest one that can be used to solve the above problem. 1 Unfortunately, 3P is not implementable in asynchronous systems with process crashes (this would violate a known impossibility result [FLP85, CT96]). <p> HB can be used to solve the problem of quiescent reliable communication and it is implementable, but its counters are unbounded. Can we solve this problem using a failure detector that is both implementable and has bounded output? <ref> [ACT97a] </ref> proves that the answer is no: The weakest failure detector with bounded output that can be used to solve quiescent reliable communication is 3P . Thus, the difference between HB, whose output is unbounded, and existing failure detectors, whose output is bounded, is more than skin deep. <p> Thus, the difference between HB, whose output is unbounded, and existing failure detectors, whose output is bounded, is more than skin deep. The results in this paper combined with those of <ref> [ACT97a] </ref>, show that failure detectors with bounded output (including those that output lists of processes) are restricted in power and/or applicability. 3 Outline of the Results We focus on two types of reliable communication mechanisms: quasi reliable send/receive and reliable broadcast. <p> It can also be used to extend the results of [BCBT96]. 4. HB is novel: it is implementable without timeouts, and it does not output lists of suspects as typical failure detectors do [BDM97, CT96, Gue95, GLS95, LH94, SM95]. The results of this paper, combined with those in <ref> [ACT97a] </ref>, show that lists of suspects is not always the best failure detector output. 5 Reliable communication is a fundamental problem that has been extensively studied, especially in the context of data link protocols (see Chapter 22 of [Lyn96] for a compendium).
Reference: [ACT97b] <author> Marcos Kawazoe Aguilera, Wei Chen, and Sam Toueg. </author> <title> Quiescent reliable communication and quiescent consensus in partitionable networks. </title> <type> Technical Report 97-1632, </type> <institution> Department of Computer Science, Cornell University, </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: By a slight abuse of notation, we sometimes use HB to refer to an arbitrary member of that class. It is easy to generalize the definition of HB so that the failure detector module at each process p outputs the heartbeat of every process in the system <ref> [ACT97b] </ref>, rather than just the heartbeats of the neighbors of p, but we do not need this generality here. 10 8 Quiescent Reliable Communication Using HB The communication networks that we consider are not necessarily completely connected, but we assume that every pair of correct processes is connected through a fair <p> In <ref> [ACT97b] </ref>, we drop this assumption and consider the more general problem of quiescent reliable communication in networks that may partition. <p> In <ref> [ACT97b] </ref> we also consider the problem of consensus for networks that may partition, and we use HB to solve this problem with a quiescent protocol (we also use a generalization of the Eventually Strong failure detector [CT96]). 13 Quiescence versus Termination In this paper we considered communication protocols that tolerate process
Reference: [AT96] <author> Marcos Kawazoe Aguilera and Sam Toueg. </author> <title> Randomization and failure detection: a hybrid approach to solve consensus. </title> <booktitle> In Proceedings of the 10th International Workshop on Distributed Algorithms, Lecture Notes on Computer Science, </booktitle> <pages> pages 29-39. </pages> <publisher> Springer-Verlag, </publisher> <month> October </month> <year> 1996. </year> <month> 24 </month>
Reference-contexts: We then explain how HB can be used to easily transform many existing algorithms that tolerate process crashes into quiescent algorithms that tolerate both process crashes and message losses (fair links). This transformation can be applied to the algorithms for consensus in <ref> [Ben83, Rab83, BT85, CMS89, FM90, AT96, CT96] </ref>, for atomic broadcast in [CT96], for k-set agreement in [Cha93], for atomic commitment in [Gue95], for approximate agreement in [DLP + 86], etc. Finally, we show that HB can be used to extend the work in [BCBT96] to obtain the following result. <p> For example, consider the randomized consensus algorithms of [Ben83, Rab83, CMS89, FM90], the failure-detector based ones of <ref> [CT96, AT96] </ref>, the probabilistic one of [BT85], and the algorithms for atomic broadcast in [CT96], k-set agreement in [Cha93], atomic commitment in [Gue95], and approximate agreement in [DLP + 86].
Reference: [BCBT96] <author> Anindya Basu, Bernadette Charron-Bost, and Sam Toueg. </author> <title> Simulating reliable links with unreliable links in the presence of process crashes. </title> <booktitle> In Proceedings of the 10th International Workshop on Distributed Algorithms, Lecture Notes on Computer Science, </booktitle> <pages> pages 105-122. </pages> <publisher> Springer-Verlag, </publisher> <month> October </month> <year> 1996. </year>
Reference-contexts: The algorithms for the second type are significantly more complex. We also briefly consider two stronger types of communication primitives, namely, reliable send and receive, and uniform reliable broadcast, and give quiescent implementations that use HB. These implementations assume that a majority of processes are correct (a result in <ref> [BCBT96] </ref> shows that this assumption is necessary). We then explain how HB can be used to easily transform many existing algorithms that tolerate process crashes into quiescent algorithms that tolerate both process crashes and message losses (fair links). <p> Finally, we show that HB can be used to extend the work in <ref> [BCBT96] </ref> to obtain the following result. Let P be a problem. Suppose P is correct-restricted (i.e., its specification refers only to the behavior of correct processes) or a majority of processes are correct. <p> is solvable with a quiescent protocol that tolerates only process crashes, then P is also solvable with a quiescent protocol that tolerates process crashes and message losses. 4 To summarize, the main contributions of this paper are: 3 This assumption precludes permanent network partitioning. 4 The link failure model in <ref> [BCBT96] </ref> is slightly different from the one used here (cf. Section 11). 4 1. <p> HB can be used to extend existing algorithms for many fundamental problems (e.g., consensus, atomic broadcast, k-set agreement, atomic commitment, approximate agreement) to tolerate message losses. It can also be used to extend the results of <ref> [BCBT96] </ref>. 4. HB is novel: it is implementable without timeouts, and it does not output lists of suspects as typical failure detectors do [BDM97, CT96, Gue95, GLS95, LH94, SM95]. <p> Our work differs from previous results by focusing on the use of unreliable failure detectors to achieve quiescent reliable communication in the presence of process crashes and link failures. The work by Basu et al. in <ref> [BCBT96] </ref> is the closest to ours, but their protocols do not use failure detectors and are not quiescent. In Section 11, we use HB to extend the results of [BCBT96] and obtain quiescent protocols. The paper is organized as follows. Our model is given in Section 4. <p> The work by Basu et al. in <ref> [BCBT96] </ref> is the closest to ours, but their protocols do not use failure detectors and are not quiescent. In Section 11, we use HB to extend the results of [BCBT96] and obtain quiescent protocols. The paper is organized as follows. Our model is given in Section 4. Section 5 defines the reliable communication primitives that we focus on. In Section 6, we show that, without failure detectors, quiescent reliable communication is impossible. <p> However, stronger types of communication primitives, namely, reliable send and receive, and uniform reliable broadcast, are sometimes needed. We now give quiescent implementations of these primitives for systems with process crashes and message losses. Let t be the number of processes that may crash. <ref> [BCBT96] </ref> shows that if t n=2 (i.e., half of the processes may crash) these primitives cannot be implemented, even if we assume that links may lose only a finite number of messages and we do not require that the implementation be quiescent. <p> made to tolerate both process crashes and message losses (with fair links) in two simple steps: (1) implement HB as described in Section 9, and (2) plug in the quiescent communication primitives given in Section 8. 12 The resulting algorithms tolerate message losses and are quiescent. 11.2 Extending Results of <ref> [BCBT96] </ref> Another way to solve problems with quiescent algorithms that tolerate both process crashes and message losses is obtained by extending the results of [BCBT96]. <p> and (2) plug in the quiescent communication primitives given in Section 8. 12 The resulting algorithms tolerate message losses and are quiescent. 11.2 Extending Results of <ref> [BCBT96] </ref> Another way to solve problems with quiescent algorithms that tolerate both process crashes and message losses is obtained by extending the results of [BCBT96]. That work addresses the following question: given a problem that can be solved in a system where the only possible failures are process crashes, is the problem still solvable if links can also fail by losing messages? One of the models of lossy links considered in [BCBT96] is called fair <p> the results of <ref> [BCBT96] </ref>. That work addresses the following question: given a problem that can be solved in a system where the only possible failures are process crashes, is the problem still solvable if links can also fail by losing messages? One of the models of lossy links considered in [BCBT96] is called fair lossy. Roughly speaking, a fair lossy link p ! q satisfies the following property: If p sends an infinite number of messages to q and q is correct, then q receives an infinite number of messages from p. <p> : and p ! q is fair lossy, q may never receive a copy of m 2 (while it receives m 1 infinitely often), whereas if p ! q is fair, q is guaranteed to receive an infinite number of copies of both m 1 and m 2 . 13 <ref> [BCBT96] </ref> establishes the following result: any problem P that can be solved in systems with process crashes can also be solved in systems with process crashes and fair lossy links, provided P is correct-restricted 14 or a majority of processes are correct. For each of these two cases, [BCBT96] shows how <p> . 13 <ref> [BCBT96] </ref> establishes the following result: any problem P that can be solved in systems with process crashes can also be solved in systems with process crashes and fair lossy links, provided P is correct-restricted 14 or a majority of processes are correct. For each of these two cases, [BCBT96] shows how to transform any algorithm that solves P in a system with process crashes, into one that solves P in a system with process crashes and fair lossy links. <p> The algorithms that result from these transformations, however, are not quiescent: each transformation requires processes to repeatedly send messages forever. Given HB, we can modify the transformations in <ref> [BCBT96] </ref> to ensure that if the original algorithm is quiescent then so is the transformed one. <p> The results in <ref> [BCBT96] </ref>, combined with the above modification, show that if a problem P can be solved with a quiescent algorithm in a system with crash failures only, and either P is correct-restricted or a majority of processes are correct, then P is solvable with a quiescent algorithm that uses HB in a <p> a quiescent algorithm that uses HB in a system with crash failures and fair lossy links. 12 Similar steps can be applied to algorithms that use reliable send/receive or uniform reliable broadcast, provided a majority of processes are correct, by plugging in the implementations given in Section 10. 13 In <ref> [BCBT96] </ref>, message piggybacking is used to overcome message losses.
Reference: [BDM97] <author> Ozalp Babao glu, Renzo Davoli, and Alberto Montresor. </author> <title> Partitionable group membership: specification and algorithms. </title> <type> Technical Report UBLCS-97-1, </type> <institution> Dept. of Computer Science, University of Bologna, Bologna, Italy, </institution> <month> January </month> <year> 1997. </year>
Reference-contexts: Introduced in [CT96], the abstraction of unreliable failure detectors has been used to solve several important problems such as consensus, atomic broadcast, group membership, non-blocking atomic commitment, and leader election <ref> [BDM97, DFKM96, Gue95, LH94, SM95] </ref>. Our goal is to use unreliable failure detectors to achieve quiescence, but before we do so we must address the following important question. <p> It can also be used to extend the results of [BCBT96]. 4. HB is novel: it is implementable without timeouts, and it does not output lists of suspects as typical failure detectors do <ref> [BDM97, CT96, Gue95, GLS95, LH94, SM95] </ref>.
Reference: [Ben83] <author> Michael Ben-Or. </author> <title> Another advantage of free choice: Completely asynchronous agreement protocols. </title> <booktitle> In Proceedings of the 2nd ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 27-30, </pages> <month> August </month> <year> 1983. </year>
Reference-contexts: We then explain how HB can be used to easily transform many existing algorithms that tolerate process crashes into quiescent algorithms that tolerate both process crashes and message losses (fair links). This transformation can be applied to the algorithms for consensus in <ref> [Ben83, Rab83, BT85, CMS89, FM90, AT96, CT96] </ref>, for atomic broadcast in [CT96], for k-set agreement in [Cha93], for atomic commitment in [Gue95], for approximate agreement in [DLP + 86], etc. Finally, we show that HB can be used to extend the work in [BCBT96] to obtain the following result. <p> For example, consider the randomized consensus algorithms of <ref> [Ben83, Rab83, CMS89, FM90] </ref>, the failure-detector based ones of [CT96, AT96], the probabilistic one of [BT85], and the algorithms for atomic broadcast in [CT96], k-set agreement in [Cha93], atomic commitment in [Gue95], and approximate agreement in [DLP + 86].
Reference: [BN92] <author> R. Bazzi and G. Neiger. </author> <title> Simulating crash failures with many faulty processors. </title> <editor> In A. Segal and S. Zaks, editors, </editor> <booktitle> Proceedings of the 6th International Workshop on Distributed Algorithms, volume 647 of Lecture Notes on Computer Science, </booktitle> <pages> pages 166-184. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: To avoid this piggybacking, in this paper we adopted the model of fair links: message losses can now be overcome by separately sending each message repeatedly. 14 Intuitively, a problem P is correct-restricted if its specification does not refer to the behavior of faulty processes <ref> [Gop92, BN92] </ref>. 23 12 Generalization to Networks that Partition In this paper, we assumed that every pair of correct processes are reachable from each other through fair paths. In [ACT97b], we drop this assumption and consider the more general problem of quiescent reliable communication in networks that may partition.
Reference: [BT85] <author> Gabriel Bracha and Sam Toueg. </author> <title> Asynchronous consensus and broadcast protocols. </title> <journal> Journal of the ACM, </journal> <volume> 32(4) </volume> <pages> 824-840, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: We then explain how HB can be used to easily transform many existing algorithms that tolerate process crashes into quiescent algorithms that tolerate both process crashes and message losses (fair links). This transformation can be applied to the algorithms for consensus in <ref> [Ben83, Rab83, BT85, CMS89, FM90, AT96, CT96] </ref>, for atomic broadcast in [CT96], for k-set agreement in [Cha93], for atomic commitment in [Gue95], for approximate agreement in [DLP + 86], etc. Finally, we show that HB can be used to extend the work in [BCBT96] to obtain the following result. <p> Informally, an implementation of SEND s;r and RECEIVE r;s is quiescent if a finite number of invocations of SEND s;r cause only a finite number of invocations of sends throughout the network. 5.2 Reliable Broadcast Reliable broadcast <ref> [BT85] </ref> is defined in terms of two primitives: broadcast (m) and deliver (m). We say that process p broadcasts message m if p invokes broadcast (m). <p> For example, consider the randomized consensus algorithms of [Ben83, Rab83, CMS89, FM90], the failure-detector based ones of [CT96, AT96], the probabilistic one of <ref> [BT85] </ref>, and the algorithms for atomic broadcast in [CT96], k-set agreement in [Cha93], atomic commitment in [Gue95], and approximate agreement in [DLP + 86]. These algorithms tolerate process crashes, and they use quasi reliable send and receive, and/or reliable broadcast, as their sole communication primitives.
Reference: [BT93] <author> Ozalp Babao glu and Sam Toueg. </author> <title> Non-blocking atomic commitment. </title> <editor> In Sape J. Mullender, editor, </editor> <booktitle> Distributed Systems, chapter 6. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1993. </year>
Reference-contexts: This requirement allows a faulty process (i.e., one that subsequently crashes) to deliver a message that is never delivered by the correct processes. This behavior is undesirable in some applications, such as atomic commitment in distributed databases <ref> [Gra78, Had86, BT93] </ref>. For such applications, a stronger version of reliable broadcast is more suitable, namely, uniform reliable broadcast which satisfies Uniform Integrity, Validity (Section 5.2) and: * Uniform Agreement [NT90]: If any process delivers a message m, then all correct processes eventually deliver m.
Reference: [Cha93] <author> Soma Chaudhuri. </author> <title> More choices allow more faults: Set consensus problems in totally asynchronous systems. </title> <journal> Information and Computation, </journal> <volume> 105(1) </volume> <pages> 132-158, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: This transformation can be applied to the algorithms for consensus in [Ben83, Rab83, BT85, CMS89, FM90, AT96, CT96], for atomic broadcast in [CT96], for k-set agreement in <ref> [Cha93] </ref>, for atomic commitment in [Gue95], for approximate agreement in [DLP + 86], etc. Finally, we show that HB can be used to extend the work in [BCBT96] to obtain the following result. Let P be a problem. <p> For example, consider the randomized consensus algorithms of [Ben83, Rab83, CMS89, FM90], the failure-detector based ones of [CT96, AT96], the probabilistic one of [BT85], and the algorithms for atomic broadcast in [CT96], k-set agreement in <ref> [Cha93] </ref>, atomic commitment in [Gue95], and approximate agreement in [DLP + 86]. These algorithms tolerate process crashes, and they use quasi reliable send and receive, and/or reliable broadcast, as their sole communication primitives.
Reference: [Cha97] <author> Tushar Deepak Chandra, </author> <month> April </month> <year> 1997. </year> <title> Private Communication. </title>
Reference-contexts: Thus, HB should not be confused with existing implementations of failure detectors (some of which, such as those in Ensemble and Phoenix, have modules that are also called heartbeat <ref> [vR97, Cha97] </ref>). Even though existing failure detectors are also based on the repeated sending of a heartbeat, they use timeouts on heartbeats in order to derive lists of processes considered to be up or down; applications can only see these lists.
Reference: [CHT96] <author> Tushar Deepak Chandra, Vassos Hadzilacos, and Sam Toueg. </author> <title> The weakest failure detector for solving consensus. </title> <journal> Journal of the ACM, </journal> <volume> 43(4) </volume> <pages> 685-722, </pages> <month> July </month> <year> 1996. </year>
Reference-contexts: Thus, at a first glance, it seems that achieving quiescent reliable communication requires a failure detector that cannot be implemented. In this paper we show that this is not so. 1 See <ref> [CHT96] </ref> for the concept of weakest for failure detectors. 2 2 The Heartbeat Failure Detector We will show that quiescent reliable communication can be achieved with a failure detector that can be implemented without timeouts in systems with process crashes and lossy links. <p> Once a process crashes, it does not recover, i.e., 8t : F (t) F (t + 1). We define 5 The authors of <ref> [CHT96] </ref> anticipated this possibility: they put no restrictions on the output of unreliable failure detectors when they determine the weakest one necessary to solve consensus. 5 crashed (F ) = S t2T F (t) and correct (F ) = P crashed (F ).
Reference: [CMS89] <author> Benny Chor, Michael Merritt, and David B. Shmoys. </author> <title> Simple constant-time consensus protocols in realistic failure models. </title> <journal> Journal of the ACM, </journal> <volume> 36(3) </volume> <pages> 591-614, </pages> <year> 1989. </year>
Reference-contexts: We then explain how HB can be used to easily transform many existing algorithms that tolerate process crashes into quiescent algorithms that tolerate both process crashes and message losses (fair links). This transformation can be applied to the algorithms for consensus in <ref> [Ben83, Rab83, BT85, CMS89, FM90, AT96, CT96] </ref>, for atomic broadcast in [CT96], for k-set agreement in [Cha93], for atomic commitment in [Gue95], for approximate agreement in [DLP + 86], etc. Finally, we show that HB can be used to extend the work in [BCBT96] to obtain the following result. <p> For example, consider the randomized consensus algorithms of <ref> [Ben83, Rab83, CMS89, FM90] </ref>, the failure-detector based ones of [CT96, AT96], the probabilistic one of [BT85], and the algorithms for atomic broadcast in [CT96], k-set agreement in [Cha93], atomic commitment in [Gue95], and approximate agreement in [DLP + 86].
Reference: [CT96] <author> Tushar Deepak Chandra and Sam Toueg. </author> <title> Unreliable failure detectors for reliable distributed systems. </title> <journal> Journal of the ACM, </journal> <volume> 43(2) </volume> <pages> 225-267, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: Moreover, the local lists of suspects dynamically change and lists of different processes do not have to agree (or even eventually agree). Introduced in <ref> [CT96] </ref>, the abstraction of unreliable failure detectors has been used to solve several important problems such as consensus, atomic broadcast, group membership, non-blocking atomic commitment, and leader election [BDM97, DFKM96, Gue95, LH94, SM95]. <p> How can we use an unreliable failure detector to achieve quiescent reliable communication in the presence of process and link failures? Consider the Eventually Perfect failure detector 3P <ref> [CT96] </ref>. Intuitively, 3P satisfies the following two properties: (a) if a process crashes then there is a time after which it is permanently suspected, and (b) if a process does not crash then there is a time after which it is never suspected. <p> In [ACT97a], Aguilera et al. show that among all failure detectors that output lists of suspects, 3P is the weakest one that can be used to solve the above problem. 1 Unfortunately, 3P is not implementable in asynchronous systems with process crashes (this would violate a known impossibility result <ref> [FLP85, CT96] </ref>). Thus, at a first glance, it seems that achieving quiescent reliable communication requires a failure detector that cannot be implemented. <p> We then explain how HB can be used to easily transform many existing algorithms that tolerate process crashes into quiescent algorithms that tolerate both process crashes and message losses (fair links). This transformation can be applied to the algorithms for consensus in <ref> [Ben83, Rab83, BT85, CMS89, FM90, AT96, CT96] </ref>, for atomic broadcast in [CT96], for k-set agreement in [Cha93], for atomic commitment in [Gue95], for approximate agreement in [DLP + 86], etc. Finally, we show that HB can be used to extend the work in [BCBT96] to obtain the following result. <p> This transformation can be applied to the algorithms for consensus in [Ben83, Rab83, BT85, CMS89, FM90, AT96, CT96], for atomic broadcast in <ref> [CT96] </ref>, for k-set agreement in [Cha93], for atomic commitment in [Gue95], for approximate agreement in [DLP + 86], etc. Finally, we show that HB can be used to extend the work in [BCBT96] to obtain the following result. Let P be a problem. <p> It can also be used to extend the results of [BCBT96]. 4. HB is novel: it is implementable without timeouts, and it does not output lists of suspects as typical failure detectors do <ref> [BDM97, CT96, Gue95, GLS95, LH94, SM95] </ref>. <p> This means that failure detectors can neither obtain feedback from applications nor be used by applications to transmit information in any manner. As an example, consider a Strong failure detector D <ref> [CT96] </ref>. Each failure detector module of D outputs a set of processes that are suspected to have crashed, i.e., R D = 2 P . D satisfies the following two properties: * Strong Completeness: Eventually every process that crashes is permanently suspected by every correct process. <p> For example, consider the randomized consensus algorithms of [Ben83, Rab83, CMS89, FM90], the failure-detector based ones of <ref> [CT96, AT96] </ref>, the probabilistic one of [BT85], and the algorithms for atomic broadcast in [CT96], k-set agreement in [Cha93], atomic commitment in [Gue95], and approximate agreement in [DLP + 86]. <p> For example, consider the randomized consensus algorithms of [Ben83, Rab83, CMS89, FM90], the failure-detector based ones of [CT96, AT96], the probabilistic one of [BT85], and the algorithms for atomic broadcast in <ref> [CT96] </ref>, k-set agreement in [Cha93], atomic commitment in [Gue95], and approximate agreement in [DLP + 86]. These algorithms tolerate process crashes, and they use quasi reliable send and receive, and/or reliable broadcast, as their sole communication primitives. <p> In [ACT97b] we also consider the problem of consensus for networks that may partition, and we use HB to solve this problem with a quiescent protocol (we also use a generalization of the Eventually Strong failure detector <ref> [CT96] </ref>). 13 Quiescence versus Termination In this paper we considered communication protocols that tolerate process crashes and message losses, and focused on achieving quiescence. What about achieving termination? A terminating protocol guarantees that every process eventually reaches a halting state from which it cannot take further actions.
Reference: [DFKM96] <author> Danny Dolev, Roy Friedman, Idit Keidar, and Dahlia Malkhi. </author> <title> Failure detectors in omission failure environments. </title> <type> Technical Report 96-1608, </type> <institution> Department of Computer Science, Cornell University, </institution> <address> Ithaca, New York, </address> <year> 1996. </year>
Reference-contexts: Introduced in [CT96], the abstraction of unreliable failure detectors has been used to solve several important problems such as consensus, atomic broadcast, group membership, non-blocking atomic commitment, and leader election <ref> [BDM97, DFKM96, Gue95, LH94, SM95] </ref>. Our goal is to use unreliable failure detectors to achieve quiescence, but before we do so we must address the following important question.
Reference: [DLP + 86] <author> Danny Dolev, Nancy A. Lynch, Shlomit S. Pinter, Eugene W. Stark, and William E. Weihl. </author> <title> Reaching approximate agreement in the presence of faults. </title> <journal> Journal of the ACM, </journal> <volume> 33(3) </volume> <pages> 499-516, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: This transformation can be applied to the algorithms for consensus in [Ben83, Rab83, BT85, CMS89, FM90, AT96, CT96], for atomic broadcast in [CT96], for k-set agreement in [Cha93], for atomic commitment in [Gue95], for approximate agreement in <ref> [DLP + 86] </ref>, etc. Finally, we show that HB can be used to extend the work in [BCBT96] to obtain the following result. Let P be a problem. Suppose P is correct-restricted (i.e., its specification refers only to the behavior of correct processes) or a majority of processes are correct. <p> For example, consider the randomized consensus algorithms of [Ben83, Rab83, CMS89, FM90], the failure-detector based ones of [CT96, AT96], the probabilistic one of [BT85], and the algorithms for atomic broadcast in [CT96], k-set agreement in [Cha93], atomic commitment in [Gue95], and approximate agreement in <ref> [DLP + 86] </ref>. These algorithms tolerate process crashes, and they use quasi reliable send and receive, and/or reliable broadcast, as their sole communication primitives.
Reference: [FLP85] <author> Michael J. Fischer, Nancy A. Lynch, and Michael S. Paterson. </author> <title> Impossibility of distributed consensus with one faulty process. </title> <journal> Journal of the ACM, </journal> <volume> 32(2) </volume> <pages> 374-382, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: In [ACT97a], Aguilera et al. show that among all failure detectors that output lists of suspects, 3P is the weakest one that can be used to solve the above problem. 1 Unfortunately, 3P is not implementable in asynchronous systems with process crashes (this would violate a known impossibility result <ref> [FLP85, CT96] </ref>). Thus, at a first glance, it seems that achieving quiescent reliable communication requires a failure detector that cannot be implemented.
Reference: [FM90] <author> Paul Feldman and Silvio Micali. </author> <title> An optimal algorithm for synchronous Byzantine agreement. </title> <type> Technical Report MIT/LCS/TM-425, </type> <institution> Laboratory for Computer Science, Massachusetts Institute of Technology, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: We then explain how HB can be used to easily transform many existing algorithms that tolerate process crashes into quiescent algorithms that tolerate both process crashes and message losses (fair links). This transformation can be applied to the algorithms for consensus in <ref> [Ben83, Rab83, BT85, CMS89, FM90, AT96, CT96] </ref>, for atomic broadcast in [CT96], for k-set agreement in [Cha93], for atomic commitment in [Gue95], for approximate agreement in [DLP + 86], etc. Finally, we show that HB can be used to extend the work in [BCBT96] to obtain the following result. <p> For example, consider the randomized consensus algorithms of <ref> [Ben83, Rab83, CMS89, FM90] </ref>, the failure-detector based ones of [CT96, AT96], the probabilistic one of [BT85], and the algorithms for atomic broadcast in [CT96], k-set agreement in [Cha93], atomic commitment in [Gue95], and approximate agreement in [DLP + 86].
Reference: [GLS95] <author> Rachid Guerraoui, Michael Larrea, and Andr e Schiper. </author> <title> Non blocking atomic commitment with an unreliable failure detector. </title> <booktitle> In Proceedings of the 14th IEEE Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 13-15, </pages> <year> 1995. </year> <month> 25 </month>
Reference-contexts: It can also be used to extend the results of [BCBT96]. 4. HB is novel: it is implementable without timeouts, and it does not output lists of suspects as typical failure detectors do <ref> [BDM97, CT96, Gue95, GLS95, LH94, SM95] </ref>.
Reference: [Gop92] <author> Ajei Gopal. </author> <title> Fault-Tolerant Broadcasts and Multicasts: The Problem of Inconsistency and Contami--nation. </title> <type> PhD thesis, </type> <institution> Cornell University, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: To avoid this piggybacking, in this paper we adopted the model of fair links: message losses can now be overcome by separately sending each message repeatedly. 14 Intuitively, a problem P is correct-restricted if its specification does not refer to the behavior of faulty processes <ref> [Gop92, BN92] </ref>. 23 12 Generalization to Networks that Partition In this paper, we assumed that every pair of correct processes are reachable from each other through fair paths. In [ACT97b], we drop this assumption and consider the more general problem of quiescent reliable communication in networks that may partition.
Reference: [Gra78] <author> James N. Gray. </author> <title> Notes on database operating systems. </title> <editor> In R. Bayer, R. M. Graham, and G. Seegmuller, editors, </editor> <booktitle> Operating Systems: An Advanced Course, volume 66 of Lecture Notes on Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1978. </year> <note> Also appears as IBM Research Laboratory Technical report RJ2188. </note>
Reference-contexts: This requirement allows a faulty process (i.e., one that subsequently crashes) to deliver a message that is never delivered by the correct processes. This behavior is undesirable in some applications, such as atomic commitment in distributed databases <ref> [Gra78, Had86, BT93] </ref>. For such applications, a stronger version of reliable broadcast is more suitable, namely, uniform reliable broadcast which satisfies Uniform Integrity, Validity (Section 5.2) and: * Uniform Agreement [NT90]: If any process delivers a message m, then all correct processes eventually deliver m.
Reference: [Gue95] <author> Rachid Guerraoui. </author> <title> Revisiting the relationship between non-blocking atomic commitment and consensus. </title> <booktitle> In Proceedings of the 9th International Workshop on Distributed Algorithms, </booktitle> <pages> pages 87-100, </pages> <address> Le Mont-St-Michel, France, 1995. </address> <publisher> Springer Verlag, LNCS 972. </publisher>
Reference-contexts: Introduced in [CT96], the abstraction of unreliable failure detectors has been used to solve several important problems such as consensus, atomic broadcast, group membership, non-blocking atomic commitment, and leader election <ref> [BDM97, DFKM96, Gue95, LH94, SM95] </ref>. Our goal is to use unreliable failure detectors to achieve quiescence, but before we do so we must address the following important question. <p> This transformation can be applied to the algorithms for consensus in [Ben83, Rab83, BT85, CMS89, FM90, AT96, CT96], for atomic broadcast in [CT96], for k-set agreement in [Cha93], for atomic commitment in <ref> [Gue95] </ref>, for approximate agreement in [DLP + 86], etc. Finally, we show that HB can be used to extend the work in [BCBT96] to obtain the following result. Let P be a problem. <p> It can also be used to extend the results of [BCBT96]. 4. HB is novel: it is implementable without timeouts, and it does not output lists of suspects as typical failure detectors do <ref> [BDM97, CT96, Gue95, GLS95, LH94, SM95] </ref>. <p> For example, consider the randomized consensus algorithms of [Ben83, Rab83, CMS89, FM90], the failure-detector based ones of [CT96, AT96], the probabilistic one of [BT85], and the algorithms for atomic broadcast in [CT96], k-set agreement in [Cha93], atomic commitment in <ref> [Gue95] </ref>, and approximate agreement in [DLP + 86]. These algorithms tolerate process crashes, and they use quasi reliable send and receive, and/or reliable broadcast, as their sole communication primitives.
Reference: [Had86] <author> Vassos Hadzilacos. </author> <title> On the relationship between the atomic commitment and consensus problems. </title> <booktitle> In Proceedings of the Workshop on Fault-Tolerant Distributed Computing, volume 448 of Lecture Notes on Computer Science, </booktitle> <pages> pages 201-208. </pages> <publisher> Springer-Verlag, </publisher> <month> March </month> <year> 1986. </year>
Reference-contexts: This requirement allows a faulty process (i.e., one that subsequently crashes) to deliver a message that is never delivered by the correct processes. This behavior is undesirable in some applications, such as atomic commitment in distributed databases <ref> [Gra78, Had86, BT93] </ref>. For such applications, a stronger version of reliable broadcast is more suitable, namely, uniform reliable broadcast which satisfies Uniform Integrity, Validity (Section 5.2) and: * Uniform Agreement [NT90]: If any process delivers a message m, then all correct processes eventually deliver m.
Reference: [HT94] <author> Vassos Hadzilacos and Sam Toueg. </author> <title> A modular approach to fault-tolerant broadcasts and related problems. </title> <type> Technical Report 94-1425, </type> <institution> Department of Computer Science, Cornell University, </institution> <address> Ithaca, New York, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Roughly speaking, a pair of send/receive primitives is quasi reliable if it satisfies the following property: if processes s and r are correct (i.e., they do not crash), then r receives a message from s exactly as many times as s sent that message to r. Reliable broadcast <ref> [HT94] </ref> ensures that if a correct process broadcasts a message m then all correct processes deliver m; moreover, all correct processes deliver the same set of messages. <p> These fields make every message unique. We say that q delivers message m if q returns from the invocation of deliver (m). Primitives broadcast and deliver satisfy the following properties <ref> [HT94] </ref>: * Validity: If a correct process broadcasts a message m, then it eventually delivers m. * Agreement: If a correct process delivers a message m, then all correct processes eventually deliver m. * Uniform Integrity: For every message m, every process delivers m at most once, and only if m <p> If we have a quiescent implementation of quasi reliable primitives SEND p;q and RECEIVE q;p for all processes p and q 2 neighbor (p), then we can obtain a quiescent implementation of reliable broadcast. The implementation of reliable broadcast, a simple flooding algorithm taken from <ref> [HT94] </ref>, is given in Figure 2 (the code consisting of lines 9 and 10 is executed atomically 7 ). It is clear that this implementation is quiescent. Indeed, for every message m, an invocation of broadcast (m) can cause at most n 1 invocations of SEND per process. <p> if r is correct and s completes the sending of m to r exactly k times, then r receives m from s at least k times. 11 11 The No Loss and Quasi No Loss properties are very similar to the Strong Validity and Validity properties in Section 6 of <ref> [HT94] </ref>. 21 1 For every process p: 2 3 To execute uniform-broadcast (m): 4 broadcast (m) 5 return 6 7 upon deliver (m) do 8 for all q 2 P do SEND p;q (ACK; m) 9 wait until RECEIVEd (ACK; m) from t + 1 processes 10 uniform-deliver (m) Reliable send
Reference: [KT88] <author> Richard Koo and Sam Toueg. </author> <title> Effects of message loss on the termination of distributed protocols. </title> <journal> Information Processing Letters, </journal> <volume> 27(4) </volume> <pages> 181-188, </pages> <month> April </month> <year> 1988. </year>
Reference-contexts: Can we use HB to obtain reliable communication protocols that are terminating? The answer is no, even for systems with no process crashes. This follows from the result in <ref> [KT88] </ref> which shows that in a system with message losses (fair links) and no process crashes there is no terminating protocol that guarantees knowledge gain. Acknowledgments We are grateful to Anindya Basu and Vassos Hadzilacos for having provided extensive comments that improved the presentation of this paper.
Reference: [LH94] <author> Wai-Kau Lo and Vassos Hadzilacos. </author> <title> Using failure detectors to solve consensus in asynchronous shared-memory systems. </title> <booktitle> In Proceedings of the 8th International Workshop on Distributed Algorithms, </booktitle> <pages> pages 280-295, </pages> <address> Terschelling, The Netherlands, </address> <year> 1994. </year>
Reference-contexts: Introduced in [CT96], the abstraction of unreliable failure detectors has been used to solve several important problems such as consensus, atomic broadcast, group membership, non-blocking atomic commitment, and leader election <ref> [BDM97, DFKM96, Gue95, LH94, SM95] </ref>. Our goal is to use unreliable failure detectors to achieve quiescence, but before we do so we must address the following important question. <p> It can also be used to extend the results of [BCBT96]. 4. HB is novel: it is implementable without timeouts, and it does not output lists of suspects as typical failure detectors do <ref> [BDM97, CT96, Gue95, GLS95, LH94, SM95] </ref>.
Reference: [Lyn96] <author> Nancy A. Lynch. </author> <title> Distributed Algorithms. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1996. </year>
Reference-contexts: The results of this paper, combined with those in [ACT97a], show that lists of suspects is not always the best failure detector output. 5 Reliable communication is a fundamental problem that has been extensively studied, especially in the context of data link protocols (see Chapter 22 of <ref> [Lyn96] </ref> for a compendium). Our work differs from previous results by focusing on the use of unreliable failure detectors to achieve quiescent reliable communication in the presence of process crashes and link failures.
Reference: [NT90] <author> Gil Neiger and Sam Toueg. </author> <title> Automatically increasing the fault-tolerance of distributed algorithms. </title> <journal> Journal of Algorithms, </journal> <volume> 11(3) </volume> <pages> 374-419, </pages> <year> 1990. </year>
Reference-contexts: This behavior is undesirable in some applications, such as atomic commitment in distributed databases [Gra78, Had86, BT93]. For such applications, a stronger version of reliable broadcast is more suitable, namely, uniform reliable broadcast which satisfies Uniform Integrity, Validity (Section 5.2) and: * Uniform Agreement <ref> [NT90] </ref>: If any process delivers a message m, then all correct processes eventually deliver m. SEND/RECEIVE between every pair of processes.
Reference: [Rab83] <author> Michael Rabin. </author> <title> Randomized Byzantine generals. </title> <booktitle> In Proceedings of the 24th Symposium on Foundations of Computer Science, </booktitle> <pages> pages 403-409. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> November </month> <year> 1983. </year>
Reference-contexts: We then explain how HB can be used to easily transform many existing algorithms that tolerate process crashes into quiescent algorithms that tolerate both process crashes and message losses (fair links). This transformation can be applied to the algorithms for consensus in <ref> [Ben83, Rab83, BT85, CMS89, FM90, AT96, CT96] </ref>, for atomic broadcast in [CT96], for k-set agreement in [Cha93], for atomic commitment in [Gue95], for approximate agreement in [DLP + 86], etc. Finally, we show that HB can be used to extend the work in [BCBT96] to obtain the following result. <p> For example, consider the randomized consensus algorithms of <ref> [Ben83, Rab83, CMS89, FM90] </ref>, the failure-detector based ones of [CT96, AT96], the probabilistic one of [BT85], and the algorithms for atomic broadcast in [CT96], k-set agreement in [Cha93], atomic commitment in [Gue95], and approximate agreement in [DLP + 86].
Reference: [SM95] <author> Laura S. Sabel and Keith Marzullo. </author> <title> Election vs. consensus in asynchronous systems. </title> <type> Technical Report 95-1488, </type> <institution> Department of Computer Science, Cornell University, </institution> <address> Ithaca, New York, </address> <month> Febrary </month> <year> 1995. </year>
Reference-contexts: Introduced in [CT96], the abstraction of unreliable failure detectors has been used to solve several important problems such as consensus, atomic broadcast, group membership, non-blocking atomic commitment, and leader election <ref> [BDM97, DFKM96, Gue95, LH94, SM95] </ref>. Our goal is to use unreliable failure detectors to achieve quiescence, but before we do so we must address the following important question. <p> It can also be used to extend the results of [BCBT96]. 4. HB is novel: it is implementable without timeouts, and it does not output lists of suspects as typical failure detectors do <ref> [BDM97, CT96, Gue95, GLS95, LH94, SM95] </ref>.
Reference: [vR97] <author> Robbert van Renesse, </author> <month> April </month> <year> 1997. </year> <title> Private Communication. </title> <type> 26 </type>
Reference-contexts: Thus, HB should not be confused with existing implementations of failure detectors (some of which, such as those in Ensemble and Phoenix, have modules that are also called heartbeat <ref> [vR97, Cha97] </ref>). Even though existing failure detectors are also based on the repeated sending of a heartbeat, they use timeouts on heartbeats in order to derive lists of processes considered to be up or down; applications can only see these lists.
References-found: 31

