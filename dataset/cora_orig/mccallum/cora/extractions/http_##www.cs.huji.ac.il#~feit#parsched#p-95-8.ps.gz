URL: http://www.cs.huji.ac.il/~feit/parsched/p-95-8.ps.gz
Refering-URL: http://www.cs.huji.ac.il/~feit/parsched/parsched95.html
Root-URL: http://www.cs.huji.ac.il
Title: The Interaction between Memory Allocation and Adaptive Partitioning in Message-Passing Multicomputers  
Author: Sanjeev K. Setia 
Address: Fairfax, VA 22030  
Affiliation: Department of Computer Science George Mason University  
Abstract: Most studies on adaptive partitioning policies for scheduling parallel jobs on distributed memory parallel computers ignore the constraints imposed by the memory requirements of the jobs. In this paper, we first show that these constraints can have a negative impact on the performance of adaptive partitioning policies. We then evaluate the performance of adaptive partitioning in a system where these minimum processor constraints are eased due to the provision of support for virtual memory. Our primary conclusion is that any performance benefits resulting from the easing of minimum processor constraints imposed by the memory requirements of jobs will be negated by the overhead due to paging.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> D. Burger, R. Hyder, B. Miller, and D. Wood. </author> <title> Paging tradeoffs in distributed shared-memory multiprocessors. </title> <booktitle> In Proceedings of Supercomputing '94. IEEE, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: Our work differs in that we consider memory-constrained adaptive partitioning policies, whereas they assume a dynamic scheduling discipline. Secondly, we also consider the feasibility of relaxing memory constraints. Finally, some recent studies <ref> [1, 21] </ref> have examined the working set characteristics and paging behavior of scientific programs on distributed memory parallel computers. 3 Scheduling Policies The policies considered in this paper have elements in common with both adaptive space-sharing policies that have been proposed in [18, 14, 17], and gang-scheduling polices [7, 8] in
Reference: 2. <author> Rohit Chandra, Scott Devine, Ben Verghese, Mendel Rosenblum, and Anoop Gupta. </author> <title> Scheduling and page migration for multiprocessor compute servers. </title> <booktitle> In Proceedings of ASPLOS-VI, </booktitle> <pages> pages 12-24. </pages> <publisher> ACM, </publisher> <month> October </month> <year> 1994. </year>
Reference-contexts: A key characteristic of these policies is that they reduce the number of processors allocated to individual jobs as the load on the system increases. The motivation behind this policy is to take advantage of the "operating point" effect <ref> [2] </ref>. Parallel applications typically experience a diminishing return in speedup as the number of processors allocated to them is increased. In a multiprogrammed environment, reducing the number of processors allocated to a job results in increased efficiency for that application and also frees up processors for use by other jobs.
Reference: 3. <author> Su-Hui Chiang, Rajesh K. Mansharamani, and Mary K. Vernon. </author> <title> Use of application characteristics and limited preemption in run-to-completion parallel processor scheduling policies. </title> <booktitle> In Proceedings of 1994 ACM Sigmetrics Conference, </booktitle> <pages> pages 33-44, </pages> <address> Nashville, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: 1 Introduction In recent years, several adaptive partitioning strategies <ref> [6, 19, 5, 18, 17, 3, 14] </ref> have been proposed for scheduling parallel jobs on message-passing multicom-puters. A key characteristic of these policies is that they reduce the number of processors allocated to individual jobs as the load on the system increases. <p> In Section 4, we compare the performance of the APMC and APVM policies. Finally, Section 5 summarizes our conclusions. 2 Related Work Job scheduling strategies for parallel computers have been studied actively during the last few years <ref> [6, 19, 20, 22, 11, 18, 17, 3, 14, 12] </ref>. A recent paper by Feitelson [8] surveys research in this area. <p> A recent paper by Feitelson [8] surveys research in this area. Numerous studies have examined adap-tive partitioning policies among these, Parsons and Sevcik [15] and Chiang et al <ref> [3] </ref> consider preemptive versions of adaptive partitioning similar to the policy considered in this paper. Only a few papers have examined the interaction between memory management and scheduling. Peris et al [16] developed analytical models for studying processor allocation tradeoffs while taking into account the impact of memory requirements. <p> It has been shown that for adaptive partitioning policies to perform well for workloads with high variability in job demand, either the policies have to be preemptive in nature <ref> [3] </ref> or they have to utilize user-supplied information about job demand [14]. In this paper, we assume that no information (about job demand) is supplied by the user and consider policies that use preemption. <p> The speedup function used in our simulations is given by S (p) = (1+fi)p=(fi+ p). This speedup function has been used by several studies <ref> [13, 3, 5] </ref> and is shown in Figure 1. For a given number of processors (p) and given job demand (on one processor), the speedup function is used to compute the processing requirement of the job on p processors. <p> For a given number of processors (p) and given job demand (on one processor), the speedup function is used to compute the processing requirement of the job on p processors. In our simulations, we assume that fi is uniformly distributed between 30 and 300, the range considered in <ref> [13, 3] </ref>. For the minimum memory requirements, M , of a job we assumed three distributions. Under the first distribution, we assumed that M is uniformly distributed in the range (1,128). <p> First, the plots show that a time-sharing version of adaptive partitioning can be designed which performs reasonably well for a workload with a high coefficient of variation, and avoids the problems associated with a "pure" space-sharing version of the policy <ref> [14, 3] </ref>. Second, the plots in Figure 2 show that at moderate loads, the performance of the AP policy is worse than that of the best GS policy for a given load.
Reference: 4. <author> H. M. Deitel. </author> <title> An Introduction to Operating Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1984. </year>
Reference-contexts: The order in which jobs get dispatched in the system is based on a negative-feedback priority scheme similar to that commonly used in uniprocessors <ref> [4] </ref>. Each job has a priority associated with it which is inversely proportional to the processing time accumulated so far by the job.
Reference: 5. <author> L. Dowdy. </author> <title> On the partitioning of multiprocessor systems. </title> <type> Technical report, </type> <institution> Van-derbilt Univ., Nashville,TN, </institution> <month> July </month> <year> 1988. </year>
Reference-contexts: 1 Introduction In recent years, several adaptive partitioning strategies <ref> [6, 19, 5, 18, 17, 3, 14] </ref> have been proposed for scheduling parallel jobs on message-passing multicom-puters. A key characteristic of these policies is that they reduce the number of processors allocated to individual jobs as the load on the system increases. <p> The speedup function used in our simulations is given by S (p) = (1+fi)p=(fi+ p). This speedup function has been used by several studies <ref> [13, 3, 5] </ref> and is shown in Figure 1. For a given number of processors (p) and given job demand (on one processor), the speedup function is used to compute the processing requirement of the job on p processors.
Reference: 6. <author> D. L. Eager, J. Zahorjan, and E. D. Lazowska. </author> <title> Speedup versus efficiency in parallel systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38:408 - 423, </volume> <month> March </month> <year> 1989. </year>
Reference-contexts: 1 Introduction In recent years, several adaptive partitioning strategies <ref> [6, 19, 5, 18, 17, 3, 14] </ref> have been proposed for scheduling parallel jobs on message-passing multicom-puters. A key characteristic of these policies is that they reduce the number of processors allocated to individual jobs as the load on the system increases. <p> In Section 4, we compare the performance of the APMC and APVM policies. Finally, Section 5 summarizes our conclusions. 2 Related Work Job scheduling strategies for parallel computers have been studied actively during the last few years <ref> [6, 19, 20, 22, 11, 18, 17, 3, 14, 12] </ref>. A recent paper by Feitelson [8] surveys research in this area.
Reference: 7. <author> D. Feitelson and L. Rudolph. </author> <title> Gang scheduling Performance Benefits for Fine-Grain Synchronization. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 16 </volume> <pages> 306-318, </pages> <year> 1992. </year>
Reference-contexts: recent studies [1, 21] have examined the working set characteristics and paging behavior of scientific programs on distributed memory parallel computers. 3 Scheduling Policies The policies considered in this paper have elements in common with both adaptive space-sharing policies that have been proposed in [18, 14, 17], and gang-scheduling polices <ref> [7, 8] </ref> in use on systems such as the Intel Paragon. They resemble gang-scheduling in that they are quantum-based policies in which all the processors in the system always context-switch synchronously at the end of a quantum.
Reference: 8. <author> Dror Feitelson. </author> <title> A survey of scheduling in multiprogrammed parallel systems. </title> <type> Technical Report RC 19790, </type> <institution> IBM Research Division, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: Finally, Section 5 summarizes our conclusions. 2 Related Work Job scheduling strategies for parallel computers have been studied actively during the last few years [6, 19, 20, 22, 11, 18, 17, 3, 14, 12]. A recent paper by Feitelson <ref> [8] </ref> surveys research in this area. Numerous studies have examined adap-tive partitioning policies among these, Parsons and Sevcik [15] and Chiang et al [3] consider preemptive versions of adaptive partitioning similar to the policy considered in this paper. <p> recent studies [1, 21] have examined the working set characteristics and paging behavior of scientific programs on distributed memory parallel computers. 3 Scheduling Policies The policies considered in this paper have elements in common with both adaptive space-sharing policies that have been proposed in [18, 14, 17], and gang-scheduling polices <ref> [7, 8] </ref> in use on systems such as the Intel Paragon. They resemble gang-scheduling in that they are quantum-based policies in which all the processors in the system always context-switch synchronously at the end of a quantum.
Reference: 9. <author> Dror Feitelson and B. Nitzberg. </author> <title> Job Characteristics of a Production Parallel Scientific Workload on the NASA Ames iPSC/860. </title> <booktitle> In Proceedings of the IPPS 95 Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <pages> pages 215-227, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: In our simulations, we assume that N = P , i.e., each job can execute on 128 processors. The total processing requirement D is chosen from a hyper-exponential distribution to model the high variability that is expected in parallel supercomputing environments <ref> [9] </ref>. We assume that jobs can be considered to belong to two classes small and large. Small jobs have a mean processing requirement of 300 seconds while large jobs have mean processing requirement of 3600 seconds.
Reference: 10. <author> Liviu Iftode, Kai Li, and Karin Peterson. </author> <title> Memory servers for multicomputers. </title> <booktitle> In Proceedings of the 1993 Spring CompCon, </booktitle> <pages> pages 538-547, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: In this paper, we make the optimistic assumption that the average page fault service time is 1 ms. We note that researchers have proposed the use of dedicated "memory server" nodes <ref> [10] </ref> for implementing fast paging stores. In the case of sequential applications, a page fault service time of 1 ms, and maximum overhead threshold of 25% would imply that the maximum page fault rate that is permissible (on average) is 250 page faults/second.
Reference: 11. <author> S. Leutenegger and M. Vernon. </author> <title> The Performance of Multiprogrammed Multiprocessor Scheduling Policies. </title> <booktitle> In Proc. of Sigmetrics '90, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: In Section 4, we compare the performance of the APMC and APVM policies. Finally, Section 5 summarizes our conclusions. 2 Related Work Job scheduling strategies for parallel computers have been studied actively during the last few years <ref> [6, 19, 20, 22, 11, 18, 17, 3, 14, 12] </ref>. A recent paper by Feitelson [8] surveys research in this area.
Reference: 12. <author> Cathy McCann and John Zahorjan. </author> <title> Processor allocation policies for message--passing parallel computers. </title> <booktitle> In Proceedings of 1994 ACM Sigmetrics Conference, </booktitle> <pages> pages 19-32, </pages> <address> Nashville, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: In Section 4, we compare the performance of the APMC and APVM policies. Finally, Section 5 summarizes our conclusions. 2 Related Work Job scheduling strategies for parallel computers have been studied actively during the last few years <ref> [6, 19, 20, 22, 11, 18, 17, 3, 14, 12] </ref>. A recent paper by Feitelson [8] surveys research in this area.
Reference: 13. <author> Cathy McCann and John Zahorjan. </author> <title> Scheduling memory constrained jobs on distributed memory parallel computers. </title> <type> Technical Report UW-CSE-94-10-05, </type> <institution> University of Washington, Department of Computer Science, </institution> <year> 1994. </year>
Reference-contexts: Secondly, our study also differs in that we take into account the impact of synchronization between threads on the overall paging overhead incurred by a parallel application. McCann and Zahorjan <ref> [13] </ref> propose and evaluate several scheduling policies that take into account the constraints imposed by the memory requirements of parallel applications. Our work differs in that we consider memory-constrained adaptive partitioning policies, whereas they assume a dynamic scheduling discipline. Secondly, we also consider the feasibility of relaxing memory constraints. <p> The speedup function used in our simulations is given by S (p) = (1+fi)p=(fi+ p). This speedup function has been used by several studies <ref> [13, 3, 5] </ref> and is shown in Figure 1. For a given number of processors (p) and given job demand (on one processor), the speedup function is used to compute the processing requirement of the job on p processors. <p> For a given number of processors (p) and given job demand (on one processor), the speedup function is used to compute the processing requirement of the job on p processors. In our simulations, we assume that fi is uniformly distributed between 30 and 300, the range considered in <ref> [13, 3] </ref>. For the minimum memory requirements, M , of a job we assumed three distributions. Under the first distribution, we assumed that M is uniformly distributed in the range (1,128). <p> This fragmentation effect is mainly due to our assumption that once a job has been configured for a certain number of processors it needs exactly that number to execute. If we assume a more dynamic environment (such as that considered in <ref> [13] </ref>), in which the job can adapt to the number of available processors, the performance of the AP policy should improve. Next, we consider the impact of the memory requirements of arriving jobs on the performance of the APMC policy. <p> Such dynamic run-time environments would allow the scheduler to use algorithms that avoid fragmentation, such as those 4 because we do not take memory constraints into consideration Fig. 3. Comparison of Adaptive Partitioning policies for different memory requirement distributions described in <ref> [13] </ref>.
Reference: 14. <author> V. K. Naik, S. K. Setia, and M. S. Squillante. </author> <title> Performance Analysis of Job Scheduling Policies in Parallel Supercomputing Environments. </title> <booktitle> In SuperComputing '93, </booktitle> <month> November </month> <year> 1993. </year>
Reference-contexts: 1 Introduction In recent years, several adaptive partitioning strategies <ref> [6, 19, 5, 18, 17, 3, 14] </ref> have been proposed for scheduling parallel jobs on message-passing multicom-puters. A key characteristic of these policies is that they reduce the number of processors allocated to individual jobs as the load on the system increases. <p> In Section 4, we compare the performance of the APMC and APVM policies. Finally, Section 5 summarizes our conclusions. 2 Related Work Job scheduling strategies for parallel computers have been studied actively during the last few years <ref> [6, 19, 20, 22, 11, 18, 17, 3, 14, 12] </ref>. A recent paper by Feitelson [8] surveys research in this area. <p> Finally, some recent studies [1, 21] have examined the working set characteristics and paging behavior of scientific programs on distributed memory parallel computers. 3 Scheduling Policies The policies considered in this paper have elements in common with both adaptive space-sharing policies that have been proposed in <ref> [18, 14, 17] </ref>, and gang-scheduling polices [7, 8] in use on systems such as the Intel Paragon. They resemble gang-scheduling in that they are quantum-based policies in which all the processors in the system always context-switch synchronously at the end of a quantum. <p> It has been shown that for adaptive partitioning policies to perform well for workloads with high variability in job demand, either the policies have to be preemptive in nature [3] or they have to utilize user-supplied information about job demand <ref> [14] </ref>. In this paper, we assume that no information (about job demand) is supplied by the user and consider policies that use preemption. Thus, the policies proposed in this paper are time-sharing versions of the adaptive partitioning policies that have been proposed and analyzed in [18, 14, 17]. <p> In this paper, we assume that no information (about job demand) is supplied by the user and consider policies that use preemption. Thus, the policies proposed in this paper are time-sharing versions of the adaptive partitioning policies that have been proposed and analyzed in <ref> [18, 14, 17] </ref>. The system scheduler maintains a job queue consisting of jobs submitted to the system. <p> First, the plots show that a time-sharing version of adaptive partitioning can be designed which performs reasonably well for a workload with a high coefficient of variation, and avoids the problems associated with a "pure" space-sharing version of the policy <ref> [14, 3] </ref>. Second, the plots in Figure 2 show that at moderate loads, the performance of the AP policy is worse than that of the best GS policy for a given load.
Reference: 15. <author> Eric W. Parsons and Kenneth C. Sevcik. </author> <title> Multiprocessor Scheduling for High-Variability Service Time Distributions. </title> <booktitle> In Proceedings of the IPPS 95 Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <pages> pages 76-88, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: A recent paper by Feitelson [8] surveys research in this area. Numerous studies have examined adap-tive partitioning policies among these, Parsons and Sevcik <ref> [15] </ref> and Chiang et al [3] consider preemptive versions of adaptive partitioning similar to the policy considered in this paper. Only a few papers have examined the interaction between memory management and scheduling.
Reference: 16. <author> Vinod G. J. Peris, Mark S. Squillante, and Vijay K. Naik. </author> <title> Analysis of the impact of memory in distributed parallel processing systems. </title> <booktitle> In Proceedings of 1994 ACM Sigmetrics Conference, </booktitle> <pages> pages 5-18, </pages> <address> Nashville, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Numerous studies have examined adap-tive partitioning policies among these, Parsons and Sevcik [15] and Chiang et al [3] consider preemptive versions of adaptive partitioning similar to the policy considered in this paper. Only a few papers have examined the interaction between memory management and scheduling. Peris et al <ref> [16] </ref> developed analytical models for studying processor allocation tradeoffs while taking into account the impact of memory requirements. Our work differs from this study in that we examine the same tradeoff for a specific adaptive partitioning policy, taking into account factors such as fragmentation overhead.
Reference: 17. <author> E. Rosti, E. Smirni, G. Serazzi, L. Dowdy, and B. Carlson. </author> <title> Robust Partitioning Policies of Multiprocessor Systems. Performance Evaluation, </title> <type> 9(2-3), </type> <year> 1994. </year>
Reference-contexts: 1 Introduction In recent years, several adaptive partitioning strategies <ref> [6, 19, 5, 18, 17, 3, 14] </ref> have been proposed for scheduling parallel jobs on message-passing multicom-puters. A key characteristic of these policies is that they reduce the number of processors allocated to individual jobs as the load on the system increases. <p> In Section 4, we compare the performance of the APMC and APVM policies. Finally, Section 5 summarizes our conclusions. 2 Related Work Job scheduling strategies for parallel computers have been studied actively during the last few years <ref> [6, 19, 20, 22, 11, 18, 17, 3, 14, 12] </ref>. A recent paper by Feitelson [8] surveys research in this area. <p> Finally, some recent studies [1, 21] have examined the working set characteristics and paging behavior of scientific programs on distributed memory parallel computers. 3 Scheduling Policies The policies considered in this paper have elements in common with both adaptive space-sharing policies that have been proposed in <ref> [18, 14, 17] </ref>, and gang-scheduling polices [7, 8] in use on systems such as the Intel Paragon. They resemble gang-scheduling in that they are quantum-based policies in which all the processors in the system always context-switch synchronously at the end of a quantum. <p> In this paper, we assume that no information (about job demand) is supplied by the user and consider policies that use preemption. Thus, the policies proposed in this paper are time-sharing versions of the adaptive partitioning policies that have been proposed and analyzed in <ref> [18, 14, 17] </ref>. The system scheduler maintains a job queue consisting of jobs submitted to the system.
Reference: 18. <author> S. K. Setia and S. K. Tripathi. </author> <title> A Comparative Analysis of Static Processor Partitioning Policies for Parallel Computers. </title> <booktitle> In Proc. of MASCOTS '93, </booktitle> <month> January </month> <year> 1993. </year>
Reference-contexts: 1 Introduction In recent years, several adaptive partitioning strategies <ref> [6, 19, 5, 18, 17, 3, 14] </ref> have been proposed for scheduling parallel jobs on message-passing multicom-puters. A key characteristic of these policies is that they reduce the number of processors allocated to individual jobs as the load on the system increases. <p> In Section 4, we compare the performance of the APMC and APVM policies. Finally, Section 5 summarizes our conclusions. 2 Related Work Job scheduling strategies for parallel computers have been studied actively during the last few years <ref> [6, 19, 20, 22, 11, 18, 17, 3, 14, 12] </ref>. A recent paper by Feitelson [8] surveys research in this area. <p> Finally, some recent studies [1, 21] have examined the working set characteristics and paging behavior of scientific programs on distributed memory parallel computers. 3 Scheduling Policies The policies considered in this paper have elements in common with both adaptive space-sharing policies that have been proposed in <ref> [18, 14, 17] </ref>, and gang-scheduling polices [7, 8] in use on systems such as the Intel Paragon. They resemble gang-scheduling in that they are quantum-based policies in which all the processors in the system always context-switch synchronously at the end of a quantum. <p> In this paper, we assume that no information (about job demand) is supplied by the user and consider policies that use preemption. Thus, the policies proposed in this paper are time-sharing versions of the adaptive partitioning policies that have been proposed and analyzed in <ref> [18, 14, 17] </ref>. The system scheduler maintains a job queue consisting of jobs submitted to the system.
Reference: 19. <author> K. C. Sevcik. </author> <title> Characterizations of parallelism in applications and their use in scheduling. </title> <booktitle> In Proc. of the ACM SIGMETRICS Conf., </booktitle> <month> May </month> <year> 1989. </year>
Reference-contexts: 1 Introduction In recent years, several adaptive partitioning strategies <ref> [6, 19, 5, 18, 17, 3, 14] </ref> have been proposed for scheduling parallel jobs on message-passing multicom-puters. A key characteristic of these policies is that they reduce the number of processors allocated to individual jobs as the load on the system increases. <p> In Section 4, we compare the performance of the APMC and APVM policies. Finally, Section 5 summarizes our conclusions. 2 Related Work Job scheduling strategies for parallel computers have been studied actively during the last few years <ref> [6, 19, 20, 22, 11, 18, 17, 3, 14, 12] </ref>. A recent paper by Feitelson [8] surveys research in this area.
Reference: 20. <author> A. Tucker and A. Gupta. </author> <title> Process control and scheduling issues for multipro-grammed shared-memory multiprocessors. </title> <booktitle> In Proc. of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1989. </year>
Reference-contexts: In Section 4, we compare the performance of the APMC and APVM policies. Finally, Section 5 summarizes our conclusions. 2 Related Work Job scheduling strategies for parallel computers have been studied actively during the last few years <ref> [6, 19, 20, 22, 11, 18, 17, 3, 14, 12] </ref>. A recent paper by Feitelson [8] surveys research in this area.
Reference: 21. <author> K. Y. Wang and Dan C. Marinescu. </author> <title> An analysis of the paging activity of parallel programs. </title> <type> Technical Report CSD-TR-94-042, </type> <institution> Purdue University, Computer Sciences Department, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: Our work differs in that we consider memory-constrained adaptive partitioning policies, whereas they assume a dynamic scheduling discipline. Secondly, we also consider the feasibility of relaxing memory constraints. Finally, some recent studies <ref> [1, 21] </ref> have examined the working set characteristics and paging behavior of scientific programs on distributed memory parallel computers. 3 Scheduling Policies The policies considered in this paper have elements in common with both adaptive space-sharing policies that have been proposed in [18, 14, 17], and gang-scheduling polices [7, 8] in <p> The correlation factor models the similarity in the pag ing behavior of different threads. (In case of SPMD programs it is reasonable to assume that there is some similarity in the memory reference patterns of the threads of the application <ref> [21] </ref>.) Our assumption that the page fault rate of each thread is identical implies that each thread incurs the same number of page faults during the simulation.
Reference: 22. <author> J. Zahorjan and C. McCann. </author> <title> Processor scheduling in shared memory multiprocessors. </title> <booktitle> In Proc. of ACM SIGMETRICS Conf., </booktitle> <year> 1990. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: In Section 4, we compare the performance of the APMC and APVM policies. Finally, Section 5 summarizes our conclusions. 2 Related Work Job scheduling strategies for parallel computers have been studied actively during the last few years <ref> [6, 19, 20, 22, 11, 18, 17, 3, 14, 12] </ref>. A recent paper by Feitelson [8] surveys research in this area.
References-found: 22

