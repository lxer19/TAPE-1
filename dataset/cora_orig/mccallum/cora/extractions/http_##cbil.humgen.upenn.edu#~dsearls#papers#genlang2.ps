URL: http://cbil.humgen.upenn.edu/~dsearls/papers/genlang2.ps
Refering-URL: http://cbil.humgen.upenn.edu/~sdong/genlang_home.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Gene Structure Prediction by Linguistic Methods  
Author: Shan Dong and David B. Searls 
Note: To appear in Genomics  
Address: Philadelphia, PA 19104-6145 USA  
Affiliation: Department of Genetics University of Pennsylvania School of Medicine 422 Curie Boulevard  
Abstract: The higher-order structure of genes and other features of biological sequences can be described by means of formal grammars. These grammars can then be used by general-purpose parsers to detect and assemble such structures by means of syntactic pattern recognition. We describe a grammar and parser for eukaryotic protein-encoding genes, which by some measures is as effective as current connectionist and combinatorial algorithms in predicting gene structures for sequence database entries. Parameters on the grammar rules are optimized for several different species, and mixing experiments performed to determine the degree of species specificity and the relative importance of compositional, signal-based, and syntactic components in gene prediction.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Brunak, J. Engelbrecht, and S. Knudsen. </author> <title> Prediction of human mRNA donor and acceptor sites from the DNA sequence. </title> <journal> J. Mol. Biol., </journal> <volume> 220 </volume> <pages> 49-65, </pages> <year> 1991. </year>
Reference-contexts: We note that the sensors used thus far are not among the most sophisticated currently under study, which include compositional measures drawn from signal processing and information theory (reviewed in [4]) and signal measures based on connectionist and classification techniques from machine learning (e.g. <ref> [1, 11] </ref>). The ability to apply such advanced sensors in a "plug and test" mode in a variety of grammar architectures and evidence combination schemes should allow them to be used to the best effect.
Reference: [2] <author> J.-M. Claverie, I. Sauvaget, and L. Bougueleret. </author> <title> k-Tuple frequency analysis: From intron/exon discrimination to T-cell epitope mapping. </title> <booktitle> Methods in Enzymology, </booktitle> <volume> 183 </volume> <pages> 237-252, </pages> <year> 1990. </year>
Reference-contexts: measures are Fickett's testcode algorithm [3], which measures positional 1 asymmetry or the tendency for base compositions to vary systematically with position within the codon, and hextuple frequencies or the relative frequencies of occurrence of each 6-mer of bases in coding (either in-frame or independent of frame) versus non-coding sequences <ref> [2] </ref>. All such methods have the disadvantage that their accuracy invariably declines with smaller window sizes, and for most metrics the optimum window size is greater than the mean exon size in typical vertebrate gene sets. <p> Compositional and Signal Measures As noted above, a number of compositional measures of exonic tendency have been proposed, most of which are interrelated to a greater or lesser degree [4]. We have chosen two of the best-known: in-frame hextuple frequency <ref> [2] </ref> and position asymmetry as measured by Fickett's testcode algorithm [3]. Their use is described further below, and in the Discussion. Local signals were largely detected using weight matrices, implemented in GenLang as follows.
Reference: [3] <author> J. W. Fickett. </author> <title> Recognition of protein coding regions in DNA sequences. </title> <journal> Nucleic Acids Res., </journal> <volume> 10 </volume> <pages> 5303-5318, </pages> <year> 1982. </year>
Reference-contexts: These compositional methods, used in what Staden termed "gene search by content" [22], typically produce for any sample window of sequence a measure of similarity, by some criterion, to "typical" exonic sequence data. Among the more commonly-used compositional measures are Fickett's testcode algorithm <ref> [3] </ref>, which measures positional 1 asymmetry or the tendency for base compositions to vary systematically with position within the codon, and hextuple frequencies or the relative frequencies of occurrence of each 6-mer of bases in coding (either in-frame or independent of frame) versus non-coding sequences [2]. <p> We have chosen two of the best-known: in-frame hextuple frequency [2] and position asymmetry as measured by Fickett's testcode algorithm <ref> [3] </ref>. Their use is described further below, and in the Discussion. Local signals were largely detected using weight matrices, implemented in GenLang as follows. <p> This score is calculated as the sum of the logarithms of the ratios of each hextuple's frequency of occurrence in coding versus non-coding regions, plus an offset to insure a positive result. 6. Position Asymmetry. For a putative coding region, a cost derived from Fickett's test-code algorithm <ref> [3] </ref>, but using tables of probabilities and weights calculated individually for the sets described below. 7. Donor Consensus. A weight matrix cost for the region extending from 3 to +6 from a putative splice donor, with an obligatory GT.
Reference: [4] <author> J. W. Fickett and C.-S. Tung. </author> <title> Assessment of protein coding measures. </title> <journal> Nucleic Acids Res., </journal> 20(24) 6441-6450, 1992. 
Reference-contexts: A formidable pattern recognition problem in biology is the recognition of protein-encoding genes in otherwise uncharacterized primary sequence data. Traditionally this has devolved to the problem of recognizing coding sequence using a variety of statistical metrics, recently reviewed in <ref> [4] </ref>. These compositional methods, used in what Staden termed "gene search by content" [22], typically produce for any sample window of sequence a measure of similarity, by some criterion, to "typical" exonic sequence data. <p> Compositional and Signal Measures As noted above, a number of compositional measures of exonic tendency have been proposed, most of which are interrelated to a greater or lesser degree <ref> [4] </ref>. We have chosen two of the best-known: in-frame hextuple frequency [2] and position asymmetry as measured by Fickett's testcode algorithm [3]. Their use is described further below, and in the Discussion. Local signals were largely detected using weight matrices, implemented in GenLang as follows. <p> We note that the sensors used thus far are not among the most sophisticated currently under study, which include compositional measures drawn from signal processing and information theory (reviewed in <ref> [4] </ref>) and signal measures based on connectionist and classification techniques from machine learning (e.g. [1, 11]). The ability to apply such advanced sensors in a "plug and test" mode in a variety of grammar architectures and evidence combination schemes should allow them to be used to the best effect.
Reference: [5] <author> C. A. Fields and C. A. Soderlund. gm: </author> <title> a practical tool for automating DNA sequence analysis. </title> <journal> CABIOS, </journal> <volume> 6(3) </volume> <pages> 263-270, </pages> <year> 1990. </year>
Reference-contexts: Not only do such gene assembly programs provide more information than strictly compositional exon finders, but by imposing additional constraints they can improve the latter's performance. Several such systems have been built on rule-based architectures <ref> [5, 7] </ref>. These advances have brought into focus the combinatorial problem of assembling and testing large sets of candidate exons; this has been addressed in the GeneID system [9] by clustering exons into equivalence classes, and in the GeneParser system [21] by a novel dynamic programming approach (see also [8]).
Reference: [6] <author> K. S. Fu. </author> <title> Syntactic Pattern Recognition and Applications. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Engle-wood Cliffs, NJ, </address> <year> 1982. </year>
Reference-contexts: Parser technology is also extensively developed, and has been applied as well to the problem of searching for complex patterns specified by grammars in large amounts of data, in a technique known as syntactic pattern recognition <ref> [6] </ref>. A formidable pattern recognition problem in biology is the recognition of protein-encoding genes in otherwise uncharacterized primary sequence data. Traditionally this has devolved to the problem of recognizing coding sequence using a variety of statistical metrics, recently reviewed in [4].
Reference: [7] <author> M. S. Gelfand. </author> <title> Computer prediction of the exon-intron structure of mammalian pre-mRNAs. </title> <journal> Nucleic Acids Res., </journal> <volume> 18 </volume> <pages> 5865-5869, </pages> <year> 1990. </year>
Reference-contexts: Not only do such gene assembly programs provide more information than strictly compositional exon finders, but by imposing additional constraints they can improve the latter's performance. Several such systems have been built on rule-based architectures <ref> [5, 7] </ref>. These advances have brought into focus the combinatorial problem of assembling and testing large sets of candidate exons; this has been addressed in the GeneID system [9] by clustering exons into equivalence classes, and in the GeneParser system [21] by a novel dynamic programming approach (see also [8]).
Reference: [8] <author> M. S. Gelfand and M. A. Roytberg. </author> <title> A dynamic programming approach for predicting the exon-intron structure. </title> <journal> BioSystems., </journal> <volume> 30 </volume> <pages> 173-182, </pages> <year> 1993. </year>
Reference-contexts: These advances have brought into focus the combinatorial problem of assembling and testing large sets of candidate exons; this has been addressed in the GeneID system [9] by clustering exons into equivalence classes, and in the GeneParser system [21] by a novel dynamic programming approach (see also <ref> [8] </ref>). These systems achieve similar levels of performance [21].
Reference: [9] <author> R. Guigo, S. Knudsen, N. Drake, and T. Smith. </author> <title> Prediction of gene structure. </title> <journal> J. Mol. Biol., </journal> <volume> 226 </volume> <pages> 141-157, </pages> <year> 1992. </year>
Reference-contexts: Several such systems have been built on rule-based architectures [5, 7]. These advances have brought into focus the combinatorial problem of assembling and testing large sets of candidate exons; this has been addressed in the GeneID system <ref> [9] </ref> by clustering exons into equivalence classes, and in the GeneParser system [21] by a novel dynamic programming approach (see also [8]). These systems achieve similar levels of performance [21]. <p> Particularly for more complex genes, it may be important to allow for such global as well as local assessments of exon quality. This departure from formal grammars, and the incorporation of features such as costs, give the resulting system the flavor of a hierarchical rule-based system such as GeneID <ref> [9] </ref>. Even traditional linguistic techniques such as chart parsing have their analogues in other technical domains. However, the lower levels of the gene grammar and indeed the recognition engine itself are still general purpose tools, which have been used to find a variety of other types of features [19]. <p> This coarse-grained branch-and-bound technique, as well as the chart parsing described above, was necessary to produce large numbers of alternative structures under the inherently costly parsing methodology, though the number examined are still small compared to other combinatorial algorithms which perform exhaustive searches <ref> [9, 21] </ref>. <p> For example, so as not to give undue weight to the large number of globin gene entries in sequence databases, it is desirable to cluster these into a single representative class, as in <ref> [9] </ref>. This was done by the simple expedient of counting the number of blast scores greater than 1200 for each entry compared against each of the other entries in the set, and assigning a weight to that entry equal to the inverse of the number of `hits'. <p> In particular, our formula for specificity is that used by [21]; it is called `Sen2' by <ref> [9] </ref>, and appears elsewhere in the literature as positive predictive value [12]. (A different formula is often used for specificity, which counts true negatives, but these numbers are generally too large in this application to be informative; in nearly every case this formula produced values that varied only between 0.95 and <p> Table II shows the results of such a comparison with a recent version of GRAIL (XGRAIL, October 1993, obtained by anonymous FTP from arthur.epm.ornl.gov). Statistics from individual entries are averaged in two ways: by gene, as in <ref> [9] </ref>, and by base (i.e. by summing results on a nucleotide by nucleotide basis), as in [21]. <p> We also analyzed the performance of GenLang relative to two other special-purpose gene prediction programs, GeneID <ref> [9] </ref> and GeneParser [21], based on data from these original papers using the GeneID test set. <p> Based on the training results above, only a single training epoch was used, and it was again confirmed that this was sufficient to achieve peak performance. Table III compares these results with original data (recalculated as required for direct comparison) from <ref> [9] </ref> and [21]. 17 test sets. Each circle represents a single entry, with correlation scores from the two programs indicated by positions on the respective axes. Thus, points above and to the left of the dashed line represent entries for which GenLang's correlation score exceeded that of GRAIL. <p> .17 .46 .66 .72 .80 .69 .70 .80 GeneParser total | .49 | | | .69 .68 .78 GenLang total .04 .26 .60 .55 .83 .58 .46 .85 (Sp-trained) human .08 .37 .69 .61 .89 .65 .55 .87 * The total test set was the mixed vertebrate set used by <ref> [9] </ref> but excluding the HAMRPS14A entry (as in [21]), for a total of 27 entries; the human test set consisted of the 12 human sequences in the total test set. Data were as in Table II, and were taken from [21] for GeneParser and from [9] for GeneID, in the latter <p> mixed vertebrate set used by <ref> [9] </ref> but excluding the HAMRPS14A entry (as in [21]), for a total of 27 entries; the human test set consisted of the 12 human sequences in the total test set. Data were as in Table II, and were taken from [21] for GeneParser and from [9] for GeneID, in the latter case by recalculation from the original entries for the human subset and for the statistics by base. <p> Others have observed a "feast or famine" effect whereby sequence entries vary tremendously in the numbers of potential genes they produce (ranging continuously over five orders of magnitude in <ref> [9] </ref>). It would of course be most interesting if such disjunctive grammars actually recognized functional differences in the "types" of genes that they recognized, for instance if they happened to classify genes by time or tissue of expression, perhaps reflecting subtle differences in the gene expression machinery. <p> Compare this with GeneID, which typically evaluates tens of thousands of gene models each of which includes multiple "equivalent" exon clusters <ref> [9] </ref>, or with GeneParser, which uses a dynamic programming matrix to literally examine every possible assignment of intron and exon boundaries in a sequence [21].
Reference: [10] <author> J. E. Hopcroft and J. D. Ullman. </author> <title> Introduction to Automata Theory, Languages, and Computation. </title> <publisher> Addison-Wesley, </publisher> <address> Reading MA, </address> <year> 1979. </year>
Reference-contexts: Introduction Formal language theory views languages as sets of strings over some alphabet, and specifies potentially infinite languages with concise sets of rules called grammars <ref> [10] </ref>. Grammars are an exceptionally well-studied methodology, familiar to all computer scientists, for the description of complex, higher-order structures embodied in strings of symbols. Moreover, they can be given as input to general-purpose programs called parsers capable of determining whether a given string satisfies the rules of the grammar. <p> grammar was then elaborated so that an additional set of node rules each invoked exactly two of either the leaf rules or other node rules. (In formal terms, the core grammar was thus reduced to Chomsky normal form, and it is known that any context-free grammar can be so structured <ref> [10] </ref>.) The resulting parse trees were therefore binary. Each node rule N was responsible for combining the cost of two lower-level rules a left (L) and right (R) child - and passing it up to its own parent.
Reference: [11] <author> M. Kudo, S. Kitamura-Abe, M. Shimbo, and Y. Lida. </author> <title> Analysis of context of 5' splice site sequences in mammalian mRNA precursors by subclass method. </title> <journal> CABIOS, </journal> <volume> 8(4) </volume> <pages> 367-376, </pages> <year> 1992. </year>
Reference-contexts: We note that the sensors used thus far are not among the most sophisticated currently under study, which include compositional measures drawn from signal processing and information theory (reviewed in [4]) and signal measures based on connectionist and classification techniques from machine learning (e.g. <ref> [1, 11] </ref>). The ability to apply such advanced sensors in a "plug and test" mode in a variety of grammar architectures and evidence combination schemes should allow them to be used to the best effect.
Reference: [12] <author> R. H. Lathrop, T. A. Webster, R. Smith, P. Winston, and T. F. Smith. </author> <title> Integrating AI with sequence analysis. </title> <editor> In L. Hunter, editor, </editor> <booktitle> Artificial Intelligence and Molecular Biology, chapter 6, </booktitle> <pages> pages 210-258. </pages> <publisher> AAAI Press, </publisher> <year> 1993. </year>
Reference-contexts: In particular, our formula for specificity is that used by [21]; it is called `Sen2' by [9], and appears elsewhere in the literature as positive predictive value <ref> [12] </ref>. (A different formula is often used for specificity, which counts true negatives, but these numbers are generally too large in this application to be informative; in nearly every case this formula produced values that varied only between 0.95 and 0.98.) There appears to be a consensus that Matthews' correlation coefficient
Reference: [13] <author> B. W. Matthews. </author> <title> Comparison of the predicted and observed secondary structure of t4 phage lysozyme. </title> <journal> Biochimica et Biophysica Acta, </journal> <volume> 405 </volume> <pages> 443-451, </pages> <year> 1975. </year>
Reference-contexts: different formula is often used for specificity, which counts true negatives, but these numbers are generally too large in this application to be informative; in nearly every case this formula produced values that varied only between 0.95 and 0.98.) There appears to be a consensus that Matthews' correlation coefficient (CC) <ref> [13] </ref> is the best overall indicator of overlap, providing as it does a single scalar metric of performance. For all sequence entries of a given set, individual and average values for each of these metrics for the minimum cost parse were compiled.
Reference: [14] <author> F.C.N. Pereira and D.H.D. Warren. </author> <title> Definite clause grammars for language analysis. </title> <journal> Artif. Intell., </journal> <volume> 13 </volume> <pages> 231-278, </pages> <year> 1980. </year>
Reference-contexts: Methods Grammars and Parsing The gene grammars to be described were implemented in the logic programming language Prolog, using a powerful and extensible grammar paradigm called definite clause grammar (DCG) <ref> [14] </ref>. DCGs are directly translated by Prolog compilers to executable code for simple recursive-descent parsers.
Reference: [15] <author> D. B. </author> <title> Searls. Representing genetic information with formal grammars. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 386-391. </pages> <booktitle> American Association for Artificial Intelligence, </booktitle> <year> 1988. </year>
Reference-contexts: These systems achieve similar levels of performance [21]. We proposed the use of formal grammars to assemble gene structures from primary sequence in 1988 <ref> [15] </ref>, and since that time have worked to build a domain-specific parser to enable the use of grammars as versatile yet reasonably efficient pattern recognition tools [16, 17, 18]. <p> This is compiled to code which evaluates a candidate sequence in a fashion optimized for rapid parsing <ref> [15] </ref>. <p> Gene Grammars Protein-encoding gene grammars are the most complex we have built, and will not be given in their full detail. (Source code and documentation are available on request, and many aspects of the grammar's design have appeared in <ref> [15, 17, 18, 20] </ref>.) Described below is the "core" of a new grammar designed specifically for automated optimization of gene prediction.
Reference: [16] <author> D. B. </author> <title> Searls. Investigating the linguistics of DNA with definite clause grammars. </title> <editor> In E. Lusk and R. Overbeek, editors, </editor> <booktitle> Logic Programming: Proceedings of the North American Conference, </booktitle> <pages> pages 189-208. </pages> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: We proposed the use of formal grammars to assemble gene structures from primary sequence in 1988 [15], and since that time have worked to build a domain-specific parser to enable the use of grammars as versatile yet reasonably efficient pattern recognition tools <ref> [16, 17, 18] </ref>. We have successfully used this system, called GenLang, for the recognition of tRNA genes, group I introns, and a variety of other features [20, 19]. We now report on more comprehensive efforts to use the GenLang system to recognize and predict structures of eukaryotic protein-encoding genes. <p> For example, it is more efficient to detect the Start Codon Consensus before evaluating the Upstream elements of the grammar. (The theory and practice of this aspect of GenLang are discussed in <ref> [16] </ref> and [18].) Moreover, while many rules refer to primary sequence directly in the tradition of formal grammars, they are intermixed with more global, evaluative rules 7 that have a distinctly heuristic flavor. <p> to parse each gene in such a way that only the known, authentic structure is allowed. (One of the advantages of the DCG methodology is that properly-written grammars may be given an instantiated parse tree as input, rather than producing it as output, so as to enforce a given parse <ref> [16] </ref>.) Thresholds may then be set to the maximum costs encountered at each node for the entire training set, i.e. so as to just barely allow every known gene and element of a gene; this is called the 100% setpoint for the grammar thresholds as a group. <p> again we have shown that similar grammars can be "relaxed" to allow for the detection of untranslateable messages, such as are produced with certain splicing defects [20]; all that is required is that the forms of mutations be modelled with the grammar as well, by methods we have described elsewhere <ref> [16, 18] </ref>. The inherent non-determinism of the GenLang parser may prove to be an advantage in addressing alternative splicing.
Reference: [17] <author> D. B. </author> <title> Searls. The linguistics of DNA. </title> <journal> American Scientist, </journal> <volume> 80(6) </volume> <pages> 579-591, </pages> <year> 1992. </year>
Reference-contexts: We proposed the use of formal grammars to assemble gene structures from primary sequence in 1988 [15], and since that time have worked to build a domain-specific parser to enable the use of grammars as versatile yet reasonably efficient pattern recognition tools <ref> [16, 17, 18] </ref>. We have successfully used this system, called GenLang, for the recognition of tRNA genes, group I introns, and a variety of other features [20, 19]. We now report on more comprehensive efforts to use the GenLang system to recognize and predict structures of eukaryotic protein-encoding genes. <p> Gene Grammars Protein-encoding gene grammars are the most complex we have built, and will not be given in their full detail. (Source code and documentation are available on request, and many aspects of the grammar's design have appeared in <ref> [15, 17, 18, 20] </ref>.) Described below is the "core" of a new grammar designed specifically for automated optimization of gene prediction. <p> We feel it is also very important that the practical grammar used here is still built upon and tied to a formally well-founded "idealized" gene grammar <ref> [17] </ref>, which continues to provide a solid foundation for other ongoing research in parallelization, formal grammars, etc. Gene Parsing A single parsing run actually entails the generation and evaluation of a large number of alternative parses, with the minimum cost parse being selected as the final answer.
Reference: [18] <author> D. B. </author> <title> Searls. The computational linguistics of biological sequences. </title> <editor> In L. Hunter, editor, </editor> <booktitle> Artificial Intelligence and Molecular Biology, chapter 2, </booktitle> <pages> pages 47-120. </pages> <publisher> AAAI Press, </publisher> <year> 1993. </year>
Reference-contexts: We proposed the use of formal grammars to assemble gene structures from primary sequence in 1988 [15], and since that time have worked to build a domain-specific parser to enable the use of grammars as versatile yet reasonably efficient pattern recognition tools <ref> [16, 17, 18] </ref>. We have successfully used this system, called GenLang, for the recognition of tRNA genes, group I introns, and a variety of other features [20, 19]. We now report on more comprehensive efforts to use the GenLang system to recognize and predict structures of eukaryotic protein-encoding genes. <p> Gene Grammars Protein-encoding gene grammars are the most complex we have built, and will not be given in their full detail. (Source code and documentation are available on request, and many aspects of the grammar's design have appeared in <ref> [15, 17, 18, 20] </ref>.) Described below is the "core" of a new grammar designed specifically for automated optimization of gene prediction. <p> For example, it is more efficient to detect the Start Codon Consensus before evaluating the Upstream elements of the grammar. (The theory and practice of this aspect of GenLang are discussed in [16] and <ref> [18] </ref>.) Moreover, while many rules refer to primary sequence directly in the tradition of formal grammars, they are intermixed with more global, evaluative rules 7 that have a distinctly heuristic flavor. <p> again we have shown that similar grammars can be "relaxed" to allow for the detection of untranslateable messages, such as are produced with certain splicing defects [20]; all that is required is that the forms of mutations be modelled with the grammar as well, by methods we have described elsewhere <ref> [16, 18] </ref>. The inherent non-determinism of the GenLang parser may prove to be an advantage in addressing alternative splicing.
Reference: [19] <author> D. B. Searls and S. Dong. </author> <title> A syntactic pattern recognition system for DNA sequences. </title> <editor> In H. A. Lim, J. Fickett, C. R. Cantor, and R. J. Robbins, editors, </editor> <booktitle> Proceedings of the 2nd International Conference on Bioinformatics, Supercomputing, and Complex Genome Analysis, </booktitle> <pages> pages 89-101. </pages> <publisher> World Scientific, </publisher> <year> 1993. </year>
Reference-contexts: We have successfully used this system, called GenLang, for the recognition of tRNA genes, group I introns, and a variety of other features <ref> [20, 19] </ref>. We now report on more comprehensive efforts to use the GenLang system to recognize and predict structures of eukaryotic protein-encoding genes. <p> Details of the implementation of GenLang can be found elsewhere <ref> [19, 20] </ref>. A significant feature of GenLang grammars is the incorporation of a notion of cost. To allow for imperfect matching, for example with a simple oligonucleotide sequence, a maximum cost may be imposed on the rule when it is invoked, and up to that number of mismatches is allowed. <p> Even traditional linguistic techniques such as chart parsing have their analogues in other technical domains. However, the lower levels of the gene grammar and indeed the recognition engine itself are still general purpose tools, which have been used to find a variety of other types of features <ref> [19] </ref>. The logic grammar framework is well-suited for rapid prototyping, and inherently supports useful features such as input management behind the scenes, parameter hiding, easily modified syntax and higher level language features, and most of all an efficient backtracking search mechanism. <p> However, we feel that by taking advantage of the chart parser 21 and designing grammar rules specialized for scanning lengthy sequences <ref> [19] </ref>, we will be able to adapt GenLang to deal with such complex genes effectively, though perhaps not at the level of the intrinsically bottom-up approaches of other programs.
Reference: [20] <author> D. B. Searls and M. O. Noordewier. </author> <title> Pattern-matching search of DNA sequences using logic grammars. </title> <booktitle> In Proceedings of the Conference on Artificial Intelligence Applications, </booktitle> <pages> pages 3-9. </pages> <publisher> IEEE, </publisher> <year> 1991. </year>
Reference-contexts: We have successfully used this system, called GenLang, for the recognition of tRNA genes, group I introns, and a variety of other features <ref> [20, 19] </ref>. We now report on more comprehensive efforts to use the GenLang system to recognize and predict structures of eukaryotic protein-encoding genes. <p> Details of the implementation of GenLang can be found elsewhere <ref> [19, 20] </ref>. A significant feature of GenLang grammars is the incorporation of a notion of cost. To allow for imperfect matching, for example with a simple oligonucleotide sequence, a maximum cost may be imposed on the rule when it is invoked, and up to that number of mismatches is allowed. <p> Gene Grammars Protein-encoding gene grammars are the most complex we have built, and will not be given in their full detail. (Source code and documentation are available on request, and many aspects of the grammar's design have appeared in <ref> [15, 17, 18, 20] </ref>.) Described below is the "core" of a new grammar designed specifically for automated optimization of gene prediction. <p> GenLang could return multiple genes in a sequence with some simple extensions, and in fact we have demonstrated this previously with multiple parses in a globin gene region <ref> [20] </ref>. Partial genes are more problematic, since the grammar represents a model of an entire gene, but grammars are easily written which span only subtrees. <p> disease gene alleles with mutations that affect translation would also not be recognized (at least in their entirety) by the grammar described here, but again we have shown that similar grammars can be "relaxed" to allow for the detection of untranslateable messages, such as are produced with certain splicing defects <ref> [20] </ref>; all that is required is that the forms of mutations be modelled with the grammar as well, by methods we have described elsewhere [16, 18]. The inherent non-determinism of the GenLang parser may prove to be an advantage in addressing alternative splicing.
Reference: [21] <author> E. E. Snyder and G. D. Stormo. </author> <title> Identification of coding regions in genomic DNA sequences: an application of dynamic programming and neural networks. </title> <journal> Nucleic Acids Res., </journal> <volume> 21 </volume> <pages> 607-613, </pages> <year> 1993. </year>
Reference-contexts: Several such systems have been built on rule-based architectures [5, 7]. These advances have brought into focus the combinatorial problem of assembling and testing large sets of candidate exons; this has been addressed in the GeneID system [9] by clustering exons into equivalence classes, and in the GeneParser system <ref> [21] </ref> by a novel dynamic programming approach (see also [8]). These systems achieve similar levels of performance [21]. <p> focus the combinatorial problem of assembling and testing large sets of candidate exons; this has been addressed in the GeneID system [9] by clustering exons into equivalence classes, and in the GeneParser system <ref> [21] </ref> by a novel dynamic programming approach (see also [8]). These systems achieve similar levels of performance [21]. We proposed the use of formal grammars to assemble gene structures from primary sequence in 1988 [15], and since that time have worked to build a domain-specific parser to enable the use of grammars as versatile yet reasonably efficient pattern recognition tools [16, 17, 18]. <p> This coarse-grained branch-and-bound technique, as well as the chart parsing described above, was necessary to produce large numbers of alternative structures under the inherently costly parsing methodology, though the number examined are still small compared to other combinatorial algorithms which perform exhaustive searches <ref> [9, 21] </ref>. <p> In particular, our formula for specificity is that used by <ref> [21] </ref>; it is called `Sen2' by [9], and appears elsewhere in the literature as positive predictive value [12]. (A different formula is often used for specificity, which counts true negatives, but these numbers are generally too large in this application to be informative; in nearly every case this formula produced values <p> Statistics from individual entries are averaged in two ways: by gene, as in [9], and by base (i.e. by summing results on a nucleotide by nucleotide basis), as in <ref> [21] </ref>. <p> We also analyzed the performance of GenLang relative to two other special-purpose gene prediction programs, GeneID [9] and GeneParser <ref> [21] </ref>, based on data from these original papers using the GeneID test set. <p> Based on the training results above, only a single training epoch was used, and it was again confirmed that this was sufficient to achieve peak performance. Table III compares these results with original data (recalculated as required for direct comparison) from [9] and <ref> [21] </ref>. 17 test sets. Each circle represents a single entry, with correlation scores from the two programs indicated by positions on the respective axes. Thus, points above and to the left of the dashed line represent entries for which GenLang's correlation score exceeded that of GRAIL. <p> GeneParser total | .49 | | | .69 .68 .78 GenLang total .04 .26 .60 .55 .83 .58 .46 .85 (Sp-trained) human .08 .37 .69 .61 .89 .65 .55 .87 * The total test set was the mixed vertebrate set used by [9] but excluding the HAMRPS14A entry (as in <ref> [21] </ref>), for a total of 27 entries; the human test set consisted of the 12 human sequences in the total test set. Data were as in Table II, and were taken from [21] for GeneParser and from [9] for GeneID, in the latter case by recalculation from the original entries for <p> total test set was the mixed vertebrate set used by [9] but excluding the HAMRPS14A entry (as in <ref> [21] </ref>), for a total of 27 entries; the human test set consisted of the 12 human sequences in the total test set. Data were as in Table II, and were taken from [21] for GeneParser and from [9] for GeneID, in the latter case by recalculation from the original entries for the human subset and for the statistics by base. <p> Compare this with GeneID, which typically evaluates tens of thousands of gene models each of which includes multiple "equivalent" exon clusters [9], or with GeneParser, which uses a dynamic programming matrix to literally examine every possible assignment of intron and exon boundaries in a sequence <ref> [21] </ref>.
Reference: [22] <author> R. Staden. </author> <title> Computer methods to locate signals in nucleic acid sequences. </title> <journal> Nucleic Acids Res., </journal> <volume> 12 </volume> <pages> 505-519, </pages> <year> 1984. </year>
Reference-contexts: Traditionally this has devolved to the problem of recognizing coding sequence using a variety of statistical metrics, recently reviewed in [4]. These compositional methods, used in what Staden termed "gene search by content" <ref> [22] </ref>, typically produce for any sample window of sequence a measure of similarity, by some criterion, to "typical" exonic sequence data. <p> Nevertheless, new systems such as GRAIL have markedly improved upon these methods by combining evidence from a number of them in a connectionist architecture [24]. Another approach to gene-finding involves what Staden termed "gene search by signal" <ref> [22] </ref>, the recognition of specific local binding sites or other cues to processes involved in gene expression, such as splice sites.
Reference: [23] <author> G. D. Stormo. </author> <title> Consensus patterns in DNA. </title> <journal> Methods Enzymol., </journal> <volume> 183 </volume> <pages> 211-221, </pages> <year> 1990. </year>
Reference-contexts: Weight matrices are a widely-used and relatively "low-tech" example of a means of detecting such local signals <ref> [23] </ref>. Recently, a number of systems (including more recent versions of GRAIL) have united compositional and signal detection techniques in hybrid gene prediction systems, in which evidence is combined to predict the most likely gene structure from a stretch of primary sequence. <p> This is compiled to code which evaluates a candidate sequence in a fashion optimized for rapid parsing [15]. The method that proved most effective with the signals described below was one that evaluates a sequence subarray S using a negative log likelihood function <ref> [23] </ref>, as follows: Cost = n X b2B Thus the cost is the sum of the negative logs of the individual base position frequencies, normalized so that the most likely base in each position contributes zero cost.
Reference: [24] <author> E. C. Uberbacher and R. J. </author> <title> Mural. Locating protein-coding regions in human DNA sequences by a multiple sensor-neural network approach. </title> <booktitle> Proc. </booktitle> <institution> Nat. Acad. Sci. USA, </institution> <month> 88 </month> <pages> 11261-11265, </pages> <year> 1991. </year>
Reference-contexts: Nevertheless, new systems such as GRAIL have markedly improved upon these methods by combining evidence from a number of them in a connectionist architecture <ref> [24] </ref>. Another approach to gene-finding involves what Staden termed "gene search by signal" [22], the recognition of specific local binding sites or other cues to processes involved in gene expression, such as splice sites. <p> Uberbacher, personal communication], which is inherent in the GenLang system.) Table II indicates that, as a rule, GRAIL performs with higher specificity, while Gen-Lang is relatively more sensitive. Reports of GRAIL results generally emphasize specificity as a measure of performance <ref> [24] </ref>, probably reflecting an orientation toward the use of GRAIL to predict putative exons for further laboratory investigation, a situation in which false positives can prove very costly.
References-found: 24

