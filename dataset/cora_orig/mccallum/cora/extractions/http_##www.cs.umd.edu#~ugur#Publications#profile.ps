URL: http://www.cs.umd.edu/~ugur/Publications/profile.ps
Refering-URL: http://www.cs.umd.edu/~ugur/papers.html
Root-URL: 
Email: ugur@cs.umd.edu  franklin@cs.umd.edu  giles@research.nj.nec.com  
Title: Constructing User Profiles Incrementally: A Multi-Modal Approach  
Author: Ugur Cetintemel Michael J. Franklin C. Lee Giles 
Note: Submitted for Publication  
Affiliation: University of Maryland  University of Maryland  NEC Research Institute and UMIACS  
Abstract: Push-based data dissemination depends upon knowledge of user interests for making scheduling, bandwidth allocation, and routing decisions. Such information is maintained as user profiles. We propose an incremental algorithm for constructing user profiles based on monitoring and user feedback. In our approach, a user-profile is represented as multiple vectors whose size and elements change adaptively based on user access behavior. This "multi-modal" approach allows the profile to more accurately represent complex user interests. The approach can be tuned to trade off profile complexity and effectiveness, making it suitable for use in large-scale information filtering applications. We evaluate the method by experimentally investigating its ability to categorize pages from the World Wide Web. Our results show that the method can provide high retrieval effectiveness with modest profile sizes and can effectively adapt to changes in users' interests.
Abstract-found: 1
Intro-found: 1
Reference: [Aal92] <author> I.J. Aalbersberg. </author> <title> Incremental relevance feedback. </title> <booktitle> In Proc. ACM SIGIR Conf., </booktitle> <pages> pages 11-22, </pages> <year> 1992. </year>
Reference-contexts: The main difference of our work is the introduction of a parametric approach that adaptively changes the number of vectors used to represent profiles. Previously, Aalbersberg evaluated the effectiveness of incremental relevance feedback <ref> [Aal92] </ref>, however, from the standpoint of an information retrieval environment. Lam et al. addressed the issue of shifts in user interests [LMMP96], using a two-level approach which combines reinforcement and Bayesian learning.
Reference: [All96] <author> James Allan. </author> <title> Incremental relevance feedback for information filtering. </title> <booktitle> In Proc. ACM SIGIR Conf., </booktitle> <address> Zurich, Switzerland, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: Thus, an incremental approach is needed. Purely incremental feedback can update a query (or profile) for each individual document judgment that is received by a system. It is also possible to combine such judgments into groups and incorporate each group using a single update. Allan <ref> [All96] </ref> studied the effect of group size on the effectiveness of incremental relevance feedback (in a non-filtering environment). <p> If set to 0, on the other hand, active vectors will not change with feedback, and virtually no adaptation will take place. 4 Experimental Environment Filtering systems developers typically rely upon the technique of user simulation in order to understand and quantify the effectiveness of their solutions (e.g., <ref> [She94, All96, LMMP96] </ref>). In this section, we describe in detail the approach we used for evaluating alternative information filtering algorithms. 4.1 Document Collection The first problem that needs to be addressed when designing a filtering study is the identification of a suitable document collection. <p> We also present results for two other algorithms, namely (purely) Incremental Rocchio (RI) and Group Rocchio (RG). RG is the incremental relevance feedback algorithm studied by Allan <ref> [All96] </ref> (see Section 2.2) that uses a group of judged documents for updating the profile using relevance feedback. RI is a special case of RG where the group size is set to 1. <p> For reasons of brevity, we only discuss previous research which is directly relevant to our work and the database community. The work most closely related to ours is that of Allan, who studied the utility of relevance feedback for information filtering environments <ref> [All96] </ref>. He investigated the case where only a few judged documents are available each time, and showed that highly effective results can be achieved using relatively few judged documents.
Reference: [Bal98] <author> M. Balabanovic. </author> <title> Exploring versus exploiting when learning user models for text recommendation. In User Modeling and User-Adapted Interaction, </title> <note> 1998. to appear. 20 </note>
Reference-contexts: By using the rank-based 7 In fact, effectiveness is sometimes slightly higher with smaller vectors, due to the well-known problem of overfit-ting [Mit97] that arises in machine learning, and has been also identified in related studies (e.g., <ref> [Bal98] </ref>) 11 measure provided by the routing benchmark, however, this problem is avoided. <p> More recently, Balabanovic conducted a similar study where he evaluated a gradient descent approach and investigated different document selection strategies by simulating a text recommendation setting using Yahoo! categories <ref> [Bal98] </ref>. Unlike the way our algorithm represents profiles as a collection of vectors, Balabanovic used multi-level category preferences to represent user interests. He evaluated his technique against Rocchio feedback and obtained comparable results.
Reference: [Cha98] <author> My Excite Channel. </author> <note> http://my.excite.com/, 1998. </note>
Reference-contexts: It is difficult for a user to exactly and correctly specify their information needs to the system. Second, state-of-the-art large-scale information filtering systems are typically built on the assumption that users change their interests only infrequently (e.g,. <ref> [YGM95, Cha98] </ref>). If the profile does not keep up with the user's information needs, then precision and recall problems will quickly arise. 1.2 Maintaining Profiles Many existing publish/subscribe based systems require users to manually reflect their interest changes to the profile. <p> The premise underlying SIFT's approach is that users know when and how their interests change and are willing to update their profiles manually each time such a change hap 19 pens. This premise is also held by current "push"-oriented products such as PointCast [Poi98] and MyExcite <ref> [Cha98] </ref>. The advantages of automatic profile construction, however, have been shown experimentally using human subjects in [FD92]. 7 Conclusions Push-based data dissemination depends upon knowledge of user interests for making scheduling, bandwidth allocation, and routing decisions. Such information is maintained as user profiles.
Reference: [FBY92] <author> W.B. Frakes and R. Baeza-Yates. </author> <title> Information Retrieval: Data Structures and Algorithms. </title> <publisher> Prentice-Hall, </publisher> <year> 1992. </year>
Reference-contexts: Such feedback can, however, also be used to create a user profile from scratch. In this paper, we present a novel approach for constructing user profiles incrementally using a supervised learning technique. Our algorithm is based on a single pass non-hierarchical clustering technique <ref> [FBY92] </ref>. A key feature that distinguishes our algorithm from previous work is that it uses a multi-modal representation of user profiles; i.e., a profile is represented as a collection of clusters of user interests rather than as a single entity. <p> The standard process for computing the vector representation of a document includes stop-list removal and stemming <ref> [FBY92] </ref>. Stop-list removal is the process of discarding words that occur very frequently in almost all documents and thus have very low content discrimination power (e.g., the, a, from etc.). <p> Any non-zero temperature value indicates an unstable condition with negative values causing strength decrease and positive values causing strength increase. 3.2 The MM Algorithm The general structure of MM is based on the traditional incremental clustering algorithm applied to document clustering <ref> [FBY92] </ref>. The main idea of incremental document clustering is to maintain clusters of document vectors. Each cluster is represented by using a single representative vector. The first document is assigned as the representative for the first cluster. <p> We do not consider this situation and choose to allow only a single merge operation in a single iteration for efficiency reasons. The other potential merge operations, if any, are accomplished lazily in future iterations if necessary. 9 3.6 Discussion MM extends the well-known non-hierarchical incremental clustering algorithm <ref> [FBY92] </ref> with new operations and structures designed specifically for filtering environments. The operators we introduced control the number of vectors that form the profile and allow for fast adaptation when there is a shift in user interests. <p> We then converted these documents to their vector representations by removing the HTML tags and other non-words, followed by stop-list removal and stemming. 6 This process is illustrated in Figure 3. We then 6 We used a stop-list of 429 stop-words and a Porter stemmer (see <ref> [FBY92] </ref>). 10 discarded the vectors containing fewer than two terms; ending up with about 2000 vectors.
Reference: [FD92] <author> P.W. Foltz and S.T. Dumais. </author> <title> Personalized information delivery: An analysis of information filtering methods. </title> <journal> Communications of the ACM, </journal> <volume> 35 </volume> <pages> 51-60, </pages> <month> 12 </month> <year> 1992. </year>
Reference-contexts: As ffi is increased, MM becomes more likely to create additional vectors. At an extreme value of ffi = 1 (not shown), MM maintains a separate vector for each relevant document presented to it. This case is similar to the "nearest relevant neighbor" (NRN) method, which was studied in <ref> [FD92] </ref>. Keeping vectors for all relevant documents, however, is not practical for an information filtering environment as the number of documents presented to such a system grows monotonically over the 9 In fact, there is a slight improvement in precision for RI and RG as categories are added. <p> Unlike the way our algorithm represents profiles as a collection of vectors, Balabanovic used multi-level category preferences to represent user interests. He evaluated his technique against Rocchio feedback and obtained comparable results. Foltz and Dumais used Latent Semantic Indexing (LSI) to derive a reduced dimensional vector space <ref> [FD92] </ref> and constructed a profile vector from each document judged as relevant by the user. The relevance of a document to the profile is then computed based on its cosine similarity to the closest profile vector. <p> This premise is also held by current "push"-oriented products such as PointCast [Poi98] and MyExcite [Cha98]. The advantages of automatic profile construction, however, have been shown experimentally using human subjects in <ref> [FD92] </ref>. 7 Conclusions Push-based data dissemination depends upon knowledge of user interests for making scheduling, bandwidth allocation, and routing decisions. Such information is maintained as user profiles. We have proposed a novel, incremental algorithm for constructing user profiles based on monitoring and user feedback.
Reference: [FZ97] <author> M. Franklin and S. Zdonik. </author> <title> A framework for scalable dissemination-based systems. </title> <booktitle> In Proc. ACM OOPSLA Conf. (Invited Paper), </booktitle> <address> Atlanta, GA, </address> <month> October </month> <year> 1997. </year>
Reference-contexts: 1 Introduction Large-scale dissemination-based information systems provide targeted distribution of data to a potentially huge set of consumers connected over intranets, extranets, the Internet, or using satellite or cable broadcast facilities <ref> [FZ97] </ref>. Dissemination-based applications include personalized electronic newsletters/newspapers, information feeds, automatic software update distribution, and traffic information systems. An increasingly popular approach for supporting such applications uses push-based data delivery based on a publish/subscribe model.
Reference: [Har95] <author> D. </author> <title> Harman. </title> <booktitle> Overview of the third Text REtrieval conference (trec-3). In Proc. 3rd TREC Conf., </booktitle> <year> 1995. </year>
Reference-contexts: Such an approach, however, would have terrible precision. In Section 4, we discuss these metrics for filtering effectiveness. Our algorithm is based on a technique called the Vector Space Model (VSM) [Sal89], which has been shown to be an effective IR model <ref> [Har95] </ref>. In VSM, documents are represented as vectors in a high-dimensional vector space where the value of dimensions are based on the words occurring in that document. Documents describing similar topics are likely to be close to each other, as they possibly include common words.
Reference: [Hul97] <author> David A. Hull. </author> <title> The TREC-6 filtering track: Description and analysis. </title> <booktitle> In The Sixth Text REtrieval Conference. </booktitle> <institution> (TREC-6), National Institute of Standards and Technology, Gaithersburg, MD, </institution> <year> 1997. </year>
Reference-contexts: The reason for this decision is that evaluations of this latter approach indicate that results obtained using it are heavily dependent on the specific filtering function (such as the setting of relevance cutoffs, etc.) used <ref> [Hul97] </ref>. This function must be optimized separately for each technique being evaluated. Thus, an evenhanded comparison of learning techniques using this latter benchmark is problematic, calling into question the quality of the filtering function used for each of the competitors.
Reference: [LMMP96] <author> W. Lam, S. Mukhopadhyay, J. Mostafa, and M Palakal. </author> <title> Detection of shifts in user interests for personalized information filtering. </title> <booktitle> In Proc. ACM SIGIR Conf., </booktitle> <address> Zurich, Switzerland, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: If set to 0, on the other hand, active vectors will not change with feedback, and virtually no adaptation will take place. 4 Experimental Environment Filtering systems developers typically rely upon the technique of user simulation in order to understand and quantify the effectiveness of their solutions (e.g., <ref> [She94, All96, LMMP96] </ref>). In this section, we describe in detail the approach we used for evaluating alternative information filtering algorithms. 4.1 Document Collection The first problem that needs to be addressed when designing a filtering study is the identification of a suitable document collection. <p> Previously, Aalbersberg evaluated the effectiveness of incremental relevance feedback [Aal92], however, from the standpoint of an information retrieval environment. Lam et al. addressed the issue of shifts in user interests <ref> [LMMP96] </ref>, using a two-level approach which combines reinforcement and Bayesian learning. Unlike our work, which adopts a quite general definition of user profiles, their work uses a fixed number of categories to define user interests.
Reference: [Mit97] <author> Tom Mitchell. </author> <title> Machine Learning. </title> <publisher> McGraw-Hill, </publisher> <year> 1997. </year>
Reference-contexts: By using the rank-based 7 In fact, effectiveness is sometimes slightly higher with smaller vectors, due to the well-known problem of overfit-ting <ref> [Mit97] </ref> that arises in machine learning, and has been also identified in related studies (e.g., [Bal98]) 11 measure provided by the routing benchmark, however, this problem is avoided.
Reference: [Oar97] <author> D.W. Oard. </author> <title> The state of the art in text filtering. In User Modeling and User-Adapted Interaction, </title> <year> 1997. </year>
Reference-contexts: The machine learning community has also shown great interest in different aspects of profile generation, especially in the framework of personalized information filtering (e.g., [SM93, Ste92, SHP97]). The interested reader may see <ref> [Oar97] </ref> for a general overview of the approaches used in filtering from a multi-disciplinary viewpoint. For reasons of brevity, we only discuss previous research which is directly relevant to our work and the database community.
Reference: [Poi98] <author> PointCast. </author> <note> http://www.pointcast.com/, 1998. </note>
Reference-contexts: The premise underlying SIFT's approach is that users know when and how their interests change and are willing to update their profiles manually each time such a change hap 19 pens. This premise is also held by current "push"-oriented products such as PointCast <ref> [Poi98] </ref> and MyExcite [Cha98]. The advantages of automatic profile construction, however, have been shown experimentally using human subjects in [FD92]. 7 Conclusions Push-based data dissemination depends upon knowledge of user interests for making scheduling, bandwidth allocation, and routing decisions. Such information is maintained as user profiles.
Reference: [Roc71] <author> Jr. J.J. Rocchio. </author> <title> Relevance feedback in information retrieval. In The Smart System - Experiments in Automatic Document Processing, </title> <address> pages 313-323. </address> <publisher> Prentice Hall, </publisher> <year> 1971. </year>
Reference-contexts: This approach places the burden of identifying changes and notifying the system on the users. In contrast, other systems use a more automatic approach based on a technique called relevance feedback <ref> [Roc71, SB90] </ref>. In this latter approach, users provide feedback to the system about the documents that they have been sent (typically a binary indication of whether or not the document was considered useful). <p> Among those, 1 In an information filtering environment, there is no static data collection from which to extract this statistical information; such information must be collected incrementally. 4 Rocchio relevance feedback <ref> [Roc71] </ref> is a well-known, effective scheme which instantiates the feedback parameters as follows: Q i+1 = Q i + 2 d2R 1 X v d Traditional relevance feedback assumes that the document collection is fixed and that all the documents relevant to the query are available at the time of query
Reference: [Sal89] <author> Gerard Salton. </author> <title> Automatic Text Processing. </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: For example, to achieve perfect recall, a system could simply return all the documents in the collection. Such an approach, however, would have terrible precision. In Section 4, we discuss these metrics for filtering effectiveness. Our algorithm is based on a technique called the Vector Space Model (VSM) <ref> [Sal89] </ref>, which has been shown to be an effective IR model [Har95]. In VSM, documents are represented as vectors in a high-dimensional vector space where the value of dimensions are based on the words occurring in that document. <p> 1 ; v 2 ) = v 1 v 2 = t w t;v 1 w t;v 2 q P t;v 1 t w 2 2.2 Relevance Feedback Relevance feedback is an effective information retrieval technique that can be used to form query (or profile) vectors based on document contents <ref> [Sal89] </ref>. The main idea is to use the documents that have already been judged (i.e., deemed as relevant or non-relevant) by the user, emphasizing the terms that occur in relevant ones while deemphasizing those occurring in non-relevant ones in future formulations of the same query.
Reference: [SB90] <author> G. Salton and C. Buckley. </author> <title> Improving retrieval performance by relevance feedback. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 41(4) </volume> <pages> 288-297, </pages> <year> 1990. </year>
Reference-contexts: This approach places the burden of identifying changes and notifying the system on the users. In contrast, other systems use a more automatic approach based on a technique called relevance feedback <ref> [Roc71, SB90] </ref>. In this latter approach, users provide feedback to the system about the documents that they have been sent (typically a binary indication of whether or not the document was considered useful).
Reference: [She94] <author> B. Sheth. </author> <title> A learning approach to personalized information filtering. </title> <type> Master's thesis, </type> <institution> MIT, Media Lab, </institution> <year> 1994. </year>
Reference-contexts: If set to 0, on the other hand, active vectors will not change with feedback, and virtually no adaptation will take place. 4 Experimental Environment Filtering systems developers typically rely upon the technique of user simulation in order to understand and quantify the effectiveness of their solutions (e.g., <ref> [She94, All96, LMMP96] </ref>). In this section, we describe in detail the approach we used for evaluating alternative information filtering algorithms. 4.1 Document Collection The first problem that needs to be addressed when designing a filtering study is the identification of a suitable document collection.
Reference: [SHP97] <author> H. Schutze, D.A. Hull, and J.O. Pedersen. </author> <title> A comparison of classifiers and document representations for the routing problem. </title> <booktitle> In Proc. ACM SIGIR Conf., </booktitle> <pages> pages 74-81, </pages> <year> 1997. </year>
Reference-contexts: The machine learning community has also shown great interest in different aspects of profile generation, especially in the framework of personalized information filtering (e.g., <ref> [SM93, Ste92, SHP97] </ref>). The interested reader may see [Oar97] for a general overview of the approaches used in filtering from a multi-disciplinary viewpoint. For reasons of brevity, we only discuss previous research which is directly relevant to our work and the database community.
Reference: [SM93] <author> B. Sheth and P. Maes. </author> <title> Evolving agents for personalized information filtering. </title> <booktitle> In Proceedings of the Ninth Conference on Artificial Intelligence for Applications, </booktitle> <pages> pages 345-352. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1993. </year>
Reference-contexts: The machine learning community has also shown great interest in different aspects of profile generation, especially in the framework of personalized information filtering (e.g., <ref> [SM93, Ste92, SHP97] </ref>). The interested reader may see [Oar97] for a general overview of the approaches used in filtering from a multi-disciplinary viewpoint. For reasons of brevity, we only discuss previous research which is directly relevant to our work and the database community.
Reference: [Ste92] <author> C. Stevens. </author> <title> Knowledge-Based Assistance for Accessing Large, Poorly Structured Information Spaces. </title> <type> PhD thesis, </type> <institution> University of Colorado, Department of Computer Science, Boulder, </institution> <year> 1992. </year> <month> 21 </month>
Reference-contexts: The machine learning community has also shown great interest in different aspects of profile generation, especially in the framework of personalized information filtering (e.g., <ref> [SM93, Ste92, SHP97] </ref>). The interested reader may see [Oar97] for a general overview of the approaches used in filtering from a multi-disciplinary viewpoint. For reasons of brevity, we only discuss previous research which is directly relevant to our work and the database community.
Reference: [VH96] <author> Ellen M. Voorhees and Donna Harman. </author> <booktitle> Overview of the fifth Text REtrieval Conference (TREC-4). In The Fifth Text REtrieval Conference. </booktitle> <institution> (TREC-5), National Institute of Standards and Technology, Gaithersburg, MD, </institution> <year> 1996. </year>
Reference-contexts: user with synthetic profile SP to a document from category d is formally defined as: f d = +1 if category d 2 SP 1 otherwise ) 4.3 Methodology and Performance Metrics We chose to base our evaluation methodology on the one used in the routing track of the TREC <ref> [VH96] </ref> benchmark. The idea is to have the system score and then rank-order a collection of documents based on their likelihood of relevance to a particular profile (or query). <p> has higher precision for static situations, but also recovers fast enough to preserve its advantage when the user's interests change. 18 6 Related Work There has been a huge volume of research on text-based profile construction in information retrieval community, especially in the framework of TREC routing and filtering tasks <ref> [VH96] </ref>. In the routing task, the system is given a set of documents relevant to a topic and is asked to rank-order an unseen set of documents according to their estimated relevance based on the constructed profile.
Reference: [YGM95] <author> T.W. Yan and H. Garcia-Molina. </author> <title> SIFT- a tool for wide-area information dissemination. </title> <booktitle> In Proceedings of the 1995 USENIX Technical Conference, </booktitle> <pages> pages 177-186, </pages> <year> 1995. </year> <month> 22 </month>
Reference-contexts: It is difficult for a user to exactly and correctly specify their information needs to the system. Second, state-of-the-art large-scale information filtering systems are typically built on the assumption that users change their interests only infrequently (e.g,. <ref> [YGM95, Cha98] </ref>). If the profile does not keep up with the user's information needs, then precision and recall problems will quickly arise. 1.2 Maintaining Profiles Many existing publish/subscribe based systems require users to manually reflect their interest changes to the profile. <p> The approach taken by SIFT, which uses the publish/subscribe model for wide-area information dissemination <ref> [YGM95] </ref>, requires users to explicitly submit their profiles and update those profiles using relevance feedback. Our algorithm also requires explicit user feedback about documents. Unlike SIFT however, it automatically constructs and updates profiles without requiring any user intervention.
References-found: 22

