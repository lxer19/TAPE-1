URL: ftp://ftp.cse.ucsc.edu/pub/tr/ucsc-crl-94-26.ps.Z
Refering-URL: ftp://ftp.cse.ucsc.edu/pub/tr/README.html
Root-URL: http://www.cse.ucsc.edu
Title: Rectangle Replacement and Variable Ordering: Two Techniques for Logic Minimization Using If-Then-Else DAGs  
Author: Kevin Karplus Martine Schlag Glen Langdon Dean 
Degree: A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in Computer Engineering by Stren Ste  The dissertation of Stren Ste is approved:  
Date: June 1994  
Affiliation: University of California Santa Cruz  of Graduate Studies and Research  
Abstract-found: 0
Intro-found: 1
Reference: [BCGH86] <author> Karen Bartlett, William Cohen, Aart De Geus, and Gary Hachtel. </author> <title> Synthesis and optimization of multilevel logic under timing constraints. </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, </journal> <volume> CAD-5(4):582-596, </volume> <month> October </month> <year> 1986. </year>
Reference-contexts: Multi-level logic minimization minimizes with the object of implementing the final circuit in random logic. Most previous work in multi-level logic minimization is based on extensions to two-level logic minimization techniques <ref> [Bra87a, BRSW87a, BHJ + 87, BCGH86] </ref>; a notable example is the misII multi-level logic minimization system [BRSW87a]. Many 6 multi-level minimizers use two-level minimization as a subroutine, usually based on the espresso two-level minimizer [BHMS84]. <p> More recently the local-transformation/rule-based and algorithmic approach has been combined, where the algorithmic approach is used in the initial phase of logic minimization, and the rule-based approach is used towards the end and in particular for technology mapping. SOCRATES <ref> [BCGH86] </ref> and more resent versions of LSS [BT88] are examples of systems combining the two approaches. A slightly different approach is to use local transformations and make them have global effect.
Reference: [Ber91] <author> C. Leonard Berman. </author> <title> Circuit width, register allocation, and reduced function graphs. </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, </journal> <volume> CAD-10(8):1059-1066, </volume> <month> August </month> <year> 1991. </year>
Reference-contexts: The order in which to traverse the input dags should be in decreasing order of height, thus computing the most compute-intensive nodes first. Berman <ref> [Ber91] </ref> later related the order of traversal in Malik's heuristic to the problem of register allocation, saying that the height of a fanin dag can be taken as a rough estimate to the number of registers required to evaluate the function represented by the fanin dag. <p> Instead of traversing the subdags in order of decreasing height, it traverses in order of decreasing count, where count is our technology-independent area estimate. The use of count to sort the subdags is inspired by Berman's paper of relating ordering heuristics to register allocation <ref> [Ber91] </ref>. Berman states that Malik's height heuristic is an approximation to the optimal register allocation technique as described in [SU70]. By choosing the highest subdag first Malik et al. has achieved a rough estimate of the number of registers required to evaluate the logic.
Reference: [BHJ + 87] <author> D. Bostick, G. D. Hachtel, R. Jacoby, M. R. Lightner, P. H. Moceyunas, C. R. Morrison, and D. Ravenscroft. </author> <title> The boulder optimal logic desing system. </title> <booktitle> In IEEE International Conference on Computer-Aided Design ICCAD-87, </booktitle> <pages> pages 62-65, </pages> <address> Santa Clara, CA, </address> <month> 9-12 November </month> <year> 1987. </year>
Reference-contexts: Multi-level logic minimization minimizes with the object of implementing the final circuit in random logic. Most previous work in multi-level logic minimization is based on extensions to two-level logic minimization techniques <ref> [Bra87a, BRSW87a, BHJ + 87, BCGH86] </ref>; a notable example is the misII multi-level logic minimization system [BRSW87a]. Many 6 multi-level minimizers use two-level minimization as a subroutine, usually based on the espresso two-level minimizer [BHMS84]. <p> Many multi-level minimization techniques rely on methods developed for two-level minimization and the sum-of-products form seemed the obvious way to go <ref> [BRSW87a, BHJ + 87] </ref>. Throughout this thesis we often use the terminology related to sum-of-products form. A variable is a symbol representing a single coordinate of the Boolean space B n (e.g., x).
Reference: [BHMS84] <author> Robert K. Brayton, Gary D. Hachtel, Curtis T. McMullen, and Alberto L. Sangiovanni-Vincentelli. </author> <title> Logic Minimization Algorithms for VLSI Synthesis. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1984. </year>
Reference-contexts: The height of a PLA is determined by the number of products, and the width is determined by the number of inputs and outputs. The area of two-level logic minimization is mature and near-minimum PLA realizations can almost always be found <ref> [BHMS84, Rud89] </ref>. Unfortunately, there are many designs for which a two-level representation is inappropriate. Not only can the number of products be exponential in the number of inputs, but a two-level representation of a design may also be considerably slower than a representation using multiple levels of logic. <p> Many 6 multi-level minimizers use two-level minimization as a subroutine, usually based on the espresso two-level minimizer <ref> [BHMS84] </ref>. The objectives in multi-level logic minimization are * To minimize area of the fabricated circuit. * To minimize critical path delay. * To make routability in layout synthesis easier. * To make testability of the final circuit easier, and in some cases, to provide a test set. <p> The main global techniques are factorization, extraction of common subexpression extraction, and various algorithms for finding common subexpressions and factors. The most notable example of an algorithmic system is misII [BRSW87a], which evolved from algorithms developed for two-level logic synthesis <ref> [BHMS84] </ref>. More recently the local-transformation/rule-based and algorithmic approach has been combined, where the algorithmic approach is used in the initial phase of logic minimization, and the rule-based approach is used towards the end and in particular for technology mapping. <p> Another important technique used prior to factorization is 2-level logic minization as in espresso <ref> [BHMS84] </ref>. In sum-of-products form, factorization of a function usually consists of finding a "factor candidate" and then "dividing" the function by this candidate. Division is not defined in a Boolean algebra, since the only operators are the binary + and fl (also known as disjunction and conjunction). <p> The binary decision diagram in Figure 2.1 is in canonical form with respect to the ordering (a; b; c; d), 1 An implicant is reduced by adding literals to the implicant|this awkward terminology was introduced in espresso <ref> [BHMS84] </ref> 27 d d b b 0 1 1 0 0 0 01 0 1 ordering (c; d; a; b). whereas the dag in Figure 3.1 shows the same function in canonical form with respect to the ordering (c; d; a; b).
Reference: [BHS90] <author> R. K. Brayton, G. D. Hachtel, and A. L. Alberto Sangiovanni-Vincentelli. </author> <title> Multilevel logic synthesis. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 78(2) </volume> <pages> 264-300, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: By using De Morgan's law the negation of a factored form is easily obtained and is itself a factored form. The literature has reported several attempts to minimize factored forms, see <ref> [BHS90] </ref> for a list of references, but unlike sum-of-products form it is hard to determine if a given factored form is optimal. <p> The function p is called a Boolean divisor of f , or if f = pq then p is called a Boolean factor of f . The number of Boolean divisors and factors is clarified by the following propositions borrowed from <ref> [BHS90] </ref>: Proposition 1: A logic function p is a Boolean factor of a logic function f if and only if f :p = 0, i.e., if f is in sum-of-products form then every term of f contains p. <p> Brayton <ref> [BHS90] </ref> presents an algorithm that performs algebraic division, that is, given f and p it uniquely determines q and r such that, * pq is an algebraic product, * r has a few cubes as possible, and * pq + r and f are the same expression (having the same number
Reference: [Bra87a] <author> Robert K. Brayton. </author> <title> Algorithms for multi-level logic synthesis and optimization. </title> <editor> In G. De Micheli, Alberto Sangiovanni-Vincentelli, and P. Antognetti, editors, </editor> <booktitle> Design Systems for VLSI Circuits|Logic Synthesis and Silicon Compilation, </booktitle> <pages> pages 197-247. </pages> <publisher> Martinus Nijhoff Publishers, </publisher> <year> 1987. </year>
Reference-contexts: Multi-level logic minimization minimizes with the object of implementing the final circuit in random logic. Most previous work in multi-level logic minimization is based on extensions to two-level logic minimization techniques <ref> [Bra87a, BRSW87a, BHJ + 87, BCGH86] </ref>; a notable example is the misII multi-level logic minimization system [BRSW87a]. Many 6 multi-level minimizers use two-level minimization as a subroutine, usually based on the espresso two-level minimizer [BHMS84]. <p> In thesis a new algorithm two-column rectangle replacement for factoring and extracting common sub-expressions in Boolean functions is presented. The algorithm is an improved variant of Brayton's Brayton's rectangle covering problem <ref> [Bra87a, BRSW87b] </ref>, and it is particularly well suited for optimizing circuits for area, while controlling delay. We also present a slight variation of the heuristic, which optimizes with respect to delay. Canonical form representation of Boolean expressions is an important part of logic synthesis and verification. <p> Boolean functions are represented as Boolean matrices, and rectangles of these matrices represent either a factor of a function or a subexpression that can be shared among several functions. The rectangle replacement problem is a variant of Brayton's rectangle-covering problem <ref> [Bra87a, BRSW87b] </ref>. In both we find sets of rectangles that cover all the 1's of the Boolean matrix|rectangle replacement differs from rectangle covering in the way rectangles are replaced. <p> Although we have used canonical forms to merge such common subex-pressions, the computation of canonical forms is often too expensive, as they will sometimes be exponentially large, even for some common circuits such as multipliers [Bry91]. In this chapter we explore rectangle replacement, a variant of rectangle covering <ref> [Bra87a, BRSW87b] </ref>, which has been useful for finding common subexpressions in sum-of-products minimizers, and see how it can be applied to if-then-else dags. <p> We use rectangle replacement primarily to recognize commonality in commutative and associative operations|roughly the equivalent of the common-cube extraction operation of misII. 5.2 Blocks and rectangles The rectangle-covering problem applied to logic synthesis was first presented by Robert Brayton <ref> [Bra87a] </ref>. He showed how a set of Boolean functions could be represented as a Boolean matrix, and that finding "rectangles" of this matrix was the same as finding 38 factors of expressions and common subexpressions of a network of functions. <p> We continue the traversal with the children of the column expression, so that all necessary replacements are done in one traversal. 5.3.3 Selecting rectangles Selecting rectangles for replacement is the most difficult part of rectangle covering <ref> [Bra87a] </ref>. The main step in rectangle replacement is to add a new column to the Boolean matrix, where the new column is an acceptable replacement for some rectangle of the matrix. <p> By considering only two-column rectangles and only one rectangle at a time, we have reduced the problem of finding rectangles. Also the work associated with finding the right two-column rectangle is considerably less than that of finding the right multi-column rectangle (a prime rectangle <ref> [Bra87a, BRSW87b] </ref>). In a matrix with n columns there are n possible two-column rectangles and 2 n possible prime rectangles. <p> When constructing an if-then-else dag from a set of terms (a sum-of-products expression) the terms are factored using a technique similar to simple literal factoring <ref> [Bra87a] </ref>. This technique will move variables appearing in many terms into if-parts of an if-then-else triple. <p> This theorem is easily related to cube- and kernel factorization of sum-of-products expressions <ref> [Bra87a] </ref>. If a cube or kernel appears in more than one term the expression can be factored by using the cube as the factor.
Reference: [Bra87b] <author> Robert K. Brayton. </author> <title> Factoring logic functions. </title> <journal> IBM Journal of research and development, </journal> <volume> 31(2) </volume> <pages> 187-198, </pages> <month> March </month> <year> 1987. </year>
Reference-contexts: Kernels provide a useful set of divisors to choose from when factoring a function, and various algorithms for finding kernels are presented in <ref> [Bra87b] </ref>. 3.2 Sub-expression extraction Consider a Boolean function f represented by the Boolean expression F . Define a sub-expression of F as an expression G, such that f can be written as f = QG + R (3.1) where Q and R are Boolean expressions and Q is non-zero.
Reference: [BRKM91] <author> Kenneth M. Butler, Don E. Ross, Rohit Kapur, and M. Ray Mercer. </author> <title> Heuristics to compute variable orderings for efficient manipulation of ordered binary decision diagrams. </title> <booktitle> In ACM IEEE 28 th Design Automation Conference Proceedings, </booktitle> <pages> pages 417-420, </pages> <address> San Francisco, California, </address> <month> June 17-21 </month> <year> 1991. </year>
Reference-contexts: Hence the space complexity gets out of hand fairly quickly. Several researchers have presented heuristics for finding variable orders that result in small obdds <ref> [FFK88, MWBS88, BRKM91, FFM93] </ref>. Here the starting point is a Boolean network, which is traversed once in a depth- or breadth-first manner to determine a total order of the variables, which is then used for building the ordered binary decision diagram. <p> A variable order is computed during a single traversal of the initial network, and thus the complexity is O (n) where n is the number of nodes in the network. Unfortunately, all traversal-based heuristics have one thing in common: no single heuristic is superior. In <ref> [BRKM91] </ref> various combinations of both breadth- and depth-first heuristics are tried, but one of their conclusions directly contradicts what other researchers have concluded: they conclude that for depth-first traversals, ordering inputs with least (or high) fanout first creates only minor differences in ordering results. <p> Other approaches for finding a good variable order include * Sorting the input variables depending on whether they are control or data variables [Bry86]. This method requires knowledge of the circuit function, and so is not feasible in many applications. * Simulation-based heuristics <ref> [BRKM91] </ref>. Initially all primary inputs are set to unknown and the state of the circuit is recorded. Next the circuit is simulated by setting each primary input to 0 first and then to 1, counting the number of changes in the simulated 59 circuit. <p> The variable that is most controlling is chosen as the next in the order, and its value is now fixed to either 0 or 1 while the remaining variables are ordered. * Testability-measure-based heuristics <ref> [BRKM91] </ref>. Primary inputs are assigned weights based on their observability and sorted in decreasing order of their weights. * Simulated annealing techniques [MKR92]. <p> The bad performance of the incremental height heuristic is due to one example, frg1, where it is approximately 40 times worse than the best. This illustrates that generally no single traversal-based heuristic is particular efficient, and trying combinations of several will almost always improve the results <ref> [BRKM91] </ref>. In Table 6.3 and Table 6.4 we compare the depth-first ordering heuristics on examples from the ISCAS benchmarks for testing [Lis88]. The results here are much more mixed and for several of the examples we ran out of memory (entries marked with oom) when converting to canonical form.
Reference: [BRSW87a] <author> Robert K. Brayton, Richard Rudell, Alberto Sangiovanni-Vincentelli, and Al-bert R. Wang. </author> <title> MIS: A multiple-level logic optimization system. </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, </journal> <volume> CAD-6(6):1062-1081, </volume> <month> November </month> <year> 1987. </year>
Reference-contexts: Multi-level logic minimization minimizes with the object of implementing the final circuit in random logic. Most previous work in multi-level logic minimization is based on extensions to two-level logic minimization techniques <ref> [Bra87a, BRSW87a, BHJ + 87, BCGH86] </ref>; a notable example is the misII multi-level logic minimization system [BRSW87a]. Many 6 multi-level minimizers use two-level minimization as a subroutine, usually based on the espresso two-level minimizer [BHMS84]. <p> Multi-level logic minimization minimizes with the object of implementing the final circuit in random logic. Most previous work in multi-level logic minimization is based on extensions to two-level logic minimization techniques [Bra87a, BRSW87a, BHJ + 87, BCGH86]; a notable example is the misII multi-level logic minimization system <ref> [BRSW87a] </ref>. Many 6 multi-level minimizers use two-level minimization as a subroutine, usually based on the espresso two-level minimizer [BHMS84]. <p> The main global techniques are factorization, extraction of common subexpression extraction, and various algorithms for finding common subexpressions and factors. The most notable example of an algorithmic system is misII <ref> [BRSW87a] </ref>, which evolved from algorithms developed for two-level logic synthesis [BHMS84]. More recently the local-transformation/rule-based and algorithmic approach has been combined, where the algorithmic approach is used in the initial phase of logic minimization, and the rule-based approach is used towards the end and in particular for technology mapping. <p> Many multi-level minimization techniques rely on methods developed for two-level minimization and the sum-of-products form seemed the obvious way to go <ref> [BRSW87a, BHJ + 87] </ref>. Throughout this thesis we often use the terminology related to sum-of-products form. A variable is a symbol representing a single coordinate of the Boolean space B n (e.g., x). <p> Recall that a cube is the either 1, a single literal, or a conjunction of literals. A kernel of a function f is a cubefree (it contains more than one cube) divisor of f . In misII <ref> [BRSW87a] </ref> the common subexpressions are sought in the set of cubes and kernels, known as common-cube extraction and kernel-intersection extraction. In common-cube extraction divisors are cube intersections common to two or more expressions. <p> ITEM item is our if-then-else minimizer used as an environment for testing various logic synthesis techniques. item is implemented in c++ and currently consists of approximately 50,000 lines of code. item is an interactive system like the misII minimizer <ref> [BRSW87a] </ref>. if-then-else dag from some network description. Various optimizations are then applied to the if-then-else dag to improve area, delay, or testability of the circuit. Once optimized the circuit is mapped to a target technology. item currently supports mapping to field-programmable gate-arrays and complex gates. <p> The block covering 1 algorithms developed for misII <ref> [BRSW87b, BRSW87a] </ref> are very effective at finding shared expressions, but are too expensive to apply to entire circuits (misII applies them only at the gate level).
Reference: [BRSW87b] <author> Robert K. Brayton, Richard Rudell, Alberto Sangiovanni-Vincentelli, and Al-bert Wang. </author> <title> Multi-level logic optimization and the rectangle covering problem. </title> <booktitle> In IEEE International Conference on Computer-Aided Design ICCAD-87, </booktitle> <pages> pages 66-69, </pages> <address> Santa Clara, CA, </address> <month> November </month> <year> 1987. </year>
Reference-contexts: In thesis a new algorithm two-column rectangle replacement for factoring and extracting common sub-expressions in Boolean functions is presented. The algorithm is an improved variant of Brayton's Brayton's rectangle covering problem <ref> [Bra87a, BRSW87b] </ref>, and it is particularly well suited for optimizing circuits for area, while controlling delay. We also present a slight variation of the heuristic, which optimizes with respect to delay. Canonical form representation of Boolean expressions is an important part of logic synthesis and verification. <p> Chapter 5 and 6 are the main contributions to the area. Chapter 5 presents a new algorithm for extracting common sub-expressions from a logic network. The technique, which we call two-column rectangle replacement, builds on the rectangle covering problem introduced by Brayton et al. <ref> [BRSW87b] </ref>. 9 Chapter 6 is concerned with variable ordering for ordered binary decision diagrams (obdds) and canonical if-then-else dags. The chapter presents new heuristics for finding variable orders that result in small canonical dags. <p> The block covering 1 algorithms developed for misII <ref> [BRSW87b, BRSW87a] </ref> are very effective at finding shared expressions, but are too expensive to apply to entire circuits (misII applies them only at the gate level). <p> Boolean functions are represented as Boolean matrices, and rectangles of these matrices represent either a factor of a function or a subexpression that can be shared among several functions. The rectangle replacement problem is a variant of Brayton's rectangle-covering problem <ref> [Bra87a, BRSW87b] </ref>. In both we find sets of rectangles that cover all the 1's of the Boolean matrix|rectangle replacement differs from rectangle covering in the way rectangles are replaced. <p> Although we have used canonical forms to merge such common subex-pressions, the computation of canonical forms is often too expensive, as they will sometimes be exponentially large, even for some common circuits such as multipliers [Bry91]. In this chapter we explore rectangle replacement, a variant of rectangle covering <ref> [Bra87a, BRSW87b] </ref>, which has been useful for finding common subexpressions in sum-of-products minimizers, and see how it can be applied to if-then-else dags. <p> By considering only two-column rectangles and only one rectangle at a time, we have reduced the problem of finding rectangles. Also the work associated with finding the right two-column rectangle is considerably less than that of finding the right multi-column rectangle (a prime rectangle <ref> [Bra87a, BRSW87b] </ref>). In a matrix with n columns there are n possible two-column rectangles and 2 n possible prime rectangles.
Reference: [Bry85] <author> Randal Everitt Bryant. </author> <title> Symbolic verification of MOS circuits. </title> <editor> In Henry Fuchs, editor, </editor> <booktitle> 1985 Chapel Hill Conference on Very Large Scale Integration, </booktitle> <pages> pages 419-438. </pages> <publisher> Computer Science Press, </publisher> <year> 1985. </year>
Reference-contexts: They have recently become very popular for verification purposes <ref> [Bry86, Bry85, MWBS88] </ref>, and attempts to use them for logic minimization has also been reported [FFK88]. A binary decision diagram is a directed acyclic graph that use a single universal operator: the if-then-else operator.
Reference: [Bry86] <author> Randal Everitt Bryant. </author> <title> Graph-based algorithms for Boolean function manipulation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-35(8):677-691, </volume> <month> August </month> <year> 1986. </year> <month> 107 </month>
Reference-contexts: Lawler [Law64] presented an algorithm for obtaining optimal factored forms, but the approach is only feasible for low-complexity functions of few inputs [Wan89]. 2.3 Binary decision diagrams Binary decision diagrams offer an alternative way of representing and manipulating Boolean expressions <ref> [Bry86] </ref>. They have recently become very popular for verification purposes [Bry86, Bry85, MWBS88], and attempts to use them for logic minimization has also been reported [FFK88]. A binary decision diagram is a directed acyclic graph that use a single universal operator: the if-then-else operator. <p> They have recently become very popular for verification purposes <ref> [Bry86, Bry85, MWBS88] </ref>, and attempts to use them for logic minimization has also been reported [FFK88]. A binary decision diagram is a directed acyclic graph that use a single universal operator: the if-then-else operator. <p> The meaning of a binary decision diagram is defined recursively as (if label (node) then meaning (then-part) else meaning (else-part)). It should be noted that each non-leaf node itself represents a Boolean expression. Binary decision diagrams are easy to construct <ref> [Bry86] </ref>, but without other restrictions they can be difficult to simplify or compare for equality|a + b can be represented with two different binary decision diagrams: one can have a as root and the other b as root. <p> Binary decision diagrams and if-then-else dags have very convenient canonical forms. Bryant formulated a canonical form for binary decision diagrams <ref> [Bry86] </ref>. As originally described, it is a weak canonical form, but adding a permanent symbol table to give unique ids to each node makes it a strong canonical form. <p> The size of a canonical binary decision diagram is very dependent on the variable ordering and finding the best ordering is a co-NP-complete problem <ref> [Bry86] </ref>. <p> In Section 6.5 we finally show how the variable 56 order may affect other transformations besides conversion to canonical form. 6.2 Background Variable order in binary decision diagrams (bdds) has been an issue ever since Bryant presented a canonical form for bdds called ordered binary decision diagrams (obdds) <ref> [Bry86] </ref>. <p> Other approaches for finding a good variable order include * Sorting the input variables depending on whether they are control or data variables <ref> [Bry86] </ref>. This method requires knowledge of the circuit function, and so is not feasible in many applications. * Simulation-based heuristics [BRKM91]. Initially all primary inputs are set to unknown and the state of the circuit is recorded.
Reference: [Bry91] <author> Randal E. Bryant. </author> <title> On the complexity of VLSI implementations and graph representations of Boolean functions with application to integer multiplication. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 40(2) </volume> <pages> 205-213, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: The NP completeness result guarantees that some functions will have exponentially large obdds or canonical if-then-else dags. Bryant proved that some useful functions (the middle output of an integer multiplier) have exponentially large obdds for any variable order <ref> [Bry91] </ref>. His results apply equally well to if-then-else dags, though there are canonical if-then-else dags with exponentially larger obdds. 30 4. <p> Although we have used canonical forms to merge such common subex-pressions, the computation of canonical forms is often too expensive, as they will sometimes be exponentially large, even for some common circuits such as multipliers <ref> [Bry91] </ref>. In this chapter we explore rectangle replacement, a variant of rectangle covering [Bra87a, BRSW87b], which has been useful for finding common subexpressions in sum-of-products minimizers, and see how it can be applied to if-then-else dags. <p> Proof: Follows from Lemma 2. 2 Lemma 5: There exist functions for which the number of nodes in a corresponding obdd is exponential in the number of input variables regardless of chosen variable order. Proof: Bryant <ref> [Bry91, Theorem 4] </ref> showed that any obdd representation for the Boolean function representing the middle output of an integer multiplier for word size n is exponential in the number of nodes. 2 Lemmas 4 and 5 prove that the complexity of the algorithm shown in Figure 6.6 is ex 82 ponential
Reference: [BT88] <author> Leonard Berman and Louise Trevillyan. </author> <title> A global approach to circuit size reduction. </title> <editor> In Jonathan Allen and F. Thomson Leighton, editors, </editor> <booktitle> Proceeding of the 5 th MIT Conference on Advanced Research in VLSI, </booktitle> <pages> pages 203-214, </pages> <address> Cambridge, MA, </address> <month> March </month> <year> 1988. </year>
Reference-contexts: More recently the local-transformation/rule-based and algorithmic approach has been combined, where the algorithmic approach is used in the initial phase of logic minimization, and the rule-based approach is used towards the end and in particular for technology mapping. SOCRATES [BCGH86] and more resent versions of LSS <ref> [BT88] </ref> are examples of systems combining the two approaches. A slightly different approach is to use local transformations and make them have global effect. This approach is used in item [Kar91c, Kar89] and is accomplished by using a global symbol table to store unique expressions. <p> We have had great success with the rectangle covering techniques and also see use for other techniques such as global flow algorithms <ref> [BT88] </ref>. * New technology mappers to cell libraries or cell generators. We are also looking for mappers for sequential logic. * Don't-care information is used by the current factoring transformations, but not very effectively.
Reference: [CCD + 92] <author> Kuang-Chien Chen, Jason Cong, Yuzheng Ding, Andrew B. Kahng, and Peter Trajmar. DAG-Map: </author> <title> Graph-based FPGA technology mapping for delay optimization. </title> <booktitle> IEEE Design and Test of Computers, </booktitle> <pages> pages 7-20, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Thus it is possible to optimize for delay by replacing two-column rectangles in the order of increasing height. A similar tree balancing approach named DMIG, has been used in DAGMAP <ref> [CCD + 92] </ref> to transform an arbitrary Boolean network into a n-input network of minimum height, where all gates have at most n inputs. item also includes a direct implementation of DMIG and in the results section we compare two-column rectangle replacement with DMIG. <p> Columns 4 and 5 are the results of using LocalFactor followed by two-column rectangle replacement optimizing for area. The next two columns are when using two-column rectangle replacement optimizing for delay as described in Section 5.3.4. Finally the last two columns reports the result of applying DMIG <ref> [CCD + 92] </ref> to the networks optimized by LocalFactor. DMIG is a tree-balancing technique that rebalances associative operators to minimize the height of the network.
Reference: [DBG + 84] <author> John A. Darringer, Daniel Brand, John V. Gerbi, Jr. William H Joyner, and Louise Trevillyan. LSS: </author> <title> A system for production logic synthesis. </title> <journal> IBM Journal of research and development, </journal> <volume> 28(5) </volume> <pages> 537-545, </pages> <month> September </month> <year> 1984. </year>
Reference-contexts: There is no limit to the number of rules that can be added to a system in order to achieve logic minimization. An example of a rule-based system is LSS <ref> [DBG + 84] </ref>, where the level of specification ranges from low-level close to hardware, through register-transfer-level to very high-level descriptions with no assumptions of structural decisions. 7 The algorithmic approach is more global in the sense that small changes may affect the entire circuit. <p> The triple should be replaced by an appropriately labeled pointer to the if-part or to true. 2.5 Two input NORs If-then-else dags and binary decision diagrams use the single universal if-then-else operator. An alternative single universal operator, which has been used in LSS <ref> [DBG + 84] </ref> is the two-input NOR gate. Obviously it is less flexible than the if-then-else operator as it can only represent only 5 Boolean functions: 0, 1, x 1 , x 0 1 , and x 0 2 .
Reference: [FFK88] <author> Masahiro Fujita, Hisanori Fujisawa, and Nobuaki Kawato. </author> <title> Evaluation and improvements of Boolean comparison method based on binary decision diagrams. </title> <booktitle> In IEEE International Conference on Computer-Aided Design ICCAD-88, </booktitle> <pages> pages 2-5, </pages> <address> Santa Clara, CA, </address> <month> 7-10 November </month> <year> 1988. </year>
Reference-contexts: They have recently become very popular for verification purposes [Bry86, Bry85, MWBS88], and attempts to use them for logic minimization has also been reported <ref> [FFK88] </ref>. A binary decision diagram is a directed acyclic graph that use a single universal operator: the if-then-else operator. Definition 1: The if-then-else operator is a ternary Boolean function, with (if a then b else c) defined as ab + :ac or, equivalently, (a + c)(:a + b). <p> In Section 6.3 we present a depth-first ordering algorithm, which generalizes the depth-first ordering heuristics of Fujita <ref> [FFK88] </ref>, Malik [MWBS88], Karplus [Kar90] and the new reconvergent ordering heuristics introduced in Section 6.3.3. <p> Hence the space complexity gets out of hand fairly quickly. Several researchers have presented heuristics for finding variable orders that result in small obdds <ref> [FFK88, MWBS88, BRKM91, FFM93] </ref>. Here the starting point is a Boolean network, which is traversed once in a depth- or breadth-first manner to determine a total order of the variables, which is then used for building the ordered binary decision diagram. <p> In [BRKM91] various combinations of both breadth- and depth-first heuristics are tried, but one of their conclusions directly contradicts what other researchers have concluded: they conclude that for depth-first traversals, ordering inputs with least (or high) fanout first creates only minor differences in ordering results. Fujita <ref> [FFK88, FFM93] </ref> presents a depth-first method that orders high fanout inputs before other inputs. Still, fast ordering heuristics are sometimes more important than spending a lot of time finding the best (or near best) variable order. <p> The second step in our approach to variable ordering, that of constructing a variable order, can be implemented as shown in Figure 6.3. We refer to the algorithm in Figure 6.3 as our general depth-first ordering algorithm, as it generalizes the depth-first ordering heuristics of Fujita <ref> [FFK88] </ref>, Malik [MWBS88], Karplus [Kar90], and the other heuristics presented here. The algorithm traverses each subdag (children) of a node (node) in an order determined by the routine Sort, which returns a sorted list of the subdags of node. <p> This heuristic corresponds to the one previously used by Karplus in item [Kar90]. Fanout heuristic, where the subdags are sorted in order of decreasing fanout. This heuristic corresponds to the one described by Fujita et al. <ref> [FFK88] </ref>. Height heuristic, where the subdags are sorted in order of decreasing height. This heuristic corresponds to a heuristic described by Malik et al. [MWBS88]. Count heuristic, where the subdags are sorted in order of decreasing count. <p> When using the simple depth heuristic on a dag constructed in this way, v 1 will be ordered before the variables in E 1 and E 0 , thus we may be able to preserve the factorization in the canonical form. Fanout heuristic Fujita et al. <ref> [FFK88] </ref> used a simple incremental depth-first heuristic to determine the variable order. Their starting point was a Boolean network, where the input nets of a node were traversed in order of decreasing fanout. <p> We have implemented a fanout heuristic similar to the heuristic used by Fujita et al. <ref> [FFK88] </ref>, except that the starting point is an if-then-else dag. It makes a depth-first traversal of the dag traversing the subdags of a node in order of decreasing fanout.
Reference: [FFM93] <author> Masahiro Fujita, Hisanori Fujisawa, and Yusuke Matsunaga. </author> <title> Variable ordering algorithms for ordered binary decision diagrams and their evaluation. </title> <journal> IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, </journal> <volume> CAD-12(1):6-12, </volume> <month> January </month> <year> 1993. </year>
Reference-contexts: Hence the space complexity gets out of hand fairly quickly. Several researchers have presented heuristics for finding variable orders that result in small obdds <ref> [FFK88, MWBS88, BRKM91, FFM93] </ref>. Here the starting point is a Boolean network, which is traversed once in a depth- or breadth-first manner to determine a total order of the variables, which is then used for building the ordered binary decision diagram. <p> In [BRKM91] various combinations of both breadth- and depth-first heuristics are tried, but one of their conclusions directly contradicts what other researchers have concluded: they conclude that for depth-first traversals, ordering inputs with least (or high) fanout first creates only minor differences in ordering results. Fujita <ref> [FFK88, FFM93] </ref> presents a depth-first method that orders high fanout inputs before other inputs. Still, fast ordering heuristics are sometimes more important than spending a lot of time finding the best (or near best) variable order. <p> Iterating SplitOrder We finally show the results of iterating SplitOrder on examples from the ISCAS bench mark set [Lis88]. Table 6.12 contains the results for the examples for which we could find previous results in the literature <ref> [MWBS88, FFM93, MKR92] </ref>. 95 Problem Outputs obdd ItemCan C432 all 1570:35 1307:35 C880 all 9021:42 7188:37 C1908 75 (866) 10356:30 9876:30 C3540 all 61054:37 58659:37 Table 6.11: Result of SplitOrder on examples from the ISCAS benchmark set. <p> 1969 all;obdd 4829 1853 1248 [MKR92] C1355 1324GAT (583);obdd 77746 3330 1324GAT (583);obdd 37706 2063 all;obdd 35842 1991 all;obdd 35298 1959 4283 [MKR92] C1908 75 (866);obdd 10356 1357 75 (866);obdd 9541 1264 1606 [MKR92] 75 (866);obdd 9515 1265 all;obdd 8863 1408 all;obdd 8805 1403 C2670 311 (1278);obdd 54895 30560 14763 <ref> [FFM93] </ref> C3540 405 (1717);obdd 61054 21791 405 (1717);obdd 43163 11269 405 (1717);obdd 36155 10334 all;obdd 42436 12462 all;obdd 36274 10305 17747 [MKR92] C5315 all;obdd 3327 780 all;obdd 2381 492 all;obdd 2289 472 1296 [MKR92] all;obdd 2320 472 Table 6.12: Result of iterating SplitOrder.
Reference: [FS87] <author> Steven J. Friedman and Kenneth J. Supowit. </author> <title> Finding the optimal variable ordering for binary decision diagrams. </title> <booktitle> In ACM IEEE 24 th Design Automation Conference Proceedings, </booktitle> <pages> pages 348-355, </pages> <address> Miami Beach, FL, </address> <month> 28 June-1 July </month> <year> 1987. </year>
Reference-contexts: The x-axis is the size of when using the first random order. Friedman and Supowit <ref> [FS87] </ref> later came up with an algorithm that finds the optimal order with complexity O (n 2 3 n ).
Reference: [GDP86] <author> D.D. Gajski, N.D. Dutt, and B.M. Pangrle. </author> <title> Silicon Compilation. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1986. </year>
Reference-contexts: Dave Johannsen [Joh79] first used the term silicon compilation in 1979 for an automatic synthesis system that assembled parameterized pieces of layout. Since then the term has been used in a much broader sense to define the translation process from a higher-level description into layout <ref> [GDP86] </ref>. The main purpose of silicon compilation can be summarized in three points: * To broaden the scope of designers who can construct ASICs.
Reference: [GJ79] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability, A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman and Company, </publisher> <address> San Francisco, CA, </address> <year> 1979. </year>
Reference-contexts: Because equivalence checking is fast in canonical form, but equivalence checking in non-canonical form is equivalent to the complement of the NP-complete problem satisfiability, refer to Gary and Johnson <ref> [GJ79, page 261] </ref>, we are almost guaranteed that conversion to canonical form is exponential in the worst case. The NP completeness result guarantees that some functions will have exponentially large obdds or canonical if-then-else dags.
Reference: [HJKM89] <author> G. Hachtel, R. Jacoby, K. Keutzer, and C. Morrison. </author> <title> On the relationship between area optimization and multifault testability of multilevel logic. </title> <booktitle> In IEEE International Conference on Computer-Aided Design ICCAD-89, </booktitle> <pages> pages 422-425, </pages> <address> Santa Clara, CA, </address> <month> November </month> <year> 1989. </year>
Reference-contexts: Extracting sub-expression tends to make placement and routability more difficult since common nodes have multiple fanout and perhaps can't be placed close to all fanout nodes at once. Testability can be preserved if all products in the rewritten expressions (3.1)-(3.3) are limited to be algebraic products <ref> [HJKM89] </ref>. Types of sub-expressions In sum-of-products forms, common sub-expressions are sought among the set of cubes and kernels. Recall that a cube is the either 1, a single literal, or a conjunction of literals.
Reference: [Joh79] <author> Dave Johannsen. </author> <title> Bristle blocks: A silicon compiler. </title> <booktitle> In Proceedings of 16th Design Automation Conference, </booktitle> <pages> pages 310-313, </pages> <year> 1979. </year>
Reference-contexts: Depending on the level of abstraction a behavioral description can range from a high-level algorithmic description to a low-level description in terms of Boolean equations. Dave Johannsen <ref> [Joh79] </ref> first used the term silicon compilation in 1979 for an automatic synthesis system that assembled parameterized pieces of layout. Since then the term has been used in a much broader sense to define the translation process from a higher-level description into layout [GDP86].
Reference: [Kar88] <author> Kevin Karplus. </author> <title> Representing Boolean functions with If-Then-Else DAGs. </title> <type> Technical Report UCSC-CRL-88-28, </type> <institution> Board of Studies in Computer Engineering, University of California at Santa Cruz, </institution> <address> Santa Cruz, CA 95064, </address> <month> December </month> <year> 1988. </year>
Reference-contexts: In Section 3.3 we will show how binary decision diagrams can be canonically represented using Bryant's canonical form. 2.4 If-Then-Else DAGs A major focus of this thesis will be on if-then-else dags, which basically are extended binary decision diagrams that allows for sharing of the if-part <ref> [Kar89, Kar88] </ref>.
Reference: [Kar89] <author> Kevin Karplus. </author> <title> Using if-then-else dags for multi-level logic minimization. </title> <editor> In Charles L. Seitz, editor, </editor> <booktitle> Advanced Research in VLSI: Proceedings of the Decennial Caltech Conference on VLSI, </booktitle> <pages> pages 101-118, </pages> <address> Pasadena, CA, </address> <month> 20-22 March </month> <year> 1989. </year>
Reference-contexts: The base technology should be as simple as possible to keep the number of different nodes low. In [Keu87] the base technology is two-input NAND-gates and inverters, while in work done by Karplus the if-then-else operator has been used as the base technology <ref> [Kar89] </ref>. The logic function for each library gate is also represented as a graph (known as the pattern graph) in the base technology. For each logic function there are many different representations using the base technology, and hence many different pattern graphs. <p> SOCRATES [BCGH86] and more resent versions of LSS [BT88] are examples of systems combining the two approaches. A slightly different approach is to use local transformations and make them have global effect. This approach is used in item <ref> [Kar91c, Kar89] </ref> and is accomplished by using a global symbol table to store unique expressions. If a transformation transforms a part of the circuit into a form that already exists somewhere in the circuit, the common form will be explicitly shared. <p> In Section 3.3 we will show how binary decision diagrams can be canonically represented using Bryant's canonical form. 2.4 If-Then-Else DAGs A major focus of this thesis will be on if-then-else dags, which basically are extended binary decision diagrams that allows for sharing of the if-part <ref> [Kar89, Kar88] </ref>. <p> Karplus <ref> [Kar89] </ref> formulated a different strong canonical form for if-then-else dags. Conversion to canonical form consist of 7 rules, three of which (the systematic-negation condition, the no-constant-if condition, and the no-two-constant condition) are usually used in all representations of if-then-else dags, even non-canonical ones, refer to Section 2.4. <p> Because the different formats have different underlying models of the circuits, conversions are more than just a simple textual substitution. For example, conversion of the sum-of-products format in BLIF to if-then-else dags requires something roughly equivalent to single-cube factoring <ref> [Kar89] </ref>. 4.2 Optimizations in ITEM After constructing the initial multiply-rooted if-then-else dag we apply optimizations to produce a dag that meets the requirements we have set forth. <p> We came up with two sets of transformations: Printform and LocalFactor. The Printform transformations <ref> [Kar89] </ref> preserves testability, but are not good at minimizing circuit area. The reason they are not good circuit minimizers is that they were originally designed to minimize the size of printed Boolean expressions, not multi-level circuits. They attempt to minimize the pcount measure [Kar89], which predicts printing size 33 quite well, <p> The Printform transformations <ref> [Kar89] </ref> preserves testability, but are not good at minimizing circuit area. The reason they are not good circuit minimizers is that they were originally designed to minimize the size of printed Boolean expressions, not multi-level circuits. They attempt to minimize the pcount measure [Kar89], which predicts printing size 33 quite well, but which is not a good predictor of circuit area or delay. The LocalFactor transformations are a rather ad hoc collection of transformations that do an adequate job of minimizing circuit area [Kar89]. Unfortunately, they do not preserve path-delay-fault testability. <p> They attempt to minimize the pcount measure <ref> [Kar89] </ref>, which predicts printing size 33 quite well, but which is not a good predictor of circuit area or delay. The LocalFactor transformations are a rather ad hoc collection of transformations that do an adequate job of minimizing circuit area [Kar89]. Unfortunately, they do not preserve path-delay-fault testability. LocalFactor relies on variable order, since one of its most powerful transformations is conversion to canonical form applied small parts of the dag. <p> Two-column rectangle replacement is well suited for optimizing multi-level logic with respect to both delay and area. For all the cases we are considering in this chapter, an expression is created from several other expressions by pairwise combining expressions with an associative and commutative operator. It has been shown <ref> [Kar89] </ref> that the height of an if-then-else dag is a usable, though not very good, delay estimate for the final circuit. The easiest way to keep the height under control is to balance the dag when we are creating it. <p> Section 5.4 presents some results of minimizing multi-level logic benchmarks using two-column rectangle replacement. Motivation The original motivation behind two-column rectangle replacement was the need for a global optimization technique that would merge logically equivalent if-then-else dags. Local factoring techniques can be used to factor if-then-else dags <ref> [Kar89] </ref>. If factoring results in two identical if-then-else sub-dags they will be merged into a single copy. Unfortunately local factoring techniques fail to give us the global view needed to identify that that two expression can be identical even though they are represented differently. <p> We have previously seen that the height of a dag is a usable delay estimate for the final circuit <ref> [Kar89] </ref>, and so we use height as our arrival time estimator. Using the height of dags to break ties results in a primitive form of tree balancing. 5.3.4 Tree balancing Tree balancing can be carried a little further than in Section 5.3.3. <p> The columns headed with count reports the count of the optimized if-then-else dag. The count metric is our technology independent area predictor, corresponding roughly to (number of outputs) + (number of literals in factored form) - (number of gates) <ref> [Kar89] </ref>. The columns headed with height reports the height of the optimized if-then-else dag. Columns 2 and 3 are the results of using only LocalFactor. Columns 4 and 5 are the results of using LocalFactor followed by two-column rectangle replacement optimizing for area. <p> This heuristic corresponds to a heuristic described by Malik et al. [MWBS88]. Count heuristic, where the subdags are sorted in order of decreasing count. Count is our technology-independent area estimate, corresponding roughly to (number of outputs) + (number of literals in factored form) - (number of gates) <ref> [Kar89] </ref>. Simple depth heuristic The simple depth ordering heuristic is the simplest incremental heuristic: it traverses the dag by first traversing the if-part followed by the then-part and finally the else-part. This heuristic is only applicable to if-then-else dags and binary decision diagrams. <p> is easy to see that if applied to a canonical dag the heuristic will produce the same order as the one used to create the canonical dag. 64 The very simple heuristic is particularly effective because of the way item constructs the initial multiply-rooted if-then-else dag from a circuit description <ref> [Kar89] </ref>. When constructing an if-then-else dag from a set of terms (a sum-of-products expression) the terms are factored using a technique similar to simple literal factoring [Bra87a]. This technique will move variables appearing in many terms into if-parts of an if-then-else triple.
Reference: [Kar90] <author> Kevin Karplus. </author> <note> Discussions in daily meetings, Fall 1990. 108 </note>
Reference-contexts: In Section 6.3 we present a depth-first ordering algorithm, which generalizes the depth-first ordering heuristics of Fujita [FFK88], Malik [MWBS88], Karplus <ref> [Kar90] </ref> and the new reconvergent ordering heuristics introduced in Section 6.3.3. The split order heuristics, Section 6.4, are not traversal-based, instead they construct the total order one variable at a time, where the next variable in the order is chosen among the remaining variables depending on some cost estimate. <p> We refer to the algorithm in Figure 6.3 as our general depth-first ordering algorithm, as it generalizes the depth-first ordering heuristics of Fujita [FFK88], Malik [MWBS88], Karplus <ref> [Kar90] </ref>, and the other heuristics presented here. The algorithm traverses each subdag (children) of a node (node) in an order determined by the routine Sort, which returns a sorted list of the subdags of node. <p> In Section 6.3.4 we provide results using the following four incremental ordering heuristics: Simple Depth heuristic, where the if-part is traversed before the then-part, which is traversed before the else-part. This heuristic corresponds to the one previously used by Karplus in item <ref> [Kar90] </ref>. Fanout heuristic, where the subdags are sorted in order of decreasing fanout. This heuristic corresponds to the one described by Fujita et al. [FFK88]. Height heuristic, where the subdags are sorted in order of decreasing height. This heuristic corresponds to a heuristic described by Malik et al. [MWBS88].
Reference: [Kar91a] <author> Kevin Karplus. Amap: </author> <title> a technology mapper for selector-based field-programmable gate arrays. </title> <booktitle> In ACM IEEE 28 th Design Automation Conference Proceedings, </booktitle> <pages> pages 244-247, </pages> <address> San Francisco, California, </address> <month> June 17-21 </month> <year> 1991. </year>
Reference-contexts: The thesis addresses two major areas in logic minimization: extraction of common sub-expressions and conversion to canonical form under different variable orders. Techniques are demonstrated using the logic synthesis tool item, where item stands for If-Then-Else Minimizer. Although this thesis concentrates on higher-level technology-independent optimizations, published papers <ref> [Kar91d, Kar91a, Kar93] </ref> show that the if-then-else dag representation style indeed is efficient when targeting various FPGA style logic components. <p> In Chapter 6 we present several variable ordering heuristics for finding variable orders that result in small canonical forms. 4.3 Mapping ITEM currently supports mapping to complex gates and field-programmable gate arrays <ref> [Kar91d, Kar91a] </ref>. Field-programmable gate array mappers have been developed for Xilinx-style arrays (Xmap [Kar91d], Xcmap and Xtmap [Kar93]) and for Actel-style arrays (Amap [Kar91a]). Both Amap and Xmap preserve testability. 35 5. <p> Field-programmable gate array mappers have been developed for Xilinx-style arrays (Xmap [Kar91d], Xcmap and Xtmap [Kar93]) and for Actel-style arrays (Amap <ref> [Kar91a] </ref>). Both Amap and Xmap preserve testability. 35 5. Rectangle Replacement This chapter describes the use of rectangle replacement for multi-level logic minimization on functions represented as if-then-else dags. We define the concept of Boolean matrices, and give formal definitions of blocks and rectangles and their meanings.
Reference: [Kar91b] <author> Kevin Karplus. </author> <title> Canonical forms of if-then-else dags are robustly path-delay-fault testable, </title> <month> April </month> <year> 1991. </year> <note> Unpublished paper. </note>
Reference-contexts: Logic synthesis has made it possible to produce 100% testable circuits automatically. The result of logic minimization is a circuit that, ideally, is irredundant, and therefore testable. Some techniques of logic minimization can be proven to preserve testability <ref> [Kar91b] </ref>, and thus if the starting point is a testable circuit the final circuit will also be testable. The objectives of logic minimization have been solved using two different approaches: * The local-transformation/rule-based approach. * The algorithmic approach. <p> Note, that Figure 3.2 is in fact an obdd, since each if-branch is a single variable. The main difference between Figure 3.1 and Figure 3.2 is that the if-then-else dag uses systematic negation, which allows an expression and its negation to be represented by the same subdag. Karplus <ref> [Kar91b] </ref> recently showed that if-then-else dags in canonical form are 100% path-delay fault testable, and hence testable for single and multiple stuck-at faults. By converting to canonical form and using testability-preserving transformations we can optimize for testability. <p> The heuristics of the replacement strategy can be tuned to maximize sharing (minimizing circuit area) or to balance operator trees (minimizing delay) [SK91]. Two-column rectangle replacement preserves path-delay-fault testability <ref> [Kar91b] </ref>. Two-column rectangle replacement does not rely on variable order. Chapter 5 presents the two-column rectangle replacement we have developed. 4.2.3 Conversion to canonical form Conversion to canonical form has several advantages.
Reference: [Kar91c] <author> Kevin Karplus. </author> <title> Item: an if-then-else minimizer for logic synthesis, </title> <month> April </month> <year> 1991. </year> <note> Unpublished paper. </note>
Reference-contexts: SOCRATES [BCGH86] and more resent versions of LSS [BT88] are examples of systems combining the two approaches. A slightly different approach is to use local transformations and make them have global effect. This approach is used in item <ref> [Kar91c, Kar89] </ref> and is accomplished by using a global symbol table to store unique expressions. If a transformation transforms a part of the circuit into a form that already exists somewhere in the circuit, the common form will be explicitly shared.
Reference: [Kar91d] <author> Kevin Karplus. Xmap: </author> <title> a technology mapper for table-lookup field-programmable gate arrays. </title> <booktitle> In ACM IEEE 28 th Design Automation Conference Proceedings, </booktitle> <pages> pages 240-243, </pages> <address> San Francisco, California, </address> <month> June 17-21 </month> <year> 1991. </year>
Reference-contexts: The thesis addresses two major areas in logic minimization: extraction of common sub-expressions and conversion to canonical form under different variable orders. Techniques are demonstrated using the logic synthesis tool item, where item stands for If-Then-Else Minimizer. Although this thesis concentrates on higher-level technology-independent optimizations, published papers <ref> [Kar91d, Kar91a, Kar93] </ref> show that the if-then-else dag representation style indeed is efficient when targeting various FPGA style logic components. <p> In Chapter 6 we present several variable ordering heuristics for finding variable orders that result in small canonical forms. 4.3 Mapping ITEM currently supports mapping to complex gates and field-programmable gate arrays <ref> [Kar91d, Kar91a] </ref>. Field-programmable gate array mappers have been developed for Xilinx-style arrays (Xmap [Kar91d], Xcmap and Xtmap [Kar93]) and for Actel-style arrays (Amap [Kar91a]). Both Amap and Xmap preserve testability. 35 5. <p> In Chapter 6 we present several variable ordering heuristics for finding variable orders that result in small canonical forms. 4.3 Mapping ITEM currently supports mapping to complex gates and field-programmable gate arrays [Kar91d, Kar91a]. Field-programmable gate array mappers have been developed for Xilinx-style arrays (Xmap <ref> [Kar91d] </ref>, Xcmap and Xtmap [Kar93]) and for Actel-style arrays (Amap [Kar91a]). Both Amap and Xmap preserve testability. 35 5. Rectangle Replacement This chapter describes the use of rectangle replacement for multi-level logic minimization on functions represented as if-then-else dags.
Reference: [Kar93] <author> Kevin Karplus. Xtmap: </author> <title> a generate-and-test mapper for table-lookup gate arrays. </title> <booktitle> In Compcon 1993, </booktitle> <pages> pages 391-399, </pages> <month> 22-26 Feb </month> <year> 1993. </year>
Reference-contexts: The thesis addresses two major areas in logic minimization: extraction of common sub-expressions and conversion to canonical form under different variable orders. Techniques are demonstrated using the logic synthesis tool item, where item stands for If-Then-Else Minimizer. Although this thesis concentrates on higher-level technology-independent optimizations, published papers <ref> [Kar91d, Kar91a, Kar93] </ref> show that the if-then-else dag representation style indeed is efficient when targeting various FPGA style logic components. <p> In Chapter 6 we present several variable ordering heuristics for finding variable orders that result in small canonical forms. 4.3 Mapping ITEM currently supports mapping to complex gates and field-programmable gate arrays [Kar91d, Kar91a]. Field-programmable gate array mappers have been developed for Xilinx-style arrays (Xmap [Kar91d], Xcmap and Xtmap <ref> [Kar93] </ref>) and for Actel-style arrays (Amap [Kar91a]). Both Amap and Xmap preserve testability. 35 5. Rectangle Replacement This chapter describes the use of rectangle replacement for multi-level logic minimization on functions represented as if-then-else dags.
Reference: [Keu87] <author> Kurt Keutzer. DAGON: </author> <title> Technology binding and local optmization by DAG matching. </title> <booktitle> In ACM IEEE 24 th Design Automation Conference Proceedings, </booktitle> <pages> pages 341-347, </pages> <address> Miami Beach, FL, </address> <month> 28 June-1 July </month> <year> 1987. </year>
Reference-contexts: Logic synthesis can be compared to language compilers; the first part, logic minimization, consists of technology-independent optimizations, which corresponds to language-independent optimizations and technology mapping corresponds to code generation and peephole optimizations. K. Keutzer <ref> [Keu87] </ref> related the problem of technology mapping to that of code generation in language compilers. From a set of decomposed functions (the result of logic minimization) a circuit graph (known as the subject graph) in a simple base technology is constructed. <p> From a set of decomposed functions (the result of logic minimization) a circuit graph (known as the subject graph) in a simple base technology is constructed. The base technology should be as simple as possible to keep the number of different nodes low. In <ref> [Keu87] </ref> the base technology is two-input NAND-gates and inverters, while in work done by Karplus the if-then-else operator has been used as the base technology [Kar89]. The logic function for each library gate is also represented as a graph (known as the pattern graph) in the base technology.
Reference: [Law64] <author> Eugene L. Lawler. </author> <title> An approach to multilevel Boolean minimization. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 11(3) </volume> <pages> 283-295, </pages> <month> July </month> <year> 1964. </year>
Reference-contexts: The literature has reported several attempts to minimize factored forms, see [BHS90] for a list of references, but unlike sum-of-products form it is hard to determine if a given factored form is optimal. Lawler <ref> [Law64] </ref> presented an algorithm for obtaining optimal factored forms, but the approach is only feasible for low-complexity functions of few inputs [Wan89]. 2.3 Binary decision diagrams Binary decision diagrams offer an alternative way of representing and manipulating Boolean expressions [Bry86].
Reference: [Lis88] <author> Robert Lisanke. </author> <title> Logic synthesis and optimization benchmarks. </title> <type> Technical report, </type> <institution> Microelectronics Center of North Carolina, </institution> <address> P.O. Box 12889, Research Triangle Park, NC 27709, </address> <month> 16 December </month> <year> 1988. </year>
Reference-contexts: The mean reduction in column count was 36%, which shows that the matrices are generally sparse. 49 5.4 Results In this section we show the results of using two-column rectangle replacement on a set of examples from the 1989 International Workshop on Logic Synthesis <ref> [Lis88] </ref>. In Table 5.2 we present the results of applying two-column rectangle replacement to examples optimized by LocalFactor in item (refer to Section 4.2.1). The columns headed with count reports the count of the optimized if-then-else dag. <p> passed as an argument to the ordering heuristic, we are not limited to only these four variations of the reconvergent ordering heuristics. 6.3.4 Results In this section we present results of applying the depth-first ordering heuristics to examples from the benchmark set for the 1989 International Workshop on Logic Synthesis <ref> [Lis88] </ref>. We provide results both for canonical if-then-else dags and ordered binary decision diagrams. For all examples, our primary goal is to compute a single variable order that works well for all the primary outputs of the network. <p> This illustrates that generally no single traversal-based heuristic is particular efficient, and trying combinations of several will almost always improve the results [BRKM91]. In Table 6.3 and Table 6.4 we compare the depth-first ordering heuristics on examples from the ISCAS benchmarks for testing <ref> [Lis88] </ref>. The results here are much more mixed and for several of the examples we ran out of memory (entries marked with oom) when converting to canonical form. <p> It is still an open problem to improve the given that operator so that it will propagate simplifications more efficiently. 6.4.5 Results The result of applying the SplitOrder heuristic to examples from the benchmark set for the 1989 International WorkShop on Logic Synthesis <ref> [Lis88] </ref> are summarized in Table 6.8. The examples used in this table are the same as those used in Table 6.1 and Table 6.2. <p> Applying SplitOrder to larger examples In Table 6.3 and 6.4 we showed results of applying the depth-first ordering heuristics to examples from the ISCAS benchmark set for testing <ref> [Lis88] </ref>. <p> This was not the case with the depth-first ordering heuristics (see Table 6.3 and 6.4). Iterating SplitOrder We finally show the results of iterating SplitOrder on examples from the ISCAS bench mark set <ref> [Lis88] </ref>.
Reference: [MBSS91] <author> Patrick C. McGeer, Robert K. Brayton, Alberto Sangiovanni-Vincentelli, and Sartaj K. Sahni. </author> <title> Performance enhancement through the generalized bypass transform. </title> <booktitle> In IEEE International Conference on Computer-Aided Design ICCAD-91, </booktitle> <pages> pages 184-187, </pages> <address> Santa Clara, CA, </address> <month> 11-14 November </month> <year> 1991. </year>
Reference-contexts: Optimizing for area is usually at the cost of increased delay and more difficult routing. Testability can be hard to preserve when certain powerful transformations, such as the generalized bypass transform by McGeer <ref> [MBSS91] </ref>, are used. 3.1 Factoring Factoring is the process of transforming a Boolean expression to a factored form, see Section 2.2.
Reference: [MF89] <author> Y. Matsunaga and Masahiro Fujita. </author> <title> Multi-level logic optimization using binary decision diagrams. </title> <booktitle> In IEEE International Conference on Computer-Aided Design ICCAD-89, </booktitle> <pages> pages 556-559, </pages> <address> Santa Clara, CA, </address> <month> November </month> <year> 1989. </year>
Reference-contexts: + z 0 ) + (x + x 0 )(y + y 0 )z 0 + xyz Due to the large number of minterms (up to 2 n 1) the sum-of-products canonical form quickly becomes impractical, and more recently researchers have adapted the binary decision diagram representation for verification purposes <ref> [MWBS88, MF89] </ref>. Binary decision diagrams and if-then-else dags have very convenient canonical forms. Bryant formulated a canonical form for binary decision diagrams [Bry86].
Reference: [MKR92] <author> M. Ray Mercer, Rohit Kapur, and Don E. Ross. </author> <title> Functional approaches to generating orderings for efficient symbolic representations. </title> <booktitle> In ACM IEEE 29 th Design Automation Conference Proceedings, </booktitle> <pages> pages 624-627, </pages> <address> Anaheim, California, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Primary inputs are assigned weights based on their observability and sorted in decreasing order of their weights. * Simulated annealing techniques <ref> [MKR92] </ref>. Here a heuristically selected order is used initially, and in one annealing step a variable is moved to a randomly chosen position at most 5 from its position in the current order. <p> Here a heuristically selected order is used initially, and in one annealing step a variable is moved to a randomly chosen position at most 5 from its position in the current order. Each time a variable is moved, an ordered partial decision diagram OPDD <ref> [Ros90, MKR92] </ref> is constructed to evaluate the cost of the new order. An OPDD is a sample of the obdd for the same order. A limit is placed on the largest number of nodes allowed in the obdd, and if the limit is exceeded, some nodes become undefined. <p> Iterating SplitOrder We finally show the results of iterating SplitOrder on examples from the ISCAS bench mark set [Lis88]. Table 6.12 contains the results for the examples for which we could find previous results in the literature <ref> [MWBS88, FFM93, MKR92] </ref>. 95 Problem Outputs obdd ItemCan C432 all 1570:35 1307:35 C880 all 9021:42 7188:37 C1908 75 (866) 10356:30 9876:30 C3540 all 61054:37 58659:37 Table 6.11: Result of SplitOrder on examples from the ISCAS benchmark set. <p> C499 and C1355 we were unable to iterate SplitOrder on all the outputs at once, thus making it impossible to optimize for total size in the most logical way. 97 Problem Method Total Largest output Best previous largest output C432 all;obdd 1570 454 all;obdd 1326 388 all;obdd 1288 370 369 <ref> [MKR92] </ref> C499 all;obdd 42162 2088 OD0 (242);obdd 41074 2055 OD0 (242);obdd 40794 2047 4283 [MKR92] C880 all;obdd 9021 3057 all;obdd 5709 2172 all;obdd 5537 1969 all;obdd 4829 1853 1248 [MKR92] C1355 1324GAT (583);obdd 77746 3330 1324GAT (583);obdd 37706 2063 all;obdd 35842 1991 all;obdd 35298 1959 4283 [MKR92] C1908 75 (866);obdd 10356 <p> once, thus making it impossible to optimize for total size in the most logical way. 97 Problem Method Total Largest output Best previous largest output C432 all;obdd 1570 454 all;obdd 1326 388 all;obdd 1288 370 369 <ref> [MKR92] </ref> C499 all;obdd 42162 2088 OD0 (242);obdd 41074 2055 OD0 (242);obdd 40794 2047 4283 [MKR92] C880 all;obdd 9021 3057 all;obdd 5709 2172 all;obdd 5537 1969 all;obdd 4829 1853 1248 [MKR92] C1355 1324GAT (583);obdd 77746 3330 1324GAT (583);obdd 37706 2063 all;obdd 35842 1991 all;obdd 35298 1959 4283 [MKR92] C1908 75 (866);obdd 10356 1357 75 (866);obdd 9541 1264 1606 [MKR92] 75 (866);obdd 9515 1265 all;obdd 8863 1408 <p> 97 Problem Method Total Largest output Best previous largest output C432 all;obdd 1570 454 all;obdd 1326 388 all;obdd 1288 370 369 <ref> [MKR92] </ref> C499 all;obdd 42162 2088 OD0 (242);obdd 41074 2055 OD0 (242);obdd 40794 2047 4283 [MKR92] C880 all;obdd 9021 3057 all;obdd 5709 2172 all;obdd 5537 1969 all;obdd 4829 1853 1248 [MKR92] C1355 1324GAT (583);obdd 77746 3330 1324GAT (583);obdd 37706 2063 all;obdd 35842 1991 all;obdd 35298 1959 4283 [MKR92] C1908 75 (866);obdd 10356 1357 75 (866);obdd 9541 1264 1606 [MKR92] 75 (866);obdd 9515 1265 all;obdd 8863 1408 all;obdd 8805 1403 C2670 311 (1278);obdd 54895 30560 14763 [FFM93] C3540 405 (1717);obdd 61054 21791 <p> all;obdd 1288 370 369 <ref> [MKR92] </ref> C499 all;obdd 42162 2088 OD0 (242);obdd 41074 2055 OD0 (242);obdd 40794 2047 4283 [MKR92] C880 all;obdd 9021 3057 all;obdd 5709 2172 all;obdd 5537 1969 all;obdd 4829 1853 1248 [MKR92] C1355 1324GAT (583);obdd 77746 3330 1324GAT (583);obdd 37706 2063 all;obdd 35842 1991 all;obdd 35298 1959 4283 [MKR92] C1908 75 (866);obdd 10356 1357 75 (866);obdd 9541 1264 1606 [MKR92] 75 (866);obdd 9515 1265 all;obdd 8863 1408 all;obdd 8805 1403 C2670 311 (1278);obdd 54895 30560 14763 [FFM93] C3540 405 (1717);obdd 61054 21791 405 (1717);obdd 43163 11269 405 (1717);obdd 36155 10334 all;obdd 42436 12462 all;obdd 36274 10305 17747 [MKR92] C5315 <p> 41074 2055 OD0 (242);obdd 40794 2047 4283 <ref> [MKR92] </ref> C880 all;obdd 9021 3057 all;obdd 5709 2172 all;obdd 5537 1969 all;obdd 4829 1853 1248 [MKR92] C1355 1324GAT (583);obdd 77746 3330 1324GAT (583);obdd 37706 2063 all;obdd 35842 1991 all;obdd 35298 1959 4283 [MKR92] C1908 75 (866);obdd 10356 1357 75 (866);obdd 9541 1264 1606 [MKR92] 75 (866);obdd 9515 1265 all;obdd 8863 1408 all;obdd 8805 1403 C2670 311 (1278);obdd 54895 30560 14763 [FFM93] C3540 405 (1717);obdd 61054 21791 405 (1717);obdd 43163 11269 405 (1717);obdd 36155 10334 all;obdd 42436 12462 all;obdd 36274 10305 17747 [MKR92] C5315 all;obdd 3327 780 all;obdd 2381 492 all;obdd 2289 472 1296 [MKR92] <p> 4283 <ref> [MKR92] </ref> C1908 75 (866);obdd 10356 1357 75 (866);obdd 9541 1264 1606 [MKR92] 75 (866);obdd 9515 1265 all;obdd 8863 1408 all;obdd 8805 1403 C2670 311 (1278);obdd 54895 30560 14763 [FFM93] C3540 405 (1717);obdd 61054 21791 405 (1717);obdd 43163 11269 405 (1717);obdd 36155 10334 all;obdd 42436 12462 all;obdd 36274 10305 17747 [MKR92] C5315 all;obdd 3327 780 all;obdd 2381 492 all;obdd 2289 472 1296 [MKR92] all;obdd 2320 472 Table 6.12: Result of iterating SplitOrder. <p> <ref> [MKR92] </ref> 75 (866);obdd 9515 1265 all;obdd 8863 1408 all;obdd 8805 1403 C2670 311 (1278);obdd 54895 30560 14763 [FFM93] C3540 405 (1717);obdd 61054 21791 405 (1717);obdd 43163 11269 405 (1717);obdd 36155 10334 all;obdd 42436 12462 all;obdd 36274 10305 17747 [MKR92] C5315 all;obdd 3327 780 all;obdd 2381 492 all;obdd 2289 472 1296 [MKR92] all;obdd 2320 472 Table 6.12: Result of iterating SplitOrder. The second column is the method used to obtain the order, all refers to using SplitOrder on all the outputs at once, obdd is converting all the outputs to obdd using the computed order.
Reference: [MWBS88] <author> Sharad Malik, Albert R. Wang, Robert K. Brayton, and Alberto Sangiovanni-Vincentelli. </author> <title> Logic verification using binary decision diagrams in a logic synthesis environment. </title> <booktitle> In IEEE International Conference on Computer-Aided Design ICCAD-88, </booktitle> <pages> pages 6-9, </pages> <address> Santa Clara, CA, </address> <month> 7-10 November </month> <year> 1988. </year>
Reference-contexts: They have recently become very popular for verification purposes <ref> [Bry86, Bry85, MWBS88] </ref>, and attempts to use them for logic minimization has also been reported [FFK88]. A binary decision diagram is a directed acyclic graph that use a single universal operator: the if-then-else operator. <p> + z 0 ) + (x + x 0 )(y + y 0 )z 0 + xyz Due to the large number of minterms (up to 2 n 1) the sum-of-products canonical form quickly becomes impractical, and more recently researchers have adapted the binary decision diagram representation for verification purposes <ref> [MWBS88, MF89] </ref>. Binary decision diagrams and if-then-else dags have very convenient canonical forms. Bryant formulated a canonical form for binary decision diagrams [Bry86]. <p> In Section 6.3 we present a depth-first ordering algorithm, which generalizes the depth-first ordering heuristics of Fujita [FFK88], Malik <ref> [MWBS88] </ref>, Karplus [Kar90] and the new reconvergent ordering heuristics introduced in Section 6.3.3. <p> Hence the space complexity gets out of hand fairly quickly. Several researchers have presented heuristics for finding variable orders that result in small obdds <ref> [FFK88, MWBS88, BRKM91, FFM93] </ref>. Here the starting point is a Boolean network, which is traversed once in a depth- or breadth-first manner to determine a total order of the variables, which is then used for building the ordered binary decision diagram. <p> Most previous work in finding a good order for the variables in ordered binary decision diagrams and if-then-else dags has used a Boolean network as starting point. In work done by Malik <ref> [MWBS88] </ref> the initial dag is a Boolean network, where nodes are in sum-of-products form. Our heuristics could be equally well applied to Boolean networks using almost any representation for the logic|we chose if-then-else dags because we had significant investment in code for manipulating them. <p> The second step in our approach to variable ordering, that of constructing a variable order, can be implemented as shown in Figure 6.3. We refer to the algorithm in Figure 6.3 as our general depth-first ordering algorithm, as it generalizes the depth-first ordering heuristics of Fujita [FFK88], Malik <ref> [MWBS88] </ref>, Karplus [Kar90], and the other heuristics presented here. The algorithm traverses each subdag (children) of a node (node) in an order determined by the routine Sort, which returns a sorted list of the subdags of node. <p> Fanout heuristic, where the subdags are sorted in order of decreasing fanout. This heuristic corresponds to the one described by Fujita et al. [FFK88]. Height heuristic, where the subdags are sorted in order of decreasing height. This heuristic corresponds to a heuristic described by Malik et al. <ref> [MWBS88] </ref>. Count heuristic, where the subdags are sorted in order of decreasing count. Count is our technology-independent area estimate, corresponding roughly to (number of outputs) + (number of literals in factored form) - (number of gates) [Kar89]. <p> We have implemented a fanout heuristic similar to the heuristic used by Fujita et al. [FFK88], except that the starting point is an if-then-else dag. It makes a depth-first traversal of the dag traversing the subdags of a node in order of decreasing fanout. Height heuristic Malik et al. <ref> [MWBS88] </ref> used a strategy similar to Fujita, but they argued that the inputs of a node should be traversed in order of decreasing transitive fanin dag height. <p> Iterating SplitOrder We finally show the results of iterating SplitOrder on examples from the ISCAS bench mark set [Lis88]. Table 6.12 contains the results for the examples for which we could find previous results in the literature <ref> [MWBS88, FFM93, MKR92] </ref>. 95 Problem Outputs obdd ItemCan C432 all 1570:35 1307:35 C880 all 9021:42 7188:37 C1908 75 (866) 10356:30 9876:30 C3540 all 61054:37 58659:37 Table 6.11: Result of SplitOrder on examples from the ISCAS benchmark set.
Reference: [NB86] <author> Ravi Nair and Daniel Brand. </author> <title> Construction of optimal DCVS trees. </title> <type> Technical Report RC 11863, </type> <institution> IBM Thomas J. Watson Research Center, </institution> <address> Yorktown Heights, NY, </address> <month> 19 March </month> <year> 1986. </year>
Reference-contexts: If we are using conversion to canonical form as a transformation for reducing size, it is important that we find the order that results in the smallest canonical dag. An optimum order could be found by considering all permutations of the variables, and Nair & Brand <ref> [NB86] </ref> present an O (n!2 n ) algorithm that does this for binary decision diagrams. <p> Finding an optimal order is only feasible for functions of up to 10 variables, and so we must resort to heuristics for finding a good order. Nair & Brand <ref> [NB86] </ref> presented some heuristics based on their optimal algorithm, but even then the complexity was exponential in the number of variables.
Reference: [Ros90] <author> Don E. Ross. </author> <title> Functional calculations using ordered partial multi decision diagrams. </title> <type> PhD thesis, </type> <institution> The University of Texas at Austin, Austin, Texas, </institution> <month> August </month> <year> 1990. </year> <month> 109 </month>
Reference-contexts: Here a heuristically selected order is used initially, and in one annealing step a variable is moved to a randomly chosen position at most 5 from its position in the current order. Each time a variable is moved, an ordered partial decision diagram OPDD <ref> [Ros90, MKR92] </ref> is constructed to evaluate the cost of the new order. An OPDD is a sample of the obdd for the same order. A limit is placed on the largest number of nodes allowed in the obdd, and if the limit is exceeded, some nodes become undefined.
Reference: [Rud89] <author> Richard L. Rudell. </author> <title> Logic Synthesis for VLSI Design. </title> <type> PhD thesis, </type> <institution> Department of Electrical and Computer Science, University of California at Berkeley, Berkeley, </institution> <address> CA, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: The height of a PLA is determined by the number of products, and the width is determined by the number of inputs and outputs. The area of two-level logic minimization is mature and near-minimum PLA realizations can almost always be found <ref> [BHMS84, Rud89] </ref>. Unfortunately, there are many designs for which a two-level representation is inappropriate. Not only can the number of products be exponential in the number of inputs, but a two-level representation of a design may also be considerably slower than a representation using multiple levels of logic. <p> However, it has proven to be useful and successful in a rule-based logic synthesis system and it is also quite popular as the fine-grain network for technology mapping <ref> [Rud89] </ref>. 2.6 Representing Boolean networks One of the tasks of logic minimization is to find common subexpressions in a network of Boolean functions constituting the entire block of logic we are optimizing.
Reference: [Rud93] <author> Richard Rudell. </author> <title> Dynamic variable ordering for ordered binary decision diagrams. </title> <booktitle> In International Workshop on Logic Synthesis, </booktitle> <address> Lake Tahoe, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: A limit is placed on the largest number of nodes allowed in the obdd, and if the limit is exceeded, some nodes become undefined. An OPDD tends to represent the top portion of the obdd containing the shortest paths to true and false. * Sifting heuristic <ref> [Rud93] </ref>. This heuristic is a dynamic ordering technique which is applied during the construction of an obdd. When a certain limit on the number of nodes in the obdd is reached, the variables are sorted according to their number of occurrences in the obdd.
Reference: [SK91] <author> Stren Ste and Kevin Karplus. </author> <title> Logic minimization using two-column rectangle replacement. </title> <booktitle> In ACM IEEE 28 th Design Automation Conference Proceedings, </booktitle> <address> San Francisco, CA, </address> <month> 17-21 June </month> <year> 1991. </year>
Reference-contexts: However, there is no guarantee that identical expressions will be recognized and transformed to a common form, and thus item also incorporates some global techniques <ref> [SK91, SK93] </ref>. Extracting common sub-expressions in a set of Boolean functions is important for minimizing the area occupied by the logic equations. In thesis a new algorithm two-column rectangle replacement for factoring and extracting common sub-expressions in Boolean functions is presented. <p> The heuristics of the replacement strategy can be tuned to maximize sharing (minimizing circuit area) or to balance operator trees (minimizing delay) <ref> [SK91] </ref>. Two-column rectangle replacement preserves path-delay-fault testability [Kar91b]. Two-column rectangle replacement does not rely on variable order. Chapter 5 presents the two-column rectangle replacement we have developed. 4.2.3 Conversion to canonical form Conversion to canonical form has several advantages.
Reference: [SK93] <author> Stren Ste and Kevin Karplus. </author> <title> Ordering heuristics for ordered binary decision diagrams and canonical if-then-else dags. </title> <booktitle> In International Workshop on Logic Synthesis, </booktitle> <address> Lake Tahoe, CA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: However, there is no guarantee that identical expressions will be recognized and transformed to a common form, and thus item also incorporates some global techniques <ref> [SK91, SK93] </ref>. Extracting common sub-expressions in a set of Boolean functions is important for minimizing the area occupied by the logic equations. In thesis a new algorithm two-column rectangle replacement for factoring and extracting common sub-expressions in Boolean functions is presented. <p> This class of heuristics was introduced in <ref> [SK93] </ref>. In the reconvergent ordering heuristics the subdag orders are not made disjoint before merging, and therefore MergeOrders must resolve inconsistencies. In Figure 6.4 we show how we resolve inconsistencies when merging three intersecting orders (the merging can be generalized to n orders).
Reference: [SU70] <author> Ravi Sethi and J. D. Ullman. </author> <title> The generation of optimal code for arithmetic expressions. </title> <journal> Journals of the ACM, </journal> <volume> 17(4) </volume> <pages> 715-728, </pages> <year> 1970. </year>
Reference-contexts: The use of count to sort the subdags is inspired by Berman's paper of relating ordering heuristics to register allocation [Ber91]. Berman states that Malik's height heuristic is an approximation to the optimal register allocation technique as described in <ref> [SU70] </ref>. By choosing the highest subdag first Malik et al. has achieved a rough estimate of the number of registers required to evaluate the logic.
Reference: [Wan89] <author> Albert Ren Rui Wang. </author> <title> Algorithms for Multilevel Logic Optimization. </title> <type> PhD thesis, </type> <institution> Department of Electrical and Computer Science, University of California at Berkeley, Berkeley, </institution> <address> CA, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: Lawler [Law64] presented an algorithm for obtaining optimal factored forms, but the approach is only feasible for low-complexity functions of few inputs <ref> [Wan89] </ref>. 2.3 Binary decision diagrams Binary decision diagrams offer an alternative way of representing and manipulating Boolean expressions [Bry86]. They have recently become very popular for verification purposes [Bry86, Bry85, MWBS88], and attempts to use them for logic minimization has also been reported [FFK88]. <p> The original 37 idea behind DMIG is due to Wang <ref> [Wan89] </ref>, who proposed a timing-driven decomposition algorithm for timing optimization. Section 5.4 presents some results of minimizing multi-level logic benchmarks using two-column rectangle replacement. Motivation The original motivation behind two-column rectangle replacement was the need for a global optimization technique that would merge logically equivalent if-then-else dags.
References-found: 46

