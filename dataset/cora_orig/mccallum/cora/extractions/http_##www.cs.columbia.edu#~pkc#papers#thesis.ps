URL: http://www.cs.columbia.edu/~pkc/papers/thesis.ps
Refering-URL: http://www.cs.columbia.edu/~pkc/
Root-URL: http://www.cs.columbia.edu
Title: An Extensible Meta-Learning Approach for Scalable and Accurate Inductive Learning  
Author: Philip Kin-Wah Chan 
Degree: Submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy in the Graduate School of Arts and Sciences.  
Date: 1996  
Affiliation: Columbia University  
Abstract-found: 0
Intro-found: 1
Reference: <author> Abramson, N. </author> <year> (1963). </year> <title> Information Theory and Coding. </title> <address> New York, NY: </address> <publisher> McGraw-Hill. </publisher>
Reference-contexts: They chose error ratio because they believe that "it becomes increasingly difficult to obtain reductions in error as the error of the single model approaches zero." 8.2.2 Diversity In information theory <ref> (Abramson, 1963) </ref>, given the probabilities of different events, entropy measures the average amount of information required to represent each event. For digital communication channels, amount of information is measured in bits. Entropy can also measure how random the different events can occur.
Reference: <author> Adleman, L. </author> <year> (1994). </year> <title> Molecular computation of solutions to combinatorial problems. </title> <journal> Science, </journal> <volume> 266, </volume> <pages> 1021-1024. </pages>
Reference: <author> Aha, D. & Kibler, D. </author> <year> (1989). </year> <title> Noise-tolerant instance-based learning algorithms. </title> <booktitle> Proc. </booktitle> <pages> IJCAI-89 (pp. 794-799). </pages>
Reference-contexts: For those incremental algorithms that do not require all examples to be resident in memory, like neural nets, many demand multiple passes over the data to achieve convergence, which usually consumes substantial processing time. Incremental IBL <ref> (Aha & Kibler, 1989) </ref> makes only one pass over the data and stores only a subset of the training examples; however, it does not bound the number of examples retained during training. 2.4 Our Approach Again, our approach for improving efficiency and accuracy for learning algorithms focuses on data reduction and
Reference: <author> Aha, D., Kibler, D., & Albert, M. </author> <year> (1991). </year> <title> Instance-based learning algorithms. </title> <journal> Machine learning, </journal> <volume> 6, </volume> <pages> 37-66. </pages>
Reference: <author> Ali, K. & Pazzani, M. </author> <year> (1996). </year> <title> Error reduction through learning multiple descriptions. </title> <journal> Machine Learning. </journal> <note> to appear. </note>
Reference-contexts: A value close to one indicates the errors made by the base classifiers are not likely to be independent. improvement when correlated error increases. Our findings here are consistent with those from <ref> (Ali & Pazzani, 1996) </ref>. Hansen and Salamon (1990) proved that for a neural-network ensemble, if the networks produce independent errors and have accuracy of at least 50%, the expected ensemble error rate goes to zero as the number of networks approaches infinity.
Reference: <author> Arnold, K. & Gosling, J. </author> <year> (1996). </year> <title> The Java Programming Language. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Studies in a heterogeneous computing environment would introduce interesting load balancing issues that are not addressed in our current study in a homogeneous computing environment. Learning algorithms and meta-learning techniques can be encapsulated in agents that can be sent across information networks. Using the new network-based architecture-independent language Java <ref> (Arnold & Gosling, 1996) </ref>, learning and meta-learning agents can roam around the internet with ease. Databases on the network can be reached by these agents and the learned classifiers can then be encapsulated in agents to perform further analyses.
Reference: <author> Booker, L., Goldberg, D., & Holland, J. </author> <year> (1989). </year> <title> Classifier systems and genetic algorithms. </title> <journal> Artificial Intelligence, </journal> <volume> 40, </volume> <pages> 235-282. </pages>
Reference: <author> Boose, J. </author> <year> (1986). </year> <title> Expertise Transfer for Expert System Design. </title> <address> Amsterdam, Netherlands: </address> <publisher> Elsevier. </publisher>
Reference-contexts: Inductive learning in this context can be viewed as automated knowledge acquisition for building knowledge-based systems. Much as knowledge engineering via human is the bottleneck in knowledge acquisition <ref> (Boose, 1986) </ref>, inefficient machine learning is the bottleneck in automated knowledge acquisition. 4 Machine learning can be a continual process, as in people, for revising outdated theories in knowledge-based systems (Ourston & Mooney, 1990; Towell & Shavlik, 1993; Brunk & Pazzani, 1995).
Reference: <author> Boswell, R. </author> <year> (1990). </year> <note> Manual for CN2 version 6.1. Turing Institure. Int. Doc. IND: TI/MLT/4.0T/RAB/1.2. 196 Bratko, </note> <author> I. & Muggleton, S. </author> <year> (1995). </year> <title> Applications of inductive logic programming. </title> <journal> Commmunications of the ACM, </journal> <volume> 38(11), </volume> <pages> 65-70. </pages>
Reference-contexts: We obtained ID3 (Quinlan, 1986) and CART (Breiman et al., 1984) as part of the IND package (Buntine & Caruana, 1991) from NASA Ames Research Center; both algorithms compute decision trees. CN2 (Clark & Niblett, 1989) is a rule learning algorithm and was obtained from Dr. Clark <ref> (Boswell, 1990) </ref>. WPEBLS is the weighted version of PEBLS (Cost & Salzberg, 1993), which is a nearest-neighbor 45 learning algorithm. BAYES is a naive Bayesian learning algorithm that is based on computing conditional probabilities as described in (Clark & Niblett, 1989).
Reference: <author> Breiman, L. </author> <year> (1994). </year> <title> Bagging Predictors. </title> <type> (Technical Report 421), </type> <institution> Berkeley, CA: Dept. of Statistics, Univ. of California. </institution>
Reference: <author> Breiman, L. </author> <year> (1996a). </year> <title> Bias, variance, and arcing classifiers. </title> <type> (technical report, </type> <institution> Berkeley, CA: Statistics Dept., U. of California. </institution>
Reference: <author> Breiman, L. </author> <year> (1996b). </year> <title> Stacked regressions. </title> <journal> Machine Learning, </journal> <volume> 24, </volume> <pages> 41-48. </pages>
Reference: <author> Breiman, L., Friedman, J. H., Olshen, R. A., & Stone, C. J. </author> <year> (1984). </year> <title> Classification and Regression Trees. </title> <address> Belmont, CA: </address> <publisher> Wadsworth. </publisher>
Reference-contexts: For example, decision trees are declarative and thus more comprehensible to humans than weights computed within a neural network architecture. However, both are capable of classifying data in meaningful ways. Decision trees are used in ID3 (Quinlan, 1986) and CART <ref> (Breiman et al., 1984) </ref>, where each concept is represented as a conjunction of terms on a path from the root of a tree to a leaf. <p> Implementations of these algorithms are "off-the-shelf" and were not modified. The variety of algorithms provide some generality for our empirical results. We obtained ID3 (Quinlan, 1986) and CART <ref> (Breiman et al., 1984) </ref> as part of the IND package (Buntine & Caruana, 1991) from NASA Ames Research Center; both algorithms compute decision trees. CN2 (Clark & Niblett, 1989) is a rule learning algorithm and was obtained from Dr. Clark (Boswell, 1990). <p> Stated another way, if we cannot display useful and interesting results of meta-learning on these small test cases, larger-scale studies are probably not warranted. 4.3 Experimental Methodology One of the more common techniques used in evaluating the accuracy of a learning program is cross validation <ref> (Breiman et al., 1984) </ref>. In an n-fold cross validation, the entire data set is divided into n disjoint subsets and n train-and-test runs are performed. In each run, two disjoint sets are formed: a training set and a test set.
Reference: <author> Brodley, C. </author> <year> (1995). </year> <title> Recursive automatic bias selection for classifier construction. </title> <journal> Machine Learning, </journal> <volume> 20, </volume> <pages> 63-94. </pages>
Reference: <author> Brodley, C. & Lane, T. </author> <year> (1996). </year> <title> Creating and exploiting coverage and diversity. Work. </title> <booktitle> Notes AAAI-96 Workshop Integrating Multiple Learned Models (pp. </booktitle> <pages> 8-14). </pages>
Reference-contexts: Although not explicitly stated, Krogh and Vedelsby's (1995) decomposition of squared classification error follows the same spirit of bias-variance decomposition and their ambiguity metric measures variance. Our diversity metric tries to approximate the variance characteristics as well. 8.2.3 Coverage Coverage <ref> (Brodley & Lane, 1996) </ref> measures the fraction of instances for which at least one of the base classifiers produces the correct predictions. That is, an instance is not covered if and only if all the base classifiers generate an incorrect prediction for that instance.
Reference: <author> Brunk, C. & Pazzani, M. </author> <year> (1995). </year> <title> A lexically based semantic bias for theory revision. </title> <booktitle> Proc. 12th Intl. Conf. Mach. </booktitle> <pages> Learning (pp. 81-89). </pages>
Reference: <author> Buntine, W. & Caruana, R. </author> <year> (1991). </year> <title> Introduction to IND and Recursive Partitioning. </title> <institution> NASA Ames Research Center. </institution>
Reference-contexts: Implementations of these algorithms are "off-the-shelf" and were not modified. The variety of algorithms provide some generality for our empirical results. We obtained ID3 (Quinlan, 1986) and CART (Breiman et al., 1984) as part of the IND package <ref> (Buntine & Caruana, 1991) </ref> from NASA Ames Research Center; both algorithms compute decision trees. CN2 (Clark & Niblett, 1989) is a rule learning algorithm and was obtained from Dr. Clark (Boswell, 1990). WPEBLS is the weighted version of PEBLS (Cost & Salzberg, 1993), which is a nearest-neighbor 45 learning algorithm.
Reference: <author> Carbonell, J. </author> <year> (1989). </year> <title> Introduction: Paradigms for machine learning. </title> <journal> Artificial Intelligence, </journal> <volume> 40, </volume> <pages> 1-9. </pages>
Reference-contexts: Introduction The key to intelligence is the ability to learn. Research in the field of machine learning <ref> (Carbonell, 1989) </ref> attempts to endow computers with this intrinsic capability that exists in all higher-order organisms to one degree or another. Learning can be loosely defined as a process that improves performance of an agent by acquiring knowledge through interactions with a changing environment.
Reference: <author> Catlett, J. </author> <year> (1991). </year> <title> Megainduction: A test flight. </title> <booktitle> Proc. Eighth Intl. Work. Machine Learning (pp. </booktitle> <pages> 596-599). </pages>
Reference-contexts: Otherwise, using a massive database would imply that 51 we have unbounded resources and time in order to compute baseline statistics. As we have noted (as well as <ref> (Catlett, 1991) </ref>) this might take many years of computing. Furthermore, scaling studies are possible on these smaller sets simply by varying the number and size of the subsets formed in the initial data reduction schemes and extrapolating.
Reference: <author> Catlett, J. </author> <year> (1992). </year> <title> Peepholing: Choosing attributes efficiently for megainduction. </title> <booktitle> Proc. Ninth Intl. Conf. Machine Learning (pp. </booktitle> <pages> 49-54). </pages> <note> 197 Chan, </note> <author> P. </author> <year> (1988). </year> <title> A critical review of CN2: A polythetic classifier system. </title> <type> (Technical Report CS-88-09 (Master's paper)), </type> <institution> Nashville, TN: Department of Computer Science, Vanderbilt University. </institution>
Reference-contexts: That is, n 1 splits are considered for n values. Catlett devised a scheme to skip some of the splits that are considered statistically not likely to be picked <ref> (Catlett, 1992) </ref>. This scheme applies only to real-numbered attributes and the processing time can still be prohibitive due to ID3's non-linear complexity (Chan & Stolfo, 1993d).
Reference: <author> Chan, P. </author> <year> (1991). </year> <title> Machine Learning in Molecular Biology Sequence Analysis. </title> <type> (Technical Report CUCS-041-91), </type> <address> New York, NY: </address> <institution> Department of Computer Science, Columbia University. </institution>
Reference: <author> Chan, P. & Stolfo, S. </author> <year> (1993a). </year> <title> Experiments on multistrategy learning by meta-learning. </title> <booktitle> Proc. Second Intl. Conf. Information and Knowledge Management (pp. </booktitle> <pages> 314-323). </pages>
Reference-contexts: Lastly, in Section 10.3, we compare our combiner strategy with the related stack generalization proposed by Wolpert (1992). The com 159 parison is based on whole (unpartitioned) data sets. 10.1 Multistrategy Meta-learning on Unpartitioned Data Here we investigate multistrategy meta-learning on whole (unpartitioned) data sets <ref> (Chan & Stolfo, 1993a) </ref>. Each of the base learners is provided with the entire training set of raw data. That is, a different learning algorithm is applied to the entire data set to generate the base classifiers and then learn a meta-classifier to integrate the base ones.
Reference: <author> Chan, P. & Stolfo, S. </author> <year> (1993b). </year> <title> Meta-learning for multistrategy and parallel learning. </title> <booktitle> Proc. Second Intl. Work. Multistrategy Learning (pp. </booktitle> <pages> 150-165). </pages>
Reference-contexts: Meta-learning <ref> (Chan & Stolfo, 1993b) </ref> is proposed as one such approach. This approach encompasses the use of learning algorithms to learn how to integrate results from multiple learning systems. <p> After evaluating two reviews for each submission, we accepted 24 papers for presentation. About 80 researchers and developers expressed interest in attending the two-day workshop; around 50 of them came and participated. 26 Chapter 3 Meta-Learning Meta-learning <ref> (Chan & Stolfo, 1993b) </ref> is loosely defined as learning of meta-knowledge about learned knowledge. In our work we concentrate on learning from the output of concept learning systems. In this case meta-learning means learning from the predictions of these classifiers on common training data.
Reference: <author> Chan, P. & Stolfo, S. </author> <year> (1993c). </year> <title> Toward multistrategy parallel and distributed learning in sequence analysis. </title> <booktitle> Proc. First Intl. Conf. Intelligent Systems for Molecular Biology (pp. </booktitle> <pages> 65-73). </pages>
Reference-contexts: Our empirical results indeed show that BAYES is a more effective meta-learner. 10.2 Multistrategy Meta-learning on Partitioned Data Here we use meta-learning to combine different learners to improve prediction accuracy and speed <ref> (Chan & Stolfo, 1993c) </ref>. The dual objectives are to improve accuracy using multiple algorithms and to speed up the learning process by parallel and distributed processing in a divide-and-conquer fashion.
Reference: <author> Chan, P. & Stolfo, S. </author> <year> (1993d). </year> <title> Toward parallel and distributed learning by meta-learning. </title> <note> Working Notes AAAI Work. Knowledge Discovery in Databases (pp. 227-240). </note>
Reference-contexts: The algorithms developed so far are generally not scalable to large databases as envisaged by the Genome Project. The complexity of typical machine learning algorithms renders their use infeasible in problems with massive amounts of data <ref> (Chan & Stolfo, 1993d) </ref>. <p> Catlett devised a scheme to skip some of the splits that are considered statistically not likely to be picked (Catlett, 1992). This scheme applies only to real-numbered attributes and the processing time can still be prohibitive due to ID3's non-linear complexity <ref> (Chan & Stolfo, 1993d) </ref>. Another approach to solving the scaling problem is simply to increase the number of processors and available memory, parallelize the learning algorithms and apply the parallelized algorithm to the entire data set. <p> In our earlier experiments reported in <ref> (Chan & Stolfo, 1993d) </ref>, the partitioning of data in the subsets was random and later we discovered that half of the final arbiter tree was trained on examples with only two of the three classes.
Reference: <author> Chan, P. & Stolfo, S. </author> <year> (1994). </year> <title> Toward Scalable and Parallel Learning: A Case Study in Splice Junction Prediction. </title> <type> (Technical Report CUCS-032-94), </type> <address> New York, NY: </address> <institution> Department of Computer Science, Columbia University. </institution> <note> (Presented at the ML94 Workshop on Machine Learning and Molecular Biology). </note>
Reference-contexts: Splice junctions In a set of experiments we measured the CPU training time of ID3, CART, BAYES, and WPEBLS with the number of training examples varying from 10 to 100,000 in the splice junction domain (examples were randomly selected and duplicated from the original data set, which has 3,190 examples) <ref> (Chan & Stolfo, 1994) </ref>. Thus, the training sets contain many duplicate examples. The results in CPU time on Sun IPXs are plotted in Figure 9.1. We observe that WPEBLS performed comparatively worse than the other three algorithms when more training examples were presented.
Reference: <author> Chan, P. & Stolfo, S. </author> <year> (1995a). </year> <title> A comparative evaluation of voting and meta-learning on partitioned data. </title> <booktitle> Proc. Twelfth Intl. Conf. Machine Learning (pp. </booktitle> <pages> 90-98). </pages>
Reference-contexts: All the meta-learning strategies discussed so far have only one level of meta-learning to create the integrating structures. Hence, we characterize these strategies as one-level meta-learning methods <ref> (Chan & Stolfo, 1995a) </ref>. 5.1 Issues Before we compare the other techniques in the literature with ours, several issues have to be addressed and are discussed as follows.
Reference: <author> Chan, P. & Stolfo, S. </author> <year> (1995b). </year> <title> Learning arbiter and combiner trees from partitioned data for scaling machine learning. </title> <booktitle> Proc. Intl. Conf. Knowledge Discovery and Data Mining (pp. </booktitle> <pages> 39-44). </pages> <note> 198 Chan, </note> <author> P. & Stolfo, S. </author> <year> (1996a). </year> <title> Scaling learning by meta-learning over disjoint and partially replicated data. </title> <booktitle> Proc. Ninth Florida AI Research Symposium (pp. </booktitle> <pages> 151-155). </pages>
Reference: <author> Chan, P. & Stolfo, S. </author> <year> (1996b). </year> <title> Sharing learned models among remote database partitions by local meta-learning. </title> <booktitle> Proc. Second Intl. Conf. Knowledge Discovery and Data Mining (pp. </booktitle> <pages> 2-7). </pages>
Reference-contexts: The next question is how we can merge the black boxes. In this chapter we explore the use of meta-learning in improving the accuracy performance of local learned models by merging them with ones imported from remote sites <ref> (Chan & Stolfo, 1996b) </ref>. That is, at each site, learned models from other sites are also available. Furthermore, we investigate the effects on local accuracy when the local underlying training data overlap with those at remote sites.
Reference: <author> P. Chan, S. Stolfo, & D. Wolpert (Eds.) </author> <year> (1996). </year> <title> Working Notes for the AAAI-96 Workshop on Integrating Multiple Learned Models for Improving and Scaling Machine Learning Algorithms, </title> <address> Portland, OR. </address>
Reference-contexts: Sal Stolfo, Dr. Dave Wolpert, and I organized a workshop at the Fourteen National Conference on Artificial Intelligence (AAAI-96) in Port-land, Oregon. The workshop was entitled "Integrating Multiple Learned Models for Improving and Scaling Machine Learning Algorithms" <ref> (Chan et al., 1996) </ref> and was held on August 4th and 5th. 33 paper submissions were received from around the world. Because of the unexpected relatively large number of submissions, reviewers other than the organizers were enlisted. After evaluating two reviews for each submission, we accepted 24 papers for presentation.
Reference: <author> Chesseman, P., Kelly, J., Self, M., Stutz, J., Taylor, W., & Freeman, D. </author> <year> (1988). </year> <title> Au-toclass: A bayesian classification system. </title> <booktitle> Proc. Fifth Intl. Conf. Machine Learning (pp. </booktitle> <pages> 54-64). </pages>
Reference: <author> Clark, P. & Niblett, T. </author> <year> (1989). </year> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <pages> 261-285. </pages>
Reference-contexts: Decision trees are used in ID3 (Quinlan, 1986) and CART (Breiman et al., 1984), where each concept is represented as a conjunction of terms on a path from the root of a tree to a leaf. Rules in AQ (Michalski et al., 1986), Decision Lists (Rivest, 17 1987), CN2 <ref> (Clark & Niblett, 1989) </ref>, and ITRULE (Goodman & Smyth, 1989) are if-then expressions, where the antecedent is a pattern expression and the consequent is a class label. <p> The variety of algorithms provide some generality for our empirical results. We obtained ID3 (Quinlan, 1986) and CART (Breiman et al., 1984) as part of the IND package (Buntine & Caruana, 1991) from NASA Ames Research Center; both algorithms compute decision trees. CN2 <ref> (Clark & Niblett, 1989) </ref> is a rule learning algorithm and was obtained from Dr. Clark (Boswell, 1990). WPEBLS is the weighted version of PEBLS (Cost & Salzberg, 1993), which is a nearest-neighbor 45 learning algorithm. <p> Clark (Boswell, 1990). WPEBLS is the weighted version of PEBLS (Cost & Salzberg, 1993), which is a nearest-neighbor 45 learning algorithm. BAYES is a naive Bayesian learning algorithm that is based on computing conditional probabilities as described in <ref> (Clark & Niblett, 1989) </ref>. The last two algorithms were reimplemented in C++. 4.2 Learning Tasks Various machine learning techniques have been applied to different molecular biology sequence analysis tasks (Chan, 1991; Craven & Shavlik, 1994). <p> The total time complexity for CART is therefore O ((av + an)2 a ) in the worst case. BAYES <ref> (Clark & Niblett, 1989) </ref> calculates the conditional probabilities for each attribute value given a class and the probabilities for each class. O (av) conditional probabilities are calculated and each takes O (n) time, hence O (avn) time is needed. 134 The class probabilities can be calculated in O (n) time.
Reference: <author> Clearwater, S. & Provost, F. </author> <year> (1990). </year> <title> RL4: A tool for knowledge-based induction. </title> <booktitle> Proc. Second Intl. IEEE Conf. Tools for AI (pp. </booktitle> <pages> 24-30). </pages> <publisher> IEEE CS Press. </publisher>
Reference-contexts: Other researchers use a more coarse-grain parallel/distributed approach. Classifiers are trained from data subsets and are combined via some mechanism. Provost et al. (Provost & Aronis, 1996; Provost & Hennessy, 1996) exchange and evaluate rules 24 to provably and optimally combine rule sets learned by RL <ref> (Clearwater & Provost, 1990) </ref>. Our meta-learning approach is similar, however, it is not restricted to a particular learning algorithm. 2.3 Incremental Learning Incremental learning algorithms have been proposed that allow the flexibility of not requiring all training examples to be inspected at once.
Reference: <author> Cost, S. & Salzberg, S. </author> <year> (1993). </year> <title> A weighted nearest neighbor algorithm for learning with symbolic features. </title> <journal> Machine Learning, </journal> <volume> 10, </volume> <pages> 57-78. </pages>
Reference-contexts: CN2 (Clark & Niblett, 1989) is a rule learning algorithm and was obtained from Dr. Clark (Boswell, 1990). WPEBLS is the weighted version of PEBLS <ref> (Cost & Salzberg, 1993) </ref>, which is a nearest-neighbor 45 learning algorithm. BAYES is a naive Bayesian learning algorithm that is based on computing conditional probabilities as described in (Clark & Niblett, 1989). <p> O (av) conditional probabilities are calculated and each takes O (n) time, hence O (avn) time is needed. 134 The class probabilities can be calculated in O (n) time. Therefore, the time complexity of BAYES is O (avn + n) or O (avn). WPEBLS <ref> (Cost & Salzberg, 1993) </ref> calculates a set of value distance matrices (VDMs) and a vector of weights for the exemplars. Each attribute has a VDM of size v by v, which takes O (nv 2 ) to calculate.
Reference: <author> Craven, M. & Shavlik, J. </author> <year> (1993). </year> <title> Learning to represent codons: A challenge problem for constructive induction. </title> <booktitle> Proc. </booktitle> <pages> IJCAI-93 (pp. 1319-1324). </pages>
Reference: <author> Craven, M. & Shavlik, J. </author> <year> (1994). </year> <title> Machine learning approaches to gene recognition. </title> <journal> IEEE Expert, </journal> <volume> 9(2), </volume> <pages> 2-10. </pages>
Reference: <author> Danyluk, A. </author> <year> (1991). </year> <title> Gemini: An integration of analytical and empirical learning. </title> <booktitle> Proc. First Intl. Work. Multistrategy Learning (pp. </booktitle> <pages> 191-206). </pages>
Reference: <author> DeJong, K. </author> <year> (1988). </year> <title> Learning with genetic algorithms: An overview. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <pages> 121-138. </pages> <address> 199 DeLisi, C. </address> <year> (1988). </year> <title> The human genome project. </title> <journal> American Scientist, </journal> <volume> 76, </volume> <pages> 488-493. </pages>
Reference: <author> Dietterich, T. & Bakiri, G. </author> <year> (1991). </year> <title> Error-correcting output codes: A general method for improving multiclass inductive learning programs. </title> <booktitle> Proc. </booktitle> <pages> AAAI-91 (pp. 572-577). </pages> <publisher> AAAI Press. </publisher>
Reference: <author> Dietterich, T. & Bakiri, G. </author> <year> (1995). </year> <title> Solving multiclass learning problems via error-correcting output codes. </title> <journal> J. AI Research, </journal> <volume> 2, </volume> <pages> 263-286. </pages>
Reference-contexts: However, work on bridging theory and practice is emerging|Dietterich et al (1996) applied the weak learning framework, introduced by Schapire (1990), to understand C4.5 (Quinlan, 1993). Moreover, recent statistical work on bias-variation decomposition, for example <ref> (Kong & Dietterich, 1995) </ref>, provides some insights on the source of errors for integrating 193 multiple learned models. Similar approaches can help explain the behavior of our meta-learning strategies. For meta-learning on partitioned data, most of the results were obtained from using only a single learning algorithm.
Reference: <author> Dietterich, T., Kearns, M., & Mansour, Y. </author> <year> (1996). </year> <title> Applying the weak learning framework to understand and improve C4.5. </title> <booktitle> Proc. Thirteenth Intl. Conf. Machine Learning (pp. </booktitle> <pages> 96-104). </pages>
Reference: <author> Dietterich, T. & Michalski, R. </author> <year> (1983). </year> <title> A comparative review of selected methods for learning from examples. </title> <editor> In R. Michalski, J. Carbonell, & T. Mitchell (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <pages> (pp. 331-363). </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In supervised inductive learning, the class labels of training examples are supplied and the learned concepts describe these class labels (or learning from examples <ref> (Dietterich & Michalski, 1983) </ref>). However, in unsupervised inductive learning (or learning from observations (Michalski & Stepp, 1983)), the class labels are not supplied or known. The learning algorithm induces clusters, which can later be identified as individual concepts.
Reference: <author> Domingos, P. </author> <year> (1995). </year> <title> Rule induction and instance-based learning: A unified approach. </title> <booktitle> Proc. </booktitle> <pages> IJCAI-95 (pp. 1226-1232). </pages>
Reference-contexts: Using data reduction techniques, Domingos (1996) significantly improves the efficiency of RISE (a specific-to-general rule induction algorithm) <ref> (Domingos, 1995) </ref>. Catlett (1991) proposes some improvements to the ID3 algorithm particularly for handling attributes with real numbers.
Reference: <author> Domingos, P. </author> <year> (1996). </year> <title> Using partitioning to speed up specific-to-general rule induction. Work. </title> <booktitle> Notes AAAI-96 Workshop Integrating Multiple Learned Models (pp. </booktitle> <pages> 29-34). </pages>
Reference: <author> Drucker, H., Schapire, R., & Simard, P. </author> <year> (1993). </year> <title> Boosting performance in neural networks. </title> <booktitle> Intl. J. Pat. Recog. Art. Intel., </booktitle> <volume> 7, </volume> <pages> 705-719. </pages>
Reference-contexts: In fact, he shows that arbitrarily high accuracy can be achieved by recursively applying the same procedure. Although his approach is limited to the PAC model of learning, some success was achieved in the domain of character recognition, using neural networks <ref> (Drucker et al., 1993) </ref>. Freund (1992) has a similar approach, but with potentially many more sequentially generated distributions involved. 19 Hansen and Salamon (1990) integrate an ensemble of neural networks by simple voting. The different networks in an ensemble are generated by randomized parameters.
Reference: <author> Duda, R. & Hart, P. </author> <year> (1973). </year> <title> Pattern classification and scene analysis. </title> <address> New York, NY: </address> <publisher> Wiley. </publisher>
Reference: <author> Fahlman, S. & Hinton, G. </author> <year> (1987). </year> <title> Connectionist architectures for artificial intelligence. </title> <journal> Computer, </journal> <volume> 20, </volume> <pages> 100-109. </pages> <note> 200 Fan, </note> <author> D., Chan, P., & Stolfo, S. </author> <year> (1996). </year> <title> A comparative evaluation of combiner and stacked generalization. </title> <booktitle> Working Notes AAAI-96 Work. Integrating Multiple Learned Models (pp. </booktitle> <pages> 40-46). </pages>
Reference: <author> Fayyad, U., Weir, N., & Djorgovski, S. </author> <year> (1993). </year> <title> SKICAT: A machine learning system for automated cataloging of large scale sky surveys. </title> <booktitle> Proc. Tenth Intl. Conf. Machine Learning (pp. </booktitle> <pages> 112-119). </pages>
Reference: <author> Fisher, D. </author> <year> (1987). </year> <title> Knowledge acquisition via incremental conceptual clustering. </title> <journal> Machine Learning, </journal> <volume> 2, </volume> <pages> 139-172. </pages>
Reference-contexts: However, in unsupervised inductive learning (or learning from observations (Michalski & Stepp, 1983)), the class labels are not supplied or known. The learning algorithm induces clusters, which can later be identified as individual concepts. CLUSTER/2 (Michalski & Stepp, 1983), COBWEB <ref> (Fisher, 1987) </ref>, and AUTOCLASS (Chesse 16 man et al., 1988) are such conceptual clustering algorithms. Our work focuses on supervised inductive learning. Inductive learning can be performed in two modes: non-incremental or incremental.
Reference: <author> Flann, N. & Dietterich, T. </author> <year> (1989). </year> <title> A study of explanation-based mehtods for inductive learning. </title> <journal> Machine Learning, </journal> <volume> 4, </volume> <pages> 187-266. </pages>
Reference: <author> Freund, Y. </author> <year> (1992). </year> <title> An improved boosting algorithm and its implications on learning complexity. </title> <booktitle> Proc. 5th Work. Comp. Learning Theory (pp. </booktitle> <pages> 391-398). </pages>
Reference: <author> Geist, A., Beguelin, A., Dongarra, J., Jiang, W., Manchek, R., & Sunderam, V. </author> <year> (1993). </year> <title> PVM 3 user's guide and reference manual. </title> <type> (Technical Report ORNL/TM-12187), </type> <institution> Oak Ridge, TN: Oak Ridge National Laboratory. </institution>
Reference-contexts: Next, we discuss our parallel implementation and empirical experiments on very large data sets. 9.2.5 Parallel implementation The hierarchical meta-learning strategies were implemented on a parallel and distributed platform based on the message-passing model. To satisfy our goal of portability, we chose PVM (Parallel Virtual Machine) <ref> (Geist et al., 1993) </ref> to provide message 150 8 leaf nodes. passing support|PVM supports a common interface for message passing among machines of diverse architectures.
Reference: <author> Goodman, R. & Smyth, P. </author> <year> (1989). </year> <title> The induction of probabilisitc rule sets-the itrule algorithm. </title> <booktitle> Proc. Sixth Intl. Work. Machine Learning (pp. </booktitle> <pages> 129-132). </pages>
Reference-contexts: Rules in AQ (Michalski et al., 1986), Decision Lists (Rivest, 17 1987), CN2 (Clark & Niblett, 1989), and ITRULE <ref> (Goodman & Smyth, 1989) </ref> are if-then expressions, where the antecedent is a pattern expression and the consequent is a class label.
Reference: <author> Grammes, C. </author> <year> (1993). </year> <note> Gnufit v1.2. (Available at ftp://ftp.dartmouth.edu/pub/gnuplot/gnufit12.tar.gz). </note>
Reference-contexts: When a general trend is observed, a line is fitted to the 16 data points using the Marquardt-Levenberg algorithm (Ralston & Rabinowitz, 1978; Press et al., 1988), a nonlinear least squares curve fitting mechanism, available in the GNUFIT <ref> (Grammes, 1993) </ref> package. Before we discuss the different metrics used in this study. We first inspect how the average accuracy of base classifiers (fi) affects the overall accuracy (ff). Their relationship is plotted in Figure 8.1. <p> The curve approximations were computed using GNUFIT <ref> (Grammes, 1993) </ref> with the Marquardt-Levenberg algorithm (Ralston & Rabinowitz, 1978; Press et al., 1988), a nonlinear least squares fit mechanism. To approximate the training speed with polynomial equations, we inspect how closely the three polynomials fit the data points.
Reference: <author> Gustafson, J. </author> <year> (1988). </year> <title> Reevaluating Amdahl's law. </title> <journal> Comm. ACM, </journal> <volume> 31(5), </volume> <pages> 532-533. </pages>
Reference: <author> Hansen, L. & Salamon, P. </author> <year> (1990). </year> <title> Neural network ensembles. </title> <journal> IEEE Trans. Pattern Analysis and Mach. Itell., </journal> <volume> 12, </volume> <pages> 993-1001. </pages>
Reference: <author> Hernandez, M. & Stolfo, S. </author> <year> (1995). </year> <title> The merge/purge problem for large databases. </title> <booktitle> Proc. </booktitle> <pages> SIGMOD-95 (pp. 127-138). </pages>
Reference-contexts: The problem of logically forming the universal relation in preparation for a data mining process is itself a difficult problem studied by a large research community (e.g. <ref> (Hernandez & Stolfo, 1995) </ref>). For this study, we make the simplifying assumption that the universal relation is available over a distributed set of processing sites.
Reference: <author> Hinton, G. </author> <year> (1989). </year> <title> Connectionist learning procedures. </title> <journal> Artificial Intelligence, </journal> <volume> 40, </volume> <pages> 185-234. </pages> <note> 201 Holder, </note> <author> L. </author> <year> (1991). </year> <title> Selection of learning methods using an adaptive model of knowledge utility. </title> <booktitle> Proc. First Intl. Work. Multistrategy Learning (pp. </booktitle> <pages> 247-254). </pages>
Reference: <author> Hunter, L. </author> <year> (1993). </year> <title> Molecular biology for computer scientists. </title> <editor> In L. Hunter (Ed.), </editor> <booktitle> Aritficial Intelligence and Molecular Biology, chapter 1, </booktitle> <pages> (pp. 1-46). </pages> <publisher> AAAI Press. </publisher>
Reference: <author> Kohavi, R. & John, G. </author> <year> (1995). </year> <title> Automatic parameter selection by minimizing estimated error. </title> <booktitle> Proc. 12th Intl. Conf. Mach. Learn. </booktitle> <pages> (pp. 304-312). </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Kohavi, R. & Wolpert, D. </author> <year> (1996). </year> <title> Bias plus variacne decomposition for zero-one loss functions. </title> <booktitle> Proc. Thirteenth Intl. Conf. Machine Learning (pp. </booktitle> <pages> 275-283). </pages>
Reference: <author> Kong, E. B. & Dietterich, T. </author> <year> (1995). </year> <title> Error-correcting output coding corrects bias and variance. </title> <booktitle> Proc. Twelfth Intl. Conf. Machine Learning (pp. </booktitle> <pages> 313-321). </pages>
Reference-contexts: However, work on bridging theory and practice is emerging|Dietterich et al (1996) applied the weak learning framework, introduced by Schapire (1990), to understand C4.5 (Quinlan, 1993). Moreover, recent statistical work on bias-variation decomposition, for example <ref> (Kong & Dietterich, 1995) </ref>, provides some insights on the source of errors for integrating 193 multiple learned models. Similar approaches can help explain the behavior of our meta-learning strategies. For meta-learning on partitioned data, most of the results were obtained from using only a single learning algorithm.
Reference: <author> Krogh, A. & Vedelsby, J. </author> <year> (1995). </year> <title> Neural network ensembles, cross validation, and active learning. </title> <editor> In G. Tesauro, D. Touretzky, & T. Leen (Eds.), </editor> <booktitle> Advances in Neural Info. Proc. Sys. </booktitle> <pages> 7 (pp. 231-238). </pages> <publisher> MIT Press. </publisher>
Reference: <author> Kumar, V., Grama, A., Gupta, A., & Karypis, G. </author> <year> (1994). </year> <title> Introduction to parallel computing: Design and analysis of algorithms. </title> <address> Redwood City, CA: Benjamin-Cummings. </address>
Reference-contexts: approach in a parallel and distributed environment, our notations and definitions are described as follows: * T S = serial execution time. * T P = parallel execution time. * p = number of processors. * n = input size (number of training examples). * W = problem size (work) <ref> (Kumar et al., 1994) </ref>, which measures the total number of computational units needed for serial execution. That is, T S = W fi t u , where t u is the time spent for a unit of computation. Hence, T S / W . <p> Scaled speedup = T S (W fi p) ; (9.1) where T S and T P are expressed as functions of problem size. Parallel system with linear or near-linear scaled speedup (with respect to p, the number of processors) is considered scalable. Other scalability metrics can be found in <ref> (Kumar & Gupta, 1994) </ref>. 143 * Efficiency is how fast an algorithm runs, which is characterized by the algorithm's time complexity. (We note that the term efficiency can be used another way in parallel computing|it measures how well a parallel algorithm utilizes the available processors and is defined as the ratio
Reference: <author> Kumar, V. & Gupta, A. </author> <year> (1994). </year> <title> Analyzing scalability of parallel algorithms and architectures. </title> <journal> J. Parallel & Distributed Computing, </journal> <volume> 22, </volume> <pages> 379-391. </pages>
Reference-contexts: approach in a parallel and distributed environment, our notations and definitions are described as follows: * T S = serial execution time. * T P = parallel execution time. * p = number of processors. * n = input size (number of training examples). * W = problem size (work) <ref> (Kumar et al., 1994) </ref>, which measures the total number of computational units needed for serial execution. That is, T S = W fi t u , where t u is the time spent for a unit of computation. Hence, T S / W . <p> Scaled speedup = T S (W fi p) ; (9.1) where T S and T P are expressed as functions of problem size. Parallel system with linear or near-linear scaled speedup (with respect to p, the number of processors) is considered scalable. Other scalability metrics can be found in <ref> (Kumar & Gupta, 1994) </ref>. 143 * Efficiency is how fast an algorithm runs, which is characterized by the algorithm's time complexity. (We note that the term efficiency can be used another way in parallel computing|it measures how well a parallel algorithm utilizes the available processors and is defined as the ratio
Reference: <author> Kwok, S. & Carter, C. </author> <year> (1990). </year> <title> Multiple decision trees. </title> <booktitle> Uncertainty in Aritificial Intelligence 4 (pp. </booktitle> <pages> 327-335). </pages>
Reference: <author> Langley, P., Iba, W., & Thompson, K. </author> <year> (1992). </year> <title> An analysis of bayesian classifiers. </title> <booktitle> Proc. </booktitle> <pages> AAAI-92 (pp. 223-228). </pages>
Reference: <author> Langley, P. & Sage, S. </author> <year> (1994). </year> <title> Induction of selective bayesian classifiers. </title> <booktitle> Proc. Tenth Conf. Uncertainty in AI (pp. </booktitle> <pages> 399-406). </pages>
Reference: <author> Langley, P. & Simon, H. </author> <year> (1995). </year> <title> Applications of machine learning and rule induction. </title> <journal> Communications of the ACM, </journal> <volume> 38(11), </volume> <pages> 54-64. </pages> <note> 202 Lewin, </note> <author> B. </author> <year> (1987). </year> <title> Genes. </title> <address> New York, NY: </address> <publisher> John Wiley & Son. </publisher>
Reference: <author> Lippmann, R. </author> <year> (1987). </year> <title> An introduction to computing with neural nets. </title> <journal> IEEE ASSP Magazine, </journal> <volume> 5(2), </volume> <pages> 4-22. </pages>
Reference: <author> Lipton, R. </author> <year> (1995). </year> <title> Using DNA to solve NP-complete problems. </title> <journal> Science, </journal> <volume> 268, </volume> <pages> 542-545. </pages>
Reference: <author> Littlestone, N. & Warmuth, M. </author> <year> (1989). </year> <title> The weighted majority algorithm. </title> <type> (Technical Report UCSC-CRL-89-16), </type> <institution> Santa Cruz, CA: Computer Research Lab., Univ. of California. </institution>
Reference-contexts: Common voting and statistical techniques are evaluated. Techniques described in Section 2.1.2 that are included in this study are: * Voting * Weighted Voting * Weighted Majority (WM) <ref> (Littlestone & Warmuth, 1989) </ref> * Weighted Majority-Limit (WML) (Littlestone & Warmuth, 1989) * Weighted Majority-Random (WMR) (Littlestone & Warmuth, 1989) 56 * Bayesian Belief (Xu et al., 1992) These familiar techniques are empirically compared to our proposed meta-learning techniques (arbiter, class-combiner, and class-attribute-combiner) described in Chapter 3. <p> Common voting and statistical techniques are evaluated. Techniques described in Section 2.1.2 that are included in this study are: * Voting * Weighted Voting * Weighted Majority (WM) <ref> (Littlestone & Warmuth, 1989) </ref> * Weighted Majority-Limit (WML) (Littlestone & Warmuth, 1989) * Weighted Majority-Random (WMR) (Littlestone & Warmuth, 1989) 56 * Bayesian Belief (Xu et al., 1992) These familiar techniques are empirically compared to our proposed meta-learning techniques (arbiter, class-combiner, and class-attribute-combiner) described in Chapter 3. <p> Common voting and statistical techniques are evaluated. Techniques described in Section 2.1.2 that are included in this study are: * Voting * Weighted Voting * Weighted Majority (WM) <ref> (Littlestone & Warmuth, 1989) </ref> * Weighted Majority-Limit (WML) (Littlestone & Warmuth, 1989) * Weighted Majority-Random (WMR) (Littlestone & Warmuth, 1989) 56 * Bayesian Belief (Xu et al., 1992) These familiar techniques are empirically compared to our proposed meta-learning techniques (arbiter, class-combiner, and class-attribute-combiner) described in Chapter 3. All the meta-learning strategies discussed so far have only one level of meta-learning to create the integrating structures.
Reference: <author> Matheus, C., Chan, P., & Piatesky-Shapiro, G. </author> <year> (1993). </year> <title> Systems for knowledge discovery in databases. </title> <journal> IEEE Trans. Knowledge and Data Engineering, </journal> <volume> 5(6), </volume> <pages> 903-913. </pages>
Reference: <author> Matheus, C. J. & Rendell, L. A. </author> <year> (1989). </year> <title> Constructive induction on decision trees. </title> <booktitle> Proc. of IJCAI-89 (pp. </booktitle> <pages> 645-650). </pages>
Reference: <author> Merz, C. & Murphy, P. </author> <year> (1996). </year> <note> UCI repository of machine learning databases [http://www.ics.uci.edu/~mlearn/mlrepository.html]. Dept. </note> <institution> of Info. and Computer Sci., Univ. of California, </institution> <address> Irvine, CA. </address>
Reference-contexts: For examples, Table 2.1 displays a tiny fraction of the congressional voting record 15 Party Mx-missile Edu-spending Crime REP n y y DEM n n y Table 2.1: A data set on congressional voting record. data set obtained from the Machine Learning Database at the University of California, Irvine <ref> (Merz & Murphy, 1996) </ref>. The data set records how lawmakers vote in the House on different legislative issues. One might want to determine if a lawmaker is a republican or a democrat by observing how he/she votes. <p> For our study, we chose three sequence analysis tasks obtained from the Machine Learning Database Repository at University of California, Irvine <ref> (Merz & Murphy, 1996) </ref>. Moreover, we also used an artificial data set that can be generated at random. 4.2.1 Molecular biology sequence analysis data Molecular biologists in genetics have been focusing on analyzing sequences obtained from proteins, DNA (DeoxyriboNucleic Acid), and RNA (RiboNucleic Acid).
Reference: <author> Michalski, R. </author> <year> (1983). </year> <title> A theory and methodology of inductive learning. </title> <editor> In R. Michal-ski, J. Carbonell, & T. Mitchell (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <pages> (pp. 83-134). </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Learning can be loosely defined as a process that improves performance of an agent by acquiring knowledge through interactions with a changing environment. In this thesis research we concentrate on a particular type of learning called inductive learning <ref> (Michalski, 1983) </ref>. Given some examples (data) obtained from the environment, inductive learning aims to discover patterns in the examples and form concepts that describe the examples. <p> In Chapter 10 we explore the integration of classifiers generated by different learning algorithms. 13 We conclude, in Chapter 11, by discussing the contributions and research direc tions of this work. 14 Chapter 2 Inductive Learning and Related Work Inductive learning <ref> (Michalski, 1983) </ref> is the task of identifying regularities in some given set of training examples with little or no knowledge about the domain from which the examples are drawn. <p> In supervised inductive learning, the class labels of training examples are supplied and the learned concepts describe these class labels (or learning from examples <ref> (Dietterich & Michalski, 1983) </ref>). However, in unsupervised inductive learning (or learning from observations (Michalski & Stepp, 1983)), the class labels are not supplied or known. The learning algorithm induces clusters, which can later be identified as individual concepts. <p> In supervised inductive learning, the class labels of training examples are supplied and the learned concepts describe these class labels (or learning from examples (Dietterich & Michalski, 1983)). However, in unsupervised inductive learning (or learning from observations <ref> (Michalski & Stepp, 1983) </ref>), the class labels are not supplied or known. The learning algorithm induces clusters, which can later be identified as individual concepts. CLUSTER/2 (Michalski & Stepp, 1983), COBWEB (Fisher, 1987), and AUTOCLASS (Chesse 16 man et al., 1988) are such conceptual clustering algorithms. <p> However, in unsupervised inductive learning (or learning from observations <ref> (Michalski & Stepp, 1983) </ref>), the class labels are not supplied or known. The learning algorithm induces clusters, which can later be identified as individual concepts. CLUSTER/2 (Michalski & Stepp, 1983), COBWEB (Fisher, 1987), and AUTOCLASS (Chesse 16 man et al., 1988) are such conceptual clustering algorithms. Our work focuses on supervised inductive learning. Inductive learning can be performed in two modes: non-incremental or incremental.
Reference: <author> Michalski, R. & Stepp, R. </author> <year> (1983). </year> <title> Learning from observation: Conceptual clustering. </title> <editor> In R. Michalski, J. Carbonell, & T. Mitchell (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <pages> (pp. 331-363). </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Learning can be loosely defined as a process that improves performance of an agent by acquiring knowledge through interactions with a changing environment. In this thesis research we concentrate on a particular type of learning called inductive learning <ref> (Michalski, 1983) </ref>. Given some examples (data) obtained from the environment, inductive learning aims to discover patterns in the examples and form concepts that describe the examples. <p> In Chapter 10 we explore the integration of classifiers generated by different learning algorithms. 13 We conclude, in Chapter 11, by discussing the contributions and research direc tions of this work. 14 Chapter 2 Inductive Learning and Related Work Inductive learning <ref> (Michalski, 1983) </ref> is the task of identifying regularities in some given set of training examples with little or no knowledge about the domain from which the examples are drawn. <p> In supervised inductive learning, the class labels of training examples are supplied and the learned concepts describe these class labels (or learning from examples <ref> (Dietterich & Michalski, 1983) </ref>). However, in unsupervised inductive learning (or learning from observations (Michalski & Stepp, 1983)), the class labels are not supplied or known. The learning algorithm induces clusters, which can later be identified as individual concepts. <p> In supervised inductive learning, the class labels of training examples are supplied and the learned concepts describe these class labels (or learning from examples (Dietterich & Michalski, 1983)). However, in unsupervised inductive learning (or learning from observations <ref> (Michalski & Stepp, 1983) </ref>), the class labels are not supplied or known. The learning algorithm induces clusters, which can later be identified as individual concepts. CLUSTER/2 (Michalski & Stepp, 1983), COBWEB (Fisher, 1987), and AUTOCLASS (Chesse 16 man et al., 1988) are such conceptual clustering algorithms. <p> However, in unsupervised inductive learning (or learning from observations <ref> (Michalski & Stepp, 1983) </ref>), the class labels are not supplied or known. The learning algorithm induces clusters, which can later be identified as individual concepts. CLUSTER/2 (Michalski & Stepp, 1983), COBWEB (Fisher, 1987), and AUTOCLASS (Chesse 16 man et al., 1988) are such conceptual clustering algorithms. Our work focuses on supervised inductive learning. Inductive learning can be performed in two modes: non-incremental or incremental.
Reference: <author> Michalski, R. S., Mozetic, I., Hong, J., & Lavrac, N. </author> <year> (1986). </year> <title> The multipurpose incremental leaning system AQ51 and its testing application to three medical domains. </title> <booktitle> Proc. </booktitle> <pages> AAAI-86 (pp. 1041-1045). </pages> <note> 203 Mitchell, </note> <author> T. </author> <year> (1980). </year> <title> The Need for Biases in Learning Generalizaions. </title> <type> (Technical Report CBM-TR-117): </type> <institution> Dept. Comp. Sci., Rutgers Univ. </institution>
Reference-contexts: However, both are capable of classifying data in meaningful ways. Decision trees are used in ID3 (Quinlan, 1986) and CART (Breiman et al., 1984), where each concept is represented as a conjunction of terms on a path from the root of a tree to a leaf. Rules in AQ <ref> (Michalski et al., 1986) </ref>, Decision Lists (Rivest, 17 1987), CN2 (Clark & Niblett, 1989), and ITRULE (Goodman & Smyth, 1989) are if-then expressions, where the antecedent is a pattern expression and the consequent is a class label.
Reference: <author> Mitchell, T. </author> <year> (1982). </year> <title> Generalization as search. </title> <journal> Artificial Intelligence, </journal> <volume> 18, </volume> <pages> 203-226. </pages>
Reference-contexts: Rules in AQ (Michalski et al., 1986), Decision Lists (Rivest, 17 1987), CN2 (Clark & Niblett, 1989), and ITRULE (Goodman & Smyth, 1989) are if-then expressions, where the antecedent is a pattern expression and the consequent is a class label. Each version space learned in the Candidate Elimination algorithm <ref> (Mitchell, 1982) </ref> defines the most general and specific description boundaries of a concept using a restricted version of first order formulae. Neural networks compute a weighted network to classify data (Fahlman & Hinton, 1987; Lippmann, 1987; Hinton, 1989).
Reference: <author> Murphy, P. & Pazzani, M. </author> <year> (1991). </year> <title> ID2-of-3: constructive induction of M-of-N concepts for discriminators in decisions trees. </title> <booktitle> Proc. Eigth Intl. work. Machine Learning (pp. </booktitle> <pages> 183-187). </pages>
Reference-contexts: In this thesis the learning algorithms used for meta-learning are "off-the-shelf" algorithms and are the same as the base learning algorithms. More specialized meta-level attributes and algorithms can be devised. Learning algorithms that search M-of-N <ref> (Murphy & Pazzani, 1991) </ref> and other counting-related concepts might be useful in locating effective combining rules. Constructive induction techniques (Matheus & Rendell, 1989; Rendell, 1990) could also be beneficial in creating potentially relevant attributes.
Reference: <author> Naik, D. & Mammone, R. </author> <year> (1992). </year> <title> Meta-neural networks that learn by learning. </title> <booktitle> Proc. </booktitle> <pages> IJCNN (pp. </pages> <month> I:437-442). </month>
Reference: <author> Nakata, K., Kanchisa, M., & DeLisi, C. </author> <year> (1985). </year> <title> Prediction of splice junctions in mRNA sequences. Nucl. </title> <journal> Acids Res., </journal> <volume> 13, </volume> <pages> 5327-5340. </pages>
Reference: <author> Optiz, D. & Shavlik, J. </author> <year> (1996). </year> <title> Generating accurage and diverse members of a neural-network ensemble. </title> <editor> In D. Touretzky, M. Morzer, & M. Hasselmo (Eds.), </editor> <booktitle> Advances in Neural Info. Proc. Sys. </booktitle> <pages> 8. </pages> <note> MIT Press. to appear. </note>
Reference: <author> Ourston, D. & Mooney, R. </author> <year> (1990). </year> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <booktitle> Proc. </booktitle> <pages> AAAI-90 (pp. 815-820). </pages>
Reference: <editor> G. Piatesky-Shapiro & W. Frawley (Eds.) </editor> <year> (1991). </year> <title> Knowledge discovery in databases. </title> <address> Cambridge, MA: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Pomerleau, D. </author> <year> (1992). </year> <title> Neural network perception for mobile robot guidance. </title> <type> PhD thesis, </type> <institution> Pittsburgh, PA: School of Computer Sci., Carnegie Mellon Univ. </institution> <type> (Tech. Rep. </type> <institution> CMU-CS-92-115). </institution>
Reference: <author> Press, W., Flannery, B., Teukolsky, S., & Vetterling, W. </author> <year> (1988). </year> <title> Numerical recipies in C: </title> <booktitle> The art of scientific computing. </booktitle> <address> Cambridge, UK: </address> <publisher> Cambridge University Press. </publisher>
Reference: <author> Provost, F. & Aronis, J. </author> <year> (1996). </year> <title> Scaling up inductive learning with massive parallelism. </title> <journal> Machine Learning, </journal> <volume> 23, </volume> <pages> 33-46. </pages>
Reference: <author> Provost, F. & Hennessy, D. </author> <year> (1996). </year> <title> Scaling up: Distributed machine learning with cooperation. </title> <booktitle> Proc. AAAI-96. </booktitle> <publisher> AAAI Press. </publisher> <pages> 74-79. </pages> <note> 204 Qian, </note> <author> N. & Sejnowski, T. </author> <year> (1988). </year> <title> Predicting the secondary structure of globular proteins using neural network models. </title> <journal> J. Mol. Biol., </journal> <volume> 202, </volume> <pages> 865-884. </pages>
Reference: <author> Quinlan, J. R. </author> <year> (1979). </year> <title> Induction over large data bases. </title> <type> (Technical Report STAN-CS-79-739): </type> <institution> Comp. Sci. Dept., Stanford Univ. </institution>
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 81-106. </pages>
Reference-contexts: The complexity of typical machine learning algorithms renders their use infeasible in problems with massive amounts of data (Chan & Stolfo, 1993d). A more concrete testimony of the efficiency problem is from Catlett (1991), who projects that ID3 <ref> (Quinlan, 1986) </ref> (a popular inductive learning algorithm) on modern machines will take several months to learn from a million records in the flight data set obtained from NASA, which is clearly unacceptable. Moreover, typical learning algorithms like ID3 rely on a monolithic memory to fit all of its training data. <p> Our work focuses on supervised inductive learning. Inductive learning can be performed in two modes: non-incremental or incremental. In non-incremental learning all of the examples are presented to the learning algorithm as an aggregation (for example, ID3 <ref> (Quinlan, 1986) </ref>) . However, in incremental learning training examples are assimilated one at a time and the learning algorithms do not have control over the order of presentation (for example, ID5 (Ut-goff, 1989), an incremental version of ID3). This research concentrates on supervised inductive learning in non-incremental mode. <p> For example, decision trees are declarative and thus more comprehensible to humans than weights computed within a neural network architecture. However, both are capable of classifying data in meaningful ways. Decision trees are used in ID3 <ref> (Quinlan, 1986) </ref> and CART (Breiman et al., 1984), where each concept is represented as a conjunction of terms on a path from the root of a tree to a leaf. <p> Wirth and Catlett (1988) show that the windowing technique does not significantly improve speed on reliable data. On the contrary, for noisy data, windowing considerably slows down the computation. Catlett (1991) demonstrates that larger amounts of data improves accuracy, but he projects that ID3 <ref> (Quinlan, 1986) </ref> on modern machines will take several months to learn from a million records in the flight data set obtained from NASA. Using data reduction techniques, Domingos (1996) significantly improves the efficiency of RISE (a specific-to-general rule induction algorithm) (Domingos, 1995). <p> We first discuss the apparatus and then the methodology for our experiments. 4.1 Learning Algorithms Five inductive learning algorithms were used in our experiments. Implementations of these algorithms are "off-the-shelf" and were not modified. The variety of algorithms provide some generality for our empirical results. We obtained ID3 <ref> (Quinlan, 1986) </ref> and CART (Breiman et al., 1984) as part of the IND package (Buntine & Caruana, 1991) from NASA Ames Research Center; both algorithms compute decision trees. CN2 (Clark & Niblett, 1989) is a rule learning algorithm and was obtained from Dr. Clark (Boswell, 1990). <p> Their top-down tree building (root to leaves) approach is the same as the one used in common decision tree algorithms like ID3 <ref> (Quinlan, 1986) </ref>. Like training the tree, classification of instances using the tree is also performed in a top-down fashion. On the contrary, our arbiter and combiner trees are built bottom-up (leaves to root) and classification of instances is performed bottom-up as well. <p> Let * a = the number of attributes, * v = the largest number of distinct values for an attribute (i.e,., the size of its domain), and * n = the number of training examples. The time complexity of ID3 <ref> (Quinlan, 1986) </ref> is a function of the number of levels in the decision tree it forms. The height of the tree is bounded by the number of attributes, O (a).
Reference: <author> Quinlan, J. R. </author> <year> (1993). </year> <title> C4.5: programs for machine learning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However, work on bridging theory and practice is emerging|Dietterich et al (1996) applied the weak learning framework, introduced by Schapire (1990), to understand C4.5 <ref> (Quinlan, 1993) </ref>. Moreover, recent statistical work on bias-variation decomposition, for example (Kong & Dietterich, 1995), provides some insights on the source of errors for integrating 193 multiple learned models. Similar approaches can help explain the behavior of our meta-learning strategies.
Reference: <author> Ralston, A. & Rabinowitz, P. </author> <year> (1978). </year> <title> A first course in numerical analysis. </title> <address> New York, NY: </address> <publisher> McGraw-Hill. </publisher>
Reference: <author> Rendell, L. </author> <year> (1990). </year> <title> Feature construction for concept learning. </title> <editor> In D. P. Benjamin (Ed.), </editor> <booktitle> Change of Representation and Inductive Bias, </booktitle> <pages> (pp. 327-353). </pages> <publisher> Kluwer Academic. </publisher>
Reference: <author> Rivest, R. </author> <year> (1987). </year> <title> Learning decision lists. </title> <journal> Machine Learning, </journal> <volume> 2, </volume> <pages> 229-246. </pages>
Reference-contexts: Decision trees are used in ID3 (Quinlan, 1986) and CART (Breiman et al., 1984), where each concept is represented as a conjunction of terms on a path from the root of a tree to a leaf. Rules in AQ (Michalski et al., 1986), Decision Lists <ref> (Rivest, 17 1987) </ref>, CN2 (Clark & Niblett, 1989), and ITRULE (Goodman & Smyth, 1989) are if-then expressions, where the antecedent is a pattern expression and the consequent is a class label.
Reference: <author> Schapire, R. </author> <year> (1990). </year> <title> The strength of weak learnability. </title> <journal> Machine Learning, </journal> <volume> 5, </volume> <pages> 197-226. </pages>
Reference-contexts: Furthermore, we note that the partitioned data approach reported here is different from much of the similar work which combines multiple classifiers trained from the "entire" data set for accuracy improvement 55 (sometimes called "boosting" <ref> (Schapire, 1990) </ref>). In this chapter we study different techniques for integrating predictions generated by a set of base classifiers, each of which is computed by a learning algorithm applied to a distinct partitioned data subset. Common voting and statistical techniques are evaluated.
Reference: <author> Schleif, R. </author> <year> (1986). </year> <title> Genetics and Molecular Biology. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Selberg, E. & Etzioni, O. </author> <year> (1996). </year> <title> Multi-service search and comparison using the MetaCrawler. </title> <booktitle> Proc. Fourth Intl. World Wide Web Conf. </booktitle>
Reference: <author> Silver, B., Frawley, W., Iba, G., Vittal, J., & Bradford, K. </author> <year> (1990). </year> <title> ILS: A framework for multi-paradigmatic learning. </title> <booktitle> Proc. Seventh Intl. Conf. Machine Learning (pp. </booktitle> <pages> 348-356). </pages>
Reference: <author> Stanfill, C. & Waltz, D. </author> <year> (1986). </year> <title> Toward memory-based reasoning. </title> <journal> Comm. ACM, </journal> <volume> 29(12), </volume> <pages> 1213-1228. </pages>
Reference: <author> Stolfo, S., Galil, Z., McKeown, K., & Mills, R. </author> <year> (1989). </year> <title> Speech recognition in parallel. </title> <booktitle> Proc. Speech Nat. Lang. Work. </booktitle> <pages> (pp. 353-373). </pages> <note> 205 Sun, </note> <author> X. & Ni, L. </author> <year> (1993). </year> <title> Scalable problems and memory-bounded speedup. </title> <journal> J. Parallel & Distributed Comp., </journal> <volume> 19, </volume> <pages> 27-37. </pages>
Reference: <author> Tcheng, D., Lambert, B., Lu, C.-Y., & Rendell, L. </author> <year> (1989). </year> <title> Building robust learning systems by computing induction and optimization. </title> <booktitle> Proc. </booktitle> <pages> IJCAI-89 (pp. 806-812). </pages>
Reference: <author> Towell, G. & Shavlik, J. </author> <year> (1993). </year> <title> The extraction of refined rules from knowledge-based neural networks. </title> <journal> Machine Learning, </journal> <volume> 13, </volume> <pages> 71-101. </pages>
Reference: <author> Towell, G., Shavlik, J., & Noordewier, M. </author> <year> (1990). </year> <title> Refinement of approximate domain theories by knowledge-based neural networks. </title> <booktitle> Proc. </booktitle> <pages> AAAI-90 (pp. 861-866). </pages>
Reference: <author> Utgoff, P. </author> <year> (1989). </year> <title> Incremental induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 4, </volume> <pages> 161-186. </pages>
Reference-contexts: However, some incremental algorithms do require the storage of all examples for future examination during learning, for example, ID5 <ref> (Utgoff, 1989) </ref>. That is, these incremental learning algorithms still demand that all examples fit in the main memory, which is not plausible for massive amounts of data.
Reference: <author> Valiant, L. </author> <year> (1984). </year> <title> A theory of the learnable. </title> <journal> Comm. ACM, </journal> <volume> 27, </volume> <pages> 1134-1142. </pages>
Reference-contexts: The predictions of the three learned classifiers are combined using a simple voting rule. Schapire proves that the overall accuracy is higher than the one achieved by simply applying the learning algorithm to the initial distribution under the PAC (Probabilistic Approximately Correct) learning model <ref> (Valiant, 1984) </ref>. In fact, he shows that arbitrarily high accuracy can be achieved by recursively applying the same procedure. Although his approach is limited to the PAC model of learning, some success was achieved in the domain of character recognition, using neural networks (Drucker et al., 1993). <p> With our current analysis tools, it is not clear when a particular meta-learning strategy performs better than another. Furthermore, a theoretical foundation like the hypothesis boosting work by Schapire (1990) would be a substantial contribution. We note that theoretical learning models (PAC <ref> (Valiant, 1984) </ref> for example) represent a class of algorithms that might not be close to the actual learning algorithms used in practice. However, work on bridging theory and practice is emerging|Dietterich et al (1996) applied the weak learning framework, introduced by Schapire (1990), to understand C4.5 (Quinlan, 1993).
Reference: <author> Wah, B. </author> <year> (1993). </year> <title> High performance computing and communications for grand challenge applications: Computer vision, speech and natural language processing, </title> <journal> and artificial intelligence. IEEE Trans. Know. Data. Eng., </journal> <volume> 5(1), </volume> <pages> 138-154. </pages>
Reference-contexts: For instance, the Human Genome Project (DeLisi, 1988), initiated by the National Institutes of Health (NIH) and Department of Energy (DOE), aims to map the entire human genome and will inevitably generate orders of magnitude more sequence data than exist today. The HPCC Grand Challenges <ref> (Wah, 1993) </ref> research efforts will generate more data and faster than ever before. Also, financial institutions and market analysis firms are already dealing with overwhelming amounts of global information that in time will undoubtedly grow in size faster than improvements in machine resources.
Reference: <author> Wirth, J. & Catlett, J. </author> <year> (1988). </year> <title> Experiments on the costs and benefits of windowing in ID3. </title> <booktitle> Proc. Fifth Intl. Conf. Machine Learning (pp. </booktitle> <pages> 87-99). </pages>
Reference: <author> Wolpert, D. </author> <year> (1992). </year> <title> Stacked generalization. </title> <booktitle> Neural Networks, </booktitle> <volume> 5, </volume> <pages> 241-259. </pages>
Reference: <author> Wolpert, D. </author> <year> (1993). </year> <type> Personal communication. </type>
Reference: <author> Xu, L., Krzyzak, A., & Suen, C. </author> <year> (1992). </year> <title> Methods of combining multiple classifires and their applications to handwriting recognition. </title> <journal> IEEE Trans. Sys. Man. Cyb., </journal> <volume> 22, </volume> <pages> 418-435. </pages>
Reference-contexts: one classifier predicts y, the other does not) might have much more predictive value (eg. when combined with a third classifier) than merely knowing that the two classifiers predict y with equal probability! We view the Bayesian approach as a baseline, and use methods derived from this approach, Bayesian Belief <ref> (Xu et al., 1992) </ref>, for comparative purposes in our experiments reported later. There are many other approaches we might imagine that are based upon learning relationships between classifiers. <p> Techniques described in Section 2.1.2 that are included in this study are: * Voting * Weighted Voting * Weighted Majority (WM) (Littlestone & Warmuth, 1989) * Weighted Majority-Limit (WML) (Littlestone & Warmuth, 1989) * Weighted Majority-Random (WMR) (Littlestone & Warmuth, 1989) 56 * Bayesian Belief <ref> (Xu et al., 1992) </ref> These familiar techniques are empirically compared to our proposed meta-learning techniques (arbiter, class-combiner, and class-attribute-combiner) described in Chapter 3. All the meta-learning strategies discussed so far have only one level of meta-learning to create the integrating structures.
Reference: <author> Zhang, X., Mckenna, M., Mesirov, J., & Waltz, D. </author> <year> (1989). </year> <title> An Efficient Implementation of the Backpropagation Algorithm on the Connection Machine CM-2. </title> <type> (Technical Report RL89-1): </type> <institution> Thinking Machines Corp. </institution> <note> 206 Zhang, </note> <author> X., Mesirov, J., & Waltz, D. </author> <year> (1992). </year> <title> A hybrid system for protein secondary structure prediction. </title> <journal> J. Mol. Biol., </journal> <volume> 225, </volume> <pages> 1049-1063. </pages>
References-found: 112

