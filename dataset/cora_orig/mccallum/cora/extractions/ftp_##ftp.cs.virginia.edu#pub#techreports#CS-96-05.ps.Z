URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-96-05.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Performance Evaluation of the Late Delta Cache Coherence Protocol  
Author: Bronis R. de Supinski Craig Williams Paul F. Reynolds, Jr. 
Abstract: Computer Science Report No. CS-96-05 March 13, 1996 
Abstract-found: 1
Intro-found: 1
Reference: [AgG88] <author> Agarwal, A. and A. Gupta, </author> <title> Memory Reference Characteristics of Multiprocessor Applications under MACH, </title> <booktitle> Proceedings of the 1988 Sigmetrics Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pp. 215-225, </pages> <year> 1988. </year>
Reference-contexts: However, later studies have chosen to model shared references with temporal locality by using a least recently used stack model (LRUSM) [Spi77]. This assumption is supported by shared memory reference pattern studies <ref> [AgG88] </ref>. This model allows cache blocks which have recently been selected to be significantly more likely to be selected again, which is important if caching is going to provide much reduction in memory latency. We have modified this approach to model contention for shared variables directly.
Reference: [ASH88] <author> Agarwal, A., R. Simoni, J. Hennessy and M. Horowitz, </author> <title> An Evaluation of Directory Schemes for Cache Coherence, </title> <booktitle> Proceedings of the 15th International Symposium on Computer Architecture, </booktitle> <pages> pp. 280-289, </pages> <year> 1988. </year>
Reference-contexts: Much research has been conducted using simulations to evaluate cache coherence protocols directly. Researchers have used both synthetic workloads, generally based on the workload model developed by Archibald and Baer [ArB86], and memory traces to generate a reference stream <ref> [EgK88, BMR89, MiB92, ASH88] </ref>. Still others have simulated an entire computer system in software [CKA91] or used the execution driven approach, where actual programs are run on the host computer and memory references are trapped to a memory hierarchy simulation as necessary [DGH90, CDK94].
Reference: [ADT90] <author> Algudady, M.S., C.R. Das and M.J. Thazhuthaveetil, </author> <title> A Write Update Cache Coherence Protocol for MIN-Based Multiprocessors with Accessibility Based Split Caches, </title> <booktitle> Proceedings of Supercomputing 90, </booktitle> <pages> pp. 544-553, </pages> <year> 1990. </year> <title> Performance Evaluation of the Late Delta Cache Coherence Protocol 25 </title>
Reference-contexts: A variety of approaches have been used to evaluate cache coherence protocols. Several researchers have modeled cache coherence protocols as Markov processes [DuB82] and attempted to derive closed form solutions for these systems. Others have used mean value analysis to compare protocols <ref> [VLZ88, BLA89, YBL89, ADT90] </ref>. Generally these approaches have relied on system simulation to verify the models proposed. Much research has been conducted using simulations to evaluate cache coherence protocols directly. <p> Previous studies have assumed that cache performance for private data in multiprocessor systems is consistent with uniprocessor cache performance. Since we model separate data caches for private and shared data <ref> [ADT90] </ref>, this assumption appears particularly valid. We assume a warm start, where a start up period elapses prior to performance measurement and eliminates the effect of compulsory misses. This assumption allows the use of a constant private hit ratio during any simulation run.
Reference: [ArB86] <author> Archibald, J. and J.L. Baer, </author> <title> Cache Coherence Protocols: Evaluation Using a Multiprocessor Simulation Model, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol. 4, No. 4, </volume> <pages> pp. 273-298, </pages> <year> 1986. </year>
Reference-contexts: Generally these approaches have relied on system simulation to verify the models proposed. Much research has been conducted using simulations to evaluate cache coherence protocols directly. Researchers have used both synthetic workloads, generally based on the workload model developed by Archibald and Baer <ref> [ArB86] </ref>, and memory traces to generate a reference stream [EgK88, BMR89, MiB92, ASH88]. <p> Synthetic Workload Generation We base the synthetic workload model used by our simulation upon a significant body of research into the performance of cache coherence protocols. Archibald and Baer <ref> [ArB86] </ref> compared a wide variety of bus based cache coherence protocols using a simulation driven by a synthetic workload. Nearly all synthetic workload simulations of cache coherence [e.g. LeR90, NaB93] have been based on this research. The remainder of this subsection details the synthetic workload model we have used. <p> This assumption allows the use of a constant private hit ratio during any simulation run. Another important parameter for private cache behavior is the percentage of blocks which are dirty upon replacement <ref> [ArB86] </ref>. The private cache hit ratio is 0.95 with a probability of 0.3 that private cache victims must be written back in all of our experiments. These values are consistent with those used by Archibald and Baer [ArB86] and studies of uniprocessor cache performance. <p> private cache behavior is the percentage of blocks which are dirty upon replacement <ref> [ArB86] </ref>. The private cache hit ratio is 0.95 with a probability of 0.3 that private cache victims must be written back in all of our experiments. These values are consistent with those used by Archibald and Baer [ArB86] and studies of uniprocessor cache performance. Performance Evaluation of the Late Delta Cache Coherence Protocol 7 Since our goal is to determine the effect of shared cache activity on performance, shared cache blocks must be modeled explicitly. <p> The cleaner semantics have therefore motivated us not to modify the LRUSM stack. 3.2. Statistical Methodology Our primary performance metric is processing power <ref> [ArB86] </ref>, which is the sum of the utilization of all processors in the system. When designing a simulation for systems as complex as cache coherent multiprocessors, an important consideration is how confidence intervals will be gathered for the statistics of interest.
Reference: [BaR89] <author> Baylor, S.J. and B.D. Rathi, </author> <title> A Study of the Memory Reference Behavior of Engineering/Scientific Applications in Parallel Processors, </title> <booktitle> Proceedings of the 1989 International Conference on Parallel Processing, </booktitle> <pages> pp. </pages> <address> I-78-I-82, </address> <year> 1989. </year>
Reference-contexts: We have used a write probability of 0.3 throughout our experiments. Shared reference pattern studies indicate that the vast majority of dynamic references is to private data <ref> [DPS86, BaR89] </ref>. For this reason, we have parameterized our reference generation method to keep the percentage of references to shared addresses low, typically about 5 or 10 percent of all references. <p> Most importantly, this exercise is unnecessary for the late delta protocol. 4.3. Varying the Probability of a Shared Access Studies of reference patterns in shared memory multiprocessor indicate that the probability of any given reference being to shared data varies greatly among applications <ref> [BaR89, DPS86] </ref>. Although this probability is low for most applications, it can be as high as 0.25 or even 0.5 for some applications. Therefore, protocols which can provide consistently good performance across a range of values for this probability are desirable.
Reference: [BMR89] <author> Baylor, S.J., </author> <title> K.P. McAuliffe and B.D. Rathi, Cache Coherence Protocols for MIN-Based Multiprocessors, </title> <institution> RC15221, IBM Research Report, </institution> <year> 1989. </year>
Reference-contexts: Much research has been conducted using simulations to evaluate cache coherence protocols directly. Researchers have used both synthetic workloads, generally based on the workload model developed by Archibald and Baer [ArB86], and memory traces to generate a reference stream <ref> [EgK88, BMR89, MiB92, ASH88] </ref>. Still others have simulated an entire computer system in software [CKA91] or used the execution driven approach, where actual programs are run on the host computer and memory references are trapped to a memory hierarchy simulation as necessary [DGH90, CDK94].
Reference: [BLA89] <author> Bhuyan, L.N., B.C. Liu and I. Ahmed, </author> <title> Analysis of MIN based Multiprocessors with Private Cache Memories, </title> <booktitle> Proceedings of the 1989 International Conference on Parallel Processing, </booktitle> <pages> pp. </pages> <address> I-51-I-58, </address> <year> 1989. </year>
Reference-contexts: A variety of approaches have been used to evaluate cache coherence protocols. Several researchers have modeled cache coherence protocols as Markov processes [DuB82] and attempted to derive closed form solutions for these systems. Others have used mean value analysis to compare protocols <ref> [VLZ88, BLA89, YBL89, ADT90] </ref>. Generally these approaches have relied on system simulation to verify the models proposed. Much research has been conducted using simulations to evaluate cache coherence protocols directly.
Reference: [CeF78] <author> Censier, L.M. and P. Feautrier, </author> <title> A New Solution to Coherence Problems in Multicache Systems, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 27, </volume> <pages> pp. 1112-1118, </pages> <year> 1978. </year>
Reference-contexts: This family of protocols exploit an isotach logical time system to provide support for sequential consistency and atomicity. We have conducted a performance study comparing one of these protocols, the late delta cache coherence protocol to a conventional directory based, invalidation protocol <ref> [CeF78, CKA91] </ref>. In this study, we expected the late delta protocol to yield excellent performance for workloads with atom-icity requirements without sacrificing sequential consistency despite the higher network latencies required to maintain isotach logical time. Our results demonstrate that the late delta protocol offers significant performance benefits.
Reference: [CKA91] <author> Chaiken, D., J. Kubiatowicz and A. Agarwal, </author> <title> LimitLESS Directories: A Scalable Cache Coherence Scheme, </title> <booktitle> Proceedings of the 4th ASPLOS, </booktitle> <pages> pp. 224-234, </pages> <year> 1991. </year>
Reference-contexts: This family of protocols exploit an isotach logical time system to provide support for sequential consistency and atomicity. We have conducted a performance study comparing one of these protocols, the late delta cache coherence protocol to a conventional directory based, invalidation protocol <ref> [CeF78, CKA91] </ref>. In this study, we expected the late delta protocol to yield excellent performance for workloads with atom-icity requirements without sacrificing sequential consistency despite the higher network latencies required to maintain isotach logical time. Our results demonstrate that the late delta protocol offers significant performance benefits. <p> We expect the late delta protocol to provide excellent performance without sacrificing sequential consistency. Thus, the conventional invalidation protocol provides the most reasonable existing comparison Our conventional protocol is based on the protocol used in the Alewife machine <ref> [CKA91] </ref>. We have modified the Alewife protocol slightly to simplify its simulation. In the Alewife protocol, if an operation is received to a block for which there are unacknowledged invalidations, a busy response is returned to the requestor. <p> Researchers have used both synthetic workloads, generally based on the workload model developed by Archibald and Baer [ArB86], and memory traces to generate a reference stream [EgK88, BMR89, MiB92, ASH88]. Still others have simulated an entire computer system in software <ref> [CKA91] </ref> or used the execution driven approach, where actual programs are run on the host computer and memory references are trapped to a memory hierarchy simulation as necessary [DGH90, CDK94]. We have evaluated the late delta protocol and our synchronization coprocessor through simulation using a synthetic workload.
Reference: [CDK94] <author> Cox, A.L., S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony and W. Zwaenepoel, </author> <title> Software Versus Hardware Shared Memory Implementation: A Case Study, </title> <booktitle> Proceedings of the 21th International Symposium on Computer Architecture, </booktitle> <pages> pp. 106-117, </pages> <year> 1994. </year>
Reference-contexts: Still others have simulated an entire computer system in software [CKA91] or used the execution driven approach, where actual programs are run on the host computer and memory references are trapped to a memory hierarchy simulation as necessary <ref> [DGH90, CDK94] </ref>. We have evaluated the late delta protocol and our synchronization coprocessor through simulation using a synthetic workload. This is the most tractable and accurate approach now available to us. The efficient support for atomicity provided by delta cache systems eliminates the use of locks.
Reference: [DPS86] <author> Darema-Rogers, F., G.F. Pfister and K. </author> <title> So, Memory Access Patterns of Parallel Scientific Programs, </title> <institution> RC12086, IBM Research Report, </institution> <year> 1986. </year>
Reference-contexts: We have used a write probability of 0.3 throughout our experiments. Shared reference pattern studies indicate that the vast majority of dynamic references is to private data <ref> [DPS86, BaR89] </ref>. For this reason, we have parameterized our reference generation method to keep the percentage of references to shared addresses low, typically about 5 or 10 percent of all references. <p> Most importantly, this exercise is unnecessary for the late delta protocol. 4.3. Varying the Probability of a Shared Access Studies of reference patterns in shared memory multiprocessor indicate that the probability of any given reference being to shared data varies greatly among applications <ref> [BaR89, DPS86] </ref>. Although this probability is low for most applications, it can be as high as 0.25 or even 0.5 for some applications. Therefore, protocols which can provide consistently good performance across a range of values for this probability are desirable.
Reference: [DGH90] <author> Davis, H., S.R. Goldschmidt and J. Hennessy, </author> <title> Tango: A Multiprocessor Simulation and Tracing System, </title> <type> Tech. Rep. </type> <institution> CSL-TR90-439 Stanford University, Computer Systems Laboratory, </institution> <year> 1990. </year>
Reference-contexts: Still others have simulated an entire computer system in software [CKA91] or used the execution driven approach, where actual programs are run on the host computer and memory references are trapped to a memory hierarchy simulation as necessary <ref> [DGH90, CDK94] </ref>. We have evaluated the late delta protocol and our synchronization coprocessor through simulation using a synthetic workload. This is the most tractable and accurate approach now available to us. The efficient support for atomicity provided by delta cache systems eliminates the use of locks.
Reference: [DuB82] <author> Dubois, M. and F.A. Briggs, </author> <title> Effects of Cache Coherency in Multiprocessors, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 31, </volume> <pages> pp. 1083-1099, </pages> <year> 1982. </year>
Reference-contexts: A variety of approaches have been used to evaluate cache coherence protocols. Several researchers have modeled cache coherence protocols as Markov processes <ref> [DuB82] </ref> and attempted to derive closed form solutions for these systems. Others have used mean value analysis to compare protocols [VLZ88, BLA89, YBL89, ADT90]. Generally these approaches have relied on system simulation to verify the models proposed. Much research has been conducted using simulations to evaluate cache coherence protocols directly. <p> Performance Evaluation of the Late Delta Cache Coherence Protocol 7 Since our goal is to determine the effect of shared cache activity on performance, shared cache blocks must be modeled explicitly. Early research <ref> [DuB82] </ref> proposed that temporal locality would be significantly reduced for shared data, and so proposed modeling shared references with the uniform reference model. However, later studies have chosen to model shared references with temporal locality by using a least recently used stack model (LRUSM) [Spi77].
Reference: [DKC93] <author> Dwarkadas, S., P. Keleher, A.L. Cox and W. Zwaenepoel, </author> <title> Evaluation of Release Consistent Software Distributed Shared Memory on Emerging Network Technology, </title> <booktitle> Proceedings of the 20th International Symposium on Computer Architecture, </booktitle> <pages> pp. 106-117, </pages> <year> 1993. </year>
Reference-contexts: A full description of the protocol is available in [WiR90]. We compare the performance of an isotach system which employs the late delta protocol to maintain coherence to systems which maintain cache coherence with a conventional directory based invalidation protocol. Existing directory based update protocols either sacrifice sequential consistency <ref> [DKC93] </ref> or require expensive techniques, such as two phased locking to propagate the updates [WiL92]. We expect the late delta protocol to provide excellent performance without sacrificing sequential consistency.
Reference: [EgK88] <author> Eggers, S.J. and R.H. Katz, </author> <title> Evaluating the Performance of Four Snooping Cache Coherency Protocols, </title> <booktitle> Proceedings of the 15th International Symposium on Computer Architecture, </booktitle> <pages> pp. 373-382, </pages> <year> 1988. </year> <title> Performance Evaluation of the Late Delta Cache Coherence Protocol 26 </title>
Reference-contexts: Much research has been conducted using simulations to evaluate cache coherence protocols directly. Researchers have used both synthetic workloads, generally based on the workload model developed by Archibald and Baer [ArB86], and memory traces to generate a reference stream <ref> [EgK88, BMR89, MiB92, ASH88] </ref>. Still others have simulated an entire computer system in software [CKA91] or used the execution driven approach, where actual programs are run on the host computer and memory references are trapped to a memory hierarchy simulation as necessary [DGH90, CDK94].
Reference: [Lam79] <author> Lamport, L., </author> <title> How to Make a Multiprocessor Computer that Correctly Executes Multiprocessor Programs, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 28, </volume> <pages> pp. 690-691, </pages> <year> 1979. </year>
Reference-contexts: For the simulations of the late delta protocol, we have used the switch algorithm of network I1 described in a previous performance evaluation of isotach networks [RWW92]. Delta cache protocols use the properties of an isotach logical time system to provide support for sequential consistency <ref> [Lam79] </ref> and atomicity without the use of locks or other special synchronization constructs. The protocols rely on the interconnection network to maintain isotach logical time. The routing algorithm of the switches of a MIN can be modified slightly to maintain isotach logical time.
Reference: [LaK92] <author> Law, A.M. and W.D. </author> <title> Kelton, Simulation Modeling and Analysis, </title> <publisher> McGraw-Hill, Inc., </publisher> <year> 1992. </year>
Reference-contexts: In order to minimize the number of runs required to gather these statistics since each run requires significant processor time, we have adopted a fixed sample size procedure <ref> [LaK92] </ref>. This procedure allows a single long simulation run to provide an accurate confidence interval for the processing power metric. We are interested primarily in the steady state performance of the systems, so the simulation is run for a significant period of time prior to gathering statistics.
Reference: [LeR90] <author> Lee, J. and U. Ramachandran, </author> <title> Synchronization with Multiprocessor Caches, </title> <booktitle> Proceedings of the 17th International Symposium on Computer Architecture, </booktitle> <pages> pp. 27-37, </pages> <year> 1990. </year>
Reference-contexts: Previous synthetic workload models are not sufficient for evaluating the performance of delta cache protocols, which provide support for atomicity and allow pipelining of atomic actions. Few model atomicity requirements <ref> [LeR90] </ref>. Further, previous workloads provided no direct method for manipulating the degree of contention for shared variables. We expect the effect of varying this contention to reveal significant differences between the systems we are evaluating.
Reference: [MiB92] <author> Min, S.L. and J.L. Baer, </author> <title> Design and Analysis of a Scalable Cache Coherence Scheme Based on Clocks and Timestamps, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> Vol. 3, No. 1, pp.25-44, </volume> <year> 1992. </year>
Reference-contexts: Much research has been conducted using simulations to evaluate cache coherence protocols directly. Researchers have used both synthetic workloads, generally based on the workload model developed by Archibald and Baer [ArB86], and memory traces to generate a reference stream <ref> [EgK88, BMR89, MiB92, ASH88] </ref>. Still others have simulated an entire computer system in software [CKA91] or used the execution driven approach, where actual programs are run on the host computer and memory references are trapped to a memory hierarchy simulation as necessary [DGH90, CDK94].
Reference: [MBK90] <author> Min, S.L., J.L. Baer and H.J. Kim, </author> <title> An Efficient Caching Support for Critical Sections in Large-Scale Shared-Memory Multiprocessors, </title> <institution> RC15311, IBM Research Report, </institution> <year> 1990. </year>
Reference-contexts: The remainder of this section details these innovations. 3.1.1. Incorporating Atomicity An important feature of the systems we have proposed is that they provide support for atomicity. The basis of our atomicity model is derived from the critical section model proposed by Min, Baer and Kim <ref> [MBK90] </ref>. In our model, a processor issues a batch of one or more references after each think period. We have chosen to model the batches as consisting entirely of either private or shared references. <p> Thus we must provide a reasonable method for assigning locks to shared atomic actions. Given the composition of the shared atomic actions, we can define a critical section graph <ref> [MBK90] </ref>. Each shared atomic action is a node in this graph. The edges of the graph are determined by the possible conicting accesses of these atomic actions.
Reference: [NaB93] <author> Nanda, A.K. and Bhuyan, </author> <title> L.N., Design and Analysis of Cache Coherent Multistage Interconnection Networks, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 42, No. 4, </volume> <pages> pp. 458-470, </pages> <year> 1993. </year>
Reference-contexts: Archibald and Baer [ArB86] compared a wide variety of bus based cache coherence protocols using a simulation driven by a synthetic workload. Nearly all synthetic workload simulations of cache coherence <ref> [e.g. LeR90, NaB93] </ref> have been based on this research. The remainder of this subsection details the synthetic workload model we have used.
Reference: [PfN85] <author> Pfister, </author> <title> G.F. and V.A. Norton, Hot Spot Contention and Combining in Multistage Interconnection Networks, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 34, No. 10, </volume> <pages> pp. 943-948, </pages> <year> 1985. </year>
Reference-contexts: Modeling Contention for Shared Variables Most previous synthetic workloads used to evaluate cache coherence protocols have not directly modeled contention for shared variables. We have chosen to include a hot spot model in our workload <ref> [PfN85] </ref>. Given that a processor is referencing a shared atomic action, with some probability, the atomic action is the hot atomic action. The hot atomic action changes during a simulation run. Periodically, a single atomic action for all processors is chosen uniformly from the set of all shared atomic actions. <p> In all of our runs, this total probability, combined with the low bandwidth requirements of the workload, is not large enough to create tree saturation <ref> [PfN85] </ref>. Thus performance of the protocols is limited by the performance of the protocol under the amount of contention implied by the hot spot accesses.
Reference: [RWW92] <author> Reynolds, Jr., P.F., C. Williams and R.R. Wagner, Jr., </author> <title> Empirical Analysis of Iso-tach Networks, </title> <type> Tech. Rep. 92-19, </type> <institution> University of Virginia, Department of Computer Science, </institution> <year> 1992. </year>
Reference-contexts: The networks are composed of standard 2X2 crossbar switches, which have been simulated in detail. For the simulations of the late delta protocol, we have used the switch algorithm of network I1 described in a previous performance evaluation of isotach networks <ref> [RWW92] </ref>. Delta cache protocols use the properties of an isotach logical time system to provide support for sequential consistency [Lam79] and atomicity without the use of locks or other special synchronization constructs. The protocols rely on the interconnection network to maintain isotach logical time. <p> The protocols rely on the interconnection network to maintain isotach logical time. The routing algorithm of the switches of a MIN can be modified slightly to maintain isotach logical time. A previous study <ref> [RWW92] </ref> has shown that these modifications result in higher raw network latency. To capture this cost, we have modelled the interconnection network explicitly in this study. Members of the delta cache family of protocols support multiple concurrent readers and writers and allow the pipelining of memory accesses.
Reference: [Spi77] <author> Spirn, J.R., </author> <title> Program Behavior: Models and Measurements, </title> <publisher> Elsevier North-Holland, Inc., </publisher> <year> 1977. </year>
Reference-contexts: Early research [DuB82] proposed that temporal locality would be significantly reduced for shared data, and so proposed modeling shared references with the uniform reference model. However, later studies have chosen to model shared references with temporal locality by using a least recently used stack model (LRUSM) <ref> [Spi77] </ref>. This assumption is supported by shared memory reference pattern studies [AgG88]. This model allows cache blocks which have recently been selected to be significantly more likely to be selected again, which is important if caching is going to provide much reduction in memory latency.
Reference: [VLZ88] <author> Vernon, M.K., E.D. Lazowska and J. Zahorjan, </author> <title> An Accurate and Efficient Performance Analysis Technique for Snooping Cache-Consistency Protocols, </title> <booktitle> Proceedings of the 15th International SYNP Computer Architecture, </booktitle> <pages> pp. 308-315, </pages> <year> 1988. </year>
Reference-contexts: A variety of approaches have been used to evaluate cache coherence protocols. Several researchers have modeled cache coherence protocols as Markov processes [DuB82] and attempted to derive closed form solutions for these systems. Others have used mean value analysis to compare protocols <ref> [VLZ88, BLA89, YBL89, ADT90] </ref>. Generally these approaches have relied on system simulation to verify the models proposed. Much research has been conducted using simulations to evaluate cache coherence protocols directly.
Reference: [Wil93] <author> Williams, C., </author> <title> Concurrency Control in Asynchronous Computations, </title> <type> Ph.D. Thesis, </type> <institution> University of Virginia, </institution> <year> 1993. </year>
Reference: [WiR90] <author> Williams, C. and P.F. Reynolds, Jr., </author> <title> Delta-Cache Protocols: A New Class of Cache Coherence Protocols, </title> <type> Tech. Rep. 90-34, </type> <institution> University of Virginia, Department of Computer Science, </institution> <year> 1990. </year> <title> Performance Evaluation of the Late Delta Cache Coherence Protocol 27 </title>
Reference-contexts: Members of the delta cache family of protocols support multiple concurrent readers and writers and allow the pipelining of memory accesses. The late delta protocol is an update based member of this protocol family. A full description of the protocol is available in <ref> [WiR90] </ref>. We compare the performance of an isotach system which employs the late delta protocol to maintain coherence to systems which maintain cache coherence with a conventional directory based invalidation protocol.
Reference: [WiL92] <author> Wilson, A.W. and R.P. LaRowe, Jr., </author> <title> Hiding Shared Memory Reference Latency on the Galactica Net Distributed Shared Memory Architecture, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 15, No. 4, </volume> <pages> pp. 351-367, </pages> <year> 1992. </year>
Reference-contexts: Existing directory based update protocols either sacrifice sequential consistency [DKC93] or require expensive techniques, such as two phased locking to propagate the updates <ref> [WiL92] </ref>. We expect the late delta protocol to provide excellent performance without sacrificing sequential consistency. Thus, the conventional invalidation protocol provides the most reasonable existing comparison Our conventional protocol is based on the protocol used in the Alewife machine [CKA91].
Reference: [WLT93] <author> Wilson, A.W., R.P. LaRowe, Jr. and M.J. Teller, </author> <title> Hardware Assist for Distributed Shared Memory, </title> <booktitle> Proceedings of the 13th International Conference on Distributed Computing Systems, </booktitle> <pages> pp. 246-255, </pages> <year> 1993. </year>
Reference-contexts: For simplicity, we assume each cache blocks holds exactly one variable. Although this cache block size is unrealistically small, we expect increasing Performance Evaluation of the Late Delta Cache Coherence Protocol 11 the block size to favor the late delta protocol since increasing the block size favors update protocols <ref> [WLT93] </ref>. We first compare the sensitivity of the systems to contention for shared variables. We then investigate the scalability of the protocols and the effect of varying the probability of referencing shared data. 4.1.
Reference: [YBL89] <author> Yang, Q., L.N. Bhuyan and B.C. Liu, </author> <title> Analysis and Comparison of Cache Coherence Protocols for a Packet-Switched Multiprocessor, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 38, No. 8, </volume> <pages> pp. 1143-1153, </pages> <year> 1989. </year> <title> Performance Evaluation of the Late Delta Cache Coherence Protocol 28 </title>
Reference-contexts: A variety of approaches have been used to evaluate cache coherence protocols. Several researchers have modeled cache coherence protocols as Markov processes [DuB82] and attempted to derive closed form solutions for these systems. Others have used mean value analysis to compare protocols <ref> [VLZ88, BLA89, YBL89, ADT90] </ref>. Generally these approaches have relied on system simulation to verify the models proposed. Much research has been conducted using simulations to evaluate cache coherence protocols directly.
References-found: 30

