URL: http://http.cs.berkeley.edu/~asah/papers/other/to-read/sunita-ndim-arrays.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~asah/papers/other/to-read/
Root-URL: http://www.cs.berkeley.edu
Title: Efficient Organization of Large Multidimensional Arrays  
Author: Sunita Sarawagi Michael Stonebraker 
Address: Berkeley  
Affiliation: Computer Science Division University of California at  
Abstract: Large multidimensional arrays are widely used in scientific and engineering database applications. In this paper, we present methods of organizing arrays to make their access on secondary and tertiary memory devices fast and efficient. We have developed four techniques for doing this: (1) storing the array in multidimensional "chunks" to minimize the number of blocks fetched, (2) reordering the chunked array to minimize seek distance between accessed blocks, (3) maintaining redundant copies of the array, each organized for a different chunk size and ordering and (4) partitioning the array onto platters of a tertiary memory device so as to minimize the number of platter switches. Our measurements on real data obtained from global change scientists show that accesses on arrays organized using these techniques are often an order of magnitude faster than on the unoptimized data. 
Abstract-found: 1
Intro-found: 1
Reference: [Doz91] <author> J. Dozier and H.K. Ramapriyan. </author> <title> Planning for the EOS data and information system. In Global Environment Change, volume 1. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction Scientific and engineering applications often utilize large multidimensional arrays. Earth scientists routinely process satellite images in the form of large two and three dimensional arrays <ref> [Doz91] </ref>. Their simulations of atmosphere and ocean climatic conditions generate large regular arrays of floating point numbers as output [Mec92]. For example, typical runs of the UCLA General Circulation Model (GCM) generate five dimensional arrays of size 5 to 50 Gigabytes.
Reference: [Equ89] <author> William H. Equitz. </author> <title> A new vector quantization clustering algorithm. </title> <journal> IEEE transactions on Ac-coustics, speech and signal processing, </journal> <volume> 37(10), </volume> <year> 1989. </year>
Reference-contexts: Initially, each class belongs to a different cluster and we progressively merge pairs of clusters with the minimal weighted distance between them until R clusters remain. Algorithms for computing minimal distance are given in <ref> [Equ89] </ref>. When a read request arrives for a replicated array, the runtime system first finds the replica with the smallest estimated access cost. The estimated cost is a weighted sum of the number of block fetches, seek distance and media switches (in case of tertiary devices).
Reference: [Fis79] <author> P. C. Fisher and R. L. Prower. </author> <title> Storage reorganization techniques for matrix computation in paging environments. </title> <journal> Communications of the ACM, </journal> <volume> 22(7), </volume> <year> 1979. </year>
Reference-contexts: Related Work The use of chunking to organize two dimensional arrays has been discussed in [Mck69] and <ref> [Fis79] </ref>. Chunking in the context of image processing has been used to build tiled virtual memory systems [Wad84] [Reu80].
Reference: [Jag90] <author> H. V. Jagadish. </author> <title> Linear clustering of objects with multiple attributes. </title> <booktitle> In Proceedings of the 1990 ACM SIGMOD International Conference on Management of Data, </booktitle> <year> 1990. </year>
Reference-contexts: A more theoretical approach to orga nizing multidimensional arrays is presented in [Ros75]. Similiar work based on mapping a multidimensional space on to a one dimensional space is discussed is <ref> [Jag90] </ref>. Their approach organizes data without regard to access pattern, whereas our work considers access patterns to optimize layout. Array organization is related to the general problem of data clustering. Most clustering algorithms [Jai88] work on a collection of records that are not structured in any way.
Reference: [Jai88] <author> Anil K. Jain and Richard C. Dubes. </author> <title> Algorithms for Clustering Data. </title> <publisher> Prentice Hall, </publisher> <year> 1988. </year>
Reference-contexts: Their approach organizes data without regard to access pattern, whereas our work considers access patterns to optimize layout. Array organization is related to the general problem of data clustering. Most clustering algorithms <ref> [Jai88] </ref> work on a collection of records that are not structured in any way. Arrays have a regular structure that facilitates a different approach to storage organization.
Reference: [Lin80] <author> Yoseph Linde, Andres Buzo, and Robert Gray. </author> <title> An algorithm for vector quantizer design. </title> <journal> IEEE Transcations on Communications, </journal> <volume> 28(1), </volume> <year> 1980. </year>
Reference-contexts: In the worst scenario, the number of partitions to be considered is exponential in the number of elements in the access pattern. * Use vector clustering techniques <ref> [Lin80] </ref> to group classes into clusters. We have a starting set of K classes and wish to divide them into R clusters. Initially, each class belongs to a different cluster and we progressively merge pairs of clusters with the minimal weighted distance between them until R clusters remain.
Reference: [Mec92] <author> C. Mechoso et al. </author> <title> Parallelization and distribution of a coupled atmosphere-ocean general circulation model, 1992. sumitted to Monthly Weather Review, </title> <month> Aug 4 </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Scientific and engineering applications often utilize large multidimensional arrays. Earth scientists routinely process satellite images in the form of large two and three dimensional arrays [Doz91]. Their simulations of atmosphere and ocean climatic conditions generate large regular arrays of floating point numbers as output <ref> [Mec92] </ref>. For example, typical runs of the UCLA General Circulation Model (GCM) generate five dimensional arrays of size 5 to 50 Gigabytes. Other areas where large arrays are commonly used include image processing [Wad84], computational chemistry, structural dynamics and seismology. <p> To make our measurements realistic we considered arrays used by global change scientists in the Sequoia project [Sto91]. The first source of data was ocean model output from the General Circulation Model (GCM) simulations done at UCLA <ref> [Mec92] </ref>. The arrays consist of three-dimensional snapshots of the ocean (covering the world or a region of it) taken at regular intervals of time with horizontal grid resolution varying from 1 3 to 1 ffi .
Reference: [Mck69] <author> A. C. McKellar and E. G. Coffman. </author> <title> Organizing matrices and matrix operations for paged virtual memory. </title> <journal> Communications of the ACM, </journal> <volume> 12(3) </volume> <pages> 153-165, </pages> <year> 1969. </year>
Reference-contexts: The above techniques can be used, in combination, to tune the array's internal structure to an access pattern obtained from either an end user or from statistical sampling by a data management system. Related Work The use of chunking to organize two dimensional arrays has been discussed in <ref> [Mck69] </ref> and [Fis79]. Chunking in the context of image processing has been used to build tiled virtual memory systems [Wad84] [Reu80].
Reference: [Mos92] <author> Claire Mosher. </author> <title> Postgres Reference Manual, </title> <type> version 4.0. </type> <institution> Electronics Research Laboratory, University of California, Berkeley, CA-94720, </institution> <year> 1992. </year> <note> No. UCB/ERL M92/85. </note>
Reference-contexts: The data field in this case is used to store the array elements contiguously in their respective internal repre sentation * Store the array as a postgres large object <ref> [Mos92] </ref> and keep a pointer to the large object in the data field of the array structure. The large object interface in postgres provides a file-oriented access to data that span multiple pages.
Reference: [Nie84] <author> J. Nievergelt, H. Hinterberger, and K. C. Sevcik. </author> <title> The grid file: An adaptable symmetric multikey file structure. </title> <journal> ACM Transactions on Database systems, </journal> <volume> 9(1), </volume> <year> 1984. </year>
Reference-contexts: Most clustering algorithms [Jai88] work on a collection of records that are not structured in any way. Arrays have a regular structure that facilitates a different approach to storage organization. This is also the reason why indexing structures like grid files <ref> [Nie84] </ref> or KDB trees used for indexing mul-tiattribute data are not relevant to array organization. For example, consider using the grid file structure for organizing a multidimensional array. The array is divided into regular chunks and each chunk is a bucket of the grid file.
Reference: [Ols92] <author> Michael Allen Olson. </author> <title> Extending the POST-GRES database system to manage tertiary storage. </title> <type> Master's thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1992. </year>
Reference-contexts: We have built into postgres a generalized interface for multidimensional arrays. postgres is well-suited for handling massive amounts of data; it supports large objects that allow attributes to span multiple pages and it has a generalized storage structure that supports huge capacity storage devices as tertiary memory <ref> [Ols92] </ref>. In our implementation, arrays are first class objects. Therefore any attribute of a class can be declared to be an array of any base type. <p> The block size, C was set to 8 KB, which is the file system block size. A second set of results was taken from data stored on a write-once optical jukebox [Son89]; the tertiary storage device currently supported by postgres <ref> [Ols92] </ref>. The jukebox consists of 50 double sided platters, each of which has a 3.27 GB capacity per side. At any time a maximum of two platters can be physically mounted, and mounting a platter takes about ten seconds.
Reference: [Reu80] <author> J. L. Reuss, S. K. Chang, and B. H. McCormick. </author> <title> Picture paging for efficient image processing. </title> <editor> In S K Chang and K S Fu, editors, </editor> <booktitle> Pictorial Information Systems, </booktitle> <pages> pages 228-243. </pages> <address> Spriger-Verlag, </address> <year> 1980. </year>
Reference-contexts: Related Work The use of chunking to organize two dimensional arrays has been discussed in [Mck69] and [Fis79]. Chunking in the context of image processing has been used to build tiled virtual memory systems [Wad84] <ref> [Reu80] </ref>. Whereas those systems deal only with two dimensional arrays and assume magnetic disk as the storage device, our interest is in multidimensional arrays with both magnetic disk and tertiary memory as storage devices. A more theoretical approach to orga nizing multidimensional arrays is presented in [Ros75].
Reference: [Ros75] <author> Arnold L. Rosenberg. </author> <title> Preserving proximity in arrays. </title> <journal> SIAM journal on Computing, </journal> <volume> 4 </volume> <pages> 443-460, </pages> <year> 1975. </year>
Reference-contexts: Whereas those systems deal only with two dimensional arrays and assume magnetic disk as the storage device, our interest is in multidimensional arrays with both magnetic disk and tertiary memory as storage devices. A more theoretical approach to orga nizing multidimensional arrays is presented in <ref> [Ros75] </ref>. Similiar work based on mapping a multidimensional space on to a one dimensional space is discussed is [Jag90]. Their approach organizes data without regard to access pattern, whereas our work considers access patterns to optimize layout. Array organization is related to the general problem of data clustering.
Reference: [Son89] <author> Sony Corporation, </author> <title> Japan. Writable Disk Drive WDD-600 and Writable Disk WDM-6DL0 Operating Instructions, </title> <year> 1989. </year> <month> 3-751-047-21(1). </month>
Reference-contexts: The first set of results is for a local 1 GB magnetic disk using the Ultrix file system. The block size, C was set to 8 KB, which is the file system block size. A second set of results was taken from data stored on a write-once optical jukebox <ref> [Son89] </ref>; the tertiary storage device currently supported by postgres [Ols92]. The jukebox consists of 50 double sided platters, each of which has a 3.27 GB capacity per side. At any time a maximum of two platters can be physically mounted, and mounting a platter takes about ten seconds.
Reference: [Sto91] <author> Michael Stonebraker and Jeff Dozier. </author> <title> Large capacity object servers to support global change research. </title> <type> Technical Report 91/1, </type> <institution> University of California at Berkeley, </institution> <year> 1991. </year>
Reference-contexts: Because of the large storage requirements for such arrays, they are usually allocated to tertiary storage devices. Achieving high performance in spite of the nonuniform access times and the high latency of such storage devices requires good allocation strategies <ref> [Sto91] </ref>. fl This research was sponsored by the National Science Foundation under grant IRI-9107455, the Defense Advanced Research Projects Agency under grant T63-92-C-0007, and the Army Research Office under grant 91-G-0183. <p> The rest of this paper is organized as follows. In Section 2 we present the different schemes we used for organizing arrays, namely chunking, reordering, redundancy and partitioning. In Section 3 we describe our implementation of multidimensional arrays in the next generation DBMS postgres <ref> [Sto91] </ref>. Section 4 presents simulation of several earth science arrays used by global change researchers in the Sequoia 2000 project [Sto91] and shows the results of our array organization schemes on this data. <p> In Section 3 we describe our implementation of multidimensional arrays in the next generation DBMS postgres <ref> [Sto91] </ref>. Section 4 presents simulation of several earth science arrays used by global change researchers in the Sequoia 2000 project [Sto91] and shows the results of our array organization schemes on this data. Lastly, we present future work and conclusions in Section 5. 2 Storage of Arrays We begin this section by presenting the access pattern model that we use for optimization of array layout. <p> Partitioning can be used for minimizing the media switches for both disk and tape tertiary devices. However, for tapes the average seek time (45 seconds) is large compared to the switch time. Hence, minimizing media switches is less crucial than minimizing seek time. 3 Implementation in postgres postgres <ref> [Sto91] </ref> is an extended relational database system being developed at Berkeley. <p> A custom storage manager transfers data between disk and tertiary memory in units of 256 KB and hence block size is 256 KB. To make our measurements realistic we considered arrays used by global change scientists in the Sequoia project <ref> [Sto91] </ref>. The first source of data was ocean model output from the General Circulation Model (GCM) simulations done at UCLA [Mec92].
Reference: [Sto91] <author> Michael Stonebraker and Greg Kemnitz. </author> <title> The POSTGRES next generation database management system. </title> <journal> Communications of the ACM, </journal> <volume> 34, </volume> <year> 1991. </year>
Reference-contexts: Because of the large storage requirements for such arrays, they are usually allocated to tertiary storage devices. Achieving high performance in spite of the nonuniform access times and the high latency of such storage devices requires good allocation strategies <ref> [Sto91] </ref>. fl This research was sponsored by the National Science Foundation under grant IRI-9107455, the Defense Advanced Research Projects Agency under grant T63-92-C-0007, and the Army Research Office under grant 91-G-0183. <p> The rest of this paper is organized as follows. In Section 2 we present the different schemes we used for organizing arrays, namely chunking, reordering, redundancy and partitioning. In Section 3 we describe our implementation of multidimensional arrays in the next generation DBMS postgres <ref> [Sto91] </ref>. Section 4 presents simulation of several earth science arrays used by global change researchers in the Sequoia 2000 project [Sto91] and shows the results of our array organization schemes on this data. <p> In Section 3 we describe our implementation of multidimensional arrays in the next generation DBMS postgres <ref> [Sto91] </ref>. Section 4 presents simulation of several earth science arrays used by global change researchers in the Sequoia 2000 project [Sto91] and shows the results of our array organization schemes on this data. Lastly, we present future work and conclusions in Section 5. 2 Storage of Arrays We begin this section by presenting the access pattern model that we use for optimization of array layout. <p> Partitioning can be used for minimizing the media switches for both disk and tape tertiary devices. However, for tapes the average seek time (45 seconds) is large compared to the switch time. Hence, minimizing media switches is less crucial than minimizing seek time. 3 Implementation in postgres postgres <ref> [Sto91] </ref> is an extended relational database system being developed at Berkeley. <p> A custom storage manager transfers data between disk and tertiary memory in units of 256 KB and hence block size is 256 KB. To make our measurements realistic we considered arrays used by global change scientists in the Sequoia project <ref> [Sto91] </ref>. The first source of data was ocean model output from the General Circulation Model (GCM) simulations done at UCLA [Mec92].
Reference: [Sto91] <author> Michael Stonebraker. </author> <title> An overview of the Se-quoia 2000 project. </title> <type> Technical Report 91/5, </type> <institution> University of California at Berkeley, </institution> <year> 1991. </year>
Reference-contexts: Because of the large storage requirements for such arrays, they are usually allocated to tertiary storage devices. Achieving high performance in spite of the nonuniform access times and the high latency of such storage devices requires good allocation strategies <ref> [Sto91] </ref>. fl This research was sponsored by the National Science Foundation under grant IRI-9107455, the Defense Advanced Research Projects Agency under grant T63-92-C-0007, and the Army Research Office under grant 91-G-0183. <p> The rest of this paper is organized as follows. In Section 2 we present the different schemes we used for organizing arrays, namely chunking, reordering, redundancy and partitioning. In Section 3 we describe our implementation of multidimensional arrays in the next generation DBMS postgres <ref> [Sto91] </ref>. Section 4 presents simulation of several earth science arrays used by global change researchers in the Sequoia 2000 project [Sto91] and shows the results of our array organization schemes on this data. <p> In Section 3 we describe our implementation of multidimensional arrays in the next generation DBMS postgres <ref> [Sto91] </ref>. Section 4 presents simulation of several earth science arrays used by global change researchers in the Sequoia 2000 project [Sto91] and shows the results of our array organization schemes on this data. Lastly, we present future work and conclusions in Section 5. 2 Storage of Arrays We begin this section by presenting the access pattern model that we use for optimization of array layout. <p> Partitioning can be used for minimizing the media switches for both disk and tape tertiary devices. However, for tapes the average seek time (45 seconds) is large compared to the switch time. Hence, minimizing media switches is less crucial than minimizing seek time. 3 Implementation in postgres postgres <ref> [Sto91] </ref> is an extended relational database system being developed at Berkeley. <p> A custom storage manager transfers data between disk and tertiary memory in units of 256 KB and hence block size is 256 KB. To make our measurements realistic we considered arrays used by global change scientists in the Sequoia project <ref> [Sto91] </ref>. The first source of data was ocean model output from the General Circulation Model (GCM) simulations done at UCLA [Mec92].
Reference: [Wad84] <author> B. T. Wada. </author> <title> A virtual memory system for pic ture processing. </title> <journal> Communications of the ACM, </journal> <volume> 27 </volume> <pages> 444-454, </pages> <year> 1984. </year>
Reference-contexts: For example, typical runs of the UCLA General Circulation Model (GCM) generate five dimensional arrays of size 5 to 50 Gigabytes. Other areas where large arrays are commonly used include image processing <ref> [Wad84] </ref>, computational chemistry, structural dynamics and seismology. Because of the large storage requirements for such arrays, they are usually allocated to tertiary storage devices. <p> Related Work The use of chunking to organize two dimensional arrays has been discussed in [Mck69] and [Fis79]. Chunking in the context of image processing has been used to build tiled virtual memory systems <ref> [Wad84] </ref> [Reu80]. Whereas those systems deal only with two dimensional arrays and assume magnetic disk as the storage device, our interest is in multidimensional arrays with both magnetic disk and tertiary memory as storage devices. A more theoretical approach to orga nizing multidimensional arrays is presented in [Ros75].
References-found: 18

