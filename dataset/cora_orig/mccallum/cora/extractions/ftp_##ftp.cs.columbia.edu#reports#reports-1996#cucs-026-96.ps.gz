URL: ftp://ftp.cs.columbia.edu/reports/reports-1996/cucs-026-96.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1996.html
Root-URL: http://www.cs.columbia.edu
Title: The exponent of discrepancy  
Author: Grzegorz W. Wasilkowski and Henryk Wozniakowski 
Date: December 1995  
Affiliation: Columbia University Computer Science Department  
Note: is at most 1:4778:::  constructive bound on the exponent p is 2:454.  
Pubnum: Report CUCS-026-96  
Abstract: We study discrepancy with arbitrary weights in the L 2 norm over the d dimensional unit cube. The exponent p fl of discrepancy is defined as the smallest p for which there exists a positive number K such that for all d and all " 1 there exist K " p points with discrepancy at most ". It is well known that p fl 2 (1; 2]. We improve the upper bound by showing that This is done by using relations between discrepancy and integration in the average case setting with the Wiener sheet measure. Our proof is not constructive. The known p fl 1:478841:::: :
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Beck and W. W. L. Chen, </author> <title> Irregularities of Distribution, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1987. </year>
Reference-contexts: 1 Introduction We study discrepancy with arbitrary weights in the L 2 norm over the d dimensional unit cube <ref> [0; 1] </ref> d . This problem is defined as finding n points from [0; 1] d which approximate the volumes of rectangles (starting from zero) with minimal error, see [8, 9] for the precise definition, history and basic properties. <p> 1 Introduction We study discrepancy with arbitrary weights in the L 2 norm over the d dimensional unit cube <ref> [0; 1] </ref> d . This problem is defined as finding n points from [0; 1] d which approximate the volumes of rectangles (starting from zero) with minimal error, see [8, 9] for the precise definition, history and basic properties. Discrepancy has been extensively studied in number theory and numerical analysis, see e.g., [1, 8, 9, 10, 11, 12]. <p> This problem is defined as finding n points from [0; 1] d which approximate the volumes of rectangles (starting from zero) with minimal error, see [8, 9] for the precise definition, history and basic properties. Discrepancy has been extensively studied in number theory and numerical analysis, see e.g., <ref> [1, 8, 9, 10, 11, 12] </ref>. Fast algorithms for computing fl 1991 Math. Subject Classification: Primary 11K38, 41A55. Key words: discrepancy, multivariate integration, average case. <p> that discrepancy for points x 1 ; x 2 ; : : : ; x n is equal to the average case integration error for the points ~ 1 x 1 ; ~ 1 x 2 ; : : : ; ~ 1 x n , where ~ 1 = <ref> [1; 1; : : : ; 1] </ref> 2 IR d . The average error is defined for the class of continuous functions defined over [0; 1] d and equipped with the Wiener sheet measure. Hence, bounds on discrepancy have immediate applications for multivariate integration. <p> The average error is defined for the class of continuous functions defined over <ref> [0; 1] </ref> d and equipped with the Wiener sheet measure. Hence, bounds on discrepancy have immediate applications for multivariate integration. Let n ("; d) be the minimal number of points from [0; 1] d for which discrepancy is at most ". <p> The average error is defined for the class of continuous functions defined over <ref> [0; 1] </ref> d and equipped with the Wiener sheet measure. Hence, bounds on discrepancy have immediate applications for multivariate integration. Let n ("; d) be the minimal number of points from [0; 1] d for which discrepancy is at most ". <p> First, we switch to the equivalent problem of integration in the average case setting with the Wiener sheet measure. Let I (f ) denote the integral of a continuous function f defined over <ref> [0; 1] </ref> d . Then, instead of integrating f directly, we approximate f by a special function f n whose computation requires n values of f . Obviously, I (f ) = I (f n ) + I (f f n ). <p> A thorough discussion on discrepancy may be found in [8, 9]. Consider n points z 1 ; z 2 ; : : : ; z n from <ref> [0; 1] </ref> d . For a vector t = [t 1 ; t 2 ; : : : ; t d ] 2 [0; 1] d , define the rectangle [0; t) = [0; t 1 ) fi [0; t 2 ) fi fi [0; t d ). <p> Consider n points z 1 ; z 2 ; : : : ; z n from <ref> [0; 1] </ref> d . For a vector t = [t 1 ; t 2 ; : : : ; t d ] 2 [0; 1] d , define the rectangle [0; t) = [0; t 1 ) fi [0; t 2 ) fi fi [0; t d ). <p> n;d (t; fz i g; fc i g) dt : The discrepancy problem is to find the points fz i g and the weights fc i g that minimize the discrepancy, DISC n;d = inf n kDISC n ( ; fz i g; fc i g)k : z i 2 <ref> [0; 1] </ref> d ; c i 2 IR; i = 1; 2; : : : ; n o Let n ("; d) be the minimal number of points for which the discrepancy is at most ", n ("; d) = min fn : DISC n;d " g : (11) 4 The <p> This relation is given by the identity kDISC n;d ( ; fz i g; fc i g)k 2 = Z Z f (t) dt i=1 ! 2 where F = C (<ref> [0; 1] </ref> d ) is the class of continuous functions defined over [0; 1] d , w is the classical Wiener sheet measure, and x i = ~ 1 z i . 3 Proof In this section we prove the bound (9) on the exponent p fl . <p> (f ) = [0;1] d Let c (x) b (d)e and consider the following randomized (Monte Carlo) quadrature Q m , Q m (f; ft i g) = I (f n ) + m i=1 with independently and uniformly distributed points t 1 ; : : : t m 2 <ref> [0; 1] </ref> d . Obviously, the quadrature Q m uses n + m 2n + 1 function values.
Reference: [2] <author> V. A. Bykovskij, </author> <title> On exact order of optimal quadrature formulas for spaces of functions with bounded mixed derivatives, </title> <institution> Report of Dalnevostochnoi Center of Academy of Sciences, Vladivostok, USSR, (in Russian), </institution> <year> 1985. </year>
Reference-contexts: Discrepancy is related to multivariate integration in the worst case and average case settings. Indeed, discrepancy is an upper bound on the worst case integration error of functions whose variation in the sense of Hardy and Krause is at most one, see e.g., <ref> [2, 8, 9, 13] </ref>.
Reference: [3] <author> B. Chazelle, </author> <title> Geometric Discrepancy Revisited, </title> <booktitle> 34th Annual Symposium on Foundations of Computer Science, p. </booktitle> <pages> 392-399, </pages> <year> 1993. </year>
Reference-contexts: Discrepancy has been recently applied in computer science, see <ref> [3, 4, 7] </ref> and the references given there. Discrepancy is related to multivariate integration in the worst case and average case settings.
Reference: [4] <author> D. P. Dobkin and D. P. Mitchell, </author> <title> Random-Edge Discrepancy of Supersampling Patterns, Graphics Interface '93, </title> <address> York, Ontario, </address> <year> 1993. </year>
Reference-contexts: Discrepancy has been recently applied in computer science, see <ref> [3, 4, 7] </ref> and the references given there. Discrepancy is related to multivariate integration in the worst case and average case settings.
Reference: [5] <author> K. K. Frolov, </author> <title> Upper bounds on discrepancy in L p , 2 p 1, </title> <journal> Dokl. Akad. Nauk SSSR, </journal> <volume> 252, </volume> <pages> p. 805-807, </pages> <year> 1980. </year>
Reference-contexts: The asymptotic behavior of n ("; d) for a fixed d and " tending to zero is known, n ("; d) = fi " 1 (log 1=") (d1)=2 ; (4) see [10] for the proof of a lower bound, and <ref> [5, 11] </ref> for the proof of an upper bound. However, the multiplicative factor in the fi-notation is an unknown function of d.
Reference: [6] <author> S. Heinrich, </author> <title> Efficient algorithms for computing the L 2 discrepancy, </title> <journal> Math. of Computation, </journal> <note> 1995, to appear. 9 </note>
Reference-contexts: Key words: discrepancy, multivariate integration, average case. The first author was partially supported by the the National Science Foundation under Grant CCR-9420543, and the second by the National Science Foundation and the Air Force Office of Scientific Research. 1 discrepancy of n given points are given in <ref> [6] </ref>. Discrepancy has been recently applied in computer science, see [3, 4, 7] and the references given there. Discrepancy is related to multivariate integration in the worst case and average case settings.
Reference: [7] <author> S. Heinrich and A. Keller, </author> <title> Quasi-Monte Carlo methods in computer graphics, Part I: The QMC-Buffer, </title> <type> Report, </type> <institution> Univ. of Kaiserslautern, Dept. Computer Science, Report No.242/1994; Part II: The radiance equation, </institution> <type> Report, </type> <institution> Univ. of Kaiserslautern, Dept. Computer Science, </institution> <note> Report No.243/1994. </note>
Reference-contexts: Discrepancy has been recently applied in computer science, see <ref> [3, 4, 7] </ref> and the references given there. Discrepancy is related to multivariate integration in the worst case and average case settings.
Reference: [8] <author> H. Niederreiter, </author> <title> Quasi-Monte Carlo methods and pseudo-random numbers, </title> <journal> Bull, Amer. Math. Soc., </journal> <volume> 84, </volume> <pages> p. 957-1041, </pages> <year> 1978. </year>
Reference-contexts: 1 Introduction We study discrepancy with arbitrary weights in the L 2 norm over the d dimensional unit cube [0; 1] d . This problem is defined as finding n points from [0; 1] d which approximate the volumes of rectangles (starting from zero) with minimal error, see <ref> [8, 9] </ref> for the precise definition, history and basic properties. Discrepancy has been extensively studied in number theory and numerical analysis, see e.g., [1, 8, 9, 10, 11, 12]. Fast algorithms for computing fl 1991 Math. Subject Classification: Primary 11K38, 41A55. Key words: discrepancy, multivariate integration, average case. <p> This problem is defined as finding n points from [0; 1] d which approximate the volumes of rectangles (starting from zero) with minimal error, see [8, 9] for the precise definition, history and basic properties. Discrepancy has been extensively studied in number theory and numerical analysis, see e.g., <ref> [1, 8, 9, 10, 11, 12] </ref>. Fast algorithms for computing fl 1991 Math. Subject Classification: Primary 11K38, 41A55. Key words: discrepancy, multivariate integration, average case. <p> Discrepancy is related to multivariate integration in the worst case and average case settings. Indeed, discrepancy is an upper bound on the worst case integration error of functions whose variation in the sense of Hardy and Krause is at most one, see e.g., <ref> [2, 8, 9, 13] </ref>. <p> A thorough discussion on discrepancy may be found in <ref> [8, 9] </ref>. Consider n points z 1 ; z 2 ; : : : ; z n from [0; 1] d .
Reference: [9] <author> H. Niederreiter, </author> <title> Random Number Generation and Quasi-Monte Carlo Methods, </title> <journal> CBMS-NSF Reg. Conf. Series Appl. Math., </journal> <volume> 63, </volume> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction We study discrepancy with arbitrary weights in the L 2 norm over the d dimensional unit cube [0; 1] d . This problem is defined as finding n points from [0; 1] d which approximate the volumes of rectangles (starting from zero) with minimal error, see <ref> [8, 9] </ref> for the precise definition, history and basic properties. Discrepancy has been extensively studied in number theory and numerical analysis, see e.g., [1, 8, 9, 10, 11, 12]. Fast algorithms for computing fl 1991 Math. Subject Classification: Primary 11K38, 41A55. Key words: discrepancy, multivariate integration, average case. <p> This problem is defined as finding n points from [0; 1] d which approximate the volumes of rectangles (starting from zero) with minimal error, see [8, 9] for the precise definition, history and basic properties. Discrepancy has been extensively studied in number theory and numerical analysis, see e.g., <ref> [1, 8, 9, 10, 11, 12] </ref>. Fast algorithms for computing fl 1991 Math. Subject Classification: Primary 11K38, 41A55. Key words: discrepancy, multivariate integration, average case. <p> Discrepancy is related to multivariate integration in the worst case and average case settings. Indeed, discrepancy is an upper bound on the worst case integration error of functions whose variation in the sense of Hardy and Krause is at most one, see e.g., <ref> [2, 8, 9, 13] </ref>. <p> A thorough discussion on discrepancy may be found in <ref> [8, 9] </ref>. Consider n points z 1 ; z 2 ; : : : ; z n from [0; 1] d .
Reference: [10] <author> K. F. Roth, </author> <title> On irregularities of distribution, </title> <journal> Mathematika, </journal> <volume> 1, </volume> <pages> p. 73-79, </pages> <year> 1954. </year>
Reference-contexts: This problem is defined as finding n points from [0; 1] d which approximate the volumes of rectangles (starting from zero) with minimal error, see [8, 9] for the precise definition, history and basic properties. Discrepancy has been extensively studied in number theory and numerical analysis, see e.g., <ref> [1, 8, 9, 10, 11, 12] </ref>. Fast algorithms for computing fl 1991 Math. Subject Classification: Primary 11K38, 41A55. Key words: discrepancy, multivariate integration, average case. <p> The asymptotic behavior of n ("; d) for a fixed d and " tending to zero is known, n ("; d) = fi " 1 (log 1=") (d1)=2 ; (4) see <ref> [10] </ref> for the proof of a lower bound, and [5, 11] for the proof of an upper bound. However, the multiplicative factor in the fi-notation is an unknown function of d.
Reference: [11] <author> K. F. Roth, </author> <title> On irregularities of distribution, IV, </title> <journal> Acta Arith., </journal> <volume> 37, </volume> <pages> p. 67-75, </pages> <year> 1980. </year>
Reference-contexts: This problem is defined as finding n points from [0; 1] d which approximate the volumes of rectangles (starting from zero) with minimal error, see [8, 9] for the precise definition, history and basic properties. Discrepancy has been extensively studied in number theory and numerical analysis, see e.g., <ref> [1, 8, 9, 10, 11, 12] </ref>. Fast algorithms for computing fl 1991 Math. Subject Classification: Primary 11K38, 41A55. Key words: discrepancy, multivariate integration, average case. <p> The asymptotic behavior of n ("; d) for a fixed d and " tending to zero is known, n ("; d) = fi " 1 (log 1=") (d1)=2 ; (4) see [10] for the proof of a lower bound, and <ref> [5, 11] </ref> for the proof of an upper bound. However, the multiplicative factor in the fi-notation is an unknown function of d.
Reference: [12] <author> I. H. Sloan and S. </author> <title> Joe Lattice methods for multiple integration, </title> <publisher> Oxford Science Publication, Oxford, </publisher> <year> 1994. </year>
Reference-contexts: This problem is defined as finding n points from [0; 1] d which approximate the volumes of rectangles (starting from zero) with minimal error, see [8, 9] for the precise definition, history and basic properties. Discrepancy has been extensively studied in number theory and numerical analysis, see e.g., <ref> [1, 8, 9, 10, 11, 12] </ref>. Fast algorithms for computing fl 1991 Math. Subject Classification: Primary 11K38, 41A55. Key words: discrepancy, multivariate integration, average case.
Reference: [13] <author> V. N. Temlyakov, </author> <title> Approximation of Functions with Bounded Mixed Derivatives, </title> <booktitle> Proc. </booktitle> <institution> Steklov Inst. Math, Moscow, </institution> <year> 1989. </year>
Reference-contexts: Discrepancy is related to multivariate integration in the worst case and average case settings. Indeed, discrepancy is an upper bound on the worst case integration error of functions whose variation in the sense of Hardy and Krause is at most one, see e.g., <ref> [2, 8, 9, 13] </ref>.
Reference: [14] <author> G. W. Wasilkowski and H. Wozniakowski, </author> <title> Explicit cost bounds of algorithms for mul-tivariate tensor product problems, </title> <journal> J. Complexity, </journal> <volume> 11, </volume> <pages> p. 1-56, </pages> <year> 1995 </year>
Reference-contexts: However, the multiplicative factor in the fi-notation is an unknown function of d. A constructive bound on n ("; d) with explicit dependence on d is given in Section 8.3 of <ref> [14] </ref>, n ("; d) 3:304 1:77959 + 2:714 d 1 1 ; (5) and this is achieved by hyperbolic cross points. <p> From (2) and (5) it follows, see Section 8.3 of <ref> [14] </ref>, that n ("; d) 7:26 " 2:454 : Hence, the known constructive bound 1 on p fl is p fl 2:454: (8) In this paper, we improve the upper bound by showing the following estimate. <p> We now take the expectation with respect to f . The expected variance of f f n is equal to the average case error of approximation between f and f n . The explicit formula for this is derived in Section 8.4 of <ref> [14] </ref>. Finally, we use a well-known fact that randomization does not help in the average case setting to conclude the existence of 2n + 1 points with the needed bound on discrepancy. Since we use the Monte Carlo algorithm in one step, the proof of (9) is not constructive. <p> Since we use the Monte Carlo algorithm in one step, the proof of (9) is not constructive. Hence, the constructive bound (8) remains unimproved. 1 In Section 8.2 of <ref> [14] </ref> we mentioned that the exponent p = 2:454 can be lowered by choosing different parameters of the basic algorithm. <p> Due to (1) and (2), we need only to consider d 2 and " &lt; 3 d=2 . The proof is heavily based on a number of results from <ref> [14] </ref>. <p> special algorithm A n () for approximating f 2 F = C ([0; 1] d ); e 2 Z Z (f (t) A n (f )(t)) dt w (df ): The approximating function f n = A n (f ) is constructed as in Section 8.4 and Lemma 8 of <ref> [14] </ref> with the parameters F 0 = 1=3, F = 4, D = 1=2, and C = B = 1= p 2. <p> We have checked this approach and, unfortunately, it does not lead to any improvement; n m is optimal. Lemma 8 of <ref> [14] </ref> can be also used for different values of the parameters F 0 ; F; D; C and B. We have checked that the choice reported in the proof leads to the smallest q fl . Remark 3. <p> Remark 3. As mentioned in the introduction, we have also analyzed the exponent for the integration problem in the average case setting with respect to the Brownian bridge. 8 For this problem, the results of <ref> [14] </ref> apply with parameters C = B = 1= p F = 2, and D = 1= 2.
Reference: [15] <author> H. Wozniakowski, </author> <title> Average Case Complexity of Multivariate Integration, </title> <journal> Bull. Amer. Math. Soc. (N.S), </journal> <volume> 24, </volume> <pages> p. 185-194, </pages> <year> 1991. </year> <title> Author's Addresses: Grzegorz W. </title> <type> Wasilkowski, </type> <institution> Department of Computer Science, University of Kentucky, Lexington, KY 40506, USA, email: greg@cs.engr.uky.edu Henryk Wozniakowski, Department of Computer Science, Columbia University, </institution> <address> New York, NY 10027, USA, </address> <institution> and Institute of Applied Mathematics, University of Warsaw, </institution> <address> ul. Banacha 2, 02-097 Warszawa, Poland, email: henryk@cs.columbia.edu 10 </address>
Reference-contexts: Indeed, discrepancy is an upper bound on the worst case integration error of functions whose variation in the sense of Hardy and Krause is at most one, see e.g., [2, 8, 9, 13]. It is also known, see <ref> [15] </ref>, that discrepancy for points x 1 ; x 2 ; : : : ; x n is equal to the average case integration error for the points ~ 1 x 1 ; ~ 1 x 2 ; : : : ; ~ 1 x n , where ~ 1 = <p> Then this integral is (2 d 3 d )=n. Applying the mean value theorem we get (3). We will use a relation between discrepancy and integration in the average case setting, see <ref> [15] </ref>.
References-found: 15

