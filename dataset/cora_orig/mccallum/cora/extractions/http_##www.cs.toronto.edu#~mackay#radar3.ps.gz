URL: http://www.cs.toronto.edu/~mackay/radar3.ps.gz
Refering-URL: http://www.cs.toronto.edu/~mackay/README.html
Root-URL: http://www.cs.toronto.edu
Title: Bayesian analysis of linear phased-array radar a linear phased-array consisting of equally spaced elements is
Author: Andrew G. Green and David J.C. MacKay 
Note: Here,  
Address: Cambridge, CB3 0HE. United Kingdom.  
Affiliation: Cavendish Laboratory  
Abstract: A number of methods have been developed to analyze the response of the linear phased array radar. These perform remarkably well when the number of sources is known, but in cases where a determination of this number is required, problems are often encountered. These problems can be resolved by a Bayesian approach. Tests using model data showed that performance at the second level of inference is critically determined by the accuracy of position estimation. If adequate parameter optimization is available, the Bayesian approach is demonstrated to work well, even in extreme circumstances. A commonly employed method of source location, noise subspace eigenanalysis of the correlation matrix, was tried and found to be inadequate. A Newton-Raphson optimization was then used starting from the positions predicted by eigenanalysis. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Reilly, J. Litva, P. Bauman, </author> <title> "New Angle-of-Arrival Estimator : Comparative Evaluation Applied to the Low Angle Tracking Problem", </title> <journal> proc. IEEE 135F, </journal> <volume> 5, </volume> <year> 1988. </year>
Reference-contexts: 1 Introduction We investigate the analysis of data from linear phased-array radar. Recent improvements in the speed of computers have made feasible the real-time use of more sophisticated methods than simple beam-sweep methods. One technique of interest is noise sub-space eigen-analysis of the correlation matrix <ref> [1] </ref>. This is one of a class of algorithms commonly known as super-resolution methods, because of their ability to resolve sources below the Rayleigh criterion [2, 3]. The merits of Bayesian inference have been demonstrated in many diverse fields of data analysis [4, 5, 6, 7]. <p> The method described in brief below, due to Reilly et al. <ref> [1] </ref>, is one of several super-resolution algorithms known as "maximum likelihood". These can be shown to depend upon the orthogonality relationship given at the end of this section [2, 3].
Reference: [2] <author> S.M. Kay, </author> <title> S.L. Marple, "Spectrum Analysis : A Modern Perspective", </title> <booktitle> proc. IEEE 69, </booktitle> <volume> 11, </volume> <year> 1981. </year>
Reference-contexts: One technique of interest is noise sub-space eigen-analysis of the correlation matrix [1]. This is one of a class of algorithms commonly known as super-resolution methods, because of their ability to resolve sources below the Rayleigh criterion <ref> [2, 3] </ref>. The merits of Bayesian inference have been demonstrated in many diverse fields of data analysis [4, 5, 6, 7]. Here, the improvements which may be made to position inference by eigen-analysis, with the application of Bayesian methods, is assessed. <p> We have, therefore, a single position vector OE for all snapshots and a set of amplitude vectors F s , one for each snapshot. 3 Eigen-analysis of correlation matrix There are a number of inter-related techniques in spectrum analysis based upon the eigen-analysis of the data correlation matrix <ref> [2, 3] </ref>. The method described in brief below, due to Reilly et al. [1], is one of several super-resolution algorithms known as "maximum likelihood". These can be shown to depend upon the orthogonality relationship given at the end of this section [2, 3]. <p> based upon the eigen-analysis of the data correlation matrix <ref> [2, 3] </ref>. The method described in brief below, due to Reilly et al. [1], is one of several super-resolution algorithms known as "maximum likelihood". These can be shown to depend upon the orthogonality relationship given at the end of this section [2, 3]. Bayesian analysis of linear phased-array radar 3 The correlation matrix is formed by taking the outer product of the data vector with itself.
Reference: [3] <author> S. Alaykin, </author> <title> "Adaptive Filter Theory", </title> <publisher> Prentice Hall Information and System Sciences Series. </publisher>
Reference-contexts: One technique of interest is noise sub-space eigen-analysis of the correlation matrix [1]. This is one of a class of algorithms commonly known as super-resolution methods, because of their ability to resolve sources below the Rayleigh criterion <ref> [2, 3] </ref>. The merits of Bayesian inference have been demonstrated in many diverse fields of data analysis [4, 5, 6, 7]. Here, the improvements which may be made to position inference by eigen-analysis, with the application of Bayesian methods, is assessed. <p> We have, therefore, a single position vector OE for all snapshots and a set of amplitude vectors F s , one for each snapshot. 3 Eigen-analysis of correlation matrix There are a number of inter-related techniques in spectrum analysis based upon the eigen-analysis of the data correlation matrix <ref> [2, 3] </ref>. The method described in brief below, due to Reilly et al. [1], is one of several super-resolution algorithms known as "maximum likelihood". These can be shown to depend upon the orthogonality relationship given at the end of this section [2, 3]. <p> based upon the eigen-analysis of the data correlation matrix <ref> [2, 3] </ref>. The method described in brief below, due to Reilly et al. [1], is one of several super-resolution algorithms known as "maximum likelihood". These can be shown to depend upon the orthogonality relationship given at the end of this section [2, 3]. Bayesian analysis of linear phased-array radar 3 The correlation matrix is formed by taking the outer product of the data vector with itself. <p> In this case, taking the Z-transform of the noise eigenvector, one obtains a polynomial whose solutions are z k = exp (iOE k ) for each of the k sources present. There exist more sophisticated ways of averaging R to form an order (k + 1) matrix <ref> [3] </ref>. These have the property of resolving correlated sources (i.e. where F s i is correlated with F s+1 j ) as well as uncorrelated sources. These are disregarded here for simplicity.
Reference: [4] <author> G.L. Bretthorst, </author> <title> "Bayesian Spectrum Analysis and Parameter Estimation", </title> <booktitle> Lecture notes in statistics, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: This is one of a class of algorithms commonly known as super-resolution methods, because of their ability to resolve sources below the Rayleigh criterion [2, 3]. The merits of Bayesian inference have been demonstrated in many diverse fields of data analysis <ref> [4, 5, 6, 7] </ref>. Here, the improvements which may be made to position inference by eigen-analysis, with the application of Bayesian methods, is assessed. The locations of a finite number of sources are inferred, with error bars, by maximizing the integrated posterior probability.
Reference: [5] <author> S.F. </author> <title> Gull, "Bayesian Inductive Inference and Maximum Entropy", </title> <booktitle> in Maximum Entropy and Bayesian Methods in Science and Engineering, </booktitle> <volume> Vol. 1, </volume> <booktitle> Foundations, </booktitle> <editor> ed. G.J. Erickson and C.R. </editor> <volume> Smith, </volume> <pages> pp. 53-74, </pages> <publisher> Kluwer, </publisher> <year> 1988. </year>
Reference-contexts: This is one of a class of algorithms commonly known as super-resolution methods, because of their ability to resolve sources below the Rayleigh criterion [2, 3]. The merits of Bayesian inference have been demonstrated in many diverse fields of data analysis <ref> [4, 5, 6, 7] </ref>. Here, the improvements which may be made to position inference by eigen-analysis, with the application of Bayesian methods, is assessed. The locations of a finite number of sources are inferred, with error bars, by maximizing the integrated posterior probability.
Reference: [6] <author> E.T. Jaynes, </author> <title> "Bayesian Methods : General Background", in Maximum Entropy and Bayesian methods in applied statistics, </title> <editor> ed. J.H. Justice. pp.1-25. C.U.P. </editor> <year> 1986. </year>
Reference-contexts: This is one of a class of algorithms commonly known as super-resolution methods, because of their ability to resolve sources below the Rayleigh criterion [2, 3]. The merits of Bayesian inference have been demonstrated in many diverse fields of data analysis <ref> [4, 5, 6, 7] </ref>. Here, the improvements which may be made to position inference by eigen-analysis, with the application of Bayesian methods, is assessed. The locations of a finite number of sources are inferred, with error bars, by maximizing the integrated posterior probability.
Reference: [7] <author> D.J.C. MacKay, </author> <title> "Bayesian Interpolation", </title> <booktitle> Neural Computation 4, </booktitle> <pages> 415-447, </pages> <year> 1992. </year>
Reference-contexts: This is one of a class of algorithms commonly known as super-resolution methods, because of their ability to resolve sources below the Rayleigh criterion [2, 3]. The merits of Bayesian inference have been demonstrated in many diverse fields of data analysis <ref> [4, 5, 6, 7] </ref>. Here, the improvements which may be made to position inference by eigen-analysis, with the application of Bayesian methods, is assessed. The locations of a finite number of sources are inferred, with error bars, by maximizing the integrated posterior probability.
Reference: [8] <author> J.P. Burg, D.G. Luenberger, D.L. Wenger, </author> <title> "Estimation of Structured Covariance Matrices", </title> <booktitle> proc. IEEE 70, </booktitle> <volume> 9, </volume> <year> 1982. </year>
Reference-contexts: These have the property of resolving correlated sources (i.e. where F s i is correlated with F s+1 j ) as well as uncorrelated sources. These are disregarded here for simplicity. An alternative method due to Burg et al. <ref> [8] </ref> involves finding the maximum likelihood Toeplitz structure matrix from the data. 4 Bayesian analysis Single snapshot The inferred parameters divide naturally into: the source amplitudes fF s g (which are different for each snapshot), the source positions OE, and the number of sources k, (specified by the hypothesis H ).
References-found: 8

