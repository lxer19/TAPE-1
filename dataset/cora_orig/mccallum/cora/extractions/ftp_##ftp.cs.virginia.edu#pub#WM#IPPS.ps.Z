URL: ftp://ftp.cs.virginia.edu/pub/WM/IPPS.ps.Z
Refering-URL: http://www.cs.virginia.edu/~wm/smc.html
Root-URL: http://www.cs.virginia.edu
Title: Abstract  
Abstract: The growing disparity between processor and memory speeds has caused memory bandwidth to become the performance bottleneck for many applications. In particular, this performance gap severely impacts stream-orientated computations such as (de)compression, encryption, and scientific vector processing. This paper describes the development of an intelligent memory interface that can exploit compiler-provided information on streamed memory access patterns to improve memory bandwidth. Simulation results show that such shared-memory multiprocessor systems can deliver nearly the full attainable bandwidth with relatively modest hardware costs. 
Abstract-found: 1
Intro-found: 1
Reference: [Bae91] <author> J.L. Baer, T.F. Chen, </author> <title> An Effective On-Chip Preloading Scheme To Reduce Data Access Penalty, </title> <booktitle> Proc. </booktitle> <address> Supercomputing91, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: In addition to traditional caching, other proposed solutions range from software prefetching [Cal91, Mow92] and iteration space tiling [Car89, Lam91, Wol89], to address transformations [Har89], unusual memory systems [Gao93, Rau91, Val92], and prefetching hardware or non-blocking caches <ref> [Bae91, Che92, Soh91, Chi94, Jou90] </ref>. Most of these schemes simply mask latency without increasing effective bandwidth. They are still useful, but will be most effective when combined with complementary technology to take advantage of memory component capabilities.
Reference: [Ben91] <author> M.E. Benitez, J.W. Davidson, </author> <title> Code Generation for Streaming: An Access/Execute Mechanism, </title> <booktitle> Proc. </booktitle> <address> ASPLOS-IV, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: These limitations motivated us to consider an implementation that dynamically reorders accesses at run-time. Benitez and Davidsons algorithm can be used to detect streams at compile-time <ref> [Ben91] </ref>, and the stream parameters can be transmitted to the reordering hardware at run-time. Our analysis is based on the simplified architecture of memory through a centralized controller, or Memory Memory Scheduling Unit (MSU) Stream FIFO FIFO CPU Unit CPU CACHE CACHE MEM MEM Buffer Scheduling Unit (MSU).
Reference: [Bur95] <author> D.C. Burger, J.R. Goodman, A. Kagi, </author> <title> The Declining Effectiveness of Dynamic Caching for General-Purpose Microprocessors, </title> <institution> Univ. of Wisconsin, Department of Computer Science, </institution> <type> Technical Report 1261, </type> <month> February </month> <year> 1995. </year>
Reference-contexts: Caching has often been used to bridge the gap between microprocessor and DRAM performance, but as the memory bandwidth problem grows, the effectiveness of the technique is rapidly diminishing <ref> [Bur95, Wul95] </ref>. Even if the addition of cache memory is a sufficient solution for general-purpose scalar computing (and some portions of streaming computations), its effectiveness for vector processing is still subject to debate.
Reference: [Cal91] <author> D. Callahan, K. Kennedy, A. Porterfield, </author> <title> Software Prefetching, </title> <booktitle> Proc. </booktitle> <address> ASPLOS-IV, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: For long-vector computations exhibiting a high degree of DRAM page-sharing, the SMC can deliver nearly the full system bandwidth. 3. The SMC There are many ways to approach the bandwidth problem, either in hardware or software. In addition to traditional caching, other proposed solutions range from software prefetching <ref> [Cal91, Mow92] </ref> and iteration space tiling [Car89, Lam91, Wol89], to address transformations [Har89], unusual memory systems [Gao93, Rau91, Val92], and prefetching hardware or non-blocking caches [Bae91, Che92, Soh91, Chi94, Jou90]. Most of these schemes simply mask latency without increasing effective bandwidth.
Reference: [Car89] <author> S. Carr, K. Kennedy, </author> <title> Blocking Linear Algebra Codes for Memory Hierarchies, </title> <booktitle> Proc. Fourth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <year> 1989. </year>
Reference-contexts: The SMC There are many ways to approach the bandwidth problem, either in hardware or software. In addition to traditional caching, other proposed solutions range from software prefetching [Cal91, Mow92] and iteration space tiling <ref> [Car89, Lam91, Wol89] </ref>, to address transformations [Har89], unusual memory systems [Gao93, Rau91, Val92], and prefetching hardware or non-blocking caches [Bae91, Che92, Soh91, Chi94, Jou90]. Most of these schemes simply mask latency without increasing effective bandwidth.
Reference: [Chi94] <author> T. Chiueh, </author> <title> Sunder: A Programmable Hardware Prefetch Architecture for Numerical Loops, </title> <booktitle> Proc. Supercomputing 94, </booktitle> <month> November </month> <year> 1994. </year>
Reference-contexts: In addition to traditional caching, other proposed solutions range from software prefetching [Cal91, Mow92] and iteration space tiling [Car89, Lam91, Wol89], to address transformations [Har89], unusual memory systems [Gao93, Rau91, Val92], and prefetching hardware or non-blocking caches <ref> [Bae91, Che92, Soh91, Chi94, Jou90] </ref>. Most of these schemes simply mask latency without increasing effective bandwidth. They are still useful, but will be most effective when combined with complementary technology to take advantage of memory component capabilities.
Reference: [Gao93] <author> Q.S. Gao, </author> <title> The Chinese Remainder Theorem and the Prime Memory System, </title> <booktitle> Proc. 20th ISCA, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: The SMC There are many ways to approach the bandwidth problem, either in hardware or software. In addition to traditional caching, other proposed solutions range from software prefetching [Cal91, Mow92] and iteration space tiling [Car89, Lam91, Wol89], to address transformations [Har89], unusual memory systems <ref> [Gao93, Rau91, Val92] </ref>, and prefetching hardware or non-blocking caches [Bae91, Che92, Soh91, Chi94, Jou90]. Most of these schemes simply mask latency without increasing effective bandwidth. They are still useful, but will be most effective when combined with complementary technology to take advantage of memory component capabilities.
Reference: [Har89] <author> D.T. Harper, </author> <title> Address Transformation to Increase Memory Performance, </title> <booktitle> Proc. 1989 International Conference on Supercomputing. </booktitle>
Reference-contexts: The SMC There are many ways to approach the bandwidth problem, either in hardware or software. In addition to traditional caching, other proposed solutions range from software prefetching [Cal91, Mow92] and iteration space tiling [Car89, Lam91, Wol89], to address transformations <ref> [Har89] </ref>, unusual memory systems [Gao93, Rau91, Val92], and prefetching hardware or non-blocking caches [Bae91, Che92, Soh91, Chi94, Jou90]. Most of these schemes simply mask latency without increasing effective bandwidth. They are still useful, but will be most effective when combined with complementary technology to take advantage of memory component capabilities.
Reference: [IEE92] <author> High-speed DRAMs, </author> <title> Special Report, </title> <journal> IEEE Spectrum, </journal> <volume> vol. 29, no. 10, </volume> <month> October </month> <year> 1992. </year>
Reference-contexts: Order matters at an even lower level, too: most memory devices manufactured in the last decade provide special features (nibble-mode, static column mode, or a small amount of SRAM cache on chip) or exhibit novel organizations (such as Rambus, Ramlink, and synchronous DRAM designs <ref> [IEE92] </ref>) that make it possible to perform some access sequences faster than others. Effective bandwidth can be increased by arranging requests to take advantage of these capabilities. Here we focus on fast-page mode devices, which behave as if they were implemented with a single on-chip cache line, or page.
Reference: [Jou90] <author> N. Jouppi, </author> <title> Improving Direct-Mapped Cache Performance by the Addition of a Small Fully Associative Cache and Prefetch Buffers, </title> <booktitle> Proc. 17th ISCA, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: In addition to traditional caching, other proposed solutions range from software prefetching [Cal91, Mow92] and iteration space tiling [Car89, Lam91, Wol89], to address transformations [Har89], unusual memory systems [Gao93, Rau91, Val92], and prefetching hardware or non-blocking caches <ref> [Bae91, Che92, Soh91, Chi94, Jou90] </ref>. Most of these schemes simply mask latency without increasing effective bandwidth. They are still useful, but will be most effective when combined with complementary technology to take advantage of memory component capabilities.
Reference: [Lam91] <author> M. Lam, E. Rothberg, M. Wolf, </author> <title> The Cache Performance and Optimizations of Blocked Algorithms, </title> <booktitle> Proc. </booktitle> <address> ASPLOS-IV, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: The SMC There are many ways to approach the bandwidth problem, either in hardware or software. In addition to traditional caching, other proposed solutions range from software prefetching [Cal91, Mow92] and iteration space tiling <ref> [Car89, Lam91, Wol89] </ref>, to address transformations [Har89], unusual memory systems [Gao93, Rau91, Val92], and prefetching hardware or non-blocking caches [Bae91, Che92, Soh91, Chi94, Jou90]. Most of these schemes simply mask latency without increasing effective bandwidth.
Reference: [Lee93] <author> K. Lee, </author> <title> The NAS860 Library Users Manual, </title> <type> NAS TR RND-93-003, </type> <institution> NASA Ames Research Center, Moffett Field, </institution> <address> CA, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: Software access-ordering techniques range from Moyers algorithms for non-caching register loads [Moy93] to schemes that stream vector data into the cache, explicitly managing it as a fast local memory <ref> [Lee93, Mea92, Pal95] </ref>. We have studied access-ordering in depth [McK95], developing performance bounds for these and other access-ordering schemes. Compile-time approaches are limited by contention for processor resources (e.g., register pressure or cache conicts) and the lack of data placement and alignment information.
Reference: [LiN94] <author> Z. Li, T.N. Nguyen, </author> <title> An Empirical Study of the Work Load Distribution Under Static Scheduling, </title> <booktitle> Proc. Intl. Conf. on Parallel Processing 1994. </booktitle> <month> [McK94a]S.A. </month> <title> McKee, Experimental Implementation of Dynamic Access Ordering, </title> <booktitle> Proc. 27th Hawaii International Conference on Systems Sciences, </booktitle> <address> Maui, HI, </address> <month> January </month> <year> 1994. </year> <note> [McK94b]S.A. </note> <author> McKee, S.A. Moyer, Wm.A. Wulf, C. Hitchcock, </author> <title> Increasing Memory Bandwidth for Vector Computations, </title> <booktitle> Proc. Programming Languages and System Architectures, </booktitle> <address> Zurich, Switzerland, </address> <month> March </month> <year> 1994. </year> <note> [McK95]S.A. McKee, http://www.cs.virginia.edu/~wm/ smc.html. </note>
Reference-contexts: If the processors proceed at different rates, some may cross page boundaries slightly sooner than others, but recent empirical studies suggest that the slowest processor is normally not more than the mean execution time of one loop iteration behind the average processor <ref> [LiN94] </ref>. The second strategy we investigate is block scheduling. Here the vector is split into approximately equal-size pieces, and each processor performs the computation on a single piece.
Reference: [Mea92] <author> L. Meadows, et.al., </author> <title> A Vectorizing Software Pipelining Compiler for LIW and Superscalar Architectures, </title> <note> RISC92. </note> <author> [Mow92]T.C. Mowry, M. Lam, A. Gupta, </author> <title> Design and Evaluation of a Compiler Algorithm for Prefetching, </title> <booktitle> Proc. ASPLOS-V, </booktitle> <month> September </month> <year> 1992. </year> <title> [Moy93]S.A. Moyer, Access Ordering and Effective Memory Bandwidth, </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Science, Univ. of Virginia, </institution> <type> Technical Report CS-93-18, </type> <month> April </month> <year> 1993. </year>
Reference-contexts: Software access-ordering techniques range from Moyers algorithms for non-caching register loads [Moy93] to schemes that stream vector data into the cache, explicitly managing it as a fast local memory <ref> [Lee93, Mea92, Pal95] </ref>. We have studied access-ordering in depth [McK95], developing performance bounds for these and other access-ordering schemes. Compile-time approaches are limited by contention for processor resources (e.g., register pressure or cache conicts) and the lack of data placement and alignment information.
Reference: [Pal95] <author> S. Palacharla, R.E. Kessler, </author> <title> Code Restructuring to Exploit Page Mode and Read-Ahead Features of the Cray T3D, </title> <booktitle> work in progress, </booktitle> <month> February </month> <year> 1995. </year>
Reference-contexts: Software access-ordering techniques range from Moyers algorithms for non-caching register loads [Moy93] to schemes that stream vector data into the cache, explicitly managing it as a fast local memory <ref> [Lee93, Mea92, Pal95] </ref>. We have studied access-ordering in depth [McK95], developing performance bounds for these and other access-ordering schemes. Compile-time approaches are limited by contention for processor resources (e.g., register pressure or cache conicts) and the lack of data placement and alignment information.
Reference: [Rau91] <author> B.R. Rau, </author> <title> Pseudo-Randomly Interleaved Memory, </title> <booktitle> Proc. 18th ISCA, </booktitle> <address> Toronto, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: The SMC There are many ways to approach the bandwidth problem, either in hardware or software. In addition to traditional caching, other proposed solutions range from software prefetching [Cal91, Mow92] and iteration space tiling [Car89, Lam91, Wol89], to address transformations [Har89], unusual memory systems <ref> [Gao93, Rau91, Val92] </ref>, and prefetching hardware or non-blocking caches [Bae91, Che92, Soh91, Chi94, Jou90]. Most of these schemes simply mask latency without increasing effective bandwidth. They are still useful, but will be most effective when combined with complementary technology to take advantage of memory component capabilities.
Reference: [Soh91] <author> G. Sohi, M. Franklin, </author> <title> High Bandwidth Memory Systems for Superscalar Processors, </title> <booktitle> Proc. </booktitle> <address> ASPLOS-IV, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: In addition to traditional caching, other proposed solutions range from software prefetching [Cal91, Mow92] and iteration space tiling [Car89, Lam91, Wol89], to address transformations [Har89], unusual memory systems [Gao93, Rau91, Val92], and prefetching hardware or non-blocking caches <ref> [Bae91, Che92, Soh91, Chi94, Jou90] </ref>. Most of these schemes simply mask latency without increasing effective bandwidth. They are still useful, but will be most effective when combined with complementary technology to take advantage of memory component capabilities.
Reference: [Val92] <author> M. Valero, et. al., </author> <title> Increasing the Number of Strides for Conict-Free Vector Access, </title> <booktitle> Proc. 19th ISCA, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: The SMC There are many ways to approach the bandwidth problem, either in hardware or software. In addition to traditional caching, other proposed solutions range from software prefetching [Cal91, Mow92] and iteration space tiling [Car89, Lam91, Wol89], to address transformations [Har89], unusual memory systems <ref> [Gao93, Rau91, Val92] </ref>, and prefetching hardware or non-blocking caches [Bae91, Che92, Soh91, Chi94, Jou90]. Most of these schemes simply mask latency without increasing effective bandwidth. They are still useful, but will be most effective when combined with complementary technology to take advantage of memory component capabilities.
Reference: [Wol89] <author> M. Wolfe, </author> <title> More Iteration Space Tiling, </title> <booktitle> Proc. Supercomputing 89, </booktitle> <year> 1989. </year>
Reference-contexts: The SMC There are many ways to approach the bandwidth problem, either in hardware or software. In addition to traditional caching, other proposed solutions range from software prefetching [Cal91, Mow92] and iteration space tiling <ref> [Car89, Lam91, Wol89] </ref>, to address transformations [Har89], unusual memory systems [Gao93, Rau91, Val92], and prefetching hardware or non-blocking caches [Bae91, Che92, Soh91, Chi94, Jou90]. Most of these schemes simply mask latency without increasing effective bandwidth.
Reference: [Wul95] <author> Wm.A. Wulf, S.A. McKee, </author> <title> Hitting the Wall: Implications of the Obvious, </title> <journal> Comp. Arch.News, </journal> <volume> 23, 1, </volume> <month> March </month> <year> 1994. </year> <title> cyclic block cyclic block cyclic block </title>
Reference-contexts: Caching has often been used to bridge the gap between microprocessor and DRAM performance, but as the memory bandwidth problem grows, the effectiveness of the technique is rapidly diminishing <ref> [Bur95, Wul95] </ref>. Even if the addition of cache memory is a sufficient solution for general-purpose scalar computing (and some portions of streaming computations), its effectiveness for vector processing is still subject to debate.
References-found: 20

