URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1995/TR44.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Email: prakash@cis.ohio-state.edu  michel.raynal@irisa.fr  singhal@cis.ohio-state.edu  
Title: An Efficient Causal Ordering Algorithm for Mobile Computing Environments  
Author: Ravi Prakash S. A. Michel Raynal Mukesh Singhal S. A. 
Keyword: Key words: Causal message ordering, direct dependency, mobile computing.  
Note: U.  U.  
Address: Columbus, OH 43210,  Cedex, France.  Columbus, OH 43210,  
Affiliation: Dept. of Computer and Info. Science The Ohio State University  IRISA Campus de Beaulieu Rennes  Dept. of Computer and Info. Science The Ohio State University  
Abstract: Causal message ordering is required for several distributed applications. In order to preserve causal ordering, only direct dependency information between messages, with respect to the destination process(es), should be sent with each message. By eliminating other kinds of control information from the messages, the communication overheads can be significantly reduced. In this paper we present an algorithm that uses this knowledge to efficiently enforce causal ordering of messages. The proposed algorithm does not require any prior knowledge of the network or communication topology. As computation proceeds, it acquires knowledge of the logical communication topology and is capable of handling dynamically changing multicast communication groups. With regard to communication overheads, the algorithm is optimal for the broadcast communication case. Its energy efficiency and low bandwidth requirement make it suitable for mobile computing systems. We present a strategy that employs the algorithm for causally ordered multicasting of messages in mobile computing environments. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Acharya and B. R. Badrinath. </author> <title> Delivering Multicast Messages in Networks with Mobile Hosts. </title> <booktitle> In Proceedings of the 13 th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 292-299. </pages> <publisher> IEEE, </publisher> <year> 1993. </year>
Reference-contexts: This results in a conservation of the limited energy supply of the MH. The mobility of nodes can lead to complications in causal multicasting of messages <ref> [1] </ref>. An M H that is a destination of a message, and moves from one cell to another, may not have the message delivered to it even though the M SSs in its previous and current cell receive the message. <p> Another issue is how long should the MSSs keep copies of a message before they can be sure that it has been delivered to each intended destination node. An algorithm to deliver exactly one copy of a message to every destination MH has been presented in <ref> [1] </ref>. However, this algorithm does not enforce causal ordering. The algorithm presented in Section 5.2 is combined with the multicasting algorithm [1] to enforce causally ordered multicasting in a mobile computing environment. 8.1 Data Structures and Algorithm Overview The following additional data structures, presented in [1], need to be maintained: M <p> An algorithm to deliver exactly one copy of a message to every destination MH has been presented in <ref> [1] </ref>. However, this algorithm does not enforce causal ordering. The algorithm presented in Section 5.2 is combined with the multicasting algorithm [1] to enforce causally ordered multicasting in a mobile computing environment. 8.1 Data Structures and Algorithm Overview The following additional data structures, presented in [1], need to be maintained: M id : a tuple (M init; M seq) maintained by each M SS. <p> MH has been presented in <ref> [1] </ref>. However, this algorithm does not enforce causal ordering. The algorithm presented in Section 5.2 is combined with the multicasting algorithm [1] to enforce causally ordered multicasting in a mobile computing environment. 8.1 Data Structures and Algorithm Overview The following additional data structures, presented in [1], need to be maintained: M id : a tuple (M init; M seq) maintained by each M SS. M seq is an integer initialized to zero. Each time a message is sent by an M SS, M seq is incremented by one.
Reference: [2] <author> F. Adelstein and M. Singhal. </author> <title> Real-Time Causal Message Ordering in Multimedia Systems. </title> <booktitle> In Proceedings of the 15 th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 36-43, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: A less severe form of ordering of message transmission and reception, called causal ordering, is required for a variety of applications like management of replicated data, observation of a distributed system, resource allocation, multimedia systems, and teleconferencing <ref> [2, 4, 15] </ref>. Protocols to implement causal ordering of messages have been presented in [5, 6, 14, 15, 17]. These protocols have high communication overheads. <p> In Figure 7, when M 1 is delivered to P 4 , P 4 knows that future messages sent to P 2 should be delivered only after M 1 has been delivered to P 2 , i.e., CB 4 <ref> [2] </ref> = f (1; 1)g. M 2 , sent by P 2 to P 3 after the delivery of M 1 to P 2 , carries information about its M 1 's delivery in its causal barrier vector. Specifically, CB M 2 [2] = f (1; 1)g is received with the <p> delivered to P 2 , i.e., CB 4 <ref> [2] </ref> = f (1; 1)g. M 2 , sent by P 2 to P 3 after the delivery of M 1 to P 2 , carries information about its M 1 's delivery in its causal barrier vector. Specifically, CB M 2 [2] = f (1; 1)g is received with the message M 2 at P 3 . So, P 3 stores information about M 1 's delivery at P 2 in its Delivered matrix. <p> So, even though the delivery of M 3 is causally dependent on the delivery of M 1 at P 2 , P 4 does not know about M 1 's delivery at P 2 . Therefore, still CB 4 <ref> [2] </ref> = f (1; 1)g. If P 4 sends a message to P 2 in the future, this redundant constraint will be carried by the message. However, the proposed algorithm is optimal when all communication is in the form of message broadcasting.
Reference: [3] <author> S. Alagar and S. Venkatesan. </author> <title> Causally Ordered Message Delivery in Mobile Systems. </title> <booktitle> In Proceedings of the Workshop on Mobile Computing Systems and Applications, </booktitle> <pages> pages 169-174, </pages> <address> Santa Cruz, </address> <month> December </month> <year> 1994. </year>
Reference-contexts: Resynchronization may contribute towards delays in message communication. Hence, the algorithm is suitable only for those applications where delays and resynchronization messages can be tolerated for reduced overheads in the computation messages. Three algorithms for causal ordering of messages in mobile systems have been described in <ref> [3] </ref>. In the first algorithm each message carries dependency information with respect to all the processes. The algorithm is not scalable due to high communication overheads. 9 The other two algorithms have lower overheads.
Reference: [4] <author> R. Baldoni, A. Mostefaoui, and M. Raynal. </author> <title> Efficient Causally Ordered Communications for Multimedia Real-Time Applications. </title> <booktitle> In Proceedings of the 4 th International Symposium on High Performance Distributed Computing, </booktitle> <pages> pages 140-147, </pages> <address> Washing-ton, D.C., </address> <month> August </month> <year> 1995. </year>
Reference-contexts: A less severe form of ordering of message transmission and reception, called causal ordering, is required for a variety of applications like management of replicated data, observation of a distributed system, resource allocation, multimedia systems, and teleconferencing <ref> [2, 4, 15] </ref>. Protocols to implement causal ordering of messages have been presented in [5, 6, 14, 15, 17]. These protocols have high communication overheads.
Reference: [5] <author> K. Birman and T. Joseph. </author> <title> Reliable Communication in Presence of Failures. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 5(1) </volume> <pages> 47-76, </pages> <month> February </month> <year> 1987. </year> <month> 34 </month>
Reference-contexts: Protocols to implement causal ordering of messages have been presented in <ref> [5, 6, 14, 15, 17] </ref>. These protocols have high communication overheads. <p> Protocols to implement causal ordering of messages have been presented in [5, 6, 14, 15, 17]. These protocols have high communication overheads. For each of these protocols (except <ref> [5] </ref> which is based on message duplication | a high communication overhead approach) the message overhead is at least fi (N 2 ) integers, where N is the number of processes in the system. Hence, the protocols are not scalable. <p> Similarly, DELIV ER events can be subscripted by a process name to indicate where they occur. However, whenever the location of an event is apparent from the context, the subscript will be dropped. 7 3 Previous Work The ISIS system presents the earliest implementation of causal ordering of messages <ref> [5] </ref>. Each message carries with itself all the messages whose transmission causally precedes it. Suppose a message M reaches a destination process and all the messages in its past, meant for the destination process, have already been delivered to the process. Then M is also delivered to the destination process. <p> Then P j does not need information about message M to enforce causal ordering at its site. Thus, a message needs to carry information only about its direct predecessor messages with respect to each of its destination processes. Unlike <ref> [5, 15, 17] </ref>, information about transitive predecessors is not needed. By restricting the dependency information carried by each message, the matrix carried by the messages in [15, 17] becomes quite sparse. Hence, rather than sending the entire matrix, only the non-empty elements are sent.
Reference: [6] <author> K. Birman, A. Schiper, and P. Stephenson. </author> <title> Lightweight Causal and Atomic Broad--cast. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 9(3) </volume> <pages> 272-314, </pages> <year> 1991. </year>
Reference-contexts: Protocols to implement causal ordering of messages have been presented in <ref> [5, 6, 14, 15, 17] </ref>. These protocols have high communication overheads. <p> Therefore, the message overhead of the implementations in [15] and [17] is fi (N 2 ) integers. When a message is always broadcast to all other processes, the matrix reduces to a vector of length N . The protocol currently used by ISIS <ref> [6] </ref> can be seen as an adaptation of the previous one to the case of causal multicasting in overlapping groups.
Reference: [7] <author> M. Callendar. </author> <title> International Standards For Personal Communications. </title> <booktitle> In Proceedings of the 39 th IEEE Vehicular Technology Conference, </booktitle> <pages> pages 722-728, </pages> <year> 1989. </year>
Reference-contexts: Alternatively, an M H can be connected through an access point of the fixed wireline network (referred to as a telepoint <ref> [7] </ref>) for communication purposes. An M H can move out of one cell and into another cell. In such a case the M SS of the old cell has to hand over the responsibilities for the M H's communication to the M SS of the new cell.
Reference: [8] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> MIT Press-McGraw-Hill Book Company, </publisher> <year> 1990. </year>
Reference-contexts: Communication overheads can be reduced by compressing causal information using knowledge about the topology of the underlying communication structure [16]. Let there be an articulation point (vertex in a graph whose removal disconnects the graph <ref> [8] </ref>) in a communication network, and a message sent from one side of the articulation point to the other side. Using causal separators, the message can avoid having to carry all dependencies that exist on the side of its origin to the other side of the articulation point.
Reference: [9] <author> J. Fidge. </author> <title> Timestamps in Message-Passing Systems that Preserve the Partial Ordering. </title> <booktitle> In Proceedings of the 11 th Australian Computer Science Conference, </booktitle> <pages> pages 56-66, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Garbage collection is required from time to time to eliminate the old messages that no longer need to be carried by the new messages. Otherwise, the number of predecessor messages carried by each message will grow indefinitely. The implementation presented in [17] uses vector clocks <ref> [9, 12] </ref>. Unlike the first version of ISIS, each message M carries control information consisting of ordered pairs of the type (destination site, vector time). There can be up to N 1 such ordered pairs with each message.
Reference: [10] <author> T. Imielinski and B. R. Badrinath. </author> <title> Mobile Wireless Computing. </title> <journal> Communications of the ACM, </journal> <volume> 37(10) </volume> <pages> 19-28, </pages> <year> 1994. </year>
Reference-contexts: A mobile computing system is a distributed system consisting of a number of mobile and fixed processing units. The fixed units, henceforth referred to as Mobile Support Stations (M SSs), can communicate with each other through a fixed wireline network <ref> [10] </ref>. The geographical area of the mobile computing system is divided into regions called cells with an M SS in each cell.
Reference: [11] <author> L. Lamport. </author> <title> Time, Clocks and the Ordering of Events in a Distributed System. </title> <journal> Communications of the ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <month> July </month> <year> 1978. </year>
Reference-contexts: An event occurring at a process is causally dependent on every preceding event that has occurred at that process. Causal dependencies between events on different processes are established by message communication. Such dependencies can be expressed using Lamport's happened before relation <ref> [11] </ref>. Two events are said to be mutually concurrent if there is no causal dependency between them. Thus, the happened before relation induces a partial ordering on events based on their causal 3 dependencies. <p> However, information about the order of occurrence of events can be gathered based on the causal dependencies between them. Such dependencies can be expressed using the happened before relation (!) between events. The happened before relation between events has been defined in <ref> [11] </ref> as: * a ! b, if a and b are events in the same process and a occurred before b. * a ! b, if a is the event of sending a message M in a process and b is the event of delivery of the same message to another
Reference: [12] <author> F. Mattern. </author> <title> Virtual Time and Global States of Distributed Systems. </title> <editor> In M.Cosnard et. al., editor, </editor> <booktitle> Proceedings of the Workshop on Parallel and Distributed Algorithm, </booktitle> <pages> pages 215-226. </pages> <publisher> Elsevier Science Publishers B.V.(North-Holland), </publisher> <year> 1989. </year>
Reference-contexts: Garbage collection is required from time to time to eliminate the old messages that no longer need to be carried by the new messages. Otherwise, the number of predecessor messages carried by each message will grow indefinitely. The implementation presented in [17] uses vector clocks <ref> [9, 12] </ref>. Unlike the first version of ISIS, each message M carries control information consisting of ordered pairs of the type (destination site, vector time). There can be up to N 1 such ordered pairs with each message.
Reference: [13] <author> A. Mostefaoui and M. Raynal. </author> <title> Causal Multicasts in Overlapping Groups: Towards a Low Cost Approach. </title> <booktitle> In Proceedings of the 4 th IEEE International Conference on Future Trends in Distributed Computing Systems, </booktitle> <pages> pages 136-142, </pages> <address> Lisbon, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: It requires each message to carry a list of integer vectors; the size of the list is the number of groups and the size of a vector is the number of members in this group. A protocol aimed at reducing this control information has been proposed in <ref> [13] </ref>. In this protocol, each message has to carry only one vector whose size is equal to the number of groups. However, a synchronous execution model is assumed which requires additional resynchronization messages so that events at the processes occur in synchronized phases. <p> As an asynchronous communication model is assumed, synchronization overheads and delays are not involved, unlike the algorithm proposed in <ref> [13] </ref>. The computation overheads at processes, for maintaining causal ordering, are low because processes have to perform only a small number of simple operations like integer comparisons and set operations at the time of sending and delivering messages.
Reference: [14] <author> L. L. Peterson, N. C. Buchholz, and R. D. Schlichting. </author> <title> Preserving and Using Context Information in Interprocess Communication. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(3) </volume> <pages> 217-246, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: Protocols to implement causal ordering of messages have been presented in <ref> [5, 6, 14, 15, 17] </ref>. These protocols have high communication overheads.
Reference: [15] <author> M. Raynal, A. Schiper, and S. Toueg. </author> <title> The causal ordering abstraction and a simple way to implement it. </title> <journal> Information Processing Letters, </journal> <volume> 39(6) </volume> <pages> 343-350, </pages> <year> 1991. </year>
Reference-contexts: A less severe form of ordering of message transmission and reception, called causal ordering, is required for a variety of applications like management of replicated data, observation of a distributed system, resource allocation, multimedia systems, and teleconferencing <ref> [2, 4, 15] </ref>. Protocols to implement causal ordering of messages have been presented in [5, 6, 14, 15, 17]. These protocols have high communication overheads. <p> Protocols to implement causal ordering of messages have been presented in <ref> [5, 6, 14, 15, 17] </ref>. These protocols have high communication overheads. <p> If not, then M is delivered to the destination process. Otherwise, M is buffered at the destination process until all its causal predecessors meant for the destination process have been delivered. In <ref> [15] </ref>, the implementation for causal ordering of messages is similar to the implementation proposed in [17]. <p> Each destination process uses the SEN T matrix received with M to determine if M can be delivered to the destination or if it should be buffered until its causal predecessors meant for the destination are delivered. Therefore, the message overhead of the implementations in <ref> [15] </ref> and [17] is fi (N 2 ) integers. When a message is always broadcast to all other processes, the matrix reduces to a vector of length N . <p> Then P j does not need information about message M to enforce causal ordering at its site. Thus, a message needs to carry information only about its direct predecessor messages with respect to each of its destination processes. Unlike <ref> [5, 15, 17] </ref>, information about transitive predecessors is not needed. By restricting the dependency information carried by each message, the matrix carried by the messages in [15, 17] becomes quite sparse. Hence, rather than sending the entire matrix, only the non-empty elements are sent. <p> Thus, a message needs to carry information only about its direct predecessor messages with respect to each of its destination processes. Unlike [5, 15, 17], information about transitive predecessors is not needed. By restricting the dependency information carried by each message, the matrix carried by the messages in <ref> [15, 17] </ref> becomes quite sparse. Hence, rather than sending the entire matrix, only the non-empty elements are sent. This leads to a reduction in communication overheads. <p> Transitivity of the causality relationship ensures the causal ordering is enforced for all the messages in the distributed application. Liveness Property Theorem 2 The algorithm ensures that every message is eventually delivered to its des tination process (es). Proof: The proof is similar to the liveness proof presented in <ref> [15] </ref>. A message M received by process P i can be delivered to the process as soon as the conditional wait specified in Step 1 of Message Reception is over. Consider all the messages that have not been delivered to process P i . <p> the assumption that among the undelivered messages to P i , M 0 's SEND event does not have a predecessor. 26 7 Discussion 7.1 Comparison with Related Work The communication overheads of previous algorithms to implement causal ordering is high because at least an N fi N integer matrix <ref> [15] </ref> or N 1 vector clock (each with N integer components) [17] are sent with every message. These matrices and vector sets contain information about the direct as well as transitive causal predecessors of a message.
Reference: [16] <author> L. Rodrigues and P. Verissimo. </author> <title> Causal Separators for Large-Scale Multicast Communication. </title> <booktitle> In Proceedings of the 15 th IEEE International Conference on Distributed Computing Systems, </booktitle> <pages> pages 83-91, </pages> <address> Vancouver, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Hence, there is a need for algorithms that minimize the communication overheads as well as the delays in message delivery. Communication overheads can be reduced by compressing causal information using knowledge about the topology of the underlying communication structure <ref> [16] </ref>. Let there be an articulation point (vertex in a graph whose removal disconnects the graph [8]) in a communication network, and a message sent from one side of the articulation point to the other side.
Reference: [17] <author> A. Schiper, J. Eggli, and A. Sandoz. </author> <title> A New Algorithm To Implement Causal Ordering. </title> <booktitle> In Proceedings of the 3 rd International Workshop on Distributed Algorithms, LNCS-392, </booktitle> <pages> pages 219-232, </pages> <address> Berlin, 1989. </address> <publisher> Springer. </publisher>
Reference-contexts: Protocols to implement causal ordering of messages have been presented in <ref> [5, 6, 14, 15, 17] </ref>. These protocols have high communication overheads. <p> Then M is delivered to the destination. Garbage collection is required from time to time to eliminate the old messages that no longer need to be carried by the new messages. Otherwise, the number of predecessor messages carried by each message will grow indefinitely. The implementation presented in <ref> [17] </ref> uses vector clocks [9, 12]. Unlike the first version of ISIS, each message M carries control information consisting of ordered pairs of the type (destination site, vector time). There can be up to N 1 such ordered pairs with each message. <p> If not, then M is delivered to the destination process. Otherwise, M is buffered at the destination process until all its causal predecessors meant for the destination process have been delivered. In [15], the implementation for causal ordering of messages is similar to the implementation proposed in <ref> [17] </ref>. <p> Each destination process uses the SEN T matrix received with M to determine if M can be delivered to the destination or if it should be buffered until its causal predecessors meant for the destination are delivered. Therefore, the message overhead of the implementations in [15] and <ref> [17] </ref> is fi (N 2 ) integers. When a message is always broadcast to all other processes, the matrix reduces to a vector of length N . <p> Then P j does not need information about message M to enforce causal ordering at its site. Thus, a message needs to carry information only about its direct predecessor messages with respect to each of its destination processes. Unlike <ref> [5, 15, 17] </ref>, information about transitive predecessors is not needed. By restricting the dependency information carried by each message, the matrix carried by the messages in [15, 17] becomes quite sparse. Hence, rather than sending the entire matrix, only the non-empty elements are sent. <p> Thus, a message needs to carry information only about its direct predecessor messages with respect to each of its destination processes. Unlike [5, 15, 17], information about transitive predecessors is not needed. By restricting the dependency information carried by each message, the matrix carried by the messages in <ref> [15, 17] </ref> becomes quite sparse. Hence, rather than sending the entire matrix, only the non-empty elements are sent. This leads to a reduction in communication overheads. <p> M 0 's SEND event does not have a predecessor. 26 7 Discussion 7.1 Comparison with Related Work The communication overheads of previous algorithms to implement causal ordering is high because at least an N fi N integer matrix [15] or N 1 vector clock (each with N integer components) <ref> [17] </ref> are sent with every message. These matrices and vector sets contain information about the direct as well as transitive causal predecessors of a message. In the proposed algorithm, a message carries information only about its direct predecessors with respect to each destination process. Hence, the communication overheads are low.
Reference: [18] <author> T. S. Soneoka and T. Ibaraki. </author> <title> Logically Instantaneous Message Passing in Asynchronous Distributed Systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 43(5) </volume> <pages> 513-527, </pages> <month> May </month> <year> 1994. </year> <month> 35 </month>
Reference-contexts: Thus, the happened before relation induces a partial ordering on events based on their causal 3 dependencies. Controlling the execution of a distributed application such that all the events are totally ordered is expensive and leads to a loss in concurrency <ref> [18] </ref>. A less severe form of ordering of message transmission and reception, called causal ordering, is required for a variety of applications like management of replicated data, observation of a distributed system, resource allocation, multimedia systems, and teleconferencing [2, 4, 15].
References-found: 18

