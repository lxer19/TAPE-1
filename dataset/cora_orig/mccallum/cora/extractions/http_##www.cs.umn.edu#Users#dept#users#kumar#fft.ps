URL: http://www.cs.umn.edu/Users/dept/users/kumar/fft.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Email: agupta@cs.umn.edu kumar@cs.umn.edu  
Title: The Scalability of FFT on Parallel Computers  
Author: Anshul Gupta and Vipin Kumar 
Address: Minneapolis, MN 55455  
Affiliation: Department of Computer Science, University of Minnesota  
Date: 4(8), August 1993.  TR 90-53, October 1990, (Revised October 1992)  
Note: Appears in IEEE Transactions on Parallel and Distributed Systems, Volume  This work was supported by IST/SDIO through the Army Research Office grant 28408-MA-SDI to the University of Minnesota and by the University of Minnesota Army High Performance Computing Research Center under contract DAAL03-89-C-0038.  
Abstract: In this paper, we present the scalability analysis of parallel Fast Fourier Transform algorithm on mesh and hypercube connected multicomputers using the isoefficiency metric. The isoefficiency function of an algorithm architecture combination is defined as the rate at which the problem size should grow with the number of processors to maintain a fixed efficiency. On the hypercube architecture, a commonly used parallel FFT algorithm can obtain linearly increasing speedup with respect to the number of processors with only a moderate increase in problem size. But there is a limit on the achievable efficiency and this limit is determined by the ratio of CPU speed and communication bandwidth of the hypercube channels. Efficiencies higher than this threshold value can be obtained if the problem size is increased very rapidly. If the hardware supports cut-through routing, then this threshold can also be overcome by using an alternate less scalable parallel formulation. The scalability analysis for the mesh connected multicomputers reveals that FFT cannot make efficient use of large-scale mesh architectures unless the bandwidth of the communication channels is increased as a function of the number of processors. We also show that it is more cost-effective to implement the FFT algorithm on a hypercube rather than a mesh despite the fact that large scale meshes are cheaper to construct than large hypercubes. Although the scope of this paper is limited to the Cooley-Tukey FFT algorithm on a few classes of architectures, the methodology can be used to study the performance of various FFT algorithms on a variety of architectures such as SIMD hypercube and mesh architectures and shared memory architecture. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alok Aggarwal, Ashok K. Chandra, and Mark Snir. </author> <title> Communication complexity of PRAMs. </title> <type> Technical Report RC 14998 (No. 64644), </type> <institution> IBM T. J. Watson Research Center, </institution> <address> Yorktown Heights, NY, Yorktown Heights, NY, </address> <year> 1989. </year>
Reference-contexts: Following the methodology in our paper, these expressions can be used to compute the scalability of FFT on shared memory systems for various mappings of data. Chandra, Snir and Aggarwal <ref> [1] </ref> analyze the performance of FFT and other algorithms on LPRAM anew model for parallel computation. This model differs from the standard PRAM model as the remote accesses are more expensive than local accesses.
Reference: [2] <author> A. V. Aho, John E. Hopcroft, and J. D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1974. </year>
Reference-contexts: Also, we assume that a processor can send or receive on only one of its ports at a time, although the ports on which it sends and receives can be different. 3 The FFT Algorithm adapted from <ref> [2, 36] </ref>. X is the input vector of length n (n = 2 r for some integer r ) and Y is its Fourier Transform. ! k denotes the complex number e j 2 n k , where j = p 1.
Reference: [3] <author> S. G. Akl. </author> <title> The Design and Analysis of Parallel Algorithms. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1989. </year> <month> 17 </month>
Reference-contexts: The scalability analysis of FFT on hypercube provides several important insights. On the hypercube architecture, a commonly used parallel formulation of the FFT algorithm (which we shall refer to as the binary-exchange algorithm in the rest of the paper) <ref> [3, 4, 6, 11, 21, 32, 41, 36, 31] </ref> can obtain linearly increasing speedup with respect to the number of processors with only a moderate increase in problem size. This is not surprising in the light of the fact that the FFT computation maps naturally to the hypercube architecture [35]. <p> As the analysis of Sections 4 and 5 will show, each of these formulations minimizes the cost due to one of these constants. 3.1 The Binary-exchange Algorithm In the most commonly used mapping that minimizes communication for the binary-exchange algorithm <ref> [25, 3, 4, 6, 11, 21, 32, 41, 36, 31] </ref>, if .b 0 b 1 b r1 / is the binary representation of i, then for all i, R [i] and S [i] are mapped to processor number .b 0 b d1 /.
Reference: [4] <author> A. Averbuch, E. Gabber, B. Gordissky, and Y. Medan. </author> <title> A parallel FFT on an MIMD machine. </title> <journal> Parallel Computing, </journal> <volume> 15 </volume> <pages> 61-74, </pages> <year> 1990. </year>
Reference-contexts: Some of the applications of the FFT algorithm include Time Series and Wave Analysis, solving Linear Partial Differential Equations, Convolution, Digital Signal Processing and Image Filtering, etc. Hence, there has been a great interest in implementing FFT on parallel computers <ref> [4, 6, 11, 14, 21, 32, 41, 5] </ref>. In this paper we analyze the scalability of the parallel FFT algorithm on mesh and hypercube connected multicomputers. We also present experimental performance results on a 1024-processor nCUBE1 T M multicomputer to support our analytical results. <p> The scalability analysis of FFT on hypercube provides several important insights. On the hypercube architecture, a commonly used parallel formulation of the FFT algorithm (which we shall refer to as the binary-exchange algorithm in the rest of the paper) <ref> [3, 4, 6, 11, 21, 32, 41, 36, 31] </ref> can obtain linearly increasing speedup with respect to the number of processors with only a moderate increase in problem size. This is not surprising in the light of the fact that the FFT computation maps naturally to the hypercube architecture [35]. <p> As the analysis of Sections 4 and 5 will show, each of these formulations minimizes the cost due to one of these constants. 3.1 The Binary-exchange Algorithm In the most commonly used mapping that minimizes communication for the binary-exchange algorithm <ref> [25, 3, 4, 6, 11, 21, 32, 41, 36, 31] </ref>, if .b 0 b 1 b r1 / is the binary representation of i, then for all i, R [i] and S [i] are mapped to processor number .b 0 b d1 /. <p> Parallel FFT algorithms and their implementation and experimental evaluation on various architectures has been pursued by many authors <ref> [21, 4, 41, 6, 11, 22, 5] </ref>.
Reference: [5] <author> David H. Bailey. </author> <title> FFTs in external or hierarchical memory. </title> <journal> The Journal of Supercomputing, </journal> <volume> 4 </volume> <pages> 23-35, </pages> <year> 1990. </year>
Reference-contexts: Some of the applications of the FFT algorithm include Time Series and Wave Analysis, solving Linear Partial Differential Equations, Convolution, Digital Signal Processing and Image Filtering, etc. Hence, there has been a great interest in implementing FFT on parallel computers <ref> [4, 6, 11, 14, 21, 32, 41, 5] </ref>. In this paper we analyze the scalability of the parallel FFT algorithm on mesh and hypercube connected multicomputers. We also present experimental performance results on a 1024-processor nCUBE1 T M multicomputer to support our analytical results. <p> On hypercubes with store-and-forward routing, efficiencies higher than this limit can be obtained only if the problem size is increased very rapidly. If the hardware supports cut-through routing, then this threshold can be overcome by using an alternate parallel formulation <ref> [5, 31, 41] </ref> that involves array transposition (we shall refer to it as the transpose algorithm in the rest of the paper). The transpose algorithm is more scalable than the binary-exchange algorithm for efficiencies much higher than the threshold, but is less scalable for efficiencies below the threshold. <p> Parallel FFT algorithms and their implementation and experimental evaluation on various architectures has been pursued by many authors <ref> [21, 4, 41, 6, 11, 22, 5] </ref>.
Reference: [6] <author> S. Bershader, T. Kraay, and J. Holland. </author> <booktitle> The giant-Fourier-transform. In Proceedings of the Fourth Conference on Hypercubes, Concurrent Computers, and Applications: </booktitle> <volume> Volume I, </volume> <pages> pages 387-389, </pages> <year> 1989. </year>
Reference-contexts: Some of the applications of the FFT algorithm include Time Series and Wave Analysis, solving Linear Partial Differential Equations, Convolution, Digital Signal Processing and Image Filtering, etc. Hence, there has been a great interest in implementing FFT on parallel computers <ref> [4, 6, 11, 14, 21, 32, 41, 5] </ref>. In this paper we analyze the scalability of the parallel FFT algorithm on mesh and hypercube connected multicomputers. We also present experimental performance results on a 1024-processor nCUBE1 T M multicomputer to support our analytical results. <p> The scalability analysis of FFT on hypercube provides several important insights. On the hypercube architecture, a commonly used parallel formulation of the FFT algorithm (which we shall refer to as the binary-exchange algorithm in the rest of the paper) <ref> [3, 4, 6, 11, 21, 32, 41, 36, 31] </ref> can obtain linearly increasing speedup with respect to the number of processors with only a moderate increase in problem size. This is not surprising in the light of the fact that the FFT computation maps naturally to the hypercube architecture [35]. <p> As the analysis of Sections 4 and 5 will show, each of these formulations minimizes the cost due to one of these constants. 3.1 The Binary-exchange Algorithm In the most commonly used mapping that minimizes communication for the binary-exchange algorithm <ref> [25, 3, 4, 6, 11, 21, 32, 41, 36, 31] </ref>, if .b 0 b 1 b r1 / is the binary representation of i, then for all i, R [i] and S [i] are mapped to processor number .b 0 b d1 /. <p> Parallel FFT algorithms and their implementation and experimental evaluation on various architectures has been pursued by many authors <ref> [21, 4, 41, 6, 11, 22, 5] </ref>.
Reference: [7] <author> Edward C. Bronson, Thomas L. Casavant, and L. H. Jamieson. </author> <title> Experimental application-driven architecture analysis of an SIMD/MIMD parallel processing system. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(2) </volume> <pages> 195-205, </pages> <year> 1990. </year>
Reference-contexts: In the following, we briefly review the work of other authors who have studied the scalability of FFT and/or have tried to do performance prediction. Jamieson et al <ref> [7] </ref> describe an implementation of parallel FFT on the PASM parallel processing system which has a hypercube interconnect. They implement a single dimensional unordered FFT on 2 and 4 processor machines with 2 data elements per processor.
Reference: [8] <author> Z. Cvetanovic. </author> <title> Performance analysis of the FFT algorithm on a shared-memory parallel architecture. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 31(4) </volume> <pages> 435-451, </pages> <year> 1987. </year>
Reference-contexts: The startup time on the PASM is minimal and hence our analysis for the hypercube is applicable to the PASM by equating t s to zero. Our analysis can provide more general performance predictions as it would be valid for any problem size and any number of processors. Cvetanovic <ref> [8] </ref> and Norton et al [32] give a rather comprehensive performance analysis of the FFT algorithm on pseudo-shared memory architectures such as IBM RP/3.
Reference: [9] <author> William J. Dally. </author> <title> A VLSI Architecture for Concurrent Data Structures. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1987. </year>
Reference-contexts: If the width of inter-processor links is maintained as O. p p/, where p is the number of processors on the mesh, then the scalability can be improved considerably. Addition of features such as cut-through-routing (also known as worm-hole routing) <ref> [9] </ref> to the mesh architecture improve the scalability of several parallel algorithms; e.g., see [30] . But these features do not improve the overall scalability characteristics of the FFT algorithm on this architecture. <p> The first model captures the cost of communication in multicomputers that use store-and-forward routing (e.g., first generation multicomputers such as nCUBE1 and Intel IPSC/1). The second model captures the cost of communication in multicomputers that use cut-through routing (also known as worm-hole routing) <ref> [9] </ref> (e.g., the second generation multicomputers such as nCUBE2 and Intel IPSC/2).
Reference: [10] <author> William J. Dally. </author> <title> Wire-efficienct VLSI multiprocessor communication network. </title> <booktitle> In Stanford Conference on Advanced Research in VLSI Networks, </booktitle> <pages> pages 391-415, </pages> <year> 1987. </year>
Reference-contexts: However, if the cost of the network is considered to be a function of the bisection width of the network, as may be the case in VLSI implementations <ref> [10] </ref>, then the picture improves for the mesh. The bisection widths of a hypercube and a mesh containing p processors each are p p p respectively.
Reference: [11] <author> Laurent Desbat and Denis Trystram. </author> <title> Implementing the discrete Fourier transform on a hypercube vector-parallel computer. </title> <booktitle> In Proceedings of the Fourth Conference on Hypercubes, Concurrent Computers, and Applications: </booktitle> <volume> Volume I, </volume> <pages> pages 407-410, </pages> <year> 1989. </year>
Reference-contexts: Some of the applications of the FFT algorithm include Time Series and Wave Analysis, solving Linear Partial Differential Equations, Convolution, Digital Signal Processing and Image Filtering, etc. Hence, there has been a great interest in implementing FFT on parallel computers <ref> [4, 6, 11, 14, 21, 32, 41, 5] </ref>. In this paper we analyze the scalability of the parallel FFT algorithm on mesh and hypercube connected multicomputers. We also present experimental performance results on a 1024-processor nCUBE1 T M multicomputer to support our analytical results. <p> The scalability analysis of FFT on hypercube provides several important insights. On the hypercube architecture, a commonly used parallel formulation of the FFT algorithm (which we shall refer to as the binary-exchange algorithm in the rest of the paper) <ref> [3, 4, 6, 11, 21, 32, 41, 36, 31] </ref> can obtain linearly increasing speedup with respect to the number of processors with only a moderate increase in problem size. This is not surprising in the light of the fact that the FFT computation maps naturally to the hypercube architecture [35]. <p> As the analysis of Sections 4 and 5 will show, each of these formulations minimizes the cost due to one of these constants. 3.1 The Binary-exchange Algorithm In the most commonly used mapping that minimizes communication for the binary-exchange algorithm <ref> [25, 3, 4, 6, 11, 21, 32, 41, 36, 31] </ref>, if .b 0 b 1 b r1 / is the binary representation of i, then for all i, R [i] and S [i] are mapped to processor number .b 0 b d1 /. <p> Parallel FFT algorithms and their implementation and experimental evaluation on various architectures has been pursued by many authors <ref> [21, 4, 41, 6, 11, 22, 5] </ref>.
Reference: [12] <author> D. L. Eager, J. Zahorjan, and E. D. Lazowska. </author> <title> Speedup versus efficiency in parallel systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(3) </volume> <pages> 408-423, </pages> <year> 1989. </year>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [27, 26, 17, 48, 23, 49, 12, 44, 33] </ref>. In this paper, we analyze the scalability of the FFT algorithm on a few important architectures using the isoefficiency metric developed by Kumar and Rao [25, 13].
Reference: [13] <author> Ananth Grama, Anshul Gupta, and Vipin Kumar. Isoefficiency: </author> <title> Measuring the scalability of parallel algorithms and architectures. </title> <journal> IEEE Parallel and Distributed Technology, </journal> <volume> 1(3) </volume> <pages> 12-21, </pages> <month> August, </month> <year> 1993. </year> <note> Also available as Technical Report TR 93-24, </note> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN. </institution>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures [27, 26, 17, 48, 23, 49, 12, 44, 33]. In this paper, we analyze the scalability of the FFT algorithm on a few important architectures using the isoefficiency metric developed by Kumar and Rao <ref> [25, 13] </ref>. The isoefficiency function of a combination of a parallel algorithm and a parallel architecture relates the problem size to the number of processors necessary for an increase in speedup in proportion to the number of processors.
Reference: [14] <author> Anshul Gupta and Vipin Kumar. </author> <title> On the scalability of FFT on parallel computers. </title> <booktitle> In Proceedings of the Third Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <year> 1990. </year> <note> Also available as Technical Report TR 90-53, </note> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN. </institution>
Reference-contexts: Some of the applications of the FFT algorithm include Time Series and Wave Analysis, solving Linear Partial Differential Equations, Convolution, Digital Signal Processing and Image Filtering, etc. Hence, there has been a great interest in implementing FFT on parallel computers <ref> [4, 6, 11, 14, 21, 32, 41, 5] </ref>. In this paper we analyze the scalability of the parallel FFT algorithm on mesh and hypercube connected multicomputers. We also present experimental performance results on a 1024-processor nCUBE1 T M multicomputer to support our analytical results.
Reference: [15] <author> Anshul Gupta and Vipin Kumar. </author> <title> The scalability of matrix multiplication algorithms on parallel computers. </title> <type> Technical Report TR 91-54, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN, </institution> <year> 1991. </year> <note> A short version appears in Proceedings of 1993 International Conference on Parallel Processing, pages III-115-III-119, </note> <year> 1993. </year>
Reference: [16] <author> Anshul Gupta, Vipin Kumar, and A. H. Sameh. </author> <title> Performance and scalability of preconditioned conjugate gradient methods on parallel computers. </title> <type> Technical Report TR 92-64, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN, </institution> <year> 1992. </year> <booktitle> A short version appears in Proceedings of the Sixth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 664-674, </pages> <year> 1993. </year>
Reference: [17] <author> John L. Gustafson. </author> <title> Reevaluating Amdahl's law. </title> <journal> Communications of the ACM, </journal> <volume> 31(5) </volume> <pages> 532-533, </pages> <year> 1988. </year>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [27, 26, 17, 48, 23, 49, 12, 44, 33] </ref>. In this paper, we analyze the scalability of the FFT algorithm on a few important architectures using the isoefficiency metric developed by Kumar and Rao [25, 13].
Reference: [18] <author> John L. Gustafson, Gary R. Montry, and Robert E. Benner. </author> <title> Development of parallel methods for a 1024-processor hypercube. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 9(4) </volume> <pages> 609-638, </pages> <year> 1988. </year>
Reference: [19] <author> Kai Hwang. </author> <title> Advanced Computer Architecture: Parallelism, Scalability, Programmability. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference: [20] <author> S. L. Johnsson and C.-T. Ho. </author> <title> Optimum broadcasting and personalized communication in hypercubes. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(9) </volume> <pages> 1249-1268, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: This communication (known as all-to-all personalized communication) can be performed by executing the following code on each processor: for i D 1 to p do send data to processor number (self address i) It is shown in <ref> [20] </ref>, that on a hypercube, in each iteration of the above code, each pair of communicating processors have a contention-free communication path. On a hypercube with store-and-forward routing, this communication will take t w n p log p C t s p time.
Reference: [21] <author> S. L. Johnsson, R. Krawitz, R. Frye, and D. McDonald. </author> <title> A radix-2 FFT on the connection machine. </title> <type> Technical report, </type> <institution> Thinking Machines Corporation, </institution> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference-contexts: Some of the applications of the FFT algorithm include Time Series and Wave Analysis, solving Linear Partial Differential Equations, Convolution, Digital Signal Processing and Image Filtering, etc. Hence, there has been a great interest in implementing FFT on parallel computers <ref> [4, 6, 11, 14, 21, 32, 41, 5] </ref>. In this paper we analyze the scalability of the parallel FFT algorithm on mesh and hypercube connected multicomputers. We also present experimental performance results on a 1024-processor nCUBE1 T M multicomputer to support our analytical results. <p> The scalability analysis of FFT on hypercube provides several important insights. On the hypercube architecture, a commonly used parallel formulation of the FFT algorithm (which we shall refer to as the binary-exchange algorithm in the rest of the paper) <ref> [3, 4, 6, 11, 21, 32, 41, 36, 31] </ref> can obtain linearly increasing speedup with respect to the number of processors with only a moderate increase in problem size. This is not surprising in the light of the fact that the FFT computation maps naturally to the hypercube architecture [35]. <p> As the analysis of Sections 4 and 5 will show, each of these formulations minimizes the cost due to one of these constants. 3.1 The Binary-exchange Algorithm In the most commonly used mapping that minimizes communication for the binary-exchange algorithm <ref> [25, 3, 4, 6, 11, 21, 32, 41, 36, 31] </ref>, if .b 0 b 1 b r1 / is the binary representation of i, then for all i, R [i] and S [i] are mapped to processor number .b 0 b d1 /. <p> Parallel FFT algorithms and their implementation and experimental evaluation on various architectures has been pursued by many authors <ref> [21, 4, 41, 6, 11, 22, 5] </ref>.
Reference: [22] <author> Ray A. Kamin and George B. Adams. </author> <title> Fast Fourier transform algorithm design and tradeoffs. </title> <type> Technical Report RIACS TR 88.18, </type> <institution> NASA Ames Research Center, Moffet Field, </institution> <address> CA, </address> <year> 1988. </year>
Reference-contexts: Parallel FFT algorithms and their implementation and experimental evaluation on various architectures has been pursued by many authors <ref> [21, 4, 41, 6, 11, 22, 5] </ref>.
Reference: [23] <author> Alan H. Karp and Horace P. Flatt. </author> <title> Measuring parallel processor performance. </title> <journal> Communications of the ACM, </journal> <volume> 33(5) </volume> <pages> 539-543, </pages> <year> 1990. </year>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [27, 26, 17, 48, 23, 49, 12, 44, 33] </ref>. In this paper, we analyze the scalability of the FFT algorithm on a few important architectures using the isoefficiency metric developed by Kumar and Rao [25, 13].
Reference: [24] <author> Kouichi Kimura and Ichiyoshi Nobuyuki. </author> <title> Probabilistic analysis of the efficiency of the dynamic load distribution. </title> <booktitle> In The Sixth Distributed Memory Computing Conference Proceedings, </booktitle> <year> 1991. </year>
Reference: [25] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis. </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms. </title> <address> Benjamin/Cummings, Redwood City, CA, </address> <year> 1994. </year>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures [27, 26, 17, 48, 23, 49, 12, 44, 33]. In this paper, we analyze the scalability of the FFT algorithm on a few important architectures using the isoefficiency metric developed by Kumar and Rao <ref> [25, 13] </ref>. The isoefficiency function of a combination of a parallel algorithm and a parallel architecture relates the problem size to the number of processors necessary for an increase in speedup in proportion to the number of processors. <p> As the analysis of Sections 4 and 5 will show, each of these formulations minimizes the cost due to one of these constants. 3.1 The Binary-exchange Algorithm In the most commonly used mapping that minimizes communication for the binary-exchange algorithm <ref> [25, 3, 4, 6, 11, 21, 32, 41, 36, 31] </ref>, if .b 0 b 1 b r1 / is the binary representation of i, then for all i, R [i] and S [i] are mapped to processor number .b 0 b d1 /. <p> The binary-exchange algorithm is nothing but a a .log p C 1/- dimensional algorithm. In this paper, we confine our discussion to the two extremes (2-D transpose and binary-exchange) of this sequence of algorithms. More detailed discussion can be found in <ref> [25] </ref>. 4 Scalability Analysis of the Binary-Exchange Algorithm for Single Di mensional Radix-2 Unordered FFT We assume that the cost of one unit of computation (i.e., the cost of executing line 8 in Figure 1) is t c . <p> As mentioned in Section 3, in this paper we have confined our discussion of the transpose algorithm to the two-dimensional case. A generalized transpose algorithm and the related performance and scalability analysis can be found in <ref> [25] </ref>. 5.1 Comparison with Binary-Exchange As discussed earlier in this paper, an overall isoefficiency function of O. p log p/ can be realized by using the binary exchange algorithm if the efficiency of operation is such that K t w t c 1. <p> In a generalization of this method <ref> [25, 39] </ref>, the vector X can be arranged in an m-dimensional array mapped on to an .m 1/-dimensional logical array of p processors, where p D n m1 m The 2-D transpose algorithm discussed in this paper is a special case of this generalization with m D 2 and the binary-exchange
Reference: [26] <author> Vipin Kumar and Anshul Gupta. </author> <title> Analyzing scalability of parallel algorithms and architectures. </title> <type> Technical Report TR 91-18, </type> <institution> Department of Computer Science Department, University of Minnesota, Minneapolis, MN, </institution> <year> 1991. </year> <note> To appear in Journal of Parallel and Distributed Computing, </note> <year> 1994. </year> <booktitle> A shorter version appears in Proceedings of the 1991 International Conference on Supercomputing, </booktitle> <pages> pages 396-405, </pages> <year> 1991. </year> <month> 18 </month>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [27, 26, 17, 48, 23, 49, 12, 44, 33] </ref>. In this paper, we analyze the scalability of the FFT algorithm on a few important architectures using the isoefficiency metric developed by Kumar and Rao [25, 13].
Reference: [27] <author> Vipin Kumar and V. N. Rao. </author> <title> Parallel depth-first search, part II: Analysis. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 16(6) </volume> <pages> 501-519, </pages> <year> 1987. </year>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [27, 26, 17, 48, 23, 49, 12, 44, 33] </ref>. In this paper, we analyze the scalability of the FFT algorithm on a few important architectures using the isoefficiency metric developed by Kumar and Rao [25, 13].
Reference: [28] <author> Vipin Kumar and V. N. Rao. </author> <title> Load balancing on the hypercube architecture. </title> <booktitle> In Proceedings of the Fourth Conference on Hypercubes, Concurrent Computers, and Applications, </booktitle> <pages> pages 603-608, </pages> <year> 1989. </year>
Reference: [29] <author> Vipin Kumar and V. N. Rao. </author> <title> Scalable parallel formulations of depth-first search. </title> <editor> In Vipin Kumar, P. S. Gopalakrishnan, and Laveen N. Kanal, editors, </editor> <booktitle> Parallel Algorithms for Machine Intelligence and Vision. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference-contexts: Above this threshold, the isoefficiency function of the binary-exchange algorithm becomes quite bad. This extreme sensitivity of the isoefficiency function to hardware related constants is rather unique to this algorithm. In many other parallel algorithms (e.g., depth-first search <ref> [29] </ref>), the hardware dependent constants such the CPU speed and communication bandwidth appear only as multiplicative factors in the isoefficiency function.
Reference: [30] <author> Vipin Kumar and Vineet Singh. </author> <title> Scalability of parallel algorithms for the all-pairs shortest path problem. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13(2) </volume> <pages> 124-138, </pages> <month> October </month> <year> 1991. </year> <note> A short version appears in the Proceedings of the International Conference on Parallel Processing, </note> <year> 1990. </year>
Reference-contexts: Addition of features such as cut-through-routing (also known as worm-hole routing) [9] to the mesh architecture improve the scalability of several parallel algorithms; e.g., see <ref> [30] </ref> . But these features do not improve the overall scalability characteristics of the FFT algorithm on this architecture.
Reference: [31] <author> Charles Van Loan. </author> <title> Computational Frameworks for the Fast Fourier Transform. </title> <publisher> SIAM, </publisher> <address> Philadelphia, PA, </address> <year> 1992. </year>
Reference-contexts: The scalability analysis of FFT on hypercube provides several important insights. On the hypercube architecture, a commonly used parallel formulation of the FFT algorithm (which we shall refer to as the binary-exchange algorithm in the rest of the paper) <ref> [3, 4, 6, 11, 21, 32, 41, 36, 31] </ref> can obtain linearly increasing speedup with respect to the number of processors with only a moderate increase in problem size. This is not surprising in the light of the fact that the FFT computation maps naturally to the hypercube architecture [35]. <p> On hypercubes with store-and-forward routing, efficiencies higher than this limit can be obtained only if the problem size is increased very rapidly. If the hardware supports cut-through routing, then this threshold can be overcome by using an alternate parallel formulation <ref> [5, 31, 41] </ref> that involves array transposition (we shall refer to it as the transpose algorithm in the rest of the paper). The transpose algorithm is more scalable than the binary-exchange algorithm for efficiencies much higher than the threshold, but is less scalable for efficiencies below the threshold. <p> As the analysis of Sections 4 and 5 will show, each of these formulations minimizes the cost due to one of these constants. 3.1 The Binary-exchange Algorithm In the most commonly used mapping that minimizes communication for the binary-exchange algorithm <ref> [25, 3, 4, 6, 11, 21, 32, 41, 36, 31] </ref>, if .b 0 b 1 b r1 / is the binary representation of i, then for all i, R [i] and S [i] are mapped to processor number .b 0 b d1 /.
Reference: [32] <author> A. Norton and A. J. Silberger. </author> <title> Parallelization and performance analysis of the Cooley-Tukey FFT algorithm for shared memory architectures. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(5):581-591, </volume> <year> 1987. </year>
Reference-contexts: Some of the applications of the FFT algorithm include Time Series and Wave Analysis, solving Linear Partial Differential Equations, Convolution, Digital Signal Processing and Image Filtering, etc. Hence, there has been a great interest in implementing FFT on parallel computers <ref> [4, 6, 11, 14, 21, 32, 41, 5] </ref>. In this paper we analyze the scalability of the parallel FFT algorithm on mesh and hypercube connected multicomputers. We also present experimental performance results on a 1024-processor nCUBE1 T M multicomputer to support our analytical results. <p> The scalability analysis of FFT on hypercube provides several important insights. On the hypercube architecture, a commonly used parallel formulation of the FFT algorithm (which we shall refer to as the binary-exchange algorithm in the rest of the paper) <ref> [3, 4, 6, 11, 21, 32, 41, 36, 31] </ref> can obtain linearly increasing speedup with respect to the number of processors with only a moderate increase in problem size. This is not surprising in the light of the fact that the FFT computation maps naturally to the hypercube architecture [35]. <p> As the analysis of Sections 4 and 5 will show, each of these formulations minimizes the cost due to one of these constants. 3.1 The Binary-exchange Algorithm In the most commonly used mapping that minimizes communication for the binary-exchange algorithm <ref> [25, 3, 4, 6, 11, 21, 32, 41, 36, 31] </ref>, if .b 0 b 1 b r1 / is the binary representation of i, then for all i, R [i] and S [i] are mapped to processor number .b 0 b d1 /. <p> Our analysis can provide more general performance predictions as it would be valid for any problem size and any number of processors. Cvetanovic [8] and Norton et al <ref> [32] </ref> give a rather comprehensive performance analysis of the FFT algorithm on pseudo-shared memory architectures such as IBM RP/3.
Reference: [33] <author> Daniel Nussbaum and Anant Agarwal. </author> <title> Scalability of parallel machines. </title> <journal> Communications of the ACM, </journal> <volume> 34(3) </volume> <pages> 57-61, </pages> <year> 1991. </year>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [27, 26, 17, 48, 23, 49, 12, 44, 33] </ref>. In this paper, we analyze the scalability of the FFT algorithm on a few important architectures using the isoefficiency metric developed by Kumar and Rao [25, 13].
Reference: [34] <author> H. J. Nussbaumer. </author> <title> Fast Fourier Transform and Convolution Algorithms. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1982. </year>
Reference-contexts: Under certain circumstances, one of these algorithms might be the best choice in terms of both concurrency and communication overheads. 6 Impact of Variations of Cooley-Tukey Algorithm on Scalability Several schemes of computing the DFT have been suggested in literature <ref> [34, 45, 37] </ref> that involve fewer arithmetic operations on a serial computer than the simple Cooley-Tukey FFT algorithm. <p> For example, for a radix-4 algorithm on a hypercube, each communication step now involves four processors distributed in two dimensions rather than two processors in one dimension. On the other hand, the number of multiplications in a radix-4 FFT is 25% less than those in a radix-2 FFT <ref> [34] </ref>. This number can be marginally improved further by going to higher radices. <p> Since both T o and W remain of the same order of magnitude, the various isoefficiency functions for a radix-q FFT will be similar to those for the radix-2 FFT with somewhat higher constants. As described in <ref> [34] </ref>, polynomial transforms can be used to reduce the number of arithmetic operations in multidimensional FFTs. In particular, the number of multiplications can be reduced by almost 50% on a two dimensional FFT by this method.
Reference: [35] <author> M. C. Pease. </author> <title> The indirect binary n-cube microprocessor array. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 26 </volume> <pages> 458-473, </pages> <year> 1977. </year>
Reference-contexts: This is not surprising in the light of the fact that the FFT computation maps naturally to the hypercube architecture <ref> [35] </ref>. However, there is a limit on the achievable efficiency which is determined by the ratio of CPU speed and communication bandwidth of the hypercube channels. This limit can be raised by increasing the bandwidth of the communication channels.
Reference: [36] <author> Michael J. Quinn. </author> <title> Designing Efficient Algorithms for Parallel Computers. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1987. </year>
Reference-contexts: The scalability analysis of FFT on hypercube provides several important insights. On the hypercube architecture, a commonly used parallel formulation of the FFT algorithm (which we shall refer to as the binary-exchange algorithm in the rest of the paper) <ref> [3, 4, 6, 11, 21, 32, 41, 36, 31] </ref> can obtain linearly increasing speedup with respect to the number of processors with only a moderate increase in problem size. This is not surprising in the light of the fact that the FFT computation maps naturally to the hypercube architecture [35]. <p> Also, we assume that a processor can send or receive on only one of its ports at a time, although the ports on which it sends and receives can be different. 3 The FFT Algorithm adapted from <ref> [2, 36] </ref>. X is the input vector of length n (n = 2 r for some integer r ) and Y is its Fourier Transform. ! k denotes the complex number e j 2 n k , where j = p 1. <p> As the analysis of Sections 4 and 5 will show, each of these formulations minimizes the cost due to one of these constants. 3.1 The Binary-exchange Algorithm In the most commonly used mapping that minimizes communication for the binary-exchange algorithm <ref> [25, 3, 4, 6, 11, 21, 32, 41, 36, 31] </ref>, if .b 0 b 1 b r1 / is the binary representation of i, then for all i, R [i] and S [i] are mapped to processor number .b 0 b d1 /.
Reference: [37] <author> C. M. Rader and N. M. Brenner. </author> <title> A new principle for Fast fourier transform. </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing, </journal> <volume> 24 </volume> <pages> 264-265, </pages> <year> 1976. </year>
Reference-contexts: Under certain circumstances, one of these algorithms might be the best choice in terms of both concurrency and communication overheads. 6 Impact of Variations of Cooley-Tukey Algorithm on Scalability Several schemes of computing the DFT have been suggested in literature <ref> [34, 45, 37] </ref> that involve fewer arithmetic operations on a serial computer than the simple Cooley-Tukey FFT algorithm.
Reference: [38] <author> S. Ranka and S. Sahni. </author> <title> Hypercube Algorithms for Image Processing and Pattern Recognition. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference: [39] <author> V. N. Rao. </author> <type> Personal Communication. </type> <institution> University of Central Florida, </institution> <address> Orlando, FL, </address> <year> 1992. </year>
Reference-contexts: In a generalization of this method <ref> [25, 39] </ref>, the vector X can be arranged in an m-dimensional array mapped on to an .m 1/-dimensional logical array of p processors, where p D n m1 m The 2-D transpose algorithm discussed in this paper is a special case of this generalization with m D 2 and the binary-exchange <p> By selecting values of m between 2 and .log p C 1/, it is possible to derive algorithms whose concurrencies and communication overheads due to t s and t w have intermediate values between those for the two algorithms described in this paper <ref> [39] </ref>.
Reference: [40] <author> Vineet Singh, Vipin Kumar, Gul Agha, and Chris Tomlinson. </author> <title> Scalability of parallel sorting on mesh multicomputers. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 20(2), </volume> <year> 1991. </year>
Reference: [41] <author> P. N. Swarztrauber. </author> <title> Multiprocessor FFTs. </title> <journal> Parallel Computing, </journal> <volume> 5 </volume> <pages> 197-210, </pages> <year> 1987. </year>
Reference-contexts: Some of the applications of the FFT algorithm include Time Series and Wave Analysis, solving Linear Partial Differential Equations, Convolution, Digital Signal Processing and Image Filtering, etc. Hence, there has been a great interest in implementing FFT on parallel computers <ref> [4, 6, 11, 14, 21, 32, 41, 5] </ref>. In this paper we analyze the scalability of the parallel FFT algorithm on mesh and hypercube connected multicomputers. We also present experimental performance results on a 1024-processor nCUBE1 T M multicomputer to support our analytical results. <p> The scalability analysis of FFT on hypercube provides several important insights. On the hypercube architecture, a commonly used parallel formulation of the FFT algorithm (which we shall refer to as the binary-exchange algorithm in the rest of the paper) <ref> [3, 4, 6, 11, 21, 32, 41, 36, 31] </ref> can obtain linearly increasing speedup with respect to the number of processors with only a moderate increase in problem size. This is not surprising in the light of the fact that the FFT computation maps naturally to the hypercube architecture [35]. <p> On hypercubes with store-and-forward routing, efficiencies higher than this limit can be obtained only if the problem size is increased very rapidly. If the hardware supports cut-through routing, then this threshold can be overcome by using an alternate parallel formulation <ref> [5, 31, 41] </ref> that involves array transposition (we shall refer to it as the transpose algorithm in the rest of the paper). The transpose algorithm is more scalable than the binary-exchange algorithm for efficiencies much higher than the threshold, but is less scalable for efficiencies below the threshold. <p> As the analysis of Sections 4 and 5 will show, each of these formulations minimizes the cost due to one of these constants. 3.1 The Binary-exchange Algorithm In the most commonly used mapping that minimizes communication for the binary-exchange algorithm <ref> [25, 3, 4, 6, 11, 21, 32, 41, 36, 31] </ref>, if .b 0 b 1 b r1 / is the binary representation of i, then for all i, R [i] and S [i] are mapped to processor number .b 0 b d1 /. <p> Parallel FFT algorithms and their implementation and experimental evaluation on various architectures has been pursued by many authors <ref> [21, 4, 41, 6, 11, 22, 5] </ref>.
Reference: [42] <author> Zhimin Tang and Guo-Jie Li. </author> <title> Optimal granularity of grid iteration problems. </title> <booktitle> In Proceedingsof the 1990 International Conference on Parallel Processing, </booktitle> <pages> pages I111-I118, </pages> <year> 1990. </year>
Reference: [43] <author> Clark D. Thompson. </author> <title> Fourier transforms in VLSI. </title> <journal> IBM Journal of Research and Development, </journal> <volume> C-32(11):1047-1057, </volume> <year> 1983. </year>
Reference-contexts: Any different mapping of input vector X on the processors does not reduce the communication overhead. It has been shown <ref> [43] </ref> that in any mapping, there will be at least one iteration in which the pairs of processors that need to communicate will be at least p p 2 hops apart.
Reference: [44] <author> Fredric A. Van-Catledge. </author> <title> Towards a general model for evaluating the relative performance of computer systems. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 3(2) </volume> <pages> 100-108, </pages> <year> 1989. </year>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [27, 26, 17, 48, 23, 49, 12, 44, 33] </ref>. In this paper, we analyze the scalability of the FFT algorithm on a few important architectures using the isoefficiency metric developed by Kumar and Rao [25, 13].
Reference: [45] <author> S. Winograd. </author> <title> A new method for computing DFT. </title> <booktitle> In IEEE International Conference on Acoustics, Speech and Signal Processing, </booktitle> <pages> pages 366-368, </pages> <year> 1977. </year>
Reference-contexts: Under certain circumstances, one of these algorithms might be the best choice in terms of both concurrency and communication overheads. 6 Impact of Variations of Cooley-Tukey Algorithm on Scalability Several schemes of computing the DFT have been suggested in literature <ref> [34, 45, 37] </ref> that involve fewer arithmetic operations on a serial computer than the simple Cooley-Tukey FFT algorithm.
Reference: [46] <author> Jinwoon Woo and Sartaj Sahni. </author> <title> Hypercube computing: </title> <journal> Connectedcomponents. Journal of Supercomputing, </journal> <note> 1991. Also available as TR 88-50 from the Department of Computer Science, </note> <institution> University of Minnesota, Minneapolis, MN. </institution>
Reference: [47] <author> Jinwoon Woo and Sartaj Sahni. </author> <title> Computing biconnected components on a hypercube. </title> <journal> Journal of Supercomputing, </journal> <month> June </month> <year> 1991. </year> <note> Also available as Technical Report TR 89-7 from the Department of Computer Science, </note> <institution> University of Minnesota, Minneapolis, MN. </institution>
Reference: [48] <author> Patrick H. Worley. </author> <title> The effect of time constraints on scaled speedup. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 11(5) </volume> <pages> 838-858, </pages> <year> 1990. </year>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [27, 26, 17, 48, 23, 49, 12, 44, 33] </ref>. In this paper, we analyze the scalability of the FFT algorithm on a few important architectures using the isoefficiency metric developed by Kumar and Rao [25, 13].
Reference: [49] <author> J. R. Zorbas, D. J. Reble, and R. E. VanKooten. </author> <title> Measuring the scalability of parallel computer systems. </title> <booktitle> In Supercomputing '89 Proceedings, </booktitle> <pages> pages 832-841, </pages> <booktitle> 1989. </booktitle> <volume> 19 i! 0 1 2 3 4 5 6 7 0 000 000 000 000 100 100 100 100 2 000 100 010 110 001 101 011 111 Table 3: </volume> <booktitle> Binary representation of the various powers of ! calculated in different iterations of an 8 point FFT. l refers to the iteration number. </booktitle>
Reference-contexts: Many different measures have been developed to study the scalability of parallel algorithms and architectures <ref> [27, 26, 17, 48, 23, 49, 12, 44, 33] </ref>. In this paper, we analyze the scalability of the FFT algorithm on a few important architectures using the isoefficiency metric developed by Kumar and Rao [25, 13].
References-found: 49

