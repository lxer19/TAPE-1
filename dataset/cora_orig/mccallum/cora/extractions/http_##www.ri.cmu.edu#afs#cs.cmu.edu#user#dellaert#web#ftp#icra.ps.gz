URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/dellaert/web/ftp/icra.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/dellaert/web/publications.html
Root-URL: 
Title: Model-Based Car Tracking Integrated with a Road-Follower  
Author: Frank Dellaert Dean Pomerleau Chuck Thorpe 
Address: Pittsburgh PA 15213  
Affiliation: Computer Science Department and The Robotics Institute Carnegie Mellon University,  
Abstract: This paper discusses how we integrated our 3D car tracking approach with the lane following module RALPH on the Navlab autonomous vehicles, obtaining a hybrid vision system that tracks both the road and cars better than those two systems in isolation. The tracking system brings precise and crisp measurements of the car in the image, and performs image stabilization. However, because it does not know about the yaw or lateral offset of the ego-vehicle, its curvature estimate can be misguided. RALPH takes a more global image processing approach and can provide this missing information, as well as a good estimate of curvature, so that the combined curvature estimate is superior to both taken in isolation. The additional information provided by RALPH also improves tracking performance, and allows us to estimate properties of the tracked car that were previously unobservable, in particular its in-lane displacement. Better car tracking, and a better idea of where the road is, gives us a substantial foundation on which to base other capabilities needed to realize fully autonomous vehicles. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Pomerleau, </author> <title> Neural Network Perception for Mobile Robot Guidance, </title> <publisher> Kluwer Academic Publishing, </publisher> <address> Boston, MA, </address> <year> 1994. </year>
Reference-contexts: Much of the research done on the Navlabs has been concentrated on road-following. The first convincingly successful system, ALVINN, consisted of a neural network that learned to predict steering direction from subsampled video images <ref> [1] </ref>. Since then, ALVINN has been superseded by RALPH, which uses a more domain specific method to estimate the curvature of the road and the lateral offset of the vehicle, which can then be used to calculate a steering command [2].
Reference: [2] <author> D. Pomerleau and T. Jochem, </author> <title> "Rapidly adapting machine vision for automated vehicle steering," </title> <journal> IEEE Expert 11, </journal> <month> April </month> <year> 1996. </year>
Reference-contexts: Since then, ALVINN has been superseded by RALPH, which uses a more domain specific method to estimate the curvature of the road and the lateral offset of the vehicle, which can then be used to calculate a steering command <ref> [2] </ref>. Although RALPH has been quite successful for road-following, it does not provide any information about the position or behavior of other cars on the road.
Reference: [3] <author> F. Dellaert and C. Thorpe, </author> <title> "Robust car tracking using Kalman filtering and Bayesian templates," </title> <booktitle> in Proceedings of SPIE: Intelligent Transportation Systems, </booktitle> <volume> vol. 3207, </volume> <month> Oc-tober </month> <year> 1997. </year>
Reference-contexts: To provide situational awareness, we recently proposed a model-based vision approach to car tracking, in which we estimate the 3D position and motion of a car by tracking a 2D bounding box in the video stream <ref> [3] </ref>. Since only line segments are tracked, the image processing involved is relatively simple, and the system can run at frame rate. <p> In the remainder of this section we will briefly discuss the image processing technique we use to track this 2D bounding box in a video stream. A more detailed treatment and a discussion of related work can be found in <ref> [3] </ref>, where we also make the coupling with the Kalman filter more explicit. The overall approach is closest in spirit to the work of Schmid [5], although the underlying image processing is quite different. <p> The result is a maximum a posteriori (MAP) estimate for the position of the bounding box. For example, when working solely in image space, the prior could be a Gaussian density centered around the previous position of the bounding box <ref> [3, 7] </ref>. When using a Kalman filter, a better prior will be available via the current belief state of the filter, and Bayes law will be applied in the measurement update equation of the filter. <p> Initialization of tracking is done automatically using the Candidate Selection and Search (CANSS) algorithm, which we discuss in detail elsewhere <ref> [3, 8] </ref>. It uses a Hough Transform on the image gradient to advance candidate image rows and columns that might contain edges of a car, after which a combinatorial search takes place for the bounding box most probably generated by a car. <p> In contrast to most work in car tracking, we do not make a flat earth assumption, but estimate the vertical coordinate Z c of the tracked vehicle as well. We do require that the vehicle is in the same lane as the tracker, which we argue in detail elsewhere <ref> [3] </ref>. Lastly, we also model the width, length, and height of the vehicle as unknown constants, leading to the 7-variable state x c = [Y c V c d c Z c W c L c H c ] T . <p> The sequence shown in Figure 3 illustrates the strengths of our approach to car tracking, that have previously been discussed in <ref> [3] </ref>. Most notably, despite the challenging nature of the sequence, the system kept track at all times for the duration of the sequence.
Reference: [4] <author> P. Maybeck, </author> <title> Stochastic Models, </title> <journal> Estimation ond Control, </journal> <volume> vol. 1, </volume> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Having this additional estimate of curvature will be especially helpful in situations where RALPH traditionally has problems, e.g., when the flat earth assumption is violated. A principled way of combining the information provided by both techniques separately is by using an extended Kalman filter <ref> [4] </ref>, and that is the way we will approach it here. Since the tracking algorithm relies heavily on a Kalman filter already, integrating the RALPH measurements in this framework comes rather naturally. <p> A Kalman filter simply implements the iterative application of Bayes law under gaussian white noise assumptions for both dynamic and measurement noise, and the use of linear dynamics and measurements <ref> [4] </ref>. It also propagates the conditional densities involved forward in time between measurements.
Reference: [5] <author> M. Schmid, </author> <title> "An approach to model-based 3-d recognition of vehicles in real time by machine vision," </title> <booktitle> in Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS '94), </booktitle> <volume> vol. </volume> <pages> 3, </pages> <address> (Munich, Germany), </address> <month> September </month> <year> 1994. </year>
Reference-contexts: A more detailed treatment and a discussion of related work can be found in [3], where we also make the coupling with the Kalman filter more explicit. The overall approach is closest in spirit to the work of Schmid <ref> [5] </ref>, although the underlying image processing is quite different. We rely on an energy minimization technique to find the bounding box around the tracked car in each frame.
Reference: [6] <author> D. Terzopoulos and R. Szeliski, </author> <title> "Tracking with Kalman snakes," in Active Vision, </title> <booktitle> A.Blake and A.Yuille, eds., </booktitle> <pages> pp. 3-20, </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: gradient perpendicular to the contour on all 4 sides: F = r l l 1 Z r I u (d; v) dv 1 Z d I v (u; l) du + d t t We can relate this objective function to a Bayesian likelihood function by using the Gibbs/Boltzmann distribution <ref> [6, 7] </ref>.
Reference: [7] <author> A. L. Yuille, P. W. Hallinan, and D. S. Cohen, </author> <title> "Feature extraction from faces using deformable templates," </title> <journal> International Journal of Computer Vision 8(2), </journal> <pages> pp. 99-111, </pages> <year> 1992. </year>
Reference-contexts: gradient perpendicular to the contour on all 4 sides: F = r l l 1 Z r I u (d; v) dv 1 Z d I v (u; l) du + d t t We can relate this objective function to a Bayesian likelihood function by using the Gibbs/Boltzmann distribution <ref> [6, 7] </ref>. <p> The result is a maximum a posteriori (MAP) estimate for the position of the bounding box. For example, when working solely in image space, the prior could be a Gaussian density centered around the previous position of the bounding box <ref> [3, 7] </ref>. When using a Kalman filter, a better prior will be available via the current belief state of the filter, and Bayes law will be applied in the measurement update equation of the filter.
Reference: [8] <author> F. Dellaert, "CANSS: </author> <title> A candidate selection and search algorithm to initialize car tracking," </title> <type> Tech. Rep. </type> <institution> CMU-RI-TR-97-34, Robotics Institute, Carnegie Mellon University, </institution> <year> 1997. </year>
Reference-contexts: Initialization of tracking is done automatically using the Candidate Selection and Search (CANSS) algorithm, which we discuss in detail elsewhere <ref> [3, 8] </ref>. It uses a Hough Transform on the image gradient to advance candidate image rows and columns that might contain edges of a car, after which a combinatorial search takes place for the bounding box most probably generated by a car.
References-found: 8

