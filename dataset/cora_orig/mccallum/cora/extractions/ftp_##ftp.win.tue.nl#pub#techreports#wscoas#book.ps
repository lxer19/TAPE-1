URL: ftp://ftp.win.tue.nl/pub/techreports/wscoas/book.ps
Refering-URL: http://as.win.tue.nl/publieng.html
Root-URL: http://www.win.tue.nl
Title: The H 1 control problem: a state space approach  
Author: A.A. Stoorvogel 
Date: March 27, 1998  
Address: Ann Arbor U.S.A.  
Affiliation: Department of Electrical Engineering and Computer Science University of Michigan  
Abstract-found: 0
Intro-found: 1
Reference: [AM] <author> B.D.O. Anderson, J.B. Moore, </author> <title> Optimal control: linear quadratic methods, </title> <publisher> Prentice-Hall, </publisher> <year> 1989. </year>
Reference-contexts: In the latter two papers this was even explicitly used to find suitable controllers. On the other hand the classical H 2 or Linear Quadratic Gaussian (LQG) control problem (see e.g. <ref> [AM] </ref>) the avarage value of the magnitude over all frequencies is minimized. The latter is not very much concerned with peaks as long as they have small width. The above reasoning implies that H 1 control is well-suited for robustness analysis via the small-gain theorem.
Reference: [Ban] <author> M.D. Banker, </author> <title> Observability and controllability of two player discrete systems and quadratic control and game problems, </title> <type> Ph.D. Thesis, </type> <institution> Stanford Univ, Stanford, </institution> <address> CA, </address> <year> 1971. </year>
Reference-contexts: Chapter 6 The singular zero-sum differential game with stability 6.1 Introduction In this chapter we shall consider the zero-sum linear quadratic finite-dimensional differential game. This is an area of research which was rather popular during the seventies (see e.g. <ref> [Ban, Ma, BO, Sw] </ref>). <p> In the last few years, the solution of the regular H 1 control problem (see chapter 3 and [Do5, Kh3, Pe]) turned out to contain the same kind of algebraic Riccati equation as the one appearing in the solution of the zero-sum differential game (see <ref> [Ban, Ma, Sw] </ref>). This Riccati equation has the special property that the quadratic term is, in general, indefinite, in contrast to, for instance, the equation appearing in linear quadratic optimal control theory (see [Wi7]), where the quadratic term in the Riccati equation is always definite.
Reference: [Bas] <author> T. Basar, </author> <title> "A dynamic games approach to controller design: disturbance rejection in discrete time", </title> <booktitle> Proc. CDC, </booktitle> <address> Tampa, FL, </address> <year> 1989, </year> <pages> pp. 407-414. </pages>
Reference-contexts: Recently, a paper has appeared solving the discrete time H 1 control problem using frequency-domain techniques (see [Gu]). The polynomial approach has also been applied to discrete time systems (see [Gri]). In addition, a couple of papers have appeared using a time-domain approach (see <ref> [Bas, Li4, Ya] </ref>). With respect to the papers which use a time-domain approach it should be noted that the references [Bas, Li4, Ya] do not contain a proof of the results obtained for the infinite horizon case and the papers [Bas, Ya] make a number of extra assumptions on the system <p> The polynomial approach has also been applied to discrete time systems (see [Gri]). In addition, a couple of papers have appeared using a time-domain approach (see <ref> [Bas, Li4, Ya] </ref>). With respect to the papers which use a time-domain approach it should be noted that the references [Bas, Li4, Ya] do not contain a proof of the results obtained for the infinite horizon case and the papers [Bas, Ya] make a number of extra assumptions on the system under consideration. In [Bas, Li4, Ya] the authors first investigate the finite horizon problem and then derive a solution of <p> With respect to the papers which use a time-domain approach it should be noted that the references [Bas, Li4, Ya] do not contain a proof of the results obtained for the infinite horizon case and the papers <ref> [Bas, Ya] </ref> make a number of extra assumptions on the system under consideration. In [Bas, Li4, Ya] the authors first investigate the finite horizon problem and then derive a solution of the infinite horizon problem by considering it as a kind of limiting case as the endpoint tends to infinity. <p> respect to the papers which use a time-domain approach it should be noted that the references <ref> [Bas, Li4, Ya] </ref> do not contain a proof of the results obtained for the infinite horizon case and the papers [Bas, Ya] make a number of extra assumptions on the system under consideration. In [Bas, Li4, Ya] the authors first investigate the finite horizon problem and then derive a solution of the infinite horizon problem by considering it as a kind of limiting case as the endpoint tends to infinity. <p> We shall use time-domain techniques which are reminiscent of those used in chapter 3 and the paper [Ta] which deal with the continuous time case. The method used in the next two chapters was derived independently of <ref> [Bas, Li4, Ya] </ref> and has already ap 166 9.1 Introduction 167 peared in [St5, St6]. After the appearance of the above papers, several new papers and a book appeared on this subject using a state space approach (see e.g. [BB, Ig, Wa]). <p> The extension to the finite horizon discrete time case (similar to chapter 8) is discussed in <ref> [Bas, Li4] </ref>. It would be interesting to find two dual Riccati equations and a coupling condition as in [Ig, Wa] for the case that either D 21 is not injective or D 12 is not surjective.
Reference: [BB] <author> T. Basar, P. Bernhard, </author> <title> H 1 -optimal control and related minimax design problems: a dynamic game approach, </title> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference-contexts: Recently, a number of papers appeared which studied a zero-sum differential game with the goal of obtaining such a characterization (see [Pe2, Pe3, We]). A very recent book on the relation between H 1 and differential games is <ref> [BB] </ref>. In chapter 4 it has been shown that if the direct-feedthrough matrix from the control input to the output is not injective then, instead of an algebraic Riccati equation, we get a quadratic matrix inequality. <p> After the appearance of the above papers, several new papers and a book appeared on this subject using a state space approach (see e.g. <ref> [BB, Ig, Wa] </ref>). Very recently the J-spectral factorization approach has also been extended to discrete time systems (see [LMK]). In this chapter we assume that we deal with the special cases that either both disturbance and state are available for feedback or only the state is available for feedback.
Reference: [BBK] <author> S. Boyd, V. Balakrishnan, P. Kabamba, </author> <title> "A bisection method for computing the H 1 -norm of a transfer matrix and related problems", Math. Contr. Sign. </title> & <journal> Syst., </journal> <volume> Vol. 2, </volume> <year> 1989, </year> <pages> pp. 207-219. </pages>
Reference-contexts: This also results in numerical problems. Fortunately there is an easy and numerically reliable test whether the resulting feedback is stabilizing and satisfies the H 1 norm bound for the closed-loop system. A good algorithm to calculate the H 1 norm can be found in <ref> [BBK, BS] </ref>. In other words, we can check whether the numerical problems resulted in a bad design. The algorithm in [OSS1, OSS2] also involves rank evaluations.
Reference: [BC] <author> J.A. Ball, N. Cohen, </author> <title> "Sensitivity minimization in the H 1 norm: parametrization of all suboptimal solutions", </title> <journal> Int. J. Contr., </journal> <volume> Vol. 46, </volume> <year> 1987, </year> <pages> pp. 785-816. </pages>
Reference: [Bel] <author> R. Bellman, </author> <title> Introduction to matrix analysis, 2nd ed., </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1970. </year>
Reference-contexts: Therefore G ((P +P T )=2) has m eigenvalues on the positive real axis and l eigenvalues on the negative real axis. We know G ((P +P T )=2)G (L) 0 since (P + P T )=2 L. An easy consequence of the theorem of Courant-Fischer (see <ref> [Bel] </ref>) then tells us that G (L) has at least l eigenvalues on the negative real axis.
Reference: [BH] <author> D.S. Bernstein, W.M. Haddad, </author> <title> "Steady state Kalman filtering with an H 1 error bound", </title> <journal> Syst. & Contr. Letters, </journal> <volume> Vol. 12, </volume> <year> 1989, </year> <pages> pp. 9-16. </pages>
Reference-contexts: This extension is discussed in <ref> [BH, BH2, Do4, HB, HB2, Kh6, ZK3] </ref>. The paper [Kh6] has been extended to the singular case in [St14]. In this chapter we extend the results of [Mu] to the singular case. We still exclude invariant zeros on the imaginary axis. <p> However, in practice we would like to know whether a controller of lower McMillan degree exists which still gives an acceptable closed-loop performance. A main area of research, therefore, lies in reduced order H 1 controllers and in model reduction with an H 1 criterion (see <ref> [BH, HB, Mu2] </ref>).
Reference: [BH2] <author> D.S. Bernstein, W.M. Haddad, </author> <title> "LQG control with an H 1 performance bound: A Riccati equation approach", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 34, No. 3, </volume> <year> 1989, </year> <pages> pp. 293-305. 260 Bibliography 261 </pages>
Reference-contexts: This extension is discussed in <ref> [BH, BH2, Do4, HB, HB2, Kh6, ZK3] </ref>. The paper [Kh6] has been extended to the singular case in [St14]. In this chapter we extend the results of [Mu] to the singular case. We still exclude invariant zeros on the imaginary axis.
Reference: [Bo] <author> P. Boekhoudt, </author> <title> The H 1 control design method: a polynomial approach, </title> <type> Ph.D. Thesis, </type> <institution> University of Twente, Enschede, </institution> <year> 1988. </year>
Reference-contexts: The detailed formulations of the results obtained via this method will be given in this chapter. * The polynomial approach (see <ref> [Bo, Kw, Kw2] </ref>). This method starts with a polynomial left (or right) coprime factorization of the transfer matrix of the system. Then it is shown that a controller which minimizes the H 1 norm of the closed-loop system is a so-called equalizing solution of a certain minimization problem. <p> Chapter 6 The singular zero-sum differential game with stability 6.1 Introduction In this chapter we shall consider the zero-sum linear quadratic finite-dimensional differential game. This is an area of research which was rather popular during the seventies (see e.g. <ref> [Ban, Ma, BO, Sw] </ref>).
Reference: [BO] <author> T. Basar, G.J. Olsder, </author> <title> Dynamic noncooperative game theory, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: The detailed formulations of the results obtained via this method will be given in this chapter. * The polynomial approach (see <ref> [Bo, Kw, Kw2] </ref>). This method starts with a polynomial left (or right) coprime factorization of the transfer matrix of the system. Then it is shown that a controller which minimizes the H 1 norm of the closed-loop system is a so-called equalizing solution of a certain minimization problem. <p> Chapter 6 The singular zero-sum differential game with stability 6.1 Introduction In this chapter we shall consider the zero-sum linear quadratic finite-dimensional differential game. This is an area of research which was rather popular during the seventies (see e.g. <ref> [Ban, Ma, BO, Sw] </ref>).
Reference: [BS] <author> N.A. Bruinsma, M. Steinbuch, </author> <title> "A fast algorithm to compute the H 1 norm of a transfer matrix", </title> <journal> Syst. & Contr. Letters, </journal> <volume> Vol. 14, </volume> <year> 1990, </year> <pages> pp. 287-293. </pages>
Reference-contexts: This also results in numerical problems. Fortunately there is an easy and numerically reliable test whether the resulting feedback is stabilizing and satisfies the H 1 norm bound for the closed-loop system. A good algorithm to calculate the H 1 norm can be found in <ref> [BBK, BS] </ref>. In other words, we can check whether the numerical problems resulted in a bad design. The algorithm in [OSS1, OSS2] also involves rank evaluations.
Reference: [BvS] <author> A. Bensoussan, J.H. van Schuppen, </author> <title> "Optimal control of partially observable stochastic systems with an exponential-of-integral performance index", </title> <journal> SIAM J. Contr. & Opt., </journal> <volume> Vol. 23, No. 4, </volume> <year> 1985, </year> <pages> pp. 599-613. </pages>
Reference-contexts: Note that the central controller can be given an interpretation as minimizing the entropy (see chapter 7) and as the optimal controller for the linear exponential Gaussian stochastic control problem (see <ref> [BvS, Wh] </ref>). For the regular case this characterization is completely similar to the characterization given in [Do5, Ta]. 5.6 No assumptions on any direct-feedthrough matrix In this section we shall briefly discuss how we can extend our result in theorem 5.1 to the more general system (2.1).
Reference: [BW] <author> D. Biss, K.G. Woodgate, </author> <title> "Gas turbine control using mixed-sensitivity H 1 optimization", Robust control of linear systems and nonlinear control, </title> <booktitle> Proc. MTNS-89, Vol II, </booktitle> <address> M.A. </address> <publisher> Kaashoek, </publisher> <editor> J.H. van Schuppen, A.C.M. Ran (eds.), </editor> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1990, </year> <pages> pp. </pages> <address> 255- 265. </address>
Reference-contexts: reflect what you can and cannot do with H 1 control. * An aircraft autopilot design: see [SLH, SC] * Vertical plane dynamics of an aircraft: see [MF, M] * Large space structure: see [SC2] * Attitude control of a flexible space platform: see [MF] * Gas turbine control: see <ref> [BW] </ref> * Control design for a 90 MW coal fired fluidized bed boiler: see [Cr]. Basically the above examples discuss the choice of weights, after which they simply apply the results as discussed in this book. The only difference is the book [MF].
Reference: [Ch] <author> T. Chen, B.A. Francis, </author> <title> "On the L 2 -induced norm of a sampled-data system", </title> <journal> Syst. & Contr. Letters, </journal> <volume> Vol. 15, </volume> <year> 1990, </year> <pages> pp. 211-220. </pages>
Reference-contexts: Finally, consider sampled-data design where we take the sample and hold functions of the digital implementation of our controller into account in the design of our controller. In <ref> [Ch, KH, SK] </ref>) it has been shown that if we use sampled-data design for a H 1 control problem of a continuous time system then this can be reduced to a discrete time H 1 control problem.
Reference: [Ch2] <author> T. Chen, B.A. Francis, </author> <title> "H 2 -optimal sampled-data control", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 36, No. 4, </volume> <year> 1991, </year> <pages> pp. 387-397. </pages>
Reference: [Cr] <author> J.W. van Crevel, </author> <title> "Control design for a 90 MW coal fired fluidized bed boiler", </title> <publisher> Cambridge Control Ltd., Report no. </publisher> <address> 36-R82/2, </address> <year> 1989. </year>
Reference-contexts: autopilot design: see [SLH, SC] * Vertical plane dynamics of an aircraft: see [MF, M] * Large space structure: see [SC2] * Attitude control of a flexible space platform: see [MF] * Gas turbine control: see [BW] * Control design for a 90 MW coal fired fluidized bed boiler: see <ref> [Cr] </ref>. Basically the above examples discuss the choice of weights, after which they simply apply the results as discussed in this book. The only difference is the book [MF]. These authors discuss a design method combining loop-shaping with robustness requirements.
Reference: [CS] <author> R.Y. Chiang, M.G. Safonov, </author> <title> Robust control toolbox user's guide, </title> <publisher> The Mathworks Inc., </publisher> <address> Sherborn, MA, </address> <year> 1988. </year>
Reference-contexts: However, results like this facilitate the construction of weights. Specific performance criteria like the ones above can be left out while constructing weights and can be incorporated at a later stage. Finally it should be noted that there are now several toolboxes available (see, e.g. <ref> [CS, Va] </ref>) using the software package Matlab which contain 11.4 An inverted pendulum on a cart 217 built-in tools to design controllers based on LQG and H 1 control techniques.
Reference: [Do] <author> J.C. Doyle, G. Stein, </author> <title> "Multivariable feedback design: concepts for a classical/modern synthesis", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 26, No. 1, </volume> <year> 1981, </year> <pages> pp. 4-16. </pages>
Reference-contexts: (P ) = n + rank R (s) G ci ; 8s 2 C 0 [ C + . 2 11.3 Practical applications Many design problems can be reformulated in terms of constraints on the largest and smallest singular values of the closed-loop transfer matrix for each frequency (see, e.g. <ref> [Do, Hor] </ref>.) This clearly gives an immediate starting point for rephrasing these problems as H 1 control problems. To reformulate the performance requirements into a standard H 1 control 11.3 Practical applications 215 problem, as we are studying in this book, requires the choice of appropriate weights.
Reference: [Do2] <author> J.C. Doyle, </author> <title> "Analysis of feedback systems with structured uncertainties", </title> <booktitle> IEE Proc., </booktitle> <volume> Vol. 129, Part D, </volume> <year> 1982, </year> <pages> pp. 242-250. </pages>
Reference: [Do3] <author> J.C. Doyle, </author> <booktitle> "Lecture notes in advances in multivariable control", ONR/Honeywell Workshop, </booktitle> <address> Minneapolis, </address> <year> 1984. </year>
Reference-contexts: In this chapter we shall investigate the more general system (2.1). Around 1984 practically all the work on H 1 control theory with measurement feedback was done with a mixture of time-domain and frequency-domain techniques (see <ref> [Do3, Fr2, Gl, Gl6] </ref>). The main drawback of these methods was that it yielded high order controllers.
Reference: [Do4] <author> J.C. Doyle, K. Zhou, B. Bodenheimer, </author> <title> "Optimal control with mixed H 2 and H 1 performance objectives", </title> <booktitle> Proc. ACC, </booktitle> <address> Pitts-burgh, PA, </address> <year> 1989, </year> <pages> pp. 2065-2070. 262 Bibliography </pages>
Reference-contexts: This extension is discussed in <ref> [BH, BH2, Do4, HB, HB2, Kh6, ZK3] </ref>. The paper [Kh6] has been extended to the singular case in [St14]. In this chapter we extend the results of [Mu] to the singular case. We still exclude invariant zeros on the imaginary axis.
Reference: [Do5] <author> J. Doyle, K. Glover, P.P. Khargonekar, B.A. Francis, </author> <title> "State space solutions to standard H 2 and H 1 control problems", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 34, No. 8, </volume> <year> 1989, </year> <pages> pp. 831-847. </pages>
Reference-contexts: One should note that the classic interpolation techniques were used for discrete time systems. At first the continuous time case was treated via a frequency-domain transformation to the discrete time case (a linear fractional transformation as given in [Gen, appendix 1]). * The time-domain approach (see <ref> [Do5, Kh3, Kh4, Pe, Ta] </ref>). This 91 92 H 1 control with measurement feedback method was the first to suggest the use of Riccati equations in H 1 control, which was an important breakthrough. <p> For the special case of full-information feedback, these methods are discussed in section 4.7. Using the first method discussed in subsection 4.7.1, which applies a transformation in the complex plane combined with the results in <ref> [Do5, Kh3, Pe, Ta] </ref>, we still have to make assumptions: two given subsystems should be left and right invertible respectively. The second method combined with the methods of the latter papers can tackle the most general case. <p> In this chapter we shall present a method which, independently of the latter papers, solves the measurement feedback case using the results of our previous chapter. In contrast to <ref> [Do5, Kh3, Pe, Ta] </ref> we shall impose no assumptions on the direct-feedthrough matrices. However, we still have to exclude invariant zeros on the imaginary axis. Our method will not have the above-mentioned drawback of a parametrized Riccati equation. <p> However, we still have to exclude invariant zeros on the imaginary axis. Our method will not have the above-mentioned drawback of a parametrized Riccati equation. Also our results reduce to the known results in <ref> [Do5, Ta] </ref> when these singularities of the direct-feedthrough matrices do not occur. Another advantage of our (weaker) assumptions will be that the special cases of state feedback and full-information feedback fall within the framework of the general problem formulation. <p> The necessary and sufficient conditions under which there exists an internally stabilizing dynamic compensator which makes the H 1 norm strictly less than some a priori given bound fl are formulated differently from recent publications <ref> [Do5, Ta] </ref>. As mentioned above, in these papers the conditions are formulated in terms of two given Riccati equations. However, when there are singularities of the direct-feedthrough matrices these Riccati equations do not exist. To replace the role of these Riccati equations we have two quadratic matrix inequalities. <p> The second quadratic matrix inequality with the remaining two rank conditions are, again as in the regular case, dual to the first matrix inequality and the first two rank conditions. Our proof will use ideas given in <ref> [Do5] </ref> to solve the regular H 1 problem with measurement feedback but is independent of the results in [Do5] and is entirely self-contained. Most of the results of this chapter already appeared in [St4]. <p> Our proof will use ideas given in <ref> [Do5] </ref> to solve the regular H 1 problem with measurement feedback but is independent of the results in [Do5] and is entirely self-contained. Most of the results of this chapter already appeared in [St4]. The outline of this chapter is as follows: In section 5.2 we formulate the problem and present the main result for the case when two given direct-feedthrough matrices are zero. <p> Moreover, we show that in the regular case and the state feedback case this result reduces to the known results in <ref> [Do5] </ref> and chapter 4, respectively. In section 5.3 it is shown that the conditions for the existence of a suitable compensator as given in our main theorem are necessary and sufficient. <p> stable: A + fl 2 EE T P B (D T 1 2 C 2 ) ; 2 C 2 (QC T 1 ) (D 1 D T 1 Together with the remaining condition ae (P Q) &lt; fl 2 , we thus obtain ex actly the same conditions as <ref> [Do5, Gl3] </ref>. 100 H 1 control with measurement feedback 5.3 Reduction of the original problem to an almost disturbance decoupling problem In this section theorem 5.1 will be proven. <p> The alternative methods mentioned in that section can also be used for the general problem with measurement feedback. 5.5 Characterization of achievable closed-loop systems A characterization of all controllers which achieve the required H 1 norm bound has been given in <ref> [Do5, Ta] </ref>. This was a kind of ball around the so-called central controller (which is given in remark (ii) after theorem 5.1). This central controller has the alternative interpretation as the controller which minimizes the entropy function defined in chapter 7. <p> The question we would like to address in this section is whether similar characterizations can be given for the singular H 1 control problem. In our opinion it is not possible to obtain a characterization similar to the one obtained in <ref> [Do5] </ref>. This is due to the fact that the so-called central controller might be non-proper. But it turns out that it is much easier to characterize the closed-loop systems with H 1 norm less than 1 we can obtain via a suitable dynamic compensator. <p> Note that the central controller can be given an interpretation as minimizing the entropy (see chapter 7) and as the optimal controller for the linear exponential Gaussian stochastic control problem (see [BvS, Wh]). For the regular case this characterization is completely similar to the characterization given in <ref> [Do5, Ta] </ref>. 5.6 No assumptions on any direct-feedthrough matrix In this section we shall briefly discuss how we can extend our result in theorem 5.1 to the more general system (2.1). We set fl = 1 but the general result can be easily obtained by scaling. <p> This is an area of research which was rather popular during the seventies (see e.g. [Ban, Ma, BO, Sw]). In the last few years, the solution of the regular H 1 control problem (see chapter 3 and <ref> [Do5, Kh3, Pe] </ref>) turned out to contain the same kind of algebraic Riccati equation as the one appearing in the solution of the zero-sum differential game (see [Ban, Ma, Sw]). <p> feedback compensator which makes the H 1 norm less than some, a priori given, upper bound fl &gt; 0 can be easily derived from theorem 10.1 by scaling. 10.3 A first system transformation 195 (ii ) If we compare these conditions with the conditions for the continuous time case (see <ref> [Do5, St2] </ref>), then we note that our Riccati equations are coupled.
Reference: [Fa] <author> P.L. </author> <title> Faurre "Stochastic realization algorithms", System Identification: advances and case studies, R.K. </title> <editor> Mehra, D.G. Lainiotis (eds.), </editor> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1976, </year> <pages> pp. 1-25. </pages>
Reference-contexts: Hence if D 1 is injective we have the possibility of calculating the solution P of our three conditions. However, for discrete time Riccati equations it is sometimes more desirable to have recursive algorithms as, e.g. is given in <ref> [Fa] </ref> for a different type of Riccati equation. This is derived in [WA, St15]. An extension of the use of symplectic pairs to the case that D 1 is not injective is useful.
Reference: [FL] <author> J.S. Freudenberg, </author> <title> D.P. Looze, "Right half plane poles and zeros and design tradeoffs in feedback systems", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 30, No. 6, </volume> <year> 1985, </year> <pages> pp. 555-565. </pages>
Reference-contexts: This requires MIMO weights which translate directional information in terms of singular values. The above should clarify why practical problems are not solved as soon as you have read this book. A good understanding of design trade-offs (as discussed in, e.g. <ref> [FL] </ref>) and your system are required to construct weights which yield an H 1 control problem which suitably reflects all your criteria. Several examples have been treated in literature.
Reference: [Fr] <author> B.A. Francis, </author> <title> "The optimal linear-quadratic time invariant regulator with cheap control", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 24, </volume> <year> 1979, </year> <pages> pp. 616-621. </pages>
Reference: [Fr2] <author> B.A. Francis, </author> <title> A course in H 1 control theory, </title> <booktitle> Lecture notes in control and information sciences, </booktitle> <volume> Vol 88, </volume> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1987. </year>
Reference-contexts: In this chapter we shall investigate the more general system (2.1). Around 1984 practically all the work on H 1 control theory with measurement feedback was done with a mixture of time-domain and frequency-domain techniques (see <ref> [Do3, Fr2, Gl, Gl6] </ref>). The main drawback of these methods was that it yielded high order controllers. <p> The latter problem has already been investigated. It is possible that the infimum over all stabilizing controllers of the closed-loop H 1 norm is never attained, attained by a non-proper controller or attained by a proper controller (see <ref> [Fr2] </ref>). Using the ideas of this chapter it might be possible to characterize whether we can attain the infimum by a proper controller. 5.7 Conclusion 119 Finally, it would be interesting to characterize all controllers which achieve the H 1 norm bound. <p> However, H 1 controllers are designed to minimize the peak value of the magnitude Bode diagram. It is well-known that using the frequency-domain approach to H 1 control (see <ref> [Fr2, Kw, Kw2] </ref>) we find closed-loop transfer matrices with a completely flat magnitude Bode diagram. In the latter two papers this was even explicitly used to find suitable controllers. <p> Our approach is based on the paper [HSK], which only treats the regular one block problem (D 12 and D 21 in (2.1) are both square invertible matrices). The H 1 control problem with measurement feedback can be reduced to the so-called model-matching problem (see <ref> [Fr2] </ref>). This is the following problem: inf kT 1 T 2 QT 3 k 1 ; (12.2) where T 1 ; T 2 and T 3 are given matrices in H 1 .
Reference: [Ga] <author> F.R. Gantmacher, </author> <title> The theory of matrices, </title> <publisher> Chelsea, </publisher> <address> New York, </address> <year> 1959. </year>
Reference: [Gee] <author> T. Geerts, </author> <title> "All optimal controls for the singular linear-quadratic problem without stability; a new interpretation of the optimal cost", </title> <journal> Lin. Alg. Appl., </journal> <volume> Vol. 122, </volume> <year> 1989, </year> <pages> pp. 65-104. </pages>
Reference-contexts: Via the reduced order Riccati equation associated with this linear matrix inequality (see appendix A) it can be shown that the largest solution of the linear matrix 11.2 Robustness problems 211 inequality, whose existence is guaranteed since (C,A) is detectable (dual-ize the results in <ref> [Gee, Wi7] </ref>), satisfies all the requirements on Q m . This shows existence of Q m . Uniqueness was already guaranteed by corollary A.7.
Reference: [Gen] <author> Y. Genin, P. van Dooren, T. Kailath, J.M. Delosme, M. Morf, </author> <title> "On -lossless transfer functions and related questions", </title> <journal> Lin. Alg. Appl., </journal> <volume> Vol. 50, </volume> <year> 1983, </year> <pages> pp. 251-275. </pages>
Reference-contexts: One should note that the classic interpolation techniques were used for discrete time systems. At first the continuous time case was treated via a frequency-domain transformation to the discrete time case (a linear fractional transformation as given in <ref> [Gen, appendix 1] </ref>). * The time-domain approach (see [Do5, Kh3, Kh4, Pe, Ta]). This 91 92 H 1 control with measurement feedback method was the first to suggest the use of Riccati equations in H 1 control, which was an important breakthrough.
Reference: [GK] <author> G. Gu, </author> <note> P.P. Khargonekar, "A class of algorithms for identification in H 1 ", To appear in Automatica. </note>
Reference-contexts: Moreover, because of the extreme importance of 234 Conclusion robustness and its strong correlation with H 1 , its relation with almost all aspects of system and control theory is interesting. We could think of identification with H 1 error bounds (see, e.g. <ref> [HJN, GK, GK2] </ref>) and other combinations which at the moment might be far-fetched. However, control engineers working in practice will be the first to acknowledge that the main reason why they are sceptical about applying modern control schemes is their concern about robustness.
Reference: [GK2] <author> G. Gu, </author> <title> P.P. Khargonekar, "Linear and nonlinear algorithms for identification in H 1 with error bounds", </title> <note> To appear in IEEE Trans. Aut. Contr.. </note>
Reference-contexts: Moreover, because of the extreme importance of 234 Conclusion robustness and its strong correlation with H 1 , its relation with almost all aspects of system and control theory is interesting. We could think of identification with H 1 error bounds (see, e.g. <ref> [HJN, GK, GK2] </ref>) and other combinations which at the moment might be far-fetched. However, control engineers working in practice will be the first to acknowledge that the main reason why they are sceptical about applying modern control schemes is their concern about robustness.
Reference: [Gl] <author> K. Glover, </author> <title> "All optimal Hankel-norm approximations of linear multivariable systems and their L 1 -error bounds", </title> <journal> Int. J. Contr., </journal> <volume> Vol. 39, </volume> <year> 1984, </year> <pages> pp. 1115-1193. </pages>
Reference-contexts: In this chapter we shall investigate the more general system (2.1). Around 1984 practically all the work on H 1 control theory with measurement feedback was done with a mixture of time-domain and frequency-domain techniques (see <ref> [Do3, Fr2, Gl, Gl6] </ref>). The main drawback of these methods was that it yielded high order controllers.
Reference: [Gl2] <author> K. Glover, </author> <title> "Robust stabilization of multivariable linear systems: relations to approximation", </title> <journal> Int. J. Contr., </journal> <volume> Vol. 43, </volume> <year> 1986, </year> <pages> pp. 741-766. Bibliography 263 </pages>
Reference-contexts: The first two problems can be found in [MF, Vi]. The last problem is discussed in [Hi]. The second and third problems will in general yield singular H 1 control problems. 205 206 Applications 11.2.1 Additive perturbations Essentially the results of this subsection have already appeared in <ref> [Gl2] </ref>. Assume that we have a continuous time system being an imperfect model of a certain plant. <p> In fact, we can find a controller which makes the H 1 norm equal to [ae (P a Q a )] 1=2 (see <ref> [Gl2] </ref>) which is clearly the best we can do. (iii) It can be shown that the bound [ae (P a Q a )] 1=2 depends only on the antistable part of . <p> This result was already known (see, e.g. <ref> [Gl2] </ref>). 11.2.2 Multiplicative perturbations The results of this subsection have already appeared in [St8]. We assume that we once again have a continuous time system being an imperfect model of a certain plant.
Reference: [Gl3] <author> K. Glover, J. Doyle, </author> <title> "State-space formulaes for all stabilizing controllers that satisfy an H 1 norm bound and relations to risk sensitivity", </title> <journal> Syst. & Contr. Letters, </journal> <volume> Vol. 11, </volume> <year> 1988, </year> <pages> pp. 167-172. </pages>
Reference-contexts: It is a kind of test whether state estimation and state feedback combined in some way yield the desired result: an internally stabilizing feedback which makes the H 1 norm less than fl. The most general result under these assumptions is stated without proof in <ref> [Gl3] </ref>. In the literature two methods have been proposed to solve the H 1 problem without assumptions on the direct-feedthrough matrices and without assumptions on the invariant zeros. For the special case of full-information feedback, these methods are discussed in section 4.7. <p> In the regular case an explicit formula for one controller satisfying part (i) can be given (see <ref> [Gl3] </ref>). 98 H 1 control with measurement feedback That is, if P and Q exist satisfying the conditions of part (ii) of theorem 5.1, then a controller satisfying part (i) is given by: F : _p = K P;Q p + L P;Q y; where M P;Q := D T 1 <p> stable: A + fl 2 EE T P B (D T 1 2 C 2 ) ; 2 C 2 (QC T 1 ) (D 1 D T 1 Together with the remaining condition ae (P Q) &lt; fl 2 , we thus obtain ex actly the same conditions as <ref> [Do5, Gl3] </ref>. 100 H 1 control with measurement feedback 5.3 Reduction of the original problem to an almost disturbance decoupling problem In this section theorem 5.1 will be proven.
Reference: [Gl4] <author> K. Glover, D. Mc.Farlane, </author> <title> "Robust stabilization of normalized coprime factor plant description with H 1 -bounded uncertainty", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 34, </volume> <year> 1989, </year> <pages> pp. 821-830. </pages>
Reference: [Gl5] <author> K. Glover, </author> <title> "Minimum entropy and risk-sensitive control: the continuous time case", </title> <booktitle> Proc. CDC, </booktitle> <address> Tampa, FL, </address> <year> 1989, </year> <pages> pp. 388-391. </pages>
Reference-contexts: This has, as far as we know, never been proven but this is the reason why the problem we discuss in this chapter is sometimes referred to as the mixed LQG/H 1 or H 2 /H 1 control problem. For the regular case, this problem was solved in <ref> [Gl5, Mu, Mu2] </ref>. It was shown that a minimizing controller, which is often called the "central controller", always exists.
Reference: [Gl6] <author> K. Glover, D.J.N. Limebeer, J.C. Doyle, E.M. Kasenally, M.G. Safonov, </author> <title> "A characterization of all solutions to the four block general distance problem", </title> <journal> SIAM J. Contr. & Opt., </journal> <volume> Vol. 29, No. 2, </volume> <year> 1991, </year> <pages> pp. 283-324. </pages>
Reference-contexts: We shall use a technique from <ref> [Gl6] </ref> to reduce this problem to the problem studied in section 4.2. Throughout this section we shall assume that fl = 1. The more general result can be easily derived by scaling. <p> In this chapter we shall investigate the more general system (2.1). Around 1984 practically all the work on H 1 control theory with measurement feedback was done with a mixture of time-domain and frequency-domain techniques (see <ref> [Do3, Fr2, Gl, Gl6] </ref>). The main drawback of these methods was that it yielded high order controllers. <p> We first tackle the extra direct-feedthrough matrix D 22 and after that the extra direct-feedthrough matrix D 11 . 5.6.1 An extra direct-feedthrough matrix from disturbance to output The method we use for the case D 22 6= 0 is as the method presented in section 4.6 and stems from <ref> [Gl6] </ref>. <p> All of this holds under the constraint of internal stability and with state feedback. This provides a natural starting point for research for testing whether we can make the H 1 norm less than or equal to 1, as done in <ref> [Gl6] </ref> for the regular case. 12.1.3 The minimum entropy H 1 control problem In chapter 7 we discuss the minimum entropy H 1 control problem. We only discussed a very limited case.
Reference: [Gr] <author> M. Green, D.J.N. Limebeer, </author> <title> "Vector interpolation, H 1 control and model reduction", Robust control of linear systems and nonlinear control, </title> <booktitle> Proc. MTNS-89, Vol II, </booktitle> <address> M.A. </address> <publisher> Kaashoek, </publisher> <editor> J.H. van Schuppen, A.C.M. Ran (eds.), </editor> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1990, </year> <pages> pp. 285-292. </pages>
Reference-contexts: During the last few years the H 1 control problem with measurement feedback was investigated via several new methods: * The interpolation approach. In fact, the interpolation approach already has quite a history and several authors have worked on this problem (see e.g. <ref> [Gr, Kh, Li3, Za2] </ref>). However, it can only treat the special case of a one-block H 1 control problem. One should note that the classic interpolation techniques were used for discrete time systems.
Reference: [Gr2] <author> M. Green, K. Glover, D.J.N. Limebeer, J.C. Doyle, </author> <title> "A J-spectral factorization approach to H 1 control", </title> <journal> SIAM J. Contr. & Opt. </journal> <volume> Vol. 28, No. 6, </volume> <year> 1990, </year> <pages> pp. 1350-1371. </pages>
Reference-contexts: Conditions for obtaining an internally stabilizing controller which minimizes the H 1 norm are then given in terms of diophantine equations. The current research in this area is to investigate the relation between these diophantine equations and the conditions found in other methods. * The J-spectral factorization approach (see <ref> [Gr2, HSK, Ki] </ref>). This method is strongly based on the classic frequency-domain approach.
Reference: [Gri] <author> M.J. Grimble, </author> <title> "Optimal robustness and the relationship to LQG design problems", </title> <journal> Int. J. Contr., </journal> <volume> Vol. 43, </volume> <year> 1986, </year> <pages> pp. 351-372. </pages>
Reference-contexts: Recently, a paper has appeared solving the discrete time H 1 control problem using frequency-domain techniques (see [Gu]). The polynomial approach has also been applied to discrete time systems (see <ref> [Gri] </ref>). In addition, a couple of papers have appeared using a time-domain approach (see [Bas, Li4, Ya]).
Reference: [GS] <author> T.T. Georgiou, M.C. Smith, </author> <title> "Optimal robustness in the gap metric", </title> <booktitle> Proc. CDC, </booktitle> <address> Tampa, FL, </address> <year> 1989, </year> <pages> pp. 2331-2336. </pages>
Reference: [Gu] <author> D.W. Gu, M.C. Tsai, S.D. O'Young, I. Postelthwaite, </author> <title> "State space formulae for discrete time H 1 optimization", </title> <journal> Int. J. Contr., </journal> <volume> Vol. 49, </volume> <year> 1989, </year> <pages> pp. 1683-1723. </pages>
Reference-contexts: In the papers on H 1 control with continuous time several methods were used to solve the H 1 control problem as discussed in section 5.1. Recently, a paper has appeared solving the discrete time H 1 control problem using frequency-domain techniques (see <ref> [Gu] </ref>). The polynomial approach has also been applied to discrete time systems (see [Gri]). In addition, a couple of papers have appeared using a time-domain approach (see [Bas, Li4, Ya]). <p> This distinction has to be made since there is a more essential difference between these two cases than in the continuous time case. The more general case of measurement feedback is discussed in the next chapter. The assumptions we shall make are weaker than the assumptions made in <ref> [Gu, Ya] </ref> and the same as the ones made in [Li4]. For the full-information case we have to make two assumptions which are exactly the discrete time analogues of the assumptions made in the regular continuous time H 1 control problem as discussed in chapter 3. <p> Note the difference with the continuous time case where we could derive a differential equation forward in time, while in discrete time we can only derive a difference equation forward in time when A is invertible. To prevent this kind of difficulty it is assumed in <ref> [Gu] </ref> that A is invertible. The proof that j yields a minimizing u is adapted from the proof of lemma 3.4: 9.3 A solution of the Riccati equation 175 Lemma 9.6 : Let the system (9.1) be given. Moreover let w and be fixed.
Reference: [Ha] <author> M.L.J. Hautus, </author> <title> "Strong detectability and observers", </title> <journal> Lin. Alg. & Appl., </journal> <volume> Vol. 50, </volume> <year> 1983, </year> <pages> pp. 353-368. </pages>
Reference: [Hab] <author> L.C.G.J.M. Habets, </author> <title> Robust stabilization in the gap topology, </title> <booktitle> Lecture notes in control and information sciences, </booktitle> <volume> Vol. 150, </volume> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference: [HB] <author> W.M. Haddad, D.S. Bernstein, </author> <title> "Combined L 2 /H 1 model reduction", </title> <journal> Int. J. Contr., </journal> <volume> Vol. 49, </volume> <year> 1989, </year> <pages> pp. 1523-1535. 264 Bibliography </pages>
Reference-contexts: This extension is discussed in <ref> [BH, BH2, Do4, HB, HB2, Kh6, ZK3] </ref>. The paper [Kh6] has been extended to the singular case in [St14]. In this chapter we extend the results of [Mu] to the singular case. We still exclude invariant zeros on the imaginary axis. <p> However, in practice we would like to know whether a controller of lower McMillan degree exists which still gives an acceptable closed-loop performance. A main area of research, therefore, lies in reduced order H 1 controllers and in model reduction with an H 1 criterion (see <ref> [BH, HB, Mu2] </ref>).
Reference: [HB2] <author> W.M. Haddad, D.S. Bernstein, </author> <title> "Generalized Riccati equations for the full- and reduced-order mixed-norm H 2 /H 1 standard problem", </title> <journal> Syst. & Contr. Letters, </journal> <volume> Vol. 14, </volume> <year> 1990, </year> <pages> pp. 185-197. </pages>
Reference-contexts: This extension is discussed in <ref> [BH, BH2, Do4, HB, HB2, Kh6, ZK3] </ref>. The paper [Kh6] has been extended to the singular case in [St14]. In this chapter we extend the results of [Mu] to the singular case. We still exclude invariant zeros on the imaginary axis.
Reference: [Hi] <author> D. Hinrichsen, A.J. Pritchard, </author> <title> "Real and complex stability radii: a survey", Control of Uncertain Systems, </title> <booktitle> Proc. International Workshop, </booktitle> <address> Bremen, 1989, </address> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1990, </year> <pages> pp. 119-162. </pages>
Reference-contexts: Each time we find a problem which can be reduced to an H 1 control problem. The first two problems can be found in [MF, Vi]. The last problem is discussed in <ref> [Hi] </ref>. The second and third problems will in general yield singular H 1 control problems. 205 206 Applications 11.2.1 Additive perturbations Essentially the results of this subsection have already appeared in [Gl2]. Assume that we have a continuous time system being an imperfect model of a certain plant. <p> In contrast with the above, the 11.2 Robustness problems 213 theory of complex stability radii is concerned with perturbations of state space realizations (an interesting overview article is <ref> [Hi] </ref>). Assume some autonomous system is given: _x = (A + DE) x: A 2 R nfin ; D 2 R nfil and E 2 R pfin are given matrices and expresses the uncertainty which is structured by the matrices D and E. <p> R;d (A; D; E) := inf fkk 1 j = (F; G; H; J ) 2 S is such that fi ci described by (11.6) is not stable.g ; where S denotes the class of quadruples of real matrices which define an asymptotically stable system, then it is shown in <ref> [Hi] </ref> that the complex stability radius is equal to the real dynamic stability radius. This makes an investigation of the complex stability radius more important because we investigate the real dynamic stability radius at the same time. In [Hi] the following relation between H 1 control and the complex stability radius <p> matrices which define an asymptotically stable system, then it is shown in <ref> [Hi] </ref> that the complex stability radius is equal to the real dynamic stability radius. This makes an investigation of the complex stability radius more important because we investigate the real dynamic stability radius at the same time. In [Hi] the following relation between H 1 control and the complex stability radius is given: Lemma 11.5 : We have r C (A; D; E) = kGk 1 where G denotes the transfer matrix of (A; D; E; 0). 2 214 Applications Next we investigate the problem of maximization of the
Reference: [HJN] <author> A.J. Helmicki, C.A. Jacobson, C.N. Nett, </author> <title> "Control oriented system identification: a worst case/deterministic approach in H 1 ", IEEE Trans. </title> <journal> Aut. Contr., </journal> <volume> Vol. 36, </volume> <year> 1991, </year> <pages> pp. 1163-1176. </pages>
Reference-contexts: Moreover, because of the extreme importance of 234 Conclusion robustness and its strong correlation with H 1 , its relation with almost all aspects of system and control theory is interesting. We could think of identification with H 1 error bounds (see, e.g. <ref> [HJN, GK, GK2] </ref>) and other combinations which at the moment might be far-fetched. However, control engineers working in practice will be the first to acknowledge that the main reason why they are sceptical about applying modern control schemes is their concern about robustness.
Reference: [Ho] <author> K. Hoffman, </author> <title> Banach spaces of analytic functions, </title> <publisher> Prentice-Hall, </publisher> <address> Englewoods Cliffs, NJ, </address> <year> 1962. </year>
Reference: [Hor] <author> I.M. Horowitz, </author> <title> Synthesis of feedback systems, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1963. </year>
Reference-contexts: (P ) = n + rank R (s) G ci ; 8s 2 C 0 [ C + . 2 11.3 Practical applications Many design problems can be reformulated in terms of constraints on the largest and smallest singular values of the closed-loop transfer matrix for each frequency (see, e.g. <ref> [Do, Hor] </ref>.) This clearly gives an immediate starting point for rephrasing these problems as H 1 control problems. To reformulate the performance requirements into a standard H 1 control 11.3 Practical applications 215 problem, as we are studying in this book, requires the choice of appropriate weights.
Reference: [HSK] <author> S. Hara, T. Sugie, R. Kondo, </author> <title> "Descriptor form solution for H 1 control problem with j!-axis zeros", </title> <note> To appear in Automatica. </note>
Reference-contexts: Conditions for obtaining an internally stabilizing controller which minimizes the H 1 norm are then given in terms of diophantine equations. The current research in this area is to investigate the relation between these diophantine equations and the conditions found in other methods. * The J-spectral factorization approach (see <ref> [Gr2, HSK, Ki] </ref>). This method is strongly based on the classic frequency-domain approach. <p> These kind of conditions are all based on the requirement that the closed-loop transfer matrix satisfies certain constraints on the imaginary axis. Without proof we shall give the following result. This result stems basically from <ref> [HSK] </ref> and [Vi, lemma 6.5.9]. Theorem 11.7 : Let a system of the form (2.1) be given. Assume that a compensator of the form (2.4) which is internally stabilizing exists such that the closed-loop system has H 1 norm less than one. <p> In this subsection we want to discuss the difficulty of these invariant zeros intuitively. The reader should not expect formal proofs in this section. A treatment of invariant zeros on the imaginary axis for continuous time systems is given in several papers, <ref> [HSK, S3, S4] </ref>. <p> Besides that, separate extra conditions have to be satisfied for each invariant zero on the imaginary axis. However, it is worthwhile to look for alternative formulations of the results in <ref> [HSK, S3, S4] </ref> in order to obtain a better insight of what the extra conditions which have to be satisfied when we have an invariant zero on the imaginary axis look like. Moreover, a numerical reliable way of finding a suitable controller, if one exists, is needed. <p> This yields good understanding of the nature of the problems but gives results which are in general numerically not very reliable. Next, we shall try to show the difficulty of invariant zeros on the imaginary axis for continuous time systems. Our approach is based on the paper <ref> [HSK] </ref>, which only treats the regular one block problem (D 12 and D 21 in (2.1) are both square invertible matrices). The H 1 control problem with measurement feedback can be reduced to the so-called model-matching problem (see [Fr2]).
Reference: [Ig] <author> P.A. Iglesias, K. Glover, </author> <title> "State space approach to discrete time H 1 control", </title> <note> To appear in Int. J. Contr., </note> <year> 1991. </year>
Reference-contexts: After the appearance of the above papers, several new papers and a book appeared on this subject using a state space approach (see e.g. <ref> [BB, Ig, Wa] </ref>). Very recently the J-spectral factorization approach has also been extended to discrete time systems (see [LMK]). In this chapter we assume that we deal with the special cases that either both disturbance and state are available for feedback or only the state is available for feedback. <p> For details we refer to [St15]. We investigate the existence of a matrix P such that: * The matrix G (P ) defined by (9.3) is invertible. * P satisfies the discrete algebraic Riccati equation (9.4). * The matrix A cl defined by (9.5) is asymptotically stable. In <ref> [Ig, Wa] </ref> solvability of the discrete time algebraic Riccati equation introduced in this chapter is reduced to a generalized eigenvalue problem for a symplectic pair. We show that this can be done if D 1 is injective. In general, no method is available for such a reduction. <p> However, this time we did not succeed in expressing the existence and the solution in terms of the solutions of the full-information Riccati equation and its dual version. Recently it has been shown (see <ref> [Ig, Wa] </ref>) that if the direct-feedthrough matrices from u to z and from w to y are injective and surjective respectively then we can reduce our result to a result similar to theorem 5.1: two uncoupled Riccati equations and a coupling condition (a bound on the spectral radius of the product <p> In <ref> [Ig, Wa] </ref> it has been shown that if D 21 is injective and D 12 is surjective then our conditions (d)-(f) are equivalent to the existence of a matrix Q which is dual to P in the sense that Q satisfies the same conditions as P but for the system T <p> The extension to the finite horizon discrete time case (similar to chapter 8) is discussed in [Bas, Li4]. It would be interesting to find two dual Riccati equations and a coupling condition as in <ref> [Ig, Wa] </ref> for the case that either D 21 is not injective or D 12 is not surjective. Nevertheless the results presented in this chapter show that it is possible to solve discrete time H 1 problems directly, instead of transforming them to continuous time problems.
Reference: [KA] <author> J.P. Keller, B.D.O. Anderson, </author> <title> "A new approach to discretization of continuous-time controllers", </title> <booktitle> Proc. ACC, </booktitle> <address> San Diego, CA, </address> <year> 1990, </year> <pages> pp. 1133-1136. </pages>
Reference: [Kh] <author> P.P. Khargonekar, A. Tannenbaum, </author> <title> "Non-Euclidian metrics and the robust stabilization of systems with parameter uncertainty", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 30, </volume> <year> 1985, </year> <pages> pp. 1005-1013. </pages>
Reference-contexts: During the last few years the H 1 control problem with measurement feedback was investigated via several new methods: * The interpolation approach. In fact, the interpolation approach already has quite a history and several authors have worked on this problem (see e.g. <ref> [Gr, Kh, Li3, Za2] </ref>). However, it can only treat the special case of a one-block H 1 control problem. One should note that the classic interpolation techniques were used for discrete time systems. <p> Finally, consider sampled-data design where we take the sample and hold functions of the digital implementation of our controller into account in the design of our controller. In <ref> [Ch, KH, SK] </ref>) it has been shown that if we use sampled-data design for a H 1 control problem of a continuous time system then this can be reduced to a discrete time H 1 control problem.
Reference: [Kh2] <author> P.P. Khargonekar, I.R. Petersen, K. Zhou, </author> <title> "Robust stabilization of uncertain systems and H 1 optimal control", </title> <booktitle> Proc. Allerton Conf. on Comm., Contr. & Comp., </booktitle> <address> Monticello, IL, </address> <year> 1987, </year> <pages> pp. 88-95. </pages>
Reference-contexts: is given in [S3] will probably lead to much more elegant conditions but these conditions are too complex to explain here in detail (some discussions on this alternative method are given in subsection 12.2.1). 4.7 Invariant zeros on the imaginary axis 85 4.7.1 Frequency-domain loop shifting The basic method (see <ref> [Kh2, Li3, Sa] </ref>) here is based on applying a transformation in the frequency-domain. This method is applicable for the full-information feedback case. <p> section 5.1 88 The general full-information H 1 control problem for the H 1 control problem with measurement feedback are often not very suitable to treat the special cases of state feedback and full-information feedback. 4.7.2 Cheap control In this subsection we shall briefly describe how the method used in <ref> [Kh3, Kh2, Pe3, Pe5, ZK2] </ref> still gives necessary and sufficient conditions for the existence of internally stabilizing controllers which make the H 1 norm of the closed-loop system less than 1 even when we have invariant zeros on the imaginary axis.
Reference: [Kh3] <author> P.P. Khargonekar, I.R. Petersen, M.A. Rotea, </author> <title> "H 1 optimal control with state feedback", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 33, </volume> <year> 1988, </year> <pages> pp. 786-788. </pages>
Reference-contexts: section 5.1 88 The general full-information H 1 control problem for the H 1 control problem with measurement feedback are often not very suitable to treat the special cases of state feedback and full-information feedback. 4.7.2 Cheap control In this subsection we shall briefly describe how the method used in <ref> [Kh3, Kh2, Pe3, Pe5, ZK2] </ref> still gives necessary and sufficient conditions for the existence of internally stabilizing controllers which make the H 1 norm of the closed-loop system less than 1 even when we have invariant zeros on the imaginary axis. <p> One should note that the classic interpolation techniques were used for discrete time systems. At first the continuous time case was treated via a frequency-domain transformation to the discrete time case (a linear fractional transformation as given in [Gen, appendix 1]). * The time-domain approach (see <ref> [Do5, Kh3, Kh4, Pe, Ta] </ref>). This 91 92 H 1 control with measurement feedback method was the first to suggest the use of Riccati equations in H 1 control, which was an important breakthrough. <p> For the special case of full-information feedback, these methods are discussed in section 4.7. Using the first method discussed in subsection 4.7.1, which applies a transformation in the complex plane combined with the results in <ref> [Do5, Kh3, Pe, Ta] </ref>, we still have to make assumptions: two given subsystems should be left and right invertible respectively. The second method combined with the methods of the latter papers can tackle the most general case. <p> In this chapter we shall present a method which, independently of the latter papers, solves the measurement feedback case using the results of our previous chapter. In contrast to <ref> [Do5, Kh3, Pe, Ta] </ref> we shall impose no assumptions on the direct-feedthrough matrices. However, we still have to exclude invariant zeros on the imaginary axis. Our method will not have the above-mentioned drawback of a parametrized Riccati equation. <p> This is an area of research which was rather popular during the seventies (see e.g. [Ban, Ma, BO, Sw]). In the last few years, the solution of the regular H 1 control problem (see chapter 3 and <ref> [Do5, Kh3, Pe] </ref>) turned out to contain the same kind of algebraic Riccati equation as the one appearing in the solution of the zero-sum differential game (see [Ban, Ma, Sw]).
Reference: [Kh4] <author> P.P. Khargonekar, </author> <title> "State-space H 1 control theory", Mathematical system theory: the influence of R.E. Kalman, Edited by A.C. </title> <publisher> Antoulas, Springer Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year> <note> Bibliography 265 </note>
Reference-contexts: One should note that the classic interpolation techniques were used for discrete time systems. At first the continuous time case was treated via a frequency-domain transformation to the discrete time case (a linear fractional transformation as given in [Gen, appendix 1]). * The time-domain approach (see <ref> [Do5, Kh3, Kh4, Pe, Ta] </ref>). This 91 92 H 1 control with measurement feedback method was the first to suggest the use of Riccati equations in H 1 control, which was an important breakthrough.
Reference: [Kh5] <author> P.P. Khargonekar, I.R. Petersen, K. Zhou, </author> <title> "Robust stabilization of uncertain linear systems: quadratic stabilizability and H 1 control theory", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 35, </volume> <year> 1990, </year> <pages> pp. 356-361. </pages>
Reference: [Kh6] <author> P.P. Khargonekar, M.A. Rotea, </author> <title> "Mixed H 2 /H 1 control: a convex optimization approach", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 36, </volume> <year> 1991, </year> <pages> pp. 824-837. </pages>
Reference-contexts: This extension is discussed in <ref> [BH, BH2, Do4, HB, HB2, Kh6, ZK3] </ref>. The paper [Kh6] has been extended to the singular case in [St14]. In this chapter we extend the results of [Mu] to the singular case. We still exclude invariant zeros on the imaginary axis. <p> This extension is discussed in [BH, BH2, Do4, HB, HB2, Kh6, ZK3]. The paper <ref> [Kh6] </ref> has been extended to the singular case in [St14]. In this chapter we extend the results of [Mu] to the singular case. We still exclude invariant zeros on the imaginary axis.
Reference: [KH] <author> P. Kabamba, S. Hara, </author> <title> "On computing the induced norm of a sampled data system", </title> <booktitle> Proc. ACC, </booktitle> <address> San Diego, CA, </address> <year> 1990, </year> <pages> pp. 319-320. </pages>
Reference-contexts: During the last few years the H 1 control problem with measurement feedback was investigated via several new methods: * The interpolation approach. In fact, the interpolation approach already has quite a history and several authors have worked on this problem (see e.g. <ref> [Gr, Kh, Li3, Za2] </ref>). However, it can only treat the special case of a one-block H 1 control problem. One should note that the classic interpolation techniques were used for discrete time systems. <p> Finally, consider sampled-data design where we take the sample and hold functions of the digital implementation of our controller into account in the design of our controller. In <ref> [Ch, KH, SK] </ref>) it has been shown that if we use sampled-data design for a H 1 control problem of a continuous time system then this can be reduced to a discrete time H 1 control problem.
Reference: [Ki] <author> H. Kimura, </author> <title> "Conjugation, interpolation and model-matching in H 1 ", Int. </title> <journal> J. Contr., </journal> <volume> Vol. 49, </volume> <year> 1989, </year> <pages> pp. 269-307. </pages>
Reference-contexts: Conditions for obtaining an internally stabilizing controller which minimizes the H 1 norm are then given in terms of diophantine equations. The current research in this area is to investigate the relation between these diophantine equations and the conditions found in other methods. * The J-spectral factorization approach (see <ref> [Gr2, HSK, Ki] </ref>). This method is strongly based on the classic frequency-domain approach.
Reference: [Ku] <author> V. Kucera, </author> <title> "A contribution to matrix quadratic equations", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 17, </volume> <year> 1972, </year> <pages> pp. 344-347. </pages>
Reference-contexts: of the algebraic Riccati equation: XA + A T X + XBB T X + C T C = 0 such that A + BB T X is asymptotically stable. 2 7.4 A system transformation 147 Proof : The existence and uniqueness of X is a well-known result (see e.g. <ref> [Ku] </ref>). It is easy to check that the transfer matrix M with realization (A; B; B T X; I) satisfies: I G G = M M Moreover, M; M 1 2 H 1 , i.e. M is a spectral factor of I G G. <p> Since (A; B) is stabilizable and (C; A) is detectable, existence and uniqueness of P a and Q a is guaranteed by standard linear quadratic control (see <ref> [Ku] </ref>). After applying theorems 5.1, 5.11 and 11.1 we find the following theorem: Theorem 11.2 : Assume that a system is given with a stabilizable and detectable realization (A; B; C; D) such that A has no eigenvalues on the imaginary axis.
Reference: [Kw] <author> H. Kwakernaak, </author> <title> "A polynomial approach to minimax frequency domain optimization of multivariable feedback systems", </title> <journal> Int. J. Contr., </journal> <volume> Vol. 41, </volume> <year> 1986, </year> <pages> pp. 117-156. </pages>
Reference-contexts: The detailed formulations of the results obtained via this method will be given in this chapter. * The polynomial approach (see <ref> [Bo, Kw, Kw2] </ref>). This method starts with a polynomial left (or right) coprime factorization of the transfer matrix of the system. Then it is shown that a controller which minimizes the H 1 norm of the closed-loop system is a so-called equalizing solution of a certain minimization problem. <p> However, H 1 controllers are designed to minimize the peak value of the magnitude Bode diagram. It is well-known that using the frequency-domain approach to H 1 control (see <ref> [Fr2, Kw, Kw2] </ref>) we find closed-loop transfer matrices with a completely flat magnitude Bode diagram. In the latter two papers this was even explicitly used to find suitable controllers.
Reference: [Kw2] <author> H. Kwakernaak, </author> <title> "Progress in the polynomial solution of the standard H 1 optimal control problem", </title> <booktitle> Proceedings 11th IFAC World Congress, </booktitle> <volume> Vol. 5, </volume> <editor> Ed. V. Utkin, U. Jaaksoo, </editor> <address> Tallinn, USSR, </address> <year> 1990, </year> <pages> pp. 122-129. </pages>
Reference-contexts: The detailed formulations of the results obtained via this method will be given in this chapter. * The polynomial approach (see <ref> [Bo, Kw, Kw2] </ref>). This method starts with a polynomial left (or right) coprime factorization of the transfer matrix of the system. Then it is shown that a controller which minimizes the H 1 norm of the closed-loop system is a so-called equalizing solution of a certain minimization problem. <p> However, H 1 controllers are designed to minimize the peak value of the magnitude Bode diagram. It is well-known that using the frequency-domain approach to H 1 control (see <ref> [Fr2, Kw, Kw2] </ref>) we find closed-loop transfer matrices with a completely flat magnitude Bode diagram. In the latter two papers this was even explicitly used to find suitable controllers.
Reference: [Li] <author> D.J.N. Limebeer, Y.S. Hung, </author> <title> "An analysis of the pole-zero cancellations in H 1 optimal control problems of the first kind", </title> <journal> SIAM J. Contr. & Opt., </journal> <volume> Vol. 25, </volume> <year> 1987, </year> <pages> pp. 1457-1493. </pages>
Reference-contexts: Around 1984 practically all the work on H 1 control theory with measurement feedback was done with a mixture of time-domain and frequency-domain techniques (see [Do3, Fr2, Gl, Gl6]). The main drawback of these methods was that it yielded high order controllers. In <ref> [Li, Li2] </ref> it was shown that the order of the controller could be reduced considerably: it was proven that for the one block H 1 control problem (the matrices D 12 and D 21 appearing in (2.1) are both square matrices) and for the two block H 1 control problem (either
Reference: [Li2] <author> D.J.N. Limebeer, G.D. Halikias, </author> <title> "A controller degree bound for H 1 control problems of the second kind", </title> <journal> SIAM J. Contr. & Opt., </journal> <volume> Vol. 26, </volume> <year> 1988, </year> <pages> pp. 646-677. </pages>
Reference-contexts: Around 1984 practically all the work on H 1 control theory with measurement feedback was done with a mixture of time-domain and frequency-domain techniques (see [Do3, Fr2, Gl, Gl6]). The main drawback of these methods was that it yielded high order controllers. In <ref> [Li, Li2] </ref> it was shown that the order of the controller could be reduced considerably: it was proven that for the one block H 1 control problem (the matrices D 12 and D 21 appearing in (2.1) are both square matrices) and for the two block H 1 control problem (either
Reference: [Li3] <author> D.J.N. Limebeer, B.D.O. Anderson, </author> <title> "An interpolation theory approach to H 1 controller degree bounds", </title> <journal> Lin. Alg. Appl., </journal> <volume> Vol. 98, </volume> <year> 1988, </year> <pages> pp. 347-386. </pages>
Reference-contexts: is given in [S3] will probably lead to much more elegant conditions but these conditions are too complex to explain here in detail (some discussions on this alternative method are given in subsection 12.2.1). 4.7 Invariant zeros on the imaginary axis 85 4.7.1 Frequency-domain loop shifting The basic method (see <ref> [Kh2, Li3, Sa] </ref>) here is based on applying a transformation in the frequency-domain. This method is applicable for the full-information feedback case. <p> During the last few years the H 1 control problem with measurement feedback was investigated via several new methods: * The interpolation approach. In fact, the interpolation approach already has quite a history and several authors have worked on this problem (see e.g. <ref> [Gr, Kh, Li3, Za2] </ref>). However, it can only treat the special case of a one-block H 1 control problem. One should note that the classic interpolation techniques were used for discrete time systems.
Reference: [Li4] <author> D.J.N. Limebeer, M. Green, D. Walker, </author> <title> "Discrete time H 1 control", </title> <booktitle> Proc. CDC, </booktitle> <address> Tampa, FL, </address> <year> 1989, </year> <pages> pp. 392-396. </pages>
Reference-contexts: Recently, a paper has appeared solving the discrete time H 1 control problem using frequency-domain techniques (see [Gu]). The polynomial approach has also been applied to discrete time systems (see [Gri]). In addition, a couple of papers have appeared using a time-domain approach (see <ref> [Bas, Li4, Ya] </ref>). With respect to the papers which use a time-domain approach it should be noted that the references [Bas, Li4, Ya] do not contain a proof of the results obtained for the infinite horizon case and the papers [Bas, Ya] make a number of extra assumptions on the system <p> The polynomial approach has also been applied to discrete time systems (see [Gri]). In addition, a couple of papers have appeared using a time-domain approach (see <ref> [Bas, Li4, Ya] </ref>). With respect to the papers which use a time-domain approach it should be noted that the references [Bas, Li4, Ya] do not contain a proof of the results obtained for the infinite horizon case and the papers [Bas, Ya] make a number of extra assumptions on the system under consideration. In [Bas, Li4, Ya] the authors first investigate the finite horizon problem and then derive a solution of <p> respect to the papers which use a time-domain approach it should be noted that the references <ref> [Bas, Li4, Ya] </ref> do not contain a proof of the results obtained for the infinite horizon case and the papers [Bas, Ya] make a number of extra assumptions on the system under consideration. In [Bas, Li4, Ya] the authors first investigate the finite horizon problem and then derive a solution of the infinite horizon problem by considering it as a kind of limiting case as the endpoint tends to infinity. <p> We shall use time-domain techniques which are reminiscent of those used in chapter 3 and the paper [Ta] which deal with the continuous time case. The method used in the next two chapters was derived independently of <ref> [Bas, Li4, Ya] </ref> and has already ap 166 9.1 Introduction 167 peared in [St5, St6]. After the appearance of the above papers, several new papers and a book appeared on this subject using a state space approach (see e.g. [BB, Ig, Wa]). <p> The more general case of measurement feedback is discussed in the next chapter. The assumptions we shall make are weaker than the assumptions made in [Gu, Ya] and the same as the ones made in <ref> [Li4] </ref>. For the full-information case we have to make two assumptions which are exactly the discrete time analogues of the assumptions made in the regular continuous time H 1 control problem as discussed in chapter 3. <p> The extension to the finite horizon discrete time case (similar to chapter 8) is discussed in <ref> [Bas, Li4] </ref>. It would be interesting to find two dual Riccati equations and a coupling condition as in [Ig, Wa] for the case that either D 21 is not injective or D 12 is not surjective.
Reference: [Li5] <author> D.J.N. Limebeer, B.D.O. Anderson, P.P. Khargonekar, M. Green, </author> <title> "A game theoretic approach to H 1 control for time-varying systems", </title> <note> To appear in SIAM J. Contr. & Opt. 266 Bibliography </note>
Reference-contexts: A number of generalizations have appeared recently. One of these is the minimization of the L 2 -induced operator norm over a finite horizon (see <ref> [Li5, Ta] </ref>). As in the infinite horizon H 1 problem, difficulties arise if the direct-feedthrough matrices do not satisfy certain assumptions (the so-called singular case). This chapter will use the techniques from chapters 4 and 5 to handle this problem for the finite-horizon case. <p> In [Ta] and <ref> [Li5] </ref> such conditions were formulated in terms of the existence of solutions to certain Riccati differential equations. Of course, in order to guarantee the existence of these Riccati differential equations, certain coefficient matrices of the system under consideration should have full rank (the regular case). <p> For two important cases these conditions are always satisfied: * If the system is time-invariant (i.e. all coefficient matrices are con stant, independent of time). * If the problem is regular in the sense as explained above. In this chapter, contrary to <ref> [Li5, Ta] </ref>, we shall assume that the system is time-invariant. We shall try to give the main ideas of the proof which follows the same lines as the proof of the results on the singular, infinite horizon, H 1 control problem discussed in the previous chapters. <p> The problem as posed here will be referred to as the finite horizon H 1 control problem by measurement feedback. This problem was studied before in <ref> [Li5, Ta] </ref>. However, these references assume that the following conditions hold: D 1 is surjective, D 2 is injective. In the present chapter we shall extend the results obtained in [Li5, Ta] to the case that D 1 and D 2 are arbitrary. <p> This problem was studied before in <ref> [Li5, Ta] </ref>. However, these references assume that the following conditions hold: D 1 is surjective, D 2 is injective. In the present chapter we shall extend the results obtained in [Li5, Ta] to the case that D 1 and D 2 are arbitrary. A central role in our study of the problem posed is played by what we shall call the quadratic differential inequality. Let fl &gt; 0 be given. <p> The same holds for Q satisfying (c) and (d). It can be shown that for the special case when D 1 and D 2 are assumed to be surjective and injective, respectively, our theorem 8.1 specializes to the results obtained before in <ref> [Li5, Ta] </ref>. <p> We have noted that the results obtained can be specialized to re-obtain results that were obtained before (see <ref> [Li5, Ta] </ref>). The development of our theory runs analogously to the theory developed in chapters 4 and 5 around the standard H 1 control problem (the infinite horizon version of the problem studied in the present chapter). <p> It should be noted that the geometric approach from appendix A is not well-suited to treat time-varying systems. This is why we cannot treat the time-varying case as in <ref> [Li5, Ta] </ref>. The formal proof for the results in this chapter is also highly technical, mainly due to the fact that the systems P and P;Q are time-varying. The reason why the approach via appendix A still works is that the singular structure of P and P;Q is time-invariant.
Reference: [LM] <author> E.B. Lee, L. Markus, </author> <title> Foundations of optimal control theory, </title> <address> Wi-ley, New York, </address> <year> 1967. </year>
Reference-contexts: After that we shall maximize over w 2 ` 2 . As in chapter 3 our proof is based on Pontryagin's maximum principle. We shall use the ideas from <ref> [LM] </ref>, together with our stability requirement x u;w; 2 ` 2 to adapt the proof to the infinite horizon discrete time case. We start by constructing a solution of the adjoint Hamilton-Jacobi equation which is a natural starting point if one wants to use Pontryagin's maximum principle.
Reference: [LMK] <author> K.Z. Liu, T. Mita, H. Kimura, </author> <title> "Complete solution to the standard H 1 control problem of discrete time systems", </title> <note> 1990, submitted for publication. </note>
Reference-contexts: After the appearance of the above papers, several new papers and a book appeared on this subject using a state space approach (see e.g. [BB, Ig, Wa]). Very recently the J-spectral factorization approach has also been extended to discrete time systems (see <ref> [LMK] </ref>). In this chapter we assume that we deal with the special cases that either both disturbance and state are available for feedback or only the state is available for feedback.
Reference: [M] <author> J. Maciejowski, </author> <title> Multivariable feedback design, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: Several examples have been treated in literature. These are physical examples and reflect what you can and cannot do with H 1 control. * An aircraft autopilot design: see [SLH, SC] * Vertical plane dynamics of an aircraft: see <ref> [MF, M] </ref> * Large space structure: see [SC2] * Attitude control of a flexible space platform: see [MF] * Gas turbine control: see [BW] * Control design for a 90 MW coal fired fluidized bed boiler: see [Cr].
Reference: [Ma] <author> E.F. Mageirou, </author> <title> "Values and strategies for infinite time linear quadratic games", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 21, </volume> <year> 1976, </year> <pages> pp. 547-550. </pages>
Reference-contexts: Chapter 6 The singular zero-sum differential game with stability 6.1 Introduction In this chapter we shall consider the zero-sum linear quadratic finite-dimensional differential game. This is an area of research which was rather popular during the seventies (see e.g. <ref> [Ban, Ma, BO, Sw] </ref>). <p> In the last few years, the solution of the regular H 1 control problem (see chapter 3 and [Do5, Kh3, Pe]) turned out to contain the same kind of algebraic Riccati equation as the one appearing in the solution of the zero-sum differential game (see <ref> [Ban, Ma, Sw] </ref>). This Riccati equation has the special property that the quadratic term is, in general, indefinite, in contrast to, for instance, the equation appearing in linear quadratic optimal control theory (see [Wi7]), where the quadratic term in the Riccati equation is always definite. <p> If a matrix P exists such that F (P ) 0 and the rank conditions (i) and (ii) in theorem 6.4 are satisfied, then an almost equilibrium exists. 2 Remarks : This is an extension of the results in <ref> [Ma] </ref>. However there is an essential difference because we require stability. This prevents some nasty effects like the one mentioned in the example of [Ma]. However, in this chapter the set of admissible inputs is no longer a simple product space and this adds extra technical difficulties. <p> rank conditions (i) and (ii) in theorem 6.4 are satisfied, then an almost equilibrium exists. 2 Remarks : This is an extension of the results in <ref> [Ma] </ref>. However there is an essential difference because we require stability. This prevents some nasty effects like the one mentioned in the example of [Ma]. However, in this chapter the set of admissible inputs is no longer a simple product space and this adds extra technical difficulties. The proof will make use of two lemmas. The following lemma has been proven in chapter 4 after the statement of theorem 4.1. <p> We know such a T exists. For the system (6.2) we shall consider the finite horizon differential game with endpoint-penalty. The cost criterion is given by J T (u; w) = 0 It is well known (see <ref> [Ma] </ref>) that the optimal strategies for w and u are given by u 0 (t) := (D T D) (B T K (T t) + C T D) x (t); and the corresponding equilibrium is J fl T () = T K (T ).
Reference: [MF] <author> D.C. McFarlane, K. Glover, </author> <title> Robust controller design using normalized coprime factor descriptions, </title> <booktitle> Lecture notes in control and information sciences, </booktitle> <volume> Vol 138, </volume> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1990. </year>
Reference-contexts: Each time we find a problem which can be reduced to an H 1 control problem. The first two problems can be found in <ref> [MF, Vi] </ref>. The last problem is discussed in [Hi]. The second and third problems will in general yield singular H 1 control problems. 205 206 Applications 11.2.1 Additive perturbations Essentially the results of this subsection have already appeared in [Gl2]. <p> Several examples have been treated in literature. These are physical examples and reflect what you can and cannot do with H 1 control. * An aircraft autopilot design: see [SLH, SC] * Vertical plane dynamics of an aircraft: see <ref> [MF, M] </ref> * Large space structure: see [SC2] * Attitude control of a flexible space platform: see [MF] * Gas turbine control: see [BW] * Control design for a 90 MW coal fired fluidized bed boiler: see [Cr]. <p> These are physical examples and reflect what you can and cannot do with H 1 control. * An aircraft autopilot design: see [SLH, SC] * Vertical plane dynamics of an aircraft: see [MF, M] * Large space structure: see [SC2] * Attitude control of a flexible space platform: see <ref> [MF] </ref> * Gas turbine control: see [BW] * Control design for a 90 MW coal fired fluidized bed boiler: see [Cr]. Basically the above examples discuss the choice of weights, after which they simply apply the results as discussed in this book. The only difference is the book [MF]. <p> platform: see <ref> [MF] </ref> * Gas turbine control: see [BW] * Control design for a 90 MW coal fired fluidized bed boiler: see [Cr]. Basically the above examples discuss the choice of weights, after which they simply apply the results as discussed in this book. The only difference is the book [MF]. These authors discuss a design method combining loop-shaping with robustness requirements. The method is still relatively ad-hoc and needs a more thorough foundation before guaranteeing the kind of problems for which the method can be used.
Reference: [Mo] <author> B.P. Molinari, </author> <title> "Nonnegativity of a quadratic functional", </title> <journal> SIAM J. Contr. & Opt., </journal> <volume> Vol. 13, </volume> <year> 1975, </year> <pages> pp. 792-806. </pages>
Reference: [Mu] <author> D. Mustafa, K. </author> <title> Glover Minimum entropy H 1 control, </title> <booktitle> Lecture notes in control and information sciences, </booktitle> <volume> Vol 146, </volume> <publisher> Springer Ver-lag, </publisher> <address> Berlin, </address> <year> 1990. </year>
Reference-contexts: This has, as far as we know, never been proven but this is the reason why the problem we discuss in this chapter is sometimes referred to as the mixed LQG/H 1 or H 2 /H 1 control problem. For the regular case, this problem was solved in <ref> [Gl5, Mu, Mu2] </ref>. It was shown that a minimizing controller, which is often called the "central controller", always exists. <p> This extension is discussed in [BH, BH2, Do4, HB, HB2, Kh6, ZK3]. The paper [Kh6] has been extended to the singular case in [St14]. In this chapter we extend the results of <ref> [Mu] </ref> to the singular case. We still exclude invariant zeros on the imaginary axis. This chapter is in essence a combination of the results of chapters 4 and 5 with the results from [Mu]. The results of this chapter have already appeared in [St10]. <p> In this chapter we extend the results of <ref> [Mu] </ref> to the singular case. We still exclude invariant zeros on the imaginary axis. This chapter is in essence a combination of the results of chapters 4 and 5 with the results from [Mu]. The results of this chapter have already appeared in [St10]. <p> The following equality is derived easily using the Lebesgue dominated convergence theorem: J (G) := lim 2 1 s 2 + ! 2 d! The latter expression was used in <ref> [Mu] </ref>. The minimum entropy H 1 control problem is then defined as: infimize J (G cl ) over all controllers which yield a strictly proper, internally stable closed-loop transfer matrix G cl with H 1 norm strictly less than 1. We shall investigate proper controllers of the form (2.4). <p> It can also be shown that conditions (i)-(iii) are automatically sat isfied if D 2 and D 1 are injective and surjective respectively. (iii) In <ref> [Mu] </ref> an H 1 norm bound fl &gt; 0 is used and a corresponding entropy function depending on this bound fl. <p> These properties were derived in <ref> [Mu] </ref> but we give separate proofs because we only investigate what is called in [Mu] "entropy at infinity" . This enables us to derive more straightforward proofs. <p> These properties were derived in <ref> [Mu] </ref> but we give separate proofs because we only investigate what is called in [Mu] "entropy at infinity" . This enables us to derive more straightforward proofs. We can derive the following properties of our entropy function (7.2): 7.3 Properties of the entropy function 143 Lemma 7.2 : Let G be a strictly proper, stable rational matrix such that kGk 1 1. <p> Then it can be shown that as fl ! 1 the entropy cost function converges to the LQG cost. Next, we give two key lemmas. Of the first lemma, the first part is equal to lemma 2.12 while the second part originates from <ref> [Mu] </ref>. We give a separate proof of the second part. Lemma 7.5 : Suppose that two systems and 2 , both described by some state space representation, are interconnected in the following way: ? 6 y u (7.6) Assume that the system is inner. <p> However, this method is too extensive (though straightforward) to discuss in this chapter. Finally we would like to note that this chapter gives a nice structured approach to "entropy at infinity" with fewer technicalities than <ref> [Mu] </ref> where entropy at infinity is simply a special yet important case. 7.6 Conclusion 153 A main open problem remains the problem of invariant zeros on the imaginary axis. Moreover, we would like to have results on LQG itself instead of the upper bound given by the entropy. <p> Not even that, we used only an upper bound for the LQG cost criterion. This problem therefore appears in one of the coming sections as one of the major open problems. What did we do? By restraining attention to "entropy at infinity" we could make the proofs of <ref> [Mu] </ref> more straightforward and less technical. Moreover, we showed how you could extend this result to singular systems. This chapter is meant to be a starting point for future research in this area.
Reference: [Mu2] <author> D. Mustafa, K. Glover, </author> <title> "Model reduction by H 1 -balanced truncation", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 36, No. 6, </volume> <year> 1991, </year> <pages> pp. 668-682. </pages>
Reference-contexts: This has, as far as we know, never been proven but this is the reason why the problem we discuss in this chapter is sometimes referred to as the mixed LQG/H 1 or H 2 /H 1 control problem. For the regular case, this problem was solved in <ref> [Gl5, Mu, Mu2] </ref>. It was shown that a minimizing controller, which is often called the "central controller", always exists. <p> However, in practice we would like to know whether a controller of lower McMillan degree exists which still gives an acceptable closed-loop performance. A main area of research, therefore, lies in reduced order H 1 controllers and in model reduction with an H 1 criterion (see <ref> [BH, HB, Mu2] </ref>).
Reference: [Ni] <author> H.H. Niemann, P. Sogaard-Andersen, J. Stoustrup, </author> <title> "Loop transfer recovery: Analysis and design for general observer architectures", </title> <note> To appear in Int. J. Contr. </note>
Reference: [OM] <author> R.E. O'Malley, Jr., </author> <title> Singular perturbation methods for ordinary differential equations, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: We obtained a stable controller by playing around with the parameters. The eigenvalues of the controller are 45:7; 22:8; 4:04; 2:37; 1:30:51i and 0:667. The fact that the controller has both very fast and relatively slow modes suggests that via singular perturbation theory (see, e.g. <ref> [OM] </ref>) we can reduce the order of the controller. There is, however, no theory available for such an approach. (iii) Our final controller can, according to the theory developed in subsection 11.2.3, stand fluctuations in the parameters F and m of 400%.
Reference: [OSS1] <author> H.K. Ozcetin, A. Saberi, P. Sannuti, </author> <title> "Design for almost disturbance decoupling problem with internal stability via state or measurement feedback- singular perturbation approach", </title> <note> To appear in Int. J. Contr. </note>
Reference-contexts: We shall describe a method which is an adapted version of the one given in [Tr]. An alternative method is described in <ref> [OSS1] </ref>. We denote the first three matrices of the quadruple in (4.16) by ~ A, ~ B and ~ C respectively. (i) We construct a new basis for the state space. We shall construct it by induction. <p> A good algorithm to calculate the H 1 norm can be found in [BBK, BS]. In other words, we can check whether the numerical problems resulted in a bad design. The algorithm in <ref> [OSS1, OSS2] </ref> also involves rank evaluations. However, by using the infinite zero structure and especially the different 80 The general full-information H 1 control problem timescales of eigenvalues that go to infinity, this algorithm results in feedbacks with lower gain to achieve the same level of disturbance decoupling.
Reference: [OSS2] <author> H.K. Ozcetin, A. Saberi and Y. </author> <title> Shamash "An H 1 almost disturbance decoupling technique for nonstrictly proper systems", </title> <note> To appear in Proc. CDC, Brighton, U.K., 1991. Bibliography 267 </note>
Reference-contexts: A good algorithm to calculate the H 1 norm can be found in [BBK, BS]. In other words, we can check whether the numerical problems resulted in a bad design. The algorithm in <ref> [OSS1, OSS2] </ref> also involves rank evaluations. However, by using the infinite zero structure and especially the different 80 The general full-information H 1 control problem timescales of eigenvalues that go to infinity, this algorithm results in feedbacks with lower gain to achieve the same level of disturbance decoupling.
Reference: [Pe] <author> I.R. Petersen, </author> <title> C.V. Hollot, "A Riccati equation approach to the stabilization of uncertain linear systems", </title> <journal> Automatica Vol. </journal> <volume> 22, </volume> <year> 1986, </year> <pages> pp. 397-411. </pages>
Reference-contexts: One should note that the classic interpolation techniques were used for discrete time systems. At first the continuous time case was treated via a frequency-domain transformation to the discrete time case (a linear fractional transformation as given in [Gen, appendix 1]). * The time-domain approach (see <ref> [Do5, Kh3, Kh4, Pe, Ta] </ref>). This 91 92 H 1 control with measurement feedback method was the first to suggest the use of Riccati equations in H 1 control, which was an important breakthrough. <p> For the special case of full-information feedback, these methods are discussed in section 4.7. Using the first method discussed in subsection 4.7.1, which applies a transformation in the complex plane combined with the results in <ref> [Do5, Kh3, Pe, Ta] </ref>, we still have to make assumptions: two given subsystems should be left and right invertible respectively. The second method combined with the methods of the latter papers can tackle the most general case. <p> In this chapter we shall present a method which, independently of the latter papers, solves the measurement feedback case using the results of our previous chapter. In contrast to <ref> [Do5, Kh3, Pe, Ta] </ref> we shall impose no assumptions on the direct-feedthrough matrices. However, we still have to exclude invariant zeros on the imaginary axis. Our method will not have the above-mentioned drawback of a parametrized Riccati equation. <p> This is an area of research which was rather popular during the seventies (see e.g. [Ban, Ma, BO, Sw]). In the last few years, the solution of the regular H 1 control problem (see chapter 3 and <ref> [Do5, Kh3, Pe] </ref>) turned out to contain the same kind of algebraic Riccati equation as the one appearing in the solution of the zero-sum differential game (see [Ban, Ma, Sw]).
Reference: [Pe2] <author> I.R. Petersen, </author> <title> "Linear quadratic differential games with cheap control", </title> <journal> Syst. & Contr. Letters, </journal> <volume> Vol. 8, </volume> <year> 1986, </year> <pages> pp. 181-188. </pages>
Reference-contexts: Recently, a number of papers appeared which studied a zero-sum differential game with the goal of obtaining such a characterization (see <ref> [Pe2, Pe3, We] </ref>). A very recent book on the relation between H 1 and differential games is [BB].
Reference: [Pe3] <author> I.R. Petersen, </author> <title> "Disturbance attenuation and H 1 optimization: a design method based on the algebraic Riccati equation", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 32, No. 5, </volume> <year> 1987, </year> <pages> pp. 427-429. </pages>
Reference-contexts: section 5.1 88 The general full-information H 1 control problem for the H 1 control problem with measurement feedback are often not very suitable to treat the special cases of state feedback and full-information feedback. 4.7.2 Cheap control In this subsection we shall briefly describe how the method used in <ref> [Kh3, Kh2, Pe3, Pe5, ZK2] </ref> still gives necessary and sufficient conditions for the existence of internally stabilizing controllers which make the H 1 norm of the closed-loop system less than 1 even when we have invariant zeros on the imaginary axis. <p> Recently, a number of papers appeared which studied a zero-sum differential game with the goal of obtaining such a characterization (see <ref> [Pe2, Pe3, We] </ref>). A very recent book on the relation between H 1 and differential games is [BB].
Reference: [Pe4] <author> I.R. Petersen, </author> <title> "Some new results on algebraic Riccati equations arising in linear quadratic differential games and the stabilization of uncertain systems", </title> <journal> Syst. & Contr. Letters, </journal> <volume> Vol. 10, </volume> <year> 1988, </year> <pages> pp. 341-348. </pages>
Reference: [Pe5] <author> I.R. Petersen, </author> <title> C.V. Hollot, "High gain observers applied to problems in the stabilization of uncertain linear systems, disturbance attenuation and H 1 optimization", </title> <journal> Int. J. Adapt. Contr. and Sign. Proc., </journal> <volume> Vol. 3, </volume> <year> 1989. </year>
Reference-contexts: section 5.1 88 The general full-information H 1 control problem for the H 1 control problem with measurement feedback are often not very suitable to treat the special cases of state feedback and full-information feedback. 4.7.2 Cheap control In this subsection we shall briefly describe how the method used in <ref> [Kh3, Kh2, Pe3, Pe5, ZK2] </ref> still gives necessary and sufficient conditions for the existence of internally stabilizing controllers which make the H 1 norm of the closed-loop system less than 1 even when we have invariant zeros on the imaginary axis.
Reference: [PM] <author> M.A. Peters, </author> <title> A time-domain approach to H 1 worst-case design, </title> <type> Masters Thesis, </type> <institution> Eindhoven University of Technology, </institution> <year> 1989. </year>
Reference: [Re] <author> R.M. Redheffer, </author> <title> "On a certain linear fractional transformation", </title> <journal> J. Math. and Physics, </journal> <volume> Vol. 39, </volume> <year> 1960, </year> <pages> pp. 269-286. </pages>
Reference: [RK] <author> M.A. </author> <month> Rotea, </month> <pages> P.P. </pages> <month> Khargonekar, </month> <title> "H 2 optimal control with an H 1 constraint: the state feedback case", </title> <journal> Automatica, </journal> <volume> Vol. 27, No. 2, </volume> <year> 1991, </year> <pages> pp. 307-316. </pages>
Reference-contexts: Moreover, we would like to have results on LQG itself instead of the upper bound given by the entropy. A first start has been made in <ref> [RK] </ref> but much more work has to be done. Finally, another interesting extension is the general setup of subsection 1.6.3 where we have two kinds of disturbances and two kinds of output to be controlled.
Reference: [RK2] <author> M.A. </author> <month> Rotea, </month> <pages> P.P. </pages> <month> Khargonekar, </month> <title> "Stabilization of uncertain systems with norm-bounded uncertainty: a control Lyapunov approach", </title> <journal> SIAM J. Contr. & Opt., </journal> <volume> Vol. 27, </volume> <year> 1989, </year> <pages> pp. 1462-1476. </pages>
Reference: [RNK] <author> R. Ravi, K. </author> <month> Nagpal, </month> <pages> P.P. </pages> <month> Khargonekar, </month> <title> "H 1 for linear time-varying systems: a state space approach", </title> <note> To appear in SIAM J. Contr. </note> & <editor> Opt., </editor> <volume> Vol. 29, No. 6, </volume> <year> 1991. </year>
Reference-contexts: We apply the dual version of lemma 2.12. Lemma 2.12 is still true for time-varying systems (see <ref> [RNK] </ref>). However V does not satisfy the conditions of lemma 2.12. Instead T V satisfies the conditions of this lemma. Therefore, in the above proof we apply the dual version of lemma 2.12. However, this dualization argument is not valid for time-varying systems.
Reference: [Ro] <author> H.H. </author> <title> Rosenbrock, "The zeros of a system", </title> <journal> Int. J. Contr., </journal> <volume> Vol. 18, </volume> <year> 1973, </year> <pages> pp. </pages> <note> 297-299 and correction Vol. 20, </note> <year> 1974, </year> <pages> pp. 525-527. </pages>
Reference: [RR] <author> M. Rosenblum, J. Rovnyak, </author> <title> Hardy classes and operator theory, </title> <publisher> Oxford University Press, </publisher> <address> New York, </address> <year> 1985. </year> <note> 268 Bibliography </note>
Reference: [Ru] <author> W. </author> <title> Rudin, Real and complex analysis, 3rd. </title> <editor> ed., </editor> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1987. </year>
Reference: [Sa] <author> M.G. Safonov, </author> <title> "Imaginary axis zeros in multivariable H 1 optimal control", Proc. NATO Workshop on Modelling, Robustness and Sensitivity Reduction in Control Systems, </title> <address> Groningen, </address> <year> 1986. </year>
Reference-contexts: is given in [S3] will probably lead to much more elegant conditions but these conditions are too complex to explain here in detail (some discussions on this alternative method are given in subsection 12.2.1). 4.7 Invariant zeros on the imaginary axis 85 4.7.1 Frequency-domain loop shifting The basic method (see <ref> [Kh2, Li3, Sa] </ref>) here is based on applying a transformation in the frequency-domain. This method is applicable for the full-information feedback case.
Reference: [SC] <author> M.G. Safonov, R.Y. Chiang, </author> <title> "CACSD Using the state space L 1 theory: </title> <journal> a design example" IEEE Trans. Aut. Contr., </journal> <volume> Vol. 33, No. 5, </volume> <year> 1988, </year> <pages> pp. 477-479. </pages>
Reference-contexts: Several examples have been treated in literature. These are physical examples and reflect what you can and cannot do with H 1 control. * An aircraft autopilot design: see <ref> [SLH, SC] </ref> * Vertical plane dynamics of an aircraft: see [MF, M] * Large space structure: see [SC2] * Attitude control of a flexible space platform: see [MF] * Gas turbine control: see [BW] * Control design for a 90 MW coal fired fluidized bed boiler: see [Cr].
Reference: [SC2] <author> M.G. Safonov, R.Y. Chiang, H. Flashner, </author> <title> "H 1 robust control synthesis for a large space structure", </title> <booktitle> Proc. ACC, </booktitle> <address> Atlanta, GA, </address> <year> 1988, </year> <pages> pp. 2038-2043. </pages>
Reference-contexts: Several examples have been treated in literature. These are physical examples and reflect what you can and cannot do with H 1 control. * An aircraft autopilot design: see [SLH, SC] * Vertical plane dynamics of an aircraft: see [MF, M] * Large space structure: see <ref> [SC2] </ref> * Attitude control of a flexible space platform: see [MF] * Gas turbine control: see [BW] * Control design for a 90 MW coal fired fluidized bed boiler: see [Cr].
Reference: [SLH] <author> M.G. Safonov, A.J. Laub, G.L. Hartmann, </author> <title> "Feedback properties of multivariable systems: the role and use of the return difference matrix", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 26, No. 1, </volume> <year> 1981, </year> <pages> pp. 47-65. </pages>
Reference-contexts: Several examples have been treated in literature. These are physical examples and reflect what you can and cannot do with H 1 control. * An aircraft autopilot design: see <ref> [SLH, SC] </ref> * Vertical plane dynamics of an aircraft: see [MF, M] * Large space structure: see [SC2] * Attitude control of a flexible space platform: see [MF] * Gas turbine control: see [BW] * Control design for a 90 MW coal fired fluidized bed boiler: see [Cr].
Reference: [S] <author> C. Scherer, </author> <title> "H 1 control by state feedback: An iterative algorithm and characterization of high gain occurence", </title> <journal> Syst. & Contr. Letters, </journal> <volume> Vol. 12, </volume> <year> 1989, </year> <pages> pp. 383-391. </pages>
Reference-contexts: The assumption of left-invertibility is not very restrictive. When the system is not left-invertible this implies that there are several inputs which have the same effect on the output and this non-uniqueness can be factored out (see, for a continuous time treatment, <ref> [S] </ref>). The assumption of right-invertibility can be removed by dualizing this reasoning. However, at this moment it is unclear how to remove the assumptions concerning zeros on the unit-circle. Chapter 11 Applications 11.1 Introduction In this book we have derived several results concerning the H 1 control problem.
Reference: [S2] <author> C. Scherer, </author> <title> "H 1 control by state feedback and fast algorithms for the computation of optimal H 1 norms", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 35, </volume> <year> 1990, </year> <pages> pp. 1090-1099. </pages>
Reference: [S3] <author> C. Scherer, </author> <title> "H 1 control by state feedback for plants with zeros on the imaginary axis", </title> <note> To appear in SIAM J. Contr. </note> & <editor> Opt., </editor> <volume> Vol. 30, No. 1, </volume> <year> 1991. </year>
Reference-contexts: A method we shall not discuss and which is given in <ref> [S3] </ref> will probably lead to much more elegant conditions but these conditions are too complex to explain here in detail (some discussions on this alternative method are given in subsection 12.2.1). 4.7 Invariant zeros on the imaginary axis 85 4.7.1 Frequency-domain loop shifting The basic method (see [Kh2, Li3, Sa]) here <p> When there are invariant zeros on the imaginary axis the methods of section 4.7 can be used. However, these methods are not really satisfactory and one would have to investigate the technique used in <ref> [S3] </ref> better to obtain nicer conditions for the general case (the conditions we have in mind are suggested in subsection 12.2.1). <p> In this subsection we want to discuss the difficulty of these invariant zeros intuitively. The reader should not expect formal proofs in this section. A treatment of invariant zeros on the imaginary axis for continuous time systems is given in several papers, <ref> [HSK, S3, S4] </ref>. <p> The reader should not expect formal proofs in this section. A treatment of invariant zeros on the imaginary axis for continuous time systems is given in several papers, [HSK, S3, S4]. For the regular state feedback case (no problems at infinity) the conditions in <ref> [S3] </ref> can, in principle, be reformulated as: a solution of a Riccati equation exists for which the matrix A cl as given in theorem 3.1 has all eigenvalues in the open left half plane or in points on the imaginary axis which are invariant zeros. <p> Besides that, separate extra conditions have to be satisfied for each invariant zero on the imaginary axis. However, it is worthwhile to look for alternative formulations of the results in <ref> [HSK, S3, S4] </ref> in order to obtain a better insight of what the extra conditions which have to be satisfied when we have an invariant zero on the imaginary axis look like. Moreover, a numerical reliable way of finding a suitable controller, if one exists, is needed. <p> Moreover, a numerical reliable way of finding a suitable controller, if one exists, is needed. As in this book, in <ref> [S3, S4] </ref> a geometric approach is chosen. This yields good understanding of the nature of the problems but gives results which are in general numerically not very reliable. Next, we shall try to show the difficulty of invariant zeros on the imaginary axis for continuous time systems.
Reference: [S4] <author> C. Scherer, </author> <title> "H 1 -optimization without assumptions on finite or infinite zeros", </title> <note> To appear in SIAM J. Contr. </note> & <editor> Opt., </editor> <volume> Vol. 30, No. 1, </volume> <year> 1991. </year>
Reference-contexts: However, how we can treat invariant zeros on the imaginary axis remains an open problem. This problem is studied in <ref> [S4] </ref>. Other open problems are the determination of the minimally required dynamic order of the controller and the characterization of the behaviour of the feedbacks and closed-loop system if we tighten the bound fl. The latter problem has already been investigated. <p> In this subsection we want to discuss the difficulty of these invariant zeros intuitively. The reader should not expect formal proofs in this section. A treatment of invariant zeros on the imaginary axis for continuous time systems is given in several papers, <ref> [HSK, S3, S4] </ref>. <p> Besides that, separate extra conditions have to be satisfied for each invariant zero on the imaginary axis. However, it is worthwhile to look for alternative formulations of the results in <ref> [HSK, S3, S4] </ref> in order to obtain a better insight of what the extra conditions which have to be satisfied when we have an invariant zero on the imaginary axis look like. Moreover, a numerical reliable way of finding a suitable controller, if one exists, is needed. <p> Moreover, a numerical reliable way of finding a suitable controller, if one exists, is needed. As in this book, in <ref> [S3, S4] </ref> a geometric approach is chosen. This yields good understanding of the nature of the problems but gives results which are in general numerically not very reliable. Next, we shall try to show the difficulty of invariant zeros on the imaginary axis for continuous time systems.
Reference: [SE] <author> E. Schijfs, </author> <title> A numerical analysis of the singular H 1 control problem, </title> <type> Masters Thesis, </type> <institution> Eindhoven University of Technology, </institution> <year> 1990. </year>
Reference-contexts: Singular systems cannot be treated with these toolboxes but software is being developed also using Matlab (see <ref> [SE] </ref>). 11.4 A design example: an inverted pendulum on a cart We shall consider the following physical example of an inverted pendulum on a cart: M r ' l d We assume the mass of the pendulum to be concentrated in the top with mass m. l is the length of
Reference: [SH] <author> J.M. Schumacher, </author> <title> Dynamic feedback in finite and infinite dimensional linear systems, </title> <publisher> Math. Centre Tracts 143, </publisher> <address> Amsterdam, </address> <year> 1981. </year>
Reference: [SH2] <author> J.M. Schumacher, </author> <title> "The role of the dissipation matrix in singular optimal control", </title> <journal> Syst. & Contr. Letters, </journal> <volume> Vol. 2, </volume> <year> 1983, </year> <pages> pp. 262-266. Bibliography 269 </pages>
Reference: [SH3] <author> J.M. Schumacher, </author> <title> "On the structure of strongly controllable systems", </title> <journal> Int. J. Contr., </journal> <volume> Vol. 38, </volume> <year> 1983, </year> <pages> pp. 525-545. </pages>
Reference: [SH4] <author> J.M. Schumacher, </author> <title> "A geometric approach to the singular filtering problem", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 30, </volume> <year> 1985, </year> <pages> pp. 1075-1082. </pages>
Reference-contexts: The first two conditions on Q m require that Q m is a rank-minimizing solution of a linear matrix inequality. The same linear matrix inequality is also appearing in the singular filtering problem (see <ref> [SH4] </ref>, this problem is dual to the singular linear quadratic control problem).
Reference: [Si] <author> L.M. Silverman, </author> <title> "Discrete Riccati equations: alternative algorithms, asymptotic properties and system theory interpretation", In Control and dynamic systems, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <note> Vol. 12, </note> <year> 1976, </year> <pages> pp. 313-386. </pages>
Reference-contexts: The existence of such L is guaranteed under the assumption that (A; B; C; D 1 ) has no invariant zeros on the unit circle 174 The discrete time full-information case and is left-invertible and, moreover, (A; B) is stabilizable (see <ref> [Si] </ref>). We define r (k) := i=k ik where X 1 := I LB (D T 1 Note that r is well-defined since the matrix A L = X T 1 A is asymptotically stable which implies that X 1 A T is asymptotically stable.
Reference: [SK] <author> N. Shivashankar, </author> <title> P.P. Khargonekar "Robust stabilization and performance analysis of sampled data systems", </title> <note> To appear in Proc. CDC, Brighton, U.K., 1991, Submitted to IEEE Trans. Aut. Contr. </note>
Reference-contexts: Finally, consider sampled-data design where we take the sample and hold functions of the digital implementation of our controller into account in the design of our controller. In <ref> [Ch, KH, SK] </ref>) it has been shown that if we use sampled-data design for a H 1 control problem of a continuous time system then this can be reduced to a discrete time H 1 control problem.
Reference: [SS] <author> P. Sannuti and A. Saberi, </author> <title> A special coordinate basis of multivari-able linear systems | finite and infinite zero structure, squaring down and decoupling, </title> <journal> Int. J. Contr., Vol.45, </journal> <volume> No.5, </volume> <year> 1987, </year> <pages> pp. 1655-1704. </pages>
Reference-contexts: However, a rank evaluation is needed to determine, e.g. the kernel, and this is known to be a numerically ill-posed problem. To determine this subspace we can also use the algorithm as described in <ref> [SS] </ref>. This has the same problem but this algorithm has been thoroughly tested via examples and seems to work well. (ii ) The method described in this section and also the method described in subsection 4.7.2 involves a parameter (" and 1=n respectively) which goes to infinity.
Reference: [St] <author> A.A. Stoorvogel, </author> <title> "H 1 control with state feedback", Robust control of linear systems and nonlinear control, </title> <booktitle> Proc. MTNS-89, Vol II, </booktitle> <address> M.A. </address> <publisher> Kaashoek, </publisher> <editor> J.H. van Schuppen, A.C.M. Ran (eds.), </editor> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1990, </year> <pages> pp. 347-354. </pages>
Reference-contexts: This subsection is worked out in more detail in <ref> [St] </ref>. We assume that we have a system of the form (4.23).
Reference: [St2] <author> A.A. Stoorvogel, H.L. Trentelman, </author> <title> "The quadratic matrix inequality in singular H 1 control with state feedback", </title> <journal> SIAM J. Contr. & Opt., </journal> <volume> Vol. 28, No. 5, </volume> <year> 1990, </year> <pages> pp. 1190-1208. </pages>
Reference-contexts: feedback compensator which makes the H 1 norm less than some, a priori given, upper bound fl &gt; 0 can be easily derived from theorem 10.1 by scaling. 10.3 A first system transformation 195 (ii ) If we compare these conditions with the conditions for the continuous time case (see <ref> [Do5, St2] </ref>), then we note that our Riccati equations are coupled.
Reference: [St3] <author> A.A. Stoorvogel, </author> <title> "The singular zero-sum differential game with stability using H 1 control theory", Math. Contr. Sign. </title> & <journal> Syst., </journal> <volume> Vol. 4, No. 2, </volume> <year> 1991, </year> <pages> pp. 121-138. </pages>
Reference-contexts: The reason for nevertheless including this chapter lies in the fact that the intuition, which yielded the results on H 1 control, mostly stems from this chapter. The results of this chapter have already appeared in <ref> [St3] </ref>. The outline of this chapter is as follows: in section 6.2 we formulate the problem and give our main results. In section 6.3 we prove the existence of an equilibrium under certain sufficient conditions. After that, in section 6.4 we derive necessary conditions for the existence of equilibria.
Reference: [St4] <author> A.A. Stoorvogel, </author> <title> "The singular H 1 control problem with dynamic measurement feedback", </title> <journal> SIAM J. Contr. & Opt.. </journal> <volume> Vol. 29, No. 1, </volume> <year> 1991, </year> <pages> pp. 160-184. </pages>
Reference-contexts: Our proof will use ideas given in [Do5] to solve the regular H 1 problem with measurement feedback but is independent of the results in [Do5] and is entirely self-contained. Most of the results of this chapter already appeared in <ref> [St4] </ref>. The outline of this chapter is as follows: In section 5.2 we formulate the problem and present the main result for the case when two given direct-feedthrough matrices are zero.
Reference: [St5] <author> A.A. Stoorvogel, </author> <title> "The discrete time H 1 control problem: the full information case", </title> <type> COSOR memorandum 89-25, </type> <institution> Eindhoven University of Technology, </institution> <month> October </month> <year> 1989. </year>
Reference-contexts: The method used in the next two chapters was derived independently of [Bas, Li4, Ya] and has already ap 166 9.1 Introduction 167 peared in <ref> [St5, St6] </ref>. After the appearance of the above papers, several new papers and a book appeared on this subject using a state space approach (see e.g. [BB, Ig, Wa]). Very recently the J-spectral factorization approach has also been extended to discrete time systems (see [LMK]).
Reference: [St6] <author> A.A. Stoorvogel, </author> <title> "The discrete time H 1 control problem with measurement feedback", </title> <note> To appear in SIAM J. Contr. </note> & <editor> Opt., </editor> <volume> Vol. 30, No. 1, </volume> <year> 1991. </year> <note> 270 Bibliography </note>
Reference-contexts: The method used in the next two chapters was derived independently of [Bas, Li4, Ya] and has already ap 166 9.1 Introduction 167 peared in <ref> [St5, St6] </ref>. After the appearance of the above papers, several new papers and a book appeared on this subject using a state space approach (see e.g. [BB, Ig, Wa]). Very recently the J-spectral factorization approach has also been extended to discrete time systems (see [LMK]). <p> We only prove the result for D 2 = 0. The general result can be proven along the same lines and this proof can be found in <ref> [St6] </ref>. (ii ) Note that part (ii) of theorem 9.2 is equivalent to the requirement that a causal operator f exists such that the feedback law u = f (x; w) satisfies part (ii). <p> The present chapter is reminiscent of chapter 5 which deals with the continuous time case. The results of this chapter already appeared in <ref> [St6] </ref>. We make the assumptions which yield an H 1 control problem which 190 10.1 Introduction 191 is the exact discrete time analogue of the regular H 1 control problem with measurement feedback.
Reference: [St7] <author> A.A. Stoorvogel, H.L. Trentelman, </author> <title> "The finite horizon singular time-varying H 1 control problem with dynamic measurement feedback", </title> <type> COSOR memorandum 89-33, </type> <institution> Eindhoven University of Technology, </institution> <year> 1989. </year>
Reference-contexts: The present paper addresses the problem formulated above without these full rank assumptions. We find necessary and sufficient conditions in terms of a pair of quadratic matrix differential inequalities. The results of this chapter have already appeared in <ref> [St7, Tr2] </ref>. The detailed proof of the results is highly technical and can be found in [St7]. This paper discusses time-varying systems which satisfy a number of con 154 8.2 Problem formulation and main results 155 ditions. <p> We find necessary and sufficient conditions in terms of a pair of quadratic matrix differential inequalities. The results of this chapter have already appeared in [St7, Tr2]. The detailed proof of the results is highly technical and can be found in <ref> [St7] </ref>. This paper discusses time-varying systems which satisfy a number of con 154 8.2 Problem formulation and main results 155 ditions. <p> However, we shall not give all the technical details. For this, we refer to <ref> [St7] </ref> The outline of this chapter is as follows: in section 8.2 we shall formulate our problem and present our main result. <p> For a more detailed discussion we would like to refer to <ref> [St7] </ref>. <p> Property (2) is stated formally in the following theorem: Theorem 8.7 : For all " &gt; 0 a time-varying dynamic compensator F exists such that kG cl;P;Q k 1 &lt; ". 2 Due to space limitations, for a proof of the latter theorem we refer to <ref> [St7] </ref>. The main difficulty is that P;Q is time-varying and therefore it is necessary to derive a time-varying version of theorem 2.20 (we do not need (2.48) but we do need (2.47)). <p> Our proofs are strongly based on the bases of appendix A and we have to make a number of assumptions to make sure these bases are not time-varying. This is not worked out in detail in this book but can be found in <ref> [St7] </ref>. 12.1.5 Discrete time systems For discrete time systems which are discrete time analogues of regular continuous time systems, we were able to derive nice conditions: a suitable controller exists if, and only if, there are positive semi-definite stabilizing solutions to two algebraic Riccati equations.
Reference: [St8] <author> A.A. Stoorvogel, </author> <title> "Robust stabilization of systems with multiplicative perturbations", </title> <type> COSOR Memorandum 90-36, </type> <institution> Eindhoven University of Technology, </institution> <note> To appear in Proc. </note> <institution> MTNS-91, </institution> <address> Kobe, Japan, </address> <year> 1991. </year>
Reference-contexts: This result was already known (see, e.g. [Gl2]). 11.2.2 Multiplicative perturbations The results of this subsection have already appeared in <ref> [St8] </ref>. We assume that we once again have a continuous time system being an imperfect model of a certain plant.
Reference: [St9] <author> A. A. Stoorvogel, </author> <title> The H 1 control problem: a state space approach, </title> <type> Ph.D. Thesis, </type> <institution> Department of Mathematics and Computing Science, Eindhoven University of Technology, The Nether-lands, </institution> <year> 1990. </year>
Reference: [St10] <author> A.A. Stoorvogel, </author> <title> "The singular minimum entropy H 1 control problem", </title> <journal> Syst. & Contr. Letters, </journal> <volume> Vol. 16, No. 6, </volume> <year> 1991, </year> <pages> pp. 411-422. </pages>
Reference-contexts: We still exclude invariant zeros on the imaginary axis. This chapter is in essence a combination of the results of chapters 4 and 5 with the results from [Mu]. The results of this chapter have already appeared in <ref> [St10] </ref>.
Reference: [St11] <author> A.A. Stoorvogel, J.W. van der Woude, </author> <title> "The disturbance decou-pling problem with measurement feedback and stability for systems with direct feedthrough matrices", </title> <journal> Syst. & Contr. Letters, </journal> <volume> Vol. 17, No. 3, </volume> <year> 1991, </year> <pages> pp. 217-226. </pages>
Reference: [St12] <author> A.A. Stoorvogel, </author> <title> "The singular H 2 control problem", </title> <note> To appear in Automatica, </note> <year> 1992. </year>
Reference-contexts: This chapter is in essence a combination of the results of chapters 4 and 5 with the results from [Mu]. The results of this chapter have already appeared in [St10]. Note that the singular LQG control problem has been investigated in <ref> [St12] </ref>. 7.2 Problem formulation and results Consider the linear time-invariant system: : &gt; &gt; &lt; _x = Ax + Bu + Ew; z = C 2 x + D 1 u; Here A; B; E; C 1 ; C 2 ; D 1 and D 2 are real matrices of suitable
Reference: [St13] <author> A.A. Stoorvogel, A. Saberi, B.M. Chen, </author> <title> "A reduced order based controller design for H 1 optimization", </title> <booktitle> Proc. AIAA Guidance, Navigation and Control Conference, </booktitle> <address> New Orleans, </address> <booktitle> LA, </booktitle> <volume> Vol. 2, </volume> <year> 1991, </year> <pages> pp. 716-722. </pages>
Reference-contexts: It turns out that it is always possible to find a compensator of the same dynamic order as the original plant. In fact, in <ref> [St13] </ref> it has been shown that we can find a suitable controller of McMillan degree n rank ( C 1 D 1 ) + rank D 1 .
Reference: [St14] <author> A.A. Stoorvogel, H.L. Trentelman, </author> <title> "The mixed H 2 and H 1 control problem", </title> <booktitle> To appear in Proc. Workshop on Robust Control, </booktitle> <address> Tokyo, Japan, </address> <year> 1991. </year>
Reference-contexts: This extension is discussed in [BH, BH2, Do4, HB, HB2, Kh6, ZK3]. The paper [Kh6] has been extended to the singular case in <ref> [St14] </ref>. In this chapter we extend the results of [Mu] to the singular case. We still exclude invariant zeros on the imaginary axis. This chapter is in essence a combination of the results of chapters 4 and 5 with the results from [Mu].
Reference: [St15] <author> A.A. Stoorvogel, A.J.T.M. Weeren, </author> <title> "The discrete time Riccati equation related to the H 1 control problem", </title> <note> Submitted for publication, </note> <month> September </month> <year> 1991. </year>
Reference-contexts: We shall not prove the results of this section because these results are not needed for our main results and to prevent a too extensive book. For details we refer to <ref> [St15] </ref>. We investigate the existence of a matrix P such that: * The matrix G (P ) defined by (9.3) is invertible. * P satisfies the discrete algebraic Riccati equation (9.4). * The matrix A cl defined by (9.5) is asymptotically stable. <p> However, for discrete time Riccati equations it is sometimes more desirable to have recursive algorithms as, e.g. is given in [Fa] for a different type of Riccati equation. This is derived in <ref> [WA, St15] </ref>. An extension of the use of symplectic pairs to the case that D 1 is not injective is useful. This is a subject of current research. 9.6 Conclusion In this chapter the discrete time full-information H 1 control problem has been investigated.
Reference: [Sw] <editor> A.C.M. van Swieten, </editor> <title> Qualitative behavior of dynamical games with feedback strategies, </title> <type> Ph.D. Thesis, </type> <institution> University of Groningen, </institution> <address> The Netherlands, </address> <year> 1977. </year>
Reference-contexts: Chapter 6 The singular zero-sum differential game with stability 6.1 Introduction In this chapter we shall consider the zero-sum linear quadratic finite-dimensional differential game. This is an area of research which was rather popular during the seventies (see e.g. <ref> [Ban, Ma, BO, Sw] </ref>). <p> In the last few years, the solution of the regular H 1 control problem (see chapter 3 and [Do5, Kh3, Pe]) turned out to contain the same kind of algebraic Riccati equation as the one appearing in the solution of the zero-sum differential game (see <ref> [Ban, Ma, Sw] </ref>). This Riccati equation has the special property that the quadratic term is, in general, indefinite, in contrast to, for instance, the equation appearing in linear quadratic optimal control theory (see [Wi7]), where the quadratic term in the Riccati equation is always definite.
Reference: [Ta] <author> G. Tadmor, </author> <title> "Worst-case design in the time domain: the maximum principle and the standard H 1 problem", Math. Contr. Sign. </title> & <journal> Syst., </journal> <volume> Vol. 3, </volume> <year> 1990, </year> <pages> pp. 301-324. Bibliography 271 </pages>
Reference-contexts: One should note that the classic interpolation techniques were used for discrete time systems. At first the continuous time case was treated via a frequency-domain transformation to the discrete time case (a linear fractional transformation as given in [Gen, appendix 1]). * The time-domain approach (see <ref> [Do5, Kh3, Kh4, Pe, Ta] </ref>). This 91 92 H 1 control with measurement feedback method was the first to suggest the use of Riccati equations in H 1 control, which was an important breakthrough. <p> For the special case of full-information feedback, these methods are discussed in section 4.7. Using the first method discussed in subsection 4.7.1, which applies a transformation in the complex plane combined with the results in <ref> [Do5, Kh3, Pe, Ta] </ref>, we still have to make assumptions: two given subsystems should be left and right invertible respectively. The second method combined with the methods of the latter papers can tackle the most general case. <p> In this chapter we shall present a method which, independently of the latter papers, solves the measurement feedback case using the results of our previous chapter. In contrast to <ref> [Do5, Kh3, Pe, Ta] </ref> we shall impose no assumptions on the direct-feedthrough matrices. However, we still have to exclude invariant zeros on the imaginary axis. Our method will not have the above-mentioned drawback of a parametrized Riccati equation. <p> However, we still have to exclude invariant zeros on the imaginary axis. Our method will not have the above-mentioned drawback of a parametrized Riccati equation. Also our results reduce to the known results in <ref> [Do5, Ta] </ref> when these singularities of the direct-feedthrough matrices do not occur. Another advantage of our (weaker) assumptions will be that the special cases of state feedback and full-information feedback fall within the framework of the general problem formulation. <p> The necessary and sufficient conditions under which there exists an internally stabilizing dynamic compensator which makes the H 1 norm strictly less than some a priori given bound fl are formulated differently from recent publications <ref> [Do5, Ta] </ref>. As mentioned above, in these papers the conditions are formulated in terms of two given Riccati equations. However, when there are singularities of the direct-feedthrough matrices these Riccati equations do not exist. To replace the role of these Riccati equations we have two quadratic matrix inequalities. <p> The alternative methods mentioned in that section can also be used for the general problem with measurement feedback. 5.5 Characterization of achievable closed-loop systems A characterization of all controllers which achieve the required H 1 norm bound has been given in <ref> [Do5, Ta] </ref>. This was a kind of ball around the so-called central controller (which is given in remark (ii) after theorem 5.1). This central controller has the alternative interpretation as the controller which minimizes the entropy function defined in chapter 7. <p> Note that the central controller can be given an interpretation as minimizing the entropy (see chapter 7) and as the optimal controller for the linear exponential Gaussian stochastic control problem (see [BvS, Wh]). For the regular case this characterization is completely similar to the characterization given in <ref> [Do5, Ta] </ref>. 5.6 No assumptions on any direct-feedthrough matrix In this section we shall briefly discuss how we can extend our result in theorem 5.1 to the more general system (2.1). We set fl = 1 but the general result can be easily obtained by scaling. <p> A number of generalizations have appeared recently. One of these is the minimization of the L 2 -induced operator norm over a finite horizon (see <ref> [Li5, Ta] </ref>). As in the infinite horizon H 1 problem, difficulties arise if the direct-feedthrough matrices do not satisfy certain assumptions (the so-called singular case). This chapter will use the techniques from chapters 4 and 5 to handle this problem for the finite-horizon case. <p> In <ref> [Ta] </ref> and [Li5] such conditions were formulated in terms of the existence of solutions to certain Riccati differential equations. Of course, in order to guarantee the existence of these Riccati differential equations, certain coefficient matrices of the system under consideration should have full rank (the regular case). <p> For two important cases these conditions are always satisfied: * If the system is time-invariant (i.e. all coefficient matrices are con stant, independent of time). * If the problem is regular in the sense as explained above. In this chapter, contrary to <ref> [Li5, Ta] </ref>, we shall assume that the system is time-invariant. We shall try to give the main ideas of the proof which follows the same lines as the proof of the results on the singular, infinite horizon, H 1 control problem discussed in the previous chapters. <p> The problem as posed here will be referred to as the finite horizon H 1 control problem by measurement feedback. This problem was studied before in <ref> [Li5, Ta] </ref>. However, these references assume that the following conditions hold: D 1 is surjective, D 2 is injective. In the present chapter we shall extend the results obtained in [Li5, Ta] to the case that D 1 and D 2 are arbitrary. <p> This problem was studied before in <ref> [Li5, Ta] </ref>. However, these references assume that the following conditions hold: D 1 is surjective, D 2 is injective. In the present chapter we shall extend the results obtained in [Li5, Ta] to the case that D 1 and D 2 are arbitrary. A central role in our study of the problem posed is played by what we shall call the quadratic differential inequality. Let fl &gt; 0 be given. <p> The same holds for Q satisfying (c) and (d). It can be shown that for the special case when D 1 and D 2 are assumed to be surjective and injective, respectively, our theorem 8.1 specializes to the results obtained before in <ref> [Li5, Ta] </ref>. <p> We have noted that the results obtained can be specialized to re-obtain results that were obtained before (see <ref> [Li5, Ta] </ref>). The development of our theory runs analogously to the theory developed in chapters 4 and 5 around the standard H 1 control problem (the infinite horizon version of the problem studied in the present chapter). <p> It should be noted that the geometric approach from appendix A is not well-suited to treat time-varying systems. This is why we cannot treat the time-varying case as in <ref> [Li5, Ta] </ref>. The formal proof for the results in this chapter is also highly technical, mainly due to the fact that the systems P and P;Q are time-varying. The reason why the approach via appendix A still works is that the singular structure of P and P;Q is time-invariant. <p> In contrast, in the next two chapters we investigate the infinite horizon case using a direct approach. We shall use time-domain techniques which are reminiscent of those used in chapter 3 and the paper <ref> [Ta] </ref> which deal with the continuous time case. The method used in the next two chapters was derived independently of [Bas, Li4, Ya] and has already ap 166 9.1 Introduction 167 peared in [St5, St6]. <p> However for this P we have R = 1. The general outline of the proof will be reminiscent of the proof given in <ref> [Ta] </ref> and chapter 3 for the continuous time case. The extra condition (9.2), the invertibility of (9.3) and the requirement of left-invertibility instead of assuming that D 1 is injective will give rise to a substantial increase in the amount of intricacies in the proof.
Reference: [Tr] <author> H.L. Trentelman, </author> <title> Almost invariant subspaces and high gain feedback, </title> <journal> CWI Tracts, </journal> <volume> Vol. </volume> <pages> 29, </pages> <address> Amsterdam, </address> <year> 1986. </year>
Reference-contexts: In our proof an important role will be played by a result in the context of the problem of almost disturbance decoupling as studied in <ref> [Tr] </ref> and [Wi5]. The results we need are recapitulated in section 2.6. We shall now formulate and prove the converse of corollary 4.2: Theorem 4.3 : Consider the system (4.1). Assume that (A; B; C; D 1 ) has no invariant zeros on the imaginary axis. <p> We shall describe a method which is an adapted version of the one given in <ref> [Tr] </ref>. An alternative method is described in [OSS1]. We denote the first three matrices of the quadruple in (4.16) by ~ A, ~ B and ~ C respectively. (i) We construct a new basis for the state space. We shall construct it by induction. <p> Define a linear mapping F such that F x j = v j ; j = 1; : : : ; i and extend it arbitrarily to the whole state space. In <ref> [Tr] </ref> it has been shown that ~ AR fl a ( ker ~ C) + im ~ B = T ( ht ) = R n . <p> F n x j;r j +1 (n) := n r j +1 v j for j = 1; : : : ; k. This determines F n uniquely. Define F n := F + F n . It is shown in <ref> [Tr] </ref> that the spectrum of ~ A + ~ BF n is the set fng. Moreover, we have lim k ~ Ce (A+BF n )t k 1 = 0 Choose n such that the impulse response has L 1 norm smaller than ffi. <p> Theorem 7.11 is in fact the main part of theorem 7.1. Exactly when the infimum of the entropy function is attained is still to be investigated. From the theory of almost disturbance decoupling (see <ref> [Tr] </ref>), it is well-known that there is often only a non-proper controller which attains the infimum (note that because the interconnection should be well-posed it is possible that not even a non-proper controller can attain the infimum). <p> The main difficulty is that P;Q is time-varying and therefore it is necessary to derive a time-varying version of theorem 2.20 (we do not need (2.48) but we do need (2.47)). The basic steps are all the same but the proof is based on <ref> [Tr, Theorem 3.25] </ref> of which we had to derive a time-varying version.
Reference: [Tr2] <author> H.L. Trentelman, A.A. Stoorvogel, </author> <title> "Completion of the squares in the finite horizon H 1 control problem by measurement feedback", New trends in system theory, </title> <booktitle> Proc. of the Universita di Genova-The Ohio State University Joint Conference, </booktitle> <editor> G. Conte, A.M. Perdon, B. Wyman (eds.), </editor> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1991, </year> <pages> pp. 692-699. </pages>
Reference-contexts: The present paper addresses the problem formulated above without these full rank assumptions. We find necessary and sufficient conditions in terms of a pair of quadratic matrix differential inequalities. The results of this chapter have already appeared in <ref> [St7, Tr2] </ref>. The detailed proof of the results is highly technical and can be found in [St7]. This paper discusses time-varying systems which satisfy a number of con 154 8.2 Problem formulation and main results 155 ditions.
Reference: [Va] <author> A. Varga, V. Ionescu, </author> <title> "HTOOLS- a toolbox for solving H 1 and H 2 synthesis problems", </title> <booktitle> IFAC CADCS '91 Symposium, </booktitle> <address> Swansea, UK, </address> <year> 1991. </year>
Reference-contexts: However, results like this facilitate the construction of weights. Specific performance criteria like the ones above can be left out while constructing weights and can be incorporated at a later stage. Finally it should be noted that there are now several toolboxes available (see, e.g. <ref> [CS, Va] </ref>) using the software package Matlab which contain 11.4 An inverted pendulum on a cart 217 built-in tools to design controllers based on LQG and H 1 control techniques.
Reference: [Vi] <author> M. Vidyasagar, </author> <title> Control System Synthesis: A factorization approach, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1985 </year>
Reference-contexts: Each time we find a problem which can be reduced to an H 1 control problem. The first two problems can be found in <ref> [MF, Vi] </ref>. The last problem is discussed in [Hi]. The second and third problems will in general yield singular H 1 control problems. 205 206 Applications 11.2.1 Additive perturbations Essentially the results of this subsection have already appeared in [Gl2]. <p> It should be noted that an assumption like fixing the number of unstable poles is needed since otherwise there are always arbitrary small perturbations that destabilize the closed-loop system. In <ref> [Vi] </ref> the following result is given: Lemma 11.1 : Let a controller F of the form (2.4) be given. <p> In <ref> [Vi] </ref> there is also a result for multiplicative perturbations: Lemma 11.3 : Let a system = (A; B; C; D) and a controller F of the form (2.4) be given. <p> These kind of conditions are all based on the requirement that the closed-loop transfer matrix satisfies certain constraints on the imaginary axis. Without proof we shall give the following result. This result stems basically from [HSK] and <ref> [Vi, lemma 6.5.9] </ref>. Theorem 11.7 : Let a system of the form (2.1) be given. Assume that a compensator of the form (2.4) which is internally stabilizing exists such that the closed-loop system has H 1 norm less than one.
Reference: [Wa] <author> D.J. Walker, </author> <title> "Relationship between three discrete-time H 1 algebraic Riccati equation solutions", </title> <journal> Int. J. Contr., </journal> <volume> Vol. 52, </volume> <year> 1990, </year> <pages> pp. 801-809. </pages>
Reference-contexts: After the appearance of the above papers, several new papers and a book appeared on this subject using a state space approach (see e.g. <ref> [BB, Ig, Wa] </ref>). Very recently the J-spectral factorization approach has also been extended to discrete time systems (see [LMK]). In this chapter we assume that we deal with the special cases that either both disturbance and state are available for feedback or only the state is available for feedback. <p> For details we refer to [St15]. We investigate the existence of a matrix P such that: * The matrix G (P ) defined by (9.3) is invertible. * P satisfies the discrete algebraic Riccati equation (9.4). * The matrix A cl defined by (9.5) is asymptotically stable. In <ref> [Ig, Wa] </ref> solvability of the discrete time algebraic Riccati equation introduced in this chapter is reduced to a generalized eigenvalue problem for a symplectic pair. We show that this can be done if D 1 is injective. In general, no method is available for such a reduction. <p> However, for discrete time Riccati equations it is sometimes more desirable to have recursive algorithms as, e.g. is given in [Fa] for a different type of Riccati equation. This is derived in <ref> [WA, St15] </ref>. An extension of the use of symplectic pairs to the case that D 1 is not injective is useful. This is a subject of current research. 9.6 Conclusion In this chapter the discrete time full-information H 1 control problem has been investigated. <p> However, this time we did not succeed in expressing the existence and the solution in terms of the solutions of the full-information Riccati equation and its dual version. Recently it has been shown (see <ref> [Ig, Wa] </ref>) that if the direct-feedthrough matrices from u to z and from w to y are injective and surjective respectively then we can reduce our result to a result similar to theorem 5.1: two uncoupled Riccati equations and a coupling condition (a bound on the spectral radius of the product <p> In <ref> [Ig, Wa] </ref> it has been shown that if D 21 is injective and D 12 is surjective then our conditions (d)-(f) are equivalent to the existence of a matrix Q which is dual to P in the sense that Q satisfies the same conditions as P but for the system T <p> The extension to the finite horizon discrete time case (similar to chapter 8) is discussed in [Bas, Li4]. It would be interesting to find two dual Riccati equations and a coupling condition as in <ref> [Ig, Wa] </ref> for the case that either D 21 is not injective or D 12 is not surjective. Nevertheless the results presented in this chapter show that it is possible to solve discrete time H 1 problems directly, instead of transforming them to continuous time problems.
Reference: [WA] <author> A.J.T.M. Weeren, </author> <title> Solving discrete time algebraic Riccati equations, </title> <type> Masters Thesis, </type> <institution> Eindhoven University of Technology, </institution> <year> 1991. </year>
Reference-contexts: After the appearance of the above papers, several new papers and a book appeared on this subject using a state space approach (see e.g. <ref> [BB, Ig, Wa] </ref>). Very recently the J-spectral factorization approach has also been extended to discrete time systems (see [LMK]). In this chapter we assume that we deal with the special cases that either both disturbance and state are available for feedback or only the state is available for feedback. <p> For details we refer to [St15]. We investigate the existence of a matrix P such that: * The matrix G (P ) defined by (9.3) is invertible. * P satisfies the discrete algebraic Riccati equation (9.4). * The matrix A cl defined by (9.5) is asymptotically stable. In <ref> [Ig, Wa] </ref> solvability of the discrete time algebraic Riccati equation introduced in this chapter is reduced to a generalized eigenvalue problem for a symplectic pair. We show that this can be done if D 1 is injective. In general, no method is available for such a reduction. <p> However, for discrete time Riccati equations it is sometimes more desirable to have recursive algorithms as, e.g. is given in [Fa] for a different type of Riccati equation. This is derived in <ref> [WA, St15] </ref>. An extension of the use of symplectic pairs to the case that D 1 is not injective is useful. This is a subject of current research. 9.6 Conclusion In this chapter the discrete time full-information H 1 control problem has been investigated. <p> However, this time we did not succeed in expressing the existence and the solution in terms of the solutions of the full-information Riccati equation and its dual version. Recently it has been shown (see <ref> [Ig, Wa] </ref>) that if the direct-feedthrough matrices from u to z and from w to y are injective and surjective respectively then we can reduce our result to a result similar to theorem 5.1: two uncoupled Riccati equations and a coupling condition (a bound on the spectral radius of the product <p> In <ref> [Ig, Wa] </ref> it has been shown that if D 21 is injective and D 12 is surjective then our conditions (d)-(f) are equivalent to the existence of a matrix Q which is dual to P in the sense that Q satisfies the same conditions as P but for the system T <p> The extension to the finite horizon discrete time case (similar to chapter 8) is discussed in [Bas, Li4]. It would be interesting to find two dual Riccati equations and a coupling condition as in <ref> [Ig, Wa] </ref> for the case that either D 21 is not injective or D 12 is not surjective. Nevertheless the results presented in this chapter show that it is possible to solve discrete time H 1 problems directly, instead of transforming them to continuous time problems.
Reference: [We] <author> S. Weiland, </author> <title> "Linear quadratic games, H 1 and the Riccati equation", Proceedings of The Riccati equation in control, systems and signals, </title> <address> Como, Italy, </address> <year> 1989, </year> <pages> pp. 156-159. </pages>
Reference-contexts: Recently, a number of papers appeared which studied a zero-sum differential game with the goal of obtaining such a characterization (see <ref> [Pe2, Pe3, We] </ref>). A very recent book on the relation between H 1 and differential games is [BB].
Reference: [Wh] <author> P. </author> <title> Whittle, </title> <journal> "Risk-sensitive linear/quadratic/Gaussian control", Adv. Appl. Prob., </journal> <volume> Vol. 13, </volume> <year> 1981, </year> <pages> pp. 764-777. </pages>
Reference-contexts: Note that the central controller can be given an interpretation as minimizing the entropy (see chapter 7) and as the optimal controller for the linear exponential Gaussian stochastic control problem (see <ref> [BvS, Wh] </ref>). For the regular case this characterization is completely similar to the characterization given in [Do5, Ta]. 5.6 No assumptions on any direct-feedthrough matrix In this section we shall briefly discuss how we can extend our result in theorem 5.1 to the more general system (2.1). <p> Note that the central controller can be given an interpretation as minimizing the entropy (a discrete time version of the entropy function discussed in chapter 7) and as the optimal controller for the linear exponential Gaussian stochastic control problem (see <ref> [Wh] </ref>). 204 The discrete time, measurement feedback case 10.6 Conclusion In this chapter we have solved the discrete time H 1 control problem with measurement feedback. It is shown that the techniques for the continuous time case can be applied to the discrete time case.
Reference: [Wi] <author> J.C. Willems, </author> <title> "Least squares stationary optimal control and the algebraic Riccati equation", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 16, </volume> <year> 1971, </year> <pages> pp. 621-634. </pages>
Reference: [Wi2] <author> J.C. Willems, </author> <title> The analysis of feedback systems, </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1971. </year>
Reference: [Wi3] <author> J.C. Willems, </author> <title> "Dissipative dynamical systems, part I: general theory", Arch. Rational Mech. </title> <journal> Anal., </journal> <volume> Vol. 45, </volume> <year> 1972, </year> <pages> pp. 321-351. </pages>
Reference: [Wi4] <author> J.C. Willems, </author> <title> "Dissipative dynamical systems, part I: linear systems with quadratic supply rates", Arch. Rational Mech. </title> <journal> Anal., </journal> <volume> Vol. 45, </volume> <year> 1972, </year> <pages> pp. 352-393. 272 Bibliography </pages>
Reference: [Wi5] <author> J.C. Willems, </author> <title> "Almost invariant subspaces: an approach to high gain feedback design- Part I: almost controlled invariant sub-spaces", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 26, </volume> <year> 1981, </year> <pages> pp. 235-252. </pages>
Reference-contexts: In our proof an important role will be played by a result in the context of the problem of almost disturbance decoupling as studied in [Tr] and <ref> [Wi5] </ref>. The results we need are recapitulated in section 2.6. We shall now formulate and prove the converse of corollary 4.2: Theorem 4.3 : Consider the system (4.1). Assume that (A; B; C; D 1 ) has no invariant zeros on the imaginary axis.
Reference: [Wi6] <author> J.C. Willems, </author> <title> "Almost invariant subspaces: an approach to high gain feedback design- Part II: almost conditionally invariant sub-spaces", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 27, </volume> <year> 1982, </year> <pages> pp. 1071-1084. </pages>
Reference: [Wi7] <author> J.C. Willems, A. Kitapci, L.M. Silverman, </author> <title> "Singular optimal control: a geometric approach", </title> <journal> SIAM J. Contr. & Opt., </journal> <volume> Vol. 24, </volume> <year> 1986, </year> <pages> pp. 323-337. </pages>
Reference-contexts: This Riccati equation has the special property that the quadratic term is, in general, indefinite, in contrast to, for instance, the equation appearing in linear quadratic optimal control theory (see <ref> [Wi7] </ref>), where the quadratic term in the Riccati equation is always definite. Since in H 1 control theory the solution of the algebraic Riccati equation has no meaning in itself it is interesting to give a more intuitive characterization such as a Nash equilibrium in the theory of differential games. <p> A similar phenomenon also occurs in linear quadratic optimal control theory, although in that case we get a linear matrix inequality (see <ref> [Wi7] </ref>). This chapter is concerned with the zero-sum differential game in the case that the direct-feedthrough matrix is not injective. It will be 120 6.2 Problem formulation and main results 121 shown that, as expected, existence of equilibria is related to solutions of a quadratic matrix inequality. <p> At this point we shall recall the following, known, result for the LQ problem with stability (see <ref> [Wi7] </ref>). 6.5 The regular differential game 135 Lemma 6.11 : Consider the system (6.2) with cost criterion (6.1). Let w = 0. Assume that (A; B) is stabilizable, that (A; B; C; D) has no invariant zeros in C 0 and that D injective. <p> Via the reduced order Riccati equation associated with this linear matrix inequality (see appendix A) it can be shown that the largest solution of the linear matrix 11.2 Robustness problems 211 inequality, whose existence is guaranteed since (C,A) is detectable (dual-ize the results in <ref> [Gee, Wi7] </ref>), satisfies all the requirements on Q m . This shows existence of Q m . Uniqueness was already guaranteed by corollary A.7.
Reference: [Wo] <author> W.M. Wonham, </author> <title> Linear multivariable control: a geometric approach, 2nd ed., </title> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1979. </year>
Reference: [WW] <author> S. Weiland, J.C. Willems, </author> <title> "Almost disturbance decoupling with internal stability", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 34, </volume> <year> 1989, </year> <pages> pp. 277-286. </pages>
Reference: [WW2] <author> S. Weiland, J.C. Willems, </author> <title> "Dissipative systems in a behavioural context", </title> <journal> Math. Models and Methods in Applied Sciences, </journal> <volume> Vol. 1, No. 1, </volume> <year> 1991, </year> <pages> pp. 1-25. </pages>
Reference: [Ya] <author> I. Yaesh, U. Shaked, </author> <title> "Minimum H 1 -norm regulation of linear discrete-time systems and its relation to linear quadratic discrete games", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 35, </volume> <year> 1990, </year> <pages> pp. 1061-1064. </pages>
Reference-contexts: Recently, a paper has appeared solving the discrete time H 1 control problem using frequency-domain techniques (see [Gu]). The polynomial approach has also been applied to discrete time systems (see [Gri]). In addition, a couple of papers have appeared using a time-domain approach (see <ref> [Bas, Li4, Ya] </ref>). With respect to the papers which use a time-domain approach it should be noted that the references [Bas, Li4, Ya] do not contain a proof of the results obtained for the infinite horizon case and the papers [Bas, Ya] make a number of extra assumptions on the system <p> The polynomial approach has also been applied to discrete time systems (see [Gri]). In addition, a couple of papers have appeared using a time-domain approach (see <ref> [Bas, Li4, Ya] </ref>). With respect to the papers which use a time-domain approach it should be noted that the references [Bas, Li4, Ya] do not contain a proof of the results obtained for the infinite horizon case and the papers [Bas, Ya] make a number of extra assumptions on the system under consideration. In [Bas, Li4, Ya] the authors first investigate the finite horizon problem and then derive a solution of <p> With respect to the papers which use a time-domain approach it should be noted that the references [Bas, Li4, Ya] do not contain a proof of the results obtained for the infinite horizon case and the papers <ref> [Bas, Ya] </ref> make a number of extra assumptions on the system under consideration. In [Bas, Li4, Ya] the authors first investigate the finite horizon problem and then derive a solution of the infinite horizon problem by considering it as a kind of limiting case as the endpoint tends to infinity. <p> respect to the papers which use a time-domain approach it should be noted that the references <ref> [Bas, Li4, Ya] </ref> do not contain a proof of the results obtained for the infinite horizon case and the papers [Bas, Ya] make a number of extra assumptions on the system under consideration. In [Bas, Li4, Ya] the authors first investigate the finite horizon problem and then derive a solution of the infinite horizon problem by considering it as a kind of limiting case as the endpoint tends to infinity. <p> We shall use time-domain techniques which are reminiscent of those used in chapter 3 and the paper [Ta] which deal with the continuous time case. The method used in the next two chapters was derived independently of <ref> [Bas, Li4, Ya] </ref> and has already ap 166 9.1 Introduction 167 peared in [St5, St6]. After the appearance of the above papers, several new papers and a book appeared on this subject using a state space approach (see e.g. [BB, Ig, Wa]). <p> This distinction has to be made since there is a more essential difference between these two cases than in the continuous time case. The more general case of measurement feedback is discussed in the next chapter. The assumptions we shall make are weaker than the assumptions made in <ref> [Gu, Ya] </ref> and the same as the ones made in [Li4]. For the full-information case we have to make two assumptions which are exactly the discrete time analogues of the assumptions made in the regular continuous time H 1 control problem as discussed in chapter 3.
Reference: [Yo] <author> N. Young, </author> <title> An introduction to Hilbert space, </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1988. </year>
Reference: [Za] <author> G. Zames, </author> <title> "Feedback and optimal sensitivity: model reference transformations, multiplicative seminorms, and approximate inverses", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol 26, </volume> <year> 1981, </year> <pages> pp. 301-320. </pages>
Reference: [Za2] <author> G. Zames, B.A. Francis, </author> <title> "Feedback, minimax sensitivity and optimal robustness", </title> <journal> IEEE Trans. Aut. Contr., </journal> <volume> Vol. 28, </volume> <year> 1983, </year> <pages> pp. 585-600. </pages>
Reference-contexts: During the last few years the H 1 control problem with measurement feedback was investigated via several new methods: * The interpolation approach. In fact, the interpolation approach already has quite a history and several authors have worked on this problem (see e.g. <ref> [Gr, Kh, Li3, Za2] </ref>). However, it can only treat the special case of a one-block H 1 control problem. One should note that the classic interpolation techniques were used for discrete time systems.
Reference: [Zh] <author> S.Q. Zhu, </author> <title> Robustness of feedback stabilization: A topological approach, </title> <type> Ph.D. Thesis, </type> <institution> Department of Mathematics and Computing Science, Eindhoven University of Technology, The Nether-lands, </institution> <year> 1989. </year>
Reference: [ZK] <author> K. Zhou, </author> <title> P.P. Khargonekar, "Robust stabilization of linear systems with norm bounded time varying uncertainty", </title> <journal> Syst. & Contr. Letters, </journal> <volume> Vol. 10, </volume> <year> 1988, </year> <pages> pp. 17-20. Bibliography 273 </pages>
Reference: [ZK2] <author> K. Zhou, </author> <title> P.P. Khargonekar, "An algebraic Riccati equation approach to H 1 optimization", </title> <journal> Syst. & Contr. Letters, </journal> <volume> Vol. 11, </volume> <year> 1988, </year> <pages> pp. 85-91. </pages>
Reference-contexts: section 5.1 88 The general full-information H 1 control problem for the H 1 control problem with measurement feedback are often not very suitable to treat the special cases of state feedback and full-information feedback. 4.7.2 Cheap control In this subsection we shall briefly describe how the method used in <ref> [Kh3, Kh2, Pe3, Pe5, ZK2] </ref> still gives necessary and sufficient conditions for the existence of internally stabilizing controllers which make the H 1 norm of the closed-loop system less than 1 even when we have invariant zeros on the imaginary axis.

References-found: 153

