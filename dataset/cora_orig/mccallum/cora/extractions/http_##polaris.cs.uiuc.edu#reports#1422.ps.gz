URL: http://polaris.cs.uiuc.edu/reports/1422.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: High Performance Algorithms for Toeplitz and block Toeplitz matrices  
Author: K. A. Gallivan S. Thirumalai P. Van Dooren V. Vermaut 
Address: Urbana IL, USA  
Affiliation: Coordinated Science Laboratory, University of Illinois at Urbana-Champaign,  Universite Catholique de Louvain, Louvain, Belgium  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> O. B. Arushanian, M. K. Samarin, V. V. Voevoedin, E. E. Tyrtyshnikov, B. S. Garbow, J. M. Boyle, W. R. Cowell, and K. W. Dritz, </author> <title> The Toeplitz package users' guide, </title> <type> tech. rep., </type> <institution> Argonne National Laboratory, </institution> <year> 1983. </year>
Reference-contexts: Based on the existing Schur type algorithms and the algorithms discussed in this paper a high performance library is currently being developed. In the past there have been efforts to develop libraries for point Toeplitz matrices <ref> [1, 19] </ref> on serial machines using the Levinson algorithm. The proposed library can be used to solve point and block Toeplitz matrices on parallel machines. On parallel machines, the Levinson algorithm suffers from reduced parallelism.
Reference: [2] <author> C. Bischof and C. V. Loan, </author> <title> The WY representation for products of Householder matrices, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 8 (1987), </volume> <pages> pp. </pages> <month> s2-s13. </month>
Reference-contexts: We extend their idea to block hyperbolic Householder transformations (required in the block Schur algorithm), using representations very similar to those proposed in <ref> [2] </ref> and [29]. Let W be a diagonal matrix whose entries are either +1 or 1. <p> This 5 allows us to use level-3 BLAS primitives rather than level-2 BLAS operations if we applied the transformations sequentially. Storage efficient ways to block regular Householder transformations are derived in <ref> [2] </ref> and [29]. We extend these methods to hyperbolic Householder transforms. Suppose U (r) = U r U r1 : : : U 2 U 1 is a product of r n fi n hyperbolic Householder matrices. <p> The matrix U can be written in two forms corresponding to the V Y form and the Y T Y T form derived in <ref> [2] </ref> and [29]. The two forms of the V Y representation differ in the types of primitives they use.
Reference: [3] <author> S. Cabay and R. Meleshko, </author> <title> A weakly stable algorithm for Pade approximants and the inversion of Hankel matrices, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 14 (1993), </volume> <pages> pp. 735-765. </pages>
Reference-contexts: Most of the techniques related to these developments are based on the theory of orthogonal polynomials [17] or equivalently on that of T conjugate directions. This theory is in turn closely connected to that of Hankel matrices and the Pade algorithm <ref> [3] </ref> and of Toeplitz matrices and the Levinson algorithm [12]. In both cases one constructs the decomposition L 1 T L T = D where T is the given Toeplitz matrix. The rows of L 1 are the conjugate directions or also contain the coefficients of the orthogonal polynomials. <p> The rows of L 1 are the conjugate directions or also contain the coefficients of the orthogonal polynomials. Look-ahead techniques have been proposed and yielded algorithms with satisfactory numerical behavior, <ref> [3] </ref>, [4],[12], [25], [18]. The look-ahead Schur algorithm proposed in [18] is based on orthogonal polynomials and does not extend to block Toeplitz matrices.
Reference: [4] <author> T. F. Chan and P. C. Hansen, </author> <title> A look-ahead Levinson algorithm for indefinite Toeplitz systems, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 13 (1992), </volume> <pages> pp. 490-506. 36 </pages>
Reference-contexts: If an exact factorization of the indefinite block Toeplitz matrix is desired, then one would have to look-ahead over the singular or near singular principal minors. Look-ahead algorithms based on the Levinson algorithm have appeared in the literature <ref> [4, 12] </ref> but suffer from the same reduced parallelism relative to the Schur algorithm mentioned above and are limited to point Toeplitz matrices. Look-ahead Schur algorithms based on orthogonal polynomials exist [18] but are limited to point Toeplitz matrices. <p> If we are to "jump" over (k 1)m steps of the Schur algorithm, we also require that the off-diagonal entries of T 1 11 T 12 not be too large. A detailed discussion on the determination of the look-ahead step size (denoted here by k) can be found in <ref> [4] </ref> and [12]. We restrict our discussion to the look-ahead scheme after the determination of the step size k. The first step in this look-ahead scheme is the computation of the first km rows of the Toeplitz or quasi Toeplitz matrix given by [ T 11 j T 12 ]. <p> This algorithm is of course only conceptual. It does not describe how to track the condition number of T 11 . For this we refer to techniques as those described in <ref> [4; 18; 12] </ref>. If no look-ahead is necessary, then the blocking scheme discussed in Section 2.5 can be used to compute H. If a look-ahead of size km is required, then H can be computed as shown in Lemma 4.
Reference: [5] <author> J. Chun and T. Kailath, </author> <title> Generalized displacement structure for block Toeplitz, Toeplitz block and Toeplitz derived matrices, </title> <institution> Informations Systems Lab., Stanford University, </institution> <address> CA, </address> <year> (1988). </year>
Reference-contexts: Let T j = L 1 1 ^ T j . It is easy to see that T 1 = L T 1 . We now define two matrices G 1 (T ) and G 2 (T ) as follows [22], <ref> [5] </ref>: G 1 (T ) = B B B B T 1 T 2 T 3 : : : T p . . . . . . . . . . . . . . .
Reference: [6] <author> J. Chun, T. Kailath, and H. Lev-Ari, </author> <title> Fast parallel algorithms for QR and triangular factorization, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 8 (1987), </volume> <pages> pp. 899-913. </pages>
Reference-contexts: In Section 3 we present two look-ahead Schur algorithms for point and block Toeplitz matrices and compare the two from a computational viewpoint. The classical Schur algorithm can be generalized to obtain the QR factorization of block Toeplitz matrices <ref> [6] </ref>. If the Toeplitz matrix is rank deficient, then we present a modification of the generalized Schur algorithm in Section 4 to obtain the QR factorization by pruning the generators of the Toepliz matrix. <p> This generalized Schur algorithm has been outlined in <ref> [6] </ref> for scalar Toeplitz matrices and can be trivially extended to block Toeplitz matrices. In this section we present a modification of the generalized Schur algorithm for rank deficient Toeplitz matrices. <p> This reduces the complexity of the generalized Schur algorithm. For numerically rank deficient block Toeplitz matrices this algorithm yields a low rank approximation. 4.1 QR factorization of Rank Deficient Toeplitz matrices The generalized Schur algorithm described in <ref> [6] </ref> was applied to block Toeplitz systems with full column rank. In several applications in signal and image processing the Toeplitz systems are related to rank deficient least squares problems and hence regularization has to be applied in order to yield an acceptable solution. <p> We show that in this case a very particular property holds in the generator obtained at the start of the k th step of the generalized Schur algorithm. As seen in <ref> [6] </ref>, the generator for the matrix T T T is of the form T T T = G T 2 G T 4 2 6 4 0 I 0 0 0 0 0 I 7 7 2 6 4 G 2 G 4 7 7 (116) where G i ; i <p> This shows the good numerical behavior of the regularization algorithm. 5 Conversion to Cauchy type matrices In Section 4, we discussed modifications to the QR factorization algorithm for block Toeplitz matrices proposed by Chun et. al. <ref> [6] </ref>. The modified algorithm could be used to obtain the QR factorization of an exactly rank deficient block Toeplitz matrix. If the Toeplitz matrix happened to be numerically rank deficient, then only a low approximation of the block Toeplitz matrix could be obtained. <p> Rank deficient Toeplitz matrices arise in image reconstruction and system identification problems. In [20] Heinig and Gesmar present a look-ahead like algorithm for fast orthogonalization of rank deficient Toeplitz matrices and in [11] Elden and Park present a modification to the algorithm proposed in <ref> [6] </ref> where they delay the application of the ill-conditioned skew hyperbolic transforms to obtain an approximate factorization. Both algorithms do not involve any pivoting since they deal with Toeplitz matrices only.
Reference: [7] <author> P. Concus and P. </author> <title> Saylor, A modified direct preconditioner for indefinite symmetric Toeplitz systems, </title> <institution> Department of Computer Science, University of Illinois at Urbana Champaign. </institution>
Reference-contexts: One way to circumvent the possible numerical instability of the Schur algorithm is to use iterative refinement on the system of equations. A similar perturbation technique has been used in <ref> [7] </ref> for the Levinson algorithm. They use the approximate factorization as a preconditioner in the conjugate-gradient algorithm. <p> In this subsection we show how to obtain this by selective perturbations introduced in the Schur algorithm. Similar ideas have independently been developed for the Levinson algorithm by Concus and Saylor <ref> [7] </ref>.
Reference: [8] <author> G. Cybenko and M. Berry, </author> <title> Hyperbolic Householder algorithms for factoring structured matrices, </title> <journal> SIAM J. Matrix Anal. Appl, </journal> <volume> 11 (1990), </volume> <pages> pp. 499-520. </pages>
Reference-contexts: Algorithms to obtain the QR factorization of exactly and nearly rank deficient Toeplitz matrices are also discussed. In this paper the classical Schur algorithm for obtaining the Cholesky factorization of symmetric positive definite block Toeplitz matrices <ref> [9, 8] </ref> is generalized to the block Toeplitz matrix case using a block generalization of the hyperbolic Householder reflectors. The block generalization of the Schur algorithm and various blocking schemes differing in the amount of storage and computational primitives used are described in Section 2. <p> This yields a rank revealing algorithm for the factorization of a semidefinite block Toeplitz matrix that is computationally less expensive than the algorithm presented in [21, 15]. 2 Symmetric positive definite block Toeplitz matrices In this section we present a block generalization of the classical Schur algorithm <ref> [8, 9] </ref> using block hyperbolic Householder reflectors. Block hyperbolic Householder transformations can be applied at the BLAS 3 rate rather than plain householder transformations which are applied at the BLAS 2 rate. On machines with a memory heirarchy this provides us with a significant improvement in performance. <p> that U G = R, where R is upper triangular, then we have T = G T W mp G = G T U T W mp U G h i I mp 0 # " 0 = R T R; (4) which gives us the Cholesky factorization of T <ref> [8] </ref>. The transformation matrix U which satisfies the property U T W mp U = W mp , is called a hyperbolic Householder transformation [26]. The basic properties of hyperbolic Householder reflectors are discussed in Section 2.2. <p> A detailed discussion of the Schur algorithm for indefinite Toeplitz matrices is presented in Section 3. 2.2 Hyperbolic Householder transformations In their paper <ref> [8] </ref>, Cybenko and Berry use hyperbolic Householder transformations [26] to reduce the generator matrix G of a scalar Toeplitz matrix to an upper triangular matrix. <p> Let x be a column vector such that x T W x 6= 0. A hyperbolic Householder matrix is defined as follows: U x = W x T W x One easily checks <ref> [8] </ref> and [27] that U x is W -unitary, i.e., U T x W U x = W . These transformations can be used to map one vector to another as long as they have the same hyperbolic norm, i.e., if a T W a = b T W b. <p> A detailed performance analysis of the three blocking schemes is presented in [14]. 2.4 The Factorization Algorithm The following algorithm is used to reduce matrix G (3) described in Section 2.1 to an upper triangular matrix. This algorithm is essentially the same as the one described in <ref> [8] </ref> except that we are dealing with blocks instead of elements. We describe the algorithm using an example as follows.
Reference: [9] <author> J.-M. Delosme, I. C. F. Ipsen, and C. C. Paige, </author> <title> The Cholesky factorization, Schur complements, correlation coefficients, angles between vectors, and the QR factorization, </title> <type> tech. rep., </type> <institution> Yale University, </institution> <year> 1988. </year>
Reference-contexts: Algorithms to obtain the QR factorization of exactly and nearly rank deficient Toeplitz matrices are also discussed. In this paper the classical Schur algorithm for obtaining the Cholesky factorization of symmetric positive definite block Toeplitz matrices <ref> [9, 8] </ref> is generalized to the block Toeplitz matrix case using a block generalization of the hyperbolic Householder reflectors. The block generalization of the Schur algorithm and various blocking schemes differing in the amount of storage and computational primitives used are described in Section 2. <p> This yields a rank revealing algorithm for the factorization of a semidefinite block Toeplitz matrix that is computationally less expensive than the algorithm presented in [21, 15]. 2 Symmetric positive definite block Toeplitz matrices In this section we present a block generalization of the classical Schur algorithm <ref> [8, 9] </ref> using block hyperbolic Householder reflectors. Block hyperbolic Householder transformations can be applied at the BLAS 3 rate rather than plain householder transformations which are applied at the BLAS 2 rate. On machines with a memory heirarchy this provides us with a significant improvement in performance.
Reference: [10] <author> P. Delsarte, Y. Genin, and Y. Kamp, </author> <title> Pseudo-Caratheodory functions and Hermitian Toeplitz matrices, </title> <journal> Philips J. Res., </journal> <volume> 41 (1986), </volume> <pages> pp. 1-54. </pages>
Reference-contexts: The look-ahead Schur algorithm proposed in [18] is based on orthogonal polynomials and does not extend to block Toeplitz matrices. Look-ahead Schur algorithms for Toeplitz systems with exactly singular principal minors have been proposed in <ref> [10] </ref>, [24]. 19 In Sections 3.3.1 and 3.3.2 we discuss two look-ahead Schur algorithms that are based entirely on matrix operations and hence extend easily to block Toeplitz matrices. 3.3.1 Algorithm 1 Consider a mp fi mp block Toeplitz or quasi block Toeplitz matrix T with a block size of m
Reference: [11] <author> L. Elden and H. Park, </author> <title> Accurate least squares solutions for Toeplitz matrices, </title> <type> tech. rep., </type> <institution> Linkoping University, Sweden, </institution> <year> 1994. </year>
Reference-contexts: Rank deficient Toeplitz matrices arise in image reconstruction and system identification problems. In [20] Heinig and Gesmar present a look-ahead like algorithm for fast orthogonalization of rank deficient Toeplitz matrices and in <ref> [11] </ref> Elden and Park present a modification to the algorithm proposed in [6] where they delay the application of the ill-conditioned skew hyperbolic transforms to obtain an approximate factorization. Both algorithms do not involve any pivoting since they deal with Toeplitz matrices only.
Reference: [12] <author> R. W. Freund and H. Zha, </author> <title> Formally biorthogonal polynomials and a look-ahead Levinson algorithm for general Toeplitz systems, </title> <note> Linear Algebra Appl., 188 (1993), p. 255. </note>
Reference-contexts: If an exact factorization of the indefinite block Toeplitz matrix is desired, then one would have to look-ahead over the singular or near singular principal minors. Look-ahead algorithms based on the Levinson algorithm have appeared in the literature <ref> [4, 12] </ref> but suffer from the same reduced parallelism relative to the Schur algorithm mentioned above and are limited to point Toeplitz matrices. Look-ahead Schur algorithms based on orthogonal polynomials exist [18] but are limited to point Toeplitz matrices. <p> This theory is in turn closely connected to that of Hankel matrices and the Pade algorithm [3] and of Toeplitz matrices and the Levinson algorithm <ref> [12] </ref>. In both cases one constructs the decomposition L 1 T L T = D where T is the given Toeplitz matrix. The rows of L 1 are the conjugate directions or also contain the coefficients of the orthogonal polynomials. <p> A detailed discussion on the determination of the look-ahead step size (denoted here by k) can be found in [4] and <ref> [12] </ref>. We restrict our discussion to the look-ahead scheme after the determination of the step size k. The first step in this look-ahead scheme is the computation of the first km rows of the Toeplitz or quasi Toeplitz matrix given by [ T 11 j T 12 ]. <p> Let us also assume that all the conditions for determining the look-ahead step size of k as discussed in <ref> [12] </ref> are satisfied. We now derive updating formulas for the Schur complement of a matrix T with low displacement rank, and show that it also has low displacement rank. <p> This algorithm is of course only conceptual. It does not describe how to track the condition number of T 11 . For this we refer to techniques as those described in <ref> [4; 18; 12] </ref>. If no look-ahead is necessary, then the blocking scheme discussed in Section 2.5 can be used to compute H. If a look-ahead of size km is required, then H can be computed as shown in Lemma 4.
Reference: [13] <author> K. Gallivan, S. Thirumalai, and P. V. Dooren, </author> <title> A block Toeplitz look-ahead Schur algorithm, </title> <booktitle> 3 rd International Workshop on SVD and Signal Processing, </booktitle> <address> Leuven, Belgium, </address> <year> (1994). </year> <title> To appear. [14] , On solving block Toeplitz matrices using a block Schur algorithm, </title> <type> tech. rep., </type> <institution> CSRD, University of Illinois at Urbana-Champaign, </institution> <year> 1994. </year>
Reference-contexts: Then there always exists a transfor mation H such that H T ~ 1 0 # " 0 2 (87) " F 21 F 22 = ^ F 11 ^ F 12 # Proof. See <ref> [13] </ref> 2 In order to simplify (85) we now must apply this lemma to construct a transformation H such that H T ~ T 1 ~ H = T 1 ; (89) " h i G = ^ T 11 ^ T 12 # where ~ T 11 and ^ T
Reference: [15] <author> I. Gohberg, T. Kailath, and V. Olshevsky, </author> <title> Gaussian elimination with partial pivoting for structured matrices, </title> <type> tech. rep., </type> <institution> Information Systems Lab., Stanford University, </institution> <year> 1994. </year>
Reference-contexts: Finally we discuss algorithms to factor Toeplitz matrices by converting them to Cauchy type matrices. Toeplitz matrices can be converted using the discrete Fourier transform into Cauchy type matrices that allow pivoting during the factorization <ref> [21, 15] </ref>. These algorithms also have the same complexity,O (n 2 ), as the Schur algorithm. The problem with this method is that any real valued Toeplitz matrix is converted to a complex Cauchy type matrix and the entire factorization algorithm proceeds in complex arithmetic. This is computationally expensive. <p> This yields a rank revealing algorithm for the factorization of a semidefinite block Toeplitz matrix that is computationally less expensive than the algorithm presented in <ref> [21, 15] </ref>. 2 Symmetric positive definite block Toeplitz matrices In this section we present a block generalization of the classical Schur algorithm [8, 9] using block hyperbolic Householder reflectors. <p> If the Toeplitz matrix happened to be numerically rank deficient, then only a low approximation of the block Toeplitz matrix could be obtained. This was because any form of pivoting applied to the generalized Schur algorithm would destroy the displacement structure of the block Toeplitz matrix. 32 In <ref> [15, 21] </ref> it was shown that if Toeplitz matrices were converted to Cauchy type matrices, then the factorization of such matrices could be carried out with pivoting. The drawbacks of the algorithms proposed in [15, 21] were that complex valued FFT's were used to convert a real valued Toeplitz matrix into <p> the generalized Schur algorithm would destroy the displacement structure of the block Toeplitz matrix. 32 In <ref> [15, 21] </ref> it was shown that if Toeplitz matrices were converted to Cauchy type matrices, then the factorization of such matrices could be carried out with pivoting. The drawbacks of the algorithms proposed in [15, 21] were that complex valued FFT's were used to convert a real valued Toeplitz matrix into a complex valued Cauchy type matrix. The algorithms were not able to exploit any symmetry in the Toeplitz or quasi-Toeplitz matrix to reduce the computational complexity. <p> The algorithms were not able to exploit any symmetry in the Toeplitz or quasi-Toeplitz matrix to reduce the computational complexity. In this section we present a modification to the algorithms in <ref> [15, 21] </ref> to factor a symmetric semidefinite quasi-Toeplitz matrix using only real arithmetic and exploiting the symmetric property of the matrix. This algorithm can be used to obtain a rank revealing factorization of the matrix T T T where T is a rank deficient Toeplitz matrix. <p> It was shown in <ref> [15, 21] </ref> that if (126) is converted to (128) using the discrete Fourier transform, then Gaussian elimination with partial pivoting can be applied to obtain a factorization.
Reference: [16] <author> G. H. Golub and C. F. V. Loan, </author> <title> Matrix Computations, </title> <publisher> The John Hopkins University Press, </publisher> <year> 1989. </year>
Reference-contexts: After obtaining the first row of X, the maximum element of this row is computed. If the (1; 1) element of X can be used as the pivot (for a detailed description of the Bunch-Kaufman algorithm see <ref> [16] </ref>), then this row can be used to compute the next row of the factorization. If the (1; 1) element cannot be used as a pivot, another row of the matrix X needs to be computed in the same way as described above.
Reference: [17] <author> M. Gutknecht, </author> <title> A completed theory of the unsymmetric Lanczos process and related algorithms, part ii, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 15 (1994), </volume> <pages> pp. 15-58. </pages>
Reference-contexts: Most of the techniques related to these developments are based on the theory of orthogonal polynomials <ref> [17] </ref> or equivalently on that of T conjugate directions. This theory is in turn closely connected to that of Hankel matrices and the Pade algorithm [3] and of Toeplitz matrices and the Levinson algorithm [12].
Reference: [18] <author> M. Gutknecht and M. Hochbruck, </author> <title> Look-ahead Levinson and Schur algorithms for non-Hermitian Toeplitz systems, </title> <type> tech. rep., </type> <institution> IPS, ETH Zurich, </institution> <year> 1994. </year>
Reference-contexts: Look-ahead algorithms based on the Levinson algorithm have appeared in the literature [4, 12] but suffer from the same reduced parallelism relative to the Schur algorithm mentioned above and are limited to point Toeplitz matrices. Look-ahead Schur algorithms based on orthogonal polynomials exist <ref> [18] </ref> but are limited to point Toeplitz matrices. In Section 3 we present two look-ahead Schur algorithms for point and block Toeplitz matrices and compare the two from a computational viewpoint. The classical Schur algorithm can be generalized to obtain the QR factorization of block Toeplitz matrices [6]. <p> The rows of L 1 are the conjugate directions or also contain the coefficients of the orthogonal polynomials. Look-ahead techniques have been proposed and yielded algorithms with satisfactory numerical behavior, [3], [4],[12], [25], <ref> [18] </ref>. The look-ahead Schur algorithm proposed in [18] is based on orthogonal polynomials and does not extend to block Toeplitz matrices. <p> The rows of L 1 are the conjugate directions or also contain the coefficients of the orthogonal polynomials. Look-ahead techniques have been proposed and yielded algorithms with satisfactory numerical behavior, [3], [4],[12], [25], <ref> [18] </ref>. The look-ahead Schur algorithm proposed in [18] is based on orthogonal polynomials and does not extend to block Toeplitz matrices. <p> This algorithm is of course only conceptual. It does not describe how to track the condition number of T 11 . For this we refer to techniques as those described in <ref> [4; 18; 12] </ref>. If no look-ahead is necessary, then the blocking scheme discussed in Section 2.5 can be used to compute H. If a look-ahead of size km is required, then H can be computed as shown in Lemma 4.
Reference: [19] <author> P. C. Hansen and T. F. Chan, </author> <title> FORTRAN subroutines for general Toeplitz systems, </title> <journal> ACM Trans. on Mathematical Software, </journal> <volume> 18 (1992), </volume> <pages> pp. 256-273. </pages>
Reference-contexts: Based on the existing Schur type algorithms and the algorithms discussed in this paper a high performance library is currently being developed. In the past there have been efforts to develop libraries for point Toeplitz matrices <ref> [1, 19] </ref> on serial machines using the Levinson algorithm. The proposed library can be used to solve point and block Toeplitz matrices on parallel machines. On parallel machines, the Levinson algorithm suffers from reduced parallelism.
Reference: [20] <author> P. C. Hansen and H. Gesmar, </author> <title> Fast orthogonal decomposition of rank deficient Toeplitz matrices, Numerical Algorithms, </title> <booktitle> 4 (1993), </booktitle> <pages> pp. 151-166. 37 </pages>
Reference-contexts: The algorithm proposed in this section is a significant simplification over a similar approach proposed in <ref> [20] </ref>, which uses the Levinson algorithm with look-ahead. We include an example to illustrate the above algorithm. <p> This algorithm can be used to obtain a rank revealing factorization of the matrix T T T where T is a rank deficient Toeplitz matrix. Rank deficient Toeplitz matrices arise in image reconstruction and system identification problems. In <ref> [20] </ref> Heinig and Gesmar present a look-ahead like algorithm for fast orthogonalization of rank deficient Toeplitz matrices and in [11] Elden and Park present a modification to the algorithm proposed in [6] where they delay the application of the ill-conditioned skew hyperbolic transforms to obtain an approximate factorization.
Reference: [21] <author> G. Heinig, </author> <title> Inversion of geberalized Cauchy matrices and other classes of structured matrices, </title> <note> (1994). To appear in IMA volumes. </note>
Reference-contexts: Finally we discuss algorithms to factor Toeplitz matrices by converting them to Cauchy type matrices. Toeplitz matrices can be converted using the discrete Fourier transform into Cauchy type matrices that allow pivoting during the factorization <ref> [21, 15] </ref>. These algorithms also have the same complexity,O (n 2 ), as the Schur algorithm. The problem with this method is that any real valued Toeplitz matrix is converted to a complex Cauchy type matrix and the entire factorization algorithm proceeds in complex arithmetic. This is computationally expensive. <p> This yields a rank revealing algorithm for the factorization of a semidefinite block Toeplitz matrix that is computationally less expensive than the algorithm presented in <ref> [21, 15] </ref>. 2 Symmetric positive definite block Toeplitz matrices In this section we present a block generalization of the classical Schur algorithm [8, 9] using block hyperbolic Householder reflectors. <p> If the Toeplitz matrix happened to be numerically rank deficient, then only a low approximation of the block Toeplitz matrix could be obtained. This was because any form of pivoting applied to the generalized Schur algorithm would destroy the displacement structure of the block Toeplitz matrix. 32 In <ref> [15, 21] </ref> it was shown that if Toeplitz matrices were converted to Cauchy type matrices, then the factorization of such matrices could be carried out with pivoting. The drawbacks of the algorithms proposed in [15, 21] were that complex valued FFT's were used to convert a real valued Toeplitz matrix into <p> the generalized Schur algorithm would destroy the displacement structure of the block Toeplitz matrix. 32 In <ref> [15, 21] </ref> it was shown that if Toeplitz matrices were converted to Cauchy type matrices, then the factorization of such matrices could be carried out with pivoting. The drawbacks of the algorithms proposed in [15, 21] were that complex valued FFT's were used to convert a real valued Toeplitz matrix into a complex valued Cauchy type matrix. The algorithms were not able to exploit any symmetry in the Toeplitz or quasi-Toeplitz matrix to reduce the computational complexity. <p> The algorithms were not able to exploit any symmetry in the Toeplitz or quasi-Toeplitz matrix to reduce the computational complexity. In this section we present a modification to the algorithms in <ref> [15, 21] </ref> to factor a symmetric semidefinite quasi-Toeplitz matrix using only real arithmetic and exploiting the symmetric property of the matrix. This algorithm can be used to obtain a rank revealing factorization of the matrix T T T where T is a rank deficient Toeplitz matrix. <p> It was shown in <ref> [15, 21] </ref> that if (126) is converted to (128) using the discrete Fourier transform, then Gaussian elimination with partial pivoting can be applied to obtain a factorization.
Reference: [22] <author> T. Kailath, S.-Y. Kung, and M. Morf, </author> <title> Displacement ranks of matrices and linear equations, </title> <journal> Journal of Mathematical Analysis and Applications, </journal> <volume> 68 (1979), </volume> <pages> pp. 395-407. </pages>
Reference-contexts: Interestingly, the recursions proposed in this algorithm provide a fast factorization of matrices with displacement rank 2. It is well known that Toeplitz matrices have a displacement rank of 2 <ref> [22] </ref>. More generally block Toeplitz matrices with a block size of m have a displacement rank of 2m. In this paper we discuss several high performance variants of the classical Schur algorithm algorithms to factor symmetric block Toeplitz matrices. <p> Let Z be a block right shift matrix. The Schur algorithm is based on the fact that the displacement of a block Toeplitz matrix T , defined as T Z T T Z, has a rank of at most 2m <ref> [22] </ref>. <p> Let T j = L 1 1 ^ T j . It is easy to see that T 1 = L T 1 . We now define two matrices G 1 (T ) and G 2 (T ) as follows <ref> [22] </ref>, [5]: G 1 (T ) = B B B B T 1 T 2 T 3 : : : T p . . . . . . . . . . . . . . .
Reference: [23] <author> T. Kailath and A. Sayed, </author> <title> Fast algorithms for generalized displacement structures, </title> <booktitle> in Recent advances in mathematical theory of systems, </booktitle> <editor> H. Kimura and S. Kodoma, eds., </editor> <year> 1992, </year> <pages> pp. 27-32. </pages> <note> Proc. MTNS-91. </note>
Reference-contexts: The rank 2m factorization of the displacement of the Schur complement provides the generator for the subsequent steps of the Schur algorithm. This part is related to the work of <ref> [23] </ref>, but is not contained in it. Define X = T 1 12 T 1 " I ; (77) then it follows that U T T U = T 11 # 12 T 1 where T sc is the Schur complement of T with respect to T 11 .
Reference: [24] <author> D. Pal and T. Kailath, </author> <title> Fast triangular factorization and inversion of Hermitian, Toeplitz related matrices with arbitrary rank profile, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 14 (1993), </volume> <pages> pp. 1016-1042. </pages>
Reference-contexts: The look-ahead Schur algorithm proposed in [18] is based on orthogonal polynomials and does not extend to block Toeplitz matrices. Look-ahead Schur algorithms for Toeplitz systems with exactly singular principal minors have been proposed in [10], <ref> [24] </ref>. 19 In Sections 3.3.1 and 3.3.2 we discuss two look-ahead Schur algorithms that are based entirely on matrix operations and hence extend easily to block Toeplitz matrices. 3.3.1 Algorithm 1 Consider a mp fi mp block Toeplitz or quasi block Toeplitz matrix T with a block size of m fi
Reference: [25] <author> B. Parlett, </author> <title> Reduction to tridiagonal form and minimal realizations, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 13 (1992), </volume> <pages> pp. 567-593. </pages>
Reference-contexts: This technique may also be used when the principal minors are badly conditioned. Look-ahead techniques were originally proposed to improve the numerical robustness of the Lanczos algorithm applied to an indefinite matrix T in the presence of singular and nearly singular leading principal minors in T <ref> [25] </ref>. Most of the techniques related to these developments are based on the theory of orthogonal polynomials [17] or equivalently on that of T conjugate directions. <p> The rows of L 1 are the conjugate directions or also contain the coefficients of the orthogonal polynomials. Look-ahead techniques have been proposed and yielded algorithms with satisfactory numerical behavior, [3], [4],[12], <ref> [25] </ref>, [18]. The look-ahead Schur algorithm proposed in [18] is based on orthogonal polynomials and does not extend to block Toeplitz matrices.
Reference: [26] <author> C. M. Rader and A. O. Steinhardt, </author> <title> Hyperbolic Householder transformations, </title> <journal> IEEE Trans. Acoust. Speech Signal Process., </journal> <volume> 34 (1986), </volume> <pages> pp. 1589-1602. </pages>
Reference-contexts: The transformation matrix U which satisfies the property U T W mp U = W mp , is called a hyperbolic Householder transformation <ref> [26] </ref>. The basic properties of hyperbolic Householder reflectors are discussed in Section 2.2. <p> A detailed discussion of the Schur algorithm for indefinite Toeplitz matrices is presented in Section 3. 2.2 Hyperbolic Householder transformations In their paper [8], Cybenko and Berry use hyperbolic Householder transformations <ref> [26] </ref> to reduce the generator matrix G of a scalar Toeplitz matrix to an upper triangular matrix. We extend their idea to block hyperbolic Householder transformations (required in the block Schur algorithm), using representations very similar to those proposed in [2] and [29].
Reference: [27] <author> C. M. Rader and A. O. Steinhardt, </author> <title> Hyperbolic Householder transforms, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 9 (1988), </volume> <pages> pp. 269-290. </pages>
Reference-contexts: Let x be a column vector such that x T W x 6= 0. A hyperbolic Householder matrix is defined as follows: U x = W x T W x One easily checks [8] and <ref> [27] </ref> that U x is W -unitary, i.e., U T x W U x = W . These transformations can be used to map one vector to another as long as they have the same hyperbolic norm, i.e., if a T W a = b T W b.
Reference: [28] <author> A. Sayed and T. Kailath, </author> <title> A look-ahead block Schur algorithm for Toeplitz-like matrices, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <month> 16 </month> <year> (1995). </year>
Reference-contexts: A similar algorithm has been developed independently by Sayed and Kailath <ref> [28] </ref>. Let T be a general symmetric, block Toeplitz matrix of dimension N fi N and block size m fi m, i.e. row of T be given as T = 6 6 6 T 0 T 1 T p1 1 T 0 . . . . . .
Reference: [29] <author> R. Schreiber and C. V. Loan, </author> <title> A storage-efficient WY representation for products of Householder transformations, </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 10 (1989), </volume> <pages> pp. 53-57. </pages>
Reference-contexts: We extend their idea to block hyperbolic Householder transformations (required in the block Schur algorithm), using representations very similar to those proposed in [2] and <ref> [29] </ref>. Let W be a diagonal matrix whose entries are either +1 or 1. <p> This 5 allows us to use level-3 BLAS primitives rather than level-2 BLAS operations if we applied the transformations sequentially. Storage efficient ways to block regular Householder transformations are derived in [2] and <ref> [29] </ref>. We extend these methods to hyperbolic Householder transforms. Suppose U (r) = U r U r1 : : : U 2 U 1 is a product of r n fi n hyperbolic Householder matrices. <p> The matrix U can be written in two forms corresponding to the V Y form and the Y T Y T form derived in [2] and <ref> [29] </ref>. The two forms of the V Y representation differ in the types of primitives they use. Lemma 1 Suppose U (k) = W k +V k Y T k is a product of k nfin hyperbolic Householder matrices, where V k and Y k are n fi k matrices.
Reference: [30] <author> I. </author> <title> Schur, Uber potenzreihen die im Inneren des Einheitskreises beschrankt sind, </title> <journal> Journal fur die Reine und Angewandte Mathematik, </journal> <volume> 147 (1917), </volume> <pages> pp. 205-232. </pages>
Reference-contexts: In addition, the two approaches differ in the kinds of computational primitives used during the factorization. In <ref> [30] </ref> Schur derived a fast recursive algorithm to check if a power series is analytic and bounded in the unit disc. Interestingly, the recursions proposed in this algorithm provide a fast factorization of matrices with displacement rank 2.
Reference: [31] <author> J. H. Wilkinson, </author> <title> The Algebraic Eigenvalue Problem, </title> <publisher> Oxford University Press, Oxford, </publisher> <address> England, </address> <year> 1965. </year>
Reference-contexts: and set r 1 = T x 1 + b. for i = 1; ::: Solve LDL T x i = r i if kx i k &lt; tol kx i k then stop else x i+1 = x i + x i endif endfor From the error analysis of <ref> [31] </ref> we know that the computed quantities x i ; x i and r i , satisfy the following identities r i = T x i + b + ffir i = r i + ffir i with kffir i k * i kT k kx i k (50) (LDL T
References-found: 30

