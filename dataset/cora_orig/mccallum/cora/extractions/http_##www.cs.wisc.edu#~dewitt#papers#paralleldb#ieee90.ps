URL: http://www.cs.wisc.edu/~dewitt/papers/paralleldb/ieee90.ps
Refering-URL: http://www.cs.wisc.edu/~dewitt/paralleldb.html
Root-URL: 
Title: The Gamma Database Machine Project  
Author: David J. DeWitt Shahram Ghandeharizadeh Donovan Schneider Allan Bricker Hui-I Hsiao Rick Rasmussen 
Note: This research was partially supported by the Defense Advanced Research Projects Agency under contract N00039-86-C-0578, by the National Science Foundation under grant DCR-8512862, by a DARPA/NASA sponsored Graduate Research Assistantship in Parallel Processing, and by research grants from Intel Scientific Computers, Tandem Computers, and Digital Equipment Corporation.  
Address: Wisconsin  
Affiliation: Computer Sciences Department University of  
Abstract-found: 0
Intro-found: 1
Reference: [AGRA85] <author> Agrawal, R., and D.J. DeWitt, </author> <title> "Recovery Architectures for Multiprocessor Database Machines," </title> <booktitle> Proceedings of the 1985 SIGMOD Conference, </booktitle> <address> Austin, TX, </address> <month> May, </month> <year> 1985. </year>
Reference-contexts: If M is the number of log processors being used, query processor i will direct its log records to the (i mod M) log processor <ref> [AGRA85] </ref>. Because this algorithm selects the log processor statically and a query processor always sends its log records to the same log processor, the recovery process at a query processing node can easily determine where to request the log records for processing a transaction abort.
Reference: [ASTR76] <author> Astrahan, M. M., et. al., </author> <title> "System R: A Relational Approach to Database Management," </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol. 1, No. 2, </volume> <month> June, </month> <year> 1976. </year>
Reference-contexts: One indexed attribute may be designated as a clustering attribute for the file. The scan mechanism is similar to that provided by System R's RSS <ref> [ASTR76] </ref> except that the predicates are compiled by the query optimizer into 386 machine language to maximize performance. 14 4. Query Processing Algorithms 4.1.
Reference: [BITT83] <author> Bitton D., D.J. DeWitt, and C. Turbyfill, </author> <title> "Benchmarking Database Systems A Systematic Approach," </title> <booktitle> Proceedings of the 1983 Very Large Database Conference, </booktitle> <month> October, </month> <year> 1983. </year>
Reference-contexts: While DIRECT demonstrated that parallelism could be successfully applied to processing database operations, it had a number of serious design deficiencies that made scaling of the architecture to 100s of processors impossible; primarily the use of shared memory and centralized control for the execution of its parallel algorithms <ref> [BITT83] </ref>. As a solution to the problems encountered with DIRECT, Gamma employs what appear today to be relatively straightforward solutions. <p> In [HSIA90], we describe how all combinations of query types, access methods, and partitioning 21 mechanisms can be handled. 6. Performance Studies 6.1. Introduction and Experiment Overview To evaluate the performance of the hypercube version of Gamma three different metrics were used. First, the set of Wisconsin <ref> [BITT83] </ref> benchmark queries were run on a 30 processor configuration using three different sizes of relations: 100,000, 1 million, and 10 million tuples. While absolute performance is one measure of a database system, speedup and scaleup are also useful metrics for multiprocessor database machines [ENGL89]. <p> The benchmark relations used for the experiments were based on the standard Wisconsin Benchmark relations <ref> [BITT83] </ref>. Each relation consists of tuples that are 208 bytes wide. We constructed 100,000, 1 million, and 10 million tuple versions of the benchmark relations. Two copies of each relation were created and loaded. Except where noted otherwise, tuples were declustered by hash partitioning on the Unique1 attribute. <p> In the first case, the input relations were declustered by hashing on the join attribute. In the second case, the input relations were declustered using a different attribute. The hybrid join algorithm was used for all queries. Performance Relative to Relation Size The first join query <ref> [BITT83] </ref>, joinABprime, is a simple join of two relations: A and Bprime. The A relation contains either 100,000, 1 million, or 10 million tuples. The Bprime relation contains, respectively, 10,000, 100,000, or 1 million tuples.
Reference: [BLAS79] <author> Blasgen, M. W., Gray, J., Mitoma, M., and T. Price, </author> <title> "The Convoy Phenomenon," </title> <journal> Operating System Review, </journal> <volume> Vol. 13, No. 2, </volume> <month> April, </month> <year> 1979. </year>
Reference-contexts: Operating and Storage System Gamma is built on top of an operating system designed specifically for supporting database management systems. NOSE provides multiple, lightweight processes with shared memory. A non-preemptive scheduling policy is used to help prevent convoys <ref> [BLAS79] </ref> from occurring. NOSE provides communications between NOSE processes using the reliable message passing hardware of the Intel iPSC/2 hypercube. File services in NOSE are based on the Wisconsin Storage System (WiSS) [CHOU85]. Critical sections of WiSS are protected using the semaphore mechanism provided by NOSE.
Reference: [BORR81] <author> Borr, A., </author> <title> "Transaction Monitoring in Encompass [TM]: </title> <booktitle> Reliable Distributed Transaction Processing," Proceedings of VLDB, </booktitle> <year> 1981. </year> <month> 34 </month>
Reference-contexts: The ARIES algorithms are also used as the basis for check-pointing and restart recovery. 5.3. Failure Management To help insure availability of the system in the event of processor and/or disk failures, Gamma employs a new availability technique termed chained declustering [HSIA90]. Like Tandem's mirrored disk mechanism <ref> [BORR81] </ref> and Teradata's interleaved declustering mechanism [TERA85, COPE89], chained declustering employs both a primary and backup copy of each relation. All three systems can sustain the failure of a single processor or disk without suffering any loss in data availability.
Reference: [BRAT84] <author> Bratbergsengen, Kjell, </author> <title> "Hashing Methods and Relational Algebra Operations", </title> <booktitle> Proceedings of the 1984 Very Large Database Conference, </booktitle> <month> August, </month> <year> 1984. </year>
Reference-contexts: This mechanism enables the processing of one page to be overlapped with the I/O for the subsequent page. 4.2. Join Operator The multiprocessor join algorithms provided by Gamma are based on concept of partitioning the two relations to be joined into disjoint subsets called buckets <ref> [GOOD81, KITS83, BRAT84] </ref>. by applying a hash function to the join attribute of each tuple. The partitioned buckets represent disjoint subsets of the original relations and have the important characteristic that all tuples with the same join attribute value are in the same bucket.
Reference: [CHOU85] <author> Chou, H-T, DeWitt, D. J., Katz, R., and T. Klug, </author> <title> "Design and Implementation of the Wisconsin Storage System (WiSS)", </title> <journal> Software Practices and Experience, </journal> <volume> Vol. 15, No. 10, </volume> <month> October, </month> <year> 1985. </year>
Reference-contexts: A non-preemptive scheduling policy is used to help prevent convoys [BLAS79] from occurring. NOSE provides communications between NOSE processes using the reliable message passing hardware of the Intel iPSC/2 hypercube. File services in NOSE are based on the Wisconsin Storage System (WiSS) <ref> [CHOU85] </ref>. Critical sections of WiSS are protected using the semaphore mechanism provided by NOSE. The file services provided by WiSS include structured sequential files, byte-stream files as in UNIX, B + indices, long data items, a sort utility, and a scan mechanism. A sequential file is a sequence of records.
Reference: [COPE88] <author> Copeland, G., Alexander, W., Boughter, E., and T. Keller, </author> <title> "Data Placement in Bubba," </title> <booktitle> Proceedings of the ACM-SIGMOD International Conference on Management of Data, </booktitle> <address> Chicago, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: In the spring of 1989, Gamma was ported to a 32 processor Intel iPSC/2 hypercube and the VAX-based prototype was retired. Gamma is similar to a number of other active parallel database machine efforts. In addition to Teradata [TERA85], Bubba <ref> [COPE88] </ref> and Tandem [TAND88] also utilize a shared-nothing architecture and employ the concept of horizontal partitioning. <p> There are a number of reasons why the shared-nothing approach has become the architecture of choice. First, there is nothing to prevent the architecture from scaling to 1000s of processors unlike shared-memory machines for which scaling beyond 30-40 processors may be impossible. Second, as demonstrated in <ref> [DEWI88, COPE88, TAND88] </ref>, by associating a small number of ... N 2 1 INTERCONNECTION NETWORK 3 disks with each processor and distributing the tuples of each relation across the disk drives, it is possible to achieve very high aggregate I/O bandwidths without using custom disk controllers [KIM86, PATT88]. <p> In retrospect, we made a serious mistake in choosing to decluster all relations across all nodes with disks. A much better approach, as proposed in <ref> [COPE88] </ref>, is to use the "heat" of a relation to determine the degree to which the relation is declustered. Unfortunately, to add such a capability to the Gamma software at this point in time would require a fairly major effort one we are not likely to undertake. 3.2.
Reference: [COPE89] <author> Copeland, G. and T. Keller, </author> <title> "A Comparison of High-Availability Media Recovery Techniques," </title> <booktitle> Proceedings of the ACM-SIGMOD International Conference on Management of Data, </booktitle> <address> Portland, Oregon June 1989. </address>
Reference-contexts: Failure Management To help insure availability of the system in the event of processor and/or disk failures, Gamma employs a new availability technique termed chained declustering [HSIA90]. Like Tandem's mirrored disk mechanism [BORR81] and Teradata's interleaved declustering mechanism <ref> [TERA85, COPE89] </ref>, chained declustering employs both a primary and backup copy of each relation. All three systems can sustain the failure of a single processor or disk without suffering any loss in data availability. <p> 1 2 3 4 5 6 7 iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii Primary Copy R0 R1 R2 R3 R4 R5 R6 R7 iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii Backup Copy r7 r0 r1 r2 r3 r4 r5 r6 iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiic c c c c Chained Declustering (Relation Cluster Size = 8) The difference between the chained and interleaved declustering mechanisms <ref> [TERA85, COPE89] </ref> is illustrated by Figure 10. In Figure 10, the fragments from the primary copy of R are declustered across all 8 disk drives by hashing on a "key" attribute. With the interleaved declustering mechanism the set of disks are divided into units of size N called clusters.
Reference: [DEWI79] <author> DeWitt, </author> <title> D.J., "DIRECT A Multiprocessor Organization for Supporting Relational Database Management Systems," </title> <journal> IEEE Transactions on Computers, </journal> <month> June, </month> <year> 1979. </year>
Reference-contexts: 1. Introduction For the last 5 years, the Gamma database machine project has focused on issues associated with the design and implementation of highly parallel database machines. In a number of ways, the design of Gamma is based on what we learned from our earlier database machine DIRECT <ref> [DEWI79] </ref>. While DIRECT demonstrated that parallelism could be successfully applied to processing database operations, it had a number of serious design deficiencies that made scaling of the architecture to 100s of processors impossible; primarily the use of shared memory and centralized control for the execution of its parallel algorithms [BITT83].
Reference: [DEWI84a] <author> DeWitt, D. J., Katz, R., Olken, F., Shapiro, D., Stonebraker, M. and D. Wood, </author> <title> "Implementation Techniques for Main Memory Database Systems", </title> <booktitle> Proceedings of the 1984 SIGMOD Conference, </booktitle> <address> Boston, MA, </address> <month> June, </month> <year> 1984. </year>
Reference-contexts: Gamma, XPRS [STON88], and Volcano [GRAE89] each utilize parallel versions of the Hybrid join algorithm <ref> [DEWI84a] </ref>. The remainder of this paper is organized as follows. In Section 2 we describe the hardware used by each of the Gamma prototypes and our experiences with each. Section 3 discusses the organization of the Gamma software and describes how multioperator queries are controlled.
Reference: [DEWI84b] <author> DeWitt, D. J., Finkel, R., and Solomon, M., </author> <title> "The Crystal Multicomputer: Design and Implementation Experience," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-13, No. 8, </volume> <month> August, </month> <year> 1987. </year>
Reference-contexts: After the design of the Gamma software was completed in the fall of 1984, work began on the first prototype which was operational by the fall of 1985. This version of Gamma was implemented on top of an existing multi-computer consisting of 20 VAX 11/750 processors <ref> [DEWI84b] </ref>. In the period of 1986-1988, the prototype was enhanced through the addition of a number of new operators (e.g. aggregate and update operators), new parallel join methods (Hybrid, Grace, and Sort-Merge [SCHN89a]), and a complete concurrency control mechanism.
Reference: [DEWI85] <author> DeWitt, D., and R. Gerber, </author> <title> "Multiprocessor Hash-Based Join Algorithms," </title> <booktitle> Proceedings of the 1985 VLDB Conference, </booktitle> <address> Stockholm, Sweden, </address> <month> August, </month> <year> 1985. </year>
Reference: [DEWI86] <author> DeWitt, D., Gerber, R., Graefe, G., Heytens, M., Kumar, K., and M. Muralikrishna, </author> <title> "GAMMA-A High Performance Dataflow Database Machine," </title> <booktitle> Proceedings of the 1986 VLDB Conference, </booktitle> <address> Japan, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: In addition, we also conducted a number of performance studies of the system during this period <ref> [DEWI86, DEWI88, GHAN89, GHAN90] </ref>. In the spring of 1989, Gamma was ported to a 32 processor Intel iPSC/2 hypercube and the VAX-based prototype was retired. Gamma is similar to a number of other active parallel database machine efforts. <p> SPLIT TABLE STREAM OF TUPLES CONTROL PACKET OF TUPLES PROCESS EXECUTING OPERATOR OUTGOING STREAMS The split table defines a mapping of values to a set of destination processes. Gamma uses three different types of split tables depending on the type of operation being performed <ref> [DEWI86] </ref>. As an example of one form of split table, consider the use of the split table shown in Figure 4 in conjunction with the execution of a join operation using 4 processors.
Reference: [DEWI88] <author> DeWitt, D., Ghandeharizadeh, S., and D. Schneider, </author> <title> "A Performance Analysis of the Gamma Database Machine," </title> <booktitle> Proceedings of the ACM-SIGMOD International Conference on Management of Data, </booktitle> <address> Chicago, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: In addition, we also conducted a number of performance studies of the system during this period <ref> [DEWI86, DEWI88, GHAN89, GHAN90] </ref>. In the spring of 1989, Gamma was ported to a 32 processor Intel iPSC/2 hypercube and the VAX-based prototype was retired. Gamma is similar to a number of other active parallel database machine efforts. <p> There are a number of reasons why the shared-nothing approach has become the architecture of choice. First, there is nothing to prevent the architecture from scaling to 1000s of processors unlike shared-memory machines for which scaling beyond 30-40 processors may be impossible. Second, as demonstrated in <ref> [DEWI88, COPE88, TAND88] </ref>, by associating a small number of ... N 2 1 INTERCONNECTION NETWORK 3 disks with each processor and distributing the tuples of each relation across the disk drives, it is possible to achieve very high aggregate I/O bandwidths without using custom disk controllers [KIM86, PATT88]. <p> The second problem we encountered was that the network interface and the Unibus on the 11/750 were both bottlenecks <ref> [GERB87, DEWI88] </ref>. While the bandwidth of the token ring itself was 80 megabits/second, the Unibus on the 11/750 (to which the network interface was attached) has a bandwidth of only 4 megabits/second. <p> When processing a join query without a selection predicate on either of the input relations, the Unibus became a bottleneck because the transfer rate of pages from the disk was higher than the speed of the Unibus <ref> [DEWI88] </ref>. The network interface was a bottleneck because it could only buffer two incoming packets at a time. Until one packet was transferred into the VAX's memory, other incoming packets were rejected and had to be retransmitted by the communications protocol.
Reference: [ENGL89] <author> Englert, S, J. Gray, T. Kocher, and P. Shah, </author> <title> "A Benchmark of NonStop SQL Release 2 Demonstrating Near-Linear Speedup and Scaleup on Large Databases," Tandem Computers, </title> <type> Technical Report 89.4, Tandem Part No. 27469, </type> <month> May </month> <year> 1989. </year> <title> [ENSC85] "Enscribe Programming Manual," Tandem Part# 82583-A00, </title> <publisher> Tandem Computers Inc., </publisher> <month> March </month> <year> 1985. </year>
Reference-contexts: First, the set of Wisconsin [BITT83] benchmark queries were run on a 30 processor configuration using three different sizes of relations: 100,000, 1 million, and 10 million tuples. While absolute performance is one measure of a database system, speedup and scaleup are also useful metrics for multiprocessor database machines <ref> [ENGL89] </ref>. Speedup is an interesting metric because it indicates whether additional processors and disks results in a corresponding decrease in the response time for a query. <p> Scaleup is a valuable metric as it indicates whether a constant response time can be maintained as the workload is increased by adding a proportional number of processors and disks. <ref> [ENGL89] </ref> describes a similar set of tests on Release 2 of Tandem's NonStop SQL system. The benchmark relations used for the experiments were based on the standard Wisconsin Benchmark relations [BITT83]. Each relation consists of tuples that are 208 bytes wide.
Reference: [GERB87] <author> Gerber, R. and D. DeWitt, </author> <title> "The Impact of Hardware and Software Alternatives on the Performance of the Gamma Database Machine", </title> <type> Computer Sciences Technical Report #708, </type> <institution> University of Wisconsin-Madison, </institution> <month> July, </month> <year> 1987. </year>
Reference-contexts: The second problem we encountered was that the network interface and the Unibus on the 11/750 were both bottlenecks <ref> [GERB87, DEWI88] </ref>. While the bandwidth of the token ring itself was 80 megabits/second, the Unibus on the 11/750 (to which the network interface was attached) has a bandwidth of only 4 megabits/second. <p> Since a single process is used to initiate the execution of a query, as the number of processors employed is increased, the load on this process is increased proportionally. Switching to a tree-based, query initiation scheme <ref> [GERB87] </ref> would distribute this overhead among all the processors. 26 RESPONSE TIME (SECONDS) PROCESSORS WITH DISKS 80 60 40 20 0 10% clustered index selection 1% clustered index selection 10% nonindexed selection 1% nonindexed selection 1% non-clustered index selection 6.3.
Reference: [GHAN89] <author> Ghandeharizadeh, S. and D. J. DeWitt, </author> <title> "A Multiuser Performance Evaluation of Selection Queries in a Single Processor Database Machine", </title> <month> July </month> <year> 1989, </year> <note> submitted for publication. </note>
Reference-contexts: In addition, we also conducted a number of performance studies of the system during this period <ref> [DEWI86, DEWI88, GHAN89, GHAN90] </ref>. In the spring of 1989, Gamma was ported to a 32 processor Intel iPSC/2 hypercube and the VAX-based prototype was retired. Gamma is similar to a number of other active parallel database machine efforts.
Reference: [GHAN90] <author> Ghandeharizadeh, S., and D.J. DeWitt, </author> <title> Performance Analysis of Alternative Declustering Strategies, </title> <booktitle> Proceedings of the 6th International Conference on Data Engineering, </booktitle> <address> Los Angeles, CA, </address> <month> February </month> <year> 1990. </year>
Reference-contexts: In addition, we also conducted a number of performance studies of the system during this period <ref> [DEWI86, DEWI88, GHAN89, GHAN90] </ref>. In the spring of 1989, Gamma was ported to a 32 processor Intel iPSC/2 hypercube and the VAX-based prototype was retired. Gamma is similar to a number of other active parallel database machine efforts.
Reference: [GOOD81] <author> Goodman, J. R., </author> <title> "An Investigation of Multiprocessor Structures and Algorithms for Database Management", </title> <institution> University of California at Berkeley, </institution> <type> Technical Report UCB/ERL, </type> <institution> M81/33, </institution> <month> May, </month> <year> 1981. </year>
Reference-contexts: This mechanism enables the processing of one page to be overlapped with the I/O for the subsequent page. 4.2. Join Operator The multiprocessor join algorithms provided by Gamma are based on concept of partitioning the two relations to be joined into disjoint subsets called buckets <ref> [GOOD81, KITS83, BRAT84] </ref>. by applying a hash function to the join attribute of each tuple. The partitioned buckets represent disjoint subsets of the original relations and have the important characteristic that all tuples with the same join attribute value are in the same bucket.
Reference: [GRAE89] <author> Graefe, G., Volcano: </author> <title> A Compact, Extensible, Dynamic, and Parallel Dataflow Query Evaluation System, </title> <type> Working Paper, </type> <institution> Oregon Graduate Center, </institution> <address> Portland, OR, </address> <month> February </month> <year> 1989. </year>
Reference-contexts: While Teradata and Tandem also rely on hashing to decentralize the execution of their parallel algorithms, both systems tend to rely on relatively conventional join algorithms such as sort-merge for 2 processing the fragments of the relation at each site. Gamma, XPRS [STON88], and Volcano <ref> [GRAE89] </ref> each utilize parallel versions of the Hybrid join algorithm [DEWI84a]. The remainder of this paper is organized as follows. In Section 2 we describe the hardware used by each of the Gamma prototypes and our experiences with each.
Reference: [GRAY78] <author> Gray, J., </author> <title> "Notes on Database Operating Systems", </title> <type> RJ 2188, </type> <institution> IBM Research Laboratory, </institution> <address> San Jose, Cali-fornia, </address> <month> February </month> <year> 1978. </year> <month> 35 </month>
Reference-contexts: While the locking mechanisms are fully operational, the recovery system is currently being implemented. We expect to begin the implementation of the failure management mechanism in early 1990. 16 5.1. Concurrency Control in Gamma Concurrency control in Gamma is based on two-phase locking <ref> [GRAY78] </ref>. Currently, two lock granularities, file, and page, and five lock modes, S, X, IS, IX, and SIX are provided. Each site in Gamma has its own local lock manager and deadlock detector. The lock manager maintains a lock table and a transaction wait-for-graph. <p> Query processing nodes save this information in a local variable, termed the Flushed LSN. The buffer managers at the query processing nodes observe the WAL protocol <ref> [GRAY78] </ref>. When a dirty page needs to be forced to disk, the buffer manager first compares the page's LSN with the local value of Flushed LSN. If the page LSN of a page is smaller or equal to the Flushed LSN, that page can be safely written to disk.
Reference: [GRAY88] <author> Gray, J., H. Sammer, and S. Whitford, </author> <title> "Shortest Seek vs Shortest Service Time Scheduling of Mirrored Disks," Tandem Computers, </title> <month> December </month> <year> 1988. </year>
Reference-contexts: With one processor, the range of the each random seek is approximately 800 cylinders while with 30 processors the range of the seek is limited to about 27 cylinders. Since the seek time is proportional to the square root of the distance traveled by the disk head <ref> [GRAY88] </ref>, reducing the size of the relation fragment on each disk significantly reduces the amount of time that the query spends seeking. A similar effect also happens with the 10% clustered index selection.
Reference: [HSIA90] <author> Hsiao, H. I. and D. J. DeWitt, </author> <title> "Chained Declustering: A New Availability Strategy for Multiprocessor Database Machines", </title> <booktitle> Proceedings of the 6th International Conference on Data Engineering, </booktitle> <address> Los Angeles, CA, </address> <month> February </month> <year> 1990. </year>
Reference-contexts: The ARIES algorithms are also used as the basis for check-pointing and restart recovery. 5.3. Failure Management To help insure availability of the system in the event of processor and/or disk failures, Gamma employs a new availability technique termed chained declustering <ref> [HSIA90] </ref>. Like Tandem's mirrored disk mechanism [BORR81] and Teradata's interleaved declustering mechanism [TERA85, COPE89], chained declustering employs both a primary and backup copy of each relation. All three systems can sustain the failure of a single processor or disk without suffering any loss in data availability. In [HSIA90], we show that <p> termed chained declustering <ref> [HSIA90] </ref>. Like Tandem's mirrored disk mechanism [BORR81] and Teradata's interleaved declustering mechanism [TERA85, COPE89], chained declustering employs both a primary and backup copy of each relation. All three systems can sustain the failure of a single processor or disk without suffering any loss in data availability. In [HSIA90], we show that chained declustering provides a higher degree of availability than interleaved declustering and, in the event of a processor or disk failure, does a better job of distributing the workload of the broken node. <p> In reality, queries cannot simply access an arbitrary fraction of a data fragment, especially given the variety of partitioning and index mechanisms provided by the Gamma software. In <ref> [HSIA90] </ref>, we describe how all combinations of query types, access methods, and partitioning 21 mechanisms can be handled. 6. Performance Studies 6.1. Introduction and Experiment Overview To evaluate the performance of the hypercube version of Gamma three different metrics were used.
Reference: [JARK84] <author> Jarke, M. and J. Koch, </author> <title> "Query Optimization in Database System," </title> <journal> ACM Computing Surveys, </journal> <volume> Vol. 16, No. 2, </volume> <month> June, </month> <year> 1984. </year>
Reference-contexts: A mechanism for passing parameters from the C program to the compiled query plans at run time is also provided. Query Execution Gamma uses traditional relational techniques for query parsing, optimization <ref> [SELI79, JARK84] </ref>, and code generation. The optimization process is somewhat simplified as Gamma only employs hash-based algorithms for joins and other complex operations. Queries are compiled into a left-deep tree of operators. At execution time, each operator is executed by one or more operator processes at each participating site.
Reference: [KIM86] <author> Kim, M., </author> <title> "Synchronized Disk Interleaving," </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. C-35, No. 11, </volume> <month> November </month> <year> 1986. </year>
Reference-contexts: N 2 1 INTERCONNECTION NETWORK 3 disks with each processor and distributing the tuples of each relation across the disk drives, it is possible to achieve very high aggregate I/O bandwidths without using custom disk controllers <ref> [KIM86, PATT88] </ref>. Furthermore, by employing off-the-shelf mass storage technology one can employ the latest technology in small 3 1/2" disk drives with embedded disk controllers. Another advantage of the shared nothing approach is that there is no longer any need to "roll your own" hardware.
Reference: [KITS83] <author> Kitsuregawa, M., Tanaka, H., and T. Moto-oka, </author> <title> "Application of Hash to Data Base Machine and Its Architecture", </title> <journal> New Generation Computing, </journal> <volume> Vol. 1, No. 1, </volume> <year> 1983. </year>
Reference-contexts: This mechanism enables the processing of one page to be overlapped with the I/O for the subsequent page. 4.2. Join Operator The multiprocessor join algorithms provided by Gamma are based on concept of partitioning the two relations to be joined into disjoint subsets called buckets <ref> [GOOD81, KITS83, BRAT84] </ref>. by applying a hash function to the join attribute of each tuple. The partitioned buckets represent disjoint subsets of the original relations and have the important characteristic that all tuples with the same join attribute value are in the same bucket. <p> The partitioned buckets represent disjoint subsets of the original relations and have the important characteristic that all tuples with the same join attribute value are in the same bucket. We have implemented parallel versions of four join algorithms on the Gamma prototype: sort-merge, Grace <ref> [KITS83] </ref>, Simple [DEWI84], and Hybrid [DEWI84]. While all four algorithms employ this concept of hash-based partitioning, the actual join computation depends on the algorithm. The parallel hybrid join algorithm is described in the following section.
Reference: [LIVN87] <author> Livny, M., S. Khoshafian, and H. Boral, </author> <title> Multi-Disk Management Algorithms, </title> <booktitle> Proceedings of the 1987 SIGMETRICS Conference, </booktitle> <address> Banff, Alberta, Canada, </address> <month> May, </month> <year> 1987. </year>
Reference-contexts: Finally, to make the best of the limited I/O bandwidth provided by the current generation of disk drives, Gamma employs the concept of horizontal partitioning [RIES78] (also termed declustering <ref> [LIVN87] </ref>) to distribute the tuples of a relation among multiple disk drives. This design enables large relations to be processed by multiple processors concurrently without incurring any communications overhead. <p> Unlike VSAM [WAGN73] and the Tandem file system [ENSC85], Gamma does not require the clustered index for a relation to be constructed on hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 3 Declustering is another term for horizontal partitioning that was coined by the Bubba project <ref> [LIVN87] </ref>. 7 the partitioning attribute. As a query is being optimized, the partitioning information for each source relation in the query is incorporated into the query plan produced by the query optimizer.
Reference: [MOHA89] <author> Mohan, C., D. Haderle, B. Linsay, H. Pirahesh, and P. Schwarz, </author> <title> "ARIES: A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging", </title> <type> RJ 6649, </type> <institution> IBM Almaden Research Center, </institution> <address> San Jose, California, </address> <month> January </month> <year> 1989. </year>
Reference-contexts: As the log records are received, the recovery process undoes the log records in reverse chronological order using the ARIES undo algorithm <ref> [MOHA89] </ref>. The ARIES algorithms are also used as the basis for check-pointing and restart recovery. 5.3. Failure Management To help insure availability of the system in the event of processor and/or disk failures, Gamma employs a new availability technique termed chained declustering [HSIA90].
Reference: [PATT88] <author> Patterson, D. A., G. Gibson, and R. H. Katz, </author> <title> "A Case for Redundant Arrays of Inexpensive Disks (RAID)," </title> <booktitle> Proceedings of the ACM-SIGMOD International Conference on Management of Data, </booktitle> <address> Chicago, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: N 2 1 INTERCONNECTION NETWORK 3 disks with each processor and distributing the tuples of each relation across the disk drives, it is possible to achieve very high aggregate I/O bandwidths without using custom disk controllers <ref> [KIM86, PATT88] </ref>. Furthermore, by employing off-the-shelf mass storage technology one can employ the latest technology in small 3 1/2" disk drives with embedded disk controllers. Another advantage of the shared nothing approach is that there is no longer any need to "roll your own" hardware.
Reference: [PROT85] <author> Proteon Associates, </author> <title> Operation and Maintenance Manual for the ProNet Model p8000, </title> <address> Waltham, Mass, </address> <year> 1985. </year>
Reference-contexts: Recently, both Intel and Ncube have added mass storage to their hypercube-based multiprocessor products. 2.2. Gamma Version 1.0 The initial version of Gamma consisted of 17 VAX 11/750 processors, each with two megabytes of memory. An 80 megabit/second token ring <ref> [PROT85] </ref> was used to connect the processors to each other and to another VAX running Unix. This processor acted as the host machine for Gamma. Attached to eight of the processors were 333 megabyte Fujitsu disk drives that were used for storing the database.
Reference: [RIES78] <author> Ries, D. and R. Epstein, </author> <title> "Evaluation of Distribution Criteria for Distributed Database Systems," </title> <type> UCB/ERL Technical Report M78/22, </type> <institution> UC Berkeley, </institution> <month> May, </month> <year> 1978. </year>
Reference-contexts: Unlike the algorithms employed by DIRECT, these algorithms require no centralized control and can thus, like the hardware architecture, be scaled almost indefinitely. Finally, to make the best of the limited I/O bandwidth provided by the current generation of disk drives, Gamma employs the concept of horizontal partitioning <ref> [RIES78] </ref> (also termed declustering [LIVN87]) to distribute the tuples of a relation among multiple disk drives. This design enables large relations to be processed by multiple processors concurrently without incurring any communications overhead. <p> This is followed by an example which illustrates the execution of a multioperator query. Finally, we briefly describe WiSS, the storage system used to provide low level database services, and NOSE, the underlying operating system. 3.1. Gamma Storage Organizations Relations in Gamma are horizontally partitioned <ref> [RIES78] </ref> across all disk drives in the system. The key idea behind horizontally partitioning each relation is to enable the database software to exploit all the I/O bandwidth provided by the hardware.
Reference: [SCHN89a] <author> Schneider, D. and D. DeWitt, </author> <title> A Performance Evaluation of Four Parallel Join Algorithms in a Shared-Nothing Multiprocessor Environment, </title> <booktitle> Proceedings of the 1989 SIGMOD Conference, </booktitle> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: In the period of 1986-1988, the prototype was enhanced through the addition of a number of new operators (e.g. aggregate and update operators), new parallel join methods (Hybrid, Grace, and Sort-Merge <ref> [SCHN89a] </ref>), and a complete concurrency control mechanism. In addition, we also conducted a number of performance studies of the system during this period [DEWI86, DEWI88, GHAN89, GHAN90]. In the spring of 1989, Gamma was ported to a 32 processor Intel iPSC/2 hypercube and the VAX-based prototype was retired. <p> While all four algorithms employ this concept of hash-based partitioning, the actual join computation depends on the algorithm. The parallel hybrid join algorithm is described in the following section. Additional information on all four parallel algorithms and their relative performance can be found in <ref> [SCHN89a] </ref>. Since this study found that the Hybrid hash join almost always provides the best performance, it is now the default algorithm in Gamma and is described in more detail in the following section.
Reference: [SCHN89b] <author> Schneider, D. and D. DeWitt, </author> <title> "Design Tradeoffs of Alternative Query Tree Representations for Multiprocessor Database Machines", </title> <type> Computer Sciences Technical Report #869, </type> <institution> University of Wisconsin-Madison, </institution> <month> August </month> <year> 1989, </year> <note> submitted for publication. </note>
Reference-contexts: Since this memory limitation was really only an artifact of the VAX prototype, we have recently begun to examine the performance implications of right deep and bushy query plans <ref> [SCHN89b] </ref>. As discussed in Section 3.1, in the process of optimizing a query, the query optimizer recognizes that certain queries can be directed to only a subset of the nodes in the system. <p> We currently have a number of new projects underway. First, we plan on implementing the chained declus-tering mechanism and evaluating its effectiveness. With respect to processing queries, we have designed <ref> [SCHN89b] </ref> and are currently evaluating alternative strategies for processing queries involving multiple join operations. For example, consider a query involving 10 joins on a machine with 100 processors.
Reference: [SELI79] <author> Selinger,P. G., et. al., </author> <title> "Access Path Selection in a Relational Database Management System," </title> <booktitle> Proceedings of the 1979 SIGMOD Conference, </booktitle> <address> Boston, MA., </address> <month> May </month> <year> 1979. </year>
Reference-contexts: A mechanism for passing parameters from the C program to the compiled query plans at run time is also provided. Query Execution Gamma uses traditional relational techniques for query parsing, optimization <ref> [SELI79, JARK84] </ref>, and code generation. The optimization process is somewhat simplified as Gamma only employs hash-based algorithms for joins and other complex operations. Queries are compiled into a left-deep tree of operators. At execution time, each operator is executed by one or more operator processes at each participating site.
Reference: [STON86] <author> Stonebraker, M., </author> <title> "The Case for Shared Nothing," </title> <journal> Database Engineering, </journal> <volume> Vol. 9, No. 1, </volume> <year> 1986. </year>
Reference-contexts: As a solution to the problems encountered with DIRECT, Gamma employs what appear today to be relatively straightforward solutions. Architecturally, Gamma is based on a shared-nothing <ref> [STON86] </ref> architecture consisting of a number of processors interconnected by a communications network such as a hypercube or a ring, with disks directly connected to the individual processors. It is generally accepted that such architectures can be scaled to incorporate 1000s of processors. <p> Section 6 contains a performance study of the 32 processor Intel hypercube prototype. Our conclusions and future research directions are described in Section 7. 2. Hardware Architecture of Gamma 2.1. Overview Gamma is based on the concept of a shared-nothing architecture <ref> [STON86] </ref> in which processors do not share disk drives or random access memory and can only communicate with one another by sending messages through an interconnection network.
Reference: [STON88] <author> Stonebraker, M., R. Katz, D. Patterson, and J. Ousterhout, </author> <booktitle> The Design of XPRS, Proceedings of the Fourteenth International Conference on Very Large Data Bases", </booktitle> <address> Los Angeles, CA, </address> <month> August, </month> <year> 1988. </year>
Reference-contexts: While Teradata and Tandem also rely on hashing to decentralize the execution of their parallel algorithms, both systems tend to rely on relatively conventional join algorithms such as sort-merge for 2 processing the fragments of the relation at each site. Gamma, XPRS <ref> [STON88] </ref>, and Volcano [GRAE89] each utilize parallel versions of the Hybrid join algorithm [DEWI84a]. The remainder of this paper is organized as follows. In Section 2 we describe the hardware used by each of the Gamma prototypes and our experiences with each.
Reference: [TAND88] <author> Tandem Performance Group, </author> <title> A Benchmark of Non-Stop SQL on the Debit Credit Transaction, </title> <booktitle> Proceedings of the 1988 SIGMOD Conference, </booktitle> <address> Chicago, IL, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: In the spring of 1989, Gamma was ported to a 32 processor Intel iPSC/2 hypercube and the VAX-based prototype was retired. Gamma is similar to a number of other active parallel database machine efforts. In addition to Teradata [TERA85], Bubba [COPE88] and Tandem <ref> [TAND88] </ref> also utilize a shared-nothing architecture and employ the concept of horizontal partitioning. <p> There are a number of reasons why the shared-nothing approach has become the architecture of choice. First, there is nothing to prevent the architecture from scaling to 1000s of processors unlike shared-memory machines for which scaling beyond 30-40 processors may be impossible. Second, as demonstrated in <ref> [DEWI88, COPE88, TAND88] </ref>, by associating a small number of ... N 2 1 INTERCONNECTION NETWORK 3 disks with each processor and distributing the tuples of each relation across the disk drives, it is possible to achieve very high aggregate I/O bandwidths without using custom disk controllers [KIM86, PATT88].
Reference: [TERA85] <author> Teradata, </author> <title> "DBC/1012 Database Computer System Manual Release 2.0," Document No. </title> <institution> C10-0001-02, Teradata Corp., </institution> <month> NOV </month> <year> 1985. </year>
Reference-contexts: It is generally accepted that such architectures can be scaled to incorporate 1000s of processors. In fact, Teradata database machines <ref> [TERA85] </ref> incorporating a shared-nothing architecture with over 200 processors are already in use. The second key idea employed by Gamma is the use of hash-based parallel algorithms. Unlike the algorithms employed by DIRECT, these algorithms require no centralized control and can thus, like the hardware architecture, be scaled almost indefinitely. <p> In the spring of 1989, Gamma was ported to a 32 processor Intel iPSC/2 hypercube and the VAX-based prototype was retired. Gamma is similar to a number of other active parallel database machine efforts. In addition to Teradata <ref> [TERA85] </ref>, Bubba [COPE88] and Tandem [TAND88] also utilize a shared-nothing architecture and employ the concept of horizontal partitioning. <p> Failure Management To help insure availability of the system in the event of processor and/or disk failures, Gamma employs a new availability technique termed chained declustering [HSIA90]. Like Tandem's mirrored disk mechanism [BORR81] and Teradata's interleaved declustering mechanism <ref> [TERA85, COPE89] </ref>, chained declustering employs both a primary and backup copy of each relation. All three systems can sustain the failure of a single processor or disk without suffering any loss in data availability. <p> 1 2 3 4 5 6 7 iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii Primary Copy R0 R1 R2 R3 R4 R5 R6 R7 iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii Backup Copy r7 r0 r1 r2 r3 r4 r5 r6 iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiic c c c c Chained Declustering (Relation Cluster Size = 8) The difference between the chained and interleaved declustering mechanisms <ref> [TERA85, COPE89] </ref> is illustrated by Figure 10. In Figure 10, the fragments from the primary copy of R are declustered across all 8 disk drives by hashing on a "key" attribute. With the interleaved declustering mechanism the set of disks are divided into units of size N called clusters.
Reference: [WAGN73] <author> Wagner, R.E., </author> <title> "Indexing Design Considerations," </title> <journal> IBM System Journal, </journal> <volume> Vol. 12, No. 4, </volume> <month> Dec. </month> <year> 1973, </year> <pages> pp. 351-367. 36 </pages>
Reference-contexts: When the user requests that an index be created on a relation, the system automatically creates an index on each fragment of the relation. Unlike VSAM <ref> [WAGN73] </ref> and the Tandem file system [ENSC85], Gamma does not require the clustered index for a relation to be constructed on hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 3 Declustering is another term for horizontal partitioning that was coined by the Bubba project [LIVN87]. 7 the partitioning attribute.
References-found: 40

