URL: http://www.umiacs.umd.edu/research/EXPAR/papers/3449.ps
Refering-URL: http://www.umiacs.umd.edu/research/EXPAR/papers/3449.html
Root-URL: 
Email: dbader@eng.umd.edu  harwood@umiacs.umd.edu  joseph@umiacs.umd.edu  lsd@umiacs.umd.edu  
Title: Parallel Algorithms for Image Enhancement and Segmentation by Region Growing with an Experimental Study  
Author: David A. Bader David Harwood Joseph JaJa Larry S. Davis 
Keyword: Parallel Algorithms, Image Processing, Region Growing, Image Enhancement, Image Segmentation, Symmetric Neighborhood Filter, Connected Components, Parallel Performance.  
Note: Also affiliated with Department of Electrical Engineering. The support by NASA Graduate Student Researcher Fellowship No. NGT-50951 is gratefully acknowledged. Supported by NSF HPCC/GCAG grant No. BIR-9318183. Also affiliated with Department of Electrical Engineering. Supported in part by NSF grant No. CCR-9103135 and NSF HPCC/GCAG grant No. BIR-9318183. Also affiliated with the Department of Computer Science and the Center for Automation Research; supported by NSF HPCC/GCAG grant No. BIR-9318183.  
Date: November 25, 1995  
Address: College Park, MD 20742  
Affiliation: Institute for Advanced Computer Studies University of Maryland,  
Abstract: This paper presents efficient and portable implementations of a useful image enhancement process, the Symmetric Neighborhood Filter (SNF), and an image segmentation technique which makes use of the SNF and a variant of the conventional connected components algorithm which we call ffi-Connected Components. Our general framework is a single-address space, distributed memory programming model. We use efficient techniques for distributing and coalescing data as well as efficient combinations of task and data parallelism. The image segmentation algorithm makes use of an efficient connected components algorithm which uses a novel approach for parallel merging. The algorithms have been coded in Split-C and run on a variety of platforms, including the Thinking Machines CM-5, IBM SP-1 and SP-2, Cray Research T3D, Meiko Scientific CS-2, Intel Paragon, and workstation clusters. Our experimental results are consistent with the theoretical analysis (and provide the best known execution times for segmentation, even when compared with machine-specific implementations.) Our test data include difficult images from the Landsat Thematic Mapper (TM) satellite data. More efficient implementations of Split-C will likely result in even faster execution times. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Alnuweiri and V. Prasanna. </author> <title> Parallel Architectures and Algorithms for Image Component Labeling. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 14 </volume> <pages> 1014-1034, </pages> <year> 1992. </year>
Reference-contexts: For this application, we crop the border by a width of three pixels. 4.3 ffi-Connected Components The image processing problem of determining the connected components of images is a fundamental task of imaging systems (e.g. <ref> [1] </ref>, [12], [13], [18], [20], [23], [24]).
Reference: [2] <author> M. Annaratone, E. Arnould, T. Gross, H.T. Kung, M. Lam, O. Menzilcioglu, and J.A. Webb. </author> <title> The Warp Computer: Architecture, Implementation, and Performance. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36:1523-1538, </volume> <year> 1987. </year>
Reference: [3] <author> J. Apostolakis, P. Coddington, and E. Marinari. </author> <title> New SIMD Algorithms for Cluster Labeling on Parallel Computers. </title> <journal> Int. J. Mod. Phys. C, </journal> <volume> 4:749, </volume> <year> 1993. </year>
Reference: [4] <author> D. A. Bader and J. JaJa. </author> <title> Parallel Algorithms for Image Histogramming and Connected Components with an Experimental Study. </title> <institution> Technical Report CS-TR-3384 and UMIACS-TR-94-133, UMIACS and Electrical Engineering, University of Maryland, College Park, MD, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: Our algorithm makes use of an efficient and fast parallel connected components algorithm which uses a novel approach for merging. For a detailed theoretical and experimental analysis of this algorithm, please refer to <ref> [4] </ref>. In real images, natural regions have significant variability in grey level. Noise, introduced from the scanning of the real scene into the digital domain, will cause single pixels outliers. Also, lighting changes can cause a gradient of grey levels in pixels across the same region. <p> An efficient matrix transposition algorithm consists of p iterations such that, during iteration i, (1 i p 1), each processor P t prefetches the appropriate block of q p elements from processor P (t+i)modp . The BDM algorithm and analysis for the matrix transpose data movement is given in <ref> [4] </ref> and is similar to that of the LogP model [16]. This matrix transpose algorithm has the following complexity: ( T comm (n; p) = t + p ; T comp (n; p) = O (q): (1) 2.2 Broadcasting Another useful data movement primitive is broadcasting. <p> This matrix transpose algorithm has the following complexity: ( T comm (n; p) = t + p ; T comp (n; p) = O (q): (1) 2.2 Broadcasting Another useful data movement primitive is broadcasting. An efficient BDM algorithm is given <ref> [4] </ref>, [25] which takes q elements on a single processor and broadcasts them to the other p 1 processors using just two matrix transpositions. <p> The analysis of this broadcasting algorithm is simple. Since this algorithm just performs two matrix transpositions, the complexities of the broadcasting algorithm are ( T comm (n; p) = 2 p ; T comp (n; p) = O (q): (2) Performance analysis given in <ref> [4] </ref> reflects the execution times from implementations on the CM-5, SP-2, and CS-2, each with p = 32 parallel processing nodes. The algorithms are written in Split-C, a parallel extension of the C programming language, primarily intended for distributed memory multiprocessors. <p> Our algorithm uses novel techniques to perform the merges and to update the labels. We will attempt to give an overview of this algorithm; for a complete description, see <ref> [4] </ref>. We merge the p subimages into larger and larger image sections with consistent labelings. There will be log p iterations since we cut the number of uncombined subimages in half during each iteration. <p> from the current label at position i, the processor will run a breadth-first search relabeling technique beginning at pixel i, relabeling all the connected pixels' labels to the new label. 6.1 Parallel Complexity for ffi-Connected Components Thus, for p n, the total complexities for the parallel ffi-Connected Components algorithm are <ref> [4] </ref> 8 : T comm (n; p) (4 log p)t + (24n + 2p) = (4 log p)t + O p ; T comp (n; p) = O p : Clearly, the computational complexity is the best possible asymptotically. <p> multi-dim. divide & conquer (partitioned input) 1994 Choudhary and Thakur [12] TMC CM-5 32 456 ms 55.7 s multi-dim. divide & conquer (partitioned input) 398 ms 48.6 s multi-dim. divide & conquer (complete im./PE) 452 ms 55.2 s multi-dim. divide & conquer (cmplt. + collect. comm.) 1994 Bader and JaJa <ref> [4] </ref> TMC CM-5 32 368 ms 44.9 s IBM SP-1 4 370 ms 5.65 s Meiko CS-2 2 809 ms 6.17 s 32 301 ms 36.7 s 1995 Bader et al.
Reference: [5] <author> D. A. Bader and J. JaJa. </author> <title> Practical Parallel Algorithms for Dynamic Data Redistribution, Median Finding, and Selection. </title> <institution> Technical Report CS-TR-3494 and UMIACS-TR-95-74, UMIACS and Electrical Engineering, University of Maryland, College Park, MD, </institution> <month> July </month> <year> 1995. </year>
Reference-contexts: The first step runs for a small number of iterations (e.g. four) with * = 0 and is used to preserve edges. We define to be the median of the standard deviations of all 3 fi 3 neighborhoods centered around each non-border pixel in the image. See <ref> [5] </ref> for a parallel median algorithm. To flatten the interior of regions, SNF is iterated with * = , where is typically set to 2:0 for this application.
Reference: [6] <author> C.F. Baillie and P.D. Coddington. </author> <title> Cluster Identification Algorithms for Spin Models Sequential and Parallel. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 3(2) </volume> <pages> 129-144, </pages> <year> 1991. </year>
Reference-contexts: as a fundamental computer vision problem in the DARPA Image Understanding benchmarks ([33], [39]), and also can be applied to several computational physics problems such as percolation ([8], [35]) and various cluster Monte Carlo algorithms for computing the spin models of magnets such as the two-dimensional Ising spin model ([3], <ref> [6] </ref>, [34]). All pixels with grey level (or `color') 0 are assumed to be background, while pixels with color &gt; 0 are foreground objects.
Reference: [7] <author> G.E. Blelloch. </author> <title> Prefix sums and their applications. </title> <type> Technical Report CMU-CS-90-190, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> November </month> <year> 1990. </year> <month> 22 </month>
Reference-contexts: Each processor i has a data value, Z i , and we need the value of Z 0 Z 1 : : : Z p1 , where is any associative operator. Parallel 9 computers can handle this efficiently <ref> [7] </ref>, and Split-C implements this as a primitive library function. A simple algorithm consists of p 1 rounds that can be pipelined [25]. Each processor P i initializes a local sum to Z i .
Reference: [8] <author> R.C. Brower, P. Tamayo, and B. York. </author> <title> A Parallel Multigrid Algorithm for Percolation Clusters. </title> <journal> Journal of Statistical Physics, </journal> <volume> 63:73, </volume> <year> 1991. </year>
Reference: [9] <author> W.W. Carlson and J.M. Draper. </author> <title> AC for the T3D. </title> <type> Technical Report SRC-TR-95-141, </type> <institution> Supercomputing Research Center, Bowie, MD, </institution> <month> February </month> <year> 1995. </year>
Reference-contexts: The Meiko CS-2 port of Split-C uses the Elan communications libraries. For the Cray T3D, Split-C is built on top of AC (version 2.6) <ref> [9] </ref> and shmem from Cray Research. 14 Year Researcher (s) Machine PE's Time work/pix Notes 1994 Copty et al. [13] TMC CM-2 8192 13.911 s 217 ms data parallel 16384 9.650 s 302 ms data parallel TMC CM-5 32 42.931 s 83.9 ms data parallel 9.567 s 18.5 ms message passing,
Reference: [10] <author> Y.-L. Chang and X. Li. </author> <title> Adaptive Image Region-Growing. </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> 3(6) </volume> <pages> 868-872, </pages> <year> 1994. </year>
Reference-contexts: Region growing is a class of techniques used in image segmentation algorithms in which, typically, regions are constructed by an agglomeration process that adds (merges) pixels to regions when those pixels are both adjacent to the regions and similar in property (most simply intensity) (e.g. <ref> [10] </ref>, [13], [21], [41], [44]). Each pixel in the image receives a label from the region growing process; pixels will have the same label if and only if they belong to the same region.
Reference: [11] <author> A. Choudhary and R. Thakur. </author> <title> Evaluation of Connected Component Labeling Algorithms on Shared and Distributed Memory Multiprocessors. </title> <booktitle> In Proceedings of the 6th International Parallel Processing Symposium, </booktitle> <pages> pages 362-365, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Kanade and Webb [27] Warp 10 4.34 s 166 s shrink/expand 1989 Weems, Riseman, Hanson, Alliant FX-80 8 7.225 s 220 s and Rosenfeld [40] Sequent Symmetry 81 8 15.12 s 461 s Warp 10 3.98 s 152 s TMC CM-2 32768 140 ms 547 s 1992 Choudhary and Thakur <ref> [11] </ref> Intel iPSC/2 32 1.914 s 234 s multi-dim. divide & conquer (partitioned input) 1.649 s 201 s multi-dim. divide & conquer (complete im./PE) 2.290 s 280 s multi-dim. divide & conquer (cmplt. + collect. comm.) Intel iPSC/860 32 1.351 s 165 s multi-dim. divide & conquer (partitioned input) 1.031 s
Reference: [12] <author> A. Choudhary and R. Thakur. </author> <title> Connected Component Labeling on Coarse Grain Parallel Computers: An Experimental Study. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 20(1) </volume> <pages> 78-83, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: For this application, we crop the border by a width of three pixels. 4.3 ffi-Connected Components The image processing problem of determining the connected components of images is a fundamental task of imaging systems (e.g. [1], <ref> [12] </ref>, [13], [18], [20], [23], [24]). <p> 32 1.351 s 165 s multi-dim. divide & conquer (partitioned input) 1.031 s 126 s multi-dim. divide & conquer (complete im./PE) 947 ms 116 s multi-dim. divide & conquer (cmplt. + collect. comm.) Encore Multimax 16 521 ms 31.8 s multi-dim. divide & conquer (partitioned input) 1994 Choudhary and Thakur <ref> [12] </ref> TMC CM-5 32 456 ms 55.7 s multi-dim. divide & conquer (partitioned input) 398 ms 48.6 s multi-dim. divide & conquer (complete im./PE) 452 ms 55.2 s multi-dim. divide & conquer (cmplt. + collect. comm.) 1994 Bader and JaJa [4] TMC CM-5 32 368 ms 44.9 s IBM SP-1 4
Reference: [13] <author> N. Copty, S. Ranka, G. Fox, and R.V. Shankar. </author> <title> A Data Parallel Algorithm for Solving the Region Growing Problem on the Connection Machine. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 21(1) </volume> <pages> 160-168, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Region growing is a class of techniques used in image segmentation algorithms in which, typically, regions are constructed by an agglomeration process that adds (merges) pixels to regions when those pixels are both adjacent to the regions and similar in property (most simply intensity) (e.g. [10], <ref> [13] </ref>, [21], [41], [44]). Each pixel in the image receives a label from the region growing process; pixels will have the same label if and only if they belong to the same region. <p> For this application, we crop the border by a width of three pixels. 4.3 ffi-Connected Components The image processing problem of determining the connected components of images is a fundamental task of imaging systems (e.g. [1], [12], <ref> [13] </ref>, [18], [20], [23], [24]). <p> better compared with other recent parallel region growing codes (<ref> [13] </ref>). Note that this implementation uses data parallel Fortran on the TMC CM-2 and CM-5 machines, and lower-level implementations on the CM-5 using Fortran with several message passing schemes. For example, Figure 7 shows two of the more difficult images from [13] which are segmented by region growing. Image 3 is a 256-grey level 128 fi 128 image, containing seven homogeneous circles. Image 6 is a binary 256 fi 256 image of a tool. Tables II and III show the comparison of execution times for Images 3 and 6, respectively. <p> The Meiko CS-2 port of Split-C uses the Elan communications libraries. For the Cray T3D, Split-C is built on top of AC (version 2.6) [9] and shmem from Cray Research. 14 Year Researcher (s) Machine PE's Time work/pix Notes 1994 Copty et al. <ref> [13] </ref> TMC CM-2 8192 13.911 s 217 ms data parallel 16384 9.650 s 302 ms data parallel TMC CM-5 32 42.931 s 83.9 ms data parallel 9.567 s 18.5 ms message passing, comm1 5.537 s 10.8 ms message passing, comm2 1995 Bader et al. <p> TMC CM-5 16 81.6 ms 79.7 s (this paper) 32 72.0 ms 141 s IBM SP-2-WD 4 62.9 ms 15.4 s Meiko CS-2 4 99.6 ms 24.3 s 8 90.9 ms 44.4 s Table II: Implementation Results of Segmentation Algorithm on Image 3 from <ref> [13] </ref>, seven grey circles (128 fi 128) The source code for the parallel algorithms presented in this paper is available for distribution to interested parties. 8 Acknowledgements We would like to thank the UMIACS parallel systems staff for their help and machine maintenance while developing this research on the 16-node IBM <p> The Meiko CS-2 Computing Facility was acquired through NSF CISE Infrastructure Grant number CDA-9218202, with support from the College of Engineering and the UCSB Office of Research, for research in parallel computing. 15 Year Researcher (s) Machine PE's Time work/pix Notes 1994 Copty et al. <ref> [13] </ref> TMC CM-2 8192 20.538 s 80.2 ms data parallel 16384 13.955 s 109 ms data parallel TMC CM-5 32 77.648 s 37.9 ms data parallel 12.290 s 6.00 ms message passing, comm1 7.334 s 3.58 ms message passing, comm2 1995 Bader et al. <p> 16 177 ms 43.2 s 8 176 ms 21.5 s Meiko CS-2 4 414 ms 25.3 s 8 274 ms 33.5 s 32 193 ms 94.2 s Cray T3D 4 396 ms 24.2 s 8 443 ms 54.1 s Table III: Implementation Results of Segmentation Algorithm on Image 6 from <ref> [13] </ref>, a binary tool (256fi256) Arvind Krishnamurthy provided additional help with his port of Split-C to the Cray Research T3D. The Jet Propulsion Lab/Caltech Cray T3D Supercomputer used in this investigation was provided by funding from the NASA Offices of Mission to Planet Earth, Aeronautics, and Space Science.
Reference: [14] <author> D.E. Culler, A. Dusseau, S.C. Goldstein, A. Krishnamurthy, S. Lumetta, S. Luna, T. von Eicken, and K. Yelick. </author> <title> Introduction to Split-C. </title> <institution> Computer Science Division - EECS, University of Cali-fornia, Berkeley, </institution> <note> version 1.0 edition, </note> <month> March 6, </month> <year> 1994. </year>
Reference-contexts: The shared memory model algorithms are written in Split-C <ref> [14] </ref>, a shared memory programming model language which follows the SPMD (single program multiple data) model on these parallel machines, and the source code is available for distribution to interested parties. 2 Block Distributed Memory Model We use the Block Distributed Memory (BDM) Model ([25], [26]) as a computation model for
Reference: [15] <author> D.E. Culler, A. Dusseau, S.C. Goldstein, A. Krishnamurthy, S. Lumetta, S. Luna, T. von Eicken, and K. Yelick. </author> <title> Programming in Split-C. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <pages> pages 262-273, </pages> <address> Portland, OR, </address> <month> November </month> <year> 1993. </year>
Reference: [16] <author> D.E. Culler, R.M. Karp, D.A. Patterson, A. Sahay, K.E. Schauser, E. Santos, R. Subramonian, and T. von Eicken. </author> <title> LogP: Towards a Realistic Model of Parallel Computation. </title> <booktitle> In Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: The BDM algorithm and analysis for the matrix transpose data movement is given in [4] and is similar to that of the LogP model <ref> [16] </ref>. This matrix transpose algorithm has the following complexity: ( T comm (n; p) = t + p ; T comp (n; p) = O (q): (1) 2.2 Broadcasting Another useful data movement primitive is broadcasting.
Reference: [17] <author> H. Derin and C.-S. Won. </author> <title> A Parallel Image Segmentation Algorithm Using Relaxation with Varying Neighborhoods and Its Mapping to Array Processors. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 40 </volume> <pages> 54-78, </pages> <year> 1987. </year>
Reference-contexts: As with the SNF implementations, most previous parallel algorithms for segmentation do not port well to other platforms (e.g. <ref> [17] </ref>, [28], [29], [36], [41], [42]). Section 2 addresses the algorithmic model and various primitive operations we use to analyze the algorithms. Section 3 discusses the test images, as well as the data layout on the parallel machines.
Reference: [18] <author> M.B. Dillencourt, H. Samet, and M. Tamminen. </author> <title> Connected Component Labeling of Binary Images. </title> <type> Technical Report CS-TR-2303, </type> <institution> Computer Science Department, University of Maryland, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: For this application, we crop the border by a width of three pixels. 4.3 ffi-Connected Components The image processing problem of determining the connected components of images is a fundamental task of imaging systems (e.g. [1], [12], [13], <ref> [18] </ref>, [20], [23], [24]).
Reference: [19] <author> R. Goldenberg, W.C. Lau, A. She, and A.M. Waxman. </author> <title> Progress on the Prototype PIPE. </title> <booktitle> In Proceedings of the 1987 Workshop on Computer Architecture for Pattern Analysis and Machine Intelligence, </booktitle> <pages> pages 67-74, </pages> <address> Seattle, WA, </address> <month> October </month> <year> 1987. </year>
Reference-contexts: A variety of SNF operators have been studied, and we chose a single parameter version which has been shown to perform well on remote sensing applications. 2 The majority of previous parallel implementations of the SNF filter are architecture- or machine--specific and do not port well to other platforms (e.g. <ref> [19] </ref>, [30], [31], [32], [37]). For example, [38] gives an implementation of a 15 fi 15 SNF filter on the CMU Warp, a 10-processor linear systolic array, which takes 4.76 seconds on a 512 fi 512 image. We present our SNF filter execution timings in Figure 10.
Reference: [20] <author> Y. Han and R.A. Wagner. </author> <title> An Efficient and Fast Parallel-Connected Component Algorithm. </title> <journal> JACM, </journal> <volume> 37(3) </volume> <pages> 626-642, </pages> <year> 1990. </year>
Reference-contexts: For this application, we crop the border by a width of three pixels. 4.3 ffi-Connected Components The image processing problem of determining the connected components of images is a fundamental task of imaging systems (e.g. [1], [12], [13], [18], <ref> [20] </ref>, [23], [24]).
Reference: [21] <author> R.M. Haralick and L.G. Shapiro. </author> <title> Image Processing Techniques. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 29 </volume> <pages> 100-132, </pages> <year> 1985. </year>
Reference-contexts: Region growing is a class of techniques used in image segmentation algorithms in which, typically, regions are constructed by an agglomeration process that adds (merges) pixels to regions when those pixels are both adjacent to the regions and similar in property (most simply intensity) (e.g. [10], [13], <ref> [21] </ref>, [41], [44]). Each pixel in the image receives a label from the region growing process; pixels will have the same label if and only if they belong to the same region.
Reference: [22] <author> D. Harwood, M. Subbarao, H. Hakalahti, and L.S. Davis. </author> <title> A New Class of Edge-Preserving Smoothing Filters. </title> <journal> Pattern Recognition Letters, </journal> <volume> 6 </volume> <pages> 155-162, </pages> <year> 1987. </year>
Reference-contexts: Also, lighting changes can cause a gradient of grey levels in pixels across the same region. Because of these and other similar effects, we preprocess the image with a stable filter, the Symmetric Neighborhood Filter (SNF) <ref> [22] </ref>, that smooths out the interior pixels of a region to a near-homogeneous level.
Reference: [23] <author> D.S. Hirschberg, A.K. Chandra, and D.V. Sarwate. </author> <title> Computing Connected Components on Parallel Computers. </title> <journal> Communications of the ACM, </journal> <volume> 22(8) </volume> <pages> 461-464, </pages> <year> 1979. </year> <month> 23 </month>
Reference-contexts: For this application, we crop the border by a width of three pixels. 4.3 ffi-Connected Components The image processing problem of determining the connected components of images is a fundamental task of imaging systems (e.g. [1], [12], [13], [18], [20], <ref> [23] </ref>, [24]).
Reference: [24] <author> J. JaJa. </author> <title> An Introduction to Parallel Algorithms. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: For this application, we crop the border by a width of three pixels. 4.3 ffi-Connected Components The image processing problem of determining the connected components of images is a fundamental task of imaging systems (e.g. [1], [12], [13], [18], [20], [23], <ref> [24] </ref>).
Reference: [25] <author> J. JaJa and K.W. Ryu. </author> <title> The Block Distributed Memory Model. </title> <type> Technical Report CS-TR-3207, </type> <institution> Computer Science Department, University of Maryland, College Park, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: This matrix transpose algorithm has the following complexity: ( T comm (n; p) = t + p ; T comp (n; p) = O (q): (1) 2.2 Broadcasting Another useful data movement primitive is broadcasting. An efficient BDM algorithm is given [4], <ref> [25] </ref> which takes q elements on a single processor and broadcasts them to the other p 1 processors using just two matrix transpositions. <p> We compute the matrix transpose of A, thus, giving every processor q p elements. Each processor then locally rearranges the data so that an additional matrix transpose will result in each processor holding a copy of all the q elements in its column of A <ref> [25] </ref>. The analysis of this broadcasting algorithm is simple. <p> Parallel 9 computers can handle this efficiently [7], and Split-C implements this as a primitive library function. A simple algorithm consists of p 1 rounds that can be pipelined <ref> [25] </ref>. Each processor P i initializes a local sum to Z i . During round r, each processors then reads Z (i+r)modp , for 1 r p 1, and adds this value to the local sum.
Reference: [26] <author> J.F. JaJa and K.W. Ryu. </author> <title> The Block Distributed Memory Model for Shared Memory Multiprocessors. </title> <booktitle> In Proceedings of the 8th International Parallel Processing Symposium, </booktitle> <pages> pages 752-756, </pages> <address> Cancun, Mexico, </address> <month> April </month> <year> 1994. </year> <note> (Extended Abstract). </note>
Reference-contexts: algorithms are written in Split-C [14], a shared memory programming model language which follows the SPMD (single program multiple data) model on these parallel machines, and the source code is available for distribution to interested parties. 2 Block Distributed Memory Model We use the Block Distributed Memory (BDM) Model ([25], <ref> [26] </ref>) as a computation model for developing and analyzing our parallel algorithms on distributed memory machines. This model allows the design of algorithms using a single address space and does not assume any particular interconnection topology.
Reference: [27] <author> T. Kanade and J.A. Webb. </author> <title> Parallel Vision Algorithm Design and Implementation 1988 End of Year Report. </title> <type> Technical Report CMU-RI-TR-89-23, </type> <institution> The Robotics Institute, Carnegie Mellon University, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: Note that the SNF and 1-Nearest Neighbor filters are iterative and data dependent, with timings that ramp down after the initial iteration; thus, only the slowest timing for 13 Year Researcher (s) Machine PE's Time work/pix Notes 1989 Kanade and Webb <ref> [27] </ref> Warp 10 4.34 s 166 s shrink/expand 1989 Weems, Riseman, Hanson, Alliant FX-80 8 7.225 s 220 s and Rosenfeld [40] Sequent Symmetry 81 8 15.12 s 461 s Warp 10 3.98 s 152 s TMC CM-2 32768 140 ms 547 s 1992 Choudhary and Thakur [11] Intel iPSC/2 32
Reference: [28] <author> J.J. Kistler and J.A. Webb. </author> <title> Connected Components With Split and Merge. </title> <booktitle> In Proceedings of the 5th International Parallel Processing Symposium, </booktitle> <pages> pages 194-201, </pages> <address> Anaheim, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: As with the SNF implementations, most previous parallel algorithms for segmentation do not port well to other platforms (e.g. [17], <ref> [28] </ref>, [29], [36], [41], [42]). Section 2 addresses the algorithmic model and various primitive operations we use to analyze the algorithms. Section 3 discusses the test images, as well as the data layout on the parallel machines.
Reference: [29] <author> H.T. Kung and J.A. Webb. </author> <title> Mapping Image Processing Operations Onto a Linear Systolic Machine. </title> <journal> Distributed Computing, </journal> <volume> 1 </volume> <pages> 246-257, </pages> <year> 1986. </year>
Reference-contexts: As with the SNF implementations, most previous parallel algorithms for segmentation do not port well to other platforms (e.g. [17], [28], <ref> [29] </ref>, [36], [41], [42]). Section 2 addresses the algorithmic model and various primitive operations we use to analyze the algorithms. Section 3 discusses the test images, as well as the data layout on the parallel machines.
Reference: [30] <author> P.J. Narayanan. </author> <title> Effective Use of SIMD Machines for Image Analysis. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Maryland, College Park, MD, </institution> <year> 1992. </year>
Reference-contexts: variety of SNF operators have been studied, and we chose a single parameter version which has been shown to perform well on remote sensing applications. 2 The majority of previous parallel implementations of the SNF filter are architecture- or machine--specific and do not port well to other platforms (e.g. [19], <ref> [30] </ref>, [31], [32], [37]). For example, [38] gives an implementation of a 15 fi 15 SNF filter on the CMU Warp, a 10-processor linear systolic array, which takes 4.76 seconds on a 512 fi 512 image. We present our SNF filter execution timings in Figure 10.
Reference: [31] <author> P.J. Narayanan and L.S. Davis. </author> <title> Replicated Data Algorithms in Image Processing. </title> <type> Technical Report CAR-TR-536/CS-TR-2614, </type> <institution> Center for Automation Research, University of Maryland, College Park, MD, </institution> <month> February </month> <year> 1991. </year>
Reference-contexts: of SNF operators have been studied, and we chose a single parameter version which has been shown to perform well on remote sensing applications. 2 The majority of previous parallel implementations of the SNF filter are architecture- or machine--specific and do not port well to other platforms (e.g. [19], [30], <ref> [31] </ref>, [32], [37]). For example, [38] gives an implementation of a 15 fi 15 SNF filter on the CMU Warp, a 10-processor linear systolic array, which takes 4.76 seconds on a 512 fi 512 image. We present our SNF filter execution timings in Figure 10. <p> Previous parallel implementations of the SNF have been based around special purpose image processing platforms, including data parallel SIMD machines such as the TMC CM-2 and the MasPar MP-1 ([30] and <ref> [31] </ref>), video-rate VLSI implementations ([32]), pipelined computers 8 ([19]), and systolic linear arrays such as the Warp ([2], [37], and [38]).
Reference: [32] <author> M. Pietikainen, T. Seppanen, and P. Alapuranen. </author> <title> A Hybrid Computer Architecture for Machine Vision. </title> <booktitle> In Proceedings of the 10th International Conference on Pattern Recognition, </booktitle> <volume> Volume 2, </volume> <pages> pages 426-431, </pages> <address> Atlantic City, NJ, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: SNF operators have been studied, and we chose a single parameter version which has been shown to perform well on remote sensing applications. 2 The majority of previous parallel implementations of the SNF filter are architecture- or machine--specific and do not port well to other platforms (e.g. [19], [30], [31], <ref> [32] </ref>, [37]). For example, [38] gives an implementation of a 15 fi 15 SNF filter on the CMU Warp, a 10-processor linear systolic array, which takes 4.76 seconds on a 512 fi 512 image. We present our SNF filter execution timings in Figure 10.
Reference: [33] <editor> A. Rosenfeld. </editor> <booktitle> A Report on the DARPA Image Understanding Architectures Workshop. In Proceedings of the 1987 Image Understanding Workshop, </booktitle> <pages> pages 298-302, </pages> <year> 1987. </year>
Reference: [34] <author> A.D. Sokal. </author> <title> New Numerical Algorithms for Critical Phenomena (Multi-grid Methods and All That). </title> <booktitle> In Proceedings of the International Conference on Lattice Field Theory, </booktitle> <address> Tallahassee, Fl, </address> <month> October </month> <year> 1990. </year> <title> (Nucl. </title> <journal> Phys. B (Proc. Suppl.) 20:55, 1991.). </journal>
Reference-contexts: a fundamental computer vision problem in the DARPA Image Understanding benchmarks ([33], [39]), and also can be applied to several computational physics problems such as percolation ([8], [35]) and various cluster Monte Carlo algorithms for computing the spin models of magnets such as the two-dimensional Ising spin model ([3], [6], <ref> [34] </ref>). All pixels with grey level (or `color') 0 are assumed to be background, while pixels with color &gt; 0 are foreground objects. A connected component in the image is a maximal collection of uniformly colored pixels such that a path exists between any pair of pixels in the component.
Reference: [35] <author> D. Stauffer. </author> <title> Introduction to Percolation Theory. Taylor and Francis, </title> <address> Philadelphia, PA, </address> <year> 1985. </year>
Reference-contexts: The task of connected component labeling is cited as a fundamental computer vision problem in the DARPA Image Understanding benchmarks ([33], [39]), and also can be applied to several computational physics problems such as percolation ([8], <ref> [35] </ref>) and various cluster Monte Carlo algorithms for computing the spin models of magnets such as the two-dimensional Ising spin model ([3], [6], [34]). All pixels with grey level (or `color') 0 are assumed to be background, while pixels with color &gt; 0 are foreground objects.
Reference: [36] <author> J.C. Tilton and S.C. Cox. </author> <title> Segmentation of Remotely Sensed Data Using Parallel Region Growing. </title> <booktitle> In Ninth International Symposium on Machine Processing of Remotely Sensed Data, </booktitle> <pages> pages 130-137, </pages> <address> West Lafayette, IN, </address> <month> June </month> <year> 1983. </year>
Reference-contexts: As with the SNF implementations, most previous parallel algorithms for segmentation do not port well to other platforms (e.g. [17], [28], [29], <ref> [36] </ref>, [41], [42]). Section 2 addresses the algorithmic model and various primitive operations we use to analyze the algorithms. Section 3 discusses the test images, as well as the data layout on the parallel machines.
Reference: [37] <author> R.S. Wallace, J.A. Webb, and I-C. Wu. </author> <title> Machine-Independent Image Processing: Performance of Apply on Diverse Architectures. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 48 </volume> <pages> 265-276, </pages> <year> 1989. </year>
Reference-contexts: operators have been studied, and we chose a single parameter version which has been shown to perform well on remote sensing applications. 2 The majority of previous parallel implementations of the SNF filter are architecture- or machine--specific and do not port well to other platforms (e.g. [19], [30], [31], [32], <ref> [37] </ref>). For example, [38] gives an implementation of a 15 fi 15 SNF filter on the CMU Warp, a 10-processor linear systolic array, which takes 4.76 seconds on a 512 fi 512 image. We present our SNF filter execution timings in Figure 10. <p> Previous parallel implementations of the SNF have been based around special purpose image processing platforms, including data parallel SIMD machines such as the TMC CM-2 and the MasPar MP-1 ([30] and [31]), video-rate VLSI implementations ([32]), pipelined computers 8 ([19]), and systolic linear arrays such as the Warp ([2], <ref> [37] </ref>, and [38]). A useful data movement needed for this 3 fi 3 local SNF filter is the fetching of tile-based ghost cells ([15], [43]) which contain shadow copies of neighboring tiles' pixel borders. These ghost cells are used in the selection process when recalculating our tile's border.
Reference: [38] <author> J.A. Webb. </author> <title> Architecture-Independent Global Image Processing. </title> <booktitle> In Proceedings of the 10th International Conference on Pattern Recognition, </booktitle> <volume> Volume 2, </volume> <pages> pages 623-628, </pages> <address> Atlantic City, NJ, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: For example, <ref> [38] </ref> gives an implementation of a 15 fi 15 SNF filter on the CMU Warp, a 10-processor linear systolic array, which takes 4.76 seconds on a 512 fi 512 image. We present our SNF filter execution timings in Figure 10. <p> parallel implementations of the SNF have been based around special purpose image processing platforms, including data parallel SIMD machines such as the TMC CM-2 and the MasPar MP-1 ([30] and [31]), video-rate VLSI implementations ([32]), pipelined computers 8 ([19]), and systolic linear arrays such as the Warp ([2], [37], and <ref> [38] </ref>). A useful data movement needed for this 3 fi 3 local SNF filter is the fetching of tile-based ghost cells ([15], [43]) which contain shadow copies of neighboring tiles' pixel borders. These ghost cells are used in the selection process when recalculating our tile's border.
Reference: [39] <author> C. Weems, E. Riseman, A. Hanson, and A. Rosenfeld. </author> <title> An Integrated Image Understanding Benchmark: Recognition of a 2 1 2 D "Mobile". </title> <booktitle> In Image Understanding Workshop, </booktitle> <pages> pages 111 126, </pages> <address> Cambridge, MA, </address> <month> April </month> <year> 1988. </year> <month> 24 </month>
Reference-contexts: The task of connected component labeling is cited as a fundamental computer vision problem in the DARPA Image Understanding benchmarks ([33], <ref> [39] </ref>), and also can be applied to several computational physics problems such as percolation ([8], [35]) and various cluster Monte Carlo algorithms for computing the spin models of magnets such as the two-dimensional Ising spin model ([3], [6], [34]).
Reference: [40] <author> C. Weems, E. Riseman, A. Hanson, and A. Rosenfeld. </author> <title> A Report on the Results of the DARPA Integrated Image Understanding Benchmark Exercise. </title> <booktitle> In Image Understanding Workshop, </booktitle> <pages> pages 165-192, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: dependent, with timings that ramp down after the initial iteration; thus, only the slowest timing for 13 Year Researcher (s) Machine PE's Time work/pix Notes 1989 Kanade and Webb [27] Warp 10 4.34 s 166 s shrink/expand 1989 Weems, Riseman, Hanson, Alliant FX-80 8 7.225 s 220 s and Rosenfeld <ref> [40] </ref> Sequent Symmetry 81 8 15.12 s 461 s Warp 10 3.98 s 152 s TMC CM-2 32768 140 ms 547 s 1992 Choudhary and Thakur [11] Intel iPSC/2 32 1.914 s 234 s multi-dim. divide & conquer (partitioned input) 1.649 s 201 s multi-dim. divide & conquer (complete im./PE) 2.290
Reference: [41] <author> T. Westman, D. Harwood, T. Laitinen, and M. Pietikainen. </author> <title> Color Segmentation By Hierarchical Connected Components Analysis with Image Enhancement by Symmetric Neighborhood Filters. </title> <booktitle> In Proceedings of the 10th International Conference on Pattern Recognition, </booktitle> <pages> pages 796-802, </pages> <address> At-lantic City, NJ, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Region growing is a class of techniques used in image segmentation algorithms in which, typically, regions are constructed by an agglomeration process that adds (merges) pixels to regions when those pixels are both adjacent to the regions and similar in property (most simply intensity) (e.g. [10], [13], [21], <ref> [41] </ref>, [44]). Each pixel in the image receives a label from the region growing process; pixels will have the same label if and only if they belong to the same region. <p> As with the SNF implementations, most previous parallel algorithms for segmentation do not port well to other platforms (e.g. [17], [28], [29], [36], <ref> [41] </ref>, [42]). Section 2 addresses the algorithmic model and various primitive operations we use to analyze the algorithms. Section 3 discusses the test images, as well as the data layout on the parallel machines.
Reference: [42] <author> M. Willebeek-LeMair and A.P. Reeves. </author> <title> Region Growing on a Highly Parallel Mesh-Connected SIMD Computer. </title> <booktitle> In The 2nd Symposium on the Frontiers of Massively Parallel Computations, </booktitle> <pages> pages 93-100, </pages> <address> Fairfax, VA, </address> <month> October </month> <year> 1988. </year>
Reference-contexts: As with the SNF implementations, most previous parallel algorithms for segmentation do not port well to other platforms (e.g. [17], [28], [29], [36], [41], <ref> [42] </ref>). Section 2 addresses the algorithmic model and various primitive operations we use to analyze the algorithms. Section 3 discusses the test images, as well as the data layout on the parallel machines.
Reference: [43] <author> R. Williams. </author> <title> Parallel Load Balancing for Parallel Applications. </title> <type> Technical Report CCSF-50, </type> <institution> Concurrent Supercomputing Facilities, California Institute of Technology, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: A useful data movement needed for this 3 fi 3 local SNF filter is the fetching of tile-based ghost cells ([15], <ref> [43] </ref>) which contain shadow copies of neighboring tiles' pixel borders. These ghost cells are used in the selection process when recalculating our tile's border. Suppose each tile of the image allocated to a processor is q fi r pixels.
Reference: [44] <author> S.W. Zucker. </author> <title> Region Growing: </title> <journal> Childhood and Adolescence. Computer Graphics and Image Processing, </journal> <volume> 5 </volume> <pages> 382-399, </pages> <year> 1976. </year> <month> 25 </month>
Reference-contexts: Region growing is a class of techniques used in image segmentation algorithms in which, typically, regions are constructed by an agglomeration process that adds (merges) pixels to regions when those pixels are both adjacent to the regions and similar in property (most simply intensity) (e.g. [10], [13], [21], [41], <ref> [44] </ref>). Each pixel in the image receives a label from the region growing process; pixels will have the same label if and only if they belong to the same region. Our algorithm makes use of an efficient and fast parallel connected components algorithm which uses a novel approach for merging.
References-found: 44

