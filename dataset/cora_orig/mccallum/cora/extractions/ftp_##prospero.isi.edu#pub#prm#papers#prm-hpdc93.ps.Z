URL: ftp://prospero.isi.edu/pub/prm/papers/prm-hpdc93.ps.Z
Refering-URL: http://www.isi.edu/~srao/cvd.html
Root-URL: http://www.isi.edu
Title: Resource Management for Distributed Parallel Systems systems, PRM employs three types of managers: system managers,
Author: B. Clifford Neuman Santosh Rao 
Affiliation: Information Sciences Institute University of Southern California  
Date: July 1993.  
Note: Proceedings of the 2nd International Symposium on High Performance Distributed Computing, Spokane,  To manage resources in such distributed parallel  
Abstract: Multiprocessor systems should exist in the the larger context of distributed systems, allowing multiprocessor resources to be shared by those that need them. Unfortunately, typical multiprocessor resource management techniques do not scale to large networks. The Pros-pero Resource Manager (PRM) is a scalable resource allocation system that supports the allocation of processing resources in large networks and multiprocessor systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal and A. K. Ezzat. </author> <title> Processor sharing in NEST: A network of computer workstations. </title> <booktitle> In Proceedings of the first International Conference on Computer Workstations, </booktitle> <pages> pages 198-208. </pages> <month> November </month> <year> 1985. </year>
Reference-contexts: The execution of the program (5) depends on run-time communication libraries (also at 4) which in turn use information about the mapping of tasks to nodes (3). Locus [10], NEST <ref> [1] </ref>, Sprite [5], and V [13] support processor allocation, and remote program loading and execution (2,4,5) to harness the computing power of lightly loaded nodes. They primarily support sequential applications where task-to-task communication is not required. <p> In Locus the target node for remote execution is selected from a list of nodes maintained in the environment of the initiating process. This approach is inflexible because the nodes available for remote execution do not change with changing load. In NEST <ref> [1] </ref>, idle machines advertise their availability, providing a dynamically changing set of available nodes; each user's workstation maintains the list of servers available for remote execution.
Reference: [2] <author> Thomas E. Anderson, Brian N. Bershad, Ed-ward D. Lazowska, and Henry M. Levy. </author> <title> Scheduler activations: Effective kernel support for the user-level management of parallelism. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 10(1) </volume> <pages> 53-79, </pages> <month> February </month> <year> 1992. </year>
Reference-contexts: As such, the job manager is better able than the system manager to allocate resources to the individual tasks within a job. This is the same argument used in favor of user-level thread management on shared-memory multiprocessors <ref> [2] </ref>. In fact, we allow the job manager to be written by the application programmer if specific functionality is required, though we do not expect this to be a common practice. We plan to eventually provide alternative job managers to support fault-tolerant and real-time applications.
Reference: [3] <author> Kenneth P. Birman and Thomas A. Joseph. </author> <title> Exploiting virtual synchrony in distributed systems. </title> <booktitle> In Proceedings of the 11th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 123-138, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: The global synchronization and reduction primitives rely on centrally maintained state information. To the extent possible, we plan to develop distributed implementations of these primitives, perhaps building on the primitives provided by ISIS <ref> [3] </ref>. PRM's transparent message routing mechanism frees the programmer from having to explicitly keep track of task to node mappings. At the application level, messages are addressed using task-identifiers (tid s), which are translated to an internet-address/port pair by the communication library.
Reference: [4] <author> David L. Black, David B. Golub, Daniel P. Julin, Richard F. Rashid, Richard P. Draves, Randall W. Dean, Alessandro Forin, Joseph Barrera, Hideyuki Tokuda, Gerald Malan, and David Bohman. </author> <title> Mi-crokernel operating system architecture and Mach. </title> <booktitle> In Proceedings of the USENIX Workshop on Mi-crokernels and Other Kernel Architectures, </booktitle> <pages> pages 11-30, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: In the present implementation, these library functions use an Asynchronous Reliable Delivery Protocol (ARDP) that transmits and receives sequenced packets over the Internet using UDP. We are currently implementing a version of the communication library layered on top of the Mach port mechanism <ref> [4] </ref>. The global synchronization and reduction primitives rely on centrally maintained state information. To the extent possible, we plan to develop distributed implementations of these primitives, perhaps building on the primitives provided by ISIS [3].
Reference: [5] <author> F. Douglis and J. Ousterhout. </author> <title> Transparent process migration for personal workstations. </title> <type> Technical Report UCB/CSD 89/540, </type> <institution> Computer Science Division, University of California, </institution> <address> Berkeley CA 94720, </address> <month> November </month> <year> 1989. </year>
Reference-contexts: The execution of the program (5) depends on run-time communication libraries (also at 4) which in turn use information about the mapping of tasks to nodes (3). Locus [10], NEST [1], Sprite <ref> [5] </ref>, and V [13] support processor allocation, and remote program loading and execution (2,4,5) to harness the computing power of lightly loaded nodes. They primarily support sequential applications where task-to-task communication is not required. <p> Additionally, resource allocation decisions in these systems are made locally by the application without the benefit of a high level view across jobs. This causes problems when applications run simultaneously. Sprite <ref> [5] </ref> uses a shared file as a centralized database to track available nodes. Clients select idle nodes from this file, marking the entry to flag its use. While this approach appears simple, it requires a solution to problems related to shared writable files, including locking, synchronization and consistency.
Reference: [6] <author> R. E. Felderman, E. M. Schooler, and L. Kleinrock. </author> <title> The Benevolent Bandit Laboratory: A testbed for distributed algorithms. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 7(2) </volume> <pages> 303-311, </pages> <month> February </month> <year> 1989. </year>
Reference-contexts: In the distributed approach a client multicasts a query to a group of candidate machines selecting the responder with the lowest load. This approach suffers from excessive network traffic and was found to perform worse than the central server approach. The UCLA Benevolent Bandit Laboratory (BBL) <ref> [6] </ref> provides an environment for running parallel applications on a network of personal computers. Like the other systems discussed, BBL provides processor allocation, and remote program loading and execution (2,3,4,5), incorporating the notion of a user-process manager separate from a systemwide resource manager.
Reference: [7] <author> B. Clifford Neuman. </author> <title> The Prospero File System: A global file system based on the Virtual System Model. </title> <journal> Computing Systems, </journal> <volume> 5(4), </volume> <month> Fall </month> <year> 1992. </year>
Reference-contexts: At the time a job is initiated, the job manager identifies the job's resource requirements. Using the Pros-pero Directory Service <ref> [7] </ref>, if available, or a configuration file otherwise, it locates system managers with jurisdiction over suitable resources and sends allocation requests. <p> This information is stored either in a configuration file or as attributes of the program in the Prospero Directory Service <ref> [7] </ref>. When a program is invoked, a new job manager is created and the job manager finds a suitable processor or set of processors by contacting system managers identified by the virtual system associated with the program. programs as if they were local to a workstation.
Reference: [8] <author> B. Clifford Neuman. </author> <title> The Virtual System Model: </title>
Reference-contexts: The organization of such systems should be based on the conceptual relationship between resources and the mapping to physical locations should be hidden from the user. These concepts form the basis of the Virtual System Model, a new model for organizing large distributed systems <ref> [8] </ref>. To apply the concepts of the Virtual System Model to the allocation of resources in large systems, we have chosen to divide the functions of resource management across three types of managers: the system manager, the job manager, and the node manager.
References-found: 8

