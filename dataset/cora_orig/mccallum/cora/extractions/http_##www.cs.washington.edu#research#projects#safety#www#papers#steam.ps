URL: http://www.cs.washington.edu/research/projects/safety/www/papers/steam.ps
Refering-URL: http://www.cs.washington.edu/homes/leveson/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Steam Engines and Computer Software  A History of the Growth of the Steam Engine  
Author: Nancy G. Leveson 
Address: Seattle, WA 98195  
Affiliation: Computer Science Eng. Dept., FR-35 University of Washington  
Note: High-Pressure  William Ruckelshaus [33, p.108] The Problems of Exploding Boilers Great inventions are never, and great discoveries are seldom, the work of any one mind. Robert H. Thurston  (1883)  
Abstract: A shortened version of this paper appeared in IEEE Computer, October 1994. 1 Even though a scientific explanation may appear to be a model of rational order, we should not infer from that order that the genesis of the explanation was itself orderly. Science is only orderly after the fact; in process, and especially at the advancing edge of some field, it is chaotic and fiercely controversial. The introduction of computers into the control of potentially dangerous devices has led to a growing awareness of the possible contribution of software to serious accidents. The number of computer-related accidents so far has been small due to the restraint that has been shown in introducing them into safety-critical control loops. However, as the economic and technological benefits of using computers become more widely accepted, their use is increasing dramatically. We need to ensure that computers are introduced into safety-critical systems in the most responsible way possible and at a speed that does not expose people to undue risk. Risk induced by technological innovation existed long before computers; this is not the first time that humans have come up with an extremely useful new technology that is potentially dangerous. We can learn from the past before we repeat the same mistakes. In particular, parallels exist between the early development of high-pressure steam engines and software engineering that we can apply to the use of computers in complex systems. fl This paper was presented as a keynote talk at the International Conference on Software Engineering, Melbourne, Aus tralia, May 1992 and is included in the proceedings. Every great invention is really either an aggregation of minor inventions, or the final step of a progression. It is not a creation but a growth | as truly so as that of the trees in the forest. Hence, the same invention is frequently brought out in several countries, and by several individuals, simultaneously. Frequently an important invention is made before the world is ready to receive it, and the unhappy inventor is taught, by his failure, that it is as unfortunate to be in advance of his age as to be behind it. Inventions only become successful when they are not only needed, but when mankind is so advanced in intelligence as to appreciate and to express the necessity for them, and to at once make use of them. Hero of Alexandria, who lived around 60 AD, conducted some of the first known investigations into the use of steam for power. But it was not until the 16th and 17th centuries that the problem of pumping water out of mines changed the search for steam power from a diversity to a necessity. Many inventors attempted to harness this source of power, but Savery is usually credited as the first to produce and sell a workable steam apparatus. Then Newcomen designed a practical cylinder and piston engine around 1700 which is the forerunner of all subsequent steam engines. In 1786, James Watt was working as an instrument maker at Glasgow University and was asked to repair a model of a Newcomen engine that was being used in a Natural Philosophy class. By one of those serendipitous coincidences of history, Watt had become friendly with several professors, including Dr. Joseph Black, a chemistry professor who discussed with Watt his recent discovery of the phenomenon of latent heat. Watt was unique among the early steam engine inventors in 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Aitken, A. </author> <title> Fault Analysis, </title> <editor> in A. E. Green (ed.), </editor> <title> High Risk Safety Technology, </title> <address> New York: </address> <publisher> John Wiley & Sons, </publisher> <year> 1982 </year>
Reference: [2] <author> Archinoff, G.H., Hohendorf, R.J., Wassyng, A., Quigley, B., and Borsch., </author> <title> M.R. Verification of the Shutdown System Software at the Darling-ton Nuclear Generating Station, </title> <booktitle> Proc. Int. Conf. on Control and Instrumentation in Nuclear Installations, </booktitle> <address> Glawgow, U.K., </address> <month> May </month> <year> 1990. </year>
Reference: [3] <author> Bollinger, T. and McGowan, C. </author> <title> A Critical Look at Software Capability Evaluations, </title> <journal> IEEE Software, </journal> <month> July </month> <year> 1991, </year> <pages> pp. 25-41. </pages>
Reference-contexts: Currently, we are applying techniques and even mandating them without validating that these work or that the underlying hypotheses and assumptions are valid (e.g., <ref> [3] </ref>). When a physicist makes an erroneous claim, such as in cold fusion, the idea may stay around for a while on the fringes of the field.
Reference: [4] <author> Bowman, W.C., Archinoff, G.H., Raina, V.M., Tremaine, D.R., and Leveson, N.G. </author> <title> An Application of Fault Tree Analysis to Safety Critical Software at Ontario Hydro, </title> <booktitle> Conf. on Probabilistic Safety Assessment and Management (PSAM), </booktitle> <address> Beverly Hills, </address> <month> April </month> <year> 1991. </year>
Reference: [5] <author> Briggs, A. </author> <title> The Power of Steam, </title> <publisher> Chicago: The University of Chicago Press, </publisher> <year> 1982. </year>
Reference: [6] <author> Brilliant, S.S., Knight, J.C., and Leveson, N.G. </author> <title> Analysis of Faults in an N-Version Software Experiment, </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> Vol. SE-16, No. 2, </volume> <month> February </month> <year> 1990, </year> <pages> pp. 238-247. </pages>
Reference-contexts: However, the few empirical studies performed on it did not test the underlying assumption of independence of failures and did not carefully analyze the data to determine whether ultra-high reliability was actually being achieved [23]. A series of experiments <ref> [6, 14, 22, 34] </ref> and a mathematical analysis [13] have cast doubt on these assumptions.
Reference: [7] <author> Brookes, M.J. </author> <title> Human Factors in the Design and Operation of Reactor Safety Systems, </title> <editor> in D.L. Sills, C.P. Wolf, and V. Shelanski (eds.), </editor> <title> Accident at Three Mile Island: The Human Dimensions, </title> <address> Boulder, Colorado: </address> <publisher> Westview Press, </publisher> <year> 1982. </year>
Reference-contexts: In fact, the events that occurred have been labelled as inevitable given the existing instrumentation <ref> [7] </ref>: They were a direct function of the electromechanical system design. For example, the computer was hours behind in printing out alarms and information although decisions had to be made in minutes, the instrumentation was unreadable under emergency conditions, and the wrong information was provided.
Reference: [8] <author> Brooks, </author> <title> F.P. No Silver Bullet: </title> <journal> Essence and Accidents of Software Engineering. IEEE Computer, </journal> <month> April </month> <year> 1987, </year> <pages> pp. 10-19. </pages>
Reference-contexts: We need to insist on the same level of evaluation and proof with regard to claims about software engineering techniques and tools. Unfortunately, this is rarely done and our belief in silver bullets persist. Even after Brooks' and Par-nas' carefully reasoned and widely-acclaimed papers <ref> [8, 27] </ref>, we are still seeing claims that the silver bullet has been found. I am not advocating that everyone stop the research they are doing in software engineering and start testing hypotheses and building foundations. Invention is a very important part of progress in engineering.
Reference: [9] <author> Burke, J.G. </author> <title> Bursting Boilers and the Federal Power, </title> <journal> Technology and Culture, </journal> <volume> Vol. VII, No. 1, </volume> <month> Winter </month> <year> 1966, </year> <pages> pp. 1-23. </pages>
Reference: [10] <author> Cameron, R. and Millard, A.J. </author> <title> Technology Assessment: A Historical Approach, </title> <address> Dubuque, Iowa: </address> <publisher> Kendall/Hunt Publishing Company, </publisher> <year> 1985. </year>
Reference-contexts: electricity, Edison warned against the problems of poor workmanship and ignorance on the part of the majority of electrical contractors just as Watt had emphasized the personal moral responsibility of the engineer to ensure a safe and efficient steam engine and the culpability of the engineer in case of accidents <ref> [10] </ref>. If we in software engineering do not ourselves insist on establishing minimum levels of competency and safety, then the government will step in and do it for us. The public expects and has the right to expect that dangerous systems are built using the safest technology available. <p> They anticipated the need for higher standards of safety and precision in the engineering of new technological systems, and they initiated the process of raising professional standards <ref> [10] </ref>. Edison and Watt believed that "engineers had a responsibility to produce competent work, including the utmost in safety" [10]. Eventually professional societies developed that took over the role of establishing safety and competency standards. Such standards and licensing requirements must be carefully composed. <p> They anticipated the need for higher standards of safety and precision in the engineering of new technological systems, and they initiated the process of raising professional standards <ref> [10] </ref>. Edison and Watt believed that "engineers had a responsibility to produce competent work, including the utmost in safety" [10]. Eventually professional societies developed that took over the role of establishing safety and competency standards. Such standards and licensing requirements must be carefully composed.
Reference: [11] <author> Dickens, Charles. </author> <title> Household Words, 1851, </title> <editor> in Stone, Harry (ed.), </editor> <booktitle> Uncollected Writings from Household Words, </booktitle> <pages> 1850-1859, </pages> <address> Bloomington: </address> <publisher> In-diana University Press, </publisher> <year> 1968. </year>
Reference: [12] <author> Dickinson, H.W. </author> <title> A Short History of the Steam Engine, </title> <publisher> London: Frank Cass & Co. Ltd., </publisher> <year> 1963. </year> <month> 11 </month>
Reference: [13] <author> Eckhardt, D.E., and Lee, L.D. </author> <title> A Theoretical Ba--sis for the Analysis of Multiversion Software Subject to Coincident Errors, </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> Vol. SE-11, No. 12, </volume> <month> December </month> <year> 1985, </year> <pages> pp. 1511-1516. </pages>
Reference-contexts: However, the few empirical studies performed on it did not test the underlying assumption of independence of failures and did not carefully analyze the data to determine whether ultra-high reliability was actually being achieved [23]. A series of experiments [6, 14, 22, 34] and a mathematical analysis <ref> [13] </ref> have cast doubt on these assumptions. The latest approach by the proponents of this technique is to relabel it "software diversity" and to compare it to the established method of hardware design diversity although again the software technique does not satisfy the basic underlying assumptions.
Reference: [14] <author> Eckhardt, D.E., Caglayan, A.K., Knight, J.C., Lee, L.D., McAllister, D.F., and Vouk, M.A. </author> <title> An Experimental Evaluation of Software Redundancy as a Strategy for Improving Reliability, </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> Vol. SE-17, No. 7, </volume> <month> July </month> <year> 1991, </year> <pages> pp. 692-702. </pages>
Reference-contexts: However, the few empirical studies performed on it did not test the underlying assumption of independence of failures and did not carefully analyze the data to determine whether ultra-high reliability was actually being achieved [23]. A series of experiments <ref> [6, 14, 22, 34] </ref> and a mathematical analysis [13] have cast doubt on these assumptions.
Reference: [15] <author> Farey, J. </author> <title> A Treatise on the Steam Engine: Historical, Practical, and Description, London: </title> <editor> Long-man, Rees, Orme, Brown, and Green, </editor> <volume> 1827. </volume>
Reference: [16] <author> Goodenough, J. B. and Gerhart, S. </author> <title> Toward a Theory of Test Data Selection, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-1, No. 2, </volume> <month> June </month> <year> 1975. </year>
Reference-contexts: Testing is one such area, although they too have a long way to go. For example, testing researchers have defined theoretical ways of comparing testing strategies both in terms of cost and effectiveness (for example, [38]), formal criteria for evaluating testing strategies (for example, <ref> [16] </ref>), and axioms or properties that any adequacy criterion (rule to determine when testing can stop) should satisfy (for example, [37]).
Reference: [17] <author> Hills, </author> <title> R.L. Power from Steam: A History of the Stationary Steam Engine, </title> <publisher> Cambridge: Cam-bridge University Press, </publisher> <year> 1989. </year>
Reference: [18] <author> Johnson, </author> <title> W.G. MORT: Safety Assurance Systems, </title> <address> New York: </address> <publisher> Marcel Dekker, Inc., </publisher> <year> 1980. </year>
Reference-contexts: Other aerospace studies show that about 80% of aircraft pilot-related accidents are due to poor training or neglect of human engineering in controls and instruments, not to stupidity or panic <ref> [18] </ref>. Humans are effective in emergencies because of their ability to analyze a situation and come up with novel solutions. Humans work well when they have a deep understanding, a sound model of the world, that they can use to predict the results of their actions.
Reference: [19] <author> Josephson, M. Edison, London: Eyre and Spot-tiswoode, </author> <year> 1961. </year>
Reference: [20] <author> Kemeny, John G. </author> <title> The Need for Change: The Legacy of Three Mile Island. Report of the President's Commission on Three Mile Island, </title> <address> New York: </address> <publisher> Pergamon Press, </publisher> <year> 1979. </year>
Reference-contexts: Prior to the Three Mile Island accident, nuclear engineers took little interest in operator interface design. The Kemeny Commission's report on the accident concluded that the operator error was precipitated and compounded by basic flaws in system design <ref> [20] </ref>. The Vincennes (Iranian Airbus) incident is well known, but many other less-publicized accidents have occurred due to poor design of the human/computer interface. At one chemical plant in Britain, a computer printed a long list of alarms when a power failure occurred.
Reference: [21] <author> Kletz, T. </author> <title> Wise After the Event, </title> <journal> Control and Instrumentation, </journal> <volume> Vol. 20, No. 10, </volume> <month> October </month> <year> 1988, </year> <pages> pp. 57-59. </pages>
Reference-contexts: Instead, the operator watched the computer print the list of alarms and wondered what to do. The operator should not bear the responsibility alone here; if any person is overloaded with too much information, they are most likely to do nothing while they try to understand the situation <ref> [21] </ref>. A basic understanding of human psychology and behavior is a prerequisite for user interface design that is commonly missing from software engineering education.
Reference: [22] <author> Knight, J.C. and Leveson, N.G. </author> <title> An Experimental Evaluation of the Assumption of Independence in Multiversion Programming, </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> Vol. SE-12, No. 1, </volume> <month> January </month> <year> 1986, </year> <pages> pp. 96-109. </pages>
Reference-contexts: However, the few empirical studies performed on it did not test the underlying assumption of independence of failures and did not carefully analyze the data to determine whether ultra-high reliability was actually being achieved [23]. A series of experiments <ref> [6, 14, 22, 34] </ref> and a mathematical analysis [13] have cast doubt on these assumptions.
Reference: [23] <author> Knight, J.C. and Leveson, N.G. </author> <title> A Reply to the Criticisms of the Knight and Leveson Experiment, </title> <booktitle> Software Engineering Notes, </booktitle> <month> January, </month> <year> 1990. </year>
Reference-contexts: However, the few empirical studies performed on it did not test the underlying assumption of independence of failures and did not carefully analyze the data to determine whether ultra-high reliability was actually being achieved <ref> [23] </ref>. A series of experiments [6, 14, 22, 34] and a mathematical analysis [13] have cast doubt on these assumptions.
Reference: [24] <author> Leveson, N.G. and Turner, C.S. </author> <title> The Story Behind the Therac-25 Accidents: A Computer-Related Accident Investigation, </title> <note> submitted for publication. </note>
Reference: [25] <author> Millard, A.J. </author> <title> Edison and the Business of Innovation, </title> <publisher> Baltimore: Johns Hopkins University Press, </publisher> <year> 1990. </year>
Reference: [26] <author> Millard, A.J. </author> <title> A Technological Lag: Diffusion of Electrical Technology in England 1879-1914, </title> <address> New York: </address> <publisher> Garland Publishers, </publisher> <year> 1987. </year>
Reference-contexts: Such standards and licensing requirements must be carefully composed. The extensive regulation of high-voltage electricity distribution in Great Britain has been blamed for its slow adoption and the lag in electrical development compared to the U.S. <ref> [26] </ref>. For example, regulations that set a minimum standard of insulation were stricter than was necessary and were blamed for the high cost of installation. But many British engineers argued that although the extensive regulation increased the cost, it also lessened the danger of fire and injury. <p> As a group, British electrical engineers in the 1890's believed that lack of regulation in the U.S. had helped the development of the electrical industry at the cost of more accidents, which were "so common as to be part and parcel of the system" <ref> [26] </ref>. At the same time, British engineers were condemning Americans for their unsafe use and maintenance of steam boilers. Just as overly strict regulations unnecessarily inhibited electrical technology development in Britain in the last century, so poorly-written standards can inhibit the development of computer technology.
Reference: [27] <author> Parnas, </author> <title> D.L. Software Aspects of Strategic Defense Systems. </title> <journal> Communications of the ACM, </journal> <volume> Vol. 28, No. 12, </volume> <month> December </month> <year> 1985, </year> <pages> pp. 1326-1335. </pages>
Reference-contexts: We need to insist on the same level of evaluation and proof with regard to claims about software engineering techniques and tools. Unfortunately, this is rarely done and our belief in silver bullets persist. Even after Brooks' and Par-nas' carefully reasoned and widely-acclaimed papers <ref> [8, 27] </ref>, we are still seeing claims that the silver bullet has been found. I am not advocating that everyone stop the research they are doing in software engineering and start testing hypotheses and building foundations. Invention is a very important part of progress in engineering.
Reference: [28] <author> Parnas, </author> <title> D.L. Why Engineers Should Not Use Artificial Intelligence. </title> <booktitle> Proceedings of the CIPS Edmonton '87 Conference, </booktitle> <address> Edmonton, Alberta, </address> <month> November 16-19, </month> <year> 1987, </year> <note> published in J. </note> <editor> Schaef-fer and L. Stewart (eds.), </editor> <booktitle> Intelligence Integration, </booktitle> <institution> Dept. of Computing Science, University of Alberta, </institution> <address> p. </address> <pages> 39-42. </pages>
Reference-contexts: Then those suggesting the use of this technique would more likely be required to prove that the system acts like an expert instead of this being taken as an axiom. In fact, psychological studies and theory have suggested that human experts do not make decisions in this way (e.g., <ref> [31, 28] </ref>): Much more sophisticated types of problem-solving are involved. Related to proof by labeling is proof by definition, for example, defining fault tolerance as redundancy (another common practice) or defining safety as the use of protection (e.g., monitoring and shutdown) systems.
Reference: [29] <author> Passer, H. </author> <title> The Electrical Manufacturers, </title> <address> Cam-bridge, Mass.: </address> <publisher> Harvard University Press, </publisher> <year> 1953. </year>
Reference: [30] <author> Pursell, C.H. </author> <title> Early Stationary Steam Engines in America, </title> <address> Washington, D.C.: </address> <publisher> Smithsonian Institution Press, </publisher> <year> 1969. </year>
Reference: [31] <author> Rasmussen, J. </author> <title> Cognitive Control and Human Error Mechanisms, </title> <editor> in J. Rasmussen, K. Duncan, and J. Leplat (eds.), </editor> <title> New Technology and Human Error, </title> <address> New York: </address> <publisher> John Wiley & Sons, </publisher> <year> 1987. </year>
Reference-contexts: Then those suggesting the use of this technique would more likely be required to prove that the system acts like an expert instead of this being taken as an axiom. In fact, psychological studies and theory have suggested that human experts do not make decisions in this way (e.g., <ref> [31, 28] </ref>): Much more sophisticated types of problem-solving are involved. Related to proof by labeling is proof by definition, for example, defining fault tolerance as redundancy (another common practice) or defining safety as the use of protection (e.g., monitoring and shutdown) systems.
Reference: [32] <author> Robinson, E. and Musson, A.E. </author> <title> James Watt and the Steam Revolution, </title> <address> New York: </address> <publisher> Augustus M. Kelley, Publishers, </publisher> <year> 1969. </year>
Reference: [33] <author> Ruckelshaus, W.D. </author> <title> Risk, Science, </title> <editor> and Democracy, in T.S. Glickman and M. Gough, </editor> <booktitle> Readings in Risk. </booktitle> <address> Washington, D.C.: </address> <booktitle> Resources for the Future, </booktitle> <year> 1990. </year>
Reference: [34] <author> Scott, R.K., Gault, J.W., and McAllister, D.F. </author> <title> Fault-Tolerant Software Reliability Modeling, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol. SE-13, No. 5, </volume> <month> May </month> <year> 1987, </year> <pages> pp. 582-592. </pages>
Reference-contexts: However, the few empirical studies performed on it did not test the underlying assumption of independence of failures and did not carefully analyze the data to determine whether ultra-high reliability was actually being achieved [23]. A series of experiments <ref> [6, 14, 22, 34] </ref> and a mathematical analysis [13] have cast doubt on these assumptions.
Reference: [35] <author> Watts, S. </author> <title> Computer Watch on Nuclear Plant Raises Safety Fears, London Independent, </title> <address> Sun-day, Oct. 13, </address> <year> 1991. </year>
Reference: [36] <author> Weil, V. </author> <title> The Browns Ferry Case, </title> <editor> in M. Curd and L. May (eds.) </editor> <title> Professional Responsibility for Harmful Actions, </title> <address> Dubuque, Iowa: Kendall Hunt, </address> <year> 1984. </year>
Reference: [37] <author> Weyuker, E.J. </author> <title> Axiomatizing Software Test Data Adequacy, </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> Vol. SE-12, No. 12, </volume> <month> Dec </month> <year> 1986, </year> <pages> pp. 1128-1138. 12 </pages>
Reference-contexts: For example, testing researchers have defined theoretical ways of comparing testing strategies both in terms of cost and effectiveness (for example, [38]), formal criteria for evaluating testing strategies (for example, [16]), and axioms or properties that any adequacy criterion (rule to determine when testing can stop) should satisfy (for example, <ref> [37] </ref>). In general, theoretical foundations can provide (1) criteria for evaluation, (2) means of comparison, (3) theoretical limits and capabilities, (4) means of prediction, and (5) underlying rules, principles, and structure. How will we build this foundation? It will require both building mathematical models and theories and performing carefully-designed experiments.
Reference: [38] <author> Weyuker, E.J., Weiss, S., and Hamlet, D. </author> <title> Com--parison of Program Testing Strategies, </title> <booktitle> Proceedings of the Fourth Symposium on Software Testing, Analysis and Verification (TAV4), </booktitle> <address> Victoria, B.C., Canada, </address> <month> Oct </month> <year> 1991, </year> <pages> pp. 1-10. 13 </pages>
Reference-contexts: Testing is one such area, although they too have a long way to go. For example, testing researchers have defined theoretical ways of comparing testing strategies both in terms of cost and effectiveness (for example, <ref> [38] </ref>), formal criteria for evaluating testing strategies (for example, [16]), and axioms or properties that any adequacy criterion (rule to determine when testing can stop) should satisfy (for example, [37]).
References-found: 38

