URL: http://ftp.eecs.umich.edu/people/swlee/paper/CVPR97.ps
Refering-URL: http://ftp.eecs.umich.edu/people/swlee/paper/
Root-URL: http://www.eecs.umich.edu
Title: Using Chromaticity Distributions and Eigenspace for Pose-, Illumination-, and Specularity-Invariant 3D Object Recognition Categories: Low-level
Abstract: Object recognition is a central problem in computer vision. Difficulties arise in recognition when there are variations in geometric pose and illumination conditions, which can produce unpredictable effects on the appearance of an object. We propose an approach to recognition that describes objects using only chromaticity distributions, which are invariant to geometric and illumination pose. To characterize appearance with respect to illumination color, a set of chromaticity histograms is generated for different lighting colors and represented in a small number of eigen basis vectors constructed from principal components analysis. Represented in an eigenspace, chromaticity signatures for each object in the model database form a manifold encompassing a range of lighting colors. Recognition and illumination color estimation are performed by projecting the chromaticity signature of a test image into the eigenspace and examining its proximity to database manifolds. Since specular reflections may displace a projection away from its corresponding manifold, a refinement algorithm is developed to reduce this discrepancy. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> R. Bajcsy, S.W. Lee, and A. Leonardis. </editor> <title> Detection of diffuse and specular interface reflections and inter-reflections by color image segmentation. </title> <journal> IJCV, </journal> <volume> 17, </volume> <year> 1996. </year>
Reference-contexts: Strong specular reflections greatly affect the color distribution of an object, and the previous research in color recognition assumes the lack of strong specularity. Detection of specularity has been a topic of active research in the field of physics-based vision [11] [13] [2] [20] <ref> [1] </ref> [25] [19] [14]. However, most of this work deals with basic modeling and algorithm development. We develop a systematic method that couples specularity detection and object recognition. The following section describes a model of chromaticity distributions, and Section 3 outlines our method. <p> Sharp specularities are removed using polarization and structured lighting. Specular reflections may instead be eliminated manually or by using one of several previously-developed approaches [14] [13] <ref> [1] </ref> [19] [25]. Our recognition process is performed on single unprocessed snapshots of objects. Typically, the color distributions of an object are similar regardless of object rotation, so a single view is representative of the object's chromaticity characteristics.
Reference: [2] <author> G. Brelstaff and A. Blake. </author> <title> Detecting specular reflections using lambertain constraints. </title> <booktitle> In Proc. of IEEE Int. Conf. on Computer Vision, </booktitle> <pages> pages 297-302, </pages> <address> Tarpon Springs, FL, </address> <year> 1988. </year>
Reference-contexts: Strong specular reflections greatly affect the color distribution of an object, and the previous research in color recognition assumes the lack of strong specularity. Detection of specularity has been a topic of active research in the field of physics-based vision [11] [13] <ref> [2] </ref> [20] [1] [25] [19] [14]. However, most of this work deals with basic modeling and algorithm development. We develop a systematic method that couples specularity detection and object recognition. The following section describes a model of chromaticity distributions, and Section 3 outlines our method. <p> Prior to this refinement algorithm, preprocessing of the test image can be performed to eliminate sharper and more intense specular reflections, by using a method such as intensity and gradient method developed by Brelstaff and Blake <ref> [2] </ref>. We instead use simple intensity thresholding, which brings the test projection closer to the correct manifold as illustrated in Figure 4 (b). This step may result in an improved initial illumination estimation, which is based on the chromaticity parameters of the closest manifold point.
Reference: [3] <author> R.T. Chin and C.R. Dyer. </author> <title> Model-based recognition in robot vision. </title> <journal> ACM Computing Surveys, </journal> <volume> 18, </volume> <year> 1986. </year>
Reference-contexts: Most traditional object recognition work focuses on using geometric cues. They include approaches that use 3-D object shape models (often parametric) and feature-based methods <ref> [3] </ref> [10]. More recently, changes in appearance due to illumination and pose were included in object representations. This description con sists of an exhaustive image set of the object under different viewing conditions.
Reference: [4] <author> M. D'Zmura and G. Iverson. </author> <title> Color constancy. i. basic theory of two-stage linear recovery of spectral description for lights and surfaces. </title> <journal> JOSA, </journal> <volume> 10 </volume> <pages> 2148-2165, </pages> <year> 1993. </year>
Reference-contexts: The problem of discounting illumination color to obtain surface reflectance color is called color constancy in human and computer vision, and it has been the topic of much research in psychology and computer vision [12] [16] <ref> [4] </ref> [6] [5]. Despite significant progress in computational color constancy, color constancy algorithms have not demonstrated the levels of performance and generality that allow them to be applied systematically for a large number of object surfaces in a color image.
Reference: [5] <author> G. D. Finlayson, M. S. Drew, and B. V. Funt. </author> <title> Color constancy: Generalized diagonal transforms suffice. </title> <journal> JOSA, </journal> <volume> 11 </volume> <pages> 3011-3019, </pages> <year> 1994. </year>
Reference-contexts: The problem of discounting illumination color to obtain surface reflectance color is called color constancy in human and computer vision, and it has been the topic of much research in psychology and computer vision [12] [16] [4] [6] <ref> [5] </ref>. Despite significant progress in computational color constancy, color constancy algorithms have not demonstrated the levels of performance and generality that allow them to be applied systematically for a large number of object surfaces in a color image.
Reference: [6] <author> D. A. Forsyth. </author> <title> A novel approach to colour constancy. </title> <journal> IJCV, </journal> <volume> 5 </volume> <pages> 5-36, </pages> <year> 1990. </year>
Reference-contexts: The problem of discounting illumination color to obtain surface reflectance color is called color constancy in human and computer vision, and it has been the topic of much research in psychology and computer vision [12] [16] [4] <ref> [6] </ref> [5]. Despite significant progress in computational color constancy, color constancy algorithms have not demonstrated the levels of performance and generality that allow them to be applied systematically for a large number of object surfaces in a color image.
Reference: [7] <author> B. V. Funt and G. D. Finlayson. </author> <title> Color constant color indexing. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 17 </volume> <pages> 522-529, </pages> <year> 1995. </year>
Reference-contexts: Recently introduced color-based methods find illumination-invariant descriptors from color distributions without using full-blown color constancy algorithms. Funt and Finlayson <ref> [7] </ref> extended the color indexing approach to handle scenes with variations in illumination intensity and color. By histogramming on ratios of RGB values, they achieve a degree of color constancy that is relatively insensitive to illumination changes.
Reference: [8] <author> G.H. Healey and D. Slater. </author> <title> Global color constancy: Recognition of objects by use of illumination-invariant properties of color distributions. </title> <journal> JOSA, </journal> <volume> 11, </volume> <year> 1994. </year>
Reference-contexts: Healey et al. presented various methods based on the affine property of color distribution change. By assuming a finite-dimensional linear surface reflectance model, changes in illumination color result in a linear transformation of their feature representation, global color pixel distributions in RGB space <ref> [8] </ref> [22]. Their work has been extended to find local color features by restricting the spatial extent of regions in a color image.
Reference: [9] <author> B. K. P. Horn. </author> <title> Robot Vision. </title> <publisher> The MIT Press, </publisher> <address> Boston, MA, </address> <year> 1986. </year>
Reference-contexts: This compact representation of the chromaticity planes greatly reduces storage space and computation time. For each diagram, we used three projections, concatenated into a single vector, from which information up to second order moments are preserved <ref> [9] </ref>. More projections may be used if second order information is insufficient for discrimination among the database objects. The differencing operation remains the same as before, except that differencing is performed between vectors, rather than planes.
Reference: [10] <author> D.P. Huttenlocher and S. Ullman. </author> <title> Recognizing solid objects by alignment. </title> <journal> IJCV, </journal> <volume> 5, </volume> <year> 1990. </year>
Reference-contexts: Most traditional object recognition work focuses on using geometric cues. They include approaches that use 3-D object shape models (often parametric) and feature-based methods [3] <ref> [10] </ref>. More recently, changes in appearance due to illumination and pose were included in object representations. This description con sists of an exhaustive image set of the object under different viewing conditions.
Reference: [11] <author> G.J. Klinker, S.A. Shafer, and T. Kanade. </author> <title> A physical approach to color image understanding. </title> <journal> IJCV, </journal> <volume> 4, </volume> <year> 1990. </year>
Reference-contexts: Strong specular reflections greatly affect the color distribution of an object, and the previous research in color recognition assumes the lack of strong specularity. Detection of specularity has been a topic of active research in the field of physics-based vision <ref> [11] </ref> [13] [2] [20] [1] [25] [19] [14]. However, most of this work deals with basic modeling and algorithm development. We develop a systematic method that couples specularity detection and object recognition. The following section describes a model of chromaticity distributions, and Section 3 outlines our method.
Reference: [12] <author> E.H. Land and J. J. </author> <title> McCann. </title> <journal> Lightness and retinex theory. JOSA, </journal> <volume> 61 </volume> <pages> 1-11, </pages> <year> 1971. </year>
Reference-contexts: The problem of discounting illumination color to obtain surface reflectance color is called color constancy in human and computer vision, and it has been the topic of much research in psychology and computer vision <ref> [12] </ref> [16] [4] [6] [5]. Despite significant progress in computational color constancy, color constancy algorithms have not demonstrated the levels of performance and generality that allow them to be applied systematically for a large number of object surfaces in a color image.
Reference: [13] <author> S.W. Lee and R. </author> <title> Bajcsy. Detection of specularity using color and multiple views. </title> <journal> Image and Vision Computing, </journal> <volume> 10 </volume> <pages> 643-653, </pages> <year> 1992. </year>
Reference-contexts: Strong specular reflections greatly affect the color distribution of an object, and the previous research in color recognition assumes the lack of strong specularity. Detection of specularity has been a topic of active research in the field of physics-based vision [11] <ref> [13] </ref> [2] [20] [1] [25] [19] [14]. However, most of this work deals with basic modeling and algorithm development. We develop a systematic method that couples specularity detection and object recognition. The following section describes a model of chromaticity distributions, and Section 3 outlines our method. <p> Sharp specularities are removed using polarization and structured lighting. Specular reflections may instead be eliminated manually or by using one of several previously-developed approaches [14] <ref> [13] </ref> [1] [19] [25]. Our recognition process is performed on single unprocessed snapshots of objects. Typically, the color distributions of an object are similar regardless of object rotation, so a single view is representative of the object's chromaticity characteristics.
Reference: [14] <author> S. Lin and S.W. Lee. </author> <title> Detection of specularity using stereo in color and polarization space. </title> <publisher> In Press, </publisher> <address> CVIU, </address> <year> 1996. </year>
Reference-contexts: Strong specular reflections greatly affect the color distribution of an object, and the previous research in color recognition assumes the lack of strong specularity. Detection of specularity has been a topic of active research in the field of physics-based vision [11] [13] [2] [20] [1] [25] [19] <ref> [14] </ref>. However, most of this work deals with basic modeling and algorithm development. We develop a systematic method that couples specularity detection and object recognition. The following section describes a model of chromaticity distributions, and Section 3 outlines our method. <p> Sharp specularities are removed using polarization and structured lighting. Specular reflections may instead be eliminated manually or by using one of several previously-developed approaches <ref> [14] </ref> [13] [1] [19] [25]. Our recognition process is performed on single unprocessed snapshots of objects. Typically, the color distributions of an object are similar regardless of object rotation, so a single view is representative of the object's chromaticity characteristics.
Reference: [15] <author> L. T. Maloney. </author> <title> Evaluation of linear models of surface reflectance with small number of parameters. </title> <journal> JOSA, </journal> <volume> 3 </volume> <pages> 29-33, </pages> <year> 1986. </year>
Reference-contexts: The surface reflection function can be approximated by three basis functions <ref> [15] </ref>, referred to as S i and weighted by coefficients oe i for i = 0; 1; 2.
Reference: [16] <author> L. T. Maloney and B. A. Wandell. </author> <title> A computational model of color constancy. </title> <journal> JOSA, </journal> <volume> 1 </volume> <pages> 29-33, </pages> <year> 1986. </year>
Reference-contexts: The problem of discounting illumination color to obtain surface reflectance color is called color constancy in human and computer vision, and it has been the topic of much research in psychology and computer vision [12] <ref> [16] </ref> [4] [6] [5]. Despite significant progress in computational color constancy, color constancy algorithms have not demonstrated the levels of performance and generality that allow them to be applied systematically for a large number of object surfaces in a color image.
Reference: [17] <author> H. Murase and S.K. Nayar. </author> <title> Visual learning and recognition of 3-d objects from appearance. </title> <journal> IJCV, </journal> <volume> 14, </volume> <year> 1995. </year>
Reference-contexts: For efficient computation, these sets are represented as manifolds in an eigenspace, and test images are projected into this space for identification. Turk and Pentland [24] developed this approach for face recognition with different incident illumination angles. Murase and Nayar <ref> [17] </ref> have utilized this means of recognition for objects under a one-dimensional change in viewing angle. Lately, color distributions have been utilized as signatures for object recognition. It has been demonstrated that color can potentially be a strong cue. <p> The square of the Euclidean distance between two points in the eigenspace is an approximation to the sum of squared differences (SSD) between the histogram values of the two corresponding chromaticity planes <ref> [17] </ref>. SSD is a standard similarity measure between images, so a test projection that lies close to a manifold may indicate a match with the corresponding database object. 3 Chromaticity Recognition This section outlines the process of recognizing objects and also of determining the incident illumination color.
Reference: [18] <author> M. Nagao, T. Matsuyama, and Y. Ikeda. </author> <title> Region extraction and shape analysis in aerial images. </title> <journal> CGIP, </journal> <volume> 10(3) </volume> <pages> 195-223, </pages> <month> July </month> <year> 1979. </year>
Reference-contexts: Lately, color distributions have been utilized as signatures for object recognition. It has been demonstrated that color can potentially be a strong cue. The earliest approach for recognizing objects based on their color distributions was developed by Swain and Ballard and by Nagao et al. <ref> [18] </ref> [23]. Although this initial work does not address the problems of changing viewing conditions such as illumination intensity and color change, it introduced the usefulness of color in recognition.
Reference: [19] <author> S. K. Nayar, X. S. Fang, and T. Boult. </author> <title> Separation of reflection components using color and polarization. </title> <booktitle> In Proc. DARPA IU Workshop, </booktitle> <pages> pages 1049-1060, </pages> <address> Washington, DC, </address> <year> 1993. </year>
Reference-contexts: Strong specular reflections greatly affect the color distribution of an object, and the previous research in color recognition assumes the lack of strong specularity. Detection of specularity has been a topic of active research in the field of physics-based vision [11] [13] [2] [20] [1] [25] <ref> [19] </ref> [14]. However, most of this work deals with basic modeling and algorithm development. We develop a systematic method that couples specularity detection and object recognition. The following section describes a model of chromaticity distributions, and Section 3 outlines our method. <p> Sharp specularities are removed using polarization and structured lighting. Specular reflections may instead be eliminated manually or by using one of several previously-developed approaches [14] [13] [1] <ref> [19] </ref> [25]. Our recognition process is performed on single unprocessed snapshots of objects. Typically, the color distributions of an object are similar regardless of object rotation, so a single view is representative of the object's chromaticity characteristics.
Reference: [20] <author> S. K. Nayar, K. Ikeuchi, and T. Kanade. </author> <title> Determining shape and reflectance of hybrid surfaces by photometric sampling. </title> <journal> IEEE Trans. Robo. Au-tom., </journal> <volume> 6 </volume> <pages> 418-431, </pages> <year> 1990. </year>
Reference-contexts: Strong specular reflections greatly affect the color distribution of an object, and the previous research in color recognition assumes the lack of strong specularity. Detection of specularity has been a topic of active research in the field of physics-based vision [11] [13] [2] <ref> [20] </ref> [1] [25] [19] [14]. However, most of this work deals with basic modeling and algorithm development. We develop a systematic method that couples specularity detection and object recognition. The following section describes a model of chromaticity distributions, and Section 3 outlines our method.
Reference: [21] <author> S.K. Nayar and R.M. Bolle. </author> <title> Reflectance based object recognition. </title> <journal> IJCV, </journal> <volume> 17, </volume> <year> 1996. </year>
Reference-contexts: By histogramming on ratios of RGB values, they achieve a degree of color constancy that is relatively insensitive to illumination changes. Independently from Funt and Finlayson, Na-yar and Bolle also used reflectance ratios for object recognition <ref> [21] </ref>. Although these methods have been shown to perform better than color indexing for illumination changes, they use color information only where surface color varies. Moreover, reflectance ratios are often sensitive to noise, especially in areas of low intensity. <p> The uniform color restriction can be relaxed if a spatial window is used in an image for limiting the spatial extent of object surfaces for obtaining local color features. We assume that specularity is localized in space (specular spike) and does not occlude critical color signatures from diffuse reflections <ref> [21] </ref>. The color distribution is in general insensitive to partial occlusions since a color distribution signature is generated from a whole object surface. Even if a small part is rejected when specularity is removed, the same chromaticity can be provided from other parts of the surface.
Reference: [22] <author> D. Slater and G.H. Healey. </author> <title> Using spectral reflectance model for the illumination-invariant recognition of local image structure. </title> <booktitle> In Proc. CVPR, </booktitle> <pages> pages 770-775, </pages> <year> 1996. </year>
Reference-contexts: Healey et al. presented various methods based on the affine property of color distribution change. By assuming a finite-dimensional linear surface reflectance model, changes in illumination color result in a linear transformation of their feature representation, global color pixel distributions in RGB space [8] <ref> [22] </ref>. Their work has been extended to find local color features by restricting the spatial extent of regions in a color image.
Reference: [23] <author> M. J. Swain. </author> <title> Color indexing. </title> <journal> IJCV, </journal> <volume> 7 </volume> <pages> 11-32, </pages> <year> 1991. </year>
Reference-contexts: Lately, color distributions have been utilized as signatures for object recognition. It has been demonstrated that color can potentially be a strong cue. The earliest approach for recognizing objects based on their color distributions was developed by Swain and Ballard and by Nagao et al. [18] <ref> [23] </ref>. Although this initial work does not address the problems of changing viewing conditions such as illumination intensity and color change, it introduced the usefulness of color in recognition.
Reference: [24] <author> M.A. Turk and A. Pentland. </author> <title> Face recognition using eigenfaces. </title> <booktitle> In Proc. CVPR, </booktitle> <pages> pages 586-591, </pages> <year> 1991. </year>
Reference-contexts: This description con sists of an exhaustive image set of the object under different viewing conditions. For efficient computation, these sets are represented as manifolds in an eigenspace, and test images are projected into this space for identification. Turk and Pentland <ref> [24] </ref> developed this approach for face recognition with different incident illumination angles. Murase and Nayar [17] have utilized this means of recognition for objects under a one-dimensional change in viewing angle. Lately, color distributions have been utilized as signatures for object recognition.
Reference: [25] <author> L. B. Wolff. </author> <title> Using polarization to separate reflection components. </title> <booktitle> In Proc. of CVPR, </booktitle> <pages> pages 363-369, </pages> <address> San Diego, </address> <year> 1989. </year>
Reference-contexts: Strong specular reflections greatly affect the color distribution of an object, and the previous research in color recognition assumes the lack of strong specularity. Detection of specularity has been a topic of active research in the field of physics-based vision [11] [13] [2] [20] [1] <ref> [25] </ref> [19] [14]. However, most of this work deals with basic modeling and algorithm development. We develop a systematic method that couples specularity detection and object recognition. The following section describes a model of chromaticity distributions, and Section 3 outlines our method. <p> Sharp specularities are removed using polarization and structured lighting. Specular reflections may instead be eliminated manually or by using one of several previously-developed approaches [14] [13] [1] [19] <ref> [25] </ref>. Our recognition process is performed on single unprocessed snapshots of objects. Typically, the color distributions of an object are similar regardless of object rotation, so a single view is representative of the object's chromaticity characteristics.
References-found: 25

