URL: http://www.aic.nrl.navy.mil/~gordon/papers/foga94.ps
Refering-URL: http://www.aic.nrl.navy.mil/~gordon/pubs.html
Root-URL: 
Email: E-mail: kdejong@gmu.edu  E-mail: spears,gordon@aic.nrl.navy.mil  
Title: Using Markov Chains to Analyze GAFOs  
Author: Kenneth A. De Jong William M. Spears Diana F. Gordon 
Address: Fairfax, VA 22030  Code 5510  Washington, D.C. 20375-5320  
Affiliation: Computer Science Department George Mason University  Navy Center for Applied Research in Artificial Intelligence  Naval Research Laboratory  
Abstract: Our theoretical understanding of the properties of genetic algorithms (GAs) being used for function optimization (GAFOs) is not as strong as we would like. Traditional schema analysis provides some first order insights, but doesn't capture the non-linear dynamics of the GA search process very well. Markov chain theory has been used primarily for steady state analysis of GAs. In this paper we explore the use of transient Markov chain analysis to model and understand the behavior of finite population GAFOs observed while in transition to steady states. This approach appears to provide new insights into the circumstances under which GAFOs will (will not) perform well. Some preliminary results are presented and an initial evaluation of the merits of this approach is provided. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Davis, T. E., & Principe, J. C. </author> <title> (1991) A simulated annealing like convergence theory for the simple genetic algorithm. </title> <booktitle> Proceedings of the 4th International Conference on Genetic Algorithms, </booktitle> <address> San Diego, </address> <pages> 174-181. </pages>
Reference: <author> De Jong, K. A. </author> <title> (1992) GAs are not function optimizers. </title> <booktitle> Proceedings of the Foundations of Genetic Algorithms Workshop. </booktitle> <address> Vail, </address> <publisher> CO: Morgan Kaufmann. </publisher>
Reference-contexts: 1 INTRODUCTION At the previous FOGA workshop the claim was made that our theoretical understanding of the properties of genetic algorithms (GAs) being used for function optimization (i.e., GAFOs) was quite weak <ref> (De Jong, 1992) </ref>. Traditional schema analysis provides insight into the optimal allocation of trials when maximizing cumulative profits is the goal (Holland, 1975), but doesn't say much about global function optimization.
Reference: <author> De Jong, K. A. </author> <title> (1975) An analysis of the behavior of a class of genetic adaptive systems. </title> <type> Doctoral Thesis, </type> <institution> Department of Computer and Communication Sciences. University of Michigan, </institution> <address> Ann Arbor. </address>
Reference: <author> Goldberg, D. E. </author> <title> (1987) Simple genetic algorithms and the minimal, deceptive problem. Chapter 6 in Genetic Algorithms and Simulated Annealing, </title> <editor> Lawrence Davis (ed.), </editor> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Static analysis of functions regarding their ``deceptiveness'' provides some insights into what kinds of functions are difficult to optimize with a GA <ref> (Goldberg, 1987) </ref>, but is a ``first order'' theory in the sense that it doesn't include the effects of the non-linear dynamics of the GA search process. <p> It is easy to show that none of these three equivalence classes obtained by permuting the values -1,2,3,4- are ``deceptive'' in the sense of static schema analysis <ref> (Goldberg, 1987) </ref> as indicated in table 3. However, note that while a GA is uniformly better than random search on the first two equivalence classes, its probability curves are actually worse than random search on class 3 in the early generations.
Reference: <author> Goldberg, D. E., & Segrest, P., </author> <title> (1987) Finite Markov chain analysis of genetic algorithms. </title> <booktitle> Proceedings of the 2nd International Conference on Genetic Algorithms, </booktitle> <address> Cambridge, </address> <pages> 1-8. </pages>
Reference-contexts: Static analysis of functions regarding their ``deceptiveness'' provides some insights into what kinds of functions are difficult to optimize with a GA <ref> (Goldberg, 1987) </ref>, but is a ``first order'' theory in the sense that it doesn't include the effects of the non-linear dynamics of the GA search process. <p> It is easy to show that none of these three equivalence classes obtained by permuting the values -1,2,3,4- are ``deceptive'' in the sense of static schema analysis <ref> (Goldberg, 1987) </ref> as indicated in table 3. However, note that while a GA is uniformly better than random search on the first two equivalence classes, its probability curves are actually worse than random search on class 3 in the early generations.
Reference: <author> Holland, J. H. </author> <booktitle> (1975) Adaptation in natural and artifi cial systems. </booktitle> <address> Ann Arbor, Michigan: </address> <publisher> The University of Michigan Press. </publisher>
Reference-contexts: Traditional schema analysis provides insight into the optimal allocation of trials when maximizing cumulative profits is the goal <ref> (Holland, 1975) </ref>, but doesn't say much about global function optimization.
Reference: <author> Horn, J. </author> <title> (1993) Finite Markov chain analysis of genetic algorithms with niching. </title> <booktitle> Proceedings of the 5th International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann, </publisher> <pages> 110-117. </pages>
Reference: <author> Horn, J., Goldberg, D. E., & Deb, K., </author> <title> (1994) Implicit niching in a learning classifier system: nature's way. </title> <journal> Evolutionary Computation, </journal> <volume> Volume 2, #1, </volume> <pages> 37-66. </pages>
Reference: <author> Juliany, J., & Vose, M. D., </author> <title> (1994) The genetic algorithm fractal. </title> <booktitle> To appear in Evolutionary Computation, </booktitle> <volume> Volume 2, </volume> <pages> #1. </pages>
Reference: <author> Manderick, B., de Weger, M., & Spiessens, P., </author> <title> (1991) The genetic algorithm and the structure of the fitness landscape. </title> <booktitle> Proceedings of the 4th International Conference on Genetic Algorithms, </booktitle> <address> San Diego, </address> <pages> 143-150. </pages>
Reference-contexts: It is also possible to study the effects of other operators (e.g., uniform crossover) and other GA features such as population size, rank selection, and so on. It would also be nice to see how well fitness correlation <ref> (Manderick et al., 1991) </ref>, which takes into account aspects of the fitness function, representation, and the genetic operators, predicts EWT performance.
Reference: <author> Mafoud, S. </author> <title> (1993) Finite Markov chain models of an alternative selection strategy for the genetic algorithm. </title> <journal> Complex Systems, </journal> <volume> 7 (2), </volume> <pages> 155-170. </pages>
Reference: <author> Nix, A. E., & Vose, M. D., </author> <title> (1992) Modelling genetic algorithms with Markov chains. </title> <journal> Annals of Mathematics and Artificial Intelligence #5, </journal> <volume> 79 - 88. </volume>
Reference-contexts: A bright diagonal line is clearly visible, indicating that significant changes in the population in one generation are very unlikely. Also, notice the interesting fractal-like patterns exhibited. This appears to be an artifact of the particular lexicographic ordering of states <ref> (given by Nix and Vose, 1992) </ref>. We are currently exploring other potentially more natural orderings. As one scans the images from left to right, notice that the changes in the probability distribution are already evident in Q 4 and quite striking in Q 10 .
Reference: <author> Rudolph, G. </author> <title> (1994) Massively parallel simulated annealing and its relation to evolutionary algorithms. </title> <journal> Evolutionary Computation, </journal> <volume> Volume 1, </volume> <pages> #4. </pages>
Reference: <author> Suzuki, J. </author> <title> (1993) A Markov chain analysis on a genetic algorithm. </title> <booktitle> Proceedings of the 5th International Conference on Genetic Algorithms, Urbana-Champaign, </booktitle> <pages> 146-153. </pages>
Reference: <editor> Vose, M. </editor> <booktitle> (1992) Modeling simple genetic algorithms. Proceedings of the Foundations of Genetic Algorithms Workshop, </booktitle> <address> Vail, </address> <publisher> CO: Morgan Kaufmann, </publisher> <pages> 63-74. </pages>
Reference-contexts: A bright diagonal line is clearly visible, indicating that significant changes in the population in one generation are very unlikely. Also, notice the interesting fractal-like patterns exhibited. This appears to be an artifact of the particular lexicographic ordering of states <ref> (given by Nix and Vose, 1992) </ref>. We are currently exploring other potentially more natural orderings. As one scans the images from left to right, notice that the changes in the probability distribution are already evident in Q 4 and quite striking in Q 10 .
Reference: <author> Whitley, D. </author> <title> (1992) An executable model of a simple genetic algorithm, </title> <booktitle> Proceedings of the Foundations of Genetic Algorithms Workshop, </booktitle> <address> Vail, </address> <publisher> CO: Morgan Kaufmann, </publisher> <pages> 45-62. </pages>
Reference-contexts: P9 1 1 0 0 L L L L L L LL L L L L L L L L L L L L Table 1: The Z matrix when n = 2 and l = 2. ____________ ______ This approach is similar in spirit to Whitley's executable GA models <ref> (Whitley, 1992) </ref>. For programming convenience we transpose the Z matrix of Nix and Vose (1992).
Reference: <author> Winston, W. </author> <title> (1991) Operations Research: Applications and Algorithms, 2nd Edition, </title> <publisher> PWS-Kent Publishing Company, </publisher> <address> Boston MA. </address>
Reference-contexts: questions. 6.1 Expected Waiting Time Theory The theory extension needed to obtain the expected waiting time until an event of interest is first observed is based on the observation that the Q matrix can be used to compute ``mean first passage times'' for going from state i to state j <ref> (for a nice discussion of this, see Winston 1991) </ref>. Questions involving waiting times to convergence using a 1-bit Markov model with mutation and selection were considered in the paper by Goldberg and Segrest (1987). Our work extends these earlier formulations.
References-found: 17

