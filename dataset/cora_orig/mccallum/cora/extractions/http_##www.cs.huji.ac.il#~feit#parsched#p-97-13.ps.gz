URL: http://www.cs.huji.ac.il/~feit/parsched/p-97-13.ps.gz
Refering-URL: http://www.cs.huji.ac.il/~feit/parsched/parsched97.html
Root-URL: http://www.cs.huji.ac.il
Email: wang-fang@cs.yale.edu  marios@eecs.umich.edu  mss@watson.ibm.com  
Title: Performance Evaluation of Gang Scheduling for Parallel and Distributed Multiprogramming  
Author: Fang Wang Marios Papaefthymiou Mark Squillante 
Address: New Haven, CT 06520  Ann Arbor, MI 48109  Yorktown Heights, NY 10598  
Affiliation: Department of Computer Science Yale University  Department of Electrical Engineering and Computer Science University of Michigan  T.J. Watson Research Center IBM Research Division  
Abstract: This paper compares the performance of various gang scheduling schemes with a version of LoadLeveler that uses backfilling. We developed an event-driven simulator of a vanilla gang scheduler that relies on the Distributed Hierarchical Control (DHC) structure. We also developed two variations of the vanilla gang scheduler that rely on a push-down heuristic and on a job-migration scheme to decrease response times by reducing processor idle time. We evaluated the gang schedulers on a compiled, one-week long history of jobs from the Cornell Theory Center. Our results demonstrate the significant performance improvements that can be achieved with gang scheduling. They also reveal, however, a number of important gang scheduling issues under certain workload conditions that must be addressed by gang scheduling strategies in practice. We identify several approaches for addressing these issues, and present evidence for the potential benefits of some of these methods. Our techniques include heuristics for mapping jobs to processors and for choosing time quanta, block paging for reducing memory overheads, and the allocation of multiple time-slices per timeplexing cycle to smaller jobs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Beretvas and W. H. Tetzlaff. </author> <title> Paging enhancements in VM/SP HPO 3.4. </title> <type> Technical Report TB GG22-9467, </type> <institution> IBM Washington Syst. Center, </institution> <month> May </month> <year> 1984. </year>
Reference-contexts: We now discuss a particular strategy to significantly reduce and effectively eliminate these overheads for a general class of large-scale parallel applications. Our approach is based in part on the concept of block paging, which was introduced in the VM/SP HPO operating system <ref> [1, 25, 26] </ref> and extended in the 189 scheduler with jobs assigned from the root, and the migration scheduler with job assigned from the leaves. Quanta are allocated uniformly, and the context-switch cost for each class is 1 sec. 190 from the root, and the job-migration policy from the leaves. <p> A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to <ref> [1, 23, 24, 25, 26, 27, 28] </ref> for additional technical details. We then discuss our approach for addressing memory and paging overheads in large-scale parallel time-sharing systems, which is based on the VM mechanisms and extensions tailored to the parallel computing environments of interest.
Reference: [2] <author> D. L. Eager, J. Zahorjan, and E. D. Lazowska. </author> <title> Speedup versus efficiency in parallel systems. </title> <journal> IEEE Trans. Comp., </journal> <volume> 38 </volume> <pages> 408-423, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: A job may not require the attention of the entire system, however. Moreover, abundant empirical evidence indicates that program dependencies and communication costs may limit the degree of achievable parallelism (e.g., <ref> [2, 16] </ref>). In these situations, space-sharing can increase throughput by partitioning resources and reducing the underutiliza-tion of system partitions.
Reference: [3] <author> D. G. Feitelson. </author> <title> Packing schemes for gang scheduling. In Job Sched. Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pages 89-110. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> LNCS Vol. 1162. </note>
Reference-contexts: The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22]. Moreover, the performance of several gang scheduling algorithms has been studied by simulation on synthetically generated workloads <ref> [3, 7] </ref>. In this paper we present an empirical evaluation of gang scheduling based on an actual parallel workload. Our focus is on the distributed hierarchical control approach to gang scheduling, although many of the principles and trends observed in this study are relevant to other forms of gang scheduling. <p> We have been working on a tree-packing scheme that exploits parasite allocations (somewhat similar to the alternative scheduling in <ref> [3] </ref>) by assigning jobs to partitions in the tree that maximize the number of processors kept busy throughout the timeplexing cycle. Much like the migration scheme, this approach uses a priority-based mechanism for choosing among multiple assign ments that are equal with respect to keeping processors busy.
Reference: [4] <author> D. G. Feitelson and L. Rudolph. </author> <title> Distributed hierarchical control for parallel processing. </title> <booktitle> Computer, </booktitle> <pages> pages 65-77, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Gang scheduling encompasses a very broad range of schedulers depending on the particular schemes used for partitioning resources and for sharing resources within each partition. One particular approach is based on the distributed hierarchical control structure <ref> [4, 5, 6] </ref>. <p> A somewhat different approach, which can be conceptually viewed as a generalization of Ousterhout's original global scheduling matrix, has also been considered [13, 14]. Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure <ref> [4, 5, 6] </ref> have been implemented for the IBM SP2 [8, 30] and for clusters of workstations [9, 29]. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14]. <p> Our focus is on the distributed hierarchical control approach to gang scheduling, although many of the principles and trends observed in this study are relevant to other forms of gang scheduling. Our study includes an examination of a vanilla gang scheduling scheme <ref> [4, 21] </ref> and two variations of this scheme that use push-down and job-migration heuristics to increase system throughput and decrease response times by minimizing idle partitions.
Reference: [5] <author> D. G. Feitelson and L. Rudolph. </author> <title> Mapping and scheduling in a shared parallel environment using distributed hierarchical control. </title> <booktitle> In Proc. International Conf. Parallel Processing, </booktitle> <volume> volume I, </volume> <pages> pages 1-8, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: Gang scheduling encompasses a very broad range of schedulers depending on the particular schemes used for partitioning resources and for sharing resources within each partition. One particular approach is based on the distributed hierarchical control structure <ref> [4, 5, 6] </ref>. <p> A somewhat different approach, which can be conceptually viewed as a generalization of Ousterhout's original global scheduling matrix, has also been considered [13, 14]. Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure <ref> [4, 5, 6] </ref> have been implemented for the IBM SP2 [8, 30] and for clusters of workstations [9, 29]. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14].
Reference: [6] <author> D. G. Feitelson and L. Rudolph. </author> <title> Gang scheduling performance benefits for fine-grain synchronization. </title> <journal> J. Parallel and Distr. Comp., </journal> <volume> 16(4) </volume> <pages> 306-318, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: Gang scheduling encompasses a very broad range of schedulers depending on the particular schemes used for partitioning resources and for sharing resources within each partition. One particular approach is based on the distributed hierarchical control structure <ref> [4, 5, 6] </ref>. <p> A somewhat different approach, which can be conceptually viewed as a generalization of Ousterhout's original global scheduling matrix, has also been considered [13, 14]. Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure <ref> [4, 5, 6] </ref> have been implemented for the IBM SP2 [8, 30] and for clusters of workstations [9, 29]. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14].
Reference: [7] <author> D. G. Feitelson and L. Rudolph. </author> <title> Evaluation of design choices for gang scheduling using distributed hierarchical control. </title> <journal> J. Parallel and Distr. Comp., </journal> <volume> 35 </volume> <pages> 18-34, </pages> <year> 1996. </year>
Reference-contexts: The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22]. Moreover, the performance of several gang scheduling algorithms has been studied by simulation on synthetically generated workloads <ref> [3, 7] </ref>. In this paper we present an empirical evaluation of gang scheduling based on an actual parallel workload. Our focus is on the distributed hierarchical control approach to gang scheduling, although many of the principles and trends observed in this study are relevant to other forms of gang scheduling.
Reference: [8] <author> H. Franke, P. Pattnaik, and L. Rudolph. </author> <title> Gang scheduling for highly efficient distributed multiprocessor systems. </title> <booktitle> In Proc. </booktitle> <address> Frontiers'96, </address> <year> 1996. </year>
Reference-contexts: Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM SP2 <ref> [8, 30] </ref> and for clusters of workstations [9, 29]. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14]. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22].
Reference: [9] <author> A. Hori, H. Tezuka, Y. Ishikawa, N. Soda, H. Konaka, and M. Maeda. </author> <title> Implementation of gang-scheduling on workstation cluster. In Job Sched. Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pages 126-139. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> LNCS Vol. 1162. </note>
Reference-contexts: Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM SP2 [8, 30] and for clusters of workstations <ref> [9, 29] </ref>. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14]. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22].
Reference: [10] <author> S. G. Hotovy. </author> <title> Workload evolution on the Cornell Theory Center IBM SP2. In Job Sched. Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pages 27-40. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> LNCS Vol. 1162. </note>
Reference-contexts: These scheduling strategies are simulated under a workload that we obtained by post-processing a trace of the workload characteristics for one week at the Cornell Theory Center <ref> [10, 11, 12] </ref>. The original workload was scheduled on a subset of the SP2 at Cornell's Theory Center using EASY-LL, an enhanced version of the ba sic LoadLeveler scheduler that uses backfilling to reduce the response times of jobs with small resource requirements [20].
Reference: [11] <author> S. G. Hotovy. </author> <type> Personal communication. </type> <year> 1997. </year>
Reference-contexts: These scheduling strategies are simulated under a workload that we obtained by post-processing a trace of the workload characteristics for one week at the Cornell Theory Center <ref> [10, 11, 12] </ref>. The original workload was scheduled on a subset of the SP2 at Cornell's Theory Center using EASY-LL, an enhanced version of the ba sic LoadLeveler scheduler that uses backfilling to reduce the response times of jobs with small resource requirements [20]. <p> The timeplexing cycle, which is given on the x-axis, was divided uniformly among the system's nine classes. We arrived at the worst-case context-switch cost of 16 seconds by assuming that the jobs have a 64MB working set on each processor <ref> [11] </ref> which must be loaded in its entirety at the rate of 1 page/millisecond with 4KB/page, given the characteristics of many parallel scientific applications [19] and the (potentially) large degree of multi programming with 9 classes.
Reference: [12] <author> S. G. Hotovy, D. J. Schneider, and T. O'Donnell. </author> <title> Analysis of the early workload on the Cornell Theory Center IBM SP2. </title> <booktitle> In Proc. ACM SIGMETRICS Conf. Measurement and Modeling of Comp. Syst., </booktitle> <pages> pages 272-273, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: These scheduling strategies are simulated under a workload that we obtained by post-processing a trace of the workload characteristics for one week at the Cornell Theory Center <ref> [10, 11, 12] </ref>. The original workload was scheduled on a subset of the SP2 at Cornell's Theory Center using EASY-LL, an enhanced version of the ba sic LoadLeveler scheduler that uses backfilling to reduce the response times of jobs with small resource requirements [20].
Reference: [13] <author> N. Islam, A. Prodromidis, M. S. Squillante, L. L. Fong, and A. S. Gopal. </author> <title> Extensible resource mangement for cluster computing. </title> <booktitle> In Proc. International Conf. Distr. Comp. Syst., </booktitle> <month> May </month> <year> 1997. </year>
Reference-contexts: A somewhat different approach, which can be conceptually viewed as a generalization of Ousterhout's original global scheduling matrix, has also been considered <ref> [13, 14] </ref>. Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM SP2 [8, 30] and for clusters of workstations [9, 29]. <p> Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM SP2 [8, 30] and for clusters of workstations [9, 29]. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations <ref> [13, 14] </ref>. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22]. Moreover, the performance of several gang scheduling algorithms has been studied by simulation on synthetically generated workloads [3, 7].
Reference: [14] <author> N. Islam, A. Prodromidis, M. S. Squillante, A. S. Gopal, and L. L. Fong. </author> <title> Extensible resource scheduling for parallel scientific applications. </title> <booktitle> In Proc. Eighth SIAM Conf. Parallel Processing for Scientific Comp., </booktitle> <month> March </month> <year> 1997. </year>
Reference-contexts: A somewhat different approach, which can be conceptually viewed as a generalization of Ousterhout's original global scheduling matrix, has also been considered <ref> [13, 14] </ref>. Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM SP2 [8, 30] and for clusters of workstations [9, 29]. <p> Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM SP2 [8, 30] and for clusters of workstations [9, 29]. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations <ref> [13, 14] </ref>. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22]. Moreover, the performance of several gang scheduling algorithms has been studied by simulation on synthetically generated workloads [3, 7].
Reference: [15] <author> T. Kimbrel, A. Tomkins, R. H. Patterson, B. Bershad, P. Cao, E. W. Felten, G. A. Gibson, A. R. Karlin, and K. Li. </author> <title> A trace-driven comparison of algorithms for parallel prefetching and caching. </title> <booktitle> In Proc. USENIX Symp. Operating Syst. Design and Implementation (OSDI), </booktitle> <pages> pages 19-34, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: The context-switch costs are 1 sec for the top and 16 sec for the bottom chart. VM/ESA operating system [23, 24]. A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature <ref> [15, 17] </ref>. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to [1, 23, 24, 25, 26, 27, 28] for additional technical details.
Reference: [16] <author> V. M. Lo. </author> <title> Heuristic algorithms for task assignment in distributed systems. </title> <journal> IEEE Trans. Comp., </journal> <volume> 37(11) </volume> <pages> 1384-1397, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: A job may not require the attention of the entire system, however. Moreover, abundant empirical evidence indicates that program dependencies and communication costs may limit the degree of achievable parallelism (e.g., <ref> [2, 16] </ref>). In these situations, space-sharing can increase throughput by partitioning resources and reducing the underutiliza-tion of system partitions.
Reference: [17] <author> T. C. Mowry, A. K. Demke, and O. Krieger. </author> <title> Automatic compiler-inserted I/O prefetching for out-of-core applications. </title> <booktitle> In Proc. USENIX Symp. Operating Syst. Design and Implem. (OSDI), </booktitle> <pages> pages 3-17, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: The context-switch costs are 1 sec for the top and 16 sec for the bottom chart. VM/ESA operating system [23, 24]. A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature <ref> [15, 17] </ref>. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to [1, 23, 24, 25, 26, 27, 28] for additional technical details.
Reference: [18] <author> J. K. Ousterhout. </author> <title> Scheduling techniques for concurrent Syst.. </title> <booktitle> In Proc. Third International Conf. Distr. Comp. Syst., </booktitle> <pages> pages 22-30, </pages> <month> October </month> <year> 1982. </year>
Reference-contexts: Gang scheduling is a flexible scheduling scheme that combines time-sharing and space-sharing with the goal of providing the advantages of both approaches, including high system throughput and low response times for short-running jobs. The roots of gang scheduling can be traced back to the coscheduling concept described in <ref> [18] </ref>. This two-dimensional division (in time and space) of resources among jobs can be easily viewed as having the resource allocations governed by a scheduling matrix, where each column represents a specific processor and each row represents a particular time-slice, or quantum.
Reference: [19] <author> V. G. Peris, M. S. Squillante, and V. K. Naik. </author> <title> Analysis of the impact of memory in distributed parallel processing systems. </title> <booktitle> In Proc. ACM SIGMETRICS Conf. Measurement and Modeling of Comp. Syst., </booktitle> <pages> pages 5-18, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: We arrived at the worst-case context-switch cost of 16 seconds by assuming that the jobs have a 64MB working set on each processor [11] which must be loaded in its entirety at the rate of 1 page/millisecond with 4KB/page, given the characteristics of many parallel scientific applications <ref> [19] </ref> and the (potentially) large degree of multi programming with 9 classes. Our results show that for jobs with large resource requirements, the gang scheduling policies achieve shorter response times than EASY-LL. <p> There are two basic approaches to address the performance issues related to the memory management component of large-scale parallel environments in general <ref> [19] </ref>, and especially in systems that time-share their resources. One approach consists of allocating jobs to partitions such that the memory requirements of all jobs on each node of the partition fit within the memory available on that node, thus avoiding the memory overhead problem. <p> As soon as the page is brought into memory, the system returns to the execution of this job and the remaining pages of the block are brought into memory in parallel with the execution of the job. Given the memory reference characteristics of many scientific applications <ref> [19] </ref>, the operating system can continue to bring into memory a number of page blocks that are chained to the faulting page block based on time (and space) affinity.
Reference: [20] <author> J. Skovira, W. Chan, H. Zhou, and D. Lifka. </author> <title> The EASY-LoadLeveler API project. In Job Sched. Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pages 41-47. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> LNCS Vol. 1162. </note>
Reference-contexts: The original workload was scheduled on a subset of the SP2 at Cornell's Theory Center using EASY-LL, an enhanced version of the ba sic LoadLeveler scheduler that uses backfilling to reduce the response times of jobs with small resource requirements <ref> [20] </ref>.
Reference: [21] <author> M. S. Squillante, F. Wang, and M. Papaefthymiou. </author> <title> An analysis of gang scheduling for multiprogrammed parallel computing environments. </title> <booktitle> In Proc. Annual ACM Symp. Parallel Algorithms and Architectures (SPAA), </booktitle> <pages> pages 89-98, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14]. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective <ref> [21, 22] </ref>. Moreover, the performance of several gang scheduling algorithms has been studied by simulation on synthetically generated workloads [3, 7]. In this paper we present an empirical evaluation of gang scheduling based on an actual parallel workload. <p> Our focus is on the distributed hierarchical control approach to gang scheduling, although many of the principles and trends observed in this study are relevant to other forms of gang scheduling. Our study includes an examination of a vanilla gang scheduling scheme <ref> [4, 21] </ref> and two variations of this scheme that use push-down and job-migration heuristics to increase system throughput and decrease response times by minimizing idle partitions. <p> We have used, and continue to use, an analytic approach <ref> [21, 22] </ref> to gain insights into this problem with which heuristics can be developed for practical gang scheduling policies. One resulting heuristic is based on the relative utilization of the resources by each class. <p> We are currently studying such approaches in more detail. Another important aspect of quanta allocation was also observed based upon our queueing-theoretic gang scheduling analysis <ref> [21, 22] </ref>. In particular, the setting of these policy parameters in gang scheduling systems must address the complex tradeoff between providing preferential treatment to short-running jobs via small quanta lengths at the expense of larger delays for long-running jobs.
Reference: [22] <author> M. S. Squillante, F. Wang, and M. Papaefthymiou. </author> <title> Stochastic analysis of gang scheduling in parallel and distributed Syst.. </title> <booktitle> Perf. Eval., </booktitle> 27&28:273-296, 1996. 
Reference-contexts: Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14]. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective <ref> [21, 22] </ref>. Moreover, the performance of several gang scheduling algorithms has been studied by simulation on synthetically generated workloads [3, 7]. In this paper we present an empirical evaluation of gang scheduling based on an actual parallel workload. <p> We have used, and continue to use, an analytic approach <ref> [21, 22] </ref> to gain insights into this problem with which heuristics can be developed for practical gang scheduling policies. One resulting heuristic is based on the relative utilization of the resources by each class. <p> We are currently studying such approaches in more detail. Another important aspect of quanta allocation was also observed based upon our queueing-theoretic gang scheduling analysis <ref> [21, 22] </ref>. In particular, the setting of these policy parameters in gang scheduling systems must address the complex tradeoff between providing preferential treatment to short-running jobs via small quanta lengths at the expense of larger delays for long-running jobs.
Reference: [23] <author> W. H. Tetzlaff. </author> <title> Paging in the VM/XA system product. </title> <journal> CMG Trans., </journal> <volume> 66 </volume> <pages> 55-64, </pages> <year> 1989. </year>
Reference-contexts: Quanta are allocated uniformly, and a worst-case context-switch cost of 16 sec is assumed for each class. 191 the two job-migration policies with a timeplexing cycle equal to 900 sec. The context-switch costs are 1 sec for the top and 16 sec for the bottom chart. VM/ESA operating system <ref> [23, 24] </ref>. A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. <p> A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to <ref> [1, 23, 24, 25, 26, 27, 28] </ref> for additional technical details. We then discuss our approach for addressing memory and paging overheads in large-scale parallel time-sharing systems, which is based on the VM mechanisms and extensions tailored to the parallel computing environments of interest. <p> For example, it is shown in <ref> [23, 24] </ref> that the delay to fetch a single page from a particular IBM 3380 disk configuration is 29ms, whereas the delay to fetch 10 pages from a simpler 3380 configuration is 48ms. <p> As a specific example, the average block size on VM systems is between 9 and 12 pages with a range of 2 to 20 pages <ref> [23, 24] </ref>. When a page is fetched from disk as part of a block and is never referenced during the block's residence in memory, then the VM algorithms subsequently eliminate the page from the block. In certain cases, the system also chains together related page blocks for additional optimizations.
Reference: [24] <author> W. H. Tetzlaff. </author> <title> Paging in VM/ESA. </title> <booktitle> In Proc. CMG'91 Conf., </booktitle> <pages> pages 723-734, </pages> <year> 1991. </year>
Reference-contexts: Quanta are allocated uniformly, and a worst-case context-switch cost of 16 sec is assumed for each class. 191 the two job-migration policies with a timeplexing cycle equal to 900 sec. The context-switch costs are 1 sec for the top and 16 sec for the bottom chart. VM/ESA operating system <ref> [23, 24] </ref>. A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. <p> A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to <ref> [1, 23, 24, 25, 26, 27, 28] </ref> for additional technical details. We then discuss our approach for addressing memory and paging overheads in large-scale parallel time-sharing systems, which is based on the VM mechanisms and extensions tailored to the parallel computing environments of interest. <p> For example, it is shown in <ref> [23, 24] </ref> that the delay to fetch a single page from a particular IBM 3380 disk configuration is 29ms, whereas the delay to fetch 10 pages from a simpler 3380 configuration is 48ms. <p> As a specific example, the average block size on VM systems is between 9 and 12 pages with a range of 2 to 20 pages <ref> [23, 24] </ref>. When a page is fetched from disk as part of a block and is never referenced during the block's residence in memory, then the VM algorithms subsequently eliminate the page from the block. In certain cases, the system also chains together related page blocks for additional optimizations.
Reference: [25] <author> W. H. Tetzlaff and T. Beretvas. </author> <title> Paging in VM/370 operating systems. </title> <journal> CMG Trans., </journal> <volume> 53 </volume> <pages> 65-76, </pages> <year> 1986. </year>
Reference-contexts: We now discuss a particular strategy to significantly reduce and effectively eliminate these overheads for a general class of large-scale parallel applications. Our approach is based in part on the concept of block paging, which was introduced in the VM/SP HPO operating system <ref> [1, 25, 26] </ref> and extended in the 189 scheduler with jobs assigned from the root, and the migration scheduler with job assigned from the leaves. Quanta are allocated uniformly, and the context-switch cost for each class is 1 sec. 190 from the root, and the job-migration policy from the leaves. <p> A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to <ref> [1, 23, 24, 25, 26, 27, 28] </ref> for additional technical details. We then discuss our approach for addressing memory and paging overheads in large-scale parallel time-sharing systems, which is based on the VM mechanisms and extensions tailored to the parallel computing environments of interest.
Reference: [26] <author> W. H. Tetzlaff, T. Beretvas, W. M. Buco, J. Greenberg, D. R. Patterson, and G. A. Spivak. </author> <title> A page-swapping prototype for VM/HPO. </title> <journal> IBM Syst. J., </journal> <volume> 26 </volume> <pages> 215-230, </pages> <year> 1987. </year>
Reference-contexts: We now discuss a particular strategy to significantly reduce and effectively eliminate these overheads for a general class of large-scale parallel applications. Our approach is based in part on the concept of block paging, which was introduced in the VM/SP HPO operating system <ref> [1, 25, 26] </ref> and extended in the 189 scheduler with jobs assigned from the root, and the migration scheduler with job assigned from the leaves. Quanta are allocated uniformly, and the context-switch cost for each class is 1 sec. 190 from the root, and the job-migration policy from the leaves. <p> A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to <ref> [1, 23, 24, 25, 26, 27, 28] </ref> for additional technical details. We then discuss our approach for addressing memory and paging overheads in large-scale parallel time-sharing systems, which is based on the VM mechanisms and extensions tailored to the parallel computing environments of interest.
Reference: [27] <author> W. H. Tetzlaff and R. Flynn. </author> <title> A comparison of page replacement algorithms. </title> <booktitle> In Proc. CMG'92 Conf., </booktitle> <pages> pages 1136-1143, </pages> <year> 1992. </year>
Reference-contexts: A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to <ref> [1, 23, 24, 25, 26, 27, 28] </ref> for additional technical details. We then discuss our approach for addressing memory and paging overheads in large-scale parallel time-sharing systems, which is based on the VM mechanisms and extensions tailored to the parallel computing environments of interest.
Reference: [28] <author> W. H. Tetzlaff, M. G. Kienzle, and J. A. Garay. </author> <title> Analysis of block-paging strategies. </title> <journal> IBM J. Res. and Devel., </journal> <volume> 33(1) </volume> <pages> 51-59, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: A few other systems have since adopted some of these concepts, and related forms of prefetching have recently appeared in the research literature [15, 17]. We first provide a brief overview of the block paging mechanisms used in VM; the interested reader is referred to <ref> [1, 23, 24, 25, 26, 27, 28] </ref> for additional technical details. We then discuss our approach for addressing memory and paging overheads in large-scale parallel time-sharing systems, which is based on the VM mechanisms and extensions tailored to the parallel computing environments of interest. <p> This page status information together with other temporal (and address) affinity information are used to minimize failures in accurately predicting future page co-reference and to dynamically 192 maintain page blocks. The analysis in <ref> [28] </ref> shows that the VM paging algorithms are very effective in maintaining appropriate page blocks (e.g., a page is incorrectly placed in a block in the sense that it is brought in as part of the block but never referenced less than 13% of the time in practice) and extremely effective
Reference: [29] <author> F. Wang. </author> <title> Multiprogramming for parallel and distributed systems. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Yale University, </institution> <year> 1997. </year>
Reference-contexts: Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM SP2 [8, 30] and for clusters of workstations <ref> [9, 29] </ref>. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14]. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22].
Reference: [30] <author> F. Wang, H. Franke, M. Papaefthymiou, P. Pattnaik, L. Rudolph, and M. S. Squillante. </author> <title> A gang scheduling design for multiprogrammed parallel computing environments. In Job Sched. Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. </editor> <booktitle> Rudolph (eds.), </booktitle> <pages> pages 111-125. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <note> LNCS Vol. 1162. 195 </note>
Reference-contexts: Due to its promising characteristics, gang scheduling has attracted considerable attention in recent years. Gang schedulers based on the distributed hierarchical control structure [4, 5, 6] have been implemented for the IBM SP2 <ref> [8, 30] </ref> and for clusters of workstations [9, 29]. Similarly, another form of gang scheduling has been implemented on both the IBM SP2 and a cluster of workstations [13, 14]. The performance of gang scheduling schemes that use distributed hierarchical control has been analyzed from a queueing-theoretic perspective [21, 22].
References-found: 30

