URL: http://american.cs.ucdavis.edu/publications/Micro25.92a.ps
Refering-URL: http://american.cs.ucdavis.edu/ArchLabPersonnel/Farrens/PubList.html
Root-URL: http://www.cs.ucdavis.edu
Email: (tyson@cs.ucdavis.edu) (farrens@cs.ucdavis.edu) (arp@tosca.colorado.edu)  
Title: d d MISC: A Multiple Instruction Stream Computer  
Author: Gary Tyson Matthew Farrens Andrew R. Pleszkun 
Address: Colorado-Boulder  
Affiliation: Computer Science Department Computer Science Department Dept of Electrical and Computer Engineering University of California, Davis University of California, Davis University of  
Abstract: This paper describes a single chip Multiple Instruction Stream Computer (MISC) capable of extracting instruction level parallelism from a broad spectrum of programs. The MISC architecture uses multiple asynchronous processing elements to separate a program into streams that can be executed in parallel, and integrates a conflict-free message passing system into the lowest level of the processor design to facilitate low latency intra-MISC communication. This approach allows for increased machine parallelism with minimal code expansion, and provides an alternative approach to single instruction stream multi-issue machines such as SuperScalar and VLIW. 
Abstract-found: 1
Intro-found: 1
Reference: [BeDa91] <author> M. E. Benitez and J. W. Davidson, </author> <title> ``Code Generation for Streaming: an Access/Execute Mechanism'', </title> <booktitle> Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <address> Santa Clara, CA (April 8-11, </address> <year> 1991), </year> <pages> pp. 132-141. </pages>
Reference-contexts: The Lawrence Livermore Loops [McMa84] provide a convenient source for small vectorizable loops found in scientific code. Although originally extracted from FORTRAN code, these loops have been translated to C for purposes of this analysis. The code was then hand compiled and optimized using available vectorizing techniques <ref> [BeDa91] </ref>. The MISC object code generated consists of 4 instruction streams.
Reference: [CGKP87] <author> G. L. Craig, J. R. Goodman, R. H. Katz, A. R. Pleszkun, K. Ramachandran, J. Sayah and J. E. Smith, </author> <title> ``PIPE: A High Performance VLSI Processor Implementation'', </title> <journal> Journal of VLSI and Computer Systems, </journal> <volume> vol. </volume> <month> 2 </month> <year> (1987). </year>
Reference-contexts: 1. The MISC Design The MISC processor, a direct descendant of the PIPE project <ref> [CGKP87, GHLP85] </ref> will exploit both the instruction and data parallelism available in a task by combining the capabilities of traditional data parallel architectures with those found in machines designed to exploit instruction level parallelism.
Reference: [FaPl91] <author> M. Farrens and A. Pleszkun, </author> <title> ``Overview of the PIPE Processor Implementation'', </title> <booktitle> Proceedings of the 24th Annual Hawaii International Conference on System Sciences, </booktitle> <address> Kapaa, Kauai (January 9-11, </address> <year> 1991), </year> <pages> pp. 433-443. </pages>
Reference-contexts: For ALU and FPU instructions, the third source field is ignored and the instructions are treated as if they were standard 3-operand instructions. In the case of control flow operations, the dest field is used as a constant to determine the number of delayed branch slots <ref> [FaPl91] </ref> be filled. The address of the branch is calculated as the sum of the src1 and src2 operands, and the src3 operand specifies the register to be tested.
Reference: [GHLP85] <author> J. R. Goodman, J. T. Hsieh, K. Liou, A. R. Pleszkun, P. B. Schechter and H. C. Young, </author> <title> ``PIPE: a VLSI Decoupled Architecture'', </title> <booktitle> Proceedings of the Twelveth Annual International Symposium on Computer Architecture(June 1985), </booktitle> <pages> pp. 20-27. </pages>
Reference-contexts: 1. The MISC Design The MISC processor, a direct descendant of the PIPE project <ref> [CGKP87, GHLP85] </ref> will exploit both the instruction and data parallelism available in a task by combining the capabilities of traditional data parallel architectures with those found in machines designed to exploit instruction level parallelism.
Reference: [McMa84] <author> F. H. McMahon, </author> <title> LLNL FORTRAN KERNELS: </title> <type> MFLOPS, </type> <institution> Lawrence Livermore Laboratories, Livermore, California, </institution> <month> (March </month> <year> 1984). </year> <title> d d </title>
Reference-contexts: Two examples have been chosen to illustrate some of the abilities of the MISC design. Of the two programs presented here, one contains highly vector-izable code and the other displays no data parallelism. The Lawrence Livermore Loops <ref> [McMa84] </ref> provide a convenient source for small vectorizable loops found in scientific code. Although originally extracted from FORTRAN code, these loops have been translated to C for purposes of this analysis. The code was then hand compiled and optimized using available vectorizing techniques [BeDa91].
References-found: 5

