URL: http://www-ksl.stanford.edu/people/mjw/um-paper.ps
Refering-URL: http://www.erg.sri.com/people/mjw/
Root-URL: 
Title: Presenting Significant Information in Expert System Explanation Content areas: expert systems, explanation, user modeling (using
Author: Michael Wolverton 
Note: Submitted for review Author's present address: KUBIT;  
Address: Chilton, DIDCOT, UK  N-7034 Trondheim, Norway;  
Affiliation: Computing and Information Systems Department Daresbury Rutherford Appleton Laboratory  SINTEF DELAB;  
Pubnum: OX11 0QX  
Email: email: Michael.Wolverton@delab.sintef.no  
Date: March 22, 1995  
Abstract-found: 0
Intro-found: 1
Reference: [1976] <institution> Webster's New Collegiate Dictionary. Merriam, </institution> <year> 1976. </year>
Reference-contexts: And finally Section 6 discusses the features and limitations of this method, and identifies directions for future research. 2 Conclusion-Substantiating Explanation The English word "explanation" is used to mean a wide variety of things. Webster's dictionary <ref> [1976] </ref> gives the following definitions for "explain": 1: to make plain or understandable 2: to give the reason for or cause of 3: to show the logical development or relationships of When applying these to automated explanation, definition 1 encompasses a wide range of communicative acts by the computer, including on-line
Reference: [Buchanan and Shortliffe, 1984] <author> B. G. Buchanan and E. H. Shortliffe, </author> <title> editors. Rule-Based Expert Systems. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1984. </year>
Reference-contexts: Therefore, this paper does not directly address other types of computer-user communication that can reasonably be called "explanation", such as answering questions on how requested inputs might be used (MYCIN's "WHY" explanations <ref> [Buchanan and Shortliffe, 1984] </ref>), defining system terminology and concepts [Paris, 1989, Mittal and Paris, 1993], tutoring [Clancey, 1983], or giving 2 help on how to use the system.
Reference: [Clancey, 1983] <author> William J. Clancey. </author> <title> The epistemology of a rule-based expert system|a framework for explanation. </title> <journal> Artificial Intelligence, </journal> <volume> 20 </volume> <pages> 215-251, </pages> <year> 1983. </year>
Reference-contexts: Therefore, this paper does not directly address other types of computer-user communication that can reasonably be called "explanation", such as answering questions on how requested inputs might be used (MYCIN's "WHY" explanations [Buchanan and Shortliffe, 1984]), defining system terminology and concepts [Paris, 1989, Mittal and Paris, 1993], tutoring <ref> [Clancey, 1983] </ref>, or giving 2 help on how to use the system.
Reference: [Clancey and Letsinger, 1981] <author> William J. Clancey and Reed Letsinger. NEOMYCIN: </author> <title> Reconfiguring a rule-based expert system for application to teaching. </title> <booktitle> In Proceedings of the Seventh International Joint Conference on Artificial Intelligence (IJCAI-81), </booktitle> <address> Vancouver, </address> <month> August </month> <year> 1981. </year>
Reference-contexts: Other important work on explanation focuses on issues other than eliminating insignificant information. Both NEOMYCIN <ref> [Clancey and Letsinger, 1981] </ref> and EES [Swartout et al., 1991] deal with the issue of explaining particular domain knowledge by showing how it is derived from general domain-independent principles.
Reference: [Gautier and Gruber, 1993] <author> Patrice O. Gautier and Thomas R. Gruber. </author> <title> Generating explanations of device behavior using compositional modeling and causal ordering. </title> <booktitle> In AAAI-93, </booktitle> <pages> pages 264-270, </pages> <address> Washington, D.C., </address> <year> 1993. </year>
Reference-contexts: A third future research direction is studying the use of this method in producing "user-driven" explanations, e.g., hypertext explanation systems (see, e.g., <ref> [Gautier and Gruber, 1993, Gruber and Gautier, 1993] </ref> for an example of this type of system). These types of explanation modules are powerful because they present only short answers to user questions and allow the user to easily select areas of the answer that should be expanded or clarified.
Reference: [Gruber and Gautier, 1993] <author> Thomas R. Gruber and Patrice O. Gautier. </author> <title> Machine-generated explanations of engineering models: A compositional modeling approach. </title> <booktitle> In IJCAI-93, </booktitle> <pages> pages 1502-1508, </pages> <address> Chambry, France, </address> <year> 1993. </year>
Reference-contexts: A third future research direction is studying the use of this method in producing "user-driven" explanations, e.g., hypertext explanation systems (see, e.g., <ref> [Gautier and Gruber, 1993, Gruber and Gautier, 1993] </ref> for an example of this type of system). These types of explanation modules are powerful because they present only short answers to user questions and allow the user to easily select areas of the answer that should be expanded or clarified.
Reference: [Johnson, 1994] <author> W. Lewis Johnson. </author> <title> Agents that explain their own actions. </title> <booktitle> In Proceeding of the Fourth Conference on Computer Generated Forces and Behavioral Representation, </booktitle> <address> Orlando, FL, </address> <year> 1994. </year>
Reference-contexts: It could be interesting to combine these approaches with the one presented here, which focuses on selecting the specific domain knowledge to present rather than justifying it based on more abstract knowledge. The Debrief system <ref> [Johnson, 1994] </ref> focuses on explaining agent behavior in an architecture, SOAR, that has no direct access to its long-term memory (and thus cannot easily get the rule trace that led to the behavior).
Reference: [Mittal and Paris, 1993] <author> Vibhu O. Mittal and Cecile Paris. </author> <title> Generating natural language descriptions with examples: Differences between introductory and advanced text. </title> <booktitle> In Proceedings of the 11th National Conference on Artificial Intelligence (AAAI-93), </booktitle> <address> Washington, D. C., </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Therefore, this paper does not directly address other types of computer-user communication that can reasonably be called "explanation", such as answering questions on how requested inputs might be used (MYCIN's "WHY" explanations [Buchanan and Shortliffe, 1984]), defining system terminology and concepts <ref> [Paris, 1989, Mittal and Paris, 1993] </ref>, tutoring [Clancey, 1983], or giving 2 help on how to use the system.
Reference: [Paris, 1989] <author> Cecile L. Paris. </author> <title> The use of explicit user models in a generation system for tailoring answers to the user's level of expertise. </title> <editor> In Alfred Kobsa and Wolfgang Wahlster, editors, </editor> <booktitle> User Models in Dialog Systems, </booktitle> <pages> pages 200-232, </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1989. </year>
Reference-contexts: Therefore, this paper does not directly address other types of computer-user communication that can reasonably be called "explanation", such as answering questions on how requested inputs might be used (MYCIN's "WHY" explanations [Buchanan and Shortliffe, 1984]), defining system terminology and concepts <ref> [Paris, 1989, Mittal and Paris, 1993] </ref>, tutoring [Clancey, 1983], or giving 2 help on how to use the system.
Reference: [Swartout et al., 1991] <author> William Swartout, Cecile Paris, and Johanna Moore. </author> <title> Design for explainable expert systems. </title> <journal> IEEE Expert, </journal> <volume> 6(3) </volume> <pages> 58-64, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Other important work on explanation focuses on issues other than eliminating insignificant information. Both NEOMYCIN [Clancey and Letsinger, 1981] and EES <ref> [Swartout et al., 1991] </ref> deal with the issue of explaining particular domain knowledge by showing how it is derived from general domain-independent principles.
Reference: [Wallis and Shortliffe, 1984] <editor> Wallis and E. H. Shortliffe. In B. G. Buchanan and E. H. Shortliffe, editors, </editor> <title> Rule-Based Expert Systems, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1984. </year>
Reference-contexts: The amount of work on using user models to guide explanations of expert system conclusions is limited. One project, Wallis and Shortliffe's explanation extension to the PUFF system <ref> [Wallis and Shortliffe, 1984] </ref>, uses a numeric rating of user expertise and ratings of the expertise level of KB rules to select 10 rules for presentation in an explanation.
Reference: [Wick and Thompson, 1992] <author> M. R. Wick and W. B. Thompson. </author> <title> Reconstructive expert system explanation. </title> <journal> Artificial Intelligence, </journal> <volume> 54(1-2):33-70, </volume> <month> 13 March </month> <year> 1992. </year>
Reference-contexts: Probably the most closely related research is Wick and Thompson's work in building the REX system <ref> [Wick and Thompson, 1992] </ref>. Wick and Thompson introduce the notion of reconstructive explanation|viewing explanation as a process that can be partly or wholly independent of the expert system's reasoning. The approach reported in this paper can be viewed as a type of reconstructive explanation.
Reference: [Wickler et al., 1993] <author> Gerhard Wickler, Helen Chappel, and Simon Lambert. </author> <title> An Architecture for a Generic Explanation Component. </title> <editor> In Michael R. Wick, editor, </editor> <booktitle> The IJCAI Workshop on Explanation and Problem Solving, </booktitle> <pages> pages 53-64, </pages> <institution> University of Wisconsin - Eau Claire, WI, </institution> <month> August </month> <year> 1993. </year> <month> 14 </month>
Reference-contexts: Furthermore, we are specifically interested in generating explanations that satisfy one particular user information need (to use the terminology of <ref> [Wickler et al., 1993] </ref>) about the conclusion: we want to convince the user that the system's conclusion is the correct one.
References-found: 13

