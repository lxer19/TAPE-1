URL: ftp://ftp.csd.uwo.ca/pub/ling/papers/jar-refinement.ps.Z
Refering-URL: http://www.csd.uwo.ca/faculty/ling/sub-pub.html
Root-URL: 
Email: E-mail: ling@csd.uwo.ca.  
Phone: Phone: 519-661-3341  
Title: Refinement of Uncertain Rule Bases via Reduction rule bases with uncertainty, inductive learning from examples,
Author: Charles X.F. Ling Marco Valtorta 
Keyword: Key Words: Refinement  
Address: Ontario, London, Ontario, Canada N6A 5B7.  
Affiliation: Department of Computer Science, University of Western  
Note: in  (Office). The work has been supported partially by an NSERC Operating Grant.  
Abstract: Refining deep (multilayer) rule bases of an expert system with uncertainty to cover a set of new examples can be very difficult (NP-hard). We analyze refinement via reduction, an approach first proposed in [Ginsberg, 1988b], where it is claimed that this approach eases the complexity of refining rule bases without uncertainty. We outline a model of rule bases with uncertainty, and give necessary and sufficient conditions on uncertainty combination functions that permit reduction from deep to flat (non-chaining) rule bases. We prove that reduction cannot be performed with most commonly used uncertainty combination functions. However, we show that there is a class of reducible rule bases in which the strength refinement problem is NP-hard in the deep rule base, reduction is polynomial, and the flat rule base can be refined in polynomial time. This result also allows polynomial refinement of practical expert systems in the form of rule deletion. Thus, our results provide some theoretical evidence that refinement via reduction is feasible. y Department of Computer Science, University of South Carolina, Columbia, SC 29208, U.S.A. E-mail: mgv@usceast.cs.scarolina.edu. Phone: 803-777-4641 (Office). The beginning of this research was supported by a University of South Carolina summer grant, which is gratefully acknowledged. 
Abstract-found: 1
Intro-found: 1
Reference: [Amarel, 1982] <author> Amarel, S. </author> <year> (1982). </year> <title> Expert behavior and problem representations. </title> <editor> In Elithorn, A. and Banerji, R., editors, </editor> <booktitle> Artificial and Human Intelligence. </booktitle> <publisher> North-Holland, </publisher> <address> New York. </address>
Reference-contexts: Solving a problem by first changing its representation is a common and very important approach in AI. Some early work on problem reformulation includes <ref> [Amarel, 1982, Korf, 1980] </ref>.
Reference: [Angluin, 1987] <author> Angluin, D. </author> <year> (1987). </year> <title> Learning propositional horn sentences with hints. </title> <type> Technical Report RR-590, </type> <institution> Department of Computer Science, Yale University. </institution>
Reference-contexts: Fourth, knowledge acquisition via cases (or examples) only may be insufficient for efficient learning. In automatic knowledge acquisition, other assistance besides cases and examples, such as explanations of the example (or hints as in <ref> [Angluin, 1987] </ref>), selected typical and "good" examples 7 , queries (e.g. membership of instances or generic cases), knowledge base support tools [Musen, 1989], and interactions with human experts, may be required, justifying a shift of activity from automatic to computer-assisted knowledge acquisition.
Reference: [Angluin and Smith, 1983] <author> Angluin, D. and Smith, C. </author> <year> (1983). </year> <title> A survey of inductive inference: theory and methods. </title> <journal> Comput. Surveys, </journal> <volume> 15 </volume> <pages> 237-269. </pages>
Reference-contexts: For summaries of classic work on inductive learning, see <ref> [Angluin and Smith, 1983] </ref> [Dietterich and Michalski, 1983]. Much work on refinement has been done. For a bibliography, see [Valtorta, 1991a]. In contrast to the present study, most of the previous research avoids numerical uncertain representations, and uses heuristics without average or worse case complexity analyses.
Reference: [Bareiss et al., 1989] <author> Bareiss, R., Porter, B. W., and Murray, K. S. </author> <year> (1989). </year> <title> Supporting start-to-finish development of knowledge bases. </title> <journal> Machine Learning, </journal> <volume> 4(3/4). </volume>
Reference: [Benjamin, 1990] <author> Benjamin, D. </author> <year> (1990). </year> <title> Change of Representation and Inductive Bias. </title> <publisher> Kluwer Academic, Norwell, </publisher> <address> MA. </address>
Reference-contexts: Solving a problem by first changing its representation is a common and very important approach in AI. Some early work on problem reformulation includes [Amarel, 1982, Korf, 1980]. However, very little of the work done in the area (such as papers in <ref> [Benjamin, 1990] </ref>) seems directly applicable to reduction in knowledge base refinement. 9 Conclusions We have demonstrated that rule base refinement to cover a set of given cases is computa-tionally intractable (NP-complete) in deep rule bases that use truth functional (extensional) uncertainty models 6 .
Reference: [Buchanan, 1989] <author> Buchanan, B. G. </author> <year> (1989). </year> <title> Can machine learning offer anything to expert systems? Machine Learning, </title> <type> 4(3/4). </type>
Reference-contexts: 1 Introduction It is well known that building and maintaining large rule bases is a time consuming, error prone "bottleneck" process. Machine learning, a young and exciting field in AI, has been providing promising solutions to the bottleneck problem <ref> [Buchanan, 1989] </ref>. Learning by induction, the central topic of machine learning, studies how a theory is constructed and revised from data. If the theory is incomplete or imperfect, some of its behavior (data or cases it explains) would be incorrect.
Reference: [Buchanan and Shortliffe, 1984] <author> Buchanan, B. G. and E. H. </author> <title> Shortliffe (1984) Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference-contexts: for detailed discussions and proofs. 3.3 What If a Theory Cannot be Reduced? Surprisingly, the MYCIN type of uncertainty combination functions are not compatible with reduction. (We consider here a simplified version of the original MYCIN combination function, as described in [Shortliffe, 1976], as opposed to the one described in <ref> [Buchanan and Shortliffe, 1984] </ref>.) In MYCIN-type rule based expert systems, the certainty factor (CF ) is a real number in [0; 1]. The particular ^^ ^ used is the minimum function, &gt;&gt; &gt; is the multiplication function, and __ _ (x; y) = x b = x + y xy.
Reference: [Dietterich and Michalski, 1983] <author> Dietterich, T. and Michalski, R. </author> <year> (1983). </year> <title> A comparative review of selected methods from learning from examples. </title> <editor> In Michalski, R., Carbonell, J., and Mitchell, T., editors, </editor> <booktitle> Machine learning: An artificial intelligence approach. </booktitle> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: For summaries of classic work on inductive learning, see [Angluin and Smith, 1983] <ref> [Dietterich and Michalski, 1983] </ref>. Much work on refinement has been done. For a bibliography, see [Valtorta, 1991a]. In contrast to the present study, most of the previous research avoids numerical uncertain representations, and uses heuristics without average or worse case complexity analyses.
Reference: [Duda et al., 1976] <author> Duda, R., Hart, P., and Nilsson, N. </author> <year> (1976). </year> <title> Subjective bayesian methods for rule-based inference systems. </title> <type> Technical Report 124, </type> <institution> Artificial Intelligence Center, SRI International. </institution>
Reference-contexts: In these cases (as in many others) the function f of theorem 3 is just f (r) = r. Functions satisfying conditions for reduction are adopted in several rule based systems. Some expert 11 systems, such as Prospector <ref> [Gashnig, 1981, Duda et al., 1976] </ref> and AL/X [Reiter, 1980], use the "fuzzy" formulae for conjunction (MIN) and disjunction (MAX) [Quinlan, 1983]. The same is true for some fuzzy control systems and rule based systems based on fuzzy logic (although not all of them). For example, [Togai and Watanabe, 1986].
Reference: [Garey and Johnson, 1979] <author> Garey, M. and Johnson, D. </author> <year> (1979). </year> <title> Computers and Intractability: </title>
Reference-contexts: Proof: One in Three Satisfiability (OTS) <ref> [Garey and Johnson, 1979] </ref> (page 259) will be transformed into SRP. The variant in which no clause in the formula contains a negative literal will be used. The generic OTS instance is a formula in 3-conjunctive normal form, with no negated variables. <p> Finally, SRP is NP-complete even if both input and s i values are restricted as just outlined at the same time. Theorem 6.1: The problem of Complete Synthesis in Reduced Theory (CSRT) with B = [0; 1] is NP-hard. Proof: We transform monotone three-conjunctive normal form satisfiability (MSAT) <ref> [Garey and Johnson, 1979] </ref> to CSRT.
References-found: 10

