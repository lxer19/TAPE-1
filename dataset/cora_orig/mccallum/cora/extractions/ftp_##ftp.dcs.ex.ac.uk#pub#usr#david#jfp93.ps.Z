URL: ftp://ftp.dcs.ex.ac.uk/pub/usr/david/jfp93.ps.Z
Refering-URL: http://www.dcs.ex.ac.uk/~david/research/york.html
Root-URL: http://www.dcs.ex.ac.uk
Title: Heap Profiling of Lazy Functional Programs  
Author: Colin Runciman and David Wakeling 
Address: York  
Affiliation: University of  
Abstract: We describe the design, implementation and use of a new kind of profiling tool that yields valuable information about the memory use of lazy functional programs. The tool has two parts: a modified functional language implementation which generates profiling information during the execution of programs, and a separate program which converts this information to graphical form. With the aid of profile graphs, one can make alterations to a functional program which dramatically reduce its space consumption. We demonstrate this in the case of a genuine example | the first to which the tool was applied | for which the results are strikingly successful. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. W. Appel. </author> <title> Compiling With Continuations. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: The basic sampling scheme could be further improved by replacing the test of the sample flag at the start of each function with a sampling interrupt similar to the timer interrupt used in the implementation of SML/NJ <ref> [1] </ref>. When a sample is due, the signal handler simply sets the heap limit register to zero. The next attempt to allocate space from the heap is then certain to call the garbage collector.
Reference: [2] <author> L. Augustsson. </author> <title> Compiling Lazy Functional Languages, Part II. </title> <type> PhD thesis, </type> <institution> Chalmers University of Technology, S-412 96 Goteborg, </institution> <month> November </month> <year> 1987. </year>
Reference-contexts: This ordering also naturally focuses attention on the "troublemakers" at the top of the graph. 4 Implementation Our implementation is based on Augustsson and Johnsson's LML compiler <ref> [9, 2] </ref>. In what follows we shall assume some familiarity with this compiler and the underlying idea of programmed graph reduction. For those without such familiarity, Augustsson and Johnsson's paper [3] provides a good overview, and an excellent tutorial description can be found Peyton Jones' book [14].
Reference: [3] <author> L. Augustsson and T. Johnsson. </author> <title> The Chalmers Lazy-ML Compiler. </title> <journal> Computer Journal, </journal> <volume> 32(2) </volume> <pages> 127-141, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: In what follows we shall assume some familiarity with this compiler and the underlying idea of programmed graph reduction. For those without such familiarity, Augustsson and Johnsson's paper <ref> [3] </ref> provides a good overview, and an excellent tutorial description can be found Peyton Jones' book [14]. Our LML compiler has a modified lambda lifting pass and a new run-time system. These are described in turn below.
Reference: [4] <author> B. Bjerner and S. Holmstrom. </author> <title> A Compositional Approach to Time Analysis of First Order Lazy Functional Programs. </title> <booktitle> In Proceedings of the 1989 Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 157-165. </pages> <publisher> ACM Press, </publisher> <month> September </month> <year> 1989. </year>
Reference-contexts: There has been some work in this area, notably by Wadler [25], Bjerner and Holmstrom <ref> [4] </ref> and Sands [19] concerning time behaviour. However, the problem is a hard one and progress has so far been modest. The practical approach involves the construction of profiling tools which gather information when the program is executed.
Reference: [5] <author> P. H. Hartel and A. H. Veen. </author> <title> Statistics on Graph Reduction of SASL Programs. </title> <journal> Software | Practice and Experience, </journal> <volume> 18 </volume> <pages> 239-253, </pages> <year> 1988. </year>
Reference-contexts: We have already noted that other heap attributes, apart from statically determined properties of individual cells, may be of interest to functional programmers. Hartel and Veen <ref> [5] </ref>, for example, studied the life-times of cells and the lengths of application chains. Indeed, one could profile all kinds of structural properties of the heap, but it is not obvious which properties to choose or what structural information would best serve the aim of reducing computational costs.
Reference: [6] <author> R. J. M. Hughes. </author> <title> The Design and Implementation of Programming Languages. </title> <type> PhD thesis, </type> <institution> Oxford University, </institution> <month> September </month> <year> 1984. </year>
Reference-contexts: This conversion involves binding the function's free variables as extra formal parameters and then passing values for these variables as extra actual parameters at every point where the function is called. Johnsson [8] christened this conversion lambda lifting, although the term supercombinator was invented by Hughes <ref> [6] </ref> who independently discovered a similar conversion. As Peyton Jones notes [14], an unfortunate consequence of lambda lifting is that the bodies of some functions get broken up into many small fragments which are then turned into individual combinators. <p> At first glance, the definition of splitat in the LML standard library seems harmless enough. splitat c [] = ([], []) splitat c (a.b) = if a = c then ([], b) else let (x, y) = splitat c b in (a.x, y) 18 However, we know from Hughes' thesis <ref> [6] </ref> that all possible definitions of splitat are subject to a space leak if an ordinary sequential evaluator y is used. The problem is easily explained. In LML, and in most other lazy functional languages, a pattern on the left-hand side of a local definition is matched lazily.
Reference: [7] <author> R. J. M. Hughes. </author> <title> A Loop-Detecting Interpreter for Lazy, Higher-Order Programs. </title> <booktitle> In Proceedings of the 5th Glasgow Workshop on Functional Programming, </booktitle> <month> July </month> <year> 1992. </year> <note> to be published by Springer. </note>
Reference-contexts: To give just two examples of various successful applications known to us, Hughes has located and fixed a space fault in his CDS loop-detecting interpreter <ref> [7] </ref>, cutting the maximum heap size when interpretting a simple but highly recursive program from 1.8Mb to 30kb. He found that heap profiling was essential, although the job was not easy.
Reference: [8] <author> T. Johnsson. </author> <title> Lambda Lifting: Transforming Programs to Recursive Equations. </title> <booktitle> In Proceedings of the 1985 Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 190-203. </pages> <publisher> Springer-Verlag, </publisher> <month> September </month> <year> 1985. </year> <note> LNCS 201. </note>
Reference-contexts: This conversion involves binding the function's free variables as extra formal parameters and then passing values for these variables as extra actual parameters at every point where the function is called. Johnsson <ref> [8] </ref> christened this conversion lambda lifting, although the term supercombinator was invented by Hughes [6] who independently discovered a similar conversion.
Reference: [9] <author> T. Johnsson. </author> <title> Compiling Lazy Functional Languages. </title> <type> PhD thesis, </type> <institution> Chalmers University of Technology, S-412 96 Goteborg, </institution> <month> February </month> <year> 1987. </year>
Reference-contexts: This ordering also naturally focuses attention on the "troublemakers" at the top of the graph. 4 Implementation Our implementation is based on Augustsson and Johnsson's LML compiler <ref> [9, 2] </ref>. In what follows we shall assume some familiarity with this compiler and the underlying idea of programmed graph reduction. For those without such familiarity, Augustsson and Johnsson's paper [3] provides a good overview, and an excellent tutorial description can be found Peyton Jones' book [14]. <p> Figure 8 (a) shows how the stack is arranged on entry to filterset', and Figure 8 (b) shows how it is rearranged prior to a tail call using the mysterious S rules hinted at by Johnsson in <ref> [9] </ref>.
Reference: [10] <author> R. Jones. </author> <title> Tail Recursion Without Space Leaks. </title> <journal> Journal of Functional Programming, </journal> <volume> 2(1) </volume> <pages> 73-79, </pages> <month> January </month> <year> 1992. </year> <month> 29 </month>
Reference-contexts: After checking our profiling tool very carefully, we were forced to conclude that the standard LML compiler was at fault, and indeed this turned out to be the case. As Jones <ref> [10] </ref> explains, LML compilers of the vintage that we were working with are subject to a space leak which causes cells to be unnecessarily preserved by the garbage collector. The problem arises when tail-recursive functions, such as filterset', are compiled into G-machine code.
Reference: [11] <author> Y. Kozato and G. P. Otto. </author> <title> Geometric Transformations in a Lazy Functional Language. </title> <booktitle> In Proceedings of 11th International Conference on Pattern Recognition, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: He found that heap profiling was essential, although the job was not easy. Kozato has also used heap profiling to guide the reformulation of a lazy image processing system <ref> [11] </ref>, so that the final version runs in constant space regardless of the size of the image. 8 Related Work Not much work seems to have been done on providing profiling facilities for lazy functional languages.
Reference: [12] <author> Z. Manna and R. Waldinger. </author> <title> The Logical Basis for Computer Programming (Volume 1: Deductive Reasoning). </title> <address> Adddison-Wesley, </address> <year> 1985. </year>
Reference-contexts: The space savings are less dramatic when the input comprises a more typical mixture of propositions (for example, the exercises from chapter 1 of <ref> [12] </ref>), but they are still impressive | between one and two orders of magnitude rather than between two and three. 7 Subsequent Developments Following our success with clausify, we extended the profiler to make it more suitable for dealing with large programs.
Reference: [13] <author> S. L. Meira. </author> <title> On the Efficiency of Applicative Algorithms. </title> <type> PhD thesis, </type> <institution> University of Kent at Canterbury, </institution> <month> March </month> <year> 1985. </year>
Reference-contexts: However, the intensional properties of a functional program (how it computes its result) can often be much harder to understand than those of an imperative one, especially in the presence of higher order functions and lazy evaluation. Several authors have observed this problem. In his thesis, Meira <ref> [13] </ref> uses a number of examples to show that it is hard to write efficient functional programs because of the need to understand the underlying order of expression evaluation.
Reference: [14] <editor> S. L. Peyton Jones. </editor> <booktitle> The Implementation of Functional Programming Languages. </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1987. </year>
Reference-contexts: All of this work is tidily summarised in a chapter of Peyton Jones' book <ref> [14] </ref>. The problem of reasoning about the time and space complexity of functional programs can be addressed in two different ways. These might be called the theoretical and the practical approaches. fl Authors' address: Department of Computer Science, University of York, Heslington, York Y01 5DD, United Kingdom. <p> In what follows we shall assume some familiarity with this compiler and the underlying idea of programmed graph reduction. For those without such familiarity, Augustsson and Johnsson's paper [3] provides a good overview, and an excellent tutorial description can be found Peyton Jones' book <ref> [14] </ref>. Our LML compiler has a modified lambda lifting pass and a new run-time system. These are described in turn below. Lambda Lifting In order to avoid the overhead of run-time environment management, the LML compiler converts all functions into supercombinators prior to code generation. <p> Johnsson [8] christened this conversion lambda lifting, although the term supercombinator was invented by Hughes [6] who independently discovered a similar conversion. As Peyton Jones notes <ref> [14] </ref>, an unfortunate consequence of lambda lifting is that the bodies of some functions get broken up into many small fragments which are then turned into individual combinators. <p> The first is to update the root of the redex with a copy of the root of the result, and the second is to update with an indirection to the result. The advantages of each choice are set out in Peyton Jones' book <ref> [14] </ref>. Since our improved definition of elim makes no difference, we can conclude that our compiler's G-machine must update by copying. Altering the update mechanism to use indirections instead gives the heap profile shown in Figure 11.
Reference: [15] <author> S. L. Peyton Jones. </author> <title> Implementation of Functional Languages on Stock Hardware: The Spineless Tagless G-machine. </title> <type> Technical report, </type> <institution> Department of Computing Science, University of Glasgow, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: Sansom describes a possible implementation of his cost centre model based on Peyton Jones' Spineless Tagless G-machine <ref> [15] </ref>. The machine is modified by adding a new CurrentCostCentre register, and by arranging for every cell in the heap to be tagged with the value of this register when it is allocated. The setCostCentre primitive saves the value of the CurrentCostCentre register and sets it to a new value.
Reference: [16] <author> C. Runciman and D. Wakeling. </author> <title> Problems and Proposals for Time and Space Profiling of Functional Programs. </title> <booktitle> In Proceedings of the 1990 Glasgow Workshop on Functional Programming, </booktitle> <pages> pages 237-245. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1990. </year>
Reference-contexts: Indeed, one could profile all kinds of structural properties of the heap, but it is not obvious which properties to choose or what structural information would best serve the aim of reducing computational costs. In a previous paper <ref> [16] </ref> we made a proposal for profiling the storage consumption of lazy functional programs. Essentially, our idea was to construct an interpretive profiler based on source level graph reduction. <p> This gave us some information about graph consumption to put alongside the production profile. Our earlier view <ref> [16] </ref> that consumer profiling could also be of value is thus confirmed.
Reference: [17] <author> C. Runciman and D. Wakeling. </author> <title> Heap Profiling of a Lazy Functional Compiler. </title> <booktitle> In Proceedings of the 1992 Glasgow Workshop on Functional Programming. </booktitle> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1992. </year> <note> In press. </note>
Reference-contexts: This idea, suggested to us by Peyton Jones, makes heap profiling intrusive because the extra sampling garbage collections alter the program's normal pattern of garbage collection. However, we consider it to be a sensible compromise between 22 virtue and efficiency. We have reported elsewhere <ref> [17] </ref> the successful application of this extended profiler to the LML compiler, including the discovery and correction of a long-standing space fault.
Reference: [18] <author> C. Runciman and D. Wakeling. </author> <title> Heap Profiling of Lazy Functional Programs. </title> <type> Technical Report 172, </type> <institution> Department of Computer Science, University of York, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: We are grateful to the referees for their comments. Our work was funded by the Science and Engineering Research Council. An earlier version of this paper was issued as a technical report <ref> [18] </ref>.
Reference: [19] <author> D. Sands. </author> <title> Time Analysis, Cost Equivalence and Program Refinement. </title> <booktitle> In Proceedings of the Conference on the Foundations of Software Technology and Theoretical Computer Science, </booktitle> <pages> pages 25-39. </pages> <publisher> Springer-Verlag, </publisher> <month> December </month> <year> 1991. </year> <note> LNCS 560. </note>
Reference-contexts: There has been some work in this area, notably by Wadler [25], Bjerner and Holmstrom [4] and Sands <ref> [19] </ref> concerning time behaviour. However, the problem is a hard one and progress has so far been modest. The practical approach involves the construction of profiling tools which gather information when the program is executed. Such execution profiles assist the programmer by revealing the underlying intensional properties of the program.
Reference: [20] <author> P. Sansom. </author> <title> Profiling Lazy Functional Languages. </title> <type> Draft Memorandum, </type> <institution> Department of Computing Science, University of Glasgow, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: This information could then be presented to the programmer in the form of a producer-consumer matrix . By studying the matrix, we hoped that the programmer could see how to modify the program so as to reduce either the maximum or the average size of the graph. Sansom <ref> [20] </ref> suggests a scheme somewhat different from our own, the central idea being that the programmer should nominate cost centres to which the cost of evaluating selected expressions should be attributed. Cost centres are attached to expressions through applications of the primitive function setCostCentre.
Reference: [21] <author> W. Stoye. </author> <title> The Implementation of Functional Languages Using Custom Hardware. </title> <type> PhD thesis, </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> December </month> <year> 1986. </year> <note> Technical Report No. 81. </note>
Reference-contexts: Wray [26] also notes that lazy evaluation leads to uncertainty about time and space behaviour, as does Stoye <ref> [21] </ref>, who laments the fact that so much research is directed towards improving implementation performance, rather than towards providing profiling facilities. All of this work is tidily summarised in a chapter of Peyton Jones' book [14].
Reference: [22] <author> E. R. Tufte. </author> <title> The Visual Display of Quantitative Information. </title> <publisher> Graphics Press, </publisher> <address> Cheshire, Connecticut, </address> <year> 1983. </year>
Reference-contexts: Furthermore, of all methods for analyzing and communicating statistical information, well-designed data graphics are usually the simplest and at the same time the most powerful <ref> [22] </ref>. The second component of our heap profiling tool is a program that generates a graph from a heap profile. <p> One might imagine using more sophisticated graphical presentation techniques which take advantage of the rapidly falling cost of colour workstations and colour laser printers. However, we believe that the effort devoted to producing colour output would be largely wasted. In his book, Tufte <ref> [22] </ref> explains that the use of colour often results in "graphical puzzles" which are actually harder to understand than if shades of grey had been used instead.
Reference: [23] <author> W. M. van der Poel. </author> <title> The Mechanization of the Lambda Calculus. </title> <institution> Undated typescript, University of Technology, Delft, The Netherlands. </institution>
Reference-contexts: Van der Poel's motto puts it another way: What cannot be made clear by white chalk alone cannot be made clear by coloured chalk either <ref> [23] </ref>. So, although we shall continue to improve our graphs with reference to Tufte's guidelines, they will still be printed with shades of grey. Our current methods of examining the graphical profiles, and interpreting them in the light of the way functions are defined, are entirely ad hoc.
Reference: [24] <author> P. Wadler. </author> <title> Fixing Some Space Leaks with a Garbage Collector. </title> <journal> Software | Practice and Experience, </journal> <volume> 17(9) </volume> <pages> 595-608, </pages> <month> September </month> <year> 1987. </year>
Reference-contexts: The idea, described by Wadler in <ref> [24] </ref>, is to modify the garbage collector to perform reductions of the form @ fst @ @ @R x ) @ snd @ @ @R y ) whenever it encounters an application of either a fst or a snd selector to a fully-evaluated argument.
Reference: [25] <author> P. Wadler. </author> <title> Strictness Analysis Aids Time Analysis. </title> <booktitle> In Fifteenth Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <pages> pages 119-131, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: There has been some work in this area, notably by Wadler <ref> [25] </ref>, Bjerner and Holmstrom [4] and Sands [19] concerning time behaviour. However, the problem is a hard one and progress has so far been modest. The practical approach involves the construction of profiling tools which gather information when the program is executed.
Reference: [26] <author> S. C. Wray. </author> <title> Implementation and Programming Techniques for Functional Lan--guages. </title> <type> PhD thesis, </type> <institution> University of Cambridge Computer Laboratory, </institution> <month> January </month> <year> 1986. </year> <type> Technical Report No. 92. 31 </type>
Reference-contexts: Several authors have observed this problem. In his thesis, Meira [13] uses a number of examples to show that it is hard to write efficient functional programs because of the need to understand the underlying order of expression evaluation. Wray <ref> [26] </ref> also notes that lazy evaluation leads to uncertainty about time and space behaviour, as does Stoye [21], who laments the fact that so much research is directed towards improving implementation performance, rather than towards providing profiling facilities.
References-found: 26

