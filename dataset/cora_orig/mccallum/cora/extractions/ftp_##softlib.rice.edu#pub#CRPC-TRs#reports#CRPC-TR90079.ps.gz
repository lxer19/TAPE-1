URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR90079.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: Fortran D Language Specification  
Author: Geoffrey Fox Seema Hiranandani Ken Kennedy Charles Koelbel Ulrich Kremer Chau-Wen Tseng Min-You Wu 
Note: Center for Research on Parallel Computation  
Date: December 1990  
Address: 90079  P.O. Box 1892 Houston, TX 77251-1892  
Affiliation: CRPC-TR  Rice University  
Abstract-found: 0
Intro-found: 1
Reference: [AK87] <author> J. R. Allen and K. Kennedy. </author> <title> Automatic translation of Fortran programs to vector form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(4) </volume> <pages> 491-542, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: This is especially true for irregular computations, since many parallel loops cannot be detected by the compiler. The compiler is forced to assume loop-carried or inter-iteration dependences that force synchronization to be inserted <ref> [AK87] </ref>. As a remedy, Fortran D defines FORALL to be a loop such that each iteration can only use values defined before the loop or within the current iteration.
Reference: [AKLS88] <author> E. Albert, K. Knobe, J. Lukas, and G. Steele, Jr. </author> <title> Compiling Fortran 8x array features for the Connection Machine computer system. </title> <booktitle> In Symposium on Parallel Programming: Experience with Applications, Languages and Systems, </booktitle> <address> New Haven, CT, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: Heuristics are employed to align data arrays, both within and across dimensions. Different distributions are evaluated, then communication using Crystal collective communication routines is generated. Since data decompositions are automatically calculated, no decomposition specifications are provided. CM Fortran <ref> [AKLS88, TMC89] </ref> is a version of Fortran extended with vector notation, alignment, and data layout specifications. Programmers must explicitly specify data parallelism in CM Fortran programs by marking certain array dimensions as parallel.
Reference: [ALS90] <author> E. Albert, J. Lukas, and G. Steele, Jr. </author> <title> Data parallel computers and the forall statement. </title> <booktitle> In Frontiers90: The 3rd Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> College Park, MD, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: In particular, FORALL loops are deterministic. As a result we believe that it will be easy to understand and use for scientific programmers. The FORALL loop possesses similar semantics to the CM Fortran FORALL statement <ref> [TMC89, ALS90] </ref> and the Myrias PARDO loop. <p> CM Fortran [AKLS88, TMC89] is a version of Fortran extended with vector notation, alignment, and data layout specifications. Programmers must explicitly specify data parallelism in CM Fortran programs by marking certain array dimensions as parallel. CM Fortran has a FORALL statement <ref> [ALS90] </ref> similar to the Fortran D FORALL loop, but which applies to only a single assignment statement. The REDUCE statement in Fortran D is patterned after equivalent reduction functions in CM Fortran.
Reference: [APT90] <author> F. Andre, J. Pazat, and H. Thomas. </author> <title> Pandore: A system to manage data distribution. </title> <booktitle> In Proceedings of the 1990 ACM International Conference on Supercomputing, </booktitle> <address> Amsterdam, The Netherlands, </address> <month> June </month> <year> 1990. </year> <month> 30 </month>
Reference-contexts: These systems do not directly specify alignments between arrays. Instead, they distribute each array individually and implicitly derive the alignment between different arrays based on their relative distributions. Systems such as Dino [RSW90], Id Nouveau [RP89], Mimdizer [SWW91], Oxygen [RA90], and Pandore <ref> [APT90] </ref> all provide data distribution specifications equivalent to some combination of BLOCK and CYCLIC. Dino also supports special stencil-based data distributions with overlaps. The Aspar [IFKF90] compiler performs automatic data decomposition and communications generation. A micro-stencil is derived and used to generate a macro-stencil to identify communication requirements.
Reference: [BFKK90] <author> V. Balasundaram, G. Fox, K. Kennedy, and U. Kremer. </author> <title> An interactive environment for data partitioning and distribution. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: We are also developing a Fortran 90D compiler for the iPSC/860 [WF91] and a Fortran 77D compiler for the Thinking Machines CM-2. We are pursuing other projects in the Fortran D programming system [HKK + 91] at Rice and Syracuse. They include automatic data decomposition <ref> [BFKK90] </ref>, static performance estimation using a machine-independent training set [BFKK91], compiler support for unstructured computations [KM90], run-time preprocessing using the Parti communications library [SBW90], as well as a suite of applications programs to evaluate the effectiveness of the Fortran D compiler.
Reference: [BFKK91] <author> V. Balasundaram, G. Fox, K. Kennedy, and U. Kremer. </author> <title> A static performance estimator to guide data partitioning decisions. </title> <booktitle> In Proceedings of the Third ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> Williamsburg, VA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: We are pursuing other projects in the Fortran D programming system [HKK + 91] at Rice and Syracuse. They include automatic data decomposition [BFKK90], static performance estimation using a machine-independent training set <ref> [BFKK91] </ref>, compiler support for unstructured computations [KM90], run-time preprocessing using the Parti communications library [SBW90], as well as a suite of applications programs to evaluate the effectiveness of the Fortran D compiler.
Reference: [BKK + 89] <author> V. Balasundaram, K. Kennedy, U. Kremer, K. S. M c Kinley, and J. Subhlok. </author> <title> The ParaScope Editor: An interactive parallel programming tool. </title> <booktitle> In Proceedings of Supercomputing '89, </booktitle> <address> Reno, NV, </address> <month> November </month> <year> 1989. </year>
Reference-contexts: Fortran D programs also have the advantage of being deterministic, unlike programs written in most explicitly parallel languages. We are in the process of implementing a Fortran 77D compiler [HKT91b] in the context of the ParaScope programming environment <ref> [CCH + 88, BKK + 89] </ref>. We chose as our first target the Intel iPSC/860, a MIMD distributed-memory machine. A later project will produce a Fortran 77D compiler for a SIMD distributed-memory machine. We have also started a Fortran 90D compiler aimed at the iPSC/860 and NCUBE-2 hypercube [WF91].
Reference: [CCH + 88] <author> D. Callahan, K. Cooper, R. Hood, K. Kennedy, and L. Torczon. </author> <title> ParaScope: A parallel programming environment. </title> <journal> The International Journal of Supercomputer Applications, </journal> <volume> 2(4) </volume> <pages> 84-99, </pages> <month> Winter </month> <year> 1988. </year>
Reference-contexts: Fortran D programs also have the advantage of being deterministic, unlike programs written in most explicitly parallel languages. We are in the process of implementing a Fortran 77D compiler [HKT91b] in the context of the ParaScope programming environment <ref> [CCH + 88, BKK + 89] </ref>. We chose as our first target the Intel iPSC/860, a MIMD distributed-memory machine. A later project will produce a Fortran 77D compiler for a SIMD distributed-memory machine. We have also started a Fortran 90D compiler aimed at the iPSC/860 and NCUBE-2 hypercube [WF91].
Reference: [CCL89] <author> M. Chen, Y. Choo, and J. Li. </author> <title> Theory and pragmatics of compiling efficient parallel code. </title> <type> Technical Report YALEU/DCS/TR-760, </type> <institution> Dept. of Computer Science, Yale University, </institution> <address> New Haven, CT, </address> <month> December </month> <year> 1989. </year>
Reference-contexts: The compiler then generates computation and communication by expanding the single point algorithm to cover all points distributed onto a node. 6.2 Alignment For computations involving multiple distributed arrays, both alignment and distribution must be dealt with in order to minimize data movement. The Crystal compiler <ref> [CCL89, LC90a, LC90b] </ref> performs automatic data decomposition and communications generation for the Crystal functional language. Heuristics are employed to align data arrays, both within and across dimensions. Different distributions are evaluated, then communication using Crystal collective communication routines is generated.
Reference: [CG89] <author> N. Carriero and D. Gelernter. </author> <title> Linda in context. </title> <journal> Communications of the ACM, </journal> <volume> 32(4) </volume> <pages> 444-458, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: A major goal for the Center for Research on Parallel Computation (CRPC) is to develop a machine-independent parallel programming model usable for both shared and distributed-memory SIMD/MIMD architectures. High-level parallel languages such as Linda <ref> [CG89] </ref>, Strand [FT90, FO90], and Delirium [LS91] are valuable when used to coordinate coarse-grained functional parallelism. However, these languages do not meet the needs of computational scientists because they are inefficient for capturing fine-grain data parallelism (of the type described by Hillis and Steele [HS86] and Karp [Kar87]).
Reference: [CK88] <author> D. Callahan and K. Kennedy. </author> <title> Compiling programs for distributed-memory multiprocessors. </title> <journal> Journal of Supercomputing, </journal> <volume> 2 </volume> <pages> 151-169, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: Superb also originated the overlap concept as a means to both specify and store nonlocal data accesses. Wolfe [Wol89, Wol90] describes transformations such as loop rotation for programs with BLOCK distributions. Callahan and Kennedy <ref> [CK88] </ref> propose methods for compiling programs with user-specified data distribution functions. They also demonstrate how such programs can be optimized using loop transformations. Booster [PvGS90] also provides user-specified distribution functions defined as program views, but does not generate or optimize communications.
Reference: [CR89] <author> A. Cheung and A. Reeves. </author> <title> The Paragon multicomputer environment: A first implementation. </title> <type> Technical Report EE-CEG-89-9, </type> <institution> Cornell University Computer Engineering Group, </institution> <address> Ithaca, NY, </address> <month> July </month> <year> 1989. </year>
Reference-contexts: Aspar derives simple BLOCK distributions; alignment specifications are not provided. Gupta and Banerjee [GB90] propose a constraint-based approach to automatically calculate suitable data decompositions. They support BLOCK and CYCLIC distributions, but do not specify alignment. Instead of standard BLOCK distributions, Superb [ZBG88, Ger89, Ger90], Suspense [RW88], and Paragon <ref> [CR89, Ree90] </ref> support arbitrary user-specified contiguous rectangular distributions. Superb also originated the overlap concept as a means to both specify and store nonlocal data accesses. Wolfe [Wol89, Wol90] describes transformations such as loop rotation for programs with BLOCK distributions.
Reference: [FO90] <author> I. Foster and R. Overbeek. </author> <title> Bilingual parallel programming. </title> <booktitle> In Proceedings of the Third Workshop on Languages and Compilers for Parallel Computing, </booktitle> <address> Irvine, CA, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: A major goal for the Center for Research on Parallel Computation (CRPC) is to develop a machine-independent parallel programming model usable for both shared and distributed-memory SIMD/MIMD architectures. High-level parallel languages such as Linda [CG89], Strand <ref> [FT90, FO90] </ref>, and Delirium [LS91] are valuable when used to coordinate coarse-grained functional parallelism. However, these languages do not meet the needs of computational scientists because they are inefficient for capturing fine-grain data parallelism (of the type described by Hillis and Steele [HS86] and Karp [Kar87]).
Reference: [FT90] <author> I. Foster and S. Taylor. Strand: </author> <title> New Concepts in Parallel Programming. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1990. </year>
Reference-contexts: A major goal for the Center for Research on Parallel Computation (CRPC) is to develop a machine-independent parallel programming model usable for both shared and distributed-memory SIMD/MIMD architectures. High-level parallel languages such as Linda [CG89], Strand <ref> [FT90, FO90] </ref>, and Delirium [LS91] are valuable when used to coordinate coarse-grained functional parallelism. However, these languages do not meet the needs of computational scientists because they are inefficient for capturing fine-grain data parallelism (of the type described by Hillis and Steele [HS86] and Karp [Kar87]).
Reference: [GB90] <author> M. Gupta and P. Banerjee. </author> <title> Automatic data partitioning on distributed memory multiprocessors. </title> <type> Technical Report CRHC-90-14, </type> <institution> Center for Reliable and High-Performance Computing, Coordinated Science Laboratory, University of Illinois at Urbana-Champaign, </institution> <month> October </month> <year> 1990. </year>
Reference-contexts: A micro-stencil is derived and used to generate a macro-stencil to identify communication requirements. Communications utilizing Express primitives are then automatically generated. In addition, reductions are identified and replaced with the appropriate Express combine operation. Aspar derives simple BLOCK distributions; alignment specifications are not provided. Gupta and Banerjee <ref> [GB90] </ref> propose a constraint-based approach to automatically calculate suitable data decompositions. They support BLOCK and CYCLIC distributions, but do not specify alignment. Instead of standard BLOCK distributions, Superb [ZBG88, Ger89, Ger90], Suspense [RW88], and Paragon [CR89, Ree90] support arbitrary user-specified contiguous rectangular distributions.
Reference: [Ger89] <author> M. Gerndt. </author> <title> Automatic Parallelization for Distributed-Memory Multiprocessing Systems. </title> <type> PhD thesis, </type> <institution> University of Bonn, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: Aspar derives simple BLOCK distributions; alignment specifications are not provided. Gupta and Banerjee [GB90] propose a constraint-based approach to automatically calculate suitable data decompositions. They support BLOCK and CYCLIC distributions, but do not specify alignment. Instead of standard BLOCK distributions, Superb <ref> [ZBG88, Ger89, Ger90] </ref>, Suspense [RW88], and Paragon [CR89, Ree90] support arbitrary user-specified contiguous rectangular distributions. Superb also originated the overlap concept as a means to both specify and store nonlocal data accesses. Wolfe [Wol89, Wol90] describes transformations such as loop rotation for programs with BLOCK distributions.
Reference: [Ger90] <author> M. Gerndt. </author> <title> Updating distributed variables in local computations. </title> <journal> Concurrency| Practice & Experience, </journal> <volume> 2(3) </volume> <pages> 171-193, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Aspar derives simple BLOCK distributions; alignment specifications are not provided. Gupta and Banerjee [GB90] propose a constraint-based approach to automatically calculate suitable data decompositions. They support BLOCK and CYCLIC distributions, but do not specify alignment. Instead of standard BLOCK distributions, Superb <ref> [ZBG88, Ger89, Ger90] </ref>, Suspense [RW88], and Paragon [CR89, Ree90] support arbitrary user-specified contiguous rectangular distributions. Superb also originated the overlap concept as a means to both specify and store nonlocal data accesses. Wolfe [Wol89, Wol90] describes transformations such as loop rotation for programs with BLOCK distributions.
Reference: [HA90] <author> D. Hudak and S. Abraham. </author> <title> Compiler techniques for data partitioning of sequentially iterated parallel loops. </title> <booktitle> In Proceedings of the 1990 ACM International Conference on Supercomputing, </booktitle> <address> Amsterdam, The Netherlands, </address> <month> June </month> <year> 1990. </year> <month> 31 </month>
Reference-contexts: These researchers do not need alignment or distribution specifications, since they automatically generate the data decomposition. Ramanujam and Sadayappan [RS89] examine both the data and iteration space to derive a combined task and data partition of the loop nest. Hudak and Abraham <ref> [HA90] </ref> find a stencil-based approach useful for analyzing communications and deriving efficient rectangular or hexagonal data distributions. These researchers do not discuss generating communication for the resulting distributions. Spot [SS90, Soc90] is a point-based SIMD data-parallel programming language for single arrays in loops.
Reference: [HKK + 91] <author> S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, and C. Tseng. </author> <title> An overview of the Fortran D programming system. </title> <type> Technical Report TR91-154, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: We are also developing a Fortran 90D compiler for the iPSC/860 [WF91] and a Fortran 77D compiler for the Thinking Machines CM-2. We are pursuing other projects in the Fortran D programming system <ref> [HKK + 91] </ref> at Rice and Syracuse.
Reference: [HKT91a] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Compiler optimizations for Fortran D on MIMD distributed-memory machines. </title> <type> Technical Report TR91-156, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: In fact, any Fortran program is also a valid Fortran D program. We are implementing a compiler to automatically convert Fortran 77D programs into message passing Fortran 77 programs that run on MIMD distributed-memory machines such as the Intel iPSC/860 <ref> [HKT91a, HKT91b] </ref>. In the process we will evaluate both the data decomposition specifications in Fortran D and the effectiveness of advanced compiler techniques for distributed-memory multiprocessors. We are also developing a Fortran 90D compiler for the iPSC/860 [WF91] and a Fortran 77D compiler for the Thinking Machines CM-2.
Reference: [HKT91b] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Compiler support for machine-independent parallel programming in Fortran D. </title> <type> Technical Report TR90-149, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> February </month> <year> 1991. </year> <note> To appear in J. </note> <editor> Saltz and P. Mehrotra, editors, </editor> <title> Compilers and Runtime Software for Scalable Multiprocessors, </title> <publisher> Elsevier, </publisher> <year> 1991. </year>
Reference-contexts: Fortran D programs also have the advantage of being deterministic, unlike programs written in most explicitly parallel languages. We are in the process of implementing a Fortran 77D compiler <ref> [HKT91b] </ref> in the context of the ParaScope programming environment [CCH + 88, BKK + 89]. We chose as our first target the Intel iPSC/860, a MIMD distributed-memory machine. A later project will produce a Fortran 77D compiler for a SIMD distributed-memory machine. <p> In fact, any Fortran program is also a valid Fortran D program. We are implementing a compiler to automatically convert Fortran 77D programs into message passing Fortran 77 programs that run on MIMD distributed-memory machines such as the Intel iPSC/860 <ref> [HKT91a, HKT91b] </ref>. In the process we will evaluate both the data decomposition specifications in Fortran D and the effectiveness of advanced compiler techniques for distributed-memory multiprocessors. We are also developing a Fortran 90D compiler for the iPSC/860 [WF91] and a Fortran 77D compiler for the Thinking Machines CM-2.
Reference: [HS86] <author> W. Hillis and G. Steele, Jr. </author> <title> Data parallel algorithms. </title> <journal> Communications of the ACM, </journal> <volume> 29(12) </volume> <pages> 1170-1183, </pages> <year> 1986. </year>
Reference-contexts: However, these languages do not meet the needs of computational scientists because they are inefficient for capturing fine-grain data parallelism (of the type described by Hillis and Steele <ref> [HS86] </ref> and Karp [Kar87]). This is mainly due to the fact that existing parallel languages lack both language and compiler support to assist in efficient data placement [PB90].
Reference: [IFKF90] <author> K. Ikudome, G. Fox, A. Kolawa, and J. Flower. </author> <title> An automatic and symbolic paral-lelization system for distributed memory parallel computers. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: Systems such as Dino [RSW90], Id Nouveau [RP89], Mimdizer [SWW91], Oxygen [RA90], and Pandore [APT90] all provide data distribution specifications equivalent to some combination of BLOCK and CYCLIC. Dino also supports special stencil-based data distributions with overlaps. The Aspar <ref> [IFKF90] </ref> compiler performs automatic data decomposition and communications generation. A micro-stencil is derived and used to generate a macro-stencil to identify communication requirements. Communications utilizing Express primitives are then automatically generated. In addition, reductions are identified and replaced with the appropriate Express combine operation.
Reference: [Kar87] <author> A. Karp. </author> <title> Programming for parallelism. </title> <journal> IEEE Computer, </journal> <volume> 20(5) </volume> <pages> 43-57, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: However, these languages do not meet the needs of computational scientists because they are inefficient for capturing fine-grain data parallelism (of the type described by Hillis and Steele [HS86] and Karp <ref> [Kar87] </ref>). This is mainly due to the fact that existing parallel languages lack both language and compiler support to assist in efficient data placement [PB90].
Reference: [KLS88] <author> K. Knobe, J. Lukas, and G. Steele, Jr. </author> <title> Massively parallel data optimization. </title> <booktitle> In Fron-tiers88: The 2nd Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> Fair-fax, VA, </address> <month> October </month> <year> 1988. </year>
Reference-contexts: CM Fortran does not possess distribution specifications since the operating system of the underlying SIMD distributed-memory machine provides the illusion of infinite machine size through the use of virtual processors. This approach has freed researchers to concentrate on deriving efficient data alignments <ref> [KLS88, TMC89, KLS90, KN90] </ref>. Proper alignment, including dynamic realignment, is especially important for SIMD machines, leading to a factor of 80-fold improvements in an example program [KN90].
Reference: [KLS90] <author> K. Knobe, J. Lukas, and G. Steele, Jr. </author> <title> Data optimization: Allocation of arrays to reduce communication on SIMD machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8(2) </volume> <pages> 102-118, </pages> <year> 1990. </year>
Reference-contexts: CM Fortran does not possess distribution specifications since the operating system of the underlying SIMD distributed-memory machine provides the illusion of infinite machine size through the use of virtual processors. This approach has freed researchers to concentrate on deriving efficient data alignments <ref> [KLS88, TMC89, KLS90, KN90] </ref>. Proper alignment, including dynamic realignment, is especially important for SIMD machines, leading to a factor of 80-fold improvements in an example program [KN90].
Reference: [KM90] <author> C. Koelbel and P. Mehrotra. </author> <title> Compiler support for unstructured scientific computations. </title> <type> Technical Report TR90-144, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: We are pursuing other projects in the Fortran D programming system [HKK + 91] at Rice and Syracuse. They include automatic data decomposition [BFKK90], static performance estimation using a machine-independent training set [BFKK91], compiler support for unstructured computations <ref> [KM90] </ref>, run-time preprocessing using the Parti communications library [SBW90], as well as a suite of applications programs to evaluate the effectiveness of the Fortran D compiler.
Reference: [KMSB90] <author> C. Koelbel, P. Mehrotra, J. Saltz, and S. Berryman. </author> <title> Parallel loops on distributed machines. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: Parti has also motivated the Arf compiler which supports BLOCK, CYCLIC, and user-defined irregular distributions. Its goal is to demonstrate that inspector and executor loops for run-time preprocessing can be automatically generated by a compiler <ref> [KMSB90, WSBH91] </ref>. Kali [KMV90, MV90], a descendent of Blaze, is the first compiler that supports both regular and irregular computations. It provides BLOCK, CYCLIC, BLOCK CYCLIC, and user-specified data distributions.
Reference: [KMV90] <author> C. Koelbel, P. Mehrotra, and J. Van Rosendale. </author> <title> Supporting shared data structures on distributed memory machines. </title> <booktitle> In Proceedings of the Second ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> Seattle, WA, </address> <month> March </month> <year> 1990. </year>
Reference-contexts: If there are multiple elements with the minimum or maximum value, the assignment is performed only for the first such value found. 5.5 On Clause Fortran D provides a feature from Kali <ref> [KMV90] </ref>, an optional on clause. The on clause is used to specify the processor which will execute each iteration of a loop. <p> Many of them have explored the problem of specifying data decompositions, and we have drawn upon their work. In particular, we have been influenced by alignment specifications and reduction functions from CM Fortran [TMC89] and structures to handle irregular distributions from Parti [WSBH91] and Kali <ref> [KMV90, MV90] </ref>. Here we quickly describe other research in the area. 6.1 Single Array Decomposition Some researchers concentrate on computations within loops that only involve a single array. These researchers do not need alignment or distribution specifications, since they automatically generate the data decomposition. <p> Parti has also motivated the Arf compiler which supports BLOCK, CYCLIC, and user-defined irregular distributions. Its goal is to demonstrate that inspector and executor loops for run-time preprocessing can be automatically generated by a compiler [KMSB90, WSBH91]. Kali <ref> [KMV90, MV90] </ref>, a descendent of Blaze, is the first compiler that supports both regular and irregular computations. It provides BLOCK, CYCLIC, BLOCK CYCLIC, and user-specified data distributions. <p> Kali [KMV90, MV90], a descendent of Blaze, is the first compiler that supports both regular and irregular computations. It provides BLOCK, CYCLIC, BLOCK CYCLIC, and user-specified data distributions. Like Parti, Kali also uses an inspector/executor strategy to support run-time preprocessing of communication for irregularly distributed arrays <ref> [KMV90] </ref>. 29 7 Conclusion Programming languages lack support to efficiently exploit fine-grain data parallelism on distributed-memory machines. We believe that explicit data alignment and distribution specifications provide programmers and compiler writers with the correct paradigm for specifying data decompositions.
Reference: [KN90] <author> K. Knobe and V. Natarajan. </author> <title> Data optimization: Minimizing residual interprocessor data motion on SIMD machines. </title> <booktitle> In Frontiers90: The 3rd Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> College Park, MD, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: CM Fortran does not possess distribution specifications since the operating system of the underlying SIMD distributed-memory machine provides the illusion of infinite machine size through the use of virtual processors. This approach has freed researchers to concentrate on deriving efficient data alignments <ref> [KLS88, TMC89, KLS90, KN90] </ref>. Proper alignment, including dynamic realignment, is especially important for SIMD machines, leading to a factor of 80-fold improvements in an example program [KN90]. <p> This approach has freed researchers to concentrate on deriving efficient data alignments [KLS88, TMC89, KLS90, KN90]. Proper alignment, including dynamic realignment, is especially important for SIMD machines, leading to a factor of 80-fold improvements in an example program <ref> [KN90] </ref>. More recently, researchers have also begun to study strip mining as a technique to avoid the inefficiencies of using virtual processors [Wei91]. 28 Al [Tse90] is a language designed for the Warp distributed-memory systolic processor. The programmer utilizes DARRAY declarations to mark parallel arrays.
Reference: [LC90a] <author> J. Li and M. Chen. </author> <title> Generating explicit communication from shared-memory program references. </title> <booktitle> In Proceedings of Supercomputing '90, </booktitle> <address> New York, NY, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: The compiler then generates computation and communication by expanding the single point algorithm to cover all points distributed onto a node. 6.2 Alignment For computations involving multiple distributed arrays, both alignment and distribution must be dealt with in order to minimize data movement. The Crystal compiler <ref> [CCL89, LC90a, LC90b] </ref> performs automatic data decomposition and communications generation for the Crystal functional language. Heuristics are employed to align data arrays, both within and across dimensions. Different distributions are evaluated, then communication using Crystal collective communication routines is generated.
Reference: [LC90b] <author> J. Li and M. Chen. </author> <title> Index domain alignment: Minimizing cost of cross-referencing between distributed arrays. </title> <booktitle> In Frontiers90: The 3rd Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> College Park, MD, </address> <month> October </month> <year> 1990. </year> <month> 32 </month>
Reference-contexts: The compiler then generates computation and communication by expanding the single point algorithm to cover all points distributed onto a node. 6.2 Alignment For computations involving multiple distributed arrays, both alignment and distribution must be dealt with in order to minimize data movement. The Crystal compiler <ref> [CCL89, LC90a, LC90b] </ref> performs automatic data decomposition and communications generation for the Crystal functional language. Heuristics are employed to align data arrays, both within and across dimensions. Different distributions are evaluated, then communication using Crystal collective communication routines is generated.
Reference: [LS91] <author> S. Lucco and O. Sharp. </author> <title> Parallel programming with coordination structures. </title> <booktitle> In Pro--ceedings of the Eighteenth Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <address> Orlando, FL, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: A major goal for the Center for Research on Parallel Computation (CRPC) is to develop a machine-independent parallel programming model usable for both shared and distributed-memory SIMD/MIMD architectures. High-level parallel languages such as Linda [CG89], Strand [FT90, FO90], and Delirium <ref> [LS91] </ref> are valuable when used to coordinate coarse-grained functional parallelism. However, these languages do not meet the needs of computational scientists because they are inefficient for capturing fine-grain data parallelism (of the type described by Hillis and Steele [HS86] and Karp [Kar87]).
Reference: [MSMB90] <author> S. Mirchandaney, J. Saltz, P. Mehrotra, and H. Berryman. </author> <title> A scheme for supporting automatic data migration on multicomputers. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: Finally, there are two systems that provide irregular data distributions to support irregular computations. Parti [SBW90], a set of run-time library routines, is first to propose and implement user-defined irregular distributions [MSS + 88], as well as a hashed cache for nonlocal values <ref> [MSMB90] </ref>. Parti has also motivated the Arf compiler which supports BLOCK, CYCLIC, and user-defined irregular distributions. Its goal is to demonstrate that inspector and executor loops for run-time preprocessing can be automatically generated by a compiler [KMSB90, WSBH91].
Reference: [MSS + 88] <author> R. Mirchandaney, J. Saltz, R. Smith, D. Nicol, and K. Crowley. </author> <title> Principles of runtime support for parallel processors. </title> <booktitle> In Proceedings of the Second International Conference on Supercomputing, </booktitle> <address> St. Malo, France, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: Finally, there are two systems that provide irregular data distributions to support irregular computations. Parti [SBW90], a set of run-time library routines, is first to propose and implement user-defined irregular distributions <ref> [MSS + 88] </ref>, as well as a hashed cache for nonlocal values [MSMB90]. Parti has also motivated the Arf compiler which supports BLOCK, CYCLIC, and user-defined irregular distributions. Its goal is to demonstrate that inspector and executor loops for run-time preprocessing can be automatically generated by a compiler [KMSB90, WSBH91].
Reference: [MV90] <author> P. Mehrotra and J. Van Rosendale. </author> <title> Programming distributed memory architectures using Kali. </title> <type> ICASE Report 90-69, </type> <institution> Institute for Computer Application in Science and Engineering, Hampton, VA, </institution> <month> October </month> <year> 1990. </year>
Reference-contexts: Many of them have explored the problem of specifying data decompositions, and we have drawn upon their work. In particular, we have been influenced by alignment specifications and reduction functions from CM Fortran [TMC89] and structures to handle irregular distributions from Parti [WSBH91] and Kali <ref> [KMV90, MV90] </ref>. Here we quickly describe other research in the area. 6.1 Single Array Decomposition Some researchers concentrate on computations within loops that only involve a single array. These researchers do not need alignment or distribution specifications, since they automatically generate the data decomposition. <p> Parti has also motivated the Arf compiler which supports BLOCK, CYCLIC, and user-defined irregular distributions. Its goal is to demonstrate that inspector and executor loops for run-time preprocessing can be automatically generated by a compiler [KMSB90, WSBH91]. Kali <ref> [KMV90, MV90] </ref>, a descendent of Blaze, is the first compiler that supports both regular and irregular computations. It provides BLOCK, CYCLIC, BLOCK CYCLIC, and user-specified data distributions.
Reference: [PB90] <author> C. Pancake and D. Bergmark. </author> <title> Do parallel languages respond to the needs of scientific programmers? IEEE Computer, </title> <booktitle> 23(12) </booktitle> <pages> 13-23, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: This is mainly due to the fact that existing parallel languages lack both language and compiler support to assist in efficient data placement <ref> [PB90] </ref>.
Reference: [Pri90] <author> J. Prins. </author> <title> A framework for efficient execution of array-based languages on SIMD computers. </title> <booktitle> In Frontiers90: The 3rd Symposium on the Frontiers of Massively Parallel Computation, </booktitle> <address> College Park, MD, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: Callahan and Kennedy [CK88] propose methods for compiling programs with user-specified data distribution functions. They also demonstrate how such programs can be optimized using loop transformations. Booster [PvGS90] also provides user-specified distribution functions defined as program views, but does not generate or optimize communications. Prins <ref> [Pri90] </ref> utilizes shape refinement in conjunction with linear transformations to specify data layouts and guide resulting data motion. Finally, there are two systems that provide irregular data distributions to support irregular computations.
Reference: [PvGS90] <author> E. Paalvast, A. van Gemund, and H. Sips. </author> <title> A method for parallel program generation with an application to the Booster language. </title> <booktitle> In Proceedings of the 1990 ACM International Conference on Supercomputing, </booktitle> <address> Amsterdam, The Netherlands, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Wolfe [Wol89, Wol90] describes transformations such as loop rotation for programs with BLOCK distributions. Callahan and Kennedy [CK88] propose methods for compiling programs with user-specified data distribution functions. They also demonstrate how such programs can be optimized using loop transformations. Booster <ref> [PvGS90] </ref> also provides user-specified distribution functions defined as program views, but does not generate or optimize communications. Prins [Pri90] utilizes shape refinement in conjunction with linear transformations to specify data layouts and guide resulting data motion. Finally, there are two systems that provide irregular data distributions to support irregular computations.
Reference: [RA90] <author> R. Ruhl and M. Annaratone. </author> <title> Parallelization of fortran code on distributed-memory parallel processors. </title> <booktitle> In Proceedings of the 1990 ACM International Conference on Supercomputing, </booktitle> <address> Amsterdam, The Netherlands, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: These systems do not directly specify alignments between arrays. Instead, they distribute each array individually and implicitly derive the alignment between different arrays based on their relative distributions. Systems such as Dino [RSW90], Id Nouveau [RP89], Mimdizer [SWW91], Oxygen <ref> [RA90] </ref>, and Pandore [APT90] all provide data distribution specifications equivalent to some combination of BLOCK and CYCLIC. Dino also supports special stencil-based data distributions with overlaps. The Aspar [IFKF90] compiler performs automatic data decomposition and communications generation.
Reference: [Ree90] <author> A. Reeves. </author> <title> The Paragon programming paradigm and distributed memory compilers. </title> <type> Technical Report EE-CEG-90-7, </type> <institution> Cornell University Computer Engineering Group, </institution> <address> Ithaca, NY, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Aspar derives simple BLOCK distributions; alignment specifications are not provided. Gupta and Banerjee [GB90] propose a constraint-based approach to automatically calculate suitable data decompositions. They support BLOCK and CYCLIC distributions, but do not specify alignment. Instead of standard BLOCK distributions, Superb [ZBG88, Ger89, Ger90], Suspense [RW88], and Paragon <ref> [CR89, Ree90] </ref> support arbitrary user-specified contiguous rectangular distributions. Superb also originated the overlap concept as a means to both specify and store nonlocal data accesses. Wolfe [Wol89, Wol90] describes transformations such as loop rotation for programs with BLOCK distributions.
Reference: [RP89] <author> A. Rogers and K. Pingali. </author> <title> Process decomposition through locality of reference. </title> <booktitle> In Proceedings of the SIGPLAN '89 Conference on Program Language Design and Implementation, </booktitle> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: These systems do not directly specify alignments between arrays. Instead, they distribute each array individually and implicitly derive the alignment between different arrays based on their relative distributions. Systems such as Dino [RSW90], Id Nouveau <ref> [RP89] </ref>, Mimdizer [SWW91], Oxygen [RA90], and Pandore [APT90] all provide data distribution specifications equivalent to some combination of BLOCK and CYCLIC. Dino also supports special stencil-based data distributions with overlaps. The Aspar [IFKF90] compiler performs automatic data decomposition and communications generation.
Reference: [RS89] <author> J. Ramanujam and P. Sadayappan. </author> <title> A methodology for parallelizing programs for mul-ticomputers and complex memory multiprocessors. </title> <booktitle> In Proceedings of Supercomputing '89, </booktitle> <address> Reno, NV, </address> <month> November </month> <year> 1989. </year>
Reference-contexts: Here we quickly describe other research in the area. 6.1 Single Array Decomposition Some researchers concentrate on computations within loops that only involve a single array. These researchers do not need alignment or distribution specifications, since they automatically generate the data decomposition. Ramanujam and Sadayappan <ref> [RS89] </ref> examine both the data and iteration space to derive a combined task and data partition of the loop nest. Hudak and Abraham [HA90] find a stencil-based approach useful for analyzing communications and deriving efficient rectangular or hexagonal data distributions.
Reference: [RSW90] <author> M. Rosing, R. Schnabel, and R. Weaver. </author> <title> The DINO parallel programming language. </title> <type> Technical Report CU-CS-457-90, </type> <institution> Dept. of Computer Science, University of Colorado, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: These systems do not directly specify alignments between arrays. Instead, they distribute each array individually and implicitly derive the alignment between different arrays based on their relative distributions. Systems such as Dino <ref> [RSW90] </ref>, Id Nouveau [RP89], Mimdizer [SWW91], Oxygen [RA90], and Pandore [APT90] all provide data distribution specifications equivalent to some combination of BLOCK and CYCLIC. Dino also supports special stencil-based data distributions with overlaps. The Aspar [IFKF90] compiler performs automatic data decomposition and communications generation.
Reference: [RW88] <author> Th. Ruppelt and G. Wirtz. </author> <title> From mathematical specifications to parallel programs on a message-based system. </title> <booktitle> In Proceedings of the Second International Conference on Supercomputing, </booktitle> <address> St. Malo, France, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: Aspar derives simple BLOCK distributions; alignment specifications are not provided. Gupta and Banerjee [GB90] propose a constraint-based approach to automatically calculate suitable data decompositions. They support BLOCK and CYCLIC distributions, but do not specify alignment. Instead of standard BLOCK distributions, Superb [ZBG88, Ger89, Ger90], Suspense <ref> [RW88] </ref>, and Paragon [CR89, Ree90] support arbitrary user-specified contiguous rectangular distributions. Superb also originated the overlap concept as a means to both specify and store nonlocal data accesses. Wolfe [Wol89, Wol90] describes transformations such as loop rotation for programs with BLOCK distributions.
Reference: [SBW90] <author> J. Saltz, H. Berryman, and J. Wu. </author> <title> Multiprocessors and runtime compilation. </title> <type> ICASE Report 90-59, </type> <institution> Institute for Computer Application in Science and Engineering, </institution> <address> Hamp 33 ton, VA, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: Prins [Pri90] utilizes shape refinement in conjunction with linear transformations to specify data layouts and guide resulting data motion. Finally, there are two systems that provide irregular data distributions to support irregular computations. Parti <ref> [SBW90] </ref>, a set of run-time library routines, is first to propose and implement user-defined irregular distributions [MSS + 88], as well as a hashed cache for nonlocal values [MSMB90]. Parti has also motivated the Arf compiler which supports BLOCK, CYCLIC, and user-defined irregular distributions. <p> We are pursuing other projects in the Fortran D programming system [HKK + 91] at Rice and Syracuse. They include automatic data decomposition [BFKK90], static performance estimation using a machine-independent training set [BFKK91], compiler support for unstructured computations [KM90], run-time preprocessing using the Parti communications library <ref> [SBW90] </ref>, as well as a suite of applications programs to evaluate the effectiveness of the Fortran D compiler.
Reference: [Soc90] <author> D. Socha. </author> <title> Compiling single-point iterative programs for distributed memory computers. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: Hudak and Abraham [HA90] find a stencil-based approach useful for analyzing communications and deriving efficient rectangular or hexagonal data distributions. These researchers do not discuss generating communication for the resulting distributions. Spot <ref> [SS90, Soc90] </ref> is a point-based SIMD data-parallel programming language for single arrays in loops. Computations are specified from the point of view of a single element in the array. This stencil-based approach allows the Spot compiler to derive efficient near-rectangular data distributions.
Reference: [SS90] <author> L. Snyder and D. Socha. </author> <title> An algorithm producing balanced partitionings of data arrays. </title> <booktitle> In Proceedings of the 5th Distributed Memory Computing Conference, </booktitle> <address> Charleston, SC, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: Hudak and Abraham [HA90] find a stencil-based approach useful for analyzing communications and deriving efficient rectangular or hexagonal data distributions. These researchers do not discuss generating communication for the resulting distributions. Spot <ref> [SS90, Soc90] </ref> is a point-based SIMD data-parallel programming language for single arrays in loops. Computations are specified from the point of view of a single element in the array. This stencil-based approach allows the Spot compiler to derive efficient near-rectangular data distributions.
Reference: [SWW91] <author> R. Sawdayi, G. Wagenbreth, and J. Williamson. MIMDizer: </author> <title> Functional and data decomposition; creating parallel programs from scratch, transforming existing Fortran programs to parallel. </title> <editor> In J. Saltz and P. Mehrotra, editors, </editor> <title> Compilers and Runtime Software for Scalable Multiprocessors. </title> <publisher> Elsevier, </publisher> <address> Amsterdam, The Netherlands, </address> <note> to appear 1991. </note>
Reference-contexts: These systems do not directly specify alignments between arrays. Instead, they distribute each array individually and implicitly derive the alignment between different arrays based on their relative distributions. Systems such as Dino [RSW90], Id Nouveau [RP89], Mimdizer <ref> [SWW91] </ref>, Oxygen [RA90], and Pandore [APT90] all provide data distribution specifications equivalent to some combination of BLOCK and CYCLIC. Dino also supports special stencil-based data distributions with overlaps. The Aspar [IFKF90] compiler performs automatic data decomposition and communications generation.
Reference: [TMC89] <institution> Thinking Machines Corporation, </institution> <address> Cambridge, MA. </address> <note> CM Fortran Reference Manual, version 5.2-0.6 edition, </note> <month> September </month> <year> 1989. </year>
Reference-contexts: The extensions proposed in Fortran D are compatible with both Fortran 77 and Fortran 90, a version of Fortran with explicit manipulation of high-level array structures. Fortran 90D can be viewed as a refinement of CM Fortran <ref> [TMC89] </ref> consistent with a parallel Fortran 77. We believe that Fortran D is powerful enough to express most fine-grain parallel computations, but also simple enough that a sophisticated compiler can produce efficient programs for different parallel architectures. <p> In particular, FORALL loops are deterministic. As a result we believe that it will be easy to understand and use for scientific programmers. The FORALL loop possesses similar semantics to the CM Fortran FORALL statement <ref> [TMC89, ALS90] </ref> and the Myrias PARDO loop. <p> Many of them have explored the problem of specifying data decompositions, and we have drawn upon their work. In particular, we have been influenced by alignment specifications and reduction functions from CM Fortran <ref> [TMC89] </ref> and structures to handle irregular distributions from Parti [WSBH91] and Kali [KMV90, MV90]. Here we quickly describe other research in the area. 6.1 Single Array Decomposition Some researchers concentrate on computations within loops that only involve a single array. <p> Heuristics are employed to align data arrays, both within and across dimensions. Different distributions are evaluated, then communication using Crystal collective communication routines is generated. Since data decompositions are automatically calculated, no decomposition specifications are provided. CM Fortran <ref> [AKLS88, TMC89] </ref> is a version of Fortran extended with vector notation, alignment, and data layout specifications. Programmers must explicitly specify data parallelism in CM Fortran programs by marking certain array dimensions as parallel. <p> CM Fortran does not possess distribution specifications since the operating system of the underlying SIMD distributed-memory machine provides the illusion of infinite machine size through the use of virtual processors. This approach has freed researchers to concentrate on deriving efficient data alignments <ref> [KLS88, TMC89, KLS90, KN90] </ref>. Proper alignment, including dynamic realignment, is especially important for SIMD machines, leading to a factor of 80-fold improvements in an example program [KN90].
Reference: [Tse90] <author> P. S. Tseng. </author> <title> A parallelizing compiler for distributed memory parallel computers. </title> <booktitle> In Proceedings of the SIGPLAN '90 Conference on Program Language Design and Implementation, </booktitle> <address> White Plains, NY, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Proper alignment, including dynamic realignment, is especially important for SIMD machines, leading to a factor of 80-fold improvements in an example program [KN90]. More recently, researchers have also begun to study strip mining as a technique to avoid the inefficiencies of using virtual processors [Wei91]. 28 Al <ref> [Tse90] </ref> is a language designed for the Warp distributed-memory systolic processor. The programmer utilizes DARRAY declarations to mark parallel arrays. The Al compiler then applies data relations to automatically align and distribute each DARRAY, detect parallelism, and generate communication.
Reference: [Wei91] <author> M. Weiss. </author> <title> Strip mining on SIMD architectures. </title> <booktitle> In Proceedings of the 1991 ACM International Conference on Supercomputing, </booktitle> <address> Cologne, Germany, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Proper alignment, including dynamic realignment, is especially important for SIMD machines, leading to a factor of 80-fold improvements in an example program [KN90]. More recently, researchers have also begun to study strip mining as a technique to avoid the inefficiencies of using virtual processors <ref> [Wei91] </ref>. 28 Al [Tse90] is a language designed for the Warp distributed-memory systolic processor. The programmer utilizes DARRAY declarations to mark parallel arrays. The Al compiler then applies data relations to automatically align and distribute each DARRAY, detect parallelism, and generate communication.
Reference: [WF91] <author> M. Wu and G. Fox. </author> <title> Compiling Fortran90 programs for distributed memory MIMD parallel computers. </title> <type> CRPC Report CRPC-TR91126, </type> <institution> Center for Research on Parallel Computation, Syracuse University, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: We chose as our first target the Intel iPSC/860, a MIMD distributed-memory machine. A later project will produce a Fortran 77D compiler for a SIMD distributed-memory machine. We have also started a Fortran 90D compiler aimed at the iPSC/860 and NCUBE-2 hypercube <ref> [WF91] </ref>. We plan to compare how closely Fortran D compilers can approach the performance of hand-coded programs, and use our experiences to evaluate the usefulness of Fortran D for data-parallel programming. <p> In the process we will evaluate both the data decomposition specifications in Fortran D and the effectiveness of advanced compiler techniques for distributed-memory multiprocessors. We are also developing a Fortran 90D compiler for the iPSC/860 <ref> [WF91] </ref> and a Fortran 77D compiler for the Thinking Machines CM-2. We are pursuing other projects in the Fortran D programming system [HKK + 91] at Rice and Syracuse.
Reference: [Wol89] <author> M. J. Wolfe. </author> <title> Semi-automatic domain decomposition. </title> <booktitle> In Proceedings of the 4th Conference on Hypercube Concurrent Computers and Applications, </booktitle> <address> Monterey, CA, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: Instead of standard BLOCK distributions, Superb [ZBG88, Ger89, Ger90], Suspense [RW88], and Paragon [CR89, Ree90] support arbitrary user-specified contiguous rectangular distributions. Superb also originated the overlap concept as a means to both specify and store nonlocal data accesses. Wolfe <ref> [Wol89, Wol90] </ref> describes transformations such as loop rotation for programs with BLOCK distributions. Callahan and Kennedy [CK88] propose methods for compiling programs with user-specified data distribution functions. They also demonstrate how such programs can be optimized using loop transformations.
Reference: [Wol90] <author> M. J. Wolfe. </author> <title> Loop rotation. </title> <editor> In D. Gelernter, A. Nicolau, and D. Padua, editors, </editor> <booktitle> Languages and Compilers for Parallel Computing. </booktitle> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Instead of standard BLOCK distributions, Superb [ZBG88, Ger89, Ger90], Suspense [RW88], and Paragon [CR89, Ree90] support arbitrary user-specified contiguous rectangular distributions. Superb also originated the overlap concept as a means to both specify and store nonlocal data accesses. Wolfe <ref> [Wol89, Wol90] </ref> describes transformations such as loop rotation for programs with BLOCK distributions. Callahan and Kennedy [CK88] propose methods for compiling programs with user-specified data distribution functions. They also demonstrate how such programs can be optimized using loop transformations.
Reference: [WSBH91] <author> J. Wu, J. Saltz, H. Berryman, and S. Hiranandani. </author> <title> Distributed memory compiler design for sparse problems. </title> <type> ICASE Report 91-13, </type> <institution> Institute for Computer Application in Science and Engineering, Hampton, VA, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: Many of them have explored the problem of specifying data decompositions, and we have drawn upon their work. In particular, we have been influenced by alignment specifications and reduction functions from CM Fortran [TMC89] and structures to handle irregular distributions from Parti <ref> [WSBH91] </ref> and Kali [KMV90, MV90]. Here we quickly describe other research in the area. 6.1 Single Array Decomposition Some researchers concentrate on computations within loops that only involve a single array. These researchers do not need alignment or distribution specifications, since they automatically generate the data decomposition. <p> Parti has also motivated the Arf compiler which supports BLOCK, CYCLIC, and user-defined irregular distributions. Its goal is to demonstrate that inspector and executor loops for run-time preprocessing can be automatically generated by a compiler <ref> [KMSB90, WSBH91] </ref>. Kali [KMV90, MV90], a descendent of Blaze, is the first compiler that supports both regular and irregular computations. It provides BLOCK, CYCLIC, BLOCK CYCLIC, and user-specified data distributions.
Reference: [ZBG88] <author> H. Zima, H.-J. Bast, and M. Gerndt. </author> <title> SUPERB: A tool for semi-automatic MIMD/SIMD parallelization. </title> <journal> Parallel Computing, </journal> <volume> 6 </volume> <pages> 1-18, </pages> <year> 1988. </year> <month> 34 </month>
Reference-contexts: Aspar derives simple BLOCK distributions; alignment specifications are not provided. Gupta and Banerjee [GB90] propose a constraint-based approach to automatically calculate suitable data decompositions. They support BLOCK and CYCLIC distributions, but do not specify alignment. Instead of standard BLOCK distributions, Superb <ref> [ZBG88, Ger89, Ger90] </ref>, Suspense [RW88], and Paragon [CR89, Ree90] support arbitrary user-specified contiguous rectangular distributions. Superb also originated the overlap concept as a means to both specify and store nonlocal data accesses. Wolfe [Wol89, Wol90] describes transformations such as loop rotation for programs with BLOCK distributions.
References-found: 57

