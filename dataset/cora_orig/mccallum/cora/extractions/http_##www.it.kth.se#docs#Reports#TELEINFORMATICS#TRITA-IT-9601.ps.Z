URL: http://www.it.kth.se/docs/Reports/TELEINFORMATICS/TRITA-IT-9601.ps.Z
Refering-URL: http://www.it.kth.se/docs/Reports/TELEINFORMATICS/
Root-URL: http://www.it.kth.se
Phone: tel: +46 8 752 13 78, fax: +46 8 751 17 93  
Title: Flow Inference, Code Generation, and Garbage Collection for Lazy Functional Languages  
Author: Karl-Filip Faxen 
Address: Electrum 204, S-164 40 Kista  
Affiliation: Dept. of Teleinformatics, Royal Institute of Technology  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Alexander Aiken, Edward L. Wimmers, and T. K. Lakshman. </author> <title> Soft typing with conditional types. </title> <booktitle> In Conference Record of POPL '94: 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 163-173, </pages> <address> Portland, Oregon, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: As a generalization, one can use inclusion constraints rather than equality constraints; then we have fo 00 o -&gt; o 0 g in place of the above constraint. See Aiken et. al. <ref> [1] </ref> and Smith [48] for type systems defined in this way. <p> Another complexity here is the generalization predicate, which we will discuss in more detail below. 2.2. THE TYPE SYSTEM 47 Another thing to note about the LET rule is that, in contrast to systems like those in <ref> [1] </ref> and [48], we do not have the restriction that Sol (S) be nonempty | instead we have the restriction that x must occur in e 0 (the body of the let expression).
Reference: [2] <author> Andrew W. Appel. </author> <title> Simple generational garbage collection and stack allocation. </title> <journal> Software Practice & Experience, </journal> <volume> 19(2) </volume> <pages> 171-183, </pages> <month> Mar 88. </month>
Reference-contexts: Andrew Ap-pels compiler for Standard ML, the SML/NJ compiler, has used a generational collector since its inception <ref> [2] </ref>; this collector has since been replaced by a new improved collector [40] which is also generational. Also, the Glasgow Haskell Compiler uses a two generation collector [43].
Reference: [3] <author> Andrew W. Appel and Trevor Jim. </author> <title> Continuation-passing, closure-passing style. </title> <booktitle> In Conference Record of the Sixteenth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 293-302, </pages> <address> Austin, Texas, </address> <month> Jan-uary </month> <year> 1989. </year>
Reference-contexts: Figure 4.1 shows the organization of the heap. After this brief sketch, we will now look closer at the different parts of the opc garbage collector. to measurements of code generated by the SML/NJ compiler which allocates all activation frames on the heap <ref> [3, 13] </ref>. 111 112 CHAPTER 4. THE GARBAGE COLLECTOR 4.1 Organization of the Heap In the current implementation, the heap is one contiguous block of memory. It is quite possible to use a non-contiguous area for the heap | our collection algorithms can easily be adapted to that environment.
Reference: [4] <author> Lennart Augustsson. </author> <title> A compiler for Lazy ML. </title> <booktitle> In Conference Record of the 1984 ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pages 218-227, </pages> <address> Austin, Texas, </address> <month> August </month> <year> 1984. </year> <note> ACM Press. </note>
Reference: [5] <author> Lennart Augustsson and Thomas Johnsson. </author> <title> Parallel graph reduction with the h; Gi-machine. </title> <booktitle> In Proc. Fourth Int. Conf. on Functional Programming, Languages and Computer Architecture '89, </booktitle> <pages> pages 202-213, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: If the value can not be proved to be in whnf, our scheme, like the original G-machine [24], requires a separate forcing operation prior to the case. If the value turns out to be a whnf, then our force operation, as in the h; Gi-machine <ref> [5] </ref> but unlike the original G-machine, is rather cheap and our scheme is still more efficient than the merged force/case, if only by a small margin. If, however, the value really is a thunk, we do lose.
Reference: [6] <author> Thomas Ball and James R. Larus. </author> <title> Branch prediction for free. </title> <journal> SIGPLAN Notices, </journal> <volume> 28(6) </volume> <pages> 300-313, </pages> <month> June </month> <year> 1993. </year> <booktitle> Proceedings of the ACM SIGPLAN '93 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: Currently, we are only performing profile based branch prediction, but we are planning to add program based prediction as well. The latter technique is based on some set of heuristics, such as those presented by Ball and Larus in <ref> [6] </ref>, and we are interested in studying possible alternatives using high level information. Ball and Larus cites branch misprediction rates of about 20% for their heuristics; this is enough to decrease the cost of braches substantially but perhaps not good enough to support trace scheduling.
Reference: [7] <author> David A. Barrett and Benjamin G. Zorn. </author> <title> Garbage collection using a dynamic threatening boundary. </title> <type> Technical Report CU-CS-659-93, </type> <institution> University of Colorado, Department of Computer Science, </institution> <year> 1993. </year>
Reference-contexts: Cheap, variable sized generations open up new and interesting possibilities in the areas of promotion policies and collection scheduling, in a way similar to Barret and Zorns Dynamic Threatening Boundary <ref> [7] </ref>. 4.4 Promotion Policies and Collection Schedul ing The promotion policy determines when objects in a younger generation are promoted to the next older generation 10 and collection scheduling is concerned with the question of when garbage collection should take place and how many 8 Since opc currently implements neither arrays
Reference: [8] <author> Urban Boquist. </author> <title> Interprocedural register allocation for lazy functional languages. </title> <booktitle> In FPCA'95, </booktitle> <address> San Diego, California, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Sestoft, in [45], however, explores the use of closure information to turn first order analyses into higher order analyses which is close in spirit to our applications were we combine flow information with local information. Recently, Boquist <ref> [8] </ref>, building on earlier work by Johnsson [25], has applied constructor analysis to the optimization of a graph reduction intermediate language. The transformations performed are related to our eval elimination, but the formulation is rather different. Boquist also uses the analysis information to enable interprocedural register allocation. <p> The third reason is that there are certain low-level optimizations that require close cooperation between the middle-end and the code generator. One example is interprocedural register allocation based on flow information, as performed by Boquist <ref> [8] </ref>. There is no way to tell the C-compiler that a certain indirect call site (where the called function is identified by a function pointer) can only transfer control to a certain subset of the functions in the program. <p> We are planning to add and interprocedural register allocator along the lines of [50], but Boquists interprocedural coalescing technique is an interesting alternative <ref> [8] </ref>. 94 CHAPTER 3.
Reference: [9] <author> David G. Bradlee, Susan J. Eggers, and Robert R. Henry. </author> <title> Integrating register allocation and instruction scheduling for RISCs. </title> <booktitle> In 4th International 143 144 BIBLIOGRAPHY Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 122-131, </pages> <address> Santa Clara, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: In general, this is good for the register-abundant RISC architectures we are interested in, but even if register pressure is an issue, the scheduler can be made to schedule for minimal register usage when storage is getting tight, as discussed in <ref> [9] </ref>, again motivating its place before register allocation. The placement of save and restore instructions can also be improved using branch prediction information, but we have not yet implemented this. Instruction Scheduling Currently, we use a provably correct, zero line instruction scheduler which never changes the order of any instructions.
Reference: [10] <author> P. Briggs, K. D. Cooper, and L. Torczon. </author> <title> Improvements to graph coloring register allocation. </title> <journal> ACM Transactions on Programming Languages and Systems (TOPLAS), </journal> <volume> 16(3) </volume> <pages> 428-455, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Variables are currently allocated to registers in a fairly random order, but we are planning to implement an order which first allocates variables with many neighbours in the interference graph, as described in <ref> [10, 11] </ref>. A variable is allocated to a register as follows: 1. If the variable has a single targeting and that register is free, it is allocated there. 2.
Reference: [11] <author> G. J. Chaitin, M. A. Auslander, A. K. Chandra, J. Cocke, M. E. Hop-kins, and P. W. Markstein. </author> <title> Register allocation via coloring. </title> <journal> Computer Languages, </journal> <volume> 6 </volume> <pages> 47-57, </pages> <year> 1981. </year>
Reference-contexts: Variables are currently allocated to registers in a fairly random order, but we are planning to implement an order which first allocates variables with many neighbours in the interference graph, as described in <ref> [10, 11] </ref>. A variable is allocated to a register as follows: 1. If the variable has a single targeting and that register is free, it is allocated there. 2.
Reference: [12] <author> Luis Damas and Robin Milner. </author> <title> Principal type-schemes for functional programs. </title> <booktitle> In Conference Record of the Ninth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 207-212, </pages> <year> 1982. </year>
Reference: [13] <author> Amer Diwan, David Tarditi, and Eliot Moss. </author> <title> Memory subsystem performance of programs using copying garbage collection. </title> <booktitle> In Principles of Programming Languages, </booktitle> <pages> pages 1-14. </pages> <publisher> ACM, </publisher> <year> 1994. </year>
Reference-contexts: Figure 4.1 shows the organization of the heap. After this brief sketch, we will now look closer at the different parts of the opc garbage collector. to measurements of code generated by the SML/NJ compiler which allocates all activation frames on the heap <ref> [3, 13] </ref>. 111 112 CHAPTER 4. THE GARBAGE COLLECTOR 4.1 Organization of the Heap In the current implementation, the heap is one contiguous block of memory. It is quite possible to use a non-contiguous area for the heap | our collection algorithms can easily be adapted to that environment.
Reference: [14] <author> Benjamin Goldberg. </author> <title> Detecting sharing of partial applications in functional programs. </title> <booktitle> In Proc. Functional Programming Lang. and Computer Arch., </booktitle> <pages> pages 408-425. </pages> <publisher> Springer Verlag, </publisher> <year> 1987. </year>
Reference-contexts: On the other hand, Peyton-Jones and Launchbury [39] take all of the requirements (polymorphism, gc and lazy evaluation) into account. They do not give any algorithm but rather argues that representation selection should be done by the programmer. In <ref> [14] </ref>, Goldberg presents an abstract interpretation that detects sharing 60 CHAPTER 2. OPTIMIZING LAZY FUNCTIONAL ... of partial applications in a nonstrict higher order language, and applies it to the generation of fully lazy supercombinators.
Reference: [15] <author> C. K. Gomard and P. Sestoft. </author> <title> Evaluation order analysis for lazy data structures. </title> <editor> In Heldal, Holst, and Wadler, editors, </editor> <booktitle> Functional Programming, Glasgow Workshop 1991, </booktitle> <pages> pages 112-127. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: Thunk inlining is already discussed by Mycroft (but only for a first order language) [34] and by Johnsson [24] who also discusses eval elimination, although he does not give any algorithm and does not discuss the interaction. Gomard and Sestoft <ref> [15, 16] </ref> and others have studied path analysis which is similar to eval elimination. Boxing has been treated by several authors, a recent example being [20] where Henglein and Jorgensen, building on work by Leroy [31], defines an optimality criterion for boxing completions in a call-by-value language.
Reference: [16] <author> C. K. Gomard and P. Sestoft. </author> <title> Path analysis for lazy data structures. </title> <editor> In M. Bruynooghe and M. Wirsing, editors, </editor> <booktitle> Programming Language Implementation and Logic Programming, 4th International Symposium, PLILP '92, Leuven, Belgium. (Lecture Notes in Computer Science, </booktitle> <volume> vol. 631), </volume> <pages> pages 54-68. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Thunk inlining is already discussed by Mycroft (but only for a first order language) [34] and by Johnsson [24] who also discusses eval elimination, although he does not give any algorithm and does not discuss the interaction. Gomard and Sestoft <ref> [15, 16] </ref> and others have studied path analysis which is similar to eval elimination. Boxing has been treated by several authors, a recent example being [20] where Henglein and Jorgensen, building on work by Leroy [31], defines an optimality criterion for boxing completions in a call-by-value language.
Reference: [17] <author> P. H. Hartel. </author> <title> Benchmarking implementations of lazy functional languages II two years later. </title> <type> Technical Report Cs-94-21, </type> <institution> Dept. of Comp. Sys, Univ. of Amsterdam, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: Examples include the Glasgow Haskell Compiler (ghc) [37, 38], the FAST/FCG compiler jointly developed by the universities of Amsterdam and Southampton [18, 28], the Bigloo Scheme compiler and the Camloo CAML compiler based on it. In a recent study <ref> [17] </ref>, ghc is shown to be performance-leading among compilers for lazy functional languages, and Camloo/Bigloo are very competitive compilers for strict languages.
Reference: [18] <author> Pieter Hartel, Hugh Glaser, and John Wild. </author> <title> FAST compiler user's guide, </title> <type> 93. </type>
Reference-contexts: C has been used as target language for several implementations of strict and lazy functional languages. Examples include the Glasgow Haskell Compiler (ghc) [37, 38], the FAST/FCG compiler jointly developed by the universities of Amsterdam and Southampton <ref> [18, 28] </ref>, the Bigloo Scheme compiler and the Camloo CAML compiler based on it. In a recent study [17], ghc is shown to be performance-leading among compilers for lazy functional languages, and Camloo/Bigloo are very competitive compilers for strict languages.
Reference: [19] <author> Nevin Heintze. </author> <title> Set-based analysis of ML programs. </title> <booktitle> In Proc. ACM Conference on LISP and Functional Programming, </booktitle> <year> 1994. </year>
Reference-contexts: It has been called closure analysis by Sestoft [45] and others, flow information by Steckler and Wand [56] and others, and control flow information by Jones, Shivers [47], and others. It is also closely related to set based analysis <ref> [19] </ref>. The way in which the information is computed also varies. In older work, such as that by Sestoft, Jones and Shivers, abstract interpretation is generally 2.5. <p> In older work, such as that by Sestoft, Jones and Shivers, abstract interpretation is generally 2.5. RELATED WORK 59 used, but recently there have been a number of formulations in terms of constraint systems, among which are Steckler and Wand [56] and Heintze <ref> [19] </ref>. Also, Palsberg [36] has used a similar framework. Common to these analyses is that the analysis problem to be solved is set up in terms of the expressions etc in the program to be analyzed. Therefore, the entire program is always needed, and separate compilation becomes very troublesome.
Reference: [20] <author> Fritz Henglein and Jesper Jorgensen. </author> <title> Formally optimal boxing. </title> <booktitle> In Conference Record of POPL '94: 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 213-226, </pages> <address> Portland, Oregon, </address> <month> January </month> <year> 1994. </year> <note> BIBLIOGRAPHY 145 </note>
Reference-contexts: Gomard and Sestoft [15, 16] and others have studied path analysis which is similar to eval elimination. Boxing has been treated by several authors, a recent example being <ref> [20] </ref> where Henglein and Jorgensen, building on work by Leroy [31], defines an optimality criterion for boxing completions in a call-by-value language. Here boxing is used only because of polymorphism, but they do not treat the requirements from garbage collection and lazy evaluation.
Reference: [21] <editor> Hudak et al. </editor> <title> Report on the programming language Haskell, a non-strict purely funcional language, version 1.2. </title> <journal> Sigplan Notices, </journal> <volume> 27(5), </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: We give the definition of Infer in Fig. 2.10 and Fig. 2.11. Most implementations of lazy functional laguages pass the value of the program to the run-time system for printing (or interpretation, as in the case of the Haskell I/O model <ref> [21] </ref>). Given that Infer (;; P ) = (S; o ), we model I/O by the constraint o o run where o run is an AnnoType representing the run-time system.
Reference: [22] <author> John Hughes. </author> <title> Compile-time analysis of functional programs. </title> <editor> In David Turner, editor, </editor> <booktitle> Research Topics in Functional Programming, chapter 5. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: In [14], Goldberg presents an abstract interpretation that detects sharing 60 CHAPTER 2. OPTIMIZING LAZY FUNCTIONAL ... of partial applications in a nonstrict higher order language, and applies it to the generation of fully lazy supercombinators. Hughes discusses a backwards sharing analysis in <ref> [22] </ref>, while in [30], Launchbury et.al. give an analysis that is closely related to a linear type system. <p> Since the transformation is rather simple and intuitively of obvious utility, we wonder how many compilers actually implement it without their authors having mentioned it. 3.1.2 Strictness Analysis The middle-end also includes a simple first order backwards strictness analyzer inspired by the work of Hughes <ref> [22] </ref> and Hughes&Wadler [54]. Backward strictness analysis is based on the idea of propagating contexts from expressions through to the free variables of the expression. A context is a description of how much of a value that is needed.
Reference: [23] <author> John Hughes. </author> <title> Why functional programming matters. </title> <editor> In David Turner, editor, </editor> <booktitle> Research Topics in Functional Programming. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference: [24] <author> Thomas Johnsson. </author> <title> Compiling Lazy Functional Languages. </title> <type> PhD thesis, </type> <institution> Chalmers University of Technology, </institution> <year> 1987. </year>
Reference-contexts: Boquist also uses the analysis information to enable interprocedural register allocation. The applications we discuss have also been much studied separately, at least from the theoretical point of view. Thunk inlining is already discussed by Mycroft (but only for a first order language) [34] and by Johnsson <ref> [24] </ref> who also discusses eval elimination, although he does not give any algorithm and does not discuss the interaction. Gomard and Sestoft [15, 16] and others have studied path analysis which is similar to eval elimination. <p> If the value can not be proved to be in whnf, our scheme, like the original G-machine <ref> [24] </ref>, requires a separate forcing operation prior to the case. <p> The Glasgow Haskell Compiler [37] implements the abstract STG machine stack with two concrete stacks, the A stack of pointers and the B stack of basic values and control information, handled like the A and B stacks of the ABC-machine. Similarly, the G-machine <ref> [24] </ref> maps its three abstract stacks (the S stack of pointers, the V stack of basic values and the dump D of control information) to two concrete stacks (the D and V stacks to the system stack and the S stack to a separate area).
Reference: [25] <author> Thomas Johnsson. </author> <title> Analysing heap contents in a graph reduction intermediate language. In S.L. </title> <editor> Peyton Jones, G. Hutton, and C.K. Holst, editors, </editor> <booktitle> Proceedings of the Glasgow Functional Programming Workshop, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: Sestoft, in [45], however, explores the use of closure information to turn first order analyses into higher order analyses which is close in spirit to our applications were we combine flow information with local information. Recently, Boquist [8], building on earlier work by Johnsson <ref> [25] </ref>, has applied constructor analysis to the optimization of a graph reduction intermediate language. The transformations performed are related to our eval elimination, but the formulation is rather different. Boquist also uses the analysis information to enable interprocedural register allocation.
Reference: [26] <author> H. B. M. Jonkers. </author> <title> A fast garbage compaction algorithm. </title> <journal> Information Processing Letters, </journal> <volume> 9(1) </volume> <pages> 26-30, </pages> <month> July </month> <year> 1979. </year>
Reference-contexts: Batches are the smallest units that can be promoted, and they are also used for statistics gathering. Thus every batch is part of exactly one generation. 4.2 The Sliding Compaction Collector Our major collection algorithm is based on Jonkers' sliding compaction collector <ref> [26] </ref>. Variants of this collector has been used in the Concurrent Clean compiler from Nijmegen and the Glasgow Haskell Compiler [42, 43]. We will now briefly review the operation of this algorithm. 3 This offset is not reflected in the discussion of the garbage collection interface in Chap. 3. 4.2.
Reference: [27] <author> D. King and J. Launchbury. </author> <title> Structuring depth first search algorithms in Haskell. </title> <booktitle> In Principles of Programming Languages, </booktitle> <address> San Francisco, </address> <year> 1995. </year>
Reference: [28] <author> Koen Langendoen and Pieter Hartel. FCG: </author> <title> a code generator for lazy functional languages. </title> <editor> In P. Pfahler U. Kastens, editor, </editor> <booktitle> Proceedings of the Conference on Compiler Construction, </booktitle> <pages> pages 278-296, </pages> <address> Paderborn, Germany, Oct 92. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: C has been used as target language for several implementations of strict and lazy functional languages. Examples include the Glasgow Haskell Compiler (ghc) [37, 38], the FAST/FCG compiler jointly developed by the universities of Amsterdam and Southampton <ref> [18, 28] </ref>, the Bigloo Scheme compiler and the Camloo CAML compiler based on it. In a recent study [17], ghc is shown to be performance-leading among compilers for lazy functional languages, and Camloo/Bigloo are very competitive compilers for strict languages.
Reference: [29] <author> John Launchbury. </author> <title> A natural semantics for lazy evaluation. </title> <booktitle> In Conference Record of the Twentieth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 144-154, </pages> <address> Charleston, South Carolina, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: We call triples of the form hG; ae; ei configurations and pairs of the form hG; ai results. Our semantics is similar in spirit to those by Launchbury <ref> [29] </ref> and Sestoft [46], but there are a few differences. First, they identify variables and addresses and dispense with the environment. Second, their semantices are for languages without explicit thunk and eval constructs. <p> We will now comment on the rules in Fig. 2.3. * The VAR rule is simple | just look up the value of the variable in the environment. In a semantics for a lazy language without explicit thunk and eval constructs, such as the above mentioned ones by Launchbury <ref> [29] </ref> and Sestoft [46], the rule for variables has to check whether the variable is bound to a whnf and force it if not, but since forcing is explicit in Fleet, no such checks need to be made. * Since function and argument are variables, the APP rule does not need
Reference: [30] <author> John Launchbury, Andrew Gill, John Hughes, Simon Marlow, Simon L Peyton Jones, and Philip Wadler. </author> <title> Avoiding unnecessary updates. </title> <booktitle> In Proceedings of the fifth annual Glasgow Workshop on Functional Programming, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: In [14], Goldberg presents an abstract interpretation that detects sharing 60 CHAPTER 2. OPTIMIZING LAZY FUNCTIONAL ... of partial applications in a nonstrict higher order language, and applies it to the generation of fully lazy supercombinators. Hughes discusses a backwards sharing analysis in [22], while in <ref> [30] </ref>, Launchbury et.al. give an analysis that is closely related to a linear type system.
Reference: [31] <author> Xavier Leroy. </author> <title> Unboxed objects and polymorphic typing. </title> <booktitle> In Conference Record of the Nineteenth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 177-188, </pages> <address> Albequerque, New Mexico, </address> <month> January </month> <year> 1992. </year> <note> 146 BIBLIOGRAPHY </note>
Reference-contexts: Gomard and Sestoft [15, 16] and others have studied path analysis which is similar to eval elimination. Boxing has been treated by several authors, a recent example being [20] where Henglein and Jorgensen, building on work by Leroy <ref> [31] </ref>, defines an optimality criterion for boxing completions in a call-by-value language. Here boxing is used only because of polymorphism, but they do not treat the requirements from garbage collection and lazy evaluation.
Reference: [32] <author> Xavier Leroy. </author> <title> Polymorphism by name for references and continuations. </title> <booktitle> In Conference Record of the Twentieth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 220-231, </pages> <address> Charleston, South Carolina, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: In Appendix A.1 we prove the soundness of this type system with respect to the operational semantics of Fleet. The proof is by induction on the height of the proof of the evaluation relation, and is similar in spirit to the one given by Leroy in <ref> [32] </ref>, where he proves the soundness of the Hindley-Milner type system relative to a natural semantics of an extension to ML with references and continuations. 2.3 A Type Inference Algorithm In this section we present an implementation of the analysis in the form of a type inference algorithm.
Reference: [33] <author> Robin Milner. </author> <title> A theory of type polymorphism in programming. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 17(3) </volume> <pages> 348-375, </pages> <month> December </month> <year> 1978. </year>
Reference: [34] <author> A. Mycroft. </author> <title> Abstract interpretation and optimizing transformations for applicative programs. </title> <type> PhD thesis, </type> <institution> Computer Science Dept,. Univ. of Edin-burgh, </institution> <year> 1981. </year>
Reference-contexts: Boquist also uses the analysis information to enable interprocedural register allocation. The applications we discuss have also been much studied separately, at least from the theoretical point of view. Thunk inlining is already discussed by Mycroft (but only for a first order language) <ref> [34] </ref> and by Johnsson [24] who also discusses eval elimination, although he does not give any algorithm and does not discuss the interaction. Gomard and Sestoft [15, 16] and others have studied path analysis which is similar to eval elimination.
Reference: [35] <author> E. Nocker, J.E.W. Smetsers, M.C.J.D. van Eekelen, and R. Plasmeijer. </author> <title> Concurrent Clean. </title> <booktitle> In PARLE '91. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1991. </year> <note> LNCS. </note>
Reference: [36] <author> Jens Palsberg. </author> <title> Closure analysis in constraint form. </title> <booktitle> In CAAP'94, </booktitle> <year> 1994. </year>
Reference-contexts: In older work, such as that by Sestoft, Jones and Shivers, abstract interpretation is generally 2.5. RELATED WORK 59 used, but recently there have been a number of formulations in terms of constraint systems, among which are Steckler and Wand [56] and Heintze [19]. Also, Palsberg <ref> [36] </ref> has used a similar framework. Common to these analyses is that the analysis problem to be solved is set up in terms of the expressions etc in the program to be analyzed. Therefore, the entire program is always needed, and separate compilation becomes very troublesome.
Reference: [37] <author> Simon Peyton Jones. </author> <title> Implementing lazy functional languages on stock hardware. </title> <journal> Journal of Functional Programming, </journal> <month> April </month> <year> 1992. </year>
Reference-contexts: Furthermore, we implement our EVAL using the test-and-branch approach, so forcing a whnf does not incur the cost of a subroutine call. This is in contrast to e.g. the STG-machine <ref> [37] </ref> where forcing is folded into case and function application. The tradeoff is that, if a value can be proved to be in whnf, our case-of-whnf gives more efficient code than the more general machinery of the merged force/case (since we can eliminate entirely the redundant forcing operation). <p> Generate C or assembly C is a widely portable high-level language with many low-level features. C has been used as target language for several implementations of strict and lazy functional languages. Examples include the Glasgow Haskell Compiler (ghc) <ref> [37, 38] </ref>, the FAST/FCG compiler jointly developed by the universities of Amsterdam and Southampton [18, 28], the Bigloo Scheme compiler and the Camloo CAML compiler based on it. <p> Descriptors Thunk and whnf headers are tagged pointers to statically allocated data structures called descriptors. These correspond to the info tables in the STG-machine <ref> [37] </ref>. The CFM syntax for a descriptor declaration is g = layout desc where layout is information for the garbage collector, and desc defines the descriptor proper. <p> The Glasgow Haskell Compiler <ref> [37] </ref> implements the abstract STG machine stack with two concrete stacks, the A stack of pointers and the B stack of basic values and control information, handled like the A and B stacks of the ABC-machine.
Reference: [38] <author> Simon L. Peyton Jones, Cordelia V. Hall, Kevin Hammond, Will Partain, and Philip Wadler. </author> <title> The Glasgow Haskell compiler: a technical overview. </title> <booktitle> In Proc. UK Joint Framework for Information Technology (JFIT) Technical Conference, </booktitle> <month> July 93. </month>
Reference-contexts: Generate C or assembly C is a widely portable high-level language with many low-level features. C has been used as target language for several implementations of strict and lazy functional languages. Examples include the Glasgow Haskell Compiler (ghc) <ref> [37, 38] </ref>, the FAST/FCG compiler jointly developed by the universities of Amsterdam and Southampton [18, 28], the Bigloo Scheme compiler and the Camloo CAML compiler based on it.
Reference: [39] <author> Simon L Peyton Jones and John Launchbury. </author> <title> Unboxed values as first class citizens in a non-strict functional language. </title> <editor> In John Hughes, editor, </editor> <volume> FPCA '91, </volume> <pages> pages 636-666. </pages> <publisher> Springer Verlag, </publisher> <year> 1991. </year> <note> LNCS 523. </note>
Reference-contexts: Their approach is considerably different from ours in that it is not based on program analysis, but rather on stepwise, meaning preserving transformations, and it is also more general than our approach. On the other hand, Peyton-Jones and Launchbury <ref> [39] </ref> take all of the requirements (polymorphism, gc and lazy evaluation) into account. They do not give any algorithm but rather argues that representation selection should be done by the programmer. In [14], Goldberg presents an abstract interpretation that detects sharing 60 CHAPTER 2.
Reference: [40] <author> John H. Reppy. </author> <title> A high-performance garbage collector for Standard ML. </title> <type> Technical memo, </type> <institution> AT&T Bell Laboratories, </institution> <month> December </month> <year> 1993. </year>
Reference-contexts: For a 32-bit machine, this represents a space overhead of about 3%. 4 Some Prolog systems use this kind of garbage collector so that they can "roll-back" the heap to an earlier state when they backtrack. 5 For example, Reppy's recent generationalcollector for SML/NJ <ref> [40] </ref>, segregate pairs, which in SML need their headers (called descriptors), only for garbage collection, into a special area, dispensing with the headers and saving 10-15% space. 114 CHAPTER 4. <p> Andrew Ap-pels compiler for Standard ML, the SML/NJ compiler, has used a generational collector since its inception [2]; this collector has since been replaced by a new improved collector <ref> [40] </ref> which is also generational. Also, the Glasgow Haskell Compiler uses a two generation collector [43]. A generational collector is based on the observation that, in most cases, older (less recently allocated) objects are less likely to die (become garbage) soon than younger objects.
Reference: [41] <author> Niklas Rojemo. </author> <title> Garbage collection, and memory efficiency, in lazy functional languages. </title> <type> PhD thesis, </type> <institution> Chalmers University of Technology, Computing Science Department, </institution> <year> 1995. </year>
Reference-contexts: We are currently considering global variables as perpetually live, but information about global variable liveness can also be placed here (we are planning to incorporate this in the compiler, since perpetually live global variables can be a major source of space leaks <ref> [41] </ref>). The change will mainly affect the encoding of the live variable sets. Register Allocation The global register allocator uses a simple algorithm inspired by graph coloring. Registers available for allocation fall into two groups | argument/result registers and local registers.
Reference: [42] <author> Patrick M. Sansom. </author> <title> Dual-mode garbage collection. </title> <type> Technical report, </type> <institution> Dept. of Computing Science, University of Glasgow, </institution> <month> Dec 91. </month>
Reference-contexts: Thus every batch is part of exactly one generation. 4.2 The Sliding Compaction Collector Our major collection algorithm is based on Jonkers' sliding compaction collector [26]. Variants of this collector has been used in the Concurrent Clean compiler from Nijmegen and the Glasgow Haskell Compiler <ref> [42, 43] </ref>. We will now briefly review the operation of this algorithm. 3 This offset is not reflected in the discussion of the garbage collection interface in Chap. 3. 4.2. THE SLIDING COMPACTION COLLECTOR 113 Garbage collection logically consists of two phases, marking and scanning (compaction).
Reference: [43] <author> Patrick M. Sansom and Simon L. Peyton Jones. </author> <title> Generation garbage collection for Haskell. </title> <booktitle> In Functional Programming Languages and Computer Architecture, </booktitle> <month> June 93. </month>
Reference-contexts: Thus every batch is part of exactly one generation. 4.2 The Sliding Compaction Collector Our major collection algorithm is based on Jonkers' sliding compaction collector [26]. Variants of this collector has been used in the Concurrent Clean compiler from Nijmegen and the Glasgow Haskell Compiler <ref> [42, 43] </ref>. We will now briefly review the operation of this algorithm. 3 This offset is not reflected in the discussion of the garbage collection interface in Chap. 3. 4.2. THE SLIDING COMPACTION COLLECTOR 113 Garbage collection logically consists of two phases, marking and scanning (compaction). <p> Andrew Ap-pels compiler for Standard ML, the SML/NJ compiler, has used a generational collector since its inception [2]; this collector has since been replaced by a new improved collector [40] which is also generational. Also, the Glasgow Haskell Compiler uses a two generation collector <ref> [43] </ref>. A generational collector is based on the observation that, in most cases, older (less recently allocated) objects are less likely to die (become garbage) soon than younger objects.
Reference: [44] <author> Andre Santos. </author> <title> Compilation by Transformation in Non-Strict Functional Languages. </title> <type> PhD thesis, </type> <institution> Glasgow University, Department of Computing Science, </institution> <year> 1995. </year> <note> BIBLIOGRAPHY 147 </note>
Reference-contexts: THE OPTIMIZING PLAIN COMPILER The push-let transformation seems to have been invented independently by us and by Andre Santos <ref> [44] </ref>, apparently in the same way | from inspection of generated intermediate code. He has done a thorough evaluation of the transformation and he also gives a more detailed algorithm.
Reference: [45] <author> Peter Sestoft. </author> <title> Analysis and efficient implementation of functional programs. </title> <type> PhD thesis, </type> <institution> DIKU, University of Copenhagen, Denmark, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: Then S = fl j 9 l 0 2 N : l 0 is reachable from l in Gg. 2.5 Related Work What we call flow analysis is known by a number of different names. It has been called closure analysis by Sestoft <ref> [45] </ref> and others, flow information by Steckler and Wand [56] and others, and control flow information by Jones, Shivers [47], and others. It is also closely related to set based analysis [19]. The way in which the information is computed also varies. <p> When it comes to exploitation of the analysis information, most of the above use the information for replacing function parameters with global variables or binding time analysis for partial evaluation. Sestoft, in <ref> [45] </ref>, however, explores the use of closure information to turn first order analyses into higher order analyses which is close in spirit to our applications were we combine flow information with local information.
Reference: [46] <author> Peter Sestoft. </author> <title> Deriving a lazy abstract machine. </title> <type> ID-TR 146, </type> <institution> Dept. of Computer Science, Technical University of Denmark, </institution> <month> September </month> <year> 1994. </year>
Reference-contexts: We call triples of the form hG; ae; ei configurations and pairs of the form hG; ai results. Our semantics is similar in spirit to those by Launchbury [29] and Sestoft <ref> [46] </ref>, but there are a few differences. First, they identify variables and addresses and dispense with the environment. Second, their semantices are for languages without explicit thunk and eval constructs. <p> In a semantics for a lazy language without explicit thunk and eval constructs, such as the above mentioned ones by Launchbury [29] and Sestoft <ref> [46] </ref>, the rule for variables has to check whether the variable is bound to a whnf and force it if not, but since forcing is explicit in Fleet, no such checks need to be made. * Since function and argument are variables, the APP rule does not need to evaluate these.
Reference: [47] <author> O. Shivers. </author> <title> The semantics of Scheme control-flow analysis. </title> <booktitle> In Proceedings of the Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <volume> volume 26, </volume> <pages> pages 190-198, </pages> <address> New Haven, CN, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: It has been called closure analysis by Sestoft [45] and others, flow information by Steckler and Wand [56] and others, and control flow information by Jones, Shivers <ref> [47] </ref>, and others. It is also closely related to set based analysis [19]. The way in which the information is computed also varies. In older work, such as that by Sestoft, Jones and Shivers, abstract interpretation is generally 2.5.
Reference: [48] <author> G.S. Smith. </author> <title> Principal type schemes for functional programs with overloading and subtyping. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 23 </volume> <pages> 197-226, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: As a generalization, one can use inclusion constraints rather than equality constraints; then we have fo 00 o -&gt; o 0 g in place of the above constraint. See Aiken et. al. [1] and Smith <ref> [48] </ref> for type systems defined in this way. <p> Another complexity here is the generalization predicate, which we will discuss in more detail below. 2.2. THE TYPE SYSTEM 47 Another thing to note about the LET rule is that, in contrast to systems like those in [1] and <ref> [48] </ref>, we do not have the restriction that Sol (S) be nonempty | instead we have the restriction that x must occur in e 0 (the body of the let expression).
Reference: [49] <author> Paul Steckler and Mitchell Wand. </author> <title> Selective thunkification. </title> <editor> In Baudouin Le Charlier, editor, </editor> <booktitle> 1st Static Analysis Symposium (SAS'94), </booktitle> <pages> pages 162-78, </pages> <address> Berlin, </address> <month> September </month> <year> 1994. </year> <note> Springer-Verlag. </note>
Reference-contexts: Sometimes, when modeling a call-by-name calculus in a call-by-value calculus, thunks are modeled as one-argument functions which ignore their argument, and forcing is represented as application of the thunk to a dummy argument (this is done for example by Steckler and Wand in <ref> [49] </ref>).
Reference: [50] <author> Peter A. Steenkiste and John L. Hennessy. </author> <title> A simple interprocedural register allocation algorithm and its effectiveness for Lisp. </title> <journal> ACM Trans. Program. Lang. Syst., </journal> <volume> 11(1) </volume> <pages> 1-32, </pages> <month> January </month> <year> 1989. </year>
Reference-contexts: A reason for this (besides the puny size of our benchmarks) may be that we are not using an interprocedural allocator, so there tend not to be many variables live in registers simultaneously. We are planning to add and interprocedural register allocator along the lines of <ref> [50] </ref>, but Boquists interprocedural coalescing technique is an interesting alternative [8]. 94 CHAPTER 3.
Reference: [51] <author> Yan-Mei Tang and Pierre Jouvelot. </author> <title> Separate abstract interpretation for control-flow analysis. </title> <booktitle> In TACS'94, </booktitle> <year> 1994. </year>
Reference-contexts: Therefore, the entire program is always needed, and separate compilation becomes very troublesome. Analyses based on type and effect inference have been studied since in a type inference setting one only need the types of the free identifiers in the program. An example is <ref> [51] </ref>, where Tang and Jouvelot study a combination of effect inference and abstract interpretation (they use abstract interpretation for its superior accuracy as compared to their monomorphic type system).
Reference: [52] <author> Mads Tofte and Jean-Pierre Talpin. </author> <title> Implementation of the typed call-by-value -calculus using a stack of regions. </title> <booktitle> In Conference Record of POPL '94: 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 188-201, </pages> <address> Portland, Oregon, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: the rest of the value. 3 For example, the expression @6 0 in the from function in Fig. 2.2 has the type hf@6g; Inti, meaning that it will always evaluate to an integer labeled with 3 Annotated types play a similar role to the decorated types in Talpin and Tofte <ref> [52] </ref>. 2.2. THE TYPE SYSTEM 35 @6. This is not the only type that can be attributed to the expression; @6 0 has every type hL; Inti such that @6 2 L.
Reference: [53] <author> John van Groningen, Eric Nocker, and Sjaak Smetsers. </author> <title> Efficient heap management in the concrete ABC machine. </title> <type> Technical Report CSTR 91-07, </type> <institution> University of Southmapton, UK, </institution> <month> June </month> <year> 1991. </year> <booktitle> In Proc. of the Third Workshop on the Parallel Implementation of Functional Languages. </booktitle>
Reference-contexts: We will probably switch to two word indirections in the next version of opc. 3.2.3 Stack Formats Most compilers for lazy functional languages use multiple stacks. The Concurrent Clean compiler <ref> [53] </ref> maps the three stacks (A of pointers, B of basic values, and C of code addresses) of its appropriately named ABC-machine, to three physical stacks, one of which (C) is the system stack and the other two (A and B) are growing towards each other in a special block set
Reference: [54] <author> P. Wadler and R. J. M. Hughes. </author> <title> Projections for strictness analysis. </title> <editor> In Gilles Kahn, editor, </editor> <booktitle> Proc. Functional Programming Lang. and Computer Arch., </booktitle> <pages> pages 385-407, </pages> <address> Berlin, </address> <month> September </month> <year> 1987. </year> <booktitle> Volume 274 of Lecture Notes in Comput. </booktitle> <publisher> Sci., Springer-Verlag. </publisher>
Reference-contexts: Since the transformation is rather simple and intuitively of obvious utility, we wonder how many compilers actually implement it without their authors having mentioned it. 3.1.2 Strictness Analysis The middle-end also includes a simple first order backwards strictness analyzer inspired by the work of Hughes [22] and Hughes&Wadler <ref> [54] </ref>. Backward strictness analysis is based on the idea of propagating contexts from expressions through to the free variables of the expression. A context is a description of how much of a value that is needed.
Reference: [55] <author> Philip Wadler. Deforestration: </author> <title> Transforming programs to eliminate trees. </title> <editor> In Harald Ganzinger, editor, </editor> <booktitle> ESOP '88, </booktitle> <pages> pages 344-358. </pages> <publisher> Springer Verlag, </publisher> <year> 1989. </year> <note> 148 BIBLIOGRAPHY </note>
Reference-contexts: The transformation from nqh to q1, called firstification could be done automatically by a compiler, but we have done the transformation by hand. qf Same as q1, but some intermediate lists eliminated by deforestration <ref> [55] </ref>. snq Same as qf, but rather than counting the solutions, it sums them. In consequence, this program does not give the same result as the other 121 122 CHAPTER 5. EXPERIMENTAL RESULTS versions.
Reference: [56] <author> Mitchell Wand and Paul Steckler. </author> <title> Selective and lightweight closure conversion. </title> <booktitle> In Conference Record of POPL '94: 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 435-445, </pages> <address> Port-land, Oregon, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: It has been called closure analysis by Sestoft [45] and others, flow information by Steckler and Wand <ref> [56] </ref> and others, and control flow information by Jones, Shivers [47], and others. It is also closely related to set based analysis [19]. The way in which the information is computed also varies. In older work, such as that by Sestoft, Jones and Shivers, abstract interpretation is generally 2.5. <p> In older work, such as that by Sestoft, Jones and Shivers, abstract interpretation is generally 2.5. RELATED WORK 59 used, but recently there have been a number of formulations in terms of constraint systems, among which are Steckler and Wand <ref> [56] </ref> and Heintze [19]. Also, Palsberg [36] has used a similar framework. Common to these analyses is that the analysis problem to be solved is set up in terms of the expressions etc in the program to be analyzed.
Reference: [57] <author> Paul R. Wilson. </author> <title> Uniprocessor garbage collection techniques (long version). </title> <note> Submitted to ACM Computing Surveys, </note> <year> 1994. </year>
Reference-contexts: Most garbage collectors are quite good at trading space for time, but having to use a heap five or ten times as large as the set of live objects in order to get reasonable performance is clearly unacceptable. Our design goal, inspired by Wilson <ref> [57] </ref>, is low overhead when the heap is half full. Strong guarantees against fragmentation. We do not want memory to be lost to fragmentation since the amount of fragmentation seems impossible to predict at compile-time. Coexistence with malloc/free.
References-found: 57

