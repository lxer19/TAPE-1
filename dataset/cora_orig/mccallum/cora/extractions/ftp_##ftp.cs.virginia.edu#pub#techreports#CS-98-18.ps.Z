URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-98-18.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.cs.virginia.edu
Title: The Spring System: Integrated Support for Complex Real-Time Systems  
Author: John A. Stankovic Krithi Ramamritham Douglas Niehaus Marty Humphrey Gary Wallace 
Keyword: real-time, real-time kernel, multiprocessor kernel, real-time scheduling, guarantees, predictability, function and time composition, reflection, integrated scheduling, multi-level scheduling, IPC  
Date: August 1, 1998  
Affiliation: Department of Computer Science University of Virginia  Department of Computer Science University of Massachusetts  Department of Electrical Engineering and Computer Science University of Kansas  Department of Computer Science University of Virginia  Department of Computer Science University of Massachusetts  
Abstract: The Spring system is a highly integrated collection of software and hardware that synergistically operates to provide end-to-end support in building complex real-time applications. In this paper, we show how Spring's specification language, programming language, software generation system, and operating system kernel are applied to build a flexible manufacturing testbed. The same ingredients have also been used to realize a predictable version of a robot pick and place application used in industry. These applications are good examples of complex real-time systems that require flexibility. The goal of this paper is to demonstrate the integrated nature of the system and the benefits of integration; in particular, the use of reflective information and the value of function and time composition. The lessons learned from these applications and the project as a whole are also presented. 
Abstract-found: 1
Intro-found: 1
Reference: [Amerasinghe 1985] <author> P. Amerasinghe, </author> <title> An Interactive Timing Analysis Tool for the SARTOR Environment, </title> <type> Master's thesis, </type> <institution> University of Texas at Austin, </institution> <year> 1985. </year>
Reference-contexts: The guarantee notion in Real-Time Concurrent C was motivated by the similar notion in Spring. 6.2 Tools for Behavior Prediction Several researchers have considered execution behavior prediction. Amerasinghe developed a tool which analyzes the assembly language emitted for a program with respect to a model of the target processor <ref> [Amerasinghe 1985, Chen 1985] </ref>, but does not take the effects of pipelining and instruction caching into account. Harmon produced a tool performing what he called micro-analysis [Harmon et. al. 1992]. The tool worked directly with the executable code, first disassembling it, and then deducing the looping structure.
Reference: [Arnold et. al. 1994] <author> R. Arnold, F. Mueller, D. B. Whalley, and M. Harmon, </author> <title> Bounding Worst-Case Instruction Cache Performance, </title> <booktitle> Proceedings of the 1994 IEEE Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1994. </year>
Reference-contexts: This permits them to consider optimizations performed by the compiler and hardware features, but does not permit them to perform transformations on the code during the same phase as their temporal analysis. More recently, a project led by Whalley has addressed behavorial prediction for data caches and instruction caches <ref> [White et. al. 1997, Arnold et. al. 1994] </ref>. 6.3 Operating Systems For relatively small, less complex, real-time systems, it is often the case that real-time systems are supported by a stripped down and optimized versions of timesharing operating systems.
Reference: [Bickford et. al. 1996] <author> C. Bickford, M. Teo, G. Wallace, J.A. Stankovic and K. Ramamritham, </author> <title> A Robotic Assembly Application on the Spring Real-Time System, </title> <booktitle> Proceedings of the 1996 IEEE Real-Time Technology and Applications Symposium, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: These applications are good examples of complex real-time systems that require flexibility and which can demonstrate the value of reflection and (function and time) composition. In this paper, we describe only the first application in Section 4 which also contains multi-level scheduling. (The second application is discussed in <ref> [Bickford et. al. 1996] </ref>.) The lessons learned from these applications and the project as a whole are presented in Section 5. Section 6 discusses the state of art related to this work. <p> passing information between the two schedulers, and showed the synergy between the two schedulers. 5 Lessons Learned The experience of designing and implementing an integrated set of real-time tools and kernel and applying them to a flexible manufacturing testbed (Section 4) and a robotic pick and place application (described in <ref> [Bickford et. al. 1996] </ref>) has taught us a number of lessons. * The amount of information the Spring scheduler provides to applications regarding the reasons for (the lack of) schedulability and the current state of execution can greatly affect performance. <p> It should be possible to view the task group representation in a readable form. At this stage, the user is provided with information that allows making intelligent changes or optimizing the application. For instance, in the robotic pick and place application <ref> [Bickford et. al. 1996] </ref>, using the Spring SGS tools we were able to analyze the task groups' structure and discovered that explicit delays and synchronous communication account for only a small number of suspension points and that most of the 685 tasks of the compiled application were due to resource use <p> In particular, how resource use is specified is important since placement of with statements can greatly affect resulting task group patterns. 20 Again, in the robot pick and place application <ref> [Bickford et. al. 1996] </ref>, we discovered that there were many sections of code in which we could move with statements to higher granularities (e.g., one with surrounding a larger block of code, rather than several within the the same block) to make the task decomposition more efficient.
Reference: [Burns and Wellings 1989] <author> A. Burns and A. Wellings, </author> <title> Real-Time Systems and Their Programming Languages. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: 6 Related Work This section discusses some of the related work most relevant to the issues considered in this paper. 6.1 Real-Time Languages Burns and Wellings give a good description of real-time systems in general and describe their implementation using straightforward adaptations of techniques used in conventional systems to real-time <ref> [Burns and Wellings 1989] </ref>. Real-time languages often add statements about the temporal constraints of computations to the syntax of the language.
Reference: [Chen 1985] <author> M. Chen, </author> <title> Timing Analysis Language - TAL Programmer's Manual, </title> <type> Technical report, </type> <institution> University of Texas at Austin, </institution> <year> 1985. </year>
Reference-contexts: The guarantee notion in Real-Time Concurrent C was motivated by the similar notion in Spring. 6.2 Tools for Behavior Prediction Several researchers have considered execution behavior prediction. Amerasinghe developed a tool which analyzes the assembly language emitted for a program with respect to a model of the target processor <ref> [Amerasinghe 1985, Chen 1985] </ref>, but does not take the effects of pipelining and instruction caching into account. Harmon produced a tool performing what he called micro-analysis [Harmon et. al. 1992]. The tool worked directly with the executable code, first disassembling it, and then deducing the looping structure.
Reference: [Di Natale and Stankovic 1994] <author> M. Di Natale and J.A. Stankovic, </author> <title> Dynamic End-to-End Guarantees in Distributed Real-Time Systems, </title> <booktitle> Proc. of the 15th Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1994. </year>
Reference-contexts: The distributed scheduling algorithms then utilize the communication and task information to guarantee the application level end-to-end deadline constraint. The algorithm is beyond the scope of this paper; details can be found in <ref> [Di Natale and Stankovic 1994] </ref>. Thus at run-time, for example, if a guaranteed task performs a synchronous receive, the scheduler knows when to schedule that task such that a message should be present.
Reference: [Furht et. al. 1991] <author> B. Furht, D. Grostick, D. Gluch, G. Rabbat, J. Parker and M. McRoberts, </author> <title> Real-Time Unix Systems, Design and Application Guide, </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA., </address> <year> 1991. </year>
Reference-contexts: In general, these kernels, as minimal extensions of the techniques used by conventional systems, perform multi-tasking. In addition, inter-task communication and synchronization are achieved via standard, well-known primitives such as mailboxes, events, signals, and semaphores. In this vein, many real-time UNIX operating systems <ref> [Furht et. al. 1991] </ref>, and a standard for real-time operating systems, called RT POSIX, have been developed [Gallmeister 1995]. There are also a large number of proprietary real-time systems, over 70 commercial real-time kernels exist, which take a similar design approach; examples include: QNX, LynxOS, OS-9, VxWorks, and VRTXsa.
Reference: [Gallmeister 1995] <author> B. Gallmeister, </author> <title> POSIX.4: Programming for the Real World, </title> <publisher> O'Reilly and Associates, </publisher> <year> 1995. </year>
Reference-contexts: In addition, inter-task communication and synchronization are achieved via standard, well-known primitives such as mailboxes, events, signals, and semaphores. In this vein, many real-time UNIX operating systems [Furht et. al. 1991], and a standard for real-time operating systems, called RT POSIX, have been developed <ref> [Gallmeister 1995] </ref>. There are also a large number of proprietary real-time systems, over 70 commercial real-time kernels exist, which take a similar design approach; examples include: QNX, LynxOS, OS-9, VxWorks, and VRTXsa.
Reference: [Gehani and Ramamritham 1991] <author> N. Gehani and K. Ramamritham, </author> <title> Real-Time Concurrent C (C++): A Language for Programming Dynamic Real-time Systems, </title> <booktitle> Real-Time Systems, </booktitle> <volume> Vol. 3., No. 4, </volume> <month> Dec. </month> <year> 1991, </year> <pages> pp 377-405. 25 </pages>
Reference-contexts: They also describe support for monotonic algorithms which explicitly support computations with unpredictable behavior by establishing an initial result early and then iteratively refining it until the deadline is reached. Real-Time Concurrent C <ref> [Gehani and Ramamritham 1991] </ref> extends Concurrent C by providing facilities for building systems with strict timing constraints.
Reference: [Gene 1990] <author> E. Gene, </author> <title> The Spring Simulation Testbed - V2 User's Guide, </title> <type> Technical report, </type> <institution> Spring Project Documentation, </institution> <year> 1990. </year>
Reference-contexts: The bottom section of the figure illustrates how the reflective information is used by off-line workload generators, scheduling simulators, and simulations of the Spring Scheduling Co-Processor (SSCoP). These aspects of the system are peripheral to this paper and are discussed elsewhere <ref> [Gene 1990, Niehaus et. al. 1993] </ref>. The top section of Figure 2 illustrates how Spring-C source files are compiled and linked by the SGS, while the middle section illustrates the processing of source files which contain only SDL statements.
Reference: [Gheith and Schwan 1993] <author> A. Gheith and K. Schwan, </author> <title> CHAOS arc : Kernel Support for Multi-Weight Objects, Invocations, and Atomicity in Real-Time Applications, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol 11., No. 1, </volume> <month> April </month> <year> 1993, </year> <pages> pp 33-72. </pages>
Reference-contexts: Rather, HARTOS focuses on interprocess communication, thereby providing some support for distributed real-time systems. In particular, HARTOS supports message send and receive, non-queued event signals, reliable streams, and message scheduling that provides a best-effort approach in delivering a message by its deadline. The CHAOS system <ref> [Gheith and Schwan 1993] </ref> represents an object based approach to real-time kernels. This approach allows easy creation of a family of kernels, each tailored to a specific hardware or application.
Reference: [Halang and Stoyenko 1991] <author> W. Halang and A. Stoyenko, </author> <title> Constructing Predictable Real-Time Systems, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year>
Reference-contexts: We use the term vertical slice to describe this approach to system design, since it slices across the traditional boundaries between system layers whose design and implementation are often addressed almost independently in conventional systems <ref> [Halang and Stoyenko 1991] </ref>. Passing reflective information, using the SDL, across layers is key to developing flexible yet predictable real-time systems. Note that the runtime system also passes reflective information between system and application layers, and vice versa.
Reference: [Harmon et. al. 1992] <author> M. Harmon, T. Baker and D. Whalley, </author> <title> A Retargetable Technique for Predicting Execution Time, </title> <booktitle> Proceedings of the IEEE Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1992, </year> <pages> pp pages 68-77. </pages>
Reference-contexts: Amerasinghe developed a tool which analyzes the assembly language emitted for a program with respect to a model of the target processor [Amerasinghe 1985, Chen 1985], but does not take the effects of pipelining and instruction caching into account. Harmon produced a tool performing what he called micro-analysis <ref> [Harmon et. al. 1992] </ref>. The tool worked directly with the executable code, first disassembling it, and then deducing the looping structure.
Reference: [Ishikawa et. al. 1990] <author> Y. Ishikawa, H. Tokuda and C. Mercer, </author> <title> Object Oriented Real-Time Language Design: Constructs for Timing Constraints, </title> <booktitle> Proceedings of OOPSLA/ECOOP, ACM, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: More recently, the Real-Time Mach system uses a language with C++ as its starting point, adding constructs for specifying timing constraints including start time, deadline, exception handling, and periods <ref> [Ishikawa et. al. 1990] </ref>. They assume the use of rate monotonic scheduling in the underlying system, but little is said about how the WCET, which rate monotonic scheduling requires, can be predicted in the object oriented environment.
Reference: [Kenney and Lin 1991] <author> K. Kenney and K. Lin, </author> <title> Building Flexible Real-Time Systems Using the Flex Language, </title> <journal> IEEE Computer, </journal> <volume> Vol. 24., No. 5, </volume> <month> May </month> <year> 1991, </year> <pages> pp 70-78. </pages>
Reference-contexts: MPL provides several ways to specify temporal constraints on blocks of code within an object. Loop bounds are specified and recursion forbidden to increase predictability. Kenny and Lin describe the Flex language, another extension of C++, which includes a number of timing constraint expressions and exception handling clauses <ref> [Kenney and Lin 1991] </ref>. This research addresses the issues of approximate processing by adopting a polymorphism analogous to operator overloading [Liu et. al. 1991]. In this instance polymorphism refers to supplying several routines implementing the same function which have different properties in space and/or time.
Reference: [Kligerman and Stoyenko 1986] <author> E. Kligerman and A. Stoyenko, </author> <title> Real-Time Euclid: A Language for Reliable Real-Time Systems, </title> <journal> IEEE Transactions on Software Engineering, </journal> <month> September </month> <year> 1986. </year>
Reference-contexts: In one of the early efforts, Kligerman and Stoyenko produced a restricted language, Real-Time Euclid, which was designed to make schedu-lability analysis possible under a number of assumptions about the system and process behavior <ref> [Kligerman and Stoyenko 1986, Stoyenko 1987] </ref>. More recently, the Real-Time Mach system uses a language with C++ as its starting point, adding constructs for specifying timing constraints including start time, deadline, exception handling, and periods [Ishikawa et. al. 1990].
Reference: [Kopetz et. al. 1989] <author> H. Kopetz, A. Damm, C. Koza and D. Mulozzani, </author> <title> Distributed Fault Tolerant Real-Time Systems: The Mars Approach, </title> <booktitle> IEEE Micro, </booktitle> <year> 1989, </year> <pages> pp 25-40. </pages>
Reference-contexts: Each real-time thread can have a value function, timing constraints, worst case execution time, phase, and delay value associated with it. The Real-Time Mach kernel is also tied to various tools that a priori analyze the system wide schedulability of the system. The MARS kernel <ref> [Kopetz et. al. 1989, Kopetz and Merker 1985] </ref> offers support for controlling a distributed application based entirely on time events (rather than asynchronous events) from the environment. Emphasis is placed on an a priori static analysis to demonstrate that all the timing requirements are met.
Reference: [Kopetz and Merker 1985] <author> H. Kopetz and W. Merker, </author> <title> The Architecture of MARS, </title> <booktitle> Proceedings 15th FTCS, </booktitle> <month> June </month> <year> 1985, </year> <pages> pp 274-279. </pages>
Reference-contexts: Each real-time thread can have a value function, timing constraints, worst case execution time, phase, and delay value associated with it. The Real-Time Mach kernel is also tied to various tools that a priori analyze the system wide schedulability of the system. The MARS kernel <ref> [Kopetz et. al. 1989, Kopetz and Merker 1985] </ref> offers support for controlling a distributed application based entirely on time events (rather than asynchronous events) from the environment. Emphasis is placed on an a priori static analysis to demonstrate that all the timing requirements are met.
Reference: [Liu et. al. 1991] <author> J. Liu, K. Lin, W. Shih, A. Yu, J. Chung and W. Zhao, </author> <title> Algorithms for Scheduling Imprecise Calculations, </title> <journal> IEEE Computer, </journal> <volume> Vol. 24., No. 5, </volume> <month> May </month> <year> 1991, </year> <pages> pp 58-68. </pages>
Reference-contexts: Kenny and Lin describe the Flex language, another extension of C++, which includes a number of timing constraint expressions and exception handling clauses [Kenney and Lin 1991]. This research addresses the issues of approximate processing by adopting a polymorphism analogous to operator overloading <ref> [Liu et. al. 1991] </ref>. In this instance polymorphism refers to supplying several routines implementing the same function which have different properties in space and/or time.
Reference: [Molesky et. al. 1989] <author> L.D. Molesky, C. Shen and G. Zlokapa, </author> <title> Predictable Synchronization Mechanisms for Multiprocessor Real-Time Systems, </title> <booktitle> Real-Time Systems, </booktitle> <volume> Vol. 2., No. 3, </volume> <year> 1989, </year> <pages> pp 163-180. </pages>
Reference: [Motorola 1986] <author> Motorola, Inc. </author> <title> MCOR Unit68020 32-bit Microprocessor User's Manual, </title> <year> 1986. </year>
Reference-contexts: The system ensures a predictable worst case global access time by using the VME backplane in round robin mode, which enforces fair contention <ref> [Motorola 1986] </ref>.
Reference: [Nahum and Yates 1990] <author> E. Nahum and D. Yates, </author> <title> Real-Time IPC for the Spring Kernel, </title> <type> COINS 777 Project Report, </type> <institution> University of Massachusetts, </institution> <address> Amherst, MA, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: The IPC subsystem is thus specifically designed to facilitate analysis of communication resource requirements <ref> [Nahum and Yates 1990] </ref>, knowledge of which is used by the SGS at compile-time, and by the scheduler at run-time. In this section we discuss how SGS facilitates the predictable execution of communicating tasks. Under Spring IPC, messages are sent to ports.
Reference: [Niehaus 1991] <author> D.Niehaus, </author> <title> Program Representation and Translation for Predictable Real-Time Systems, </title> <booktitle> Proceedings of the IEEE Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1991, </year> <pages> pp 53-63. </pages>
Reference-contexts: Detailed discussion of the translation method is available elsewhere <ref> [Niehaus 1994, Niehaus 1991] </ref>. 5 It is important to note, however, that the reflective information used by the system is accumulated and derived in the course of this translation. <p> The SGS's use and production of the reflective information supported by the SDL was discussed briefly in Section 2.1, illustrated in Figure 2, and is discussed in detail elsewhere <ref> [Niehaus et. al. 1990, Niehaus 1991, Niehaus 1994] </ref>. Consider the role of the IPC subsystem in the compilation and execution of a simple process group containing two processes: one performing a synchronous send and one performing a synchronous receive. <p> An advantage of the approach taken by the Spring project is that its timing analysis is integrated into the compiler, and is performed after compiler optimization but before final emission of assembler code <ref> [Niehaus 1994, Niehaus 1991] </ref>. This enables Spring to take compiler optimizations into account while also basing its predictions on exactly the code that will be executed. It also makes it possible to perform program transformations required to enhance predictability and to fully implement the run-time model [Niehaus 1994].
Reference: [Niehaus 1994] <author> D. Niehaus, </author> <title> Program Representation and Execution in Real-Time Multiprocessor Systems, </title> <type> PhD thesis, </type> <institution> University of Massachusetts, </institution> <address> Amherst MA, </address> <year> 1994. </year>
Reference-contexts: The specification language, called SDL [Niehaus et. al. 1995], explicitly supports specifying a computation's real-time behavioral constraints, end-to-end constraints, concurrency, and details of the hardware-software platform that are required to accurately analyze the system and achieve predictability. The programming language, Spring-C <ref> [Niehaus 1994] </ref>, works in concert with the specification language. Its structure constrains the programmer in ways which ensure that worst case execution behavior, including execution times, can be automatically predicted for the particular hardware platform being used. Of course, such platforms should have predictable instruction execution times. <p> This information is supplied in the form required by the Spring scheduler, which manages computations represented as precedence related groups of tasks with resource and deadline constraints <ref> [Zhao and Ramamritham 1987, Niehaus 1994] </ref>. <p> Another novel feature and important contribution of the SGS is its translation from a process based representation of a computation used by the programmer to a representation of a computation's execution behavior as precedence-related tasks used by both on-line and off-line schedulers <ref> [Zhao and Ramamritham 1987, Niehaus et. al. 1990, Niehaus 1994] </ref>. Detailed discussion of the translation method is available elsewhere [Niehaus 1994, Niehaus 1991]. 5 It is important to note, however, that the reflective information used by the system is accumulated and derived in the course of this translation. <p> Detailed discussion of the translation method is available elsewhere <ref> [Niehaus 1994, Niehaus 1991] </ref>. 5 It is important to note, however, that the reflective information used by the system is accumulated and derived in the course of this translation. <p> This enables the SGS to distinguish local and global memory accesses, and thus to produce accurate worst case execution time predictions <ref> [Niehaus 1994] </ref>. <p> The SGS's use and production of the reflective information supported by the SDL was discussed briefly in Section 2.1, illustrated in Figure 2, and is discussed in detail elsewhere <ref> [Niehaus et. al. 1990, Niehaus 1991, Niehaus 1994] </ref>. Consider the role of the IPC subsystem in the compilation and execution of a simple process group containing two processes: one performing a synchronous send and one performing a synchronous receive. <p> An advantage of the approach taken by the Spring project is that its timing analysis is integrated into the compiler, and is performed after compiler optimization but before final emission of assembler code <ref> [Niehaus 1994, Niehaus 1991] </ref>. This enables Spring to take compiler optimizations into account while also basing its predictions on exactly the code that will be executed. It also makes it possible to perform program transformations required to enhance predictability and to fully implement the run-time model [Niehaus 1994]. <p> This enables Spring to take compiler optimizations into account while also basing its predictions on exactly the code that will be executed. It also makes it possible to perform program transformations required to enhance predictability and to fully implement the run-time model <ref> [Niehaus 1994] </ref>. Puschner and Koza take an approach to determining execution times in the context of the MARS system [Puschner and Koza 1990], which is very similar to that taken by Spring in many ways.
Reference: [Niehaus et. al. 1990] <author> D. Niehaus, L. Molesky and J.A. Stankovic, </author> <title> Spring System Programming and Run-Time Models, Spring Project Documentation, </title> <institution> University of Massachusetts, </institution> <address> Amherst, MA, </address> <month> June </month> <year> 1990 </year> <month> 26 </month>
Reference-contexts: Another novel feature and important contribution of the SGS is its translation from a process based representation of a computation used by the programmer to a representation of a computation's execution behavior as precedence-related tasks used by both on-line and off-line schedulers <ref> [Zhao and Ramamritham 1987, Niehaus et. al. 1990, Niehaus 1994] </ref>. Detailed discussion of the translation method is available elsewhere [Niehaus 1994, Niehaus 1991]. 5 It is important to note, however, that the reflective information used by the system is accumulated and derived in the course of this translation. <p> The SGS's use and production of the reflective information supported by the SDL was discussed briefly in Section 2.1, illustrated in Figure 2, and is discussed in detail elsewhere <ref> [Niehaus et. al. 1990, Niehaus 1991, Niehaus 1994] </ref>. Consider the role of the IPC subsystem in the compilation and execution of a simple process group containing two processes: one performing a synchronous send and one performing a synchronous receive.
Reference: [Niehaus et. al. 1993] <author> D. Niehaus, K. Ramamritham, J.A. Stankovic, G. Wallace, C. Weems, W. Burleson and J. Ko, </author> <title> The Spring Scheduling Co-Processor: Design, Use, and Performance, </title> <booktitle> Proceedings of the Fourteenth IEEE Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1993, </year> <pages> pp 106-111. </pages>
Reference-contexts: The bottom section of the figure illustrates how the reflective information is used by off-line workload generators, scheduling simulators, and simulations of the Spring Scheduling Co-Processor (SSCoP). These aspects of the system are peripheral to this paper and are discussed elsewhere <ref> [Gene 1990, Niehaus et. al. 1993] </ref>. The top section of Figure 2 illustrates how Spring-C source files are compiled and linked by the SGS, while the middle section illustrates the processing of source files which contain only SDL statements. <p> Each multiprocessor contains one (or more) application processors (APs), one (or more) system processors (SPs), and an I/O subsystem. Ultimately, SPs could be specifically designed to offer hardware support to system activities such as guaranteeing computations <ref> [Niehaus et. al. 1993] </ref>. The I/O subsystem is partitioned from the Spring kernel, handling non-critical I/O, slow I/O devices, and fast sensors.
Reference: [Niehaus et. al. 1995] <author> D. Niehaus, J.A. Stankovic and K. Ramamritham, </author> <title> A Real-Time System Description Language, </title> <booktitle> Proceedings of the 1995 IEEE Real-Time Technology and Applications Symposium, </booktitle> <month> May </month> <year> 1995. </year>
Reference-contexts: The Spring system is a highly integrated collection of software and hardware that synergistically operates to provide end-to-end support in building complex real-time systems. The specification language, called SDL <ref> [Niehaus et. al. 1995] </ref>, explicitly supports specifying a computation's real-time behavioral constraints, end-to-end constraints, concurrency, and details of the hardware-software platform that are required to accurately analyze the system and achieve predictability. The programming language, Spring-C [Niehaus 1994], works in concert with the specification language.
Reference: [Nirkhe et. al. 1990] <author> V. Nirkhe, S. Tripathi and A. Agrawala, </author> <title> Language Support for the Maruti Real-Time System, </title> <booktitle> Proceedings of the IEEE Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1990. </year>
Reference-contexts: The programming language for the Maruti system, MPL, also extends C++ and uses ideas close to those of Spring in some areas <ref> [Nirkhe et. al. 1990] </ref>. MPL provides several ways to specify temporal constraints on blocks of code within an object. Loop bounds are specified and recursion forbidden to increase predictability.
Reference: [Park and Shaw 1991] <author> C. Park and A. Shaw, </author> <title> Experiments with a Program Timing Tool Based on Source-Level Timing Schema, </title> <journal> IEEE Computer, </journal> <volume> Vol. 24., No. 5, </volume> <month> May </month> <year> 1991, </year> <pages> pp 48-57. </pages>
Reference-contexts: The tool worked directly with the executable code, first disassembling it, and then deducing the looping structure. Park and Shaw took an approach at the source level, using what they call source level timing schema for the basic elements in a restricted subset of C <ref> [Park and Shaw 1991] </ref>. Each timing schema describes the execution time for a C language statement or construct. One problem with this approach is that since the schema are for source level constructs, the method has difficulty taking into account any optimizations performed by the compiler which cross schema boundaries.
Reference: [Pflugel et. al. 1989] <author> M. Pflugel, A. Damm and W. Schwabl, </author> <title> Interprocess Communication in MARS, </title> <booktitle> ITG/GI Conference on Communication in Distributed Systems, </booktitle> <address> Stuttgart, Germany, </address> <month> February </month> <year> 1989. </year>
Reference: [Puschner and Koza 1990] <author> P. Puschner and C. Koza, </author> <title> Calculating the Maximum Execution Time of Real-Time Programs, </title> <journal> Real-Time Systems Journal, </journal> <volume> Vol 1., No. 2, </volume> <year> 1990. </year>
Reference-contexts: It also makes it possible to perform program transformations required to enhance predictability and to fully implement the run-time model [Niehaus 1994]. Puschner and Koza take an approach to determining execution times in the context of the MARS system <ref> [Puschner and Koza 1990] </ref>, which is very similar to that taken by Spring in many ways. They take a two phase approach, the first phase combines information about program structure and timing, and the second analyzes this representation to determine the worst case execution time.
Reference: [Ramaritham, Stankovic and Shiah 1989] <author> K. Ramamritham, J.A. Stankovic and P. Shiah, </author> <title> Efficient Scheduling Algorithms for Real-Time Multiprocessor Systems, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> Vol 1., No. 2, </volume> <month> February </month> <year> 1989, </year> <pages> pp. 184-194. </pages>
Reference: [Ramamritham, Stankovic and Zhao 1989] <author> K. Ramamritham, J.A. Stankovic, and W. Zhao, </author> <title> Distributed Scheduling of Tasks with Deadlines and Resource Requirements, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol 38., No. 8, </volume> <month> August </month> <year> 1989, </year> <pages> pp 1110-1123. </pages>
Reference: [Saksena et. al. 1995] <author> M. Saksena, J. da Silva and A. Agrawala, </author> <title> Design and Implementation of Maruti-II, Advances in Real-Time Systems, Sang Son, editor, </title> <publisher> Prentice-Hall, </publisher> <year> 1995. </year>
Reference-contexts: The scheduling approach is static table-driven. Support for distributed real-time systems includes a hardware based clock synchronization algorithm and a TDMA-like protocol to guarantee timely message delivery. 23 The MARUTI system <ref> [Saksena et. al. 1995] </ref> focuses on support for dynamic on-line guarantees that tasks will make their deadlines and on fault tolerance. It is object based and supports distributed systems. Each object has service access points which are the operations (services) that the object provides.
Reference: [Saltzer et. al. 1984] <author> J.H. Saltzer, D.P. Reed and D.D. Clark, </author> <title> End to End Arguments in System Design, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol 2., No. 2, </volume> <month> November </month> <year> 1984. </year>
Reference: [Sha and Goodenough 1988] <author> L. Sha and J. Goodenough, </author> <title> Real-Time Scheduling Theory and ADA, </title> <address> Cmu/sei-88-tr-33, CMU, </address> <month> November </month> <year> 1988. </year>
Reference-contexts: Our approach to dealing with the blocking problem (automatically via the compiler and scheduler) presents a second major paradigm for solving this problem (the other being rate monotonic with priority ceiling <ref> [Sha and Goodenough 1988] </ref>). * Many realistically complex real-time applications contain large collections of tasks with sophisticated requirements such as precedence constraints, shared resources, communication requirements, and varying deadlines and values for the tasks in the system.
Reference: [Shen et. al. 1993] <author> C. Shen, K. Ramamritham and J.A. Stankovic, </author> <title> Resource Reclaiming in Multiprocessor Real-Time Systems, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> Vol 4., No. 4, </volume> <month> April </month> <year> 1993, </year> <pages> pp 382-398. </pages>
Reference: [Shin 1991] <author> K. Shin, </author> <title> HARTS: A Distributed Real-Time Architecture, </title> <journal> IEEE Computer, </journal> <volume> Vol 24., No. 5, </volume> <year> 1991. </year>
Reference-contexts: The Hexagonal Architecture for Real-Time Systems (HARTS) consists of multiple sites connected by a hexagonal mesh network. Each site may be a uniprocessor or multiprocessor and contains an intelligent network processor. The intelligent network processor handles much of the low level communication functions. An experimental operating system called HARTOS <ref> [Shin 1991, Shin et. al. 1995] </ref> is a distributed real-time kernel running on HARTS. On each site HARTOS runs in conjunction with the commercial uniprocessor OS, pSOS, so, by itself, is not a full operating system. Rather, HARTOS focuses on interprocess communication, thereby providing some support for distributed real-time systems.
Reference: [Shin et. al. 1995] <author> K.G. Shin, D.D. Kandlur, D.L. Kiskis, P.S. Dodd, H.A. Rosenberg, and A. Indiresan, </author> <title> A Software Overview of HARTS: A Distributed Real-Time System, Advances in Real-Time Systems. Sang Son, editor, </title> <publisher> Prentice-Hall, </publisher> <year> 1995. </year>
Reference-contexts: The Hexagonal Architecture for Real-Time Systems (HARTS) consists of multiple sites connected by a hexagonal mesh network. Each site may be a uniprocessor or multiprocessor and contains an intelligent network processor. The intelligent network processor handles much of the low level communication functions. An experimental operating system called HARTOS <ref> [Shin 1991, Shin et. al. 1995] </ref> is a distributed real-time kernel running on HARTS. On each site HARTOS runs in conjunction with the commercial uniprocessor OS, pSOS, so, by itself, is not a full operating system. Rather, HARTOS focuses on interprocess communication, thereby providing some support for distributed real-time systems.
Reference: [Stallman 1992] <author> R. Stallman, </author> <title> Using and Porting GNU CC, </title> <type> Technical report, </type> <institution> Free Software Foundation, </institution> <month> May </month> <year> 1992. </year> <month> 27 </month>
Reference-contexts: The SGS currently supports three host architectures, DEC Vaxstations, Decstations, and DEC Alphas as well as one target architecture, the Motorola 68020. However, many parts of the SGS are extensions of the Free Software Foundation's tools <ref> [Stallman 1992] </ref>, which support a wide range of hosts, and share their portability. The SGS supports the programming environment, which presents the programmer with a virtual machine capable of supporting real-time computations. The target system implements the virtual real-time machine which manages computations' execution according to their requirements and constraints.
Reference: [Stankovic 1988] <author> J.A. Stankovic, </author> <title> Misconceptions about Real-Time Computing: A Serious Problem for Next Generation Systems, </title> <booktitle> IEEE Computer, </booktitle> <month> October </month> <year> 1988, </year> <pages> pp 10-19. </pages>
Reference: [Stankovic et. al., 1993] <author> J.A. Stankovic, D. Niehaus and K. Ramamritham, SpringNet: </author> <title> An Architecture for High Performance Distributed Real-Time Computing, </title> <booktitle> Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: Other examples of are given throughout the paper. 2 an ability to dynamically compose computations along both the function and time dimensions. The Spring system also uses a careful hardware layout, SpringNet <ref> [Stankovic et. al., 1993] </ref>, to simplify the design and analysis problem. For complex real-time systems, the extra hardware cost is negligible with respect to overall system cost. The Spring system was in development for more than ten years and many results produced along the way have been published. <p> SpringNet is a physically distributed network of multiprocessor nodes each running the Spring kernel <ref> [Stankovic et. al., 1993] </ref>. Each multiprocessor contains one (or more) application processors (APs), one (or more) system processors (SPs), and an I/O subsystem. Ultimately, SPs could be specifically designed to offer hardware support to system activities such as guaranteeing computations [Niehaus et. al. 1993].
Reference: [Stankovic and Ramamritham 1987] <author> J.A. Stankovic and K. Ramamritham, </author> <title> The Design of the Spring Kernel, </title> <booktitle> Proc. of the 8th Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1987, </year> <pages> pp 146-157. </pages>
Reference: [Stankovic and Ramamritham 1991] <author> J.A. Stankovic and K. Ramamritham, </author> <title> The Spring Kernel: A New Paradigm for Real-Time Systems, </title> <journal> IEEE Software, </journal> <volume> Vol 8., No. 3, </volume> <month> May </month> <year> 1991, </year> <pages> pp 62-72. </pages>
Reference-contexts: We refer to the data used at run-time as reflective information 1 . The explicit way in which the Spring system automatically addresses blocking and its effect on meeting deadlines is one of its key contributions. The run-time kernel, called the Spring kernel <ref> [Stankovic and Ramamritham 1991] </ref>, not only provides predictable primitives, but also gives significant added value by solving the central decision problem for the end-users of real-time systems whether a collection of active modules, sharing resources, communicating, and subject to time constraints will predictably satisfy those constraints.
Reference: [Stoyenko 1987] <author> A. Stoyenko, </author> <title> A Schedulability Analyzer for Real-Time Euclid, </title> <booktitle> IEEE Real-Time Systems Symposium, </booktitle> <month> December </month> <year> 1987. </year>
Reference-contexts: In one of the early efforts, Kligerman and Stoyenko produced a restricted language, Real-Time Euclid, which was designed to make schedu-lability analysis possible under a number of assumptions about the system and process behavior <ref> [Kligerman and Stoyenko 1986, Stoyenko 1987] </ref>. More recently, the Real-Time Mach system uses a language with C++ as its starting point, adding constructs for specifying timing constraints including start time, deadline, exception handling, and periods [Ishikawa et. al. 1990].
Reference: [SYSTRAN 1991] <author> SYSTRAN Corporation, </author> <title> SCRAMNet Network Reference Manual, </title> <address> Dayton, Ohio, 45432, </address> <year> 1991. </year>
Reference-contexts: The shared memory (sometimes called reflective memory), illustrated in Figure 4, provides a shared memory model for its 2 Mb (of physically distributed but logically centralized memory), and is implemented via the off-the-shelf product called Scramnet <ref> [SYSTRAN 1991] </ref>. The memory 8 is "reflective" in that the reflective memory boards in each of the Spring nodes always contain the same information, subject to transmission delays on the fiber optic ring connecting them.
Reference: [Tokuda et. al. 1989] <author> H. Tokuda, C.W. Mercer, Y. Ishikawa and T. Marchok, </author> <title> Priority Inversions in Real-Time Communication, </title> <booktitle> Proc. of the 10th Real-Time Systems Symposium, </booktitle> <month> May </month> <year> 1989, </year> <pages> pp 348-359. </pages>
Reference: [Tokuda et. al. 1990] <author> H. Tokuda, T. Nakajima and P. Rao, </author> <title> Real-Time MACH: Towards a Predictable Real-Time System, </title> <booktitle> Proceedings of the USENIX MACH Workshop, </booktitle> <year> 1990. </year>
Reference-contexts: Research projects also sometimes take this approach, the most obvious example being Real-Time Mach, which is an extension of Mach <ref> [Tokuda et. al. 1990] </ref>. <p> Real-time kernels are also being extended to operate in highly cooperative multiprocessor and distributed system environment. For example, the Real-Time Mach kernel <ref> [Tokuda et. al. 1990] </ref> provides a distributed real-time computing environment that works in conjunction with the static priority-driven preemptive scheduling paradigm. The kernel supports the notion of real-time objects and real-time threads. Each real-time object is time encapsulated.
Reference: [White et. al. 1997] <author> R.T. White, F. Mueller, C.A. Healy, D. B. Whalley, and M. G. Harmon, </author> <title> Timing Analysis for Data Caches and Set-Associative Caches, </title> <booktitle> Proceedings of the 1997 IEEE Real-Time Technology and Applications Symposium, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: This permits them to consider optimizations performed by the compiler and hardware features, but does not permit them to perform transformations on the code during the same phase as their temporal analysis. More recently, a project led by Whalley has addressed behavorial prediction for data caches and instruction caches <ref> [White et. al. 1997, Arnold et. al. 1994] </ref>. 6.3 Operating Systems For relatively small, less complex, real-time systems, it is often the case that real-time systems are supported by a stripped down and optimized versions of timesharing operating systems.
Reference: [Zhao and Ramamritham 1987] <author> W. Zhao and K. Ramamritham, </author> <title> Simple and Integrated Heuristic Algorithms for Scheduling Tasks with Time and Resource Constraints, </title> <journal> Journal of Systems and Software, </journal> <volume> Vol 7., No. 3, </volume> <month> September </month> <year> 1987, </year> <pages> pp 195-205. 28 </pages>
Reference-contexts: This information is supplied in the form required by the Spring scheduler, which manages computations represented as precedence related groups of tasks with resource and deadline constraints <ref> [Zhao and Ramamritham 1987, Niehaus 1994] </ref>. <p> Another novel feature and important contribution of the SGS is its translation from a process based representation of a computation used by the programmer to a representation of a computation's execution behavior as precedence-related tasks used by both on-line and off-line schedulers <ref> [Zhao and Ramamritham 1987, Niehaus et. al. 1990, Niehaus 1994] </ref>. Detailed discussion of the translation method is available elsewhere [Niehaus 1994, Niehaus 1991]. 5 It is important to note, however, that the reflective information used by the system is accumulated and derived in the course of this translation.
References-found: 50

