URL: ftp://parcftp.xerox.com/pub/qca/SIGIR95.ps
Refering-URL: http://www.cs.jhu.edu/~weiss/papers.html
Root-URL: 
Email: fschuetze,pederseng@parc.xerox.com hull@xerox.fr  
Title: A Comparison of Classifiers and Document Representations for the Routing Problem  
Author: Hinrich Schutze David A. Hull Jan O. Pedersen 
Web: URL: ftp://parcftp.xerox.com/pub/qca/SIGIR95.ps  
Address: 3333 Coyote Hill Road 6 Chemin de Maupertuis Palo Alto, CA 94304, USA 38240 Meylan, France  
Affiliation: Xerox Palo Alto Research Center Rank Xerox Research Center  
Abstract: In this paper, we compare learning techniques based on statistical classification to traditional methods of relevance feedback for the document routing problem. We consider three classification techniques which have decision rules that are derived via explicit error minimization: linear discriminant analysis, logistic regression, and neural networks. We demonstrate that the classifiers perform 10-15% better than relevance feedback via Rocchio expansion for the TREC-2 and TREC-3 routing tasks. Error minimization is difficult in high-dimensional feature spaces because the convergence process is slow and the models are prone to overfitting. We use two different strategies, latent semantic indexing and optimal term selection, to reduce the number of features. Our results indicate that features based on latent semantic indexing are more effective for techniques such as linear discriminant analysis and logistic regression, which have no way to protect against overfitting. Neural networks perform equally well with either set of features and can take advantage of the additional information available when both feature sets are used as input. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Apte, F. Damerau, and S.M. Weiss. </author> <title> Towards language independent automated learning of text categorization models. </title> <booktitle> In Proc. 17th Int'l Conference on R&D in IR (SIGIR), </booktitle> <pages> pages 23-30, </pages> <year> 1994. </year>
Reference-contexts: the performance of features based on variable selection to those generated by Latent Semantic Indexing and determine which are more effective for learning algorithms. 3 Learning Algorithms Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction <ref> [1] </ref>, nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]. The majority of these algorithms require that the number of feature variables be restricted in some way.
Reference: [2] <author> Rik K. Belew. </author> <title> Adaptive information retrieval: Using a connectionist representation to retrieve and learn about documents. </title> <booktitle> In Proceedings of SIGIR '89, </booktitle> <pages> pages 11-20, </pages> <address> Cambridge MA, </address> <year> 1989. </year>
Reference-contexts: We focus on the learning aspect of neural networks, in particular explicit error minimization. In contrast, other work on neural networks in IR has been closely related to the vector space model [35] or relevance feedback <ref> [2] </ref>. Kwok's work in [21] bears most similarity with our approach. However, apart from the standard learning algorithm we use, our input consists of reduced representations (either by feature selection or reparameterization). This representational scheme substantially reduces training time, and is less prone to overfitting, because there are fewer parameters.
Reference: [3] <author> Michael W. Berry. </author> <title> Large-scale sparse singular value compu-tations. </title> <journal> The International Journal of Supercomputer Applications, </journal> <volume> 6(1) </volume> <pages> 13-49, </pages> <year> 1992. </year>
Reference-contexts: A small number of the most important factors are then selected to approximate the covariance structure of the full collection. We use SVDPACK, a sparse SVD algorithm, for our computations <ref> [3] </ref>. Even though this algorithm does not need to calculate all orthogonal factors, it is still difficult to compute the LSI solution for the TREC collection, since it contains over a million terms and documents.
Reference: [4] <author> Chris Buckley, Gerard Salton, and James Allan. </author> <title> The effect of adding relevance information in a relevance feedback environment. </title> <booktitle> In Proceedings of SIGIR '94, </booktitle> <pages> pages 292-300, </pages> <year> 1994. </year>
Reference-contexts: On the surface, one might expect that learning algorithms that use more parameters and/or a larger feature space will have an easier time capturing the distinction between relevant and non-relevant documents (cf. Buckley's recent experiments that show better performance with increasing number of terms <ref> [4] </ref>). However, the improved performance is only guaranteed for the training data, which is simply a sample from the underlying population of relevant documents which may not adequately characterize its true distribution. <p> We define the local region for a query as the 2000 nearest documents, where similarity is measured using the inner product score to the Rocchio-expansion of the initial query vector <ref> [4] </ref>, corresponding to our baseline feedback algorithm. 5 The documents in the local region are then used as the training set for the learning algorithms. The documents in this region for which relevance judgements do not exist are treated as not relevant. <p> Documents with a query-correlation higher than the threshold are automatically ranked ahead of those that fall outside the local region. 5 Only the one-thousand highest-weighted terms were used which may partly explain why our performance is not as good as the one in <ref> [4] </ref>. 5 Experimental Results Table 1 presents routing results for 5 different classifiers and 4 dif ferent representations. <p> Previous work [20] suggests that RDA does not improve performance when applied to the LSI representation. To the best of our knowledge, the results given here for LDA and neural networks are at least as good as the best routing results published for TREC-2 <ref> [4] </ref> and TREC-3 [27]. Selection of the best routing technique in an operational system may depend on efficiency as well as IR performance.
Reference: [5] <author> Wm. S. Cooper, Aitao Chen, and Fredric C. Gey. </author> <title> Full text retrieval based on probabilistic equations with coefficients fitted by logistic regression. </title> <address> pages 57-66, </address> <year> 1994. </year> <note> In [15]. </note>
Reference-contexts: selection to those generated by Latent Semantic Indexing and determine which are more effective for learning algorithms. 3 Learning Algorithms Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression <ref> [5] </ref>, least-square methods [11], discriminant analysis [19], and neural networks [32, 34]. The majority of these algorithms require that the number of feature variables be restricted in some way. <p> The optimal value of fi is derived using maximum likelihood [26] and the Newton-Raphson method of numerical optimization. Logistic regression has been used for text retrieval in previous experiments <ref> [5, 12, 32] </ref>. Our approach is similar but all our feature variables are query-specific, i.e. we do not make use of general properties that are common to all queries in the collection.
Reference: [6] <author> W. B. Croft, J. Callan, and J. Broglio. </author> <title> Trec-2 routing and ad-hoc retrieval evaluation using the INQUERY system. </title> <booktitle> 1994. In [15]. </booktitle>
Reference-contexts: Our experiments will compare the performance of features based on variable selection to those generated by Latent Semantic Indexing and determine which are more effective for learning algorithms. 3 Learning Algorithms Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks <ref> [6] </ref>, Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]. The majority of these algorithms require that the number of feature variables be restricted in some way.
Reference: [7] <author> Douglass R. Cutting, Jan O. Pedersen, and Per-Kristian Halvorsen. </author> <title> An object-oriented architecture for text retrieval. </title> <booktitle> In Conference Proceedings of RIAO'91, Intelligent Text and Image Handling, Barcelona, Spain, </booktitle> <pages> pages 285-298, </pages> <month> April </month> <year> 1991. </year> <note> Also available as Xerox PARC technical report SSL-90-83. </note>
Reference-contexts: It consists of 3.3 gigabytes of text in over one million documents from several different sources: newswire, patents, scientific abstracts, and the Federal Register [14]. There are also 200 Tipster queries, detailed statements of information need that are called topics. We preprocess the corpus using the TDB system <ref> [7] </ref>, performing document parsing, tokenization including stemming using a two-level finite-state morphology, and removal of terms from a 951 word stop-list.
Reference: [8] <author> S. Deerwester, S. Dumais, G. Furnas, T. Landauer, and R. Harshman. </author> <title> Indexing by latent semantic analysis. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 41(6) </volume> <pages> 391-407, </pages> <year> 1990. </year>
Reference-contexts: For reparameterization, we use Latent Semantic Indexing (LSI) <ref> [8] </ref>, a technique that represents features and documents by a low-dimensional linear combination of orthogonal indexing variables. Our use of LSI differs in two important aspects from [8]. <p> For reparameterization, we use Latent Semantic Indexing (LSI) <ref> [8] </ref>, a technique that represents features and documents by a low-dimensional linear combination of orthogonal indexing variables. Our use of LSI differs in two important aspects from [8]. We compute a separate representation of terms and documents for each query, focusing on the documents which are most likely to be relevant [19]. <p> This approach differs from the one in [19] in that the local region now contains both relevant and non-relevant documents, which was found to be more effective than using only relevant documents [20]. 2.1 Discussion LSI captures the theme (or latent semantic structure <ref> [8] </ref>) of a document by analyzing the patterns of cooccurrence between terms. 2 Focusing on the theme of a document addresses the problems of synonymy and near-synonymy: In a term-based representation scheme, documents that are about the same theme but describe it with different vocabulary are represented in a way that
Reference: [9] <author> Susan T. Dumais. </author> <title> Latent semantic indexing (lsi) and trec-2. </title> <booktitle> In The Second Text REtrieval Conference (TREC-2), </booktitle> <pages> pages 105-115, </pages> <year> 1993. </year>
Reference-contexts: Furthermore, these factors are capturing the structure of the document collection as a whole and are not tuned for particular queries. Previous work has shown that LSI is more successful when applied to a local region on a query specific basis [19]. Dumais <ref> [9] </ref> also applies LSI to the routing task, but uses the judged documents for all the queries to generate her reduced representation, a method that corresponds roughly to taking the union of the local LSI regions for each query.
Reference: [10] <author> Jerome H. Friedman. </author> <title> Regularized discriminant analysis. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 84(405) </volume> <pages> 165-175, </pages> <year> 1989. </year>
Reference-contexts: There is a more well-behaved alternative known as Regularized Discriminant Analysis (RDA) <ref> [10] </ref>. RDA uses a pair of shrinkage parameters to create a very general family of estimators for the group covariance matrices. Rather than choosing between the pooled (LDA) and unpooled (QDA) covariance matrices, it looks at a weighted combination of them. <p> Linear discriminant analysis also suffers from overfitting, which explains why it works most successfully with the compact LSI representation. One might be able to improve performance for word-based features by applying regularized discriminant analysis <ref> [10] </ref>, which uses cross-validation to adjust for this problem. However, we did not conduct such an experiment here, due to the prohibitive computational cost of cross-validation for large IR problems. Previous work [20] suggests that RDA does not improve performance when applied to the LSI representation.
Reference: [11] <author> Norbert Fuhr. </author> <title> Optimum polynomial retrieval funcions based on the probability ranking principle. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 7(3) </volume> <pages> 183-204, </pages> <year> 1989. </year>
Reference-contexts: generated by Latent Semantic Indexing and determine which are more effective for learning algorithms. 3 Learning Algorithms Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods <ref> [11] </ref>, discriminant analysis [19], and neural networks [32, 34]. The majority of these algorithms require that the number of feature variables be restricted in some way.
Reference: [12] <author> Norbert Fuhr and U. Pfeifer. </author> <title> Probabilistic information retrieval as a combination of abstraction, inductive learning, and probabilistic assumptions. </title> <journal> ACM TOIS, </journal> <volume> 12(1), </volume> <month> Jan </month> <year> 1994. </year>
Reference-contexts: The optimal value of fi is derived using maximum likelihood [26] and the Newton-Raphson method of numerical optimization. Logistic regression has been used for text retrieval in previous experiments <ref> [5, 12, 32] </ref>. Our approach is similar but all our feature variables are query-specific, i.e. we do not make use of general properties that are common to all queries in the collection.
Reference: [13] <author> R. Gnanadesikan. </author> <title> Methods for Statistical Data Analysis of Multivariate Observations. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1977. </year>
Reference-contexts: Logistic regression uses the Newton-Raphson technique while neural networks rely an backpropagation (gradient descent). 3.1 Linear Discriminant Analysis Linear Discriminant Analysis (LDA) for the two-group problem can be derived as follows <ref> [13] </ref>. Suppose that one has a sample of data from two groups with n 1 and n 2 members, with mean vectors x 1 and x 2 and covariance matrices S 1 and S 2 respectively.
Reference: [14] <author> Donna Harman. </author> <booktitle> Overview of the first trec conference. In Proceedings of SIGIR '93, </booktitle> <year> 1993. </year>
Reference-contexts: It consists of 3.3 gigabytes of text in over one million documents from several different sources: newswire, patents, scientific abstracts, and the Federal Register <ref> [14] </ref>. There are also 200 Tipster queries, detailed statements of information need that are called topics. We preprocess the corpus using the TDB system [7], performing document parsing, tokenization including stemming using a two-level finite-state morphology, and removal of terms from a 951 word stop-list.
Reference: [15] <author> Donna Harman, </author> <title> editor. </title> <booktitle> Proceedings of the 2nd Text Retrieval Conference (TREC-2), </booktitle> <year> 1994. </year>
Reference-contexts: This paper will demonstrate that these advantagestranslate directly into improved retrieval performance for the routing problem. We use the Tipster collection and the TREC-2 and TREC-3 routing tasks to test classifiers and representations <ref> [15, 16] </ref>. There are some risks associated with using more general models of the relevant document space. On the surface, one might expect that learning algorithms that use more parameters and/or a larger feature space will have an easier time capturing the distinction between relevant and non-relevant documents (cf. <p> There is thus a fundamental trade-off between a large fea ture space with a restrictive learning algorithm and fewer features with a more general learning algorithm. In the past <ref> [15] </ref>, evidence has suggested that a weak learning rule (query expansion) and a high-dimensional feature space (terms) optimizes performance. We will demonstrate that the alternative approach is likely to prove superior in the long run. Sections 2 and 3 describe and motivate our dimensionality reduction strategies and classification techniques. <p> Disks 1 and 2 (about two gigabytes) are the training set for our run, Disk 3 (about one gigabyte) is the test set. Each combination of classifier and input representation is run for two sets of topics: 51-100 (corresponding to the routing task in TREC 2 <ref> [15] </ref>) and 101-150 (corresponding to the routing task in TREC 3 [16]). <p> We also provide evidence that non-linear extensions of the classifiers (RDA and non-linear neural networks) do not improve performance, probably becausethere is not enough information in the Tipster data collection to accurately learn complex models. Past evidence <ref> [15] </ref> has suggested that a weak learning algorithm (relevance feedback) and a high-dimensional feature space (terms) optimizes performance. We interpret the results in this paper as evidence that the alternative approach, complex learning algorithms and a reduced feature space is both practical and beneficial for the routing problem. Acknowledgments.
Reference: [16] <author> Donna Harman, </author> <title> editor. </title> <booktitle> Proceedings of the 3rd Text Retrieval Conference (TREC-3), </booktitle> <year> 1995. </year> <note> to appear. </note>
Reference-contexts: This paper will demonstrate that these advantagestranslate directly into improved retrieval performance for the routing problem. We use the Tipster collection and the TREC-2 and TREC-3 routing tasks to test classifiers and representations <ref> [15, 16] </ref>. There are some risks associated with using more general models of the relevant document space. On the surface, one might expect that learning algorithms that use more parameters and/or a larger feature space will have an easier time capturing the distinction between relevant and non-relevant documents (cf. <p> Each combination of classifier and input representation is run for two sets of topics: 51-100 (corresponding to the routing task in TREC 2 [15]) and 101-150 (corresponding to the routing task in TREC 3 <ref> [16] </ref>).
Reference: [17] <author> Marti A. Hearst. </author> <title> Multi-paragraph segmentation of expository discourse. </title> <booktitle> In Proceedings of the 32nd Meeting of the Association for Computational Linguistics, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: This process produced over 2.5 million terms. We also break up documents into chunks of about 250 terms, called text-tiles <ref> [17] </ref>. Only the tile with the highest proximity to the topic (i.e. the highest correlation in the vector space model) is selected and used for all subsequent experiments (both in training and test). For our routing runs, we replicate the routing setup at the second and third TREC conferences.
Reference: [18] <author> David Hull. </author> <title> Using statistical testing in the evaluation of retrieval performance. </title> <booktitle> In Proc. of the 16th ACM/SIGIR Conference, </booktitle> <pages> pages 329-338, </pages> <year> 1993. </year>
Reference-contexts: This strategy was motivated by poor results for runs in which terms were weighted according to frequency of occurrence and a desire to let the learning algorithms select the proper weight for each term. These experimental results are analyzed using ANOVA and the Friedman Test <ref> [18] </ref> to measure their statistical significance. ANOVA determines that one method is significantly better than another if the average difference in performance is large compared to its variability, correcting for differences between queries.
Reference: [19] <author> David Hull. </author> <title> Improving text retrieval for the routing problem using latent semantic indexing. </title> <booktitle> In Proceedings of SIGIR '94, </booktitle> <pages> pages 282-289, </pages> <year> 1994. </year>
Reference-contexts: Our use of LSI differs in two important aspects from [8]. We compute a separate representation of terms and documents for each query, focusing on the documents which are most likely to be relevant <ref> [19] </ref>. We refer to this technique as Local LSI since it is only applied to a region of the document space that is in the neighborhood of the query. <p> A second innovation is that the LSI representations are not used to construct a query which is analyzed using the vector space model. Rather, they are used as input parameters to a learning algorithm <ref> [19, 34] </ref>. LSI works by applying a matrix decomposition to the term by document matrix of the collection, which generates a large number of orthogonal LSI factors. A small number of the most important factors are then selected to approximate the covariance structure of the full collection. <p> Furthermore, these factors are capturing the structure of the document collection as a whole and are not tuned for particular queries. Previous work has shown that LSI is more successful when applied to a local region on a query specific basis <ref> [19] </ref>. Dumais [9] also applies LSI to the routing task, but uses the judged documents for all the queries to generate her reduced representation, a method that corresponds roughly to taking the union of the local LSI regions for each query. <p> This approach differs from the one in <ref> [19] </ref> in that the local region now contains both relevant and non-relevant documents, which was found to be more effective than using only relevant documents [20]. 2.1 Discussion LSI captures the theme (or latent semantic structure [8]) of a document by analyzing the patterns of cooccurrence between terms. 2 Focusing on <p> Semantic Indexing and determine which are more effective for learning algorithms. 3 Learning Algorithms Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis <ref> [19] </ref>, and neural networks [32, 34]. The majority of these algorithms require that the number of feature variables be restricted in some way. The issue of how best to accomplish this dimensionality reduction is one that has been neglected in the research on learning algorithms in information retrieval. <p> This approach can be generalized to more than two groups and it can be extended to create a non-linear classifier by modeling a separate covariance matrix for each group. LDA has already been applied to the routing problem by Hull <ref> [19] </ref>. In order to produce a non-linear classifier, one can estimate a separate covariance matrix for each group, rather than using a pooled estimate of the covariance matrix S, an approach known as Quadratic Discriminant Analysis (QDA).
Reference: [20] <author> David A. Hull. </author> <title> Information Retrieval using Statistical Classification. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1995. </year>
Reference-contexts: This approach differs from the one in [19] in that the local region now contains both relevant and non-relevant documents, which was found to be more effective than using only relevant documents <ref> [20] </ref>. 2.1 Discussion LSI captures the theme (or latent semantic structure [8]) of a document by analyzing the patterns of cooccurrence between terms. 2 Focusing on the theme of a document addresses the problems of synonymy and near-synonymy: In a term-based representation scheme, documents that are about the same theme but <p> RDA selects the optimal values for the shrinkage parameters based on cross-validation over the training set. However, previous experiments have not found much benefit to applying RDA to the routing problem <ref> [20] </ref>. 3.2 Logistic Regression Logistic regression is a statistical technique for modeling a binary response variable by a linear combination of one or more predictor variables, using a logit link function: g () = log (=(1 )) and modeling variance with a binomial random variable, i.e., the dependent variable log (=(1)) <p> One might be able to improve performance for word-based features by applying regularized discriminant analysis [10], which uses cross-validation to adjust for this problem. However, we did not conduct such an experiment here, due to the prohibitive computational cost of cross-validation for large IR problems. Previous work <ref> [20] </ref> suggests that RDA does not improve performance when applied to the LSI representation. To the best of our knowledge, the results given here for LDA and neural networks are at least as good as the best routing results published for TREC-2 [4] and TREC-3 [27].
Reference: [21] <author> K. L. Kwok. </author> <title> Experiment with a component theory of probabilistic information retrieval based on single terms as document components. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 8(4) </volume> <pages> 363-386, </pages> <year> 1990. </year>
Reference-contexts: We focus on the learning aspect of neural networks, in particular explicit error minimization. In contrast, other work on neural networks in IR has been closely related to the vector space model [35] or relevance feedback [2]. Kwok's work in <ref> [21] </ref> bears most similarity with our approach. However, apart from the standard learning algorithm we use, our input consists of reduced representations (either by feature selection or reparameterization). This representational scheme substantially reduces training time, and is less prone to overfitting, because there are fewer parameters.
Reference: [22] <author> David Lewis and Marc Ringuette. </author> <title> A comparison of two learning algorithms for text categorization. In Symposium on Document Analysis and Information Retrieval. </title> <institution> University of Nevada, </institution> <address> Las Vegas, </address> <year> 1994. </year>
Reference-contexts: Our experiments will compare the performance of features based on variable selection to those generated by Latent Semantic Indexing and determine which are more effective for learning algorithms. 3 Learning Algorithms Previous approaches to routing and text categorization [24] have used classification trees <ref> [33, 22] </ref>, Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]. The majority of these algorithms require that the number of feature variables be restricted in some way. <p> Our experiments will compare the performance of features based on variable selection to those generated by Latent Semantic Indexing and determine which are more effective for learning algorithms. 3 Learning Algorithms Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers <ref> [22, 23] </ref>, rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]. The majority of these algorithms require that the number of feature variables be restricted in some way.
Reference: [23] <author> David D. Lewis. </author> <title> An evaluation of phrasal and clustered representations on a text categorization task. </title> <booktitle> In SIGIR, </booktitle> <pages> pages 37-50, </pages> <year> 1992. </year>
Reference-contexts: Our experiments will compare the performance of features based on variable selection to those generated by Latent Semantic Indexing and determine which are more effective for learning algorithms. 3 Learning Algorithms Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers <ref> [22, 23] </ref>, rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]. The majority of these algorithms require that the number of feature variables be restricted in some way.
Reference: [24] <author> David D. Lewis and Philip J. Hayes. </author> <title> Special issue on text categorization. guest editorial. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 12(3):231, </volume> <year> 1994. </year>
Reference-contexts: Our experiments will compare the performance of features based on variable selection to those generated by Latent Semantic Indexing and determine which are more effective for learning algorithms. 3 Learning Algorithms Previous approaches to routing and text categorization <ref> [24] </ref> have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34].
Reference: [25] <author> Brij Masand, Gordon Linoff, and David Waltz. </author> <title> Classifying news stories using memory based reasoning. </title> <booktitle> In SIGIR, </booktitle> <pages> pages 59-65, </pages> <year> 1992. </year>
Reference-contexts: features based on variable selection to those generated by Latent Semantic Indexing and determine which are more effective for learning algorithms. 3 Learning Algorithms Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques <ref> [25, 36] </ref>, logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]. The majority of these algorithms require that the number of feature variables be restricted in some way.
Reference: [26] <author> P. McCullagh and J.A. Nelder. </author> <title> Generalized Linear Models, </title> <booktitle> chapter 4, </booktitle> <pages> pages 101-123. </pages> <publisher> Chapman and Hall, </publisher> <address> 2nd edition, </address> <year> 1989. </year>
Reference-contexts: The optimal value of fi is derived using maximum likelihood <ref> [26] </ref> and the Newton-Raphson method of numerical optimization. Logistic regression has been used for text retrieval in previous experiments [5, 12, 32].
Reference: [27] <author> S. E. Robertson, S. Walker, S. Jones, M. M. Hancock-Beaulieu, and M. Gatford. </author> <booktitle> Okapi at trec-3. In Text Retrieval Conference 3 (preproceedings), </booktitle> <year> 1994. </year>
Reference-contexts: Previous work [20] suggests that RDA does not improve performance when applied to the LSI representation. To the best of our knowledge, the results given here for LDA and neural networks are at least as good as the best routing results published for TREC-2 [4] and TREC-3 <ref> [27] </ref>. Selection of the best routing technique in an operational system may depend on efficiency as well as IR performance.
Reference: [28] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In David E. Rumelhart, James L. McClelland, and the PDP Research Group, editors, </editor> <booktitle> Parallel Distributed Processing. Explorations in the Microstructure of Cognition. Volume 1: Foundations. </booktitle> <publisher> The MIT Press, </publisher> <address> Cambridge MA, </address> <year> 1986. </year>
Reference-contexts: Neural networks are trained by backpropagation: the activation of each input pattern is propagated forward through the network, and the error produced is then backpropagated and the parameters changed so as to reduce the error <ref> [28] </ref>. The strength of neural networks is that they are robust, i.e., they have the ability to fit a wide range of distributions accurately. For example, any member of the exponential family can be modeled [29]. Unfortunately, this capacity leads to the danger of overfit-ting. <p> Relevance for a document is computed by setting the activations of the input units to the document's representation and propagating the activation through the network to the output unit, then propagating the error back through the network, using a gradient descent algorithm <ref> [28] </ref>.
Reference: [29] <author> David E. Rumelhart, Richard Durbin, Richard Golden, and Yves Chauvin. </author> <title> Backpropagation: The basic theory. </title> <editor> In Yves Chauvin and David E. Rumelhart, editors, </editor> <title> Back-propagation: Theory, Architectures, and Applications. </title> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale NJ, </address> <year> 1995. </year>
Reference-contexts: The strength of neural networks is that they are robust, i.e., they have the ability to fit a wide range of distributions accurately. For example, any member of the exponential family can be modeled <ref> [29] </ref>. Unfortunately, this capacity leads to the danger of overfit-ting. Neural networks can produce a model which fits the training data too precisely and does not generalize to the full population. <p> We chose the sigmoid: f (x) = 1 + e x as the activation function f for the units of the network, It can be shown <ref> [29] </ref> that in this case backpropagation minimizes the same error as the logistic regression, the cross-entropy error: L = i 4 Table 1 confirms this result: precision for logistic regression decreases when more features are added. where t i is the relevance for document i and o i is the estimated
Reference: [30] <author> Gerard Salton and Chris Buckley. </author> <title> Term-weighting approaches in automatic text retrieval. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 24(5) </volume> <pages> 513-523, </pages> <year> 1988. </year>
Reference-contexts: The mathematical description of the classification rule is generally expressed as a function f (x), where x is a vector of feature variables. The traditional approach to relevance feedback <ref> [30] </ref> defines f (x) = q fl x, where q, the feedback query, is a weighted combination of the original query vector and the vectors of the relevant (and perhaps non-relevant) documents. Methods which use this functional form (QE, LDA, LR, and LNN) are known as linear classifiers.
Reference: [31] <author> Gerard Salton and Chris Buckley. </author> <title> Improving retrieval performance by relevance feedback. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 41(4) </volume> <pages> 288-297, </pages> <year> 1990. </year>
Reference-contexts: to query vector for LSI, 200 terms, and LSI + 200 terms and proximity to expanded query vector for expansion) b) logistic regression c) linear NN (architecture (a) in Figure 1) d) non-linear NN (architecture (b) in Figure 1) e) LDA (linear discriminant analysis) The run expansion was tf-idf weighted <ref> [31] </ref>, and terms in the baseline runs were idf-weighted. Inverse document frequency (idf) weights are derived from the entire training set, not from the local region. All other runs on terms were not weighted: the input was 1 if the term occurred in the document and 0 otherwise.
Reference: [32] <author> Hinrich Schutze, Jan O. Pedersen, and Marti A. Hearst. </author> <title> Xerox TREC 3 report: Combining exact and fuzzy predictors. </title> <note> 1995. In [16], to appear. </note>
Reference-contexts: which are more effective for learning algorithms. 3 Learning Algorithms Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks <ref> [32, 34] </ref>. The majority of these algorithms require that the number of feature variables be restricted in some way. The issue of how best to accomplish this dimensionality reduction is one that has been neglected in the research on learning algorithms in information retrieval. <p> The optimal value of fi is derived using maximum likelihood [26] and the Newton-Raphson method of numerical optimization. Logistic regression has been used for text retrieval in previous experiments <ref> [5, 12, 32] </ref>. Our approach is similar but all our feature variables are query-specific, i.e. we do not make use of general properties that are common to all queries in the collection.
Reference: [33] <author> Richard M. Tong and Lee A. </author> <title> Appelbaum. </title> <booktitle> Machine learning for knowledge-based document routing (a reprot on the trec-2 experiment). </booktitle> <pages> pages 253-264, </pages> <year> 1994. </year> <note> In [15]. </note>
Reference-contexts: Our experiments will compare the performance of features based on variable selection to those generated by Latent Semantic Indexing and determine which are more effective for learning algorithms. 3 Learning Algorithms Previous approaches to routing and text categorization [24] have used classification trees <ref> [33, 22] </ref>, Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]. The majority of these algorithms require that the number of feature variables be restricted in some way.
Reference: [34] <author> Erik Wiener, Jan Pedersen, and Andreas S. Weigend. </author> <title> A neural network approach to topic spotting. </title> <booktitle> In Fourth Annual Symposium on Document Analysis and Information Retrieval, </booktitle> <address> Las Vegas NV, </address> <year> 1995. </year> <note> To appear. </note>
Reference-contexts: A second innovation is that the LSI representations are not used to construct a query which is analyzed using the vector space model. Rather, they are used as input parameters to a learning algorithm <ref> [19, 34] </ref>. LSI works by applying a matrix decomposition to the term by document matrix of the collection, which generates a large number of orthogonal LSI factors. A small number of the most important factors are then selected to approximate the covariance structure of the full collection. <p> which are more effective for learning algorithms. 3 Learning Algorithms Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks <ref> [32, 34] </ref>. The majority of these algorithms require that the number of feature variables be restricted in some way. The issue of how best to accomplish this dimensionality reduction is one that has been neglected in the research on learning algorithms in information retrieval.
Reference: [35] <author> Ross Wilkinson and Philip Hingston. </author> <title> Using the cosine measure in a neural network for document retrieval. </title> <booktitle> In SIGIR, </booktitle> <pages> pages 202-210, </pages> <address> Chicago, </address> <year> 1991. </year>
Reference-contexts: We focus on the learning aspect of neural networks, in particular explicit error minimization. In contrast, other work on neural networks in IR has been closely related to the vector space model <ref> [35] </ref> or relevance feedback [2]. Kwok's work in [21] bears most similarity with our approach. However, apart from the standard learning algorithm we use, our input consists of reduced representations (either by feature selection or reparameterization).
Reference: [36] <author> Yiming Yang. </author> <title> Expert network: Effective and efficient learning form human decisions in text categorization and retrieval. </title> <booktitle> In Proceedings of SIGIR '94, </booktitle> <pages> pages 13-22, </pages> <year> 1994. </year>
Reference-contexts: features based on variable selection to those generated by Latent Semantic Indexing and determine which are more effective for learning algorithms. 3 Learning Algorithms Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques <ref> [25, 36] </ref>, logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]. The majority of these algorithms require that the number of feature variables be restricted in some way.
References-found: 36

