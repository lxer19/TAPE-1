URL: http://math.univ-mlv.fr/users/chauveau/CLTC.ps.gz
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: MCMC CONVERGENCE DIAGNOSTIC VIA THE CENTRAL LIMIT THEOREM  
Author: Didier Chauveau Jean Diebolt flfl 
Date: July 1997  
Affiliation: Universite Marne-la-Vallee CNRS et Universite de Grenoble  
Abstract: Markov Chain Monte Carlo (MCMC) methods, as introduced by Gelfand and Smith (1990), provide a simulation based strategy for statistical inference. The application fields related to these methods, as well as theoretical convergence properties, have been intensively studied in the recent literature. However, many improvements are still expected to provide workable and theoretically well-grounded solutions to the problem of monitoring the convergence of actual outputs from MCMC algorithms (i.e. the convergence assessment problem). In this paper, we introduce and discuss a methodology based on the Central Limit Theorem for Markov chains to assess convergence of MCMC algorithms. Instead of searching for approximate stationarity, we primarily intend to control the precision of estimates of the invariant probability measure, or of integrals of functions with respect to this measure, through confidence regions based on normal approximation. The first proposed control method tests the normality hypothesis for normalized averages of functions of the Markov chain over independent parallel chains. This normality control provides good guarantees that the whole state space has been explored, even in multimodal situations. It can lead to automated stopping rules. A second tool connected with the normality control is based on graphical monitoring of the stabilization of the variance after n iterations near the limiting variance appearing in the CLT. Both methods require no knowledge of the sampler driving the chain. In this paper, we mainly focus on finite state Markov chains, since this setting allows us to derive consistent estimates of both the limiting variance and the variance after n iterations. Heuristic procedures based on Berry-Esseen bounds are investigated. An extension to the continuous case is also proposed. Numerical simulations illustrating the performance of these methods are given for several examples: a finite chain with multimodal invariant probability, a finite state random walk for which the theoretical rate of convergence to stationarity is known, and a continuous state chain with multimodal invariant probability issued from a Gibbs sampler. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Billingsley, P. </author> <year> (1986), </year> <title> Probability and Measure, 2nd Ed., </title> <publisher> John Wiley & Sons, </publisher> <address> New York. </address>
Reference: <author> Bolthausen, E. </author> <year> (1982), </year> <title> The Berry-Esseen Theorem for Strongly Mixing Harris Recurrent Markov Chains, </title> <journal> Z. Wahrscheinlichkeitstheorie verw. </journal> <volume> Gebiete 60, </volume> <pages> 283-289. </pages>
Reference-contexts: The Berry-Esseen theorem is said to hold when (2.5) sup fi fi (f ) n fi fi D. Chauveau and J. Diebolt 5 where is the standard normal c.d.f. General conditions have been given for (2.5) to hold in both the discrete and continuous case <ref> (see, e.g., Bolthausen, 1982) </ref>. However, a workable bound requires precise estimation of the constant involved in the right-hand side of (2.5). This question has been investigated by Mann (1996) for countable state MC's, but the proposed constants are far too large for practical use in our case.
Reference: <author> Brooks, S., and Roberts, G. </author> <year> (1995), </year> <title> Diagnosing Convergence of Markov Chain Monte Carlo Algorithms, </title> <type> Tech. report 95-12, </type> <institution> Stat. Lab., U. of Cambridge. </institution>
Reference-contexts: Last but not least, interpretability is important. As Brooks and Roberts point out, "a diagnostic which produces a definitive solution will generally be preferred to one which requires subjective interpretation and/or experience on the part of the user". Both parallel and single chain methods have well-known advantages and drawbacks <ref> (see Brooks and Roberts, 1995, or Robert, 1996) </ref>, but we believe that only parallel chain methods can provide satisfactory control tools.
Reference: <author> Caperaa, P., and Van Cutsem, B. </author> <year> (1988), </year> <institution> Methodes et Modeles en Statistique non parametrique, Dunod. </institution>
Reference-contexts: The Shapiro-Wilk statistic SW is normalized so that SW 2 (0; 1), and assumes values close to 1 if the null hypothesis H 0 is true <ref> (see, e.g., Caperaa and Van Cutsem, 1988) </ref>. Notice that this test does not require prior knowledge of the expectation n i of N i (n).
Reference: <author> Chung, K.L. </author> <year> (1967), </year> <title> Markov Chains with Stationary Transition Probabilities, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference: <author> Diaconis, P., Graham, R. and Morrison, J. </author> <year> (1990), </year> <title> Asymptotic analysis of random walks on a hypercube with many dimensions, Random structures and algorithms 1, </title> <type> 52-72. </type>
Reference: <author> Diebolt, J. and Robert, C.P. </author> <year> (1994), </year> <title> Estimation of Finite Mixture Distributions by Bayesian Sampling, </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 56, </volume> <pages> 363-375. </pages>
Reference-contexts: D. Chauveau and J. Diebolt 3 The proposed control methods can be applied to large finite chains resulting from actual situations or to finite chains obtained from continuous state Markov chains through theoretically valid discretization procedures (e.g., Guihenneuc and Robert, 1996), or through the duality principle <ref> (Diebolt and Robert, 1994) </ref>. We point out that a single chain technique making use of finite Markov chain theory has already been proposed by Raftery and Lewis (1992, 1996). <p> EXTENSION TO GENERAL MARKOV CHAINS Although this paper mainly focuses on finite MC's, we briefly show how normality control methods can also help assessing convergence of continuous state space MCMC's. More details will appear in a forthcoming companion paper. The duality principle <ref> (Diebolt and Robert, 1994) </ref> and the discretization method (Gui-henneuc and Robert, 1996) transform continuous MCMC's x (t) into a finite MC y (t) which captures the main convergence features of x (t) . The Duality principle.
Reference: <author> Feller, W. </author> <year> (1968), </year> <title> An Introduction to Probability Theory and Its Applications - Vol. II, </title> <publisher> Wiley. </publisher>
Reference-contexts: A heuristic procedure for MCMC control using Berry-Esseen type error bounds in the CLT <ref> (Feller, 1968) </ref> is also investigated. Section 3 describes two control methods for finite Markov chains: A test of normality for (1.3) with the indicator functions f = I i , i 2 E. <p> This question has been investigated by Mann (1996) for countable state MC's, but the proposed constants are far too large for practical use in our case. Another approach consists in using the Berry-Esseen theorem for the i.i.d. case <ref> (Feller, 1968) </ref>, where the constant has been precisely evaluated.
Reference: <author> Gelfand, A.E., and Smith, A.F.M. </author> <year> (1990), </year> <title> Sampling Based Approaches to Calculating Marginal Densities, </title> <journal> Journal of the American Statistical Association 86, </journal> <pages> 398-409. </pages>
Reference: <author> Gelman, A. and Rubin, D. B. </author> <year> (1992), </year> <title> Inference from Iterative Simulation Using Multiple Sequences, </title> <journal> Stat. Science 7, </journal> <volume> no. 4, </volume> <pages> 457-511. </pages>
Reference-contexts: Although parallel methods obviously require a larger computational expense, they are more dedicated to output i.i.d. random variables from and convey more confidence that the whole support of has been explored <ref> (see Gelman and Rubin, 1992, for a discussion) </ref>. Above all, checking convergence to stationarity of (x (t) ) basically requires comparing the distributions of x (t) for different values of t. This involves comparing probabilities of x (t) -measurable events for different values of t.
Reference: <author> Guihenneuc, C. and Robert, C.P. </author> <year> (1996), </year> <title> Discretizations of continuous state space Markov chains for MCMC convergence assessment, </title> <type> Preprint, </type> <institution> University of Paris V.. </institution>
Reference-contexts: D. Chauveau and J. Diebolt 3 The proposed control methods can be applied to large finite chains resulting from actual situations or to finite chains obtained from continuous state Markov chains through theoretically valid discretization procedures <ref> (e.g., Guihenneuc and Robert, 1996) </ref>, or through the duality principle (Diebolt and Robert, 1994). We point out that a single chain technique making use of finite Markov chain theory has already been proposed by Raftery and Lewis (1992, 1996). <p> We do not base our extension of the normality control methodology to the continuous case on renewal theory for atoms or small sets. Since the construction of desirable small sets requires some knowledge of the transition kernel and of the target probability <ref> (Guihenneuc and Robert, 1996) </ref>, this would result in strongly problem-specific control techniques (thus not in the spirit of our normality control principles).
Reference: <author> Mann, B. </author> <year> (1996), </year> <title> Berry-Esseen Central Limit Theorem for Markov Chains, </title> <type> PhD Thesis, </type> <institution> Harvard University. </institution>
Reference: <author> Meyn, S.P., and Tweedie, R.L. </author> <year> (1993), </year> <title> Markov Chains and Stochastic Stability, </title> <publisher> Springer-Verlag, London. </publisher>
Reference-contexts: The Discretization Method. This method produces finite MC's on the basis of a limited number of suitably chosen small sets <ref> (Meyn and Tweedie, 1993) </ref> of x (t) . Both normality control and variance comparison can be applied to the resulting MC y (t) . 5.1. Normality control for general Markov chains. Consider an ergodic Markov chain x (t) with continuous state space E and invariant probability distribution .
Reference: <author> Raftery, A.E., and Lewis, S. </author> <year> (1992), </year> <title> How many iterations in the Gibbs Sampler?, Bayesian Statistics (J.O. </title>
Reference: <editor> Berger, J.M. Bernardo, A.P. Dawid and A.F.M. Smith, eds.), </editor> <volume> vol. 4, </volume> <publisher> Oxford University Press, Oxford, </publisher> <pages> pp. 763-773. </pages>
Reference: <author> Raftery, A.E., and Lewis, S. </author> <year> (1996), </year> <title> Implementing MCMC, Markov Chain Monte Carlo in Practice (W.R. </title>
Reference: <author> Gilks, S.T. </author> <title> Richardson and D.J. </title> <editor> Spiegelhalter, eds.), </editor> <publisher> Chapman and Hall, London, </publisher> <pages> pp. 115-130. </pages>
Reference: <author> Robert, C.P. </author> <year> (1996), </year> <title> Methodes de Monte Carlo par Cha^nes de Markov, </title> <address> Economica, Paris. </address>
Reference-contexts: D. Chauveau and J. Diebolt 3 The proposed control methods can be applied to large finite chains resulting from actual situations or to finite chains obtained from continuous state Markov chains through theoretically valid discretization procedures <ref> (e.g., Guihenneuc and Robert, 1996) </ref>, or through the duality principle (Diebolt and Robert, 1994). We point out that a single chain technique making use of finite Markov chain theory has already been proposed by Raftery and Lewis (1992, 1996). <p> Their binary control relies on an approximation of some binary process issued from a general MCMC algorithm by a two-state Markov chain. However, this approximation is rather weak and the estimation of the entries of the transition matrix of this two-state Markov chain is in general poor <ref> (see, e.g., Robert, 1996) </ref>. This method is nevertheless often used. It is not problem-specific and is available in existing computer softwares. Section 2 contains the theoretical background for finite ergodic Markov chains. <p> Our control method based on the CLT is more specifically directed to such chains, which actually appear in practical situations (e.g., mixtures), and for which usual convergence control methods based on graphical evaluations of cumulated sums or similar quantities do not reveal multimodality <ref> (see Robert, 1996) </ref>. Dealing with multimodality is the usual argument in favor of parallel chain methods. <p> More details will appear in a forthcoming companion paper. The duality principle (Diebolt and Robert, 1994) and the discretization method <ref> (Gui-henneuc and Robert, 1996) </ref> transform continuous MCMC's x (t) into a finite MC y (t) which captures the main convergence features of x (t) . The Duality principle. When it applies, this principle allows for convergence control over the dual finite Markov chain derived from the continuous one. <p> We do not base our extension of the normality control methodology to the continuous case on renewal theory for atoms or small sets. Since the construction of desirable small sets requires some knowledge of the transition kernel and of the target probability <ref> (Guihenneuc and Robert, 1996) </ref>, this would result in strongly problem-specific control techniques (thus not in the spirit of our normality control principles).
Reference: <author> Seoh, M. and Hallin, M.(1997), When does Edgeworth beat Berry and Esseen?, </author> <note> Journal of Statistical Planning and Inference (to appear). </note>
Reference-contexts: i ; : : : ; X n are i.i.d. random variables with zero expectation, variance 2 and such that = E fi &lt; 1, then sup fi fi P n n fi fi n where the constant, initially evaluated at 33=4, has been lowered down to C BE 0:7915 <ref> (see, e.g., Seoh and Hallin, 1997) </ref>. This result is usually transferred to discrete MC's by considering the "block sums method" based on renewal theory. <p> It is known that, even in simple i.i.d. situations, the Berry-Esseen bound leads to fairly large sample sizes to ensure that the Kolmogorov-Smirnov distance between the distribution of the normalized sums and the standard normal is smaller than a given " &gt; 0 <ref> (see, e.g., Seoh and Hallin, 1997) </ref>. The simulations in Section 4 show that this is also the case in our situation, and that this heuristic leads to dramatically conservative values for the n i 's.
Reference: <author> Tierney, L. </author> <year> (1994), </year> <title> Markov Chains for Exploring Posterior Distributions (with discussion), </title> <journal> Ann. Statist. </journal> <volume> 22, </volume> <pages> 1701-1762. </pages> * <institution> Universit e Marne la Vall ee, Equipe d'Analyse et de Math ematiques Appliqu ees, </institution> <address> 2, rue de la Butte Verte, 93166 NOISY-LE-GRAND cedex, France. </address> <institution> E-mail address: chauveau@math.univ-mlv.fr ** CNRS, UMR 5523-LMC, Equipe de Statistique et de Mod elisation Stochastique, </institution> <address> BP 53, 38041 GRENOBLE Cedex 09, France. </address>
Reference-contexts: f 2 L 2 (), there exists 0 &lt; 2 (f ) &lt; +1 such that (5.1) p n X ! N 0; 2 (f ) : Various sets of sufficient conditions for the CLT in the context of general MCMC's (e.g. for Metropolis and Gibbs kernels) have been investigated <ref> (see, e.g., Tierney, 1994) </ref>. A comprehensive survey can be found in Robert (1996). We do not base our extension of the normality control methodology to the continuous case on renewal theory for atoms or small sets.
Reference: <institution> E-mail address: Jean.Diebolt@imag.fr </institution>
References-found: 21

