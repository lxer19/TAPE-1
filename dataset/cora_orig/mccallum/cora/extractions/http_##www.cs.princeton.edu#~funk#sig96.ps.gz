URL: http://www.cs.princeton.edu/~funk/sig96.ps.gz
Refering-URL: http://www.cs.princeton.edu/~funk/
Root-URL: http://www.cs.princeton.edu
Title: Coarse-Grained Parallelism for Hierarchical Radiosity Using Group Iterative Methods  
Author: Thomas A. Funkhouser 
Keyword: CR Categories and Subject Descriptors: D.1.3 [Programming Techniques]: Concurrent Programming Distributed Programming; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism Radiosity.  
Affiliation: Bell Laboratories  
Abstract: This paper describes algorithms that allow multiple hierarchical radiosity solvers to work on the same radiosity solution in parallel. We have developed a system based on a group iterative approach that repeatedly: 1) partitions patches into groups, 2) distributes a copy of each group to a slave processor which updates radiosities for all patches in that group, and 3) merges the updates back into a master solution. The primary advantage of this approach is that separate instan-tiations of a hierarchical radiosity solver can gather radios-ity to patches in separate groups in parallel with very little contention or communication overhead. This feature, along with automatic partitioning and dynamic load balancing algorithms, enables our implemented system to achieve significant speedups running on moderate numbers of workstations connected by a local area network. This system has been used to compute the radiosity solution for a very large model representing a five floor building with furniture. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Baum, D., and Winget, J. </author> <title> Real Time Radiosity Through Parallel Processing and Hardware Acceleration. </title> <booktitle> Computer Graphics (1990 Symposium on Interactive 3D Graphics), </booktitle> <volume> 24, 2, </volume> <pages> 67-75. </pages>
Reference-contexts: Most of this work has been applied to the progressive radiosity algorithm [6] which has O (n 2 ) computational complexity when solved to full convergence. Implementations for this algorithm have been described for MIMD computers [2, 3, 16, 19], SIMD computers [8], transputers [9], shared memory multi-processors <ref> [1, 7] </ref>, and networks of workstations [4, 20]. Recently, a few papers have appeared describing work on parallelizing the Monte Carlo Radiosity algorithm [10, 30].
Reference: [2] <author> Bouatouch, K., and Priol, T. </author> <title> Data Management Scheme for Parallel Radiosity. </title> <booktitle> Computer-Aided Design, </booktitle> <volume> 26, 12, </volume> <month> December, </month> <year> 1994, </year> <pages> 876-883. </pages>
Reference-contexts: There has been considerable prior work on parallel implementations of the radiosity method. Most of this work has been applied to the progressive radiosity algorithm [6] which has O (n 2 ) computational complexity when solved to full convergence. Implementations for this algorithm have been described for MIMD computers <ref> [2, 3, 16, 19] </ref>, SIMD computers [8], transputers [9], shared memory multi-processors [1, 7], and networks of workstations [4, 20]. Recently, a few papers have appeared describing work on parallelizing the Monte Carlo Radiosity algorithm [10, 30].
Reference: [3] <author> Chalmers, A, and Paddon, D. </author> <title> Parallel Processing of Progressive Refinement Radiosity Methods. </title> <booktitle> Second Eurographics Workshop on Rendering, </booktitle> <address> Barcelona, Spain, </address> <month> May, </month> <year> 1991. </year>
Reference-contexts: There has been considerable prior work on parallel implementations of the radiosity method. Most of this work has been applied to the progressive radiosity algorithm [6] which has O (n 2 ) computational complexity when solved to full convergence. Implementations for this algorithm have been described for MIMD computers <ref> [2, 3, 16, 19] </ref>, SIMD computers [8], transputers [9], shared memory multi-processors [1, 7], and networks of workstations [4, 20]. Recently, a few papers have appeared describing work on parallelizing the Monte Carlo Radiosity algorithm [10, 30]. <p> First, each group "gathering" step updates radiosities only for the elements in its group, which is advantageous for concurrency control when compared to "shooting" algorithms that update radiosities for all elements in each step <ref> [3] </ref>. Second, with Jacobi methods, updates to the radiosity values of elements in each group depend only upon radiosity values copied at the end of the previous iteration, and do not require access to current ra-diosity values for elements in all groups.
Reference: [4] <author> Chen, </author> <title> S.E. A Progressive Radiosity Method and its Implementation in a Distributed Processing Environment. </title> <type> Master's Thesis, </type> <institution> Cornell University, </institution> <year> 1989. </year>
Reference-contexts: Implementations for this algorithm have been described for MIMD computers [2, 3, 16, 19], SIMD computers [8], transputers [9], shared memory multi-processors [1, 7], and networks of workstations <ref> [4, 20] </ref>. Recently, a few papers have appeared describing work on parallelizing the Monte Carlo Radiosity algorithm [10, 30]. Most current implementations require a complete description of the scene's geometry to be resident in memory on all processors, thus limiting the size of models for which they can be applied.
Reference: [5] <author> Cohen, M., Greenberg, D., Immel, D., and Brock, P. </author> <title> An Efficient Radiosity Approach for Realistic Image Synthesis. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 6, </volume> <month> 3 (March, </month> <year> 1986), </year> <pages> 25-35. </pages>
Reference-contexts: Finally, Section 7 contains a brief summary and conclusion. 2 Previous work Radiosity methods [14] simulate diffuse global illumination by computing the amount of light arriving at each patch by emission or diffuse reflection from other patches. If each patch is composed of elements (i.e., substructured <ref> [5] </ref>), the method must solve the following linear system of equations: B i = E i + i j=1 where B i is the radiosity of element i, E i is the emission of element i, i is the diffuse reflectivity of element i, F ij is the fraction of the
Reference: [6] <author> Cohen, M., Chen, S., Wallace, J., and Greenberg, D. </author> <title> A Progressive Refinement Approach to Fast Radiosity Image Generation. </title> <booktitle> Computer Graphics (Proc. SIGGRAPH '88), </booktitle> <volume> 22, 4, </volume> <pages> 75-84. </pages>
Reference-contexts: There has been considerable prior work on parallel implementations of the radiosity method. Most of this work has been applied to the progressive radiosity algorithm <ref> [6] </ref> which has O (n 2 ) computational complexity when solved to full convergence. Implementations for this algorithm have been described for MIMD computers [2, 3, 16, 19], SIMD computers [8], transputers [9], shared memory multi-processors [1, 7], and networks of workstations [4, 20].
Reference: [7] <author> Drettakis, G., Fiume, E., and Fournier, A. </author> <title> Tightly-Coupled MultiProcessing for a Global Illumination Algorithm. </title> <type> EUROGRAPHICS '90, </type> <institution> Montreux, Switzerland, </institution> <year> 1990. </year>
Reference-contexts: Most of this work has been applied to the progressive radiosity algorithm [6] which has O (n 2 ) computational complexity when solved to full convergence. Implementations for this algorithm have been described for MIMD computers [2, 3, 16, 19], SIMD computers [8], transputers [9], shared memory multi-processors <ref> [1, 7] </ref>, and networks of workstations [4, 20]. Recently, a few papers have appeared describing work on parallelizing the Monte Carlo Radiosity algorithm [10, 30].
Reference: [8] <author> Drucker, S., and Schroder, P. </author> <title> Fast Radiosity Using a Data Parallel Architecture. </title> <booktitle> Third Eurographics Workshop on Rendering, </booktitle> <year> 1992. </year>
Reference-contexts: Most of this work has been applied to the progressive radiosity algorithm [6] which has O (n 2 ) computational complexity when solved to full convergence. Implementations for this algorithm have been described for MIMD computers [2, 3, 16, 19], SIMD computers <ref> [8] </ref>, transputers [9], shared memory multi-processors [1, 7], and networks of workstations [4, 20]. Recently, a few papers have appeared describing work on parallelizing the Monte Carlo Radiosity algorithm [10, 30].
Reference: [9] <author> Feda, M., and Purgathofer, W. </author> <title> Progressive Refinement Radiosity on a Transputer Network. </title> <booktitle> Second Eurographics Workshop on Rendering, </booktitle> <year> 1991, </year> <pages> 139-148. </pages>
Reference-contexts: Most of this work has been applied to the progressive radiosity algorithm [6] which has O (n 2 ) computational complexity when solved to full convergence. Implementations for this algorithm have been described for MIMD computers [2, 3, 16, 19], SIMD computers [8], transputers <ref> [9] </ref>, shared memory multi-processors [1, 7], and networks of workstations [4, 20]. Recently, a few papers have appeared describing work on parallelizing the Monte Carlo Radiosity algorithm [10, 30].
Reference: [10] <author> Feda, M., and Purgathofer, W. </author> <title> Progressive Ray Refinement for Monte Carlo Radiosity. </title> <booktitle> Fourth Eurographics Workshop on Rendering, </booktitle> <year> 1993, </year> <pages> 15-25. </pages>
Reference-contexts: Implementations for this algorithm have been described for MIMD computers [2, 3, 16, 19], SIMD computers [8], transputers [9], shared memory multi-processors [1, 7], and networks of workstations [4, 20]. Recently, a few papers have appeared describing work on parallelizing the Monte Carlo Radiosity algorithm <ref> [10, 30] </ref>. Most current implementations require a complete description of the scene's geometry to be resident in memory on all processors, thus limiting the size of models for which they can be applied.
Reference: [11] <author> Garey, M., and Johnson, D. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. </title> <publisher> Freeman and Company, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Our goal is to schedule group radiosity subcomputations on slaves in a manner that maximizes the rate of convergence to an overall solution. Unfortunately, this Multi-Processor Scheduling Problem is NP-Complete since each subcompu-tation is non-preemptable, task execution times are highly variable, and workstations may have different performance capabilities <ref> [11] </ref>. In this section, we describe our approximation algorithms for scheduling and load balancing. First-Fit Decreasing Algorithm A common scheduling strategy for minimizing the total completion time for a set of tasks run on multiple processors is to select tasks in order of their expected execution times, largest to smallest. <p> First-Fit Decreasing Algorithm A common scheduling strategy for minimizing the total completion time for a set of tasks run on multiple processors is to select tasks in order of their expected execution times, largest to smallest. This strategy is called the First Fit Decreasing (FFD) algorithm <ref> [11] </ref>. The idea is to schedule the large tasks first so that there is less chance that their execution times will extend beyond the last execution time of any other task. We have applied this principal in our radiosity system.
Reference: [12] <author> Guattery, S., and Miller, G. </author> <title> On the Performance of Spectral Graph Partitioning Methods. </title> <booktitle> 1995 ACM-SIAM Symposium on Discrete Algorithms (SODA), </booktitle> <year> 1995. </year>
Reference-contexts: Unfortunately, this problem is equivalent to the Graph Bisection Problem <ref> [12] </ref>, which is known to be NP-complete. However, we have developed two automatic algorithms that find approximate and useful solutions in polynomial time. The first algorithm, called the Merge Algorithm, starts by assigning each cluster to a separate group and then iteratively merges groups.
Reference: [13] <author> Golub, G., and Van Loan, C. </author> <title> Matrix Computations. </title> <publisher> John Hopkins University Press, </publisher> <address> Baltimore, MD, 2nd Edition, </address> <year> 1989. </year>
Reference-contexts: Group iterative methods partition the B i variables into groups, and rather than just relaxing one variable at a time, they relax an entire group during a single step <ref> [13, 29] </ref>. <p> It then becomes practical to use efficient, yet complicated, radiosity algorithms, such as Hierarchical Radiosity [17], to solve each group subproblem. Finally, group methods exhibit better cache coherence than element-by-element methods <ref> [13] </ref> since links between patches in the same group can be reused several times as the group is solved to convergence. This feature is particularly important for radiosity problems whose form factor matrices do not fit in memory all at once.
Reference: [14] <author> Goral, C., Torrance, K., Greenberg, D., and Battaile, B. </author> <title> Modeling the Interaction of Light Between Diffuse Surfaces. </title> <booktitle> Computer Graphics (Proc. SIGGRAPH '84), </booktitle> <volume> 18, 3, </volume> <pages> 213-222. </pages>
Reference-contexts: An overview of our system organization appears in Section 4, while detailed descriptions of the partitioning and load balancing algorithms are included in Section 5. Section 6 contains results of experiments with our system. Finally, Section 7 contains a brief summary and conclusion. 2 Previous work Radiosity methods <ref> [14] </ref> simulate diffuse global illumination by computing the amount of light arriving at each patch by emission or diffuse reflection from other patches.
Reference: [15] <author> Gortler, S., Schroder, P., Cohen, M., and Hanrahan, P. </author> <title> Wavelet Ra-diosity. </title> <booktitle> Computer Graphics (Proc. SIGGRAPH '93), </booktitle> <pages> 221-230. </pages>
Reference-contexts: The radiosity solver is based on the hierarchical (wavelet) radiosity system described in <ref> [15, 17, 27] </ref>. Although its de tails are not the focus of this paper, it is important to note that it stores its evolving solution in a disk-resident database and loads into memory only the data required for the current subcomputation.
Reference: [16] <author> Guitton, P., Roman, J., and Subrenat, G. </author> <title> Implementation Results and Analysis of a Parallel Progressive Radiosity. </title> <booktitle> In 1995 Parallel Rendering Symposium, </booktitle> <address> Atlanta, Georgia, </address> <month> October, </month> <year> 1995, </year> <pages> 31-37. </pages>
Reference-contexts: There has been considerable prior work on parallel implementations of the radiosity method. Most of this work has been applied to the progressive radiosity algorithm [6] which has O (n 2 ) computational complexity when solved to full convergence. Implementations for this algorithm have been described for MIMD computers <ref> [2, 3, 16, 19] </ref>, SIMD computers [8], transputers [9], shared memory multi-processors [1, 7], and networks of workstations [4, 20]. Recently, a few papers have appeared describing work on parallelizing the Monte Carlo Radiosity algorithm [10, 30].
Reference: [17] <author> Hanrahan, P., and Salzman, D. </author> <title> A Rapid Hierarchical Radiosity Algorithm. </title> <booktitle> Computer Graphics (Proc. SIGGRAPH '91), </booktitle> <volume> 25, 4, </volume> <pages> 197-206. </pages>
Reference-contexts: There has been relatively little work on parallel implementations of the hierarchical radiosity method, which is surprising at first glance since its asymptotic complexity is O (n) <ref> [17] </ref>. Singh [23] implemented a parallel hierarchical radiosity solver for a shared memory multiprocessor system in which each processor was initially assigned a queue of element-element interactions to process. When a processor subdivided an element, it added new interactions for the element's children to the head of its own queue. <p> This property allows multiple radiosity solvers to execute concurrently on different groups, with each solver updating a separate copy of the radiosity values without readers/writers contention. It then becomes practical to use efficient, yet complicated, radiosity algorithms, such as Hierarchical Radiosity <ref> [17] </ref>, to solve each group subproblem. Finally, group methods exhibit better cache coherence than element-by-element methods [13] since links between patches in the same group can be reused several times as the group is solved to convergence. <p> The radiosity solver is based on the hierarchical (wavelet) radiosity system described in <ref> [15, 17, 27] </ref>. Although its de tails are not the focus of this paper, it is important to note that it stores its evolving solution in a disk-resident database and loads into memory only the data required for the current subcomputation.
Reference: [18] <author> Naylor, B. </author> <title> Constructing Good Partitioning Trees. Graphics Interface `93. </title> <address> Toronto, CA, </address> <month> May, </month> <year> 1993, </year> <pages> 181-191. </pages>
Reference-contexts: We use geometric split heuristics originally developed for construction of spatial subdivisions for use in visibility determination (e.g., BSP trees <ref> [18] </ref>). Specifically, we partition the model along planes aligned with "major occluding" polygons of the model (see [25] for details). As the model is split recursively by these planes, clusters are assigned to groups depending on whether their centroid lies above or below the splitting plane (see Figure 6).
Reference: [19] <author> Paddon, D., and Chalmers, A. </author> <title> Parallel Processing of the Radiosity Method. </title> <booktitle> Computer-Aided Design, </booktitle> <volume> 26, 12, </volume> <month> December, </month> <year> 1994, </year> <pages> 917-927. </pages>
Reference-contexts: There has been considerable prior work on parallel implementations of the radiosity method. Most of this work has been applied to the progressive radiosity algorithm [6] which has O (n 2 ) computational complexity when solved to full convergence. Implementations for this algorithm have been described for MIMD computers <ref> [2, 3, 16, 19] </ref>, SIMD computers [8], transputers [9], shared memory multi-processors [1, 7], and networks of workstations [4, 20]. Recently, a few papers have appeared describing work on parallelizing the Monte Carlo Radiosity algorithm [10, 30].
Reference: [20] <author> Recker, R., George, D., and Greenberg, D. </author> <title> Acceleration Techniques for Progressive Refinement Radiosity. </title> <booktitle> Computer Graphics (1990 Sym posium on Interactive 3D Graphics), </booktitle> <volume> 24, 2, </volume> <pages> 59-66. </pages>
Reference-contexts: Implementations for this algorithm have been described for MIMD computers [2, 3, 16, 19], SIMD computers [8], transputers [9], shared memory multi-processors [1, 7], and networks of workstations <ref> [4, 20] </ref>. Recently, a few papers have appeared describing work on parallelizing the Monte Carlo Radiosity algorithm [10, 30]. Most current implementations require a complete description of the scene's geometry to be resident in memory on all processors, thus limiting the size of models for which they can be applied.
Reference: [21] <author> Rushmeier, H., Patterson, C., and Veerasamy, A. </author> <title> Geometric Simplification for Indirect Illumination Calculations. </title> <booktitle> Graphics Interface '93, </booktitle> <month> May, </month> <year> 1993, </year> <pages> 227-236. </pages>
Reference-contexts: Although clustering and visibility techniques are an important research area, and essential to the efficient execution of our radiosity system, these topics are not addressed in this paper. See <ref> [21, 22, 24, 26] </ref> for further information. Since only the master has access to the complete scene database, it must download portions of the database (i.e., potential working sets) to slaves during execution.
Reference: [22] <author> Sillion, F. </author> <title> A Unified Hierarchical Algorithm for Global Illumination with Scattering Volumes and Object Clusters. </title> <journal> IEEE Transactions on Visualization and Computer Graphics, </journal> <volume> I, 3, </volume> <month> September, </month> <year> 1995. </year>
Reference-contexts: Although clustering and visibility techniques are an important research area, and essential to the efficient execution of our radiosity system, these topics are not addressed in this paper. See <ref> [21, 22, 24, 26] </ref> for further information. Since only the master has access to the complete scene database, it must download portions of the database (i.e., potential working sets) to slaves during execution.
Reference: [23] <author> Singh, J.P., Gupta, A. and Levoy, M. </author> <title> Parallel Visualization Algorithms: Performance and Architectural Implications. </title> <journal> IEEE Computer, </journal> <volume> 27, </volume> <month> 7 (July </month> <year> 1994), </year> <pages> 45-55. </pages>
Reference-contexts: There has been relatively little work on parallel implementations of the hierarchical radiosity method, which is surprising at first glance since its asymptotic complexity is O (n) [17]. Singh <ref> [23] </ref> implemented a parallel hierarchical radiosity solver for a shared memory multiprocessor system in which each processor was initially assigned a queue of element-element interactions to process. When a processor subdivided an element, it added new interactions for the element's children to the head of its own queue.
Reference: [24] <author> Smits, B., Arvo, J., and Greenberg, D. </author> <title> A Clustering Algorithm for Radiosity in Complex Environments. </title> <journal> Computer Graphics (Proc. </journal> <volume> SIG-GRAPH '94), </volume> <pages> 435-442. </pages>
Reference-contexts: Although clustering and visibility techniques are an important research area, and essential to the efficient execution of our radiosity system, these topics are not addressed in this paper. See <ref> [21, 22, 24, 26] </ref> for further information. Since only the master has access to the complete scene database, it must download portions of the database (i.e., potential working sets) to slaves during execution.
Reference: [25] <author> Teller, S., </author> <title> Visibility Computations in Densely Occluded Polyhedral Environments. </title> <type> Ph.D. thesis, </type> <institution> Computer Science Division (EECS), University of California, Berkeley, </institution> <year> 1992. </year> <note> Also available as UC Berkeley technical report UCB/CSD-92-708. </note>
Reference-contexts: We use geometric split heuristics originally developed for construction of spatial subdivisions for use in visibility determination (e.g., BSP trees [18]). Specifically, we partition the model along planes aligned with "major occluding" polygons of the model (see <ref> [25] </ref> for details). As the model is split recursively by these planes, clusters are assigned to groups depending on whether their centroid lies above or below the splitting plane (see Figure 6).
Reference: [26] <author> Teller, S., and Hanrahan, P. </author> <title> Global Visibility Algorithms for Illumination Computations. </title> <booktitle> Computer Graphics (Proc. SIGGRAPH '93), </booktitle> <pages> 239-246. </pages>
Reference-contexts: The patches are stored in the scene database arranged in clusters specified by the modeler at scene creation time. The scene database also contains pre-computed cluster-to-cluster visibility information. The cluster visibility calculation is performed off-line using the algorithms described in <ref> [26] </ref> and generates a list for each cluster indicating which other clusters are potentially visible to it - i.e., not occluded by a wall, ceiling, or floor. <p> Although clustering and visibility techniques are an important research area, and essential to the efficient execution of our radiosity system, these topics are not addressed in this paper. See <ref> [21, 22, 24, 26] </ref> for further information. Since only the master has access to the complete scene database, it must download portions of the database (i.e., potential working sets) to slaves during execution.
Reference: [27] <author> Teller, S., Fowler, C., Funkhouser, T., and Hanrahan, P. </author> <title> Partitioning and Ordering Large Radiosity Computations. </title> <booktitle> Computer Graphics (Proc. SIGGRAPH '94), </booktitle> <pages> 443-450. </pages>
Reference-contexts: The radiosity solver is based on the hierarchical (wavelet) radiosity system described in <ref> [15, 17, 27] </ref>. Although its de tails are not the focus of this paper, it is important to note that it stores its evolving solution in a disk-resident database and loads into memory only the data required for the current subcomputation.
Reference: [28] <author> Wallace, J., Elmquist, K., Haines, E. </author> <title> A Ray Tracing Algorithm for Progressive Radiosity. </title> <booktitle> Computer Graphics (Proc. SIGGRAPH '89), </booktitle> <volume> 23, 3, </volume> <pages> 315-324. </pages>
Reference-contexts: Otherwise, the form factor, F AB , from one cluster A to another cluster B is estimated as the solid angle subtended by a disk representing cluster B <ref> [28] </ref>: F AB = r =(d + r ) (2) where d is the distance between A and B, and r is the radius of a sphere bounding B. This approximation is an overestimate that does not consider individual patch orientations and assumes that A is entirely visible to B.
Reference: [29] <author> Young, </author> <title> D.M. Iterative Solution of Large Linear Systems. </title> <booktitle> Computer Science and Applied Mathematics. </booktitle> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1971. </year>
Reference-contexts: Group iterative methods partition the B i variables into groups, and rather than just relaxing one variable at a time, they relax an entire group during a single step <ref> [13, 29] </ref>. <p> its computation, avoiding full replication of the entire database on any processor as is required by most other parallel radiosity systems. 4.3 Convergence Proof Proof of convergence of our parallel group iterative method can be shown by comparison to the standard sequential group Jacobi method, which is known to converge <ref> [29] </ref>. Consider splitting the matrix A (as in Ax = b) into A = DLU where D has blocks along the diagonal, L has the opposites of element below D, and U has opposites of elements above D. <p> We prove (I M ) (I J ) using corollary 5.6 on page 125 of Young <ref> [29] </ref>: "Let A be a monotone matrix and let A = Q 1 R 1 and A = Q 2 R 2 be two regular splittings of A.
Reference: [30] <author> Zareski, D., Wade, B., Hubbard, P. and Shirley, P. </author> <title> Efficient Parallel Global Illumination using Density Estimation. </title> <booktitle> 1995 Parallel Rendering Symposium. </booktitle> <address> Atlanta, Georgia, </address> <month> October, </month> <year> 1995, </year> <pages> 47-54. </pages>
Reference-contexts: Implementations for this algorithm have been described for MIMD computers [2, 3, 16, 19], SIMD computers [8], transputers [9], shared memory multi-processors [1, 7], and networks of workstations [4, 20]. Recently, a few papers have appeared describing work on parallelizing the Monte Carlo Radiosity algorithm <ref> [10, 30] </ref>. Most current implementations require a complete description of the scene's geometry to be resident in memory on all processors, thus limiting the size of models for which they can be applied.
Reference: [31] <author> Zareski, D. </author> <title> Parallel Decomposition of View-Independent Global Illumination Algorithms. </title> <type> Master's thesis, </type> <institution> Cornell University, </institution> <year> 1996. </year>
Reference-contexts: Load balancing was achieved by task stealing idle processors removed and processed interactions from the tail of other processors' queues. Due its communication intensive nature, this approach is not practical for a network of distributed workstations. Zareski <ref> [31] </ref> implemented a parallel version of the hierarchical radiosity algorithm on a network of workstations using a master-slave architecture in which each slave performed patch-ray intersection calculations for a separate subset of patches in the scene.
References-found: 31

