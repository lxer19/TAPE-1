URL: http://www.cs.arizona.edu/people/bkmoon/papers/shpcc94.ps.gz
Refering-URL: http://www.cs.arizona.edu/people/bkmoon/papers.html
Root-URL: http://www.cs.arizona.edu
Email: fbkmoon, saltzg@cs.umd.edu  
Title: Scalable High Performance  Adaptive Runtime Support for Direct Simulation Monte Carlo Methods on Distributed Memory Architectures  
Author: Bongki Moon Joel Saltz 
Address: College Park, MD 20742  
Affiliation: UMIACS and Dept. of Computer Sc., University of Maryland,  
Date: May 1994, pages 176-183.  
Note: Computing Conference, Knoxville, TN,  
Abstract: In highly adaptive irregular problems such as many Particle-In-Cell (PIC) codes and Direct Simulation Monte Carlo (DSMC) codes, data access patterns may vary from time step to time step. This fluctuation may hinder efficient utilization of distributed memory parallel computers because of the resulting overhead for data redistribution and dynamic load balancing. To efficiently parallelize such adaptive irregular problems on distributed memory parallel computers, several issues such as effective methods for domain partitioning and fast data transportation must be addressed. This paper presents efficient runtime support methods for such problems. A simple one-dimensional domain partitioning method is implemented and compared with unstructured mesh partitioners such as recursive coordinate bisection and recursive inertial bisection. A remapping decision policy has been investigated for dynamic load balancing on 3-dimensional DSMC codes. Performance results are presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. J. Berger and S. H. Bokhari. </author> <title> A partitioning strategy for nonuniform problems on multiprocessors. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-36(5):570-580, </volume> <month> May </month> <year> 1987. </year>
Reference-contexts: Recursive coordinate bisection (RCB) <ref> [1] </ref> is a well-known algorithm which bisections a problem domain into two pieces of equal work load recursively until the number of subdomains is equal to the number of processors.
Reference: [2] <author> Graeme A. Bird. </author> <title> The G2/A3 Program System Users Manual, </title> <type> version 1.8. </type> <institution> G.A.B. Consulting Pty Ltd, </institution> <year> 1992. </year>
Reference: [3] <author> Graeme A. Bird. </author> <title> Molecular Gas Dynamics and the Direct Simulation of Gas Flows. </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1994. </year>
Reference: [4] <author> S. H. Bokhari. </author> <title> Partitioning problems in parallel, pipelined, </title> <journal> and distributed computing. IEEE Trans. on Computers, </journal> <volume> 37(1) </volume> <pages> 48-57, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: That is, a problem domain has to be partitioned in such a way that work units i and i+1 are assigned to the same or to adjacent processors. Relatively simple algorithms for finding the optimal partition of a chain-structured problem have been suggested <ref> [4, 10, 5] </ref>. While these algorithms are developed to optimize computation and communication costs at the same time, we have developed and used a new chain partitioning algorithm which considers computation cost only. This algorithm requires only one step of global communication and a few steps of local computation.
Reference: [5] <author> Hyeong-Ah Choi and B. Narahari. </author> <title> Efficient algorithms for mapping and partitioning a class of parallel computations. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 19 </volume> <pages> 349-363, </pages> <year> 1993. </year>
Reference-contexts: That is, a problem domain has to be partitioned in such a way that work units i and i+1 are assigned to the same or to adjacent processors. Relatively simple algorithms for finding the optimal partition of a chain-structured problem have been suggested <ref> [4, 10, 5] </ref>. While these algorithms are developed to optimize computation and communication costs at the same time, we have developed and used a new chain partitioning algorithm which considers computation cost only. This algorithm requires only one step of global communication and a few steps of local computation.
Reference: [6] <author> R. Das, D. J. Mavriplis, J. Saltz, S. Gupta, and R. Ponnusamy. </author> <title> The design and implementation of a parallel unstructured Euler solver using software primitives, </title> <booktitle> AIAA-92-0562. In Proceedings of the 30th Aerospace Sciences Meeting, </booktitle> <month> January </month> <year> 1992. </year>
Reference-contexts: NAG-11560, by ONR under contract No. SC 292-1-22913 and by ARPA under contract No. NAG-11485. The authors assume all responsibility for the contents of the paper. lems in which data access patterns do not change during computation. <ref> [16, 6, 7] </ref> To parallelize such problems, the PARTI runtime primitives coordinate interprocessor data movement, manage the storage of, and access to, copies of off-processor data, and partition work and data structures. <p> Thus load balance is not an issue for this problem and we can study the effectiveness of the light-weight schedule and data migration primitives without interference from other aspects such as partitioning methods and remapping frequencies. The inspector/executor method of PARTI runtime library <ref> [17, 6] </ref> which is applied to the 2-dimensional problem carries out pre-processing of communication patterns every time step because the reference patterns to off-processor data change from time step to time step. Consequently preprocessing cost is greater for the inspector/executor method than using light-weight schedules.
Reference: [7] <author> R. Das and J. Saltz. </author> <title> Parallelizing molecular dynamics codes using the Parti software. </title> <booktitle> In Proceedings of the Sixth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 187-192. </pages> <publisher> SIAM, </publisher> <month> March </month> <year> 1993. </year>
Reference-contexts: NAG-11560, by ONR under contract No. SC 292-1-22913 and by ARPA under contract No. NAG-11485. The authors assume all responsibility for the contents of the paper. lems in which data access patterns do not change during computation. <ref> [16, 6, 7] </ref> To parallelize such problems, the PARTI runtime primitives coordinate interprocessor data movement, manage the storage of, and access to, copies of off-processor data, and partition work and data structures.
Reference: [8] <author> P. C. Liewer, E. W. Leaver, V. K. Decyk, and J. M. Dawson. </author> <title> Dynamic load balancing in a concurrent plasma PIC code on the JPL/Caltech Mark III hypercube. </title> <booktitle> In Proceedings of the Fifth Distributed Memory Computing Conference, </booktitle> <volume> Vol. II, </volume> <pages> pages 939-942. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> April </month> <year> 1990. </year>
Reference-contexts: A heuristic has been studied and manipulated to help make remapping decisions dynamically at runtime. A related work that achieves dynamic load balance by monitoring load imbalance at user specified interval has been reported <ref> [8] </ref>. 4.1 Periodic remapping DSMC codes can be characterized by statistical calculations involving particles associated with each cell, particles moved to new cells as a result of calculations, and cells partitioned over the processing nodes.
Reference: [9] <author> J. McDonald and L. Dagum. </author> <title> A comparison of particle simulation implementations on two different parallel architectures. </title> <booktitle> In Proceedings of the Sixth Distributed Memory Computing Conference, </booktitle> <pages> pages 413-419. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> April </month> <year> 1991. </year>
Reference-contexts: However, the DSMC method has a unique feature that distinguishes it from PIC method: the movement and collision processes are completely uncoupled over a time step [15]. McDonald and Dagum have compared implementations of direct particle simulation on SIMD and MIMD architectures. <ref> [9] </ref> 2.2 Computational characteristics Changes in position coordinates may cause the particles to move from current cells to new cells according to their new position coordinates.
Reference: [10] <author> David M. Nicol and David R. O'Hallaron. </author> <title> Improved algorithms for mapping pipelined and parallel computations. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 40(3) </volume> <pages> 295-306, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: That is, a problem domain has to be partitioned in such a way that work units i and i+1 are assigned to the same or to adjacent processors. Relatively simple algorithms for finding the optimal partition of a chain-structured problem have been suggested <ref> [4, 10, 5] </ref>. While these algorithms are developed to optimize computation and communication costs at the same time, we have developed and used a new chain partitioning algorithm which considers computation cost only. This algorithm requires only one step of global communication and a few steps of local computation.
Reference: [11] <author> David M. Nicol and Joel H. Saltz. </author> <title> Dynamic remapping of parallel computations with varying resource demands. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 37(9) </volume> <pages> 1073-1087, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: In addition, the periodic remapping method requires potentially impractical pre-runtime analysis to determine an optimal periodicity. Stop-At-Rise (SAR) remapping decision policy has been implemented and experimented, which was introduced previously <ref> [11] </ref>. The SAR heuristic trades the cost of problem remapping against time wasted due to load imbalance. It assumes that processors synchronize globally at every time step, that the cost of remapping and idle time for each processor since the last remapping are known at runtime.
Reference: [12] <author> B. Nour-Omid, A. Raefsky, and G. Lyzenga. </author> <title> Solving finite element equations on concurrent computers. </title> <booktitle> In Proc. of Symposium on Parallel Computations and their Impact on Mechanics, </booktitle> <address> Boston, </address> <month> December </month> <year> 1987. </year>
Reference-contexts: Recursive coordinate bisection (RCB) [1] is a well-known algorithm which bisections a problem domain into two pieces of equal work load recursively until the number of subdomains is equal to the number of processors. Recursive inertial bisection (RIB) <ref> [12] </ref> is similar to RCB in that it bisects a problem domain recursively based on spatial information, but RIB uses minimum moment of inertia when it selects bisectioning directions, whereas RCB selects bisectioning directions from x-, y-, or z-dimensions.
Reference: [13] <author> A. Pothen, H. D. Simon, and K.-P. Liou. </author> <title> Partitioning sparse matrices with eigenvectors of graphs. </title> <journal> SIAM J. Mat. Anal. Appl., </journal> <volume> 11(3) </volume> <pages> 430-452, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Clearly the number of processors has to be a power of 2 to apply these algorithms on parallel computers. Recursive bisection algorithms produce partitions of reasonable quality for static irregular problems, with relatively low overhead when compared with Recursive spectral bisection <ref> [13] </ref> and Simulated Annealing [19]. von Hanxleden [18] and Williams [19] discuss the qualities of partitions produced by the recursive bisection algorithms, and compare their performance with other partitioning methods in several aspects. 3.2 Chain partitioner Minimization of partitioning overheads is particularly important in problems that require frequent repartitioning.
Reference: [14] <author> D. F. G. Rault and M. S. Woronowicz. </author> <title> Spacecraft contamination investigation by direct simulation Monte Carlo contamination on UARS/HALOE. </title> <booktitle> In Proceedings AIAA 31th Aerospace Sciences Meeting and Exhibit, </booktitle> <address> Reno, Nevada, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: It includes movement and collision handling of simulated particles on a spatial flow field domain overlaid by a Cartesian mesh <ref> [14, 20] </ref>. The spatial location of each particle is associated with a Cartesian mesh cell. Each mesh cell typically contains multiple particles.
Reference: [15] <author> Patrick J. Roache. </author> <title> Computational Fluid Dynamics. </title> <publisher> Hermosa Publishers, </publisher> <address> Albuquerque, N.M., </address> <year> 1972. </year>
Reference-contexts: However, the DSMC method has a unique feature that distinguishes it from PIC method: the movement and collision processes are completely uncoupled over a time step <ref> [15] </ref>. McDonald and Dagum have compared implementations of direct particle simulation on SIMD and MIMD architectures. [9] 2.2 Computational characteristics Changes in position coordinates may cause the particles to move from current cells to new cells according to their new position coordinates.
Reference: [16] <author> Joel Saltz, Harry Berryman, and Janet Wu. </author> <title> Multiprocessors and run-time compilation. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 3(6) </volume> <pages> 573-592, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: NAG-11560, by ONR under contract No. SC 292-1-22913 and by ARPA under contract No. NAG-11485. The authors assume all responsibility for the contents of the paper. lems in which data access patterns do not change during computation. <ref> [16, 6, 7] </ref> To parallelize such problems, the PARTI runtime primitives coordinate interprocessor data movement, manage the storage of, and access to, copies of off-processor data, and partition work and data structures.
Reference: [17] <author> Joel Saltz, Kathleen Crowley, Ravi Mirchandaney, and Harry Berryman. </author> <title> Run-time scheduling and execution of loops on message passing machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8(4) </volume> <pages> 303-312, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: Thus load balance is not an issue for this problem and we can study the effectiveness of the light-weight schedule and data migration primitives without interference from other aspects such as partitioning methods and remapping frequencies. The inspector/executor method of PARTI runtime library <ref> [17, 6] </ref> which is applied to the 2-dimensional problem carries out pre-processing of communication patterns every time step because the reference patterns to off-processor data change from time step to time step. Consequently preprocessing cost is greater for the inspector/executor method than using light-weight schedules.
Reference: [18] <author> Reinhard v. Hanxleden and L. Riggway Scott. </author> <title> Load balancing on message passing architectures. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 13(3) </volume> <pages> 312-324, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: Clearly the number of processors has to be a power of 2 to apply these algorithms on parallel computers. Recursive bisection algorithms produce partitions of reasonable quality for static irregular problems, with relatively low overhead when compared with Recursive spectral bisection [13] and Simulated Annealing [19]. von Hanxleden <ref> [18] </ref> and Williams [19] discuss the qualities of partitions produced by the recursive bisection algorithms, and compare their performance with other partitioning methods in several aspects. 3.2 Chain partitioner Minimization of partitioning overheads is particularly important in problems that require frequent repartitioning.
Reference: [19] <author> R. Williams. </author> <title> Performance of dynamic load balancing algorithms for unstructured mesh calculations. </title> <journal> Con-currency, Practice and Experience, </journal> <volume> 3(5) </volume> <pages> 457-481, </pages> <month> Oc-tober </month> <year> 1991. </year>
Reference-contexts: Clearly the number of processors has to be a power of 2 to apply these algorithms on parallel computers. Recursive bisection algorithms produce partitions of reasonable quality for static irregular problems, with relatively low overhead when compared with Recursive spectral bisection [13] and Simulated Annealing <ref> [19] </ref>. von Hanxleden [18] and Williams [19] discuss the qualities of partitions produced by the recursive bisection algorithms, and compare their performance with other partitioning methods in several aspects. 3.2 Chain partitioner Minimization of partitioning overheads is particularly important in problems that require frequent repartitioning. <p> Recursive bisection algorithms produce partitions of reasonable quality for static irregular problems, with relatively low overhead when compared with Recursive spectral bisection [13] and Simulated Annealing <ref> [19] </ref>. von Hanxleden [18] and Williams [19] discuss the qualities of partitions produced by the recursive bisection algorithms, and compare their performance with other partitioning methods in several aspects. 3.2 Chain partitioner Minimization of partitioning overheads is particularly important in problems that require frequent repartitioning. We therefore considered low overhead partitioning methods, especially chain partitioners.
Reference: [20] <author> M. S. Woronowicz and D. F. G. Rault. </author> <title> On predicting contamination levels of HALOE optics aboard UARS using direct simulation Monte Carlo. </title> <booktitle> In Proceedings AIAA 28th Thermophysics Conference, </booktitle> <address> Or-lando, Florida, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: It includes movement and collision handling of simulated particles on a spatial flow field domain overlaid by a Cartesian mesh <ref> [14, 20] </ref>. The spatial location of each particle is associated with a Cartesian mesh cell. Each mesh cell typically contains multiple particles.
References-found: 20

