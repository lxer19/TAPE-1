URL: ftp://ftp.cc.gatech.edu/pub/gvu/tr/1992/92-05.ps.Z
Refering-URL: http://www.cs.gatech.edu/gvu/reports/1992/
Root-URL: 
Email: beth@cc.gatech.edu, keith@cc.gatech.edu  
Title: The Mercator Environment: A Nonvisual Interface to X Windows and Unix Workstations  
Author: Elizabeth Mynatt and W. Keith Edwards 
Keyword: user interfaces, auditory interfaces, visual impairment, auditory icons, rooms, three dimensional audio  
Address: Atlanta Georgia, 30332-0280  
Affiliation: Multimedia Computing Group Georgia Institute of Technology  
Abstract: User interfaces to computer workstations are heavily dependent on visual information. These Graphical User Interfaces, commonly found on powerful desktop computers, are almost completely inaccessible to blind and visually impaired individuals. In order to make these types of computers accessible to non-sighted users, it will be necessary to develop a new interface which replaces the visual communication with audio and tactile communication. This paper describes the Mercator Environment|an auditory and tactile interface to X Windows and Unix workstations designed for the visually impaired. 
Abstract-found: 1
Intro-found: 1
Reference: [Ant79] <author> Andreas Antonious. </author> <title> Digital Filters: Analysis and Design. </title> <publisher> McGraw-Hill, </publisher> <year> 1979. </year>
Reference-contexts: We will use a digital signal processing program which will be given a single sound and a location as its input and will produce two sounds, one for each ear, which when played in stereo headphones give the listener the effect of the original sound at the correct location. <ref> [Ant79, Bla73, Opp83, OS75, Wol88] </ref> STATUS AND FUTURE DIRECTIONS We are currently in the advanced design stage and early implementation stage of a Mercator prototype for the NASA Marshall Space Flight Center.
Reference: [BBV90] <author> L.H. Boyd, W.L. Boyd, </author> <title> and G.C. Vander-heiden. The graphical user interface: Crisis, </title> <journal> danger and opportunity. Journal of Visual Impairment and Blindness, </journal> <pages> pages 496-502, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: These graphical user interfaces can convey a great deal more information at a time than the older character-based interfaces. While the use and acceptance of GUIs has been a great boon for most computer users, those users with visual impairments have been left behind. <ref> [BBV90, Bux86] </ref> Unlike the character-based computer displays of a few years ago, there is no simple mapping from graphical window-based systems to the auditory and tactile domains.
Reference: [BBV91] <author> L.H. Boyd, W.L. Boyd, </author> <title> and G.C. Van-derheiden. Graphics-bases computers and the blind: Riding the tides of change. </title> <booktitle> In Technology and Persons with Disabilities, </booktitle> <year> 1991. </year>
Reference-contexts: Like the solutions which were developed for the older character-based systems, these access systems for GUIs largely rely on auditory feed-back to convey information to the user. Essentially these interfaces attempt to capture information en-route to the screen and convert it into an accessible format. <ref> [BBV91, Van89, Van, Fox91, KY87] </ref>. Most of this research has resulted in prototype systems that allow users with visual disabilities some degree of access to a computer with a GUI.
Reference: [Bla73] <author> Jens Blauert. </author> <title> Spatial Hearing. </title> <publisher> MIT Press, </publisher> <year> 1973. </year>
Reference-contexts: We will use a digital signal processing program which will be given a single sound and a location as its input and will produce two sounds, one for each ear, which when played in stereo headphones give the listener the effect of the original sound at the correct location. <ref> [Ant79, Bla73, Opp83, OS75, Wol88] </ref> STATUS AND FUTURE DIRECTIONS We are currently in the advanced design stage and early implementation stage of a Mercator prototype for the NASA Marshall Space Flight Center.
Reference: [Bux86] <author> William Buxton. </author> <booktitle> Human interface design and the handicapped user. In CHI '86 Conference Proceedings, </booktitle> <pages> pages 291-297, </pages> <year> 1986. </year>
Reference-contexts: These graphical user interfaces can convey a great deal more information at a time than the older character-based interfaces. While the use and acceptance of GUIs has been a great boon for most computer users, those users with visual impairments have been left behind. <ref> [BBV90, Bux86] </ref> Unlike the character-based computer displays of a few years ago, there is no simple mapping from graphical window-based systems to the auditory and tactile domains.
Reference: [CAH87] <author> Stuart K. Card and Jr. Austin Hender-son. </author> <title> A multiple, virtual-workspace interface to support user task switching. </title> <booktitle> In CHI '87 Conference Proceedings, </booktitle> <pages> pages 53-59, </pages> <year> 1987. </year>
Reference-contexts: In the audio domain, this clutter is called noise. Research initiated at the Xerox Palo Alto Research Center (Xerox PARC) has resulted in a solution for visual window clutter <ref> [DAHC86, CAH87, Cla91] </ref>. Researchers at Xerox PARC found that for a given set of windows on a user's display, that users tended to follow a certain pattern of window accesses.
Reference: [Cla91] <author> Mark A. Clarkson. </author> <title> An easier interface. </title> <journal> BYTE, </journal> <pages> pages 277-282, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: In the audio domain, this clutter is called noise. Research initiated at the Xerox Palo Alto Research Center (Xerox PARC) has resulted in a solution for visual window clutter <ref> [DAHC86, CAH87, Cla91] </ref>. Researchers at Xerox PARC found that for a given set of windows on a user's display, that users tended to follow a certain pattern of window accesses.
Reference: [DAHC86] <author> Jr. D. Austin Henderson and Stuart K. Card. Rooms: </author> <title> The use of multiple virtual workspaces to reduce space contention in a window-based graphical user interface. </title> <journal> ACM Transactions on Graphics, </journal> <pages> pages 211-243, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: In the audio domain, this clutter is called noise. Research initiated at the Xerox Palo Alto Research Center (Xerox PARC) has resulted in a solution for visual window clutter <ref> [DAHC86, CAH87, Cla91] </ref>. Researchers at Xerox PARC found that for a given set of windows on a user's display, that users tended to follow a certain pattern of window accesses.
Reference: [Fox91] <author> Jackie Fox. </author> <title> Unlocking the door: Pcs and people with disabilities. </title> <booktitle> PCToday, </booktitle> <pages> pages 43-51, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: Like the solutions which were developed for the older character-based systems, these access systems for GUIs largely rely on auditory feed-back to convey information to the user. Essentially these interfaces attempt to capture information en-route to the screen and convert it into an accessible format. <ref> [BBV91, Van89, Van, Fox91, KY87] </ref>. Most of this research has resulted in prototype systems that allow users with visual disabilities some degree of access to a computer with a GUI.
Reference: [Gav89] <author> William W. Gaver. </author> <title> The sonicfinder: An interface that uses auditory icons. </title> <booktitle> Human Computer Interaction, </booktitle> <volume> 4 </volume> <pages> 67-94, </pages> <year> 1989. </year>
Reference-contexts: Each object has a default sound which identifies its type. Users may choose unique sounds for objects to aid them in quickly identifying and locating objects. <ref> [Gav89] </ref>. Just as with light, sound has many different dimensions in which it can be perceived. Visual perception distinguishes such dimensions as color, saturation, luminescence, and texture. Audition has an equally rich space in which human beings can perceive difference: pitch, timbre, and amplitude.
Reference: [KY87] <author> Richard M. Kane and Matthew Yuschik. </author> <title> A case example of human factors in product definition: Needs finding for a voice output workstation for the blind. </title> <booktitle> In CHI '87 Conference Proceedings, </booktitle> <pages> pages 69-73, </pages> <year> 1987. </year>
Reference-contexts: Like the solutions which were developed for the older character-based systems, these access systems for GUIs largely rely on auditory feed-back to convey information to the user. Essentially these interfaces attempt to capture information en-route to the screen and convert it into an accessible format. <ref> [BBV91, Van89, Van, Fox91, KY87] </ref>. Most of this research has resulted in prototype systems that allow users with visual disabilities some degree of access to a computer with a GUI.
Reference: [Lad88] <author> Richard E. Ladner. </author> <title> Public law 99-506, section 508, electronic equipment accessibility for disabled workers. </title> <booktitle> In CHI '88 Conference Proceedings, </booktitle> <pages> pages 219-222, </pages> <year> 1988. </year>
Reference-contexts: Furthermore, there may be no meaningful mapping between the on-screen position of items and the underlying information represented by the visual metaphor anyway. Despite recently enacted governmental legislation requiring computer vendors to demonstrate that their equipment and software can be made accessible <ref> [Lad88] </ref> to be eligible for Federal procurement contracts (Title 508 of the Rehabilitation Act of 1986), and requiring employers to purchase equipment and software to make their systems accessible according to the needs of their users (the Americans with Disabilities Act), reasonable access to GUIs remains an unsolved problem.
Reference: [Opp83] <author> Alan Oppenhiem. </author> <title> Signals and Systems. </title> <publisher> Prentice-Hall, </publisher> <year> 1983. </year>
Reference-contexts: We will use a digital signal processing program which will be given a single sound and a location as its input and will produce two sounds, one for each ear, which when played in stereo headphones give the listener the effect of the original sound at the correct location. <ref> [Ant79, Bla73, Opp83, OS75, Wol88] </ref> STATUS AND FUTURE DIRECTIONS We are currently in the advanced design stage and early implementation stage of a Mercator prototype for the NASA Marshall Space Flight Center.
Reference: [OS75] <author> Alan Oppenhiem and Schafer. </author> <title> Digital Signal Processing. </title> <publisher> Prentice-Hall, </publisher> <year> 1975. </year>
Reference-contexts: We will use a digital signal processing program which will be given a single sound and a location as its input and will produce two sounds, one for each ear, which when played in stereo headphones give the listener the effect of the original sound at the correct location. <ref> [Ant79, Bla73, Opp83, OS75, Wol88] </ref> STATUS AND FUTURE DIRECTIONS We are currently in the advanced design stage and early implementation stage of a Mercator prototype for the NASA Marshall Space Flight Center.
Reference: [Pet91] <author> Chris D. Peterson. </author> <title> Editres-a graphical resource editor for x toolkit applications. </title> <booktitle> In Conference Proceedings, Fifth Annual X Technical Conference, </booktitle> <address> Boston, Mas-sachussets, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: Thus, for a text dis-player widget, it is possible to query the resources associated with the text displayer to determine what text is actually being displayed currently, what text is highlighted or selected, what are the properties of the displayed text, and so forth <ref> [Pet91] </ref>. By using resources, it is possible to query any client application and retrieve complete information about the structure of that application.
Reference: [Ros90] <author> Thomas D. Rossing. </author> <title> The Science of Sound. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference: [SA87] <author> Ralph R. </author> <title> Swick and M.S. Ackerman. The x toolkit: More bricks for building user interfaces, or, widgets for hire. </title> <booktitle> In Conference Proceedings, Usenix, Winter, </booktitle> <year> 1987. </year>
Reference-contexts: Further, each type of widget has certain data associated with it in a list called a resource list. The data in the resource list controls virtually all aspects of the widget: what text is displayed, whether or not the widget is accepting input, etc. <ref> [SA87] </ref> It is possible to change or examine the values of individual resources.
Reference: [Sch87] <author> Robert W. Scheifler. </author> <title> X window system protocol specification, </title> <type> version 11. </type> <institution> Massachusetts Institute of Technology, Cambridge, Massachusetts, and Digital Equipment Corporation, Maynard, Mas-sachusetts, </institution> <year> 1987. </year>
Reference-contexts: This layer of software can then interpret the requests it receives, decide to act upon those it wishes to act upon, and discard those that are irrelevant <ref> [Sch87] </ref>. This is how we intend to allow existing applications to function in our environment. Since we can intercept virtually every graphics output request an application can make, we have full control over what the user sees (or in our case, hears) while the application is running.
Reference: [SG86] <author> Robert W. Scheifler and J. Gettys. </author> <title> The x window system. </title> <journal> ACM Transactions on Graphics, </journal> <volume> (2), </volume> <month> April </month> <year> 1986. </year>
Reference-contexts: In the case of X, the server and any clients do not even have to be on the same machine: they communicate with one another via interprocess communication <ref> [SG86] </ref>. This rigid dichotomy between client and server is a great boon for implementors of systems such as Mercator.
Reference: [Van] <author> G.C. Vanderheiden. </author> <title> Graphic user interfaces: A tough problem with a net gain for users who are blind. Prepared for Perspectives section of Technology and Disability. </title>
Reference-contexts: Like the solutions which were developed for the older character-based systems, these access systems for GUIs largely rely on auditory feed-back to convey information to the user. Essentially these interfaces attempt to capture information en-route to the screen and convert it into an accessible format. <ref> [BBV91, Van89, Van, Fox91, KY87] </ref>. Most of this research has resulted in prototype systems that allow users with visual disabilities some degree of access to a computer with a GUI.
Reference: [Van89] <author> G.C. Vanderheiden. </author> <title> Nonvisual alternative display techniques for output from graphics-based computers. </title> <journal> Journal of Visual Impairment and Blindness, </journal> <year> 1989. </year>
Reference-contexts: Like the solutions which were developed for the older character-based systems, these access systems for GUIs largely rely on auditory feed-back to convey information to the user. Essentially these interfaces attempt to capture information en-route to the screen and convert it into an accessible format. <ref> [BBV91, Van89, Van, Fox91, KY87] </ref>. Most of this research has resulted in prototype systems that allow users with visual disabilities some degree of access to a computer with a GUI.
Reference: [Wol88] <author> Stephen Wolfram. </author> <title> Mathematica. </title> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference-contexts: We will use a digital signal processing program which will be given a single sound and a location as its input and will produce two sounds, one for each ear, which when played in stereo headphones give the listener the effect of the original sound at the correct location. <ref> [Ant79, Bla73, Opp83, OS75, Wol88] </ref> STATUS AND FUTURE DIRECTIONS We are currently in the advanced design stage and early implementation stage of a Mercator prototype for the NASA Marshall Space Flight Center.
Reference: [Yor87] <author> Bryant York. </author> <title> Pbe programming by ear (a programming environment for the visually handicapped). </title> <type> Technical Report BUCS Technical Report No.87-009, </type> <institution> Boston University, </institution> <month> September </month> <year> 1987. </year>
Reference-contexts: In this way the system of rooms and doors begins to resemble a network. The linkages of rooms and doors resembles the transition patterns that the users follow in their daily work. The visual medium has much more bandwidth for communication than the auditory medium <ref> [Yor87] </ref>. Therefore it is even more important in an auditory-based environment to have some sort of mechanism to sort and segregate applications and documents by functionality and patterns of access.
References-found: 23

