URL: ftp://ftp.research.microsoft.com/pub/TR/TR-93-14.ps
Refering-URL: http://www.research.microsoft.com/~rusa/papers.html
Root-URL: http://www.research.microsoft.com
Title: Sequentializing Program Dependence Graphs for Irreducible Programs  
Author: Bjarne Steensgaard 
Date: October 1993  
Address: One Microsoft Way Redmond, WA 98052  
Affiliation: Microsoft Research  
Abstract: Compilers using a parallel intermediate program representation like the program dependence graph must sequentialize the code as part of code generation. We have taken the final steps needed to solve the problem of converting a program dependence graph representation into a control flow graph representation for irreducible programs. We have done this without increasing the computational complexity of the fastest previously published algorithm unable to handle irreducible programs. We introduce the concepts of loop entry nodes and loop closing edges, which are generalizations of loop headers and backedges. Using these nodes, we can perform the necessary preprocessing without fixpoint iteration. 
Abstract-found: 1
Intro-found: 1
Reference: [AHU74] <author> Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1974. </year>
Reference-contexts: Instead of a definition of nested SCRs, an algorithm for finding them and simultaneously finding the loop header nodes and loop closing edges is given. The algorithm proceeds iteratively by first identifying ordinary SCRs for rooted graphs (e.g., using Tarjan's algorithm <ref> [AHU74] </ref>). The loop entry nodes and loop closing edges are then found for the identified loop bodies.
Reference: [BH92] <author> Thomas Ball and Susan Horwitz. </author> <title> Contructing control flow from control dependence. </title> <type> Technical Report TR No. 1091, </type> <institution> University of Wisconsin | Madison, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: The given algorithm still only handles PDGs with acyclic CDGs, but it is sketched how to extend the algorithm to handle single entry loops in CDGs. Our work is an extension of this algorithm. Ball and Horwitz also developed an algorithm for constructing a CFG from a CDG <ref> [BH92] </ref>. They use their algorithm in combination with a CFG-to-CDG conversion to check for conflicts in a version control system. They ignore data dependences in the PDG, so their algorithm cannot be used to generate programs.
Reference: [BM92] <author> Robert A. Ballance and Arthur B. Maccabe. </author> <title> Program dependence graphs for the rest of us. </title> <type> Technical Report TR 92-10, </type> <institution> Department of Computer Science, The University of New Mexico, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: The PDG consists of a data dependence graph (DDG) and a control dependence graph (CDG). The DDG reflects dependences between computations. The CDG reflects under what conditions computations must be executed. Some intuition about the PDG and how to translate common constructs into a CDG is given in <ref> [BM92] </ref>. The DDG part of the PDG is not well defined. Any kind of data dependence edges may be part of the data dependence graph (e.g., def-use, anti-dependence, output-dependence, etc.).
Reference: [FM85] <author> Jeanne Ferrante and Mary Mace. </author> <title> On linearizing parallel code. </title> <booktitle> In Proceedings of the Twelfth Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 179-190, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: We show how to solve the necessary dataflow problems rapidly using these nodes to guide processing of the nodes in the graph. 1 1.1 Related Work Ferrante and Mace did the initial work on generating sequential code from a PDG <ref> [FM85] </ref>. Their algorithm only handled PDGs for some programs; due to an oversight, the subset handled correctly is even smaller than the one they claimed to handle. A follow-up paper by Ferrante, Mace, and Simons [FMS88] gives more detail about this work but does not correct the oversight. <p> A simple algorithm exists for flattening CDGs which do not obey the 2-region rule. The predicate padding rule states that the targets of edges from predicate nodes must be region or entry nodes. 3 The Problem It is demonstrated <ref> [FM85] </ref> and proved [SAF90] that the problem of generating sequential code for a PDG can be phrased as a problem of ordering sibling subgraphs in the constituent CDG. Sibling subgraphs are children of the same region, entry, or root node.
Reference: [FMS88] <author> Jeanne Ferrante, Mary Mace, and Barbara Simons. </author> <title> Generating sequential code from parallel code. </title> <booktitle> In Proceedings of the 1988 International Conference on Supercomputing, </booktitle> <pages> pages 582-592, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: We only consider PDGs for which code duplication or insertion of extra predicates is not necessary. As the algorithm that our work is based upon the algorithm indicates where code duplication or insertion of extra predicates is needed <ref> [FMS88, SAF90, SF93] </ref>. The contribution of this paper is the extension of the previous work on sequentializing parallel program representations to handle programs with arbitrary control flow (i.e., irreducible programs). To achieve this goal, we introduce the concept of loop entry nodes and loop closing edges in rooted directed graphs. <p> Their algorithm only handled PDGs for some programs; due to an oversight, the subset handled correctly is even smaller than the one they claimed to handle. A follow-up paper by Ferrante, Mace, and Simons <ref> [FMS88] </ref> gives more detail about this work but does not correct the oversight. Simons, Alpern, and Ferrante [SAF90] take a more mathematical approach and present a correct algorithm for PDGs with acyclic CDGs.
Reference: [FOW87] <author> Jeanne Ferrante, Karl J. Ottenstein, and Joe D. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: They ignore data dependences in the PDG, so their algorithm cannot be used to generate programs. It is not clear how to extend their work to generate correct programs. 2 The Program Dependence Graph The program dependence graph (PDG) is a program representation suggested by Ferrante, Ottenstein and Warren <ref> [FOW87] </ref>. It is an incomplete representation of a sequential program, as there may be several sequential programs having the same PDG. Two sequential programs with the same PDG are semantically equivalent [PS91]. The PDG consists of a data dependence graph (DDG) and a control dependence graph (CDG).
Reference: [KU76] <author> John B. Kam and Jeffrey D. Ullman. </author> <title> Global data flow analysis and iterative algorithms. </title> <journal> Journal of the ACM, </journal> <volume> 23(1) </volume> <pages> 158-171, </pages> <month> January </month> <year> 1976. </year>
Reference-contexts: We show how to compute the same preprocessing information for CDGs with entry and close nodes and possibly with multiple entry loops. An important result of this paper is how to perform the preprocessing in a constant number of passes, regardless of the loop interconnectedness <ref> [KU76] </ref> of the graph. The method of computing the preprocessing information for region, predicate, and statement nodes is adapted from [SF93].
Reference: [PS91] <author> Phil Pfeiffer and Rebecca Parsons Selke. </author> <title> On the adequacy of dependence-based representations for programs with heaps. </title> <booktitle> In Proceedings of the International Conference on Theoretical Aspects of Computer Software, </booktitle> <pages> pages 365-386, </pages> <year> 1991. </year>
Reference-contexts: It is an incomplete representation of a sequential program, as there may be several sequential programs having the same PDG. Two sequential programs with the same PDG are semantically equivalent <ref> [PS91] </ref>. The PDG consists of a data dependence graph (DDG) and a control dependence graph (CDG). The DDG reflects dependences between computations. The CDG reflects under what conditions computations must be executed. Some intuition about the PDG and how to translate common constructs into a CDG is given in [BM92].
Reference: [SAF90] <author> Barbara Simons, David Alpern, and Jeanne Ferrante. </author> <title> A foundation for sequentializing parallel code | extended abstract. </title> <booktitle> In Proceedings of the 2nd ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 350-359, </pages> <year> 1990. </year>
Reference-contexts: The parallel program representation considered is the program dependence graph (PDG). A PDG is a combination of a control dependence graph (CDG) and a data dependence graph (DDG). Earlier work <ref> [SAF90, SF93] </ref> gave algorithms for sequentializing PDGs without loops in the CDG. The same papers sketch how to handle CDGs with single entry loops. We extend this existing work to work for CDGs with arbitrary loops. <p> The generated CFG should ideally contain no more computation statements/nodes than the PDG does. For some PDGs code duplication or insertion of extra predicates is necessary to generate a CFG representation of the same program <ref> [SAF90] </ref>. We only consider PDGs for which code duplication or insertion of extra predicates is not necessary. As the algorithm that our work is based upon the algorithm indicates where code duplication or insertion of extra predicates is needed [FMS88, SAF90, SF93]. <p> We only consider PDGs for which code duplication or insertion of extra predicates is not necessary. As the algorithm that our work is based upon the algorithm indicates where code duplication or insertion of extra predicates is needed <ref> [FMS88, SAF90, SF93] </ref>. The contribution of this paper is the extension of the previous work on sequentializing parallel program representations to handle programs with arbitrary control flow (i.e., irreducible programs). To achieve this goal, we introduce the concept of loop entry nodes and loop closing edges in rooted directed graphs. <p> A follow-up paper by Ferrante, Mace, and Simons [FMS88] gives more detail about this work but does not correct the oversight. Simons, Alpern, and Ferrante <ref> [SAF90] </ref> take a more mathematical approach and present a correct algorithm for PDGs with acyclic CDGs. The paper contains a proof of correctness for the algorithm applied to such PDGs, for which there exists a corresponding concise CFG. <p> The no postdominance rule is necessary for eliminating unnecessary control dependence. As in <ref> [SAF90, SF93] </ref>, additional restrictions are imposed on the structure of the CDG. We state these restrictions for the CDG after the transformations in Section 5.1 have been performed, as the rules are complicated to state for the CDG before the transformations. <p> A simple algorithm exists for flattening CDGs which do not obey the 2-region rule. The predicate padding rule states that the targets of edges from predicate nodes must be region or entry nodes. 3 The Problem It is demonstrated [FM85] and proved <ref> [SAF90] </ref> that the problem of generating sequential code for a PDG can be phrased as a problem of ordering sibling subgraphs in the constituent CDG. Sibling subgraphs are children of the same region, entry, or root node. <p> The external edge into the "If 2 " subgraph forces that subgraph to be scheduled after "Stmnt 1 ". Previous algorithms <ref> [SAF90, SF93] </ref> for ordering subgraphs according to the structure of the CDG do not work correctly for programs with multiple entry loops in the CDG. Programs with multiple entry loops in the CDG correspond to irreducible sequential programs. <p> We use the fact that sequentializing a constituent PDG amounts to ordering sibling subgraphs of the CDG if the CDG obeys the structural rules stated in Section 2 (this has been proved for acyclic graphs <ref> [SAF90] </ref>). In the presence of multiple entry loops in the CDG it is still possible to use the concept of external edges into subgraphs to order sibling subgraphs. In the previous algorithm [SF93], the CDG was acyclic and the subgraph of a node well defined. <p> The eec information for all nodes in the shown CDGs is listed in Table 2. 5.3 Computing a partial ordering of computations A subgraph represents a set of computations that can be scheduled as a unit relative to sibling subgraphs <ref> [SAF90] </ref>. Specifying an order for sibling subgraphs effectively reduces the problem of generating a CFG from the PDG to a simple traverse-and-link problem. In this section we show how to order sibling subgraphs. The ordering rules can specify a cyclic ordering of subgraphs. <p> In this section we show how to order sibling subgraphs. The ordering rules can specify a cyclic ordering of subgraphs. A cyclic ordering means that it is not possible to construct a CFG from the CDG without duplicating code or inserting extra predicates <ref> [SAF90, SF93] </ref>.
Reference: [SF93] <author> Barbara Simons and Jeanne Ferrante. </author> <title> An efficient algorithm for constructing a control flow graph for parallel code. </title> <type> Technical Report TR 03.465, </type> <institution> IBM, Santa Teresa Laboratory, </institution> <address> San Jose, California, </address> <month> February </month> <year> 1993. </year> <month> 14 </month>
Reference-contexts: The parallel program representation considered is the program dependence graph (PDG). A PDG is a combination of a control dependence graph (CDG) and a data dependence graph (DDG). Earlier work <ref> [SAF90, SF93] </ref> gave algorithms for sequentializing PDGs without loops in the CDG. The same papers sketch how to handle CDGs with single entry loops. We extend this existing work to work for CDGs with arbitrary loops. <p> We only consider PDGs for which code duplication or insertion of extra predicates is not necessary. As the algorithm that our work is based upon the algorithm indicates where code duplication or insertion of extra predicates is needed <ref> [FMS88, SAF90, SF93] </ref>. The contribution of this paper is the extension of the previous work on sequentializing parallel program representations to handle programs with arbitrary control flow (i.e., irreducible programs). To achieve this goal, we introduce the concept of loop entry nodes and loop closing edges in rooted directed graphs. <p> The paper contains a proof of correctness for the algorithm applied to such PDGs, for which there exists a corresponding concise CFG. The paper contains a sketch of how to handle CDGs with single entry loops. Simons and Ferrante <ref> [SF93] </ref> presents an algorithm with a much better time complexity. The major contribution of [SF93] is a preprocessing mechanism that makes information about external edges into subgraphs available in every CDG node. This makes it possible to order two sibling subgraphs in constant time. <p> The paper contains a sketch of how to handle CDGs with single entry loops. Simons and Ferrante <ref> [SF93] </ref> presents an algorithm with a much better time complexity. The major contribution of [SF93] is a preprocessing mechanism that makes information about external edges into subgraphs available in every CDG node. This makes it possible to order two sibling subgraphs in constant time. <p> The no postdominance rule is necessary for eliminating unnecessary control dependence. As in <ref> [SAF90, SF93] </ref>, additional restrictions are imposed on the structure of the CDG. We state these restrictions for the CDG after the transformations in Section 5.1 have been performed, as the rules are complicated to state for the CDG before the transformations. <p> The external edge into the "If 2 " subgraph forces that subgraph to be scheduled after "Stmnt 1 ". Previous algorithms <ref> [SAF90, SF93] </ref> for ordering subgraphs according to the structure of the CDG do not work correctly for programs with multiple entry loops in the CDG. Programs with multiple entry loops in the CDG correspond to irreducible sequential programs. <p> In the presence of multiple entry loops in the CDG it is still possible to use the concept of external edges into subgraphs to order sibling subgraphs. In the previous algorithm <ref> [SF93] </ref>, the CDG was acyclic and the subgraph of a node well defined. In the sketch of how to extend the algorithm for CDGs with single entry loops, backedges were ignored when computing the nodes of a subgraph. <p> The subgraphs of entry nodes of a loop are therefore all the same. The subgraph of X is not always the part of the graph that is reachable without following edges from close nodes to entry nodes that dominate X. The fastest previous algorithm <ref> [SF93] </ref> used a preprocessing mechanism to make information about external edges into subgraphs available in every CDG node. This makes it possible to order two sibling subgraphs possible in constant time. We extend this mechanism to work for CDGs with multiple entry loops. <p> If needed, a region node can be inserted between the entry node and the non-close parents. The transformations are illustrated for the example PDG in Figure 5. 5.2 Preprocessing In <ref> [SF93] </ref>, the CDG is preprocessed before the actual sequentializing phase. The preprocessing information gives information for each node about external edges into subgraphs and enables ordering of two sibling subgraphs in constant time. The cost of preprocessing is O (ne) when using bit-vector operations. <p> An important result of this paper is how to perform the preprocessing in a constant number of passes, regardless of the loop interconnectedness [KU76] of the graph. The method of computing the preprocessing information for region, predicate, and statement nodes is adapted from <ref> [SF93] </ref>. <p> The name eec is adopted from <ref> [SF93] </ref>. It is an acronym for "external edge condition". <p> In Figure 1, eec (If 2 ) is the set containing only the If 1 node. The computation of the eec information is performed using the region information for each node in the graph. The name and this two-step method for computing the eec information is adopted from <ref> [SF93] </ref>. Definition 5 (region) region (X) is the set of nodes n such that for all paths, , in the CDG from the root node to X, n has a region, root, or entry node on as a parent. <p> If 1 , If 2 , and Stmnt 1 . 2 The difference between the eec information and the region information is whether we consider execution of X or execution of any node in G (X). 8 Computing region (X) We first describe how the region information was computed in <ref> [SF93] </ref>, and then describe how the algorithm must be modified to work for CDGs with multiple entry loops. In [SF93], the region information is computed during a top-down traversal of the CDG, where each node is processed only after all its (non-close) parents have been processed (reverse postorder processing). <p> region information is whether we consider execution of X or execution of any node in G (X). 8 Computing region (X) We first describe how the region information was computed in <ref> [SF93] </ref>, and then describe how the algorithm must be modified to work for CDGs with multiple entry loops. In [SF93], the region information is computed during a top-down traversal of the CDG, where each node is processed only after all its (non-close) parents have been processed (reverse postorder processing). <p> Subsequently, the region information is computed for the rest of the loop body. Table 1 lists the region information for all nodes in the shown CDGs. Computing eec (X) We first describe how the eec information was computed in <ref> [SF93] </ref>, and then describe the algorithm for CDGs with multiple entry loops. In [SF93], the eec information is computed via a postorder processing of the graph using the region information we just computed. <p> Table 1 lists the region information for all nodes in the shown CDGs. Computing eec (X) We first describe how the eec information was computed in <ref> [SF93] </ref>, and then describe the algorithm for CDGs with multiple entry loops. In [SF93], the eec information is computed via a postorder processing of the graph using the region information we just computed. <p> Suppose X has children Z 1 ; Z 2 ; : : : ; Z n , and suppose eec (Z i ) has already been computed for 1 i n. Then eec (X) = i=1 ! When sketching how to handle single entry loops in the CDG, <ref> [SF93] </ref> treats close nodes as leaf nodes. We modify this algorithm to work for CDGs with multiple entry loops. We observe that if E is an entry node, then eec (E) " G (E) fEg. <p> In this section we show how to order sibling subgraphs. The ordering rules can specify a cyclic ordering of subgraphs. A cyclic ordering means that it is not possible to construct a CFG from the CDG without duplicating code or inserting extra predicates <ref> [SAF90, SF93] </ref>. <p> The close node in the CDG eventually become a jump in the CFG, and all other computations must be scheduled before the jump if they are to be executed at all. This rule is a refinement of the rule in <ref> [SF93] </ref> for handling subgraphs with backedges. We are now ready to state the ordering rules for sibling subgraphs X and Y . All the rules except those involving entry or close nodes are similar to the rules listed in [SF93]. <p> This rule is a refinement of the rule in <ref> [SF93] </ref> for handling subgraphs with backedges. We are now ready to state the ordering rules for sibling subgraphs X and Y . All the rules except those involving entry or close nodes are similar to the rules listed in [SF93]. To make the description simpler we ignore that subgraphs may be marked as having to be scheduled last among all sibling subgraphs. Table 3 is a decision table specifying how to order sibling subgraphs.
References-found: 10

