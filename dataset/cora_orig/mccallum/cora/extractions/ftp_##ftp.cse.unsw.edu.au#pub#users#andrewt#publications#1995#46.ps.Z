URL: ftp://ftp.cse.unsw.edu.au/pub/users/andrewt/publications/1995/46.ps.Z
Refering-URL: http://www.cse.unsw.edu.au/school/publications/1995/SCSE_publications.html
Root-URL: http://www.cse.unsw.edu.au
Email: mann@cse.unsw.edu.au  
Title: BEELINE A SITUATED, BOUNDED CONCEPTUAL KNOWLEDGE SYSTEM  
Author: GRAHAM MANN 
Address: Sydney 2052, Australia  
Affiliation: School of Computer Science Engineering, University of New South Wales  
Abstract: How do recent theoretical arguments about situated cognition and bounded rationality affect the practical matter of designing and building intelligent knowledge based systems? A particular view of situated cognition is adopted, in which conceptual knowledge structures are grounded by being linked to objects, events and behaviours in nested environments outside the system through channels that are analogous to biological sensors and actuators. These grounded conceptual structures can be created and modified through a variety of arbitrarily bounded conceptual processes, including natural language text parsing. Fruitful interactions between conceptual structures from these different sources may then be explored. BEELINE is a software platform designed for experimenting with these ideas. It immerses a language-using, goalseeking cognitive agent in a simulated physical world. It can use real English instructions to achieve a navigational goal. This predicament offers fresh solutions to old knowledge engineering problems, and presents some new challenges for knowledge based systems of the future. Because they have mainly been conducted at a highly theoretical level, one might wonder what recent arguments about the fundamental nature of knowledge and its processes imply for builders of practical knowledge-based systems. In this paper I focus on two recent issues being debated in the AI and cognitive science literature, principally that of situated cognition and secondarily that of bounded rationality. As a way of making sense of these notions, I will describe an experimental knowledge-based system that embodies my positions on these issues. I will argue that both these ideas can be incorporated into conventional systems, without requiring them to be radically redesigned. Furthermore, I will suggest that such modifications can help with some old knowledge processing problems, as well pose some new ones. A range of theoretical claims and matters of emphasis appear under the rubric of situated cognition. There appears to be no official position, but all these ideas emphasise the role of the physical and social environment or context, within which a cognitive agent is imbedded, as a pattern for reaction. They deemphasise or reject the established notions of planning, reasoning and other manipulations of stored patterns of symbols (exemplified by such representation works as Newell & Simon (1972), Anderson (1983) and Newell (1981; 1990) and by such planning works as Sussman (1977) and Sarcedoti (1977)) especially those originating from theory or a priori assertions about the domain. William Clancey (1993) makes a philosophical meal of situatedness, using it to motivate a fundamental change in the way perception, cognition and action are to be understood. He argues that the physical symbol system hypothesis - that symbols are a necessary and sufficient condition for intelligent processing - confuses the notation used for communicating scientific theories with 
Abstract-found: 1
Intro-found: 1
Reference: <author> Anderson, J.R. </author> <booktitle> (1983) The Architecture of Cognition. </booktitle> <address> Cambridge, Mass., </address> <publisher> Harvard University Press. </publisher>
Reference: <author> Bonasso, </author> <title> R.P. (1992) Integrating reaction plans and layered competences through synchronous control. </title> <booktitle> Proc. 12th International Joint Conference on Artificial Intelligence, </booktitle> <address> Sydney, Australia. </address>
Reference-contexts: The use of sensors and actuators in a reactive manner need not conflict with the notion of representation by conceptual structures. A number of robot experiments <ref> (Bonasso, 1992) </ref> have suggested the value of adding a separate planning or reasoning module to behaviour-based robot architectures; the question of how the two would interact is an active area of research.
Reference: <author> Birnbaum, L & Selfridge, M. </author> <title> (1981) Conceptual analysis of natural language. In: Inside Computer Understanding. Edited by Schank, </title> <editor> R.C & Riesbeck, C.K. </editor> <address> Hillsdale, New Jersey, </address> <publisher> Lawrence Earlbaum Assoc. </publisher>
Reference-contexts: In real texts this can be a highly ambiguous process, entailing expensive search and no guarantee of a unique solution. To deal with this problem, it was necessary to depart from existing conceptual graph parser designs by abandoning syntax as an important organising principle. Early work on conceptual analysis <ref> (Birnbaum & Selfridge, 1981) </ref> demonstrated that the semantic content of representations is much more important guide to the assembly process. In the BEELINE parser active processes called actors are attached at strategic points on the meaning-graphs.
Reference: <author> Brachman, R.J. and Smoltze, J.G. </author> <title> (1985) An overview of the KL-ONE knowledge representation system. </title> <journal> Cognitive Science, </journal> <volume> 7, </volume> <pages> 171-216. </pages>
Reference-contexts: Some of the most mature have developed semantic network theory into specific languages that allow the creation, manipulation and disposal of structures of nodes and arcs standing for concept types and the relationships between them, respectively (conceptual dependencies (Schank, 1975); KL-ONE <ref> (Brachman, 1985) </ref>; conceptual graphs (Sowa,1984)). It has been argued elsewhere (Mann, 1993) that conceptual graph theory is a good choice for knowledge processing in general and natural language understanding in particular.
Reference: <author> Brooks R. </author> <title> (1989) A robot that walks; emergent behaviours from a carefully evolved network. </title>
Reference-contexts: The success of he and his students at constructing insect-like robot creatures encouraged him to advance a theory of intelligent action that eliminates the need for an internally stored world model by allowing his machines to directly sense and physically react on the world itself <ref> (Brooks, 1989) </ref>. When avoiding an obstacle, for example, they do not rely on a plan; instead hardwired sensory-motor behaviours from a carefully layered subsumption architecture are triggered to negotiate the obstruction.
Reference: <author> A.I. </author> <type> Memo #1091, </type> <institution> MIT Artificial Intelligence Laboratory. </institution>
Reference: <author> Brooks R. </author> <title> (1991) Intelligence without representation. </title> <journal> Artificial Intelligence, </journal> <volume> 47, </volume> <pages> 139-159. </pages>
Reference-contexts: Perhaps such opposition is simply the way important revisions of theory make themselves known. Yet some of the arguments seem to strike at the basic idea of internally stored symbolic representations as models of the world <ref> (e.g. Brooks, 1991) </ref>, or even at the very foundations of empirical science (e.g. Lave, 1988). For many of us, this goes too far. Recent, more moderate interpretations take these ideas as necessary updates to a basically correct symbolic representational paradigm (Vera & Simon, 1993).
Reference: <author> Chomsky, N. </author> <title> (1959) Review of B.F. Skinner, Verbal Behaviour. </title> <booktitle> In Language, </booktitle> <volume> 35, </volume> <pages> 26-58. </pages>
Reference: <author> Clancey, W. </author> <title> (1993) Situated action: A neuropsychological interpretation response to Vera and Simon, </title> <journal> Cognitive Science, </journal> <volume> 17, </volume> <pages> 87-116. </pages>
Reference: <author> Grimes, J. </author> <title> (1972) The thread of discourse. </title> <type> NSF Technical Report #1, </type> <institution> Cornell University, </institution> <address> Ithaca, New York. </address>
Reference-contexts: a working memory limited to a small number of conceptual structures, such as the human STMs 7-2 (Miller, 1957), can suffer from an explosion of uncontrolled inference. (A figure of this magnitude has, not surprisingly, been recommended as a maximum number of case attachments for conceptual representations of human languages <ref> (Grimes, 1972) </ref>). The price of maintaining only a limited amount of knowledge in working memory is the need to ensure that important information (i.e. that pertinent to survival or to the task at hand) is kept at the expense of the unimportant information.
Reference: <author> Hayes, P.J., Ford, K.M. and Agnew, N. </author> <title> (1994) On babies and bathwater: a cautionary tale. </title> <journal> AI Magazine, </journal> <volume> 15, 4, </volume> <pages> 15-26. </pages>
Reference: <author> Hollnagle, E., Mancini, G. & Woods, D. </author> <booktitle> (1989) Cognitive Engineering in Dynamic Worlds. </booktitle> <publisher> Academic Press. </publisher>
Reference-contexts: Reasoning, in this view, is the process of building up, elaborating and manipulating these structures according to rules which change them in truth-preserving ways. Ultimately, the conceptual structures are to be interpreted by programs that convert them into useful actions. Practical knowledge-based systems have been built on this foundation <ref> (Hollnagle et. al., 1989) </ref>, but our aim is to construct better ones by situating the knowledge in them and by restricting processing on the knowledge within arbitrary limits. The key to successful conceptual KBS design is a good representation theory.
Reference: <author> Hebb, </author> <title> D.O. (1949) The Organisation of Behaviour: A Neuropsychological Theory. </title> <address> New York, </address> <publisher> Wiley. </publisher>
Reference: <author> Jackson, P. </author> <title> (1988) Introduction to Expert Systems. </title> <address> Reading, Mass., </address> <publisher> Addison-Wesley Publishing Company. </publisher>
Reference-contexts: To be practical these mechanisms must not depend on complete knowledge-level processing, but rather on relatively cheaply computed features of the representations such as "interestingness" (Lenat & Brown, 1984), information content (Quinlan,1993) or conflict resolution criteria, such as recency and specificity, that are already used in production systems like OPS5 <ref> (Jackson, 1988) </ref>. Yet even without such attentional selection mechanisms, an arbitrarily bounded conceptual knowledge system can function well in tasks that depend on reaction to simple but dynamic environments, which offer frequent cues to update working memory and require little lookup of past conceptual structures.
Reference: <author> Kahneman, D. </author> <title> (1973) Attention and Effort. </title> <address> Englewood Cliffs, New Jersey, </address> <publisher> Prentice Hall. </publisher>
Reference: <author> Lave, J. </author> <title> (1988) Cognition in Practice: Mind, Mathematics, Culture in Everyday Life. </title> <address> New York: </address> <publisher> Cambridge University Press. </publisher>
Reference-contexts: Perhaps such opposition is simply the way important revisions of theory make themselves known. Yet some of the arguments seem to strike at the basic idea of internally stored symbolic representations as models of the world (e.g. Brooks, 1991), or even at the very foundations of empirical science <ref> (e.g. Lave, 1988) </ref>. For many of us, this goes too far. Recent, more moderate interpretations take these ideas as necessary updates to a basically correct symbolic representational paradigm (Vera & Simon, 1993).
Reference: <author> Lenat, D. & Brown, J.S. </author> <title> (1984) Why AM and Eurisko appear to work. </title> <journal> Artificial Intelligence Journal, </journal> <volume> 23, </volume> <pages> 269-294. </pages>
Reference-contexts: To be practical these mechanisms must not depend on complete knowledge-level processing, but rather on relatively cheaply computed features of the representations such as "interestingness" <ref> (Lenat & Brown, 1984) </ref>, information content (Quinlan,1993) or conflict resolution criteria, such as recency and specificity, that are already used in production systems like OPS5 (Jackson, 1988).
Reference: <author> Maes, P. </author> <title> (1994) Agents that reduce work and information overload. </title> <journal> Comm. of the ACM, </journal> <volume> 37, 7, </volume> <pages> 31-40. </pages>
Reference-contexts: The flexibility and range of possible behaviour for the BEELINE system is broad and difficult to summarise quantitatively (performance measures of the agent's navigational efficiency are only part of the answer). KBS architectures of this kind would be potentially valuable in remote-programming model agents <ref> (Maes, 1994) </ref>. These agents will roam the communication networks of the future, autonomously carrying out the wishes of their users. To be useable, it is likely that such systems will need to be highly responsive to natural language instructions.
Reference: <author> Mann G.A. </author> <title> (1993) Conceptual graphs for natural language understanding. </title> <type> Technical Report #9311, </type> <institution> School of Computer Science & Engineering, University of New South Wales. </institution>
Reference-contexts: It has been argued elsewhere <ref> (Mann, 1993) </ref> that conceptual graph theory is a good choice for knowledge processing in general and natural language understanding in particular. A conceptual graph is an abstraction consisting of two kinds of nodes - concepts and relations - linked together into a directed semantic network. <p> Other constraints on inference need to be applied to ensure this. A number of higher-order functions (functions based on the formation rules) are also commonly used in conceptual graph engines. Only two of these, projection and maximal-join will be mentioned here <ref> (for more detail see Mann, 1993) </ref>. The projection operator is a function of two graphs: p (f,q).
Reference: <author> Mann G.A. </author> <title> (1994a) Results of a conceptual parse can inform a navigating rational agent, </title> <booktitle> Proc. AAAI Spring Symposium, </booktitle> <address> Stanford University, Palo Alto California. </address>
Reference: <author> Mann G.A. </author> <title> (1994b) A rational, goalseeking agent using conceptual graphs. In: Conceptual Structures: Current Practices, </title> <booktitle> Lecture Notes in AI 835, Edited by Tepfenhart, </booktitle> <editor> W. M., Dick, J. P. and Sowa, J. F. </editor> <publisher> Berlin, Springer-Verlag. </publisher>
Reference-contexts: Finally, appropriate acts, in the form of links to procedures, can be implied by concepts. For a given goal, acts are chosen by their likely outcome, and viability <ref> (Mann, 1994b) </ref>. Use of the four-pole framework helps clarify what extensions are needed and how a given attachment will participate in complex processing.
Reference: <author> Miller, </author> <title> G.A. The magical number seven, plus or minus two: some limits on our capacity for processing information. </title> <journal> Psychological Review , 63, </journal> <pages> 81-97. </pages>
Reference: <author> Newell, A. & Simon, H. </author> <title> (1972) Human Problem Solving. </title> <address> Englewood Cliffs, New Jersey, </address> <publisher> Prentice Hall. </publisher>
Reference: <author> Newell, A. </author> <title> (1981) The Knowledge Level. </title> <institution> Technical Report CSU-CS-81-131 Carnegie Mellon University. </institution>
Reference-contexts: Whatever their source, goals are fundamental knowledge processes. They need not be structurally distinct from other knowledge assertions, but are stored separately and used differently <ref> (Newell, 1981) </ref>. Their presence within a motive module marks the states of affairs they describe as desirable.
Reference: <author> Newell, A. </author> <title> (1990) Unified Theories of Cognition. </title> <address> Cambridge, Mass. </address> <publisher> Harvard University Press. </publisher>
Reference: <author> Ogasawara, G.H & Russell, S.J. </author> <title> (1993) Planning using multiple execution architectures Proc. </title> <booktitle> 13th International Joint Conference on Artificial Intelligence, </booktitle> <address> Chambery, France., </address> <month> 1, </month> <pages> 338-344. </pages>
Reference-contexts: In effect, the four architectures can themselves be treated as actions, and their choices weighted according to their suitability in this instance. These ideas were implemented in a practical agent, MEA-RALPH <ref> (Ogasawara & Russell, 1993) </ref> which was used to model the control of an automated underwater vehicle. Russels ideas are consistent with the notion that the constraints on rationality include computational and memory limits as well as time limits.
Reference: <author> Quinlan J.R. </author> <title> (1993) C4.5 Programs for Machine Learning. </title> <address> San Meteo, Calif., </address> <publisher> Morgan Kaufmann, </publisher> <pages> 20-26. </pages>
Reference-contexts: To be practical these mechanisms must not depend on complete knowledge-level processing, but rather on relatively cheaply computed features of the representations such as "interestingness" (Lenat & Brown, 1984), information content <ref> (Quinlan,1993) </ref> or conflict resolution criteria, such as recency and specificity, that are already used in production systems like OPS5 (Jackson, 1988).
Reference: <author> Rich, E. & Myers, W. </author> <title> (1990) Expert systems and neural networks can work together. </title> <journal> IEEE Expert, </journal> <month> Oct, </month> <pages> 5-7. </pages>
Reference-contexts: Yet procedural state-machines are scarcely a practical basis for KBS software (the maintenance problem alone rules this out) and while some successes in adapting neural network mechanisms to KBS design have been reported <ref> (see Rich & Myers, 1990) </ref>, neither of these alternatives are attractive to the knowledge engineer who wants to incorporate new improvements rather than revolutionise paradigms.
Reference: <author> Russell, S.J. </author> <title> (1991) An architecture for bounded rationality. </title> <journal> SIGART Bulletin, </journal> <volume> 2, 4, </volume> <pages> 146-150. </pages>
Reference: <author> Sarcedoti, E. </author> <title> (1977) A Structure for Plans and Behaviour. </title> <publisher> Elsevier/North Holland. </publisher>
Reference: <author> Schank, </author> <title> R.C. </title> <booktitle> (1975) Conceptual information processing. </booktitle> <address> Amsterdam: </address> <publisher> North Holland. </publisher>
Reference-contexts: Some of the most mature have developed semantic network theory into specific languages that allow the creation, manipulation and disposal of structures of nodes and arcs standing for concept types and the relationships between them, respectively (conceptual dependencies <ref> (Schank, 1975) </ref>; KL-ONE (Brachman, 1985); conceptual graphs (Sowa,1984)). It has been argued elsewhere (Mann, 1993) that conceptual graph theory is a good choice for knowledge processing in general and natural language understanding in particular.
Reference: <author> Simon H.A. </author> <title> (1976) Administrative Behaviour. </title> <address> New York, </address> <publisher> Macmillan. </publisher>
Reference: <author> Simon H.A. </author> <booktitle> (1981) The Sciences of the Artificial. </booktitle> <address> Cambridge, Mass., </address> <publisher> MIT Press. </publisher>
Reference: <author> Sowa J.F. </author> <title> (1984) Conceptual Structures. </title> <address> Menlo Park, Calif., </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: Some of the most mature have developed semantic network theory into specific languages that allow the creation, manipulation and disposal of structures of nodes and arcs standing for concept types and the relationships between them, respectively (conceptual dependencies (Schank, 1975); KL-ONE (Brachman, 1985); conceptual graphs <ref> (Sowa,1984) </ref>). It has been argued elsewhere (Mann, 1993) that conceptual graph theory is a good choice for knowledge processing in general and natural language understanding in particular.
Reference: <author> Sowa J.F. </author> <title> (1988) Using a lexicon of canonical graphs in a sematic interpreter. In: Relational models of the lexicon. Edited by Evens, </title> <address> M.W. Cambridge, Mass., </address> <publisher> Cambridge University Press, </publisher> <pages> 113-137. </pages>
Reference: <author> Sowa J.F. </author> <title> and Way, E.C. (1986) Implementing a semantic interpreter using conceptual graphs. </title> <journal> IBM Journal of Research & Development, </journal> <volume> 30, 1, </volume> <pages> 57-96. </pages>
Reference: <author> Sowa J.F. </author> <title> Conceptual graphs summary. In: Conceptual Structures: Current Research and Practice. Edited by Nagle, </title> <editor> T.E. et. al. </editor> <address> Chichester, </address> <publisher> Ellis Horwood, </publisher> <pages> 3-51. </pages>
Reference: <author> Steels L. </author> <year> (1991), </year> <title> Emergent frame recognition and its use in artificial creatures. </title> <booktitle> Proceedings of the Twelfth International Joint Conference on Artificial Intelligence 2, </booktitle> <pages> 1219-1224. </pages>
Reference-contexts: Certainly physical robots can be made to genuinely recognise simple objects <ref> (Steels, 1991) </ref>. Conceptual Parser. The parser uses a lexicon of about 25,000 words, only a small fraction of which are needed in this domain.
Reference: <author> Suchman, L.A. </author> <title> (1987) Plans and Situated Actions. </title> <address> Cambridge, Mass., </address> <publisher> Cambridge University Press. </publisher>
Reference: <author> Sussman, G.J. </author> <title> A Computer Model of Skill Acquisition. </title> <address> New York, </address> <publisher> American Elsevier. </publisher>
Reference: <author> Vera, A.H. & Simon, H.A. </author> <title> (1993) Situated action: a symbolic interpretation. </title> <journal> Cognitive Science, </journal> <volume> 17, </volume> <pages> 7-48. </pages>
Reference-contexts: Brooks, 1991), or even at the very foundations of empirical science (e.g. Lave, 1988). For many of us, this goes too far. Recent, more moderate interpretations take these ideas as necessary updates to a basically correct symbolic representational paradigm <ref> (Vera & Simon, 1993) </ref>. Throwing out the entire representational paradigm is an overeaction to the admitted failure of existing systems of stored knowledge to adequately reflect important features and track important changes in outside world.
References-found: 41

