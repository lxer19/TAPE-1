URL: ftp://ftp.cs.brown.edu/pub/techreports/93/cs93-14.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-93-14.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [AHMP87] <author> H. Alt, T. Hagerup, K. Mehlhorn, </author> <title> and F.P. Preparata. Deterministic simulation of idealized parallel computers on more realistic ones. </title> <journal> SIAM J. on Computing, </journal> <volume> 16(5) </volume> <pages> 808-835, </pages> <year> 1987. </year>
Reference-contexts: An early survey by [Kuc77] quotes fourteen works that deal with some special cases. More recently, it has become the main focus of the large body of work concerning the simulation of the PRAM on distributed memory machines <ref> [MV84, UW87, AHMP87, KU88, LPP88, Her89, LPP90, Her90, Ran91, Mey92, KLM92] </ref>. <p> They do not provide an explicit construction for G but show that a random graph exhibits the desired properties, with high probability. Several authors followed the ideas in [UW87] improving the time complexity and using bounded degree networks instead of the complete network of the MPC <ref> [AHMP87, HB88, Her89, LPP90, Her90, AS90] </ref>.
Reference: [AS90] <author> Y. Aumann and A. Schuster. </author> <title> Improved memory utilization in deterministic PRAM simulations. </title> <type> Manuscript, </type> <year> 1990. </year>
Reference-contexts: They do not provide an explicit construction for G but show that a random graph exhibits the desired properties, with high probability. Several authors followed the ideas in [UW87] improving the time complexity and using bounded degree networks instead of the complete network of the MPC <ref> [AHMP87, HB88, Her89, LPP90, Her90, AS90] </ref>.
Reference: [Ber68] <author> E.R. Berlekamp. </author> <title> Algebraic Coding Theory. </title> <publisher> McGraw-Hill, </publisher> <year> 1968. </year>
Reference-contexts: The operations in F q n can be implemented using feedback shift registers, each operation taking O (n) = O (log N ) time and space equivalent to the storage of O (1) field elements (see <ref> [Ber68, Ch. 2] </ref> for details). We used p 0 ; . . . ; p q n1 1 to denote the polynomials of P fl . Each polynomial can be uniquely associated with its (n 1) coefficients.
Reference: [Gor68] <author> D. Gorenstein. </author> <title> Finite Groups. </title> <publisher> Harper and Row, </publisher> <address> New York NY, </address> <year> 1968. </year>
Reference-contexts: The Projective Linear Group of degree 2 over F k (P GL 2 (k)) is the group of 2 fi 2 nonsingular matrices with entries in F k , modulo its center, the group of scalar matrices <ref> [Gor68] </ref>. For convenience, a matrix of P GL 2 (k) will be written either as fl 1 or ff fi ! , with ff; fi; fl 2 F k , and the equality between matrices will be modulo scalar multiples. Let q be a power of 2 and n 3. <p> The following properties derive from well known facts in group theory (see <ref> [Gor68] </ref>). Fact 1 We have 1. jV j = (q+1)q (q1) q1 3. The degree of each node in V is q + 1 4.
Reference: [HB88] <author> K.T. Herley and G. Bilardi. </author> <title> Deterministic simulations of PRAMs on bounded degree networks. </title> <booktitle> Proc. of the 26th Annual Allerton Conference on Communication, Control and Computation, </booktitle> <pages> pages 1084-1093, </pages> <year> 1988. </year>
Reference-contexts: They do not provide an explicit construction for G but show that a random graph exhibits the desired properties, with high probability. Several authors followed the ideas in [UW87] improving the time complexity and using bounded degree networks instead of the complete network of the MPC <ref> [AHMP87, HB88, Her89, LPP90, Her90, AS90] </ref>.
Reference: [Her89] <author> K.T. Herley. </author> <title> Efficient simulations of small shared memories on bounded degree networks. </title> <booktitle> Proc. of the 30th IEEE Symp. on Foundations of Comp. Sc., </booktitle> <pages> pages 390-395, </pages> <year> 1989. </year>
Reference-contexts: An early survey by [Kuc77] quotes fourteen works that deal with some special cases. More recently, it has become the main focus of the large body of work concerning the simulation of the PRAM on distributed memory machines <ref> [MV84, UW87, AHMP87, KU88, LPP88, Her89, LPP90, Her90, Ran91, Mey92, KLM92] </ref>. <p> They do not provide an explicit construction for G but show that a random graph exhibits the desired properties, with high probability. Several authors followed the ideas in [UW87] improving the time complexity and using bounded degree networks instead of the complete network of the MPC <ref> [AHMP87, HB88, Her89, LPP90, Her90, AS90] </ref>.
Reference: [Her90] <author> K.T. Herley. </author> <title> Space-efficient representations of shared data for parallel computers. </title> <booktitle> Proc. of the 2nd ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 407-416, </pages> <year> 1990. </year>
Reference-contexts: An early survey by [Kuc77] quotes fourteen works that deal with some special cases. More recently, it has become the main focus of the large body of work concerning the simulation of the PRAM on distributed memory machines <ref> [MV84, UW87, AHMP87, KU88, LPP88, Her89, LPP90, Her90, Ran91, Mey92, KLM92] </ref>. <p> They do not provide an explicit construction for G but show that a random graph exhibits the desired properties, with high probability. Several authors followed the ideas in [UW87] improving the time complexity and using bounded degree networks instead of the complete network of the MPC <ref> [AHMP87, HB88, Her89, LPP90, Her90, AS90] </ref>. <p> How can a processor determine, for any variable, the modules storing its copies and the physical address of each copy within its module? The hypothesis of a complete memory map stored internally in each processor appears eminently impractical and even the approach of Herley <ref> [Her90] </ref>, where the memory map is distributed among the processors with only polylogarithmic storage per processor, has a very involved implementation. <p> In both schemes the implementation is simple and each processor can determine the physical address of any copy in O (log N ) time using O (1) storage. In this paper, we deal with a smaller number of variables; this is an interesting case, as <ref> [Her90] </ref> already pointed out, since, in a typical parallel application, the size of the data memory required is not enormously larger than the number of processors. Our main result is summarized in the following theorem.
Reference: [KLM92] <author> R. Karp, M. Luby, and F. Meyer auf der Heide. </author> <title> Efficient PRAM simulation on distributed machines. </title> <booktitle> Proc. of the 24th ACM Symp. on Theory of Comp., </booktitle> <pages> pages 318-326, </pages> <year> 1992. </year> <month> 26 </month>
Reference-contexts: An early survey by [Kuc77] quotes fourteen works that deal with some special cases. More recently, it has become the main focus of the large body of work concerning the simulation of the PRAM on distributed memory machines <ref> [MV84, UW87, AHMP87, KU88, LPP88, Her89, LPP90, Her90, Ran91, Mey92, KLM92] </ref>. <p> For the latter, a number of randomized schemes have been successfully developed based on the use of universal classes of hash functions to distribute the variables among the modules <ref> [MV84, KU88, LPP88, Ran91, Mey92, KLM92] </ref>.
Reference: [KU88] <author> A.R. Karlin and E. Upfal. </author> <title> Parallel hashing: An efficient implementation of shared memory. </title> <journal> J. ACM, </journal> <volume> 35(4) </volume> <pages> 876-892, </pages> <year> 1988. </year>
Reference-contexts: An early survey by [Kuc77] quotes fourteen works that deal with some special cases. More recently, it has become the main focus of the large body of work concerning the simulation of the PRAM on distributed memory machines <ref> [MV84, UW87, AHMP87, KU88, LPP88, Her89, LPP90, Her90, Ran91, Mey92, KLM92] </ref>. <p> For the latter, a number of randomized schemes have been successfully developed based on the use of universal classes of hash functions to distribute the variables among the modules <ref> [MV84, KU88, LPP88, Ran91, Mey92, KLM92] </ref>.
Reference: [Kuc77] <author> D.J. Kuck. </author> <title> A survey of parallel machine organization and programming. </title> <journal> ACM Computing Surveys, </journal> <volume> 21 </volume> <pages> 339-374, </pages> <year> 1977. </year>
Reference-contexts: This problem, originally referred to as granularity problem, naturally arises in the design and implementation of parallel systems (such as PRAMs and parallel databases) and has received considerable attention in the literature. An early survey by <ref> [Kuc77] </ref> quotes fourteen works that deal with some special cases. More recently, it has become the main focus of the large body of work concerning the simulation of the PRAM on distributed memory machines [MV84, UW87, AHMP87, KU88, LPP88, Her89, LPP90, Her90, Ran91, Mey92, KLM92].
Reference: [LPP88] <author> F. Luccio, A. Pietracaprina, and G. Pucci. </author> <title> A probabilistic simulation of PRAMs in VLSI. </title> <journal> Information Processing Lett., </journal> <volume> 28(3) </volume> <pages> 141-147, </pages> <year> 1988. </year>
Reference-contexts: An early survey by [Kuc77] quotes fourteen works that deal with some special cases. More recently, it has become the main focus of the large body of work concerning the simulation of the PRAM on distributed memory machines <ref> [MV84, UW87, AHMP87, KU88, LPP88, Her89, LPP90, Her90, Ran91, Mey92, KLM92] </ref>. <p> For the latter, a number of randomized schemes have been successfully developed based on the use of universal classes of hash functions to distribute the variables among the modules <ref> [MV84, KU88, LPP88, Ran91, Mey92, KLM92] </ref>.
Reference: [LPP90] <author> F. Luccio, A. Pietracaprina, and G. Pucci. </author> <title> A new scheme for the deterministic simulation of PRAMs in VLSI. </title> <journal> Algorithmica, </journal> <volume> 5 </volume> <pages> 529-544, </pages> <year> 1990. </year>
Reference-contexts: An early survey by [Kuc77] quotes fourteen works that deal with some special cases. More recently, it has become the main focus of the large body of work concerning the simulation of the PRAM on distributed memory machines <ref> [MV84, UW87, AHMP87, KU88, LPP88, Her89, LPP90, Her90, Ran91, Mey92, KLM92] </ref>. <p> They do not provide an explicit construction for G but show that a random graph exhibits the desired properties, with high probability. Several authors followed the ideas in [UW87] improving the time complexity and using bounded degree networks instead of the complete network of the MPC <ref> [AHMP87, HB88, Her89, LPP90, Her90, AS90] </ref>.
Reference: [Mey92] <editor> F. Meyer auf der Heide. </editor> <title> Hashing strategies for simulating shared memory on distributed memory machines. </title> <booktitle> Proc. 1st Heinz Nixdorf Symp. on Parallel Architectures and their Efficient Use, </booktitle> <year> 1992. </year> <note> to appear in LNCS. </note>
Reference-contexts: An early survey by [Kuc77] quotes fourteen works that deal with some special cases. More recently, it has become the main focus of the large body of work concerning the simulation of the PRAM on distributed memory machines <ref> [MV84, UW87, AHMP87, KU88, LPP88, Her89, LPP90, Her90, Ran91, Mey92, KLM92] </ref>. <p> For the latter, a number of randomized schemes have been successfully developed based on the use of universal classes of hash functions to distribute the variables among the modules <ref> [MV84, KU88, LPP88, Ran91, Mey92, KLM92] </ref>. <p> P GL 2 (2) consists of six matrices: H 0 (1) = 1 0 ! 1 0 H 0 (2) = 1 1 ! 0 1 H 0 (3) = 0 1 ! 1 1 1 Note that when q = 2 there are three copies per variable, which, as <ref> [Mey92] </ref> pointed out, appears to be one of the interesting cases for practical PRAM simulations. 19 Since jP GL 2 (2 n )j = (2 2n 1)2 n , we have M = jP GL 2 (2 n )=H 0 j = 2 n1 2 2n 1 The main idea that
Reference: [Mor91] <author> M. Morgenstern. </author> <title> Explicit construction of natural bounded concentrators. </title> <booktitle> Proc. of the 32th IEEE Symp. on Foundations of Comp. Sc., </booktitle> <pages> pages 392-397, </pages> <year> 1991. </year>
Reference-contexts: Indeed, the scheme presented here and that of [PP93] are the first constructive approaches known to achieve sublinear, and eminently practical, worst-case access time with constant redundancy. Inspired by the construction presented by <ref> [Mor91] </ref> for bounded concentrators, we associate the sets V and U with two quotients of P GL 2 (q n ) (the group of non-singular 2 fi 2 matrices over the field F q n , modulo its center), and define the edges as intersections of cosets. <p> This is accomplished without resort to the (here ineffective) standard second-eigenvalue bound, and solves a major problem left open in <ref> [Mor91] </ref>. This result allows us to achieve the time complexity claimed in Theorem 1 using an access protocol similar to [UW87]. The rest of the paper describes the memory organization scheme. <p> In particular, given a set of variables S V we want to bound from below the size of the set of modules (S) containing the copies of the variables in S. This problem was left open in <ref> [Mor91] </ref>, where the node sets V and U were two stages of a multistage diagram, each stage consisting of a quotient of P GL 2 (q n ) with respect to a different subgroup. Theorem 4 Let S V .
Reference: [MV84] <author> K. Mehlhorn and U. Vishkin. </author> <title> Randomized and deterministic simulations of PRAMs by parallel machines with restricted granularity of parallel memories. </title> <journal> Acta Informatica, </journal> <volume> 9(1) </volume> <pages> 29-59, </pages> <year> 1984. </year>
Reference-contexts: An early survey by [Kuc77] quotes fourteen works that deal with some special cases. More recently, it has become the main focus of the large body of work concerning the simulation of the PRAM on distributed memory machines <ref> [MV84, UW87, AHMP87, KU88, LPP88, Her89, LPP90, Her90, Ran91, Mey92, KLM92] </ref>. <p> It is convenient to study this problem on a synchronous system where processors and memories are ideally thought of as being connected by a complete bipartite graph and each memory module is able to fulfill at most one access request (read/write) per time unit (Module Parallel Computer (MPC)) <ref> [MV84] </ref>. Thus, the time needed to access a set of variables is proportional to the maximum number of access requests that a single module must fulfill. <p> For the latter, a number of randomized schemes have been successfully developed based on the use of universal classes of hash functions to distribute the variables among the modules <ref> [MV84, KU88, LPP88, Ran91, Mey92, KLM92] </ref>. <p> The pioneering work of Mehlhorn and Vishkin <ref> [MV84] </ref> introduced the idea of representing each variable by several copies so that a read operation needs access only one (the most convenient) copy. This is necessary to avoid the worst case when all the requests are addressed to the same module.
Reference: [PP93] <author> A. Pietracaprina and F.P. Preparata. </author> <title> An O( p n)-worst-case-time solution to the granularity problem. </title> <booktitle> Proc. of the 10th Symp. on Theoretical Aspects of Comp. Sc., </booktitle> <volume> LNCS 665 </volume> <pages> 110-119, </pages> <year> 1993. </year>
Reference-contexts: As <ref> [PP93] </ref> have recently pointed out, the only known technique, based on the second eigenvalue, cannot be applied when the sizes of the two sets V and U differ by more than a constant factor, which is the case for memory organizations. (2) The representation of the memory map poses substantial implementation <p> Recently, we presented explicit deterministic memory organization schemes for M 2 fi (N 2 ) and M 2 fi (N 3 ) variables where any set of N variables can be accessed in O ( p N) and O (N 2=3 ) time on the MPC, respectively, using constant redundancy <ref> [PP93] </ref>. In both schemes the implementation is simple and each processor can determine the physical address of any copy in O (log N ) time using O (1) storage. <p> The paramount contribution of this paper is the construction and implementation of the graph G and the analysis of its expansion capabilities. Indeed, the scheme presented here and that of <ref> [PP93] </ref> are the first constructive approaches known to achieve sublinear, and eminently practical, worst-case access time with constant redundancy. <p> Suppose each processor issues a read/write request for a distinct variable. Recall that, because of the majority rule, for each variable it is sufficient to access only q=2 + 1 copies. The access protocol we propose is similar to the ones of <ref> [UW87, PP93] </ref>. The processors are subdivided into N=(q + 1) clusters, with q + 1 processors per cluster. Let P (i; j) denote the jth processor in cluster i, for 1 i N=(q + 1) and 1 j q + 1.
Reference: [Ran91] <author> A.G. Ranade. </author> <title> How to emulate shared memory. </title> <journal> J. on Computers and System Sci., </journal> <volume> 42 </volume> <pages> 307-326, </pages> <year> 1991. </year>
Reference-contexts: An early survey by [Kuc77] quotes fourteen works that deal with some special cases. More recently, it has become the main focus of the large body of work concerning the simulation of the PRAM on distributed memory machines <ref> [MV84, UW87, AHMP87, KU88, LPP88, Her89, LPP90, Her90, Ran91, Mey92, KLM92] </ref>. <p> For the latter, a number of randomized schemes have been successfully developed based on the use of universal classes of hash functions to distribute the variables among the modules <ref> [MV84, KU88, LPP88, Ran91, Mey92, KLM92] </ref>.
Reference: [Tho79] <author> R.H. Thomas. </author> <title> A majority consensus approach to concurrency control for multiple copy databases. </title> <journal> ACM Transactions on Databases Systems, </journal> <volume> 4(2) </volume> <pages> 180-209, </pages> <year> 1979. </year>
Reference-contexts: Later, Upfal and Widgerson [UW87] proposed a more balanced use of the multiple copies exploiting the majority concept previously adopted for databases <ref> [Tho79] </ref>. Each variable is represented by 2c 1 copies. Each copy contains the value of the variable and a time-stamp indicating the last time that particular copy has been accessed.
Reference: [UW87] <author> E. Upfal and A. Widgerson. </author> <title> How to share memory in a distributed system. </title> <journal> J. ACM, </journal> <volume> 34(1) </volume> <pages> 116-127, </pages> <year> 1987. </year>
Reference-contexts: An early survey by [Kuc77] quotes fourteen works that deal with some special cases. More recently, it has become the main focus of the large body of work concerning the simulation of the PRAM on distributed memory machines <ref> [MV84, UW87, AHMP87, KU88, LPP88, Her89, LPP90, Her90, Ran91, Mey92, KLM92] </ref>. <p> However, this use of the copies penalizes the execution of write operations where all the copies of the variables must be accessed, so requiring O (cN ) time in the worst case. Later, Upfal and Widgerson <ref> [UW87] </ref> proposed a more balanced use of the multiple copies exploiting the majority concept previously adopted for databases [Tho79]. Each variable is represented by 2c 1 copies. Each copy contains the value of the variable and a time-stamp indicating the last time that particular copy has been accessed. <p> For M polynomial in N and c 2 fi (log N ), <ref> [UW87] </ref> show that there exist graphs G with suitable expansion properties so that N variables can be accessed in O (log N (log log N ) 2 ) worst-case time on the MPC. <p> They do not provide an explicit construction for G but show that a random graph exhibits the desired properties, with high probability. Several authors followed the ideas in <ref> [UW87] </ref> improving the time complexity and using bounded degree networks instead of the complete network of the MPC [AHMP87, HB88, Her89, LPP90, Her90, AS90]. <p> The less attractive time complexity, however, is mitigated by the fact that with constant redundancy (desirable from a practical standpoint) a polylogarithmic complexity cannot be obtained, at least for M 2 (N 1+* ). In fact, <ref> [UW87] </ref> show that using a fixed number r of copies per variables on average, the time complexity of any memory organization scheme is at least ((M=N ) 1=2r ). <p> Our memory access mechanism incorporates most of the ideas and notations pioneered by <ref> [UW87] </ref> and adopted since by several authors. Each variable is represented by q + 1 copies (i.e., q + 1 = 2c 1), where q is a power of 2, and a read/write operation needs access only q=2 + 1 copies. <p> This is accomplished without resort to the (here ineffective) standard second-eigenvalue bound, and solves a major problem left open in [Mor91]. This result allows us to achieve the time complexity claimed in Theorem 1 using an access protocol similar to <ref> [UW87] </ref>. The rest of the paper describes the memory organization scheme. In Section 2 we define the graph G, study its structure and give a tight bound to its expansion capability. <p> Suppose each processor issues a read/write request for a distinct variable. Recall that, because of the majority rule, for each variable it is sufficient to access only q=2 + 1 copies. The access protocol we propose is similar to the ones of <ref> [UW87, PP93] </ref>. The processors are subdivided into N=(q + 1) clusters, with q + 1 processors per cluster. Let P (i; j) denote the jth processor in cluster i, for 1 i N=(q + 1) and 1 j q + 1. <p> The following lemma is similar to Lemma 3.3 of <ref> [UW87] </ref>. Lemma 5 For any k 0, R k+1 R k 1 c q 1=3 with 0:19 c 0:25. Proof: Let L k be the number of live variables remaining after the kth iteration. Note that L k R k =(q + 1). <p> Before closing this section, we want to give the reader an idea on how far from optimal the performance of our scheme is. The following theorem, which is patterned after <ref> [UW87, Theorem 4.1] </ref> with appropriate modifications, provides a lower bound to the performance of any memory organization scheme.
References-found: 19

