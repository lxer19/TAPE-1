URL: http://www.cs.wisc.edu/~fischer/course/html/submissions/127.ps.gz
Refering-URL: http://www.cs.wisc.edu/~fischer/course/html/submissions/
Root-URL: http://www.cs.wisc.edu
Email: wender@top.cis.syr.edu  
Phone: 13090-2810. Phone: 315-622-2145  
Title: Simplicity and Performance in a Parallel Programming System optimizing compiler are presented, and in particular,
Author: Elaine Wenderholm 
Note: Through the use of an example the language features of Em are presented. Then, aspects of the  The topics in this extended abstract address:  
Date: October 19, 1995  
Address: New York  214 Riverdale Rd, Liverpool NY  
Affiliation: Northeast Parallel Architectures Center and Sch. Computer Info. Science Syracuse University,  USMail: Syracuse University,  
Abstract: Em is a high-level programming system which puts parallelism within the reach of scientists who are not sophisticated programmers. Em both restricts and simplifies the programming interface, and thereby eases both the conceptual task of the programmer and the analytical task of the compiler, without sacrificing performance. These restrictions are used to achieve a high degree of optimization. Figures which assist in understanding the features of the Em system are included after the references. Appendix A contains a complete proof of the data partitioning algorithm, along with a discussion of termination. Appendix A is not required for an understanding of the abstract, but is provided to substantiate the text. 
Abstract-found: 1
Intro-found: 1
Reference: [Bec94] <author> Micah Beck. </author> <type> personal communication. </type> <institution> Computer Science Department, University of Tennessee at Knoxville, </institution> <year> 1994. </year>
Reference-contexts: The risk of fire in the dry marshes is high. To develop policy for the rationing of water to farmers, the effect of such policies on the duck populations and on the risk of fire requires modeling <ref> [Bec94] </ref>. The simulated ecosystem is described easily using Em. Each cell is defined by five state variables: (1) the fixed geography of the region; (2) the concentration of water; (3) the amount of water pumping; (4) habitation by ducks; and, (5) the risk of fire.
Reference: [Bra93] <author> Thomas Brandes. </author> <title> Compiling data parallel programs to message passing programs for massively parallel MIMD systems. In Programming Models for Massively Parallel Computers. </title> <publisher> IEEE Computer Science Press, </publisher> <address> Berlin, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: Em's compiler analysis obviates the need for this classification, and does not require hand-written message-passing code. Languages such as BLAZE [MVR85] for shared memory machines, and Kali [MVR90], Vienna Fortran [CMZ92], DINO [RSW90], Booster [PvGS90], Fortran D [FHK + 91], Fortran 90D [WF91], Adaptor <ref> [Bra93] </ref>, SUPERB [ZBG88] for distributed memory machines, permit the user to specify the distribution and alignment of data. Adaptor has a back end which maps to several communication packages. SUPERB maps to SIMD and MIMD machines. Crystal [Che86] and ASPAR [IFKF90] perform automatic data distribution based on symbolic pattern matching.
Reference: [CFR + 92] <author> Alok Choudhary, Geoffrey Fox, Sanjay Ranka, Seema Hiranadani, Ken Kennedy, Charles Koelbel, and Chau-Wen Tseng. </author> <title> Compiling Fortran 77D and 90D for MIMD distributed-memory machines. </title> <type> Technical Report SCCS-251 (CRPC Report CRPC-TR92203), </type> <institution> Syra-cuse Center for Computational Science, Syracuse University, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: The performance results, shown in Figures 6 and 7, demonstrate that under these conditions, the algorithm selects the correct processor topology. Related Work Several parallel programming languages have been proposed to support general purpose parallel programming. OCCAM [Cok91] is designed for the transputer. Languages such as Fortran <ref> [Thi89, CFR + 92, CMZ92] </ref> and C [RS87], have been extended, include new compiler directives, and have library routines to manage processes and communication. Typically these languages are difficult to analyze. Pointer code in C makes analysis difficult. <p> Most current systems share resource allocation between the system and the programmer: the programmer specifies the data placement and the system automatically inserts the communication implied by the partition <ref> [ZBG88, CFR + 92] </ref>. Given that the scientific community prefers using standard imperative languages, the compiler must perform program analysis in order to transform the sequential program into equivalent concurrent code for execution on the parallel machine.
Reference: [Che86] <author> Marina C. Chen. </author> <title> A parallel language and its compilation to multiprocessor machines for VLSI. </title> <booktitle> In Conference Record of the 13th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 131-139, </pages> <address> St. Petersburg Beach, Florida, </address> <month> January 13-15, </month> <year> 1986. </year>
Reference-contexts: Adaptor has a back end which maps to several communication packages. SUPERB maps to SIMD and MIMD machines. Crystal <ref> [Che86] </ref> and ASPAR [IFKF90] perform automatic data distribution based on symbolic pattern matching. Crystal requires a loop nest similar to Em, and more than one sequential loop may be defined. Neither performs interprocedural analysis.
Reference: [CM91] <author> Robert Costanza and Thomas Maxwell. </author> <title> Spatial ecosystem modelling using parallel processors. </title> <journal> Ecological Modelling, </journal> <volume> 58 </volume> <pages> 159-183, </pages> <year> 1991. </year>
Reference-contexts: An additional benefit of Em is the existence of procedure summaries for interprocedural analysis, because only the interface to the procedures requires analysis. With the exception of FIDIL [HC88], Cellang [Eck92], and SMP <ref> [CM91] </ref>, Em appears to be the only language which is domain-specific. FIDIL has a strongly applicative style and requires many users to learn a new style of programming. Em is designed for users accustomed to programming imperative languages.
Reference: [CMZ92] <author> Barbara Chapman, Piyush Mehrotra, and Hans Zima. </author> <title> Programming in Vienna Fortran. </title> <type> Technical Report ICASE 92-9, </type> <institution> NASA Langley Research Center, Hampton, VA, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: The performance results, shown in Figures 6 and 7, demonstrate that under these conditions, the algorithm selects the correct processor topology. Related Work Several parallel programming languages have been proposed to support general purpose parallel programming. OCCAM [Cok91] is designed for the transputer. Languages such as Fortran <ref> [Thi89, CFR + 92, CMZ92] </ref> and C [RS87], have been extended, include new compiler directives, and have library routines to manage processes and communication. Typically these languages are difficult to analyze. Pointer code in C makes analysis difficult. <p> This classification is used to generate message-passing code. If not pre-defined, it must be hand-written. Em's compiler analysis obviates the need for this classification, and does not require hand-written message-passing code. Languages such as BLAZE [MVR85] for shared memory machines, and Kali [MVR90], Vienna Fortran <ref> [CMZ92] </ref>, DINO [RSW90], Booster [PvGS90], Fortran D [FHK + 91], Fortran 90D [WF91], Adaptor [Bra93], SUPERB [ZBG88] for distributed memory machines, permit the user to specify the distribution and alignment of data. Adaptor has a back end which maps to several communication packages. SUPERB maps to SIMD and MIMD machines.
Reference: [Cok91] <author> R. ~ S. Cok. </author> <title> Parallel Programs for the Transputer. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1991. </year>
Reference-contexts: The code was written in C, and compiled unoptimized. The performance results, shown in Figures 6 and 7, demonstrate that under these conditions, the algorithm selects the correct processor topology. Related Work Several parallel programming languages have been proposed to support general purpose parallel programming. OCCAM <ref> [Cok91] </ref> is designed for the transputer. Languages such as Fortran [Thi89, CFR + 92, CMZ92] and C [RS87], have been extended, include new compiler directives, and have library routines to manage processes and communication. Typically these languages are difficult to analyze. Pointer code in C makes analysis difficult.
Reference: [Eck92] <author> J. Dana Eckart. </author> <title> A cellular automata simulation system. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 27(8) </volume> <pages> 80-106, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: An additional benefit of Em is the existence of procedure summaries for interprocedural analysis, because only the interface to the procedures requires analysis. With the exception of FIDIL [HC88], Cellang <ref> [Eck92] </ref>, and SMP [CM91], Em appears to be the only language which is domain-specific. FIDIL has a strongly applicative style and requires many users to learn a new style of programming. Em is designed for users accustomed to programming imperative languages.
Reference: [FHK + 91] <author> Geoffrey Fox, Seema Hiranadani, Ken Kennedy, Charles Koelbel, Uli Kremer, Chau-Wen Tseng, and Min-You Wu. </author> <title> Fortran D language specification. </title> <institution> Technical Report SCCS-42c (Rice COMP TR90-141), Syracuse Center for Computational Science, Syracuse University (Center for Research on Parallel Computation, Rice University), </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: If not pre-defined, it must be hand-written. Em's compiler analysis obviates the need for this classification, and does not require hand-written message-passing code. Languages such as BLAZE [MVR85] for shared memory machines, and Kali [MVR90], Vienna Fortran [CMZ92], DINO [RSW90], Booster [PvGS90], Fortran D <ref> [FHK + 91] </ref>, Fortran 90D [WF91], Adaptor [Bra93], SUPERB [ZBG88] for distributed memory machines, permit the user to specify the distribution and alignment of data. Adaptor has a back end which maps to several communication packages. SUPERB maps to SIMD and MIMD machines.
Reference: [FJL + 88] <author> Geoffrey C. Fox, Mark A. Johnson, Gregory A. Lyzenga, Steve W. Otto, John K. Salmon, and David W. Walker. </author> <title> Solving Problems on Concurrent Processors, Volume I. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1988. </year>
Reference-contexts: Data Partitioning Assuming a square iteration space, an optimal partitioning of the space is square <ref> [FJL + 88] </ref> when solving Laplace's equation using Jacobi iteration. However, partitioning data across processors is not always so obvious: array accesses need not be center symmetric; the iteration space may not be regular; or, the communication pattern may not be regular. <p> A naive approach to communication would construct four messages for the north, south, east, and west faces of the block, and two additional messages for the two remaining diagonal elements of the block. But as pointed out in Ch. 16 of <ref> [FJL + 88] </ref>, separate communication for diagonal elements is not necessary for Cartesian partitions: a maximum of 2n messages are required.
Reference: [HA90] <author> David E. Hudak and Santosh G. Abraham. </author> <title> Compiler techniques for data partitioning of sequentially iterated parallel loops. </title> <booktitle> In Proceedings of the 1990 International Conference on Supercomputing, </booktitle> <pages> pages 187-200, </pages> <address> Amsterdam, The Netherlands, </address> <month> June 11-15, </month> <year> 1990. </year> <note> Published as ACM SIGARCH Computer Architecture News 18(3). </note>
Reference-contexts: Em's data partitioning algorithm assumes a distributed multiprocessor system. The number of processors is a power of two. The data is partitioned statically across processors. This data partitioning strategy has the following advantages: (1) There is no restriction to a square iteration space as in <ref> [HA90, RAP87] </ref>; (2) There is no restriction to one variable as in [HA90]; (3) Conditional procedure invocation, whose execution count may be determined at compile time, is incorporated into the strategy; (4) Zero-weighted communications are incorporated; and, (5) Data sets which have an iteration space of less than n dimensions are <p> The number of processors is a power of two. The data is partitioned statically across processors. This data partitioning strategy has the following advantages: (1) There is no restriction to a square iteration space as in [HA90, RAP87]; (2) There is no restriction to one variable as in <ref> [HA90] </ref>; (3) Conditional procedure invocation, whose execution count may be determined at compile time, is incorporated into the strategy; (4) Zero-weighted communications are incorporated; and, (5) Data sets which have an iteration space of less than n dimensions are accommodated. <p> The p i are rounded up/down to the nearest integer power of 2 which produce the smallest non-minimal surface area. The communication weight per dimension is computed using a min-max construction <ref> [HA90] </ref>, and is considered a "best case" estimate since it assumes that all data external to a block need be communicated only once to satisfy all internal references. This construction satisfies Em's array access rules. <p> The set of access vectors for the non-symmetric forward-difference stencil is f [1; 1]; [0; 1]; [1; 0]g and ~w = [2; 1]; An optimal partition <ref> [HA90] </ref> is achieved when the ratio of the block faces are 2 : 1 for an n fi n iteration space. An Em program consists of one or more procedure invocations within a loop, and one or more array variables. Communication weight is extended to be a function of variable.
Reference: [HC88] <author> Paul N. Hilfinger and Phillip Colella. FIDIL: </author> <title> A language for scientific computing. </title> <type> Technical Report UCRL-98057, </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> January </month> <year> 1988. </year>
Reference-contexts: Because of the inherent difficulty, interprocedural analysis typically is not performed. Languages like Em simplify both compiler transformations needed to extract parallelism and inter-procedural analysis because of value-result semantics for procedure parameters and disallowal of access to non-local variables <ref> [MVR85, HC88] </ref>. An additional benefit of Em is the existence of procedure summaries for interprocedural analysis, because only the interface to the procedures requires analysis. With the exception of FIDIL [HC88], Cellang [Eck92], and SMP [CM91], Em appears to be the only language which is domain-specific. <p> An additional benefit of Em is the existence of procedure summaries for interprocedural analysis, because only the interface to the procedures requires analysis. With the exception of FIDIL <ref> [HC88] </ref>, Cellang [Eck92], and SMP [CM91], Em appears to be the only language which is domain-specific. FIDIL has a strongly applicative style and requires many users to learn a new style of programming. Em is designed for users accustomed to programming imperative languages.
Reference: [IFKF90] <author> K. Ikudome, G. Fox, A. Kolawa, and J. Flower. </author> <title> An automatic and symbolic parallelization system for distributed memory parallel computers. </title> <booktitle> In Proceedings of the Fifth Distributed Memory Conputing Converence, </booktitle> <pages> pages 1105-1114, </pages> <address> Charleston SC, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: Adaptor has a back end which maps to several communication packages. SUPERB maps to SIMD and MIMD machines. Crystal [Che86] and ASPAR <ref> [IFKF90] </ref> perform automatic data distribution based on symbolic pattern matching. Crystal requires a loop nest similar to Em, and more than one sequential loop may be defined. Neither performs interprocedural analysis. Programming details are removed in Em, and variable declarations alone specify their semantic meaning in the model.
Reference: [MVR85] <author> Piyush Mehrotra and John Van Rosendale. </author> <title> The BLAZE language: A parallel language for scientific programming. </title> <type> Technical Report ICASE 85-29, </type> <institution> NASA Langley Research Center, Hampton, VA, </institution> <month> May </month> <year> 1985. </year>
Reference-contexts: Because of the inherent difficulty, interprocedural analysis typically is not performed. Languages like Em simplify both compiler transformations needed to extract parallelism and inter-procedural analysis because of value-result semantics for procedure parameters and disallowal of access to non-local variables <ref> [MVR85, HC88] </ref>. An additional benefit of Em is the existence of procedure summaries for interprocedural analysis, because only the interface to the procedures requires analysis. With the exception of FIDIL [HC88], Cellang [Eck92], and SMP [CM91], Em appears to be the only language which is domain-specific. <p> This classification is used to generate message-passing code. If not pre-defined, it must be hand-written. Em's compiler analysis obviates the need for this classification, and does not require hand-written message-passing code. Languages such as BLAZE <ref> [MVR85] </ref> for shared memory machines, and Kali [MVR90], Vienna Fortran [CMZ92], DINO [RSW90], Booster [PvGS90], Fortran D [FHK + 91], Fortran 90D [WF91], Adaptor [Bra93], SUPERB [ZBG88] for distributed memory machines, permit the user to specify the distribution and alignment of data.
Reference: [MVR90] <author> Piyush Mehrotra and John Van Rosendale. </author> <title> Programming distributed memory architectures using Kali. </title> <type> Technical Report ICASE 90-69, </type> <institution> NASA Langley Research Center, Hampton, VA, </institution> <month> October </month> <year> 1990. </year>
Reference-contexts: This classification is used to generate message-passing code. If not pre-defined, it must be hand-written. Em's compiler analysis obviates the need for this classification, and does not require hand-written message-passing code. Languages such as BLAZE [MVR85] for shared memory machines, and Kali <ref> [MVR90] </ref>, Vienna Fortran [CMZ92], DINO [RSW90], Booster [PvGS90], Fortran D [FHK + 91], Fortran 90D [WF91], Adaptor [Bra93], SUPERB [ZBG88] for distributed memory machines, permit the user to specify the distribution and alignment of data. Adaptor has a back end which maps to several communication packages.
Reference: [Pug92] <author> William Pugh. </author> <title> A practical algorithm for exact array dependence analysis. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 102-114, </pages> <month> August </month> <year> 1992. </year> <month> 12 </month>
Reference-contexts: Two factors limit the effectiveness of current compiler technology: the structure of most programs is 9 not sufficiently regular, and low level code is hard to analyze <ref> [Pug92] </ref>. Even a program which might be written in a regular style might not be parallelizable by the compiler, simply because a general purpose language is used.
Reference: [PvGS90] <author> E. Paalvast, A. van Gemund, and H. Sips. </author> <title> A method of parallel program generation with an application to booster language. </title> <booktitle> In Proceedings of the 1990 International Conference on Supercomputing, </booktitle> <address> page ??, Amsterdam, The Netherlands, </address> <month> June 11-15, </month> <year> 1990. </year> <note> Published as ACM SIGARCH Computer Architecture News 18(3). </note>
Reference-contexts: This classification is used to generate message-passing code. If not pre-defined, it must be hand-written. Em's compiler analysis obviates the need for this classification, and does not require hand-written message-passing code. Languages such as BLAZE [MVR85] for shared memory machines, and Kali [MVR90], Vienna Fortran [CMZ92], DINO [RSW90], Booster <ref> [PvGS90] </ref>, Fortran D [FHK + 91], Fortran 90D [WF91], Adaptor [Bra93], SUPERB [ZBG88] for distributed memory machines, permit the user to specify the distribution and alignment of data. Adaptor has a back end which maps to several communication packages. SUPERB maps to SIMD and MIMD machines.
Reference: [RAP87] <author> Daniel A. Reed, Loyce M. Adams, and Merrell L. Patrick. </author> <title> Stencils and problem par-titionings: Their influence on the performance of multiple processor systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(7):845-858, </volume> <month> July </month> <year> 1987. </year>
Reference-contexts: Em's data partitioning algorithm assumes a distributed multiprocessor system. The number of processors is a power of two. The data is partitioned statically across processors. This data partitioning strategy has the following advantages: (1) There is no restriction to a square iteration space as in <ref> [HA90, RAP87] </ref>; (2) There is no restriction to one variable as in [HA90]; (3) Conditional procedure invocation, whose execution count may be determined at compile time, is incorporated into the strategy; (4) Zero-weighted communications are incorporated; and, (5) Data sets which have an iteration space of less than n dimensions are
Reference: [RS87] <author> J. Rose and G. Steele. </author> <title> C*: an extended C language for data parallel programming. </title> <type> Technical Report PL87-5, </type> <institution> Thinking Machines, Inc., </institution> <year> 1987. </year>
Reference-contexts: Related Work Several parallel programming languages have been proposed to support general purpose parallel programming. OCCAM [Cok91] is designed for the transputer. Languages such as Fortran [Thi89, CFR + 92, CMZ92] and C <ref> [RS87] </ref>, have been extended, include new compiler directives, and have library routines to manage processes and communication. Typically these languages are difficult to analyze. Pointer code in C makes analysis difficult. In both languages code may be written so that subscript analysis is difficult, if not impossible, for the compiler.
Reference: [RSW90] <author> M. Rosing, R. ~ W. Schnabel, and R. ~ P. Weaver. </author> <title> The dino parallel programming language. </title> <type> Technical Report CU-CS-457-90, </type> <institution> University of Colorado, Boulder, CO, </institution> <month> April </month> <year> 1990. </year>
Reference-contexts: This classification is used to generate message-passing code. If not pre-defined, it must be hand-written. Em's compiler analysis obviates the need for this classification, and does not require hand-written message-passing code. Languages such as BLAZE [MVR85] for shared memory machines, and Kali [MVR90], Vienna Fortran [CMZ92], DINO <ref> [RSW90] </ref>, Booster [PvGS90], Fortran D [FHK + 91], Fortran 90D [WF91], Adaptor [Bra93], SUPERB [ZBG88] for distributed memory machines, permit the user to specify the distribution and alignment of data. Adaptor has a back end which maps to several communication packages. SUPERB maps to SIMD and MIMD machines.
Reference: [SR58] <author> I.S. Sokolnikoff and R.M. Redheffer. </author> <title> Mathematics of Physics and Modern Engineering. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1958. </year>
Reference: [Thi89] <institution> Thinking Machines, Inc., </institution> <address> Cambridge, MA. </address> <note> CM Fortran Reference Manual, version 5.2 edition, </note> <year> 1989. </year>
Reference-contexts: The performance results, shown in Figures 6 and 7, demonstrate that under these conditions, the algorithm selects the correct processor topology. Related Work Several parallel programming languages have been proposed to support general purpose parallel programming. OCCAM [Cok91] is designed for the transputer. Languages such as Fortran <ref> [Thi89, CFR + 92, CMZ92] </ref> and C [RS87], have been extended, include new compiler directives, and have library routines to manage processes and communication. Typically these languages are difficult to analyze. Pointer code in C makes analysis difficult.
Reference: [WF91] <author> Min-You Wu and Geoffrey C. Fox. </author> <title> Fortran 90D compiler for distributed memory MIMD parallel computers. </title> <type> Technical Report SCCS-88b, </type> <institution> Syracuse Center for Computational Science, Syracuse University, </institution> <year> 1991. </year>
Reference-contexts: If not pre-defined, it must be hand-written. Em's compiler analysis obviates the need for this classification, and does not require hand-written message-passing code. Languages such as BLAZE [MVR85] for shared memory machines, and Kali [MVR90], Vienna Fortran [CMZ92], DINO [RSW90], Booster [PvGS90], Fortran D [FHK + 91], Fortran 90D <ref> [WF91] </ref>, Adaptor [Bra93], SUPERB [ZBG88] for distributed memory machines, permit the user to specify the distribution and alignment of data. Adaptor has a back end which maps to several communication packages. SUPERB maps to SIMD and MIMD machines.
Reference: [ZBG88] <author> H. P. Zima, H. Bast, and M. Gerndt. </author> <title> SUPERB: A tool for semi-automatic MIMD/SIMD parallelization. </title> <journal> Parallel Computing, </journal> <volume> 6 </volume> <pages> 1-18, </pages> <year> 1988. </year>
Reference-contexts: Em's compiler analysis obviates the need for this classification, and does not require hand-written message-passing code. Languages such as BLAZE [MVR85] for shared memory machines, and Kali [MVR90], Vienna Fortran [CMZ92], DINO [RSW90], Booster [PvGS90], Fortran D [FHK + 91], Fortran 90D [WF91], Adaptor [Bra93], SUPERB <ref> [ZBG88] </ref> for distributed memory machines, permit the user to specify the distribution and alignment of data. Adaptor has a back end which maps to several communication packages. SUPERB maps to SIMD and MIMD machines. Crystal [Che86] and ASPAR [IFKF90] perform automatic data distribution based on symbolic pattern matching. <p> Most current systems share resource allocation between the system and the programmer: the programmer specifies the data placement and the system automatically inserts the communication implied by the partition <ref> [ZBG88, CFR + 92] </ref>. Given that the scientific community prefers using standard imperative languages, the compiler must perform program analysis in order to transform the sequential program into equivalent concurrent code for execution on the parallel machine.

References-found: 24

