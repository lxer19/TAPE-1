URL: http://www.cs.kuleuven.ac.be/~wimv/Docs/kdd94.ps.gz
Refering-URL: http://www.cs.kuleuven.ac.be/~wimv/Docs/kdd94.html
Root-URL: 
Title: Applications of a logical discovery engine  
Author: Wim Van Laer, Luc Dehaspe and Luc De Raedt 
Keyword: inductive logic programming, knowledge discovery in databases, deductive databases, first order logic, machine learning.  
Address: Celestijnenlaan 200A, B-3001 Heverlee, Belgium  
Affiliation: Department of Computer Science, Katholieke Universiteit Leuven  
Email: email :fWim.VanLaer,Luc.Dehaspe,Luc.DeRaedtg@cs.kuleuven.ac.be  
Phone: fax 32 16 20 53 08; telephone 32 16 20 10 15  
Date: June 13, 1994  
Abstract: The clausal discovery engine claudien is presented. claudien discovers regularities in data and is a representative of the inductive logic programming paradigm. As such, it represents data and regularities by means of first order clausal theories. Because the search space of clausal theories is larger than that of attribute value representation, claudien also accepts as input a declarative specification of the language bias, which determines the set of syntactically well-formed regularities. Whereas other papers on claudien focuss on the semantics or logical problem specification of claudien, on the discovery algorithm, or the PAC-learning aspects, this paper wants to illustrate the power of the resulting technique. In order to achieve this aim, we show how claudien can be used to learn 1) integrity constraints in databases, 2) functional dependencies and determinations, 3) properties of sequences, 4) mixed quantitative and qualitative laws, 5) reverse engineering, and 6) classification rules. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Ade, L. De Raedt, and M. Bruynooghe. </author> <title> Declarative Bias for Bottom Up ILP Learning Systems, </title> <note> 1994. Submitted to Machine Learning. </note>
Reference-contexts: As our aim is to design a general algorithm to solve these different discovery tasks, we need an elegant mechanism to specify the language bias. 2.3 Specifying well-formed formulae Several formalisms to specify the bias exist in inductive logic programming, see for instance <ref> [1, 2, 3, 4, 15, 21] </ref>. It is generally agreed that among these competing formalisms that of Cohen is the most powerful but also the least declarative. <p> On the other hand, the formalisms by Kietz and Wrobel and by Bergadano are very declarative and also complementary in the sense that languages that are easy to represent in one formalism are hard to represent in the other formalism. This motivated our group <ref> [1] </ref> to integrate these two formalisms in a straightforward manner. The resulting formalism approaches the expressive power of Cohen's formalism while retaining the same declarative spirit of the Bergadano and Kietz and Wrobel representations.
Reference: [2] <author> F. Bergadano and D. Gunetti. </author> <title> An interactive system to learn functional logic programs. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1044-1049. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: As our aim is to design a general algorithm to solve these different discovery tasks, we need an elegant mechanism to specify the language bias. 2.3 Specifying well-formed formulae Several formalisms to specify the bias exist in inductive logic programming, see for instance <ref> [1, 2, 3, 4, 15, 21] </ref>. It is generally agreed that among these competing formalisms that of Cohen is the most powerful but also the least declarative.
Reference: [3] <author> W. Cohen. </author> <title> Grammatically biased learning: learning logic programs using an explicit antecedent description language. </title> <journal> Artificial Intelligence, </journal> <note> 1994. To appear. </note>
Reference-contexts: As our aim is to design a general algorithm to solve these different discovery tasks, we need an elegant mechanism to specify the language bias. 2.3 Specifying well-formed formulae Several formalisms to specify the bias exist in inductive logic programming, see for instance <ref> [1, 2, 3, 4, 15, 21] </ref>. It is generally agreed that among these competing formalisms that of Cohen is the most powerful but also the least declarative.
Reference: [4] <author> L. De Raedt. </author> <title> Interactive Theory Revision: an Inductive Logic Programming Approach. </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: As our aim is to design a general algorithm to solve these different discovery tasks, we need an elegant mechanism to specify the language bias. 2.3 Specifying well-formed formulae Several formalisms to specify the bias exist in inductive logic programming, see for instance <ref> [1, 2, 3, 4, 15, 21] </ref>. It is generally agreed that among these competing formalisms that of Cohen is the most powerful but also the least declarative.
Reference: [5] <author> L. De Raedt and M. Bruynooghe. </author> <title> A theory of clausal discovery. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1058-1063. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Throughout the paper, we will focuss on the mentioned applications, as the problem setting and the claudien system were already presented elsewhere (see <ref> [5, 6, 7, 21] </ref>). The paper is structured as follows: in section 2, we introduce the claudien setting and algorithm, and in section 3, we focuss on the mentioned applications. <p> A full discussion of these further extensions is outside the scope of this paper. 2.4 The claudien algorithm We briefly sketch the claudien algorithm that efficiently implements the above discovery paradigm. For a full discussion of claudien and its several optimizations, we refer to <ref> [5] </ref>. 4 A key observation underlying claudien is that clauses c that are false in the least model model of the knowledge base KB are overly general, i.e. that there exist substitutions for which body (c) is true and head (c) is false in the model. <p> optimizations of this algorithm, in particular, we employ an optimal refinement operator (which generates all clauses in L at most once), we use advanced search strategies, we test whether clauses c are logically redundant with regard to H, and we apply the balance principle to prune away useless clauses, see <ref> [5] </ref> for more information on this. Secondly, it is important to regard claudien as an any-time algorithm. By this we mean that the algorithm can be interupted at any time. The longer claudien will run, the more clauses the hypothesis will contain, and the more interesting the results will be.
Reference: [6] <author> L. De Raedt and S. Dzeroski. </author> <title> First order jk clausal theories are PAC-learnable. </title> <type> Technical Report KUL-CW-, </type> <institution> Department of Computer Science, Katholieke Universiteit Leuven, </institution> <year> 1993. </year> <note> submitted to Artificial Intelligence. </note>
Reference-contexts: Throughout the paper, we will focuss on the mentioned applications, as the problem setting and the claudien system were already presented elsewhere (see <ref> [5, 6, 7, 21] </ref>). The paper is structured as follows: in section 2, we introduce the claudien setting and algorithm, and in section 3, we focuss on the mentioned applications. <p> Two important consequences of this are that the PAC-learning results for our setting are much better than those for the normal setting (see <ref> [6, 11, 16] </ref>) and that there are problems in the normal setting when learning multiple predicates (see for instance [8]). One of the main contributions of this paper will be to show that a variety of different discovery tasks fit in this logical paradigm.
Reference: [7] <author> L. De Raedt and N. Lavrac. </author> <title> The many faces of inductive logic programming. </title> <editor> In J. Ko-morowski, editor, </editor> <booktitle> Proceedings of the 7th International Symposium on Methodologies for Intelligent Systems, Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year> <type> invited paper. </type>
Reference-contexts: Throughout the paper, we will focuss on the mentioned applications, as the problem setting and the claudien system were already presented elsewhere (see <ref> [5, 6, 7, 21] </ref>). The paper is structured as follows: in section 2, we introduce the claudien setting and algorithm, and in section 3, we focuss on the mentioned applications. <p> When desired, these can be used as further restrictions on H. Our problem setting differs from the normal inductive logic programming paradigm, see [21], where one learns concepts or predicates from positive and negative examples. The differences between the two settings are elaborated in <ref> [7, 21] </ref>. From a computational point of view, the most important difference is that in our framework all clauses may be considered independent of each other, which is not true in the normal setting of inductive logic programming.
Reference: [8] <author> L. De Raedt, N. Lavrac, and S. Dzeroski. </author> <title> Multiple predicate learning. </title> <booktitle> In Proceedings of the 13th International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1037-1042. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Two important consequences of this are that the PAC-learning results for our setting are much better than those for the normal setting (see [6, 11, 16]) and that there are problems in the normal setting when learning multiple predicates (see for instance <ref> [8] </ref>). One of the main contributions of this paper will be to show that a variety of different discovery tasks fit in this logical paradigm. In particular, we will show how apparently different discovery tasks can be obtained by varying the set of well-formed clauses in L.
Reference: [9] <author> T.G. Dietterich and R.S. Michalski. </author> <title> Discovering patterns in sequences of events. </title> <journal> Artificial Intelligence, </journal> <volume> 25 </volume> <pages> 257-294, </pages> <year> 1985. </year>
Reference-contexts: (D; E; F; Y ); C = F; A = D: It is easy to write clausemodels that would find determinations P (X; Y ) Q (X; Z); R (Z; Y ) (as [29]), determinations as [27] and multivalued dependencies as [13]. 3.3 Non deterministic sequence prediction Dietterich and Michalski <ref> [9] </ref> describe an approach to non deterministic sequence prediction. The problem of non deterministic sequence prediction is that of determining constraints on the k-th event in a sequence given the k 1 previous events.
Reference: [10] <author> B. Dolsak and S. Muggleton. </author> <title> The application of inductive logic programming to finite element mesh design. </title> <editor> In S. Muggleton, editor, </editor> <booktitle> Inductive logic programming, </booktitle> <pages> pages 453-472. </pages> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: and discover properties as sorted (Y ) quicksort (X; Y ). 3.6 Classification One standard benchmark for inductive logic programming systems operating under the normal setting (i.e. that where positive as well as negative examples are supplied of a target predicate), is that of learning finite element mesh-design (see e.g. <ref> [10, 18] </ref>). Here we will address the same learning task. However, whereas the other approaches require positive as well as negative examples, claudien needs only the positive.
Reference: [11] <author> S. Dzeroski, S. Muggleton, and S. Russel. </author> <title> PAC-learnability of determinate logic programs. </title> <booktitle> In Proceedings of the 5th ACM workshop on Computational Learning Theory, </booktitle> <pages> pages 128-135, </pages> <year> 1992. </year>
Reference-contexts: Two important consequences of this are that the PAC-learning results for our setting are much better than those for the normal setting (see <ref> [6, 11, 16] </ref>) and that there are problems in the normal setting when learning multiple predicates (see for instance [8]). One of the main contributions of this paper will be to show that a variety of different discovery tasks fit in this logical paradigm.
Reference: [12] <author> S. Dzeroski and L. Todorovski. </author> <title> Discovering dynamics: from inductive logic programming to machine discovery. </title> <booktitle> In Proceedings of the AAAI'93 Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 125-137. </pages> <publisher> AAAI Press, </publisher> <address> 1993. Washington DC. </address>
Reference-contexts: Otherwise, it is discarded. Although the procedure illustrated is simple, it is quite general and could be extended towards more interesting forms of regularities (e.g. employing statistical regression techniques as in Dzeroski's LAGRANGE <ref> [12] </ref>), and towards more advanced techniques (e.g. the BACON strategy [17]). We illustrate the quantitative technique on discovering non deterministic sequence prediction in Eleusis.
Reference: [13] <author> P. Flach. </author> <title> Predicate invention in inductive data engineering. </title> <editor> In P. Brazdil, editor, </editor> <booktitle> Proceedings of the 6th European Conference on Machine Learning, Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 83-94. </pages> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: clauses would typically be integrity constraints and the second and third one would define the view predicate human. 3.2 Functional dependencies and determinations One of the important topics in knowledge discovery in databases addresses how to efficiently discover specific types of regularities, such as functional and multivalued dependencies (see e.g. <ref> [13, 14, 26] </ref>) and determinations (see [27, 29]). <p> X = Y train (A; B; C; X); train (D; E; F; Y ); C = F; A = D: It is easy to write clausemodels that would find determinations P (X; Y ) Q (X; Z); R (Z; Y ) (as [29]), determinations as [27] and multivalued dependencies as <ref> [13] </ref>. 3.3 Non deterministic sequence prediction Dietterich and Michalski [9] describe an approach to non deterministic sequence prediction. The problem of non deterministic sequence prediction is that of determining constraints on the k-th event in a sequence given the k 1 previous events.
Reference: [14] <author> M. Kantola, H. Mannila, K.J. Raiha, and H. Siirtola. </author> <title> Discovering functional and inclusion dependencies in relational databases. </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 7(7), </volume> <year> 1992. </year>
Reference-contexts: clauses would typically be integrity constraints and the second and third one would define the view predicate human. 3.2 Functional dependencies and determinations One of the important topics in knowledge discovery in databases addresses how to efficiently discover specific types of regularities, such as functional and multivalued dependencies (see e.g. <ref> [13, 14, 26] </ref>) and determinations (see [27, 29]).
Reference: [15] <author> J-U. Kietz and S. Wrobel. </author> <title> Controlling the complexity of learning in logic through syntactic and task-oriented models. </title> <editor> In S. Muggleton, editor, </editor> <booktitle> Inductive logic programming, </booktitle> <pages> pages 335-359. </pages> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: As our aim is to design a general algorithm to solve these different discovery tasks, we need an elegant mechanism to specify the language bias. 2.3 Specifying well-formed formulae Several formalisms to specify the bias exist in inductive logic programming, see for instance <ref> [1, 2, 3, 4, 15, 21] </ref>. It is generally agreed that among these competing formalisms that of Cohen is the most powerful but also the least declarative.
Reference: [16] <author> J.U. Kietz. </author> <title> Some lower bounds for the computational complexity of inductive logic programming. </title> <booktitle> In Proceedings of the 6th European Conference on Machine Learning, </booktitle> <volume> volume 667, </volume> <pages> pages 115-124. </pages> <booktitle> Lecture Notes in Artificial Intelligence, </booktitle> <year> 1993. </year>
Reference-contexts: Two important consequences of this are that the PAC-learning results for our setting are much better than those for the normal setting (see <ref> [6, 11, 16] </ref>) and that there are problems in the normal setting when learning multiple predicates (see for instance [8]). One of the main contributions of this paper will be to show that a variety of different discovery tasks fit in this logical paradigm.
Reference: [17] <author> P. Langley, G.L. Bradshaw, and H.A. Simon. </author> <title> Rediscovering chemistry with the BACON system. </title> <editor> In R.S Michalski, J.G. Carbonell, and T.M. Mitchell, editors, </editor> <booktitle> Machine Learning: an artificial intelligence approach, </booktitle> <volume> volume 1, </volume> <pages> pages 307-330. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1983. </year>
Reference-contexts: Otherwise, it is discarded. Although the procedure illustrated is simple, it is quite general and could be extended towards more interesting forms of regularities (e.g. employing statistical regression techniques as in Dzeroski's LAGRANGE [12]), and towards more advanced techniques (e.g. the BACON strategy <ref> [17] </ref>). We illustrate the quantitative technique on discovering non deterministic sequence prediction in Eleusis.
Reference: [18] <author> N. Lavrac and S. Dzeroski. </author> <title> Inductive Logic Programming: Techniques and Applications. </title> <publisher> Ellis Horwood, </publisher> <year> 1993. </year>
Reference-contexts: Since then, the game of Eleusis has been employed in the context of inductive logic programming by Quinlan [25] and Lavrac and Dzeroski <ref> [18] </ref>. We show how the task was addressed by claudien. Given were the following sequences of cards (taken from [25]): 6 1. <p> and discover properties as sorted (Y ) quicksort (X; Y ). 3.6 Classification One standard benchmark for inductive logic programming systems operating under the normal setting (i.e. that where positive as well as negative examples are supplied of a target predicate), is that of learning finite element mesh-design (see e.g. <ref> [10, 18] </ref>). Here we will address the same learning task. However, whereas the other approaches require positive as well as negative examples, claudien needs only the positive. <p> The discovered rules were then tested against the structure left out. The result are summarized in table 1. The results of claudien are compared with those of golem, foil and mfoil in table 2, these results were taken from <ref> [18] </ref>. We believe the results of these tests are very encouraging because the rules learned by claudien have by far the best classification accuracy and also because the cpu-requirements of claudien are of the same order as those by the other systems.
Reference: [19] <author> J.W. Lloyd. </author> <title> Foundations of logic programming. </title> <publisher> Springer-Verlag, </publisher> <address> 2nd edition, </address> <year> 1987. </year>
Reference-contexts: Finally, in section 4, we conclude. 2 The discovery framework 2.1 Some logic programming concepts We briefly review some standard logic programming concepts (see <ref> [19] </ref> for more details). A clause is a formula of the form A 1 ; :::; A m B 1 ; :::; B n where the A i and B i are positive literals (atomic formulae).
Reference: [20] <editor> S. Muggleton, editor. </editor> <booktitle> Inductive Logic Programming. </booktitle> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: Although many of these systems are based on the same search principles (i.e. general to specific, possibly guided by heuristics), they often focuss on finding particular forms of regularities expressible in an attribute value representation. When analysing these discovery systems and the new trend of inductive logic programming (cf. <ref> [20, 21] </ref>), two important questions arise: 1. Can (some of) these techniques be abstracted into a more general technique? or can we build a generic discovery algorithm? 2.
Reference: [21] <author> S. Muggleton and L. De Raedt. </author> <title> Inductive logic programming : Theory and methods. </title> <journal> Journal of Logic Programming, </journal> <note> 1994. To appear. </note>
Reference-contexts: Although many of these systems are based on the same search principles (i.e. general to specific, possibly guided by heuristics), they often focuss on finding particular forms of regularities expressible in an attribute value representation. When analysing these discovery systems and the new trend of inductive logic programming (cf. <ref> [20, 21] </ref>), two important questions arise: 1. Can (some of) these techniques be abstracted into a more general technique? or can we build a generic discovery algorithm? 2. <p> Throughout the paper, we will focuss on the mentioned applications, as the problem setting and the claudien system were already presented elsewhere (see <ref> [5, 6, 7, 21] </ref>). The paper is structured as follows: in section 2, we introduce the claudien setting and algorithm, and in section 3, we focuss on the mentioned applications. <p> When desired, these can be used as further restrictions on H. Our problem setting differs from the normal inductive logic programming paradigm, see <ref> [21] </ref>, where one learns concepts or predicates from positive and negative examples. The differences between the two settings are elaborated in [7, 21]. <p> When desired, these can be used as further restrictions on H. Our problem setting differs from the normal inductive logic programming paradigm, see [21], where one learns concepts or predicates from positive and negative examples. The differences between the two settings are elaborated in <ref> [7, 21] </ref>. From a computational point of view, the most important difference is that in our framework all clauses may be considered independent of each other, which is not true in the normal setting of inductive logic programming. <p> As our aim is to design a general algorithm to solve these different discovery tasks, we need an elegant mechanism to specify the language bias. 2.3 Specifying well-formed formulae Several formalisms to specify the bias exist in inductive logic programming, see for instance <ref> [1, 2, 3, 4, 15, 21] </ref>. It is generally agreed that among these competing formalisms that of Cohen is the most powerful but also the least declarative.
Reference: [22] <author> S. Muggleton and C. Feng. </author> <title> Efficient induction of logic programs. </title> <booktitle> In Proceedings of the 1st conference on algorithmic learning theory, </booktitle> <pages> pages 368-381. </pages> <address> Ohmsma, Tokyo, Japan, </address> <year> 1990. </year>
Reference-contexts: The original mesh-application contains data about 5 different structures (a-e), with the number of edges per structure varying between 28 and 96. There are 278 positive examples (and 2840 negative ones) and the original backgroundtheory contains 1872 facts. The original backgroundtheory was made determinate (because the golem system of <ref> [22] </ref> cannot work with indeterminate clauses). As claudien does not suffer from this restriction, we could compact the database to 639 (equivalent facts). An example of a positive example is mesh (b11; 6) meaning that edge 11 of structure b should be divided in 6 subedges.
Reference: [23] <editor> G. Piatetsky-Shapiro and W. Frawley, editors. </editor> <title> Knowledge discovery in databases. </title> <publisher> The MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: 1 Introduction In the literature, a wide range of discovery systems are described (see e.g. <ref> [23, 24] </ref>). Although many of these systems are based on the same search principles (i.e. general to specific, possibly guided by heuristics), they often focuss on finding particular forms of regularities expressible in an attribute value representation.
Reference: [24] <editor> G. (Ed.) Piatetsky-Shapiro. </editor> <title> Special issue on knowledge discovery in databases. </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 7(7), </volume> <year> 1992. </year>
Reference-contexts: 1 Introduction In the literature, a wide range of discovery systems are described (see e.g. <ref> [23, 24] </ref>). Although many of these systems are based on the same search principles (i.e. general to specific, possibly guided by heuristics), they often focuss on finding particular forms of regularities expressible in an attribute value representation.
Reference: [25] <author> J.R. Quinlan. </author> <title> Learning logical definition from relations. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 239-266, </pages> <year> 1990. </year>
Reference-contexts: Since then, the game of Eleusis has been employed in the context of inductive logic programming by Quinlan <ref> [25] </ref> and Lavrac and Dzeroski [18]. We show how the task was addressed by claudien. Given were the following sequences of cards (taken from [25]): 6 1. <p> Since then, the game of Eleusis has been employed in the context of inductive logic programming by Quinlan <ref> [25] </ref> and Lavrac and Dzeroski [18]. We show how the task was addressed by claudien. Given were the following sequences of cards (taken from [25]): 6 1.
Reference: [26] <author> I. </author> <title> Savnik and P.A. Flach. Bottom-up induction of functional dependencies from relations. </title> <booktitle> In Proceedings of the AAAI'93 Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 174-185. </pages> <publisher> AAAI Press, </publisher> <address> 1993. Washington DC. </address>
Reference-contexts: clauses would typically be integrity constraints and the second and third one would define the view predicate human. 3.2 Functional dependencies and determinations One of the important topics in knowledge discovery in databases addresses how to efficiently discover specific types of regularities, such as functional and multivalued dependencies (see e.g. <ref> [13, 14, 26] </ref>) and determinations (see [27, 29]).
Reference: [27] <author> J. Schlimmer. </author> <title> Learning determinations and checking databases. </title> <booktitle> In Proceedings of the AAAI'91 Workshop on Knowledge Discovery in Databases, </booktitle> <pages> pages 64-76, </pages> <address> 1991. Washing-ton DC. </address>
Reference-contexts: and the second and third one would define the view predicate human. 3.2 Functional dependencies and determinations One of the important topics in knowledge discovery in databases addresses how to efficiently discover specific types of regularities, such as functional and multivalued dependencies (see e.g. [13, 14, 26]) and determinations (see <ref> [27, 29] </ref>). <p> = F; B = E: X = Y train (A; B; C; X); train (D; E; F; Y ); C = F; A = D: It is easy to write clausemodels that would find determinations P (X; Y ) Q (X; Z); R (Z; Y ) (as [29]), determinations as <ref> [27] </ref> and multivalued dependencies as [13]. 3.3 Non deterministic sequence prediction Dietterich and Michalski [9] describe an approach to non deterministic sequence prediction. The problem of non deterministic sequence prediction is that of determining constraints on the k-th event in a sequence given the k 1 previous events.
Reference: [28] <author> E.Y. Shapiro. </author> <title> Algorithmic Program Debugging. </title> <publisher> The MIT Press, </publisher> <year> 1983. </year>
Reference: [29] <author> W.M Shen. </author> <title> Discovering regularities from knowledge bases. </title> <journal> International Journal of Intelligent Systems, </journal> <volume> 7(7), </volume> <year> 1992. </year>
Reference-contexts: and the second and third one would define the view predicate human. 3.2 Functional dependencies and determinations One of the important topics in knowledge discovery in databases addresses how to efficiently discover specific types of regularities, such as functional and multivalued dependencies (see e.g. [13, 14, 26]) and determinations (see <ref> [27, 29] </ref>). <p> F ); C = F; B = E: X = Y train (A; B; C; X); train (D; E; F; Y ); C = F; A = D: It is easy to write clausemodels that would find determinations P (X; Y ) Q (X; Z); R (Z; Y ) (as <ref> [29] </ref>), determinations as [27] and multivalued dependencies as [13]. 3.3 Non deterministic sequence prediction Dietterich and Michalski [9] describe an approach to non deterministic sequence prediction.
Reference: [30] <author> W. Van Laer and L. De Raedt. </author> <title> Discovering quantitative laws in inductive logic programming. </title> <booktitle> In Proceedings of the Familiarization Workshop of the ESPRIT Network of Excellence on Machine Learning, </booktitle> <pages> pages 8-11, </pages> <year> 1993. </year> <note> Extended Abstract, Blanes, Spain. 12 </note>
Reference-contexts: First however, we need to explain how numbers are handled by claudien (see also <ref> [30] </ref>). To handle numbers the refinement operator has to be adapted. The reason is that a standard refinement operator can only enumerate the refinements of a given clause.
References-found: 30

