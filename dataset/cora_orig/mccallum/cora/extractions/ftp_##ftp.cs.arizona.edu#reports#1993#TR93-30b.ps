URL: ftp://ftp.cs.arizona.edu/reports/1993/TR93-30b.ps
Refering-URL: http://www.cs.arizona.edu/research/reports.html
Root-URL: http://www.cs.arizona.edu
Title: A Comparison of Implicit and Explicit Parallel Programming  
Author: Vincent W. Freeh 
Note: TR 93-30a  
Abstract-found: 0
Intro-found: 1
Reference: [AE88] <author> Arvind and Kattamuri Ekanadham. </author> <title> Future scientific programming on parallel machines. </title> <journal> J. Par. and Dist. Comp., </journal> <volume> 5 </volume> <pages> 460-493, </pages> <year> 1988. </year>
Reference-contexts: Furthermore, it is easier to reason about and make assertions of a program that is referentially transparent|helping greatly in program verification. Moreover, debugging is much simpler in a deterministic language <ref> [Bac78, AE88] </ref>. The functional model has two significant handicaps: no state and no asynchrony. Without state, some applications, such as data bases, cannot be written. Furthermore, because of determinism, asynchronous programs (such as interrupt-driven device drivers) also cannot be written.
Reference: [And91] <author> Gregory R. Andrews. </author> <title> Concurrent Programming: </title> <booktitle> Principles and Practice. </booktitle> <address> Ben-jamin/Cummings, Redwood City, California, </address> <year> 1991. </year>
Reference-contexts: Because this statement creates a process for each call, it results in an explosion of processes. The second program, bag, uses a bag of tasks, which contains all tasks to be done, and worker processes, which continuously remove and execute tasks <ref> [And91] </ref>. In this algorithm, we create work by inserting a task (describing the work) into the bag; eventually a worker removes and executes this task.
Reference: [AO93] <author> Gregory R. Andrews and Ronald A. Olsson. </author> <title> The SR Programming Language. </title> <address> Ben-jamin/Cummings, Redwood City, California, </address> <year> 1993. </year> <month> 16 </month>
Reference-contexts: The compiler can schedule the execution of expressions in any order, including concurrently, as long as it preserves data dependencies. Appendix A contains a brief overview of Sisal. SR (Synchronizing Resources) is a general purpose imperative language with processes, communication, and synchronization integrated into the language <ref> [AOC + 88, AO93] </ref>. It has shared variables, semaphores, synchronous and asynchronous message passing, remote procedure call, and rendezvous. Sequential, shared-memory, and distributed programs can be written in SR. Appendix B contains a brief overview of SR.
Reference: [AOC + 88] <author> G. Andrews, R. Olsson, M. Coffin, I. Elshoff, K. Nilsen, T. Purdin, and G. Townsend. </author> <title> An overview of the SR programming language and implementation. </title> <journal> TOPLAS, </journal> <volume> 10(1) </volume> <pages> 51-86, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: The compiler can schedule the execution of expressions in any order, including concurrently, as long as it preserves data dependencies. Appendix A contains a brief overview of Sisal. SR (Synchronizing Resources) is a general purpose imperative language with processes, communication, and synchronization integrated into the language <ref> [AOC + 88, AO93] </ref>. It has shared variables, semaphores, synchronous and asynchronous message passing, remote procedure call, and rendezvous. Sequential, shared-memory, and distributed programs can be written in SR. Appendix B contains a brief overview of SR.
Reference: [Bac78] <author> Jim Backus. </author> <title> Can programming be liberated from the von Neumann style? CACM, </title> <type> 21(8), </type> <month> August 78. </month>
Reference-contexts: Furthermore, it is easier to reason about and make assertions of a program that is referentially transparent|helping greatly in program verification. Moreover, debugging is much simpler in a deterministic language <ref> [Bac78, AE88] </ref>. The functional model has two significant handicaps: no state and no asynchrony. Without state, some applications, such as data bases, cannot be written. Furthermore, because of determinism, asynchronous programs (such as interrupt-driven device drivers) also cannot be written.
Reference: [BO94] <author> A. P. W. Bohm and R. R. Oldehoeft. </author> <title> Two issues in parallel language design. </title> <journal> Transactions on Programming Languages and Systems, </journal> <volume> 16(6) </volume> <pages> 1675-1683, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: The programmer knows that the array can be re-used on the next iteration; however, this cannot be expressed in Sisal. Two of the implementors of Sisal have reached the same conclusion; <ref> [BO94] </ref> states that some Sisal programmers "have found that they need greater freedom to express algorithms." Sisal provides a high-level abstraction that hides many details from the programmer.
Reference: [Cof90] <author> Michael H. Coffin. </author> <title> Par: An Approach to Architecture-Independent Parallel Programming. </title> <type> PhD thesis, </type> <institution> University of Arizona, </institution> <address> Tucson, AZ 85721, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: Thus, we can expect more and more scientists to turn to parallel computing. There are three main approaches to programming parallel computers: parallelizing compilers, implicit parallel programming languages, and explicit parallel programming languages <ref> [Cof90] </ref>. A parallelizing compiler creates a parallel program from sequential source code. Thus, existing sequential programs become parallel programs, and the programmer need not learn a new language. Unfortunately, this approach has two major drawbacks. First, the compiler usually cannot discover all the available parallelism in a program. <p> Unfortunately, this approach has two major drawbacks. First, the compiler usually cannot discover all the available parallelism in a program. Second, the best parallel solution to a problem often differs from the best sequential solution <ref> [Cof90] </ref>. An implicit parallel programming language, such as Id or Sisal, relies on a compiler to exploit the parallelism inherent in a program. These languages have no constructs to create and manage parallelism, and hence, program design and development is generally simpler than in an explicit parallel language. <p> However, like a parallelizing compiler for a sequential language, a compiler for an implicit parallel language has to create and manage parallelism. Thus, like in the above approach, the compiler may not discover all the parallelism available <ref> [Cof90] </ref>. An explicit parallel programming language provides constructs, such as cobegin, that allow the programmer to create and manage concurrency. Modern concurrent languages, such as Ada and SR, have parallel constructs integrated into the language. <p> Because parallelism is explicit, the programmer can write an efficient program and tune it for peak performance. However, the need to code parallelism explicitly makes this approach more difficult than either of the other approaches <ref> [Cof90] </ref>. This paper compares using an implicit parallel language, Sisal, to using an explicit parallel language, SR. Sisal (Streams and Iteration in a Single Assignment Language) is a general purpose functional language [FCO90].
Reference: [Dew85] <author> A. K. Dewdney. </author> <title> Computer recreations. </title> <publisher> Scientific American, </publisher> <pages> pages 16-24, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: Unfortunately, slup does not exchange two elements in place during the pivot; therefore, it must copy all n elements in each row to a newly allocated row, performing the pivot while copying. 2.5 Mandelbrot The Mandelbrot set is in of the two-dimensional plane of the complex numbers <ref> [Dew85] </ref>.
Reference: [EAL93] <author> Dawson R. Engler, Gregory R. Andrews, and David K. Lowenthal. </author> <title> Shared Filaments: Efficient support for fine-grain parallelism on shared-memory multiprocessors. </title> <type> TR 93-13, </type> <institution> Dept. of Computer Science, University of Arizona, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: We added it by modifying the compiler back end to generate code for the Filaments package, which supports efficient fine-grain parallelism on shared-memory multiprocessors, distributed-memory multicomputers, and clusters of workstations <ref> [EAL93, FLA94] </ref>. The performance results presented in this paper are the median of at least three separate executions. The reported time reflects only the performance of the applications; it does not include any initialization or finalization of the run-time systems.
Reference: [Ega93] <author> G. K. Egan. </author> <title> Implementing the kernel of the Australian region weather prediction model in SISAL. </title> <editor> In John T. Feo, editor, </editor> <volume> SISAL '93, </volume> <pages> pages 11-17, </pages> <address> Livermore, CA, </address> <month> October </month> <year> 1993. </year> <institution> Lawrence Livermore National Laboratory, Computer Research Group. </institution>
Reference-contexts: Both of these limitations increase the number of parameters to a function, which can be become very large. For example, the main function to the Australian Weather Kernel that has 43 input and 12 output parameters <ref> [Ega93] </ref>. The primary advantage of the explicit mechanism in SR is that the programmer has complete control over the parallelism. This provides flexibility and does not require, nor rely, on compiler analysis. However, there are three major disadvantages.
Reference: [FA95] <author> Vincent W. Freeh and Gregory R. Andrews. fsc: </author> <title> a Sisal compiler for both distributed-and shared-memory machines. </title> <editor> In A. P. W. Bohm and John T. Feo, editors, </editor> <booktitle> Proceedings of the High-Performance Functional Computing Conference, </booktitle> <pages> pages 164-172. </pages> <institution> Lawrence Livermore National Laboratory, </institution> <month> April </month> <year> 1995. </year>
Reference-contexts: Modifications were made to the osc run time system and to the code generation phase of the back end. Because the modifications to the back end of the compiler were confined to the code generator, fsc retains the optimizations performed by osc <ref> [FA95] </ref>. 2.3.2 SR Programs We wrote three different adaptive quadrature programs in SR. The simplest SR program, co, uses the SR co (cobegin) statement to invoke the two recursive calls in parallel (the next to last line in Figure 5). <p> The Sisal program uses 8 recursive calls, it is a poor implementation; a recursive SR program finishes in 18.1 seconds|as fast as prune and 32% faster than the Sisal program. The times shown in the fsc column of Figure 6 were obtained using fsc, a modified Sisal compiler <ref> [FA95] </ref>. The speedup is nearly perfect and on a single processor it is better than Sisal. The Filaments library performs pruning, which explains the excellent speedup and the good single processor performance. The co program is not very efficient.
Reference: [FCO90] <author> John T. Feo, David C. Cann, and Rodney R. Oldehoeft. </author> <title> A report on the SISAL language project. </title> <journal> J. of Par. and Dist. Computing, </journal> <volume> 10(4) </volume> <pages> 349-366, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: This paper compares using an implicit parallel language, Sisal, to using an explicit parallel language, SR. Sisal (Streams and Iteration in a Single Assignment Language) is a general purpose functional language <ref> [FCO90] </ref>. It is implemented using a dataflow model, meaning program execution is determined by the availability of the data, not the static ordering of expressions in the source code. The compiler can schedule the execution of expressions in any order, including concurrently, as long as it preserves data dependencies.
Reference: [FLA94] <author> Vincent W. Freeh, David K. Lowenthal, and Gregory R. Andrews. </author> <title> Distributed Filaments: Efficient fine-grain parallelism on a cluster of workstations. </title> <booktitle> In First Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 201-213, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: We added it by modifying the compiler back end to generate code for the Filaments package, which supports efficient fine-grain parallelism on shared-memory multiprocessors, distributed-memory multicomputers, and clusters of workstations <ref> [EAL93, FLA94] </ref>. The performance results presented in this paper are the median of at least three separate executions. The reported time reflects only the performance of the applications; it does not include any initialization or finalization of the run-time systems. <p> The modified compiler, fsc, links the generated code with the Filaments run time library, which provides efficient fine-grain parallelism, and in particular, fork/join or function call parallelism 7 SISAL SR C CPUs osc fsc bag prune 1 26.7 23.7 25.8 18.2 7.79 3 8.17 13.3 6.07 2.61 <ref> [FLA94] </ref>. Modifications were made to the osc run time system and to the code generation phase of the back end.
Reference: [Hug90] <author> John Hughes. </author> <title> Why functional programming matters. </title> <editor> In David A. Turner, editor, </editor> <booktitle> Research Topics in Functional Programming, </booktitle> <pages> pages 17-42, </pages> <address> Reading, MA, 1990. University of Kent, </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: In other words, a functional language has no side effects and is referentially transparent. Therefore, expressions can 13 be evaluated in any order, and a variable can be replaced by its value (and vice-versa), providing flexibility in the order of execution of the expressions <ref> [Hug90] </ref>. Furthermore, it is easier to reason about and make assertions of a program that is referentially transparent|helping greatly in program verification. Moreover, debugging is much simpler in a deterministic language [Bac78, AE88]. The functional model has two significant handicaps: no state and no asynchrony.
Reference: [Knu71] <author> Donald E. Knuth. </author> <title> An empirical study of Fortran programs. </title> <journal> Software|Practice and Experience, </journal> <volume> 1(2) </volume> <pages> 105-33, </pages> <month> April-June </month> <year> 1971. </year>
Reference-contexts: Nonetheless, the results presented here show the flavor, strengths, and weaknesses of the languages. Moreover, in a large application most of the time is spent executing a small portion of the code <ref> [Knu71] </ref>; thus, our performance results provide an indication of the expected performance of a larger application. We compare the performance of these programs to each other and to equivalent C programs, which provide a performance baseline and show the overheads introduced by Sisal and SR.
Reference: [PFTV88] <author> William H. Press, Brian P. Flannery, Saul A. Teukolsky, and William T. Vetterling. </author> <title> Numerical Recipes in C. </title> <publisher> Cambridge University Press, </publisher> <address> Cambrigde, </address> <year> 1988. </year>
Reference-contexts: The program prune limits the number of tasks that are inserted, which both reduces contention and eliminates some insertions and deletions. 2.4 LU Decomposition LU decomposition solves the linear system: Ax = b <ref> [PFTV88] </ref>, by decomposing A into lower-and upper-triangular matrices, such that A = LU . Then the linear system becomes A = LU x = b and the solution, x, is obtained by solving two triangular systems Ly = b and U x = y, using back-substitution.
Reference: [SY88] <author> Stephen Skedzielewski and Robert Kim Yates. </author> <title> Fibre: an external format for SISAL and IF1 data objects. </title> <type> Report M-154, </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> April </month> <year> 1988. </year> <month> 17 </month>
References-found: 17

