URL: http://www.cse.ucsc.edu/research/kestrel/papers/arvlsi97.ps
Refering-URL: http://www.cse.ucsc.edu/research/kestrel/papers.html
Root-URL: http://www.cse.ucsc.edu
Title: c flIEEE CS Kestrel: Design of an 8-bit SIMD parallel processor the entire machine should
Author: David M. Dahle Jeffrey D. Hirschberg Kevin Karplus Hansjorg Keller Eric Rice Don Speck Douglas H. Williams Richard Hughey 
Keyword: chip tester) and CDA-9115268 (MasPar parallel computer). http://www.cse.ucsc.edu/research/kestrel  
Address: Santa Cruz, CA 95064  
Affiliation: Department of Computer Engineering Jack Baskin School of Engineering University of California,  
Note: Proc. 17th Conf. on Advanced Research in VLSI,  1: Introduction  
Email: rph@cse.ucsc.edu  
Date: September 15-17, 1997.  
Abstract: Kestrel is a high-performance programmable parallel co-processor. Its design is the result of examination and reexamination of algorithmic, architectural, packaging, and silicon design issues, and the interrelations between them. The final system features a linear array of 8-bit processing elements, each with local memory, an arithmetic logic unit (ALU), a multiplier, and other functional units. Sixty-four Kestrel processing elements fit in a 1.4 million transistor, 60 mm 2 , 0.5 m CMOS chip with just 84 pins. The planned single-board, 8-chip system will, for some applications, provide supercomputer performance at a fraction of the cost. This paper surveys four of our applications (sequence analysis, neural networks, image compression, and floating-point arithmetic), and discusses the philosophy behind many of the design decisions. We present the processing element and system architectures, emphasizing the ALU and comparator's compact instruction encoding and design, the architecture's facility with nested conditionals, and the multiplier's flexibility in performing multiprecision operations. Finally, we discuss Kestrel is a simple yet powerful VLSI parallel processor. The focus of our initial design effort was the sequence analysis applications from computational biology. As more and more DNA, RNA, and protein molecules are sequenced into their constituent nucleotides or amino acids (essentially, alphabets with four or twenty characters), the need for high-speed sequence analysis is becoming more and more urgent. The Genbank database, for example, has over one million entries with over 700 million nucleotides [1]. Because computational biology (and indeed any field) is constantly discovering new analysis methods, programmability is a key issue in designing a system that can serve the needs of this vast community. Thus, Kestrel has been designed for use with a host of different methods, from the standard Smith and Waterman algorithm [37] to hidden Markov models [23], with many variations in between and yet to come. Our goal, however, has never been to build just a sequence analysis machine. Once the requirement for programmability in a sequence analysis machine is realized, it becomes obvious that This work was supported in part by NSF grant MIP-9423985 and its REU supplement. Keller was supported in part by a sabbatical leave grant from the State of Berne, Switzerland. Dahle and Rice were supported in part by ARCS Foundation fellowships. The work was initially funded by the UCSC Division of Natural Sciences. This work made use of equipment purchased under NSF grants CDA-9022505 (IMS the implementation and performance of the Kestrel test chips.
Abstract-found: 1
Intro-found: 0
Reference: [1] <author> D. Benson, M. Boguski, D. Lipman, and J. Ostell, </author> <title> "Genbank," </title> <journal> Nucleic Acids Research, </journal> <volume> vol. 25, no. 1, </volume> <pages> pp. 1-6, </pages> <year> 1997. </year>
Reference-contexts: The Genbank database, for example, has over one million entries with over 700 million nucleotides <ref> [1] </ref>. Because computational biology (and indeed any field) is constantly discovering new analysis methods, programmability is a key issue in designing a system that can serve the needs of this vast community.
Reference: [2] <author> D. W. Blevins et al., "BLITZEN: </author> <title> A highly integrated massively parallel machine," </title> <journal> J. Parallel and Distributed Computing, </journal> <volume> vol. 8, </volume> <pages> pp. 150-160, </pages> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: The inner loop of one common form of sequence analysis requires 21 instructions on Kestrel. Our target single board, 512-PE system running at 33 MHz will perform this application at a speed similar to the vastly more expensive 16 384-processing element Maspar MP-2 <ref> [2, 15] </ref>. 2.2: Instruction broadcast SIMD instruction broadcast can be slow, especially with many processing elements. The typical SIMD instruction memory is centralized for all processing elements to eliminate the overhead of local control. <p> Each chip of just under one million transistors has 32 processing elements and two router interfaces. The ALU and memory interface can operate concurrently to partially alleviate the bandwidth problem of off-chip communication. The chips have a 12.5 MHz clock, with simple operations requiring three clock cycles <ref> [2] </ref>. Pentium MMX The Intel Pentium's MMX unit provides small-scale SIMD processing of 8-, 16-or 32-bit subfields of its 64 bit data. The Pentium architecture is cached and features two execution pipelines which under optimal conditions enable execution of 2 MMX instructions per cycle. <p> Our design grew from an initial desire to build a small, fast, and inexpensive sequence analysis machine into a general purpose parallel accelerator. The design does not exist in a vacuum, however. Its evolution has been shaped in particular by several architectures including B-SYS [16], MasPar [30], Blitzen <ref> [2] </ref>, and the unbuilt MISC machine [33], as well as MGAP and PIM [3, 12]. Contemporaneous sets of design choices can be found with the CNAPS [14], RaPiD [8], Rapid-2 (not related) [9], Samba [24], and SIMPil [10] architectures, among others.
Reference: [3] <author> M. Borah, C. Nagendra, R. Owens, and M. J. Irwin, </author> <title> "The MGAP: A high-performance, user-programmable, multifunctional architecture for DSP," </title> <booktitle> in Proc. Hawaii Int. Conf. System Sciences, </booktitle> <pages> pp. 96-104, </pages> <publisher> IEEE, </publisher> <year> 1994. </year>
Reference-contexts: A reconfigurable machine can be thought of as a SIMD machine with a single exceedingly long instruction that is executed many times <ref> [3, 41, 11] </ref>. Unfortunately, this great flexibility can cause programming to be more difficult than on a true SIMD machine, and can cause a much lower ratio of processing power to area. Alternatively, instructions can be cached at the PE (for a MIMD machine), chip, or board level. <p> The design does not exist in a vacuum, however. Its evolution has been shaped in particular by several architectures including B-SYS [16], MasPar [30], Blitzen [2], and the unbuilt MISC machine [33], as well as MGAP and PIM <ref> [3, 12] </ref>. Contemporaneous sets of design choices can be found with the CNAPS [14], RaPiD [8], Rapid-2 (not related) [9], Samba [24], and SIMPil [10] architectures, among others.
Reference: [4] <author> D. Brutlag, J.-P. Deautricourt, and J. Griffin. </author> <type> Personal Communication, </type> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: Such storage systems are more in the domain of general-purpose supercomputers than cost-effective parallel co-processors. Second, for many applications, data buffering and recirculating among a small number of high-speed processors can be an effective solution. This idea has been adapted by a number of special-purpose machines <ref> [4, 24, 40] </ref>. 2 Third, programmable processing elements that require several instructions to compute the basic function can be used. This solution, used by Kestrel, essentially allows the addition of programmability into the processing elements with little penalty over the single-purpose system. <p> The standard NN configuration consists of 3 layers (input, hidden, and output), each containing a 5 Machines: BISP (single purpose, not completed) [5], BioSCAN (single purpose) [36], 15-board Decypher-II (FPGA, $173k) [40], 5-board FDF (single purpose, $50k), 16,536-PE MasPar, [34], SAMBA (single purpose) [24], 1- and 2-board Mercury (single purpose) <ref> [4] </ref>, Biocellera-tor (FPGA, about $50k) [7], 1-board Decypher-II ($18k), 32-node Paragon [31], 1024-PE MasPar, 5 DEC Alpha 3000 workstations [31], B-SYS [16], and Sun Ultrasparc 140. number of nodes that receive all components of the output vector from the previous layer.
Reference: [5] <author> E. Chow, T. Hunkapiller, J. Peterson, and M. S. Waterman, </author> <title> "Biological information signal processor," </title> <booktitle> in Proc. Int. Conf. </booktitle> <editor> ASAP (M. Valero et al., eds.), </editor> <publisher> (Los Alamitos, CA), </publisher> <pages> pp. 144-160, </pages> <publisher> IEEE CS, </publisher> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: The standard NN configuration consists of 3 layers (input, hidden, and output), each containing a 5 Machines: BISP (single purpose, not completed) <ref> [5] </ref>, BioSCAN (single purpose) [36], 15-board Decypher-II (FPGA, $173k) [40], 5-board FDF (single purpose, $50k), 16,536-PE MasPar, [34], SAMBA (single purpose) [24], 1- and 2-board Mercury (single purpose) [4], Biocellera-tor (FPGA, about $50k) [7], 1-board Decypher-II ($18k), 32-node Paragon [31], 1024-PE MasPar, 5 DEC Alpha 3000 workstations [31], B-SYS [16], and
Reference: [6] <author> N. H. Christ and A. E. Terrano, </author> <title> "A micro-based supercomputer," </title> <journal> Byte, </journal> <pages> pp. 145-160, </pages> <month> Apr. </month> <year> 1986. </year>
Reference-contexts: The first machine to include SSRs was B-SYS [16], though two earlier machines included shared memory chips, one with a port for each processing element [19], the other with a combination of asynchronous local operation and synchronized shared memory operation to eliminate contention problems <ref> [6] </ref>. SSRs make for an elegant programming model and provide a low-overhead solution to the inter-PE communication problem|the cost is one bit per register address. 2.4: Instruction sequencing The final part of co-processor design is the instruction sequencer and interface to the host workstation.
Reference: [7] <author> Compugen Ltd., </author> <title> "Biocellerator information package." Obtained from compugen@datasrv.co.il, </title> <year> 1994. </year>
Reference-contexts: of 3 layers (input, hidden, and output), each containing a 5 Machines: BISP (single purpose, not completed) [5], BioSCAN (single purpose) [36], 15-board Decypher-II (FPGA, $173k) [40], 5-board FDF (single purpose, $50k), 16,536-PE MasPar, [34], SAMBA (single purpose) [24], 1- and 2-board Mercury (single purpose) [4], Biocellera-tor (FPGA, about $50k) <ref> [7] </ref>, 1-board Decypher-II ($18k), 32-node Paragon [31], 1024-PE MasPar, 5 DEC Alpha 3000 workstations [31], B-SYS [16], and Sun Ultrasparc 140. number of nodes that receive all components of the output vector from the previous layer.
Reference: [8] <author> C. Ebeling, D. C. Conquist, and P. Franklin, </author> <title> RaPiD | Reconfigurable Pipelined Datapath, </title> <journal> pp. </journal> <pages> 126-135. </pages> <address> New York: </address> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference-contexts: Transistor estimates are not yet available. The reference's estimate of fitting 16 cells on a chip running at 100 MHz will allow close to 1.6 million DCTs/sec (8 fi 8 blocks of 8-bit pixels) <ref> [8] </ref>. 8: Conclusions Kestrel steers a course between special-purpose co-processors, reconfigurable-logic systems, and general-purpose supercomputers. Our design grew from an initial desire to build a small, fast, and inexpensive sequence analysis machine into a general purpose parallel accelerator. The design does not exist in a vacuum, however. <p> Its evolution has been shaped in particular by several architectures including B-SYS [16], MasPar [30], Blitzen [2], and the unbuilt MISC machine [33], as well as MGAP and PIM [3, 12]. Contemporaneous sets of design choices can be found with the CNAPS [14], RaPiD <ref> [8] </ref>, Rapid-2 (not related) [9], Samba [24], and SIMPil [10] architectures, among others. The resulting design provides high performance at low cost on its prime target application, biological sequence analysis, as well as on other applications amenable to SIMD parallelization.
Reference: [9] <author> P. Faudemay and L. Winckel, </author> <title> "An abstract model for a low cost SIMD architecture," </title> <booktitle> in Proc. Int. Conf. </booktitle> <address> ASAP, (Los Alamitos, CA), </address> <pages> pp. 145-154, </pages> <publisher> IEEE CS, </publisher> <month> July </month> <year> 1996. </year>
Reference-contexts: Its evolution has been shaped in particular by several architectures including B-SYS [16], MasPar [30], Blitzen [2], and the unbuilt MISC machine [33], as well as MGAP and PIM [3, 12]. Contemporaneous sets of design choices can be found with the CNAPS [14], RaPiD [8], Rapid-2 (not related) <ref> [9] </ref>, Samba [24], and SIMPil [10] architectures, among others. The resulting design provides high performance at low cost on its prime target application, biological sequence analysis, as well as on other applications amenable to SIMD parallelization.
Reference: [10] <author> A. Gentile et al., </author> <title> "Real-time implementation of full-search vector quantization on a low memory SIMD architecture," </title> <booktitle> in IEEE Data Compression Conference, </booktitle> <address> p. 438, </address> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: Contemporaneous sets of design choices can be found with the CNAPS [14], RaPiD [8], Rapid-2 (not related) [9], Samba [24], and SIMPil <ref> [10] </ref> architectures, among others. The resulting design provides high performance at low cost on its prime target application, biological sequence analysis, as well as on other applications amenable to SIMD parallelization.
Reference: [11] <author> M. Gokhale et al., </author> <title> "Building and using a highly parallel programmable logic array," </title> <journal> Computer, </journal> <volume> vol. 24, </volume> <pages> pp. 81-89, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: A reconfigurable machine can be thought of as a SIMD machine with a single exceedingly long instruction that is executed many times <ref> [3, 41, 11] </ref>. Unfortunately, this great flexibility can cause programming to be more difficult than on a true SIMD machine, and can cause a much lower ratio of processing power to area. Alternatively, instructions can be cached at the PE (for a MIMD machine), chip, or board level.
Reference: [12] <author> M. Gokhale et al., </author> <title> "Processing in memory: The Terasys massively parallel PIM array," </title> <journal> Computer, </journal> <volume> vol. 28, </volume> <pages> pp. 23-31, </pages> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: The design does not exist in a vacuum, however. Its evolution has been shaped in particular by several architectures including B-SYS [16], MasPar [30], Blitzen [2], and the unbuilt MISC machine [33], as well as MGAP and PIM <ref> [3, 12] </ref>. Contemporaneous sets of design choices can be found with the CNAPS [14], RaPiD [8], Rapid-2 (not related) [9], Samba [24], and SIMPil [10] architectures, among others.
Reference: [13] <author> J. A. Grice, R. Hughey, and D. Speck, </author> <title> "Reduced space sequence alignment," </title> <journal> CABIOS, </journal> <volume> vol. 13, no. 1, </volume> <pages> pp. 45-53, </pages> <year> 1997. </year>
Reference-contexts: The twin problem of sequence alignment, finding the minimizing correspondence between two sequences, requires the saving of the selector bits of the minimizations and recirculation of sequence data <ref> [13] </ref>. Kestrel's single-board sequence analysis performance is expected to be comparable to both a 16 384-processor MasPar computer and a 15-board FPGA-based system (Figure 3).
Reference: [14] <author> D. W. Hammerstrom and D. P. Lulich, </author> <title> "Image processing using one-dimensional processor arrays," </title> <journal> Proc. IEEE, </journal> <volume> vol. 84, no. 7, </volume> <pages> pp. 1005-1018, </pages> <year> 1996. </year>
Reference-contexts: I/O between the PEs and the controller uses shared 8-bit buses. Inter-PE communication uses a 2-bit bus, and instructions are 31 bits. Parallelism of execution for the different components allows 1 billion 16-bit MAC operations per second <ref> [14] </ref>. MasPar The MasPar MP-2 is a mesh-based SIMD supercomputer-class machine with a global router. Processing elements feature 40 32-bit registers, a 32-bit ALU with functional units to aid floating-point calculation, and a 64 Kbyte off-chip, locally-addressed memory. <p> Its evolution has been shaped in particular by several architectures including B-SYS [16], MasPar [30], Blitzen [2], and the unbuilt MISC machine [33], as well as MGAP and PIM [3, 12]. Contemporaneous sets of design choices can be found with the CNAPS <ref> [14] </ref>, RaPiD [8], Rapid-2 (not related) [9], Samba [24], and SIMPil [10] architectures, among others. The resulting design provides high performance at low cost on its prime target application, biological sequence analysis, as well as on other applications amenable to SIMD parallelization.
Reference: [15] <author> R. Hughey, </author> <title> "Parallel sequence comparison and alignment," </title> <journal> CABIOS, </journal> <volume> vol. 12, no. 6, </volume> <pages> pp. 473-479, </pages> <year> 1996. </year>
Reference-contexts: The inner loop of one common form of sequence analysis requires 21 instructions on Kestrel. Our target single board, 512-PE system running at 33 MHz will perform this application at a speed similar to the vastly more expensive 16 384-processing element Maspar MP-2 <ref> [2, 15] </ref>. 2.2: Instruction broadcast SIMD instruction broadcast can be slow, especially with many processing elements. The typical SIMD instruction memory is centralized for all processing elements to eliminate the overhead of local control. <p> Sequence comparison with affine gap penalties and various other features, greatly preferred by biologists, involves three interconnected recurrences of a similar form [29, 35, 37]. The dynamic programming calculation easily maps to a linear array of processing elements <ref> [15] </ref>. A common mapping is to assign one PE to each character of the query string, and then to shift the database through the linear chain of PEs. <p> Further details on parallel hardware for sequence analysis can be found in two comparative studies <ref> [15, 39] </ref>. 3.2: Neural Networks Neural networks (NNs) [28] have become an tool for pattern recognition and classification tasks.
Reference: [16] <author> R. Hughey and D. P. Lopresti, "B-SYS: </author> <title> A 470-processor programmable systolic array," </title> <booktitle> in Proc. Int. Conf. Parallel Processing (C. </booktitle> <editor> Wu, ed.), </editor> <volume> vol. </volume> <pages> 1, </pages> <address> (Boca Raton, FL), </address> <pages> pp. 580-583, </pages> <publisher> CRC Press, </publisher> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: During a subsequent instruction, each PE can read from its left register file to get the previously-stored value. Because all addresses for these register files are issued globally, adjacent PEs never write to the same register bank. The first machine to include SSRs was B-SYS <ref> [16] </ref>, though two earlier machines included shared memory chips, one with a port for each processing element [19], the other with a combination of asynchronous local operation and synchronized shared memory operation to eliminate contention problems [6]. <p> completed) [5], BioSCAN (single purpose) [36], 15-board Decypher-II (FPGA, $173k) [40], 5-board FDF (single purpose, $50k), 16,536-PE MasPar, [34], SAMBA (single purpose) [24], 1- and 2-board Mercury (single purpose) [4], Biocellera-tor (FPGA, about $50k) [7], 1-board Decypher-II ($18k), 32-node Paragon [31], 1024-PE MasPar, 5 DEC Alpha 3000 workstations [31], B-SYS <ref> [16] </ref>, and Sun Ultrasparc 140. number of nodes that receive all components of the output vector from the previous layer. Each node computes a weighted sum of its inputs, adds a bias, and normalizes the output by the so-called activation function. <p> The ALU is a static CMOS design because operands are not stable until several nanoseconds into phase one. Our desire to keep pin count and instruction width low meant that we could not afford unencoded generate and kill lookup tables, as were used in B-SYS and the OM-2 <ref> [16, 27] </ref>. However, we required symmetric operations. In the Kestrel ALU, Operand A is always a register while Operand B can come from several sources. It would be a tremendous handicap for programmers and compiler writers if A B was supported but not B A. <p> Our design grew from an initial desire to build a small, fast, and inexpensive sequence analysis machine into a general purpose parallel accelerator. The design does not exist in a vacuum, however. Its evolution has been shaped in particular by several architectures including B-SYS <ref> [16] </ref>, MasPar [30], Blitzen [2], and the unbuilt MISC machine [33], as well as MGAP and PIM [3, 12]. Contemporaneous sets of design choices can be found with the CNAPS [14], RaPiD [8], Rapid-2 (not related) [9], Samba [24], and SIMPil [10] architectures, among others.
Reference: [17] <author> Intel Corporation, </author> <title> http://developer.intel.com/drg/mmx/manuals/prm/prm.htm, MMX Technology Developer's Programmer's Reference Manual, </title> <year> 1997. </year>
Reference-contexts: The table displays peak rates for the 200 MHz Pentium MMX; real performance for applications that do not fit in the 8 MMX registers or have data hazards between instructions is likely to be considerably less <ref> [17] </ref>. MGAP The MGAP-2 is a very fine grained architecture. Each chip has 1536 1-bit PEs connected in an octagonal mesh. Each PE has a 16-bit dual-port local storage and two 3-input, 1-output function multiplexers for calculation.
Reference: [18] <author> ISO/IEC, "IS-10918: </author> <title> Compression and coding of continuous-tine still images." </title>
Reference-contexts: training input of 18 000 vectors per second and this number increases to about 50 000 v/s for a more typical case of n 1 = 8, 6 n 2 = 12, and n 3 = 6. 3.3: Discrete Cosine Transform The discrete cosine transform (DCT) and its inverse (IDCT) <ref> [18] </ref>, as part of video compression and decompression standards, process 8 fi 8 arrays either as 8-bit pixels I (x; y) or as 12-bit to 14-bit coefficients a (u; v).
Reference: [19] <author> N. Jagadish, J. M. Kumar, and L. M. Patnaik, </author> <title> "An efficient scheme for interprocessor communication using dual-ported RAMs," </title> <booktitle> IEEE Micro, </booktitle> <pages> pp. 10-19, </pages> <month> Oct. </month> <year> 1989. </year>
Reference-contexts: Because all addresses for these register files are issued globally, adjacent PEs never write to the same register bank. The first machine to include SSRs was B-SYS [16], though two earlier machines included shared memory chips, one with a port for each processing element <ref> [19] </ref>, the other with a combination of asynchronous local operation and synchronized shared memory operation to eliminate contention problems [6].
Reference: [20] <author> T. P. Kelliher, E. S. Gayles, R. M. Owens, and M. J. Irwin, </author> <title> "The MGAP-2: An advanced, massively parallel VLSI signal processor," </title> <booktitle> in Proc. Int. Conf. Acoustics, Speech, Signal Processing, </booktitle> <volume> vol. 5, </volume> <pages> pp. 3219-22, </pages> <publisher> IEEE, </publisher> <month> May </month> <year> 1995. </year>
Reference-contexts: The configuration is stored in a local register but memory access is globally controlled. The system runs at 50 MHz. Performance is 6.8 kDCT/s (8 fi 8 blocks of 8-bit pixels) for the MGAP-2 chip <ref> [20, 21] </ref>. RaPiD The RaPiD system is the most hardware-oriented among these examples: it is a "coarse grained FPGA," with 16 cells per chip arranged in a linear array.
Reference: [21] <author> H.-N. Kim, M. Borah, R. M. Owens, and M. J. Irwin, </author> <title> "2-D discrete cosine transforms on a fine grain array processor," </title> <booktitle> in Proc. VLSI Signal Processing VII, </booktitle> <pages> pp. 356-367, </pages> <publisher> IEEE, </publisher> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: The configuration is stored in a local register but memory access is globally controlled. The system runs at 50 MHz. Performance is 6.8 kDCT/s (8 fi 8 blocks of 8-bit pixels) for the MGAP-2 chip <ref> [20, 21] </ref>. RaPiD The RaPiD system is the most hardware-oriented among these examples: it is a "coarse grained FPGA," with 16 cells per chip arranged in a linear array.
Reference: [22] <author> D. E. Knuth, </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> vol. </volume> <pages> 2. </pages> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <editor> 2nd ed., </editor> <year> 1981. </year>
Reference-contexts: The contents of the MultHi latch can then be read out on the Operand B bus or added to a subsequent multiply. Both Operand C and MultHi can be added internally to the product with no danger of overflow <ref> [22] </ref>. The ability to perform a multiply-accumulate-accumulate greatly speeds multiprecision multiplication (Figure 8). The multiplier packs 2900 transistors in 1 162 075 2 , including bus drivers, operand latches, and control logic. The major design concern was finding an acceptable balance between speed and power consumption.
Reference: [23] <author> A. Krogh, M. Brown, I. S. Mian, K. Sjolander, and D. Haussler, </author> <title> "Hidden Markov models in computational biology: Applications to protein modeling," </title> <journal> J. Mol. Biol., </journal> <volume> vol. 235, </volume> <pages> pp. 1501-1531, </pages> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: Thus, Kestrel has been designed for use with a host of different methods, from the standard Smith and Waterman algorithm [37] to hidden Markov models <ref> [23] </ref>, with many variations in between and yet to come. Our goal, however, has never been to build just a sequence analysis machine.
Reference: [24] <author> D. Lavenier, </author> <title> "SAMBA: Systolic accelerators for molecular biological applications," </title> <type> Tech. Rep. 988, </type> <institution> IRISA, </institution> <address> 35042 Rennes Cedex, France, </address> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: Such storage systems are more in the domain of general-purpose supercomputers than cost-effective parallel co-processors. Second, for many applications, data buffering and recirculating among a small number of high-speed processors can be an effective solution. This idea has been adapted by a number of special-purpose machines <ref> [4, 24, 40] </ref>. 2 Third, programmable processing elements that require several instructions to compute the basic function can be used. This solution, used by Kestrel, essentially allows the addition of programmability into the processing elements with little penalty over the single-purpose system. <p> The standard NN configuration consists of 3 layers (input, hidden, and output), each containing a 5 Machines: BISP (single purpose, not completed) [5], BioSCAN (single purpose) [36], 15-board Decypher-II (FPGA, $173k) [40], 5-board FDF (single purpose, $50k), 16,536-PE MasPar, [34], SAMBA (single purpose) <ref> [24] </ref>, 1- and 2-board Mercury (single purpose) [4], Biocellera-tor (FPGA, about $50k) [7], 1-board Decypher-II ($18k), 32-node Paragon [31], 1024-PE MasPar, 5 DEC Alpha 3000 workstations [31], B-SYS [16], and Sun Ultrasparc 140. number of nodes that receive all components of the output vector from the previous layer. <p> Contemporaneous sets of design choices can be found with the CNAPS [14], RaPiD [8], Rapid-2 (not related) [9], Samba <ref> [24] </ref>, and SIMPil [10] architectures, among others. The resulting design provides high performance at low cost on its prime target application, biological sequence analysis, as well as on other applications amenable to SIMD parallelization.
Reference: [25] <author> C. Lindsey and T. Lindblad, </author> <title> "Review of hardware neural networks: a user's perspective," </title> <booktitle> in Proceedings of the Second Workshop on Neural Networks, Elba International Physics Center, </booktitle> <year> 1994. </year> <note> Updated version (with Bruce Denby) at http://www1.cern.ch/NeuralNets /nnwInHepHard.html. </note>
Reference-contexts: Figure 4 shows decision and input data rates as functions of the vector size and the maximum number of nodes in a layer, respectively. This performance is equal to the performance range of commercial, single-purpose NN chips <ref> [25] </ref>. Training of a neural network by backpropagation uses pipelines of registers in both directions. The input vectors and the intermediate outputs are stored in each node for later use, so that the forward part is split into a transfer and store phase followed by the local MAC operations.
Reference: [26] <author> R. N. Mayo et al., </author> <note> "1990 DECWRL/Livermore Magic Release," Research Report 90/7, </note> <institution> Digital Western Research Laboratory, </institution> <address> Palo Alto, CA, </address> <month> Sept. </month> <year> 1990. </year>
Reference-contexts: The result can be forced to one or the other of these values, or it can be chosen by a flag from the ALU, comparator, bit shifter, or a neighboring PE's bit shifter. 5: Kestrel Design Kestrel's full custom VLSI layout was done using the Magic tool suite <ref> [26] </ref>. With hindsight, a combination of custom layout of the PEs and standard cell for the global logic may have saved some time without incurring high area or power costs. It is only the regularity of the design that enabled the hand layout of 1.4 million transistors.
Reference: [27] <author> C. A. Mead and L. A. Conway, </author> <title> Introduction to VLSI Systems. </title> <address> Reading, MA: </address> <publisher> Addison-Wesley, </publisher> <year> 1980. </year>
Reference-contexts: As register writes can be disabled by the writing PE, mask setup at the register bank must be complete by the beginning of phase two. This means that inter-chip communication occurs during both phases. approximately one half the feature size of the CMOS process <ref> [27] </ref>. The height of the register bank is slightly less than half the height of the PE, so the register banks from the adjacent column can be fit into the extra space by turning the adjacent column sideways, reducing the horizontal pitch of the PE by about 500 . <p> The ALU is a static CMOS design because operands are not stable until several nanoseconds into phase one. Our desire to keep pin count and instruction width low meant that we could not afford unencoded generate and kill lookup tables, as were used in B-SYS and the OM-2 <ref> [16, 27] </ref>. However, we required symmetric operations. In the Kestrel ALU, Operand A is always a register while Operand B can come from several sources. It would be a tremendous handicap for programmers and compiler writers if A B was supported but not B A.
Reference: [28] <editor> K. Mehrotra et al., </editor> <booktitle> Elements of Artificial Neural Networks. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT, </publisher> <year> 1997. </year>
Reference-contexts: Further details on parallel hardware for sequence analysis can be found in two comparative studies [15, 39]. 3.2: Neural Networks Neural networks (NNs) <ref> [28] </ref> have become an tool for pattern recognition and classification tasks.
Reference: [29] <author> S. B. Needleman and C. D. Wunsch, </author> <title> "A general method applicable to the search for similarities in the amino acid sequences of two proteins," </title> <journal> J. Mol. Biol., </journal> <volume> vol. 48, </volume> <pages> pp. 443-453, </pages> <year> 1970. </year>
Reference-contexts: Sequence comparison with affine gap penalties and various other features, greatly preferred by biologists, involves three interconnected recurrences of a similar form <ref> [29, 35, 37] </ref>. The dynamic programming calculation easily maps to a linear array of processing elements [15]. A common mapping is to assign one PE to each character of the query string, and then to shift the database through the linear chain of PEs.
Reference: [30] <author> J. R. Nickolls, </author> <title> "The design of the Maspar MP-1: A cost effective massively parallel computer," </title> <booktitle> in Proc. COMPCON Spring 1990, </booktitle> <address> (Los Alamitos, CA), </address> <pages> pp. 25-28, </pages> <publisher> IEEE Computer Society Press, </publisher> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: Our design grew from an initial desire to build a small, fast, and inexpensive sequence analysis machine into a general purpose parallel accelerator. The design does not exist in a vacuum, however. Its evolution has been shaped in particular by several architectures including B-SYS [16], MasPar <ref> [30] </ref>, Blitzen [2], and the unbuilt MISC machine [33], as well as MGAP and PIM [3, 12]. Contemporaneous sets of design choices can be found with the CNAPS [14], RaPiD [8], Rapid-2 (not related) [9], Samba [24], and SIMPil [10] architectures, among others.
Reference: [31] <author> W. R. Pearson, </author> <type> "Personal communication," </type> <year> 1995. </year>
Reference-contexts: output), each containing a 5 Machines: BISP (single purpose, not completed) [5], BioSCAN (single purpose) [36], 15-board Decypher-II (FPGA, $173k) [40], 5-board FDF (single purpose, $50k), 16,536-PE MasPar, [34], SAMBA (single purpose) [24], 1- and 2-board Mercury (single purpose) [4], Biocellera-tor (FPGA, about $50k) [7], 1-board Decypher-II ($18k), 32-node Paragon <ref> [31] </ref>, 1024-PE MasPar, 5 DEC Alpha 3000 workstations [31], B-SYS [16], and Sun Ultrasparc 140. number of nodes that receive all components of the output vector from the previous layer. <p> purpose, not completed) [5], BioSCAN (single purpose) [36], 15-board Decypher-II (FPGA, $173k) [40], 5-board FDF (single purpose, $50k), 16,536-PE MasPar, [34], SAMBA (single purpose) [24], 1- and 2-board Mercury (single purpose) [4], Biocellera-tor (FPGA, about $50k) [7], 1-board Decypher-II ($18k), 32-node Paragon <ref> [31] </ref>, 1024-PE MasPar, 5 DEC Alpha 3000 workstations [31], B-SYS [16], and Sun Ultrasparc 140. number of nodes that receive all components of the output vector from the previous layer. Each node computes a weighted sum of its inputs, adds a bias, and normalizes the output by the so-called activation function.
Reference: [32] <author> E. Rice and R. Hughey, </author> <title> "Multiprecision division on an 8-bit processor," </title> <booktitle> in Proc. 13th IEEE Symp. Computer Arithmetic, </booktitle> <publisher> IEEE CS, </publisher> <month> July </month> <year> 1997. </year>
Reference-contexts: Among other techniques, we save steps by using low precision arithmetic in the early stages of iteration <ref> [32] </ref>.
Reference: [33] <author> J. D. Roberts, MISC: </author> <title> A parallel architecture for AI. </title> <type> PhD thesis, </type> <institution> University California, </institution> <address> Santa Cruz, CA, </address> <year> 1995. </year>
Reference-contexts: The design does not exist in a vacuum, however. Its evolution has been shaped in particular by several architectures including B-SYS [16], MasPar [30], Blitzen [2], and the unbuilt MISC machine <ref> [33] </ref>, as well as MGAP and PIM [3, 12]. Contemporaneous sets of design choices can be found with the CNAPS [14], RaPiD [8], Rapid-2 (not related) [9], Samba [24], and SIMPil [10] architectures, among others.
Reference: [34] <author> L. Roberts, </author> <title> "New chip may speed genome analysis," </title> <journal> Science, </journal> <volume> vol. 244, </volume> <pages> pp. 655-6, </pages> <month> 12 May </month> <year> 1989. </year>
Reference-contexts: The standard NN configuration consists of 3 layers (input, hidden, and output), each containing a 5 Machines: BISP (single purpose, not completed) [5], BioSCAN (single purpose) [36], 15-board Decypher-II (FPGA, $173k) [40], 5-board FDF (single purpose, $50k), 16,536-PE MasPar, <ref> [34] </ref>, SAMBA (single purpose) [24], 1- and 2-board Mercury (single purpose) [4], Biocellera-tor (FPGA, about $50k) [7], 1-board Decypher-II ($18k), 32-node Paragon [31], 1024-PE MasPar, 5 DEC Alpha 3000 workstations [31], B-SYS [16], and Sun Ultrasparc 140. number of nodes that receive all components of the output vector from the previous
Reference: [35] <author> P. H. Sellers, </author> <title> "On the theory and computation of evolutionary distances," </title> <journal> SIAM J. Appl. Math., </journal> <volume> vol. 26, </volume> <pages> pp. 787-793, </pages> <year> 1974. </year>
Reference-contexts: Sequence comparison with affine gap penalties and various other features, greatly preferred by biologists, involves three interconnected recurrences of a similar form <ref> [29, 35, 37] </ref>. The dynamic programming calculation easily maps to a linear array of processing elements [15]. A common mapping is to assign one PE to each character of the query string, and then to shift the database through the linear chain of PEs.
Reference: [36] <author> R. Singh et al., </author> <title> "A scalable systolic multiprocessor system for biosequence similarity analysis," </title> <booktitle> in Symp. Integrated Systems (L. Snyder, </booktitle> <publisher> ed.), </publisher> <pages> pp. 169-181, </pages> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <month> Apr. </month> <year> 1993. </year>
Reference-contexts: The one system expected to be significantly faster than Kestrel is the BioSCAN machine, a single-purpose machine that calculates scores for ungapped alignment segments (c i;j = c i1;j1 + dist a i ; b j ), and then performs statistical post-processing to gauge similarity <ref> [36] </ref>. Further details on parallel hardware for sequence analysis can be found in two comparative studies [15, 39]. 3.2: Neural Networks Neural networks (NNs) [28] have become an tool for pattern recognition and classification tasks. <p> The standard NN configuration consists of 3 layers (input, hidden, and output), each containing a 5 Machines: BISP (single purpose, not completed) [5], BioSCAN (single purpose) <ref> [36] </ref>, 15-board Decypher-II (FPGA, $173k) [40], 5-board FDF (single purpose, $50k), 16,536-PE MasPar, [34], SAMBA (single purpose) [24], 1- and 2-board Mercury (single purpose) [4], Biocellera-tor (FPGA, about $50k) [7], 1-board Decypher-II ($18k), 32-node Paragon [31], 1024-PE MasPar, 5 DEC Alpha 3000 workstations [31], B-SYS [16], and Sun Ultrasparc 140. number
Reference: [37] <author> T. F. Smith and M. S. Waterman, </author> <title> "Identification of common molecular subsequences," </title> <journal> J. Mol. Biol., </journal> <volume> vol. 147, </volume> <pages> pp. 195-197, </pages> <year> 1981. </year>
Reference-contexts: Thus, Kestrel has been designed for use with a host of different methods, from the standard Smith and Waterman algorithm <ref> [37] </ref> to hidden Markov models [23], with many variations in between and yet to come. Our goal, however, has never been to build just a sequence analysis machine. <p> Sequence comparison with affine gap penalties and various other features, greatly preferred by biologists, involves three interconnected recurrences of a similar form <ref> [29, 35, 37] </ref>. The dynamic programming calculation easily maps to a linear array of processing elements [15]. A common mapping is to assign one PE to each character of the query string, and then to shift the database through the linear chain of PEs.
Reference: [38] <institution> Telenor Research and Development, </institution> <note> "H.263 software version 2.0," 1996. Available from http://www.fou.telenor.no/brukere/DVC/h263 software/. </note>
Reference-contexts: According to the equation, each element would need 64 multiply and accumulate operations, but more efficient algorithms similar to FFT exist. Our implementation was derived from the Telenor H.263 software distribution <ref> [38] </ref> and averages 9.5 additions, 6 multiplications and 2 scaling operations per pixel. It would be tempting to implement the DCT in pipelined fashion, shifting in a pixel stream and doing the MAC operations on the coefficients while shifting them toward the output.
Reference: [39] <author> T. A. Thanaraj and T. Flores, </author> <title> "Assessment of Smith-Waterman sequence search tools implemented in Biocellerator, FDF, and MasPar," </title> <type> tech. rep., </type> <institution> European Bioinformatics Institute, Wellcome Trust Genome Campus, </institution> <address> Hinxton, Cambridge, </address> <month> Feb. </month> <year> 1997. </year> <note> Available from http://industry.ebi.ac.uk/~thanaraj/seqassess/report.html. </note>
Reference-contexts: Further details on parallel hardware for sequence analysis can be found in two comparative studies <ref> [15, 39] </ref>. 3.2: Neural Networks Neural networks (NNs) [28] have become an tool for pattern recognition and classification tasks.
Reference: [40] <institution> Time Logic Inc., "Decypher II product literature." </institution> <address> Incline Village, NV, http://www.timelogic.com, 1996. </address>
Reference-contexts: Such storage systems are more in the domain of general-purpose supercomputers than cost-effective parallel co-processors. Second, for many applications, data buffering and recirculating among a small number of high-speed processors can be an effective solution. This idea has been adapted by a number of special-purpose machines <ref> [4, 24, 40] </ref>. 2 Third, programmable processing elements that require several instructions to compute the basic function can be used. This solution, used by Kestrel, essentially allows the addition of programmability into the processing elements with little penalty over the single-purpose system. <p> The standard NN configuration consists of 3 layers (input, hidden, and output), each containing a 5 Machines: BISP (single purpose, not completed) [5], BioSCAN (single purpose) [36], 15-board Decypher-II (FPGA, $173k) <ref> [40] </ref>, 5-board FDF (single purpose, $50k), 16,536-PE MasPar, [34], SAMBA (single purpose) [24], 1- and 2-board Mercury (single purpose) [4], Biocellera-tor (FPGA, about $50k) [7], 1-board Decypher-II ($18k), 32-node Paragon [31], 1024-PE MasPar, 5 DEC Alpha 3000 workstations [31], B-SYS [16], and Sun Ultrasparc 140. number of nodes that receive all
Reference: [41] <author> J. E. Vuillemin, P. Bertin, D. Roncin, M. Shand, et al., </author> <title> "Programmable active memories: reconfigurable systems come of age," </title> <journal> IEEE Trans. VLSI Systems, </journal> <volume> vol. 4, no. 1, </volume> <pages> pp. 56-69, </pages> <year> 1996. </year>
Reference-contexts: A reconfigurable machine can be thought of as a SIMD machine with a single exceedingly long instruction that is executed many times <ref> [3, 41, 11] </ref>. Unfortunately, this great flexibility can cause programming to be more difficult than on a true SIMD machine, and can cause a much lower ratio of processing power to area. Alternatively, instructions can be cached at the PE (for a MIMD machine), chip, or board level.
References-found: 41

