URL: ftp://ftp.cs.rochester.edu/pub/papers/robotics/94.tr487.Seeing_behind_occlusions.somefigs.ps.Z
Refering-URL: http://www.cs.rochester.edu/u/rao/papers.html
Root-URL: 
Title: Seeing Behind Occlusions  
Author: Dana H. Ballard and Rajesh P.N. Rao 
Date: February 1994  
Address: Rochester, New York 14627  
Affiliation: The University of Rochester Computer Science Department  
Pubnum: Technical Report 487  
Abstract: The location of objects in images is difficult owing to the view variance of geometric features but can be determined by developing view-insensitive descriptions of the intensities local to image points. View-insensitive descriptions are achieved in this work by describing points in terms of the responses of steerable filters at multiple scales. Owing to the use of multiple scales, the vector for each point is, for all practical purposes, unique, and thus can be easily matched to other instances of the point in other images. We show that this method can be extended to handle the case where the area near a point of interest is partially occluded. The method uses a description of the occluder in the form of a template that can be obtained easily via active vision systems using a method such as disparity filtering. This research is supported by the Human Science Frontiers Program research grant and by the National Science Foundation under NSF research grant no. CDA-8822724. This report is a slightly enlarged version of a paper accepted at the Third European Conference on Computer Vision (ECCV), Stockholm, Sweden, May 1994. 
Abstract-found: 1
Intro-found: 1
Reference: [Ballard, 1989] <author> D. H. Ballard, </author> <title> "Behavioral constraints on animate vision," </title> <journal> Image and Vision Computing, </journal> <volume> 7(1) </volume> <pages> 3-9, </pages> <month> February </month> <year> 1989. </year>
Reference: [Ballard and Wixson, 1993] <author> Dana H. Ballard and Lambert E. Wixson, </author> <title> "Object Recognition Using Steerable Filters at Multiple Scales," </title> <booktitle> In Proceedings of the IEEE Workshop on Qualitative Vision, </booktitle> <year> 1993. </year>
Reference-contexts: Image color as a measure of surface albedo is insensitive to variations in viewing direction. Swain used color for object recognition problems by exploiting properties of the color histogram [Swain, 1990; Swain and Ballard, 1991]. Previously we have shown that geometric features can be found that behave like color <ref> [Ballard and Wixson, 1993] </ref>. These are the steerable filters [Freeman and Adelson, 1991; Jones and Malik, 1992; Malik and Perona, 1989]. Such filters are a way of describing the intensities near a given point.
Reference: [Ballard, 1991] <author> D.H. Ballard, </author> <title> "Animate vision," </title> <journal> Artificial Intelligence, </journal> <volume> 48 </volume> <pages> 57-86, </pages> <year> 1991. </year>
Reference-contexts: In one instance the face is painted on a picket fence; in the other it is behind the picket fence. The results show that identification is improved in the latter case. This observation forms the inspiration for our solution. Suppose that an active imaging system is used <ref> [Ballard, 1991] </ref>. As a consequence we can assume that the occluder can be detected by a method such as disparity filtering [Coombs and Brown, 1992]. Disparity filtering is a way of creating a filter that only passes image energy in the horopter.
Reference: [Coombs and Brown, 1992] <author> D.J. Coombs and C.M. Brown, </author> <title> "Real-time smooth pursuit tracking for a moving binocular head," </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 23-38, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The results show that identification is improved in the latter case. This observation forms the inspiration for our solution. Suppose that an active imaging system is used [Ballard, 1991]. As a consequence we can assume that the occluder can be detected by a method such as disparity filtering <ref> [Coombs and Brown, 1992] </ref>. Disparity filtering is a way of creating a filter that only passes image energy in the horopter. Ideally one can create a template T (x; y) such that T (x; y) = 1 for material in the horopter and T (x; y) = 0 otherwise.
Reference: [Danielsson and Seger, 1990] <author> P.E. Danielsson and O. Seger, </author> <title> "Rotation invariance in gradient and higher derivative detectors," Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 49(2), </volume> <month> February </month> <year> 1990. </year>
Reference: [D.J. Fleet and Jenkin, 1991] <editor> A.D. Jepson D.J. Fleet and M.R.M. Jenkin, </editor> <booktitle> "Phase-based disparity measurement," CVGIP Image Understanding, </booktitle> <volume> 53(2) </volume> <pages> 198-210, </pages> <month> March </month> <year> 1991. </year>
Reference: [Fleet and Jepson, 1985] <author> D.J. Fleet and A.D. Jepson, </author> <title> "On the hierarchical construction of orientation and velocity selective filters," </title> <type> Technical Report RBCV-TR-85-8, </type> <institution> Computer Science Dept., University of Toronto, </institution> <month> November </month> <year> 1985. </year>
Reference: [Freeman and Adelson, 1991] <author> William T. Freeman and Edward H. Adelson, </author> <title> "The Design and Use of Steerable Filters," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(9) </volume> <pages> 891-906, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: As shown by Freeman and Adelson <ref> [Freeman and Adelson, 1991] </ref>, starting from a symmetric Gaussian function in Cartesian coordinates: G (x; y) = e (x 2 +y 2 ) it is possible to define basis filters G n n as: n = @ n 2.1 The Interpolation Functions As Freeman and Adelson [Freeman and Adelson, 1991] have <p> by Freeman and Adelson <ref> [Freeman and Adelson, 1991] </ref>, starting from a symmetric Gaussian function in Cartesian coordinates: G (x; y) = e (x 2 +y 2 ) it is possible to define basis filters G n n as: n = @ n 2.1 The Interpolation Functions As Freeman and Adelson [Freeman and Adelson, 1991] have also shown, different order filters are steered with different interpolation functions. The number of the interpolation functions that are needed for the steering is one more than the filter order.
Reference: [Frei and Chen, 1977] <author> W. Frei and C.-C. Chen, </author> <title> "Fast boundary detection: A generalization and a new algorithm," </title> <journal> IEEE Trans. on Computers, </journal> <volume> 26(10) </volume> <pages> 988-998, </pages> <month> October </month> <year> 1977. </year>
Reference: [Heeger and Jepson, 1990] <author> D.J. Heeger and A.D. Jepson, </author> <title> "Simple method for computing 3d motion and depth," </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <year> 1990. </year>
Reference: [Jones and Malik, 1992] <author> David G. Jones and Jitendra Malik, </author> <title> "A Computational Framework for Determining Stereo Correspondence from a Set of Linear Spatial Filters," </title> <booktitle> In Proceedings of the Second European Conference on Computer Vision, </booktitle> <year> 1992. </year>
Reference-contexts: As a consequence the image intensities near every point can be reconstructed by appropriately combining the responses and filter functions. As the functions are not orthogonal, a pseudo-inverse must be used to do this <ref> [Jones and Malik, 1992] </ref>. This ability to reconstruct the local intensities allows the stored prototype to be made comparable to the occluded image responses. For every point, the reconstructed image intensities are appropriately masked using the occluding template. A similar process is done to the incoming image.
Reference: [Malik and Perona, 1989] <author> Jitendra Malik and Pietro Perona, </author> <title> "A computational model of texture segmentation," </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 326-332, </pages> <month> June </month> <year> 1989. </year>
Reference: [Murase and Nayar, 1993] <author> H. Murase and S.K. Nayar, </author> <title> "Learning and recognition of 3-D objects from brightness images," </title> <booktitle> Working Notes, AAAI Fall Symp. Series (Machine Learning in Computer Vision: What, Why, and How?), </booktitle> <pages> pages 25-29, </pages> <month> October </month> <year> 1993. </year> <month> 12 </month>
Reference-contexts: Thus the use of the template can be seen as merely an extension of the steps in the backprojection algorithm. The idea of basis functions makes it suitable for instantaneously acquiring new points. This makes it different than principal components methods <ref> [Murase and Nayar, 1993] </ref>. But most important, as the principal components do not have an inverse, the occlusion strategy described herein could not be used.
Reference: [Nakayama and Shimojo, 1990] <author> K. Nakayama and S. Shimojo, </author> <title> "Towards a neural under-standing of visual surface representation," </title> <booktitle> Cold Spring Harbor Symp. on Quantitative Biology, </booktitle> <volume> Vol. </volume> <month> 55, </month> <title> The Brain, edited by T. Sejnowski, E.R. </title> <type> Kandel, C.F. </type> <institution> Stevens, and J.D. Watson, </institution> <year> 1990. </year>
Reference: [Poggio and Girosi, 1990] <author> T. Poggio and F. Girosi, </author> <title> "AI Memo 1140, AI Lab, </title> <publisher> MIT, </publisher> <year> 1989;," </year> <booktitle> Proc. IEEE, </booktitle> <address> 78:1481, </address> <year> 1990. </year>
Reference: [Swain, 1990] <author> Michael J. Swain, </author> <title> "Color Indexing," </title> <type> Technical Report 360, </type> <institution> University of Rochester Computer Science Dept., </institution> <year> 1990. </year>
Reference-contexts: Instead, image features are required to be only relatively insensitive to variations in the view. Such a feature is color. Image color as a measure of surface albedo is insensitive to variations in viewing direction. Swain used color for object recognition problems by exploiting properties of the color histogram <ref> [Swain, 1990; Swain and Ballard, 1991] </ref>. Previously we have shown that geometric features can be found that behave like color [Ballard and Wixson, 1993]. These are the steerable filters [Freeman and Adelson, 1991; Jones and Malik, 1992; Malik and Perona, 1989].
Reference: [Swain and Ballard, 1991] <author> Michael J. Swain and Dana H. Ballard, </author> <title> "Color Indexing," </title> <journal> International Journal of Computer Vision, </journal> <volume> 7 </volume> <pages> 11-32, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: Instead, image features are required to be only relatively insensitive to variations in the view. Such a feature is color. Image color as a measure of surface albedo is insensitive to variations in viewing direction. Swain used color for object recognition problems by exploiting properties of the color histogram <ref> [Swain, 1990; Swain and Ballard, 1991] </ref>. Previously we have shown that geometric features can be found that behave like color [Ballard and Wixson, 1993]. These are the steerable filters [Freeman and Adelson, 1991; Jones and Malik, 1992; Malik and Perona, 1989].
Reference: [Wilkes and Tsotsos, 1992] <author> David Wilkes and John K. Tsotsos, </author> <title> "Active Object Recognition," </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <month> June </month> <year> 1992. </year>
Reference: [Wiskott and von der Malsburg, 1992] <author> L. Wiskott and C. von der Malsburg, </author> <title> "A neural system for the recognition of partially occluded objects in cluttered scenes," </title> <type> Tr, </type> <institution> Inst. fur Neuroinformatik, </institution> <address> Ruhr-Universitat Bochum, </address> <year> 1992. </year> <month> 13 </month>
Reference-contexts: The filters method has a further advantage over such methods in that the long feature vector formed by the steerable filter responses is robust to noise in some filter channels. The occlusion strategy could be used in a more complicated graph-matching strategy such as that of <ref> [Wiskott and von der Malsburg, 1992] </ref>, which also uses multi-resolution filters, but that would require additional computational machinery. The multi-resolution structure of the filters has the additional advantage that the low-resolution components can be used in a variable resolution imaging system similar to the human retina.
References-found: 19

