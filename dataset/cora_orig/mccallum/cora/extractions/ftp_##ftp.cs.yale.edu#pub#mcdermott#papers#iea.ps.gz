URL: ftp://ftp.cs.yale.edu/pub/mcdermott/papers/iea.ps.gz
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/mcdermott.html
Root-URL: http://www.cs.yale.edu
Email: e-mail: mcdermott@cs.yale.edu  
Phone: phone: 203-432-1281 fax: 203-432-0593  
Title: THE CURRENT STATE OF AI PLANNING RESEARCH  
Author: Drew McDermott 
Address: 51 Prospect Street, P.O. Box 808285 New Haven, CT 06520-8285  
Affiliation: Yale Computer Science Department  
Abstract: Planning is designing the behavior of an agent. The classical theory of planning assumes that the planner has perfect information, and needs to bring about a definite result, by finding a series of actions that brings it about. These classical assumptions have been questioned, but are quite reasonable for many engineering applications. The problem is that traditional algorithms, while elegant, are not effective on realistic-sized problems. Recently some more promising algorithms have been developed, based on avoiding costly searches by doing a more exhaustive analysis at each search state. However, these algorithms may still not be ready for the kinds of problems that arise in manufacturing and other domains where real geometry and kinematics are important. 
Abstract-found: 1
Intro-found: 1
Reference: [BF95] <author> Avrim L. Blum and Merrick L. Furst. </author> <title> Fast planning through planning graph analysis. </title> <booktitle> In Proc. Ijcai, </booktitle> <year> 1995. </year>
Reference-contexts: What I would like to do from here on out is talk about a couple of ideas that depart fairly radically from the "tradition" in this area. One of these is due to me [McD96], the other to Blum and Furst <ref> [BF95] </ref>. Each seems to show some promise in overcoming the combinatorial explosion that arises in classical planning. (Of course, the explosions cannot be eliminated completely, because the planning problem is NP-complete [ENS95].) Although they were developed independently, they bear some interesting similarities. <p> It deals better with addition than with deletion of literals, and in particular is fooled when a deletion becomes inevitable, but it requires an exploration of an exponential number of plan prefixes to prove that it is inevitable. The algorithm of Blum and Furst <ref> [BF95] </ref> is even more divergent from the planning mainstream, and it is not yet clear just which planning problems it works well on. One feature that puts it out of the mainstream is that it does not simply search a space of partial plans.
Reference: [BW94] <author> Anthony Barrett and Daniel S. Weld. </author> <title> Partial-order planning: evaluating possible efficiency gains. </title> <booktitle> Artificial Intelligence , 67(1) </booktitle> <pages> 71-112, </pages> <year> 1994. </year>
Reference-contexts: In the figure, the planner is considering a three-step plan (not counting the dummy START and END steps), but it has not picked a total ordering for the steps. In some cases <ref> [BW94] </ref>, this THE CURRENT STATE OF PLANNING ability to postpone ordering decisions can make a big difference to efficiency. Each of these traditions is alive and well. Each camp is enthusiastic about its own approach, and critical of the other camp's.
Reference: [ENS95] <author> Kutluhan Erol, Dana Nau, </author> <title> and V.S. Subrahmanian. Complexity, decidabil-ity and undecidability results for domain-independent planning. </title> <editor> In Drew McDermott and James Hendler, </editor> <title> editors, </title> <journal> Artificial Intelligence 76, Special Issue on Planning and Scheduling, </journal> <pages> pages 75-88. NIL, </pages> <year> 1995. </year>
Reference-contexts: One of these is due to me [McD96], the other to Blum and Furst [BF95]. Each seems to show some promise in overcoming the combinatorial explosion that arises in classical planning. (Of course, the explosions cannot be eliminated completely, because the planning problem is NP-complete <ref> [ENS95] </ref>.) Although they were developed independently, they bear some interesting similarities. Both seem to take off in directions that are counterintuitive to AI researchers, which may say something about our intuitions.
Reference: [FN71] <author> Richard Fikes and Nils J. Nilsson. </author> <title> Strips: A new approach to the application of theorem proving to problem solving. </title> <booktitle> Artificial Intelligence 2, </booktitle> <pages> pages 189-208, </pages> <year> 1971. </year>
Reference-contexts: To produce the description of the situation following an action, we delete the formulas flagged with "Del:," and add the formulas flagged with "Add:" (with variables suitably substituted). All other formulas remain the same. This idea, of course, goes back to the Strips planner <ref> [FN71] </ref>. We are given an initial-situation description and a goal formula. We can find an action sequence from one to the other by working forward or backward. <p> See Figure 1. Some planners include only one of these elements, and some include both. The two dominant traditions might be characterized thus: * The GPS-Strips-Prodigy tradition <ref> [NS61, FN71, FV94] </ref>: A search state has both elements, as in Figure reffig:plansearch.
Reference: [FV94] <author> Eugene Fink and Manuela Veloso. </author> <title> Prodigy planning algorithm. </title> <type> Technical Report 94-123, </type> <institution> CMU School of Computer Science, </institution> <year> 1994. </year>
Reference-contexts: See Figure 1. Some planners include only one of these elements, and some include both. The two dominant traditions might be characterized thus: * The GPS-Strips-Prodigy tradition <ref> [NS61, FN71, FV94] </ref>: A search state has both elements, as in Figure reffig:plansearch.
Reference: [Kam95] <author> Subbarao Kambhampati. </author> <title> Universal classical planner: an algorithm for unifying state-space and plan-space planning. </title> <booktitle> In Proc. </booktitle> <address> AAAI-95, </address> <year> 1995. </year>
Reference-contexts: There are two kinds of operator: Committing to an action to achieve a goal, and imposing ordering relationships among steps to exploit or avoid interactions. It is agued in <ref> [Kam95] </ref> that the difference between these two traditions is superficial, but I believe there is a profound distinction between the two, based on the fact that in the first style of planning, there is a current situation, resulting from the plan prefix already committed to, and in the second style there
Reference: [KKY95] <author> Subbarao Kambhampati, Craig A. Knoblock, and Qiang Yang. </author> <title> Planning as refinement search: a unified framework for evaluating design tradeoffs in partial-order planning. </title> <editor> In Drew McDermott and James Hendler, </editor> <title> editors, </title> <journal> Artificial Intelligence 76, Special Issue on Planning and Scheduling, </journal> <pages> pages 167-238. NIL, </pages> <year> 1995. </year>
Reference-contexts: My own work starts from the observation that the standard planning algorithms are curiously deficient in a key area: the heuristic estimator. One can read many planning papers without ever seeing a mention of search control. Even then, the focus is often on strategies for ordering alternative operators (e.g., <ref> [KKY95] </ref>). Almost no attention is given to the question: How do you measure whether one partial plan is more promising than another? That's why our planners get so lost on problems like those in the Manhattan world. There are so many possibilities, and they all look alike.
Reference: [MH69] <author> John McCarthy and Patrick Hayes. </author> <title> Some philosophical problems from the standpoint of artificial intelligence. </title> <editor> In Bernard Meltzer and Donald Michie, editors, </editor> <booktitle> Machine Intelligence 4, </booktitle> <pages> pages 463-502. </pages> <publisher> Edinburgh University Press, </publisher> <year> 1969. </year>
Reference-contexts: But even ignoring that issue, the representation may be too simple. I will come back to this problem later. Action schemas bear a superficial resemblance to predicate-calculus descriptions of actions, using the situation calculus <ref> [MH69] </ref>. However, we are not going to use them deductively. Instead, we treat them, not as axioms for use in deducing properties of situations, but as specification of how to edit situation de scriptions. We assume that we are given a complete description of an initial situation.
Reference: [McD96] <author> Drew McDermott. </author> <title> A Heuristic Estimator for Means-ends Analysis in Planning. </title> <booktitle> In Proc. International Conference on AI Planning Systems 3, </booktitle> <year> 1996. </year>
Reference-contexts: This domain is simple, but is bordering on being realistic. One could imagine a factory-delivery robot whose world model would not be too different from this. A problem in this domain is as shown in Figure 3, which is borrowed from <ref> [McD96] </ref>. The robot needs to get dk, the diamond-shaped key at location h2; 1i to location h3; 0i. Unfortunately, the destination is surrounded by locked intersections. So the robot will have to use a key to open one of them. <p> What I would like to do from here on out is talk about a couple of ideas that depart fairly radically from the "tradition" in this area. One of these is due to me <ref> [McD96] </ref>, the other to Blum and Furst [BF95]. Each seems to show some promise in overcoming the combinatorial explosion that arises in classical planning. (Of course, the explosions cannot be eliminated completely, because the planning problem is NP-complete [ENS95].) Although they were developed independently, they bear some interesting similarities. <p> In this case the estimated effort for the top goal is 3, which is correct. In other cases, the estimate can be too high or too low. I don't have space in this paper to go into details about this structure. Please see <ref> [McD96] </ref> for those details.
Reference: [MH95] <author> Drew McDermott and James Hendler. </author> <title> Planning: What it is, what it could be. </title> <journal> Artificial Intelligence (1-2), </journal> <volume> 76 </volume> <pages> 1-16, </pages> <year> 1995. </year>
Reference-contexts: There is still a gap between theory and practice. Closing it is a challenging but worthwhile project. Acknowledgements: Many of my ideas on planning have been worked out in collaboration with Jim Hendler <ref> [MH95] </ref>. Some of the figures in this paper were used in an unpublished talk at the AI Planning Systems Conference, 1994.
Reference: [MR91] <author> David McAllester and David Rosenblitt. </author> <title> Systematic nonlinear planning. </title> <booktitle> In Proc. AAAI 9, </booktitle> <pages> pages 634-639, </pages> <year> 1991. </year> <title> THE CURRENT STATE OF PLANNING </title>
Reference-contexts: There are two kinds of operator in the search space: committing to an action in the plan prefix, and committing to an action (and new precondition goals) in the goal network. * The Nonlin-SNLP-Ucpop tradition <ref> [Tat77, MR91, PW92] </ref>: A search state consists only of a goal network. There are two kinds of operator: Committing to an action to achieve a goal, and imposing ordering relationships among steps to exploit or avoid interactions.
Reference: [NS61] <author> Allen Newell and Herbert Simon. </author> <title> GPS: a program that simulates human thought. </title> <booktitle> In Lernende Automaten, </booktitle> <pages> pages 279-293. </pages> <note> R. Oldenbourg KG. Reprinted in Feigenbaum and Feldman 1963, </note> <year> 1961. </year>
Reference-contexts: See Figure 1. Some planners include only one of these elements, and some include both. The two dominant traditions might be characterized thus: * The GPS-Strips-Prodigy tradition <ref> [NS61, FN71, FV94] </ref>: A search state has both elements, as in Figure reffig:plansearch. <p> Regressing through the action specification gives the precondition in (ob,?lathe) ^ on (?lathe). If the object is already known to be in a certain lathe, L1, then we can bind lathe = L1, and treat on (L1) as a difference to be reduced (using GPS terminology <ref> [NS61] </ref>). It's at this point that the GPS-Strips-Prodigy tradition continues by considering all possible ways to bind the variables, and by exploring them using goal networks. But we have a more humble aim: we want merely to estimate how many actions it will take to achieve the goal.
Reference: [Ped89] <author> Edwin Peter Dawson Pednault. </author> <title> ADL: Exploring the middle ground between Strips and the situation calculus. </title> <booktitle> In Proc. Conf. on Knowledge Representation and Reasoning 1, </booktitle> <pages> pages 324-332, </pages> <year> 1989. </year>
Reference-contexts: Second, if you want to avoid changing the color of an object, you may want to take it out of a container that is going to be spray-painted. Following <ref> [Ped89] </ref>, we say that in (y,x) is a causation precondition of color (y,c) before spray paint (x,c); and :in (y,x) is a preservation precondition of :color (y,c) before that same action. We use the term secondary preconditions to denote both kinds.
Reference: [PW92] <author> J. Scott Penberthy and Daniel S. Weld. Ucpop: </author> <title> A sound, complete, partial order planner for ADL. </title> <booktitle> In Proceedings, Conf. on Knowedge Representation and Reasoning 3, </booktitle> <year> 1992. </year>
Reference-contexts: There are two kinds of operator in the search space: committing to an action in the plan prefix, and committing to an action (and new precondition goals) in the goal network. * The Nonlin-SNLP-Ucpop tradition <ref> [Tat77, MR91, PW92] </ref>: A search state consists only of a goal network. There are two kinds of operator: Committing to an action to achieve a goal, and imposing ordering relationships among steps to exploit or avoid interactions.
Reference: [Tat77] <author> Austin Tate. </author> <title> Generating project networks. </title> <booktitle> In Proc. IJCAI 5, </booktitle> <pages> pages 888-893, </pages> <year> 1977. </year>
Reference-contexts: There are two kinds of operator in the search space: committing to an action in the plan prefix, and committing to an action (and new precondition goals) in the goal network. * The Nonlin-SNLP-Ucpop tradition <ref> [Tat77, MR91, PW92] </ref>: A search state consists only of a goal network. There are two kinds of operator: Committing to an action to achieve a goal, and imposing ordering relationships among steps to exploit or avoid interactions.
References-found: 15

