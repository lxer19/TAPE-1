URL: http://neurobotics.bu.edu/conferences/CIRA98/paper/biofinal.ps.gz
Refering-URL: http://neurobotics.bu.edu/conferences/CIRA98/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: hneumanng@neuro.informatik.uni-ulm.de  
Title: Real-Time Navigation and Obstacle Avoidance from Optical Flow on a Space-Variant Map  
Author: Gregory Baratoff Christian Toepfer Moritz Wende, Heiko Neumann 
Keyword: real-time robot navigation, optical flow, complex-logarithmic mapping, purposive representation  
Address: 89069 Ulm, Germany fbaratoff, ct, mwende,  
Affiliation: Department of Neural Information Processing University of Ulm  
Abstract: Navigation and obstacle avoidance belong to the basic behavioral repertoire of any biological or technical autonomous agent. A moving observer equipped with a monocular visual sensor can gain information pertinent for the performance of these tasks from the optical flow field induced by its own motion. In the periphery of the visual field image flow can be evaluated for speed and direction control, whereas the central flow indicates imminent collisions. We show that a space-variant mapping augmented with a purposive representation of the environment allows a robot to take into account these structural properties of the flow field and to navigate in real-time in an unknown environment. We implemented an extended simulation environment, and verified reliability, speed, control and robustness of our proposed scheme. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Aloimonos. </author> <title> Purposive and qualitative active vision. </title> <booktitle> In Image Understanding Workshop, </booktitle> <pages> pages 816-828, </pages> <year> 1990. </year>
Reference-contexts: This has been the traditional path taken in Computer Vision for many years. Recently, however, it has been realized that it is more efficient and robust to extract only so-called purposive representations <ref> [1] </ref>, i.e. parameters that are relevant to the particular task and behavioral constraints at hand. Following this idea, we base the navigation behavior of our robot on three parameters : a TTC value for the central region, and two representative flow vectors for the left and right periphery.
Reference: [2] <author> Y. Aloimonos. </author> <title> Is visual reconstruction necessary?: Obstacle avoidance without passive ranging. </title> <journal> J. of Robotics Systems, </journal> <volume> 9(6) </volume> <pages> 843-858, </pages> <year> 1992. </year>
Reference-contexts: The optical flow field induced by the robot's motion can be used for this navigational task without an internal reconstruction of the 3D environment <ref> [2] </ref>. The development of such optical flow based control schemes has been influenced by the sci entific investigation of navigational tasks and control mechanisms in insects [15]. These tasks are part of a hierarchy of visually oriented behaviors.
Reference: [3] <author> S. Amari. </author> <title> Dynamics of pattern formation in lateral-inhibition type neural fields. </title> <journal> Biol. Cybernetics, </journal> <volume> 27 </volume> <pages> 77-87, </pages> <year> 1977. </year>
Reference-contexts: Secondly, we are investigating ways in which our currently crude controller could be replaced by one based on Amari competitive fields <ref> [3] </ref>. This would allow a smoother control of the robot's behavior and would serve as a common data format for the integration of different sensory and command channels. Thirdly, we are incorporating the additional visual ability of determining the robot's heading direction and its rotation, i.e. its egomotion.
Reference: [4] <author> V. </author> <title> Braitenberg. Vehicles: Experiments in synthetic psychology. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1984. </year>
Reference-contexts: 1 Motivation Insights into successful mechanisms of sensory processing and motor behavior in biological and artificial systems can be obtained from the study of various aspects of the perception-action-cycle <ref> [4, 9] </ref>. In our investigation, a simulated mobile robot explores its environment with the primary task to follow corridors and to avoid collisions utilizing only a monochromatic camera fixed to the robot's base.
Reference: [5] <author> H. Bulthoff, J. Little, and T. Poggio. </author> <title> A parallel algorithm for real-time computation of optical flow. </title> <journal> Nature, </journal> <volume> 337(6207) </volume> <pages> 549-553, </pages> <year> 1989. </year>
Reference-contexts: Furthermore, we chose a = 1 which guarantees that the resolution is not reduced at the origin. 1 To estimate the flow in the Logmap we implemented Little's biologically inspired correlation-based algorithm <ref> [5] </ref>. We added a time stack of past Logmap images in the central region to achieve a flow field with sub-pixel precision.
Reference: [6] <author> T. A. Camus. </author> <title> Real-Time Optical Flow. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Brown University, </institution> <year> 1994. </year>
Reference-contexts: This is particularly useful considering the small size of the flow vectors on which TTC computation is based <ref> [6] </ref>. In the peripheral regions, flow vectors are still large enough so that we only store the last image, but have a bigger, one-dimensional spatial search area (e.g. 1 x 10 Logmap pixel). Our algorithm (implemented in C) achieves real-time performance on a Sun Ultra 1 with 167 MHz.
Reference: [7] <author> D. Coombs, M. Herman, T. Hong, and M. Nashman. </author> <title> Real-time obstacle avoidance using central flow divergence and peripheral flow. </title> <booktitle> In Fifth Int. Conf. on Computer Vision, </booktitle> <pages> pages 276-283, </pages> <address> Los Alamitos, CA, </address> <year> 1995. </year>
Reference-contexts: At the lower end of this hierarchy, two basic tasks can be realized with the data available in the optical flow field <ref> [7] </ref>: (1) Corridor following through balancing of the flow fields in the left and right peripheral regions of the image representation; (2) Collision avoidance through evaluation of time to contact (TTC) in the central region of the image. In section 2, we review the flow field in these situations. <p> Following this idea, we base the navigation behavior of our robot on three parameters : a TTC value for the central region, and two representative flow vectors for the left and right periphery. This is also the approach taken by <ref> [7] </ref>. Taken together, these parameters can be thought of as the agent's simplified representation of the environment as a corridor in terms of a frontal and two side walls. 2 As the robot approaches an obstacle in its heading direction, the TTC value decreases. <p> A major advantage of this format is that it represents a common data structure, the central and peripheral regions of which sub-serve different navigational behaviors. Previous approaches either employed images with uniform resolution, requiring the use of special-purpose image processing hardware <ref> [12, 7] </ref>, or were based on the plain log-polar mapping [10, 16], which introduces instabilities in the central region responsible for signaling the time-to-contact. The modified Logmap employed in our system realizes a data-reduction in the periphery, and avoids instabilities in the computation of the TTC.
Reference: [8] <author> A. P. Duchon. </author> <title> Maze navigation using optical flow. </title> <booktitle> In Proc. 4th Intl. Conf. on Simulation of Adaptive Behavior, </booktitle> <address> Cambridge, MA, 1996. </address> <publisher> MIT Press/Bradford Book. </publisher>
Reference-contexts: These tasks are part of a hierarchy of visually oriented behaviors. The simplest such behavior can be identified as an orientation behavior based on an op-tokinetic reflex. Obstacle avoidance, non-goal directed cruising through visible terrain and landmark detection require an already more elaborate repertoire of mechanisms. Goal directed locomotion <ref> [8] </ref>, searching target locations invisible from the local position and manipulation require even smarter mechanisms that must be supported by highly elaborate sensory and representational capabilities.
Reference: [9] <author> J. J. Gibson. </author> <title> The Perception of the Visual World. </title> <publisher> Houghton Mi*in, </publisher> <address> Boston, MA, </address> <year> 1950. </year>
Reference-contexts: 1 Motivation Insights into successful mechanisms of sensory processing and motor behavior in biological and artificial systems can be obtained from the study of various aspects of the perception-action-cycle <ref> [4, 9] </ref>. In our investigation, a simulated mobile robot explores its environment with the primary task to follow corridors and to avoid collisions utilizing only a monochromatic camera fixed to the robot's base.
Reference: [10] <author> R. Jain, S. L. Bartlett, and N. O'Brian. </author> <title> Motion stereo using ego-motion complex logarithmic mapping. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 9 </volume> <pages> 356-369, </pages> <year> 1987. </year>
Reference-contexts: Previous approaches either employed images with uniform resolution, requiring the use of special-purpose image processing hardware [12, 7], or were based on the plain log-polar mapping <ref> [10, 16] </ref>, which introduces instabilities in the central region responsible for signaling the time-to-contact. The modified Logmap employed in our system realizes a data-reduction in the periphery, and avoids instabilities in the computation of the TTC.
Reference: [11] <author> H. A. Mallot. </author> <title> An overall description of retinotopic mapping in the cat's visual cortex areas 17, 18, and 19. </title> <journal> Biol. Cybernetics, </journal> <volume> 52 </volume> <pages> 45-51, </pages> <year> 1985. </year>
Reference-contexts: We took our inspiration from space-variant mappings that have been found to occur between the retina and higher visual (cortical) areas in animals. Several mathematical mod els have been proposed to account for these mappings (e.g. <ref> [11] </ref> for the cat, and [13, 14] for primates). 3.1 Complex Logarithmic Mapping For data reduction, we employed the complex logarithmic mapping (Logmap) proposed in [14].
Reference: [12] <author> J. Santos-Victor, G. Sandini, F. Curotto, and S. Garibaldi. </author> <title> Divergent stereo for robot navigation : Learning from bees. </title> <booktitle> In Computer Vision and Pattern Recognition (CVPR'93), </booktitle> <pages> pages 434-439, </pages> <address> New York, USA, </address> <year> 1993. </year>
Reference-contexts: A major advantage of this format is that it represents a common data structure, the central and peripheral regions of which sub-serve different navigational behaviors. Previous approaches either employed images with uniform resolution, requiring the use of special-purpose image processing hardware <ref> [12, 7] </ref>, or were based on the plain log-polar mapping [10, 16], which introduces instabilities in the central region responsible for signaling the time-to-contact. The modified Logmap employed in our system realizes a data-reduction in the periphery, and avoids instabilities in the computation of the TTC.
Reference: [13] <author> E. Schwartz. </author> <title> Spatial mapping in the primate sensory projection: Analytic structure and relevance to perception. </title> <journal> Biol. Cybernetics, </journal> <volume> 25 </volume> <pages> 181-194, </pages> <year> 1977. </year>
Reference-contexts: We took our inspiration from space-variant mappings that have been found to occur between the retina and higher visual (cortical) areas in animals. Several mathematical mod els have been proposed to account for these mappings (e.g. [11] for the cat, and <ref> [13, 14] </ref> for primates). 3.1 Complex Logarithmic Mapping For data reduction, we employed the complex logarithmic mapping (Logmap) proposed in [14].
Reference: [14] <author> E. Schwartz. </author> <title> Visual cortex from a computational perspective. </title> <editor> In A. Peters and K. Rockland, editors, Cerebral Cortex, </editor> <volume> volume 10. </volume> <publisher> Plenum, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: In section 2, we review the flow field in these situations. In section 3 the necessity to reduce the large amount of input data leads us to introduce a space-variant mapping. We employ a special form which has been found to describe the retino-cortical projection in primates <ref> [14] </ref>. An examination of the flow patterns in this map reveals its specific advantages in combining the two navigational tasks. <p> We took our inspiration from space-variant mappings that have been found to occur between the retina and higher visual (cortical) areas in animals. Several mathematical mod els have been proposed to account for these mappings (e.g. [11] for the cat, and <ref> [13, 14] </ref> for primates). 3.1 Complex Logarithmic Mapping For data reduction, we employed the complex logarithmic mapping (Logmap) proposed in [14]. <p> Several mathematical mod els have been proposed to account for these mappings (e.g. [11] for the cat, and [13, 14] for primates). 3.1 Complex Logarithmic Mapping For data reduction, we employed the complex logarithmic mapping (Logmap) proposed in <ref> [14] </ref>. <p> The robot even finds its way through the simulated environment without collisions if up to 40% of the flow measurements are disturbed by simulated jitter. 5 Summary and Outlook We have demonstrated that a space-variant mapping found to describe the retino-cortical projection in primates <ref> [14] </ref> generates a data format whose space is chosen as the representative TTC value.
Reference: [15] <author> M. V. Srinivasan. </author> <title> How bees exploit optical flow: Behavioral experiments and neural models. </title> <journal> Phil. Trans. of the Royal Society of London B, </journal> <volume> 337 </volume> <pages> 253-259, </pages> <year> 1992. </year>
Reference-contexts: The development of such optical flow based control schemes has been influenced by the sci entific investigation of navigational tasks and control mechanisms in insects <ref> [15] </ref>. These tasks are part of a hierarchy of visually oriented behaviors. The simplest such behavior can be identified as an orientation behavior based on an op-tokinetic reflex. Obstacle avoidance, non-goal directed cruising through visible terrain and landmark detection require an already more elaborate repertoire of mechanisms. <p> The modified Logmap employed in our system realizes a data-reduction in the periphery, and avoids instabilities in the computation of the TTC. Largely inspired by studies on vision-based navigation in insects <ref> [15] </ref>, we employed a purposive representation of the robot's environment as a virtual corridor, and showed through simulation that this minimal representation provides behaviorally relevant control signals for flexible and robust navigation. We are currently extending our work in three respects.
Reference: [16] <author> M. Tistarelli and G. </author> <title> Sandini. On the advantages of polar and log-polar mapping for direct estimation of time-to-impact from optical flow. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 15 </volume> <pages> 401-410, </pages> <year> 1992. </year>
Reference-contexts: Previous approaches either employed images with uniform resolution, requiring the use of special-purpose image processing hardware [12, 7], or were based on the plain log-polar mapping <ref> [10, 16] </ref>, which introduces instabilities in the central region responsible for signaling the time-to-contact. The modified Logmap employed in our system realizes a data-reduction in the periphery, and avoids instabilities in the computation of the TTC.
References-found: 16

