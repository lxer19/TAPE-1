URL: http://www-csag.cs.uiuc.edu/papers/kim-ms.ps
Refering-URL: http://www-csag.cs.uiuc.edu/papers/index.html
Root-URL: http://www.cs.uiuc.edu
Title: PLANAR-ADAPTIVE ROUTING (PAR) :LOW-COST ADAPTIVE NETWORKS FOR MULTIPROCESSORS  
Author: BY 
Degree: THESIS Submitted in partial fulfillment of the requirements for the degree of Master of Science in Electrical Engineering in the Graduate College of the  
Date: 1990  
Address: College Park,  1993 Urbana, Illinois  
Affiliation: B.S.Eng., University of Maryland at  University of Illinois at Urbana-Champaign,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. Agarwal et. al. </author> <title> The MIT Alewife Machine: A Large-Scale Distributed-Memory Multiprocessor. </title> <type> Lcs-technical memo 454, </type> <institution> Massachusetts Institute of Technology, Laboratory for Computer Science, </institution> <year> 1991. </year>
Reference-contexts: Due to this scalability advantage, direct networks are gaining wide acceptance; recent multiprocessor machines such as Tera Computer's TERA machine [5], Stanford DASH [34] and the MIT Alewife <ref> [1] </ref> all use direct networks. For all types of concurrent computers, communication networks play a critical role in overall system performance. Unfortunately, even direct networks cannot provide the characteristics of an ideal network, infinite bandwidth and zero latency. To close the gap, several approaches have been developed. <p> Unfortunately, even direct networks cannot provide the characteristics of an ideal network, infinite bandwidth and zero latency. To close the gap, several approaches have been developed. One approach is to reduce the frequency of the communications by using cache (Stanford DASH [34], and the MIT Alewife <ref> [1] </ref>). The number of memory references to distant memory units can be dramatically reduced by exploiting locality of reference. Another approach is to hide or tolerate the latency by overlapping useful work with communication latency. Multicomputers such as the MIT J-machine [23] use context switching to tolerate remote object access.
Reference: [2] <author> A. Gottlieb et al. </author> <title> The NYU Ultracomputer Designing an MIMD Shared Memory Parallel Computer. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-32(2):175-189, </volume> <month> February </month> <year> 1983. </year>
Reference-contexts: Shared-memory multiprocessors provide a single address space shared by all of the processors. Processors communicate by accessing data in shared-memory units. Due to the equidis-tance property between any processor and any memory unit, multistage interconnection networks have been preferred by multiprocessors <ref> [44, 2] </ref>. Since communication between any pairs of nodes occurs through multiple stages of the network, multistage networks are also referred as indirect networks. In contrast, message-passing multicomputers do not provide a global address space.
Reference: [3] <author> A. Agarwal. </author> <title> Limits on Interconnection Network Performance. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 398-412, </pages> <year> 1991. </year>
Reference-contexts: In addition, low-dimensional networks are preferred because wire lengths increase with network dimension. The significance of increased wire length is discussed extensively in <ref> [3] </ref>. Wire bisection is not the only constraint that applies to network implementation. In practical systems, channel width may be constrained by node sizes rather than wire bisection [18]. Under the node size constraint, moderate (3, 4 or 5)-dimensional networks are more attractive. <p> As the network dimension increases, the advantages of high-dimensional networks overwhelm the reduced channel width. Consequently, under pin limitation, two-dimensional networks give much worse performance than do networks of moderate dimensions especially under heavy loads. An analytical comparison under the pin limitation was done by Agarwal <ref> [3] </ref>. He also showed that the optimal dimension is highly sensitive to system parameters such as packet length. There are two alternative ways to implement k-ary n-cube networks, with (torus) or without (mesh) wraparound channels. <p> From such a complex range of sources, we anticipate a new range of network communication workloads with a wide variety of traffic patterns and message size distributions. However, to date much of the study of multicomputer network performance is based on uniform message size distributions <ref> [17, 3, 41] </ref>. While presuming uniform traffic simplifies simulations and the interpretation of results, these traffic loads are not representative of the actual communication workloads. It is also important to study the interaction of messages of different sizes, examining the impact of hybrid traffic loads.
Reference: [4] <author> R. Alauskas. </author> <title> iPSC/2 System: A Second Generation Hypercube. </title> <booktitle> In Proceedings of the Third Conference on Hypercube Computers. Association for Computing Machinery, </booktitle> <publisher> ACM Press, </publisher> <month> January </month> <year> 1988. </year>
Reference-contexts: Issues of virtual lanes as well as planar-adaptive routing will be revisited for high-performance networks under the hybrid traffic. 118 7 NETWORK PERFORMANCE UNDER BIMODAL LOADS As large scale commercial multicomputers gain wider acceptance, their patterns of use inevitably change. While previous systems <ref> [4, 38] </ref> were used primarily as back-end computational engines, contemporary systems are likely to be used to support a variety of applications, programming systems, system software, and batch and interactive loads.
Reference: [5] <author> G. Alverson, R. Alverson, D. Callahan, B. Koblenz, A. Porterfield, and B. Smith. </author> <title> Exploiting Heterogeneous Parallelism on a Multithreaded Multiprocessor. </title> <booktitle> In Proceedings of the 6th ACM Interational Conference on Supercomputing, </booktitle> <year> 1992. </year>
Reference-contexts: Due to this scalability advantage, direct networks are gaining wide acceptance; recent multiprocessor machines such as Tera Computer's TERA machine <ref> [5] </ref>, Stanford DASH [34] and the MIT Alewife [1] all use direct networks. For all types of concurrent computers, communication networks play a critical role in overall system performance. Unfortunately, even direct networks cannot provide the characteristics of an ideal network, infinite bandwidth and zero latency. <p> Another approach is to hide or tolerate the latency by overlapping useful work with communication latency. Multicomputers such as the MIT J-machine [23] use context switching to tolerate remote object access. The TERA machine <ref> [5] </ref> uses fine-grain multithreading to hide the latency, and the Stanford DASH and MIT Alewife also use the multithreading to complement remote memory access due to cache misses. However, the techniques we have described cannot solve all of the problems related to nonideal networks. <p> Consequently, this scheme is livelock free. The Chaos router has been proved to provide high performance on various network topologies, hypercube [32], mesh or torus [7]. Another interesting nonminimal adaptive algorithm is deflection routing, which is being used in Tera Computer's TERA machine <ref> [5] </ref>. In deflection routing, messages arriving at a node are guaranteed to leave the node in the next routing cycle. Profitable 2 channels are preferred, but if not available, misrouting is taken. The algorithm is similar to Chaos routing in using randomization for livelock prevention. <p> We focus on low (two, three, or four)-dimensional mesh networks because they are currently in 68 widespread use in many machines such as the Intel Paragon [14], Intel iWARP [8, 43], the MIT J-machine [21, 24], Stanford DASH [35], and Tera Computer's TERA machine <ref> [5] </ref>. Unless stated otherwise, the two- and four-dimensional networks used contain 256 nodes. The size was determined for reasonable amounts of simulation time. For simplicity, we study networks with uniform radix, k. Hence, two-dimensional networks are 16x16 mesh and four dimensional networks are 4x4x4x4 mesh connected.
Reference: [6] <author> P. Berman, L. Gravano, G. Pifarre, and J. Sanz. </author> <title> Adaptive Deadlock and Livelock Free Routing with All Minimal Paths in Torus Networks. </title> <booktitle> In Proceedings of the Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1992. </year>
Reference-contexts: Unfortunately, as in Dally-Aoki's algorithm, adaptivity in the scheme is restricted by the number of virtual channels provided. 33 3.2.6 The *-Channels algorithm Recently, an algorithm called *-Channels has been introduced to reduce the hardware cost and complexity, while allowing fully adaptive minimal routing <ref> [6] </ref>. The algorithm is provably deadlock and livelock free. The *-Channels algorithm requires only two (or four) 5 virtual channels for n-dimensional mesh (or torus) networks regardless of the network dimension n. This is significantly smaller when compared to Linder-Harden algorithm. <p> Thus blocking is eventually resolved, and there is no deadlock. The algorithm significantly reduces the buffer requirements of previous fully adaptive routing algorithms. However, since this algorithm depends on flow control for routing 5 These numbers are per physical channel. They are slightly different from the numbers presented in <ref> [6] </ref>. It is because we follow the counting method used in Linder-Harden's algorithm. 34 decisions, the router control scheme may be more complicated. For instance, to set up a path, checking the states of output buffers in the current node is not sufficient.
Reference: [7] <author> K. Bolding and L. Snyder. </author> <title> Mesh and Torus Chaotic Routing. </title> <booktitle> In Proceedings of the 1992 Brown/MIT Conference on Advanced Research in VLSI, </booktitle> <year> 1992. </year>
Reference-contexts: Consequently, this scheme is livelock free. The Chaos router has been proved to provide high performance on various network topologies, hypercube [32], mesh or torus <ref> [7] </ref>. Another interesting nonminimal adaptive algorithm is deflection routing, which is being used in Tera Computer's TERA machine [5]. In deflection routing, messages arriving at a node are guaranteed to leave the node in the next routing cycle. Profitable 2 channels are preferred, but if not available, misrouting is taken.
Reference: [8] <author> S. Borkar, R. Cohn, G. Cox, S. Gleason, T. Gross, H. T. Kung, M. Lam, B. Moore, C. Peterson, J. Pieper, L. Rankin, P. S. Tseng, J. Sutton, J. Urbanski, and J. Webb. </author> <title> iWARP: An Integrated Solution to High-Speed Parallel Computing. </title> <booktitle> In Proceedings of Supercomputing '88, </booktitle> <pages> pages 330-341. </pages> <publisher> IEEE Press, </publisher> <address> 1988. Orlando, Florida. </address>
Reference-contexts: Throughout this chapter, we use the network model described below. Network Topology We basically study n-dimensional mesh networks. We focus on low (two, three, or four)-dimensional mesh networks because they are currently in 68 widespread use in many machines such as the Intel Paragon [14], Intel iWARP <ref> [8, 43] </ref>, the MIT J-machine [21, 24], Stanford DASH [35], and Tera Computer's TERA machine [5]. Unless stated otherwise, the two- and four-dimensional networks used contain 256 nodes. The size was determined for reasonable amounts of simulation time. For simplicity, we study networks with uniform radix, k.
Reference: [9] <author> S. Borkar, R. Cohn, G. Cox, T. Gross, H. T. Kung, M. Lam, M. Levine, B. Moore, W. Moore, C. Peterson, J. Susman, J. Sutton, J. Urbanski, and J. Webb. </author> <title> Supporting Systolic and Memory Communication in iWARP. </title> <booktitle> In Proceedings of the 17th International Symposium on Computer Architecture. IEEE Computer Society, </booktitle> <year> 1990. </year>
Reference-contexts: In [19], Dally showed that virtual lanes give much higher performance than does the use of the given storage as a single deep FIFO queue. A similar idea was used in the Intel iWARP machines <ref> [9] </ref> where they were called logical channels. Each iWARP node provides 20 logical input channels and 20 logical output channels dynamically connected by a crossbar switch. The logical channels share 8 physical channels linked to neighbor nodes by time multiplexing. <p> The two adjacent planes are connected only through a dimension interface. Figure 5.2 shows the internal organization of a three-dimensional planar-adaptive router. The figures assumed that a router is integrated into a processor chip as in NDF [26] and the Intel iWARP <ref> [9] </ref>. Because of its small size and enhanced VLSI technology, the PAR can be embedded in the processor chip without a significant effect on processor performance. The embedded router scheme eliminates an external interface between a processor and a network. <p> The interface bandwidth can be augmented by the multiple channels. The importance of interface bandwidth has been observed by other researchers and the multichannel path was actually used in the design of the Intel iWARP <ref> [9] </ref>. Second, for bimodal traffic loads, less frequent long messages can block subsequent short messages and prevent them from being 124 injected. To explore the characteristics of a network itself under bimodal traffic loads, we eliminate the undesirable effect of interface by providing multiple channels.
Reference: [10] <author> D. Chaiken, C. Fields, K. Kurihara, and A. Agarwal. </author> <title> Directory-Based Cache Coherence in Large-Scale Multiprocessors. </title> <booktitle> IEEE Computer, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: Not only does a lesser packet requirement reduce network loading, it also may improve a critical performance feature, memory operation latency, by eliminating waits for acknowledgements in the protocol. In a number of other shared-memory protocols, preserving message-transmission order may also simplify the protocol and improve its performance <ref> [10, 28, 42] </ref>. Our minimal, adaptive routing algorithms support both in-order packet delivery and adaptive, unordered packet delivery simultaneously. All traffic must be specified as ordered or unordered.
Reference: [11] <author> M. Chandy and S. Taylor. </author> <title> An Introduction to Parallel Programming. </title> <editor> Jones and Bartlett, </editor> <year> 1991. </year> <month> 149 </month>
Reference-contexts: From the network's point of view, packetization eliminates the extremely long messages and dramatically increases the number of messages at the maximum physical transfer size. Messages below the maximum transfer size are transmitted without resizing. Fourth, a variety of novel programming models such as <ref> [12, 11, 15] </ref> seek to exploit parallelism at a finer granularity. This typically implies using short messages much more frequently. In addition, a variety of message-passing library functions such as global synchronization, reduction operations and multicasts give rise to short messages.
Reference: [12] <author> A. A. Chien and W. J. Dally. </author> <title> Concurrent Aggregates (CA). </title> <booktitle> In Proceedings of Second Symposium on Principles and Practice of Parallel Programming. ACM, </booktitle> <month> March </month> <year> 1990. </year>
Reference-contexts: From the network's point of view, packetization eliminates the extremely long messages and dramatically increases the number of messages at the maximum physical transfer size. Messages below the maximum transfer size are transmitted without resizing. Fourth, a variety of novel programming models such as <ref> [12, 11, 15] </ref> seek to exploit parallelism at a finer granularity. This typically implies using short messages much more frequently. In addition, a variety of message-passing library functions such as global synchronization, reduction operations and multicasts give rise to short messages.
Reference: [13] <author> S. Chittor and R. Enbody. </author> <title> Performance Evaluation of Mesh-connected Wormhole-routed Networks for Interprocessor Communication in Multicomputers. </title> <booktitle> In Proceedings of Supercomputing, </booktitle> <year> 1990. </year>
Reference-contexts: Third, typical message passing libraries implement some form of packetization, breaking long messages down into some maximum physical transfer size (256 or 512 bytes, typically). For instance, in the Symult 2010, messages longer than 256 bytes are sent as a series of 256 byte packets <ref> [13] </ref>. From the network's point of view, packetization eliminates the extremely long messages and dramatically increases the number of messages at the maximum physical transfer size. Messages below the maximum transfer size are transmitted without resizing. <p> Thus, most packetization systems use fairly large packets. More significantly, packetization introduces additional overhead for message-to-packet conversion and reassembly and resequencing at the destination. If these tasks are performed in software, they can dramatically increase message-passing latency <ref> [13] </ref>. The obvious alternative is to implement them in hardware, but to date no commercial multicomputers have done so. Perhaps this is because the cost of packetization hardware can be significant. In addition, the performance benefits of packetization are unclear.
Reference: [14] <author> Intel Corporation. </author> <title> Paragon XP/S Product Overview. Product Overview, </title> <year> 1991. </year>
Reference-contexts: Throughout this chapter, we use the network model described below. Network Topology We basically study n-dimensional mesh networks. We focus on low (two, three, or four)-dimensional mesh networks because they are currently in 68 widespread use in many machines such as the Intel Paragon <ref> [14] </ref>, Intel iWARP [8, 43], the MIT J-machine [21, 24], Stanford DASH [35], and Tera Computer's TERA machine [5]. Unless stated otherwise, the two- and four-dimensional networks used contain 256 nodes. The size was determined for reasonable amounts of simulation time. For simplicity, we study networks with uniform radix, k. <p> With long messages, we have a bimodal traffic load. Without them, we have a uniform-sized 126 traffic load, a familiar point of reference. Dimension-order routers without virtual lanes (such as those found in the Intel Paragon <ref> [14] </ref>) are used for both traffic loads. For this study, the long messages studied are 4 % of the total number of messages and 512 flits long. The short messages in both cases are 24 flits each.
Reference: [15] <author> D. Culler, A. Sah, K. Schauser, T. von Eicken, and J. Wawrzynek. </author> <title> Fine-grain Parallelism with Minimal Hardware Support: A Compiler-Controlled Threaded Abstract Machine. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages an Operating Systems, </booktitle> <pages> pages 164-75, </pages> <year> 1991. </year>
Reference-contexts: From the network's point of view, packetization eliminates the extremely long messages and dramatically increases the number of messages at the maximum physical transfer size. Messages below the maximum transfer size are transmitted without resizing. Fourth, a variety of novel programming models such as <ref> [12, 11, 15] </ref> seek to exploit parallelism at a finer granularity. This typically implies using short messages much more frequently. In addition, a variety of message-passing library functions such as global synchronization, reduction operations and multicasts give rise to short messages.
Reference: [16] <author> W. J. Dally. </author> <title> Fine-grain Message-Passing Concurrent Computers. </title> <booktitle> In Proceedings of the Third Conference on Hypercube Computers, </booktitle> <pages> pages 2-12. </pages> <publisher> Association for Computing Machinery, ACM Press, </publisher> <month> January </month> <year> 1988. </year>
Reference-contexts: Within the virtual networks, cyclic dependences of network resources can be removed by restricting the routing algorithm appropriately. 3.2.1 Dally's 2D mesh adaptive router A prototypical model of the approach was given by Dally in <ref> [16] </ref>. Dally divided two-dimensional mesh networks into two separate virtual networks by providing two virtual channels for each y-dimensional link. Eastbound messages and westbound messages 3 are routed on separate virtual networks. These networks are completely decoupled. Figure 3.1 shows the virtual networks and their use for deadlock prevention.
Reference: [17] <author> W. J. Dally. </author> <title> Performance Analysis of k-ary n-cube Interconnection Networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(6), </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: For a given message length, narrow channels increase message latency, overwhelming the advantages of high-dimensional networks. In a comparative study based on normalized channel width on the assumption of constant wire bisection, Dally showed in <ref> [17] </ref> that low-dimensional (two or three dimensions) networks provide better performance than high-dimensional networks. In addition, low-dimensional networks are preferred because wire lengths increase with network dimension. The significance of increased wire length is discussed extensively in [3]. Wire bisection is not the only constraint that applies to network implementation. <p> Guaranted in-order packet delevery has been known to simplify communication protocol and/or improve network performance. In Section 4.5, we summarize the algorithms presented in this chapter. 4.1 Notation and Terminology We adopt notation similar to that in <ref> [17, 36] </ref>. We present routing algorithm only for a physical topology of a k-ary n-cube with no wraparound paths (mesh networks). Torus networks require slightly more complicated algorithm for deadlock prevention. <p> From such a complex range of sources, we anticipate a new range of network communication workloads with a wide variety of traffic patterns and message size distributions. However, to date much of the study of multicomputer network performance is based on uniform message size distributions <ref> [17, 3, 41] </ref>. While presuming uniform traffic simplifies simulations and the interpretation of results, these traffic loads are not representative of the actual communication workloads. It is also important to study the interaction of messages of different sizes, examining the impact of hybrid traffic loads.
Reference: [18] <author> W. J. Dally. </author> <title> Express Cubes: Improving the Performance of k-ary n-cube Interconnection Networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 40(9) </volume> <pages> 1016-1023, </pages> <year> 1991. </year>
Reference-contexts: The significance of increased wire length is discussed extensively in [3]. Wire bisection is not the only constraint that applies to network implementation. In practical systems, channel width may be constrained by node sizes rather than wire bisection <ref> [18] </ref>. Under the node size constraint, moderate (3, 4 or 5)-dimensional networks are more attractive. Since the number of pins is limited by the node size, channel width decreases as the network dimension increases. <p> The hypercube network is an instance of a k-ary n-cube network, where k=2. To accommodate more nodes, the network dimension, n must increase. Several first- and second-generation multicomputers 2 used hypercubes. Hypercube networks have the advantages and disadvantages of high-dimensional networks. In <ref> [18] </ref>, Dally introduced the express cube, an extension of low-dimensional k-ary n-cube networks. An express cube network consists of a hierarchy of mesh or torus networks superimposed on each other. The idea behind the express cube is to provide short cuts for messages traveling long distances.
Reference: [19] <author> W. J. Dally. </author> <title> Virtual Channel Flow Control. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(2) </volume> <pages> 194-205, </pages> <year> 1992. </year>
Reference-contexts: As the depth of queues grows, network throughput increases proportionally. The performance dependence on the depth of the queues is described in detail in [37]. The other scheme, called virtual lane flow control, virtually eliminates the interferences by providing passing lanes over the blocked channel <ref> [19] </ref>. The idea behind virtual lanes is to implement the duplicate channels by using buffers instead of additional physical wires since physical channels would increase the network cost significantly. Several buffers, called virtual lanes, are associated with a single physical channel and share its bandwidth. <p> Several buffers, called virtual lanes, are associated with a single physical channel and share its bandwidth. Once a packet holding a buffer is blocked, the packet releases the physical channel so that other packets can use it for bypassing. In <ref> [19] </ref>, Dally showed that virtual lanes give much higher performance than does the use of the given storage as a single deep FIFO queue. A similar idea was used in the Intel iWARP machines [9] where they were called logical channels. <p> All traffic must be specified as ordered or unordered. Planar-adaptive routing guarantees in-order packet delivery for the ordered traffic both in the fault-free case, and in the presence of static faults. 4 Since, for simplicity, we assume only one "virtual lane" <ref> [19] </ref> per virtual channel, packets routed along a single path cannot pass each other. <p> PAR allows hardware implementation of a low cost, wormhole routed, adaptive router. In addition, the lesser virtual channels requirement may significantly improve router speed or allow additional hardware resources to be used for other performance enhancing schemes such as deep FIFO queues for partial buffering or virtual lanes <ref> [37, 19] </ref>. 1 This is the maximum number of virtual channels required. In fact, the first dimension requires a single virtual channel per link and the last dimension requires two virtual channels only. All of the intermediate dimensions require three virtual channels. <p> We also show that the PARs give significant benefits under nonuniform traffic loads. Second, we discuss the effects of virtual lanes on the performance of PARs. Virtual lanes have been shown to dramatically increase performance in dimension-order routers <ref> [19] </ref>. We show that the addition of virtual lanes improves the PAR's performance as well. Based on the results, we again compare the two kinds of routers, but this time, using an equal quantity of network resources (virtual channels/virtual lanes) for each router. <p> However, other than locality, users do not have to worry about the detailed traffic patterns generated by applications. 85 by decoupling two types of network resources: buffers and physical channels <ref> [19] </ref>. If a message holding a buffer is blocked, the message releases the physical channel so that other messages can use it. <p> Network throughput is increased for all three networks as the number of lanes increases up to certain number. Conversely, the latency is slightly increased by the addition of virtual lanes. The results are similar to the effects of virtual lanes on dimension-order routers shown in <ref> [19] </ref>. The figure shows that the magnitude of virtual lane effects is different depending on the radix k, which determines the number of nodes along a dimension. In the 4x4 mesh network shown in Figure 6.6 (a), virtual lanes do not affect network performance significantly. <p> PARs (2,2,2) and (4,1,1) which have an equal number of virtual channels but different configurations are compared on (a) 4x4 2D, (b) 8x8 2D, and (c) 16x16 2D mesh networks. 90 more lanes than 8x8 small networks. In <ref> [19] </ref>, Dally presented similar results showing that more than four virtual lanes degrade the performance in 16x16 mesh networks with dimension-order routing. Determining the number of beneficial virtual lanes is important for the design of a high-performance network. <p> and variance of short messages increase significantly. 7.3.3 Effect of virtual lanes To explore a means of faster and more predictable message delivery under hybrid traffic loads, we explore a promising technique, the addition of virtual lanes which are known to increase the network throughput under uniform size traffic loads <ref> [19] </ref>. Virtual lanes reduce the interference of long messages on short messages by providing a way of bypassing channels monopolized by long messages. Virtual lanes share the physical channel, allowing both messages to make progress.
Reference: [20] <author> W. J. Dally. </author> <title> Message-Passing Concurrent Computers, </title> <note> chapter 7. Addison-Wesley, To be published. C. Seitz's Book. </note>
Reference-contexts: Packet storage occurs only when all of the possible outgoing channels are busy. Consequently, virtual cut-through performs, at worst, as slowly as packet routing, and at best, much faster. An alternative technique, called wormhole routing, was presented by Dally and Seitz in <ref> [20] </ref>, providing similar performance, but much reducing the storage requirement of each node. The primary distinction between the virtual cut-through and wormhole routing is 15 the action taken when a message's path is blocked. Instead of buffering entire messages in the blocked node, wormhole routing stops the message in place.
Reference: [21] <author> W. J. Dally, S. Ahmed, P. Carrick, A. Chien, R. Davison, J. Fiske, G. Fyler, W. Hor-wat, J. Keen, S. Lear, R. Lethin, M. Vestrich, T. Nguyen, M. Noakes, P. Nuth, and D. Wills. </author> <title> Design and Implementation of the Message-Driven Processor. </title> <booktitle> In Proceedings of the 1992 Brown/MIT Conference on Advanced Research in VLSI and Parallel Systems, </booktitle> <editor> T. Knight and J. Savage, eds. </editor> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Network Topology We basically study n-dimensional mesh networks. We focus on low (two, three, or four)-dimensional mesh networks because they are currently in 68 widespread use in many machines such as the Intel Paragon [14], Intel iWARP [8, 43], the MIT J-machine <ref> [21, 24] </ref>, Stanford DASH [35], and Tera Computer's TERA machine [5]. Unless stated otherwise, the two- and four-dimensional networks used contain 256 nodes. The size was determined for reasonable amounts of simulation time. For simplicity, we study networks with uniform radix, k.
Reference: [22] <author> W. J. Dally and H. Aoki. </author> <title> Deadlock-Free Adaptive Routing in Multicomputer Networks usin g Virtual Channels. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <note> To appear. </note>
Reference-contexts: However, then, eastbound messages must be carefully controlled not to be misrouted to the east of the destination node for livelock prevention. 3.2.4 Dally-Aoki's algorithm Using the virtual channel technique based on the notion of dimension reversal, Dally and Aoki have suggested another adaptive routing algorithm in <ref> [22] </ref>. Based on the utilization of virtual channels, their algorithm divides into static and dynamic schemes. In the static scheme, the virtual channels for each link are divided into r classes, labeled 0 to r 1. <p> This scheme allows an arbitrary number of dimension reversals but increases router complexity by requiring the updating of reversal counts and making routing decisions on that basis. As in the Turn model, both static and dynamic schemes may allow misrouting. However, the livelock prevention mechanism suggested in <ref> [22] </ref> makes them even more complicated. 3.2.5 The multipath e-cube algorithm (MECA) The MECA algorithm, described in [27], is similar to the static scheme of Dally and Aoki. MECA stands for multipath e-cube algorithm. As it implies, MECA allows adaptive routing by providing duplicate paths, each for dimension-order routing. <p> A primary concern in adaptive networks is the cost of deadlock prevention. To assure deadlock-free routing, the planar scheme requires only three virtual channels for k-ary n-cubes without wraparound channels. This is a dramatic improvement over previously published schemes <ref> [36, 22] </ref>. As shown before, the Linder-Harden deadlock prevention scheme requires 2 n1 virtual channels, a significant hardware overhead. Equally important, in planar-adaptive routing, deadlock and livelock are avoided without any complex reversal counting [22] or aging schemes [39]. <p> This is a dramatic improvement over previously published schemes [36, 22]. As shown before, the Linder-Harden deadlock prevention scheme requires 2 n1 virtual channels, a significant hardware overhead. Equally important, in planar-adaptive routing, deadlock and livelock are avoided without any complex reversal counting <ref> [22] </ref> or aging schemes [39]. This means that planar-adaptive routers can be very simple and as a result can make routing decisions very rapidly. Consequently, 45 they may run faster than other adaptive routers which require complex techniques for deadlock and livelock prevention.
Reference: [23] <author> W. J. Dally, A. Chien, S. Fiske, W. Horwat, J. Keen, M. Larivee, R. Lethin, P. Nuth, S. Wills, P. Carrick, and G. Fyler. </author> <title> The J-Machine: A Fine-Grain Concurrent Computer. </title> <booktitle> In Information Processing 89, Proceedings of the IFIP Congress, </booktitle> <pages> pages 1147-1153, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: Instead, memory is distributed across the processing nodes; only the data in local memory can be accessed directly. Access to data in remote memories is supported by message passing between processors. Direct networks, represented by grid or mesh networks, have been used predominantly in multicomputers <ref> [47, 45, 23, 46] </ref>. However, as direct networks gain acceptance in shared-memory multiprocessor designs, distinguishing these machines by network topology is less appropriate. <p> The number of memory references to distant memory units can be dramatically reduced by exploiting locality of reference. Another approach is to hide or tolerate the latency by overlapping useful work with communication latency. Multicomputers such as the MIT J-machine <ref> [23] </ref> use context switching to tolerate remote object access. The TERA machine [5] uses fine-grain multithreading to hide the latency, and the Stanford DASH and MIT Alewife also use the multithreading to complement remote memory access due to cache misses. <p> However, these characteristics are dependent on the granularity of the parallelism exploited and the communication reducing techniques used. Hence, throughout the thesis, we refer to them as multicomputer networks implying communication networks for both types of concurrent computers. 1.2 The Problem Most multicomputers use dimension-order routing <ref> [47, 45, 23, 46] </ref> due to its simplicity and deadlock freedom. Under dimension-order routing, a message is routed successively in each of the dimensions. Since each message passes through the network dimensions in the same order, interdimensional cycles causing deadlock cannot form. <p> However, adaptive routing introduces new possibilities of deadlock or livelock. In the next chapter, we discuss a variety of adaptive routing algorithms suggested to prevent deadlock and livelock. 24 3 RELATED WORK: ADAPTIVE ROUTING ALGORITHMS Most existing multicomputers use dimension-order routing <ref> [47, 45, 23, 46] </ref> due to its simplicity and freedom from deadlock. However, dimension-order routing allocates network resources inflexibly, preventing full utilization of the physical channels. To increase routing flexibility, many algorithms have been suggested to route messages adaptively based on the network state.
Reference: [24] <author> W. J. Dally, J. A. S. Fiske, J. S. Keen, R. A. Lethin, M. D. Noakes, P. R. Nuth, R. E. Davison, and G. A. Fyler. </author> <title> The Message-Driven Processor. </title> <booktitle> IEEE Micro, </booktitle> <month> April </month> <year> 1992. </year>
Reference-contexts: Network Topology We basically study n-dimensional mesh networks. We focus on low (two, three, or four)-dimensional mesh networks because they are currently in 68 widespread use in many machines such as the Intel Paragon [14], Intel iWARP [8, 43], the MIT J-machine <ref> [21, 24] </ref>, Stanford DASH [35], and Tera Computer's TERA machine [5]. Unless stated otherwise, the two- and four-dimensional networks used contain 256 nodes. The size was determined for reasonable amounts of simulation time. For simplicity, we study networks with uniform radix, k.
Reference: [25] <author> W. J. Dally and C. Seitz. </author> <title> The Torus Routing Chip. </title> <booktitle> Distributed Computing, </booktitle> <pages> pages 187-96, </pages> <year> 1986. </year>
Reference-contexts: Details of the scheme are described in [29]. The idea can be expanded for wormhole-routed networks. In wormhole-routed networks, channels are the critical resources to be managed. Dally and Seitz introduced the channel dependence graph (CDG) and used it to develop a deadlock-free routing function in wormhole routing networks <ref> [25] </ref>. The channel dependence graph is a directed graph defined as CDG = G (C; E), where vertices of the graph C are the set of communication channels of the network, and edges of the graph E represent the dependence relation between channels in C.
Reference: [26] <author> W. J. Dally and P. Song. </author> <title> Design of a Self-Timed VLSI Multicomputer Communication Controller. </title> <booktitle> In Proceedings of the International Conference on Computer Design, </booktitle> <pages> pages 230-4. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1987. </year>
Reference-contexts: These logical networks can be used to provide multiple network services on a single physical network. Messages in one logical network do not block messages in other logical networks. For instance, multiple priority message delivery can be implemented by virtual lanes as in the Network Design Frame <ref> [26] </ref>. 2.4 Routing Functions Routing functions which determine the path to be used to route a message, can be divided into two major categories: deterministic or adaptive. In deterministic routing, a path is determined by a source and destination pair, usually a single path for each pair. <p> The two adjacent planes are connected only through a dimension interface. Figure 5.2 shows the internal organization of a three-dimensional planar-adaptive router. The figures assumed that a router is integrated into a processor chip as in NDF <ref> [26] </ref> and the Intel iWARP [9]. Because of its small size and enhanced VLSI technology, the PAR can be embedded in the processor chip without a significant effect on processor performance. The embedded router scheme eliminates an external interface between a processor and a network.
Reference: [27] <author> J. Draper and J. Ghosh. </author> <title> Multipath E-cube Algorithms (MECA) for Adaptive Wormhole Routing and Broadcasting in k-ary n-cubes. </title> <booktitle> In The Fifth International Parallel Processing Symposium, </booktitle> <year> 1992. </year>
Reference-contexts: As in the Turn model, both static and dynamic schemes may allow misrouting. However, the livelock prevention mechanism suggested in [22] makes them even more complicated. 3.2.5 The multipath e-cube algorithm (MECA) The MECA algorithm, described in <ref> [27] </ref>, is similar to the static scheme of Dally and Aoki. MECA stands for multipath e-cube algorithm. As it implies, MECA allows adaptive routing by providing duplicate paths, each for dimension-order routing. By using p virtual channels, p sets of dimension-order paths are composed.
Reference: [28] <author> M. Dubois, C. Scheurich, and F. Briggs. </author> <title> Synchronization, Coherence and Event Ordering in Multiprocessors. </title> <booktitle> IEEE Computer, </booktitle> <pages> (9-21), </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Not only does a lesser packet requirement reduce network loading, it also may improve a critical performance feature, memory operation latency, by eliminating waits for acknowledgements in the protocol. In a number of other shared-memory protocols, preserving message-transmission order may also simplify the protocol and improve its performance <ref> [10, 28, 42] </ref>. Our minimal, adaptive routing algorithms support both in-order packet delivery and adaptive, unordered packet delivery simultaneously. All traffic must be specified as ordered or unordered.
Reference: [29] <author> K. D. Gunther. </author> <title> Prevention of Deadlocks in Packet-Switched Data Transport Systems. </title> <journal> IEEE Transactions on Communications, </journal> <volume> COM-29(4), </volume> <year> 1981. </year>
Reference-contexts: The message buffers in each node are partitioned into several classes, and messages are assigned to the partitioned buffers in a way of defining a partial order. Details of the scheme are described in <ref> [29] </ref>. The idea can be expanded for wormhole-routed networks. In wormhole-routed networks, channels are the critical resources to be managed. Dally and Seitz introduced the channel dependence graph (CDG) and used it to develop a deadlock-free routing function in wormhole routing networks [25].
Reference: [30] <author> J. M. Hsu and P. Banerjee. </author> <title> Performance Measurement and Trace Driven Simulation of Parallel CAD and Numeric Applications on a Hypercube Multicomputer. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(4) </volume> <pages> 451-464, </pages> <year> 1992. </year>
Reference-contexts: There are number of factors which give rise to nonuniform message sizes in communication workloads. First, applications may give rise to a range of message sizes. Studies of parallel CAD applications reported in <ref> [30] </ref> demonstrate a wide variety of message sizes ranging from 17 to over 8,000 bytes at the application level. Second, the protocols imple 119 mented by the message-passing libraries give rise to several distinct message sizes. Many synchronous message passing implementations use a three-phase protocol to allocate buffer storage.
Reference: [31] <author> P. Kermani and L. Kleinrock. </author> <title> Virtual Cut-through: A New Computer Communications Switching Technique. </title> <journal> Computer Networks, </journal> <volume> 3(4) </volume> <pages> 267-86, </pages> <year> 1979. </year>
Reference-contexts: Unfortunately, there is a limit to the benefit of reducing the packet size because of the routing information overhead attached to each packet. A hybrid scheme of circuit switching and packet switching, called virtual cut-through, was suggested by Kermani and Kleinrock in <ref> [31] </ref>. The hybrid scheme is very similar to packet switching except that it allows cut-through. If an outgoing channel is free when the head of a message arrives at an intermediate node, the message is not forced to wait until the message is completely buffered.
Reference: [32] <author> S. Konstantinidou and L. Snyder. </author> <title> Chaos Router: Architecture and Performance. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 212-21, </pages> <year> 1991. </year>
Reference-contexts: Second, the routing decision is dependent on the priority as well as the destination address, complicating the routing decision procedure and increasing node delay significantly. An interesting algorithm which reduces the complexity is Chaos routing <ref> [32] </ref>. In Chaos routing, a packet is randomly selected when misrouting is needed. There is no complex scheme on which routing is based. <p> Consequently, this scheme is livelock free. The Chaos router has been proved to provide high performance on various network topologies, hypercube <ref> [32] </ref>, mesh or torus [7]. Another interesting nonminimal adaptive algorithm is deflection routing, which is being used in Tera Computer's TERA machine [5]. In deflection routing, messages arriving at a node are guaranteed to leave the node in the next routing cycle.
Reference: [33] <author> A. Landin, E. Hagersten, and S. Haridi. </author> <title> Race-free Interconnection Networks and Multiprocessor Consistency. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <pages> pages 106-115, </pages> <year> 1991. </year>
Reference-contexts: Landin and Haridi showed that in-order packet delivery, or "race-free" networks can significantly reduce the number of packets required to implement serialization protocols for coherent shared memory <ref> [33] </ref>. Not only does a lesser packet requirement reduce network loading, it also may improve a critical performance feature, memory operation latency, by eliminating waits for acknowledgements in the protocol.
Reference: [34] <author> D. Lenoski, K. Gharachorloo, J. Laudon, A. Gupta, J. Hennessy, M. Horowitz, and M. Lam. </author> <title> Design of Scalable Shared-Memory Multiprocessors: The DASH Approach. </title> <booktitle> In Proceedings of COMPCON, </booktitle> <pages> pages 62-7, </pages> <year> 1990. </year>
Reference-contexts: Due to this scalability advantage, direct networks are gaining wide acceptance; recent multiprocessor machines such as Tera Computer's TERA machine [5], Stanford DASH <ref> [34] </ref> and the MIT Alewife [1] all use direct networks. For all types of concurrent computers, communication networks play a critical role in overall system performance. Unfortunately, even direct networks cannot provide the characteristics of an ideal network, infinite bandwidth and zero latency. <p> Unfortunately, even direct networks cannot provide the characteristics of an ideal network, infinite bandwidth and zero latency. To close the gap, several approaches have been developed. One approach is to reduce the frequency of the communications by using cache (Stanford DASH <ref> [34] </ref>, and the MIT Alewife [1]). The number of memory references to distant memory units can be dramatically reduced by exploiting locality of reference. Another approach is to hide or tolerate the latency by overlapping useful work with communication latency.
Reference: [35] <author> D. Lenoski, J. Laudon, K. Gharacharloo, W. Weber, A. Gupta, J. Hennessy, M. Horowitz, and M. Lam. </author> <title> The Stanford Dash Multiprocessor. </title> <booktitle> IEEE Computer, </booktitle> <month> March </month> <year> 1992. </year>
Reference-contexts: Network Topology We basically study n-dimensional mesh networks. We focus on low (two, three, or four)-dimensional mesh networks because they are currently in 68 widespread use in many machines such as the Intel Paragon [14], Intel iWARP [8, 43], the MIT J-machine [21, 24], Stanford DASH <ref> [35] </ref>, and Tera Computer's TERA machine [5]. Unless stated otherwise, the two- and four-dimensional networks used contain 256 nodes. The size was determined for reasonable amounts of simulation time. For simplicity, we study networks with uniform radix, k.
Reference: [36] <author> D. Linder and J. Harden. </author> <title> An Adaptive and Fault Tolerant Wormhole Routing Strategy for k-ary n-cubes. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-40(1):2-12, </volume> <month> January </month> <year> 1991. </year>
Reference-contexts: dependency, and thus no deadlock. 3 Eastbound or westbound messages means that they are destined to nodes located to the east or west of the source nodes, respectively. 28 westbound messages are shown. 3.2.2 Linder-Harden's algorithm Dally's approach is expanded to higher-dimensional and/or torus networks by Linder and Harden in <ref> [36] </ref>. Adaptive routing for n-dimensional mesh networks is expanded from Dally's scheme by dividing the network into 2 n1 virtual networks to break all of the inter-dimensional cycles. Thus, each physical channel is associated with 2 n1 virtual channels for deadlock-free adaptive routing. <p> Guaranted in-order packet delevery has been known to simplify communication protocol and/or improve network performance. In Section 4.5, we summarize the algorithms presented in this chapter. 4.1 Notation and Terminology We adopt notation similar to that in <ref> [17, 36] </ref>. We present routing algorithm only for a physical topology of a k-ary n-cube with no wraparound paths (mesh networks). Torus networks require slightly more complicated algorithm for deadlock prevention. <p> A primary concern in adaptive networks is the cost of deadlock prevention. To assure deadlock-free routing, the planar scheme requires only three virtual channels for k-ary n-cubes without wraparound channels. This is a dramatic improvement over previously published schemes <ref> [36, 22] </ref>. As shown before, the Linder-Harden deadlock prevention scheme requires 2 n1 virtual channels, a significant hardware overhead. Equally important, in planar-adaptive routing, deadlock and livelock are avoided without any complex reversal counting [22] or aging schemes [39]. <p> To explore the answer to the question, in this section, the fully adaptive router is compared with the PAR with equal or fewer hardware resources. The fully adaptive router used in the study is modeled on Linder and Harden's adaptive routing algorithm <ref> [36] </ref>. The fully adaptive router allows messages to take all possible minimal paths. Details on their routing algorithms have been described in Section 3.2. Their model requires 2 n1 virtual channels per link to prevent deadlock for n-dimensional mesh networks.
Reference: [37] <author> John N. Mailhot. </author> <title> A Comparative Study of Routing and Flow Control Strategies in K-ary N-cube Networks. B.s. </title> <type> thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1988. </year> <month> 151 </month>
Reference-contexts: As the depth of queues grows, network throughput increases proportionally. The performance dependence on the depth of the queues is described in detail in <ref> [37] </ref>. The other scheme, called virtual lane flow control, virtually eliminates the interferences by providing passing lanes over the blocked channel [19]. The idea behind virtual lanes is to implement the duplicate channels by using buffers instead of additional physical wires since physical channels would increase the network cost significantly. <p> PAR allows hardware implementation of a low cost, wormhole routed, adaptive router. In addition, the lesser virtual channels requirement may significantly improve router speed or allow additional hardware resources to be used for other performance enhancing schemes such as deep FIFO queues for partial buffering or virtual lanes <ref> [37, 19] </ref>. 1 This is the maximum number of virtual channels required. In fact, the first dimension requires a single virtual channel per link and the last dimension requires two virtual channels only. All of the intermediate dimensions require three virtual channels. <p> Straightforward approaches to moving these blocks give rise to long messages. While we know of no studies examining the performance of wormhole-routed networks under traffic with nonuniform packet sizes, there has been a study of the impact of different message sizes (uniform distribution) on network performance <ref> [37] </ref>. This study shows that long messages reduce network throughput in wormhole-routed networks because longer messages increase the coupling between channels and buffer resources in the 120 network, increasing message interaction. This increased interaction causes congestion at lower load factors, reducing maximum throughput.
Reference: [38] <author> NCUBE, </author> <title> Beaverton, Oregon. NCUBE 2 6400 Series Supercomputer: </title> <type> Technical Overview, </type> <year> 1989. </year>
Reference-contexts: Issues of virtual lanes as well as planar-adaptive routing will be revisited for high-performance networks under the hybrid traffic. 118 7 NETWORK PERFORMANCE UNDER BIMODAL LOADS As large scale commercial multicomputers gain wider acceptance, their patterns of use inevitably change. While previous systems <ref> [4, 38] </ref> were used primarily as back-end computational engines, contemporary systems are likely to be used to support a variety of applications, programming systems, system software, and batch and interactive loads.
Reference: [39] <author> J. Ngai. </author> <title> A Framework for Adaptive Routing in Multicomputer Networks. </title> <type> PhD thesis, </type> <institution> California Institute of Technology, Computer Science Department, </institution> <year> 1989. </year> <month> Caltech-CS-TR-89-09. </month>
Reference-contexts: This is a dramatic improvement over previously published schemes [36, 22]. As shown before, the Linder-Harden deadlock prevention scheme requires 2 n1 virtual channels, a significant hardware overhead. Equally important, in planar-adaptive routing, deadlock and livelock are avoided without any complex reversal counting [22] or aging schemes <ref> [39] </ref>. This means that planar-adaptive routers can be very simple and as a result can make routing decisions very rapidly. Consequently, 45 they may run faster than other adaptive routers which require complex techniques for deadlock and livelock prevention.
Reference: [40] <author> J. Ngai and C. Seitz. </author> <title> A Framework for Adaptive Routing in Multicomputer Networks. </title> <booktitle> In Proceedings of the 1989 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1989. </year>
Reference-contexts: Instead, misrouting gives rise to a new problem, guaranteeing that all of the messages are eventually delivered to their destinations. We briefly review some of the approaches that have been developed to guarantee packet delivery. A priority based adaptive routing algorithm was introduced by Ngai and Seitz in <ref> [40] </ref>. Each packet is assigned a priority which is based on the age of the packet and the distance to its destination. The priority changes dynamically, increasing as the packet remains in the network longer or approaches its destination.
Reference: [41] <author> L. Ni and C. Glass. </author> <title> The Turn Model for Adaptive Routing. </title> <booktitle> In Proceedings of the International Symposium on Computer Architecture, </booktitle> <year> 1992. </year>
Reference-contexts: Several approaches have shown that the hardware cost for deadlock prevention is reduced by restricting adaptivity to some extent. A good example of the partially-adaptive routing algorithm is the Turn model introduced by Ni and Glass in <ref> [41] </ref>. They observed that prohibiting some turns on k-ary n-cube networks allows adaptive routing without causing any channel dependency cycles. Figure 3.2 illustrates an application of the Turn model to two-dimensional networks. <p> Consequently, all of the westbound messages are routed in a deterministic way. However, all of the eastbound messages are routed in a fully adaptive way. This algorithm is called west-first. The Turn model may or may not allow misrouting. Although a livelock prevention mechanism was not presented in <ref> [41] </ref>, the Turn model is capable of allowing misrouting on wormhole-routed networks. In contrast to other wormhole-routed adaptive algorithms, it does not require any virtual channels for deadlock prevention. However, since the Turn model resolves deadlocks in an irregular fashion, it may cause uneven channel utilization. <p> From such a complex range of sources, we anticipate a new range of network communication workloads with a wide variety of traffic patterns and message size distributions. However, to date much of the study of multicomputer network performance is based on uniform message size distributions <ref> [17, 3, 41] </ref>. While presuming uniform traffic simplifies simulations and the interpretation of results, these traffic loads are not representative of the actual communication workloads. It is also important to study the interaction of messages of different sizes, examining the impact of hybrid traffic loads.
Reference: [42] <author> M. Parthasarathy. </author> <title> Implementing Shared Memory on Large-Scale Multiprocessors. </title> <type> Master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, Department of Electrical and Computer Engineering, </institution> <year> 1992. </year>
Reference-contexts: Not only does a lesser packet requirement reduce network loading, it also may improve a critical performance feature, memory operation latency, by eliminating waits for acknowledgements in the protocol. In a number of other shared-memory protocols, preserving message-transmission order may also simplify the protocol and improve its performance <ref> [10, 28, 42] </ref>. Our minimal, adaptive routing algorithms support both in-order packet delivery and adaptive, unordered packet delivery simultaneously. All traffic must be specified as ordered or unordered.
Reference: [43] <author> C. Peterson, J. Sutton, and P. Wiley. </author> <title> iWarp: a 100-MOPS LIW Microprocessor for Multicomputers. </title> <booktitle> IEEE Micro, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: Throughout this chapter, we use the network model described below. Network Topology We basically study n-dimensional mesh networks. We focus on low (two, three, or four)-dimensional mesh networks because they are currently in 68 widespread use in many machines such as the Intel Paragon [14], Intel iWARP <ref> [8, 43] </ref>, the MIT J-machine [21, 24], Stanford DASH [35], and Tera Computer's TERA machine [5]. Unless stated otherwise, the two- and four-dimensional networks used contain 256 nodes. The size was determined for reasonable amounts of simulation time. For simplicity, we study networks with uniform radix, k.
Reference: [44] <author> G. F. Pfister. </author> <title> The IBM Research Parallel Processor Prototype (RP3): Introduction and Architecture. </title> <booktitle> In Proceedings of the ICPP, </booktitle> <pages> pages 764-771, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: Shared-memory multiprocessors provide a single address space shared by all of the processors. Processors communicate by accessing data in shared-memory units. Due to the equidis-tance property between any processor and any memory unit, multistage interconnection networks have been preferred by multiprocessors <ref> [44, 2] </ref>. Since communication between any pairs of nodes occurs through multiple stages of the network, multistage networks are also referred as indirect networks. In contrast, message-passing multicomputers do not provide a global address space.
Reference: [45] <author> S. Lillevik, </author> <title> Intel Corporation. Touchstone Program Overview. </title> <booktitle> In Proceedings of the Fifth Distributed Memory Computers Conference, </booktitle> <year> 1990. </year>
Reference-contexts: Instead, memory is distributed across the processing nodes; only the data in local memory can be accessed directly. Access to data in remote memories is supported by message passing between processors. Direct networks, represented by grid or mesh networks, have been used predominantly in multicomputers <ref> [47, 45, 23, 46] </ref>. However, as direct networks gain acceptance in shared-memory multiprocessor designs, distinguishing these machines by network topology is less appropriate. <p> However, these characteristics are dependent on the granularity of the parallelism exploited and the communication reducing techniques used. Hence, throughout the thesis, we refer to them as multicomputer networks implying communication networks for both types of concurrent computers. 1.2 The Problem Most multicomputers use dimension-order routing <ref> [47, 45, 23, 46] </ref> due to its simplicity and deadlock freedom. Under dimension-order routing, a message is routed successively in each of the dimensions. Since each message passes through the network dimensions in the same order, interdimensional cycles causing deadlock cannot form. <p> However, adaptive routing introduces new possibilities of deadlock or livelock. In the next chapter, we discuss a variety of adaptive routing algorithms suggested to prevent deadlock and livelock. 24 3 RELATED WORK: ADAPTIVE ROUTING ALGORITHMS Most existing multicomputers use dimension-order routing <ref> [47, 45, 23, 46] </ref> due to its simplicity and freedom from deadlock. However, dimension-order routing allocates network resources inflexibly, preventing full utilization of the physical channels. To increase routing flexibility, many algorithms have been suggested to route messages adaptively based on the network state.
Reference: [46] <author> C. L. Seitz. </author> <title> The Cosmic Cube. </title> <journal> Communications of the ACM, </journal> <volume> 28(1) </volume> <pages> 22-33, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: Instead, memory is distributed across the processing nodes; only the data in local memory can be accessed directly. Access to data in remote memories is supported by message passing between processors. Direct networks, represented by grid or mesh networks, have been used predominantly in multicomputers <ref> [47, 45, 23, 46] </ref>. However, as direct networks gain acceptance in shared-memory multiprocessor designs, distinguishing these machines by network topology is less appropriate. <p> However, these characteristics are dependent on the granularity of the parallelism exploited and the communication reducing techniques used. Hence, throughout the thesis, we refer to them as multicomputer networks implying communication networks for both types of concurrent computers. 1.2 The Problem Most multicomputers use dimension-order routing <ref> [47, 45, 23, 46] </ref> due to its simplicity and deadlock freedom. Under dimension-order routing, a message is routed successively in each of the dimensions. Since each message passes through the network dimensions in the same order, interdimensional cycles causing deadlock cannot form. <p> However, adaptive routing introduces new possibilities of deadlock or livelock. In the next chapter, we discuss a variety of adaptive routing algorithms suggested to prevent deadlock and livelock. 24 3 RELATED WORK: ADAPTIVE ROUTING ALGORITHMS Most existing multicomputers use dimension-order routing <ref> [47, 45, 23, 46] </ref> due to its simplicity and freedom from deadlock. However, dimension-order routing allocates network resources inflexibly, preventing full utilization of the physical channels. To increase routing flexibility, many algorithms have been suggested to route messages adaptively based on the network state.
Reference: [47] <author> C. L. Seitz, W. C. Athas, C. M. Flaig, A. J. Martin, J. Seizovic, C. S. Steele, and W. Su. </author> <booktitle> The Architecture and Programming of the Ametek Series 2010 Multicom-puter. In Proceedings of the Third Conference on Hypercube Computers, </booktitle> <pages> pages 33-6. </pages> <publisher> Association for Computing Machinery, ACM Press, </publisher> <month> January </month> <year> 1988. </year>
Reference-contexts: Instead, memory is distributed across the processing nodes; only the data in local memory can be accessed directly. Access to data in remote memories is supported by message passing between processors. Direct networks, represented by grid or mesh networks, have been used predominantly in multicomputers <ref> [47, 45, 23, 46] </ref>. However, as direct networks gain acceptance in shared-memory multiprocessor designs, distinguishing these machines by network topology is less appropriate. <p> However, these characteristics are dependent on the granularity of the parallelism exploited and the communication reducing techniques used. Hence, throughout the thesis, we refer to them as multicomputer networks implying communication networks for both types of concurrent computers. 1.2 The Problem Most multicomputers use dimension-order routing <ref> [47, 45, 23, 46] </ref> due to its simplicity and deadlock freedom. Under dimension-order routing, a message is routed successively in each of the dimensions. Since each message passes through the network dimensions in the same order, interdimensional cycles causing deadlock cannot form. <p> However, adaptive routing introduces new possibilities of deadlock or livelock. In the next chapter, we discuss a variety of adaptive routing algorithms suggested to prevent deadlock and livelock. 24 3 RELATED WORK: ADAPTIVE ROUTING ALGORITHMS Most existing multicomputers use dimension-order routing <ref> [47, 45, 23, 46] </ref> due to its simplicity and freedom from deadlock. However, dimension-order routing allocates network resources inflexibly, preventing full utilization of the physical channels. To increase routing flexibility, many algorithms have been suggested to route messages adaptively based on the network state.

References-found: 47

