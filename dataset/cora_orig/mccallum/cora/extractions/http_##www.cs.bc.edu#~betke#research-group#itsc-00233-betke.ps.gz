URL: http://www.cs.bc.edu/~betke/research-group/itsc-00233-betke.ps.gz
Refering-URL: http://www.cs.bc.edu/techreps.html
Root-URL: http://www.cs.bc.edu
Title: Highway Scene Analysis in Hard Real-Time  
Author: Margrit Betke Esin Haritaoglu and Larry S. Davis 
Address: Chestnut Hill, MA 02167 College Park, MD 20742  
Affiliation: Boston College University of Maryland  
Abstract: A hard real-time vision system has been developed that analyses color videos taken from a car driving on a highway. The system uses a combination of color, edge, and motion information to recognize and track the road boundaries, lane markings and other vehicles on the road. Cars are recognized by matching templates that are cropped from the input data online, by detecting image features, and by evaluating how these features relate to each other. Cars are also recognized by temporal differencing and by tracking motion parameters that are typical for cars. The system recognizes and tracks road boundaries and lane markings using a recursive least squares filter. Experimental results demonstrate robust, real-time car recognition and tracking over thousands of image frames. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Betke, E. Haritaoglu, and L. Davis. </author> <title> Multiple vehicle detection and tracking in hard real time. </title> <booktitle> In Intelligent Vehicles, </booktitle> <pages> pages 351-356, </pages> <year> 1996. </year> <note> Also UMD CAR-TR-858, http://www.cfar.umd.edu:80/ftp/TRs/CVL-Reports-1996/TR3667-Betke.ps.gz. </note>
Reference-contexts: Even in the specific case of a highway's well-structured environment, this is a difficult problem. Traffic volume, driver behavior, lighting and road conditions, and so forth are unpredictable. Our initial vision system, introduced in Ref. <ref> [1] </ref>, failed in heavy traffic or on highways with cluttered roadsides. <p> This description could be used to estimate the positions of the vehicles in the environment and their distances from the camera-assisted car. The vision system contains four main components: the car detector, the road detector, the tracker, and the process coordinator (see Figure 1). Ref. <ref> [1] </ref> provides the details of an early version of the system. 3 COLOR IMAGE ANALYSIS Color provides information that makes feature detection more robust. For example, in Figure 2, the hue and saturation images highlight the traffic signs, some car features, and the lane markings. <p> Recognition of vehicles that suddenly enter the scene is difficult. Cars and trucks come into view with very different speeds, sizes, and appearances. In Ref. <ref> [1] </ref>, we describe how passing vehicles are recognized by an analysis of the motion information provided by multiple consecutive image frames. <p> The size of this boundary is determined adaptively. The outline of the potential car within the current tracking window is computed by a feature search described in detail in Ref. <ref> [1] </ref>. As a next step, a template of a size corresponding to the hypothesized size of the vehicle is created from a stored model image using the method developed in Ref. [2]. The template is correlated with the image region that is hypothesized to contain the vehicle. <p> Note that the correlation coefficient is invariant to constant scale factors in brightness and can therefore adapt to the lighting conditions of a particular image frame. The model images shown in Ref. <ref> [1] </ref> are only used to create car templates online as long as the tracked object is not recognized to be a vehicle yet; otherwise, the model is created online by cropping the currently tracked vehicle. Online model creation.

Reference: [3] <author> D. Beymer and J. Malik. </author> <title> Tracking vehicles in congested traffic. </title> <booktitle> In Intelligent Vehicles, </booktitle> <pages> pages 130-135, </pages> <year> 1996. </year>
Reference-contexts: Related problems are autonomous convoy driving, e.g., Ref. [15] and traffic monitoring using a station-ary camera, e.g., Ref. <ref> [3, 9] </ref>. 2 VISION SYSTEM OVERVIEW Given an input of a video sequence taken from a moving car, the vision system outputs an online description of road parameters and locations and sizes of other vehicles in the images.
Reference: [4] <author> J. D. Crisman and Ch. E. Thorpe. SCARF: </author> <title> A color vision system that tracks roads and intersections. </title> <journal> IEEE Trans. on Robotics and Automation, </journal> <volume> 9 </volume> <pages> 49-58, </pages> <year> 1993. </year>
Reference-contexts: Approaches for recognizing and/or tracking cars from a moving camera are, for example, given in Refs. [5, 6, 10, 11, 12, 16, 17, 18] and for lane detection, e.g., in Refs. <ref> [4, 11, 12, 13] </ref>.
Reference: [5] <author> U. Franke and I. Kutzbach. </author> <title> Fast stereo based object detection for stop & go traffic. </title> <booktitle> In Intelligent Vehicles, </booktitle> <pages> pages 339-344, </pages> <year> 1996. </year>
Reference-contexts: Approaches for recognizing and/or tracking cars from a moving camera are, for example, given in Refs. <ref> [5, 6, 10, 11, 12, 16, 17, 18] </ref> and for lane detection, e.g., in Refs. [4, 11, 12, 13].
Reference: [6] <author> V. Graefe and W. Efenberger. </author> <title> A novel approach for the detection of vehicles on freeways by real-time vision. </title> <booktitle> In Intelligent Vehicles, </booktitle> <pages> pages 363-368, </pages> <year> 1996. </year>
Reference-contexts: Approaches for recognizing and/or tracking cars from a moving camera are, for example, given in Refs. <ref> [5, 6, 10, 11, 12, 16, 17, 18] </ref> and for lane detection, e.g., in Refs. [4, 11, 12, 13].
Reference: [7] <author> H. A. Hansson, H. W. Lawson, M. Stromberg, and S. Larsson. BASEMENT: </author> <title> A distributed real-time architecture for vehicle applications. </title> <booktitle> Real-Time Systems, </booktitle> <volume> 11 </volume> <pages> 223-244, </pages> <year> 1996. </year>
Reference-contexts: Not only must the supporting vision system do its processing extremely fast, i.e., in soft real time, but it also must guarantee to react within a fixed time frame under all circumstances, i.e., in hard real time. Hansson et al. <ref> [7] </ref> have developed a non-vision based, distributed real-time architecture for vehicle applications that incorporates both hard and soft real-time processing. However, computer vision research for intelligent vehicles has so far only aimed at soft real-time performance, i.e., fast processing without timing guarantees.
Reference: [8] <author> S. Haykin. </author> <title> Adaptive Filter Theory. </title> <publisher> Prentice Hall, </publisher> <year> 1991. </year>
Reference-contexts: Finally, it ensures that the tracker does not lose a car even if the road curves. 6 BOUNDARY AND LANE DETECTION Road boundaries and lane markings are detected in each frame by a spatial recursive least squares filter (RLS) <ref> [8] </ref>. The image in Figure 4 illustrates the detected lane and boundary points as black "+" symbols and shows the lines fitted to these points.
Reference: [9] <author> T. Ikeda, S. Ohnaka, and M. Mizoguchi. </author> <title> Traffic measurement with a roadside vision system - individual tracking of overlapped vehicles. </title> <booktitle> In ICPR, </booktitle> <pages> pages 859-864, </pages> <year> 1996. </year>
Reference-contexts: Related problems are autonomous convoy driving, e.g., Ref. [15] and traffic monitoring using a station-ary camera, e.g., Ref. <ref> [3, 9] </ref>. 2 VISION SYSTEM OVERVIEW Given an input of a video sequence taken from a moving car, the vision system outputs an online description of road parameters and locations and sizes of other vehicles in the images.
Reference: [10] <author> L. Kaminski, J. Allen, I. Masaki, and G. Lemus. </author> <title> A sub-pixel stereo vision system for cost-effective intelligent vehicle applications. </title> <booktitle> In Intelligent Vehicles, </booktitle> <pages> pages 7-12, </pages> <year> 1995. </year>
Reference-contexts: Approaches for recognizing and/or tracking cars from a moving camera are, for example, given in Refs. <ref> [5, 6, 10, 11, 12, 16, 17, 18] </ref> and for lane detection, e.g., in Refs. [4, 11, 12, 13].
Reference: [11] <author> Q. Luong, J. Weber, D. Koller, and J. Malik. </author> <title> An integrated stereo-based approach to automatic vehicle guidance. </title> <booktitle> In ICCV, </booktitle> <pages> pages 52-57, </pages> <year> 1995. </year>
Reference-contexts: Approaches for recognizing and/or tracking cars from a moving camera are, for example, given in Refs. <ref> [5, 6, 10, 11, 12, 16, 17, 18] </ref> and for lane detection, e.g., in Refs. [4, 11, 12, 13]. <p> Approaches for recognizing and/or tracking cars from a moving camera are, for example, given in Refs. [5, 6, 10, 11, 12, 16, 17, 18] and for lane detection, e.g., in Refs. <ref> [4, 11, 12, 13] </ref>.
Reference: [12] <author> M. Maurer, R. Behringer, S. Furst, F. Thomarek, and E. D. Dickmanns. </author> <title> A compact vision system for road vehicle guidance. </title> <booktitle> In ICPR, </booktitle> <volume> volume 3, </volume> <pages> pages 313-317, </pages> <year> 1996. </year>
Reference-contexts: Approaches for recognizing and/or tracking cars from a moving camera are, for example, given in Refs. <ref> [5, 6, 10, 11, 12, 16, 17, 18] </ref> and for lane detection, e.g., in Refs. [4, 11, 12, 13]. <p> Approaches for recognizing and/or tracking cars from a moving camera are, for example, given in Refs. [5, 6, 10, 11, 12, 16, 17, 18] and for lane detection, e.g., in Refs. <ref> [4, 11, 12, 13] </ref>.
Reference: [13] <author> D. Pomerleau. RALPH: </author> <title> Rapidly adapting lateral position handler. </title> <booktitle> In Intelligent Vehicles, </booktitle> <pages> pages 506-511, </pages> <year> 1995. </year>
Reference-contexts: Approaches for recognizing and/or tracking cars from a moving camera are, for example, given in Refs. [5, 6, 10, 11, 12, 16, 17, 18] and for lane detection, e.g., in Refs. <ref> [4, 11, 12, 13] </ref>.
Reference: [14] <author> M. C. Saksena, J. da Silva, and A. K. </author> <title> Agrawala. </title> <booktitle> Design and implementation of Maruti-II. In Principles of Real-Time Systems. </booktitle> <publisher> Prentice-Hall, </publisher> <year> 1994. </year>
Reference-contexts: We utilize the advantages of the hard real-time operating system "Maruti," whose scheduling guarantees prior to any execution that the required deadlines are met and the vision system will react in a timely manner <ref> [14] </ref>. Approaches for recognizing and/or tracking cars from a moving camera are, for example, given in Refs. [5, 6, 10, 11, 12, 16, 17, 18] and for lane detection, e.g., in Refs. [4, 11, 12, 13].
Reference: [15] <author> H. Schneiderman, M. Nashman, A. J. Wavering, and R. Lumia. </author> <title> Vision-based robotic convoy driving. </title> <journal> Machine Vision and Applications, </journal> <volume> 8(6) </volume> <pages> 359-364, </pages> <year> 1995. </year>
Reference-contexts: Approaches for recognizing and/or tracking cars from a moving camera are, for example, given in Refs. [5, 6, 10, 11, 12, 16, 17, 18] and for lane detection, e.g., in Refs. [4, 11, 12, 13]. Related problems are autonomous convoy driving, e.g., Ref. <ref> [15] </ref> and traffic monitoring using a station-ary camera, e.g., Ref. [3, 9]. 2 VISION SYSTEM OVERVIEW Given an input of a video sequence taken from a moving car, the vision system outputs an online description of road parameters and locations and sizes of other vehicles in the images.
Reference: [16] <author> S. M. Smith. ASSET-2: </author> <title> Real-time motion segmentation and shape tracking. </title> <booktitle> In ICCV, </booktitle> <pages> pages 237-244, </pages> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: Approaches for recognizing and/or tracking cars from a moving camera are, for example, given in Refs. <ref> [5, 6, 10, 11, 12, 16, 17, 18] </ref> and for lane detection, e.g., in Refs. [4, 11, 12, 13].
Reference: [17] <author> F. Thomanek, E. D. Dickmanns, and D. Dick-manns. </author> <title> Multiple object recognition and scene interpretation for autonomous road vehicle guidance. </title> <booktitle> In Intelligent Vehicles, </booktitle> <pages> pages 231-236, </pages> <year> 1994. </year>
Reference-contexts: Approaches for recognizing and/or tracking cars from a moving camera are, for example, given in Refs. <ref> [5, 6, 10, 11, 12, 16, 17, 18] </ref> and for lane detection, e.g., in Refs. [4, 11, 12, 13].
Reference: [18] <author> T. Zielke, M. Brauckmann, and W. von Seelen. </author> <title> Intensity and edge-based symmetry detection with an application to car-following. CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> 58 </volume> <pages> 177-190, </pages> <year> 1993. </year>
Reference-contexts: Approaches for recognizing and/or tracking cars from a moving camera are, for example, given in Refs. <ref> [5, 6, 10, 11, 12, 16, 17, 18] </ref> and for lane detection, e.g., in Refs. [4, 11, 12, 13].
References-found: 17

