URL: http://www-robotics.usc.edu/~maja/publications/techrep.ps.gz
Refering-URL: http://www-robotics.usc.edu/~maja/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: What do People Look at When Watching Human Movement?  
Author: Maja J Mataric Marc Pomplun 
Keyword: Perceptual-motor interaction; Eye-tracking; Movement imitation  
Address: 941 West 37th Place, Los Angeles, CA 90089-0781  33501 Bielefeld, Germany.  
Affiliation: Computer Science Department, University of Southern California,  Department of Neuroinformatics, Faculty of Technology, Bielefeld University,  
Note: Neuroscience Program and the  
Abstract: This paper describes experiments performed with forty subjects wearing an eye-tracker and watching and imitating videos of finger, hand, and arm movements. For all types of stimuli, the subjects tended to fixate on the hand, regardless of whether they were imitating or just watching. The results lend insight into the connection between visual perception and motor control, suggesting that: 1) people analyze human arm movements largely by tracking the hand or the end-point, even if the movement is performed with the entire arm, and 2) when imitating, people use internal innate and learned models of movement, possibly in the form of motor primitives, to recreate the details of whole-arm posture and movement from end-point trajecto ries.
Abstract-found: 1
Intro-found: 1
Reference: <author> Ballard, D. H., Hayhoe, M. M., Li, F. & Whitehead, S. D. </author> <year> (1992), </year> <title> Hand-Eye Co-ordination During Sequential Tasks, </title> <booktitle> in `Proceedings of the Royal Society of London'. </booktitle>
Reference-contexts: More recently, eye-tracking of video stimuli has been applied to cooperative problem solving (Velichkovsky, Pomplun & Rieser 1996) and toward exploring the role of eye movements in working memory tested on tasis involving construction from a model <ref> (Ballard, Hayhoe, Li & Whitehead 1992, Hayhoe, Ballard & Whitehead 1993) </ref>. All eye-tracking experiments so far were aimed at addressing perceptual behavior. Interestingly, our data have implications not only on the perception of movement, but on its links with movement generation.
Reference: <author> Carpenter, G. A. & Grossberg, S. </author> <year> (1987), </year> <title> `A massively parallel architecture for a self-organizing neural pattern recognition machine', Computer Vision, Graphics, </title> <booktitle> and Image Processing 37, </booktitle> <pages> 54-115. </pages>
Reference: <author> Daugs, R., Bliscke, K. & Olivier, N. </author> <year> (1978), </year> <title> Scanning Habits and Visuo-Motor Learning, </title> <editor> in J. K. O'Regan & A. Levy-Schoen, eds, </editor> <title> `Eye Movements, From Physiology to Cognition: </title> <booktitle> Selected/Edited Proceedings of the Third European Conference on Eye Movements', </booktitle> <pages> pp. 323-332. </pages>
Reference-contexts: The experiments we report on are the first to use eye-tracking with video to study imitation of human movement. Eye-tracking experiments have been used on static images; for example in object boundary tracking (Kudo, Uo-mori, Yamada, Oinishi & Sugie 1992), and skill learning from rows of picture-text combinations <ref> (Daugs, Bliscke & Olivier 1978) </ref>. Early work with video has been applied to the study of memory representations (Teichner, LeMaster & Kinney 1978).
Reference: <author> Davis, J. M. </author> <year> (1973), </year> <title> Imitation: A Review and Critique, </title> <editor> in Bateson & Klopfer, eds, `Perspectives in Ethology', </editor> <volume> Vol. 1, </volume> <publisher> Plenum Press, </publisher> <pages> pp. 43-72. </pages>
Reference: <author> Decety, J. </author> <year> (1996), </year> <title> `Do imagined and executed actions share the same neural substrate?', </title> <journal> Cognitive Brain Research 3, </journal> <pages> 87-93. </pages>
Reference: <author> Epelboim, J., Steinman, R. M., Kowler, E., Edwards, M., Pizlo, Z., Erkelens, C. J. & Collewijn, H. </author> <year> (1995), </year> <title> `The Function of Visual Search and Memory in Sequential Looking Tasks', </title> <booktitle> Vision Research 35(23-24), </booktitle> <pages> 3401-3422. </pages>
Reference-contexts: The data are also related to results found when subjects were tested in a task involving just looking at targets or looking while tapping; the subjects' eye-movements differed between the two <ref> (Epelboim, Steinman, Kowler, Edwards, Pizlo, Erkelens & Collewijn 1995) </ref>, presumably due to varied memory load. Our lack of difference between the imitation and no-imitation conditions points to a general movement observation strategy.
Reference: <author> Flash, T. & Hogan, N. </author> <year> (1985), </year> <title> `The coordination of the arm movements: an experimentally confirmed mathematical model', </title> <journal> Journal of Neuro-science 7, </journal> <pages> 1688-1703. </pages>
Reference: <author> Georgopoulos, A. P., Kettner, R. E. & Schwartz, A. B. </author> <year> (1988), </year> <title> `Primate Motor Cortex and Free Arm Movements to Visual Targets in Tree-Dimensional Space 2. Coding of the Direction of Movement by a Neuronal Population', </title> <journal> Journal of Neuroscience 8, </journal> <pages> 2928-2937. </pages>
Reference: <author> Gomi, H. & Kawato, M. </author> <year> (1996), </year> <title> `Equilibrium-Point Control Hypothesis Examined by Measured Arm Stiffness During Multijoint Movement', </title> <booktitle> Science 272, </booktitle> <pages> 117-120. </pages>
Reference: <author> Hayhoe, M. M., Ballard, D. H. & Whitehead, S. D. </author> <year> (1993), </year> <title> Memory Use During Hand-Eye Coordination, </title> <booktitle> in `Proceedings of the Fifteenth Annual Conference of the Cognitive Science Society', </booktitle> <address> Boulder, Colorado, </address> <pages> pp. 534-538. </pages>
Reference: <author> Hinton, G. E., Dayan, P., Frey, B. J. & Neal, R. M. </author> <year> (1995), </year> <title> `The wake-sleep algorithm for unsupervised neural networks', </title> <booktitle> Science 268, </booktitle> <pages> 1158-1161. </pages>
Reference: <author> Kahneman, D. </author> <year> (1973), </year> <title> Attention and Effort, </title> <publisher> Prentice Hall, </publisher> <address> Englewood-Cliffs, New Jersey. </address>
Reference-contexts: No interaction between the two factors was found (F = 1:83; p = 0:167). Since our stimuli were of constant brightness, the variation of pupil dilation can be assumed to be positively correlated with the subjects' cognitive activity <ref> (Kahneman 1973) </ref>. In this context, the data reveal that increased stimulus complexity induces higher mental effort, i.e., pupil dilation increases from finger to hand to arm movement films.
Reference: <author> Kolb, B. & Milner, B. </author> <year> (1981), </year> <title> `Performance of Complex Arm and Facial Movements After Focal Brain Lesions', </title> <booktitle> Neurophychologia 19, </booktitle> <pages> 491-504. </pages> <note> 26 Konczak, </note> <author> J. & Thelen, E. </author> <year> (1996), </year> <title> Bi-directional theory approach to integra-tion, </title> <editor> in T. Inui & J. McClelland, eds, </editor> <title> `Attention and Performance XVI', </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <pages> pp. 335-367. </pages>
Reference: <author> Kudo, H., Uomori, K., Yamada, N., Oinishi, N. & Sugie, N. </author> <year> (1992), </year> <title> Binocular Fixation-Point Shifts Induced by a Limb Occulusion, </title> <booktitle> in `Proceedings of the IEEE/EMBS', </booktitle> <pages> pp. 1670-1671. </pages>
Reference-contexts: The experiments we report on are the first to use eye-tracking with video to study imitation of human movement. Eye-tracking experiments have been used on static images; for example in object boundary tracking <ref> (Kudo, Uo-mori, Yamada, Oinishi & Sugie 1992) </ref>, and skill learning from rows of picture-text combinations (Daugs, Bliscke & Olivier 1978). Early work with video has been applied to the study of memory representations (Teichner, LeMaster & Kinney 1978).
Reference: <author> Miyamoto, H., Schaal, S., Gandolfo, F., Gomi, H., Koike, Y., Osu, R., Nakano, E., Wada, Y. & Kawato, M. </author> <year> (1996), </year> <title> `A Kendama Learning Robot Based on Bi-Directional Theory', Neural Networks. </title>
Reference: <author> Morasso, P. </author> <year> (1981), </year> <title> `Spatial control of arm movements', </title> <journal> Experimental Brain Research 42, </journal> <pages> 223-227. </pages>
Reference-contexts: The observed results are consistent with the extensive body of work supporting end-point motion planning <ref> (Morasso 1981, Flash & Hogan 1985, Georgopoulos, Kettner & Schwartz 1988) </ref>.
Reference: <author> Pelisson, D., Goodale, M. A. & Prablanc, C. </author> <year> (1978), </year> <title> Adjustments of Hand Pointings to Visual Targets do not Need Visual Reafference From the Moving Limb, </title> <editor> in J. K. O'Regan & A. Levy-Schoen, eds, </editor> <title> `Eye Movements, From Physiology to Cognition: </title> <booktitle> Selected/Edited Proceedings of the Third European Conference on Eye Movements', </booktitle> <pages> pp. 115|121. </pages>
Reference-contexts: Vogt (1995) studied the connection with an imitation in drawing of sine/cosine wave functions and suggested the absence of an intermediate level between perception and motor control and the presence of a generative perception module. Earlier experiments in hand-pointing adjustments without visual feedback allow for similar conclusions <ref> (Pelisson, Goodale & Prablanc 1978) </ref>. Imitation serves as a natural domain for studying sensori-motor integration and addressing a number of interesting questions. This paper focuses on analyzing data from the perceptual side of the imitation process in order to address some of those questions of interplay between the two systems.
Reference: <author> Rizzolatti, G., Gadiga, L., Gallese, V. & Fogassi, L. </author> <year> (1996), </year> <title> `Premotor cortex and the recognition of motor actions', </title> <journal> Cognitive Brain Research 3, </journal> <pages> 131-141. </pages>
Reference: <author> Stampe, D. M. </author> <year> (1993), </year> <title> `Heuristic filtering and reliable calibration methods for video-based pupil-tracking systems', Behavioral Research Methods, Instruments, </title> <booktitle> and Computers 25, </booktitle> <pages> 137-142. </pages>
Reference-contexts: The "Omnitrack1" eye-tracker <ref> (Stampe 1993) </ref> was used, consisting of a light metal head-mounted frame that points an infra-red camera at the subject's right pupil and another camera mounted on the front of the frame and directed at the stimulus screen.
Reference: <author> Teichner, W. H., LeMaster, D. & Kinney, P. A. </author> <year> (1978), </year> <title> Eye Movements During Inspection and Recall, </title> <editor> in J. W. Senders, D. F. Fisher & R. A. Monty, eds, </editor> <booktitle> `Eye Movements and the Higher Psychological Functions', </booktitle> <pages> pp. 259-277. </pages>
Reference-contexts: Eye-tracking experiments have been used on static images; for example in object boundary tracking (Kudo, Uo-mori, Yamada, Oinishi & Sugie 1992), and skill learning from rows of picture-text combinations (Daugs, Bliscke & Olivier 1978). Early work with video has been applied to the study of memory representations <ref> (Teichner, LeMaster & Kinney 1978) </ref>.
Reference: <author> Tomasello, M., Kruger, A. C. & Rather, H. H. </author> <year> (1993), </year> <title> `Cultural Learning', </title> <journal> The Journal of Behavioral and Brain Sciences 16(3), </journal> <pages> 495-552. </pages>
Reference-contexts: This result would add overt fixation behavior to other data supporting the connection. The second question addresses issues of underlying mechanisms for motor control. Since fixations alone do not provide complete information for translating the observed stimulus movement into arm coordinates, yet people are capable of great imitative proficiency <ref> (Tomasello, Kruger & Rather 1993, Kolb & Milner 1981, Davis 1973) </ref>, what motor representations might be used to fill in the details about posture and movement? Using eye-tracking of video stimuli of human movement allowed us to study these questions from a unique perspective. 2 Materials and Methods 2.1 Subjects The
Reference: <author> Veen, H. A. H. C. V. </author> <year> (1996), </year> <title> Visually Acquired Information about Rotating Objects, </title> <type> PhD thesis, </type> <institution> Universiteit Utrech. </institution>
Reference-contexts: We expect to find results showing consistent errors, complementary for example to those shown in experiments studying the subjects' ability to mimic the rotary movement of hand-held three-dimensional objects by changing their orientation <ref> (Veen 1996) </ref>. We are currently analyzing subjects' motor data in order to further address the connection between perception and motor control. 23 Acknowledgements The research reported here was supported in part by the National Science Foundation CAREER Grant IRI-9624237. The experiments were made possible by Prof.
Reference: <author> Velichkovsky, B., Pomplun, M. & Rieser, J. </author> <year> (1996), </year> <title> Attention and communication: eye-movement-based research paradigms, in `Visual Attention and Cognition', </title> <publisher> Elsevier Science Publishers, Amsterdam, </publisher> <pages> pp. 125-154. </pages>
Reference-contexts: Early work with video has been applied to the study of memory representations (Teichner, LeMaster & Kinney 1978). More recently, eye-tracking of video stimuli has been applied to cooperative problem solving <ref> (Velichkovsky, Pomplun & Rieser 1996) </ref> and toward exploring the role of eye movements in working memory tested on tasis involving construction from a model (Ballard, Hayhoe, Li & Whitehead 1992, Hayhoe, Ballard & Whitehead 1993). All eye-tracking experiments so far were aimed at addressing perceptual behavior.
Reference: <author> Vogt, S. </author> <year> (1995), </year> <title> `Imagery and perception-action mediation in imitative actions', </title> <journal> Cognitive Brain Research 3, </journal> <pages> 79-86. </pages>
Reference: <author> Weir, J. D., Stein, J. F. & Miall, R. C. </author> <year> (1989), </year> <title> `Cues and control strategies in visually guided tracking', </title> <journal> Journal of Motor Behavior 21(3), </journal> <pages> 185-204. 28 </pages>
Reference-contexts: Finally, no delay was found between the hand position in the arm movement films and the subjects' corresponding gaze position. This is not surprising, since the movement speed in the stimuli was slow enough to allow for smooth pursuit <ref> (Weir, Stein & Miall 1989) </ref>. 3.3 Fixation Transitions Between Features To verify stimuli consistency, we measured the "probabilities of transition" between all pairs of features for the three different types of stimulus films in order to assess whether some transitions are more likely than others.
References-found: 25

