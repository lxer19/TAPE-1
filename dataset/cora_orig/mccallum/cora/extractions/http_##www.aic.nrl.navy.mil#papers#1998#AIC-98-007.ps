URL: http://www.aic.nrl.navy.mil/papers/1998/AIC-98-007.ps
Refering-URL: http://www.aic.nrl.navy.mil/~aha/pub-details.html
Root-URL: 
Email: faha,breslowg@aic.nrl.navy.mil  
Title: Correcting for Length Biasing in Conversational Case Scoring  
Author: David W. Aha and Leonard A. Breslow 
Note: Citation: NCARAI TR AIC-98-007  
Address: DC USA  
Affiliation: Navy Center for Applied Research in Artificial Intelligence Naval Research Laboratory Washington,  
Abstract: Inference's conversational case-based reasoning (CCBR) approach, embedded in the CBR Content Navigator line of products, is susceptible to a bias in its case scoring algorithm. In particular, shorter cases tend to be given higher scores, assuming all other factors are held constant. This report summarizes our investigation for mediating this bias. We introduce an approach for eliminating this bias and evaluate how it affects retrieval performance for six case libraries. We also suggest explanations for these results, and note the limitations of our study. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D. W., & Breslow, L. A. </author> <year> (1997). </year> <title> Refining conversational case libraries. </title> <booktitle> Proceedings of the Second International Conference on Case-Based Reasoning (pp. </booktitle> <pages> 267-278). </pages> <address> Providence, RI: </address> <publisher> Springer. </publisher>
Reference-contexts: as the relative frequency with which a selected solution solves a given problem, and retrieval efficiency, defined as an inverse function of the number of questions answered before a solution is retrieved. 2 Biasing in Case Scoring We have developed a CCBR tool named NaCoDAE (Navy Conversational Decision Aids Environment) <ref> (Breslow & Aha, 1997) </ref>. <p> That is, combining the biases for shorter and longer cases can sometimes be more effective than using only one in isolation. We used a leave-one-in <ref> (Aha & Breslow, 1997) </ref> strategy to evaluate case retrieval performance. This strategy is similar to well-known leave-one-out cross validation, except that no case is ever removed from the case library, because it might be unique with respect to its solution. <p> To date, the only approach we have tested that has simultaneously increased retrieval precision and retrieval efficiency is case library revision, as described in <ref> (Aha & Breslow, 1997) </ref>. An initial analysis of these results does not show a clear statistical trend for explaining when we can expect the new case scoring algorithm to deliver higher precision.
Reference: <author> Breslow, L., & Aha, D. W. </author> <year> (1997). </year> <title> NaCoDAE: Navy Conversational Decision Aids Environment (Technical Report AIC-97-018). </title> <address> Washington, DC: </address> <institution> Naval Research Laboratory, Navy Center for Applied Research in Artificial Intelligence. Inference Corporation (1995). </institution> <month> CBR2: </month> <title> Designing CBR Express Case Bases. </title> <note> Unpublished. </note>
Reference-contexts: as the relative frequency with which a selected solution solves a given problem, and retrieval efficiency, defined as an inverse function of the number of questions answered before a solution is retrieved. 2 Biasing in Case Scoring We have developed a CCBR tool named NaCoDAE (Navy Conversational Decision Aids Environment) <ref> (Breslow & Aha, 1997) </ref>. <p> That is, combining the biases for shorter and longer cases can sometimes be more effective than using only one in isolation. We used a leave-one-in <ref> (Aha & Breslow, 1997) </ref> strategy to evaluate case retrieval performance. This strategy is similar to well-known leave-one-out cross validation, except that no case is ever removed from the case library, because it might be unique with respect to its solution. <p> To date, the only approach we have tested that has simultaneously increased retrieval precision and retrieval efficiency is case library revision, as described in <ref> (Aha & Breslow, 1997) </ref>. An initial analysis of these results does not show a clear statistical trend for explaining when we can expect the new case scoring algorithm to deliver higher precision.
References-found: 2

