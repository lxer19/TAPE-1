URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-386.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: (bobick jdavis@media.mit.edu)  
Title: Real-time Recognition of Activity Using Temporal Templates  
Author: Aaron F. Bobick and James W. Davis 
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 386 Appears in: The Workshop on Applications of Computer Vision, December 1996 (WACV'96) Abstract A new view-based approach to the representation and recognition of action is presented. The basis of the representation is a motion-history image (MHI) | a static image where intensity is a function of the recency of motion in a sequence. We develop a recognition method which uses both binary and scalar-valued versions of the MHI as temporal templates to match against stored instances of actions. The method automatically performs temporal segmentation, is invariant to linear changes in speed, and runs in real-time on a standard platform. The applications we have begin to develop include simple room moni toring and an interactive game.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Akita, K. </author> <title> Image sequence analysis of real world human motion. </title> <journal> Pattern Recognition, </journal> <volume> 17, </volume> <year> 1984. </year>
Reference-contexts: Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in <ref> [1, 4, 10, 13, 14, 6, 17] </ref>. In [3] we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. <p> We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 10, 13, 14, 6, 17] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action, while others use only the two-dimensional appearance.
Reference: [2] <author> Black, M. and Y. Yacoob. </author> <title> Tracking and recognizing rigid and non-rigid facial motion using local parametric models of image motion. </title> <booktitle> In ICCV, </booktitle> <year> 1995. </year>
Reference-contexts: In [3] we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. The approach is a natural extension of Black and Yacoob's work on facial expression recognition <ref> [2] </ref>. In this work we continue to develop this approach. We review the construction of a motion-energy image (MEI) which is a binary representation of where motion Frame 5 25 40 present in each frame people can trivially recognize the action as someone sitting. has occurred in an image sequence. <p> However, underlying all of these techniques is the requirement that there be individual features or properties that can be extracted from each frame of the image sequence. These approaches accomplish motion understanding by recognizing a sequence of static configurations. Alternatively, there is the work on direct motion recognition <ref> [12, 15, 16, 2, 8] </ref>. These approaches attempt Frame 0 20 40 to characterize the motion itself without any reference to the underlying static images. Of these techniques, the work of Black and Yacoob [2] is the most relevant to the results presented here. <p> Alternatively, there is the work on direct motion recognition [12, 15, 16, 2, 8]. These approaches attempt Frame 0 20 40 to characterize the motion itself without any reference to the underlying static images. Of these techniques, the work of Black and Yacoob <ref> [2] </ref> is the most relevant to the results presented here.
Reference: [3] <author> Bobick, A. and J. Davis. </author> <title> An appearance-based representation of action. </title> <booktitle> In ICPR, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: This paper presents an alternative to the three-dimensional reconstruction proposal. We develop a view-based approach to the representation and recognition of action that is designed to support the direct recognition of the motion itself. In previous work <ref> [3] </ref> we described how people can easily recognize action in even extremely blurred image sequences such as shown in Figure 1. <p> Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in [1, 4, 10, 13, 14, 6, 17]. In <ref> [3] </ref> we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. The approach is a natural extension of Black and Yacoob's work on facial expression recognition [2]. <p> In <ref> [3] </ref> we performed this division by using a binary image to represent where motion occurred and a patch model of how the motion moves. Here, we replace the dynamic patch tracking with a static representation of the motion. <p> Fortunately, in the recognition section we derive a backward-looking (in time) algorithm which can dynamically search over a range of t . In Figure 3 we display the MEIs of viewing a sitting action across 90 ffi . In <ref> [3] </ref> we exploited the smooth variation of motion over angle to compress the entire view circle into a low order representation.
Reference: [4] <author> Campbell, L. and A. Bobick. </author> <title> Recognition of human body motion using phase space constraints. </title> <booktitle> In ICCV, </booktitle> <year> 1995. </year>
Reference-contexts: Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in <ref> [1, 4, 10, 13, 14, 6, 17] </ref>. In [3] we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. <p> We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 10, 13, 14, 6, 17] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action, while others use only the two-dimensional appearance.
Reference: [5] <author> Cedras, C. and M. Shah. </author> <title> Motion-based recognition: A survey. </title> <booktitle> Image and Vision Computing, </booktitle> <year> 1995. </year>
Reference-contexts: For an excellent review on the machine understanding of motion see <ref> [5] </ref>. We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include [1, 4, 10, 13, 14, 6, 17].
Reference: [6] <author> Cui, Y., D. Swets, and J. Weng. </author> <title> Learning-based hand sign recognition using shoslif-m. </title> <booktitle> In ICCV, </booktitle> <year> 1995. </year>
Reference-contexts: Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in <ref> [1, 4, 10, 13, 14, 6, 17] </ref>. In [3] we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. <p> We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 10, 13, 14, 6, 17] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action, while others use only the two-dimensional appearance.
Reference: [7] <author> Darrell, T., P. Maes, B. Blumberg, and A. Pent-land. </author> <title> A novel environment for situated vision and behavior. In IEEE Wkshp. for Visual Behaviors (CVPR-94), </title> <year> 1994. </year>
Reference-contexts: 1 Introduction The recent shift in computer vision from static images to video sequences has focused research on the understanding of action or behavior. In particular, the lure of wireless interfaces (e.g. [9]) and interactive environments <ref> [7] </ref> has heightened interest in understanding human actions. Recently a number of approaches have appeared attempting the full three-dimensional reconstruction of the human form from image sequences, with the presumption that such information would be useful and perhaps even necessary to understand the action taking place (e.g. [13]). <p> To extend this paradigm to such actions requires some mechanism to automatically mask away regions of motion. We have not yet addressed this problem. In this paper we have introduced a new core technology with many potential applications to monitoring, surveillance, and human-computer interaction. Systems such as Alive <ref> [7] </ref> require good understanding of action. Currently most such systems use sequences of static configurations to identify action and are therefore subject to the same brittleness that static modeling approaches suffer. By using the motion itself we hope to improve the robustness of such interaction.
Reference: [8] <author> Essa, I. and S. Pentland. </author> <title> Facial expression recognition using a dynamic model and motion energy. </title> <booktitle> In ICCV, </booktitle> <year> 1995. </year>
Reference-contexts: However, underlying all of these techniques is the requirement that there be individual features or properties that can be extracted from each frame of the image sequence. These approaches accomplish motion understanding by recognizing a sequence of static configurations. Alternatively, there is the work on direct motion recognition <ref> [12, 15, 16, 2, 8] </ref>. These approaches attempt Frame 0 20 40 to characterize the motion itself without any reference to the underlying static images. Of these techniques, the work of Black and Yacoob [2] is the most relevant to the results presented here.
Reference: [9] <author> Freeman, W. </author> <title> Orientation histogram for hand gesture recognition. </title> <booktitle> In Int'l Workshop on Automatic Face- and Gesture-Recognition, </booktitle> <year> 1995. </year>
Reference-contexts: 1 Introduction The recent shift in computer vision from static images to video sequences has focused research on the understanding of action or behavior. In particular, the lure of wireless interfaces (e.g. <ref> [9] </ref>) and interactive environments [7] has heightened interest in understanding human actions.
Reference: [10] <author> Hogg, D. </author> <title> Model-based vision: a paradigm to see a walking person. </title> <journal> Image and Vision Computing, </journal> <volume> 1(1), </volume> <year> 1983. </year>
Reference-contexts: Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in <ref> [1, 4, 10, 13, 14, 6, 17] </ref>. In [3] we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. <p> We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 10, 13, 14, 6, 17] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action, while others use only the two-dimensional appearance.
Reference: [11] <author> Hu, M. </author> <title> Visual pattern recognition by moment invariants. </title> <journal> IRE Trans. Information Theory, </journal> <volume> IT-8(2), </volume> <year> 1962. </year>
Reference-contexts: We first collect training examples of each action from a variety of viewing angles. Given a set of MEIs and MHIs for each view/action combination, we compute statistical descriptions of the these images using moment-based features. Our current choice are 7 Hu moments <ref> [11] </ref> which are known to yield reasonable shape discrimination in a translation- and scale-invariant manner. For each view of each action a statistical model (mean and covariance matrix) is generated for both the MEI and MHI.
Reference: [12] <author> Polana, R. and R. Nelson. </author> <title> Low level recognition of human motion. </title> <booktitle> In IEEE Workshop on Non-rigid and Articulated Motion, </booktitle> <year> 1994. </year>
Reference-contexts: However, underlying all of these techniques is the requirement that there be individual features or properties that can be extracted from each frame of the image sequence. These approaches accomplish motion understanding by recognizing a sequence of static configurations. Alternatively, there is the work on direct motion recognition <ref> [12, 15, 16, 2, 8] </ref>. These approaches attempt Frame 0 20 40 to characterize the motion itself without any reference to the underlying static images. Of these techniques, the work of Black and Yacoob [2] is the most relevant to the results presented here.
Reference: [13] <author> Rehg, J. and T. Kanade. </author> <title> Model-based tracking of self-occluding articulated objects. </title> <booktitle> In ICCV, </booktitle> <year> 1995. </year>
Reference-contexts: Recently a number of approaches have appeared attempting the full three-dimensional reconstruction of the human form from image sequences, with the presumption that such information would be useful and perhaps even necessary to understand the action taking place (e.g. <ref> [13] </ref>). This paper presents an alternative to the three-dimensional reconstruction proposal. We develop a view-based approach to the representation and recognition of action that is designed to support the direct recognition of the motion itself. <p> Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in <ref> [1, 4, 10, 13, 14, 6, 17] </ref>. In [3] we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. <p> We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 10, 13, 14, 6, 17] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action, while others use only the two-dimensional appearance.
Reference: [14] <author> Rohr, K. </author> <title> Towards model-based recognition of human movements in image sequences. CVGIP, Image Understanding, </title> <type> 59(1), </type> <year> 1994. </year>
Reference-contexts: Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in <ref> [1, 4, 10, 13, 14, 6, 17] </ref>. In [3] we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. <p> We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 10, 13, 14, 6, 17] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action, while others use only the two-dimensional appearance.
Reference: [15] <author> Shavit, E. and A. Jepson. </author> <title> Motion understanding using phase portraits. </title> <booktitle> In IJCAI Workshop: Looking at People, </booktitle> <year> 1995. </year>
Reference-contexts: However, underlying all of these techniques is the requirement that there be individual features or properties that can be extracted from each frame of the image sequence. These approaches accomplish motion understanding by recognizing a sequence of static configurations. Alternatively, there is the work on direct motion recognition <ref> [12, 15, 16, 2, 8] </ref>. These approaches attempt Frame 0 20 40 to characterize the motion itself without any reference to the underlying static images. Of these techniques, the work of Black and Yacoob [2] is the most relevant to the results presented here.
Reference: [16] <author> Yacoob, Y. and L. Davis. </author> <title> Computing spatio-temporal representations of human faces. </title> <booktitle> In CVPR, </booktitle> <year> 1994. </year>
Reference-contexts: However, underlying all of these techniques is the requirement that there be individual features or properties that can be extracted from each frame of the image sequence. These approaches accomplish motion understanding by recognizing a sequence of static configurations. Alternatively, there is the work on direct motion recognition <ref> [12, 15, 16, 2, 8] </ref>. These approaches attempt Frame 0 20 40 to characterize the motion itself without any reference to the underlying static images. Of these techniques, the work of Black and Yacoob [2] is the most relevant to the results presented here.
Reference: [17] <author> Yamato, J., J. Ohya, and K. Ishii. </author> <title> Recognizing human action in time sequential images using hidden markov models. </title> <booktitle> In CVPR, </booktitle> <year> 1992. </year> <month> 4 </month>
Reference-contexts: Such capabilities argue for recognizing action from the motion itself, as opposed to first reconstructing a 3-dimensional model of a person, and then recognizing the action of the model as advocated in <ref> [1, 4, 10, 13, 14, 6, 17] </ref>. In [3] we proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the motion is moving. <p> We divide the relevant prior work into two areas: human action recognition and motion-based recognition. The first and most obvious body of relevant work includes all the approaches to understanding action, and in particular human action. Some recent examples include <ref> [1, 4, 10, 13, 14, 6, 17] </ref>. Some of these techniques assume that a three-dimensional reconstruction precedes the recognition of action, while others use only the two-dimensional appearance.
References-found: 17

