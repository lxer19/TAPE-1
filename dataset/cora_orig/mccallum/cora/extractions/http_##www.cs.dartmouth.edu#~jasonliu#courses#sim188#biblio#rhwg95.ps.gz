URL: http://www.cs.dartmouth.edu/~jasonliu/courses/sim188/biblio/rhwg95.ps.gz
Refering-URL: http://www.cs.dartmouth.edu/~jasonliu/courses/sim188/notes-13.html
Root-URL: http://www.cs.dartmouth.edu
Email: gupta-@cs.stanford.edu  
Title: Complete Computer System Simulation: The SimOS Approach  Complete Computer System Simulation: The SimOS Approach  
Author: Mendel Rosenblum, Stephen A. Herrod, Emmett Witchel, and Anoop Gupta 
Keyword: Machine Simulation, Performance Evaluation, Multiprocessing Systems, Virtual Machines  
Address: -mendel, herrod, witchel,  
Affiliation: Computer Systems Laboratory Stanford University  
Note: Page 1 ACCEPTED FOR PUBLICATION IN IEEE Parallel and Distributed Technology This is not the final version.  
Abstract: The complexity of modern computer systems, coupled with the diverse workloads that they must support, presents a challenge to researchers and designers who need to understand a systems behavior. We describe SimOS, a machine simulation environment designed for the efficient and accurate study of both uniprocessor and multiprocessor computer systems. SimOS simulates computer hardware in enough detail to run an entire operating system. By running a commercial operating system, SimOS provides the ability to investigate realistic workloads, which was not possible with previous simulation tools. SimOS also provides substantial exibility in the trade-off between the speed and detail of a simulation. We employ fast simulation techniques to scan over the less interesting, time-consuming parts of a workload. To focus in on interesting sections of a workloads execution, we employ slower, more detailed levels of simulation. SimOS ability to change levels of detail on-the-y enhances its ability to study complex work-loads, allowing the investigator to pay the cost of detailed simulation only when the resulting data is desired. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> John Chapin, Stephen A. Herrod, Mendel Rosenblum, and Anoop Gupta, </author> <title> UNIX Performance on CC-NUMA Multiprocessors, </title> <booktitle> In 1995 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> May </month> <year> 1995, </year> <pages> pp. 1-13. </pages>
Reference-contexts: Because each simulated CPU executes as a sepa lw r3,10 (r1) Workload Code Block load tmp1,simRegs <ref> [1] </ref> Minimal Binary Translation Code Annotations load tmp1,simRegs [2] load tmp2,simRegs [3] add tmp3,tmp1,tmp2 store tmp3,simRegs [4] load tmp2,(tmp1+10) store tmp2,simRegs [3] MMU Data Address Translation (8 instr on hit) Cycle Counting (2 instructions) MMU Instr Address Translation (4 instr on hit) Cache Simulation (2 instr on hit) FIGURE 4.1.
Reference: [2] <author> J. Bradley Chen and Brian Bershad, </author> <title> The Impact of Operating System Structure on Memory System Performance, </title> <journal> Operating Systems Review, </journal> <volume> vol. 27, no. 5, </volume> <month> Dec. </month> <year> 1993, </year> <pages> pp 120-133. </pages>
Reference-contexts: Because each simulated CPU executes as a sepa lw r3,10 (r1) Workload Code Block load tmp1,simRegs [1] Minimal Binary Translation Code Annotations load tmp1,simRegs <ref> [2] </ref> load tmp2,simRegs [3] add tmp3,tmp1,tmp2 store tmp3,simRegs [4] load tmp2,(tmp1+10) store tmp2,simRegs [3] MMU Data Address Translation (8 instr on hit) Cycle Counting (2 instructions) MMU Instr Address Translation (4 instr on hit) Cache Simulation (2 instr on hit) FIGURE 4.1. The mechanics of binary translation.
Reference: [3] <author> Robert Cmelik and David Keppel, Shade: </author> <title> A Fast Instruction Set Simulator for Execution Profiling, Performance Evaluation Review, </title> <journal> May 1994, </journal> <volume> vol. 22, no. 1, </volume> <pages> pp. 128-137. </pages>
Reference-contexts: Because each simulated CPU executes as a sepa lw r3,10 (r1) Workload Code Block load tmp1,simRegs [1] Minimal Binary Translation Code Annotations load tmp1,simRegs [2] load tmp2,simRegs <ref> [3] </ref> add tmp3,tmp1,tmp2 store tmp3,simRegs [4] load tmp2,(tmp1+10) store tmp2,simRegs [3] MMU Data Address Translation (8 instr on hit) Cycle Counting (2 instructions) MMU Instr Address Translation (4 instr on hit) Cache Simulation (2 instr on hit) FIGURE 4.1. The mechanics of binary translation. <p> Because each simulated CPU executes as a sepa lw r3,10 (r1) Workload Code Block load tmp1,simRegs [1] Minimal Binary Translation Code Annotations load tmp1,simRegs [2] load tmp2,simRegs <ref> [3] </ref> add tmp3,tmp1,tmp2 store tmp3,simRegs [4] load tmp2,(tmp1+10) store tmp2,simRegs [3] MMU Data Address Translation (8 instr on hit) Cycle Counting (2 instructions) MMU Instr Address Translation (4 instr on hit) Cache Simulation (2 instr on hit) FIGURE 4.1. The mechanics of binary translation.
Reference: [4] <author> Jim Gray, Ed. </author> <title> The Benchmark Handbook for Database and Transaction Processing Systems, </title> <publisher> Morgan Kauf-mann Publishers, </publisher> <year> 1991. </year>
Reference-contexts: Because each simulated CPU executes as a sepa lw r3,10 (r1) Workload Code Block load tmp1,simRegs [1] Minimal Binary Translation Code Annotations load tmp1,simRegs [2] load tmp2,simRegs [3] add tmp3,tmp1,tmp2 store tmp3,simRegs <ref> [4] </ref> load tmp2,(tmp1+10) store tmp2,simRegs [3] MMU Data Address Translation (8 instr on hit) Cycle Counting (2 instructions) MMU Instr Address Translation (4 instr on hit) Cache Simulation (2 instr on hit) FIGURE 4.1. The mechanics of binary translation.
Reference: [5] <author> Mark Heinrich, Jeff Kuskin, David Ofelt, John Heinlein, Joel Baxter, Jaswinder Pal Singh, Kourosh Gharachor-loo, Dave Nakahira, Mark Horowitz, Anoop Gupta, and Mendel Rosenblum., </author> <title> The Performance Impact of Complete Computer System Simulation: The SimOS Approach Page 15 ACCEPTED FOR PUBLICATION IN IEEE Parallel and Distributed Technology - This is not the final version. Flexibility in the Stanford FLASH Multiprocessor, </title> <booktitle> In Proceedings of the 6th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1994, </year> <pages> pp. 274-284. </pages>
Reference: [6] <author> John Ousterhout. </author> <title> Why Arent Operating Systems Getting Faster as Fast as Hardware? In Proceedings of the Summer 1990 USENIX Conference, </title> <month> June </month> <year> 1990, </year> <pages> pp. 247-256. </pages>
Reference: [7] <editor> SPEC Newsletter, </editor> <volume> vol. 3, No 4, </volume> <month> Dec </month> <year> 1991, </year> <pages> pp. 18-21. </pages>
Reference: [8] <author> Jaswinder Pal Singh, Wolf-Dietrich Weber, and Anoop Gupta, </author> <title> SPLASH: Stanford Parallel Applications for Shared Memory, </title> <journal> Computer Architecture News, </journal> <volume> vol. 20, num 1, </volume> <month> March </month> <year> 1992, </year> <pages> pp. 5-44. </pages>
References-found: 8

