URL: file://ftp.cis.ohio-state.edu/pub/hpce/tensor/Papers/JISE95-direct.ps.gz
Refering-URL: http://www.cis.ohio-state.edu/~chh/Publication/tensor-papers.html
Root-URL: 
Phone: 2  3  
Title: An Algebraic Theory for Modeling Direct Interconnection Networks 1  
Author: S. D. Kaushik S. Sharma C.-H. Huang J. R. Johnson R. W. Johnson and P. Sadayappan 
Keyword: Tensor product, Block recursive algorithm, Direct interconnection network, Al gorithm mapping, Network embedding.  
Address: Columbus, OH 43210.  Philadelphia, PA 19104.  St. Cloud, MN 56301.  
Affiliation: 1 Department of Computer and Information Science, The Ohio State University,  Department of Mathematics and Computer Science, Drexel University,  Department of Computer Science, St. Cloud State University,  
Abstract: The theory of tensor products has been used for designing and implementing block recursive numerical algorithms on shared-memory vector multiprocessors such as the Cray-YMP. In this paper, we present an algebraic theory based on tensor products for modeling direct interconnection networks. The development of this model is expected to facilitate the development of a methodology for mapping algorithms expressed in tensor product form onto distributed-memory architectures. A network is defined as a tuple that includes a set of processors and a set of permutations expressed in tensor product notation which collectively represent the network topology. The tensor product of networks is defined to facilitate the recursive construction of complex networks from simple networks. Using the tensor product of networks, properties of the simple networks, such as network embedding, can be easily extended to the complex networks. We start with a simple ring network and recursively construct two-dimensional torus and hypercube networks. Network embed-dings for the ring network are extended in a straightforward fashion to those for two-dimensional torus and hypercube networks. A formal model for specifying and verifying network embedding is presented. Using this model and the tensor product representation, the embeddings of the ring and the two-dimensional torus into the hypercube are specified and verified. Algorithm mapping using the tensor product formulation is demonstrated by mapping matrix transposition and matrix multiplication onto different networks. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Y. Chan and F. Y. L. Chin. </author> <title> On embedding rectangular grids in hypercubes. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-37(10):1285-1288, </volume> <month> Oct. </month> <year> 1988. </year> <month> 23 </month>
Reference-contexts: Efficient algorithms for performing various permutations, such as bit reversal, vector reversal, perfect shu*e, and unshu*e, on the mesh and hypercube architectures have been presented in [5, 9, 17, 18, 19, 23, 25]. Several strategies for embedding direct networks onto other direct networks have been described in <ref> [1, 3, 10, 22, 24] </ref>. Most previous approaches are based on the graph and binary representations of these networks. It has been proved that the graph and binary representations for a given class of interconnection networks are equivalent to tensor product representations [2]. <p> Several strategies for embedding direct networks in other direct networks have been described in <ref> [1, 3, 10, 22, 24] </ref>. In this section, we demonstrate the use of the tensor product notation to specify and verify several network embeddings. <p> ) B (I 16 I 2 n4 ) do i = 0,3 /* computation for I 8 L 32 2 */ 2 A loc [0 : 1; 0 : 15] /* computation for I 8 (S 2 I 16 )*/ Exchange A loc [0; 0 : 15] and A loc <ref> [1; 0 : 15] </ref> /* communication for C 8 0 I 32 */ if (proc id = 2 fl j)then send A loc [1; 0 : 15]+ to proc (2 fl j + 1); recv A loc [1; 0 : 15] from proc (2 fl j + 1); elseif (proc id <p> loc [0 : 1; 0 : 15] /* computation for I 8 (S 2 I 16 )*/ Exchange A loc [0; 0 : 15] and A loc <ref> [1; 0 : 15] </ref> /* communication for C 8 0 I 32 */ if (proc id = 2 fl j)then send A loc [1; 0 : 15]+ to proc (2 fl j + 1); recv A loc [1; 0 : 15] from proc (2 fl j + 1); elseif (proc id = 2 fl j + 1) then send A loc [0; 0 : 15] to proc (2 fl j); recv A loc [0; <p> I 16 )*/ Exchange A loc [0; 0 : 15] and A loc <ref> [1; 0 : 15] </ref> /* communication for C 8 0 I 32 */ if (proc id = 2 fl j)then send A loc [1; 0 : 15]+ to proc (2 fl j + 1); recv A loc [1; 0 : 15] from proc (2 fl j + 1); elseif (proc id = 2 fl j + 1) then send A loc [0; 0 : 15] to proc (2 fl j); recv A loc [0; 0 : 15] from proc (2 fl j); endif /* communication for L 8
Reference: [2] <author> Marc Davio. </author> <title> Kronecker Products and Shu*e Algebra. </title> <journal> IEEE Transaction on Computers, </journal> <volume> C-30(2):116-125, </volume> <month> Feb. </month> <year> 1981. </year>
Reference-contexts: Most previous approaches are based on the graph and binary representations of these networks. It has been proved that the graph and binary representations for a given class of interconnection networks are equivalent to tensor product representations <ref> [2] </ref>. However, the tensor product notation is more versatile in the ability to represent both algorithms and architectures and hence is expected to serve as a better representation for algorithm mapping. In this paper, we focus on modeling direct interconnection networks.
Reference: [3] <author> J. A. Ellis. </author> <title> Embedding rectangular grids into square grids. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-40(1):46-52, </volume> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: Efficient algorithms for performing various permutations, such as bit reversal, vector reversal, perfect shu*e, and unshu*e, on the mesh and hypercube architectures have been presented in [5, 9, 17, 18, 19, 23, 25]. Several strategies for embedding direct networks onto other direct networks have been described in <ref> [1, 3, 10, 22, 24] </ref>. Most previous approaches are based on the graph and binary representations of these networks. It has been proved that the graph and binary representations for a given class of interconnection networks are equivalent to tensor product representations [2]. <p> Several strategies for embedding direct networks in other direct networks have been described in <ref> [1, 3, 10, 22, 24] </ref>. In this section, we demonstrate the use of the tensor product notation to specify and verify several network embeddings.
Reference: [4] <author> T. Feng. </author> <title> A survey of interconnection networks. </title> <journal> IEEE Transactions on Computer Systems, </journal> <volume> C-30(12):12-27, </volume> <month> Dec. </month> <year> 1981. </year>
Reference-contexts: We will model direct interconnection networks including rings, two-dimensional tori and hypercubes using the tensor product notation. A number of direct interconnection networks have been proposed for implementing multiprocessor systems <ref> [4] </ref>. Among these are rings, n-dimensional tori, hypercubes, and cube-connected cycles. Topological properties of direct interconnection networks have been studied in the literature [8, 24].
Reference: [5] <author> P. M. Flanders. </author> <title> A unified approach to a class of data movements on an array processor. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-31(9):809-819, </volume> <month> Sept. </month> <year> 1982. </year>
Reference-contexts: Topological properties of direct interconnection networks have been studied in the literature [8, 24]. Efficient algorithms for performing various permutations, such as bit reversal, vector reversal, perfect shu*e, and unshu*e, on the mesh and hypercube architectures have been presented in <ref> [5, 9, 17, 18, 19, 23, 25] </ref>. Several strategies for embedding direct networks onto other direct networks have been described in [1, 3, 10, 22, 24]. Most previous approaches are based on the graph and binary representations of these networks.
Reference: [6] <author> A. Graham. </author> <title> Kronecker Products and Matrix Calculus: With Applications. </title> <publisher> Ellis Horwood Limited, </publisher> <year> 1981. </year>
Reference-contexts: 1 Introduction Tensor products, also known as Kronecker products, have been previously used for matrix calculus <ref> [6, 11] </ref>. This notation has also been used for the design and implementation of block recursive numerical algorithms such as fast Fourier transforms [13, 15, 16, 26] and Strassen's matrix multiplication [12, 16]. <p> Conclusions and future directions are given in Section 6. 2 The Tensor Product Notation In this section, we give an overview of the tensor product notation and the properties which are used in the representation of direct interconnection networks. For details of this theory, the reader is referred to <ref> [6, 11] </ref>. Definition 2.1 (Tensor Product) Let A and B be two matrices of size mfin and pfiq, respectively. The tensor product of A and B is the block matrix obtained by replacing each element a i;j by a i;j B.
Reference: [7] <author> S. K. S. Gupta, S. D. Kaushik, C.-H. Huang, J. R. Johnson, R. W. Johnson, and P. Sadayappan. </author> <title> A methodology for the generation of data distributions to optimize communication. </title> <booktitle> In Proc. of IEEE Symposium on Parallel and Distributed Processing, </booktitle> <pages> pages 436-441, </pages> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: We extend this work to use the tensor product notation for designing and implementing efficient algorithms for distributed-memory multiprocessors. Tensor products have been used for the generation of data distributions for distributed memory machines <ref> [7] </ref>. A major step in mapping algorithms to distributed-memory multiprocessors is to model algorithms and interconnection networks in a compatible form. We will model direct interconnection networks including rings, two-dimensional tori and hypercubes using the tensor product notation.
Reference: [8] <author> J. P. Hayes. </author> <title> Computer Architecture and Organization. </title> <publisher> McGraw Hill, </publisher> <year> 1988. </year>
Reference-contexts: A number of direct interconnection networks have been proposed for implementing multiprocessor systems [4]. Among these are rings, n-dimensional tori, hypercubes, and cube-connected cycles. Topological properties of direct interconnection networks have been studied in the literature <ref> [8, 24] </ref>. Efficient algorithms for performing various permutations, such as bit reversal, vector reversal, perfect shu*e, and unshu*e, on the mesh and hypercube architectures have been presented in [5, 9, 17, 18, 19, 23, 25].
Reference: [9] <author> C. T. Ho and S. L. Johnsson. </author> <title> Distributed routing algorithms for broadcasting and personalized communication in hypercubes. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages 640-648, </pages> <year> 1986. </year>
Reference-contexts: Topological properties of direct interconnection networks have been studied in the literature [8, 24]. Efficient algorithms for performing various permutations, such as bit reversal, vector reversal, perfect shu*e, and unshu*e, on the mesh and hypercube architectures have been presented in <ref> [5, 9, 17, 18, 19, 23, 25] </ref>. Several strategies for embedding direct networks onto other direct networks have been described in [1, 3, 10, 22, 24]. Most previous approaches are based on the graph and binary representations of these networks.
Reference: [10] <author> C. T. Ho and S. L. Johnsson. </author> <title> Embedding meshes in boolean cubes by graph decomposition. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 8 </volume> <pages> 325-339, </pages> <year> 1990. </year>
Reference-contexts: Efficient algorithms for performing various permutations, such as bit reversal, vector reversal, perfect shu*e, and unshu*e, on the mesh and hypercube architectures have been presented in [5, 9, 17, 18, 19, 23, 25]. Several strategies for embedding direct networks onto other direct networks have been described in <ref> [1, 3, 10, 22, 24] </ref>. Most previous approaches are based on the graph and binary representations of these networks. It has been proved that the graph and binary representations for a given class of interconnection networks are equivalent to tensor product representations [2]. <p> Several strategies for embedding direct networks in other direct networks have been described in <ref> [1, 3, 10, 22, 24] </ref>. In this section, we demonstrate the use of the tensor product notation to specify and verify several network embeddings. <p> Network embedding of a source network G S (V S ; E S ) in a target network G T (V T ; E T ) has been defined as a mapping : V S ! V T <ref> [10] </ref>. The embedding function maps each node in G S to a node in G T . The dilation of the embedding , is the maximum distance between (i) and (j) for all (i; j) 2 E S .
Reference: [11] <author> R.A. Horn and C.R. Johnson. </author> <title> Topics in Matrix Analysis. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction Tensor products, also known as Kronecker products, have been previously used for matrix calculus <ref> [6, 11] </ref>. This notation has also been used for the design and implementation of block recursive numerical algorithms such as fast Fourier transforms [13, 15, 16, 26] and Strassen's matrix multiplication [12, 16]. <p> Conclusions and future directions are given in Section 6. 2 The Tensor Product Notation In this section, we give an overview of the tensor product notation and the properties which are used in the representation of direct interconnection networks. For details of this theory, the reader is referred to <ref> [6, 11] </ref>. Definition 2.1 (Tensor Product) Let A and B be two matrices of size mfin and pfiq, respectively. The tensor product of A and B is the block matrix obtained by replacing each element a i;j by a i;j B.
Reference: [12] <author> C.-H. Huang, J. R. Johnson, and R. W. Johnson. </author> <title> A tensor product formulation of Strassen's matrix multiplication algorithm. </title> <journal> Appl. Math Letters, </journal> <volume> 3(3) </volume> <pages> 67-71, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction Tensor products, also known as Kronecker products, have been previously used for matrix calculus [6, 11]. This notation has also been used for the design and implementation of block recursive numerical algorithms such as fast Fourier transforms [13, 15, 16, 26] and Strassen's matrix multiplication <ref> [12, 16] </ref>. The tensor product formulation of these algorithms has been used to generate efficient parallel and vector programs for shared-memory multiprocessors. It has been proved to be useful for extracting parallel and vector operations and for automatically generating code for complex index computations [14].
Reference: [13] <author> C.-H. Huang, J. R. Johnson, and R. W. Johnson. </author> <title> Generating parallel programs from tensor product formulas: A case study of Strassen's matrix multiplication algorithm. </title> <booktitle> In Proc. of Intl. Conf. on Parallel Processing, volume III, </booktitle> <pages> pages 104-108, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction Tensor products, also known as Kronecker products, have been previously used for matrix calculus [6, 11]. This notation has also been used for the design and implementation of block recursive numerical algorithms such as fast Fourier transforms <ref> [13, 15, 16, 26] </ref> and Strassen's matrix multiplication [12, 16]. The tensor product formulation of these algorithms has been used to generate efficient parallel and vector programs for shared-memory multiprocessors.
Reference: [14] <author> J. R. Johnson, C.-H. Huang, and R. W. Johnson. </author> <title> Tensor permutations and block matrix allocation. </title> <booktitle> In Second International Workshop on Array Structures (ATABLE-92), </booktitle> <year> 1992. </year> <note> To appear. </note>
Reference-contexts: The tensor product formulation of these algorithms has been used to generate efficient parallel and vector programs for shared-memory multiprocessors. It has been proved to be useful for extracting parallel and vector operations and for automatically generating code for complex index computations <ref> [14] </ref>. We extend this work to use the tensor product notation for designing and implementing efficient algorithms for distributed-memory multiprocessors. Tensor products have been used for the generation of data distributions for distributed memory machines [7].
Reference: [15] <author> J.R. Johnson, R.W. Johnson, D. Rodriguez, and R. Tolimieri. </author> <title> A methodology for designing, modifying and implementing fourier transform algorithms on various architectures. </title> <journal> Circuits Systems Signal Process, </journal> <volume> 9(4) </volume> <pages> 450-500, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction Tensor products, also known as Kronecker products, have been previously used for matrix calculus [6, 11]. This notation has also been used for the design and implementation of block recursive numerical algorithms such as fast Fourier transforms <ref> [13, 15, 16, 26] </ref> and Strassen's matrix multiplication [12, 16]. The tensor product formulation of these algorithms has been used to generate efficient parallel and vector programs for shared-memory multiprocessors. <p> Using the properties of the the vector reversal permutation we have, J 2 n (e 2 i n1 e 2 e 2 i n1 e 2 i 0 . The following properties of the tensor product permutations are used in this paper. We refer the proofs to <ref> [15, 21] </ref>. 1. If N = rst, then L N st = L N t 2. If N = rst, then L N t = L rt t 3. L 2 n Q n2 2 I 2 i 4.
Reference: [16] <author> R. W. Johnson, C.-H. Huang, and J. R. Johnson. </author> <title> Multilinear algebra and parallel programming. </title> <journal> Journal of Supercomputing, </journal> <volume> 5 </volume> <pages> 189-218, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction Tensor products, also known as Kronecker products, have been previously used for matrix calculus [6, 11]. This notation has also been used for the design and implementation of block recursive numerical algorithms such as fast Fourier transforms <ref> [13, 15, 16, 26] </ref> and Strassen's matrix multiplication [12, 16]. The tensor product formulation of these algorithms has been used to generate efficient parallel and vector programs for shared-memory multiprocessors. <p> 1 Introduction Tensor products, also known as Kronecker products, have been previously used for matrix calculus [6, 11]. This notation has also been used for the design and implementation of block recursive numerical algorithms such as fast Fourier transforms [13, 15, 16, 26] and Strassen's matrix multiplication <ref> [12, 16] </ref>. The tensor product formulation of these algorithms has been used to generate efficient parallel and vector programs for shared-memory multiprocessors. It has been proved to be useful for extracting parallel and vector operations and for automatically generating code for complex index computations [14].
Reference: [17] <author> S. L. Johnsson and C. T. Ho. </author> <title> Communication efficient basic linear computations on hypercube architectures. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 4 </volume> <pages> 133-172, </pages> <year> 1987. </year>
Reference-contexts: Topological properties of direct interconnection networks have been studied in the literature [8, 24]. Efficient algorithms for performing various permutations, such as bit reversal, vector reversal, perfect shu*e, and unshu*e, on the mesh and hypercube architectures have been presented in <ref> [5, 9, 17, 18, 19, 23, 25] </ref>. Several strategies for embedding direct networks onto other direct networks have been described in [1, 3, 10, 22, 24]. Most previous approaches are based on the graph and binary representations of these networks.
Reference: [18] <author> S. L. Johnsson and C. T. Ho. </author> <title> Shu*e permutations on boolean cubes. </title> <type> Technical Report YALEU/DCS/RR-653, </type> <institution> Department of Computer Sciences, Yale University, </institution> <month> Oct. </month> <year> 1988. </year>
Reference-contexts: Topological properties of direct interconnection networks have been studied in the literature [8, 24]. Efficient algorithms for performing various permutations, such as bit reversal, vector reversal, perfect shu*e, and unshu*e, on the mesh and hypercube architectures have been presented in <ref> [5, 9, 17, 18, 19, 23, 25] </ref>. Several strategies for embedding direct networks onto other direct networks have been described in [1, 3, 10, 22, 24]. Most previous approaches are based on the graph and binary representations of these networks.
Reference: [19] <author> S. L. Johnsson and C. T. Ho. </author> <title> On the conversion between binary code and binary-reflected gray code on boolean cubes. </title> <type> Technical Report YALEU/DCS/TR-20-91, </type> <institution> Department of Computer Sciences, Yale University, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: Topological properties of direct interconnection networks have been studied in the literature [8, 24]. Efficient algorithms for performing various permutations, such as bit reversal, vector reversal, perfect shu*e, and unshu*e, on the mesh and hypercube architectures have been presented in <ref> [5, 9, 17, 18, 19, 23, 25] </ref>. Several strategies for embedding direct networks onto other direct networks have been described in [1, 3, 10, 22, 24]. Most previous approaches are based on the graph and binary representations of these networks.
Reference: [20] <author> S. D. Kaushik, S. Sharma, and C.-H. Huang. </author> <title> An algebraic theory for modeling multistage interconnection networks. </title> <journal> Journal of Information Science and Engineering, </journal> <volume> 9(1) </volume> <pages> 1-26, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: Representations for the hexagonal network and cube-connected cycles network have also been developed [21]. Tensor product representations of multistage interconnection networks such as the omega network, the indirect binary n-cube network, and the generalized cube network, have also been developed <ref> [20] </ref>. These representations have been used to prove topological and functional equivalence of these networks and have been used to map algorithms onto specific dynamic networks.
Reference: [21] <author> S. D. Kaushik, S. Sharma, C.-H. Huang, J. R. Johnson, R. W. Johnson, and P. Sadayappan. </author> <title> An algebraic theory for modeling direct interconnection networks. </title> <type> Technical Report OSU-CIS-RC-1/92-TR5, </type> <institution> Dept. of Computer and Information Science, The Ohio State University, </institution> <month> Jan. </month> <year> 1992. </year> <note> Also in Proc. of Supercomputing'92, pp. 488-497. 24 </note>
Reference-contexts: Using the properties of the the vector reversal permutation we have, J 2 n (e 2 i n1 e 2 e 2 i n1 e 2 i 0 . The following properties of the tensor product permutations are used in this paper. We refer the proofs to <ref> [15, 21] </ref>. 1. If N = rst, then L N st = L N t 2. If N = rst, then L N t = L rt t 3. L 2 n Q n2 2 I 2 i 4. <p> The technique can be generalized to construct n-dimensioal torus networks <ref> [21] </ref>. 3.2.2 The Hypercube Interconnection Network The n-dimensional hypercube interconnection network is a 2-ary n-cube and is recursively constructed as the tensor product of n rings, each of size two. <p> Def. 4.3 follows from Def. 4.4 by noting that G 2 n = G 2 n1 which is equivalent to f0 G n1 ; 1 G n1 g. We now present a recursive definition for the Gray permu tation. The proof is referred to <ref> [21] </ref>. 15 Lemma 4.1 G 2 n = I 2 G 2 n1 I 2 n2 ; where G 2 2 = (I 2 J 2 ) Lemma 4.1 will be used extensively in the verification of various network embeddings. 4.4 Embedding Rings in Hypercubes It is known that a ring <p> Tensor product representations of the ring, torus and hypercube network were presented in this paper. Representations for the hexagonal network and cube-connected cycles network have also been developed <ref> [21] </ref>. Tensor product representations of multistage interconnection networks such as the omega network, the indirect binary n-cube network, and the generalized cube network, have also been developed [20].
Reference: [22] <author> R. G. Melhem and G. Hwang. </author> <title> Embedding rectangular grids into square grids with dilation two. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-39(12):1446-1455, </volume> <month> Dec. </month> <year> 1990. </year>
Reference-contexts: Efficient algorithms for performing various permutations, such as bit reversal, vector reversal, perfect shu*e, and unshu*e, on the mesh and hypercube architectures have been presented in [5, 9, 17, 18, 19, 23, 25]. Several strategies for embedding direct networks onto other direct networks have been described in <ref> [1, 3, 10, 22, 24] </ref>. Most previous approaches are based on the graph and binary representations of these networks. It has been proved that the graph and binary representations for a given class of interconnection networks are equivalent to tensor product representations [2]. <p> Several strategies for embedding direct networks in other direct networks have been described in <ref> [1, 3, 10, 22, 24] </ref>. In this section, we demonstrate the use of the tensor product notation to specify and verify several network embeddings.
Reference: [23] <author> D. Nassimi and S. Sahni. </author> <title> An optimal routing algorithm for mesh-connected parallel computers. </title> <journal> Journal of ACM, </journal> <volume> 27(1) </volume> <pages> 6-29, </pages> <month> Jan. </month> <year> 1980. </year>
Reference-contexts: Topological properties of direct interconnection networks have been studied in the literature [8, 24]. Efficient algorithms for performing various permutations, such as bit reversal, vector reversal, perfect shu*e, and unshu*e, on the mesh and hypercube architectures have been presented in <ref> [5, 9, 17, 18, 19, 23, 25] </ref>. Several strategies for embedding direct networks onto other direct networks have been described in [1, 3, 10, 22, 24]. Most previous approaches are based on the graph and binary representations of these networks.
Reference: [24] <author> Y. Saad and M. Schultz. </author> <title> Topological properties of hypercubes. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-37:867-872, </volume> <year> 1988. </year>
Reference-contexts: A number of direct interconnection networks have been proposed for implementing multiprocessor systems [4]. Among these are rings, n-dimensional tori, hypercubes, and cube-connected cycles. Topological properties of direct interconnection networks have been studied in the literature <ref> [8, 24] </ref>. Efficient algorithms for performing various permutations, such as bit reversal, vector reversal, perfect shu*e, and unshu*e, on the mesh and hypercube architectures have been presented in [5, 9, 17, 18, 19, 23, 25]. <p> Efficient algorithms for performing various permutations, such as bit reversal, vector reversal, perfect shu*e, and unshu*e, on the mesh and hypercube architectures have been presented in [5, 9, 17, 18, 19, 23, 25]. Several strategies for embedding direct networks onto other direct networks have been described in <ref> [1, 3, 10, 22, 24] </ref>. Most previous approaches are based on the graph and binary representations of these networks. It has been proved that the graph and binary representations for a given class of interconnection networks are equivalent to tensor product representations [2]. <p> Several strategies for embedding direct networks in other direct networks have been described in <ref> [1, 3, 10, 22, 24] </ref>. In this section, we demonstrate the use of the tensor product notation to specify and verify several network embeddings.
Reference: [25] <author> Y. Saad and M. Schultz. </author> <title> Data communication in hypercubes. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 6 </volume> <pages> 115-135, </pages> <year> 1989. </year>
Reference-contexts: Topological properties of direct interconnection networks have been studied in the literature [8, 24]. Efficient algorithms for performing various permutations, such as bit reversal, vector reversal, perfect shu*e, and unshu*e, on the mesh and hypercube architectures have been presented in <ref> [5, 9, 17, 18, 19, 23, 25] </ref>. Several strategies for embedding direct networks onto other direct networks have been described in [1, 3, 10, 22, 24]. Most previous approaches are based on the graph and binary representations of these networks.
Reference: [26] <author> C. Van Loan. </author> <title> Computational frameworks for the fast Fourier transform. </title> <publisher> SIAM, </publisher> <year> 1992. </year> <month> 25 </month>
Reference-contexts: 1 Introduction Tensor products, also known as Kronecker products, have been previously used for matrix calculus [6, 11]. This notation has also been used for the design and implementation of block recursive numerical algorithms such as fast Fourier transforms <ref> [13, 15, 16, 26] </ref> and Strassen's matrix multiplication [12, 16]. The tensor product formulation of these algorithms has been used to generate efficient parallel and vector programs for shared-memory multiprocessors.
References-found: 26

