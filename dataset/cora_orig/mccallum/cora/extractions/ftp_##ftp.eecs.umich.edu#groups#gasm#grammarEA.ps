URL: ftp://ftp.eecs.umich.edu/groups/gasm/grammarEA.ps
Refering-URL: http://www.eecs.umich.edu/gasm/papers.html
Root-URL: http://www.cs.umich.edu
Email: djohns@watson.ibm.com lmoss@indiana.edu  
Title: Grammar Formalisms Viewed as Evolving Algebras  
Author: David E. Johnson Lawrence S. Moss 
Address: Yorktown Heights, NY 10598 Bloomington, IN 47401  
Affiliation: Mathematical Sciences Department Mathematics Department Thomas J. Watson Research Center Computer Science Department IBM Research Division Indiana University  
Abstract: We consider the use of evolving algebra methods of specifying grammars for natural languages. We are especially interested in distributed evolving algebras. We provide the motivation for doing this, and we give a reconstruction of some classical grammatical formalisms in directly dynamic terms. Finally, we consider some technical questions arising from the use of direct dynamism in grammatical formalisms.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Borger and D. Rosenzweig. </author> <title> A simple mathematical model for full prolog. </title> <type> Tech. Report TR-33/92, </type> <institution> Dipartimento di Informatica, U. Pisa, </institution> <year> 1992. </year>
Reference-contexts: The method was also used to great effect by Borger and Rosenzweig in studying the semantics of Prolog [2]. This last contribution is noteworthy because it not only provided a semantics for the language, it also lead to an analysis of the Warren Abstract Machine <ref> [1] </ref> and to a proof of the correctness of the WAM. Working with evolving algebras allows one to take seriously the dynamic and resource-bounded aspects of computation. Indeed, these features should be taken as primary. <p> The transition rules would expand these graphs, adding new nodes and edge labels, and finally producing a yield from the graph. 16 2 6 6 6 [Cat] S [Head] gave [3] M ary 3 7 7 7 Dative ====) 6 6 6 4 <ref> [1] </ref> J oe [Head] gave [3; 2] M ary 3 7 7 7 Passive ====) 6 6 6 4 [1; 8] J oe [Head] gave [3; 2; 1] M ary 3 7 7 7 Raising & By-Flagging ======) 6 6 6 6 6 6 6 6 6 6 6 [Cat] S <p> labels, and finally producing a yield from the graph. 16 2 6 6 6 [Cat] S [Head] gave [3] M ary 3 7 7 7 Dative ====) 6 6 6 4 [1] J oe [Head] gave [3; 2] M ary 3 7 7 7 Passive ====) 6 6 6 4 <ref> [1; 8] </ref> J oe [Head] gave [3; 2; 1] M ary 3 7 7 7 Raising & By-Flagging ======) 6 6 6 6 6 6 6 6 6 6 6 [Cat] S [Head] was [Comp] 2 6 6 6 6 6 6 6 [Cat] V P [Head] given [2; 8] tea <p> from the graph. 16 2 6 6 6 [Cat] S [Head] gave [3] M ary 3 7 7 7 Dative ====) 6 6 6 4 [1] J oe [Head] gave [3; 2] M ary 3 7 7 7 Passive ====) 6 6 6 4 [1; 8] J oe [Head] gave <ref> [3; 2; 1] </ref> M ary 3 7 7 7 Raising & By-Flagging ======) 6 6 6 6 6 6 6 6 6 6 6 [Cat] S [Head] was [Comp] 2 6 6 6 6 6 6 6 [Cat] V P [Head] given [2; 8] tea [0; 8] 6 [Cat] P P
Reference: [2] <author> E. Borger and D. Rosenzweig. </author> <title> The WAM definition and compiler correctness. </title> <type> Tech. Report TR-33/92, </type> <institution> Dipartimento di Informatica, U. Pisa, </institution> <year> 1992. </year>
Reference-contexts: The work started with large-scale descriptions of programming languages, including Modula-2 [6] and C [7], and Occam [8]. The method was also used to great effect by Borger and Rosenzweig in studying the semantics of Prolog <ref> [2] </ref>. This last contribution is noteworthy because it not only provided a semantics for the language, it also lead to an analysis of the Warren Abstract Machine [1] and to a proof of the correctness of the WAM. <p> The transition rules would expand these graphs, adding new nodes and edge labels, and finally producing a yield from the graph. 16 2 6 6 6 [Cat] S [Head] gave [3] M ary 3 7 7 7 Dative ====) 6 6 6 4 [1] J oe [Head] gave <ref> [3; 2] </ref> M ary 3 7 7 7 Passive ====) 6 6 6 4 [1; 8] J oe [Head] gave [3; 2; 1] M ary 3 7 7 7 Raising & By-Flagging ======) 6 6 6 6 6 6 6 6 6 6 6 [Cat] S [Head] was [Comp] 2 6 <p> from the graph. 16 2 6 6 6 [Cat] S [Head] gave [3] M ary 3 7 7 7 Dative ====) 6 6 6 4 [1] J oe [Head] gave [3; 2] M ary 3 7 7 7 Passive ====) 6 6 6 4 [1; 8] J oe [Head] gave <ref> [3; 2; 1] </ref> M ary 3 7 7 7 Raising & By-Flagging ======) 6 6 6 6 6 6 6 6 6 6 6 [Cat] S [Head] was [Comp] 2 6 6 6 6 6 6 6 [Cat] V P [Head] given [2; 8] tea [0; 8] 6 [Cat] P P <p> 6 4 [1; 8] J oe [Head] gave [3; 2; 1] M ary 3 7 7 7 Raising & By-Flagging ======) 6 6 6 6 6 6 6 6 6 6 6 [Cat] S [Head] was [Comp] 2 6 6 6 6 6 6 6 [Cat] V P [Head] given <ref> [2; 8] </ref> tea [0; 8] 6 [Cat] P P [0; M arked] ii J oe 3 5 7 7 7 7 7 7 7 5 7 7 7 7 7 7 7 7 7 7 7 5 Conclusions and Future Directions In this paper we have modeled grammatical formalisms as evolving
Reference: [3] <author> N. Correa. </author> <title> Attribute and unification grammar: A review and analysis of formalisms. </title> <journal> Linguistics and Philosophy, </journal> <volume> 199? </volume>
Reference-contexts: The equals sign here is not an assignment statement but rather is a node-admissibility condition. For more background, cf. Knuth [12] or Correa <ref> [3] </ref>. Now AG's do have an intuitive dynamics in the sense that we think of the attributes as somehow being dynamically determined by the rules. This dynamism is complicated because attributes may be either synthesized or inherited. In general, combining the top-down and bottom-up information is likely to be complicated. <p> This dynamism is complicated because attributes may be either synthesized or inherited. In general, combining the top-down and bottom-up information is likely to be complicated. For this reason, Correa <ref> [3] </ref> holds that "Most practical attribute evaluators are static and may be generated only for certain subclasses of attributed grammar : : :." These subclasses include those in which all the attributes in a derivation may be taken to be synthesized (S-grammars), in which case the dynamism is transparent. <p> The transition rules would expand these graphs, adding new nodes and edge labels, and finally producing a yield from the graph. 16 2 6 6 6 [Cat] S [Head] gave <ref> [3] </ref> M ary 3 7 7 7 Dative ====) 6 6 6 4 [1] J oe [Head] gave [3; 2] M ary 3 7 7 7 Passive ====) 6 6 6 4 [1; 8] J oe [Head] gave [3; 2; 1] M ary 3 7 7 7 Raising & By-Flagging ======) <p> The transition rules would expand these graphs, adding new nodes and edge labels, and finally producing a yield from the graph. 16 2 6 6 6 [Cat] S [Head] gave [3] M ary 3 7 7 7 Dative ====) 6 6 6 4 [1] J oe [Head] gave <ref> [3; 2] </ref> M ary 3 7 7 7 Passive ====) 6 6 6 4 [1; 8] J oe [Head] gave [3; 2; 1] M ary 3 7 7 7 Raising & By-Flagging ======) 6 6 6 6 6 6 6 6 6 6 6 [Cat] S [Head] was [Comp] 2 6 <p> from the graph. 16 2 6 6 6 [Cat] S [Head] gave [3] M ary 3 7 7 7 Dative ====) 6 6 6 4 [1] J oe [Head] gave [3; 2] M ary 3 7 7 7 Passive ====) 6 6 6 4 [1; 8] J oe [Head] gave <ref> [3; 2; 1] </ref> M ary 3 7 7 7 Raising & By-Flagging ======) 6 6 6 6 6 6 6 6 6 6 6 [Cat] S [Head] was [Comp] 2 6 6 6 6 6 6 6 [Cat] V P [Head] given [2; 8] tea [0; 8] 6 [Cat] P P
Reference: [4] <author> P. Glavan and D. Rosenzweig. </author> <title> Communicating evolving algebras. </title> <booktitle> In Proceedings of the Workshop on Computer Science Logic. </booktitle> <publisher> Springer LNCS, to appear. </publisher>
Reference-contexts: As we have argued in Section 1.1, syntactic frameworks are implicitly dynamic, and we would like to explore explicitly dynamic models. (b) The EA framework has been applied to distributed computation ([8], <ref> [4] </ref>).
Reference: [5] <author> Y. Gurevich. </author> <title> Evolving algebras: a tutorial introduction. </title> <journal> Bulletin of the European Association for Theoretical Computer Science, </journal> <volume> 43 </volume> <pages> 264-286, </pages> <year> 1991. </year>
Reference-contexts: It led to formal language theory, and later developments in that field have found their way back to linguistics. But in addition, ideas originally developed for other applications have been incorporated into linguistic research. This paper considers the use of techniques from the theory of evolving algebras (see Gurevich <ref> [5] </ref>) in the development of syntactic formalisms. Our application of evolving algebras to grammatical formalisms may be viewed as part of several trends. <p> For a more leisurely introduction (which contains a fuller discussion of the reasons for the EA approach to programming semantics), see Gurevich <ref> [5] </ref>. An evolving algebra is a many-sorted, first-order structure together with some transition rules. A many-sorted, first-order structure is just a family of sets (called universes) with functions between them. Typically these universes will be finite, and they will usually come with some basic static functions and relations.
Reference: [6] <author> Y. Gurevich and J. Morris. </author> <title> Algebraic operational semantics and Modula-2. </title> <booktitle> In Proceedings of the First Workshop on Computer Science Logic, </booktitle> <pages> pages 81-101. </pages> <publisher> Springer LNCS 329, </publisher> <year> 1987. </year>
Reference-contexts: At first, it was not completely clear how to describe the local interactions or how the whole fit together from the parts. The EA framework has proved successful in modeling a large number of situations in computing. The work started with large-scale descriptions of programming languages, including Modula-2 <ref> [6] </ref> and C [7], and Occam [8]. The method was also used to great effect by Borger and Rosenzweig in studying the semantics of Prolog [2].
Reference: [7] <author> Y. Gurevich and J. Huggins. </author> <title> The semantics of the C programming language. </title> <booktitle> In Proceedings of the Workshop on Computer Science Logic. </booktitle> <publisher> Springer LNCS, to appear. </publisher>
Reference-contexts: The EA framework has proved successful in modeling a large number of situations in computing. The work started with large-scale descriptions of programming languages, including Modula-2 [6] and C <ref> [7] </ref>, and Occam [8]. The method was also used to great effect by Borger and Rosenzweig in studying the semantics of Prolog [2].
Reference: [8] <author> Y. Gurevich and L.S. Moss. </author> <title> Algebraic operational semantics and Occam. </title> <editor> In E. Borger (et al), editor, </editor> <booktitle> Proceedings of the Third Workshop on Computer Science Logic, </booktitle> <pages> pages 176-196. </pages> <publisher> Springer LNCS 440, </publisher> <year> 1990. </year>
Reference-contexts: The EA framework has proved successful in modeling a large number of situations in computing. The work started with large-scale descriptions of programming languages, including Modula-2 [6] and C [7], and Occam <ref> [8] </ref>. The method was also used to great effect by Borger and Rosenzweig in studying the semantics of Prolog [2]. <p> However, we shall not do this. We present examples of evolving algebras for grammatical formalisms in Sections 3 and 4 below. Examples of runs are harder to come by, since they are so long. For a discussion of these, see <ref> [8] </ref>. 2.3 Choice-Points in the Theory of Evolving Algebras A point that is often confusing is that work in the EA vein is more of a methodology than a fixed set of dogmas. <p> We have presented the algebra this way in part because it matches the presentation of <ref> [8] </ref> and in part because it will be easier to adapt this particular rendering to more complicated formalisms.) The rules above can be regarded two ways: they are either rule schemata and can therefore be instantiated to a particular grammar G to give a fixed EA M G . <p> Indeed, since each node of the tree must go through starting, working, reporting, and dormant modes, the run will have exactly four times as many nodes as the parse tree. The edge relation on the run will be fairly dense as well; see <ref> [8] </ref> for an example spelled out completely. Nevertheless, we can prove results about the set of runs of the EA above. <p> This co-evolution of two nodes is something that is straightforward to express in our setting; indeed, it is exactly the analog of communication as it occurs in the formalization of Occam <ref> [8] </ref>. <p> labels, and finally producing a yield from the graph. 16 2 6 6 6 [Cat] S [Head] gave [3] M ary 3 7 7 7 Dative ====) 6 6 6 4 [1] J oe [Head] gave [3; 2] M ary 3 7 7 7 Passive ====) 6 6 6 4 <ref> [1; 8] </ref> J oe [Head] gave [3; 2; 1] M ary 3 7 7 7 Raising & By-Flagging ======) 6 6 6 6 6 6 6 6 6 6 6 [Cat] S [Head] was [Comp] 2 6 6 6 6 6 6 6 [Cat] V P [Head] given [2; 8] tea <p> 6 4 [1; 8] J oe [Head] gave [3; 2; 1] M ary 3 7 7 7 Raising & By-Flagging ======) 6 6 6 6 6 6 6 6 6 6 6 [Cat] S [Head] was [Comp] 2 6 6 6 6 6 6 6 [Cat] V P [Head] given <ref> [2; 8] </ref> tea [0; 8] 6 [Cat] P P [0; M arked] ii J oe 3 5 7 7 7 7 7 7 7 5 7 7 7 7 7 7 7 7 7 7 7 5 Conclusions and Future Directions In this paper we have modeled grammatical formalisms as evolving <p> 8] J oe [Head] gave [3; 2; 1] M ary 3 7 7 7 Raising & By-Flagging ======) 6 6 6 6 6 6 6 6 6 6 6 [Cat] S [Head] was [Comp] 2 6 6 6 6 6 6 6 [Cat] V P [Head] given [2; 8] tea <ref> [0; 8] </ref> 6 [Cat] P P [0; M arked] ii J oe 3 5 7 7 7 7 7 7 7 5 7 7 7 7 7 7 7 7 7 7 7 5 Conclusions and Future Directions In this paper we have modeled grammatical formalisms as evolving algebras. <p> The formalization of racing processes (for example, where a process waits for input on two channels and acts according to whichever channel was ready first) in our terms can be found in <ref> [8] </ref>; that paper specifically considers the ALT feature of Occam. We suggest that it would be interesting to design grammatical formalisms which incorporate temporal information, and that the use of evolving algebras might make such grammars easier to propose and study.
Reference: [9] <author> D. E. Johnson, A. Meyers, and L. S. Moss. </author> <title> Parsing with relational grammar. </title> <booktitle> In Proeedings of the 31st Annual Meeting of the Association for Computational Linguistics, to appear. </booktitle> <pages> 18 </pages>
Reference-contexts: As we know, a requirement of justification amounts to a requirement that a structure be obtained from a run of some sort of evolving structure. We feel that SFG could be entirely recast dynamically. In fact, something along these lines has already been done in the implementation of SFG <ref> [9] </ref>. We might note that like TAG's, the primary building blocks of SFG are fragments of graphs which are associated with lexical items.
Reference: [10] <author> D. E. Johnson and L. S. Moss. </author> <title> Generalizing feature structures for stratified relational analyses. </title> <booktitle> To appear in the proceedings of the University of Illinois conference on linguistics and computation, </booktitle> <month> June </month> <year> 1991, 1991. </year>
Reference-contexts: In the last position, 0 indicates that the target of the edge does not bear a surface relation to the source. More detailed discussion of these and other rules can be found in <ref> [10] </ref>.) As it stands, SFG is a purely declarative framework. However, it is based on intuitively dynamic notions. The main dynamism in SFG is that the edge sequences are obtained through a kind of updating process.
Reference: [11] <author> D. E. Johnson and L. S. Moss. </author> <title> Some formal properties of stratified feature grammars. </title> <journal> Annals of Mathematics and Artificial Intelligence, </journal> <year> 1993. </year>
Reference-contexts: We feel that these considerations turned people away from the kind of formalism we are pursuing. At the same time, we feel that there are answers to the worries above. Although we do not yet have complexity results for grammar classes, our upper bound results for SFG <ref> [11] </ref> suggest that it will be possible to define significant classes of "mildly context-sensitive" grammars using EA's.
Reference: [12] <author> D. Knuth. </author> <title> Semantics of context-free languages. </title> <journal> Mathematical Systems Theory, </journal> <volume> 2, No. 2 </volume> <pages> 127-145, </pages> <year> 1968. </year>
Reference-contexts: The equals sign here is not an assignment statement but rather is a node-admissibility condition. For more background, cf. Knuth <ref> [12] </ref> or Correa [3]. Now AG's do have an intuitive dynamics in the sense that we think of the attributes as somehow being dynamically determined by the rules. This dynamism is complicated because attributes may be either synthesized or inherited. <p> A complete run of a machine for a given grammar corresponds to a series of attribute definitions which cannot be extended. As Knuth <ref> [12] </ref> remarks, "The process of attribute definition is to be applied throughout the tree until no more attribute values can be defined : : :". Runs which end with output from the root correspond exactly to AG parses.
Reference: [13] <author> W. E. Marsh. </author> <title> Graphs and grammars. </title> <editor> In A. Manaster-Ramer, editor, </editor> <booktitle> Mathematics of Language. </booktitle> <publisher> John Benjamins, </publisher> <year> 1987. </year>
Reference-contexts: In this way, every string in the language of a given TAG G is the output of at least one run of the evolving algebra M G corresponding to G. 4.5 Grammars Based on Graphs Marsh <ref> [13] </ref> presents three kinds of grammars which use graphs which are not trees. He specifically studies Pereira's extraposition grammars, Peters and Ritchie's phrase-link grammars and his own mother-and-daughter grammars.
Reference: [14] <author> B. Partee, A. ter Meulen, and R. E. Wall. </author> <title> Mathematical Methods In Linguistics. </title> <publisher> Kluwer, </publisher> <address> Dordrecht, </address> <year> 1990. </year>
Reference-contexts: The careful writing of transition rules is something of an art. 4 Extensions to CF Grammars In this section, we show how to extend the simple rules for CF grammars to richer formalisms. For more background on these formalisms, see,e.g. Partee et al <ref> [14] </ref>. We might mention here that it is possible to characterize the context-sensitive languages in terms of runs of evolving algebras. However, in contrast to the extensions below, the work for CSL's is much more involved. <p> We shall follow the exposition in section 21.3 of Partee et al <ref> [14] </ref>; this follows Weir et al [17] who used a result of Roach [16] to simplify the presentation of head grammars. Accordingly, an HG derivation generates strings of terminals which in general contain a split string marker ".
Reference: [15] <author> C. Pollard. </author> <title> Generalized Phrase Structure Grammars, Head Grammars, and Natural Language. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1984. </year>
Reference-contexts: would depend on which characterization of CSL's is used, but we know of no way to do it that does not bring in new modes or universes. 9 4.1 Head Grammars One simple extension of the EA in the Section 3 is to the head grammars first studied by Pollard <ref> [15] </ref>. We shall follow the exposition in section 21.3 of Partee et al [14]; this follows Weir et al [17] who used a result of Roach [16] to simplify the presentation of head grammars.
Reference: [16] <author> K. Roach. </author> <title> Formal properties of head grammars. </title> <editor> In A. Manaster-Ramer, editor, </editor> <booktitle> Mathematics of Language. </booktitle> <publisher> John Benjamins, </publisher> <year> 1987. </year>
Reference-contexts: We shall follow the exposition in section 21.3 of Partee et al [14]; this follows Weir et al [17] who used a result of Roach <ref> [16] </ref> to simplify the presentation of head grammars. Accordingly, an HG derivation generates strings of terminals which in general contain a split string marker ".
Reference: [17] <author> D. J. Weir, K. Vijay-Shanker, and A. K. Joshi. </author> <title> Combinatory categorial grammars: generative power and relationship to linear context-free rewriting systems. </title> <booktitle> In Proceedings of the 26th Meeting of the Association for Computational Linguistics, </booktitle> <year> 1986. </year> <month> 19 </month>
Reference-contexts: We shall follow the exposition in section 21.3 of Partee et al [14]; this follows Weir et al <ref> [17] </ref> who used a result of Roach [16] to simplify the presentation of head grammars. Accordingly, an HG derivation generates strings of terminals which in general contain a split string marker ".
References-found: 17

