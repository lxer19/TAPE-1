URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1996/tr-96-001.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1996.html
Root-URL: http://www.icsi.berkeley.edu
Title: Interaction Selection and Complexity Control for Learning in Binarized Domains  
Phone: (510) 643-9153 FAX (510) 643-7684  
Author: Gerald Fahner 
Address: I 1947 Center St. Suite 600 Berkeley, California 94704-1198  
Affiliation: INTERNATIONAL COMPUTER SCIENCE INSTITUTE  
Pubnum: TR-96-001  
Abstract: We empirically investigate the potential of a novel, greatly simplified classifier design for binarized data. The generic model allocates a sparse, "digital" hidden layer comprised of interaction nodes that compute Parity of selected submasks of input bits, followed by a sigmoidal output node with adjustable weights. Model identification incorporates user-assigned complexity preferences. We discuss the situations: a) when the input space obeys a metrics, and b) when the inputs are discrete attributes. We propose a family of respective model priors that make search through the combinatorial space of multi-input interactions feasible. Model capacity and smoothness of the approximation are controlled by two complexity parameters. Model comparison over the parameter plane discovers models with excellent performance. In some cases interpretable structures are achieved. We point out the significance of our novel data mining tool for overcoming scaling problems, impacts on real-time systems, and possible contributions to the development of non-standard computing devices for inductive inference. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ahmed, N.; and Rao, K. R. </author> <year> 1975. </year> <title> Orthogonal Transforms for Digital Signal Processing. </title> <address> New York: </address> <publisher> Springer. </publisher>
Reference: <author> Elder IV, J. F.; and Pregibon, D. </author> <year> 1996. </year> <title> A statistical perspective on knowledge discovery in databases. In: Advances in Knowledge Discovery and Data Mining. </title> <editor> U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, R. Uthurusamy, eds. </editor> <publisher> The MIT Press, </publisher> <address> Menlo Park, CA. </address>
Reference-contexts: Eventually, the process is iterated with a modified or augmented model which takes into account additional interactions. Besides the principal difficulty of discovering unexpected dependencies during this biased way of modelling, huge databases with many variables that interact in complex, unpredictable ways can render the manual design cycle unmanageable <ref> (Elder and Pregibon 1996) </ref>. Vapnik emphasizes a complementary approach to data modelling, which is largely followed by the Neural Network community: "Real-life problems are such that there exist a large number of "weak features" whose "smart" linear combination approximates the unknown dependency well.
Reference: <author> Fahner G.; and Eckmiller, R. </author> <year> 1994. </year> <title> Structural adaptation of parsimonious higher-order neural classifiers. </title> <booktitle> Neural Networks 7(2), </booktitle> <pages> pp. 279-289. </pages>
Reference-contexts: Each node basically evaluates the Parity predicate (in the (0; 1) representation) over some selected sub-mask of input bits, which can be done in parallel. Heuristic supervised learning algorithms for such models were proposed for classification problems of unknown order <ref> (Fahner and Eckmiller 1994) </ref>, and applied for complicated robot navigation problems (Fahner 1995). 3 Searching Sparse Multinomials Model identification requires determination of model size and set of interactions, while parameter estimation yields the respective weights i;k;:: .
Reference: <author> Fahner G. </author> <year> 1995. </year> <title> Vehicle guidance in dynamic environments based on pattern recognition of quasilocal spacetime embeddings. </title> <booktitle> In: Proceedings of the International Conference of Artificial Neural Networks (ICANN-95). </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg. </address>
Reference-contexts: Heuristic supervised learning algorithms for such models were proposed for classification problems of unknown order (Fahner and Eckmiller 1994), and applied for complicated robot navigation problems <ref> (Fahner 1995) </ref>. 3 Searching Sparse Multinomials Model identification requires determination of model size and set of interactions, while parameter estimation yields the respective weights i;k;:: . The algorithm presented in the box below is applied for simultaneous identification and estimation.
Reference: <author> Lang, K. J.; and Witbrok M. </author> <year> 1988. </year> <title> Learning to tell two spirals apart. </title> <booktitle> In: Proceedings of the 1988 Connectionists Model Summer School, </booktitle> <pages> pp. 52-59. </pages> <editor> D. S. Touretzky, G. </editor> <publisher> E. </publisher>
Reference-contexts: The maximum achievable number of zero crossings for an arbitrary direction line-sweep is given by z a + z b = 5. 5 Simulation Results We illustrate the working of the sparse multinomial classifier for the 2-spirals problem. In the original formulation <ref> (Lang and Witbrok 1988) </ref>, the classifier has to find a decision surface to separate two continuous point sets in IR 2 that belong to one or the other of intertwined spirals.
Reference: <editor> Hinton, T. J. Sejnowski, eds. </editor> <address> New York: </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference: <author> Murphy, P. M.; and Aha, D. W. </author> <year> 1992. </year> <title> UCI Repository of machine learning databases, </title> <institution> ftp-site: ics.uci.edu, University of California, </institution> <address> Irvine, CA. </address> <note> 9 Noordewier M. </note> <author> O.; Towell G. G.; and Shavlik J. W. </author> <year> 1991. </year> <title> Training knowledge-based neural networks to recognize genes in DNA sequences. </title> <booktitle> In: Advances in Neural Information Processing Systems 3, </booktitle> <pages> pp 530-536. </pages> <editor> R. P. Lippmann, J. E. Moody, D. S. Touretzky, eds. </editor> <address> San Mateo, CA: </address> <publisher> Morgan Kauffman. </publisher>
Reference-contexts: The best models contain only a few second and no significant higher order interaction. The test error is around 7%, comparable to results from literature with MLP's, and superior to experiments with ID3 and Nearest Neighbor <ref> (Murphy and Aha 1992) </ref>. histograms for the splice-junction predictor: the 120 inputs are ordered along the x-axis. The vertical axis measures absolute weight coefficients assigned to each interaction.
Reference: <author> Vapnik, V. N. </author> <year> 1992. </year> <title> Principles of risk minimization for learning theory. </title> <booktitle> In: Advances in Neural Information Processing Systems 4, </booktitle> <pages> pp. 831-838. </pages> <editor> J. E. Moody, S. J. Hanson, R. P. Lippmann, eds. </editor> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: issues of model selection: * Sparseness: how many interaction terms should a reasonable model include? * Preference: which interaction terms are likely candidates for the problem at hand? * Simplicity: can the computation of interactions be greatly simplified? The first question is answered by an application of "Structural Risk Minimization" <ref> (Vapnik 1992) </ref>. For the sparse multinomial model family discussed in this paper, a nested set of models of increasing size is searched and the optimum compromise between low training error and tight worst case bound for the test error is determined.
Reference: <author> Vapnik, V. N. </author> <year> 1995. </year> <title> The Nature of Statistical Learning Theory. </title> <address> New York: </address> <publisher> Springer. </publisher>
Reference-contexts: Therefore, it is not very important what kind of "weak feature" one uses, it is more important to form "smart" linear combinations." <ref> (Vapnik 1995) </ref>. Data mining tools operating accordingly must support automatic identification of the relevant interactions.
Reference: <author> Walsh, J. L. </author> <year> 1923. </year> <title> A closed set of orthogonal functions. </title> <journal> American Journal of Mathematics 45, </journal> <pages> pp. 5-24. </pages>
References-found: 10

