URL: ftp://ftp.cs.utexas.edu/pub/garbage/johnstone-dissertation.ps.gz
Refering-URL: http://www.cs.utexas.edu/users/oops/papers.html
Root-URL: http://www.cs.utexas.edu
Title: by  
Author: Mark Stuart Johnstone 
Date: 1997  
Note: Copyright  
Abstract-found: 0
Intro-found: 1
Reference: [AEL88] <author> Andrew W. Appel, John R. Ellis, and Kai Li. </author> <title> Real-time concurrent garbage collection on stock multiprocessors. </title> <booktitle> In Proceedings of the 1988 SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 11-20, </pages> <address> Atlanta, Georgia, </address> <month> June </month> <year> 1988. </year> <note> ACM Press. Cited on page 137. </note>
Reference-contexts: In short, Baker's 136 scheme will unpredictably suffer from unacceptably large amounts of garbage collection work, possibly during critical application operations. This problem is even worse in recent collectors which use page-wise virtual memory protection to trigger larger increments of collector work <ref> [AEL88, Det90a, Joh92, BDS91] </ref>, and is also significant on Lisp-machine style hardware.
Reference: [AP87] <author> S. Abraham and J. Patel. </author> <title> Parallel garbage collection on a virtual memory system. </title> <editor> In E. Chiricozzi and A. D'Amato, editors, </editor> <booktitle> International Conference on Parallel Processing and Applications, </booktitle> <pages> pages 243-246, </pages> <address> L'Aquila, Italy, </address> <month> September </month> <year> 1987. </year> <note> Elsevier North-Holland. Cited on page 146. </note>
Reference-contexts: One strategy is to ensure that objects can never get lost, by preventing any pointers from being destroyed <ref> [AP87, Yua90] </ref>. Before overwriting a pointer, the old pointer value is immediately traversed, or saved away so that the collector can still find it and trace it later. We call this a snapshot at beginning algorithm because the collector's view of reachable data structures is fixed when collection begins.
Reference: [Bak78] <author> Henry G. Baker, Jr. </author> <title> List processing in real time on a serial computer. </title> <journal> Communications of the ACM, </journal> <volume> 21(4) </volume> <pages> 280-294, </pages> <month> April </month> <year> 1978. </year> <note> Cited on page 136. </note>
Reference-contexts: For a more extensive survey of this and other work on garbage collection, see [Wil]. 4.2.1 Baker's Incremental Copying Technique Baker's incremental copying technique <ref> [Bak78] </ref> is the best-known "real-time" collection strategy, but it is actually poorly suited to real-time garbage collection on stock hardware: its close coupling between application program actions and collector actions makes it intrinsically more expensive and difficult to use for real-time applications.
Reference: [Bak91] <author> Henry G. Baker, Jr. </author> <title> The Treadmill: Real-time garbage collection without motion sickness. In OOPSLA '91 Workshop on Garbage Collection in Object-Oriented Systems [OOP91]. </title> <note> Position paper. Also appears as SIGPLAN Notices 27(3) 66-70, </note> <month> March </month> <year> 1992. </year> <note> Cited on pages 6, 8, 10, 147, and 150. </note>
Reference-contexts: The garbage objects are never examined, and their space is implicitly reclaimed. While at first these two methods of reclaiming garbage memory may seem fundamentally different, there is a way to combine them to receive many of the advantages of both <ref> [Wan89, Bak91] </ref>. This "fake copying" approach is fundamental to our real-time garbage collector implementation. 1.4.1 Real-Time Garbage Collection Real-time programs are usually characterized as being either hard real-time or soft real-time. Hard real-time programs are programs with very strict bounds on the running times of program operations. <p> This model is based on tricolor marking [DLM + 78] and is augmented with the key idea that garbage collection is really the process of marking objects and moving them from one set to another <ref> [Bak91] </ref>. In addition, this model uses two important invariants that allow us to address the issues of consistency and conservatism in incremental collection. <p> In Section 4.8.1 we explain a technique known as "fake copying" [Wan89] (also known as "implicit reclamation" <ref> [Bak91] </ref>) which avoids the cost of a sweep phase. 10 Chapter 2 Memory Allocation Studies An important part of our research involved studying the "fragmentation problem." In this chapter, we present our results. <p> the test for an incremental update write-barrier can be sped up considerably, at the cost of increased conservatism, by always assuming that any pointer store will violate the write-barrier and optimistically shading the R-value without checking the color of the L-value. 4.6 Non-Copying Incremental Read-Barrier Techniques Wang [Wan89] and Baker <ref> [Bak91] </ref> independently presented a critical insight that can be used to make a mark-sweep collector have many of the advantages of a copying collector. Their insight was that in a copying collector, the "spaces" of the collector are really just a particular implementation of sets. <p> In addition, it must be relatively easy to move an object from one set to another. Finally, it must be easy to switch the roles of the sets at the end of collection. Baker's incremental non-copying garbage collection algorithm <ref> [Bak91] </ref> 10 uses doubly-linked lists (and per-object color fields) to implement the garbage collection sets, rather than separate memory areas. These lists are linked into a cyclic structure, as shown in Figure 4.3. This cyclic structure is divided into four sections: the new-set, the free-set, the from-set and the to-set. <p> We expand on this idea considerably in Section 4.14. 4.8.1 Non-Copying Implicit Reclamation The testbed garbage collector we have implemented combines an incremental update write-barrier with a generalization of Baker's non-copying implicit-reclamation strategy <ref> [Bak91] </ref>, so that objects not yet reached need not be traversed to be reclaimed, as is necessary in the sweep phase of a mark-sweep collector.
Reference: [BBB + 88] <author> Randal E. Bryant, Derek Beatty, Karl Brace, Kyeongsoon Cho, and Thomas Shef-fler. Cosmos: </author> <title> A compiled simulator for MOS circuits. </title> <booktitle> In 25 Years of Electronic Design Automation, </booktitle> <pages> pages 496-503, </pages> <address> New York, New York, </address> <year> 1988. </year> <note> ACM Press. Cited on page 33. </note>
Reference-contexts: Memory is allocated in size classes that are powers of two, (i.e., 4, 8, 16, 32, . . . words). Memory is requested from the operating system in 4K increments. This memory allocator was originally implemented for the COSMOS circuit simulator <ref> [BBB + 88, Bea97] </ref>. * Double Buddy 5K: a double buddy system, using a pair of buddy systems to manage memory for two different (staggered) sets of power-of-two size classes.
Reference: [BC92] <editor> Yves Bekkers and Jacques Cohen, editors. </editor> <booktitle> International Workshop on Memory Management, number 637 in Lecture Notes in Computer Science, </booktitle> <address> St. Malo, France, </address> <month> September </month> <year> 1992. </year> <note> Springer-Verlag. Cited on pages 319 and 321. </note>
Reference: [BDS91] <author> Hans-Juergen Boehm, Alan J. Demers, and Scott Shenker. </author> <title> Mostly parallel garbage collection. </title> <booktitle> In Proceedings of the 1991 SIGPLAN Conference on Programming Language Design and Implementation [PLD91], </booktitle> <pages> pages 157-164. </pages> <note> Cited on pages 137 and 147. </note>
Reference-contexts: In short, Baker's 136 scheme will unpredictably suffer from unacceptably large amounts of garbage collection work, possibly during critical application operations. This problem is even worse in recent collectors which use page-wise virtual memory protection to trigger larger increments of collector work <ref> [AEL88, Det90a, Joh92, BDS91] </ref>, and is also significant on Lisp-machine style hardware. <p> When such a pointer 146 is created, the collector is notified so that it can either trace the pointed-to object immediately, or re-examine the location in which the pointer was stored again later to find any "hidden" objects <ref> [Ste75, DLM + 78, BDS91] </ref>. For example, in Figure 4.2 step 2, when the pointer from object A to object E is created, a pointer to this pointer is recorded, and object E would be traversed when this pointer is re-examined.
Reference: [Bea97] <author> Derek L. Beatty, </author> <year> 1997. </year> <type> personal communication. </type> <note> Cited on page 33. </note>
Reference-contexts: Memory is allocated in size classes that are powers of two, (i.e., 4, 8, 16, 32, . . . words). Memory is requested from the operating system in 4K increments. This memory allocator was originally implemented for the COSMOS circuit simulator <ref> [BBB + 88, Bea97] </ref>. * Double Buddy 5K: a double buddy system, using a pair of buddy systems to manage memory for two different (staggered) sets of power-of-two size classes.
Reference: [Bec82] <author> Leland L. Beck. </author> <title> A dynamic storage allocation technique based on memory residence time. </title> <journal> Communications of the ACM, </journal> <volume> 25(10) </volume> <pages> 714-724, </pages> <month> October </month> <year> 1982. </year> <note> Cited on page 15. 316 </note>
Reference-contexts: In order to develop a sound methodology for studying fragmentation, it is necessary to understand what really causes fragmentation. with real data.) 4 We show in Section 2.12 that this is in fact the case for the programs we studied. 5 Beck <ref> [Bec82] </ref> makes the only clear statement of this principle which we have found in our exhausting review of the literature. His paper is seldom cited, and its important ideas have generally gone unnoticed. 15 Fragmentation is caused by isolated deaths.
Reference: [Ber88] <author> Steven H. Bergstein. </author> <title> Best-case caching in a symbolic multiprocessor. </title> <type> Bachelor's thesis, </type> <institution> Massachusetts Institute of Technology EECS Department, </institution> <address> Cambridge, Mas-sachusetts, </address> <month> February </month> <year> 1988. </year> <note> Cited on page 4. </note>
Reference-contexts: They have made these programs, many of which we used, available by anonymous ftp. We will do the same with the additional programs we used. 2 While there has been some work on the locality of reference of memory allocators that can move memory (such as garbage collectors) <ref> [WLM90, WLM92, Zor91, PS89, JLS92, Nut87, Ber88] </ref>, [GZH93] was the only paper on the topic of locality and non-moving memory allocation that we were able to locate.
Reference: [Bro84] <author> Rodney A. Brooks. </author> <title> Trading data space for reduced time and code space in real-time collection on stock hardware. </title> <booktitle> In Conference Record of the 1984 ACM Symposium on LISP and Functional Programming [LFP84], </booktitle> <pages> pages 108-113. </pages> <note> Cited on pages 137 and 138. </note>
Reference-contexts: The above algorithms all fall into the class of incremental copying read-barrier techniques. Others have proposed copying-based algorithms that rely on a combination of a read-barrier and a write-barrier (extra instructions executed at every pointer store) <ref> [Bro84] </ref>, or on a write-barrier only [NOPH92] to coordinate the collector's view of the graph with that of the application. 3 Nilsen gives no indication of the parameters used in timing this worst-case, so it is impossible to evaluate this pause. 137 4.2.3 Brooks' Technique Brooks' algorithm [Bro84] deserves special mention <p> every pointer store) <ref> [Bro84] </ref>, or on a write-barrier only [NOPH92] to coordinate the collector's view of the graph with that of the application. 3 Nilsen gives no indication of the parameters used in timing this worst-case, so it is impossible to evaluate this pause. 137 4.2.3 Brooks' Technique Brooks' algorithm [Bro84] deserves special mention as the only copying hard real-time garbage collection algorithm that we know of. This algorithm combines a read-barrier and a write-barrier to coordinate the work of the mutator and the garbage collector in a way that is easier to make real-time than Baker's algorithm.
Reference: [Che70] <author> C. J. </author> <title> Cheney. A nonrecursive list compacting algorithm. </title> <journal> Communications of the ACM, </journal> <volume> 13(11) </volume> <pages> 677-678, </pages> <month> November </month> <year> 1970. </year> <note> Cited on page 6. </note>
Reference-contexts: An example of explicit reclamation is mark-sweep collection [McC60]. In a mark-sweep collector, once the live objects have been distinguished from the garbage objects, memory is exhaustively examined (swept) to find all of the garbage objects and reclaim their space. An example of implicit reclamation is copying collection <ref> [FY69, Che70] </ref>. In a copying collector, the live objects are copied out of one area of memory and into another. Once all live objects have been copied out of the original memory area, that entire area is considered to be garbage and can be reclaimed in one operation.
Reference: [CK93] <author> Robert Cmelik and David Keppel. Shade: </author> <title> A fast instruction-set simulator for execution profiling. </title> <type> Technical Report UWCSE 93-06-06, </type> <institution> Dept. of Computer Science and Engineering, University of Washington, </institution> <address> Seattle, Washington, </address> <year> 1993. </year> <note> Cited on pages 39 and 106. </note>
Reference-contexts: For our locality studies, we collected and processed the data loads and stores of our test programs by using the Shade trace gathering tool <ref> [CK93] </ref>. These traces were processed on-line by piping directly from Shade to the processing tools (see Section 3.5). 2.8 Experimental Design A goal of this research is to measure the true fragmentation costs of particular memory allocation policies independently of their implementations. <p> We accomplished this by using trace-driven simulation (Section 2.7). We gathered a trace of the instruction and data references of our test programs using the Shade instruction-level trace gathering tool <ref> [CK93] </ref>. Shade [CK93] is a program that generates exact instruction level traces of any program that runs on the Sparc architecture (V8 & V9). <p> We accomplished this by using trace-driven simulation (Section 2.7). We gathered a trace of the instruction and data references of our test programs using the Shade instruction-level trace gathering tool <ref> [CK93] </ref>. Shade [CK93] is a program that generates exact instruction level traces of any program that runs on the Sparc architecture (V8 & V9). By using Shade and a small routine we wrote, we were able to generate dinero format [Hil87] instruction-level traces for each combination of test program and allocation policy.
Reference: [Col61] <author> G. O. Collins. </author> <title> Experience in automatic storage allocation. </title> <journal> Communications of the ACM, </journal> <volume> 4(10) </volume> <pages> 436-440, </pages> <month> October </month> <year> 1961. </year> <note> Cited on pages 12 and 86. </note>
Reference-contexts: This is expected to grow to $2.25 billion by 1999. 11 improve upon the default implementation. This practice invariably results in wasted space, subtle bugs, and portability problems. 2 The overwhelming majority of memory allocation studies to date have been based on a methodology developed in the 1960's <ref> [Col61] </ref>, which uses synthetic traces intended to model "typical" program behavior. This methodology has the advantages that it is easy to implement and allows experiments to avoid quirky behavior specific to a few programs. <p> Second, researchers have tended to use an experimental methodology that is fundamentally flawed. The overwhelming majority of memory allocation studies to date have been based on a methodology developed in the 1960's <ref> [Col61] </ref>, which uses synthetic traces intended to model "typical" program behavior. This methodology has the advantage that it is easy to implement, and allows experiments to avoid idiosyncratic behavior specific to only a few programs.
Reference: [DDZ93] <author> David Detlefs, Al Dosser, and Benjamin Zorn. </author> <title> Memory allocation costs in large C and C++ programs. </title> <type> Technical Report CU-CS-665-93, </type> <institution> University of Colorado at Boulder, Dept. of Computer Science, Boulder, Colorado, </institution> <month> August </month> <year> 1993. </year> <note> Cited on pages 4 and 35. </note>
Reference-contexts: Surprisingly, researchers have virtually ignored one of the most important effects on a program's locality of reference: that of the dynamic memory allocator's placement choices. 2 1 The studies by Zorn <ref> [DDZ93, ZG92] </ref> and by Vo [Vo95] were the only work we found that used actual programs in their studies. They have made these programs, many of which we used, available by anonymous ftp. <p> Our suite does include one almost non-freeing program, LRUsim, which is the only non-freeing program we had that we were sure did not leak. 15 Two programs used by Zorn and Grunwald [ZG92] and by Detlefs, Dosser, and Zorn <ref> [DDZ93] </ref>, which we did not use, have heaps that are quite small: Cfrac only uses 21.4 KB and Gawk only uses 41 KB, which are only a few pages on most modern machines.
Reference: [Den70] <author> Peter J. Denning. </author> <title> Virtual memory. </title> <journal> Computing Surveys, </journal> <volume> 3(2) </volume> <pages> 153-189, </pages> <month> September </month> <year> 1970. </year> <note> Cited on page 101. </note>
Reference-contexts: In this research, we only studied write-allocate caches. Virtual Memory Although most people think of a computer's RAM as being its main memory, in most modern computers, the RAM is just a cache for the larger disk-based virtual memory <ref> [Den70] </ref>. Thus, many of the same locality issues exist at the virtual memory level as do at the cache level of the memory hierarchy. In particular, because disk storage is around 1,000,000 times slower than RAM, achieving good locality of reference is very important.
Reference: [Det90a] <author> David L. Detlefs. </author> <title> Concurrent garbage collection for C++. </title> <type> Technical Report CMU-CS-90-119, </type> <institution> Carnegie-Mellon University, </institution> <month> May </month> <year> 1990. </year> <note> Cited on page 137. </note>
Reference-contexts: In short, Baker's 136 scheme will unpredictably suffer from unacceptably large amounts of garbage collection work, possibly during critical application operations. This problem is even worse in recent collectors which use page-wise virtual memory protection to trigger larger increments of collector work <ref> [AEL88, Det90a, Joh92, BDS91] </ref>, and is also significant on Lisp-machine style hardware.
Reference: [DeT90b] <author> John DeTreville. </author> <title> Experience with concurrent garbage collectors for Modula-2+. </title> <type> Technical Report 64, </type> <institution> Digital Equipment Corporation Systems Research Center, Palo Alto, California, </institution> <month> August </month> <year> 1990. </year> <note> Cited on page 8. </note>
Reference-contexts: In most programs in a variety of languages, most objects live a very short time, while a small percentage live much longer <ref> [LH83, Ung84, Sha88, Zor90, DeT90b, Hay91] </ref>.
Reference: [DLM + 78] <author> Edsger W. Dijkstra, Leslie Lamport, A. J. Martin, C. S. Scholten, and E. F. M. Steffens. </author> <title> On-the-fly garbage collection: An exercise in cooperation. </title> <journal> Communications of the ACM, </journal> <volume> 21(11) </volume> <pages> 966-975, </pages> <month> November </month> <year> 1978. </year> <note> Cited on pages 7, 8, 141, 144, and 147. </note>
Reference-contexts: For this reason, discussions of incremental collectors typically refer to the running program as the mutator <ref> [DLM + 78] </ref>. An incremental scheme must have some way of keeping track of the changes to the graph of reachable objects, perhaps re-computing parts of its traversal in the face of those changes. <p> This model is based on tricolor marking <ref> [DLM + 78] </ref> and is augmented with the key idea that garbage collection is really the process of marking objects and moving them from one set to another [Bak91]. <p> traversal algorithm. 5 5 In parallel and distributed garbage collection, a relaxed consistency model also allows more parallelism and/or less synchronization, but that is beyond the scope of this dissertation. 140 4.4 Tri-Color Marking The abstraction of tri-color marking is helpful in understanding coherence and conservatism in incremental garbage collection <ref> [DLM + 78] </ref>. Garbage collection algorithms can be conceptually described as a process of traversing the graph of reachable objects and coloring them. The objects are originally colored white, and as the graph is traversed, they are colored black 6 . <p> The tri-color invariant takes on two forms which we now define: 1. The strong tri-color invariant: For all black objects in the graph which have a path to a white object, all paths from that black object to that white object must contain at least one gray object <ref> [DLM + 78] </ref>. 2. The weak tri-color invariant: For all black objects in the graph which have a path to a white object, at least one path from that black object to that white object must contain at least one gray object [Yua90]. <p> When such a pointer 146 is created, the collector is notified so that it can either trace the pointed-to object immediately, or re-examine the location in which the pointer was stored again later to find any "hidden" objects <ref> [Ste75, DLM + 78, BDS91] </ref>. For example, in Figure 4.2 step 2, when the pointer from object A to object E is created, a pointer to this pointer is recorded, and object E would be traversed when this pointer is re-examined.
Reference: [Ede92] <author> Daniel Ross Edelson. </author> <title> Smart pointers: They're smart, but they're not pointers. </title> <booktitle> In USENIX C++ Conference, </booktitle> <pages> pages 1-19, </pages> <address> Portland, Oregon, </address> <month> August </month> <year> 1992. </year> <title> USENIX Association. </title> <type> Technical Report UCSC-CRL-92-27, </type> <institution> University of California at Santa Cruz, Baskin Center for Computer Engineering and Information Sciences, </institution> <month> June </month> <year> 1992. </year> <note> Cited on page 161. </note>
Reference-contexts: In this interface, garbage-collected objects have an associated pointer type defined in a library as a parameterized class, and client code must use these pointers rather than raw C++ pointers. (Parameterization and operator overloading make this relatively easy, although smart pointers cannot be used quite as flexibly as raw pointers <ref> [Ede92] </ref>.) The main difference between our parameterized pointers and normal pointers is that pointer assignments execute an additional few lines of code, which constitute the write-barrier. In our system, each object has a hidden header field, created by our overloaded version of the C++ new operator.
Reference: [EV91] <author> Steven Engelstad and Jim Vandendorp. </author> <title> Automatic storage management for systems with real time constraints. In OOPSLA '91 Workshop on Garbage Collection in Object-Oriented Systems [OOP91]. </title> <note> Position paper. Cited on page 136. 317 </note>
Reference-contexts: This read-barrier cost is potentially high, and very unpredictable, because the cost of traversing an ordinary list is strongly dependent on whether or not the list has already been reached and copied by the collector <ref> [Nil88, EV91, Wit91] </ref>.
Reference: [Fre84] <author> John E. Freund. </author> <title> Modern Elementary Statistics. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1984. </year> <note> Cited on page 47. </note>
Reference-contexts: Because we only have one variation on first fit FIFO (the second first fit FIFO allocator only removed footer costs, which have been removed in the 26 This interpretation of the t-test comes from <ref> [Fre84] </ref>.
Reference: [FW86] <author> Philip J. Fleming and John J. Wallace. </author> <title> How not to lie with statistics: the correct way to summarize benchmark results. </title> <journal> Communications of the ACM, </journal> <volume> 29(3), </volume> <month> March </month> <year> 1986. </year> <note> Cited on page 42. </note>
Reference-contexts: by as much as 4K times the number of size classes, which is roughly 4K fl ln (largest size smallest size), and 4K fl 2 fl ln (largest size smallest size) (one sixteenth of this value for our final numbers). 2.8.4 Our Use of Averages In this dissertation, we follow <ref> [FW86, PH96] </ref> when we present averages. If the numbers being averaged are simple numbers, such as the fragmentation of a program given a particular allocator, we use the arithmetic mean.
Reference: [FY69] <author> Robert R. Fenichel and Jerome C. Yochelson. </author> <title> A LISP garbage-collector for virtual-memory computer systems. </title> <journal> Communications of the ACM, </journal> <volume> 12(11) </volume> <pages> 611-612, </pages> <note> Novem-ber 1969. Cited on page 6. </note>
Reference-contexts: An example of explicit reclamation is mark-sweep collection [McC60]. In a mark-sweep collector, once the live objects have been distinguished from the garbage objects, memory is exhaustively examined (swept) to find all of the garbage objects and reclaim their space. An example of implicit reclamation is copying collection <ref> [FY69, Che70] </ref>. In a copying collector, the live objects are copied out of one area of memory and into another. Once all live objects have been copied out of the original memory area, that entire area is considered to be garbage and can be reclaimed in one operation.
Reference: [GZH93] <author> Dirk Grunwald, Benjamin Zorn, and Robert Henderson. </author> <title> Improving the cache locality of memory allocation. </title> <booktitle> In Proceedings of the 1993 SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 177-186, </pages> <address> Albuquerque, New Mexico, </address> <month> June </month> <year> 1993. </year> <note> ACM Press. Cited on pages 4, 5, 10, 96, and 102. </note>
Reference-contexts: We will do the same with the additional programs we used. 2 While there has been some work on the locality of reference of memory allocators that can move memory (such as garbage collectors) [WLM90, WLM92, Zor91, PS89, JLS92, Nut87, Ber88], <ref> [GZH93] </ref> was the only paper on the topic of locality and non-moving memory allocation that we were able to locate. The authors of 4 Grunwald, Zorn, and Henderson [GZH93] show that different allocators can have an important effect on the locality of the programs that use them. <p> the locality of reference of memory allocators that can move memory (such as garbage collectors) [WLM90, WLM92, Zor91, PS89, JLS92, Nut87, Ber88], <ref> [GZH93] </ref> was the only paper on the topic of locality and non-moving memory allocation that we were able to locate. The authors of 4 Grunwald, Zorn, and Henderson [GZH93] show that different allocators can have an important effect on the locality of the programs that use them. However, they failed to separate the locality effects of the allocation policy from those of the particular mechanism. <p> Because a memory allocator has complete control of the program's layout of dynamic memory, it seems obvious that the choice of memory allocation policy will have a major effect on the locality of reference of that program. Surprisingly, we were only able to find a single paper <ref> [GZH93] </ref> discussing the effects of non-moving memory allocation algorithms on locality of reference. Having clarified these issues, we devote the final third of this dissertation to our work on real-time garbage collection. <p> Surprisingly, researchers have virtually ignored one of the most important effects on a program's locality of reference: that of the dynamic memory allocator's placement choices. 1 The only paper on this topic we were able to find was <ref> [GZH93] </ref>. This paper's key contribution was showing that the choice of memory allocator can affect the locality of the application. Unfortunately, its authors failed to separate the locality effects of the allocation policy from those of their implementation. <p> It is this last effect on locality that we studied for this research. Surprisingly, <ref> [GZH93] </ref> was the only work we could find that studied the effect of non-moving memory algorithms on the locality of reference of programs. The authors of [GZH93] also found it surprising that this seems to be an entirely unexplored research area. <p> It is this last effect on locality that we studied for this research. Surprisingly, <ref> [GZH93] </ref> was the only work we could find that studied the effect of non-moving memory algorithms on the locality of reference of programs. The authors of [GZH93] also found it surprising that this seems to be an entirely unexplored research area. Having settled the issue of how different allocation policies affect fragmentation, we wanted to study how these same policy decisions affect locality of reference.
Reference: [Han90] <author> David R. Hanson. </author> <title> Fast allocation and deallocation of memory based on object lifetimes. </title> <journal> Software Practice and Experience, </journal> <volume> 20(1), </volume> <month> January </month> <year> 1990. </year> <note> Cited on page 37. </note>
Reference-contexts: Memory usage is dominated by a large AVL tree 24 19 Obstacks are an extension to the C language, used to optimize the allocation and deallocation objects in stack-like ways. A similar scheme is described in <ref> [Han90] </ref>. 20 It is our belief that we should study the behavior of the program without hand-optimized memory allocation, because a well-designed allocator should usually be able to do as well as or better than most programmers' hand optimizations.
Reference: [Hay91] <author> Barry Hayes. </author> <title> Using key object opportunism to collect old objects. </title> <editor> In Andreas Paepcke, editor, </editor> <booktitle> Conference on Object Oriented Programming Systems, Languages and Applications (OOPSLA '91), </booktitle> <pages> pages 33-46, </pages> <address> Phoenix, Arizona, </address> <month> October </month> <year> 1991. </year> <note> ACM Press. Cited on page 8. </note>
Reference-contexts: In most programs in a variety of languages, most objects live a very short time, while a small percentage live much longer <ref> [LH83, Ung84, Sha88, Zor90, DeT90b, Hay91] </ref>.
Reference: [Hil87] <author> Mark D. Hill. </author> <title> Aspects of Cache Memory and Instruction Buffer Performance. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, Berkeley, California, </institution> <month> November </month> <year> 1987. </year> <note> Cited on page 106. </note>
Reference-contexts: Shade [CK93] is a program that generates exact instruction level traces of any program that runs on the Sparc architecture (V8 & V9). By using Shade and a small routine we wrote, we were able to generate dinero format <ref> [Hil87] </ref> instruction-level traces for each combination of test program and allocation policy. A dinero trace of a program is just an ascii trace of the loads, stores, and other instructions of that program, along with their corresponding addresses. <p> To measure locality at the cache level, we used the tycho cache simulator. Tycho <ref> [Hil87] </ref> is a trace-driven cache simulator that can simulate many alternative direct-mapped, set-associative, and fully-associative caches with one pass through a dinero format address trace to produce a table of miss ratios.
Reference: [JLS92] <author> Phillip J. Koopman Jr., Peter Lee, and Daniel P. Siewiorek. </author> <title> Cache performance of combinator graph reduction. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 14(2) </volume> <pages> 265-297, </pages> <month> April </month> <year> 1992. </year> <note> Cited on page 4. </note>
Reference-contexts: They have made these programs, many of which we used, available by anonymous ftp. We will do the same with the additional programs we used. 2 While there has been some work on the locality of reference of memory allocators that can move memory (such as garbage collectors) <ref> [WLM90, WLM92, Zor91, PS89, JLS92, Nut87, Ber88] </ref>, [GZH93] was the only paper on the topic of locality and non-moving memory allocation that we were able to locate.
Reference: [Joh92] <author> Ralph E. Johnson. </author> <title> Reducing the latency of a real-time garbage collector. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 1(1) </volume> <pages> 46-58, </pages> <month> March </month> <year> 1992. </year> <note> Cited on page 137. </note>
Reference-contexts: In short, Baker's 136 scheme will unpredictably suffer from unacceptably large amounts of garbage collection work, possibly during critical application operations. This problem is even worse in recent collectors which use page-wise virtual memory protection to trigger larger increments of collector work <ref> [AEL88, Det90a, Joh92, BDS91] </ref>, and is also significant on Lisp-machine style hardware.
Reference: [Kak97] <author> Sheetal V. Kakkad. </author> <title> Address Translation and Storage Management for Persistent Object Stores. </title> <type> PhD thesis, </type> <institution> The University of Texas at Austin, Austin, Texas, </institution> <note> De-cember 1997. Cited on page 161. </note>
Reference-contexts: The actual type descriptor information is constructed by compiling the program with the debugging option turned on, and by using a special program which extracts structure layouts from the debugging information <ref> [Kak97] </ref>. (We use code from the GNU gdb debugger for this, so our collector should be easily portable to any system that uses a debugging output format that gdb understands.) 23 Clearly, a program that exceeds its hard resource bounds is simply incorrect.
Reference: [Kin] <author> Chris Kingsley. </author> <title> Implementation of malloc from bsd 4.2 unix. </title> <note> http: //www.plaza.hitachi-sk.co.jp/ftp/FreeBSD/FreeBSD-stable/src/lib/ libc/stdlib/malloc.c. Cited on page 18. </note>
Reference-contexts: Time It is well known that it is easy to write a memory allocator that is very fast, as long as space issues are not important. Kingsley's BSD 4.2 UNIX memory allocator is an example of such an allocator <ref> [Kin] </ref>. It is a simple segregated storage allocator (Section 2.4.1) that rounds all object request sizes up to powers of two minus a constant.
Reference: [Kno65] <author> Kenneth C. Knowlton. </author> <title> A fast storage allocator. </title> <journal> Communications of the ACM, </journal> <volume> 8(10) </volume> <pages> 623-625, </pages> <month> October </month> <year> 1965. </year> <note> Cited on pages 24 and 25. 318 </note>
Reference-contexts: Finally, free regions of memory can be searched quickly by looking at several bits at a time and using a table to determine if that bit pattern could possibly hold an object of the desired size. 2.4.3 Buddy Systems Buddy systems <ref> [Kno65, PN77] </ref> are a variant of segregated lists, supporting a limited but efficient kind of splitting and coalescing. In the simple buddy schemes, the entire heap area is conceptually split into two large areas which are called buddies. <p> Several significant variations on buddy systems have been devised. Of these, we studied binary buddies and double buddies. Binary Buddy Binary buddy is the simplest and best-known of the buddy systems <ref> [Kno65] </ref>. In this scheme, all buddy sizes are a power of two, and each size is divided into two equal parts.
Reference: [Knu73] <author> Donald E. Knuth. </author> <title> The Art of Computer Programming, volume 1: Fundamental Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1973. </year> <note> First edition published in 1968. Cited on pages 15, 21, 22, 23, 45, and 93. </note>
Reference-contexts: of those sizes, making it possible to find a perfect fit. 4 On the other hand, if the object sizes are smoothly distributed, then the requested sizes will almost always be slightly different, thus increasing the chances of fragmentation. 2.1.2 Probabilistic Analyses Since Knuth's derivation of the "fifty percent rule" <ref> [Knu73] </ref>, there have been many attempts to reason probabilistically about the interactions between program behavior and allocator policy, and to assess the overall cost in terms of fragmentation and/or CPU time. <p> Typically, sequential-fit algorithms use Knuth's boundary tag technique to support coalescing of all adjacent free areas <ref> [Knu73] </ref>. The list of free blocks is usually maintained in either FIFO, LIFO, or address order (AO). <p> toward behaving like best fit over time, because the smallest blocks end up near the front of the list, so that blocks are effectively searched in size order, and the smallest chosen first. 8 Next fit A common "optimization" of first fit is to use a roving pointer for allocation <ref> [Knu73] </ref>. The pointer records the position where the last search was satisfied, and the next search begins from there. <p> In addition, segregated-fit algorithms (Section 2.4.1) can be a very good approximation to best fit and are easy to implement efficiently. Boundary Tags and Per-Object Overheads Sequential-fit techniques are usually implemented using boundary tags to support the coalescing of free areas <ref> [Knu73] </ref>. Each block of memory has a header and a footer field, both of which record the size of the block and whether it is in use. <p> In terms of rank order of allocator policies, these results contrast with traditional simulation results, where best fit usually performs well but is sometimes outperformed by next fit (e.g., in Knuth's small but influential study <ref> [Knu73] </ref>). In terms of practical application, we believe this is one of our most significant findings. <p> Only three versions of next fit had less than 10% actual fragmentation, and all of those versions used an address-ordered free list. These results contrast with traditional simulation results, where best fit usually performs well but is sometimes outperformed by next fit (e.g., in Knuth's small but influential study <ref> [Knu73] </ref>). In terms of practical applications, we believe this is one of our most significant findings. It has long been believed that increasing internal fragmentation to reduce external fragmentation is a good tradeoff.
Reference: [Kuh70] <author> Thomas S. Kuhn. </author> <title> The Structure of Scientific Revolutions (Second Edition, </title> <type> Enlarged). </type> <institution> University of Chicago Press, Chicago, Illinois, </institution> <year> 1970. </year> <note> Cited on page 14. </note>
Reference-contexts: Even now, researchers often use simple and smooth mathematical functions to generate traces for allocator evaluation. 3 The use of smooth 3 We are unclear on why this should be, except that a particular theoretical and experimental paradigm <ref> [Kuh70] </ref> had simply become thoroughly entrenched by the early 1970's. (It is also somewhat easier than dealing 14 distributions is questionable, because it bears directly on issues of fragmentation.
Reference: [KV85] <author> David G. Korn and Kiem-Phong Vo. </author> <title> In search of a better malloc. </title> <booktitle> In Proc. USENIX Summer 1985, </booktitle> <pages> pages 489-506, </pages> <address> Portland, Oregon, </address> <month> June </month> <year> 1985. </year> <booktitle> USENIX Association. Cited on pages 27 and 94. </booktitle>
Reference-contexts: This block is usually rather large, and a mistake in managing it can be expensive. Since such blocks are allocated whenever heap memory grows, consistent mistakes could be disastrous <ref> [KV85] </ref>. <p> Korn and Vo call this a "wilderness preservation heuristic," and report that it is helpful for some allocators <ref> [KV85] </ref> (however, no quantitative results are given). Our results show that for the best allocation policies (best fit and first fit address ordered), special treatment of the wilderness block is unnecessary. <p> Korn and Vo suggest special treatment of the block of memory most recently obtained from the operating system. They call this a "wilderness preservation heuristic," and report that it is helpful for some allocators <ref> [KV85] </ref>. However, our results (in Section 2.9) show that for the best allocation policies (best fit and first fit address ordered), special treatment of the wilderness block is unnecessary.
Reference: [Lea] <author> Doug Lea. </author> <title> Implementations of malloc. </title> <note> See also the short paper on the implementation of this allocator. Available at www://g.oswego.edu. Cited on page 95. </note>
Reference-contexts: For example, best fit can be implemented using a tree of lists of same-sized objects [Sta80], and first fit address ordered can be implemented using a Cartesian tree [Ste83]. Most importantly, an excellent allocator implementation that runs on many platforms was written by Douglas Lea and is freely available <ref> [Lea] </ref>. This allocator was improved partly due to the results in our original survey [WJNB95], and is now a very close approximation of best fit.
Reference: [LFP84] <institution> Conference Record of the 1984 ACM Symposium on LISP and Functional Programming, Austin, Texas, </institution> <month> August </month> <year> 1984. </year> <note> ACM Press. Cited on pages 317 and 319. </note>
Reference: [LH83] <author> Henry Lieberman and Carl Hewitt. </author> <title> A real-time garbage collector based on the lifetimes of objects. </title> <journal> Communications of the ACM, </journal> <volume> 26(6) </volume> <pages> 419-429, </pages> <month> June </month> <year> 1983. </year> <note> Cited on pages 8, 9, and 162. </note>
Reference-contexts: In most programs in a variety of languages, most objects live a very short time, while a small percentage live much longer <ref> [LH83, Ung84, Sha88, Zor90, DeT90b, Hay91] </ref>. <p> These objects are processed at every collection, over and over, and the garbage collector spends most of its time processing the same old objects repeatedly. This is the major source of inefficiency in simple garbage collectors. Generational collection <ref> [LH83] </ref> avoids much of this repeated processing by segregating objects into multiple areas by age, and collecting areas containing older objects less often than the younger ones. Once objects have survived a small number of collections, they are "moved" to a less frequently collected area. <p> Areas containing younger objects are collected quite frequently, because most objects there will generally die quickly, freeing up space; processing the few that survive does not cost much. These survivors are advanced to older status after a few collections, to keep processing costs down. <ref> [LH83, Moo84, Ung84, Wil92] </ref>. For stop-and-collect garbage collection, generational garbage collection has the additional benefit that most collections take only a short time (collecting just the youngest generation is much faster than a full garbage collection). <p> The minority of objects that survive for a longer period are made exempt from most garbage collection cycles so that they may have more time to die before again being considered for garbage collection <ref> [LH83, Moo84, Ung84, Wil92] </ref>. Because generational techniques rely on a heuristic|the guess that most objects will die young and that older objects will not die soon|they are not strictly reliable, and may degrade collector performance in the worst case. Therefore, for purely hard real-time systems, they may not be attractive.
Reference: [McC60] <author> John McCarthy. </author> <title> Recursive functions of symbolic expressions and their computation by machine. </title> <journal> Communications of the ACM, </journal> <volume> 3(4) </volume> <pages> 184-195, </pages> <month> April </month> <year> 1960. </year> <note> Cited on page 6. </note>
Reference-contexts: Find and reclaim all objects known to be garbage (explicit garbage reclamation). 2. Find and preserve all objects known to be live. All objects left over are garbage and can be reclaimed in one action (implicit garbage reclamation). An example of explicit reclamation is mark-sweep collection <ref> [McC60] </ref>. In a mark-sweep collector, once the live objects have been distinguished from the garbage objects, memory is exhaustively examined (swept) to find all of the garbage objects and reclaim their space. An example of implicit reclamation is copying collection [FY69, Che70].
Reference: [MH95] <author> B. Magnusson and R. Henriksson. </author> <title> Garbage collection for control systems. </title> <editor> In Henry Baker, editor, </editor> <booktitle> International Workshop on Memory Management, Lecture Notes in Computer Science, </booktitle> <address> Scotland, </address> <month> September </month> <year> 1995. </year> <note> Springer-Verlag. Cited on page 138. </note>
Reference-contexts: Implementation and study of this modification to Brooks' algorithm is future work. 4.2.5 Magnusson and Henriksson's Scheduling Techniques Magnusson and Henriksson address scheduling considerations for hard real-time garbage collectors <ref> [MH95] </ref>. While their approach is described as an extension of a Brooks-style copying garbage collector, we believe that it would work equally well with a non-copying garbage collector such as ours. They suggest that the scheduler be modified to accommodate three priority levels: 1. High-priority processes 2. Garbage collection 3.
Reference: [Moo84] <author> David Moon. </author> <title> Garbage collection in a large Lisp system. </title> <booktitle> In Conference Record of the 1984 ACM Symposium on LISP and Functional Programming [LFP84], </booktitle> <pages> pages 235-246. </pages> <note> Cited on pages 9 and 162. </note>
Reference-contexts: Areas containing younger objects are collected quite frequently, because most objects there will generally die quickly, freeing up space; processing the few that survive does not cost much. These survivors are advanced to older status after a few collections, to keep processing costs down. <ref> [LH83, Moo84, Ung84, Wil92] </ref>. For stop-and-collect garbage collection, generational garbage collection has the additional benefit that most collections take only a short time (collecting just the youngest generation is much faster than a full garbage collection). <p> The minority of objects that survive for a longer period are made exempt from most garbage collection cycles so that they may have more time to die before again being considered for garbage collection <ref> [LH83, Moo84, Ung84, Wil92] </ref>. Because generational techniques rely on a heuristic|the guess that most objects will die young and that older objects will not die soon|they are not strictly reliable, and may degrade collector performance in the worst case. Therefore, for purely hard real-time systems, they may not be attractive.
Reference: [Nil88] <author> Kelvin Nilsen. </author> <title> Garbage collection of strings and linked data structures in real time. </title> <journal> Software Practice and Experience, </journal> <volume> 18(7) </volume> <pages> 613-640, </pages> <month> July </month> <year> 1988. </year> <note> Cited on page 136. </note>
Reference-contexts: This read-barrier cost is potentially high, and very unpredictable, because the cost of traversing an ordinary list is strongly dependent on whether or not the list has already been reached and copied by the collector <ref> [Nil88, EV91, Wit91] </ref>.
Reference: [NOPH92] <author> Scott Nettles, James O'Toole, David Pierce, and Nicholas Haines. </author> <title> Replication-based incremental copying collection. </title> <booktitle> In Bekkers and Cohen [BC92], </booktitle> <pages> pages 357-364. </pages> <note> Cited on pages 137 and 140. </note>
Reference-contexts: The above algorithms all fall into the class of incremental copying read-barrier techniques. Others have proposed copying-based algorithms that rely on a combination of a read-barrier and a write-barrier (extra instructions executed at every pointer store) [Bro84], or on a write-barrier only <ref> [NOPH92] </ref> to coordinate the collector's view of the graph with that of the application. 3 Nilsen gives no indication of the parameters used in timing this worst-case, so it is impossible to evaluate this pause. 137 4.2.3 Brooks' Technique Brooks' algorithm [Bro84] deserves special mention as the only copying hard real-time <p> Incremental copying collectors pose more severe coordination problems|the mutator must also be protected from changes made by the garbage collector. It may be enlightening to view these issues as a variety of coherence problems: having multiple processes attempt to share changing data, while maintaining some kind of consistent view <ref> [NOPH92] </ref>. (Readers unfamiliar with coherence problems in parallel systems should not worry too much about this terminology; the issues should become apparent as we go along.) An incremental mark-sweep traversal poses a multiple readers, single writer coherence problem|the collector's traversal must respond to changes, but only the mutator can change the
Reference: [NS90] <author> Kelvin Nilsen and William J. Schmidt. </author> <title> A high-level overview of hardware assisted real-time garbage collection. </title> <type> Technical Report TR 90-18a, </type> <institution> Dept. of Computer Science, Iowa State University, Ames, Iowa, </institution> <year> 1990. </year> <note> Cited on page 137. </note>
Reference-contexts: Even if the necessary checks are performed by dedicated parallel hardware, most of the available CPU time may be used up (in the worst case) by trapping to copying routines and performing the copying operations. 4.2.2 Nilsen's Hardware Assisted Technique Nilsen and Schmidt <ref> [NS90] </ref> argue that even if increments of garbage collection work are small, a real-time program may miss its deadlines if too many small increments add up to too much total overhead over some period of time relevant to a deadline. <p> Nilsen's proposed solution to this problem is to build special hardware that guarantees that the worst-case delay for any individual program operation is small relative to that operation's normal execution time <ref> [NS90] </ref>. Unfortunately, he gives no indication of what that worst-case delay is for his hardware, except to admit that the worst-case for a pointer dereference is 2 microseconds. 3 On a 100 MIPS machine, this would be a slowdown of 200 times.
Reference: [Nut87] <author> Peter R. Nuth. </author> <title> Communication patterns in a symbolic multiprocessor. </title> <type> Technical Report MIT/LCS/TR-395, </type> <institution> Massachusetts Institute of Technology Laboratory for Computer Science, Cambridge, Massachusetts, </institution> <month> June </month> <year> 1987. </year> <note> Cited on page 4. 319 </note>
Reference-contexts: They have made these programs, many of which we used, available by anonymous ftp. We will do the same with the additional programs we used. 2 While there has been some work on the locality of reference of memory allocators that can move memory (such as garbage collectors) <ref> [WLM90, WLM92, Zor91, PS89, JLS92, Nut87, Ber88] </ref>, [GZH93] was the only paper on the topic of locality and non-moving memory allocation that we were able to locate.
Reference: [OOP91] <institution> OOPSLA '91 Workshop on Garbage Collection in Object-Oriented Systems, </institution> <note> Octo--ber 1991. available at ftp://ftp.cs.utexas.edu/pub/garbage/GC91. Cited on pages 316, 317, and 322. </note>
Reference: [PH86] <author> Ivor P. Page and Jeff Hagins. </author> <title> Improving the performance of buddy systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-35(5):441-447, </volume> <month> May </month> <year> 1986. </year> <note> Cited on page 25. </note>
Reference-contexts: Double Buddy Double buddy <ref> [Wis78, PH86] </ref> uses a different technique to allow a closer spacing of size classes. It uses two different buddy systems, with staggered sizes. <p> if we had done the work immediately after the blocks were freed. 9 To our knowledge, the implementation we built for the present study may actually be the only double buddy system in existence, though Page wrote a simulator that is almost an entire implementation of a double buddy allocator <ref> [PH86] </ref>. 25 Quick Lists One way to separate free objects that have not been coalesced from those that have is to create a special list for these objects, and then search this list before looking for a chunk in the coalesced list. However, a list search can be quite expensive.
Reference: [PH96] <author> David A. Patterson and John L. Hennessy. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1996. </year> <title> 2nd Edition. </title> <booktitle> Cited on pages 4, </booktitle> <volume> 42, 98, 99, </volume> <booktitle> and 100. </booktitle>
Reference-contexts: An implication of locality is that we can predict with reasonable accuracy which instructions and data a program will use in the near future based on its accesses in the recent past <ref> [PH96] </ref>. There are two fundamental kinds of locality: spatial locality and temporal locality. Spatial locality is the property that data and instructions whose addresses are near one another tend to be referenced close together in time. <p> by as much as 4K times the number of size classes, which is roughly 4K fl ln (largest size smallest size), and 4K fl 2 fl ln (largest size smallest size) (one sixteenth of this value for our final numbers). 2.8.4 Our Use of Averages In this dissertation, we follow <ref> [FW86, PH96] </ref> when we present averages. If the numbers being averaged are simple numbers, such as the fragmentation of a program given a particular allocator, we use the arithmetic mean. <p> An implication of locality is that we can predict, with reasonable accuracy, which instructions and data a program will use in the near future based on its accesses in the recent past <ref> [PH96] </ref>. There are two fundamental kinds of locality: spatial locality and temporal locality. Spatial locality is the property that data and instructions whose addresses are near one another tend to be referenced close together in time. <p> Cache Memory A cache memory is a small, fast memory located close to the CPU that holds the most recently accessed code or data <ref> [PH96] </ref>. While there are many possible implementations of a cache, they all share some common properties: they hold a small subset of the total memory, they are very fast to access, and they attempt to exploit locality of reference. The design of a cache must answer four basic questions [PH96]: 1. <p> data <ref> [PH96] </ref>. While there are many possible implementations of a cache, they all share some common properties: they hold a small subset of the total memory, they are very fast to access, and they attempt to exploit locality of reference. The design of a cache must answer four basic questions [PH96]: 1. Where can a block be placed? 2. How is a block found if it is in the cache? 3. Which block should be replaced if a new block is brought into the cache? 4. <p> As a rule of thumb, a direct-mapped cache of size N has about the same miss rate as a 2-way set-associative cache of size N/2 <ref> [PH96] </ref>. Unfortunately, as set size increases, access time also increases. Thus, there is a fundamental tradeoff between the probability of a cache hit and the time it takes for that hit to occur. Most modern computers use a 4-way set-associative cache, with advanced designs moving towards 8-way set-associative caches.
Reference: [PLD91] <institution> Proceedings of the 1991 SIGPLAN Conference on Programming Language Design and Implementation, Toronto, </institution> <address> Ontario, </address> <month> June </month> <year> 1991. </year> <note> ACM Press. Published as SIG-PLAN Notices 26(6), June 1992. Cited on page 316. </note>
Reference: [PN77] <author> J. L. Peterson and T. A. Norman. </author> <title> Buddy systems. </title> <journal> Communications of the ACM, </journal> <volume> 20(6) </volume> <pages> 421-431, </pages> <month> June </month> <year> 1977. </year> <note> Cited on page 24. </note>
Reference-contexts: Finally, free regions of memory can be searched quickly by looking at several bits at a time and using a table to determine if that bit pattern could possibly hold an object of the desired size. 2.4.3 Buddy Systems Buddy systems <ref> [Kno65, PN77] </ref> are a variant of segregated lists, supporting a limited but efficient kind of splitting and coalescing. In the simple buddy schemes, the entire heap area is conceptually split into two large areas which are called buddies.
Reference: [PS89] <author> C.-J. Peng and Gurindar S. Sohi. </author> <title> Cache memory design considerations to support languages with dynamic heap allocation. </title> <type> Technical Report 860, </type> <institution> Computer Sciences Dept. University of Wisconsin, Madison, Wisconsin, </institution> <month> July </month> <year> 1989. </year> <note> Cited on page 4. </note>
Reference-contexts: They have made these programs, many of which we used, available by anonymous ftp. We will do the same with the additional programs we used. 2 While there has been some work on the locality of reference of memory allocators that can move memory (such as garbage collectors) <ref> [WLM90, WLM92, Zor91, PS89, JLS92, Nut87, Ber88] </ref>, [GZH93] was the only paper on the topic of locality and non-moving memory allocation that we were able to locate.
Reference: [PSC71] <author> P. W. Purdom, S. M. Stigler, and Tat-Ong Cheam. </author> <title> Statistical investigation of three storage allocation algorithms. </title> <journal> BIT, </journal> <volume> 11 </volume> <pages> 187-195, </pages> <year> 1971. </year> <note> Cited on page 29. </note>
Reference-contexts: At the time of this writing, the most recent version is 2.6.4, which we did not study. * Lea 2.5.1: a "segregated storage" algorithm in the (rather misleading) sense of Purdom, Stigler, and Cheam <ref> [PSC71] </ref>. Actual storage is not segregated, and one-word header and footer fields support boundary-tag coalescing. A set of free lists is maintained, "segregating" (indexing) free objects by approximate size to speed up searches.
Reference: [RK68] <author> Brian Randell and C. J. Kuehner. </author> <title> Dynamic storage allocation systems. </title> <journal> Communications of the ACM, </journal> <volume> 12(7) </volume> <pages> 297-306, </pages> <month> May </month> <year> 1968. </year> <note> Cited on page 2. </note>
Reference-contexts: Fragmentation is said to be present when sufficient free memory is available, but is unusable because it exists as many small fragments of memory rather than as one large block. Traditionally, fragmentation is classified as external or internal <ref> [RK68] </ref>, and is combatted by splitting and coalescing free blocks. External fragmentation arises when free blocks of memory are available for allocation, but cannot be used to hold objects of the sizes actually requested by a program.
Reference: [Sha88] <author> Robert A. Shaw. </author> <title> Empirical Analysis of a Lisp System. </title> <type> PhD thesis, </type> <institution> Stanford University, Palo Alto, California, </institution> <month> February </month> <year> 1988. </year> <type> Technical Report CSL-TR-88-351, </type> <institution> Stanford University Computer Systems Laboratory. </institution> <note> Cited on page 8. </note>
Reference-contexts: In most programs in a variety of languages, most objects live a very short time, while a small percentage live much longer <ref> [LH83, Ung84, Sha88, Zor90, DeT90b, Hay91] </ref>.
Reference: [SKW92] <author> Vivek Singhal, Sheetal V. Kakkad, and Paul R. Wilson. </author> <title> Texas: an efficient, portable persistent store. </title> <editor> In Antonio Albano and Ron Morrison, editors, </editor> <booktitle> Fifth International Workshop on Persistent Object Systems, </booktitle> <pages> pages 11-33, </pages> <address> San Miniato, Italy, </address> <month> September </month> <year> 1992. </year> <note> Springer-Verlag. Cited on page 28. </note>
Reference-contexts: We have two implementations of this algorithm: * Simple Seg 2 N allocates objects in size classes that are powers of two (e.g., 16, 32, 64, etc., bytes). This allocator was originally written by Sheetal Kakkad for use in the Texas Persistent Store <ref> [SKW92] </ref>, but is very similar to the widely used and venerable BSD UNIX allocator written by Chris Kingsley and studied by Zorn and Grunwald [ZG94]. (However, Zorn and Grunwald incorrectly describe this allocator as a "buddy-based algorithm.") * Simple Seg 2 N & 3 fl 2 N is very similar to
Reference: [Smi82] <author> Alan J. Smith. </author> <title> Cache memories. </title> <journal> Computing Surveys, </journal> <volume> 14(3) </volume> <pages> 473-530, </pages> <month> September </month> <year> 1982. </year> <note> Cited on page 38. </note>
Reference-contexts: The idea of trace-driven memory simulation is not new. In his survey of cache memories, A. J. Smith <ref> [Smi82] </ref> gives examples of trace-driven memory system studies that date back to 1966. Trace-driven memory simulation typically consists of three stages: 1. Trace collection is the process of recording the exact sequence of memory references (instruction and data) of a program.
Reference: [Ss92] <author> Bjarne Stroustrup. </author> <title> The C++ Programming Language. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1992. </year> <note> Cited on pages 135 and 161. </note>
Reference-contexts: Strict bounds on individual garbage collection pauses are often used as the only criterion for real-time garbage 1 Information on RScheme is available from the RScheme web site http://www.rscheme.org. 2 We use the smart pointer idiom <ref> [Ss92] </ref> to provide the necessary support for garbage collection. 135 collection, but for practical applications, the requirements are often even stricter. A second requirement for real-time applications that has been almost universally overlooked in the real-time garbage collection literature is that the application must be able to make significant progress. <p> The user is free to set the number of bytes allocated per increment of collection as needed in order to meet the real-time bounds. 24 4.13 Interface to C++ Currently, our garbage collector uses a smart pointer interface to collect C++ programs <ref> [Ss92] </ref>.
Reference: [ST85] <author> Daniel Dominic Sleator and Robert Endre Tarjan. </author> <title> Self-adjusting binary search trees. </title> <journal> Journal of the ACM, </journal> <volume> 32(3), </volume> <year> 1985. </year> <note> Cited on page 102. </note>
Reference-contexts: The idea behind a hash-table is that subsequent references access 101 unrelated areas of the table to improve performance by reducing the chance of colli-sions. However, this same property reduces the spatial locality of the program. On the other hand, a splay-tree <ref> [ST85] </ref> attempts to increase performance by increasing temporal locality. The tree is reorganized after every access to move recently accessed objects nearer to the top of the tree. Thus, when recently accessed nodes are again accessed, fewer tree node traversals will be required.
Reference: [Sta80] <author> Thomas Standish. </author> <title> Data Structure Techniques. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massa-chusetts, </address> <year> 1980. </year> <note> Cited on pages 18, 22, and 95. 320 </note>
Reference-contexts: Standish and Tadman showed how to efficiently implement best fit using two sets of free lists: an array of free lists of same-sized objects for small blocks, and a binary tree of free lists for larger blocks <ref> [Sta80, Tad78] </ref>. Unfortunately, this work seems to have gone unnoticed. These allocation policies can be implemented even more efficiently if deferred coalescing (Section 2.4.4) is used in addition to the techniques described above. To date, it has been unclear whether deferred coalescing would affect fragmentation. <p> In summary, by using good, scalable data structures such as those described in [Ste83] or <ref> [Sta80, Tad78] </ref>, memory allocators with very low fragmentation need not be slow. <p> The three that we mentioned above as implementation choices (FIFO, LIFO, and address ordered) are also policy choices. What is important is that each of these policies has several different possible implementations. For example, best fit can be implemented using a tree of lists of same sized objects <ref> [Sta80] </ref>, and first fit address ordered can be implemented using a Cartesian tree [Ste83]. For concreteness and simplicity, we describe the well-known implementations of sequential-fit algorithms, but we stress that the same policies can be implemented more efficiently. <p> In addition, very good implementations of the best policies are already known. For example, best fit can be implemented using a tree of lists of same-sized objects <ref> [Sta80] </ref>, and first fit address ordered can be implemented using a Cartesian tree [Ste83]. Most importantly, an excellent allocator implementation that runs on many platforms was written by Douglas Lea and is freely available [Lea].
Reference: [Ste75] <author> Guy L. Steele Jr. </author> <title> Multiprocessing compactifying garbage collection. </title> <journal> Communica--tions of the ACM, </journal> <volume> 18(9) </volume> <pages> 495-508, </pages> <month> September </month> <year> 1975. </year> <note> Cited on page 147. </note>
Reference-contexts: When such a pointer 146 is created, the collector is notified so that it can either trace the pointed-to object immediately, or re-examine the location in which the pointer was stored again later to find any "hidden" objects <ref> [Ste75, DLM + 78, BDS91] </ref>. For example, in Figure 4.2 step 2, when the pointer from object A to object E is created, a pointer to this pointer is recorded, and object E would be traversed when this pointer is re-examined.
Reference: [Ste83] <author> C. J. Stephenson. </author> <title> Fast fits: New methods for dynamic storage allocation. </title> <booktitle> In Proceedings of the Ninth Symposium on Operating Systems Principles, </booktitle> <pages> pages 30-32, </pages> <address> Bretton Woods, New Hampshire, </address> <month> October </month> <year> 1983. </year> <note> ACM Press. Published as Operating Systems Review 17(5), October 1983. Cited on pages 18, 22, 27, and 95. </note>
Reference-contexts: As we will show in Section 2.9, best fit and first fit address ordered are among the best allocation policies in terms of fragmentation. Stephenson described how to efficiently implement first fit address ordered using a cartesian tree 6 <ref> [Ste83] </ref>. Standish and Tadman showed how to efficiently implement best fit using two sets of free lists: an array of free lists of same-sized objects for small blocks, and a binary tree of free lists for larger blocks [Sta80, Tad78]. Unfortunately, this work seems to have gone unnoticed. <p> In summary, by using good, scalable data structures such as those described in <ref> [Ste83] </ref> or [Sta80, Tad78], memory allocators with very low fragmentation need not be slow. <p> What is important is that each of these policies has several different possible implementations. For example, best fit can be implemented using a tree of lists of same sized objects [Sta80], and first fit address ordered can be implemented using a Cartesian tree <ref> [Ste83] </ref>. For concreteness and simplicity, we describe the well-known implementations of sequential-fit algorithms, but we stress that the same policies can be implemented more efficiently. <p> Since such blocks are allocated whenever heap memory grows, consistent mistakes could be disastrous [KV85]. Thus, there is the very important question of how to treat a virgin block of significant size, to minimize fragmentation. (This block is sometimes called the "wilderness" <ref> [Ste83] </ref> to signify that it is as yet unspoiled.) Consider what happens if a first-fit or next-fit policy is being used, and the wilderness block is placed at the beginning of the free list. <p> In addition, very good implementations of the best policies are already known. For example, best fit can be implemented using a tree of lists of same-sized objects [Sta80], and first fit address ordered can be implemented using a Cartesian tree <ref> [Ste83] </ref>. Most importantly, an excellent allocator implementation that runs on many platforms was written by Douglas Lea and is freely available [Lea]. This allocator was improved partly due to the results in our original survey [WJNB95], and is now a very close approximation of best fit.
Reference: [Tad78] <author> M. Tadman. Fast-fit: </author> <title> A new hierarchical dynamic storage allocation technique. </title> <type> Master's thesis, </type> <institution> UC Irvine, Computer Science Dept., </institution> <year> 1978. </year> <note> Cited on page 18. </note>
Reference-contexts: Standish and Tadman showed how to efficiently implement best fit using two sets of free lists: an array of free lists of same-sized objects for small blocks, and a binary tree of free lists for larger blocks <ref> [Sta80, Tad78] </ref>. Unfortunately, this work seems to have gone unnoticed. These allocation policies can be implemented even more efficiently if deferred coalescing (Section 2.4.4) is used in addition to the techniques described above. To date, it has been unclear whether deferred coalescing would affect fragmentation. <p> In summary, by using good, scalable data structures such as those described in [Ste83] or <ref> [Sta80, Tad78] </ref>, memory allocators with very low fragmentation need not be slow.
Reference: [Tec97] <institution> Solid State Technology. </institution> <month> W.s.t.s.: </month> <title> Chip sales back on track, good 4th quarter will usher in 1997 growth, </title> <note> 1997. available at http://www.solid-state.com/sst/ Newsitems/9612/news01.html. Cited on page 11. </note>
Reference-contexts: By 1999, this number is expected to increase to $56.3 billion <ref> [Tec97] </ref>. If just 20% of this memory is used for heap allocated data, and 20% of that memory is unnecessarily wasted, then over $1.5 billion of the memory sold in 1996 was wasted. This is expected to grow to $2.25 billion by 1999. 11 improve upon the default implementation.
Reference: [UM97] <author> Richard A. Uhlig and Trevor N. Mudge. </author> <title> Trace-driven memory simulation: A survey. </title> <journal> Computing Surveys, </journal> <volume> 29(2) </volume> <pages> 128-170, </pages> <month> June </month> <year> 1997. </year> <note> Cited on page 38. </note>
Reference-contexts: The input, adj.perl, formatted the contents of a dictionary into filled paragraphs. Hand-optimized memory allocation was removed by Zorn [Zor93]. 2.7 Trace-Driven Memory Simulation Trace-driven memory simulation <ref> [UM97] </ref> is the process of capturing a trace of the events of interest (instructions, loads, and stores, or allocation and deallocation requests) of actual programs running on actual hardware, and then using these traces to simulate and study different computer designs. The idea of trace-driven memory simulation is not new.
Reference: [Ung84] <author> David M. Ungar. </author> <title> Generation scavenging: A non-disruptive high-performance storage reclamation algorithm. </title> <booktitle> In ACM SIGSOFT/SIGPLAN Software Engineering Symposium on Practical Software Development Environments, </booktitle> <pages> pages 157-167. </pages> <publisher> ACM Press, </publisher> <month> April </month> <year> 1984. </year> <note> Published as ACM SIGPLAN Notices 19(5), May, 1987. Cited on pages 8, 9, and 162. </note>
Reference-contexts: In most programs in a variety of languages, most objects live a very short time, while a small percentage live much longer <ref> [LH83, Ung84, Sha88, Zor90, DeT90b, Hay91] </ref>. <p> Areas containing younger objects are collected quite frequently, because most objects there will generally die quickly, freeing up space; processing the few that survive does not cost much. These survivors are advanced to older status after a few collections, to keep processing costs down. <ref> [LH83, Moo84, Ung84, Wil92] </ref>. For stop-and-collect garbage collection, generational garbage collection has the additional benefit that most collections take only a short time (collecting just the youngest generation is much faster than a full garbage collection). <p> This reduces the frequency of disruptive pauses, and for many programs without real-time deadlines, this is sufficient for acceptable interactive use. The majority of pauses are so brief (a fraction of a second) that they are unlikely to be noticed by users <ref> [Ung84] </ref>; the longer pauses for multi-generation collections can often be postponed until the system is not in use, or hidden within non-interactive compute-bound phases of program operation [WM89]. Generational techniques are often used as an acceptable substitute for more expensive incremental techniques, as well as to improve overall efficiency. <p> The minority of objects that survive for a longer period are made exempt from most garbage collection cycles so that they may have more time to die before again being considered for garbage collection <ref> [LH83, Moo84, Ung84, Wil92] </ref>. Because generational techniques rely on a heuristic|the guess that most objects will die young and that older objects will not die soon|they are not strictly reliable, and may degrade collector performance in the worst case. Therefore, for purely hard real-time systems, they may not be attractive.
Reference: [Vo95] <author> Kiem-Phong Vo. </author> <title> Vmalloc: A general and efficient memory allocator. </title> <journal> Software Practice and Experience, </journal> <note> 1995. To appear. Cited on page 4. </note>
Reference-contexts: Surprisingly, researchers have virtually ignored one of the most important effects on a program's locality of reference: that of the dynamic memory allocator's placement choices. 2 1 The studies by Zorn [DDZ93, ZG92] and by Vo <ref> [Vo95] </ref> were the only work we found that used actual programs in their studies. They have made these programs, many of which we used, available by anonymous ftp.
Reference: [Vui80] <author> Jean Vuillemin. </author> <title> A unifying look at data structures. </title> <journal> Communications of the ACM, </journal> <volume> 29(4) </volume> <pages> 229-239, </pages> <month> April </month> <year> 1980. </year> <note> Cited on page 18. </note>
Reference-contexts: In addition, by using deferred coalescing, the usual case can be optimized to be very fast with 6 Cartesian trees were first described in <ref> [Vui80] </ref>. 18 very little increase in fragmentation. 2.3 A Sound Methodology for Studying Fragmentation The traditional view has been that the program behavior responsible for fragmentation is determined only by the distributions of object sizes and lifetimes.
Reference: [Wan89] <author> Thomas Wang. </author> <title> MM garbage collector for C++. </title> <type> Master's thesis, </type> <institution> California Polytechnic State University, </institution> <address> San Luis Obispo, California, </address> <month> October </month> <year> 1989. </year> <note> Cited on pages 6, 10, and 147. </note>
Reference-contexts: The garbage objects are never examined, and their space is implicitly reclaimed. While at first these two methods of reclaiming garbage memory may seem fundamentally different, there is a way to combine them to receive many of the advantages of both <ref> [Wan89, Bak91] </ref>. This "fake copying" approach is fundamental to our real-time garbage collector implementation. 1.4.1 Real-Time Garbage Collection Real-time programs are usually characterized as being either hard real-time or soft real-time. Hard real-time programs are programs with very strict bounds on the running times of program operations. <p> In Section 4.8.1 we explain a technique known as "fake copying" <ref> [Wan89] </ref> (also known as "implicit reclamation" [Bak91]) which avoids the cost of a sweep phase. 10 Chapter 2 Memory Allocation Studies An important part of our research involved studying the "fragmentation problem." In this chapter, we present our results. <p> be noted that the test for an incremental update write-barrier can be sped up considerably, at the cost of increased conservatism, by always assuming that any pointer store will violate the write-barrier and optimistically shading the R-value without checking the color of the L-value. 4.6 Non-Copying Incremental Read-Barrier Techniques Wang <ref> [Wan89] </ref> and Baker [Bak91] independently presented a critical insight that can be used to make a mark-sweep collector have many of the advantages of a copying collector. Their insight was that in a copying collector, the "spaces" of the collector are really just a particular implementation of sets.
Reference: [Wil] <author> Paul R. Wilson. </author> <title> Garbage collection. </title> <note> Expanded version of [Wil92]. In revision for ACM Computing Surveys. Draft available at http://www.cs.utexas.edu/users/ oops. Cited on page 136. </note>
Reference-contexts: For a more extensive survey of this and other work on garbage collection, see <ref> [Wil] </ref>. 4.2.1 Baker's Incremental Copying Technique Baker's incremental copying technique [Bak78] is the best-known "real-time" collection strategy, but it is actually poorly suited to real-time garbage collection on stock hardware: its close coupling between application program actions and collector actions makes it intrinsically more expensive and difficult to use for real-time
Reference: [Wil88] <author> Paul R. Wilson. </author> <title> Opportunistic garbage collection. </title> <journal> SIGPLAN Notices, </journal> <volume> 23(12) </volume> <pages> 98-102, </pages> <month> December </month> <year> 1988. </year> <note> Cited on page 164. </note>
Reference-contexts: all pointers from older generations into younger ones also to be roots. 28 While it is not clear how many generations a collector should have, two generations appear to give good results because it gives many of the advantages of generational collection without too many repeated traversals of the objects <ref> [Wil88] </ref>. 164 counter without the associated cost. Once an object reaches the oldest generation, it simply remains there until it dies or the program terminates. The second consideration in object advancement is what color to advance the object.
Reference: [Wil92] <author> Paul R. Wilson. </author> <title> Uniprocessor garbage collection techniques. </title> <booktitle> In Bekkers and Cohen [BC92], </booktitle> <pages> pages 1-42. </pages> <note> Cited on pages 9, 146, 162, and 321. </note>
Reference-contexts: Areas containing younger objects are collected quite frequently, because most objects there will generally die quickly, freeing up space; processing the few that survive does not cost much. These survivors are advanced to older status after a few collections, to keep processing costs down. <ref> [LH83, Moo84, Ung84, Wil92] </ref>. For stop-and-collect garbage collection, generational garbage collection has the additional benefit that most collections take only a short time (collecting just the youngest generation is much faster than a full garbage collection). <p> In addition, if a newly allocated object becomes garbage before the end of this collection cycle, it cannot be reclaimed before the end of the next garbage collection cycle. 4.5 Incremental Tracing Algorithms Two basic incremental tracing strategies are possible <ref> [Wil92] </ref>. One strategy is to ensure that objects can never get lost, by preventing any pointers from being destroyed [AP87, Yua90]. Before overwriting a pointer, the old pointer value is immediately traversed, or saved away so that the collector can still find it and trace it later. <p> The minority of objects that survive for a longer period are made exempt from most garbage collection cycles so that they may have more time to die before again being considered for garbage collection <ref> [LH83, Moo84, Ung84, Wil92] </ref>. Because generational techniques rely on a heuristic|the guess that most objects will die young and that older objects will not die soon|they are not strictly reliable, and may degrade collector performance in the worst case. Therefore, for purely hard real-time systems, they may not be attractive.
Reference: [Wis78] <author> David S. Wise. </author> <title> The double buddy-system. </title> <type> Technical Report 79, </type> <institution> Computer Science Department, Indiana University, Bloomington, Indiana, </institution> <month> December </month> <year> 1978. </year> <note> Cited on page 25. 321 </note>
Reference-contexts: Double Buddy Double buddy <ref> [Wis78, PH86] </ref> uses a different technique to allow a closer spacing of size classes. It uses two different buddy systems, with staggered sizes.
Reference: [Wit91] <author> P. T. Withington. </author> <title> How real is "real time" garbage collection? In OOPSLA '91 Workshop on Garbage Collection in Object-Oriented Systems [OOP91]. </title> <note> Position paper. Cited on page 136. </note>
Reference-contexts: This read-barrier cost is potentially high, and very unpredictable, because the cost of traversing an ordinary list is strongly dependent on whether or not the list has already been reached and copied by the collector <ref> [Nil88, EV91, Wit91] </ref>.
Reference: [WJ93] <author> Paul R. Wilson and Mark S. Johnstone. </author> <title> Truly real-time non-copying garbage collection. </title> <booktitle> In OOPSLA '93 Workshop on Memory Management and Garbage Collection, </booktitle> <month> December </month> <year> 1993. </year> <note> Expanded version of workshop position paper submitted for publication. Cited on page 162. </note>
Reference-contexts: The generational write-barrier essentially records very similar information to that of an incremental update write-barrier, so most of the overhead should be able to serve both purposes. 4.14.1 Discussion Generational collection can be combined with real-time techniques, but in the general case, the marriage is not a particularly happy one <ref> [WJ93] </ref>. Typically, generational techniques improve 25 Pointers may point to an element of an array or a substructure of a record.
Reference: [WJNB95] <author> Paul R. Wilson, Mark S. Johnstone, Michael Neely, and David Boles. </author> <title> Dynamic storage allocation: A survey and critical review. </title> <booktitle> In 1995 International Workshop on Memory Management, </booktitle> <address> Kinross, Scotland, UK, 1995. </address> <publisher> Springer Verlag LNCS. </publisher> <pages> Cited on pages 19, </pages> <note> 86, and 95. </note>
Reference-contexts: Recent experimental results show that this is false <ref> [ZG94, WJNB95] </ref>, because the ordering of requests has a large effect on fragmentation. <p> We believe that research on memory allocation should first focus on finding good policies. Once these policies are identified, it is relatively easy to develop good implementations. All of the measurements presented in this dissertation are for the 7 For a much more extensive discussion on these issues, see <ref> [WJNB95] </ref> 19 memory allocation policy under consideration, independent of any particular implementation of that policy. Unfortunately, many good policies are discounted because the obvious implementation is inefficient. <p> What all of this previous work ignores is that a randomly generated trace is not valid for predicting how well a particular allocator will perform on a real program. We published an extensive review of the relevant literature in <ref> [WJNB95] </ref>, and describe at length the traditional methodology and why it is unsound. The interested reader is encouraged to see this paper for more details. There are three basic reasons why randomly generated traces fail to represent real program traces. <p> Most importantly, an excellent allocator implementation that runs on many platforms was written by Douglas Lea and is freely available [Lea]. This allocator was improved partly due to the results in our original survey <ref> [WJNB95] </ref>, and is now a very close approximation of best fit.
Reference: [WLM90] <author> Paul R. Wilson, Michael S. Lam, and Thomas G. Moher. </author> <title> Caching consideration for generational garbage collection: A case for large and set-associative caches. </title> <type> Technical Report UIC-EECS-90-5, </type> <institution> University of Illinois at Chicago EECS Dept., Chicago, Illinois, </institution> <month> December </month> <year> 1990. </year> <note> Cited on page 4. </note>
Reference-contexts: They have made these programs, many of which we used, available by anonymous ftp. We will do the same with the additional programs we used. 2 While there has been some work on the locality of reference of memory allocators that can move memory (such as garbage collectors) <ref> [WLM90, WLM92, Zor91, PS89, JLS92, Nut87, Ber88] </ref>, [GZH93] was the only paper on the topic of locality and non-moving memory allocation that we were able to locate.
Reference: [WLM92] <author> Paul R. Wilson, Michael S. Lam, and Thomas G. Moher. </author> <title> Caching considerations for generational garbage collection. </title> <booktitle> In Conference Record of the 1992 ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pages 32-42, </pages> <address> San Francisco, California, </address> <month> June </month> <year> 1992. </year> <note> ACM Press. Cited on page 4. </note>
Reference-contexts: They have made these programs, many of which we used, available by anonymous ftp. We will do the same with the additional programs we used. 2 While there has been some work on the locality of reference of memory allocators that can move memory (such as garbage collectors) <ref> [WLM90, WLM92, Zor91, PS89, JLS92, Nut87, Ber88] </ref>, [GZH93] was the only paper on the topic of locality and non-moving memory allocation that we were able to locate.
Reference: [WM89] <author> Paul R. Wilson and Thomas G. Moher. </author> <title> Design of the Opportunistic Garbage Collector. </title> <booktitle> In Conference on Object Oriented Programming Systems, Languages and Applications (OOPSLA '89) Proceedings, </booktitle> <pages> pages 23-35, </pages> <address> New Orleans, Louisiana, </address> <year> 1989. </year> <note> ACM Press. Cited on page 9. </note>
Reference-contexts: The majority of pauses are so brief (a fraction of a second) that they are unlikely to be noticed by users [Ung84]; the longer pauses for multi-generation collections can often be postponed until the system is not in use, or hidden within non-interactive compute-bound phases of program operation <ref> [WM89] </ref>. Generational techniques are often used as an acceptable substitute for more expensive incremental techniques, as well as to improve overall efficiency.
Reference: [Yua90] <author> Taichi Yuasa. </author> <title> Real-time garbage collection on general-purpose machines. </title> <journal> Journal of Systems and Software, </journal> <volume> 11 </volume> <pages> 181-198, </pages> <year> 1990. </year> <note> Cited on pages 144 and 146. </note>
Reference-contexts: The weak tri-color invariant: For all black objects in the graph which have a path to a white object, at least one path from that black object to that white object must contain at least one gray object <ref> [Yua90] </ref>. <p> One strategy is to ensure that objects can never get lost, by preventing any pointers from being destroyed <ref> [AP87, Yua90] </ref>. Before overwriting a pointer, the old pointer value is immediately traversed, or saved away so that the collector can still find it and trace it later. We call this a snapshot at beginning algorithm because the collector's view of reachable data structures is fixed when collection begins.
Reference: [ZG92] <author> Benjamin Zorn and Dirk Grunwald. </author> <title> Empirical measurements of six allocation-intensive C programs. </title> <type> Technical Report CU-CS-604-92, </type> <institution> University of Colorado at Boulder, Dept. of Computer Science, </institution> <month> July </month> <year> 1992. </year> <note> Cited on pages 4 and 35. </note>
Reference-contexts: Surprisingly, researchers have virtually ignored one of the most important effects on a program's locality of reference: that of the dynamic memory allocator's placement choices. 2 1 The studies by Zorn <ref> [DDZ93, ZG92] </ref> and by Vo [Vo95] were the only work we found that used actual programs in their studies. They have made these programs, many of which we used, available by anonymous ftp. <p> This biases our sample slightly toward potentially more problematic traces, which have more potential for fragmentation. Our suite does include one almost non-freeing program, LRUsim, which is the only non-freeing program we had that we were sure did not leak. 15 Two programs used by Zorn and Grunwald <ref> [ZG92] </ref> and by Detlefs, Dosser, and Zorn [DDZ93], which we did not use, have heaps that are quite small: Cfrac only uses 21.4 KB and Gawk only uses 41 KB, which are only a few pages on most modern machines.
Reference: [ZG94] <author> Benjamin Zorn and Dirk Grunwald. </author> <title> Evaluating models of memory allocation. </title> <journal> ACM Transactions on Modeling and Computer Simulation, </journal> <volume> 1(4) </volume> <pages> 107-131, </pages> <year> 1994. </year> <note> Cited on pages 19 and 28. </note>
Reference-contexts: Recent experimental results show that this is false <ref> [ZG94, WJNB95] </ref>, because the ordering of requests has a large effect on fragmentation. <p> This allocator was originally written by Sheetal Kakkad for use in the Texas Persistent Store [SKW92], but is very similar to the widely used and venerable BSD UNIX allocator written by Chris Kingsley and studied by Zorn and Grunwald <ref> [ZG94] </ref>. (However, Zorn and Grunwald incorrectly describe this allocator as a "buddy-based algorithm.") * Simple Seg 2 N & 3 fl 2 N is very similar to Simple Seg 2 N , but the size classes are closer together, to decrease internal fragmentation at a possible expense in external fragmentation.
Reference: [Zor90] <author> Benjamin Zorn. </author> <title> Comparing mark-and-sweep and stop-and-copy garbage collection. </title> <booktitle> In Conference Record of the 1990 ACM Symposium on LISP and Functional Programming, </booktitle> <pages> pages 87-98, </pages> <address> Nice, France, </address> <month> June </month> <year> 1990. </year> <note> ACM Press. Cited on page 8. </note>
Reference-contexts: In most programs in a variety of languages, most objects live a very short time, while a small percentage live much longer <ref> [LH83, Ung84, Sha88, Zor90, DeT90b, Hay91] </ref>.
Reference: [Zor91] <author> Benjamin Zorn. </author> <title> The effect of garbage collection on cache performance. </title> <type> Technical Report CU-CS-528-91, </type> <institution> University of Colorado at Boulder, Dept. of Computer Science, Boulder, Colorado, </institution> <month> May </month> <year> 1991. </year> <note> Cited on page 4. 322 </note>
Reference-contexts: They have made these programs, many of which we used, available by anonymous ftp. We will do the same with the additional programs we used. 2 While there has been some work on the locality of reference of memory allocators that can move memory (such as garbage collectors) <ref> [WLM90, WLM92, Zor91, PS89, JLS92, Nut87, Ber88] </ref>, [GZH93] was the only paper on the topic of locality and non-moving memory allocation that we were able to locate.
Reference: [Zor93] <author> Benjamin Zorn. </author> <title> The measured cost of conservative garbage collection. </title> <journal> Software| Practice and Experience, </journal> <volume> 23(7) </volume> <pages> 733-756, </pages> <month> July </month> <year> 1993. </year> <note> Cited on pages 37 and 38. 323 </note>
Reference-contexts: () calls. 20 The input data for the compilation was the the largest source file of the compiler itself (combine.c). 21 * Ghost is Ghostscript, a widely-used portable interpreter for the Postscript (page rendering) language, written by Peter Deutsch and modified by Zorn, et al., to remove hand-optimized memory allocation <ref> [Zor93] </ref>. The input was manual.ps, the largest of the standard inputs available from Zorn's ftp site. <p> Some support for this idea comes from <ref> [Zor93] </ref>, which showed that hand optimizations usually do little good compared to choosing the right allocator. 21 Because of the way the GNU C compiler is distributed, this is a very common workload| people frequently down-load a new version of the compiler, compile it with an old version, then recompile it <p> The input, adj.perl, formatted the contents of a dictionary into filled paragraphs. Hand-optimized memory allocation was removed by Zorn <ref> [Zor93] </ref>. 2.7 Trace-Driven Memory Simulation Trace-driven memory simulation [UM97] is the process of capturing a trace of the events of interest (instructions, loads, and stores, or allocation and deallocation requests) of actual programs running on actual hardware, and then using these traces to simulate and study different computer designs.
References-found: 85

