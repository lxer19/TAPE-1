URL: ftp://ftp.sics.se/pub/SICS-reports/Reports/SICS-T--97-03--SE.ps.Z
Refering-URL: http://www.sics.se/libindex.html
Root-URL: 
Title: Exploratory Study of IR Interaction for User Interface Design.  
Author: Preben Hansen 
Keyword: Information retrieval, interaction, user-oriented evaluation, information seeking strategies, cognition, interaction processes, user interface design  
Address: Box 1263, SE 164 28, Kista, Sweden  
Affiliation: Institute of Computer Science  
Date: November 1997  
Note: An  preben@sics.se Swedish  
Abstract: SICS Technical Report ISRN:SICS-T--97/03-SE T97:03 ISSN: 1100-3154 Abstract The thesis describe an exploratory and experimental evaluation of the user interface of the Dienst system, a WWW-based IR system implemented in a real-world online WWW setting. The study deals with two tasks: one evaluation task and one methodological task. Concerning the evaluation we investigate if the current user interface to the Dienst WWW-based IR system provide sufficient support in order to conduct an information seeking task. We identify and describe characteristics of the user population. We also make suggestions for supporting user characteristics and needs in the user interface redesign The methods are based on an interdisciplinary approach which combines both the IR interaction perspective and the user-centered design methods in HCI. The study implemented in an experimental real-world online WWW setting. We collect and analyze cognitive and statistical data from users performing an information seeking task using a combination of both qualitative (questionnaires) and quantitative (transaction logs) data collection methods. Finally, based on our findings, we suggest important factors to be considered and supported in the user interface design. Also published : Poster presentation at the SIGIR 97 Conference, 27-31 July, Washington, USA. In : N. Belkin, A. D. Narasimhalu, and Peter Willett (eds.). Proceedings of the 20th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. 27-31 July, 1997, Philadelphia, Pennsylvania, USA. p.135. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ahlberg, C. </author> <year> (1996), </year> <title> Dynamic queries. </title> <type> Doctoral dissertation. </type> <institution> Department of Computing Science, Chalmers University of Technology, Gteborg, Sweden: Gteborg University. </institution>
Reference-contexts: It should be noted that the results and the following conclusions mainly concerns computer science domain, but the implications drawn could represent important factors to be considered for IR design in general. The evaluation: For the evaluation methodology purpose, we could use a visualizing tool, such as Spotfire <ref> (Ahlberg, 1996) </ref>, to automatically gather, process and monitor transaction log data and visually display the results. This could be done on both an individual level and on a general level using different time parameters.
Reference: <author> Allen, B. </author> <year> (1996a), </year> <title> Information tasks. Towards a user-centered approach to information systems. </title> <publisher> San Diego : Academic Press. </publisher>
Reference-contexts: Furthermore, he characterizes the information system as components that are linked to each other, defining the collective purpose and function of the system <ref> (Allen, 1996a, p. 4) </ref>. A general and traditional model of the information retrieval process involve components such as representation, storage, searching, finding, and presentation of potential information, desired by the information seeker (Ingwersen, 1992, p. 49 and Meadow, 1992, p. 2). <p> To accomplish our task of investigating the user activities and linking them to the user interface design, we will follow a model and a framework (Table 2) proposed by Allen (1996a, p. 24) which is slightly modified 15 : Table 2. Model for user-centered IR interaction and interface design <ref> (based on a model by Allen, 1996a, p.24) </ref> COMPONENT METHOD TASK Resource Analysis (chapter 3) Description of information system functionality Describe resource (s) that are used to complete the tasks. User Needs Analysis (section 5.1 to 5.4) 1.
Reference: <author> Allen, B. </author> <year> (1996b), </year> <title> From research to design: A user-centered approach. </title> <editor> In: Ingwersen, P. and Pors, N. O. (eds.). </editor> <booktitle> CoLIS 2. Second International Conference on Conceptions of Library and Information Science: Integration in Perspective, </booktitle> <address> Copenhagen, Denmark. </address> <month> October 13-16, </month> <year> 1996. </year> <pages> pp. 45-59. </pages> <institution> Copehagen : The Royal School of Librarianship. </institution> <year> 1996. </year>
Reference: <author> Allen, B. </author> <year> (1994), </year> <title> Cognitive abilities and information system usability. </title> <booktitle> Information Processing & Management, 1994, </booktitle> <volume> Vol. 30 (2), </volume> <pages> pp. 177-191. </pages>
Reference-contexts: In order to understand these, we need to examine factors such as: how users interact with IR systems; how to design user interfaces for IR systems; different information seeking strategies and behaviours (Belkin et. al. 1995); the users tasks and goals, individual differences (Borgman, 1989), cognitive abilities <ref> (Allen, 1994) </ref>, and how to enhance users' navigation in the information space (Benyon and Hk, 1997). We are constantly involved in various interactions with the environment through different communication mechanisms and processes. Information seeking is such a process, where users in different ways interact with the information environment.
Reference: <author> Babbie, E. </author> <year> (1983), </year> <title> The practice of social research. Belmont, </title> <publisher> CA : Wadsworth Publ. </publisher>
Reference-contexts: Generally, the Likert scale offer five response categories ranging from negative to positive responses, with a category of undecided as the middle score or as a separate score <ref> (Babbie, 1983, pp. 380-381) </ref>. In our study we use the undecided score as the middle (point 3) score. 17 4. 2 WWW-based evaluation Information retrieval systems, techniques and tools have been evaluated for a long time. The evaluation has mainly focused on effectiveness measured through precision and recall.
Reference: <author> Belkin, N. J., C. Cool, A. Stein and U. Thiel. </author> <year> (1995), </year> <title> Cases, scripts, and information seeking strategies: On the design of interactive information retrieval systems. Expert Systems With Applications, </title> <booktitle> 1995, </booktitle> <volume> Vol. 9 (3), </volume> <pages> pp. 379-396. </pages>
Reference-contexts: In order to understand these, we need to examine factors such as: how users interact with IR systems; how to design user interfaces for IR systems; different information seeking strategies and behaviours <ref> (Belkin et. al. 1995) </ref>; the users tasks and goals, individual differences (Borgman, 1989), cognitive abilities (Allen, 1994), and how to enhance users' navigation in the information space (Benyon and Hk, 1997). We are constantly involved in various interactions with the environment through different communication mechanisms and processes. <p> One central issue within IR research today is how systems and intermediary mechanisms should be designed to support interactive information seeking tasks. This includes knowledge of the end-users information seeking activities and design to support the users interaction with the system <ref> (Belkin et. al., 1995) </ref>. One of the goals within IR interaction research is then to improve the communication task between the participants in the IR environment. <p> In the episode model <ref> (Belkin et. al. 1995, p. 380) </ref>, the users interaction with the information system is the central process which should be understood as interaction, and then, especially as human-computer interaction. ...the information seeking behaviour is characterized by movement from one strategy to another within the course of a single information seeking episode, <p> al. 1995, p. 380), the users interaction with the information system is the central process which should be understood as interaction, and then, especially as human-computer interaction. ...the information seeking behaviour is characterized by movement from one strategy to another within the course of a single information seeking episode, ... <ref> (Belkin et. al., 1995, p. 381) </ref>. These interactions between the user and the different IR system components depend, according to Belkin, on the users characteristics, such as the users state of knowledge and tasks and goals. <p> Based on earlier studies, Belkin et. al. (1990, and further elaborated in Belkin et. al., 1995, pp. 380-381) proposed a model of information seeking behaviour consisting of four dimensions (Table 1), and a model of 16 information seeking strategies (ISSs). Table 1. Dimensions of information-seeking strategies. <ref> (Belkin et al. 1995, p. 380) </ref> Method of Interaction scanning &lt;--------------------------------&gt; searching Goal of Interaction learning &lt;-------------------------------&gt; selecting Mode of Retrieval recognition &lt;-------------------------------&gt; specification Resource Considered information &lt;-------------------------------&gt; meta-information According to Belkin, the user moves between these different strategies.
Reference: <author> Belkin, N., Marchetti, P and Cool, C. </author> <year> (1993), </year> <title> BRAQUE: Design of an interface to support user interaction in information retrieval. </title> <booktitle> Information Processing & management, </booktitle> <volume> Vol. 29, (3), </volume> <pages> pp. 325-344. </pages>
Reference: <author> Belkin, N., Chang, S-J., Downs, T., Saracevic, T., and Zhao, S. </author> <year> (1990), </year> <title> Taking account of user tasks, goals and behaviour for the design of online public access catalogs. </title> <editor> In: Henderson, D. (ed.). </editor> <booktitle> Proceedings of the 53rd ASIS Annual Meeting. </booktitle> <pages> pp. 69-79. </pages> <address> Medford, </address> <publisher> NJ : Learned Information. </publisher>
Reference-contexts: These interactions between the user and the different IR system components depend, according to Belkin, on the users characteristics, such as the users state of knowledge and tasks and goals. Based on earlier studies, Belkin et. al. <ref> (1990, and further elaborated in Belkin et. al., 1995, pp. 380-381) </ref> proposed a model of information seeking behaviour consisting of four dimensions (Table 1), and a model of 16 information seeking strategies (ISSs). Table 1.
Reference: <author> Belkin, N., </author> <year> (1980), </year> <title> Anomalous States of Knowledge as a Basis Information retrieval. </title> <journal> The Canadian Journal of Information Science. </journal> <volume> Vol. 5, </volume> <pages> pp. 133-143. </pages>
Reference-contexts: Belkin (1980) proposed a (theoretical) model where the information user is concerned with solving a problem. This model makes the assumption that the user has a problematic situation, which means that there exists some kind of need for information. Belkin calls this the user's Anomalous State of Knowledge (ASK) <ref> (Belkin, 1980, p. 135) </ref> The information seeking action then involves a process where the user must articulate a search request. An information need (or ASK) initiates a person to perform an information seeking task and thus activates information seeking behaviour and strategies.
Reference: <author> Benyon, D. and Hk, K. </author> <year> (1997), </year> <title> Navigation in information space: supporting the individual. </title> <publisher> Forthcoming. </publisher> <address> INTERACT'97. July, Australia. </address>
Reference-contexts: factors such as: how users interact with IR systems; how to design user interfaces for IR systems; different information seeking strategies and behaviours (Belkin et. al. 1995); the users tasks and goals, individual differences (Borgman, 1989), cognitive abilities (Allen, 1994), and how to enhance users' navigation in the information space <ref> (Benyon and Hk, 1997) </ref>. We are constantly involved in various interactions with the environment through different communication mechanisms and processes. Information seeking is such a process, where users in different ways interact with the information environment. <p> In our study we will view the concept of browsing and searching as a general term of how a user seeks information. Navigation has different meanings depending on discipline. At a general level, navigation could be understood as a conscious activity and way to seek information <ref> (Benyon and Hk, 1997) </ref>. Some suggested subcategories within the HCI area are social navigation, wayfinding and exploring. In the area of IR interaction, Peter Ingwersen talks about information needs and navigation at two levels.
Reference: <author> Borgman, C. </author> <year> (1989). </year> <title> All users of information retrieval systems are not created equal: an exploration into individual differences. </title> <booktitle> Information Processing & Management, </booktitle> <volume> Vol. 25 (3), </volume> <pages> pp. 237-252. </pages>
Reference-contexts: In order to understand these, we need to examine factors such as: how users interact with IR systems; how to design user interfaces for IR systems; different information seeking strategies and behaviours (Belkin et. al. 1995); the users tasks and goals, individual differences <ref> (Borgman, 1989) </ref>, cognitive abilities (Allen, 1994), and how to enhance users' navigation in the information space (Benyon and Hk, 1997). We are constantly involved in various interactions with the environment through different communication mechanisms and processes. <p> As we adopt a user-oriented and interdisciplinary approach to IR interaction and user interface design 2 we will combine theories and methodologies relevant to this study from both the information science field, especially within the areas of information retrieval interaction (Ingwersen, 1992, p. 12), information interaction, information seeking behaviour <ref> (Borgman, 1989) </ref>, and evaluation of information systems, and also from the computer science field with, in particular HCI research, i.e. user interface design, user-centered evaluation, task analysis (Norman, 1986; Diaper, 1989; and Nielsen, 1994). <p> Koenemann and Belkin, 1996; Brajnik, Mizarro and Tasso, 1996). It has been shown that there are individual differences when performing information seeking tasks within IR systems. Borgman (1989) reports that individual differences were found when investigating technical aptitudes and personality characteristics in relation to academic orientation <ref> (Borgman, 1989, pp. 242-248) </ref>. Furthermore, Borgman suggests that these individual characteristics have implications for both design and training of users of information systems (ibid, p. 248-249). 2.2.2 Browsing and searching strategies Browsing and searching strategies are two concepts that need to be further described.
Reference: <author> Brajnik, G., Mizzaro, S and Tasso, C. </author> <year> (1996), </year> <title> Evaluating user interfaces to information retrieval systems. A case study on user support. </title> <editor> In: Frei, H-P., Harman, D., Schuble, P., and Wilkinson, R. (eds.). </editor> <booktitle> Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'96). </booktitle> <address> Zurich, Switzerland. </address> <month> August 18-22, </month> <pages> pp. 128-136. </pages> <year> 1996. </year>
Reference-contexts: Support should be designed to provide the user with the necessary assistance in gaining her goal. A user interface to an information retrieval system can be described as a front-end program which interacts with the user and controls an underlying information retrieval system accessing information resources <ref> (Brajnik, Mizarro, and Tasso, 1996, p. 128) </ref>, which includes built in possibilities for communication, interaction and different functions and tools to support the user.
Reference: <author> Brusilovsky, P. </author> <year> (1996), </year> <title> Methods and techniques of adaptive hypermedia. </title> <booktitle> User modeling and user-adapted interaction, </booktitle> <volume> no. 6, </volume> <pages> pp. 87-129. </pages>
Reference-contexts: Recent studies have been focused on evaluation and design of adaptive user interfaces and hypermedia systems <ref> (e.g. Brusilovsky, 1996 and Hk, 1996b) </ref>. See section 2.4. Since information retrieval deal with human needs of information, we need to investigate users needs, expectations, knowledge, as well as the IR system itself (in our case the user interface). <p> This way the design of the IR interface (and system) could be adaptive <ref> (Brusilovsky, 1996) </ref> and support the users in their information seeking task. This knowledge represents the users thoughts and behaviour and reveals problematic situations that will have to be considered in an IR user interface design.
Reference: <author> Chang, S-J. L. </author> <year> (1995), </year> <title> Towards a multidimensional framework for understanding browsing. </title> <type> Doctoral Dissertation, Communication, </type> <institution> information and library studies, Rutgers University, USA. </institution>
Reference-contexts: Searching (or non-browsing), on the other hand, is indicative and exclusive. Evaluative means comparison and contrast among alternatives and thus supposes the inclusion of many alternatives not known beforehand for further examination. Indicative means seeking a definite target and thus the exclusion of other choices. <ref> (Chang, 1995, p. 201) </ref>. Chang suggests that browsing can serve as a search strategy. Marchionini (1995) talks about information seeking as the generic term and includes searching and browsing as two extremes on the same scale.
Reference: <author> Davis, J. R. and Lagoze, C. </author> <year> (1994), </year> <title> A protocol and server for a distributed digital technical report library. </title> <address> 25 April, </address> <year> 1994. </year> <institution> Cornell University TR-1418. </institution> <address> URL: http://cs-tr.cs.cornell.edu/Dienst/UI/2.0/Describe/ncstrl.cornell%2fTR94-1418?abstract= Diaper, D. </address> <year> (1989), </year> <title> Task observation for human-computer interaction. </title> <editor> In: Daiper, D. (ed.). </editor> <booktitle> Task analysis for human-computer interaction, </booktitle> <pages> pp. 210-237. </pages> <publisher> Chichester : Ellis Horwood. 46 Dillon, A. </publisher> <year> (1996), </year> <title> User analysis in HCI - the historical lessons from individual differences research. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> Vol. 45, </volume> <pages> pp. 619-637. </pages>
Reference-contexts: This will be done in section 5.6. 3. The Domain For our study purpose, we will use the Dienst database system, version 4.0. The Dienst system <ref> (Davis and Lagoze, 1994) </ref> was originally developed at Cornell University and Xerox Corporation in 1993 and further developed at Cornell University for the ARPA-funded Computer Science Technical Reports project in the USA, and now forms the basis of the Networked Computer Science Technical Report Library (NCSTRL) (Lagoze and Davis, 1995).
Reference: <author> Egan, D. </author> <year> (1988), </year> <title> Individual differences inhuman-computer interaction. </title> <editor> In: Helander, M. (ed.), </editor> <booktitle> Handbook of Human-Computer Interaction, </booktitle> <pages> pp. 541-568. </pages> <address> Amsterdam: </address> <publisher> North-Holland. </publisher>
Reference: <author> Ghiselli, E., Cambell, J. and Zedeck, S. </author> <year> (1981), </year> <title> Measurement theory for the behavioural sciences. </title> <address> San Francisco, </address> <publisher> CA : W. H. Freeman and Co. </publisher> <year> 1981. </year>
Reference-contexts: A method designed to scale subjects and which is used to gather individual differences in attitudes concerning an issue. The subject examines an item and respond accordingly to a scale generally from 1 to 5 or 7 <ref> (Ghiselli, Cambell and Zedeck 1981, p. 413) </ref>. Generally, the Likert scale offer five response categories ranging from negative to positive responses, with a category of undecided as the middle score or as a separate score (Babbie, 1983, pp. 380-381).
Reference: <author> Hansen, P. and Karlgren, J. </author> <year> (1996), </year> <title> Designing interactive IR combining adaption to user tasks and strategies with non-topic document analysis. First DELOS Workshop. An overview on projects and research activities in Digital Library related fields. </title> <institution> Sophia Antipolis, France, </institution> <month> 4-6 March, </month> <year> 1996. </year> <pages> pp. 23-26. </pages> <note> DELOS Working Group Reports: ERCIM-97-W0001. </note>
Reference-contexts: The users' information needs, knowledge, experience and goals may vary and influence the information seeking process, and need to be identified and supported in the user interface design <ref> (Hansen and Karlgren 1996, p. 23) </ref>. This situation presents a number of challenges in the field of information retrieval and Human-Computer Interaction (HCI) research.
Reference: <author> Harman, D. </author> <year> (1995), </year> <title> Overview of the second text retrieval conference. </title> <booktitle> (TREC-2). Information Processing & Management, </booktitle> <volume> Vol. 31 (3), </volume> <pages> 271-289. </pages>
Reference-contexts: Traditional IR experiments have been carried out for almost forty years such as the Cranfield and TREC <ref> (Harman, 1995) </ref> studies. Studies conducted by Robertson and Hancock-Beaulieu (1992) and Su (1992) investigate user behaviour, interaction and IR systems. Within HCI research, there has been extensive work within the usability 4 evaluation area.
Reference: <author> Harter, S. </author> <year> (1986), </year> <title> Online information retrieval. </title> <booktitle> Concepts, principles, and techniques. </booktitle> <address> Orlando: </address> <publisher> Academic Press. </publisher>
Reference-contexts: One of its goals is to support the user performing effective tasks. 5 2. 2 Information retrieval models. A general view of an information retrieval system is that the IR system consists of a device interposed between a potential user of information and the information collection itself <ref> (Harter, 1986, p. 2) </ref>.
Reference: <author> Henninger, S. and Belkin, N. </author> <year> (1996), </year> <title> Interface issues and interaction strategies for information retrieval systems. </title> <booktitle> Tutorial Notes. </booktitle> <pages> pp. 1-172. </pages> <booktitle> CHI96. Conference on Human Factors in Computing Systems, </booktitle> <address> Vancouver, British Colombia, Canada, </address> <month> 13-18 April, </month> <year> 1996. </year>
Reference: <author> Hewins, E. T. </author> <year> (1990), </year> <title> Information need and use studies. </title> <editor> In : Williams, M. E. (ed.). </editor> <booktitle> Annual review of information science and technology (ARIST), </booktitle> <volume> Vol. 25, </volume> <year> 1990. </year> <pages> pp. 145-172. </pages> <address> Amsterdam, The Netherlands, </address> <publisher> Elsevier : ASIS. </publisher>
Reference: <author> Hix, D. and Hartson, H. R. </author> <year> (1993), </year> <title> Developing user interfaces. Ensuring usability through product and process. </title> <publisher> New York : Wiley. </publisher>
Reference-contexts: This way it is possible to conduct several iterative 5 evaluation stages as it is being developed <ref> (Hix and Hartson, 1993) </ref>. <p> Generally this is achived through following a design-cycle containing prototype, evaluation, requirements, design and implementation. This cycle is then repeated several times. 10 design <ref> (Hix and Hartson, 1993, pp. 283-286) </ref>. In contrast, the summative evaluation, is done after a product, tool or service is ready for marketing and then an evaluation test is performed to measure the usability of that tool. Our study is influenced by this formative evaluation method approach. <p> The difference between them is that the interaction component deals with how a user interface works and its behaviour in response to what the user does while performing a task. The interface software deals mainly with the implementation of the code for the interaction component <ref> (Hix and Hartson, 1993, pp. 5-11) </ref>. For our study purpose, we will focus on the interaction component. There are different interaction styles to choose between when designing the interaction component. <p> There are different interaction styles to choose between when designing the interaction component. Interaction styles are described as a set of interface objects that provide different views on how the user can communicate with the system. Common interaction styles are typed-command languages, menus, windows, boxes, graphical interfaces <ref> (Hix and Hartson, 1993, pp. 58-59) </ref>. Many of these are used in, what is called, direct manipulation interfaces where the user directly performs the actions rather than indirectly (i.e. describing the actions to be performed in writing).
Reference: <author> Hk, K. </author> <year> (1996a), </year> <title> Moving the usability lab onto the web. </title> <note> URL: http://sics.se/humle/projects/www_evaluation.html Hk, </note> <author> K. </author> <year> (1996b), </year> <title> A glass box approach to adaptive hypermedia. </title> <type> Doctoral Dissertation. </type> <institution> Department of Computer and Systems Science. Stockholm University. SICS Dissertation Series 20. Stockholm : Stockholm Univeristy. </institution>
Reference-contexts: As we make information retrieval tools, like Dienst, available on the WWW, they can provide us with a good opportunity to get feedback concerning functionality, design and user behaviour <ref> (Hk, 1996a) </ref>. Using questionnaires and combining both quantitative and qualitative data collection methods created a large set of data that could be analyzed in many different ways.
Reference: <author> Ingwersen, P. </author> <year> (1996), </year> <title> Cognitive perspectives of information retrieval interaction: Elements of a cognitive IR theory. </title> <journal> Journal of Documentation, 1996, </journal> <volume> Vol. 52, (1), </volume> <pages> pp. 3-50. </pages>
Reference-contexts: As we could see in Figure 2, Ingwersen also recognizes different aspects that are involved in the IR interaction, which can be viewed as cognitive processes <ref> (Ingwersen, 1996, pp. 9-10) </ref>. 8 Belkin et al (1995) proposed a scheme for classifying information seeking strategies (ISS) according to a number of behavioural dimensions.
Reference: <author> Ingwersen, P. </author> <year> (1992), </year> <title> Information Retrieval Interaction. </title> <address> London, UK: </address> <publisher> Taylor Graham. </publisher>
Reference-contexts: As we adopt a user-oriented and interdisciplinary approach to IR interaction and user interface design 2 we will combine theories and methodologies relevant to this study from both the information science field, especially within the areas of information retrieval interaction <ref> (Ingwersen, 1992, p. 12) </ref>, information interaction, information seeking behaviour (Borgman, 1989), and evaluation of information systems, and also from the computer science field with, in particular HCI research, i.e. user interface design, user-centered evaluation, task analysis (Norman, 1986; Diaper, 1989; and Nielsen, 1994). <p> A general and traditional model of the information retrieval process involve components such as representation, storage, searching, finding, and presentation of potential information, desired by the information seeker <ref> (Ingwersen, 1992, p. 49 and Meadow, 1992, p. 2) </ref>. A simplified version of the traditional IR model can be seen in Figure 1 below. <p> These processes involve system characteristics (representational and retrieval techniques), the users situational characteristics and the functionalities of the intermediary. Ingwersen makes a very interesting point when he says that different cognitive (knowledge) structures are involved in the IR interaction and the information space <ref> (Ingwersen, 1992, p. 134-146) </ref>. Users do not only interact with systems, but also with texts and objects, indexing rules and the user interface.
Reference: <author> Ingwersen, P. and Borlund, P. </author> <year> (1996), </year> <title> Information transfer viewed as interactive cognitive processes. </title> <editor> In: Ingwersen, P. and Pors, N. O. (eds.) </editor> <booktitle> CoLIS 2. Second International Conference on Conceptions of Library and information Science: Integration in Perspective, </booktitle> <address> Copenhagen, Denmark. </address> <month> Oct. </month> <pages> 13-16, </pages> <year> 1996. </year> <pages> pp. 219-232. </pages> <institution> Copenhagen : The Royal School of Librarianship. </institution>
Reference-contexts: As we could see in Figure 2, Ingwersen also recognizes different aspects that are involved in the IR interaction, which can be viewed as cognitive processes <ref> (Ingwersen, 1996, pp. 9-10) </ref>. 8 Belkin et al (1995) proposed a scheme for classifying information seeking strategies (ISS) according to a number of behavioural dimensions.
Reference: <author> Ingwersen, P. and Willett, P. </author> <year> (1997). </year> <title> Algorithmic and cognitive approaches to information retrieval. An introduction. </title> <booktitle> Tutorial notes. SIGIR97. The 20th Annual international conference on Research and Development in Information Science. </booktitle>
Reference-contexts: theoretical model, called the episode model (see chapter 2.2.2) has been proposed by Belkin et al. (1995), and yet another one has recently been proposed by Saracevic (1996), suggesting a stratified model of IR interaction. take the form of transformations generated by a variety of different intentionalities and cognitive origins. <ref> (Ingwersen and Willett, 1997) </ref>. 7 2.2.1 Information retrieval process, behaviour and strategies When users want to find information, they consult an information knowledge resource, and initiate a communication process (Meadow, 1992, p. 2). <p> In variable and well-defined information needs to clarify, review or to explore information at a topical level, the user uses exploratory navigation which require dynamic interaction <ref> (Ingwersen and Willett, 1997) </ref>. Navigation will not be further examined in this study. 2. 3 Information retrieval evaluation Generally, one of the main tasks of evaluating IR systems is to obtain information about the satisfaction of the users task in a specific work environment.
Reference: <author> Jeffries, R., Miller, J., Wharton, C., and Uyeda, K. </author> <year> (1991), </year> <title> User interface evaluation in the real world. A comparison of four techniques. </title> <booktitle> Proceedings of the ACM CHI91, </booktitle> <address> New Orleans, LA, 27 April-2 May, </address> <year> 1991, </year> <pages> pp. 119-124. </pages>
Reference: <author> Koenemann, J. and Belkin, N. </author> <year> (1996), </year> <title> A case for interaction: A study of interactive information retrieval behaviour and effectiveness. </title> <editor> In: Tauber, M., Bellotti, V., Jeffries, R., Mackinlay, J. and Nielsen, J. (Eds.), </editor> <booktitle> Proceedings of CHI96 Human Factors in Computing Systems. </booktitle> <publisher> New York : ACM Press. </publisher> <pages> pp. 205-212. </pages> <address> 1996. 47 Kuhlthau, C. </address> <year> (1993), </year> <title> Seeking meaning. A process approach to library and information services. </title> <publisher> New York : Ablex publ. </publisher>
Reference-contexts: Saracevic and Kantor, 1988; Kuhlthau, 1993; Marchionini, 1995). Studies of the interface and system design (e.g. Belkin, Marchetti and Cool, 1993; Brajnik, Mizarro and Tasso, 1996) are also of pertinence. Recently, we have seen examples of interdisciplinary research within the information science and the computer science areas <ref> (Koenemann and Belkin, 1996) </ref>. <p> One task for the design of user interfaces would then be to cope with and to reflect the users tasks of seeking information and their behaviour through consideration of users knowledge and goals. Recent studies <ref> (Koenemann and Belkin, 1996) </ref> show that when the end-users are given more instructions and more control over their searches, this affects their satisfaction and performance in a positive way.
Reference: <author> Lagoze, C. and Davis, J. </author> <year> (1995), </year> <title> Dienst: An architecture for distributed document libraries. </title> <journal> Communications of the ACM, 1995, </journal> <volume> Vol. 38 (4), </volume> <editor> p. </editor> <volume> 47. </volume>
Reference-contexts: The Dienst system (Davis and Lagoze, 1994) was originally developed at Cornell University and Xerox Corporation in 1993 and further developed at Cornell University for the ARPA-funded Computer Science Technical Reports project in the USA, and now forms the basis of the Networked Computer Science Technical Report Library (NCSTRL) <ref> (Lagoze and Davis, 1995) </ref>. The first attempts to establish a comprehensive report archive or library were done in 1993, when the system called Unified Computer Science Technical Reports Index (UCSTRI) was set up.
Reference: <author> Losee, R. and Worley, K. </author> <year> (1993), </year> <title> Research and evaluation for information professionals. </title> <address> San Diego, </address> <publisher> CA : Academic Press. </publisher>
Reference-contexts: Answers to the questions were made on a 5-point Likert 16 scale, to be checked by the user. Furthermore, after each question, an open-ended question <ref> (Losee and Worley, 1993, pp. 133-134) </ref> field was offered. The questionnaires were set up in a non-controlled situation, i.e. the subjects were asked to participate and the questionnaires were made available online so that the subjects could do their search through the system at any time. <p> The answers were then sent (through a program) to the mailbox which was set up for this study, and a copy was sent to the subject as well. The questionnaires were first tested on a small group of subjects <ref> (Losee and Worley, 1993, p.134) </ref> and some changes to the question formulation were made. Written or open-ended data : In addition to every question within the questionnaires, there was a "comment"-field, where the subject could submit information to clarify or verify her statement on the 5-point Likert scale. <p> To perform the study, the subjects received an URL 18 to access the database. 17 Pearson correlation measures the strength of association between 2 variables <ref> (Losee and Worley, 1993) </ref> 18 Uniform Resource Locator is a standard way to specify the location of a resource available electronically on the Internet. 19 5. Results The method and research questions described in section 1.1 and chapter 4 were evaluated in a study during August-November 1996.
Reference: <author> Lwgren, J. </author> <year> (1993), </year> <title> Human-computer interaction. What every system developer should know. </title> <booktitle> Lund : Studentlitteratur. Marchionini, G (1995), Information seeking in electronic environments. Cambridge Series on Human Computer Interaction 9. </booktitle> <publisher> Cambridge : Cambridge University Press. </publisher>
Reference-contexts: Studies conducted by Robertson and Hancock-Beaulieu (1992) and Su (1992) investigate user behaviour, interaction and IR systems. Within HCI research, there has been extensive work within the usability 4 evaluation area. To begin with, we need to make a distinction between formative and summative evaluations <ref> (Lwgren, 1993, p. 52) </ref>, where the former evaluates the product, tool or service before and during the development of that tool. This way it is possible to conduct several iterative 5 evaluation stages as it is being developed (Hix and Hartson, 1993). <p> To do this, a set of usability guidelines are used. 7 Cognitive walkthrough is f several structured walktrough methods <ref> (Lwgren, 1993, p. 53) </ref>. Cognitive walkthrough is a theory-based method to perform usability evaluations of user interfaces and emphasize basic usability principles.
Reference: <author> Marchionini, G. </author> <year> (1992). </year> <title> Interface for end-user information seeking. </title> <journal> Journal of the American Society for Information Science, 1992, </journal> <volume> 43, (2), </volume> <pages> pp. 156-163. </pages>
Reference-contexts: In information retrieval interaction, the user interface is the primary mechanism and serves as a link or a communication channel <ref> (Marchionini, 1992, p. 156) </ref> between the user and the computer (system). Information systems are becoming increasingly accessible to end-users and there 6 Heuristic evaluation is a technique where a small group of experts (for example three to five) evaluate the design of a system.
Reference: <author> Marchionini, G. </author> <year> (1988), </year> <title> Finding facts vs. browsing knowledge in hypertext systems. </title> <journal> IEEE Computer, 1988, </journal> <volume> Vol. 21, (1), </volume> <pages> pp. 70-79. </pages>
Reference: <author> Meadow, C. </author> <year> (1992), </year> <title> Text information retrieval systems. </title> <publisher> San Diego : Academic Press. </publisher> <year> 1992. </year>
Reference-contexts: A general and traditional model of the information retrieval process involve components such as representation, storage, searching, finding, and presentation of potential information, desired by the information seeker <ref> (Ingwersen, 1992, p. 49 and Meadow, 1992, p. 2) </ref>. A simplified version of the traditional IR model can be seen in Figure 1 below. <p> a stratified model of IR interaction. take the form of transformations generated by a variety of different intentionalities and cognitive origins. (Ingwersen and Willett, 1997). 7 2.2.1 Information retrieval process, behaviour and strategies When users want to find information, they consult an information knowledge resource, and initiate a communication process <ref> (Meadow, 1992, p. 2) </ref>. In IR interaction an interactive communication process takes place between the different participants during an information retrieval activity.
Reference: <author> Nielsen, J. and Mack, R. </author> <year> (1994), </year> <title> Executive summary. </title> <editor> In: Nielsen, J. and Mack, R. (eds.). </editor> <title> Usability inspection methods. </title> <publisher> New York : John Wiley & Sons. </publisher>
Reference-contexts: Some of the characteristics that is investigated are ease of learning and subjective user satisfaction. Relevant issues include design procedures, design guidelines, and evaluation methods. Examples of methods to identify user interface problems are heuristic evaluation and Cognitive walkthrough <ref> (Nielsen and Mack, 1994, pp. 1-2) </ref>. 5 The basic idea is that the evaluation is done in several steps until satisfactory results are reached. Generally this is achived through following a design-cycle containing prototype, evaluation, requirements, design and implementation. <p> Usually, these evaluations and user tests are conducted within a highly controlled laboratory environment, where subjects are performing specific tasks and are observed using different techniques like Talk aloud or video-recording, etc. Some evaluation methods used within HCI are heuristic evaluations 6 <ref> (Nielsen and Mack, 1994) </ref> and cognitive walkthrough 7 (Wharton et. al., 1994) which can be described as expert methods (i.e. a set of experts on interface design).
Reference: <author> Norman, D. </author> <year> (1986), </year> <title> Cognitive engineering. </title> <editor> In: Norman, D. and Draper, S. (eds.) </editor> <year> (1986). </year> <title> User centered system design. </title> <booktitle> New perspectives on human-computer interaction. </booktitle> <pages> pp. 31-61. </pages> <editor> Hillsdale, N. J. </editor> : <publisher> Lawrence Erlbaum Ass. </publisher>
Reference-contexts: The system, however, presents its current state in physical terms. Goals and system state differ significantly in form and content, creating the Gulfs that need to be bridged if the system can be used <ref> (Norman, 1986, p. 38) </ref> It is important to investigate these differences in order to improve the design of the system and user interface. 2 Design of the medium through which the user and the system interact. <p> HCI as a research field includes, on a general level, user interface hardware and software, user and system modeling, cognitive and behavioural studies, human factors, empirical studies, different methods and techniques <ref> (some described in Norman, 1986 and Dillon, 1996) </ref>, and tools. Generally, the user interface can be divided in 2 parts: the development of interaction components and the development of interface software. <p> Many of these are used in, what is called, direct manipulation interfaces where the user directly performs the actions rather than indirectly (i.e. describing the actions to be performed in writing). Some of its research focus is evaluating and designing user interfaces by using different methods and techniques <ref> (Norman, 1986) </ref> and usability studies conducted and (described by Dillon, 1996).
Reference: <author> Robertson, S. E. and Hancock-Beaulieu, M. M. </author> <year> (1992), </year> <title> On evaluation of IR systems. </title> <booktitle> Information Processing and Management, </booktitle> <volume> Vol. 28, (4), </volume> <pages> pp. 457-466. </pages>
Reference: <author> Saracevic, T. </author> <year> (1996), </year> <title> Relevance reconcidered 96. </title> <editor> In: Ingwersen, P. and Pors, N. O. (eds.) </editor> <booktitle> CoLIS 2. Second International Conference on Conceptions of Library and information Science: Integration in Perspective, </booktitle> <address> Copenhagen, Denmark. </address> <month> Oct. </month> <pages> 13-16, </pages> <year> 1996. </year> <pages> pp. 201-218. </pages> <institution> Copenhagen, Denmark: The Royal School of Librarianship. </institution> <year> 1996. </year>
Reference: <author> Saracevic, T. </author> <year> (1995), </year> <title> Evaluation of evaluation in information retrieval. </title> <editor> In: Fox, E. A., </editor> <address> P. </address>
Reference: <editor> Ingwersen, and F. Fidel (eds.). </editor> <booktitle> Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'95). </booktitle> <address> Seattle, Washington, USA. </address> <month> July 9-13, </month> <year> 1995. </year> <pages> pp. 138-146. </pages> <address> New York: </address> <publisher> ACM. </publisher> <year> 1995. </year>
Reference: <author> Saracevic, T. and Kantor, P. </author> <year> (1988), </year> <title> A study of information seeking and retrieval. II. Users, questions and effectiveness. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> Vol. 39, (3), </volume> <pages> pp. 177-196. </pages>
Reference: <author> Shephard, A. </author> <year> (1989), </year> <title> Analysis and training in information technology tasks. </title> <editor> In : Diaper, D. (ed.), </editor> <title> Task analysis for human-computer interaction. </title> <publisher> Chichester : Ellis Horwood. </publisher>
Reference-contexts: HTA can be described as 12 a general form of task analysis, capable of dealing with cognitive as well as motor tasks, that embodies principles that are just as relevant to HCI tasks, especially with regards to aspects of training and supporting skills <ref> (Shephard, 1989, p. 16) </ref>. In this method, the aim is to describe the way (s) in which a goal may be achieved.
Reference: <author> Su, L. T. </author> <year> (1992). </year> <title> Evaluation measures for interactive information retrieval. </title> <booktitle> Information Processing & Management Vol. </booktitle> <volume> 28, (4), </volume> <pages> pp. 503-516. </pages>
Reference: <author> Sugar, W. </author> <year> (1995). </year> <title> User-centered perspective of information retrieval research and analysis methods. </title> <editor> In : Williams, M. E (ed.). </editor> <booktitle> Annual Review of Information Science and Technology (ARIST), </booktitle> <volume> Vol. 30, </volume> <year> 1995. </year> <pages> pp. 77-109. </pages> <address> Medford, N.J. : ASIS. </address> <year> 1995. </year>
Reference: <author> Tague-Sutcliffe, J. </author> <year> (1995), </year> <title> Measuring Information. An information services perspective. </title> <address> San Diego, </address> <publisher> CA : Academic Press. </publisher>
Reference: <author> Wharton, C. et. al. </author> <year> (1994), </year> <title> The cognitive walkthrough method: A practitioners guide. </title> <editor> In: Nielsen, J. and Mack, L. (eds.). </editor> <title> Usability inspection methods. </title> <booktitle> 1994. </booktitle> <pages> pp. </pages> <month> 105-140. </month> <title> New York : Wiley. 48 Appendice A : List of Tables and Figures. List of Tables TABLE 1. DIMENSIONS OF INFORMATION-SEEKING STRATEGIES. </title> <editor> (BELKIN ET AL. </editor> <year> 1995, </year> <title> P. 380) 8 TABLE 2. MODEL FOR USER-CENTERED IR INTERACTION AND INTERFACE DESIGN (BASED ON </title>
Reference-contexts: Some evaluation methods used within HCI are heuristic evaluations 6 (Nielsen and Mack, 1994) and cognitive walkthrough 7 <ref> (Wharton et. al., 1994) </ref> which can be described as expert methods (i.e. a set of experts on interface design). Task analysis (TA) is another method (see section 2.5), which builds on the assumption that the users interaction with a system is based on a set of goal (s).
References-found: 48

