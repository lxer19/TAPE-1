URL: ftp://www.cs.rutgers.edu/pub/technical-reports/lcsr-tr-272.ps.Z
Refering-URL: http://www.cs.rutgers.edu/pub/technical-reports/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: REDUCING RANDOMNESS IN COMPUTATION VIA EXPLICIT CONSTRUCTIONS  Written under the direction of  
Author: BY SHIYU ZHOU Professor Michael Saks 
Degree: A dissertation submitted to the Graduate School|New Brunswick  in partial fulfillment of the requirements for the degree of Doctor of Philosophy  and approved by  
Date: October, 1996  
Note: Graduate Program in Computer Science  
Address: New Jersey  Brunswick, New Jersey  
Affiliation: Rutgers, The State University of  New  
Abstract-found: 0
Intro-found: 1
Reference: [AH87] <author> L. Adelman and M. Huang. </author> <title> Recognizing primes in random polynomial time. </title> <booktitle> In Proc. of 19th ACM Symposium on Theory of Computing, </booktitle> <year> 1987. </year>
Reference-contexts: The use of randomization has played an important role in both complexity theory and algorithm design. Its apparent success in application has motivated a substantial effort to understand how much power randomness can provide over determinism. For many problems, a randomized algorithm is by far faster (e.g. primality testing <ref> [SS77, Rab80, AH87] </ref>), more parallel (e.g. perfect matching construction [KUW86, MVV87]), more space-efficient (e.g. undirected graph connectivity [AKLLR79]), or simpler (e.g. the min-cut problem [Kar93]) than any known deterministic algorithm.
Reference: [AKS87] <author> M. Ajtai, J. Komlos and E. Szemeredi. </author> <title> Deterministic Simulation of Logspace. </title> <booktitle> In Proc. of 19th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 132-140, </pages> <year> 1987. </year>
Reference-contexts: We refer the reader to [Nis96] for a survey on this method. With respect to polynomial time randomized computation, there are two fundamental approaches to derandomization: the method of conditional probabilities [ES73, Spe87, Rag88] and constructing small-sized sample spaces <ref> [KW84, Lub85, ABI86, AKS87, NN90] </ref>. <p> The most commonly used tools for constructing small-sized sample spaces are: k-wise independent hashing [CW79], sample spaces with limited independence [KW84, Lub85, ABI86], sample spaces with small bias [NN90], and expander graphs <ref> [AKS87] </ref>. Remark: Here we have assumed that the polynomial time randomized computation has one-side error, in which case, finding a good sample point is sufficient for deran-domization. <p> of proper complexity function is formally defined in [Pap94] and includes most "reasonable" functions, including polynomials, polylogarithmic functions, exponential funtions, etc. 12 performance of exact rather than approximate matrix computations, is not generalized by Theorem 2.1.1.) In recent years, despite considerable progress on deterministic simulations of small space randomized algorithms <ref> [AKS87, BNS89, Nis90, Nis92, NSW92, NZ93] </ref> there has been no general improvement on this space bound.
Reference: [AKLLR79] <author> R. Aleliunas, R. Karp, R. Lipton, L. Lovasz and C. Rackoff. </author> <title> Random walks, universal sequences and the complexity of maze problems. </title> <booktitle> In Proc. of 20th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 218-223, </pages> <year> 1979. </year>
Reference-contexts: For many problems, a randomized algorithm is by far faster (e.g. primality testing [SS77, Rab80, AH87]), more parallel (e.g. perfect matching construction [KUW86, MVV87]), more space-efficient (e.g. undirected graph connectivity <ref> [AKLLR79] </ref>), or simpler (e.g. the min-cut problem [Kar93]) than any known deterministic algorithm. In fact, there are many problems such as primality testing, perfect matching construction and undirected graph connectivity which (in certain respects) have very efficient randomized algorithms, but are not known to have corresponding deterministic counterparts. <p> Using Nisan's generator, Nisan, Szemeredi, Wigderson [NSW92] showed that undirected (s; t) connectivity, which is in RL <ref> [AKLLR79] </ref> and is complete for the complexity class SL [LP82], can be computed in DSP ACE (log 3=2 n). It was this result that motivated our research that we present in this work. As with these other results, Nisan's pseudorandom generator is a major component of our simulation.
Reference: [AO94] <author> E. Allender and M. Ogihara. </author> <title> Relationships among PL, #L, </title> <booktitle> and the de-termininant. Proc. of 9th Conference on Structure in Complexity Theory, </booktitle> <pages> pp. 267-279, </pages> <year> 1994. </year>
Reference-contexts: In fact, the weaker containment for R H SP ACE (S (n)) also follows from Savitch's theorem [Sav70] N SP ACE (S (n)) DSP ACE (S (n) 2 ). (Independently, Borodin, Cook and Pippenger [BCP83] and Jung [Jun81] (see also <ref> [AO94] </ref>) showed that the same DSP ACE (S (n) 2 ) bound can be achieved in Gill's [Gil77] stronger model of randomized space computation in which cyclic configuration transitions are allowed. This model, in particular, contains N SP ACE (S (n)).
Reference: [Alo86] <author> N. Alon. </author> <title> Explicit constructions of exponential sized families of k-independent sets. </title> <journal> Discrete Math, </journal> <volume> 58 </volume> <pages> 191-193, </pages> <year> 1986. </year>
Reference-contexts: Theorem 4.4.1 in particular gives a polynomial time construction of an (n; ( [n] universal set of size O (2 k k log n) for fixed k, which is optimal following the lower bound argument in [SB88]. Alon <ref> [Alo86] </ref> showed an explicit construction of (n; ( [n] k ))-universal sets of size log n2 O (k 2 ) for the case k is fixed. In [NN90] and [ABNNR92], nearly optimal constructions of size log n 2 O (k) were given.
Reference: [Alo91] <author> N. Alon. </author> <title> A parallel algorithm version of the Local Lemma. Random Structures and Algorithms, </title> <booktitle> 2(4) </booktitle> <pages> 367-378, </pages> <year> 1991. </year>
Reference-contexts: This approach has been widely used and proven effective in many applications (see e.g. <ref> [KW84, Lub85, ABI86, BR89, MNN89, NN90, Alo91, Sch92, KM93, KK94] </ref>). Along the line of this approach, the construction of k-wise independent sample spaces is one of the earliest studied problems.
Reference: [ABI86] <author> N. Alon, L. Babai and A. Itai. </author> <title> A fast and simple randomized parallel algorithm for the Maximal Independent Set Problem. </title> <journal> J. </journal> <volume> Algorithms 7 </volume> <pages> 567-583, </pages> <year> 1986. </year>
Reference-contexts: We refer the reader to [Nis96] for a survey on this method. With respect to polynomial time randomized computation, there are two fundamental approaches to derandomization: the method of conditional probabilities [ES73, Spe87, Rag88] and constructing small-sized sample spaces <ref> [KW84, Lub85, ABI86, AKS87, NN90] </ref>. <p> The most commonly used tools for constructing small-sized sample spaces are: k-wise independent hashing [CW79], sample spaces with limited independence <ref> [KW84, Lub85, ABI86] </ref>, sample spaces with small bias [NN90], and expander graphs [AKS87]. Remark: Here we have assumed that the polynomial time randomized computation has one-side error, in which case, finding a good sample point is sufficient for deran-domization. <p> Usually, constructions that satisfy this 6 requirement are especially useful for designing or derandomizing parallel algorithms (see e.g. <ref> [KW84, Lub85, ABI86, NN90] </ref>), and for constructing pseudorandom generators for space bounded computation [BNS89, Nis90, NZ93, INW94, AW95, ASWZ96]. As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well). <p> These include almost all the explicit constructions of pseudorandom generators (e.g. [NW88, Nis90]), expanders (e.g. [GG81, LPS86]), dispersers (e.g. [CW89, SSZ95]), extractors (e.g. [NZ93, TaS96]), k-wise independent sample spaces (e.g. <ref> [Lub85, ABI86] </ref>), small-bias sample spaces (e.g. [NN90, AGHP91]), etc. <p> This approach has been widely used and proven effective in many applications (see e.g. <ref> [KW84, Lub85, ABI86, BR89, MNN89, NN90, Alo91, Sch92, KM93, KK94] </ref>). Along the line of this approach, the construction of k-wise independent sample spaces is one of the earliest studied problems. <p> An efficient construction of k-wise independent sample spaces of size n bk=2c was presented in <ref> [ABI86] </ref> (see also [Lub85]), whose size basically matches the lower bound given in [CGHFRS85] (see also [ABI86, KM94]). <p> An efficient construction of k-wise independent sample spaces of size n bk=2c was presented in [ABI86] (see also [Lub85]), whose size basically matches the lower bound given in [CGHFRS85] (see also <ref> [ABI86, KM94] </ref>). In a more general setting, Schulman [Sch92] considered the problem of constructing sample spaces uniform over a family of subsets of f1; 2; : : :; ng (neighborhoods), i.e., the distribution induced on the random variables in any particular neighborhood in the family is uniformly independent.
Reference: [ABNNR92] <author> N. Alon, J. Bruck, J. Naor, M. Naor and R. Roth. </author> <title> Construction of asymptotically good low-rate error-correcting codes through pseudo-random graphs. </title> <journal> IEEE Trans. on Info. Theory, </journal> <volume> 38(2) </volume> <pages> 509-515, </pages> <year> 1992. </year>
Reference-contexts: Alon [Alo86] showed an explicit construction of (n; ( [n] k ))-universal sets of size log n2 O (k 2 ) for the case k is fixed. In [NN90] and <ref> [ABNNR92] </ref>, nearly optimal constructions of size log n 2 O (k) were given. The previously best known construction in this case is due to [NSS95] and has size 2 k k O (log k) log n.
Reference: [AGHP91] <author> N. Alon, O, Goldreich, J. Hastad and R. Peralta. </author> <title> Simple constructions of almost k-wise independent random variables. Random Structures and Algorithms 3(3) </title> <type> 289-303, </type> <year> 1992. </year>
Reference-contexts: These include almost all the explicit constructions of pseudorandom generators (e.g. [NW88, Nis90]), expanders (e.g. [GG81, LPS86]), dispersers (e.g. [CW89, SSZ95]), extractors (e.g. [NZ93, TaS96]), k-wise independent sample spaces (e.g. [Lub85, ABI86]), small-bias sample spaces (e.g. <ref> [NN90, AGHP91] </ref>), etc. <p> They presented an efficient construction of *-biased sample spaces of size O (n=* 4 ). Alon et al. in <ref> [AGHP91] </ref> gave three more simple constructions of *-biased sample spaces of size O (n 2 =* 2 ). <p> Let us denote the maximum cardinality of any element of F by (F ). Then two previously best known constructions for this problem are of sizes O ((F ) log n=* 4 ) [NN90] and O ((F ) 2 log 2 n=* 2 ) <ref> [AGHP91] </ref>, respectively, which are obtained by constructing (F )-wise *-biased sample spaces. We shall present a new construction whose size is O (log jF j=* 2 ). The running time needed in our construction is polynomial in n; * 1 and jF j. <p> Then we apply the method of conditional probabilities to searching for such a desired small subset of points from an * 2 - biased sample space. Since the previous work in [NN90] and <ref> [AGHP91] </ref> give us explicit constructions of such sample spaces of polynomial size, the size of our search space becomes sufficiently small so that we are able accomplish the construction efficiently. <p> It is said to be *-biased if it is *-biased with respect to fl ([n]), and it is said to be k-wise *-biased if it is *-biased with respect to fl (( [n] We will need the next result due to <ref> [AGHP91] </ref>: Theorem 4.2.1 Let n be a positive integer and 0 &lt; * 1. There is an efficient construction of an *-biased sample space in f1; 1g n of size O (n 2 =* 2 ). <p> We certainly would fail in the former case since the construction time needed in this case is more than jSj = 2 n . On the other hand, we should succeed in the latter case since the work in [NN90] and <ref> [AGHP91] </ref> provide us explicit constructions of * 2 of size polynomial in n and * 1 , and therefore, provided that the conditional expectations are easy to compute, the construction time we need is n O (1) jSj which is polynomial in n and * 1 .
Reference: [AS91] <author> N. Alon and J. Spencer. </author> <title> The Probabilistic Method. </title> <publisher> Wiley, </publisher> <year> 1991. </year>
Reference-contexts: We will need a technical lemma whose proof is given in <ref> [AS91] </ref>. Lemma 4.3.1 For all ff 2 [0; 1] and all fi, ffe fi (1ff) + (1 ff)e fiff e fi 2 =8 . Lemma 4.3.2 Let ffi v f1; 1g n be a ffi-biased sample space and let F be a family of subsets of [n]. <p> To accomplish this, we apply the standard Chernoff bound for large deviations. The argument we shall present uses the proof of a theorem in <ref> [AS91] </ref> (Corollary A.7). We show the details here for later reference. 90 For each 1 i m, let us define a random variable X J i E [Y J Clearly, X J = P m i .
Reference: [ASWZ96] <author> R. Armoni, M. Saks, A. Wigderson and S. Zhou. </author> <title> Discrepancy sets and pseudorandom generators for combinatorial rectangles. </title> <type> Manuscript, </type> <year> 1996. </year>
Reference-contexts: Usually, constructions that satisfy this 6 requirement are especially useful for designing or derandomizing parallel algorithms (see e.g. [KW84, Lub85, ABI86, NN90]), and for constructing pseudorandom generators for space bounded computation <ref> [BNS89, Nis90, NZ93, INW94, AW95, ASWZ96] </ref>. As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well).
Reference: [AW95] <author> R. Armoni and A. Wigderson. </author> <title> Pseudorandomness for space bounded computations. </title> <type> Manuscript, </type> <year> 1995. </year>
Reference-contexts: Usually, constructions that satisfy this 6 requirement are especially useful for designing or derandomizing parallel algorithms (see e.g. [KW84, Lub85, ABI86, NN90]), and for constructing pseudorandom generators for space bounded computation <ref> [BNS89, Nis90, NZ93, INW94, AW95, ASWZ96] </ref>. As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well).
Reference: [BNS89] <author> L. Babai, N. Nisan and M. Szegedy. </author> <title> Multiparty protocols and logspace-hard pseudorandom sequences. </title> <booktitle> In Proc. of 21st ACM Symposium on Theory of Computing, </booktitle> <year> 1989. </year> <month> 101 </month>
Reference-contexts: The objective of deterministic amplification is to achieve high success probability while minimizing the number of random bits, and the goal of derandomization is to eliminate randomness from computation. There are two basic methods that are employed in deterministic amplification. The first method is to construct pseudorandom generators <ref> [Yao82, BM84, NW88, BNS89] </ref>, which are functions that map short random seeds to much longer strings so that any randomized algorithm of a certain type cannot distinguish statistically between the output strings from the generators and the truly random strings. <p> Usually, constructions that satisfy this 6 requirement are especially useful for designing or derandomizing parallel algorithms (see e.g. [KW84, Lub85, ABI86, NN90]), and for constructing pseudorandom generators for space bounded computation <ref> [BNS89, Nis90, NZ93, INW94, AW95, ASWZ96] </ref>. As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well). <p> of proper complexity function is formally defined in [Pap94] and includes most "reasonable" functions, including polynomials, polylogarithmic functions, exponential funtions, etc. 12 performance of exact rather than approximate matrix computations, is not generalized by Theorem 2.1.1.) In recent years, despite considerable progress on deterministic simulations of small space randomized algorithms <ref> [AKS87, BNS89, Nis90, Nis92, NSW92, NZ93] </ref> there has been no general improvement on this space bound.
Reference: [BR89] <author> B. Berger and J. Rompel. </author> <title> Simulating (log c n)-wise independence in NC. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 38(4) </volume> <pages> 1026-1046, </pages> <year> 1991. </year>
Reference-contexts: This approach has been widely used and proven effective in many applications (see e.g. <ref> [KW84, Lub85, ABI86, BR89, MNN89, NN90, Alo91, Sch92, KM93, KK94] </ref>). Along the line of this approach, the construction of k-wise independent sample spaces is one of the earliest studied problems.
Reference: [Blu86] <author> M. Blum. </author> <title> Independent Unbiased Coin Flips from a Correlated Biased Source: a Finite Markov Chain. </title> <journal> Combinatorica, </journal> <volume> 6(2) </volume> <pages> 97-108, </pages> <year> 1986. </year>
Reference-contexts: For example, von Neumann [Neu63] presented a technique to convert independent but biased coin-flips into independent and unbiased ones; Blum <ref> [Blu86] </ref> showed how to convert the bits output by an unknown Markov chain into a sequence of perfectly random bits. However, for more general faulty sources, it can be shown (see e.g. [SV86]) that to construct such a direct conversion f is impossible.
Reference: [BM84] <author> M. Blum and S. Micali. </author> <title> How to generate cryptographically strong sequences of pseudo-random bits. </title> <journal> J. SIAM, </journal> <volume> 13(4) </volume> <pages> 850-864, </pages> <year> 1984. </year>
Reference-contexts: The objective of deterministic amplification is to achieve high success probability while minimizing the number of random bits, and the goal of derandomization is to eliminate randomness from computation. There are two basic methods that are employed in deterministic amplification. The first method is to construct pseudorandom generators <ref> [Yao82, BM84, NW88, BNS89] </ref>, which are functions that map short random seeds to much longer strings so that any randomized algorithm of a certain type cannot distinguish statistically between the output strings from the generators and the truly random strings.
Reference: [BCP83] <author> A. Borodin, S. Cook and N. Pippenger. </author> <title> Parallel computation and well-endowed rings and space-bounded probabilistic machines. </title> <journal> Information and Control, </journal> <volume> 58 </volume> <pages> 113-136, </pages> <year> 1983. </year>
Reference-contexts: In this work we present a deterministic algorithm that uses only O (r 1=2 s) space. Our algorithm has r 1=2 recursive levels of O (s) space each, and additional overhead of O (r 1=2 s) space. It is well known (see e.g. [Gil77], <ref> [BCP83] </ref>) that approximating substochastic matrix repeated squaring is closely related to the problem of derandomizing space-bounded randomized algorithms. In this section we give a review of the connection between these two problems and summarize the consequences of our new result. <p> In fact, the weaker containment for R H SP ACE (S (n)) also follows from Savitch's theorem [Sav70] N SP ACE (S (n)) DSP ACE (S (n) 2 ). (Independently, Borodin, Cook and Pippenger <ref> [BCP83] </ref> and Jung [Jun81] (see also [AO94]) showed that the same DSP ACE (S (n) 2 ) bound can be achieved in Gill's [Gil77] stronger model of randomized space computation in which cyclic configuration transitions are allowed. This model, in particular, contains N SP ACE (S (n)).
Reference: [CW79] <author> L. Carter and M. Wegman. </author> <title> Universal hash functions. </title> <journal> J. Comp. and Syst. Sci., </journal> <volume> 18(2) </volume> <pages> 143-154, </pages> <year> 1979. </year>
Reference-contexts: The most commonly used tools for constructing small-sized sample spaces are: k-wise independent hashing <ref> [CW79] </ref>, sample spaces with limited independence [KW84, Lub85, ABI86], sample spaces with small bias [NN90], and expander graphs [AKS87]. Remark: Here we have assumed that the polynomial time randomized computation has one-side error, in which case, finding a good sample point is sufficient for deran-domization. <p> For the purpose of constructing Nisan's generator, we will be interested in the composition of (m; 2)-generators. Universal Hash Function Families We review some of the properties of universal hash function families. Definition 2.6.3 <ref> [CW79] </ref> A family H of functions that map f0; 1g p to f0; 1g q is called a universal hash function family if for all x 1 6= x 2 2 f0; 1g p and all y 1 ; y 2 2 f0; 1g q , P r h2H [h (x
Reference: [CFL83] <author> A. Chandra, M. Furst and R. Lipton. </author> <title> Multi-party protocols. </title> <booktitle> In Proc. of 15th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 94-99, </pages> <year> 1983. </year>
Reference: [CG88] <author> B. Chor and O. Goldreich. </author> <title> Unbiased Bits from Sources of Weak Randomness and Probabilistic Communication Complexity. </title> <journal> SIAM J. Comput., </journal> <volume> 17(2) </volume> <pages> 230-261, </pages> <year> 1988. </year>
Reference-contexts: One problem that is closely related to deterministic amplification is to design randomized algorithms that are robust under the presence of imperfect random sources. This problem itself is an important issue in randomized computation and has been studied extensively during the past decade (see e.g. <ref> [SV86, CG88, Zuc90] </ref>). Using the techniques developed in the study of computing with imperfect sources, we give an improved construction of a family of dispersers that can be applied to designing randomized polynomial time algorithms that achieve maximal robustness. <p> For example, Santha and Vazirani [SV86] studied the class of weak sources called "slightly random sources", which was further examined in [VV85, Vaz86, Vaz87a, Vaz87b]. A more general model "PRB-sources" is considered later by Chor and Goldreich <ref> [CG88] </ref>. In [Zuc90, Zuc91], Zuckerman introduced the model of ffi-sources which generalizes all the previous models. Let D be a probability distribution on a set X.
Reference: [CG86] <author> B. Chor and O. Goldreich. </author> <title> On the power of two point based sampling. </title> <journal> Journal of Complexity, </journal> <volume> 5 </volume> <pages> 96-106, </pages> <year> 1989. </year>
Reference: [CGHFRS85] <author> B. Chor, O. Goldreich, J. Hastad, J. Friedman, S. Rudich and R. Smolen-sky. </author> <title> The bit extraction problem or t-resilient functions. </title> <booktitle> In Proc. of 26th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 396-407, </pages> <year> 1985. </year>
Reference-contexts: An efficient construction of k-wise independent sample spaces of size n bk=2c was presented in [ABI86] (see also [Lub85]), whose size basically matches the lower bound given in <ref> [CGHFRS85] </ref> (see also [ABI86, KM94]).
Reference: [CRS94] <author> S. Chari, P. Rohatgi and A. Srinivasan. </author> <title> Improved algorithms via approximations of probability distributions. </title> <booktitle> In Proc. of 26th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 584-592, </pages> <year> 1994. </year>
Reference: [Coo85] <author> S. Cook. </author> <title> A taxonomy of problems with fast parallel algorithms. </title> <journal> Information and Control, </journal> <volume> 64 </volume> <pages> 2-22, </pages> <year> 1985. </year>
Reference: [CW89] <author> A. Cohen and A. Wigderson. Dispersers, </author> <title> Deterministic Amplification, and Weak Random Sources. </title> <booktitle> In Proc. of IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 14-19, </pages> <year> 1989. </year>
Reference-contexts: As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well). These include almost all the explicit constructions of pseudorandom generators (e.g. [NW88, Nis90]), expanders (e.g. [GG81, LPS86]), dispersers (e.g. <ref> [CW89, SSZ95] </ref>), extractors (e.g. [NZ93, TaS96]), k-wise independent sample spaces (e.g. [Lub85, ABI86]), small-bias sample spaces (e.g. [NN90, AGHP91]), etc. <p> Co-hen and Wigderson <ref> [CW89] </ref> classified dispersers into two types: OR-dispersers and MAJORITY-dispersers. <p> For the case where ffi is a fixed positive constant, Zuckerman [Zuc91, Zuc96] showed how to simulate any BPP algorithm efficiently with ffi-sources. What about sources whose entropy rate decreases with R: how weak can the source get and still be usable 50 for efficient simulations? In <ref> [CW89] </ref>, it was observed that, for information-theoretic reasons, if S is any class of sources for which there is an efficient black-box simulation of RP or BPP (that works correctly with high probability) using any source S 2 S, then every source S must be close to a ffi-source with ffi <p> takes time m O (log m) , where m is the number of random bits needed by the original RP algorithm. (This result has been improved recently by Ta-Shma in [TaS96], where he presented a BPP simulation that uses time m O (log (k) m) for any fixed k.) In <ref> [San87, Sip88, CW89] </ref> it was observed that the black-box simulation described above can be defined by a sequence G m = (V m ; W m ; E m ) of bipartite multigraphs, one for each m, where V m = f0; 1g R (m) and W m = f0; 1g
Reference: [EGLNV92] <author> G. Even, O. Goldreich, M. Luby, N. Nisan and B. Velickovic. </author> <title> Approximations of general independent distributions. </title> <booktitle> In Proc. of 24th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 10-16, </pages> <year> 1992. </year>
Reference-contexts: Following the work in [NN90], these constructions of *-biased sample spaces gave constructions of k-wise *-biased sample spaces of size O (k log n=* 4 ) and O (k 2 log 2 n=* 2 ), respectively. In <ref> [EGLNV92] </ref>, constructions of sample spaces with small bias for general independent distributions were studied. Koller and Megiddo in [KM93] introduced the framework of constructing sample spaces that satisfy a set of probability constraints, which generalized the construction approach used in [Sch92].
Reference: [ES73] <author> P. Erdos and J. Selfridge. </author> <title> On a combinatorial game. </title> <journal> Journal of Combinatorial Theory, Series A 14 </journal> <pages> 298-301, </pages> <year> 1973. </year>
Reference-contexts: The application of this approach gives extremely high success probability using only a moderate number of random bits. We refer the reader to [Nis96] for a survey on this method. With respect to polynomial time randomized computation, there are two fundamental approaches to derandomization: the method of conditional probabilities <ref> [ES73, Spe87, Rag88] </ref> and constructing small-sized sample spaces [KW84, Lub85, ABI86, AKS87, NN90]. <p> we may apply the following modifications to make the previous definitions and statements work: we map 1 to 0, -1 to 1 and change the product correspondingly to the sum modulo 2. 4.2.3 The Method of Conditional Probabilities The method of conditional probabilities, which was introduced by Erdos and Selfridge <ref> [ES73] </ref>, Spencer [Spe87], and Raghavan [Rag88], is a powerful tool in derandomization. In this 86 section, we review a basic framework for this method in terms of the conditional expectations. For a set S and a positive integer n, let v S n .
Reference: [FLW92] <author> A. M. Ferrenberg, D. P. Landau and Y. J. Wong. </author> <title> Monte Carlo simulations: Hidden errors from "good" random number generators. </title> <journal> Physical Review Letters, </journal> <volume> 69(23) </volume> <pages> 3382-3384, </pages> <year> 1992. </year> <month> 102 </month>
Reference-contexts: Empirically, this often seems to be sufficient. However, there are reports of algorithms giving quite different results under different pseudo-random generators (see e.g., <ref> [FLW92] </ref> for such reports on Monte-Carlo simulations, and [Hsu93, HRD94] for the deviant performance of some RN C algorithms for graph problems). An alternative approach is to use the output of some physical source of randomness, such 48 as a Zener diode, or the last digits of a real-time clock.
Reference: [FN93] <author> A. Fiat and M. Naor. </author> <title> Implicit O(1) probe search. </title> <journal> SIAM J. Comput., </journal> <volume> 22 </volume> <pages> 1-10, </pages> <year> 1993. </year>
Reference-contexts: For example, it gives improvements on the expander construction and the consequent applications given in [WZ93], on the the hardness results of approximating the clique function [Zuc93, SZ94], and on the results for a problem in 46 data structures: implicit O (1) probe search <ref> [FN93, Zuc91] </ref>. These consequences were each observed by previous researchers, and provided much of the motivation for the search for good dispersers. The details of these improvements can be derived from the corresponding original papers by plugging in our construction, and will not be given here.
Reference: [Fun94] <author> A. Fundia. </author> <title> Derandomizing Chebyshev's inequality to find independent sets in uncrowded hypergraghs. </title> <type> Manuscript, </type> <year> 1994. </year>
Reference-contexts: One effective technique to overcome 87 this difficulty that has been proven successful in applications is by way of employing pessimistic estimators, which was first introduced by Raghavan [Rag88]. We describe below a modified version of pessimistic estimators due to Fundia <ref> [Fun94] </ref> (see also [Sak94]). Continuing the above discussion, we suppose that for some given v 1 ; : : : ; v i 2 S, the conditional expectation E [Zjv 1 ; : : : ; v i ] is difficult to compute. <p> We want to apply the method of conditional probabilities to Z and construct such a desired point in . 92 Unfortunately, there seems to be no easy way to directly compute the conditional expectation of Z. To overcome this difficulty, we adopt the idea of pessimistic estimators <ref> [Rag88, Fun94] </ref> and introduce another random variable W J to estimate each Z J , where W J is defined as W J = e (*ffi) 2 m (e (*ffi)X J ): P What we would like to see is that the random variable W satisfies the conditions (A), (B) and
Reference: [Gil77] <author> J. Gill. </author> <title> Computational complexity of probabilistic Turing machines. </title> <journal> SIAM J. Computing, </journal> <volume> 6 </volume> <pages> 675-695, </pages> <year> 1977. </year>
Reference-contexts: In this work we present a deterministic algorithm that uses only O (r 1=2 s) space. Our algorithm has r 1=2 recursive levels of O (s) space each, and additional overhead of O (r 1=2 s) space. It is well known (see e.g. <ref> [Gil77] </ref>, [BCP83]) that approximating substochastic matrix repeated squaring is closely related to the problem of derandomizing space-bounded randomized algorithms. In this section we give a review of the connection between these two problems and summarize the consequences of our new result. <p> H SP ACE (S (n)) also follows from Savitch's theorem [Sav70] N SP ACE (S (n)) DSP ACE (S (n) 2 ). (Independently, Borodin, Cook and Pippenger [BCP83] and Jung [Jun81] (see also [AO94]) showed that the same DSP ACE (S (n) 2 ) bound can be achieved in Gill's <ref> [Gil77] </ref> stronger model of randomized space computation in which cyclic configuration transitions are allowed. This model, in particular, contains N SP ACE (S (n)).
Reference: [GG81] <author> O. Gabber and Z. Galil. </author> <title> Explicit construction of linear-sized supercon-centrators. </title> <journal> J. Comp. and Syst. Sci., </journal> <volume> 22 </volume> <pages> 407-420, </pages> <year> 1981. </year>
Reference-contexts: As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well). These include almost all the explicit constructions of pseudorandom generators (e.g. [NW88, Nis90]), expanders (e.g. <ref> [GG81, LPS86] </ref>), dispersers (e.g. [CW89, SSZ95]), extractors (e.g. [NZ93, TaS96]), k-wise independent sample spaces (e.g. [Lub85, ABI86]), small-bias sample spaces (e.g. [NN90, AGHP91]), etc.
Reference: [HRD94] <author> T.-s. Hsu, V. Ramachandran and N. Dean. </author> <title> Parallel implementation of algorithms for finding connected components. </title> <booktitle> In Proc. DIMACS International Algorithm Implementation Challenge, </booktitle> <pages> pp. 1-14, </pages> <year> 1994. </year>
Reference-contexts: Empirically, this often seems to be sufficient. However, there are reports of algorithms giving quite different results under different pseudo-random generators (see e.g., [FLW92] for such reports on Monte-Carlo simulations, and <ref> [Hsu93, HRD94] </ref> for the deviant performance of some RN C algorithms for graph problems). An alternative approach is to use the output of some physical source of randomness, such 48 as a Zener diode, or the last digits of a real-time clock.
Reference: [Hsu93] <author> T.-s. Hsu. </author> <title> Graph augmentation and related problems: theory and practice. </title> <type> PhD thesis, </type> <institution> Department of Computer Sciences, University of Texas at Austin, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: Empirically, this often seems to be sufficient. However, there are reports of algorithms giving quite different results under different pseudo-random generators (see e.g., [FLW92] for such reports on Monte-Carlo simulations, and <ref> [Hsu93, HRD94] </ref> for the deviant performance of some RN C algorithms for graph problems). An alternative approach is to use the output of some physical source of randomness, such 48 as a Zener diode, or the last digits of a real-time clock.
Reference: [Imm88] <author> N. Immerman. </author> <title> Nondeterministic space is closed under complementation. </title> <journal> SIAM Journal of Computing, </journal> <volume> 17 </volume> <pages> 935-938, </pages> <year> 1988. </year>
Reference: [IZ89] <author> R. Impagliazzo and D. Zuckerman. </author> <title> How to Recycle Random Bits. </title> <booktitle> In Proc. of 30th Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 248-253, </pages> <year> 1989. </year>
Reference: [ILL89] <author> R. Impagliazzo, L. Levin and M. Luby. </author> <title> Pseudo-Random Generation from One-Way Functions. </title> <booktitle> In Proc. of ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 12-24, </pages> <year> 1989. </year>
Reference: [INW94] <author> R. Impagliazzo, N. Nisan and A. Wigderson. </author> <title> Pseudorandomness for network algorithms. </title> <booktitle> In Proc. of ACM Symposium on Theory of Computing, </booktitle> <year> 1994. </year>
Reference-contexts: Usually, constructions that satisfy this 6 requirement are especially useful for designing or derandomizing parallel algorithms (see e.g. [KW84, Lub85, ABI86, NN90]), and for constructing pseudorandom generators for space bounded computation <ref> [BNS89, Nis90, NZ93, INW94, AW95, ASWZ96] </ref>. As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well).
Reference: [Jun81] <author> H. Jung. </author> <title> Relationships between probabilistic and deterministic tape complexity. </title> <booktitle> In 10th Symposium on Mathematical Foundations of Computer Science, Lecture Notes in Computer Science, </booktitle> <volume> 118 </volume> <pages> 339-346, </pages> <publisher> Springer-Verlag. </publisher>
Reference-contexts: In fact, the weaker containment for R H SP ACE (S (n)) also follows from Savitch's theorem [Sav70] N SP ACE (S (n)) DSP ACE (S (n) 2 ). (Independently, Borodin, Cook and Pippenger [BCP83] and Jung <ref> [Jun81] </ref> (see also [AO94]) showed that the same DSP ACE (S (n) 2 ) bound can be achieved in Gill's [Gil77] stronger model of randomized space computation in which cyclic configuration transitions are allowed. This model, in particular, contains N SP ACE (S (n)).
Reference: [Kar93] <author> D. Karger. </author> <title> Global min-cuts in RN C, and other ramifications of a simple min-cut algorithm. </title> <booktitle> In Proc. of the 4th Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pp. 21-30, </pages> <year> 1993. </year>
Reference-contexts: For many problems, a randomized algorithm is by far faster (e.g. primality testing [SS77, Rab80, AH87]), more parallel (e.g. perfect matching construction [KUW86, MVV87]), more space-efficient (e.g. undirected graph connectivity [AKLLR79]), or simpler (e.g. the min-cut problem <ref> [Kar93] </ref>) than any known deterministic algorithm. In fact, there are many problems such as primality testing, perfect matching construction and undirected graph connectivity which (in certain respects) have very efficient randomized algorithms, but are not known to have corresponding deterministic counterparts.
Reference: [KK94] <author> D. Karger and D. Koller. </author> <title> (De)randomized construction of small sample spaces in N C. </title> <booktitle> In Proc. of 35th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 252-263, </pages> <year> 1994. </year>
Reference-contexts: On the other hand, explicit constructions obtained via using the method of conditional probabilities (e.g. [Rag88, SZ96]) or solving linear constraints (e.g. <ref> [Sch92, KK94] </ref>) typically satisfy the first requirement but not necessarily the second. 1.3 The Organization of the Thesis So far we have summarized the general approaches to reducing randomness in computation via explicit constructions. <p> This approach has been widely used and proven effective in many applications (see e.g. <ref> [KW84, Lub85, ABI86, BR89, MNN89, NN90, Alo91, Sch92, KM93, KK94] </ref>). Along the line of this approach, the construction of k-wise independent sample spaces is one of the earliest studied problems. <p> Koller and Megiddo in [KM93] introduced the framework of constructing sample spaces that satisfy a set of probability constraints, which generalized the construction approach used in [Sch92]. This method was further extended by Karger and Koller in <ref> [KK94] </ref> where they showed how to deal with the more general expectation constraints. In the latter work, an N C algorithm for constructing sample spaces that approximate general independent distributions with relative error was shown.
Reference: [KM94] <author> H. Karloff and Y. Mansour. </author> <title> On construction of k-wise independent random variables. </title> <booktitle> In Proc. of the 26th Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1994. </year> <month> 103 </month>
Reference-contexts: An efficient construction of k-wise independent sample spaces of size n bk=2c was presented in [ABI86] (see also [Lub85]), whose size basically matches the lower bound given in [CGHFRS85] (see also <ref> [ABI86, KM94] </ref>). In a more general setting, Schulman [Sch92] considered the problem of constructing sample spaces uniform over a family of subsets of f1; 2; : : :; ng (neighborhoods), i.e., the distribution induced on the random variables in any particular neighborhood in the family is uniformly independent.
Reference: [KUW86] <author> R. Karp, E. Upfal and A. Wigderson. </author> <title> Constructing a maximum matching is in random N C. </title> <journal> Combinatorica, </journal> <volume> 6(1) </volume> <pages> 35-48, </pages> <year> 1986. </year>
Reference-contexts: Its apparent success in application has motivated a substantial effort to understand how much power randomness can provide over determinism. For many problems, a randomized algorithm is by far faster (e.g. primality testing [SS77, Rab80, AH87]), more parallel (e.g. perfect matching construction <ref> [KUW86, MVV87] </ref>), more space-efficient (e.g. undirected graph connectivity [AKLLR79]), or simpler (e.g. the min-cut problem [Kar93]) than any known deterministic algorithm.
Reference: [KW84] <author> R. Karp and A. Wigderson. </author> <title> A fast parallel algorithm for the maximal independent set problem. </title> <booktitle> In Proc. of the 16th Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1984. </year>
Reference-contexts: We refer the reader to [Nis96] for a survey on this method. With respect to polynomial time randomized computation, there are two fundamental approaches to derandomization: the method of conditional probabilities [ES73, Spe87, Rag88] and constructing small-sized sample spaces <ref> [KW84, Lub85, ABI86, AKS87, NN90] </ref>. <p> The most commonly used tools for constructing small-sized sample spaces are: k-wise independent hashing [CW79], sample spaces with limited independence <ref> [KW84, Lub85, ABI86] </ref>, sample spaces with small bias [NN90], and expander graphs [AKS87]. Remark: Here we have assumed that the polynomial time randomized computation has one-side error, in which case, finding a good sample point is sufficient for deran-domization. <p> Usually, constructions that satisfy this 6 requirement are especially useful for designing or derandomizing parallel algorithms (see e.g. <ref> [KW84, Lub85, ABI86, NN90] </ref>), and for constructing pseudorandom generators for space bounded computation [BNS89, Nis90, NZ93, INW94, AW95, ASWZ96]. As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well). <p> This approach has been widely used and proven effective in many applications (see e.g. <ref> [KW84, Lub85, ABI86, BR89, MNN89, NN90, Alo91, Sch92, KM93, KK94] </ref>). Along the line of this approach, the construction of k-wise independent sample spaces is one of the earliest studied problems.
Reference: [KM93] <author> D. Koller and N. Megiddo. </author> <title> Finding small sample spaces satisfying given constraints. </title> <booktitle> In Proc. of the 25th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 268-277, </pages> <year> 1993. </year>
Reference-contexts: This approach has been widely used and proven effective in many applications (see e.g. <ref> [KW84, Lub85, ABI86, BR89, MNN89, NN90, Alo91, Sch92, KM93, KK94] </ref>). Along the line of this approach, the construction of k-wise independent sample spaces is one of the earliest studied problems. <p> In [EGLNV92], constructions of sample spaces with small bias for general independent distributions were studied. Koller and Megiddo in <ref> [KM93] </ref> introduced the framework of constructing sample spaces that satisfy a set of probability constraints, which generalized the construction approach used in [Sch92]. This method was further extended by Karger and Koller in [KK94] where they showed how to deal with the more general expectation constraints.
Reference: [KN95] <author> E. Kushilevitz and N. Nisan. </author> <title> Communication Complexity. </title>
Reference-contexts: We will not provide all the proof details here since they are out of the scope of this thesis. We refer the reader to the book by Kuselevitz and Nisan <ref> [KN95] </ref> on communication complexity.) 96 Example 1: We consider the case where F includes fl (( [n] 2 )). Then in the communication matrix associated with the problem, the submatrix indexed by the set of n-bit strings with a single 1-bit has full rank n.
Reference: [LP82] <author> H. Lewis and C. Papadimitiou. </author> <title> Symmetric space-bounded computation. </title> <journal> Theoretical Computer Science, </journal> <volume> 19 </volume> <pages> 161-187, </pages> <year> 1982. </year>
Reference-contexts: Using Nisan's generator, Nisan, Szemeredi, Wigderson [NSW92] showed that undirected (s; t) connectivity, which is in RL [AKLLR79] and is complete for the complexity class SL <ref> [LP82] </ref>, can be computed in DSP ACE (log 3=2 n). It was this result that motivated our research that we present in this work. As with these other results, Nisan's pseudorandom generator is a major component of our simulation.
Reference: [LN86] <author> R. Lidl and H. Niederreiter, </author> <title> Introduction to Finite Fields and their applications, </title> <publisher> Cambridge University Press, </publisher> <year> 1986. </year>
Reference-contexts: We refer the reader to <ref> [LN86] </ref> for more background on finite fields.) Fix such an encoding. Having done this, in what follows, we view the elements of F k as binary strings of length mk and vice versa.
Reference: [LLSZ95] <author> N. Linial, M. Luby, M. Saks and D. Zuckerman. </author> <title> Efficient construction of a small hitting set for combinatorial rectangles in high dimension. </title> <booktitle> In Proc. of 25th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 258-267, </pages> <year> 1993. </year>
Reference: [LPS86] <author> A. Lubotzky, R. Phillips and P. Sarnak. </author> <title> Explicit expanders and the Ra-manujan conjectures. </title> <booktitle> In Proc. of 18th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 240-246, </pages> <year> 1986. </year>
Reference-contexts: As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well). These include almost all the explicit constructions of pseudorandom generators (e.g. [NW88, Nis90]), expanders (e.g. <ref> [GG81, LPS86] </ref>), dispersers (e.g. [CW89, SSZ95]), extractors (e.g. [NZ93, TaS96]), k-wise independent sample spaces (e.g. [Lub85, ABI86]), small-bias sample spaces (e.g. [NN90, AGHP91]), etc.
Reference: [Lub85] <author> M. Luby. </author> <title> A simple parallel algorithm for the maximal independent set problem. </title> <journal> SIAM J. Comput., </journal> <volume> 15(4) </volume> <pages> 1036-1053, </pages> <year> 1986. </year>
Reference-contexts: We refer the reader to [Nis96] for a survey on this method. With respect to polynomial time randomized computation, there are two fundamental approaches to derandomization: the method of conditional probabilities [ES73, Spe87, Rag88] and constructing small-sized sample spaces <ref> [KW84, Lub85, ABI86, AKS87, NN90] </ref>. <p> The most commonly used tools for constructing small-sized sample spaces are: k-wise independent hashing [CW79], sample spaces with limited independence <ref> [KW84, Lub85, ABI86] </ref>, sample spaces with small bias [NN90], and expander graphs [AKS87]. Remark: Here we have assumed that the polynomial time randomized computation has one-side error, in which case, finding a good sample point is sufficient for deran-domization. <p> Usually, constructions that satisfy this 6 requirement are especially useful for designing or derandomizing parallel algorithms (see e.g. <ref> [KW84, Lub85, ABI86, NN90] </ref>), and for constructing pseudorandom generators for space bounded computation [BNS89, Nis90, NZ93, INW94, AW95, ASWZ96]. As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well). <p> These include almost all the explicit constructions of pseudorandom generators (e.g. [NW88, Nis90]), expanders (e.g. [GG81, LPS86]), dispersers (e.g. [CW89, SSZ95]), extractors (e.g. [NZ93, TaS96]), k-wise independent sample spaces (e.g. <ref> [Lub85, ABI86] </ref>), small-bias sample spaces (e.g. [NN90, AGHP91]), etc. <p> This approach has been widely used and proven effective in many applications (see e.g. <ref> [KW84, Lub85, ABI86, BR89, MNN89, NN90, Alo91, Sch92, KM93, KK94] </ref>). Along the line of this approach, the construction of k-wise independent sample spaces is one of the earliest studied problems. <p> An efficient construction of k-wise independent sample spaces of size n bk=2c was presented in [ABI86] (see also <ref> [Lub85] </ref>), whose size basically matches the lower bound given in [CGHFRS85] (see also [ABI86, KM94]).
Reference: [MR95] <author> R. Motwani and P. Raghavan. </author> <title> Randomized Algorithms. </title> <publisher> Cambridge University Press, </publisher> <year> 1995. </year>
Reference-contexts: We refer the reader to the textbook <ref> [MR95] </ref> for more background on randomized algorithms. Generally speaking, reducing randomness has two broad meanings: deterministic amplification and derandomization. The objective of deterministic amplification is to achieve high success probability while minimizing the number of random bits, and the goal of derandomization is to eliminate randomness from computation.
Reference: [MNN89] <author> R. Motwani, J. Naor and M. Naor. </author> <title> The probabilistic method yields deterministic parallel algorithms. </title> <booktitle> In Proc. of 30th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 8-13, </pages> <year> 1989. </year>
Reference-contexts: This approach has been widely used and proven effective in many applications (see e.g. <ref> [KW84, Lub85, ABI86, BR89, MNN89, NN90, Alo91, Sch92, KM93, KK94] </ref>). Along the line of this approach, the construction of k-wise independent sample spaces is one of the earliest studied problems.
Reference: [MVV87] <author> K. Mulmuley, U. Vazirani and V. Vazirani. </author> <title> Matching is as easy as matrix inversion. </title> <booktitle> In Proc. of 19th ACM Symposium on Theory of Computing, </booktitle> <year> 1987. </year>
Reference-contexts: Its apparent success in application has motivated a substantial effort to understand how much power randomness can provide over determinism. For many problems, a randomized algorithm is by far faster (e.g. primality testing [SS77, Rab80, AH87]), more parallel (e.g. perfect matching construction <ref> [KUW86, MVV87] </ref>), more space-efficient (e.g. undirected graph connectivity [AKLLR79]), or simpler (e.g. the min-cut problem [Kar93]) than any known deterministic algorithm.
Reference: [NN90] <author> J. Naor and M. Naor. </author> <title> Small-bias probability spaces: efficient constructions and applications. </title> <journal> SIAM J. Comput., </journal> <volume> 22(4) </volume> <pages> 838-856, </pages> <year> 1993. </year>
Reference-contexts: We refer the reader to [Nis96] for a survey on this method. With respect to polynomial time randomized computation, there are two fundamental approaches to derandomization: the method of conditional probabilities [ES73, Spe87, Rag88] and constructing small-sized sample spaces <ref> [KW84, Lub85, ABI86, AKS87, NN90] </ref>. <p> The most commonly used tools for constructing small-sized sample spaces are: k-wise independent hashing [CW79], sample spaces with limited independence [KW84, Lub85, ABI86], sample spaces with small bias <ref> [NN90] </ref>, and expander graphs [AKS87]. Remark: Here we have assumed that the polynomial time randomized computation has one-side error, in which case, finding a good sample point is sufficient for deran-domization. <p> Usually, constructions that satisfy this 6 requirement are especially useful for designing or derandomizing parallel algorithms (see e.g. <ref> [KW84, Lub85, ABI86, NN90] </ref>), and for constructing pseudorandom generators for space bounded computation [BNS89, Nis90, NZ93, INW94, AW95, ASWZ96]. As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well). <p> These include almost all the explicit constructions of pseudorandom generators (e.g. [NW88, Nis90]), expanders (e.g. [GG81, LPS86]), dispersers (e.g. [CW89, SSZ95]), extractors (e.g. [NZ93, TaS96]), k-wise independent sample spaces (e.g. [Lub85, ABI86]), small-bias sample spaces (e.g. <ref> [NN90, AGHP91] </ref>), etc. <p> In our final chapter, Chapter 4, we study the problem of constructing sample spaces with small bias on designated sets of bit positions (neighborhoods). We give a construction that improves the previously best result which can be derived from the explicit construction of small-bias sample spaces in <ref> [NN90] </ref>. The size of our new construction matches the bound given by the probabilistic argument, and leads to the best efficient construction of k-wise small-bias sample spaces for fixed k. <p> This approach has been widely used and proven effective in many applications (see e.g. <ref> [KW84, Lub85, ABI86, BR89, MNN89, NN90, Alo91, Sch92, KM93, KK94] </ref>). Along the line of this approach, the construction of k-wise independent sample spaces is one of the earliest studied problems. <p> For a subset S f1; 2; : : :; ng, the quantity jP r [ P P 81 where the sum is modulo 2, is called the bias of S ([Vaz86]). Naor and Naor <ref> [NN90] </ref> introduced the notion of *-biased (resp. k-wise *-biased) sample space, in which the bias of every subset (resp. every subset of size at most k) of f1; 2; : : :; ng is at most *. <p> They presented an efficient construction of *-biased sample spaces of size O (n=* 4 ). Alon et al. in [AGHP91] gave three more simple constructions of *-biased sample spaces of size O (n 2 =* 2 ). Following the work in <ref> [NN90] </ref>, these constructions of *-biased sample spaces gave constructions of k-wise *-biased sample spaces of size O (k log n=* 4 ) and O (k 2 log 2 n=* 2 ), respectively. In [EGLNV92], constructions of sample spaces with small bias for general independent distributions were studied. <p> Let us denote the maximum cardinality of any element of F by (F ). Then two previously best known constructions for this problem are of sizes O ((F ) log n=* 4 ) <ref> [NN90] </ref> and O ((F ) 2 log 2 n=* 2 ) [AGHP91], respectively, which are obtained by constructing (F )-wise *-biased sample spaces. We shall present a new construction whose size is O (log jF j=* 2 ). <p> Then we apply the method of conditional probabilities to searching for such a desired small subset of points from an * 2 - biased sample space. Since the previous work in <ref> [NN90] </ref> and [AGHP91] give us explicit constructions of such sample spaces of polynomial size, the size of our search space becomes sufficiently small so that we are able accomplish the construction efficiently. <p> In our case that both parties have limited computation power, the previously best known protocol one could achieve, which uses O ((F ) log n) bits of communication, is by way of applying the explicit construction of (F )-wise *-biased sample spaces <ref> [NN90] </ref>. In this work, using our construction of sample spaces with small bias on neighborhoods, we close the gap between these two bounds by presenting a deterministic protocol for the problem using O (log n) bits. <p> We certainly would fail in the former case since the construction time needed in this case is more than jSj = 2 n . On the other hand, we should succeed in the latter case since the work in <ref> [NN90] </ref> and [AGHP91] provide us explicit constructions of * 2 of size polynomial in n and * 1 , and therefore, provided that the conditional expectations are easy to compute, the construction time we need is n O (1) jSj which is polynomial in n and * 1 . <p> The design of our protocol exploits the explicit construction of sample spaces with small bias on neighborhoods. Applying explicit constructions of sample spaces with small bias to the design of communication protocols was first introduced by Naor and Naor in <ref> [NN90] </ref>. In their paper, they presented a randomized protocol for the EQUALITY problem that achieves polynomially small error using O (log n) bits. <p> The work in <ref> [NN90] </ref> provides an explicit construction of ((F ))-wise 1 2 -biased sample spaces of size fi ((F ) log n), which in our case is polylogarithmic in n. Such a sample space is by definition 1 2 -biased with respect to F . <p> Then there is an explicit construction of an (n; F )-universal set of size O (2 (F) log jfl (F )j). The construction uses time polynomial in n and jfl (F )j. To prove the theorem we need the following fact which was shown in <ref> [NN90] </ref> (whose proof in turn is based on a lemma in [Vaz86]): Proposition 4.4.2 If v f0; 1g k is 2 k1 -biased, then f0; 1g k . Corollary 4.4.1 If v f0; 1g n is 2 (F)1 -biased with respect to fl (F ), then is (n; F )-universal. <p> Alon [Alo86] showed an explicit construction of (n; ( [n] k ))-universal sets of size log n2 O (k 2 ) for the case k is fixed. In <ref> [NN90] </ref> and [ABNNR92], nearly optimal constructions of size log n 2 O (k) were given. The previously best known construction in this case is due to [NSS95] and has size 2 k k O (log k) log n.
Reference: [NSS95] <author> M. Naor, L. Schulman and A. Srinivasan. </author> <title> Splitters and near-optimal derandomization. </title> <booktitle> In Proc. of 36th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp 182-191, </pages> <year> 1995. </year>
Reference-contexts: In [NN90] and [ABNNR92], nearly optimal constructions of size log n 2 O (k) were given. The previously best known construction in this case is due to <ref> [NSS95] </ref> and has size 2 k k O (log k) log n. Our construction has the least size and at the same time matches the bound given by the probabilistic argument. 100
Reference: [Neu63] <author> J. von Neumann. </author> <title> Various techniques for use in connection with random digits. </title> <booktitle> In von Neumann's Collected works, </booktitle> <pages> pp 768-770, </pages> <address> Pergaman, New York, </address> <year> 1963. </year> <month> 104 </month>
Reference-contexts: For example, von Neumann <ref> [Neu63] </ref> presented a technique to convert independent but biased coin-flips into independent and unbiased ones; Blum [Blu86] showed how to convert the bits output by an unknown Markov chain into a sequence of perfectly random bits.
Reference: [Nis90] <author> N. Nisan. </author> <title> Pseudorandom generators for space-bounded computation. </title> <booktitle> In Proc. of 22nd ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 204-212, </pages> <year> 1990. </year>
Reference-contexts: Usually, constructions that satisfy this 6 requirement are especially useful for designing or derandomizing parallel algorithms (see e.g. [KW84, Lub85, ABI86, NN90]), and for constructing pseudorandom generators for space bounded computation <ref> [BNS89, Nis90, NZ93, INW94, AW95, ASWZ96] </ref>. As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well). <p> As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well). These include almost all the explicit constructions of pseudorandom generators (e.g. <ref> [NW88, Nis90] </ref>), expanders (e.g. [GG81, LPS86]), dispersers (e.g. [CW89, SSZ95]), extractors (e.g. [NZ93, TaS96]), k-wise independent sample spaces (e.g. [Lub85, ABI86]), small-bias sample spaces (e.g. [NN90, AGHP91]), etc. <p> The algorithm employs Nisan's pseudorandom generator for space-bounded computation <ref> [Nis90] </ref>. As a consequence, we show that any randomized algorithm (with possibly 7 two-sided error) that runs in space O (S) and always halts can be simulated deterministically in space O (S 3=2 ), i.e., BP H SP ACE (S) DSP ACE (S 3=2 ). <p> of proper complexity function is formally defined in [Pap94] and includes most "reasonable" functions, including polynomials, polylogarithmic functions, exponential funtions, etc. 12 performance of exact rather than approximate matrix computations, is not generalized by Theorem 2.1.1.) In recent years, despite considerable progress on deterministic simulations of small space randomized algorithms <ref> [AKS87, BNS89, Nis90, Nis92, NSW92, NZ93] </ref> there has been no general improvement on this space bound. <p> The central result in the area is Nisan's marvelous pseudorandom generator for space-bounded computation <ref> [Nis90] </ref>, which he used to show that RL (i.e., R H SP ACE (log n)) can be simulated by a deterministic algorithm that is simultaneously in polynomial time and O (log 2 n) space. <p> As stated earlier, this algorithm is derived from Nisan's pseudorandom generator construction <ref> [Nis90] </ref>. In what follows, we first examine the general relationship between approximating sub-stochastic matrix exponentiation and constructing pseudorandom generators. Then we present in detail the construction of Nisan's pseudorandom generator and analyze its properties. <p> The arguments here mainly follow Nisan's work in <ref> [Nis90] </ref>. The presentation is self-contained and is a variant of the one given in [Nis90]. In the following discussion, if ff and fi are two strings then fffi denotes their concatenation, and all the probability distributions are assumed to be uniform. <p> The arguments here mainly follow Nisan's work in <ref> [Nis90] </ref>. The presentation is self-contained and is a variant of the one given in [Nis90]. In the following discussion, if ff and fi are two strings then fffi denotes their concatenation, and all the probability distributions are assumed to be uniform. <p> This concludes the proof. 2 Finally we prove the main technical result of Nisan in <ref> [Nis90] </ref>: 40 Lemma 2.6.8 Let m; d; r be integers and * &gt; 0. There is an explicit family fG ~ h j ~ h 2 f0; 1g 2mr g of (m; 2 r )-generators that has the following property: 1.
Reference: [Nis91] <author> N. Nisan. </author> <title> Using hard problems to create pseudorandom generators. </title> <publisher> The MIT Press, </publisher> <year> 1991. </year> <note> (An ACM Distinguished Dissertation) </note>
Reference: [Nis92] <author> N. Nisan. </author> <title> RL SC. </title> <booktitle> In Proc. of ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 619-623, </pages> <year> 1992. </year>
Reference-contexts: For space-bounded randomized computation, on the other hand, the main approach to derandomization which has been proven effective is the application of pseudorandom generators (see e.g. <ref> [Nis92, NSW92, NZ93, SZ95] </ref>). 4 1.2 Explicit Constructions Explicit constructions are also called efficient constructions. Generally, the success of reducing randomness by way of constructing combinatorial objects does not merely depend on the existence of the objects, but mainly depends on the efficiency of the constructions. <p> of proper complexity function is formally defined in [Pap94] and includes most "reasonable" functions, including polynomials, polylogarithmic functions, exponential funtions, etc. 12 performance of exact rather than approximate matrix computations, is not generalized by Theorem 2.1.1.) In recent years, despite considerable progress on deterministic simulations of small space randomized algorithms <ref> [AKS87, BNS89, Nis90, Nis92, NSW92, NZ93] </ref> there has been no general improvement on this space bound. <p> Given x and y, the operation of the algorithm is completely deterministic. We will refer to this method of using random bits as "o*ine randomization". This paradigm has been used implicitly in previous work on derandomizing randomized algorithms (see e.g. <ref> [Nis92, NZ93] </ref>), here we make it explicit in order to clarify certain subtleties. We think of an o*ine randomized algorithm A as a function A (x; y) of two input strings: x the "true" input and y, the "o*ine random input".
Reference: [Nis93] <author> N. Nisan. </author> <title> On read-once vs. multiple access to randomness in Logspace. </title> <journal> Theoretical Computer Science, </journal> <volume> 107 </volume> <pages> 135-144, </pages> <year> 1993. </year>
Reference: [Nis96] <author> N. Nisan. </author> <title> Extracting Randomness: How and Why. </title> <booktitle> In Proc. of 11th Annual Conference on Computational Complexity, </booktitle> <pages> pp. 44-58, </pages> <year> 1996. </year>
Reference-contexts: The application of this approach gives extremely high success probability using only a moderate number of random bits. We refer the reader to <ref> [Nis96] </ref> for a survey on this method. With respect to polynomial time randomized computation, there are two fundamental approaches to derandomization: the method of conditional probabilities [ES73, Spe87, Rag88] and constructing small-sized sample spaces [KW84, Lub85, ABI86, AKS87, NN90]. <p> The details of these improvements can be derived from the corresponding original papers by plugging in our construction, and will not be given here. We refer the reader to a comprehensive survey paper by Nisan <ref> [Nis96] </ref>. 3.1.1 The Equivalence of RP and Strong-RP Definition 3.1.1 Random polynomial time (RP) is the set of languages L f0; 1g fl such that there is a deterministic polynomial-time Turing machine M L (; ) for which x 2 L ! P r [M L (x; y) accepts] &gt; 1=2;
Reference: [NSW92] <author> N. Nisan, E. Szemeredi and A. Wigderson. </author> <title> Undirected Connectivity in O(log 1:5 n) Space. </title> <booktitle> In Proc. of 30th Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 248-253, </pages> <year> 1992. </year>
Reference-contexts: For space-bounded randomized computation, on the other hand, the main approach to derandomization which has been proven effective is the application of pseudorandom generators (see e.g. <ref> [Nis92, NSW92, NZ93, SZ95] </ref>). 4 1.2 Explicit Constructions Explicit constructions are also called efficient constructions. Generally, the success of reducing randomness by way of constructing combinatorial objects does not merely depend on the existence of the objects, but mainly depends on the efficiency of the constructions. <p> Our result includes as a special case the result due to Nisan, Szemeredi and Wigderson <ref> [NSW92] </ref> that undirected graph connectivity can be computed in space O (log 3=2 n). In Chapter 3 we examine the connection between deterministic amplification and the disperser construction. <p> of proper complexity function is formally defined in [Pap94] and includes most "reasonable" functions, including polynomials, polylogarithmic functions, exponential funtions, etc. 12 performance of exact rather than approximate matrix computations, is not generalized by Theorem 2.1.1.) In recent years, despite considerable progress on deterministic simulations of small space randomized algorithms <ref> [AKS87, BNS89, Nis90, Nis92, NSW92, NZ93] </ref> there has been no general improvement on this space bound. <p> Using Nisan's generator, Nisan, Szemeredi, Wigderson <ref> [NSW92] </ref> showed that undirected (s; t) connectivity, which is in RL [AKLLR79] and is complete for the complexity class SL [LP82], can be computed in DSP ACE (log 3=2 n). It was this result that motivated our research that we present in this work.
Reference: [NT95] <author> N. Nisan and A. Ta-Shma. </author> <title> Symmetric logspace is closed under complement. </title> <booktitle> In Proc. of 27th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 140-146, </pages> <year> 1995. </year>
Reference: [NW88] <author> N. Nisan and A. Wigderson. </author> <title> Hardness vs. randomness. </title> <booktitle> In Proc. of 29th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 2-12, </pages> <year> 1988. </year>
Reference-contexts: The objective of deterministic amplification is to achieve high success probability while minimizing the number of random bits, and the goal of derandomization is to eliminate randomness from computation. There are two basic methods that are employed in deterministic amplification. The first method is to construct pseudorandom generators <ref> [Yao82, BM84, NW88, BNS89] </ref>, which are functions that map short random seeds to much longer strings so that any randomized algorithm of a certain type cannot distinguish statistically between the output strings from the generators and the truly random strings. <p> As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well). These include almost all the explicit constructions of pseudorandom generators (e.g. <ref> [NW88, Nis90] </ref>), expanders (e.g. [GG81, LPS86]), dispersers (e.g. [CW89, SSZ95]), extractors (e.g. [NZ93, TaS96]), k-wise independent sample spaces (e.g. [Lub85, ABI86]), small-bias sample spaces (e.g. [NN90, AGHP91]), etc.
Reference: [NZ93] <author> N. Nisan and D. Zuckerman. </author> <title> More Deterministic Simulation in Logspace. </title> <booktitle> In Proc. of ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 235-244, </pages> <year> 1993. </year>
Reference-contexts: We refer the reader to [Sak96] for a survey on the latter subject. The most often used method in deterministic amplification, on the other hand, is to build a type of bipartite expander called dispersers [Sip88] (or its variant called extractors <ref> [NZ93] </ref>). The application of this approach gives extremely high success probability using only a moderate number of random bits. We refer the reader to [Nis96] for a survey on this method. <p> For space-bounded randomized computation, on the other hand, the main approach to derandomization which has been proven effective is the application of pseudorandom generators (see e.g. <ref> [Nis92, NSW92, NZ93, SZ95] </ref>). 4 1.2 Explicit Constructions Explicit constructions are also called efficient constructions. Generally, the success of reducing randomness by way of constructing combinatorial objects does not merely depend on the existence of the objects, but mainly depends on the efficiency of the constructions. <p> Usually, constructions that satisfy this 6 requirement are especially useful for designing or derandomizing parallel algorithms (see e.g. [KW84, Lub85, ABI86, NN90]), and for constructing pseudorandom generators for space bounded computation <ref> [BNS89, Nis90, NZ93, INW94, AW95, ASWZ96] </ref>. As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well). <p> As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well). These include almost all the explicit constructions of pseudorandom generators (e.g. [NW88, Nis90]), expanders (e.g. [GG81, LPS86]), dispersers (e.g. [CW89, SSZ95]), extractors (e.g. <ref> [NZ93, TaS96] </ref>), k-wise independent sample spaces (e.g. [Lub85, ABI86]), small-bias sample spaces (e.g. [NN90, AGHP91]), etc. <p> of proper complexity function is formally defined in [Pap94] and includes most "reasonable" functions, including polynomials, polylogarithmic functions, exponential funtions, etc. 12 performance of exact rather than approximate matrix computations, is not generalized by Theorem 2.1.1.) In recent years, despite considerable progress on deterministic simulations of small space randomized algorithms <ref> [AKS87, BNS89, Nis90, Nis92, NSW92, NZ93] </ref> there has been no general improvement on this space bound. <p> Given x and y, the operation of the algorithm is completely deterministic. We will refer to this method of using random bits as "o*ine randomization". This paradigm has been used implicitly in previous work on derandomizing randomized algorithms (see e.g. <ref> [Nis92, NZ93] </ref>), here we make it explicit in order to clarify certain subtleties. We think of an o*ine randomized algorithm A as a function A (x; y) of two input strings: x the "true" input and y, the "o*ine random input". <p> For this discussion, let us assume V = f0; 1g n ; n = log N and W = f0; 1g m ; m = log M , and N; M; T are related as they are in the Main Theorem. Building on the ideas developed in <ref> [NZ93] </ref> and [SZ94], our construction G D = (V; W; E) of an (N; M; T )-disperser with degree polylogarithmic in N is obtained by composing two bipartite graphs. Let Z = f0; 1g sn where s = a log n for some constant a. <p> The family F C of functions mapping Z to W that specifies carrier G C is obtained by adjusting parameters in the "block-wise extractor" as presented in [SZ94], which is in turn an improvement on a similar construction in <ref> [NZ93] </ref>. Generally speaking, a block-wise extractor is a function taking two input strings z and y such that if z comes from a block-wise source and y from a pure random source, then the distribution induced on the output of the function is nearly uniform. <p> Intuitively, to convert an arbitrary distribution D into a block-wise source we want to "chop up" the sequence of bits from D into a sequence of blocks so that each block has a sufficient amount of information relative to D. As in <ref> [NZ93] </ref>, the good bit indicator is an appropriate way to measure the dispersal of information within any string from the source. <p> The proof we present is a variant of the correctness proof of the extractor (Function C) in <ref> [NZ93] </ref>. In Section 3.4.2 we defined the parameters t s = 32 and q = p s = 4t s + d6 log ne (thus q = O (log n)).
Reference: [Pap94] <author> C. Papadimitriou. </author> <title> Computational Complexity. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: This model, in particular, contains N SP ACE (S (n)). Their result, which requires the 1 The notion of proper complexity function is formally defined in <ref> [Pap94] </ref> and includes most "reasonable" functions, including polynomials, polylogarithmic functions, exponential funtions, etc. 12 performance of exact rather than approximate matrix computations, is not generalized by Theorem 2.1.1.) In recent years, despite considerable progress on deterministic simulations of small space randomized algorithms [AKS87, BNS89, Nis90, Nis92, NSW92, NZ93] there has been
Reference: [Rab80] <author> M. Rabin. </author> <title> Probabilistic algorithm for testing primality. </title> <journal> J. of Number Theory, </journal> <volume> 12 </volume> <pages> 128-138, </pages> <year> 1980. </year>
Reference-contexts: The use of randomization has played an important role in both complexity theory and algorithm design. Its apparent success in application has motivated a substantial effort to understand how much power randomness can provide over determinism. For many problems, a randomized algorithm is by far faster (e.g. primality testing <ref> [SS77, Rab80, AH87] </ref>), more parallel (e.g. perfect matching construction [KUW86, MVV87]), more space-efficient (e.g. undirected graph connectivity [AKLLR79]), or simpler (e.g. the min-cut problem [Kar93]) than any known deterministic algorithm.
Reference: [Rag88] <author> P. Raghavan. </author> <title> Probabilistic construction of deterministic algorithms: approximating packing integer programs. </title> <journal> J. Comp. and Syst. Sci., </journal> <volume> 37 </volume> <pages> 130-143, </pages> <year> 1988. </year>
Reference-contexts: The application of this approach gives extremely high success probability using only a moderate number of random bits. We refer the reader to [Nis96] for a survey on this method. With respect to polynomial time randomized computation, there are two fundamental approaches to derandomization: the method of conditional probabilities <ref> [ES73, Spe87, Rag88] </ref> and constructing small-sized sample spaces [KW84, Lub85, ABI86, AKS87, NN90]. <p> On the other hand, explicit constructions obtained via using the method of conditional probabilities (e.g. <ref> [Rag88, SZ96] </ref>) or solving linear constraints (e.g. [Sch92, KK94]) typically satisfy the first requirement but not necessarily the second. 1.3 The Organization of the Thesis So far we have summarized the general approaches to reducing randomness in computation via explicit constructions. <p> modifications to make the previous definitions and statements work: we map 1 to 0, -1 to 1 and change the product correspondingly to the sum modulo 2. 4.2.3 The Method of Conditional Probabilities The method of conditional probabilities, which was introduced by Erdos and Selfridge [ES73], Spencer [Spe87], and Raghavan <ref> [Rag88] </ref>, is a powerful tool in derandomization. In this 86 section, we review a basic framework for this method in terms of the conditional expectations. For a set S and a positive integer n, let v S n . We call S the sample range of . <p> Nevertheless, in many circumstances, direct computations of conditional expectations (or conditional probabilities) are not easy. One effective technique to overcome 87 this difficulty that has been proven successful in applications is by way of employing pessimistic estimators, which was first introduced by Raghavan <ref> [Rag88] </ref>. We describe below a modified version of pessimistic estimators due to Fundia [Fun94] (see also [Sak94]). <p> We want to apply the method of conditional probabilities to Z and construct such a desired point in . 92 Unfortunately, there seems to be no easy way to directly compute the conditional expectation of Z. To overcome this difficulty, we adopt the idea of pessimistic estimators <ref> [Rag88, Fun94] </ref> and introduce another random variable W J to estimate each Z J , where W J is defined as W J = e (*ffi) 2 m (e (*ffi)X J ): P What we would like to see is that the random variable W satisfies the conditions (A), (B) and
Reference: [Sak94] <author> M. Saks. </author> <title> Lecture notes on Random Structures and Algorithms (manuscript). </title> <institution> Applied Math 587, Rutgers University, </institution> <year> 1994. </year>
Reference-contexts: One effective technique to overcome 87 this difficulty that has been proven successful in applications is by way of employing pessimistic estimators, which was first introduced by Raghavan [Rag88]. We describe below a modified version of pessimistic estimators due to Fundia [Fun94] (see also <ref> [Sak94] </ref>). Continuing the above discussion, we suppose that for some given v 1 ; : : : ; v i 2 S, the conditional expectation E [Zjv 1 ; : : : ; v i ] is difficult to compute.
Reference: [Sak96] <author> M. Saks. </author> <title> Randomization and Derandomization in Space-Bounded Computation. </title> <booktitle> In Proc. of 11th Annual Conference on Computational Complexity, </booktitle> <year> 1996. </year>
Reference-contexts: For polynomial time computation, unfortunately, the currently available constructions of pseudorandom generators 3 all rely on certain unproven assumptions. Nevertheless, for space-bounded computation, successful constructions of pseudorandom generators have been obtained. We refer the reader to <ref> [Sak96] </ref> for a survey on the latter subject. The most often used method in deterministic amplification, on the other hand, is to build a type of bipartite expander called dispersers [Sip88] (or its variant called extractors [NZ93]). <p> In this section we give a review of the connection between these two problems and summarize the consequences of our new result. For a general retrospective on the problems and developments in the related subjects of randomized space computation, we refer the reader to the survey by Saks <ref> [Sak96] </ref>. 10 A randomized space S (n) machine is a nondeterministic Turing machine that runs in space S (n) on any input of length n, and has two nondeterministic choices at any stage of the computation depending on an unbiased coin-flip.
Reference: [SSZ95] <author> M. Saks, A. Srinivasan and S. Zhou. </author> <title> Explicit dispersers with polylog degree. </title> <booktitle> In Proc. of 27th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 479-488, </pages> <year> 1995. </year>
Reference-contexts: As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well). These include almost all the explicit constructions of pseudorandom generators (e.g. [NW88, Nis90]), expanders (e.g. [GG81, LPS86]), dispersers (e.g. <ref> [CW89, SSZ95] </ref>), extractors (e.g. [NZ93, TaS96]), k-wise independent sample spaces (e.g. [Lub85, ABI86]), small-bias sample spaces (e.g. [NN90, AGHP91]), etc. <p> We present an essentially optimal error-correcting communication protocol for this problem. The results in Chapter 2 and Chapter 4 appeared in [SZ95] and [SZ96], respectively, and are joint work with Michael Saks. The results in Chapter 3 appeared in <ref> [SSZ95] </ref> and are joint work with Michael Saks and Aravind Srinivasan. 9 Chapter 2 BP H SPACE (S) DSPACE (S 3=2 ) 2.1 Matrix Repeated Squaring and Randomized Space Computation For a nonnegative integer r, the repeated squaring function fl (r) is defined on square matrices M by fl (0) (M
Reference: [SZ95] <author> M. Saks and S. Zhou. </author> <booktitle> RSP ACE(S) DSP ACE(S 3=2 ). In Proc. of 36th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 344-353, </pages> <year> 1995. </year> <month> 105 </month>
Reference-contexts: For space-bounded randomized computation, on the other hand, the main approach to derandomization which has been proven effective is the application of pseudorandom generators (see e.g. <ref> [Nis92, NSW92, NZ93, SZ95] </ref>). 4 1.2 Explicit Constructions Explicit constructions are also called efficient constructions. Generally, the success of reducing randomness by way of constructing combinatorial objects does not merely depend on the existence of the objects, but mainly depends on the efficiency of the constructions. <p> We present an essentially optimal error-correcting communication protocol for this problem. The results in Chapter 2 and Chapter 4 appeared in <ref> [SZ95] </ref> and [SZ96], respectively, and are joint work with Michael Saks.
Reference: [SZ96] <author> M. Saks and S. Zhou. </author> <title> Sample spaces with small bias on neighborhoods and error-correcting communication protocols. </title> <type> Manuscript, </type> <year> 1996. </year>
Reference-contexts: On the other hand, explicit constructions obtained via using the method of conditional probabilities (e.g. <ref> [Rag88, SZ96] </ref>) or solving linear constraints (e.g. [Sch92, KK94]) typically satisfy the first requirement but not necessarily the second. 1.3 The Organization of the Thesis So far we have summarized the general approaches to reducing randomness in computation via explicit constructions. <p> We present an essentially optimal error-correcting communication protocol for this problem. The results in Chapter 2 and Chapter 4 appeared in [SZ95] and <ref> [SZ96] </ref>, respectively, and are joint work with Michael Saks.
Reference: [San87] <author> M. Santha. </author> <title> On Using Deterministic Functions in Probabilistic Algorithms. </title> <journal> Information and Computation, </journal> <volume> 74(3) </volume> <pages> 241-249, </pages> <year> 1987. </year>
Reference-contexts: In this chapter we investigate the problem of efficiently constructing OR-dispersers with small degree. For convenience, we will use the term "disperser" instead of "OR-disperser" unless otherwise specified. It was proved in <ref> [San87] </ref> by a probabilistic argument that there exist (N; M; T )- dispersers for N &gt; T = M with degree at most log 2 N + 2. <p> takes time m O (log m) , where m is the number of random bits needed by the original RP algorithm. (This result has been improved recently by Ta-Shma in [TaS96], where he presented a BPP simulation that uses time m O (log (k) m) for any fixed k.) In <ref> [San87, Sip88, CW89] </ref> it was observed that the black-box simulation described above can be defined by a sequence G m = (V m ; W m ; E m ) of bipartite multigraphs, one for each m, where V m = f0; 1g R (m) and W m = f0; 1g
Reference: [SV86] <author> M. Santha and U. Vazirani. </author> <title> Generating Quasi-Random Sequences from Slightly Random Sources. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 33 </volume> <pages> 75-87, </pages> <year> 1986. </year>
Reference-contexts: One problem that is closely related to deterministic amplification is to design randomized algorithms that are robust under the presence of imperfect random sources. This problem itself is an important issue in randomized computation and has been studied extensively during the past decade (see e.g. <ref> [SV86, CG88, Zuc90] </ref>). Using the techniques developed in the study of computing with imperfect sources, we give an improved construction of a family of dispersers that can be applied to designing randomized polynomial time algorithms that achieve maximal robustness. <p> However, for more general faulty sources, it can be shown (see e.g. <ref> [SV86] </ref>) that to construct such a direct conversion f is impossible. On the other hand, the following broader idea of conversion (introduced in [VV85, Vaz86]) works for simulating randomized algorithms: Suppose the randomized computation C we wish to simulate needs m random bits. <p> The high-level structure of this simulation is common to all subsequent work in this area. We refer to such a simulation as a "black-box" simulation. Applying this framework, efficient simulations of RP and BPP under various models of weak sources have been extensively studied. For example, Santha and Vazirani <ref> [SV86] </ref> studied the class of weak sources called "slightly random sources", which was further examined in [VV85, Vaz86, Vaz87a, Vaz87b]. A more general model "PRB-sources" is considered later by Chor and Goldreich [CG88]. In [Zuc90, Zuc91], Zuckerman introduced the model of ffi-sources which generalizes all the previous models.
Reference: [Sav70] <author> W.J. Savitch. </author> <title> Relationships between nondeterministic and deterministic space complexities. </title> <journal> J. Comp. and Syst. Sci., </journal> <volume> 4(2) </volume> <pages> 177-192, </pages> <year> 1970. </year>
Reference-contexts: This improves the best previously known result that such algorithms have deterministic space O (S 2 ) simulations which, for one-sided error algorithms, follows from Savitch's Theorem <ref> [Sav70] </ref> and for two-sided error algorithms follows by reduction to recursive matrix exponentiation. Our result includes as a special case the result due to Nisan, Szemeredi and Wigderson [NSW92] that undirected graph connectivity can be computed in space O (log 3=2 n). <p> In fact, the weaker containment for R H SP ACE (S (n)) also follows from Savitch's theorem <ref> [Sav70] </ref> N SP ACE (S (n)) DSP ACE (S (n) 2 ). (Independently, Borodin, Cook and Pippenger [BCP83] and Jung [Jun81] (see also [AO94]) showed that the same DSP ACE (S (n) 2 ) bound can be achieved in Gill's [Gil77] stronger model of randomized space computation in which cyclic configuration
Reference: [Sch92] <author> L. Schulman. </author> <title> Sample spaces uniform on neighborhoods. </title> <booktitle> In Proc. of 24th ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 17-25, </pages> <year> 1992. </year>
Reference-contexts: On the other hand, explicit constructions obtained via using the method of conditional probabilities (e.g. [Rag88, SZ96]) or solving linear constraints (e.g. <ref> [Sch92, KK94] </ref>) typically satisfy the first requirement but not necessarily the second. 1.3 The Organization of the Thesis So far we have summarized the general approaches to reducing randomness in computation via explicit constructions. <p> This approach has been widely used and proven effective in many applications (see e.g. <ref> [KW84, Lub85, ABI86, BR89, MNN89, NN90, Alo91, Sch92, KM93, KK94] </ref>). Along the line of this approach, the construction of k-wise independent sample spaces is one of the earliest studied problems. <p> An efficient construction of k-wise independent sample spaces of size n bk=2c was presented in [ABI86] (see also [Lub85]), whose size basically matches the lower bound given in [CGHFRS85] (see also [ABI86, KM94]). In a more general setting, Schulman <ref> [Sch92] </ref> considered the problem of constructing sample spaces uniform over a family of subsets of f1; 2; : : :; ng (neighborhoods), i.e., the distribution induced on the random variables in any particular neighborhood in the family is uniformly independent. <p> In [EGLNV92], constructions of sample spaces with small bias for general independent distributions were studied. Koller and Megiddo in [KM93] introduced the framework of constructing sample spaces that satisfy a set of probability constraints, which generalized the construction approach used in <ref> [Sch92] </ref>. This method was further extended by Karger and Koller in [KK94] where they showed how to deal with the more general expectation constraints. In the latter work, an N C algorithm for constructing sample spaces that approximate general independent distributions with relative error was shown. <p> Now the corollary together with Theorem 4.3.1 clearly give us Theorem 4.4.1. Constructing (n; F )-universal sets is useful for exhaustively testing combinatorial logic circuits in which each functional component depends only on a subset of inputs (see [SB88]). Schulman in <ref> [Sch92] </ref> gave an explicit construction of (n; F )-universal sets of size O (d2 (F) ), where d denotes the maximum number of neighborhoods containing any particular element. The size of our construction is smaller than that of [Sch92] when d &gt; c log jfl (F )j for some constant c. <p> Schulman in <ref> [Sch92] </ref> gave an explicit construction of (n; F )-universal sets of size O (d2 (F) ), where d denotes the maximum number of neighborhoods containing any particular element. The size of our construction is smaller than that of [Sch92] when d &gt; c log jfl (F )j for some constant c. Theorem 4.4.1 in particular gives a polynomial time construction of an (n; ( [n] universal set of size O (2 k k log n) for fixed k, which is optimal following the lower bound argument in [SB88].
Reference: [SB88] <author> G. Seroussi and N. Bshouty. </author> <title> Vector sets for exhaustive testing of logic circuits. </title> <journal> IEEE Trans. on Info. Theory, </journal> <volume> 34(3) </volume> <pages> 513-522, </pages> <year> 1988. </year>
Reference-contexts: Now the corollary together with Theorem 4.3.1 clearly give us Theorem 4.4.1. Constructing (n; F )-universal sets is useful for exhaustively testing combinatorial logic circuits in which each functional component depends only on a subset of inputs (see <ref> [SB88] </ref>). Schulman in [Sch92] gave an explicit construction of (n; F )-universal sets of size O (d2 (F) ), where d denotes the maximum number of neighborhoods containing any particular element. <p> Theorem 4.4.1 in particular gives a polynomial time construction of an (n; ( [n] universal set of size O (2 k k log n) for fixed k, which is optimal following the lower bound argument in <ref> [SB88] </ref>. Alon [Alo86] showed an explicit construction of (n; ( [n] k ))-universal sets of size log n2 O (k 2 ) for the case k is fixed. In [NN90] and [ABNNR92], nearly optimal constructions of size log n 2 O (k) were given.
Reference: [Sip88] <author> M. Sipser. Expanders, </author> <title> Randomness, or Time versus Space. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 36 </volume> <pages> 379-383, </pages> <year> 1988. </year>
Reference-contexts: Nevertheless, for space-bounded computation, successful constructions of pseudorandom generators have been obtained. We refer the reader to [Sak96] for a survey on the latter subject. The most often used method in deterministic amplification, on the other hand, is to build a type of bipartite expander called dispersers <ref> [Sip88] </ref> (or its variant called extractors [NZ93]). The application of this approach gives extremely high success probability using only a moderate number of random bits. We refer the reader to [Nis96] for a survey on this method. <p> As a result, we show that every randomized polynomial time algorithm has an extremely efficient amplification scheme. In particular, we resolve a conjecture posed by Sipser <ref> [Sip88] </ref> that the complexity class Strong Randomized Polynomial Time (Strong-RP) is equivalent to Randomized Polynomial Time (RP). In our final chapter, Chapter 4, we study the problem of constructing sample spaces with small bias on designated sets of bit positions (neighborhoods). <p> So we have Theorem 2.7.1 There is a deterministic algorithm for AME with space complexity O (s log 1=2 p). 44 Chapter 3 Explicit Dispersers with Polylogarithmic Degree 3.1 Main Result and Applications A disperser is a type of expander which was first introduced by Sipser in <ref> [Sip88] </ref>. Co-hen and Wigderson [CW89] classified dispersers into two types: OR-dispersers and MAJORITY-dispersers. <p> We call W x L = fy 2 f0; 1g m jM L (x; y) acceptsg the witness set of M L on input x, where m is the number of random bits used by M L on inputs of length jxj. Sipser <ref> [Sip88] </ref> defined the complexity class strong random polynomial time (Strong-RP) to be the class of languages L for which there is an RP machine M L (; ) and a real number 0 &lt; &lt; 1 such that on input a string x 2 L of (any) length n, M L <p> The construction we give here is sufficient for Sipser's purposes and so we obtain Theorem 3.1.1 RP = Strong-RP. Proof: The argument in this proof is essentially the same as in Sipser's original paper <ref> [Sip88] </ref>. We show the proof here for later reference. By definition, Strong-RP RP. We show that RP Strong-RP. 47 Suppose we have an RP machine M L that needs m random bits on an input x 2 L of length n, for some m polynomial in n. <p> takes time m O (log m) , where m is the number of random bits needed by the original RP algorithm. (This result has been improved recently by Ta-Shma in [TaS96], where he presented a BPP simulation that uses time m O (log (k) m) for any fixed k.) In <ref> [San87, Sip88, CW89] </ref> it was observed that the black-box simulation described above can be defined by a sequence G m = (V m ; W m ; E m ) of bipartite multigraphs, one for each m, where V m = f0; 1g R (m) and W m = f0; 1g
Reference: [SS77] <author> R. Solovay and V. Strassen. </author> <title> A fast Monte-Carlo test for primality. </title> <journal> SIAM J. on Computing, </journal> <volume> 6 </volume> <pages> 84-85, </pages> <year> 1977. </year>
Reference-contexts: The use of randomization has played an important role in both complexity theory and algorithm design. Its apparent success in application has motivated a substantial effort to understand how much power randomness can provide over determinism. For many problems, a randomized algorithm is by far faster (e.g. primality testing <ref> [SS77, Rab80, AH87] </ref>), more parallel (e.g. perfect matching construction [KUW86, MVV87]), more space-efficient (e.g. undirected graph connectivity [AKLLR79]), or simpler (e.g. the min-cut problem [Kar93]) than any known deterministic algorithm.
Reference: [Spe87] <author> J. Spencer. </author> <title> Ten Lectures on the Probabilistic Method, </title> <address> SIAM(Philadelphia), </address> <year> 1987. </year>
Reference-contexts: The application of this approach gives extremely high success probability using only a moderate number of random bits. We refer the reader to [Nis96] for a survey on this method. With respect to polynomial time randomized computation, there are two fundamental approaches to derandomization: the method of conditional probabilities <ref> [ES73, Spe87, Rag88] </ref> and constructing small-sized sample spaces [KW84, Lub85, ABI86, AKS87, NN90]. <p> apply the following modifications to make the previous definitions and statements work: we map 1 to 0, -1 to 1 and change the product correspondingly to the sum modulo 2. 4.2.3 The Method of Conditional Probabilities The method of conditional probabilities, which was introduced by Erdos and Selfridge [ES73], Spencer <ref> [Spe87] </ref>, and Raghavan [Rag88], is a powerful tool in derandomization. In this 86 section, we review a basic framework for this method in terms of the conditional expectations. For a set S and a positive integer n, let v S n . We call S the sample range of .
Reference: [SZ94] <author> A. Srinivasan and D. Zuckerman. </author> <title> Computing with Very Weak Random Sources. </title> <booktitle> In Proc. of IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 264-275, </pages> <year> 1994. </year> <note> Full version available as Technical Report TRA4/96, </note> <institution> Department of Information Systems and Computer Science, National University of Singapore, </institution> <month> April </month> <year> 1996. </year>
Reference-contexts: In fact, most of the previous disperser constructions are implicit in the work of simulating randomized algorithms using weak sources. The best previously known constructions are due to Zuckerman [Zuc91, Zuc96], who achieved degree polylogarithmic in N if N = T O (1) , and Srinivasan and Zuckerman <ref> [SZ94] </ref>, whose construction works for N = 2 polylog (T ) but requires degree (log N ) O (loglog N) . In recent work, Ta-Shma [TaS96] improved the degree of the construction in [SZ94] to (log N ) O (log (k) log N) for any fixed integer k, where log (k) <p> who achieved degree polylogarithmic in N if N = T O (1) , and Srinivasan and Zuckerman <ref> [SZ94] </ref>, whose construction works for N = 2 polylog (T ) but requires degree (log N ) O (loglog N) . In recent work, Ta-Shma [TaS96] improved the degree of the construction in [SZ94] to (log N ) O (log (k) log N) for any fixed integer k, where log (k) denotes the logarithm to the base 2 iterated k times. In this chapter, we give an improved construction of an (N; M; T )-disperser. <p> It is worth noticing that although the constructions of [Zuc91], <ref> [SZ94] </ref> and [TaS96] do not give polylogarithmic degree, they do give MAJORITY-dispersers. Unfortunately, we could not strengthen our construction to give a MAJORITY-disperser. <p> There are other consequences of our disperser construction. For example, it gives improvements on the expander construction and the consequent applications given in [WZ93], on the the hardness results of approximating the clique function <ref> [Zuc93, SZ94] </ref>, and on the results for a problem in 46 data structures: implicit O (1) probe search [FN93, Zuc91]. These consequences were each observed by previous researchers, and provided much of the motivation for the search for good dispersers. <p> The question is: for each &gt; 0, is there a polynomial-time simulation of BPP, or even RP, that works for all -minimally random sources? The previously best known simulation for RP with -minimally random sources is due to <ref> [SZ94] </ref>, which takes time m O (log m) , where m is the number of random bits needed by the original RP algorithm. (This result has been improved recently by Ta-Shma in [TaS96], where he presented a BPP simulation that uses time m O (log (k) m) for any fixed k.) <p> For this discussion, let us assume V = f0; 1g n ; n = log N and W = f0; 1g m ; m = log M , and N; M; T are related as they are in the Main Theorem. Building on the ideas developed in [NZ93] and <ref> [SZ94] </ref>, our construction G D = (V; W; E) of an (N; M; T )-disperser with degree polylogarithmic in N is obtained by composing two bipartite graphs. Let Z = f0; 1g sn where s = a log n for some constant a. <p> Carrier G C is similarly specified by a family F C of functions. The family F C of functions mapping Z to W that specifies carrier G C is obtained by adjusting parameters in the "block-wise extractor" as presented in <ref> [SZ94] </ref>, which is in turn an improvement on a similar construction in [NZ93]. <p> Generally speaking, a block-wise extractor is a function taking two input strings z and y such that if z comes from a block-wise source and y from a pure random source, then the distribution induced on the output of the function is nearly uniform. By modifying the construction in <ref> [SZ94] </ref>, we obtain a block-wise extractor C such that on input a string z coming from any block-wise source on Z with s equal-sized blocks and with block-wise min-entropy nearly log T , and a purely random string y of length O (log n), the distribution induced on C (z; y) <p> The function C is a straightforward modification of the block-wise extractor of <ref> [SZ94] </ref>. To describe the construction, we need the following lemma which is derived from the improved Leftover Hash Lemma in [SZ94]: Lemma 3.4.1 Let t n be nonnegative integers. <p> The function C is a straightforward modification of the block-wise extractor of <ref> [SZ94] </ref>. To describe the construction, we need the following lemma which is derived from the improved Leftover Hash Lemma in [SZ94]: Lemma 3.4.1 Let t n be nonnegative integers. <p> This is obtained from the improved Leftover Hash Lemma of <ref> [SZ94] </ref>, by setting k = t=8 and * = 2 1k . 2 65 The following reformulation is more convenient for our purposes.
Reference: [Sze88] <author> R. Szelepcsenyi. </author> <title> The method of forced enumeration for nondeterministic automata. </title> <journal> Acta Informatica. </journal> <volume> 26 </volume> <pages> 279-284, </pages> <year> 1988. </year>
Reference: [TaS96] <author> A. Ta-Shma. </author> <title> On extracting randomness from weak random sources. </title> <booktitle> In Proc. of ACM Symposium on Theory of Computing, </booktitle> <year> 1996. </year>
Reference-contexts: As a matter of fact, most of the known explicit constructions satisfy the second requirement (and thus satisfy the first as well). These include almost all the explicit constructions of pseudorandom generators (e.g. [NW88, Nis90]), expanders (e.g. [GG81, LPS86]), dispersers (e.g. [CW89, SSZ95]), extractors (e.g. <ref> [NZ93, TaS96] </ref>), k-wise independent sample spaces (e.g. [Lub85, ABI86]), small-bias sample spaces (e.g. [NN90, AGHP91]), etc. <p> In recent work, Ta-Shma <ref> [TaS96] </ref> improved the degree of the construction in [SZ94] to (log N ) O (log (k) log N) for any fixed integer k, where log (k) denotes the logarithm to the base 2 iterated k times. In this chapter, we give an improved construction of an (N; M; T )-disperser. <p> It is worth noticing that although the constructions of [Zuc91], [SZ94] and <ref> [TaS96] </ref> do not give polylogarithmic degree, they do give MAJORITY-dispersers. Unfortunately, we could not strengthen our construction to give a MAJORITY-disperser. Nevertheless, the construction of a good OR-disperser is itself an interesting combinatorial problem and, as we will see, has significant applications to both complexity theory and randomized algorithm design. <p> all -minimally random sources? The previously best known simulation for RP with -minimally random sources is due to [SZ94], which takes time m O (log m) , where m is the number of random bits needed by the original RP algorithm. (This result has been improved recently by Ta-Shma in <ref> [TaS96] </ref>, where he presented a BPP simulation that uses time m O (log (k) m) for any fixed k.) In [San87, Sip88, CW89] it was observed that the black-box simulation described above can be defined by a sequence G m = (V m ; W m ; E m ) of
Reference: [Vaz86] <author> U. Vazirani. </author> <title> Randomness, Adversaries and Computation. </title> <type> Ph.D. Thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1986. </year>
Reference-contexts: However, for more general faulty sources, it can be shown (see e.g. [SV86]) that to construct such a direct conversion f is impossible. On the other hand, the following broader idea of conversion (introduced in <ref> [VV85, Vaz86] </ref>) works for simulating randomized algorithms: Suppose the randomized computation C we wish to simulate needs m random bits. The simulation first requests R = R (m) bits from the faulty source. <p> Applying this framework, efficient simulations of RP and BPP under various models of weak sources have been extensively studied. For example, Santha and Vazirani [SV86] studied the class of weak sources called "slightly random sources", which was further examined in <ref> [VV85, Vaz86, Vaz87a, Vaz87b] </ref>. A more general model "PRB-sources" is considered later by Chor and Goldreich [CG88]. In [Zuc90, Zuc91], Zuckerman introduced the model of ffi-sources which generalizes all the previous models. Let D be a probability distribution on a set X. <p> The construction uses time polynomial in n and jfl (F )j. To prove the theorem we need the following fact which was shown in [NN90] (whose proof in turn is based on a lemma in <ref> [Vaz86] </ref>): Proposition 4.4.2 If v f0; 1g k is 2 k1 -biased, then f0; 1g k . Corollary 4.4.1 If v f0; 1g n is 2 (F)1 -biased with respect to fl (F ), then is (n; F )-universal.
Reference: [Vaz87a] <author> U. Vazirani. </author> <title> Efficiency Considerations in Using Semi-Random Sources. </title> <booktitle> In Proc. of ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 160-168, </pages> <year> 1987. </year>
Reference-contexts: Applying this framework, efficient simulations of RP and BPP under various models of weak sources have been extensively studied. For example, Santha and Vazirani [SV86] studied the class of weak sources called "slightly random sources", which was further examined in <ref> [VV85, Vaz86, Vaz87a, Vaz87b] </ref>. A more general model "PRB-sources" is considered later by Chor and Goldreich [CG88]. In [Zuc90, Zuc91], Zuckerman introduced the model of ffi-sources which generalizes all the previous models. Let D be a probability distribution on a set X.
Reference: [Vaz87b] <author> U. Vazirani. </author> <title> Strong Communication Complexity or Generating Quasi-Random Sequences from Two Communicating Semi-Random Sources. </title> <journal> Combinatorica, </journal> <volume> 7(4) </volume> <pages> 375-392, </pages> <year> 1987. </year>
Reference-contexts: Applying this framework, efficient simulations of RP and BPP under various models of weak sources have been extensively studied. For example, Santha and Vazirani [SV86] studied the class of weak sources called "slightly random sources", which was further examined in <ref> [VV85, Vaz86, Vaz87a, Vaz87b] </ref>. A more general model "PRB-sources" is considered later by Chor and Goldreich [CG88]. In [Zuc90, Zuc91], Zuckerman introduced the model of ffi-sources which generalizes all the previous models. Let D be a probability distribution on a set X.
Reference: [VV85] <author> U. Vazirani and V. Vazirani. </author> <title> Random Polynomial Time is Equal to Slightly-Random Polynomial Time. </title> <booktitle> In Proc. of IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 417-428, </pages> <year> 1985. </year> <month> 106 </month>
Reference-contexts: However, for more general faulty sources, it can be shown (see e.g. [SV86]) that to construct such a direct conversion f is impossible. On the other hand, the following broader idea of conversion (introduced in <ref> [VV85, Vaz86] </ref>) works for simulating randomized algorithms: Suppose the randomized computation C we wish to simulate needs m random bits. The simulation first requests R = R (m) bits from the faulty source. <p> Applying this framework, efficient simulations of RP and BPP under various models of weak sources have been extensively studied. For example, Santha and Vazirani [SV86] studied the class of weak sources called "slightly random sources", which was further examined in <ref> [VV85, Vaz86, Vaz87a, Vaz87b] </ref>. A more general model "PRB-sources" is considered later by Chor and Goldreich [CG88]. In [Zuc90, Zuc91], Zuckerman introduced the model of ffi-sources which generalizes all the previous models. Let D be a probability distribution on a set X.
Reference: [Wig92] <author> A. Wigderson. </author> <title> The complexity of graph connectivity. </title> <booktitle> Mathematical Foundations of Computer Science: Proceedings, 17th Symposium, Lecture Notes in Computer Science 629 </booktitle> <pages> 112-132, </pages> <year> 1992. </year>
Reference: [WZ93] <author> A. Wigderson and D. Zuckerman. </author> <title> Expanders that Beat the Eigenvalue Bound: Explicit Construction and Applications. </title> <booktitle> In Proc. of ACM Symposium on Theory of Computing, </booktitle> <pages> pp. 245-251, </pages> <year> 1993. </year>
Reference-contexts: There are other consequences of our disperser construction. For example, it gives improvements on the expander construction and the consequent applications given in <ref> [WZ93] </ref>, on the the hardness results of approximating the clique function [Zuc93, SZ94], and on the results for a problem in 46 data structures: implicit O (1) probe search [FN93, Zuc91].
Reference: [Yao79] <author> A. C-C Yao. </author> <title> Some complexity questions related to distributive computing. </title> <booktitle> In Proc. of 11th ACM Symposium on Theory of Computing, </booktitle> <pages> pp 209-213, </pages> <year> 1979. </year>
Reference-contexts: The goal is to mininize the communication. The error-detecting case of this problem is a natrual variant of the equality problem in the study of communication complexity (see e.g. <ref> [Yao79] </ref>), in which A and B have unlimited computation power and try to tell whether or not x and y are the same (using the above language, F contains all the non-empty subsets of f1; 2; : : : ; ng). <p> The theorem clearly leads to the best efficient construction of k-wise *-biased sample spaces of size O (log n=* 2 ) for fixed k and polynomially small *. 94 4.4 Applications 4.4.1 Error-Correcting Communication Protocols In the standard model of the communication complexity study <ref> [Yao79] </ref>, there are two parties A and B with unlimited computation power. Given a private input to each party, A and B communicate with each other following a specified protocol to compute a function of both inputs. <p> It has been shown <ref> [Yao79] </ref> that for this problem, the two parties in general cannot do anything better than trivially sending the whole input from one side to the other.
Reference: [Yao82] <author> A. C-C Yao. </author> <title> Theory and applications of trapdoor functions. </title> <booktitle> In Proc. of 23rd IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 80-91, </pages> <year> 1982. </year>
Reference-contexts: The objective of deterministic amplification is to achieve high success probability while minimizing the number of random bits, and the goal of derandomization is to eliminate randomness from computation. There are two basic methods that are employed in deterministic amplification. The first method is to construct pseudorandom generators <ref> [Yao82, BM84, NW88, BNS89] </ref>, which are functions that map short random seeds to much longer strings so that any randomized algorithm of a certain type cannot distinguish statistically between the output strings from the generators and the truly random strings.
Reference: [Zuc90] <author> D. Zuckerman. </author> <title> General Weak Random Sources. </title> <booktitle> In Proc. of IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 534-543, </pages> <year> 1990. </year>
Reference-contexts: One problem that is closely related to deterministic amplification is to design randomized algorithms that are robust under the presence of imperfect random sources. This problem itself is an important issue in randomized computation and has been studied extensively during the past decade (see e.g. <ref> [SV86, CG88, Zuc90] </ref>). Using the techniques developed in the study of computing with imperfect sources, we give an improved construction of a family of dispersers that can be applied to designing randomized polynomial time algorithms that achieve maximal robustness. <p> For example, Santha and Vazirani [SV86] studied the class of weak sources called "slightly random sources", which was further examined in [VV85, Vaz86, Vaz87a, Vaz87b]. A more general model "PRB-sources" is considered later by Chor and Goldreich [CG88]. In <ref> [Zuc90, Zuc91] </ref>, Zuckerman introduced the model of ffi-sources which generalizes all the previous models. Let D be a probability distribution on a set X.
Reference: [Zuc91] <author> D. Zuckerman. </author> <title> Simulating BPP Using a General Weak Random Source. </title> <booktitle> In Proc. of IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pp. 79-89, </pages> <year> 1991. </year> <note> Final version to appear in Algorithmica. </note>
Reference-contexts: In fact, most of the previous disperser constructions are implicit in the work of simulating randomized algorithms using weak sources. The best previously known constructions are due to Zuckerman <ref> [Zuc91, Zuc96] </ref>, who achieved degree polylogarithmic in N if N = T O (1) , and Srinivasan and Zuckerman [SZ94], whose construction works for N = 2 polylog (T ) but requires degree (log N ) O (loglog N) . <p> It is worth noticing that although the constructions of <ref> [Zuc91] </ref>, [SZ94] and [TaS96] do not give polylogarithmic degree, they do give MAJORITY-dispersers. Unfortunately, we could not strengthen our construction to give a MAJORITY-disperser. <p> For example, it gives improvements on the expander construction and the consequent applications given in [WZ93], on the the hardness results of approximating the clique function [Zuc93, SZ94], and on the results for a problem in 46 data structures: implicit O (1) probe search <ref> [FN93, Zuc91] </ref>. These consequences were each observed by previous researchers, and provided much of the motivation for the search for good dispersers. The details of these improvements can be derived from the corresponding original papers by plugging in our construction, and will not be given here. <p> For example, Santha and Vazirani [SV86] studied the class of weak sources called "slightly random sources", which was further examined in [VV85, Vaz86, Vaz87a, Vaz87b]. A more general model "PRB-sources" is considered later by Chor and Goldreich [CG88]. In <ref> [Zuc90, Zuc91] </ref>, Zuckerman introduced the model of ffi-sources which generalizes all the previous models. Let D be a probability distribution on a set X. <p> Any source is a 0-source, and a 1-source is the pure random source. In general, the smaller that ffi gets, the weaker (stochastically) the source can be. For the case where ffi is a fixed positive constant, Zuckerman <ref> [Zuc91, Zuc96] </ref> showed how to simulate any BPP algorithm efficiently with ffi-sources.
Reference: [Zuc93] <author> D. Zuckerman. </author> <title> N P -complete problems have a version that's hard to approximate. </title> <booktitle> In Proc. of IEEE Conference on Structure in Complexity Theory, </booktitle> <pages> pp. 305-312, </pages> <year> 1993. </year>
Reference-contexts: There are other consequences of our disperser construction. For example, it gives improvements on the expander construction and the consequent applications given in [WZ93], on the the hardness results of approximating the clique function <ref> [Zuc93, SZ94] </ref>, and on the results for a problem in 46 data structures: implicit O (1) probe search [FN93, Zuc91]. These consequences were each observed by previous researchers, and provided much of the motivation for the search for good dispersers.
Reference: [Zuc96] <author> D. Zuckerman. </author> <title> Randomness-optimal sampling, extractors and constructive leader election. </title> <booktitle> In Proc. ACM Symposium on Theory of Computing, </booktitle> <year> 1996. </year> <month> 107 </month>
Reference-contexts: In fact, most of the previous disperser constructions are implicit in the work of simulating randomized algorithms using weak sources. The best previously known constructions are due to Zuckerman <ref> [Zuc91, Zuc96] </ref>, who achieved degree polylogarithmic in N if N = T O (1) , and Srinivasan and Zuckerman [SZ94], whose construction works for N = 2 polylog (T ) but requires degree (log N ) O (loglog N) . <p> Any source is a 0-source, and a 1-source is the pure random source. In general, the smaller that ffi gets, the weaker (stochastically) the source can be. For the case where ffi is a fixed positive constant, Zuckerman <ref> [Zuc91, Zuc96] </ref> showed how to simulate any BPP algorithm efficiently with ffi-sources.
References-found: 97

