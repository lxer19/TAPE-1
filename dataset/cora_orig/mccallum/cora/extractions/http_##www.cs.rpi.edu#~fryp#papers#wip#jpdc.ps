URL: http://www.cs.rpi.edu/~fryp/papers/wip/jpdc.ps
Refering-URL: http://www.cs.rpi.edu/~fryp/resume/
Root-URL: http://www.cs.rpi.edu
Email: E-mail: ffryp, neshj, szymanskg@cs.rpi.edu  
Title: Parallel Distributed Computation of Twin Primes Distribution  
Author: Patrick H. Fry Jeffrey Nesheiwat Boleslaw K. Szymanski 
Address: Troy, NY USA 12180 3590  
Affiliation: Department of Computer Science Rensselaer Polytechnic Institute,  
Abstract: This paper presents a distributed framework designed for parallel processing of an application using idle processor time on large numbers of heterogeneous computers. The system places no requirements on the performance or availability of the network interconnections. As such, it is most suitable to parallel applications with modest synchronization requirements and a high ratio of computation time to amount of data needed to define the problem domain subspace. We also provide details on our first application using this framework: a parallel computation which counts the distribution of twin primes, calculates Brun's constant and the maximal distance between pairs of twin primes. Two primes are twins if they differ by two. We present an overview of our implementation and provide preliminary results and future directions for the system. 1 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. P. Brent. </author> <title> Irregularities in the distribution of primes and twin primes. </title> <journal> Math. Comp., </journal> <volume> 29(129) </volume> <pages> 43-56, </pages> <year> 1975. </year>
Reference-contexts: B is known as Brun's Constant <ref> [1] </ref>. This value has been estimated by summing the inverses of twin primes over ever increasing ranges [1, 6, 14] with the current upper limit of 10 14 . <p> B is known as Brun's Constant [1]. This value has been estimated by summing the inverses of twin primes over ever increasing ranges <ref> [1, 6, 14] </ref> with the current upper limit of 10 14 . For this application, our goal is to refine this estimate by enumerating twin primes two orders of magnitude further, up to 10 16 . <p> Prior to this work, the most accurate estimate of this constant was done by Thomas Nicely who reported the value 1:9021605778 2:1 10 9 [14]. Increasing the computation to 10 16 will increase the accuracy to 6:24 10 10 <ref> [1] </ref>. <p> Results The largest range for which all twin primes were found has been growing together with capabilities of computers <ref> [1, 6, 14] </ref> and currently is 10 14 [14]. As of the writing of this paper, spare cycles on over 325 computers have been used to compute twin primes up to 3:610 15 , Thus far, 2046397127045 twins have been found. Brun's constant up to 3:610 15 is 1.82793644930989.
Reference: [2] <author> V. Brun. </author> <note> La serie 1/5 + 1/7 + 1/11 + 1/13 + 1/17 + 1/19 + 1/29 + 1/31 + 1/41 + 1/43 + 1/59 + 1/61 + ... ou les denominateurs sont `nombres premieres jumeaux' est convergente ou finie. </note> <author> Bull. </author> <title> Sci. </title> <journal> Math., </journal> <volume> 43 </volume> <pages> 124-128, </pages> <year> 1919. </year>
Reference-contexts: Two subsequent odd numbers that are both primes are called twin primes or twins for short. (3; 5), (5; 7), (11; 13), and (41; 43) are all twins. Although it is still not known if the set of twins is infinite, Brun <ref> [2] </ref> proved that the sum of the reciprocals B = ( 3 1 ) + ( 5 1 ) + ( 11 1 ) + ( 17 1 ) + is convergent; unlike the divergent sum of the reciprocals of all individual primes. B is known as Brun's Constant [1]. <p> The 10 13 twins already found would require approximately 8 bytes of storage or 80000GB total if stored individually. Even with a more efficient storage method that would use one byte per pair (e.g. storing the difference between the twins), 10000GB would still be required. Brun <ref> [2] </ref> proved the sum of inverses of all twins is convergent, in contrast with the divergent sum of inverses of individual primes. Prior to this work, the most accurate estimate of this constant was done by Thomas Nicely who reported the value 1:9021605778 2:1 10 9 [14].
Reference: [3] <author> N. Carriero, E. Freeman, D. Gelernter, and D. Kaminsky. </author> <title> Adaptive parallelism and piranha. </title> <journal> Computer, </journal> <volume> 28(1) </volume> <pages> 40-49, </pages> <year> 1995. </year>
Reference-contexts: For example, Legion [10, 11] requires at least two daemons to run on each client and uses a specialized file system. If a client fails, the centralized configuration database must be manually updated if the client cannot be restarted. Piranha <ref> [4, 3] </ref> is built on a tuple-space based coordination language, Linda [8]. Piranha implements master-worker parallelism but assumes that the master process is persistent and requires Linda compiler and system on each participating machine. Virtual BSP Computer library [13] supports BSP computations over a network of non-dedicated workstations.
Reference: [4] <author> N. Carriero, D. Gelernter, D. Kaminsky, and J. Westbrook. </author> <title> Adaptive parallelism with Piranha. </title> <type> Technical Report 954, </type> <institution> Yale University, </institution> <year> 1993. </year>
Reference-contexts: These kinds of computations can benefit from harvesting idle processor time on a pool of computers. To facilitate such harvesting, we have developed and implemented a framework that is described in this paper. There have been many attempts to use idle processor time for useful computation <ref> [4, 10, 12, 13, 16, 19] </ref>. Our interest is in distributed computation using the idle time on large numbers of heterogeneous distributed computers with minimal requirements on the performance and availability of the network interconnections. An example would be the use of hundreds or thousands of computers over the Internet. <p> For example, Legion [10, 11] requires at least two daemons to run on each client and uses a specialized file system. If a client fails, the centralized configuration database must be manually updated if the client cannot be restarted. Piranha <ref> [4, 3] </ref> is built on a tuple-space based coordination language, Linda [8]. Piranha implements master-worker parallelism but assumes that the master process is persistent and requires Linda compiler and system on each participating machine. Virtual BSP Computer library [13] supports BSP computations over a network of non-dedicated workstations.
Reference: [5] <author> G. A. Drosehn. </author> <title> SCATTERS a Simple Cool Admin Tool To Everywhere Run Something. </title> <address> http://www.rpi.edu/~drosehn/Projects/SCATTERS.html. </address>
Reference-contexts: In other cases, one wants to use machines which are being used for other purposes, and run workers only when completely idle. At Rensselaer, workers are run on a large number of public UNIX workstations by taking advantage of a separate project under development, called SCATTERS <ref> [5] </ref>. These public workstations are intended for students to use from console. It is expected they will have the full resources of that machine. <p> Top 6 contributors. on public workstations using SCATTERS <ref> [5] </ref>. Nathan Schimke (RPI-CS) for automating startup on CS department workstations. Tom Cwik (JPL) for access to HPCC resources, Josh Wilmes (RPI-CS) for assistance in porting to AIX, Robert Dugan (RPI-CS) for assistance with porting to win95/NT.
Reference: [6] <author> C. E. Froberg. </author> <title> On the sum of inverses of primes and twin primes. </title> <journal> Nordisk Tidskr. Informationsbehandling (BIT), </journal> <volume> 1 </volume> <pages> 15-20, </pages> <year> 1961. </year>
Reference-contexts: B is known as Brun's Constant [1]. This value has been estimated by summing the inverses of twin primes over ever increasing ranges <ref> [1, 6, 14] </ref> with the current upper limit of 10 14 . For this application, our goal is to refine this estimate by enumerating twin primes two orders of magnitude further, up to 10 16 . <p> Results The largest range for which all twin primes were found has been growing together with capabilities of computers <ref> [1, 6, 14] </ref> and currently is 10 14 [14]. As of the writing of this paper, spare cycles on over 325 computers have been used to compute twin primes up to 3:610 15 , Thus far, 2046397127045 twins have been found. Brun's constant up to 3:610 15 is 1.82793644930989.
Reference: [7] <author> P. H. Fry, J. Nesheiwat, and B. K. Szymanski. </author> <title> Computing twin primes and brun's constant: A distributed approach. </title> <booktitle> In Proceedings of the Seventh IEEE International Symposium on High Performance Distributed Computing, </booktitle> <pages> pages 42-49, </pages> <address> Chicago, IL, </address> <month> July </month> <year> 1998. </year> <journal> IEEE Computer Society. </journal>
Reference-contexts: In its most fl The author acknowledges support from IBM Corp. y The authors acknowledge support from NSF Grant 9527151 1 An initial version of this paper was presented at Seventh International Symposium on High Performance Distributed Computing and published in its Proceedings <ref> [7] </ref>. general form, the farmer-worker method makes no assumptions about the number of workers or the reliability of the connection between worker and farmer. Our design goals were to use as many processors as possible, and to enable a computation to proceed for many months.
Reference: [8] <author> D. Gelernter, M. Jourdenais, and D. Kaminsky. </author> <title> Piranha scheduling: Strategies and their implementation. </title> <type> Technical Report 983, </type> <institution> Yale University, </institution> <year> 1993. </year>
Reference-contexts: If a client fails, the centralized configuration database must be manually updated if the client cannot be restarted. Piranha [4, 3] is built on a tuple-space based coordination language, Linda <ref> [8] </ref>. Piranha implements master-worker parallelism but assumes that the master process is persistent and requires Linda compiler and system on each participating machine. Virtual BSP Computer library [13] supports BSP computations over a network of non-dedicated workstations.
Reference: [9] <author> M. K. Goldberg and D. L. Hollinger. </author> <title> Database learning: a method for empirical algorithm design. </title> <booktitle> In Proc. Workshop on Algorithm Engineering, </booktitle> <year> 1997. </year>
Reference-contexts: For example, in our computation n = 200; p = 1=5, so in 99:84% cases we will be able to finish in two stages, yielding a respectable efficiency of 50% compared to non-synchronous case. A maximum independent set problem is an example of a synchronous parallel computation <ref> [9] </ref> with a low communication requirement if proper data distribution is used [13]. We plan to use our system with a protocol extended for synchronous computation to this problem. 6.
Reference: [10] <author> A. S. Grimshaw, A. Nguyen-Tuong, and W. A. Wulf. </author> <title> Campus-wide computing: Early results using legion at the University of Virginia. </title> <type> Technical report, </type> <institution> University of Virginia, </institution> <year> 1995. </year>
Reference-contexts: These kinds of computations can benefit from harvesting idle processor time on a pool of computers. To facilitate such harvesting, we have developed and implemented a framework that is described in this paper. There have been many attempts to use idle processor time for useful computation <ref> [4, 10, 12, 13, 16, 19] </ref>. Our interest is in distributed computation using the idle time on large numbers of heterogeneous distributed computers with minimal requirements on the performance and availability of the network interconnections. An example would be the use of hundreds or thousands of computers over the Internet. <p> Minimal host requirements open the problem up to a greater number of potential contributors. Similar goals and means were used by the DESCHALL project which cracked the code in the RSA DES Challenge [19]. The majority of existing systems with similar goals impose significant system requirements. For example, Legion <ref> [10, 11] </ref> requires at least two daemons to run on each client and uses a specialized file system. If a client fails, the centralized configuration database must be manually updated if the client cannot be restarted. Piranha [4, 3] is built on a tuple-space based coordination language, Linda [8].
Reference: [11] <author> A. S. Grimshaw, W. A. Wulf, J. C. French, A. C. Weaver, and P. F. R. Jr. </author> <title> A synopsis of the Legion project. </title> <type> Technical report, </type> <institution> University of Virginia, </institution> <year> 1994. </year>
Reference-contexts: Minimal host requirements open the problem up to a greater number of potential contributors. Similar goals and means were used by the DESCHALL project which cracked the code in the RSA DES Challenge [19]. The majority of existing systems with similar goals impose significant system requirements. For example, Legion <ref> [10, 11] </ref> requires at least two daemons to run on each client and uses a specialized file system. If a client fails, the centralized configuration database must be manually updated if the client cannot be restarted. Piranha [4, 3] is built on a tuple-space based coordination language, Linda [8].
Reference: [12] <author> G. Judd, M. Clement, and Q. </author> <title> Shell. The DOGMA approach to high-utilization supercomputing. </title> <booktitle> In Proceedings of the Seventh IEEE International Symposium on High Performance Distributed Computing, </booktitle> <pages> pages 64-70, </pages> <address> Chicago, IL, </address> <month> July </month> <year> 1998. </year> <journal> IEEE Computer Society. </journal>
Reference-contexts: These kinds of computations can benefit from harvesting idle processor time on a pool of computers. To facilitate such harvesting, we have developed and implemented a framework that is described in this paper. There have been many attempts to use idle processor time for useful computation <ref> [4, 10, 12, 13, 16, 19] </ref>. Our interest is in distributed computation using the idle time on large numbers of heterogeneous distributed computers with minimal requirements on the performance and availability of the network interconnections. An example would be the use of hundreds or thousands of computers over the Internet.
Reference: [13] <author> M. Nibhanupudi and B. K. Szymanski. </author> <title> Runtime support for virtual BSP computer. </title> <booktitle> In Proc. Workshops at 12th Intern. Parallel Processing Symposium. </booktitle> <publisher> Springer Verlag, </publisher> <year> 1998. </year>
Reference-contexts: These kinds of computations can benefit from harvesting idle processor time on a pool of computers. To facilitate such harvesting, we have developed and implemented a framework that is described in this paper. There have been many attempts to use idle processor time for useful computation <ref> [4, 10, 12, 13, 16, 19] </ref>. Our interest is in distributed computation using the idle time on large numbers of heterogeneous distributed computers with minimal requirements on the performance and availability of the network interconnections. An example would be the use of hundreds or thousands of computers over the Internet. <p> Piranha [4, 3] is built on a tuple-space based coordination language, Linda [8]. Piranha implements master-worker parallelism but assumes that the master process is persistent and requires Linda compiler and system on each participating machine. Virtual BSP Computer library <ref> [13] </ref> supports BSP computations over a network of non-dedicated workstations. This system migrates processes from workstations which became unavailable and supports scalability and tightly synchronized parallel computations. However, it requires an extended BSP library on each participating workstation and cannot survive a crash on the master process. <p> A maximum independent set problem is an example of a synchronous parallel computation [9] with a low communication requirement if proper data distribution is used <ref> [13] </ref>. We plan to use our system with a protocol extended for synchronous computation to this problem. 6. Conclusions We have described our distributed farmer worker framework and shown how we have used it to create a distributed twin primes computation application.
Reference: [14] <author> T. R. </author> <title> Nicely. Enumeration to 1e14 of the twin primes and Brun's constant. </title> <journal> Virginia Journal of Science, </journal> <volume> 46(3) </volume> <pages> 195-204, </pages> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: B is known as Brun's Constant [1]. This value has been estimated by summing the inverses of twin primes over ever increasing ranges <ref> [1, 6, 14] </ref> with the current upper limit of 10 14 . For this application, our goal is to refine this estimate by enumerating twin primes two orders of magnitude further, up to 10 16 . <p> In addition to counting the number of twin primes and computing the sum of their inverses, we also find the maximum distance between twins and the location of these gaps. These data are of interest to number theoreticians <ref> [14] </ref>. This is a formidable computation which would take over 100 years on a single workstation. Parallelism and careful algorithm optimization are necessary to obtain results in more timely manner. <p> Brun [2] proved the sum of inverses of all twins is convergent, in contrast with the divergent sum of inverses of individual primes. Prior to this work, the most accurate estimate of this constant was done by Thomas Nicely who reported the value 1:9021605778 2:1 10 9 <ref> [14] </ref>. Increasing the computation to 10 16 will increase the accuracy to 6:24 10 10 [1]. <p> This memory requirement was reduced by using just one byte per prime by storing the difference between the current prime and its previous prime; thus using only 6MB. This is the implementation used by Thomas Nicely <ref> [14] </ref>. Currently, one bit for each potential prime up to 10 8 is used. Eliminating multiples of 2, 3, and 5 leaves only 8 potential primes for each 30 numbers. As shown in Figure 4, the potential primes are 1, 7, 11, 13, 17, 19, 23, and 29, modulo 30. <p> Finally, we ignore all the higher terms, which contributes to the numerical error of the result. The magnitude of this error can be estimated as at most twice the sum of fourth terms which in turn is less than 2 n r 3 =s 4 . Using Nicely's result <ref> [14] </ref>, we can set b = 10 14 and the final precision of the sum of inverses will be at least 30 decimal digits for r = 3003 (for convenience, we select the size that is the divisor of the gallery size). <p> Results The largest range for which all twin primes were found has been growing together with capabilities of computers <ref> [1, 6, 14] </ref> and currently is 10 14 [14]. As of the writing of this paper, spare cycles on over 325 computers have been used to compute twin primes up to 3:610 15 , Thus far, 2046397127045 twins have been found. Brun's constant up to 3:610 15 is 1.82793644930989. <p> Results The largest range for which all twin primes were found has been growing together with capabilities of computers [1, 6, 14] and currently is 10 14 <ref> [14] </ref>. As of the writing of this paper, spare cycles on over 325 computers have been used to compute twin primes up to 3:610 15 , Thus far, 2046397127045 twins have been found. Brun's constant up to 3:610 15 is 1.82793644930989.
Reference: [15] <author> T. R. </author> <title> Nicely. </title> <type> Private communication. </type> <year> 1998. </year> <note> See also http://www.lynchburg.edu/public/academic/math/nicely/gaps/gaps.htm. </note>
Reference-contexts: Total server uptime is 208 days. After a server crash, the server is simply restarted in recovery mode and continues assigning intervals from where the last checkpoint file was created. Initial computation from 0 to 1:0 10 15 were confirmed using Nicely's results up to 1:0 10 15 <ref> [15] </ref>. 5. Future Work Extensions to this work involve furthering the existing twin primes computation and also applying this fault tolerant distributed computing framework to similar problems. To maximize utilization of idle workstations, our attention has been focused on the Windows 95/NT worker.
Reference: [16] <author> J. Pruyne and M. Livny. </author> <title> Interfacing Condor and PVM to harness the cycles of workstation clusters. </title> <journal> Future Generation Computer Systems, </journal> <volume> 12(1) </volume> <pages> 67-85, </pages> <year> 1996. </year>
Reference-contexts: These kinds of computations can benefit from harvesting idle processor time on a pool of computers. To facilitate such harvesting, we have developed and implemented a framework that is described in this paper. There have been many attempts to use idle processor time for useful computation <ref> [4, 10, 12, 13, 16, 19] </ref>. Our interest is in distributed computation using the idle time on large numbers of heterogeneous distributed computers with minimal requirements on the performance and availability of the network interconnections. An example would be the use of hundreds or thousands of computers over the Internet.
Reference: [17] <author> M. J. Quinn. </author> <title> Parallel Computing: Theory and Practice. </title> <publisher> McGraw-Hill, Inc., </publisher> <year> 1994. </year>
Reference: [18] <author> T. Sterling, D. Becker, J. Salmon, D. Katz, P. Angelino, D. Ridge, and J. Lindheim. </author> <title> How to build a Beowulf: A tutorial, </title> <address> Oct. </address> <year> 1997. </year> <title> Presented by the Center for Advanced Computing Research, </title> <institution> California Institute of Technology. </institution>
Reference-contexts: This relay receives worker messages, forwards them to the farmer, and sends the farmer's response back to the worker. This has proven useful for Beowulf class machines <ref> [18] </ref> in which only one node is accessible outside the cluster. The relay runs on the gateway node which has access outside the cluster. In a network with a firewall, the relay resides on the firewall.
Reference: [19] <author> R. Verser. </author> <title> The $10,000 DES challenge. </title> <address> http://www.frii.com/~rcv/deschall.htm. </address>
Reference-contexts: These kinds of computations can benefit from harvesting idle processor time on a pool of computers. To facilitate such harvesting, we have developed and implemented a framework that is described in this paper. There have been many attempts to use idle processor time for useful computation <ref> [4, 10, 12, 13, 16, 19] </ref>. Our interest is in distributed computation using the idle time on large numbers of heterogeneous distributed computers with minimal requirements on the performance and availability of the network interconnections. An example would be the use of hundreds or thousands of computers over the Internet. <p> Minimal host requirements open the problem up to a greater number of potential contributors. Similar goals and means were used by the DESCHALL project which cracked the code in the RSA DES Challenge <ref> [19] </ref>. The majority of existing systems with similar goals impose significant system requirements. For example, Legion [10, 11] requires at least two daemons to run on each client and uses a specialized file system. <p> Some suitable applications would be search or enumeration algorithms. The amount of data returned to the farmer should be small as well. A code-breaker, or decryption application is a good example <ref> [19] </ref>. The worker is given a region (interval of integers defined by just two numbers) to search for keys in and returns a bit indicating found / not found answer with some statistics. We describe here also the first application of our farmer worker system to computing twin primes distribution. <p> The problem specific computations are done by the worker. This mechanism is similar to that employed by the DESCHALL project <ref> [19] </ref>. Both mechanisms are designed to allow an arbitrarily large number of clients to join the computation while making no assumptions as to reliability.

References-found: 19

