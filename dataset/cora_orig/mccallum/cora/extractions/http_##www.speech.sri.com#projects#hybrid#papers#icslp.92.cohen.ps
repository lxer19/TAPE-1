URL: http://www.speech.sri.com/projects/hybrid/papers/icslp.92.cohen.ps
Refering-URL: http://www.speech.sri.com/projects/hybrid/publications.html
Root-URL: 
Title: HYBRID NEURAL NETWORK/HIDDEN MARKOV MODEL CONTINUOUS-SPEECH RECOGNITION system, in which the advantages of both approaches
Author: Michael Cohen*, Horacio Franco*, Nelson Morgan**, David Rumelhart***, and Victor Abrash* 
Note: tion  
Address: Menlo Park, CA 9402  1947 Center Street, Suite 600, Berkeley, CA 94704  Stanford, CA 94305  
Affiliation: Speech Research Program, SRI International,  Intl. Computer Science Inst.,  Stanford University, Dept. of Psychology,  
Abstract: n In this paper we present a hybrid multilayer perceptron (MLP)/hidde arkov model (HMM) speaker-independent continuous-speech recogni-b
Abstract-found: 1
Intro-found: 1
Reference: <author> 1] N. Morgan and H. Bourlard, </author> <title> ``Continuous Speech Recognition Using Mul , tilayer Perceptrons with Hidden Markov Models,'' </title> <booktitle> ICASSP 90 , pp. </booktitle> <address> 413-416 lburquerque, New Mexico, </address> <year> 1990. </year>
Reference: [2] <author> V. Abrash, H. Franco, M. Cohen, N. Morgan, and Y. Konig, </author> <title> ``Connectionist R Gender Adaptation in a Hybrid Neural Network/Hidden Markov Model Speech ecognition System,'' this volume. </title>
Reference-contexts: approach for integrating MLP-based estima-b tion techniques; present a number of new techniques that have een developed to allow the modeling of multiple distributions for t phonetic classes and context-dependent phonetic classes; and show he results of recognition experiments for the systems described. - 2 - s Abrash et al. <ref> [2] </ref> and Konig et al. [3] describe extensions of th ystem presented here to the modeling of long-term speech consistencies. 2. <p> To train the MLP, the training set was divided into a set of 510 sentences for adjusting weights during back-propagation s training, and 480 sentences for cross-validation. None of the test escribed here use the gender-dependent DECIPHER system, T which is described elsewhere <ref> [2] </ref>. able 1: Number of system parameters and percent word error for pure HMM and hybrid MLP/HMM with no grammar. iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii i Feb89 Oct89 Feb91 # Parameters iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii i CI-HMM 44.1 45.3 44.8 125K iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii i CI-MLP 24.9 27.0 25.0 311K iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii i CD-MLP 19.4 20.8 20.5 1,409K iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii i
Reference: [3] <author> Y. Konig, N. Morgan, and C. Chandra, ``GDNN: </author> <title> A Gender-Dependent S Neural Network for Continuous Speech Recognition,'' </title> <institution> International Computer cience Institute Technical Report TR-91-071, </institution> <month> December </month> <year> 1991. </year> - <title> 11 s </title>
Reference-contexts: tion techniques; present a number of new techniques that have een developed to allow the modeling of multiple distributions for t phonetic classes and context-dependent phonetic classes; and show he results of recognition experiments for the systems described. - 2 - s Abrash et al. [2] and Konig et al. <ref> [3] </ref> describe extensions of th ystem presented here to the modeling of long-term speech consistencies. 2. <p> HMMs which model gender ased speech consistencies typically have twice the number of o parameters of gender-independent HMMs. For example, a version f the DECIPHER system that models male and female speech ] separately has more than 11 million parameters. Abrash et al. [2 nd Konig et al. <ref> [3] </ref> discuss methods for exploiting the distributed h nature of MLPs to model gender-based speech consistencies wit nly a relatively small increase in the number of parameters. n The distributed representation used by MLPs is exploited i he context-dependent modeling approach described in Section 4 t by sharing the input-to-hidden layer
Reference: [4] <author> H. Murveit, M. Cohen, P. Price, G. Baldwin, M. Weintraub, and J. Bern tein, </author> <title> ``SRI's DECIPHER System,'' </title> <booktitle> DARPA Speech and Natural Language [ Workshop, </booktitle> <month> February </month> <year> 1989. </year> <note> 5] S. </note> <author> E. Levinson, L. R. Rabiner, and M.M. Sondhi, </author> <title> ``An introduction to the a application of the theory of probabilistic functions of a Markov process to utomatic speech recognition,'' </title> <journal> Bell Syst. Tech. Journal 62, </journal> <pages> 1035-1074, </pages> <address> 1983. e </address>
Reference-contexts: HYBRID MLP/HMM T 2.1 The DECIPHER System he baseline system into which we incorporated MLP probability , estimation is the SRI-DECIPHER system, a phone-based peaker-independent, continuous-speech recognition system, based e on semicontinuous (tied Gaussian mixture) HMMs <ref> [4] </ref>. The system xtracts four features from the input speech waveform, including - 12th-order mel cepstrum, log energy, and their smoothed deriva ives. The front end produces the 26 coefficients for these four features for each 10-ms frame of speech.

Reference: [10] <author> R. M. Schwartz, Y. L. Chow, O. A. Kimball, S. Roucos, M. Krasner, and f J. Makhoul, </author> <title> ``Context-dependent modeling for acoustic-phonetic recognition o ontinuous speech,'' </title> <booktitle> ICASSP 85, </booktitle> <pages> 1205-1208, </pages> <year> 1985. </year> <institution> t </institution>
Reference-contexts: This technique has been combined with the approach to context-dependent modeling, described next. 4. CONTEXT-DEPENDENCE - Experience with HMM technology has shown that using context ependent phonetic models improves recognition accuracy - significantly <ref> [10] </ref>. This is because acoustic correlates of coarticula ory effects are modeled explicitly, producing sharper and less c overlapping probability density functions for the different phone lasses. Context-dependent HMMs use different probability distri-p butions for every phone in every different relevant context.
Reference: [11] <author> H. Bourlard, N. Morgan, C. Wooters, S Renals, </author> <title> ``CDNN: A Contex ependent Neural Network for Continuous Speech Recognition,'' </title> <booktitle> ICASSP 92, </booktitle> [ <volume> Vol. 2, </volume> <pages> pp. 349-352, </pages> <address> San Francisco, </address> <year> 1992. </year> <note> 12] H. </note> <author> Franco, M. Cohen, N. Morgan, D. Rumelhart, V. Abrash, </author> <title> ``Context t Dependent Connectionist Probability Estimation in a Hybrid HNN-Neural Ne peech Recognition System,'' in press, </title> <booktitle> IJCNN, </booktitle> <address> Beijing, </address> <year> 1992. </year> - 
Reference-contexts: approach to average th robabilities from different MLPs; however, since the MLP train u ing algorithm is a discriminant procedure, it would be desirable to se a discriminant procedure to smooth the MLP probabilities. g An earlier approach to context-dependent phonetic modelin ith MLPs was proposed by Bourlard et al. <ref> [11] </ref>. It is based on y factoring the context-dependent likelihood and uses a set of binar nputs to the network to specify context classes.
Reference: [13] <author> M. Cohen, H. Franco, N. Morgan, D. Rumelhart, V. Abrash, </author> <title> ``Multiple tate Context-Dependent Phonetic Modeling with MLPs,'' </title> <booktitle> Proceedings Speech F Research Symposium XII, Rutgers, </booktitle> <year> 1992. </year> <note> igure 1: Context-dependent MLP. </note>
Reference-contexts: hat uses a different factoring of the desired context-dependent l likelihoods, a network architecture that shares the input-to-hidden ayer among the context-dependent classes to reduce the number w of parameters, and a training procedure that smooths networks ith different degrees of context-dependence in order to achieve robustness in probability estimates <ref> [12, 13] </ref>. Our initial implementation of context-dependent MLPs t models generalized biphone phonetic categories. We chose a se f eight left and eight right generalized biphone phonetic-context c classes, based principally on place of articulation and acoustic haracteristics.
References-found: 7

