URL: ftp://zeus.cs.gsu.edu/pub/volshevsky/papers/asspol1.ps
Refering-URL: http://www.cs.gsu.edu/~matvro/papers.html
Root-URL: http://www.cs.gsu.edu
Email: olshevsk@rascals.stanford.edu  
Title: Unitary Hessenberg matrices and the generalized Parker-Forney-Traub and Bjorck-Pereyra algorithms for Szego-Vandermonde matrices  
Author: T.Kailath and V.Olshevsky 
Date: October 2, 1997  
Address: Stanford CA 94305 4055, U.S.A.  
Affiliation: Information Systems Laboratory, Stanford University,  
Abstract: It is well-known that the associated polynomials (or Horner polynomials) describe the struc ture of the inverses of Vandermonde matrices V (x) = fi i , leading to the fast O(n 2 ) Parker-Forney-Traub inversion algorithm. In this paper we show how the generalized associated polynomials define the structure of the inverses of polynomial-Vandermonde matrices V P (x) = P j1 (x i ) , and use this description to generalize to V P (x) the Parker-Forney-Traub inversion algorithm, as well as the Bjorck-Pereyra algorithm for solving Vandermonde linear systems. We show that in the case when the polynomials fP k (x)g involved in V P (x) are the Szego polynomials, the properties of the corresponding unitary Hessenberg matrix allow us a dramatic simplification, leading to fast O(n 2 ) computational procedures for inversion of what we call Szego-Vandermonde matrices V P (x), and for solving the associated linear systems. 
Abstract-found: 1
Intro-found: 1
Reference: [ACR96] <author> G.Ammar, D.Calvetti and L.Reichel, </author> <title> Continuation methods for the computation of zeros of Szego polynomials, Linear Algebra and Its Applications, </title> <booktitle> 249 (1996), </booktitle> <pages> 125-155. </pages>
Reference-contexts: If C R (r n ) is unitary, then its eigenvalues can be computed using algorithms of [G86] [GR90]. If C R (r n ) is not unitary, then its eigenvalues can be computed by an algorithm of <ref> [ACR96] </ref>. Here we assume that we already know the eigenvalues fx 1 ; x 2 ; : : : ; x n g of C R (r n ) and note that the generalized Parker-Forney-Traub algorithm in fact computes its eigenvectors.
Reference: [AGR93] <author> G.Ammar, W.Gragg and L.Reichel, </author> <title> An analogue for the Szego polynomials of the Clenshaw algorithm, </title> <journal> J. Computational Appl. Math., </journal> <note> 46 (1993) pp., 211-216. </note>
Reference-contexts: As a by-product, we obtain a new, three-term Clenshaw-type rule for evaluation of a polynomial represented in a basis of Szego polynomials. This is an alternative to the two-term Clenshaw-type rule recently obtained in <ref> [AGR93] </ref>. Another by-product is a downdating divided differences scheme. It is analytically shown that this new scheme, implemented in a finite precision arithmetic, provides a favorably small backward error, if the Leja ordering [Hig90], [R90] of interpolation points is employed. 2 The paper is structured as follows. <p> Summarizing, the overall complexity of the suggested inversion algorithm is O (n 2 ). 6.5. An analogue of the Clenshaw algorithm for Szego polynomials In a recent paper <ref> [AGR93] </ref> Ammar, Gragg and Reichel used the two-term recurrence relations (6.1) to formulate an analogue for the Szego polynomials of the Clenshaw algorithm. <p> Therefore b (x) can be evaluated by using (6.8) for k = 0; 1; :::; n. Note that this algorithm is based on the use of three-term recurrence relations (6.2), suggesting an alternative to the method in <ref> [AGR93] </ref>. 6.6. Finding eigenvectors of Hessenberg matrices which differ from unitary only in the last column. Let R = fr 0 (x); r 1 (x); : : : ; r n (x)g be a family of Szego polynomials.
Reference: [B75] <author> S.Barnett, </author> <title> A companion matrix analogue for orthogonal polynomials, </title> <journal> Linear Algebra Appl., </journal> <volume> 12 (1975), </volume> <pages> 197-208. </pages>
Reference-contexts: ff 3 . . . 0 . . . . . . ff n1 b n3 . . . . . . fi n1 ff n b n ff n1 b n1 3 7 7 7 7 7 7 7 ; (4.4) which has been called a comrade matrix in <ref> [B75] </ref>. <p> Specifically, for Vandermonde matrices, C P (r n ) is just the companion matrix of r n (x), and when R satisfy three-term recurrence relations (4.3) the C R (r n ) has almost tridiagonal form (4.4) which has been called a comrade matrix in <ref> [B75] </ref>. Note that the sparsity of C R (r n ) means that the n 2 entries of V R (x) are completely defined by a smaller number O (n) of parameters. Therefore it is not surprising that operating on these parameters we are able to achieve a faster computation.
Reference: [BKO95] <author> T.Boros, T.Kailath and V.Olshevsky, </author> <title> The Fast Bjorck-Pereyra-type algorithm for solving Cauchy linear equations, </title> <note> submitted, 1995. 18 </note>
Reference-contexts: Moreover, it was analytically shown that the Bjorck-Pereyra algorithm is not only faster but it is often more accurate than the standard methods, see, e.g. [Hig87] for the forward stability and <ref> [BKO95] </ref> for the backward stability analyses.
Reference: [BP70] <author> A.Bjorck and V.Pereyra, </author> <title> Solution of Vandermonde Systems of Equations, </title> <journal> Math. Comp., </journal> <volume> 24 (1970), </volume> <pages> 893-903. </pages>
Reference-contexts: It was demonstrated numerically in [GO96] that the Parker-Forney-Traub algorithm is not only faster, but it is also much more accurate that the standard numerically stable methods. There is another formula representing V (x) 1 as a product of 2n bidiagonal matrices, this expression was used in <ref> [BP70] </ref> to obtain the now well-known O (n 2 ) fast Bjorck-Pereyra algorithm for solving Vandermonde linear equations. <p> Table 1. Fast O (n 2 ) algorithms for three-term Vandermonde matrices. Inversion Solving linear system Parker-Forney-Traub Bjorck-Pereyra Vandermonde algorithm [P64], [F66], [T66] algorithm <ref> [BP70] </ref> Gohberg-Olshevsky Reichel-Opfer Chebyshev-Vandermonde algorithm [GO94] algorithm [RO91] Calvetti-Reichel Higham three-term Vandermonde algorithm [CR93] algorithm [Hig90] However, many problems in signal processing applications usually involve computations with Szego polynomials, i.e., polynomials orthogonal on the unit circle. <p> Another representation for the inverse of V P (x). Bjorck and Pereyra derived in <ref> [BP70] </ref> a decomposition of the inverse of a Vandermonde matrix, V P (x) 1 = U 1 :::U n1 ~ L n1 ::: ~ L 1 ; (5.1) into a product of of bidiagonal factors of the form U k = 6 6 6 ff 1 fi 1 . . .
Reference: [C11] <author> F.Cajori, </author> <title> Horner's method of approximation anticipated by Ruffini, </title> <journal> Bull. Amer. Math. Soc., </journal> <volume> 17(1911), </volume> <pages> 301-312. </pages>
Reference-contexts: However, as was noted in <ref> [C11] </ref>, the Horner's method was anticipated by Ruffini, and moreover Horner himself pointed out in [H1819], that these polynomials were known to Lagrange [L1775]. However, all of the above men had been anticipated by Chinese mathematicians, see e.g. [C11]. <p> However, as was noted in <ref> [C11] </ref>, the Horner's method was anticipated by Ruffini, and moreover Horner himself pointed out in [H1819], that these polynomials were known to Lagrange [L1775]. However, all of the above men had been anticipated by Chinese mathematicians, see e.g. [C11]. For these historical reasons in [T66] polynomials ^ P = f^p 0 (x); ^p 1 (x); :::; ^p n1 (x); ^p n (x)g were called in [T66] the associated with P = f1; x; x 2 ; :::; x n1 ; b (x)g polynomials. 3 2.2.
Reference: [C55] <author> C.Clenshaw, </author> <title> A note on summation of Chebyshev series, </title> <journal> M.T.A.C., </journal> <volume> 9(51)(1955), </volume> <pages> 118-120. </pages>
Reference-contexts: In particular, this includes as a special case the Clenshaw method <ref> [C55] </ref> of evaluation (4.2) in the case of orthogonal polynomials, satisfying the three-term recurrence relations r k (x) = (ff k x fi k ) r k1 (x) fl k r k1 (x); (4.3) Observe that (4.3) means that the C R (r n ) has almost tridiagonal form C R
Reference: [F66] <author> G.Forney, </author> <title> Concatenated codes, </title> <publisher> The M.I.T. Press, </publisher> <address> 1966, Cambridge. </address>
Reference-contexts: Government. 1 fast inversion algorithm has been rederived in the mathematical and engineering literature several times, and now it is usually associated with the names of Parker [P64], Forney <ref> [F66] </ref> and Traub [T66] (see also [Wertz65], [K69]). It was demonstrated numerically in [GO96] that the Parker-Forney-Traub algorithm is not only faster, but it is also much more accurate that the standard numerically stable methods. <p> In this case fast O (n 2 ) algorithms are also possible, and in the next table we list these algorithms along with the corresponding references. Table 1. Fast O (n 2 ) algorithms for three-term Vandermonde matrices. Inversion Solving linear system Parker-Forney-Traub Bjorck-Pereyra Vandermonde algorithm [P64], <ref> [F66] </ref>, [T66] algorithm [BP70] Gohberg-Olshevsky Reichel-Opfer Chebyshev-Vandermonde algorithm [GO94] algorithm [RO91] Calvetti-Reichel Higham three-term Vandermonde algorithm [CR93] algorithm [Hig90] However, many problems in signal processing applications usually involve computations with Szego polynomials, i.e., polynomials orthogonal on the unit circle.
Reference: [GO94] <author> I.Gohberg and V.Olshevsky, </author> <title> Fast inversion of Chebyshev-Vandermonde matrices, </title> <journal> Nu-merische Mathematik, </journal> <volume> 67, No. 1 (1994), 71 - 92. </volume>
Reference-contexts: Table 1. Fast O (n 2 ) algorithms for three-term Vandermonde matrices. Inversion Solving linear system Parker-Forney-Traub Bjorck-Pereyra Vandermonde algorithm [P64], [F66], [T66] algorithm [BP70] Gohberg-Olshevsky Reichel-Opfer Chebyshev-Vandermonde algorithm <ref> [GO94] </ref> algorithm [RO91] Calvetti-Reichel Higham three-term Vandermonde algorithm [CR93] algorithm [Hig90] However, many problems in signal processing applications usually involve computations with Szego polynomials, i.e., polynomials orthogonal on the unit circle. In this paper we generalize both the Parker-Forney-Traub and Bjorck-Pereyra algorithms to what we call Szego-Vandermonde matrices.
Reference: [CR93] <author> Calvetti, D. and Reichel, L. </author> : <title> Fast inversion of Vandermonde-like matrices involving orthogonal polynomials, </title> <journal> BIT, </journal> <year> 1993. </year>
Reference-contexts: Table 1. Fast O (n 2 ) algorithms for three-term Vandermonde matrices. Inversion Solving linear system Parker-Forney-Traub Bjorck-Pereyra Vandermonde algorithm [P64], [F66], [T66] algorithm [BP70] Gohberg-Olshevsky Reichel-Opfer Chebyshev-Vandermonde algorithm [GO94] algorithm [RO91] Calvetti-Reichel Higham three-term Vandermonde algorithm <ref> [CR93] </ref> algorithm [Hig90] However, many problems in signal processing applications usually involve computations with Szego polynomials, i.e., polynomials orthogonal on the unit circle. In this paper we generalize both the Parker-Forney-Traub and Bjorck-Pereyra algorithms to what we call Szego-Vandermonde matrices. <p> Multiply the matrices on the right hand side of (2.7). In the case of the monomial basis, R = P , this procedure reduces to the conventional Parker-Forney-Traub algorithm, described in Sec. 1. For polynomials orthogonal on a real interval, this procedure reduces to the Calvetti-Reichel algorithm <ref> [CR93] </ref> for inversion of three-term Vander-monde matrices. In both cases the computational complexity is O (n 2 ) operations, however for general polynomials, satisfying only deg p k (x) = k, the above generalized Parker-Forney-Traub algorithm requires the same amount O (n 3 ) operations as standard methods.
Reference: [G48] <author> L.Y.Geronimus, </author> <title> Polynomials orthogonal on a circle and their applications, </title> <journal> Amer. Math. </journal> <note> Translations, 3 p.1-78, 1954 (Russian original 1948). </note>
Reference-contexts: To efficiently specialize the generalized Parker-Forney-Traub algorithm for V (x) we need to write down the corresponding confederate matrix, for this purposes it will be more convenient to use not (6.1), but recently somewhat ignored three-term recurrence relations for Szego polynomials (see, e.g., <ref> [G48] </ref>) 1 (x OE 0 (x) ae 1 OE 0 (x)); 1 x + ae k1 k ae k k1 x OE k2 (x): (6.2) In fact, when Szego first introduced the polynomials orthogonal on the unit circle, he gave the expected three-term recursion (6.2).
Reference: [G86] <author> W.B.Gragg, </author> <title> The QR algorithm for unitary Hessenberg matrices, </title> <journal> J.Comput. Appl. Math., </journal> <volume> 16 (1986), </volume> <pages> 1-8. </pages>
Reference-contexts: By (6.4) the corresponding confederate matrix C R (r n ) differs from unitary only in the last column. If C R (r n ) is unitary, then its eigenvalues can be computed using algorithms of <ref> [G86] </ref> [GR90]. If C R (r n ) is not unitary, then its eigenvalues can be computed by an algorithm of [ACR96].
Reference: [G82] <author> W.B.Gragg, </author> <title> Positive definite Toeplitz matrices, the Arnoldi process for isometric operators, and Gaussian quadrature on the unit circle (in Russian). In : E.S. </title> <editor> Nikolaev (Ed.), </editor> <booktitle> Numerical methods in Linear Algebra, </booktitle> <pages> pp. 16-32, </pages> <publisher> Moskow University Press, </publisher> <year> 1982. </year> <title> English translation in : J. </title> <journal> Comput. and Appl. Math., </journal> <volume> 46(1993), </volume> <pages> 183-198. </pages>
Reference-contexts: n n . . . 3 . . . . . . n2 ae n n1 ae fl b n n n1 b n1 3 7 7 7 7 (6.4) The matrix (6.4) differs from the unitary Hessenberg matrix only in the last column, and this matrix was written down <ref> [G82] </ref>) (in a slightly different form), and [KP83]. The useful properties of this unitary Hessenberg matrices were later intensively studied in the signal processing (where it appears as a system matrix of orthogonal lattice filters), and quite independently in numerical analysis literature.
Reference: [GL89] <author> G.Golub and C.Van Loan, </author> <title> Matrix Analysis, </title> <note> second edition, </note> <author> John Hopkins U. P., Bal-timore, </author> <year> 1989. </year>
Reference-contexts: (x) = LU , and taking an advantage of the observation that rearrangement of fx i g is equivalent to a row permutation of V P (x), we arrive at the conclusion that the partial pivoting ordering, which guarantees that the entries of jLj are less than unity, see, e.g. <ref> [GL89] </ref>, yields a pleasing backward stability of downdating divided differences : jf k ^ f k j ((1 u) 3 (n1) 1) i=1 17 Here ^ f k = L^c are the values of the actually computed Newton polynomial ^ f (x) = P n Q i1 x k ) at
Reference: [GO96] <author> I.Gohberg and V.Olshevsky, </author> <title> A fast generalized Parker-Traub algorithm for inversion of Vandermonde and related matrices, </title> <note> to appear in Journal of Complexity. A short version in pp. in Communications, Computation, Control and Signal Processing: A tribute to Thomas Kailath, </note> <editor> Eds. A.Paulraj, V Roychowdhury and C.Shaper, </editor> <publisher> Kluwer Academic Publishing, </publisher> <year> 1996, </year> <month> p.205-221. </month>
Reference-contexts: Government. 1 fast inversion algorithm has been rederived in the mathematical and engineering literature several times, and now it is usually associated with the names of Parker [P64], Forney [F66] and Traub [T66] (see also [Wertz65], [K69]). It was demonstrated numerically in <ref> [GO96] </ref> that the Parker-Forney-Traub algorithm is not only faster, but it is also much more accurate that the standard numerically stable methods. <p> Second, since the differences of fx k g appear in the denominators, (8.11) suppresses the growth of computed quantities. This also reduces the size of ^c k involved in (8.10). Note that the numerical experiments in <ref> [GO96] </ref> indicate that Leja ordering yields an extremely high accuracy of the Parker-Forney-Traub algorithm. 9 Conclusion In this paper we generalized the well-known Parker-Forney-Traub, and Bjorck-Pereyra algorithms to polynomial-Vandermonde matrices. These algorithm are derived by exploiting the properties of the corresponding confederate matrix (i.e., Hessenberg matrix capturing the recurrence relations).
Reference: [GR90] <author> W.B.Gragg and L.Reichel, </author> <title> A divide and conquer method for unitary and orthogonal eigenproblems, </title> <journal> Numer. Math., </journal> <volume> 57 (1990), </volume> <pages> 695-718. </pages>
Reference-contexts: By (6.4) the corresponding confederate matrix C R (r n ) differs from unitary only in the last column. If C R (r n ) is unitary, then its eigenvalues can be computed using algorithms of [G86] <ref> [GR90] </ref>. If C R (r n ) is not unitary, then its eigenvalues can be computed by an algorithm of [ACR96].
Reference: [Hig87] <author> N.Higham, </author> <title> Error analysis of the Bjorck-Pereyra algorithms for solving Vandermonde systems, </title> <journal> Numerische mathematic, </journal> <volume> 50 (1987), 613 - 632. </volume>
Reference-contexts: Moreover, it was analytically shown that the Bjorck-Pereyra algorithm is not only faster but it is often more accurate than the standard methods, see, e.g. <ref> [Hig87] </ref> for the forward stability and [BKO95] for the backward stability analyses.
Reference: [Hig90] <author> N.Higham, </author> <title> Stability analysis of algorithms for solving confluent Vandermonde-like systems, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 11(1) (1990), </volume> <pages> 23-41. </pages>
Reference-contexts: Table 1. Fast O (n 2 ) algorithms for three-term Vandermonde matrices. Inversion Solving linear system Parker-Forney-Traub Bjorck-Pereyra Vandermonde algorithm [P64], [F66], [T66] algorithm [BP70] Gohberg-Olshevsky Reichel-Opfer Chebyshev-Vandermonde algorithm [GO94] algorithm [RO91] Calvetti-Reichel Higham three-term Vandermonde algorithm [CR93] algorithm <ref> [Hig90] </ref> However, many problems in signal processing applications usually involve computations with Szego polynomials, i.e., polynomials orthogonal on the unit circle. In this paper we generalize both the Parker-Forney-Traub and Bjorck-Pereyra algorithms to what we call Szego-Vandermonde matrices. <p> This is an alternative to the two-term Clenshaw-type rule recently obtained in [AGR93]. Another by-product is a downdating divided differences scheme. It is analytically shown that this new scheme, implemented in a finite precision arithmetic, provides a favorably small backward error, if the Leja ordering <ref> [Hig90] </ref>, [R90] of interpolation points is employed. 2 The paper is structured as follows. In the next section we recall the conventional Parker--Forney-Traub algorithm, and moreover, providing a nice interpretation in terms of the corresponding (Hessenberg) companion matrix. <p> the successive maximization of the quantities k1 Y jx k x i j = max k1 Y jx j x i j: (8.11) Note that (8.11) is called Leja ordering, see, e.g., [R90] and the references therein, and that the O (n 2 ) algorithm for computing (8.11) appeared in <ref> [Hig90] </ref>. The formula (8.11) provides some insight why Leja ordering improves the numerical performance of the new divided differences. Indeed, their downdating nature allows us to first process the outliers among fx k g, which has the following advantages.
Reference: [Hig96] <author> N.Higham, </author> <title> Accuracy and Stability of Numerical Algorithms, </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: Recall that the standard updating divided differences are computed by c = ~ L n1 ::: ~ L 1 f; with ~ L as in (8.2), and that the rounding error analysis for it can be found, for example, in <ref> [Hig96] </ref>, where it was mentioned that such bounds without explanation appeared in [KF63]. <p> It was noted in <ref> [Hig96] </ref>, p.111 that if interpolation points are monotonically ordered, x 1 &lt; x 2 &lt; ::: &lt; x n , then the sign pattern of the factors (8.2) prevents any cancellation, allowing to replace (8.7) by a better bound jf L ^cj ((1 u) 3 (n1) 1)j jLj j^cj: (8.8) Note,
Reference: [H1819] <author> W.G.Horner, </author> <title> A new method of solving numerical equations of all orders by continuous approximation, </title> <journal> Philos. Trans. Roy. Soc. London, </journal> <volume> (1819), </volume> <pages> 308-335. 19 </pages>
Reference-contexts: However, as was noted in [C11], the Horner's method was anticipated by Ruffini, and moreover Horner himself pointed out in <ref> [H1819] </ref>, that these polynomials were known to Lagrange [L1775]. However, all of the above men had been anticipated by Chinese mathematicians, see e.g. [C11].
Reference: [K69] <author> I.Kaufman, </author> <title> The inversion of the Vandermonde matrix and the transformation to the Jordan canonical form, </title> <journal> IEEE Trans. on Automatic Control, </journal> <volume> 14(1969), 774 - 777. </volume>
Reference-contexts: Government. 1 fast inversion algorithm has been rederived in the mathematical and engineering literature several times, and now it is usually associated with the names of Parker [P64], Forney [F66] and Traub [T66] (see also [Wertz65], <ref> [K69] </ref>). It was demonstrated numerically in [GO96] that the Parker-Forney-Traub algorithm is not only faster, but it is also much more accurate that the standard numerically stable methods.
Reference: [KF63] <author> W.Kahan and I.Farkas, </author> <title> Algorithms 167 - 169, </title> <journal> Comm. ACM, </journal> <volume> 6 No 4, </volume> <month> April </month> <year> 1963, </year> <note> 164-165; see also the certification, </note> <editor> isid, </editor> <volume> 6 No 9, </volume> <month> September </month> <year> 1963, </year> <month> 523. </month>
Reference-contexts: the standard updating divided differences are computed by c = ~ L n1 ::: ~ L 1 f; with ~ L as in (8.2), and that the rounding error analysis for it can be found, for example, in [Hig96], where it was mentioned that such bounds without explanation appeared in <ref> [KF63] </ref>.
Reference: [KO94] <author> T.Kailath and V.Olshevsky, </author> <title> Displacement structure approach to polynomial Vander-monde and related matrices, </title> <type> preprint, </type> <year> 1994. </year>
Reference-contexts: In the next section we shall use (2.14) to extend the concept of the associated polynomials to arbitrary polynomial system R. 5 2.4. Associated polynomials and displacement structure. In <ref> [KO94] </ref> we used (for arbitrary given polynomials R = fr 0 (x); ::; r n (x)g) the (generalized) associated polynomials ^ R = f^r 0 (x); :::; ^r n (x)g that were specified by their confederate matrix C ^ R (^r n ) = ~ I C R (r n ) <p> This fact allowed us to to obtain in <ref> [KO94] </ref> explicit inversion formulas for polynomial Vandermonde-like matrices in terms of associated polynomials, and to design an efficient inversion procedure. However, a connection with the original Parker-Forney-Traub algorithm was not revealed in [KO94], this issue is addressed in section 2 below, where this algorithms is generalized to invert a polynomial Vandermonde <p> This fact allowed us to to obtain in <ref> [KO94] </ref> explicit inversion formulas for polynomial Vandermonde-like matrices in terms of associated polynomials, and to design an efficient inversion procedure. However, a connection with the original Parker-Forney-Traub algorithm was not revealed in [KO94], this issue is addressed in section 2 below, where this algorithms is generalized to invert a polynomial Vandermonde matrix. 3 The generalized Parker-Forney-Traub algorithm In this section we show how associated polynomials ^ R define the structure of V R (x) 1 .
Reference: [KP83] <author> T.Kailath and B.Porat, </author> <title> State-space generators for orthogonal polynomials, in Prediction theory and harmonic analysis, The Pesi Masani Volume, </title> <editor> V.Mandrekar and H.Salehi (eds.), pp.131-163, </editor> <publisher> North-Holland Publishing Company, </publisher> <year> 1983. </year>
Reference-contexts: . . . . . n2 ae n n1 ae fl b n n n1 b n1 3 7 7 7 7 (6.4) The matrix (6.4) differs from the unitary Hessenberg matrix only in the last column, and this matrix was written down [G82]) (in a slightly different form), and <ref> [KP83] </ref>. The useful properties of this unitary Hessenberg matrices were later intensively studied in the signal processing (where it appears as a system matrix of orthogonal lattice filters), and quite independently in numerical analysis literature.
Reference: [L1775] <author> J.L.Lagrange, </author> <title> Sur les suites recurrentes, </title> <editor> Nouveau Memories de l'Academie Royale de Berlin, </editor> <volume> 6(1775), </volume> <pages> 183-195. </pages>
Reference-contexts: However, as was noted in [C11], the Horner's method was anticipated by Ruffini, and moreover Horner himself pointed out in [H1819], that these polynomials were known to Lagrange <ref> [L1775] </ref>. However, all of the above men had been anticipated by Chinese mathematicians, see e.g. [C11].
Reference: [MB79] <author> J.Maroulas and S.Barnett, </author> <title> Polynomials with respect to a general basis. I. </title> <journal> Theory, J. of Math. Analysis and Appl., </journal> <note> 72 : 177 -194 (1979). </note>
Reference-contexts: Let polynomials R = fr 0 (x); r 1 (x) ; :::; r n (x)g be specified by the recurrence relations r k (x) = ff k x r k1 (x) a k1;k r k1 (x) a k2;k r k2 (x) ::: a 0;k r 0 (x): (2.9) Following <ref> [MB79] </ref>, define for the polynomial b (x) = b 0 r 0 (x) + b 1 r 1 (x) + ::: + b n1 r n1 (x) + b n r n (x) (2.10) its confederate matrix C R (b) = 6 6 6 6 6 4 ff 1 ff 2 <p> We refer to <ref> [MB79] </ref> for many useful properties of the confederate matrix and only recall here that det (xI C R (b)) = b (x)=(ff 0 ff 1 ::: ff n b n ), and that similarly, the characteristic polynomial of the k fi k leading submatrix of C R (b) is equal to <p> According to <ref> [MB79] </ref> we have C R (r n ) = S 1 6 From here and (2.15) it follows immediately that C ^ R (^r n ) = ( ~ IS T ~ I) 1 C ^ Q (^q n ) ( ~ IS T ~ I): (3.5) Briefly, the similarity matrices
Reference: [P64] <author> F.Parker, </author> <title> Inverses of Vandermonde matrices, </title> <journal> Amer. Math. Monthly, </journal> <volume> 71 (1964), 410 - 411. </volume>
Reference-contexts: Government. 1 fast inversion algorithm has been rederived in the mathematical and engineering literature several times, and now it is usually associated with the names of Parker <ref> [P64] </ref>, Forney [F66] and Traub [T66] (see also [Wertz65], [K69]). It was demonstrated numerically in [GO96] that the Parker-Forney-Traub algorithm is not only faster, but it is also much more accurate that the standard numerically stable methods. <p> In this case fast O (n 2 ) algorithms are also possible, and in the next table we list these algorithms along with the corresponding references. Table 1. Fast O (n 2 ) algorithms for three-term Vandermonde matrices. Inversion Solving linear system Parker-Forney-Traub Bjorck-Pereyra Vandermonde algorithm <ref> [P64] </ref>, [F66], [T66] algorithm [BP70] Gohberg-Olshevsky Reichel-Opfer Chebyshev-Vandermonde algorithm [GO94] algorithm [RO91] Calvetti-Reichel Higham three-term Vandermonde algorithm [CR93] algorithm [Hig90] However, many problems in signal processing applications usually involve computations with Szego polynomials, i.e., polynomials orthogonal on the unit circle.
Reference: [R90] <author> L.Reichel, </author> <title> Newton interpolation at Leja points, </title> <journal> BIT, </journal> <volume> 30(1990), 23 - 41. </volume>
Reference-contexts: This is an alternative to the two-term Clenshaw-type rule recently obtained in [AGR93]. Another by-product is a downdating divided differences scheme. It is analytically shown that this new scheme, implemented in a finite precision arithmetic, provides a favorably small backward error, if the Leja ordering [Hig90], <ref> [R90] </ref> of interpolation points is employed. 2 The paper is structured as follows. In the next section we recall the conventional Parker--Forney-Traub algorithm, and moreover, providing a nice interpretation in terms of the corresponding (Hessenberg) companion matrix. <p> partial pivoting ordering is the one maximizing the successive determinants of leading sumbatrices, which for Vandermonde structure means the successive maximization of the quantities k1 Y jx k x i j = max k1 Y jx j x i j: (8.11) Note that (8.11) is called Leja ordering, see, e.g., <ref> [R90] </ref> and the references therein, and that the O (n 2 ) algorithm for computing (8.11) appeared in [Hig90]. The formula (8.11) provides some insight why Leja ordering improves the numerical performance of the new divided differences.
Reference: [RO91] <author> L.Reichel and G.Opfer, </author> <title> Chebyshev-Vandermonde systems, </title> <journal> Math. of Comp., </journal> <volume> 57 (1991), </volume> <pages> 703-721. </pages>
Reference-contexts: Table 1. Fast O (n 2 ) algorithms for three-term Vandermonde matrices. Inversion Solving linear system Parker-Forney-Traub Bjorck-Pereyra Vandermonde algorithm [P64], [F66], [T66] algorithm [BP70] Gohberg-Olshevsky Reichel-Opfer Chebyshev-Vandermonde algorithm [GO94] algorithm <ref> [RO91] </ref> Calvetti-Reichel Higham three-term Vandermonde algorithm [CR93] algorithm [Hig90] However, many problems in signal processing applications usually involve computations with Szego polynomials, i.e., polynomials orthogonal on the unit circle. In this paper we generalize both the Parker-Forney-Traub and Bjorck-Pereyra algorithms to what we call Szego-Vandermonde matrices.
Reference: [SB80] <author> J.Stoer and R.Bulirsch, </author> <title> Introduction to Numerical Analysis, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: Then the standard divided differences in Table 1 have an updating nature, recursively computing P i;i+1;:::;i+k (x) ! P i;i+1;:::;i+k+1 (x), see, e.g., <ref> [SB80] </ref>. For example, the first step updates P i (x) = f i ! P i;i+1 (x) = f i + f i+1 f i i = 1; 2; :::; n 1. Note that the interpolation data remain unchanged.
Reference: [T66] <author> J. Traub, </author> <title> Associated polynomials and uniform methods for the solution of linear problems, </title> <journal> SIAM Review, </journal> <volume> 8, No. 3 (1966), 277 - 301. </volume>
Reference-contexts: Government. 1 fast inversion algorithm has been rederived in the mathematical and engineering literature several times, and now it is usually associated with the names of Parker [P64], Forney [F66] and Traub <ref> [T66] </ref> (see also [Wertz65], [K69]). It was demonstrated numerically in [GO96] that the Parker-Forney-Traub algorithm is not only faster, but it is also much more accurate that the standard numerically stable methods. <p> In this case fast O (n 2 ) algorithms are also possible, and in the next table we list these algorithms along with the corresponding references. Table 1. Fast O (n 2 ) algorithms for three-term Vandermonde matrices. Inversion Solving linear system Parker-Forney-Traub Bjorck-Pereyra Vandermonde algorithm [P64], [F66], <ref> [T66] </ref> algorithm [BP70] Gohberg-Olshevsky Reichel-Opfer Chebyshev-Vandermonde algorithm [GO94] algorithm [RO91] Calvetti-Reichel Higham three-term Vandermonde algorithm [CR93] algorithm [Hig90] However, many problems in signal processing applications usually involve computations with Szego polynomials, i.e., polynomials orthogonal on the unit circle. <p> However, as was noted in [C11], the Horner's method was anticipated by Ruffini, and moreover Horner himself pointed out in [H1819], that these polynomials were known to Lagrange [L1775]. However, all of the above men had been anticipated by Chinese mathematicians, see e.g. [C11]. For these historical reasons in <ref> [T66] </ref> polynomials ^ P = f^p 0 (x); ^p 1 (x); :::; ^p n1 (x); ^p n (x)g were called in [T66] the associated with P = f1; x; x 2 ; :::; x n1 ; b (x)g polynomials. 3 2.2. The Parker-Forney-Traub inversion algorithm. <p> However, all of the above men had been anticipated by Chinese mathematicians, see e.g. [C11]. For these historical reasons in <ref> [T66] </ref> polynomials ^ P = f^p 0 (x); ^p 1 (x); :::; ^p n1 (x); ^p n (x)g were called in [T66] the associated with P = f1; x; x 2 ; :::; x n1 ; b (x)g polynomials. 3 2.2. The Parker-Forney-Traub inversion algorithm. Traub used the simplicity of the recursion (2.3) to derive in [T66] a fast O (n 2 ) algorithm for inversion of Vandermonde matrices. <p> 0 (x); ^p 1 (x); :::; ^p n1 (x); ^p n (x)g were called in <ref> [T66] </ref> the associated with P = f1; x; x 2 ; :::; x n1 ; b (x)g polynomials. 3 2.2. The Parker-Forney-Traub inversion algorithm. Traub used the simplicity of the recursion (2.3) to derive in [T66] a fast O (n 2 ) algorithm for inversion of Vandermonde matrices. Before describing his result, let us introduce the necessary notations.
Reference: [Wertz65] <author> H.J.Wertz, </author> <title> On the numerical inversion of a recurrent problem : the Vandermonde matrix, </title> <journal> IEEE Trans. on Automatic Control, AC-10, </journal> <volume> 4(1965), 492. </volume> <pages> 20 </pages>
Reference-contexts: Government. 1 fast inversion algorithm has been rederived in the mathematical and engineering literature several times, and now it is usually associated with the names of Parker [P64], Forney [F66] and Traub [T66] (see also <ref> [Wertz65] </ref>, [K69]). It was demonstrated numerically in [GO96] that the Parker-Forney-Traub algorithm is not only faster, but it is also much more accurate that the standard numerically stable methods.
References-found: 32

