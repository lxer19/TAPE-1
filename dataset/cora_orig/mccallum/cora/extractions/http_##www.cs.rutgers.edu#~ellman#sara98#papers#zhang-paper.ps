URL: http://www.cs.rutgers.edu/~ellman/sara98/papers/zhang-paper.ps
Refering-URL: http://www.cs.rutgers.edu/~ellman/sara98/papers/
Root-URL: http://www.cs.rutgers.edu
Email: E-mail: zhang@isi.edu  
Title: Flexible and Approximate Computation Through State-Space Reduction  
Author: Weixiong Zhang 
Address: 4676 Admiralty Way, Marina del Rey, CA 90292  
Affiliation: Information Sciences Institute and Department of Computer Science University of Southern California  
Abstract: In the real world, insufficient information, limited computation resources, and complex problem structures often force an autonomous agent to make a decision in time less than that required to solve the problem at hand completely. Flexible and approximate computation are two approaches to decision making under limited computation resources. Flexible computation helps an agent to flexibly allocate limited computation resources so that the overall system utility is maximized. Approximate computation enables an agent to find the best satisfactory solution within a deadline. In this paper, we present two state-space reduction methods for flexible and approximate computation: quantitative reduction to deal with inaccurate heuristic information, and structural reduction to handle complex problem structures. These two methods can be applied successively to continuously improve solution quality if more computation is available. Our results show that these reduction methods are effective and efficient, finding better solutions with less computation than some existing well-known methods.
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> AAAI Fall Symposium on Rational Agency, </institution> <address> Cam-bridge, MA, 1995. </address> <publisher> AAAI. </publisher>
Reference-contexts: The performance of the agent depends not only on the quality of its decision, but also on the amount of computation resources that it uses and the penalty introduced by response delay. This area of research is becoming more and more important and has drawn much attention recently <ref> [1, 2, 3] </ref>. An important issue of flexible computation is to find the relationship between deliberation, which is the process of searching for a high-quality decision, and the payoff of such a decision [5, 9, 14, 32]. This relationship is usually represented by a performance profile [32].
Reference: [2] <institution> IJCAI-95 Workshop on Anytime Algorithms and Deliberation Scheduling, Montreal, Canada, </institution> <month> Aug. </month> <year> 1995. </year>
Reference-contexts: The performance of the agent depends not only on the quality of its decision, but also on the amount of computation resources that it uses and the penalty introduced by response delay. This area of research is becoming more and more important and has drawn much attention recently <ref> [1, 2, 3] </ref>. An important issue of flexible computation is to find the relationship between deliberation, which is the process of searching for a high-quality decision, and the payoff of such a decision [5, 9, 14, 32]. This relationship is usually represented by a performance profile [32].
Reference: [3] <institution> AAAI Fall Symposium on Flexible Computation in Intelligent Systems, </institution> <address> Cambridge, MA, 1996. </address> <publisher> AAAI. </publisher>
Reference-contexts: The performance of the agent depends not only on the quality of its decision, but also on the amount of computation resources that it uses and the penalty introduced by response delay. This area of research is becoming more and more important and has drawn much attention recently <ref> [1, 2, 3] </ref>. An important issue of flexible computation is to find the relationship between deliberation, which is the process of searching for a high-quality decision, and the payoff of such a decision [5, 9, 14, 32]. This relationship is usually represented by a performance profile [32].
Reference: [4] <author> R. Bisiani. </author> <title> Search, beam. </title> <editor> In S. C. Shapiro, editor, </editor> <booktitle> Encyclopedia of Artificial Intelligence, </booktitle> <pages> pages 1467-1468. </pages> <publisher> Wiley-Interscience, </publisher> <address> New York, 2nd edition, </address> <year> 1992. </year>
Reference-contexts: The idea of quantitative reduction was originally developed in [25, 31] for finding approximate solutions to combinatorial optimization problems. The basic idea of structural reduction can be traced back to beam search <ref> [4] </ref>, an old heuristic technique for reducing search complexity. This heuristic technique was recently turned into a complete, anytime search algorithm [28]. In this paper, we re-examine these ideas and techniques for flexible and approximate computation. The paper is organized as follows. In Section 2, we briefly discuss state-space search.
Reference: [5] <author> M. Boddy and T. Dean. </author> <title> Deliberation scheduling for problem solving in time-constrained environments. </title> <journal> Artificial Intelligence, </journal> <volume> 67 </volume> <pages> 245-285, </pages> <year> 1994. </year>
Reference-contexts: In situation where computation resources are limited and a deadline must be met, flexible computation can assist an agent to allocate its computation resources in such a way that its overall performance or utility is maximized <ref> [5, 9, 14, 32] </ref>. The performance of the agent depends not only on the quality of its decision, but also on the amount of computation resources that it uses and the penalty introduced by response delay. <p> This area of research is becoming more and more important and has drawn much attention recently [1, 2, 3]. An important issue of flexible computation is to find the relationship between deliberation, which is the process of searching for a high-quality decision, and the payoff of such a decision <ref> [5, 9, 14, 32] </ref>. This relationship is usually represented by a performance profile [32]. If the agent has a performance profile of a problem to be solved, it can estimate the amount of computation that it needs in order to find a solution with a satisfactory quality, or vice versa.
Reference: [6] <author> G. Carpaneto and P. Toth. </author> <title> Some new branching and bounding criteria for the asymmetric traveling salesman problem. </title> <journal> Management Science, </journal> <volume> 26 </volume> <pages> 736-743, </pages> <year> 1980. </year>
Reference-contexts: If the solution to the assignment problem happens to be a single complete tour, it is also the solution to the ATSP. When the solution to the assignment problem is not a complete tour, it is decomposed, generating subproblems. In our implementation of DFBnB, we adopted Carpaneto and Toth's <ref> [6] </ref> method to generate subproblems. To set the value of " fl , we need information of node branching factors and edge costs in state space. We use an online sampling method to empirically calculate the node branching factors and distribution of the edge costs.
Reference: [7] <author> P. Dagum and M. Luby. </author> <title> Approximating probabilistic inference in bayesian belief networks is NP-hard. </title> <journal> Artificial Intelligence, </journal> <volume> 60 </volume> <pages> 141-153, </pages> <year> 1993. </year>
Reference-contexts: Approximation methods can be categorized into two classes. The first class finds solutions of qualities within a predefined acceptance bound [22]. However, finding approximate solutions with a predefined quality for some difficult problems, such as evaluation of Bayesian belief networks and graph coloring, still remains NP-hard <ref> [7, 22] </ref>. In addition, algorithms in this class usually cannot generate a useful result before the end of execution.
Reference: [8] <author> D. Davis and H. Putnam. </author> <title> A computing procedure for quantification theory. </title> <journal> JACM, </journal> <volume> 7 </volume> <pages> 201-215, </pages> <year> 1960. </year>
Reference-contexts: The next iteration increases probability p by 0.1, and so forth, until no reduction has been applied in the latest iteration or probability p is greater than 1. We compared ffi-DFBnB against DFBnB on maximum 3-satisfiability (3-Sat) [12] using a variation of Davis-Putnam method <ref> [8] </ref>. We generated maximum 3-Sat problem instances by randomly selecting three variables and negating them with probability 0.5 for each clause. Duplicate clauses were removed.
Reference: [9] <author> T. Dean and M. Boddy. </author> <title> An analysis of time-dependent planning. </title> <booktitle> In Proc. AAAI-88, </booktitle> <pages> pages 49-54, </pages> <address> St. Paul, MN, </address> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: In situation where computation resources are limited and a deadline must be met, flexible computation can assist an agent to allocate its computation resources in such a way that its overall performance or utility is maximized <ref> [5, 9, 14, 32] </ref>. The performance of the agent depends not only on the quality of its decision, but also on the amount of computation resources that it uses and the penalty introduced by response delay. <p> This area of research is becoming more and more important and has drawn much attention recently [1, 2, 3]. An important issue of flexible computation is to find the relationship between deliberation, which is the process of searching for a high-quality decision, and the payoff of such a decision <ref> [5, 9, 14, 32] </ref>. This relationship is usually represented by a performance profile [32]. If the agent has a performance profile of a problem to be solved, it can estimate the amount of computation that it needs in order to find a solution with a satisfactory quality, or vice versa. <p> In addition, algorithms in this class usually cannot generate a useful result before the end of execution. The second class of approximation methods are anytime algorithms <ref> [9] </ref>, which first finds a solution quickly, and then successively improves the quality of the best solution at hand as long as more computation is available. Therefore, these methods do not have to set their goals in advance.
Reference: [10] <author> R. Dechter. </author> <title> Constraint networks. </title> <editor> In S. C. Shapiro, editor, </editor> <booktitle> Encyclopedia of Artificial Intelligence, </booktitle> <pages> pages 276-285. </pages> <publisher> Wiley-Interscience, </publisher> <address> New York, 2 edition, </address> <year> 1992. </year>
Reference-contexts: For example, a state-space graph is more complex than a state-space tree. A concrete example is that a constraint network can be solved optimally in linear time if the network is tree structured <ref> [10] </ref>, while finding solutions of a constraint network is NP-complete in general [18]. 3 Quantitative State-Space Reduction Quantitative state-space reduction was motivated to deal with computation complexity introduced by the lack of sufficient or precise information about the problem to be solved.
Reference: [11] <author> R. Dechter and J. Pearl. </author> <title> Generalized best-first search strategies and the optimality of A fl . JACM, </title> <booktitle> 32 </booktitle> <pages> 505-536, </pages> <year> 1985. </year>
Reference-contexts: BFS is optimal among all algorithms that are guaranteed to find an optimal goal node using the same cost function, up to tie breaking <ref> [11] </ref>. Therefore, the complexity of BFS is the complexity of the problem, in terms of the number of nodes generated. However, BFS usually requires memory exponential in search depth, making it im-practical for large problems. DFBnB uses an upper bound u on the cost of an optimal goal. <p> Following the optimality of BFS <ref> [11] </ref>, Theorem 3.1 means that the expected complexity of finding an opti mal goal experiences an abrupt transition, from exponential to polynomial in the search depth.
Reference: [12] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <publisher> Freeman, </publisher> <address> New York, NY, </address> <year> 1979. </year>
Reference-contexts: The next iteration increases probability p by 0.1, and so forth, until no reduction has been applied in the latest iteration or probability p is greater than 1. We compared ffi-DFBnB against DFBnB on maximum 3-satisfiability (3-Sat) <ref> [12] </ref> using a variation of Davis-Putnam method [8]. We generated maximum 3-Sat problem instances by randomly selecting three variables and negating them with probability 0.5 for each clause. Duplicate clauses were removed.
Reference: [13] <author> M. Held and R. M. Karp. </author> <title> The traveling salesman problem and minimum spanning trees: Part ii. </title> <journal> Mathematical Programming, </journal> <volume> 1 </volume> <pages> 6-25, </pages> <year> 1971. </year>
Reference-contexts: We also compared iterative ffi-DFBnB against DFBnB on the symmetric TSP (STSP), in which the cost from city i to city j is the same as that of from j to i. In our implementation, we use Held-Karp lower bound function <ref> [13] </ref> to compute node costs. This cost function iteratively computes a Lagrangian relaxation on the STSP, with each step constructing a 1-tree.
Reference: [14] <author> E. J. Horvitz. </author> <title> Reasoning about beliefs and actions under computational resource constraints. </title> <booktitle> In Proc. 3rd Workshop on UAI, </booktitle> <year> 1987. </year>
Reference-contexts: In situation where computation resources are limited and a deadline must be met, flexible computation can assist an agent to allocate its computation resources in such a way that its overall performance or utility is maximized <ref> [5, 9, 14, 32] </ref>. The performance of the agent depends not only on the quality of its decision, but also on the amount of computation resources that it uses and the penalty introduced by response delay. <p> This area of research is becoming more and more important and has drawn much attention recently [1, 2, 3]. An important issue of flexible computation is to find the relationship between deliberation, which is the process of searching for a high-quality decision, and the payoff of such a decision <ref> [5, 9, 14, 32] </ref>. This relationship is usually represented by a performance profile [32]. If the agent has a performance profile of a problem to be solved, it can estimate the amount of computation that it needs in order to find a solution with a satisfactory quality, or vice versa.
Reference: [15] <author> T. Ibaraki, S. Muro, T. Murakami, and T. Hasegawa. </author> <title> Using branch-and-bound algorithms to obtain suboptimal solutions. </title> <journal> Zeitchrift fur Operations Research, </journal> <volume> 27 </volume> <pages> 177-202, </pages> <year> 1983. </year>
Reference-contexts: Starting with a low-quality solution, local search repeatedly improves the current solution with local perturbations until it reaches a local minimum. It then repeats this procedure with a new starting solution if more computation is available. Another anytime algorithm is truncated depth-first branch-and-bound (DFBnB) <ref> [15, 27] </ref>. Truncated DFBnB executes DFBnB until it exhausts all available computation. The best solution found so far is then an approximate solution. In this paper, we present two general and efficient state-space reduction methods for flexible and approximate computation.
Reference: [16] <author> P. C. Kanellakis and C. H. Papadimitriou. </author> <title> Local search for the asymmetric traveling salesman problem. </title> <journal> Operations Research, </journal> <volume> 28 </volume> <pages> 1086-1099, </pages> <year> 1980. </year>
Reference-contexts: These estimates are then used to calculate a value for ". As the search proceeds, the estimates of the branching factor and edge-cost distribution can be refined and used to update the value of ". We compared " fl -DFBnB with local search for the ATSP <ref> [16] </ref>. The average running time of local search is longer than that of "-DFBnB on four different problem structures we considered.
Reference: [17] <author> R. M. Karp and J. Pearl. </author> <title> Searching for an optimal path in a tree with random costs. </title> <journal> Artificial Intelligence, </journal> <volume> 21 </volume> <pages> 99-117, </pages> <year> 1983. </year>
Reference-contexts: A state space can be captured by an abstract model called incremental random tree, which has been used to analyze many state-space search algorithms <ref> [17, 19, 30] </ref>. This model is illustrated by Figure 1 and is defined as follows. Definition 2.1 An incremental random tree T (b; d) is a tree with depth d, variable branching factors with mean b, and non-negative variable edge costs. <p> Then bp 0 is the expected number of children of a node whose costs are the same as that of their parent, which are referred to as same-cost children of the node. Theorem 3.1 <ref> [17, 19, 30] </ref> On an incremental random tree T (b; d), as d ! 1, (1) when bp 0 &lt; 1, both BFS and DFBnB generate (fl d ) nodes on average for some constant fl, 1 &lt; fl b, (2) when bp 0 = 1, BFS generates (d 2 )
Reference: [18] <author> A. K. Mackworth. </author> <title> Consistency in networks of relations. </title> <journal> Artificial Intelligence, </journal> <volume> 8 </volume> <pages> 99-118, </pages> <year> 1977. </year>
Reference-contexts: For example, a state-space graph is more complex than a state-space tree. A concrete example is that a constraint network can be solved optimally in linear time if the network is tree structured [10], while finding solutions of a constraint network is NP-complete in general <ref> [18] </ref>. 3 Quantitative State-Space Reduction Quantitative state-space reduction was motivated to deal with computation complexity introduced by the lack of sufficient or precise information about the problem to be solved.
Reference: [19] <author> C. J. H. McDiarmid and G. M. A. Provan. </author> <title> An expected-cost analysis of backtracking and non-backtracking algorithms. </title> <booktitle> In Proc. IJCAI-91, </booktitle> <pages> pages 172-177, </pages> <address> Sydney, Australia, </address> <month> August </month> <year> 1991. </year>
Reference-contexts: A state space can be captured by an abstract model called incremental random tree, which has been used to analyze many state-space search algorithms <ref> [17, 19, 30] </ref>. This model is illustrated by Figure 1 and is defined as follows. Definition 2.1 An incremental random tree T (b; d) is a tree with depth d, variable branching factors with mean b, and non-negative variable edge costs. <p> Then bp 0 is the expected number of children of a node whose costs are the same as that of their parent, which are referred to as same-cost children of the node. Theorem 3.1 <ref> [17, 19, 30] </ref> On an incremental random tree T (b; d), as d ! 1, (1) when bp 0 &lt; 1, both BFS and DFBnB generate (fl d ) nodes on average for some constant fl, 1 &lt; fl b, (2) when bp 0 = 1, BFS generates (d 2 )
Reference: [20] <author> D. L. Miller and J. F. Pekny. </author> <title> Exact solution of large asymmetric traveling salesman problems. </title> <journal> Science, </journal> <volume> 251 </volume> <pages> 754-761, </pages> <year> 1991. </year>
Reference-contexts: Figure 5 shows the results on the ATSP with (c i;j ) uniformly selected from f0; 1; ; i fi jg, which are known to be very difficult for BnB using the assignment problem evaluation function <ref> [20] </ref>. Each data point in Figure 5 is averaged over 100 problems, ranging from 100 cities to 1,000 cities. The results show that "-DFBnB outperforms local search: it runs faster and finds better solutions. 3.4 Iterative quantitative reduction Quantitative reduction can be applied successively.
Reference: [21] <author> D. Mitchell, B. Selman, and H. Levesque. </author> <title> Hard and easy distributions of SAT problems. </title> <booktitle> In Proc. AAAI-92, </booktitle> <pages> pages 459-465, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Duplicate clauses were removed. The problem instances we used have a large ratio of the number of clauses to the number of variables (clause to variable ratio), since random 3-Sat problems with a small clause-to-variable ratio are generally satisfiable <ref> [21] </ref>. Figure 8 (a) shows the experimental result of on 3-Sat with 30 variables and 450 clauses, averaged over 100 random problem instances. Figure 8 (a) shows that iterative ffi-DFBnB significantly improves the anytime performance of DFBnB, finding better solutions sooner.
Reference: [22] <author> R. Motwani. </author> <title> Lecture notes on approximation algorithms. </title> <type> Technical Report STAN-CS-92-1435, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1992. </year>
Reference-contexts: In situations where seeking an optimal solution is not feasible, approximation methods enable an agent to find satisfactory solutions that can be found with a reasonable amount of computation. Approximation methods can be categorized into two classes. The first class finds solutions of qualities within a predefined acceptance bound <ref> [22] </ref>. However, finding approximate solutions with a predefined quality for some difficult problems, such as evaluation of Bayesian belief networks and graph coloring, still remains NP-hard [7, 22]. In addition, algorithms in this class usually cannot generate a useful result before the end of execution. <p> Approximation methods can be categorized into two classes. The first class finds solutions of qualities within a predefined acceptance bound [22]. However, finding approximate solutions with a predefined quality for some difficult problems, such as evaluation of Bayesian belief networks and graph coloring, still remains NP-hard <ref> [7, 22] </ref>. In addition, algorithms in this class usually cannot generate a useful result before the end of execution.
Reference: [23] <author> C. H. Papadimitriou and K. Steiglitz. </author> <title> Combinatorial Optimization: Algorithms and Complexity. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1982. </year>
Reference-contexts: Therefore, these methods do not have to set their goals in advance. The challenge for anytime algorithms is how to find good solutions as soon as possible. Many existing incremental refinement and iterative improvement methods have been used as anytime algorithms. One important any-time algorithm is local search <ref> [23] </ref>. Starting with a low-quality solution, local search repeatedly improves the current solution with local perturbations until it reaches a local minimum. It then repeats this procedure with a new starting solution if more computation is available. Another anytime algorithm is truncated depth-first branch-and-bound (DFBnB) [15, 27]. <p> Similarly, solutions with lower costs (higher quality) can be generated with greater computation by using a smaller value of ", on average. 3.3 Performance of quantitative reduction We have applied quantitative reduction to several combinatorial optimization problems, including the Traveling Salesman Problem (TSP) and constraint satisfaction problems <ref> [23] </ref>. We now report our results on the asymmetric TSP (ATSP). <p> When (c i;j ) is asymmetric, i.e., the cost from city i to city j is not necessarily equal to that from j to i, the problem is referred to as the ATSP. The best cost function to the ATSP is the assignment problem <ref> [23] </ref>, which is a relaxation of the ATSP since the assignments do not need to form a single tour, but instead can form a collection of disjoint subtours. If the solution to the assignment problem happens to be a single complete tour, it is also the solution to the ATSP. <p> In our implementation, we use Held-Karp lower bound function [13] to compute node costs. This cost function iteratively computes a Lagrangian relaxation on the STSP, with each step constructing a 1-tree. A 1-tree is a minimum spanning tree (MST) <ref> [23] </ref> on n 1 cities plus the two shortest edges from the city not in the MST to two cities in the MST. Note that a complete TSP tour is a 1-tree.
Reference: [24] <author> J. Pearl. </author> <title> Heuristics: Intelligent Search Strategies for Computer Problem Solving. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1984. </year>
Reference-contexts: A state-space tree is a special state space which has been used extensively <ref> [24] </ref>. In a state-space tree, a leaf node is a goal state or a state that cannot lead to a solution, A node's cost is the estimate of the actual cost of solving the problem through that node. <p> An important class of node costs is monotonic, in the sense that a node cost is monotonically nondecreasing with its depth in the search tree. For most real-world problems, monotonic node costs are available or can be easily derived <ref> [24] </ref>. A state-space tree can also be viewed as if it has edge costs. The cost of an edge connecting two nodes is the cost difference between the child node and the parent, or the cost of the operator mapping the parent to the child. <p> It is known that a very limited search is required if an accurate heuristic evaluation function is given. However, inaccurate heuristic functions generally prevents a problem from being solvable in polynomial time in terms of the problem size, even in an average case <ref> [24, 30] </ref>. The second source that leads to a difficult state space is the structure of the state space itself. For example, a state-space graph is more complex than a state-space tree.
Reference: [25] <author> J. C. Pemberton and W. Zhang. Epsilon-transformation: </author> <title> Exploiting phase transitions to solve combinatorial optimization problems. </title> <journal> Artificial Intelligence, </journal> <volume> 81 </volume> <pages> 297-325, </pages> <year> 1996. </year>
Reference-contexts: It abandons or postpones exploring nonpromising search avenues. Both quantitative and structural reduction methods can be applied repeatedly to incrementally provide better solutions with additional computation. The idea of quantitative reduction was originally developed in <ref> [25, 31] </ref> for finding approximate solutions to combinatorial optimization problems. The basic idea of structural reduction can be traced back to beam search [4], an old heuristic technique for reducing search complexity. This heuristic technique was recently turned into a complete, anytime search algorithm [28]. <p> For notational simplicity, we refer to BnB (BFS or DF-BnB) using quantitative reduction as "-BnB ("-BFS or "-DFBnB). The expected performance of " fl -BnB is summarized in the following theorem. Theorem 3.2 <ref> [25, 31] </ref> On an incremental tree T (b; d) with bp 0 &lt; 1, as d ! 1, " fl -BnB runs in an expected time that is at most cubic in d, and finds a goal whose expected relative solution cost error is almost surely a constant less than or
Reference: [26] <author> T. Volgenant and R. Jonker. </author> <title> A branch and bound algorithm for the symmetric Traveling Salesman problem based on the 1-tree relaxation. </title> <journal> European J. of Operations Research, </journal> <volume> 9 </volume> <pages> 83-89, </pages> <year> 1982. </year>
Reference-contexts: Note that a complete TSP tour is a 1-tree. If no complete TSP tour has been found after a predefined number of steps of Lagrangian relaxation, which is n=2 in our experiment, the problem is decomposed into at most three subproblems using the Volgenant and Jonker's branching rule <ref> [26] </ref>. We generated STSP problem instances by uniformly choosing a cost between two cities from f0; 1; 2; ; 2 32 1g. Figure 8 (b) shows the experimental result on 100-city random STSPs, averaged over 100 instances.
Reference: [27] <author> W. Zhang. </author> <title> Truncated branch-and-bound: A case study on the asymmetric TSP. </title> <booktitle> In Working Notes of AAAI 1993 Spring Symp.: AI and NP-Hard Problems, </booktitle> <pages> pages 160-166, </pages> <address> Stanford, CA, </address> <year> 1993. </year>
Reference-contexts: Starting with a low-quality solution, local search repeatedly improves the current solution with local perturbations until it reaches a local minimum. It then repeats this procedure with a new starting solution if more computation is available. Another anytime algorithm is truncated depth-first branch-and-bound (DFBnB) <ref> [15, 27] </ref>. Truncated DFBnB executes DFBnB until it exhausts all available computation. The best solution found so far is then an approximate solution. In this paper, we present two general and efficient state-space reduction methods for flexible and approximate computation.
Reference: [28] <author> W. Zhang. </author> <title> Complete anytime beam search. </title> <booktitle> In Proc. </booktitle> <address> AAAI-98, Madison, WI, </address> <month> July </month> <year> 1998. </year>
Reference-contexts: The basic idea of structural reduction can be traced back to beam search [4], an old heuristic technique for reducing search complexity. This heuristic technique was recently turned into a complete, anytime search algorithm <ref> [28] </ref>. In this paper, we re-examine these ideas and techniques for flexible and approximate computation. The paper is organized as follows. In Section 2, we briefly discuss state-space search. In Section 3 and Section 4, we describe quantitative and structural state-space reduction methods, respectively, along with experimental results.
Reference: [29] <author> W. Zhang and R. E. Korf. </author> <title> Performance of linear-space search algorithms. </title> <journal> Artificial Intelligence, </journal> <volume> 79 </volume> <pages> 241-292, </pages> <year> 1995. </year>
Reference: [30] <author> W. Zhang and J. C. Pemberton. Epsilon-transformation: </author> <title> Exploiting phase transitions to solve combinatorial optimization problems Initial results. </title> <booktitle> In Proc. AAAI-94. </booktitle>
Reference-contexts: A state space can be captured by an abstract model called incremental random tree, which has been used to analyze many state-space search algorithms <ref> [17, 19, 30] </ref>. This model is illustrated by Figure 1 and is defined as follows. Definition 2.1 An incremental random tree T (b; d) is a tree with depth d, variable branching factors with mean b, and non-negative variable edge costs. <p> Whenever a new leaf node is found whose cost is less than u, u is revised to its cost. Since DFBnB only needs memory linear in the search depth, it is preferable for large problems in practice <ref> [30] </ref>. 2.2 Why state-space search is difficult Two sources make a state space difficult to search. The first is the lack of sufficient or precise information about the problem to be solved. It is known that a very limited search is required if an accurate heuristic evaluation function is given. <p> It is known that a very limited search is required if an accurate heuristic evaluation function is given. However, inaccurate heuristic functions generally prevents a problem from being solvable in polynomial time in terms of the problem size, even in an average case <ref> [24, 30] </ref>. The second source that leads to a difficult state space is the structure of the state space itself. For example, a state-space graph is more complex than a state-space tree. <p> Then bp 0 is the expected number of children of a node whose costs are the same as that of their parent, which are referred to as same-cost children of the node. Theorem 3.1 <ref> [17, 19, 30] </ref> On an incremental random tree T (b; d), as d ! 1, (1) when bp 0 &lt; 1, both BFS and DFBnB generate (fl d ) nodes on average for some constant fl, 1 &lt; fl b, (2) when bp 0 = 1, BFS generates (d 2 ) <p> A simple example of a phase transition is that water changes from a solid phase to a liquid phase when the temperature rises from below the freezing point to above that point. This complexity transition is studied in great detail in <ref> [30] </ref> and is illustrated by Figure 2. 3.2 Quantitative state-space reduction Quantitative reduction reduces a difficult state space in the exponential region of Figure 2 into an easy one in the polynomial region. <p> The accuracy of a heuristic evaluation can be measured by the cost of the optimal goal node of a state space. The smaller the cost of an optimal goal node, the more accurate the evaluation function <ref> [30] </ref>. The cost of an optimal goal node in the reduced state space is no larger than the cost of an optimal goal node in the original state space, because quantitative reduction reduces some edge costs to zero.
Reference: [31] <author> S. Zilberstein and S. J. Russell. </author> <title> Optimal composition of real-time systems. </title> <journal> Artificial Intelligence, </journal> <volume> 82 </volume> <pages> 181-213, </pages> <year> 1996. </year>
Reference-contexts: It abandons or postpones exploring nonpromising search avenues. Both quantitative and structural reduction methods can be applied repeatedly to incrementally provide better solutions with additional computation. The idea of quantitative reduction was originally developed in <ref> [25, 31] </ref> for finding approximate solutions to combinatorial optimization problems. The basic idea of structural reduction can be traced back to beam search [4], an old heuristic technique for reducing search complexity. This heuristic technique was recently turned into a complete, anytime search algorithm [28]. <p> For notational simplicity, we refer to BnB (BFS or DF-BnB) using quantitative reduction as "-BnB ("-BFS or "-DFBnB). The expected performance of " fl -BnB is summarized in the following theorem. Theorem 3.2 <ref> [25, 31] </ref> On an incremental tree T (b; d) with bp 0 &lt; 1, as d ! 1, " fl -BnB runs in an expected time that is at most cubic in d, and finds a goal whose expected relative solution cost error is almost surely a constant less than or
References-found: 31

