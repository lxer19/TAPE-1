URL: http://www.tns.lcs.mit.edu/~djw/library/osdi96/greenwald.ps.gz
Refering-URL: http://www.tns.lcs.mit.edu/~djw/library/osdi96/index.html
Root-URL: 
Email: Email: office@usenix.org  
Title: The Synergy Between Non-blocking Synchronization and Operating System Structure  
Phone: 1. Phone: 510 528-8649 2. FAX: 510 548-5738 3.  4.  
Author: Michael Greenwald and David Cheriton 
Affiliation: Stanford University  
Web: WWW URL: http://www.usenix.org  
Date: October 1996  
Note: The following paper was originally published in the Proceedings of the USENIX 2nd Symposium on Operating Systems Design and Implementation Seattle, Washington,  For more information about USENIX Association contact:  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> J. Allemany and E.W.Felton, </author> <title> Performance issues in non-blocking synchronization on shared memory multiprocessors. </title> <booktitle> Proceedings of the 11th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pp 125-134, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Four algorithms were simulated: 1. DCAS/Cload: Our DCAS algorithm with contention controlled by advisory locking, as implemented on Paradigm. 2. DCAS/A&F: DCAS algorithm with contention controlled by OS intervention as proposed by Allemany and Felten <ref> [1] </ref> and described in Section 8.4. 3. CAS: An implementation using only CAS and supporting a much higher degree of concurrency based on a technique by Valois [24] 6 . 4. SpinLock: Spin-lock with exponential back-off as a base case. <p> Thus, P 1 delays P 3 . Longer chains can be constructed. hardware complexity of the other schemes unnecessary. 8.4 Operating System Support Allemany and Felten <ref> [1] </ref> reduce useless concurrency with OS support to provide the same functionality that we support in hardware using cache-based advisory locking. The method is a variation on the technique of Bershad discussed in Section 6.1.
Reference: [2] <author> J.H. Anderson and M. Moir, </author> <title> Universal Constructions for Multi-Object Operations, </title> <booktitle> Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <address> Ottawa, Ont. Canada, </address> <pages> pp 184-193, </pages> <month> August 20-23, </month> <year> 1995 </year>
Reference-contexts: Anderson and Moir <ref> [2] </ref> improve upon this, requiring only realistic sized words, O (1) time, but still requiring a prohibitively large amount of space. Finally, Software Transactional Memory [19] is an attempt to implement Transactional Memory in software, depending only on LL/SC .
Reference: [3] <author> G. Barnes, </author> <title> A Method for Implementing Lock-Free Shared Data Structures Proceedings of the 5th ACM Symposium on Parallel Algorithms and Architectures 1993 </title>
Reference-contexts: In contrast, our contribution is a set of general techniques that the programmer incorporates in the software design and implementation, allowing the software to be used in both sequential and parallel execution with no modification and with acceptable performance. Barnes <ref> [3] </ref>, Turek [23], and Valois [24] provide techniques for increasing the concurrency with some non-blocking synchronization. However, the cost of concurrent updates appears to outweigh the actual benefit, because the low rates of contention in our system.
Reference: [4] <author> B.N. Bershad, </author> <title> Practical considerations for non-blocking concurrent objects. </title> <booktitle> Proceedings 13th IEEE International Conference on Distributed Computing Systems, </booktitle> <address> Los Alamitos CA, </address> <publisher> IEEE Computer Society Press, </publisher> <pages> pp 264-273, </pages> <month> May 25-28, </month> <year> 1993. </year>
Reference-contexts: We have worked out a detailed design for the implementation of these two instructions in a RISC processor such as the R4000 but the description is omitted for brevity. 6.1 Software Implementation of DCAS DCAS functionality can be implemented in software using a technique introduced by Bershad <ref> [4] </ref>. DCAS is implemented using a lock known to the operating system. If a process holding this locks is delayed by a context switch, the operating system rolls back the process out of the DCAS procedure and releases the lock.
Reference: [5] <author> E.A. Brewer, C.N. Dellarocas, A. Colbrook, and W.E. Weihl, PROTEUS: </author> <title> A High-Performance Parallel-Architecture Simulator, </title> <type> Technical Report MIT/LCS/TR-516, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: To understand how our system behaves under heavy load, we have simulated insertion/deletion into a singly linked list under loads far heavier than would ever be encountered in the Cache Kernel. Our simulation was run on the Proteus simulator <ref> [5] </ref>, simulating 16 processors, a cache with 2 lines per set, a shared bus, and using the Goodman cache-coherence protocol. All times are reported in cycles from start of test until the last processor finishes executing. Memory la tency is modeled at 10 times the cost of a cache reference.
Reference: [6] <author> D.R. Cheriton, </author> <title> The V Distributed System. </title> <journal> Communications of the ACM, </journal> <volume> 31(3), </volume> <pages> pp 314-333, </pages> <month> March </month> <year> 1988 </year>
Reference-contexts: First, signals are the only kernel-supported form of notification, allowing a simple, efficient kernel implementation compared to more complex kernel message primitives, such as those used in V <ref> [6] </ref>. Class libraries implement higher-level communication like RPC in terms of signals and shared memory regions [25]. Non-blocking synchronization allows efficient library implementation without the overhead of disabling and enabling signals as part of access and without needing to carefully restrict the code executed by signal handlers.
Reference: [7] <author> D.R. Cheriton and K. Duda. </author> <title> A Caching Model of Operating System Kernel Functionality. </title> <booktitle> Proceedings of 1st Symposium on Operation Systems Design and Implementation, </booktitle> <address> Monterey, CA, </address> <pages> pp 179-193, </pages> <month> Nov 14-17, </month> <year> 1994. </year>
Reference-contexts: 1 Introduction We chose to use non-blocking synchronization in the design and implementation of the Cache Kernel <ref> [7] </ref> operating system kernel and supporting libraries for several reasons. First, non-blocking synchronization allows synchronized code to be executed in an (asynchronous) signal handler without danger of deadlock. <p> TSM also minimizes the complexity of implementing the caching model <ref> [7] </ref> of descriptors in the operating system kernel. In this approach, the number of descriptors of a given type is limited but an allocation never fails. <p> In particular, all the data structures that allow a descriptor to be absent from a list allow the descriptor to be inserted incrementally. Overall, the major Cache Kernel <ref> [7] </ref> data structures are synchronized in a straightforward manner. Threads are in two linked lists: the ready queue and the delay queue. Descriptor free lists are operated as stacks, making allocation and deallocation simple and inexpensive.
Reference: [8] <author> D.R. Cheriton, H. Goosen, and P. Boyle, </author> <title> ParaDiGM: A highly scalable shared-memory multi-computer architecture. </title> <journal> IEEE Computer, </journal> <volume> 24(2), </volume> <month> February </month> <year> 1991. </year>
Reference-contexts: The cost of using Cload in the common case is simply testing whether the Cload succeeded, given that a load of the version number is required in any case. Cload can be implemented using the cache-based advisory locking mechanism implemented in ParaDiGM <ref> [8] </ref>. Briefly, the processor advises the cache controller that a particular cache line is locked. Normal loads and stores ignore the lock bit, but the Cload instruction tests and sets the cache-level lock for a given cache line or else fails if it is already set. <p> We then discuss results from simulation indicating the performance of our approach under high contention. Finally, we discuss aspects of overall system performance. 7.1 Experimental Implementation The operating system kernel and class libraries run on the ParaDiGM architecture <ref> [8] </ref>. The basic configuration consists of 4-processor Motorola 68040-based multiprocessors running with 25 MHz clocks. The 68040 processor has a DCAS instruction, namely CAS2. This software also runs with no change except for a software implementation of DCAS, on a uniprocessor 66 MHz PowerPC 603.
Reference: [9] <author> D.R. Cheriton and R. Kutter. </author> <title> Optimizing memory-based messaging for scalable shared memory multiprocessor architectures. </title> <note> To appear in USENIX Computer Systems Journal 1996. (available as Stanford Computer Science Technical Report CS-93-123, </note> <month> December </month> <year> 1993.) </year>
Reference: [10] <author> D.R. Cheriton, H. Goosen, and P. Machanick, </author> <title> Restructuring a Parallel Simulation to Improve Cache Behavior in a Shared-Memory Multiprocessor: A First Experience. </title> <booktitle> In Proceedings of the International Symposium on Shared Memory Multiprocessing, </booktitle> <pages> pp 23-31, </pages> <address> Tokyo, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: The spatial locality of data access achieved by these techniques provides significant benefit for synchronization, whether non-blocking or conventional locks. This spatial locality also minimizes the consistency overhead when the system is running across multiple processors, with each caching portions of this shared data. In general, our experience (e.g. <ref> [10] </ref>) suggests that it is better to (re)structure the data structures to reduce contention rather than attempt to improve the behavior of able can reside in the same cache line unit so there can be physical contention without logical contention if two processor attempt to update the variables simultaneously, each processor
Reference: [11] <author> Joseph Heinrich. </author> <title> MIPS R4000 User's Manual, </title> <publisher> PTR Prentice Hall, </publisher> <address> Englewood Cliffs NJ, </address> <year> 1993 </year>
Reference: [12] <author> M.P. Herlihy and J.E.B. Moss. </author> <title> Transactional Memory: Architectural support for lock-free data structures. </title> <booktitle> 1993 20th Annual Symposium on Computer Architecture San Diego, Calif. </booktitle> <pages> pp. 289-301. </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: The RISC-like extension that we propose in Section 6 suggests that it is feasible to support in modern processors. The CISC approach does not appear viable with most current and future processors and seems likely to die out with the current processors that support it. Transactional Memory <ref> [12] </ref> provides hardware support for multiple-address atomic memory operations. It is more general than DCAS but comes at a correspondingly higher cost.
Reference: [13] <author> M. P. Herlihy. </author> <title> Wait-free synchronization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(1), </volume> <pages> pp 123-149, </pages> <month> January, </month> <year> 1991 </year>
Reference-contexts: This approach is a variant of Herlihy's general methodology <ref> [13] </ref> which can convert a sequential implementation of any data structure into a wait-free, concurrent one. However, we use DCAS to ensure atomicity with respect to the entire data structure (the scope of the version number) even though we are only copying a single descriptor 4 . <p> Herlihy's general methodology <ref> [13] </ref> shows that that single CAS is adequate in theory but appears too inefficient in practice. A few processors such as the Motorola 68040 provide a multi-word atomic instruction but that functionality is rare and is not present in any RISC processor to our knowledge.
Reference: [14] <author> M. Herlihy. </author> <title> A Methodology for Implementing Highly Concurrent Data Objects ACM Transactions on Programming Languages and Systems, </title> <booktitle> 15(5), </booktitle> <pages> 745-770, </pages> <month> November, </month> <year> 1993 </year>
Reference-contexts: In contrast, our implementation of linked lists is general, and is usable by arbitrary application code. 8.2 Methodologies for Implementing Con current Data Objects Herlihy <ref> [14] </ref> presents a methodology for converting sequential implementations of data structures into wait-free concurrent implementations. The goal is to provide a specification and transformation that is provably correct and can be applied automatically to sequential code. <p> The goal is to provide a specification and transformation that is provably correct and can be applied automatically to sequential code. It converts a sequential implementation of any data structure into a wait-free, concurrent one, just using CAS (or, slightly more efficiently <ref> [14] </ref> using load-linked and store-conditional). However, this method involves copying the entire data structure, modifying the copy, and then atomically replacing the old copy with the new copy using CAS, and retrying the entire copy and modifying if there is a conflict. <p> However, this method involves copying the entire data structure, modifying the copy, and then atomically replacing the old copy with the new copy using CAS, and retrying the entire copy and modifying if there is a conflict. Performance can be improved using other, more ad-hoc, techniques <ref> [14] </ref>, but these techniques tend to add hard-to-catch subtle synchronization problems and are still expensive. Overall, we regard this approach as impractically expensive because of the copy overhead.
Reference: [15] <author> A. Israeli and L. Rappaport, </author> <title> Disjoint-Access-Parallel Implementations of Strong Shared Memory Primitives, </title> <booktitle> Proceedings of the 13th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <address> Los Angeles, CA, </address> <pages> pp 151-160, </pages> <month> August 14-17, </month> <year> 1994 </year>
Reference-contexts: As with hardware versus software DCAS, the hardware implementation is simple and fast; further measurements are required to determine if it is compellingly so. In other work, Israeli and Rappaport <ref> [15] </ref> implement n-way atomic Compare and Swap and n-way LL/SC for P processors out of single CAS.
Reference: [16] <author> A. Israeli and L. Rappaport, </author> <title> Efficient wait-free implementation of a concurrent priority queue 7th Intl Workshop on Distributed Algorithms '93, Lausanne, </title> <booktitle> Switzerland, Lecture Notes in Computer Science 725, </booktitle> <publisher> Springer Verlag, </publisher> <pages> pp 1-17, </pages> <month> Sept. </month> <year> 1993 </year>
Reference-contexts: Other work has investigated other alternatives or optimizations of this approach, in which helper functions are executed by a new thread if there is work left to complete or rollback by a previous thread accessing this data structure. For example, Israeli et al. <ref> [16] </ref> describe a non-blocking heap implemented using 2-word LL/SC along these lines, performing multiple updates as multiple distinct operations. However, to date, we have not needed to employ these so-called helper techniques and therefore cannot comment on their actual practicality or utility.
Reference: [17] <author> H. Massalin and C. Pu. </author> <title> A lock-free multiprocessor OS kernel. </title> <type> Technical Report CUCS-005-01, </type> <institution> Computer Science Department, Columbia University, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: The server process can also be carefully protected against failure so the data structure is protected against fail-stop behavior of a random application thread, which may be destroyed by the application. This approach was used by Pu and Massalin <ref> [17] </ref>. For example, a general-purpose memory page allocator can be synchronized in this manner, relying on a TSM memory pool to minimize the access to the general allocator. However, in our code to date, the only case of queueing messages for a server module arises with device I/O. <p> from this optimization, particularly for short-execution calls that are common to operating system services and simulations. 8 Related Work Previous work has explored lock-free operating systems implementations, general techniques for wait-free concurrent data structures, and hardware and operating system support for non-blocking synchronization. 8.1 Lock-Free Operating Systems Massalin and Pu <ref> [17] </ref> describe the lock-free (non-blocking) implementation of the Synthesis V.1 multiprocessor kernel, using just CAS and DCAS, the same as our work. Their work supports our contention that DCAS is sufficient for the practical implementation of large systems using non-blocking synchronization.
Reference: [18] <author> M. Michael and M. Scott, </author> <title> Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue Algorithms, </title> <booktitle> Proceedings of the 15th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <address> Philadelphia, PA, </address> <pages> pp 267-276, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Using the crude metric of lines of code, a CAS implementation (Valois) of concurrent insertion/deletion from a linked list requires 110 lines, while the corresponding DCAS implementation requires 38 (a non-concurrent DCAS implementation takes 25). The CAS-only implementation of a FIFO queue described in <ref> [18] </ref> requires 37 lines, our DCAS version only 24. The DCAS versions are correspondingly simpler to understand and to informally verify as correct. In many cases, using DCAS, the translation from a well-understood blocking implementation to a non-blocking one is straightforward. <p> In this scenario, processes can be preempted possibly while holding a lock. As is expected, spin-locks are non-competitive once delays are introduced. In 7 The Valois simulation in Michael and Scott <ref> [18] </ref> reports better asymptotic behavior than we do. The difference appears because the authors are only simulating a FIFO queue. In the FIFO queue algorithm where insertion always occurs at the tail and deletion at the head auxiliary nodes are not traversed in general and thus don't affect completion time.
Reference: [19] <author> N. Shavit and D. Tovitov, </author> <title> Software Transactional Memory, </title> <booktitle> Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <address> Ot-tawa, Ont. Canada, </address> <pages> pp 204-213, </pages> <month> August 20-23, </month> <year> 1995 </year>
Reference-contexts: Anderson and Moir [2] improve upon this, requiring only realistic sized words, O (1) time, but still requiring a prohibitively large amount of space. Finally, Software Transactional Memory <ref> [19] </ref> is an attempt to implement Transactional Memory in software, depending only on LL/SC . Unfortunately, their implementation will not work correctly on existing implementations of LL/SC because their code (AcquireOwnerships) depends on the ability to interleave two outstanding LL/SC's simultaneously, which is not supported.
Reference: [20] <author> R. Sites, ed., </author> <title> DEC Alpha Architecture, </title> <publisher> Digital Press, </publisher> <address> Burlington, Mass. </address> <year> 1992 </year>
Reference: [21] <author> J. Stone, H. Stone, P. Heidelbergher, and J. Turek. </author> <title> Multiple Reservations and the Oklahoma Update. </title> <journal> IEEE Parallel and Distributed Technology, </journal> <volume> vol 1, no.4, </volume> <pages> pp 58-71, </pages> <month> November, </month> <year> 1993 </year>
Reference-contexts: Double LL/SC appears to be a more practical solution because DCAS functionality is sufficient and significantly simpler to implement. Oklahoma Update <ref> [21] </ref> provides an alternate implementation of multiple-address atomic memory operations. Rather than duplicating entire cache lines involved in transactions (as Transactional Memory does), Okla-homa Update requires only a reservation register per word used in their version of Load Linked. This register contains flags plus two words (and optionally two more).
Reference: [22] <author> J. Torrellas, A. Gupta, and J. Hennessy. </author> <title> Characterizing the Caching and Synchronization Performance of a Multiprocessor Operating System. </title> <booktitle> In Fifth International Conference on Architectural Support for Programminlg Languages and Operating Systems, </booktitle> <pages> pp 162-174, </pages> <month> October </month> <year> 1992 </year>
Reference-contexts: Barnes [3], Turek [23], and Valois [24] provide techniques for increasing the concurrency with some non-blocking synchronization. However, the cost of concurrent updates appears to outweigh the actual benefit, because the low rates of contention in our system. Studies such as <ref> [22] </ref>, which also reported a low level of contention on kernel data structures, suggest that this phenomenon might be more widely true than just in the Cache Kernel. 8.3 Hardware Support Most processors provide at most single Compare-and-Swap (CAS) functionality to support non-blocking synchronization.
Reference: [23] <author> J. Turek, D. Shasha and S. Prakash. </author> <title> Locking without blocking: Making Lock-Based Concurrent Data Structure Algorithms Non-Blocking. </title> <booktitle> Proceedings of the 1992 Principles of Database Systems pp 212-222, </booktitle> <year> 1992. </year>
Reference-contexts: In contrast, our contribution is a set of general techniques that the programmer incorporates in the software design and implementation, allowing the software to be used in both sequential and parallel execution with no modification and with acceptable performance. Barnes [3], Turek <ref> [23] </ref>, and Valois [24] provide techniques for increasing the concurrency with some non-blocking synchronization. However, the cost of concurrent updates appears to outweigh the actual benefit, because the low rates of contention in our system.
Reference: [24] <author> J. Valois, </author> <title> Lock-Free Linked Lists Using Compare-and-Swap, </title> <booktitle> Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <address> Ottawa, Ont. Canada, </address> <pages> pp 214-222, </pages> <month> August 20-23, </month> <year> 1995 </year>
Reference-contexts: DCAS/A&F: DCAS algorithm with contention controlled by OS intervention as proposed by Allemany and Felten [1] and described in Section 8.4. 3. CAS: An implementation using only CAS and supporting a much higher degree of concurrency based on a technique by Valois <ref> [24] </ref> 6 . 4. SpinLock: Spin-lock with exponential back-off as a base case. Each test performed a total of 10,000 insertions and deletions, divided evenly between all processes. We varied the number of processors from 1 to 16 and the number of processes per processor from 1 to 3. <p> The bus and memory contention are so much greater that the 6 It was necessary to derive our own version of the algorithm, as the algorithm presented in <ref> [24] </ref> is not strictly correct. This is the natural result of the complicated contortions necessary when using only CAS. The DCAS algorithm is relatively straightforward. per processor = 1 concurrency does not gain enough to offset the loss due to overhead. <p> In contrast, our contribution is a set of general techniques that the programmer incorporates in the software design and implementation, allowing the software to be used in both sequential and parallel execution with no modification and with acceptable performance. Barnes [3], Turek [23], and Valois <ref> [24] </ref> provide techniques for increasing the concurrency with some non-blocking synchronization. However, the cost of concurrent updates appears to outweigh the actual benefit, because the low rates of contention in our system.
Reference: [25] <author> M. Zelesko and D. R. Cheriton, </author> <title> Specializing Object Oriented RPC for Functionality and Performance, </title> <booktitle> Proceedings 16th IEEE International Conference on Distributed Computing Systems, </booktitle> <publisher> IEEE Computer Society Press, </publisher> <month> May 27-30, </month> <year> 1996. </year>
Reference-contexts: First, non-blocking synchronization allows synchronized code to be executed in an (asynchronous) signal handler without danger of deadlock. For instance, an asynchronous RPC handler (as described in <ref> [25] </ref>) can directly store a string into a synchronized data structure such as a hash table even though it may be interrupting another thread updating the same table. With locking, the signal handler could deadlock with this other thread. Second, non-blocking synchronization minimizes interference between process scheduling and synchronization. <p> First, signals are the only kernel-supported form of notification, allowing a simple, efficient kernel implementation compared to more complex kernel message primitives, such as those used in V [6]. Class libraries implement higher-level communication like RPC in terms of signals and shared memory regions <ref> [25] </ref>. Non-blocking synchronization allows efficient library implementation without the overhead of disabling and enabling signals as part of access and without needing to carefully restrict the code executed by signal handlers. <p> Second, we simplified the kernel and allows specialization of these facilities using the C++ inheritance mechanism by implementating of most operating system mechanisms at the class library level, particularly the object-oriented RPC system <ref> [25] </ref>. Non-blocking syn-chronization allows the class library level to be tolerant of user threads being terminated (fail-stopped) in the middle of performing some system library function such as (re)scheduling or handling a page fault. <p> Programming the higher-level software with best-effort signal delivery has required incorporating timeout and retry mechanisms but these are required for distributed operation in any case and do not add significant overhead <ref> [25] </ref>. These techniques, related to the transport-layer in network protocols, also make the system more resilient to faults. Note that just having a search mechanism retry a search when it fails in conjunction with this approach can lead to deadlock. <p> However, they do indicate that our techniques handle stress well. 7.3 Overall System Performance We do not have the ideal measurements to show the benefit of non-blocking synchronization for overall system performance. However, in other work <ref> [25] </ref>, system performance has been shown to benefit considerably from the ability to execute code in signal handlers as exploited extensively by the Cache Kernel object-oriented remote procedure call system.
Reference: [26] <institution> M68000 Family Programmer's Reference Manual, Motorola, Inc. </institution> <year> 1989 </year>
Reference-contexts: This instruction overhead is comparable to that required for locked synchronization, given that lock access can fail thus requiring test for success and retry. The Motorola 68040's CAS2 <ref> [26] </ref> is slow, apparently because of inefficient handling of the on-chip cache so synchronization takes about 3.5 microseconds in processor time. In comparison, spin locks take on average 2.1 secs and queuelocks take about 3.4 secs.
Reference: [27] <institution> PowerPC 601 RISC Mircroprocessor User's Manual, Motorola Inc, </institution> <year> 1993 </year>
References-found: 27

