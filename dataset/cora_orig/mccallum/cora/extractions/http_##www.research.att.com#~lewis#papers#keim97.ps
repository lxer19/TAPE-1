URL: http://www.research.att.com/~lewis/papers/keim97.ps
Refering-URL: http://www.research.att.com/~lewis/chronobib.html
Root-URL: 
Email: keim,madigan@stat.washington.edu  lewis@research.att.com  
Title: Bayesian Information Retrieval: Preliminary Evaluation  
Author: Michelle Keim David D. Lewis David Madigan 
Address: Box 354322  Seattle, WA 98195  600 Mountain Ave., 2A-410 Murray Hill, NJ 07974  
Affiliation: Dept. of Statistics,  University of Washington  AT&T Labs Research  
Abstract: Given a database of documents and a user's query, how can we locate those documents that meet the user's information needs? Because there is no precise definition of which documents in the database match the user's query, uncertainty is inherent in the information retrieval process. Therefore, probability theory is a natural tool for formalizing the retrieval task. In this paper, we propose a Bayesian approach to one of the conventional probabilistic information retrieval models. We discuss the motivation for such a model, describe its implementation, and present some experimental results. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bookstein, A. </author> <year> (1983). </year> <title> Information Retrieval: A Sequential Learning Process. </title> <journal> Journal of the American society for Information Science, </journal> <volume> 34(5) </volume> <pages> 331-342. </pages>
Reference: <author> Croft, W. and Harper, D. </author> <year> (1979). </year> <title> Using Probabilistic Models of Document Retrieval Without Relevance Information. </title> <journal> Journal of Documentation, </journal> <volume> 35(4) </volume> <pages> 285-295. </pages>
Reference: <editor> Croft, W. B. and van Rijsbergen, C., editors (1994). </editor> <booktitle> Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. </booktitle>
Reference: <editor> Fox, E. A., Ingwersen, P., and Fidel, R., editors (1995). </editor> <booktitle> Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. </booktitle>
Reference: <author> Fuhr, N. </author> <year> (1992). </year> <title> Probabilistic Models in Information Retrieval. </title> <journal> The Computer Journal, </journal> <volume> 35(3) </volume> <pages> 243-254. </pages>
Reference: <author> Gelman, A., Carlin, J. B., Sterm, H. S., and Rubin, D. B. </author> <year> (1995). </year> <title> Bayesian Data Analysis. </title> <publisher> Chapman and Hall. </publisher>
Reference: <author> Hersh, W., Buckley, C., Leone, T., and Hickman, D. </author> <year> (1994). </year> <title> OHSUMED: an interactive retrieval evaluation and new large test collection for research. </title>
Reference-contexts: Another extension that we are considering is formalizing the approach of incorporating knowledge about queries into the prior distribution via a hierarchical Bayesian model. Lastly, we would like to experiment on a larger test collection. We plan to use the OHSUMED test collection <ref> (Hersh et al. 1994) </ref> for our experiments. The OHSUMED test collection consists of Medline records from the years 1987 to 1991 which the National Library of Medicine has categorized by the Medical Subject Headings (MeSH). There are 233,445 records in the OHSUMED collection, each consisting of a title and abstract.
Reference: <institution> In Croft and van Rijsbergen (1994). </institution>
Reference: <author> Langley, P., Iba, W., and Thompson, K. </author> <year> (1992). </year> <title> An analysis of Bayesian Classifiers. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 223-228. </pages> <publisher> AAAI Press and M.I.T. Press. </publisher>
Reference: <author> Lewis, D. D. and Gale, W. </author> <year> (1994). </year> <title> A Sequential Algorithm for Training Text Classifiers. </title> <booktitle> In Croft and van Rijsbergen (1994), </booktitle> <pages> pages 3-12. </pages>
Reference: <author> Losee, R. </author> <year> (1988). </year> <title> Parameter Estimation for Probabilistic document-retrieval models. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 39(1) </volume> <pages> 8-16. </pages>
Reference: <author> Maron, M. and Kuhns, J. </author> <year> (1960). </year> <title> On Relevance, Probabilistic Indexing and Information Retrieval. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 7(3) </volume> <pages> 216-244. </pages>
Reference-contexts: Next, we describe the Bayesian model and some of the details in implementing it. We conclude with a presentation of some preliminary results and our plans for anticipated future work. 2 A Probabilistic IR Model Probabilistic information retrieval models date back to the early 60's <ref> (Maron and Kuhns 1960) </ref>, but have rarely been used in operational retrieval systems. However, the probabilistic model was perhaps the first IR model with a firm theoretical foundation.
Reference: <author> Raghavan, V. V. and Sever, H. </author> <year> (1995). </year> <title> On the Reuse of Past Optimal Queries. </title> <editor> In Fox et al. </editor> <year> (1995), </year> <pages> pages 344-350. </pages>
Reference: <author> Robertson, S. and Sparck Jones, K. </author> <year> (1976). </year> <title> Relevance Weighting of Search Terms. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 27(3) </volume> <pages> 129-146. </pages>
Reference: <author> Salton, G., </author> <title> editor (1971). The Smart Retrieval System-Experiments in Automatic Document Procesing. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ. </address>
Reference-contexts: Voorhees et al. (1995) discuss query similarity for a different application. They develop collection fusion strategies to successfully merge the results of retrieval runs on separate independent collections into a single result. They suggest two ways to determine similarity between queries. Their first method applies the vector space model <ref> (Salton 1971) </ref> to queries and their second method clusters queries based on the number of common relevant documents retrieved. We have adopted the vector space approach. The vector space approach represents a query as a vector, where each vector element corresponds to a possible term. <p> We would prefer to evaluate the "feedback effect," the improvement in performance due to the ranking of new, unseen documents. To do so, we use the "test and control method" <ref> (Salton 1971, Chapter 17) </ref>. We randomly split the document collection in half. We use the first half, the "test group," to run an initial search based on the prior distributions. We then obtain relevance judgments for some documents and update the distributions.
Reference: <author> Sparck Jones, K. and van Rijsbergen, C. </author> <year> (1976). </year> <title> Information Retrieval Test Collections. </title> <journal> Journal of Documentation, </journal> <volume> 32(1) </volume> <pages> 59-75. </pages> <editor> van Rijsbergen, C. </editor> <booktitle> (1979). Information Retrieval. </booktitle> <address> But-terworths, London, </address> <note> second edition. </note>
Reference: <author> Voorhees, E. M., Gupta, N. K., and Johnson-Laird, B. </author> <year> (1995). </year> <title> Learning Collection Fusion Strategies. </title>
References-found: 17

