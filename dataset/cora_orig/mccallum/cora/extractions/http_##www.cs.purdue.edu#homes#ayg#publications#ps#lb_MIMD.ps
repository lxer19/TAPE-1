URL: http://www.cs.purdue.edu/homes/ayg/publications/ps/lb_MIMD.ps
Refering-URL: http://www.cs.purdue.edu/homes/ayg/publications/work.html
Root-URL: http://www.cs.purdue.edu
Title: Scalable Load Balancing Techniques for Parallel Computers  
Author: Vipin Kumar and Ananth Y. Grama and Vempaty Nageshwara Rao 
Address: Minneapolis, MN 55455  Orlando, Florida 32816  
Affiliation: Department of Computer Science, University of Minnesota  Department of Computer Science University of Central Florida  
Abstract: In this paper we analyze the scalability of a number of load balancing algorithms which can be applied to problems that have the following characteristics : the work done by a processor can be partitioned into independent work pieces; the work pieces are of highly variable sizes; and it is not possible (or very difficult) to estimate the size of total work at a given processor. Such problems require a load balancing scheme that distributes the work dynamically among different processors. Our goal here is to determine the most scalable load balancing schemes for different architectures such as hypercube, mesh and network of workstations. For each of these architectures, we establish lower bounds on the scalability of any possible load balancing scheme. We present the scalability analysis of a number of load balancing schemes that have not been analyzed before. This gives us valuable insights into their relative performance for different problem and architectural characteristics. For each of these architectures, we are able to determine near optimal load balancing schemes. Results obtained from implementation of these schemes in the context of the Tautology Verification problem on the Ncube/2 T M 1 multicomputer are used to validate our theoretical results for the hypercube architecture. These results also demonstrate the accuracy and viability of our framework for scalability analysis. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Arvindam, Vipin Kumar, and V. Nageshwara Rao. </author> <title> Floorplan optimization on multiprocessors. </title> <booktitle> In Proceedings of the 1989 International Conference on Computer Design (ICCD-89), </booktitle> <year> 1989. </year> <note> Also published as MCC Tech Report ACT-OODS-241-89. </note>
Reference-contexts: In such domains, sender based schemes may potentially perform better than receiver based schemes. A network of workstations provides us with a cheap and universally available platform for parallelizing applications. Several applications have been parallelized to run on a small number of workstations <ref> [1, 26] </ref>. For example, in [1] an implementation of parallel depth first branch and bound for VLSI floorplan optimization is presented. Linear speedups were obtained on up to 16 processors. The essential part of this branch-and-bound algorithm is a scalable load balancing technique. <p> In such domains, sender based schemes may potentially perform better than receiver based schemes. A network of workstations provides us with a cheap and universally available platform for parallelizing applications. Several applications have been parallelized to run on a small number of workstations [1, 26]. For example, in <ref> [1] </ref> an implementation of parallel depth first branch and bound for VLSI floorplan optimization is presented. Linear speedups were obtained on up to 16 processors. The essential part of this branch-and-bound algorithm is a scalable load balancing technique.
Reference: [2] <author> S. Arvindam, Vipin Kumar, and V. Nageshwara Rao. </author> <title> Efficient parallel algorithms for search problems: Applications in vlsi cad. </title> <booktitle> In Proceedings of the Frontiers 90 Conference on Massively Parallel Computation, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: All the experiments were done on a second generation Ncube T M in the context of the Satisfiability problem [5]. The Satisfiability problem consists of testing the validity of boolean formulae. Such problems arise in areas such as VLSI design and theorem proving among others <ref> [2, 5] </ref>. The problem is "given a boolean formula containing binary variables in disjunctive normal form, find out if it is unsatisfiable". The Davis and Putnam algorithm [5] presents a fast and efficient way of solving this problem.
Reference: [3] <author> S. Arvindam, Vipin Kumar, V. Nageshwara Rao, and Vineet Singh. </author> <title> Automatic test pattern generation on multiprocessors. </title> <journal> Parallel Computing, </journal> <volume> 17, number 12 </volume> <pages> 1323-1342, </pages> <month> December </month> <year> 1991. </year>
Reference: [4] <author> E. Charniak and D. McDermott. </author> <title> Introduction to Artificial Intelligence. </title> <publisher> Addison Wesley, </publisher> <year> 1985. </year>
Reference-contexts: For practical problems, in depth first search, it is much cheaper to incrementally build the state associated with each node rather than copy and/or create the new node from scratch <ref> [39, 4] </ref>. This also introduces additional inefficiency. Further, the memory requirement at a processor is potentially unbounded, as a processor may be required to store an arbitrarily large number of work pieces during execution.
Reference: [5] <author> M. Davis, G. Logeman, and D. Loveland. </author> <title> A machine program for theorem proving. </title> <journal> Communications of the ACM, </journal> <volume> 5, number 7, </volume> <year> 1962. </year>
Reference-contexts: All the experiments were done on a second generation Ncube T M in the context of the Satisfiability problem <ref> [5] </ref>. The Satisfiability problem consists of testing the validity of boolean formulae. Such problems arise in areas such as VLSI design and theorem proving among others [2, 5]. The problem is "given a boolean formula containing binary variables in disjunctive normal form, find out if it is unsatisfiable". <p> All the experiments were done on a second generation Ncube T M in the context of the Satisfiability problem [5]. The Satisfiability problem consists of testing the validity of boolean formulae. Such problems arise in areas such as VLSI design and theorem proving among others <ref> [2, 5] </ref>. The problem is "given a boolean formula containing binary variables in disjunctive normal form, find out if it is unsatisfiable". The Davis and Putnam algorithm [5] presents a fast and efficient way of solving this problem. <p> Such problems arise in areas such as VLSI design and theorem proving among others [2, 5]. The problem is "given a boolean formula containing binary variables in disjunctive normal form, find out if it is unsatisfiable". The Davis and Putnam algorithm <ref> [5] </ref> presents a fast and efficient way of solving this problem. The algorithm essentially works by performing a depth first search of the binary tree formed by true/false assignments to the literals. Thus the maximum depth of the tree cannot exceed the number of literals.
Reference: [6] <author> A. Gottlieb et al. </author> <title> The NYU ultracomputer designing a MIMD, shared memory parallel computer. </title> <journal> IEEE Transactions on Computers, </journal> <pages> pages 175-189, </pages> <month> February </month> <year> 1983. </year>
Reference: [7] <author> Chris Ferguson and Richard Korf. </author> <title> Distributed tree search and its application to alpha-beta pruning. </title> <booktitle> In Proceedings of the 1988 National Conference on Artificial Intelligence, </booktitle> <month> August </month> <year> 1988. </year>
Reference: [8] <author> Raphael A. Finkel and Udi Manber. </author> <title> DIB a distributed implementation of backtracking. </title> <journal> ACM Trans. of Progr. Lang. and Systems, </journal> <volume> 9 No. 2 </volume> <pages> 235-256, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: of the parallel system if it asymptotically dominates all other terms (due to reasons other than the communication overhead). 5.2 Computation of V (P) for various load balancing schemes Clearly, it can be seen that V (P ) is fi (P ) for GRR and GRR-M, and as shown in <ref> [8, 23] </ref> it is O (P 2 ) for Asynchronous Round Robin techniques. The worst case for Asynchronous Round Robin techniques is realized when all processors generate successive work requests at almost identical instances of time and the initial value of counters at all processors is almost identical.
Reference: [9] <author> Roger Frye and Jacek Myczkowski. </author> <title> Exhaustive search of unstructured trees on the connection machine. </title> <institution> In Thinking Machines Corporation Technical Report, </institution> <year> 1990. </year>
Reference-contexts: Examples can be found in scientific computations involving the solution of partial differential equations. Dynamic load Balancing algorithms for SIMD processors are of a very different nature compared to those for MIMD architectures <ref> [9, 27, 32, 18] </ref>. Due to architectural constraints in SIMD machines, load balancing needs to be done on a global scale. In contrast, on MIMD machines, load can be balanced among a small subset of processors while the others are busy doing work.
Reference: [10] <author> M. Furuichi, K. Taki, and N. Ichiyoshi. </author> <title> A multi-level load balancing scheme for or-parallel exhaustive search programs on the multi-psi. </title> <booktitle> In Proceedings of the 2nd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <year> 1990. </year> <month> pp.50-59. </month>
Reference-contexts: In these schemes, the generation of subtasks is independent of the work requests from idle processors. These subtasks are delivered to processors needing them, either on demand (i:e:, when they are idle) <ref> [10] </ref> or without demand [33, 36, 35]. 17 Scheme! ARR NN GRR GRR-M RP Lower Bound Arch# SM O (P 2 log P) O (P 2 log P) O (P 2 log P) O (P log P) O (P log 2 P ) O (P ) Cube O (P 2 log <p> Now, since W = k fi z, substituting lower bounds for k and z, we get the isoefficiency function to be W = (P 2 ). Furuichi et. al. <ref> [10] </ref> present a similar analysis to predict speedup and efficiency. This analysis does not consider the idle time incurred by processors between making a work request and receiving work. <p> They show that in this case, the isoefficiency of SL is given by fi (P 2 log P ). 6.2 Multi Level Load Balancing (ML) This scheme tries to circumvent the subtask generation bottleneck <ref> [10] </ref> of SL through multiple level subtask generation. In this scheme, all processors are arranged in the form of an m-ary tree of depth l. The task of super-subtask generation is given to the root processor.
Reference: [11] <author> Ananth Grama, Vipin Kumar, and V. Nageshwara Rao. </author> <title> Experimental evaluation of load balancing techniques for the hypercube. </title> <booktitle> In Proceedings of the Parallel Computing 91 Conference, </booktitle> <year> 1991. </year>
Reference: [12] <author> Anshul Gupta and Vipin Kumar. </author> <title> The scalability of Matrix Multiplication Algorithms on parallel computers. </title> <type> Technical Report TR 91-54, </type> <institution> Computer Science Department, University of Minnesota, </institution> <address> Minneapolis, MN 55455, </address> <year> 1991. </year>
Reference-contexts: This shows that the impact of changes in technology dependent factors is moderate. These can, however, be quite drastic for other algorithms such as FFT [13] and Matrix algorithms <ref> [12] </ref>. Being able to make such predictions is one of the significant advantages of isoefficiency analysis. Two problem characteristics, communication coupling between subtasks and the ability to estimate work size, define a spectrum of application areas. Different load balancing strategies are needed for different points in this spectrum.
Reference: [13] <author> Anshul Gupta and Vipin Kumar. </author> <title> The scalability of FFT on parallel computers. </title> <booktitle> In Proceedings of the Frontiers 90 Conference on Massively Parallel Computation, </booktitle> <month> October </month> <year> 1990. </year> <note> An extended version of the paper will appear in IEEE Transactions on Parallel and Distributed Systems, </note> <year> 1993. </year>
Reference-contexts: This shows that the impact of changes in technology dependent factors is moderate. These can, however, be quite drastic for other algorithms such as FFT <ref> [13] </ref> and Matrix algorithms [12]. Being able to make such predictions is one of the significant advantages of isoefficiency analysis. Two problem characteristics, communication coupling between subtasks and the ability to estimate work size, define a spectrum of application areas.
Reference: [14] <author> John L. Gustafson. </author> <title> Reevaluating Amdahl's Law. </title> <journal> Communications of the ACM, </journal> <volume> 31(5) </volume> <pages> 532-533, </pages> <year> 1988. </year>
Reference: [15] <author> John L. Gustafson, Gary R. Montry, and Robert E. Benner. </author> <title> Development of parallel methods for a 1024-processor hypercube. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 9 No. 4 </volume> <pages> 609-638, </pages> <year> 1988. </year>
Reference: [16] <author> Ellis Horowitz and Sartaj Sahni. </author> <title> Fundamentals of Computer Algorithms. </title> <publisher> Computer Science Press, </publisher> <address> Rockville, Maryland, </address> <year> 1978. </year>
Reference: [17] <author> L. V. Kale. </author> <title> Comparing the performance of two dynamic load distribution methods. </title> <booktitle> In Proceedings of International conference on Parallel Processing, </booktitle> <pages> pages 8-12, </pages> <year> 1988. </year>
Reference: [18] <author> George Karypis and Vipin Kumar. </author> <title> Unstructured Tree Search on SIMD Parallel Computers. </title> <type> Technical Report 92-21, </type> <institution> Computer Science Department, University of Minnesota, </institution> <year> 1992. </year> <note> A short version of this paper appears in the Proceedings of Supercomputing 1992 Conference, </note> <month> November </month> <year> 1992. </year>
Reference-contexts: Examples can be found in scientific computations involving the solution of partial differential equations. Dynamic load Balancing algorithms for SIMD processors are of a very different nature compared to those for MIMD architectures <ref> [9, 27, 32, 18] </ref>. Due to architectural constraints in SIMD machines, load balancing needs to be done on a global scale. In contrast, on MIMD machines, load can be balanced among a small subset of processors while the others are busy doing work. <p> Hence, the load balancing schemes developed for MIMD architectures may not perform well on SIMD architectures. Analysis similar to that used in this paper has been used to understand the scalability of different load 31 balancing schemes for SIMD architectures and to determine best schemes <ref> [18] </ref>. Appendix A Analysis of Load Balancing Algorithms for Mesh Architectures Here we analyze the isoefficiency function for the above schemes on the mesh architecture. Asynchronous Round Robin As before, for this case, V (P ) = O (P 2 ).
Reference: [19] <author> R. Keller and F. Lin. </author> <title> Simulated performance of a reduction based multiprocessor. </title> <journal> IEEE Computers, </journal> <month> July </month> <year> 1984 1984. </year>
Reference: [20] <author> Kouichi Kimura and Ichiyoshi Nobuyuki. </author> <title> Probabilistic analysis of the efficiency of the dynamic load distribution. </title> <booktitle> In Proceedings of 1991 Distributed Memory and Concurrent Computers, </booktitle> <year> 1991. </year>
Reference-contexts: In general, subtask sizes (z) can be of widely differing sizes. Kimura and Ichiyoshi present a detailed analysis in <ref> [20] </ref> for the case in which subtasks can be of random sizes. <p> A leaf processor is allocated to another subtask generator when its designated subtask generator runs out of work. For l = 1, ML and SL become identical. For ML utilizing an l level distribution scheme, it has been shown in <ref> [20] </ref> that the isoefficiency is given by fi (P l+1 l+1 2 ). These isoefficiency functions were derived by assuming that the cost of work transfers between any pair of processors is fi (1).
Reference: [21] <author> Vipin Kumar and Anshul Gupta. </author> <title> Analyzing the scalability of parallel algorithms and architectures: A survey. </title> <booktitle> In Proceedings of the 1991 International Conference on Supercomputing, </booktitle> <month> June </month> <year> 1991. </year> <note> also appear as an invited paper in the Proc. of 29th Annual Allerton Conference on Communuication, Control and Computing, Urbana,IL, </note> <month> October </month> <year> 1991. </year>
Reference: [22] <editor> Vipin Kumar, Dana Nau, and Laveen Kanal. </editor> <title> General branch-and-bound formulation for and/or graph and game tree search. </title> <editor> In Laveen Kanal and Vipin Kumar, editors, </editor> <booktitle> Search in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1988. </year>
Reference: [23] <author> Vipin Kumar and V. Nageshwara Rao. </author> <title> Parallel depth-first search, part II: Analysis. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 16 (6):501-519, 1987. 34 </volume>
Reference-contexts: of the parallel system if it asymptotically dominates all other terms (due to reasons other than the communication overhead). 5.2 Computation of V (P) for various load balancing schemes Clearly, it can be seen that V (P ) is fi (P ) for GRR and GRR-M, and as shown in <ref> [8, 23] </ref> it is O (P 2 ) for Asynchronous Round Robin techniques. The worst case for Asynchronous Round Robin techniques is realized when all processors generate successive work requests at almost identical instances of time and the initial value of counters at all processors is almost identical. <p> For NN, V (P ) is unbounded for architectures such as the hypercube. That is why isoefficiency functions for NN are determined in <ref> [23] </ref> using a different technique. Random Polling In the worst case, the value of V (P ) is unbounded for random polling. Here we present an average case analysis for computing the value of V (P ). Consider a system of P boxes. <p> Thus V (P ) is O (P ). 5.3 Analysis of Receiver Initiated Load Balancing Algorithms for Hypercube Here we present analyses for all the schemes introduced in section 4 with the exception of NN. Scalability analysis for NN was presented in <ref> [23] </ref>. Some of the techniques analyzed here have better scalability than the NN, and have near optimal isoefficiency functions. In this section, we assume that work can be transferred through fixed size messages. The effect of relaxing this assumption is presented in Section 7. <p> Consequently U comm also decreases. In particular, for high enough efficiencies, U comm will be close to the optimal limit imposed by the network bandwidth. Table 1 shows the isoefficiency functions for different receiver initiated schemes for various architectures. The results in boldface were derived in <ref> [23] </ref>. Others were either derived in Section 5, Appendix A, or can be derived by a similar analysis.
Reference: [24] <author> Vipin Kumar and V. Nageshwara Rao. </author> <title> Load balancing on the hypercube architecture. </title> <booktitle> In Proceedings of the 1989 Conference on Hypercubes, Concurrent Computers and Applications, </booktitle> <pages> pages 603-608, </pages> <year> 1989. </year>
Reference: [25] <author> Vipin Kumar and Vineet Singh. </author> <title> Scalability of Parallel Algorithms for the All-Pairs Shortest Path Problem: A Summary of Results. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <year> 1990. </year> <note> Extended version appears in Journal of Parallel and Distributed Processing (special issue on massively parallel computation), Volume 13, 124-138, </note> <year> 1991. </year>
Reference: [26] <author> Kai Li. Ivy: </author> <title> A shared virtual memory system for parallel computing. </title> <booktitle> In Proceedings of International conference on Parallel Processing: </booktitle> <volume> Vol II, </volume> <pages> pages 94-101, </pages> <year> 1988. </year>
Reference-contexts: In such domains, sender based schemes may potentially perform better than receiver based schemes. A network of workstations provides us with a cheap and universally available platform for parallelizing applications. Several applications have been parallelized to run on a small number of workstations <ref> [1, 26] </ref>. For example, in [1] an implementation of parallel depth first branch and bound for VLSI floorplan optimization is presented. Linear speedups were obtained on up to 16 processors. The essential part of this branch-and-bound algorithm is a scalable load balancing technique.
Reference: [27] <author> A. Mahanti and C. Daniels. </author> <title> Simd parallel heuristic search. </title> <note> To appear in Artificial Intelligence, </note> <year> 1992. </year>
Reference-contexts: Examples can be found in scientific computations involving the solution of partial differential equations. Dynamic load Balancing algorithms for SIMD processors are of a very different nature compared to those for MIMD architectures <ref> [9, 27, 32, 18] </ref>. Due to architectural constraints in SIMD machines, load balancing needs to be done on a global scale. In contrast, on MIMD machines, load can be balanced among a small subset of processors while the others are busy doing work.
Reference: [28] <author> B. Monien and O. Vornberger. </author> <title> Parallel processing of combinatorial search trees. </title> <booktitle> In Proceedings of International Workshop on Parallel Algorithms and Architectures, </booktitle> <month> May </month> <year> 1987. </year>
Reference: [29] <author> V. Nageshwara Rao and Vipin Kumar. </author> <title> Parallel depth-first search, part I: Implementation. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 16 </volume> (6):479-499, 1987. 
Reference-contexts: Apart from these, all the other 20 restrictions on applicability of this scheme are the same as those for Shu and Kale's [36] scheme. The problem of performing a communication for each node expansion can be alleviated by enforcing a granularity control over the partitioning and transferring process <ref> [29, 36] </ref>. It is , however, not clear whether mechanisms for effective granularity control can be derived for highly irregular state space trees. One possible method [29] of granularity control works by not giving away nodes below a certain "cutoff" depth. Search below this depth is done sequentially. <p> It is , however, not clear whether mechanisms for effective granularity control can be derived for highly irregular state space trees. One possible method <ref> [29] </ref> of granularity control works by not giving away nodes below a certain "cutoff" depth. Search below this depth is done sequentially. This clearly reduces the number of communications. <p> Experimental results show that NN performs slightly better than RP. Recall that the isoef-ficiency of NN is fi (P r ), where r is determined by the quality of the splitting function (better splitting functions result in smaller values of r). In the context of the 15 puzzle, in <ref> [29] </ref>, r was determined to be 1.57. For up to 1024 processors, NN and RP have very similar performance. However, for higher values of P , P log 2 P would become smaller than P r and RP would outperform NN.
Reference: [30] <author> Srinivas Patil and Prithviraj Banerjee. </author> <title> A parallel branch and bound algorithm for test generation. </title> <journal> In IEEE Transactions on Computer Aided Design, </journal> <volume> Vol. 9, No. 3, </volume> <month> March </month> <year> 1990. </year>
Reference: [31] <author> Judea Pearl. </author> <title> Heuristics Intelligent Search Strategies for Computer Problem Solving. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1984. </year>
Reference: [32] <author> C. Powley, R. Korf, and C. Ferguson. </author> <title> Ida* on the connection machine. </title> <note> To appear in Artificial Intelligence, </note> <year> 1992. </year>
Reference-contexts: Examples can be found in scientific computations involving the solution of partial differential equations. Dynamic load Balancing algorithms for SIMD processors are of a very different nature compared to those for MIMD architectures <ref> [9, 27, 32, 18] </ref>. Due to architectural constraints in SIMD machines, load balancing needs to be done on a global scale. In contrast, on MIMD machines, load can be balanced among a small subset of processors while the others are busy doing work.
Reference: [33] <author> Abhiram Ranade. </author> <title> Optimal speedup for backtrack search on a butterfly network. </title> <booktitle> In Proceedings of the Third ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1991. </year>
Reference-contexts: In these schemes, the generation of subtasks is independent of the work requests from idle processors. These subtasks are delivered to processors needing them, either on demand (i:e:, when they are idle) [10] or without demand <ref> [33, 36, 35] </ref>. 17 Scheme! ARR NN GRR GRR-M RP Lower Bound Arch# SM O (P 2 log P) O (P 2 log P) O (P 2 log P) O (P log P) O (P log 2 P ) O (P ) Cube O (P 2 log 2 P ) (P <p> For instance, P 4 3 3 2 only for P &gt; 1024. 6.3 Randomized Allocation A number of techniques using randomized allocation have been presented in the context of parallel depth first search of state space trees <ref> [33, 36, 35] </ref>. In depth first search of trees, the expansion of a node corresponds to performing a certain amount of useful computation and generation of successor nodes, which can be treated as subtasks. <p> In contrast, for all other load balancing schemes discussed up to this point, the memory requirement of parallel depth first search remains similar to that of serial depth first search. Ranade <ref> [33] </ref> presents a variant of the above scheme for execution on butterfly networks or hy-percubes. This scheme uses a dynamic algorithm to embed nodes of a binary search tree into a butterfly network. <p> A major drawback of this scheme is that it requires the fine tuning of a number of parameters to obtain best possible performance. The random allocation scheme for the hypercube presented in <ref> [33] </ref> has an isoefficiency of O (P log P ), which is optimal. However, for many problems, the maximum obtainable efficiency of this scheme has an upper bound much less than 1.
Reference: [34] <author> S. Ranka and S. Sahni. </author> <title> Hypercube Algorithms for Image Processing and Pattern Recognition. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1990. </year>
Reference: [35] <author> Vikram Saletore and L. V. Kale. </author> <title> Consistent linear speedup to a first solution in parallel state-space search. </title> <booktitle> In Proceedings of the 1990 National Conference on Artificial Intelligence, </booktitle> <pages> pages 227-233, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: In these schemes, the generation of subtasks is independent of the work requests from idle processors. These subtasks are delivered to processors needing them, either on demand (i:e:, when they are idle) [10] or without demand <ref> [33, 36, 35] </ref>. 17 Scheme! ARR NN GRR GRR-M RP Lower Bound Arch# SM O (P 2 log P) O (P 2 log P) O (P 2 log P) O (P log P) O (P log 2 P ) O (P ) Cube O (P 2 log 2 P ) (P <p> For instance, P 4 3 3 2 only for P &gt; 1024. 6.3 Randomized Allocation A number of techniques using randomized allocation have been presented in the context of parallel depth first search of state space trees <ref> [33, 36, 35] </ref>. In depth first search of trees, the expansion of a node corresponds to performing a certain amount of useful computation and generation of successor nodes, which can be treated as subtasks.
Reference: [36] <author> Wei Shu and L. V. Kale. </author> <title> A dynamic scheduling strategy for the chare-kernel system. </title> <booktitle> In Proceedings of Supercomputing 89, </booktitle> <pages> pages 389-398, </pages> <year> 1989. </year>
Reference-contexts: In these schemes, the generation of subtasks is independent of the work requests from idle processors. These subtasks are delivered to processors needing them, either on demand (i:e:, when they are idle) [10] or without demand <ref> [33, 36, 35] </ref>. 17 Scheme! ARR NN GRR GRR-M RP Lower Bound Arch# SM O (P 2 log P) O (P 2 log P) O (P 2 log P) O (P log P) O (P log 2 P ) O (P ) Cube O (P 2 log 2 P ) (P <p> For instance, P 4 3 3 2 only for P &gt; 1024. 6.3 Randomized Allocation A number of techniques using randomized allocation have been presented in the context of parallel depth first search of state space trees <ref> [33, 36, 35] </ref>. In depth first search of trees, the expansion of a node corresponds to performing a certain amount of useful computation and generation of successor nodes, which can be treated as subtasks. <p> In depth first search of trees, the expansion of a node corresponds to performing a certain amount of useful computation and generation of successor nodes, which can be treated as subtasks. In the Randomized Allocation Strategy proposed by Shu and Kale <ref> [36] </ref>, every time a node is expanded, all of the newly generated successor nodes are assigned to randomly chosen processors. The random allocation of subtasks ensures a degree of load balance over the processors. There are however some practical difficulties with the implementation of this scheme. <p> This adds an additional overhead of managing heaps, but may help in reducing the overall memory requirement. Apart from these, all the other 20 restrictions on applicability of this scheme are the same as those for Shu and Kale's <ref> [36] </ref> scheme. The problem of performing a communication for each node expansion can be alleviated by enforcing a granularity control over the partitioning and transferring process [29, 36]. It is , however, not clear whether mechanisms for effective granularity control can be derived for highly irregular state space trees. <p> Apart from these, all the other 20 restrictions on applicability of this scheme are the same as those for Shu and Kale's [36] scheme. The problem of performing a communication for each node expansion can be alleviated by enforcing a granularity control over the partitioning and transferring process <ref> [29, 36] </ref>. It is , however, not clear whether mechanisms for effective granularity control can be derived for highly irregular state space trees. One possible method [29] of granularity control works by not giving away nodes below a certain "cutoff" depth. Search below this depth is done sequentially.
Reference: [37] <author> Vineet Singh, Vipin Kumar, Gul Agha, and Chris Tomlinson. </author> <title> Scalability of parallel sorting on mesh multicom-puters. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 20 (2), </volume> <year> 1991. </year> <note> A short version of this paper appears in the Proceedings of the Fifth International Parallel Processing Symposium, </note> <year> 1991. </year>
Reference: [38] <author> Douglas R. Smith. </author> <title> Random trees and the analysis of branch and bound proceedures. </title> <journal> Journal of the ACM, </journal> <volume> 31 No. 1, </volume> <year> 1984. </year>
Reference-contexts: However, there are problems for which the work transfer cost is a function of the amount of work transferred. Instances of such problems are found in tree search applications for domains where strong heuristics are available <ref> [38] </ref>. For such applications, the search space is polynomial in nature and the size of the stack used to transfer work varies significantly with the amount of work transferred.
Reference: [39] <author> Nageshwara Rao Vempaty, Vipin Kumar, and Richard Korf. </author> <title> Analysis of heuristic search algorithms. </title> <booktitle> In Proceedings of the National Conf. on Artificial Intelligenc e (AAAI-91), </booktitle> <year> 1991. </year>
Reference-contexts: For practical problems, in depth first search, it is much cheaper to incrementally build the state associated with each node rather than copy and/or create the new node from scratch <ref> [39, 4] </ref>. This also introduces additional inefficiency. Further, the memory requirement at a processor is potentially unbounded, as a processor may be required to store an arbitrarily large number of work pieces during execution.
Reference: [40] <author> Benjamin W. Wah, G.J. Li, and C. F. Yu. </author> <title> Multiprocessing of combinatorial search problems. </title> <journal> IEEE Computers, </journal> <month> June </month> <year> 1985 1985. </year>
Reference: [41] <author> Benjamin W. Wah and Y. W. Eva Ma. </author> <title> Manip amulticomputer architecture for solving combinatorial extremum-search problems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> c-33, </volume> <month> May </month> <year> 1984. </year>
Reference: [42] <author> Jinwoon Woo and Sartaj Sahni. </author> <title> Hypercube computing : connected components. </title> <journal> Journal of Supercomputing, </journal> <year> 1991. </year>
Reference: [43] <author> Jinwoon Woo and Sartaj Sahni. </author> <title> Computing biconnected components on a hypercube. </title> <journal> Journal of Supercomputing, </journal> <month> June </month> <year> 1991. </year> <month> 35 </month>
References-found: 43

