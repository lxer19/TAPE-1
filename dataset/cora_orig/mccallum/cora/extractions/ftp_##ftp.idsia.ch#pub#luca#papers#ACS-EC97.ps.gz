URL: ftp://ftp.idsia.ch/pub/luca/papers/ACS-EC97.ps.gz
Refering-URL: http://www.idsia.ch/journals.html
Root-URL: 
Email: mdorigo@ulb.ac.be,  luca@idsia.ch,  
Title: Dorigo and Gambardella Ant Colony System 1 Ant Colony System: A Cooperative Learning Approach to
Author: Marco Dorigo Luca Maria Gambardella 
Note: Accepted for publication in the IEEE Transactions on Evolutionary Computation, Vol.1, No.1, 1997. In press.  
Web: http://iridia.ulb.ac.be/dorigo/dorigo.html  http://www.idsia.ch/~luca  
Address: Belgium  Bruxelles, CP 194/6, Avenue Franklin Roosevelt 50 1050 Bruxelles, Belgium  Corso Elvezia 36, 6900 Lugano, Switzerland  
Affiliation: Universit Libre de Bruxelles  IRIDIA, Universit Libre de  IDSIA,  
Pubnum: TR/IRIDIA/1996-5  
Abstract: This paper introduces ant colony system (ACS), a distributed algorithm that is applied to the traveling salesman problem (TSP). In ACS, a set of cooperating agents called ants cooperate to find good solutions to TSPs. Ants cooperate using an indirect form of communication mediated by pheromone they deposit on the edges of the TSP graph while building solutions. We study ACS by running experiments to understand its operation. The results show that ACS outperforms other nature-inspired algorithms such as simulated annealing and evolutionary computation, and we conclude comparing ACS-3-opt, a version of ACS augmented with a local search procedure, to some of the best performing algorithms for symmetric and asymmetric TSPs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Baluja and R. Caruana, </author> <title> Removing the genetics from the standard genetic algorithm, </title> <booktitle> Proceedings of ML-95, Twelfth International Conference on Machine Learning, </booktitle> <editor> A. Prieditis and S. Russell (Eds.), </editor> <booktitle> 1995, </booktitle> <publisher> Morgan Kaufmann, </publisher> <pages> pp. 3846. </pages>
Reference-contexts: Besides the two works above, among the "nature-inspired" heuristics, the closest to ACS seems to be Baluja and Caruanas Population Based Incremental Learning (PBIL) <ref> [1] </ref>. PBIL, which takes inspiration from genetic algorithms, maintains a vector of real numbers, the generating vector, which plays a role similar to that of the population in GAs. <p> Dorigo and Gambardella - Ant Colony System 20 population will have the ith bit set to 1 with a probability which is a function of the ith value in the generating vector (in practice, values in the generating vector are normalized to the interval <ref> [0, 1] </ref> so that they can directly represent the probabilities). <p> A first possibility regards the number of ants which should contribute to the global updating rule. In ant system all the ants deposited their pheromone, while in ACS only the best one does: obviously there are intermediate possibilities. Baluja and Caruana <ref> [1] </ref> have shown that the use of the two best individuals can help PBIL to obtain better results, since the probability of being trapped in a local minimum becomes smaller. Another change to ACS could be, again taking inspiration from [1], allowing ants which produce very bad tours to subtract pheromone. <p> Baluja and Caruana <ref> [1] </ref> have shown that the use of the two best individuals can help PBIL to obtain better results, since the probability of being trapped in a local minimum becomes smaller. Another change to ACS could be, again taking inspiration from [1], allowing ants which produce very bad tours to subtract pheromone. A second possibility is to move from the current parallel local updating of pheromone to a sequential one. In ACS all ants apply the local updating rule in parallel, while they are building their tours.
Reference: [2] <author> A.G. Barto, </author> <title> R.S. Sutton, P.S. Brower, Associative search network: a reinforcement learning associative memory, </title> <journal> Biological Cybernetics, </journal> <volume> vol. 40, </volume> <pages> pp. </pages> <address> 201211, </address> <year> 1981. </year>
Reference-contexts: Pheromone updating is intended to allocate a greater amount of pheromone to shorter tours. In a sense, this is similar to a reinforcement learning scheme <ref> [2] </ref>, [26] in which better solutions get a higher reinforcement (as happens, for example, in genetic algorithms under proportional selection).
Reference: [3] <author> R. Beckers, J.L. Deneubourg, and S. Goss, </author> <title> Trails and U-turns in the selection of the shortest path by the ant Lasius Niger, </title> <journal> Journal of Theoretical Biology , vol. </journal> <volume> 159, </volume> <pages> pp. 397415, </pages> <year> 1992. </year>
Reference-contexts: In press. Dorigo and Gambardella - Ant Colony System 2 I. Introduction The natural metaphor on which ant algorithms are based is that of ant colonies. Real ants are capable of finding the shortest path from a food source to their nest <ref> [3] </ref>, [22] without using visual cues [24] by exploiting pheromone information. While walking, ants deposit pheromone on the ground, and follow, in probability, pheromone previously deposited by other ants. A way ants exploit pheromone to find a shortest path between two points is shown in Fig. 1.
Reference: [4] <author> J.L. Bentley, </author> <title> Fast algorithms for geometric traveling salesman problem, </title> <journal> ORSA Journal on Computing , vol. </journal> <volume> 4, </volume> <pages> pp. 387411, </pages> <year> 1992. </year>
Reference-contexts: Heuristic approaches to the TSP can be classified as tour constructive heuristics and tour improvement heuristics (these last also called local optimization heuristics). Tour constructive heuristics (see <ref> [4] </ref> for an overview) usually start selecting a random city from the set of cities and then incrementally build a feasible TSP solution by adding new cities chosen according to some heuristic rule. <p> The implementation of the restricted 3-opt procedure includes some typical tricks which accelerate its use for TSP/ATSP problems. First, search for the candidate nodes during the restricted 3-opt procedure is only made inside the candidate list [25]. Second, the procedure uses a data structure called dont look bit <ref> [4] </ref> in which each bit is associated to a node of the tour. At the beginning of the local optimization procedure all the bits are turned off and the bit associated to node r is turned on when a search for an improving move starting from r fails.
Reference: [5] <author> H. Bersini, M. Dorigo, S. Langerman, G. Seront, and L. M. Gambardella, </author> <booktitle> Results of the first international contest on evolutionary optimisation (1st ICEO), Proceedings of IEEE International Conference on Evolutionary Computation, IEEE-EC 96, 1996, </booktitle> <publisher> IEEE Press, </publisher> <pages> pp. 611615. </pages>
Reference-contexts: In Section 6 we add local optimization to ACS, obtaining a new algorithm called ACS-3-opt. This algorithm is compared favorably with the winner of the First International Contest on Evolutionary Optimization <ref> [5] </ref> on ATSP problems, while it yields a slightly worse performance on TSP problems. Section 7 is dedicated to the discussion of the main characteristics of ACS and indicates directions for further research. II. <p> The results obtained with ACS-3-opt on ATSP problems are quite impressive. Experiments were run on the set of ATSP problems proposed in the First International Contest on Evolutionary Optimization <ref> [5] </ref>, but see also http://iridia.ulb.ac.be/langerman/ICEO.html). For all the problems ACS-3-opt reached the optimal best known solution in a few seconds (see Table V) in all the ten trials, except in the case of ft70, a problem considered relatively hard, where the optimum was reached 8 out of 10 times.
Reference: [6] <author> H. Bersini, C. Oury, and M. Dorigo, </author> <title> Hybridization of genetic algorithms, </title> <type> Tech. Rep. </type> <institution> No. IRIDIA/95-22, 1995, Universit Libre de Bruxelles, Belgium. </institution>
Reference-contexts: Optimum Eil50 (50-city problem) 425 [1,830] (N/A) 426 [100,000] (N/A) 425 Eil75 (75-city problem) 535 [3,480] (N/A) 542 [325,000] (N/A) 535 KroA100 (100-city problem) 21,282 [4,820] (N/A) N/A [N/A] (N/A) 21,282 Results using EP are from [15], and those using GA are from [41] for Eil50, and Eil75, and from <ref> [6] </ref> for KroA100. Results using SA are from [29]. Eil50, Eil75 are from [14] and are included in TSPLIB with an additional city as Eil51.tsp and Eil76.tsp. KroA100 is also in TSPLIB. The best result for each problem is in boldface.
Reference: [7] <author> A. Colorni, M. Dorigo, and V. Maniezzo, </author> <title> Distributed optimization by ant colonies, </title> <booktitle> Proceedings of ECAL91 - European Conference on Artificial Life , Paris, </booktitle> <address> France, </address> <year> 1991, </year> <editor> F. Varela and P. Bourgine (Eds.), </editor> <publisher> Elsevier Publishing, </publisher> <pages> pp. 134142. </pages>
Reference-contexts: Ant system has been applied to combinato rial optimiza tion problems such as the traveling salesman problem (TSP) <ref> [7] </ref>, [8], [10], [12], and the quadratic assignment problem [32]. Ant colony system (ACS), the algorithm presented in this article, builds on the previous ant system in the direction of improving efficiency when applied to symmetric and asymmetric TSPs.
Reference: [8] <author> A. Colorni, M. Dorigo, and V. Maniezzo, </author> <title> An investigation of some properties of an ant algorithm, </title> <booktitle> Proceedings of the Parallel Problem Solving from Nature Conference (PPSN 92) , 1992, </booktitle> <editor> R. Mnner and B. Manderick (Eds.), </editor> <publisher> Elsevier Publishing, </publisher> <pages> pp. 509520. </pages>
Reference-contexts: Ant system has been applied to combinato rial optimiza tion problems such as the traveling salesman problem (TSP) [7], <ref> [8] </ref>, [10], [12], and the quadratic assignment problem [32]. Ant colony system (ACS), the algorithm presented in this article, builds on the previous ant system in the direction of improving efficiency when applied to symmetric and asymmetric TSPs.
Reference: [9] <author> J.L. Deneubourg, </author> <title> Application de lordre par fluctuations la description de certaines tapes de la construction du nid chez les termites, </title> <journal> Insect Sociaux, </journal> <volume> vol. 24, </volume> <pages> pp. 117130, </pages> <year> 1977. </year>
Reference-contexts: This allows an indirect form of communication called stigmergy [23], <ref> [9] </ref>. The interested reader will find a full description of ant system, of its biological motivations, and computational results in [12].
Reference: [10] <author> M. Dorigo, </author> <title> Optimization, learning and natural algorithms. </title> <institution> Ph.D.Thesis, Politecnico di Milano, Italy, </institution> <year> 1992. </year> <note> (In Italian.) </note>
Reference-contexts: Ant system has been applied to combinato rial optimiza tion problems such as the traveling salesman problem (TSP) [7], [8], <ref> [10] </ref>, [12], and the quadratic assignment problem [32]. Ant colony system (ACS), the algorithm presented in this article, builds on the previous ant system in the direction of improving efficiency when applied to symmetric and asymmetric TSPs. <p> Section 7 is dedicated to the discussion of the main characteristics of ACS and indicates directions for further research. II. Background Ant system <ref> [10] </ref> is the progenitor of all our research efforts with ant algorithms, and was first applied to the traveling salesman problem (TSP), which is defined in Fig. 2.
Reference: [11] <author> M. Dorigo and L.M. Gambardella, </author> <title> A study of some properties of Ant-Q, </title> <booktitle> Proceedings of PPSN IVFourth International Conference on Parallel Problem Solving From Nature, </booktitle> <editor> H.M. Voigt, W. Ebeling, I. Rechenberg and H.S. Schwefel (Eds.), </editor> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1996, </year> <pages> pp. 656665. </pages>
Reference-contexts: ACS with Dt g tr s s z z J s k ( ) max , which we have called Ant-Q in <ref> [11] </ref> and [19], and ACS with Dt (r,s)= t 0 , called simply ACS hereafter, resulted to be the two best performing algorithms, with a similar performance level.
Reference: [12] <author> M. Dorigo, V. Maniezzo, and A.Colorni, </author> <title> The ant system: optimization by a colony of coop - Dorigo and Gambardella - Ant Colony System 22 erating agents, </title> <journal> IEEE Transactions on Systems, Man, and CyberneticsPart B , vol. </journal> <volume> 26, No. 2, </volume> <pages> pp. 2941, </pages> <year> 1996. </year>
Reference-contexts: Ant system has been applied to combinato rial optimiza tion problems such as the traveling salesman problem (TSP) [7], [8], [10], <ref> [12] </ref>, and the quadratic assignment problem [32]. Ant colony system (ACS), the algorithm presented in this article, builds on the previous ant system in the direction of improving efficiency when applied to symmetric and asymmetric TSPs. <p> This allows an indirect form of communication called stigmergy [23], [9]. The interested reader will find a full description of ant system, of its biological motivations, and computational results in <ref> [12] </ref>. Although ant system was useful for discovering good or optimal solutions for small TSPs (up to 30 cities), the time required to find such results made it unfeasible for larger problems. <p> The above intuition is supported by encouraging, although preliminary, results obtained with ant system on the Dorigo and Gambardella - Ant Colony System 21 quadratic assignment problem <ref> [12] </ref>, [32]. In conclusion, in this paper we have shown that ACS is an interesting novel approach to parallel stochastic optimization of the TSP. ACS has been shown to compare favorably with previous attempts to apply other heuristic algorithms like genetic algorithms, evolutionary programming, and simulated annealing.
Reference: [13] <author> R. Durbin and D. Willshaw, </author> <title> An analogue approach to the travelling salesman problem using an elastic net method, </title> <journal> Nature, </journal> <volume> vol. 326, </volume> <pages> pp. 689-691, </pages> <year> 1987. </year>
Reference-contexts: Finally, we also ran experiments in which local-updating was not applied (i.e., the local updating rule is not used, as was the case in ant system). Results obtained running experiments (see Table I) on a set of five randomly generated 50-city TSPs <ref> [13] </ref>, on the Oliver30 symmetric TSP [41], and the ry48p asymmetric TSP [35] essentially suggest that local-updating is definitely useful, and that the local updating rule with Dt (r,s)=0 yields worse performance than local-updating with D t (r,s)= t 0 or with Dt g tr s s z , , ( <p> Table II reports the results on the random instances. The heuristics with which we compare ACS are simulated annealing (SA), elastic net (EN), and self organizing map (SOM). Results on SA, EN, and SOM are from <ref> [13] </ref>, [34]. ACS was run for 2,500 iterations using 10 ants (this amounts to approximately the same number of tour searched by the heuristics with which we compare our results). ACS results are averaged over 25 trials.
Reference: [14] <author> S. Eilon, C.D.T. Watson-Gandy, and N. Christofides, </author> <title> Distribution management: mathematical modeling and practical analysis, </title> <journal> Operational Research Quarterly, </journal> <volume> vol. 20, </volume> <pages> pp. 3753, </pages> <year> 1969. </year>
Reference-contexts: Families of edges classified according to different behavior with respect to the level of the pheromone closeness product. Problem: Eil51 <ref> [14] </ref>. a) Pheromonecloseness behavior when the system performance is good. Best solution found after 1,000 iterations: 426, a=r=0.1. b) Pheromonecloseness behavior when the system performance is bad. Best solution found after 1,000 iterations: 465, a=r=0.9. B. The optimal number of ants Consider Fig. 6 3 . <p> Results using SA are from [29]. Eil50, Eil75 are from <ref> [14] </ref> and are included in TSPLIB with an additional city as Eil51.tsp and Eil76.tsp. KroA100 is also in TSPLIB. The best result for each problem is in boldface. Again, ACS offers the best performance in nearly every case.
Reference: [15] <author> D. Fogel, </author> <title> Applying evolutionary programming to selected traveling salesman problems, </title> <journal> Cybernetics and Systems: An International Journal, </journal> <volume> vol. 24, </volume> <pages> pp. 2736, </pages> <year> 1993. </year>
Reference-contexts: Problem name ACS GA E SA Optimum Eil50 (50-city problem) 425 [1,830] (N/A) 426 [100,000] (N/A) 425 Eil75 (75-city problem) 535 [3,480] (N/A) 542 [325,000] (N/A) 535 KroA100 (100-city problem) 21,282 [4,820] (N/A) N/A [N/A] (N/A) 21,282 Results using EP are from <ref> [15] </ref>, and those using GA are from [41] for Eil50, and Eil75, and from [6] for KroA100. Results using SA are from [29]. Eil50, Eil75 are from [14] and are included in TSPLIB with an additional city as Eil51.tsp and Eil76.tsp. KroA100 is also in TSPLIB. <p> worse solution using real-valued distance as compared with EP, but ACS only visits 1,830 tours, while EP used 100,000 such evaluations (although it is possible that EP found its best solution Dorigo and Gambardella - Ant Colony System 14 earlier in the run, this is not specified in the paper <ref> [15] </ref>). B. ACS on some bigger problems When trying to solve big TSP problems it is common practice [28], [35] to use a data structure known as candidate list.
Reference: [16] <author> M.L. Fredman, D.S. Johnson, L.A. McGeoch, and G. Ostheimer, </author> <title> Data structures for traveling salesmen, </title> <journal> Journal of Algorithms, </journal> <volume> vol. 18, </volume> <pages> pp. 432479, </pages> <year> 1995. </year>
Reference-contexts: Last, a traditional array data structure to represent candidate lists and tours is used (see <ref> [16] </ref> for more sophisticated data structures). <p> that can not be reverted in one step by 3-opt, LK and 2-opt.) A fair comparison of our results with the results obtained with the currently best performing algorithms for symmetric TSPs [25] is difficult since they use as local search a LinKernighan heuristic based on a segment-tree data structure <ref> [16] </ref> that is faster and gives better results than our restricted-3-opt procedure. It will be the subject of future work to add such a procedure to ACS. TABLE VII Results obtained by ACS-3-opt on TSP problems taken from the First International Contest on Evolutionary Optimization.
Reference: [17] <author> B. Freisleben and P. Merz, </author> <title> Genetic local search algorithm for solving symmetric and asymmetric traveling salesman problems, </title> <booktitle> Proceedings of IEEE International Conference on Evolutionary Computation, IEEE-EC 96, 1996, </booktitle> <publisher> IEEE Press, </publisher> <pages> pp. 616-621. </pages>
Reference-contexts: An example of successful application of the above alternate strategy is the work by Freisleben and Merz <ref> [17] </ref>, [18] in which a genetic algorithm is used to generate new solutions to be locally optimized by a tour improvement heuristic. <p> In Table VI results obtained by ACS-3-opt are compared with those obtained by ATSP-GA <ref> [17] </ref>, the winner of the ATSP competition. ATSP-GA is based on a genetic algorithm that starts its search from a set of individuals generated using a nearest neighbor heuristic. Individuals are strings of cities which represent feasible solutions. <p> The results used for comparisons are those published in [18], which are slightly better than those published in <ref> [17] </ref>. Our results are, on the other hand, comparable to those obtained by other algorithms considered to be very good. For example, on the lin318 problem ACS-3-opt has approximately the same performance as the large step Markov chain algorithm [33].
Reference: [18] <author> B. Freisleben and P. Merz, </author> <title> New genetic local search operators for the traveling salesman problem, </title> <booktitle> Proceedings of PPSN IVFourth International Conference on Parallel Problem Solving From Nature, </booktitle> <editor> H.M. Voigt, W. Ebeling, I. Rechenberg and H.S. Schwefel (Eds.), </editor> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1996, </year> <pages> pp. 890899. </pages>
Reference-contexts: An example of successful application of the above alternate strategy is the work by Freisleben and Merz [17], <ref> [18] </ref> in which a genetic algorithm is used to generate new solutions to be locally optimized by a tour improvement heuristic. <p> The results used for comparisons are those published in <ref> [18] </ref>, which are slightly better than those published in [17]. Our results are, on the other hand, comparable to those obtained by other algorithms considered to be very good. For example, on the lin318 problem ACS-3-opt has approximately the same performance as the large step Markov chain algorithm [33].
Reference: [19] <author> L. Gambardella and M. Dorigo, Ant-Q: </author> <title> a reinforcement learning approach to the travel ing salesman problem, </title> <booktitle> Proceedings of ML-95, Twelfth International Conference on Machine Learning, </booktitle> <editor> A. Prieditis and S. Russell (Eds.), </editor> <publisher> Morgan Kaufmann, </publisher> <year> 1995, </year> <pages> pp. 252260. </pages>
Reference-contexts: Since the problem our ants have to solve is similar to a reinforcement learning problem (ants have to learn which city to move to as a function of their current location), we set <ref> [19] </ref> Dt g tr s s z z J s k ( ) max , which is exactly the same formula used in Q-learning (0 g1 is a parameter). <p> ACS with Dt g tr s s z z J s k ( ) max , which we have called Ant-Q in [11] and <ref> [19] </ref>, and ACS with Dt (r,s)= t 0 , called simply ACS hereafter, resulted to be the two best performing algorithms, with a similar performance level.
Reference: [20] <author> L.M. Gambardella and M. Dorigo, </author> <title> Solving symmetric and asymmetric TSPs by ant colonies, </title> <booktitle> Proceedings of IEEE International Conference on Evolutionary Computation, </booktitle> <publisher> IEEE-EC 96 , IEEE Press, </publisher> <year> 1996, </year> <pages> pp. 622627. </pages>
Reference-contexts: We implemented therefore a version of ACS <ref> [20] </ref> which incorporates a candidate list: An ant in this extended version of ACS first chooses the city to move to among those belonging to the candidate list. Only if none of the cities in the candidate list can be visited then it considers the rest of the cities.
Reference: [21] <author> B. Golden and W. Stewart, </author> <title> Empiric analysis of heuristics, in The traveling salesman problem, </title> <editor> E.L. Lawler, J.K. Lenstra, A.H.G. Rinnooy-Kan, D.B. Shmoys (Eds.), </editor> <publisher> Wiley and Sons: </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: CPU time (sec) D 0 0.02 0.04 0.06 Cooperating ants Noncooperating ants Fig. 7. Cooperation changes the probability distribution of first finishing times: cooperating ants have a higher probability to find quickly an optimal solution. Test problem: CCAO <ref> [21] </ref>. The number of ants was set to m=4. Cpu time (msec) T o u r l e n g t h 50 51 52 0 100 200 300 400 500 600 700 800 Cooperating ants Noncooperating ants Fig. 8. Cooperating ants find better solutions in a shorter time. <p> Cpu time (msec) T o u r l e n g t h 50 51 52 0 100 200 300 400 500 600 700 800 Cooperating ants Noncooperating ants Fig. 8. Cooperating ants find better solutions in a shorter time. Test problem: CCAO <ref> [21] </ref>. Average on 25 runs. The number of ants was set to m =4. D. The importance of the pheromone and the heuristic function Experimental results have shown that the heuristic function h is fundamental in making the algorithm find good solutions in a reasonable time.
Reference: [22] <author> S. Goss, S. Aron, J.L. Deneubourg, and J.M. Pasteels, </author> <title> Self-organized shortcuts in the argentine ant, </title> <journal> Naturwissenschaften, </journal> <volume> vol. 76, </volume> <pages> pp. 579581, </pages> <year> 1989. </year>
Reference-contexts: In press. Dorigo and Gambardella - Ant Colony System 2 I. Introduction The natural metaphor on which ant algorithms are based is that of ant colonies. Real ants are capable of finding the shortest path from a food source to their nest [3], <ref> [22] </ref> without using visual cues [24] by exploiting pheromone information. While walking, ants deposit pheromone on the ground, and follow, in probability, pheromone previously deposited by other ants. A way ants exploit pheromone to find a shortest path between two points is shown in Fig. 1.
Reference: [23] <editor> P. P. Grass, La reconstruction du nid et les coordinations inter-individuelles chez Bellicositermes natalensis et Cubitermes sp . La thorie de la stigmergie: Essai dinterprtation des termites constructeurs, Insect Sociaux, </editor> <volume> vol. 6, </volume> <pages> pp. 4183, </pages> <year> 1959. </year>
Reference-contexts: This allows an indirect form of communication called stigmergy <ref> [23] </ref>, [9]. The interested reader will find a full description of ant system, of its biological motivations, and computational results in [12].
Reference: [24] <author> B. Hlldobler and E.O. Wilson, </author> <title> The ants. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1990. </year>
Reference-contexts: In press. Dorigo and Gambardella - Ant Colony System 2 I. Introduction The natural metaphor on which ant algorithms are based is that of ant colonies. Real ants are capable of finding the shortest path from a food source to their nest [3], [22] without using visual cues <ref> [24] </ref> by exploiting pheromone information. While walking, ants deposit pheromone on the ground, and follow, in probability, pheromone previously deposited by other ants. A way ants exploit pheromone to find a shortest path between two points is shown in Fig. 1.
Reference: [25] <author> D.S. Johnson and L.A. McGeoch, </author> <title> in press, The travelling salesman problem: a case study in local optimization, in Local Search in Combinatorial Optimization, </title> <editor> E.H.L. Aarts and J.K. Lenstra (Eds.), </editor> <publisher> Wiley and Sons: </publisher> <address> New York. </address>
Reference-contexts: ACS plus local search In Section 5 we have shown that ACS is competitive with other nature-inspired algorithms on some relatively simple problems. On the other hand, in the past years a lot of work has been done to define ad-hoc heuristics, see <ref> [25] </ref> for an overview, to solve the TSP. In general, these ad-hoc heuristics greatly outperform, on the specific problem of the TSP, general purpose algorithms approaches like evolutionary computation and simulated annealing. <p> A general approach is to use tour constructive heuristics to generate a solution and then to apply a tour improvement heuristic to locally optimize it. It has been shown recently <ref> [25] </ref> that it is more effective to alternate an improvement heuristic with mutations of the last (or of the best) solution produced, rather than iteratively executing a tour improvement heuristic starting from solutions generated randomly or by a constructive heuristic. <p> We have therefore added a tour improvement heuristic to ACS. In order to maintain ACS ability to solve both TSP and ATSP problems we have decided to base the local optimization heuristic on a restricted 3-opt procedure <ref> [25] </ref>, [27] that, while inserting/removing three edges on the path, considers only 3-opt moves that do not revert the order in which the cities are visited. The resulting algorithm, called ACS-3-opt, is shown in Fig. 10. <p> The implementation of the restricted 3-opt procedure includes some typical tricks which accelerate its use for TSP/ATSP problems. First, search for the candidate nodes during the restricted 3-opt procedure is only made inside the candidate list <ref> [25] </ref>. Second, the procedure uses a data structure called dont look bit [4] in which each bit is associated to a node of the tour. <p> a nonsequential-4-changes called double-bridge. (The double-bridge mutation has the property that it is the smallest change (4 edges) that can not be reverted in one step by 3-opt, LK and 2-opt.) A fair comparison of our results with the results obtained with the currently best performing algorithms for symmetric TSPs <ref> [25] </ref> is difficult since they use as local search a LinKernighan heuristic based on a segment-tree data structure [16] that is faster and gives better results than our restricted-3-opt procedure. It will be the subject of future work to add such a procedure to ACS. <p> Nevertheless, competition on the TSP is very tough, and a combination of a constructive method which generates good starting solution with local search which takes these solutions to a local optimum seems to be the best strategy <ref> [25] </ref>. We have shown that ACS is also a very good constructive heuristic to provide such starting solutions for local optimizers. Acknowledgments Marco Dorigo is a Research Associate with the FNRS. Luca Gambardella is Research Director at IDSIA.
Reference: [26] <author> L.P. Kaelbling, L.M. Littman and A.W. Moore, </author> <title> Reinforcement learning: a survey, </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> vol. 4, </volume> <pages> pp. 237285, </pages> <year> 1996. </year>
Reference-contexts: Pheromone updating is intended to allocate a greater amount of pheromone to shorter tours. In a sense, this is similar to a reinforcement learning scheme [2], <ref> [26] </ref> in which better solutions get a higher reinforcement (as happens, for example, in genetic algorithms under proportional selection). <p> We have experimented with three values for the term D t (r,s). The first choice was loosely inspired by Q-learning [40], an algorithm developed to solve reinforcement learning problems <ref> [26] </ref>.
Reference: [27] <author> P-C. Kanellakis and C.H. Papadimitriou, </author> <title> Local search for the asymmetric traveling salesman problem, </title> <journal> Operations Research, </journal> <volume> vol. 28, no. 5, </volume> <pages> pp. 10871099, </pages> <year> 1980. </year>
Reference-contexts: We have therefore added a tour improvement heuristic to ACS. In order to maintain ACS ability to solve both TSP and ATSP problems we have decided to base the local optimization heuristic on a restricted 3-opt procedure [25], <ref> [27] </ref> that, while inserting/removing three edges on the path, considers only 3-opt moves that do not revert the order in which the cities are visited. The resulting algorithm, called ACS-3-opt, is shown in Fig. 10.
Reference: [28] <author> E. L. Lawler, J. K. Lenstra, A. H. G. Rinnooy-Kan, and D. B. Shmoys (Eds.), </author> <title> The traveling salesman problem. </title> <publisher> Wiley and Sons: </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: B. ACS on some bigger problems When trying to solve big TSP problems it is common practice <ref> [28] </ref>, [35] to use a data structure known as candidate list.
Reference: [29] <author> F.T. Lin, C.Y. Kao, and C.C. Hsu, </author> <title> Applying the genetic approach to simulated annealing in solving some NP-Hard problems, </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> vol. 23, </volume> <pages> pp. 17521767, </pages> <year> 1993. </year>
Reference-contexts: Results using SA are from <ref> [29] </ref>. Eil50, Eil75 are from [14] and are included in TSPLIB with an additional city as Eil51.tsp and Eil76.tsp. KroA100 is also in TSPLIB. The best result for each problem is in boldface. Again, ACS offers the best performance in nearly every case.
Reference: [30] <author> S. Lin., </author> <title> Computer solutions of the traveling salesman problem, </title> <journal> Bell Systems Journal, </journal> <volume> vol. 44, </volume> <pages> pp. 22452269, </pages> <year> 1965. </year>
Reference-contexts: The most used and well-known tour improvement heuristics are 2-opt and 3-opt <ref> [30] </ref>, and LinKernighan [31] in which respectively two, three, and a variable number of edges are exchanged. It has been experimentally shown [35] that, in general, tour improvement heuristics produce better quality results than tour constructive heuristics.
Reference: [31] <author> S. Lin and B.W. Kernighan, </author> <title> An effective heuristic algorithm for the traveling salesman problem, </title> <journal> Operations Re search, </journal> <volume> vol. 21, </volume> <pages> pp. 498516, </pages> <year> 1973. </year>
Reference-contexts: The most used and well-known tour improvement heuristics are 2-opt and 3-opt [30], and LinKernighan <ref> [31] </ref> in which respectively two, three, and a variable number of edges are exchanged. It has been experimentally shown [35] that, in general, tour improvement heuristics produce better quality results than tour constructive heuristics.
Reference: [32] <author> V. Maniezzo, A.Colorni, and M.Dorigo, </author> <title> The ant system applied to the quadratic assignment problem, </title> <type> Tech. Rep. </type> <institution> IRIDIA/94-28 , 1994, Universit Libre de Bruxelles, Belgium. </institution> <note> Dorigo and Gambardella - Ant Colony System 23 </note>
Reference-contexts: Ant system has been applied to combinato rial optimiza tion problems such as the traveling salesman problem (TSP) [7], [8], [10], [12], and the quadratic assignment problem <ref> [32] </ref>. Ant colony system (ACS), the algorithm presented in this article, builds on the previous ant system in the direction of improving efficiency when applied to symmetric and asymmetric TSPs. <p> The above intuition is supported by encouraging, although preliminary, results obtained with ant system on the Dorigo and Gambardella - Ant Colony System 21 quadratic assignment problem [12], <ref> [32] </ref>. In conclusion, in this paper we have shown that ACS is an interesting novel approach to parallel stochastic optimization of the TSP. ACS has been shown to compare favorably with previous attempts to apply other heuristic algorithms like genetic algorithms, evolutionary programming, and simulated annealing.
Reference: [33] <author> O. Martin, S.W. Otto, </author> <title> and E.W. Felten, Largestep Markov chains for the TSP incorporating local search heuristics, </title> <journal> Operations Research Letters, </journal> <volume> vol. 11, </volume> <pages> pp. 219-224, </pages> <year> 1992. </year>
Reference-contexts: Our results are, on the other hand, comparable to those obtained by other algorithms considered to be very good. For example, on the lin318 problem ACS-3-opt has approximately the same performance as the large step Markov chain algorithm <ref> [33] </ref>.
Reference: [34] <author> J.Y. Potvin, </author> <year> 1993, </year> <title> The traveling salesman problem: a neural network perspective, </title> <journal> ORSA Journal of Computing, </journal> <volume> vol. 5, No. 4, </volume> <pages> pp. 328347. </pages>
Reference-contexts: Table II reports the results on the random instances. The heuristics with which we compare ACS are simulated annealing (SA), elastic net (EN), and self organizing map (SOM). Results on SA, EN, and SOM are from [13], <ref> [34] </ref>. ACS was run for 2,500 iterations using 10 ants (this amounts to approximately the same number of tour searched by the heuristics with which we compare our results). ACS results are averaged over 25 trials.
Reference: [35] <author> G. Reinelt, </author> <title> The traveling salesman: computational solutions for TSP applications. </title> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: Results obtained running experiments (see Table I) on a set of five randomly generated 50-city TSPs [13], on the Oliver30 symmetric TSP [41], and the ry48p asymmetric TSP <ref> [35] </ref> essentially suggest that local-updating is definitely useful, and that the local updating rule with Dt (r,s)=0 yields worse performance than local-updating with D t (r,s)= t 0 or with Dt g tr s s z , , ( ) = ( ) max . <p> B. ACS on some bigger problems When trying to solve big TSP problems it is common practice [28], <ref> [35] </ref> to use a data structure known as candidate list. <p> The most used and well-known tour improvement heuristics are 2-opt and 3-opt [30], and LinKernighan [31] in which respectively two, three, and a variable number of edges are exchanged. It has been experimentally shown <ref> [35] </ref> that, in general, tour improvement heuristics produce better quality results than tour constructive heuristics. A general approach is to use tour constructive heuristics to generate a solution and then to apply a tour improvement heuristic to locally optimize it.
Reference: [36] <author> D.J. Rosenkrantz, R.E. Stearns, and P.M. Lewis, </author> <title> An analysis of several heuristics for the traveling salesman problem, </title> <journal> SIAM Journal on Computing, </journal> <volume> vol. 6, </volume> <pages> pp. 563581, </pages> <year> 1977. </year>
Reference-contexts: ACS parameter settings In all experiments of the following sections the numeric parameters, except when indicated differently, are set to the following values: b=2, q 0 =0.9, a=r=0.1, t 0 =( nL nn ) -1 , where L nn is the tour length produced by the nearest neighbor heuristic 1 <ref> [36] </ref> and n is the number of cities.
Reference: [37] <author> R. Schoonderwoerd, O. Holland, J. Bruten, and L. Rothkrantz, </author> <title> Ant-based load balancing in telecommunications networks, Adaptive Behavior, </title> <publisher> in press. </publisher>
Reference-contexts: So ACS can be seen as a sort of guided parallel stochastic search in the neighborhood of the best tour. Recently there has been growing interest in the application of ant colony algorithms to difficult combinatorial problems. A first example is the work of Schoonderwoerd, Holland, Bruten and Rothkrantz <ref> [37] </ref> who apply an ant colony algorithm to the load balancing problem in telecommunications networks. Their algorithm takes inspiration from the same biological metaphor as ant system, although their implementation differs in many details due to the different characteristics of the problem.
Reference: [38] <author> T. Sttzle and H. Hoosa, </author> <title> Improvements on the ant system, introducing the MAX-MIN ant system, </title> <booktitle> Proceedings of ICANNGA97 - Third International Conference on Artificial Neural Networks and Genetic Algorithms, </booktitle> <year> 1997, </year> <institution> University of East Anglia, Norwich, UK. </institution>
Reference-contexts: Another interesting ongoing research is that of Sttzle and Hoos who are studying various extensions of ant system to improve its performance: in <ref> [38] </ref> they impose an upper and lower bound on the value of pheromone on edges, in [39] they add local search, much in the same spirit as we did in the previous Section 6.
Reference: [39] <author> T. Sttzle and H. Hoos, </author> <title> The ant system and local search for the traveling salesman problem, </title> <booktitle> Proceedings of ICEC'97 - 1997 IEEE 4th Inter national Conference on Evolutionary Computation, 1997, </booktitle> <publisher> IEEE Press. </publisher>
Reference-contexts: Another interesting ongoing research is that of Sttzle and Hoos who are studying various extensions of ant system to improve its performance: in [38] they impose an upper and lower bound on the value of pheromone on edges, in <ref> [39] </ref> they add local search, much in the same spirit as we did in the previous Section 6. Besides the two works above, among the "nature-inspired" heuristics, the closest to ACS seems to be Baluja and Caruanas Population Based Incremental Learning (PBIL) [1].
Reference: [40] <author> C.J.C.H. Watkins, </author> <title> Learning with delayed rewards. </title> <type> Ph.D. dissertation, </type> <institution> Psychology Department, University of Cambridge, </institution> <address> England, </address> <year> 1989. </year>
Reference-contexts: We have experimented with three values for the term D t (r,s). The first choice was loosely inspired by Q-learning <ref> [40] </ref>, an algorithm developed to solve reinforcement learning problems [26].
Reference: [41] <author> D. Whitley, T. Starkweather, and D. Fuquay, </author> <title> Scheduling problems and travelling salesman: the ge netic edge recombination operator, </title> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms , Morgan Kaufmann, </booktitle> <year> 1989, </year> <pages> pp. </pages> <note> 133140. Dorigo and Gambardella - Ant Colony System 24 </note>
Reference-contexts: Finally, we also ran experiments in which local-updating was not applied (i.e., the local updating rule is not used, as was the case in ant system). Results obtained running experiments (see Table I) on a set of five randomly generated 50-city TSPs [13], on the Oliver30 symmetric TSP <ref> [41] </ref>, and the ry48p asymmetric TSP [35] essentially suggest that local-updating is definitely useful, and that the local updating rule with Dt (r,s)=0 yields worse performance than local-updating with D t (r,s)= t 0 or with Dt g tr s s z , , ( ) = ( ) max . <p> Problem name ACS GA E SA Optimum Eil50 (50-city problem) 425 [1,830] (N/A) 426 [100,000] (N/A) 425 Eil75 (75-city problem) 535 [3,480] (N/A) 542 [325,000] (N/A) 535 KroA100 (100-city problem) 21,282 [4,820] (N/A) N/A [N/A] (N/A) 21,282 Results using EP are from [15], and those using GA are from <ref> [41] </ref> for Eil50, and Eil75, and from [6] for KroA100. Results using SA are from [29]. Eil50, Eil75 are from [14] and are included in TSPLIB with an additional city as Eil51.tsp and Eil76.tsp. KroA100 is also in TSPLIB. The best result for each problem is in boldface.
References-found: 41

