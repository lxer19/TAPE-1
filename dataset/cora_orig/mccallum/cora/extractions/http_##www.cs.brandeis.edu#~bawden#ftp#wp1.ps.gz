URL: http://www.cs.brandeis.edu/~bawden/ftp/wp1.ps.gz
Refering-URL: http://www.cs.brandeis.edu/~bawden/ftp/
Root-URL: http://www.cs.brandeis.edu
Title: Linear Naming and Computation  Linear naming: experimental software for optimizing communication protocols  
Author: Alan Bawden Harry G. Mairson 
Date: 1.5, October 6, 1998  
Note: Working Paper No. 1 Draft  
Abstract: We propose to design and implement significant new forms of procedure calling protocols, together with relevant supporting formal tools and implementation technology, and experiments that evaluate their feasibility and effectiveness. 
Abstract-found: 1
Intro-found: 1
Reference: [AM98] <author> Andrea Asperti and Harry G. Mairson. </author> <title> Parallel beta is not elementary recursive. </title> <booktitle> In Proc. 25-th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <address> Albuquerque, New Mexico. </address> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <month> January </month> <year> 1998. </year>
Reference-contexts: Bologna, he has investigated the algorithmic problems of graph reduction, shown why the technique can be considered efficient, and proved that the algorithm is correct <ref> [LM96, LM97, AM98] </ref>. Correctness is nontrivial, and a first-principles explanation has been lacking.
Reference: [App92] <author> Andrew W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: This property is what makes translating a program into "continuation-passing style" <ref> [Ste78, App92] </ref> an effective technique for a compiler. This translation exposes the unnamed intermediate values and continuations necessary to execute the program by turning them into explicitly named quantities. This simplifies working with the original program by reducing all reference manipulation to the named case.
Reference: [AS85] <author> Harold Abelson and Gerald Jay Sussman. </author> <title> Structure and Interpretation of Computer Programs. </title> <publisher> MIT Press, </publisher> <year> 1985. </year>
Reference-contexts: do we "unshare" its two uses, namely the respective applications to M and N? A more complex example where both sharing and unsharing is needed can be seen in the evaluation of the Scheme code ((lambda (x) ((x z)(x t))) (lambda (y) ((lambda (z) z) y))) using the substitution model <ref> [Lev80, AS85] </ref>. Draft 1.5, October 6, 1998 3 to be surmounted to make this technology work is to get these two kinds of sharing to work in tandem.
Reference: [Baw86] <author> Alan Bawden. </author> <title> Connection graphs. </title> <booktitle> In Proc. Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 258-265. </pages> <publisher> ACM, </publisher> <month> August </month> <year> 1986. </year>
Reference-contexts: Exploring this space of computational mechanisms, Bawden developed the linear graph reduction model as the most elegant abstraction of the kind of systems he was trying to build. As it happened, the "Connection Graphs" he described in <ref> [Baw86] </ref> are almost indistinguishable from the "Interaction Nets" later described by Lafont in [Laf90]. We think there must be something very deep about linear graph reduction given that it can be discovered from such different directions. During the late 1980s, Bawden got interested in the problems of computer networking.
Reference: [Baw92] <author> Alan Bawden. </author> <title> Linear Graph Reduction: Confronting the Cost of Naming. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <month> May </month> <year> 1992. </year> <institution> Dept. of Electrical Engineering and Computer Science. </institution>
Reference-contexts: Simultaneously, Alan Bawden (one of the co-PIs) was working on linear naming, and built a real distributed Scheme system using the same kind of technology <ref> [Baw92] </ref>. The French scientists, motivated by theory, called Lamping an "autodidactic engineer," but the first such real engineer was Bawden. 3.2 Implementation experience In the mid 1980s, Bawden was working on the seemingly unrelated problem of programming massively parallel SIMD computers, such as the Connection Machine [Hil85]. <p> Bawden built the nlgr (Network Linear Graph Reduction) system to demonstrate these capabilities <ref> [Baw92] </ref>. Linear references made it easy to support cheap cross-network references and highly portable data structures, and linear references also facilitated the demand-driven migration of tasks and data around the network without requiring explicit guidance from the programmer.
Reference: [BN84] <author> A. D. Birrell and B. J. Nelson. </author> <title> Implementing remote procedure calls. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(1) </volume> <pages> 39-59, </pages> <month> February </month> <year> 1984. </year> <note> 24 Draft 1.5, October 6, </note> <year> 1998 </year>
Reference-contexts: just as continuation-passing style style does not directly support intermediate values and continuations, the linear graph reduction model does not directly support nonlinear naming (sharing). 2.2 Applications to distributed computing 2.2.1 The state of the art The remote procedure call (RPC) is well established as a basis for distributed computing <ref> [BN84] </ref>. If what is needed is a single interaction with some remote entity, and if the nature of that interaction is known in advance, then RPC works well. RPC achieves a nice modularity by neatly aligning the network interface with the procedure call interface. <p> By distributed the vertices among the processors on a network, and migrating subgraphs from processor to processor as needed in order to apply reduction rules, linear graph reduction could be used to improve on existing network technology such as remote procedure calls (RPC) <ref> [BN84] </ref> and network futures [LS88]. Bawden built the nlgr (Network Linear Graph Reduction) system to demonstrate these capabilities [Baw92].
Reference: [CAL + 97] <author> Isabel Cruz, Michael Averbuch, Wendy T. Lucas, Melissa Radzymin--ski, and Kirby Zhang. </author> <title> Delaunay: a database visualization system. </title> <booktitle> In Proc. ACM SIGMOD, </booktitle> <pages> pages 510-513. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1997. </year>
Reference-contexts: While layout is a complicated problem for VLSI among other systems, we would like to have a try at such visualization, and there are geometric tools (e.g., the Delaunay system) that may be helpful here <ref> [CAL + 97] </ref>. 4.1.2 A virtual linear graph reduction machine The toolkit described above will be useful, but we want to use linear graph reduction as the basis for doing real computation.
Reference: [CJK95] <author> Henry Cejtin, Suresh Jagannathan, and Richard Kelsey. </author> <title> Higher-order distributed objects. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 17(5) </volume> <pages> 704-739, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: People working on distributed systems are starting to work with this idea now <ref> [HWW93, CJK95] </ref>. In addition to performance problems, there is another shortcoming shared by RPC and all the improvements described above: They all require the caller to specify the network node where the next step of the computation is to take place.
Reference: [FE85] <author> Joseph R. Falcone and Joel S. Emer. </author> <title> A programmable interface language for heterogeneous distributed systems. </title> <type> TR 371, </type> <institution> Digital Equipment Corp. Eastern Research Lab, </institution> <month> December </month> <year> 1985. </year>
Reference-contexts: This requires some language for describing that task to the remote site. Typical description language choices are Java [GJS96] or a dialect of Lisp or PostScript <ref> [FE85, Par92, Sun90] </ref>. Neither of these techniques is a fully general solution to the performance problems of pure RPC. In particular, neither addresses the continuation problem, since both techniques always insist on returning answers directly to the questioner.
Reference: [Fil89] <author> Andrzej Filinski. </author> <title> Declarative continuations and categorical duality. </title> <type> Master's thesis, </type> <institution> University of Copenhagen, Computer Science Department, </institution> <year> 1989. </year>
Reference-contexts: these ideas: its notion of demand-driven copying fits hand-in-glove with the logical ideas inherent in linear types. 2.3.4 Symmetric language design Following the above straightforward intuition of the "symmetry" of procedures, we recall research by Filinski, where he tried to construct a symmetric language where functions can abstract over either <ref> [Fil89] </ref>. He failed to get a true symmetry, and introduced an overly complicated language design to get his system to work, but the technology of graph reduction provides an avenue to a proper solution of his problem.
Reference: [Gir87] <author> Jean-Yves Girard. </author> <title> Linear logic. </title> <journal> Theoretical Computer Science, </journal> <volume> 50, </volume> <year> 1987. </year>
Reference-contexts: Graph reduction captures this exactly, and does so in a typed framework. Linear logic provides type information for this new perspective into what a procedure does, with new insights as well into how to write programs, and does so in a way that is very different from continuation-passing style <ref> [Gir87, Gir95] </ref>. This insight gives us a different view of control threads and into naming, where information about functions is considerably refined. In linear logic, a procedure of type A ffi B is one that accesses a datum of type A exactly once, and returns a datum of type B.
Reference: [Gir95] <author> Jean-Yves Girard. </author> <title> Linear logic: Its syntax and semantics. </title> <editor> In J.-Y. Girard, Y. Lafont, and L. Regnier, editors, </editor> <booktitle> Advances in Linear Logic, </booktitle> <pages> pages 1-42. </pages> <publisher> Cambridge University Press, </publisher> <year> 1995. </year> <booktitle> Proceedings of the Workshop on Linear Logic, </booktitle> <address> Ithaca, New York, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Graph reduction captures this exactly, and does so in a typed framework. Linear logic provides type information for this new perspective into what a procedure does, with new insights as well into how to write programs, and does so in a way that is very different from continuation-passing style <ref> [Gir87, Gir95] </ref>. This insight gives us a different view of control threads and into naming, where information about functions is considerably refined. In linear logic, a procedure of type A ffi B is one that accesses a datum of type A exactly once, and returns a datum of type B.
Reference: [GJS96] <author> James Gosling, Bill Joy, and Guy L. Steele Jr. </author> <title> The Java Language Specification. The Java Series. </title> <publisher> Addison-Wesley, </publisher> <year> 1996. </year>
Reference-contexts: This is almost like RPC, except that an arbitrary task is performed remotely, rather than selecting one from a fixed menu of exported procedures. This requires some language for describing that task to the remote site. Typical description language choices are Java <ref> [GJS96] </ref> or a dialect of Lisp or PostScript [FE85, Par92, Sun90]. Neither of these techniques is a fully general solution to the performance problems of pure RPC. In particular, neither addresses the continuation problem, since both techniques always insist on returning answers directly to the questioner.
Reference: [Hil85] <author> W. Daniel Hillis. </author> <title> The Connection Machine. </title> <publisher> MIT Press, </publisher> <year> 1985. </year>
Reference-contexts: The French scientists, motivated by theory, called Lamping an "autodidactic engineer," but the first such real engineer was Bawden. 3.2 Implementation experience In the mid 1980s, Bawden was working on the seemingly unrelated problem of programming massively parallel SIMD computers, such as the Connection Machine <ref> [Hil85] </ref>. In order to control communications network contention problems Draft 1.5, October 6, 1998 17 in such machines, he was working with programming languages in which com-munications bottlenecks are prevented by the simple expedient of outlawing the ability to make copies of references.
Reference: [HWW93] <author> W. C. Hsieh, P. Wang, and W. E. Weihl. </author> <title> Computation migration: enhancing locality for distributed-memory parallel systems. </title> <booktitle> In 4th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPOPP 93), </booktitle> <pages> pages 239-248, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: People working on distributed systems are starting to work with this idea now <ref> [HWW93, CJK95] </ref>. In addition to performance problems, there is another shortcoming shared by RPC and all the improvements described above: They all require the caller to specify the network node where the next step of the computation is to take place.
Reference: [KKR + 86] <author> David Kranz, Richard Kelsey, Jonathan Rees, Paul Hudak, James Philbin, and Norman Adams. </author> <title> ORBIT: An optimizing compiler for Scheme. </title> <booktitle> In Proc. of the SIGPLAN '86 Symposium on Compiler Construction, </booktitle> <pages> pages 219-233. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1986. </year>
Reference-contexts: Compiler writers that use continuation-passing style are aware of this loss of explicit information. They generally take special pains to be sure that the compiler stack-allocates continuations (at least in the common cases). See <ref> [KKR + 86] </ref> for an example. In effect they must work to recover some special case information about linearity that the translation into continuation-passing style has hidden. The translation of a program into the linear graph reduction model is closely analogous to the translation into continuation-passing style style.
Reference: [Laf90] <author> Yves Lafont. </author> <title> Interaction nets. </title> <booktitle> In Proc. Symposium on Principles of Programming Languages, </booktitle> <pages> pages 95-108. </pages> <publisher> ACM, </publisher> <month> January </month> <year> 1990. </year> <note> Draft 1.5, October 6, 1998 25 </note>
Reference-contexts: The problem was really solved by John Lamping about 1990 [Lam90], using a graph reduction technology that was very similar to one invented by Yves Lafont, who was using it for other purposes <ref> [Laf90] </ref>. Simultaneously, Alan Bawden (one of the co-PIs) was working on linear naming, and built a real distributed Scheme system using the same kind of technology [Baw92]. <p> As it happened, the "Connection Graphs" he described in [Baw86] are almost indistinguishable from the "Interaction Nets" later described by Lafont in <ref> [Laf90] </ref>. We think there must be something very deep about linear graph reduction given that it can be discovered from such different directions. During the late 1980s, Bawden got interested in the problems of computer networking.
Reference: [Lam90] <author> John Lamping. </author> <title> An algorithm for optimal lambda calculus reduction. </title> <booktitle> In Proc. Symposium on Principles of Programming Languages, </booktitle> <pages> pages 16-30. </pages> <publisher> ACM, </publisher> <month> January </month> <year> 1990. </year>
Reference-contexts: In the late 1970s, Jean-Jacques Levy was working on the idea of shared computation in the -calculus [Lev80]: he knew what a solution would have to do, but lacked all the algorithmic pieces to put together a solution. The problem was really solved by John Lamping about 1990 <ref> [Lam90] </ref>, using a graph reduction technology that was very similar to one invented by Yves Lafont, who was using it for other purposes [Laf90]. Simultaneously, Alan Bawden (one of the co-PIs) was working on linear naming, and built a real distributed Scheme system using the same kind of technology [Baw92].
Reference: [LBG + 88] <author> Barbara Liskov, Toby Bloom, David Gifford, Robert Scheifler, and William Weihl. </author> <title> Communication in the Mercury system. </title> <booktitle> In Proc. Hawaii Conference on System Sciences, </booktitle> <pages> pages 178-187. </pages> <publisher> IEEE, </publisher> <month> Jan-uary </month> <year> 1988. </year>
Reference-contexts: In order to take full advantage of this pipelining, the originator needs to be able to make many calls before claiming any of the returns. Some additional linguistic support is required to make such "call-streams" as neatly modular as simple RPC <ref> [LBG + 88, LS88] </ref>. In many cases the streaming problem can be solved by migrating the client to the location of the data, instead of insisting that the data journey to the client. Consider the case where the individual elements of the stream are to be summed together.
Reference: [Lev80] <author> Jean-Jaques Levy. </author> <title> Optimal reductions in the lambda-calculus. </title> <editor> In J. P. Seldin and J. R. Hindley, editors, To H. B. </editor> <booktitle> Curry: Essays in Combinatory Logic, Lambda Calculus and Formalism, </booktitle> <pages> pages 159-191. </pages> <publisher> Academic Press, </publisher> <year> 1980. </year>
Reference-contexts: do we "unshare" its two uses, namely the respective applications to M and N? A more complex example where both sharing and unsharing is needed can be seen in the evaluation of the Scheme code ((lambda (x) ((x z)(x t))) (lambda (y) ((lambda (z) z) y))) using the substitution model <ref> [Lev80, AS85] </ref>. Draft 1.5, October 6, 1998 3 to be surmounted to make this technology work is to get these two kinds of sharing to work in tandem. <p> In the late 1970s, Jean-Jacques Levy was working on the idea of shared computation in the -calculus <ref> [Lev80] </ref>: he knew what a solution would have to do, but lacked all the algorithmic pieces to put together a solution.
Reference: [LM96] <author> Julia L. Lawall and Harry G. Mairson. </author> <title> Optimality and inefficiency: </title> <booktitle> What isn't a cost model of the lambda calculus? In Proceedings of the 1996 ACM SIGPLAN International Conference on Functional Programming, </booktitle> <pages> pages 92-101, </pages> <address> Philadelphia, Pennsylvania, </address> <month> 24-26 May </month> <year> 1996. </year>
Reference-contexts: Bologna, he has investigated the algorithmic problems of graph reduction, shown why the technique can be considered efficient, and proved that the algorithm is correct <ref> [LM96, LM97, AM98] </ref>. Correctness is nontrivial, and a first-principles explanation has been lacking.
Reference: [LM97] <author> Julia L. Lawall and Harry G. Mairson. </author> <title> On global dynamics of optimal graph reduction. </title> <booktitle> In Proceedings of the 1997 ACM SIGPLAN International Conference on Functional Programming, </booktitle> <pages> pages 188-195, </pages> <address> Amsterdam, The Netherlands, </address> <month> 9-11 June </month> <year> 1997. </year>
Reference-contexts: Bologna, he has investigated the algorithmic problems of graph reduction, shown why the technique can be considered efficient, and proved that the algorithm is correct <ref> [LM96, LM97, AM98] </ref>. Correctness is nontrivial, and a first-principles explanation has been lacking.
Reference: [LS88] <author> Barbara Liskov and Liuba Shrira. </author> <title> Promises: Linguistic support for efficient asynchronous procedure calls in distributed systems. </title> <booktitle> In Proc. Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 260-267. </pages> <publisher> ACM, </publisher> <month> July </month> <year> 1988. </year>
Reference-contexts: In order to take full advantage of this pipelining, the originator needs to be able to make many calls before claiming any of the returns. Some additional linguistic support is required to make such "call-streams" as neatly modular as simple RPC <ref> [LBG + 88, LS88] </ref>. In many cases the streaming problem can be solved by migrating the client to the location of the data, instead of insisting that the data journey to the client. Consider the case where the individual elements of the stream are to be summed together. <p> By distributed the vertices among the processors on a network, and migrating subgraphs from processor to processor as needed in order to apply reduction rules, linear graph reduction could be used to improve on existing network technology such as remote procedure calls (RPC) [BN84] and network futures <ref> [LS88] </ref>. Bawden built the nlgr (Network Linear Graph Reduction) system to demonstrate these capabilities [Baw92].
Reference: [Mog91] <author> Eugenio Moggi. </author> <title> Notions of computation and monads. Information and Computation, </title> <address> 93:1:55-92, </address> <year> 1991. </year>
Reference-contexts: a virtual linear graph reduction machine. * New techniques for compiling linear graph reduction rules into efficient runtime code. * New language constructs for handling control flow, with relevant compiler extensions. * An implementation of "symmetric building blocks" for manipulating continuations, state, I/O, etc., including a comparative analysis with mon-ads <ref> [Mog91, Wad92] </ref>, a standard functional programming solution to these problems. * Experiments evaluating "standard" versus "customized" graph reduction rules. * New techniques for optimizing the demand-driven incremental copying of closures that lies at the heart of our technology. * Sample applications that test our technology in the real-world domain of network
Reference: [Par92] <author> Craig Partridge. </author> <title> Late Binding RPC. </title> <type> PhD thesis, </type> <institution> Harvard University, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: This requires some language for describing that task to the remote site. Typical description language choices are Java [GJS96] or a dialect of Lisp or PostScript <ref> [FE85, Par92, Sun90] </ref>. Neither of these techniques is a fully general solution to the performance problems of pure RPC. In particular, neither addresses the continuation problem, since both techniques always insist on returning answers directly to the questioner. <p> The continuation problem could be solved by using a variant of RPC where the call message explicitly contained a continuation that said where to 4 Each RPC call takes 2T , T for the call to travel from caller to callee, and T for the reply to return. See <ref> [Par92] </ref> for a good presentation of the argument why ultimately T is the only time worth worrying about. Draft 1.5, October 6, 1998 9 send the answer.
Reference: [Pos81] <author> J. B. Postel. </author> <title> Transmission control protocol. Request for Comments (RFC) 793, </title> <institution> USC/Information Sciences Institute, </institution> <month> September </month> <year> 1981. </year> <note> Available from ftp://ftp.ds.internic.net/rfc/. </note>
Reference-contexts: A network stream (such as a TCP connection <ref> [Pos81] </ref>) will achieve the same goal with much better performance, by allowing data and acknowledgments to flow in both directions 8 Draft 1.5, October 6, 1998 at the same time, but it is very difficult to duplicate the way a stream uses the network given only RPC.
Reference: [Ste78] <author> Guy L. Steele Jr. RABBIT: </author> <title> A compiler for SCHEME (a study in compiler optimization). </title> <type> TR 474, </type> <institution> MIT AI Lab, </institution> <month> May </month> <year> 1978. </year> <note> 26 Draft 1.5, October 6, </note> <year> 1998 </year>
Reference-contexts: This property is what makes translating a program into "continuation-passing style" <ref> [Ste78, App92] </ref> an effective technique for a compiler. This translation exposes the unnamed intermediate values and continuations necessary to execute the program by turning them into explicitly named quantities. This simplifies working with the original program by reducing all reference manipulation to the named case.
Reference: [Sun90] <author> Sun Microsystems, Inc. </author> <title> Network extensible file system protocol spec-ification, </title> <month> February </month> <year> 1990. </year> <note> Contact nfs3@sun.com. </note>
Reference-contexts: This requires some language for describing that task to the remote site. Typical description language choices are Java [GJS96] or a dialect of Lisp or PostScript <ref> [FE85, Par92, Sun90] </ref>. Neither of these techniques is a fully general solution to the performance problems of pure RPC. In particular, neither addresses the continuation problem, since both techniques always insist on returning answers directly to the questioner.
Reference: [Wad92] <editor> Philip Wadler. </editor> <booktitle> The essence of functional programming. In Proc. ACM International Conference on Principles of Programming Languages, </booktitle> <pages> pages 1-14, </pages> <year> 1992. </year> <note> Draft 1.5, October 6, 1998 27 </note>
Reference-contexts: a virtual linear graph reduction machine. * New techniques for compiling linear graph reduction rules into efficient runtime code. * New language constructs for handling control flow, with relevant compiler extensions. * An implementation of "symmetric building blocks" for manipulating continuations, state, I/O, etc., including a comparative analysis with mon-ads <ref> [Mog91, Wad92] </ref>, a standard functional programming solution to these problems. * Experiments evaluating "standard" versus "customized" graph reduction rules. * New techniques for optimizing the demand-driven incremental copying of closures that lies at the heart of our technology. * Sample applications that test our technology in the real-world domain of network
References-found: 29

