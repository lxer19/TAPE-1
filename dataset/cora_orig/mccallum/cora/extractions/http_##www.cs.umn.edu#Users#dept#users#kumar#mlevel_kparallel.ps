URL: http://www.cs.umn.edu/Users/dept/users/kumar/mlevel_kparallel.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Title: Multilevel k -way Partitioning Scheme for Irregular Graphs  
Author: George Karypis and Vipin Kumar 
Keyword: Parallel Graph Partitioning, Multilevel Partitioning Methods, Spectral Partitioning Methods, Kernighan-Lin Heuristic, Parallel Sparse Matrix Algorithms.  
Address: Minneapolis, MN 55455,  9:02am  
Affiliation: University of Minnesota, Department of Computer Science  at  
Note: Parallel  
Pubnum: Technical Report: 96-036  
Email: fkarypis, kumarg@cs.umn.edu  
Date: Last updated on October 24, 1996  
Abstract: A short version of this paper appears in Supercomputing 1996 The serial algorithms described in this paper are implemented by the `METIS: Unstructured Graph Partitioning and Sparse Matrix Ordering System'. METIS is available on WWW at URL: http://www.cs.umn.edu/karypis/metis/metis.html Abstract In this paper we present a parallel formulation of a multilevel k-way graph partitioning algorithm. The multilevel k-way partitioning algorithm reduces the size of the graph by collapsing vertices and edges (coarsening phase), finds a k-way partitioning of the smaller graph, and then it constructs a k-way partitioning for the original graph by projecting and refining the partition to successively finer graphs (uncoarsening phase). A key innovative feature of our parallel formulation is that it utilizes graph coloring to effectively parallelize both the coarsening and the refinement during the uncoarsening phase. Our algorithm is able to achieve a high degree of concurrency, while maintaining the high quality partitions produced by the serial algorithm. We test our scheme on a large number of graphs from finite element methods, and transportation domains. For graphs with a million vertices, our parallel formulation produces high quality 128-way partitions on 128 processors in a little over two seconds, on Cray T3D. Thus our parallel algorithm makes it feasible to perform frequent dynamic graph partition in adaptive computations without compromising quality. fl This work was supported by NSF CCR-9423082 and by Army Research Office contract DA/DAAH04-95-1-0538, and by Army High Performance Computing Research Center under the auspices of the Department of the Army, Army Research Laboratory cooperative agreement number DAAH04-95-2-0003/contract number DAAH04-95-C-0008, the content of which does not necessarily reflect the position or the policy of the government, and no official endorsement should be inferred. Access to computing facilities was provided by AHPCRC, Minnesota Supercomputer Institute, Cray Research Inc, and by the Pittsburgh Supercomputing Center. Related papers are available via WWW at URL: http://www.cs.umn.edu/karypis 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Stephen T. Barnard. Pmrsb: </author> <title> Parallel multilevel recursive spectral bisection. </title> <booktitle> In Supercomputing 1995, </booktitle> <year> 1995. </year>
Reference-contexts: Despite the small run time of multilevel schemes, it is important to develop highly parallel formulations of these schemes for reasons discussed in Section 3. Developing parallel graph partitioning algorithms has received a lot of attention <ref> [15, 35, 6, 19, 2, 1, 23] </ref> due to its extensive applications in many areas. However, most of this work was concentrated on algorithms based on geometric graph partitioning [15, 6], or algorithms that have very high computational requirements, such as spectral bisection [2, 1, 19]. <p> However, most of this work was concentrated on algorithms based on geometric graph partitioning [15, 6], or algorithms that have very high computational requirements, such as spectral bisection <ref> [2, 1, 19] </ref>. Geometric graph partitioning algorithms tend to be inherently parallel, but often produce significantly worse partitions compared with the multilevel algorithms. <p> Development of formulations of multilevel graph partitioning schemes is quite challenging. Coarsening requires that nodes connected via edges be merged together. Since the graph is distributed randomly across the processors, parallel coarsening schemes can require a lot of communication <ref> [35, 1, 23] </ref>. The Kernighan-Lin refinement heuristic and its variant, that are used during the uncoarsening phase, appear serial in nature [9], and previous attempts to parallelize them have had mixed success [9, 6, 23]. In this paper we present a parallel formulation for the multilevel k-way partitioning algorithm [22]. <p> The speedup obtained by this algorithm are similar to those obtained by our algorithm, as the underlying communication in the coarsening phase is similar to that in the different phases of our algorithm. Barnard <ref> [1] </ref> has developed a parallel formulation of multilevel spectral algorithm. This algorithm uses a one-dimensional mapping of the graph to the processors and uses a parallel formulation of Luby's [28] algorithm to compute a maximal independent set of vertices to construct the next level coarser graph.
Reference: [2] <author> Stephen T. Barnard and Horst Simon. </author> <title> A parallel implementation of multilevel recursive spectral bisection for application to adaptive unstructured meshes. </title> <booktitle> In Proceedings of the seventh SIAM conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 627-632, </pages> <year> 1995. </year>
Reference-contexts: Despite the small run time of multilevel schemes, it is important to develop highly parallel formulations of these schemes for reasons discussed in Section 3. Developing parallel graph partitioning algorithms has received a lot of attention <ref> [15, 35, 6, 19, 2, 1, 23] </ref> due to its extensive applications in many areas. However, most of this work was concentrated on algorithms based on geometric graph partitioning [15, 6], or algorithms that have very high computational requirements, such as spectral bisection [2, 1, 19]. <p> However, most of this work was concentrated on algorithms based on geometric graph partitioning [15, 6], or algorithms that have very high computational requirements, such as spectral bisection <ref> [2, 1, 19] </ref>. Geometric graph partitioning algorithms tend to be inherently parallel, but often produce significantly worse partitions compared with the multilevel algorithms.
Reference: [3] <author> Stephen T. Barnard and Horst D. Simon. </author> <title> A fast multilevel implementation of recursive spectral bisection for partitioning unstructured problems. </title> <booktitle> In Proceedings of the sixth SIAM conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 711-718, </pages> <year> 1993. </year>
Reference-contexts: These schemes provide significantly better partitions than those provided by spectral partitioning techniques [33], and are generally at least an order of magnitude faster than even the state-of-the art implementation of spectral techniques <ref> [3] </ref>. Despite the small run time of multilevel schemes, it is important to develop highly parallel formulations of these schemes for reasons discussed in Section 3. <p> In this paper we present a parallel formulation for the multilevel k-way partitioning algorithm [22]. This formulation is also generally applicable to any multilevel graph partitioning algorithm that does coarsening of the graph and refines the partitions during the uncoarsening phase <ref> [21, 3] </ref>. A key feature of our parallel formulation is that it utilizes graph coloring to successfully parallelize both the coarsening and the refinement phases. <p> The experiments presented in [22] show that our algorithm produces partitions that are of comparable or better quality than those produced by the multilevel recursive bisection algorithm [21] and significantly better than those produced by the state-of-the art multilevel spectral bisection algorithm <ref> [3] </ref>. Furthermore, our k-way partitioning algorithm is up to 5 times faster than the multilevel recursive bisection, and up to 150 times faster than multilevel spectral bisection. <p> However, the quality differences can be eliminated if the multilevel bisection is used during the initial partitioning phase. The quality of the parallel partitioning algorithm relative to the widely used, multilevel spectral bisection (MSB) <ref> [3] </ref>, is shown in Figure 5. The MSB partitions were produced using the state-of-the art MSB algorithm as implemented in the Chaco 2 [17] graph partitioning package.
Reference: [4] <author> T. Bui and C. Jones. </author> <title> A heuristic for reducing fill in sparse matrix factorization. </title> <booktitle> In 6th SIAM Conf. Parallel Processing for Scientific Computing, </booktitle> <pages> pages 445-452, </pages> <year> 1993. </year>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. Recently, a number of researchers have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 5, 13, 14, 16, 7, 32, 21, 20] </ref>. <p> Some of these multilevel schemes <ref> [4, 16, 21, 20, 22] </ref> provide excellent partitions for a wide variety of graphs. These schemes provide significantly better partitions than those provided by spectral partitioning techniques [33], and are generally at least an order of magnitude faster than even the state-of-the art implementation of spectral techniques [3]. <p> Note that the coarsening scheme used in Barnard's algorithm can not be used in any multilevel graph partitioning algorithm <ref> [4, 16, 21, 22, 35] </ref>. The reason is that the coarsened graph of the multilevel spectral algorithms does not have enough information to enforce balance constraints and partition quality.
Reference: [5] <author> Chung-Kuan Cheng and Yen-Chuen A. Wei. </author> <title> An improved two-way partitioning algorithm with stable performance. </title> <journal> IEEE Transactions on Computer Aided Design, </journal> <volume> 10(12) </volume> <pages> 1502-1511, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. Recently, a number of researchers have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 5, 13, 14, 16, 7, 32, 21, 20] </ref>.
Reference: [6] <author> Pedro Diniz, Steve Plimpton, Bruce Hendrickson, and Robert Leland. </author> <title> Parallel algorithms for dynamically partitioning unstructured grids. </title> <booktitle> In Proceedings of the seventh SIAM conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 615-620, </pages> <year> 1995. </year>
Reference-contexts: Despite the small run time of multilevel schemes, it is important to develop highly parallel formulations of these schemes for reasons discussed in Section 3. Developing parallel graph partitioning algorithms has received a lot of attention <ref> [15, 35, 6, 19, 2, 1, 23] </ref> due to its extensive applications in many areas. However, most of this work was concentrated on algorithms based on geometric graph partitioning [15, 6], or algorithms that have very high computational requirements, such as spectral bisection [2, 1, 19]. <p> Developing parallel graph partitioning algorithms has received a lot of attention [15, 35, 6, 19, 2, 1, 23] due to its extensive applications in many areas. However, most of this work was concentrated on algorithms based on geometric graph partitioning <ref> [15, 6] </ref>, or algorithms that have very high computational requirements, such as spectral bisection [2, 1, 19]. Geometric graph partitioning algorithms tend to be inherently parallel, but often produce significantly worse partitions compared with the multilevel algorithms. <p> The Kernighan-Lin refinement heuristic and its variant, that are used during the uncoarsening phase, appear serial in nature [9], and previous attempts to parallelize them have had mixed success <ref> [9, 6, 23] </ref>. In this paper we present a parallel formulation for the multilevel k-way partitioning algorithm [22]. This formulation is also generally applicable to any multilevel graph partitioning algorithm that does coarsening of the graph and refines the partitions during the uncoarsening phase [21, 3]. <p> Our algorithm is able to achieve high degree of concurrency while it maintains the high quality of the partitions produced by the serial multilevel partitioning algorithm. This parallel refinement algorithm can also be used in conjunction with any other parallel graph partitioning algorithm that requires k-way refinement (e.g., <ref> [6] </ref>) to improve its quality. We test our scheme on a large number of graphs from finite element methods, and transportation domains. Our parallel formulation on Cray T3D produces high quality 128-way partitions on 128 processors in small amount of time. <p> Being able to compute good partitions fast (in parallel) is essential for reducing the overall run time of this type of applications. In some problems, the computational effort in each grid cell changes over time <ref> [6] </ref>. For example, in many codes that advect particles through a grid, large temporal and spatial variations in particle density can introduce substantial load imbalance. Dynamic repartition of the corresponding vertex-weighted graph is crucial to balance the computation among processors. <p> Clearly, the group selection algorithm must eliminate this type of unnecessary vertex movements. One possible way of performing the k-way refinement is to pairwise refine partitions <ref> [6] </ref>. That is, assuming that we have four partitions all having common boundaries, we do a 4-way refinement by performing the following 2-way refinements: (1,2), (3,4), (1,3), (2,4), (1,4), (2,3). Since we have a total of four processors, two of these 2-way refinements can go on at the same time. <p> Since we have a total of four processors, two of these 2-way refinements can go on at the same time. The pairs that can be refined concurrently are determined by a matching of the processor graph <ref> [6] </ref>. However, this parallel refinement algorithm restricts the type of vertex movements that can be performed in each step. <p> Diniz et al., <ref> [6] </ref> present a parallel formulation of the inertial algorithm [31] for partitioning. This algorithm computes a k-way partition using inertial recursive bisection (which is naturally parallel), and then does pairwise partition refinement using the Kernighan-Lin heuristic as described in Section 4.
Reference: [7] <author> J. Garbers, H. J. Promel, and A. Steger. </author> <title> Finding clusters in VLSI circuits. </title> <booktitle> In Proceedings of IEEE International Conference on Computer Aided Design, </booktitle> <pages> pages 520-523, </pages> <year> 1990. </year>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. Recently, a number of researchers have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 5, 13, 14, 16, 7, 32, 21, 20] </ref>.
Reference: [8] <author> A. George. </author> <title> Nested dissection of a regular finite-element mesh. </title> <journal> SIAM Journal on Numerical Ananlysis, </journal> <volume> 10 </volume> <pages> 345-363, </pages> <year> 1973. </year>
Reference-contexts: This is done as follows: The various pieces of the coarse graph are gathered to all the processors using an all-to-all broadcast operation [27]. At this point the processors perform recursive bisection using an algorithm that is based on nested dissection <ref> [8] </ref> and greedy partition refinement. However, as illustrated in Figure 3, each processor explores only a single path of the recursive bisection tree. At the end each processor stores the vertices that correspond to its partition of the p-way partition.
Reference: [9] <author> J. R. Gilbert and E. Zmijewski. </author> <title> A parallel graph partitioning algorithm for a message-passing multiprocessor. </title> <journal> Internation Journal of Parallel Programming, </journal> (16):498-513, 1987. 
Reference-contexts: Coarsening requires that nodes connected via edges be merged together. Since the graph is distributed randomly across the processors, parallel coarsening schemes can require a lot of communication [35, 1, 23]. The Kernighan-Lin refinement heuristic and its variant, that are used during the uncoarsening phase, appear serial in nature <ref> [9] </ref>, and previous attempts to parallelize them have had mixed success [9, 6, 23]. In this paper we present a parallel formulation for the multilevel k-way partitioning algorithm [22]. <p> The Kernighan-Lin refinement heuristic and its variant, that are used during the uncoarsening phase, appear serial in nature [9], and previous attempts to parallelize them have had mixed success <ref> [9, 6, 23] </ref>. In this paper we present a parallel formulation for the multilevel k-way partitioning algorithm [22]. This formulation is also generally applicable to any multilevel graph partitioning algorithm that does coarsening of the graph and refines the partitions during the uncoarsening phase [21, 3].
Reference: [10] <author> Anshul Gupta. </author> <title> Fast and effective algorithms for graph partitioning and sparse matrix reordering. </title> <type> Technical Report RC 20496 (90799), </type> <institution> IBM T. J. Watson Research Center, </institution> <address> Yorktown Heights, NY, </address> <month> July 10, </month> <year> 1996. </year>
Reference-contexts: This algorithm obtains speedup in the range of 25 to 40 on 128-processor CM5. Due to limited global matching and the absence of partition refinement, the orderings produced by this algorithm are worse than those produced by state-of-the-art multilevel ordering algorithms <ref> [21, 18, 10] </ref>. The speedup obtained by this algorithm are similar to those obtained by our algorithm, as the underlying communication in the coarsening phase is similar to that in the different phases of our algorithm. Barnard [1] has developed a parallel formulation of multilevel spectral algorithm.
Reference: [11] <author> Anshul Gupta, George Karypis, and Vipin Kumar. </author> <title> Highly scalable parallel algorithms for sparse matrix factorization. </title> <type> Technical Report 94-63, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN, </institution> <year> 1994. </year> <note> To appear in IEEE Transactions on Parallel and Distributed Computing. Available on WWW at URL http://www.cs.umn.edu/karypis/papers/sparse-cholesky.ps. </note>
Reference-contexts: Dynamic repartition of the corresponding vertex-weighted graph is crucial to balance the computation among processors. Furthermore, with recent development of highly parallel formulations of sparse Cholesky factorization algorithms <ref> [12, 25, 11, 36] </ref>, numeric factorization on parallel computers can take much less time than the step for computing a fill-reducing ordering on a serial computer, making that the new bottleneck.
Reference: [12] <author> Anshul Gupta and Vipin Kumar. </author> <title> A scalable parallel algorithm for sparse matrix factorization. </title> <type> Technical Report 94-19, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN, </institution> <year> 1994. </year> <note> A shorter version appears in Supercomputing '94. TR available in users/kumar/sparse-cholesky.ps at anonymous FTP site ftp.cs.umn.edu. </note>
Reference-contexts: Dynamic repartition of the corresponding vertex-weighted graph is crucial to balance the computation among processors. Furthermore, with recent development of highly parallel formulations of sparse Cholesky factorization algorithms <ref> [12, 25, 11, 36] </ref>, numeric factorization on parallel computers can take much less time than the step for computing a fill-reducing ordering on a serial computer, making that the new bottleneck.
Reference: [13] <author> Lars Hagen and Andrew Kahng. </author> <title> Fast spectral methods for ratio cut partitioning and clustering. </title> <booktitle> In Proceedings of IEEE International Conference on Computer Aided Design, </booktitle> <pages> pages 10-13, </pages> <year> 1991. </year>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. Recently, a number of researchers have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 5, 13, 14, 16, 7, 32, 21, 20] </ref>.
Reference: [14] <author> Lars Hagen and Andrew Kahng. </author> <title> A new approach to effective circuit clustering. </title> <booktitle> In Proceedings of IEEE International Conference on Computer Aided Design, </booktitle> <pages> pages 422-427, </pages> <year> 1992. </year>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. Recently, a number of researchers have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 5, 13, 14, 16, 7, 32, 21, 20] </ref>.
Reference: [15] <author> M. T. Heath and Padma Raghavan. </author> <title> A Cartesian parallel nested dissection algorithm. </title> <journal> SIAM Journal of Matrix Analysis and Applications, </journal> <volume> 16(1) </volume> <pages> 235-253, </pages> <year> 1995. </year>
Reference-contexts: Despite the small run time of multilevel schemes, it is important to develop highly parallel formulations of these schemes for reasons discussed in Section 3. Developing parallel graph partitioning algorithms has received a lot of attention <ref> [15, 35, 6, 19, 2, 1, 23] </ref> due to its extensive applications in many areas. However, most of this work was concentrated on algorithms based on geometric graph partitioning [15, 6], or algorithms that have very high computational requirements, such as spectral bisection [2, 1, 19]. <p> Developing parallel graph partitioning algorithms has received a lot of attention [15, 35, 6, 19, 2, 1, 23] due to its extensive applications in many areas. However, most of this work was concentrated on algorithms based on geometric graph partitioning <ref> [15, 6] </ref>, or algorithms that have very high computational requirements, such as spectral bisection [2, 1, 19]. Geometric graph partitioning algorithms tend to be inherently parallel, but often produce significantly worse partitions compared with the multilevel algorithms. <p> Furthermore, our k-way partitioning algorithm is up to 5 times faster than the multilevel recursive bisection, and up to 150 times faster than multilevel spectral bisection. The run time of our k-way partitioning algorithm is comparable to the run time of geometric recursive bisection algorithms <ref> [15, 34, 30, 29, 31] </ref> while it produces partitions that are generally 20% better [21].
Reference: [16] <author> Bruce Hendrickson and Robert Leland. </author> <title> A multilevel algorithm for partitioning graphs. </title> <type> Technical Report SAND93-1301, </type> <institution> Sandia National Laboratories, </institution> <year> 1993. </year>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. Recently, a number of researchers have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 5, 13, 14, 16, 7, 32, 21, 20] </ref>. <p> Some of these multilevel schemes <ref> [4, 16, 21, 20, 22] </ref> provide excellent partitions for a wide variety of graphs. These schemes provide significantly better partitions than those provided by spectral partitioning techniques [33], and are generally at least an order of magnitude faster than even the state-of-the art implementation of spectral techniques [3]. <p> Note that the coarsening scheme used in Barnard's algorithm can not be used in any multilevel graph partitioning algorithm <ref> [4, 16, 21, 22, 35] </ref>. The reason is that the coarsened graph of the multilevel spectral algorithms does not have enough information to enforce balance constraints and partition quality. <p> For example, refinement algorithms that are able to climb out of local minima by performing some moves that do not decrease the edge-cut <ref> [16, 21] </ref> can be easily implemented using the techniques described in this paper. The performance achieved by our algorithm allows for the development of efficient and scalable parallel formulations for many diverse problems that utilize and operate on unstructured graphs.
Reference: [17] <author> Bruce Hendrickson and Robert Leland. </author> <title> The chaco user's guide, version 2.0. </title> <type> Technical Report SAND94-2692, </type> <institution> Sandia National Laboratories, </institution> <year> 1994. </year>
Reference-contexts: The quality of the parallel partitioning algorithm relative to the widely used, multilevel spectral bisection (MSB) [3], is shown in Figure 5. The MSB partitions were produced using the state-of-the art MSB algorithm as implemented in the Chaco 2 <ref> [17] </ref> graph partitioning package. From this figure we see that the quality of our parallel multilevel k-way partitioning algorithm is usually 10% to 20% better than that of MSB, and for some graphs, it is up to 75% better.
Reference: [18] <author> Bruce Hendrickson and Edward Rothberg. </author> <title> Improving the runtime and quality of nested dissection ordering. </title> <type> Technical Report CS-96-000, </type> <institution> Sandia National Laboratories, </institution> <year> 1996. </year>
Reference-contexts: This algorithm obtains speedup in the range of 25 to 40 on 128-processor CM5. Due to limited global matching and the absence of partition refinement, the orderings produced by this algorithm are worse than those produced by state-of-the-art multilevel ordering algorithms <ref> [21, 18, 10] </ref>. The speedup obtained by this algorithm are similar to those obtained by our algorithm, as the underlying communication in the coarsening phase is similar to that in the different phases of our algorithm. Barnard [1] has developed a parallel formulation of multilevel spectral algorithm.
Reference: [19] <author> Zdenek Johan, Kapil K. Mathur, S. Lennart Johnsson, and Thomas J. R. Hughes. </author> <title> Finite element methods on the connection machine cm-5 system. </title> <type> Technical report, </type> <institution> Thinking Machines Corporation, </institution> <year> 1993. </year>
Reference-contexts: Despite the small run time of multilevel schemes, it is important to develop highly parallel formulations of these schemes for reasons discussed in Section 3. Developing parallel graph partitioning algorithms has received a lot of attention <ref> [15, 35, 6, 19, 2, 1, 23] </ref> due to its extensive applications in many areas. However, most of this work was concentrated on algorithms based on geometric graph partitioning [15, 6], or algorithms that have very high computational requirements, such as spectral bisection [2, 1, 19]. <p> However, most of this work was concentrated on algorithms based on geometric graph partitioning [15, 6], or algorithms that have very high computational requirements, such as spectral bisection <ref> [2, 1, 19] </ref>. Geometric graph partitioning algorithms tend to be inherently parallel, but often produce significantly worse partitions compared with the multilevel algorithms.
Reference: [20] <author> G. Karypis and V. Kumar. </author> <title> Analysis of multilevel graph partitioning. </title> <type> Technical Report TR 95-037, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/karypis/papers/mlevel analysis.ps. A short version appears in Supercomputing 95. 20 </note>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. Recently, a number of researchers have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 5, 13, 14, 16, 7, 32, 21, 20] </ref>. <p> Some of these multilevel schemes <ref> [4, 16, 21, 20, 22] </ref> provide excellent partitions for a wide variety of graphs. These schemes provide significantly better partitions than those provided by spectral partitioning techniques [33], and are generally at least an order of magnitude faster than even the state-of-the art implementation of spectral techniques [3].
Reference: [21] <author> G. Karypis and V. Kumar. </author> <title> A fast and high quality multilevel scheme for partitioning irregular graphs. </title> <type> Technical Report TR 95-035, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/karypis/papers/mlevel serial.ps. A short version appears in Intl. Conf. on Parallel Processing 1995. </note>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. Recently, a number of researchers have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 5, 13, 14, 16, 7, 32, 21, 20] </ref>. <p> Some of these multilevel schemes <ref> [4, 16, 21, 20, 22] </ref> provide excellent partitions for a wide variety of graphs. These schemes provide significantly better partitions than those provided by spectral partitioning techniques [33], and are generally at least an order of magnitude faster than even the state-of-the art implementation of spectral techniques [3]. <p> In this paper we present a parallel formulation for the multilevel k-way partitioning algorithm [22]. This formulation is also generally applicable to any multilevel graph partitioning algorithm that does coarsening of the graph and refines the partitions during the uncoarsening phase <ref> [21, 3] </ref>. A key feature of our parallel formulation is that it utilizes graph coloring to successfully parallelize both the coarsening and the refinement phases. <p> The basic structure of a multilevel algorithm is illustrated in Figure 1. The graph G D .V ; E / is first coarsened down to a small number of vertices, a k-way partition of this much smaller graph is computed (using multilevel recursive bisection <ref> [21] </ref>), and then this partition is projected back towards the original graph (finer graph), by periodically refining the partition. Since the finer graph has more degrees of freedom, such refinements improve the quality of the partitions. <p> Since the finer graph has more degrees of freedom, such refinements improve the quality of the partitions. The experiments presented in [22] show that our algorithm produces partitions that are of comparable or better quality than those produced by the multilevel recursive bisection algorithm <ref> [21] </ref> and significantly better than those produced by the state-of-the art multilevel spectral bisection algorithm [3]. Furthermore, our k-way partitioning algorithm is up to 5 times faster than the multilevel recursive bisection, and up to 150 times faster than multilevel spectral bisection. <p> The run time of our k-way partitioning algorithm is comparable to the run time of geometric recursive bisection algorithms [15, 34, 30, 29, 31] while it produces partitions that are generally 20% better <ref> [21] </ref>. <p> Figure 2 (b) shows the coarsened graph that results from the contraction of shaded vertices in Figure 2 (a). Numbers on the vertices and edges in Figure 2 (b) show their resulting weights. Maximal matchings can be computed in different ways <ref> [21, 22] </ref>. The method used to compute the matching greatly affects both the quality of the partition, and the time required during the uncoarsening phase. <p> In our partitioning algorithm, the k-way partition of G m is computed using our multilevel recursive bisection algorithm <ref> [21] </ref>. <p> This algorithm obtains speedup in the range of 25 to 40 on 128-processor CM5. Due to limited global matching and the absence of partition refinement, the orderings produced by this algorithm are worse than those produced by state-of-the-art multilevel ordering algorithms <ref> [21, 18, 10] </ref>. The speedup obtained by this algorithm are similar to those obtained by our algorithm, as the underlying communication in the coarsening phase is similar to that in the different phases of our algorithm. Barnard [1] has developed a parallel formulation of multilevel spectral algorithm. <p> Note that the coarsening scheme used in Barnard's algorithm can not be used in any multilevel graph partitioning algorithm <ref> [4, 16, 21, 22, 35] </ref>. The reason is that the coarsened graph of the multilevel spectral algorithms does not have enough information to enforce balance constraints and partition quality. <p> This decrease in partition quality is due to fact that pairwise partition refinement is not as effective as the coloring-based global refinement scheme used by our algorithm. Karypis and Kumar [23] present a parallel formulation of the serial multilevel recursive bisection algorithm <ref> [21] </ref> for graph partitioning and sparse matrix ordering. That algorithm uses a two-dimensional distribution of the graph to the processors and computes a local heavy-edge matching on the diagonal processors as discussed in Section 4. <p> For example, refinement algorithms that are able to climb out of local minima by performing some moves that do not decrease the edge-cut <ref> [16, 21] </ref> can be easily implemented using the techniques described in this paper. The performance achieved by our algorithm allows for the development of efficient and scalable parallel formulations for many diverse problems that utilize and operate on unstructured graphs.
Reference: [22] <author> G. Karypis and V. Kumar. </author> <title> Multilevel k-way partitioning scheme for irregular graphs. </title> <type> Technical Report TR 95-064, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/karypis/papers/mlevel kway.ps. </note>
Reference-contexts: Some of these multilevel schemes <ref> [4, 16, 21, 20, 22] </ref> provide excellent partitions for a wide variety of graphs. These schemes provide significantly better partitions than those provided by spectral partitioning techniques [33], and are generally at least an order of magnitude faster than even the state-of-the art implementation of spectral techniques [3]. <p> The Kernighan-Lin refinement heuristic and its variant, that are used during the uncoarsening phase, appear serial in nature [9], and previous attempts to parallelize them have had mixed success [9, 6, 23]. In this paper we present a parallel formulation for the multilevel k-way partitioning algorithm <ref> [22] </ref>. This formulation is also generally applicable to any multilevel graph partitioning algorithm that does coarsening of the graph and refines the partitions during the uncoarsening phase [21, 3]. <p> Section 4 2 details our parallel formulation of the multilevel k-way partitioning algorithm. Section 5 provides a theoretical perfor-mance and scalability analysis. Section 6 presents an experimental evaluation of the parallel algorithm and compares its performance to that of the serial algorithm. 2 Multilevel k -way Graph Partitioning In <ref> [22] </ref> we presented a k-way graph partitioning algorithm that is based on the multilevel paradigm, whose complexity is linear on the number of vertices in the graph. The basic structure of a multilevel algorithm is illustrated in Figure 1. <p> Since the finer graph has more degrees of freedom, such refinements improve the quality of the partitions. The experiments presented in <ref> [22] </ref> show that our algorithm produces partitions that are of comparable or better quality than those produced by the multilevel recursive bisection algorithm [21] and significantly better than those produced by the state-of-the art multilevel spectral bisection algorithm [3]. <p> In the rest of this section we briefly describe the various phases of the multilevel algorithm. The reader should refer to <ref> [22] </ref> for further details. 2.1 Coarsening Phase During the coarsening phase, a sequence of smaller graphs G i D .V i ; E i /, is constructed from the original graph G 0 D .V 0 ; E 0 / such that jV i j &gt; jV iC1 j. <p> Figure 2 (b) shows the coarsened graph that results from the contraction of shaded vertices in Figure 2 (a). Numbers on the vertices and edges in Figure 2 (b) show their resulting weights. Maximal matchings can be computed in different ways <ref> [21, 22] </ref>. The method used to compute the matching greatly affects both the quality of the partition, and the time required during the uncoarsening phase. <p> From Table 3, we see that the run times of the serial multilevel k-way partitioning algorithm increases as k increases. Since the asymptotic complexity of the serial algorithm is O.n/ <ref> [22] </ref>, this increase in run time is due to an increase in the number of interface vertices that exist as the number of partitions increases. Refining these interface vertices also leads to more work, but does not increase the asymptotic complexity of the algorithm. <p> Note that the coarsening scheme used in Barnard's algorithm can not be used in any multilevel graph partitioning algorithm <ref> [4, 16, 21, 22, 35] </ref>. The reason is that the coarsened graph of the multilevel spectral algorithms does not have enough information to enforce balance constraints and partition quality. <p> Furthermore, our algorithm is 25 to 30 times faster than the spectral algorithm, which is consistent with the serial computational requirements of the two algorithms. This difference in the edge-cuts of the two parallel formulations is similar to that for their serial counterparts <ref> [22] </ref>.
Reference: [23] <author> G. Karypis and V. Kumar. </author> <title> A parallel algorithms for multilevel graph partitioning and sparse matrix ordering. </title> <type> Technical Report TR 95-036, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/karypis/papers/mlevel parallel.ps. A short version appears in Intl. Parallel Processing Symposium 1996. </note>
Reference-contexts: Despite the small run time of multilevel schemes, it is important to develop highly parallel formulations of these schemes for reasons discussed in Section 3. Developing parallel graph partitioning algorithms has received a lot of attention <ref> [15, 35, 6, 19, 2, 1, 23] </ref> due to its extensive applications in many areas. However, most of this work was concentrated on algorithms based on geometric graph partitioning [15, 6], or algorithms that have very high computational requirements, such as spectral bisection [2, 1, 19]. <p> Development of formulations of multilevel graph partitioning schemes is quite challenging. Coarsening requires that nodes connected via edges be merged together. Since the graph is distributed randomly across the processors, parallel coarsening schemes can require a lot of communication <ref> [35, 1, 23] </ref>. The Kernighan-Lin refinement heuristic and its variant, that are used during the uncoarsening phase, appear serial in nature [9], and previous attempts to parallelize them have had mixed success [9, 6, 23]. In this paper we present a parallel formulation for the multilevel k-way partitioning algorithm [22]. <p> The Kernighan-Lin refinement heuristic and its variant, that are used during the uncoarsening phase, appear serial in nature [9], and previous attempts to parallelize them have had mixed success <ref> [9, 6, 23] </ref>. In this paper we present a parallel formulation for the multilevel k-way partitioning algorithm [22]. This formulation is also generally applicable to any multilevel graph partitioning algorithm that does coarsening of the graph and refines the partitions during the uncoarsening phase [21, 3]. <p> The reason is that even a random partition of a graph among a small number of processors can leave many connected components at each processor. Our earlier work on parallelizing the multilevel recursive bisection algorithm <ref> [23] </ref> used a two-dimensional distribution of the graph, which required the vertices of the graph to be partitioned only among p processors. Hence, this graph distribution allowed a moderate amount of coarsening even by using purely local match-ings. <p> This decrease in partition quality is due to fact that pairwise partition refinement is not as effective as the coloring-based global refinement scheme used by our algorithm. Karypis and Kumar <ref> [23] </ref> present a parallel formulation of the serial multilevel recursive bisection algorithm [21] for graph partitioning and sparse matrix ordering. That algorithm uses a two-dimensional distribution of the graph to the processors and computes a local heavy-edge matching on the diagonal processors as discussed in Section 4. <p> For a variety of problems, our parallel formulation of multilevel k-way partitioning presented in this paper is 3 to 4 times faster on a 128 processor Cray T3D, while the quality is better by about 5% to 10% compared with the formulation in <ref> [23] </ref>. This difference in run times for these parallel formulations is primarily because the algorithm in [23] does recursive bisection (requiring log p rounds of coarsening), and the algorithm in this paper does k-way partitioning (requiring only one coarsening phase). The edge-cuts produced by the parallel scheme in [23] are also <p> multilevel k-way partitioning presented in this paper is 3 to 4 times faster on a 128 processor Cray T3D, while the quality is better by about 5% to 10% compared with the formulation in <ref> [23] </ref>. This difference in run times for these parallel formulations is primarily because the algorithm in [23] does recursive bisection (requiring log p rounds of coarsening), and the algorithm in this paper does k-way partitioning (requiring only one coarsening phase). The edge-cuts produced by the parallel scheme in [23] are also somewhat worse because matching is limited to local vertices only. 8 Conclusion In this paper we <p> formulation in <ref> [23] </ref>. This difference in run times for these parallel formulations is primarily because the algorithm in [23] does recursive bisection (requiring log p rounds of coarsening), and the algorithm in this paper does k-way partitioning (requiring only one coarsening phase). The edge-cuts produced by the parallel scheme in [23] are also somewhat worse because matching is limited to local vertices only. 8 Conclusion In this paper we presented a scalable and highly parallel formulation of the multilevel k-way partitioning algorithm that is able to produce very good partitions of very large unstructured graphs in very small amount of time.
Reference: [24] <author> George Karypis. </author> <title> Graph Partitioning and Its Applications to Scientific Computing. </title> <type> PhD thesis, </type> <institution> University of Minnesota, Minneapolis, MN, </institution> <year> 1996. </year>
Reference-contexts: This also allows for the creation of highly parallel preconditioners for iterative methods based on domain decomposition as well as on incomplete factorizations <ref> [24] </ref>. Furthermore, adaptive finite element methods can now be effectively parallelized, since the mesh can be repartitioned on the fly very fast.
Reference: [25] <author> George Karypis and Vipin Kumar. </author> <title> Fast sparse Cholesky factorization on scalable parallel computers. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, MN, </institution> <year> 1994. </year> <note> A short version appears in the Eighth Symposium on the Frontiers of Massively Parallel Computation, 1995. Available on WWW at URL http://www.cs.umn.edu/karypis/papers/frontiers95.ps. </note>
Reference-contexts: Dynamic repartition of the corresponding vertex-weighted graph is crucial to balance the computation among processors. Furthermore, with recent development of highly parallel formulations of sparse Cholesky factorization algorithms <ref> [12, 25, 11, 36] </ref>, numeric factorization on parallel computers can take much less time than the step for computing a fill-reducing ordering on a serial computer, making that the new bottleneck. <p> For example, on a 1024-processor Cray T3D, some matrices can be factored in less that two seconds using our parallel sparse Cholesky factorization algorithm <ref> [25] </ref>, but serial graph partitioning (needed for computing a fill-reducing ordering) takes two orders of magnitude more time. 4 Parallel Formulation Developing a highly parallel formulation for the multilevel k-way partitioning algorithm is particularly difficult because both the task of computing a maximal matching during the coarsening phase, and the task
Reference: [26] <author> B. W. Kernighan and S. Lin. </author> <title> An efficient heuristic procedure for partitioning graphs. </title> <journal> The Bell System Technical Journal, </journal> <year> 1970. </year>
Reference-contexts: The multilevel k-way partitioning algorithm is based on a simplified version of the Kernighan-Lin <ref> [26] </ref> algorithm, extended to provide k-way partition refinement. This algorithm, is called greedy refinement (GR). Its complexity is largely independent of the number of partitions being refined.
Reference: [27] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis. </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms. </title> <publisher> Benjamin/Cummings Publishing Company, </publisher> <address> Redwood City, CA, </address> <year> 1994. </year>
Reference-contexts: A key step in each iteration of these methods is the multiplication of a sparse matrix and a (dense) vector. A good partition of the graph corresponding to matrix A can significantly reduce the amount of communication in parallel sparse matrix-vector multiplication <ref> [27] </ref>. The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. <p> Nevertheless, in our algorithm we also parallelize this phase by using a parallel algorithm that parallelizes the recursive nature of the algorithm. This is done as follows: The various pieces of the coarse graph are gathered to all the processors using an all-to-all broadcast operation <ref> [27] </ref>. At this point the processors perform recursive bisection using an algorithm that is based on nested dissection [8] and greedy partition refinement. However, as illustrated in Figure 3, each processor explores only a single path of the recursive bisection tree. <p> Of course, all the vertices are moved to their proper location at the end of the partitioning algorithm, using a single all-to-all personalized communication <ref> [27] </ref>. The balance conditions are maintained as follows. Initially, each processor knows the weights of all p partitions. During each refinement sub-phase, each processor enforces balance constraints based on these partition weights. For every vertex it decides to moves it locally updates these weights. <p> Hence, each processor needs to exchange data with O.n= p 2 / vertices of each processor. Alternatively, each processor needs to send information for about O.n= p 2 / locally stored vertices to each other processor. This can be accomplished by using the all-to-all personalized communication operation <ref> [27] </ref>, whose complexity is O.n= p/ C O. p/. The communication complexity over all O.log n/ coarsening levels, is T comm D O p C O. p log n/; (2) since the size of the graph is successively halved. <p> In addition to the communication of the interface vertices, both matching and refinement perform additional communication. During matching, a prefix-sum is performed to determine the numbering of the vertices in the coarser graph. The complexity of this operation over all O.log n/ coarsening levels is O.log p log n/ <ref> [27] </ref>. During refinement, a reduction of a p-vector is performed to compute the weights of the partitions. Since the size of the vector is equal to p, each such reduction can be done in O. p/ time [27]. <p> this operation over all O.log n/ coarsening levels is O.log p log n/ <ref> [27] </ref>. During refinement, a reduction of a p-vector is performed to compute the weights of the partitions. Since the size of the vector is equal to p, each such reduction can be done in O. p/ time [27]. Thus, the complexity over the all O.log n/ coarsening levels is O. p log n/. Finally, all four algorithms require global synchronizations, whose complexity is O.log p log n/. <p> During the initial partitioning phase, a graph of size O. p/ is partitioned into p partitions using recursive bisection. As described in Section 4.3, the graph is gathered on each processor using an all-to-all broadcast operation <ref> [27] </ref>, whose complexity is O. p/. After that each processor performs recursive bisection, but only keeps one of the two bisections. Thus, the computational complexity of the initial partition is O. p/. <p> Assuming that the graph is randomly distributed among the processors, this permutation is equivalent to an all-to-all personalized communication of the original graph. The run time of this communication operation is O.n= p/ C O. p/ <ref> [27] </ref>. Thus, the run time of our parallel graph partitioning algorithm is only slightly higher (by a factor of O.log n/ in the second term of Equation 3) than this absolute lower bound. Finally, since the sequential complexity of the serial algorithm is O.n/, the isoefficiency function [27] of our algorithm <p> C O. p/ <ref> [27] </ref>. Thus, the run time of our parallel graph partitioning algorithm is only slightly higher (by a factor of O.log n/ in the second term of Equation 3) than this absolute lower bound. Finally, since the sequential complexity of the serial algorithm is O.n/, the isoefficiency function [27] of our algorithm is O. p 2 log p/. 6 Experimental Results We evaluated the performance of our parallel multilevel k-way graph partitioning algorithm on a wide range of graphs arising in different application domains. The characteristics of these graphs are described in Table 1. <p> From the analysis in Section 5, we have shown that the isoefficiency function of our parallel algorithm is O. p 2 log p/. That is, in order to maintain a fixed efficiency, the graph size should increase as O. p 2 log p/ <ref> [27] </ref>. For example, if we double the number of processors, then we need to increase the size of the graph by a factor little over 4 in order to achieve the same efficiency.
Reference: [28] <author> Michael Luby. </author> <title> A simple parallel algorithm for the maximal independent set problem. </title> <journal> SIAM Journal on Computing, </journal> <volume> 15(4) </volume> <pages> 1036-1053, </pages> <year> 1986. </year>
Reference-contexts: We like to find a coloring such that the number of distinct colors used is small. Our parallel graph coloring algorithm con 7 sists of a number of iterations. In each iteration, a maximal independent set of vertices I is selected using a variation of Luby's <ref> [28] </ref> algorithm. All vertices in this independent set are assigned the same color. Before the next iteration begins, the vertices in I are removed from the graph, and this smaller graph becomes the input graph for the next iteration. <p> Now this process is repeated for the vertices in S that are neither in I nor adjacent to vertices in I , and I is augmented similarly. This incremental augmentation of I ends when no more vertices can be inserted in I . It is shown in <ref> [28] </ref> that one iteration of Luby's algorithm requires a total of O.log jSj/ such augmentation steps to find a maximal independent set of a set S. In our implementation of Luby's algorithm, we perform only a single augmentation step to compute the independent set during each iteration. <p> Barnard [1] has developed a parallel formulation of multilevel spectral algorithm. This algorithm uses a one-dimensional mapping of the graph to the processors and uses a parallel formulation of Luby's <ref> [28] </ref> algorithm to compute a maximal independent set of vertices to construct the next level coarser graph. Note that the coarsening scheme used in Barnard's algorithm can not be used in any multilevel graph partitioning algorithm [4, 16, 21, 22, 35].
Reference: [29] <author> Gary L. Miller, Shang-Hua Teng, W. Thurston, and Stephen A. Vavasis. </author> <title> Automatic mesh partitioning. </title> <editor> In A. George, John R. Gilbert, and J. W.-H. Liu, editors, </editor> <title> Sparse Matrix Computations: Graph Theory Issues and Algorithms. (An IMA Workshop Volume). </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: Furthermore, our k-way partitioning algorithm is up to 5 times faster than the multilevel recursive bisection, and up to 150 times faster than multilevel spectral bisection. The run time of our k-way partitioning algorithm is comparable to the run time of geometric recursive bisection algorithms <ref> [15, 34, 30, 29, 31] </ref> while it produces partitions that are generally 20% better [21].
Reference: [30] <author> Gary L. Miller, Shang-Hua Teng, and Stephen A. Vavasis. </author> <title> A unified geometric approach to graph separators. </title> <booktitle> In Proceedings of 31st Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 538-547, </pages> <year> 1991. </year>
Reference-contexts: Furthermore, our k-way partitioning algorithm is up to 5 times faster than the multilevel recursive bisection, and up to 150 times faster than multilevel spectral bisection. The run time of our k-way partitioning algorithm is comparable to the run time of geometric recursive bisection algorithms <ref> [15, 34, 30, 29, 31] </ref> while it produces partitions that are generally 20% better [21].
Reference: [31] <author> B. Nour-Omid, A. Raefsky, and G. Lyzenga. </author> <title> Solving finite element equations on concurrent computers. </title> <editor> In A. K. Noor, editor, </editor> <publisher> American Soc. Mech. Eng, </publisher> <pages> pages 291-307, </pages> <year> 1986. </year>
Reference-contexts: Furthermore, our k-way partitioning algorithm is up to 5 times faster than the multilevel recursive bisection, and up to 150 times faster than multilevel spectral bisection. The run time of our k-way partitioning algorithm is comparable to the run time of geometric recursive bisection algorithms <ref> [15, 34, 30, 29, 31] </ref> while it produces partitions that are generally 20% better [21]. <p> Diniz et al., [6] present a parallel formulation of the inertial algorithm <ref> [31] </ref> for partitioning. This algorithm computes a k-way partition using inertial recursive bisection (which is naturally parallel), and then does pairwise partition refinement using the Kernighan-Lin heuristic as described in Section 4.
Reference: [32] <author> R. Ponnusamy, N. Mansour, A. Choudhary, and G. C. Fox. </author> <title> Graph contraction and physical optimization methods: a quality-cost tradeoff for mapping data on parallel computers. </title> <booktitle> In International Conference of Supercomputing, </booktitle> <year> 1993. </year>
Reference-contexts: The graph partitioning problem is NP-complete. However, many algorithms have been developed that find a reasonably good partition. Recently, a number of researchers have investigated a class of algorithms that are based on multilevel graph partitioning that have moderate computational complexity <ref> [4, 5, 13, 14, 16, 7, 32, 21, 20] </ref>.
Reference: [33] <author> Alex Pothen, Horst D. Simon, and Kang-Pu Liou. </author> <title> Partitioning sparse matrices with eigenvectors of graphs. </title> <journal> SIAM Journal of Matrix Analysis and Applications, </journal> <volume> 11(3) </volume> <pages> 430-452, </pages> <year> 1990. </year>
Reference-contexts: Some of these multilevel schemes [4, 16, 21, 20, 22] provide excellent partitions for a wide variety of graphs. These schemes provide significantly better partitions than those provided by spectral partitioning techniques <ref> [33] </ref>, and are generally at least an order of magnitude faster than even the state-of-the art implementation of spectral techniques [3]. Despite the small run time of multilevel schemes, it is important to develop highly parallel formulations of these schemes for reasons discussed in Section 3.
Reference: [34] <author> P. Raghavan. </author> <title> Line and plane separators. </title> <type> Technical Report UIUCDCS-R-93-1794, </type> <institution> Department of Computer Science, University of Illinois, Urbana, </institution> <address> IL 61801, </address> <month> February </month> <year> 1993. </year>
Reference-contexts: Furthermore, our k-way partitioning algorithm is up to 5 times faster than the multilevel recursive bisection, and up to 150 times faster than multilevel spectral bisection. The run time of our k-way partitioning algorithm is comparable to the run time of geometric recursive bisection algorithms <ref> [15, 34, 30, 29, 31] </ref> while it produces partitions that are generally 20% better [21].
Reference: [35] <author> Padma Raghavan. </author> <title> Parallel ordering using edge contraction. </title> <type> Technical Report CS-95-293, </type> <institution> Department of Computer Science, University of Tennessee, </institution> <year> 1995. </year>
Reference-contexts: Despite the small run time of multilevel schemes, it is important to develop highly parallel formulations of these schemes for reasons discussed in Section 3. Developing parallel graph partitioning algorithms has received a lot of attention <ref> [15, 35, 6, 19, 2, 1, 23] </ref> due to its extensive applications in many areas. However, most of this work was concentrated on algorithms based on geometric graph partitioning [15, 6], or algorithms that have very high computational requirements, such as spectral bisection [2, 1, 19]. <p> Development of formulations of multilevel graph partitioning schemes is quite challenging. Coarsening requires that nodes connected via edges be merged together. Since the graph is distributed randomly across the processors, parallel coarsening schemes can require a lot of communication <ref> [35, 1, 23] </ref>. The Kernighan-Lin refinement heuristic and its variant, that are used during the uncoarsening phase, appear serial in nature [9], and previous attempts to parallelize them have had mixed success [9, 6, 23]. In this paper we present a parallel formulation for the multilevel k-way partitioning algorithm [22]. <p> In this case, the improvements are not as dramatic (somewhere between 27% and 40% on 16 processors). This is because, during k-way refinement only a few vertices get moved; hence, there is limited cache reuse. 7 Related Work Raghavan <ref> [35] </ref> presents a parallel formulation of a nested dissection ordering algorithm that is based on multilevel graph partitioning. Raghavan's parallel algorithm uses one-dimensional partitioning of the graphs and construct successive coarser graphs by computing matchings between different pairs of processors at each coarsening level. <p> Note that the coarsening scheme used in Barnard's algorithm can not be used in any multilevel graph partitioning algorithm <ref> [4, 16, 21, 22, 35] </ref>. The reason is that the coarsened graph of the multilevel spectral algorithms does not have enough information to enforce balance constraints and partition quality.
Reference: [36] <author> Edward Rothberg. </author> <title> Performance of panel and block approaches to sparse Cholesky factorization on the iPSC/860 and Paragon multicomputers. </title> <booktitle> In Proceedings of the 1994 Scalable High Performance Computing Conference, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: Dynamic repartition of the corresponding vertex-weighted graph is crucial to balance the computation among processors. Furthermore, with recent development of highly parallel formulations of sparse Cholesky factorization algorithms <ref> [12, 25, 11, 36] </ref>, numeric factorization on parallel computers can take much less time than the step for computing a fill-reducing ordering on a serial computer, making that the new bottleneck.
Reference: [37] <author> Yousef Saad. </author> <title> Iterative Methods for Sparse Linear Systems. </title> <publisher> PWS Publishing, </publisher> <address> Boston, MA, </address> <year> 1996. </year>
Reference-contexts: The performance achieved by our algorithm allows for the development of efficient and scalable parallel formulations for many diverse problems that utilize and operate on unstructured graphs. The domain decomposition techniques used extensively in scientific computing <ref> [37] </ref> can be completely parallelized, removing the computational bottleneck created by serial domain decomposition prior to parallel computation. This also allows for the creation of highly parallel preconditioners for iterative methods based on domain decomposition as well as on incomplete factorizations [24].
Reference: [38] <author> Ravi V. Shankar and Sanjay Ranka. </author> <title> Random data accesses on coarse-grained parallel machine. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <note> 1995. To appear. 21 </note>
Reference-contexts: Note that for Equation 2 to be valid, the data to be communicated among processor must be roughly equally distributed. Since the graph is randomly distributed, this is a reasonable assumption (otherwise, a somewhat more expensive generalized all-to-all personalized communication <ref> [38] </ref> is needed). Furthermore, for the successive coarser graphs, the graphs also remains randomly distributed because during matching, decisions regarding where the contracted vertex will reside is done randomly. In addition to the communication of the interface vertices, both matching and refinement perform additional communication.
References-found: 38

