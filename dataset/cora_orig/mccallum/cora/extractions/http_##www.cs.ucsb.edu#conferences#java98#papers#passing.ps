URL: http://www.cs.ucsb.edu/conferences/java98/papers/passing.ps
Refering-URL: http://www.cs.ucsb.edu/conferences/java98/program.html
Root-URL: http://www.cs.ucsb.edu
Email: (yalamanc,cohen)@ece.uah.edu  
Title: Communication Performance of Java based Parallel Virtual Machines  
Author: Narendar Yalamanchilli and William Cohen 
Date: February 7, 1998  
Address: Huntsville, AL 35899, USA  
Affiliation: Department of Electrical and Computer Engineering University of Alabama in Huntsville,  
Abstract: Message passing libraries such as Parallel Virtual Machine (PVM) and Message Passing Interface (MPI) provide a common Application Programming Interface (API) to implement parallel programs across multiple computers. Such libraries provide a means to program a collection of normally independent computers to work cooperatively on a single computation. However, for programs written in C and Fortran these collections of machines may provide a heterogenous set of computer architectures, requiring a different executable for each type of architecture. The Java language offers a potentially machine-independent method of distributing the same code to perform the computations on different computer architectures. The communication performance between processors running Java programs is a crucial issue for this type of application. This paper compares the performance between tradition PVM implemented in C code, Java code interfaced to the traditional PVM libraries (JavaPVM), and Java code that performs functions equivalent to the traditional PVM library (JPVM). The Java implementations are slower, but performance improvements are possible.
Abstract-found: 1
Intro-found: 1
Reference: [DH95] <author> Jack Dongarra and Tony Hey. </author> <title> The ParkBench Benchmark Collection, </title> <month> November </month> <year> 1995. </year> <note> URL: http://parallel.rz.uni-mannheim.de/top500/reports/report94/benrep3/benrep3.html. 4 </note>
Reference-contexts: JPVM makes use of the socket interface in the standard API for communication between these parallel units. The Java standards for data formats and built-in parallel programming constructs of Java dramatically simplify the implementation of this communication library. 5 Communication Benchmark The COMMS1 <ref> [DH95] </ref> or ping-pong benchmark was used to measure the basic communication performance of the three PVM software packages.
Reference: [Fer96] <author> Adam J. Ferrari. JPVM: </author> <title> The Java Parallel Virtual Machine, </title> <month> June </month> <year> 1996. </year> <note> URL: http://www.cs.virginia.edu/ ajf2j/jpvm.html. </note>
Reference-contexts: In an effort to leverage existing message passing programs, Java classes similar to PVM have been implemented. This paper will examine the performance of two of these PVM-like libraries, JavaPVM [Thu96] and JPVM <ref> [Fer96, Fer97] </ref>, against the native C implementation of PVM. The gathered data is useful for implementors of communication libraries to determine areas of improvement and is useful for application programmer to determine whether it is profitable to parallelize certain sections of their program. <p> PVM would allow communication between the different languages. Thus, JavaPVM would allow programmers to reuse existing code on some processors and not force the programmer to switch all the code to Java. 4 JPVM JPVM <ref> [Fer96, Fer97] </ref> differs from PVM and JavaPVM; it is implemented entirely in Java and uses none of the original PVM code. Unlike JavaPVM, JPVM is not inter-operable with standard PVM. JPVM provides a Java implementation of the PVM daemon (pvmd) and a library for communication.
Reference: [Fer97] <author> JPVM: </author> <title> Network Parallel Computing in Java. </title> <type> Technical Report CS-97-29, Uni. </type> <institution> of Virginia, Char-lottesville, Virginia, </institution> <month> December </month> <year> 1997. </year>
Reference-contexts: In an effort to leverage existing message passing programs, Java classes similar to PVM have been implemented. This paper will examine the performance of two of these PVM-like libraries, JavaPVM [Thu96] and JPVM <ref> [Fer96, Fer97] </ref>, against the native C implementation of PVM. The gathered data is useful for implementors of communication libraries to determine areas of improvement and is useful for application programmer to determine whether it is profitable to parallelize certain sections of their program. <p> PVM would allow communication between the different languages. Thus, JavaPVM would allow programmers to reuse existing code on some processors and not force the programmer to switch all the code to Java. 4 JPVM JPVM <ref> [Fer96, Fer97] </ref> differs from PVM and JavaPVM; it is implemented entirely in Java and uses none of the original PVM code. Unlike JavaPVM, JPVM is not inter-operable with standard PVM. JPVM provides a Java implementation of the PVM daemon (pvmd) and a library for communication.
Reference: [GBJ + 94] <author> A. Geist, A. Beguelin, J.Dongarra, W. Jiang, R.Manchek, and V. Sunderam. </author> <title> PVM: Parallel Virtual Machine A Users' Guide and Tutorial for Networked Parallel Computing Scientific and Engineering Series. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: 1 Introduction The message passing model, which exchanges data between individual processors with explicit message transmission and reception, has been attractive to parallel application developers because libraries such as the Parallel Virtual Machine (PVM) <ref> [GBJ + 94] </ref> and the Message Passing Interface (MPI) [MPI94] allow existing clusters of workstations to be used in a cooperative manner to solve a single problem. However, there have been two impediments to writing parallel programs using these libraries: heterogenous processor architectures and interprocessor communication performance. <p> A description of PVM, JavaPVM and JPVM are given in sections 2, 3, and 4, respectively. The test conditions and results are given in section 5. The performances of the message passing libraries are analyzed in section 6. Finally, the results are summarized in section 7. 2 PVM PVM <ref> [GBJ + 94] </ref> is a message passing system that connects a heterogeneous collection of computers running the software into one large distributed memory computer. Thus, PVM provides the capability to solve computationally intensive problems by using the aggregate memory and computing power of many computers.
Reference: [GJS96] <author> J. Gosling, B. Joy, and G. Steel. </author> <title> The Java Language Specification. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts, </address> <year> 1996. </year>
Reference-contexts: The generation of multiple executables leads to problems ensuring that the multiple versions are available to all machines and that each machine obtains the correct version of the code. The object-oriented programming language Java <ref> [GJS96] </ref> may provide some relief from this problem. Rather than compiling Java code to a specific processor instruction set, it is compiled into code for the Java Virtual Machine (JVM) [LY97], an abstract instruction set, and this code is distributed to the processors.
Reference: [HCJ + 97] <author> C.-H. A. Hsieh, M. T. Conte, T. L. Johson, J. C. Gyllenhall, and W.-M. W. Hwu. </author> <title> A Study of the Cache and Branch Performance Issues with Running Java on Current Hardware Platforms. </title> <booktitle> In Proceedings of IEEE CompCon '97, </booktitle> <address> San Jose, California, </address> <month> February </month> <year> 1997. </year>
Reference-contexts: Thus, the dynamic creation and removal of objects in JPVM can create additional overhead. * The way that Java I/O is implemented was found to be a major source of overhead in some bench marks <ref> [HCJ + 97] </ref>. JPVM make heavy use of the sockets implemented in the Java I/O library. 7 Conclusion Due to the better communication performance of JavaPVM over JPVM, JavaPVM is currently a better choice for running communication intensive Java applications.
Reference: [HGH96] <author> C.-H. A. Hsieh, J. C. Gyllenhall, and W.-M. W. Hwu. </author> <title> Java Bytecode to Native Code Translation: The Caffeine Prototype and Preliminary Results. </title> <booktitle> In Proceedings of the 29th Annual International Symposium on Microarchitecture, </booktitle> <address> Paris, France, </address> <month> December </month> <year> 1996. </year>
Reference-contexts: The Just-In-Time (JIT) compilers that translate the Java Virtual Machine code into native instructions have made significant strides to improve performance, and Java programs have been estimated of being able to obtain 68% of the speed of traditional C code <ref> [HGH96] </ref>. Thus, Java may provide a viable environment for high-performance programming. 1 The performance of a parallel program is also influenced by the speed that data can be exchanged between the processors performing the computations. The Java programs communicate between independent machines based on a message passing model.
Reference: [LY97] <author> T. Lindholm and F. Yellin. </author> <title> The Java Virtual Machine Specification. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts, </address> <year> 1997. </year>
Reference-contexts: The object-oriented programming language Java [GJS96] may provide some relief from this problem. Rather than compiling Java code to a specific processor instruction set, it is compiled into code for the Java Virtual Machine (JVM) <ref> [LY97] </ref>, an abstract instruction set, and this code is distributed to the processors. The machines that obtain the code in this format can either use an interpreter or can perform another compilation step to generate native code.
Reference: [MPI94] <author> MPI: </author> <title> A Message-Passing Interface Standard. </title> <type> Technical Report us-cs-94-230, Uni. </type> <institution> of Tennessee, Knoxville, Tennessee, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: 1 Introduction The message passing model, which exchanges data between individual processors with explicit message transmission and reception, has been attractive to parallel application developers because libraries such as the Parallel Virtual Machine (PVM) [GBJ + 94] and the Message Passing Interface (MPI) <ref> [MPI94] </ref> allow existing clusters of workstations to be used in a cooperative manner to solve a single problem. However, there have been two impediments to writing parallel programs using these libraries: heterogenous processor architectures and interprocessor communication performance.
Reference: [Thu96] <author> David A. Thurman. JavaPVM: </author> <title> The Java to PVM Interface, </title> <month> December </month> <year> 1996. </year> <note> URL: http://www.isye.gatech.edu/chmsr/JavaPVM/. 5 </note>
Reference-contexts: In an effort to leverage existing message passing programs, Java classes similar to PVM have been implemented. This paper will examine the performance of two of these PVM-like libraries, JavaPVM <ref> [Thu96] </ref> and JPVM [Fer96, Fer97], against the native C implementation of PVM. The gathered data is useful for implementors of communication libraries to determine areas of improvement and is useful for application programmer to determine whether it is profitable to parallelize certain sections of their program. <p> These interface routines allow the creation and termination of tasks across heterogeneous clusters of computers as well as communication and synchronization between tasks. The PVM libraries, including the ones used for these experiments, are written in C and must be compiled for each machine architecture. 3 JavaPVM JavaPVM <ref> [Thu96] </ref> is layered upon the standard distribution of PVM and makes use of Java's capability to call functions written in other languages. The functions written in languages other than Java and called from Java are known as native methods.
References-found: 10

