URL: http://www.cs.umd.edu/~rich/courses/cmsc818G-s98/papers/liu_optimal.ps
Refering-URL: http://www.cs.umd.edu/~rich/courses/cmsc818G-s98/resources.html
Root-URL: 
Email: tia@cs.uiuc.edu  
Title: Algorithms and Optimality of Scheduling Soft Aperiodic Requests in Fixed-Priority Preemptive Systems  
Author: TOO-SENG TIA, JANE W.-S. LIU AND MALLIKARJUN SHANKAR 
Keyword: scheduling, aperiodic, fixed-priority, optimality  
Address: Urbana, IL 61801  
Affiliation: Department of Computer Science, University of Illinois at Urbana-Champaign,  
Note: To appear in The Journal of Real-Time Systems, 1-21 c Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Abstract: In this paper, we investigate the problem of scheduling soft aperiodic requests in systems where periodic tasks are scheduled on a fixed-priority, preemptive basis. First, we show that given any queueing discipline for the aperiodic requests, no scheduling algorithm can minimize the response time of every aperiodic request and guarantee that the deadlines of the periodic tasks are met when the periodic tasks are scheduled on a fixed-priority, preemptive basis. We then develop two algorithms: Algorithm L is locally optimal in that it minimizes the response time of the aperiodic request at the head of the aperiodic service queue. Algorithm G is globally optimal in that it completes the current backlog of work in the aperiodic service queue as early as possible. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> C. L. Liu and J. W. Layland, </author> <title> "Scheduling Algorithms for Multiprogramming in a Hard Real Time Environment," </title> <journal> in J. Assoc. Comput. Mach., </journal> <volume> vol. 20(1), </volume> <pages> pp. 46-61, </pages> <year> 1973. </year>
Reference-contexts: Fixed-priority preemptive scheduling of periodic tasks, such as the rate-monotonic or the deadline-monotonic approach, has gained popularity in recent years as it provides a sound theoretical basis for designing predictable real-time systems <ref> [1] </ref>, [2]. Several algorithms have been proposed to integrate the scheduling of aperiodic requests within such a framework. These algorithms can be classified into the following two categories: 1. Bandwidth preserving server algorithms include the priority-exchange server [3], deferrable server [4], and sporadic server [5].
Reference: 2. <author> J. Lehoczhy, L. Sha, and Y. Ding, </author> <title> "The Rate Monotonic Scheduling Algorithm Exact Characterization and Average Case Behavior," </title> <booktitle> in Proceedings of the Real-Time System Symposium, </booktitle> <pages> pp. 166-171, </pages> <year> 1989. </year>
Reference-contexts: Fixed-priority preemptive scheduling of periodic tasks, such as the rate-monotonic or the deadline-monotonic approach, has gained popularity in recent years as it provides a sound theoretical basis for designing predictable real-time systems [1], <ref> [2] </ref>. Several algorithms have been proposed to integrate the scheduling of aperiodic requests within such a framework. These algorithms can be classified into the following two categories: 1. Bandwidth preserving server algorithms include the priority-exchange server [3], deferrable server [4], and sporadic server [5].
Reference: 3. <author> B. Sprunt, J. P. Lehoczky, and L. Sha, </author> <title> "Exploiting Unused Periodic Time for Aperiodic Service Using the Extended Priority Exchange Algorithm," </title> <booktitle> in Proceedings of the Real-Time System Symposium, </booktitle> <pages> pp. 251-258, </pages> <year> 1988. </year>
Reference-contexts: Several algorithms have been proposed to integrate the scheduling of aperiodic requests within such a framework. These algorithms can be classified into the following two categories: 1. Bandwidth preserving server algorithms include the priority-exchange server <ref> [3] </ref>, deferrable server [4], and sporadic server [5]. A server is a periodic task with an execution capacity. The capacity, which is set as large as possible without affecting the schedulability of the periodic tasks, is used to execute aperiodic requests. <p> However, due to the fact that T 1;2 is ready at time 3, has a priority higher than T 2;1 and cannot possibly complete before time 4 (since c 1 = 1), T 2;1 cannot be scheduled during the SCHEDULING SOFT APERIODIC REQUESTS 9 interval <ref> [3; 4] </ref> according to the fixed-priority rule of the algorithm. Hence it must be completed by time 3, i.e., e 2;1 = 3. The effective deadlines of all the periodic requests can be determined by constructing the schedule of periodic tasks for a hyperperiod.
Reference: 4. <author> J. P. Lehoczky, L. Sha, and J. K. Strosnider, </author> <title> "Enhanced Aperiodic Scheduling in Hard-Real-Time Environments," </title> <booktitle> in Proceedings of the Real-Time System Symposium, </booktitle> <pages> pp. 261-270, </pages> <month> Dec. </month> <year> 1987. </year>
Reference-contexts: Several algorithms have been proposed to integrate the scheduling of aperiodic requests within such a framework. These algorithms can be classified into the following two categories: 1. Bandwidth preserving server algorithms include the priority-exchange server [3], deferrable server <ref> [4] </ref>, and sporadic server [5]. A server is a periodic task with an execution capacity. The capacity, which is set as large as possible without affecting the schedulability of the periodic tasks, is used to execute aperiodic requests. <p> However, due to the fact that T 1;2 is ready at time 3, has a priority higher than T 2;1 and cannot possibly complete before time 4 (since c 1 = 1), T 2;1 cannot be scheduled during the SCHEDULING SOFT APERIODIC REQUESTS 9 interval <ref> [3; 4] </ref> according to the fixed-priority rule of the algorithm. Hence it must be completed by time 3, i.e., e 2;1 = 3. The effective deadlines of all the periodic requests can be determined by constructing the schedule of periodic tasks for a hyperperiod.
Reference: 5. <author> B. Sprunt, L. Sha, and J. P. Lehoczky, </author> <title> "Aperiodic Task Scheduling for Hard Real-Time Systems," </title> <journal> The Journal of Real-Time Systems, </journal> <volume> vol. 1, </volume> <pages> pp. 27-60, </pages> <year> 1989. </year>
Reference-contexts: Several algorithms have been proposed to integrate the scheduling of aperiodic requests within such a framework. These algorithms can be classified into the following two categories: 1. Bandwidth preserving server algorithms include the priority-exchange server [3], deferrable server [4], and sporadic server <ref> [5] </ref>. A server is a periodic task with an execution capacity. The capacity, which is set as large as possible without affecting the schedulability of the periodic tasks, is used to execute aperiodic requests.
Reference: 6. <author> J. P. Lehoczky and S. Ramos-Thuel, </author> <title> "An Optimal Algorithm for Scheduling Soft-Aperiodic Tasks in Fixed-Priority Preemptive Systems," </title> <booktitle> in Proceedings of the Real-Time System Symposium, </booktitle> <pages> pp. 110-123, </pages> <year> 1992. </year>
Reference-contexts: The amount of slack time during a time interval [t 1 ; t 2 ] is equal to the amount of time that can be used to execute aperiodic requests without causing any periodic request to miss its deadline. Several slack stealing algorithms have been proposed <ref> [6] </ref>, [7], [8]. All the previous slack stealing algorithms [6], [7], [8] are greedy: whenever there is slack available, a greedy algorithm schedules soft aperiodic requests at the highest priority level so that they can make use of the slack immediately to minimize their response times. <p> Several slack stealing algorithms have been proposed <ref> [6] </ref>, [7], [8]. All the previous slack stealing algorithms [6], [7], [8] are greedy: whenever there is slack available, a greedy algorithm schedules soft aperiodic requests at the highest priority level so that they can make use of the slack immediately to minimize their response times. These algorithms were shown to be optimal among all greedy algorithms. <p> We will show in the next section that even a clairvoyant algorithm (i.e. one with a priori knowledge of future aperiodic requests) cannot be strongly optimal. Hence, contrary to the claims in <ref> [6] </ref>, [8] that their algorithms are optimal among all algorithms using the FIFO queueing discipline, their algorithms are not optimal. <p> A locally optimal algorithm is a valid algorithm which, among all valid algorithms, yields the minimal response time for the aperiodic request at the head of the aperiodic service queue. As in <ref> [6] </ref>, [8], we assume that overhead for context switching, task scheduling and delay in preemption are negligibly small compared with computation times of the tasks. Requests in periodic tasks are ready at the start of their periods and do not suspend themselves or synchronize with other tasks. <p> Hence, without a priori knowledge of the aperiodic requests, an on-line algorithm will not know whether to schedule each aperiodic request as soon as possible so as to minimize the average response time. We now show that the greedy slack stealing algorithms in <ref> [6] </ref>, [8] may not give the minimal response time for a single aperiodic request. To do so, we consider again the periodic tasks in Figure 1 and suppose that an aperiodic request J 1 arrives at time 2. <p> For this example, the algorithms in <ref> [6] </ref>, [8] would have produced schedule A. J 1 's response time would not be minimal if its computation time lies within the range (1; 2]. We will show in Section 5 how our proposed algorithm can correctly schedule J 1 . <p> J 1 's response time would not be minimal if its computation time lies within the range (1; 2]. We will show in Section 5 how our proposed algorithm can correctly schedule J 1 . The main flaw in the proofs of the algorithms' optimality in <ref> [6] </ref>, [8] lies in the assertion that given any two time instants t 1 and t 2 , the amount of time available for executing aperiodic requests in the interval [t 1 ; t 2 ] cannot exceed the slack given by their slack computations. <p> For the above example, their algorithms determine at time 2 that the amount of slack time in time interval <ref> [0; 6] </ref> is 1. Only this amount is available if the slack is used at time 2. On the other hand, the conclusion that the amount of slack time in [0; 6] can never be more than 1 is not true as evident from schedule B in Figure 5. 4. <p> For the above example, their algorithms determine at time 2 that the amount of slack time in time interval <ref> [0; 6] </ref> is 1. Only this amount is available if the slack is used at time 2. On the other hand, the conclusion that the amount of slack time in [0; 6] can never be more than 1 is not true as evident from schedule B in Figure 5. 4. <p> Two methods of computing the slack function, which gives the amount of slack available within an interval [t 1 ; t 2 ], have been proposed; the static method in <ref> [6] </ref> and the dynamic method in [8]. Either of these methods can be used in our algorithms to determine the amount of slack. As stated earlier, the major difference between our algorithms and the algorithms in [6], [8] is that the latter are greedy slack stealing algorithms. <p> interval [t 1 ; t 2 ], have been proposed; the static method in <ref> [6] </ref> and the dynamic method in [8]. Either of these methods can be used in our algorithms to determine the amount of slack. As stated earlier, the major difference between our algorithms and the algorithms in [6], [8] is that the latter are greedy slack stealing algorithms. They schedule a ready aperiodic request J m at the highest priority whenever the value of the slack function is not zero. <p> LIU AND M. SHANKAR of the aperiodic request at the head of the aperiodic service queue is not necessarily the highest when the value is not zero. We will elaborate on this point in the next section when we describe our algorithms. Existing Methods According to the static method <ref> [6] </ref>, the amount of slack available before the deadline of all periodic requests over the hyperperiod is precomputed and stored in a table. During run-time, these values are used to compute the actual amount of slack time available. The values are updated at the completion of each periodic request. <p> The amount of computation needed to compute the current available slack from the table is O (n), where n is the number of periodic tasks. The amount of computation needed to update the table after the completion of each periodic request is O (n) as given in <ref> [6] </ref>. However, we will show later that this update can be reduced to O (1). According to the dynamic method [8], whenever there is an aperiodic request to be scheduled, the algorithm computes the amount of slack available for the current request of each periodic task. <p> Our Static Method We now present the method that our algorithms use to compute and update the available slack. This method generally resembles the static method in <ref> [6] </ref> but is more efficient. It uses the effective deadlines of periodic requests. The effective deadline, denoted by e i;j , of a periodic request T i;j , is the latest time by which T i;j must complete. <p> Following <ref> [6] </ref>, we call the amount of time which 10 T.-S. TIA, JANE W.-S. LIU AND M. <p> By updating C i , we need only perform a O (1) computation after the completion of a periodic request. In contrast, the method given in <ref> [6] </ref> updates a quantity similar to L i when each periodic request completes, and hence it takes O (n) for each update. From Eq.(3), we see that S i (t c ; t) is a non-decreasing staircase function. <p> How to use this function, which is called A fl (t c ; t) in <ref> [6] </ref>, is a major difference between our algorithms and the algorithms [6], [8]. In [6], [8], the function A fl (t c ; t) is taken to be the maximum amount of time available to execute aperiodic requests during [t c ; t]. <p> How to use this function, which is called A fl (t c ; t) in <ref> [6] </ref>, is a major difference between our algorithms and the algorithms [6], [8]. In [6], [8], the function A fl (t c ; t) is taken to be the maximum amount of time available to execute aperiodic requests during [t c ; t]. We will show later that this is not the case. <p> How to use this function, which is called A fl (t c ; t) in <ref> [6] </ref>, is a major difference between our algorithms and the algorithms [6], [8]. In [6], [8], the function A fl (t c ; t) is taken to be the maximum amount of time available to execute aperiodic requests during [t c ; t]. We will show later that this is not the case. <p> For clarity, the periodic requests are not shown in the schedule. Schedules (a) and (b) are generated by assigning the highest priority to the aperiodic requests whenever there is slack as it is done in <ref> [6] </ref>, [8]. Schedule (a) uses the FIFO queueing discipline and the average response time of the three aperiodic requests is 13.67. Schedule (b) uses the SRPT queueing discipline and gives an average response time of 9.67 for the three aperiodic requests. <p> We note that previous algorithms also have this dynamic nature, albeit to a lesser degree, of priority assignment; when there is slack, the aperiodic requests have the highest priority, and when the slack runs out, the aperiodic requests have the lowest priority. As mentioned earlier, the methods used in <ref> [6] </ref>, [8] to compute the slack function can also be used by our algorithms. Consequently, our algorithms can also apply the extensions mentioned in [8] to reclaim unused periodic execution time and to handle periodic tasks with release jitter, synchronization requirements and arbitrary deadlines.
Reference: 7. <author> S. Ramos-Thuel and J. P. Lehoczky, </author> <title> "On-Line Scheduling of Hard Deadline Aperiodic Tasks in Fixed-Priority Systems," </title> <booktitle> in Proceedings of the Real-Time System Symposium, </booktitle> <pages> pp. 160-171, </pages> <year> 1993. </year>
Reference-contexts: The amount of slack time during a time interval [t 1 ; t 2 ] is equal to the amount of time that can be used to execute aperiodic requests without causing any periodic request to miss its deadline. Several slack stealing algorithms have been proposed [6], <ref> [7] </ref>, [8]. All the previous slack stealing algorithms [6], [7], [8] are greedy: whenever there is slack available, a greedy algorithm schedules soft aperiodic requests at the highest priority level so that they can make use of the slack immediately to minimize their response times. <p> Several slack stealing algorithms have been proposed [6], <ref> [7] </ref>, [8]. All the previous slack stealing algorithms [6], [7], [8] are greedy: whenever there is slack available, a greedy algorithm schedules soft aperiodic requests at the highest priority level so that they can make use of the slack immediately to minimize their response times. These algorithms were shown to be optimal among all greedy algorithms.
Reference: 8. <author> R. I. Davis, K. W. Tindell, and A. Burns, </author> <title> "Scheduling Slack Time in Fixed-Priority Preemptive Systems," </title> <booktitle> in Proceedings of the Real-Time System Symposium, </booktitle> <pages> pp. 222-231, </pages> <year> 1993. </year>
Reference-contexts: The amount of slack time during a time interval [t 1 ; t 2 ] is equal to the amount of time that can be used to execute aperiodic requests without causing any periodic request to miss its deadline. Several slack stealing algorithms have been proposed [6], [7], <ref> [8] </ref>. All the previous slack stealing algorithms [6], [7], [8] are greedy: whenever there is slack available, a greedy algorithm schedules soft aperiodic requests at the highest priority level so that they can make use of the slack immediately to minimize their response times. <p> Several slack stealing algorithms have been proposed [6], [7], <ref> [8] </ref>. All the previous slack stealing algorithms [6], [7], [8] are greedy: whenever there is slack available, a greedy algorithm schedules soft aperiodic requests at the highest priority level so that they can make use of the slack immediately to minimize their response times. These algorithms were shown to be optimal among all greedy algorithms. <p> We will show in the next section that even a clairvoyant algorithm (i.e. one with a priori knowledge of future aperiodic requests) cannot be strongly optimal. Hence, contrary to the claims in [6], <ref> [8] </ref> that their algorithms are optimal among all algorithms using the FIFO queueing discipline, their algorithms are not optimal. <p> A locally optimal algorithm is a valid algorithm which, among all valid algorithms, yields the minimal response time for the aperiodic request at the head of the aperiodic service queue. As in [6], <ref> [8] </ref>, we assume that overhead for context switching, task scheduling and delay in preemption are negligibly small compared with computation times of the tasks. Requests in periodic tasks are ready at the start of their periods and do not suspend themselves or synchronize with other tasks. <p> Hence, without a priori knowledge of the aperiodic requests, an on-line algorithm will not know whether to schedule each aperiodic request as soon as possible so as to minimize the average response time. We now show that the greedy slack stealing algorithms in [6], <ref> [8] </ref> may not give the minimal response time for a single aperiodic request. To do so, we consider again the periodic tasks in Figure 1 and suppose that an aperiodic request J 1 arrives at time 2. <p> For this example, the algorithms in [6], <ref> [8] </ref> would have produced schedule A. J 1 's response time would not be minimal if its computation time lies within the range (1; 2]. We will show in Section 5 how our proposed algorithm can correctly schedule J 1 . <p> J 1 's response time would not be minimal if its computation time lies within the range (1; 2]. We will show in Section 5 how our proposed algorithm can correctly schedule J 1 . The main flaw in the proofs of the algorithms' optimality in [6], <ref> [8] </ref> lies in the assertion that given any two time instants t 1 and t 2 , the amount of time available for executing aperiodic requests in the interval [t 1 ; t 2 ] cannot exceed the slack given by their slack computations. <p> Two methods of computing the slack function, which gives the amount of slack available within an interval [t 1 ; t 2 ], have been proposed; the static method in [6] and the dynamic method in <ref> [8] </ref>. Either of these methods can be used in our algorithms to determine the amount of slack. As stated earlier, the major difference between our algorithms and the algorithms in [6], [8] is that the latter are greedy slack stealing algorithms. <p> [t 1 ; t 2 ], have been proposed; the static method in [6] and the dynamic method in <ref> [8] </ref>. Either of these methods can be used in our algorithms to determine the amount of slack. As stated earlier, the major difference between our algorithms and the algorithms in [6], [8] is that the latter are greedy slack stealing algorithms. They schedule a ready aperiodic request J m at the highest priority whenever the value of the slack function is not zero. <p> The amount of computation needed to update the table after the completion of each periodic request is O (n) as given in [6]. However, we will show later that this update can be reduced to O (1). According to the dynamic method <ref> [8] </ref>, whenever there is an aperiodic request to be scheduled, the algorithm computes the amount of slack available for the current request of each periodic task. <p> Based on worst-case performance, this method is more efficient than the method proposed in <ref> [8] </ref>. The actual relative performance of the two dynamic methods, however, depends on the characteristics of the periodic tasks. One advantage of the dynamic method over the static method is that the dynamic method is able to handle periodic tasks with release time jitters or synchronization requirements. <p> How to use this function, which is called A fl (t c ; t) in [6], is a major difference between our algorithms and the algorithms [6], <ref> [8] </ref>. In [6], [8], the function A fl (t c ; t) is taken to be the maximum amount of time available to execute aperiodic requests during [t c ; t]. We will show later that this is not the case. <p> How to use this function, which is called A fl (t c ; t) in [6], is a major difference between our algorithms and the algorithms [6], <ref> [8] </ref>. In [6], [8], the function A fl (t c ; t) is taken to be the maximum amount of time available to execute aperiodic requests during [t c ; t]. We will show later that this is not the case. <p> For clarity, the periodic requests are not shown in the schedule. Schedules (a) and (b) are generated by assigning the highest priority to the aperiodic requests whenever there is slack as it is done in [6], <ref> [8] </ref>. Schedule (a) uses the FIFO queueing discipline and the average response time of the three aperiodic requests is 13.67. Schedule (b) uses the SRPT queueing discipline and gives an average response time of 9.67 for the three aperiodic requests. <p> As mentioned earlier, the methods used in [6], <ref> [8] </ref> to compute the slack function can also be used by our algorithms. Consequently, our algorithms can also apply the extensions mentioned in [8] to reclaim unused periodic execution time and to handle periodic tasks with release jitter, synchronization requirements and arbitrary deadlines. <p> As mentioned earlier, the methods used in [6], <ref> [8] </ref> to compute the slack function can also be used by our algorithms. Consequently, our algorithms can also apply the extensions mentioned in [8] to reclaim unused periodic execution time and to handle periodic tasks with release jitter, synchronization requirements and arbitrary deadlines. We have conducted extensive simulation to evaluate our algorithms. The detailed simulation results are presented in [9].
Reference: 9. <author> T.-S. Tia, J. W.-S. Liu, and M. Shankar, </author> <title> "Aperiodic Request Scheduling in Fixed-Priority Preemptive Systems," </title> <type> Tech. Rep. </type> <institution> UIUCDCS-R-94-1859, Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <year> 1994. </year>
Reference-contexts: Consequently, our algorithms can also apply the extensions mentioned in [8] to reclaim unused periodic execution time and to handle periodic tasks with release jitter, synchronization requirements and arbitrary deadlines. We have conducted extensive simulation to evaluate our algorithms. The detailed simulation results are presented in <ref> [9] </ref>. Our simulation study shows that the average performance of our algorithms is essentially the same as the average performance of the greedy slack stealing algorithms for most of the test cases. In the other cases, our algorithms only outperform the greedy slack stealing algorithms by a small margin.
References-found: 9

