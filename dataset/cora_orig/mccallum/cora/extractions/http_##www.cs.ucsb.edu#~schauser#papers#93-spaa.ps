URL: http://www.cs.ucsb.edu/~schauser/papers/93-spaa.ps
Refering-URL: http://www.cs.ucsb.edu/~schauser/papers/
Root-URL: http://www.cs.ucsb.edu
Title: Optimal Broadcast and Summation in the LogP Model  
Author: Richard M. Karp Abhijit Sahay, Eunice E. Santos, Klaus Erik Schauser 
Address: Berkeley  
Affiliation: Computer Science Division, University of California,  
Abstract: In many distributed-memory parallel computers the only built-in communication primitive is point-to-point message transmission, and more powerful operations such as broadcast and synchronization must be realized using this primitive. Within the LogP model of parallel computation we present algorithms that yield optimal communication schedules for several broadcast and synchronization operations. Most of our algorithms are the absolutely best possible in that not even the constant factors can be improved upon. For one particular broadcast problem, called continuous broadcast, the optimality of our algorithm is not yet completely proven, although proofs have been achieved for a certain range of parameters. We also devise an optimal algorithm for summing or, more generally, applying a non-commutative associative binary operator to a set of operands. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal, A. K. Chandra, and M. Snir. </author> <title> On Communication Latency in PRAM Computation. </title> <booktitle> In Proceedings of the ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 11-21. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Most models of parallel computation reflect the communication bottlenecks of real parallel machines inadequately. The PRAM [11], for example, allows interprocessor communication at zero cost. Researchers have proposed several variations on the PRAM that address particular aspects of interprocessor communication such as latency, memory contention and synchronization <ref> [16, 15, 17, 1, 2] </ref>, but no single model properly accounts for all these aspects.
Reference: [2] <author> A. Aggarwal, A. K. Chandra, and M. Snir. </author> <title> Communication Complexity of PRAMs. </title> <booktitle> Theoretical Computer Science, </booktitle> <pages> pages 3-28, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: 1 Introduction Most models of parallel computation reflect the communication bottlenecks of real parallel machines inadequately. The PRAM [11], for example, allows interprocessor communication at zero cost. Researchers have proposed several variations on the PRAM that address particular aspects of interprocessor communication such as latency, memory contention and synchronization <ref> [16, 15, 17, 1, 2] </ref>, but no single model properly accounts for all these aspects.
Reference: [3] <author> N. Alon, A. Barak, and U. Manber. </author> <title> On disseminating infomation reliably without broadcasting. </title> <booktitle> In Proceedings of the International Conference on Distributed Computing Systems, </booktitle> <year> 1987. </year>
Reference-contexts: Cockayne and Thomason [8] and Farley [10] gave optimal algorithms for a model where each processor can either send or receive a message in one time step. Alon, Barak and Manber <ref> [3] </ref> studied reliable broadcast in a model that allows simultaneous send and receive. Bar-Noy and Kipnis [5] recently introduced the postal model which incorporates a latency parameter in addition to stipulating that at most one message be sent or received by a processor per time step.
Reference: [4] <author> A. Bar-Noy and S. Kipnis. </author> <title> Broadcasting Multiple Messages in Simultaneous Send/Receive Systems. </title> <type> Technical Report NO. RC 18352, </type> <institution> IBM Research Division, </institution> <month> September </month> <year> 1992. </year> <note> Also to appear in Discrete Applied Mathematics. </note>
Reference-contexts: We can then normalize so that g = 1, yielding the postal model. For this model, Bar-Noy and Kipnis have given an optimal algorithm for the single-item broadcast problem as well as a sub-optimal algorithm for the multiple-item broadcast problem <ref> [5, 4] </ref>. The remainder of the paper is organized as follows. Section 2 defines the single-item broadcast problem and develops an optimal algorithm for it. It also provides an illustration of the roles of the various parameters of the LogP model. <p> We will study this problem in the postal model. The algorithm of Bar-Noy and Kipnis [6] for k-item broadcast is sub-optimal except for the case L = 1 <ref> [4] </ref>. Its running time of 2B (P ) + k + O (L) is considerably larger than the lower bound derived below. Our lower bound will be given in terms of the ff i g sequence defined in Section 2.
Reference: [5] <author> A. Bar-Noy and S. Kipnis. </author> <title> Designing Broadcasting Algorithms in the Postal Model for Message-Passing Systems. </title> <booktitle> In Proceedings of the ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 11-22, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Cockayne and Thomason [8] and Farley [10] gave optimal algorithms for a model where each processor can either send or receive a message in one time step. Alon, Barak and Manber [3] studied reliable broadcast in a model that allows simultaneous send and receive. Bar-Noy and Kipnis <ref> [5] </ref> recently introduced the postal model which incorporates a latency parameter in addition to stipulating that at most one message be sent or received by a processor per time step. <p> We can then normalize so that g = 1, yielding the postal model. For this model, Bar-Noy and Kipnis have given an optimal algorithm for the single-item broadcast problem as well as a sub-optimal algorithm for the multiple-item broadcast problem <ref> [5, 4] </ref>. The remainder of the paper is organized as follows. Section 2 defines the single-item broadcast problem and develops an optimal algorithm for it. It also provides an illustration of the roles of the various parameters of the LogP model. <p> Note that for any broadcast algorithm A; t A (1) = 0; Our algorithm for single-item broadcast generalizes that of <ref> [5] </ref> for the postal model. It is based on the simple and intuitive idea that all informed processors should send the datum to uninformed processors as early and as frequently as possible. <p> Define the sequence ff i g by: 2. f i = f i1 + f iL otherwise. Fact 2.1 For each t; 1 + S i=t i=0 f i = f t+L . The following can be easily proved. (See <ref> [5] </ref> for a proof and for bounds on f t .) Theorem 2.2 For t 0 and L &gt; 0, P (t; L; 0; 1) = f t 3 The k-item Broadcast Problem In this section, we consider the k-item broadcast problem in which k &gt; 1 data items initially residing
Reference: [6] <author> A. Bar-Noy and S. Kipnis. </author> <title> Multiple Message Broadcasting in the Postal Model. </title> <booktitle> In Proceedings of the Seventh International Parallel Processing Symposium, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: We will study this problem in the postal model. The algorithm of Bar-Noy and Kipnis <ref> [6] </ref> for k-item broadcast is sub-optimal except for the case L = 1 [4]. Its running time of 2B (P ) + k + O (L) is considerably larger than the lower bound derived below.
Reference: [7] <author> D. P. Bertsekas and J. N. Tsitsiklis. </author> <title> Parallel and Distributed Computation: Numerical Methods. </title> <publisher> Prentice-Hall, </publisher> <year> 1989. </year>
Reference-contexts: that the initial distribution of the numbers among the processor/memory pairs may be stipulated by the algorithm. (Here, addition" means the application of any binary associative operator.) Given the considerable importance of broadcasting problems in parallel and distributed computation, several variations of it have been well studied in the literature <ref> [7, 12] </ref>. Much of this work has focused on the design of efficient algorithms for broadcasting on specific networks such as hypercubes [13, 14]. For fully connected systems (such as those modeled by LogP) broadcast problems have been studied in several communication models, but without latency.
Reference: [8] <author> E. Cockayne and A. Thomason. </author> <title> Optimal multi-message broadcasting in complete graphs. </title> <booktitle> In Proceedings of the 11th SE Conference on Combinatorics, Graph Theory, and Computing, </booktitle> <pages> pages 181-199, </pages> <year> 1980. </year>
Reference-contexts: Much of this work has focused on the design of efficient algorithms for broadcasting on specific networks such as hypercubes [13, 14]. For fully connected systems (such as those modeled by LogP) broadcast problems have been studied in several communication models, but without latency. Cockayne and Thomason <ref> [8] </ref> and Farley [10] gave optimal algorithms for a model where each processor can either send or receive a message in one time step. Alon, Barak and Manber [3] studied reliable broadcast in a model that allows simultaneous send and receive.
Reference: [9] <author> D. E. Culler, R. M. Karp, D. A. Patterson, A. Sahay, K. E. Schauser, E. Santos, R. Subramonian, and T. von Eicken. </author> <title> LogP: Towards a Realistic Model of Parallel Computation. </title> <booktitle> In Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <month> May </month> <year> 1993. </year> <note> Also appears as TR No. UCB/CS/92 713. </note>
Reference-contexts: There have also been a number of studies of parallel communication on specific networks such as the hypercube or mesh. Recently, Culler et al <ref> [9] </ref> proposed a general purpose model, the LogP model for distributed-memory machines. In this model, processors work asynchronously and communicate by point-to-point messages that travel through a network.
Reference: [10] <author> A. M. Farley. </author> <title> Broadcast time in communication networks. </title> <journal> SIAM Journal on Applied Mathematics, </journal> <volume> 39(2) </volume> <pages> 385-390, </pages> <month> October </month> <year> 1980. </year>
Reference-contexts: For fully connected systems (such as those modeled by LogP) broadcast problems have been studied in several communication models, but without latency. Cockayne and Thomason [8] and Farley <ref> [10] </ref> gave optimal algorithms for a model where each processor can either send or receive a message in one time step. Alon, Barak and Manber [3] studied reliable broadcast in a model that allows simultaneous send and receive.
Reference: [11] <author> S. Fortune and J. Wyllie. </author> <title> Parallelism in Random Access Machines. </title> <booktitle> In Proceedings of the 10th Annual Symposium on Theory of Computing, </booktitle> <pages> pages 114-118, </pages> <year> 1978. </year>
Reference-contexts: 1 Introduction Most models of parallel computation reflect the communication bottlenecks of real parallel machines inadequately. The PRAM <ref> [11] </ref>, for example, allows interprocessor communication at zero cost. Researchers have proposed several variations on the PRAM that address particular aspects of interprocessor communication such as latency, memory contention and synchronization [16, 15, 17, 1, 2], but no single model properly accounts for all these aspects.
Reference: [12] <author> S. M. Hedetniemi, S. T. Hedetniemi, and A. L. Liestman. </author> <title> A Survey of Gossiping and Broadcasting in Communication Networks. </title> <journal> Networks, </journal> <volume> 18(4) </volume> <pages> 319-349, </pages> <year> 1988. </year>
Reference-contexts: that the initial distribution of the numbers among the processor/memory pairs may be stipulated by the algorithm. (Here, addition" means the application of any binary associative operator.) Given the considerable importance of broadcasting problems in parallel and distributed computation, several variations of it have been well studied in the literature <ref> [7, 12] </ref>. Much of this work has focused on the design of efficient algorithms for broadcasting on specific networks such as hypercubes [13, 14]. For fully connected systems (such as those modeled by LogP) broadcast problems have been studied in several communication models, but without latency.
Reference: [13] <author> C-T. Ho. </author> <title> Optimal Comunication Primitives and Graph Em-beddings on Hypercubes. </title> <type> Ph.D. Thesis, </type> <institution> Yale University 1990. </institution>
Reference-contexts: Much of this work has focused on the design of efficient algorithms for broadcasting on specific networks such as hypercubes <ref> [13, 14] </ref>. For fully connected systems (such as those modeled by LogP) broadcast problems have been studied in several communication models, but without latency.
Reference: [14] <author> C-T. Ho and S.L. Johnsson. </author> <title> Distributed routing algorithms for broadcasting and personalized communication in hypercubes. </title> <booktitle> In Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <pages> pages 640-648. </pages> <publisher> IEEE Computer Society, </publisher> <year> 1986. </year>
Reference-contexts: Much of this work has focused on the design of efficient algorithms for broadcasting on specific networks such as hypercubes <ref> [13, 14] </ref>. For fully connected systems (such as those modeled by LogP) broadcast problems have been studied in several communication models, but without latency.
Reference: [15] <author> R. M. Karp, M. Luby, and F. Meyer auf der Heide. </author> <title> Efficient PRAM Simulation on a Distributed Memory Machine. </title> <booktitle> In Proceedings of the Twenty-Fourth Annual ACM Symposium of the Theory of Computing, </booktitle> <pages> pages 318-326. </pages> <publisher> ACM, ACM, </publisher> <month> May </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Most models of parallel computation reflect the communication bottlenecks of real parallel machines inadequately. The PRAM [11], for example, allows interprocessor communication at zero cost. Researchers have proposed several variations on the PRAM that address particular aspects of interprocessor communication such as latency, memory contention and synchronization <ref> [16, 15, 17, 1, 2] </ref>, but no single model properly accounts for all these aspects.
Reference: [16] <author> K. Mehlhorn and U. Vishkin. </author> <title> Randomized and deterministic simulations of PRAMs by parallel machines with restricted granularity of parallel memories. </title> <journal> Acta Informatica, </journal> <volume> 21 </volume> <pages> 339-374, </pages> <year> 1984. </year>
Reference-contexts: 1 Introduction Most models of parallel computation reflect the communication bottlenecks of real parallel machines inadequately. The PRAM [11], for example, allows interprocessor communication at zero cost. Researchers have proposed several variations on the PRAM that address particular aspects of interprocessor communication such as latency, memory contention and synchronization <ref> [16, 15, 17, 1, 2] </ref>, but no single model properly accounts for all these aspects.
Reference: [17] <author> C. H. Papadimitriou and M. Yannakakis. </author> <title> Towards an Architecture-Independent Analysis of Parallel Algorithms. </title> <booktitle> In Proceedings of the Twentieth Annual ACM Symposium of the Theory of Computing, </booktitle> <pages> pages 510-513. </pages> <publisher> ACM, </publisher> <year> 1988. </year>
Reference-contexts: 1 Introduction Most models of parallel computation reflect the communication bottlenecks of real parallel machines inadequately. The PRAM [11], for example, allows interprocessor communication at zero cost. Researchers have proposed several variations on the PRAM that address particular aspects of interprocessor communication such as latency, memory contention and synchronization <ref> [16, 15, 17, 1, 2] </ref>, but no single model properly accounts for all these aspects.
Reference: [18] <author> L. G. Valiant. </author> <title> A Bridging Model for Parallel Computation. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 33(8) </volume> <pages> 103-11, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: Researchers have proposed several variations on the PRAM that address particular aspects of interprocessor communication such as latency, memory contention and synchronization [16, 15, 17, 1, 2], but no single model properly accounts for all these aspects. Valiant's BSP model <ref> [18] </ref> is more realistic, but imposes a rigid programming style in which a parallel algorithm is expressed as a series of supersteps, where each superstep terminates with a barrier synchronization involving all the processors.
References-found: 18

