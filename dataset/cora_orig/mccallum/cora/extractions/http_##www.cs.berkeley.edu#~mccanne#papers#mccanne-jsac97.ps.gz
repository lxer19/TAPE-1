URL: http://www.cs.berkeley.edu/~mccanne/papers/mccanne-jsac97.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~mccanne/papers.html
Root-URL: http://www.cs.berkeley.edu
Title: Low-complexity Video Coding for Receiver-driven Layered Multicast  
Author: Steven McCanne, Member, IEEE, Martin Vetterli, Fellow, IEEE, and Van Jacobson 
Note: ACCEPTED FOR PUBLICATION IN IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS 1  
Abstract: In recent years the Internet Multicast Backbone, or MBone, has risen from a small, research curiosity to a large scale and widely used communications infrastructure. A driving force behind this growth was the development of multipoint audio, video, and shared whiteboard conferencing applications. Because these real-time media are transmitted at a uniform rate to all the receivers in the network, a source must either run at the bottleneck rate or overload portions of its multicast distribution tree. We overcome this limitation by moving the burden of rate-adaptation from the source to the receivers with a scheme we call Receiver-driven Layered Multicast, or RLM. In RLM, a source distributes a hierarchical signal by striping the different layers across multiple multicast groups and receivers adjust their reception rate by simply joining and leaving multicast groups. In this paper we describe a layered video compression algorithm which, when combined with RLM, provides a comprehensive solution for scalable multicast video transmission in heterogeneous networks. In addition to a layered representation, our coder has low-complexity (admitting an efficient software implementation) and high loss resilience (admitting robust operation in loosely controlled environments like the Internet). Even with these constraints, our hybrid DCT/wavelet-based coder exhibits good compression performance. It outperforms all publicly available Internet video codecs while maintaining comparable run-time performance. We have implemented our coder in a real application the UCB/LBL video conferencing tool vic.Unlike previous work on layered video compression and transmission, we have built a fully operational system that is currently being deployed on a very large scale over the MBone. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Steve Deering, </author> <title> Internet multicast routing: State of the art and open research issues, </title> <booktitle> Oct. 1993, Multimedia Integrated Conferencing for Europe (MICE) Seminar at the Swedish Institute of Computer Science, </booktitle> <address> Stockholm. </address>
Reference-contexts: In this scheme, the network must be able to selectively drop layers at each bottleneck link. While much of the previous work leaves this problem as an implementation detail, a novel and practical scheme was proposed by Deering <ref> [1] </ref> and was further described and/or independently cited in [10], [2], [3], [4], [7]. In this approach, the layers that comprise the hierarchical signal are striped across distinct IP Multicast groups thereby allowing receivers to adjust their reception rate by controlling the number of groups they receive. <p> In recent work, we filled this void with a specific protocol we call Receiver-driven Layered Multicast or RLM [11]. A number of research activities have laid the groundwork both for layered video compression [10], [6], [8] and for layered transmission systems <ref> [1] </ref>, [12], [13], [7]. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem. <p> Proposition 2: Maximizing the total transmitted bit rate does not necessarily minimize the total distortion. We take the same example as in Proposition 1. Any split of the bandwidth B into portions ffB and (1 ff)B, ff 2 <ref> [0; 1] </ref>, maximizes the sum of delivered bandwidth to users 1 and 2.
Reference: [2] <author> Luca Delgrossi, Christian Halstrick, Dietmar Hehmann, Ralf Guido Her-rtwich, Oliver Krone, Jochen Sandvoss, and Carsten Vogt, </author> <title> Media scaling for audiovisual communication with the Heidelberg transport system, </title> <booktitle> in Proceedings of ACM Multimedia '93. ACM, </booktitle> <month> Aug. </month> <year> 1993, </year> <pages> pp. 99-104. </pages>
Reference-contexts: The decoder module D is capable of decoding any cumulative set of bit strings. Each additional string produces an improvement in reconstruction quality. By combining this approach of layered source coding with a layered transmission system, we can solve the multicast heterogeneity problem <ref> [2] </ref>, [4], [5], [7]. In this architecture, the multi-cast source produces a layered stream where each layer is transmitted on a different network channel, as illustrated in Figure 4 for the case of the UCB seminar. <p> In this scheme, the network must be able to selectively drop layers at each bottleneck link. While much of the previous work leaves this problem as an implementation detail, a novel and practical scheme was proposed by Deering [1] and was further described and/or independently cited in [10], <ref> [2] </ref>, [3], [4], [7]. In this approach, the layers that comprise the hierarchical signal are striped across distinct IP Multicast groups thereby allowing receivers to adjust their reception rate by controlling the number of groups they receive.
Reference: [3] <author> Don Hoffman and Michael Speer, </author> <title> Hierarchical video distribution over Internet-style networks, </title> <booktitle> in Proceedings of the IEEE International Conference on Image Processing, </booktitle> <address> Lausanne, Switzerland, </address> <month> Sept. </month> <year> 1996, </year> <pages> pp. 5-8. </pages>
Reference-contexts: In this scheme, the network must be able to selectively drop layers at each bottleneck link. While much of the previous work leaves this problem as an implementation detail, a novel and practical scheme was proposed by Deering [1] and was further described and/or independently cited in [10], [2], <ref> [3] </ref>, [4], [7]. In this approach, the layers that comprise the hierarchical signal are striped across distinct IP Multicast groups thereby allowing receivers to adjust their reception rate by controlling the number of groups they receive. <p> PVH can also be used in tandem with the Resource ReserVation Protocol (RSVP) [50], which supports the notion of layered reservations. In this approach, receivers negotiate explicitly with the network for bandwidth by adjusting their reservation to the maximum number of layers that the network can deliver <ref> [3] </ref>. ACCEPTED FOR PUBLICATION IN IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS 18 VI. SUMMARY In this paper, we proposed a framework for the transmission of layered signals over heterogeneous networks using a receiver-driven adaptation protocol, RLM.
Reference: [4] <author> Steven McCanne and Martin Vetterli, </author> <title> Joint source/channel coding for multicast packet video, </title> <booktitle> in Proceedings of the IEEE International Conference on Image Processing, </booktitle> <address> Washington, DC, </address> <month> Oct. </month> <year> 1995, </year> <pages> pp. 25-28. </pages>
Reference-contexts: The decoder module D is capable of decoding any cumulative set of bit strings. Each additional string produces an improvement in reconstruction quality. By combining this approach of layered source coding with a layered transmission system, we can solve the multicast heterogeneity problem [2], <ref> [4] </ref>, [5], [7]. In this architecture, the multi-cast source produces a layered stream where each layer is transmitted on a different network channel, as illustrated in Figure 4 for the case of the UCB seminar. <p> While much of the previous work leaves this problem as an implementation detail, a novel and practical scheme was proposed by Deering [1] and was further described and/or independently cited in [10], [2], [3], <ref> [4] </ref>, [7]. In this approach, the layers that comprise the hierarchical signal are striped across distinct IP Multicast groups thereby allowing receivers to adjust their reception rate by controlling the number of groups they receive. <p> B. Spatial Compression Once the conditional replenishment algorithm decides to code a block, we spatially compress the block before transmitting it. In this section, we discuss the layered spatial compression algorithm that we apply to each block. The first version of our coder <ref> [4] </ref> utilized subband decomposition to exploit its inherently layered representation. Concep ACCEPTED FOR PUBLICATION IN IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS 9 tually, we carry out subband decomposition over the entire image and then use pixel-domain conditional replenishment to determine the subband coefficients to transmit.
Reference: [5] <author> Nachum Shacham, </author> <title> Multicast routing of hierachical data, </title> <booktitle> in Proceedings of the International Conference on Computer Communications. IEEE, </booktitle> <year> 1992. </year>
Reference-contexts: The decoder module D is capable of decoding any cumulative set of bit strings. Each additional string produces an improvement in reconstruction quality. By combining this approach of layered source coding with a layered transmission system, we can solve the multicast heterogeneity problem [2], [4], <ref> [5] </ref>, [7]. In this architecture, the multi-cast source produces a layered stream where each layer is transmitted on a different network channel, as illustrated in Figure 4 for the case of the UCB seminar.
Reference: [6] <author> David Taubman and Avideh Zakhor, </author> <title> Multi-rate 3-D subband coding of video, </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> vol. 3, no. 5, </volume> <pages> pp. 572-588, </pages> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: In recent work, we filled this void with a specific protocol we call Receiver-driven Layered Multicast or RLM [11]. A number of research activities have laid the groundwork both for layered video compression [10], <ref> [6] </ref>, [8] and for layered transmission systems [1], [12], [13], [7]. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem. <p> Instead of a standardized compression algorithm, we could potentially adopt an existing experimental layered compression algorithm in our system. Taubman and Zakhor's 3D Subband Coding system is a high performance scalable video compression algorithm that produces a very fine-grained layered representation <ref> [6] </ref>. Its computational complexity, however, is relatively high and acceptable run-time performance will require a few more generations of processor evolution. Vishwanath and Chou's Weighted Wavelet Hierarchical Vector Quantization algorithm [8] is low-complexity and has a layered output format.
Reference: [7] <author> Thierry Turletti and Jean-Chrysostome Bolot, </author> <title> Issues with multicast video distribution in heterogeneous packet networks, </title> <booktitle> in Proceedings of the Sixth International Workshop on Packet Video, </booktitle> <address> Portland, OR, </address> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: The decoder module D is capable of decoding any cumulative set of bit strings. Each additional string produces an improvement in reconstruction quality. By combining this approach of layered source coding with a layered transmission system, we can solve the multicast heterogeneity problem [2], [4], [5], <ref> [7] </ref>. In this architecture, the multi-cast source produces a layered stream where each layer is transmitted on a different network channel, as illustrated in Figure 4 for the case of the UCB seminar. <p> While much of the previous work leaves this problem as an implementation detail, a novel and practical scheme was proposed by Deering [1] and was further described and/or independently cited in [10], [2], [3], [4], <ref> [7] </ref>. In this approach, the layers that comprise the hierarchical signal are striped across distinct IP Multicast groups thereby allowing receivers to adjust their reception rate by controlling the number of groups they receive. <p> In recent work, we filled this void with a specific protocol we call Receiver-driven Layered Multicast or RLM [11]. A number of research activities have laid the groundwork both for layered video compression [10], [6], [8] and for layered transmission systems [1], [12], [13], <ref> [7] </ref>. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem.
Reference: [8] <author> Mohan Vishwanath and Phil Chou, </author> <title> An efficient algorithm for hierarchical compression of video, </title> <booktitle> in Proceedings of the IEEE International Conference on Image Processing, </booktitle> <address> Austin, TX, </address> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: In recent work, we filled this void with a specific protocol we call Receiver-driven Layered Multicast or RLM [11]. A number of research activities have laid the groundwork both for layered video compression [10], [6], <ref> [8] </ref> and for layered transmission systems [1], [12], [13], [7]. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem. <p> Its computational complexity, however, is relatively high and acceptable run-time performance will require a few more generations of processor evolution. Vishwanath and Chou's Weighted Wavelet Hierarchical Vector Quantization algorithm <ref> [8] </ref> is low-complexity and has a layered output format. Their algorithm is based entirely on table look-ups and runs fast on current generation hardware. However, they have not produced a publicly available implementation nor presented details on its overall performance in real environments.
Reference: [9] <author> Allen Gersho and Robert M. Gray, </author> <title> Vector Quantization and Signal Compression, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year>
Reference-contexts: Fig. 4. Layered Transmission. By combining a layered source coder with a layered transmission system, we solve the heterogeneity problem. The network forwards only the number of layers that each physical link can support. vector quantizer of size N approaches D I (R) as N increases <ref> [9] </ref>. A layered coder D L (R) generally performs worse than the vector quantizer because layering imposes an additional constraint. On the other hand, the advantage of the layered representation is that both the encoder and decoder can travel along the distortion rate curve.
Reference: [10] <author> Navin Chaddha, </author> <title> Software only scalable video delivery system for multimedia applications over hetrogeneous networks, </title> <booktitle> in Proceedings of the ACCEPTED FOR PUBLICATION IN IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS 19 IEEE International Conference on Image Processing, </booktitle> <address> Washington, DC, </address> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: In this scheme, the network must be able to selectively drop layers at each bottleneck link. While much of the previous work leaves this problem as an implementation detail, a novel and practical scheme was proposed by Deering [1] and was further described and/or independently cited in <ref> [10] </ref>, [2], [3], [4], [7]. In this approach, the layers that comprise the hierarchical signal are striped across distinct IP Multicast groups thereby allowing receivers to adjust their reception rate by controlling the number of groups they receive. <p> In recent work, we filled this void with a specific protocol we call Receiver-driven Layered Multicast or RLM [11]. A number of research activities have laid the groundwork both for layered video compression <ref> [10] </ref>, [6], [8] and for layered transmission systems [1], [12], [13], [7]. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem.
Reference: [11] <author> Steven McCanne, Van Jacobson, and Martin Vetterli, </author> <title> Receiver-driven layered multicast, </title> <booktitle> in Proceedings of SIGCOMM '96, </booktitle> <address> Stanford, CA, </address> <month> Aug. </month> <year> 1996, </year> <note> ACM. </note>
Reference-contexts: In recent work, we filled this void with a specific protocol we call Receiver-driven Layered Multicast or RLM <ref> [11] </ref>. A number of research activities have laid the groundwork both for layered video compression [10], [6], [8] and for layered transmission systems [1], [12], [13], [7]. <p> Finally, we report on implementation status and deployment, and conclude. II. RECEIVER-DRIVEN LAYERED MULTICAST In this section, we give a high-level sketch of our Receiver-driven Layered Multicast scheme to establish design constraints on and motivation for a new layered codec. Details of RLM are presented in <ref> [11] </ref> and [14]. RLM operates within the traditional Internet Protocol architecture and relies upon the delivery efficiency of IP Multicast [15]. It does not require real-time traffic guarantees and assumes Fig. 5. Dynamic group membership. Receivers join and leave multicast groups at will. <p> Instead, RLM augments its adaptation scheme with shared learning, where receivers learn from other receivers' failed join-experiments. Details of the shared learning algorithm are described in <ref> [11] </ref>. Although RLM receivers adapt locally to network capacity, the target operating point is not globally optimized. If multiple, simultaneous transmissions are sharing a single network, RLM apportions the bandwidth among each transmission in an ad hoc fashion. <p> An effort is currently underway based in part on the work presented in this paper to modify RTP to allow a single session to span multiple underlying network channels <ref> [11] </ref>, [47]. Our proposed change is an extension to RTP that allows a participant to use one Source-ID consistently across the logically distinct RTP sessions comprising the hierarchy. <p> The PVH codec and framing protocol are implemented as a modular C++ object in the Tcl/Tk-based [48] multimedia toolkit used to build vic. We implemented the RLM protocol in our network simulation testbed [49] and carried out a simulation study reported in <ref> [11] </ref>, [14]. Even with RLM fully integrated into vic, the current framework is still experimental. We are just beginning to understand the interaction between RLM and other adaptive congestion control schemes in the Internet (e.g., TCP slow start).
Reference: [12] <author> Joseph C. Pasquale, George C. Polyzos, Eric W. Anderson, and Vachspathi P. Kompella, </author> <title> Filter propagation in disseme-nation trees: Trading off bandwidth and processing in continuous media networks, </title> <booktitle> in Proceedings of the Fourth International Workshop on Network and OS Support for Digital Audio and Video, </booktitle> <address> Lancaster, U.K., </address> <month> Nov. </month> <year> 1993, </year> <booktitle> ACM, </booktitle> <pages> pp. 269-278. </pages>
Reference-contexts: In recent work, we filled this void with a specific protocol we call Receiver-driven Layered Multicast or RLM [11]. A number of research activities have laid the groundwork both for layered video compression [10], [6], [8] and for layered transmission systems [1], <ref> [12] </ref>, [13], [7]. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem.
Reference: [13] <author> Nachum Shacham, </author> <title> Multipoint communication by hierarchically encoded data, </title> <booktitle> in Proceedings IEEE Infocom '92, </booktitle> <year> 1992, </year> <pages> pp. 2107-2114. </pages>
Reference-contexts: In recent work, we filled this void with a specific protocol we call Receiver-driven Layered Multicast or RLM [11]. A number of research activities have laid the groundwork both for layered video compression [10], [6], [8] and for layered transmission systems [1], [12], <ref> [13] </ref>, [7]. However, these research efforts are each polarized: they either solve the networking half of the problem (i.e., the transmission system) or they solve the compression half of the problem.
Reference: [14] <author> Steven R. McCanne, </author> <title> Scalable Video Coding and Transmission for Internet Multicast Video, </title> <type> Ph.D. thesis, </type> <institution> University of California, Berkeley, </institution> <month> Dec. </month> <year> 1996. </year>
Reference-contexts: Finally, we report on implementation status and deployment, and conclude. II. RECEIVER-DRIVEN LAYERED MULTICAST In this section, we give a high-level sketch of our Receiver-driven Layered Multicast scheme to establish design constraints on and motivation for a new layered codec. Details of RLM are presented in [11] and <ref> [14] </ref>. RLM operates within the traditional Internet Protocol architecture and relies upon the delivery efficiency of IP Multicast [15]. It does not require real-time traffic guarantees and assumes Fig. 5. Dynamic group membership. Receivers join and leave multicast groups at will. <p> Moreover, the redundancy present in lower-rate layers, where bandwidth is critical, is less than that in higher-rate layers. For example, layer 1 alone never has a redundant block update, while the full hierarchy contains the maximum number of redundant updates. <ref> [14] </ref> contains a more detailed analysis of this overhead. B. Spatial Compression Once the conditional replenishment algorithm decides to code a block, we spatially compress the block before transmitting it. In this section, we discuss the layered spatial compression algorithm that we apply to each block. <p> Finally, the actual order of bits in the output are shuffled around to carry out a performance optimiza tion described later. Version 1 of this codec bit syntax, which we call Progressive Video with Hybrid transform (PVH), is definitively defined in the appendix of <ref> [14] </ref>. B.2 Bit Allocation To optimize the compression performance of PVH, we must partition the rate between the DCT and subband coding subpro-cesses in an intelligent fashion. <p> The PVH codec and framing protocol are implemented as a modular C++ object in the Tcl/Tk-based [48] multimedia toolkit used to build vic. We implemented the RLM protocol in our network simulation testbed [49] and carried out a simulation study reported in [11], <ref> [14] </ref>. Even with RLM fully integrated into vic, the current framework is still experimental. We are just beginning to understand the interaction between RLM and other adaptive congestion control schemes in the Internet (e.g., TCP slow start).
Reference: [15] <author> Stephen E. Deering, </author> <title> Multicast Routing in a Datagram Internetwork, </title> <type> Ph.D. thesis, </type> <institution> Stanford University, </institution> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: Details of RLM are presented in [11] and [14]. RLM operates within the traditional Internet Protocol architecture and relies upon the delivery efficiency of IP Multicast <ref> [15] </ref>. It does not require real-time traffic guarantees and assumes Fig. 5. Dynamic group membership. Receivers join and leave multicast groups at will. The network forwards traffic only along paths that have downstream receivers.
Reference: [16] <author> W. Fenner, </author> <title> Internet Group Management Protocol, </title> <type> Version 2, </type> <institution> Internet Engineering Task Force, Inter-Domain Multicast Routing Working Group, </institution> <month> Feb. </month> <year> 1996, </year> <note> Internet Draft expires 8/31/96. </note>
Reference-contexts: Host groups provide a group-oriented communication framework where senders need not know explicitly about receivers and receivers need not know about senders. Instead, a sender simply transmits packets to a group address and receivers tell the network (via the Internet Group Management Protocol or IGMP <ref> [16] </ref>) that they are interested in receiving packets sent to that group. Moreover, the process by which receivers join and leave these multicast groups is timely and efficient (on the order of a few milliseconds). be used to dynamically induce selective forwarding of layers.
Reference: [17] <author> Van Jacobson, </author> <title> Congestion avoidance and control, </title> <booktitle> in Proceedings of SIGCOMM '88, </booktitle> <address> Stanford, CA, </address> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: each receiver runs the following simple control loop: * on congestion, drop a layer * on spare capacity, add a layer Under this scheme, a receiver searches for the optimal level of subscription much as a TCP source searches for the bottleneck transmission rate with the slow-start congestion avoidance algorithm <ref> [17] </ref>. The receiver adds layers until congestion occurs and backs off to an operating point below this bottleneck.
Reference: [18] <author> Jeffrey M. Jaffe, </author> <title> Bottleneck flow control, </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. 29, no. 7, </volume> <pages> pp. 954-962, </pages> <month> July </month> <year> 1981. </year>
Reference-contexts: If multiple, simultaneous transmissions are sharing a single network, RLM apportions the bandwidth among each transmission in an ad hoc fashion. In general it is not possible to achieve a fair allocation of bandwidth without some additional machinery in the network, even if all the end-nodes cooperate <ref> [18] </ref>. Even if the bandwidth allocation were fair, the aggregate system performance, as measured by the sum of distortions at each receiver, would not be optimal. As shown in the appendix, minimization of the total distortion in general requires an exchange of information among receivers. III.
Reference: [19] <author> Steven McCanne and Van Jacobson, </author> <title> vic: a flexible framework for packet video, </title> <booktitle> in Proceedings of ACM Multimedia '95, </booktitle> <address> San Francisco, CA, </address> <month> Nov. </month> <year> 1995, </year> <booktitle> ACM, </booktitle> <pages> pp. 511-522. </pages>
Reference-contexts: Given that no current algorithm satisfied all of our design constraints, we designed a new layered compression scheme based on our experiences adapting H.261 for Internet transmission <ref> [19] </ref>. To meet our goal of low-complexity, the algorithm is relatively simple and admits an efficient software implementation. Moreover, the software-based approach provides an easy route for incrementally improving the algorithm as technology improves and as we better understand how to achieve robust compression in the presence of packet loss. <p> Our algorithm employs a very simple model for temporal compression known as block-based conditional replenishment <ref> [19] </ref>, [20], and uses a hybrid DCT/subband transform coding scheme for spatial compression. In the next section, we describe the conditional replenishment algorithm and in the subsequent section, we describe the spatial compression algorithm. A. <p> A. Temporal Compression In block-based conditional replenishment, the input image is gridded into small blocks (e.g., 8x8 or 16x16 pixels) and only the blocks that change in each new frame are encoded and transmitted. Several existing Internet video tools use this approach (e.g., our tool vic <ref> [19] </ref>, the Xerox PARC Network Video nv [21] and Cornell's CU-SeeMe [22]) and some commercial H.261 codecs send block skip codes for static blocks. transmitted blocks. For each new block, a distance between the reference block and the new block is computed. <p> Although this codec outperforms several existing Internet video coding schemes, its compression performance is somewhat inferior to the commonly used Intra-H.261 format <ref> [19] </ref>. To carry out ongoing, large-scale experiments within the MBone user community, we rely on active use of the applications, protocols, and compression formats. <p> We implemented PVH and these optimizations in our video conferencing application vic and compared its performance with the widely used Intra-H.261 codec <ref> [19] </ref>. As a simple quantitative assessment, we measured the run-time performance of both codecs within vic on an SGI Indy (200MHz MIPS R4400) using the built-in VINO video device. <p> After several iterations of protocols and experimentation with audio and several different video compression formats, ACCEPTED FOR PUBLICATION IN IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS 15 it became clear that a one size fits all protocol was inadequate [42], <ref> [19] </ref>. Instead, a framework based on ALF emerged where a thin base protocol defines the core mechanisms and profile extensions define application-specific semantics. <p> We based our framing protocol in part on our work adapting H.261 for resilient packet transmission in vic. In this previous work, we developed a codec based on a subset of the H.261 standard, called Intra-H.261, that uses only intra-coding of conditionally replenished blocks <ref> [19] </ref>. One nice property of the Intra-H.261 framing protocol is that packets are independent of each other and can be decoded in isolation or in arbitrary order (up to a frame boundary). This simplifies loss recovery since the start of each packet provides an explicit resynchronization point.
Reference: [20] <author> F. W. Mounts, </author> <title> A video encoding system with conditional picture-element replenishment, </title> <journal> Bell Systems Technical Journal, </journal> <volume> vol. 48, no. 7, </volume> <pages> pp. 2545-2554, </pages> <month> Sept. </month> <year> 1969. </year>
Reference-contexts: Our algorithm employs a very simple model for temporal compression known as block-based conditional replenishment [19], <ref> [20] </ref>, and uses a hybrid DCT/subband transform coding scheme for spatial compression. In the next section, we describe the conditional replenishment algorithm and in the subsequent section, we describe the spatial compression algorithm. A.
Reference: [21] <author> Ron Frederick, </author> <title> Experiences with real-time software video compression, </title> <booktitle> in Proceedings of the Sixth International Workshop on Packet Video, </booktitle> <address> Port-land, OR, </address> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: Several existing Internet video tools use this approach (e.g., our tool vic [19], the Xerox PARC Network Video nv <ref> [21] </ref> and Cornell's CU-SeeMe [22]) and some commercial H.261 codecs send block skip codes for static blocks. transmitted blocks. For each new block, a distance between the reference block and the new block is computed. <p> We now describe the major components of our conditional replenishment algorithm: block selection, block aging, and temporal layering. Our scheme is derived in part from the condi tional replenishment algorithm used by the Xerox PARC Network Video tool, nv <ref> [21] </ref>. A.1 Block Selection To decide whether or not to encode and transmit a block, the conditional replenishment algorithm computes a distance between the reference block and the current block.
Reference: [22] <author> Tim Dorcey, </author> <title> CU-SeeMe desktop videoconferencing software, </title> <journal> ConneX-ions, </journal> <volume> vol. 9, no. 3, </volume> <month> Mar. </month> <year> 1995. </year>
Reference-contexts: Several existing Internet video tools use this approach (e.g., our tool vic [19], the Xerox PARC Network Video nv [21] and Cornell's CU-SeeMe <ref> [22] </ref>) and some commercial H.261 codecs send block skip codes for static blocks. transmitted blocks. For each new block, a distance between the reference block and the new block is computed. If the distance is above a threshold, the block is encoded and transmitted across the network.
Reference: [23] <author> Charles Compton and David Tennenhouse, </author> <title> Collaborative load shedding for media-based applications, </title> <booktitle> International Conference on Multimedia Computing and Systems, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: Consequently, in addition to packet loss in the network, messages can be lost in the end-system when the decoder cannot keep up with a high-rate incoming bit-stream. In this case, the decoder should gracefully adapt by trading off reconstruction quality to shed work <ref> [23] </ref>, [24]. However, such adaptation is difficult under the temporal prediction model because the decoder must fully decode all differential updates to maintain a consistent prediction state. In contrast, with conditional replenishment, compute-scalability is both feasible and simple.
Reference: [24] <author> Kevin Fall, Joseph Pasquale, and Steven McCanne, </author> <title> Workstation video playback performance with competitive process load, </title> <booktitle> in Proceedings of the Fifth International Workshop on Network and OS Support for Digital Audio and Video, </booktitle> <address> Durham, NH, </address> <month> Apr. </month> <year> 1995, </year> <pages> pp. 179-182. </pages>
Reference-contexts: Consequently, in addition to packet loss in the network, messages can be lost in the end-system when the decoder cannot keep up with a high-rate incoming bit-stream. In this case, the decoder should gracefully adapt by trading off reconstruction quality to shed work [23], <ref> [24] </ref>. However, such adaptation is difficult under the temporal prediction model because the decoder must fully decode all differential updates to maintain a consistent prediction state. In contrast, with conditional replenishment, compute-scalability is both feasible and simple.
Reference: [25] <author> Leonid Kasperovich, </author> <title> Multiplication free scaled 8x8 DCT algorithm with 530 additions, </title> <booktitle> in Proc. SPIE. ACM, 1995, </booktitle> <volume> vol. 2419, </volume> <pages> pp. 105-110. </pages>
Reference-contexts: Here we can exploit numerical approximations to trade off reconstruction quality for run-time performance. For example, the inverse DCT could be replaced by an approximate algorithm that runs faster at the expense of decreased accuracy <ref> [25] </ref>. For these reasons, we sacrifice the compression advantage of temporal prediction (i.e., assuming zero loss and unconstrained computational power) for the simplicity and systems-oriented advantages of conditional replenishment. In short, our compression algorithm exploits temporal redundancy only through conditional replenishment.
Reference: [26] <author> Anil K. Jain, </author> <title> Fundamentals of Digital Image Processing, </title> <publisher> Prentice-Hall International, Inc., </publisher> <year> 1989. </year>
Reference-contexts: A 16x16 replenishment unit has two advantages over an 8x8 unit. First, the overhead in representing the block addressing information is reduced since there are four times fewer blocks and therefore four times fewer location codes. Second, the larger block size in general allows more efficient spatial compression techniques <ref> [26] </ref>. However, larger blocks cause coarse grained image updates, which consequently results in redundant transmission. This places a limit on the potential improvement of an arbitrarily large block. A.2 Robust Refresh The threshold in the block selection algorithm provides hysteresis by suppressing block updates when there is little change.
Reference: [27] <author> Jerome M. Shapiro, </author> <title> Embedded image coding using zerotrees of wavelet coefficients, </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 41, no. 12, </volume> <pages> pp. 3445-3462, </pages> <month> Dec. </month> <year> 1993. </year>
Reference-contexts: After subband analysis, we encode those sub-band coefficients whose basis vectors are spatially centered over each selected pixel block. We then group the coefficients across scales with like orientation into the well-known quad-tree structure, and then zero-tree code them using Shapiro's scheme for Embedded Zerotrees of Wavelet coefficients (EZW) <ref> [27] </ref>. This coding structure is illustrated in Figure 11. Unfortunately, a tension arises between subband decomposition and conditional replenishment. While subband decomposition induces a multiscale structure where transform coefficients correspond to multiple overlapping regions of the image, conditional replenishment assumes spatially confined pixel blocks. <p> Hence, we removed temporal coding overheads (like macroblock addressing codes) from each codec. Because we compare only grayscale PSNR performance, we additionally removed chrominance syntax overhead. In addition to the Internet video codecs, we compared our results against Shapiro's EZW algorithm <ref> [27] </ref> and progressive-mode JPEG [30, Annex G] to gauge the performance of our scheme against well-established subband- and DCT-based image codecs. For each algorithm, we obtained a distortion-rate characteristic for the 512x512 Lena gray scale test image as follows: * Intra-H.261. <p> We obtained the curve using the JPEG codec's - scans option to compute multiple operating points by controlling the number of refinement passes used by the en coder. * EZW. We used the performance results reported in <ref> [27] </ref>. ACCEPTED FOR PUBLICATION IN IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS 12 Fig. 15. Temporal/Spatial Scaling. We cannot scale the spatial and temporal qualities simultaneously. Instead, we must choose a single path through this rate-scaling space.
Reference: [28] <author> Martin Vetterli and Jelena Kovacevic, </author> <title> Wavelets and Subband Coding, </title> <publisher> Prentice-Hall, </publisher> <year> 1995. </year>
Reference-contexts: Our solution was to use short analysis filters to increase the coherence between the subband and pixel representations. For example, in one version of the coder, we use the following biorthogonal filters for the first stage analysis <ref> [28] </ref>: H 0 (z) = 1 + 3z 1 + 3z 2 z 3 with the following synthesis 2 G 0 (z) = (1 + 3z 1 + 3z 2 + z 3 )=16 and Haar filters for the remaining three stages. <p> Assume the two sessions start simultaneously, so that they will, through competition, each get bandwidth B=2 on the critical link. Now, unless @D 1 (R) fi fi R=B=2 @D 2 (R) fi fi R=B=2 (which is the usual optimality condition for rate allocation <ref> [28] </ref>), the solution is suboptimal. If the two services are similar, they have the same distortion rate function and equality in (4) would hold.
Reference: [29] <author> D. J. LeGall, H. Gaggioni, and C. T. Chen, </author> <title> Transmission of HDTV signals under 140 Mbits/s using a subband decomposition and Discrete Cosine Transform coding, in Signal Processing of HDTV, </title> <editor> L. Chiariglione, </editor> <publisher> Ed., </publisher> <pages> pp. 287-293. </pages> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1988. </year>
Reference-contexts: Since this coarse-scale block represents a low-resolution version of the original image, its statistics are consistent with a typical image signal. Hence, a coding scheme tailored for normal images will work well on the coarse-scale LL subband <ref> [29] </ref>. Rather than carry out additional subband decomposition using the Haar transform on the LL subband, we instead apply an 8x8 DCT as depicted in Figure 12. To retain an embedded bit stream, we encode the transform coefficients progressively by coding the DCT coefficients a bit-plane at a time. <p> By decomposing the compression process into a number of passes that successively refine the transform coefficients, we can easily format the bit stream into a layered representation. Although DCT-based coding of the LL coarse scale band has been previously proposed <ref> [29] </ref>, as far as we know, the combination of progressive DCT transmission and multiresolution subband decomposition has not been explored. Simultaneously with the progressive coding of DCT coefficients, we encode the LH and HL subband coefficients using a simple quad-tree decomposition of bit-planes.
Reference: [30] <institution> ISO DIS 10918-1 Digital compression and coding of continuous-tone still images (JPEG), CCITT Recommendation T.81. </institution>
Reference-contexts: To retain an embedded bit stream, we encode the transform coefficients progressively by coding the DCT coefficients a bit-plane at a time. Our technique is similar to the point transform used in progressive-mode JPEG <ref> [30, Annex G] </ref> and the SNR-scalability profile in MPEG-2. We code the DCT coefficients in a number of passes. <p> Hence, we removed temporal coding overheads (like macroblock addressing codes) from each codec. Because we compare only grayscale PSNR performance, we additionally removed chrominance syntax overhead. In addition to the Internet video codecs, we compared our results against Shapiro's EZW algorithm [27] and progressive-mode JPEG <ref> [30, Annex G] </ref> to gauge the performance of our scheme against well-established subband- and DCT-based image codecs. For each algorithm, we obtained a distortion-rate characteristic for the 512x512 Lena gray scale test image as follows: * Intra-H.261.
Reference: [31] <author> Richard L. White, </author> <title> High-performance compression of astronomical images, </title> <booktitle> in Proceedings of the NASA Space and Earth Science Data Compression Workshop, </booktitle> <editor> James C. Tilton, Ed., </editor> <address> Snowbird, Utah, </address> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: Otherwise, output 1. If this is the most significant bit of the magnitude of this position, output the sign. Divide bit-plane into four equally sized bit-planes, and recursively code these subplanes. This approach is similar to the hcompress algorithm described in <ref> [31] </ref>, except that we are coding individual blocks rather than entire images (and we use a different wavelet decomposition). In practice, our algorithm diverges somewhat from this conceptual framework in order to optimize the syntax for better run-time performance.
Reference: [32] <author> Elan Amir, Steven McCanne, and Martin Vetterli, </author> <title> A layered DCT coder for Internet video, </title> <booktitle> in Proceedings of the IEEE International Conference on Image Processing, </booktitle> <address> Lausanne, Switzerland, </address> <month> Sept. </month> <year> 1996, </year> <pages> pp. 13-16. </pages>
Reference-contexts: Instead of carrying out a separate pass for every bit-plane, the first several planes are grouped together and treated as a quantized coefficient. This reduces the run-time overhead since we process multiple layers in parallel as is done by the Layered-DCT implementation in <ref> [32] </ref>. We scan the sub-band coefficients in a quad-tree fashion as described above and entropy-code each non-zero coefficient that is identified in the scan. <p> Existing solutions to heterogeneous video transmission are either network-oriented or compression-oriented in contrast, our focus is on the complete systems design and implementation. Together, RLM and PVH provide a comprehensive solution for scalable multicast video transmission in heterogeneous networks. VII. ACKNOWLEDGMENTS Elan Amir's work on his Layered-DCT algorithm <ref> [32] </ref> inspired our approach to decomposing the LL subband with a DCT and progressively coding transform coefficients. Elan Amir and Hari Balakrishnan provided thoughtful comments on drafts of this paper. We thank the anonymous reviewers for their excellent feedback.
Reference: [33] <author> Antonio Ortega, Kannan Ramchandran, and Martin Vetterli, </author> <title> Optimal trellis-based buffered compression and fast approximations, </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> vol. 3, no. 1, </volume> <pages> pp. 16-40, </pages> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: Each curve is swept out by progressively scanning the DCT coefficients of the LL subband and each separate curve corresponds to a fixed set of LH/HL coefficient refinement passes. approximation of the optimal solution <ref> [33] </ref>. Unfortunately, computing an on-line, adaptive optimization algorithm like this adds complexity that inhibits real-time performance. An alternative approach is to pre-select a fixed set of quantizers by hand and hope that they are never far from optimal.
Reference: [34] <author> Ketan Patel, Brian C. Smith, and Lawrence A. Rowe, </author> <title> Performance of a software MPEG video decoder, </title> <booktitle> in Proceedings of ACM Multimedia '93. ACM, </booktitle> <month> Aug. </month> <year> 1993, </year> <pages> pp. 75-82. </pages>
Reference-contexts: However, the codewords whose lengths are greater than M collide with other codewords in the table. In this case, the table entry contains an ESCAPE code that instructs the decoder to use a slower but completely defined operation (e.g., a full-sized table lookup). The Berkeley MPEG decoder <ref> [34] </ref> uses a similar table-driven approach. Several operations are combined or are carried out in-place to reduce processor/memory traffic: * The subband analysis stage performs quantization on the fly so that the output coefficients are stored in 8-bit format.
Reference: [35] <author> David D. Clark and David L. Tennenhouse, </author> <title> Architectural considerations for a new generation of protocols, </title> <booktitle> in Proceedings of SIGCOMM '90, </booktitle> <address> Philadelphia, PA, </address> <month> Sept. </month> <year> 1990, </year> <note> ACM. </note>
Reference-contexts: In 1990 Clark and Tennenhouse recognized that this problem could be solved if application semantics were reflected in the design of an application's network protocol. Their Application Level Framing (ALF) protocol architecture <ref> [35] </ref> leads to a design where the application takes an active role in the encapsulation of its data into network packets, and hence, can optimize for loss recovery through intelligent fragmentation and framing.
Reference: [36] <author> Van Jacobson and Steven McCanne, </author> <title> Visual Audio Tool, </title> <institution> Lawrence Berke-ley Laboratory, </institution> <note> Software on-line 4 . 4 ftp://ftp.ee.lbl.gov/conferencing/vat </note>
Reference-contexts: About the same time that ALF emerged, we and others developed a number of tools to explore the problem of interactive audio and video transport across packet-switched networks <ref> [36] </ref>, [37], [38], [39], [40], [41]. After several iterations of protocols and experimentation with audio and several different video compression formats, ACCEPTED FOR PUBLICATION IN IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS 15 it became clear that a one size fits all protocol was inadequate [42], [19].
Reference: [37] <author> Eve M. Schooler and Stephen L. Casner, </author> <title> A packet-switched multimedia conferencing system, </title> <journal> ACM Special Interest Group on Office Information Systems Bulletin, </journal> <volume> vol. 10, </volume> <pages> pp. 12-22, </pages> <month> Jan. </month> <year> 1989. </year>
Reference-contexts: About the same time that ALF emerged, we and others developed a number of tools to explore the problem of interactive audio and video transport across packet-switched networks [36], <ref> [37] </ref>, [38], [39], [40], [41]. After several iterations of protocols and experimentation with audio and several different video compression formats, ACCEPTED FOR PUBLICATION IN IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS 15 it became clear that a one size fits all protocol was inadequate [42], [19].
Reference: [38] <author> Ron Frederick, </author> <title> Network Video (nv), </title> <institution> Xerox Palo Alto Research Center, </institution> <note> Software on-line 5 </note> . 
Reference-contexts: About the same time that ALF emerged, we and others developed a number of tools to explore the problem of interactive audio and video transport across packet-switched networks [36], [37], <ref> [38] </ref>, [39], [40], [41]. After several iterations of protocols and experimentation with audio and several different video compression formats, ACCEPTED FOR PUBLICATION IN IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS 15 it became clear that a one size fits all protocol was inadequate [42], [19].
Reference: [39] <author> Steven McCanne, </author> <title> A distributed whiteboard for network conferencing, </title> <month> May </month> <year> 1992, </year> <institution> U.C. Berkeley CS268 Computer Networks term project. </institution>
Reference-contexts: About the same time that ALF emerged, we and others developed a number of tools to explore the problem of interactive audio and video transport across packet-switched networks [36], [37], [38], <ref> [39] </ref>, [40], [41]. After several iterations of protocols and experimentation with audio and several different video compression formats, ACCEPTED FOR PUBLICATION IN IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS 15 it became clear that a one size fits all protocol was inadequate [42], [19].
Reference: [40] <author> Thierry Turletti, </author> <title> INRIA Video Conferencing System (ivs), </title> <institution> Institut National de Recherche en Informatique et an Automatique, </institution> <note> Software on-line 6 </note> . 
Reference-contexts: About the same time that ALF emerged, we and others developed a number of tools to explore the problem of interactive audio and video transport across packet-switched networks [36], [37], [38], [39], <ref> [40] </ref>, [41]. After several iterations of protocols and experimentation with audio and several different video compression formats, ACCEPTED FOR PUBLICATION IN IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS 15 it became clear that a one size fits all protocol was inadequate [42], [19].
Reference: [41] <author> Henning Schulzrinne, </author> <title> Voice communication across the Internet: A network voice terminal, </title> <type> Technical Report TR 92-50, </type> <institution> Dept. of Computer Science, University of Massachusetts, Amherst, Massachusetts, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: About the same time that ALF emerged, we and others developed a number of tools to explore the problem of interactive audio and video transport across packet-switched networks [36], [37], [38], [39], [40], <ref> [41] </ref>. After several iterations of protocols and experimentation with audio and several different video compression formats, ACCEPTED FOR PUBLICATION IN IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS 15 it became clear that a one size fits all protocol was inadequate [42], [19].
Reference: [42] <author> Sally Floyd, Van Jacobson, Steven McCanne, Ching-Gung Liu, and Lixia Zhang, </author> <title> A reliable multicast framework for light-weight sessions and application level framing, </title> <booktitle> in Proceedings of SIGCOMM '95, </booktitle> <address> Boston, MA, </address> <month> Sept. </month> <year> 1995, </year> <booktitle> ACM, </booktitle> <pages> pp. 342-356. </pages>
Reference-contexts: After several iterations of protocols and experimentation with audio and several different video compression formats, ACCEPTED FOR PUBLICATION IN IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS 15 it became clear that a one size fits all protocol was inadequate <ref> [42] </ref>, [19]. Instead, a framework based on ALF emerged where a thin base protocol defines the core mechanisms and profile extensions define application-specific semantics.
Reference: [43] <author> Henning Schulzrinne, Steve Casner, Ron Frederick, and Van Jacobson, RTP: </author> <title> A Transport Protocol for Real-Time Applications, </title> <institution> Internet Engineering Task Force, Audio-Video Transport Working Group, </institution> <month> Jan. </month> <year> 1996, </year> <month> RFC-1889. </month>
Reference-contexts: Instead, a framework based on ALF emerged where a thin base protocol defines the core mechanisms and profile extensions define application-specific semantics. The Audio/Video Transport Working Group of the Internet Engineering Task Force (IETF) standardized this base protocol in the Real-time Transport Protocol or RTP <ref> [43] </ref> and developed a profile for Audio and Video conferences with minimal control [44] along with a number of payload format standards for specific applications like H.261, JPEG, MPEG, etc. A.
Reference: [44] <author> Henning Schulzrinne, </author> <title> RTP Profile for Audio and Video Conferences with Minimal Control, </title> <institution> Internet Engineering Task Force, Audio-Video Transport Working Group, </institution> <month> Jan. </month> <year> 1996, </year> <month> RFC-1890. </month>
Reference-contexts: The Audio/Video Transport Working Group of the Internet Engineering Task Force (IETF) standardized this base protocol in the Real-time Transport Protocol or RTP [43] and developed a profile for Audio and Video conferences with minimal control <ref> [44] </ref> along with a number of payload format standards for specific applications like H.261, JPEG, MPEG, etc. A. The Real-time Transport Protocol RTP defines much of the protocol architecture necessary for video transmission over a multipoint packet network.
Reference: [45] <author> J. Postel, </author> <title> User Datagram Protocol, ARPANET Working Group Requests for Comment, </title> <institution> DDN Network Information Center, USC/Information Sciences Institute, </institution> <month> Aug. </month> <year> 1980, </year> <month> RFC-768. </month>
Reference-contexts: A. The Real-time Transport Protocol RTP defines much of the protocol architecture necessary for video transmission over a multipoint packet network. An RTP session represents a collection of two or more end systems sending data and control information to each other over two distinct underlying transport channels. For UDP <ref> [45] </ref> over IP Mul-ticast, these two underlying transport channels are mapped onto two distinct UDP port numbers sharing a common IP multicast group address. An active source transmits its signal by generating packets on the data channel that conform to the payload format specification for the underlying compression format.
Reference: [46] <author> Van Jacobson, </author> <title> SIGCOMM '94 Tutorial: Multimedia conferencing on the Internet, </title> <month> Aug. </month> <year> 1994. </year>
Reference-contexts: To counteract delay variances induced by the network, each receiver dynamically adjusts the amount of playback buffering in order to reconstruct the sender's original timing while minimizing delay. This playback point algorithm can be extended to carry out cross media synchronization <ref> [46] </ref> by aligning each individual media with the media that has the maximal playback point. Unfortunately, RTP has no notion of layered streams. In particular, the use of multiple IP multicast addresses in RLM requires that the layered bit stream be striped across distinct RTP sessions.
Reference: [47] <author> Michael F. Speer and Steven McCanne, </author> <title> RTP usage with Layered Multimedia Streams, </title> <institution> Internet Engineering Task Force, Audio-Video Transport Working Group, </institution> <month> Mar. </month> <year> 1996, </year> <note> Internet Draft expires 9/1/96. </note>
Reference-contexts: An effort is currently underway based in part on the work presented in this paper to modify RTP to allow a single session to span multiple underlying network channels [11], <ref> [47] </ref>. Our proposed change is an extension to RTP that allows a participant to use one Source-ID consistently across the logically distinct RTP sessions comprising the hierarchy. <p> Accordingly, we run the Source-ID allocation and collision detection algorithm only on the base layer, and likewise, transmit sender identification information only on the base layer. These changes are currently under review by the IETF <ref> [47] </ref>. B. The PVH Framing Protocol The flexibility of RTP's ALF-based framework gives us the freedom to optimize the PVH framing protocol for robust interaction with the underlying network. We based our framing protocol in part on our work adapting H.261 for resilient packet transmission in vic.
Reference: [48] <author> John K. Ousterhout, </author> <title> Tcl and the Tk Toolkit, </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: V. IMPLEMENTATION STATUS The PVH codec, spatio-temporal layering, and RTP-based packetization scheme are all implemented in an experimental version of our video conferencing application vic. The PVH codec and framing protocol are implemented as a modular C++ object in the Tcl/Tk-based <ref> [48] </ref> multimedia toolkit used to build vic. We implemented the RLM protocol in our network simulation testbed [49] and carried out a simulation study reported in [11], [14]. Even with RLM fully integrated into vic, the current framework is still experimental.
Reference: [49] <author> Steven McCanne and Sally Floyd, </author> <title> The LBNL Network Simulator, </title> <institution> Lawrence Berkeley Laboratory, </institution> <note> Software on-line 7 </note> . 
Reference-contexts: The PVH codec and framing protocol are implemented as a modular C++ object in the Tcl/Tk-based [48] multimedia toolkit used to build vic. We implemented the RLM protocol in our network simulation testbed <ref> [49] </ref> and carried out a simulation study reported in [11], [14]. Even with RLM fully integrated into vic, the current framework is still experimental. We are just beginning to understand the interaction between RLM and other adaptive congestion control schemes in the Internet (e.g., TCP slow start).
Reference: [50] <author> Lixia Zhang, Steve Deering, Deborah Estrin, Scott Shenker, and Daniel Zappala, RSVP: </author> <title> A new resource reservation protocol, </title> <journal> IEEE Network, </journal> <volume> vol. 7, </volume> <pages> pp. 8-18, </pages> <month> Sept. </month> <year> 1993. </year> <note> 5 ftp://ftp.parc.xerox.com/net-research 6 http://www.inria.fr/rodeo/ivs.html 7 http://www-nrg.ee.lbl.gov/ns/ </note>
Reference-contexts: For example, we might distribute the UCB MBone seminar by sending 32 kb/s to the world scope, 128 kb/s to the well-connected MBone, 256 kb/s across our campus network, and 1 Mb/s throughout the department network. PVH can also be used in tandem with the Resource ReserVation Protocol (RSVP) <ref> [50] </ref>, which supports the notion of layered reservations. In this approach, receivers negotiate explicitly with the network for bandwidth by adjusting their reservation to the maximum number of layers that the network can deliver [3]. ACCEPTED FOR PUBLICATION IN IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS 18 VI.
References-found: 50

