URL: http://meru.uwyo.edu/~karl/papers/j6.ps
Refering-URL: http://meru.uwyo.edu/~karl/pubs.html
Root-URL: 
Email: karl@index.uwyo.edu patb@astro.psu.edu  
Phone: 3682 0525  (307) 766-4258 (814) 863-5505  
Title: Automated Acquisition of User Preferences  
Author: L. Karl Branting Patrick S. Broos 
Address: Box  82071 University Park, PA 16802  
Affiliation: Department of Computer Science Department of Astronomy University of Wyoming Pennsylvania State University  Davey Laboratory Laramie, Wy  
Abstract: Decision support systems often require knowledge of users' preferences. However, preferences may vary among individual users or be difficult for users to articulate. This paper describes how user preferences can be acquired in the form of preference predicates by a learning apprentice system and proposes two new instance-based algorithms for preference predicate acquisition: 1ARC and Compositional Instance-Based Learning (CIBL). An empirical evaluation using simulated preference behavior indicated that the instance-based approaches are preferable to decision-tree induction and perceptrons as the learning component of a learning apprentice system if representation of the relevant characteristics of problem-solving states requires a large number of attributes, if attributes interact in a complex fashion, or if there are very few training instances. Conversely, decision-tree induction or perceptron learning is preferable if there are a 
Abstract-found: 1
Intro-found: 1
Reference: [Aha, 1989] <author> Aha, D. </author> <year> (1989). </year> <title> Incremental, instance-based learning of independent and graded concepts. </title> <booktitle> In Proceedings of the Sixth International Workshop on Machine Learning, </booktitle> <pages> pages 387-391. </pages>
Reference-contexts: Finally, a potential weakness of the instance-based approaches is that both depend on a Euclidean distance function. Instance-based methods that use Euclidean distance functions typically are sensitive to irrelevant features <ref> [Aha, 1989, Aha and Goldstone, 1990] </ref>. In summary, the characteristics of the arc representation of preference instances Automated Acquisition of User Preferences 13 A C E Feature value Quality and P Q (D,E). Concatenating CD with BC permits CIBL to conclude that P Q (B,D).
Reference: [Aha, 1990] <author> Aha, D. </author> <year> (1990). </year> <title> A Study of Instance-Based Algorithms for Supervised Learning Tasks. </title> <type> PhD thesis, </type> <institution> University of California at Irvine. </institution>
Reference-contexts: Under these circumstances, instanced-based learning methods are sometimes more effective. 2.1 Instance-Based Learning of Preference Predicates Instance-based learning (IBL) is a strategy in which concepts are represented by exemplars rather than by generalizations induced from those exemplars <ref> [Aha, 1990, Stanfill and Waltz, 1986] </ref>. Perhaps the simplest form of instance-based learning is Automated Acquisition of User Preferences 6 k-nearest-neighbor (k-NN) classification, which classifies a new instance according to the majority classification of its k nearest neighbors in feature space. <p> Perhaps the simplest form of instance-based learning is Automated Acquisition of User Preferences 6 k-nearest-neighbor (k-NN) classification, which classifies a new instance according to the majority classification of its k nearest neighbors in feature space. In most recent IBL systems, k = 1 <ref> [Aha, 1990] </ref>. 1ARC is a 1-NN strategy for learning preference predicates that uses a representation of training instances as arcs in feature space.
Reference: [Aha, 1992] <author> Aha, D. </author> <year> (1992). </year> <title> Generalizing from case studies: A case study. </title> <booktitle> In Proceedings of the Ninth International Workshop on Machine Learning, </booktitle> <pages> pages 1-10. </pages>
Reference-contexts: Decision tree induction algorithms such as ID3 are suitable for nonlinearly separable data. However, the performance of decision tree induction algorithms has been shown to be sometimes weaker than that of instance-based algorithms when the training set is sparse or the concept being learned is "irregular" <ref> [Aha, 1992] </ref>. Under these circumstances, instanced-based learning methods are sometimes more effective. 2.1 Instance-Based Learning of Preference Predicates Instance-based learning (IBL) is a strategy in which concepts are represented by exemplars rather than by generalizations induced from those exemplars [Aha, 1990, Stanfill and Waltz, 1986].
Reference: [Aha and Goldstone, 1990] <author> Aha, D. W. and Goldstone, R. L. </author> <year> (1990). </year> <title> Learning attribute relevance in context in instance-based learning algorithms. </title> <booktitle> In Twelfth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 141-149. </pages>
Reference-contexts: Finally, a potential weakness of the instance-based approaches is that both depend on a Euclidean distance function. Instance-based methods that use Euclidean distance functions typically are sensitive to irrelevant features <ref> [Aha, 1989, Aha and Goldstone, 1990] </ref>. In summary, the characteristics of the arc representation of preference instances Automated Acquisition of User Preferences 13 A C E Feature value Quality and P Q (D,E). Concatenating CD with BC permits CIBL to conclude that P Q (B,D).
Reference: [Aho et al., 1974] <author> Aho, A., Hopcroft, J., and Ullman, J. </author> <year> (1974). </year> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley Publishing Co. </publisher>
Reference-contexts: CIBL differs from 1ARC in that it can construct a path between two new objects by sequentially connecting multiple training instances. CIBL uses the Dijkstra algorithm <ref> [Aho et al., 1974] </ref> to Automated Acquisition of User Preferences 8 find the least-cost path, assuming that the path from the tail to the head of a training instance has zero cost and all other portions of the path have a cost equal to their Euclidean length.
Reference: [Barrett and Thomas, 1991] <author> Barrett, J. D. and Thomas, R. C. </author> <year> (1991). </year> <title> An algorithm for the support of telescope microscheduling. </title> <journal> Publications of the Astronomical Society of the Pacific, </journal> <volume> 103 </volume> <pages> 1218-1230. </pages>
Reference-contexts: In particular, astronomers can neither specify a set of rules for choosing between any two proposed schedules nor formulate a merit function that measures the relative quality of schedules. Moreover, individual astronomers appear to differ significantly in their preferences. Previous approaches to automated telescope scheduling [Johnston, 1989] <ref> [Barrett and Thomas, 1991] </ref> have cast the problem as a constraint satisfaction problem (CSP). The CSP framework provides a useful representation of hard constraints.
Reference: [Broos, 1993] <author> Broos, P. </author> <year> (1993). </year> <title> An expert system for telescope scheduling. </title> <type> Master's thesis, </type> <institution> University of Wyoming. </institution> <note> Automated Acquisition of User Preferences 41 </note>
Reference-contexts: This scheme does not emulate all of the scheduling strategies employed by humans. For example, 4 A more detailed description of the Observing Assistant is set forth in <ref> [Broos, 1993] </ref>. Automated Acquisition of User Preferences 25 humans may employ complex backtracking steps such as switching the position of two objects already in the schedule. A general-purpose schedule editor in OA allows the human to make complex changes to the schedule by hand.
Reference: [Callan et al., 1991] <author> Callan, J., Fawcett, T., and Rissland, E. </author> <year> (1991). </year> <title> Adaptive case-based reasoning. </title> <booktitle> In Proceedings of the Third DARPA Case-Based Reasoning Workshop, </booktitle> <pages> pages 179-190. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The state-preference method can be implemented through perceptron learning. However, these approaches are not well-suited to all possible preference predicates. The state preference method presupposes that the underlying evaluation function Q has an accurate linear approximation. However, in many domains preference predicates have no linear approximation <ref> [Callan et al., 1991] </ref>. Decision tree induction algorithms such as ID3 are suitable for nonlinearly separable data.
Reference: [Dent et al., 1992] <author> Dent, L., Boticario, J., McDermott, J., Mitchell, T., and Zabowski, D. </author> <year> (1992). </year> <title> A personal learning apprentice. </title> <booktitle> In Proceedings of Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 96-103, </pages> <address> San Jose, CA. </address> <publisher> AAAI Press/MIT Press. </publisher>
Reference-contexts: Systems that engage in this form of learning are termed learning apprentice systems [Mitchell et al., 1985]. Learning apprentice systems have been developed for VLSI design [Mahadevan et al., 1993], acquisition of "interface agents" [Maes and Kozierok, 1993], and calendar management <ref> [Dent et al., 1992] </ref>. An important form of knowledge that can be acquired by observing users' decisions is knowledge of users' preferences. In configuration tasks such as design or scheduling, for example, there may be numerous configurations that satisfy all applicable hard constraints. <p> Automated acquisition of users' preferences is particularly important when users differ in their individual preferences or are unable to articulate the precise preference criteria that they use. Under these circumstances the most promising approach is to develop a learning apprentice system capable of forming "personalized knowledge-based systems" <ref> [Dent et al., 1992] </ref>.
Reference: [Dhar and Ranganathan, 1990] <author> Dhar, V. and Ranganathan, N. </author> <year> (1990). </year> <title> Integer programming vs expert systems: an experimental comparison. </title> <journal> Communications of the ACM, </journal> <volume> 33(3) </volume> <pages> 323-336. </pages>
Reference: [Feldman and Golumbic, 1989] <author> Feldman, R. and Golumbic, M. </author> <year> (1989). </year> <title> Constraint satisfiability algorithms for interactive student scheduling. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1010-1015. </pages>
Reference: [Freuder, 1989] <author> Freuder, E. </author> <year> (1989). </year> <title> Partial constraint satisfaction. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 278-283. </pages>
Reference: [Johnston, 1989] <author> Johnston, M. D. </author> <year> (1989). </year> <title> Knowledge based telescope scheduling. In Heck, </title> <editor> A. and Murtaghn, F., editors, </editor> <title> Knowledge-Based Systems in Astronomy. Springer-Verlag. Automated Acquisition of User Preferences 42 </title>
Reference-contexts: In particular, astronomers can neither specify a set of rules for choosing between any two proposed schedules nor formulate a merit function that measures the relative quality of schedules. Moreover, individual astronomers appear to differ significantly in their preferences. Previous approaches to automated telescope scheduling <ref> [Johnston, 1989] </ref> [Barrett and Thomas, 1991] have cast the problem as a constraint satisfaction problem (CSP). The CSP framework provides a useful representation of hard constraints. <p> Many such scheduling systems also provide facilities for encoding preferences and for using those preferences to guide a state space search [Zweben et al., 1992, Feldman and Golumbic, 1989, Freuder, 1989, Dhar and Ranganathan, 1990, Johnston, 1989]. For example, in SPIKE <ref> [Johnston, 1989] </ref>, a system used to schedule observations on the Hubble Space Telescope, hard constraints and preferences are encoded as suitability functions taking on non-negative values. All the suitability functions are multiplied together to form a total suitability function that is used to choose between proposed schedules.
Reference: [Maes and Kozierok, 1993] <author> Maes, P. and Kozierok, R. </author> <year> (1993). </year> <title> Learning interface agents. </title> <booktitle> In Proceedings of Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 459-466, </pages> <address> Washington, D.C. </address> <publisher> AAAI Press/MIT Press. </publisher>
Reference-contexts: Systems that engage in this form of learning are termed learning apprentice systems [Mitchell et al., 1985]. Learning apprentice systems have been developed for VLSI design [Mahadevan et al., 1993], acquisition of "interface agents" <ref> [Maes and Kozierok, 1993] </ref>, and calendar management [Dent et al., 1992]. An important form of knowledge that can be acquired by observing users' decisions is knowledge of users' preferences. In configuration tasks such as design or scheduling, for example, there may be numerous configurations that satisfy all applicable hard constraints.
Reference: [Mahadevan et al., 1993] <author> Mahadevan, S., Mitchell, T., Mostow, J., Steinberg, L., and Tadepalli, P. </author> <year> (1993). </year> <title> An apprentice-based approach to knowledge acquisition. </title> <journal> Artificial Intelligence, </journal> <volume> 64(1). </volume>
Reference-contexts: Systems that engage in this form of learning are termed learning apprentice systems [Mitchell et al., 1985]. Learning apprentice systems have been developed for VLSI design <ref> [Mahadevan et al., 1993] </ref>, acquisition of "interface agents" [Maes and Kozierok, 1993], and calendar management [Dent et al., 1992]. An important form of knowledge that can be acquired by observing users' decisions is knowledge of users' preferences.
Reference: [Mitchell et al., 1985] <author> Mitchell, T., Mahadevan, S., and Steinberg, L. </author> <year> (1985). </year> <title> LEAP: A learning apprentice for VLSI design. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: One approach to reducing these costs is to design systems that can acquire knowledge by observing human problem-solving steps during normal use of the system. Systems that engage in this form of learning are termed learning apprentice systems <ref> [Mitchell et al., 1985] </ref>. Learning apprentice systems have been developed for VLSI design [Mahadevan et al., 1993], acquisition of "interface agents" [Maes and Kozierok, 1993], and calendar management [Dent et al., 1992]. An important form of knowledge that can be acquired by observing users' decisions is knowledge of users' preferences.
Reference: [Quinlan, 1983] <author> Quinlan, J. R. </author> <year> (1983). </year> <title> Learning efficient classification procedures and their application to chess end games. </title> <editor> In Carbonell, J. G., Michalski, R. S., and Mitchell, T. M., editors, </editor> <booktitle> Machine Learning, </booktitle> <volume> volume 1, </volume> <pages> pages 463-482. </pages> <publisher> Tioga, </publisher> <address> Palo Alto, CA. </address>
Reference-contexts: relevant characteristics of problem-solving 9 A well-known illustration of the dependence of inductive learning techniques on the representation of instances is Quinlan's experience that devising a set of derived features for chess board positions sufficient to enable ID3 to induce a decision tree for "lost in 3-ply" required 2 person-months <ref> [Quinlan, 1983] </ref>. Automated Acquisition of User Preferences 37 states, (2) these state characteristics can be adequately represented as an attribute vector, but (3) users differ as to or are unable to articulate evaluation criteria for problem solving states in terms of these attributes.
Reference: [Quinlan, 1986] <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106. </pages>
Reference-contexts: One approach has been to use decision tree induction algorithms, such as ID3 <ref> [Quinlan, 1986] </ref>, to induce a general representation for P Q . <p> summarize an entire linear region of feature space, i.e., the 1ARC procedure using a single arc parallel to the gradient of a linear function will correctly rank any testing instance in terms of that linear function. 2 By contrast, the standard method for applying decision trees to numerical feature spaces, <ref> [Quinlan, 1986] </ref>, (described in more detail below) entails division of feature space into hyper-rectangular regions. For example, given a single instance P Q (X; Y ), this approach finds a hyperplane that divides feature space into two regions: one containing X and one containing Y . <p> Suppose that we are given the following preference instances as training data: P Q (A,B), P Q (B,C), P Q (C,D), and P Q (D,E). Under the standard approach to applying decision trees to numerical feature spaces described in <ref> [Quinlan, 1986] </ref>, each point P in feature space would be represented as a 4-element vector v 2 f0; 1g 4 , where the first element is 1 if P &gt; F 1 and 0 otherwise, the second element is 1 if P &gt; F 2 and Automated Acquisition of User Preferences
Reference: [Quinlan, 1993] <author> Quinlan, R. </author> <year> (1993). </year> <title> C4.5: Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: [Stanfill and Waltz, 1986] <author> Stanfill, C. and Waltz, D. </author> <year> (1986). </year> <title> Toward memory-based reasoning. </title> <journal> Communications of the ACM, </journal> <volume> 29(12). </volume> <booktitle> Automated Acquisition of User Preferences 43 </booktitle>
Reference-contexts: Under these circumstances, instanced-based learning methods are sometimes more effective. 2.1 Instance-Based Learning of Preference Predicates Instance-based learning (IBL) is a strategy in which concepts are represented by exemplars rather than by generalizations induced from those exemplars <ref> [Aha, 1990, Stanfill and Waltz, 1986] </ref>. Perhaps the simplest form of instance-based learning is Automated Acquisition of User Preferences 6 k-nearest-neighbor (k-NN) classification, which classifies a new instance according to the majority classification of its k nearest neighbors in feature space.
Reference: [Utgoff and Clouse, 1991] <author> Utgoff, P. </author> <title> and Clouse (1991). Two kinds of training information for evaluation function learning. </title> <booktitle> In Proceedings of Ninth National Conference on Artificial Intelligence, </booktitle> <pages> pages 596-600, </pages> <address> Anaheim. </address> <publisher> AAAI Press/MIT Press. </publisher>
Reference-contexts: Previous approaches to acquisition of preference predicates from sets of training Automated Acquisition of User Preferences 5 instances have used inductive learning methods to form generalizations from sets of training instances <ref> [Utgoff and Saxena, 1987, Utgoff and Clouse, 1991] </ref>. One approach has been to use decision tree induction algorithms, such as ID3 [Quinlan, 1986], to induce a general representation for P Q . <p> An alternative approach, termed the state preference method, uses parameter adjustment to learn a set of feature weights W such that for every training instance, P Q (x; y), W (F (x) F (y)) &gt; 0, where F (n) is a vector of numeric attributes representing state n <ref> [Utgoff and Clouse, 1991] </ref>. The state-preference method can be implemented through perceptron learning. However, these approaches are not well-suited to all possible preference predicates. The state preference method presupposes that the underlying evaluation function Q has an accurate linear approximation.
Reference: [Utgoff and Saxena, 1987] <author> Utgoff, P. and Saxena, S. </author> <year> (1987). </year> <title> Learning a preference predicate. </title> <booktitle> In Proceedings of the Fourth International Workshop on Machine Learning, </booktitle> <pages> pages 115-121. </pages>
Reference-contexts: astronomical scheduling, explains why acquisition of user preferences is important for an automated assistant for this task, and presents preliminary results indicating that automated preference acquisition is feasible for tasks of this type. 2 Techniques for Acquiring User Preferences Knowledge of users' preferences can be expressed as a preference predicate <ref> [Utgoff and Saxena, 1987] </ref> P Q (x; y) [Q (x) &gt; Q (y)] "state x is preferred to state y", where Q (s) is an evaluation function that expresses the "quality" of state s. <p> Previous approaches to acquisition of preference predicates from sets of training Automated Acquisition of User Preferences 5 instances have used inductive learning methods to form generalizations from sets of training instances <ref> [Utgoff and Saxena, 1987, Utgoff and Clouse, 1991] </ref>. One approach has been to use decision tree induction algorithms, such as ID3 [Quinlan, 1986], to induce a general representation for P Q .
Reference: [Zweben et al., 1992] <author> Zweben, M., Davis, E., Daun, B., and Deale, M. </author> <year> (1992). </year> <title> Rescheduling with iterative repair. </title> <type> Technical Report FIA-92-05, </type> <institution> NASA Ames Research Center. </institution>
References-found: 23

