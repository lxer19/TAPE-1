URL: http://theory.lcs.mit.edu/~harchol/Papers/tools.ps
Refering-URL: http://theory.lcs.mit.edu/~harchol/Papers/papers.html
Root-URL: 
Email: harchol@theory.lcs.mit.edu  fcrovella,murtag@bu.edu  
Title: On Choosing a Task Assignment Policy for a Distributed Server System  
Author: Mor Harchol-Balter Mark E. Crovella Cristina D. Murta 
Keyword: Task assignment, scheduling, heavy-tailed workloads, high variance, dis tributed servers, queueing theory.  
Note: Supported by the NSF Postdoctoral Fellowship in the Mathematical Sciences. Supported in part by NSF Grants CCR-9501822 and CCR-9706685. Supported by a grant from CAPES, Brazil. Permanent address: Depto.  
Address: NE43-340 Cambridge, MA 02139  Boston, MA 02215  Parana, Curitiba, PR 81531, Brazil.  
Affiliation: Laboratory for Computer Science MIT,  Department of Computer Science Boston University  de Informatica, Universidade Federal do  
Abstract: We consider a distributed server system model and ask which policy should be used for assigning tasks to hosts. In our model each host processes tasks in First-Come-First-Serve order and the task's service demand is known in advance. We consider four task assignment policies commonly proposed for such distributed server systems: Round-Robin, Random, Size-Based, in which all tasks within a give size range are assigned to a particular host, and Dynamic-Least-Work-Remaining, in which a task is assigned to the host with the least outstanding work. Our goal is to understand the influence of task size variability on the decision of which task assignment policy is best. We evaluate the above policies using both analysis and simulation. We find that no one of the above task assignment policies is best and that the answer depends critically on the variability in the task size distribution. In particular we find that when the task sizes are not highly variabile, the Dynamic policy is preferable. However when task sizes show the degree of variability more characteristic of empirically meausred computer workloads, the Size-Based policy is the best choice. We use the resulting observations to argue in favor of a specific size-based policy, SITA-E, that can outperform the Dynamic policy by almost 2 orders of magnitude and can outperform other task assignment policies by many orders of magnitude, under a realistic task size distribution. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Mark E. Crovella and Azer Bestavros. </author> <title> Self-similarity in World Wide Web traffic: Evidence and possible causes. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 5(6) </volume> <pages> 835-846, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: These include, for example: * Unix process CPU requirements measured at Bellcore: 1 ff 1:25 [7]. * Unix process CPU requirements, measured at UC Berkeley: ff 1 [4]. * Sizes of files transferred through the Web: 1:1 ff 1:3 <ref> [1, 3] </ref>. 4 * Sizes of files stored in Unix filesystems: [6]. * I/O times: [11]. * Sizes of FTP transfers in the Internet: :9 ff 1:1 [10]. In most of these cases where estimates of ff were made, 1 ff 2. <p> To focus on the effect of changing variance, we keep the distributional mean fixed (at 3000) and the maximum value fixed (at p = 10 10 ), which correspond to typical values taken from <ref> [1] </ref>. In order to keep the mean constant, we adjust k slightly as ff changes (0 &lt; k 1500). The above parameters are summarized in Table 1. Note that the Bounded Pareto distribution has all its moments finite.
Reference: [2] <author> Mark E. Crovella and Lester Lipsky. </author> <title> Long-lasting transient conditions in simulations with heavy-tailed workloads. </title> <booktitle> In Proceedings of the 1997 Winter Simulation Conference, </booktitle> <year> 1997. </year>
Reference-contexts: We initially consider an eight host system (h = 8) operating at a utilization () of 0.8. Simulating a server system with heavy-tailed, highly variable service times is difficult because the system approaches steady state very slowly and usually from below <ref> [2] </ref>. This occurs because the running average of task sizes is typically at the outset well below the true mean; the true mean isn't achieved until enough large tasks arrive. The consequence for a system like our own is that simulation outputs appear more optimistic than they would in steady-state.
Reference: [3] <author> Mark E. Crovella, Murad S. Taqqu, and Azer Bestavros. </author> <title> Heavy-tailed probability distributions in the world wide web. In A Practical Guide To Heavy Tails, </title> <booktitle> chapter 1, </booktitle> <pages> pages 1-23. </pages> <publisher> Chapman & Hall, </publisher> <address> New York, </address> <year> 1998. </year>
Reference-contexts: These include, for example: * Unix process CPU requirements measured at Bellcore: 1 ff 1:25 [7]. * Unix process CPU requirements, measured at UC Berkeley: ff 1 [4]. * Sizes of files transferred through the Web: 1:1 ff 1:3 <ref> [1, 3] </ref>. 4 * Sizes of files stored in Unix filesystems: [6]. * I/O times: [11]. * Sizes of FTP transfers in the Internet: :9 ff 1:1 [10]. In most of these cases where estimates of ff were made, 1 ff 2.
Reference: [4] <author> Mor Harchol-Balter and Allen Downey. </author> <title> Exploiting process lifetime distributions for dynamic load balancing. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 15(3), </volume> <year> 1997. </year>
Reference-contexts: As a concrete example, Figure 2 depicts graphically on a log-log plot the measured distribution of CPU requirements of over a million UNIX processes, taken from paper <ref> [4] </ref>. This distribution closely fits the curve PrfProcess Lifetime &gt; T g = 1=T: In [4] it is shown that this distribution is present in a variety of computing environments, including instructional, reasearch, and administrative environments. In fact, heavy-tailed distributions appear to fit many recent measurements of computing systems. <p> As a concrete example, Figure 2 depicts graphically on a log-log plot the measured distribution of CPU requirements of over a million UNIX processes, taken from paper <ref> [4] </ref>. This distribution closely fits the curve PrfProcess Lifetime &gt; T g = 1=T: In [4] it is shown that this distribution is present in a variety of computing environments, including instructional, reasearch, and administrative environments. In fact, heavy-tailed distributions appear to fit many recent measurements of computing systems. <p> In fact, heavy-tailed distributions appear to fit many recent measurements of computing systems. These include, for example: * Unix process CPU requirements measured at Bellcore: 1 ff 1:25 [7]. * Unix process CPU requirements, measured at UC Berkeley: ff 1 <ref> [4] </ref>. * Sizes of files transferred through the Web: 1:1 ff 1:3 [1, 3]. 4 * Sizes of files stored in Unix filesystems: [6]. * I/O times: [11]. * Sizes of FTP transfers in the Internet: :9 ff 1:1 [10].
Reference: [5] <author> Steven Hotovy, David Schneider, and Timothy O'Donnell. </author> <title> Analysis of the early workload on the cornell theory center ibm sp2. </title> <type> Technical Report 96TR234, </type> <institution> Cornell Theory Center, </institution> <month> January </month> <year> 1996. </year>
Reference-contexts: policies) Table 2: Notation Used in the Paper 15 minutes, a 3-hour queue for tasks of size between 15 minutes and 3 hours, a 6-hour queue, a 12-hour queue and an 18-hour queue, for example. (This example is used in practice at the Cornell Theory Center IBM SP2 job scheduler <ref> [5] </ref>.) In this paper we choose a more formal algorithm for size-based task assignment, which we refer to as SITA-E | Size Interval Task Assignment with Equal Load.
Reference: [6] <author> Gordon Irlam. </author> <title> Unix file size survey - 1993. </title> <note> Available at http://www.base.com/gordoni /ufs93.html, </note> <month> September </month> <year> 1994. </year>
Reference-contexts: These include, for example: * Unix process CPU requirements measured at Bellcore: 1 ff 1:25 [7]. * Unix process CPU requirements, measured at UC Berkeley: ff 1 [4]. * Sizes of files transferred through the Web: 1:1 ff 1:3 [1, 3]. 4 * Sizes of files stored in Unix filesystems: <ref> [6] </ref>. * I/O times: [11]. * Sizes of FTP transfers in the Internet: :9 ff 1:1 [10]. In most of these cases where estimates of ff were made, 1 ff 2.
Reference: [7] <author> W. E. Leland and T. J. Ott. </author> <title> Load-balancing heuristics and process behavior. </title> <booktitle> In Proceedings of Performance and ACM Sigmetrics, </booktitle> <pages> pages 54-69, </pages> <year> 1986. </year>
Reference-contexts: In fact, heavy-tailed distributions appear to fit many recent measurements of computing systems. These include, for example: * Unix process CPU requirements measured at Bellcore: 1 ff 1:25 <ref> [7] </ref>. * Unix process CPU requirements, measured at UC Berkeley: ff 1 [4]. * Sizes of files transferred through the Web: 1:1 ff 1:3 [1, 3]. 4 * Sizes of files stored in Unix filesystems: [6]. * I/O times: [11]. * Sizes of FTP transfers in the Internet: :9 ff 1:1
Reference: [8] <author> Randolph D. Nelson and Thomas K. Philips. </author> <title> An approximation to the response time for shortest queue routing. </title> <journal> Performance Evaluation Review, </journal> <volume> 7(1) </volume> <pages> 181-189, </pages> <year> 1989. </year>
Reference-contexts: This optimality result was extended by Weber [13] to include task size distributions with nondecreasing failure rate. The actual performance of the Shortest-Line policy is not known exactly, but is approximated by Nelson and Phillips <ref> [8] </ref>. These approximations have been exteded to include more general task size distributions than the exponential distribution, however the approxima 2 tions grow less accurate as the variability of the task size distribution increases [9].
Reference: [9] <author> Randolph D. Nelson and Thomas K. Philips. </author> <title> An approximation for the mean response time for shortest queue routing with general interarrival and service times. Performance Evaluation, </title> <booktitle> 17 </booktitle> <pages> 123-139, </pages> <year> 1998. </year>
Reference-contexts: These approximations have been exteded to include more general task size distributions than the exponential distribution, however the approxima 2 tions grow less accurate as the variability of the task size distribution increases <ref> [9] </ref>. In fact as the variability of the task size distribution grows, the Shortest-Line policy is no longer optimal, as proven by Whitt [14].
Reference: [10] <author> Vern Paxson and Sally Floyd. </author> <title> Wide-area traffic: The failure of Poisson modeling. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <pages> pages 226-244, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: * Unix process CPU requirements, measured at UC Berkeley: ff 1 [4]. * Sizes of files transferred through the Web: 1:1 ff 1:3 [1, 3]. 4 * Sizes of files stored in Unix filesystems: [6]. * I/O times: [11]. * Sizes of FTP transfers in the Internet: :9 ff 1:1 <ref> [10] </ref>. In most of these cases where estimates of ff were made, 1 ff 2. In fact, typically ff tends to be close to 1, which represents very high variability in task service requirements. 3 Model and Problem Formulation In this section we describe more precisely our model and problem.
Reference: [11] <author> David L. Peterson and David B. Adams. </author> <title> Fractal patterns in DASD I/O traffic. </title> <booktitle> In CMG Proceedings, </booktitle> <month> December </month> <year> 1996. </year>
Reference-contexts: * Unix process CPU requirements measured at Bellcore: 1 ff 1:25 [7]. * Unix process CPU requirements, measured at UC Berkeley: ff 1 [4]. * Sizes of files transferred through the Web: 1:1 ff 1:3 [1, 3]. 4 * Sizes of files stored in Unix filesystems: [6]. * I/O times: <ref> [11] </ref>. * Sizes of FTP transfers in the Internet: :9 ff 1:1 [10]. In most of these cases where estimates of ff were made, 1 ff 2.
Reference: [12] <author> S. Sozaki and R. Ross. </author> <title> Approximations in finite capacity multiserver queues with poisson arrivals. </title> <journal> Journal of Applied Probability, </journal> <volume> 13 </volume> <pages> 826-834, </pages> <year> 1978. </year>
Reference-contexts: The proof is by induction on i, and is provided in full detail in the Appendix. Fortunately, there exist known approximations for the performance metrics of the M/G/h/FCFS queue. We consider two approximations from the literature given in <ref> [12] </ref> and [16]. Both approximations reduce to almost identical values under our particular input parameters, so we state the 3 Recall, in an M/G/h/FCFS queue, arriving tasks are placed in one central queue in the order they arrive.
Reference: [13] <author> R. W. Weber. </author> <title> On the optimal assignment of customers to parallel servers. </title> <journal> Journal of Applied Probability, </journal> <volume> 15 </volume> <pages> 406-413, </pages> <year> 1978. </year>
Reference-contexts: In the case where task sizes are unknown, the following results exist: Under an exponential task size distribution, the optimality of Shortest-Line task assignment policy (send the task to the host with the shortest queue) has been proven by Winston [15]. This optimality result was extended by Weber <ref> [13] </ref> to include task size distributions with nondecreasing failure rate. The actual performance of the Shortest-Line policy is not known exactly, but is approximated by Nelson and Phillips [8]. <p> The scenario has been considered in which the ages (time in service) of the tasks currently serving are known, so that it is possible to compute an arriving task's expected delay at each queue. In this scenario, Weber <ref> [13] </ref> has shown that the Shortest-Expected-Delay rule is optimal for task size distributions with increasing failure rate, and Whitt [14] has shown that there exist task size distributions for which the Shortest-Expected-Delay rule is not optimal. 2.2 Measurements of task size distributions in computer applications As described in Section 1, we
Reference: [14] <author> Ward Whitt. </author> <title> Deciding which queue to join: Some counterexamples. </title> <journal> Operations Research, </journal> <volume> 34(1) </volume> <pages> 226-244, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: In fact as the variability of the task size distribution grows, the Shortest-Line policy is no longer optimal, as proven by Whitt <ref> [14] </ref>. In the case where the individual task sizes are known, as in our model, equivalent optimality and performance results have not been developed, to the best of our knowledge. <p> In this scenario, Weber [13] has shown that the Shortest-Expected-Delay rule is optimal for task size distributions with increasing failure rate, and Whitt <ref> [14] </ref> has shown that there exist task size distributions for which the Shortest-Expected-Delay rule is not optimal. 2.2 Measurements of task size distributions in computer applications As described in Section 1, we are concerned with how the distribution of task sizes affects the decision of which task assignment policy to use.
Reference: [15] <author> W. Winston. </author> <title> Optimality of the shortest line discipline. </title> <journal> Journal of Applied Probability, </journal> <volume> 14 </volume> <pages> 181-189, </pages> <year> 1977. </year>
Reference-contexts: In the case where task sizes are unknown, the following results exist: Under an exponential task size distribution, the optimality of Shortest-Line task assignment policy (send the task to the host with the shortest queue) has been proven by Winston <ref> [15] </ref>. This optimality result was extended by Weber [13] to include task size distributions with nondecreasing failure rate. The actual performance of the Shortest-Line policy is not known exactly, but is approximated by Nelson and Phillips [8].

References-found: 15

