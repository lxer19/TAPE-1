URL: http://www.ai.mit.edu/people/lola/aa97-online.ps
Refering-URL: http://www.ai.mit.edu/people/lola/publis.html
Root-URL: 
Email: lola@ai.mit.edu  
Title: Modeling Motivations and Emotions as a Basis for Intelligent Behavior  
Author: Dolores Ca namero 
Address: 545, Technology Square Cambridge, MA 02139  
Affiliation: Massachusetts Institute of Technology Artificial Intelligence Laboratory  
Abstract: We report on an experiment to implement an autonomous creature situated in a two-dimensional world, that shows various learning and problem-solving capabilities, within the Society of Mind framework. This goal is approached from a developmental perspective, where phases in the experiment correspond broadly to cognitive stages in the development of an infant. This paper describes the first stage, the creature being a newborn whose behavior is strongly driven by motivational statesimpulses to action based on bodily needsand basic emotionsperipheral and cognitive responsestriggered by the recognition of a significant event. Physiological parameters are used to model both concepts, which are seen by analogy with control systems. Motivations drive behavior selection and organization based on the notions of arousal and satiation, and the exploitation principle. Emotions exert further control by sending hormones that may affect the intensity of the selected behavior, enable it, or prevent it. They also influence the attentional and perception mechanisms. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Abbott, </author> <title> E.A. 1884. Flatland: A Roman of Many Dimensions. </title> <publisher> London: Seeley & Co., Ltd. </publisher>
Reference: <author> Agre, P.E. and Chapman, D. </author> <year> 1990. </year> <title> What Are Plans for?. </title> <editor> In Maes, P. ed. </editor> <title> Designing Autonomous Agents: Theory and Practice from Biology to Engineering and Back, </title> <address> 17-34. Cambridge, MA: </address> <publisher> The MIT Press. </publisher>
Reference-contexts: This use of the exploitation principle allows us to avoid having to program a different behavior for each of the potential incentive stimuli (e.g., go-toward-food, go-toward-water, etc.), without however making use of classical variables. Indeed, ours can be seen as a form of active indexical-functional or deictic representation <ref> (Agre & Chapman 1990) </ref>. Primitive Affects In the next section we briefly examine some theories concerning motivations and emotions in biological systems that have served as a source of inspiration for our design.
Reference: <author> Brooks, R.A. </author> <year> 1991. </year> <title> Intelligence Without Representation. </title> <booktitle> Artificial Intelligence 47(2): </booktitle> <pages> 139-159. </pages>
Reference-contexts: This creature should end developing more complex and clever behavior as a result of its interactions with the world. The incremental design approach we have adopted follows also the principle underlying the subsumption architecture <ref> (Brooks 1991) </ref>. To achieve more and more complex behavior, we will keep adding agents to our creature without modifying the existing onesonly their connections will grow more complex. <p> This notion of agent promotes system decomposition by activitya pattern of interactions with the world <ref> (Brooks 1991) </ref>.
Reference: <editor> Brooks, R.A. and Viola, </editor> <address> P.A. </address> <year> 1990. </year> <title> Network Based Autonomous Robot Motor Control: from Hormones to Learning. </title> <editor> In Eckmiller, R. ed. </editor> <booktitle> Advanced Neural Computers, </booktitle> <pages> 341-348. </pages> <publisher> Elsevier Science Publishers B.V. (North-Holland). </publisher>
Reference-contexts: In extreme cases, this can prevent the execution of the behavior. Previous work by <ref> (Brooks & Viola 1990) </ref> implementing Kravitz's model of hormonal control of behavior in lobsters (Kravitz 1988) used hormones to bias behavior selection in a six-legged robot, controlling this way the gross behavior of the robot; however, hormones did not modify individual behaviors or lower level motor actions.
Reference: <author> Carpenter, G.A. and Grossberg, S. </author> <year> 1988. </year> <title> The ART of Adaptive Pattern Recognition by a Self-Organizing Neural Network. </title> <booktitle> Computer, </booktitle> <month> March: </month> <pages> 77-88. </pages>
Reference-contexts: The only type of recognizers used at this stage are object recognizers. Ab-bott uses two object recognizersa tactile recognizer, and a visual recognizer. These agents use an ART-1 neural net <ref> (Carpenter & Grossberg 1988) </ref> to perform the recognition task. We have arbitrarily set the size of the output (recognition or categorization) layer of both networks to 20 units, although only a few of them are currently used.
Reference: <author> Damasio, A.R. </author> <year> 1994. </year> <title> Descartes' Error. </title> <address> New York, NY: </address> <publisher> G.P. Putnam's Sons. </publisher>
Reference: <author> Dennett, D. </author> <year> 1978. </year> <title> Brainstorms. </title> <address> Cambridge, MA: </address> <publisher> The MIT Press. </publisher>
Reference-contexts: The agent/agency distinction parallels the inside/outside view of a system. Our purpose is to engineer societies of agents in such a way that they look as clever, goal-oriented agencies or intentional systems <ref> (Dennett 1978) </ref> to an external observer.
Reference: <author> Drescher, G.L. </author> <year> 1991. </year> <title> Made-Up Minds: A Constructivist Approach to Artificial Intelligence. </title> <address> Cambridge, MA: </address> <publisher> The MIT Press. </publisher>
Reference-contexts: The fact of using internal motivations and emotional states to drive the creature's behavior and learningamong other thingsdistinguishes our work from other developmental models such as <ref> (Drescher 1991) </ref> and from other tabula rasa approaches to learning. The paper is organized as follows. Next section introduces the experimental setting chosen to implement our ideas. Then, the different agents in charge of sensing, perceiving and acting are presented, to continue with our model of (early) motivations and emotions.
Reference: <author> Kandel, E.R., Schwartz, J.H., Jessell, T.M. </author> <year> 1995. </year> <title> Essentials of Neural Science and Behavior. </title> <institution> Norwalk, CT: Appleton & Lange. </institution>
Reference-contexts: Motivation varies as a function of deprivation. Like classical homeostatic systems, it involves arousal and satiation. Externalincentivestimuli, both innate and learned, are also able to motivate and drive behavior. Motivational states have three functions <ref> (Kandel et al.1995) </ref>: (a) a directing functionthey steer behavior toward, or away from, a specific goal; (b) an activating functionthey increase general alertness and energize the individual to action; and (c) an organizing functionthey combine individual behavioral components into a coherent, goal-oriented behavioral sequence. Emotional states. <p> Emotional states. The status of emotions is far from being clear. The development and expression of an emotion seems to imply three major components <ref> (Kandel et al.1995) </ref>: (a) the recognition of an important event; (b) a conscious emotional experience in the cortex that mediates outgoing signals to peripheral structures; and (c) reflexive autonomic and visceral responses.
Reference: <author> Kravitz, </author> <title> E.A. </title> <booktitle> 1988. Hormonal Control of Behavior: Amines and the Biasing of Behavioral Output in Lobsters, Science 241, </booktitle> <month> September 30: </month> <pages> 1775-1781. </pages>
Reference-contexts: In extreme cases, this can prevent the execution of the behavior. Previous work by (Brooks & Viola 1990) implementing Kravitz's model of hormonal control of behavior in lobsters <ref> (Kravitz 1988) </ref> used hormones to bias behavior selection in a six-legged robot, controlling this way the gross behavior of the robot; however, hormones did not modify individual behaviors or lower level motor actions.
Reference: <author> Maes, P. </author> <year> 1990. </year> <title> Situated Agents Can Have Goals. </title> <editor> In Maes, P. ed. </editor> <title> Designing Autonomous Agents: Theory and Practice from Biology to Engineering and Back, </title> <address> 49-70. Cambridge, MA: </address> <publisher> The MIT Press. </publisher>
Reference: <author> Maes, P. </author> <year> 1991. </year> <title> A Bottom-Up Mechanism for Behavior Selection in an Artificial Creature. </title> <editor> In Meyer, J.-A. & Wilson, S.W., eds. </editor> <booktitle> From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> 238-246. </pages> <address> Cambridge, MA: </address> <publisher> The MIT Press. </publisher>
Reference-contexts: Hand's motor actions are open, close, push, and pull. Foot's motor actions are go-up, go-left, go-down, go-right (all with varying intensities), and stop. The mouth's only action is ingest. Behaviors Our behaviors resemble to the notion of competence modules in <ref> (Maes 1991) </ref>. As in her case, we distinguish between consumatory and appetitive behaviors. Behavior agents correspond to consumatory behaviorsthose contributing to the balance of resources that ensure a creature's self-sufficiencywhile appetitive behaviors are realized by managers agents.
Reference: <author> McFarland, D. </author> <year> 1995. </year> <title> Opportunity versus Goals in Robots, Animals and People. </title> <editor> In Roitblat, H.L., Meyer, J.-A. eds. </editor> <booktitle> Comparative Approaches to Cognitive Science. </booktitle> <pages> 415-433. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: As in her case, we distinguish between consumatory and appetitive behaviors. Behavior agents correspond to consumatory behaviorsthose contributing to the balance of resources that ensure a creature's self-sufficiencywhile appetitive behaviors are realized by managers agents. Behaviors implement goal-achieving systems <ref> (McFarland 1995) </ref>a system that can recognize a stimulus or goal (or at least change its behavior) when it encounters it, but the process of arriving at the goal is determined by the environment. According to McFarland (p. 421), the main characteristic of goal-achieving behavior is preprogrammed recognition. <p> In our implementation, this simulus has the form of one or several agentsmaps or sensorsthat the manager will try to turn into an active state. Therefore, manager agents exhibit a goal-directed behavior <ref> (McFarland 1995) </ref>, that is guided by an explicit representation of the goal to be achieved. Managers are exploited by proto-specialists, and they can exploit other managers, behaviors, or simple motor actions.
Reference: <author> Minsky, M. </author> <year> 1985. </year> <title> The Society of Mind. </title> <address> New York, NY: </address> <publisher> Simon & Schuster. </publisher> <address> Pribram, K,H. </address> <year> 1984. </year> <note> Emotion: A Neurobehavioral Analysis. In Scherer, </note> <author> K.R. & Ekman, P. </author> <title> Approaches to Emotion, </title> <address> 13-38. Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum. </publisher>
Reference-contexts: Creatures as Societies of Agents A creature consists of societies of agents of many different types. We will adopt the broad definition of agent given in <ref> (Minsky 1985, p. 326) </ref>: any part or process of the mind that by itself is simple enough to understandeven though the interactions among groups of such agents may produce phenomena that are much harder to understand. <p> The notion of agent is to be (defclass agent () ((name ... :initarg :name) (owner ... :initarg :owner) (stimulus ... :initarg :stimulus) (activation ... :initarg :activation) (state ... :initform 0))) seen by opposition to that of an agency <ref> (Minsky 1985, p. 326) </ref>any assembly of parts considered in terms of what it can accomplish as a unit, without regard to what each of its parts does by itself. The agent/agency distinction parallels the inside/outside view of a system. <p> Sensors A sensor is an agent whose inputs are sensitive to stimuli that come from the world outside the brain <ref> (Minsky 1985, 11.1) </ref>. Abbott has three kinds of sensorssomatic, tactile, and visual. Somatic sensors provide Abbott with information about different aspects of its own body. <p> Recognizers Recognizer agents are higher-level processors of sensory data. Their output thus carries some information on complex objects, rather than on isolated features. A recognizer is an agent that becomes active in response to a particular pattern of input signals <ref> (Minsky 1985, 19.6) </ref>. The only type of recognizers used at this stage are object recognizers. Ab-bott uses two object recognizersa tactile recognizer, and a visual recognizer. These agents use an ART-1 neural net (Carpenter & Grossberg 1988) to perform the recognition task. <p> Direction-nemes Direction-nemes are agents associated with a particular direction or region in space <ref> (Minsky 1985, 24.6) </ref>. Abbott has eight direction-nemes: top, top-left, left, bottom-left, bottom, bottom-right, right, and top-right. Each of them can only read the information in one of the positions of the vector that constitutes the output of the different sensors it can communicate with. <p> The effect of these agents is that Abbott can only perceive and act on the world within a spatial framework, i.e., all the external objects and events have a spatial stamp inherently associated with them. Maps Maps closely resemble picture-frames <ref> (Minsky 1985, 24.7) </ref>a type of frame whose terminals are controlled by direction-nemes, and that is particularly suited to representing certain kinds of spatial information. Like picture-frames, maps are fed by direction-nemes; all maps share the same terminals, i.e., the same direction-nemes. <p> Managers Manager agentsor societies of agentsimplement very simple skills that can be seen to correspond to appetitive behaviors in the ethology literature, i.e., behaviors that make more likely that the conditions that allow to satisfy a basic needthe presence of a stimulushold. Examples of manager agents in <ref> (Minsky 1985) </ref> are Find, Get, Put, Grasp, etc. Abbott's main managers are the finder, look-for, and go-toward agents. <p> Contrary to behaviors, managers do not have preprogrammed recognition of an incentive stimulus; rather, we have implemented them by taking advantage of the exploitation principle,the act of one agency making use of the activity of another agency, without understanding how it works <ref> (Minsky 1985, 4.5, 16.7) </ref>. Managers can respond to any stimulusor rather simulus (16.8)that another agent tells them to attend to, or in other words, makes them hallucinate. <p> They also switch states and activities very easily, as if unable to maintain their attention in one activity for a long period in the face of novel stimuli or new internal needs. These primitive emotional states Minsky calls proto-specialistsgenetically constructed subsystems responsible for some of an animal's instinctive behavior <ref> (Minsky 1985, 16.3) </ref>. Proto-specialists control what happens in an infant's brain. As children grow older, the context and their own experience teaches them to control these proto-specialists and to feel and behave as appropriate in every circumstance. <p> Many more agents need to be added yet. In the first place, we need adequate memory agents that make learning possible. We have started investigating a model of memory based on K-lines <ref> (Minsky 1985, 8.1) </ref> and their related controlling agents that allow Abbott to remember previous partial mental states that were useful in a given situation for some reason. Again, motivations and emotions constitute a key factor in determining what has to be remembered and why.
Reference: <author> Russell, S.J. and Norvig, P. </author> <year> 1995. </year> <title> Artificial Intelligent: A Modern Approach. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall. </publisher>
Reference-contexts: An agent can thus be considered as a function that maps percepts into actions <ref> (Russell & Norvig 1995) </ref>, where an action can be an observable activity that affects the external world, or turning another agent on of off. This notion of agent promotes system decomposition by activitya pattern of interactions with the world (Brooks 1991).
Reference: <author> Schachter, S. </author> <year> 1964. </year> <title> The Interaction of Cognitive and Physiological Determinants of Emotional States. </title> <editor> In Berkowitz, L. ed. </editor> <booktitle> Advances in Experimental Social Psychology Vol. </booktitle> <volume> 1, </volume> <pages> 49-80. </pages> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: <author> Tomkins. S.S. </author> <year> 1984. </year> <note> Affect Theory. In Scherer, </note> <author> K.R. & Ekman, P. </author> <title> Approaches to Emotion, </title> <address> 163-195. Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: With respect to this latter, we adhere to the idea that the affect system provides the primary blueprints for cognition, decision, and action <ref> (Tomkins 1984) </ref>. This creature should end developing more complex and clever behavior as a result of its interactions with the world. The incremental design approach we have adopted follows also the principle underlying the subsumption architecture (Brooks 1991). <p> It thus combines urgency and generality <ref> (Tomkins 1984, p. 164) </ref>. This generality of time, object, intensity, and density of emotions are not the consequence of learning, but rather the structural innate features that make learning possible.
References-found: 17

