URL: http://cs.nyu.edu/cs/faculty/spencer/papers/alonboppanapaper.ps
Refering-URL: http://cs.nyu.edu/cs/faculty/spencer/papers/papers.html
Root-URL: http://www.cs.nyu.edu
Title: An Asymptotic Isoperimetric Inequality  
Author: Noga Alon Ravi Boppana Joel Spencer 
Abstract: For a finite metric space V with a metric , let V n be the metric space in which the distance between (a 1 ; : : : ; a n ) and (b 1 ; : : : ; b n ) is the sum P n i=1 (a i ; b i ). We obtain an asymptotic formula for the logarithm of the maximum possible number of points in V n of distance at least d from a set of half the points of V n , when n tends to infinity and d satisfies d p 1 The Main Results 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Ahlswede, E. Yang and Z. Zhang, </author> <title> Identification via compressed data, </title> <note> to appear. </note>
Reference-contexts: The new aspect of the present work is the finding of the correct constant, giving an asymptotic formula with the right constant for ln f n (d). For a different approach that can yield related results, see <ref> [1] </ref>. As an example illustrating Theorem 1.2 consider the metric space V consisting of three points with equal probability, where the distance between any two is 1.
Reference: [2] <author> V. B. Alekseev, </author> <title> The number of monotone k-valued functions, </title> <journal> Problemy Kibernet. </journal> <note> 28 (1974), 5-24 (in Russian). Correction in Problemy Kibernet. 29 (1974), 248. </note>
Reference-contexts: Definition: The spread constant c is the maximum possible Var [X] over all Lipschitz X. The spread constant appears to be new and may well be of independent interest. Alekseev <ref> [2] </ref> and Engel [12, 13] used a somewhat similar constant to estimate the width of a product of partial orders. We call X optimal if it is Lipschitz with maximum possible variance. <p> We named Lipschitz in honor of Rudolf O. S. Lipschitz (1832-1903), who developed the concept of Lipschitz continuity. Acknowledgments We thank Jeong Han Kim and Charles Epstein for helpful comments. We thank Rodney Canfield for pointing out the references <ref> [2, 12, 13] </ref>, and Prasad Tetali for pointing out the reference [7].
Reference: [3] <author> N. Alon, J. H. Kim, and J. Spencer, </author> <title> Nearly perfect matchings in regular simple hypergraphs, </title> <journal> Israel J. </journal> <note> Mathematics 100 (1997), 171-187. </note>
Reference-contexts: K 1 n 1=2 ]: When d n 1=2 we can write d K 1 n 1=2 = d (1 + o (1)) so that Pr [Y &gt; d] &lt; e d 2 as claimed. 2.4 Large Deviation Inequalities via Martingales The following discussion is similar to the ones in <ref> [6, 18, 3] </ref>. Let X be a random variable with E [X] = 0, Var [X] = 1, and jXj K. For any , 2 + i3 i! Now suppose = o (1).
Reference: [4] <author> N. Alon and M. Krivelevich, </author> <title> Constructive bounds for a Ramsey-type problem, Graphs and Combinatorics, </title> <publisher> in press. </publisher> <pages> 24 </pages>
Reference-contexts: This supplies a tight isoperimetric inequality for the space of all vectors of length n over the alphabet f1; 2; 3g with the Hamming metric, and can be used, for example, to improve the estimate for * in one of the explicit constructions of <ref> [4] </ref> of a K 4 -free graph on N vertices in which any set of at least N 1* vertices contains a triangle. 2 Sublinear Distances In this section we consider the case d = o (n), prove Theorem 1.1, and establish several results on the spread constant. 2.1 Graphs The
Reference: [5] <author> N. Alon and V. D. Milman, </author> <title> 1 , isoperimetric inequalities for graphs, </title> <journal> and superconcentrators, J. Combinatorial Theory Ser. </journal> <volume> B 38 (1985), </volume> <pages> 73-88. </pages>
Reference-contexts: for fixed t 2 (0; m) and d ~ tn, we have f n (d) = e R (t)n (1+o (1)) : We note that it is not difficult to show that for all values of n and d, f n (d) exp [fi (d 2 =n)]: See, for example, <ref> [19, 5, 21, 20, 10, 24] </ref>. The new aspect of the present work is the finding of the correct constant, giving an asymptotic formula with the right constant for ln f n (d). For a different approach that can yield related results, see [1]. <p> This matrix is symmetric, and thus has real eigenvalues. Its smallest eigenvalue is 0, and its second smallest eigenvalue, denoted by 1 , is strictly positive iff G is connected. This eigenvalue appears in certain isoperimetric inequalities for G; see <ref> [5] </ref>. The discussion in [5, p. 76] easily implies that the spread constant c of G satisfies c jEj= 1 . When G is an edge on the vertices 0; 1 an optimal X has X (0) = 0, X (1) = 1. <p> This matrix is symmetric, and thus has real eigenvalues. Its smallest eigenvalue is 0, and its second smallest eigenvalue, denoted by 1 , is strictly positive iff G is connected. This eigenvalue appears in certain isoperimetric inequalities for G; see [5]. The discussion in <ref> [5, p. 76] </ref> easily implies that the spread constant c of G satisfies c jEj= 1 . When G is an edge on the vertices 0; 1 an optimal X has X (0) = 0, X (1) = 1.
Reference: [6] <author> N. Alon and J. Spencer, </author> <title> The Probabilistic Method, </title> <publisher> Wiley, </publisher> <year> 1992. </year>
Reference-contexts: K 1 n 1=2 ]: When d n 1=2 we can write d K 1 n 1=2 = d (1 + o (1)) so that Pr [Y &gt; d] &lt; e d 2 as claimed. 2.4 Large Deviation Inequalities via Martingales The following discussion is similar to the ones in <ref> [6, 18, 3] </ref>. Let X be a random variable with E [X] = 0, Var [X] = 1, and jXj K. For any , 2 + i3 i! Now suppose = o (1).
Reference: [7] <author> S. G. Bobkov and C. Houdre, </author> <title> Variance of Lipschitz functions and an isoperimetric problem for a class of product measures, </title> <booktitle> Bernoulli 2 (1996), </booktitle> <pages> 249-255. </pages>
Reference-contexts: Corollary 3.7 L G n = nL G . Proof. Follows from Theorem 3.6 and induction on n. 2 As another corollary, we deduce that the spread constant tensorizes. Bobkov and Houdre <ref> [7] </ref> proved a similar result. Corollary 3.8 c (G fi H) = c (G) + c (H). In particular, c (G n ) = c (G)n. Proof. <p> S. Lipschitz (1832-1903), who developed the concept of Lipschitz continuity. Acknowledgments We thank Jeong Han Kim and Charles Epstein for helpful comments. We thank Rodney Canfield for pointing out the references [2, 12, 13], and Prasad Tetali for pointing out the reference <ref> [7] </ref>.
Reference: [8] <author> H. F. Bohnenblust, S. Karlin, and L. S. Shapley, </author> <title> Games with continuous, convex pay-off, in Contributions to the Theory of Games vol. </title> <journal> 1 , Annals of Mathematics Studies no. </journal> <volume> 24, </volume> <editor> (H. W. Kuhn and A. W. Tucker, eds.), </editor> <publisher> Princeton Univ. Press (1950), </publisher> <pages> 181-192. </pages>
Reference-contexts: Hence Bernstein has an optimal strategy that is deterministic. Using that observation, it is easy to see that the value of the game is exactly R G (t). Note that Bernstein's strategy domain is the 1-dimensional set R. From the main result of Bohnenblust, Karlin, and Shapley <ref> [8] </ref>, it follows that Lipschitz must have an optimal strategy that is the mixture of only 2 deterministic strategies. In the proof of our lower bound, we have borrowed some ideas from that paper, namely in our choice of the functions Y and Z and the "mixture" W .
Reference: [9] <author> B. Bollobas and I. </author> <title> Leader, An isoperimetric inequality on the discrete torus, </title> <journal> SIAM J. Discrete Math. </journal> <volume> 3 (1990), </volume> <pages> 32-37. </pages>
Reference-contexts: In particular, the set S of (a 1 ; : : : ; a n ) with P n i=1 X (a i ) r has the minimal jB [S; d]j among all S of that size. When G is an even cycle, Bollobas and Leader <ref> [9] </ref> have again given the precise isoperimetric result. Our results are more general but less precise. This tradeoff leads to a tantalizing speculation.
Reference: [10] <author> B. Bollobas and I. </author> <title> Leader, Compressions and isoperimetric inequalities, </title> <journal> J. Combinatorial Theory Ser. </journal> <note> A 56 (1991), 47-62. </note>
Reference-contexts: for fixed t 2 (0; m) and d ~ tn, we have f n (d) = e R (t)n (1+o (1)) : We note that it is not difficult to show that for all values of n and d, f n (d) exp [fi (d 2 =n)]: See, for example, <ref> [19, 5, 21, 20, 10, 24] </ref>. The new aspect of the present work is the finding of the correct constant, giving an asymptotic formula with the right constant for ln f n (d). For a different approach that can yield related results, see [1]. <p> More generally let G be a path on vertices 0; 1; : : : ; k 1, in that order. It is not difficult to prove that X (i) = i for all i is an optimal X. Here Bollobas and Leader <ref> [10] </ref> have given the precise isoperimetric result for all jSj and all d. In particular, the set S of (a 1 ; : : : ; a n ) with P n i=1 X (a i ) r has the minimal jB [S; d]j among all S of that size.
Reference: [11] <author> V. F. Dem'yanov and L. V. Vasil'ev, </author> <title> Nondifferentiable Optimization, Optimization Software, </title> <publisher> Inc., Publications Division, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Being convex and finite, L G is continuous and, further, is left-differentiable and right-differentiable (Rockafellar [22, Theorem 23.1]). Because is compact, L X is convex and differentiable, and X 7! L X () is continous, it follows from Dem'yanov and Vasil'ev <ref> [11, p. 160] </ref> that the right derivative L r G () is the maximum of L 0 X () over all -optimal functions X. Similarly, the left derivative L ` G () is the minimum of L 0 X () over all -optimal functions X.
Reference: [12] <author> K. </author> <title> Engel, Optimal representations of partially ordered sets and a limit Sperner theorem, </title> <editor> Euro-pean J. </editor> <booktitle> Combinatorics 7 (1986), </booktitle> <pages> 287-302. </pages>
Reference-contexts: Definition: The spread constant c is the maximum possible Var [X] over all Lipschitz X. The spread constant appears to be new and may well be of independent interest. Alekseev [2] and Engel <ref> [12, 13] </ref> used a somewhat similar constant to estimate the width of a product of partial orders. We call X optimal if it is Lipschitz with maximum possible variance. <p> We named Lipschitz in honor of Rudolf O. S. Lipschitz (1832-1903), who developed the concept of Lipschitz continuity. Acknowledgments We thank Jeong Han Kim and Charles Epstein for helpful comments. We thank Rodney Canfield for pointing out the references <ref> [2, 12, 13] </ref>, and Prasad Tetali for pointing out the reference [7].
Reference: [13] <author> K. </author> <title> Engel, Sperner Theory, </title> <publisher> Cambridge Univ. Press, </publisher> <year> 1997. </year>
Reference-contexts: Definition: The spread constant c is the maximum possible Var [X] over all Lipschitz X. The spread constant appears to be new and may well be of independent interest. Alekseev [2] and Engel <ref> [12, 13] </ref> used a somewhat similar constant to estimate the width of a product of partial orders. We call X optimal if it is Lipschitz with maximum possible variance. <p> We named Lipschitz in honor of Rudolf O. S. Lipschitz (1832-1903), who developed the concept of Lipschitz continuity. Acknowledgments We thank Jeong Han Kim and Charles Epstein for helpful comments. We thank Rodney Canfield for pointing out the references <ref> [2, 12, 13] </ref>, and Prasad Tetali for pointing out the reference [7].
Reference: [14] <author> W. Feller, </author> <title> An Introduction to Probability Theory and Its Applications Volume II (Second Edition), </title> <publisher> Wiley, </publisher> <year> 1971. </year>
Reference-contexts: That is what we wanted to show. 2 In this theorem, we can weaken the hypothesis to d mad (G)(n + 3), using the Berry-Esseen theorem (see Feller <ref> [14, Section XVI.5] </ref>). We omit the details. 3.4 Upper Bound Let d be such that d p p n. Our goal is to show that ln f n (d) ~ nR G (d=n). <p> We can weaken the hypothesis mad (G)n d p n to d mad (G)(n 10) and still prove the asymptotic estimate ln f n (d) ~ R G (d=n)n. The proof replaces our second-moment method with the Berry-Esseen theorem (see Feller <ref> [14, Section XVI.5] </ref>). We omit the details. 23 3.6 Game Theory Our original solution of the linear-distance case was in terms of a game. Although our current solution does not use this game, we describe the game here for its possible independent interest. We call our game the Bernstein-Lipschitz game.
Reference: [15] <author> P. Frankl and Z. Furedi, </author> <title> A short proof of a theorem of Harper about Hamming spheres, </title> <journal> Discrete Math. </journal> <volume> 34 (1981), </volume> <pages> 311-313. </pages>
Reference-contexts: This is the isoperimetric problem in the Hamming cube, for which the precise result is known for all jSj and all d by the work of Harper [17]; see also <ref> [15] </ref>. In particular, the set S of (a 1 ; : : : ; a n ) 2 f0; 1g n with P n i=1 a i r has the minimal jB [S; d]j among all S of that size.
Reference: [16] <author> G. H. Hardy, J. E. Littlewood, and G. Polya, </author> <title> Inequalities (Second Edition), </title> <publisher> Cambridge Univ. Press, </publisher> <year> 1952. </year>
Reference-contexts: over a, we get yet another formula for the second derivative: L 00 a2R E [e X ] 9 By expanding (X L 0 X ()) 3 , we get another formula for the third derivative: L 000 E [(X L 0 E [e X ] By Jensen's inequality (see <ref> [16] </ref>), if E [X] = 0 then L X is nonnegative. By Equation (8), the second derivative of L X is nonnegative, so L X is convex. By Holder's inequality (see [16]), the function X 7! L X () is convex on R V . <p> formula for the third derivative: L 000 E [(X L 0 E [e X ] By Jensen's inequality (see <ref> [16] </ref>), if E [X] = 0 then L X is nonnegative. By Equation (8), the second derivative of L X is nonnegative, so L X is convex. By Holder's inequality (see [16]), the function X 7! L X () is convex on R V . Being convex and finite, the function X 7! L X () is automatically continuous (Rockafellar [22, Corollary 10.1.1]).
Reference: [17] <author> L. Harper, </author> <title> Optimal numbering and isoperimetric problems on graphs, </title> <editor> J. </editor> <booktitle> Combinatorial Theory 1 (1966), </booktitle> <pages> 385-394. </pages>
Reference-contexts: When G is an edge on the vertices 0; 1 an optimal X has X (0) = 0, X (1) = 1. This is the isoperimetric problem in the Hamming cube, for which the precise result is known for all jSj and all d by the work of Harper <ref> [17] </ref>; see also [15]. In particular, the set S of (a 1 ; : : : ; a n ) 2 f0; 1g n with P n i=1 a i r has the minimal jB [S; d]j among all S of that size.
Reference: [18] <author> J. Kahn, </author> <title> Asymptotically good list-colorings, </title> <journal> J. Combinatorial Theory Ser. </journal> <note> A 73 (1996), 1-59. </note>
Reference-contexts: K 1 n 1=2 ]: When d n 1=2 we can write d K 1 n 1=2 = d (1 + o (1)) so that Pr [Y &gt; d] &lt; e d 2 as claimed. 2.4 Large Deviation Inequalities via Martingales The following discussion is similar to the ones in <ref> [6, 18, 3] </ref>. Let X be a random variable with E [X] = 0, Var [X] = 1, and jXj K. For any , 2 + i3 i! Now suppose = o (1).
Reference: [19] <author> B. Maurey, </author> <title> Construction de suites symetriques, </title> <type> Compt. </type> <institution> Rend. Acad. Sci. </institution> <note> Paris 288 (1979), 679-681 (in French). 25 </note>
Reference-contexts: for fixed t 2 (0; m) and d ~ tn, we have f n (d) = e R (t)n (1+o (1)) : We note that it is not difficult to show that for all values of n and d, f n (d) exp [fi (d 2 =n)]: See, for example, <ref> [19, 5, 21, 20, 10, 24] </ref>. The new aspect of the present work is the finding of the correct constant, giving an asymptotic formula with the right constant for ln f n (d). For a different approach that can yield related results, see [1].
Reference: [20] <author> C. J. H. McDiarmid, </author> <title> On the method of bounded differences, </title> <booktitle> in Surveys in Combinatorics 1989, London Math. Society Lecture Notes Series 141 (J. </booktitle> <editor> Siemons, ed.), </editor> <publisher> Cambridge Univ. Press (1989), </publisher> <pages> 148-188. </pages>
Reference-contexts: for fixed t 2 (0; m) and d ~ tn, we have f n (d) = e R (t)n (1+o (1)) : We note that it is not difficult to show that for all values of n and d, f n (d) exp [fi (d 2 =n)]: See, for example, <ref> [19, 5, 21, 20, 10, 24] </ref>. The new aspect of the present work is the finding of the correct constant, giving an asymptotic formula with the right constant for ln f n (d). For a different approach that can yield related results, see [1].
Reference: [21] <author> V. D. Milman and G. Schechtman, </author> <title> Asymptotic Theory of Finite Dimensional Normed Spaces, </title> <booktitle> Lecture Notes in Mathematics 1200, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin and New York, </address> <year> 1986. </year>
Reference-contexts: for fixed t 2 (0; m) and d ~ tn, we have f n (d) = e R (t)n (1+o (1)) : We note that it is not difficult to show that for all values of n and d, f n (d) exp [fi (d 2 =n)]: See, for example, <ref> [19, 5, 21, 20, 10, 24] </ref>. The new aspect of the present work is the finding of the correct constant, giving an asymptotic formula with the right constant for ln f n (d). For a different approach that can yield related results, see [1].
Reference: [22] <author> R. T. Rockafellar, </author> <title> Convex Analysis, </title> <publisher> Princeton Univ. Press, </publisher> <year> 1970. </year>
Reference-contexts: By Equation (8), the second derivative of L X is nonnegative, so L X is convex. By Holder's inequality (see [16]), the function X 7! L X () is convex on R V . Being convex and finite, the function X 7! L X () is automatically continuous (Rockafellar <ref> [22, Corollary 10.1.1] </ref>). Let V be a finite set, be a metric on V , and be a probability distribution on V . Let G = (V; ; ). Let be the set of Lipschitz X: V ! R with E [X] = 0. <p> Because all L X are convex, so is L G . Because X is Lipschitz iff X is Lipschitz, L G is even. Being convex and finite, L G is continuous and, further, is left-differentiable and right-differentiable (Rockafellar <ref> [22, Theorem 23.1] </ref>). Because is compact, L X is convex and differentiable, and X 7! L X () is continous, it follows from Dem'yanov and Vasil'ev [11, p. 160] that the right derivative L r G () is the maximum of L 0 X () over all -optimal functions X.
Reference: [23] <author> A. Shwartz and A. Weiss, </author> <title> Large Deviations for Performance Analysis, </title> <publisher> Chapman & Hall, </publisher> <address> London, </address> <year> 1995. </year>
Reference-contexts: space G = (V; ; ), define the rate function R G : R ! R [ f1g by R G (t) = sup [t L G ()]: We have borrowed the term "rate function" from the theory of Large Deviations, where a similar concept appears; see Shwartz and Weiss <ref> [23] </ref> for an introduction. Because L G is a nonnegative function that vanishes at 0, for t 0 we need to take the supremum only over 0. Because L G is a nonnegative function that vanishes at 0, so is R G .
Reference: [24] <author> M. Talagrand, </author> <title> Concentration of measure and isoperimetric inequalities in product spaces, </title> <institution> Inst. Hautes Etudes Sci. Publ. Math. </institution> <month> 81 </month> <year> (1995), </year> <pages> 73-205. 26 </pages>
Reference-contexts: for fixed t 2 (0; m) and d ~ tn, we have f n (d) = e R (t)n (1+o (1)) : We note that it is not difficult to show that for all values of n and d, f n (d) exp [fi (d 2 =n)]: See, for example, <ref> [19, 5, 21, 20, 10, 24] </ref>. The new aspect of the present work is the finding of the correct constant, giving an asymptotic formula with the right constant for ln f n (d). For a different approach that can yield related results, see [1].
References-found: 24

