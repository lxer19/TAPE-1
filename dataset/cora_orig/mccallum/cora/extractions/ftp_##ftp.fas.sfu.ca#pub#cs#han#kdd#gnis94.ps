URL: ftp://ftp.fas.sfu.ca/pub/cs/han/kdd/gnis94.ps
Refering-URL: http://fas.sfu.ca/cs/research/groups/DB/sections/publication/kdd/kdd.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: fhan, zaiane, yongjiang@cs.sfu.ca  
Title: Resource and Knowledge Discovery in Global Information Systems: A Multiple Layered Database Approach  
Author: Jiawei Han Osmar R. Zaane Yongjian Fu 
Note: Research partially supported by the Natural Sciences and Engineering Research Council of Canada under the grant OGP0037230 and by the Networks of Centres of Excellence Program under the grant IRIS-HMI5.  
Address: Burnaby, B.C., Canada V5A 1S6  
Affiliation: Database Systems Laboratory School of Computing Science Simon Fraser University  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal, S. Ghosh, T. Imielinski, B. Iyer, and A. Swami. </author> <title> An interval classifier for database mining applications. </title> <booktitle> In Proc. 18th Int. Conf. Very Large Data Bases, </booktitle> <pages> pages 560-573, </pages> <address> Vancouver, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: The constructed concept hierarchies should be replicated to each server, together with the higher layered databases, for information browsing and resource discovery. Generalization on numerical attributes can be performed in a more automatic way by the examination of data distribution characteristics <ref> [1, 13, 8] </ref>. In many cases, it may not require any predefined concept hierarchies.
Reference: [2] <author> R. Alonso, D. Barbara, and H. Garcia-Molina. </author> <title> Data caching issues in an information retrieval system. </title> <journal> In ACM Transactions on Database Systems, </journal> <pages> pages 359-384, </pages> <year> 1990. </year>
Reference-contexts: It is also plausible to construct higher layered databases for a special interested community of users (e.g., ACM/SIGMOD, IEEE/CS) on top of a common layer of the global database. This customized local higher layer acts as cache which may drastically reduce the overall network traffic <ref> [7, 2] </ref>.
Reference: [3] <author> T. Berners-Lee, R. Cailian, A. Luotonen, H. F. Nielsen, and A. </author> <title> Secret. The world-wide web. </title> <journal> Communications of the ACM, </journal> <volume> 37 </volume> <pages> 76-82, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: Although these tools provide indexing and document delivery services, they aim at a very specific service like FTP or gopher [24]. Attempts have also been made to discover resources in the World Wide Web <ref> [3, 27] </ref>. Spider-based indexing techniques, like the WWW Worm [23], RBSE database [9], Lycos [22] and others, create a substantial value to the web users but generate an increasing Internet backbone traffic.
Reference: [4] <author> C. M. Bowman, P. B. Danzig, U. Manber, and M. Schwartz. </author> <title> Scalable internet resource discovery: Research problems and approaches. </title> <journal> Communication of the ACM, </journal> <volume> 37 </volume> <pages> 98-114, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: The second challenge is the diversity of user community. The Internet currently connects over 2 million workstations <ref> [4] </ref>, and the user community is still expanding rapidly. Users may have quite different backgrounds, interests, and purposes of usage.
Reference: [5] <author> M. Bowman, P. Danzig, D. Hardy, U. Manber, and M. Schwartz. Harvest, </author> <title> A scalable, Customizable Discovery and Access System. </title> <institution> Technical Report CU-CS-732-94 Department of CS, University of Colorado, Boulder, </institution> <month> July </month> <year> 1994. </year> <note> Available from ftp://ftp.cs.colorado.edu/pub/cs/techreports/schwartz/Harvest.FullTR.ps.Z. </note>
Reference-contexts: They not only flood the network and overload the servers but also lose the structure and the context of the documents gathered. These wandering software agents on the World Wide Web have already created controversies [21]. Other indexing solutions, like ALIWEB [20] or Harvest <ref> [5] </ref>, behave well on the network but still struggle with the difficulty to isolate information with relevant context. Essence [17, 5], which uses a "semantic" indexing, is one of the most comprehensive indexing systems known up to now. <p> These wandering software agents on the World Wide Web have already created controversies [21]. Other indexing solutions, like ALIWEB [20] or Harvest [5], behave well on the network but still struggle with the difficulty to isolate information with relevant context. Essence <ref> [17, 5] </ref>, which uses a "semantic" indexing, is one of the most comprehensive indexing systems known up to now. However, it still cannot solve most of the problems posed for systematic discovery of resources and knowledge in the global information base. <p> Since the layer-1 construction is a major effort, a set of softwares should be developed to automate the construction process. (Notice that some existing global information index construction softwares, like the Harvest Gatherer <ref> [5] </ref>, have contributed to such practice and could be further developed to meet our needs).
Reference: [6] <author> P. Danzig, K. Obraczka, D. DeLucia, and N. Alam. </author> <title> Massively replicating services in autonomously managed wide-area internetworks. </title> <type> Technical report, </type> <year> 1994. </year> <note> Available from ftp://catarina.usc.edu/pub/kobraczk/ToN.ps.Z. </note>
Reference-contexts: The merged database can be replicated and propagated to other remote sites for further integration <ref> [6] </ref>. This integrated, 3 higher-layer database may serve a diverse user community as a high-level, global information base for resource discovery, information browsing, statistical studies, etc. <p> Information resource management: Incremental updating can be performed on different layers using efficient algorithms, as discussed in Section 3. With the MLDB architecture, it is relatively easy to manage the global MLDB and make it consistent and up-to-date. For example, it is easy to locate weakly-consistent replicas <ref> [6] </ref> based on their property similarity at higher layers (rather than searching through the whole global information base!). Based on accessing statistics, one can also decide whether a duplicate should be removed or be preserved for resource redirection.
Reference: [7] <author> P. B. Danzig, R. S. Hall, and M. F. Schwartz. </author> <title> A case for caching file objects inside internetworks. </title> <booktitle> In Proc. SIGCOMM'93, </booktitle> <pages> pages 239-248, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: It is also plausible to construct higher layered databases for a special interested community of users (e.g., ACM/SIGMOD, IEEE/CS) on top of a common layer of the global database. This customized local higher layer acts as cache which may drastically reduce the overall network traffic <ref> [7, 2] </ref>.
Reference: [8] <author> B. de Ville. </author> <title> Applying statistical knowledge to database analysis and knowledge base construction. </title> <booktitle> In Proc. 6th Conf. on Artificial Intelligence Applications, </booktitle> <pages> pages 30-36, </pages> <address> Santa Barbara, CA, </address> <year> 1990. </year> <month> 29 </month>
Reference-contexts: The constructed concept hierarchies should be replicated to each server, together with the higher layered databases, for information browsing and resource discovery. Generalization on numerical attributes can be performed in a more automatic way by the examination of data distribution characteristics <ref> [1, 13, 8] </ref>. In many cases, it may not require any predefined concept hierarchies.
Reference: [9] <author> D. Eichmann. </author> <title> The RBSE spider balancing effective search against web load. </title> <booktitle> In Proc. 1st Int. Conf. on the World Wide Web, </booktitle> <pages> pages 113-120, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Although these tools provide indexing and document delivery services, they aim at a very specific service like FTP or gopher [24]. Attempts have also been made to discover resources in the World Wide Web [3, 27]. Spider-based indexing techniques, like the WWW Worm [23], RBSE database <ref> [9] </ref>, Lycos [22] and others, create a substantial value to the web users but generate an increasing Internet backbone traffic. They not only flood the network and overload the servers but also lose the structure and the context of the documents gathered.
Reference: [10] <author> R. Elmasri and S. B. Navathe. </author> <title> Fundamentals of Database Systems, </title> <editor> 2nd ed. Bemjamin/Cummings, </editor> <year> 1994. </year>
Reference-contexts: Such nested structures, sets, lists, hypertext or multimedia data can be defined by extended data types, as in many extended-relational or object-oriented database systems <ref> [10, 19] </ref>. 2. Missing attribute values. Since different users may have different conventions to connect the information to the network, it often happens that some attribute values may be missing. For example, publication, publication date, and table of contents may not exist in a particular document. <p> An information manager cannot construct a new database for every user's definition. Most such definitions will be treated like views, i.e., no physical databases will be created, and queries on such views will be answered by the query modification technique <ref> [10, 19] </ref>. Only if such a view is shared and frequently referenced, may it be worthwhile to create a new database for it. Notice that the replication of higher-layered databases at network servers may take nontrivial disk space. <p> of the definition with the j-th column of a relation S. 4.2 A query language for information discovery in the global MLDB With the construction of the global MLDB, a query language, NetQL, can be defined for resource and knowledge discovery using a syntax similar to the relational language SQL <ref> [10, 19] </ref>. Four newly introduced operators have their correspondent language primitives in NetQL, as shown in Table 3.
Reference: [11] <author> A. Emtage and P. Deutsh. Archie: </author> <title> An electronic directory service for the internet. </title> <booktitle> Proc. of the USENIX Winter Conf., </booktitle> <pages> pages 93-110, </pages> <year> 1992. </year>
Reference-contexts: Search effectiveness (e.g., hit ratio) and performance (e.g., response time) will be bottlenecks for the successful applications of the global information system. 2 There have been many interesting studies on information indexing and searching in the global information base with many global information system servers developed, including Archie <ref> [11] </ref>, Veronica, WAIS [18], etc. Although these tools provide indexing and document delivery services, they aim at a very specific service like FTP or gopher [24]. Attempts have also been made to discover resources in the World Wide Web [3, 27].
Reference: [12] <author> O. Etzioni and D. Weld. </author> <title> A softbot-based interface to the internet. </title> <journal> Communication of the ACM, </journal> <volume> 37 </volume> <pages> 72-76, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: The interactive interface will facilitate users to browse the information base, quickly locate the resource, or progressively deepen the search or browse to lower information layers <ref> [12, 28] </ref>. The concrete NetQL examples will be presented and analyzed in the next two subsections. 4.3 Resource discovery in the global MLDB Most search engines currently available on the Internet are keyword-driven, and the answers presented are a list of URL anchors related to the keywords.
Reference: [13] <author> D. Fisher. </author> <title> Improving inference through conceptual clustering. </title> <booktitle> In Proc. 1987 AAAI Conf., </booktitle> <pages> pages 461-465, </pages> <address> Seattle, Washington, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: The constructed concept hierarchies should be replicated to each server, together with the higher layered databases, for information browsing and resource discovery. Generalization on numerical attributes can be performed in a more automatic way by the examination of data distribution characteristics <ref> [1, 13, 8] </ref>. In many cases, it may not require any predefined concept hierarchies.
Reference: [14] <author> J. Han, Y. Cai, and N. Cercone. </author> <title> Data-driven discovery of quantitative rules in relational databases. </title> <journal> IEEE Trans. Knowledge and Data Engineering, </journal> <volume> 5 </volume> <pages> 29-40, </pages> <year> 1993. </year>
Reference-contexts: The proposal is based on the previous studies on multiple layered databases [26, 16] and data mining <ref> [25, 14] </ref> and the following observations. With the development of data analysis, transformation and generalization techniques, it is possible to generalize and transform the diverse, primitive information in the network into reasonably structured, classified, descriptive and higher-level information. <p> Choice of partitions can be determined by studying the referencing statistics. Another direction is to further generalize some attributes in the relation and merge identical tuples to obtain a "summary" relation (e.g., doc summary) with data distribution statistics associated <ref> [14] </ref>. The third direction is to join two or more relations. For 6 example, doc author brief can be produced by generalization on the join of document and person. Moreover, different schemes can be combined to produce even higher layered databases. <p> Clearly, successful generalization becomes a key to the construction of higher layered databases. Following our previous studies on attribute-oriented induction for knowledge discovery in relational 10 databases <ref> [14, 15] </ref>, an attribute-oriented generalization method has been proposed for the construc-tion of multiple layered databases [16]. According to this method, data in a lower layer relation are generalized, attribute by attribute, into appropriate higher layer concepts. <p> Notice that a new layer could be formed by performing generalization on one relation or on a join of several relations based on the selected, frequently used attributes and patterns. Generalization <ref> [14] </ref> is performed by removing a set of less-interested attributes, substituting the concepts in one or a set of attributes by their corresponding higher level concepts, performing aggregation or approximation on certain attributes, etc. <p> the global MLDB must be a precise join. (i.e., join cannot be performed on the generalized attributes.) 3.2.4 An MLDB construction algorithm Based on the previous discussion, the construction of an MLDB can be summarized into the following algorithm, which is similar to attribute-oriented generalization in knowledge discovery in databases <ref> [14] </ref>. Algorithm 3.1 Construction of an MLDB. Input: A global information base, a set of concept hierarchies, and a set of frequently referenced attributes and frequently used query patterns. Output: A global multiple layered database (MLDB). Method. A global MLDB is constructed in the following steps. 1. <p> Obviously, the frequently referenced attributes should be preserved in higher layers, and the frequently referenced concept levels should be considered as the candidate concept levels in the construction of higher layers. Steps 2 and 3 are performed in a way similar to the attribute-oriented induction, studied previously <ref> [14, 16] </ref>. <p> Another alternative is to present information in relevance to more than one attribute, such as "For IBM Almaden Research Center, 70% were published in major database conferences between 1990-1993, etc.". This presentation mechanism has been implemented in the DBLearn system in our previous work <ref> [14, 16] </ref>. 2 These examples, though simple, demonstrates that a broad spectrum of knowledge discovery queries can be posed to the global MLDB system to explore some interesting, general or statistical information about the global information base. 5 Discussion The multiple layered database architecture provides the following advantages for information discovery
Reference: [15] <author> J. Han, Y. Fu, Y. Huang, Y. Cai, and N. Cercone. </author> <title> DBLearn: A system prototype for knowledge discovery in relational databases. </title> <booktitle> In Proc. 1994 ACM-SIGMOD Conf. Management of Data, </booktitle> <pages> page 516, </pages> <address> Minneapolis, MN, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Clearly, successful generalization becomes a key to the construction of higher layered databases. Following our previous studies on attribute-oriented induction for knowledge discovery in relational 10 databases <ref> [14, 15] </ref>, an attribute-oriented generalization method has been proposed for the construc-tion of multiple layered databases [16]. According to this method, data in a lower layer relation are generalized, attribute by attribute, into appropriate higher layer concepts.
Reference: [16] <author> J. Han, Y. Fu, and R. Ng. </author> <title> Cooperative query answering using multiple-layered databases. </title> <booktitle> In Proc. 2nd Int. Conf. Cooperative Information Systems, </booktitle> <pages> pages 47-58, </pages> <address> Toronto, Canada, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: The proposal is based on the previous studies on multiple layered databases <ref> [26, 16] </ref> and data mining [25, 14] and the following observations. With the development of data analysis, transformation and generalization techniques, it is possible to generalize and transform the diverse, primitive information in the network into reasonably structured, classified, descriptive and higher-level information. <p> Clearly, successful generalization becomes a key to the construction of higher layered databases. Following our previous studies on attribute-oriented induction for knowledge discovery in relational 10 databases [14, 15], an attribute-oriented generalization method has been proposed for the construc-tion of multiple layered databases <ref> [16] </ref>. According to this method, data in a lower layer relation are generalized, attribute by attribute, into appropriate higher layer concepts. Different lower level concepts may be generalized into the same concepts at a higher level and be merged together, which reduces the size of the database. <p> The generalized keys should be marked explicitly since they usually cannot be used as join keys at generating subsequent layers. It is crucial to identify altered keys since if the altered keys were used to perform joins of different relations, it may generate incorrect information <ref> [16] </ref>. Notice that join on generalized attributes, though undesirable in most cases, could be useful if the join is to link the tuples with approximately the same attribute values together. For example, for search documents, one may like to consider some closely related but not exactly the same subjects. <p> Obviously, the frequently referenced attributes should be preserved in higher layers, and the frequently referenced concept levels should be considered as the candidate concept levels in the construction of higher layers. Steps 2 and 3 are performed in a way similar to the attribute-oriented induction, studied previously <ref> [14, 16] </ref>. <p> Another alternative is to present information in relevance to more than one attribute, such as "For IBM Almaden Research Center, 70% were published in major database conferences between 1990-1993, etc.". This presentation mechanism has been implemented in the DBLearn system in our previous work <ref> [14, 16] </ref>. 2 These examples, though simple, demonstrates that a broad spectrum of knowledge discovery queries can be posed to the global MLDB system to explore some interesting, general or statistical information about the global information base. 5 Discussion The multiple layered database architecture provides the following advantages for information discovery
Reference: [17] <author> D. Hardy and M. F. Schwartz. </author> <title> Essence: A resource discovery system based on semantic file indexing. </title> <booktitle> In Proc. of the USENIX Winter Conf., </booktitle> <pages> pages 361-374, </pages> <year> 1993. </year>
Reference-contexts: These wandering software agents on the World Wide Web have already created controversies [21]. Other indexing solutions, like ALIWEB [20] or Harvest [5], behave well on the network but still struggle with the difficulty to isolate information with relevant context. Essence <ref> [17, 5] </ref>, which uses a "semantic" indexing, is one of the most comprehensive indexing systems known up to now. However, it still cannot solve most of the problems posed for systematic discovery of resources and knowledge in the global information base.
Reference: [18] <author> B. Kahle. </author> <title> An information system for corporate users: Wide area information servers. </title> <note> In Thinking Machines technical report TMC-199, </note> <month> April </month> <year> 1991. </year>
Reference-contexts: effectiveness (e.g., hit ratio) and performance (e.g., response time) will be bottlenecks for the successful applications of the global information system. 2 There have been many interesting studies on information indexing and searching in the global information base with many global information system servers developed, including Archie [11], Veronica, WAIS <ref> [18] </ref>, etc. Although these tools provide indexing and document delivery services, they aim at a very specific service like FTP or gopher [24]. Attempts have also been made to discover resources in the World Wide Web [3, 27].
Reference: [19] <author> H. F. Korth and A. Silberschatz. </author> <title> Database System Concepts, </title> <publisher> 2ed. McGraw-Hill, </publisher> <year> 1991. </year>
Reference-contexts: Such nested structures, sets, lists, hypertext or multimedia data can be defined by extended data types, as in many extended-relational or object-oriented database systems <ref> [10, 19] </ref>. 2. Missing attribute values. Since different users may have different conventions to connect the information to the network, it often happens that some attribute values may be missing. For example, publication, publication date, and table of contents may not exist in a particular document. <p> An information manager cannot construct a new database for every user's definition. Most such definitions will be treated like views, i.e., no physical databases will be created, and queries on such views will be answered by the query modification technique <ref> [10, 19] </ref>. Only if such a view is shared and frequently referenced, may it be worthwhile to create a new database for it. Notice that the replication of higher-layered databases at network servers may take nontrivial disk space. <p> of the definition with the j-th column of a relation S. 4.2 A query language for information discovery in the global MLDB With the construction of the global MLDB, a query language, NetQL, can be defined for resource and knowledge discovery using a syntax similar to the relational language SQL <ref> [10, 19] </ref>. Four newly introduced operators have their correspondent language primitives in NetQL, as shown in Table 3.
Reference: [20] <author> M. Koster. </author> <title> ALIWEB archie-like indexing in the web. </title> <booktitle> In Proc. 1st Int. Conf. on the World Wide Web, </booktitle> <pages> pages 91-100, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: They not only flood the network and overload the servers but also lose the structure and the context of the documents gathered. These wandering software agents on the World Wide Web have already created controversies [21]. Other indexing solutions, like ALIWEB <ref> [20] </ref> or Harvest [5], behave well on the network but still struggle with the difficulty to isolate information with relevant context. Essence [17, 5], which uses a "semantic" indexing, is one of the most comprehensive indexing systems known up to now.
Reference: [21] <author> M. Koster. </author> <title> A Standard for Robot Exclusion. </title> <institution> Nexor Corp., </institution> <year> 1994. </year> <note> Available from http://web.nexor.co.uk/mak/doc/robots/norobots.html. </note>
Reference-contexts: They not only flood the network and overload the servers but also lose the structure and the context of the documents gathered. These wandering software agents on the World Wide Web have already created controversies <ref> [21] </ref>. Other indexing solutions, like ALIWEB [20] or Harvest [5], behave well on the network but still struggle with the difficulty to isolate information with relevant context. Essence [17, 5], which uses a "semantic" indexing, is one of the most comprehensive indexing systems known up to now.
Reference: [22] <author> M. L. Mauldin. Lycos: </author> <note> Hunting WWW Information. CMU, 1994. Available from http://lycos.cs.cmu.edu/. </note>
Reference-contexts: Although these tools provide indexing and document delivery services, they aim at a very specific service like FTP or gopher [24]. Attempts have also been made to discover resources in the World Wide Web [3, 27]. Spider-based indexing techniques, like the WWW Worm [23], RBSE database [9], Lycos <ref> [22] </ref> and others, create a substantial value to the web users but generate an increasing Internet backbone traffic. They not only flood the network and overload the servers but also lose the structure and the context of the documents gathered.
Reference: [23] <author> O. McBryan. </author> <title> GENVL and WWWW: Tools for taming the web. </title> <booktitle> In Proc. 1st Int. Conf. on the World Wide Web, </booktitle> <pages> pages 79-90, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Although these tools provide indexing and document delivery services, they aim at a very specific service like FTP or gopher [24]. Attempts have also been made to discover resources in the World Wide Web [3, 27]. Spider-based indexing techniques, like the WWW Worm <ref> [23] </ref>, RBSE database [9], Lycos [22] and others, create a substantial value to the web users but generate an increasing Internet backbone traffic. They not only flood the network and overload the servers but also lose the structure and the context of the documents gathered.
Reference: [24] <author> M. McCahill. </author> <title> The internet gopher protocol: A distributed server information system. </title> <journal> ConneXions-The Interoperability Report, </journal> <volume> 6 </volume> <pages> 10-14, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Although these tools provide indexing and document delivery services, they aim at a very specific service like FTP or gopher <ref> [24] </ref>. Attempts have also been made to discover resources in the World Wide Web [3, 27]. Spider-based indexing techniques, like the WWW Worm [23], RBSE database [9], Lycos [22] and others, create a substantial value to the web users but generate an increasing Internet backbone traffic.
Reference: [25] <author> G. Piatetsky-Shapiro and W. J. Frawley. </author> <title> Knowledge Discovery in Databases. </title> <publisher> AAAI/MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: The proposal is based on the previous studies on multiple layered databases [26, 16] and data mining <ref> [25, 14] </ref> and the following observations. With the development of data analysis, transformation and generalization techniques, it is possible to generalize and transform the diverse, primitive information in the network into reasonably structured, classified, descriptive and higher-level information.
Reference: [26] <author> R.L. Read, D.S. Fussell, and A. Silberschatz. </author> <title> A multi-resolution relational data model. </title> <booktitle> In Proc. 18th Int. Conf. Very Large Data Bases, </booktitle> <pages> pages 139-150, </pages> <address> Vancouver, Canada, </address> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: The proposal is based on the previous studies on multiple layered databases <ref> [26, 16] </ref> and data mining [25, 14] and the following observations. With the development of data analysis, transformation and generalization techniques, it is possible to generalize and transform the diverse, primitive information in the network into reasonably structured, classified, descriptive and higher-level information.
Reference: [27] <author> M. F. Schwartz, A. Emtage, B. Kahle, and B. C. Neuman. </author> <title> A comparison of internet resource discovery approaches. </title> <journal> Comput. Syst., </journal> <volume> 5 </volume> <pages> 461-493, </pages> <month> Fall </month> <year> 1992. </year>
Reference-contexts: Although these tools provide indexing and document delivery services, they aim at a very specific service like FTP or gopher [24]. Attempts have also been made to discover resources in the World Wide Web <ref> [3, 27] </ref>. Spider-based indexing techniques, like the WWW Worm [23], RBSE database [9], Lycos [22] and others, create a substantial value to the web users but generate an increasing Internet backbone traffic.
Reference: [28] <author> R. J. Vetter, C. Spell, and C. Ward. </author> <title> Mosaic and the world-wide web. </title> <journal> Computer, </journal> <volume> 27 </volume> <pages> 49-57, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: But their inclusion not only makes the query more readable but also helps system locate the corresponding layer-3 relation if there exists one. The where-clause is similar to that in SQL except that several new operators may be used. Moreover, Mosaic-like <ref> [28] </ref> graphics user interfaces can be developed on top of NetQL, making browsing and searching "instruction-free", i.e., mainly relying on field-filling and button-clicking operations. <p> The interactive interface will facilitate users to browse the information base, quickly locate the resource, or progressively deepen the search or browse to lower information layers <ref> [12, 28] </ref>. The concrete NetQL examples will be presented and analyzed in the next two subsections. 4.3 Resource discovery in the global MLDB Most search engines currently available on the Internet are keyword-driven, and the answers presented are a list of URL anchors related to the keywords.
References-found: 28

