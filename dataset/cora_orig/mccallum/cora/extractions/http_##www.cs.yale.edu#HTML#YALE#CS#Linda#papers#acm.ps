URL: http://www.cs.yale.edu/HTML/YALE/CS/Linda/papers/acm.ps
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/Linda/network-piranha.html
Root-URL: http://www.cs.yale.edu
Title: Supercomputing out of Recycled Garbage: Preliminary Experience with Piranha  
Author: David Gelernter David Kaminsky 
Note: This work was supported by the National Science Foundation under grant number CCR-8657615 and NASA under grant number NGT-50719.  
Affiliation: Yale University  Yale University  
Abstract: In this paper we present a new system for making use of the cycles routinely wasted in local area networks. The Piranha system harnesses these cycles to run explicitly parallel programs. Programs written for Piranha are specializations of Linda master/worker programs[5]. We have used Piranha to run a number of production applications. We present a description of the Piranha prototype, briefly explain the Piranha programming methodology, and explore different types of Piranha algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ahmed, S. and Gelernter, D. </author> <title> "A CASE Environment for Parallel Programming", </title> <booktitle> Proceedings of the Fifth International Workshop on Computer-Aided Software Engineering, </booktitle> <publisher> IEEE Computer Science Press, </publisher> <month> July 6-10, </month> <year> 1992. </year>
Reference-contexts: More complicated retreat functions pass accumulated state from a retreating process to some other Piranha process. Since retreat functions can be difficult for a user to write, we intend to develop a standard library that can be slotted into place automatically using the Linda Program Builder <ref> [1] </ref>.
Reference: [2] <author> Anderson, B. and Shasha, D., </author> <title> "Persistent Linda: Linda + Transactions + Query Processing", </title> <booktitle> Proc. Research Directions in High-Level Parallel Programming Languages, </booktitle> <address> June 17-19, 1991, Mont Saint-Michel, France, </address> <pages> pp. 129-142. </pages>
Reference: [3] <author> Bjornson, R., </author> <title> "Linda on Distributed Memory Multiprocessors", </title> <type> Ph.D. Thesis, </type> <institution> Yale University, </institution> <year> 1991. </year>
Reference-contexts: Retreated tasks are placed at the head of the queue so the window can continue to slide. An example is a computational fluid dynamics code used to simulate a helicopter rotor. The code, called Freewake, 5 is an n-body problem run for a succession of timesteps <ref> [3] </ref>. The steps within an iteration are run using sliding window parallelism. It is possible to rewrite this code using a bag of tasks, but we chose sliding window to preserve the program structure. Forty-six nodes were in the Piranha pool (but only a fraction were idle). <p> The 5 Freewake was written by Alan Egolf of United Technology Research Center, Hartford, CT. 6 TSnet, a registered trademark of Scientific Computing Associates, New Haven, CT, is a network version of Linda. 7 Data from TSnet and the iPSC/860 was provided by Robert Bjornson <ref> [3] </ref>. 8 Matrix algorithm development is joint work with Professors Sandeep Bhatt and Jeffrey Westbrook of the Yale Computer Science Department Bjornson [3] ran an 8k Freewake problem for five time steps on a network of Decstations and the In-tel iPSC/860. (A sequential version of Freewake was not available for benchmarking.) <p> a registered trademark of Scientific Computing Associates, New Haven, CT, is a network version of Linda. 7 Data from TSnet and the iPSC/860 was provided by Robert Bjornson <ref> [3] </ref>. 8 Matrix algorithm development is joint work with Professors Sandeep Bhatt and Jeffrey Westbrook of the Yale Computer Science Department Bjornson [3] ran an 8k Freewake problem for five time steps on a network of Decstations and the In-tel iPSC/860. (A sequential version of Freewake was not available for benchmarking.) The run times (in seconds) are given for runs on four to 128 nodes.
Reference: [4] <author> Bjornson, R., Carriero, N., Gelernter, D., Kaminsky, D., Mattson, T., and Sherman, A. </author> <title> "Experience with Linda", </title> <journal> YALEU/DCS/TR-866, </journal> <volume> 8/91. </volume>
Reference: [5] <author> Carriero, N. and Gelernter, D. </author> <title> How to write parallel programs: A first course. </title> <publisher> (Cambridge: MIT Press, </publisher> <year> 1990). </year>
Reference-contexts: When a user reclaims his workstation, it leaves the ongoing parallel computation and returns to normal duties. The Piranha model makes no assumptions in the abstract about how parallel applications are structured. In practice, Piranha is an immediate fit to the Linda model: Linda 1 <ref> [5] </ref> makes it easy to structure computations as collections of workers sharing access to distributed data structures. Thus our Piranha system is, in practice, an execution model and support system for a certain class of Linda programs.
Reference: [6] <author> Cheriton, D. </author> <title> "The V Distributed System", </title> <journal> CACM, </journal> <pages> pp 314-333, 3/88. </pages>
Reference-contexts: After retreat completes, the systems transitions to Exec User. When the owner no longer needs the node, the system returns to the Available state. ones. Examples include Amoeba [17], Butler [12], Condor [11], Sprite [13], and V <ref> [6] </ref>. Such systems deliver job level parallelism: a collection of (essentially) independent and unrelated sequential programs can be run simultaneously.
Reference: [7] <author> Crandall, R., </author> <title> "Tales of godzilla: Adventures in Distributed Computing", </title> <address> NeXTon Campus, </address> <month> Summer, </month> <year> 1990. </year>
Reference-contexts: Piranha, in short, provides a mechanism for solving large problems via parallel programs on idle workstations. Systems such as Condor or Sprite provide a more pleasant working environment by keeping per node workload down. NeXT's Godzilla system <ref> [7] </ref> is probably Piranha's nearest neighbor among existing systems. Godzilla allows a user to fork worker processes on idle network nodes. Each process computes a result and passes it back to a master process.
Reference: [8] <author> Douglis, F. and Ousterhout, J., </author> <title> "Transparent Process Migration: Design Alternatives and the Sprite Implementation", </title> <journal> Software-Practice and Experience, </journal> <volume> Vol 21(8), </volume> <pages> pp 757-787, 8/91. </pages>
Reference-contexts: Some studies suggest that job level parallelism may not be a very effective way to soak up idle cycles. (The Sprite developers report that over two-thirds of their workstations are idle during the middle of the day, yet less than five percent are used by migrated processes <ref> [8] </ref>.) At any rate, Piranha's goals are different: it attempts to deliver maximum performance on a single job, assuming that this job can be expressed as a parallel program of the appropriate type. Piranha, in short, provides a mechanism for solving large problems via parallel programs on idle workstations.
Reference: [9] <author> Gates, E., Krauss, L., White, M., </author> <title> "Solar Neutrino Data and Its Implications", </title> <institution> YCTP-P26-91, Yale University, </institution> <month> 8/91. </month>
Reference-contexts: When a Piranha is active, it removes a task, consumes it, and returns a result. When a process retreats, it returns the task to tuple space. A neutrino simulation code <ref> [9] </ref> run under Piranha takes this form.
Reference: [10] <author> Kambhatla, S. and Walpole, J. </author> <title> "Recovery with Limited Replay: Fault-Tolerant Processes in Linda", </title> <institution> Oregon Graduate Institute, Department of Computer Science and Engineering Tech Report CS/E 90-019, </institution> <month> 9/90. </month>
Reference: [11] <author> Litzkow, M., Livny, M., and Matka, M.W. </author> <title> "Condor A Hunter of Idle Workstations", </title> <booktitle> Presented at the 8th Intl Conf on Distributed Computing Systems, </booktitle> <address> San Jose, CA, </address> <month> 6/88. </month>
Reference-contexts: If an owner demands the node in the Exec Piranha state, the retreat function is called. After retreat completes, the systems transitions to Exec User. When the owner no longer needs the node, the system returns to the Available state. ones. Examples include Amoeba [17], Butler [12], Condor <ref> [11] </ref>, Sprite [13], and V [6]. Such systems deliver job level parallelism: a collection of (essentially) independent and unrelated sequential programs can be run simultaneously.
Reference: [12] <author> Nichols, D.A. </author> <title> "Multiprocessing in a Network of Workstations", </title> <type> PhD Thesis, </type> <address> CMU, CMU-CS-90-107, </address> <month> 2/90. </month>
Reference-contexts: If an owner demands the node in the Exec Piranha state, the retreat function is called. After retreat completes, the systems transitions to Exec User. When the owner no longer needs the node, the system returns to the Available state. ones. Examples include Amoeba [17], Butler <ref> [12] </ref>, Condor [11], Sprite [13], and V [6]. Such systems deliver job level parallelism: a collection of (essentially) independent and unrelated sequential programs can be run simultaneously.
Reference: [13] <author> Ousterhout, J.K., Cherenson, A.R., Douglis, F., Nelson, M.N., and Welch, B.B. </author> <title> "The Sprite Network Operating System", </title> <booktitle> IEEE Computer Vol 21 No 6, </booktitle> <pages> pp 23-36, 2/88. </pages>
Reference-contexts: After retreat completes, the systems transitions to Exec User. When the owner no longer needs the node, the system returns to the Available state. ones. Examples include Amoeba [17], Butler [12], Condor [11], Sprite <ref> [13] </ref>, and V [6]. Such systems deliver job level parallelism: a collection of (essentially) independent and unrelated sequential programs can be run simultaneously.
Reference: [14] <author> Rao, S. </author> <type> personal communication. </type>
Reference-contexts: The program breaks the search space into a number of subspaces, and a coarse-grid local-minima search is performed on these subspaces. The local-minima are then localized using a factorial-pattern search. <ref> [14] </ref> Table 4: Dipole Localization Performance Avg Full Run Node Wkr Spd Run Nds Nds Tm Tm Tm Up Avg 20 20 1.56 31.2 29.6 18.5 Sqtl 1 1 28.8 28.8 28.8 1 This table analogous to Table 3 except for the omission of the comparison to network Linda run on
Reference: [15] <author> Shoch, J.F. and Hupp, J.A. </author> <title> "The Worm Programs | Early Experience with a Distributed Computation", </title> <journal> CACM, </journal> <pages> pp 172-180, 3/82. </pages>
Reference-contexts: Linda's tuple spaces easily support Piranha's task collections, other global state objects, and general communication among processes whose identities are mutually unknown and whose lifetimes might not overlap. 3 Piranha in Context It has long been understood that computations can be run profitably on idle network nodes <ref> [15] </ref>.
Reference: [16] <author> Silverman, R., </author> <booktitle> "Massively Distributed Computing and Factoring Large Integers", </booktitle> <volume> CACM Vol 34 No 2, </volume> <pages> pp 95-103, 11/91. </pages>
Reference: [17] <author> Tanenbaum, A."Amoeba: </author> <title> A Distributed Operating System for the 1990's", </title> <booktitle> IEEE Computer, </booktitle> <pages> pp 44-53, 5/90. </pages>
Reference-contexts: If an owner demands the node in the Exec Piranha state, the retreat function is called. After retreat completes, the systems transitions to Exec User. When the owner no longer needs the node, the system returns to the Available state. ones. Examples include Amoeba <ref> [17] </ref>, Butler [12], Condor [11], Sprite [13], and V [6]. Such systems deliver job level parallelism: a collection of (essentially) independent and unrelated sequential programs can be run simultaneously.
Reference: [18] <author> Waldspurger, C., Hogg, T., Huberman, B., Kephart, J., and Stornetta, S. </author> <month> "SPAWN: </month>
References-found: 18

