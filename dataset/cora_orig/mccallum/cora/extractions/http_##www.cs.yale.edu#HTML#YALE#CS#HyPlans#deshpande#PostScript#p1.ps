URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/deshpande/PostScript/p1.ps
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/deshpande/research.html
Root-URL: http://www.cs.yale.edu
Title: Efficient Parallel Programming with Linda  
Author: Ashish Deshpande and Martin Schultz 
Address: New Haven, CT 06520  
Affiliation: Department of Computer Science Yale University  
Abstract: Linda is a coordination language invented by David Gelernter at Yale University [7], which, when combined with a computation language (like C) yields a high-level parallel programming language for MIMD machines. Linda is based on a virtual shared associative memory containing objects called tuples. Skeptics have long claimed that Linda programs could not be efficient on distributed memory architectures. In this paper, we address this claim by discussing C-Linda's performance in solving a particular scientific computing problem, the shallow water equations, and make comparisons with alternatives available on various shared and distributed memory parallel machines. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Beguelin, J. Dongarra, A. Geist, B. Manchek, and V. Sunderam. </author> <title> A user's guide to PVM parallel virtual machine. </title> <type> Technical Report TM-1126, ORNL, </type> <month> July </month> <year> 1991. </year>
Reference-contexts: We investigated the performance of Network Linda (Version 2.4.6) and PVM (Version 2.3.2 4 ) on a LAN of SUN Sparcstations. PVM (which stands for Parallel Virtual Machine) was developed at Oak Ridge National Labs, the University of Tennessee and at Emory University <ref> [1, 6, 9] </ref>. It is a direct, message passing system for networks of computers. In our experiments, we used PVM and Linda programs which used the same computation module, in order to eliminate possible differences in compilation. The two programs differed only in the communication routines.
Reference: [2] <author> R. Bjornson. </author> <title> Experience with Linda on the iPSC/2. </title> <type> Technical Report DCS/RR-520, </type> <institution> Yale University, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: We refer the reader to <ref> [2] </ref> for further details. This cost depends on the latency associated with the underlying communication medium as well as the size of the tuple.
Reference: [3] <author> N. Carriero and D. Gelernter. </author> <title> Applications experience with Linda. </title> <booktitle> In Proc. ACM Symposium on Parallel Programming, </booktitle> <pages> pages 173-187, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: Linda has been discussed extensively in the literature and we shall assume some knowledge of Linda. We refer the reader to <ref> [3, 4, 5, 7] </ref> for further details. For the sake of completeness, we include a very brief discussion of Linda in the Appendix.
Reference: [4] <author> N. Carriero and D. Gelernter. </author> <title> Linda in context. </title> <journal> Communications of the ACM, </journal> <volume> 32(4) </volume> <pages> 444-458, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Linda has been discussed extensively in the literature and we shall assume some knowledge of Linda. We refer the reader to <ref> [3, 4, 5, 7] </ref> for further details. For the sake of completeness, we include a very brief discussion of Linda in the Appendix.
Reference: [5] <author> N. Carriero and D. Gelernter. </author> <title> How to write parallel programs: A guide to the perplexed. </title> <journal> ACM Computing Surveys, </journal> <volume> 21(3) </volume> <pages> 323-357, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: Linda has been discussed extensively in the literature and we shall assume some knowledge of Linda. We refer the reader to <ref> [3, 4, 5, 7] </ref> for further details. For the sake of completeness, we include a very brief discussion of Linda in the Appendix.
Reference: [6] <author> G.A. Geist and V.S. Sunderam. </author> <title> Network based concurrent computing on the PVM system. </title> <journal> Con-currency: </journal> <note> Practice and Experience (in press). </note>
Reference-contexts: We investigated the performance of Network Linda (Version 2.4.6) and PVM (Version 2.3.2 4 ) on a LAN of SUN Sparcstations. PVM (which stands for Parallel Virtual Machine) was developed at Oak Ridge National Labs, the University of Tennessee and at Emory University <ref> [1, 6, 9] </ref>. It is a direct, message passing system for networks of computers. In our experiments, we used PVM and Linda programs which used the same computation module, in order to eliminate possible differences in compilation. The two programs differed only in the communication routines. <p> However, the authors of PVM do claim good performance for traditional parallel applications <ref> [6, 9] </ref>. 5 Conclusions A number of computer scientists have contended that Linda cannot possibly be implemented efficiently on distributed memory machines because there is simply too much overhead.
Reference: [7] <author> D. Gelernter. </author> <title> Generative communication in Linda. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 1 </volume> <pages> 80-112, </pages> <year> 1985. </year>
Reference-contexts: Linda has been discussed extensively in the literature and we shall assume some knowledge of Linda. We refer the reader to <ref> [3, 4, 5, 7] </ref> for further details. For the sake of completeness, we include a very brief discussion of Linda in the Appendix.
Reference: [8] <author> R. Sadourney. </author> <title> The dynamics of the finite-difference models of the shallow water equations. </title> <journal> Journal of the Atmospheric Sciences, </journal> <volume> 32 </volume> <pages> 680-689, </pages> <year> 1975. </year>
Reference-contexts: t) where w = (u; v; ) T is the solution, rigid wall in the y-direction v (x; 0; t) = v (x; D; t) = 0; and the initial condition is w (x; y; 0) = F (x; y): We use the finite difference approximations described by Robert Sadourney <ref> [8] </ref>, which have been used in previous studies of the same problem. We solve these equations numerically using simple, finite difference approximations: @f = 2x which can be derived from the Taylor series expansion for a function.
Reference: [9] <author> V.S. Sunderam. </author> <title> PVM: A framework for parallel distributed computing. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 2(4) </volume> <pages> 315-339, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: We investigated the performance of Network Linda (Version 2.4.6) and PVM (Version 2.3.2 4 ) on a LAN of SUN Sparcstations. PVM (which stands for Parallel Virtual Machine) was developed at Oak Ridge National Labs, the University of Tennessee and at Emory University <ref> [1, 6, 9] </ref>. It is a direct, message passing system for networks of computers. In our experiments, we used PVM and Linda programs which used the same computation module, in order to eliminate possible differences in compilation. The two programs differed only in the communication routines. <p> However, the authors of PVM do claim good performance for traditional parallel applications <ref> [6, 9] </ref>. 5 Conclusions A number of computer scientists have contended that Linda cannot possibly be implemented efficiently on distributed memory machines because there is simply too much overhead.
Reference: [10] <author> W.M. Washington and C.L. Parkinson. </author> <title> An Introduction to Three-Dimensional Climate Modeling. </title> <publisher> University Science Books, </publisher> <address> Mill Valley, </address> <publisher> CA and Oxford University Press, </publisher> <address> N.Y., </address> <year> 1986. </year> <pages> 422 pp. </pages>
Reference-contexts: Thus, given the values of u; v and at t and t + t, we can calculate their values at t + 2t at all gridpoints simultaneously. A detailed description of the algorithms can be found in <ref> [10] </ref>. 3 Linda Implementation The Linda implementation of our problem relies on the production and consumption of tuples for flow control. As always, we would like to minimize the amount of time spent by each process in communication.
References-found: 10

