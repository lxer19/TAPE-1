URL: ftp://ftpipr.ira.uka.de/pub/papers/1993/isir93au.ps.gz
Refering-URL: ftp://ftpipr.ira.uka.de/.public_html/papersna.html
Root-URL: 
Title: Trajectory Reconstruction from Stereo Image Sequences for Teaching Robot Paths  
Author: Ales UDE Rudiger DILLMANN 
Keyword: Robot programming, Stereo vision, Smoothing splines.  
Address: Kaiserstr. 12, 76128 Karlsruhe, Germany  
Affiliation: Institute for Real-Time Computer Systems and Robotics, University of Karlsruhe,  
Date: November 1993  
Note: In: Proc. 24 Int. Symp. Industrial Robots, pp. 407-414, Tokyo, Japan,  
Abstract: This paper presents a new method for programming of robot trajectories. We employ the "Teaching by Showing" programming paradigm which enables the user to efficiently program robot tasks by means of vision. The user specifies the desired trajectory by moving the object to be manipulated with his own hand. The motion is measured by a stereo vision system. We take advantage of a CAD model of the object in order to facilitate the process of measurement. Smoothing vector splines are utilized to reconstruct the trajectory either in Cartesian or in joint coordinates. Uncertainties resulting from the noise of the sensors are considered explicitly in the process of reconstruction. Important points that must be reached by the robot's end-effector exactly can be specified and limitations on robot's velocities and accelerations can be set. The conversion of the reconstructed trajectory into the robot language commands is discussed. Some experimental and simulation results are presented to substantiate our approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. de Boor. </author> <title> A Practical Guide to Splines. </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: if we limit our attention to the interesting part of the trajectory, i.e. on the interval [a; b] = [s 1 ; s N ], may be written as 2m1 X ~ ff 1i (t s 1 ) 2m1i + j=2 i=0 + : (13) It has been shown in <ref> [1] </ref> that such curve belongs to the space spanned by B-splines fB j g 1; ~ N ; ~ N = P N j=1 (k j + 1) = M + L; defined on the knot sequence in which s 1 and s N appear 2m times and the other s
Reference: [2] <author> H. I. El-Zorkany, R. Liscano, B. Tondu, and G. Sawatzky. </author> <title> Sensor-based location and trajectory specification and correction in robot programming. </title> <booktitle> In Proc. 16th Int. Symp. Industrial Robots, </booktitle> <pages> pages 643-655, </pages> <address> Brussels, Belgium, </address> <month> Oc-tober </month> <year> 1986. </year>
Reference-contexts: A PSD camera for measuring the desired pose (position and orientation) at the important passing points was described in [8]. Robot paths were specified as simple point-to-point motions. Another camera system for programming of robot trajectories was proposed in <ref> [2] </ref>. A dense set of poses on the desired trajectory was measured in order to estimate the overall trajectory. Various heuristics were developed to improve the quality of the reconstructed trajectory.
Reference: [3] <author> R. L. Eubank. </author> <title> Spline Smoothing and Nonpara-metric Regression. </title> <publisher> Marcel Dekker, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: We would like to minimize the criteria f () and g k () simultaneously, but these are conflicting goals in general. A standard nonparametric so lution is to minimize the following combined criterion <ref> [3, 15] </ref>: = arg min f () + k=1 4 This criterion function is minimized over all trajectories with at least piecewise continuous m-th derivative. = [ 1 ; : : : ; D ] T , k &gt; 0, is called the smoothing parameter which controls the tradeoff between goodness-of-fit <p> Here we redefined a and b from the expression (6) to be equal to minft 1 ; t 1 g and maxft M ; t L g, respectively. It turns out (see <ref> [3] </ref> for 1-D case) that the solution to this problem can be written as (t) = j=0 M X ffi j (t t j ) 2m1 L X i ((t t i ) 2m1 with the additional condition that is a polynomial of degree m1 outside the interval [a; b].
Reference: [4] <author> J. A. Fessler. </author> <title> Nonparametric fixed-interval smoothing with vector splines. </title> <journal> IEEE Trans. Signal Processing, </journal> <volume> 39(4) </volume> <pages> 852-859, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: It can be shown that the solution to the minimization problem (7) is a vector spline with component functions which are each natural splines of order 2m with the knot sequence ft 1 ; : : : ; t M g <ref> [4] </ref>. A local basis for the M -dimensional space of natural splines which consists of B-splines that are modified to fulfill the natural boundary conditions is described in [11]. Let fx 1 ; : : : ; x M g be the natural splines belonging to this basis. <p> If the components of run from zero to infinity, runs from an interpolant to the data, to the polynomial of degree m 1 best fitting the data in a least squares sense. Some methods for the estimation of the smoothing parameter are given in <ref> [4, 14] </ref>. Some simulation results showing the accuracy of the reconstructed trajectory as a function of time are depicted in Figures 3 and 4. In this experiment, m from the expression (6) was set to 3, i.e. the jerk was kept small in order to smooth the trajectory. <p> The quadratic pro gram (15) has a unique solution. The estimation of the smoothing parameter is not to be discussed in this paper because it is a topic of its own. For the case D = 1 we relate the interested reader to [15]. Using the results from <ref> [4, 14] </ref>, the methods from [15] can be extended to the higher dimensions.
Reference: [5] <author> D. B. Gennery. </author> <title> Visual tracking of known three-dimensional objects. </title> <journal> Intern. J. Comput. Vis., </journal> <volume> 7(3) </volume> <pages> 243-270, </pages> <year> 1992. </year>
Reference-contexts: The input to the tracking procedure is the object's pose estimated in the bootstrapping phase and a stream of images supplied by the stereo camera system. The tracking procedure tries to predict the object's pose at the next time instant by use of a random acceleration kinematic model <ref> [5] </ref> for the object's motion and Kalman filtering. A ray tracing procedure which uses the estimated pose and the object's CSG tree is employed to predict the position, visibility and detectability of the object features. These predictions lead the search for correspondences at the next computing step.
Reference: [6] <author> K. Ikeuchi, M. Kawade, and T. Suehiro. </author> <title> Assembly task recognition with planar, curved and mechanical contacts. </title> <booktitle> In Proc. IEEE Int. Conf. Robotics and Automation, </booktitle> <volume> Vol. II, </volume> <pages> pages 688-694, </pages> <address> Atlanta, Georgia, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Some results on visual recognition of action sequences performed by the user and their transformation into the robot language commands specifying the task have been given in <ref> [10, 6] </ref>. Programming of robot paths with the help of vision has also received some attention in the past. A PSD camera for measuring the desired pose (position and orientation) at the important passing points was described in [8]. Robot paths were specified as simple point-to-point motions.
Reference: [7] <author> M. Inaba and H. Inoue. </author> <title> Vision-based robot programming. </title> <editor> In H. Miura and S. Arimoto, editors, </editor> <booktitle> Robotics Research 5, </booktitle> <pages> pages 129-136. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1990. </year>
Reference-contexts: 1. Introduction Communication problems between the user and the robot manipulator represent a major burden for a more general-purpose use of modern robots. The recently introduced idea of vision-based robot programming <ref> [7, 12] </ref> represents an attempt to overcome this difficulty. Vision-based programming uses vision as a powerful medium for communication between the user and the robot manipulator. Vision can be applied to transfer data in both directions, i.e. from the user to the robot and reversely.
Reference: [8] <author> M. Ishii, S. Sakane, M. Kakikura, and Y. Mikami. </author> <title> A 3-D sensor system for teaching robot paths and environments. </title> <journal> Int. J. Robotics Res., </journal> <volume> 6(2) </volume> <pages> 45-59, </pages> <month> Summer </month> <year> 1987. </year>
Reference-contexts: Programming of robot paths with the help of vision has also received some attention in the past. A PSD camera for measuring the desired pose (position and orientation) at the important passing points was described in <ref> [8] </ref>. Robot paths were specified as simple point-to-point motions. Another camera system for programming of robot trajectories was proposed in [2]. A dense set of poses on the desired trajectory was measured in order to estimate the overall trajectory.
Reference: [9] <author> Y. Kuniyoshi, M. Inaba, and H. Inoue. </author> <title> Teaching by showing: Generating robot programs by visual observation of human performance. </title> <booktitle> In Proc. 20th Int. Symp. Industrial Robots, </booktitle> <pages> pages 119-126, </pages> <address> Tokyo, Japan, </address> <year> 1989. </year>
Reference-contexts: Vision-based programming paradigm can be employed to simultaneously solve both problems. A straightforward method for transferring the user's knowledge about the task by means of vision is "Teaching by Showing" <ref> [9] </ref> which can be viewed as a part of vision-based programming. When using this method, the user shows the intended task to the robot by actually doing it himself. The performed task is observed and processed by the robot's visual system.
Reference: [10] <author> Y. Kuniyoshi, M. Inaba, and H. Inoue. </author> <title> Seeing, understanding and doing human task. </title> <booktitle> In Proc. IEEE Int. Conf. Robotics and Automation, </booktitle> <pages> pages 2-9, </pages> <address> Nice, France, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Some results on visual recognition of action sequences performed by the user and their transformation into the robot language commands specifying the task have been given in <ref> [10, 6] </ref>. Programming of robot paths with the help of vision has also received some attention in the past. A PSD camera for measuring the desired pose (position and orientation) at the important passing points was described in [8]. Robot paths were specified as simple point-to-point motions.
Reference: [11] <author> T. Lyche and L. L. Schumaker. </author> <title> Computation of smoothing and interpolating natural splines via local bases. </title> <journal> SIAM J. Numer Anal., </journal> <volume> 10(6) </volume> <pages> 1027-1036, </pages> <month> December </month> <year> 1973. </year>
Reference-contexts: A local basis for the M -dimensional space of natural splines which consists of B-splines that are modified to fulfill the natural boundary conditions is described in <ref> [11] </ref>. Let fx 1 ; : : : ; x M g be the natural splines belonging to this basis.
Reference: [12] <author> B. Shepherd. </author> <title> Applying visual programming to robotics. </title> <booktitle> In Proc. IEEE Int. Conf. Robotics and Automation, </booktitle> <volume> Vol. II, </volume> <pages> pages 707-712, </pages> <address> At-lanta, Georgia, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: 1. Introduction Communication problems between the user and the robot manipulator represent a major burden for a more general-purpose use of modern robots. The recently introduced idea of vision-based robot programming <ref> [7, 12] </ref> represents an attempt to overcome this difficulty. Vision-based programming uses vision as a powerful medium for communication between the user and the robot manipulator. Vision can be applied to transfer data in both directions, i.e. from the user to the robot and reversely.
Reference: [13] <author> Staubli-Unimation. </author> <title> Unival Robot Controller | Users's Guide to VAL II, </title> <type> Version 4, </type> <year> 1990. </year>
Reference-contexts: But the covariance matrix of the parameters describing the orientation becomes singular at the critical orientations which results in insignificant measurements. For this reason we decided to use the Euler angles to parameterize the orientational part of the pose. In particular, we use the PUMA's OAT angles <ref> [13] </ref>. Note that the parameterization of the orientation in the procedure for trajectory reconstruction need not be the same as the one used when the pose is calculated. <p> With joint-interpolated motion the user can command the poses in time intervals as short as about 60 milliseconds while the time interval between the two commands in the other types of motion must be at least about 140 milliseconds <ref> [13] </ref>. Since the reconstructed trajectories are continuous, the user can generate the motion commands at an arbitrary time interval. Therefore is the joint-interpolated motion a method of choice. It results in the fastest cycle time for a particular move.
Reference: [14] <author> A. Ude. </author> <title> Trajectory generation from noisy positions of object features for teaching robot paths. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 11(2) </volume> <pages> 113-127, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: More details on the estimation of the covariance matrix x can be found in <ref> [14] </ref>. It is often useful to estimate the trajectory at the joint level. In this way, one can avoid the transformation of the Cartesian coordinates into joint coordinates at run time. Besides, the bounds on robot's joint velocities and accelerations are often set. <p> The banded linear system which must be solved to calculate the coefficients ff j is given in <ref> [14] </ref>. The optimal smoothing parameter must be determined by some objective method. If the components of run from zero to infinity, runs from an interpolant to the data, to the polynomial of degree m 1 best fitting the data in a least squares sense. <p> If the components of run from zero to infinity, runs from an interpolant to the data, to the polynomial of degree m 1 best fitting the data in a least squares sense. Some methods for the estimation of the smoothing parameter are given in <ref> [4, 14] </ref>. Some simulation results showing the accuracy of the reconstructed trajectory as a function of time are depicted in Figures 3 and 4. In this experiment, m from the expression (6) was set to 3, i.e. the jerk was kept small in order to smooth the trajectory. <p> The quadratic pro gram (15) has a unique solution. The estimation of the smoothing parameter is not to be discussed in this paper because it is a topic of its own. For the case D = 1 we relate the interested reader to [15]. Using the results from <ref> [4, 14] </ref>, the methods from [15] can be extended to the higher dimensions.
Reference: [15] <author> G. Wahba. </author> <title> Spline Models for Observational Data. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1990. </year>
Reference-contexts: We would like to minimize the criteria f () and g k () simultaneously, but these are conflicting goals in general. A standard nonparametric so lution is to minimize the following combined criterion <ref> [3, 15] </ref>: = arg min f () + k=1 4 This criterion function is minimized over all trajectories with at least piecewise continuous m-th derivative. = [ 1 ; : : : ; D ] T , k &gt; 0, is called the smoothing parameter which controls the tradeoff between goodness-of-fit <p> The matrix Y is also sparse. The quadratic pro gram (15) has a unique solution. The estimation of the smoothing parameter is not to be discussed in this paper because it is a topic of its own. For the case D = 1 we relate the interested reader to <ref> [15] </ref>. Using the results from [4, 14], the methods from [15] can be extended to the higher dimensions. <p> The estimation of the smoothing parameter is not to be discussed in this paper because it is a topic of its own. For the case D = 1 we relate the interested reader to <ref> [15] </ref>. Using the results from [4, 14], the methods from [15] can be extended to the higher dimensions.
Reference: [16] <author> F. Wallner, P. Weckesser, and R. Dillmann. </author> <title> Calibration of the active stereo vision system KASTOR with standardized perspective matrices. </title> <editor> In A. Gruen and H. Kahmen, editors, </editor> <booktitle> Optical 3-D Measurement Techniques II, </booktitle> <pages> pages 98-105. </pages> <address> Wichmann, Karlsruhe, </address> <year> 1993. </year>
Reference-contexts: First of all, the vision system must be capable of processing the images in real-time. Furthermore, since the object must be tracked in space and time, active stereo vision systems are preferred to the passive ones. We use the active stereo vision system KASTOR 2 <ref> [16] </ref> which has been developed at the University of Karlsruhe. It comprises two CCD camera units with three motors for zoom, focus and vergence each and a central unit with motors for pan and tilt control of the camera head. <p> This symbolic data is used as an input to the algorithm which estimates the object's pose. More details on the design of our vision system can be found in <ref> [16] </ref>. 1 Hybrid Object Model 2 Karlsruhe Active Stereo Real-Time Vision System 2 The object localization and tracking procedure consists of two phases: a bootstrapping phase and a tracking phase.
Reference: [17] <author> J. Weng, P. Cohen, and N. Rebibo. </author> <title> Motion and structure estimation from stereo image sequences. </title> <journal> IEEE Trans. Robotics Automat., </journal> <volume> 8(3) </volume> <pages> 362-382, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Geometric and stereo constraints are considered in this procedure. The matched segments can be used to estimate the instantaneous pose of the object [18]. Alternatively, the object's corner points can be detected and the pose can be estimated using point correspondences <ref> [17] </ref>.
Reference: [18] <author> Z. Zhang and O. Faugeras. </author> <title> 3D Dynamic Scene Analysis. </title> <publisher> Springer, </publisher> <address> Berlin, Heidelberg, </address> <year> 1992. </year> <month> 8 </month>
Reference-contexts: This is done by simultaneous matching of straight line segments extracted from the stereo image pair with modelled object features. Geometric and stereo constraints are considered in this procedure. The matched segments can be used to estimate the instantaneous pose of the object <ref> [18] </ref>. Alternatively, the object's corner points can be detected and the pose can be estimated using point correspondences [17].
References-found: 18

