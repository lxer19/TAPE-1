URL: http://http.cs.berkeley.edu/~kanazawa/papers/aaai94.ps
Refering-URL: http://http.cs.berkeley.edu/~kanazawa/papers/aaai94.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: kanazawa@cs.berkeley.edu  
Title: Sensible Decisions: Toward A Theory of Decision-Theoretic Information Invariants  
Author: Keiji Kanazawa 
Address: Berkeley, California 94720  
Affiliation: Computer Science Division University of California  
Abstract: We propose a decision-theoretic notion of invariance in bounded rational decision making. We show how optimal decision making in sensory robotics can be approximately preserved under transformations of the decision rule. In particular, we present a decision theoretic analysis of the use of visual routines in action arbitration in real-time robot soccer. In this domain, stochastic dominance, and therefore decisions, can be sensed approximately from the environment, and we exploit this in our decision making. This paper appears in AAAI-94. 
Abstract-found: 1
Intro-found: 1
Reference: [AC87] <author> Philip E. Agre and David Chapman. Pengi: </author> <title> An implementation of a theory of activity. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pages 268-272, </pages> <address> Seattle, Washington, 1987. </address> <publisher> AAAI. </publisher>
Reference-contexts: A visual routine might also, for example, help pool players with projection of ball trajectories. Visual routines theory was developed as a model of biological vision. It was applied to video game playing by Chapman and Agre <ref> [AC87, Cha92] </ref>. Dynamite soccer is similar to their video games, especially in our current configuration with a camera that has a complete bird's eye view of the game playing area. Thus it is at least plausible that Dynamites can apply visual routines fruitfully.
Reference: [BKM + 93] <author> Rod Barman, Stewart Kingdon, Alan Mackworth, Dinesh Pai, Michael Sahota, Heath Wilkinson, and Ying Zhang. Dynamite: </author> <title> A testbed for multiple mobile robots. </title> <booktitle> In Proceedings of the 1993 IJCAI Workshop on Dynamically Interacting Robots, </booktitle> <address> Chambery, France, </address> <year> 1993. </year> <month> IJCAII. </month>
Reference-contexts: decision-theoretic information invariance, where approximately optimal transformations in an agent's decision rules can lead to improved performance with bounded loss in decision quality. 2 The Soccer Domain The Laboratory for Computational Intelligence at the University of British Columbia has been undertaking a project called Dynamo centering around mobile robot soccer <ref> [BKM + 93] </ref>. Soccer is a highly dynamic domain ideal for research in bounded rational decision-making. It is characterized by continual activity, direct physical manipulation, distributed interacting agents (friendly, hostile, and neutral), and a high degree of uncertainty.
Reference: [Cha92] <author> David Chapman. </author> <title> Vision, Instruction, and Action. </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, Massachusetts, </address> <year> 1992. </year>
Reference-contexts: A visual routine is like a subroutine built out of the primitive computations of visual operators. A visual routine can, for example, detect if a point is in an enclosed region in an image by color-filling from the point outward <ref> [Cha92] </ref>. A visual routine might also, for example, help pool players with projection of ball trajectories. Visual routines theory was developed as a model of biological vision. It was applied to video game playing by Chapman and Agre [AC87, Cha92]. <p> A visual routine might also, for example, help pool players with projection of ball trajectories. Visual routines theory was developed as a model of biological vision. It was applied to video game playing by Chapman and Agre <ref> [AC87, Cha92] </ref>. Dynamite soccer is similar to their video games, especially in our current configuration with a camera that has a complete bird's eye view of the game playing area. Thus it is at least plausible that Dynamites can apply visual routines fruitfully.
Reference: [Coo90] <author> Gregory F. Cooper. </author> <title> The computational complexity of probabilistic inference using bayesian belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 42(2-3):393-405, </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: As designers of autonomous agents, we seek 1 robustness in agent behavior in the face of uncertainty. Decision theory and game theory [Sav54, vNM47] are normative theories of action with optimal prescriptions about rational behavior. Applying these theories is often a battle with computational complexity <ref> [Coo90] </ref>. The space of possible contingencies is typically large, and guaranteeing an agent's response time to external events often requires trading off the optimality of the agent's decisions. <p> Decision theory prescribes a rational agent to undertake the action ^ a that has the maximum expected utility. The number of states w is of exponential order, and the problem of finding the action with maximum utility is NP-hard <ref> [Coo90] </ref>. 6 4 Decision-theoretic Information Invariants The main thesis of this paper is that we can substitute expensive decision-theoretic computation by simple visual computations with bounded loss in the optimality of the decisions made. We capture this with the notion of decision-theoretic information invariance.
Reference: [DB88] <author> Thomas Dean and Mark Boddy. </author> <title> An analysis of time dependent planning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 49-54, </pages> <address> Minneapolis, Minnesota, 1988. </address> <publisher> AAAI. </publisher>
Reference-contexts: In 3 Depending on performance characteristics desired, and given rules whose reliability and efficiency are known, we can build a control system that approximates an optimal DTA with known error and performance. This is similar to control of inference using anytime and contract algorithms <ref> [DB88, Zil93] </ref>. 8 9 the following, we present an analysis of the accuracy of the VRA. Bear in mind that ours is but a coarse analysis with many simplifying assumptions. <p> The analysis that we have performed here is for a special simple case. It is effectively an analysis of the sensitivity of control output to the type of algorithm used. It is related to work in value of information [How66], anytime and contract algorithms <ref> [DB88, Zil93] </ref>, and approximation and abstraction in Bayesian networks [Pro93]. In addition to work presented here, we have performed analyses using different assumptions about enemy and ball behavior and their uncertainty. For example, we have performed analyses incorporating steering uncertainty in addition to uncertainty about vehicle velocity.
Reference: [DJR93] <author> Bruce Donald, James Jennings, and Daniela Rus. </author> <title> Towards a theory of information invariants for cooperating autonomous mobile robots. </title> <booktitle> 16 In Proceedings of the International Symposium on Robotics Research (ISRR), </booktitle> <address> Hidden Valley, Pennsylvania, </address> <year> 1993. </year>
Reference-contexts: We capture this with the notion of decision-theoretic information invariance. Recently, Donald and colleagues <ref> [DJR93] </ref> and Horswill [Hor93] have introduced theories of program transformation focusing on the invariance of the input/output behavior of sensory-robotic control programs. Roughly speaking, two programs are informationally invariant (borrowing Donald's terminology) if they achieve the same results in the same situations.
Reference: [Gol93] <author> Moises Goldszmidt. </author> <title> Putting Qualitative Probability to Work Workshop, </title> <month> November </month> <year> 1993. </year>
Reference-contexts: The space of possible contingencies is typically large, and guaranteeing an agent's response time to external events often requires trading off the optimality of the agent's decisions. For this reason, there is great interest in theories of qualitative probability and decision theory incorporating, for example, technology from nonmonotonic reasoning <ref> [Gol93] </ref>. We propose a new point in the spectrum of qualitative decision-making, a continuous counterpart to symbolic qualitative reasoning. Our theory attempts to shed light on the informational utility of certain classes of geometric relations and perceptual cues.
Reference: [Hor93] <author> Ian D. Horswill. </author> <title> Specialization of Perceptual Processes. </title> <type> PhD thesis, </type> <institution> MIT, Cambridge, Massachusetts, </institution> <year> 1993. </year>
Reference-contexts: We capture this with the notion of decision-theoretic information invariance. Recently, Donald and colleagues [DJR93] and Horswill <ref> [Hor93] </ref> have introduced theories of program transformation focusing on the invariance of the input/output behavior of sensory-robotic control programs. Roughly speaking, two programs are informationally invariant (borrowing Donald's terminology) if they achieve the same results in the same situations.
Reference: [How66] <author> Ronald A. Howard. </author> <title> Information value theory. </title> <journal> IEEE Transactions on Systems Science and Cybernetics, </journal> <volume> 2(1) </volume> <pages> 22-26, </pages> <year> 1966. </year>
Reference-contexts: The analysis that we have performed here is for a special simple case. It is effectively an analysis of the sensitivity of control output to the type of algorithm used. It is related to work in value of information <ref> [How66] </ref>, anytime and contract algorithms [DB88, Zil93], and approximation and abstraction in Bayesian networks [Pro93]. In addition to work presented here, we have performed analyses using different assumptions about enemy and ball behavior and their uncertainty.
Reference: [Pro93] <author> Gregory Provan. </author> <title> Tradeoffs in constructing and evaluating temporal influence diagrams. </title> <booktitle> In Proceedings of the Ninth Conference on Uncertainty in Artificial Intelligence, </booktitle> <address> Washington, D.C., </address> <year> 1993. </year>
Reference-contexts: It is effectively an analysis of the sensitivity of control output to the type of algorithm used. It is related to work in value of information [How66], anytime and contract algorithms [DB88, Zil93], and approximation and abstraction in Bayesian networks <ref> [Pro93] </ref>. In addition to work presented here, we have performed analyses using different assumptions about enemy and ball behavior and their uncertainty. For example, we have performed analyses incorporating steering uncertainty in addition to uncertainty about vehicle velocity.
Reference: [Sah94] <author> Michael Sahota. </author> <title> Reactive deliberation: An architecture for real-time intelligent control in dynamic environments. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <address> Seattle, Wash-ington, </address> <year> 1994. </year> <note> AAAI Press. To appear. </note>
Reference-contexts: The vehicles can be commanded at 60Hz as well; actual lag depends on the controller used. Members of the Dynamo group 1 have implemented a layered control architecture with vehicle and ball trajectory planning and demonstrated it in real games of Dynamite soccer <ref> [Sah94] </ref>. The state of the art in this experimentation has been two robots playing against each other. This author is currently investigating algorithms to incorporate more players.
Reference: [Sav54] <author> Leonard J. Savage. </author> <title> The Foundations of Statistics. </title> <publisher> Dover, </publisher> <year> 1954. </year>
Reference-contexts: 1 Introduction The world demands behavior that is immediate, and yet guided by the anticipated consequences of observed events. As designers of autonomous agents, we seek 1 robustness in agent behavior in the face of uncertainty. Decision theory and game theory <ref> [Sav54, vNM47] </ref> are normative theories of action with optimal prescriptions about rational behavior. Applying these theories is often a battle with computational complexity [Coo90].
Reference: [Ull83] <author> Shimon Ullman. </author> <title> Visual routines. </title> <institution> AI-Memo-723, MIT Artificial Intelligence Laboratory, </institution> <address> Cambridge, MA, </address> <year> 1983. </year>
Reference-contexts: Rather than being a purely symbolic theory, our approach points the way toward the embodiment of qualitative probability in systems dynamically sensing and interacting with their environments in real-time. Concretely, we adapt visual routines <ref> [Ull83] </ref> to extract geometric information that accurately or approximately indexes optimal actions in the control of soccer-playing mobile robots. <p> In the process, we hope to show that adopting a biologically-inspired algorithm need not conflict with being a good Bayesian. The theory of visual routines is due to Ullman <ref> [Ull83] </ref>. Visual routines theory assumes the existence of a small set of primitive visual operators that perform computations on a scene or image. Examples of operators are line projection (drawing rays), detecting intersections of rays, measuring distances, and filling regions with color.
Reference: [vNM47] <author> John von Neumann and O. Morgenstern. </author> <title> Theory of games and economic behavior. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, 2nd edition, </address> <year> 1947. </year>
Reference-contexts: 1 Introduction The world demands behavior that is immediate, and yet guided by the anticipated consequences of observed events. As designers of autonomous agents, we seek 1 robustness in agent behavior in the face of uncertainty. Decision theory and game theory <ref> [Sav54, vNM47] </ref> are normative theories of action with optimal prescriptions about rational behavior. Applying these theories is often a battle with computational complexity [Coo90].
Reference: [Zil93] <author> Shlomo Zilberstein. </author> <title> Operational Rationality Through Compilation of Anytime Algorithms. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley, California, </institution> <year> 1993. </year> <month> 17 </month>
Reference-contexts: In 3 Depending on performance characteristics desired, and given rules whose reliability and efficiency are known, we can build a control system that approximates an optimal DTA with known error and performance. This is similar to control of inference using anytime and contract algorithms <ref> [DB88, Zil93] </ref>. 8 9 the following, we present an analysis of the accuracy of the VRA. Bear in mind that ours is but a coarse analysis with many simplifying assumptions. <p> The analysis that we have performed here is for a special simple case. It is effectively an analysis of the sensitivity of control output to the type of algorithm used. It is related to work in value of information [How66], anytime and contract algorithms <ref> [DB88, Zil93] </ref>, and approximation and abstraction in Bayesian networks [Pro93]. In addition to work presented here, we have performed analyses using different assumptions about enemy and ball behavior and their uncertainty. For example, we have performed analyses incorporating steering uncertainty in addition to uncertainty about vehicle velocity.
References-found: 15

