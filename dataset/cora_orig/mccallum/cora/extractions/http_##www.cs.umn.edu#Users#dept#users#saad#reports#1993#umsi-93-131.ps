URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1993/umsi-93-131.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1993/
Root-URL: http://www.cs.umn.edu
Title: DQGMRES: a Quasi minimal residual algorithm based on incomplete orthogonalization  
Author: Youcef Saad and Kesheng Wu 
Note: This work was supported in part by DARPA under grant number NIST 60NANB2D1272 and in part by NSF under grant number NSF/CCR-9214116.  
Date: October, 1993  
Affiliation: University of Minnesota, Computer Science Department  
Abstract: We describe a Krylov subspace technique based on incomplete orthogonalization of the Krylov vectors which can be considered as a truncated version of GMRES. Unlike GMRES the parent algorithm from which it is derived, DQGMRES does not require restarting. It seems also to be less prone to stagnation. In addition, the algorithm allows flexible preconditioning, i.e., it can accomodate variations in the preconditioner at every step. A number of numerical tests are reported which show that the algorithm often performs better than GMRES and FGMRES. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. N. Brown and A. C. Hindmarsh. </author> <title> Matrix-free methods for stiff systems of odes. </title> <journal> SIAM J. Num. Anal., </journal> <volume> 23 </volume> <pages> 610-638, </pages> <year> 1986. </year>
Reference-contexts: This technique was first described by Brown and Hindmarsh <ref> [1] </ref> who reported some numerical tests with it in the context of systems of ODE's. Algorithm 4.1 Quasi-GMRES Algorithm Run a modification of GMRES algorithm in which the Arnoldi process is replaced by the Incomplete Orthogonalization process and every other computation remains unchanged.
Reference: [2] <author> R. W. Freund and N. M. Nachtigal. </author> <title> QMR: a quasi-minimal residual method for non-Hermitian linear systems. </title> <journal> Numer. Math., </journal> <volume> 60 </volume> <pages> 315-339, </pages> <year> 1991. </year>
Reference-contexts: We note that DQGMRES is similar in nature to the GMRESR family of algorithms introduced by Van der Vorst and Vuik [9]. Finally, we would like to mention that convergence results identical to those of the QMR algorithm <ref> [2, 3] </ref> hold.
Reference: [3] <author> Noel M. Nachtigal. </author> <title> A look-ahead variant of the Lanczos Algorithm and its application to the Quasi-Minimal Residual method for non-Hermitian linear systems. </title> <type> PhD thesis, </type> <institution> MIT, Appliexd Mathematics, </institution> <address> Cambridge, Massachusetts 02139, </address> <year> 1991. </year>
Reference-contexts: We note that DQGMRES is similar in nature to the GMRESR family of algorithms introduced by Van der Vorst and Vuik [9]. Finally, we would like to mention that convergence results identical to those of the QMR algorithm <ref> [2, 3] </ref> hold.
Reference: [4] <author> Y. Saad. </author> <title> Krylov subspace methods for solving large unsymmetric linear systems. </title> <journal> Mathematics of Computation, </journal> <volume> 37 </volume> <pages> 105-126, </pages> <year> 1981. </year>
Reference-contexts: i ; v j ) = ffi ij for ji jj&lt;k In addition, the relations (4) - (5) are still valid, but the matrix H m now has a particular structure, namely, it is banded Hessenberg since h i;j = 0 for i j k. 3.2 DIOM The IOM algorithm <ref> [5, 4] </ref> is defined similarly to the FOM algorithm except that the Arnoldi vectors obtained are not orthogonal but locally orthogonal. The Hessenberg matrix H m obtained from the incomplete orthogonalization process has a band structure with a bandwidth of k + 1.
Reference: [5] <author> Y. Saad. </author> <title> Practical use of some Krylov subspace methods for solving indefinite and unsymmetric linear systems. </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 5 </volume> <pages> 203-228, </pages> <year> 1984. </year>
Reference-contexts: Several methods based on this approach have been developed in the past, one of which we refer to as the Full Orthogonalization Method (FOM) <ref> [5] </ref>. Given an initial guess x 0 to the linear system (1) we consider the choice v 1 = r 0 =fi fi kr 0 k 2 (7) in the Arnoldi procedure. <p> i ; v j ) = ffi ij for ji jj&lt;k In addition, the relations (4) - (5) are still valid, but the matrix H m now has a particular structure, namely, it is banded Hessenberg since h i;j = 0 for i j k. 3.2 DIOM The IOM algorithm <ref> [5, 4] </ref> is defined similarly to the FOM algorithm except that the Arnoldi vectors obtained are not orthogonal but locally orthogonal. The Hessenberg matrix H m obtained from the incomplete orthogonalization process has a band structure with a bandwidth of k + 1. <p> This raises the question of developing a formula whereby the approximate solution can be easily computed from the previous approximation x m1 and a small number of vectors that are being updated at each step. A procedure of this type called DIOM (Direct version of IOM) was presented in <ref> [5] </ref> and we would like describe it briefly for the sake of completeness. DIOM is derived by writing the LU factorization of H m as H m = L m U m . <p> We note that a simple formulation of the algorithm which exploits Gaussian Elimination with partial pivoting when solving the Hessenberg system was also developed in <ref> [5] </ref>.
Reference: [6] <author> Y. Saad. ILUT: </author> <title> a dual threshold incomplete ILU factorization. </title> <type> Technical Report 92-38, </type> <institution> Minnesota Supercomputer Institute, University of Minnesota, Minneapolis, </institution> <year> 1992. </year>
Reference-contexts: Most of them are on a SPARC-10, a small number of tests are run on SPARC-2 and SPARC-IPX workstations. We used a number of different preconditioners in our tests, including the standard m-step SOR (Successive Over-Relaxation) and SSOR (Symmetric Successive Over-Relaxation) precon-ditioners, ILU (0), and ILUT (k; *) <ref> [6] </ref>. Our version of DQGMRES was implemented with the variable right preconditioning option, to enable us to exploit various types of iterative linear system solvers as preconditioners. Thus, for DQGMRES we also tested using a number of iterative solvers as preconditioners including, BCG, CGNR, etc.. <p> In figure 4 (b), DQGMRES (8) converges in 308 iterations. For the two other linear systems tested, the effectiveness of the ILU0 preconditioning is comparable with that of SSOR. Next, we test a more sophisticated version of ILU, called ILUT (p, *), discussed in <ref> [6] </ref>. This is an incomplete LU factorization with a dual dropping strategy, where p is the maximum number of fill-ins allowed per row, * is a relative drop tolerance.
Reference: [7] <author> Y. Saad. </author> <title> A flexible inner-outer preconditioned GMRES algorithm. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 14 </volume> <pages> 461-469, </pages> <year> 1993. </year>
Reference-contexts: An important characteristic of DQGMRES is that it is flexible in that it can allow variable preconditioners without requiring additional storage. Specifically, when right preconditioning is used, the preconditioner M is allowed to vary at each step. The idea is similar to that of FGMRES <ref> [7] </ref>. In both cases we must compute the vectors M 1 j v j 's and in the case of FGMRES, we need to save these vectors which requires extra storage [7]. <p> The idea is similar to that of FGMRES <ref> [7] </ref>. In both cases we must compute the vectors M 1 j v j 's and in the case of FGMRES, we need to save these vectors which requires extra storage [7]. <p> One advantage of DQGMRES over GMRES, TFQMR and BiCGSTAB, is that it is `flexible'. It allows the preconditioner to vary at each step without requiring extra storage as is the case for GMRES <ref> [7] </ref>. Generally speaking the algorithm often does better than GMRES for the same k, the number of vectors that are mutually orthogonal in the Arnoldi sequence at any given step. However for the same k, DQGMRES requires twice as much storage as GMRES, but the same storage as FGMRES. Acknowledgement.
Reference: [8] <author> Y. Saad and M. H. Schultz. </author> <title> GMRES: a generalized minimal residual algorithm for solving nonsymmetric linear systems. </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 7 </volume> <pages> 856-869, </pages> <year> 1986. </year>
Reference-contexts: V m y] ? spanfV m g 3 immediately yields V T and as a result the approximate solution using the above m-dimensional subspaces is given by x m = x 0 + V m y m (8) m (fie 1 ) : (9) The Generalized Minimum Residual Method (GMRES) <ref> [8] </ref> is a projection method which minimizes the residual norm over all vectors in the affine subspace x 0 +K m . The implementation of an algorithm based on this approach is very similar to that of the FOM algorithm. <p> The idea is simply to save the previous rotations, then apply them on each newly computed column of H m . Once this is done we can then determine the last rotation needed to eliminate h m+1;m . For details see <ref> [8] </ref>. 3 Methods based on incomplete Arnoldi orthogonalization In the previous algorithms, the dimension m of the Krylov subspace increases by one a each step and this makes the procedure impractical for large m. There are two typical remedies for this. The simplest remedy is to restart the algorithm.
Reference: [9] <author> H. A. van der Vorst and C. Vuik. GMRESR: </author> <title> a family of nested gmres methods. </title> <type> Technical Report 91-80, </type> <institution> Delft University of Technology, Mathematics and Informatics, Delft, </institution> <address> The Netherlands, </address> <year> 1991. </year> <month> 25 </month>
Reference-contexts: In fact, we can simply overwrite it onto the space used for p j and modify step 4 of algorithm 4.2 accordingly. We note that DQGMRES is similar in nature to the GMRESR family of algorithms introduced by Van der Vorst and Vuik <ref> [9] </ref>. Finally, we would like to mention that convergence results identical to those of the QMR algorithm [2, 3] hold.
References-found: 9

