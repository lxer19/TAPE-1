URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-205.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Title: Finding Similar Patterns in Large Image Databases  
Author: R. W. Picard and T. Kabir 
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 205 Appeared: IEEE ICASSP, Minneapolis, MN, Vol. V., pp.161-164, Apr. 1993 Abstract We address a new and rapidly growing application, automated searching through large sets of images to find a pattern "similar to this one." Classical matched filtering fails at this problem since patterns, particularly textures, can differ in every pixel and still be perceptually similar. Most potential recognition methods have not been tested on large sets of imagery. This paper evaluates a key recognition method on a library of almost 1000 images, based on the entire Brodatz texture album. The features used for searching rely on a significant improvement to the traditional Karhunen-Loeve (KL) transform which makes it shift-invariant. Results are shown for a variety of false alarm rates and for different subsets of KL features. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Brodatz. </author> <title> Textures: A Photographic Album for Artists and Designers. </title> <publisher> Dover, </publisher> <address> New York, </address> <year> 1966. </year>
Reference-contexts: The mean-squared error, or a weighted version of it is then used to measure "closeness" in this new space. Most studies of potential transformation algorithms have been run on small sets of test data, typically four to sixteen images at once from the standard Brodatz library of natural textures <ref> [1] </ref>. Moreover, selected test images have typically exhibited a lot of visual and semantic dissimilarity, as well as a lot of within-class homogeneity.
Reference: [2] <author> R. Haralick. </author> <title> Statistical and structural approaches to texture. </title> <journal> Proc. IEEE, </journal> <volume> 67 </volume> <pages> 786-804, </pages> <month> May </month> <year> 1979. </year>
Reference-contexts: For texture, it has been shown that local second order statistics are important, and that statistics such as co-occurrences incorporate perceptually significant changes <ref> [2] </ref>. However, features based purely on co-occurrences have been out-performed by features based on outputs of various local filters, and emphasis has shifted to the choice of these filters [3, 4, 5]. This study begins with the "eigen-filters," or principle components of the texture covariance.
Reference: [3] <author> F. Ade. </author> <title> Characterization of textures by `Eigenfilters'. </title> <booktitle> Signal Processing, </booktitle> <volume> 5 </volume> <pages> 451-457, </pages> <year> 1983. </year>
Reference-contexts: However, features based purely on co-occurrences have been out-performed by features based on outputs of various local filters, and emphasis has shifted to the choice of these filters <ref> [3, 4, 5] </ref>. This study begins with the "eigen-filters," or principle components of the texture covariance. Eigenfilters have been shown to provide good texture discrimination on small sets of data [3, 4]. <p> This study begins with the "eigen-filters," or principle components of the texture covariance. Eigenfilters have been shown to provide good texture discrimination on small sets of data <ref> [3, 4] </ref>. The eigenfilter method is more commonly known in the image coding community as the Karhunen-Loeve (KL) transform or principal components analysis, and is optimal for decorrelating the features.
Reference: [4] <author> M. Unser. </author> <title> Local linear transforms for texture measurements. </title> <booktitle> Signal Processing, </booktitle> <volume> 11 </volume> <pages> 61-78, </pages> <year> 1986. </year>
Reference-contexts: However, features based purely on co-occurrences have been out-performed by features based on outputs of various local filters, and emphasis has shifted to the choice of these filters <ref> [3, 4, 5] </ref>. This study begins with the "eigen-filters," or principle components of the texture covariance. Eigenfilters have been shown to provide good texture discrimination on small sets of data [3, 4]. <p> This study begins with the "eigen-filters," or principle components of the texture covariance. Eigenfilters have been shown to provide good texture discrimination on small sets of data <ref> [3, 4] </ref>. The eigenfilter method is more commonly known in the image coding community as the Karhunen-Loeve (KL) transform or principal components analysis, and is optimal for decorrelating the features.
Reference: [5] <author> R. Vistnes. </author> <title> Texture models and image measures for texture discrimination. </title> <journal> Int. J. of Comp. Vis., </journal> <volume> 3 </volume> <pages> 313-336, </pages> <year> 1989. </year>
Reference-contexts: However, features based purely on co-occurrences have been out-performed by features based on outputs of various local filters, and emphasis has shifted to the choice of these filters <ref> [3, 4, 5] </ref>. This study begins with the "eigen-filters," or principle components of the texture covariance. Eigenfilters have been shown to provide good texture discrimination on small sets of data [3, 4].
Reference: [6] <author> C. W. Therrien. </author> <title> Decision Estimation and Classification. </title> <publisher> John Wiley and Sons, Inc., </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: With this analysis the calculations are greatly reduced. The associated eigenvalues are used to order the eigenvectors. Note that in recognition, unlike in coding, j &gt; i does not imply that u j will be more useful in reducing error than u i <ref> [6] </ref>. For a given database, these values and the projection of each x i , i = 1; : : : ; d, onto the p eigenvectors are pre-computed and stored. These projections (or KL transform coefficients) are the features used for comparing patterns. <p> It is acceptable in database search applications to declare success if all the patterns it should have found get displayed. Each point on this plot was formed from an average of the performance for all the 999 database images. Similar to the Neyman-Pearson operating characteristic <ref> [6] </ref>, these curves show that the performance of the shift-invariant principal components will increase monotonically with the permitted number of false detections. In the limit of course, as Avg. Recogn. Brodatz Avg. Recogn.
Reference: [7] <author> S. Akamatsu, T. Sasaki, H. Fukamachi, and Y. Sue-naga. </author> <title> A robust face identification scheme - KL expansion of an invariant feature space. </title> <booktitle> In Proc. SPIE Conf. On Intell. Robots and Comp. Vis., </booktitle> <volume> volume 1607, </volume> <pages> pages 71-84, </pages> <address> Boston, Ma, </address> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: However, using the DFT magnitudes makes the KL features invariant to spatial translation. This one difference made an immediately noticeable improvement in the recognition ability of the algorithm. This improvement is similar to one noticed by Akamatsu, et. al. <ref> [7] </ref> in face recognition. Incorporating translation-invariance makes the recognition algorithm perform a little more closely like a human. Other invariants not investigated here [8] may also be similar to those used by humans.
Reference: [8] <author> L. Jacobson and H. Wechsler. </author> <title> Invariant analogical image representation and pattern recognition. Patt. </title> <journal> Rec. Lett., </journal> <volume> 2 </volume> <pages> 289-299, </pages> <year> 1984. </year> <month> 4 </month>
Reference-contexts: This one difference made an immediately noticeable improvement in the recognition ability of the algorithm. This improvement is similar to one noticed by Akamatsu, et. al. [7] in face recognition. Incorporating translation-invariance makes the recognition algorithm perform a little more closely like a human. Other invariants not investigated here <ref> [8] </ref> may also be similar to those used by humans. Although phase is important for structural image reconstruction, the linear part of the phase appears to be unimportant for much of pattern recognition. We suggest that selective use of phase components should be better than discarding all the phase.
References-found: 8

