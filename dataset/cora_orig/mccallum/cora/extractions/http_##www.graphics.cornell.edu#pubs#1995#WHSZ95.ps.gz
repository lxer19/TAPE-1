URL: http://www.graphics.cornell.edu/pubs/1995/WHSZ95.ps.gz
Refering-URL: 
Root-URL: 
Title: Efficient Parallel Global Illumination using Density Estimation key difference of the DE algorithm from conventional
Author: David Zareski Bretton Wade Philip Hubbard Peter Shirley Frank H. T. 
Keyword: CR Categories and Subject Descriptors: D.1.3 [Programming Techniques]: Parallel Programming; I.3.0 [Computer Graphics]: General; I.3.6 [Computer Graphics]: Methodology and Techniques; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism. Additional Key Words and Phrases: Parallel computing, network computing, radiosity, realistic image synthesis, global illumination, density estimation.  
Address: Rhodes Hall, Ithaca, NY  
Note: The  580  14853. World Wide Web home page: http://www.graphics.cornell.edu  
Affiliation: Program of Computer Graphics Cornell University  
Abstract: This paper presents a multi-computer, parallel version of the recently-proposed "Density Estimation" (DE) global illumination method, designed for computing solutions of environments with high geometric complexity (as many as hundreds of thousands of initial surfaces). In addition to the diffuse inter-reflections commonly handled by conventional radiosity methods, this new method can also handle energy transport involving arbitrary non-diffuse surfaces. Output can either be Gouraud-shaded elements for interactive walk-throughs, or ray-traced images for higher quality still frames. The goal of this effort is to provide a near-linear speedup for solutions to existing environment models using tens of processors. The parallel efficiency of the first program has been measured to be above 90% for as many as 16 workers, and the parallel efficiency of the second program has been measured to be above 70% for as many as 12 workers. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> John M. Airey and Ming Ouh-Young. </author> <title> Two adaptive techniques let progressive radiosity outperform the traditional radiosity algorithm. </title> <type> Technical Report TR89-20, </type> <institution> University of North Car-olina at Chapel Hill, </institution> <month> August </month> <year> 1989. </year>
Reference-contexts: Its ability to accurately compute interreflections in a view-independent manner makes it an excellent technique to use in many applications, particularly architectural walkthroughs. Even though several performance improvements to the original algorithm have been made, including hierarchical radiosity [14, 6, 27] and Monte Carlo radiosity <ref> [18, 1, 22, 20] </ref>, which can in practice reduce the execution time from O (n 2 ) to O (n log n) in many cases, performance remains a key research issue.
Reference: [2] <author> Didier Badouel, Thierry Priol, and Kadi Bouatouch. </author> <title> Ray tracing on distributed memory parallel computers: Strategies for distributing computations and data. Parallel Algorithms and Architectures for 3D Image Generation, </title> <note> 1990. ACM Siggraph '90 Course 28 Notes. </note>
Reference-contexts: Therefore, our new algorithm for energy transport more closely resembles ray tracing than the classical radiosity algorithms, which is encouraging since ray tracing has been parallelized successfully <ref> [13, 2, 16] </ref>. One key difference is that our algorithm traces rays from the luminaires (light sources) to the surfaces, while a ray tracer sends rays from the eye to the surfaces and then to the luminaires.
Reference: [3] <author> Daniel R. Baum, Holly E. Rushmeier, and James M. Winget. </author> <title> Improving radiosity solutions through the use of analytically determined form-factors. </title> <journal> Computer Graphics, </journal> <volume> 23(3) </volume> <pages> 325-334, </pages> <month> July </month> <year> 1989. </year> <booktitle> ACM Siggraph '89 Conference Proceedings. </booktitle>
Reference-contexts: Unfortunately, much of this prior work deals primarily with older varieties of the serial radiosity algorithm, which can lead to some inaccuracies in the resulting solutions, such as the well-known artifacts of the hemi-cube method <ref> [3] </ref>. An even larger concern is that progressive refinement radiosity [32] is an O (n 2 ) algorithm when run to final convergence 1 .
Reference: [4] <author> Daniel R. Baum and James M. Winget. </author> <title> Real time radiosity through parallel processing and hardware acceleration. </title> <journal> Computer Graphics, </journal> <volume> 24(1) </volume> <pages> 67-75, </pages> <year> 1990. </year> <booktitle> ACM Workshop on Interactive Graphics Proceedings. </booktitle>
Reference-contexts: Next, performance results from that implementation are presented. Finally, we make some concluding remarks and briefly discuss some ideas for future work. 2 Prior Work Prior research has been done on parallel progressive radiosity by several groups <ref> [9, 21, 4, 11, 8, 10, 31, 7, 5] </ref>, and Chalmers and Paddon have written a survey paper [19] which analyzes both parallel full-matrix (gathering) radiosity and parallel progressive (shooting) radiosity methods.
Reference: [5] <author> Kadi Bouatouch and Thierry Priol. </author> <title> Data management sceme for parallel radiosity. </title> <booktitle> Computer Aided Design, </booktitle> <volume> 26(12) </volume> <pages> 876-882, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: Next, performance results from that implementation are presented. Finally, we make some concluding remarks and briefly discuss some ideas for future work. 2 Prior Work Prior research has been done on parallel progressive radiosity by several groups <ref> [9, 21, 4, 11, 8, 10, 31, 7, 5] </ref>, and Chalmers and Paddon have written a survey paper [19] which analyzes both parallel full-matrix (gathering) radiosity and parallel progressive (shooting) radiosity methods. <p> The most recent of these papers, by Bouatouch and Priol <ref> [5] </ref>, showed an efficiency greater than 82% for as many as 32 processors on scenes of 17,500 and 50,500 patches. <p> The parallel performance results for the Mackintosh room are shown in Figures 5 and 6. Plate 3 is a large furniture warehouse, which contains approximately 150,000 surfaces. This environment is three to four times larger than the largest scenes used in prior ra-diosity research <ref> [29, 27, 5] </ref>, and is more typical of the size that view-independent global illumination algorithms will be facing in the near future.
Reference: [6] <author> Michael B. Carter. </author> <title> Parallel Hierarchical Radiosity Rendering. </title> <type> PhD thesis, </type> <institution> Iowa State University, Department of Electrical Engineering and Computer Engineering, Ames, Iowa, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: Its ability to accurately compute interreflections in a view-independent manner makes it an excellent technique to use in many applications, particularly architectural walkthroughs. Even though several performance improvements to the original algorithm have been made, including hierarchical radiosity <ref> [14, 6, 27] </ref> and Monte Carlo radiosity [18, 1, 22, 20], which can in practice reduce the execution time from O (n 2 ) to O (n log n) in many cases, performance remains a key research issue. <p> The most prominent sub-quadratic radiosity algorithm is hierarchical radiosity [14], which treats subdivided surface patches as a hierarchy rather than a set of independent patches for the purpose of energy transport. Subsequent "clustering" enhancements have been devised <ref> [6, 27] </ref> which can hierarchically group separate surfaces as well. <p> Their attempt to implement this algorithm on a distributed-memory message passing parallel system became "an exercise in frustration" and was abandoned as not being worthwhile [25]. Another attempt to parallelize hierarchical radiosity on a distributed-memory system is described by Carter in his PhD thesis <ref> [6] </ref>. <p> By viewing energy transport from the macroscopic level, the process potentially involves pairwise interactions between all surfaces in the environment. Although hierarchical techniques with clustering <ref> [6, 27] </ref> can usually reduce the number of interactions from O (n 2 ) to O (n log n) by clustering collections of surfaces of limited visibility to another surface, and by eliminating interactions between mutually-occluded pairs of surfaces, the determination of visibility is usually not a local problem 2 .
Reference: [7] <author> C~ apin, Aykanat, and Ozgu~c. </author> <title> Progressive refinement radiosity on ring-connected multicomputers. </title> <booktitle> In Proceedings of the 1993 Symposium on Parallel Rendering in San Jose, California, </booktitle> <pages> pages 71-76, </pages> <year> 1993. </year>
Reference-contexts: Next, performance results from that implementation are presented. Finally, we make some concluding remarks and briefly discuss some ideas for future work. 2 Prior Work Prior research has been done on parallel progressive radiosity by several groups <ref> [9, 21, 4, 11, 8, 10, 31, 7, 5] </ref>, and Chalmers and Paddon have written a survey paper [19] which analyzes both parallel full-matrix (gathering) radiosity and parallel progressive (shooting) radiosity methods.
Reference: [8] <author> Alan Chalmers and Derek Paddon. </author> <title> Parallel processing of progressive refinement radiosity methods. </title> <booktitle> In Proceedings of the Second Eurographics Workshop on Rendering, </booktitle> <year> 1991. </year>
Reference-contexts: Next, performance results from that implementation are presented. Finally, we make some concluding remarks and briefly discuss some ideas for future work. 2 Prior Work Prior research has been done on parallel progressive radiosity by several groups <ref> [9, 21, 4, 11, 8, 10, 31, 7, 5] </ref>, and Chalmers and Paddon have written a survey paper [19] which analyzes both parallel full-matrix (gathering) radiosity and parallel progressive (shooting) radiosity methods.
Reference: [9] <author> Shenchang Eric Chen. </author> <title> A progressive radiosity method and its implementation in a distributed processing environment. </title> <type> Master's thesis, </type> <institution> Program of Computer Graphics, Cornell University, </institution> <month> January </month> <year> 1989. </year>
Reference-contexts: Next, performance results from that implementation are presented. Finally, we make some concluding remarks and briefly discuss some ideas for future work. 2 Prior Work Prior research has been done on parallel progressive radiosity by several groups <ref> [9, 21, 4, 11, 8, 10, 31, 7, 5] </ref>, and Chalmers and Paddon have written a survey paper [19] which analyzes both parallel full-matrix (gathering) radiosity and parallel progressive (shooting) radiosity methods.
Reference: [10] <author> Steven M. Drucker and Peter Schroder. </author> <title> Fast radiosity using a data parallel architecture. </title> <booktitle> In Proceedings of the Third Euro-graphics Workshop on Rendering, </booktitle> <pages> pages 247-258, </pages> <year> 1992. </year>
Reference-contexts: Next, performance results from that implementation are presented. Finally, we make some concluding remarks and briefly discuss some ideas for future work. 2 Prior Work Prior research has been done on parallel progressive radiosity by several groups <ref> [9, 21, 4, 11, 8, 10, 31, 7, 5] </ref>, and Chalmers and Paddon have written a survey paper [19] which analyzes both parallel full-matrix (gathering) radiosity and parallel progressive (shooting) radiosity methods.
Reference: [11] <author> Martin Feda and Werner Purgathofer. </author> <title> Progressive refinement radiosity on a transputer network. </title> <booktitle> In Proceedings of the Second Eurographics Workshop on Rendering, </booktitle> <year> 1991. </year>
Reference-contexts: Next, performance results from that implementation are presented. Finally, we make some concluding remarks and briefly discuss some ideas for future work. 2 Prior Work Prior research has been done on parallel progressive radiosity by several groups <ref> [9, 21, 4, 11, 8, 10, 31, 7, 5] </ref>, and Chalmers and Paddon have written a survey paper [19] which analyzes both parallel full-matrix (gathering) radiosity and parallel progressive (shooting) radiosity methods.
Reference: [12] <author> Al Geist, Adam Beguelin, Jack Dongarra, Weicheng Jiang, Robert Manchek, and Vaidy Sunderam. </author> <title> PVM 3 user's guide and reference manual. </title> <type> Technical Report ORNL/TM-12187, </type> <institution> Oak Ridge National Laboratory, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: For implementing the intertask communication, we chose the PVM 3 (Parallel Virtual Machine version 3) message passing library, which is developed and distributed by Oak Ridge National Laboratory <ref> [12] </ref>. PVM's main advantages are that it is readily available and it supports a wide range of machines, including many brands of workstations, main frames, and parallel supercomputers.
Reference: [13] <author> Stuart A. Green and Derek J. Paddon. </author> <title> A highly flexible multiprocessor solution for ray tracing. </title> <journal> Visual Computer, </journal> <volume> 6 </volume> <pages> 62-73, </pages> <year> 1990. </year>
Reference-contexts: Therefore, our new algorithm for energy transport more closely resembles ray tracing than the classical radiosity algorithms, which is encouraging since ray tracing has been parallelized successfully <ref> [13, 2, 16] </ref>. One key difference is that our algorithm traces rays from the luminaires (light sources) to the surfaces, while a ray tracer sends rays from the eye to the surfaces and then to the luminaires.
Reference: [14] <author> Pat Hanrahan, David Salzman, and Larry Aupperle. </author> <title> A rapid hierarchical radiosity algorithm. </title> <journal> Computer Graphics, </journal> <volume> 25(4) </volume> <pages> 197-206, </pages> <month> July </month> <year> 1991. </year> <booktitle> ACM Siggraph '91 Conference Proceedings. </booktitle>
Reference-contexts: Its ability to accurately compute interreflections in a view-independent manner makes it an excellent technique to use in many applications, particularly architectural walkthroughs. Even though several performance improvements to the original algorithm have been made, including hierarchical radiosity <ref> [14, 6, 27] </ref> and Monte Carlo radiosity [18, 1, 22, 20], which can in practice reduce the execution time from O (n 2 ) to O (n log n) in many cases, performance remains a key research issue. <p> The most prominent sub-quadratic radiosity algorithm is hierarchical radiosity <ref> [14] </ref>, which treats subdivided surface patches as a hierarchy rather than a set of independent patches for the purpose of energy transport. Subsequent "clustering" enhancements have been devised [6, 27] which can hierarchically group separate surfaces as well.
Reference: [15] <author> Paul S. Heckbert. </author> <title> Adaptive radiosity textures for bidirectional ray tracing. </title> <journal> Computer Graphics, </journal> <volume> 24(3) </volume> <pages> 145-154, </pages> <month> August </month> <year> 1990. </year> <booktitle> ACM Siggraph '90 Conference Proceedings. </booktitle>
Reference-contexts: One key difference is that our algorithm traces rays from the luminaires (light sources) to the surfaces, while a ray tracer sends rays from the eye to the surfaces and then to the luminaires. In this respect, our algorithm more closely resembles Heckbert's bidirectional ray tracer <ref> [15] </ref>, and can produce either a 3-D view-independent solution or a 2-D view-dependent image, whereas a ray tracer can only produce the latter.
Reference: [16] <author> Wilfred Lefer. </author> <title> An efficient parallel ray tracing scheme for distributed memory parallel computers. </title> <booktitle> In Proceedings of the 1993 Symposium on Parallel Rendering in San Jose, California, </booktitle> <pages> pages 77-88, </pages> <year> 1993. </year>
Reference-contexts: Therefore, our new algorithm for energy transport more closely resembles ray tracing than the classical radiosity algorithms, which is encouraging since ray tracing has been parallelized successfully <ref> [13, 2, 16] </ref>. One key difference is that our algorithm traces rays from the luminaires (light sources) to the surfaces, while a ray tracer sends rays from the eye to the surfaces and then to the luminaires.
Reference: [17] <author> Dani Lischinski, Filippo Tampieri, and Donald P. Greenberg. </author> <title> Combining hierarchical radiosity and discontinuity meshing. </title> <journal> Computer Graphics, </journal> <pages> pages 199-208, </pages> <month> August </month> <year> 1993. </year> <booktitle> ACM Sig-graph '93 Conference Proceedings. </booktitle>
Reference-contexts: We have also made some initial attempts to parallelize hierarchical radiosity (before the advent of clustering), using a two-pass method with discontinuity meshing <ref> [17] </ref>. The "local pass," which refines the initial "global pass" solution, parallelized quite well on a small scale, with a parallel efficiency of 75% or higher for up to eight processors [34]. <p> and to search for a new algorithm with richer inherent parallelism. 3 Re-examination of Radiosity and Global Illumination After studying existing radiosity algorithms, we came to believe that "the" main limit to parallelism was their view of energy transport, as exemplified by the global pass of the two-pass hierarchical-radiosity algorithms <ref> [17, 27] </ref>. By viewing energy transport from the macroscopic level, the process potentially involves pairwise interactions between all surfaces in the environment.
Reference: [18] <author> Thomas J. V. Malley. </author> <title> A shading method for computer generated images. </title> <type> Master's thesis, </type> <institution> University of Utah, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: Its ability to accurately compute interreflections in a view-independent manner makes it an excellent technique to use in many applications, particularly architectural walkthroughs. Even though several performance improvements to the original algorithm have been made, including hierarchical radiosity [14, 6, 27] and Monte Carlo radiosity <ref> [18, 1, 22, 20] </ref>, which can in practice reduce the execution time from O (n 2 ) to O (n log n) in many cases, performance remains a key research issue.
Reference: [19] <author> Derek Paddon and Alan Chalmers. </author> <title> Parallel processing of the radiosity method. </title> <booktitle> Computer Aided Design, </booktitle> <volume> 26(12) </volume> <pages> 917-927, </pages> <month> De-cember </month> <year> 1994. </year>
Reference-contexts: Finally, we make some concluding remarks and briefly discuss some ideas for future work. 2 Prior Work Prior research has been done on parallel progressive radiosity by several groups [9, 21, 4, 11, 8, 10, 31, 7, 5], and Chalmers and Paddon have written a survey paper <ref> [19] </ref> which analyzes both parallel full-matrix (gathering) radiosity and parallel progressive (shooting) radiosity methods. The most recent of these papers, by Bouatouch and Priol [5], showed an efficiency greater than 82% for as many as 32 processors on scenes of 17,500 and 50,500 patches.
Reference: [20] <author> S. N. Pattanaik and S. P. Mudur. </author> <title> Computation of global illumination by Monte Carlo simulation of the particle model of light. </title> <booktitle> Third Eurographics Workshop on Rendering, </booktitle> <pages> pages 71-83, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Its ability to accurately compute interreflections in a view-independent manner makes it an excellent technique to use in many applications, particularly architectural walkthroughs. Even though several performance improvements to the original algorithm have been made, including hierarchical radiosity [14, 6, 27] and Monte Carlo radiosity <ref> [18, 1, 22, 20] </ref>, which can in practice reduce the execution time from O (n 2 ) to O (n log n) in many cases, performance remains a key research issue. <p> high local complexity, then partitioning may not reduce the subprob-lems to a solvable size. 3 This idea, of course, is not new, and has been the basis of Monte Carlo algorithms since the 1950s, including the classic computer graphics ray tracing algorithm [33] and and Monte Carlo radiosity's photon tracing <ref> [22, 20] </ref>. The parallelization of Monte Carlo algorithms has a long history as well, from Ulam's work in the 1950s to more recent research [28].
Reference: [21] <author> William Recker, David George, and Donald P. Greenberg. </author> <title> Acceleration techniques for progressive refinement radiosity. </title> <journal> Computer Graphics, </journal> <volume> 24(1) </volume> <pages> 59-66, </pages> <year> 1990. </year> <booktitle> ACM Workshop on Interactive Graphics Proceedings. </booktitle>
Reference-contexts: Next, performance results from that implementation are presented. Finally, we make some concluding remarks and briefly discuss some ideas for future work. 2 Prior Work Prior research has been done on parallel progressive radiosity by several groups <ref> [9, 21, 4, 11, 8, 10, 31, 7, 5] </ref>, and Chalmers and Paddon have written a survey paper [19] which analyzes both parallel full-matrix (gathering) radiosity and parallel progressive (shooting) radiosity methods.
Reference: [22] <author> Peter Shirley. </author> <title> A ray tracing method for illumination calculation in diffuse-specular scenes. </title> <booktitle> In Proceedings of Graphics Interface '90, </booktitle> <pages> pages 205-212, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Its ability to accurately compute interreflections in a view-independent manner makes it an excellent technique to use in many applications, particularly architectural walkthroughs. Even though several performance improvements to the original algorithm have been made, including hierarchical radiosity [14, 6, 27] and Monte Carlo radiosity <ref> [18, 1, 22, 20] </ref>, which can in practice reduce the execution time from O (n 2 ) to O (n log n) in many cases, performance remains a key research issue. <p> high local complexity, then partitioning may not reduce the subprob-lems to a solvable size. 3 This idea, of course, is not new, and has been the basis of Monte Carlo algorithms since the 1950s, including the classic computer graphics ray tracing algorithm [33] and and Monte Carlo radiosity's photon tracing <ref> [22, 20] </ref>. The parallelization of Monte Carlo algorithms has a long history as well, from Ulam's work in the 1950s to more recent research [28].
Reference: [23] <author> Peter Shirley, Bretton Wade, David Zareski, Philip Hubbard, Bruce Walter, and Donald P. Greenberg. </author> <title> Global illumination via density estimation. </title> <booktitle> In Proceedings of the Sixth Eurographics Workshop on Rendering, </booktitle> <pages> pages 187-199, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: This new global illumination method, called "Density Estimation," is named after the statistical technique we used to compute surface irradiance [24], and is described in detail in our companion paper <ref> [23] </ref>. This current paper briefly sum-marizes our study of global illumination and development of the DE method, and then focuses on the aspects of that method that are key to the parallel implementation. Next, performance results from that implementation are presented. <p> The algorithm is outlined in Figure 1. Further details of this algorithm can be found in our companion paper <ref> [23] </ref>. The adjustable variable in this algorithm is the number of particles that are traced. More particles will result in better resolution of illumination detail. <p> to shading discontinuities or Z-buffer effects at some of the seams. 9 A pilot study which used various number of particles (from 1 million to 40 million) found comparable speedup results, with execution time increasing quite linearly with the number of particles. 10 See section 4.2 of our companion paper <ref> [23] </ref> for a description of these density-estimation constants. for the furniture warehouse. Execution time ranged from a maximum of 9h59m to a minimum of 2h03m. did not noticeably affect the parallel performance. <p> Additional results and further analysis of this parallel implementation are also available [34]. 7 Conclusion and Future Work We have presented a parallel version of the recently introduced Density-Estimation global illumination algorithm <ref> [23] </ref> that has a straightforward implementation and provides reasonably good parallel performance, at least on a small scale.
Reference: [24] <author> B. W. Silverman. </author> <title> Density Estimation for Statistics and Data Analysis. </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: This new global illumination method, called "Density Estimation," is named after the statistical technique we used to compute surface irradiance <ref> [24] </ref>, and is described in detail in our companion paper [23]. This current paper briefly sum-marizes our study of global illumination and development of the DE method, and then focuses on the aspects of that method that are key to the parallel implementation. <p> In fact it is probably several orders of magnitude beyond the capabilities of today's computing resources. Fortunately, however, the illumination of each surface can be approximated, or "estimated," from a reasonably small set of hit points using a statistical technique known as "density estimation" <ref> [24] </ref>. The density estimation of the illumination of each surface can be computed independently, and therefore parallelizes quite well. <p> When all particles traces are completed, each surface has a distribution of particle hits that are denser in bright regions than in dimly-lit regions. A density-estimation <ref> [24] </ref> technique is then used to construct a smooth illumination function with a shape that is consistent with the hit point densities. This function is then converted into a piecewise linear mesh for more efficient display. The algorithm is composed of three basic phases: 1.
Reference: [25] <author> Jaswinder P. Singh, Annop Gupta, and Marc Levoy. </author> <title> Parallel visualization algorithms: Performance and architectural implications. </title> <journal> IEEE Computer, </journal> <volume> 27(7) </volume> <pages> 45-55, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: Little prior work has been published to date on parallel hierarchical radiosity. Publications from the Computer Systems Laboratory at Stanford University <ref> [25, 26] </ref> state that most ideas which succeed for parallelizing the gravitational N-body methods do not succeed nearly as well for hierarchical radiosity. <p> Their attempt to implement this algorithm on a distributed-memory message passing parallel system became "an exercise in frustration" and was abandoned as not being worthwhile <ref> [25] </ref>. Another attempt to parallelize hierarchical radiosity on a distributed-memory system is described by Carter in his PhD thesis [6].
Reference: [26] <author> Jaswinder P. Singh, C. Holt, T. Totsuka, A. Gupta, and J. L. Hennessy. </author> <title> Load balancing and data locality in hierarchical N-body methods. </title> <institution> CSL-TR-92-505., Computer Systems Laboratory, Stanford University, </institution> <year> 1992. </year>
Reference-contexts: Little prior work has been published to date on parallel hierarchical radiosity. Publications from the Computer Systems Laboratory at Stanford University <ref> [25, 26] </ref> state that most ideas which succeed for parallelizing the gravitational N-body methods do not succeed nearly as well for hierarchical radiosity.
Reference: [27] <author> Brian E. Smits, James R. Arvo, and Donald P. Greenberg. </author> <title> A clustering algorithm for radiosity in complex environments. </title> <journal> Computer Graphics, </journal> <volume> 28(3) </volume> <pages> 435-442, </pages> <month> July </month> <year> 1994. </year> <booktitle> ACM Siggraph '94 Conference Proceedings. </booktitle>
Reference-contexts: Its ability to accurately compute interreflections in a view-independent manner makes it an excellent technique to use in many applications, particularly architectural walkthroughs. Even though several performance improvements to the original algorithm have been made, including hierarchical radiosity <ref> [14, 6, 27] </ref> and Monte Carlo radiosity [18, 1, 22, 20], which can in practice reduce the execution time from O (n 2 ) to O (n log n) in many cases, performance remains a key research issue. <p> The most prominent sub-quadratic radiosity algorithm is hierarchical radiosity [14], which treats subdivided surface patches as a hierarchy rather than a set of independent patches for the purpose of energy transport. Subsequent "clustering" enhancements have been devised <ref> [6, 27] </ref> which can hierarchically group separate surfaces as well. <p> and to search for a new algorithm with richer inherent parallelism. 3 Re-examination of Radiosity and Global Illumination After studying existing radiosity algorithms, we came to believe that "the" main limit to parallelism was their view of energy transport, as exemplified by the global pass of the two-pass hierarchical-radiosity algorithms <ref> [17, 27] </ref>. By viewing energy transport from the macroscopic level, the process potentially involves pairwise interactions between all surfaces in the environment. <p> By viewing energy transport from the macroscopic level, the process potentially involves pairwise interactions between all surfaces in the environment. Although hierarchical techniques with clustering <ref> [6, 27] </ref> can usually reduce the number of interactions from O (n 2 ) to O (n log n) by clustering collections of surfaces of limited visibility to another surface, and by eliminating interactions between mutually-occluded pairs of surfaces, the determination of visibility is usually not a local problem 2 . <p> The parallel performance results for the Mackintosh room are shown in Figures 5 and 6. Plate 3 is a large furniture warehouse, which contains approximately 150,000 surfaces. This environment is three to four times larger than the largest scenes used in prior ra-diosity research <ref> [29, 27, 5] </ref>, and is more typical of the size that view-independent global illumination algorithms will be facing in the near future.
Reference: [28] <author> J. C. Solem. </author> <title> A multiprocessor concept specialized to Monte Carlo. </title> <booktitle> Springer-Verlag Lecture Notes in Physics, </booktitle> <volume> 240, </volume> <year> 1985. </year>
Reference-contexts: The parallelization of Monte Carlo algorithms has a long history as well, from Ulam's work in the 1950s to more recent research <ref> [28] </ref>. Therefore, our new algorithm for energy transport more closely resembles ray tracing than the classical radiosity algorithms, which is encouraging since ray tracing has been parallelized successfully [13, 2, 16].
Reference: [29] <author> Seth Teller, Celeste Fowler, Thomas Funkhouser, and Pat Han-rahan. </author> <title> Partitioning and ordering large radiosity calculations. </title> <journal> Computer Graphics, </journal> <volume> 28(3) </volume> <pages> 443-450, </pages> <month> July </month> <year> 1994. </year> <booktitle> ACM Siggraph '94 Conference Proceedings. </booktitle>
Reference-contexts: intertask communication is needed at all. 2 In cases where the environment has a very high "global complexity" (large number of surfaces), but a limited "local complexity" (only small subsets of surfaces are mutually visible), partitioning can be used to decompose the environment into subsets which can be solved separately <ref> [29] </ref>. <p> The parallel performance results for the Mackintosh room are shown in Figures 5 and 6. Plate 3 is a large furniture warehouse, which contains approximately 150,000 surfaces. This environment is three to four times larger than the largest scenes used in prior ra-diosity research <ref> [29, 27, 5] </ref>, and is more typical of the size that view-independent global illumination algorithms will be facing in the near future.
Reference: [30] <author> Seth Teller and Pat Hanrahan. </author> <title> Global visibility algorithms for illumination computations. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series, </booktitle> <year> 1993, </year> <pages> pages 239-246, </pages> <year> 1993. </year>
Reference-contexts: This was because the potentially O (n 2 ) interactions between patches during the local pass was significantly reduced using visibility-determination preprocessing techniques <ref> [30] </ref>. We found no clear way to parallelize the global pass, however. Since the global pass takes about one quarter of the total serial execution time in typical usage, the overall parallel speedup of this two-pass algorithm was limited to a factor of four.
Reference: [31] <author> Amitabh Varshney and Jan F. Prins. </author> <title> An environment projection approach to radiosity for mesh-connected computers. </title> <booktitle> In Proceedings of the Third Eurographics Workshop on Rendering, </booktitle> <pages> pages 271-281, </pages> <year> 1992. </year>
Reference-contexts: Next, performance results from that implementation are presented. Finally, we make some concluding remarks and briefly discuss some ideas for future work. 2 Prior Work Prior research has been done on parallel progressive radiosity by several groups <ref> [9, 21, 4, 11, 8, 10, 31, 7, 5] </ref>, and Chalmers and Paddon have written a survey paper [19] which analyzes both parallel full-matrix (gathering) radiosity and parallel progressive (shooting) radiosity methods.
Reference: [32] <author> John R. Wallace, Kells A. Elmquist, and Eric A. Haines. </author> <title> A ray tracing algorithm for progressive radiosity. </title> <journal> Computer Graphics, </journal> <volume> 23(3) </volume> <pages> 335-344, </pages> <month> July </month> <year> 1989. </year> <booktitle> ACM Siggraph '89 Conference Proceedings. </booktitle>
Reference-contexts: Unfortunately, much of this prior work deals primarily with older varieties of the serial radiosity algorithm, which can lead to some inaccuracies in the resulting solutions, such as the well-known artifacts of the hemi-cube method [3]. An even larger concern is that progressive refinement radiosity <ref> [32] </ref> is an O (n 2 ) algorithm when run to final convergence 1 .
Reference: [33] <author> Turner Whitted. </author> <title> An improved illumination model for shaded display. </title> <journal> Communications of the ACM, </journal> <volume> 23(6) </volume> <pages> 343-349, </pages> <month> June </month> <year> 1980. </year>
Reference-contexts: But if any subset has a high local complexity, then partitioning may not reduce the subprob-lems to a solvable size. 3 This idea, of course, is not new, and has been the basis of Monte Carlo algorithms since the 1950s, including the classic computer graphics ray tracing algorithm <ref> [33] </ref> and and Monte Carlo radiosity's photon tracing [22, 20]. The parallelization of Monte Carlo algorithms has a long history as well, from Ulam's work in the 1950s to more recent research [28].
Reference: [34] <author> David M. Zareski. </author> <title> Parallel decomposition of view-independent global illumination algorithms. </title> <type> Master's thesis, </type> <institution> Program of Computer Graphics, Cornell University, </institution> <note> expected 1995. </note>
Reference-contexts: The "local pass," which refines the initial "global pass" solution, parallelized quite well on a small scale, with a parallel efficiency of 75% or higher for up to eight processors <ref> [34] </ref>. This was because the potentially O (n 2 ) interactions between patches during the local pass was significantly reduced using visibility-determination preprocessing techniques [30]. We found no clear way to parallelize the global pass, however. <p> Execution time ranged from a maximum of 9h59m to a minimum of 2h03m. did not noticeably affect the parallel performance. Additional results and further analysis of this parallel implementation are also available <ref> [34] </ref>. 7 Conclusion and Future Work We have presented a parallel version of the recently introduced Density-Estimation global illumination algorithm [23] that has a straightforward implementation and provides reasonably good parallel performance, at least on a small scale.
References-found: 34

