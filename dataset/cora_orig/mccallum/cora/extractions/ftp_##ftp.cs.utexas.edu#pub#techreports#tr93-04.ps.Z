URL: ftp://ftp.cs.utexas.edu/pub/techreports/tr93-04.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/vbb/eosdis-bm.html
Root-URL: http://www.cs.utexas.edu
Title: SYSTEM-WIDE MULTIRESOLUTION  
Author: Robert L. Read, Donald S. Fussell and Avi Silberschatz 
Date: February 1993  
Address: Austin, Texas 78712-1188  austin, texas 78712  
Affiliation: Department of Computer Sciences University of Texas at Austin  DEPARTMENT OF COMPUTER SCIENCES THE UNIVERSITY OF TEXAS AT AUSTIN  
Pubnum: TR-93-04  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Gregory K. Wallace. </author> <title> The JPEG still picture compression standard. </title> <journal> Communications of the ACM, </journal> <volume> 34(4) </volume> <pages> 31-44, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: A number of existing systems address this problem by allowing quality to be traded for performance. For instance, in response to the volume of data generated by audio, still video, and motion video, the JPEG, MPEG, and pfi64 <ref> [1, 2, 3] </ref> lossy compression protocols all offer some inherent scalability of the quality, or resolution, of the data. The most important benefit of lossy compression [4] is that the I/O and transmission costs are decreased.
Reference: [2] <author> Didier Le Gall. </author> <title> MPEG: A video compression standard for multimedia applications. </title> <journal> Communications of the ACM, </journal> <volume> 34(4) </volume> <pages> 47-58, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: A number of existing systems address this problem by allowing quality to be traded for performance. For instance, in response to the volume of data generated by audio, still video, and motion video, the JPEG, MPEG, and pfi64 <ref> [1, 2, 3] </ref> lossy compression protocols all offer some inherent scalability of the quality, or resolution, of the data. The most important benefit of lossy compression [4] is that the I/O and transmission costs are decreased. <p> Thus, the payoff of saving storage access costs by retrieving lower-resolution data is of ever-increasing value. The growing use of multimedia brings us up against bandwidth limitations. MPEG data streams at 1.5 Megabits/s <ref> [2] </ref> are expensive relative to current 10 Megabit/s Ethernet and Token Ring LANs. HDTV will contain 8 to 16 times more data than MPEG [13] and will be expensive on fiber networks even at 1,000 Megabit/s.
Reference: [3] <author> Ming Liou. </author> <title> Overview of the pfi64 kbit/s video coding standard. </title> <journal> Communications of the ACM, </journal> <volume> 34(4) </volume> <pages> 60-63, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: A number of existing systems address this problem by allowing quality to be traded for performance. For instance, in response to the volume of data generated by audio, still video, and motion video, the JPEG, MPEG, and pfi64 <ref> [1, 2, 3] </ref> lossy compression protocols all offer some inherent scalability of the quality, or resolution, of the data. The most important benefit of lossy compression [4] is that the I/O and transmission costs are decreased. <p> The notion of multiresolution has previously been treated more formally [12]. We provide informal examples of two distinct multiresolution data types here. We seek to apply multiresolution concepts to all kinds of data. Example 1: pfi64 <ref> [3] </ref> is an inherently scalable motion video protocol used for teleconferencing over limited bandwidth lines. It could serve as the basis for a multiresolution data type of "motion-video" consisting of motion pictures at different qualities.
Reference: [4] <author> M. Nelson. </author> <title> The Data Compression Book. </title> <publisher> M & T Publishing Inc., </publisher> <address> 501 Galveston Drive, Redwood City, CA 94063, </address> <year> 1991. </year>
Reference-contexts: For instance, in response to the volume of data generated by audio, still video, and motion video, the JPEG, MPEG, and pfi64 [1, 2, 3] lossy compression protocols all offer some inherent scalability of the quality, or resolution, of the data. The most important benefit of lossy compression <ref> [4] </ref> is that the I/O and transmission costs are decreased. For example, Fluent Systems Inc. [5] sells software and hardware that dynamically adjust the resolution|measured in terms of bits/second|of audio/video streams on a LAN in response to changes in the available bandwidth.
Reference: [5] <institution> Fluent Systems, Inc. </institution> <address> 594 Worchester Rd., Natick, Massachussetts, </address> <pages> 01760-1827. </pages>
Reference-contexts: The most important benefit of lossy compression [4] is that the I/O and transmission costs are decreased. For example, Fluent Systems Inc. <ref> [5] </ref> sells software and hardware that dynamically adjust the resolution|measured in terms of bits/second|of audio/video streams on a LAN in response to changes in the available bandwidth. These applications demonstrate the utility and convenience of the resolution/performance tradeoff for digital representations of continuous functions, such as images and sounds.
Reference: [6] <author> Hanan Samet. </author> <title> The Design and Analysis of Spatial Data Structures. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: These applications demonstrate the utility and convenience of the resolution/performance tradeoff for digital representations of continuous functions, such as images and sounds. Additionally, scalable resolution of geometric data is used in spatial databases <ref> [6] </ref>, geographic information systems [7], and flight simulators. Even more generally, the related technique of imprecise computation has been suggested as an approach to meeting real-time constraints on database queries over any data type [8, 9, 10, 11].
Reference: [7] <author> W. E. Huxhold. </author> <title> An Introduction to Urban Geographic Information Systems. </title> <publisher> Oxford University Press, </publisher> <address> 200 Madison Avenue, New York, NY 10016, </address> <year> 1991. </year>
Reference-contexts: These applications demonstrate the utility and convenience of the resolution/performance tradeoff for digital representations of continuous functions, such as images and sounds. Additionally, scalable resolution of geometric data is used in spatial databases [6], geographic information systems <ref> [7] </ref>, and flight simulators. Even more generally, the related technique of imprecise computation has been suggested as an approach to meeting real-time constraints on database queries over any data type [8, 9, 10, 11].
Reference: [8] <author> S. V. Vrbsky and J. W. S. Liu. </author> <title> An object-oriented query processor that returns monotonically improving answers. </title> <booktitle> In Proceedings of the 7th IEEE Conf. on Data Engineering, </booktitle> <address> Kobe, Japan, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Additionally, scalable resolution of geometric data is used in spatial databases [6], geographic information systems [7], and flight simulators. Even more generally, the related technique of imprecise computation has been suggested as an approach to meeting real-time constraints on database queries over any data type <ref> [8, 9, 10, 11] </ref>. Systematic support for scalable quality naturally complements imprecise computation by allowing larger tradeoffs of quality for time. We call systems that support this tradeoff multiresolution systems [12].
Reference: [9] <author> K. Liu and R. Sunderraman. </author> <title> On representing indefinite and maybe information in relational databases. </title> <booktitle> In Proceedings: The Fourth International Conference on Data Engineering, </booktitle> <pages> pages 250-257, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: Additionally, scalable resolution of geometric data is used in spatial databases [6], geographic information systems [7], and flight simulators. Even more generally, the related technique of imprecise computation has been suggested as an approach to meeting real-time constraints on database queries over any data type <ref> [8, 9, 10, 11] </ref>. Systematic support for scalable quality naturally complements imprecise computation by allowing larger tradeoffs of quality for time. We call systems that support this tradeoff multiresolution systems [12].
Reference: [10] <author> K. J. Lin, S. Natarajan, and J. W. S. Liu. </author> <title> Imprecise results: utilizing partial computations in real-time systems. </title> <booktitle> In Proceedings of the IEEE 8th Real-Time Systems Symposium, </booktitle> <address> San Jose, California, </address> <month> December </month> <year> 1987. </year>
Reference-contexts: Additionally, scalable resolution of geometric data is used in spatial databases [6], geographic information systems [7], and flight simulators. Even more generally, the related technique of imprecise computation has been suggested as an approach to meeting real-time constraints on database queries over any data type <ref> [8, 9, 10, 11] </ref>. Systematic support for scalable quality naturally complements imprecise computation by allowing larger tradeoffs of quality for time. We call systems that support this tradeoff multiresolution systems [12].
Reference: [11] <author> K. B. Kenney and K. J. Lin. </author> <title> Structuring large real-time systems with performance poly-morphism. </title> <booktitle> In Proceedings of the IEEE 11th Real-Time Systems Symposium, </booktitle> <pages> pages 238-246, </pages> <address> Orlando, Florida, </address> <month> December </month> <year> 1990. </year>
Reference-contexts: Additionally, scalable resolution of geometric data is used in spatial databases [6], geographic information systems [7], and flight simulators. Even more generally, the related technique of imprecise computation has been suggested as an approach to meeting real-time constraints on database queries over any data type <ref> [8, 9, 10, 11] </ref>. Systematic support for scalable quality naturally complements imprecise computation by allowing larger tradeoffs of quality for time. We call systems that support this tradeoff multiresolution systems [12].
Reference: [12] <author> Robert L. Read, Donald S. Fussell, and Avi Silberschatz. </author> <title> A multi-resolution relational data model. </title> <booktitle> In 18th International Conference on Very Large Data Bases, </booktitle> <pages> pages 139-150, </pages> <address> Vancouver, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Systematic support for scalable quality naturally complements imprecise computation by allowing larger tradeoffs of quality for time. We call systems that support this tradeoff multiresolution systems <ref> [12] </ref>. This paper argues that ubiquitous, systematic support for scalable multiresolution is essential to next-generation applications that access very large quantities of data. These next-generation applications are the focus of great excitement. <p> The meaning of data, and hence the notion of resolution, is always application dependent. For example, the form of multiresolution supported by JPEG has no meaning for non-raster data. The notion of multiresolution has previously been treated more formally <ref> [12] </ref>. We provide informal examples of two distinct multiresolution data types here. We seek to apply multiresolution concepts to all kinds of data. Example 1: pfi64 [3] is an inherently scalable motion video protocol used for teleconferencing over limited bandwidth lines. <p> Under certain conditions, a histogram may completely determine the membership of a set, which is the highest resolution possible. A generalization of histograms called the sandbag has been suggested as a general purpose approach to multiresolution sets <ref> [12] </ref>. 2 3 These two types demonstrate a particular property of approximations that is generally true, though not universally obtained in practice. If X is a low resolution version of Y , then X requires less space to be represented by a computer than Y . <p> We have proposed a multiresolution data model <ref> [12] </ref> that is a framework for further research. <p> Although a database of the over five billion people may be constructed, there is little point in locating them all precisely for some applications. At least one approach to this kind of resolution has been suggested <ref> [12] </ref>. The transmission of these three different kinds of data over limited bandwidth lines to and from computers of greatly varying capacities demands multiresolution. The applications of the Geoscope boggle the mind. It will be the ultimate Atlas.
Reference: [13] <author> Karen A. Frenkel. </author> <title> HDTV and the computer industry. </title> <journal> Communications of the ACM, </journal> <volume> 32(11) </volume> <pages> 1300-1312, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: We call systems that support this tradeoff multiresolution systems [12]. This paper argues that ubiquitous, systematic support for scalable multiresolution is essential to next-generation applications that access very large quantities of data. These next-generation applications are the focus of great excitement. They include HDTV <ref> [13] </ref>, multimedia systems, geographic, seismology, astronomy, environmental and other scientific databases [14, 15, 16], spatial databases and geographic information systems, virtual reality systems [17], and terabyte-sized databases of traditional data [18]. fl This material is based in part upon work supported by the Texas Advanced Technology Program under Grant No. <p> The growing use of multimedia brings us up against bandwidth limitations. MPEG data streams at 1.5 Megabits/s [2] are expensive relative to current 10 Megabit/s Ethernet and Token Ring LANs. HDTV will contain 8 to 16 times more data than MPEG <ref> [13] </ref> and will be expensive on fiber networks even at 1,000 Megabit/s. The popularity of audio/video data and the merging of computer and entertainment systems demand multiresolution and resolution management to extract the most utility from any particular network of hardware.
Reference: [14] <author> Jeff Dozier. </author> <title> Access to data in NASA's Earth Observing System. </title> <booktitle> In SIGMOD Conference Proceedings, </booktitle> <pages> page 1, </pages> <year> 1992. </year> <title> Keynote Address. </title>
Reference-contexts: This paper argues that ubiquitous, systematic support for scalable multiresolution is essential to next-generation applications that access very large quantities of data. These next-generation applications are the focus of great excitement. They include HDTV [13], multimedia systems, geographic, seismology, astronomy, environmental and other scientific databases <ref> [14, 15, 16] </ref>, spatial databases and geographic information systems, virtual reality systems [17], and terabyte-sized databases of traditional data [18]. fl This material is based in part upon work supported by the Texas Advanced Technology Program under Grant No. ATP-024, the National Science Foundation under Grant Nos. <p> Finally, the construction of ever-larger banks of data, exemplified by the Earth Observing System <ref> [14] </ref>, necessitates multiresolution. So much data is being collected that it cannot be examined in detail. While all of the data is precious, only a fraction of it can be computed against or examined by a human at any particular moment.
Reference: [15] <author> A. Shoshani and H. K. T. Wong. </author> <title> Statistical and scientific datbase issues. </title> <journal> IEEE Transactions on Software Engineering, </journal> <pages> pages 1040-1046, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: This paper argues that ubiquitous, systematic support for scalable multiresolution is essential to next-generation applications that access very large quantities of data. These next-generation applications are the focus of great excitement. They include HDTV [13], multimedia systems, geographic, seismology, astronomy, environmental and other scientific databases <ref> [14, 15, 16] </ref>, spatial databases and geographic information systems, virtual reality systems [17], and terabyte-sized databases of traditional data [18]. fl This material is based in part upon work supported by the Texas Advanced Technology Program under Grant No. ATP-024, the National Science Foundation under Grant Nos.
Reference: [16] <author> M. A. Bassiouni. </author> <title> Data compression in scientific and statistical databases. </title> <journal> IEEE Transactions on Software Engineering, </journal> <pages> pages 1047-1058, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: This paper argues that ubiquitous, systematic support for scalable multiresolution is essential to next-generation applications that access very large quantities of data. These next-generation applications are the focus of great excitement. They include HDTV [13], multimedia systems, geographic, seismology, astronomy, environmental and other scientific databases <ref> [14, 15, 16] </ref>, spatial databases and geographic information systems, virtual reality systems [17], and terabyte-sized databases of traditional data [18]. fl This material is based in part upon work supported by the Texas Advanced Technology Program under Grant No. ATP-024, the National Science Foundation under Grant Nos.
Reference: [17] <author> Ken Pimentel and Kevin Teixeira. </author> <title> Virtual Reality: Through the new looking glass. </title> <publisher> Windcrest Books, </publisher> <year> 1993. </year>
Reference-contexts: These next-generation applications are the focus of great excitement. They include HDTV [13], multimedia systems, geographic, seismology, astronomy, environmental and other scientific databases [14, 15, 16], spatial databases and geographic information systems, virtual reality systems <ref> [17] </ref>, and terabyte-sized databases of traditional data [18]. fl This material is based in part upon work supported by the Texas Advanced Technology Program under Grant No. ATP-024, the National Science Foundation under Grant Nos. IRI-9003341 and IRI-9106450, and grants from the IBM and Hewlett-Packard corporations.
Reference: [18] <author> A. Silberschatz, M. Stonebraker, and J. Ullman. </author> <title> Database systems: Achievements and opportunities. </title> <journal> Communications of the ACM, </journal> <volume> 34(10) </volume> <pages> 110-120, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: These next-generation applications are the focus of great excitement. They include HDTV [13], multimedia systems, geographic, seismology, astronomy, environmental and other scientific databases [14, 15, 16], spatial databases and geographic information systems, virtual reality systems [17], and terabyte-sized databases of traditional data <ref> [18] </ref>. fl This material is based in part upon work supported by the Texas Advanced Technology Program under Grant No. ATP-024, the National Science Foundation under Grant Nos. IRI-9003341 and IRI-9106450, and grants from the IBM and Hewlett-Packard corporations.
Reference: [19] <author> J. L. Hennesy and D. A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, CA, </address> <year> 1990. </year> <month> 8 </month>
Reference-contexts: The storage density of solid state memory chips, magnetic disks, and optical storage doubles every few years, leading to exponential growth in storage capacity over time <ref> [19] </ref>. However, only relatively small improvements per year in the access times and throughputs of these devices have been realized and are expected.
Reference: [20] <author> T. Imielinski and B. R. Badrinath. </author> <title> Querying in highly mobile distributed environments. </title> <booktitle> In 18th International Conference on Very Large Data Bases, </booktitle> <pages> pages 41-52, </pages> <address> Vancouver, Canada, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: Inherently scalable protocols like pfi64 address the problem of transmitting audio and video on low-bandwidth lines, such as cellular phone lines. The number of portable and mobile personal computers networked via such low-bandwidth mechanisms is expected to explode <ref> [20] </ref>. Computer resources at various nodes of these inter-connected networks will be of increasingly heterogeneous capability, as supercomputers communicate with palm-tops. Much of the traffic on such networks will be audio/video data.
Reference: [21] <author> Personal communication with Dr. </author> <title> Anita Cochron about the Halley Watch Archive CD image library. </title>
Reference-contexts: So much data is being collected that it cannot be examined in detail. While all of the data is precious, only a fraction of it can be computed against or examined by a human at any particular moment. Already, image databases use 2 low resolution "browse images" <ref> [21, 22] </ref> to allow rapid preliminary examination of the data. After seeing low resolution overviews of data, scientists may then examine a certain feature at maximum resolution.
Reference: [22] <author> A. Turtur, F. Prampolini, M. Fantini, R. Guarda, and M. A. Imperato. IDB: </author> <title> An image database system. </title> <journal> IBM Journal of Research and Development, </journal> 35(1/2):88-96, January/March 1991. 
Reference-contexts: So much data is being collected that it cannot be examined in detail. While all of the data is precious, only a fraction of it can be computed against or examined by a human at any particular moment. Already, image databases use 2 low resolution "browse images" <ref> [21, 22] </ref> to allow rapid preliminary examination of the data. After seeing low resolution overviews of data, scientists may then examine a certain feature at maximum resolution.
Reference: [23] <author> P. Buneman, A. Jung, and A. Ohori. </author> <title> Using powerdomains to generalize relational databases. </title> <booktitle> Theoretical Computer Science, </booktitle> <pages> pages 23-55, </pages> <year> 1991. </year>
Reference-contexts: We believe these trends will necessitate multiresolution across every component of a system and for all kinds of data. 3 Multiresolution Multiresolution is the concept of viewing data at different levels of information content. The fields of denotational semantics <ref> [23, 24] </ref> and information theory [25, 26] provide an intuitive and a formal definition of information content. We repeat the informal definition of this concept here to provide the reader with the necessary intuitions. Data describe the real world. Some data are more descriptive than other data.
Reference: [24] <author> J. E. Stoy. </author> <title> Denotational Semantics: The Scott-Strachey Approach to Programming Language Theory. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1977. </year>
Reference-contexts: We believe these trends will necessitate multiresolution across every component of a system and for all kinds of data. 3 Multiresolution Multiresolution is the concept of viewing data at different levels of information content. The fields of denotational semantics <ref> [23, 24] </ref> and information theory [25, 26] provide an intuitive and a formal definition of information content. We repeat the informal definition of this concept here to provide the reader with the necessary intuitions. Data describe the real world. Some data are more descriptive than other data.
Reference: [25] <author> H. L. Resnikoff. </author> <title> The Illusion of Reality. </title> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: We believe these trends will necessitate multiresolution across every component of a system and for all kinds of data. 3 Multiresolution Multiresolution is the concept of viewing data at different levels of information content. The fields of denotational semantics [23, 24] and information theory <ref> [25, 26] </ref> provide an intuitive and a formal definition of information content. We repeat the informal definition of this concept here to provide the reader with the necessary intuitions. Data describe the real world. Some data are more descriptive than other data.
Reference: [26] <author> R. W. </author> <title> Hamming. Coding and Information Theory. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, 07632, </address> <year> 1986. </year>
Reference-contexts: We believe these trends will necessitate multiresolution across every component of a system and for all kinds of data. 3 Multiresolution Multiresolution is the concept of viewing data at different levels of information content. The fields of denotational semantics [23, 24] and information theory <ref> [25, 26] </ref> provide an intuitive and a formal definition of information content. We repeat the informal definition of this concept here to provide the reader with the necessary intuitions. Data describe the real world. Some data are more descriptive than other data.
Reference: [27] <author> P. Venkat Rangan, Harrick M. Vin, and Srinivas Ramanathan. </author> <title> Designing an on-demand multimedia service. </title> <journal> IEEE Communications Magazine, </journal> <pages> pages 56-64, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: A poor quality movie would be "low resolution" and would approximate "higher-resolution" movies of the same film. This motion-video type, or one based on different protocols, could be used in an on-demand video-server <ref> [27] </ref> that plays any number of movies to viewers on a digital network. When the number of movies currently being viewed is very high, the server might provide relatively low resolution video, allowing its storage devices and network capability to meet the demand. <p> In order to take advantage of heterogeneity of hardware in networks, every software component in the system must support scalable resolution. In a situation where a service is being sold over a network <ref> [27, 28] </ref>, the utility of the data, and therefore the demand for the data, is based on resolution. The total utility provided to clients (and the income of the server!) is maximized by systems that can both provide and utilize data at different levels of resolution.
Reference: [28] <author> Joe Sutherland and Larry Litteral. </author> <title> Residential video services. </title> <journal> IEEE Communications Magazine, </journal> <pages> pages 36-41, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: In order to take advantage of heterogeneity of hardware in networks, every software component in the system must support scalable resolution. In a situation where a service is being sold over a network <ref> [27, 28] </ref>, the utility of the data, and therefore the demand for the data, is based on resolution. The total utility provided to clients (and the income of the server!) is maximized by systems that can both provide and utilize data at different levels of resolution.
Reference: [29] <author> C. A. Waldspurger, T. Hogg, B. A. Huberman, J. O. Kephart, and W. S. Storne. Spawn: </author> <title> A distributed computational economy. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 18(2), </volume> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: Multiresolution specifically raises interesting questions of market-based allocation of resources <ref> [29] </ref>, especially network bandwidth. The more resolution scalable each component of a software system is, the more control the client user or client application can have over the result resolution. This control is essential to the utility of a multiresolution system because different situations have different performance and resolution requirements.
Reference: [30] <author> Michael Benedikt, </author> <title> editor. Cyberspace: First Steps. </title> <publisher> Cambridge, MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Although we are working on these problems, research on a larger scale is needed. The field of graphics has used multiresolution concepts from its beginning. Additional systems-level research into the integration of this technology with database and network technology will be extremely fruitful. Further, we believe cyberspace <ref> [30] </ref> and virtual reality systems will require similar lossy compression technology for geometric rather than raster based graphic representation, and that this technology also must carefully consider the general ideas of multiresolution transmission and calculation [31, 32].
Reference: [31] <author> L. Bergman, H. Fuchs, E. Grant, and S. Spach. </author> <title> Image rendering by adaptive refinement. </title> <journal> Computer Graphics, </journal> <volume> 20(4) </volume> <pages> 29-38, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: Further, we believe cyberspace [30] and virtual reality systems will require similar lossy compression technology for geometric rather than raster based graphic representation, and that this technology also must carefully consider the general ideas of multiresolution transmission and calculation <ref> [31, 32] </ref>.
Reference: [32] <author> M. F. Cohen, S. E. Chen, J. R. Wallace, and D. P. Greenberg. </author> <title> A progressive refinement approach to fast radiosity image generation. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 75-84, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Further, we believe cyberspace [30] and virtual reality systems will require similar lossy compression technology for geometric rather than raster based graphic representation, and that this technology also must carefully consider the general ideas of multiresolution transmission and calculation <ref> [31, 32] </ref>.
Reference: [33] <author> R. L. Read, D. S. Fussell, and A. Silberschatz. </author> <title> The fact set approach to the sandbag imprecise set representation and its complexity. </title> <note> Submitted to PODS. </note>
Reference-contexts: Multiresolution systems will provide the greatest benefit when every data type supports notions of multiresolution. We are currently developing a notion of multiresolution set, called the sandbag <ref> [33] </ref>. The multiresolution set is a fraction of the data types that need to be considered.
Reference: [34] <author> R. Buckminster Fuller. </author> <title> Critical Path. </title> <address> St. </address> <publisher> Martin's Press, </publisher> <year> 1981. </year> <title> Chapter 5, Part II. </title> <type> 9 </type>
Reference-contexts: R. Buckminster Fuller (1895-1983), scientist, inventor, philosopher, futurist, cartographer, and poet, was very concerned with mapping the earth and understanding global trends. In 1953 he proposed the construction of a 60-meter diameter sphere to be suspended in space next to the United Nations building in New York <ref> [34] </ref>. This enormous 6 ball was to be a precise simulacrum of the planet Earth, on a such a scale that a tourist could observe on its surface the house in which he or she lived with the aid of powerful binoculars.
References-found: 34

