URL: http://www.cs.berkeley.edu/~sinclair/flow.ps
Refering-URL: http://www.cs.berkeley.edu/~sinclair/
Root-URL: 
Title: Improved bounds for mixing rates of Markov chains and multicommodity flow  
Author: Alistair Sinclair 
Note: Appeared in Combinatorics, Probability Computing 1 (1992), pp. 351-370.  
Address: The King's Buildings, Edinburgh EH9 3JZ, Scotland  
Affiliation: Department of Computer Science, University of Edinburgh  
Abstract: Part of this work was done while the author was visiting the International Computer Science Institute at Berkeley and the Center for Discrete Mathematics and Theoretical Computer Science at Rutgers University. A preliminary version of this paper appeared in the Proceedings of the 1st Latin American Symposium on Theoretical Informatics, S~ao Paulo, Brazil, April 1992 (Springer Lecture Notes in Computer Science Vol. 583). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Aldous, D. </author> <title> Some inequalities for reversible Markov chains. </title> <journal> Journal of the London Mathematical Society (2) 25 (1982), </journal> <pages> pp. 564-576. </pages>
Reference-contexts: Part (i) follows from [8, Proposition 3] and gives an upper bound on the time to reach equilibrium from a given initial state x in terms of max and (x). The converse, part (ii), which is a discrete-time version of <ref> [1, Proposition 8] </ref>, says that convergence cannot be rapid unless max is bounded away from 1. (Note that in the latter bound there is a maximisation over initial states: it is possible for a chain to converge fast from certain states even when max is close to 1.
Reference: [2] <author> Aldous, D. </author> <title> On the Markov chain simulation method for uniform combinatorial distributions and simulated annealing. </title> <booktitle> Probability in the Engineering and Informational Sciences 1 (1987), </booktitle> <pages> pp. 33-46. 19 </pages>
Reference-contexts: Thus measures the ability of the chain to escape from any small region of the state space, and hence to make rapid progress to equilibrium. The following result formalising this intuition is from [23, 24]; see also <ref> [2, 3, 4, 16, 19, 21] </ref> for related results.
Reference: [3] <author> Alon, N. </author> <title> Eigenvalues and expanders. </title> <booktitle> Combinatorica 6 (1986), </booktitle> <pages> pp. 83-96. </pages>
Reference-contexts: Thus measures the ability of the chain to escape from any small region of the state space, and hence to make rapid progress to equilibrium. The following result formalising this intuition is from [23, 24]; see also <ref> [2, 3, 4, 16, 19, 21] </ref> for related results.
Reference: [4] <author> Alon, N. and Milman, V.D. </author> <title> 1 , isoperimetric inequalities for graphs and superconcentrators. </title> <journal> Journal of Combinatorial Theory Series B 38 (1985), </journal> <pages> pp. 73-88. </pages>
Reference-contexts: Thus measures the ability of the chain to escape from any small region of the state space, and hence to make rapid progress to equilibrium. The following result formalising this intuition is from [23, 24]; see also <ref> [2, 3, 4, 16, 19, 21] </ref> for related results.
Reference: [5] <author> Broder, A.Z. </author> <title> How hard is it to marry at random? (On the approximation of the permanent). </title> <booktitle> Proceedings of the 18th ACM Symposium on Theory of Computing, </booktitle> <year> 1986, </year> <pages> pp. 50-58. </pages> <booktitle> Erratum in Proceedings of the 20th ACM Symposium on Theory of Computing, </booktitle> <year> 1988, </year> <note> p. 551. </note>
Reference-contexts: (n ); and [11] gives a bound on the ratio of n 10 for random graphs of low density. (The ratio can in fact be exponentially large, but then the chain no longer converges in polynomial time.) (ii) Broder's chain for the dense permanent This chain, which was proposed in <ref> [5] </ref> and analysed in [11, 23], is a restricted version of Example (i); it again allows the number of perfect matchings in a graph to be estimated in polynomial time provided the ratio of the number of near-perfect matchings to the number of perfect matchings is polynomially bounded.
Reference: [6] <author> Dagum, P., Luby, M., Mihail, M. and Vazirani, </author> <title> U.V. Polytopes, permanents and graphs with large factors. </title> <booktitle> Proceedings of the 29th IEEE Symposium on Foundations of Computer Science (1988), </booktitle> <pages> pp. 412-421. </pages>
Reference-contexts: It seems difficult to get this close using canonical paths. A similar bound was obtained by a slightly different method in [8]. The above idea of using all geodesic paths first appeared in the analysis of a Markov chain on matchings by Dagum et al <ref> [6] </ref>. By analogy with the conductance , we may define the resistance y of a revers ible Markov chain described by a graph G by (G) = inf (f); where the infimum is taken over all valid flows in G.
Reference: [7] <author> Diaconis, P. </author> <title> Group representations in probability and statistics. </title> <booktitle> Lecture Notes Monograph Series Vol. 11, </booktitle> <institution> Institute of Mathematical Statistics, Hay-ward, California, </institution> <year> 1988. </year>
Reference-contexts: This has led to the development recently of new analytic tools, based on coupling, stopping times and group representation theory, which have been successfully applied to chains with a regular structure such as random walks on certain special graphs or groups. The book by Diaconis <ref> [7] </ref> gives an excellent survey. Markov chains arising in the combinatorial applications mentioned above are typically much more complex, however. The first analyses of such chains were 1 made possible using a quantity called the conductance [23, 24].
Reference: [8] <author> Diaconis, P., and Stroock, D. </author> <title> Geometric bounds for eigenvalues of Markov chains. </title> <booktitle> Annals of Applied Probability 1 (1991), </booktitle> <pages> pp. 36-61. </pages>
Reference-contexts: In a recent paper <ref> [8] </ref>, Diaconis and Stroock observed that path arguments similar to that described above can lead directly to bounds on the mixing rate, independently of the conductance . In this paper, we present a new bound which is a modification of that of Diaconis and Stroock. <p> Part (i) follows from <ref> [8, Proposition 3] </ref> and gives an upper bound on the time to reach equilibrium from a given initial state x in terms of max and (x). <p> edge e with 1 X (x)(y) Q (S; S) (S) = 2 Theorems 2 and 3 immediately yield the following bound on 1 : Corollary 4 For any reversible Markov chain, and any choice of canonical paths, the second eigenvalue 1 satisfies 1 1 8 2 : In recent work <ref> [8] </ref>, Diaconis and Stroock observed that bounds on 1 can be obtained directly in terms of canonical paths, without appealing to the conductance bound of Theorem 2. <p> Theorem 5 For any reversible Markov chain, and any choice of canonical paths, the second eigenvalue 1 satisfies 1 1 Proof: Let L = I P , so that the eigenvalues of L are i = 1 i . Follow ing <ref> [8] </ref>, the variational characterisation of 1 is 1 = inf P 2 P 2 ; (5) where the infimum is taken over all non-constant functions : X ! R. (The constant functions are the only eigenfunctions of L with eigenvalue 0 = 0.) Now for any , and any choice of <p> Frequently, however, the maximum path length ` will be significantly less than the estimate obtained for ; in such cases, Corollary 6 will give a sharper bound than Corollary 4. The improved bounds presented in the next section are all based on this observation. Remark: Diaconis and Stroock <ref> [8] </ref> give a bound which is similar to that of Theorem 5 but which uses a different measure of path length. <p> To get their bound we replace jfl xy j in the definition (4) of by the quantity jfl xy j Q;e = e 0 2fl xy Q (e 0 ) with everything else defined as before. Let DS be the measure obtained in this way. Diaconis' and Stroock's bound <ref> [8, Proposition 1] </ref>, may be stated as 1 1 DS : (6) The examples in the next section indicate that , or `, may be a more useful quantity to work with in practice that DS . <p> Most of the examples discussed by Diaconis and Stroock <ref> [8] </ref> are in fact random walks on graphs, so our bound yields identical results for them. Note also that jfl xy j Q;e 1 for all fl xy and e, so certainly DS is bounded below by . <p> Hence the bounds of Theorem 5 and Corollary 6 can be worse than (6) by at most a factor `. Moreover, there are examples for which is provably significantly better than DS ; one such is the Ehrenfest urn model, discussed by Diaconis and Stroock <ref> [8] </ref>. However, the two quantities seem to be incomparable in general. The examples in the next section and in [8] indicate that frequently leads to sharper bounds on 1 than does itself. <p> Moreover, there are examples for which is provably significantly better than DS ; one such is the Ehrenfest urn model, discussed by Diaconis and Stroock <ref> [8] </ref>. However, the two quantities seem to be incomparable in general. The examples in the next section and in [8] indicate that frequently leads to sharper bounds on 1 than does itself. By way of contrast, here is a simple example where Corollary 4 provably does better than Theorem 5 and Corollary 6. <p> However, since the maximum path length is at most 2n, Corollary 6 yields the sharper bound 1 1 O (n 7 ). The mixing rate is therefore reduced by a factor O (n ). This is exactly the same improvement as that discussed in Section 4 of <ref> [8] </ref>: in this case the Diaconis-Stroock bound (6) is equivalent to Theorem 5 because there are no weights, i.e., Q (e) is uniform. (iii) The Ising model In this example drawn from statistical physics, the states of the Markov chain are all subgraphs of the graph (V; A) of interactions of <p> In the case n = 2k , the exact value is 1 = 1 2=k , so the estimate is correct within a factor of about k=2. It seems difficult to get this close using canonical paths. A similar bound was obtained by a slightly different method in <ref> [8] </ref>. The above idea of using all geodesic paths first appeared in the analysis of a Markov chain on matchings by Dagum et al [6].
Reference: [9] <author> Dyer, M., Frieze, A. and Kannan, R. </author> <title> A random polynomial time algorithm for approximating the volume of convex bodies. </title> <booktitle> Proceedings of the 21st ACM Symposium on Theory of Computing (1989), </booktitle> <pages> pp. 375-381. </pages>
Reference-contexts: in positive results, lower bounds on are generally of greater interest and we focus on them for most of the rest of this paper. (We shall consider negative results in Section 4.) In some cases such a bound can be obtained directly, using elementary arguments [16, 24] or geometric ideas <ref> [9, 14] </ref>. However, in many important applications the only known handle on is via the canonical path approach sketched in the previous section.
Reference: [10] <author> Fill, J. </author> <type> Unpublished manuscript. </type>
Reference-contexts: Then the proof of Theorem 8 shows that 1 (t) t ; provided t is large enough that P t (x; y) &gt; 0 for all x; y 2 X . A similar result has been observed independently by Jim Fill <ref> [10] </ref>. 17 In fact, a direct comparison of and sheds some interesting light on these two quantities. It is convenient at this point to introduce a symmetrised version of , namely = min 0&lt;(S)&lt;1 (S)(S) Clearly 0 0 differ by at most a constant factor.
Reference: [11] <author> Jerrum, M. R. and Sinclair, A. J. </author> <title> Approximating the permanent. </title> <journal> SIAM Journal on Computing 18 (1989), </journal> <pages> pp. 1149-1178. </pages>
Reference-contexts: Conversely, a large value of means that the chain cannot get trapped by any small region of the space, and hence should be rapidly mixing. A useful piece of technology for obtaining lower bounds on in complex examples was developed in <ref> [11, 23] </ref>. The idea is to construct a canonical path fl xy in the graph G between each ordered pair of distinct states x and y . <p> Approximate counting of various other structures may be reduced to this problem [12, 20]. Finally, weighted sampling of matchings also enables a matching of nearly maximum cardinality to be found with high probability, an example of stochastic search by simulated annealing. Details of these applications may be found in <ref> [11, 23] </ref>. In order for the resulting algorithms to be efficient (in the sense of having polynomially bounded runtime), accurate sampling must be possible in time bounded by a polynomial in the size of H and c max = maxf1; max a2A c (a)g. <p> We now present a brief sketch of the canonical path argument used to obtain such a bound. In doing so, our aim will be to illustrate how the quantity arises naturally from a combinatorial encoding technique. For the details the reader is referred to <ref> [11, 23] </ref>. Let I and F be matchings in H , and consider the symmetric difference S = I F . The connected components of S are paths and cycles in H whose edges belong alternately to I and F . <p> But Q (e) = (M )P (M; M 0 ), so (10) gives us an upper bound on the crucial quantity Q (e) 1 P fl IF 3e (I)(F ), and hence on . Precisely, the bound derived in <ref> [11, 23] </ref> by this method is 4jAjc 2 rollary 4 therefore yields 1 1 1=128jAj c max : On the other hand, the maximum length of any canonical path is easily seen to be at most jV j = n, so Corollary 6 gives the much sharper bound 1 1 1=4njAjc <p> of H are unmatched.) This quantity is at least n=2, and can be quite large in interesting cases: for example, for dense graphs (with minimum vertex degree at least n=2), the ratio is about n 2 and jAj n 2 =2, leading to an improvement of O (n ); and <ref> [11] </ref> gives a bound on the ratio of n 10 for random graphs of low density. (The ratio can in fact be exponentially large, but then the chain no longer converges in polynomial time.) (ii) Broder's chain for the dense permanent This chain, which was proposed in [5] and analysed in <p> gives a bound on the ratio of n 10 for random graphs of low density. (The ratio can in fact be exponentially large, but then the chain no longer converges in polynomial time.) (ii) Broder's chain for the dense permanent This chain, which was proposed in [5] and analysed in <ref> [11, 23] </ref>, is a restricted version of Example (i); it again allows the number of perfect matchings in a graph to be estimated in polynomial time provided the ratio of the number of near-perfect matchings to the number of perfect matchings is polynomially bounded.
Reference: [12] <author> Jerrum, M. R. and Sinclair, A. J. </author> <title> Fast Uniform Generation of Regular Graphs. </title> <booktitle> Theoretical Computer Science 73 (1990), </booktitle> <pages> pp. 91-100. </pages>
Reference-contexts: In particular, for most graphs the number of perfect matchings can be estimated, a problem which corresponds to evaluating the permanent of a 0-1 matrix. Approximate counting of various other structures may be reduced to this problem <ref> [12, 20] </ref>. Finally, weighted sampling of matchings also enables a matching of nearly maximum cardinality to be found with high probability, an example of stochastic search by simulated annealing. Details of these applications may be found in [11, 23].
Reference: [13] <author> Jerrum, M. R. and Sinclair, A. J. </author> <title> Polynomial-time approximation algorithms for the Ising model. </title> <type> Technical Report CSR-1-90, </type> <institution> Dept. of Computer Science, University of Edinburgh. </institution> <note> To appear in SIAM Journal on Computing; Extended Abstract in Proceedings of the 17th International Colloquium on Automata, Languages and Programming (1990), Springer LNCS Vol. </note> <month> 443, </month> <pages> pp. 462-475. </pages>
Reference-contexts: By sampling from this distribution, various important quantities, such as the partition function of the system, can be effectively approximated; the details are in <ref> [13] </ref>. In [13] a choice of canonical paths is presented for which it can be shown, again using the encoding technique sketched in Example (i), that 2jAj 4 . This leads to the bound 1 1 8 2 , from Corollary 4. <p> By sampling from this distribution, various important quantities, such as the partition function of the system, can be effectively approximated; the details are in <ref> [13] </ref>. In [13] a choice of canonical paths is presented for which it can be shown, again using the encoding technique sketched in Example (i), that 2jAj 4 . This leads to the bound 1 1 8 2 , from Corollary 4. <p> The length of paths here is at most jAj, so Corollary 6 yields the sharper bound 1 1 4 2 improvement in the spectral gap is therefore a factor 16 4 . In the applications discussed in <ref> [13] </ref>, the parameter is taken down to n 1 , where n = jV j is the number of sites in the system.
Reference: [14] <author> Karzanov, A. and Khachiyan, L. </author> <title> On the conductance of order Markov chains. </title> <type> Technical Report DCS 268, </type> <institution> Rutgers University, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: in positive results, lower bounds on are generally of greater interest and we focus on them for most of the rest of this paper. (We shall consider negative results in Section 4.) In some cases such a bound can be obtained directly, using elementary arguments [16, 24] or geometric ideas <ref> [9, 14] </ref>. However, in many important applications the only known handle on is via the canonical path approach sketched in the previous section.
Reference: [15] <author> Keilson, J. </author> <title> Markov chain models | rarity and exponentiality. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: This is actually an approximate max-flow min-cut theorem for the multicommodity flow problem, and is a natural generalisation of a result obtained in a different context by Leighton and Rao [17]. 2 Bounds on the mixing rate We assume familiarity with the elementary theory of Markov chains: see, e.g., <ref> [15] </ref> for a more detailed treatment. Let X be a finite set, and P the transition matrix of a discrete-time Markov chain on state space X .
Reference: [16] <author> Lawler, </author> <title> G.F. and Sokal, A.D. Bounds on the L 2 spectrum for Markov chains and Markov processes: a generalization of Cheeger's inequality. </title> <journal> Transactions of the American Mathematical Society 309 (1988), </journal> <pages> pp. 557-580. </pages>
Reference-contexts: Thus measures the ability of the chain to escape from any small region of the state space, and hence to make rapid progress to equilibrium. The following result formalising this intuition is from [23, 24]; see also <ref> [2, 3, 4, 16, 19, 21] </ref> for related results. <p> we are usually more interested in positive results, lower bounds on are generally of greater interest and we focus on them for most of the rest of this paper. (We shall consider negative results in Section 4.) In some cases such a bound can be obtained directly, using elementary arguments <ref> [16, 24] </ref> or geometric ideas [9, 14]. However, in many important applications the only known handle on is via the canonical path approach sketched in the previous section.
Reference: [17] <author> Leighton, T. and Rao, S. </author> <title> An approximate max-flow min-cut theorem for uniform multicommodity flow problems with applications to approximation 20 algorithms. </title> <booktitle> Proceedings of the 29th IEEE Symposium on Foundations of Computer Science (1988), </booktitle> <pages> pp. 422-431. </pages>
Reference-contexts: This is actually an approximate max-flow min-cut theorem for the multicommodity flow problem, and is a natural generalisation of a result obtained in a different context by Leighton and Rao <ref> [17] </ref>. 2 Bounds on the mixing rate We assume familiarity with the elementary theory of Markov chains: see, e.g., [15] for a more detailed treatment. Let X be a finite set, and P the transition matrix of a discrete-time Markov chain on state space X . <p> Asymptotically, therefore, exceeds 01 by a factor 5 4 . Thus we are led to ask by how much can exceed 0 1 in general. This question was addressed, again in a different context, by Leighton and Rao <ref> [17] </ref>. <p> In our setting, this leads to the following result for arbitrary stationary distributions; since the proof is essentially the same as that of <ref> [17, Theorem 1] </ref> we omit it here. Theorem 9 For any reversible Markov chain with N states, = O log N ! Putting together Theorem 9 and Theorem 2, we obtain a lower bound on the second eigenvalue in terms of .
Reference: [18] <author> Matula, D. W. and Shahrokhi, F. </author> <title> Sparsest cuts and bottlenecks in graphs. </title> <booktitle> Discrete Applied Mathematics 27 (1990), </booktitle> <pages> pp. 113-123. </pages>
Reference-contexts: Hence we have = min Q (e) x2S P (y) e f (e) 1 where (S; S) is the partition of X induced by the cut edge e. The above question was extensively studied in more generality, and in a totally unrelated context, by Matula and Shahrokhi <ref> [18, 22] </ref>. The determination of is a case of what Matula and Shahrokhi call the Maximum Concurrent Flow Problem, while computing 0 is a case of the Sparsest Cut Problem. Matula and Shahrokhi show that these two problems are "near-duals" of one other, and make this statement precise.
Reference: [19] <author> Mihail, M. </author> <title> Conductance and convergence of Markov chains: a combinatorial treatment of expanders. </title> <booktitle> Proceedings of the 30th IEEE Symposium on Foundations of Computer Science (1989), </booktitle> <pages> pp. 526-531. </pages>
Reference-contexts: Thus measures the ability of the chain to escape from any small region of the state space, and hence to make rapid progress to equilibrium. The following result formalising this intuition is from [23, 24]; see also <ref> [2, 3, 4, 16, 19, 21] </ref> for related results.
Reference: [20] <author> Mihail, M. and Winkler, P. </author> <title> On the number of Eulerian orientations of a graph. </title> <booktitle> Proceedings of the 3rd ACM-SIAM Symposium on Discrete Algorithms (1992), </booktitle> <pages> pp. 138-145. </pages>
Reference-contexts: In particular, for most graphs the number of perfect matchings can be estimated, a problem which corresponds to evaluating the permanent of a 0-1 matrix. Approximate counting of various other structures may be reduced to this problem <ref> [12, 20] </ref>. Finally, weighted sampling of matchings also enables a matching of nearly maximum cardinality to be found with high probability, an example of stochastic search by simulated annealing. Details of these applications may be found in [11, 23].
Reference: [21] <author> Mohar, B. </author> <title> Isoperimetric numbers of graphs. </title> <journal> Journal of Combinatorial Theory, Series B 47 (1989), </journal> <pages> pp. 274-291. </pages>
Reference-contexts: Thus measures the ability of the chain to escape from any small region of the state space, and hence to make rapid progress to equilibrium. The following result formalising this intuition is from [23, 24]; see also <ref> [2, 3, 4, 16, 19, 21] </ref> for related results.
Reference: [22] <author> Shahrokhi, F. and Matula, D. W. </author> <title> The maximum concurrent flow problem. </title> <journal> Journal of the ACM 37 (1990), </journal> <pages> pp. 318-334. </pages>
Reference-contexts: Hence we have = min Q (e) x2S P (y) e f (e) 1 where (S; S) is the partition of X induced by the cut edge e. The above question was extensively studied in more generality, and in a totally unrelated context, by Matula and Shahrokhi <ref> [18, 22] </ref>. The determination of is a case of what Matula and Shahrokhi call the Maximum Concurrent Flow Problem, while computing 0 is a case of the Sparsest Cut Problem. Matula and Shahrokhi show that these two problems are "near-duals" of one other, and make this statement precise.
Reference: [23] <author> Sinclair, A.J. </author> <title> Algorithms for random generation and counting: a Markov chain approach. </title> <type> PhD Thesis, </type> <institution> University of Edinburgh, </institution> <month> June </month> <year> 1988. </year> <note> To appear as a monograph in the series Progress in Theoretical Computer Science, </note> <editor> Birkhauser, </editor> <address> Boston, </address> <year> 1992. </year>
Reference-contexts: The book by Diaconis [7] gives an excellent survey. Markov chains arising in the combinatorial applications mentioned above are typically much more complex, however. The first analyses of such chains were 1 made possible using a quantity called the conductance <ref> [23, 24] </ref>. Suppose we view a (reversible) Markov chain as a weighted graph G, whose vertices are states and whose edges are transitions. Then the conductance (G) is essentially the edge expansion of G. <p> Conversely, a large value of means that the chain cannot get trapped by any small region of the space, and hence should be rapidly mixing. A useful piece of technology for obtaining lower bounds on in complex examples was developed in <ref> [11, 23] </ref>. The idea is to construct a canonical path fl xy in the graph G between each ordered pair of distinct states x and y . <p> However, even if such a state exists, finding it requires more detailed information about the chain than is usually available in the more complex examples of interest to us.) Results analogous to Proposition 1 hold for measures other than the variation distance. For example, <ref> [23, 24] </ref> give bounds in terms of the relative pointwise distance, defined by rpd t In the remainder of this paper, we will ignore the technical issues arising from the choice of initial state. <p> We therefore focus attention on the second eigenvalue 1 . 4 As indicated in the previous section, the first upper bounds on 1 for complex Markov chains were based on the conductance <ref> [23, 24] </ref>, defined by (G) = min 0&lt;(S)1=2 (S) where G is the weighted graph describing the chain and Q (S; S) denotes the sum of Q (x; y) over edges fx; yg in G with x 2 S and y 2 S = X S . <p> Thus measures the ability of the chain to escape from any small region of the state space, and hence to make rapid progress to equilibrium. The following result formalising this intuition is from <ref> [23, 24] </ref>; see also [2, 3, 4, 16, 19, 21] for related results. <p> Approximate counting of various other structures may be reduced to this problem [12, 20]. Finally, weighted sampling of matchings also enables a matching of nearly maximum cardinality to be found with high probability, an example of stochastic search by simulated annealing. Details of these applications may be found in <ref> [11, 23] </ref>. In order for the resulting algorithms to be efficient (in the sense of having polynomially bounded runtime), accurate sampling must be possible in time bounded by a polynomial in the size of H and c max = maxf1; max a2A c (a)g. <p> We now present a brief sketch of the canonical path argument used to obtain such a bound. In doing so, our aim will be to illustrate how the quantity arises naturally from a combinatorial encoding technique. For the details the reader is referred to <ref> [11, 23] </ref>. Let I and F be matchings in H , and consider the symmetric difference S = I F . The connected components of S are paths and cycles in H whose edges belong alternately to I and F . <p> But Q (e) = (M )P (M; M 0 ), so (10) gives us an upper bound on the crucial quantity Q (e) 1 P fl IF 3e (I)(F ), and hence on . Precisely, the bound derived in <ref> [11, 23] </ref> by this method is 4jAjc 2 rollary 4 therefore yields 1 1 1=128jAj c max : On the other hand, the maximum length of any canonical path is easily seen to be at most jV j = n, so Corollary 6 gives the much sharper bound 1 1 1=4njAjc <p> gives a bound on the ratio of n 10 for random graphs of low density. (The ratio can in fact be exponentially large, but then the chain no longer converges in polynomial time.) (ii) Broder's chain for the dense permanent This chain, which was proposed in [5] and analysed in <ref> [11, 23] </ref>, is a restricted version of Example (i); it again allows the number of perfect matchings in a graph to be estimated in polynomial time provided the ratio of the number of near-perfect matchings to the number of perfect matchings is polynomially bounded. <p> Simulation of the Markov chain allows the structures to be sampled from an almost uniform distribution, and indirectly enables one to bootstrap the crude counting estimates to arbitrarily precise estimates of the number of structures. For the details and some applications, see <ref> [23, 24] </ref>. In [23, 24] a direct argument gives the bound (4r 2 1 for the conductance, where d is the depth of the tree and r 1 is the error factor allowed in the crude counting estimates. <p> Simulation of the Markov chain allows the structures to be sampled from an almost uniform distribution, and indirectly enables one to bootstrap the crude counting estimates to arbitrarily precise estimates of the number of structures. For the details and some applications, see <ref> [23, 24] </ref>. In [23, 24] a direct argument gives the bound (4r 2 1 for the conductance, where d is the depth of the tree and r 1 is the error factor allowed in the crude counting estimates.
Reference: [24] <author> Sinclair, A.J. and Jerrum, </author> <title> M.R. Approximate counting, uniform generation and rapidly mixing Markov chains. </title> <booktitle> Information and Computation 82 (1989), </booktitle> <pages> pp. 93-133. </pages>
Reference-contexts: The book by Diaconis [7] gives an excellent survey. Markov chains arising in the combinatorial applications mentioned above are typically much more complex, however. The first analyses of such chains were 1 made possible using a quantity called the conductance <ref> [23, 24] </ref>. Suppose we view a (reversible) Markov chain as a weighted graph G, whose vertices are states and whose edges are transitions. Then the conductance (G) is essentially the edge expansion of G. <p> However, even if such a state exists, finding it requires more detailed information about the chain than is usually available in the more complex examples of interest to us.) Results analogous to Proposition 1 hold for measures other than the variation distance. For example, <ref> [23, 24] </ref> give bounds in terms of the relative pointwise distance, defined by rpd t In the remainder of this paper, we will ignore the technical issues arising from the choice of initial state. <p> We therefore focus attention on the second eigenvalue 1 . 4 As indicated in the previous section, the first upper bounds on 1 for complex Markov chains were based on the conductance <ref> [23, 24] </ref>, defined by (G) = min 0&lt;(S)1=2 (S) where G is the weighted graph describing the chain and Q (S; S) denotes the sum of Q (x; y) over edges fx; yg in G with x 2 S and y 2 S = X S . <p> Thus measures the ability of the chain to escape from any small region of the state space, and hence to make rapid progress to equilibrium. The following result formalising this intuition is from <ref> [23, 24] </ref>; see also [2, 3, 4, 16, 19, 21] for related results. <p> we are usually more interested in positive results, lower bounds on are generally of greater interest and we focus on them for most of the rest of this paper. (We shall consider negative results in Section 4.) In some cases such a bound can be obtained directly, using elementary arguments <ref> [16, 24] </ref> or geometric ideas [9, 14]. However, in many important applications the only known handle on is via the canonical path approach sketched in the previous section. <p> Simulation of the Markov chain allows the structures to be sampled from an almost uniform distribution, and indirectly enables one to bootstrap the crude counting estimates to arbitrarily precise estimates of the number of structures. For the details and some applications, see <ref> [23, 24] </ref>. In [23, 24] a direct argument gives the bound (4r 2 1 for the conductance, where d is the depth of the tree and r 1 is the error factor allowed in the crude counting estimates. <p> Simulation of the Markov chain allows the structures to be sampled from an almost uniform distribution, and indirectly enables one to bootstrap the crude counting estimates to arbitrarily precise estimates of the number of structures. For the details and some applications, see <ref> [23, 24] </ref>. In [23, 24] a direct argument gives the bound (4r 2 1 for the conductance, where d is the depth of the tree and r 1 is the error factor allowed in the crude counting estimates.
References-found: 24

