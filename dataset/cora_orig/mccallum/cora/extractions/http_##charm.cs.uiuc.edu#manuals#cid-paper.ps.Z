URL: http://charm.cs.uiuc.edu/manuals/cid-paper.ps.Z
Refering-URL: http://charm.cs.uiuc.edu/manuals/
Root-URL: http://www.cs.uiuc.edu
Title: Cid A Parallel, "Shared-memory" C for Distributed-memory Machines  
Author: Rishiyur S. Nikhil 
Date: September 29, 1994  
Affiliation: Digital Equipment Corporation Cambridge Research Laboratory  
Abstract: Cid is a parallel, "shared-memory" superset of C for distributed-memory machines. A major objective is to keep the entry cost low. For users- the language should be easily comprehensible to a C programmer. For implementors- it should run on standard hardware (including workstation farms); it should not require major new compilation techniques (which may not even be widely applicable); and it should be compatible with existing code, run-time systems and tools. Cid is implemented with a simple pre-processor and a library, uses available C compilers and packet-transport primitives, and links with existing libraries. Cid extends C with MIMD threads and global objects and a common "join-variable" mechanism for dealing with asynchronous actions. The number of threads is arbitrary and may vary dynamically. Any C object can be registered as a global object; the resulting "global pointer" may be used to access the object from any PE (processing element) in a locked, coherent, cached manner. Combining locking with cacheing reduces communication traffic. Being entirely in software, there is the opportunity to vary coherence protocols to suit the application. Distributed data structures may built by linking across PEs with global pointers, or by using Cid's distributed array primitives. The programmer does no explicit message-passing, but Cid exposes some abstractions of the distributed memory machine. PEs have separate address spaces; threads may be forked to different PEs, but a thread does not span PE boundaries. Threads access remote data only via thread arguments and results, and global objects. Finally, several Cid operations are made explicitly asynchronous, in recognition of the underlying communication and synchronization costs. In this paper, we describe the language, our first, multi-threaded implementation, some preliminary results, and compare with related systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agarwal, D. Chaiken, G. D'Souza, K. Johnson, D. Kranz, J. Kubiatowicz, K. Kurihara, B.-H. Lim, G. Maa, D. Nussbaum, M. Parkin, and D. Yeung. </author> <title> The MIT Alewife Machine: A Large-Scale Distributed-Memory Multiprocessor. </title> <booktitle> In Proc. Wkshp. on Multithreaded Computers, Supercomputing '91, </booktitle> <address> Albuquerque NM, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: One approach is to restore completely the original "SMP" threads-plus-locks shared memory programming model, relying on transparent, global, consistent cacheing that is supported by a combination of hardware and systems software (e.g., the KSR-1, DASH [14] and FLASH [13] at Stanford, *T-ng [2] and Alewife <ref> [1] </ref> at MIT, Tempest and Typhoon [20, 17] at Wisconsin, etc.).
Reference: [2] <author> Arvind, B. S. Ang, and D. Chiou. </author> <title> StarT the Next Generation: Integrating Global Caches and Dataflow Architecture. </title> <booktitle> In Proc. ISCA '92 Dataflow Workshop, </booktitle> <address> Hamilton Island, Australia, 1994 (expected). </address>
Reference-contexts: One approach is to restore completely the original "SMP" threads-plus-locks shared memory programming model, relying on transparent, global, consistent cacheing that is supported by a combination of hardware and systems software (e.g., the KSR-1, DASH [14] and FLASH [13] at Stanford, *T-ng <ref> [2] </ref> and Alewife [1] at MIT, Tempest and Typhoon [20, 17] at Wisconsin, etc.).
Reference: [3] <author> B. N. Bershad, M. J. Zekauskas, and W. A. Sawdon. </author> <title> The Midway Distributed Memory System. </title> <type> Technical Report CMU-CS-93-119, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: machines, and about 300% faster on 8 machines. 4 Related work Other researchers have worked on tailoring software-based coherence protocols to the nature of sharing; on tying coherence mechanisms to program-level objects (rather than architectural units such as pages or cache lines), and on combining synchronization with data access (e.g., <ref> [3] </ref>, [15], [20], [18]. However, the languages that seem most closely related to Id are discussed below. 4.1 Split-C The first main difference between Split-C [6] and Cid is that Cid has an MIMD model, whereas Split-C has an SPMD model.
Reference: [4] <author> M. C. Carlisle, A. Rogers, J. H. Reppy, and L. J. Hendren. </author> <title> Early Experience with Olden. </title> <booktitle> In Proc. 6th Ann. Wkshp. on Languages and Compilers for Parallel Computing, </booktitle> <address> Portland OR, </address> <publisher> Springer-Verlag LNCS 768, </publisher> <pages> pages 1-20, </pages> <month> August 12-14 </month> <year> 1993. </year>
Reference-contexts: We describe the programming model for Cid in Section 2. We provide an overview of the implementation, and the current implementation status in Section 3. In Section 4, we discuss related work, notably Split-C [6], Olden <ref> [4] </ref>, Charm [12] and Threaded-C [9]. Section 5 is a brief conclusion. 2 Cid Cid is basically C, plus threads and global objects, plus a join mechanism for asynchronous thread and object operations. 2.1 Threads and Joins Forking a thread in Cid is an asynchronous function call. <p> This is achieved because the communication costs of each primitive is roughly predictable. In Cid, the object cacheing and dynamic distribution of work and data make the communication costs less predictable. 4.2 Olden Olden is a parallel C from Princeton <ref> [4] </ref>. A long term goal is for the programmer to use ordinary, sequential C, with opportunities for MIMD parallelism exposed automatically through analysis by 11 the compiler (the designers introduce parallelism manually for now, while concentrating on runtime system implmentation issues).
Reference: [5] <author> D. Chaiken, C. Fields, K. Kurihara, and A. Agarwal. </author> <title> Directory-based Cache Coherence in Large-Scale Multiprocessors. </title> <journal> IEEE Computer, </journal> <volume> 23(6) </volume> <pages> 49-59, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: When it has received all these notifications, it sends the write-copy to the requesting PE. This is essentially a directory-based coherence mechanism similar to many that are well discussed in the literature <ref> [5] </ref>. We expect to experiment with many variations. 10 3.7 Implementation status and preliminary results We have recently completed our first implementation of Cid, on Digital Alpha/OSF1 workstation farms (with a Gigaswitch FDDI crossbar interconnect). We can use any, possibly unreliable, non-blocking, packet-transport layer; for now, we use UDP sockets.
Reference: [6] <author> D. E. Culler, A. Dusseau, S. C. Goldstein, S. Lumetta, T. von Eicken, and K. Yelick. </author> <title> Parallel Programming in Split-C. </title> <booktitle> In Proc. Supercomputing 93, </booktitle> <address> Portland OR, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: We describe the programming model for Cid in Section 2. We provide an overview of the implementation, and the current implementation status in Section 3. In Section 4, we discuss related work, notably Split-C <ref> [6] </ref>, Olden [4], Charm [12] and Threaded-C [9]. Section 5 is a brief conclusion. 2 Cid Cid is basically C, plus threads and global objects, plus a join mechanism for asynchronous thread and object operations. 2.1 Threads and Joins Forking a thread in Cid is an asynchronous function call. <p> If gp is NULL, cid to pe returns the current PE. One may obtain a local pointer to a global object using: 3 Unfortunately, this loses type information. If we implement/modify a C type-checker, we could improve this notation, as is done in Split-C <ref> [6] </ref>. 5 lp = cid_to_local (gp) This may involve copying the object from its "home" PE (details in the next section, where we discuss cid get obj (), of which cid to local () is only a special case). <p> However, the languages that seem most closely related to Id are discussed below. 4.1 Split-C The first main difference between Split-C <ref> [6] </ref> and Cid is that Cid has an MIMD model, whereas Split-C has an SPMD model. In Cid, execution begins with one thread on PE 0, which forks threads under program control; the number of threads may vary dynamically, and there may be many threads per PE.
Reference: [7] <author> D. E. Culler, A. Sah, K. E. Schauser, T. von Eicken, and J. Wawrzynek. </author> <title> Fine-grain Parallelism with Minimal Hardware Support: A Compiler-Controlled Threaded Abstract Machine. </title> <booktitle> In 4th Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 164-175, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: Recognizing this difficulty, the designers of Charm are attempting to develop a simpler, graphical notation called Dagger. Berkeley's TAM <ref> [7] </ref>, and the author's own P-RISC [16] are both message-driven models used for implementing the Id programming language. Both have split-phase actions for latency tolerance, and both use join counters to wait for n long-latency events.
Reference: [8] <author> R. Das, M. Uysal, J. Saltz, and Y.-S. Hwang. </author> <title> Communication Optimizations for Irregular Scientific Computations on Distributed Memory Architectures. </title> <type> Technical Report CS-TR-3163, </type> <institution> U. Maryland Computer Science, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: HPF (High Performance Fortran) [11] is one such model, but seems limited to computations involving simple loop-level parallelism on dense rectangular arrays (although there is much active research to go beyond this, see for example <ref> [8] </ref>).
Reference: [9] <author> M. Halbherr, Y. Zhou, and C. F. Joerg. </author> <title> MIMD-style Parallel Programming Based on Continuation-Passing Threads. </title> <type> Technical Report CSG Memo 355, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> March 7 </month> <year> 1994. </year>
Reference-contexts: We describe the programming model for Cid in Section 2. We provide an overview of the implementation, and the current implementation status in Section 3. In Section 4, we discuss related work, notably Split-C [6], Olden [4], Charm [12] and Threaded-C <ref> [9] </ref>. Section 5 is a brief conclusion. 2 Cid Cid is basically C, plus threads and global objects, plus a join mechanism for asynchronous thread and object operations. 2.1 Threads and Joins Forking a thread in Cid is an asynchronous function call. <p> This is a restriction on normal C programming style. Olden also requires a fair number of changes to existing C compilers, which we explicitly avoid. 4.3 Charm, Threaded-C, TAM and P-RISC Charm [12] and Threaded-C <ref> [9] </ref> are message-driven parallel C's for distributed memory machines. The fundamental difference between these two languages and Cid, Split-C and Olden is that they require a "continuation-passing style" of programming.
Reference: [10] <author> R. H. Halstead. </author> <title> Multilisp: A Language for Concurrent Symbolic Computation. </title> <journal> ACM Trans. on Pro--gramming Languages and Systems, </journal> <volume> 7(4) </volume> <pages> 501-539, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: Join variables are just a pre-defined struct type; they may be embedded in other data structures, passed as arguments, returned as results, dynamically allocated, etc. The cid fork statement is related to Multilisp futures <ref> [10] </ref>. Here, we unbundle the synchronization variable from the result variable, so that it is possible for more than one forked call to share synchronization variables.
Reference: [11] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran: Language Specification, </title> <note> Version 1.0, May 3 1993. Anonymous ftp: titan.cs.rice.edu. </note>
Reference-contexts: Email: nikhil@crl.dec.com 1 is explicit message-passing, with their "multicomputer" nature visible to the programmer. It is now widely conceded that this is too difficult for routine programming, and there is a search for simpler, shared-memory parallel programming models. HPF (High Performance Fortran) <ref> [11] </ref> is one such model, but seems limited to computations involving simple loop-level parallelism on dense rectangular arrays (although there is much active research to go beyond this, see for example [8]).
Reference: [12] <author> L. V. Kale. </author> <title> Parallel Programming with CHARM: An Overview. </title> <type> Technical Report 93-8, </type> <institution> Dept. of Computer Science, University of Illinois at Urbana-Champaign, </institution> <year> 1993. </year>
Reference-contexts: We describe the programming model for Cid in Section 2. We provide an overview of the implementation, and the current implementation status in Section 3. In Section 4, we discuss related work, notably Split-C [6], Olden [4], Charm <ref> [12] </ref> and Threaded-C [9]. Section 5 is a brief conclusion. 2 Cid Cid is basically C, plus threads and global objects, plus a join mechanism for asynchronous thread and object operations. 2.1 Threads and Joins Forking a thread in Cid is an asynchronous function call. <p> This is a restriction on normal C programming style. Olden also requires a fair number of changes to existing C compilers, which we explicitly avoid. 4.3 Charm, Threaded-C, TAM and P-RISC Charm <ref> [12] </ref> and Threaded-C [9] are message-driven parallel C's for distributed memory machines. The fundamental difference between these two languages and Cid, Split-C and Olden is that they require a "continuation-passing style" of programming.
Reference: [13] <author> J. Kuskin, D. Ofelt, M. Heinrich, J. Heinlein, R. Simoni, K. Gharachorloo, J. Chapin, D. Nakahira, J. Baxter, M. Horowitz, A. Gupta, M. Rosenblum, and J. Hennessy. </author> <title> The Stanford FLASH Multiprocessor. </title> <booktitle> In Proc. ISCA 94, </booktitle> <address> Chicago IL, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: One approach is to restore completely the original "SMP" threads-plus-locks shared memory programming model, relying on transparent, global, consistent cacheing that is supported by a combination of hardware and systems software (e.g., the KSR-1, DASH [14] and FLASH <ref> [13] </ref> at Stanford, *T-ng [2] and Alewife [1] at MIT, Tempest and Typhoon [20, 17] at Wisconsin, etc.).
Reference: [14] <author> D. Lenoski, J. Laudon, K. Gharachorloo, W.-D. Weber, A. Gupta, J. Hennessy, M. Horowitz, and M. S. Lam. </author> <title> The Stanford DASH Multiprocessor. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 63-79, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: One approach is to restore completely the original "SMP" threads-plus-locks shared memory programming model, relying on transparent, global, consistent cacheing that is supported by a combination of hardware and systems software (e.g., the KSR-1, DASH <ref> [14] </ref> and FLASH [13] at Stanford, *T-ng [2] and Alewife [1] at MIT, Tempest and Typhoon [20, 17] at Wisconsin, etc.).
Reference: [15] <author> R. S. Nikhil. </author> <title> Id (Version 90.1) Reference Manual. </title> <type> Technical Report CSG Memo 284-2, </type> <institution> MIT Laboratory for Computer Science, 545 Technology Square, </institution> <address> Cambridge MA 02139, USA, </address> <month> July 15 </month> <year> 1991. </year>
Reference-contexts: This allows us to express "futures", pre-fetches and post-stores, barrier synchronizations, etc. By combining lock acquisition with remote data access, Cid reduces communication traffic, and makes 1 The name derives from C, and from the Id parallel programming language <ref> [15] </ref>, our multi-threaded implementation of which inspired many ideas in Cid [16]. 2 shared data access not much more verbose than conventional SMP code. Cid's asynchronous operations are exploited in the implementation which is multi-threaded and overlaps computation with the long latencies of remote operations and synchronization waits. <p> and about 300% faster on 8 machines. 4 Related work Other researchers have worked on tailoring software-based coherence protocols to the nature of sharing; on tying coherence mechanisms to program-level objects (rather than architectural units such as pages or cache lines), and on combining synchronization with data access (e.g., [3], <ref> [15] </ref>, [20], [18]. However, the languages that seem most closely related to Id are discussed below. 4.1 Split-C The first main difference between Split-C [6] and Cid is that Cid has an MIMD model, whereas Split-C has an SPMD model.
Reference: [16] <author> R. S. Nikhil. </author> <title> A Multithreaded Implementation of Id using P-RISC Graphs. </title> <booktitle> In Proc. 6th Ann. Wkshp. on Languages and Compilers for Parallel Computing, </booktitle> <address> Portland, Oregon, </address> <publisher> Springer-Verlag LNCS 768, </publisher> <pages> pages 390-405, </pages> <month> August 12-14 </month> <year> 1993. </year>
Reference-contexts: By combining lock acquisition with remote data access, Cid reduces communication traffic, and makes 1 The name derives from C, and from the Id parallel programming language [15], our multi-threaded implementation of which inspired many ideas in Cid <ref> [16] </ref>. 2 shared data access not much more verbose than conventional SMP code. Cid's asynchronous operations are exploited in the implementation which is multi-threaded and overlaps computation with the long latencies of remote operations and synchronization waits. <p> Recognizing this difficulty, the designers of Charm are attempting to develop a simpler, graphical notation called Dagger. Berkeley's TAM [7], and the author's own P-RISC <ref> [16] </ref> are both message-driven models used for implementing the Id programming language. Both have split-phase actions for latency tolerance, and both use join counters to wait for n long-latency events.
Reference: [17] <author> S. K. Reinhardt, J. R. Larus, and D. A. Wood. Tempest and Typhoon: </author> <title> User-Level Shared Memory. </title> <booktitle> In Proc. ISCA 94, </booktitle> <address> Chicago IL, </address> <month> April </month> <year> 1994. </year>
Reference-contexts: approach is to restore completely the original "SMP" threads-plus-locks shared memory programming model, relying on transparent, global, consistent cacheing that is supported by a combination of hardware and systems software (e.g., the KSR-1, DASH [14] and FLASH [13] at Stanford, *T-ng [2] and Alewife [1] at MIT, Tempest and Typhoon <ref> [20, 17] </ref> at Wisconsin, etc.).
Reference: [18] <author> B. Totty and D. A. Reed. </author> <title> Dynamic Object Management for Distributed Data Structures. </title> <booktitle> In Proc. Supercomputing 92, </booktitle> <pages> pages 692-701, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: 300% faster on 8 machines. 4 Related work Other researchers have worked on tailoring software-based coherence protocols to the nature of sharing; on tying coherence mechanisms to program-level objects (rather than architectural units such as pages or cache lines), and on combining synchronization with data access (e.g., [3], [15], [20], <ref> [18] </ref>. However, the languages that seem most closely related to Id are discussed below. 4.1 Split-C The first main difference between Split-C [6] and Cid is that Cid has an MIMD model, whereas Split-C has an SPMD model.
Reference: [19] <author> T. von Eicken, D. E. Culler, S. C. Goldstein, and K. E. Schauser. </author> <title> Active Messages: a Mechanism for Integrated Communication and Computation. </title> <booktitle> In Proc. 19th. Ann. Intl. Symp. on Computer Architecture, Australia, </booktitle> <pages> pages 256-266, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Then, a message is sent back which causes the result to be deposited in x and jv to be signalled. All messages are active messages <ref> [19] </ref>, i.e., they contain a pointer to a C function (called a handler ) that is directly called with the message itself as argument. Incoming messages are executed at any 8 time, as they arrive, on top of whatever stack happens to be active at the time.
Reference: [20] <author> D. A. Wood, S. Chandra, B. Falsafi, M. D. Hill, J. R. Larus, A. R. Lebeck, J. C. Lewis, S. Mukerjee, S. Palacharla, and S. K. Reinhardt. </author> <title> Mechanisms for Cooperative Shared Memory. </title> <booktitle> In Proc. 21st ISCA, </booktitle> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <month> 14 </month>
Reference-contexts: approach is to restore completely the original "SMP" threads-plus-locks shared memory programming model, relying on transparent, global, consistent cacheing that is supported by a combination of hardware and systems software (e.g., the KSR-1, DASH [14] and FLASH [13] at Stanford, *T-ng [2] and Alewife [1] at MIT, Tempest and Typhoon <ref> [20, 17] </ref> at Wisconsin, etc.). <p> about 300% faster on 8 machines. 4 Related work Other researchers have worked on tailoring software-based coherence protocols to the nature of sharing; on tying coherence mechanisms to program-level objects (rather than architectural units such as pages or cache lines), and on combining synchronization with data access (e.g., [3], [15], <ref> [20] </ref>, [18]. However, the languages that seem most closely related to Id are discussed below. 4.1 Split-C The first main difference between Split-C [6] and Cid is that Cid has an MIMD model, whereas Split-C has an SPMD model.
References-found: 20

