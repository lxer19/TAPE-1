URL: http://www.cs.rice.edu/~adve/CS615/nexus.multi-method.jpdc.ps
Refering-URL: http://www.cs.rice.edu/~adve/comp615.html
Root-URL: 
Email: http://www.mcs.anl.gov/nexus/  
Title: Managing Multiple Communication Methods in High-Performance Networked Computing Systems  
Author: Ian Foster Jonathan Geisler Carl Kesselman and Steven Tuecke 
Abstract: Modern networked computing environments and applications often require|or can benefit from|the use of multiple communication substrates, transport mechanisms, and protocols, chosen according to where communication is directed, what is communicated, or when communication is performed. We propose techniques that allow multiple communication methods to be supported transparently in a single application, with either automatic or user-specified selection criteria guiding the methods used for each communication. We explain how communication link and remote service request mechanisms facilitate the specification and implementation of multimethod communication. These mechanisms have been implemented in the Nexus multithreaded runtime system, and we use this system to illustrate solutions to various problems that arise when implementing multimethod communication. We also illustrate the application of our techniques by describing a multimethod, multithreaded implementation of the Message Passing Interface (MPI) standard, constructed by integrating Nexus with the Argonne MPICH library. Finally, we present the results of experimental studies that reveal performance characteristics of multimethod communication, the Nexus-based MPI implementation, and a large scientific application running in a heterogeneous networked environment.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. E. Bal, J. G. Steiner, and A. S. Tanenbaum. </author> <title> Programming languages for distributed computing systems. </title> <journal> ACM Computing Surveys, </journal> <volume> 21(3) </volume> <pages> 261-322, </pages> <year> 1989. </year> <month> 22 </month>
Reference-contexts: In addition, mechanisms are required for identifying applicable methods and for incorporating multiple communication methods into an implementation. No existing system addresses all of these issues. Various tools support computing in heterogeneous environments <ref> [1, 4, 32] </ref>, but most do not exploit or expose the heterogeneous nature of the network or applications. The p4 [5] and PVM [20] communication libraries can use different low-level methods in heterogeneous environments, but the set of methods used is not extensible. <p> Nexus/MPL+TCP 1 55.5 55.9 Nexus/MPL+TCP 2 54.4 54.8 Nexus/MPL+TCP 5 53.7 53.7 Nexus/MPL+TCP 20 55.1 53.2 Nexus/MPL+TCP 100 52.5 53.3 Nexus/MPL+TCP 1000 52.3 52.4 Nexus/MPL+TCP 7000 52.8 51.8 Nexus/MPL+TCP 10000 52.8 52.9 20 6 Related Work Many researchers have proposed and investigated communication mechanisms for heterogeneous computing systems (for example, <ref> [1, 4, 32] </ref>). However, this work has typically been concerned with hiding heterogeneity by providing a uniform user-level interface rather than with exploiting and exposing the heterogeneous nature of networks and applications. Some communication libraries permit different communication methods to coexist.
Reference: [2] <author> R. Bhoedjang, T. Rumlhl, R. Hofman, K. Langendoen, and H. Bal. Panda: </author> <title> A portable platform to support parallel programming languages. </title> <booktitle> In Symposium on Experiences with Distributed and Multiprocessor Systems IV, </booktitle> <pages> pages 213-226, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: The concurrent execution of multiple lightweight threads within a single process is a useful technique for masking variable latencies, exploiting multiprocessors, and providing concurrent access to shared resources. Various approaches to the integration of multithreading into a message-passing framework have been proposed <ref> [2, 12, 18, 37, 39, 13, 25, 42] </ref>. The Nexus implementation of MPI supports a particularly simple and elegant model that does not require that explicit thread identifiers be exported from MPI processes.
Reference: [3] <author> E. Biagioni. </author> <title> A structured TCP in Standard ML. </title> <booktitle> In Proc. SIGCOMM '94, </booktitle> <year> 1994. </year> <note> Also as Technical Report CMU-CS-94-171, Carnegie Mellon. </note>
Reference-contexts: Early results with Horus suggest that these compositional formulations simplify implementation, but can introduce overheads similar to those encountered when layering MPICH on Nexus: additional message header information, function calls, and messages. Tschudin [38] and the Fox project <ref> [3] </ref> have explored similar concepts and report similar results. Active Messages (AM) [29] and Fast Messages (FM) [34] are communication systems based on asynchronous handler invocation mechanisms similar to those used in Nexus. The latest AM specification introduces an endpoint construct with some similarities to the Nexus endpoint.
Reference: [4] <author> A. Birrell and B. Nelson. </author> <title> Implementing remote procedure calls. </title> <journal> ACM Transactions on Computing Systems, </journal> <volume> 2 </volume> <pages> 39-59, </pages> <year> 1984. </year>
Reference-contexts: In addition, mechanisms are required for identifying applicable methods and for incorporating multiple communication methods into an implementation. No existing system addresses all of these issues. Various tools support computing in heterogeneous environments <ref> [1, 4, 32] </ref>, but most do not exploit or expose the heterogeneous nature of the network or applications. The p4 [5] and PVM [20] communication libraries can use different low-level methods in heterogeneous environments, but the set of methods used is not extensible. <p> Nexus/MPL+TCP 1 55.5 55.9 Nexus/MPL+TCP 2 54.4 54.8 Nexus/MPL+TCP 5 53.7 53.7 Nexus/MPL+TCP 20 55.1 53.2 Nexus/MPL+TCP 100 52.5 53.3 Nexus/MPL+TCP 1000 52.3 52.4 Nexus/MPL+TCP 7000 52.8 51.8 Nexus/MPL+TCP 10000 52.8 52.9 20 6 Related Work Many researchers have proposed and investigated communication mechanisms for heterogeneous computing systems (for example, <ref> [1, 4, 32] </ref>). However, this work has typically been concerned with hiding heterogeneity by providing a uniform user-level interface rather than with exploiting and exposing the heterogeneous nature of networks and applications. Some communication libraries permit different communication methods to coexist.
Reference: [5] <author> R. Butler and E. Lusk. </author> <title> Monitors, message, and clusters: The p4 parallel programming system. </title> <journal> Parallel Computing, </journal> <volume> 20 </volume> <pages> 547-564, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: No existing system addresses all of these issues. Various tools support computing in heterogeneous environments [1, 4, 32], but most do not exploit or expose the heterogeneous nature of the network or applications. The p4 <ref> [5] </ref> and PVM [20] communication libraries can use different low-level methods in heterogeneous environments, but the set of methods used is not extensible. <p> Some communication libraries permit different communication methods to coexist. For example, the Intel Paragon implementations of p4 and PVM support heterogeneous computing by using the NX communication library for internal communication and TCP for external communication <ref> [5, 20] </ref>; p4 supports NX and TCP within a single process, while PVM uses a proxy process for TCP. In both systems, the choice of method is hard coded and cannot be extended or changed without substantial reengineering.
Reference: [6] <author> K. M. Chandy and C. Kesselman. </author> <title> CC ++ : A declarative concurrent object oriented programming notation. In Research Directions in Object Oriented Programming. </title> <publisher> The MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: In evaluating these techniques, we must necessarily be concerned with both their generality and the efficiency with which they can be implemented. With respect to generality, we note that Nexus has been used to implement a variety of parallel languages and communication libraries <ref> [6, 14, 10] </ref>. We describe here an implementation of the standard Message Passing Interface (MPI) [24], constructed by adapting the MPICH [23] implementation of MPI to use Nexus communication primitives [16]. <p> We also explain how the Nexus implementation of MPI benefits from access to Nexus multithreading mechanisms. This MPI implementation was used extensively in the I-WAY wide area computing experiment [8], where it and other Nexus-based tools <ref> [6, 10] </ref> supported multiple applications on a wide range of networks and computers, including IBM SP2, Intel Paragon, Cray C90, and SGI Power Challenge. <p> We emphasize that an implementation of MPI is not the only application of Nexus mechanisms; it is certainly not the programming model for which Nexus is best suited. Other systems that use Nexus facilities include parallel object-oriented languages (for example, CC++ <ref> [6] </ref> and Fortran M [14]), parallel scripting languages (nPerl), and communication libraries (CAVEcomm [10] 12 and a Java library).
Reference: [7] <author> D. E. Comer. </author> <title> Internetworking with TCP/IP. </title> <publisher> Prentice Hall, 3rd edition, </publisher> <year> 1995. </year>
Reference-contexts: These examples show that it can be necessary to vary the methods used for a particular communication according to where communication is directed, what is communicated, and even when communication is performed. * Transport mechanisms. While the Internet Protocol provides a standard transport mechanism <ref> [7] </ref>, parallel computers and local area networks often support alternative, more efficient mechanisms: for example, shared memory, a vendor-specific communication library such as IBM's Message Passing Library (MPL), or MessageWay over a local Asynchronous Transfer Mode (ATM) switch.
Reference: [8] <author> T. DeFanti, I. Foster, M. Papka, R. Stevens, and T. Kuhfuss. </author> <title> Overview of the I-WAY: Wide area visual supercomputing. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 10(2), </volume> <year> 1996. </year>
Reference-contexts: We also explain how the Nexus implementation of MPI benefits from access to Nexus multithreading mechanisms. This MPI implementation was used extensively in the I-WAY wide area computing experiment <ref> [8] </ref>, where it and other Nexus-based tools [6, 10] supported multiple applications on a wide range of networks and computers, including IBM SP2, Intel Paragon, Cray C90, and SGI Power Challenge. <p> For example, a key TCP BUFFER SIZE might be used to specify the buffer size to be used on a particular communicator. A second benefit that accrues from the Nexus implementation of MPI is interoperability with other Nexus-based tools. For example, in the I-WAY networking experiment <ref> [8] </ref>, numerous applications used the CAVEcomm [10] client-server package to transfer data among one or more virtual reality systems and a scientific simulation running on a supercomputer. When 14 the simulation itself was developed using MPI, the need arose to integrate the polling required to detect communication from either source.
Reference: [9] <author> D. Diachin, L. Freitag, D. Heath, J. Herzog, W. Michels, and P. Plassmann. </author> <title> Remote engineering tools for the design of pollution control systems for commercial boilers. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 10(2), </volume> <year> 1996. </year>
Reference-contexts: 1 Introduction Increasingly, high-performance applications need to exploit heterogeneous collections of computing resources interconnected via high speed networks. Examples of such applications include coupled modules [30, 31], collaborative environments <ref> [9, 10] </ref> and computations that couple specialized data sources to supercomputers for processing and visualization [28]. These applications are heterogeneous not only in in their computational requirements, but also in the types of data that they communicate.
Reference: [10] <author> T. L. Disz, M. E. Papka, M. Pellegrino, and R. Stevens. </author> <title> Sharing visualization experiences among remote virtual environments. </title> <booktitle> In International Workshop on High Performance Computing for Computer Graphics and Visualization, </booktitle> <pages> pages 217-237. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: 1 Introduction Increasingly, high-performance applications need to exploit heterogeneous collections of computing resources interconnected via high speed networks. Examples of such applications include coupled modules [30, 31], collaborative environments <ref> [9, 10] </ref> and computations that couple specialized data sources to supercomputers for processing and visualization [28]. These applications are heterogeneous not only in in their computational requirements, but also in the types of data that they communicate. <p> In evaluating these techniques, we must necessarily be concerned with both their generality and the efficiency with which they can be implemented. With respect to generality, we note that Nexus has been used to implement a variety of parallel languages and communication libraries <ref> [6, 14, 10] </ref>. We describe here an implementation of the standard Message Passing Interface (MPI) [24], constructed by adapting the MPICH [23] implementation of MPI to use Nexus communication primitives [16]. <p> We also explain how the Nexus implementation of MPI benefits from access to Nexus multithreading mechanisms. This MPI implementation was used extensively in the I-WAY wide area computing experiment [8], where it and other Nexus-based tools <ref> [6, 10] </ref> supported multiple applications on a wide range of networks and computers, including IBM SP2, Intel Paragon, Cray C90, and SGI Power Challenge. <p> Other systems that use Nexus facilities include parallel object-oriented languages (for example, CC++ [6] and Fortran M [14]), parallel scripting languages (nPerl), and communication libraries (CAVEcomm <ref> [10] </ref> 12 and a Java library). <p> A second benefit that accrues from the Nexus implementation of MPI is interoperability with other Nexus-based tools. For example, in the I-WAY networking experiment [8], numerous applications used the CAVEcomm <ref> [10] </ref> client-server package to transfer data among one or more virtual reality systems and a scientific simulation running on a supercomputer. When 14 the simulation itself was developed using MPI, the need arose to integrate the polling required to detect communication from either source.
Reference: [11] <author> J. Drake, I. Foster, J. Michalakes, B. Toonen, and P. Worley. </author> <title> Design and performance of a scalable parallel Community Climate Model. </title> <journal> Parallel Computing, </journal> <volume> 21(10) </volume> <pages> 1571-1591, </pages> <year> 1995. </year>
Reference-contexts: The two graphs show results for small and large messages, respectively. support. The application is a climate model that couples a large atmosphere model (the Parallel Community Climate Model <ref> [11] </ref>) with an ocean model (from U. Wisconsin). In brief, the two components execute concurrently, perform considerable internal communication, and periodically exchange boundary information such as sea surface temperature and various fluxes.
Reference: [12] <author> E. Felton and D. McNamee. </author> <title> Improving the performance of message-passing applications by multithreading. </title> <booktitle> In Proc. 1992 Scalable High Performance Computing Conf., </booktitle> <pages> pages 84-89. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year>
Reference-contexts: The concurrent execution of multiple lightweight threads within a single process is a useful technique for masking variable latencies, exploiting multiprocessors, and providing concurrent access to shared resources. Various approaches to the integration of multithreading into a message-passing framework have been proposed <ref> [2, 12, 18, 37, 39, 13, 25, 42] </ref>. The Nexus implementation of MPI supports a particularly simple and elegant model that does not require that explicit thread identifiers be exported from MPI processes.
Reference: [13] <author> A. Ferrari and V. S. Sunderam. TPVM: </author> <title> Distributed concurrent computing with lightweight processes. </title> <type> Technical Report CSTR-940802, </type> <institution> University of Virginia, </institution> <year> 1994. </year>
Reference-contexts: The concurrent execution of multiple lightweight threads within a single process is a useful technique for masking variable latencies, exploiting multiprocessors, and providing concurrent access to shared resources. Various approaches to the integration of multithreading into a message-passing framework have been proposed <ref> [2, 12, 18, 37, 39, 13, 25, 42] </ref>. The Nexus implementation of MPI supports a particularly simple and elegant model that does not require that explicit thread identifiers be exported from MPI processes.
Reference: [14] <author> I. Foster and K. M. Chandy. </author> <title> Fortran M: A language for modular parallel programming. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 26(1) </volume> <pages> 24-35, </pages> <year> 1995. </year>
Reference-contexts: In evaluating these techniques, we must necessarily be concerned with both their generality and the efficiency with which they can be implemented. With respect to generality, we note that Nexus has been used to implement a variety of parallel languages and communication libraries <ref> [6, 14, 10] </ref>. We describe here an implementation of the standard Message Passing Interface (MPI) [24], constructed by adapting the MPICH [23] implementation of MPI to use Nexus communication primitives [16]. <p> We emphasize that an implementation of MPI is not the only application of Nexus mechanisms; it is certainly not the programming model for which Nexus is best suited. Other systems that use Nexus facilities include parallel object-oriented languages (for example, CC++ [6] and Fortran M <ref> [14] </ref>), parallel scripting languages (nPerl), and communication libraries (CAVEcomm [10] 12 and a Java library).
Reference: [15] <author> I. Foster, J. Geisler, C. Kesselman, and S. Tuecke. </author> <title> Multimethod communication for high-performance metacomputing applications. </title> <booktitle> In Proceedings of Supercomputing '96. ACM, </booktitle> <year> 1996. </year>
Reference-contexts: In the "manual" strategy, polling is explicitly disabled except when in the coupler; hence, this represents a best case. In the "forwarder" case, a proxy processor (Section 3.4) is used to handle TCP communications (see <ref> [15] </ref> for details). Finally, we present results for a variety of skip poll values. Results are presented in Table 3. We see that considerable benefits result from the use of multimethod communication: time per day is 51.5 secs (in an "optimal" case) vs. 65.9 secs when only TCP is used.
Reference: [16] <author> I. Foster, J. Geisler, and S. Tuecke. </author> <title> MPI on the I-WAY: A wide-area, multimethod implementation of the Message Passing Interface. </title> <booktitle> In Proceedings of the 1996 MPI Developers Conference, </booktitle> <pages> pages 10-17. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1996. </year>
Reference-contexts: We describe here an implementation of the standard Message Passing Interface (MPI) [24], constructed by adapting the MPICH [23] implementation of MPI to use Nexus communication primitives <ref> [16] </ref>. This implementation allows an MPI program to execute unchanged in heterogeneous environments, with communication method selected according to default rules, depending on the source and destination of the message being sent. We also explain how the Nexus implementation of MPI benefits from access to Nexus multithreading mechanisms.
Reference: [17] <author> I. Foster, N.T. Karonis, C. Kesselman, G. Koenig, and S. Tuecke. </author> <title> A secure communications infrastructure for high-performance distributed computing. </title> <type> Preprint, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <year> 1996. </year>
Reference-contexts: However, the advantages of multimethod communication extend beyond communication protocols. We can use the same techniques to control other aspects of communication, such as security. In <ref> [17] </ref>, we show how our multimethod communication architecture can be used to support applications in which certain communication operations must encrypt data before sending it over an open network.
Reference: [18] <author> I. Foster, C. Kesselman, and M. Snir. </author> <title> Generalized communicators in the Message Passing Interface. </title> <booktitle> In Proceedings of the 1996 MPI Developers Conference, </booktitle> <pages> pages 42-49. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1996. </year> <month> 23 </month>
Reference-contexts: Each communicator behaves like a separate endpoint in our primitives and can|as we describe below|utilize a specific communication method. However, a communicator must be created by a collective operation and cannot be transferred between nodes, limiting its utility for multimethod communication. In <ref> [18] </ref>, we propose an extension to MPI communicators that overcomes this limitation. However, a second limitation of two-sided communication that cannot be overcome is that the protocol for synchronizing and extracting data at the receive side of the transfer is defined by the communication model. <p> The concurrent execution of multiple lightweight threads within a single process is a useful technique for masking variable latencies, exploiting multiprocessors, and providing concurrent access to shared resources. Various approaches to the integration of multithreading into a message-passing framework have been proposed <ref> [2, 12, 18, 37, 39, 13, 25, 42] </ref>. The Nexus implementation of MPI supports a particularly simple and elegant model that does not require that explicit thread identifiers be exported from MPI processes. <p> The multithreaded MPI also has its limitations. In particular, it is not possible to define a collective operation that involves more than one thread per process. This functionality requires extensions to the MPI model <ref> [18, 26, 37] </ref>. 5 Performance Studies We have conducted a variety of experiments to evaluate the performance of both our multi-method communication mechanisms and the Nexus implementation of MPI.
Reference: [19] <author> I. Foster, C. Kesselman, and S. Tuecke. </author> <title> The Nexus approach to integrating multithreading and communication. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <note> 1996. To appear. </note>
Reference-contexts: We describe a single-sided communication mechanism called a remote service request, and explain how this mechanisms can be used to implement both point-to-point and streaming protocols. These techniques have all been implemented in the context of the Nexus multithreaded runtime system <ref> [19] </ref>, and we use the architecture of the Nexus implementation to illustrate the presentation. In evaluating these techniques, we must necessarily be concerned with both their generality and the efficiency with which they can be implemented. <p> With our primitives, communication flows from a communication startpoint to a communication endpoint. (Earlier papers on the Nexus communication primitives <ref> [19] </ref> used the term global pointer to describe a startpoint and provided an implicitly defined endpoint. We introduce the terms startpoint and endpoint because we find them more descriptive.) A startpoint is bound to an endpoint to form a communication link. <p> That is, data must be extracted by a matching receive. This rigidity hinders implementation of the third scenario. 3 Architecture We now turn our attention to the techniques used to implement multimethod communication. We describe these techniques in the context of Nexus <ref> [19] </ref>, a portable, multithreaded communication library designed for use by parallel language compilers and higher-level communication libraries. In addition to communication links and remote service requests, Nexus provides support for lightweight threading, which, as we shall explain, can simplify the implementation of multimethod communication. <p> The techniques used to detect and process incoming RSRs have to trade off fast RSR response time against overheads incurred at the destination processor <ref> [19] </ref>. Threads can simplify implementation. If an OS allows a thread to block on a system call, then a specialized communication server thread may be created for each OS mechanism. This thread will be enabled only when an RSR is available. <p> If an OS does not provide this capability, we use explicit probe operations performed by a single communication server thread. Various combinations of round-robin scheduling, priorities, and explicit yields in user code can provide some degree of control over the frequency with which the server thread is scheduled <ref> [19] </ref>. When using probe operations to detect RSRs, complex tradeoffs can arise if probes for different communication methods have very different costs. <p> To provide a basis for comparison, we also evaluate an MPL program that implements the same communication pattern using point-to-point communication. We measure performance for pphandle using both Nexus and a single-threaded version of Nexus called NexusLite. (The former case corresponds to test case H-to-H in <ref> [19] </ref>.) In NexusLite, user programs cannot create multiple threads, and probe operations are performed within the computation thread rather than within a separate communication server thread. In addition, there is no need to protect communication operations with locks to ensure mutual exclusion. Hence, NexusLite results provide insights into multithreading costs. <p> NexusLite and Nexus take 82.8 and 112.4 sec respectively when configured to use MPL communication only. We have documented Nexus overheads elsewhere <ref> [19] </ref>. Briefly, the principal sources of the 21.4 sec difference between NexusLite and MPL are the setup and communication of the 32-byte header contained in a Nexus message (about 8 sec) and the lookup and dispatch of the handler on the receive side (about 7 sec).
Reference: [20] <author> A. Geist, A. Beguelin, J. Dongarra, W. Jiang, B. Manchek, and V. Sunderam. </author> <title> PVM: Parallel Virtual Machine|A User's Guide and Tutorial for Network Parallel Computing. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: No existing system addresses all of these issues. Various tools support computing in heterogeneous environments [1, 4, 32], but most do not exploit or expose the heterogeneous nature of the network or applications. The p4 [5] and PVM <ref> [20] </ref> communication libraries can use different low-level methods in heterogeneous environments, but the set of methods used is not extensible. The x-kernel [33] and Horus [40] allow new protocols to be constructed by composing primitive elements, but do not support automatic discovery or dynamic reconfiguration of communication methods. <p> Communication links are used in conjunction with asynchronous remote service requests (RSRs) which invoke actions on remote objects. An RSR is specified by providing a startpoint, an RSR handler identifier and a data buffer, which is constructed using PVM <ref> [20] </ref> style put routines. Issuing an RSR causes the data buffer to be transfered from the startpoint to the bound endpoint, after which the routine specified by the handler is executed, potentially in a new thread of control. <p> Some communication libraries permit different communication methods to coexist. For example, the Intel Paragon implementations of p4 and PVM support heterogeneous computing by using the NX communication library for internal communication and TCP for external communication <ref> [5, 20] </ref>; p4 supports NX and TCP within a single process, while PVM uses a proxy process for TCP. In both systems, the choice of method is hard coded and cannot be extended or changed without substantial reengineering.
Reference: [21] <author> W. Gropp and E. Lusk. </author> <title> An abstract device definition to support the implementation of a high-level point-to-point message-passing interface. </title> <type> Preprint MCS-P342-1193, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <year> 1994. </year>
Reference-contexts: MPICH [23] is a portable, high-performance implementation of MPI. It is structured in terms of an abstract device interface (ADI) that defines low-level communication-related functions that can be implemented in different ways on different machines <ref> [21, 22] </ref>. The Nexus implementation of MPI is constructed by providing a Nexus implementation of this device.
Reference: [22] <author> W. Gropp and E. Lusk. </author> <title> MPICH working note: Creating a new MPICH device using the channel interface. </title> <type> Technical Report ANL/MCS-TM-213, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <year> 1995. </year>
Reference-contexts: MPICH [23] is a portable, high-performance implementation of MPI. It is structured in terms of an abstract device interface (ADI) that defines low-level communication-related functions that can be implemented in different ways on different machines <ref> [21, 22] </ref>. The Nexus implementation of MPI is constructed by providing a Nexus implementation of this device.
Reference: [23] <author> W. Gropp, E. Lusk, N. Doss, and A. Skjellum. </author> <title> A high-performance, portable implementation of the MPI message passing interface standard. </title> <type> Technical Report ANL/MCS-TM-213, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <year> 1996. </year>
Reference-contexts: With respect to generality, we note that Nexus has been used to implement a variety of parallel languages and communication libraries [6, 14, 10]. We describe here an implementation of the standard Message Passing Interface (MPI) [24], constructed by adapting the MPICH <ref> [23] </ref> implementation of MPI to use Nexus communication primitives [16]. This implementation allows an MPI program to execute unchanged in heterogeneous environments, with communication method selected according to default rules, depending on the source and destination of the message being sent. <p> The communicator construct combines a group of processes and a unique tag space, and can be used to ensure that communications associated with different parts of a program are not confused. MPICH <ref> [23] </ref> is a portable, high-performance implementation of MPI. It is structured in terms of an abstract device interface (ADI) that defines low-level communication-related functions that can be implemented in different ways on different machines [21, 22]. <p> A typical implementation of the ADI will map some functions directly to low-level mechanisms, and implement others via library calls. The mapping of MPICH functions to ADI mechanisms is achieved via macros and preprocessors, not function calls. Hence, the overhead associated with this organization is often small or nonexistent <ref> [23] </ref>. The ADI provides a fairly high-level abstraction of a communication device: for example, it assumes that the device handles the buffering and queuing of messages. The lower-level channel interface defines simpler functions for moving data from one processor to another. <p> Interestingly, a modest skip poll value provides a significant improvement in MPL performance, while not impacting TCP performance very badly. 5.2 MPI Performance We next report on experiments that evaluate the performance of the Nexus implementation of MPI. We used the MPI mpptest program <ref> [23] </ref>, which incorporates a "ping-pong" benchmark equivalent to pphandle. We executed this program using MPICH and with the Nexus implementation of MPI, in the latter case evaluating NexusLite and Nexus, both with MPL support only, and with MPL and TCP support. Figure 8 shows our results.
Reference: [24] <author> W. Gropp, E. Lusk, and A. Skjellum. </author> <title> Using MPI: Portable Parallel Programming with the Message Passing Interface. </title> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: With respect to generality, we note that Nexus has been used to implement a variety of parallel languages and communication libraries [6, 14, 10]. We describe here an implementation of the standard Message Passing Interface (MPI) <ref> [24] </ref>, constructed by adapting the MPICH [23] implementation of MPI to use Nexus communication primitives [16]. This implementation allows an MPI program to execute unchanged in heterogeneous environments, with communication method selected according to default rules, depending on the source and destination of the message being sent. <p> An alternative approach to multimethod communication is to use two-sided message passing primitives, rather than single-sided remote service requests, and to associate method choices with group constructs such as MPI communicators <ref> [24] </ref>. This is not an unreasonable approach, but is less flexible than communication links and RSRs. We use the three scenarios above to explain why. First, we note that two-sided communication as found in first-generation libraries such as PVM provides, in effect, just a single endpoint per node. <p> The Message Passing Interface defines a standard set of functions for interprocess communication <ref> [24] </ref>. It defines functions for sending messages from one process to another (point-to-point communication), for communication operations that involve groups of processes (collective communication, such as reduction), and for obtaining information about the environment in which a program executes (enquiry functions).
Reference: [25] <author> M. Haines, D. Cronk, and P. Mehrotra. </author> <title> On the design of Chant: A talking threads package. </title> <booktitle> In Proceedings of Supercomputing '94, </booktitle> <pages> pages 350-359, </pages> <year> 1993. </year>
Reference-contexts: The concurrent execution of multiple lightweight threads within a single process is a useful technique for masking variable latencies, exploiting multiprocessors, and providing concurrent access to shared resources. Various approaches to the integration of multithreading into a message-passing framework have been proposed <ref> [2, 12, 18, 37, 39, 13, 25, 42] </ref>. The Nexus implementation of MPI supports a particularly simple and elegant model that does not require that explicit thread identifiers be exported from MPI processes.
Reference: [26] <author> M. Haines, P. Mehrotra, and D. Cronk. Ropes: </author> <title> Support for collective operations among distributed threads. </title> <type> Technical Report 95-36, </type> <institution> Institute for Computer Application in Science and Engineering, </institution> <year> 1995. </year>
Reference-contexts: The multithreaded MPI also has its limitations. In particular, it is not possible to define a collective operation that involves more than one thread per process. This functionality requires extensions to the MPI model <ref> [18, 26, 37] </ref>. 5 Performance Studies We have conducted a variety of experiments to evaluate the performance of both our multi-method communication mechanisms and the Nexus implementation of MPI.
Reference: [27] <editor> IEEE. IEEE P1003.1c/D10: </editor> <title> Draft standard for information technology portable operating systems interface (POSIX), </title> <month> September </month> <year> 1994. </year>
Reference-contexts: For pragmatic reasons, Nexus thread support is based on a 6 shows the startpoint, communication descriptor table, communication object, function table, and communication module. The data structures are explained in the text. subset of the POSIX threads standard <ref> [27] </ref>; it supports thread creation, termination, and synchronization. Nexus also supports the ability to create multiple address spaces, or contexts, within a single node.
Reference: [28] <author> C. Lee, C. Kesselman, and S. Schwab. </author> <title> Near-real-time satellite image processing: Metacomputing in CC++. </title> <journal> Computer Graphics and Applications, </journal> <note> 1996. to appear. </note>
Reference-contexts: 1 Introduction Increasingly, high-performance applications need to exploit heterogeneous collections of computing resources interconnected via high speed networks. Examples of such applications include coupled modules [30, 31], collaborative environments [9, 10] and computations that couple specialized data sources to supercomputers for processing and visualization <ref> [28] </ref>. These applications are heterogeneous not only in in their computational requirements, but also in the types of data that they communicate. One significant consequence of this changing environment is an increase in the number of communication methods that can usefully be employed in networked computations.
Reference: [29] <author> A. Mainwaring. </author> <title> Active Message applications programming interface and communication subsystem organization. </title> <type> Technical report, </type> <institution> Dept. of Computer Science, UC Berkeley, Berkeley, </institution> <address> CA, </address> <year> 1996. </year>
Reference-contexts: Tschudin [38] and the Fox project [3] have explored similar concepts and report similar results. Active Messages (AM) <ref> [29] </ref> and Fast Messages (FM) [34] are communication systems based on asynchronous handler invocation mechanisms similar to those used in Nexus. The latest AM specification introduces an endpoint construct with some similarities to the Nexus endpoint.
Reference: [30] <author> C. Mechoso et al. </author> <title> Distribution of a Coupled-ocean General Circulation Model across high-speed networks. </title> <booktitle> In Proceedings of the 4th International Symposium on Computational Fluid Dynamics, </booktitle> <year> 1991. </year>
Reference-contexts: 1 Introduction Increasingly, high-performance applications need to exploit heterogeneous collections of computing resources interconnected via high speed networks. Examples of such applications include coupled modules <ref> [30, 31] </ref>, collaborative environments [9, 10] and computations that couple specialized data sources to supercomputers for processing and visualization [28]. These applications are heterogeneous not only in in their computational requirements, but also in the types of data that they communicate.
Reference: [31] <author> M. Norman et al. </author> <title> Galaxies collide on the I-WAY: An example of heterogeneous wide-area collaborative supercomputing. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 10(2), </volume> <year> 1996. </year>
Reference-contexts: 1 Introduction Increasingly, high-performance applications need to exploit heterogeneous collections of computing resources interconnected via high speed networks. Examples of such applications include coupled modules <ref> [30, 31] </ref>, collaborative environments [9, 10] and computations that couple specialized data sources to supercomputers for processing and visualization [28]. These applications are heterogeneous not only in in their computational requirements, but also in the types of data that they communicate.
Reference: [32] <author> D. Notkin, A. Black, E. Lazowska, H. Levy, J. Sanislo, and J. Zahorjan. </author> <title> Interconnecting heterogeneous computer systems. </title> <journal> Communications of the ACM, </journal> <volume> 31(3) </volume> <pages> 259-273, </pages> <year> 1988. </year>
Reference-contexts: In addition, mechanisms are required for identifying applicable methods and for incorporating multiple communication methods into an implementation. No existing system addresses all of these issues. Various tools support computing in heterogeneous environments <ref> [1, 4, 32] </ref>, but most do not exploit or expose the heterogeneous nature of the network or applications. The p4 [5] and PVM [20] communication libraries can use different low-level methods in heterogeneous environments, but the set of methods used is not extensible. <p> Nexus/MPL+TCP 1 55.5 55.9 Nexus/MPL+TCP 2 54.4 54.8 Nexus/MPL+TCP 5 53.7 53.7 Nexus/MPL+TCP 20 55.1 53.2 Nexus/MPL+TCP 100 52.5 53.3 Nexus/MPL+TCP 1000 52.3 52.4 Nexus/MPL+TCP 7000 52.8 51.8 Nexus/MPL+TCP 10000 52.8 52.9 20 6 Related Work Many researchers have proposed and investigated communication mechanisms for heterogeneous computing systems (for example, <ref> [1, 4, 32] </ref>). However, this work has typically been concerned with hiding heterogeneity by providing a uniform user-level interface rather than with exploiting and exposing the heterogeneous nature of networks and applications. Some communication libraries permit different communication methods to coexist.
Reference: [33] <author> S. O'Malley and L. Peterson. </author> <title> A dynamic network architecture. </title> <journal> ACM Transactions on Computing Systems, </journal> <volume> 10(2) </volume> <pages> 110-143, </pages> <year> 1992. </year>
Reference-contexts: The p4 [5] and PVM [20] communication libraries can use different low-level methods in heterogeneous environments, but the set of methods used is not extensible. The x-kernel <ref> [33] </ref> and Horus [40] allow new protocols to be constructed by composing primitive elements, but do not support automatic discovery or dynamic reconfiguration of communication methods. <p> In both systems, the choice of method is hard coded and cannot be extended or changed without substantial reengineering. The x-kernel <ref> [33] </ref> and the Horus distributed systems toolkit [40] both support the concurrent use of different communication methods. In Horus, the primary motivation for multimethod communication is to support various group communication mechanisms in a way that allows applications to pay only for the services that they use [41].
Reference: [34] <author> S. Pakin, M. Lauria, and A. Chien. </author> <title> High performance messaging on workstations: Illinois Fast Messages (fm) for Myrinet. </title> <booktitle> In Proceedings of Supercomputing '95. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1996. </year>
Reference-contexts: Tschudin [38] and the Fox project [3] have explored similar concepts and report similar results. Active Messages (AM) [29] and Fast Messages (FM) <ref> [34] </ref> are communication systems based on asynchronous handler invocation mechanisms similar to those used in Nexus. The latest AM specification introduces an endpoint construct with some similarities to the Nexus endpoint. However, the AM endpoint is a more heavyweight structure, incorporating both startpoint and endpoint functionality.
Reference: [35] <author> C. Partridge. </author> <title> Gigabit Networking. </title> <publisher> Addison-Wesley, </publisher> <year> 1994. </year>
Reference-contexts: Future ATM-based networks will support channel-based QoS reservation and negotiation <ref> [35] </ref>. High-performance multimedia applications will likely want to reserve several channels providing different QoS. For example, a multimedia application might use a high-reliability, low-bandwidth channel for control information, and a lower-reliability, high-bandwidth channel for image data. * Interoperability of tools.
Reference: [36] <author> B. Schneier. </author> <title> Applied Cryptography. </title> <publisher> John Wiley and Sons, </publisher> <year> 1993. </year>
Reference-contexts: In heterogeneous environments, an MPI program may need to interoperate with other MPI implementations. In each case, different protocols must be used to communicate with different processes. * Security. Different mechanisms may be used to authenticate or protect the integrity or confidentiality of communicated data <ref> [36] </ref>, depending on where communication is directed and what is communicated. For example, control information might be encrypted outside a site, but not within, while data is not encrypted in either case. * Time-varying properties.
Reference: [37] <author> A. Skjellum, N. Doss, K. Viswanathan, A. Chowdappa, and P. </author> <title> Bangalore. Extending the message passing interface. </title> <booktitle> In Proc. 1994 Scalable Parallel Libraries Conf. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1994. </year>
Reference-contexts: The concurrent execution of multiple lightweight threads within a single process is a useful technique for masking variable latencies, exploiting multiprocessors, and providing concurrent access to shared resources. Various approaches to the integration of multithreading into a message-passing framework have been proposed <ref> [2, 12, 18, 37, 39, 13, 25, 42] </ref>. The Nexus implementation of MPI supports a particularly simple and elegant model that does not require that explicit thread identifiers be exported from MPI processes. <p> The multithreaded MPI also has its limitations. In particular, it is not possible to define a collective operation that involves more than one thread per process. This functionality requires extensions to the MPI model <ref> [18, 26, 37] </ref>. 5 Performance Studies We have conducted a variety of experiments to evaluate the performance of both our multi-method communication mechanisms and the Nexus implementation of MPI.
Reference: [38] <author> C. Tschudin. </author> <title> Flexible protocol stacks. </title> <booktitle> In Proc. ACM SIGCOMM '91. ACM, </booktitle> <year> 1991. </year>
Reference-contexts: These mechanisms could be used within Nexus to simplify the development of new communication modules. Early results with Horus suggest that these compositional formulations simplify implementation, but can introduce overheads similar to those encountered when layering MPICH on Nexus: additional message header information, function calls, and messages. Tschudin <ref> [38] </ref> and the Fox project [3] have explored similar concepts and report similar results. Active Messages (AM) [29] and Fast Messages (FM) [34] are communication systems based on asynchronous handler invocation mechanisms similar to those used in Nexus.
Reference: [39] <author> T. v. Eicken, D. Culler, S. Goldstein, and K. Schauser. </author> <title> Active messages: A mechanism for integrated communication and computation. </title> <booktitle> In Proceedings of the 19th International Symposium on Computer Architecture, </booktitle> <address> Gold Coast, Australia, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: The concurrent execution of multiple lightweight threads within a single process is a useful technique for masking variable latencies, exploiting multiprocessors, and providing concurrent access to shared resources. Various approaches to the integration of multithreading into a message-passing framework have been proposed <ref> [2, 12, 18, 37, 39, 13, 25, 42] </ref>. The Nexus implementation of MPI supports a particularly simple and elegant model that does not require that explicit thread identifiers be exported from MPI processes.
Reference: [40] <author> R. van Renesse, K. Birman, R. Friedman, M. Hayden, and D. Karr. </author> <title> A framework for protocol composition in Horus. </title> <booktitle> In Proc. Principles of Distributed Computing Conf., </booktitle> <year> 1995. </year> <note> http://www.cs.cornell.edu/Info/People/rvr/papers/podc/podc.html. </note>
Reference-contexts: The p4 [5] and PVM [20] communication libraries can use different low-level methods in heterogeneous environments, but the set of methods used is not extensible. The x-kernel [33] and Horus <ref> [40] </ref> allow new protocols to be constructed by composing primitive elements, but do not support automatic discovery or dynamic reconfiguration of communication methods. <p> In both systems, the choice of method is hard coded and cannot be extended or changed without substantial reengineering. The x-kernel [33] and the Horus distributed systems toolkit <ref> [40] </ref> both support the concurrent use of different communication methods. In Horus, the primary motivation for multimethod communication is to support various group communication mechanisms in a way that allows applications to pay only for the services that they use [41].
Reference: [41] <author> R. van Renesse, T. Hickey, and K. Birman. </author> <title> Design and performance of Horus: A lightweight group communications system. </title> <type> Technical Report TR94-1442, </type> <institution> Cornell University, </institution> <year> 1994. </year>
Reference-contexts: The x-kernel [33] and the Horus distributed systems toolkit [40] both support the concurrent use of different communication methods. In Horus, the primary motivation for multimethod communication is to support various group communication mechanisms in a way that allows applications to pay only for the services that they use <ref> [41] </ref>. The choice of method is associated with a group, and typical methods include reliable and unreliable multicast, and ordered and unordered delivery. Horus provides some support for varying the communication method associated with an entire group.
Reference: [42] <author> D. A. Wallach, W. C. Hsieh, K. Johnson, M. F. Kaashoek, and W. E. Weihl. </author> <title> Optimistic active messages: A mechanism for scheduling communication with computation. </title> <type> Technical report, </type> <institution> MIT Laboratory for Computer Science, </institution> <year> 1995. </year> <month> 25 </month>
Reference-contexts: The concurrent execution of multiple lightweight threads within a single process is a useful technique for masking variable latencies, exploiting multiprocessors, and providing concurrent access to shared resources. Various approaches to the integration of multithreading into a message-passing framework have been proposed <ref> [2, 12, 18, 37, 39, 13, 25, 42] </ref>. The Nexus implementation of MPI supports a particularly simple and elegant model that does not require that explicit thread identifiers be exported from MPI processes.
References-found: 42

