URL: http://www.cs.ucsd.edu/~silvia/hcw98_final.ps.Z
Refering-URL: http://www.cs.ucsd.edu/~silvia/
Root-URL: http://www.cs.ucsd.edu
Title: Abstract the execution time of the application to account for the aggregate load. The model
Note: used to adjust  
Abstract: Data-parallel applications executing in multi-user clustered environments share resources with other applications. Since this sharing of resources dramatically affects the performance of individual applications, it is critical to estimate its effect, i.e., the application slowdown, in order to predict application behavior. In this paper, we develop a new approach for predicting the slowdown imposed on data-parallel applications executing on homogeneous and heterogeneous clusters of workstations. Our model synthesizes the slowdown on each machine used by an application into a contention measure the aggregate slowdown factor 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. H. Arpaci, A. C. Dusseau, A. M. Vahdat, L. T. Liu, T. E. Anderson, and D. A. Patterson, </author> <title> The Interaction of Parallel and Sequential Workloads on a Network of Workstations, </title> <booktitle> in Proceedings of SIGMETRICS95/PERFORMANCE95 Joint International Conference on Measurement and Modeling of Computer Systems , pp. </booktitle> <pages> 267-278, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Workstations in such clusters are typically timeshared, causing competing applications to split the CPU and memory capacity on each node. The result of such sharing is that the fraction of resources available for a single distributed parallel application is reduced, causing a slowdown in the overall application performance. In <ref> [1] </ref>, Arpaci et al. have shown that this slowdown can be significant. When slowdown can be predicted accurately, this information can be used to improve scheduling decisions in shared distributed systems [9]. A number of researchers have investigated how slowdown might be calculated and used to improve performance.
Reference: [2] <author> M. Atallah, C. Black, D. Marinescu, H. Siegel, and T. Casa-vant, </author> <title> Models and Algorithms for Coscheduling Compute-Intensive Tasks on a Network of Workstations, </title> <journal> Journal of Parallel and Distributed Computing , vol. </journal> <volume> 16, </volume> <pages> pp. 319-327, </pages> <year> 1992. </year>
Reference-contexts: Slowdown on a single machine has been used for task scheduling (as shown in [3] and [6]) and to predict performance (as shown in [10], [13] and [22]). Co-scheduling algorithms developed for networks of workstations have taken the slowdown on each machine into account, as shown in <ref> [2] </ref> and [7]. Weissman [19] has proposed a scheduling model based on resource contention using an interference paradigm . The interference measure determines how much slower an application will compute or a parallel application will communicate.
Reference: [3] <author> A. Beguelin, J. Dongarra, G. Geist, R. Manchek, and V. Sunderam, </author> <title> Graphical Development Tools for Network-Based Concurrent Supercomputing, </title> <booktitle> in Proceedings of Supercomputing 91 </booktitle>
Reference-contexts: 1. Introduction Clusters of workstations have been used effectively as parallel machines for large, data-parallel, scientific applications <ref> [3, 4, 6, 16] </ref>. Workstations in such clusters are typically timeshared, causing competing applications to split the CPU and memory capacity on each node. <p> A number of researchers have investigated how slowdown might be calculated and used to improve performance. Slowdown on a single machine has been used for task scheduling (as shown in <ref> [3] </ref> and [6]) and to predict performance (as shown in [10], [13] and [22]). Co-scheduling algorithms developed for networks of workstations have taken the slowdown on each machine into account, as shown in [2] and [7]. <p> when all tasks are CPU-bound and have the same priority), the slowdown imposed by contention on each node can be calculated simply as , (8) where is the number of extra processes executing on node Equation (8) - with some slight variations - has been used for slowdown predictions in <ref> [3, 4, 6, 13, 19, 22] </ref>. However, it assumes that the competing applications executing on the nodes of the cluster are well balanced and executing at full speed (without idle intervals). This may not be always the case.
Reference: [4] <author> A. Bricker, M. Litzkow, and M. Livny, </author> <title> Condor Technical Summary, </title> <type> Technical Report #1069, </type> <institution> University of Wiscon sin, Computer Science Department, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: 1. Introduction Clusters of workstations have been used effectively as parallel machines for large, data-parallel, scientific applications <ref> [3, 4, 6, 16] </ref>. Workstations in such clusters are typically timeshared, causing competing applications to split the CPU and memory capacity on each node. <p> when all tasks are CPU-bound and have the same priority), the slowdown imposed by contention on each node can be calculated simply as , (8) where is the number of extra processes executing on node Equation (8) - with some slight variations - has been used for slowdown predictions in <ref> [3, 4, 6, 13, 19, 22] </ref>. However, it assumes that the competing applications executing on the nodes of the cluster are well balanced and executing at full speed (without idle intervals). This may not be always the case.
Reference: [5] <author> W. L. Briggs, </author> <title> A Multigrid Tutorial, </title> <institution> Society for Industrial and Applied Mathematics, </institution> <address> Philadelphia, Pennsylvania, </address> <year> 1987. </year>
Reference-contexts: Experiments The formulas presented in Section 3 provide a model for the aggregate slowdown. To assess the accuracy of this model, we performed a large collection of experiments on a wide range of CPU-bound benchmarks commonly found in high-performance scientific applications. Some examples of the applications used were: Jacobi2D <ref> [5] </ref>, Jacobi3D [5], Red-Black SOR [5], Multigrid [5], Genetic Algorithm [20], and LU Solver [15]. In these experiments, we compared actual execution times with modeled times (dedicated time factored by aggregate slowdown) for applications executing on a cluster of workstations with busy busy CPU-bound synthetic loads. <p> To assess the accuracy of this model, we performed a large collection of experiments on a wide range of CPU-bound benchmarks commonly found in high-performance scientific applications. Some examples of the applications used were: Jacobi2D <ref> [5] </ref>, Jacobi3D [5], Red-Black SOR [5], Multigrid [5], Genetic Algorithm [20], and LU Solver [15]. In these experiments, we compared actual execution times with modeled times (dedicated time factored by aggregate slowdown) for applications executing on a cluster of workstations with busy busy CPU-bound synthetic loads. <p> To assess the accuracy of this model, we performed a large collection of experiments on a wide range of CPU-bound benchmarks commonly found in high-performance scientific applications. Some examples of the applications used were: Jacobi2D <ref> [5] </ref>, Jacobi3D [5], Red-Black SOR [5], Multigrid [5], Genetic Algorithm [20], and LU Solver [15]. In these experiments, we compared actual execution times with modeled times (dedicated time factored by aggregate slowdown) for applications executing on a cluster of workstations with busy busy CPU-bound synthetic loads. <p> To assess the accuracy of this model, we performed a large collection of experiments on a wide range of CPU-bound benchmarks commonly found in high-performance scientific applications. Some examples of the applications used were: Jacobi2D <ref> [5] </ref>, Jacobi3D [5], Red-Black SOR [5], Multigrid [5], Genetic Algorithm [20], and LU Solver [15]. In these experiments, we compared actual execution times with modeled times (dedicated time factored by aggregate slowdown) for applications executing on a cluster of workstations with busy busy CPU-bound synthetic loads. <p> Shown is a distributed SOR application <ref> [5] </ref> developed using PVM [18] and executed on 4 nodes of the DEC Alpha-Farm w it h tw o d iff e r e nt lo a d s. T he p ar a m e te r s f or the experiments are shown in Table 1. <p> and two serial CPU-bound applications executing on another node, as shown in aggregate capacity 1 / 3 + 1 = 2.33, and the SOR algorithm was slowed by a factor of 4 / 2.33 = 1.72. nodes of the DEC Alpha-Farm in dedicated mode and with 2 different loads. application <ref> [5] </ref> (developed using KeLP [11] and MPI [14]) executed for different problem sizes (given by nodes of the DEC Alpha-farm. <p> They present examples of a Jacobi3D algorithm <ref> [5] </ref> (developed using KeLP [11] and MPI [14]) executing for different problem sizes (given by ). The dedicated time was given for a uniform work partitioning. Figure 5 shows modeled and measured times for execution on 4 nodes where other applications are also executing. <p> nodes of the DEC Alpha-Farm in dedicated mode and together with the load described in Table 5. 5.2 Experiments on the Heterogeneous Cluster We now relax the constraints that all the nodes in the cluster are uniform and communication links within the cluster are dedicated to the cluster itself. benchmark <ref> [5] </ref> (developed using PVM [18]) for different p r o b l e m s i z e s ( g i v e n b y N N ) o n t h e 4 node heterogeneous cluster. <p> T h e a gg r e g a t e slowdown is 1.18. with load-dependent work partitioning on a heterogeneous cluster in dedicated mode and under contention. SOR application <ref> [5] </ref> developed using PVM [18] and executed for different problem sizes (given by Table 7: Parameters for the Experiment in Figure 7 Node alpha alpha rs 1 1.00 1 Table 8: Parameters for the Experiment in Figure 8 Node alpha alpha rs 1 1.0 2 500 600 700 800 no contention <p> It presents examples of a Jacobi2D benchmark <ref> [5] </ref> (developed using KeLP [11] and MPI [14]) executing for different problem sizes (given by ). The graph shows modeled and measured times for execution on the 4 nodes.
Reference: [6] <author> H. Dietz, W. Cohen, and B. Grant, </author> <title> Would you run it here...or there? (AHS: Automatic Heterogeneous Supercomputing), </title> <booktitle> in Proceedings of the International Conference on Parallel Processing , vol. II, </booktitle> <pages> pp. 217221, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: 1. Introduction Clusters of workstations have been used effectively as parallel machines for large, data-parallel, scientific applications <ref> [3, 4, 6, 16] </ref>. Workstations in such clusters are typically timeshared, causing competing applications to split the CPU and memory capacity on each node. <p> A number of researchers have investigated how slowdown might be calculated and used to improve performance. Slowdown on a single machine has been used for task scheduling (as shown in [3] and <ref> [6] </ref>) and to predict performance (as shown in [10], [13] and [22]). Co-scheduling algorithms developed for networks of workstations have taken the slowdown on each machine into account, as shown in [2] and [7]. Weissman [19] has proposed a scheduling model based on resource contention using an interference paradigm . <p> when all tasks are CPU-bound and have the same priority), the slowdown imposed by contention on each node can be calculated simply as , (8) where is the number of extra processes executing on node Equation (8) - with some slight variations - has been used for slowdown predictions in <ref> [3, 4, 6, 13, 19, 22] </ref>. However, it assumes that the competing applications executing on the nodes of the cluster are well balanced and executing at full speed (without idle intervals). This may not be always the case.
Reference: [7] <author> X. Du and X. Zhang, </author> <title> Coordinating Parallel Processes on Networks of Workstations, </title> <type> Technical Report, </type> <institution> High Performance Computing and Software Lab, University of Texas at San Antonio, </institution> <month> August </month> <year> 1996. </year>
Reference-contexts: Slowdown on a single machine has been used for task scheduling (as shown in [3] and [6]) and to predict performance (as shown in [10], [13] and [22]). Co-scheduling algorithms developed for networks of workstations have taken the slowdown on each machine into account, as shown in [2] and <ref> [7] </ref>. Weissman [19] has proposed a scheduling model based on resource contention using an interference paradigm . The interference measure determines how much slower an application will compute or a parallel application will communicate. <p> The value for can be calculated as the ratio of the time to execute a task on the slowest node to the time to execute the same task on node (as described in <ref> [7] </ref>). In a homogeneous cluster, . <p> Note that weights are dependent on the benchmark chosen <ref> [7, 9] </ref>.
Reference: [8] <author> A. C. Dusseau, R. H. Arpaci, and D. E. Culler, </author> <title> Effective Distributed Scheduling of Parallel Workloads, </title> <booktitle> in Proceedings of ACM SIGMETRICS96 , pp. </booktitle> <pages> 25-36, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: In our experiments, we assumed that each workstation schedules its processes locally and independently using a round-robin mechanism. Note that priority-based mechanisms, usually employed by workstations operating systems, reduce to round-robin when the competing applications are CPU-bound <ref> [8] </ref>. Finally, we assume that the memory in each node fits the working set of all the applications executing on the node and that no delay is imposed by swapping. The model can be extended to include more varied memory access costs in a straightforward manner. 3.
Reference: [9] <author> S. M. Figueira, </author> <title> Modeling the Effects of Contention on Application Performance in Multi-User Environments, </title> <type> Ph.D. Dissertation, </type> <institution> CSE Department, UCSD, </institution> <month> December </month> <year> 1996. </year>
Reference-contexts: In [1], Arpaci et al. have shown that this slowdown can be significant. When slowdown can be predicted accurately, this information can be used to improve scheduling decisions in shared distributed systems <ref> [9] </ref>. A number of researchers have investigated how slowdown might be calculated and used to improve performance. Slowdown on a single machine has been used for task scheduling (as shown in [3] and [6]) and to predict performance (as shown in [10], [13] and [22]). <p> Note that weights are dependent on the benchmark chosen <ref> [7, 9] </ref>. <p> In this paper, we show representative experiments for each scheduling policy. On all graphs, we show actual times in contentious (multi-user) environment, predicted times using our slowdown model, and dedicated (single-user) actual times for comparison. A more complete list of the experiments can be found in <ref> [9] </ref>. All of our experiments show the modeled execution times to be within 15% of actual execution times. This demonstrates that, for reasonably accurate dedicated time performance estimates, aggregate slowdown captures contention delays in multiuser systems correctly and can provide an accurate model for performance predictions.
Reference: [10] <author> S. M. Figueira and F. Berman, </author> <title> Predicting Slowdown for Networked Workstations, </title> <booktitle> in Proceedings of the Sixth International Symposium on High-Performance Distributed Computing , August 1997. </booktitle>
Reference-contexts: A number of researchers have investigated how slowdown might be calculated and used to improve performance. Slowdown on a single machine has been used for task scheduling (as shown in [3] and [6]) and to predict performance (as shown in <ref> [10] </ref>, [13] and [22]). Co-scheduling algorithms developed for networks of workstations have taken the slowdown on each machine into account, as shown in [2] and [7]. Weissman [19] has proposed a scheduling model based on resource contention using an interference paradigm . <p> Local Slowdown The aggregate slowdown is calculated based on the local slowdown on each workstation of the cluster. The local slowdown on node is the delay imposed on an application running on node as a function of other applications that share s CPU. In <ref> [10] </ref>, we presented a m o d e l to c a l c u la te th e l o c a l s l o w d ow n b a se d o n information (such as the computation/communication ratio) about the applications executing on the system.
Reference: [11] <author> S. J. Fink, S. B. Baden, and S. R. Kohn, </author> <title> Flexible Communication Mechanisms for Dynamic Structured Applications, </title> <booktitle> in Proceedings of the Third International Workshop on Parallel Algorithms for Irregularly Structured Problems Santa Barbara, </booktitle> <address> CA, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: applications executing on another node, as shown in aggregate capacity 1 / 3 + 1 = 2.33, and the SOR algorithm was slowed by a factor of 4 / 2.33 = 1.72. nodes of the DEC Alpha-Farm in dedicated mode and with 2 different loads. application [5] (developed using KeLP <ref> [11] </ref> and MPI [14]) executed for different problem sizes (given by nodes of the DEC Alpha-farm. Two of the nodes (nodes 2 and 3) also host a CPU-bound data-parallel application, and one of the nodes (node 1) also hosts two serial, CPU-bound applications, as shown in Figure 2. <p> They present examples of a Jacobi3D algorithm [5] (developed using KeLP <ref> [11] </ref> and MPI [14]) executing for different problem sizes (given by ). The dedicated time was given for a uniform work partitioning. Figure 5 shows modeled and measured times for execution on 4 nodes where other applications are also executing. <p> It presents examples of a Jacobi2D benchmark [5] (developed using KeLP <ref> [11] </ref> and MPI [14]) executing for different problem sizes (given by ). The graph shows modeled and measured times for execution on the 4 nodes.
Reference: [12] <author> G. Fox, </author> <title> Hardware and Software Architectures for Irregular Problem Architectures, in Unstructured Scientific Computation on Scalable Multiprocessors , P. </title> <editor> Mehrotra, J. Saltz, and R. Voigt, </editor> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <pages> pp. 125 160, </pages> <year> 1992. </year>
Reference-contexts: For this paper, we focus on loosely synchronous CPU-bound applications as defined by Fox <ref> [12] </ref>. These applications are coarse-grained data-parallel scientific applications in which computation and communication phases alternate. Such applications can profit from execution in clustered environments. The c omputa tional e nvir onme nt is a c luster of homogeneous or heterogeneous workstations.
Reference: [13] <author> S. Leutenegger and X. Sun, </author> <title> Distributed Computing Feasibility in a Non-Dedicated Homogeneous Distributed System, </title> <type> NASA - ICASE Technical Report 93-65, </type> <month> September </month> <year> 1993. </year>
Reference-contexts: A number of researchers have investigated how slowdown might be calculated and used to improve performance. Slowdown on a single machine has been used for task scheduling (as shown in [3] and [6]) and to predict performance (as shown in [10], <ref> [13] </ref> and [22]). Co-scheduling algorithms developed for networks of workstations have taken the slowdown on each machine into account, as shown in [2] and [7]. Weissman [19] has proposed a scheduling model based on resource contention using an interference paradigm . <p> when all tasks are CPU-bound and have the same priority), the slowdown imposed by contention on each node can be calculated simply as , (8) where is the number of extra processes executing on node Equation (8) - with some slight variations - has been used for slowdown predictions in <ref> [3, 4, 6, 13, 19, 22] </ref>. However, it assumes that the competing applications executing on the nodes of the cluster are well balanced and executing at full speed (without idle intervals). This may not be always the case.
Reference: [14] <author> Message-Passing Interface Forum, </author> <title> MPI: A Message-Passing Interface Standard, </title> <institution> University of Tennessee, Knox ville, TN, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: another node, as shown in aggregate capacity 1 / 3 + 1 = 2.33, and the SOR algorithm was slowed by a factor of 4 / 2.33 = 1.72. nodes of the DEC Alpha-Farm in dedicated mode and with 2 different loads. application [5] (developed using KeLP [11] and MPI <ref> [14] </ref>) executed for different problem sizes (given by nodes of the DEC Alpha-farm. Two of the nodes (nodes 2 and 3) also host a CPU-bound data-parallel application, and one of the nodes (node 1) also hosts two serial, CPU-bound applications, as shown in Figure 2. <p> They present examples of a Jacobi3D algorithm [5] (developed using KeLP [11] and MPI <ref> [14] </ref>) executing for different problem sizes (given by ). The dedicated time was given for a uniform work partitioning. Figure 5 shows modeled and measured times for execution on 4 nodes where other applications are also executing. <p> It presents examples of a Jacobi2D benchmark [5] (developed using KeLP [11] and MPI <ref> [14] </ref>) executing for different problem sizes (given by ). The graph shows modeled and measured times for execution on the 4 nodes.
Reference: [15] <institution> NAS Parallel Benchmarks, </institution> <address> http://www.nas.nasa.gov/NAS/ NPB. </address>
Reference-contexts: To assess the accuracy of this model, we performed a large collection of experiments on a wide range of CPU-bound benchmarks commonly found in high-performance scientific applications. Some examples of the applications used were: Jacobi2D [5], Jacobi3D [5], Red-Black SOR [5], Multigrid [5], Genetic Algorithm [20], and LU Solver <ref> [15] </ref>. In these experiments, we compared actual execution times with modeled times (dedicated time factored by aggregate slowdown) for applications executing on a cluster of workstations with busy busy CPU-bound synthetic loads. The synthetic loads were formed by a combination of CPU-bound serial and/or data-parallel applications distributed over the cluster.
Reference: [16] <institution> NOW, </institution> <note> http://now.cs.berkeley.edu. </note>
Reference-contexts: 1. Introduction Clusters of workstations have been used effectively as parallel machines for large, data-parallel, scientific applications <ref> [3, 4, 6, 16] </ref>. Workstations in such clusters are typically timeshared, causing competing applications to split the CPU and memory capacity on each node.
Reference: [17] <author> J. Schopf and F. Berman, </author> <title> Performance Prediction in Production Environments, </title> <note> in Proceedings of IPPS/SPDP '98 to appear. </note>
Reference-contexts: Note that in Figure 13, for problem size 4400 one execution of the benchmark with contention was faster than the execution in dedicated mode. This phenomenon is explained by a variation in the execution time in dedicated mode <ref> [17] </ref> caused by traffic in the network, which is nondedicated in the heterogeneous cluster.
Reference: [18] <author> V. Sunderam, </author> <title> PVM: A Framework for Parallel Distributed Computing, </title> <journal> Concurrency: Practice and Experience , vol. </journal> <volume> 2, </volume> <editor> n. </editor> <volume> 4, </volume> <pages> pp. 315339, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Shown is a distributed SOR application [5] developed using PVM <ref> [18] </ref> and executed on 4 nodes of the DEC Alpha-Farm w it h tw o d iff e r e nt lo a d s. T he p ar a m e te r s f or the experiments are shown in Table 1. <p> Alpha-Farm in dedicated mode and together with the load described in Table 5. 5.2 Experiments on the Heterogeneous Cluster We now relax the constraints that all the nodes in the cluster are uniform and communication links within the cluster are dedicated to the cluster itself. benchmark [5] (developed using PVM <ref> [18] </ref>) for different p r o b l e m s i z e s ( g i v e n b y N N ) o n t h e 4 node heterogeneous cluster. The work was divided among the machines according to their capacity and loads. <p> 180 dedicated mode measured modeled t i m d problem size (N) Fig u re 8 r e p re s e nts e x pe r im e nts u si ng a loa d - dependent work partitioning policy with a Genetic Algorithm application [20] developed using PVM <ref> [18] </ref>. <p> T h e a gg r e g a t e slowdown is 1.18. with load-dependent work partitioning on a heterogeneous cluster in dedicated mode and under contention. SOR application [5] developed using PVM <ref> [18] </ref> and executed for different problem sizes (given by Table 7: Parameters for the Experiment in Figure 7 Node alpha alpha rs 1 1.00 1 Table 8: Parameters for the Experiment in Figure 8 Node alpha alpha rs 1 1.0 2 500 600 700 800 no contention modeled measured t i
Reference: [19] <author> J. Weissman, </author> <title> The Interference Paradigm for Network Job Scheduling, </title> <booktitle> in Proceedings of the Heterogeneous Computing Workshop , pp. </booktitle> <pages> 38-45, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: Co-scheduling algorithms developed for networks of workstations have taken the slowdown on each machine into account, as shown in [2] and [7]. Weissman <ref> [19] </ref> has proposed a scheduling model based on resource contention using an interference paradigm . The interference measure determines how much slower an application will compute or a parallel application will communicate. <p> when all tasks are CPU-bound and have the same priority), the slowdown imposed by contention on each node can be calculated simply as , (8) where is the number of extra processes executing on node Equation (8) - with some slight variations - has been used for slowdown predictions in <ref> [3, 4, 6, 13, 19, 22] </ref>. However, it assumes that the competing applications executing on the nodes of the cluster are well balanced and executing at full speed (without idle intervals). This may not be always the case.
Reference: [20] <author> D. Whitley, T. Starkweather, and DUAnn Fuquay, </author> <title> Scheduling Problems and Traveling Salesman: The Genetic Edge Recombination Operator, </title> <booktitle> in Proceedings of International Conference on Genetic Algorithms </booktitle>
Reference-contexts: To assess the accuracy of this model, we performed a large collection of experiments on a wide range of CPU-bound benchmarks commonly found in high-performance scientific applications. Some examples of the applications used were: Jacobi2D [5], Jacobi3D [5], Red-Black SOR [5], Multigrid [5], Genetic Algorithm <ref> [20] </ref>, and LU Solver [15]. In these experiments, we compared actual execution times with modeled times (dedicated time factored by aggregate slowdown) for applications executing on a cluster of workstations with busy busy CPU-bound synthetic loads. <p> (N) 60 100 140 180 dedicated mode measured modeled t i m d problem size (N) Fig u re 8 r e p re s e nts e x pe r im e nts u si ng a loa d - dependent work partitioning policy with a Genetic Algorithm application <ref> [20] </ref> developed using PVM [18].
Reference: [21] <author> R. Wolski, </author> <title> Dynamically Forecasting Network Performance to Support Dynamic Scheduling Using the Network Weather Service, </title> <booktitle> in Proceedings of the 6th High-Performance Distributed Computing Conference , August 1997. </booktitle>
Reference-contexts: Note that is a fraction provided by the operating system. This fraction can also be predicted by tools such as the Network Weather Service <ref> [21] </ref>.

References-found: 21

