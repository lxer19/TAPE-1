URL: http://www.cs.berkeley.edu/~ang/papers/colt-95.ps
Refering-URL: http://www.cs.berkeley.edu/~ang/
Root-URL: http://www.cs.berkeley.edu/~ang/
Title: An Experimental and Theoretical Comparison of Model Selection Methods  
Author: Michael Kearns Yishay Mansour Andrew Y. Ng Dana Ron 
Address: Murray Hill, New Jersey  Tel Aviv, Israel  Pittsburgh, Pennsylvania  Jerusalem, Israel  
Affiliation: AT&T Bell Laboratories  Tel Aviv University  Carnegie Mellon University  Hebrew University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. R. Barron and T. M. </author> <title> Cover. Minimum complexity density estimation. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 37 </volume> <pages> 1034-1054, </pages> <year> 1991. </year>
Reference-contexts: In this model selection problem (which we shall refer to as the intervals model selection problem), the input domain is simply the real line segment <ref> [0; 1] </ref>, and the hypothesis class F d is simply the class of all boolean functions over [0; 1] in which we allow at most d alternations of label; thus F d is the class of all binary step functions with at most d=2 steps. <p> In this model selection problem (which we shall refer to as the intervals model selection problem), the input domain is simply the real line segment <ref> [0; 1] </ref>, and the hypothesis class F d is simply the class of all boolean functions over [0; 1] in which we allow at most d alternations of label; thus F d is the class of all binary step functions with at most d=2 steps. For the experiments, the underlying learning algorithm L that we have implemented performs training error minimization. <p> This is a rare case where efficient minimization is possible; we have developed an algorithm based on dynamic programming that runs in linear time, thus making experiments on large samples feasible. The sample S was generated using the target function in F 100 that divides <ref> [0; 1] </ref> into 100 segments of equal width 1=100 and alternating label. <p> The actual rule given in Equation (1) is slightly more complex than this, and reflects a refined bound on j *(d) *(d)j that varies from d=m for *(d) close to 0 to p d=m otherwise. The next algorithm we consider, the Minimum Description Length Principle (MDL) <ref> [5, 6, 7, 1, 4] </ref> has rather different origins than GRM. <p> Here fl 2 <ref> [0; 1] </ref> is a parameter of the CV algorithm whose tuning we discuss briefly later. <p> The experimental behavior we observe foreshadows a number of important themes that we shall revisit in our formal results. We begin with Figure 2. To obtain this figure, a training sample was generated from the uniform input distribution and labeled according to an intervals function over <ref> [0; 1] </ref> consisting of 100 intervals of alternating label and equal width 5 ; the sample was corrupted with noise at rate j = 0:2. <p> Let G : <ref> [0; 1] </ref> fi &lt; ! &lt; be a function that is continuous and increasing in both its arguments, and let * G (m) denote the expected generalization error of the penalty-based model selection algorithm d = argmin d fG ( *(d); d=m)g on a training sample of size m. <p> Furthermore, if * opt (d) + d=m approximates *(d) well, then such a bound is about the best we could hope for. However, there is no reason in general to expect this to be the case. Bounds of this type were first given by Barron and Cover <ref> [1] </ref> in the context of density estimation.
Reference: [2] <author> T. Cover and J. Thomas. </author> <title> Elements of Information Theory. </title> <publisher> Wiley, </publisher> <year> 1991. </year>
Reference: [3] <author> D. Haussler, M. Kearns, H.S. Seung, and N. Tishby. </author> <title> Rigourous learning curve bounds from statistical mechanics. </title> <booktitle> In Proceedings of the Seventh Annual ACM Confernce on Computational Learning Theory, </booktitle> <pages> pages 76-87, </pages> <year> 1994. </year>
Reference-contexts: First, and perhaps most importantly, * M ((1fl)m) may be considerably larger than * M (m). This could either be due to properties of the underlying learning algorithm L, or due to inherent phase transitions (sudden decreases) in the optimal information-theoretic learning curve <ref> [8, 3] </ref> thus, in an extreme case, it could be that the generalization error that can be achieved within some class F d by training on m examples is close to 0, but that the optimal generalization error that can be achieved in F d by training on a slightly smaller <p> We believe that giving similarly general bounds for any penalty-based algorithm would be extremely difficult, if not impossible. The reason for this belief arises from the diversity of learning curve behavior documented by the statistical mechanics approach <ref> [8, 3] </ref>, among other sources.
Reference: [4] <author> J. R. Quinlan and R. L. Rivest. </author> <title> Inferring decision trees using the minimum description length principle. </title> <journal> Information and Computation, </journal> <volume> 80(3) </volume> <pages> 227-248, </pages> <year> 1989. </year>
Reference-contexts: The actual rule given in Equation (1) is slightly more complex than this, and reflects a refined bound on j *(d) *(d)j that varies from d=m for *(d) close to 0 to p d=m otherwise. The next algorithm we consider, the Minimum Description Length Principle (MDL) <ref> [5, 6, 7, 1, 4] </ref> has rather different origins than GRM.
Reference: [5] <author> J. Rissanen. </author> <title> Modeling by shortest data description. </title> <journal> Automat-ica, </journal> <volume> 14 </volume> <pages> 465-471, </pages> <year> 1978. </year>
Reference-contexts: The actual rule given in Equation (1) is slightly more complex than this, and reflects a refined bound on j *(d) *(d)j that varies from d=m for *(d) close to 0 to p d=m otherwise. The next algorithm we consider, the Minimum Description Length Principle (MDL) <ref> [5, 6, 7, 1, 4] </ref> has rather different origins than GRM.
Reference: [6] <author> J. Rissanen. </author> <title> Stochastic complexity and modeling. </title> <journal> Annals of Statistics, </journal> <volume> 14(3) </volume> <pages> 1080-1100, </pages> <year> 1986. </year>
Reference-contexts: The actual rule given in Equation (1) is slightly more complex than this, and reflects a refined bound on j *(d) *(d)j that varies from d=m for *(d) close to 0 to p d=m otherwise. The next algorithm we consider, the Minimum Description Length Principle (MDL) <ref> [5, 6, 7, 1, 4] </ref> has rather different origins than GRM.
Reference: [7] <author> J. Rissanen. </author> <title> Stochastic Complexity in Statistical Inquiry, </title> <booktitle> volume 15 of Series in Computer Science. World Scientific, </booktitle> <year> 1989. </year>
Reference-contexts: In Section 3, we introduce the three model selection algorithms we examine in the experiments: Vapnik's Guaranteed Risk Minimization (GRM) [11], an instantiation of Rissanen's Minimum Description Length Principle (MDL) <ref> [7] </ref>, and Cross Validation (CV). Section 4 describes our controlled experimental comparison of the three algorithms. <p> The actual rule given in Equation (1) is slightly more complex than this, and reflects a refined bound on j *(d) *(d)j that varies from d=m for *(d) close to 0 to p d=m otherwise. The next algorithm we consider, the Minimum Description Length Principle (MDL) <ref> [5, 6, 7, 1, 4] </ref> has rather different origins than GRM.
Reference: [8] <author> H. S. Seung, H. Sompolinsky, and N. Tishby. </author> <title> Statistical mechanics of learning from examples. </title> <journal> Physical Review, </journal> <volume> A45:6056-6091, </volume> <year> 1992. </year>
Reference-contexts: First, and perhaps most importantly, * M ((1fl)m) may be considerably larger than * M (m). This could either be due to properties of the underlying learning algorithm L, or due to inherent phase transitions (sudden decreases) in the optimal information-theoretic learning curve <ref> [8, 3] </ref> thus, in an extreme case, it could be that the generalization error that can be achieved within some class F d by training on m examples is close to 0, but that the optimal generalization error that can be achieved in F d by training on a slightly smaller <p> We believe that giving similarly general bounds for any penalty-based algorithm would be extremely difficult, if not impossible. The reason for this belief arises from the diversity of learning curve behavior documented by the statistical mechanics approach <ref> [8, 3] </ref>, among other sources.
Reference: [9] <author> M. Stone. </author> <title> Cross-validatory choice and assessment of statistical predictions. </title> <journal> Journal of the Royal Statistical Society B, </journal> <volume> 36 </volume> <pages> 111-147, </pages> <year> 1974. </year>
Reference-contexts: The third model selection algorithm that we examine has a different spirit than the penalty-based algorithms. In cross validation (CV) <ref> [9, 10] </ref>, we use only a fraction (1 fl) of the examples in S to obtain the hypothesis sequence h 1 2 F 1 ; : : : ; h d 2 F d ; : : : that is, h d is now L (S 0 ; d), where S
Reference: [10] <author> M. Stone. </author> <title> Asymptotics for and against cross-validation. </title> <journal> Biometrika, </journal> <volume> 64(1) </volume> <pages> 29-35, </pages> <year> 1977. </year>
Reference-contexts: The third model selection algorithm that we examine has a different spirit than the penalty-based algorithms. In cross validation (CV) <ref> [9, 10] </ref>, we use only a fraction (1 fl) of the examples in S to obtain the hypothesis sequence h 1 2 F 1 ; : : : ; h d 2 F d ; : : : that is, h d is now L (S 0 ; d), where S
Reference: [11] <author> V. N. Vapnik. </author> <title> Estimation of Dependences Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: We also introduce the specific model selection problem that will be the basis for our experimental results, and describe an initial experiment demonstrating that the problem is nontrivial. In Section 3, we introduce the three model selection algorithms we examine in the experiments: Vapnik's Guaranteed Risk Minimization (GRM) <ref> [11] </ref>, an instantiation of Rissanen's Minimum Description Length Principle (MDL) [7], and Cross Validation (CV). Section 4 describes our controlled experimental comparison of the three algorithms. <p> In Vapnik's Guaranteed Risk Minimization (GRM) <ref> [11] </ref>, d is chosen according to the rule 1 d = argmin d f *(d) + (d=m)(1 + p where for convenience but without loss of generality we have assumed that d is the Vapnik-Chervonenkis dimension [11, 12] of the class F d ; this assumption holds in the intervals model <p> In Vapnik's Guaranteed Risk Minimization (GRM) [11], d is chosen according to the rule 1 d = argmin d f *(d) + (d=m)(1 + p where for convenience but without loss of generality we have assumed that d is the Vapnik-Chervonenkis dimension <ref> [11, 12] </ref> of the class F d ; this assumption holds in the intervals model selection problem. <p> The origin of this rule can be summarized as follows: it has been shown <ref> [11] </ref> (ignoring logarithmic factors) that for every d and for every h 2 F d , p d=m is an upper bound on j *(h) *(h)j and hence j *(d) *(d)j d=m.

References-found: 11

