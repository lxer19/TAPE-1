URL: http://www.cs.unc.edu/Research/stc/pubs/future_office.ps.gz
Refering-URL: http://www.cs.unc.edu/Research/stc/pubs/index.html
Root-URL: http://www.cs.unc.edu
Title: The Office of the Future: A Unified Approach to Image-Based Modeling and Spatially Immersive Displays
Author: Ramesh Raskar, Greg Welch, Matt Cutts, Adam Lake, Lev Stesin, and Henry Fuchs ea l i t I . [I m a g e P ro c e ss i n g a n d Co m p u te r Vi s r en d e r i ng r a ng e d ep t h re e c ta n c e p r o j e ct i o n v i r t u al 
Keyword: imperceptible structured light I.3.3 [Computer Graphics]: Picture/Image GenerationDigitizing and scanning; Display algorithms; Viewing algorithms; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and RealismVirtual  Digitization and Image CaptureImaging geometry; Reectance; Sampling; Scanning; I.4.8 [Image Processing and Computer Vision]: Scene AnalysisColor; Range data; Shading; Shape; Surface fitting; Time-varying imagery; Tracking; I.4.9 [Image Processing and Computer Vision]: Applications; B.4.2 [Input/ Output and Data Communications] Input/Output DevicesImage display Additional Key Words and Phrases  
Affiliation: University of North Carolina at Chapel Hill and the NSF Science and Technology Center for Computer Graphics and Scientific Visualization  
Date: 1998  
Note: 1 SIGGRAPH 98, Orlando, Florida, July 19-24, 1998 C OMPUTER RAPHICS Proceedings, Annual Conference Series,  an office of the future  r  i on  display, spatially immersive  environments, calibration, autocalibration.  
Abstract: We introduce ideas, proposed technologies, and initial results for To accomplish the simultaneous capture and display we envision an office of the future where the ceiling lights are replaced by computer controlled cameras and smart projectors that are used to capture dynamic image-based models with techniques, and to display high-resolution images on designated display surfaces. By doing both simultaneously on the designated display surfaces, one can dynamically adjust or autocalibrate for geometric, intensity, and resolution variations resulting from irregular or changing display surfaces, or overlapped projector images. Our current approach to dynamic image-based modeling is to use an optimized structured light scheme that can capture per-pixel d e p t h a n d r e e c t a n c e a t i n t e r a c t iv e r a t e s . O u r s y s t e m implementation is not yet imperceptible, but we can demonstrate the approach in the laboratory. Our approach to rendering on the designated (potentially irregular) display surfaces is to employ a two-pass projective texture scheme to generate images that when projected onto the surfaces appear correct to a moving head-tracked observer. We present here an initial implementation of the overal l v isio n, i n a n office- like se ttin g, an d preli mina ry demonstrations of our dynamic modeling and display techniques. CR Categories and Subject Descriptors 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bajaj, C.L., F. Bernardini, and G. Xu. </author> <title> Automatic reconstruction of surfaces and scalar fields from 3D scans, </title> <booktitle> SIGGRAPH 95 Conference Proceedings, Annual Conference Series, ACM SIGGRAPH, </booktitle> <publisher> Addison-Wesley, </publisher> <pages> pp. 109-118, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: The simplification method must be careful not to simplify in regions of rapid change or high curvature where information might be lost. The automatic reconstruction of surfaces from range data is explored in <ref> [13, 1, 8, 11, 17, 22] </ref>. Unfortunately, the dynamic nature and the presence of noise in our system, disallow the use of well-established simplification algorithms.
Reference: [2] <author> Bennett, David T. </author> <title> Chairman and Co-Founder of Alternate Realities Corporation. Internet: </title> <address> http://www.virtual-reality.com. 215 Southport Drive Suite 1300 Morrisville, NC 27560. </address>
Reference-contexts: SIDs are typically roomsized, thus accommodating multiple viewers, and are usually implemented with multiple fixed front or rear-projection display units. Probably the most well-known examples of general-purpose SIDs are the Cave Automated Virtual Environment (CAVE) [12], the related tiled-display PowerWall and Infinity Wall systems, and Alternate Realities VisionDome <ref> [2] </ref>. There are several good examples of telecollaboration applications where the users see and interact with their remote collaborators using a CAVE or CAVE-like system, for example [34]. <p> The attempts at creating a seamless display are discussed in the previously cited ight simulator papers. Domed displays are another example <ref> [2] </ref>. Such systems are often limited to only one high resolution projector and have rarely employed a mechanism to capture depth or projection surface information from the scene.
Reference: [3] <author> Bowen, Loftin, R. </author> <title> Hands Across the Atlantic, </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 17, No. 2, </volume> <pages> pp. 78-79, </pages> <month> March-April </month> <year> 1997. </year>
Reference: [4] <author> Bryson, Steve, David Zeltzer, Mark T. Bolas, Bertrand de La Chapelle, and David Bennett. </author> <title> The Future of Virtual Reality: Head Mounted Displays Versus Spatially Immersive Displays, </title> <booktitle> SIGGRAPH 97 Conference Proceedings, Annual Conference Series, ACM SIGGRAPH, </booktitle> <publisher> Addison-Wesley, </publisher> <pages> pp. 485-486, </pages> <month> August </month> <year> 1997. </year>
Reference-contexts: A more attractive alternative is to get the display off of the users head, and to instead use a spatially immersive display A SID is a display that physically surrounds the viewer with a panorama of imagery <ref> [4] </ref>. SIDs are typically roomsized, thus accommodating multiple viewers, and are usually implemented with multiple fixed front or rear-projection display units. Probably the most well-known examples of general-purpose SIDs are the Cave Automated Virtual Environment (CAVE) [12], the related tiled-display PowerWall and Infinity Wall systems, and Alternate Realities VisionDome [2].
Reference: [5] <author> Buxton, W. </author> <year> 1992. </year> <title> Telepresence: integrating shared task and person spaces, </title> <booktitle> Proceedings of Graphics Interface '92, </booktitle> <pages> 123-129. </pages> <note> Earlier version appears in Proceedings of Groupware '91, </note> <institution> Amsterdam, </institution> <month> Oct. 29, </month> <year> 1991, </year> <month> 27-36.. </month>
Reference-contexts: Telecollaboration Interfaces While telecollaboration systems using 2D talking heads and shared white boards have improved significantly over the years, we believe that the through-the-window paradigm itself often inhibits much of the interaction that would otherwise take place if the collaborators were actually together in the same room. In <ref> [5] </ref> Buxton identifies several tasks for which commercial televideo systems provide only limited support.
Reference: [6] <author> Capin, Tolga K., Hansrudi Noser, Daniel Thalmann, Igor Sunday Pandzic and Nadia Magnenat Thalman. </author> <title> Virtual Human Representation and Communication in VLNet, </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 17, No. 2, </volume> <pages> pp. 42-53, </pages> <month> March-April </month> <year> 1997. </year>
Reference: [7] <author> Chi, Vern, Matt Cutts, Henry Fuchs, Kurtis Keller, Greg Welch, Mark Bloomenthal, Elaine Cohen, Sam Drake, Russ Fish, Rich Riesenfeld. </author> <year> 1998. </year> <title> A Wide Field-of-View Camera Cluster, </title> <institution> University of North Carolina at Chapel Hill, Dept of Computer Science, </institution> <note> Technical Report TR98-018. </note>
Reference-contexts: We plan to integrate scene acquisition and display in such a way that the acquisition is imperceptible, or at least unobtrusive. This will involve some combination of light control and cameras, possibly wide-field-of-view high-resolution clusters as described in <ref> [7] </ref>.
Reference: [8] <author> Chien, C.H., Y.B. Sim, and J.K. Aggarwal. </author> <title> Generation of volume/surface octree from range data, </title> <booktitle> In The Computer Graphics Society Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 254-260, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: The simplification method must be careful not to simplify in regions of rapid change or high curvature where information might be lost. The automatic reconstruction of surfaces from range data is explored in <ref> [13, 1, 8, 11, 17, 22] </ref>. Unfortunately, the dynamic nature and the presence of noise in our system, disallow the use of well-established simplification algorithms.
Reference: [9] <author> Clodfelter, Robert M. </author> <title> Predicting Display System Performance, </title> <booktitle> Presented at the 1996 IMAGE Conference, </booktitle> <address> Scottsdale, AZ, </address> <pages> pp. 1-5, </pages> <month> June 23-28, </month> <year> 1996. </year>
Reference-contexts: The CAVE does not deal with intensity blending and has no method of capturing the geometry of the environment, which is reasonable since this was not an intended goal of their system. The military simulation/ight simulator industry is full of numerous examples of spatially immersive displays <ref> [9, 23, 29, 32, 35] </ref>. These systems typical use CRT projectors which need frequent calibration. Also, they usually (but not always) restrict themselves to matching the seams of the display instead of considering the whole display area as something that needs to be blended seamlessly.
Reference: [10] <author> Conner, D.B, Cutts, M., Fish, R., Fuchs, H., Holden, L., Jacobs, M., Loss, B., Markosian, L., Riesenfeld, R., and Turk, G. </author> <title> An Immersive Tool for Wide-Area Collaborative Design, TeamCAD, the First Graphics Visualization, and Usability (GVU) Workshop on Collaborative Design. </title> <address> Atlanta, Georgia, </address> <month> May 12-13, </month> <year> 1997. </year>
Reference: [11] <author> Connolly, C.I. </author> <title> Cumulative generation of octree models from range data, </title> <booktitle> Proceedings, Intl. Conference Robotics, </booktitle> <pages> pp. 25-32, </pages> <month> March </month> <year> 1984. </year>
Reference-contexts: The simplification method must be careful not to simplify in regions of rapid change or high curvature where information might be lost. The automatic reconstruction of surfaces from range data is explored in <ref> [13, 1, 8, 11, 17, 22] </ref>. Unfortunately, the dynamic nature and the presence of noise in our system, disallow the use of well-established simplification algorithms.
Reference: [12] <author> Cruz-Neira, Carolina, Daniel J. Sandin, and Thomas A. DeFanti. </author> <title> Surround-Screen Projection-Based Virtual Reality: </title> <booktitle> The Design and Implementation of the CAVE, Computer Graphics, SIGGRAPH Annual Conference Proceedings, </booktitle> <year> 1993. </year> <title> The Office of the Future: A Unified Approach to Image-Based Modeling and Spatially Immersive Displays 10 SIGGRAPH 98, </title> <address> Orlando, Florida, </address> <month> July 19-24, </month> <booktitle> 1998 C OMPUTER RAPHICS Proceedings, Annual Conference Series, </booktitle> <year> 1998 </year>
Reference-contexts: SIDs are typically roomsized, thus accommodating multiple viewers, and are usually implemented with multiple fixed front or rear-projection display units. Probably the most well-known examples of general-purpose SIDs are the Cave Automated Virtual Environment (CAVE) <ref> [12] </ref>, the related tiled-display PowerWall and Infinity Wall systems, and Alternate Realities VisionDome [2]. There are several good examples of telecollaboration applications where the users see and interact with their remote collaborators using a CAVE or CAVE-like system, for example [34]. <p> o m o de l t h e p r oj ec to r op t ic s a n d demonstrates an extended radiosity method to simulate directional lighting characteristics. 2.3 Spatially Immersive Displays The most well known spatially immersive display in the graphics community is probably the CAVE <ref> [12] </ref>. The CAVE exists in many forms, typically it is configured as a left, right, and rear wall rear projection system. In some implementations they use a mirror above the CAVE that projects an image onto the oor.
Reference: [13] <author> Curless, Brian, and Marc Levoy. </author> <title> A Volumetric Method for Building Complex Models from Range Images, </title> <booktitle> SIGGRAPH 96 Conference Proceedings, Annual Conference Series, ACM SIGGRAPH, </booktitle> <publisher> Addison-Wesley. </publisher> <pages> pp. 303-312, </pages> <year> 1996. </year>
Reference-contexts: The simplification method must be careful not to simplify in regions of rapid change or high curvature where information might be lost. The automatic reconstruction of surfaces from range data is explored in <ref> [13, 1, 8, 11, 17, 22] </ref>. Unfortunately, the dynamic nature and the presence of noise in our system, disallow the use of well-established simplification algorithms.
Reference: [14] <author> DePiero, F.W., and Trivedi, </author> <title> M.M., 3-D Computer Vision using Structured Light: Design, Calibration, </title> <booktitle> and Implementation Issues, Advances in Computers(43), 1996, </booktitle> <publisher> Academic Press, pp.243-278 </publisher>
Reference-contexts: This prevents the use of lasers or other invasive methods. Our system currently uses one video camera and one projector in a pair, although multiple cameras could work with one projector [43]. The correspondence problem is solved by projecting binary coded vertical bars <ref> [14] </ref>. The camera looks at a set of n successive images, creates binary images using adaptive thresholding on a per-pixel basis, and generates an bit code for every pixel corresponding to the code for the vertical bar that was imaged at this pixel.
Reference: [15] <author> Dias, Jos Miguel Salles, Ricardo Galli, Antnio Carlos Almeida, Carlos A. C. Belo, and Jos Manuel Rebord. </author> <month> mWorld: </month>
References-found: 15

