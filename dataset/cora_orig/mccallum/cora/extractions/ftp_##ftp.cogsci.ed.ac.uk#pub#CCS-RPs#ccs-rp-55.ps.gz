URL: ftp://ftp.cogsci.ed.ac.uk/pub/CCS-RPs/ccs-rp-55.ps.gz
Refering-URL: ftp://ftp.cogsci.ed.ac.uk/pub/CCS-RPs/CCS-RPs.html
Root-URL: 
Email: email: asch@cogsci.ed.ac.uk  
Title: Compiling Feature Structures into Terms: an Empirical Study in Prolog  
Author: Andreas Schoter 
Date: January 1993  
Address: 2 Buccleuch Place Edinburgh eh8 9lw  
Affiliation: University of Edinburgh Centre for Cognitive Science  
Abstract: This paper explores the issue of feature structure representation and its effect on the efficiency of parsing within the context of prolog: it compares four different representation systems whilst holding the parsing strategy fixed. The representations are: i) interpreted patr equations; ii) partially evaluated patr feature structures; iii) feature structures compiled to lists; and iv) feature structures compiled to flat terms. The parser uses a simple shift-reduce strategy with a grammar based loosely on Generalized Phrase Structure Grammar (gpsg). I begin by considering why partial information is important in computational linguistics and compare directed acyclic graphs (dags) and fixed arity terms as representations for partial information. I present details of the basic compiler and then go on to consider the four representations in detail. I assume a familiarity with prolog notation and with the basic notions of feature structure representation. An emergent property of the compilation process, namely automatic type generation for category structures, is discussed: these types are implemented so as to ensure that unification of the compiled representations automatically respects them. The use of additional user specified information to guide the compiler is also discussed. This involves axioms for explicit type checking during compilation and a notion of designated features. fl Thanks to Holly Branigan, Paul Cairns, Michael Clegg, and Sam Ibrahim with whom I developed the original system on which these techniques have been tested; to Carl Vogel, who read and commented extensively upon an early draft; to the participants at the 5th Annual Cognitive Science Conference (Part 1) at the Centre for Cognitive Science, Edinburgh, where this paper was first presented, for valuable feedback; and to the anonymous reviewers of the first submission. This research was done whilst studying for an MSc at the Centre for Cognitive Science, Edinburgh, on ESRC award number K00429113301. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. At-Kaci and R. Nasr. </author> <title> LOGIN: A logic programming language with built-in inheritance. </title> <journal> Journal of Logic Programming, </journal> <volume> 3 </volume> <pages> 185-215, </pages> <year> 1986. </year>
Reference-contexts: At-Kaci and Nasr <ref> [1] </ref> present an algorithm for dag unification that is nearly linear in complexity. However, this requires that the dags be represented in a special way: namely as balanced, shallow trees. <p> The remaining arguments define the syntactic structure which the rule licenses: the first of these is the mother category of the rule, and the remaining arguments are the daughters. Thus, in gpsg notation, Figure 2 represents the basic cfg rule V 1 ! H <ref> [1] </ref>; N 2 . In all incarnations of the grammar the structure of the heads of the rules remain the same, and the only difference lies in the nature of the equations that appear in the body.
Reference: [2] <author> M.A. Covington. GULP 2.0: </author> <title> An extension of prolog for unification-based grammar. </title> <type> Technical Report AI-1989-01, </type> <institution> Advanced Computaional Methods Center, University of Georgia, </institution> <year> 1989. </year>
Reference-contexts: This must be distinguished from the prolog representation of dags which have tail variables in the lists, contain partial information, allow extension, and require special unification; Hirsh's lists have no tail variables, are complete, and can be term unified. Covington <ref> [2] </ref> presents an extension to prolog that he calls gulp (Graph Unification Logic Programming). <p> The requirements of the base system are harder to estimate because of the use of category macros. Although I have not considered Covington's gulp system <ref> [2] </ref> in the empirical comparisons, it is interesting to consider its representation scheme from a theoretical perspective. Essentially gulp converts a feature structure notation (broadly equivalent to the the patr dag representation used here) into a flat list structure. <p> In this case the compiled representation will always contain a large number of unusable uninstantiated or nil slots. If these slots come to dominate the compiled representation then it could become the case that the dag-based systems turned out to be more efficient than the term based systems. Covington <ref> [2] </ref> suggests that it might be possible to extend the gulp system to solve this problem by specifying explicit types for certain categories and having the compiler generate different term representations for each type.
Reference: [3] <author> G. Gazdar, E. Klein, G. Pullum, and I. Sag. </author> <title> Generalized Phrase Structure Grammar. </title> <publisher> Harvard University Press, </publisher> <year> 1985. </year>
Reference-contexts: The compiler system has been tested on the syntactic portion of the grammar, ignoring the semantic representations. The grammar is based on the ideas of Generalized Phrase Structure Grammar (see <ref> [3] </ref>) modified by the more general structural considerations of unification-based formalisms (e.g. [14]). <p> For example, the head feature convention <ref> [3, p.50] </ref>, which requires that all the head features on the mother are identical to the head features on the head daughter is realized by explicitly including a unification in each rule (see Figure 2). <p> It is interesting to note that precisely this distinction is made by Gazdar et al in the gpsg category system (see <ref> [3, pp.24-25] </ref>). <p> Further examples abound: in Section 4.2.1 it was pointed out that a nominal category cannot ever have a value for the feature vform and that verb categories cannot take values for case. In gpsg these kinds of type restriction are encoded by axioms called Feature Co-occurrence Restrictions (fcr) <ref> [3, pp.27-29] </ref>. Shieber [15] discusses reconstructing gpsg in patr but does not tackle this problem in any detail. <p> Then, if there is no slash in a given category just that single argument is nil, and if it does 13 This differs from the usual gpsg analysis, where slash is a complex F type feature within the main category body (see <ref> [3, Chp.7] </ref>). This change is made for computational reasons brought out by example (27). 32 have a slash specification then the argument will be a dagX/N term containing the feature information for the gap. <p> S:body:head === VP:body:head, S:body:subj === '+', 40 S:slash === VP:slash. % a topicalized sentence rule: S --&gt; XP, S/XP example (2,[S0,XP,S1]):- XP:body:bar === 2, S1:slash === XP:body, S1:body:head:cat:n === '-', S1:body:head:cat:v === '+', S1:body:subj === '+', S0:slash === [], S0:body:head === S1:body:head. % a ditransitive VP rule: VP --&gt; V <ref> [3] </ref>, NP, PP [to] example (3,[VP,V,NP,PP]):- VP:body:head === V:body:head, VP:body:bar === 2, V:body:subcat === 3, V:body:bar === 0, V:body:head:cat:n === '-', V:body:head:cat:v === '+', V:body:subj === '-', NP:body:head:cat:n === '+', NP:body:head:cat:v === '-', NP:body:head:case === acc, NP:body:bar === 2, PP:body:head:cat:n === '-', PP:body:head:cat:v === '-', PP:body:head:pform === to, PP:body:bar === 2.
Reference: [4] <author> G. Gazdar and C. Mellish. </author> <title> Natural Language Processing in prolog An Introduction to Computational Linguistics. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1989. </year>
Reference-contexts: As trees are simplified dags (dags without path equivalence) this should provide no problems. The following conventions are extended from the presentation of patr notation in Gazdar and Mellish <ref> [4, p.241] </ref>: (1) a. DAG1 === DAG2 b. DAG1:Path1 === DAG2:Path2 c. DAG:Path &lt;== Val Example (1a) signifies that DAG1 and DAG2 are graph unified (term unification will be expressed with prolog's usual =/2 operator). <p> These differences are crucial, both for the human writer of grammars and for any machine implementation of a parser. Gazdar and Mellish <ref> [4, p.273] </ref> spell this out. Firstly consider the human: working with terms one must know the arity of term at the outset and information must be specified by more or less instantiated versions of this maximal term (compare (2b) and (3b)). <p> The question this paper seeks to address is whether and when the best of both worlds can be had. 1.4 Previous Work Gazdar and Mellish <ref> [4, p.276] </ref> state that the process of compiling dag based grammars into term based grammars can be automated but provide no details; Mellish [9, pp.208-212] describes a translation process from dags to terms used to improve the efficiency of a natural language generation system, stating that the data needed by the
Reference: [5] <author> G. Gazdar, G.K. Pullum, R. Carpenter, E. Klein, T.E. Hukari, and R.D. Levine. </author> <title> Category structures. </title> <journal> Computational Linguistics, </journal> <volume> 14(1) </volume> <pages> 1-19, </pages> <year> 1988. </year>
Reference-contexts: Shieber [14]). For example, when parsing a 1 Gazdar et al <ref> [5] </ref> show that the category structures used in a wide range of linguistic theories, including gpsg, can be modelled using only trees.
Reference: [6] <author> S.B. Hirsh. P-PATR: </author> <title> A compiler for unification-based grammars. </title> <type> Master's thesis, </type> <institution> Department of Linguistics, Stanford University, </institution> <year> 1986. </year>
Reference-contexts: Hirsh <ref> [6, 7] </ref> presents the details of a system that takes the patr specification of a grammar and generates an equivalent prolog dcg that is then parsed using a left-corner parser.
Reference: [7] <author> S.B. Hirsh. P-PATR: </author> <title> A compiler for unification-based grammars. </title> <editor> In V. Dahl and P. Saint-Dizier, editors, </editor> <booktitle> Natural Language Understanding and Logic Programming, II, </booktitle> <pages> pages 63-78. </pages> <publisher> Elsevier Science Publishers BV (North-Holland), </publisher> <year> 1988. </year>
Reference-contexts: Hirsh <ref> [6, 7] </ref> presents the details of a system that takes the patr specification of a grammar and generates an equivalent prolog dcg that is then parsed using a left-corner parser.
Reference: [8] <author> M. Kay. </author> <title> Unification in grammar. </title> <editor> In V. Dahl and P. Saint-Dizier, editors, </editor> <booktitle> Natural Language Understanding and Logic Programming, </booktitle> <pages> pages 233-240. </pages> <publisher> Elsevier Science Publishers BV (North-Holland), </publisher> <year> 1985. </year>
Reference-contexts: In contrast, when using dags unimportant features may be omited altogether and features at the same level of nesting may be arbitrarily ordered within a structure. Kay <ref> [8, p.235] </ref> highlights these differences by noting that terms have a principle functor and a fixed arity, whilst a dag has arbitrarily many functors (its labels) of equal status.
Reference: [9] <author> C.S. Mellish. </author> <title> Generating natural language explanations from plans. </title> <editor> In L. Sterling, editor, </editor> <booktitle> The Practice of Prolog, </booktitle> <pages> pages 181-223. </pages> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The question this paper seeks to address is whether and when the best of both worlds can be had. 1.4 Previous Work Gazdar and Mellish [4, p.276] state that the process of compiling dag based grammars into term based grammars can be automated but provide no details; Mellish <ref> [9, pp.208-212] </ref> describes a translation process from dags to terms used to improve the efficiency of a natural language generation system, stating that the data needed by the translation mechanism can be automatically generated.
Reference: [10] <author> R.A. O'Keefe. </author> <title> The Craft of Prolog. Logic Programming. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Firstly, I shall present a theoretical analysis of the memory requirements based on the structures being generated: these figures are based on the description of memory requirements given by O'Keefe <ref> [10, p.78] </ref>. <p> The predicate dict/2 looks up an item in the lexicon, defn/2 recovers a basic category definition, and the predicate cpu_time/3 (from O'Keefe <ref> [10, p.83] </ref>), calls its second argument the number of times specified by the first argument and returns the time taken as the third argument. 19 (10) dict (have,A),defn (verb,B),cpu_time (10000,A===B,T). (11) cpu_time (10000,(dict (have,A),defn (verb,A)),T). (12) dict (the,A),defn (onion,B),cpu_time (10000,A:head:agr===B:head:agr,T). The results (shown in Figure 10) are as expected.
Reference: [11] <author> F.C.N. Pereira and S.M. Shieber. </author> <title> Prolog and Natural-Language Analysis, </title> <booktitle> volume 10 of Lecture Notes. Center for the Study of Language and Information, </booktitle> <year> 1987. </year>
Reference-contexts: Pereira and Shieber <ref> [11, pp.70-87] </ref>). Using patr equations to encode the information in the grammar one need only state the features relevant to a given context; other information may be safely ignored.
Reference: [12] <author> J.D. Philips. </author> <title> A computational representation for generalised phrase-structure grammars. </title> <journal> Linguistics and Philosophy, </journal> <volume> 15 </volume> <pages> 255-287, </pages> <year> 1992. </year>
Reference-contexts: However, it is important to realize that the system does not represent an implementation of gpsg in the same way as the systems described by Shieber [15] and Philips <ref> [12] </ref>; rather, it borrows the ideas and principles and realizes them implicitly in the structure of the grammar.
Reference: [13] <author> C. Pollard and I. Sag. </author> <title> Information-Based Syntax and Semantics Volume 1: Fundamentals, </title> <booktitle> volume 13 of Lecture Notes. Center for the Study of Language and Information, </booktitle> <year> 1987. </year>
Reference-contexts: Note that although (18) is ill-formed under F type, the T type of each of n and num are respected. 5.2 Prespecified Type Information Pollard and Sag <ref> [13, pp.38-40] </ref> discuss typing of feature structures and make a point similar to that raised above with respect to the F and T types. <p> However, many systems based on patr have more in common with the lexicalist-style of grammar as put forward by Pollard and Sag <ref> [13] </ref>. The main difference between these two formalisms, as far as compilation is concerned, is that the former specifies complement structure via grammar rules selected by subcategorization indexes, whilst the latter specifies complement information directly in the relevant lexical items.
Reference: [14] <author> S.M. Shieber. </author> <title> An Introduction to Unification-Based Approaches to Grammar, </title> <booktitle> volume 4 of Lecture Notes. Center for the Study of Language and Information, </booktitle> <year> 1986. </year>
Reference-contexts: Other notation is derived directly from standard prolog practice, i.e. the underscore as an anonymous variable. 1.2 Incremental Description Building The notions of partial information and unification are key to much recent work in computational linguistics (for a good introduction see e.g. Shieber <ref> [14] </ref>). For example, when parsing a 1 Gazdar et al [5] show that the category structures used in a wide range of linguistic theories, including gpsg, can be modelled using only trees. <p> The compiler system has been tested on the syntactic portion of the grammar, ignoring the semantic representations. The grammar is based on the ideas of Generalized Phrase Structure Grammar (see [3]) modified by the more general structural considerations of unification-based formalisms (e.g. <ref> [14] </ref>). However, it is important to realize that the system does not represent an implementation of gpsg in the same way as the systems described by Shieber [15] and Philips [12]; rather, it borrows the ideas and principles and realizes them implicitly in the structure of the grammar. <p> In patr this is commonly encoded by a list structure as shown in (23) where A and B will be instantiated as actual category structures corresponding to the expected complements (see Shieber <ref> [14, pp.27-32] </ref> for details). (23) 6 6 6 6 6 subcat: 2 6 6 6 first: A rest: 2 4 first: B rest: nil 3 5 7 7 7 5 7 7 7 7 7 There are a number of problems that prevent the current system from handling this kind of
Reference: [15] <author> S.M. Shieber. </author> <title> A simple reconstruction of gpsg. </title> <type> Technical Report 384, </type> <institution> Center for the Study of Language and Information, </institution> <year> 1986. </year>
Reference-contexts: However, it is important to realize that the system does not represent an implementation of gpsg in the same way as the systems described by Shieber <ref> [15] </ref> and Philips [12]; rather, it borrows the ideas and principles and realizes them implicitly in the structure of the grammar. <p> In gpsg these kinds of type restriction are encoded by axioms called Feature Co-occurrence Restrictions (fcr) [3, pp.27-29]. Shieber <ref> [15] </ref> discusses reconstructing gpsg in patr but does not tackle this problem in any detail. <p> Hirsh's system ignores this and simply leaves the slots uninstantiated, but fcr axioms can be used to ensure that categories are well-formed 12 Shieber <ref> [15, p.13] </ref> suggests that it might be necessary to also check these constraints at run-time, but given the use of nil in this system to mark feature values as illegal in given contexts (as described below) this is not the case. 30 fcr (1,X):- ("+ X:head:cat:maj &lt;== [n:nil,v:nil|_]) -&gt; (X:head:cat:min ===
Reference: [16] <author> D.F. Stubbs and N.W. Webre. </author> <title> Data Structures: with Abstract Data Types and Pascal. </title> <publisher> Brooks/Cole Publishing Company, </publisher> <year> 1985. </year> <month> 46 </month>
Reference-contexts: automatic generation of type specifications for category structures during compilation, and finally, Section 6 considers an extension to the basic system that allows for the efficient handling both of the gpsg slash feature and the patr first/rest subcat lists. and Webre which has a complexity of O (n 2 ) <ref> [16, p.275] </ref>. At-Kaci and Nasr [1] present an algorithm for dag unification that is nearly linear in complexity. However, this requires that the dags be represented in a special way: namely as balanced, shallow trees.
References-found: 16

