URL: ftp://ftp.cis.upenn.edu/pub/pelachaud/cogsci94/cogsci94.ps.Z
Refering-URL: http://www.cis.upenn.edu/~hms/publications.html
Root-URL: 
Title: MODELING THE INTERACTION BETWEEN SPEECH AND GESTURE  
Author: Justine Cassell Mark Steedman Norm Badler Catherine Pelachaud Matthew Stone Brett Douville Scott Prevost Brett Achorn 
Keyword: Areas: discourse, gesture, animation Presentation: talk  
Address: Philadelphia, PA 19104-6389  
Affiliation: Computer Information Science University of Pennsylvania  
Pubnum: Fax:(215) 898-0587  
Email: justine@central.cis.upenn.edu  
Phone: Telephone: (215) 573-2821  
Date: February 14, 1994  
Abstract: Until now theories of the gesture-speech relationship have been difficult to evaluate because of their descriptive basis. In this paper we provide a tool for investigating the relationship between speech and gesture: a system that generates speech, intonation, and gesture using two copies of an identical program that have different knowledge of the world and must cooperate to accomplish a goal. The output of the dialogue generation is fed into a three-dimensional interactive animated model two graphic figures on a computer screen who gesture according to the rules given to the system. The advantage of computer modeling in this domain is that it forces us to come up with predictive theories of the gesture-speech relationship. A felicitous outcome is a working system to realize autonomous animated conversational agents, for virtual reality and other purposes. fl This research is partially supported by NSF VPW GER-9350179; NSF IRI91-17110; NSF graduate fellowships; ARO Grant DAAL03-89-C-0031 including participation by the U.S. Army Research Laboratory (Aberdeen); U.S. Air Force DEPTH contract through Hughes Missile Systems F33615-91-C-000; DMSO through the University of Iowa; National Defense Science and Engineering Graduate Fellowships; Naval Training Systems Center N61339-93-M-0843; Sandia Labs AG-6076; NASA KSC NAG10-0122; MOCO, Inc.; and NSF Instrumentation and Laboratory Improvement Program Grant USE-9152503. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. W. Alibali and S. Goldin-Meadow. </author> <title> Modeling Learning using Evidence from Speech and Gesture. </title> <booktitle> Proceedings of the Annual Conference of the Cognitive Science Society, </booktitle> <year> 1993. </year>
Reference-contexts: At a cognitive level, [4] established that listeners rely on information conveyed in gesture as they try to comprehend a story; <ref> [1] </ref> showed that children may express in gesture information that they cannot yet express in speech. Other evidence comes from the sheer frequency of gestures during speech.
Reference: [2] <author> Welton M. Becket. </author> <title> The jack lisp api. </title> <type> Technical Report MS-CIS-94-01/Graphics Lab 59, </type> <institution> University of Pennsylvania, </institution> <year> 1994. </year>
Reference: [3] <author> J. Cassell and D. McNeill. </author> <title> Non-verbal imagery and the poetics of prose. </title> <journal> Poetics Today, </journal> <volume> 12(3) </volume> <pages> 375-404, </pages> <year> 1991. </year>
Reference: [4] <author> J. Cassell, D. McNeill, and K.-E. McCullough. Kids, </author> <title> don't try this at home: Experimental mismatches of speech and gesture. </title> <booktitle> Presented at the International Communication Association annual meeting, </booktitle> <year> 1993. </year>
Reference-contexts: Evidence from many sources suggests a close relationship between speech and gesture. At the prosodic level, [10] found that the stroke phase (most effortful part) of these gestures tends to co-occur with or just before the phonologically most prominent syllable of the accompanying speech. At a cognitive level, <ref> [4] </ref> established that listeners rely on information conveyed in gesture as they try to comprehend a story; [1] showed that children may express in gesture information that they cannot yet express in speech. Other evidence comes from the sheer frequency of gestures during speech.
Reference: [5] <author> J. Cassell, C. Pelachaud, N. Badler, M. Steedman, B. Achorn, T. Becket, B. Douville, S. Prevost, C. Seah, and M. Stone. </author> <title> Animated conversation: Rule based generation of facial expression, gesture and spoken intonation for multiple conversational agents. </title> <booktitle> In SIGGRAPH'94, </booktitle> <year> 1994. </year> <note> (submitted). </note>
Reference: [6] <author> S. Feiner and K. McKeown. </author> <title> Automating the generation of coordinated multimedia explanations. </title> <journal> IEEE Computer, </journal> <volume> 24(10), </volume> <year> 1991. </year>
Reference: [7] <author> B.J. Grosz and C.L. Sidner. </author> <title> Attention, intentions, and the structure of discourse. </title> <journal> Computational Linguistics, </journal> <volume> 12(3), </volume> <year> 1986. </year>
Reference-contexts: Accordingly, both parties also separately record the most specific purpose for a segment for which evidence has been given. This architecture of intentional structure, attentional state, and discourse purposes, and the relationship between them was first proposed by <ref> [7] </ref>; the implementation of these notions here follows their suggestions as closely as possible.
Reference: [8] <author> E. Hajicov a and P. Sgall. </author> <title> Topic and focus of a sentence and the patterning of a text. </title> <editor> In J anos Petofi, editor, </editor> <booktitle> Text and Discourse Constitution. </booktitle> <publisher> De Gruyter, </publisher> <address> Berlin, </address> <year> 1988. </year>
Reference-contexts: Which question is asked determines which items in the response are most important or salient, which in turn determines how the phrase is uttered. These types of salience distinctions are encoded in the information structure representation of an utterance. Following Halliday and others ([9], <ref> [8] </ref>), we use the terms theme and rheme to denote two distinct information structural attributes of an utterance. 1 The theme roughly corresponds to what the utterance is about. The rheme corresponds to what the speaker has to contribute concerning the theme.
Reference: [9] <author> M. Halliday. </author> <title> Intonation and Grammar in British English. </title> <publisher> Mouton, </publisher> <address> The Hague, </address> <year> 1967. </year>
Reference: [10] <author> A. Kendon. </author> <title> Movement coordination in social interaction: some examples described. In Weitz, editor, Nonverbal Communication. </title> <publisher> Oxford University Press, </publisher> <year> 1974. </year>
Reference-contexts: An example is waving one's left hand briefly up and down along with the stressed words in the phrase Go AHEAD. Evidence from many sources suggests a close relationship between speech and gesture. At the prosodic level, <ref> [10] </ref> found that the stroke phase (most effortful part) of these gestures tends to co-occur with or just before the phonologically most prominent syllable of the accompanying speech.
Reference: [11] <author> A. Kendon. </author> <title> Do gestures communicate: A review. Research on Language and Social Interaction, </title> <year> 1994. </year>
Reference-contexts: Note also, however, that following Kendon we are led to believe that gestures may be more standardized than previously thought <ref> [11] </ref>. 3 Another model currently in progress generates gaze and head movements, and synchronizes gestures with these facial parameters as well as with movements of the lips ([14],[5]) 7 parse-net, is a control network which parses the output of the speech synthesis module described above.
Reference: [12] <author> M. Liberman and A. L. Buchsbaum. </author> <title> Structure and usage of current Bell Labs text to speech programs. </title> <type> Technical Memorandum TM 11225-850731-11, </type> <institution> AT&T Bell Laboratories, </institution> <year> 1985. </year>
Reference: [13] <author> D. McNeill. </author> <title> Hand and Mind: What Gestures Reveal about Thought. </title> <institution> University of Chicago, </institution> <year> 1992. </year>
Reference-contexts: Other evidence comes from the sheer frequency of gestures during speech. About three-quarters of all clauses in narrative discourse are accompanied by gestures of one kind or another <ref> [13] </ref>, and perhaps surprisingly, although the proportion of gesture types may change, all of these gestures, and spontaneous gesturing in general, are found in discourses by speakers of most languages. In this paper, however, our primary concern is with the semantic and pragmatic relationship between the two media.
Reference: [14] <author> C. Pelachaud, N.I. Badler, and M. Steedman. </author> <title> Linguistic issues in facial animation. </title> <editor> In N. Magnenat-Thalmann and D. Thalmann, editors, </editor> <booktitle> Computer Animation '91, </booktitle> <pages> pages 15-30. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference: [15] <author> R. </author> <title> Power. The organisation of purposeful dialogues. </title> <booktitle> Linguistics, </booktitle> <year> 1977. </year>
Reference: [16] <author> S. Prevost and M. Steedman. </author> <title> Generating contextually appropriate intonation. </title> <booktitle> In Proceedings of the 6th Conference of the European Chapter of the Association for Computational Linguistics, </booktitle> <pages> pages 332-340, </pages> <address> Utrecht, </address> <year> 1993. </year>
Reference-contexts: Focus is assigned to references according to the theory of contrast in <ref> [16] </ref>, while the discourse status of entities is determined from the agents' knowledge of each other and from the attentional 6 state.
Reference: [17] <author> S. Prevost and M. Steedman. </author> <title> Using context to specify intonation in speech synthesis. </title> <booktitle> In Proceedings of the 3rd European Conference of Speech Communication and Technology (EuroSpeech), </booktitle> <pages> pages 2103-2106, </pages> <address> Berlin, </address> <year> 1993. </year>
Reference: [18] <author> E. F. Prince. </author> <title> The ZPG letter: Subjects, definiteness and information status. </title> <editor> In S. Thompson and W. Mann, editors, </editor> <booktitle> Discourse description: diverse analyses of a fund raising text, </booktitle> <pages> pages 295-325. </pages> <publisher> John Benjamins B.V., </publisher> <year> 1992. </year>
Reference: [19] <author> M. Steedman. </author> <title> Structure and intonation. </title> <booktitle> Language, </booktitle> <pages> pages 260-296, </pages> <year> 1991. </year>
Reference: [20] <author> K. Tuite. </author> <title> The production of gesture. </title> <journal> Semiotica, </journal> <volume> 93(1/2), </volume> <year> 1993. </year>
Reference: [21] <author> W. Wahlster, E. Andr e, W. Graf, and T. Rist. </author> <title> Designing illustrated texts. </title> <booktitle> In Proceedings of the 5th EACL, </booktitle> <pages> pages 8-14, </pages> <year> 1991. </year> <month> 11 </month>
References-found: 21

