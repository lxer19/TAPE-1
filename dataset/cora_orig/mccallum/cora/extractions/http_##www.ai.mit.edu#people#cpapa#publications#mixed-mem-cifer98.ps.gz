URL: http://www.ai.mit.edu/people/cpapa/publications/mixed-mem-cifer98.ps.gz
Refering-URL: http://www.ai.mit.edu/people/cpapa/publications.html
Root-URL: 
Email: cpapa@ai.mit.edu  
Title: MIXED MEMORY MARKOV MODELS FOR TIME SERIES ANALYSIS  
Author: Constantine P. Papageorgiou 
Address: Cambridge, MA 02139 USA  
Affiliation: Center for Biological and Computational Learning and Artificial Intelligence Laboratory Massachusetts Institute of Technology  
Note: Appears in CIFEr '98, March 29-31, New York City  
Abstract: This paper presents a method for analyzing coupled time series using Markov models in a domain where the state space is immense. To make the parameter estimation tractable, the large state space is represented as the Cartesian product of smaller state spaces, a paradigm known as factorial Markov models. The transition matrix for this model is represented as a mixture of the transition matrices of the underlying dynamical processes. This formulation is know as mixed memory Markov models. Using this framework, we analyze the daily exchange rates for five currencies - British pound, Canadian dollar, Deutsch mark, Japanese yen, and Swiss franc as measured against the U.S. dollar.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Dempster, N. Laird, and D. Rubin. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> B39:1-38, </volume> <year> 1977. </year>
Reference-contexts: If -(-) &lt; 1, then this means that other components at time t 1 influence the -th component at time t. The parameters of this model are estimated by using an Expectation Maximization (EM) proce dure <ref> [1] </ref>, that iterates until the estimated values reach quiescence.
Reference: [2] <author> Z. Ghahramani and M.I. Jordan. </author> <title> Factorial hidden markov models. </title> <editor> In D.S. Touretzky, M.C. Mozer, and M. Hasselmo, editors, </editor> <booktitle> Advances in Neural Information Processing Systems. </booktitle> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: This paper presents a framework for analyzing coupled time series using Markov models that reduces the burden of estimating the (usually large number of) parameters involved in all but the most trivial of models. For this, we appeal to work in factorial Markov models <ref> [2] </ref> and mixed memory Markov models [4]. 2 Markov models Markov models offer a stochastic interpretation of time series; the next event has a probabilistic dependency on the past k events.
Reference: [3] <author> L.R. Rabiner and B.H. Juang. </author> <title> An introduction to hidden markov models. </title> <journal> IEEE Acoustics, Speech, and Signal Processing Magazine, </journal> <volume> 3(1) </volume> <pages> 4-16, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: 1 Introduction Markov models have achieved a prominent position in the analysis and recognition of time series in several domains, most notably, speech recognition <ref> [3] </ref> and natural language processing.
Reference: [4] <author> L.K. Saul and M.I. Jordan. </author> <title> Mixed memory markov models. </title> <booktitle> In Proceedings of the 1997 Conference on Artificial Intelligence and Statistics, </booktitle> <year> 1997. </year>
Reference-contexts: For this, we appeal to work in factorial Markov models [2] and mixed memory Markov models <ref> [4] </ref>. 2 Markov models Markov models offer a stochastic interpretation of time series; the next event has a probabilistic dependency on the past k events. The most trivial Markov model is a Markov chain, a simple integer time process composed of a set of n states. <p> This combinatorial explosion in the size of the state space leads to large increases in the number of parameters that need to be estimated in the transition matrix. 1 t denotes the th component of I t . Mixed memory Markov models <ref> [4] </ref> overcome this problem by representing the transition matrix as a convex combination of the elementary transition matrices of each underlying component; the description presented here closely follows that presented in [4]. <p> Mixed memory Markov models <ref> [4] </ref> overcome this problem by representing the transition matrix as a convex combination of the elementary transition matrices of each underlying component; the description presented here closely follows that presented in [4]. Let I t denote the tth element of a coupled time series and i t denote the th component of I t .
Reference: [5] <author> A.S. Weigend, B.A. Huberman, and D.E. Rumelhart. </author> <title> Predicting sunspots and exchange rates. </title> <editor> In M. Casdagli and S. Eubank, editors, </editor> <booktitle> Nonlinear Modeling and Forecasting, </booktitle> <pages> pages 395-432, </pages> <year> 1992. </year> <month> 6 </month>
Reference-contexts: t P (x - t1 ) 2 where x - t is the hidden variable indicating which component of I t1 determines the transition matrix for i - 3 Experimental Results We apply the mixed memory Markov model to an exchange rate time series previously reported on in the literature <ref> [5] </ref> with the following components, each measured against the U.S. dollar: British pound, Canadian dollar, Deutsch mark, Japanese yen, and Swiss franc. The series is from 06/01/73 to 05/21/87 and the separate components are shown in Figure 2.
References-found: 5

