URL: http://www.cs.nyu.edu/phd_students/parida/res/public/kona97.ps.gz
Refering-URL: http://www.cs.nyu.edu/phd_students/parida/res/res.html
Root-URL: http://www.cs.nyu.edu
Email: parida@cs.nyu.edu, geiger@cs.nyu.edu, hummel@cs.nyu.edu.  
Title: Energy Minimization Methods in Computer Vision and Pattern Recognition Kona: A Multi-Junction Detector using Minimum
Author: Laxmi Parida, Davi Geiger, Robert Hummel 
Address: New York University, New York, NY 10012, U.S.A.  
Affiliation: Courant Institute of Mathematical Sciences,  
Date: 51-65, May 1997.  
Note: (EMMCVPR'97),Pelillo, Hancock (Eds), LNCS vol 1223, pp  
Abstract: Corners, T-, Y-, X-junctions give vital depth cues which is a critical aspect of image understanding tasks like object recognition: junctions form an important class of features invaluable in most vision systems. The three main issues in a junction (or any feature) detector are: scale, location, and, the junction (feature) parameters. The junction parameters are (1) the radius, or size, of the junction, (2) the kind of junction: lines, corners, 3-junctions such as T or Y, or, 4-junction such as X-junction, etcetera, (3) angles of the wedges, and, (4) intensity in each of the wedges. Our main contribution in this paper is a modeling of the junction (using the minimum description length principle), which is complex enough to handle all the three issues and simple enough to admit an effective dynamic programming solution. Kona is an implementation of this model. A similar approach can be used to model other features like thick edges, blobs and end-points.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> W. Freeman, E. Adelson, </author> <title> Junction Detection and Classification, </title> <booktitle> Proc. </booktitle> <month> ARVO </month> <year> 1991. </year>
Reference-contexts: There have been basically two different paradigms for detecting junctions: edge detection followed by grouping of edges to form junctions <ref> [13, 12, 1, 16] </ref>, and, treating junction as a template matching phenomenon [4], In the former, it is assumed that the presence (or absence) of a junction is determined by "grouping" the intensity gradient near a hypothesized junction. <p> The threshold used to dynamically determine the window size R 1 , is the same at all places on the image, irrespective of the local contrast. We achieve this by normalizing the input data (i.e., rescaling the intensities in the input signal to lie in a standard range, say <ref> [0; 1] </ref>). Thus, regions with low contrast get comparable values to regions with high contrast. Hence, a single global threshold works.
Reference: 2. <author> A. Guzman, </author> <title> Decomposition of a Visual Scene into Three-Dimensional Bodies, </title> <booktitle> Proc. AFIPS 1968 Fall Joint Computer Conference, </booktitle> <year> 1968. </year>
Reference-contexts: These junctions are also critical for stereo vision modules or motion modules, since these are places where occlusions can be identified. Such points, for example, coincide with the images of trihedral vertices of an object. These are critical features for recognition as suggested by <ref> [2] </ref>, [3], [5]. We use the template deformation framework to develop a "junction detector," to finds corners (two-junctions), tri-corners (tri-junctions), quad-corners (quad-junctions), etc., defined as points where two or more homogeneous surface patches are located within an arbitrarily small neighborhood of the point.
Reference: 3. <author> D.A. Huffman, </author> <title> A Duality Concept for the Analysis of Polyhedral Scenes, </title> <journal> Machine Intelligence, </journal> <volume> Vol 6, </volume> <publisher> Edinburgh Univ. Press, Edinburgh, </publisher> <address> U.K., </address> <year> 1971. </year>
Reference-contexts: These junctions are also critical for stereo vision modules or motion modules, since these are places where occlusions can be identified. Such points, for example, coincide with the images of trihedral vertices of an object. These are critical features for recognition as suggested by [2], <ref> [3] </ref>, [5]. We use the template deformation framework to develop a "junction detector," to finds corners (two-junctions), tri-corners (tri-junctions), quad-corners (quad-junctions), etc., defined as points where two or more homogeneous surface patches are located within an arbitrarily small neighborhood of the point.
Reference: 4. <author> M. F. Hueckel, </author> <title> An operator which locates edges in digitized pictures, J, </title> <journal> Assoc. Compt. Mach. </journal> <volume> Vol 18, </volume> <year> 1971. </year>
Reference-contexts: There have been basically two different paradigms for detecting junctions: edge detection followed by grouping of edges to form junctions [13, 12, 1, 16], and, treating junction as a template matching phenomenon <ref> [4] </ref>, In the former, it is assumed that the presence (or absence) of a junction is determined by "grouping" the intensity gradient near a hypothesized junction. Usually one is interested in examining large gradients in the direction perpendicular to the hypothesized radial line. <p> This involves minimizing an energy function which gives a measure of the "distance" of the junction-model from the input signal. The idea of performing local feature detection by projecting image data onto a subspace is fundamental in <ref> [4, 7] </ref>. Basically, the input is orthogonally projected onto a finite dimensional subspace of the Hilbert space of functions. An energy function (which is the L 2 norm of the the difference of the input and the fitted function) is minimized in this finite dimensional space. <p> The two main issues are finding an orthonormal basis that spans a good finite dimensional subspace and minimizing the energy function. This approach can give closed form solutions for edges <ref> [4, 7] </ref>, and lines [6]. But, the generalization to junctions is complex and the solution is not apparent.
Reference: 5. <author> D. L. Waltz, </author> <title> Understanding Line Drawings of Scenes with Shadows, The Psychology of Computer Vision, </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1972. </year> <title> Energy Minimization Methods in Computer Vision and Pattern Recognition (EMMCVPR'97),Pelillo, </title> <editor> Hancock (Eds), </editor> <volume> LNCS vol 1223, </volume> <pages> pp 51-65, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: These junctions are also critical for stereo vision modules or motion modules, since these are places where occlusions can be identified. Such points, for example, coincide with the images of trihedral vertices of an object. These are critical features for recognition as suggested by [2], [3], <ref> [5] </ref>. We use the template deformation framework to develop a "junction detector," to finds corners (two-junctions), tri-corners (tri-junctions), quad-corners (quad-junctions), etc., defined as points where two or more homogeneous surface patches are located within an arbitrarily small neighborhood of the point.
Reference: 6. <author> M. F. Hueckel, </author> <title> A local operator which recognizes edges and lines, J, </title> <journal> Assoc. Compt. Mach. </journal> <volume> Vol 20, </volume> <year> 1973. </year>
Reference-contexts: The two main issues are finding an orthonormal basis that spans a good finite dimensional subspace and minimizing the energy function. This approach can give closed form solutions for edges [4, 7], and lines <ref> [6] </ref>. But, the generalization to junctions is complex and the solution is not apparent. In [9], corners and junctions (which are modeled as two adjacent corners) are represented by functions (models) that are blurred with a Gaussian (or an exponential filter) where the authors use a closed form solution.
Reference: 7. <author> R. Hummel, </author> <title> Feature Detection Using Basis Functions, </title> <journal> Computer Graphics and Image Processing, </journal> <volume> Vol 9, </volume> <year> 1979. </year>
Reference-contexts: This involves minimizing an energy function which gives a measure of the "distance" of the junction-model from the input signal. The idea of performing local feature detection by projecting image data onto a subspace is fundamental in <ref> [4, 7] </ref>. Basically, the input is orthogonally projected onto a finite dimensional subspace of the Hilbert space of functions. An energy function (which is the L 2 norm of the the difference of the input and the fitted function) is minimized in this finite dimensional space. <p> The two main issues are finding an orthonormal basis that spans a good finite dimensional subspace and minimizing the energy function. This approach can give closed form solutions for edges <ref> [4, 7] </ref>, and lines [6]. But, the generalization to junctions is complex and the solution is not apparent.
Reference: 8. <author> W. Forstner, E. Gulch, </author> <title> A Fast Operator for Detection and Precise Location of Distinct Points, Corners, and Centres of Circular Features, </title> <booktitle> Procc of Intercommssion Conference on Fast Processing of Photogrammetric Data, </booktitle> <address> Interlaken, Switzerland, </address> <year> 1987, </year> <pages> pp 281-305. </pages>
Reference-contexts: The radius of the disk addresses the "scale" issue, and the location of the center is a kind of "interest operator" <ref> [8] </ref> that determines the position where the feature is located in a region, possibly pre-defined. We can formulate the junction detection problem as one of finding the parameter values that yield a junction that best approximates the local data, and declaring local minima of the error as junctions.
Reference: 9. <author> R. Deriche, T. Blaszka, </author> <title> Recovering and Characterizing Image Features Using An Efficient Model Based Approach. </title> <booktitle> In Proceedings of Computer Vision and Pattern Recognition, </booktitle> <address> New York, </address> <year> 1993. </year>
Reference-contexts: The two main issues are finding an orthonormal basis that spans a good finite dimensional subspace and minimizing the energy function. This approach can give closed form solutions for edges [4, 7], and lines [6]. But, the generalization to junctions is complex and the solution is not apparent. In <ref> [9] </ref>, corners and junctions (which are modeled as two adjacent corners) are represented by functions (models) that are blurred with a Gaussian (or an exponential filter) where the authors use a closed form solution.
Reference: 10. <author> G. Giraudon and R. Deriche. </author> <title> On corner and vertex detection. </title> <booktitle> In Proceedings of Computer Vision and Pattern Recognition, Hawaii, </booktitle> <year> 1991. </year>
Reference-contexts: In general, numerical methods are used to obtain parameters that minimize the distance to the input data using an L 2 norm. This is also the case in <ref> [10] </ref>. Our approach is to use a combination of the two paradigms: grouping of edges and fitting templates. We use a template deformation framework, using the minimum description length (MDL) principle, that includes the gradient information in order to detect the radial partitions of the template as a grouping mechanism.
Reference: 11. <author> D. Mumford, T. Shah, </author> <title> Optimal Approximation by Piecewise Smooth Functions and Associated Variational Problems, </title> <journal> Comm. on Pure and Applied Mathematics, </journal> <volume> Vol XLII, No 5, </volume> <month> July </month> <year> 1989. </year>
Reference-contexts: G = 0 0 jrI (r; ) rT ()j 2 g fl (r)rdrd: (3) where g fl (r) is an appropriate modulating function, not necessarily the same as g (r). It may be pointed out that this form is different from the Mumford-Shah functional <ref> [11] </ref> particularly because of the presence of the term rI (r; ) in our model. As we explain in the next section, this term is critical in obtaining the portion of the image, or window, to which we fit a multi-junction template.
Reference: 12. <author> M. Nitzberg, D. Mumford, T. Shiota, </author> <title> Filtering, Segmentation, and Depth, </title> <publisher> Springer Verlag Berlin 1993. </publisher>
Reference-contexts: There have been basically two different paradigms for detecting junctions: edge detection followed by grouping of edges to form junctions <ref> [13, 12, 1, 16] </ref>, and, treating junction as a template matching phenomenon [4], In the former, it is assumed that the presence (or absence) of a junction is determined by "grouping" the intensity gradient near a hypothesized junction.
Reference: 13. <author> D. </author> <month> Beymer, </month> <institution> Massachusetts Institute of Technology Master's thesis, </institution> <month> Junctions: </month> <title> Their detection and use for grouping images, </title> <year> 1989. </year>
Reference-contexts: There have been basically two different paradigms for detecting junctions: edge detection followed by grouping of edges to form junctions <ref> [13, 12, 1, 16] </ref>, and, treating junction as a template matching phenomenon [4], In the former, it is assumed that the presence (or absence) of a junction is determined by "grouping" the intensity gradient near a hypothesized junction. <p> Usually one is interested in examining large gradients in the direction perpendicular to the hypothesized radial line. Experiments in this framework are limited and even the richest ones shown in <ref> [13] </ref> are interesting but not exhaustive. In the latter it is assumed that Energy Minimization Methods in Computer Vision and Pattern Recognition (EMMCVPR'97),Pelillo, Hancock (Eds), LNCS vol 1223, pp 51-65, May 1997. a (suitably small) local neighborhood is sufficient to detect a junction.
Reference: 14. <author> L. Parida, D. Geiger, B. Hummel, </author> <title> Junction Detection Using Piecewise Constant Functions, </title> <year> 1996. </year>
Reference-contexts: The interested reader may Energy Minimization Methods in Computer Vision and Pattern Recognition (EMMCVPR'97),Pelillo, Hancock (Eds), LNCS vol 1223, pp 51-65, May 1997. Fig. 1. Piecewise constant features. A bar detector and a junction detector. look at <ref> [14] </ref> for a more rigorous definition of the template as a smooth function of two variables. Further, let I denote the input signal. <p> Fig. 4. An example to show the dynamic computation of the windows at different locations on the image. we have omitted the details of the derivations here; they appear in <ref> [14] </ref>. Estimating wedge angles and intensities: Let us assume the number of wedges is fixed. In the next section we discuss how to estimate the number of wedges. We propose a dynamic programming formulation, although in practice we use the simpler version which is reasonably effective (See section 4).
Reference: 15. <author> J. Rissanen, </author> <title> A universal prior for integers and estimation by minimum description length, </title> <journal> Annals Statistics, </journal> <volume> vol. 11, </volume> <pages> pp, 416-431, </pages> <year> 1983. </year>
Reference: 16. <author> V. Caselles, B. Coll, J. M. Morel, </author> <title> A Kanizsa Programme, </title> <type> Technical Report, </type> <institution> Uni-versitat de les Illes Balears, Spain, </institution> <year> 1996. </year>
Reference-contexts: There have been basically two different paradigms for detecting junctions: edge detection followed by grouping of edges to form junctions <ref> [13, 12, 1, 16] </ref>, and, treating junction as a template matching phenomenon [4], In the former, it is assumed that the presence (or absence) of a junction is determined by "grouping" the intensity gradient near a hypothesized junction.
Reference: 17. <author> D. Geiger, K. Kumaran, L. Parida, </author> <title> Visual Organization for Figure/Ground Separation , CVPR-96, </title> <address> San Francisco, </address> <year> 1996. </year>
Reference-contexts: The results of this is used by an algorithm that runs on stereo images and estimates depth of objects in the scene. Figure 10 shows some results of obtaining illusory contours from junctions on an image. See <ref> [17] </ref> for details of the algorithm. 6 Conclusions To conclude, we summarize the contributions of this paper as follows. Firstly, an effective modeling of the junction that includes a gradient term in the model, and, the removal of a small disk at the center of the junction.
Reference: 18. <author> Y. Lamdan, H. J. Wolfson, </author> <title> Geometric Hashing: A general and efficient model-based recognition scheme in Second IEEE International Conference on Computer Vision, </title> <type> 238-249, </type> <year> 1988. </year>
Reference: 19. <author> J. Morel, S. Solimini, </author> <title> Variational Methods in Image Segmentation, </title> <publisher> Birkhauser Boston, </publisher> <year> 1995. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: A variational form that may justify this approach is to use, as suggested in the book of Morel and Solimini <ref> [19] </ref>, a split and merge algorithm for the energy ~ E = log (r n ): 4 Implementation Although the energy equation E of the last section looks fairly complex, it has a remarkably simple and natural interpretation.
References-found: 19

