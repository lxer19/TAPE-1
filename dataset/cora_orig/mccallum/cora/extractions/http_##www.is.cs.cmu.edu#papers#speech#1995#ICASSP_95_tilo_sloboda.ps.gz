URL: http://www.is.cs.cmu.edu/papers/speech/1995/ICASSP_95_tilo_sloboda.ps.gz
Refering-URL: http://www.is.cs.cmu.edu/ISL.speech.publications.html
Root-URL: 
Email: sloboda@ira.uka.de  
Title: DICTIONARY LEARNING: PERFORMANCE THROUGH CONSISTENCY  
Author: Tilo Sloboda 
Address: USA  
Affiliation: Interactive Systems Laboratories University of Karlsruhe Germany Carnegie Mellon University  
Abstract: We present first results from our efforts in automatically increasing and adapting phonetic dictionaries for spontaneous speech recognition. Spontaneous speech adds a variety of phenomena to a speech recognition task: false starts [1], human and nonhuman noises [2], new words [3] and alternative pronunciations. All of these phenomena have to be tackled when adapting a speech recognition system for spontaneous speech. For phonetic dictionaries (especially for spontaneous speech) it is important to choose the pronunciations of a word according to the frequency in which they appear in the database rather than the "correct" pronunciation as it might be found in a lexicon. Additionally modifications of the dictionary should not lead to a higher phoneme confusability. Therefore we propose a data-driven approach to add new pronunciations to a given phonetic dictionary, in a way that they model the given occurrences of words in the database. We show how even a simple approach can lead to significant improvements in recognition performance. First experiments have been performed on the German Spontaneous Scheduling Task (GSST), using the speech recognition engine of JANUS-2 [4, 5, 6], the spontaneous speech-to-speech translation system of the Interactive Systems Laboratories at Carnegie Mellon and Karl-sruhe University. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Douglas O'Shaughnessy: </author> <title> Correcting Complex False Starts in Spontaneous Speech, </title> <booktitle> Proceedings of the ICASSP 1994, Adelaide, </booktitle> <volume> volume 1, </volume> <pages> pp 349-352. </pages>
Reference: [2] <author> Tanja Schultz, Ivica Rogina: </author> <title> Acoustic and Language Modeling of Human and Nonhuman Noises for Human-to-Human Spontaneous Speech Recognition, </title> <booktitle> Proceedings of the ICASSP 1995. </booktitle>
Reference-contexts: Results of Algorithm A For the experiments reported here we used the hybrid LVQ/HMM recognizer of JANUS [6], using 69 context independent 1 phoneme models (including noise models <ref> [2] </ref>) as a baseline system.
Reference: [3] <author> B.Suhm, M.Woszczyna, A.Waibel: </author> <title> Detection and Transcription of New Words, </title> <booktitle> Proceedings of the EU-ROSPEECH, </booktitle> <address> Berlin, </address> <year> 1993. </year>
Reference: [4] <author> L. Osterholtz, A. McNair, I. Rogina, H. Saito, T. Slo boda, J. Tebelskis, A. Waibel, and M. Woszczyna: </author> <title> Testing Generality in JANUS: A Multi-Lingual Speech to Speech Translation System, </title> <booktitle> Proceedings of the ICASSP 1992, San Francisco, </booktitle> <volume> volume 1, </volume> <pages> pp 209-212. </pages>
Reference-contexts: Outline of Algorithm A We modified a pre-trained speech recognizer for the given task to run as a phoneme recognizer with smoothed phoneme-bigrams (e.g. based on our JANUS speech recognition engine <ref> [4, 5, 6] </ref> in context independent mode 1 ).
Reference: [5] <author> M.Woszczyna, N.Coccaro, A.Eisele, A.Lavie, A.McNair, T.Polzin, I.Rogina, C.P.Rose, T.Sloboda, M.Tomita, J.Tsutsumi, N.Aoki-Waibel, A.Waibel, W.Ward: </author> <title> Recent Advances in Janus, a Speech to Speech Translation System, </title> <booktitle> Proceedings of the EUROSPEECH, </booktitle> <address> Berlin, </address> <year> 1993. </year>
Reference-contexts: Outline of Algorithm A We modified a pre-trained speech recognizer for the given task to run as a phoneme recognizer with smoothed phoneme-bigrams (e.g. based on our JANUS speech recognition engine <ref> [4, 5, 6] </ref> in context independent mode 1 ).
Reference: [6] <author> M. Woszczyna, N. Aoki-Waibel, F.D. But, N. Coc caro, K. Horiguchi, T. Kemp, A. Lavie, A. McNair, T. Polzin, I. Rogina, C.P. Rose, T. Schultz, B. Suhm, M. Tomita, A. Waibel: </author> <title> JANUS 93: Towards Spontaneous Speech Translation, </title> <booktitle> Proceedings of the ICASSP 1994, Adelaide, </booktitle> <volume> volume 1, </volume> <pages> pp 345-348. </pages>
Reference-contexts: Outline of Algorithm A We modified a pre-trained speech recognizer for the given task to run as a phoneme recognizer with smoothed phoneme-bigrams (e.g. based on our JANUS speech recognition engine <ref> [4, 5, 6] </ref> in context independent mode 1 ). <p> Results of Algorithm A For the experiments reported here we used the hybrid LVQ/HMM recognizer of JANUS <ref> [6] </ref>, using 69 context independent 1 phoneme models (including noise models [2]) as a baseline system.
Reference: [7] <author> J.L.Gauvain, L.F.Lamel, G.Adda, M.Adda-Decker: </author> <title> The LIMSI Continuous Speech Dictation System: Evaluation on the ARPA Wall Street Journal Task, </title> <booktitle> Proceedings of the ICASSP 1994, Adelaide, </booktitle> <volume> volume 1, </volume> <pages> pp 557-560. </pages>
Reference-contexts: If the phonetic transcriptions in the dictionary don't match the actual occurrences in the database, the phonetic units will be contaminated during the training with inadequate acoustics. This will degrade the overall performance of the recognizer. State-of-the-art speech recognition systems (e.g. <ref> [8, 7] </ref>) start to put more and more effort into creating adequate dictionaries with alternative pronunciations and function words, which can also model interword effects such as coar-ticulation between words. This is usually done either by modifying the dictionary by hand or applying phonological rules to a given dictionary.
Reference: [8] <author> Chuck Wooters, Andreas Stolcke: </author> <title> Multiple-Pronunciation Lexical Modeling in a Speaker Independent Speech Understanding System, </title> <booktitle> Proceedings of the ICSLP 1994, Yokohama, </booktitle> <volume> volume 3, </volume> <pages> pp 1363-1366. </pages>
Reference-contexts: If the phonetic transcriptions in the dictionary don't match the actual occurrences in the database, the phonetic units will be contaminated during the training with inadequate acoustics. This will degrade the overall performance of the recognizer. State-of-the-art speech recognition systems (e.g. <ref> [8, 7] </ref>) start to put more and more effort into creating adequate dictionaries with alternative pronunciations and function words, which can also model interword effects such as coar-ticulation between words. This is usually done either by modifying the dictionary by hand or applying phonological rules to a given dictionary.
References-found: 8

