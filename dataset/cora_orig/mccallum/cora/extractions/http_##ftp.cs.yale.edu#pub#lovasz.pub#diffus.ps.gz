URL: http://ftp.cs.yale.edu/pub/lovasz.pub/diffus.ps.gz
Refering-URL: http://ftp.cs.yale.edu/pub/lovasz.pub/
Root-URL: http://www.cs.yale.edu
Title: Mixing of Random Walks and Other Diffusions on a Graph  
Author: Laszlo Lovasz and Peter Winkler 
Abstract: We survey results on two diffusion processes on graphs: random walks and chip-firing (closely related to the "abelian sandpile" or "avalanche" model of self-organized criticality in statistical mechanics). Many tools in the study of these processes are common, and results on one can be used to obtain results on the other. We survey some classical tools in the study of mixing properties of random walks; then we introduce the notion of "access time" between two distributions on the nodes, and show that it has nice properties. Surveying and extending work of Aldous, we discuss several notions of mixing time of a random walk. Then we describe chip-firing games, and show how these new results on random walks can be used to improve earlier results. We also give a brief illustration how general results on chip-firing games can be applied in the study of avalanches.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Aleliunas, R.M. Karp, R.J. Lipton, L. Lovasz and C.W. Rackoff, </author> <title> Random walks, universal travelling sequences, and the complexity of maze problems, </title> <booktitle> Proc. 20th Ann. Symp. on Foundations of Computer Science (1979), </booktitle> <pages> 218-223. </pages>
Reference-contexts: This particular method does not generalize; in fact, apart from the complete graph, the cycle is the only graph which enjoys this property (see [36]). Consider another quite simple graph, the cube, which we view as the graph of vertices and edges of <ref> [0; 1] </ref> n . Let us do a random walk on it as follows: at Mixing of Random Walks 11 each vertex, we select an edge incident with the vertex at random, then flip a coin. <p> A halting node j gets g j = 1. The threshold rule. Every "threshold vector" h = (h 1 ; : : : ; h n ), h i 2 <ref> [0; 1] </ref> gives rise to a stopping rule in a manner opposite to the "deadlines" mentioned in connection with the filling rule: we stop at node j if we hit it after time h j + 1; time; if we hit the node j at time t where h j &lt; <p> The "shopping rule" is then 18 L. Lovasz and P. Winkler implemented by choosing a random real "budget" r uniformly from <ref> [0; 1] </ref> and walking until a node j with r (j) r is reached. The shopping rule shares with the filling rule the "now-or-never" property that once a node is exited, it can never be the node at which the rule stops.
Reference: [2] <author> W. Aiello, B. Awerbuch, B. Maggs and S. Rao, </author> <title> Approximate load balancing on dynamic and asynchronous networks, </title> <booktitle> Proc. 25th ACM Symp. of Theory of Computing (1993), </booktitle> <pages> 632-634. </pages>
Reference: [3] <author> N. Alon, </author> <title> Eigenvalues and expanders, </title> <booktitle> Combinatorica 6 (1986), </booktitle> <pages> 83-96. </pages>
Reference-contexts: Sinclair and Jerrum [33] established a connection between the spectral gap and the conductance of an undirected graph. A similar result for the related, but somewhat different parameter called expansion rate was proved by Alon <ref> [3] </ref> and, independently, by Dodziuk and Kendall [23] (cf. also Diaconis and Stroock [24]). All these results may be considered as discrete versions of Cheeger's inequality in differential geometry.
Reference: [4] <author> R.J. Anderson, L. Lovasz, P.W. Shor, J. Spencer, E. Tardos and S. Wino-grad, </author> <title> Disks, balls, and walls: analysis of a combinatorial game, </title> <journal> Amer. Math. </journal> <volume> Monthly 96 (1989), </volume> <pages> 481-493. </pages>
Reference-contexts: Engel [26], [27] considered a procedure he called the "probabilistic abacus", as a method of determining the limit distribution of certain Markov chains by combinatorial means. Spencer [45] introduced the special case when the underlying graph is a path, as a tool in analyzing a certain "balancing" game. In <ref> [4] </ref> Spencer's process was analyzed in greater detail. The analysis of the procedure was extended to general (undirected) graphs in [13], and to directed graphs by Bjorner and Lovasz [14]. <p> A key property of these games is that from a given position, all sequences of firings behave similarly: either they all can be extended infinitely, or they all terminate after the same number of moves, with the same final position (Church-Rosser property). This was observed in <ref> [4] </ref> and in [20].
Reference: [5] <author> D.J. Aldous, </author> <title> Reversible Markov Chains and Random Walks on Graphs (book), </title> <note> to appear. </note>
Reference-contexts: The most important special case arises when one wishes to generate a node from the stationary distribution, starting from a given node. The "distance" from a node to the stationary distribution, maximized over all nodes, provides a precise natural definition of mixing time (considered by Aldous <ref> [5] </ref>, [6] in the reversible case). This notion agrees, up to a constant factor, with most of the usual definitions of mixing time, which depend on a specific choice of how nearness to the limit distribution is measured. <p> H (i; j) = C (5) is independent of the choice of i; in other words, the expected number of steps we have to walk to hit a node randomly chosen from the stationary distribution is C, independent of the starting point (see, e.g., the "right averaging principle" in Aldous <ref> [5] </ref>). The hitting time from i to j may be different from the hitting time from j to i, even in an undirected regular graph. Still, one expects that time-reversibility should give some sort of symmetry of these quantities. <p> It follows from Theorem 4.2 that the exit frequencies of any mean-optimal stopping rule from to t are the same. We denote them by x i (; t ). Let us determine the exit frequencies in some simple cases. The first result is from Aldous <ref> [5] </ref>. Several related formulas could be derived using relations to electrical networks, as in [18] or [46]. <p> Aldous (see e.g <ref> [5] </ref>) proved a converse inequality in the time-reversible case. <p> = X j max H (i; j) j (H (; j) on the right hand side could be replaced by H (k; j) with any k 2 V by (5).) Using this formula, one can prove the following inequalities (for the case of undirected graphs, they were proved by Aldous <ref> [5] </ref>). Theorem 5.10 For every digraph, T set T forget 6T tv : (Hence (1=10)T tv T forget 6T tv .) We conjecture that there is a constant c such that for any digraph, T mix cT reset . Maximum time and pointwise mixing.
Reference: [6] <author> D.J. Aldous, </author> <title> Some inequalities for reversible Markov chains, </title> <journal> J. London Math. Soc. </journal> <volume> 25 (1982), </volume> <pages> 564-576. </pages>
Reference-contexts: The most important special case arises when one wishes to generate a node from the stationary distribution, starting from a given node. The "distance" from a node to the stationary distribution, maximized over all nodes, provides a precise natural definition of mixing time (considered by Aldous [5], <ref> [6] </ref> in the reversible case). This notion agrees, up to a constant factor, with most of the usual definitions of mixing time, which depend on a specific choice of how nearness to the limit distribution is measured. <p> Mixing of Random Walks 23 Other mixing measures. Theorems 5.1 and 5.2, and, in a weaker way, 5.3 are special cases of a surprising phenomenon, first explored by Aldous ([5], <ref> [6] </ref>). Mixing parameters of a random walk, that are only loosely related by their definition, are often very close. In fact, there seem to be three groups of parameters; within each group, any two are within (reasonably small) absolute constant factors to each other.
Reference: [7] <author> D.J. Aldous, </author> <title> On simulating a Markov chain stationary distribution when transition probabilities are unknown, </title> <note> preprint (1993). </note>
Reference-contexts: It is not at all obvious how to know (just by observing the walk) how long is "sufficiently long". But Aldous <ref> [7] </ref> describes a way to do so, and comes within total variation " of the stationary distribution in time polynomial in 1=" and linear in the maximum hitting time of the graph.
Reference: [8] <author> S. Asmussen, </author> <title> Applied Probability and Queues, </title> <publisher> Wiley, </publisher> <address> New York 1987. </address>
Reference-contexts: In other words, T forget = min t t s (since the worst starting distribution for any given target distribution t is clearly concentrated on a single node). This notion is central to the modern theory of Harris-recurrent chains; see e.g. <ref> [8] </ref>.
Reference: [9] <author> S. Asmussen, P. W. Glynn and H. Thorisson, </author> <title> Stationary detection in the initial transient problem, </title> <booktitle> ACM Transactions on Modeling and Computer Simulation 2 (1992), </booktitle> <pages> 130-157. </pages>
Reference-contexts: It is easy to argue that no matter how long we observe the walk, it is impossible to compute the stationary distribution exactly. Thus it is a bit surprising that one can achieve it exactly. Nonetheless that is what is done by Asmussen, Glynn and Thorisson <ref> [9] </ref>: they give a stopping rule where the probability of stopping after a walk w 0 w 1 w 2 : : : depends only on the repetition pattern of nodes, and which produces a node from exactly the stationary distribution.
Reference: [10] <author> J.R. Baxter and R.V. Chacon, </author> <title> Stopping times for recurrent Markov processes, </title> <journal> Illinois J. Math. </journal> <volume> 20 (1976), </volume> <pages> 467-475. </pages>
Reference-contexts: The filling rule. This rule is the discrete version of the "filling scheme," introduced by Chacon and Ornstein [16] and shown by Baxter and Chacon <ref> [10] </ref> to minimize expected number of steps. We call it the filling rule (from to t ), and define it recursively as follows.
Reference: [11] <author> D. Bayer and P. Diaconis, </author> <title> Trailing the dovetail shu*e to its lair, </title> <journal> Ann. Appl. Probab. </journal> <volume> 2 (1992), </volume> <pages> 294-313. </pages>
Reference-contexts: Informally, let as call the necessary number of steps the mixing time. The surprising fact, allowing these algorithmic applications, is that this mixing time may be much less than the number of nodes. For example, it takes only 7 moves <ref> [11] </ref> to shu*e a deck of 52 cards quite well, using the standard "dovetail" shu*e|even though the graph has 52! nodes. On an expander graph with n nodes, it takes only O (log n) steps to mix.
Reference: [12] <author> P. Bak, C. Tang and K. Wiesenfeld, </author> <title> Self-organized criticality, </title> <journal> Physical Revue A 38 (1988), </journal> <pages> 364-374. </pages>
Reference-contexts: The analysis of the procedure was extended to general (undirected) graphs in [13], and to directed graphs by Bjorner and Lovasz [14]. Chip-firing turns out to be closely related to the "avalanche" or "sandpile" model of catastrophic events (also called self-organized criticality), introduced by Bak, Tang and Wiesenfeld <ref> [12] </ref> and Dhar [20]. The nodes of the digraph represent "sites" where snow is accumulating. There is a special node, the "outside universe".
Reference: [13] <author> A. Bjorner, L. Lovasz and P. Shor, </author> <title> Chip-firing games on graphs, Europ. </title> <journal> J. Comb. </journal> <volume> 12 (1991), </volume> <pages> 283-291. </pages>
Reference-contexts: A simpler but powerful tool is the "conservation equation" first noted by Pitman [41] (see Section 4). Chip-firing and avalanches. Another diffusion process on graphs was introduced by Bjorner, Lovasz and Shor <ref> [13] </ref> under the name of "chip-firing game". We place a pile of chips on each node of a directed graph, and then 4 L. Lovasz and P. <p> Spencer [45] introduced the special case when the underlying graph is a path, as a tool in analyzing a certain "balancing" game. In [4] Spencer's process was analyzed in greater detail. The analysis of the procedure was extended to general (undirected) graphs in <ref> [13] </ref>, and to directed graphs by Bjorner and Lovasz [14]. Chip-firing turns out to be closely related to the "avalanche" or "sandpile" model of catastrophic events (also called self-organized criticality), introduced by Bak, Tang and Wiesenfeld [12] and Dhar [20]. <p> it last? If infinite, how soon can it cycle? How many chips are needed for an infinite procedure? How does one determine if a given position (distribution of chips) can be transformed into another one by firings? In the case of undirected graphs, these questions are more-or-less fully answered in <ref> [13] </ref>, [14] and the work of Tardos [46]. For example, a finite procedure terminates in O (n 4 ) steps; the shortest period of a periodic game in n; the minimum number of chips that allow an infinite game is m, the number of edges. <p> There is a strong connection between chip firings, random walks on graphs, and the Laplace operator. In particular, the "conservation equation" plays an important role. This connection in the undirected case was observed in Mixing of Random Walks 5 <ref> [13] </ref>; the extension to the directed case is due to [14], where it was used to show that no terminating firing sequence is longer than a polynomial times the length of the period of a periodic firing sequence. (This extends the result of [46], the directed case.) The new results on <p> For ff 2 L s , we denote by jffj the length of ff. The multiset of nodes occuring in ff is called the score of ff and is denoted by [ff]. The following properties of L have been proved in <ref> [13] </ref> for the undirected case, and extended to the directed case in [14]; they are also closely related to properties of abelian sandpiles proved by Dhar [20]. <p> Given a graph, we may ask: what is the minimum number of chips that allows an infinite game? What is the maximum number of chips that allows a finite game? In <ref> [13] </ref> it was shown that for an undirected graph with n nodes and m edges, more than 2m n chips guarantees that the game is infinite; fewer than m chips guarantee that the game is finite; for every number N of chips with m N 2m n, there are initial positions <p> Moreover, the feedback number is always a lower bound on the number of chips in an infinite game. Chip conservation. A useful tool in the study of chip-firing games is the following "chip conservation equation" from <ref> [13] </ref> (cf. Lemma 4.1). Let s be the initial and t, the final configuration of a finite game, and let x i denote the number of times the node i is fired. Let a ij be the number of edges from node i to node j.
Reference: [14] <author> A. Bjorner and L. Lovasz, </author> <title> Chip-firing games on directed graphs, </title> <editor> J. </editor> <booktitle> Algebraic Combinatorics 1 (1992), </booktitle> <pages> 305-328. </pages> <note> 34 L. Lovasz and P. Winkler </note>
Reference-contexts: In [4] Spencer's process was analyzed in greater detail. The analysis of the procedure was extended to general (undirected) graphs in [13], and to directed graphs by Bjorner and Lovasz <ref> [14] </ref>. Chip-firing turns out to be closely related to the "avalanche" or "sandpile" model of catastrophic events (also called self-organized criticality), introduced by Bak, Tang and Wiesenfeld [12] and Dhar [20]. The nodes of the digraph represent "sites" where snow is accumulating. There is a special node, the "outside universe". <p> last? If infinite, how soon can it cycle? How many chips are needed for an infinite procedure? How does one determine if a given position (distribution of chips) can be transformed into another one by firings? In the case of undirected graphs, these questions are more-or-less fully answered in [13], <ref> [14] </ref> and the work of Tardos [46]. For example, a finite procedure terminates in O (n 4 ) steps; the shortest period of a periodic game in n; the minimum number of chips that allow an infinite game is m, the number of edges. <p> There is a strong connection between chip firings, random walks on graphs, and the Laplace operator. In particular, the "conservation equation" plays an important role. This connection in the undirected case was observed in Mixing of Random Walks 5 [13]; the extension to the directed case is due to <ref> [14] </ref>, where it was used to show that no terminating firing sequence is longer than a polynomial times the length of the period of a periodic firing sequence. (This extends the result of [46], the directed case.) The new results on mixing times of random walks give improvements of these results. <p> A converse inequality, conjectured in <ref> [14] </ref>, will also be proved here, using the conservation equation. There are a number of other diffusion processes on graphs, which we do not survey here in detail. Load balancing in distributed networks seems to be very closely related. <p> For digraphs, hitting times are not bounded by any polynomial of the number of edges in general. In fact, they are closely tied to the smallest stationary probability ^. Bjorner and Lovasz proved in <ref> [14] </ref> that H (G) i2V i ; (3) which, together with the trivial lower bound, implies that 1 1 H (G) ^ Hitting times have many interesting combinatorial and algebraic properties; see [34] for several of these. We only state here two special properties, for later reference. <p> The multiset of nodes occuring in ff is called the score of ff and is denoted by [ff]. The following properties of L have been proved in [13] for the undirected case, and extended to the directed case in <ref> [14] </ref>; they are also closely related to properties of abelian sandpiles proved by Dhar [20]. <p> This assertion is analogous to Theorem 4.5 for stopping rules; however, it does not remain true for general digraphs. It was shown in <ref> [14] </ref> that it remains true for eulerian digraphs, and that it can be extended to digraphs in a different way (see Lemma 6.5 below). <p> It is not known how to determine the minimum number of chips allowing an infinite game on a general digraph. This is not just a function of the number of nodes and edges. For eulerian digraphs, it was mentioned in a remark added in proof to <ref> [14] </ref> that the minimum number of chips that can start an infinite game is the edge-feedback number, i.e., the minimum number of edges whose removal destroys all directed cycles. Moreover, the feedback number is always a lower bound on the number of chips in an infinite game. Chip conservation. <p> Mixing of Random Walks 29 Eriksson [28] showed that on a directed graph (even on a graph with all but one edges undirected) a terminating game can be exponentially long. It was proved in <ref> [14] </ref> that the maximum length of a terminating game can exceed the period length by a polynomial factor only. It was conjectured that a converse inequality, bounding the period length by a polynomial multiple of the maximum game length, also holds. <p> To prove the other inequality (and thereby verify a conjecture from <ref> [14] </ref>), place d i 1 chips on node i. We claim that every game from this starting position is finite; in fact, we claim that no node can be fired v i times. <p> Then one can argue that the hitting time remains polynomial; on the other hand, the example of Eriksson mentioned above is of this type, and here the game length and period length are exponentially large. Algorithmic issues. Results mentioned above were used in <ref> [14] </ref> to give an algorithm for checking whether a given position on an undirected graph can be transformed to another given position by a sequence of firings.
Reference: [15] <author> G. Brightwell and P. Winkler, </author> <title> Maximum hitting time for random walks on graphs, </title> <editor> J. </editor> <booktitle> Random Structures and Algorithms 1 (1990), </booktitle> <pages> 263-276. </pages>
Reference-contexts: We denote by H (G) the largest hitting time between any two nodes of the graph G. For undirected graphs, hitting times are polynomial in the number of edges ([1]). Brightwell and Winkler <ref> [15] </ref> proved that for every simple graph, H (G) (4=27)n 3 , and determined the graph that provides the maximum. For digraphs, hitting times are not bounded by any polynomial of the number of edges in general. In fact, they are closely tied to the smallest stationary probability ^.
Reference: [16] <author> R.V. Chacon and D.S. Ornstein, </author> <title> A general ergodic theorem, </title> <journal> Illinois J. Math. </journal> <volume> 4 (1960), </volume> <pages> 153-160. </pages>
Reference-contexts: The filling rule. This rule is the discrete version of the "filling scheme," introduced by Chacon and Ornstein <ref> [16] </ref> and shown by Baxter and Chacon [10] to minimize expected number of steps. We call it the filling rule (from to t ), and define it recursively as follows.
Reference: [17] <author> F.R.K. Chung and S.-T. Yau, </author> <title> Eigenvalues of graphs and Sobolev inequalities, </title> <note> to appear. </note>
Reference-contexts: To be sure, eigenvalue methods can provide very sharp estimates, but for this, detailed information on the spectrum, and even on the eigenvectors, is needed (see Diaconis [21] or Chung and Yau <ref> [17] </ref>). This kind of spectral information can be derived, it seems, only in the presence of some algebraic structure, e.g. a large automorphism group. Therefore, combinatorial techniques that yield only bounds on the mixing rate and mixing time are often preferable.
Reference: [18] <author> A.K. Chandra, P. Raghavan, W.L. Ruzzo, R. Smolensky and P. Tiwari, </author> <title> The electrical resistance of a graph captures its commute and cover times, </title> <booktitle> Proc. 21st ACM Annual ACM Symposium on the Theory of Computing (1989), </booktitle> <pages> 574-586. </pages>
Reference-contexts: We denote them by x i (; t ). Let us determine the exit frequencies in some simple cases. The first result is from Aldous [5]. Several related formulas could be derived using relations to electrical networks, as in <ref> [18] </ref> or [46].
Reference: [19] <author> D. Coppersmith, P. Tetali and P. Winkler, </author> <title> Collisions among Random Walks on a Graph, </title> <note> SIAM J. on Discrete Mathematics 6 No. </note> <month> 3 </month> <year> (1993), </year> <pages> 363-374. </pages>
Reference-contexts: Still, one expects that time-reversibility should give some sort of symmetry of these quantities. One symmetry property of hitting times for undirected graphs was discovered by Coppersmith, Tetali and Winkler <ref> [19] </ref>: H (i; j) + H (j; k) + H (k; i) = H (i; k) + H (k; j) + H (j; i) (6) for every three nodes.
Reference: [20] <author> D. Dhar, </author> <title> Self-organized critical state of sandpile automaton models, </title> <journal> Physical Revue Letters 64 (1990), </journal> <pages> 1613-1616. </pages>
Reference-contexts: Chip-firing turns out to be closely related to the "avalanche" or "sandpile" model of catastrophic events (also called self-organized criticality), introduced by Bak, Tang and Wiesenfeld [12] and Dhar <ref> [20] </ref>. The nodes of the digraph represent "sites" where snow is accumulating. There is a special node, the "outside universe". <p> A key property of these games is that from a given position, all sequences of firings behave similarly: either they all can be extended infinitely, or they all terminate after the same number of moves, with the same final position (Church-Rosser property). This was observed in [4] and in <ref> [20] </ref>. <p> The following properties of L have been proved in [13] for the undirected case, and extended to the directed case in [14]; they are also closely related to properties of abelian sandpiles proved by Dhar <ref> [20] </ref>.
Reference: [21] <author> P. Diaconis, </author> <title> Group Representations in Probability and Statistics, </title> <institution> Inst. of Math. Statistics, </institution> <address> Hayward, CA (1988). </address>
Reference-contexts: Lovasz and P. Winkler Much of this was motivated by applications to computer science. Perhaps the most important of these (though certainly not the only one) is sampling by random walk (see, e.g., <ref> [21] </ref>, [33], [25]). This method is based on the fact that (at least for connected non-bipartite undirected graphs, which is easy to guarantee), the distribution of the current node after t steps tends to a well-defined distribution , called the stationary distribution (which is uniform if the graph is regular). <p> To be sure, eigenvalue methods can provide very sharp estimates, but for this, detailed information on the spectrum, and even on the eigenvectors, is needed (see Diaconis <ref> [21] </ref> or Chung and Yau [17]). This kind of spectral information can be derived, it seems, only in the presence of some algebraic structure, e.g. a large automorphism group. Therefore, combinatorial techniques that yield only bounds on the mixing rate and mixing time are often preferable.
Reference: [22] <author> P. Diaconis and D. Stroock, </author> <title> Geometric bounds for eigenvalues of Markov chains, </title> <journal> Annals of Appl. Prob. </journal> <volume> 1 (1991), </volume> <pages> 36-62. </pages>
Reference: [23] <author> J. Dodziuk and W.S. Kendall, </author> <title> Combinatorial Laplacians and isoperi-metric inequality, in: From Local Times to Global Geometry, Control and Physics, </title> <editor> (ed. K. D. Ellworthy), Pitman Res. </editor> <booktitle> Notes in Math. Series 150 (1986), </booktitle> <pages> 68-74. </pages>
Reference-contexts: Sinclair and Jerrum [33] established a connection between the spectral gap and the conductance of an undirected graph. A similar result for the related, but somewhat different parameter called expansion rate was proved by Alon [3] and, independently, by Dodziuk and Kendall <ref> [23] </ref> (cf. also Diaconis and Stroock [24]). All these results may be considered as discrete versions of Cheeger's inequality in differential geometry.
Reference: [24] <author> P.G. Doyle and J.L. Snell, </author> <title> Random Walks and Electric Networks, </title> <publisher> Mathematical Assoc. of America, </publisher> <address> Washington, DC 1984. </address>
Reference-contexts: Sinclair and Jerrum [33] established a connection between the spectral gap and the conductance of an undirected graph. A similar result for the related, but somewhat different parameter called expansion rate was proved by Alon [3] and, independently, by Dodziuk and Kendall [23] (cf. also Diaconis and Stroock <ref> [24] </ref>). All these results may be considered as discrete versions of Cheeger's inequality in differential geometry. Theorem 3.2 If G is an undirected graph, then every eigenvalue of M satisfies 1 8 This result allows an eigenvalue near 1, which means that the graph is almost bipartite. <p> example, we may attach d i loops at each node i; for the random walk on this modified graph we get Corollary 3.3 For any starting distribution , any A V and any t 0, fi fi t (A) (A) fi 1 ^ 1 8 : See Diaconis and Stroock <ref> [24] </ref>, Mihail [40], Fill [29], and also Lovasz and Simonovits [35] for sharper bounds and for extensions to the directed case. 4 Stopping rules and exit frequencies Examples. There are several examples of "stopping rules" that can achieve specified distributions in an elegant or surprising manner.
Reference: [25] <author> M. Dyer, A. Frieze and R. Kannan, </author> <title> A random polynomial time algorithm for estimating volumes of convex bodies, </title> <booktitle> Proc. 21st Annual ACM Symposium on the Theory of Computing (1989), </booktitle> <pages> 375-381. </pages>
Reference-contexts: Lovasz and P. Winkler Much of this was motivated by applications to computer science. Perhaps the most important of these (though certainly not the only one) is sampling by random walk (see, e.g., [21], [33], <ref> [25] </ref>). This method is based on the fact that (at least for connected non-bipartite undirected graphs, which is easy to guarantee), the distribution of the current node after t steps tends to a well-defined distribution , called the stationary distribution (which is uniform if the graph is regular).
Reference: [26] <author> A. </author> <title> Engel, The probabilistic abacus, Educ. </title> <journal> Stud. in Math. </journal> <volume> 6 (1975), </volume> <pages> 1-22. </pages>
Reference-contexts: We call this step firing a node. This step is repeated as often as we wish or until no node remains that can be fired. Procedures equivalent to chip-firing games were introduced, independently, at least three times (not counting the obvious similarity to neural nets, which remains unexplored). Engel <ref> [26] </ref>, [27] considered a procedure he called the "probabilistic abacus", as a method of determining the limit distribution of certain Markov chains by combinatorial means. Spencer [45] introduced the special case when the underlying graph is a path, as a tool in analyzing a certain "balancing" game.
Reference: [27] <author> A. </author> <title> Engel, Why does the probabilistic abacus work? Educ. </title> <journal> Stud. in Math. </journal> <volume> 7 (1976), </volume> <pages> 59-69. </pages>
Reference-contexts: This step is repeated as often as we wish or until no node remains that can be fired. Procedures equivalent to chip-firing games were introduced, independently, at least three times (not counting the obvious similarity to neural nets, which remains unexplored). Engel [26], <ref> [27] </ref> considered a procedure he called the "probabilistic abacus", as a method of determining the limit distribution of certain Markov chains by combinatorial means. Spencer [45] introduced the special case when the underlying graph is a path, as a tool in analyzing a certain "balancing" game.
Reference: [28] <author> K. Eriksson, </author> <title> No polynomial bound for the chip-firing game on directed graphs, </title> <journal> Proc. Amer. Math. Soc. </journal> <volume> 112 (1991), </volume> <pages> 1203-1205. </pages> <note> Mixing of Random Walks 35 </note>
Reference-contexts: This implies that X d i z i = H (t; ) T mix : Hence we get: Theorem 6.7 The number of chips moved during a terminating game on an undirected graph G is at most mT mix . Mixing of Random Walks 29 Eriksson <ref> [28] </ref> showed that on a directed graph (even on a graph with all but one edges undirected) a terminating game can be exponentially long. It was proved in [14] that the maximum length of a terminating game can exceed the period length by a polynomial factor only.
Reference: [29] <author> J.A. Fill, </author> <title> Eigenvalue bounds on convergence to stationary for nonreversible Markov chains, with an application to the exclusion process, </title> <journal> Ann. of Appl. Prob. </journal> <volume> 1 (1991), </volume> <pages> 62-87. </pages>
Reference-contexts: d i loops at each node i; for the random walk on this modified graph we get Corollary 3.3 For any starting distribution , any A V and any t 0, fi fi t (A) (A) fi 1 ^ 1 8 : See Diaconis and Stroock [24], Mihail [40], Fill <ref> [29] </ref>, and also Lovasz and Simonovits [35] for sharper bounds and for extensions to the directed case. 4 Stopping rules and exit frequencies Examples. There are several examples of "stopping rules" that can achieve specified distributions in an elegant or surprising manner.
Reference: [30] <author> A. Gabrielov, Avalanches, sandpiles, </author> <title> and Tutte decomposition for directed graphs, </title> <note> preprint (1993). </note>
Reference-contexts: The reader may recognize that this determinant is just the number of spanning arborescences of G rooted at s, by the "Matrix-Tree Theorem" of Tutte. This relation is explained and exploited in <ref> [30] </ref>, [31]. There are many characterizations of recurrent positions. For example, a position p is recurrent if and only if there exists a position q with p i q i for each node i 6= s such that the avalanche starting from q ends with p.
Reference: [31] <author> A. Gabrielov, </author> <note> Asymmetric abelian avalanches and sandpiles, preprint (1993). </note>
Reference-contexts: The reader may recognize that this determinant is just the number of spanning arborescences of G rooted at s, by the "Matrix-Tree Theorem" of Tutte. This relation is explained and exploited in [30], <ref> [31] </ref>. There are many characterizations of recurrent positions. For example, a position p is recurrent if and only if there exists a position q with p i q i for each node i 6= s such that the avalanche starting from q ends with p.
Reference: [32] <author> B. Ghosh and S. Muthukrishnan, </author> <title> Dynamic load balancing by random matchings, </title> <journal> J. Comp. Sys. </journal> <note> Sci, to appear. </note>
Reference-contexts: This is quite similar in spirit to random walks on a regular graph, where "probability" is passed along the edges and eventually equalized. Indeed, upper and lower bounds on the time needed to equalize the loads ([2], <ref> [32] </ref>) involve parameters familiar from the theory of random walks: expansion rate, conductance, eigenvalue gap.
Reference: [33] <author> M.R. Jerrum and A. Sinclair, </author> <title> Approximating the permanent, </title> <journal> SIAM J. Comput. </journal> <volume> 18 (1989), </volume> <pages> 1149-1178. </pages>
Reference-contexts: Lovasz and P. Winkler Much of this was motivated by applications to computer science. Perhaps the most important of these (though certainly not the only one) is sampling by random walk (see, e.g., [21], <ref> [33] </ref>, [25]). This method is based on the fact that (at least for connected non-bipartite undirected graphs, which is easy to guarantee), the distribution of the current node after t steps tends to a well-defined distribution , called the stationary distribution (which is uniform if the graph is regular). <p> Lovasz and P. Winkler from S to V n S. So can be viewed as a certain measure of how independent consecutive nodes of the random walk are. Sinclair and Jerrum <ref> [33] </ref> established a connection between the spectral gap and the conductance of an undirected graph. A similar result for the related, but somewhat different parameter called expansion rate was proved by Alon [3] and, independently, by Dodziuk and Kendall [23] (cf. also Diaconis and Stroock [24]).
Reference: [34] <author> L. Lovasz, </author> <title> Random walks on graphs: a survey, in: Combinatorics, </title> <editor> Paul Erd-os is Eighty, (eds. D. Miklos, V.T.Sos and T. Sz-onyi) J. </editor> <title> Bolyai Math. </title> <journal> Soc., </journal> <volume> Vol. </volume> <pages> II, </pages> <note> to appear. </note>
Reference-contexts: Therefore, combinatorial techniques that yield only bounds on the mixing rate and mixing time are often preferable. Two main techniques that have Mixing of Random Walks 3 been used are coupling and conductance. We only give a brief discussion of the second; see <ref> [34] </ref> for more details. Recent work by the authors provides a further method to prove bounds on the mixing time. Our work was motivated by the following observation. <p> In fact, they are closely tied to the smallest stationary probability ^. Bjorner and Lovasz proved in [14] that H (G) i2V i ; (3) which, together with the trivial lower bound, implies that 1 1 H (G) ^ Hitting times have many interesting combinatorial and algebraic properties; see <ref> [34] </ref> for several of these. We only state here two special properties, for later reference. <p> A more detailed survey, at least in the case of undirected graphs, can be found in <ref> [34] </ref>. The matrix M has eigenvalue 1, with corresponding left eigenvector and corresponding right eigenvector 1, the all-1 vector on V . It follows from the Frobenius-Perron Theorem that every other eigenvalue satisfies jj 1 and is G non-periodic, then in fact jj &lt; 1.
Reference: [35] <author> L. Lovasz and M. Simonovits, </author> <title> Random walks in a convex body and an improved volume algorithm, Random Structures and Alg. </title> <booktitle> 4 (1993), </booktitle> <pages> 359-412. </pages>
Reference-contexts: i; for the random walk on this modified graph we get Corollary 3.3 For any starting distribution , any A V and any t 0, fi fi t (A) (A) fi 1 ^ 1 8 : See Diaconis and Stroock [24], Mihail [40], Fill [29], and also Lovasz and Simonovits <ref> [35] </ref> for sharper bounds and for extensions to the directed case. 4 Stopping rules and exit frequencies Examples. There are several examples of "stopping rules" that can achieve specified distributions in an elegant or surprising manner. We consider two; several more are mentioned in [38]. <p> The way out is to Mixing of Random Walks 19 do some kind of averaging: the (somewhat improperly named) "continuous time" model corresponds to choosing t from a Poisson distribution, while the "lazy walk" trick (see e.g. Lovasz and Simonovits <ref> [35] </ref> corresponds to choosing t from a binomial distribution. It turns out that none of these differences mean too much, at least if we allow averaging.
Reference: [36] <author> L. Lovasz and P. Winkler, </author> <title> A note on the last new vertex visited by a random walk, </title> <editor> J. </editor> <booktitle> Graph Theory 17 (1993), </booktitle> <pages> 593-596. </pages>
Reference-contexts: This particular method does not generalize; in fact, apart from the complete graph, the cycle is the only graph which enjoys this property (see <ref> [36] </ref>). Consider another quite simple graph, the cube, which we view as the graph of vertices and edges of [0; 1] n . <p> To be specific, say we want t i (9=10) i for all i. (In <ref> [36] </ref>, the dependence on a parameter c in place of 9=10 is also studied, but here we simplify our discussion by fixing this value.) It is not immediately clear how to compare these two definitions.
Reference: [37] <author> L. Lovasz and P. Winkler, </author> <title> Exact mixing in an unknown Markov chain, </title> <note> preprint (1994). </note>
Reference-contexts: In these considerations, we assume that the graph is known, and we put no restriction on the computation needed to decide when to stop. This requirement makes direct use of our stopping rules as sampling mechanisms unlikely. (We show in <ref> [37] </ref> that it is possible to obtain the exact stationary distribution with an unknown graph, not in as efficient a manner, although still in time polynomial in the maximum hitting time.) However, one can describe a simple rule whose implementation requires no knowledge about the graph other than its mixing time,
Reference: [38] <author> L. Lovasz and P. Winkler, </author> <title> Fast mixing in a Markov chain, </title> <note> preprint (1994). </note>
Reference-contexts: There are several examples of "stopping rules" that can achieve specified distributions in an elegant or surprising manner. We consider two; several more are mentioned in <ref> [38] </ref>. Consider the following interesting fact from folklore. Let G be a cycle of length n and start a random walk on G from a node u. <p> By definition we stop immediately if and when any halting node is entered. (But of course we may stop in other nodes too, just not all the time.) The following theorem from <ref> [38] </ref> gives an extremely useful characterization of optimality. 14 L. Lovasz and P. Winkler Theorem 4.5 A stopping rule is optimal if and only if it has a halting node. The "if" part is a trivial consequence of Theorem 4.2. <p> But Aldous [7] describes a way to do so, and comes within total variation " of the stationary distribution in time polynomial in 1=" and linear in the maximum hitting time of the graph. In <ref> [38] </ref> we describe a simple stopping rule which can reach the stationary distribution exactly, in any strongly connected digraph G. The rule requires only coin-flips for its randomization and can even be made deterministic unless the digraph is a single cycle (possibly with multiple edges).
Reference: [39] <author> L. Lovasz and P. Winkler, </author> <title> The forget time of a Markov chain, </title> <note> preprint (1994). </note>
Reference-contexts: Lovasz and P. Winkler which we call the reset time of the random walk. Trivially, T reset T mix . The following result is proved in <ref> [39] </ref>. Theorem 5.8 If the graph is undirected, then T forget = T reset . In the case of directed graphs, these two values may be arbitrarily far apart.
Reference: [40] <author> M. Mihail, </author> <title> Conductance and convergence of Markov chains: a combinatorial treatment of expanders, </title> <booktitle> Proc. 30th Ann. Symp. on Foundations of Computer Science (1989), </booktitle> <pages> 526-531. </pages>
Reference-contexts: may attach d i loops at each node i; for the random walk on this modified graph we get Corollary 3.3 For any starting distribution , any A V and any t 0, fi fi t (A) (A) fi 1 ^ 1 8 : See Diaconis and Stroock [24], Mihail <ref> [40] </ref>, Fill [29], and also Lovasz and Simonovits [35] for sharper bounds and for extensions to the directed case. 4 Stopping rules and exit frequencies Examples. There are several examples of "stopping rules" that can achieve specified distributions in an elegant or surprising manner.
Reference: [41] <author> J.W. </author> <title> Pitman, Occupation measures for Markov chains, </title> <journal> Adv. Appl. Prob. </journal> <volume> 9 (1977), </volume> <pages> 69-86. </pages>
Reference-contexts: Mixing times, hitting times, cover times and many other important parameters are closely related to the "eigenvalue gap" of this matrix, at least in the undirected case. A simpler but powerful tool is the "conservation equation" first noted by Pitman <ref> [41] </ref> (see Section 4). Chip-firing and avalanches. Another diffusion process on graphs was introduced by Bjorner, Lovasz and Shor [13] under the name of "chip-firing game". We place a pile of chips on each node of a directed graph, and then 4 L. Lovasz and P. <p> The expected number x i of times the walk leaves node i before stopping will be called the exit frequency of node i for . Clearly E = i Exit frequencies were considered by Pitman <ref> [41] </ref>; he gave the following simple but very powerful "conservation law", relating them to the starting and ending distributions: Mixing of Random Walks 13 Lemma 4.1 The exit frequencies of any stopping rule from to t satisfy the equation X i The identity expresses the simple fact that the probability of
Reference: [42] <author> W. Reisig, </author> <title> Petri Nets: An Introduction, </title> <publisher> Springer-Verlag, </publisher> <address> New York 1985. </address>
Reference: [43] <author> A. Skorokhod, </author> <title> Studies in the Theory of Random Processes, </title> <publisher> orig. pub. Addison-Wesley (1965), 2nd ed. Dover, </publisher> <address> New York 1982. </address> <note> 36 L. Lovasz and P. Winkler </note>
Reference: [44] <author> E. R. Speer, </author> <title> Asymmetric Abelian sandpile models, </title> <journal> J. Stat. Phys. </journal> <volume> 71 (1993), </volume> <pages> 61-74. </pages>
Reference-contexts: There are many characterizations of recurrent positions. For example, a position p is recurrent if and only if there exists a position q with p i q i for each node i 6= s such that the avalanche starting from q ends with p. Speer <ref> [44] </ref> gives a characterization that gives a way to test for recurrence. To describe this, we introduce a version of the period vector.
Reference: [45] <author> J. Spencer, </author> <title> Balancing vectors in the max norm, </title> <booktitle> Combinatorica 6 (1986), </booktitle> <pages> 55-66. </pages>
Reference-contexts: Engel [26], [27] considered a procedure he called the "probabilistic abacus", as a method of determining the limit distribution of certain Markov chains by combinatorial means. Spencer <ref> [45] </ref> introduced the special case when the underlying graph is a path, as a tool in analyzing a certain "balancing" game. In [4] Spencer's process was analyzed in greater detail.
Reference: [46] <author> G. Tardos, </author> <title> Polynomial bound for a chip firing game on graphs SIAM J. </title> <journal> Disc. Math 1 (1988), </journal> <pages> 397-398. </pages>
Reference-contexts: it cycle? How many chips are needed for an infinite procedure? How does one determine if a given position (distribution of chips) can be transformed into another one by firings? In the case of undirected graphs, these questions are more-or-less fully answered in [13], [14] and the work of Tardos <ref> [46] </ref>. For example, a finite procedure terminates in O (n 4 ) steps; the shortest period of a periodic game in n; the minimum number of chips that allow an infinite game is m, the number of edges. <p> observed in Mixing of Random Walks 5 [13]; the extension to the directed case is due to [14], where it was used to show that no terminating firing sequence is longer than a polynomial times the length of the period of a periodic firing sequence. (This extends the result of <ref> [46] </ref>, the directed case.) The new results on mixing times of random walks give improvements of these results. A converse inequality, conjectured in [14], will also be proved here, using the conservation equation. <p> We denote them by x i (; t ). Let us determine the exit frequencies in some simple cases. The first result is from Aldous [5]. Several related formulas could be derived using relations to electrical networks, as in [18] or <ref> [46] </ref>. <p> The number of times a given node is fired is the same in every terminating game. If a game is infinite, then every node gets fired infinitely often. In the case of undirected graphs, Tardos <ref> [46] </ref> proved a strong converse of the last assertion: Lemma 6.3 If a chip-firing game on an undirected graph is finite, then there is a node that is never fired. This assertion is analogous to Theorem 4.5 for stopping rules; however, it does not remain true for general digraphs. <p> This is of course an upper bound on the number of firings, and is never more than a factor of m larger. Tardos <ref> [46] </ref> proved that on an undirected graph, every terminating game ends in a polynomial number of steps. We sketch a new proof based on the conservation equation. Consider a game that terminates, and let z i be the number of times node i is fired.
References-found: 46

