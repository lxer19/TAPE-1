URL: http://www.stats.bris.ac.uk/~maspb/MCMC/others/robetal.ps.gz
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Convergence properties of perturbed Markov chains  
Author: by Gareth O. Roberts*, Jeffrey S. Rosenthal**, and Peter O. Schwartz*** 
Date: (November 13, 1995.)  
Abstract: Acknowledgements. We thank Neal Madras, Radford Neal, Peter Rosenthal, and Richard Tweedie for helpful conversations. This work was partially supported by EPSRC of the U.K., and by NSERC of Canada. 
Abstract-found: 1
Intro-found: 1
Reference: <author> S. </author> <title> Asmussen (1987), Applied Probability and Queues. </title> <publisher> John Wiley & Sons, </publisher> <address> New York. </address>
Reference: <author> K.B. Athreya and P. </author> <title> Ney (1978), A new approach to the limit theory of recurrent Markov chains. </title> <journal> Trans. Amer. Math. Soc. </journal> <volume> 245, </volume> <pages> 493-501. </pages>
Reference: <author> S.N. Ethier and T.G. </author> <title> Kurtz (1986), Markov processes, characterization and convergence. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: Thus, for this case we shall instead consider weak convergence, written ), and metrized by the Prohorov metric <ref> (Ethier and Kurtz, 1986, Section 3.1) </ref>, defined by d (; -) = inff* ; P (dist (X; Y ) *) * for some (X; Y ) 2 D ;- g ; where D ;- is the collection of all random variable pairs (X; Y ) taking values in X with laws <p> Recall also that k ) is equivalent to saying 12 that R R fd, for each uniformly continuous bounded function f : X ! R <ref> (Ethier and Kurtz, 1986, p. 108) </ref>. Finally, it is easily seen that k -k var d (; -) ; (3) where k -k var = sup AX j (A) -(A)j is total variation distance. We prove the two results using different approaches.
Reference: <author> A.E. Gelfand and A.F.M. </author> <title> Smith (1990), Sampling based approaches to calculating marginal densities. </title> <journal> J. Amer. Stat. Assoc. </journal> <volume> 85, </volume> <pages> 398-409. </pages>
Reference: <author> S.D. </author> <title> Jacka and G.O. Roberts (1995), Strong forms of weak convergence. </title> <type> Preprint. </type>
Reference-contexts: such that X k 0 2 C 0 , and such that if t k denotes the first non-zero return time of the process X k to the set C 0 , then lim P (X k s ; 0 s t k = t 1 ) = 1 : <ref> (For details see Jacka and Roberts, 1995.) </ref> Let f be a function on X (extended to C 0 by copying its values from C), such that jfj 1.
Reference: <author> S.P. Meyn and R.L. </author> <month> Tweedie </month> <year> (1993), </year> <title> Markov chains and stochastic stability. </title> <publisher> Springer-Verlag, London. </publisher>
Reference-contexts: Thus, geometric ergodicity is not preserved in general under small roundoff error. We then begin proving positive results. We largely concentrate on the case in which P is geometrically ergodic, with stationary distribution (), which is implied by <ref> (Meyn and Tweedie, 1993, Theorems 15.0.1 and 5.5.7) </ref> the existence of a -a.e.-finite function V : X ! [1; 1], a subset C X , and finite positive numbers fi and b, such that the (geometric) drift condition V (x) fiV (x) + b1 C (x) ; x 2 X (2) <p> It follows that P satisfies (2) with C = [0; 2]. Hence <ref> (Meyn and Tweedie, 1993) </ref>, since P is aperiodic, it has a stationary distribution and is geometrically ergodic. On the other hand, given ffi &gt; 0, set h (x) = x + ffi min (x; 1). Then h is one-to-one, onto, and continuous, with sup x2X jh (x) xj = ffi. <p> This lemma shows that perturbations of P , which have a sufficiently small effect on P V , preserve the drift condition (2) (with suitable modification of fi). To study preservation of geometric ergodicity, one must also worry about preservation of -irreducibility, aperiodicity, and the smallness of C <ref> (Meyn and Tweedie, 1993) </ref>. We have no control over these items in general. However for rounded off chains as given by (1), this is more feasible. Indeed we have Lemma 3.
Reference: <author> S.P. Meyn and R.L. </author> <month> Tweedie </month> <year> (1994), </year> <title> Computable bounds for convergence rates of Markov chains. </title> <journal> Ann. Appl. Prob. </journal> <volume> 4, </volume> <pages> 981-1011. </pages>
Reference: <author> R.M. </author> <title> Neal (1993), Probabilistic inference using Markov chain Monte Carlo methods. </title> <type> Tech. Rep. </type> <institution> CRG-TR-93-1, Dept. of Computer Science, University of Toronto. </institution>
Reference: <author> E. </author> <month> Nummelin </month> <year> (1984), </year> <title> General irreducible Markov chains and non-negative operators. </title> <publisher> Cambridge University Press. 17 G.O. Roberts and R.L. </publisher> <month> Tweedie </month> <year> (1994), </year> <title> Geometric convergence and central limit the-orems for multidimensional Hastings and Metropolis algorithms. </title> <type> Research Rep. 94-9, </type> <institution> Statistical Laboratory, University of Cambridge. </institution>
Reference: <author> J.S. </author> <title> Rosenthal (1994), Convergence of Gibbs sampler for a model related to James-Stein estimators. </title> <journal> Stat. and Comput., </journal> <note> to appear. </note>
Reference: <author> J.S. </author> <title> Rosenthal (1995), Minorization conditions and convergence rates for Markov chain Monte Carlo. </title> <journal> J. Amer. Stat. Assoc. </journal> <volume> 90, </volume> <pages> 558-566. </pages>
Reference: <author> A. </author> <title> Sinclair (1992), Improved bounds for mixing rates of Markov chains and multicom-modity flow. Combinatorics, </title> <journal> Prob., Comput. </journal> <volume> 1, </volume> <pages> 351-370. </pages>
Reference: <author> A.F.M. Smith and G.O. </author> <title> Roberts (1993), Bayesian computation via the Gibbs sampler and related Markov chain Monte Carlo methods (with discussion). </title> <journal> J. Roy. Stat. Soc. Ser. </journal> <volume> B 55, </volume> <pages> 3-24. </pages>
Reference: <author> A.D. </author> <month> Sokal </month> <year> (1989), </year> <title> Monte Carlo methods in statistical mechanics: foundations and new algorithms. </title> <institution> Dept. of Physics, New York University. Cours de Troisieme Cycle de la Physique en Suisse Romande, Lausanne, Switzerland. </institution> <month> 18 </month>
Reference-contexts: 1. Introduction. Markov chain Monte Carlo algorithms such as Gibbs sampler and Metropolis-Hastings are now widely used in statistics (Gelfand and Smith, 1990; Smith and Roberts, 1993), physical chemistry <ref> (Sokal, 1989) </ref>, and computer science (Sinclair, 1992; Neal, 1993). To explore a complicated probability distribution (), a Markov chain P (x; ) is defined such that () is stationary for the Markov chain. Hopefully, the Markov chain will converge in distribution to (), allowing for inferences to be drawn.
References-found: 14

