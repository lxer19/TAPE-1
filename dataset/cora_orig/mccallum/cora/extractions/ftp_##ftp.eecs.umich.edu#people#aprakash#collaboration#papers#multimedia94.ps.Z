URL: ftp://ftp.eecs.umich.edu/people/aprakash/collaboration/papers/multimedia94.ps.Z
Refering-URL: http://www.eecs.umich.edu/~mathur/
Root-URL: http://www.cs.umich.edu
Email: Email: fmathur,aprakashg@eecs.umich.edu  
Title: Protocols for Integrated Audio and Shared Windows in Collaborative Systems  
Author: Amit G. Mathur and Atul Prakash 
Address: Ann Arbor, MI 48109.  
Affiliation: Department of Electrical Engineering and Computer Science University of Michigan,  
Abstract: This paper describes the architecture and protocols for integrating real-time audio and shared windows in computer-supported cooperative work (CSCW) environments. Such applications require that actions on shared windows be synchronized with accompanying audio. We give a characterization of this synchronization problem and propose an architecture for handling audio-enhanced cooperative work. We present a protocol for synchronizing the audio stream and window-event streams and evaluate its performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S.R. Ahuja, J.R. Ensor, and D.N. Horn, </author> <title> The Rapport Multimedia Conferencing System, </title> <booktitle> in Proc. of the Conf. on Office Information Systems, </booktitle> <address> Palo Alto, CA, </address> <month> Mar. </month> <year> 1988, </year> <pages> pp. 1-8. </pages>
Reference-contexts: The goal of our work is to integrate audio with shared windows and allow for a close synchronization of window-events with accompanying audio. Our work differs from previous work on multimedia collaborative systems <ref> [1, 2, 6, 7] </ref> in the level of integration supported. Earlier systems allowed for audio conferencing with little or no notion of synchronizing audio with work in shared workspaces. In our system it is possible to synchronize audio with activities in shared windows, allowing for enhanced synchronous collaboration.
Reference: [2] <author> L. Aguilar, J.J. Garcia-Luna-Aceves, D. Moran, E.J. Craighill, and R. Brungart, </author> <title> Architecture for a Multimedia Teleconferencing System, </title> <booktitle> in Proc. of the ACM SIGCOMM, </booktitle> <month> Aug. </month> <year> 1986, </year> <pages> pp. 126-136. </pages>
Reference-contexts: The goal of our work is to integrate audio with shared windows and allow for a close synchronization of window-events with accompanying audio. Our work differs from previous work on multimedia collaborative systems <ref> [1, 2, 6, 7] </ref> in the level of integration supported. Earlier systems allowed for audio conferencing with little or no notion of synchronizing audio with work in shared workspaces. In our system it is possible to synchronize audio with activities in shared windows, allowing for enhanced synchronous collaboration.
Reference: [3] <author> P.T. Brady, </author> <title> A Technique for Investigating On-Off Patterns of Speech, </title> <journal> The Bell System Technical Journal, </journal> <volume> Vol. 44, No. 1, </volume> <month> Jan. </month> <year> 1965, </year> <pages> pp. 1-22. </pages>
Reference-contexts: The first deals with silence detection, while the second deals with absence of streams. In typical voice conversations, audio is generated in bursts, referred to as talkspurts, that are separated by pauses <ref> [3] </ref>. Using silence detection, it is possible to send audio packets only during the talkspurts, thus saving bandwidth.
Reference: [4] <author> C. R. Clauer et al, </author> <title> A Prototype Upper Atmospheric Research Collaboratory (UARC), </title> <journal> EOS, Trans. Amer. Geophys. Union, </journal> <volume> 74, </volume> <year> 1993. </year>
Reference-contexts: synchronization of audio and shared windows and then give general characteristics of such systems. 2.1 An Example Our example comes from the Upper Atmospheric Research Collaboratory (UARC) project, a multi-disciplinary effort linking research in computer science, behavioral science, and upper atmosphere and space physics, here at the University of Michigan <ref> [4, 5] </ref>. As part of this project we are developing a collaborative system to provide space scientists with the means to effectively view and analyze data collected by various remote instruments, present ones being located in Greenland.
Reference: [5] <author> C.R. Clauer, J.D. Kelly, T.J. Rosenberg, C.E.P. Stauning, E. Friis-Christensen, R.J. Niciejewski, T.L. Killeen, S. Mende, T.E. Weymouth, A. Prakash, S.E. McDaniel, G.M. Olson, T.A. Finholt, and D.E. Atkins, </author> <title> The Upper Atmospheric Research Collaboratory: A Testbed for Electronically supported Scientific Collaboration, </title> <journal> EOS, Trans. Amer. </journal> <note> Geophys. Union, in press, </note> <year> 1994. </year>
Reference-contexts: synchronization of audio and shared windows and then give general characteristics of such systems. 2.1 An Example Our example comes from the Upper Atmospheric Research Collaboratory (UARC) project, a multi-disciplinary effort linking research in computer science, behavioral science, and upper atmosphere and space physics, here at the University of Michigan <ref> [4, 5] </ref>. As part of this project we are developing a collaborative system to provide space scientists with the means to effectively view and analyze data collected by various remote instruments, present ones being located in Greenland.
Reference: [6] <author> T. Crowler, P. Milazzo, E. Baka, H. Forsdick, and R. Tomlinson, MMConf: </author> <title> An Infrastructure for Building Shared Multimedia Applications, </title> <booktitle> in Proc. of the 3rd. Conf. on Computer Supported Cooperative Work, </booktitle> <month> Oct. </month> <year> 1990, </year> <pages> pp. 329-342. </pages>
Reference-contexts: The goal of our work is to integrate audio with shared windows and allow for a close synchronization of window-events with accompanying audio. Our work differs from previous work on multimedia collaborative systems <ref> [1, 2, 6, 7] </ref> in the level of integration supported. Earlier systems allowed for audio conferencing with little or no notion of synchronizing audio with work in shared workspaces. In our system it is possible to synchronize audio with activities in shared windows, allowing for enhanced synchronous collaboration.
Reference: [7] <author> E. Craighill, R. Lang, M. Fong, K. Skinner, </author> <month> CECED: </month>
Reference-contexts: The goal of our work is to integrate audio with shared windows and allow for a close synchronization of window-events with accompanying audio. Our work differs from previous work on multimedia collaborative systems <ref> [1, 2, 6, 7] </ref> in the level of integration supported. Earlier systems allowed for audio conferencing with little or no notion of synchronizing audio with work in shared workspaces. In our system it is possible to synchronize audio with activities in shared windows, allowing for enhanced synchronous collaboration.
References-found: 7

