URL: http://s2k-ftp.cs.berkeley.edu:8000/sequoia/tech-reports/s2k-91-5/s2k-91-05.ps.Z
Refering-URL: http://s2k-ftp.cs.berkeley.edu:8000/sequoia/tech-reports/s2k-91-5/
Root-URL: http://www.cs.berkeley.edu
Title: AN OVERVIEW OF THE SEQUOIA 2000 PROJECT  
Author: Michael Stonebraker 
Abstract: Sequoia 2000 Technical Report 91/5 Computer Science Division, EECS Department University of California Berkeley, Ca. 94720 Abstract Achieving the goals of the U.S. Global Change Research Program will depend not only on improved measurement systems, but also on improved data systems that will allow scientists to manipulate the resulting large-scale data sets and climate system models, as well as compare model results with observations. New modes of research, especially the synergistic interactions between observations and model-based simulations, will require massive amounts of diverse data to be stored, organized, accessed, distributed, visualized, and analyzed. Computer scientists and environmental researchers at several UC campuses are collaborating to address these challenges. Refinements in computing specifically involving storage, networking, file systems, extensible data base management, and visualization will be applied to specific Global Change applications. We have named this project Sequoia 2000, after the giant trees of the Sierra Nevada, the largest organisms on the Earth's land surface. 
Abstract-found: 1
Intro-found: 1
Reference: [BAIL91] <author> Bailey, M.J., </author> <title> ``Scientific Visualization for a Large, Remotely-Distributed User Community,'' </title> <booktitle> Graphicon Conference Proceedings, </booktitle> <pages> pp. </pages> <month> 11-26 (February </month> <year> 1991). </year>
Reference-contexts: We have designed a standard language for representing image files, a so-called inter-lingua, and are currently designing conversion tools that convert from popular file formats to and from our interlingua. Currently, more than 20 popular formats are understood, and more are under development <ref> [BAIL91] </ref>. Our third visualization effort concerns the architecture of such tools. Currently, visualization tools perform two separate functions, namely they provide data rendering and data manipulation. Hence, it is possible in many systems to overlay two images data manipulation) and then place the result on the screen (rendering).
Reference: [BELK87] <author> Belkin, N. and Croft, W., </author> <title> ``Retrieval Techniques,'' </title> <journal> Annual Review of Information Science and Technology, </journal> <volume> vol. 22, </volume> <pages> pp. </pages> <month> 109-145 </month> <year> (1987). </year>
Reference-contexts: Finally, mature techniques exist for indexing and retrieving textual documents based on automatic and manual indexing using keywords, thesaurus terms, and classification schemes. Statistically-based probabilistic match techniques have been developed that present the "best-matching" documents to the user in response to an imprecise query <ref> [BELK87, LARS91] </ref>. These techniques must be extended to deal with indexing large collections of complete textual documents, rather than just collections of document surrogates (i.e. titles and abstracts). Tools are also needed to allow users to browse this repository to find objects relevant to their work.
Reference: [CEES91] <institution> Committee on Earth and Environmental Sciences, Our Changing Planet: The FY 1992 U.S. Global Change Research Program, Office of Science and Technology Policy, </institution> <address> Washington, D.C. </address> <year> (1991). </year>
Reference-contexts: and involving changes in photosynthesis, respiration, transpiration, and trace gas exchange, both on the land and in the ocean. 1 Environmental Scientists, typically in Earth Sciences departments, are addressing these concerns and report considerable shortcomings in current information systems that impair their ability to make research progress on these problems <ref> [CEES91] </ref>. Specifically, they report the five shortcomings indicated in the next subsection. 1.2. Shortcomings of Current Information Systems 1) Current storage management system technology is inadequate to store and access the massive amounts of data required. The data requirements in these problem areas are massive.
Reference: [CHEN92] <author> Chen, J. et. al., </author> <note> "The Sequoia 2000 Object Browser," (elsewhere in this proceedings). </note>
Reference-contexts: THE SEQUOIA 2000 RESEARCH PLAN Sequoia 2000 is organized around an interconnected collection of hardware, file system, DBMS, networking, visualization, and repository projects. We discuss each in turn, concentrating on issues not covered in the companion papers <ref> [KATZ92, FERR92, CHEN92] </ref>. 2.1. Hardware Concepts The Global Change research groups wish to store approximately 100 Tbytes of data at reasonable cost and in a reasonable footprint. <p> As our second approach to the repository, we expect to explore this "pan and zoom" paradigm, popularized for military ships by SDMS [HERO80]. Our last companion paper presents the initial design of our browsing system <ref> [CHEN92] </ref>.
Reference: [CPM91] <institution> Committee on Physical, Mathematical and Engineering Sciences, Grand Challenges: High Performance Computing and Communications, Office of Science and Technology Policy, </institution> <address> Washington, D.C. </address> <year> (1991). </year>
Reference-contexts: 1. INTRODUCTION 1.1. Background One of the most important challenges that will confront the scientific and computing communities during the 1990s is the development of models to predict the impact of Global Change on the planet Earth <ref> [CPM91] </ref>.
Reference: [FERR90] <author> Ferrari, D. and Verma, D., </author> <title> "A Scheme for Real-time Channel Establishment in Wide-area Networks," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <month> April </month> <year> 1990. </year>
Reference-contexts: Although they can buffer data at their client workstations, and then render the data at a smooth rate onto their screen, it would be preferable for the network (as well as the rest of the system) to be able to make guarantees about information delivery. In <ref> [FERR90] </ref> algorithms are presented which make such delivery guarantees, and we are in the process of migrating these algorithms to the Sequoia network. Although image sequences require high bandwidth and low delay guarantees, these guarantees are often statistical in nature.
Reference: [FERR92] <author> Ferrari, D. et. al., </author> <title> "Network Issues for Sequoia 2000," </title> <note> (elsewhere in this proceedings). </note>
Reference-contexts: THE SEQUOIA 2000 RESEARCH PLAN Sequoia 2000 is organized around an interconnected collection of hardware, file system, DBMS, networking, visualization, and repository projects. We discuss each in turn, concentrating on issues not covered in the companion papers <ref> [KATZ92, FERR92, CHEN92] </ref>. 2.1. Hardware Concepts The Global Change research groups wish to store approximately 100 Tbytes of data at reasonable cost and in a reasonable footprint. <p> We have several research ideas which we propose to explore on this network, as discussed in the companion paper <ref> [FERR92] </ref>. First, routers and switches are typically constructed from specialized hardware components. On the other hand, we expect general purpose RISC machines will be fast enough to serve this function on future networks without resorting to special purpose iron.
Reference: [HAAS90] <author> Haas, L. et al., </author> <title> ``Starburst Mid-Flight: As the Dust Clears,'' </title> <journal> IEEE Transactions on Knowledge and Data Engineering (1990). </journal>
Reference-contexts: Current commercial relational data base systems (e.g. DB 2, RDB, ORACLE, INGRES, etc.) are not good at managing these kinds of data. During the last several years a variety of next generation DBMSs have been built, including IRIS [WILK90], ORION [KIM90], POSTGRES [STON90], and Starburst <ref> [HAAS90] </ref>. The more general of these systems appear to be usable, at least to some extent, for point, vector, and text data. However, none are adequate for the full range of needed capabilities. 5) It is extremely difficult to share the objects noted above with other interested researchers.
Reference: [HERO80] <author> Herot, C., ``SDMS: </author> <title> A Spatial Data Base System,'' </title> <journal> ACM TODS (1980). </journal>
Reference-contexts: Zooming into an icon would then cause the icon to be replaced by a window with the more detailed data. As our second approach to the repository, we expect to explore this "pan and zoom" paradigm, popularized for military ships by SDMS <ref> [HERO80] </ref>. Our last companion paper presents the initial design of our browsing system [CHEN92].
Reference: [KATZ89] <author> Katz, R., et al., </author> <title> ``Disk System Architectures for High Performance Computing,'' </title> <journal> Proceedings of the IEEE, </journal> <note> Special Issue on Supercomputing 10 (December 1989). </note>
Reference-contexts: Our first technique is based on the ideas developed in RAID technology [PATT88], a new way to construct high bandwidth, high availability disk systems based on arrays of small form factor disks <ref> [KATZ89] </ref>. High bandwidth comes from striping data across many disk actuators and harnessing this inherent parallelism to dramatically improve transfer rates. We are investigating applying these techniques to systems which include tertiary memory, and are considering striping in a wide variety of ways as noted in [KATZ92].
Reference: [KARL89] <author> Karlson, G. and Vetterli, M., </author> <title> ``Packet Video and its Integration into the Network Architecture,'' </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 8, </volume> <pages> pp. </pages> <month> 380-390 </month> <year> (1990). </year> <month> [KATZ92] </month>
Reference-contexts: This is particularly relevant when one is fast-forwarding through a sequence of images; supporting full resolution might not be possible, and users might be willing to accept a lower resolution picture in return for faster movement. One approach to this problem is hierarchical coding <ref> [KARL89] </ref>, whereby a unit of information such as an image is decomposed into a set of ordered sub-images. A selected subset of these may be re-composed to obtain various levels of resolution of the original image.
Reference: [KIM90] <author> Kim, W. et al., </author> <title> ``Architecture of the ORION Next-Generation Database System,'' </title> <journal> IEEE Transactions on Knowledge and Data Engineering (March 1990). </journal>
Reference-contexts: Current commercial relational data base systems (e.g. DB 2, RDB, ORACLE, INGRES, etc.) are not good at managing these kinds of data. During the last several years a variety of next generation DBMSs have been built, including IRIS [WILK90], ORION <ref> [KIM90] </ref>, POSTGRES [STON90], and Starburst [HAAS90]. The more general of these systems appear to be usable, at least to some extent, for point, vector, and text data.
Reference: [LARS91] <author> Larson, R., </author> <title> ``Classification Clustering, Probabilistic Information Retrieval and the Online Catalog,'' </title> <journal> Library Quarterly, </journal> <volume> vol. </volume> <month> 61 (April </month> <year> 1991). </year>
Reference-contexts: Finally, mature techniques exist for indexing and retrieving textual documents based on automatic and manual indexing using keywords, thesaurus terms, and classification schemes. Statistically-based probabilistic match techniques have been developed that present the "best-matching" documents to the user in response to an imprecise query <ref> [BELK87, LARS91] </ref>. These techniques must be extended to deal with indexing large collections of complete textual documents, rather than just collections of document surrogates (i.e. titles and abstracts). Tools are also needed to allow users to browse this repository to find objects relevant to their work.
Reference: [LELE87] <author> Lelewer, D. and Hirschberg, D., </author> <title> ``Data Compression,'' </title> <journal> ACM Computing Surveys, </journal> <volume> vol. </volume> <month> 19 (September </month> <year> 1987). </year>
Reference-contexts: We are investigating applying these techniques to systems which include tertiary memory, and are considering striping in a wide variety of ways as noted in [KATZ92]. Besides striping, a second method for improving the transfer rate (and incidentally the capacity) of the storage system is compression <ref> [LELE87, MARK91] </ref>. Depending on the type of data present, size reductions from a factor of 2 - 30 have been reported. However, the compression technique which must be applied is specific to the type of data involved, and there is likely to be high leverage from hardware support.
Reference: [LYNC88] <author> Lynch, C. and Stonebraker, M., </author> <title> ``Extended User-Defined Indexing with Application to Textual Databases,'' </title> <booktitle> Proceedings 1988 VLDB Conference, </booktitle> <address> Los Angeles (1988). </address>
Reference-contexts: To perform this search requires indexes on the result of a classification function and not on the raw image. Second, indexing functions for images and text often return a collection of values for which efficient access is desired <ref> [LYNC88] </ref>. For example, a keyword extraction function might return a set of relevant keywords for a document, and the user desires indexing on all keywords. In this 7 case one desires instance indexing on the set of values returned by a function.
Reference: [MARK91] <author> Markoff, J., </author> <title> ``A System to Speed Computer Data ,'' New York Times, </title> <editor> p. </editor> <month> C7 (January 23, </month> <year> 1991). </year>
Reference-contexts: We are investigating applying these techniques to systems which include tertiary memory, and are considering striping in a wide variety of ways as noted in [KATZ92]. Besides striping, a second method for improving the transfer rate (and incidentally the capacity) of the storage system is compression <ref> [LELE87, MARK91] </ref>. Depending on the type of data present, size reductions from a factor of 2 - 30 have been reported. However, the compression technique which must be applied is specific to the type of data involved, and there is likely to be high leverage from hardware support.
Reference: [MULL91] <author> Muller, K. and Pasquale, J., </author> <title> "A High Performance Multi-structured File System Design," </title> <booktitle> Proc. 13th ACM Symposium on Operating Systems Principles, </booktitle> <address> Pacific Grove, Ca., </address> <month> October </month> <year> 1991. </year>
Reference-contexts: User files are byte-addressible variable length, byte strings, that can be hierarchically organized into directories. User programs then can address files using the file system. It is clear that one or more storage managers are desirable. Moreover, the argument is made in <ref> [MULL91] </ref> that several file systems are desirable, and the file system switch being implemented in OSF/1 supports this concept. Many traditional data base systems, e.g. INGRES and ORACLE, run using the model of INGRES maps each relation into an operating system file.
Reference: [PASQ92] <author> Pasquale, J. et. al., </author> <title> "Internet Throughput and Delay Measurements between Sequoia 2000 Sites", </title> <note> (in preparation). </note>
Reference-contexts: As a result, Sequoia is planning to use conventional RISC computers as routers and switches. Initial measurements have been encouraging as indicated in <ref> [PASQ92] </ref>. Second, our network must carry primarily data traffic, composed entirely of large objects.
Reference: [PATT88] <author> Patterson, D. et al., </author> <title> ``A Case for Redundant Arrays of Inexpensive Disks,'' </title> <booktitle> Proceedings 1988 ACM-SIGMOD Conference on Management of Data, </booktitle> <address> Chicago, IL (1988). </address>
Reference-contexts: This system, called BIGFOOT I, should be operational in early 1992. As noted in the companion paper in this volume [KATZ92], we are studying two different techniques to achieve high performance. Our first technique is based on the ideas developed in RAID technology <ref> [PATT88] </ref>, a new way to construct high bandwidth, high availability disk systems based on arrays of small form factor disks [KATZ89]. High bandwidth comes from striping data across many disk actuators and harnessing this inherent parallelism to dramatically improve transfer rates.
Reference: [RANA90] <author> Ranade, S. and Ng, J., </author> <title> Systems Integration for Write-Once Optical Storage, Meckler, </title> <address> Westport, CT (1990). </address>
Reference-contexts: Hardware Concepts The Global Change research groups wish to store approximately 100 Tbytes of data at reasonable cost and in a reasonable footprint. Obviously, a critical aspect of a storage management system subsystem of this size will be its support for managing a complex hierarchy of diverse storage media <ref> [RANA90] </ref>. Our goal is to build such a storage system, denoted BIGFOOT, capable of this level of capacity and with sufficient speed to support the traffic which will be directed to it.
Reference: [ROSE91] <author> Rosenblum, M., and Ousterhout, J., </author> <title> ``The Design and Implementation of a Log-Structured File System,'' </title> <note> submitted for publication, </note> <month> February </month> <year> 1991. </year>
Reference-contexts: We are in the process of bringing up all three file systems in our environment, and a performance "bake-off" is planned. In the future, we are planning on other innovative tertiary memory file systems, including one based on ideas from the log structured file system (LFS) <ref> [ROSE91] </ref>. Moreover, we are experimenting with four and five level hierarchies, and migration algorithms that could take advantage of more than three levels. 2.2.1. Data Management Issues In some environments it is desirable to use a DBMS rather than the file system to manage collections of large objects.
Reference: [STON90] <author> Stonebraker, M. et al., </author> <title> ``The Implementation of POSTGRES,'' </title> <journal> IEEE Transactions on Knowledge and Data Engineering (March 1990). </journal>
Reference-contexts: Current commercial relational data base systems (e.g. DB 2, RDB, ORACLE, INGRES, etc.) are not good at managing these kinds of data. During the last several years a variety of next generation DBMSs have been built, including IRIS [WILK90], ORION [KIM90], POSTGRES <ref> [STON90] </ref>, and Starburst [HAAS90]. The more general of these systems appear to be usable, at least to some extent, for point, vector, and text data. <p> Data Management Issues In some environments it is desirable to use a DBMS rather than the file system to manage collections of large objects. Hence, we propose to extend the next-generation DBMS POSTGRES <ref> [STON90] </ref> to effectively manage Global Change data. There are three avenues of extension that we propose to explore. First, POSTGRES has been designed to effectively manage point, vector and text data. However, satellite data are series of large multidimensional arrays.
Reference: [STON91] <author> Stonebraker, M., </author> <title> ``Managing Persistent Objects in a Multi-level Store,'' </title> <booktitle> Proceedings 1990 ACM SIGMOD Conference on Management of Data, </booktitle> <address> Denver, CO (1990). </address>
Reference-contexts: Such migration might simply depend on the algorithms of the underlying file system discussed above to manage storage. However, the DBMS understands the logical structure of the data and can make more intelligent partitioning decisions as noted in <ref> [STON91] </ref>. The third area where we propose investigations concerns indexing. The conventional DBMS paradigm is to provide value indexing. Hence, one can designate one or more fields in a record as indexed, and POSTGRES will build the appropriate kind of index on the data in the required fields.
Reference: [STON92] <author> Stonebraker, M,. and Olson, M., </author> <title> "Large Object Support in POSTGRES," </title> <note> (in preparation). </note>
Reference-contexts: POSTGRES has been written so it can function under either the model in Figure 1 or the model in Figure 2. Moreover, it has several notions for supporting large objects <ref> [STON92] </ref>. Hence, support for files can be provided as suggested in Figure 3. Here, a hierarchical file system is supported on top of the DBMS.
Reference: [WILK90] <author> Wilkinson, K. et al., </author> <title> ``The IRIS Architecture and Implementation,'' </title> <journal> IEEE Transactions on Knowledge and Data Engineering (March 1990). </journal> <volume> 11 </volume>
Reference-contexts: Current commercial relational data base systems (e.g. DB 2, RDB, ORACLE, INGRES, etc.) are not good at managing these kinds of data. During the last several years a variety of next generation DBMSs have been built, including IRIS <ref> [WILK90] </ref>, ORION [KIM90], POSTGRES [STON90], and Starburst [HAAS90]. The more general of these systems appear to be usable, at least to some extent, for point, vector, and text data.
References-found: 25

