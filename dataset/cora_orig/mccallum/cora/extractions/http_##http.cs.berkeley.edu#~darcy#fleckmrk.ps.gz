URL: http://http.cs.berkeley.edu/~darcy/fleckmrk.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~darcy/research.html
Root-URL: 
Email: -darcy,dgay-@CS.Berkeley.EDU  
Title: FLECKmarks Measuring Floating Point Performance using a F ul L IEE E C ompliant Arithmetic
Author: Joseph D. Darcy and David Gay 
Abstract: 1. Abstract 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Anderson, Z. Bai, C. Bischof, J. Demmel, J. Dongarra, J. Du Croz, A. Gennbaum, S. Hammerling, A. McKenney, S. Ostrouchov, and D. Sorensen, </author> <note> LAPACK Users Guide, Release 1.0 SIAM, Philadelphia, </note> <year> 1992. </year>
Reference-contexts: Two of our benchmarks are based on existing FORTRAN code, and one is written in C. The two FORTRAN benchmarks are modified LAPACK <ref> [1] </ref> routines to get higher performance from exploiting IEEE features. They come from work of J. Demmel and X. Li [3]. same set of flags.
Reference: [2] <author> ANSI/IEEE, </author> <title> New York, IEEE Standard for Binary Floating Point Arithmetic, </title> <editor> Std 754-1985 ed., </editor> <year> 1985 </year>
Reference-contexts: When restricted to a declared subset of the standard, these programs should produce identical results on all conforming systems <ref> [2] </ref>. Since its introduction, IEEE 754 has become universally available on all significant microprocessors for PCs and workstations (Intel x86 line and clones, Motorola 68000, Power PC, HP PA RISC, Sun SPARC, SGI MIPS, and DEC Alpha, among others). <p> Section 5 discusses related work and presents our conclusions. 3. Programming Language Extensions for IEEE 754 Arithmetic 3.1 Brief Description of an IEEE 754 Machine Before discussing the language extensions or benchmarks, the features of IEEE floating point need to be briefly summarized. The standard <ref> [2] </ref> discusses these features in much greater detail and should be referred to for more complete explanations.
Reference: [3] <author> James W. Demmel and Xiaoye Li, </author> <title> Faster Numerical Algorithms via Exception Handling, </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol 43, NO 8, </volume> <month> August </month> <year> 1994, </year> <pages> pp. 983-992. </pages>
Reference-contexts: Programming language support for IEEE 754 was discussed before the standard was adopted [5]. Even if not employed directly, many users could benefit from more efficient libraries written using IEEE 754s advanced capabilities <ref> [3] </ref>. Due to the ubiquity of IEEE 754, programming languages should now support IEEE 754 specific features not available under other floating point standards. IEEE 754 was designed to allow sophisticated numerical algorithms, programming languages should not hinder that effort by lack of expressiveness. <p> Two of our benchmarks are based on existing FORTRAN code, and one is written in C. The two FORTRAN benchmarks are modified LAPACK [1] routines to get higher performance from exploiting IEEE features. They come from work of J. Demmel and X. Li <ref> [3] </ref>. same set of flags. However, to better compare to the Linpack and FLECK results, we did not degrade the optimization levels of the other nine benchmarks due to buggy optimizers on one program. <p> It is thus a partial repetition of the results of <ref> [3] </ref> on more recent machines. Table 10 lists the speedups for both benchmarks and both inputs when compared against the LAPACK version of the algorithm (which do not use any IEEE features). <p> J. Hauser in [6] and [7] provides detailed examples justifying the usefulness of exception handling in floating point computations. Different language interfaces to exceptions are discussed in [7]. J. Demmel and X. Li measured the differing computation speeds on IEEE special values in <ref> [3] </ref>. 5.2 Observations Orders of magnitude difference in the speed of handling normal and special values exist on current microprocessors. <p> Acknowledgments The authors would like to thank W. Kahan for his advice and discussion on matters related to this project, including recommending the poly benchmark. Alex Aiken provided feedback on the floating point language design issues. Xiaoye Li also deserves thanks for advice and assistance using the benchmarks from <ref> [3] </ref>. 14
Reference: [4] <author> J. Dongarra, J. Bunch, C. Moler, and G. W. Stewart. </author> <title> LINPACK Users Guide. </title> <publisher> SIAM, </publisher> <address> Philadelphia PA, </address> <year> 1979. </year>
Reference-contexts: In cases where static and dynamic rounding are mixed, the slower time is more realistic. 4.2 FLECK This section presents the result of our program-level benchmarking. We first present the results of running the SPECfp95 benchmark suite and the Linpack <ref> [4] </ref> 1000x1000 benchmark to measure the performance of traditional floating point operations on our machine and compiler combinations. We then present our benchmarking suite, FLECK, and report the results. We end with a comparison of all benchmark results.
Reference: [5] <author> Richard J. Fateman, </author> <title> High-Level Language Implications of the Proposed IEEE Floating-Point Standard, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 4, No. 2, </volume> <month> April </month> <year> 1982, </year> <pages> pp. 239-257. </pages>
Reference-contexts: Programming language support for IEEE 754 was discussed before the standard was adopted <ref> [5] </ref>. Even if not employed directly, many users could benefit from more efficient libraries written using IEEE 754s advanced capabilities [3]. Due to the ubiquity of IEEE 754, programming languages should now support IEEE 754 specific features not available under other floating point standards.
Reference: [6] <author> John R. Hauser, </author> <title> Handling Floating-Point Exceptions, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 18, No. 2, </volume> <month> March </month> <year> 1996, </year> <pages> pp. 139-174. </pages>
Reference-contexts: In [8], W. Kahan discusses the features and implications of the IEEE 754 floating point standard as well as proposing language mechanisms to access those features. J. Hauser in <ref> [6] </ref> and [7] provides detailed examples justifying the usefulness of exception handling in floating point computations. Different language interfaces to exceptions are discussed in [7]. J. Demmel and X.
Reference: [7] <author> John R. Hauser, </author> <title> Programmed exception handling. M.S. </title> <type> Thesis, </type> <institution> University of California, Berkeley, </institution> <address> CA 1994. </address>
Reference-contexts: In [8], W. Kahan discusses the features and implications of the IEEE 754 floating point standard as well as proposing language mechanisms to access those features. J. Hauser in [6] and <ref> [7] </ref> provides detailed examples justifying the usefulness of exception handling in floating point computations. Different language interfaces to exceptions are discussed in [7]. J. Demmel and X. <p> J. Hauser in [6] and <ref> [7] </ref> provides detailed examples justifying the usefulness of exception handling in floating point computations. Different language interfaces to exceptions are discussed in [7]. J. Demmel and X. Li measured the differing computation speeds on IEEE special values in [3]. 5.2 Observations Orders of magnitude difference in the speed of handling normal and special values exist on current microprocessors.
Reference: [8] <author> William Kahan, </author> <title> Lecture Notes on the Status of IEEE Standard 754 for Binary Floating-Point Arithmetic, </title> <address> http://HTTP.CS.Berkeley.EDU/~wkahan/ieee754status/ieee754.ps </address>
Reference-contexts: The proposed libraries for the functional language Haskell 1.3 include an optional library LibIEEE_Float that has rounding arithmetic operators and comparison operators similar to the structures in Sections 3.2.2 and 3.2.3. In <ref> [8] </ref>, W. Kahan discusses the features and implications of the IEEE 754 floating point standard as well as proposing language mechanisms to access those features. J. Hauser in [6] and [7] provides detailed examples justifying the usefulness of exception handling in floating point computations.
Reference: [9] <author> David Kahaner, </author> <title> Benchmarks for real programs, </title> <journal> SIAM News, </journal> <month> November </month> <year> 1988. </year>
Reference-contexts: Our three benchmarks cover all these features except subnormals, we were unable to find an algorithm which depended on their presence for correct functioning (in fact, we found one, SDRWAVE <ref> [9] </ref>, that depended on their absence). Two of our benchmarks are based on existing FORTRAN code, and one is written in C. The two FORTRAN benchmarks are modified LAPACK [1] routines to get higher performance from exploiting IEEE features. They come from work of J. Demmel and X.
Reference: [10] <editor> PARISC 1.1 Architecture and Instruction Set Reference Manual, </editor> <booktitle> Third Edition, </booktitle> <publisher> Hewlett Packard Company, </publisher> <year> 1996. </year>
Reference: [11] <institution> Pentium Pro Family Developers Manual, Intel Corporation, </institution> <year> 1996. </year>
Reference: [12] <editor> Naur, et al, </editor> <booktitle> Report on the Algorithmic Language ALGOL 60 </booktitle>
Reference-contexts: The control of the possible consequences of such differences must be carried out by the methods of numerical analysis <ref> [12] </ref>. Therefore, the same source program compiled and run on different architectures produced different output due to varying range, precision, and other properties of a particular floating point format.
Reference: [13] <author> Richard L. Sites, Richard T. Witek, </author> <title> Alpah AXP Architecture Reference Manual, Second Edition, </title> <publisher> Digital Press, </publisher> <year> 1995. </year>
Reference-contexts: This measurements reflect the performance that an application compiled with IEEE support enabled can expect. An attempt to reduce the number of trap barriers to one per basic block, which should be possible according to the Alpha architecture manual <ref> [13] </ref>, produced speeds comparable to the fast results for normal numbers, but also gave incorrect results for the non-pipelined addition of subnormal numbers, which is rather unfortunate.
Reference: [14] <author> Jim Thomas, </author> <title> C9X Floating Point, </title> <note> WG14/N595 X3J11/96-059 (Draft 9/12/96) </note>
Reference-contexts: When the hardware supports these features, the IEEE algorithms are always much faster than the originals. 13 5. Conclusions 5.1 Related Work Other groups are also concerned with providing IEEE 754 floating point support in languages. The C9X group is working on incorporating floating point into the C standard <ref> [14] </ref>. Their proposal takes a less integrated approach than we recommend, relying on many macros and #defines . For example, instead of new constants, NaN and infinity values in C9X are returned by NAN and INFINITY macros.
Reference: [15] <institution> Standard Performance Evaluation Corporation, </institution> <note> http://www.specbench.org/ </note>
Reference-contexts: The ease of access to the IEEE functionality is in practice a language and operating system issue, this aspect is covered by our proposed language extensions. The differences in speed can be compared with a standard benchmark. The floating point part of the SPEC95 CPU benchmark <ref> [15] </ref>, derived from actual programs, provides a popular way of comparing the floating point speed of different processors. However, the codes used in SPEC95 only exercise traditional floating point features.
Reference: [16] <author> David L. Weaver and Tom Germond, ed., </author> <title> The SPARC Architecture Manual, version 9, </title> <publisher> Prentice Hall, </publisher> <year> 1994. </year>
Reference: [17] <institution> Working Paper for the Draft Proposed International Standard for Information Systems Programming Language C++, </institution> <note> Doc No: X3J16/95-0087 </note>
Reference-contexts: For example, instead of new constants, NaN and infinity values in C9X are returned by NAN and INFINITY macros. In C9X, the functionality of the new comparison operators discussed in Section 3.2.3 are implemented with function calls like isgreaterequal () . The working draft of the C++ standard <ref> [17] </ref> has facilities to query many properties of a floating point type relevant to IEEE floating point numbers. The proposed libraries for the functional language Haskell 1.3 include an optional library LibIEEE_Float that has rounding arithmetic operators and comparison operators similar to the structures in Sections 3.2.2 and 3.2.3.
References-found: 17

