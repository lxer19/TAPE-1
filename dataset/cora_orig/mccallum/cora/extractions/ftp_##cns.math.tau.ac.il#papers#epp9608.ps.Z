URL: ftp://cns.math.tau.ac.il/papers/epp9608.ps.Z
Refering-URL: http://www.math.tau.ac.il/~nin/research.html
Root-URL: 
Title: Multimodality Exploration in Training an Unsupervised Projection Pursuit Neural Network  
Author: Yocheved Dotan and Nathan Intrator 
Date: August, 1996  
Affiliation: Tel-Aviv University  
Abstract: Graphical inspection of multimodality is demonstrated using unsupervised lateral-inhibition neural networks. Three projection pursuit indices are compared on low dimensional simulated and real-world data: principal components [22], Legendre poly nomial [6] and projection pursuit network [16]. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. E. Bellman. </author> <title> Adaptive Control Processes. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1961. </year>
Reference-contexts: 1 Introduction Modes exploration of an unknown multivariate distribution from observations, arises in exploratory multivariate data analysis. The task is sensitive to the dimensionality, as robust estimation requires an exponential growth of the observations number with the dimensionality <ref> [1] </ref>. Investigation of the modality in a density function has been considered by several authors. A few [4, 10] seem to depend on implicit or explicit choice of the scale of the density being studied.
Reference: [2] <author> E. L. Bienenstock, L. N Cooper, and P. W. Munro. </author> <title> Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex. </title> <journal> Journal Neuroscience, </journal> <volume> 2 </volume> <pages> 32-48, </pages> <year> 1982. </year>
Reference-contexts: We are mainly interested in comparison between a 2 conventional index e.g., a one based on Legendre polynomials with a biologically motivated index based on the BCM theory for visual cortical plasticity <ref> [2] </ref> as is described in [16]. For a base line, we have some limited comparison with principal components features. <p> It is a variant of the biologically motivated BCM rule <ref> [2] </ref> which was presented to model learning in visual cortex.
Reference: [3] <author> N. A. Campbell and R. J. Mahon. </author> <title> A multivariate study of variation in two species of rock crab of genus lepto-grapsus. Aust. </title> <journal> J. Zool, </journal> <volume> 22 </volume> <pages> 417-425, </pages> <year> 1974. </year>
Reference-contexts: The best projections are demonstrated in Figure 14. 4.6 Crabs data Recently, Ripley [23, p. 301] has demonstrated the performance of exploratory projection pursuit methods using the Crabs data <ref> [3] </ref> which has become a standard test data for various learning algorithms. 1 This data has five variables, four classes corresponding to sex and two 1 It can be retrieved from the UCI repository [20]. 6 crab subspecies and 50 samples from each class.
Reference: [4] <author> D.R. Cox. </author> <title> Notes on analysis of mixed frequency distributions. </title> <journal> British Journal of Math. Statist. Psychol, </journal> <volume> 7 </volume> <pages> 1-26, </pages> <year> 1966. </year>
Reference-contexts: The task is sensitive to the dimensionality, as robust estimation requires an exponential growth of the observations number with the dimensionality [1]. Investigation of the modality in a density function has been considered by several authors. A few <ref> [4, 10] </ref> seem to depend on implicit or explicit choice of the scale of the density being studied. A simple approach based on kernel density estimate was proposed [24], by making this choice automatically. The classical parametric and nonparametric methods for estimating density functions have a number of drawbacks.
Reference: [5] <author> P. Diaconis and D. Friedman. </author> <title> Asymptotics of graphical projection pursuit. </title> <journal> Annals of Statistics, </journal> <volume> 12 </volume> <pages> 793-815, </pages> <year> 1984. </year>
Reference-contexts: Interestingness of the projections is related to their deviation from normality as follows from Diaconis and Freedman's result on the nature of most projections of high dimensional data <ref> [5] </ref>. Various projection indices make different assumptions about the nature of deviation from normality, and differ in their computational efficiency. Projection pursuit methods concentrate on projections that allow discrimination between modes, and not faithful representation of the data which is the goal of many data compression methods.
Reference: [6] <author> J. H. Friedman. </author> <title> Exploratory projection pursuit. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 82 </volume> <pages> 599-608, </pages> <year> 1987. </year>
Reference-contexts: Graphical inspection of multimodality is demonstrated here using a lateral inhibition neural network architecture, classical projection indices and a biologically motivated parameter estimation rule. Projection Pursuit methods seek structure in the observation space via (non-linear) functions of linear projections <ref> [8, 12, 6] </ref>. These methods have the potential to overcome the curse of dimensionality when important structure in the data lies in a smaller dimensional space and can be extracted by linear projection. <p> Lateral inhibition distinguishes the neural net approach from classical projection pursuit methods, where the concurrent search for several projections scales exponentially with the number of projections sought. To overcome this problem, a sequential search for single projections has been suggested <ref> [7, 6] </ref>. This was achieved by eliminating structure in directions that have already been found, before proceeding to seek the next projection. <p> The inhibited activity network does not find principal components exactly since the orthogonality constraint between projections is relaxed. 3.2 Legendre Polynomial Friedman <ref> [6] </ref> used this polynomial extension for measuring deviation from Gaussian distributions. <p> The variables are highly correlated, thus making it difficult to find structure in the data. Ripley compared three indices: Hermite [11], Friedman-Tukey [9] and Legendre <ref> [6] </ref> index. Our application of the BCM projection index in a lateral inhibition network to this data (Figures 15 and 16) reveals the full 4-class structure of the data.
Reference: [7] <author> J. H. Friedman and W. Stuetzle. </author> <title> Projection pursuit regression. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 76 </volume> <pages> 817-823, </pages> <year> 1981. </year>
Reference-contexts: Lateral inhibition distinguishes the neural net approach from classical projection pursuit methods, where the concurrent search for several projections scales exponentially with the number of projections sought. To overcome this problem, a sequential search for single projections has been suggested <ref> [7, 6] </ref>. This was achieved by eliminating structure in directions that have already been found, before proceeding to seek the next projection.
Reference: [8] <author> J. H. Friedman, W. Stuetzle, and A. Schreder. </author> <title> Projection pursuit density estimation. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 79 </volume> <pages> 599-608, </pages> <year> 1984. </year>
Reference-contexts: Graphical inspection of multimodality is demonstrated here using a lateral inhibition neural network architecture, classical projection indices and a biologically motivated parameter estimation rule. Projection Pursuit methods seek structure in the observation space via (non-linear) functions of linear projections <ref> [8, 12, 6] </ref>. These methods have the potential to overcome the curse of dimensionality when important structure in the data lies in a smaller dimensional space and can be extracted by linear projection.
Reference: [9] <author> J. H. Friedman and J.W. Tukey. </author> <title> Projection pursuit algorithm for exploratory data analysis. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 23 </volume> <pages> 881-890, </pages> <year> 1974. </year>
Reference-contexts: The variables are highly correlated, thus making it difficult to find structure in the data. Ripley compared three indices: Hermite [11], Friedman-Tukey <ref> [9] </ref> and Legendre [6] index. Our application of the BCM projection index in a lateral inhibition network to this data (Figures 15 and 16) reveals the full 4-class structure of the data.
Reference: [10] <author> I.J. Good and R.A. Gaskins. </author> <title> Density estimation and bump hunting by the penalized likelihood method exemplified by scattering and meteorite data. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 75 </volume> <pages> 42-56, </pages> <year> 1975. </year>
Reference-contexts: The task is sensitive to the dimensionality, as robust estimation requires an exponential growth of the observations number with the dimensionality [1]. Investigation of the modality in a density function has been considered by several authors. A few <ref> [4, 10] </ref> seem to depend on implicit or explicit choice of the scale of the density being studied. A simple approach based on kernel density estimate was proposed [24], by making this choice automatically. The classical parametric and nonparametric methods for estimating density functions have a number of drawbacks.
Reference: [11] <author> P. Hall. </author> <title> On polynomial-based projection indices for exploratory projection pursuit. </title> <journal> The Annals of Statistics, </journal> <volume> 17 </volume> <pages> 589-605, </pages> <year> 1989. </year>
Reference-contexts: The variables are highly correlated, thus making it difficult to find structure in the data. Ripley compared three indices: Hermite <ref> [11] </ref>, Friedman-Tukey [9] and Legendre [6] index. Our application of the BCM projection index in a lateral inhibition network to this data (Figures 15 and 16) reveals the full 4-class structure of the data.
Reference: [12] <author> P. Huber. </author> <title> Projection pursuit. </title> <journal> Annals of Statistics, </journal> <volume> 13:435 - 525, </volume> <year> 1985. </year>
Reference-contexts: Graphical inspection of multimodality is demonstrated here using a lateral inhibition neural network architecture, classical projection indices and a biologically motivated parameter estimation rule. Projection Pursuit methods seek structure in the observation space via (non-linear) functions of linear projections <ref> [8, 12, 6] </ref>. These methods have the potential to overcome the curse of dimensionality when important structure in the data lies in a smaller dimensional space and can be extracted by linear projection. <p> This was achieved by eliminating structure in directions that have already been found, before proceeding to seek the next projection. While this method leads to linear growth in search time, it lacks the ability to reveal structure which can only be found by two or more concurrent projections <ref> [12, for discussion] </ref>. In contrast, in a neural net setup, the computation time only increases linearly with the number of features sought.
Reference: [13] <author> Q. Q. Huynh, L. N Cooper, N. Intrator, and H. Shouval. </author> <title> Classification of underwater mammals using feature extraction based on time-frequency analysis and bcm theory. </title> <booktitle> In Time-Freq Conference Proceedings. </booktitle> <month> June 18-21, </month> <note> Paris (To appear), 1996. 8 </note>
Reference-contexts: These results are consistent with those obtained by applying the BCM feature extraction to several real world applications with dimensionality between 100 to 5000 <ref> [15, 17, 18, 13] </ref>. 7
Reference: [14] <author> J. N. Hwang, S. R. Lay, M. Maechler, D. Martin, and J. Schimert. </author> <title> Regression modeling in back-propagation and projection pursuit learning. </title> <journal> IEEE Transactions on Neural Networks, </journal> <year> 1993. </year>
Reference-contexts: Revealing structure with the Legendre projection index is achieved while incresing neurons to 5 as depicted in Figure 3. The variance projection index did not reveal more information with more projections. 4.2 Simple Interaction Function Following <ref> [14] </ref>, the function f (x1; x2) = 10:391 ((x1 0:4)(x2 0:6) + 0:36); was used, with a set of 225 pairs (x1; x2) of independent uniform random variables on [0,1]. This 3D nonlinear function is depicted in Figure 4.
Reference: [15] <author> N. Intrator. </author> <title> Feature extraction using an unsupervised neural network. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 98-107, </pages> <year> 1992. </year>
Reference-contexts: These results are consistent with those obtained by applying the BCM feature extraction to several real world applications with dimensionality between 100 to 5000 <ref> [15, 17, 18, 13] </ref>. 7
Reference: [16] <author> N. Intrator and L. N. Cooper. </author> <title> Objective function formulation of the BCM theory of visual cortical plasticity: Statistical connections, stability conditions. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 3-17, </pages> <year> 1992. </year>
Reference-contexts: We are mainly interested in comparison between a 2 conventional index e.g., a one based on Legendre polynomials with a biologically motivated index based on the BCM theory for visual cortical plasticity [2] as is described in <ref> [16] </ref>. For a base line, we have some limited comparison with principal components features. <p> activity ~ C k is given by: ~ C k = (C k j6=k and appropriately, @ ~ C k = ( ~ C k )[C k j6=k 0 This form which is easy to calculate can be seen as a first approximation to a fully recurrent lateral inhibition network <ref> [16] </ref>. <p> 2 P 0 (R) = 1; P 1 (R) = R; P j (R) = j RP j1 (R) j P j2 (R) Legendre gradient is given by: @R k = j=1 0 C k 2 where: P 0 0 0 3.3 BCM Index This index which was introduced in <ref> [16] </ref> uses low order polynomial moments which are computationally efficient. It is a variant of the biologically motivated BCM rule [2] which was presented to model learning in visual cortex.
Reference: [17] <author> N. Intrator and J. I. Gold. </author> <title> Three-dimensional object recognition of gray level images: The usefulness of distinguishing features. </title> <journal> Neural Computation, </journal> <volume> 5 </volume> <pages> 61-74, </pages> <year> 1993. </year>
Reference-contexts: These results are consistent with those obtained by applying the BCM feature extraction to several real world applications with dimensionality between 100 to 5000 <ref> [15, 17, 18, 13] </ref>. 7
Reference: [18] <author> N. Intrator, D. Reisfeld, and Y. Yeshurun. </author> <title> Face recognition using a hybrid supervised/unsupervised neural network. </title> <journal> Pattern Recognition Letters, </journal> <volume> 17 </volume> <pages> 67-76, </pages> <year> 1996. </year>
Reference-contexts: These results are consistent with those obtained by applying the BCM feature extraction to several real world applications with dimensionality between 100 to 5000 <ref> [15, 17, 18, 13] </ref>. 7
Reference: [19] <author> D.W. Muller and G. Sawitzki. </author> <title> Excess mass estimates and tests for multimodality. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 86, </volume> <year> 1991. </year>
Reference-contexts: Parametric methods give weak results on unknown distributions, while nonparametric methods which do not assume that the density belongs to a particular parametric family, require extensive amount of observations [25]. A different approach is based on the excess mass functional <ref> [19] </ref>. This functional measures empirical mass, while separating the investigation about the number of modes, from the estimation of their location. Recently, a new index was proposed for measuring multimodality, based on an integer-weighted sum of excess masses [21].
Reference: [20] <author> P. M. Murphy and D. W. Aha. </author> <title> Uci repository of machine learning databases, </title> <year> 1992. </year>
Reference-contexts: [23, p. 301] has demonstrated the performance of exploratory projection pursuit methods using the Crabs data [3] which has become a standard test data for various learning algorithms. 1 This data has five variables, four classes corresponding to sex and two 1 It can be retrieved from the UCI repository <ref> [20] </ref>. 6 crab subspecies and 50 samples from each class. The variables are highly correlated, thus making it difficult to find structure in the data. Ripley compared three indices: Hermite [11], Friedman-Tukey [9] and Legendre [6] index.
Reference: [21] <author> G.P. Nason and Robin Sibson. </author> <title> Measuring multimodality. </title> <journal> Statistics and Computing, </journal> <pages> pages 153-160, </pages> <year> 1992. </year>
Reference-contexts: A different approach is based on the excess mass functional [19]. This functional measures empirical mass, while separating the investigation about the number of modes, from the estimation of their location. Recently, a new index was proposed for measuring multimodality, based on an integer-weighted sum of excess masses <ref> [21] </ref>. Graphical inspection of multimodality is demonstrated here using a lateral inhibition neural network architecture, classical projection indices and a biologically motivated parameter estimation rule. Projection Pursuit methods seek structure in the observation space via (non-linear) functions of linear projections [8, 12, 6].
Reference: [22] <author> E. Oja. </author> <title> A simplified neuron model as a principal component analyzer. </title> <journal> Math. Biology, </journal> <volume> 15 </volume> <pages> 267-273, </pages> <year> 1982. </year>
Reference: [23] <author> B. D. Ripley. </author> <title> Pattern Recognition and Neural Networks. </title> <publisher> Cambridge University Press, </publisher> <year> 1996. </year>
Reference-contexts: Exploration was succeeded using BCM in inhibited net with 4 and 5 neurons. Again, Legendre index tends to be more sensitive to outliers, while BCM index is sensitive to the center of the distribution. The best projections are demonstrated in Figure 14. 4.6 Crabs data Recently, Ripley <ref> [23, p. 301] </ref> has demonstrated the performance of exploratory projection pursuit methods using the Crabs data [3] which has become a standard test data for various learning algorithms. 1 This data has five variables, four classes corresponding to sex and two 1 It can be retrieved from the UCI repository [20]. <p> Our application of the BCM projection index in a lateral inhibition network to this data (Figures 15 and 16) reveals the full 4-class structure of the data. It produces similar results to those obtained by the natural Hermite index <ref> [23, p. 303] </ref> which were best among the three indices which Ripley had used. 5 Conclusions Our results demonstrate that a lateral inhibition network is capable of multi-dimensional exploration of complex data.
Reference: [24] <author> B.W. Silverman. </author> <title> Using kernel density estimates to investigate multimodality. </title> <journal> Journal of the American Statistical Association, </journal> <volume> B43:97-99, </volume> <year> 1981. </year>
Reference-contexts: Investigation of the modality in a density function has been considered by several authors. A few [4, 10] seem to depend on implicit or explicit choice of the scale of the density being studied. A simple approach based on kernel density estimate was proposed <ref> [24] </ref>, by making this choice automatically. The classical parametric and nonparametric methods for estimating density functions have a number of drawbacks.

References-found: 24

