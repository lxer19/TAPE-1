URL: http://www.isi.edu/soar/johnson/ml-sim.ps
Refering-URL: http://www.isi.edu/soar/johnson/debriefable.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: USING MACHINE LEARNING TO EXTEND AUTONOMOUS AGENT CAPABILITIES  
Author: W. Lewis Johnson and Milind Tambe 
Keyword: machine learning, interactive simulation, military  
Note: To appear in the Procedings of the 1995 Summer Computer Simulation Conference. c flSociety for Computer Simulation, 1995. Made available for distribution over the Internet by permission of SCS.  
Address: 4676 Admiralty Way, Marina del Rey, CA 90292-6695  
Affiliation: USC Information Sciences Institute Computer Science Dept.  
Email: fjohnson,tambeg@isi.edu  
Web: WWW: http://www.isi.edu/soar/fjohnson, tambeg  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> R.B. Calder, J.E. Smith, A.J. Courtemanche, J.M.F. Mar, and A.Z. Ceranowicz. </author> <title> ModSAF behavior simulation and control. </title> <booktitle> In Proceedings of the Third Conference on Computer Generated Forces and Behavioral Representation, </booktitle> <pages> pages 347-359, </pages> <address> Orlando, FL, </address> <month> March </month> <year> 1993. </year> <institution> Institute for Simulation and Training, University of Central Florida. </institution>
Reference-contexts: Needless to say, achieving these goals successfully is a significant achievement for artificial intelligence. Soar/IFOR agents interact with distributed simulations via the ModSAF simulation package <ref> [1] </ref>. Each agent is assigned to a ModSAF simulation of a vehicle, e.g., an aircraft.
Reference: [2] <author> R.B. Doorenbos. </author> <title> Matching 100,000 learned rules. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 290-296, </pages> <address> Menlo Park, CA, </address> <month> August </month> <year> 1993. </year> <note> AAAI. </note>
Reference-contexts: This chunking process is a form of explanation-based learning EBL [7, 6]. Chunking can lead to speedup in learner performance, and is instrumental to the learning of new concepts. Some Soar systems have managed to learn thousands, and even hundreds of thousands, of chunks <ref> [2] </ref>. From the previous experience with learning in Soar, it was taken as a given that the Soar/IFOR agents could be made capable of applying chunking in service of their performance requirements.
Reference: [3] <author> W.L. Johnson. </author> <title> Agents that learn to explain themselves. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 1257-1263, </pages> <address> Seat-tle, WA, </address> <month> August </month> <year> 1994. </year> <booktitle> AAAI, </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: This has led to the development of an automated explanation capability, called Debrief, that enables users to engage agents in a question-answer dialog, in a manner analogous to an after-action review <ref> [3] </ref>. 3 Learning in Soar Agents The air-combat simulation environment|by virtue of its complex, real-world characteristics|presents Soar/IFOR agents with a number of challenging functional and performance requirements. There are also many ways in which machine learning can help the agents meet these requirements. <p> Learning enables knowledge encoded for one purpose, i.e., controlling the agent's behavior, to be employed for other purposes, e.g., explaining the agent's decisions. Soar/IFOR's interactive explanation capability, called Debrief, makes extensive use of chunking for knowledge reorganization <ref> [3] </ref>. The agents can explain the rationales for decisions made during an engagement, by relating chosen decisions to the critical factors in the situation that led to those decisions.
Reference: [4] <author> J.E. Laird, A. Newell, </author> <title> and P.S. Rosenbloom. Soar: An architecture for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 1-64, </pages> <year> 1987. </year>
Reference-contexts: Soar/IFOR agents are implemented in Soar, a problem solving architecture that integrates a number of human cognitive functions, including problem solving, perception, and learning <ref> [4] </ref>. Learning occurs through the application of a general mechanism called chunking that summarizes the results of processing on subgoals, in the form of rules that can apply to similar sub-goals in the future. This chunking process is a form of explanation-based learning EBL [7, 6].
Reference: [5] <author> S. Minton. </author> <title> Quantitative results concerning the utility of explanation-based learning. </title> <journal> Artificial Intelligence, </journal> <volume> 42(2-3):363-391, </volume> <year> 1990. </year>
Reference-contexts: Finally, chunks created during a mission or during after-action review are saved so that they can be employed by agents in future missions and review sessions, enabling the agents to learn from accumulated experience. 3.1 Speeding Up Decisions In much machine learning research, such as <ref> [5] </ref>, speedup is measured by comparing problem solving time after learning to problem solving time without learning. Such a measure is inappropriate for learning in Soar/IFOR, because chunking does not yield an overall speedup, i.e., it does not reduce the overall duration of the engagement.
Reference: [6] <author> T. M. Mitchell, Keller R. M., and S. T. Kedar-Cabelli. </author> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 47-80, </pages> <year> 1986. </year>
Reference-contexts: Learning occurs through the application of a general mechanism called chunking that summarizes the results of processing on subgoals, in the form of rules that can apply to similar sub-goals in the future. This chunking process is a form of explanation-based learning EBL <ref> [7, 6] </ref>. Chunking can lead to speedup in learner performance, and is instrumental to the learning of new concepts. Some Soar systems have managed to learn thousands, and even hundreds of thousands, of chunks [2].
Reference: [7] <author> P. S. Rosenbloom and J. E. Laird. </author> <title> Mapping explanation-based generalization onto soar. </title> <booktitle> In Proceedings of the Fifth National Conference on Artificial Intelligence, </booktitle> <pages> pages 561-567, </pages> <year> 1986. </year>
Reference-contexts: Learning occurs through the application of a general mechanism called chunking that summarizes the results of processing on subgoals, in the form of rules that can apply to similar sub-goals in the future. This chunking process is a form of explanation-based learning EBL <ref> [7, 6] </ref>. Chunking can lead to speedup in learner performance, and is instrumental to the learning of new concepts. Some Soar systems have managed to learn thousands, and even hundreds of thousands, of chunks [2].
Reference: [8] <author> K.B. Schwamb, V.F. Koss, and D. Keirsey. </author> <title> Working with ModSAF: Interfaces for programs and users. </title> <booktitle> In Proceedings of the Fourth Conference on Computer Generated Forces and Behavior Representation, </booktitle> <pages> pages 395-399, </pages> <address> Orlando, FL, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: Soar/IFOR agents interact with distributed simulations via the ModSAF simulation package [1]. Each agent is assigned to a ModSAF simulation of a vehicle, e.g., an aircraft. Soar/IFOR receives inputs from the vehicle, via an abstract interface <ref> [8] </ref>, information similar to what a human controlling the same vehicle in the real world would receive, such as position of the vehicle, presence of enemy vehicles in the area, etc.
Reference: [9] <author> V.J. Shute and J.W. Regian. </author> <title> Principles for evaluating intelligent tutoring systems. </title> <journal> Journal of Artificial Intelligence in Education, </journal> 4(2/3):245-273, 1993. 
Reference: [10] <author> M. Tambe, W.L. Johnson, R.M. Jones, F. Koss, J.E. Laird, P.S. Rosenbloom, and K. Schwamb. </author> <title> Intelligent agents for interactive simulation environments. </title> <note> To appear in AI Magazine, Spring 1995. </note>
Reference-contexts: 1 Introduction The Soar/IFOR project is developing human-like, intelligent agents that can interact with humans, and with each other, in battlefield simulations <ref> [10] </ref>. Our agents play a variety of roles such as fighter pilots, helicopter pilots, and airspace controllers.

References-found: 10

