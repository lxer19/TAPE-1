URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/avrim/www/Papers/navig.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/avrim/www/Papers/pubs.html
Root-URL: 
Email: avrim@theory.cs.cmu.edu  chal@cs.cmu.edu  
Title: An On-Line Algorithm for Improving Performance in Navigation  
Author: Avrim Blum Prasad Chalasani 
Keyword: n=i) times the shortest s-t path length.  
Note: can be defined based on the positions of the obstacles.  
Address: Pittsburgh, PA 15213  Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  School of Computer Science Carnegie Mellon University  
Abstract: We consider the following scenario. A point robot is placed at some start location s in a 2-dimensional scene containing oriented rectangular obstacles. The robot must repeatedly travel back and forth between s and a second location t in the scene. The robot knows the coordinates of s and t but initially knows nothing about the positions or sizes of the obstacles. It can only determine the obstacles' locations by bumping into them. We would like an intelligent strategy for the robot so that its trips between s and t both are relatively fast initially, and improve as more trips are taken and more information is gathered. In this paper we describe an algorithm for this problem with the following guarantee: in the first k n trips, the average distance per trip is at most O( n=k) times the length of the shortest s-t path in the scene, where n is the Euclidean distance between s and t. We also show a matching lower bound for deterministic strategies. These results generalize known bounds on the one-trip problem. Our algorithm is based on a novel method for making an optimal tradeoff between search effort and the goodness of the path found. We improve this algorithm to a smooth variant having the property that for every i n, the robot's ith trip length is O( A key idea of this paper is a method for analyzing obstacle scenes using a tree structure that p
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Baeza-Yates, J. Culberson, and G. Rawlins. </author> <title> Searching in the plane. Information and Computation, </title> <address> 106(2):234252, </address> <year> 1993. </year>
Reference-contexts: This information is used only to tell the robot whether or not there is a t -post at the point of encounter. With only a constant factor penalty (see the analysis in <ref> [1] </ref>) the robot can obtain this information on its own, using the standard doubling strategy: Move up a distance 1, then down 2, then up 4, and so on, each time moving double the previous distance. 10 Conclusion and Open Problems The core result of this paper is an algorithm that
Reference: [2] <author> P. Berman, A. Blum, A. Fiat, H. Karloff, A. Rosen, and M. Saks. </author> <title> Randomized robot navigation algorithms. </title> <type> Unpublished Manuscript. </type>
Reference-contexts: For instance, can randomization provide a better or simpler algorithm? For the one trip problem, the best lower bound known is (log log n) by Karloff, Rabani and Ravid [11], and the best upper bound is O (n 4=9 log n) by Berman, Blum, Fiat, Karloff and Rosen and Saks <ref> [2] </ref>. What about extending our multi-trip results to more general scenes? Recently, Berman and Karpinski [4] have designed a randomized O (n 3=4 )- competitive single-trip algorithm for 2-dimensional scenes containing arbitrary convex obstacles within which a unit circle can be inscribed.
Reference: [3] <author> E. Bar-Eli, P. Berman, A. Fiat, and P. Yan. </author> <title> On-line navigation in a room. </title> <booktitle> In Proc. 3rd ACM-SIAM SODA, </booktitle> <year> 1992. </year>
Reference-contexts: Our algorithms are easily extended to the case where t is a point, using the Room Problem algorithms of [7] or <ref> [3] </ref>, and we describe this modification in Section 8. We model the robot as having only tactile sensors; that is, it discovers an obstacle only when it bumps into it. <p> As before, if we do not know L, we can use the standard guessing and doubling approach and suffer only a constant factor penalty in performance. On the first trip, the robot can get to t using the optimal point-to-point algorithms of [7] or <ref> [3] </ref>, with a single-trip ratio of O ( p Once at t, the robot creates a greedy up-left path and a greedy down-left path from t, within a window of height 4L centered at t.
Reference: [4] <author> P. Berman and M. Karpinski. </author> <title> Wall problem with convex obstacles. </title> <type> Unpublished Manuscript, </type> <month> July </month> <year> 1994. </year>
Reference-contexts: What about extending our multi-trip results to more general scenes? Recently, Berman and Karpinski <ref> [4] </ref> have designed a randomized O (n 3=4 )- competitive single-trip algorithm for 2-dimensional scenes containing arbitrary convex obstacles within which a unit circle can be inscribed. Achieving an O ( p n) ratio for such scenes seems considerably harder.
Reference: [5] <author> M. Betke, R. Rivest, and M. Singh. </author> <title> Piecemeal learning of an unknown environment. </title> <booktitle> In Proc. 6th ACM Conf. on Computational Learning Theory, </booktitle> <pages> pages 277286, </pages> <year> 1993. </year>
Reference-contexts: In addition, our method for achieving this tradeoff has the property that it can be performed in a piecemeal fashion (somewhat like the piecemeal learning of <ref> [5] </ref>). In particular, the searching can be performed a little bit at a time on each trip. This latter property is what allows us to turn our cumulative algorithm into one that is more like a learning algorithm, with optimal per-trip performance. <p> In other machine learning literature, Chen [9] considers how the computation time for path-planning in a known scene can be improved by making use of (portions of) solutions to previous path planning problems in the same scene. Betke, Rivest and Singh <ref> [5] </ref> consider a related problem of completely exploring an environment, but with the restriction that the robot must return to the start to refuel every d steps for some distance d. They call this piecemeal learning and provide algorithms for the case of a bounded region with axis-parallel rectangular obstacles.
Reference: [6] <author> A. Blum and P. Chalasani. </author> <title> An online algorithm for improving performance in navigation. </title> <booktitle> In Proceedings of the 34th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 211, </pages> <year> 1993. </year>
Reference-contexts: Thus, such scenes do not allow one to demonstrate theoretically the value of a useful approach by the performance guarantees achieved. An extended abstract of this paper appears as <ref> [6] </ref>. 1.1 Results and goodness measures Given the basic scenario described above, the first question to be addressed is the measure of success to use.
Reference: [7] <author> A. Blum, P. Raghavan, and B. Schieber. </author> <title> Navigating in unfamiliar geometric terrain. </title> <booktitle> In Proc. 23rd ACM STOC, </booktitle> <year> 1991. </year>
Reference-contexts: What is a strategy that allows your path taken each time to be good, and to improve with experience? Perhaps you might even design your paths explicitly so as to gain more information for future trips. Specifically, we consider the scenario (examined in <ref> [17, 7, 11, 10] </ref>) where there is a start point s and target t in a 2-dimensional plane filled with non-overlapping, axis-parallel rectangular obstacles, fl This material is based upon work supported under NSF National Young Investigator grant CCR-9357793 and a Sloan Foundation Research Fellowship. having corners at integral coordinates. <p> In the problem considered in previous papers, the robot's goal is to travel from s to t as quickly as possible. We call this the one-trip problem. For this problem, if n is the Euclidean s-t distance, <ref> [7] </ref> presents an algorithm that guarantees an O ( p n) ratio of the distance traveled to the shortest path length, which is known to be optimal for deterministic algorithms [17]. Here, we consider the situation where the robot may be asked to make multiple trips between s and t. <p> For example, the question of when one should give up on a difficult region in the scene and move to a new region that might be more promising; also the question of which information is worth gathering. Second, if one allows arbitrarily shaped obstacles, it is known <ref> [7] </ref> that one cannot perform much better in the worst case than a simpleminded depth-first-search strategy. Thus, such scenes do not allow one to demonstrate theoretically the value of a useful approach by the performance guarantees achieved. <p> Subsequently, Blum, Raghavan and Schieber (BRS) <ref> [7] </ref> showed an algorithm having a performance guarantee that matches this lower bound. For the multi-trip problem we consider two similar measures of performance. In the cumulative 2 measure, we compare the total distance traveled on the first k trips to the length of the optimal path. <p> To simplify the exposition, for most of this paper we will take t to be the infinite vertical line (a wall) x = n and require the robot only to get to any point on this line; this is the Wall Problem of <ref> [7] </ref>. Our algorithms are easily extended to the case where t is a point, using the Room Problem algorithms of [7] or [3], and we describe this modification in Section 8. <p> to be the infinite vertical line (a wall) x = n and require the robot only to get to any point on this line; this is the Wall Problem of <ref> [7] </ref>. Our algorithms are easily extended to the case where t is a point, using the Room Problem algorithms of [7] or [3], and we describe this modification in Section 8. We model the robot as having only tactile sensors; that is, it discovers an obstacle only when it bumps into it. <p> It will be convenient to assume, however, that when the robot hits an obstacle, it is told which corner of the obstacle is nearest to it, and how far that corner is from its current position. As in <ref> [7] </ref>, our algorithms can be modified to work without this assumption with only a constant factor penalty. We describe these modifications toward the end of the paper. Consider a robot strategy R for making k trips between s and t. <p> Until the wall is reached, walk to the right, alternately building up and down fences across a window of height 2L centered at s. 1 This is called a sweep in <ref> [7] </ref>. 8 are not disjoint since the band of F 3 between 8 0 and 9 overlaps the band of F 1 between 3 and 4. <p> As before, if we do not know L, we can use the standard guessing and doubling approach and suffer only a constant factor penalty in performance. On the first trip, the robot can get to t using the optimal point-to-point algorithms of <ref> [7] </ref> or [3], with a single-trip ratio of O ( p Once at t, the robot creates a greedy up-left path and a greedy down-left path from t, within a window of height 4L centered at t.
Reference: [8] <author> P. Chalasani. </author> <title> Online Performance-improvement algorithms. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1994. </year>
Reference-contexts: However, we know of no way to find new disjoint fences this cheaply. The naive strategy of extending each new fence greedily and using previously found paths to bypass obstacles that enter existing fences can be too expensive in certain scenes. Examples of such scenes are given in <ref> [8] </ref>. Our approach, as hinted in Section 4, is to give up on trying to create new disjoint fences on each trip, and instead to try to find a group of disjoint fences all at once on one trip. Specifically, we do the following. <p> Thus there is only a constant factor penalty for not knowing L. The advantage of building an entire collection of fences on one trip is that this allows the robot to make more effective use of its movements. In <ref> [8] </ref> a detailed example is given where building fences one-by-one on consecutive trips can be too expensive.
Reference: [9] <author> P. Chen. </author> <title> Improving path planning with learning. </title> <booktitle> In Prof. 9th Int'l Workshop on Machine Learning, </booktitle> <year> 1992. </year>
Reference-contexts: Thrun [18] describes heuristics for path improvement in scenes containing (possibly concave) obstacles and presents empirical results. Koenig and Simmons [12] consider a similar problem on graphs. In other machine learning literature, Chen <ref> [9] </ref> considers how the computation time for path-planning in a known scene can be improved by making use of (portions of) solutions to previous path planning problems in the same scene.
Reference: [10] <author> E.G. Coffman and E.N. Gilbert. </author> <title> Paths through a maze of rectangles. </title> <journal> Networks, </journal> <volume> vol. 22, no. 4, </volume> <pages> pp. 349 367, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: What is a strategy that allows your path taken each time to be good, and to improve with experience? Perhaps you might even design your paths explicitly so as to gain more information for future trips. Specifically, we consider the scenario (examined in <ref> [17, 7, 11, 10] </ref>) where there is a start point s and target t in a 2-dimensional plane filled with non-overlapping, axis-parallel rectangular obstacles, fl This material is based upon work supported under NSF National Young Investigator grant CCR-9357793 and a Sloan Foundation Research Fellowship. having corners at integral coordinates.
Reference: [11] <author> H. Karloff, Y. Rabani, and Y. Ravid. </author> <title> Lower bounds for randomized k-server and motion-planning algorithms. </title> <booktitle> In Proceedings of the 23rd Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 278 288, </pages> <year> 1991. </year>
Reference-contexts: What is a strategy that allows your path taken each time to be good, and to improve with experience? Perhaps you might even design your paths explicitly so as to gain more information for future trips. Specifically, we consider the scenario (examined in <ref> [17, 7, 11, 10] </ref>) where there is a start point s and target t in a 2-dimensional plane filled with non-overlapping, axis-parallel rectangular obstacles, fl This material is based upon work supported under NSF National Young Investigator grant CCR-9357793 and a Sloan Foundation Research Fellowship. having corners at integral coordinates. <p> There are several other interesting research directions that can be explored. For instance, can randomization provide a better or simpler algorithm? For the one trip problem, the best lower bound known is (log log n) by Karloff, Rabani and Ravid <ref> [11] </ref>, and the best upper bound is O (n 4=9 log n) by Berman, Blum, Fiat, Karloff and Rosen and Saks [2].
Reference: [12] <author> S. Koenig and R.G.Simmons. </author> <title> Complexity analysis of real-time reinforcement learning. </title> <booktitle> In Proc. AAAI, </booktitle> <pages> pages 99105, </pages> <year> 1993. </year>
Reference-contexts: The tree structure is defined formally in Section 5. 1.3 Related Work Versions of the multi-trip problem have been addressed in the framework of reinforcement learning. Thrun [18] describes heuristics for path improvement in scenes containing (possibly concave) obstacles and presents empirical results. Koenig and Simmons <ref> [12] </ref> consider a similar problem on graphs. In other machine learning literature, Chen [9] considers how the computation time for path-planning in a known scene can be improved by making use of (portions of) solutions to previous path planning problems in the same scene.
Reference: [13] <author> V. Lumelsky. </author> <title> Algorithmic issues of sensor-based robot motion planning. </title> <booktitle> In 26th IEEE Conference on Decision, </booktitle> <pages> pages 17961801, </pages> <year> 1987. </year>
Reference-contexts: They call this piecemeal learning and provide algorithms for the case of a bounded region with axis-parallel rectangular obstacles. Lumelsky and Stepanov <ref> [13, 14, 15] </ref> describe some very simple algorithms that can be used 3 top, t is at the bottom), and the thin and thick lines are the search path. The robot occasionally will back up, which accounts for the dead ends. Obstacles hit are shaded.
Reference: [14] <author> V. Lumelsky. </author> <title> Algorithmic and complexity issues of robot motion in an uncertain environment. </title> <journal> Journal of Complexity, </journal> <volume> 3:146182, </volume> <year> 1987. </year>
Reference-contexts: They call this piecemeal learning and provide algorithms for the case of a bounded region with axis-parallel rectangular obstacles. Lumelsky and Stepanov <ref> [13, 14, 15] </ref> describe some very simple algorithms that can be used 3 top, t is at the bottom), and the thin and thick lines are the search path. The robot occasionally will back up, which accounts for the dead ends. Obstacles hit are shaded.
Reference: [15] <author> V. Lumelsky and A. Stepanov. </author> <title> Dynamic path planning for a mobile automaton with limited information on the environment. </title> <journal> IEEE Trans. on Automatic Control, </journal> <volume> 31:10581063, </volume> <year> 1986. </year>
Reference-contexts: They call this piecemeal learning and provide algorithms for the case of a bounded region with axis-parallel rectangular obstacles. Lumelsky and Stepanov <ref> [13, 14, 15] </ref> describe some very simple algorithms that can be used 3 top, t is at the bottom), and the thin and thick lines are the search path. The robot occasionally will back up, which accounts for the dead ends. Obstacles hit are shaded.
Reference: [16] <author> M.S. Manasse, L.A. McGeoch, and D.D. Sleator. </author> <title> Competitive algorithms for on-line problems. </title> <journal> Journal of Algorithms, </journal> <volume> 11:208230, </volume> <year> 1990. </year>
Reference-contexts: The multi-trip problem has aspects of both a machine learning and an on-line algorithms problem. As in machine learning settings, we would like our algorithm to improve its performance with experience. As in standard on-line algorithms settings (e.g., <ref> [16] </ref>), decisions the robot makes now may affect the costs it experiences in the future. However, our scenario also exhibits key differences.
Reference: [17] <author> C. Papadimitriou and M. Yannakakis. </author> <title> Shortest paths without a map. </title> <booktitle> In Proc. 16th ICALP, </booktitle> <year> 1989. </year>
Reference-contexts: What is a strategy that allows your path taken each time to be good, and to improve with experience? Perhaps you might even design your paths explicitly so as to gain more information for future trips. Specifically, we consider the scenario (examined in <ref> [17, 7, 11, 10] </ref>) where there is a start point s and target t in a 2-dimensional plane filled with non-overlapping, axis-parallel rectangular obstacles, fl This material is based upon work supported under NSF National Young Investigator grant CCR-9357793 and a Sloan Foundation Research Fellowship. having corners at integral coordinates. <p> We call this the one-trip problem. For this problem, if n is the Euclidean s-t distance, [7] presents an algorithm that guarantees an O ( p n) ratio of the distance traveled to the shortest path length, which is known to be optimal for deterministic algorithms <ref> [17] </ref>. Here, we consider the situation where the robot may be asked to make multiple trips between s and t. <p> The idea of competitive analysis is to compare the performance of one's algorithm to the best one could hope to do if there were no missing information (in our case, if a map of the scene was known). For instance, for the one-trip problem, Papadimitriou and Yannakakis <ref> [17] </ref> showed that for any deterministic algorithm and integer n &gt; 0, there exist scenes having Euclidean s-t distance n (the width of the thinnest obstacle is taken as 1 unit), forcing the algorithm to travel ( p n) times the length of the shortest path.
Reference: [18] <author> S. Thrun. </author> <title> Efficient exploration in reinforcement learning. </title> <type> Technical Report CMU-CS-92-102, </type> <institution> Carnegie Mellon University, </institution> <year> 1992. </year> <month> 31 </month>
Reference-contexts: The tree structure is defined formally in Section 5. 1.3 Related Work Versions of the multi-trip problem have been addressed in the framework of reinforcement learning. Thrun <ref> [18] </ref> describes heuristics for path improvement in scenes containing (possibly concave) obstacles and presents empirical results. Koenig and Simmons [12] consider a similar problem on graphs.
References-found: 18

