URL: http://www.cs.toronto.edu/~grigoris/papers/fss96.ps.Z
Refering-URL: http://www.cs.toronto.edu/~grigoris/sigma.html
Root-URL: http://www.cs.toronto.edu
Email: karakoul@cibc.ca innes@ai.iit.nrc.ca  
Phone: 500,  
Title: A Computational Market Model for Multi-Agent Learning  
Author: Grigoris J. Karakoulas Innes A. Ferguson 
Address: 161 Bay St., BCE-8, P.O. Box  Toronto ON, Canada M5J 2S8 Ottawa ON, Canada K1A 0R6  
Affiliation: Global Analytics Group Interactive Information Group Canadian Imperial Bank of Commerce Institute for Information Technology  National Research Council  
Abstract: This paper presents an adaptive model for multi-agent learning based on the metaphor of economic markets, that can cope with the non-stationary and partially observable nature of complex tasks. Goods within the computational market are information items that are exchanged among producers and consumers. Reinforcement learning and other learning techniques are integrated into the model. As a result of this integration learning through the model exploits market competition in order to adaptively build mixtures of local experts from selfish, heterogeneous and limited resource producers. The model is embedded into SIGMA (System of Information Gathering Market-based Agents). Preliminary evaluation experiments are reported on the application of the system to an information filtering task. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ghahramani, Z. and Jordan, M. </author> <year> 1994. </year> <title> Supervised learning from incomplete data via an EM approach. </title> <booktitle> In Advances in Neural Information Processing Systems 6, </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: Within the statistics and neural network communities, the idea of distributing a supervised/unsupervised learning problem among a set of local experts has been proposed for robustness against non-stationarity (McLachlan & Basford 1988; Jordan & Jacobs 1994) and partial observability <ref> (Ghahramani & Jordan 1994) </ref>. These local experts compete with each other in order to acquire local expertise in regions of the input space which may be overlapping. In the models so developed, gating of the experts is fixed and depends on prior assumptions about the input data distributions.
Reference: <author> Huberman, B.A.; and Hogg, T. </author> <year> 1995. </year> <title> Distributed computation as an economic system. </title> <journal> Journal of Economic Perspectives, </journal> <volume> 9(1) </volume> <pages> 141-152. </pages>
Reference-contexts: Most of the market-like systems that are currently developed focus on finding an appropriate agent for solving a single task <ref> (Huberman & Hogg 1995) </ref>. In addition, learning within these systems occurs by mixing market and heuristic mechanisms for adjusting prices.
Reference: <author> Jaakola, T.; Singh, S.; and Jordan, M. </author> <year> 1995. </year> <title> Reinforcement learning algorithms for partially observable markovian decision processes. </title> <booktitle> In Advances in Neural Information Processing Systems 7. </booktitle>
Reference: <author> Jordan, M.; and Jacobs, R. </author> <year> 1994. </year> <title> Hierarchical mixtures of experts and the EM algorithm. </title> <journal> Neural Computation, </journal> <volume> 6, </volume> <pages> 181-214. </pages>
Reference-contexts: Within the statistics and neural network communities, the idea of distributing a supervised/unsupervised learning problem among a set of local experts has been proposed for robustness against non-stationarity (McLachlan & Basford 1988; Jordan & Jacobs 1994) and partial observability <ref> (Ghahramani & Jordan 1994) </ref>. These local experts compete with each other in order to acquire local expertise in regions of the input space which may be overlapping. In the models so developed, gating of the experts is fixed and depends on prior assumptions about the input data distributions.
Reference: <author> Karakoulas, G.; and Ferguson, I. </author> <year> 1996. </year> <title> SIGMA: Integrating learning techniques in computational markets for information filtering. </title> <booktitle> In Proceedings of AAAI 96 Spring Symposium on Machine Learning and Information Access, </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: by using VSM; and (ii) the Profile Generators (PG) which are mid-producers since each of them takes as input a subset of the output of the FE producers and transforms it into a profile (a compact representation of documents) which the PG agent expects will satisfy the respective consumers interests <ref> (Karakoulas & Ferguson 1996) </ref>. To generate the VSM representation of an article an FE agent first parses the document for eliminating noisy words and extracting stemmed terms.
Reference: <author> Karakoulas, G. </author> <year> 1995. </year> <title> A Q-Learning approach to cost-effective classification. </title> <type> Technical Report NRC-38390, </type> <institution> Knowledge Systems Laboratory, National Research Council, Ottawa, ON, Canada. </institution>
Reference-contexts: The PS agent uses the feedback to update its Q-value function and propagates it to the PGs for them to update their efficiencies. We have developed a learning algorithm for implementing this learning behavior of the PS agent based on earlier work on a Q-learning algorithm for cost-effective classification <ref> (Karakoulas 1995) </ref>. Scalability of SIGMA for an IF Task In the Usenet IF task the user submits a partial list of keywords that reects his/her interests.
Reference: <author> McLachlan, G.; and Basford, K. </author> <year> 1988. </year> <title> Mixture models. </title> <publisher> Mar-cel Dekker. </publisher>
Reference: <author> Mullen, T.; and Wellman, M. </author> <year> 1996. </year> <title> Some issues in the design of market-oriented agents. </title> <editor> In M. Wooldridge, </editor> <publisher> J.P. </publisher>
Reference: <editor> Mller and M.Tambe, eds., </editor> <booktitle> Intelligent Agents Volume II-Proceedings of the 1995 Workshop on Agent Theories, Architectures and Languages, Lecture Notes in Artificial Intelligence, </booktitle> <publisher> Springer Verlag. </publisher>
Reference: <author> Sahami, M.; Hearst, M.; and Saund, E. </author> <year> 1996. </year> <title> Applying the multiple cause mixture model to text categorization. </title> <booktitle> In Proceedings of AAAI 96 Spring Symposium on Machine Learning and Information Access, </booktitle> <publisher> AAAI Press. </publisher>
Reference: <author> Salton, G; and McGill, M. </author> <year> 1983. </year> <title> Introduction to modern information retrieval. </title> <publisher> McGraw-Hill. </publisher>
Reference-contexts: In this IF task the type of good which is exchanged most within SIGMA, is the Vector Space Model (VSM) representation of an article <ref> (Salton & McGill 1983) </ref>. Like any other type of document an article contains structured information in its header part (author, subject, newsgroup, etc.) as well as unstructured information in its text part.
Reference: <author> Salton, G.; and Buckley, C. </author> <year> 1987. </year> <title> Term weighting approaches in automated text retrieval. </title> <type> Technical Report 87-88, </type> <institution> Cornell University, Department of Computer Science. </institution>
Reference-contexts: Throughout its operation the agent updates its profile with the user evaluation feedback (an integer in the range [0,5]) for each article that it sells to the PS agent. The term weight vector of the PG i s profile is updated according to <ref> (Salton & Buckley 1987) </ref> (8) where a is the learning rate, r is the reward received from PS and w (t,d) is the term weight vector of document d.
Reference: <author> Schaerf, A.; Shoham, Y.; and Tennenholtz, M. </author> <year> 1995. </year> <title> Adaptive load balancing: A study in multi-agent learning. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 2 </volume> <pages> 475-500. </pages>
Reference-contexts: In the reinforcement learning community, part of the success in Tesauros TD-Backgammon player (Tesauro 1995) can be attributed to learning from games against a fictitious opponent that is embedded into the system. Also, in <ref> (Schaerf et al. 1995) </ref> multi-agent reinforcement learning is applied to study the dynamics of an emergent load-balancing system. In this work, we propose a model of multi-agent learning based on the metaphor of economic markets. Markets have been devised within economics for allocating limited or scarce resources among competing agents.
Reference: <author> Tesauro, G. </author> <year> 1995. </year> <title> Temporal difference learning and TD-Gammon. </title> <booktitle> Communication of the ACM, </booktitle> <pages> 58-67. </pages>
Reference-contexts: In the models so developed, gating of the experts is fixed and depends on prior assumptions about the input data distributions. In the reinforcement learning community, part of the success in Tesauros TD-Backgammon player <ref> (Tesauro 1995) </ref> can be attributed to learning from games against a fictitious opponent that is embedded into the system. Also, in (Schaerf et al. 1995) multi-agent reinforcement learning is applied to study the dynamics of an emergent load-balancing system.
Reference: <author> Tsitsiklis, J.; and Van Roy, B. </author> <year> 1996. </year> <title> Feature-based methods for large state dynamic programming. </title> <journal> Machine Learning, </journal> 22(1/2/3):59-94. 
Reference: <author> Wellman, </author> <title> M.P. 1994. A computational market model for distributed configuration design. </title> <booktitle> In Proceedings Conference of the American Association for Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <month> 401407. </month>
Reference: <author> Whitehead, S.; and Lin, L. </author> <year> 1995. </year> <title> Reinforcement learning of non-markov decision processes. </title> <journal> Artificial Intelligence, </journal> <volume> 73 </volume> <pages> 271-306. </pages>
References-found: 17

