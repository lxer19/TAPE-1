URL: ftp://ftp.cs.toronto.edu/pub/zoubin/cohn96a.ps.Z
Refering-URL: http://www.cs.toronto.edu/~zoubin/older.html
Root-URL: 
Email: cohn@harlequin.com  zoubin@cs.toronto.edu  jordan@psyche.mit.edu  
Title: Active Learning with Statistical Models  
Author: David A. Cohn Zoubin Ghahramani Michael I. Jordan 
Address: Cambridge, MA 02139 USA  
Affiliation: Center for Biological and Computational Learning Dept. of Brain and Cognitive Sciences Massachusetts Institute of Technology  
Note: Journal of Artificial Intelligence Research 4 (1996) 129-145 Submitted 11/95; published 3/96  
Abstract: For many types of machine learning algorithms, one can compute the statistically "optimal" way to select training data. In this paper, we review how optimal data selection techniques have been used with feedforward neural networks. We then show how the same principles may be used to select data for two alternative, statistically-based learning architectures: mixtures of Gaussians and locally weighted regression. While the techniques for neural networks are computationally expensive and approximate, the techniques for mixtures of Gaussians and locally weighted regression are both efficient and accurate. Empirically, we observe that the optimality criterion sharply decreases the number of training examples the learner needs in order to achieve good performance.
Abstract-found: 1
Intro-found: 1
Reference: <author> Angluin, D. </author> <year> (1988). </year> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2, </volume> <pages> 319-342. </pages>
Reference: <author> Baum, E., & Lang, K. </author> <year> (1991). </year> <title> Neural network algorithms that learn in polynomial time from examples and queries. </title> <journal> IEEE Trans. Neural Networks, </journal> <volume> 2. </volume>
Reference: <author> Box, G., & Draper, N. </author> <year> (1987). </year> <title> Empirical model-building and response surfaces. </title> <publisher> Wiley. </publisher>
Reference-contexts: The favored technique for this kind of optimization is usually a form of response surface methodology <ref> (Box & Draper, 1987) </ref>, which performs experiments that guide hill-climbing through the input space. A related problem exists in the field of adaptive control, where one must learn a control policy by taking actions.
Reference: <author> Cheeseman, P., Self, M., Kelly, J., Taylor, W., Freeman, D., & Stutz, J. </author> <year> (1988). </year> <title> Bayesian classification. </title> <booktitle> In AAAI 88, The 7th National Conference on Artificial Intelligence, </booktitle> <pages> pp. 607-611. </pages> <publisher> AAAI Press. </publisher>
Reference: <author> Cleveland, W., Devlin, S., & Grosse, E. </author> <year> (1988). </year> <title> Regression by local fitting. </title> <journal> Journal of Econometrics, </journal> <volume> 37, </volume> <pages> 87-114. </pages>
Reference-contexts: A regression is then computed using the weighted points. We consider here a form of locally weighted regression that is a variant of the LOESS model <ref> (Cleveland, Devlin, & Grosse, 1988) </ref>. The LOESS model performs a linear regression on points in the data set, weighted by a kernel centered at x (see Figure 2).
Reference: <author> Cohn, D. </author> <year> (1994). </year> <title> Neural network exploration using optimal experiment design. </title> <editor> In Cowan, J., Tesauro, G., & Alspector, J. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 6. </booktitle> <address> Morgan Kaufmann. </address> <note> Expanded version available as MIT AI Lab memo 1491 by anonymous ftp to publications.ai.mit.edu. </note>
Reference-contexts: See Cohn (1994) for details. In practice, @ ^y=@w may be highly nonlinear, and P (yjx) may be far from Gaussian; in spite of this, empirical results show that it works well on some problems <ref> (Cohn, 1994) </ref>. It has the advantage of being grounded in statistics, and is optimal given the assumptions. Furthermore, the expectation is differentiable with respect to ~x. <p> In these cases, it is more efficient to differentiate Equation 9 and hillclimb on @ D ^y =@ ~x to find a locally maximal ~x. See, for example, <ref> (Cohn, 1994) </ref>. 4. Locally Weighted Regression Model-based methods, such as neural networks and the mixture of Gaussians, use the data to build a parameterized model. After training, the model is used for predictions and the data are generally discarded.
Reference: <author> Cohn, D. </author> <year> (1995). </year> <title> Minimizing statistical bias with queries. </title> <institution> AI Lab memo AIM-1552, Massachusetts Institute of Technology. </institution> <note> Available by anonymous ftp from publications.ai.mit.edu. </note>
Reference-contexts: As noted in Section 2, the learner's error is composed of both bias and variance. The variance-minimizing strategy examined here ignores the bias component, which can lead to significant errors when the learner's bias is non-negligible. Work in progress examines effective ways of measuring and optimally eliminating bias <ref> (Cohn, 1995) </ref>; future work will examine how to jointly minimize both bias and variance to produce a criterion that truly minimizes the learner's expected error. Another direction for future research is the derivation of variance- (and bias-) minimizing techniques for other statistical learning models.
Reference: <author> Cohn, D., Atlas, L., & Ladner, R. </author> <year> (1990). </year> <title> Training connectionist networks with queries and selective sampling. </title> <editor> In Touretzky, D. (Ed.), </editor> <booktitle> Advances in Neural Information Processing Systems 2. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: There are many heuristics for choosing ~x, including choosing places where we don't have data (Whitehead, 1991), where we perform poorly (Linden & Weber, 1993), where we have low confidence (Thrun & Moller, 1992), where we expect it to change our model <ref> (Cohn, Atlas, & Ladner, 1990, 1994) </ref>, and where we previously found data that resulted in learning (Schmidhuber & Storck, 1993). In this paper we will consider how one may select ~x in a statistically "optimal" manner for some classes of machine learning algorithms.
Reference: <author> Cohn, D., Atlas, L., & Ladner, R. </author> <year> (1994). </year> <title> Improving generalization with active learning. </title> <journal> Machine Learning, </journal> <volume> 5 (2), </volume> <pages> 201-221. </pages>
Reference-contexts: See Cohn (1994) for details. In practice, @ ^y=@w may be highly nonlinear, and P (yjx) may be far from Gaussian; in spite of this, empirical results show that it works well on some problems <ref> (Cohn, 1994) </ref>. It has the advantage of being grounded in statistics, and is optimal given the assumptions. Furthermore, the expectation is differentiable with respect to ~x. <p> In these cases, it is more efficient to differentiate Equation 9 and hillclimb on @ D ^y =@ ~x to find a locally maximal ~x. See, for example, <ref> (Cohn, 1994) </ref>. 4. Locally Weighted Regression Model-based methods, such as neural networks and the mixture of Gaussians, use the data to build a parameterized model. After training, the model is used for predictions and the data are generally discarded.
Reference: <author> Dempster, A., Laird, N., & Rubin, D. </author> <year> (1977). </year> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> J. Royal Statistical Society Series B, </journal> <volume> 39, </volume> <pages> 1-38. </pages>
Reference-contexts: In the context of learning from random examples, one begins by producing a joint density estimate over the input/output space X fiY based on the training set D. The EM algorithm <ref> (Dempster, Laird, & Rubin, 1977) </ref> can be used to efficiently find a locally optimal fit of the Gaussians to the data. It is then straightforward to compute ^y given x by conditioning the joint distribution on x and taking the expected value. density.
Reference: <author> Fedorov, V. </author> <year> (1972). </year> <title> Theory of Optimal Experiments. </title> <publisher> Academic Press. </publisher>
Reference: <author> Fe'ldbaum, A. A. </author> <year> (1965). </year> <title> Optimal control systems. </title> <publisher> Academic Press, </publisher> <address> New York, NY. </address> <note> 144 Active Learning with Statistical Models Geman, </note> <author> S., Bienenstock, E., & Doursat, R. </author> <year> (1992). </year> <title> Neural networks and the bias/variance dilemma. </title> <journal> Neural Computation, </journal> <volume> 4, </volume> <pages> 1-58. </pages>
Reference: <author> Ghahramani, Z., & Jordan, M. </author> <year> (1994). </year> <title> Supervised learning from incomplete data via an EM approach. </title> <editor> In Cowan, J., Tesauro, G., & Alspector, J. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 6. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: With the mixture model, it is also straightforward to compute the mode of the output, rather than its mean, which obviates many of the problems of learning direct inverse models <ref> (Ghahramani & Jordan, 1994) </ref>. 133 Cohn, Ghahramani & Jordan For each Gaussian g i we will denote the input/output means as x;i and y;i and vari ances and covariances as 2 x;i , 2 y;i and xy;i respectively.
Reference: <author> Heckerman, D., Geiger, D., & Chickering, D. </author> <year> (1994). </year> <title> Learning Bayesian networks: the combination of knowledge and statistical data. </title> <type> Tech report MSR-TR-94-09, </type> <institution> Microsoft. </institution>
Reference: <author> Linden, A., & Weber, F. </author> <year> (1993). </year> <title> Implementing inner drive by competence reflection. </title> <editor> In Roitblat, H. (Ed.), </editor> <booktitle> Proceedings of the 2nd International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: The question we will be concerned with is how to choose which ~x to try next. There are many heuristics for choosing ~x, including choosing places where we don't have data (Whitehead, 1991), where we perform poorly <ref> (Linden & Weber, 1993) </ref>, where we have low confidence (Thrun & Moller, 1992), where we expect it to change our model (Cohn, Atlas, & Ladner, 1990, 1994), and where we previously found data that resulted in learning (Schmidhuber & Storck, 1993).
Reference: <author> MacKay, D. J. </author> <year> (1992). </year> <title> Information-based objective functions for active data selection. </title> <journal> Neural Computation, </journal> <volume> 4 (4), </volume> <pages> 590-604. </pages>
Reference-contexts: The estimated output variance of the network is 2 @w @w 2 @ ^y (x) ; <ref> (MacKay, 1992) </ref> where the true variance is approximated by a second-order Taylor series expansion around S 2 . This estimate makes the assumption that @ ^y=@w is locally linear.
Reference: <author> Nowlan, S. </author> <year> (1991). </year> <title> Soft competitive adaptation: Neural network learning algorithms based on fitting statistical mixtures. </title> <type> Tech report CS-91-126, </type> <institution> Carnegie Mellon University. </institution>
Reference: <author> Paass, G., & Kindermann, J. </author> <year> (1995). </year> <title> Bayesian query construction for neural network models. </title>
Reference: <editor> In Tesauro, G., Touretzky, D., & Leen, T. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 7. </booktitle> <publisher> MIT Press. </publisher>
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probablistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Plutowski, M., & White, H. </author> <year> (1993). </year> <title> Selecting concise training sets from clean data. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 4, </volume> <pages> 305-318. </pages>
Reference: <author> Schaal, S., & Atkeson, C. </author> <year> (1994). </year> <title> Robot juggling: An implementation of memory-based learning. </title> <journal> Control Systems, </journal> <volume> 14, </volume> <pages> 57-71. </pages>
Reference-contexts: Locally weighted regression (LWR) is a memory-based method that performs a regression around a point of interest using only training data that are "local" to that point. One recent study demonstrated that LWR was suitable for real-time control by constructing an LWR-based system that learned a difficult juggling task <ref> (Schaal & Atkeson, 1994) </ref>. x in question using a kernel. A regression is then computed using the weighted points. We consider here a form of locally weighted regression that is a variant of the LOESS model (Cleveland, Devlin, & Grosse, 1988).
Reference: <author> Schmidhuber, J., & Storck, J. </author> <year> (1993). </year> <title> Reinforcement driven information acquisition in nondeterministic environments. </title> <type> Tech report, </type> <institution> Fakultat fur Informatik, Technische Univer-sitat Munchen. </institution>
Reference-contexts: choosing places where we don't have data (Whitehead, 1991), where we perform poorly (Linden & Weber, 1993), where we have low confidence (Thrun & Moller, 1992), where we expect it to change our model (Cohn, Atlas, & Ladner, 1990, 1994), and where we previously found data that resulted in learning <ref> (Schmidhuber & Storck, 1993) </ref>. In this paper we will consider how one may select ~x in a statistically "optimal" manner for some classes of machine learning algorithms. We first briefly review how the statistical approach can be applied to neural networks, as described in earlier work (MacKay, 1992; Cohn, 1994).
Reference: <author> Specht, D. </author> <year> (1991). </year> <title> A general regression neural network. </title> <journal> IEEE Trans. Neural Networks, </journal> <volume> 2 (6), </volume> <pages> 568-576. </pages>
Reference: <author> Thrun, S., & Moller, K. </author> <year> (1992). </year> <title> Active exploration in dynamic environments. </title> <editor> In Moody, J., Hanson, S., & Lippmann, R. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 4. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The question we will be concerned with is how to choose which ~x to try next. There are many heuristics for choosing ~x, including choosing places where we don't have data (Whitehead, 1991), where we perform poorly (Linden & Weber, 1993), where we have low confidence <ref> (Thrun & Moller, 1992) </ref>, where we expect it to change our model (Cohn, Atlas, & Ladner, 1990, 1994), and where we previously found data that resulted in learning (Schmidhuber & Storck, 1993).
Reference: <author> Titterington, D., Smith, A., & Makov, U. </author> <year> (1985). </year> <title> Statistical Analysis of Finite Mixture Distributions. </title> <publisher> Wiley. </publisher>
Reference-contexts: In the rest of this paper, we consider two "non-neural" machine learning architectures that are much more amenable to optimal data selection. 3. Mixtures of Gaussians The mixture of Gaussians model is a powerful estimation and prediction technique with roots in the statistics literature <ref> (Titterington, Smith, & Makov, 1985) </ref>; it has, over the last few years, been adopted by researchers in machine learning (Cheeseman et al., 1988; Nowlan, 1991; Specht, 1991; Ghahramani & Jordan, 1994).
Reference: <author> Weisberg, S. </author> <year> (1985). </year> <title> Applied Linear Regression. </title> <publisher> Wiley. </publisher>
Reference-contexts: Problems requiring classification could be handled analogously with the appropriate models. For learning classification with a mixture model, one would select examples so as to maximize discriminability between Gaussians; for locally weighted regression, one would use a logistic regression instead of the linear one considered here <ref> (Weisberg, 1985) </ref>. Our future work will proceed in several directions. The most important is active bias minimization. As noted in Section 2, the learner's error is composed of both bias and variance.
Reference: <author> Whitehead, S. </author> <year> (1991). </year> <title> A study of cooperative mechanisms for faster reinforcement learning. </title> <type> Technical report CS-365, </type> <institution> University of Rochester, Rochester, </institution> <address> NY. </address> <month> 145 </month>
Reference-contexts: The question we will be concerned with is how to choose which ~x to try next. There are many heuristics for choosing ~x, including choosing places where we don't have data <ref> (Whitehead, 1991) </ref>, where we perform poorly (Linden & Weber, 1993), where we have low confidence (Thrun & Moller, 1992), where we expect it to change our model (Cohn, Atlas, & Ladner, 1990, 1994), and where we previously found data that resulted in learning (Schmidhuber & Storck, 1993).
References-found: 28

