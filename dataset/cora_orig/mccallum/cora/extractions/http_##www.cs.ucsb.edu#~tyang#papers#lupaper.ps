URL: http://www.cs.ucsb.edu/~tyang/papers/lupaper.ps
Refering-URL: http://www.cs.ucsb.edu/Research/rapid_sweb/RAPID.html
Root-URL: http://www.cs.ucsb.edu
Title: Efficient Sparse LU Factorization with Partial Pivoting on Distributed Memory Architectures  
Author: Cong Fu, Xiangmin Jiao and Tao Yang 
Keyword: GFLOPS on shared memory machines [8]. Index Terms: Sparse LU factorization, Gaussian Elimination with partial pivoting, Dense structures, Asynchronous computation scheduling, Irregular parallelism.  
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California  
Abstract: A sparse LU factorization based on Gaussian elimination with partial pivoting (GEPP) is important to many scientific applications, but it is still an open problem to develop a high performance GEPP code on distributed memory machines. The main difficulty is that partial pivoting operations dynamically change computation and nonzero fill-in structures during the elimination process. This paper presents an approach called S fl for parallelizing this problem on distributed memory machines. The S fl approach adopts static symbolic factorization to avoid run-time control overhead, incorporates 2-D L/U supernode partitioning and amalgamation strategies to improve caching performance, and exploits irregular task parallelism embedded in sparse LU using asynchronous computation scheduling. The paper discusses and compares the algorithms using 1-D and 2-D data mapping schemes, and presents experimental studies on Cray-T3D and T3E. The performance results for a set of nonsymmetric benchmark matrices are very encouraging and S fl has achieved up to 6.878 GFLOPS on 128 T3E nodes. This is the highest performance known for this challenging problem and the previous record was 2.583 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Ashcraft and R. Grimes. </author> <title> The Influence of Relaxed Supernode Partitions on the Multifrontal Method. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 15(4) </volume> <pages> 291-309, </pages> <year> 1989. </year>
Reference-contexts: We also incorporate a supernode amalgamation <ref> [1, 10] </ref> technique to increase the granularity of the computation. In exploiting irregular parallelism in the re-designed sparse LU algorithm, we have experimented with two mapping methods, one of which uses 1-D data mapping and the other uses 2-D data mapping.
Reference: [2] <author> C. Ashcraft, R. Grimes, J. Lewis, B. Peyton, and H. Simon. </author> <title> Progress in Sparse Matrix Methods for Large Sparse Linear Systems on Vector Supercomputers. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 1 </volume> <pages> 10-30, </pages> <year> 1987. </year>
Reference-contexts: af23560 23560 460598 1.054 30.39 44.39 57.40 1.46 3.16 14 vavasis3 41092 1683902 1.999 29.21 32.03 38.75 1.10 1.43 Table 1: Testing matrices and their statistics. 3.2 2-D L/U supernode partitioning and dense structure identification Supernode partitioning is a commonly used technique to improve the caching performance of sparse code <ref> [2] </ref>. For a symmetric sparse matrix, a supernode is defined as a group of consecutive columns that have nested structure in the L factor of the matrix. Excellent performance has been achieved in [26, 30, 31] using supernode partitioning for Cholesky factorization.
Reference: [3] <author> T. Davis. </author> <title> User's guide for the Unsymmetric-pattern Multifrontal Package (UMFPACK). </title> <type> Technical Report TR-93-020, </type> <institution> Computer and Information Sciences Department, University of Florida, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: SuperLU performs symbolic factorization and generates supernodes on the fly as the factorization proceeds. UMFPACK is another competitive sequential code for this problem and neither SuperLU nor UMFPACK is always better than the other <ref> [3, 4, 7] </ref>. MA41 is a code for sparse matrices with symmetric patterns. All of them are regarded as of high quality and deliver excellent megaflop performance.
Reference: [4] <author> T. Davis. </author> <type> Personal Communication, </type> <year> 1997. </year>
Reference-contexts: SuperLU performs symbolic factorization and generates supernodes on the fly as the factorization proceeds. UMFPACK is another competitive sequential code for this problem and neither SuperLU nor UMFPACK is always better than the other <ref> [3, 4, 7] </ref>. MA41 is a code for sparse matrices with symmetric patterns. All of them are regarded as of high quality and deliver excellent megaflop performance.
Reference: [5] <author> T. Davis and I. S. Duff. </author> <title> An Unsymmetric-pattern Multifrontal Method for Sparse LU factorization. </title> <journal> SIAM Matrix Analysis & Applications, </journal> <month> January </month> <year> 1997. </year>
Reference-contexts: The adaptive and irregular nature of sparse LU data structures makes an efficient implementation of this algorithm very hard even on a modern sequential machine with memory hierarchies. There are several approaches that can be used for solving nonsymmetric systems. One approach is the unsymmetric-pattern multi-frontal method <ref> [5, 25] </ref> that uses elimination graphs to model irregular parallelism and guide the parallel computation. Another approach [19] is to restructure a sparse matrix into a bordered block upper triangular form and use a special pivoting technique which preserves the structure and maintains numerical stability at acceptable levels. <p> For sparse LU, an elimination tree of A T A does not directly reflect the available parallelism. Dynamically created DAGs have been used for modeling parallelism and guiding run-time execution in a nonsymmetric multi-frontal method <ref> [5, 25] </ref>. Given the task definitions in Figures 6, 7 and 8 we can define the structure of a sparse LU task graph in the following.
Reference: [6] <author> J. Demmel. </author> <title> Numerical Linear Algebra on Parallel Processors. </title> <booktitle> Lecture Notes for NSF-CBMS Regional Conference in the Mathematical Sciences, </booktitle> <month> June </month> <year> 1995. </year> <note> To be published as a book by SIAM. </note>
Reference-contexts: However in many applications, the associated equation systems involve nonsymmetric matrices and pivoting may be required to maintain numerical stability for such nonsymmetric linear systems <ref> [6, 23] </ref>. <p> Develop scheduling techniques for exploiting maximum irregular parallelism and reducing memory requirements for solving large problems. We observe that on most current commodity processors with memory hierarchies, a highly optimized BLAS-3 subroutine usually outperforms a BLAS-2 subroutine in implementing the same numerical operations <ref> [6, 9] </ref>. We can afford to introduce some extra BLAS-3 operations in re-designing the LU algorithm so that the new algorithm is easy to be parallelized but the sequential performance of this code is still competitive to the current best sequential code. <p> It is also a fact that BLAS-3 routine DGEMM (matrix-matrix multiplication) is usually much faster than BLAS-1 and BLAS-2 routines <ref> [6] </ref>. On Cray-T3D with a matrix of size 25 fi 25, DGEMM can achieve 103 MFLOPS while DGEMV only reaches 85 MFLOPS. <p> Instead of performing the row interchange to the right part of the matrix right after each pivoting search, a technique called "delayed-pivoting" is used <ref> [6] </ref>. In this technique, the pivoting sequence is held until the factorization of the k-th column block is completed. Then the pivoting sequence is applied to the rest of the matrix, i.e., interchange rows.
Reference: [7] <author> J. Demmel, S. Eisenstat, J. Gilbert, X. Li, and J. Liu. </author> <title> A Supernodal Approach to Sparse Partial Pivoting. </title> <type> Technical Report CSD-95-883, </type> <institution> UC Berkeley, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: It is easy to get speedups by comparing a parallel code to a sequential code which does not fully exploit the uniprocessor capability, but it is not as easy to parallelize a highly optimized sequential code. One such sequential code is SuperLU <ref> [7] </ref> which uses a supernode approach to conduct sequential sparse LU with partial pivoting. The supernode partitioning makes it possible to perform most of the numerical updates using BLAS-2 level dense matrix-vector multiplications, and therefore to better exploit memory hierarchies. <p> SuperLU performs symbolic factorization and generates supernodes on the fly as the factorization proceeds. UMFPACK is another competitive sequential code for this problem and neither SuperLU nor UMFPACK is always better than the other <ref> [3, 4, 7] </ref>. MA41 is a code for sparse matrices with symmetric patterns. All of them are regarded as of high quality and deliver excellent megaflop performance. <p> We will use this static strategy in our S fl approach. But the overestimation does in-troduce extra fill-ins and lead to a substantial amount of unnecessary operations in the numerical factorization. We observe that in SuperLU <ref> [7] </ref> the DGEMV routine (the BLAS-2 level dense matrix vector multiplication) accounts for 78% to 98% of the floating point operations (excluding the symbolic factorization part). It is also a fact that BLAS-3 routine DGEMM (matrix-matrix multiplication) is usually much faster than BLAS-1 and BLAS-2 routines [6]. <p> Thus it is necessary and beneficial to identify dense structures in a sparse matrix after the static symbolic factorization. It should be noted that there are some cases that static symbolic factorization leads to excessive overestimation. For example, memplus matrix <ref> [7] </ref> is such a case. The static scheme produces 119 times as many nonzeros as SuperLU does. In fact, for this case, the ordering for SuperLU is applied based on A T + A instead of A T A. <p> In fact, for this case, the ordering for SuperLU is applied based on A T + A instead of A T A. Otherwise the overestimation ratio is 2.34 if using A T A for SuperLU also. For another matrix wang3 <ref> [7] </ref>, the static scheme produces 4 times as many nonzeros as SuperLU does. But our code can still produce 1 GFLOPS for it on 128 nodes of T3E. This paper focuses on the development of a high performance parallel code when overestimation ratios are not too high. <p> Excellent performance has been achieved in [26, 30, 31] using supernode partitioning for Cholesky factorization. However, the above definition is not directly applicable to sparse LU with nonsymmetric matrices. A good analysis for defining unsymmetric supernodes in an L factor is available in <ref> [7] </ref>. Notice that supernodes may need to be further broken into smaller ones to fit into cache and to expose more parallelism. <p> This results in very fine grained tasks. Amalgamating small supernodes can lead to great performance improvement for both parallel and sequential sparse codes because it can improve caching performance and reduce interprocessor communication overhead. There could be many ways to amalgamate supernodes <ref> [7, 30] </ref>. The basic idea is to relax the restriction that all the columns in a supernode must have exactly the same nonzero structure below diagonal. The amalgamation is usually guided by a supernode elimination tree. <p> Let be the ratio of symbolic factorization time to numerical factorization time in SuperLU, then we simplify Equation (1) to the following: T SuperLU = (1 + ) ! 2 C: (3) We estimate that 0:82 for the tested matrices based on the results in <ref> [7] </ref>. In [17], we have also measured as approximately 0:67. The ratios of the number of floating point operations performed in S fl and SuperLU for the tested matrices are available in Table 1. In average, the value of C 0 C is 3:98.
Reference: [8] <author> J. Demmel, J. Gilbert, and X. Li. </author> <title> An Asynchronous Parallel Supernodal Algorithm for Sparse Gaussian Elimination. </title> <type> Technical Report CSD-97-943, </type> <institution> UC Berkeley, </institution> <month> February </month> <year> 1997. </year>
Reference-contexts: Using these ideas, we are able to exploit more data regularity for this open irregular problem and achieve up to 6.878 GFLOPS on 128 T3E nodes. This is the highest performance known for this challenging problem and the previous record was 2.583 GFLOPS on shared memory machines <ref> [8] </ref>. 28 Matrix P=2 P=4 P=8 P=16 P=32 P=64 sherman5 7.7% 6.4% 19.4% 28.1% 25.9% 24.1% lnsp3937 7.3% 7.1% 22.2% 28.57% 26.9% 27.9% lns3937 6.6% 2.8% 18.8% 26.5% 28.6% 26.8% sherman3 10.2% 12.4% 20.3% 22.7% 26.0% 25.0% jpwh991 8.7% 10.0% 23.8% 33.3% 35.7% 28.6% orsreg1 6.1% 7.7% 17.5% 28.0% 20.5% 28.2%
Reference: [9] <author> J. Dongarra, J. Du Croz, S. Hammarling, and R. Hanson. </author> <title> An Extended Set of Basic Linear Algebra Subroutines. </title> <journal> ACM Trans. on Mathematical Software, </journal> <volume> 14 </volume> <pages> 18-32, </pages> <year> 1988. </year>
Reference-contexts: Develop scheduling techniques for exploiting maximum irregular parallelism and reducing memory requirements for solving large problems. We observe that on most current commodity processors with memory hierarchies, a highly optimized BLAS-3 subroutine usually outperforms a BLAS-2 subroutine in implementing the same numerical operations <ref> [6, 9] </ref>. We can afford to introduce some extra BLAS-3 operations in re-designing the LU algorithm so that the new algorithm is easy to be parallelized but the sequential performance of this code is still competitive to the current best sequential code.
Reference: [10] <author> I. Duff and J. Reid. </author> <title> The Multifrontal Solution of Indefinite Sparse Symmetric Systems of Equations. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 9 </volume> <pages> 302-325, </pages> <year> 1983. </year>
Reference-contexts: We also incorporate a supernode amalgamation <ref> [1, 10] </ref> technique to increase the granularity of the computation. In exploiting irregular parallelism in the re-designed sparse LU algorithm, we have experimented with two mapping methods, one of which uses 1-D data mapping and the other uses 2-D data mapping.
Reference: [11] <author> I. S. Duff. </author> <title> On Algorithms for Obtaining a Maximum Transversal. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 7(3) </volume> <pages> 315-330, </pages> <month> September </month> <year> 1981. </year>
Reference-contexts: For any nonsingular matrix which does not have a zero-free diagonal, it is always possible to permute the rows of the matrix so that the permuted matrix has a 5 zero-free diagonal <ref> [11] </ref>. Though the symbolic factorization does work on a matrix that contains zero entries in the diagonal, it is not preferable because it makes the overestimation too generous. <p> This symbolic factorization is applied after an ordering is performed on the matrix A to reduce fill-ins. The ordering we are currently using is the multiple minimum degree ordering for A T A. We also permute the rows of the matrix using a transversal obtained from Duff's algorithm <ref> [11] </ref> to make A have a zero-free diagonal. The transversal can often help reduce fill-ins [12]. We have tested the storage impact of overestimation for a number of nonsymmetric testing matrices from various sources. The results are listed in Table 1.
Reference: [12] <author> I. S. Duff. </author> <type> Personal Communication, </type> <year> 1996. </year> <month> 30 </month>
Reference-contexts: The ordering we are currently using is the multiple minimum degree ordering for A T A. We also permute the rows of the matrix using a transversal obtained from Duff's algorithm [11] to make A have a zero-free diagonal. The transversal can often help reduce fill-ins <ref> [12] </ref>. We have tested the storage impact of overestimation for a number of nonsymmetric testing matrices from various sources. The results are listed in Table 1.
Reference: [13] <author> S. Eisenstat and J. W. H. Liu. </author> <title> Structural Representations of Schur Complements in Sparse Matrices, volume 56 of Graph Theory and Sparse Matrix Computation (Edited by Alan George and John R. </title> <editor> Gilbert and Joseph W.H. </editor> <booktitle> Liu), </booktitle> <pages> pages 85-100. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: There are other issues which are related to this work and need to be further studied, for example, alternative for parallel sparse LU based on Schur complements <ref> [13] </ref> and static estimation and parallelism exploitation for sparse QR [29, 35]. It should be noted that the static symbolic factorization could fail to be practical if the input matrix has a nearly dense row because it will lead to an almost complete fill-in of the whole matrix.
Reference: [14] <author> C. Fu, X. Jiao, and T. Yang. </author> <title> A Comparison of 1-D and 2-D Data Mapping for Sparse LU Factorization with Partial Pivoting. </title> <booktitle> In Proc. of Eighth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <month> March </month> <year> 1997. </year>
Reference-contexts: It shows that asynchronous design improves performance significantly, especially on large number of processors on T3E. It demonstrates the importance of exploiting parallelism using asynchronous execution. The experiment 27 data on T3D is in <ref> [14] </ref>. 7 Concluding remarks In this paper we present an approach for parallelizing sparse LU factorization with partial pivoting on distributed memory machines.
Reference: [15] <author> C. Fu and T. Yang. </author> <title> Efficient Run-time Support for Irregular Task Computations with Mixed Granularities. </title> <booktitle> In Proceedings of IEEE International Parallel Processing Symposium, </booktitle> <pages> pages 823-830, </pages> <address> Hawaii, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: One advantage of using 1-D data mapping is that the corresponding LU algorithm can be easily modeled by directed acyclic task graphs (DAGs). Graph scheduling techniques and efficient run-time support are available to schedule and execute DAG parallelism <ref> [15, 16] </ref>. Scheduling and executing DAG parallelism is a difficult job because parallelism in sparse problems is irregular and execution must be asynchronous. The important optimizations are overlapping computation with communication, balancing processor loads and eliminating unnecessary communication overhead. <p> if column block k has not been received (15) Receive column block k and the pivoting choices; (16) Interchange rows according to the pivoting sequence; (17) Perform task U pdate (k; j); (18) endfor (19) endfor Graph scheduling has been shown effective in exploiting irregular parallelism for other applications (e.g. <ref> [15, 16] </ref>). Graph scheduling should outperform the CA scheduling for sparse LU because it 15 does not have a constraint in ordering F actor () tasks. We demonstrate this point using the LU task graph in Figure 9. <p> It does not incur any copying/buffering during a data transfer since low communication overhead is critical for sparse code with mixed granularities. RMA is available in modern multi-processor architectures such as Cray-T3D [34], T3E [32] and Meiko CS-2 <ref> [15] </ref>. Since the RMA directly writes data to a remote address, it is possible that the content at the remote address is still being used by other tasks and then the execution at the remote processor could be incorrect.
Reference: [16] <author> C. Fu and T. Yang. </author> <title> Run-time Compilation for Parallel Sparse Matrix Computations. </title> <booktitle> In Proceedings of ACM International Conference on Supercomputing, </booktitle> <pages> pages 237-244, </pages> <address> Philadelphia, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: One advantage of using 1-D data mapping is that the corresponding LU algorithm can be easily modeled by directed acyclic task graphs (DAGs). Graph scheduling techniques and efficient run-time support are available to schedule and execute DAG parallelism <ref> [15, 16] </ref>. Scheduling and executing DAG parallelism is a difficult job because parallelism in sparse problems is irregular and execution must be asynchronous. The important optimizations are overlapping computation with communication, balancing processor loads and eliminating unnecessary communication overhead. <p> We add one more property, that while not necessary, simplifies implementation. This property essentially does not allow exploiting commutativity among U pdate () tasks. However, according to our experience with Cholesky factorization <ref> [16] </ref>, the performance loss due to this property is not substantial, about 6% in average when graph scheduling is used. * There is a dependence from U pdate (k; j) to U pdate (k 0 ; j), where k &lt; k 0 and there exists no task U pdate (t; j) <p> if column block k has not been received (15) Receive column block k and the pivoting choices; (16) Interchange rows according to the pivoting sequence; (17) Perform task U pdate (k; j); (18) endfor (19) endfor Graph scheduling has been shown effective in exploiting irregular parallelism for other applications (e.g. <ref> [15, 16] </ref>). Graph scheduling should outperform the CA scheduling for sparse LU because it 15 does not have a constraint in ordering F actor () tasks. We demonstrate this point using the LU task graph in Figure 9. <p> However the implementation of the CA algorithm is much easier since the efficient execution of a sparse task graph schedule requires a sophisticated run-time system to support asynchronous communication protocols. We have used the RAPID run-time system <ref> [16] </ref> for the parallelization of sparse LU using graph scheduling. The key optimization is to use Remote Memory Access (RMA) to communicate a data object between two processors. It does not incur any copying/buffering during a data transfer since low communication overhead is critical for sparse code with mixed granularities. <p> Thus for a general computation, a permission to write the remote address needs to be obtained before issuing a remote write. However in the RAPID system, this hand-shaking process is avoided by a carefully designed task communication protocol <ref> [16] </ref>. This property greatly reduces task synchronization cost. As shown in [17], the RAPID sparse code can deliver more than 70% of the speedup predicted by the scheduler on Cray-T3D. <p> For sparse LU, each processor in the worst case may need a space for holding the entire matrix. The RAPID system <ref> [16] </ref> also needs extra memory space to hold dependence structures. Based on the above observation, our goal for the 2-D code is to reduce memory space requirement while exploiting a reasonable amount of parallelism so that it can solve large problem instances in an efficient way.
Reference: [17] <author> C. Fu and T. Yang. </author> <title> Sparse LU Factorization with Partial Pivoting on Distributed Memory Machines. </title> <booktitle> In Proceedings of ACM/IEEE Supercomputing, </booktitle> <address> Pittsburgh, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: Thus for a general computation, a permission to write the remote address needs to be obtained before issuing a remote write. However in the RAPID system, this hand-shaking process is avoided by a carefully designed task communication protocol [16]. This property greatly reduces task synchronization cost. As shown in <ref> [17] </ref>, the RAPID sparse code can deliver more than 70% of the speedup predicted by the scheduler on Cray-T3D. <p> Let be the ratio of symbolic factorization time to numerical factorization time in SuperLU, then we simplify Equation (1) to the following: T SuperLU = (1 + ) ! 2 C: (3) We estimate that 0:82 for the tested matrices based on the results in [7]. In <ref> [17] </ref>, we have also measured as approximately 0:67. The ratios of the number of floating point operations performed in S fl and SuperLU for the tested matrices are available in Table 1. In average, the value of C 0 C is 3:98. <p> Let P T a and P T be the parallel time with and without supernode amalgamation respectively. The parallel time improvement ratios (1 P T a =P T ) on T3E for several testing matrices are listed in Table 4 and similar results on T3D are in <ref> [17] </ref>. Apparently the supernode amalgamation has brought significant improvement due to the increase of supernode size which implies an increase of the task granularities.
Reference: [18] <author> C. Fu and T. Yang. </author> <title> Space and Time Efficient Execution of Parallel Irregular Computations. </title> <booktitle> In Proc. of 6th ACM SIGPLAN Symposium on Principles & Practice of Parallel Programming, </booktitle> <pages> pages 57-68, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: Recently we have conducted research on developing space efficient scheduling algorithms while retaining good time efficiency <ref> [18] </ref>. It is still an open problem to develop advanced scheduling techniques that better exploit parallelism for 2-D sparse LU factorization with partial pivoting.
Reference: [19] <author> K. Gallivan, B. Marsolf, and H. Wijshoff. </author> <title> The Parallel Solution of Nonsymmetric Sparse Linear Systems Using H* Reordering and an Associated Factorization. </title> <booktitle> In Proc. of ACM International Conference on Supercomputing, </booktitle> <pages> pages 419-430, </pages> <address> Manchester, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: There are several approaches that can be used for solving nonsymmetric systems. One approach is the unsymmetric-pattern multi-frontal method [5, 25] that uses elimination graphs to model irregular parallelism and guide the parallel computation. Another approach <ref> [19] </ref> is to restructure a sparse matrix into a bordered block upper triangular form and use a special pivoting technique which preserves the structure and maintains numerical stability at acceptable levels. This method has been implemented on Illinois Cedar multi-processors based on Aliant shared memory clusters.
Reference: [20] <author> A. George and E. Ng. </author> <title> Symbolic Factorization for Sparse Gaussian Elimination with Partial Pivoting. </title> <journal> SIAM J. Scientific and Statistical Computing, </journal> <volume> 8(6) </volume> <pages> 877-898, </pages> <month> November </month> <year> 1987. </year>
Reference-contexts: We use the static symbolic factorization technique first proposed in <ref> [20, 21] </ref> to predict the worst possible structures of L and U factors without knowing the actual numerical values, then we develop a 2-D L/U supernode partitioning technique to identify dense structures in both L and U factors, and maximize the use of BLAS-3 level subroutines for these dense structures. <p> Using the precise pivoting information at each elimination step can certainly optimize data space usage, reduce communication and improve load balance, but such benefits could be offset by high run-time control and communication overhead. The strategy of static data structure prediction in <ref> [20] </ref> is valuable in avoiding dynamic symbolic factorization, identifying the maximum data dependence patterns and minimizing dynamic control 4 overhead. We will use this static strategy in our S fl approach. <p> It has been shown that the structure of L c can be used as an upper bound for the structures of L and U factors regardless of the choice of the pivot row at each step <ref> [20] </ref>. But it turns out that this bound is not very tight. It often substantially overestimates the structures of the L and U factors (refer to Table 1). Instead we consider another method from [20]. The basic idea is to statically consider all possible pivoting choices at each step. <p> of L and U factors regardless of the choice of the pivot row at each step <ref> [20] </ref>. But it turns out that this bound is not very tight. It often substantially overestimates the structures of the L and U factors (refer to Table 1). Instead we consider another method from [20]. The basic idea is to statically consider all possible pivoting choices at each step. The space is allocated for all the possible nonzeros that would be introduced by any pivoting sequence that could occur during the numerical factorization. We summarize the symbolic factorization method briefly as follows.
Reference: [21] <author> A. George and E. Ng. </author> <title> Parallel Sparse Gaussian Elimination with Partial Pivoting. </title> <journal> Annals of Operations Research, </journal> <volume> 22 </volume> <pages> 219-240, </pages> <year> 1990. </year>
Reference-contexts: This method has been implemented on Illinois Cedar multi-processors based on Aliant shared memory clusters. This paper focuses on parallelization issues for a given column ordering with row interchanges to maintain numerical stability. Parallelization of sparse LU with partial pivoting is also studied in <ref> [21] </ref> on a shared memory machine by using static symbolic LU factorization to overestimate nonzero fill-ins and avoid dynamic variation of LU data structures. <p> We use the static symbolic factorization technique first proposed in <ref> [20, 21] </ref> to predict the worst possible structures of L and U factors without knowing the actual numerical values, then we develop a 2-D L/U supernode partitioning technique to identify dense structures in both L and U factors, and maximize the use of BLAS-3 level subroutines for these dense structures. <p> We will discuss how 2-D parallelism is exploited using asynchronous schedule execution. 5 Parallelism exploitation 5.1 Scheduling and run-time support for 1-D methods We discuss how 1-D sparse LU tasks are scheduled and executed so that parallel time can be minimized. George and Ng <ref> [21] </ref> used a dynamic load balancing algorithm on a shared memory machine.
Reference: [22] <author> A. Gerasoulis and T. Yang. </author> <title> On the Granularity and Clustering of Directed Acyclic Task Graphs . IEEE Transactions on Parallel and Distributed Systems, </title> <booktitle> 4(6) </booktitle> <pages> 686-701, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Apparently the supernode amalgamation has brought significant improvement due to the increase of supernode size which implies an increase of the task granularities. This is important to obtaining good parallel performance <ref> [22] </ref>. 25 Matrix P=1 P=2 P=4 P=8 P=16 P=32 sherman5 47% 47% 46% 50% 40% 43% lnsp3937 50% 51% 53% 53% 51% 39% lns3937 55% 54% 54% 54% 51% 35% sherman3 20% 25% 23% 28% 22% 14% jpwh991 48% 48% 48% 50% 47% 40% orsreg1 16% 18% 18% 26% 15% 10%
Reference: [23] <author> G. Golub and J. M. Ortega. </author> <title> Scientific Computing: An Introduction with Parallel Computing Compilers . Academic Press, </title> <year> 1993. </year>
Reference-contexts: However in many applications, the associated equation systems involve nonsymmetric matrices and pivoting may be required to maintain numerical stability for such nonsymmetric linear systems <ref> [6, 23] </ref>. <p> This is to use block-cyclic mapping of tasks with a compute-ahead execution strategy, which is demonstrated in Figure 10. This idea has been used to speed up parallel dense factorizations <ref> [23] </ref>. It executes the numerical factorization layer by layer based on the current submatrix index. The parallelism is exploited for concurrent updating.
Reference: [24] <author> A. Gupta and V. Kumar. </author> <title> Highly Scalable Parallel Algorithms for Sparse Matrix Factorization. </title> <type> Technical Report TR 94-63, </type> <institution> Computer Science, Univ. of Minnesota, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Sparse matrix factorization is an important approach to solving a sparse system of linear equations. If a matrix is symmetric and positive definite, Cholesky factorization can be used, for which fast sequential and parallel algorithms have been developed in <ref> [24, 30, 31] </ref>. However in many applications, the associated equation systems involve nonsymmetric matrices and pivoting may be required to maintain numerical stability for such nonsymmetric linear systems [6, 23]. <p> For even larger matrices such as vavasis3, we cannot run S fl on one node, but as shown later, the 2-D code can achieve 32.8 MFLOPS per node on 16 T3D processors. Notice that the megaflops performance per node for sparse Choleksy reported in <ref> [24] </ref> on 16 T3D nodes is around 40 MFLOPS, which is also a good indication that S fl single-node performance is satisfactory. We present a quantitative analysis to explain why S fl can be competitive to SuperLU.
Reference: [25] <author> S. Hadfield and T. Davis. </author> <title> A Parallel Unsymmetric-pattern Multifrontal Method. </title> <type> Technical Report TR-94-028, </type> <institution> Computer and Information Sciences Department, University of Florida, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: The adaptive and irregular nature of sparse LU data structures makes an efficient implementation of this algorithm very hard even on a modern sequential machine with memory hierarchies. There are several approaches that can be used for solving nonsymmetric systems. One approach is the unsymmetric-pattern multi-frontal method <ref> [5, 25] </ref> that uses elimination graphs to model irregular parallelism and guide the parallel computation. Another approach [19] is to restructure a sparse matrix into a bordered block upper triangular form and use a special pivoting technique which preserves the structure and maintains numerical stability at acceptable levels. <p> For sparse LU, an elimination tree of A T A does not directly reflect the available parallelism. Dynamically created DAGs have been used for modeling parallelism and guiding run-time execution in a nonsymmetric multi-frontal method <ref> [5, 25] </ref>. Given the task definitions in Figures 6, 7 and 8 we can define the structure of a sparse LU task graph in the following.
Reference: [26] <author> M. Heath, E. Ng, and B. Peyton. </author> <title> Parallel Algorithms for Sparse Linear Systems . SIAM Review, </title> <booktitle> 33(3) </booktitle> <pages> 420-460, </pages> <month> September </month> <year> 1991. </year> <month> 31 </month>
Reference-contexts: To better exploit memory hierarchy in modern architectures, supernode partitioning is an important technique to exploit the regularity of sparse matrix computations and utilize BLAS routines to speed up the computation. It has been successfully applied to Cholesky factorization <ref> [26, 30, 31] </ref>. The difficulty for the nonsymmetric factorization is that supernode structure depends on pivoting choices during the factorization thus cannot be determined in advance. SuperLU performs symbolic factorization and identifies supernodes on the fly. <p> For a symmetric sparse matrix, a supernode is defined as a group of consecutive columns that have nested structure in the L factor of the matrix. Excellent performance has been achieved in <ref> [26, 30, 31] </ref> using supernode partitioning for Cholesky factorization. However, the above definition is not directly applicable to sparse LU with nonsymmetric matrices. A good analysis for defining unsymmetric supernodes in an L factor is available in [7].
Reference: [27] <author> X. Jiao. </author> <title> Parallel sparse gaussian elimination with partial pivoting and 2-d data mapping. </title> <type> Master's thesis, </type> <institution> Dept. of Computer Science, University of California at Santa Barbara, </institution> <month> August </month> <year> 1997. </year>
Reference-contexts: We have used a simpler approach that does not require any permutation. This approach only amalgamates consecutive supernodes if their nonzero structures only differ by a small number of entries and it can be performed in a very efficient manner which only has a time complexity of O (n) <ref> [27] </ref>. We can control the maximum allowed differences by an amalgamation factor r. Our experiments show that when r is in the range of 4 6, it gives the best performance for the tested matrices and leads to 10 55% improvement on the execution times of the sequential code.
Reference: [28] <author> J. W. H. Liu. </author> <title> Computational Models and Task Scheduling for Parallel Sparse Cholesky Factorization. </title> <journal> Parallel Computing, </journal> <volume> 18 </volume> <pages> 327-342, </pages> <year> 1986. </year>
Reference-contexts: The DAGs are constructed statically before numerical factorization. Previous work on exploiting task parallelism for sparse Cholesky factorization has used elimination trees (e.g. <ref> [28, 30] </ref>), which is a good way to expose the available parallelism because pivoting is not required. For sparse LU, an elimination tree of A T A does not directly reflect the available parallelism.
Reference: [29] <author> P. Raghavan. </author> <title> Distributed Sparse Gaussian Elimination and Orthogonal Factorization. </title> <journal> SIAM Journal on Scientific Computing, </journal> <volume> 16(6) </volume> <pages> 1462-1477, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: There are other issues which are related to this work and need to be further studied, for example, alternative for parallel sparse LU based on Schur complements [13] and static estimation and parallelism exploitation for sparse QR <ref> [29, 35] </ref>. It should be noted that the static symbolic factorization could fail to be practical if the input matrix has a nearly dense row because it will lead to an almost complete fill-in of the whole matrix. It might be possible to use different matrix reordering to avoid that.
Reference: [30] <author> E. Rothberg. </author> <title> Exploiting the Memory Hierarchy in Sequential and Parallel Sparse Cholesky Factorization. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Stanford, </institution> <month> December </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Sparse matrix factorization is an important approach to solving a sparse system of linear equations. If a matrix is symmetric and positive definite, Cholesky factorization can be used, for which fast sequential and parallel algorithms have been developed in <ref> [24, 30, 31] </ref>. However in many applications, the associated equation systems involve nonsymmetric matrices and pivoting may be required to maintain numerical stability for such nonsymmetric linear systems [6, 23]. <p> To better exploit memory hierarchy in modern architectures, supernode partitioning is an important technique to exploit the regularity of sparse matrix computations and utilize BLAS routines to speed up the computation. It has been successfully applied to Cholesky factorization <ref> [26, 30, 31] </ref>. The difficulty for the nonsymmetric factorization is that supernode structure depends on pivoting choices during the factorization thus cannot be determined in advance. SuperLU performs symbolic factorization and identifies supernodes on the fly. <p> For a symmetric sparse matrix, a supernode is defined as a group of consecutive columns that have nested structure in the L factor of the matrix. Excellent performance has been achieved in <ref> [26, 30, 31] </ref> using supernode partitioning for Cholesky factorization. However, the above definition is not directly applicable to sparse LU with nonsymmetric matrices. A good analysis for defining unsymmetric supernodes in an L factor is available in [7]. <p> This results in very fine grained tasks. Amalgamating small supernodes can lead to great performance improvement for both parallel and sequential sparse codes because it can improve caching performance and reduce interprocessor communication overhead. There could be many ways to amalgamate supernodes <ref> [7, 30] </ref>. The basic idea is to relax the restriction that all the columns in a supernode must have exactly the same nonzero structure below diagonal. The amalgamation is usually guided by a supernode elimination tree. <p> The DAGs are constructed statically before numerical factorization. Previous work on exploiting task parallelism for sparse Cholesky factorization has used elimination trees (e.g. <ref> [28, 30] </ref>), which is a good way to expose the available parallelism because pivoting is not required. For sparse LU, an elimination tree of A T A does not directly reflect the available parallelism. <p> Another advantage is that parallelism modeled by the above dependence structure can be effectively exploited using graph scheduling techniques. 2-D data mapping. In the literature 2-D mapping has been shown more scalable than 1-D for sparse Cholesky <ref> [30, 31] </ref>. However there are several difficulties to apply the 2-D block-oriented mapping to the case of sparse LU factorization even the static structure is predicted. Firstly, pivoting operations and row interchanges require frequent and well-synchronized interprocessor communication when submatrices in the same column block are assigned to different processors.
Reference: [31] <author> E. Rothberg and R. Schreiber. </author> <title> Improved Load Distribution in Parallel Sparse Cholesky Factorization. </title> <booktitle> In Proc. of Supercomputing'94, </booktitle> <pages> pages 783-792, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Sparse matrix factorization is an important approach to solving a sparse system of linear equations. If a matrix is symmetric and positive definite, Cholesky factorization can be used, for which fast sequential and parallel algorithms have been developed in <ref> [24, 30, 31] </ref>. However in many applications, the associated equation systems involve nonsymmetric matrices and pivoting may be required to maintain numerical stability for such nonsymmetric linear systems [6, 23]. <p> To better exploit memory hierarchy in modern architectures, supernode partitioning is an important technique to exploit the regularity of sparse matrix computations and utilize BLAS routines to speed up the computation. It has been successfully applied to Cholesky factorization <ref> [26, 30, 31] </ref>. The difficulty for the nonsymmetric factorization is that supernode structure depends on pivoting choices during the factorization thus cannot be determined in advance. SuperLU performs symbolic factorization and identifies supernodes on the fly. <p> For a symmetric sparse matrix, a supernode is defined as a group of consecutive columns that have nested structure in the L factor of the matrix. Excellent performance has been achieved in <ref> [26, 30, 31] </ref> using supernode partitioning for Cholesky factorization. However, the above definition is not directly applicable to sparse LU with nonsymmetric matrices. A good analysis for defining unsymmetric supernodes in an L factor is available in [7]. <p> Another advantage is that parallelism modeled by the above dependence structure can be effectively exploited using graph scheduling techniques. 2-D data mapping. In the literature 2-D mapping has been shown more scalable than 1-D for sparse Cholesky <ref> [30, 31] </ref>. However there are several difficulties to apply the 2-D block-oriented mapping to the case of sparse LU factorization even the static structure is predicted. Firstly, pivoting operations and row interchanges require frequent and well-synchronized interprocessor communication when submatrices in the same column block are assigned to different processors. <p> We partially explain the reason by analyzing load balance factors of the 1-D RAPID code and the 2-D code in Figure 18. The load balance factor is defined as work total =(P work max ) <ref> [31] </ref>. Here we only count the work from the updating part because it is the major part of the computation. The 2-D code has better load balance, which can make up for the impact of lacking of efficient task scheduling. This is verified by Figure 17 and Figure 18.
Reference: [32] <author> S. L. Scott. </author> <title> Synchronization and Communication in the T3E Multiprocess. </title> <booktitle> In ASPLOS-VII, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: It does not incur any copying/buffering during a data transfer since low communication overhead is critical for sparse code with mixed granularities. RMA is available in modern multi-processor architectures such as Cray-T3D [34], T3E <ref> [32] </ref> and Meiko CS-2 [15]. Since the RMA directly writes data to a remote address, it is possible that the content at the remote address is still being used by other tasks and then the execution at the remote processor could be incorrect.
Reference: [33] <author> S. L. Scott and G. M. Thorson. </author> <title> The Cray T3E Network: Adaptive Routing in a High Performance 3D Torus. </title> <booktitle> In Proceedings of HOT Interconnects IV, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: Each T3E node has a clock rate of 300 MHZ, an 8Kbytes internal cache, 96Kbytes second level cache, and 128 Mbytes main memory. The peak bandwidth between nodes is reported as 500 Mbytes/s and the peak round trip communication latency is about 0.5 to 2 s <ref> [33] </ref>. We have observed that when block size is 25, DGEMM achieves 388 MFLOPS while DGEMV reaches 255 MFLOPS. We have used block size 25 in our experiments since if the block size is too large, the available parallelism will be reduced.
Reference: [34] <author> T. Stricker, J. Stichnoth, D. O'Hallaron, S. Hinrichs, and T. Gross. </author> <title> Decoupling Synchronization and Data Transfer in Message Passing Systems of Parallel Computers. </title> <booktitle> In Proc. of International Conference on Supercomputing, </booktitle> <pages> pages 1-10, </pages> <address> Barcelona, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: It does not incur any copying/buffering during a data transfer since low communication overhead is critical for sparse code with mixed granularities. RMA is available in modern multi-processor architectures such as Cray-T3D <ref> [34] </ref>, T3E [32] and Meiko CS-2 [15]. Since the RMA directly writes data to a remote address, it is possible that the content at the remote address is still being used by other tasks and then the execution at the remote processor could be incorrect. <p> The communication network of the T3D is a 3-D torus. Cray provides a shared memory access library called shmem which can achieve 126 Mbytes/s bandwidth and 2:7s communication overhead using shmem put () primitive <ref> [34] </ref>. We have used shmem put () for the communications in all the implementations. We have also conducted experiments on a newly acquired Cray-T3E at San Diego Supercomputing Center.
Reference: [35] <author> C. Sun. </author> <title> Parallel Sparse Orthogonal Factorization on Distributed-memory Multiprocessors. </title> <journal> SIAM Journal on Scientific Computing, </journal> <volume> 17(3) </volume> <pages> 666-685, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: There are other issues which are related to this work and need to be further studied, for example, alternative for parallel sparse LU based on Schur complements [13] and static estimation and parallelism exploitation for sparse QR <ref> [29, 35] </ref>. It should be noted that the static symbolic factorization could fail to be practical if the input matrix has a nearly dense row because it will lead to an almost complete fill-in of the whole matrix. It might be possible to use different matrix reordering to avoid that.
Reference: [36] <author> T. Yang and A. Gerasoulis. </author> <title> PYRROS: Static Task Scheduling and Code Generation for Message-Passing Multiprocessors . In Proc. </title> <booktitle> of 6th ACM International Conference on Supercomputing, </booktitle> <pages> pages 428-437, </pages> <year> 1992. </year> <month> 32 </month>
Reference-contexts: We order task execution within each processor using the graph scheduling algorithms in <ref> [36] </ref>. The basic optimizations are balancing processor loads and overlapping computation with communication to hide communication latency.
References-found: 36

