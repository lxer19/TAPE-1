URL: ftp://ftp.cs.wisc.edu/machine-learning/shavlik-group/shavlik.aaai-wkshp98.ps
Refering-URL: http://www.cs.wisc.edu/~shavlik/abstracts/shavlik.aaai-wkshp98.ps.abstract.html
Root-URL: 
Email: fshavlik, eliassig@cs.wisc.edu  
Title: Intelligent Agents for Web-based Tasks: An Advice-Taking Approach  
Author: Jude Shavlik and Tina Eliassi-Rad 
Web: http://www.cs.wisc.edu/~fshavlik, eliassig  
Address: 1210 W. Dayton Street Madison, Wisconsin 53706  
Affiliation: University of Wisconsin-Madison  
Date: July 1998.  
Note: Appears in the Working Notes of the AAAI/ICML Workshop on Learning for Text Categorization,  
Abstract: We present and evaluate an implemented system with which to rapidly and easily build intelligent software agents for Web-based tasks. Our design is centered around two basic functions: ScoreThisLink and ScoreThisPage. If given highly accurate such functions, standard heuristic search would lead to efficient retrieval of useful information. Our approach allows users to tailor our system's behavior by providing approximate advice about the above functions. This advice is mapped into neural network implementations of the two functions. Subsequent reinforcements from the Web (e.g., dead links) and any ratings of retrieved pages that the user wishes to provide are, respectively, used to refine the link- and page-scoring functions. Hence, our architecture provides an appealing middle ground between nonadaptive agent programming languages and systems that solely learn user preferences from the user's ratings of pages. We describe our internal representation of Web pages, the major predicates in our advice language, how advice is mapped into neural networks, and the mechanisms for refining advice based on subsequent feedback. We also present a case study where we provide some simple advice and specialize our general-purpose system into a "home-page finder". An empirical study demonstrates that our approach leads to a more effective home-page finder than that of a leading commercial Web search site. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Croft, W.; Turtle, H.; and Lewis, D. </author> <year> 1991. </year> <title> The use of phrases and structured queries in information retrieval. </title> <booktitle> In 14th International ACM SIGIR Conference on R & D in Information Retrieval, </booktitle> <pages> 32-45. </pages>
Reference-contexts: Thus, there is the potential for words not mentioned in advice to impact the networks' output, following much BP training.) WAWA's Complex Predicates. Phrases <ref> (Croft, Turtle, & Lewis 1991) </ref>, which specify desired properties of consecutive words, play a central role in creating more complex constructs out of the basic features we extract from Web pages. Table 3 contains some of the more complicated predicates that Wawa defines in terms of the basic input features.
Reference: <author> Drummond, C.; Ionescu, D.; and Holte, R. </author> <year> 1995. </year> <title> A learning agent that assists the browsing of software libraries. </title> <type> Technical report, </type> <institution> University of Ottawa. </institution>
Reference-contexts: They, respectively, use a Bayesian classifier and a reinforcement learning-tfidf hybrid to learn about interesting Web pages and hyperlinks. Drummond et al. <ref> (Drummond, Ionescu, & Holte 1995) </ref> have created a system which assists users browsing software libraries; it learns unobtrusively by observing users' actions. Letizia (Lieberman 1995) is a system 7 similar to Drummond et al.'s that uses lookahead search from the current location in the user's Web browser.
Reference: <author> Joachims, T.; Freitag, D.; and Mitchell, T. </author> <year> 1997. </year> <title> Web-watcher: A tour guide for the World Wide Web. </title> <booktitle> In Proc. IJCAI-97. </booktitle>
Reference-contexts: Table 4: Empirical Results System % Found Mean Rank Wawa with BP 80% 1:2 Ahoy! 74% 1:5 Wawa without BP 70% 1:3 H'Bot person search 66% 12:0 HotBot general 44% 15:4 Related Work Like Wawa, Syskill and Webert (Pazzani, Muramatsu, & Billsus 1996), and WebWatcher <ref> (Joachims, Freitag, & Mitchell 1997) </ref> are Web-based systems that use machine learning techniques. They, respectively, use a Bayesian classifier and a reinforcement learning-tfidf hybrid to learn about interesting Web pages and hyperlinks.
Reference: <author> Lieberman, H. </author> <year> 1995. </year> <title> Letzia: An agent that assists web browsing. </title> <booktitle> In Proc. IJCAI-95. </booktitle>
Reference-contexts: They, respectively, use a Bayesian classifier and a reinforcement learning-tfidf hybrid to learn about interesting Web pages and hyperlinks. Drummond et al. (Drummond, Ionescu, & Holte 1995) have created a system which assists users browsing software libraries; it learns unobtrusively by observing users' actions. Letizia <ref> (Lieberman 1995) </ref> is a system 7 similar to Drummond et al.'s that uses lookahead search from the current location in the user's Web browser.
Reference: <author> Maclin, R., and Shavlik, J. </author> <year> 1996. </year> <title> Creating advice-taking reinforcement learners. </title> <booktitle> Machine Learning 22 </booktitle> <pages> 251-281. </pages>
Reference-contexts: These functions, respectively, guide the system's wandering within the Web and judge the value of the pages encountered. The user mainly programs these two functions by providing what we call advice, which is basically, rules-of-thumb for guiding WAWA's wandering and for specifying how it scores pages. Following <ref> (Maclin & Shavlik 1996) </ref>, we call our programming language an advice language, since this name emphasizes that the underlying system does not blindly follow the user-provided instructions, but instead refines this advice based on the system's experience. <p> Observing the system's behavior is likely to invoke thoughts of good additional instructions. Wawa can accept new advice and augment its neural networks at any time. It simply adds to a network additional hidden units that represent the compiled advice, a technique whose effectiveness was demonstrated <ref> (Maclin & Shavlik 1996) </ref> on several tasks. Providing additional hints can rapidly and drastically improve the performance of Wawa, provided the advice is relevant. (In this paper's experiments we do not evaluate incremental provision of advice, though (Maclin & Shavlik 1996) have done so on their testbeds. <p> hidden units that represent the compiled advice, a technique whose effectiveness was demonstrated <ref> (Maclin & Shavlik 1996) </ref> on several tasks. Providing additional hints can rapidly and drastically improve the performance of Wawa, provided the advice is relevant. (In this paper's experiments we do not evaluate incremental provision of advice, though (Maclin & Shavlik 1996) have done so on their testbeds. They also showed Table 1: The WAWA Algorithm Unless they have been saved to disk in a previous session, create the ScoreLink and ScoreP age neural networks by reading the user's initial advice (if any).
Reference: <author> Miller, G. </author> <year> 1995. </year> <title> WordNet: A lexical database for English. </title> <journal> Communications of the ACM 38 </journal> <pages> 39-41. </pages>
Reference-contexts: This last agent is of particular interest to researchers who want to find published papers. Moreover, we have set out to expand our advice language and to build into Wawa the ability to use information about synonyms (e.g., WordNet <ref> (Miller 1995) </ref>) and other knowledge about text. We would also like to add the capability of automatically creating plausible training examples by unobtrusively observing the actions made by users during their ordinary use of Wawa.
Reference: <author> Mitchell, T. </author> <year> 1997. </year> <title> Machine Learning. </title> <publisher> McGraw-Hill. </publisher>
Reference-contexts: version of Wawa, specialized into a home-page finder by adding simple advice, produces a better home-page finder than does the proprietary people-finder created by HotBot; with 95% probability, we can say that Wawa's accuracy on this testset is between 69% and 91% (e.g., using the formula on p. 131 of <ref> (Mitchell 1997) </ref>). Thus it is fair to claim that the difference between Wawa and HotBot in this experiment is statistically significant. The differences between the first and third rows also suggests that BP-refinement of Score-Links is effective. <p> Table 4: Empirical Results System % Found Mean Rank Wawa with BP 80% 1:2 Ahoy! 74% 1:5 Wawa without BP 70% 1:3 H'Bot person search 66% 12:0 HotBot general 44% 15:4 Related Work Like Wawa, Syskill and Webert (Pazzani, Muramatsu, & Billsus 1996), and WebWatcher <ref> (Joachims, Freitag, & Mitchell 1997) </ref> are Web-based systems that use machine learning techniques. They, respectively, use a Bayesian classifier and a reinforcement learning-tfidf hybrid to learn about interesting Web pages and hyperlinks.
Reference: <author> Ourston, D., and Mooney, R. </author> <year> 1994. </year> <title> Theory refinement: Combining analytical and empirical methods. </title> <journal> Artif. Intel. </journal> <volume> 66 </volume> <pages> 273-309. </pages>
Reference: <author> Pazzani, M., and Kibler, D. </author> <year> 1992. </year> <title> The utility of knowledge in inductive learning. </title> <booktitle> Machine Learning 9 </booktitle> <pages> 57-94. </pages>
Reference: <author> Pazzani, M.; Muramatsu, J.; and Billsus, D. </author> <year> 1996. </year> <title> Identifying interesting web sites. </title> <booktitle> In Proc. AAAI-96. </booktitle>
Reference-contexts: This can be useful when the user is unable to articulate why the system is misscoring pages and links, but is able to provide better scores. This standard learning-from-labeled-examples methodology has been previously investigated by other researchers, e.g., <ref> (Pazzani, Muramatsu, & Billsus 1996) </ref>, and we will not further discuss this aspect of Wawa in this article. We do conjecture, though, that most of the improvement to Wawa's neural networks, especially to ScorePage, will result from users providing advice. <p> Table 4: Empirical Results System % Found Mean Rank Wawa with BP 80% 1:2 Ahoy! 74% 1:5 Wawa without BP 70% 1:3 H'Bot person search 66% 12:0 HotBot general 44% 15:4 Related Work Like Wawa, Syskill and Webert <ref> (Pazzani, Muramatsu, & Billsus 1996) </ref>, and WebWatcher (Joachims, Freitag, & Mitchell 1997) are Web-based systems that use machine learning techniques. They, respectively, use a Bayesian classifier and a reinforcement learning-tfidf hybrid to learn about interesting Web pages and hyperlinks.
Reference: <author> Rumelhart, D.; Hinton, G.; and Williams, R. </author> <year> 1986. </year> <title> Learning representations by back-propagating errors. </title> <booktitle> Nature 323 </booktitle> <pages> 533-536. </pages>
Reference-contexts: After fetching and analyzing the text, the system will have a better estimate of the page's value to the user. Any differences between the "before" and "after" estimates constitute an error that can be used by backpropagation (BP) <ref> (Rumelhart, Hinton, & Williams 1986) </ref> to improve the ScoreLink neural network. We cover the details of this process later. In addition to the above system-internal method of automatically creating training examples, the user can improve the ScorePage and ScoreLink neural networks in two ways.
Reference: <author> Salton, G. </author> <year> 1991. </year> <title> Developments in automatic text retrieval. </title> <booktitle> Science 253 </booktitle> <pages> 974-979. </pages>
Reference-contexts: Following our description of the basic features, we discuss the more complicated language constructs created from the basic ones. We then show some sample advice used in our "home-page finder" experiments. Extracting Features from Web Pages. A standard representation of text used in information retrieval is the vector-space model <ref> (Salton 1991) </ref> (or the bag-of-words representation). The left side of Fig. 2 illustrates this representation. Basically, word order is lost and all that is used is a vector that records the words present on the page, usually scaled according to the number of occurrences and other properties (e.g., tfidf (Salton 1991)). <p> model <ref> (Salton 1991) </ref> (or the bag-of-words representation). The left side of Fig. 2 illustrates this representation. Basically, word order is lost and all that is used is a vector that records the words present on the page, usually scaled according to the number of occurrences and other properties (e.g., tfidf (Salton 1991)). Typically, information retrieval systems also discard common ("stop") words and "stem" all words to their root form (e.g., "walked" and "walking" both become "walk") (Salton 1991). Doing so greatly reduces the dimensionality (i.e., number of possible features) of the problem. Wawa performs these two preprocessing steps. <p> is a vector that records the words present on the page, usually scaled according to the number of occurrences and other properties (e.g., tfidf <ref> (Salton 1991) </ref>). Typically, information retrieval systems also discard common ("stop") words and "stem" all words to their root form (e.g., "walked" and "walking" both become "walk") (Salton 1991). Doing so greatly reduces the dimensionality (i.e., number of possible features) of the problem. Wawa performs these two preprocessing steps. Instead of solely using the bag-of-words model, we use a richer representation that preserves some word-order information.
Reference: <author> Sejnowski, T., and Rosenberg, C. </author> <year> 1987. </year> <title> Parallel networks that learn to pronounce English text. </title> <booktitle> Complex Systems 1 </booktitle> <pages> 145-168. </pages>
Reference-contexts: Scoring Arbitrarily Long Pages with Fixed-Sized Neural Networks Wawa's use of neural networks means we need a mechanism for processing arbitrarily long Web pages with fixed-sized input vectors. One approach would be to use recurrent networks, but instead we borrow an idea from NETtalk <ref> (Sejnowski & Rosenberg 1987) </ref>, though our basic unit is a word rather than an (alphabetic) letter as in NETtalk. Wawa slides a fixed-sized window across a page, and most of the features we use to represent a page are defined with respect to the current center of this window.
Reference: <author> Shakes, J.; Langheinrich, M.; and Etzioni, O. </author> <year> 1997. </year> <title> Dynamic reference sifting: A case study in the home-page domain. </title> <booktitle> In Proc. of the Sixth International World Wide Web Conference, </booktitle> <pages> 189-200. </pages>
Reference-contexts: Experiments This section presents a case study that illustrates the effectiveness and ease of specializing the general-purpose Wawa system for a Web-based task. We chose a task already in the literature: creating a home-page finder <ref> (Shakes, Langheinrich, & Etzioni 1997) </ref>. Their Ahoy! system uses a technique called Dynamic Reference Sifting, which filters the output of several Web indices and generates new guesses for urls' when no promising candidates are found. <p> We compare the performance of Wawa with the performances of Ahoy! and HotBot, a search engine not used by Wawa and the one that performed best in the home-page experiments of <ref> (Shakes, Langheinrich, & Etzioni 1997) </ref>. We provided the names in our test-set to Ahoy! via its Web interface. We ran HotBot under two different conditions. The first setting performs a specialized HotBot search for people; we use the name given on Aha's page for these queries.
Reference: <author> Sutton, R. </author> <year> 1988. </year> <title> Learning to predict by the methods of temporal differences. </title> <booktitle> Machine Learning 3 </booktitle> <pages> 9-44. </pages>
Reference-contexts: Deriving Training Examples for ScoreLink We use temporal difference methods <ref> (Sutton 1988) </ref> to automatically train ScoreLink; Wawa employs a form of Q-learning (Watkins 1989)|a type of reinforcement learning (RL). Recall that the difference between Wawa's prediction of the link's value before fetching the url and its new estimate serves as an error that BP tries to reduce.
Reference: <author> Towell, G., and Shavlik, J. </author> <year> 1994. </year> <booktitle> Knowledge-based artificial neural networks. Artif. Intel. </booktitle> <volume> 70 </volume> <pages> 119-165. </pages>
Reference-contexts: Users specify their personal interests and preferences using the language we designed for discussing aspects of the contents and structure of Web pages. These instructions are then "compiled" into "knowledge based" neural networks <ref> (Towell & Shavlik 1994) </ref>, thereby allowing subsequent refinement whenever training examples are available. As will be seen, the Wisconsin Adaptive Web Assistant (Wawa) uses ideas from reinforcement learning to automatically create its own training examples, though Wawa can also use any user-provided training examples. <p> This is accomplished using a variant of the Kbann algorithm <ref> (Towell & Shavlik 1994) </ref>, as sketched in Fig. 3. During advice compilation, Wawa maps the consecu-tiveInX construct by centering it over the sliding window, with the additional constraint that the window is sliding over portion X of the page (e.g., the title, hypertext, etc.).
Reference: <author> Valiant, L. </author> <year> 1984. </year> <title> A theory of the learnable. </title> <journal> Communications of the ACM 27 </journal> <pages> 1134-1142. </pages>
Reference-contexts: One might ask how a learning system can hope to do well in such a large space of input features. Dealing with this many input features would indeed be infeasible if Wawa solely learned from labeled examples <ref> (Valiant 1984) </ref>. Fortunately, as we shall see, our use of advice means that users indirectly select a subset feature space from this huge implicit input vector.
Reference: <author> Watkins, C. </author> <year> 1989. </year> <title> Learning from Delayed Rewards. </title> <type> Ph.D. Dissertation, </type> <institution> King's College. </institution> <month> 8 </month>
Reference-contexts: Deriving Training Examples for ScoreLink We use temporal difference methods (Sutton 1988) to automatically train ScoreLink; Wawa employs a form of Q-learning <ref> (Watkins 1989) </ref>|a type of reinforcement learning (RL). Recall that the difference between Wawa's prediction of the link's value before fetching the url and its new estimate serves as an error that BP tries to reduce.
References-found: 18

