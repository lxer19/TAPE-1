URL: http://www.ai.mit.edu/people/jeannie/papers/mm96.ps
Refering-URL: http://www.ai.mit.edu/people/jeannie/resume.html
Root-URL: 
Title: Negotiation for Automated Generation of Temporal Multimedia Presentations  
Author: Mukesh Dalal, Steven Feiner, Kathleen McKeown, Shimei Pan, Michelle Zhou Tobias H ollerer, James Shaw, Yong Feng, Jeanne Fromer 
Keyword: media coordination, natural language generation, knowledge-based graphics generation, speech  
Address: 500 W. 120th St., 450 CS Building New York, NY 10027  
Affiliation: Columbia University Department of Computer Science  
Note: To appear in Proc. ACM Mulimedia, Boston,  
Email: fdalal,feiner,mckeowng@cs.columbia.edu  
Phone: +1-212-939-7000  
Date: Nov. 1996.  
Abstract: Creating high-quality multimedia presentations requires much skill, time, and effort. This is particularly true when temporal media, such as speech and animation, are involved. We describe the design and implementation of a knowledge-based system that generates customized temporal multimedia presentations. We provide an overview of the system's architecture, and explain how speech, written text, and graphics are generated and coordinated. Our emphasis is on how temporal media are coordinated by the system through a multi-stage negotiation process. In negotiation, media-specific generation components interact with a novel coordination component that solves temporal constraints provided by the generators. We illustrate our work with a set of examples generated by the system in a testbed application intended to update hospital caregivers on the status of patients who have undergone a cardiac bypass operation. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J.F. Allen. </author> <title> Maintaining knowledge about temporal intervals. </title> <journal> Communications of the ACM, </journal> <volume> 26(11) </volume> <pages> 832-843, </pages> <year> 1983. </year>
Reference-contexts: While the constraint solver in [12], which is based on linear programming, is exponential in the worst case, the solver in [13], which allows flexible quantitative constraints, sometimes provides false inconsistent results. In contrast, MAGIC allows disjunctive qualitative constraints using a language that extends Allen's interval algebra <ref> [1] </ref> by allowing more than two intervals in the same disjunct. MAGIC also allows simple quantitative constraints and uses an efficient but incomplete constraint solver. <p> The media coordinator uses a constraint solver component to detect inconsistencies among the different components' plans. The media coordinator handles any inconsistencies by negotiating alternatives with the media-specific content planners. Currently only temporal constraints are explicitly represented, by using qualitative relations based on Allen's interval algebra <ref> [1] </ref> and simple quantitative information. The media-specific content planners and generators engage in fine-grained collaboration to develop a detailed plan for each communicative goal. When the presentation for a goal is agreed upon, it is ready for display. <p> This will ultimately allow MAGIC to select the appropriate option for the specific situation.) The temporal constraints used for coordinating speech and graphics are represented using relations in Allen's interval algebra <ref> [1] </ref>. For example, the qualitative constraint (&lt; name (* age gender)) among speech objects indicates that the reference to name should be spoken before (&lt;) the references to age and gender, which in turn may be spoken in any order (*). <p> This approach greatly facilitates negotiation between the graphics generator and the speech generator. For coordinating order, each media generator provides a weighted list of possible partial orders of media actions, ranked according to the generator's preferences. These constraints are expressed in an interval-based model <ref> [1] </ref> for representing qualitative constraints among temporal intervals. The media coordinator determines a total ordering compatible with the highest-ranked ordering of each medium. If this fails, it negotiates among the speech and graphics preferences until it finds a compatible ordering by systematically traversing the lists.
Reference: 2. <editor> J.F. Allen. </editor> <booktitle> Natural Language Understanding. </booktitle> <address> Ben-jamin/Cummings, Menlo Park, CA, </address> <year> 1987. </year>
Reference-contexts: These hierarchies are all accessible to the other components in MAGIC. The concept hierarchy is a general domain-independent ontology providing a taxonomy for generic information, such as the fact that reals and integers are both numbers (similar to those found in <ref> [2, 22] </ref>). The domain hierarchy represents domain-dependent medical information using the same classifications used in the clinical information system at Columbia Presbyterian Medical Center.
Reference: 3. <author> E. Andre, W. Finkler, W. Graf, T. Rist, A. Schauder, and W. Wahlster. WIP: </author> <title> The automatic synthesis of multimodal presentations. </title> <editor> In M. Maybury, editor, </editor> <booktitle> Intelligent Multimedia Interfaces, </booktitle> <pages> pages 75-93. </pages> <publisher> AAAI Press / The MIT Press, </publisher> <address> Menlo Park, CA, </address> <year> 1993. </year>
Reference-contexts: MAGIC also allows simple quantitative constraints and uses an efficient but incomplete constraint solver. Dynamic multimedia generation systems include SAGE [21, 14], COMET [9], and WIP <ref> [3] </ref>, which are knowledge-based multimedia generation systems that coordinate written text with static graphics. Weitzman and Wittenburg [27] also handle media coordination in their work on generating multimedia presentations.
Reference: 4. <author> M. Buchanan and P. Zellweger. </author> <title> Automatically generating consistent schedules for multimedia documents. </title> <journal> Multimedia Systems, </journal> <volume> 1(2) </volume> <pages> 55-67, </pages> <year> 1993. </year>
Reference-contexts: For example, in [12], each media object is associated with a triple: maximum, minimum, and optimum length. The system is able to provide an optimal cost solution that can satisfy all the temporal constraints with fairness in distributing necessary stretching or shrinking across the media objects. Others (e.g., <ref> [4] </ref>, [13]) incorporate unpredictable temporal behaviors in their temporal relation models. Their algorithms can adjust to compensate for the behavior of indeterministic objects at run-time. In contrast, most of MAGIC's temporal coordination and synchronization constraints are dynamically generated, and they are specified at a more detailed level of representation. <p> to example sentences 1-3 above, produced for the demographics information in the speech output for Figure 2 are: 1. (&lt; name age (* diabetes hypertension) gender surgeon operation) [10] 2. (&lt; name age gender surgeon operation (* diabetes hypertension)) [5] 3. (&lt; name age gender (* diabetes hypertension) surgeon operation) <ref> [4] </ref> Note that the speech content planner and lexical chooser determine that diabetes and hypertension can be referred to using adjectives and thus folded into one sentence in a concise way.
Reference: 5. <author> J. Cassell, C. Pelachaud, N. Badler, M. Steedman, B. Achorn, T. Becket, B. Douville, S. Provost, and M. Stone. </author> <title> Animated conversation: Rule-based generation of facial expression, gesture and spoken intonation for multiple conversational agents. </title> <booktitle> In Proc. SIGGRAPH '94, </booktitle> <pages> pages 413-420, </pages> <year> 1994. </year>
Reference-contexts: More recently, a system has been developed at University of Pennsylvania that automatically generates conversations between two human-like agents through synchronized speech, facial expressions, and gestures <ref> [5, 16, 17] </ref>. This system synchronizes 3D graphics with speech by using the timing information generated by the speech generator to decide when and how facial expressions and gestures are produced. For example, if insufficient time is available to generate a gesture, the system may abort the gesture. <p> The candidate object orders, 1 which correspond to example sentences 1-3 above, produced for the demographics information in the speech output for Figure 2 are: 1. (&lt; name age (* diabetes hypertension) gender surgeon operation) [10] 2. (&lt; name age gender surgeon operation (* diabetes hypertension)) <ref> [5] </ref> 3. (&lt; name age gender (* diabetes hypertension) surgeon operation) [4] Note that the speech content planner and lexical chooser determine that diabetes and hypertension can be referred to using adjectives and thus folded into one sentence in a concise way.
Reference: 6. <author> M. Dalal, S. Feiner, K. McKeown, D. Jordan, B. Allen, and Y. alSafadi. </author> <title> Magic: An experimental system for generating multimedia briefings about post-bypass patient status. </title> <booktitle> In Proceedings American Medical Infor-matics Association Annual Fall Symposium, </booktitle> <address> Washing-ton, D.C., </address> <month> October </month> <year> 1996. </year>
Reference-contexts: Our focus in this paper is on the problem of coordinating how and when information is conveyed by different temporal media to create a coherent and effective presentation. Our approach is embodied in a testbed system, MAGIC (Multimedia Abstract Generation for Intensive Care) <ref> [6] </ref>, which automatically generates multimedia briefings that describe the postoperative status of a patient undergoing Coronary Artery Bypass Graft (CABG) surgery.
Reference: 7. <author> M. Dalal and Y. Feng. </author> <title> Anytime temporal reasoning based on propositional satisfiability (extended abstract). </title> <editor> In E. C. Freuder, editor, </editor> <booktitle> Proceedings of Second International Conference on Principles and Practice of Constraint Programming (CP96), </booktitle> <pages> pages 535-536, </pages> <address> Cam-bridge, Massachusetts, Aug 1996. </address> <publisher> Springer. </publisher>
Reference-contexts: What is actually communicated to the media coordinator is a set of partially ordered graphical actions. For example, the set of partial orders specified for the actions listed above are: 1. (di Action1 ((&lt; m) Action2 Action3 Action4)) [10] 2. (di Action1 (* Action2 Action3 Action4)) <ref> [7] </ref> Here, di specifies the relationship contains (also known as during-inverse), indicating that Action1 starts before and ends after all the other actions. <p> That is, there are certain temporal constraints that cannot be expressed (e.g., disjunctions of conjunctions of temporal relations). We are exploring using a new anytime algorithm for reasoning with temporal temporal constraint networks that is based on propositional satisfia-bility <ref> [7] </ref>. In addition to our focus thus far on representing and reasoning about temporal constraints, we will also explore using similar approaches to handle spatial constraints on multimedia objects.
Reference: 8. <author> Michael Elhadad. </author> <title> Using Argumentation to Control Lexical Choice: A Functional Unification Implementation. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Columbia University, </institution> <address> New York, </address> <year> 1993. </year>
Reference-contexts: The media coordinator, which is implemented in C, runs on a Sun Ultra--Sparc workstation. Currently the general content planner and the media allocator are implemented as one module, using Allegro Common Lisp. The speech content planner and generator are implemented in Allego Common Lisp and the FUF/Surge package <ref> [8] </ref>. FUF (Functional Unification Formalism) is a unification-based natural language generator program, consisting of a unifier and a linearizer. Surge is a large, robust unification grammar of English. Both were developed at Columbia University and have been used in a wide range of applications at Columbia and elsewhere.
Reference: 9. <author> S. Feiner and K. McKeown. </author> <title> Automating the generation of coordinated multimedia explanations. </title> <journal> IEEE Computer, </journal> <volume> 24(10) </volume> <pages> 33-41, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: In contrast, MAGIC allows disjunctive qualitative constraints using a language that extends Allen's interval algebra [1] by allowing more than two intervals in the same disjunct. MAGIC also allows simple quantitative constraints and uses an efficient but incomplete constraint solver. Dynamic multimedia generation systems include SAGE [21, 14], COMET <ref> [9] </ref>, and WIP [3], which are knowledge-based multimedia generation systems that coordinate written text with static graphics. Weitzman and Wittenburg [27] also handle media coordination in their work on generating multimedia presentations.
Reference: 10. <author> B. Janssen, D. Severson, and M. Spreitzer. </author> <title> ILU 1.8 Reference Manual. </title> <institution> Xerox Corporation, </institution> <address> Palo Alto, CA, 1993-1995. </address> <note> version 1.8. </note>
Reference-contexts: The candidate object orders, 1 which correspond to example sentences 1-3 above, produced for the demographics information in the speech output for Figure 2 are: 1. (&lt; name age (* diabetes hypertension) gender surgeon operation) <ref> [10] </ref> 2. (&lt; name age gender surgeon operation (* diabetes hypertension)) [5] 3. (&lt; name age gender (* diabetes hypertension) surgeon operation) [4] Note that the speech content planner and lexical chooser determine that diabetes and hypertension can be referred to using adjectives and thus folded into one sentence in a <p> What is actually communicated to the media coordinator is a set of partially ordered graphical actions. For example, the set of partial orders specified for the actions listed above are: 1. (di Action1 ((&lt; m) Action2 Action3 Action4)) <ref> [10] </ref> 2. (di Action1 (* Action2 Action3 Action4)) [7] Here, di specifies the relationship contains (also known as during-inverse), indicating that Action1 starts before and ends after all the other actions. <p> CURRENT IMPLEMENTATION MAGIC's modules are written in Common Lisp, C, C++, and CLIPS. The entire system is integrated using the ILU (Inter-Language Unification) package <ref> [10] </ref>. ILU makes it possible for the different components to share data structures and to communicate efficiently across different hardware platforms and implementation languages.
Reference: 11. <author> H. Kautz. </author> <title> MATS (Metric/Allen Time System) Documentation. </title> <institution> AT&T Bell Laboratories, </institution> <year> 1991. </year>
Reference-contexts: The modules along the main pipeline of MAGIC act as ILU servers as well as ILU clients, so they offer functionality to other modules and also call functions provided by other modules. The media coordinator currently uses a constraint solver based on Metric/Allen Time System (MATS) <ref> [11] </ref> for solving the temporal constraints and determining a total global ordering. The constraint solver can handle both qualitative constraints for expressing ordering and quantitative constraints for expressing durations. It works by computing the transitive closure over qualitative constraints and then using constraint satisfaction for point-based metric reasoning [29].
Reference: 12. <author> M.Y. Kim and J. Song. </author> <title> Multimedia documents with elastic time. </title> <booktitle> In Proc. ACM Multimedia '95, </booktitle> <pages> pages 143-154, </pages> <address> San Francisco, CA, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: Although research in the development of multimedia authoring tools also addresses the problem of automatic synchronization, coordination constraints are explicitly stated by the presentation designer and scheduled at the media object level. The media objects could be audio, video segments, or graphics animations. For example, in <ref> [12] </ref>, each media object is associated with a triple: maximum, minimum, and optimum length. The system is able to provide an optimal cost solution that can satisfy all the temporal constraints with fairness in distributing necessary stretching or shrinking across the media objects. <p> For example, temporal constraints are specified among words and phrases in speech and among displaying and highlighting in graphics. Media synchronization is controlled by the system at run-time with much finer granularity. Although <ref> [12, 13] </ref> allow both qualitative and quantitative temporal constraints, they do not allow disjunctions among those constraints. While the constraint solver in [12], which is based on linear programming, is exponential in the worst case, the solver in [13], which allows flexible quantitative constraints, sometimes provides false inconsistent results. <p> Media synchronization is controlled by the system at run-time with much finer granularity. Although [12, 13] allow both qualitative and quantitative temporal constraints, they do not allow disjunctions among those constraints. While the constraint solver in <ref> [12] </ref>, which is based on linear programming, is exponential in the worst case, the solver in [13], which allows flexible quantitative constraints, sometimes provides false inconsistent results.
Reference: 13. <author> N. Layaida and C. Keramane. </author> <title> Maintaining temporal consistency of multimedia documents. </title> <booktitle> In Electronic Proceedings of the Effective Abstractions in Multimedia Workshop, ACM Multimedia '95, </booktitle> <year> 1995. </year>
Reference-contexts: For example, in [12], each media object is associated with a triple: maximum, minimum, and optimum length. The system is able to provide an optimal cost solution that can satisfy all the temporal constraints with fairness in distributing necessary stretching or shrinking across the media objects. Others (e.g., [4], <ref> [13] </ref>) incorporate unpredictable temporal behaviors in their temporal relation models. Their algorithms can adjust to compensate for the behavior of indeterministic objects at run-time. In contrast, most of MAGIC's temporal coordination and synchronization constraints are dynamically generated, and they are specified at a more detailed level of representation. <p> For example, temporal constraints are specified among words and phrases in speech and among displaying and highlighting in graphics. Media synchronization is controlled by the system at run-time with much finer granularity. Although <ref> [12, 13] </ref> allow both qualitative and quantitative temporal constraints, they do not allow disjunctions among those constraints. While the constraint solver in [12], which is based on linear programming, is exponential in the worst case, the solver in [13], which allows flexible quantitative constraints, sometimes provides false inconsistent results. <p> Although [12, 13] allow both qualitative and quantitative temporal constraints, they do not allow disjunctions among those constraints. While the constraint solver in [12], which is based on linear programming, is exponential in the worst case, the solver in <ref> [13] </ref>, which allows flexible quantitative constraints, sometimes provides false inconsistent results. In contrast, MAGIC allows disjunctive qualitative constraints using a language that extends Allen's interval algebra [1] by allowing more than two intervals in the same disjunct.
Reference: 14. <author> V. Mittal, S.F. Roth, J.D. Moore, J.A. Mattis, and G. Carenini. </author> <title> Generating explanatory captions for information graphics. </title> <booktitle> In Proc. Int. Joint Conf. on Artificial Intelligence. IJCAI, </booktitle> <address> Montreal, Canada, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: In contrast, MAGIC allows disjunctive qualitative constraints using a language that extends Allen's interval algebra [1] by allowing more than two intervals in the same disjunct. MAGIC also allows simple quantitative constraints and uses an efficient but incomplete constraint solver. Dynamic multimedia generation systems include SAGE <ref> [21, 14] </ref>, COMET [9], and WIP [3], which are knowledge-based multimedia generation systems that coordinate written text with static graphics. Weitzman and Wittenburg [27] also handle media coordination in their work on generating multimedia presentations.
Reference: 15. <author> J.G. Neal, C.Y. Thielman, Z. Dobes, S.M. Haller, and S.C. Shapiro. </author> <title> Natural language with integrated deic-tic and graphic gestures. </title> <booktitle> In Proc. Speech and Natural Language Workshop, </booktitle> <pages> pages 410-423. </pages> <address> Cape Cod, MA, </address> <year> 1989. </year>
Reference-contexts: They construct a simple network of spatial and temporal constraints for each grammar to accommodate dynamic relationships among presentation elements, but do not support the replanning capabilities we provide in MAGIC. Temporal media introduce additional complexity, and none of these systems support them. CUBRICON <ref> [15] </ref> is one of the earliest systems to dynamically generate coordinated speech and graphics. It combines speech with simple deictic gestures and 2D map graphics to guide the user's visual focus of attention.
Reference: 16. <author> C. Pelachaud and S. Prevost. </author> <title> Sight and sound: Generating facial expressions and spoken intonation from context. </title> <booktitle> In Proc. 2nd ESCA/IEEE Workshop on Speech Synthesis, </booktitle> <pages> pages 216-219. </pages> <address> New Paltz, NY, </address> <year> 1994. </year>
Reference-contexts: More recently, a system has been developed at University of Pennsylvania that automatically generates conversations between two human-like agents through synchronized speech, facial expressions, and gestures <ref> [5, 16, 17] </ref>. This system synchronizes 3D graphics with speech by using the timing information generated by the speech generator to decide when and how facial expressions and gestures are produced. For example, if insufficient time is available to generate a gesture, the system may abort the gesture.
Reference: 17. <author> C. Pelachaud and S. Prevost. </author> <title> Coordinating vocal and visual parameters for 3D virtual agents. </title> <booktitle> In Proc. 2nd Eu-rographics Workshop on Virtual Environments. Monte Carlo, </booktitle> <year> 1995. </year>
Reference-contexts: More recently, a system has been developed at University of Pennsylvania that automatically generates conversations between two human-like agents through synchronized speech, facial expressions, and gestures <ref> [5, 16, 17] </ref>. This system synchronizes 3D graphics with speech by using the timing information generated by the speech generator to decide when and how facial expressions and gestures are produced. For example, if insufficient time is available to generate a gesture, the system may abort the gesture.
Reference: 18. <author> S. Ramanathan and P.V. Rangan. </author> <title> Adaptive feedback techniques for synchronized multimedia retreival over integrated networks. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> 1(2) </volume> <pages> 246-260, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Research on network and operating system synchronization issues, such as feedback techniques and protocols for intermedia synchronization given network jitter (e.g., <ref> [18, 19, 20] </ref>), also falls within this category. In MAGIC, conceptual objects are generated dynamically, so object duration information and inter-object synchronization points can rarely be stored or computed prior to the generation of a presentation plan.
Reference: 19. <author> P.V. Rangan and S. Ramanathan. </author> <title> Feedback techniques for continuity and synchronization in multimedia information retrival. </title> <journal> ACM Transactions on Information Systems, </journal> <year> 1993. </year>
Reference-contexts: Research on network and operating system synchronization issues, such as feedback techniques and protocols for intermedia synchronization given network jitter (e.g., <ref> [18, 19, 20] </ref>), also falls within this category. In MAGIC, conceptual objects are generated dynamically, so object duration information and inter-object synchronization points can rarely be stored or computed prior to the generation of a presentation plan.
Reference: 20. <author> P.V. Rangan, S. Ramanathan, and T. Kaeppner. </author> <title> Performance of inter-media synchronization in distributed and heterogeneous multimedia systems. </title> <booktitle> Computer Networks and ISDN Systems, </booktitle> <year> 1993. </year>
Reference-contexts: Research on network and operating system synchronization issues, such as feedback techniques and protocols for intermedia synchronization given network jitter (e.g., <ref> [18, 19, 20] </ref>), also falls within this category. In MAGIC, conceptual objects are generated dynamically, so object duration information and inter-object synchronization points can rarely be stored or computed prior to the generation of a presentation plan.
Reference: 21. <author> S.F. Roth, J.A. Mattis, and X. Mesnard. </author> <title> Graphics and natural language as components of automatic explanation. </title> <editor> In J.W. Sullivan and S.W. Tyler, editors, </editor> <booktitle> Intelligent User Interfaces, </booktitle> <pages> pages 207-239. </pages> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1991. </year>
Reference-contexts: In contrast, MAGIC allows disjunctive qualitative constraints using a language that extends Allen's interval algebra [1] by allowing more than two intervals in the same disjunct. MAGIC also allows simple quantitative constraints and uses an efficient but incomplete constraint solver. Dynamic multimedia generation systems include SAGE <ref> [21, 14] </ref>, COMET [9], and WIP [3], which are knowledge-based multimedia generation systems that coordinate written text with static graphics. Weitzman and Wittenburg [27] also handle media coordination in their work on generating multimedia presentations.
Reference: 22. <author> S. Russell and P. Norvig. </author> <title> Artificial Intelligence: A Modern Approach. </title> <publisher> Prentice Hall, </publisher> <year> 1995. </year>
Reference-contexts: These hierarchies are all accessible to the other components in MAGIC. The concept hierarchy is a general domain-independent ontology providing a taxonomy for generic information, such as the fact that reals and integers are both numbers (similar to those found in <ref> [2, 22] </ref>). The domain hierarchy represents domain-dependent medical information using the same classifications used in the clinical information system at Columbia Presbyterian Medical Center.
Reference: 23. <author> Software Technology Branch, Lyndon B. </author> <title> Johnson Space Center. CLIPS Reference Manual, </title> <month> June </month> <year> 1993. </year> <note> CLIPS Version 6.0, JSC-25012. </note>
Reference-contexts: The speech synthesizer is Lucent Bell Laboratories' Text to Speech system. The speech content planner and generator run on a Sun UltraSparc workstation. The graphics content planner and generator are written in C++ and the CLIPS production system language <ref> [23] </ref>. We have implemented the knowledge-based design component in CLIPS, and the rendering component using the SGI Open Inventor 3D graphics toolkit [25]. We use a hierarchical decompositional partial order planner [32] that is based in part on the research of [28, 30].
Reference: 24. <author> R. Steinmetz and K. Nahrstedt. </author> <title> Multimedia: Computing, Communications, & Applications. </title> <publisher> Prentice Hall, </publisher> <year> 1995. </year>
Reference-contexts: PREVIOUS WORK Related work in multimedia systems falls into three broad categories: low level synchronization of stored multimedia, flexible synchronization using hand-specified temporal constraints, and dynamic generation of multimedia. In their unified overview of low-level multimedia synchronization, Steinmetz and Nahrstedt <ref> [24] </ref> present a four-layer synchronization reference model, an overview of multimedia synchronization approaches, and an account of multimedia presentation requirements; they focus on multimedia synchronization issues for stored multimedia systems. <p> We will also extend negotiation to synchronize durations, if no compatible timings can be determined initially. Furthermore, we will investigate the incorporation of established techniques to alleviate lags that arise from network delays <ref> [24] </ref>. ACKNOWLEDGMENTS We are grateful to our collaborators, Profs. Desmond Jor-dan (Department of Anesthesiology) and Barry Allen (Department of Medical Informatics) at the Columbia College of Physicians and Surgeons, who provided domain expertise in medical and database issues.
Reference: 25. <author> P. Strauss and R. Carey. </author> <title> An object-oriented 3D graphics toolkit. </title> <booktitle> Computer Graphics (Proc. SIGGRAPH '92), </booktitle> <volume> 26(2) </volume> <pages> 341-349, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: The graphics content planner and generator are written in C++ and the CLIPS production system language [23]. We have implemented the knowledge-based design component in CLIPS, and the rendering component using the SGI Open Inventor 3D graphics toolkit <ref> [25] </ref>. We use a hierarchical decompositional partial order planner [32] that is based in part on the research of [28, 30]. The graphics content planner and generator run on a 250 MHZ R4400 SGI Indigo Maximum Impact.
Reference: 26. <author> R. Wehrend and C. Lewis. </author> <title> A problem-oriented classification of visualization techniques. </title> <booktitle> In Proc. 1st IEEE Conference on Visualization: Visualization '90, </booktitle> <pages> pages 139-143. </pages> <publisher> IEEE, Los Alamitos, </publisher> <address> CA, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: To this end the graphics content planner uses a hierarchical-decomposition partial-order planning component [30] that selects visual goals to be accomplished. We have adopted the visual goal categorization developed by Wehrend and Lewis <ref> [26] </ref>. The planning component computes a partially ordered (and, therefore, flexible) set of graphical actions. While the speech components order spoken references to objects to obtain possible object orders, the graphics components partially order graphical actions that imply possible object orders.
Reference: 27. <author> L. Weitzman and K. Wittenburg. </author> <title> Automatic presentation of multimedia documents using relational grammars. </title> <booktitle> In Proc. ACM Multimedia '94, </booktitle> <pages> pages 403-412, </pages> <address> San Francisco, CA, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: MAGIC also allows simple quantitative constraints and uses an efficient but incomplete constraint solver. Dynamic multimedia generation systems include SAGE [21, 14], COMET [9], and WIP [3], which are knowledge-based multimedia generation systems that coordinate written text with static graphics. Weitzman and Wittenburg <ref> [27] </ref> also handle media coordination in their work on generating multimedia presentations. They construct a simple network of spatial and temporal constraints for each grammar to accommodate dynamic relationships among presentation elements, but do not support the replanning capabilities we provide in MAGIC.
Reference: 28. <author> D.E. Wilkins. </author> <title> Practical Planning: Extending the Classical AI Paradigm. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: We have implemented the knowledge-based design component in CLIPS, and the rendering component using the SGI Open Inventor 3D graphics toolkit [25]. We use a hierarchical decompositional partial order planner [32] that is based in part on the research of <ref> [28, 30] </ref>. The graphics content planner and generator run on a 250 MHZ R4400 SGI Indigo Maximum Impact.
Reference: 29. <author> E. Yampratoom and J.F. Allen. </author> <title> MATS (Performance of Temporal Reasoning Systems). </title> <institution> Computer Science Department, University of Rochester, </institution> <year> 1993. </year> <note> TRAINS Technical Note 93-1. </note>
Reference-contexts: The constraint solver can handle both qualitative constraints for expressing ordering and quantitative constraints for expressing durations. It works by computing the transitive closure over qualitative constraints and then using constraint satisfaction for point-based metric reasoning <ref> [29] </ref>. The media coordinator, which is implemented in C, runs on a Sun Ultra--Sparc workstation. Currently the general content planner and the media allocator are implemented as one module, using Allegro Common Lisp. The speech content planner and generator are implemented in Allego Common Lisp and the FUF/Surge package [8].
Reference: 30. <author> R.M. Young, M.E. Pollack, and J.D. Moore. </author> <title> Decomposition and causality in partial-order planning. </title> <booktitle> In 2nd Int. Conf. on AI Planning Systems: AIPS-94, </booktitle> <pages> pages 188-193. </pages> <address> Chicago, IL, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: To this end the graphics content planner uses a hierarchical-decomposition partial-order planning component <ref> [30] </ref> that selects visual goals to be accomplished. We have adopted the visual goal categorization developed by Wehrend and Lewis [26]. The planning component computes a partially ordered (and, therefore, flexible) set of graphical actions. <p> We have implemented the knowledge-based design component in CLIPS, and the rendering component using the SGI Open Inventor 3D graphics toolkit [25]. We use a hierarchical decompositional partial order planner [32] that is based in part on the research of <ref> [28, 30] </ref>. The graphics content planner and generator run on a 250 MHZ R4400 SGI Indigo Maximum Impact.
Reference: 31. <author> M. Zhou and S. Feiner. </author> <title> Data characterization for automatically visualizing heterogeneous information. </title> <booktitle> In Proc. INFOVIS '96 (IEEE Symp. on Information Visualization, </booktitle> <address> San Francisco, CA, </address> <month> October 28-29 </month> <year> 1996. </year>
Reference-contexts: information is based on both the information characteristics (e.g., a patient is a physical entity) and the situation/user model (e.g., of the ICU nurses, for whom this particular presentation layout is designed, prefer to see this information arranged relative to the body, but do not need a detailed body model) <ref> [31] </ref>. Although additional graphics and speech are presented in later parts of both patients' briefings, they are not shown or discussed here. In this paper, we concentrate only on the generation and coordination of speech (a) (b) Speech: Ms. <p> The graphics generator has a set of visual operators that are based on standard graphic design techniques, such as highlighting <ref> [31] </ref>. The graphics components utilize a set of visual policies to determine what visual operators to use and how to use them to achieve visual goals. In our examples, demographics are displayed in a textual table and a visual policy states that highlighting is appropriate for distinguishing textual table objects.
Reference: 32. <author> M. Zhou and S. Feiner. </author> <title> Top-down hierarchical planning of coherent visual discourse. </title> <booktitle> In Proc. IUI '97 (1997 Int. Conf. on Intelligent User Interfaces), </booktitle> <address> Orlando, FL, </address> <month> January 6-9 </month> <year> 1997. </year>
Reference-contexts: The graphics content planner and generator are written in C++ and the CLIPS production system language [23]. We have implemented the knowledge-based design component in CLIPS, and the rendering component using the SGI Open Inventor 3D graphics toolkit [25]. We use a hierarchical decompositional partial order planner <ref> [32] </ref> that is based in part on the research of [28, 30]. The graphics content planner and generator run on a 250 MHZ R4400 SGI Indigo Maximum Impact.
References-found: 32

