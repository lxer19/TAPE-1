URL: http://www.ai.mit.edu/~mpf/articles/Baum+Smith/BaumSmith_Mar10.ps
Refering-URL: 
Root-URL: 
Email: Email: eric and wds @research.NJ.NEC.COM  
Title: Best Play for Imperfect Players and Game Tree Search  
Author: Eric B. Baum and Warren D. Smith 
Date: March 10, 1993  
Note: DRAFT  
Address: 4 Independence Way Princeton NJ 08540  
Affiliation: NEC Research Institute  
Abstract: We propose a new approach to game tree search. We train up an evaluation function which returns, rather than a single number estimating the value of a position, a probability distribution P L (x). P L (x) is the probability that if we expanded leaf L to some depth, the backed up value of leaf L would then be found to be x. We describe how to propagate these distributions efficiently up the tree so that at any node n we compute without approximation the probability node n's negamax value is x given that a value is assigned to each leaf from its distribution. After we are done expanding the tree, the best move is the child of the root whose distribution has highest mean. Note that we take means at the child of the root after propagating, whereas the normal (Shannon) approach takes the mean at the leaves before propagating, which throws away information. Now we model the expansion of a leaf as selection of one value from its distribution. The total utility of all possible expansion is defined as the ensemble sum over those possible leaf configurations for which the current favorite move is inferior to some alternate move, weighted by the probability of the leaf configuration and the amount the current favorite move is inferior. We propose as the natural measure of the expansion importance of leaf L, the expected absolute change in this utility when we expand leaf L. We support this proposal with several arguments including an approximation theorem valid in the limit that one expands until the remaining utility of expansion becomes small. In summary, we gather distributions at the leaves, propagate exactly all this information to the root, and incrementally grow a tree expanding approximately the most interesting leaf at each step. Under reasonable conditions, we accomplish all of this in time O(N ), where N is the number of leaves in the tree when we are done expanding. That is, we pay only a small constant factor overhead for all of our bookkeeping. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. B. Baum: </author> <title> On optimal game tree propagation for imperfect players. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence. American Association for Artificial Intelligence 1992. </booktitle>
Reference-contexts: Reasoning along these lines, one discovers that in attempting to value the nodes in a search tree, one must take account of the extra information one will have when playing at the position <ref> [1] </ref>.
Reference: [2] <author> M. Blum, R. Floyd, V. Pratt, R. Rivest, R. Tarjan: </author> <title> Time Bounds for selection, </title> <journal> J. Computer System Sci. </journal> <month> 7 </month> <year> (1973) </year> <month> 448-461 </month>
Reference-contexts: Step 7 takes O (L) time and storage by the use of a linear-time selection algorithm [3] <ref> [2] </ref>.
Reference: [3] <author> R. Floyd and R. Rivest: </author> <title> Expected time bounds for selection, </title> <journal> Commun. </journal> <note> ACM 18,3 (March 1975) 165-173 </note>
Reference-contexts: Step 7 takes O (L) time and storage by the use of a linear-time selection algorithm <ref> [3] </ref> [2].
Reference: [4] <author> Richard M. Karp, Michael Luby, and Neal Madras: </author> <title> Monte-Carlo Approximation Algorithms for Enu meration Problems, </title> <note> Journal of Algorithms 10 (1989) 429-448 </note>
Reference-contexts: QED. Note that we can approximate the exact CDFs at all nodes, taking full account of the DAG dependencies, by Monte Carlo evaluation. (See also <ref> [4] </ref>.) This may be useful in evaluating our move choice, but we believe is likely to be too slow in convergence to be useful in deciding how to expand the tree. The reason for this 11 Unless P=NP=#P. <p> participates in, and expand the 12 One might imagine a more sophisticated Monte Carlo procedure which evaluated the utility of leaf L by sampling uniformly directly from the region in which the value of leaf L is relevant and then computed the integral by some procedure analogous to that of <ref> [4] </ref>, but we have been unable to construct a procedure along these lines which is efficient and rapidly mixing. 13 Actually the situation is worse than this for two reasons. First we must sample from such regions many times because of the inherent noise in the Monte Carlo procedure.
Reference: [5] <author> Feng-hsiung Hsu: </author> <title> Large Scale Parallelization of Alpha Beta Search: An Algorithmic and Architectural Study with Computer Chess, </title> <type> (PhD thesis) Tech. </type> <institution> Rept. CMU-CS-90-108 (Feb 1990) School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh PA 15213 </address>
Reference-contexts: This allows one to explore a tree twice as deep as one might expect. Fast special purpose hardware has been developed which for example allows the Deep Thought machine to explore chess to a depth of about 10 ply <ref> [5] </ref>. This has proved effective in chess. Nonetheless it seems wasteful to explore the full width tree, since almost all lines are ludicrously bad. One might prefer an approach which preferentially explored more important lines. See x12 for a brief summary of some previous work along these lines.
Reference: [6] <author> Kai-Fu Lee and Sanjoy Mahajan: </author> <title> The development of a world class othello program, </title> <note> Artificial Intelli gence 43 (1990) 21-36 </note>
Reference: [7] <author> Kai-Fu Lee and Sanjoy Mahajan: </author> <title> A pattern classification approach to evaluation function learning, </title> <booktitle> Artificial Intelligence 36 (1988) 1-25 </booktitle>
Reference-contexts: The second, which we dub "BPIP-DFISA," is philosophically more pleasing and makes evident some approximations that might have been overlooked in the ensemble view. We describe these in the next two subsections. 1 As an alternative to a linear least-squares fit, we mention the quadratic fitting procedure of <ref> [7] </ref>. 2 We do not intend to imply that this suggested procedure is a particularly new or good way to design a CDF-returning evaluation function. It is merely a way.
Reference: [8] <author> D.A. McAllester: </author> <title> Conspiracy numbers for min max search, </title> <booktitle> Artificial Intelligence 35 (1988) 287-310 </booktitle>
Reference-contexts: Then if our algorithm and alpha-beta explore for the same amount of time, the tree we grow will be up to three times as deep, but contain about half as many leaves, as that of alpha-beta. Previous tree growth algorithms by MacAllester <ref> [8] </ref>, Rivest [11], Russell and Wefald [12], and Palay [9] are discussed in x12. These authors all valued the importance of leaves in greedy or ad hoc fashion. In contrast we take into account the possible outcomes of future expansion in our leaf importance measure. <p> We have not experimented with either transposition tables in BPIP, or this heuristic. 12 Tree-shaping algorithms by previous authors We now list some tree-shaping techniques, proposed by previous authors, which require storage of the whole tree S. 12.1 Conspiracies D. McAllester <ref> [8] </ref> suggested a method of "conspiracies" in the negamax tree-searching philosophy.
Reference: [9] <author> A.J. Palay: </author> <title> Searching with probabilities, </title> <publisher> Pitman 1985 </publisher>
Reference-contexts: Previous tree growth algorithms by MacAllester [8], Rivest [11], Russell and Wefald [12], and Palay <ref> [9] </ref> are discussed in x12. These authors all valued the importance of leaves in greedy or ad hoc fashion. In contrast we take into account the possible outcomes of future expansion in our leaf importance measure. We discuss shortcomings of greedy approaches in sections 8 and 12.1. <p> MGSS* becomes completely helpless (terminates) if the move choice conspiracy number ever exceeds 1. Furthermore we have argued in x8.3 that the metagreedy approximation they make is a poor guide to the leaf importance even when the conspiracy number is 1. 12.4 Palay Andrew Palay <ref> [9] </ref> proposed an interesting scheme that uses probability distributions as node values. <p> Another drawback to Palay's approach is the following. Rather than determine which leaf of the tree was best to expand (under his criteria), Palay marched down from the root at each node choosing the most likely child until he reached a leaf. As he realized (p13 <ref> [9] </ref>) this greedy procedure need not pick the globally best leaf, nor even a good approximation. Palay was forced into this expedient, however, because examining all the leaves to find the best would have caused his runtime to grow superlinearly.
Reference: [10] <author> J. Pearl: </author> <title> Heuristics, </title> <publisher> Addison-Wesley 1984 </publisher>
Reference-contexts: If two sibling positions are assigned by an ordinary evaluation function a value .5 meaning that the probability of winning in that position is .5, it would be unwise to assume that these are independent and assign a probability of winning of .75 to their parent,as is sometimes advocated <ref> [10] </ref>. Our distributions, however, are over the error in the evaluation function, or to put it another way, are distributions over changes in our opinion about the position that would arise from future expansion. <p> Such a distribution of errors in the evaluation function, would seem to be inherently less correlated than the evaluation function itself. 4.2 BPIP-DFISA When it was first remarked that any evaluation function returns probabilistic information <ref> [10] </ref>, the question arose whether minimax is the correct way to propagate this information up a tree. One might instead propose a rule for combination of probabilities [10]. <p> be inherently less correlated than the evaluation function itself. 4.2 BPIP-DFISA When it was first remarked that any evaluation function returns probabilistic information <ref> [10] </ref>, the question arose whether minimax is the correct way to propagate this information up a tree. One might instead propose a rule for combination of probabilities [10]. This reasoning correctly asserts that a position with 100 alternative moves, each of which has independently .1 probability of leading to a won game, is almost certainly a won position. <p> In negamaxing of single numerical values, the graph of the influence function consists of three line segments, the outer two being constant and the inner one being of slope 1. The t-values of the corners are the "ff-fi window." <ref> [10] </ref>. In this section we describe how we may associate to each jump in the CDF at each node in our search tree an influence coefficient.
Reference: [11] <author> R.L. Rivest: </author> <title> Game tree searching by min max approximation, </title> <booktitle> Artificial Intelligence 34 (1988) 77-96 </booktitle>
Reference-contexts: Then if our algorithm and alpha-beta explore for the same amount of time, the tree we grow will be up to three times as deep, but contain about half as many leaves, as that of alpha-beta. Previous tree growth algorithms by MacAllester [8], Rivest <ref> [11] </ref>, Russell and Wefald [12], and Palay [9] are discussed in x12. These authors all valued the importance of leaves in greedy or ad hoc fashion. In contrast we take into account the possible outcomes of future expansion in our leaf importance measure. <p> Also we take account of the possibility of perturbations to leaves not in the conspiracy which might either counteract or reinforce this conspiracy. 12.2 Rivest's suggestion R. Rivest <ref> [11] </ref> suggested a method where the "max" in negamaxing is replaced by an L p mean. The root value then depends differentiably on the leaf values. One may find the gradient of the root value with respect to the leaf values, by applying the chain rule.
Reference: [12] <author> S. Russell and E. Wefald: </author> <title> Do the Right Thing, </title> <note> MIT Press 1991 (see especially chapter 4) </note>
Reference-contexts: Then if our algorithm and alpha-beta explore for the same amount of time, the tree we grow will be up to three times as deep, but contain about half as many leaves, as that of alpha-beta. Previous tree growth algorithms by MacAllester [8], Rivest [11], Russell and Wefald <ref> [12] </ref>, and Palay [9] are discussed in x12. These authors all valued the importance of leaves in greedy or ad hoc fashion. In contrast we take into account the possible outcomes of future expansion in our leaf importance measure. We discuss shortcomings of greedy approaches in sections 8 and 12.1. <p> total additive change in U all leaves as independent 0-mean steps of a random walk, and thus conclude that the variance in Q 1 would be the right leaf importance measure 9 . 8 The procedure of expanding the leaf with optimal SLEU is akin to the procedure advocated by <ref> [12] </ref> in that leaves are valued as if there was no possibility for future expansion. They call this approach "metagreedy". 9 Another problem with the variance is that it seems to overvalue low probability high value perturbations, because it is a sum of squares. <p> Russell and Wefald also experimented with MGSS2, a version permitting partial node expansion, and got good preliminary results (table p109 of <ref> [12] </ref>). The logic behind MGSS2 seems to us seriously flawed, however. We omit discussion here. Russell and Wefald's MGSS* results are dramatic evidence for the power of the ideas of "expansion utility" and the use of probability distributions at leaves to describe value changes after expansion.
Reference: [13] <author> J. Schaeffer: </author> <title> Conspiracy numbers, </title> <booktitle> Artificial Intelligence 43 (1990) 67-84 </booktitle>
Reference-contexts: One continues until either S is unwieldily large, or the conspiracy number, i.e. the cardinality of the smallest conspiracy, is greater than some desired value. McAllester's tree-shaping method was found experimentally to work well in tactical chess middlegames by J. Schaeffer <ref> [13] </ref>, but it worked badly in "positional" chess and in forced mates in which moves near the end of the forced mate line were "any"s. We now remark that large conspiracy number occurs even if one makes no special effort to shape the tree.
Reference: [14] <author> G. Schrufer: </author> <title> Presence and Absence of Pathology on Game Trees, </title> <editor> in D.F. Beal, ed., </editor> <booktitle> Advances in Com puter Chess 4, </booktitle> <publisher> (Pergamon, Oxford, </publisher> <pages> 1986) pp 101-112. </pages>
Reference-contexts: A similar result holds in Schrufer's <ref> [14] </ref> more realistic probabilistic model of b-uniform depth-d game trees with Boolean leaf values. Indeed, Schrufer's theoretical results can be viewed as proving that, in his model, exponentially large conspiracy numbers occur if and only if negamax search is not pathological.
Reference: [15] <author> C.E. Shannon: </author> <title> Programming a computer for playing chess, </title> <journal> Philos. </journal> <note> Magazine 41,7 (1950) 256-275 </note>
Reference-contexts: It is well known that if you have the computational resources to explore the whole tree, the optimal move is given by negamax. Shannon <ref> [15] </ref> proposed looking at the subtree of depth D, where D is as large as one can afford, and assigning a numerical value at the leaves of this subtree using an evaluation function.
Reference: [16] <author> Warren D. Smith: </author> <title> Fixed point for negamaxing probability distributions on regular trees, </title> <note> Submitted for publication </note>
Reference-contexts: Some justification for this assumption of drastic shrinking, and hence of DFISA, is provided by the results of <ref> [16] </ref>. In any case we are only using this assumption to decide which order to expand leaves in. If we continue to expand to some depth below a node, we will in practice achieve substantial sharpening of the distribution at that node.

References-found: 16

