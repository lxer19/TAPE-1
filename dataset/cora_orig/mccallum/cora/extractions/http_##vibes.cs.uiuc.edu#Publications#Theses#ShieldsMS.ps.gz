URL: http://vibes.cs.uiuc.edu/Publications/Theses/ShieldsMS.ps.gz
Refering-URL: http://vibes.cs.uiuc.edu/Publications/publications.htm
Root-URL: http://www.cs.uiuc.edu
Title: PERFORMANCE ANALYSIS OF PARALLEL SYSTEMS USING VIRTUAL REALITY  
Author: BY KEITH ARNETT SHIELDS 
Degree: 1991 THESIS Submitted in partial fulfillment of the requirements for the degree of Master of Science in Computer Science in the Graduate College of the  
Address: 1994 Urbana, Illinois  
Affiliation: B.S., University of South Alabama,  University of Illinois at Urbana-Champaign,  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Arendt, J. W. </author> <title> Parallel Genome Sequence Comparison Using an iPSC/2 with a Concurrent File System. </title> <type> Master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: The sequence matching is based on a generalization of the Needleman, Wunsch, and Sellers (NWS) sequence comparison algorithm in conjunction with a k-tuple heuristic to improve the overall performance of the sequencing process [26] [40] <ref> [1] </ref>. The NWS algorithm uses a dynamic programming approach to determine how well aligned (matched) two sequences are. Each sequence in the database is compared in turn to the input genome sequence. The elements of these two sequences are compared in pairwise fashion. <p> Sequence length, however, does not solely determine how long sequence matching will take. Because the k-tuple heuristic allows the NWS algorithm to perform matching on a subset of the elements within each sequence, the time to perform matching also depends heavily on how closely related the two sequences are <ref> [1] </ref>. In the current implementation of this code, each processor accesses a unique portion of the genome database. The processor performs sequence matching against all genomes in that portion of the database and the input sequence.
Reference: [2] <author> Ascension Technology Corporation. </author> <title> The Flock of Birds Installation and Operation Guide. </title> <address> Burlington, VT, </address> <month> Mar. </month> <year> 1993. </year>
Reference: [3] <author> Aukstakalnis, S., and Blatner, D. </author> <title> Silicon Mirage: The Art and Science of Virtual Reality. </title> <publisher> Peachpit Press, </publisher> <year> 1992. </year>
Reference: [4] <author> Aydt, R. A. </author> <title> A Description of the Classes and Methods of the Pablo SDDF Interface Library. </title> <type> Tech. rep., </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Feb. </month> <year> 1993. </year>
Reference-contexts: Both subclasses process SDDF records, but SDDFSocketReader contains extra support to read these records from a standard UNIX datagram socket. Both these subclasses use a specialized library capable of processing SDDF performance data <ref> [4] </ref>. The TraceReader class is also responsible for filtering the performance data as it is read. Because the desired filtering activities will change based on the analysis task at hand, the filtering specifics are controlled by user configuration options.
Reference: [5] <author> Aydt, R. A. </author> <title> The Pablo Self-Defining Data Format. </title> <type> Tech. rep., </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: As we have noted, on-line analysis is useful in situations where Avatar is being used to provide real-time adaptive control, as discussed in x4.7. The Pablo instrumentation environment generates output in a Self-Describing Data Format (SDDF), also developed at the University of Illinois <ref> [5] </ref>. This is a self-contained data meta-format made up of record definitions and record instances.
Reference: [6] <author> Beshers, C., and Feiner, S. AutoVisual: </author> <title> Rule-Based Design of Interactive Multivariate Visualizations. </title> <journal> IEEE Computer Graphics and Applications 13, </journal> <month> 4 (July </month> <year> 1993), </year> <pages> 41-49. </pages>
Reference: [7] <author> Bryson, S., and Levit, C. </author> <title> The Virtual Wind Tunnel. SIGGRAPH '93 Course Notes - Course 43: Implementing Virtual Reality (1993), </title> <publisher> 2.1-2.10. </publisher>
Reference: [8] <author> Chernoff, H. </author> <title> The Use of Faces to Represent Points in k-Dimensional Space Graphically. </title> <journal> Journal of the American Statistical Association 68 (1973), </journal> <pages> 361-368. </pages>
Reference: [9] <author> Cleveland, W., and McGill, M., Eds. </author> <title> Dynamic Graphics for Statistics. </title> <publisher> Wadsworth & Brooks/Cole, </publisher> <year> 1988. </year> <month> 118 </month>
Reference-contexts: Enabling history lines for all data points can create very busy displays that tend to confuse more than help. We have found that enabling history for a subset of points provides clearer insight into the data's behavior. In this case, history lines play the role of brushing <ref> [9] </ref> in statistical graphics. Because the performance data being analyzed with Avatar represents the time-varying behavior of some activity, temporal accuracy in the display of data points becomes an issue. The data points shown in a given scattercube represent the most recent values for a set of performance metrics.
Reference: [10] <author> Cruz-Neira, C., Sandin, D., DeFanti, T., Kenyon, R., and Hart, J. </author> <title> The CAVE, Audio Visual Experience Automatic Virtual Environment. </title> <journal> Communications of the ACM (June 1992), </journal> <pages> 64-72. </pages>
Reference-contexts: One example of how Avatar's design supports experimentation with new hardware and software configurations is the recent porting of Avatar to the CAVE <ref> [10] </ref>. The CAVE is a alternate means of presenting virtual environments to a number of users simultaneously. It consists of 97 video walls onto which stereoscopic scenes of the virtual environment are projected. Users wear stereo goggles, described in x2.3, to experience the display in three-dimensions.
Reference: [11] <author> Davison, D. </author> <title> Sequence Similarity ('Homology') Searching for Molecular Biologists. </title> <journal> Bulletin of Mathematical Biology 47, </journal> <volume> 4 (1985), </volume> <pages> 437-474. </pages>
Reference-contexts: This scenario involves examining the performance of a parallel genome sequencing code <ref> [11] </ref> running on a Intel Paragon [20]. While analyzing the performance of this code, we were able to utilize all of Avatar's major features and determine the strengths and weaknesses of each. Section 5.2.1 will describe the genome code used in this performance analysis study.
Reference: [12] <author> DiZio, P., and Lackner, J. R. </author> <title> Spatial Orientation, Adaptation, and Motion Sickness in Real and Virtual Environments. Presence 1, </title> <booktitle> 3 (1992), </booktitle> <pages> 319-328. </pages>
Reference: [13] <author> Feiner, S., and Beshers, C. </author> <title> Visualizing n-Dimensional Virtual Worlds with n-Vision. </title> <booktitle> In ACM SIGGRAPH Computer Graphics (Mar. 1990), </booktitle> <volume> vol. 24, </volume> <pages> pp. 37-39. </pages>
Reference: [14] <author> Foley, J., vanDam, A., Feiner, S., and Hughes, J. </author> <title> Computer Graphics Principles and Practice, second ed. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1990. </year>
Reference-contexts: A scene with a fixed perspective, such as the base scene rendered by a data display, can be modified via a series of transformations to accommodate any point of view <ref> [14] </ref>. In this way, the fixed-perspective scene rendered by the data display can modified by rendering control to accommodate any possible user location and perspective. Rendering control is also responsible for managing the display hardware being used.
Reference: [15] <author> Foster, S. H. </author> <title> Convolvotron User's Manual. Crystal River Engineering, </title> <address> Groveland, CA. </address>
Reference: [16] <author> Heath, M. T., and Etheridge, J. A. </author> <title> Visualizing the Performance of Parallel Programs. </title> <booktitle> IEEE Software (Sept. </booktitle> <year> 1991), </year> <pages> 29-39. </pages>
Reference: [17] <author> Hodges, L. F. </author> <title> Tutorial: Time-Multiplexed Stereoscopic Computer Displays. </title> <journal> IEEE Computer Graphics and Applications (Mar. </journal> <year> 1992), </year> <pages> 20-30. </pages>
Reference: [18] <author> Hollingsworth, J. K., and Miller, B. P. </author> <title> Dynamic Control of Performance Monitoring on Large Scale Parallel Systems. </title> <institution> University of Wisconsin-Madison, </institution> <year> 1993. </year>
Reference: [19] <author> Huber, P. J. </author> <title> Experiences with Three-Dimensional Scatterplots. In Dynamic Graphics for Statistics, </title> <editor> W. S. Cleveland and M. E. MiGill, Eds. </editor> <publisher> Wadsworth & Brooks/Cole, </publisher> <year> 1988, </year> <pages> pp. 448-453. </pages>
Reference: [20] <author> Intel Supercomputer Systems Division. </author> <title> Paragon XP/S Product Overview. </title> <address> Beaver-ton, OR, </address> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: This scenario involves examining the performance of a parallel genome sequencing code [11] running on a Intel Paragon <ref> [20] </ref>. While analyzing the performance of this code, we were able to utilize all of Avatar's major features and determine the strengths and weaknesses of each. Section 5.2.1 will describe the genome code used in this performance analysis study.
Reference: [21] <author> Jain, A. K., and Dubes, R. C. </author> <title> Algorithms for Clustering Data. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1988. </year> <month> 119 </month>
Reference: [22] <author> Madhyastha, T. M. </author> <title> A Portable System for Data Sonification. </title> <type> Master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: This is a general purpose library that provides high-level interface routines to gather position and orientation information in a device independent fashion. Use of this library allows the hardware-specific features of the tracker to be isolated from the rest of Avatar. Finally, we use Porsonify <ref> [22] </ref>, a portable tool to support data sonification, as the basis for our three-dimensional audio displays. Porsonify supports easy, rapid development of user-configurable sonifications. <p> There is no strict constraint within Avatar that graphical and audio displays be used simultaneously, but experience shows that the combination of graphical and audio displays provides a richer data analysis environment <ref> [22] </ref> [35]. Although Avatar's audio displays can be used independently of any graphical displays, we have found that audio is quite useful in augmenting the information presented within a graphical display. For this reason, Avatar's audio displays currently focus on supporting analysis activities within the scattercube array graphical display.
Reference: [23] <author> Madhyastha, T. M. Porsonify: </author> <title> A Portable System for Data Sonification. </title> <type> Tech. rep., </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Sept. </month> <year> 1993. </year>
Reference: [24] <author> McLendon, P. </author> <title> Graphics Library Programming Guide. </title> <institution> Silicon Graphics Incorporated, Mountain View, </institution> <address> CA, </address> <year> 1992. </year>
Reference-contexts: An additional benefit of GL is that it is designed to interact closely with the graphics hardware on the Silicon Graphics workstation. This allows for higher performance than could be otherwise obtained <ref> [24] </ref>. Avatar supports several unusual user input mechanisms (e.g., speech recognition system or three-dimensional mouse). Although powerful, these mechanisms are not appropriate for all input activities (e.g., system configuration). Consequently, Avatar also supports a graphical user interface (GUI) to provide an additional form of user input.
Reference: [25] <author> Meyer, K., Applewhite, H. L., and A.Biocca, F. </author> <title> A Survey of Position Trackers. Presence 1, </title> <booktitle> 2 (1992), </booktitle> <pages> 173-200. </pages>
Reference: [26] <author> Needleman, S. B., and Wunsch, C. D. </author> <title> An Efficient Method Applicable to the Search for Similarities in the Amino Acid Sequences of Two Proteins. </title> <journal> Journal of Molecular Biology 48 (1970), </journal> <pages> 444-453. </pages>
Reference-contexts: The sequence matching is based on a generalization of the Needleman, Wunsch, and Sellers (NWS) sequence comparison algorithm in conjunction with a k-tuple heuristic to improve the overall performance of the sequencing process <ref> [26] </ref> [40] [1]. The NWS algorithm uses a dynamic programming approach to determine how well aligned (matched) two sequences are. Each sequence in the database is compared in turn to the input genome sequence. The elements of these two sequences are compared in pairwise fashion.
Reference: [27] <author> Noe, R. J. </author> <title> Pablo Instrumentation Environment Users Guide. </title> <type> Tech. rep., </type> <institution> University of Illinois at Urbana-Champaign, Department of Computer Science, </institution> <month> Apr. </month> <year> 1994. </year>
Reference-contexts: Collection of data is a necessary first step in the analysis process; however, it can be performed separately from the rest of Avatar. Consequently, we use the Pablo instrumentation environment developed at the University of Illinois <ref> [27] </ref>. This environment allows users to instrument a parallel activity with calls to a portable trace library. This trace library monitors the parallel activity as it executes and generates data that details the events that occur. This provides the raw performance data used by Avatar.
Reference: [28] <author> Reed, D. A., Aydt, R. A., Noe, R. J., Roth, P. C., Shields, K. A., Schwartz, B. W., and Tavera, L. F. </author> <title> Scalable Performance Analysis: The Pablo Performance Analysis Environment. </title> <booktitle> In Proceedings of the Scalable Parallel Libraries Conference (1993), </booktitle> <editor> A. Skjellum, Ed., </editor> <publisher> IEEE Computer Society, </publisher> <pages> pp. 104-113. </pages>
Reference: [29] <author> Robinett, W. </author> <title> Designing Virtual Worlds. SIGGRAPH '93 Course Notes Course 43: Implementing Virtual Reality (1993), </title> <publisher> 1.5.1-1.5.3. </publisher>
Reference-contexts: Consequently, walking is a suitable navigation technique only if small distances are being traversed. We find it useful when exploring a single cube or moving to nearby cubes but inappropriate for large-scale movement through the virtual world <ref> [29] </ref>. For long-distance movement through the virtual world, flying is a more suitable technique. The user can travel in arbitrary directions and distances without needing to change physical position. One key drawback to flying is that it is not an intuitive navigation technique and consequently can be disorienting.
Reference: [30] <author> Robinett, W., and Rolland, J. P. </author> <title> A Computational Model for the Stereoscopic Optics of a Head-Mounted Display. Presence 1, </title> <booktitle> 1 (1992), </booktitle> <pages> 45-62. </pages>
Reference: [31] <institution> Silicon Graphics Incorporated. Parallel Programming on Silicon Graphics Computer Systems. Mountain View, </institution> <address> CA, </address> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: Mutual exclusion on this shared memory must be provided to guarantee that the data retrieved is reliable. Care must be taken to ensure that the overhead of performing mutual exclusion is not detrimental to the thread's performance <ref> [31] </ref>. It would be possible to have more than the above three threads in Avatar, but there are tradeoffs that must be considered when doing so. Because the Silicon Graphics workstation that Avatar currently uses has four processors, it can support four simultaneously executing threads of control; one per processor.
Reference: [32] <institution> Silicon Graphics Incorporated. </institution> <type> POWER Series Technical Report. </type> <institution> Mountain View, </institution> <address> CA, </address> <year> 1992. </year>
Reference: [33] <author> StereoGraphics Corporation. </author> <title> CrystalEyes Stereoscopic System User's Manual. </title> <address> San Rafael, CA, </address> <year> 1993. </year> <month> 120 </month>
Reference: [34] <author> Stroustrup, B. </author> <title> The C++ Programming Language. </title> <publisher> Addison-Wesley Publishing Com--pany, </publisher> <year> 1986. </year>
Reference-contexts: This is a popular and widely available object-oriented extension to the C programming language that supports data encapsulation, information hiding, and code reuse in a manner consistent with our goals <ref> [34] </ref>. As we have seen, collecting performance data is a fundamentally different task from the rest of Avatar's activities. Collection of data is a necessary first step in the analysis process; however, it can be performed separately from the rest of Avatar.
Reference: [35] <author> Tavera, L. </author> <title> Three Dimensional Sound for Data Presentation in a Virtual Reality Environment. </title> <type> Master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1994. </year>
Reference-contexts: Therefore, the parts of Avatar that handle three-dimensional audio and voice recognition have their own threads of control. This allows the requisite communication with other hardware components to occur without impeding the rest of Avatar. Additional details about Avatar's three-dimensional audio support can be found in <ref> [35] </ref>. The separate threads are spawned from the main thread of control using the sproc () system call on the Silicon Graphics workstation. <p> There is no strict constraint within Avatar that graphical and audio displays be used simultaneously, but experience shows that the combination of graphical and audio displays provides a richer data analysis environment [22] <ref> [35] </ref>. Although Avatar's audio displays can be used independently of any graphical displays, we have found that audio is quite useful in augmenting the information presented within a graphical display. For this reason, Avatar's audio displays currently focus on supporting analysis activities within the scattercube array graphical display. <p> For this reason, Avatar's audio displays currently focus on supporting analysis activities within the scattercube array graphical display. Avatar's support for audio data displays is covered in greater detail in <ref> [35] </ref>. A common set of features is shared across all graphical data displays. Some of these features, such as how stereoscopic viewing in handled, may depend on the output display device, but will be consistent for any of Avatar's graphical displays. <p> We intend to add several new data displays that will allow us to provide a richer data exploration environment. Additional audio displays, such as audio distribution plots in which sound characteristics are mapped to data distribution patterns, are discussed in <ref> [35] </ref>. In addition to new audio metaphors, we plan to explore the use of sound in Avatar's interface. As opposed to being used for data analysis, these sounds would serve as an additional form of feedback to the user.
Reference: [36] <author> Taylor, R. M., Robinett, W., Chi, V. L., Jr., F. P. B., Wright, W. V., Williams, R. S., and Snyder, E. J. </author> <title> The Nanomanipulator: A Virtual Reality Interface for a Scanning Tunneling Microscope. </title> <booktitle> In Computer Graphics Proceedings, Annual Conference Series (1993), </booktitle> <pages> pp. 127-134. </pages>
Reference: [37] <author> Tufte, E. R. </author> <title> Envisioning Information. </title> <publisher> Graphics Press, </publisher> <address> Cheshire, CT, </address> <year> 1990. </year>
Reference: [38] <institution> Virtual Research Flight Helmet Product Information, </institution> <year> 1992. </year>
Reference: [39] <author> Voice Connexion Incorporated. </author> <title> Micro Introvoice Software Developers Manual. </title> <address> Irvine, CA, </address> <month> Feb. </month> <year> 1993. </year>
Reference: [40] <author> Wilbur, W. J., and Lipman, D. J. </author> <title> Rapid Similarity Searches of Nucleic Acid and Protein Data Banks. </title> <booktitle> In Proceedings of the National Academy of Sciences (1983), </booktitle> <volume> vol. 80, </volume> <pages> pp. 726-730. </pages>
Reference-contexts: The sequence matching is based on a generalization of the Needleman, Wunsch, and Sellers (NWS) sequence comparison algorithm in conjunction with a k-tuple heuristic to improve the overall performance of the sequencing process [26] <ref> [40] </ref> [1]. The NWS algorithm uses a dynamic programming approach to determine how well aligned (matched) two sequences are. Each sequence in the database is compared in turn to the input genome sequence. The elements of these two sequences are compared in pairwise fashion.
Reference: [41] <author> Yan, J., Hontalas, P., and Listgarten, S. </author> <title> The Automated Instrumentation and Monitoring System (AIMS) Reference Manual. </title> <type> Tech. rep., </type> <institution> NASA Ames Research Center, </institution> <year> 1993. </year>
References-found: 41

