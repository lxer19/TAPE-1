URL: ftp://ftp.mcs.anl.gov/pub/neos/PCx/PCx-user.ps
Refering-URL: http://www.mcs.anl.gov/otc/Tools/PCx/Windows/
Root-URL: 
Title: OPTIMIZATION TECHNOLOGY CENTER PCx User Guide (Version 1.1) 1  
Author: by Joseph Czyzyk, Sanjay Mehrotra, Michael Wagner, and Stephen J. Wright 
Date: November 3, 1997  
Pubnum: Technical Report OTC 96/01  
Abstract: We describe the code PCx, a primal-dual interior-point code for linear programming. Information is given about problem formulation and the underlying algorithm, along with instructions for installing, invoking, and using the code. Computational results on standard test problems are tabulated. The current version number is 1.1. Key words: linear programming, interior-point methods, software. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. D. Andersen and K. D. Andersen, </author> <title> Presolving in linear programming, </title> <journal> Mathematical Programming, </journal> <volume> 71 (1995), </volume> <pages> pp. 221-245. </pages>
Reference-contexts: The scalar 2 <ref> [0; 1] </ref> in (12) is chosen by a complicated heuristic that is based on the ability of the pure affine-scaling step to attain large reductions in the duality measure before reaching the boundary of the positive orthant for the (x; s; r; w) components. <p> Given the affine-scaling step, we calculate the maximum step to this boundary in primal and dual variables from the definitions ff aff;P = inffff 2 <ref> [0; 1] </ref> j (x; w) + ff (x aff ; w aff ) 0g; (14a) ff aff;D = inffff 2 [0; 1] j (s; r) + ff (s aff ; r aff ) 0g: (14b) We then compute the duality measure aff at this point as aff = 2n (x + <p> Given the affine-scaling step, we calculate the maximum step to this boundary in primal and dual variables from the definitions ff aff;P = inffff 2 <ref> [0; 1] </ref> j (x; w) + ff (x aff ; w aff ) 0g; (14a) ff aff;D = inffff 2 [0; 1] j (s; r) + ff (s aff ; r aff ) 0g: (14b) We then compute the duality measure aff at this point as aff = 2n (x + ff aff;P x) T (s + ff aff;D s) + (w + ff aff;P w) T (r + ff aff;D <p> Similarly to (14), we calculate ff max;P = inf fff 2 <ref> [0; 1] </ref> j (x; w) + ff (x; w) 0g; (18a) and set where fl P and fl D are two scaling factors obtained from Mehrotra's adaptive steplength heuristic [8, p. 588]. <p> Presolvers significantly enhance the efficiency and robustness of both simplex and interior-point codes. 10 The presolver in PCx works with the formulation (1) stored in the LPtype data structure. It makes use of techniques described by Andersen and Andersen <ref> [1] </ref>, checking the data for the following features: Infeasibility. Check that u i 0 for each upper bound u i , i 2 U , and that a zero row of A has a corresponding zero in the right-hand side vector b. Empty Rows. <p> Forced Rows. Sometimes, the linear constraint represented by row i of A forces all its variables to either their upper or lower bounds. An example would be the constraint 10x 3 4x 10 + x 12 = 4 subject to the bounds x 3 2 <ref> [0; +1); x 10 2 [0; 1] </ref>; x 12 2 [0; +1): In this case, we must have x 3 = 0, x 10 = 1 and x 12 = 0, so these three variables (and the corresponding row of A) can be eliminated. <p> Sometimes, the linear constraint represented by row i of A forces all its variables to either their upper or lower bounds. An example would be the constraint 10x 3 4x 10 + x 12 = 4 subject to the bounds x 3 2 [0; +1); x 10 2 <ref> [0; 1] </ref>; x 12 2 [0; +1): In this case, we must have x 3 = 0, x 10 = 1 and x 12 = 0, so these three variables (and the corresponding row of A) can be eliminated.
Reference: [2] <author> A. R. Curtis and J. K. Reid, </author> <title> On the automatic scaling of matrices for Gaussian elimination, </title> <journal> J. Inst. Maths Applics, </journal> <volume> 10 (1972), </volume> <pages> pp. 118-124. </pages>
Reference-contexts: We refer the interested reader to Gondzio's paper for details. Our implementation draws not only on this paper and also on Gondzio's code HOPDM (version 2.13), in which slightly different heuristics from those described in the paper are used. Our code applies the scaling technique of Curtis and Reid <ref> [2] </ref> to the coefficient matrix A before solving.
Reference: [3] <author> J. R. Gilbert, E. Ng, and B. W. Peyton, </author> <title> An efficient algorithm to compute row and column counts for sparse cholesky factorization, </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 15 (1994), </volume> <pages> pp. 1075-1091. 22 </pages>
Reference-contexts: This strategy was introduced by Liu [6]. The scheme used for symbolic factorization is partly described by Liu [7] and Gilbert, Ng, and Peyton <ref> [3] </ref>. The numerical factorization is performed by a left-looking block sparse Cholesky algorithm, as described by Ng and Peyton [9].
Reference: [4] <author> J. Gondzio, </author> <title> Multiple centrality corrections in a primal-dual method for linear programming, </title> <journal> Computational Optimization and Applications, </journal> <volume> 6 (1996), </volume> <pages> pp. 137-156. </pages>
Reference-contexts: 1 Introduction PCx is a linear programming solver developed at the Optimization Technology Center at Ar-gonne National Laboratory and Northwestern University. It implements a variant of Mehrotra's predictor-corrector algorithm [8] with the higher-order correction strategy of Gondzio <ref> [4] </ref>. This approach is the most effective one known at present for general linear programs. The bulk of PCx is written in the C programming language. <p> Gondzio's <ref> [4] </ref> higher-order correction strategy is used to enhance the search direction at each iteration. In this approach, additional centering/correction directions are computed by solving (9) for different right-hand sides. <p> Default: 3.0. dualfeastol fvalueg Specify a dual feasibility tolerance. Default: 10 8 . history fyesg/fnog Request that a history file be written (yes) or not written (no). If yes, the file probname.log is written to the working directory (see Section 8). 12 HOCorrections fyesg/fnog Request that Gondzio's <ref> [4] </ref> higher-order corrections be used to en- hance the search direction. Default: yes. inputdirectory fnameg If PCx is to search for the MPS input files in another directory, in addition to the current working directory, name this other directory here. Remember to include a trailing "/". <p> PCx solved these problems efficiently, as shown in Tables 3. The improvements obtained by using higher-order corrections are not too dramatic. Part of the reason is that the factorization routine is more efficient relative to the solution routine than is the case in, for example, HOPDM (see Gondzio <ref> [4] </ref>). It follows that there is less to be gained by economizing on matrix factorizations. Significant improvements can however be observed on several problems, including dfl001, pds-10, NEMSemm1, and NEMSwrld.
Reference: [5] <author> A. Gupta, M. Joshi, and V. Kumar, WSSMP: </author> <title> Watson Symmetric Sparse Matrix Package, </title> <institution> IBM Research Report RC 20923 (92699), IBM, </institution> <month> July </month> <year> 1997. </year>
Reference-contexts: the interface with the sparse Cholesky solver, showing the user how alternative solvers can be hooked up to PCx without the need to understand or modify the bulk of the code. (In addition to the Ng-Peyton solver, the PCx distribution contains the routines needed to link to IBM's WSSMP solver <ref> [5] </ref>. Unlike the Ng-Peyton solver, the WSSMP library is proprietary and must be obtained separately.) Finally, Section 10 reports on computational results for the standard netlib test set of feasible and infeasible problems, together with some new problems arising from the NEMS project at Argonne. <p> The release of Ng and Peyton's code used here is version 0.4 of May 1995. Release 1.1 of PCx also contains a link the IBM code WSSMP, described by Gupta, Joshi, and Kumar <ref> [5] </ref>. This is a multifrontal sparse Cholesky package which uses a nested dissection ordering, and it appears to be especially effective for larger problems. WSSMP is currently supplied in the form of libraries for IBM RS6000 architectures. <p> The transfer mode should be set to binary by using the bin command in ftp before attempting to transfer PCx.tar.gz or any of the executable files. If the WSSMP library <ref> [5] </ref> can be obtained, an executable PCx that calls this library can be created by placing the library in a directory called ./wssmp and typing build PCx wssmp 8 Invoking PCx By downloading and installing PCx on one's system (see Section 7), the user will have an executable PCx, a Makefile
Reference: [6] <author> J. W.-H. Liu, </author> <title> Modification of the minimum degree algorithm by multiple elimination, </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 11 (1985), </volume> <pages> pp. </pages> <month> 141-153. </month> <title> [7] , The role of elimination trees in sparse factorization, </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 11 (1990), </volume> <pages> pp. 134-172. </pages>
Reference-contexts: This strategy was introduced by Liu <ref> [6] </ref>. The scheme used for symbolic factorization is partly described by Liu [7] and Gilbert, Ng, and Peyton [3]. The numerical factorization is performed by a left-looking block sparse Cholesky algorithm, as described by Ng and Peyton [9].
Reference: [8] <author> S. Mehrotra, </author> <title> On the implementation of a primal-dual interior point method, </title> <journal> SIAM Journal on Optimization, </journal> <volume> 2 (1992), </volume> <pages> pp. 575-601. </pages>
Reference-contexts: 1 Introduction PCx is a linear programming solver developed at the Optimization Technology Center at Ar-gonne National Laboratory and Northwestern University. It implements a variant of Mehrotra's predictor-corrector algorithm <ref> [8] </ref> with the higher-order correction strategy of Gondzio [4]. This approach is the most effective one known at present for general linear programs. The bulk of PCx is written in the C programming language. <p> = 0; i = 1; 2; : : :; n; (8e) We stress that the PCx code actually works with the formulation (2); we use the simpler form (6) in our discussion solely to avoid creating a notational jungle in the next few sections. 3 The Algorithm Mehrotra's predictor-corrector algorithm <ref> [8] </ref> is based on Newton's method for the KKT conditions (4a)-(4e), modified to retain positivity of the (x; s; r; w) components, to incorporate a "centering" component in the search direction, and to improve the order of accuracy to which the search direction approximates the nonlinear equations (4d) and (4e). <p> Similarly to (14), we calculate ff max;P = inf fff 2 [0; 1] j (x; w) + ff (x; w) 0g; (18a) and set where fl P and fl D are two scaling factors obtained from Mehrotra's adaptive steplength heuristic <ref> [8, p. 588] </ref>. <p> If the solution file is written, it is named probname.out and is placed in the working directory (see Section 8). Default: yes. stepfactor fvalueg Specify a value in the range (0; 1) that is used in Mehrotra's adaptive steplength heuristic from <ref> [8, p. 118] </ref>. This value is a lower bound for fl P and fl D in (19). Default: 0:9. unrollinglevel fvalueg Specify the level of loop unrolling. Allowable values are 1, 2, 4, and 8. (This parameter is used only in the Ng-Peyton sparse Cholesky code.) Default: 4.
Reference: [9] <author> E. Ng and B. W. Peyton, </author> <title> Block sparse Cholesky algorithms on advanced uniprocessor computers, </title> <journal> SIAM Journal on Scientific Computing, </journal> <volume> 14 (1993), </volume> <pages> pp. 1034-1056. </pages>
Reference-contexts: The bulk of PCx is written in the C programming language. Its main computational operation|solution of a sparse linear system of equations at each iteration|is performed by a call to the sparse Cholesky package of Ng and Peyton <ref> [9] </ref>, which is programmed in Fortran 77. Source codes for both PCx and the Ng-Peyton linear equations solver can be found in the PCx distribution file. They are available subject to the qualifications in the copyright statement on the PCx home page on the World Wide Web (see Section 7). <p> Section 3 describes the algorithm, including details of termination and infeasibility detection. Section 4 discusses the major computational issue in the code|factorization of a sparse, positive definite matrix|including the modifications to the Ng-Peyton code <ref> [9] </ref> needed in this context. (Alternative factorization modules to the Ng-Peyton code will require similar modifications.) Presolver capabilities are outlined in Section 5. The user can set various algorithmic options and control the amount and type of output by means of a specifications file; details are provided in Section 6. <p> These factorizations and triangular substitutions dominate the computational cost of the algorithm. The default PCx uses the sparse Cholesky solver of Ng and Peyton <ref> [9] </ref>, modified slightly to handle the small pivot elements that frequently arise during later iterations of the interior-point method. <p> This strategy was introduced by Liu [6]. The scheme used for symbolic factorization is partly described by Liu [7] and Gilbert, Ng, and Peyton [3]. The numerical factorization is performed by a left-looking block sparse Cholesky algorithm, as described by Ng and Peyton <ref> [9] </ref>. The code exploits hierarchical memory by splitting the supernodes into blocks that fit into available cache. (Cache size is passed to the code as a parameter.) Loop unrolling is used to make better use of registers.
Reference: [10] <author> S. J. Wright, </author> <title> The Cholesky factorization in interior-point and barrier methods, </title> <type> Preprint MCS-P600-0596, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <month> May </month> <year> 1996. </year> <title> [11] , Primal-Dual Interior-Point Methods, </title> <publisher> SIAM Publications, </publisher> <address> Philadelphia, Pa, </address> <year> 1997. </year>
Reference-contexts: This substitution causes the off-diagonal elements in the ith column of the Cholesky factor L to be extremely small (essentially zero) and causes the ith component of the solution vector to be extremely small. Analysis of this technique has been performed by Wright <ref> [10] </ref>. A similar pivot modification strategy is used by the MATLAB-based code LIPSOL (see Zhang [12],[13]), which also uses Ng and Peyton's code as its computational engine.
Reference: [12] <author> Y. Zhang, </author> <title> User's Guide to LIPSOL, </title> <institution> Department of Mathematics and Statistics, University of Maryland Baltimore County, Baltimore, Maryland, </institution> <month> July </month> <year> 1995. </year> <title> [13] , Solving large-scale linear programs by interior-point methods under the MATLAB en-viroment, </title> <type> Technical Report TR96-01, </type> <institution> Department of Mathematics and Statistics, University of Maryland Baltimore County, Baltimore, Md, </institution> <year> 1996. </year>
Reference: [14] <institution> Annual Energy Outlook 1996, Energy Information Administration, U. S. Department of Energy, </institution> <address> Washington, DC 20585, </address> <year> 1996. </year> <note> Document DOE/EIA-0383(96). 23 </note>
Reference-contexts: In two other cases, infeasibility was detected by the preprocessor, so the interior-point solver did not need to be called at all. The NEMS problems are instances of models in the National Energy Modeling System (NEMS) of the Energy Information Administration of the United States Department of Energy <ref> [14] </ref>. These problems are taken from NEMS modules which are used to model electricity capacity planning, petroleum marketing, and coal marketing. PCx solved these problems efficiently, as shown in Tables 3. The improvements obtained by using higher-order corrections are not too dramatic.
References-found: 11

