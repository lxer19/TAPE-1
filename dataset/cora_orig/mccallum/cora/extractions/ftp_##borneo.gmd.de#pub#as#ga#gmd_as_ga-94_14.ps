URL: ftp://borneo.gmd.de/pub/as/ga/gmd_as_ga-94_14.ps
Refering-URL: http://www.ing.unlp.edu.ar/cetad/mos/memetic_home.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Strategy Adaptation by Competing Subpopulations  
Author: Dirk Schlierkamp-Voosen and Heinz Muhlenbein 
Keyword: breeder genetic algorithm, strategy adaptation, competition, multiresolution search  
Address: Schlo Birlinghoven D-53754 Sankt Augustin, Germany  
Affiliation: GMD  
Abstract: The breeder genetic algorithm BGA depends on a set of control parameters and genetic operators. In this paper it is shown that strategy adaptation by competing subpopulations makes the BGA more robust and more efficient. Each subpopulation uses a different strategy which competes with other subpopulations. Numerical results are pre sented for a number of test functions.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Thomas Back. </author> <title> Self-Adaption in Genetic Algorithms. </title> <editor> In Francisco Varela and Paul Bourgine, editors, </editor> <booktitle> Towards a Practice of Autonomous Systems, </booktitle> <pages> pages 263-271, </pages> <year> 1992. </year>
Reference-contexts: This approach is successfully used in evolution strategies [3]. In evolution strategies the adaptation of control parameters is done in the same manner as the adaptation of the parameters defining the fitness functions <ref> [1] </ref>. The crucial question of the second approach concerns the level where the adaptation is done. It may be the level of the individual as it is done in evolution strategies. <p> Then ffi is given by ffi = 2 j This mutation scheme is discrete. For a number of reasons we now use a continuous mutation scheme where ffi is computed as follows ffi = 2 kff ff 2 <ref> [0; 1] </ref> The discussion of this scheme is outside the scope of this paper. BGA line recombination The BGA line recombination uses components from both, mutation and recombination. It creates new points in a direction given by the two parent points.
Reference: 2. <editor> Thomas Back and Hans-Paul Schwefel. </editor> <title> A Survey of Evolution Strategies. </title> <booktitle> In Proceedings of the Fourth International Conference of Genetic Algorithms, </booktitle> <pages> pages 2-9, </pages> <address> San Diego, </address> <year> 1991. </year> <month> ICGA. </month>
Reference-contexts: This will be described in the next section. 3 Competition between Subpopulations The adaptation of parameters controlling evolutionary algorithms can be done on different levels, for example the level of the individuals, the level of subpopula-tions or the level of populations. Back et al. <ref> [2] </ref> have implemented the adaptation of strategy parameters on the level of the individual. The strategy parameters of the best individuals are recombined, giving the new stepsize for the mutation operator in the next generation. Herdy [5] uses competition on the population level.
Reference: 3. <editor> Thomas Back and Hans-Paul Schwefel. </editor> <title> An Overview of Evolutionary Algorithms for Parameter Optimization. </title> <journal> Evolutionary Computation, </journal> <volume> 1 </volume> <pages> 1-24, </pages> <year> 1993. </year>
Reference-contexts: In the second approach the mechanisms of evolution itself are used to adapt the control parameters. The adaptation is not driven by an external schedule but by the internal forces of evolution itself. This approach is successfully used in evolution strategies <ref> [3] </ref>. In evolution strategies the adaptation of control parameters is done in the same manner as the adaptation of the parameters defining the fitness functions [1]. The crucial question of the second approach concerns the level where the adaptation is done.
Reference: 4. <author> Terence C. Fogarty. </author> <title> Varying the probability of Mutation in the Genetic Algorithm. </title> <editor> In J. David Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference of Genetic Algorithms, </booktitle> <pages> pages 104-109. </pages> <address> Morgan-Kaufman, </address> <year> 1989. </year>
Reference-contexts: This approach is derived from simulated annealing. The temperature is set at a large initial value, then it is continuously reduced. In genetic algorithms this approach has been tried for changing the mutation rate or the selection <ref> [4] </ref>. In the second approach the mechanisms of evolution itself are used to adapt the control parameters. The adaptation is not driven by an external schedule but by the internal forces of evolution itself. This approach is successfully used in evolution strategies [3].
Reference: 5. <author> Michael Herdy. </author> <title> Reproductive Isolation as Strategy Parameter in Hierarchical Organized Evolution Strategies. </title> <booktitle> In PPSN 2 Bruxelles, </booktitle> <pages> pages 207-217, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Back et al. [2] have implemented the adaptation of strategy parameters on the level of the individual. The strategy parameters of the best individuals are recombined, giving the new stepsize for the mutation operator in the next generation. Herdy <ref> [5] </ref> uses competition on the population level. In this case whole populations are evaluated at certain generations. The strategies of the successful populations proliferate, the strategies of populations with bad performance die out. They are replaced by the successful strategies and afterwards modified by genetic operators.
Reference: 6. <author> Heinz Muhlenbein and Dirk Schlierkamp-Voosen. </author> <title> Predictive Models for the Breeder Genetic Algorithm: Continuous Parameter Optimization. </title> <journal> Evolutionary Computation, </journal> <volume> 1(1) </volume> <pages> 25-49, </pages> <year> 1993. </year>
Reference-contexts: multimodal functions. 2 The BGA for Continuous Parameter Optimization Let an unconstrained optimization problem be given on a domain D IR n min (F (x)) a i x i b i i = 1; :::; n : (1) The breeder genetic algorithm BGA was designed to solve the above problem <ref> [6] </ref>. The BGA depends on some control parameters which we summarize shortly. The selection is done by truncation selection, also called mass selection by breeders. The T % best of the individuals are selected as parents and then mated randomly. <p> Discrete recombination is a breadth search. It uses the information contained in the two parent points. The BGA line recombination tries new points in a direction defined by the parent points. In <ref> [6] </ref> we have proven that a BGA with popsize N = 1 (1 parent, 1 offspring, the better of the two survives) using only mutation has approximate linear order of convergence for unimodal functions. Theorem 1. <p> At the end the group with the smallest mutation steps has taken over. Fig. 5. Quality criterion which af fected the variation of the population sizes shown in Fig. 4. 5 Multiresolution Search for Multimodal Functions The BGA is intended to solve multimodal optimization problems. In <ref> [6] </ref> we have shown that the standard BGA using mutation and discrete recombination has also linear order of convergence for some of the popular multimodal test functions. The scaling constants are specific to the fitness function and the precision constant k of the BGA. <p> The multimodality only reduces the probability of creating better offspring. Fig. 6. Competition vs. normal BGA run; For fine tuning competition is more effective. Note the waves of the competition run. We have pointed out in <ref> [6] </ref> that the local minima of these test functions are regularly distributed. For these classes of problems discrete recombination is an especially efficient operator. Therefore these test functions are not a challenge for the BGA.
Reference: 7. <author> Heinz Muhlenbein and Dirk Schlierkamp-Voosen. </author> <title> The science of breeding and its application to the breeder genetic algorithm. </title> <journal> Evolutionary Computation, </journal> <volume> 1(4) </volume> <pages> 335-360, </pages> <year> 1994. </year>
Reference-contexts: Small values of k have a better progress at the beginning, but they are able to locate the best fitness to a certain precision only. Next we summarize the mathematical properties of discrete recombination. A detailed investigation can be found in <ref> [7] </ref>. Discrete recombination has also linear order of convergence in number of generations versus fitness until near the equilibrium. Equilibrium is defined as all genotypes of the population being equal. The fitness value achieved at equilibrium depends on the size of the population and the truncation selection threshold.
Reference: 8. <author> H. H. </author> <title> Rosenbrock. An automatic method for finding the greatest or least value of a function. </title> <journal> The Computer Journal, </journal> <volume> 3(3) </volume> <pages> 175-184, </pages> <month> 10 </month> <year> 1960. </year>
Reference-contexts: In the final stage of the search the group with the smallest steps locates the optimum with high precision. A real challenge for any continuous function optimization program is to follow a steep curved valley which is only slightly decreasing. An example is the function of Rosenbrock <ref> [8] </ref>. In [10] the two dimensional function was extended to a n-dimensional function. F 16 (x) = i=1 100 (x i+1 x 2 5:12 x i 5:12 (11) For these kind of functions the BGA mutation scheme is not efficient. Line recombination seems much more promising.
Reference: 9. <author> Fabio Schoen. </author> <title> A Wide Class of Test Functions for Global Optimization. </title> <journal> Journal of Global Optimization, </journal> <volume> 3(2) </volume> <pages> 133-137, </pages> <year> 1993. </year>
Reference-contexts: The run without competition is slightly more effective. But the BGA with competition is more robust. The BGA without competition converged in 9 of 10 cases to the second minima. We will now turn to optimization problems where the local minima are distributed more randomly. In <ref> [9] </ref> these kind of test functions are also proposed as a common benchmark for global optimization problems. We have used the following test function originally proposed by Rechenberg.
Reference: 10. <author> H.-P. Schwefel. </author> <title> Numerical Optimization of Computer Models. </title> <publisher> Wiley, </publisher> <address> Chichester, </address> <year> 1981. </year>
Reference-contexts: In the final stage of the search the group with the smallest steps locates the optimum with high precision. A real challenge for any continuous function optimization program is to follow a steep curved valley which is only slightly decreasing. An example is the function of Rosenbrock [8]. In <ref> [10] </ref> the two dimensional function was extended to a n-dimensional function. F 16 (x) = i=1 100 (x i+1 x 2 5:12 x i 5:12 (11) For these kind of functions the BGA mutation scheme is not efficient. Line recombination seems much more promising.
References-found: 10

