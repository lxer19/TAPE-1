URL: http://www.cs.arizona.edu/scout/Papers/spe96.ps
Refering-URL: http://www.cs.arizona.edu/scout/publications.html
Root-URL: http://www.cs.arizona.edu
Email: fdavidm,druschel,llpg@cs.arizona.edu  
Title: Implementing Atomic Sequences on Uniprocessors Using Rollforward  
Author: David Mosberger, Peter Druschel and Larry L. Peterson 
Date: Summary  
Address: Tucson, AZ 85721  
Affiliation: Department of Computer Science University of Arizona  
Abstract: This article presents a software-only solution to the synchronization problem for uniprocessors. The idea is to execute atomic sequences without any hardware protection, and in the rare case of pre-emption, to roll the sequence forward to the end, thereby preserving atomicity. One of the proposed implementations protects atomic sequences without any memory-accesses. This is significant as it enables execution at CPU-speeds, rather than memory-speeds. The benefit of this method increases with the frequency at which atomic sequences are executed. It therefore encourages the building of systems with fine-grained synchronization. This has the additional advantage of reducing average latency. Experiments demonstrate that this technique has the potential to outperform even the best hardware mechanisms. The main contribution of this article is to discuss operating-system related issues of rollforward and to demonstrate its practicality, both in terms of flexibility and performance.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Maurice Herlihy, </author> <title> `Wait-free synchronization', </title> <journal> ACM Trancsactions on Programming Languages and Systems, </journal> <volume> 11(1), </volume> <month> 124-149 </month> <year> (1991). </year>
Reference-contexts: It is by no means to only technique to implement atomic sequences <ref> [1] </ref>. 1 over 100 cycles to move a 64 bit quantity atomically between two memory locations. While it is certainly possible to reduce this overhead, this example does illustrate that hardware synchronization primitives are designed and optimized for the multiprocessor case.
Reference: [2] <author> Gregory R. Andrews, </author> <title> Concurrent Programming: </title> <booktitle> Principles and Practice, </booktitle> <address> Benjamin/Cummings, Menlo Park, </address> <year> 1991. </year>
Reference-contexts: 1 Introduction Atomic sequencesa sequence of instructions that needs to execute without interferenceare fundamental to concurrent programs, including operating systems. 1 For this reason, processors generally provide synchro nization primitives, such as test-and-set or compare-and-swap in their instruction-set architecture <ref> [2, 3, 4, 5, 6, 7, 8] </ref>. Due to the trend of implementing processors that are suitable for use in shared-memory multiprocessors, these primitives have become quite expensive.
Reference: [3] <author> Hewlett-Packard, </author> <title> PA-RISC 1.1 Architecture and Instruction Set Reference Manual, </title> <institution> Hewlett-Packard, Cupertino, California, </institution> <note> first edition, </note> <month> November </month> <year> 1990. </year> <title> Part number 09740-90039. </title>
Reference-contexts: 1 Introduction Atomic sequencesa sequence of instructions that needs to execute without interferenceare fundamental to concurrent programs, including operating systems. 1 For this reason, processors generally provide synchro nization primitives, such as test-and-set or compare-and-swap in their instruction-set architecture <ref> [2, 3, 4, 5, 6, 7, 8] </ref>. Due to the trend of implementing processors that are suitable for use in shared-memory multiprocessors, these primitives have become quite expensive. <p> For software-based schemes, this includes registration overheads, for example. The hardware on which we obtained these results consisted of a DEC 3000 Model 600 AXP workstation with an Alpha CPU operating at 175 MHz and an HP 9000/735 with a PA-RISC 1.1 CPU operating at 99 MHz <ref> [7, 3] </ref>. All tests were small enough to fit in the cache and the reported results are the execution times when running in the cache (i.e., with a warm cache). Both machines provide timers with a resolution of a single CPU cycle.
Reference: [4] <author> Intel, </author> <note> 80960CA User's Manual, </note> <year> 1989. </year>
Reference-contexts: 1 Introduction Atomic sequencesa sequence of instructions that needs to execute without interferenceare fundamental to concurrent programs, including operating systems. 1 For this reason, processors generally provide synchro nization primitives, such as test-and-set or compare-and-swap in their instruction-set architecture <ref> [2, 3, 4, 5, 6, 7, 8] </ref>. Due to the trend of implementing processors that are suitable for use in shared-memory multiprocessors, these primitives have become quite expensive.
Reference: [5] <institution> The PowerPC Architecture, </institution> <month> Cath May, </month> <editor> Ed Silha, Rick Simpson, and Hank Warren (eds.), </editor> <publisher> Morgan Kaufman, </publisher> <address> second edition, </address> <year> 1994. </year>
Reference-contexts: 1 Introduction Atomic sequencesa sequence of instructions that needs to execute without interferenceare fundamental to concurrent programs, including operating systems. 1 For this reason, processors generally provide synchro nization primitives, such as test-and-set or compare-and-swap in their instruction-set architecture <ref> [2, 3, 4, 5, 6, 7, 8] </ref>. Due to the trend of implementing processors that are suitable for use in shared-memory multiprocessors, these primitives have become quite expensive.
Reference: [6] <author> Charles Price, </author> <title> MIPS IV Instruction Set, MIPS Technologies, </title> <publisher> Inc., </publisher> <address> Mountain View, CA, </address> <year> 1995. </year> <month> 23 </month>
Reference-contexts: 1 Introduction Atomic sequencesa sequence of instructions that needs to execute without interferenceare fundamental to concurrent programs, including operating systems. 1 For this reason, processors generally provide synchro nization primitives, such as test-and-set or compare-and-swap in their instruction-set architecture <ref> [2, 3, 4, 5, 6, 7, 8] </ref>. Due to the trend of implementing processors that are suitable for use in shared-memory multiprocessors, these primitives have become quite expensive.
Reference: [7] <editor> Alpha Architecture Reference Manual, Richard L. Sites (ed.), </editor> <publisher> Digital Press, </publisher> <address> Burlington, Massachusetts, </address> <year> 1992. </year> <title> Order number EY-L520E-DP. </title>
Reference-contexts: 1 Introduction Atomic sequencesa sequence of instructions that needs to execute without interferenceare fundamental to concurrent programs, including operating systems. 1 For this reason, processors generally provide synchro nization primitives, such as test-and-set or compare-and-swap in their instruction-set architecture <ref> [2, 3, 4, 5, 6, 7, 8] </ref>. Due to the trend of implementing processors that are suitable for use in shared-memory multiprocessors, these primitives have become quite expensive. <p> Due to the trend of implementing processors that are suitable for use in shared-memory multiprocessors, these primitives have become quite expensive. For example, the Alpha architecture <ref> [7] </ref> pro vides a multiprocessor-safe load-linked/store-conditionally instruction that, on some uniprocessors, requires fl Author's current address: Department of Computer Science, Rice University, P.O. <p> For software-based schemes, this includes registration overheads, for example. The hardware on which we obtained these results consisted of a DEC 3000 Model 600 AXP workstation with an Alpha CPU operating at 175 MHz and an HP 9000/735 with a PA-RISC 1.1 CPU operating at 99 MHz <ref> [7, 3] </ref>. All tests were small enough to fit in the cache and the reported results are the execution times when running in the cache (i.e., with a warm cache). Both machines provide timers with a resolution of a single CPU cycle. <p> That is, the code to change the interrupt priority level is no longer inlined. PALcode: The Alpha architecture defines a Privileged Architecture Library (PALcode). This library code is invoked via traps and executes in privileged kernel mode with interrupts turned off <ref> [7] </ref>. We did not have the opportunity to implement the benchmarks as PALcode yet, but found that it takes at least 13 cycles just to invoke PALcode and return immediately from it. It is not possible to inline PALcode. <p> As shown in row splx, this is rather expensive. Finally, as the last row indicates, a pair of load-linked/store-conditionally instructions has a surprisingly high cost. Considering this and the rather long list of conditions under which a store-conditionally is (almost) guaranteed to fail <ref> [7] </ref>, this does not appear to be an effective scheme to provide atomicity in a uniprocessor. 4.2 Overhead per Rollforward The overhead per rollforward consists of two components: the time to check whether it is safe to do a rollforward and the time to activate and return from the rollforward (i.e., <p> Conservatively, we set O R = 480 cycles. On the other side, the best architecturally defined hardware-based scheme on the Alpha is PALcode <ref> [7] </ref>. As shown in Table 1, the overhead per PALcode invocation is at least 13 cycles. Optimistically, O H is 13 cycles.
Reference: [8] <author> SPARC International, </author> <title> The SPARC Architecture Manual, Version 8, </title> <publisher> Prentice-Hall, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction Atomic sequencesa sequence of instructions that needs to execute without interferenceare fundamental to concurrent programs, including operating systems. 1 For this reason, processors generally provide synchro nization primitives, such as test-and-set or compare-and-swap in their instruction-set architecture <ref> [2, 3, 4, 5, 6, 7, 8] </ref>. Due to the trend of implementing processors that are suitable for use in shared-memory multiprocessors, these primitives have become quite expensive.
Reference: [9] <author> Daniel Stodolsky, J. Bradley Chen, and Brian N. Bershad, </author> <title> `Fast interrupt priority management in operating system kernels', </title> <booktitle> Proceedings of the Second Usenix Workshop on Microkernels and Other Kernel Architectures. Usenix, </booktitle> <month> September </month> <year> 1993, </year> <pages> pp. 105-110. </pages>
Reference-contexts: Although an order of magnitude faster than load-linked/store-conditionally, operations for disabling interrupts are usually privileged, meaning that they cannot be directly invoked by user processes. It is also the case that support for hierarchical priority levels is more expensive than one might hope <ref> [9] </ref>. Because of the limitations of these two hardware-based approaches, Bershad, Redell, and Ellis have proposed a software-only implementation of mutual exclusion on uniprocessors [10]. However, the solution is applicable only to simple atomic sequences that involve at most one write to shared memory. <p> The paper gives only a superficial treatment of the issues involved. It does not give any indications as to the cost or limitations of rollforward. Finally, Stodolsky et al. <ref> [9] </ref> present a technique called optimistic interrupt protection. The idea is to use delayed (lazy) evaluation to reduce the number of times that expensive interrupt level changing instructions have to be invoked.
Reference: [10] <author> Brian N. Bershad, David D. Redell, and John R. Ellis, </author> <title> `Fast mutual exclusion for uniprocessors', </title> <booktitle> Fifth Symposium on Architectural Support for Programming Languages and Operating Systems. ACM, </booktitle> <month> October </month> <year> 1992, </year> <pages> pp. 223-233. </pages>
Reference-contexts: It is also the case that support for hierarchical priority levels is more expensive than one might hope [9]. Because of the limitations of these two hardware-based approaches, Bershad, Redell, and Ellis have proposed a software-only implementation of mutual exclusion on uniprocessors <ref> [10] </ref>. However, the solution is applicable only to simple atomic sequences that involve at most one write to shared memory. While this is sufficient to implement synchronization primitives powerful enough to construct higher-level synchronization objects, the approach is still limited. <p> Many registration schemes are conceivable and we present only four possibilities in that spectrum: designated sequences, static registration, dynamic registration, and hybrid registration. The first two were previously suggested by Bershad et al. <ref> [10] </ref>; we repeat them here for completeness. We found that both approaches rather seriously limit flexibility. The third and fourth approach remove these limitations at the cost of slightly higher overheads. 3 2.2.1 Designated Sequences The first proposal in [10] is to use designated instruction sequences to mark atomic sequences. <p> The first two were previously suggested by Bershad et al. <ref> [10] </ref>; we repeat them here for completeness. We found that both approaches rather seriously limit flexibility. The third and fourth approach remove these limitations at the cost of slightly higher overheads. 3 2.2.1 Designated Sequences The first proposal in [10] is to use designated instruction sequences to mark atomic sequences. This is also the technique used in [16]. Designated sequences must not appear anywhere but in atomic sequences. <p> Minimizing variance, as opposed to minimizing latency, is a performance goal that we expect to increase in importance [23]. 19 5 Related Work As mentioned in the introduction, Bershad et al. propose a software-based technique for mutual exclusion on uniprocessors <ref> [10] </ref>. It is based on rollback instead of rollforward and differs from the latter in several specific ways. First, the solution is limited to atomic sequences that contain only a single write to shared memory, whereas the rollforward approach permits multiple writes. <p> Third, dynamic registration schemes allow inlining of atomic sequences, whereas the static registration scheme proposed in <ref> [10] </ref> severely restricts the number of atomic sequences. Similarly, designated sequences are substantially easier to use with rollforward because false hits are acceptable. The bottom line is that rollforward makes software-based mutual exclusion a much more easily applicable technique. <p> First, we described that page faults present a bigger challenge with rollforward than with rollback. With rollback, page faults are a problem only if an interrupt handler needs to inspect the interrupted code in order to determine whether it interrupted an atomic sequence <ref> [10] </ref>. With rollforward, there is the additional potential for a page fault during recovery.
Reference: [11] <author> Henry Massalin, </author> <title> `Synthesis: An efficient implementation of fundamental operating system services', </title> <type> Ph.D. Thesis, </type> <institution> Columbia University, </institution> <address> New York, NY 10027, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: as this code cannot risk blocking. (In general, lock-based solutions introduce the problem of deadlock.) Second, while it is possible to create lock-free data-structures based on some of these primitives, it is well-known that this approach can incur significant overheads, often requiring reference counts and/or shadow copies of shared objects <ref> [11, 12] </ref>. To alleviate these limitations, we propose the use of rollforward. When an atomic sequence is preempted, the system arranges for the sequence to be executed to the end before resuming the new task. This approach puts few restrictions on the code that constitutes atomic sequences. <p> On the positive side, it combines the advantages of designated sequences and static registration. Inlining poses no problem. The extent of an atomic sequence 4 can be computed at run time, so even late forms of inlining, such as code synthesis <ref> [11] </ref>, would work. Checking whether an atomic sequence was interrupted is efficient as well. It involves no more than two comparisons: one to determine whether an atomic sequence is registered and a second to check whether the sequence has finished execution already. <p> First, the solution is limited to atomic sequences that contain only a single write to shared memory, whereas the rollforward approach permits multiple writes. It is often more convenient, and in the end more efficient, to implement shared data-structures via sequences that require multiple writes to shared memory <ref> [11] </ref>. Second, rollforward supports efficient lock-free solutions, whereas rollback was designed for a lock-based scenario.
Reference: [12] <author> Maurice Herlihy, </author> <title> `A methodology for implementing highly concurrent data objects', </title> <journal> ACM Trancsac-tions on Programming Languages and Systems, </journal> <volume> 15(5), </volume> <month> 745-770 </month> <year> (1993). </year>
Reference-contexts: as this code cannot risk blocking. (In general, lock-based solutions introduce the problem of deadlock.) Second, while it is possible to create lock-free data-structures based on some of these primitives, it is well-known that this approach can incur significant overheads, often requiring reference counts and/or shadow copies of shared objects <ref> [11, 12] </ref>. To alleviate these limitations, we propose the use of rollforward. When an atomic sequence is preempted, the system arranges for the sequence to be executed to the end before resuming the new task. This approach puts few restrictions on the code that constitutes atomic sequences. <p> These advantages apply to multiprocessors as well. However, as argued by Herlihy <ref> [12] </ref>, the interest in multi-processor community appears to be based mainly on the second property (absence of deadlock), which makes it easier to build machines that are resilient against processor failures.
Reference: [13] <author> Samuel J. Leffler, Marshall Kirk McKusick, Michael J. Karels, and John S. Quarterman, </author> <title> The Design and Implementation of the 4.3BSD UNIX Operating System, </title> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference-contexts: Also, as the technique is purely software-based, it can be used to achieve mutual exclusion at any privilege level. This makes it equally well suited for implementation within the OS kernel (e.g., for device drivers) and in user-level processes (e.g., to protect against asynchronous events such as Unix signals <ref> [13] </ref> or VMS Asynchronous System Traps [14]). Even though the technique is not directly applicable to multiprocessor synchronization, it is useful in constructing lock-free data-structures on machines that do not have sufficiently powerful hardware-primitives [15]. While the idea of rollforward is straight-forward, there are several interesting issues.
Reference: [14] <author> Ruth E. Goldenberg and Saro Saravanan, </author> <title> VMS for Alpha PlatformsInternals and Data Structures, volume 1, </title> <publisher> DEC Press, </publisher> <address> Burlington, Massachusetts, prelimenary edition, </address> <year> 1992. </year> <title> Order number EY-L466E-P1. </title>
Reference-contexts: This makes it equally well suited for implementation within the OS kernel (e.g., for device drivers) and in user-level processes (e.g., to protect against asynchronous events such as Unix signals [13] or VMS Asynchronous System Traps <ref> [14] </ref>). Even though the technique is not directly applicable to multiprocessor synchronization, it is useful in constructing lock-free data-structures on machines that do not have sufficiently powerful hardware-primitives [15]. While the idea of rollforward is straight-forward, there are several interesting issues.
Reference: [15] <author> Brian N. Bershad, </author> <title> `Practical considerations for non-blocking concurrent objects', </title> <booktitle> Proceedings of the 13th International Conference on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1993, </year> <pages> pp. 264-273. </pages>
Reference-contexts: Even though the technique is not directly applicable to multiprocessor synchronization, it is useful in constructing lock-free data-structures on machines that do not have sufficiently powerful hardware-primitives <ref> [15] </ref>. While the idea of rollforward is straight-forward, there are several interesting issues. For example, we found that it is possible to trade flexibility for performance. As different applications require different performance/flexibility tradeoffs, no single solution will suite all of them. <p> Another shortcoming is that the Trellis/Owl work does not address any of the operating system issues raised by rollforward. Being a language system, it is unclear whether the same techniques could be generalized to other languages or supported in a language-independent manner. Rollforward is also mentioned in <ref> [15] </ref>. That work appears to dismiss rollforward as a practical solution for two reasons: (a) execution of code on behalf of another thread and (b) page faults. It is true that executing code on behalf of another thread is difficult.
Reference: [16] <author> J. Eliot B. Moss and Walter H. Kohler, </author> <title> `Concurrency features for the Trellis/Owl language', </title> <booktitle> European Conference on Object-Oriented Programming, number 276 in Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1987, </year> <pages> pp. 171-180. </pages>
Reference-contexts: The third and fourth approach remove these limitations at the cost of slightly higher overheads. 3 2.2.1 Designated Sequences The first proposal in [10] is to use designated instruction sequences to mark atomic sequences. This is also the technique used in <ref> [16] </ref>. Designated sequences must not appear anywhere but in atomic sequences. An interrupt handler can check whether the program-counter (PC) is inside an atomic sequence by matching the surrounding code according to a set of templates. <p> Similarly, designated sequences are substantially easier to use with rollforward because false hits are acceptable. The bottom line is that rollforward makes software-based mutual exclusion a much more easily applicable technique. Rollforward has been used successfully in the VAX runtime system of the Trellis/Owl language <ref> [16] </ref>. There, rollforward was implemented by emulating the instructions from the point of interruption to the end of the atomic sequence. We do not believe that emulation is feasible in the applications we envision. The complexity and overheads involved would be simply too big.
Reference: [17] <author> T.E. Anderson, B.N. Bershad, E.D. Lazowska, and H.M. Levy, </author> <title> `Scheduler activations: Effective kernel support for the user-level management of parallelism', </title> <booktitle> Proceedings of the Thirteenth ACM Symposium on Operating System Principles, </booktitle> <year> 1991. </year>
Reference-contexts: Older processors that do not employ separate instruction and data caches guarantee this automatically. 5 On many modern processors, however, establishing coherence requires explicit cache flushing, which can be costly. 2.3.2 Cloning The designers of Scheduler Activations <ref> [17] </ref> proposed a technique that has no overheads per atomic sequence but does not require write access to the code segment. The idea was to clone every atomic sequence. <p> Also, we discussed scenarios in which page faults do not pose a problem and proposed several solutions on how page faults could be handled in an environment in which they are not transparent. Another system that employed rollforward is Scheduler Activations <ref> [17] </ref>. Unlike Trellis/Owl, it does not use rollforward to achieve mutual exclusion. Instead, it is used to avoid deadlock. Scheduler Activations use lock-based synchronization. For performance and liveness reasons, it is undesirable to suspend a process while it is holding a lock.
Reference: [18] <author> John L. Hennessey and David A. Patterson, </author> <title> Computer Architecture: A Quantitative Approach, </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Palo Alto, </address> <year> 1990. </year>
Reference-contexts: The only condition on the kinds of faults that 6 can be used for this purpose is that it must be possible to resume a process after taking such a fault. Any precise fault guarantees this <ref> [18] </ref>. 2.4 Challenges in Realizing Rollforward So far, we have proposed mechanisms to regain control once an atomic sequence has finished execution. This is not sufficient, as it is also necessary to guarantee that a rollforward does indeed terminate. <p> In practice, this overhead is often in the 30 cycle range due to cache effects (PALcode is located at a platform-dependent fixed address and therefore not inlinable). As the gap between memory system and CPU 21 performance continues to grow <ref> [18, 24] </ref>, techniques that yield good cache performance will become ever more important. Software-based methods that use designated sequences, a dynamic, or hybrid scheme to register atomic sequences can all be inlined easily. Fourth, our experience is that rollforward is very practical.
Reference: [19] <author> DEC, </author> <title> DECchip 21064-AA Microprocessor Hardware Reference Manual, </title> <publisher> Digital Press, </publisher> <address> Maynard, Massachusetts, first edition, </address> <month> October </month> <year> 1992. </year> <title> Order number EC-N0079-72. </title> <type> 24 </type>
Reference-contexts: DI: Disabling all interrupts before entering an atomic sequence and enabling all interrupts after leaving it; i.e., this scheme does not admit interrupt priority levels. The Alpha architecture does not support this. However, the implementation described in <ref> [19] </ref> provides the required facilities in a chip specific fashion. These low-level facilities normally are not accessible to kernel-level software. The measurements therefore had to be performed in a small stand-alone system.
Reference: [20] <author> M. Accetta, R. Baron, W. Bolosky, D. Golub, R. Rashid, A. Tevanian, and M. Young, </author> <title> `Mach: A new kernel foundation for UNIX development', </title> <booktitle> USENIX Conference, </booktitle> <year> 1986, </year> <pages> pp. 93-112. </pages>
Reference-contexts: However, the implementation described in [19] provides the required facilities in a chip specific fashion. These low-level facilities normally are not accessible to kernel-level software. The measurements therefore had to be performed in a small stand-alone system. For the PA-RISC, the technique was measured in a Mach <ref> [20] </ref> kernel that was extended with the test programs. CIPL: Changing interrupt priority level via inlined code. The same comments as for DI apply. 14 splx: This is the same as CIPL except that it adds the overhead of a function call.
Reference: [21] <author> A. M. </author> <title> Turing, `On computable numbers, with an application to the Entscheidungsproblem', </title> <booktitle> Proceedings, </booktitle> <publisher> London Mathematical Society,, </publisher> <year> 1936, </year> <pages> pp. </pages> <month> 230-265. </month> <title> Published as Proceedings, </title> <journal> London Mathematical Society,, </journal> <volume> volume 2, number 42. </volume>
Reference-contexts: It is a well-known result that the halting problem for any universal language is undecidable <ref> [21] </ref>. It is therefore necessary to restrict the code in atomic sequences such that safety can be decided efficiently.
Reference: [22] <author> DEC, </author> <title> DEC 3000 300/400/500/600/800 Models, System Programmer's Manual, </title> <institution> Digital Equipment Corp., </institution> <year> 1993. </year> <title> Order number EK-D3SYS-PM.A01. </title>
Reference-contexts: Just prior to the interrupt, the CPU was executing in that address range. It is therefore likely that the instructions around A are in the instruction as well as in the secondary level cache (the latter is a superset of the primary caches <ref> [22] </ref>). As programs typically do not load data from the address range they are executing in, it is unlikely that any of the instructions around A reside in the primary data cache.
Reference: [23] <author> A. B. Montz, D. Mosberger, S. W. O'Malley, L. L. Peterson, T. A. Proebsting, and J. H. Hartman, </author> <title> `Scout: A communications-oriented operating system', </title> <type> Technical Report 94/20, </type> <institution> University of Arizona, </institution> <address> Tucson, AZ 85721, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Second, rollforward consistently showed a standard-deviation that was a factor of two smaller than PALcode. Minimizing variance, as opposed to minimizing latency, is a performance goal that we expect to increase in importance <ref> [23] </ref>. 19 5 Related Work As mentioned in the introduction, Bershad et al. propose a software-based technique for mutual exclusion on uniprocessors [10]. It is based on rollback instead of rollforward and differs from the latter in several specific ways.
Reference: [24] <author> Betty Prince, </author> <title> `Memory in the fast lane', </title> <journal> IEEE Spectrum, </journal> <volume> 31(2), </volume> <month> 38-41 </month> <year> (1994). </year>
Reference-contexts: In practice, this overhead is often in the 30 cycle range due to cache effects (PALcode is located at a platform-dependent fixed address and therefore not inlinable). As the gap between memory system and CPU 21 performance continues to grow <ref> [18, 24] </ref>, techniques that yield good cache performance will become ever more important. Software-based methods that use designated sequences, a dynamic, or hybrid scheme to register atomic sequences can all be inlined easily. Fourth, our experience is that rollforward is very practical.
Reference: [25] <author> Frank Mueller, </author> <title> `A library implementation of POSIX threads under UNIX', </title> <booktitle> USENIX Technical Conference Proceedings. USENIX, Winter 1993, </booktitle> <pages> pp. 29-41. 25 </pages>
Reference-contexts: A good example is the user-level implementation of POSIX threads presented in <ref> [25] </ref>. Concerns about the overhead of signal-masking led to a design using one big monitor rather than small atomic sequences. As a result, a major redesign will be necessary should this package ever be extended to support multiprocessors.
References-found: 25

