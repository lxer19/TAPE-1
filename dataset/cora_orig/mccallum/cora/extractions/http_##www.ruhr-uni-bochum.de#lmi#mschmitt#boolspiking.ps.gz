URL: http://www.ruhr-uni-bochum.de/lmi/mschmitt/boolspiking.ps.gz
Refering-URL: http://www.ruhr-uni-bochum.de/lmi/mschmitt/
Root-URL: http://www.ruhr-uni-bochum.de/lmi/mschmitt/
Email: mschmitt@igi.tu-graz.ac.at  
Title: On Computing Boolean Functions by a Spiking Neuron  
Author: Michael Schmitt 
Address: Klosterwiesgasse 32/2 A-8010 Graz, Austria  
Affiliation: Institute for Theoretical Computer Science Technische Universitat Graz  
Abstract: Computations by spiking neurons are performed using the timing of action potentials. We investigate the computational power of a simple model for such a spiking neuron in the Boolean domain by comparing it with traditional neuron models such as threshold gates (or McCulloch-Pitts neurons) and sigma-pi units (or polynomial threshold gates). In particular, we estimate the number of gates required to simulate a spiking neuron by a disjunction of threshold gates and we establish tight bounds for this threshold number. Furthermore, we analyze the degree of the polynomials that a sigma-pi unit must use for the simulation of a spiking neuron. We show that this degree cannot be bounded by any fixed value. Our results give evidence that the use of continuous time as a computational resource endows single-cell models with substantially larger computational capabilities. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. Chvatal and P. L. Hammer, </author> <title> Aggregation of inequalities in integer programming, in: Studies in Integer Programming, </title> <editor> eds. P. L. Hammer, E. L. Johnson, B. H. Korte and G. L. Nemhauser, </editor> <booktitle> Annals of Discrete Mathematics 1, </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1977, </year> <pages> pp. 145-162. 10 </pages>
Reference-contexts: Calculating the threshold number of a computational unit is a natural way to measure how much more powerful the unit is than a threshold gate. Investigations of the threshold number of Boolean functions can be traced back to Jeroslow [4] and Chvatal and Hammer <ref> [1] </ref>. Jeroslow [4] has shown that every Boolean function on n variables has threshold number at most 2 n1 , and further that for each k, where 1 k 2 n1 , there is a Boolean function having threshold number k, with the parity function attaining the maximum value. <p> Chvatal and Hammer <ref> [1] </ref> proved that computing the threshold number is NP-hard. The first explicit definition of the threshold number appears in later work by Hammer et al. [3]. They established bounds for the threshold number of positive Boolean functions.
Reference: [2] <author> W. Gerstner, </author> <title> Time structure of the activity in neural network models, </title> <note> Phys--ical Review E 51 (1995) 738-758. </note>
Reference-contexts: The neuron model that we consider here is a simple version of a leaky integrate-and-fire neuron. Further discussions of this and other neuron models can be found in the brief article of Softky and Koch [15] or in the surveys by Gerstner <ref> [2] </ref> and Maass [7, 8]. The latter also contain comprehensive lists of references to relevant literature from biophysics and neurobiology. The main simplification of our model is the embodiment of the postsynaptic potential as a rectangular pulse rather than a continuous function of a similar shape.
Reference: [3] <author> P. L. Hammer, T. Ibaraki and U. N. Peled, </author> <title> Threshold numbers and threshold completions, in: Studies on Graphs and Discrete Programming, </title> <editor> ed. P. Hansen, </editor> <booktitle> Annals of Discrete Mathematics 11, (Mathematics Studies 59), </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1981, </year> <pages> pp. 125-145. </pages>
Reference-contexts: Chvatal and Hammer [1] proved that computing the threshold number is NP-hard. The first explicit definition of the threshold number appears in later work by Hammer et al. <ref> [3] </ref>. They established bounds for the threshold number of positive Boolean functions. A Boolean function is positive (sometimes called monotone) if it satisfies f (x) f (y) for any pair of binary vectors x; y with x y. <p> A binary vector p is said to be a prime implicant of a Boolean function f if f (p) = 1 holds and p is minimal with respect to having this property. Every positive Boolean function is known to have a unique collection of prime implicants. Hammer et al. <ref> [3] </ref> show in particular that the threshold number of such a function is less than i bn=2c . Zuev and Lipkin [18] proved that almost all Boolean functions have a threshold number that satisfies the bounds (2 n =n) and O ((ln n) 2 n =n). <p> The disjunction of these at most n 1 gates is then equivalent to the spiking neuron. We show now that the upper bound is almost optimal up to a factor of 2. For the proof of this statement we use the following result by Hammer et al. <ref> [3] </ref>. Proposition 3 (Hammer et al. [3]) Let f be a positive Boolean function and P its collection of prime implicants. <p> We show now that the upper bound is almost optimal up to a factor of 2. For the proof of this statement we use the following result by Hammer et al. <ref> [3] </ref>. Proposition 3 (Hammer et al. [3]) Let f be a positive Boolean function and P its collection of prime implicants.
Reference: [4] <author> R. G. Jeroslow, </author> <title> On defining sets of vertices of the hypercube by linear inequalities, </title> <note> Discrete Mathematics 11 (1975) 119-124. </note>
Reference-contexts: Calculating the threshold number of a computational unit is a natural way to measure how much more powerful the unit is than a threshold gate. Investigations of the threshold number of Boolean functions can be traced back to Jeroslow <ref> [4] </ref> and Chvatal and Hammer [1]. Jeroslow [4] has shown that every Boolean function on n variables has threshold number at most 2 n1 , and further that for each k, where 1 k 2 n1 , there is a Boolean function having threshold number k, with the parity function attaining <p> Calculating the threshold number of a computational unit is a natural way to measure how much more powerful the unit is than a threshold gate. Investigations of the threshold number of Boolean functions can be traced back to Jeroslow <ref> [4] </ref> and Chvatal and Hammer [1]. Jeroslow [4] has shown that every Boolean function on n variables has threshold number at most 2 n1 , and further that for each k, where 1 k 2 n1 , there is a Boolean function having threshold number k, with the parity function attaining the maximum value.
Reference: [5] <author> W. Maass, </author> <title> Lower bounds for the computational power of networks of spiking neurons, </title> <booktitle> Neural Computation 8 (1996) 1-40. </booktitle>
Reference-contexts: Rectangular pulses are widely used in silicon implementations of networks of spiking neurons such as 3 described by Murray and Tarassenko [13]. Theoretical investigations concerning the computational power of networks of a neuron type that employs more complex functions as postsynaptic potentials can be found in Maass <ref> [5, 6, 7] </ref>. A spiking neuron may be viewed as a digital or analog computational element, depending on the type of temporal coding that is used. In the following we restrict our analysis to the coding of binary values.
Reference: [6] <author> W. Maass, </author> <title> Fast sigmoidal networks via spiking neurons, </title> <booktitle> Neural Computation 9 (1997) 279-304. </booktitle>
Reference-contexts: Rectangular pulses are widely used in silicon implementations of networks of spiking neurons such as 3 described by Murray and Tarassenko [13]. Theoretical investigations concerning the computational power of networks of a neuron type that employs more complex functions as postsynaptic potentials can be found in Maass <ref> [5, 6, 7] </ref>. A spiking neuron may be viewed as a digital or analog computational element, depending on the type of temporal coding that is used. In the following we restrict our analysis to the coding of binary values.
Reference: [7] <author> W. Maass, </author> <title> Networks of spiking neurons: </title> <booktitle> The third generation of neural network models, Neural Networks 10 (1997) 1659-1671. </booktitle>
Reference-contexts: We investigate in this article a simple version of a spiking neuron, the so-called "spiking neuron of type A" according to the terminology of Maass <ref> [7] </ref>. Despite its simplicity, the model has sufficient qualities so that one can observe the impact that the use of time as a resource has on the computational capabilites of a single neuron. We focus on the computation of Boolean functions by a spiking neuron. <p> A Boolean function computable by a threshold gate is also called threshold function. In this article we focus on a simple model for a spiking neuron. This particular variant, the so-called "spiking neuron of type A", has been introduced by Maass <ref> [7] </ref>. For the sake of brevity we will refer to it as a spiking neuron henceforth throughout this paper. A spiking neuron v receives inputs in the form of short pulses, also known as spikes, from n input neurons a 1 ; : : : ; a n . <p> The neuron model that we consider here is a simple version of a leaky integrate-and-fire neuron. Further discussions of this and other neuron models can be found in the brief article of Softky and Koch [15] or in the surveys by Gerstner [2] and Maass <ref> [7, 8] </ref>. The latter also contain comprehensive lists of references to relevant literature from biophysics and neurobiology. The main simplification of our model is the embodiment of the postsynaptic potential as a rectangular pulse rather than a continuous function of a similar shape. <p> Rectangular pulses are widely used in silicon implementations of networks of spiking neurons such as 3 described by Murray and Tarassenko [13]. Theoretical investigations concerning the computational power of networks of a neuron type that employs more complex functions as postsynaptic potentials can be found in Maass <ref> [5, 6, 7] </ref>. A spiking neuron may be viewed as a digital or analog computational element, depending on the type of temporal coding that is used. In the following we restrict our analysis to the coding of binary values. <p> For a discussion of the biological relevance of such mechanisms see Maass and Schmitt [9, 10] and the references in there. When considering the computation of Boolean functions, it is not hard to see (and was already stated in <ref> [7] </ref>) that the type of a spiking neuron studied here is at least as powerful as a threshold gate. The latter can be simulated by using the same weights and assigning equal values to all delays. Moreover, in [7] a concrete Boolean function has been exhibited that can be computed by <p> functions, it is not hard to see (and was already stated in <ref> [7] </ref>) that the type of a spiking neuron studied here is at least as powerful as a threshold gate. The latter can be simulated by using the same weights and assigning equal values to all delays. Moreover, in [7] a concrete Boolean function has been exhibited that can be computed by a single spiking neuron, but requires at least n=(2 log ((n=2) + 1)) threshold gates when computed by a circuit. <p> By an explicit construction Maass <ref> [7] </ref> has shown that there is a Boolean function that can be computed by a spiking neuron, whereas any threshold circuit that computes this function has at least n=(2 log (n=2 + 1)) gates. <p> Consider the function x 1 x 2 _ x 3 x 4 _ _ x n1 x n which can be computed by a spiking neuron as follows <ref> [7] </ref>: Choose weights and threshold equal to 1 and adjust the delays such that d 2i1 = d 2i and d 2i + 1 &lt; d 2i+1 .
Reference: [8] <author> W. Maass, </author> <title> On the relevance of time in neural computation and learning, </title> <booktitle> in: Proceedings of the 8th International Workshop on Algorithmic Learning Theory ALT'97, </booktitle> <editor> eds. M. Li and A. Maruoka, </editor> <booktitle> Lecture Notes in Artificial Intelligence, </booktitle> <volume> vol. 1316, </volume> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1997, </year> <pages> pp. 364-384. </pages>
Reference-contexts: The neuron model that we consider here is a simple version of a leaky integrate-and-fire neuron. Further discussions of this and other neuron models can be found in the brief article of Softky and Koch [15] or in the surveys by Gerstner [2] and Maass <ref> [7, 8] </ref>. The latter also contain comprehensive lists of references to relevant literature from biophysics and neurobiology. The main simplification of our model is the embodiment of the postsynaptic potential as a rectangular pulse rather than a continuous function of a similar shape.
Reference: [9] <author> W. Maass and M. Schmitt, </author> <title> On the complexity of learning for a spiking neuron, </title> <booktitle> in: Proceedings of the Tenth Annual Conference on Computational Learning Theory COLT'97, </booktitle> <publisher> ACM Press, </publisher> <address> New York, </address> <year> 1997, </year> <pages> pp. 54-61. </pages>
Reference-contexts: Hence a learning algorithm may change the function computed by the spiking neuron not only by modifying its synaptic efficacies but also by tuning the transmission delays between neurons. For a discussion of the biological relevance of such mechanisms see Maass and Schmitt <ref> [9, 10] </ref> and the references in there. When considering the computation of Boolean functions, it is not hard to see (and was already stated in [7]) that the type of a spiking neuron studied here is at least as powerful as a threshold gate. <p> Moreover, in [7] a concrete Boolean function has been exhibited that can be computed by a single spiking neuron, but requires at least n=(2 log ((n=2) + 1)) threshold gates when computed by a circuit. Further results in <ref> [9] </ref> indicate that the expressive power of a spiking neuron with n variable delays is much higher than that of a threshold gate: When the weights are fixed and the delays are programmable, the VC-dimension of a spiking neuron is fi (n log n), whereas for a threshold gate with variable <p> gate: When the weights are fixed and the delays are programmable, the VC-dimension of a spiking neuron is fi (n log n), whereas for a threshold gate with variable weights it is fi (n). (The VC-dimension can be considered a measure for the variety of a class of functions; see <ref> [9] </ref> for details.) The significant increase of the VC-dimension from a threshold gate to a spiking neuron is somewhat remarkable since from a cardinality point of view, a spiking neuron seems only slightly more powerful than a threshold gate: It has been shown that a spiking neuron can compute at most <p> a threshold gate to a spiking neuron is somewhat remarkable since from a cardinality point of view, a spiking neuron seems only slightly more powerful than a threshold gate: It has been shown that a spiking neuron can compute at most 2 n 2 +O (n log n) Boolean functions <ref> [9] </ref>. <p> Zuev and Lipkin [18] proved that almost all Boolean functions have a threshold number that satisfies the bounds (2 n =n) and O ((ln n) 2 n =n). In <ref> [9] </ref> (see also [10]) Maass and Schmitt have shown that every Boolean function computable by a spiking neuron can be computed by a disjunction of at most 2n 1 threshold gates. This implies a threshold number of at most 2n 1 for the spiking neuron. <p> Hence the function has threshold number 2. On the other hand, restricting the function to inputs x 1 ; x 2 by fixing 0 to the remaining inputs we obtain the parity function. It is not hard to see (and was already stated in <ref> [9] </ref>) that the parity of two inputs cannot be computed by a spiking neuron.
Reference: [10] <author> W. Maass and M. Schmitt, </author> <title> On the complexity of learning for spiking neurons with temporal coding, </title> <booktitle> Electronic Colloquium on Computational Compexity, </booktitle> <address> ECCC TR97-049, </address> <year> 1997, </year> <note> available via WWW at URL http://www.eccc.uni-trier.de/eccc/. Also available at http://www.cis.tu-graz.ac.at/igi/mschmitt/. </note>
Reference-contexts: Hence a learning algorithm may change the function computed by the spiking neuron not only by modifying its synaptic efficacies but also by tuning the transmission delays between neurons. For a discussion of the biological relevance of such mechanisms see Maass and Schmitt <ref> [9, 10] </ref> and the references in there. When considering the computation of Boolean functions, it is not hard to see (and was already stated in [7]) that the type of a spiking neuron studied here is at least as powerful as a threshold gate. <p> Zuev and Lipkin [18] proved that almost all Boolean functions have a threshold number that satisfies the bounds (2 n =n) and O ((ln n) 2 n =n). In [9] (see also <ref> [10] </ref>) Maass and Schmitt have shown that every Boolean function computable by a spiking neuron can be computed by a disjunction of at most 2n 1 threshold gates. This implies a threshold number of at most 2n 1 for the spiking neuron.
Reference: [11] <author> M. L. Minsky and S. A. Papert, </author> <title> Perceptrons: An Introduction to Computational Geometry, expanded edition, </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1988. </year>
Reference-contexts: m i i and a threshold , such that X Sf1;:::;ng;0&lt;jSjm w S i2S We define the threshold order of a computational unit as the largest threshold order of any Boolean function the unit can compute. 8 The notion of a threshold order has been introduced by Minsky and Papert <ref> [11] </ref>. (They simply called it order.) In particular they showed that each Boolean function on n variables has threshold order at most n with the parity function being of order exactly n. <p> The weights can then be chosen as 1 and the threshold as 4k 2 . We show that the function has threshold order at least k using a result by Minsky and Papert <ref> [11] </ref> on the dual of f . (The dual f d of a Boolean function f is defined as f d (x 1 ; : : : ; x n ) = f (x 1 ; : : : ; x n ).) Due to Theorem 3.2 of Minsky and Papert <p> on the dual of f . (The dual f d of a Boolean function f is defined as f d (x 1 ; : : : ; x n ) = f (x 1 ; : : : ; x n ).) Due to Theorem 3.2 of Minsky and Papert <ref> [11] </ref>, f d has threshold order at least k. By Corollary 2.3 of Wang and Williams [16], the threshold order of a function is equal to the threshold order of its dual. Since k = (n=4) 1=3 , the statement of the theorem follows.
Reference: [12] <author> S. Muroga, </author> <title> Threshold Logic and Its Applications, </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1971. </year>
Reference-contexts: On the other hand it is known that a threshold gate can compute at least 2 n 2 (110= ln n) Boolean functions [17]. (This bound almost matches the upper bound 2 n 2 <ref> [12] </ref>.) It is therefore only the term O (n log n) in the upper bound of the cardinality that accounts for the higher VC-dimension of the spiking neuron. This demonstrates that a delay as a programmable parameter has a considerably larger impact on the computational power than a weight.
Reference: [13] <author> A. Murray and L. Tarassenko, </author> <title> Analogue Neural VLSI: A Pulse Stream Approach, </title> <publisher> Chapman & Hall, </publisher> <address> London, </address> <year> 1994 </year>
Reference-contexts: The main simplification of our model is the embodiment of the postsynaptic potential as a rectangular pulse rather than a continuous function of a similar shape. Rectangular pulses are widely used in silicon implementations of networks of spiking neurons such as 3 described by Murray and Tarassenko <ref> [13] </ref>. Theoretical investigations concerning the computational power of networks of a neuron type that employs more complex functions as postsynaptic potentials can be found in Maass [5, 6, 7].
Reference: [14] <author> F. Rieke, D. Warland, W. Bialek and R. de Ruyter van Steveninck, SPIKES: </author> <title> Exploring the Neural Code, </title> <publisher> The MIT-Press, </publisher> <address> Cambridge, Mass., </address> <year> 1996. </year> <month> 11 </month>
Reference-contexts: Neurophysiological experiments have rather lead to the conclusion that neural information processing also takes place in terms of temporal patterns of neural activity (see e.g. Rieke et al. <ref> [14] </ref>). fl Work supported in part by the ESPRIT Working Group NeuroCOLT No. 8556 1 Models of single neurons like the threshold or the sigmoidal gate are theoret-ically well investigated and widely used in applications.
Reference: [15] <author> W. Softky and C. Koch, </author> <title> Single-cell models, in: The Handbook of Brain Theory and Neural Networks, </title> <editor> ed. M. A. Arbib, </editor> <publisher> The MIT Press, </publisher> <address> Cambridge, Mass., </address> <year> 1995, </year> <pages> 879-884. </pages>
Reference-contexts: Therefore we treat the threshold as a constant throughout this article. The neuron model that we consider here is a simple version of a leaky integrate-and-fire neuron. Further discussions of this and other neuron models can be found in the brief article of Softky and Koch <ref> [15] </ref> or in the surveys by Gerstner [2] and Maass [7, 8]. The latter also contain comprehensive lists of references to relevant literature from biophysics and neurobiology. <p> A natural generalization of this notion is to allow for higher order terms in the weighted sum such that one arrives at polynomial surfaces as classifiers. Neuron models employing polynomials as activation functions are also known as sigma-pi units (see, e.g., Softky and Koch <ref> [15] </ref>). Such models are computationally more powerful than threshold gates even in the Boolean domain and even when the degree of the polynomial is bounded by some small constant as in the case of, for instance, quadratic surfaces.
Reference: [16] <author> C. Wang and A. C. Williams, </author> <title> The threshold order of a Boolean function, </title> <note> Discrete Applied Mathematics 31 (1991) 51-69. </note>
Reference-contexts: A proof that parity is the only function of threshold order n is due to Wang and Williams <ref> [16] </ref>. Obviously, a threshold gate has threshold order 1. We show that the threshold order of a spiking neuron is significantly larger. Theorem 7 The threshold order of a spiking neuron with n inputs is (n 1=3 ). Proof. Assume that n = 4k 3 for some k 1. <p> By Corollary 2.3 of Wang and Williams <ref> [16] </ref>, the threshold order of a function is equal to the threshold order of its dual. Since k = (n=4) 1=3 , the statement of the theorem follows. We have shown that the threshold order of a spiking neuron grows arbitrarily large with the number of inputs.
Reference: [17] <author> Yu. A. Zuev, </author> <title> Asymptotics of the logarithm of the number of threshold functions of the algebra of logic, </title> <note> Soviet Mathematics Doklady 39 (1989) 512-513. </note>
Reference-contexts: On the other hand it is known that a threshold gate can compute at least 2 n 2 (110= ln n) Boolean functions <ref> [17] </ref>. (This bound almost matches the upper bound 2 n 2 [12].) It is therefore only the term O (n log n) in the upper bound of the cardinality that accounts for the higher VC-dimension of the spiking neuron.
Reference: [18] <author> Yu. A. Zuev and L. I. Lipkin, </author> <title> Estimating the efficiency of threshold representations of Boolean functions, </title> <journal> Kibernetika (Kiev) no. </journal> <note> 6 (1988) 29-37. English translation in: Cybernetics 24 (1988) 713-723. 12 </note>
Reference-contexts: Every positive Boolean function is known to have a unique collection of prime implicants. Hammer et al. [3] show in particular that the threshold number of such a function is less than i bn=2c . Zuev and Lipkin <ref> [18] </ref> proved that almost all Boolean functions have a threshold number that satisfies the bounds (2 n =n) and O ((ln n) 2 n =n).
References-found: 18

