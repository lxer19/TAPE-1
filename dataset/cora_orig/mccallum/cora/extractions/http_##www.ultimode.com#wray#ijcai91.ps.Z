URL: http://www.ultimode.com/wray/ijcai91.ps.Z
Refering-URL: http://WWW.Ultimode.com/~wray/refs.html
Root-URL: 
Email: wray@ptolemy.arc.nasa.gov  
Phone: Phone: +1 (415) 604-3389  
Title: Classifiers: A Theoretical and Empirical Study  
Author: Wray Buntine 
Address: Moffet Field, CA 94035, USA  
Affiliation: RIACS Artificial Intelligence Research Branch NASA Ames Research Center, Mail Stop 244-17  
Abstract: This paper describes how a competitive tree learning algorithm can be derived from first principles. The algorithm approximates the Bayesian decision theoretic solution to the learning task. Comparative experiments with the algorithm and the several mature AI and statistical families of tree learning algorithms currently in use show the derived Bayesian algorithm is consistently as good or better, although sometimes at computational cost. Using the same strategy, we can design algorithms for many other supervised and model learning tasks given just a probabilistic representation for the kind of knowledge to be learned. As an illustration, a second learning algorithm is derived for learning Bayesian networks from data. Implications to incremental learning and the use of multiple models are also discussed.
Abstract-found: 1
Intro-found: 1
Reference: [ Berger, 1985 ] <author> J. O. Berger. </author> <title> Statistical Decision Theory and Bayesian Analysis. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: The justification for Bayesian decision theory comes from fundamental principles of how uncertain reasoning should be done <ref> [ Berger, 1985 ] </ref> . The theory applies widely in inference and plausible reasoning and its use is continually expanding in AI. But there is not a single "Bayesian learning algorithm," as some people mistakenly believe when they learn about Bayesian classifiers [ Tou and Gonzalez, 1974 ] . <p> They are quick to code in many cases and hence offer a viable alternative. Only Bayesian decision theory is able to claim that it is the most rational alternative in the information poor environment of learning from smaller samples <ref> [ Berger, 1985 ] </ref> . Minimum encoding approaches [ Rissanen, 1989 ] are sometimes touted as alternatives, however they are, mathematically, an interpretation of the Bayesian "most probable model" approach, which itself is an approximation to Bayesian decision theory [ Wallace and Freeman, 1987; Buntine, 1990c ] .
Reference: [ Breiman et al., 1984 ] <author> L. Breiman, J.H. Friedman, R.A. Olshen, and C.J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Belmont, </address> <year> 1984. </year>
Reference-contexts: Second, tree learning is a common meeting ground for the different areas of inquiry outside of AI that have learning theories of some form or another such as classical statistics <ref> [ Breiman et al., 1984 ] </ref> and minimum encoding approaches [ Rissanen, 1989 ] . This provides a rare opportunity to contrast these different learning theories theoretically as well as empirically. <p> The formulation is sufficiently general so that it could just as well be applied to other models such as probabilistic rules, Bayesian networks, or one of many other knowledge representations that have a probabilistic interpretation. Class probability trees have a vector of class probabilities at their leaves <ref> [ Breiman et al., 1984 ] </ref> , and they represent a conditional probability distribution of class value conditioned on example value. <p> That is, a few tree structures are generated in approximate proportion with their posterior (this is done using the tree growing heuristic [ Bun-tine, 1990a ] ), and their class probability vectors uni formly averaged. 3 Experimental Results Reimplementations of CART <ref> [ Breiman et al., 1984 ] </ref> , C4 [ Quinlan, 1988 ] , and a generic minimum encoding ap proach were compared with the Bayesian approaches 2 . The algorithms were applied to 12 different data sets with a range of characteristics. <p> The algorithms were applied to 12 different data sets with a range of characteristics. These included Quin-lan's hypothyroid and XD6 data [ Quinlan, 1988 ] , the CART digital LED problem <ref> [ Breiman et al., 1984 ] </ref> , three medical domains made available by Bratko's induction group [ Cestnik et al., 1987 ] , and a variety of other data sets from the Irvine Machine Learning Database such as "glass," "voting records," "hepatitis," and "mushrooms." Data sets were divided into training/test pairs, <p> Learning theoreticians are now using Bayesian methods [ Haussler et al., 1991 ] to analyse the smaller sample case, as suggested earlier by Buntine [ Buntine, 1989 ] . Statisticians overcome these overfitting problems with a variety of resampling techniques (as applied to trees, see <ref> [ Breiman et al., 1984; Crawford, 1989 ] </ref> ) that have good intuition and performance, but again only have asymptotic theory.
Reference: [ Buntine and Weigend, 1991 ] <author> W.L. </author> <title> Buntine and A.S. Weigend. Bayesian back-propagation. </title> <note> Submitted, </note> <year> 1991. </year>
Reference-contexts: The strategy has also been applied to analyse the training of feed-forward neural networks <ref> [ Buntine and Weigend, 1991 ] </ref> , where popular heuristic procedures for cost functions and network pruning were found to conform well to corresponding methods developed from Bayesian first principles. 2 The Algorithm Design Strategy The algorithm design strategy presented here is based on approximating Bayesian decision theory. <p> 2jl i + ff) estimates E jT;Sample n ijl + ff smoothing because the posterior is a product over the nodes in the tree structure, all conditional probability distributions along a branch can be averaged together using a linear-time recursive algorithm Table 1: Bayesian analysis of learning class probability trees <ref> [ Buntine and Weigend, 1991 ] </ref> for an approximation in the more complex domain of feed-forward neural networks. 4. Devise a heuristic search procedure for searching the space of structures to find structures with high posterior.
Reference: [ Buntine, 1989 ] <author> W.L. Buntine. </author> <title> A critique of the Valiant model. </title> <booktitle> In International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 837-842, </pages> <address> Detroit, 1989. </address> <publisher> Mor-gan Kaufmann. </publisher>
Reference-contexts: Some experimental comparisons are given in [ Buntine, 1990c ] . Learning theoreticians are now using Bayesian methods [ Haussler et al., 1991 ] to analyse the smaller sample case, as suggested earlier by Buntine <ref> [ Buntine, 1989 ] </ref> . Statisticians overcome these overfitting problems with a variety of resampling techniques (as applied to trees, see [ Breiman et al., 1984; Crawford, 1989 ] ) that have good intuition and performance, but again only have asymptotic theory.
Reference: [ Buntine, 1990a ] <author> W.L. Buntine. </author> <title> Learning classification trees. </title> <type> Technical Report FIA-90-12-19-01, </type> <institution> RIACS and NASA Ames Research Center, Moffett Field, </institution> <address> CA, </address> <year> 1990. </year> <booktitle> Paper presented at Third International Workshop on Artificial Intelligence and Statistics. </booktitle>
Reference-contexts: The development is presented as a generic algorithm design strategy in the second section, and the results discussed in the third section. More detail of the statistical aspects of the system can be found in <ref> [ Buntine, 1990a; Buntine, 1990c ] </ref> . Because of the large number of different trials and data sets that were used, full detail of the results are reported elsewhere [ Buntine, 1990c ] . <p> A reasonable alternative is one we currently have high subjective belief in. I will first explain how this applies to trees <ref> [ Buntine, 1990a ] </ref> , to introduce the notation. This is done for the two-class problem with discrete tests at nodes, but easily extends to the multi-class problem, and adjustments for real-valued tests at nodes exist [ Buntine, 1990c, Sec.6.5.5 ] . <p> Develop a prior over the structural and continuous components of the model. The form of the prior should be flexible enough so that it can be changed from application to application. In <ref> [ Buntine, 1990a ] </ref> , a range of priors are presented for trees. One is given in the table. The prior on the tree structures, P r (T ), is not given but could, for instance, be assumed uniform.
Reference: [ Buntine, 1990b ] <author> W.L. Buntine. </author> <title> Myths and legends in learning classification rules. </title> <booktitle> In Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 736-742, </pages> <address> Boston, Massachusetts, </address> <year> 1990. </year>
Reference: [ Buntine, 1990c ] <author> W.L. Buntine. </author> <title> A Theory of Learning Classification Rules. </title> <type> PhD thesis, </type> <institution> University of Technology, </institution> <address> Sydney, </address> <year> 1990. </year> <month> Forthcoming. </month>
Reference-contexts: The development is presented as a generic algorithm design strategy in the second section, and the results discussed in the third section. More detail of the statistical aspects of the system can be found in <ref> [ Buntine, 1990a; Buntine, 1990c ] </ref> . Because of the large number of different trials and data sets that were used, full detail of the results are reported elsewhere [ Buntine, 1990c ] . <p> More detail of the statistical aspects of the system can be found in [ Buntine, 1990a; Buntine, 1990c ] . Because of the large number of different trials and data sets that were used, full detail of the results are reported elsewhere <ref> [ Buntine, 1990c ] </ref> . <p> I will first explain how this applies to trees [ Buntine, 1990a ] , to introduce the notation. This is done for the two-class problem with discrete tests at nodes, but easily extends to the multi-class problem, and adjustments for real-valued tests at nodes exist <ref> [ Buntine, 1990c, Sec.6.5.5 ] </ref> . The formulation is sufficiently general so that it could just as well be applied to other models such as probabilistic rules, Bayesian networks, or one of many other knowledge representations that have a probabilistic interpretation. <p> These correspond to different ways of estimating the sum in Formula (1): Smoothing: The sum can be computed in closed form if it is restricted to the set of tree structures obtained by pruning a large tree structure in all possible ways. A linear time algorithm is given in <ref> [ Buntine, 1990c, Lemma 6.5.1 ] </ref> . This is called smoothing because it is equivalent to smoothing out the class probabilities at the leaf of a tree by averaging them with some class probabilities from interior nodes of the tree. <p> These techniques have no theoretical justification that they will provide good average-case performance on smaller samples. Some experimental comparisons are given in <ref> [ Buntine, 1990c ] </ref> . Learning theoreticians are now using Bayesian methods [ Haussler et al., 1991 ] to analyse the smaller sample case, as suggested earlier by Buntine [ Buntine, 1989 ] . <p> Minimum encoding approaches [ Rissanen, 1989 ] are sometimes touted as alternatives, however they are, mathematically, an interpretation of the Bayesian "most probable model" approach, which itself is an approximation to Bayesian decision theory <ref> [ Wallace and Freeman, 1987; Buntine, 1990c ] </ref> . Experiments support this approximation view, and also indicate the minimum encoding approximation can degrade significantly as the sample size decreases. This happens because the encoding methods do not consider multiple models, as suggested here. <p> In Bayesian theory, priors are viewed as assumptions that are essential when making inference from limited information such as a small training sample. Uniform convergence theory constrains samples so they are large enough to make the effect of the prior assumptions negligible <ref> [ Buntine, 1990c, Lemma 4.2.1 ] </ref> . According to Bayesian theory, methods applied to smaller samples have implicitly built in particular assumptions which correspond to a choice of prior. Breiman et al.'s cost complexity pruning with cross validation and the 0 SE rule, for instance, favors smaller trees.
Reference: [ Cestnik et al., 1987 ] <author> B. Cestnik, I. Kononenko, and I. Bratko. Assistant86: </author> <title> A knowledge-elicitation tool for sophisticated users. </title> <editor> In I. Bratko and N. Lavrac, editors, </editor> <booktitle> Progress in Machine Learning: Proceedings of EWSL-87, </booktitle> <pages> pages 31-45, </pages> <address> Bled, Yugoslavia, </address> <year> 1987. </year> <note> Sigma Press. </note> [ <author> Cheeseman et al., 1988 ] P. Cheeseman, M. Self, J. Kelly, W. Taylor, D. Freeman, and J. Stutz. </author> <title> Bayesian classification. </title> <booktitle> In Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 607-611, </pages> <address> Saint Paul, Minnesota, </address> <year> 1988. </year>
Reference-contexts: 1 Introduction Systems for learning classification trees <ref> [ Quinlan, 1986; Cestnik et al., 1987 ] </ref> are common in machine learning, statistics and pattern recognition. <p> To prevent overflow/underflow, this measure has to be calculated in log-space. The measure behaves similarly to Quin-lan's information gain heuristic, but has some correction terms for multivalued attributes and small samples. This heuristic can also be used as a stopping rule <ref> [ Cestnik et al., 1987 ] </ref> . 5. Given a training sample Sample and a structure T , determine a formula or approximation for the posterior expected values of the parameters , as required for Formula (1). 6. <p> The algorithms were applied to 12 different data sets with a range of characteristics. These included Quin-lan's hypothyroid and XD6 data [ Quinlan, 1988 ] , the CART digital LED problem [ Breiman et al., 1984 ] , three medical domains made available by Bratko's induction group <ref> [ Cestnik et al., 1987 ] </ref> , and a variety of other data sets from the Irvine Machine Learning Database such as "glass," "voting records," "hepatitis," and "mushrooms." Data sets were divided into training/test pairs, a classifier was built on the training sample and the accuracy, predicted accuracy, and mean square
Reference: [ Cooper and Herskovits, 1991 ] <author> G. Cooper and E. Her-skovits. </author> <title> A Bayesian method for the induction of probabilistic networks from data. </title> <type> Technical Report KSL-91-02, </type> <institution> Knowledge Systems Laboratory, Medical Computer Science, Stanford University, </institution> <year> 1991. </year>

Reference: [ Gams, 1989 ] <author> M. </author> <title> Gams. New measurements highlight the importance of redundant knowledge. </title> <editor> In K. Morik, editor, </editor> <booktitle> Proceedings of the Fourth European Working Session on Learning, </booktitle> <pages> pages 71-80, </pages> <address> Montpellier, 1989. </address> <publisher> Pitman Publishing. </publisher>
Reference-contexts: Kwok and Carter used a heuristic approximation to Bayesian decision theory [ Kwok and Carter, 1990 ] ; they built multiple decision trees and when processing a new example, processed it with each tree individually and averaged the multiple class predictions. Gams discussed the notion of "redundant knowledge" <ref> [ Gams, 1989 ] </ref> , where he weighs up the predictions of several overlapping rules when classifying a new example. Jacobs et al. present another approach that does adaptive mixing of multiple feed-forward networks [ Jacobs et al., 1991 ] .
Reference: [ Geiger et al., 1990 ] <author> D. Geiger, A. Paz, and J. Pearl. </author> <title> Learning causal trees from dependence information. </title> <booktitle> In Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 770-771, </pages> <address> Boston, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: A similar method has been independently developed and implemented by Herskovits and Cooper and they report good experimental results [ Cooper and Her-skovits, 1991 ] . The different approach of Geiger et al. is concerned with learning networks from known depen dency information <ref> [ Geiger et al., 1990 ] </ref> (for instance, as extracted from a large sample) so is not relevant to the problem of learning from a smaller sample when dependency information is uncertain. Bayesian networks in their simplest formulation specify dependence properties between variables by using a directed acyclic graph.
Reference: [ Gennari et al., 1990 ] <author> J.H. Gennari, P. Langley, and D. Fisher. </author> <title> Models of incremental concept formation. </title> <journal> Artificial Intelligence, </journal> <year> 1990. </year>
Reference-contexts: This has the advantage that the long sequence of theoretical and empirical work that led to the development of the algorithm is not wasted. Some algorithms, however, are designed to be incremental from the beginning <ref> [ Gennari et al., 1990 ] </ref> . These algorithms can suffer from order-sensitivity [ Lan-gley and McKusick, 1990 ] , which is an incremental manifestation of the overfitting problem, a problem which is largely solved for batch algorithms.
Reference: [ Haussler et al., 1991 ] <author> D. Haussler, M. Kearns, and R.E. Schapire. </author> <title> Unifying bounds on the sample complexity of Bayesian learning using information theory and the VC dimension. </title> <booktitle> In COLT'91: 1991 Workshop on Com putational Learning Theory. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year> <note> To appear. </note>
Reference-contexts: Jacobs et al. present another approach that does adaptive mixing of multiple feed-forward networks [ Jacobs et al., 1991 ] . A survey of some related theoretical work in "aggregrating learning strategies" and "weighted majority" is given in <ref> [ Haussler et al., 1991 ] </ref> . Suggested modifications to learning algorithms rarely perform consistently better (see for instance [ Mingers, 1989 ] ). <p> These techniques have no theoretical justification that they will provide good average-case performance on smaller samples. Some experimental comparisons are given in [ Buntine, 1990c ] . Learning theoreticians are now using Bayesian methods <ref> [ Haussler et al., 1991 ] </ref> to analyse the smaller sample case, as suggested earlier by Buntine [ Buntine, 1989 ] .
Reference: [ Jacobs et al., 1991 ] <author> R.A. Jacobs, M.I. Jordan, S.J. Nowlan, and G.E. Hinton. </author> <title> Adaptive mixtures of local experts. </title> <journal> Neural Computation, </journal> <volume> 3(1), </volume> <year> 1991. </year>
Reference-contexts: Gams discussed the notion of "redundant knowledge" [ Gams, 1989 ] , where he weighs up the predictions of several overlapping rules when classifying a new example. Jacobs et al. present another approach that does adaptive mixing of multiple feed-forward networks <ref> [ Jacobs et al., 1991 ] </ref> . A survey of some related theoretical work in "aggregrating learning strategies" and "weighted majority" is given in [ Haussler et al., 1991 ] . Suggested modifications to learning algorithms rarely perform consistently better (see for instance [ Mingers, 1989 ] ).
Reference: [ Kwok and Carter, 1990 ] <author> S.K. Kwok and C. Carter. </author> <title> Multiple decision trees. </title> <editor> In R.D. Schacter, T.D. Levitt, L.N. Kanal, and J.F. Lemmer, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 4. </booktitle> <publisher> North-Holland, </publisher> <year> 1990. </year> [ <note> Langley and McKusick, 1990 ] P. </note> <author> Langley and K. McKusick. </author> <type> Personal communication, </type> <year> 1990. </year>
Reference-contexts: This is an approximate method for doing the averaging presented in Section 2, and is different from the technique of combining independent sources of knowledge multiplicatively, using the probability formula for independence (the basis of "idiot" Bayes classifiers). Kwok and Carter used a heuristic approximation to Bayesian decision theory <ref> [ Kwok and Carter, 1990 ] </ref> ; they built multiple decision trees and when processing a new example, processed it with each tree individually and averaged the multiple class predictions.
Reference: [ Lauritzen and Spiegelhalter, 1988 ] <author> S.L. Lauritzen and D.J. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> J. Roy. Statist. Soc. B, </journal> <volume> 50(2) </volume> <pages> 240-265, </pages> <year> 1988. </year>
Reference-contexts: These are discussed in the fourth section. We can now design algorithms for many other supervised and model learning tasks given just a probabilistic representation for the kind of knowledge to be learned. As an illustration, a method is outlined in the fifth section for learning Bayesian networks <ref> [ Lauritzen and Spiegelhalter, 1988 ] </ref> , a common representation in medical expert systems. This is a model learning task.
Reference: [ Mingers, 1989 ] <author> J. Mingers. </author> <title> An empirical comparison of pruning methods for decision-tree induction. </title> <journal> Machine Learning, </journal> <volume> 4(2) </volume> <pages> 227-243, </pages> <year> 1989. </year>
Reference-contexts: Joint Conf. on AI, Sydney, 1991. y Research Institute for Advanced Computer Science 1 Except, perhaps, in the area of learning strictly logical rules where recent techniques learn new terms; but the focus of this paper is primarily learning noisy or uncertain con cepts, where gains have been more incremental. <ref> [ Mingers, 1989 ] </ref> . The systems have stood the test of time and are now widely used for benchmarking and comparative studies. If an algorithm design strategy yields a superior tree learning algorithm despite this tough competition, it is likely the strategy will be successful on other learning tasks. <p> A survey of some related theoretical work in "aggregrating learning strategies" and "weighted majority" is given in [ Haussler et al., 1991 ] . Suggested modifications to learning algorithms rarely perform consistently better (see for instance <ref> [ Mingers, 1989 ] </ref> ).
Reference: [ Quinlan and Rivest, 1989 ] <author> J.R. Quinlan and R.L. Rivest. </author> <title> Inferring decision trees using the min imum description length principle. </title> <journal> Information and Computation, </journal> <volume> 80 </volume> <pages> 227-248, </pages> <year> 1989. </year>
Reference-contexts: According to Bayesian theory, methods applied to smaller samples have implicitly built in particular assumptions which correspond to a choice of prior. Breiman et al.'s cost complexity pruning with cross validation and the 0 SE rule, for instance, favors smaller trees. And the various minimum encoding approaches <ref> [ Rissanen, 1989; Quinlan and Rivest, 1989 ] </ref> have a very strong preference towards smaller trees.
Reference: [ Quinlan, 1986 ] <author> J.R. Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: 1 Introduction Systems for learning classification trees <ref> [ Quinlan, 1986; Cestnik et al., 1987 ] </ref> are common in machine learning, statistics and pattern recognition. <p> Devise a heuristic search procedure for searching the space of structures to find structures with high posterior. A simple one-ply lookahead procedure can be tried, which corresponds to the standard tree growing algorithm <ref> [ Quinlan, 1986 ] </ref> , although two-ply or three-ply versions could also be tried. Start with the trivial structure, the empty tree.
Reference: [ Quinlan, 1988 ] <author> J.R. Quinlan. </author> <title> Simplifying decision trees. </title> <editor> In B. Gaines and J. Boose, editors, </editor> <booktitle> Knowl edge Acquisition for Knowledge-Based Systems, </booktitle> <pages> pages 239-252. </pages> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1988. </year>
Reference-contexts: That is, a few tree structures are generated in approximate proportion with their posterior (this is done using the tree growing heuristic [ Bun-tine, 1990a ] ), and their class probability vectors uni formly averaged. 3 Experimental Results Reimplementations of CART [ Breiman et al., 1984 ] , C4 <ref> [ Quinlan, 1988 ] </ref> , and a generic minimum encoding ap proach were compared with the Bayesian approaches 2 . The algorithms were applied to 12 different data sets with a range of characteristics. These included Quin-lan's hypothyroid and XD6 data [ Quinlan, 1988 ] , the CART digital LED problem <p> CART [ Breiman et al., 1984 ] , C4 <ref> [ Quinlan, 1988 ] </ref> , and a generic minimum encoding ap proach were compared with the Bayesian approaches 2 . The algorithms were applied to 12 different data sets with a range of characteristics. These included Quin-lan's hypothyroid and XD6 data [ Quinlan, 1988 ] , the CART digital LED problem [ Breiman et al., 1984 ] , three medical domains made available by Bratko's induction group [ Cestnik et al., 1987 ] , and a variety of other data sets from the Irvine Machine Learning Database such as "glass," "voting records,"
Reference: [ Rissanen, 1989 ] <author> J. Rissanen. </author> <title> Stochastic Complexity in Statistical Enquiry. </title> <publisher> World Scientific, </publisher> <year> 1989. </year>
Reference-contexts: Second, tree learning is a common meeting ground for the different areas of inquiry outside of AI that have learning theories of some form or another such as classical statistics [ Breiman et al., 1984 ] and minimum encoding approaches <ref> [ Rissanen, 1989 ] </ref> . This provides a rare opportunity to contrast these different learning theories theoretically as well as empirically. <p> Devise a procedure for approximating the summation of Formula (1) by a small set of high posterior structures. Several suggestions are given below. This is currently an active area of research. Minimum encoding approaches <ref> [ Rissanen, 1989; Wal-lace and Freeman, 1987 ] </ref> to supervised learning and the so-called "most probable model" (Bayesian) approach are first-order approximations to Formula (1), because they attempt to find a single high posterior structure. <p> They are quick to code in many cases and hence offer a viable alternative. Only Bayesian decision theory is able to claim that it is the most rational alternative in the information poor environment of learning from smaller samples [ Berger, 1985 ] . Minimum encoding approaches <ref> [ Rissanen, 1989 ] </ref> are sometimes touted as alternatives, however they are, mathematically, an interpretation of the Bayesian "most probable model" approach, which itself is an approximation to Bayesian decision theory [ Wallace and Freeman, 1987; Buntine, 1990c ] . <p> According to Bayesian theory, methods applied to smaller samples have implicitly built in particular assumptions which correspond to a choice of prior. Breiman et al.'s cost complexity pruning with cross validation and the 0 SE rule, for instance, favors smaller trees. And the various minimum encoding approaches <ref> [ Rissanen, 1989; Quinlan and Rivest, 1989 ] </ref> have a very strong preference towards smaller trees.
Reference: [ Schlimmer and Granger Jr., 1986 ] <author> J.C. Schlimmer and R.H. Granger Jr. </author> <title> Incremental learning from noisy data. </title> <journal> Machine Learning, </journal> <volume> 1(3) </volume> <pages> 317-354, </pages> <year> 1986. </year>
Reference-contexts: Finally, classification trees have been the framework in which a number of discoveries have been made in machine learning: the overfitting problem (related to the accuracy-complexity tradeoff and Ockham's razor), incremental algorithms <ref> [ Schlimmer and Granger Jr., 1986 ] </ref> , and interactive induction [ Shapiro, 1987 ] . The learning problem tree systems tackle is difficult enough to be considered "unlearnable," yet simple enough so not requiring the specialized machinery to learn relations or do constructive induction. <p> But because of their iterative nature, they can be easily modified to form incremental versions. For instance, one could add the new training data to the next iteration. Some batch algorithms do not lend themselves naturally to incremental versions. In these cases, as done with trees <ref> [ Schlimmer and Granger Jr., 1986 ] </ref> , the batch learning algorithm is differentiated.
Reference: [ Shapiro, 1987 ] <author> A. Shapiro. </author> <title> Structured Induction in Expert Systems. </title> <publisher> Addison Wesley, </publisher> <address> London, </address> <year> 1987. </year>
Reference-contexts: Finally, classification trees have been the framework in which a number of discoveries have been made in machine learning: the overfitting problem (related to the accuracy-complexity tradeoff and Ockham's razor), incremental algorithms [ Schlimmer and Granger Jr., 1986 ] , and interactive induction <ref> [ Shapiro, 1987 ] </ref> . The learning problem tree systems tackle is difficult enough to be considered "unlearnable," yet simple enough so not requiring the specialized machinery to learn relations or do constructive induction.
Reference: [ Tou and Gonzalez, 1974 ] <author> J.T. Tou and R.C. Gonza lez. </author> <title> Pattern Recognition Principles. </title> <publisher> Addison-Wesley, </publisher> <address> USA, </address> <year> 1974. </year>
Reference-contexts: The theory applies widely in inference and plausible reasoning and its use is continually expanding in AI. But there is not a single "Bayesian learning algorithm," as some people mistakenly believe when they learn about Bayesian classifiers <ref> [ Tou and Gonzalez, 1974 ] </ref> . Rather, Bayesian decision theory presents computational guidelines on how learning should be done for many different learning problems, including for instance, improving an approximate theory using data.
Reference: [ Vapnik, 1982 ] <author> V. Vapnik. </author> <title> Estimation of Dependencies Based on Empirical Data. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: If a sample size is large enough, uniform convergence theory provides bounds on the predictive performance of classifiers learned by minimizing empirical error <ref> [ Vapnik, 1982 ] </ref> . In practice when sample sizes are not large enough, one needs to make a tradeoff between the complexity of the hypothesis chosen and the accuracy of the fit to the data. <p> Here, uniform convergence methods give less guide, only asymptotic (i.e. large sample) theory regarding their performance (see, for instance, the principle of structural risk minimization in <ref> [ Vapnik, 1982 ] </ref> ). These techniques have no theoretical justification that they will provide good average-case performance on smaller samples. Some experimental comparisons are given in [ Buntine, 1990c ] .
Reference: [ Wallace and Freeman, 1987 ] <author> C.S. Wallace and P.R. Freeman. </author> <title> Estimation and inference by compact encoding. </title> <journal> J. Roy. Statist. Soc. B, </journal> <volume> 49(3) </volume> <pages> 240-265, </pages> <year> 1987. </year>
Reference-contexts: Minimum encoding approaches [ Rissanen, 1989 ] are sometimes touted as alternatives, however they are, mathematically, an interpretation of the Bayesian "most probable model" approach, which itself is an approximation to Bayesian decision theory <ref> [ Wallace and Freeman, 1987; Buntine, 1990c ] </ref> . Experiments support this approximation view, and also indicate the minimum encoding approximation can degrade significantly as the sample size decreases. This happens because the encoding methods do not consider multiple models, as suggested here.
References-found: 26

