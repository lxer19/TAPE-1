URL: ftp://ftp.eng.auburn.edu/pub/techreports/cse/93/TR-93-07.ps.Z
Refering-URL: ftp://ftp.eng.auburn.edu/pub/techreports/README.html
Root-URL: 
Email: mccreary@eng.auburn.edu  
Title: A Comparison of Heuristics for Scheduling DAGs on Multiprocessors  
Author: C.L. McCreary, A.A. Khan, J. Thompson, M.E. McArdle, 
Address: AL 36849  
Affiliation: Department of Computer Science and Engineering Auburn University,  
Abstract: Many algorithms to schedule DAGs on multiprocessors have been proposed, but there has been little work done to determine their effectiveness. Since multi-processor scheduling is an NP-hard problem, no exact tractable algorithm exists, and no baseline is available from which to compare the resulting schedules. This paper is an attempt to quantify the differences in a few of the heuristics. The empiracle performance of five heuristics is compared when they are applied to ten specific DAGs which represent program dependence graphs of important applications. The comparison is made between a graph based method, a list scheduling technique and three critical path mathods. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Anger, F.D.. Hwang, J.J., and Chow,Y.C. </author> <title> Scheduling with Sufficient Loosely Coupled Processors. </title> <journal> Journal of Parallel and Distributed Comput., </journal> <volume> 9, </volume> <year> 1990, </year> <pages> pp. 87-92. </pages>
Reference-contexts: A taxonomy of these techniques as well as a comparison of four specific heuristics can be found in the work of Gerasoulis and Yang [4]. In this paper we include experimental results from three critical path algorithms, DSC, Linear Clustering and MCP. List scheduling heuristics <ref> [1, 10, 12, 13, 14, 18, 20] </ref>: These algorithms assign priorities to the processes and schedule them according to a list priority scheme. For example, a high priority might be given to a task with many heavily weighted incident edges or to a task whose neighbors have already been scheduled. <p> This simplified model allows schedulers to concentrate on the essential problem of task scheduling. 4 (3) Duplication of the execution of tasks in separate grains is not allowed. Several heuristics <ref> [12, 1, 20] </ref> have been developed that take advantage of this option, and these algorithms deserve further analysis. However, it is beyond the scope of this paper to consider them. (4) Tasks communicate only before starting and after completing their execution.
Reference: 2. <author> Baxter, J. and Patel, J.H., </author> <title> The LAST Algorithm: A Heuristic-Based Static Task Allocation Algorithm. </title> <booktitle> Proceedings of the 1989 Int. Conference on Parallel Processing, </booktitle> <volume> Vol. 2, </volume> <year> 1989, </year> <pages> pp. 217-222. </pages>
Reference: 3. <author> Coffman E.G., Jr., (Ed.) </author> <title> Computer and Job-Shop Scheduling Thoery. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1976. </year>
Reference-contexts: Since neither analytic nor absolute results are known, the goal of this paper is to determine the relative performance of some promising techniques. The techniques are applied to graphical representations of some real programs. In classical scheduling, communication costs are not considered <ref> [3, 7] </ref>. Introducing the communication cost is necessary because communication between processors does take time in real parallel systems, especially in distributed memory systems where communication costs tend to be high relative to processor speed.
Reference: 4. <author> Gerasoulis, A. and Yang, T. </author> <title> A Comparison of Clustering Heuristics for Scheduling DAGs on Multiprocessors, </title> <journal> Journal or Parallel and Distributed Computing, </journal> <month> Dec. </month> <year> 1992, </year> <pages> 16, pp. 276-2 </pages>
Reference-contexts: The challenge in the extended scheduling problem is to consider the tradeoff between communication time and degree of parallelism [17]. 2 Many researchers have studied the problem and proposed solutions. This paper considers algorithms from three caregories: critical path heuristics, list scheduling heuristics and graph analysis. Critical path heuristics <ref> [4, 5, 11, 21, 23, 24] </ref>: For DAGs with edge weights and node weights, a path weight is defined to be the sum of the weights of both nodes and edges on the path. <p> Paths are shortened by removing communication requirements (zeroing edges) and combining the adjacent tasks into a grain. This approach has received the most attention. A taxonomy of these techniques as well as a comparison of four specific heuristics can be found in the work of Gerasoulis and Yang <ref> [4] </ref>. In this paper we include experimental results from three critical path algorithms, DSC, Linear Clustering and MCP. List scheduling heuristics [1, 10, 12, 13, 14, 18, 20]: These algorithms assign priorities to the processes and schedule them according to a list priority scheme. <p> On Figure 2, LC generates the same the clustering as DSC. The computational complexity of LC is O (v (e+v)). 3.1.2 Dominant Sequence Clustering (DSC) DSC by Yang and Gerasoulis <ref> [4] </ref> is also an edge zeroing algorithm. The two major ideas behind DSC are to directly attempt to reduce the Dominant Sequence of the graph, and to create an algorithm with low computational complexity, This algorithm keeps track of the dominant sequence 6 The Algorithm (LC): Phase I: clustering 1.
Reference: 5. <author> Gerasoulis,A., Venugopal, S., and Yang,T. </author> <title> Clustering Task Graphs for Message Passing Architectures. </title> <booktitle> Proc. of ACM Int'l conf. on Supercomputing, </booktitle> <year> 1990, </year> <pages> pp. 447-456. </pages>
Reference-contexts: The challenge in the extended scheduling problem is to consider the tradeoff between communication time and degree of parallelism [17]. 2 Many researchers have studied the problem and proposed solutions. This paper considers algorithms from three caregories: critical path heuristics, list scheduling heuristics and graph analysis. Critical path heuristics <ref> [4, 5, 11, 21, 23, 24] </ref>: For DAGs with edge weights and node weights, a path weight is defined to be the sum of the weights of both nodes and edges on the path.
Reference: 6. <author> Graham, </author> <title> R.L. Bounds on Multiprocessing timing Anomalies. </title> <journal> SIAM J. Appl. Math., </journal> <volume> 26 Vol. 17, No. 2, </volume> <month> Mar. </month> <year> 1969, </year> <pages> pp. 416-429. </pages>
Reference-contexts: For example, a high priority might be given to a task with many heavily weighted incident edges or to a task whose neighbors have already been scheduled. Extending the list scheduling heuristic in classical scheduling <ref> [6] </ref>, these algorithms use greedy heuristics and schedule tasks in a certain order. Task duplications have been used in [12,1, 20] to reduce the communication costs. One list scheduling method, the LAST algorithm, is included in this comparison study.
Reference: 7. <author> Graham, R.L., Lawer, E.L., Lenstra, J.K. , and Rinnooy Kan, A.H.G. </author> <title> Optimization and Approximation in Deterministric Sequencing and Scheduling: A Survey. </title> <journal> Ann. Discrete Math., </journal> <volume> 5, </volume> <year> 1979, </year> <pages> pp. 287-326. </pages>
Reference-contexts: Since neither analytic nor absolute results are known, the goal of this paper is to determine the relative performance of some promising techniques. The techniques are applied to graphical representations of some real programs. In classical scheduling, communication costs are not considered <ref> [3, 7] </ref>. Introducing the communication cost is necessary because communication between processors does take time in real parallel systems, especially in distributed memory systems where communication costs tend to be high relative to processor speed.
Reference: 8. <author> Horowitz E.,and Sahni, S. </author> <title> Fundamentals of Computer Algorithms. </title> <publisher> Computer Science Press, </publisher> <address> Rockville, MD, </address> <year> 1984. </year>
Reference: 9. <author> Hu, </author> <title> T.C. Parallel Sequencing and Assembly Line Problems. </title> <journal> Oper. Res., </journal> <volume> Vol. 9, No. 6, </volume> <year> 1961, </year> <pages> pp. 841-848. </pages>
Reference-contexts: A critical path is a path of greatest weight from a source node to a sink node. Extending the critical path method due to Hu <ref> [9] </ref> in classical scheduling, these algorithms try to shorten the longest execution path in the DAG. Paths are shortened by removing communication requirements (zeroing edges) and combining the adjacent tasks into a grain. This approach has received the most attention.
Reference: 10. <author> Hwang, J.J., Chow, Y.C. , Anger, F.D., and Lee, </author> <title> B.Y. Scheduling Precedence Graphs in Systems with Interprocessor Communication Times. </title> <journal> SIAM J. Comput., </journal> <volume> Vol. 18, No. 2, </volume> <month> Apr. </month> <year> 1989, </year> <pages> pp. 244-257. </pages>
Reference-contexts: A taxonomy of these techniques as well as a comparison of four specific heuristics can be found in the work of Gerasoulis and Yang [4]. In this paper we include experimental results from three critical path algorithms, DSC, Linear Clustering and MCP. List scheduling heuristics <ref> [1, 10, 12, 13, 14, 18, 20] </ref>: These algorithms assign priorities to the processes and schedule them according to a list priority scheme. For example, a high priority might be given to a task with many heavily weighted incident edges or to a task whose neighbors have already been scheduled.
Reference: 11. <author> Kim, S.J. and Browne, </author> <title> J.C. A General Approach to Mapping of Parallel Computation upon Multiprocessor Architectures. </title> <booktitle> Proc. of Int'l Conf. on Parallel Processing, </booktitle> <volume> Vol. III, </volume> <year> 1988, </year> <pages> pp. 1-8. </pages>
Reference-contexts: A good assignment will shorten the execution time of the program. The partitioning and assignment is called the scheduling problem. The problem is also known as grain size determination [12], the clustering problem <ref> [11, 24] </ref>, and internalization pre-pass [21]. The problem is important because solution methods can be used to generate efficient parallel programs. The partitioning/scheduling problem is intractable, and heuristics are required to find sub-optimal solutions. In addition, there are no known performance guarantees for scheduling heuristics for general graphs. <p> The challenge in the extended scheduling problem is to consider the tradeoff between communication time and degree of parallelism [17]. 2 Many researchers have studied the problem and proposed solutions. This paper considers algorithms from three caregories: critical path heuristics, list scheduling heuristics and graph analysis. Critical path heuristics <ref> [4, 5, 11, 21, 23, 24] </ref>: For DAGs with edge weights and node weights, a path weight is defined to be the sum of the weights of both nodes and edges on the path. <p> FFT5 again has computation and communication values based on hypercube estimates, but contains 16 input and output vertices and assumes twice as much computation per node. NEQ <ref> [11] </ref> is based on Gaussian elimination algorithm for solving four equations in four 17 variables. The graph was chosen for its slightly irregular layout. The edges range in value from 55 to 116 as shown in Figure 11 and the vertex values range from 1 to 361. <p> The graph was chosen for its slightly irregular layout. The edges range in value from 55 to 116 as shown in Figure 11 and the vertex values range from 1 to 361. IRR is an adaptation of a PDG of a physics algorithm <ref> [11] </ref>, and was chosen because of the highly irregular layout. Each of the edges has weight 50. 5. Results & Analysis The comparative analysis will be divided over three graph sets: trees, FFTs and irregular graphs.
Reference: 12. <author> Kruatrachue, B. and Lewis, T. </author> <title> Grain Size Determination for Parallel Processing. </title> <journal> IEEE Softw., </journal> <month> Jan. </month> <year> 1988, </year> <pages> pp. 23-32. </pages>
Reference-contexts: Given a PDG, the graph is partitioned into appropriately sized grains which are assigned to processors of a parallel machine. A good assignment will shorten the execution time of the program. The partitioning and assignment is called the scheduling problem. The problem is also known as grain size determination <ref> [12] </ref>, the clustering problem [11, 24], and internalization pre-pass [21]. The problem is important because solution methods can be used to generate efficient parallel programs. The partitioning/scheduling problem is intractable, and heuristics are required to find sub-optimal solutions. <p> A taxonomy of these techniques as well as a comparison of four specific heuristics can be found in the work of Gerasoulis and Yang [4]. In this paper we include experimental results from three critical path algorithms, DSC, Linear Clustering and MCP. List scheduling heuristics <ref> [1, 10, 12, 13, 14, 18, 20] </ref>: These algorithms assign priorities to the processes and schedule them according to a list priority scheme. For example, a high priority might be given to a task with many heavily weighted incident edges or to a task whose neighbors have already been scheduled. <p> This simplified model allows schedulers to concentrate on the essential problem of task scheduling. 4 (3) Duplication of the execution of tasks in separate grains is not allowed. Several heuristics <ref> [12, 1, 20] </ref> have been developed that take advantage of this option, and these algorithms deserve further analysis. However, it is beyond the scope of this paper to consider them. (4) Tasks communicate only before starting and after completing their execution.
Reference: 13. <author> Lee,C.Y. , Hwang, J.J., Chow, Y.C. , and Anger, </author> <title> F.D. Multiprocessor Scheduling with Interporcessor Communication Delays. </title> <journal> Oper. Res. Lett., </journal> <volume> 7, 3, </volume> <year> 1988, </year> <pages> pp. 141-147. </pages>
Reference-contexts: A taxonomy of these techniques as well as a comparison of four specific heuristics can be found in the work of Gerasoulis and Yang [4]. In this paper we include experimental results from three critical path algorithms, DSC, Linear Clustering and MCP. List scheduling heuristics <ref> [1, 10, 12, 13, 14, 18, 20] </ref>: These algorithms assign priorities to the processes and schedule them according to a list priority scheme. For example, a high priority might be given to a task with many heavily weighted incident edges or to a task whose neighbors have already been scheduled.
Reference: 14. <author> Liu, Z. </author> <title> A Note on Graham's Bound. </title> <journal> Inform. Processing Lett., </journal> <volume> 36, </volume> <month> Oct. </month> <year> 1990, </year> <pages> pp. 1-5. </pages>
Reference-contexts: A taxonomy of these techniques as well as a comparison of four specific heuristics can be found in the work of Gerasoulis and Yang [4]. In this paper we include experimental results from three critical path algorithms, DSC, Linear Clustering and MCP. List scheduling heuristics <ref> [1, 10, 12, 13, 14, 18, 20] </ref>: These algorithms assign priorities to the processes and schedule them according to a list priority scheme. For example, a high priority might be given to a task with many heavily weighted incident edges or to a task whose neighbors have already been scheduled.
Reference: 15. <author> McCreary, C. and Gill, H. </author> <title> Automatic Determination of Grain Size for Efficient Parallel Processing. </title> <journal> Comm. of ACM, </journal> <volume> Vol. 32, No. 9, </volume> <month> Sept. </month> <year> 1989, </year> <pages> pp. 1073-1078. </pages>
Reference-contexts: Task duplications have been used in [12,1, 20] to reduce the communication costs. One list scheduling method, the LAST algorithm, is included in this comparison study. Graph decomposition method <ref> [15, 16] </ref>: Based on graph decomposition theory, the method parses a graph into a hierarchy (tree) of subgraphs. Communication and execution costs are applied to the tree to determine the grain size that results in the most efficient schedule.
Reference: 16. <author> McCreary, C., Thompson, J., Gill, H., Smith, T., Zhu, Y., </author> <title> Partitioning and Scheduling Using Graph Decomposition. </title> <institution> Auburn University Tech. Rpt., Dept. of Computer Science and Engineering, CSE-93-06. </institution>
Reference-contexts: Task duplications have been used in [12,1, 20] to reduce the communication costs. One list scheduling method, the LAST algorithm, is included in this comparison study. Graph decomposition method <ref> [15, 16] </ref>: Based on graph decomposition theory, the method parses a graph into a hierarchy (tree) of subgraphs. Communication and execution costs are applied to the tree to determine the grain size that results in the most efficient schedule.
Reference: 17. <author> Papadimitrou,C.H., and Ullman, J.D. </author> <title> A Communication-Time Tradeoff. </title> <journal> SIAM J. Comput., </journal> <volume> Vol. 16, No. 4, </volume> <month> Aug. </month> <year> 19876, </year> <pages> pp. 639-646. </pages>
Reference-contexts: The challenge in the extended scheduling problem is to consider the tradeoff between communication time and degree of parallelism <ref> [17] </ref>. 2 Many researchers have studied the problem and proposed solutions. This paper considers algorithms from three caregories: critical path heuristics, list scheduling heuristics and graph analysis.
Reference: 18. <author> Papadimitrou, C.H. and Yannakakis,M. </author> <title> Towards an Architecture-Independent Analysis of Parallel Algorithms. </title> <journal> SIAM J. Comput., </journal> <volume> Vol. 19, No. 2, </volume> <month> April </month> <year> 1990, </year> <pages> pp. 322-328. </pages>
Reference-contexts: A taxonomy of these techniques as well as a comparison of four specific heuristics can be found in the work of Gerasoulis and Yang [4]. In this paper we include experimental results from three critical path algorithms, DSC, Linear Clustering and MCP. List scheduling heuristics <ref> [1, 10, 12, 13, 14, 18, 20] </ref>: These algorithms assign priorities to the processes and schedule them according to a list priority scheme. For example, a high priority might be given to a task with many heavily weighted incident edges or to a task whose neighbors have already been scheduled.
Reference: 19. <author> Reingold, E.M., Nievergelt, J. , and Deo, N. </author> <title> Combinatorial Algorithms: Theory and Practice, </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1977. </year>
Reference: 20. <author> Rewini, H.E. and Lewis,T.G. </author> <title> Scheduling Parallel Program Tasks onto Arbitrary Target Machines. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 9, </volume> <year> 1990, </year> <pages> pp. 138-153. </pages>
Reference-contexts: A taxonomy of these techniques as well as a comparison of four specific heuristics can be found in the work of Gerasoulis and Yang [4]. In this paper we include experimental results from three critical path algorithms, DSC, Linear Clustering and MCP. List scheduling heuristics <ref> [1, 10, 12, 13, 14, 18, 20] </ref>: These algorithms assign priorities to the processes and schedule them according to a list priority scheme. For example, a high priority might be given to a task with many heavily weighted incident edges or to a task whose neighbors have already been scheduled. <p> Extending the list scheduling heuristic in classical scheduling [6], these algorithms use greedy heuristics and schedule tasks in a certain order. Task duplications have been used in <ref> [12,1, 20] </ref> to reduce the communication costs. One list scheduling method, the LAST algorithm, is included in this comparison study. Graph decomposition method [15, 16]: Based on graph decomposition theory, the method parses a graph into a hierarchy (tree) of subgraphs. <p> This simplified model allows schedulers to concentrate on the essential problem of task scheduling. 4 (3) Duplication of the execution of tasks in separate grains is not allowed. Several heuristics <ref> [12, 1, 20] </ref> have been developed that take advantage of this option, and these algorithms deserve further analysis. However, it is beyond the scope of this paper to consider them. (4) Tasks communicate only before starting and after completing their execution.
Reference: 21. <author> Sarkar, V., </author> <title> Partitioning and Scheduling Parallel Programs for Execution on Multiprocessors. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: partitioning scheme will minimize the parallel running time ( elapsed time from the start of the first processor to the completion of the last 1 processor.) A sequential program is commonly represented as a Program Dependence Graph (PDG) which is a directed acyclic graph (DAG) with node and edge weights <ref> [21] </ref>. Each vertex in a PDG denotes a task and a weight, which represents its processing time. Each edge denotes the precedence relation between the two tasks, and the weight of the edge is the communication cost incurred if the two tasks are assigned to different processors. <p> A good assignment will shorten the execution time of the program. The partitioning and assignment is called the scheduling problem. The problem is also known as grain size determination [12], the clustering problem [11, 24], and internalization pre-pass <ref> [21] </ref>. The problem is important because solution methods can be used to generate efficient parallel programs. The partitioning/scheduling problem is intractable, and heuristics are required to find sub-optimal solutions. In addition, there are no known performance guarantees for scheduling heuristics for general graphs. <p> The challenge in the extended scheduling problem is to consider the tradeoff between communication time and degree of parallelism [17]. 2 Many researchers have studied the problem and proposed solutions. This paper considers algorithms from three caregories: critical path heuristics, list scheduling heuristics and graph analysis. Critical path heuristics <ref> [4, 5, 11, 21, 23, 24] </ref>: For DAGs with edge weights and node weights, a path weight is defined to be the sum of the weights of both nodes and edges on the path. <p> The PDGs include very regular and very irregular graphs representing real program dependence graphs. 2. Problem Definition and Assumptions The problem of parallelizing the PDG to achieve minimal parallel time is NP-hard <ref> [21] </ref>. Two distinct steps are usually described in this parallelization process: partitioning and scheduling. Partitioning combines tasks from the PDG onto groups of tasks called grains to be executed on the same processor. The optimal size of a grain is dependent on the characteristics of the target architecture.
Reference: 22. <author> Terrano,A.E., Dunn, S.M., and Peters, </author> <title> H.E. Using an Architectural Knowledge Base to Generate Code for Parallel Computer. </title> <journal> Comm. of ACM, </journal> <volume> Vol. 32, No. 9, </volume> <month> Sept. </month> <year> 1989, </year> <pages> pp. 1065-1072. </pages>
Reference: 23. <author> Wu, M.Y., and Gajski, </author> <title> D.D. Hypertool: A Programming Aid for Message-Passing Systems. </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> Vol. 1, No. 3, </volume> <month> July </month> <year> 1990, </year> <pages> pp. 330-343. </pages>
Reference-contexts: The challenge in the extended scheduling problem is to consider the tradeoff between communication time and degree of parallelism [17]. 2 Many researchers have studied the problem and proposed solutions. This paper considers algorithms from three caregories: critical path heuristics, list scheduling heuristics and graph analysis. Critical path heuristics <ref> [4, 5, 11, 21, 23, 24] </ref>: For DAGs with edge weights and node weights, a path weight is defined to be the sum of the weights of both nodes and edges on the path.
Reference: 24. <author> Yu, </author> <title> W.H. LU Decomposition on a Multiprocessing System with Communication Delay. </title> <type> Ph.D. Theses, </type> <institution> Dept. of EE and CS, University of California, Berkeley, </institution> <year> 1984. </year> <pages> 27 28 </pages>
Reference-contexts: A good assignment will shorten the execution time of the program. The partitioning and assignment is called the scheduling problem. The problem is also known as grain size determination [12], the clustering problem <ref> [11, 24] </ref>, and internalization pre-pass [21]. The problem is important because solution methods can be used to generate efficient parallel programs. The partitioning/scheduling problem is intractable, and heuristics are required to find sub-optimal solutions. In addition, there are no known performance guarantees for scheduling heuristics for general graphs. <p> The challenge in the extended scheduling problem is to consider the tradeoff between communication time and degree of parallelism [17]. 2 Many researchers have studied the problem and proposed solutions. This paper considers algorithms from three caregories: critical path heuristics, list scheduling heuristics and graph analysis. Critical path heuristics <ref> [4, 5, 11, 21, 23, 24] </ref>: For DAGs with edge weights and node weights, a path weight is defined to be the sum of the weights of both nodes and edges on the path.
References-found: 24

