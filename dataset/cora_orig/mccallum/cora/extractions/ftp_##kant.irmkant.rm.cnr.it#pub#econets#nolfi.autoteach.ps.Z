URL: ftp://kant.irmkant.rm.cnr.it/pub/econets/nolfi.autoteach.ps.Z
Refering-URL: http://kant.irmkant.rm.cnr.it/public.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Email: stiva@irmkant.Bitnet domenico@irmkant.Bitnet  
Title: Auto-teaching: networks that develop their own teaching input  
Author: Stefano Nolfi Domenico Parisi 
Address: Rome  
Affiliation: Institute of Psychology National Research Council  
Abstract: Backpropagation learning (Rumelhart, Hinton and Williams, 1986) is a useful research tool but it has a number of undesiderable features such as having the experimenter decide from outside what should be learned. We describe a number of simulations of neural networks that internally generate their own teaching input. The networks generate the teaching input by trasforming the network input through connection weights that are evolved using a form of genetic algorithm. What results is an innate (evolved) capacity not to behave efficiently in an environment but to learn to behave efficiently. The analysis of what these networks evolve to learn shows some interesting results. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ackley, D.E. and Littman, </author> <title> M.L. </title> <booktitle> 1991. Proceedings of the Second Conference on Artificial Life. </booktitle> <publisher> Addison-Wesley: </publisher> <address> Reading, MA. </address>
Reference: <author> Belew, R.K. </author> <year> 1989. </year> <title> Evolution, learning and culture: computational metaphors for adaptive algorithms. </title> <type> CSE Technical Report CS89-156. </type> <institution> University of California, </institution> <address> San Diego. </address>
Reference: <author> Belew, R.K., McInerney, J., Schraudolph, N. </author> <year> 1990. </year> <title> Evolving networks: using the genetic algorithm with connectionist learning. </title> <type> CSE Technical Report CS89-174. </type> <institution> University of California, </institution> <address> San Diego. </address>
Reference: <author> Elman, J.L. </author> <year> 1990. </year> <title> Finding Structure in Time. </title> <journal> Cognitive Science, </journal> <volume> 14, </volume> <pages> 179-211. </pages>
Reference: <author> Goldberg, D.E., Holland, J.H. </author> <year> 1988. </year> <title> Genetic Algorithms. </title> <journal> Machine Learning, </journal> <volume> 3, </volume> <pages> 95-245. </pages>
Reference: <author> Hinton, G.E., Nowlan S.J. </author> <year> 1987. </year> <title> How Learning Guides Evolution. </title> <journal> Complex System, </journal> <volume> 1, </volume> <pages> 495-502. </pages>
Reference: <author> Holland, J.J. </author> <year> 1975. </year> <title> Adaptation in Natural and Artificial Systems. </title> <institution> Ann Arbor, Michigan: University of Michigan Press. </institution>
Reference-contexts: Fully supervised paradigms such as backpropagation (Rumelhart, Hinton, and Williams, 1986) supply immediate and detailed correct answers as feedback. Reinforcement paradigms (Sutton, 1984) supply only judgments of right or wrong. Simulated annealing algorithms (Kirkpatrick, Gelatt and Vecchi, 1983) and genetic algorithms <ref> (Holland, 1975) </ref>, applied to neural networks, supply still less, only a global evaluation of network's performace. Unsupervised paradigms (Hopfield, 1982; Kohonen, 1982) do not require supervision at all and therefore avoid these problems.
Reference: <author> Hopfield, J.J. </author> <year> 1982. </year> <title> Neural Networks and Physical Systems with Emergent Collective Computational Abilities. </title> <booktitle> Proceedings of the National Academy of Sciences, U.S.A., </booktitle> <volume> 79, </volume> <pages> 2554-2558. </pages>
Reference: <author> Kirkpatrick, </author> <title> C.D., Gelatt, </title> <publisher> M.P., Vecchi, M.P. </publisher> <year> 1983. </year> <title> Optimization by Simulated Annealing. </title> <journal> Science. </journal> <volume> 220. </volume>
Reference-contexts: Learning algorithms vary in the amount and nature of the feedback required. Fully supervised paradigms such as backpropagation (Rumelhart, Hinton, and Williams, 1986) supply immediate and detailed correct answers as feedback. Reinforcement paradigms (Sutton, 1984) supply only judgments of right or wrong. Simulated annealing algorithms <ref> (Kirkpatrick, Gelatt and Vecchi, 1983) </ref> and genetic algorithms (Holland, 1975), applied to neural networks, supply still less, only a global evaluation of network's performace. Unsupervised paradigms (Hopfield, 1982; Kohonen, 1982) do not require supervision at all and therefore avoid these problems.
Reference: <author> Kohonen, T. </author> <year> 1982. </year> <title> Self-organized formation of topologically correct feature maps. </title> <journal> Biological Cybernetics, </journal> <volume> 43, </volume> <pages> 59-69. </pages>
Reference: <author> Miller, G.F. and Todd, P.M. </author> <year> 1990. </year> <title> Exploring adaptive agency I: theory and methods for simulating the evolution of learning. </title> <editor> In D.S. Touretzky, J.L. Elman, </editor> <publisher> T.J. </publisher>
Reference: <editor> Sejnowski and G.E. Hinton (eds.), </editor> <booktitle> Proceedings of the 1990 Connectionist Models Summer School. </booktitle> <address> San Matteo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Nolfi, S., Elman, J, and Parisi, D. </author> <year> 1990. </year> <title> Learning and evolution in neural networks. </title> <type> CRL Technical Report 9019. </type> <institution> University of California, </institution> <address> San Diego. </address>
Reference: <author> Parisi, D., Cecconi, F., Nolfi, S. </author> <year> 1990. </year> <title> Econets: Neural Networks that Learn in an Environment. </title> <journal> Network, </journal> <volume> 1, </volume> <pages> 149-168. </pages>
Reference: <author> Parisi, D., Nolfi, S. and Cecconi, F. </author> <year> 1991. </year> <title> Learning, behavior, and evolution. </title> <editor> In: Varela, F, Bourgine, P. </editor> <title> Toward a pratice of autonomous systems. </title> <publisher> MIT Press. </publisher>
Reference: <author> Rumelhart, D.E., Hinton G.E., and Williams, R.J. </author> <year> 1986. </year> <title> Learning internal representations by error propagation. </title> <editor> In D.E. Rumelhart, and J.L. McClelland, (eds.), </editor> <booktitle> Parallel Distributed Processing. Vol.1: Foundations. </booktitle> <address> Cambridge, Mass.: </address> <publisher> MIT Press. </publisher>
Reference-contexts: However, there is a third case in which neither the function nor the empirical data are available and still we may want the network to learn. Learning algorithms vary in the amount and nature of the feedback required. Fully supervised paradigms such as backpropagation <ref> (Rumelhart, Hinton, and Williams, 1986) </ref> supply immediate and detailed correct answers as feedback. Reinforcement paradigms (Sutton, 1984) supply only judgments of right or wrong.
Reference: <author> Sutton, R.S. </author> <year> 1984. </year> <title> Temporal credit assignment in reinforcement learning. </title> <institution> University of Massachusetts. Departement of Computer and Information Science. </institution> <type> Technical Report 84-2. </type> <address> Amherst, MA. </address>
Reference-contexts: Learning algorithms vary in the amount and nature of the feedback required. Fully supervised paradigms such as backpropagation (Rumelhart, Hinton, and Williams, 1986) supply immediate and detailed correct answers as feedback. Reinforcement paradigms <ref> (Sutton, 1984) </ref> supply only judgments of right or wrong. Simulated annealing algorithms (Kirkpatrick, Gelatt and Vecchi, 1983) and genetic algorithms (Holland, 1975), applied to neural networks, supply still less, only a global evaluation of network's performace.
Reference: <author> Weigend, A.S., Huberman, B.A., Rumelhart, D.E. </author> <year> 1990. </year> <title> Predicting the Future: a Connectionist Approach. </title> <journal> International Journal of Neural Systems, </journal> <volume> 1, </volume> <pages> 193-209. </pages>
Reference: <author> Willshaw, D. </author> <year> 1981. </year> <title> Holografy, associative memory and inductive generalization. </title> <editor> In Hinton, G. and J. Anderson (Eds.) </editor> <title> Parallel Model of Associative Memory. </title> <address> Hillsdale: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> Zipser, D. </author> <year> 1990. </year> <title> Modeling cortical computation with backpropagation. </title> <address> In M.A. </address>
Reference-contexts: Zipser (1990) considers two cases, one in which the function that generates these pairs is known and can be used to generate the teaching input, and the other in which "no function is known but where empirical input-output data is available" which "can be used to train the network" <ref> (Zipser, 1990 p.357) </ref>. However, there is a third case in which neither the function nor the empirical data are available and still we may want the network to learn. Learning algorithms vary in the amount and nature of the feedback required. <p> Unsupervised paradigms (Hopfield, 1982; Kohonen, 1982) do not require supervision at all and therefore avoid these problems. On the other hand, unsupervised learning models cannot learn arbitrary functions and appear to be restricted to tasks in which what must be learned is basically the statistical properties of the inputs <ref> (Zipser, 1990, p.358) </ref>. Nolfi, Elman, and Parisi (1990) described networks that simulate organisms moving in an environment and looking for food elements. <p> Developing good internal representations when the input-output mapping is a complex one, i.e. when "the similarity structure of the input and output patterns is very different", is the fundamental function of hidden units <ref> (Zipser and Rumelhart, 1990, pag. 193) </ref>. Auto-teaching units might be an evolved mechanism to accelerate the learning of good internal representations. (3) Another interesting result of Simulation 2 is that the auto-teaching mechanism almost extinguishes itself in the last generations.
Reference: <editor> Gluck and D.E. Rumelhart (eds.) </editor> <title> Neuroscience and Connectionist Theory. </title> <address> Hillsdale, N.J., </address> <publisher> Erlbaum. </publisher>
Reference: <author> Zipser, D. and Rumelhart, D.E. </author> <year> 1990. </year> <title> The neurobiological significance of the new learning models. </title> <editor> In Schwartz, E.L. (Ed.) </editor> <booktitle> Computational Neuroscience. </booktitle> <address> Cambridge, Mass.: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Zipser (1990) considers two cases, one in which the function that generates these pairs is known and can be used to generate the teaching input, and the other in which "no function is known but where empirical input-output data is available" which "can be used to train the network" <ref> (Zipser, 1990 p.357) </ref>. However, there is a third case in which neither the function nor the empirical data are available and still we may want the network to learn. Learning algorithms vary in the amount and nature of the feedback required. <p> Unsupervised paradigms (Hopfield, 1982; Kohonen, 1982) do not require supervision at all and therefore avoid these problems. On the other hand, unsupervised learning models cannot learn arbitrary functions and appear to be restricted to tasks in which what must be learned is basically the statistical properties of the inputs <ref> (Zipser, 1990, p.358) </ref>. Nolfi, Elman, and Parisi (1990) described networks that simulate organisms moving in an environment and looking for food elements. <p> Developing good internal representations when the input-output mapping is a complex one, i.e. when "the similarity structure of the input and output patterns is very different", is the fundamental function of hidden units <ref> (Zipser and Rumelhart, 1990, pag. 193) </ref>. Auto-teaching units might be an evolved mechanism to accelerate the learning of good internal representations. (3) Another interesting result of Simulation 2 is that the auto-teaching mechanism almost extinguishes itself in the last generations.
References-found: 22

