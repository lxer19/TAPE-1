URL: ftp://ftp.cs.uu.nl/pub/RUU/CS/techreps/CS-1996/1996-28.ps.gz
Refering-URL: http://www.cs.ruu.nl/docs/research/publication/TechList1.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: On Evidence Absorption for Belief Networks  
Author: Linda C. van der Gaag 
Keyword: Key words: belief networks, probabilistic inference, evidence absorption, (average-case) computational complexity.  
Address: P.O. Box 80.089, 3508 TB Utrecht The Netherlands  
Affiliation: Utrecht University Department of Computer Science  
Abstract: More and more real-life applications of the belief-network framework are emerging. As applications grow larger, the belief networks involved increase in size accordingly. For large belief networks, probabilistic inference tends to become rather time-consuming. In the worst case this tendency may not be denied as probabilistic inference is known to be NP-hard. However, it is possible to improve on the average-case performance of the algorithms involved. For this purpose, the method of evidence absorption can be exploited. In this paper, we detail the method of evidence absorption and outline its integration into a well-known algorithm for probabilistic inference. The ability of the method to improve on the average-case computational expense of probabilistic inference is illustrated by means of experiments performed on both randomly generated and real-life belief networks. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Andreassen, M. Woldbye, B. Falck, S.K. Andersen. </author> <title> MUNIN | A causal probabilistic network for interpretation of electromyographic findings, </title> <booktitle> Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pp. 366 - 372, </pages> <year> 1987. </year>
Reference-contexts: 1 Introduction The belief-network framework for reasoning with uncertainty in knowledge-based systems has been around for some time now, and more and more practical applications employing the framework are being developed <ref> [1, 2, 3] </ref>. As applications of the framework grow larger, the belief networks involved increase in size accordingly: belief networks comprising hundreds, or even thousands, of variables are no exception. <p> vertices V (G) = fV 1 ; : : : ; V n g, n 1, and * = ffl V i j V i 2 V (G)g is a set of real-valued functions fl V i : fC V i g fi fC G (V i ) g ! <ref> [0; 1] </ref>, called probability assessment functions, such that for each configuration c G (V i ) of the set G (V i ) of (immediate) predecessors of vertex V i we have that fl V i (:v i j c G (V i ) ) = 1 fl V i (v <p> successors of the vertex V i in G, and * v i = ffl v i V j j V j 2 V (G)g is the set of real-valued functions fl v i V j : fC V j g fi fC G v i (V j ) g ! <ref> [0; 1] </ref> with - fl V j (V j j C G v i (V j ) ) = fl V j (V j j C G (V j )nfV i g ^ v i ), for all vertices V j 2 G (V i ), and - fl V k
Reference: [2] <author> D.E. Heckerman, E.J. Horvitz, </author> <title> B.N. Nathwani. Toward normative expert systems. Part 1: The Pathfinder project, </title> <booktitle> Methods of Information in Medicine, </booktitle> <volume> vol. 31, </volume> <pages> pp. 90 - 105, </pages> <year> 1992. </year>
Reference-contexts: 1 Introduction The belief-network framework for reasoning with uncertainty in knowledge-based systems has been around for some time now, and more and more practical applications employing the framework are being developed <ref> [1, 2, 3] </ref>. As applications of the framework grow larger, the belief networks involved increase in size accordingly: belief networks comprising hundreds, or even thousands, of variables are no exception.
Reference: [3] <author> P.D. Bruza, L.C. van der Gaag. </author> <title> Index expression belief networks for information disclosure, </title> <journal> The International Journal of Expert Systems: Research and Applications, </journal> <volume> vol. 7, no. 2, </volume> <pages> pp. 107 - 138, </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction The belief-network framework for reasoning with uncertainty in knowledge-based systems has been around for some time now, and more and more practical applications employing the framework are being developed <ref> [1, 2, 3] </ref>. As applications of the framework grow larger, the belief networks involved increase in size accordingly: belief networks comprising hundreds, or even thousands, of variables are no exception.
Reference: [4] <author> G.F. Cooper. </author> <title> The computational complexity of probabilistic inference using Bayesian belief networks, </title> <journal> Artificial Intelligence, </journal> <volume> vol. 42, </volume> <pages> pp. 393 - 405, </pages> <year> 1990. </year>
Reference-contexts: For belief networks of this size, probabilistic inference shows a tendency to become rather time-consuming, even so to an unacceptable extent. Since probabilistic inference is known to be NP-hard <ref> [4] </ref>, this tendency may not be denied in general: the basic algorithms associated with a belief network have an exponential worst-case computational time complexity and it is not expected that a general polynomial-time algorithm will be found.
Reference: [5] <author> R.D. Shachter. </author> <title> Evidence absorption and propagation through evidence reversals, </title> <editor> in: M. Henrion, R.D. Shachter, L.N. Kanal, J.F. Lemmer (editors). </editor> <booktitle> Uncertainty in Artificial Intelligence 5, </booktitle> <publisher> Elsevier Science Publishers (North-Holland), Amsterdam, </publisher> <pages> pp. 173 - 190, </pages> <year> 1990. </year>
Reference-contexts: We propose exploiting for this purpose the method of evidence absorption. The method of evidence absorption has been first introduced by R.D. Shachter as part of an algorithm for processing evidence in a belief network <ref> [5] </ref>. The basic idea of the method is to dynamically modify a belief network as evidence becomes available so as to explicitly represent newly created independences. <p> An algorithm for probabilistic inference with a belief network provides for computing probabilities of interest and for processing evidence, that is, for entering evidence into the network and subsequently computing the revised probability distribution given the evidence. Several such algorithms have been developed <ref> [5, 6, 7] </ref>. Here, we only briefly review the basic idea of the algorithm designed by J. Pearl [6]. In outlining Pearl's algorithm for probabilistic inference, we take an object-centered point of view. <p> It is possible to modify the topology of the digraph of the network dynamically so as to reflect these newly created dependences and independences explicitly. In fact, Shachter's algorithm for probabilistic inference is built on this very idea <ref> [5] </ref>. As we will argue in the sequel, however, it is worthwhile to modify the topology of the digraph to reflect the new independences only. The method of evidence absorption is designed for this purpose.
Reference: [6] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. Networks of Plausible Inference, </title> <publisher> Morgan Kaufmann, </publisher> <address> Palo Alto, </address> <year> 1988. </year>
Reference-contexts: The paper is rounded off with some conclusions in Section 6. 2 Preliminaries In this section we review the basic notions involved in the belief-network formalism and briefly outline Pearl's enhanced algorithm for probabilistic inference with a belief network; for further details, the reader is referred to <ref> [6] </ref>. 2.1 The Belief-Network Formalism A belief network is a terse representation of a joint probability distribution on a set of statistical variables. It consists of a qualitative and a quantitative part. <p> Note that in the previous definition V i is viewed as a vertex from the digraph and as a statistical variable, alternatively. To link the qualitative and quantitative parts of a belief network, a probabilistic meaning is assigned to the topology of the digraph of the network <ref> [6] </ref>. Definition 2.2 Let G = (V (G); A (G)) be an acyclic digraph and let s be a chain in G. <p> An algorithm for probabilistic inference with a belief network provides for computing probabilities of interest and for processing evidence, that is, for entering evidence into the network and subsequently computing the revised probability distribution given the evidence. Several such algorithms have been developed <ref> [5, 6, 7] </ref>. Here, we only briefly review the basic idea of the algorithm designed by J. Pearl [6]. In outlining Pearl's algorithm for probabilistic inference, we take an object-centered point of view. <p> Several such algorithms have been developed [5, 6, 7]. Here, we only briefly review the basic idea of the algorithm designed by J. Pearl <ref> [6] </ref>. In outlining Pearl's algorithm for probabilistic inference, we take an object-centered point of view. <p> Pearl has proposed several methods for probabilistic inference with a belief network comprising a multiply connected digraph <ref> [6] </ref>. Of these, the method of loop cutset conditioning may be looked upon as a supplement to the basic algorithm. The idea underlying this method is that of reasoning by assumption.
Reference: [7] <author> S.L. Lauritzen, </author> <title> D.J. Spiegelhalter. Local computations with probabilities on graphical structures and their application to expert systems, </title> <journal> Journal of the Royal Statistical Society, Series B, </journal> <volume> vol. 50, </volume> <pages> pp. 157 - 224, </pages> <year> 1988. </year>
Reference-contexts: An algorithm for probabilistic inference with a belief network provides for computing probabilities of interest and for processing evidence, that is, for entering evidence into the network and subsequently computing the revised probability distribution given the evidence. Several such algorithms have been developed <ref> [5, 6, 7] </ref>. Here, we only briefly review the basic idea of the algorithm designed by J. Pearl [6]. In outlining Pearl's algorithm for probabilistic inference, we take an object-centered point of view.
Reference: [8] <author> H.J. Suermondt and G.F. Cooper. </author> <title> Probabilistic inference in multiply connected belief networks using loop cutsets. </title> <journal> International Journal of Approximate Reasoning, </journal> <volume> vol. 4, </volume> <pages> pp. 283-306, </pages> <year> 1990. </year>
Reference-contexts: Unfortunately, Pearl's algorithm applies to belief networks involving a singly connected digraph only. Straightforward application of the algorithm to an acyclic digraph comprising one or more loops leads to insuperable problems <ref> [8] </ref>: vertices may indefinitely send updated messages to their neighbours causing the network never to reach a new equilibrium, or, if the network does reach an equilibrium, it is not guaranteed to correctly reflect the updated joint probability distribution.
Reference: [9] <author> L.C. van der Gaag. </author> <title> Evidence Absorption for Belief Networks, </title> <type> Technical Report CS-RUU-93-35, </type> <institution> Utrecht University, </institution> <year> 1993. </year>
Reference-contexts: In the following lemma, we state more formally that the two networks represent the same independences given the evidence; a separate proof for this property is provided in <ref> [9] </ref>. Lemma 3.4 Let B = (G; ) be a belief network with G = (V (G); A (G)).
Reference: [10] <author> E. Kaspers, L.C. van der Gaag. </author> <title> Dynamic Loop Cutset Reduction, </title> <note> in preparation. </note>
Reference-contexts: The method of evidence absorption therefore provides for dynamically reducing an initial loop cutset as evidence is entered into a belief network involving a multiply connect digraph; for further details of dynamic loop cutset reduction, we refer to a forthcoming paper <ref> [10] </ref>. 5 The Experiments and Their Results In the previous sections, we have detailed the method of evidence absorption and its incorporation into Pearl's enhanced algorithm for probabilistic inference.
Reference: [11] <author> L.C. van der Gaag. </author> <title> Evidence Absorption Experiments on Different Classes of Randomly Generated Belief Networks, </title> <type> Technical Report UU-CS-94-42, </type> <institution> Utrecht University, </institution> <year> 1994. </year>
Reference-contexts: The Set-Up of the Experiments In each experiment, we have generated a set of one hundred (connected) acyclic digraphs by means of a graph generator; for further details of the graph generator used, we refer the reader to <ref> [11] </ref>. Each digraph is randomly generated to comprise n vertices, n 1, and m arcs, n 1 m 1 2 n (n 1). <p> In this paper, however, we will not address the impact of these biases. For further details of the evidence generator and for an overview of all experiments performed and their results, we refer the reader once more to <ref> [11] </ref>. 10 (a) (b) (b) The Average Number of Components, (c) The Average Size of the Minimum Component, (d) The Average Size of the Maximum Component The Results of the Experiments The aim of the first experiment reported here has been to study, in isolation, the influence of the degree of
Reference: [12] <author> B. Bollobas. </author> <title> Random Graphs, </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: We now address the average numbers of components and their respective sizes found in the experiments. For this purpose, we first consider the generation of a random digraph by successive addition of arcs between randomly selected vertices <ref> [12] </ref>. It will be evident that the more arcs are added to a digraph in the making, the more likely it is to become connected.
Reference: [13] <author> M. Korver, P.J.F. Lucas. </author> <title> Converting a rule-based expert system into a belief network, </title> <journal> Medical Informatics, </journal> <volume> vol. 18, </volume> <pages> pp. 219 - 241, </pages> <year> 1993. </year>
Reference-contexts: In addition to our experiments on randomly generated belief networks, we therefore have also done some experiments on real-life networks, among which is the HEPAR belief network <ref> [13] </ref>. The HEPAR belief network is a small medical belief network for the diagnosis of Wilson's disease.
Reference: [14] <author> I.A. Beinlich, H.J. Suermondt, R.M. Chavez, </author> <title> G.F. Cooper. The ALARM monitoring system: a case study with two probabilistic inference techniques for belief networks, </title> <editor> in: J. Hunter, J. Cookson, J. Wyatt (eds.) </editor> <booktitle> AIME-89 Proceedings of the Second Conference on Artificial Intelligence in Medicine, </booktitle> <publisher> Springer-Verlag, Berlin, </publisher> <pages> pp. 247 - 256, </pages> <year> 1989. </year> <month> 17 </month>
Reference-contexts: copper Kayser-Fleischer rings Psychiatric disease Neurological disease Renal disease The impact of the method of evidence absorption as outlined above for the HEPAR belief network appears to be typical for (small-scaled) diagnostic belief networks: we have found similar results for other networks such as for example the ALARM Monitoring system <ref> [14] </ref>. We would like to note that at present only few full-scaled, real-life belief networks are available from the literature, rendering extensive experiments on such networks practically infeasible.
References-found: 14

