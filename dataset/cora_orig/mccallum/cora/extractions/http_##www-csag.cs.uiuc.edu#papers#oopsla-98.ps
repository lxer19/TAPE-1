URL: http://www-csag.cs.uiuc.edu/papers/oopsla-98.ps
Refering-URL: http://www-csag.cs.uiuc.edu/papers/index.html
Root-URL: http://www.cs.uiuc.edu
Email: dolby@cs.uiuc.edu  achien@cs.ucsd.edu  
Title: An Evaluation of Automatic Object Inline Allocation Techniques  
Author: Julian Dolby Andrew A. Chien 
Address: Urbana  San Diego  
Affiliation: Department of Computer Science University of Illinois at  Department of Computer Science and Engineering University of California,  
Abstract: We present three compiler analyses to identify inlin-able fields by tracking accesses to heap objects. These analyses span a range from local data flow to adaptive whole-program, flow-sensitive inter-procedural analysis. We measure their cost and effectiveness on a suite of moderate-sized C++ programs (up to 30,000 lines including libraries). We show that aggressive inter-procedural analysis is required to enable object inlin-ing, and our adaptive inter-procedural analysis [23] computes precise information efficiently. Object inlining eliminates typically 40% of object accesses and allocations (improving performance up to 50%). Furthermore, 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> O. Agesen, J. Palsberg, and M. Schwartzbach. </author> <title> Type inference of Self: Analysis of objects with dynamic and multiple inheritance. </title> <booktitle> In Proceedings of ECOOP '93, </booktitle> <year> 1993. </year>
Reference-contexts: The combination of small methods and dynamic dispatch is a well-studied problem: dynamic dispatches are optimized statically by type inference <ref> [1, 6, 21, 24] </ref>, dynamically by inline caching [16] or with hybrid approaches like type feedback [17]. Static or hybrid type analysis has been combined with method specialization [8, 25] to allow inlining, removing the small functions common in object-oriented code.
Reference: [2] <author> P. </author> <title> America. Inheritance and subtyping in a parallel object-oriented language. </title> <booktitle> In Proceedings of ECOOP, </booktitle> <pages> pages 234-42. </pages> <publisher> Springer-Verlag, </publisher> <month> June </month> <year> 1987. </year>
Reference-contexts: 1 Introduction Object-oriented languages provide abstraction, allowing programmers to isolate conceptual portions of a given program behind opaque interfaces, with attendant benefits in code modularity and reusability. Languages such as Java [32], Lisp [30], Pool <ref> [2] </ref> and Sather [31] provide this abstraction with opaque objects for which clients have a reference and an interface specification. This isolates the clients from any changes in a given object's implementation.
Reference: [3] <author> A. Black, N. Hutchinson, E. Jul, and H. Levy. </author> <title> Object structure in the emerald system. </title> <booktitle> In Proceedings of OOPSLA '86, </booktitle> <pages> pages 78-86. </pages> <publisher> ACM, </publisher> <month> September </month> <year> 1986. </year>
Reference-contexts: The idea of doing automatic object inlining dates back at least to the Emerald system, which has a reference object model <ref> [3] </ref> that was designed so that the compiler [18] could optimize object structures. However, while our adaptive analysis can produce the information needed for inline allocation (see Section 5.1), the simple, graph-algorithm-based analysis system of the Emerald compiler was sufficient only to allow the inlining of (boxed) immediate types.
Reference: [4] <author> Zoran Budimlic and Ken Kennedy. </author> <title> Optimizing java: </title> <journal> Theory and practice. Concurrency: Practice and Experience, </journal> <volume> 9(6), </volume> <month> June </month> <year> 1997. </year> <month> 17 </month>
Reference-contexts: Immediate types in Emerald posed fewer analysis challenges for they had by definition the value semantics required for inlining. Budimlic and Kennedy <ref> [4] </ref> sketch a combined object and method inlining optimization which they call object inlining. In their scheme, for an object created within a method, all its called methods are inlined and the state of the object replaced with local variables.
Reference: [5] <author> Brad Calder, Dirk Grunwald, and Benjamin Zorn. </author> <title> Quantifying differences between C and C++ programs. </title> <type> Technical Report CU-CS-698-94, </type> <institution> University of Colorado, Boulder, </institution> <month> January </month> <year> 1994. </year>
Reference-contexts: Additionally, an object-oriented programming style generally encourages the use of small methods and objects To appear in the 13th Annual Conference on Object-Oriented Systems, Languages and Applications (OOP-SLA), Vancover, British Columbia, October 1998 <ref> [5] </ref>. The combination of small methods and dynamic dispatch is a well-studied problem: dynamic dispatches are optimized statically by type inference [1, 6, 21, 24], dynamically by inline caching [16] or with hybrid approaches like type feedback [17].
Reference: [6] <author> C. Chambers and D. Ungar. </author> <title> Iterative type analysis and extended message splitting. </title> <booktitle> In Proceedings of the SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 150-60, </pages> <year> 1990. </year>
Reference-contexts: The combination of small methods and dynamic dispatch is a well-studied problem: dynamic dispatches are optimized statically by type inference <ref> [1, 6, 21, 24] </ref>, dynamically by inline caching [16] or with hybrid approaches like type feedback [17]. Static or hybrid type analysis has been combined with method specialization [8, 25] to allow inlining, removing the small functions common in object-oriented code.
Reference: [7] <author> Andrew Chien, Julian Dolby, Bishwaroop Ganguly, Vijay Karamcheti, and Xingbin Zhang. </author> <title> Supporting high level programming with high performance: The Illinois Concert system. </title> <booktitle> In Proceedings of the Second International Workshop on High-level Parallel Programming Models and Supportive Environments, </booktitle> <pages> pages 15-24, </pages> <month> April </month> <year> 1997. </year>
Reference-contexts: Fortunately, the adaptive inter-procedural analysis we employed [24] computes precise information efficiently. We begin by discussing our approach to inline allocation in Section 2 and presenting an example program in Section 3. Next, Section 4 describes the Concert System <ref> [7] </ref> in which work was done, and Section 5 details our three program analyses. These analyses are evaluated on a suite of C++ programs in Section 6. This suite is summarized in Section 6.2 and performance metrics and results are given in Sections 6.3 and 6.4. <p> These two x pos operations must have different implementations, as one must access the inlined field and the other a free standing one. 3 4 Background: The Concert Compiler The implementation of our object inlining analyses was done in the Illinois Concert System <ref> [7] </ref>, and so a brief discussion of the relevant aspects of the system is given here to provide context for subsequent description of the optimization.
Reference: [8] <author> Jeffrey Dean, Craig Chambers, and David Grove. </author> <title> Selective specialization for object-oriented languages. </title> <booktitle> In Proceedings of the ACM SIGPLAN '95 Conference on Programmin g Language Design and Implementation, </booktitle> <pages> pages 93-102, </pages> <address> La Jolla, CA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: The combination of small methods and dynamic dispatch is a well-studied problem: dynamic dispatches are optimized statically by type inference [1, 6, 21, 24], dynamically by inline caching [16] or with hybrid approaches like type feedback [17]. Static or hybrid type analysis has been combined with method specialization <ref> [8, 25] </ref> to allow inlining, removing the small functions common in object-oriented code. Pervasive use of heap-allocated objects introduces overhead for memory management and repeated pointer dereference. This can both increase memory traffic and hurt local code efficiency by reducing opportunities for register allocation which inhibits many scalar optimizations.
Reference: [9] <author> Julian Dolby. </author> <title> Automatic inline allocation of objects. </title> <booktitle> In Proceedings of the 1997 ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 7-17, </pages> <address> Las Vegas, Nevada, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: A whole-program analysis that does this was presented in <ref> [9] </ref>, and showed speedups of up to three-fold on a set of object-intensive benchmarks. However, that study did not assess much analysis power is really required, and how many fields can be inlined on a wider range of benchmarks. In this paper, we address those questions. <p> They all use data-flow properties to track how object fields are used and defined; the analysis frameworks employed are lo-cal data flow, traditional control flow analysis [27] and adaptive flow analysis [24]. The control flow analysis and adaptive analysis variants are based upon the techniques in our prior work <ref> [9] </ref>; however, our study revealed deficiencies in those techniques so we generalized them substantially for this study. <p> We first define precisely what a tag is, then discuss how they are propagated using nCFA analysis. Finally we detail how to compute E f , R f and U p f . This analysis|and the similar adaptive analysis discussed next|is based upon techniques we devised previously <ref> [9] </ref>. The tag propagation for forward tags is exactly the same, but our prior technique worked by copying fields of the child object into the fused object, which we called definition specialization. <p> These codes represent a superset of the benchmarks used in our prior work <ref> [9] </ref>; that work used only silo, richards, polyover and oopack. 6.3 Metrics To assess the respective benefits and costs of our approaches to object inlining, we measure compile-time cost and effectiveness and the runtime impact.
Reference: [10] <author> Margaret A. Ellis and Bjarne Stroustrup. </author> <title> The Annotated C++ Reference Manual. </title> <publisher> Addison-Wesley, </publisher> <year> 1990. </year>
Reference-contexts: Modify the allocation points to use the new object definitions 3. Rewrite all accesses to the child object's state as accesses to the inlined child object. 2.2 Explicit Inline Allocation Some programming languages <ref> [10, 33] </ref>, notably C++, allow programmers to manually specify inline object allocation to improve performance. As with the automatic approaches, the objective is to reduce storage management overhead as well as the number of pointer deref-erences required to execute a program.
Reference: [11] <author> Maryam Emami, Rakesh Ghiya, and Laurie J. Hen-dren. </author> <title> Context-sensitive interprocedural points-to analysis in the presence of function pointers. </title> <booktitle> In Proceedings of the 1994 ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 242-256, </pages> <year> 1994. </year>
Reference-contexts: Our inter-procedural analyses have two advantages. First, our field tags are more general, as they handle arbitrary object structures, rather than lists. Second, our inter-procedural analysis analyzes only specializations that are actually used. In <ref> [11] </ref>, the authors describe access paths, which are used in various kinds of pointer analyses. The basic idea is that access paths keep track of object fields traversed during pointer dereferences.
Reference: [12] <author> Jeanne Ferrante, Karl J. Ottenstein, and Joe D. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-49, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: Most relevant is the program representation and the analysis and cloning frameworks, all discussed below. 4.1 Program Representation The primary program representation used by the Concert Compiler is the Program Dependence Graph (PDG <ref> [12] </ref>) in Static Single Assignment (SSA) form, of which a brief sketch is provided here mostly to introduce terminology we use while describing our analyses. Figure 4 shows an example PDG fragment from the Point::belowRight? method from Figure 3.
Reference: [13] <author> Tim Freeman and Frank Pfenning. </author> <title> Refinement types for ML. </title> <booktitle> In Proceedings of the 1991 ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: Due to the lazy semantics of Haskell, the transformation must be told what variables can be safely unboxed; furthermore, this transformation only unboxes immediate types. In [26], Shao et al. unroll linked lists-essentially inline allocating tail pointers-in a functional subset of ML. Their analysis works using refinement types <ref> [13] </ref> that distinguish odd and even length lists. These refined types are propagated using an abstract interpretation, with rules for the refined types generated by cons statements. All functions that take list parameters are cloned and specialized with all possible combinations of refinement types for their list parameters.
Reference: [14] <author> Keith E. Gorlen, Sanford M. Orlow, and Perry S. Plexico. </author> <title> Data Abstraction and Object-Oriented Programming in C++. </title> <publisher> John Wiley and Sons, </publisher> <year> 1991. </year>
Reference-contexts: In this paper, we address those questions. So to assess the feasibility and benefit of object in-lining, we study its effectiveness using several analysis frameworks of varying power and cost, and a benchmark suite including the NIHCL <ref> [14] </ref> and OATH class libraries, which together provide multiple implementations of a range of common data structures. These codes range from a few hundred lines to over 10,000 lines of C++ code (plus 20,000 lines of library). We implemented three different program analyses.
Reference: [15] <author> Cordelia Hall, Simon L. Peyton-Jones, and Patrick M. Sansom. </author> <title> Functional Programming, Glasgow 1994, chapter Unboxing Using Specialization. </title> <booktitle> Workshops in Computing Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: The unboxing transformation of [20] handles polymorphism by generating specialized code only for monomorphic functions and coercing between general and unboxed representations as needed. On the other hand, our optimization is a global transformation that specializes polymorphic functions as needed. In <ref> [15] </ref>, Cordelia Hall and company present a transformation for Haskell that does generate specialized code to exploit unboxing for polymorphic functions. Their transformation resembles ours in that it propagates "unboxedness" throughout the program generating specialized code wherever needed. Our optimization is fully automatic and handles arbitrary user-defined object types.
Reference: [16] <author> Urs Holzle, Craig Chambers, and David Un-gar. </author> <title> Optimizing dynamically-typed object-oriented languages with polymorphic inline caches. </title> <booktitle> In ECOOP'91 Conference Proceedings. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1991. </year> <note> Lecture Notes in Computer Science 512. </note>
Reference-contexts: The combination of small methods and dynamic dispatch is a well-studied problem: dynamic dispatches are optimized statically by type inference [1, 6, 21, 24], dynamically by inline caching <ref> [16] </ref> or with hybrid approaches like type feedback [17]. Static or hybrid type analysis has been combined with method specialization [8, 25] to allow inlining, removing the small functions common in object-oriented code. Pervasive use of heap-allocated objects introduces overhead for memory management and repeated pointer dereference.
Reference: [17] <author> Urs Holzle and David Ungar. </author> <title> Optimizing dynamically-dispatched calls with run-time type feedback. </title> <booktitle> In Proceedings of the 1994 ACM SIG-PLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 326-336, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: The combination of small methods and dynamic dispatch is a well-studied problem: dynamic dispatches are optimized statically by type inference [1, 6, 21, 24], dynamically by inline caching [16] or with hybrid approaches like type feedback <ref> [17] </ref>. Static or hybrid type analysis has been combined with method specialization [8, 25] to allow inlining, removing the small functions common in object-oriented code. Pervasive use of heap-allocated objects introduces overhead for memory management and repeated pointer dereference.
Reference: [18] <author> Norman C. Hutchinson. </author> <title> Emerald: An Object-Based Language for Distributed Programming. </title> <type> PhD thesis, </type> <institution> University of Washington, Department of Computer Science, </institution> <address> Seattle, Washington, </address> <year> 1987. </year> <month> TR-87-01-01. </month>
Reference-contexts: The idea of doing automatic object inlining dates back at least to the Emerald system, which has a reference object model [3] that was designed so that the compiler <ref> [18] </ref> could optimize object structures. However, while our adaptive analysis can produce the information needed for inline allocation (see Section 5.1), the simple, graph-algorithm-based analysis system of the Emerald compiler was sufficient only to allow the inlining of (boxed) immediate types.
Reference: [19] <author> Christopher Lapkowski and Laurie Hendren. </author> <title> Extended ssa numbering: Introducing ssa properties to languages with multi-level pointers. </title> <booktitle> In Proceedings of CASCON, </booktitle> <year> 1996. </year>
Reference-contexts: This topic has been studied by many researchers, using both runtime techniques (e.g. fine grained multi threading [22]) and compile time approaches (e.g. representations that explicate dependencies thru pointers <ref> [19] </ref>). But it remains a challenging open problem. Object inlining coalesces objects by inline allocating child objects within their container objects. This attacks pointer chasing by eliding the pointers and converts an unpredictable memory reference into one with spatial locality.
Reference: [20] <author> Xavier Leroy. </author> <title> Unboxed objects and polymorphic typing. </title> <booktitle> In Proceedings of the 19th Symposium on the Principles of Programming Languages, </booktitle> <pages> pages 177-188, </pages> <year> 1992. </year>
Reference-contexts: Our adaptive flow analysis is able to compute precise inlin-ing information in the presence of assignments to object fields; the unboxing work does not need to address this as there is no structure assignment in functional languages. The unboxing transformation of <ref> [20] </ref> handles polymorphism by generating specialized code only for monomorphic functions and coercing between general and unboxed representations as needed. On the other hand, our optimization is a global transformation that specializes polymorphic functions as needed.
Reference: [21] <author> J. Palsberg and M. Schwartzbach. </author> <title> Object-oriented type inference. </title> <booktitle> In Proceedings of OOPSLA '91, </booktitle> <pages> pages 146-61, </pages> <year> 1991. </year>
Reference-contexts: The combination of small methods and dynamic dispatch is a well-studied problem: dynamic dispatches are optimized statically by type inference <ref> [1, 6, 21, 24] </ref>, dynamically by inline caching [16] or with hybrid approaches like type feedback [17]. Static or hybrid type analysis has been combined with method specialization [8, 25] to allow inlining, removing the small functions common in object-oriented code.
Reference: [22] <author> James Philbin, Jan Edler, Otto J. Anshus, Craig C. Douglas, and Kai Li. </author> <title> Thread scheduling for cache locality. </title> <booktitle> In Proceedings of the Seventh Symposium on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VII), </booktitle> <pages> pages 60-71, </pages> <year> 1996. </year>
Reference-contexts: Pointer dereference (called pointer chasing) overhead not only incurs additional memory traffic, but given performance sensitivity to data locality, typically reduces cache efficiency. This topic has been studied by many researchers, using both runtime techniques (e.g. fine grained multi threading <ref> [22] </ref>) and compile time approaches (e.g. representations that explicate dependencies thru pointers [19]). But it remains a challenging open problem. Object inlining coalesces objects by inline allocating child objects within their container objects.
Reference: [23] <author> John Plevyak. </author> <title> Optimization of Object-Oriented and Concurrent Programs. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, Urbana, Illinois, </institution> <year> 1996. </year>
Reference-contexts: assume that unnecessary moves are eliminated, so the kind of creation (v) be one of call, phi, access, primitive or creation. creation (n) the node which creates n reaching (n) the set of nodes using n 4.2 The Analysis Framework The Concert compiler has a global analysis framework adaptive analysis <ref> [24, 23] </ref> that performs context sensitive flow analysis. The flow analysis ultimately builds a program-wide data-flow graph connecting the values within and across the individual method program graphs, with those values being specialized as needed by context sensitivity.
Reference: [24] <author> John Plevyak and Andrew A. Chien. </author> <title> Precise concrete type inference of object-oriented programs. </title> <booktitle> In Proceedings of OOPSLA'94, Object-Oriented Programming Systems, Languages and Architectures, </booktitle> <pages> pages 324-340, </pages> <year> 1994. </year>
Reference-contexts: The combination of small methods and dynamic dispatch is a well-studied problem: dynamic dispatches are optimized statically by type inference <ref> [1, 6, 21, 24] </ref>, dynamically by inline caching [16] or with hybrid approaches like type feedback [17]. Static or hybrid type analysis has been combined with method specialization [8, 25] to allow inlining, removing the small functions common in object-oriented code. <p> We implemented three different program analyses. They all use data-flow properties to track how object fields are used and defined; the analysis frameworks employed are lo-cal data flow, traditional control flow analysis [27] and adaptive flow analysis <ref> [24] </ref>. The control flow analysis and adaptive analysis variants are based upon the techniques in our prior work [9]; however, our study revealed deficiencies in those techniques so we generalized them substantially for this study. <p> However, reaping these benefits requires powerful inter-procedural analysis that must focus effort to avoid excessive cost. Both the simple local technique nor the traditional flow analysis proved insufficent. Fortunately, the adaptive inter-procedural analysis we employed <ref> [24] </ref> computes precise information efficiently. We begin by discussing our approach to inline allocation in Section 2 and presenting an example program in Section 3. Next, Section 4 describes the Concert System [7] in which work was done, and Section 5 details our three program analyses. <p> assume that unnecessary moves are eliminated, so the kind of creation (v) be one of call, phi, access, primitive or creation. creation (n) the node which creates n reaching (n) the set of nodes using n 4.2 The Analysis Framework The Concert compiler has a global analysis framework adaptive analysis <ref> [24, 23] </ref> that performs context sensitive flow analysis. The flow analysis ultimately builds a program-wide data-flow graph connecting the values within and across the individual method program graphs, with those values being specialized as needed by context sensitivity. <p> We explore three different analysis frameworks, ranging from local data-flow analysis to adaptive flow-sensitive analysis <ref> [24] </ref>. These frameworks allow us to explore the cost-effectiveness space of inlining analyses. Local Data Flow Conventional intra-procedural analysis which is fast, but limits the identification of inlinable fields to those for which both E f and R f confined to a single procedure. <p> But reaping these benefits requires powerful inter-procedural analysis that must focus effort to avoid excessive cost. Fortunately, the adaptive inter-procedural analysis we employed <ref> [24] </ref> computes precise information efficiently. Acknowledgments The Concert Compiler used for the experiments described in this paper has been the work of John Plevyak, Vijay Karamcheti, Xingbin Zhang and Hao-Hua Chu in addition to the present authors.
Reference: [25] <author> John Plevyak and Andrew A. Chien. </author> <title> Type directed cloning for object-oriented programs. </title> <booktitle> In Proceedings of the Workshop for Languages and Compilers for Parallel Computing, </booktitle> <pages> pages 566-580, </pages> <year> 1995. </year>
Reference-contexts: The combination of small methods and dynamic dispatch is a well-studied problem: dynamic dispatches are optimized statically by type inference [1, 6, 21, 24], dynamically by inline caching [16] or with hybrid approaches like type feedback [17]. Static or hybrid type analysis has been combined with method specialization <ref> [8, 25] </ref> to allow inlining, removing the small functions common in object-oriented code. Pervasive use of heap-allocated objects introduces overhead for memory management and repeated pointer dereference. This can both increase memory traffic and hurt local code efficiency by reducing opportunities for register allocation which inhibits many scalar optimizations.
Reference: [26] <author> Zhong Shao, John H. Reppy, and Andrew W. Ap-pel. </author> <title> Unrolling lists. </title> <booktitle> In ACM Conference on Lisp and Functional Programming, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: Our optimization is fully automatic and handles arbitrary user-defined object types. Due to the lazy semantics of Haskell, the transformation must be told what variables can be safely unboxed; furthermore, this transformation only unboxes immediate types. In <ref> [26] </ref>, Shao et al. unroll linked lists-essentially inline allocating tail pointers-in a functional subset of ML. Their analysis works using refinement types [13] that distinguish odd and even length lists. These refined types are propagated using an abstract interpretation, with rules for the refined types generated by cons statements.
Reference: [27] <author> Olin Shivers. </author> <title> Control flow analysis in scheme. </title> <booktitle> In SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 164-74. </pages> <publisher> ACM, </publisher> <year> 1988. </year>
Reference-contexts: We implemented three different program analyses. They all use data-flow properties to track how object fields are used and defined; the analysis frameworks employed are lo-cal data flow, traditional control flow analysis <ref> [27] </ref> and adaptive flow analysis [24]. The control flow analysis and adaptive analysis variants are based upon the techniques in our prior work [9]; however, our study revealed deficiencies in those techniques so we generalized them substantially for this study.
Reference: [28] <author> Olin Shivers. </author> <title> Control-Flow Analysis of Higher-Order Languages. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University Department of Computer Science, </institution> <address> Pitts-burgh, PA, </address> <month> May </month> <year> 1991. </year> <note> also CMU-CS-91-145. 18 </note>
Reference-contexts: This limitation could be mitigated by good procedure inlining heuristics. 5 (a) Pass One (b) Pass Two nCFA A conventional form of inter-procedural analysis with flow-sensitivity based on n of levels of calling context <ref> [28] </ref>. Because of compute cost exponential in n, only small values of n are practical. The context sensitivity of nCFA allows inlining of objects for which E f and R f span procedure boundaries.
Reference: [29] <author> Olin Shivers. </author> <title> Topics in Advanced Language Imple--mentation, chapter Data-Flow Analysis and Type Recovery in Scheme, </title> <address> pages 47-88. </address> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: Context sensitivity adapts to program structure, focusing analysis effort on interesting portions of the program. The unit of context sensitivity is the contour <ref> [29] </ref>, each of which represents an execution environment. For a given method, method contours can discriminate arbitrary data-flow properties of its caller and creator: caller the calling statement and contour. This covers arguments, allowing discrimination based upon data-flow properties of caller and its arguments. creator the object contour representing self.
Reference: [30] <author> Guy L. Steele Jr. </author> <title> Common LISP: The Language. </title> <note> Digital Press, second edition, </note> <year> 1990. </year>
Reference-contexts: 1 Introduction Object-oriented languages provide abstraction, allowing programmers to isolate conceptual portions of a given program behind opaque interfaces, with attendant benefits in code modularity and reusability. Languages such as Java [32], Lisp <ref> [30] </ref>, Pool [2] and Sather [31] provide this abstraction with opaque objects for which clients have a reference and an interface specification. This isolates the clients from any changes in a given object's implementation.
Reference: [31] <author> David Stoutamire and Stephen Omohundro. </author> <note> Sather 1.1, draft. Available online from http:// www.icsi.berkeley.edu/~sather/Sather-1.1.ps, August 1995. </note>
Reference-contexts: 1 Introduction Object-oriented languages provide abstraction, allowing programmers to isolate conceptual portions of a given program behind opaque interfaces, with attendant benefits in code modularity and reusability. Languages such as Java [32], Lisp [30], Pool [2] and Sather <ref> [31] </ref> provide this abstraction with opaque objects for which clients have a reference and an interface specification. This isolates the clients from any changes in a given object's implementation. Even fine-grained portions of a program, such as individual points for a graphics library, can be conveniently expressed in this manner.
Reference: [32] <author> Sun Microsystems Computer Corporation. </author> <title> The Java Language Specification, </title> <month> March </month> <year> 1995. </year> <note> Available at http://java.sun.com/1.0alpha2/doc/java-whitepaper.ps. </note>
Reference-contexts: 1 Introduction Object-oriented languages provide abstraction, allowing programmers to isolate conceptual portions of a given program behind opaque interfaces, with attendant benefits in code modularity and reusability. Languages such as Java <ref> [32] </ref>, Lisp [30], Pool [2] and Sather [31] provide this abstraction with opaque objects for which clients have a reference and an interface specification. This isolates the clients from any changes in a given object's implementation.
Reference: [33] <author> N. Wirth and J. Gutknecht. </author> <title> Project Oberon: The Design of an Operating System and Compiler. </title> <publisher> Ad-dison Wesley, </publisher> <year> 1992. </year>
Reference-contexts: Modify the allocation points to use the new object definitions 3. Rewrite all accesses to the child object's state as accesses to the inlined child object. 2.2 Explicit Inline Allocation Some programming languages <ref> [10, 33] </ref>, notably C++, allow programmers to manually specify inline object allocation to improve performance. As with the automatic approaches, the objective is to reduce storage management overhead as well as the number of pointer deref-erences required to execute a program.
References-found: 33

