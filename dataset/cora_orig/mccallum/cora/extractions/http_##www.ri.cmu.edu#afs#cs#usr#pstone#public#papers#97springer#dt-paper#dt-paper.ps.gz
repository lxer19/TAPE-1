URL: http://www.ri.cmu.edu/afs/cs/usr/pstone/public/papers/97springer/dt-paper/dt-paper.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs/usr/pstone/mosaic/pstone-papers.html
Root-URL: 
Email: fpstone,velosog@cs.cmu.edu  
Title: Using Decision Tree Confidence Factors for Multiagent Control  
Author: Peter Stone and Manuela Veloso 
Web: http://www.cs.cmu.edu/f~pstone,~mmvg  
Address: Pittsburgh, PA 15213  
Affiliation: Computer Science Department Carnegie Mellon University  
Abstract: Although Decision Trees are widely used for classification tasks, they are typically not used for agent control. This paper presents a novel technique for agent control in a complex multiagent domain based on the confidence factors provided by the C4.5 Decision Tree algorithm. Using Robotic Soccer as an example of such a domain, this paper incorporates a previously-trained Decision Tree into a full multiagent behavior that is capable of controlling agents throughout an entire game. Along with using Decision Trees for control, this behavior also makes use of the ability to reason about action-execution time to eliminate options that would not have adequate time to be executed successfully. This multiagent behavior represents a bridge between low-level and high-level learning in the Layered Learning paradigm. The newly created behavior is tested empirically in game situations.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Minoru Asada, Eiji Uchibe, Shoichi Noda, Sukoya Tawaratsumida, and Koh Hosoda. </author> <title> Coordination of multiple behaviors acquired by vision-based reinforcement learning. </title> <booktitle> In Proc. of IEEE/RSJ/GI International Conference on Intelligent Robots and Systems 1994 (IROS '94), </booktitle> <pages> pages 917-924, </pages> <year> 1994. </year>
Reference-contexts: Opportunities, and indeed demands, for innovative and novel techniques abound. Robotic Soccer systems have been recently developed both in simulation [6, 9, 12, 14] and with real robots <ref> [1, 4, 10, 11, 15, 13] </ref>. While robotic systems are difficult, expensive, and time-consuming to use, they provide a certain degree of realism that is never possible in simulation.
Reference: 2. <author> Mike Bowling, Peter Stone, and Manuela Veloso. </author> <title> Predictive memory for an inaccessible environment. </title> <booktitle> In Proceedings of the IROS-96 Workshop on RoboCup, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: The input of an RCF is the client's perception of the current state of the world. This perceived state includes both the agent's latest sensory perception and remembered past positions of currently unseen objects <ref> [2] </ref>. The output of an RCF is an action from among the options dribble, kick, or pass, and a direction, either in terms of a player (i.e. towards teammate number 4) or in terms of a part of the field (i.e. towards the goal). <p> For the purposes of this paper, "within 10m" is an empirically acceptable approximation. As mentioned above, this concept is not purely reactive: the positions of opponents that are outside an agent's field of view are remembered <ref> [2] </ref>. Similarly, the point of dribbling the ball (kicking the ball a small amount in a certain direction and staying with it) is to keep the ball for a little longer until a good pass becomes available or until the player is in a good position to shoot. <p> When turning away from the ball, it remembers the ball's location for a short amount of time; however after about three seconds, if it hasn't seen the ball, it assumes that it no longer knows where the ball is <ref> [2] </ref>. Once the ball has been located, the client can execute its behavior. As described in Section 3.1, each player is assigned a particular position on the field. Unless chasing the ball, the client goes to its position, moving around randomly within a small range of the position.
Reference: 3. <author> Andrew Garland and Richard Alterman. </author> <title> Multiagent learning through collective memory. In Adaptation, Coevolution and Learning in Multiagent Systems: </title> <booktitle> Papers from the 1996 AAAI Spring Symposium, </booktitle> <pages> pages 33-38, </pages> <address> Menlo Park,CA, </address> <month> March </month> <year> 1996. </year> <note> AAAI Press. AAAI Technical Report SS-96-01. </note>
Reference-contexts: This paper extends these basic learned behaviors into a full multiagent behavior that is capable of controlling agents throughout an entire game. This behavior makes control decisions based on the confidence factors associated with DT classifications|a novel approach. While operator success probabilities have previously been stored in tree structures <ref> [3] </ref>, our work makes use of confidence measures originally derived from learning classification tasks. It also makes use of the ability to reason about action-execution time to eliminate options that would not have adequate time to be executed successfully. The newly created behavior is tested empirically in game situations.
Reference: 4. <editor> Jong-Hwan Kim, editor. </editor> <booktitle> Proceedings of the Micro-Robot World Cup Soccer Tournament, </booktitle> <address> Taejon, Korea, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: Opportunities, and indeed demands, for innovative and novel techniques abound. Robotic Soccer systems have been recently developed both in simulation [6, 9, 12, 14] and with real robots <ref> [1, 4, 10, 11, 15, 13] </ref>. While robotic systems are difficult, expensive, and time-consuming to use, they provide a certain degree of realism that is never possible in simulation.
Reference: 5. <author> Hiroaki Kitano, Yasuo Kuniyoshi, Itsuki Noda, Minoru Asada, Hitoshi Matsubara, and Eiichi Osawa. </author> <title> RoboCup: A challenge problem for AI. </title> <journal> AI Magazine, </journal> <volume> 18(1):73--85, </volume> <month> Spring </month> <year> 1997. </year>
Reference-contexts: Extensive empirical results are reported in Section 4, and Section 5 concludes. 2 Foundational Work This section presents brief overviews of Robotic Soccer research and of Layered Learning. Further details with regards to both topics can be found in [13]. 2.1 Robotic Soccer As described in <ref> [5] </ref>, Robotic Soccer is an exciting AI domain for many reasons. The fast-paced nature of the domain necessitates real-time sensing coupled with quick behaving and decision making. <p> The differences in cumulative games won as the runs progress. time, will perform favorably against teams that cover our players unevenly so that the DT can find an open player to whom to pass. Indeed, it was used successfully as part of the CMUnited simulator team at RoboCup-97 <ref> [5] </ref> which was held at IJCAI-97.
Reference: 6. <author> Hitoshi Matsubara, Itsuki Noda, and Kazuo Hiraki. </author> <title> Learning of cooperative actions in multi-agent systems: a case study of pass play in soccer. In Adaptation, Coevolution and Learning in Multiagent Systems: </title> <booktitle> Papers from the 1996 AAAI Spring Symposium, </booktitle> <pages> pages 63-67, </pages> <address> Menlo Park,CA, </address> <month> March </month> <year> 1996. </year> <note> AAAI Press. AAAI Technical Report SS-96-01. </note>
Reference-contexts: Opportunities, and indeed demands, for innovative and novel techniques abound. Robotic Soccer systems have been recently developed both in simulation <ref> [6, 9, 12, 14] </ref> and with real robots [1, 4, 10, 11, 15, 13]. While robotic systems are difficult, expensive, and time-consuming to use, they provide a certain degree of realism that is never possible in simulation.
Reference: 7. <editor> Itsuki Noda and Hitoshi Matsubara. </editor> <booktitle> Soccer server and researches on multi-agent systems. In Proceedings of the IROS-96 Workshop on RoboCup, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: While much of the past research has used Machine Learning in constrained situations, nobody has yet developed a full behavior based on learning techniques that can be used successfully in a game situation. The Soccer Server <ref> [7] </ref>, which serves as the substrate system for the research reported in this paper, captures enough real-world complexities to be a very challenging domain.
Reference: 8. <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Then, using this learned skill, they learned a higher-level, more "social," skill: one that involves multiple players. The second skill, the ability to estimate the likelihood that a pass to a particular teammate will succeed, was learned using a Decision Tree (DT). The DT was trained using C4.5 <ref> [8] </ref> under the assumption that the player receiving the ball uses the trained NN when trying to receive the pass. This technique of incorporating one learned behavior as part of another is an important component of Layered Learning. <p> The DT algorithm used is C4.5 <ref> [8] </ref>, which automatically returns confidence factors along with classifications.
Reference: 9. <author> Michael K. Sahota. </author> <title> Dynasim user guide. </title> <note> http://www.cs.ubc.ca/nest/lci/soccer, January 1996. </note>
Reference-contexts: Opportunities, and indeed demands, for innovative and novel techniques abound. Robotic Soccer systems have been recently developed both in simulation <ref> [6, 9, 12, 14] </ref> and with real robots [1, 4, 10, 11, 15, 13]. While robotic systems are difficult, expensive, and time-consuming to use, they provide a certain degree of realism that is never possible in simulation.
Reference: 10. <author> Michael K. Sahota, Alan K. Mackworth, Rod A. Barman, and Stewart J. Kingdon. </author> <title> Real-time control of soccer-playing robots using off-board vision: the dynamite testbed. </title> <booktitle> In IEEE International Conference on Systems, Man, and Cybernetics, </booktitle> <pages> pages 3690-3663, </pages> <year> 1995. </year>
Reference-contexts: Opportunities, and indeed demands, for innovative and novel techniques abound. Robotic Soccer systems have been recently developed both in simulation [6, 9, 12, 14] and with real robots <ref> [1, 4, 10, 11, 15, 13] </ref>. While robotic systems are difficult, expensive, and time-consuming to use, they provide a certain degree of realism that is never possible in simulation.
Reference: 11. <author> Randy Sargent, Bill Bailey, Carl Witty, and Anne Wright. </author> <title> Dynamic object capture using fast vision tracking. </title> <journal> AI Magazine, </journal> <volume> 18(1) </volume> <pages> 65-72, </pages> <month> Spring </month> <year> 1997. </year>
Reference-contexts: Opportunities, and indeed demands, for innovative and novel techniques abound. Robotic Soccer systems have been recently developed both in simulation [6, 9, 12, 14] and with real robots <ref> [1, 4, 10, 11, 15, 13] </ref>. While robotic systems are difficult, expensive, and time-consuming to use, they provide a certain degree of realism that is never possible in simulation.
Reference: 12. <author> Peter Stone and Manuela Veloso. </author> <title> Beating a defender in robotic soccer: Memory-based learning of a continuous function. </title> <editor> In David S. Touretzky, Michael C. Mozer, and Michael E. Hasselmo, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 8, </booktitle> <pages> pages 896-902, </pages> <address> Cambridge, MA, 1996. </address> <publisher> MIT press. </publisher>
Reference-contexts: Opportunities, and indeed demands, for innovative and novel techniques abound. Robotic Soccer systems have been recently developed both in simulation <ref> [6, 9, 12, 14] </ref> and with real robots [1, 4, 10, 11, 15, 13]. While robotic systems are difficult, expensive, and time-consuming to use, they provide a certain degree of realism that is never possible in simulation.
Reference: 13. <author> Peter Stone and Manuela Veloso. </author> <title> A layered approach to learning client behaviors in the RoboCup soccer server. </title> <note> To appear in Applied AI Journal, </note> <year> 1998. </year>
Reference-contexts: Especially in domains that include independently designed agents with conflicting goals (adversaries), learning may allow agents to adapt to unforeseen behaviors on the parts of other agents. Layered Learning is an approach to complex multiagent domains that involves incorporating low-level learned behaviors into higher-level behaviors <ref> [13] </ref>. Using simulated Robotic Soccer (see Section 2) as an example of such a domain, a Neural Network (NN) was used to learn a low-level individual behavior (ball interception), which was then incorporated into a basic collaborative behavior (passing). The collaborative behavior was learned via a Decision Tree (DT) [13]. <p> behaviors <ref> [13] </ref>. Using simulated Robotic Soccer (see Section 2) as an example of such a domain, a Neural Network (NN) was used to learn a low-level individual behavior (ball interception), which was then incorporated into a basic collaborative behavior (passing). The collaborative behavior was learned via a Decision Tree (DT) [13]. This paper extends these basic learned behaviors into a full multiagent behavior that is capable of controlling agents throughout an entire game. This behavior makes control decisions based on the confidence factors associated with DT classifications|a novel approach. <p> Extensive empirical results are reported in Section 4, and Section 5 concludes. 2 Foundational Work This section presents brief overviews of Robotic Soccer research and of Layered Learning. Further details with regards to both topics can be found in <ref> [13] </ref>. 2.1 Robotic Soccer As described in [5], Robotic Soccer is an exciting AI domain for many reasons. The fast-paced nature of the domain necessitates real-time sensing coupled with quick behaving and decision making. <p> Opportunities, and indeed demands, for innovative and novel techniques abound. Robotic Soccer systems have been recently developed both in simulation [6, 9, 12, 14] and with real robots <ref> [1, 4, 10, 11, 15, 13] </ref>. While robotic systems are difficult, expensive, and time-consuming to use, they provide a certain degree of realism that is never possible in simulation. <p> We use a hierarchical, bottom-up approach. Two low-level behaviors have been previously learned. The work reported in this paper creates a team behavior that facilitates higher-level learning. To date, two levels of learned behaviors have been implemented <ref> [13] </ref>. First, Soccer Server clients used a Neural Network (NN) to learn a low-level individual skill: how to intercept a moving ball. Then, using this learned skill, they learned a higher-level, more "social," skill: one that involves multiple players. <p> However, the resulting behaviors have not yet been tested in full game situations. In this paper, we examine the effectiveness in game situations of the DT learned in <ref> [13] </ref>. To our knowledge, this paper reports the first use of confidence factors from DTs for agent control.
Reference: 14. <author> Peter Stone and Manuela Veloso. </author> <title> Towards collaborative and adversarial learning: A case study in robotic soccer. </title> <journal> in International Journal of Human-Computer Systems (IJHCS), </journal> <volume> 48, </volume> <year> 1998. </year>
Reference-contexts: Opportunities, and indeed demands, for innovative and novel techniques abound. Robotic Soccer systems have been recently developed both in simulation <ref> [6, 9, 12, 14] </ref> and with real robots [1, 4, 10, 11, 15, 13]. While robotic systems are difficult, expensive, and time-consuming to use, they provide a certain degree of realism that is never possible in simulation.
Reference: 15. <author> Manuela Veloso, Peter Stone, Kwun Han, and Sorin Achim. CMUnited: </author> <title> A team of robotic soccer agents collaborating in an adversarial environment. </title> <editor> In H. Kitano, editor, RoboCup-97: </editor> <title> The First Robot World Cup Soccer Games and Conferences. </title> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1998, </year> <title> in this volume. This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: Opportunities, and indeed demands, for innovative and novel techniques abound. Robotic Soccer systems have been recently developed both in simulation [6, 9, 12, 14] and with real robots <ref> [1, 4, 10, 11, 15, 13] </ref>. While robotic systems are difficult, expensive, and time-consuming to use, they provide a certain degree of realism that is never possible in simulation.
References-found: 15

