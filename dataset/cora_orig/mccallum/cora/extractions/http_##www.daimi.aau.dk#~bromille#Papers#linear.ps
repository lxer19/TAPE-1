URL: http://www.daimi.aau.dk/~bromille/Papers/linear.ps
Refering-URL: http://www.daimi.aau.dk/~bromille/Papers/index.html
Root-URL: http://www.daimi.aau.dk
Email: E-mail: dietzf@ls2.informatik.uni-dortmund.de.  E-mail: bromille@brics.dk.  E-mail: erez@dimacs.rutgers.edu.  E-mail: tardos@cs.elte.hu.  
Title: Is Linear Hashing Good? worst possible, since with respect to a universal class of hash
Author: Noga Alon Martin Dietzfelbinger Peter Bro Miltersen Erez Petrank Gabor Tardos p p 
Web: O(2  
Address: Dortmund, D-44221 Dortmund, Germany.  Aarhus, Ny Munkegade, Aarhus, Denmark.  P.O.Box 1179, Piscataway, NJ 08855-1179, USA.  
Affiliation: Fachbereich Informatik, Lehrstuhl II, Universitat  University of  University of Toronto. DIMACS,  University of Toronto. Mathematical Institute of the Hungarian Academy of Sciences,  University of Toronto.  
Note: n. (This is  Partially supported by DFG grant Di 412/5-1. BRICS, Centre of the Danish National Research Foundation,  Supported by the ESPRIT Long Term Research Programme of the EU under project number 20244 (ALCOM-IT).  Part of this work was done while the author was at the  Part of this work was done while the author was visiting the  Pf. 127, Budapest, H-1364 Hungary and Institute for Advanced Study, Princeton, NJ 08540. Supported by NSF grants CCR-95-03254 and DMS-9304580, a grant from Fuji Bank and the grant OTKA-F014919.  Part of this work was done while the author was visiting the  for this class was  
Abstract: Consider the set H of all linear (or affine) transformations between two vector spaces over a finite field F . We study how good H is as a class of hash functions, namely we consider hashing a set S of size n into a range having the same cardinality n by a randomly chosen function from H and look at the expected size of the largest hash bucket. H is a universal class of hash functions for any finite field, but with respect to our measure different fields behave differently. If the finite field F has n elements then there is a bad set S ae F 2 of size n with expected maximal bucket size (n 1=3 ). If n is a perfect square then there is even a bad set with largest bucket size always at least fl Dep. of Math., Sackler Faculty of Exact Sciences, Tel Aviv University, Tel Aviv, Israel and Institute for Advanced Study, Princeton, NJ 08540. Research supported in part by a USA-Israeli BSF grant, by the Sloan Foundation grant No. 96-6-2 and by an NEC Research Institute grant. E-mail: noga@math.tau.ac.il. If, however, we consider the field of two elements then we get much better bounds. The best previously known upper bound on the expected size of the largest bucket log n ). We reduce this upper bound to O(log n log log n). Note that this is not far from the guarantee for a random function. There, the average largest bucket would be fi(log n= log log n). In the course of our proof we develop a tool which may be of independent interest. Suppose we have a subset S of a vector space D over Z 2 , and consider a random linear mapping of D to a smaller vector space R. If the cardinality of S is larger than c * jRj log jRj then with probability 1 *, the image of S will cover all elements in the range. p
Abstract-found: 1
Intro-found: 1
Reference: [ABI86] <author> N. Alon, L. Babai and A. Itai, </author> <title> A fast and simple randomized parallel algorithm for the maximal independent set problem. </title> <journal> J. </journal> <note> Algorithms 7 (1986) 567-583. </note>
Reference-contexts: One immediate such result is obtained by looking at the class of d-degree polynomials over finite fields, where d = c log n= log log n (see, e.g., <ref> [ABI86] </ref>.) It is easy to see that this class maps each d elements of the domain independently to the range, and thus, the bound that applies to the class of all functions also applies to this class.
Reference: [ABM87] <author> N. Alon, A. Barak and U. Manber, </author> <title> On disseminating information reliably without broadcasting, </title> <booktitle> in: Proc. 7th International Conference on Distributed Computing Systems (ICDS), </booktitle> <address> Berlin, </address> <year> 1987, </year> <pages> pp. 74-81. </pages>
Reference-contexts: Imagine the vectors v 1 ; : : : ; v s being chosen one by one and consider v 1 ; : : : ; v i fixed and thus ff i determined. By Lemma 4.2 E (ff i+1 ) = ff 2 Following the (simple) idea in <ref> [ABM87] </ref>, we want to say that the choice of v i+1 is successful if ff i+1 is small enough with respect to ff i . The decrease of ff i is different depending on ff i being greater or less than 1=2.
Reference: [AS92] <author> N. Alon and J. H. Spencer, </author> <title> The Probabilistic Method, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: Then, we check the probability that in the remaining ss 0 steps we get that ff s &lt; 2 m . Applying Chernoff's bound (similarly to Corollary A.7 in Appendix A of <ref> [AS92] </ref>) implies that the probability that we do not have at least 9 log C successful choices out of the choices of v 1 ; : : :; v s 0 is at most *=3.
Reference: [AHNR95] <author> A. Andersson, T. Hagerup, S. Nilsson, and R. Raman, </author> <title> Sorting in linear time?, </title> <booktitle> in: Proc. 27th ACM Symposium on Theory of Computing, </booktitle> <year> 1995, </year> <pages> pp. 427-436. </pages>
Reference-contexts: Examples of the families we have in mind include: Arithmetic over Z p [CW79, FKS84] (with h k (x) = (kx mod p) mod n), integer multiplication <ref> [DHKP93, AHNR95] </ref> (with h a (x) = (ax mod 2 k ) div 2 kl ), Boolean convolution [MNT93] (with h a (x) = a ffi x projected to some subspace).
Reference: [CW79] <author> J. L. Carter and M. N. Wegman, </author> <title> Universal classes of hash functions, </title> <institution> J. Comput. Syst. Sci. </institution> <month> 18 </month> <year> (1979) </year> <month> 143-154. </month>
Reference-contexts: 1 Introduction 1.1 Results The seminal paper of Carter and Wegman <ref> [CW79] </ref> introduced the concept of universal hashing. The setting is as follows. A class H of hash functions, each mapping a universe U to f1; 2; : : : ; sg, is fixed. <p> The families from [S89] and [DM90] are somewhat complex to implement while the class of linear mappings requires only very basic bit operations (as discussed already in <ref> [CW79] </ref>). It is therefore desirable to study this class, and this is the main purpose of the present paper. 1.4 Notation If S is a subset of the domain D of a function h we use h (S) to denote fh (s) j s 2 Sg. <p> Examples of the families we have in mind include: Arithmetic over Z p <ref> [CW79, FKS84] </ref> (with h k (x) = (kx mod p) mod n), integer multiplication [DHKP93, AHNR95] (with h a (x) = (ax mod 2 k ) div 2 kl ), Boolean convolution [MNT93] (with h a (x) = a ffi x projected to some subspace).
Reference: [CLR90] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest, </author> <title> Introduction to Algorithms, </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: what the right bound is for the class of linear mappings, i.e., is it as good as O (log s= log log s)? We leave this as an open question. 1.2 Motivation There is no doubt that the method of implementing a dictionary by hashing with chaining, recommended in textbooks <ref> [CLR90, GBY90] </ref> especially for situations with many update operations, is a practically important scheme.
Reference: [DHKP93] <author> M. Dietzfelbinger, T. Hagerup, J. Katajai-nen, and M. Penttonen, </author> <title> A reliable randomized algorithm for the closest-pair problem, </title> <type> Technical Report 513, </type> <institution> Fachbereich Infor-matik, Universitat Dortmund, </institution> <year> 1993. </year>
Reference-contexts: Examples of the families we have in mind include: Arithmetic over Z p [CW79, FKS84] (with h k (x) = (kx mod p) mod n), integer multiplication <ref> [DHKP93, AHNR95] </ref> (with h a (x) = (ax mod 2 k ) div 2 kl ), Boolean convolution [MNT93] (with h a (x) = a ffi x projected to some subspace).
Reference: [DM90] <editor> M. Dietzfelbinger and F. Meyer auf der Heide, </editor> <title> Dynamic hashing in real time, </title> <editor> in: J. Buchmann, H. Ganzinger, W. J. Paul (Eds.): </editor> <booktitle> Informatik Festschrift zum 60. </booktitle> <editor> Geburtstag von Gunter Hotz, </editor> <title> Teubner-Texte zur Informatik, Band 1, </title> <editor> B. G. </editor> <publisher> Teubner, </publisher> <year> 1992, </year> <pages> pp. </pages> <month> 95-119. </month> <title> (A preliminary version appeared under the title "A New Universal Class of Hash Functions and Dynamic Hashing in Real Time" in ICALP'90.) </title> <editor> [DKMHRT94] M. Dietzfelbinger, A. Karlin, K. Mehlhorn, F. Meyer Auf Der Heide, H. </editor> <title> Rohnert, R.E. Tarjan, Dynamic perfect hashing: upper and lower bounds, </title> <journal> SIAM J. Comput. </journal> <month> 23 </month> <year> (1994) </year> <month> 738-761. </month>
Reference-contexts: For other simple hash classes such bounds on the worst case bucket size are not available or are even wrong (see Theorem 4); other, more sophisticated hash families <ref> [S89, DM90, DGMP92] </ref> that do guarantee small maximal bucket sizes consist of functions with higher evaluation time. <p> time for certain operations is absolutely necessary, the known two-level hashing schemes can be used, e. g., the FKS scheme [FKS84] for static dictionaries; dynamic perfect hashing [DKMHRT94] for the dynamic case with constant time lookups and expected time O (n) for n update operations; and the "real-time dictionaries" from <ref> [DM90] </ref> that perform each operation in constant time, with high probability. <p> More efficient (but much larger) families where given by Siegel [S89] and by Dietzfelbinger and Meyer auf der Heide <ref> [DM90] </ref>. Both provide families of size jU j n * such that the functions can be evaluated in O (1) time on a RAM and with L n n = fi (log n= log log n). The families from [S89] and [DM90] are somewhat complex to implement while the class of <p> [S89] and by Dietzfelbinger and Meyer auf der Heide <ref> [DM90] </ref>. Both provide families of size jU j n * such that the functions can be evaluated in O (1) time on a RAM and with L n n = fi (log n= log log n). The families from [S89] and [DM90] are somewhat complex to implement while the class of linear mappings requires only very basic bit operations (as discussed already in [CW79]).
Reference: [DGMP92] <author> M. Dietzfelbinger, J. Gil, Y. Matias, and N. Pippenger, </author> <title> Polynomial hash functions are reliable, </title> <publisher> ICALP'92, Springer LNCS 623, </publisher> <pages> pp. 235-246. </pages>
Reference-contexts: For other simple hash classes such bounds on the worst case bucket size are not available or are even wrong (see Theorem 4); other, more sophisticated hash families <ref> [S89, DM90, DGMP92] </ref> that do guarantee small maximal bucket sizes consist of functions with higher evaluation time.
Reference: [FKS84] <author> M. L. Fredman, J. Komlos, and E. Sze-meredi, </author> <title> Storing a sparse table with O(1) worst case access time, </title> <journal> J. Ass. Comput. Mach. </journal> <month> 31 </month> <year> (1984) </year> <month> 538-544. </month>
Reference-contexts: Of course, if worst case constant time for certain operations is absolutely necessary, the known two-level hashing schemes can be used, e. g., the FKS scheme <ref> [FKS84] </ref> for static dictionaries; dynamic perfect hashing [DKMHRT94] for the dynamic case with constant time lookups and expected time O (n) for n update operations; and the "real-time dictionaries" from [DM90] that perform each operation in constant time, with high probability. <p> Examples of the families we have in mind include: Arithmetic over Z p <ref> [CW79, FKS84] </ref> (with h k (x) = (kx mod p) mod n), integer multiplication [DHKP93, AHNR95] (with h a (x) = (ax mod 2 k ) div 2 kl ), Boolean convolution [MNT93] (with h a (x) = a ffi x projected to some subspace).
Reference: [GBY90] <author> G. Gonnet and R. Baeza-Yates, </author> <title> Handbook of Algorithms and Data Structures, </title> <publisher> Addison-Wesley, </publisher> <year> 1991. </year>
Reference-contexts: what the right bound is for the class of linear mappings, i.e., is it as good as O (log s= log log s)? We leave this as an open question. 1.2 Motivation There is no doubt that the method of implementing a dictionary by hashing with chaining, recommended in textbooks <ref> [CLR90, GBY90] </ref> especially for situations with many update operations, is a practically important scheme.
Reference: [GR90] <author> S. W. Graham and C. J. Ringrose, </author> <title> Lower bounds for least quadratic nonresidues, in: Analytic Number Theory: </title> <booktitle> Proceedings of a Conference in Honor of P.T. </booktitle> <editor> Bateman, B. C. Berndt et al. (Eds.), </editor> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: Note that for ev ery nonzero element a 2 Z p , the set aS ( mod p) is either the set of all quadratic residues or the set of all quadratic non-residues modulo p. The main result of Graham and Ringrose <ref> [GR90] </ref> asserts that for infinitely many primes p, the smallest quadratic non-residue modulo p is at least (log p log log log p) (this result holds for primes p j 3 ( mod 4) as well, as follows from the remark in the end of [GR90]). <p> result of Graham and Ringrose <ref> [GR90] </ref> asserts that for infinitely many primes p, the smallest quadratic non-residue modulo p is at least (log p log log log p) (this result holds for primes p j 3 ( mod 4) as well, as follows from the remark in the end of [GR90]).
Reference: [MCW78] <author> G. Markowsky, J. L. Carter, and M. N. Wegman, </author> <title> Analysis of a universal class of hash functions, </title> <booktitle> in: Proc. 7th Conference on Math. Found. of Computer Science (MFCS), 1978, </booktitle> <publisher> Springer LNCS 64, </publisher> <pages> pp. 345-354. </pages>
Reference-contexts: For this class, Markowsky, Carter and Wegman <ref> [MCW78] </ref> showed that L s s (H) = O (s 1=4 ). Mehlhorn and Vishkin [MV84] improved on this result (although this is implicit in their paper) and showed that L s s (H) = O (2 log s ).
Reference: [MV84] <author> K. Mehlhorn and U. Vishkin, </author> <title> Randomized and deterministic simulations of PRAMs by parallel machines with restricted granularity of parallel memories., </title> <note> Acta Informatica 21 (1984) 339-374. </note>
Reference-contexts: For this class, Markowsky, Carter and Wegman [MCW78] showed that L s s (H) = O (s 1=4 ). Mehlhorn and Vishkin <ref> [MV84] </ref> improved on this result (although this is implicit in their paper) and showed that L s s (H) = O (2 log s ).
Reference: [MNT93] <author> Y. Mansour, N. Nisan, and P. Tiwari, </author> <title> The computational complexity of universal hashing. </title> <note> Theoretical Computer Science 107 (1993) 121-133. </note>
Reference-contexts: Examples of the families we have in mind include: Arithmetic over Z p [CW79, FKS84] (with h k (x) = (kx mod p) mod n), integer multiplication [DHKP93, AHNR95] (with h a (x) = (ax mod 2 k ) div 2 kl ), Boolean convolution <ref> [MNT93] </ref> (with h a (x) = a ffi x projected to some subspace). Another question is whether there exists a class H of size only 2 O (log log jUj+log n) and with L n n (H) = O (log n= log log n).
Reference: [PA95] <author> J. Pach and P. K. Agarwal, </author> <title> Combinatorial Geometry, </title> <publisher> Wiley 1995. </publisher>
Reference-contexts: Clearly jS 0 j &lt; n. It is well known that each of the n most popular lines contains at least m n 1=3 =3 points of S 0 . This is usually proved for the same grid in the Euclidean plane (see e.g. <ref> [PA95] </ref>, pp. 178-179)) but that result implies the same for our grid in F 2 . Now let n = p k and let F 0 be the subfield in F of p elements.
Reference: [S89] <author> A. Siegel, </author> <title> On universal classes of fast high performance hash functions, their time-space tradeoff, and their application, </title> <booktitle> in: Proc. 30th IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1989, </year> <pages> pp. 20-25. </pages>
Reference-contexts: For other simple hash classes such bounds on the worst case bucket size are not available or are even wrong (see Theorem 4); other, more sophisticated hash families <ref> [S89, DM90, DGMP92] </ref> that do guarantee small maximal bucket sizes consist of functions with higher evaluation time. <p> More efficient (but much larger) families where given by Siegel <ref> [S89] </ref> and by Dietzfelbinger and Meyer auf der Heide [DM90]. Both provide families of size jU j n * such that the functions can be evaluated in O (1) time on a RAM and with L n n = fi (log n= log log n). The families from [S89] and [DM90] <p> by Siegel <ref> [S89] </ref> and by Dietzfelbinger and Meyer auf der Heide [DM90]. Both provide families of size jU j n * such that the functions can be evaluated in O (1) time on a RAM and with L n n = fi (log n= log log n). The families from [S89] and [DM90] are somewhat complex to implement while the class of linear mappings requires only very basic bit operations (as discussed already in [CW79]).
Reference: [VC71] <author> V. A. Vapnik and A. Y. Chervonenkis, </author> <title> On the uniform convergence of relative frequencies of events to their probabilities, </title> <journal> Theory of Prob. </journal> <note> Applications 16 (1971) 264-280. </note>
Reference-contexts: Thus, the probability of E 1 must be small. We remark here that a somewhat similar line of reasoning was used in the seminal paper of Vapnik and Chervonenkis <ref> [VC71] </ref>. This main line of the proof is presented in Section 5. In order to show these lower and upper bounds on the probability, we use the following tool which may be of independent interest.
References-found: 18

