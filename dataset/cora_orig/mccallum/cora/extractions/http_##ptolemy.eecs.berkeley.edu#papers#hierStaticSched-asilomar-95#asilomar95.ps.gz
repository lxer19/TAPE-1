URL: http://ptolemy.eecs.berkeley.edu/papers/hierStaticSched-asilomar-95/asilomar95.ps.gz
Refering-URL: http://ptolemy.eecs.berkeley.edu/papers/hierStaticSched-asilomar-95/
Root-URL: 
Author: Jos Luis Pino e Coo pe r at i ve Re s ea r c h 
Affiliation: Cadence, Dolby, Hitachi, Mentor Graphics, Mitsubishi, NEC, Pacific Bell, Philips, Rockwell, Sony, and Synopsys.  
Note: 6 Conclusions Acknowledgments This research is part of the Ptolemy project, which is supported by the Advanced Research Projects Agency and the U.S. Air Force (under the RASSP program, contract F33615-93-C-1317), Semiconductor Research Corporation (project 94-DC-008), National Science Foundation (MIP-9201605), Office of Naval Technology (via Naval Research Laboratories), the State of California MICR O program, and the following companies: Bell Northern Research,  is also supported by A T&T Be ll La b or a tor ie s as pa r t of th  Fellowship Program. References  
Abstract: schedulers on the final clusters, we are able to realize a s i g n i fi c a n t i m p r o v e m e n t i n m e m o r y u s a g e . T h i s improvement in memory is particularly e vident in the acoustic 320 bps quadrature amplitude modulation (4-QAM) acoustical modem, where the multiprocessor schedule generated from the fully e xpanded DAG has one function call (or inlined procedure) for each of its 9267 nodes as compared to only 59 function calls for the hierarchical schedule. In the case of all three modem examples, where the DSP card only has access to 16K of me mor y, th is f ra me wo rk en ab le d th e synth es is o f applications previously not possible using full D AG expansion multiprocessor scheduling techniques. We have developed a hierarchical scheduling framework for SDF graphs being mapped onto multiple processors. Using user specified clustering, this frame work has dramatically improved the scheduling time and reduced the memory requirements needed in the generated system. In some cases, the hierarchical scheduling framework enabled the synthesis of applications previously impossible. To test whether a given clustering step is valid, we have developed the SDF composition theorem. This theorem is significantly more general than those that ha ve been developed in previous work and can be tested efficiently. We plan to implement more automated clustering heuristics for use on the SDF graph before the SDF to DAG translation. As with the adaptation of Sarkar s clustering heuristic, these will be inspired by the D AG clustering heuristics found in other multiprocessor schedulers. The objective is to hide only the parallelism that w ould not be exploited in final multiprocessor scheduling phase, and in doing so, simplifying the DAG. [1] J. Buck, S. Ha, E.A. Lee, and D.G. Messerschmitt, Ptolemy: A framework for simulating and prototyping heterogeneous systems, International Journal of Computer Si mul at io n, sp eci al i ss ue o n Si mu lat io n So ft war e Development, vol. 4, 1994. http://ptolemy.eecs.berkeley.edu/papers/JEurSim [2] E.A. Lee and D.G. Messerschmitt, Synchronous data ow, Proceedings of the IEEE, vol. 75, no. 9, 1987. [3] J. L. P ino, S. S . Bhattach aryya, and E. A. Lee, A hierarchical multiprocessor scheduling framework for synchronous dataflo w gr aphs, UCB/ERL M95/36 , Electronics Research Laboratory, University of California at Berkeley, May 30, 1995. http://ptolemy.eecs.berkeley.edu/ papers/erl-95-36 [4] A. Gerasoulis and T. Yang, A comparison of clustering heuristics for scheduling directed ac yclic graphs on multiprocessors, Journal of Parallel and Distributed Computing, vol. 16, no. 4, 1992. [5] S.J. Kim and J.C. Browne, A general approach to mapping of parallel computations upon multiprocessor architectures, International Conference on Parallel Processing, vol. 3, University Park, PA, USA, Pennsylvania State Univ, 1988. [6] V. Sarkar, Partitioning and scheduling parallel programs for multiprocessors, Cambridge, Mass.: MIT Press, 1989. [7] G. C. Sih, Multiprocessor scheduling to account for interprocessor communication, Ph.D. Dissertation, UCB/ ERL M91/29, Electronics Research Laboratory, University of California at Berkeley, 1991. [8] H. Printz, Automatic mapping of large signal processing systems to a parallel machine, Ph.D. Dissertation CMU-CS-91-101, Carnegie Mellon, 1991. [9] S. S. Bhattacharyya, J. T. Buck, S. Ha, and E. A. Lee, Generating compact code from dataflow specifications of multirate signal processing algorithms, IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications, March, 1995. [10] S. S. Bhattacharyya, P. K. Murthy, and E. A. Lee, Two complementary heuristics for tr anslating graphical DSP p rog ra m s i n t o mi n im u m me m or y i mp l em e nt a ti o n s , Memorandum UCB/ERL M95/3, Electronics Research Laboratory, University of California at Berk eley, January, 1995. [11] S. Ritz, M. Pankert, and H. Meyr, Optimum vectorization of scalable synchronous dataflow graphs, Proceedings of the International Conference on ApplicationSpecific Array Processors, October, 1993. [12] S.S. Bhattacharyya, Compiling dataflow programs for digital signal processing, Ph.D. Dissertation UCB/ERL M94/52, University of California at Berkeley, 1994. [13] J.L. Pino and E.A. Lee, Hierarchical static scheduling of d a t a fl ow g r a p h s o n t o m u l t i p l e p r o c e s s o r s , I E E E International Conference on Acoustics, Speech, and Signal Processing, Detroit, Michigan, IEEE, 1995. http://ptolemy.eecs.berkeley.edu/papers/hierStaticSched 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Buck, S. Ha, E.A. Lee, and D.G. Messerschmitt, Ptolemy: </author> <title> A framework for simulating and prototyping heterogeneous systems, International Journal of Computer Si mul at io n, sp eci al i ss ue o n Si mu lat io n So ft war e Development, </title> <journal> vol. </journal> <volume> 4, </volume> <year> 1994. </year> <note> http://ptolemy.eecs.berkeley.edu/papers/JEurSim </note>
Reference: [2] <author> E.A. Lee and D.G. Messerschmitt, </author> <title> Synchronous data ow, </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 75, no. 9, </volume> <year> 1987. </year>
Reference: [3] <author> J. L. P ino, S. S . Bhattach aryya, and E. A. Lee, </author> <title> A hierarchical multiprocessor scheduling framework for synchronous dataflo w gr aphs, </title> <institution> UCB/ERL M95/36 , Electronics Research Laboratory, University of California at Berkeley, </institution> <month> May 30, </month> <year> 1995. </year> <note> http://ptolemy.eecs.berkeley.edu/ papers/erl-95-36 </note>
Reference: [4] <author> A. Gerasoulis and T. Yang, </author> <title> A comparison of clustering heuristics for scheduling directed ac yclic graphs on multiprocessors, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 16, no. 4, </volume> <year> 1992. </year>
Reference: [5] <author> S.J. Kim and J.C. Browne, </author> <title> A general approach to mapping of parallel computations upon multiprocessor architectures, </title> <booktitle> International Conference on Parallel Processing, </booktitle> <volume> vol. </volume> <pages> 3, </pages> <institution> University Park, PA, USA, Pennsylvania State Univ, </institution> <year> 1988. </year>
Reference: [6] <author> V. Sarkar, </author> <title> Partitioning and scheduling parallel programs for multiprocessors, </title> <address> Cambridge, Mass.: </address> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference: [7] <author> G. C. Sih, </author> <title> Multiprocessor scheduling to account for interprocessor communication, </title> <type> Ph.D. Dissertation, </type> <institution> UCB/ ERL M91/29, Electronics Research Laboratory, University of California at Berkeley, </institution> <year> 1991. </year>
Reference: [8] <author> H. Printz, </author> <title> Automatic mapping of large signal processing systems to a parallel machine, </title> <type> Ph.D. </type> <institution> Dissertation CMU-CS-91-101, Carnegie Mellon, </institution> <year> 1991. </year>
Reference: [9] <author> S. S. Bhattacharyya, J. T. Buck, S. Ha, and E. A. Lee, </author> <title> Generating compact code from dataflow specifications of multirate signal processing algorithms, </title> <journal> IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications, </journal> <month> March, </month> <year> 1995. </year>
Reference: [10] <author> S. S. Bhattacharyya, P. K. Murthy, and E. A. Lee, </author> <title> Two complementary heuristics for tr anslating graphical DSP p rog ra m s i n t o mi n im u m me m or y i mp l em e nt a ti o n s , Memorandum UCB/ERL M95/3, </title> <institution> Electronics Research Laboratory, University of California at Berk eley, </institution> <month> January, </month> <year> 1995. </year>
Reference: [11] <author> S. Ritz, M. Pankert, and H. Meyr, </author> <title> Optimum vectorization of scalable synchronous dataflow graphs, </title> <booktitle> Proceedings of the International Conference on ApplicationSpecific Array Processors, </booktitle> <month> October, </month> <year> 1993. </year>
Reference: [12] <author> S.S. Bhattacharyya, </author> <title> Compiling dataflow programs for digital signal processing, </title> <type> Ph.D. </type> <institution> Dissertation UCB/ERL M94/52, University of California at Berkeley, </institution> <year> 1994. </year>

References-found: 12

