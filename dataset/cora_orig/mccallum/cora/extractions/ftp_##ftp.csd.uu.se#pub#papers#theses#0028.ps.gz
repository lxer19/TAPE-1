URL: ftp://ftp.csd.uu.se/pub/papers/theses/0028.ps.gz
Refering-URL: http://www.csd.uu.se/papers/long-theses.html
Root-URL: 
Title: Exploiting Fine-grain Parallelism in Concurrent Constraint Languages  
Author: Johan Montelius 
Degree: A Dissertation to be submitted for the Degree of Doctor of Philosophy  
Note: Uppsala Thesis in Computing Science 28 SICS Dissertation Series 25 ISSN 0283-359X ISSN 1101-1335 ISBN 91-506-1215-8 ISRN SICS/D--25--SE  
Date: April 1997  
Address: Sweden  Box 311 Box 1263 SE-751 05 Uppsala, Sweden SE-164 29 Kista, Sweden  
Affiliation: Computing Science Department Uppsala University  Uppsala University Swedish Institute Computing Science Department of Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> S. Aditya, Arvind, J. Maessen, L. Augustsson, and R. S. Nikhil. </author> <title> Semantics of pH: A parallel dialect of Haskell. </title> <booktitle> In Proceedings from the Haskell Workshop (at FPCA 95), </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: ):- ? true. line (2, on, on, off):? true. line (2, on, off, on ):- ? true. line (2, off, on, on ):- ? true. line (3, on, on, on ):- ? true. 3.4.3 Simple solution The first problem is given by a horizontal image [2,0,1] and a vertical image <ref> [1, 0, 2] </ref>. The rays are ordered top to bottom and left to right. <p> The pH system is a parallel version of Haskell developed by Arvind's group at the MIT Lab for Computer Science, and Nikhil at the DEC Cambridge Research Lab <ref> [1] </ref>. The pH system is developed using experience gained in the work on Id, a functional language designed for data-flow machines [49]. One interesting feature in pH is the so-called I-structure. The data type is a record that can hold holes.
Reference: [2] <author> H. </author> <title> A it-Kaci. The WAM: A (real) tutorial. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Compound terms can have arbitrary number of arguments where each argument is a term. Following an old tradition we use a special syntax for lists. A list is either empty [] or contains one or more elements. [a], <ref> [f (a,b), 2] </ref>, [1,2,3,4],... We can also use a construct [A|Rest] to describe a list with A as its first element and Rest as the remaining, possibly empty, list of elements. <p> ):- ? true. line (2, on, on, off):? true. line (2, on, off, on ):- ? true. line (2, off, on, on ):- ? true. line (3, on, on, on ):- ? true. 3.4.3 Simple solution The first problem is given by a horizontal image [2,0,1] and a vertical image <ref> [1, 0, 2] </ref>. The rays are ordered top to bottom and left to right. <p> The abstract machines have served mainly as tool for language implementors. An abstract machine is often implemented in software although several machines have been at least partly implemented in hardware. The abstract machine presented in this chapter has borrowed many concepts from the Warren Abstract Machine (WAM) <ref> [72, 2] </ref>. 6.2 The execution state The execution state is divided into: a representation of the configuration which is shared between all workers, the structures that are local to each worker and the representation of the terms. All parts of the execution state are equally accessible to all workers.
Reference: [3] <author> K. A. M. Ali. </author> <title> A parallel copying garbage collection scheme for shared-memory multiprocessors. </title> <journal> New Generation Computing, </journal> <volume> 13(4), </volume> <month> December </month> <year> 1995. </year>
Reference-contexts: The system was implemented within a concurrent logic programming system called VPIM, a parallel KL1 emulator. The approach we have taken is a parallelization of a sequential stop-and-copy garbage collection scheme based on traversing active data in a depth-first manner proposed by Ali <ref> [3] </ref>. 8.5.1 Stop and copy The garbage collector is a stop-and-copy collector i.e. execution stops, the living data structures are copied to a new memory area and the old memory area is reclaimed [13]. <p> Ali, in his paper <ref> [3] </ref> proposes the idea for parallelizing the scanning of cells, by dividing the latter chain into a number of smaller sub-chains and to make them available to the other workers. Each chain is a piece of work that can be processed by any worker.
Reference: [4] <author> K. A. M. Ali and R. Karlsson. </author> <title> The MUSE or-parallel Prolog model and its performance. </title> <booktitle> In North American Conference on Logic Programming. </booktitle> <publisher> MIT Press, </publisher> <month> October </month> <year> 1990. </year>
Reference-contexts: If the solution is at the far left in the search tree two workers do not find the solution faster than one worker. The second worker only does speculative work. In a system that is targeted to or-parallel execution the ability to avoid doing speculative work is crucial <ref> [4] </ref>. 9.5.1 Speculative work A simple queens benchmark can be used to show how unproductive speculative work can be. The program finds one solution in a sixteen-queens puzzle using a short circuiting technique. <p> Only in the last years have systems been built that include both forms of parallelism while maintaining the Prolog execution model [24]. 10.2.1 Or-parallelism There are two challenges when building an or-parallel Prolog system, maintaining the multiple binding environments and minimizing speculative work <ref> [41, 4] </ref>. The binding schemes used in these systems are quite different from the scheme used in the Penny system. This is only natural since the execution state of a deep AKL program is very different from a Prolog execution.
Reference: [5] <author> G. A. M. A. Atlam. </author> <title> Parallel Garbage Collection in a Multiprocessors Implementation of a Concurrent Constraint Programming System. </title> <type> Phd thesis, </type> <institution> Menoufia University, Egypt, </institution> <month> January </month> <year> 1997. </year>
Reference-contexts: The scheme is flexible and has proved most useful. 8.5 Garbage collection The garbage collector was designed and implemented together with Galal Atlam and Khayri Ali. Both the strategy, its implementation, and performance has been described in the thesis by Galal <ref> [5] </ref>, this section will only be a brief overview. 1 Except during unification. This order need not be preserved. 120 The Implementation Parallel garbage collectors have a long history [27, 6, 20, 60]. The one that come closest to our implementation is the implementation by Imai and Tick [30].
Reference: [6] <author> H. G. Baker. </author> <title> List processing in real time on a serial computer. </title> <journal> Communications of the ACM, </journal> <volume> 21(4) </volume> <pages> 280-294, </pages> <year> 1978. </year>
Reference-contexts: Both the strategy, its implementation, and performance has been described in the thesis by Galal [5], this section will only be a brief overview. 1 Except during unification. This order need not be preserved. 120 The Implementation Parallel garbage collectors have a long history <ref> [27, 6, 20, 60] </ref>. The one that come closest to our implementation is the implementation by Imai and Tick [30]. They parallelized a stop-and-copy garbage collection scheme for shared-memory multiprocessors. The system was implemented within a concurrent logic programming system called VPIM, a parallel KL1 emulator.
Reference: [7] <author> U. Baron and et.al. </author> <title> The parallel ECRC Prolog system PEPSys: an overview and evaluation results. </title> <booktitle> In Proceedings of the International Conference of Fifth Generation Computer Systems, </booktitle> <pages> pages 841-850, </pages> <year> 1988. </year>
Reference-contexts: No comparison has been done for parallel execution since the ParAKL system does not run in parallel on the sparcCenter-2000. The implementation differs from the Penny system mainly in the handling of binding environment. The binding scheme in ParAKL is built using the PEPSys hashing scheme <ref> [7] </ref>. The workers maintain a shared tree of hash tables that are updated to reflect the binding environments of the different and-boxes. The hashing scheme is more complicated than the explicit binding scheme used in the Penny system.
Reference: [8] <author> P. S. Barth, R. S. Nikhil, and Arvind. M-structures: </author> <title> Extending a parallel, non-strict, functional language with state. </title> <booktitle> In Proceedings on Functional Programming and Computer Architecture, </booktitle> <pages> pages 28-30, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: The data type is a record that can hold holes. The holes can be assigned a value but only once. The I-structures are thus closely related to the variables used in logic programming languages. Another interesting feature in pH is the M-structure <ref> [8] </ref>. The structure allows multiple atomic updates and is similar to the cell construct provided in Oz in combination with a logical variable [64]. The M-structure solves the same problem as the port construct in Penny.
Reference: [9] <author> J. Bevemyr, T. Lindgren, and H. Millrot. </author> <title> Reform Prolog: the language and its implementation. </title> <editor> In D. S. Warren, editor, </editor> <booktitle> Proceedings of the Tenth International Conference on Logic Programming, </booktitle> <address> Budapest, Hungary, 1993. </address> <publisher> The MIT Press. </publisher>
Reference-contexts: An implementation of the scheme (DASWAM) shows good parallel performance. [62]. This system so far relies on user annotations to collect information about shared variable, but this can in the future be provided by a compiler. A radical approach was taken by the Reform group at Uppsala University <ref> [9] </ref>. Their approach was to limit the system to handle only and-parallelism generated in linear-recursive deterministic procedures. The system can still handle non-deterministic computations but this will limit the parallelism. The restriction is well chosen; deterministic procedures are the main source of parallelism in Prolog programs.
Reference: [10] <author> P. Brand. </author> <title> Performance of the AKL compiler. </title> <type> personal communication. </type>
Reference-contexts: Preliminary results from the new AGENTS compiler developed by Per Brand show figures that are as good as the figures for SICStus v3 <ref> [10] </ref>. This indicates that a better compiler and runtime system can speedup the sequential performance of the Penny system by a factor of two. Table 10.2 shows the execution time using the native code compiler of SICStus v3.
Reference: [11] <author> P. Brand. </author> <title> Decision graph compilation. </title> <booktitle> In Proceedings of the Twelfth International Conference on Logic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: In the Penny system only limited decision code has been implemented since a more carefully study and design has been worked out by Per Brand <ref> [11] </ref>. switch N Ls The switch instruction examines the term in argument register N and then proceed execution at one of the labels.
Reference: [12] <author> B. Carlsson. </author> <title> Compiling and Executing Finite Domain Constraints. </title> <institution> Uppsala thesis in computing science 21, SICS dissertation series 18, Uppsala University, SICS, </institution> <year> 1995. </year>
Reference-contexts: The Penny system 29 tionality provided by the AGENTS system. The syntactical restrictions do not limit the usefulness of the system as research platform. The AGENTS system includes a finite domain constraint solver but this has not been ported to the Penny system <ref> [12] </ref>. The system also included a feature called auto-closing. When all references of a port were lost, the stream of messages was closed i.e. bound to []. This is an attractive feature but is not easily implemented and has not been ported to the Penny system.
Reference: [13] <author> C. J. </author> <title> Cheney. A nonrecursive list compacting algorithm. </title> <journal> Communications of the ACM, </journal> <volume> 13(11) </volume> <pages> 677-678, </pages> <month> November </month> <year> 1970. </year>
Reference-contexts: sequential stop-and-copy garbage collection scheme based on traversing active data in a depth-first manner proposed by Ali [3]. 8.5.1 Stop and copy The garbage collector is a stop-and-copy collector i.e. execution stops, the living data structures are copied to a new memory area and the old memory area is reclaimed <ref> [13] </ref>. Copying garbage collector is attractive for systems that have a high rate of garbage generation, as in functional and logical programming languages. The garbage collection time is proportional to the amount of data in use by the system [50].
Reference: [14] <author> T. Chikayama. KLIC: </author> <title> a KL1 Implementation for Unix Systems. </title> <journal> New Generation Computing, </journal> <volume> 12(1) </volume> <pages> 123-124, </pages> <year> 1993. </year> <month> 198 </month>
Reference-contexts: All task must be executed sometime unless the computation fails. The question is more how task should be evenly distributed over the available processors. In some systems the distribution is under the programmers control <ref> [14] </ref> while others will make the distribution automatically either statically at compile time or dynamic during run time. In the Penny system we wanted to experiment with dynamic scheduling without any user annotations. <p> The languages was developed at ICOT in the Fifth Generation project and was used both to implement the operating system and various high-level application oriented programming languages [71]. The KLIC implementation of KL1 is efficient and supports shared-memory architectures as well as message passing and distributed architectures <ref> [14] </ref>. 182 Related Work System Penny KLIC hanoi 2.9s (1.0) 0.59 (0.20) kkqueen 2.7s (1.0) 0.22 (0.08) tsp 1.7s (1.0) 0.64 (0.39) mastermind 2.6s (1.0) 0.13 (0.05) matrix 2.5s (1.0) 0.26 (0.10) Table 10.4: Penny vs. KLIC The KLIC compiler compiles KL1 programs into C.
Reference: [15] <author> K. Clark and S. Gregory. </author> <title> PARLOG: </title> <booktitle> Parallel Programming in Logic, chapter 3, </booktitle> <pages> pages 84-139. </pages> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: be harmful since a worker will have to wait for other workers to perform their tasks before the next generation of border cells can be computed. 10.3.3 Deep guards Deep guards were used in the early committed choice languages for example Guarded Horn Clauses (GHC), Concurrent Prolog (CP) and PARLOG <ref> [15, 58, 70, 66] </ref>. These 184 Related Work languages used deep guards for complex deterministic tests. In CP the guard computation was allowed to make local bindings to external variables. This introduced a complexity in the implementation. <p> The deep guards were also later removed from the languages resulting in the flat committed choice programming languages. 10.3.4 Including non-determinism Non-determinism is included in PARLOG but the language makes a distinction between single-solution relations and all-solutions relations <ref> [15] </ref>. The single-solution relations provided concurrency whereas the all-solutions relations provided the non-determinism. A PARLOG program is at the top-level executing in single-solution mode but can through special constructs call goals defined by all-solutions relations.
Reference: [16] <author> J. Crammond. </author> <title> Implementation of Committed Choice Logic Languages on Shared Memory Multiprocessors. </title> <type> Phd thesis, </type> <institution> Heriot-Watt University, </institution> <year> 1988. </year>
Reference-contexts: The locking scheme, does not change the dereference procedure. This locking scheme has been proposed, by Jim Crammond, as a technique for locking multiple variables in a FCP <ref> [16] </ref>. The technique has also been used in the Super Monaco system, implemented by Evan Tick and his group [37]. 7.5.2 Hazards There are two possible hazards in the binding scheme: circular references and deadlock situations.
Reference: [17] <author> I. de Castro Duatra. </author> <title> Strategies for scheduling and- and or- work in parallel logic programming systems. </title> <editor> In M. Bruynooghe, editor, </editor> <booktitle> Proceedings of the 1994 International Logic Programming Symposium, </booktitle> <address> Ithaca, 1994. </address> <publisher> ALP, MIT Press. </publisher>
Reference-contexts: In flat committed choice languages and in and-parallel or or-parallel Prolog implementations there is only one type of parallelism to consider. The Andorra-I system is one of the few implementations where research on load balancing for both and-and or-parallel work has been conducted <ref> [17] </ref>. The Andorra-I system is however limited to and-parallel execution in each leaf of an or-tree. An AKL program differs from a Prolog or a KL1 program. We can have and-parallelism at all levels in the execution.
Reference: [18] <author> S. Debray and M. Jain. </author> <title> A simple program transformation for parallelism. </title> <editor> In M. Bruynooghe, editor, </editor> <booktitle> Proceedings of the 1994 International Logic Programming Symposium, </booktitle> <address> Ithaca, 1994. </address> <publisher> ALP, MIT Press. </publisher>
Reference-contexts: If we represent the matrix as a tree instead of a list (as in Figure 9.3.4), the system has no difficulties in obtaining good speedup even for matrices with small rows. Other techniques to transform sequential programs are described in <ref> [18, 28] </ref>. 9.4 Communicating processes The benchmarks in the previous section are all programs that divided up into more or less independent parts. The speedup is as expected good, the only problem is task granularity.
Reference: [19] <author> A. K. Dewdney. </author> <title> How to resurrect a cat from its grin. </title> <publisher> Scientific American, </publisher> <pages> pages 124 - 127, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: A CAT scanner can from a series of x-ray images, each taken from a different angle, make a cross-section image of a human body. A recreational form of the CAT scanner was presented by A.K.Dewdney, the problem was simplified to the reconstruction of a pattern in a rectangular grid <ref> [19] </ref>. The squares in the grid could have only one of two values: filled or empty. The x-ray image was reduced to a image where each ray traverses a line in the grid.
Reference: [20] <author> J. R. Ellis, K. Li, and A. W. Appel. </author> <title> Real-time concurrent collection on stock multiprocessors. </title> <booktitle> In SIGPLAN' 88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 11-20, </pages> <month> June </month> <year> 1988. </year> <note> Also Digital SRC Research Report number 25. </note>
Reference-contexts: Both the strategy, its implementation, and performance has been described in the thesis by Galal [5], this section will only be a brief overview. 1 Except during unification. This order need not be preserved. 120 The Implementation Parallel garbage collectors have a long history <ref> [27, 6, 20, 60] </ref>. The one that come closest to our implementation is the implementation by Imai and Tick [30]. They parallelized a stop-and-copy garbage collection scheme for shared-memory multiprocessors. The system was implemented within a concurrent logic programming system called VPIM, a parallel KL1 emulator.
Reference: [21] <author> I. Foster, R. Olson, and S. Tuecke. </author> <title> Productive parallel programming: The PCN approach. </title> <journal> Scientific Programming, </journal> <volume> 1(1) </volume> <pages> 51-66, </pages> <year> 1992. </year>
Reference-contexts: Non-determinism was abandoned at an early stage and the systems were then restricted to handle only flat guards [58, 68]. Some systems went even further and removed general unification, disallowed multiple readers of variables, and included imperative variables <ref> [22, 21] </ref>. 10.3.1 KLIC One of the systems that kept the logical variables in the language is KL1. The languages was developed at ICOT in the Fifth Generation project and was used both to implement the operating system and various high-level application oriented programming languages [71].
Reference: [22] <author> I. Foster and S. Taylor. Strand: </author> <title> A practical parallel programming language. </title> <booktitle> In Proceedings of the North American Conference on Logic Programming, </booktitle> <year> 1989. </year>
Reference-contexts: Non-determinism was abandoned at an early stage and the systems were then restricted to handle only flat guards [58, 68]. Some systems went even further and removed general unification, disallowed multiple readers of variables, and included imperative variables <ref> [22, 21] </ref>. 10.3.1 KLIC One of the systems that kept the logical variables in the language is KL1. The languages was developed at ICOT in the Fifth Generation project and was used both to implement the operating system and various high-level application oriented programming languages [71].
Reference: [23] <author> T. Franzen. </author> <title> Some formal aspects of AKL. </title> <institution> SICS Research Report R94:10, Swedish Institute of Computer Science, </institution> <year> 1994. </year>
Reference-contexts: The operational semantics is also important when alternative language constructs are discussed. The Penny computation model is based on the description of AKL in [32]. The semantics of AKL has also been described in [33], and <ref> [23] </ref>. The Penny computation model is simplified compared to the original AKL computation model. The original model is more general and is better suited when alternative language constructs is discussed.
Reference: [24] <author> G. Gupta, M. Hermenegildo, E. Pontelli, and V. Santos Costa. </author> <title> ACE: and/or-parallel copying-based execution of logic programs. </title> <editor> In P. van Hentenryck, editor, </editor> <booktitle> Proceedings of the Eleventh International Conference on Logic Programming, </booktitle> <pages> pages 93-109, </pages> <address> Santa Marherita Ligure, Italy, 1994. </address> <publisher> The MIT Press. </publisher>
Reference-contexts: Only in the last years have systems been built that include both forms of parallelism while maintaining the Prolog execution model <ref> [24] </ref>. 10.2.1 Or-parallelism There are two challenges when building an or-parallel Prolog system, maintaining the multiple binding environments and minimizing speculative work [41, 4]. The binding schemes used in these systems are quite different from the scheme used in the Penny system. <p> Nor is it possible to encapsulate non-deterministic computations, a deficiency that makes it hard to design reactive systems that also exploits the non-determinism. In ACE, a system based on a parallel copying execution scheme, each node in an or-parallel execution can be executed using and-parallelism <ref> [24] </ref>. The scheme combines the execution mechanism of MUSE and &-Prolog. The combination of the to models introduces implementation complexity. The exploited parallelism is similar to the Andorra-I system, but the ACE system does not change the execution model of the language.
Reference: [25] <author> G. Gupta and B. Jayaraman. </author> <title> On criteria for or-parallel execution models of logic programs. </title> <editor> In S. Debray and M. Hermenegildo, editors, </editor> <booktitle> Proceedings of the 1990 North American Conference on Logic Programming, </booktitle> <pages> pages 737-756, </pages> <address> Austin, 1990. </address> <publisher> ALP, MIT Press. </publisher>
Reference-contexts: There is no need to put to much work into an efficient implementation of these cases. It is more important to keep the implementation as simple as possible in order to be able to implement them correctly. 106 The Binding Scheme 7.7 Related work Gopal Gupta and Bharat Jayarama <ref> [25] </ref> describe criteria for or-parallel execution models of logic programs. Comparing the Penny scheme with or-parallel Prolog models is however not straightforward. The implementation of choice splitting sacrifices constant-time task creation whereas the binding scheme sacrifices constant-time variable access.
Reference: [26] <author> R. H. Halstead. </author> <title> Multilisp: A language for concurrent symbolic computation. </title> <journal> In ACM Transactions on Programming Languages and Systems, </journal> <volume> volume 7, </volume> <pages> pages 501-538, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: The functional systems are easier to implement since they do not handle logical variables and consequently not encapsulated computation spaces. The flat sub-set of AKL does however have many similarities with the functional programming languages. The Multilisp system was one of the first systems that exploited implicit parallelism <ref> [26] </ref>. It is a system that is similar in its approach to the Penny system in that it created the tasks on demand.
Reference: [27] <author> R. H. Halstead Jr. </author> <title> Multilisp: A language for concurrent symbolic computation. </title> <journal> ACM Transactions Programming Languages and Systems, </journal> <volume> 7(4) </volume> <pages> 501-538, </pages> <month> October </month> <year> 1985. </year> <month> 199 </month>
Reference-contexts: Both the strategy, its implementation, and performance has been described in the thesis by Galal [5], this section will only be a brief overview. 1 Except during unification. This order need not be preserved. 120 The Implementation Parallel garbage collectors have a long history <ref> [27, 6, 20, 60] </ref>. The one that come closest to our implementation is the implementation by Imai and Tick [30]. They parallelized a stop-and-copy garbage collection scheme for shared-memory multiprocessors. The system was implemented within a concurrent logic programming system called VPIM, a parallel KL1 emulator.
Reference: [28] <author> M. Hermenegildo and M. Carro. </author> <title> Relating data-parallelism and (and-) parallelism in logic programs. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> 966, </volume> <pages> pages 27-41. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: If we represent the matrix as a tree instead of a list (as in Figure 9.3.4), the system has no difficulties in obtaining good speedup even for matrices with small rows. Other techniques to transform sequential programs are described in <ref> [18, 28] </ref>. 9.4 Communicating processes The benchmarks in the previous section are all programs that divided up into more or less independent parts. The speedup is as expected good, the only problem is task granularity.
Reference: [29] <author> M. Hermenegildo and F. Rossi. </author> <title> Strict and non-strict independent and-parallelism in logic programs: Correctness, efficiency, and compile-time conditions. </title> <journal> Journal of Logic Programming, </journal> <volume> 22(1), </volume> <month> January </month> <year> 1995. </year>
Reference-contexts: The first schemes implemented various forms of independent and-parallelism. The problem is how to detect that computations are independent. Compile-time analysis is sometimes not enough and must therefore be complemented with runtime tests <ref> [29] </ref>. When dependent computations are executed in parallel the big problem is how to handle non-determinism. Various solutions have been proposed that vary in their degree of providing unrestricted parallelism [53]. The Dynamic Dependent And-parallel Scheme (DDAS) proposed by Kish Shen is so far the most promising [61].
Reference: [30] <author> A. Imai and E. Tick. </author> <title> Evaluation of parallel copying garbage collection on a shared-memory multiprocessor. </title> <journal> IEEE Transactions on Parallel and Distributed Computing, </journal> <volume> 4(9) </volume> <pages> 1030-1040, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: This order need not be preserved. 120 The Implementation Parallel garbage collectors have a long history [27, 6, 20, 60]. The one that come closest to our implementation is the implementation by Imai and Tick <ref> [30] </ref>. They parallelized a stop-and-copy garbage collection scheme for shared-memory multiprocessors. The system was implemented within a concurrent logic programming system called VPIM, a parallel KL1 emulator.
Reference: [31] <author> R. Jain. </author> <title> The art of computer systems performance analysis. </title> <publisher> Wiley Professional Computing, </publisher> <year> 1991. </year>
Reference-contexts: The median execution time is used for comparison. The median execution time is chosen since it is less influenced by the few slow executions that are caused by operating system fluctuations. The median execution time gives the user better information about the typical performance of the system <ref> [31] </ref>. The difference between the median and mean is in reality not big. shows the the distribution of execution time of the Smith-Waterman benchmark from three thousand runs using four, eight and sixteen processors. The distributions are as expected slightly skewed.
Reference: [32] <author> S. Janson. AKL: </author> <title> A multiparadigm programming language. </title> <institution> Uppsala Thesis in Computing Science 19, SICS Dissertation Series 14, Uppsala University, SICS, </institution> <year> 1994. </year>
Reference-contexts: The operational semantics is also important when alternative language constructs are discussed. The Penny computation model is based on the description of AKL in <ref> [32] </ref>. The semantics of AKL has also been described in [33], and [23]. The Penny computation model is simplified compared to the original AKL computation model. The original model is more general and is better suited when alternative language constructs is discussed. <p> The constraint store is thus not monotonic. It is possible to describe the send rule and keep the monotonic property of the constraint store but this requires that we use a more powerful constraint theory than equality over rational trees <ref> [32] </ref>. The apply rule apply (x; y) requires that env () j= x = q (u; p (v)). The variables u in p (v) are substituted by y giving the new expression p (v 0 ).
Reference: [33] <author> S. Janson and S. Haridi. </author> <title> Programming paradigms of the Andorra Kernel Language. </title> <editor> In V. Saraswat and K. Ueda, editors, </editor> <booktitle> Logic Programming, Proceedings of the 1991 International Symposium, </booktitle> <pages> pages 167-186, </pages> <address> San Diego, USA, 1991. </address> <publisher> The MIT Press. </publisher>
Reference-contexts: The operational semantics is also important when alternative language constructs are discussed. The Penny computation model is based on the description of AKL in [32]. The semantics of AKL has also been described in <ref> [33] </ref>, and [23]. The Penny computation model is simplified compared to the original AKL computation model. The original model is more general and is better suited when alternative language constructs is discussed.
Reference: [34] <author> S. Janson and J. Montelius. </author> <title> The design of the AKL/PS 0.0 prototype implementation of the Andorra Kernel Language. ESPRIT deliverable, </title> <type> EP 2471 (PEPMA), </type> <institution> Swedish Institute of Computer Science, </institution> <year> 1992. </year>
Reference-contexts: The execution model is based on the execution model for the sequential AKL system that was used in the implementation of the AGENTS 1.0 system <ref> [34] </ref>. The sequential execution model was designed to favor non suspending computations in order to be competitive with non-concurrent languages. The model led to an efficient implementation that has, despite the complexity of the AKL computation model, only a small overhead compared to, for example, Prolog implementations. <p> If two workers are executing in the same and-node the last spawned will record its bindings in a private hash window. Research has been done on compile time analysis for stability detection [47]. The sequential prototype implementation of AKL <ref> [34] </ref> uses a trailing scheme to implement the constraint stores. All bindings are made in place but external bindings are trailed.
Reference: [35] <author> S. Janson, J. Montelius, and S. Haridi. </author> <title> Ports for Objects in Concurrent Logic Programs, </title> <booktitle> chapter 8, </booktitle> <pages> pages 211-231. </pages> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: A many-to-one communication is harder to describe. In AKL ports are used to implement many-to-one communication <ref> [35] </ref>. A port is a link to a stream of messages represented by a list. Messages are sent to the port but are read from the stream. The receiver of the messages need therefore only have access to the stream. The port synchronizes the access to the process.
Reference: [36] <author> R. Karlsson. </author> <title> Parallelism in Smith-Waterman. </title> <type> personal communication. </type>
Reference-contexts: The parallelism was obvious since the matching operations are independent. An interesting challenge came from Roland Karlsson who argued that the obtained parallelism was not so interesting since the tasks are independent <ref> [36] </ref>. The real quest would be to make the algorithm itself run in parallel. It turned out that it was already running in parallel and the program only needed minor changes to give good speedup.
Reference: [37] <author> J. S. Larson, B. C. Massey, and E. Tick. </author> <title> Super Monaco: Its portable and efficient parallel runtime system. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> 966, </volume> <pages> pages 527-538. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: The locking scheme, does not change the dereference procedure. This locking scheme has been proposed, by Jim Crammond, as a technique for locking multiple variables in a FCP [16]. The technique has also been used in the Super Monaco system, implemented by Evan Tick and his group <ref> [37] </ref>. 7.5.2 Hazards There are two possible hazards in the binding scheme: circular references and deadlock situations. If two local variables are unified, the binding scheme does not specify the direction of the binding.
Reference: [38] <author> B. Lewis and D. J. Berg. </author> <title> Threads Primer. </title> <publisher> SunSoft Press, </publisher> <year> 1996. </year>
Reference-contexts: It is therefore important to separate data structures that will be accessed by many workers into separate cache lines. This might mean that the local cache in a uni-processor system is not fully utilized. 8.1.2 Threads The Solaris Multithreading system is used to implement the system <ref> [38] </ref>. The system allows a Unix process to be divided into multiple threads. Each thread has its own program counter, registers and execution stack but they all share the the same address space. The shared address space allow threads to easily access and modify a shared data representation.
Reference: [39] <author> T. Lindgren, J. Bevemyr, and H. Millrot. </author> <title> Compiler optimizations in Reform Prolog: Experiments on the KSR-1 multiprocessor. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> 966, </volume> <pages> pages 553 -564. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: The restriction is well chosen; deterministic procedures are the main source of parallelism in Prolog programs. By avoiding the problem of handling non-determinism the system can compete with optimized sequential systems. The Reform system is the fastest and-parallel system for the type of programs that complies to the restrictions <ref> [39] </ref>. 10.3. Concurrent logic programming 181 10.2.3 A combination of the two Combining and- and or-parallelism is tricky. Andorra-I is one system that uses the Basic Andorra Model to solve the problem [54]. Deterministic goals are allowed to proceed while non-deterministic goals are temporary suspended.
Reference: [40] <author> J. Loeckx and K. Sieber. </author> <title> The Foundation of Logic Programming. </title> <publisher> Pitman Press, Ltd., </publisher> <address> Bath, Avon, </address> <year> 1984. </year>
Reference-contexts: Abstract machines have been used to give clear operational semantics to as well as describing the execution mechanism of languages languages <ref> [40] </ref>. In the logic programming community the semantical properties of languages have been described by model theory or rewrite systems. The abstract machines have served mainly as tool for language implementors. An abstract machine is often implemented in software although several machines have been at least partly implemented in hardware.
Reference: [41] <editor> E. Lusk, D. H. D. Warren, S. Haridi, et al. </editor> <title> The Aurora or-parallel Prolog system. </title> <booktitle> In International Conference on Fifth Generation Computer Systems 1988. </booktitle> <publisher> ICOT, </publisher> <year> 1988. </year> <month> 200 </month>
Reference-contexts: Only in the last years have systems been built that include both forms of parallelism while maintaining the Prolog execution model [24]. 10.2.1 Or-parallelism There are two challenges when building an or-parallel Prolog system, maintaining the multiple binding environments and minimizing speculative work <ref> [41, 4] </ref>. The binding schemes used in these systems are quite different from the scheme used in the Penny system. This is only natural since the execution state of a deep AKL program is very different from a Prolog execution.
Reference: [42] <author> P. Magnusson. </author> <title> A Design for Efficient Simulation of a Multiprocessor. </title> <booktitle> In Proceedings of MASCOTS, </booktitle> <pages> pages 69-78, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: There are now tools available for debugging of multithreaded programs but these tool were not available when the system was implemented. In the last phase of the project the instruction level simulator SimICS <ref> [43, 42, 44] </ref> was used. The simulator accurately simulates a multiprocessor SPARC architecture and can provide valuable statistics. The simulator was mainly used for performance debugging and proved to be a vital tool.
Reference: [43] <author> P. Magnusson and B. Werner. </author> <title> Some efficient techniques for simulating memory. </title> <type> Technical Report T94:16, </type> <institution> Swedish Institute of Computer Science, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: There are now tools available for debugging of multithreaded programs but these tool were not available when the system was implemented. In the last phase of the project the instruction level simulator SimICS <ref> [43, 42, 44] </ref> was used. The simulator accurately simulates a multiprocessor SPARC architecture and can provide valuable statistics. The simulator was mainly used for performance debugging and proved to be a vital tool.
Reference: [44] <author> P. Magnusson and B. Werner. </author> <title> Efficient Memory Simulation in SimICS. </title> <booktitle> In Proceedings of the 28th Annual Simulation Symposium, </booktitle> <year> 1995. </year>
Reference-contexts: There are now tools available for debugging of multithreaded programs but these tool were not available when the system was implemented. In the last phase of the project the instruction level simulator SimICS <ref> [43, 42, 44] </ref> was used. The simulator accurately simulates a multiprocessor SPARC architecture and can provide valuable statistics. The simulator was mainly used for performance debugging and proved to be a vital tool.
Reference: [45] <author> M. J. Maher. </author> <title> Logic semantics for a class of committed choice programs. </title> <booktitle> In Proceedings of the Fourth International Conference on Logic Programming. </booktitle> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: If the constructs are introduced without parallel execution in mind automatic parallelization becomes as difficult as it is for the imperative languages. 2.3 Concurrent Constraint Languages Concurrent constraint programming languages were developed from research in logic programming <ref> [45, 55] </ref>. It unified two strands of research, constraint logic programming and concurrent logic programming. 2.3.1 Constraints As explained earlier a declarative program can be viewed as operations that assign, or read, the values of fields.
Reference: [46] <author> T. Miyazaki, A. Takeuchi, and T. Chikayama. </author> <title> A sequential implementation of concurrent Prolog based on the shallow binding scheme. </title> <booktitle> In Symposium on Logic Programming, </booktitle> <pages> pages 110-118. </pages> <booktitle> IEEE Computer Society, Technical Committee on Computer Languages, </booktitle> <publisher> The Computer Society Press, </publisher> <month> July </month> <year> 1985. </year>
Reference-contexts: The environment identifier is then compared to this and-node. Environment references can be updated any time during execution, there is no need to keep an reference that refers to a promoted and-node. This scheme is similar to the scheme designed in a sequential implementation of Concurrent Prolog <ref> [46] </ref> where variables also have to be identified with a level in the computation. 7.3 Binding lists Bindings to local variables can never be removed and can therefore be recorded in place, i.e. the value of a variable is permanently replaced by the binding.
Reference: [47] <author> R. Moolenaar. </author> <title> The parallel implementation of the Andorra Kernel Language. </title> <type> Phd. thesis, </type> <institution> Katholieke Univeristeit Leuven, </institution> <year> 1995. </year>
Reference-contexts: The hierarchical structure reflects how work has been spawned and not the structure of the configuration. If two workers are executing in the same and-node the last spawned will record its bindings in a private hash window. Research has been done on compile time analysis for stability detection <ref> [47] </ref>. The sequential prototype implementation of AKL [34] uses a trailing scheme to implement the constraint stores. All bindings are made in place but external bindings are trailed. <p> using the notion of stability. 10.4 Parallel implementations of AKL This section describes the tw other parallel implementations of AKL, namely ParAKL and DAM, and how they differ from the Penny system. 10.4.1 ParAKL ParAKL is the parallel implementation of AKL developed by Remco Moolenaar at the University of Leuven <ref> [47] </ref>. The implementation was developed using an early 10.4. Parallel implementations of AKL 185 System Penny ParAKL hanoi (14) 0.72s (1.0) 2.4s (3.33) matrix (250) 0.61s (1.0) 1.5s (2.46) Table 10.6: Sequential execution speed, ParAKL version of the AGENTS system.
Reference: [48] <author> R. Moolenaar and B. Demoen. </author> <title> A parallel implementation for AKL. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> 714, </volume> <pages> pages 246-261. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1993. </year>
Reference-contexts: The "deep scheme" proposed by Sato, H. et al. [56] is similar to the Penny binding scheme. That scheme also uses a hierarchy of binding lists that have to be searched for each access of an external variable. The ParAKL <ref> [48] </ref> implementation of AKL uses a binding scheme based on the PEP-Sys hashing scheme. A hierarchical structure of hash tables is used to represent the constraint stores. The hierarchical structure reflects how work has been spawned and not the structure of the configuration.
Reference: [49] <author> R. S. Nikhil and Arvind. </author> <title> Id: A language with implicit parallelism. </title> <publisher> Elsevier Science Publishers, </publisher> <month> February </month> <year> 1990. </year>
Reference-contexts: The pH system is a parallel version of Haskell developed by Arvind's group at the MIT Lab for Computer Science, and Nikhil at the DEC Cambridge Research Lab [1]. The pH system is developed using experience gained in the work on Id, a functional language designed for data-flow machines <ref> [49] </ref>. One interesting feature in pH is the so-called I-structure. The data type is a record that can hold holes. The holes can be assigned a value but only once. The I-structures are thus closely related to the variables used in logic programming languages.
Reference: [50] <author> S. C. North and J. H. Reppy. </author> <title> Concurrent garbage collection on stock hardware. </title> <booktitle> In Proceeding of the Third Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 113-133, </pages> <month> September </month> <year> 1987. </year>
Reference-contexts: Copying garbage collector is attractive for systems that have a high rate of garbage generation, as in functional and logical programming languages. The garbage collection time is proportional to the amount of data in use by the system <ref> [50] </ref>. This is in contrast to a mark-and-sweep technique, which has garbage collection time proportional to the entire area. The one disadvantage with a copying collector is that it normally only can use half of the available space.
Reference: [51] <author> A. Podelski and G. Smolka. </author> <title> Situated simplification. </title> <editor> In U. Montanari, editor, </editor> <booktitle> Proceedings of the 1st Conference on Principles and Practice of Constraint Programming, Lecture Notes in Computer Science, </booktitle> <volume> vol. 976, </volume> <pages> pages 328-344, </pages> <address> Cassis, France, </address> <month> September </month> <year> 1995. </year> <note> Springer-Verlag. </note>
Reference-contexts: A similar scheme is used in the DFKI-OZ system but the stability check has been limited to and-nodes immediately below solve combinators. Andreas Podelski and Gert Smolka has presented situated simplification <ref> [51] </ref> that is a formal description of a system that is similar to the Penny binding scheme. The description differs mainly in that the local binding of a variable is accessed through the variable using the environment as an index.
Reference: [52] <author> A. Podelski and P. Van Roy. </author> <title> The beauty and beast algorithm: Quasi-linear incremental tests of entailment and disentailment over trees. </title> <editor> In M. Bruynooghe, editor, </editor> <booktitle> Proceedings of the 1994 International Logic Programming Symposium, </booktitle> <pages> pages 359-374, </pages> <address> Ithaca, 1994. </address> <publisher> ALP, MIT Press. </publisher>
Reference-contexts: The optimization is not so important since unification of larger structures is rare. The access to a hash table could, however, be costly, if they are infrequent. The table, most certainly, will not be in the cache. Andreas Podelski and Peter van Roy have presented <ref> [52] </ref> an algorithm called "the beauty and beast" for tests of entailment and dis-entailment.
Reference: [53] <author> E. Pontelli and G. Gupta. </author> <title> Analysis of dependent and-parallelism. </title> <booktitle> In Proceedings of the fourth Compulog-Net Workshop on Parallelism and Implementation Technologies for (Constraint) Logic Languages, </booktitle> <pages> pages 73-91, </pages> <month> September </month> <year> 1996. </year>
Reference-contexts: Compile-time analysis is sometimes not enough and must therefore be complemented with runtime tests [29]. When dependent computations are executed in parallel the big problem is how to handle non-determinism. Various solutions have been proposed that vary in their degree of providing unrestricted parallelism <ref> [53] </ref>. The Dynamic Dependent And-parallel Scheme (DDAS) proposed by Kish Shen is so far the most promising [61]. In this scheme the system keeps track of variables that are shared between workers.
Reference: [54] <author> V. Santos Costa, D. H. D. Warren, and R. Yang. </author> <title> The Andorra-I engine: A parallel implementation of the Basic Andorra Model. </title> <type> Technical note, </type> <institution> University of Bristol, Department of Computer Science, </institution> <month> March </month> <year> 1990. </year> <month> 201 </month>
Reference-contexts: Concurrent logic programming 181 10.2.3 A combination of the two Combining and- and or-parallelism is tricky. Andorra-I is one system that uses the Basic Andorra Model to solve the problem <ref> [54] </ref>. Deterministic goals are allowed to proceed while non-deterministic goals are temporary suspended. When a nondeterministic step is performed the resulting branches can be executed in parallel. The execution model improves the ordinary Prolog search strategy, but it is still inferior to finite-domain constraint based systems [57].
Reference: [55] <author> V. A. Saraswat. </author> <title> Concurrent Constraint Programming Languages. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University, </institution> <month> January </month> <year> 1990. </year>
Reference-contexts: If the constructs are introduced without parallel execution in mind automatic parallelization becomes as difficult as it is for the imperative languages. 2.3 Concurrent Constraint Languages Concurrent constraint programming languages were developed from research in logic programming <ref> [45, 55] </ref>. It unified two strands of research, constraint logic programming and concurrent logic programming. 2.3.1 Constraints As explained earlier a declarative program can be viewed as operations that assign, or read, the values of fields.
Reference: [56] <author> H. Sato, N. Ichiyoshi, T. Dasai, T. Miyazaki, and A. Takeuchi. </author> <title> A sequential implementation of Concurrent Prolog based on the deep binding scheme. </title> <booktitle> In The First National Conference of Japan Society for Software Science and Technology, </booktitle> <pages> pages 299-302, </pages> <year> 1984. </year> <title> In Japanese. </title>
Reference-contexts: A copying strategy for choice splitting was chosen since it simplifies the binding scheme. Binding schemes for Concurrent Prolog have, as in AKL, to deal with multiple levels of bindings and suspension of goals. The "deep scheme" proposed by Sato, H. et al. <ref> [56] </ref> is similar to the Penny binding scheme. That scheme also uses a hierarchy of binding lists that have to be searched for each access of an external variable. The ParAKL [48] implementation of AKL uses a binding scheme based on the PEP-Sys hashing scheme.
Reference: [57] <author> C. Schulte and G. Smolka. </author> <title> Encapsulated search in higher-order concurrent constraint programming. </title> <editor> In M. Bruynooghe, editor, </editor> <booktitle> Proceedings of the 1994 International Logic Programming Symposium, </booktitle> <pages> pages 505-520, </pages> <address> Ithaca, 1994. </address> <publisher> ALP, MIT Press. </publisher>
Reference-contexts: This can lead to simplifications in the implementation that we discuss later. The higher order approach to handle search was developed in the DFKI-Oz programming system and has later been included in the AGENTS system <ref> [57] </ref>. Is is powerful since it gives the programmer the tool for implementing a variety of search strategies. Note that the question of how parallelism should be exploited now is under the programmer's control. <p> Deterministic goals are allowed to proceed while non-deterministic goals are temporary suspended. When a nondeterministic step is performed the resulting branches can be executed in parallel. The execution model improves the ordinary Prolog search strategy, but it is still inferior to finite-domain constraint based systems <ref> [57] </ref>. A problem with the Andorra-I approach is that it does not provide the programmer with the tools to guide the search. It is up to the compiler to detect determinate goals. There is no clear notion of a guard as in the AKL.
Reference: [58] <author> E. Shapiro. </author> <title> Concurrent Prolog: A Progress Report, </title> <booktitle> chapter 2, </booktitle> <pages> pages 27-83. </pages> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: In the quest for performance the developers gradually removed properties of traditional logic programming languages. Non-determinism was abandoned at an early stage and the systems were then restricted to handle only flat guards <ref> [58, 68] </ref>. Some systems went even further and removed general unification, disallowed multiple readers of variables, and included imperative variables [22, 21]. 10.3.1 KLIC One of the systems that kept the logical variables in the language is KL1. <p> be harmful since a worker will have to wait for other workers to perform their tasks before the next generation of border cells can be computed. 10.3.3 Deep guards Deep guards were used in the early committed choice languages for example Guarded Horn Clauses (GHC), Concurrent Prolog (CP) and PARLOG <ref> [15, 58, 70, 66] </ref>. These 184 Related Work languages used deep guards for complex deterministic tests. In CP the guard computation was allowed to make local bindings to external variables. This introduced a complexity in the implementation.
Reference: [59] <author> E. Shapiro, </author> <title> editor. Concurrent Prolog: Collected Papers. </title> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: This is different from how the deep guards were used in the early committed choice languages for example Guarded Horn Clauses or Concurrent Prolog <ref> [59] </ref>. These languages used the deep guards as complex but deterministic tests and to spawn speculative parallel computations that could be pruned once a solution was found. This sort of parallelism is in my experience hard to exploit and the programming style is not easy to follow.
Reference: [60] <author> R. Sharma and M. L. Soffa. </author> <title> Parallel generational garbage collection. </title> <booktitle> In OOP-SLA'91, </booktitle> <pages> pages 16-32, </pages> <year> 1991. </year>
Reference-contexts: Both the strategy, its implementation, and performance has been described in the thesis by Galal [5], this section will only be a brief overview. 1 Except during unification. This order need not be preserved. 120 The Implementation Parallel garbage collectors have a long history <ref> [27, 6, 20, 60] </ref>. The one that come closest to our implementation is the implementation by Imai and Tick [30]. They parallelized a stop-and-copy garbage collection scheme for shared-memory multiprocessors. The system was implemented within a concurrent logic programming system called VPIM, a parallel KL1 emulator.
Reference: [61] <author> K. Shen. </author> <title> Exploiting and-parallelism in Prolog: the Dynamic Dependent And-parallel Scheme DDAS. </title> <booktitle> In Proceedings of the Joint International Conference and Symposium on Logic Programming, </booktitle> <pages> pages 717-731, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: When dependent computations are executed in parallel the big problem is how to handle non-determinism. Various solutions have been proposed that vary in their degree of providing unrestricted parallelism [53]. The Dynamic Dependent And-parallel Scheme (DDAS) proposed by Kish Shen is so far the most promising <ref> [61] </ref>. In this scheme the system keeps track of variables that are shared between workers. The worker that is working on the leftmost goal has priority to bind a shared variable, other workers will suspend when they try to access the variable.
Reference: [62] <author> K. Shen. </author> <title> Overview of DASWAM: Exploitation of dependent and-parallelism. </title> <journal> Journal of Logic Programming, </journal> <volume> 29 </volume> <pages> 245-293, </pages> <month> October/December </month> <year> 1996. </year>
Reference-contexts: If the binder of the variable later has to backtrack it will signal the consumers of the variable to redo their computations. An implementation of the scheme (DASWAM) shows good parallel performance. <ref> [62] </ref>. This system so far relies on user annotations to collect information about shared variable, but this can in the future be provided by a compiler. A radical approach was taken by the Reform group at Uppsala University [9].
Reference: [63] <institution> SICS. SICStus v3. </institution> <note> URL http://www.sics.se/isl/sicstus.html. </note>
Reference-contexts: This is of course expensive and induces a cost that is hard to justify. To estimate the overhead I have compared the Penny system to MUSE, an or-parallel Prolog system available with the SICStus v3 system <ref> [63] </ref>. Table 10.3 shows the performance using a ten-queens benchmark on an eight processor sparcCenter-2000. In this benchmark the MUSE system outperforms the Penny system by almost a factor of nine.
Reference: [64] <author> G. Smolka. </author> <title> The definition of Kernel Oz. </title> <editor> In A. Podelski, editor, </editor> <title> Constraints: Basics and Trends, </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> vol. 910, </volume> <pages> pages 251-292. </pages> <publisher> Springer, </publisher> <year> 1995. </year>
Reference-contexts: Properties of the Execution Model 65 The problem could of course be avoided by restricting the concurrency in the language. The original DFKI Oz system defines the execution order to be "left to right" as long as no goals are suspended <ref> [64] </ref>. A parallel implementation would however have reduced chances of exploiting parallelism since it would have to make sure that the sequential execution order is maintained. 5.6.4 Fairness The execution model is in no way fair. <p> The I-structures are thus closely related to the variables used in logic programming languages. Another interesting feature in pH is the M-structure [8]. The structure allows multiple atomic updates and is similar to the cell construct provided in Oz in combination with a logical variable <ref> [64] </ref>. The M-structure solves the same problem as the port construct in Penny. Chapter 11 Summary A s explained in the introduction, this dissertation presents the design, implementation, and evaluation of a system that exploits fine-grain implicit parallelism in a concurrent constraint programming language.
Reference: [65] <author> P. Stenstrom and F. Dahlgren. </author> <title> Applications for shared memory multiprocessors. </title> <journal> IEEE Computer, </journal> <volume> 29(12), </volume> <month> October </month> <year> 1996. </year>
Reference: [66] <author> A. Takeuchi and K. Furakawa. </author> <booktitle> Parallel Logic Programming Languages, chapter 6, pages 188- 201. </booktitle> <publisher> MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: be harmful since a worker will have to wait for other workers to perform their tasks before the next generation of border cells can be computed. 10.3.3 Deep guards Deep guards were used in the early committed choice languages for example Guarded Horn Clauses (GHC), Concurrent Prolog (CP) and PARLOG <ref> [15, 58, 70, 66] </ref>. These 184 Related Work languages used deep guards for complex deterministic tests. In CP the guard computation was allowed to make local bindings to external variables. This introduced a complexity in the implementation.
Reference: [67] <author> E. Tick. </author> <title> Parallel Logic Programming. </title> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: The number of processes can be fixed or be a function of the input. The programs can often be executed "from left to right" without any suspensions. The programs that we have chosen are all well-known benchmarks in the committed choice community <ref> [67] </ref>. The benchmarks are: mastermind: The mastermind puzzle by E. Tick, using two guesses and three colors. kkqueen: The candidates/non-candidates queens program by K. Kumon and E. Tick, using 9 queens. 9.4. Communicating processes 153 turtles: The turtles puzzle by E.
Reference: [68] <author> E. Tick. </author> <title> The devolution of concurrent logic programming languages. </title> <journal> Journal of Logic Programming, </journal> <volume> 23(2), </volume> <month> May </month> <year> 1995. </year>
Reference-contexts: In the quest for performance the developers gradually removed properties of traditional logic programming languages. Non-determinism was abandoned at an early stage and the systems were then restricted to handle only flat guards <ref> [58, 68] </ref>. Some systems went even further and removed general unification, disallowed multiple readers of variables, and included imperative variables [22, 21]. 10.3.1 KLIC One of the systems that kept the logical variables in the language is KL1.
Reference: [69] <author> H. Ueda and J. Montelius. </author> <title> Dynamic scheduling in an implicit parallel system. </title> <booktitle> In Ninth International Conference on Parallel and Distributed Computing Systems, </booktitle> <month> September </month> <year> 1996. </year>
Reference-contexts: The scheduler was nick-named "the wild-west scheduler" for its brute approach but it turned out to be a good strategy. The scheduler was later renamed to "the stealer" and proved to be a hard to beat <ref> [69] </ref>. 8.7.2 Task stacks There are as described earlier three task stacks and one context stack. The stacks are protected by a single lock that must be taken to remove or change an entry.
Reference: [70] <author> K. Ueda. </author> <title> Guarded Horn Clauses, </title> <booktitle> chapter 4, </booktitle> <pages> pages 140-156. </pages> <publisher> MIT Press, </publisher> <year> 1987. </year> <month> 202 </month>
Reference-contexts: be harmful since a worker will have to wait for other workers to perform their tasks before the next generation of border cells can be computed. 10.3.3 Deep guards Deep guards were used in the early committed choice languages for example Guarded Horn Clauses (GHC), Concurrent Prolog (CP) and PARLOG <ref> [15, 58, 70, 66] </ref>. These 184 Related Work languages used deep guards for complex deterministic tests. In CP the guard computation was allowed to make local bindings to external variables. This introduced a complexity in the implementation.
Reference: [71] <author> K. Ueda and T. Chikayama. </author> <title> Design of the Kernel Language for the Parallel Inference Machine. </title> <journal> The computer Journal, </journal> <volume> 33(6) </volume> <pages> 494-500, </pages> <year> 1990. </year>
Reference-contexts: The languages was developed at ICOT in the Fifth Generation project and was used both to implement the operating system and various high-level application oriented programming languages <ref> [71] </ref>.
Reference: [72] <author> D. H. D. Warren. </author> <title> An abstract Prolog instruction set. </title> <type> Technical Report 309, </type> <institution> SRI International, </institution> <year> 1983. </year>
Reference-contexts: The abstract machines have served mainly as tool for language implementors. An abstract machine is often implemented in software although several machines have been at least partly implemented in hardware. The abstract machine presented in this chapter has borrowed many concepts from the Warren Abstract Machine (WAM) <ref> [72, 2] </ref>. 6.2 The execution state The execution state is divided into: a representation of the configuration which is shared between all workers, the structures that are local to each worker and the representation of the terms. All parts of the execution state are equally accessible to all workers. <p> And-continuation An and-continuation represents a sequence of atoms by a tuple of registers and a program counter. The program counter is a pointer to a sequence of instructions. An and-continuation is similar, in its structure and use, to an "environment" in WAM <ref> [72] </ref>. The first and-continuation allocated in an and-node implicitly holds the representation of both the guard and body of the guarded goal. The body need not be explicitly represented since it is only needed after the instructions that pertain to the atoms of the guard have been executed. <p> Registers The instruction handler needs some registers: a code pointer, a structure pointer, a mode flag and a set of argument registers. The code pointer, structure pointer, mode flag and argument registers are use much in the same way as in WAM <ref> [72] </ref>. The worker also has registers to hold pointers to the current and-box, current and-continuation and current insertion cell. <p> Figure 7.1 shows an example of how the structure "foo (X,a,Y,X)" (where the variable "Y" is constrained) is represented. Note, that the representation of variables is different from the representation of variables in WAM <ref> [72] </ref> where unbound variables are represented by a self-reference. Care must be taken when a variable is bound to another variable or copied to a register. In WAM the value of any term is simply copied to a register. <p> The unify instructions that operate in write mode will ignore the contents of the positions and operate just like their AGENTS counterparts. 8.6.2 How expensive is it? To understand how expensive the get-list instruction is we will compare it to the get-list instruction in the WAM <ref> [72] </ref>. We will therefore only consider the case were variables are local and unconstrained since this will be the case if we execute Prolog like programs. If the argument register holds anything other than a reference term only the tag will be examined.
Reference: [73] <author> P. R. Woodward. </author> <title> Perspective on supercomputing: Three decades of change. </title> <journal> IEEE Computing, </journal> <volume> 29(10), </volume> <month> October </month> <year> 1995. </year>
Reference-contexts: The smaller systems have six to eight processors while the larger servers can have up to 128 processors. The shared-memory architecture is even challenging the super-computer 14 Background segment with high-end computation servers. Clusters of such servers are likely to replace the traditional super computers <ref> [73] </ref>. The shared-memory architecture has also been introduced for personal computers. Two and four processor computers are available. These systems might become the standard configuration. The competing parallel architectures are vector machines and message passing machines.

References-found: 73

