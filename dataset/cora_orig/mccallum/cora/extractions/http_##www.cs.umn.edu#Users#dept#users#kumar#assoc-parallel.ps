URL: http://www.cs.umn.edu/Users/dept/users/kumar/assoc-parallel.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Email: han@cs.umn.edu  karypis@cs.umn.edu  kumar@cs.umn.edu  
Title: Scalable Parallel Data Mining for Association Rules  
Author: Eui-Hong (Sam) Han George Karypis Vipin Kumar 
Address: Minneapolis, MN 55455  Minneapolis, MN 55455  Minneapolis, MN 55455  
Affiliation: Department of Computer Science University of Minnesota  Department of Computer Science University of Minnesota  Department of Computer Science University of Minnesota  
Abstract: One of the important problems in data mining is discovering association rules from databases of transactions where each transaction consists of a set of items. The most time consuming operation in this discovery process is the computation of the frequency of the occurrences of interesting subset of items (called candidates) in the database of transactions. To prune the exponentially large space of candidates, most existing algorithms, consider only those candidates that have a user defined minimum support. Even with the pruning, the task of finding all association rules requires a lot of computation power and time. Parallel computers offer a potential solution to the computation requirement of this task, provided efficient and scalable parallel algorithms can be designed. In this paper, we present two new parallel algorithms for mining association rules. The Intelligent Data Distribution algorithm efficiently uses aggregate memory of the parallel computer by employing intelligent candidate partitioning scheme and uses efficient communication mechanism to move data among the processors. The Hybrid Distribution algorithm further improves upon the Intelligent Data Distribution algorithm by dynamically partitioning the candidate set to maintain good load balance. The experimental results on a Cray T3D parallel computer show that the Hybrid Distribution algorithm scales linearly and exploits the aggregate memory better and can generate more association rules with a single scan of database per pass. 
Abstract-found: 1
Intro-found: 1
Reference: [AIS93] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Mining association rules between sets of items in large databases. </title> <booktitle> In Proc. of 1993 ACM-SIGMOD Int. Conf. on Management of Data, </booktitle> <address> Washington, D.C., </address> <year> 1993. </year>
Reference-contexts: A number of algorithms have been developed for discovering association rules <ref> [AIS93, AS94, HS95] </ref>. Our parallel algorithms are based on the Apriori algorithm [AS94] that has smaller computational complexity compared to other algorithms. In the rest of this section, we briefly describe the Apriori algorithm. The reader should refer to [AS94] for further details. 1.
Reference: [AS94] <author> R. Agrawal and R. Srikant. </author> <title> Fast algorithms for mining association rules. </title> <booktitle> In Proc. of the 20th VLDB Conference, </booktitle> <pages> pages 487-499, </pages> <address> Santi-ago, Chile, </address> <year> 1994. </year>
Reference-contexts: Since usually such transaction-based databases contain extremely large amounts of data and large number of distinct items, the total number of candidates is prohibitively large. Hence, current association rule discovery techniques <ref> [AS94, HS95, SON95, SA95] </ref> try to prune the search space by requiring a minimum level of support for candidates under consideration. Support is a measure based on the number of occurrences of the candidates in database transactions. <p> Hence, current association rule discovery techniques [AS94, HS95, SON95, SA95] try to prune the search space by requiring a minimum level of support for candidates under consideration. Support is a measure based on the number of occurrences of the candidates in database transactions. Apriori <ref> [AS94] </ref> is a recent state-of-the-art algorithm that aggressively prunes the set of potential candidates of size k by looking at the precise support for candidates of size k 1. In the k th iteration, this algorithm computes the occurrences of potential candidates of size k in each of the transactions. <p> A number of algorithms have been developed for discovering association rules <ref> [AIS93, AS94, HS95] </ref>. Our parallel algorithms are based on the Apriori algorithm [AS94] that has smaller computational complexity compared to other algorithms. In the rest of this section, we briefly describe the Apriori algorithm. The reader should refer to [AS94] for further details. 1. <p> A number of algorithms have been developed for discovering association rules [AIS93, AS94, HS95]. Our parallel algorithms are based on the Apriori algorithm <ref> [AS94] </ref> that has smaller computational complexity compared to other algorithms. In the rest of this section, we briefly describe the Apriori algorithm. The reader should refer to [AS94] for further details. 1. <p> Our parallel algorithms are based on the Apriori algorithm <ref> [AS94] </ref> that has smaller computational complexity compared to other algorithms. In the rest of this section, we briefly describe the Apriori algorithm. The reader should refer to [AS94] for further details. 1. F 1 = f frequent 1-item-setsg ; 2. for ( k = 2; F k1 6= OE; k++ ) do begin 3. C k = apriori gen (F k1 ) 4. for all transactions t 2 T 5. subset (C k , t) 6. <p> A faster way of performing this operation is to use a candidate hash tree in which the candidate item-sets are hashed <ref> [AS94] </ref>. Figure 2 shows one example of the candidate hash tree with candidates of length 3. The internal nodes of the hash tree have hash tables that contain links to child nodes. The leaf nodes contain the candidate item-sets. <p> For communication we used the message passing interface (MPI). Our experiments have shown that for 16Kbytes we obtain a bandwidth of 74Mbytes/seconds and an effective startup time of 150 microseconds. We generated a synthetic dataset using a tool provided by [Pro96] and described in <ref> [AS94] </ref>. The parameters for the data set chosen are average transaction length of 15 and average size of frequent item sets of 6. Data sets with 1000 transactions (6.3KB) were generated for different processors.
Reference: [AS96] <author> R. Agrawal and J.C. Shafer. </author> <title> Parallel mining of association rules. </title> <journal> IEEE Transactions on Knowledge and Data Eng., </journal> <volume> 8(6) </volume> <pages> 962-969, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: Parallel computers also offer increased memory to solve this problem. Two parallel algorithms, Count Distribution and Data Distribution were proposed in <ref> [AS96] </ref>. The Count Distribution algorithm has shown to scale linearly and have excellent speedup and sizeup behavior with respect to the number of transactions [AS96]. <p> Parallel computers also offer increased memory to solve this problem. Two parallel algorithms, Count Distribution and Data Distribution were proposed in <ref> [AS96] </ref>. The Count Distribution algorithm has shown to scale linearly and have excellent speedup and sizeup behavior with respect to the number of transactions [AS96]. However, this algorithm works only when the entire hash tree in each pass of the algorithm fits into the main memory of single processor of the parallel computers. Hence, the Count Distribution algorithm, like its sequential counterpart Apriori, is unscalable with respect to increasing candidate size. <p> The Data Distribution algorithm addresses the memory problem of the Count Distribution algorithm by partitioning the candidate set and assigning a partition to each processor in the system. However, this algorithm results in high communication overhead due to data movement and redundant computation <ref> [AS96] </ref>. In this paper, we present two parallel algorithms for mining association rules. We first present Intelligent Data Distribution algorithm that improves upon the Data Distribu tion algorithm such that the communication overhead and redundant computation is minimized. <p> For this reason, parallel association algorithms focus on how to parallelize the first step. The parallel implementation of the second step is straightforward and is discussed in <ref> [AS96] </ref>. 3 Parallel Algorithms In this section, we will focus on the parallelization of the first task that finds all frequent item-sets. We first discuss two parallel algorithms proposed in [AS96] to help motivate our parallel formulations. <p> The parallel implementation of the second step is straightforward and is discussed in <ref> [AS96] </ref>. 3 Parallel Algorithms In this section, we will focus on the parallelization of the first task that finds all frequent item-sets. We first discuss two parallel algorithms proposed in [AS96] to help motivate our parallel formulations. In all our discussions, we assume that the transactions are evenly distributed among the processors. 3.1 Count Distribution Algorithm In the Count Distribution (CD) algorithm proposed in [AS96], each processor computes how many times all the candidates appear in the locally stored transactions. <p> We first discuss two parallel algorithms proposed in <ref> [AS96] </ref> to help motivate our parallel formulations. In all our discussions, we assume that the transactions are evenly distributed among the processors. 3.1 Count Distribution Algorithm In the Count Distribution (CD) algorithm proposed in [AS96], each processor computes how many times all the candidates appear in the locally stored transactions. This is done by building the entire hash tree that corresponds to all the candidates and then performing a single pass over the locally stored transactions to collect the counts. <p> Thus, excluding the global reduction, each processor in the CD algorithm executes the serial Apriori algorithm on the locally stored transactions. This algorithm has been shown to scale linearly with the number of transactions <ref> [AS96] </ref>. This is because each processor can compute the counts independently of the other processors and needs to communicate with the other processors only once at the end of the computation step. <p> Thus the CD algorithm is effective for small number of distinct items and a high minimum support level. 3.2 Data Distribution Algorithm The Data Distribution (DD) algorithm <ref> [AS96] </ref> addresses the memory problem of the CD algorithm by partitioning the candidate item-sets among the processors. This partitioning is done in a round robin fashion. Each processor is responsible for computing the counts of its locally stored subset of the candidate item-sets for all the transactions in the database. <p> This algorithm exploits the total available memory better than CD, as it partitions the candidate set among processors. As the number of processors increases, the number of candidates that the algorithm can handle also increases. However, as reported in <ref> [AS96] </ref>, the performance of this algorithm is significantly worse than the CD algorithm. The run time of this algorithm is 10 to 20 times more than that of the CD algorithm on 16 processors [AS96]. <p> However, as reported in <ref> [AS96] </ref>, the performance of this algorithm is significantly worse than the CD algorithm. The run time of this algorithm is 10 to 20 times more than that of the CD algorithm on 16 processors [AS96]. The problem lies with the communication pattern of the algorithm and the redundant work that is performed in processing all the transactions. The communication pattern of this algorithm causes two problems. <p> With 0.25% support, both algorithms switched to CD algorithm in pass 7 of total 12 passes and 90.7% of the overall response time of the serial code was spent in the first 6 passes. These scaleup results are shown in Figure 9. As noted in <ref> [AS96] </ref>, the CD algorithm scales very well. Looking at the performance obtained by IDD, we see that its response time increases as we increase the number of processors. <p> This is due to the load balancing problem discussed in Section 3, where the number of candidates per processor decreases as the number of processors increases. However, the performance achieved by IDD is much better than that of the DD algorithm of <ref> [AS96] </ref>. In particular, IDD has 4.4 times less response time than DD on 32 processors. It can be seen that the performance gap between IDD and DD is widening as the number of processors increases.
Reference: [HF95] <author> J. Han and Y. Fu. </author> <title> Discovery of multiple-level association rules from large databases. </title> <booktitle> In Proc. of the 21st VLDB Conference, </booktitle> <address> Zurich, Switzer-land, </address> <year> 1995. </year>
Reference-contexts: We plan to perform experiments on different platforms including Cray T3E, IBM SP2 and SGI SMP clusters. We also plan on implementing our ideas in generalized association rules <ref> [HF95, SA95] </ref>, and sequential patterns [MTV95, SA96].
Reference: [HKK97] <author> E.H. Han, G. Karypis, and V. Kumar. </author> <title> Scalable parallel data mining for association rules. </title> <type> Technical Report TR-97-??, </type> <institution> Department of Computer Science, University of Minnesota, M in-neapolis, </institution> <year> 1997. </year>
Reference-contexts: An extended version of this paper that also contains the analysis of the performance of these schemes is available in <ref> [HKK97] </ref>. The rest of this paper is organized as follows. Section 2 provides an overview of the serial algorithm for mining association rules. Section 3 describes existing and proposed parallel algorithms. Experimental results are shown in Section 4.
Reference: [HS95] <author> M. A. W. Houtsma and A. N. Swami. </author> <title> Set-oriented mining for association rules in relational databases. </title> <booktitle> In Proc. of the 11th Int'l Conf. on Data Eng., </booktitle> <pages> pages 25-33, </pages> <address> Taipei, Taiwan, </address> <year> 1995. </year>
Reference-contexts: Since usually such transaction-based databases contain extremely large amounts of data and large number of distinct items, the total number of candidates is prohibitively large. Hence, current association rule discovery techniques <ref> [AS94, HS95, SON95, SA95] </ref> try to prune the search space by requiring a minimum level of support for candidates under consideration. Support is a measure based on the number of occurrences of the candidates in database transactions. <p> A number of algorithms have been developed for discovering association rules <ref> [AIS93, AS94, HS95] </ref>. Our parallel algorithms are based on the Apriori algorithm [AS94] that has smaller computational complexity compared to other algorithms. In the rest of this section, we briefly describe the Apriori algorithm. The reader should refer to [AS94] for further details. 1.
Reference: [KGGK94] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis. </author> <title> Introduction to Parallel Computing: Algorithm Design and Analysis. </title> <publisher> Benjamin Cummings/ Addison Wesley, </publisher> <address> Redwod City, </address> <year> 1994. </year>
Reference-contexts: This is done by building the entire hash tree that corresponds to all the candidates and then performing a single pass over the locally stored transactions to collect the counts. The global counts of the candidates are computed by summing these individual counts using a global reduction operation <ref> [KGGK94] </ref>. This algorithm is illustrated in Figure 4. Note that since each processor needs to build a hash tree for all the candidates, these hash trees are identical at each processor. <p> This continues until every processor has processed all the transactions. Having computed the counts of its candidate item-sets, each processor finds the frequent item-sets from its candidate item-set and these frequent item-sets are sent to every other processor using an all-to-all broadcast operation <ref> [KGGK94] </ref>. Figure 5 shows the high level operations of the algorithm. Note that each processor has a different set of candidates in the candidate hash tree. This algorithm exploits the total available memory better than CD, as it partitions the candidate set among processors. <p> The locally stored portions of the database can be sent to all the other processors by using the ring-based all-to-all broadcast described in <ref> [KGGK94] </ref>. This operation does not suffer from the contention problems and it takes O (N ) time on any parallel architecture that can be embedded in a ring. Figure 6 shows the pseudo code for this data movement operation. <p> The global reduction operation is broken into two parts corresponding to the step 2 and 3 of the Figure 8. In the step 2, perform reduction operation <ref> [KGGK94] </ref> along the row such that the processor in the first column of the same row has the total counts for the candidates in the same row processors. <p> Then the processors in the first column broadcast the full frequent sets to the processors along the same row using one-to-all broadcast operation <ref> [KGGK94] </ref>. At this point, all the processors have the frequent sets and ready to proceed to the next pass. This algorithm inherits all the good features of the IDD algorithm. It also provides good load balance and enough computation work by maintaining minimum number of candidates per processor.
Reference: [MJHS96] <author> B. Mobasher, N. Jain, E.H. Han, and J. Sri-vastava. </author> <title> Web mining: Pattern discovery from world wide web transactions. </title> <type> Technical Report TR-96-050, </type> <institution> Department of Computer Science, University of Minnesota, M inneapolis, </institution> <year> 1996. </year>
Reference-contexts: The IDD algorithm also outperforms the DD algorithm, but is not as scalable as HD and CD. Future works include applying these algorithms to real data like retail sales transaction, mail order history database and World Wide Web server logs <ref> [MJHS96] </ref> to confirm the experimental results in the real life domain. We plan to perform experiments on different platforms including Cray T3E, IBM SP2 and SGI SMP clusters. We also plan on implementing our ideas in generalized association rules [HF95, SA95], and sequential patterns [MTV95, SA96].
Reference: [MTV95] <author> H. Mannila, H. Toivonen, and A. I. Verkamo. </author> <title> Discovering frequent episodes in sequences. </title> <booktitle> In Proc. of the First Int'l Conference on Knowledge Discovery and Data Mining, </booktitle> <pages> pages 210-215, </pages> <address> Montreal, Quebec, </address> <year> 1995. </year>
Reference-contexts: We plan to perform experiments on different platforms including Cray T3E, IBM SP2 and SGI SMP clusters. We also plan on implementing our ideas in generalized association rules [HF95, SA95], and sequential patterns <ref> [MTV95, SA96] </ref>.
Reference: [Pro96] <author> IBM Quest Data Mining Project. </author> <title> Quest synthetic data generation code. </title> <note> http://www.almaden.ibm.com/cs/quest/syndata.html, 1996. </note>
Reference-contexts: For communication we used the message passing interface (MPI). Our experiments have shown that for 16Kbytes we obtain a bandwidth of 74Mbytes/seconds and an effective startup time of 150 microseconds. We generated a synthetic dataset using a tool provided by <ref> [Pro96] </ref> and described in [AS94]. The parameters for the data set chosen are average transaction length of 15 and average size of frequent item sets of 6. Data sets with 1000 transactions (6.3KB) were generated for different processors.
Reference: [PS82] <author> C. H. Papadimitriou and K. Steiglitz. </author> <title> Combinatorial Optimization: Algorithms and Complexity. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1982. </year>
Reference-contexts: To achieve a load-balanced distribution of the candidate item-sets, we use a partitioning algorithm that is based on bin-packing <ref> [PS82] </ref>. For each item in the database, we compute the number of candidate item-sets starting with this particular item. We then use a bin-packing algorithm to partition these items in P buckets such that the numbers of the candidate item-sets starting with these items in each bucket are equal.
Reference: [SA95] <author> R. Srikant and R. Agrawal. </author> <title> Mining generalized association rules. </title> <booktitle> In Proc. of the 21st VLDB Conference, </booktitle> <pages> pages 407-419, </pages> <address> Zurich, Switzerland, </address> <year> 1995. </year>
Reference-contexts: Since usually such transaction-based databases contain extremely large amounts of data and large number of distinct items, the total number of candidates is prohibitively large. Hence, current association rule discovery techniques <ref> [AS94, HS95, SON95, SA95] </ref> try to prune the search space by requiring a minimum level of support for candidates under consideration. Support is a measure based on the number of occurrences of the candidates in database transactions. <p> We plan to perform experiments on different platforms including Cray T3E, IBM SP2 and SGI SMP clusters. We also plan on implementing our ideas in generalized association rules <ref> [HF95, SA95] </ref>, and sequential patterns [MTV95, SA96].
Reference: [SA96] <author> R. Srikant and R. Agrawal. </author> <title> Mining sequential patterns: Generalizations and performance improvements. </title> <booktitle> In Proc. of the Fifth Int'l Conference on Extending Database Technology, </booktitle> <address> Avi-gnon, France, </address> <year> 1996. </year>
Reference-contexts: We plan to perform experiments on different platforms including Cray T3E, IBM SP2 and SGI SMP clusters. We also plan on implementing our ideas in generalized association rules [HF95, SA95], and sequential patterns <ref> [MTV95, SA96] </ref>.
Reference: [SAD + 93] <author> M. Stonebraker, R. Agrawal, U. Dayal, E. J. Neuhold, and A. Reuter. </author> <title> DBMS research at a crossroads: The vienna update. </title> <booktitle> In Proc. of the 19th VLDB Conference, </booktitle> <pages> pages 688-692, </pages> <address> Dublin, Ireland, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction One of the important problems in data mining <ref> [SAD + 93] </ref> is discovering association rules from databases of transactions, fl This work was supported by NSF grant ASC-9634719, Army Research Office contract DA/DAAH04-95-1-0538, Cray Research Inc.
Reference: [SON95] <author> A. Savasere, E. Omiecinski, and S. Navathe. </author> <title> An efficient algorithm for mining association rules in large databases. </title> <booktitle> In Proc. of the 21st VLDB Conference, </booktitle> <pages> pages 432-443, </pages> <address> Zurich, Switzerland, </address> <year> 1995. </year>
Reference-contexts: Since usually such transaction-based databases contain extremely large amounts of data and large number of distinct items, the total number of candidates is prohibitively large. Hence, current association rule discovery techniques <ref> [AS94, HS95, SON95, SA95] </ref> try to prune the search space by requiring a minimum level of support for candidates under consideration. Support is a measure based on the number of occurrences of the candidates in database transactions.
References-found: 15

