URL: http://www.cs.umn.edu/Users/dept/users/kumar/class-paper.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Title: An Efficient, Scalable, Parallel Classifier for Data Mining  
Author: Anurag Srivastava Vineet Singh Eui-Hong (Sam) Han, Vipin Kumar 
Keyword: Data mining, parallel processing, classification, scalability. decision trees.  
Address: 4-192 EE/CS Bldg., 200 Union St. SE  Minneapolis, MN 55455, USA  
Note: Contact Address:  
Affiliation: Dept. of Computer Science University of Minnesota  IBM T.J. Watson Research Center  Dept. of Computer Science University of Minnesota  Dept. of Computer Science  University of Minnesota  
Email: Email: anurag@cs.umn.edu  
Phone: Tel: (612) 626-7515  
Abstract: One of the important problems in data mining is classification. Recently there has been a lot of interest in classifying disk resident datasets. Experiments show that classifying large datasets leads to improvement in accuracy. Most of the current algorithms are suited for small datasets and are inefficient for large disk resident data sets. SPRINT is a state of the art decision tree based algorithm for disk resident data. We propose a new decision-tree-based algorithm which achieves essentially similar accuracy as SPRINT and gives much better performance. Our algorithm has absolutely no memory restrictions compared to SPRINT which has some memory restrictions. Our algorithm also does significantly less I/O than SPRINT. We also present a parallel formulation of our serial algorithm which is inherently more scalable than parallel-SPRINT. An analysis of the cost of computation and communication of our parallel formulation is done. Our analysis and experimental results on IBM SP2 show that our parallel formulation exhibits superior performance and scalability than parallel-SPRINT. 
Abstract-found: 1
Intro-found: 1
Reference: [AIS93] <author> R. Agrawal, T. Imielinski, and A. Swami. </author> <title> Database mining: A performance perspective. </title> <journal> IEEE Transactions on Knowledge and Data Eng., </journal> <volume> 5(6) </volume> <pages> 914-925, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: Australian 2.1 1.5 7.1 6.7 Diabetes 2.5 1.4 1.8 1.4 DNA 33.4 9.21 19.3 21 Letter 251.3 53.08 39.0 61.0 Satimage 224.7 37.06 16.5 21.1 Segment 30.2 9.7 5.2 12.1 Table 3: Run Times [MAR96] The tests on synthetic data sets were carried out for the synthetic datasets proposed in <ref> [AIS93] </ref> and also used by SPRINT. The accuracies were essentially similar. The run times for two different sizes are as follows: i) For 0.4 million examples SPRINT: 1000sec, Ours: 405 sec, ii) 0.8 million examples SPRINT 2100 sec, Ours 766 sec..
Reference: [CS93a] <author> Philip K. Chan and Salvatore J. Stolfo. </author> <title> Experiments on multistrategy learning by metalearning. </title> <booktitle> In Proc. Second Intl. Conference on Info. and Knowledge Mgmt., </booktitle> <pages> pages 314-323, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Classification is an important and a well studied data mining problem. Recently there has been a lot of interest in classifying disk resident datasets because working with large dataset has been shown to improve the accuracy of classification <ref> [CS93a] </ref>, [CS93b]. A classification problem has an input dataset called the training set which consists of a number of examples each having a number of attributes. Each example in the training set has a class label associated with it.
Reference: [CS93b] <author> Philip K. Chan and Salvatore J. Stolfo. </author> <title> Metalearning for multistrategy learning and parallel learning. </title> <booktitle> In Proc. Second Intl. Conference on Multistrategy Learning, </booktitle> <pages> pages 150-165, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Classification is an important and a well studied data mining problem. Recently there has been a lot of interest in classifying disk resident datasets because working with large dataset has been shown to improve the accuracy of classification [CS93a], <ref> [CS93b] </ref>. A classification problem has an input dataset called the training set which consists of a number of examples each having a number of attributes. Each example in the training set has a class label associated with it.
Reference: [FI93] <author> U.M. Fayyad and K.B Irani. </author> <title> Multi-interval discretization of continuous-valued attributes for classification learning. </title> <booktitle> In Proceedings of the 13th Int. Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1022-1027, </pages> <year> 1993. </year>
Reference-contexts: This extra decision tree node increases the size of the decision tree without gaining anything by the way of accuracy. <ref> [FI93] </ref> shows, based on the mathematical definition of entropy, that there is no need for evaluating each distinct value of the sorted continuous attribute list as a potential cutpoint. Entropy can be minimized by only considering those points which lie at the crossover of class runs. <p> The hybrid scheme was implemented on the IBM SP2. The analysis and results for our parallel version show 19 that it extremely scalable and can can handle very large datasets. Speedups got were very near to the ideal case. The algorithm also showed nice scaleup. Some recent papers [KS96], <ref> [FI93] </ref> results have shown that considering the continuous attributes as categorical attributes by considering multiple split points and sub setting on these split points improves the accuracy of classification. This capability is difficult to achieve on sorting based algorithms as it requires multiple scans of the disk resident attribute lists.
Reference: [Gol89] <author> D. E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimizations and Machine Learning. </title> <address> morgan-kaufman, </address> <year> 1989. </year>
Reference-contexts: The objective is to build a classification model that can be used to classify new data, based upon the attribute values. Applications include fraud detection from credit card data, bankruptcy prediction, etc.. Several classification models like neural networks [Lip87], genetic algorithms <ref> [Gol89] </ref>, decision trees [Qui93] have been proposed. Decision trees are perhaps the most popular classification models. They are relatively computationally inexpensive to construct. They also obtain comparable accuracy on datasets compared to other methods [MST94].
Reference: [KGGK94] <author> Vipin Kumar, Ananth Grama, Anshul Gupta, and George Karypis. </author> <title> Introduction to Parallel Computing: Algorithm Design and Analysis. </title> <publisher> Benjamin Cummings/ Addison Wesley, </publisher> <address> Redwod City, </address> <year> 1994. </year>
Reference-contexts: Discrete and continuous attributes are treated differently. Categorical Attributes For discrete attributes, there are three steps. In the first step, every processor computes the class histogram for its local data. In the second step, the processors combine their local class distribution information using global reduction <ref> [KGGK94] </ref> to get a class histogram for all the examples at a particular node. Finally, processors calculates compute entropy gains of the discrete attributes and find the best discrete attribute. Numerical Attributes For continuous attributes, there are three steps for each attribute. <p> Although the design of SPRINT has been done to make it scalable, Some components of it are not very scalable. The reasons SPRINT is not scalable are * During decision tree building process at each level of the tree, a costly all-to-all broadcast <ref> [KGGK94] </ref> of a data structure (hash table), which is proportional to number of total examples in the input data, is done. * There is some serial work which is not parallelizable in SPRINT. The hash tables have the same size at each processor independent of the number of processors.
Reference: [KR90] <author> L. Kaufman and P.J. Rousseeuw. </author> <title> Finding Groups in Data: an Introduction to Cluster Analysis. </title> <publisher> John Wiley & Sons, </publisher> <year> 1990. </year>
Reference-contexts: An element is assigned to a particular bucket based on its class. This element is processed inside its bucket by a one pass clustering algorithm. The clustering algorithms we have used is a modified version of K-means clustering <ref> [KR90] </ref>. The element is assigned to one of a fixed number of cluster centroids based on its distance from the centroids. These centroids are rearranged and processed after a fixed block of data has been read. <p> clustering could be done in two ways. * Each processor clusters its local data, independent of data at other processors and then at the end these clusters are combined. * all processors cooperate to cluster all attribute values in each class separately using a standard clustering algorithm such as k-means <ref> [KR90] </ref> for a single pass over the data 1 . At the end of this step, all processors have the cluster results for each attribute for each class.
Reference: [KS96] <author> R. Kohavi and M. Sahami. </author> <title> Error-based and entropy-based discretization of continuous features. </title> <booktitle> In Proc. of the Second Int'l Conference on Knowledge Discovery and Data Mining, </booktitle> <pages> pages 114-119, </pages> <address> Portland, OR, </address> <year> 1996. </year>
Reference-contexts: The hybrid scheme was implemented on the IBM SP2. The analysis and results for our parallel version show 19 that it extremely scalable and can can handle very large datasets. Speedups got were very near to the ideal case. The algorithm also showed nice scaleup. Some recent papers <ref> [KS96] </ref>, [FI93] results have shown that considering the continuous attributes as categorical attributes by considering multiple split points and sub setting on these split points improves the accuracy of classification.
Reference: [Lip87] <author> R. Lippmann. </author> <title> An introduction to computing with neural nets. </title> <journal> IEEE ASSP Magazine, </journal> <volume> 4(22), </volume> <month> April </month> <year> 1987. </year>
Reference-contexts: The objective is to build a classification model that can be used to classify new data, based upon the attribute values. Applications include fraud detection from credit card data, bankruptcy prediction, etc.. Several classification models like neural networks <ref> [Lip87] </ref>, genetic algorithms [Gol89], decision trees [Qui93] have been proposed. Decision trees are perhaps the most popular classification models. They are relatively computationally inexpensive to construct. They also obtain comparable accuracy on datasets compared to other methods [MST94].
Reference: [MAR96] <author> M. Mehta, R. Agrawal, and J. Rissanen. SLIQ: </author> <title> A fast scalable classifier for data mining. </title> <booktitle> In Proc. of the Fifth Int'l Conference on Extending Database Technology, </booktitle> <address> Avignon, France, </address> <year> 1996. </year>
Reference-contexts: C4.5 [Qui93] is one of the commonly used algorithms. But it is not suitable for large disk resident data sets because it requires all the training set to be memory resident and requires sorting at each node. SLIQ classifier <ref> [MAR96] </ref> is designed to be more suitable for large datasets. But the algorithm requires a data structure proportional to the number of records to stay memory resident. This restriction puts a hard limit on the amount of data that can be handled by this classifier. <p> As of now the implementation uses the least memory possible. The disk resident data structures are implemented as buffered files with a fixed buffer of 4k. Full MDL based pruning in the SLIQ paper <ref> [MAR96] </ref> is used on the decision trees generated. The accuracy, decision tree size, and the run times of other algorithms has been taken from the SLIQ paper [MAR96] for comparison purposes. All the experiments were run on a 66MHz RS6000 workstation with 64MB main memory running AIX 4.1. <p> Full MDL based pruning in the SLIQ paper <ref> [MAR96] </ref> is used on the decision trees generated. The accuracy, decision tree size, and the run times of other algorithms has been taken from the SLIQ paper [MAR96] for comparison purposes. All the experiments were run on a 66MHz RS6000 workstation with 64MB main memory running AIX 4.1. The results are shown for the statlog data sets, a commonly used benchmarking dataset for classification algorithms. 4.1 Results Table 1 shows classification accuracy. <p> Our algorithm performs essentially identical to all the other widely used tree classifiers. It's accuracy is almost identical (within 0.9%) to SPRINT. Tree Sizes are compared in Table 2. We have used Full MDL pruning strategy <ref> [MAR96] </ref>; therefore the results of the rest of the algorithms are also for the same pruning scheme. The final tree sizes after pruning are essentially similar to SPRINT and better than the others. Table 3 shows the execution times. The execution time comparison is shown to give a relative idea. <p> The comparison is not entirely valid, as the the results for other algorithms are for an experimental set up of an IBM RS/6000 250 workstation with 64 MB main memory and executing the AIX 3.2.5 OS. These timings are again taken from <ref> [MAR96] </ref>. Since we did not have access to SPRINT we could not run it to get the run times on our system. <p> only been 8 Datasets IND-Cart IND-C4 SPRINT Ours Australian 85.3 84.4 84.9 84.6 Diabetes 74.6 70.1 75.4 74.5 DNA 92.2 92.5 92.1 92.3 Letter 84.7 86.8 84.6 84.6 Satimage 85.3 85.2 86.3 85.8 Segment 94.9 95.9 94.6 95.0 Shuttle 99.9 99.9 99.9 99.9 Table 1: Classification accuracy for different algorithms <ref> [MAR96] </ref> Datasets IND-Cart IND-C4 SPRINT Ours Australian 5.2 85 14.6 13 Diabetes 11.5 179.7 35 33 DNA 35 171 55 54 Letter 1199.5 3241.3 1141 1089 Satimage 90 563 159 133 Segment 52 102 18.6 19 Shuttle 27 57 29 21 Table 2: Pruned Tree Sizes (Full Mdl Pruning)[MAR96] used for <p> Datasets IND-Cart IND-C4 SLIQ Ours Australian 2.1 1.5 7.1 6.7 Diabetes 2.5 1.4 1.8 1.4 DNA 33.4 9.21 19.3 21 Letter 251.3 53.08 39.0 61.0 Satimage 224.7 37.06 16.5 21.1 Segment 30.2 9.7 5.2 12.1 Table 3: Run Times <ref> [MAR96] </ref> The tests on synthetic data sets were carried out for the synthetic datasets proposed in [AIS93] and also used by SPRINT. The accuracies were essentially similar. <p> "attribute lists" on disk and use the memory only for storing program specific data structures, the class histograms and the clustering structures. 7.1 Description of the dataset and Architecture In the absence of any benchmark having large datasets, we have used the synthetic dataset proposed by in the SLIQ paper <ref> [MAR96] </ref> for all our experiments. Ten classification functions were also proposed in [MAR96] for these functions. We have used the function 2 dataset for our algorithm. In this dataset each record consists of 9 attributes having 3 categoric and 9 continuous attributes. There are two classes. <p> specific data structures, the class histograms and the clustering structures. 7.1 Description of the dataset and Architecture In the absence of any benchmark having large datasets, we have used the synthetic dataset proposed by in the SLIQ paper <ref> [MAR96] </ref> for all our experiments. Ten classification functions were also proposed in [MAR96] for these functions. We have used the function 2 dataset for our algorithm. In this dataset each record consists of 9 attributes having 3 categoric and 9 continuous attributes. There are two classes. The same dataset was also used by the SPRINT algorithm for evaluating its performance.

Reference: [Qui93] <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: The objective is to build a classification model that can be used to classify new data, based upon the attribute values. Applications include fraud detection from credit card data, bankruptcy prediction, etc.. Several classification models like neural networks [Lip87], genetic algorithms [Gol89], decision trees <ref> [Qui93] </ref> have been proposed. Decision trees are perhaps the most popular classification models. They are relatively computationally inexpensive to construct. They also obtain comparable accuracy on datasets compared to other methods [MST94]. <p> Such methods do not yield the same classification accuracy as a decision tree classifier that uses the entire data set. [WC88]. Most current algorithms classification algorithm are based on ID3 algorithm <ref> [Qui93] </ref>. C4.5 [Qui93] is one of the commonly used algorithms. But it is not suitable for large disk resident data sets because it requires all the training set to be memory resident and requires sorting at each node. SLIQ classifier [MAR96] is designed to be more suitable for large datasets. <p> Such methods do not yield the same classification accuracy as a decision tree classifier that uses the entire data set. [WC88]. Most current algorithms classification algorithm are based on ID3 algorithm <ref> [Qui93] </ref>. C4.5 [Qui93] is one of the commonly used algorithms. But it is not suitable for large disk resident data sets because it requires all the training set to be memory resident and requires sorting at each node. SLIQ classifier [MAR96] is designed to be more suitable for large datasets. <p> Here we provide a quick overview of the ID3 type decision tree classifier. For more details, the reader is referred to <ref> [Qui93] </ref>, [SAM96]. Figure 1 shows a decision tree constructed based on the training set shown. Each node of the decision-tree is either a 1. a leaf indicating a class, or 2. a decision node which specifies a test on a single attribute value.
Reference: [SAM96] <author> J. Shafer, Rakesh Agrawal, and Manish Mehta. SPRINT: </author> <title> A scalable parallel classifier for data mining. </title> <booktitle> In 22nd VLDB conference, </booktitle> <year> 1996. </year>
Reference-contexts: SLIQ classifier [MAR96] is designed to be more suitable for large datasets. But the algorithm requires a data structure proportional to the number of records to stay memory resident. This restriction puts a hard limit on the amount of data that can be handled by this classifier. SPRINT <ref> [SAM96] </ref> algorithm is a recently developed classification algorithm which is more scalable than SLIQ. But it also has a hash table data structure proportional to the number of tuples associated with the present decision tree node. This data structure should stay memory resident; otherwise the algorithm suffers serious I/O overheads. <p> Here we provide a quick overview of the ID3 type decision tree classifier. For more details, the reader is referred to [Qui93], <ref> [SAM96] </ref>. Figure 1 shows a decision tree constructed based on the training set shown. Each node of the decision-tree is either a 1. a leaf indicating a class, or 2. a decision node which specifies a test on a single attribute value. <p> Figure 12 shows the speedups. They are very close to the the ideal case of a horizontal line. The deviation from the ideal case is due to the fact that communication overhead increases as the number of processors increase. 7.4 Comparison with parallel SPRINT SPRINT paper <ref> [SAM96] </ref> contains details of SPRINT parallelizations. Although the design of SPRINT has been done to make it scalable, Some components of it are not very scalable.
Reference: [WC88] <author> J. Wirth and J. Catlett. </author> <title> Experiments on the costs and benefits of windowing in ID3. </title> <booktitle> In 5th Int'l Conference on Machine learning, </booktitle> <year> 1988. </year>
Reference-contexts: One way to reduce the computational complexity of decision tree classifier on large datasets is to use only a small sample of training data to construct the decision tree. Such methods do not yield the same classification accuracy as a decision tree classifier that uses the entire data set. <ref> [WC88] </ref>. Most current algorithms classification algorithm are based on ID3 algorithm [Qui93]. C4.5 [Qui93] is one of the commonly used algorithms. But it is not suitable for large disk resident data sets because it requires all the training set to be memory resident and requires sorting at each node.
References-found: 13

